Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=7, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 392-447
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00427444
Iteration 2/25 | Loss: 0.00167112
Iteration 3/25 | Loss: 0.00158103
Iteration 4/25 | Loss: 0.00156706
Iteration 5/25 | Loss: 0.00156305
Iteration 6/25 | Loss: 0.00156208
Iteration 7/25 | Loss: 0.00156208
Iteration 8/25 | Loss: 0.00156208
Iteration 9/25 | Loss: 0.00156208
Iteration 10/25 | Loss: 0.00156208
Iteration 11/25 | Loss: 0.00156208
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0015620783669874072, 0.0015620783669874072, 0.0015620783669874072, 0.0015620783669874072, 0.0015620783669874072]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015620783669874072

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67307961
Iteration 2/25 | Loss: 0.00373160
Iteration 3/25 | Loss: 0.00373160
Iteration 4/25 | Loss: 0.00373160
Iteration 5/25 | Loss: 0.00373160
Iteration 6/25 | Loss: 0.00373160
Iteration 7/25 | Loss: 0.00373160
Iteration 8/25 | Loss: 0.00373160
Iteration 9/25 | Loss: 0.00373160
Iteration 10/25 | Loss: 0.00373160
Iteration 11/25 | Loss: 0.00373160
Iteration 12/25 | Loss: 0.00373160
Iteration 13/25 | Loss: 0.00373159
Iteration 14/25 | Loss: 0.00373159
Iteration 15/25 | Loss: 0.00373159
Iteration 16/25 | Loss: 0.00373159
Iteration 17/25 | Loss: 0.00373159
Iteration 18/25 | Loss: 0.00373159
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0037315948866307735, 0.0037315948866307735, 0.0037315948866307735, 0.0037315948866307735, 0.0037315948866307735]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0037315948866307735

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00373159
Iteration 2/1000 | Loss: 0.00008004
Iteration 3/1000 | Loss: 0.00005247
Iteration 4/1000 | Loss: 0.00004060
Iteration 5/1000 | Loss: 0.00003523
Iteration 6/1000 | Loss: 0.00003281
Iteration 7/1000 | Loss: 0.00003097
Iteration 8/1000 | Loss: 0.00002972
Iteration 9/1000 | Loss: 0.00002938
Iteration 10/1000 | Loss: 0.00002900
Iteration 11/1000 | Loss: 0.00002870
Iteration 12/1000 | Loss: 0.00002840
Iteration 13/1000 | Loss: 0.00002810
Iteration 14/1000 | Loss: 0.00002802
Iteration 15/1000 | Loss: 0.00002783
Iteration 16/1000 | Loss: 0.00002782
Iteration 17/1000 | Loss: 0.00002778
Iteration 18/1000 | Loss: 0.00002774
Iteration 19/1000 | Loss: 0.00002773
Iteration 20/1000 | Loss: 0.00002773
Iteration 21/1000 | Loss: 0.00002773
Iteration 22/1000 | Loss: 0.00002773
Iteration 23/1000 | Loss: 0.00002772
Iteration 24/1000 | Loss: 0.00002771
Iteration 25/1000 | Loss: 0.00002770
Iteration 26/1000 | Loss: 0.00002768
Iteration 27/1000 | Loss: 0.00002767
Iteration 28/1000 | Loss: 0.00002766
Iteration 29/1000 | Loss: 0.00002766
Iteration 30/1000 | Loss: 0.00002766
Iteration 31/1000 | Loss: 0.00002761
Iteration 32/1000 | Loss: 0.00002758
Iteration 33/1000 | Loss: 0.00002757
Iteration 34/1000 | Loss: 0.00002751
Iteration 35/1000 | Loss: 0.00002751
Iteration 36/1000 | Loss: 0.00002750
Iteration 37/1000 | Loss: 0.00002750
Iteration 38/1000 | Loss: 0.00002750
Iteration 39/1000 | Loss: 0.00002750
Iteration 40/1000 | Loss: 0.00002750
Iteration 41/1000 | Loss: 0.00002750
Iteration 42/1000 | Loss: 0.00002750
Iteration 43/1000 | Loss: 0.00002748
Iteration 44/1000 | Loss: 0.00002748
Iteration 45/1000 | Loss: 0.00002747
Iteration 46/1000 | Loss: 0.00002747
Iteration 47/1000 | Loss: 0.00002747
Iteration 48/1000 | Loss: 0.00002747
Iteration 49/1000 | Loss: 0.00002747
Iteration 50/1000 | Loss: 0.00002746
Iteration 51/1000 | Loss: 0.00002746
Iteration 52/1000 | Loss: 0.00002746
Iteration 53/1000 | Loss: 0.00002746
Iteration 54/1000 | Loss: 0.00002746
Iteration 55/1000 | Loss: 0.00002746
Iteration 56/1000 | Loss: 0.00002746
Iteration 57/1000 | Loss: 0.00002746
Iteration 58/1000 | Loss: 0.00002746
Iteration 59/1000 | Loss: 0.00002745
Iteration 60/1000 | Loss: 0.00002745
Iteration 61/1000 | Loss: 0.00002745
Iteration 62/1000 | Loss: 0.00002745
Iteration 63/1000 | Loss: 0.00002744
Iteration 64/1000 | Loss: 0.00002744
Iteration 65/1000 | Loss: 0.00002744
Iteration 66/1000 | Loss: 0.00002743
Iteration 67/1000 | Loss: 0.00002743
Iteration 68/1000 | Loss: 0.00002742
Iteration 69/1000 | Loss: 0.00002742
Iteration 70/1000 | Loss: 0.00002742
Iteration 71/1000 | Loss: 0.00002741
Iteration 72/1000 | Loss: 0.00002741
Iteration 73/1000 | Loss: 0.00002740
Iteration 74/1000 | Loss: 0.00002739
Iteration 75/1000 | Loss: 0.00002739
Iteration 76/1000 | Loss: 0.00002738
Iteration 77/1000 | Loss: 0.00002738
Iteration 78/1000 | Loss: 0.00002738
Iteration 79/1000 | Loss: 0.00002737
Iteration 80/1000 | Loss: 0.00002737
Iteration 81/1000 | Loss: 0.00002736
Iteration 82/1000 | Loss: 0.00002736
Iteration 83/1000 | Loss: 0.00002736
Iteration 84/1000 | Loss: 0.00002735
Iteration 85/1000 | Loss: 0.00002735
Iteration 86/1000 | Loss: 0.00002735
Iteration 87/1000 | Loss: 0.00002734
Iteration 88/1000 | Loss: 0.00002733
Iteration 89/1000 | Loss: 0.00002733
Iteration 90/1000 | Loss: 0.00002733
Iteration 91/1000 | Loss: 0.00002733
Iteration 92/1000 | Loss: 0.00002732
Iteration 93/1000 | Loss: 0.00002732
Iteration 94/1000 | Loss: 0.00002731
Iteration 95/1000 | Loss: 0.00002730
Iteration 96/1000 | Loss: 0.00002728
Iteration 97/1000 | Loss: 0.00002728
Iteration 98/1000 | Loss: 0.00002728
Iteration 99/1000 | Loss: 0.00002728
Iteration 100/1000 | Loss: 0.00002728
Iteration 101/1000 | Loss: 0.00002727
Iteration 102/1000 | Loss: 0.00002727
Iteration 103/1000 | Loss: 0.00002727
Iteration 104/1000 | Loss: 0.00002727
Iteration 105/1000 | Loss: 0.00002727
Iteration 106/1000 | Loss: 0.00002727
Iteration 107/1000 | Loss: 0.00002727
Iteration 108/1000 | Loss: 0.00002725
Iteration 109/1000 | Loss: 0.00002725
Iteration 110/1000 | Loss: 0.00002725
Iteration 111/1000 | Loss: 0.00002725
Iteration 112/1000 | Loss: 0.00002725
Iteration 113/1000 | Loss: 0.00002725
Iteration 114/1000 | Loss: 0.00002725
Iteration 115/1000 | Loss: 0.00002725
Iteration 116/1000 | Loss: 0.00002725
Iteration 117/1000 | Loss: 0.00002725
Iteration 118/1000 | Loss: 0.00002724
Iteration 119/1000 | Loss: 0.00002724
Iteration 120/1000 | Loss: 0.00002724
Iteration 121/1000 | Loss: 0.00002724
Iteration 122/1000 | Loss: 0.00002724
Iteration 123/1000 | Loss: 0.00002724
Iteration 124/1000 | Loss: 0.00002724
Iteration 125/1000 | Loss: 0.00002724
Iteration 126/1000 | Loss: 0.00002724
Iteration 127/1000 | Loss: 0.00002723
Iteration 128/1000 | Loss: 0.00002723
Iteration 129/1000 | Loss: 0.00002723
Iteration 130/1000 | Loss: 0.00002722
Iteration 131/1000 | Loss: 0.00002722
Iteration 132/1000 | Loss: 0.00002722
Iteration 133/1000 | Loss: 0.00002722
Iteration 134/1000 | Loss: 0.00002722
Iteration 135/1000 | Loss: 0.00002721
Iteration 136/1000 | Loss: 0.00002721
Iteration 137/1000 | Loss: 0.00002721
Iteration 138/1000 | Loss: 0.00002720
Iteration 139/1000 | Loss: 0.00002720
Iteration 140/1000 | Loss: 0.00002720
Iteration 141/1000 | Loss: 0.00002720
Iteration 142/1000 | Loss: 0.00002720
Iteration 143/1000 | Loss: 0.00002720
Iteration 144/1000 | Loss: 0.00002719
Iteration 145/1000 | Loss: 0.00002719
Iteration 146/1000 | Loss: 0.00002719
Iteration 147/1000 | Loss: 0.00002719
Iteration 148/1000 | Loss: 0.00002719
Iteration 149/1000 | Loss: 0.00002719
Iteration 150/1000 | Loss: 0.00002719
Iteration 151/1000 | Loss: 0.00002719
Iteration 152/1000 | Loss: 0.00002718
Iteration 153/1000 | Loss: 0.00002718
Iteration 154/1000 | Loss: 0.00002718
Iteration 155/1000 | Loss: 0.00002718
Iteration 156/1000 | Loss: 0.00002718
Iteration 157/1000 | Loss: 0.00002718
Iteration 158/1000 | Loss: 0.00002717
Iteration 159/1000 | Loss: 0.00002717
Iteration 160/1000 | Loss: 0.00002717
Iteration 161/1000 | Loss: 0.00002717
Iteration 162/1000 | Loss: 0.00002717
Iteration 163/1000 | Loss: 0.00002717
Iteration 164/1000 | Loss: 0.00002717
Iteration 165/1000 | Loss: 0.00002717
Iteration 166/1000 | Loss: 0.00002717
Iteration 167/1000 | Loss: 0.00002717
Iteration 168/1000 | Loss: 0.00002717
Iteration 169/1000 | Loss: 0.00002716
Iteration 170/1000 | Loss: 0.00002716
Iteration 171/1000 | Loss: 0.00002716
Iteration 172/1000 | Loss: 0.00002716
Iteration 173/1000 | Loss: 0.00002716
Iteration 174/1000 | Loss: 0.00002716
Iteration 175/1000 | Loss: 0.00002716
Iteration 176/1000 | Loss: 0.00002716
Iteration 177/1000 | Loss: 0.00002716
Iteration 178/1000 | Loss: 0.00002716
Iteration 179/1000 | Loss: 0.00002716
Iteration 180/1000 | Loss: 0.00002715
Iteration 181/1000 | Loss: 0.00002715
Iteration 182/1000 | Loss: 0.00002715
Iteration 183/1000 | Loss: 0.00002715
Iteration 184/1000 | Loss: 0.00002715
Iteration 185/1000 | Loss: 0.00002715
Iteration 186/1000 | Loss: 0.00002715
Iteration 187/1000 | Loss: 0.00002715
Iteration 188/1000 | Loss: 0.00002715
Iteration 189/1000 | Loss: 0.00002715
Iteration 190/1000 | Loss: 0.00002715
Iteration 191/1000 | Loss: 0.00002715
Iteration 192/1000 | Loss: 0.00002715
Iteration 193/1000 | Loss: 0.00002715
Iteration 194/1000 | Loss: 0.00002715
Iteration 195/1000 | Loss: 0.00002715
Iteration 196/1000 | Loss: 0.00002715
Iteration 197/1000 | Loss: 0.00002715
Iteration 198/1000 | Loss: 0.00002715
Iteration 199/1000 | Loss: 0.00002714
Iteration 200/1000 | Loss: 0.00002714
Iteration 201/1000 | Loss: 0.00002714
Iteration 202/1000 | Loss: 0.00002714
Iteration 203/1000 | Loss: 0.00002714
Iteration 204/1000 | Loss: 0.00002714
Iteration 205/1000 | Loss: 0.00002713
Iteration 206/1000 | Loss: 0.00002713
Iteration 207/1000 | Loss: 0.00002713
Iteration 208/1000 | Loss: 0.00002713
Iteration 209/1000 | Loss: 0.00002713
Iteration 210/1000 | Loss: 0.00002713
Iteration 211/1000 | Loss: 0.00002713
Iteration 212/1000 | Loss: 0.00002713
Iteration 213/1000 | Loss: 0.00002712
Iteration 214/1000 | Loss: 0.00002712
Iteration 215/1000 | Loss: 0.00002712
Iteration 216/1000 | Loss: 0.00002712
Iteration 217/1000 | Loss: 0.00002712
Iteration 218/1000 | Loss: 0.00002712
Iteration 219/1000 | Loss: 0.00002712
Iteration 220/1000 | Loss: 0.00002712
Iteration 221/1000 | Loss: 0.00002712
Iteration 222/1000 | Loss: 0.00002712
Iteration 223/1000 | Loss: 0.00002712
Iteration 224/1000 | Loss: 0.00002712
Iteration 225/1000 | Loss: 0.00002712
Iteration 226/1000 | Loss: 0.00002712
Iteration 227/1000 | Loss: 0.00002712
Iteration 228/1000 | Loss: 0.00002712
Iteration 229/1000 | Loss: 0.00002712
Iteration 230/1000 | Loss: 0.00002712
Iteration 231/1000 | Loss: 0.00002712
Iteration 232/1000 | Loss: 0.00002712
Iteration 233/1000 | Loss: 0.00002712
Iteration 234/1000 | Loss: 0.00002712
Iteration 235/1000 | Loss: 0.00002712
Iteration 236/1000 | Loss: 0.00002712
Iteration 237/1000 | Loss: 0.00002712
Iteration 238/1000 | Loss: 0.00002712
Iteration 239/1000 | Loss: 0.00002712
Iteration 240/1000 | Loss: 0.00002712
Iteration 241/1000 | Loss: 0.00002712
Iteration 242/1000 | Loss: 0.00002712
Iteration 243/1000 | Loss: 0.00002712
Iteration 244/1000 | Loss: 0.00002712
Iteration 245/1000 | Loss: 0.00002712
Iteration 246/1000 | Loss: 0.00002712
Iteration 247/1000 | Loss: 0.00002712
Iteration 248/1000 | Loss: 0.00002712
Iteration 249/1000 | Loss: 0.00002712
Iteration 250/1000 | Loss: 0.00002712
Iteration 251/1000 | Loss: 0.00002712
Iteration 252/1000 | Loss: 0.00002712
Iteration 253/1000 | Loss: 0.00002712
Iteration 254/1000 | Loss: 0.00002712
Iteration 255/1000 | Loss: 0.00002712
Iteration 256/1000 | Loss: 0.00002712
Iteration 257/1000 | Loss: 0.00002712
Iteration 258/1000 | Loss: 0.00002712
Iteration 259/1000 | Loss: 0.00002712
Iteration 260/1000 | Loss: 0.00002712
Iteration 261/1000 | Loss: 0.00002712
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 261. Stopping optimization.
Last 5 losses: [2.7118645448354073e-05, 2.7118645448354073e-05, 2.7118645448354073e-05, 2.7118645448354073e-05, 2.7118645448354073e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7118645448354073e-05

Optimization complete. Final v2v error: 4.618030071258545 mm

Highest mean error: 4.888974666595459 mm for frame 112

Lowest mean error: 4.334351062774658 mm for frame 149

Saving results

Total time: 47.95930862426758
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00957689
Iteration 2/25 | Loss: 0.00191214
Iteration 3/25 | Loss: 0.00158482
Iteration 4/25 | Loss: 0.00155598
Iteration 5/25 | Loss: 0.00154871
Iteration 6/25 | Loss: 0.00154797
Iteration 7/25 | Loss: 0.00154797
Iteration 8/25 | Loss: 0.00154797
Iteration 9/25 | Loss: 0.00154797
Iteration 10/25 | Loss: 0.00154797
Iteration 11/25 | Loss: 0.00154797
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0015479696448892355, 0.0015479696448892355, 0.0015479696448892355, 0.0015479696448892355, 0.0015479696448892355]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015479696448892355

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65755367
Iteration 2/25 | Loss: 0.00310111
Iteration 3/25 | Loss: 0.00310111
Iteration 4/25 | Loss: 0.00310111
Iteration 5/25 | Loss: 0.00310111
Iteration 6/25 | Loss: 0.00310111
Iteration 7/25 | Loss: 0.00310111
Iteration 8/25 | Loss: 0.00310110
Iteration 9/25 | Loss: 0.00310110
Iteration 10/25 | Loss: 0.00310110
Iteration 11/25 | Loss: 0.00310110
Iteration 12/25 | Loss: 0.00310110
Iteration 13/25 | Loss: 0.00310110
Iteration 14/25 | Loss: 0.00310110
Iteration 15/25 | Loss: 0.00310110
Iteration 16/25 | Loss: 0.00310110
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.003101103939116001, 0.003101103939116001, 0.003101103939116001, 0.003101103939116001, 0.003101103939116001]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003101103939116001

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00310110
Iteration 2/1000 | Loss: 0.00006117
Iteration 3/1000 | Loss: 0.00004324
Iteration 4/1000 | Loss: 0.00003808
Iteration 5/1000 | Loss: 0.00003583
Iteration 6/1000 | Loss: 0.00003479
Iteration 7/1000 | Loss: 0.00003423
Iteration 8/1000 | Loss: 0.00003384
Iteration 9/1000 | Loss: 0.00003337
Iteration 10/1000 | Loss: 0.00003298
Iteration 11/1000 | Loss: 0.00003277
Iteration 12/1000 | Loss: 0.00003269
Iteration 13/1000 | Loss: 0.00003260
Iteration 14/1000 | Loss: 0.00003254
Iteration 15/1000 | Loss: 0.00003251
Iteration 16/1000 | Loss: 0.00003250
Iteration 17/1000 | Loss: 0.00003250
Iteration 18/1000 | Loss: 0.00003250
Iteration 19/1000 | Loss: 0.00003249
Iteration 20/1000 | Loss: 0.00003249
Iteration 21/1000 | Loss: 0.00003249
Iteration 22/1000 | Loss: 0.00003249
Iteration 23/1000 | Loss: 0.00003248
Iteration 24/1000 | Loss: 0.00003248
Iteration 25/1000 | Loss: 0.00003248
Iteration 26/1000 | Loss: 0.00003248
Iteration 27/1000 | Loss: 0.00003248
Iteration 28/1000 | Loss: 0.00003247
Iteration 29/1000 | Loss: 0.00003247
Iteration 30/1000 | Loss: 0.00003247
Iteration 31/1000 | Loss: 0.00003247
Iteration 32/1000 | Loss: 0.00003247
Iteration 33/1000 | Loss: 0.00003246
Iteration 34/1000 | Loss: 0.00003246
Iteration 35/1000 | Loss: 0.00003246
Iteration 36/1000 | Loss: 0.00003246
Iteration 37/1000 | Loss: 0.00003246
Iteration 38/1000 | Loss: 0.00003245
Iteration 39/1000 | Loss: 0.00003245
Iteration 40/1000 | Loss: 0.00003245
Iteration 41/1000 | Loss: 0.00003245
Iteration 42/1000 | Loss: 0.00003245
Iteration 43/1000 | Loss: 0.00003245
Iteration 44/1000 | Loss: 0.00003245
Iteration 45/1000 | Loss: 0.00003245
Iteration 46/1000 | Loss: 0.00003245
Iteration 47/1000 | Loss: 0.00003245
Iteration 48/1000 | Loss: 0.00003245
Iteration 49/1000 | Loss: 0.00003244
Iteration 50/1000 | Loss: 0.00003244
Iteration 51/1000 | Loss: 0.00003244
Iteration 52/1000 | Loss: 0.00003244
Iteration 53/1000 | Loss: 0.00003244
Iteration 54/1000 | Loss: 0.00003244
Iteration 55/1000 | Loss: 0.00003244
Iteration 56/1000 | Loss: 0.00003244
Iteration 57/1000 | Loss: 0.00003244
Iteration 58/1000 | Loss: 0.00003244
Iteration 59/1000 | Loss: 0.00003244
Iteration 60/1000 | Loss: 0.00003244
Iteration 61/1000 | Loss: 0.00003243
Iteration 62/1000 | Loss: 0.00003243
Iteration 63/1000 | Loss: 0.00003243
Iteration 64/1000 | Loss: 0.00003243
Iteration 65/1000 | Loss: 0.00003242
Iteration 66/1000 | Loss: 0.00003241
Iteration 67/1000 | Loss: 0.00003241
Iteration 68/1000 | Loss: 0.00003241
Iteration 69/1000 | Loss: 0.00003241
Iteration 70/1000 | Loss: 0.00003240
Iteration 71/1000 | Loss: 0.00003240
Iteration 72/1000 | Loss: 0.00003240
Iteration 73/1000 | Loss: 0.00003240
Iteration 74/1000 | Loss: 0.00003240
Iteration 75/1000 | Loss: 0.00003239
Iteration 76/1000 | Loss: 0.00003239
Iteration 77/1000 | Loss: 0.00003239
Iteration 78/1000 | Loss: 0.00003239
Iteration 79/1000 | Loss: 0.00003239
Iteration 80/1000 | Loss: 0.00003239
Iteration 81/1000 | Loss: 0.00003239
Iteration 82/1000 | Loss: 0.00003239
Iteration 83/1000 | Loss: 0.00003239
Iteration 84/1000 | Loss: 0.00003239
Iteration 85/1000 | Loss: 0.00003239
Iteration 86/1000 | Loss: 0.00003239
Iteration 87/1000 | Loss: 0.00003239
Iteration 88/1000 | Loss: 0.00003239
Iteration 89/1000 | Loss: 0.00003239
Iteration 90/1000 | Loss: 0.00003239
Iteration 91/1000 | Loss: 0.00003239
Iteration 92/1000 | Loss: 0.00003239
Iteration 93/1000 | Loss: 0.00003239
Iteration 94/1000 | Loss: 0.00003239
Iteration 95/1000 | Loss: 0.00003239
Iteration 96/1000 | Loss: 0.00003239
Iteration 97/1000 | Loss: 0.00003239
Iteration 98/1000 | Loss: 0.00003239
Iteration 99/1000 | Loss: 0.00003239
Iteration 100/1000 | Loss: 0.00003239
Iteration 101/1000 | Loss: 0.00003239
Iteration 102/1000 | Loss: 0.00003239
Iteration 103/1000 | Loss: 0.00003239
Iteration 104/1000 | Loss: 0.00003239
Iteration 105/1000 | Loss: 0.00003239
Iteration 106/1000 | Loss: 0.00003239
Iteration 107/1000 | Loss: 0.00003239
Iteration 108/1000 | Loss: 0.00003239
Iteration 109/1000 | Loss: 0.00003239
Iteration 110/1000 | Loss: 0.00003239
Iteration 111/1000 | Loss: 0.00003239
Iteration 112/1000 | Loss: 0.00003239
Iteration 113/1000 | Loss: 0.00003239
Iteration 114/1000 | Loss: 0.00003239
Iteration 115/1000 | Loss: 0.00003239
Iteration 116/1000 | Loss: 0.00003239
Iteration 117/1000 | Loss: 0.00003239
Iteration 118/1000 | Loss: 0.00003239
Iteration 119/1000 | Loss: 0.00003239
Iteration 120/1000 | Loss: 0.00003239
Iteration 121/1000 | Loss: 0.00003239
Iteration 122/1000 | Loss: 0.00003239
Iteration 123/1000 | Loss: 0.00003239
Iteration 124/1000 | Loss: 0.00003239
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [3.238730278098956e-05, 3.238730278098956e-05, 3.238730278098956e-05, 3.238730278098956e-05, 3.238730278098956e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.238730278098956e-05

Optimization complete. Final v2v error: 4.958438873291016 mm

Highest mean error: 5.144105434417725 mm for frame 0

Lowest mean error: 4.821660041809082 mm for frame 15

Saving results

Total time: 31.50408411026001
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01001636
Iteration 2/25 | Loss: 0.00177756
Iteration 3/25 | Loss: 0.00163542
Iteration 4/25 | Loss: 0.00159078
Iteration 5/25 | Loss: 0.00158056
Iteration 6/25 | Loss: 0.00157859
Iteration 7/25 | Loss: 0.00157858
Iteration 8/25 | Loss: 0.00157858
Iteration 9/25 | Loss: 0.00157858
Iteration 10/25 | Loss: 0.00157858
Iteration 11/25 | Loss: 0.00157858
Iteration 12/25 | Loss: 0.00157858
Iteration 13/25 | Loss: 0.00157858
Iteration 14/25 | Loss: 0.00157858
Iteration 15/25 | Loss: 0.00157858
Iteration 16/25 | Loss: 0.00157858
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0015785794239491224, 0.0015785794239491224, 0.0015785794239491224, 0.0015785794239491224, 0.0015785794239491224]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015785794239491224

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60427523
Iteration 2/25 | Loss: 0.00297383
Iteration 3/25 | Loss: 0.00297379
Iteration 4/25 | Loss: 0.00297379
Iteration 5/25 | Loss: 0.00297379
Iteration 6/25 | Loss: 0.00297379
Iteration 7/25 | Loss: 0.00297379
Iteration 8/25 | Loss: 0.00297379
Iteration 9/25 | Loss: 0.00297379
Iteration 10/25 | Loss: 0.00297379
Iteration 11/25 | Loss: 0.00297379
Iteration 12/25 | Loss: 0.00297379
Iteration 13/25 | Loss: 0.00297379
Iteration 14/25 | Loss: 0.00297379
Iteration 15/25 | Loss: 0.00297379
Iteration 16/25 | Loss: 0.00297379
Iteration 17/25 | Loss: 0.00297379
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0029737891163676977, 0.0029737891163676977, 0.0029737891163676977, 0.0029737891163676977, 0.0029737891163676977]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0029737891163676977

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00297379
Iteration 2/1000 | Loss: 0.00007406
Iteration 3/1000 | Loss: 0.00005552
Iteration 4/1000 | Loss: 0.00004670
Iteration 5/1000 | Loss: 0.00004354
Iteration 6/1000 | Loss: 0.00004129
Iteration 7/1000 | Loss: 0.00003972
Iteration 8/1000 | Loss: 0.00003860
Iteration 9/1000 | Loss: 0.00003801
Iteration 10/1000 | Loss: 0.00003756
Iteration 11/1000 | Loss: 0.00003711
Iteration 12/1000 | Loss: 0.00003683
Iteration 13/1000 | Loss: 0.00003663
Iteration 14/1000 | Loss: 0.00003651
Iteration 15/1000 | Loss: 0.00003647
Iteration 16/1000 | Loss: 0.00003645
Iteration 17/1000 | Loss: 0.00003644
Iteration 18/1000 | Loss: 0.00003644
Iteration 19/1000 | Loss: 0.00003643
Iteration 20/1000 | Loss: 0.00003643
Iteration 21/1000 | Loss: 0.00003642
Iteration 22/1000 | Loss: 0.00003642
Iteration 23/1000 | Loss: 0.00003641
Iteration 24/1000 | Loss: 0.00003641
Iteration 25/1000 | Loss: 0.00003641
Iteration 26/1000 | Loss: 0.00003641
Iteration 27/1000 | Loss: 0.00003640
Iteration 28/1000 | Loss: 0.00003640
Iteration 29/1000 | Loss: 0.00003640
Iteration 30/1000 | Loss: 0.00003637
Iteration 31/1000 | Loss: 0.00003637
Iteration 32/1000 | Loss: 0.00003637
Iteration 33/1000 | Loss: 0.00003637
Iteration 34/1000 | Loss: 0.00003636
Iteration 35/1000 | Loss: 0.00003636
Iteration 36/1000 | Loss: 0.00003635
Iteration 37/1000 | Loss: 0.00003635
Iteration 38/1000 | Loss: 0.00003634
Iteration 39/1000 | Loss: 0.00003634
Iteration 40/1000 | Loss: 0.00003634
Iteration 41/1000 | Loss: 0.00003634
Iteration 42/1000 | Loss: 0.00003634
Iteration 43/1000 | Loss: 0.00003634
Iteration 44/1000 | Loss: 0.00003634
Iteration 45/1000 | Loss: 0.00003633
Iteration 46/1000 | Loss: 0.00003633
Iteration 47/1000 | Loss: 0.00003633
Iteration 48/1000 | Loss: 0.00003632
Iteration 49/1000 | Loss: 0.00003632
Iteration 50/1000 | Loss: 0.00003632
Iteration 51/1000 | Loss: 0.00003632
Iteration 52/1000 | Loss: 0.00003632
Iteration 53/1000 | Loss: 0.00003632
Iteration 54/1000 | Loss: 0.00003632
Iteration 55/1000 | Loss: 0.00003632
Iteration 56/1000 | Loss: 0.00003631
Iteration 57/1000 | Loss: 0.00003631
Iteration 58/1000 | Loss: 0.00003631
Iteration 59/1000 | Loss: 0.00003631
Iteration 60/1000 | Loss: 0.00003631
Iteration 61/1000 | Loss: 0.00003631
Iteration 62/1000 | Loss: 0.00003631
Iteration 63/1000 | Loss: 0.00003631
Iteration 64/1000 | Loss: 0.00003631
Iteration 65/1000 | Loss: 0.00003631
Iteration 66/1000 | Loss: 0.00003631
Iteration 67/1000 | Loss: 0.00003631
Iteration 68/1000 | Loss: 0.00003631
Iteration 69/1000 | Loss: 0.00003631
Iteration 70/1000 | Loss: 0.00003631
Iteration 71/1000 | Loss: 0.00003631
Iteration 72/1000 | Loss: 0.00003631
Iteration 73/1000 | Loss: 0.00003631
Iteration 74/1000 | Loss: 0.00003631
Iteration 75/1000 | Loss: 0.00003631
Iteration 76/1000 | Loss: 0.00003631
Iteration 77/1000 | Loss: 0.00003631
Iteration 78/1000 | Loss: 0.00003631
Iteration 79/1000 | Loss: 0.00003631
Iteration 80/1000 | Loss: 0.00003631
Iteration 81/1000 | Loss: 0.00003631
Iteration 82/1000 | Loss: 0.00003631
Iteration 83/1000 | Loss: 0.00003631
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 83. Stopping optimization.
Last 5 losses: [3.631275103543885e-05, 3.631275103543885e-05, 3.631275103543885e-05, 3.631275103543885e-05, 3.631275103543885e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.631275103543885e-05

Optimization complete. Final v2v error: 5.117737770080566 mm

Highest mean error: 6.5434250831604 mm for frame 70

Lowest mean error: 4.304594993591309 mm for frame 6

Saving results

Total time: 32.0295045375824
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01181267
Iteration 2/25 | Loss: 0.01181267
Iteration 3/25 | Loss: 0.00302626
Iteration 4/25 | Loss: 0.00199317
Iteration 5/25 | Loss: 0.00204451
Iteration 6/25 | Loss: 0.00190486
Iteration 7/25 | Loss: 0.00182528
Iteration 8/25 | Loss: 0.00180029
Iteration 9/25 | Loss: 0.00175198
Iteration 10/25 | Loss: 0.00170895
Iteration 11/25 | Loss: 0.00171673
Iteration 12/25 | Loss: 0.00169017
Iteration 13/25 | Loss: 0.00170828
Iteration 14/25 | Loss: 0.00164105
Iteration 15/25 | Loss: 0.00163801
Iteration 16/25 | Loss: 0.00162324
Iteration 17/25 | Loss: 0.00163282
Iteration 18/25 | Loss: 0.00163807
Iteration 19/25 | Loss: 0.00161835
Iteration 20/25 | Loss: 0.00162130
Iteration 21/25 | Loss: 0.00162029
Iteration 22/25 | Loss: 0.00163928
Iteration 23/25 | Loss: 0.00160311
Iteration 24/25 | Loss: 0.00159082
Iteration 25/25 | Loss: 0.00158226

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79386568
Iteration 2/25 | Loss: 0.01136056
Iteration 3/25 | Loss: 0.00747844
Iteration 4/25 | Loss: 0.00747844
Iteration 5/25 | Loss: 0.00747844
Iteration 6/25 | Loss: 0.00747844
Iteration 7/25 | Loss: 0.00747844
Iteration 8/25 | Loss: 0.00747844
Iteration 9/25 | Loss: 0.00747844
Iteration 10/25 | Loss: 0.00747844
Iteration 11/25 | Loss: 0.00747844
Iteration 12/25 | Loss: 0.00747844
Iteration 13/25 | Loss: 0.00747844
Iteration 14/25 | Loss: 0.00747844
Iteration 15/25 | Loss: 0.00747844
Iteration 16/25 | Loss: 0.00747844
Iteration 17/25 | Loss: 0.00747844
Iteration 18/25 | Loss: 0.00747844
Iteration 19/25 | Loss: 0.00747844
Iteration 20/25 | Loss: 0.00747843
Iteration 21/25 | Loss: 0.00747844
Iteration 22/25 | Loss: 0.00747844
Iteration 23/25 | Loss: 0.00747844
Iteration 24/25 | Loss: 0.00747844
Iteration 25/25 | Loss: 0.00747844

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00747844
Iteration 2/1000 | Loss: 0.00345054
Iteration 3/1000 | Loss: 0.00697909
Iteration 4/1000 | Loss: 0.00501447
Iteration 5/1000 | Loss: 0.00382903
Iteration 6/1000 | Loss: 0.00465067
Iteration 7/1000 | Loss: 0.00247194
Iteration 8/1000 | Loss: 0.00545565
Iteration 9/1000 | Loss: 0.00323990
Iteration 10/1000 | Loss: 0.00212895
Iteration 11/1000 | Loss: 0.00345976
Iteration 12/1000 | Loss: 0.00323452
Iteration 13/1000 | Loss: 0.01596039
Iteration 14/1000 | Loss: 0.00830747
Iteration 15/1000 | Loss: 0.02217768
Iteration 16/1000 | Loss: 0.00412803
Iteration 17/1000 | Loss: 0.00251670
Iteration 18/1000 | Loss: 0.01249261
Iteration 19/1000 | Loss: 0.00532890
Iteration 20/1000 | Loss: 0.00455725
Iteration 21/1000 | Loss: 0.00512943
Iteration 22/1000 | Loss: 0.00867434
Iteration 23/1000 | Loss: 0.00730126
Iteration 24/1000 | Loss: 0.00317058
Iteration 25/1000 | Loss: 0.00575720
Iteration 26/1000 | Loss: 0.01006978
Iteration 27/1000 | Loss: 0.00312452
Iteration 28/1000 | Loss: 0.00440654
Iteration 29/1000 | Loss: 0.00261936
Iteration 30/1000 | Loss: 0.00336142
Iteration 31/1000 | Loss: 0.00873681
Iteration 32/1000 | Loss: 0.00779750
Iteration 33/1000 | Loss: 0.00423760
Iteration 34/1000 | Loss: 0.00695290
Iteration 35/1000 | Loss: 0.00291516
Iteration 36/1000 | Loss: 0.00291842
Iteration 37/1000 | Loss: 0.00505203
Iteration 38/1000 | Loss: 0.00282671
Iteration 39/1000 | Loss: 0.00284049
Iteration 40/1000 | Loss: 0.00247047
Iteration 41/1000 | Loss: 0.00309198
Iteration 42/1000 | Loss: 0.00327122
Iteration 43/1000 | Loss: 0.00363729
Iteration 44/1000 | Loss: 0.00263410
Iteration 45/1000 | Loss: 0.00245603
Iteration 46/1000 | Loss: 0.00244645
Iteration 47/1000 | Loss: 0.00141669
Iteration 48/1000 | Loss: 0.00141396
Iteration 49/1000 | Loss: 0.00223101
Iteration 50/1000 | Loss: 0.00259527
Iteration 51/1000 | Loss: 0.00271340
Iteration 52/1000 | Loss: 0.00178957
Iteration 53/1000 | Loss: 0.00187927
Iteration 54/1000 | Loss: 0.00341482
Iteration 55/1000 | Loss: 0.00222589
Iteration 56/1000 | Loss: 0.00175894
Iteration 57/1000 | Loss: 0.00166941
Iteration 58/1000 | Loss: 0.00346820
Iteration 59/1000 | Loss: 0.00341584
Iteration 60/1000 | Loss: 0.00364901
Iteration 61/1000 | Loss: 0.00293400
Iteration 62/1000 | Loss: 0.00405624
Iteration 63/1000 | Loss: 0.00464320
Iteration 64/1000 | Loss: 0.00304611
Iteration 65/1000 | Loss: 0.00514047
Iteration 66/1000 | Loss: 0.00411750
Iteration 67/1000 | Loss: 0.00214019
Iteration 68/1000 | Loss: 0.00400996
Iteration 69/1000 | Loss: 0.00358274
Iteration 70/1000 | Loss: 0.00216881
Iteration 71/1000 | Loss: 0.00237397
Iteration 72/1000 | Loss: 0.00258705
Iteration 73/1000 | Loss: 0.00192047
Iteration 74/1000 | Loss: 0.00196870
Iteration 75/1000 | Loss: 0.00191078
Iteration 76/1000 | Loss: 0.00413457
Iteration 77/1000 | Loss: 0.00192168
Iteration 78/1000 | Loss: 0.00184267
Iteration 79/1000 | Loss: 0.00171290
Iteration 80/1000 | Loss: 0.00179630
Iteration 81/1000 | Loss: 0.00325857
Iteration 82/1000 | Loss: 0.00277976
Iteration 83/1000 | Loss: 0.00396862
Iteration 84/1000 | Loss: 0.00455023
Iteration 85/1000 | Loss: 0.00142361
Iteration 86/1000 | Loss: 0.00232513
Iteration 87/1000 | Loss: 0.00142746
Iteration 88/1000 | Loss: 0.00143866
Iteration 89/1000 | Loss: 0.00144906
Iteration 90/1000 | Loss: 0.00117720
Iteration 91/1000 | Loss: 0.00132389
Iteration 92/1000 | Loss: 0.00156555
Iteration 93/1000 | Loss: 0.00123315
Iteration 94/1000 | Loss: 0.00145988
Iteration 95/1000 | Loss: 0.00163213
Iteration 96/1000 | Loss: 0.00201204
Iteration 97/1000 | Loss: 0.00178750
Iteration 98/1000 | Loss: 0.00159840
Iteration 99/1000 | Loss: 0.00254711
Iteration 100/1000 | Loss: 0.00195403
Iteration 101/1000 | Loss: 0.00308005
Iteration 102/1000 | Loss: 0.00378487
Iteration 103/1000 | Loss: 0.00123307
Iteration 104/1000 | Loss: 0.00197289
Iteration 105/1000 | Loss: 0.00128453
Iteration 106/1000 | Loss: 0.00121826
Iteration 107/1000 | Loss: 0.00183459
Iteration 108/1000 | Loss: 0.00162490
Iteration 109/1000 | Loss: 0.00090031
Iteration 110/1000 | Loss: 0.00169020
Iteration 111/1000 | Loss: 0.00128639
Iteration 112/1000 | Loss: 0.00132224
Iteration 113/1000 | Loss: 0.00071478
Iteration 114/1000 | Loss: 0.00079134
Iteration 115/1000 | Loss: 0.00192560
Iteration 116/1000 | Loss: 0.00093936
Iteration 117/1000 | Loss: 0.00078728
Iteration 118/1000 | Loss: 0.00119042
Iteration 119/1000 | Loss: 0.00095565
Iteration 120/1000 | Loss: 0.00084405
Iteration 121/1000 | Loss: 0.00053774
Iteration 122/1000 | Loss: 0.00059973
Iteration 123/1000 | Loss: 0.00072878
Iteration 124/1000 | Loss: 0.00113827
Iteration 125/1000 | Loss: 0.00132712
Iteration 126/1000 | Loss: 0.00246870
Iteration 127/1000 | Loss: 0.00176392
Iteration 128/1000 | Loss: 0.00144933
Iteration 129/1000 | Loss: 0.00106705
Iteration 130/1000 | Loss: 0.00085804
Iteration 131/1000 | Loss: 0.00097945
Iteration 132/1000 | Loss: 0.00108321
Iteration 133/1000 | Loss: 0.00096026
Iteration 134/1000 | Loss: 0.00095307
Iteration 135/1000 | Loss: 0.00100285
Iteration 136/1000 | Loss: 0.00073290
Iteration 137/1000 | Loss: 0.00066333
Iteration 138/1000 | Loss: 0.00092744
Iteration 139/1000 | Loss: 0.00106778
Iteration 140/1000 | Loss: 0.00086399
Iteration 141/1000 | Loss: 0.00043464
Iteration 142/1000 | Loss: 0.00095962
Iteration 143/1000 | Loss: 0.00052534
Iteration 144/1000 | Loss: 0.00049326
Iteration 145/1000 | Loss: 0.00049626
Iteration 146/1000 | Loss: 0.00038719
Iteration 147/1000 | Loss: 0.00022051
Iteration 148/1000 | Loss: 0.00037395
Iteration 149/1000 | Loss: 0.00032321
Iteration 150/1000 | Loss: 0.00028624
Iteration 151/1000 | Loss: 0.00034716
Iteration 152/1000 | Loss: 0.00045228
Iteration 153/1000 | Loss: 0.00027605
Iteration 154/1000 | Loss: 0.00040413
Iteration 155/1000 | Loss: 0.00027062
Iteration 156/1000 | Loss: 0.00032590
Iteration 157/1000 | Loss: 0.00029056
Iteration 158/1000 | Loss: 0.00048247
Iteration 159/1000 | Loss: 0.00033959
Iteration 160/1000 | Loss: 0.00033963
Iteration 161/1000 | Loss: 0.00036314
Iteration 162/1000 | Loss: 0.00033245
Iteration 163/1000 | Loss: 0.00054023
Iteration 164/1000 | Loss: 0.00060722
Iteration 165/1000 | Loss: 0.00068903
Iteration 166/1000 | Loss: 0.00040778
Iteration 167/1000 | Loss: 0.00019071
Iteration 168/1000 | Loss: 0.00030788
Iteration 169/1000 | Loss: 0.00022725
Iteration 170/1000 | Loss: 0.00044635
Iteration 171/1000 | Loss: 0.00026585
Iteration 172/1000 | Loss: 0.00020490
Iteration 173/1000 | Loss: 0.00013094
Iteration 174/1000 | Loss: 0.00030529
Iteration 175/1000 | Loss: 0.00017522
Iteration 176/1000 | Loss: 0.00037158
Iteration 177/1000 | Loss: 0.00034533
Iteration 178/1000 | Loss: 0.00047642
Iteration 179/1000 | Loss: 0.00005105
Iteration 180/1000 | Loss: 0.00029933
Iteration 181/1000 | Loss: 0.00011302
Iteration 182/1000 | Loss: 0.00004840
Iteration 183/1000 | Loss: 0.00028491
Iteration 184/1000 | Loss: 0.00004724
Iteration 185/1000 | Loss: 0.00004660
Iteration 186/1000 | Loss: 0.00059960
Iteration 187/1000 | Loss: 0.00042408
Iteration 188/1000 | Loss: 0.00038015
Iteration 189/1000 | Loss: 0.00004668
Iteration 190/1000 | Loss: 0.00004422
Iteration 191/1000 | Loss: 0.00004292
Iteration 192/1000 | Loss: 0.00034761
Iteration 193/1000 | Loss: 0.00004247
Iteration 194/1000 | Loss: 0.00004173
Iteration 195/1000 | Loss: 0.00005169
Iteration 196/1000 | Loss: 0.00004107
Iteration 197/1000 | Loss: 0.00060257
Iteration 198/1000 | Loss: 0.00060257
Iteration 199/1000 | Loss: 0.00097469
Iteration 200/1000 | Loss: 0.00037856
Iteration 201/1000 | Loss: 0.00045195
Iteration 202/1000 | Loss: 0.00013804
Iteration 203/1000 | Loss: 0.00023554
Iteration 204/1000 | Loss: 0.00004419
Iteration 205/1000 | Loss: 0.00004064
Iteration 206/1000 | Loss: 0.00004038
Iteration 207/1000 | Loss: 0.00032459
Iteration 208/1000 | Loss: 0.00007816
Iteration 209/1000 | Loss: 0.00010218
Iteration 210/1000 | Loss: 0.00131997
Iteration 211/1000 | Loss: 0.00044682
Iteration 212/1000 | Loss: 0.00059681
Iteration 213/1000 | Loss: 0.00004342
Iteration 214/1000 | Loss: 0.00005159
Iteration 215/1000 | Loss: 0.00004029
Iteration 216/1000 | Loss: 0.00004003
Iteration 217/1000 | Loss: 0.00003984
Iteration 218/1000 | Loss: 0.00003974
Iteration 219/1000 | Loss: 0.00003974
Iteration 220/1000 | Loss: 0.00031632
Iteration 221/1000 | Loss: 0.00015113
Iteration 222/1000 | Loss: 0.00009308
Iteration 223/1000 | Loss: 0.00004206
Iteration 224/1000 | Loss: 0.00004014
Iteration 225/1000 | Loss: 0.00004100
Iteration 226/1000 | Loss: 0.00003983
Iteration 227/1000 | Loss: 0.00026074
Iteration 228/1000 | Loss: 0.00026074
Iteration 229/1000 | Loss: 0.00019618
Iteration 230/1000 | Loss: 0.00004893
Iteration 231/1000 | Loss: 0.00003969
Iteration 232/1000 | Loss: 0.00003967
Iteration 233/1000 | Loss: 0.00003967
Iteration 234/1000 | Loss: 0.00004790
Iteration 235/1000 | Loss: 0.00056106
Iteration 236/1000 | Loss: 0.00036147
Iteration 237/1000 | Loss: 0.00013310
Iteration 238/1000 | Loss: 0.00005145
Iteration 239/1000 | Loss: 0.00003976
Iteration 240/1000 | Loss: 0.00003961
Iteration 241/1000 | Loss: 0.00003961
Iteration 242/1000 | Loss: 0.00003961
Iteration 243/1000 | Loss: 0.00003959
Iteration 244/1000 | Loss: 0.00003958
Iteration 245/1000 | Loss: 0.00003958
Iteration 246/1000 | Loss: 0.00003958
Iteration 247/1000 | Loss: 0.00003957
Iteration 248/1000 | Loss: 0.00003956
Iteration 249/1000 | Loss: 0.00003956
Iteration 250/1000 | Loss: 0.00003956
Iteration 251/1000 | Loss: 0.00003955
Iteration 252/1000 | Loss: 0.00003955
Iteration 253/1000 | Loss: 0.00003955
Iteration 254/1000 | Loss: 0.00003955
Iteration 255/1000 | Loss: 0.00003955
Iteration 256/1000 | Loss: 0.00003955
Iteration 257/1000 | Loss: 0.00003955
Iteration 258/1000 | Loss: 0.00003955
Iteration 259/1000 | Loss: 0.00003955
Iteration 260/1000 | Loss: 0.00003955
Iteration 261/1000 | Loss: 0.00003955
Iteration 262/1000 | Loss: 0.00003955
Iteration 263/1000 | Loss: 0.00003954
Iteration 264/1000 | Loss: 0.00003954
Iteration 265/1000 | Loss: 0.00004044
Iteration 266/1000 | Loss: 0.00003955
Iteration 267/1000 | Loss: 0.00003951
Iteration 268/1000 | Loss: 0.00003951
Iteration 269/1000 | Loss: 0.00003951
Iteration 270/1000 | Loss: 0.00003951
Iteration 271/1000 | Loss: 0.00003950
Iteration 272/1000 | Loss: 0.00003950
Iteration 273/1000 | Loss: 0.00003950
Iteration 274/1000 | Loss: 0.00003950
Iteration 275/1000 | Loss: 0.00003950
Iteration 276/1000 | Loss: 0.00003950
Iteration 277/1000 | Loss: 0.00003950
Iteration 278/1000 | Loss: 0.00003950
Iteration 279/1000 | Loss: 0.00003950
Iteration 280/1000 | Loss: 0.00003950
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 280. Stopping optimization.
Last 5 losses: [3.950375321437605e-05, 3.950375321437605e-05, 3.950375321437605e-05, 3.950375321437605e-05, 3.950375321437605e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.950375321437605e-05

Optimization complete. Final v2v error: 5.053008556365967 mm

Highest mean error: 22.513975143432617 mm for frame 136

Lowest mean error: 4.4223952293396 mm for frame 14

Saving results

Total time: 420.9828987121582
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00650899
Iteration 2/25 | Loss: 0.00162122
Iteration 3/25 | Loss: 0.00152377
Iteration 4/25 | Loss: 0.00151185
Iteration 5/25 | Loss: 0.00150921
Iteration 6/25 | Loss: 0.00150866
Iteration 7/25 | Loss: 0.00150866
Iteration 8/25 | Loss: 0.00150866
Iteration 9/25 | Loss: 0.00150866
Iteration 10/25 | Loss: 0.00150866
Iteration 11/25 | Loss: 0.00150866
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0015086558414623141, 0.0015086558414623141, 0.0015086558414623141, 0.0015086558414623141, 0.0015086558414623141]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015086558414623141

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.21565199
Iteration 2/25 | Loss: 0.00305868
Iteration 3/25 | Loss: 0.00305867
Iteration 4/25 | Loss: 0.00305867
Iteration 5/25 | Loss: 0.00305867
Iteration 6/25 | Loss: 0.00305867
Iteration 7/25 | Loss: 0.00305867
Iteration 8/25 | Loss: 0.00305867
Iteration 9/25 | Loss: 0.00305867
Iteration 10/25 | Loss: 0.00305867
Iteration 11/25 | Loss: 0.00305867
Iteration 12/25 | Loss: 0.00305867
Iteration 13/25 | Loss: 0.00305867
Iteration 14/25 | Loss: 0.00305867
Iteration 15/25 | Loss: 0.00305867
Iteration 16/25 | Loss: 0.00305867
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.003058666130527854, 0.003058666130527854, 0.003058666130527854, 0.003058666130527854, 0.003058666130527854]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003058666130527854

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00305867
Iteration 2/1000 | Loss: 0.00005087
Iteration 3/1000 | Loss: 0.00003339
Iteration 4/1000 | Loss: 0.00002933
Iteration 5/1000 | Loss: 0.00002648
Iteration 6/1000 | Loss: 0.00002501
Iteration 7/1000 | Loss: 0.00002457
Iteration 8/1000 | Loss: 0.00002423
Iteration 9/1000 | Loss: 0.00002394
Iteration 10/1000 | Loss: 0.00002357
Iteration 11/1000 | Loss: 0.00002331
Iteration 12/1000 | Loss: 0.00002312
Iteration 13/1000 | Loss: 0.00002309
Iteration 14/1000 | Loss: 0.00002306
Iteration 15/1000 | Loss: 0.00002306
Iteration 16/1000 | Loss: 0.00002305
Iteration 17/1000 | Loss: 0.00002305
Iteration 18/1000 | Loss: 0.00002299
Iteration 19/1000 | Loss: 0.00002299
Iteration 20/1000 | Loss: 0.00002299
Iteration 21/1000 | Loss: 0.00002297
Iteration 22/1000 | Loss: 0.00002297
Iteration 23/1000 | Loss: 0.00002297
Iteration 24/1000 | Loss: 0.00002297
Iteration 25/1000 | Loss: 0.00002296
Iteration 26/1000 | Loss: 0.00002296
Iteration 27/1000 | Loss: 0.00002296
Iteration 28/1000 | Loss: 0.00002296
Iteration 29/1000 | Loss: 0.00002295
Iteration 30/1000 | Loss: 0.00002294
Iteration 31/1000 | Loss: 0.00002293
Iteration 32/1000 | Loss: 0.00002293
Iteration 33/1000 | Loss: 0.00002291
Iteration 34/1000 | Loss: 0.00002291
Iteration 35/1000 | Loss: 0.00002291
Iteration 36/1000 | Loss: 0.00002291
Iteration 37/1000 | Loss: 0.00002291
Iteration 38/1000 | Loss: 0.00002290
Iteration 39/1000 | Loss: 0.00002290
Iteration 40/1000 | Loss: 0.00002289
Iteration 41/1000 | Loss: 0.00002289
Iteration 42/1000 | Loss: 0.00002289
Iteration 43/1000 | Loss: 0.00002288
Iteration 44/1000 | Loss: 0.00002287
Iteration 45/1000 | Loss: 0.00002287
Iteration 46/1000 | Loss: 0.00002286
Iteration 47/1000 | Loss: 0.00002286
Iteration 48/1000 | Loss: 0.00002286
Iteration 49/1000 | Loss: 0.00002285
Iteration 50/1000 | Loss: 0.00002285
Iteration 51/1000 | Loss: 0.00002284
Iteration 52/1000 | Loss: 0.00002284
Iteration 53/1000 | Loss: 0.00002284
Iteration 54/1000 | Loss: 0.00002284
Iteration 55/1000 | Loss: 0.00002284
Iteration 56/1000 | Loss: 0.00002283
Iteration 57/1000 | Loss: 0.00002283
Iteration 58/1000 | Loss: 0.00002283
Iteration 59/1000 | Loss: 0.00002282
Iteration 60/1000 | Loss: 0.00002282
Iteration 61/1000 | Loss: 0.00002282
Iteration 62/1000 | Loss: 0.00002282
Iteration 63/1000 | Loss: 0.00002281
Iteration 64/1000 | Loss: 0.00002281
Iteration 65/1000 | Loss: 0.00002281
Iteration 66/1000 | Loss: 0.00002281
Iteration 67/1000 | Loss: 0.00002280
Iteration 68/1000 | Loss: 0.00002280
Iteration 69/1000 | Loss: 0.00002280
Iteration 70/1000 | Loss: 0.00002280
Iteration 71/1000 | Loss: 0.00002280
Iteration 72/1000 | Loss: 0.00002279
Iteration 73/1000 | Loss: 0.00002279
Iteration 74/1000 | Loss: 0.00002279
Iteration 75/1000 | Loss: 0.00002279
Iteration 76/1000 | Loss: 0.00002278
Iteration 77/1000 | Loss: 0.00002278
Iteration 78/1000 | Loss: 0.00002278
Iteration 79/1000 | Loss: 0.00002278
Iteration 80/1000 | Loss: 0.00002278
Iteration 81/1000 | Loss: 0.00002278
Iteration 82/1000 | Loss: 0.00002278
Iteration 83/1000 | Loss: 0.00002278
Iteration 84/1000 | Loss: 0.00002278
Iteration 85/1000 | Loss: 0.00002278
Iteration 86/1000 | Loss: 0.00002278
Iteration 87/1000 | Loss: 0.00002278
Iteration 88/1000 | Loss: 0.00002278
Iteration 89/1000 | Loss: 0.00002278
Iteration 90/1000 | Loss: 0.00002278
Iteration 91/1000 | Loss: 0.00002278
Iteration 92/1000 | Loss: 0.00002278
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [2.2781352527090348e-05, 2.2781352527090348e-05, 2.2781352527090348e-05, 2.2781352527090348e-05, 2.2781352527090348e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2781352527090348e-05

Optimization complete. Final v2v error: 4.136465072631836 mm

Highest mean error: 4.440332412719727 mm for frame 65

Lowest mean error: 3.980689287185669 mm for frame 25

Saving results

Total time: 31.913337230682373
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00448655
Iteration 2/25 | Loss: 0.00159010
Iteration 3/25 | Loss: 0.00147940
Iteration 4/25 | Loss: 0.00146639
Iteration 5/25 | Loss: 0.00146325
Iteration 6/25 | Loss: 0.00146206
Iteration 7/25 | Loss: 0.00146182
Iteration 8/25 | Loss: 0.00146182
Iteration 9/25 | Loss: 0.00146182
Iteration 10/25 | Loss: 0.00146182
Iteration 11/25 | Loss: 0.00146182
Iteration 12/25 | Loss: 0.00146182
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0014618166023865342, 0.0014618166023865342, 0.0014618166023865342, 0.0014618166023865342, 0.0014618166023865342]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014618166023865342

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65013683
Iteration 2/25 | Loss: 0.00320297
Iteration 3/25 | Loss: 0.00320297
Iteration 4/25 | Loss: 0.00320297
Iteration 5/25 | Loss: 0.00320297
Iteration 6/25 | Loss: 0.00320297
Iteration 7/25 | Loss: 0.00320297
Iteration 8/25 | Loss: 0.00320297
Iteration 9/25 | Loss: 0.00320297
Iteration 10/25 | Loss: 0.00320297
Iteration 11/25 | Loss: 0.00320297
Iteration 12/25 | Loss: 0.00320297
Iteration 13/25 | Loss: 0.00320297
Iteration 14/25 | Loss: 0.00320297
Iteration 15/25 | Loss: 0.00320297
Iteration 16/25 | Loss: 0.00320297
Iteration 17/25 | Loss: 0.00320297
Iteration 18/25 | Loss: 0.00320297
Iteration 19/25 | Loss: 0.00320297
Iteration 20/25 | Loss: 0.00320297
Iteration 21/25 | Loss: 0.00320297
Iteration 22/25 | Loss: 0.00320297
Iteration 23/25 | Loss: 0.00320297
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.003202966880053282, 0.003202966880053282, 0.003202966880053282, 0.003202966880053282, 0.003202966880053282]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003202966880053282

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00320297
Iteration 2/1000 | Loss: 0.00005007
Iteration 3/1000 | Loss: 0.00003510
Iteration 4/1000 | Loss: 0.00003028
Iteration 5/1000 | Loss: 0.00002826
Iteration 6/1000 | Loss: 0.00002640
Iteration 7/1000 | Loss: 0.00002600
Iteration 8/1000 | Loss: 0.00002581
Iteration 9/1000 | Loss: 0.00002559
Iteration 10/1000 | Loss: 0.00002558
Iteration 11/1000 | Loss: 0.00002548
Iteration 12/1000 | Loss: 0.00002537
Iteration 13/1000 | Loss: 0.00002519
Iteration 14/1000 | Loss: 0.00002516
Iteration 15/1000 | Loss: 0.00002516
Iteration 16/1000 | Loss: 0.00002515
Iteration 17/1000 | Loss: 0.00002512
Iteration 18/1000 | Loss: 0.00002511
Iteration 19/1000 | Loss: 0.00002509
Iteration 20/1000 | Loss: 0.00002509
Iteration 21/1000 | Loss: 0.00002504
Iteration 22/1000 | Loss: 0.00002500
Iteration 23/1000 | Loss: 0.00002500
Iteration 24/1000 | Loss: 0.00002498
Iteration 25/1000 | Loss: 0.00002498
Iteration 26/1000 | Loss: 0.00002498
Iteration 27/1000 | Loss: 0.00002497
Iteration 28/1000 | Loss: 0.00002497
Iteration 29/1000 | Loss: 0.00002497
Iteration 30/1000 | Loss: 0.00002497
Iteration 31/1000 | Loss: 0.00002497
Iteration 32/1000 | Loss: 0.00002497
Iteration 33/1000 | Loss: 0.00002497
Iteration 34/1000 | Loss: 0.00002497
Iteration 35/1000 | Loss: 0.00002497
Iteration 36/1000 | Loss: 0.00002497
Iteration 37/1000 | Loss: 0.00002496
Iteration 38/1000 | Loss: 0.00002496
Iteration 39/1000 | Loss: 0.00002496
Iteration 40/1000 | Loss: 0.00002496
Iteration 41/1000 | Loss: 0.00002495
Iteration 42/1000 | Loss: 0.00002495
Iteration 43/1000 | Loss: 0.00002495
Iteration 44/1000 | Loss: 0.00002495
Iteration 45/1000 | Loss: 0.00002495
Iteration 46/1000 | Loss: 0.00002494
Iteration 47/1000 | Loss: 0.00002494
Iteration 48/1000 | Loss: 0.00002494
Iteration 49/1000 | Loss: 0.00002493
Iteration 50/1000 | Loss: 0.00002493
Iteration 51/1000 | Loss: 0.00002493
Iteration 52/1000 | Loss: 0.00002493
Iteration 53/1000 | Loss: 0.00002493
Iteration 54/1000 | Loss: 0.00002493
Iteration 55/1000 | Loss: 0.00002492
Iteration 56/1000 | Loss: 0.00002492
Iteration 57/1000 | Loss: 0.00002492
Iteration 58/1000 | Loss: 0.00002492
Iteration 59/1000 | Loss: 0.00002491
Iteration 60/1000 | Loss: 0.00002491
Iteration 61/1000 | Loss: 0.00002491
Iteration 62/1000 | Loss: 0.00002491
Iteration 63/1000 | Loss: 0.00002491
Iteration 64/1000 | Loss: 0.00002491
Iteration 65/1000 | Loss: 0.00002491
Iteration 66/1000 | Loss: 0.00002490
Iteration 67/1000 | Loss: 0.00002490
Iteration 68/1000 | Loss: 0.00002490
Iteration 69/1000 | Loss: 0.00002490
Iteration 70/1000 | Loss: 0.00002489
Iteration 71/1000 | Loss: 0.00002489
Iteration 72/1000 | Loss: 0.00002489
Iteration 73/1000 | Loss: 0.00002489
Iteration 74/1000 | Loss: 0.00002488
Iteration 75/1000 | Loss: 0.00002488
Iteration 76/1000 | Loss: 0.00002488
Iteration 77/1000 | Loss: 0.00002488
Iteration 78/1000 | Loss: 0.00002488
Iteration 79/1000 | Loss: 0.00002488
Iteration 80/1000 | Loss: 0.00002488
Iteration 81/1000 | Loss: 0.00002488
Iteration 82/1000 | Loss: 0.00002488
Iteration 83/1000 | Loss: 0.00002487
Iteration 84/1000 | Loss: 0.00002487
Iteration 85/1000 | Loss: 0.00002487
Iteration 86/1000 | Loss: 0.00002487
Iteration 87/1000 | Loss: 0.00002486
Iteration 88/1000 | Loss: 0.00002485
Iteration 89/1000 | Loss: 0.00002485
Iteration 90/1000 | Loss: 0.00002485
Iteration 91/1000 | Loss: 0.00002485
Iteration 92/1000 | Loss: 0.00002485
Iteration 93/1000 | Loss: 0.00002485
Iteration 94/1000 | Loss: 0.00002485
Iteration 95/1000 | Loss: 0.00002485
Iteration 96/1000 | Loss: 0.00002485
Iteration 97/1000 | Loss: 0.00002485
Iteration 98/1000 | Loss: 0.00002484
Iteration 99/1000 | Loss: 0.00002484
Iteration 100/1000 | Loss: 0.00002484
Iteration 101/1000 | Loss: 0.00002483
Iteration 102/1000 | Loss: 0.00002483
Iteration 103/1000 | Loss: 0.00002483
Iteration 104/1000 | Loss: 0.00002482
Iteration 105/1000 | Loss: 0.00002482
Iteration 106/1000 | Loss: 0.00002482
Iteration 107/1000 | Loss: 0.00002482
Iteration 108/1000 | Loss: 0.00002482
Iteration 109/1000 | Loss: 0.00002482
Iteration 110/1000 | Loss: 0.00002482
Iteration 111/1000 | Loss: 0.00002482
Iteration 112/1000 | Loss: 0.00002481
Iteration 113/1000 | Loss: 0.00002481
Iteration 114/1000 | Loss: 0.00002481
Iteration 115/1000 | Loss: 0.00002481
Iteration 116/1000 | Loss: 0.00002480
Iteration 117/1000 | Loss: 0.00002480
Iteration 118/1000 | Loss: 0.00002480
Iteration 119/1000 | Loss: 0.00002480
Iteration 120/1000 | Loss: 0.00002480
Iteration 121/1000 | Loss: 0.00002480
Iteration 122/1000 | Loss: 0.00002480
Iteration 123/1000 | Loss: 0.00002480
Iteration 124/1000 | Loss: 0.00002480
Iteration 125/1000 | Loss: 0.00002480
Iteration 126/1000 | Loss: 0.00002480
Iteration 127/1000 | Loss: 0.00002479
Iteration 128/1000 | Loss: 0.00002479
Iteration 129/1000 | Loss: 0.00002479
Iteration 130/1000 | Loss: 0.00002479
Iteration 131/1000 | Loss: 0.00002479
Iteration 132/1000 | Loss: 0.00002478
Iteration 133/1000 | Loss: 0.00002478
Iteration 134/1000 | Loss: 0.00002478
Iteration 135/1000 | Loss: 0.00002478
Iteration 136/1000 | Loss: 0.00002478
Iteration 137/1000 | Loss: 0.00002478
Iteration 138/1000 | Loss: 0.00002478
Iteration 139/1000 | Loss: 0.00002478
Iteration 140/1000 | Loss: 0.00002478
Iteration 141/1000 | Loss: 0.00002478
Iteration 142/1000 | Loss: 0.00002478
Iteration 143/1000 | Loss: 0.00002478
Iteration 144/1000 | Loss: 0.00002478
Iteration 145/1000 | Loss: 0.00002478
Iteration 146/1000 | Loss: 0.00002478
Iteration 147/1000 | Loss: 0.00002478
Iteration 148/1000 | Loss: 0.00002478
Iteration 149/1000 | Loss: 0.00002478
Iteration 150/1000 | Loss: 0.00002478
Iteration 151/1000 | Loss: 0.00002477
Iteration 152/1000 | Loss: 0.00002477
Iteration 153/1000 | Loss: 0.00002477
Iteration 154/1000 | Loss: 0.00002477
Iteration 155/1000 | Loss: 0.00002477
Iteration 156/1000 | Loss: 0.00002477
Iteration 157/1000 | Loss: 0.00002477
Iteration 158/1000 | Loss: 0.00002477
Iteration 159/1000 | Loss: 0.00002477
Iteration 160/1000 | Loss: 0.00002477
Iteration 161/1000 | Loss: 0.00002477
Iteration 162/1000 | Loss: 0.00002477
Iteration 163/1000 | Loss: 0.00002477
Iteration 164/1000 | Loss: 0.00002477
Iteration 165/1000 | Loss: 0.00002477
Iteration 166/1000 | Loss: 0.00002477
Iteration 167/1000 | Loss: 0.00002477
Iteration 168/1000 | Loss: 0.00002477
Iteration 169/1000 | Loss: 0.00002477
Iteration 170/1000 | Loss: 0.00002476
Iteration 171/1000 | Loss: 0.00002476
Iteration 172/1000 | Loss: 0.00002476
Iteration 173/1000 | Loss: 0.00002476
Iteration 174/1000 | Loss: 0.00002476
Iteration 175/1000 | Loss: 0.00002476
Iteration 176/1000 | Loss: 0.00002476
Iteration 177/1000 | Loss: 0.00002476
Iteration 178/1000 | Loss: 0.00002476
Iteration 179/1000 | Loss: 0.00002476
Iteration 180/1000 | Loss: 0.00002476
Iteration 181/1000 | Loss: 0.00002476
Iteration 182/1000 | Loss: 0.00002476
Iteration 183/1000 | Loss: 0.00002476
Iteration 184/1000 | Loss: 0.00002476
Iteration 185/1000 | Loss: 0.00002476
Iteration 186/1000 | Loss: 0.00002476
Iteration 187/1000 | Loss: 0.00002476
Iteration 188/1000 | Loss: 0.00002476
Iteration 189/1000 | Loss: 0.00002475
Iteration 190/1000 | Loss: 0.00002475
Iteration 191/1000 | Loss: 0.00002475
Iteration 192/1000 | Loss: 0.00002475
Iteration 193/1000 | Loss: 0.00002475
Iteration 194/1000 | Loss: 0.00002475
Iteration 195/1000 | Loss: 0.00002475
Iteration 196/1000 | Loss: 0.00002475
Iteration 197/1000 | Loss: 0.00002475
Iteration 198/1000 | Loss: 0.00002475
Iteration 199/1000 | Loss: 0.00002474
Iteration 200/1000 | Loss: 0.00002474
Iteration 201/1000 | Loss: 0.00002474
Iteration 202/1000 | Loss: 0.00002474
Iteration 203/1000 | Loss: 0.00002474
Iteration 204/1000 | Loss: 0.00002474
Iteration 205/1000 | Loss: 0.00002474
Iteration 206/1000 | Loss: 0.00002474
Iteration 207/1000 | Loss: 0.00002474
Iteration 208/1000 | Loss: 0.00002474
Iteration 209/1000 | Loss: 0.00002474
Iteration 210/1000 | Loss: 0.00002474
Iteration 211/1000 | Loss: 0.00002474
Iteration 212/1000 | Loss: 0.00002474
Iteration 213/1000 | Loss: 0.00002473
Iteration 214/1000 | Loss: 0.00002473
Iteration 215/1000 | Loss: 0.00002473
Iteration 216/1000 | Loss: 0.00002473
Iteration 217/1000 | Loss: 0.00002473
Iteration 218/1000 | Loss: 0.00002473
Iteration 219/1000 | Loss: 0.00002473
Iteration 220/1000 | Loss: 0.00002473
Iteration 221/1000 | Loss: 0.00002473
Iteration 222/1000 | Loss: 0.00002473
Iteration 223/1000 | Loss: 0.00002473
Iteration 224/1000 | Loss: 0.00002473
Iteration 225/1000 | Loss: 0.00002473
Iteration 226/1000 | Loss: 0.00002473
Iteration 227/1000 | Loss: 0.00002473
Iteration 228/1000 | Loss: 0.00002473
Iteration 229/1000 | Loss: 0.00002473
Iteration 230/1000 | Loss: 0.00002473
Iteration 231/1000 | Loss: 0.00002473
Iteration 232/1000 | Loss: 0.00002473
Iteration 233/1000 | Loss: 0.00002473
Iteration 234/1000 | Loss: 0.00002473
Iteration 235/1000 | Loss: 0.00002473
Iteration 236/1000 | Loss: 0.00002473
Iteration 237/1000 | Loss: 0.00002473
Iteration 238/1000 | Loss: 0.00002473
Iteration 239/1000 | Loss: 0.00002473
Iteration 240/1000 | Loss: 0.00002473
Iteration 241/1000 | Loss: 0.00002473
Iteration 242/1000 | Loss: 0.00002473
Iteration 243/1000 | Loss: 0.00002473
Iteration 244/1000 | Loss: 0.00002473
Iteration 245/1000 | Loss: 0.00002473
Iteration 246/1000 | Loss: 0.00002473
Iteration 247/1000 | Loss: 0.00002473
Iteration 248/1000 | Loss: 0.00002473
Iteration 249/1000 | Loss: 0.00002473
Iteration 250/1000 | Loss: 0.00002473
Iteration 251/1000 | Loss: 0.00002473
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 251. Stopping optimization.
Last 5 losses: [2.473078347975388e-05, 2.473078347975388e-05, 2.473078347975388e-05, 2.473078347975388e-05, 2.473078347975388e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.473078347975388e-05

Optimization complete. Final v2v error: 4.4039692878723145 mm

Highest mean error: 4.69951868057251 mm for frame 64

Lowest mean error: 4.189983367919922 mm for frame 55

Saving results

Total time: 40.073238134384155
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00731144
Iteration 2/25 | Loss: 0.00178573
Iteration 3/25 | Loss: 0.00155130
Iteration 4/25 | Loss: 0.00150736
Iteration 5/25 | Loss: 0.00149665
Iteration 6/25 | Loss: 0.00149636
Iteration 7/25 | Loss: 0.00149039
Iteration 8/25 | Loss: 0.00148732
Iteration 9/25 | Loss: 0.00148550
Iteration 10/25 | Loss: 0.00148509
Iteration 11/25 | Loss: 0.00148511
Iteration 12/25 | Loss: 0.00148467
Iteration 13/25 | Loss: 0.00148410
Iteration 14/25 | Loss: 0.00148452
Iteration 15/25 | Loss: 0.00148430
Iteration 16/25 | Loss: 0.00148458
Iteration 17/25 | Loss: 0.00148442
Iteration 18/25 | Loss: 0.00148450
Iteration 19/25 | Loss: 0.00148440
Iteration 20/25 | Loss: 0.00148446
Iteration 21/25 | Loss: 0.00148445
Iteration 22/25 | Loss: 0.00148445
Iteration 23/25 | Loss: 0.00148422
Iteration 24/25 | Loss: 0.00148400
Iteration 25/25 | Loss: 0.00148419

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.96155643
Iteration 2/25 | Loss: 0.00326659
Iteration 3/25 | Loss: 0.00326659
Iteration 4/25 | Loss: 0.00326659
Iteration 5/25 | Loss: 0.00326659
Iteration 6/25 | Loss: 0.00326659
Iteration 7/25 | Loss: 0.00326659
Iteration 8/25 | Loss: 0.00326659
Iteration 9/25 | Loss: 0.00326659
Iteration 10/25 | Loss: 0.00326659
Iteration 11/25 | Loss: 0.00326659
Iteration 12/25 | Loss: 0.00326659
Iteration 13/25 | Loss: 0.00326659
Iteration 14/25 | Loss: 0.00326659
Iteration 15/25 | Loss: 0.00326659
Iteration 16/25 | Loss: 0.00326659
Iteration 17/25 | Loss: 0.00326659
Iteration 18/25 | Loss: 0.00326659
Iteration 19/25 | Loss: 0.00326659
Iteration 20/25 | Loss: 0.00326659
Iteration 21/25 | Loss: 0.00326659
Iteration 22/25 | Loss: 0.00326659
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.003266590880230069, 0.003266590880230069, 0.003266590880230069, 0.003266590880230069, 0.003266590880230069]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003266590880230069

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00326659
Iteration 2/1000 | Loss: 0.00006776
Iteration 3/1000 | Loss: 0.00004781
Iteration 4/1000 | Loss: 0.00003959
Iteration 5/1000 | Loss: 0.00003633
Iteration 6/1000 | Loss: 0.00003520
Iteration 7/1000 | Loss: 0.00003338
Iteration 8/1000 | Loss: 0.00003281
Iteration 9/1000 | Loss: 0.00003223
Iteration 10/1000 | Loss: 0.00003188
Iteration 11/1000 | Loss: 0.00003153
Iteration 12/1000 | Loss: 0.00003181
Iteration 13/1000 | Loss: 0.00003141
Iteration 14/1000 | Loss: 0.00003150
Iteration 15/1000 | Loss: 0.00003130
Iteration 16/1000 | Loss: 0.00003111
Iteration 17/1000 | Loss: 0.00003095
Iteration 18/1000 | Loss: 0.00003091
Iteration 19/1000 | Loss: 0.00003091
Iteration 20/1000 | Loss: 0.00003090
Iteration 21/1000 | Loss: 0.00003090
Iteration 22/1000 | Loss: 0.00003090
Iteration 23/1000 | Loss: 0.00003090
Iteration 24/1000 | Loss: 0.00003090
Iteration 25/1000 | Loss: 0.00003090
Iteration 26/1000 | Loss: 0.00003090
Iteration 27/1000 | Loss: 0.00003090
Iteration 28/1000 | Loss: 0.00003089
Iteration 29/1000 | Loss: 0.00003089
Iteration 30/1000 | Loss: 0.00003115
Iteration 31/1000 | Loss: 0.00003094
Iteration 32/1000 | Loss: 0.00003094
Iteration 33/1000 | Loss: 0.00003092
Iteration 34/1000 | Loss: 0.00003091
Iteration 35/1000 | Loss: 0.00003090
Iteration 36/1000 | Loss: 0.00003090
Iteration 37/1000 | Loss: 0.00003086
Iteration 38/1000 | Loss: 0.00003072
Iteration 39/1000 | Loss: 0.00003071
Iteration 40/1000 | Loss: 0.00003069
Iteration 41/1000 | Loss: 0.00003068
Iteration 42/1000 | Loss: 0.00003068
Iteration 43/1000 | Loss: 0.00003068
Iteration 44/1000 | Loss: 0.00003067
Iteration 45/1000 | Loss: 0.00003067
Iteration 46/1000 | Loss: 0.00003067
Iteration 47/1000 | Loss: 0.00003066
Iteration 48/1000 | Loss: 0.00003066
Iteration 49/1000 | Loss: 0.00003066
Iteration 50/1000 | Loss: 0.00003066
Iteration 51/1000 | Loss: 0.00003066
Iteration 52/1000 | Loss: 0.00003066
Iteration 53/1000 | Loss: 0.00003066
Iteration 54/1000 | Loss: 0.00003066
Iteration 55/1000 | Loss: 0.00003066
Iteration 56/1000 | Loss: 0.00003066
Iteration 57/1000 | Loss: 0.00003065
Iteration 58/1000 | Loss: 0.00003065
Iteration 59/1000 | Loss: 0.00003065
Iteration 60/1000 | Loss: 0.00003065
Iteration 61/1000 | Loss: 0.00003065
Iteration 62/1000 | Loss: 0.00003065
Iteration 63/1000 | Loss: 0.00003065
Iteration 64/1000 | Loss: 0.00003064
Iteration 65/1000 | Loss: 0.00003064
Iteration 66/1000 | Loss: 0.00003064
Iteration 67/1000 | Loss: 0.00003064
Iteration 68/1000 | Loss: 0.00003064
Iteration 69/1000 | Loss: 0.00003064
Iteration 70/1000 | Loss: 0.00003064
Iteration 71/1000 | Loss: 0.00003064
Iteration 72/1000 | Loss: 0.00003064
Iteration 73/1000 | Loss: 0.00003064
Iteration 74/1000 | Loss: 0.00003064
Iteration 75/1000 | Loss: 0.00003064
Iteration 76/1000 | Loss: 0.00003064
Iteration 77/1000 | Loss: 0.00003064
Iteration 78/1000 | Loss: 0.00003064
Iteration 79/1000 | Loss: 0.00003063
Iteration 80/1000 | Loss: 0.00003063
Iteration 81/1000 | Loss: 0.00003063
Iteration 82/1000 | Loss: 0.00003063
Iteration 83/1000 | Loss: 0.00003063
Iteration 84/1000 | Loss: 0.00003063
Iteration 85/1000 | Loss: 0.00003063
Iteration 86/1000 | Loss: 0.00003063
Iteration 87/1000 | Loss: 0.00003063
Iteration 88/1000 | Loss: 0.00003063
Iteration 89/1000 | Loss: 0.00003063
Iteration 90/1000 | Loss: 0.00003063
Iteration 91/1000 | Loss: 0.00003063
Iteration 92/1000 | Loss: 0.00003063
Iteration 93/1000 | Loss: 0.00003063
Iteration 94/1000 | Loss: 0.00003063
Iteration 95/1000 | Loss: 0.00003063
Iteration 96/1000 | Loss: 0.00003063
Iteration 97/1000 | Loss: 0.00003063
Iteration 98/1000 | Loss: 0.00003063
Iteration 99/1000 | Loss: 0.00003063
Iteration 100/1000 | Loss: 0.00003063
Iteration 101/1000 | Loss: 0.00003063
Iteration 102/1000 | Loss: 0.00003063
Iteration 103/1000 | Loss: 0.00003063
Iteration 104/1000 | Loss: 0.00003063
Iteration 105/1000 | Loss: 0.00003063
Iteration 106/1000 | Loss: 0.00003063
Iteration 107/1000 | Loss: 0.00003063
Iteration 108/1000 | Loss: 0.00003063
Iteration 109/1000 | Loss: 0.00003063
Iteration 110/1000 | Loss: 0.00003063
Iteration 111/1000 | Loss: 0.00003063
Iteration 112/1000 | Loss: 0.00003063
Iteration 113/1000 | Loss: 0.00003063
Iteration 114/1000 | Loss: 0.00003063
Iteration 115/1000 | Loss: 0.00003063
Iteration 116/1000 | Loss: 0.00003063
Iteration 117/1000 | Loss: 0.00003063
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [3.062667019548826e-05, 3.062667019548826e-05, 3.062667019548826e-05, 3.062667019548826e-05, 3.062667019548826e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.062667019548826e-05

Optimization complete. Final v2v error: 4.813582420349121 mm

Highest mean error: 11.127099990844727 mm for frame 151

Lowest mean error: 4.242546081542969 mm for frame 49

Saving results

Total time: 83.25804495811462
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_39_nl_6338/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_39_nl_6338/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00915736
Iteration 2/25 | Loss: 0.00180139
Iteration 3/25 | Loss: 0.00160822
Iteration 4/25 | Loss: 0.00157741
Iteration 5/25 | Loss: 0.00156962
Iteration 6/25 | Loss: 0.00156702
Iteration 7/25 | Loss: 0.00156653
Iteration 8/25 | Loss: 0.00156653
Iteration 9/25 | Loss: 0.00156653
Iteration 10/25 | Loss: 0.00156653
Iteration 11/25 | Loss: 0.00156653
Iteration 12/25 | Loss: 0.00156653
Iteration 13/25 | Loss: 0.00156653
Iteration 14/25 | Loss: 0.00156653
Iteration 15/25 | Loss: 0.00156653
Iteration 16/25 | Loss: 0.00156653
Iteration 17/25 | Loss: 0.00156653
Iteration 18/25 | Loss: 0.00156653
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0015665327664464712, 0.0015665327664464712, 0.0015665327664464712, 0.0015665327664464712, 0.0015665327664464712]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015665327664464712

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.41487002
Iteration 2/25 | Loss: 0.00431832
Iteration 3/25 | Loss: 0.00431826
Iteration 4/25 | Loss: 0.00431825
Iteration 5/25 | Loss: 0.00431825
Iteration 6/25 | Loss: 0.00431825
Iteration 7/25 | Loss: 0.00431825
Iteration 8/25 | Loss: 0.00431825
Iteration 9/25 | Loss: 0.00431825
Iteration 10/25 | Loss: 0.00431825
Iteration 11/25 | Loss: 0.00431825
Iteration 12/25 | Loss: 0.00431825
Iteration 13/25 | Loss: 0.00431825
Iteration 14/25 | Loss: 0.00431825
Iteration 15/25 | Loss: 0.00431825
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.004318252671509981, 0.004318252671509981, 0.004318252671509981, 0.004318252671509981, 0.004318252671509981]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004318252671509981

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00431825
Iteration 2/1000 | Loss: 0.00008638
Iteration 3/1000 | Loss: 0.00005013
Iteration 4/1000 | Loss: 0.00004197
Iteration 5/1000 | Loss: 0.00003755
Iteration 6/1000 | Loss: 0.00003464
Iteration 7/1000 | Loss: 0.00003284
Iteration 8/1000 | Loss: 0.00003193
Iteration 9/1000 | Loss: 0.00003111
Iteration 10/1000 | Loss: 0.00003067
Iteration 11/1000 | Loss: 0.00003024
Iteration 12/1000 | Loss: 0.00002985
Iteration 13/1000 | Loss: 0.00002962
Iteration 14/1000 | Loss: 0.00002955
Iteration 15/1000 | Loss: 0.00002943
Iteration 16/1000 | Loss: 0.00002925
Iteration 17/1000 | Loss: 0.00002923
Iteration 18/1000 | Loss: 0.00002923
Iteration 19/1000 | Loss: 0.00002921
Iteration 20/1000 | Loss: 0.00002921
Iteration 21/1000 | Loss: 0.00002920
Iteration 22/1000 | Loss: 0.00002917
Iteration 23/1000 | Loss: 0.00002913
Iteration 24/1000 | Loss: 0.00002912
Iteration 25/1000 | Loss: 0.00002911
Iteration 26/1000 | Loss: 0.00002909
Iteration 27/1000 | Loss: 0.00002908
Iteration 28/1000 | Loss: 0.00002907
Iteration 29/1000 | Loss: 0.00002905
Iteration 30/1000 | Loss: 0.00002904
Iteration 31/1000 | Loss: 0.00002903
Iteration 32/1000 | Loss: 0.00002900
Iteration 33/1000 | Loss: 0.00002900
Iteration 34/1000 | Loss: 0.00002899
Iteration 35/1000 | Loss: 0.00002898
Iteration 36/1000 | Loss: 0.00002896
Iteration 37/1000 | Loss: 0.00002896
Iteration 38/1000 | Loss: 0.00002896
Iteration 39/1000 | Loss: 0.00002896
Iteration 40/1000 | Loss: 0.00002896
Iteration 41/1000 | Loss: 0.00002896
Iteration 42/1000 | Loss: 0.00002895
Iteration 43/1000 | Loss: 0.00002895
Iteration 44/1000 | Loss: 0.00002895
Iteration 45/1000 | Loss: 0.00002893
Iteration 46/1000 | Loss: 0.00002893
Iteration 47/1000 | Loss: 0.00002893
Iteration 48/1000 | Loss: 0.00002892
Iteration 49/1000 | Loss: 0.00002892
Iteration 50/1000 | Loss: 0.00002892
Iteration 51/1000 | Loss: 0.00002892
Iteration 52/1000 | Loss: 0.00002891
Iteration 53/1000 | Loss: 0.00002891
Iteration 54/1000 | Loss: 0.00002891
Iteration 55/1000 | Loss: 0.00002890
Iteration 56/1000 | Loss: 0.00002890
Iteration 57/1000 | Loss: 0.00002890
Iteration 58/1000 | Loss: 0.00002890
Iteration 59/1000 | Loss: 0.00002889
Iteration 60/1000 | Loss: 0.00002889
Iteration 61/1000 | Loss: 0.00002889
Iteration 62/1000 | Loss: 0.00002888
Iteration 63/1000 | Loss: 0.00002888
Iteration 64/1000 | Loss: 0.00002888
Iteration 65/1000 | Loss: 0.00002888
Iteration 66/1000 | Loss: 0.00002888
Iteration 67/1000 | Loss: 0.00002888
Iteration 68/1000 | Loss: 0.00002887
Iteration 69/1000 | Loss: 0.00002887
Iteration 70/1000 | Loss: 0.00002887
Iteration 71/1000 | Loss: 0.00002887
Iteration 72/1000 | Loss: 0.00002887
Iteration 73/1000 | Loss: 0.00002887
Iteration 74/1000 | Loss: 0.00002886
Iteration 75/1000 | Loss: 0.00002886
Iteration 76/1000 | Loss: 0.00002886
Iteration 77/1000 | Loss: 0.00002886
Iteration 78/1000 | Loss: 0.00002886
Iteration 79/1000 | Loss: 0.00002886
Iteration 80/1000 | Loss: 0.00002886
Iteration 81/1000 | Loss: 0.00002886
Iteration 82/1000 | Loss: 0.00002886
Iteration 83/1000 | Loss: 0.00002886
Iteration 84/1000 | Loss: 0.00002886
Iteration 85/1000 | Loss: 0.00002886
Iteration 86/1000 | Loss: 0.00002885
Iteration 87/1000 | Loss: 0.00002885
Iteration 88/1000 | Loss: 0.00002885
Iteration 89/1000 | Loss: 0.00002885
Iteration 90/1000 | Loss: 0.00002885
Iteration 91/1000 | Loss: 0.00002885
Iteration 92/1000 | Loss: 0.00002885
Iteration 93/1000 | Loss: 0.00002885
Iteration 94/1000 | Loss: 0.00002884
Iteration 95/1000 | Loss: 0.00002884
Iteration 96/1000 | Loss: 0.00002884
Iteration 97/1000 | Loss: 0.00002884
Iteration 98/1000 | Loss: 0.00002884
Iteration 99/1000 | Loss: 0.00002884
Iteration 100/1000 | Loss: 0.00002884
Iteration 101/1000 | Loss: 0.00002884
Iteration 102/1000 | Loss: 0.00002884
Iteration 103/1000 | Loss: 0.00002884
Iteration 104/1000 | Loss: 0.00002884
Iteration 105/1000 | Loss: 0.00002884
Iteration 106/1000 | Loss: 0.00002884
Iteration 107/1000 | Loss: 0.00002884
Iteration 108/1000 | Loss: 0.00002884
Iteration 109/1000 | Loss: 0.00002884
Iteration 110/1000 | Loss: 0.00002884
Iteration 111/1000 | Loss: 0.00002884
Iteration 112/1000 | Loss: 0.00002884
Iteration 113/1000 | Loss: 0.00002884
Iteration 114/1000 | Loss: 0.00002884
Iteration 115/1000 | Loss: 0.00002884
Iteration 116/1000 | Loss: 0.00002884
Iteration 117/1000 | Loss: 0.00002884
Iteration 118/1000 | Loss: 0.00002884
Iteration 119/1000 | Loss: 0.00002884
Iteration 120/1000 | Loss: 0.00002884
Iteration 121/1000 | Loss: 0.00002884
Iteration 122/1000 | Loss: 0.00002884
Iteration 123/1000 | Loss: 0.00002884
Iteration 124/1000 | Loss: 0.00002884
Iteration 125/1000 | Loss: 0.00002884
Iteration 126/1000 | Loss: 0.00002884
Iteration 127/1000 | Loss: 0.00002884
Iteration 128/1000 | Loss: 0.00002884
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [2.8839825972681865e-05, 2.8839825972681865e-05, 2.8839825972681865e-05, 2.8839825972681865e-05, 2.8839825972681865e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8839825972681865e-05

Optimization complete. Final v2v error: 4.766448497772217 mm

Highest mean error: 5.257861614227295 mm for frame 126

Lowest mean error: 4.341677665710449 mm for frame 35

Saving results

Total time: 44.91483283042908
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00547256
Iteration 2/25 | Loss: 0.00152570
Iteration 3/25 | Loss: 0.00130721
Iteration 4/25 | Loss: 0.00128523
Iteration 5/25 | Loss: 0.00128259
Iteration 6/25 | Loss: 0.00128234
Iteration 7/25 | Loss: 0.00128234
Iteration 8/25 | Loss: 0.00128234
Iteration 9/25 | Loss: 0.00128234
Iteration 10/25 | Loss: 0.00128234
Iteration 11/25 | Loss: 0.00128234
Iteration 12/25 | Loss: 0.00128234
Iteration 13/25 | Loss: 0.00128234
Iteration 14/25 | Loss: 0.00128234
Iteration 15/25 | Loss: 0.00128234
Iteration 16/25 | Loss: 0.00128234
Iteration 17/25 | Loss: 0.00128234
Iteration 18/25 | Loss: 0.00128234
Iteration 19/25 | Loss: 0.00128234
Iteration 20/25 | Loss: 0.00128234
Iteration 21/25 | Loss: 0.00128234
Iteration 22/25 | Loss: 0.00128234
Iteration 23/25 | Loss: 0.00128234
Iteration 24/25 | Loss: 0.00128234
Iteration 25/25 | Loss: 0.00128234

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.10940146
Iteration 2/25 | Loss: 0.00332375
Iteration 3/25 | Loss: 0.00332375
Iteration 4/25 | Loss: 0.00332375
Iteration 5/25 | Loss: 0.00332375
Iteration 6/25 | Loss: 0.00332375
Iteration 7/25 | Loss: 0.00332375
Iteration 8/25 | Loss: 0.00332374
Iteration 9/25 | Loss: 0.00332374
Iteration 10/25 | Loss: 0.00332374
Iteration 11/25 | Loss: 0.00332374
Iteration 12/25 | Loss: 0.00332374
Iteration 13/25 | Loss: 0.00332374
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.003323744749650359, 0.003323744749650359, 0.003323744749650359, 0.003323744749650359, 0.003323744749650359]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003323744749650359

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00332374
Iteration 2/1000 | Loss: 0.00004007
Iteration 3/1000 | Loss: 0.00002612
Iteration 4/1000 | Loss: 0.00002331
Iteration 5/1000 | Loss: 0.00002174
Iteration 6/1000 | Loss: 0.00002069
Iteration 7/1000 | Loss: 0.00001988
Iteration 8/1000 | Loss: 0.00001923
Iteration 9/1000 | Loss: 0.00001882
Iteration 10/1000 | Loss: 0.00001852
Iteration 11/1000 | Loss: 0.00001830
Iteration 12/1000 | Loss: 0.00001812
Iteration 13/1000 | Loss: 0.00001792
Iteration 14/1000 | Loss: 0.00001791
Iteration 15/1000 | Loss: 0.00001769
Iteration 16/1000 | Loss: 0.00001764
Iteration 17/1000 | Loss: 0.00001762
Iteration 18/1000 | Loss: 0.00001761
Iteration 19/1000 | Loss: 0.00001761
Iteration 20/1000 | Loss: 0.00001760
Iteration 21/1000 | Loss: 0.00001759
Iteration 22/1000 | Loss: 0.00001755
Iteration 23/1000 | Loss: 0.00001755
Iteration 24/1000 | Loss: 0.00001755
Iteration 25/1000 | Loss: 0.00001754
Iteration 26/1000 | Loss: 0.00001754
Iteration 27/1000 | Loss: 0.00001754
Iteration 28/1000 | Loss: 0.00001754
Iteration 29/1000 | Loss: 0.00001754
Iteration 30/1000 | Loss: 0.00001752
Iteration 31/1000 | Loss: 0.00001752
Iteration 32/1000 | Loss: 0.00001752
Iteration 33/1000 | Loss: 0.00001752
Iteration 34/1000 | Loss: 0.00001751
Iteration 35/1000 | Loss: 0.00001751
Iteration 36/1000 | Loss: 0.00001751
Iteration 37/1000 | Loss: 0.00001751
Iteration 38/1000 | Loss: 0.00001751
Iteration 39/1000 | Loss: 0.00001751
Iteration 40/1000 | Loss: 0.00001751
Iteration 41/1000 | Loss: 0.00001751
Iteration 42/1000 | Loss: 0.00001751
Iteration 43/1000 | Loss: 0.00001751
Iteration 44/1000 | Loss: 0.00001751
Iteration 45/1000 | Loss: 0.00001749
Iteration 46/1000 | Loss: 0.00001748
Iteration 47/1000 | Loss: 0.00001747
Iteration 48/1000 | Loss: 0.00001747
Iteration 49/1000 | Loss: 0.00001747
Iteration 50/1000 | Loss: 0.00001746
Iteration 51/1000 | Loss: 0.00001746
Iteration 52/1000 | Loss: 0.00001746
Iteration 53/1000 | Loss: 0.00001746
Iteration 54/1000 | Loss: 0.00001746
Iteration 55/1000 | Loss: 0.00001746
Iteration 56/1000 | Loss: 0.00001745
Iteration 57/1000 | Loss: 0.00001745
Iteration 58/1000 | Loss: 0.00001745
Iteration 59/1000 | Loss: 0.00001745
Iteration 60/1000 | Loss: 0.00001744
Iteration 61/1000 | Loss: 0.00001744
Iteration 62/1000 | Loss: 0.00001744
Iteration 63/1000 | Loss: 0.00001744
Iteration 64/1000 | Loss: 0.00001744
Iteration 65/1000 | Loss: 0.00001744
Iteration 66/1000 | Loss: 0.00001744
Iteration 67/1000 | Loss: 0.00001744
Iteration 68/1000 | Loss: 0.00001744
Iteration 69/1000 | Loss: 0.00001744
Iteration 70/1000 | Loss: 0.00001743
Iteration 71/1000 | Loss: 0.00001743
Iteration 72/1000 | Loss: 0.00001743
Iteration 73/1000 | Loss: 0.00001742
Iteration 74/1000 | Loss: 0.00001741
Iteration 75/1000 | Loss: 0.00001741
Iteration 76/1000 | Loss: 0.00001741
Iteration 77/1000 | Loss: 0.00001740
Iteration 78/1000 | Loss: 0.00001740
Iteration 79/1000 | Loss: 0.00001740
Iteration 80/1000 | Loss: 0.00001740
Iteration 81/1000 | Loss: 0.00001740
Iteration 82/1000 | Loss: 0.00001740
Iteration 83/1000 | Loss: 0.00001739
Iteration 84/1000 | Loss: 0.00001739
Iteration 85/1000 | Loss: 0.00001739
Iteration 86/1000 | Loss: 0.00001739
Iteration 87/1000 | Loss: 0.00001739
Iteration 88/1000 | Loss: 0.00001739
Iteration 89/1000 | Loss: 0.00001739
Iteration 90/1000 | Loss: 0.00001739
Iteration 91/1000 | Loss: 0.00001739
Iteration 92/1000 | Loss: 0.00001739
Iteration 93/1000 | Loss: 0.00001739
Iteration 94/1000 | Loss: 0.00001739
Iteration 95/1000 | Loss: 0.00001739
Iteration 96/1000 | Loss: 0.00001737
Iteration 97/1000 | Loss: 0.00001737
Iteration 98/1000 | Loss: 0.00001737
Iteration 99/1000 | Loss: 0.00001737
Iteration 100/1000 | Loss: 0.00001737
Iteration 101/1000 | Loss: 0.00001737
Iteration 102/1000 | Loss: 0.00001737
Iteration 103/1000 | Loss: 0.00001737
Iteration 104/1000 | Loss: 0.00001737
Iteration 105/1000 | Loss: 0.00001737
Iteration 106/1000 | Loss: 0.00001737
Iteration 107/1000 | Loss: 0.00001737
Iteration 108/1000 | Loss: 0.00001737
Iteration 109/1000 | Loss: 0.00001737
Iteration 110/1000 | Loss: 0.00001737
Iteration 111/1000 | Loss: 0.00001737
Iteration 112/1000 | Loss: 0.00001737
Iteration 113/1000 | Loss: 0.00001737
Iteration 114/1000 | Loss: 0.00001737
Iteration 115/1000 | Loss: 0.00001737
Iteration 116/1000 | Loss: 0.00001737
Iteration 117/1000 | Loss: 0.00001737
Iteration 118/1000 | Loss: 0.00001737
Iteration 119/1000 | Loss: 0.00001737
Iteration 120/1000 | Loss: 0.00001737
Iteration 121/1000 | Loss: 0.00001737
Iteration 122/1000 | Loss: 0.00001737
Iteration 123/1000 | Loss: 0.00001737
Iteration 124/1000 | Loss: 0.00001737
Iteration 125/1000 | Loss: 0.00001737
Iteration 126/1000 | Loss: 0.00001737
Iteration 127/1000 | Loss: 0.00001737
Iteration 128/1000 | Loss: 0.00001737
Iteration 129/1000 | Loss: 0.00001737
Iteration 130/1000 | Loss: 0.00001737
Iteration 131/1000 | Loss: 0.00001737
Iteration 132/1000 | Loss: 0.00001737
Iteration 133/1000 | Loss: 0.00001737
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [1.736534250085242e-05, 1.736534250085242e-05, 1.736534250085242e-05, 1.736534250085242e-05, 1.736534250085242e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.736534250085242e-05

Optimization complete. Final v2v error: 3.5164430141448975 mm

Highest mean error: 3.731652021408081 mm for frame 64

Lowest mean error: 3.1391165256500244 mm for frame 16

Saving results

Total time: 33.107887744903564
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00594955
Iteration 2/25 | Loss: 0.00173563
Iteration 3/25 | Loss: 0.00129992
Iteration 4/25 | Loss: 0.00127625
Iteration 5/25 | Loss: 0.00127232
Iteration 6/25 | Loss: 0.00127079
Iteration 7/25 | Loss: 0.00127059
Iteration 8/25 | Loss: 0.00127059
Iteration 9/25 | Loss: 0.00127059
Iteration 10/25 | Loss: 0.00127059
Iteration 11/25 | Loss: 0.00127059
Iteration 12/25 | Loss: 0.00127059
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.00127059081569314, 0.00127059081569314, 0.00127059081569314, 0.00127059081569314, 0.00127059081569314]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00127059081569314

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.96326399
Iteration 2/25 | Loss: 0.00247857
Iteration 3/25 | Loss: 0.00247857
Iteration 4/25 | Loss: 0.00247857
Iteration 5/25 | Loss: 0.00247857
Iteration 6/25 | Loss: 0.00247857
Iteration 7/25 | Loss: 0.00247857
Iteration 8/25 | Loss: 0.00247857
Iteration 9/25 | Loss: 0.00247857
Iteration 10/25 | Loss: 0.00247857
Iteration 11/25 | Loss: 0.00247857
Iteration 12/25 | Loss: 0.00247857
Iteration 13/25 | Loss: 0.00247857
Iteration 14/25 | Loss: 0.00247857
Iteration 15/25 | Loss: 0.00247857
Iteration 16/25 | Loss: 0.00247857
Iteration 17/25 | Loss: 0.00247857
Iteration 18/25 | Loss: 0.00247857
Iteration 19/25 | Loss: 0.00247857
Iteration 20/25 | Loss: 0.00247857
Iteration 21/25 | Loss: 0.00247857
Iteration 22/25 | Loss: 0.00247857
Iteration 23/25 | Loss: 0.00247857
Iteration 24/25 | Loss: 0.00247857
Iteration 25/25 | Loss: 0.00247857

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00247857
Iteration 2/1000 | Loss: 0.00006032
Iteration 3/1000 | Loss: 0.00004571
Iteration 4/1000 | Loss: 0.00004065
Iteration 5/1000 | Loss: 0.00003837
Iteration 6/1000 | Loss: 0.00003733
Iteration 7/1000 | Loss: 0.00003635
Iteration 8/1000 | Loss: 0.00003551
Iteration 9/1000 | Loss: 0.00003491
Iteration 10/1000 | Loss: 0.00003445
Iteration 11/1000 | Loss: 0.00003407
Iteration 12/1000 | Loss: 0.00003373
Iteration 13/1000 | Loss: 0.00003342
Iteration 14/1000 | Loss: 0.00003317
Iteration 15/1000 | Loss: 0.00003294
Iteration 16/1000 | Loss: 0.00003271
Iteration 17/1000 | Loss: 0.00003250
Iteration 18/1000 | Loss: 0.00003230
Iteration 19/1000 | Loss: 0.00003214
Iteration 20/1000 | Loss: 0.00003203
Iteration 21/1000 | Loss: 0.00003200
Iteration 22/1000 | Loss: 0.00003198
Iteration 23/1000 | Loss: 0.00003195
Iteration 24/1000 | Loss: 0.00003193
Iteration 25/1000 | Loss: 0.00003188
Iteration 26/1000 | Loss: 0.00003185
Iteration 27/1000 | Loss: 0.00003185
Iteration 28/1000 | Loss: 0.00003184
Iteration 29/1000 | Loss: 0.00003184
Iteration 30/1000 | Loss: 0.00003184
Iteration 31/1000 | Loss: 0.00003184
Iteration 32/1000 | Loss: 0.00003184
Iteration 33/1000 | Loss: 0.00003184
Iteration 34/1000 | Loss: 0.00003184
Iteration 35/1000 | Loss: 0.00003184
Iteration 36/1000 | Loss: 0.00003183
Iteration 37/1000 | Loss: 0.00003183
Iteration 38/1000 | Loss: 0.00003182
Iteration 39/1000 | Loss: 0.00003182
Iteration 40/1000 | Loss: 0.00003182
Iteration 41/1000 | Loss: 0.00003181
Iteration 42/1000 | Loss: 0.00003181
Iteration 43/1000 | Loss: 0.00003181
Iteration 44/1000 | Loss: 0.00003181
Iteration 45/1000 | Loss: 0.00003180
Iteration 46/1000 | Loss: 0.00003180
Iteration 47/1000 | Loss: 0.00003180
Iteration 48/1000 | Loss: 0.00003180
Iteration 49/1000 | Loss: 0.00003180
Iteration 50/1000 | Loss: 0.00003180
Iteration 51/1000 | Loss: 0.00003179
Iteration 52/1000 | Loss: 0.00003179
Iteration 53/1000 | Loss: 0.00003179
Iteration 54/1000 | Loss: 0.00003179
Iteration 55/1000 | Loss: 0.00003179
Iteration 56/1000 | Loss: 0.00003179
Iteration 57/1000 | Loss: 0.00003179
Iteration 58/1000 | Loss: 0.00003179
Iteration 59/1000 | Loss: 0.00003179
Iteration 60/1000 | Loss: 0.00003179
Iteration 61/1000 | Loss: 0.00003179
Iteration 62/1000 | Loss: 0.00003178
Iteration 63/1000 | Loss: 0.00003178
Iteration 64/1000 | Loss: 0.00003178
Iteration 65/1000 | Loss: 0.00003178
Iteration 66/1000 | Loss: 0.00003178
Iteration 67/1000 | Loss: 0.00003178
Iteration 68/1000 | Loss: 0.00003178
Iteration 69/1000 | Loss: 0.00003178
Iteration 70/1000 | Loss: 0.00003177
Iteration 71/1000 | Loss: 0.00003176
Iteration 72/1000 | Loss: 0.00003176
Iteration 73/1000 | Loss: 0.00003176
Iteration 74/1000 | Loss: 0.00003176
Iteration 75/1000 | Loss: 0.00003176
Iteration 76/1000 | Loss: 0.00003176
Iteration 77/1000 | Loss: 0.00003176
Iteration 78/1000 | Loss: 0.00003176
Iteration 79/1000 | Loss: 0.00003176
Iteration 80/1000 | Loss: 0.00003176
Iteration 81/1000 | Loss: 0.00003176
Iteration 82/1000 | Loss: 0.00003176
Iteration 83/1000 | Loss: 0.00003175
Iteration 84/1000 | Loss: 0.00003175
Iteration 85/1000 | Loss: 0.00003175
Iteration 86/1000 | Loss: 0.00003175
Iteration 87/1000 | Loss: 0.00003175
Iteration 88/1000 | Loss: 0.00003175
Iteration 89/1000 | Loss: 0.00003175
Iteration 90/1000 | Loss: 0.00003175
Iteration 91/1000 | Loss: 0.00003174
Iteration 92/1000 | Loss: 0.00003174
Iteration 93/1000 | Loss: 0.00003174
Iteration 94/1000 | Loss: 0.00003174
Iteration 95/1000 | Loss: 0.00003174
Iteration 96/1000 | Loss: 0.00003174
Iteration 97/1000 | Loss: 0.00003174
Iteration 98/1000 | Loss: 0.00003174
Iteration 99/1000 | Loss: 0.00003174
Iteration 100/1000 | Loss: 0.00003173
Iteration 101/1000 | Loss: 0.00003173
Iteration 102/1000 | Loss: 0.00003173
Iteration 103/1000 | Loss: 0.00003173
Iteration 104/1000 | Loss: 0.00003173
Iteration 105/1000 | Loss: 0.00003173
Iteration 106/1000 | Loss: 0.00003173
Iteration 107/1000 | Loss: 0.00003172
Iteration 108/1000 | Loss: 0.00003172
Iteration 109/1000 | Loss: 0.00003172
Iteration 110/1000 | Loss: 0.00003172
Iteration 111/1000 | Loss: 0.00003172
Iteration 112/1000 | Loss: 0.00003172
Iteration 113/1000 | Loss: 0.00003172
Iteration 114/1000 | Loss: 0.00003172
Iteration 115/1000 | Loss: 0.00003172
Iteration 116/1000 | Loss: 0.00003172
Iteration 117/1000 | Loss: 0.00003172
Iteration 118/1000 | Loss: 0.00003171
Iteration 119/1000 | Loss: 0.00003171
Iteration 120/1000 | Loss: 0.00003171
Iteration 121/1000 | Loss: 0.00003171
Iteration 122/1000 | Loss: 0.00003171
Iteration 123/1000 | Loss: 0.00003171
Iteration 124/1000 | Loss: 0.00003171
Iteration 125/1000 | Loss: 0.00003171
Iteration 126/1000 | Loss: 0.00003171
Iteration 127/1000 | Loss: 0.00003171
Iteration 128/1000 | Loss: 0.00003171
Iteration 129/1000 | Loss: 0.00003170
Iteration 130/1000 | Loss: 0.00003170
Iteration 131/1000 | Loss: 0.00003170
Iteration 132/1000 | Loss: 0.00003170
Iteration 133/1000 | Loss: 0.00003170
Iteration 134/1000 | Loss: 0.00003170
Iteration 135/1000 | Loss: 0.00003170
Iteration 136/1000 | Loss: 0.00003170
Iteration 137/1000 | Loss: 0.00003170
Iteration 138/1000 | Loss: 0.00003170
Iteration 139/1000 | Loss: 0.00003170
Iteration 140/1000 | Loss: 0.00003170
Iteration 141/1000 | Loss: 0.00003170
Iteration 142/1000 | Loss: 0.00003170
Iteration 143/1000 | Loss: 0.00003170
Iteration 144/1000 | Loss: 0.00003170
Iteration 145/1000 | Loss: 0.00003170
Iteration 146/1000 | Loss: 0.00003170
Iteration 147/1000 | Loss: 0.00003170
Iteration 148/1000 | Loss: 0.00003170
Iteration 149/1000 | Loss: 0.00003170
Iteration 150/1000 | Loss: 0.00003170
Iteration 151/1000 | Loss: 0.00003170
Iteration 152/1000 | Loss: 0.00003170
Iteration 153/1000 | Loss: 0.00003170
Iteration 154/1000 | Loss: 0.00003170
Iteration 155/1000 | Loss: 0.00003170
Iteration 156/1000 | Loss: 0.00003170
Iteration 157/1000 | Loss: 0.00003170
Iteration 158/1000 | Loss: 0.00003170
Iteration 159/1000 | Loss: 0.00003170
Iteration 160/1000 | Loss: 0.00003170
Iteration 161/1000 | Loss: 0.00003170
Iteration 162/1000 | Loss: 0.00003170
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [3.170271884300746e-05, 3.170271884300746e-05, 3.170271884300746e-05, 3.170271884300746e-05, 3.170271884300746e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.170271884300746e-05

Optimization complete. Final v2v error: 4.157384395599365 mm

Highest mean error: 5.732078552246094 mm for frame 92

Lowest mean error: 2.584989309310913 mm for frame 1

Saving results

Total time: 46.99540972709656
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00422045
Iteration 2/25 | Loss: 0.00137495
Iteration 3/25 | Loss: 0.00121001
Iteration 4/25 | Loss: 0.00119069
Iteration 5/25 | Loss: 0.00118664
Iteration 6/25 | Loss: 0.00118626
Iteration 7/25 | Loss: 0.00118626
Iteration 8/25 | Loss: 0.00118626
Iteration 9/25 | Loss: 0.00118626
Iteration 10/25 | Loss: 0.00118626
Iteration 11/25 | Loss: 0.00118626
Iteration 12/25 | Loss: 0.00118626
Iteration 13/25 | Loss: 0.00118626
Iteration 14/25 | Loss: 0.00118626
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0011862622341141105, 0.0011862622341141105, 0.0011862622341141105, 0.0011862622341141105, 0.0011862622341141105]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011862622341141105

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.06531239
Iteration 2/25 | Loss: 0.00293049
Iteration 3/25 | Loss: 0.00293047
Iteration 4/25 | Loss: 0.00293047
Iteration 5/25 | Loss: 0.00293047
Iteration 6/25 | Loss: 0.00293047
Iteration 7/25 | Loss: 0.00293047
Iteration 8/25 | Loss: 0.00293046
Iteration 9/25 | Loss: 0.00293046
Iteration 10/25 | Loss: 0.00293046
Iteration 11/25 | Loss: 0.00293046
Iteration 12/25 | Loss: 0.00293046
Iteration 13/25 | Loss: 0.00293046
Iteration 14/25 | Loss: 0.00293046
Iteration 15/25 | Loss: 0.00293046
Iteration 16/25 | Loss: 0.00293046
Iteration 17/25 | Loss: 0.00293046
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.002930464455857873, 0.002930464455857873, 0.002930464455857873, 0.002930464455857873, 0.002930464455857873]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002930464455857873

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00293046
Iteration 2/1000 | Loss: 0.00002820
Iteration 3/1000 | Loss: 0.00001990
Iteration 4/1000 | Loss: 0.00001754
Iteration 5/1000 | Loss: 0.00001593
Iteration 6/1000 | Loss: 0.00001528
Iteration 7/1000 | Loss: 0.00001474
Iteration 8/1000 | Loss: 0.00001437
Iteration 9/1000 | Loss: 0.00001405
Iteration 10/1000 | Loss: 0.00001405
Iteration 11/1000 | Loss: 0.00001384
Iteration 12/1000 | Loss: 0.00001374
Iteration 13/1000 | Loss: 0.00001373
Iteration 14/1000 | Loss: 0.00001368
Iteration 15/1000 | Loss: 0.00001365
Iteration 16/1000 | Loss: 0.00001349
Iteration 17/1000 | Loss: 0.00001346
Iteration 18/1000 | Loss: 0.00001346
Iteration 19/1000 | Loss: 0.00001345
Iteration 20/1000 | Loss: 0.00001344
Iteration 21/1000 | Loss: 0.00001344
Iteration 22/1000 | Loss: 0.00001340
Iteration 23/1000 | Loss: 0.00001340
Iteration 24/1000 | Loss: 0.00001340
Iteration 25/1000 | Loss: 0.00001340
Iteration 26/1000 | Loss: 0.00001340
Iteration 27/1000 | Loss: 0.00001340
Iteration 28/1000 | Loss: 0.00001340
Iteration 29/1000 | Loss: 0.00001340
Iteration 30/1000 | Loss: 0.00001340
Iteration 31/1000 | Loss: 0.00001340
Iteration 32/1000 | Loss: 0.00001340
Iteration 33/1000 | Loss: 0.00001340
Iteration 34/1000 | Loss: 0.00001340
Iteration 35/1000 | Loss: 0.00001340
Iteration 36/1000 | Loss: 0.00001340
Iteration 37/1000 | Loss: 0.00001340
Iteration 38/1000 | Loss: 0.00001340
Iteration 39/1000 | Loss: 0.00001340
Iteration 40/1000 | Loss: 0.00001340
Iteration 41/1000 | Loss: 0.00001340
Iteration 42/1000 | Loss: 0.00001340
Iteration 43/1000 | Loss: 0.00001340
Iteration 44/1000 | Loss: 0.00001340
Iteration 45/1000 | Loss: 0.00001340
Iteration 46/1000 | Loss: 0.00001340
Iteration 47/1000 | Loss: 0.00001340
Iteration 48/1000 | Loss: 0.00001340
Iteration 49/1000 | Loss: 0.00001340
Iteration 50/1000 | Loss: 0.00001340
Iteration 51/1000 | Loss: 0.00001340
Iteration 52/1000 | Loss: 0.00001340
Iteration 53/1000 | Loss: 0.00001340
Iteration 54/1000 | Loss: 0.00001340
Iteration 55/1000 | Loss: 0.00001340
Iteration 56/1000 | Loss: 0.00001340
Iteration 57/1000 | Loss: 0.00001340
Iteration 58/1000 | Loss: 0.00001340
Iteration 59/1000 | Loss: 0.00001340
Iteration 60/1000 | Loss: 0.00001340
Iteration 61/1000 | Loss: 0.00001340
Iteration 62/1000 | Loss: 0.00001340
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 62. Stopping optimization.
Last 5 losses: [1.3403246157395188e-05, 1.3403246157395188e-05, 1.3403246157395188e-05, 1.3403246157395188e-05, 1.3403246157395188e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3403246157395188e-05

Optimization complete. Final v2v error: 3.1481118202209473 mm

Highest mean error: 3.548224449157715 mm for frame 97

Lowest mean error: 2.7742457389831543 mm for frame 42

Saving results

Total time: 26.438589334487915
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00427956
Iteration 2/25 | Loss: 0.00126704
Iteration 3/25 | Loss: 0.00120650
Iteration 4/25 | Loss: 0.00120058
Iteration 5/25 | Loss: 0.00119871
Iteration 6/25 | Loss: 0.00119833
Iteration 7/25 | Loss: 0.00119833
Iteration 8/25 | Loss: 0.00119833
Iteration 9/25 | Loss: 0.00119833
Iteration 10/25 | Loss: 0.00119833
Iteration 11/25 | Loss: 0.00119833
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.00119833427015692, 0.00119833427015692, 0.00119833427015692, 0.00119833427015692, 0.00119833427015692]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00119833427015692

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.80705065
Iteration 2/25 | Loss: 0.00322914
Iteration 3/25 | Loss: 0.00322914
Iteration 4/25 | Loss: 0.00322914
Iteration 5/25 | Loss: 0.00322913
Iteration 6/25 | Loss: 0.00322913
Iteration 7/25 | Loss: 0.00322913
Iteration 8/25 | Loss: 0.00322913
Iteration 9/25 | Loss: 0.00322913
Iteration 10/25 | Loss: 0.00322913
Iteration 11/25 | Loss: 0.00322913
Iteration 12/25 | Loss: 0.00322913
Iteration 13/25 | Loss: 0.00322913
Iteration 14/25 | Loss: 0.00322913
Iteration 15/25 | Loss: 0.00322913
Iteration 16/25 | Loss: 0.00322913
Iteration 17/25 | Loss: 0.00322913
Iteration 18/25 | Loss: 0.00322913
Iteration 19/25 | Loss: 0.00322913
Iteration 20/25 | Loss: 0.00322913
Iteration 21/25 | Loss: 0.00322913
Iteration 22/25 | Loss: 0.00322913
Iteration 23/25 | Loss: 0.00322913
Iteration 24/25 | Loss: 0.00322913
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.003229132853448391, 0.003229132853448391, 0.003229132853448391, 0.003229132853448391, 0.003229132853448391]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003229132853448391

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00322913
Iteration 2/1000 | Loss: 0.00003385
Iteration 3/1000 | Loss: 0.00001771
Iteration 4/1000 | Loss: 0.00001464
Iteration 5/1000 | Loss: 0.00001369
Iteration 6/1000 | Loss: 0.00001308
Iteration 7/1000 | Loss: 0.00001281
Iteration 8/1000 | Loss: 0.00001244
Iteration 9/1000 | Loss: 0.00001220
Iteration 10/1000 | Loss: 0.00001183
Iteration 11/1000 | Loss: 0.00001176
Iteration 12/1000 | Loss: 0.00001160
Iteration 13/1000 | Loss: 0.00001141
Iteration 14/1000 | Loss: 0.00001130
Iteration 15/1000 | Loss: 0.00001125
Iteration 16/1000 | Loss: 0.00001124
Iteration 17/1000 | Loss: 0.00001113
Iteration 18/1000 | Loss: 0.00001110
Iteration 19/1000 | Loss: 0.00001109
Iteration 20/1000 | Loss: 0.00001109
Iteration 21/1000 | Loss: 0.00001107
Iteration 22/1000 | Loss: 0.00001107
Iteration 23/1000 | Loss: 0.00001107
Iteration 24/1000 | Loss: 0.00001106
Iteration 25/1000 | Loss: 0.00001105
Iteration 26/1000 | Loss: 0.00001105
Iteration 27/1000 | Loss: 0.00001104
Iteration 28/1000 | Loss: 0.00001104
Iteration 29/1000 | Loss: 0.00001103
Iteration 30/1000 | Loss: 0.00001103
Iteration 31/1000 | Loss: 0.00001102
Iteration 32/1000 | Loss: 0.00001102
Iteration 33/1000 | Loss: 0.00001101
Iteration 34/1000 | Loss: 0.00001097
Iteration 35/1000 | Loss: 0.00001095
Iteration 36/1000 | Loss: 0.00001095
Iteration 37/1000 | Loss: 0.00001095
Iteration 38/1000 | Loss: 0.00001095
Iteration 39/1000 | Loss: 0.00001095
Iteration 40/1000 | Loss: 0.00001095
Iteration 41/1000 | Loss: 0.00001094
Iteration 42/1000 | Loss: 0.00001093
Iteration 43/1000 | Loss: 0.00001092
Iteration 44/1000 | Loss: 0.00001092
Iteration 45/1000 | Loss: 0.00001092
Iteration 46/1000 | Loss: 0.00001091
Iteration 47/1000 | Loss: 0.00001091
Iteration 48/1000 | Loss: 0.00001091
Iteration 49/1000 | Loss: 0.00001090
Iteration 50/1000 | Loss: 0.00001090
Iteration 51/1000 | Loss: 0.00001090
Iteration 52/1000 | Loss: 0.00001089
Iteration 53/1000 | Loss: 0.00001089
Iteration 54/1000 | Loss: 0.00001088
Iteration 55/1000 | Loss: 0.00001088
Iteration 56/1000 | Loss: 0.00001088
Iteration 57/1000 | Loss: 0.00001088
Iteration 58/1000 | Loss: 0.00001088
Iteration 59/1000 | Loss: 0.00001088
Iteration 60/1000 | Loss: 0.00001088
Iteration 61/1000 | Loss: 0.00001088
Iteration 62/1000 | Loss: 0.00001088
Iteration 63/1000 | Loss: 0.00001088
Iteration 64/1000 | Loss: 0.00001088
Iteration 65/1000 | Loss: 0.00001088
Iteration 66/1000 | Loss: 0.00001088
Iteration 67/1000 | Loss: 0.00001088
Iteration 68/1000 | Loss: 0.00001088
Iteration 69/1000 | Loss: 0.00001088
Iteration 70/1000 | Loss: 0.00001088
Iteration 71/1000 | Loss: 0.00001088
Iteration 72/1000 | Loss: 0.00001088
Iteration 73/1000 | Loss: 0.00001088
Iteration 74/1000 | Loss: 0.00001088
Iteration 75/1000 | Loss: 0.00001088
Iteration 76/1000 | Loss: 0.00001088
Iteration 77/1000 | Loss: 0.00001088
Iteration 78/1000 | Loss: 0.00001088
Iteration 79/1000 | Loss: 0.00001088
Iteration 80/1000 | Loss: 0.00001088
Iteration 81/1000 | Loss: 0.00001088
Iteration 82/1000 | Loss: 0.00001088
Iteration 83/1000 | Loss: 0.00001088
Iteration 84/1000 | Loss: 0.00001088
Iteration 85/1000 | Loss: 0.00001088
Iteration 86/1000 | Loss: 0.00001088
Iteration 87/1000 | Loss: 0.00001088
Iteration 88/1000 | Loss: 0.00001088
Iteration 89/1000 | Loss: 0.00001088
Iteration 90/1000 | Loss: 0.00001088
Iteration 91/1000 | Loss: 0.00001088
Iteration 92/1000 | Loss: 0.00001088
Iteration 93/1000 | Loss: 0.00001088
Iteration 94/1000 | Loss: 0.00001088
Iteration 95/1000 | Loss: 0.00001088
Iteration 96/1000 | Loss: 0.00001088
Iteration 97/1000 | Loss: 0.00001088
Iteration 98/1000 | Loss: 0.00001088
Iteration 99/1000 | Loss: 0.00001088
Iteration 100/1000 | Loss: 0.00001088
Iteration 101/1000 | Loss: 0.00001088
Iteration 102/1000 | Loss: 0.00001088
Iteration 103/1000 | Loss: 0.00001088
Iteration 104/1000 | Loss: 0.00001088
Iteration 105/1000 | Loss: 0.00001088
Iteration 106/1000 | Loss: 0.00001088
Iteration 107/1000 | Loss: 0.00001088
Iteration 108/1000 | Loss: 0.00001088
Iteration 109/1000 | Loss: 0.00001088
Iteration 110/1000 | Loss: 0.00001088
Iteration 111/1000 | Loss: 0.00001088
Iteration 112/1000 | Loss: 0.00001088
Iteration 113/1000 | Loss: 0.00001088
Iteration 114/1000 | Loss: 0.00001088
Iteration 115/1000 | Loss: 0.00001088
Iteration 116/1000 | Loss: 0.00001088
Iteration 117/1000 | Loss: 0.00001088
Iteration 118/1000 | Loss: 0.00001088
Iteration 119/1000 | Loss: 0.00001088
Iteration 120/1000 | Loss: 0.00001088
Iteration 121/1000 | Loss: 0.00001088
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 121. Stopping optimization.
Last 5 losses: [1.0875725820369553e-05, 1.0875725820369553e-05, 1.0875725820369553e-05, 1.0875725820369553e-05, 1.0875725820369553e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0875725820369553e-05

Optimization complete. Final v2v error: 2.862602472305298 mm

Highest mean error: 3.299278736114502 mm for frame 107

Lowest mean error: 2.5374929904937744 mm for frame 70

Saving results

Total time: 32.57820272445679
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01061893
Iteration 2/25 | Loss: 0.00455765
Iteration 3/25 | Loss: 0.00208630
Iteration 4/25 | Loss: 0.00173353
Iteration 5/25 | Loss: 0.00157669
Iteration 6/25 | Loss: 0.00163643
Iteration 7/25 | Loss: 0.00159317
Iteration 8/25 | Loss: 0.00145851
Iteration 9/25 | Loss: 0.00139836
Iteration 10/25 | Loss: 0.00136273
Iteration 11/25 | Loss: 0.00135074
Iteration 12/25 | Loss: 0.00133221
Iteration 13/25 | Loss: 0.00132049
Iteration 14/25 | Loss: 0.00130368
Iteration 15/25 | Loss: 0.00130308
Iteration 16/25 | Loss: 0.00130952
Iteration 17/25 | Loss: 0.00130793
Iteration 18/25 | Loss: 0.00131854
Iteration 19/25 | Loss: 0.00131513
Iteration 20/25 | Loss: 0.00131514
Iteration 21/25 | Loss: 0.00131191
Iteration 22/25 | Loss: 0.00131042
Iteration 23/25 | Loss: 0.00131070
Iteration 24/25 | Loss: 0.00130215
Iteration 25/25 | Loss: 0.00130397

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49605525
Iteration 2/25 | Loss: 0.00424539
Iteration 3/25 | Loss: 0.00423665
Iteration 4/25 | Loss: 0.00423665
Iteration 5/25 | Loss: 0.00423665
Iteration 6/25 | Loss: 0.00423665
Iteration 7/25 | Loss: 0.00423665
Iteration 8/25 | Loss: 0.00423665
Iteration 9/25 | Loss: 0.00423664
Iteration 10/25 | Loss: 0.00423664
Iteration 11/25 | Loss: 0.00423664
Iteration 12/25 | Loss: 0.00423664
Iteration 13/25 | Loss: 0.00423664
Iteration 14/25 | Loss: 0.00423664
Iteration 15/25 | Loss: 0.00423664
Iteration 16/25 | Loss: 0.00423664
Iteration 17/25 | Loss: 0.00423664
Iteration 18/25 | Loss: 0.00423664
Iteration 19/25 | Loss: 0.00423664
Iteration 20/25 | Loss: 0.00423664
Iteration 21/25 | Loss: 0.00423664
Iteration 22/25 | Loss: 0.00423664
Iteration 23/25 | Loss: 0.00423664
Iteration 24/25 | Loss: 0.00423664
Iteration 25/25 | Loss: 0.00423664

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00423664
Iteration 2/1000 | Loss: 0.00020104
Iteration 3/1000 | Loss: 0.00029171
Iteration 4/1000 | Loss: 0.00028640
Iteration 5/1000 | Loss: 0.00050581
Iteration 6/1000 | Loss: 0.00050226
Iteration 7/1000 | Loss: 0.00046627
Iteration 8/1000 | Loss: 0.00040168
Iteration 9/1000 | Loss: 0.00040820
Iteration 10/1000 | Loss: 0.00029071
Iteration 11/1000 | Loss: 0.00026026
Iteration 12/1000 | Loss: 0.00022033
Iteration 13/1000 | Loss: 0.00030797
Iteration 14/1000 | Loss: 0.00056017
Iteration 15/1000 | Loss: 0.00046215
Iteration 16/1000 | Loss: 0.00072834
Iteration 17/1000 | Loss: 0.00062582
Iteration 18/1000 | Loss: 0.00053903
Iteration 19/1000 | Loss: 0.00048192
Iteration 20/1000 | Loss: 0.00061745
Iteration 21/1000 | Loss: 0.00032805
Iteration 22/1000 | Loss: 0.00028019
Iteration 23/1000 | Loss: 0.00034741
Iteration 24/1000 | Loss: 0.00040262
Iteration 25/1000 | Loss: 0.00039362
Iteration 26/1000 | Loss: 0.00023447
Iteration 27/1000 | Loss: 0.00033323
Iteration 28/1000 | Loss: 0.00027146
Iteration 29/1000 | Loss: 0.00010859
Iteration 30/1000 | Loss: 0.00007741
Iteration 31/1000 | Loss: 0.00007270
Iteration 32/1000 | Loss: 0.00038185
Iteration 33/1000 | Loss: 0.00007987
Iteration 34/1000 | Loss: 0.00073919
Iteration 35/1000 | Loss: 0.00028053
Iteration 36/1000 | Loss: 0.00072900
Iteration 37/1000 | Loss: 0.00379368
Iteration 38/1000 | Loss: 0.00166352
Iteration 39/1000 | Loss: 0.00115168
Iteration 40/1000 | Loss: 0.00059475
Iteration 41/1000 | Loss: 0.00033787
Iteration 42/1000 | Loss: 0.00021708
Iteration 43/1000 | Loss: 0.00022608
Iteration 44/1000 | Loss: 0.00009802
Iteration 45/1000 | Loss: 0.00034808
Iteration 46/1000 | Loss: 0.00042512
Iteration 47/1000 | Loss: 0.00031209
Iteration 48/1000 | Loss: 0.00004678
Iteration 49/1000 | Loss: 0.00004585
Iteration 50/1000 | Loss: 0.00002989
Iteration 51/1000 | Loss: 0.00002650
Iteration 52/1000 | Loss: 0.00003258
Iteration 53/1000 | Loss: 0.00022319
Iteration 54/1000 | Loss: 0.00019669
Iteration 55/1000 | Loss: 0.00020734
Iteration 56/1000 | Loss: 0.00029942
Iteration 57/1000 | Loss: 0.00014558
Iteration 58/1000 | Loss: 0.00017294
Iteration 59/1000 | Loss: 0.00024765
Iteration 60/1000 | Loss: 0.00010344
Iteration 61/1000 | Loss: 0.00015585
Iteration 62/1000 | Loss: 0.00023570
Iteration 63/1000 | Loss: 0.00005687
Iteration 64/1000 | Loss: 0.00004354
Iteration 65/1000 | Loss: 0.00004195
Iteration 66/1000 | Loss: 0.00003424
Iteration 67/1000 | Loss: 0.00004797
Iteration 68/1000 | Loss: 0.00011766
Iteration 69/1000 | Loss: 0.00010160
Iteration 70/1000 | Loss: 0.00002518
Iteration 71/1000 | Loss: 0.00003586
Iteration 72/1000 | Loss: 0.00004368
Iteration 73/1000 | Loss: 0.00015249
Iteration 74/1000 | Loss: 0.00005139
Iteration 75/1000 | Loss: 0.00016709
Iteration 76/1000 | Loss: 0.00003351
Iteration 77/1000 | Loss: 0.00003478
Iteration 78/1000 | Loss: 0.00003375
Iteration 79/1000 | Loss: 0.00003771
Iteration 80/1000 | Loss: 0.00015294
Iteration 81/1000 | Loss: 0.00009848
Iteration 82/1000 | Loss: 0.00003357
Iteration 83/1000 | Loss: 0.00013983
Iteration 84/1000 | Loss: 0.00003215
Iteration 85/1000 | Loss: 0.00003588
Iteration 86/1000 | Loss: 0.00002909
Iteration 87/1000 | Loss: 0.00004079
Iteration 88/1000 | Loss: 0.00003404
Iteration 89/1000 | Loss: 0.00005131
Iteration 90/1000 | Loss: 0.00003457
Iteration 91/1000 | Loss: 0.00003206
Iteration 92/1000 | Loss: 0.00003371
Iteration 93/1000 | Loss: 0.00002563
Iteration 94/1000 | Loss: 0.00002274
Iteration 95/1000 | Loss: 0.00026167
Iteration 96/1000 | Loss: 0.00008733
Iteration 97/1000 | Loss: 0.00004844
Iteration 98/1000 | Loss: 0.00003938
Iteration 99/1000 | Loss: 0.00002683
Iteration 100/1000 | Loss: 0.00024811
Iteration 101/1000 | Loss: 0.00019232
Iteration 102/1000 | Loss: 0.00003169
Iteration 103/1000 | Loss: 0.00003207
Iteration 104/1000 | Loss: 0.00003502
Iteration 105/1000 | Loss: 0.00003129
Iteration 106/1000 | Loss: 0.00003088
Iteration 107/1000 | Loss: 0.00003588
Iteration 108/1000 | Loss: 0.00003485
Iteration 109/1000 | Loss: 0.00003410
Iteration 110/1000 | Loss: 0.00003362
Iteration 111/1000 | Loss: 0.00003445
Iteration 112/1000 | Loss: 0.00003073
Iteration 113/1000 | Loss: 0.00001939
Iteration 114/1000 | Loss: 0.00004643
Iteration 115/1000 | Loss: 0.00002896
Iteration 116/1000 | Loss: 0.00003139
Iteration 117/1000 | Loss: 0.00002846
Iteration 118/1000 | Loss: 0.00003046
Iteration 119/1000 | Loss: 0.00002738
Iteration 120/1000 | Loss: 0.00001621
Iteration 121/1000 | Loss: 0.00002834
Iteration 122/1000 | Loss: 0.00002904
Iteration 123/1000 | Loss: 0.00003179
Iteration 124/1000 | Loss: 0.00003004
Iteration 125/1000 | Loss: 0.00003131
Iteration 126/1000 | Loss: 0.00002873
Iteration 127/1000 | Loss: 0.00002698
Iteration 128/1000 | Loss: 0.00003020
Iteration 129/1000 | Loss: 0.00003441
Iteration 130/1000 | Loss: 0.00003068
Iteration 131/1000 | Loss: 0.00003046
Iteration 132/1000 | Loss: 0.00003075
Iteration 133/1000 | Loss: 0.00001673
Iteration 134/1000 | Loss: 0.00001719
Iteration 135/1000 | Loss: 0.00003555
Iteration 136/1000 | Loss: 0.00002662
Iteration 137/1000 | Loss: 0.00002951
Iteration 138/1000 | Loss: 0.00002724
Iteration 139/1000 | Loss: 0.00002923
Iteration 140/1000 | Loss: 0.00002898
Iteration 141/1000 | Loss: 0.00005067
Iteration 142/1000 | Loss: 0.00002882
Iteration 143/1000 | Loss: 0.00003374
Iteration 144/1000 | Loss: 0.00002910
Iteration 145/1000 | Loss: 0.00002947
Iteration 146/1000 | Loss: 0.00003007
Iteration 147/1000 | Loss: 0.00002730
Iteration 148/1000 | Loss: 0.00003123
Iteration 149/1000 | Loss: 0.00001657
Iteration 150/1000 | Loss: 0.00003392
Iteration 151/1000 | Loss: 0.00003747
Iteration 152/1000 | Loss: 0.00003266
Iteration 153/1000 | Loss: 0.00003083
Iteration 154/1000 | Loss: 0.00002698
Iteration 155/1000 | Loss: 0.00002871
Iteration 156/1000 | Loss: 0.00002587
Iteration 157/1000 | Loss: 0.00002841
Iteration 158/1000 | Loss: 0.00002572
Iteration 159/1000 | Loss: 0.00003132
Iteration 160/1000 | Loss: 0.00002788
Iteration 161/1000 | Loss: 0.00002952
Iteration 162/1000 | Loss: 0.00002875
Iteration 163/1000 | Loss: 0.00002931
Iteration 164/1000 | Loss: 0.00002865
Iteration 165/1000 | Loss: 0.00002862
Iteration 166/1000 | Loss: 0.00002557
Iteration 167/1000 | Loss: 0.00001439
Iteration 168/1000 | Loss: 0.00002688
Iteration 169/1000 | Loss: 0.00002709
Iteration 170/1000 | Loss: 0.00003098
Iteration 171/1000 | Loss: 0.00002732
Iteration 172/1000 | Loss: 0.00003199
Iteration 173/1000 | Loss: 0.00002776
Iteration 174/1000 | Loss: 0.00003598
Iteration 175/1000 | Loss: 0.00002968
Iteration 176/1000 | Loss: 0.00002527
Iteration 177/1000 | Loss: 0.00001399
Iteration 178/1000 | Loss: 0.00001241
Iteration 179/1000 | Loss: 0.00001166
Iteration 180/1000 | Loss: 0.00001135
Iteration 181/1000 | Loss: 0.00001122
Iteration 182/1000 | Loss: 0.00001121
Iteration 183/1000 | Loss: 0.00001120
Iteration 184/1000 | Loss: 0.00001116
Iteration 185/1000 | Loss: 0.00001116
Iteration 186/1000 | Loss: 0.00001115
Iteration 187/1000 | Loss: 0.00001113
Iteration 188/1000 | Loss: 0.00001112
Iteration 189/1000 | Loss: 0.00001111
Iteration 190/1000 | Loss: 0.00001111
Iteration 191/1000 | Loss: 0.00001111
Iteration 192/1000 | Loss: 0.00001110
Iteration 193/1000 | Loss: 0.00001110
Iteration 194/1000 | Loss: 0.00001110
Iteration 195/1000 | Loss: 0.00001109
Iteration 196/1000 | Loss: 0.00001109
Iteration 197/1000 | Loss: 0.00001109
Iteration 198/1000 | Loss: 0.00001108
Iteration 199/1000 | Loss: 0.00001108
Iteration 200/1000 | Loss: 0.00001106
Iteration 201/1000 | Loss: 0.00001102
Iteration 202/1000 | Loss: 0.00001101
Iteration 203/1000 | Loss: 0.00001101
Iteration 204/1000 | Loss: 0.00001101
Iteration 205/1000 | Loss: 0.00001100
Iteration 206/1000 | Loss: 0.00001100
Iteration 207/1000 | Loss: 0.00001099
Iteration 208/1000 | Loss: 0.00001099
Iteration 209/1000 | Loss: 0.00001099
Iteration 210/1000 | Loss: 0.00001099
Iteration 211/1000 | Loss: 0.00001099
Iteration 212/1000 | Loss: 0.00001098
Iteration 213/1000 | Loss: 0.00001098
Iteration 214/1000 | Loss: 0.00001097
Iteration 215/1000 | Loss: 0.00001097
Iteration 216/1000 | Loss: 0.00001097
Iteration 217/1000 | Loss: 0.00001097
Iteration 218/1000 | Loss: 0.00001096
Iteration 219/1000 | Loss: 0.00001096
Iteration 220/1000 | Loss: 0.00001096
Iteration 221/1000 | Loss: 0.00001094
Iteration 222/1000 | Loss: 0.00001094
Iteration 223/1000 | Loss: 0.00001094
Iteration 224/1000 | Loss: 0.00001094
Iteration 225/1000 | Loss: 0.00001094
Iteration 226/1000 | Loss: 0.00001094
Iteration 227/1000 | Loss: 0.00001094
Iteration 228/1000 | Loss: 0.00001094
Iteration 229/1000 | Loss: 0.00001094
Iteration 230/1000 | Loss: 0.00001093
Iteration 231/1000 | Loss: 0.00001093
Iteration 232/1000 | Loss: 0.00001093
Iteration 233/1000 | Loss: 0.00001093
Iteration 234/1000 | Loss: 0.00001093
Iteration 235/1000 | Loss: 0.00001093
Iteration 236/1000 | Loss: 0.00001093
Iteration 237/1000 | Loss: 0.00001092
Iteration 238/1000 | Loss: 0.00001092
Iteration 239/1000 | Loss: 0.00001092
Iteration 240/1000 | Loss: 0.00001091
Iteration 241/1000 | Loss: 0.00001091
Iteration 242/1000 | Loss: 0.00001090
Iteration 243/1000 | Loss: 0.00001090
Iteration 244/1000 | Loss: 0.00001089
Iteration 245/1000 | Loss: 0.00001089
Iteration 246/1000 | Loss: 0.00001088
Iteration 247/1000 | Loss: 0.00001088
Iteration 248/1000 | Loss: 0.00001087
Iteration 249/1000 | Loss: 0.00001087
Iteration 250/1000 | Loss: 0.00001087
Iteration 251/1000 | Loss: 0.00001087
Iteration 252/1000 | Loss: 0.00001087
Iteration 253/1000 | Loss: 0.00001087
Iteration 254/1000 | Loss: 0.00001087
Iteration 255/1000 | Loss: 0.00001086
Iteration 256/1000 | Loss: 0.00001086
Iteration 257/1000 | Loss: 0.00001086
Iteration 258/1000 | Loss: 0.00001086
Iteration 259/1000 | Loss: 0.00001085
Iteration 260/1000 | Loss: 0.00001085
Iteration 261/1000 | Loss: 0.00001084
Iteration 262/1000 | Loss: 0.00001084
Iteration 263/1000 | Loss: 0.00001084
Iteration 264/1000 | Loss: 0.00001083
Iteration 265/1000 | Loss: 0.00001083
Iteration 266/1000 | Loss: 0.00001083
Iteration 267/1000 | Loss: 0.00001083
Iteration 268/1000 | Loss: 0.00001083
Iteration 269/1000 | Loss: 0.00001082
Iteration 270/1000 | Loss: 0.00001082
Iteration 271/1000 | Loss: 0.00001082
Iteration 272/1000 | Loss: 0.00001082
Iteration 273/1000 | Loss: 0.00001081
Iteration 274/1000 | Loss: 0.00001081
Iteration 275/1000 | Loss: 0.00001081
Iteration 276/1000 | Loss: 0.00001081
Iteration 277/1000 | Loss: 0.00001080
Iteration 278/1000 | Loss: 0.00001080
Iteration 279/1000 | Loss: 0.00001080
Iteration 280/1000 | Loss: 0.00001080
Iteration 281/1000 | Loss: 0.00001080
Iteration 282/1000 | Loss: 0.00001079
Iteration 283/1000 | Loss: 0.00001079
Iteration 284/1000 | Loss: 0.00001079
Iteration 285/1000 | Loss: 0.00001079
Iteration 286/1000 | Loss: 0.00001079
Iteration 287/1000 | Loss: 0.00001079
Iteration 288/1000 | Loss: 0.00001079
Iteration 289/1000 | Loss: 0.00001079
Iteration 290/1000 | Loss: 0.00001079
Iteration 291/1000 | Loss: 0.00001079
Iteration 292/1000 | Loss: 0.00001079
Iteration 293/1000 | Loss: 0.00001079
Iteration 294/1000 | Loss: 0.00001079
Iteration 295/1000 | Loss: 0.00001079
Iteration 296/1000 | Loss: 0.00001078
Iteration 297/1000 | Loss: 0.00001078
Iteration 298/1000 | Loss: 0.00001078
Iteration 299/1000 | Loss: 0.00001078
Iteration 300/1000 | Loss: 0.00001078
Iteration 301/1000 | Loss: 0.00001078
Iteration 302/1000 | Loss: 0.00001078
Iteration 303/1000 | Loss: 0.00001078
Iteration 304/1000 | Loss: 0.00001078
Iteration 305/1000 | Loss: 0.00001078
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 305. Stopping optimization.
Last 5 losses: [1.0783356628962792e-05, 1.0783356628962792e-05, 1.0783356628962792e-05, 1.0783356628962792e-05, 1.0783356628962792e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0783356628962792e-05

Optimization complete. Final v2v error: 2.757803201675415 mm

Highest mean error: 3.9750523567199707 mm for frame 78

Lowest mean error: 2.3423383235931396 mm for frame 31

Saving results

Total time: 299.20155334472656
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01012114
Iteration 2/25 | Loss: 0.00255147
Iteration 3/25 | Loss: 0.00225192
Iteration 4/25 | Loss: 0.00221082
Iteration 5/25 | Loss: 0.00212839
Iteration 6/25 | Loss: 0.00201305
Iteration 7/25 | Loss: 0.00190316
Iteration 8/25 | Loss: 0.00195414
Iteration 9/25 | Loss: 0.00186463
Iteration 10/25 | Loss: 0.00178144
Iteration 11/25 | Loss: 0.00171204
Iteration 12/25 | Loss: 0.00171061
Iteration 13/25 | Loss: 0.00171259
Iteration 14/25 | Loss: 0.00171300
Iteration 15/25 | Loss: 0.00169779
Iteration 16/25 | Loss: 0.00169268
Iteration 17/25 | Loss: 0.00169166
Iteration 18/25 | Loss: 0.00169151
Iteration 19/25 | Loss: 0.00169145
Iteration 20/25 | Loss: 0.00169144
Iteration 21/25 | Loss: 0.00169143
Iteration 22/25 | Loss: 0.00169143
Iteration 23/25 | Loss: 0.00169143
Iteration 24/25 | Loss: 0.00169143
Iteration 25/25 | Loss: 0.00169143

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.09595418
Iteration 2/25 | Loss: 0.00636065
Iteration 3/25 | Loss: 0.00636065
Iteration 4/25 | Loss: 0.00636065
Iteration 5/25 | Loss: 0.00636065
Iteration 6/25 | Loss: 0.00636065
Iteration 7/25 | Loss: 0.00636065
Iteration 8/25 | Loss: 0.00636065
Iteration 9/25 | Loss: 0.00636064
Iteration 10/25 | Loss: 0.00636064
Iteration 11/25 | Loss: 0.00636064
Iteration 12/25 | Loss: 0.00636064
Iteration 13/25 | Loss: 0.00636064
Iteration 14/25 | Loss: 0.00636064
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.006360644940286875, 0.006360644940286875, 0.006360644940286875, 0.006360644940286875, 0.006360644940286875]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006360644940286875

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00636064
Iteration 2/1000 | Loss: 0.00044761
Iteration 3/1000 | Loss: 0.00034654
Iteration 4/1000 | Loss: 0.00030376
Iteration 5/1000 | Loss: 0.00027928
Iteration 6/1000 | Loss: 0.00026306
Iteration 7/1000 | Loss: 0.00024932
Iteration 8/1000 | Loss: 0.00024262
Iteration 9/1000 | Loss: 0.00023166
Iteration 10/1000 | Loss: 0.00022309
Iteration 11/1000 | Loss: 0.00021545
Iteration 12/1000 | Loss: 0.00021086
Iteration 13/1000 | Loss: 0.00020742
Iteration 14/1000 | Loss: 0.00020498
Iteration 15/1000 | Loss: 0.00020273
Iteration 16/1000 | Loss: 0.00020193
Iteration 17/1000 | Loss: 0.00020103
Iteration 18/1000 | Loss: 0.00020047
Iteration 19/1000 | Loss: 0.00019971
Iteration 20/1000 | Loss: 0.00019892
Iteration 21/1000 | Loss: 0.00019839
Iteration 22/1000 | Loss: 0.00019798
Iteration 23/1000 | Loss: 0.00019768
Iteration 24/1000 | Loss: 0.00019746
Iteration 25/1000 | Loss: 0.00019730
Iteration 26/1000 | Loss: 0.00019713
Iteration 27/1000 | Loss: 0.00019708
Iteration 28/1000 | Loss: 0.00019705
Iteration 29/1000 | Loss: 0.00019697
Iteration 30/1000 | Loss: 0.00019696
Iteration 31/1000 | Loss: 0.00019696
Iteration 32/1000 | Loss: 0.00019696
Iteration 33/1000 | Loss: 0.00019696
Iteration 34/1000 | Loss: 0.00019696
Iteration 35/1000 | Loss: 0.00019696
Iteration 36/1000 | Loss: 0.00019696
Iteration 37/1000 | Loss: 0.00019696
Iteration 38/1000 | Loss: 0.00019696
Iteration 39/1000 | Loss: 0.00019696
Iteration 40/1000 | Loss: 0.00019696
Iteration 41/1000 | Loss: 0.00019696
Iteration 42/1000 | Loss: 0.00019696
Iteration 43/1000 | Loss: 0.00019694
Iteration 44/1000 | Loss: 0.00019694
Iteration 45/1000 | Loss: 0.00019693
Iteration 46/1000 | Loss: 0.00019693
Iteration 47/1000 | Loss: 0.00019692
Iteration 48/1000 | Loss: 0.00019692
Iteration 49/1000 | Loss: 0.00019692
Iteration 50/1000 | Loss: 0.00019692
Iteration 51/1000 | Loss: 0.00019692
Iteration 52/1000 | Loss: 0.00019692
Iteration 53/1000 | Loss: 0.00019692
Iteration 54/1000 | Loss: 0.00019692
Iteration 55/1000 | Loss: 0.00019692
Iteration 56/1000 | Loss: 0.00019692
Iteration 57/1000 | Loss: 0.00019691
Iteration 58/1000 | Loss: 0.00019691
Iteration 59/1000 | Loss: 0.00019691
Iteration 60/1000 | Loss: 0.00019691
Iteration 61/1000 | Loss: 0.00019691
Iteration 62/1000 | Loss: 0.00019691
Iteration 63/1000 | Loss: 0.00019691
Iteration 64/1000 | Loss: 0.00019691
Iteration 65/1000 | Loss: 0.00019691
Iteration 66/1000 | Loss: 0.00019690
Iteration 67/1000 | Loss: 0.00019690
Iteration 68/1000 | Loss: 0.00019690
Iteration 69/1000 | Loss: 0.00019690
Iteration 70/1000 | Loss: 0.00019690
Iteration 71/1000 | Loss: 0.00019689
Iteration 72/1000 | Loss: 0.00019689
Iteration 73/1000 | Loss: 0.00019689
Iteration 74/1000 | Loss: 0.00019689
Iteration 75/1000 | Loss: 0.00019689
Iteration 76/1000 | Loss: 0.00019689
Iteration 77/1000 | Loss: 0.00019689
Iteration 78/1000 | Loss: 0.00019689
Iteration 79/1000 | Loss: 0.00019689
Iteration 80/1000 | Loss: 0.00019689
Iteration 81/1000 | Loss: 0.00019689
Iteration 82/1000 | Loss: 0.00019689
Iteration 83/1000 | Loss: 0.00019688
Iteration 84/1000 | Loss: 0.00019688
Iteration 85/1000 | Loss: 0.00019688
Iteration 86/1000 | Loss: 0.00019688
Iteration 87/1000 | Loss: 0.00019688
Iteration 88/1000 | Loss: 0.00019688
Iteration 89/1000 | Loss: 0.00019688
Iteration 90/1000 | Loss: 0.00019688
Iteration 91/1000 | Loss: 0.00019688
Iteration 92/1000 | Loss: 0.00019688
Iteration 93/1000 | Loss: 0.00019688
Iteration 94/1000 | Loss: 0.00019688
Iteration 95/1000 | Loss: 0.00019688
Iteration 96/1000 | Loss: 0.00019688
Iteration 97/1000 | Loss: 0.00019688
Iteration 98/1000 | Loss: 0.00019688
Iteration 99/1000 | Loss: 0.00019687
Iteration 100/1000 | Loss: 0.00019687
Iteration 101/1000 | Loss: 0.00019687
Iteration 102/1000 | Loss: 0.00019687
Iteration 103/1000 | Loss: 0.00019687
Iteration 104/1000 | Loss: 0.00019687
Iteration 105/1000 | Loss: 0.00019687
Iteration 106/1000 | Loss: 0.00019687
Iteration 107/1000 | Loss: 0.00019687
Iteration 108/1000 | Loss: 0.00019687
Iteration 109/1000 | Loss: 0.00019687
Iteration 110/1000 | Loss: 0.00019687
Iteration 111/1000 | Loss: 0.00019687
Iteration 112/1000 | Loss: 0.00019687
Iteration 113/1000 | Loss: 0.00019687
Iteration 114/1000 | Loss: 0.00019687
Iteration 115/1000 | Loss: 0.00019687
Iteration 116/1000 | Loss: 0.00019687
Iteration 117/1000 | Loss: 0.00019687
Iteration 118/1000 | Loss: 0.00019686
Iteration 119/1000 | Loss: 0.00019686
Iteration 120/1000 | Loss: 0.00019686
Iteration 121/1000 | Loss: 0.00019686
Iteration 122/1000 | Loss: 0.00019686
Iteration 123/1000 | Loss: 0.00019686
Iteration 124/1000 | Loss: 0.00019686
Iteration 125/1000 | Loss: 0.00019686
Iteration 126/1000 | Loss: 0.00019686
Iteration 127/1000 | Loss: 0.00019686
Iteration 128/1000 | Loss: 0.00019686
Iteration 129/1000 | Loss: 0.00019685
Iteration 130/1000 | Loss: 0.00019685
Iteration 131/1000 | Loss: 0.00019685
Iteration 132/1000 | Loss: 0.00019685
Iteration 133/1000 | Loss: 0.00019685
Iteration 134/1000 | Loss: 0.00019685
Iteration 135/1000 | Loss: 0.00019685
Iteration 136/1000 | Loss: 0.00019685
Iteration 137/1000 | Loss: 0.00019685
Iteration 138/1000 | Loss: 0.00019685
Iteration 139/1000 | Loss: 0.00019685
Iteration 140/1000 | Loss: 0.00019685
Iteration 141/1000 | Loss: 0.00019685
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [0.0001968494470929727, 0.0001968494470929727, 0.0001968494470929727, 0.0001968494470929727, 0.0001968494470929727]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0001968494470929727

Optimization complete. Final v2v error: 7.742520332336426 mm

Highest mean error: 10.0940523147583 mm for frame 84

Lowest mean error: 4.422591686248779 mm for frame 4

Saving results

Total time: 75.12089848518372
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01044870
Iteration 2/25 | Loss: 0.00229637
Iteration 3/25 | Loss: 0.00164836
Iteration 4/25 | Loss: 0.00152008
Iteration 5/25 | Loss: 0.00148528
Iteration 6/25 | Loss: 0.00153277
Iteration 7/25 | Loss: 0.00139869
Iteration 8/25 | Loss: 0.00132586
Iteration 9/25 | Loss: 0.00127623
Iteration 10/25 | Loss: 0.00127476
Iteration 11/25 | Loss: 0.00126504
Iteration 12/25 | Loss: 0.00124740
Iteration 13/25 | Loss: 0.00124172
Iteration 14/25 | Loss: 0.00124042
Iteration 15/25 | Loss: 0.00124040
Iteration 16/25 | Loss: 0.00123923
Iteration 17/25 | Loss: 0.00123765
Iteration 18/25 | Loss: 0.00123640
Iteration 19/25 | Loss: 0.00123597
Iteration 20/25 | Loss: 0.00123248
Iteration 21/25 | Loss: 0.00123201
Iteration 22/25 | Loss: 0.00123180
Iteration 23/25 | Loss: 0.00123180
Iteration 24/25 | Loss: 0.00123180
Iteration 25/25 | Loss: 0.00123180

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.10772467
Iteration 2/25 | Loss: 0.00415040
Iteration 3/25 | Loss: 0.00407490
Iteration 4/25 | Loss: 0.00407490
Iteration 5/25 | Loss: 0.00407490
Iteration 6/25 | Loss: 0.00407490
Iteration 7/25 | Loss: 0.00407490
Iteration 8/25 | Loss: 0.00407490
Iteration 9/25 | Loss: 0.00407490
Iteration 10/25 | Loss: 0.00407490
Iteration 11/25 | Loss: 0.00407490
Iteration 12/25 | Loss: 0.00407490
Iteration 13/25 | Loss: 0.00407490
Iteration 14/25 | Loss: 0.00407490
Iteration 15/25 | Loss: 0.00407490
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.004074899945408106, 0.004074899945408106, 0.004074899945408106, 0.004074899945408106, 0.004074899945408106]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004074899945408106

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00407490
Iteration 2/1000 | Loss: 0.00010053
Iteration 3/1000 | Loss: 0.00010337
Iteration 4/1000 | Loss: 0.00007424
Iteration 5/1000 | Loss: 0.00004334
Iteration 6/1000 | Loss: 0.00005268
Iteration 7/1000 | Loss: 0.00002748
Iteration 8/1000 | Loss: 0.00003445
Iteration 9/1000 | Loss: 0.00003226
Iteration 10/1000 | Loss: 0.00002488
Iteration 11/1000 | Loss: 0.00003591
Iteration 12/1000 | Loss: 0.00002598
Iteration 13/1000 | Loss: 0.00027469
Iteration 14/1000 | Loss: 0.00007203
Iteration 15/1000 | Loss: 0.00020861
Iteration 16/1000 | Loss: 0.00065611
Iteration 17/1000 | Loss: 0.00025646
Iteration 18/1000 | Loss: 0.00150127
Iteration 19/1000 | Loss: 0.00192108
Iteration 20/1000 | Loss: 0.00204193
Iteration 21/1000 | Loss: 0.00203395
Iteration 22/1000 | Loss: 0.00176185
Iteration 23/1000 | Loss: 0.00148445
Iteration 24/1000 | Loss: 0.00012533
Iteration 25/1000 | Loss: 0.00050160
Iteration 26/1000 | Loss: 0.00006819
Iteration 27/1000 | Loss: 0.00016439
Iteration 28/1000 | Loss: 0.00003434
Iteration 29/1000 | Loss: 0.00007908
Iteration 30/1000 | Loss: 0.00002769
Iteration 31/1000 | Loss: 0.00016429
Iteration 32/1000 | Loss: 0.00002065
Iteration 33/1000 | Loss: 0.00001801
Iteration 34/1000 | Loss: 0.00002692
Iteration 35/1000 | Loss: 0.00001565
Iteration 36/1000 | Loss: 0.00003839
Iteration 37/1000 | Loss: 0.00002141
Iteration 38/1000 | Loss: 0.00001472
Iteration 39/1000 | Loss: 0.00001433
Iteration 40/1000 | Loss: 0.00001433
Iteration 41/1000 | Loss: 0.00001412
Iteration 42/1000 | Loss: 0.00003503
Iteration 43/1000 | Loss: 0.00001545
Iteration 44/1000 | Loss: 0.00001642
Iteration 45/1000 | Loss: 0.00003700
Iteration 46/1000 | Loss: 0.00001716
Iteration 47/1000 | Loss: 0.00011236
Iteration 48/1000 | Loss: 0.00001485
Iteration 49/1000 | Loss: 0.00001392
Iteration 50/1000 | Loss: 0.00001551
Iteration 51/1000 | Loss: 0.00001326
Iteration 52/1000 | Loss: 0.00001323
Iteration 53/1000 | Loss: 0.00001323
Iteration 54/1000 | Loss: 0.00001323
Iteration 55/1000 | Loss: 0.00001323
Iteration 56/1000 | Loss: 0.00001323
Iteration 57/1000 | Loss: 0.00001323
Iteration 58/1000 | Loss: 0.00001323
Iteration 59/1000 | Loss: 0.00001323
Iteration 60/1000 | Loss: 0.00001322
Iteration 61/1000 | Loss: 0.00001322
Iteration 62/1000 | Loss: 0.00001321
Iteration 63/1000 | Loss: 0.00001321
Iteration 64/1000 | Loss: 0.00001320
Iteration 65/1000 | Loss: 0.00001319
Iteration 66/1000 | Loss: 0.00001319
Iteration 67/1000 | Loss: 0.00001319
Iteration 68/1000 | Loss: 0.00001318
Iteration 69/1000 | Loss: 0.00001318
Iteration 70/1000 | Loss: 0.00001317
Iteration 71/1000 | Loss: 0.00001317
Iteration 72/1000 | Loss: 0.00001317
Iteration 73/1000 | Loss: 0.00001317
Iteration 74/1000 | Loss: 0.00001323
Iteration 75/1000 | Loss: 0.00001316
Iteration 76/1000 | Loss: 0.00001316
Iteration 77/1000 | Loss: 0.00001315
Iteration 78/1000 | Loss: 0.00001394
Iteration 79/1000 | Loss: 0.00001843
Iteration 80/1000 | Loss: 0.00001314
Iteration 81/1000 | Loss: 0.00001314
Iteration 82/1000 | Loss: 0.00001314
Iteration 83/1000 | Loss: 0.00001314
Iteration 84/1000 | Loss: 0.00001314
Iteration 85/1000 | Loss: 0.00001398
Iteration 86/1000 | Loss: 0.00001324
Iteration 87/1000 | Loss: 0.00001327
Iteration 88/1000 | Loss: 0.00001453
Iteration 89/1000 | Loss: 0.00001313
Iteration 90/1000 | Loss: 0.00001313
Iteration 91/1000 | Loss: 0.00001312
Iteration 92/1000 | Loss: 0.00001312
Iteration 93/1000 | Loss: 0.00001312
Iteration 94/1000 | Loss: 0.00001312
Iteration 95/1000 | Loss: 0.00001312
Iteration 96/1000 | Loss: 0.00001312
Iteration 97/1000 | Loss: 0.00001312
Iteration 98/1000 | Loss: 0.00001312
Iteration 99/1000 | Loss: 0.00001312
Iteration 100/1000 | Loss: 0.00001312
Iteration 101/1000 | Loss: 0.00001312
Iteration 102/1000 | Loss: 0.00001312
Iteration 103/1000 | Loss: 0.00001311
Iteration 104/1000 | Loss: 0.00001311
Iteration 105/1000 | Loss: 0.00001311
Iteration 106/1000 | Loss: 0.00001311
Iteration 107/1000 | Loss: 0.00001378
Iteration 108/1000 | Loss: 0.00001424
Iteration 109/1000 | Loss: 0.00001343
Iteration 110/1000 | Loss: 0.00001308
Iteration 111/1000 | Loss: 0.00001308
Iteration 112/1000 | Loss: 0.00001308
Iteration 113/1000 | Loss: 0.00001308
Iteration 114/1000 | Loss: 0.00001333
Iteration 115/1000 | Loss: 0.00001338
Iteration 116/1000 | Loss: 0.00001723
Iteration 117/1000 | Loss: 0.00001723
Iteration 118/1000 | Loss: 0.00004262
Iteration 119/1000 | Loss: 0.00003224
Iteration 120/1000 | Loss: 0.00001354
Iteration 121/1000 | Loss: 0.00001306
Iteration 122/1000 | Loss: 0.00001306
Iteration 123/1000 | Loss: 0.00001306
Iteration 124/1000 | Loss: 0.00001306
Iteration 125/1000 | Loss: 0.00001323
Iteration 126/1000 | Loss: 0.00001305
Iteration 127/1000 | Loss: 0.00001304
Iteration 128/1000 | Loss: 0.00001304
Iteration 129/1000 | Loss: 0.00001304
Iteration 130/1000 | Loss: 0.00001304
Iteration 131/1000 | Loss: 0.00001304
Iteration 132/1000 | Loss: 0.00001304
Iteration 133/1000 | Loss: 0.00001304
Iteration 134/1000 | Loss: 0.00001304
Iteration 135/1000 | Loss: 0.00001304
Iteration 136/1000 | Loss: 0.00001304
Iteration 137/1000 | Loss: 0.00001304
Iteration 138/1000 | Loss: 0.00001304
Iteration 139/1000 | Loss: 0.00001304
Iteration 140/1000 | Loss: 0.00001304
Iteration 141/1000 | Loss: 0.00001304
Iteration 142/1000 | Loss: 0.00001304
Iteration 143/1000 | Loss: 0.00001304
Iteration 144/1000 | Loss: 0.00001304
Iteration 145/1000 | Loss: 0.00001304
Iteration 146/1000 | Loss: 0.00001304
Iteration 147/1000 | Loss: 0.00001304
Iteration 148/1000 | Loss: 0.00001304
Iteration 149/1000 | Loss: 0.00001304
Iteration 150/1000 | Loss: 0.00001304
Iteration 151/1000 | Loss: 0.00001304
Iteration 152/1000 | Loss: 0.00001304
Iteration 153/1000 | Loss: 0.00001304
Iteration 154/1000 | Loss: 0.00001304
Iteration 155/1000 | Loss: 0.00001304
Iteration 156/1000 | Loss: 0.00001304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.3039411896897946e-05, 1.3039411896897946e-05, 1.3039411896897946e-05, 1.3039411896897946e-05, 1.3039411896897946e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3039411896897946e-05

Optimization complete. Final v2v error: 3.1121952533721924 mm

Highest mean error: 3.664649724960327 mm for frame 198

Lowest mean error: 2.655639410018921 mm for frame 53

Saving results

Total time: 139.5220651626587
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00832590
Iteration 2/25 | Loss: 0.00139776
Iteration 3/25 | Loss: 0.00123042
Iteration 4/25 | Loss: 0.00121497
Iteration 5/25 | Loss: 0.00121224
Iteration 6/25 | Loss: 0.00121197
Iteration 7/25 | Loss: 0.00121197
Iteration 8/25 | Loss: 0.00121197
Iteration 9/25 | Loss: 0.00121197
Iteration 10/25 | Loss: 0.00121197
Iteration 11/25 | Loss: 0.00121197
Iteration 12/25 | Loss: 0.00121197
Iteration 13/25 | Loss: 0.00121197
Iteration 14/25 | Loss: 0.00121197
Iteration 15/25 | Loss: 0.00121197
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.001211968483403325, 0.001211968483403325, 0.001211968483403325, 0.001211968483403325, 0.001211968483403325]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001211968483403325

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.52622461
Iteration 2/25 | Loss: 0.00351457
Iteration 3/25 | Loss: 0.00351454
Iteration 4/25 | Loss: 0.00351453
Iteration 5/25 | Loss: 0.00351453
Iteration 6/25 | Loss: 0.00351453
Iteration 7/25 | Loss: 0.00351453
Iteration 8/25 | Loss: 0.00351453
Iteration 9/25 | Loss: 0.00351453
Iteration 10/25 | Loss: 0.00351453
Iteration 11/25 | Loss: 0.00351453
Iteration 12/25 | Loss: 0.00351453
Iteration 13/25 | Loss: 0.00351453
Iteration 14/25 | Loss: 0.00351453
Iteration 15/25 | Loss: 0.00351453
Iteration 16/25 | Loss: 0.00351453
Iteration 17/25 | Loss: 0.00351453
Iteration 18/25 | Loss: 0.00351453
Iteration 19/25 | Loss: 0.00351453
Iteration 20/25 | Loss: 0.00351453
Iteration 21/25 | Loss: 0.00351453
Iteration 22/25 | Loss: 0.00351453
Iteration 23/25 | Loss: 0.00351453
Iteration 24/25 | Loss: 0.00351453
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0035145319998264313, 0.0035145319998264313, 0.0035145319998264313, 0.0035145319998264313, 0.0035145319998264313]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0035145319998264313

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00351453
Iteration 2/1000 | Loss: 0.00003492
Iteration 3/1000 | Loss: 0.00002235
Iteration 4/1000 | Loss: 0.00002036
Iteration 5/1000 | Loss: 0.00001891
Iteration 6/1000 | Loss: 0.00001808
Iteration 7/1000 | Loss: 0.00001735
Iteration 8/1000 | Loss: 0.00001678
Iteration 9/1000 | Loss: 0.00001636
Iteration 10/1000 | Loss: 0.00001603
Iteration 11/1000 | Loss: 0.00001581
Iteration 12/1000 | Loss: 0.00001563
Iteration 13/1000 | Loss: 0.00001562
Iteration 14/1000 | Loss: 0.00001551
Iteration 15/1000 | Loss: 0.00001551
Iteration 16/1000 | Loss: 0.00001550
Iteration 17/1000 | Loss: 0.00001550
Iteration 18/1000 | Loss: 0.00001549
Iteration 19/1000 | Loss: 0.00001547
Iteration 20/1000 | Loss: 0.00001543
Iteration 21/1000 | Loss: 0.00001541
Iteration 22/1000 | Loss: 0.00001540
Iteration 23/1000 | Loss: 0.00001539
Iteration 24/1000 | Loss: 0.00001539
Iteration 25/1000 | Loss: 0.00001538
Iteration 26/1000 | Loss: 0.00001537
Iteration 27/1000 | Loss: 0.00001536
Iteration 28/1000 | Loss: 0.00001536
Iteration 29/1000 | Loss: 0.00001535
Iteration 30/1000 | Loss: 0.00001535
Iteration 31/1000 | Loss: 0.00001533
Iteration 32/1000 | Loss: 0.00001533
Iteration 33/1000 | Loss: 0.00001533
Iteration 34/1000 | Loss: 0.00001533
Iteration 35/1000 | Loss: 0.00001533
Iteration 36/1000 | Loss: 0.00001533
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 36. Stopping optimization.
Last 5 losses: [1.5330666428781115e-05, 1.5330666428781115e-05, 1.5330666428781115e-05, 1.5330666428781115e-05, 1.5330666428781115e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5330666428781115e-05

Optimization complete. Final v2v error: 3.330610752105713 mm

Highest mean error: 4.342087268829346 mm for frame 195

Lowest mean error: 2.821244716644287 mm for frame 13

Saving results

Total time: 32.46365571022034
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00963082
Iteration 2/25 | Loss: 0.00199860
Iteration 3/25 | Loss: 0.00150179
Iteration 4/25 | Loss: 0.00145541
Iteration 5/25 | Loss: 0.00144044
Iteration 6/25 | Loss: 0.00140948
Iteration 7/25 | Loss: 0.00131669
Iteration 8/25 | Loss: 0.00124221
Iteration 9/25 | Loss: 0.00124615
Iteration 10/25 | Loss: 0.00120994
Iteration 11/25 | Loss: 0.00120540
Iteration 12/25 | Loss: 0.00120294
Iteration 13/25 | Loss: 0.00120089
Iteration 14/25 | Loss: 0.00120018
Iteration 15/25 | Loss: 0.00119945
Iteration 16/25 | Loss: 0.00119939
Iteration 17/25 | Loss: 0.00119865
Iteration 18/25 | Loss: 0.00120158
Iteration 19/25 | Loss: 0.00120079
Iteration 20/25 | Loss: 0.00119918
Iteration 21/25 | Loss: 0.00119897
Iteration 22/25 | Loss: 0.00120314
Iteration 23/25 | Loss: 0.00120033
Iteration 24/25 | Loss: 0.00119951
Iteration 25/25 | Loss: 0.00119740

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.20655394
Iteration 2/25 | Loss: 0.00367605
Iteration 3/25 | Loss: 0.00348143
Iteration 4/25 | Loss: 0.00348143
Iteration 5/25 | Loss: 0.00348143
Iteration 6/25 | Loss: 0.00348143
Iteration 7/25 | Loss: 0.00348143
Iteration 8/25 | Loss: 0.00348143
Iteration 9/25 | Loss: 0.00348143
Iteration 10/25 | Loss: 0.00348143
Iteration 11/25 | Loss: 0.00348143
Iteration 12/25 | Loss: 0.00348143
Iteration 13/25 | Loss: 0.00348143
Iteration 14/25 | Loss: 0.00348143
Iteration 15/25 | Loss: 0.00348143
Iteration 16/25 | Loss: 0.00348143
Iteration 17/25 | Loss: 0.00348143
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.003481425577774644, 0.003481425577774644, 0.003481425577774644, 0.003481425577774644, 0.003481425577774644]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003481425577774644

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00348143
Iteration 2/1000 | Loss: 0.00005431
Iteration 3/1000 | Loss: 0.00011613
Iteration 4/1000 | Loss: 0.00004202
Iteration 5/1000 | Loss: 0.00002383
Iteration 6/1000 | Loss: 0.00003728
Iteration 7/1000 | Loss: 0.00003387
Iteration 8/1000 | Loss: 0.00021726
Iteration 9/1000 | Loss: 0.00004035
Iteration 10/1000 | Loss: 0.00004473
Iteration 11/1000 | Loss: 0.00003399
Iteration 12/1000 | Loss: 0.00002414
Iteration 13/1000 | Loss: 0.00002938
Iteration 14/1000 | Loss: 0.00002414
Iteration 15/1000 | Loss: 0.00002046
Iteration 16/1000 | Loss: 0.00013778
Iteration 17/1000 | Loss: 0.00004688
Iteration 18/1000 | Loss: 0.00009154
Iteration 19/1000 | Loss: 0.00008255
Iteration 20/1000 | Loss: 0.00017793
Iteration 21/1000 | Loss: 0.00044294
Iteration 22/1000 | Loss: 0.00003427
Iteration 23/1000 | Loss: 0.00005236
Iteration 24/1000 | Loss: 0.00014479
Iteration 25/1000 | Loss: 0.00018847
Iteration 26/1000 | Loss: 0.00012485
Iteration 27/1000 | Loss: 0.00002853
Iteration 28/1000 | Loss: 0.00012553
Iteration 29/1000 | Loss: 0.00005466
Iteration 30/1000 | Loss: 0.00005231
Iteration 31/1000 | Loss: 0.00004547
Iteration 32/1000 | Loss: 0.00002051
Iteration 33/1000 | Loss: 0.00004020
Iteration 34/1000 | Loss: 0.00005404
Iteration 35/1000 | Loss: 0.00004261
Iteration 36/1000 | Loss: 0.00003785
Iteration 37/1000 | Loss: 0.00014394
Iteration 38/1000 | Loss: 0.00005085
Iteration 39/1000 | Loss: 0.00012036
Iteration 40/1000 | Loss: 0.00014345
Iteration 41/1000 | Loss: 0.00005339
Iteration 42/1000 | Loss: 0.00027013
Iteration 43/1000 | Loss: 0.00003678
Iteration 44/1000 | Loss: 0.00013065
Iteration 45/1000 | Loss: 0.00001836
Iteration 46/1000 | Loss: 0.00001634
Iteration 47/1000 | Loss: 0.00015047
Iteration 48/1000 | Loss: 0.00010021
Iteration 49/1000 | Loss: 0.00001493
Iteration 50/1000 | Loss: 0.00007809
Iteration 51/1000 | Loss: 0.00002583
Iteration 52/1000 | Loss: 0.00001396
Iteration 53/1000 | Loss: 0.00001359
Iteration 54/1000 | Loss: 0.00017339
Iteration 55/1000 | Loss: 0.00001604
Iteration 56/1000 | Loss: 0.00019982
Iteration 57/1000 | Loss: 0.00021983
Iteration 58/1000 | Loss: 0.00054601
Iteration 59/1000 | Loss: 0.00003473
Iteration 60/1000 | Loss: 0.00017425
Iteration 61/1000 | Loss: 0.00007596
Iteration 62/1000 | Loss: 0.00001922
Iteration 63/1000 | Loss: 0.00002362
Iteration 64/1000 | Loss: 0.00016417
Iteration 65/1000 | Loss: 0.00012850
Iteration 66/1000 | Loss: 0.00020070
Iteration 67/1000 | Loss: 0.00010358
Iteration 68/1000 | Loss: 0.00002257
Iteration 69/1000 | Loss: 0.00001535
Iteration 70/1000 | Loss: 0.00001458
Iteration 71/1000 | Loss: 0.00001411
Iteration 72/1000 | Loss: 0.00002056
Iteration 73/1000 | Loss: 0.00011847
Iteration 74/1000 | Loss: 0.00001954
Iteration 75/1000 | Loss: 0.00001467
Iteration 76/1000 | Loss: 0.00001279
Iteration 77/1000 | Loss: 0.00001225
Iteration 78/1000 | Loss: 0.00001216
Iteration 79/1000 | Loss: 0.00014360
Iteration 80/1000 | Loss: 0.00002288
Iteration 81/1000 | Loss: 0.00001412
Iteration 82/1000 | Loss: 0.00001238
Iteration 83/1000 | Loss: 0.00001195
Iteration 84/1000 | Loss: 0.00001181
Iteration 85/1000 | Loss: 0.00001167
Iteration 86/1000 | Loss: 0.00001162
Iteration 87/1000 | Loss: 0.00001161
Iteration 88/1000 | Loss: 0.00001161
Iteration 89/1000 | Loss: 0.00001146
Iteration 90/1000 | Loss: 0.00001145
Iteration 91/1000 | Loss: 0.00001144
Iteration 92/1000 | Loss: 0.00001144
Iteration 93/1000 | Loss: 0.00001140
Iteration 94/1000 | Loss: 0.00001139
Iteration 95/1000 | Loss: 0.00001138
Iteration 96/1000 | Loss: 0.00001138
Iteration 97/1000 | Loss: 0.00001137
Iteration 98/1000 | Loss: 0.00001136
Iteration 99/1000 | Loss: 0.00001133
Iteration 100/1000 | Loss: 0.00001133
Iteration 101/1000 | Loss: 0.00001133
Iteration 102/1000 | Loss: 0.00001133
Iteration 103/1000 | Loss: 0.00001133
Iteration 104/1000 | Loss: 0.00001133
Iteration 105/1000 | Loss: 0.00001133
Iteration 106/1000 | Loss: 0.00001133
Iteration 107/1000 | Loss: 0.00001132
Iteration 108/1000 | Loss: 0.00001132
Iteration 109/1000 | Loss: 0.00001132
Iteration 110/1000 | Loss: 0.00001132
Iteration 111/1000 | Loss: 0.00001132
Iteration 112/1000 | Loss: 0.00001129
Iteration 113/1000 | Loss: 0.00001129
Iteration 114/1000 | Loss: 0.00001128
Iteration 115/1000 | Loss: 0.00001127
Iteration 116/1000 | Loss: 0.00001127
Iteration 117/1000 | Loss: 0.00001127
Iteration 118/1000 | Loss: 0.00001126
Iteration 119/1000 | Loss: 0.00001126
Iteration 120/1000 | Loss: 0.00001122
Iteration 121/1000 | Loss: 0.00001122
Iteration 122/1000 | Loss: 0.00001122
Iteration 123/1000 | Loss: 0.00001122
Iteration 124/1000 | Loss: 0.00001121
Iteration 125/1000 | Loss: 0.00001121
Iteration 126/1000 | Loss: 0.00001121
Iteration 127/1000 | Loss: 0.00001121
Iteration 128/1000 | Loss: 0.00001121
Iteration 129/1000 | Loss: 0.00001121
Iteration 130/1000 | Loss: 0.00001121
Iteration 131/1000 | Loss: 0.00001121
Iteration 132/1000 | Loss: 0.00001121
Iteration 133/1000 | Loss: 0.00001120
Iteration 134/1000 | Loss: 0.00001120
Iteration 135/1000 | Loss: 0.00001120
Iteration 136/1000 | Loss: 0.00001120
Iteration 137/1000 | Loss: 0.00001120
Iteration 138/1000 | Loss: 0.00001120
Iteration 139/1000 | Loss: 0.00001120
Iteration 140/1000 | Loss: 0.00001120
Iteration 141/1000 | Loss: 0.00001120
Iteration 142/1000 | Loss: 0.00001119
Iteration 143/1000 | Loss: 0.00001119
Iteration 144/1000 | Loss: 0.00001119
Iteration 145/1000 | Loss: 0.00001119
Iteration 146/1000 | Loss: 0.00001119
Iteration 147/1000 | Loss: 0.00001119
Iteration 148/1000 | Loss: 0.00001119
Iteration 149/1000 | Loss: 0.00001119
Iteration 150/1000 | Loss: 0.00001119
Iteration 151/1000 | Loss: 0.00001118
Iteration 152/1000 | Loss: 0.00001118
Iteration 153/1000 | Loss: 0.00001118
Iteration 154/1000 | Loss: 0.00001118
Iteration 155/1000 | Loss: 0.00001118
Iteration 156/1000 | Loss: 0.00001118
Iteration 157/1000 | Loss: 0.00001118
Iteration 158/1000 | Loss: 0.00001118
Iteration 159/1000 | Loss: 0.00001118
Iteration 160/1000 | Loss: 0.00001118
Iteration 161/1000 | Loss: 0.00001118
Iteration 162/1000 | Loss: 0.00001118
Iteration 163/1000 | Loss: 0.00001118
Iteration 164/1000 | Loss: 0.00001117
Iteration 165/1000 | Loss: 0.00001117
Iteration 166/1000 | Loss: 0.00001117
Iteration 167/1000 | Loss: 0.00001117
Iteration 168/1000 | Loss: 0.00001117
Iteration 169/1000 | Loss: 0.00001117
Iteration 170/1000 | Loss: 0.00001117
Iteration 171/1000 | Loss: 0.00001117
Iteration 172/1000 | Loss: 0.00001116
Iteration 173/1000 | Loss: 0.00001116
Iteration 174/1000 | Loss: 0.00001116
Iteration 175/1000 | Loss: 0.00001116
Iteration 176/1000 | Loss: 0.00001116
Iteration 177/1000 | Loss: 0.00001116
Iteration 178/1000 | Loss: 0.00001116
Iteration 179/1000 | Loss: 0.00001116
Iteration 180/1000 | Loss: 0.00001116
Iteration 181/1000 | Loss: 0.00001116
Iteration 182/1000 | Loss: 0.00001116
Iteration 183/1000 | Loss: 0.00001116
Iteration 184/1000 | Loss: 0.00001116
Iteration 185/1000 | Loss: 0.00001116
Iteration 186/1000 | Loss: 0.00001115
Iteration 187/1000 | Loss: 0.00001115
Iteration 188/1000 | Loss: 0.00001115
Iteration 189/1000 | Loss: 0.00001115
Iteration 190/1000 | Loss: 0.00001115
Iteration 191/1000 | Loss: 0.00001115
Iteration 192/1000 | Loss: 0.00001115
Iteration 193/1000 | Loss: 0.00001115
Iteration 194/1000 | Loss: 0.00001115
Iteration 195/1000 | Loss: 0.00001115
Iteration 196/1000 | Loss: 0.00001115
Iteration 197/1000 | Loss: 0.00001115
Iteration 198/1000 | Loss: 0.00001115
Iteration 199/1000 | Loss: 0.00001115
Iteration 200/1000 | Loss: 0.00001115
Iteration 201/1000 | Loss: 0.00001115
Iteration 202/1000 | Loss: 0.00001115
Iteration 203/1000 | Loss: 0.00001115
Iteration 204/1000 | Loss: 0.00001115
Iteration 205/1000 | Loss: 0.00001115
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 205. Stopping optimization.
Last 5 losses: [1.1152485967613757e-05, 1.1152485967613757e-05, 1.1152485967613757e-05, 1.1152485967613757e-05, 1.1152485967613757e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1152485967613757e-05

Optimization complete. Final v2v error: 2.832580089569092 mm

Highest mean error: 4.3991498947143555 mm for frame 23

Lowest mean error: 2.491380453109741 mm for frame 61

Saving results

Total time: 174.5552990436554
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00847996
Iteration 2/25 | Loss: 0.00146521
Iteration 3/25 | Loss: 0.00122310
Iteration 4/25 | Loss: 0.00120211
Iteration 5/25 | Loss: 0.00119936
Iteration 6/25 | Loss: 0.00119903
Iteration 7/25 | Loss: 0.00119903
Iteration 8/25 | Loss: 0.00119903
Iteration 9/25 | Loss: 0.00119903
Iteration 10/25 | Loss: 0.00119903
Iteration 11/25 | Loss: 0.00119903
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0011990315979346633, 0.0011990315979346633, 0.0011990315979346633, 0.0011990315979346633, 0.0011990315979346633]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011990315979346633

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.12152016
Iteration 2/25 | Loss: 0.00333097
Iteration 3/25 | Loss: 0.00333096
Iteration 4/25 | Loss: 0.00333096
Iteration 5/25 | Loss: 0.00333096
Iteration 6/25 | Loss: 0.00333096
Iteration 7/25 | Loss: 0.00333096
Iteration 8/25 | Loss: 0.00333096
Iteration 9/25 | Loss: 0.00333096
Iteration 10/25 | Loss: 0.00333096
Iteration 11/25 | Loss: 0.00333096
Iteration 12/25 | Loss: 0.00333096
Iteration 13/25 | Loss: 0.00333096
Iteration 14/25 | Loss: 0.00333096
Iteration 15/25 | Loss: 0.00333096
Iteration 16/25 | Loss: 0.00333096
Iteration 17/25 | Loss: 0.00333096
Iteration 18/25 | Loss: 0.00333096
Iteration 19/25 | Loss: 0.00333096
Iteration 20/25 | Loss: 0.00333096
Iteration 21/25 | Loss: 0.00333096
Iteration 22/25 | Loss: 0.00333096
Iteration 23/25 | Loss: 0.00333096
Iteration 24/25 | Loss: 0.00333096
Iteration 25/25 | Loss: 0.00333096

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00333096
Iteration 2/1000 | Loss: 0.00002724
Iteration 3/1000 | Loss: 0.00001628
Iteration 4/1000 | Loss: 0.00001432
Iteration 5/1000 | Loss: 0.00001300
Iteration 6/1000 | Loss: 0.00001213
Iteration 7/1000 | Loss: 0.00001162
Iteration 8/1000 | Loss: 0.00001103
Iteration 9/1000 | Loss: 0.00001068
Iteration 10/1000 | Loss: 0.00001044
Iteration 11/1000 | Loss: 0.00001013
Iteration 12/1000 | Loss: 0.00001005
Iteration 13/1000 | Loss: 0.00001000
Iteration 14/1000 | Loss: 0.00000999
Iteration 15/1000 | Loss: 0.00000999
Iteration 16/1000 | Loss: 0.00000998
Iteration 17/1000 | Loss: 0.00000997
Iteration 18/1000 | Loss: 0.00000986
Iteration 19/1000 | Loss: 0.00000977
Iteration 20/1000 | Loss: 0.00000963
Iteration 21/1000 | Loss: 0.00000954
Iteration 22/1000 | Loss: 0.00000949
Iteration 23/1000 | Loss: 0.00000949
Iteration 24/1000 | Loss: 0.00000949
Iteration 25/1000 | Loss: 0.00000949
Iteration 26/1000 | Loss: 0.00000949
Iteration 27/1000 | Loss: 0.00000949
Iteration 28/1000 | Loss: 0.00000949
Iteration 29/1000 | Loss: 0.00000948
Iteration 30/1000 | Loss: 0.00000948
Iteration 31/1000 | Loss: 0.00000948
Iteration 32/1000 | Loss: 0.00000948
Iteration 33/1000 | Loss: 0.00000948
Iteration 34/1000 | Loss: 0.00000947
Iteration 35/1000 | Loss: 0.00000945
Iteration 36/1000 | Loss: 0.00000945
Iteration 37/1000 | Loss: 0.00000945
Iteration 38/1000 | Loss: 0.00000944
Iteration 39/1000 | Loss: 0.00000944
Iteration 40/1000 | Loss: 0.00000944
Iteration 41/1000 | Loss: 0.00000944
Iteration 42/1000 | Loss: 0.00000944
Iteration 43/1000 | Loss: 0.00000943
Iteration 44/1000 | Loss: 0.00000943
Iteration 45/1000 | Loss: 0.00000942
Iteration 46/1000 | Loss: 0.00000941
Iteration 47/1000 | Loss: 0.00000941
Iteration 48/1000 | Loss: 0.00000940
Iteration 49/1000 | Loss: 0.00000940
Iteration 50/1000 | Loss: 0.00000940
Iteration 51/1000 | Loss: 0.00000940
Iteration 52/1000 | Loss: 0.00000940
Iteration 53/1000 | Loss: 0.00000940
Iteration 54/1000 | Loss: 0.00000939
Iteration 55/1000 | Loss: 0.00000938
Iteration 56/1000 | Loss: 0.00000937
Iteration 57/1000 | Loss: 0.00000937
Iteration 58/1000 | Loss: 0.00000937
Iteration 59/1000 | Loss: 0.00000936
Iteration 60/1000 | Loss: 0.00000936
Iteration 61/1000 | Loss: 0.00000936
Iteration 62/1000 | Loss: 0.00000936
Iteration 63/1000 | Loss: 0.00000936
Iteration 64/1000 | Loss: 0.00000936
Iteration 65/1000 | Loss: 0.00000936
Iteration 66/1000 | Loss: 0.00000935
Iteration 67/1000 | Loss: 0.00000935
Iteration 68/1000 | Loss: 0.00000934
Iteration 69/1000 | Loss: 0.00000934
Iteration 70/1000 | Loss: 0.00000934
Iteration 71/1000 | Loss: 0.00000934
Iteration 72/1000 | Loss: 0.00000934
Iteration 73/1000 | Loss: 0.00000934
Iteration 74/1000 | Loss: 0.00000934
Iteration 75/1000 | Loss: 0.00000934
Iteration 76/1000 | Loss: 0.00000934
Iteration 77/1000 | Loss: 0.00000933
Iteration 78/1000 | Loss: 0.00000933
Iteration 79/1000 | Loss: 0.00000933
Iteration 80/1000 | Loss: 0.00000932
Iteration 81/1000 | Loss: 0.00000931
Iteration 82/1000 | Loss: 0.00000931
Iteration 83/1000 | Loss: 0.00000931
Iteration 84/1000 | Loss: 0.00000931
Iteration 85/1000 | Loss: 0.00000931
Iteration 86/1000 | Loss: 0.00000931
Iteration 87/1000 | Loss: 0.00000931
Iteration 88/1000 | Loss: 0.00000930
Iteration 89/1000 | Loss: 0.00000930
Iteration 90/1000 | Loss: 0.00000930
Iteration 91/1000 | Loss: 0.00000930
Iteration 92/1000 | Loss: 0.00000929
Iteration 93/1000 | Loss: 0.00000929
Iteration 94/1000 | Loss: 0.00000929
Iteration 95/1000 | Loss: 0.00000929
Iteration 96/1000 | Loss: 0.00000929
Iteration 97/1000 | Loss: 0.00000929
Iteration 98/1000 | Loss: 0.00000928
Iteration 99/1000 | Loss: 0.00000928
Iteration 100/1000 | Loss: 0.00000928
Iteration 101/1000 | Loss: 0.00000928
Iteration 102/1000 | Loss: 0.00000928
Iteration 103/1000 | Loss: 0.00000928
Iteration 104/1000 | Loss: 0.00000928
Iteration 105/1000 | Loss: 0.00000928
Iteration 106/1000 | Loss: 0.00000928
Iteration 107/1000 | Loss: 0.00000928
Iteration 108/1000 | Loss: 0.00000928
Iteration 109/1000 | Loss: 0.00000928
Iteration 110/1000 | Loss: 0.00000928
Iteration 111/1000 | Loss: 0.00000928
Iteration 112/1000 | Loss: 0.00000928
Iteration 113/1000 | Loss: 0.00000928
Iteration 114/1000 | Loss: 0.00000928
Iteration 115/1000 | Loss: 0.00000928
Iteration 116/1000 | Loss: 0.00000928
Iteration 117/1000 | Loss: 0.00000928
Iteration 118/1000 | Loss: 0.00000928
Iteration 119/1000 | Loss: 0.00000928
Iteration 120/1000 | Loss: 0.00000928
Iteration 121/1000 | Loss: 0.00000928
Iteration 122/1000 | Loss: 0.00000928
Iteration 123/1000 | Loss: 0.00000928
Iteration 124/1000 | Loss: 0.00000928
Iteration 125/1000 | Loss: 0.00000928
Iteration 126/1000 | Loss: 0.00000928
Iteration 127/1000 | Loss: 0.00000928
Iteration 128/1000 | Loss: 0.00000928
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [9.276182026951574e-06, 9.276182026951574e-06, 9.276182026951574e-06, 9.276182026951574e-06, 9.276182026951574e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.276182026951574e-06

Optimization complete. Final v2v error: 2.5736355781555176 mm

Highest mean error: 2.8352317810058594 mm for frame 64

Lowest mean error: 2.4238057136535645 mm for frame 12

Saving results

Total time: 35.90871262550354
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00952339
Iteration 2/25 | Loss: 0.00166504
Iteration 3/25 | Loss: 0.00152934
Iteration 4/25 | Loss: 0.00135625
Iteration 5/25 | Loss: 0.00130524
Iteration 6/25 | Loss: 0.00128755
Iteration 7/25 | Loss: 0.00126321
Iteration 8/25 | Loss: 0.00126266
Iteration 9/25 | Loss: 0.00125811
Iteration 10/25 | Loss: 0.00125766
Iteration 11/25 | Loss: 0.00125707
Iteration 12/25 | Loss: 0.00125970
Iteration 13/25 | Loss: 0.00125438
Iteration 14/25 | Loss: 0.00125269
Iteration 15/25 | Loss: 0.00125204
Iteration 16/25 | Loss: 0.00125162
Iteration 17/25 | Loss: 0.00125129
Iteration 18/25 | Loss: 0.00125126
Iteration 19/25 | Loss: 0.00125126
Iteration 20/25 | Loss: 0.00125126
Iteration 21/25 | Loss: 0.00125125
Iteration 22/25 | Loss: 0.00125125
Iteration 23/25 | Loss: 0.00125125
Iteration 24/25 | Loss: 0.00125125
Iteration 25/25 | Loss: 0.00125125

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26521528
Iteration 2/25 | Loss: 0.00359843
Iteration 3/25 | Loss: 0.00359842
Iteration 4/25 | Loss: 0.00359842
Iteration 5/25 | Loss: 0.00359842
Iteration 6/25 | Loss: 0.00359842
Iteration 7/25 | Loss: 0.00359841
Iteration 8/25 | Loss: 0.00359841
Iteration 9/25 | Loss: 0.00359841
Iteration 10/25 | Loss: 0.00359841
Iteration 11/25 | Loss: 0.00359841
Iteration 12/25 | Loss: 0.00359841
Iteration 13/25 | Loss: 0.00359841
Iteration 14/25 | Loss: 0.00359841
Iteration 15/25 | Loss: 0.00359841
Iteration 16/25 | Loss: 0.00359841
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0035984136629849672, 0.0035984136629849672, 0.0035984136629849672, 0.0035984136629849672, 0.0035984136629849672]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0035984136629849672

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00359841
Iteration 2/1000 | Loss: 0.00003496
Iteration 3/1000 | Loss: 0.00007616
Iteration 4/1000 | Loss: 0.00002020
Iteration 5/1000 | Loss: 0.00009035
Iteration 6/1000 | Loss: 0.00001775
Iteration 7/1000 | Loss: 0.00001705
Iteration 8/1000 | Loss: 0.00001649
Iteration 9/1000 | Loss: 0.00011418
Iteration 10/1000 | Loss: 0.00001621
Iteration 11/1000 | Loss: 0.00001576
Iteration 12/1000 | Loss: 0.00001544
Iteration 13/1000 | Loss: 0.00001515
Iteration 14/1000 | Loss: 0.00001507
Iteration 15/1000 | Loss: 0.00001501
Iteration 16/1000 | Loss: 0.00001501
Iteration 17/1000 | Loss: 0.00001481
Iteration 18/1000 | Loss: 0.00001467
Iteration 19/1000 | Loss: 0.00001466
Iteration 20/1000 | Loss: 0.00001466
Iteration 21/1000 | Loss: 0.00001465
Iteration 22/1000 | Loss: 0.00001455
Iteration 23/1000 | Loss: 0.00001453
Iteration 24/1000 | Loss: 0.00001452
Iteration 25/1000 | Loss: 0.00001452
Iteration 26/1000 | Loss: 0.00001451
Iteration 27/1000 | Loss: 0.00001451
Iteration 28/1000 | Loss: 0.00001451
Iteration 29/1000 | Loss: 0.00001451
Iteration 30/1000 | Loss: 0.00001450
Iteration 31/1000 | Loss: 0.00001450
Iteration 32/1000 | Loss: 0.00001449
Iteration 33/1000 | Loss: 0.00001448
Iteration 34/1000 | Loss: 0.00001448
Iteration 35/1000 | Loss: 0.00001448
Iteration 36/1000 | Loss: 0.00001447
Iteration 37/1000 | Loss: 0.00001447
Iteration 38/1000 | Loss: 0.00001447
Iteration 39/1000 | Loss: 0.00001446
Iteration 40/1000 | Loss: 0.00001446
Iteration 41/1000 | Loss: 0.00001445
Iteration 42/1000 | Loss: 0.00001445
Iteration 43/1000 | Loss: 0.00001444
Iteration 44/1000 | Loss: 0.00001443
Iteration 45/1000 | Loss: 0.00001443
Iteration 46/1000 | Loss: 0.00001442
Iteration 47/1000 | Loss: 0.00001442
Iteration 48/1000 | Loss: 0.00001442
Iteration 49/1000 | Loss: 0.00001441
Iteration 50/1000 | Loss: 0.00001441
Iteration 51/1000 | Loss: 0.00001441
Iteration 52/1000 | Loss: 0.00001441
Iteration 53/1000 | Loss: 0.00001440
Iteration 54/1000 | Loss: 0.00001440
Iteration 55/1000 | Loss: 0.00001439
Iteration 56/1000 | Loss: 0.00001439
Iteration 57/1000 | Loss: 0.00001439
Iteration 58/1000 | Loss: 0.00001439
Iteration 59/1000 | Loss: 0.00001439
Iteration 60/1000 | Loss: 0.00001439
Iteration 61/1000 | Loss: 0.00001439
Iteration 62/1000 | Loss: 0.00001439
Iteration 63/1000 | Loss: 0.00001438
Iteration 64/1000 | Loss: 0.00001438
Iteration 65/1000 | Loss: 0.00001438
Iteration 66/1000 | Loss: 0.00001438
Iteration 67/1000 | Loss: 0.00001438
Iteration 68/1000 | Loss: 0.00001437
Iteration 69/1000 | Loss: 0.00001437
Iteration 70/1000 | Loss: 0.00001437
Iteration 71/1000 | Loss: 0.00001437
Iteration 72/1000 | Loss: 0.00001436
Iteration 73/1000 | Loss: 0.00001436
Iteration 74/1000 | Loss: 0.00001436
Iteration 75/1000 | Loss: 0.00001436
Iteration 76/1000 | Loss: 0.00001436
Iteration 77/1000 | Loss: 0.00001436
Iteration 78/1000 | Loss: 0.00001435
Iteration 79/1000 | Loss: 0.00001435
Iteration 80/1000 | Loss: 0.00001435
Iteration 81/1000 | Loss: 0.00001435
Iteration 82/1000 | Loss: 0.00001434
Iteration 83/1000 | Loss: 0.00001434
Iteration 84/1000 | Loss: 0.00001434
Iteration 85/1000 | Loss: 0.00001434
Iteration 86/1000 | Loss: 0.00001433
Iteration 87/1000 | Loss: 0.00001433
Iteration 88/1000 | Loss: 0.00001433
Iteration 89/1000 | Loss: 0.00001433
Iteration 90/1000 | Loss: 0.00001433
Iteration 91/1000 | Loss: 0.00001432
Iteration 92/1000 | Loss: 0.00001432
Iteration 93/1000 | Loss: 0.00001432
Iteration 94/1000 | Loss: 0.00001432
Iteration 95/1000 | Loss: 0.00001432
Iteration 96/1000 | Loss: 0.00001432
Iteration 97/1000 | Loss: 0.00001432
Iteration 98/1000 | Loss: 0.00001432
Iteration 99/1000 | Loss: 0.00001432
Iteration 100/1000 | Loss: 0.00001432
Iteration 101/1000 | Loss: 0.00001431
Iteration 102/1000 | Loss: 0.00001431
Iteration 103/1000 | Loss: 0.00001431
Iteration 104/1000 | Loss: 0.00001431
Iteration 105/1000 | Loss: 0.00001431
Iteration 106/1000 | Loss: 0.00001431
Iteration 107/1000 | Loss: 0.00001431
Iteration 108/1000 | Loss: 0.00001430
Iteration 109/1000 | Loss: 0.00001430
Iteration 110/1000 | Loss: 0.00001430
Iteration 111/1000 | Loss: 0.00001430
Iteration 112/1000 | Loss: 0.00001430
Iteration 113/1000 | Loss: 0.00001430
Iteration 114/1000 | Loss: 0.00001430
Iteration 115/1000 | Loss: 0.00001430
Iteration 116/1000 | Loss: 0.00001430
Iteration 117/1000 | Loss: 0.00001430
Iteration 118/1000 | Loss: 0.00001429
Iteration 119/1000 | Loss: 0.00001429
Iteration 120/1000 | Loss: 0.00001429
Iteration 121/1000 | Loss: 0.00001429
Iteration 122/1000 | Loss: 0.00001429
Iteration 123/1000 | Loss: 0.00001429
Iteration 124/1000 | Loss: 0.00001429
Iteration 125/1000 | Loss: 0.00001429
Iteration 126/1000 | Loss: 0.00001429
Iteration 127/1000 | Loss: 0.00001428
Iteration 128/1000 | Loss: 0.00001428
Iteration 129/1000 | Loss: 0.00001428
Iteration 130/1000 | Loss: 0.00001428
Iteration 131/1000 | Loss: 0.00001427
Iteration 132/1000 | Loss: 0.00001427
Iteration 133/1000 | Loss: 0.00001427
Iteration 134/1000 | Loss: 0.00001426
Iteration 135/1000 | Loss: 0.00001426
Iteration 136/1000 | Loss: 0.00001426
Iteration 137/1000 | Loss: 0.00001426
Iteration 138/1000 | Loss: 0.00001426
Iteration 139/1000 | Loss: 0.00001426
Iteration 140/1000 | Loss: 0.00001426
Iteration 141/1000 | Loss: 0.00001426
Iteration 142/1000 | Loss: 0.00001426
Iteration 143/1000 | Loss: 0.00001426
Iteration 144/1000 | Loss: 0.00001426
Iteration 145/1000 | Loss: 0.00001425
Iteration 146/1000 | Loss: 0.00001425
Iteration 147/1000 | Loss: 0.00001425
Iteration 148/1000 | Loss: 0.00001425
Iteration 149/1000 | Loss: 0.00001425
Iteration 150/1000 | Loss: 0.00001425
Iteration 151/1000 | Loss: 0.00001425
Iteration 152/1000 | Loss: 0.00001425
Iteration 153/1000 | Loss: 0.00001425
Iteration 154/1000 | Loss: 0.00001425
Iteration 155/1000 | Loss: 0.00001425
Iteration 156/1000 | Loss: 0.00001425
Iteration 157/1000 | Loss: 0.00001424
Iteration 158/1000 | Loss: 0.00001424
Iteration 159/1000 | Loss: 0.00001424
Iteration 160/1000 | Loss: 0.00001424
Iteration 161/1000 | Loss: 0.00001424
Iteration 162/1000 | Loss: 0.00001424
Iteration 163/1000 | Loss: 0.00001424
Iteration 164/1000 | Loss: 0.00001424
Iteration 165/1000 | Loss: 0.00001424
Iteration 166/1000 | Loss: 0.00001423
Iteration 167/1000 | Loss: 0.00001423
Iteration 168/1000 | Loss: 0.00001423
Iteration 169/1000 | Loss: 0.00001423
Iteration 170/1000 | Loss: 0.00001423
Iteration 171/1000 | Loss: 0.00001423
Iteration 172/1000 | Loss: 0.00001423
Iteration 173/1000 | Loss: 0.00001423
Iteration 174/1000 | Loss: 0.00001422
Iteration 175/1000 | Loss: 0.00001422
Iteration 176/1000 | Loss: 0.00001422
Iteration 177/1000 | Loss: 0.00001422
Iteration 178/1000 | Loss: 0.00001422
Iteration 179/1000 | Loss: 0.00001422
Iteration 180/1000 | Loss: 0.00001422
Iteration 181/1000 | Loss: 0.00001422
Iteration 182/1000 | Loss: 0.00001422
Iteration 183/1000 | Loss: 0.00001422
Iteration 184/1000 | Loss: 0.00001422
Iteration 185/1000 | Loss: 0.00001422
Iteration 186/1000 | Loss: 0.00001422
Iteration 187/1000 | Loss: 0.00001422
Iteration 188/1000 | Loss: 0.00001422
Iteration 189/1000 | Loss: 0.00001422
Iteration 190/1000 | Loss: 0.00001422
Iteration 191/1000 | Loss: 0.00001422
Iteration 192/1000 | Loss: 0.00001422
Iteration 193/1000 | Loss: 0.00001422
Iteration 194/1000 | Loss: 0.00001422
Iteration 195/1000 | Loss: 0.00001422
Iteration 196/1000 | Loss: 0.00001422
Iteration 197/1000 | Loss: 0.00001422
Iteration 198/1000 | Loss: 0.00001422
Iteration 199/1000 | Loss: 0.00001422
Iteration 200/1000 | Loss: 0.00001422
Iteration 201/1000 | Loss: 0.00001422
Iteration 202/1000 | Loss: 0.00001422
Iteration 203/1000 | Loss: 0.00001422
Iteration 204/1000 | Loss: 0.00001422
Iteration 205/1000 | Loss: 0.00001422
Iteration 206/1000 | Loss: 0.00001422
Iteration 207/1000 | Loss: 0.00001422
Iteration 208/1000 | Loss: 0.00001422
Iteration 209/1000 | Loss: 0.00001422
Iteration 210/1000 | Loss: 0.00001422
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 210. Stopping optimization.
Last 5 losses: [1.4222532627172768e-05, 1.4222532627172768e-05, 1.4222532627172768e-05, 1.4222532627172768e-05, 1.4222532627172768e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4222532627172768e-05

Optimization complete. Final v2v error: 3.248718738555908 mm

Highest mean error: 3.906040906906128 mm for frame 38

Lowest mean error: 2.526653289794922 mm for frame 200

Saving results

Total time: 67.34704971313477
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00372780
Iteration 2/25 | Loss: 0.00131284
Iteration 3/25 | Loss: 0.00119841
Iteration 4/25 | Loss: 0.00117668
Iteration 5/25 | Loss: 0.00117347
Iteration 6/25 | Loss: 0.00117236
Iteration 7/25 | Loss: 0.00117236
Iteration 8/25 | Loss: 0.00117236
Iteration 9/25 | Loss: 0.00117236
Iteration 10/25 | Loss: 0.00117236
Iteration 11/25 | Loss: 0.00117236
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0011723629431799054, 0.0011723629431799054, 0.0011723629431799054, 0.0011723629431799054, 0.0011723629431799054]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011723629431799054

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.08191073
Iteration 2/25 | Loss: 0.00429767
Iteration 3/25 | Loss: 0.00429767
Iteration 4/25 | Loss: 0.00429767
Iteration 5/25 | Loss: 0.00429767
Iteration 6/25 | Loss: 0.00429767
Iteration 7/25 | Loss: 0.00429767
Iteration 8/25 | Loss: 0.00429767
Iteration 9/25 | Loss: 0.00429767
Iteration 10/25 | Loss: 0.00429766
Iteration 11/25 | Loss: 0.00429766
Iteration 12/25 | Loss: 0.00429766
Iteration 13/25 | Loss: 0.00429766
Iteration 14/25 | Loss: 0.00429766
Iteration 15/25 | Loss: 0.00429766
Iteration 16/25 | Loss: 0.00429766
Iteration 17/25 | Loss: 0.00429766
Iteration 18/25 | Loss: 0.00429766
Iteration 19/25 | Loss: 0.00429766
Iteration 20/25 | Loss: 0.00429766
Iteration 21/25 | Loss: 0.00429766
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.004297663923352957, 0.004297663923352957, 0.004297663923352957, 0.004297663923352957, 0.004297663923352957]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004297663923352957

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00429766
Iteration 2/1000 | Loss: 0.00003262
Iteration 3/1000 | Loss: 0.00001907
Iteration 4/1000 | Loss: 0.00001530
Iteration 5/1000 | Loss: 0.00001391
Iteration 6/1000 | Loss: 0.00001278
Iteration 7/1000 | Loss: 0.00001201
Iteration 8/1000 | Loss: 0.00001195
Iteration 9/1000 | Loss: 0.00001161
Iteration 10/1000 | Loss: 0.00001132
Iteration 11/1000 | Loss: 0.00001115
Iteration 12/1000 | Loss: 0.00001108
Iteration 13/1000 | Loss: 0.00001098
Iteration 14/1000 | Loss: 0.00001090
Iteration 15/1000 | Loss: 0.00001089
Iteration 16/1000 | Loss: 0.00001089
Iteration 17/1000 | Loss: 0.00001088
Iteration 18/1000 | Loss: 0.00001086
Iteration 19/1000 | Loss: 0.00001085
Iteration 20/1000 | Loss: 0.00001084
Iteration 21/1000 | Loss: 0.00001076
Iteration 22/1000 | Loss: 0.00001074
Iteration 23/1000 | Loss: 0.00001073
Iteration 24/1000 | Loss: 0.00001072
Iteration 25/1000 | Loss: 0.00001071
Iteration 26/1000 | Loss: 0.00001071
Iteration 27/1000 | Loss: 0.00001070
Iteration 28/1000 | Loss: 0.00001069
Iteration 29/1000 | Loss: 0.00001068
Iteration 30/1000 | Loss: 0.00001066
Iteration 31/1000 | Loss: 0.00001066
Iteration 32/1000 | Loss: 0.00001064
Iteration 33/1000 | Loss: 0.00001063
Iteration 34/1000 | Loss: 0.00001062
Iteration 35/1000 | Loss: 0.00001061
Iteration 36/1000 | Loss: 0.00001060
Iteration 37/1000 | Loss: 0.00001060
Iteration 38/1000 | Loss: 0.00001059
Iteration 39/1000 | Loss: 0.00001059
Iteration 40/1000 | Loss: 0.00001058
Iteration 41/1000 | Loss: 0.00001058
Iteration 42/1000 | Loss: 0.00001058
Iteration 43/1000 | Loss: 0.00001058
Iteration 44/1000 | Loss: 0.00001057
Iteration 45/1000 | Loss: 0.00001056
Iteration 46/1000 | Loss: 0.00001056
Iteration 47/1000 | Loss: 0.00001056
Iteration 48/1000 | Loss: 0.00001056
Iteration 49/1000 | Loss: 0.00001055
Iteration 50/1000 | Loss: 0.00001055
Iteration 51/1000 | Loss: 0.00001055
Iteration 52/1000 | Loss: 0.00001055
Iteration 53/1000 | Loss: 0.00001055
Iteration 54/1000 | Loss: 0.00001054
Iteration 55/1000 | Loss: 0.00001054
Iteration 56/1000 | Loss: 0.00001054
Iteration 57/1000 | Loss: 0.00001053
Iteration 58/1000 | Loss: 0.00001053
Iteration 59/1000 | Loss: 0.00001053
Iteration 60/1000 | Loss: 0.00001053
Iteration 61/1000 | Loss: 0.00001053
Iteration 62/1000 | Loss: 0.00001053
Iteration 63/1000 | Loss: 0.00001053
Iteration 64/1000 | Loss: 0.00001053
Iteration 65/1000 | Loss: 0.00001053
Iteration 66/1000 | Loss: 0.00001053
Iteration 67/1000 | Loss: 0.00001053
Iteration 68/1000 | Loss: 0.00001052
Iteration 69/1000 | Loss: 0.00001052
Iteration 70/1000 | Loss: 0.00001052
Iteration 71/1000 | Loss: 0.00001052
Iteration 72/1000 | Loss: 0.00001052
Iteration 73/1000 | Loss: 0.00001051
Iteration 74/1000 | Loss: 0.00001051
Iteration 75/1000 | Loss: 0.00001051
Iteration 76/1000 | Loss: 0.00001051
Iteration 77/1000 | Loss: 0.00001051
Iteration 78/1000 | Loss: 0.00001051
Iteration 79/1000 | Loss: 0.00001051
Iteration 80/1000 | Loss: 0.00001051
Iteration 81/1000 | Loss: 0.00001051
Iteration 82/1000 | Loss: 0.00001051
Iteration 83/1000 | Loss: 0.00001051
Iteration 84/1000 | Loss: 0.00001051
Iteration 85/1000 | Loss: 0.00001051
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [1.0507845217944123e-05, 1.0507845217944123e-05, 1.0507845217944123e-05, 1.0507845217944123e-05, 1.0507845217944123e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0507845217944123e-05

Optimization complete. Final v2v error: 2.701735496520996 mm

Highest mean error: 2.938633680343628 mm for frame 78

Lowest mean error: 2.47776198387146 mm for frame 53

Saving results

Total time: 32.3876097202301
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00767592
Iteration 2/25 | Loss: 0.00129529
Iteration 3/25 | Loss: 0.00117705
Iteration 4/25 | Loss: 0.00116580
Iteration 5/25 | Loss: 0.00116491
Iteration 6/25 | Loss: 0.00116491
Iteration 7/25 | Loss: 0.00116491
Iteration 8/25 | Loss: 0.00116491
Iteration 9/25 | Loss: 0.00116491
Iteration 10/25 | Loss: 0.00116491
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0011649098014459014, 0.0011649098014459014, 0.0011649098014459014, 0.0011649098014459014, 0.0011649098014459014]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011649098014459014

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.07564640
Iteration 2/25 | Loss: 0.00402912
Iteration 3/25 | Loss: 0.00402910
Iteration 4/25 | Loss: 0.00402910
Iteration 5/25 | Loss: 0.00402910
Iteration 6/25 | Loss: 0.00402910
Iteration 7/25 | Loss: 0.00402910
Iteration 8/25 | Loss: 0.00402910
Iteration 9/25 | Loss: 0.00402910
Iteration 10/25 | Loss: 0.00402910
Iteration 11/25 | Loss: 0.00402910
Iteration 12/25 | Loss: 0.00402910
Iteration 13/25 | Loss: 0.00402910
Iteration 14/25 | Loss: 0.00402910
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.004029097501188517, 0.004029097501188517, 0.004029097501188517, 0.004029097501188517, 0.004029097501188517]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004029097501188517

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00402910
Iteration 2/1000 | Loss: 0.00002273
Iteration 3/1000 | Loss: 0.00001614
Iteration 4/1000 | Loss: 0.00001477
Iteration 5/1000 | Loss: 0.00001302
Iteration 6/1000 | Loss: 0.00001200
Iteration 7/1000 | Loss: 0.00001150
Iteration 8/1000 | Loss: 0.00001109
Iteration 9/1000 | Loss: 0.00001076
Iteration 10/1000 | Loss: 0.00001060
Iteration 11/1000 | Loss: 0.00001056
Iteration 12/1000 | Loss: 0.00001046
Iteration 13/1000 | Loss: 0.00001042
Iteration 14/1000 | Loss: 0.00001020
Iteration 15/1000 | Loss: 0.00000998
Iteration 16/1000 | Loss: 0.00000973
Iteration 17/1000 | Loss: 0.00000970
Iteration 18/1000 | Loss: 0.00000964
Iteration 19/1000 | Loss: 0.00000961
Iteration 20/1000 | Loss: 0.00000960
Iteration 21/1000 | Loss: 0.00000960
Iteration 22/1000 | Loss: 0.00000960
Iteration 23/1000 | Loss: 0.00000959
Iteration 24/1000 | Loss: 0.00000957
Iteration 25/1000 | Loss: 0.00000956
Iteration 26/1000 | Loss: 0.00000956
Iteration 27/1000 | Loss: 0.00000955
Iteration 28/1000 | Loss: 0.00000954
Iteration 29/1000 | Loss: 0.00000953
Iteration 30/1000 | Loss: 0.00000952
Iteration 31/1000 | Loss: 0.00000951
Iteration 32/1000 | Loss: 0.00000950
Iteration 33/1000 | Loss: 0.00000949
Iteration 34/1000 | Loss: 0.00000949
Iteration 35/1000 | Loss: 0.00000948
Iteration 36/1000 | Loss: 0.00000948
Iteration 37/1000 | Loss: 0.00000947
Iteration 38/1000 | Loss: 0.00000947
Iteration 39/1000 | Loss: 0.00000947
Iteration 40/1000 | Loss: 0.00000946
Iteration 41/1000 | Loss: 0.00000946
Iteration 42/1000 | Loss: 0.00000946
Iteration 43/1000 | Loss: 0.00000946
Iteration 44/1000 | Loss: 0.00000946
Iteration 45/1000 | Loss: 0.00000944
Iteration 46/1000 | Loss: 0.00000942
Iteration 47/1000 | Loss: 0.00000942
Iteration 48/1000 | Loss: 0.00000942
Iteration 49/1000 | Loss: 0.00000942
Iteration 50/1000 | Loss: 0.00000942
Iteration 51/1000 | Loss: 0.00000942
Iteration 52/1000 | Loss: 0.00000941
Iteration 53/1000 | Loss: 0.00000939
Iteration 54/1000 | Loss: 0.00000939
Iteration 55/1000 | Loss: 0.00000939
Iteration 56/1000 | Loss: 0.00000939
Iteration 57/1000 | Loss: 0.00000939
Iteration 58/1000 | Loss: 0.00000939
Iteration 59/1000 | Loss: 0.00000939
Iteration 60/1000 | Loss: 0.00000939
Iteration 61/1000 | Loss: 0.00000939
Iteration 62/1000 | Loss: 0.00000939
Iteration 63/1000 | Loss: 0.00000938
Iteration 64/1000 | Loss: 0.00000938
Iteration 65/1000 | Loss: 0.00000938
Iteration 66/1000 | Loss: 0.00000937
Iteration 67/1000 | Loss: 0.00000937
Iteration 68/1000 | Loss: 0.00000936
Iteration 69/1000 | Loss: 0.00000936
Iteration 70/1000 | Loss: 0.00000935
Iteration 71/1000 | Loss: 0.00000935
Iteration 72/1000 | Loss: 0.00000934
Iteration 73/1000 | Loss: 0.00000934
Iteration 74/1000 | Loss: 0.00000933
Iteration 75/1000 | Loss: 0.00000933
Iteration 76/1000 | Loss: 0.00000933
Iteration 77/1000 | Loss: 0.00000932
Iteration 78/1000 | Loss: 0.00000932
Iteration 79/1000 | Loss: 0.00000931
Iteration 80/1000 | Loss: 0.00000931
Iteration 81/1000 | Loss: 0.00000930
Iteration 82/1000 | Loss: 0.00000930
Iteration 83/1000 | Loss: 0.00000929
Iteration 84/1000 | Loss: 0.00000928
Iteration 85/1000 | Loss: 0.00000928
Iteration 86/1000 | Loss: 0.00000928
Iteration 87/1000 | Loss: 0.00000927
Iteration 88/1000 | Loss: 0.00000927
Iteration 89/1000 | Loss: 0.00000926
Iteration 90/1000 | Loss: 0.00000926
Iteration 91/1000 | Loss: 0.00000925
Iteration 92/1000 | Loss: 0.00000925
Iteration 93/1000 | Loss: 0.00000925
Iteration 94/1000 | Loss: 0.00000925
Iteration 95/1000 | Loss: 0.00000925
Iteration 96/1000 | Loss: 0.00000925
Iteration 97/1000 | Loss: 0.00000924
Iteration 98/1000 | Loss: 0.00000924
Iteration 99/1000 | Loss: 0.00000924
Iteration 100/1000 | Loss: 0.00000924
Iteration 101/1000 | Loss: 0.00000924
Iteration 102/1000 | Loss: 0.00000924
Iteration 103/1000 | Loss: 0.00000923
Iteration 104/1000 | Loss: 0.00000923
Iteration 105/1000 | Loss: 0.00000923
Iteration 106/1000 | Loss: 0.00000922
Iteration 107/1000 | Loss: 0.00000922
Iteration 108/1000 | Loss: 0.00000922
Iteration 109/1000 | Loss: 0.00000922
Iteration 110/1000 | Loss: 0.00000922
Iteration 111/1000 | Loss: 0.00000922
Iteration 112/1000 | Loss: 0.00000921
Iteration 113/1000 | Loss: 0.00000921
Iteration 114/1000 | Loss: 0.00000921
Iteration 115/1000 | Loss: 0.00000920
Iteration 116/1000 | Loss: 0.00000920
Iteration 117/1000 | Loss: 0.00000919
Iteration 118/1000 | Loss: 0.00000919
Iteration 119/1000 | Loss: 0.00000919
Iteration 120/1000 | Loss: 0.00000919
Iteration 121/1000 | Loss: 0.00000919
Iteration 122/1000 | Loss: 0.00000919
Iteration 123/1000 | Loss: 0.00000919
Iteration 124/1000 | Loss: 0.00000919
Iteration 125/1000 | Loss: 0.00000919
Iteration 126/1000 | Loss: 0.00000918
Iteration 127/1000 | Loss: 0.00000918
Iteration 128/1000 | Loss: 0.00000918
Iteration 129/1000 | Loss: 0.00000918
Iteration 130/1000 | Loss: 0.00000918
Iteration 131/1000 | Loss: 0.00000918
Iteration 132/1000 | Loss: 0.00000918
Iteration 133/1000 | Loss: 0.00000918
Iteration 134/1000 | Loss: 0.00000918
Iteration 135/1000 | Loss: 0.00000918
Iteration 136/1000 | Loss: 0.00000918
Iteration 137/1000 | Loss: 0.00000918
Iteration 138/1000 | Loss: 0.00000918
Iteration 139/1000 | Loss: 0.00000918
Iteration 140/1000 | Loss: 0.00000918
Iteration 141/1000 | Loss: 0.00000918
Iteration 142/1000 | Loss: 0.00000918
Iteration 143/1000 | Loss: 0.00000918
Iteration 144/1000 | Loss: 0.00000918
Iteration 145/1000 | Loss: 0.00000918
Iteration 146/1000 | Loss: 0.00000918
Iteration 147/1000 | Loss: 0.00000918
Iteration 148/1000 | Loss: 0.00000918
Iteration 149/1000 | Loss: 0.00000918
Iteration 150/1000 | Loss: 0.00000918
Iteration 151/1000 | Loss: 0.00000918
Iteration 152/1000 | Loss: 0.00000918
Iteration 153/1000 | Loss: 0.00000918
Iteration 154/1000 | Loss: 0.00000918
Iteration 155/1000 | Loss: 0.00000918
Iteration 156/1000 | Loss: 0.00000918
Iteration 157/1000 | Loss: 0.00000918
Iteration 158/1000 | Loss: 0.00000918
Iteration 159/1000 | Loss: 0.00000918
Iteration 160/1000 | Loss: 0.00000918
Iteration 161/1000 | Loss: 0.00000918
Iteration 162/1000 | Loss: 0.00000918
Iteration 163/1000 | Loss: 0.00000918
Iteration 164/1000 | Loss: 0.00000918
Iteration 165/1000 | Loss: 0.00000918
Iteration 166/1000 | Loss: 0.00000918
Iteration 167/1000 | Loss: 0.00000918
Iteration 168/1000 | Loss: 0.00000918
Iteration 169/1000 | Loss: 0.00000918
Iteration 170/1000 | Loss: 0.00000918
Iteration 171/1000 | Loss: 0.00000918
Iteration 172/1000 | Loss: 0.00000918
Iteration 173/1000 | Loss: 0.00000918
Iteration 174/1000 | Loss: 0.00000918
Iteration 175/1000 | Loss: 0.00000918
Iteration 176/1000 | Loss: 0.00000918
Iteration 177/1000 | Loss: 0.00000918
Iteration 178/1000 | Loss: 0.00000918
Iteration 179/1000 | Loss: 0.00000918
Iteration 180/1000 | Loss: 0.00000918
Iteration 181/1000 | Loss: 0.00000918
Iteration 182/1000 | Loss: 0.00000918
Iteration 183/1000 | Loss: 0.00000918
Iteration 184/1000 | Loss: 0.00000918
Iteration 185/1000 | Loss: 0.00000918
Iteration 186/1000 | Loss: 0.00000918
Iteration 187/1000 | Loss: 0.00000918
Iteration 188/1000 | Loss: 0.00000918
Iteration 189/1000 | Loss: 0.00000918
Iteration 190/1000 | Loss: 0.00000918
Iteration 191/1000 | Loss: 0.00000918
Iteration 192/1000 | Loss: 0.00000918
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 192. Stopping optimization.
Last 5 losses: [9.179144399240613e-06, 9.179144399240613e-06, 9.179144399240613e-06, 9.179144399240613e-06, 9.179144399240613e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.179144399240613e-06

Optimization complete. Final v2v error: 2.610522747039795 mm

Highest mean error: 3.1086161136627197 mm for frame 156

Lowest mean error: 2.363570213317871 mm for frame 6

Saving results

Total time: 41.67993521690369
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01008016
Iteration 2/25 | Loss: 0.00208468
Iteration 3/25 | Loss: 0.00173096
Iteration 4/25 | Loss: 0.00151593
Iteration 5/25 | Loss: 0.00147004
Iteration 6/25 | Loss: 0.00143389
Iteration 7/25 | Loss: 0.00139862
Iteration 8/25 | Loss: 0.00138488
Iteration 9/25 | Loss: 0.00137349
Iteration 10/25 | Loss: 0.00136945
Iteration 11/25 | Loss: 0.00136402
Iteration 12/25 | Loss: 0.00135383
Iteration 13/25 | Loss: 0.00134876
Iteration 14/25 | Loss: 0.00135025
Iteration 15/25 | Loss: 0.00134592
Iteration 16/25 | Loss: 0.00134331
Iteration 17/25 | Loss: 0.00134144
Iteration 18/25 | Loss: 0.00134148
Iteration 19/25 | Loss: 0.00134311
Iteration 20/25 | Loss: 0.00134092
Iteration 21/25 | Loss: 0.00134150
Iteration 22/25 | Loss: 0.00134124
Iteration 23/25 | Loss: 0.00134343
Iteration 24/25 | Loss: 0.00134181
Iteration 25/25 | Loss: 0.00133740

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.95965213
Iteration 2/25 | Loss: 0.00338757
Iteration 3/25 | Loss: 0.00338756
Iteration 4/25 | Loss: 0.00338756
Iteration 5/25 | Loss: 0.00338756
Iteration 6/25 | Loss: 0.00338756
Iteration 7/25 | Loss: 0.00338755
Iteration 8/25 | Loss: 0.00338755
Iteration 9/25 | Loss: 0.00338755
Iteration 10/25 | Loss: 0.00338755
Iteration 11/25 | Loss: 0.00338755
Iteration 12/25 | Loss: 0.00338755
Iteration 13/25 | Loss: 0.00338755
Iteration 14/25 | Loss: 0.00338755
Iteration 15/25 | Loss: 0.00338755
Iteration 16/25 | Loss: 0.00338755
Iteration 17/25 | Loss: 0.00338755
Iteration 18/25 | Loss: 0.00338755
Iteration 19/25 | Loss: 0.00338755
Iteration 20/25 | Loss: 0.00338755
Iteration 21/25 | Loss: 0.00338755
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0033875524532049894, 0.0033875524532049894, 0.0033875524532049894, 0.0033875524532049894, 0.0033875524532049894]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0033875524532049894

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00338755
Iteration 2/1000 | Loss: 0.00020745
Iteration 3/1000 | Loss: 0.00008732
Iteration 4/1000 | Loss: 0.00012940
Iteration 5/1000 | Loss: 0.00013973
Iteration 6/1000 | Loss: 0.00014626
Iteration 7/1000 | Loss: 0.00015803
Iteration 8/1000 | Loss: 0.00014483
Iteration 9/1000 | Loss: 0.00015157
Iteration 10/1000 | Loss: 0.00012746
Iteration 11/1000 | Loss: 0.00006707
Iteration 12/1000 | Loss: 0.00008127
Iteration 13/1000 | Loss: 0.00010217
Iteration 14/1000 | Loss: 0.00010292
Iteration 15/1000 | Loss: 0.00018295
Iteration 16/1000 | Loss: 0.00017176
Iteration 17/1000 | Loss: 0.00015615
Iteration 18/1000 | Loss: 0.00008321
Iteration 19/1000 | Loss: 0.00008139
Iteration 20/1000 | Loss: 0.00006126
Iteration 21/1000 | Loss: 0.00013518
Iteration 22/1000 | Loss: 0.00012224
Iteration 23/1000 | Loss: 0.00017076
Iteration 24/1000 | Loss: 0.00011660
Iteration 25/1000 | Loss: 0.00007795
Iteration 26/1000 | Loss: 0.00007239
Iteration 27/1000 | Loss: 0.00008745
Iteration 28/1000 | Loss: 0.00010902
Iteration 29/1000 | Loss: 0.00010442
Iteration 30/1000 | Loss: 0.00010241
Iteration 31/1000 | Loss: 0.00007873
Iteration 32/1000 | Loss: 0.00005437
Iteration 33/1000 | Loss: 0.00004725
Iteration 34/1000 | Loss: 0.00013379
Iteration 35/1000 | Loss: 0.00011618
Iteration 36/1000 | Loss: 0.00014653
Iteration 37/1000 | Loss: 0.00009597
Iteration 38/1000 | Loss: 0.00011364
Iteration 39/1000 | Loss: 0.00009930
Iteration 40/1000 | Loss: 0.00010290
Iteration 41/1000 | Loss: 0.00007785
Iteration 42/1000 | Loss: 0.00007969
Iteration 43/1000 | Loss: 0.00021580
Iteration 44/1000 | Loss: 0.00009719
Iteration 45/1000 | Loss: 0.00010750
Iteration 46/1000 | Loss: 0.00007902
Iteration 47/1000 | Loss: 0.00011470
Iteration 48/1000 | Loss: 0.00008100
Iteration 49/1000 | Loss: 0.00012923
Iteration 50/1000 | Loss: 0.00013234
Iteration 51/1000 | Loss: 0.00006710
Iteration 52/1000 | Loss: 0.00008887
Iteration 53/1000 | Loss: 0.00007217
Iteration 54/1000 | Loss: 0.00007351
Iteration 55/1000 | Loss: 0.00011797
Iteration 56/1000 | Loss: 0.00008901
Iteration 57/1000 | Loss: 0.00012450
Iteration 58/1000 | Loss: 0.00004133
Iteration 59/1000 | Loss: 0.00003194
Iteration 60/1000 | Loss: 0.00002947
Iteration 61/1000 | Loss: 0.00002825
Iteration 62/1000 | Loss: 0.00002701
Iteration 63/1000 | Loss: 0.00002540
Iteration 64/1000 | Loss: 0.00002498
Iteration 65/1000 | Loss: 0.00002461
Iteration 66/1000 | Loss: 0.00002436
Iteration 67/1000 | Loss: 0.00002406
Iteration 68/1000 | Loss: 0.00002387
Iteration 69/1000 | Loss: 0.00002373
Iteration 70/1000 | Loss: 0.00002366
Iteration 71/1000 | Loss: 0.00002361
Iteration 72/1000 | Loss: 0.00002353
Iteration 73/1000 | Loss: 0.00002351
Iteration 74/1000 | Loss: 0.00002344
Iteration 75/1000 | Loss: 0.00002344
Iteration 76/1000 | Loss: 0.00002343
Iteration 77/1000 | Loss: 0.00002340
Iteration 78/1000 | Loss: 0.00002340
Iteration 79/1000 | Loss: 0.00002336
Iteration 80/1000 | Loss: 0.00002336
Iteration 81/1000 | Loss: 0.00002336
Iteration 82/1000 | Loss: 0.00002335
Iteration 83/1000 | Loss: 0.00002335
Iteration 84/1000 | Loss: 0.00002335
Iteration 85/1000 | Loss: 0.00002334
Iteration 86/1000 | Loss: 0.00002334
Iteration 87/1000 | Loss: 0.00002334
Iteration 88/1000 | Loss: 0.00002334
Iteration 89/1000 | Loss: 0.00002333
Iteration 90/1000 | Loss: 0.00002333
Iteration 91/1000 | Loss: 0.00002333
Iteration 92/1000 | Loss: 0.00002333
Iteration 93/1000 | Loss: 0.00002333
Iteration 94/1000 | Loss: 0.00002332
Iteration 95/1000 | Loss: 0.00002332
Iteration 96/1000 | Loss: 0.00002332
Iteration 97/1000 | Loss: 0.00002331
Iteration 98/1000 | Loss: 0.00002331
Iteration 99/1000 | Loss: 0.00002325
Iteration 100/1000 | Loss: 0.00002319
Iteration 101/1000 | Loss: 0.00002318
Iteration 102/1000 | Loss: 0.00002318
Iteration 103/1000 | Loss: 0.00002318
Iteration 104/1000 | Loss: 0.00002318
Iteration 105/1000 | Loss: 0.00002317
Iteration 106/1000 | Loss: 0.00002317
Iteration 107/1000 | Loss: 0.00002316
Iteration 108/1000 | Loss: 0.00002315
Iteration 109/1000 | Loss: 0.00002315
Iteration 110/1000 | Loss: 0.00002314
Iteration 111/1000 | Loss: 0.00002314
Iteration 112/1000 | Loss: 0.00002313
Iteration 113/1000 | Loss: 0.00002313
Iteration 114/1000 | Loss: 0.00002313
Iteration 115/1000 | Loss: 0.00002312
Iteration 116/1000 | Loss: 0.00002312
Iteration 117/1000 | Loss: 0.00002310
Iteration 118/1000 | Loss: 0.00002309
Iteration 119/1000 | Loss: 0.00002309
Iteration 120/1000 | Loss: 0.00002309
Iteration 121/1000 | Loss: 0.00002308
Iteration 122/1000 | Loss: 0.00002308
Iteration 123/1000 | Loss: 0.00002308
Iteration 124/1000 | Loss: 0.00002307
Iteration 125/1000 | Loss: 0.00002307
Iteration 126/1000 | Loss: 0.00002307
Iteration 127/1000 | Loss: 0.00002307
Iteration 128/1000 | Loss: 0.00002306
Iteration 129/1000 | Loss: 0.00002306
Iteration 130/1000 | Loss: 0.00002306
Iteration 131/1000 | Loss: 0.00002306
Iteration 132/1000 | Loss: 0.00002306
Iteration 133/1000 | Loss: 0.00002306
Iteration 134/1000 | Loss: 0.00002305
Iteration 135/1000 | Loss: 0.00002305
Iteration 136/1000 | Loss: 0.00002305
Iteration 137/1000 | Loss: 0.00002305
Iteration 138/1000 | Loss: 0.00002305
Iteration 139/1000 | Loss: 0.00002305
Iteration 140/1000 | Loss: 0.00002305
Iteration 141/1000 | Loss: 0.00002305
Iteration 142/1000 | Loss: 0.00002305
Iteration 143/1000 | Loss: 0.00002305
Iteration 144/1000 | Loss: 0.00002305
Iteration 145/1000 | Loss: 0.00002304
Iteration 146/1000 | Loss: 0.00002304
Iteration 147/1000 | Loss: 0.00002304
Iteration 148/1000 | Loss: 0.00002304
Iteration 149/1000 | Loss: 0.00002304
Iteration 150/1000 | Loss: 0.00002304
Iteration 151/1000 | Loss: 0.00002304
Iteration 152/1000 | Loss: 0.00002304
Iteration 153/1000 | Loss: 0.00002304
Iteration 154/1000 | Loss: 0.00002304
Iteration 155/1000 | Loss: 0.00002304
Iteration 156/1000 | Loss: 0.00002304
Iteration 157/1000 | Loss: 0.00002304
Iteration 158/1000 | Loss: 0.00002304
Iteration 159/1000 | Loss: 0.00002304
Iteration 160/1000 | Loss: 0.00002304
Iteration 161/1000 | Loss: 0.00002304
Iteration 162/1000 | Loss: 0.00002304
Iteration 163/1000 | Loss: 0.00002304
Iteration 164/1000 | Loss: 0.00002304
Iteration 165/1000 | Loss: 0.00002304
Iteration 166/1000 | Loss: 0.00002304
Iteration 167/1000 | Loss: 0.00002304
Iteration 168/1000 | Loss: 0.00002304
Iteration 169/1000 | Loss: 0.00002304
Iteration 170/1000 | Loss: 0.00002304
Iteration 171/1000 | Loss: 0.00002304
Iteration 172/1000 | Loss: 0.00002304
Iteration 173/1000 | Loss: 0.00002304
Iteration 174/1000 | Loss: 0.00002304
Iteration 175/1000 | Loss: 0.00002304
Iteration 176/1000 | Loss: 0.00002304
Iteration 177/1000 | Loss: 0.00002304
Iteration 178/1000 | Loss: 0.00002304
Iteration 179/1000 | Loss: 0.00002304
Iteration 180/1000 | Loss: 0.00002304
Iteration 181/1000 | Loss: 0.00002304
Iteration 182/1000 | Loss: 0.00002304
Iteration 183/1000 | Loss: 0.00002304
Iteration 184/1000 | Loss: 0.00002304
Iteration 185/1000 | Loss: 0.00002304
Iteration 186/1000 | Loss: 0.00002304
Iteration 187/1000 | Loss: 0.00002304
Iteration 188/1000 | Loss: 0.00002304
Iteration 189/1000 | Loss: 0.00002304
Iteration 190/1000 | Loss: 0.00002304
Iteration 191/1000 | Loss: 0.00002304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 191. Stopping optimization.
Last 5 losses: [2.3044131012284197e-05, 2.3044131012284197e-05, 2.3044131012284197e-05, 2.3044131012284197e-05, 2.3044131012284197e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3044131012284197e-05

Optimization complete. Final v2v error: 3.865417003631592 mm

Highest mean error: 5.078977584838867 mm for frame 131

Lowest mean error: 2.9436397552490234 mm for frame 6

Saving results

Total time: 157.7133104801178
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00783282
Iteration 2/25 | Loss: 0.00145460
Iteration 3/25 | Loss: 0.00126705
Iteration 4/25 | Loss: 0.00122054
Iteration 5/25 | Loss: 0.00120223
Iteration 6/25 | Loss: 0.00119955
Iteration 7/25 | Loss: 0.00119939
Iteration 8/25 | Loss: 0.00119750
Iteration 9/25 | Loss: 0.00119573
Iteration 10/25 | Loss: 0.00119555
Iteration 11/25 | Loss: 0.00119553
Iteration 12/25 | Loss: 0.00119553
Iteration 13/25 | Loss: 0.00119553
Iteration 14/25 | Loss: 0.00119553
Iteration 15/25 | Loss: 0.00119553
Iteration 16/25 | Loss: 0.00119552
Iteration 17/25 | Loss: 0.00119552
Iteration 18/25 | Loss: 0.00119552
Iteration 19/25 | Loss: 0.00119552
Iteration 20/25 | Loss: 0.00119552
Iteration 21/25 | Loss: 0.00119552
Iteration 22/25 | Loss: 0.00119552
Iteration 23/25 | Loss: 0.00119552
Iteration 24/25 | Loss: 0.00119552
Iteration 25/25 | Loss: 0.00119552

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.13641500
Iteration 2/25 | Loss: 0.00647378
Iteration 3/25 | Loss: 0.00647375
Iteration 4/25 | Loss: 0.00647375
Iteration 5/25 | Loss: 0.00647375
Iteration 6/25 | Loss: 0.00647375
Iteration 7/25 | Loss: 0.00647375
Iteration 8/25 | Loss: 0.00647375
Iteration 9/25 | Loss: 0.00647375
Iteration 10/25 | Loss: 0.00647375
Iteration 11/25 | Loss: 0.00647375
Iteration 12/25 | Loss: 0.00647375
Iteration 13/25 | Loss: 0.00647375
Iteration 14/25 | Loss: 0.00647375
Iteration 15/25 | Loss: 0.00647375
Iteration 16/25 | Loss: 0.00647375
Iteration 17/25 | Loss: 0.00647375
Iteration 18/25 | Loss: 0.00647375
Iteration 19/25 | Loss: 0.00647375
Iteration 20/25 | Loss: 0.00647375
Iteration 21/25 | Loss: 0.00647375
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.006473745685070753, 0.006473745685070753, 0.006473745685070753, 0.006473745685070753, 0.006473745685070753]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006473745685070753

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00647375
Iteration 2/1000 | Loss: 0.00003891
Iteration 3/1000 | Loss: 0.00004272
Iteration 4/1000 | Loss: 0.00002282
Iteration 5/1000 | Loss: 0.00001597
Iteration 6/1000 | Loss: 0.00001501
Iteration 7/1000 | Loss: 0.00001440
Iteration 8/1000 | Loss: 0.00003055
Iteration 9/1000 | Loss: 0.00001633
Iteration 10/1000 | Loss: 0.00001355
Iteration 11/1000 | Loss: 0.00001341
Iteration 12/1000 | Loss: 0.00001323
Iteration 13/1000 | Loss: 0.00001322
Iteration 14/1000 | Loss: 0.00001322
Iteration 15/1000 | Loss: 0.00002143
Iteration 16/1000 | Loss: 0.00002143
Iteration 17/1000 | Loss: 0.00001292
Iteration 18/1000 | Loss: 0.00001283
Iteration 19/1000 | Loss: 0.00001276
Iteration 20/1000 | Loss: 0.00001275
Iteration 21/1000 | Loss: 0.00001273
Iteration 22/1000 | Loss: 0.00001272
Iteration 23/1000 | Loss: 0.00001272
Iteration 24/1000 | Loss: 0.00001271
Iteration 25/1000 | Loss: 0.00001265
Iteration 26/1000 | Loss: 0.00001262
Iteration 27/1000 | Loss: 0.00001261
Iteration 28/1000 | Loss: 0.00001261
Iteration 29/1000 | Loss: 0.00001261
Iteration 30/1000 | Loss: 0.00001261
Iteration 31/1000 | Loss: 0.00001260
Iteration 32/1000 | Loss: 0.00001260
Iteration 33/1000 | Loss: 0.00001259
Iteration 34/1000 | Loss: 0.00001259
Iteration 35/1000 | Loss: 0.00001258
Iteration 36/1000 | Loss: 0.00001257
Iteration 37/1000 | Loss: 0.00001257
Iteration 38/1000 | Loss: 0.00001257
Iteration 39/1000 | Loss: 0.00001256
Iteration 40/1000 | Loss: 0.00001256
Iteration 41/1000 | Loss: 0.00001256
Iteration 42/1000 | Loss: 0.00001255
Iteration 43/1000 | Loss: 0.00001255
Iteration 44/1000 | Loss: 0.00001254
Iteration 45/1000 | Loss: 0.00001254
Iteration 46/1000 | Loss: 0.00001253
Iteration 47/1000 | Loss: 0.00001253
Iteration 48/1000 | Loss: 0.00001253
Iteration 49/1000 | Loss: 0.00001252
Iteration 50/1000 | Loss: 0.00001252
Iteration 51/1000 | Loss: 0.00001252
Iteration 52/1000 | Loss: 0.00001251
Iteration 53/1000 | Loss: 0.00001251
Iteration 54/1000 | Loss: 0.00001250
Iteration 55/1000 | Loss: 0.00001250
Iteration 56/1000 | Loss: 0.00001250
Iteration 57/1000 | Loss: 0.00001250
Iteration 58/1000 | Loss: 0.00001250
Iteration 59/1000 | Loss: 0.00001250
Iteration 60/1000 | Loss: 0.00001249
Iteration 61/1000 | Loss: 0.00001249
Iteration 62/1000 | Loss: 0.00001249
Iteration 63/1000 | Loss: 0.00001249
Iteration 64/1000 | Loss: 0.00001248
Iteration 65/1000 | Loss: 0.00001247
Iteration 66/1000 | Loss: 0.00001247
Iteration 67/1000 | Loss: 0.00001247
Iteration 68/1000 | Loss: 0.00001247
Iteration 69/1000 | Loss: 0.00001247
Iteration 70/1000 | Loss: 0.00001247
Iteration 71/1000 | Loss: 0.00001247
Iteration 72/1000 | Loss: 0.00001247
Iteration 73/1000 | Loss: 0.00001247
Iteration 74/1000 | Loss: 0.00001246
Iteration 75/1000 | Loss: 0.00001246
Iteration 76/1000 | Loss: 0.00001246
Iteration 77/1000 | Loss: 0.00001246
Iteration 78/1000 | Loss: 0.00001246
Iteration 79/1000 | Loss: 0.00001246
Iteration 80/1000 | Loss: 0.00001245
Iteration 81/1000 | Loss: 0.00001245
Iteration 82/1000 | Loss: 0.00001245
Iteration 83/1000 | Loss: 0.00001245
Iteration 84/1000 | Loss: 0.00001244
Iteration 85/1000 | Loss: 0.00001244
Iteration 86/1000 | Loss: 0.00001244
Iteration 87/1000 | Loss: 0.00001244
Iteration 88/1000 | Loss: 0.00001244
Iteration 89/1000 | Loss: 0.00001244
Iteration 90/1000 | Loss: 0.00001244
Iteration 91/1000 | Loss: 0.00001244
Iteration 92/1000 | Loss: 0.00001244
Iteration 93/1000 | Loss: 0.00001244
Iteration 94/1000 | Loss: 0.00001244
Iteration 95/1000 | Loss: 0.00001244
Iteration 96/1000 | Loss: 0.00001244
Iteration 97/1000 | Loss: 0.00001244
Iteration 98/1000 | Loss: 0.00001244
Iteration 99/1000 | Loss: 0.00001244
Iteration 100/1000 | Loss: 0.00001243
Iteration 101/1000 | Loss: 0.00001243
Iteration 102/1000 | Loss: 0.00001243
Iteration 103/1000 | Loss: 0.00001243
Iteration 104/1000 | Loss: 0.00001242
Iteration 105/1000 | Loss: 0.00001242
Iteration 106/1000 | Loss: 0.00001242
Iteration 107/1000 | Loss: 0.00001242
Iteration 108/1000 | Loss: 0.00001242
Iteration 109/1000 | Loss: 0.00001241
Iteration 110/1000 | Loss: 0.00001241
Iteration 111/1000 | Loss: 0.00001241
Iteration 112/1000 | Loss: 0.00001241
Iteration 113/1000 | Loss: 0.00001241
Iteration 114/1000 | Loss: 0.00001241
Iteration 115/1000 | Loss: 0.00001241
Iteration 116/1000 | Loss: 0.00001241
Iteration 117/1000 | Loss: 0.00001241
Iteration 118/1000 | Loss: 0.00001241
Iteration 119/1000 | Loss: 0.00001241
Iteration 120/1000 | Loss: 0.00001241
Iteration 121/1000 | Loss: 0.00001241
Iteration 122/1000 | Loss: 0.00001240
Iteration 123/1000 | Loss: 0.00001240
Iteration 124/1000 | Loss: 0.00001240
Iteration 125/1000 | Loss: 0.00001240
Iteration 126/1000 | Loss: 0.00001240
Iteration 127/1000 | Loss: 0.00001240
Iteration 128/1000 | Loss: 0.00001240
Iteration 129/1000 | Loss: 0.00001240
Iteration 130/1000 | Loss: 0.00001240
Iteration 131/1000 | Loss: 0.00001240
Iteration 132/1000 | Loss: 0.00001240
Iteration 133/1000 | Loss: 0.00001240
Iteration 134/1000 | Loss: 0.00001240
Iteration 135/1000 | Loss: 0.00001240
Iteration 136/1000 | Loss: 0.00001240
Iteration 137/1000 | Loss: 0.00001240
Iteration 138/1000 | Loss: 0.00001239
Iteration 139/1000 | Loss: 0.00001239
Iteration 140/1000 | Loss: 0.00001239
Iteration 141/1000 | Loss: 0.00001239
Iteration 142/1000 | Loss: 0.00001239
Iteration 143/1000 | Loss: 0.00001239
Iteration 144/1000 | Loss: 0.00001239
Iteration 145/1000 | Loss: 0.00001239
Iteration 146/1000 | Loss: 0.00001239
Iteration 147/1000 | Loss: 0.00001239
Iteration 148/1000 | Loss: 0.00001239
Iteration 149/1000 | Loss: 0.00001239
Iteration 150/1000 | Loss: 0.00001239
Iteration 151/1000 | Loss: 0.00001239
Iteration 152/1000 | Loss: 0.00001239
Iteration 153/1000 | Loss: 0.00001239
Iteration 154/1000 | Loss: 0.00001239
Iteration 155/1000 | Loss: 0.00001239
Iteration 156/1000 | Loss: 0.00001239
Iteration 157/1000 | Loss: 0.00001239
Iteration 158/1000 | Loss: 0.00001239
Iteration 159/1000 | Loss: 0.00001238
Iteration 160/1000 | Loss: 0.00001238
Iteration 161/1000 | Loss: 0.00001238
Iteration 162/1000 | Loss: 0.00001238
Iteration 163/1000 | Loss: 0.00001238
Iteration 164/1000 | Loss: 0.00001238
Iteration 165/1000 | Loss: 0.00001238
Iteration 166/1000 | Loss: 0.00001238
Iteration 167/1000 | Loss: 0.00001238
Iteration 168/1000 | Loss: 0.00001238
Iteration 169/1000 | Loss: 0.00001238
Iteration 170/1000 | Loss: 0.00001238
Iteration 171/1000 | Loss: 0.00001238
Iteration 172/1000 | Loss: 0.00001238
Iteration 173/1000 | Loss: 0.00001238
Iteration 174/1000 | Loss: 0.00001238
Iteration 175/1000 | Loss: 0.00001238
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 175. Stopping optimization.
Last 5 losses: [1.238100685441168e-05, 1.238100685441168e-05, 1.238100685441168e-05, 1.238100685441168e-05, 1.238100685441168e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.238100685441168e-05

Optimization complete. Final v2v error: 3.0146167278289795 mm

Highest mean error: 3.3927905559539795 mm for frame 69

Lowest mean error: 2.6990997791290283 mm for frame 187

Saving results

Total time: 50.82626724243164
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00399492
Iteration 2/25 | Loss: 0.00124707
Iteration 3/25 | Loss: 0.00117091
Iteration 4/25 | Loss: 0.00116061
Iteration 5/25 | Loss: 0.00115740
Iteration 6/25 | Loss: 0.00115616
Iteration 7/25 | Loss: 0.00115605
Iteration 8/25 | Loss: 0.00115605
Iteration 9/25 | Loss: 0.00115605
Iteration 10/25 | Loss: 0.00115605
Iteration 11/25 | Loss: 0.00115605
Iteration 12/25 | Loss: 0.00115605
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011560487328097224, 0.0011560487328097224, 0.0011560487328097224, 0.0011560487328097224, 0.0011560487328097224]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011560487328097224

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.63741732
Iteration 2/25 | Loss: 0.00378142
Iteration 3/25 | Loss: 0.00378141
Iteration 4/25 | Loss: 0.00378141
Iteration 5/25 | Loss: 0.00378141
Iteration 6/25 | Loss: 0.00378141
Iteration 7/25 | Loss: 0.00378141
Iteration 8/25 | Loss: 0.00378141
Iteration 9/25 | Loss: 0.00378141
Iteration 10/25 | Loss: 0.00378141
Iteration 11/25 | Loss: 0.00378141
Iteration 12/25 | Loss: 0.00378141
Iteration 13/25 | Loss: 0.00378141
Iteration 14/25 | Loss: 0.00378141
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.003781411563977599, 0.003781411563977599, 0.003781411563977599, 0.003781411563977599, 0.003781411563977599]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003781411563977599

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00378141
Iteration 2/1000 | Loss: 0.00002220
Iteration 3/1000 | Loss: 0.00001410
Iteration 4/1000 | Loss: 0.00001228
Iteration 5/1000 | Loss: 0.00001148
Iteration 6/1000 | Loss: 0.00001068
Iteration 7/1000 | Loss: 0.00001027
Iteration 8/1000 | Loss: 0.00000994
Iteration 9/1000 | Loss: 0.00000980
Iteration 10/1000 | Loss: 0.00000974
Iteration 11/1000 | Loss: 0.00000973
Iteration 12/1000 | Loss: 0.00000973
Iteration 13/1000 | Loss: 0.00000964
Iteration 14/1000 | Loss: 0.00000963
Iteration 15/1000 | Loss: 0.00000962
Iteration 16/1000 | Loss: 0.00000953
Iteration 17/1000 | Loss: 0.00000946
Iteration 18/1000 | Loss: 0.00000943
Iteration 19/1000 | Loss: 0.00000942
Iteration 20/1000 | Loss: 0.00000941
Iteration 21/1000 | Loss: 0.00000939
Iteration 22/1000 | Loss: 0.00000939
Iteration 23/1000 | Loss: 0.00000938
Iteration 24/1000 | Loss: 0.00000937
Iteration 25/1000 | Loss: 0.00000937
Iteration 26/1000 | Loss: 0.00000937
Iteration 27/1000 | Loss: 0.00000936
Iteration 28/1000 | Loss: 0.00000935
Iteration 29/1000 | Loss: 0.00000935
Iteration 30/1000 | Loss: 0.00000935
Iteration 31/1000 | Loss: 0.00000935
Iteration 32/1000 | Loss: 0.00000935
Iteration 33/1000 | Loss: 0.00000934
Iteration 34/1000 | Loss: 0.00000934
Iteration 35/1000 | Loss: 0.00000933
Iteration 36/1000 | Loss: 0.00000933
Iteration 37/1000 | Loss: 0.00000932
Iteration 38/1000 | Loss: 0.00000932
Iteration 39/1000 | Loss: 0.00000931
Iteration 40/1000 | Loss: 0.00000931
Iteration 41/1000 | Loss: 0.00000931
Iteration 42/1000 | Loss: 0.00000931
Iteration 43/1000 | Loss: 0.00000930
Iteration 44/1000 | Loss: 0.00000930
Iteration 45/1000 | Loss: 0.00000929
Iteration 46/1000 | Loss: 0.00000929
Iteration 47/1000 | Loss: 0.00000928
Iteration 48/1000 | Loss: 0.00000928
Iteration 49/1000 | Loss: 0.00000928
Iteration 50/1000 | Loss: 0.00000928
Iteration 51/1000 | Loss: 0.00000927
Iteration 52/1000 | Loss: 0.00000927
Iteration 53/1000 | Loss: 0.00000927
Iteration 54/1000 | Loss: 0.00000927
Iteration 55/1000 | Loss: 0.00000926
Iteration 56/1000 | Loss: 0.00000926
Iteration 57/1000 | Loss: 0.00000926
Iteration 58/1000 | Loss: 0.00000926
Iteration 59/1000 | Loss: 0.00000926
Iteration 60/1000 | Loss: 0.00000926
Iteration 61/1000 | Loss: 0.00000926
Iteration 62/1000 | Loss: 0.00000925
Iteration 63/1000 | Loss: 0.00000925
Iteration 64/1000 | Loss: 0.00000925
Iteration 65/1000 | Loss: 0.00000925
Iteration 66/1000 | Loss: 0.00000925
Iteration 67/1000 | Loss: 0.00000924
Iteration 68/1000 | Loss: 0.00000924
Iteration 69/1000 | Loss: 0.00000924
Iteration 70/1000 | Loss: 0.00000923
Iteration 71/1000 | Loss: 0.00000923
Iteration 72/1000 | Loss: 0.00000923
Iteration 73/1000 | Loss: 0.00000923
Iteration 74/1000 | Loss: 0.00000923
Iteration 75/1000 | Loss: 0.00000923
Iteration 76/1000 | Loss: 0.00000923
Iteration 77/1000 | Loss: 0.00000922
Iteration 78/1000 | Loss: 0.00000922
Iteration 79/1000 | Loss: 0.00000922
Iteration 80/1000 | Loss: 0.00000922
Iteration 81/1000 | Loss: 0.00000922
Iteration 82/1000 | Loss: 0.00000922
Iteration 83/1000 | Loss: 0.00000922
Iteration 84/1000 | Loss: 0.00000922
Iteration 85/1000 | Loss: 0.00000922
Iteration 86/1000 | Loss: 0.00000922
Iteration 87/1000 | Loss: 0.00000922
Iteration 88/1000 | Loss: 0.00000921
Iteration 89/1000 | Loss: 0.00000921
Iteration 90/1000 | Loss: 0.00000920
Iteration 91/1000 | Loss: 0.00000920
Iteration 92/1000 | Loss: 0.00000920
Iteration 93/1000 | Loss: 0.00000920
Iteration 94/1000 | Loss: 0.00000920
Iteration 95/1000 | Loss: 0.00000920
Iteration 96/1000 | Loss: 0.00000919
Iteration 97/1000 | Loss: 0.00000919
Iteration 98/1000 | Loss: 0.00000919
Iteration 99/1000 | Loss: 0.00000919
Iteration 100/1000 | Loss: 0.00000919
Iteration 101/1000 | Loss: 0.00000919
Iteration 102/1000 | Loss: 0.00000919
Iteration 103/1000 | Loss: 0.00000919
Iteration 104/1000 | Loss: 0.00000919
Iteration 105/1000 | Loss: 0.00000919
Iteration 106/1000 | Loss: 0.00000919
Iteration 107/1000 | Loss: 0.00000919
Iteration 108/1000 | Loss: 0.00000919
Iteration 109/1000 | Loss: 0.00000919
Iteration 110/1000 | Loss: 0.00000919
Iteration 111/1000 | Loss: 0.00000919
Iteration 112/1000 | Loss: 0.00000919
Iteration 113/1000 | Loss: 0.00000919
Iteration 114/1000 | Loss: 0.00000919
Iteration 115/1000 | Loss: 0.00000919
Iteration 116/1000 | Loss: 0.00000919
Iteration 117/1000 | Loss: 0.00000919
Iteration 118/1000 | Loss: 0.00000919
Iteration 119/1000 | Loss: 0.00000919
Iteration 120/1000 | Loss: 0.00000919
Iteration 121/1000 | Loss: 0.00000919
Iteration 122/1000 | Loss: 0.00000919
Iteration 123/1000 | Loss: 0.00000919
Iteration 124/1000 | Loss: 0.00000919
Iteration 125/1000 | Loss: 0.00000919
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [9.191370736516546e-06, 9.191370736516546e-06, 9.191370736516546e-06, 9.191370736516546e-06, 9.191370736516546e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.191370736516546e-06

Optimization complete. Final v2v error: 2.578031539916992 mm

Highest mean error: 2.9852237701416016 mm for frame 57

Lowest mean error: 2.3006856441497803 mm for frame 84

Saving results

Total time: 32.30063605308533
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00817601
Iteration 2/25 | Loss: 0.00190306
Iteration 3/25 | Loss: 0.00133636
Iteration 4/25 | Loss: 0.00129052
Iteration 5/25 | Loss: 0.00128620
Iteration 6/25 | Loss: 0.00128600
Iteration 7/25 | Loss: 0.00128600
Iteration 8/25 | Loss: 0.00128600
Iteration 9/25 | Loss: 0.00128600
Iteration 10/25 | Loss: 0.00128600
Iteration 11/25 | Loss: 0.00128600
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0012859991984441876, 0.0012859991984441876, 0.0012859991984441876, 0.0012859991984441876, 0.0012859991984441876]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012859991984441876

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.04860151
Iteration 2/25 | Loss: 0.00300038
Iteration 3/25 | Loss: 0.00300038
Iteration 4/25 | Loss: 0.00300038
Iteration 5/25 | Loss: 0.00300038
Iteration 6/25 | Loss: 0.00300038
Iteration 7/25 | Loss: 0.00300038
Iteration 8/25 | Loss: 0.00300038
Iteration 9/25 | Loss: 0.00300038
Iteration 10/25 | Loss: 0.00300038
Iteration 11/25 | Loss: 0.00300038
Iteration 12/25 | Loss: 0.00300038
Iteration 13/25 | Loss: 0.00300038
Iteration 14/25 | Loss: 0.00300038
Iteration 15/25 | Loss: 0.00300038
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0030003793071955442, 0.0030003793071955442, 0.0030003793071955442, 0.0030003793071955442, 0.0030003793071955442]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0030003793071955442

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00300038
Iteration 2/1000 | Loss: 0.00004022
Iteration 3/1000 | Loss: 0.00002581
Iteration 4/1000 | Loss: 0.00002253
Iteration 5/1000 | Loss: 0.00002106
Iteration 6/1000 | Loss: 0.00002030
Iteration 7/1000 | Loss: 0.00001967
Iteration 8/1000 | Loss: 0.00001909
Iteration 9/1000 | Loss: 0.00001877
Iteration 10/1000 | Loss: 0.00001845
Iteration 11/1000 | Loss: 0.00001823
Iteration 12/1000 | Loss: 0.00001810
Iteration 13/1000 | Loss: 0.00001785
Iteration 14/1000 | Loss: 0.00001763
Iteration 15/1000 | Loss: 0.00001745
Iteration 16/1000 | Loss: 0.00001726
Iteration 17/1000 | Loss: 0.00001718
Iteration 18/1000 | Loss: 0.00001717
Iteration 19/1000 | Loss: 0.00001709
Iteration 20/1000 | Loss: 0.00001706
Iteration 21/1000 | Loss: 0.00001705
Iteration 22/1000 | Loss: 0.00001704
Iteration 23/1000 | Loss: 0.00001703
Iteration 24/1000 | Loss: 0.00001698
Iteration 25/1000 | Loss: 0.00001698
Iteration 26/1000 | Loss: 0.00001696
Iteration 27/1000 | Loss: 0.00001695
Iteration 28/1000 | Loss: 0.00001695
Iteration 29/1000 | Loss: 0.00001695
Iteration 30/1000 | Loss: 0.00001694
Iteration 31/1000 | Loss: 0.00001692
Iteration 32/1000 | Loss: 0.00001692
Iteration 33/1000 | Loss: 0.00001692
Iteration 34/1000 | Loss: 0.00001692
Iteration 35/1000 | Loss: 0.00001691
Iteration 36/1000 | Loss: 0.00001691
Iteration 37/1000 | Loss: 0.00001691
Iteration 38/1000 | Loss: 0.00001691
Iteration 39/1000 | Loss: 0.00001691
Iteration 40/1000 | Loss: 0.00001691
Iteration 41/1000 | Loss: 0.00001691
Iteration 42/1000 | Loss: 0.00001691
Iteration 43/1000 | Loss: 0.00001691
Iteration 44/1000 | Loss: 0.00001691
Iteration 45/1000 | Loss: 0.00001691
Iteration 46/1000 | Loss: 0.00001690
Iteration 47/1000 | Loss: 0.00001690
Iteration 48/1000 | Loss: 0.00001689
Iteration 49/1000 | Loss: 0.00001689
Iteration 50/1000 | Loss: 0.00001689
Iteration 51/1000 | Loss: 0.00001689
Iteration 52/1000 | Loss: 0.00001689
Iteration 53/1000 | Loss: 0.00001688
Iteration 54/1000 | Loss: 0.00001688
Iteration 55/1000 | Loss: 0.00001688
Iteration 56/1000 | Loss: 0.00001688
Iteration 57/1000 | Loss: 0.00001688
Iteration 58/1000 | Loss: 0.00001688
Iteration 59/1000 | Loss: 0.00001688
Iteration 60/1000 | Loss: 0.00001688
Iteration 61/1000 | Loss: 0.00001688
Iteration 62/1000 | Loss: 0.00001688
Iteration 63/1000 | Loss: 0.00001688
Iteration 64/1000 | Loss: 0.00001688
Iteration 65/1000 | Loss: 0.00001688
Iteration 66/1000 | Loss: 0.00001688
Iteration 67/1000 | Loss: 0.00001687
Iteration 68/1000 | Loss: 0.00001687
Iteration 69/1000 | Loss: 0.00001687
Iteration 70/1000 | Loss: 0.00001686
Iteration 71/1000 | Loss: 0.00001686
Iteration 72/1000 | Loss: 0.00001686
Iteration 73/1000 | Loss: 0.00001686
Iteration 74/1000 | Loss: 0.00001686
Iteration 75/1000 | Loss: 0.00001686
Iteration 76/1000 | Loss: 0.00001686
Iteration 77/1000 | Loss: 0.00001686
Iteration 78/1000 | Loss: 0.00001686
Iteration 79/1000 | Loss: 0.00001686
Iteration 80/1000 | Loss: 0.00001686
Iteration 81/1000 | Loss: 0.00001685
Iteration 82/1000 | Loss: 0.00001685
Iteration 83/1000 | Loss: 0.00001685
Iteration 84/1000 | Loss: 0.00001685
Iteration 85/1000 | Loss: 0.00001685
Iteration 86/1000 | Loss: 0.00001685
Iteration 87/1000 | Loss: 0.00001685
Iteration 88/1000 | Loss: 0.00001685
Iteration 89/1000 | Loss: 0.00001685
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 89. Stopping optimization.
Last 5 losses: [1.6854826753842644e-05, 1.6854826753842644e-05, 1.6854826753842644e-05, 1.6854826753842644e-05, 1.6854826753842644e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6854826753842644e-05

Optimization complete. Final v2v error: 3.4161458015441895 mm

Highest mean error: 4.251224040985107 mm for frame 181

Lowest mean error: 2.801453113555908 mm for frame 101

Saving results

Total time: 40.89979863166809
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00613809
Iteration 2/25 | Loss: 0.00151791
Iteration 3/25 | Loss: 0.00128496
Iteration 4/25 | Loss: 0.00125921
Iteration 5/25 | Loss: 0.00124542
Iteration 6/25 | Loss: 0.00124426
Iteration 7/25 | Loss: 0.00123919
Iteration 8/25 | Loss: 0.00123597
Iteration 9/25 | Loss: 0.00123469
Iteration 10/25 | Loss: 0.00123397
Iteration 11/25 | Loss: 0.00123366
Iteration 12/25 | Loss: 0.00123347
Iteration 13/25 | Loss: 0.00123339
Iteration 14/25 | Loss: 0.00123337
Iteration 15/25 | Loss: 0.00123337
Iteration 16/25 | Loss: 0.00123337
Iteration 17/25 | Loss: 0.00123337
Iteration 18/25 | Loss: 0.00123336
Iteration 19/25 | Loss: 0.00123336
Iteration 20/25 | Loss: 0.00123336
Iteration 21/25 | Loss: 0.00123336
Iteration 22/25 | Loss: 0.00123336
Iteration 23/25 | Loss: 0.00123336
Iteration 24/25 | Loss: 0.00123336
Iteration 25/25 | Loss: 0.00123335

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.13220072
Iteration 2/25 | Loss: 0.00429523
Iteration 3/25 | Loss: 0.00429519
Iteration 4/25 | Loss: 0.00429519
Iteration 5/25 | Loss: 0.00429519
Iteration 6/25 | Loss: 0.00429519
Iteration 7/25 | Loss: 0.00429518
Iteration 8/25 | Loss: 0.00429518
Iteration 9/25 | Loss: 0.00429518
Iteration 10/25 | Loss: 0.00429518
Iteration 11/25 | Loss: 0.00429518
Iteration 12/25 | Loss: 0.00429518
Iteration 13/25 | Loss: 0.00429518
Iteration 14/25 | Loss: 0.00429518
Iteration 15/25 | Loss: 0.00429518
Iteration 16/25 | Loss: 0.00429518
Iteration 17/25 | Loss: 0.00429518
Iteration 18/25 | Loss: 0.00429518
Iteration 19/25 | Loss: 0.00429518
Iteration 20/25 | Loss: 0.00429518
Iteration 21/25 | Loss: 0.00429518
Iteration 22/25 | Loss: 0.00429518
Iteration 23/25 | Loss: 0.00429518
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.004295182880014181, 0.004295182880014181, 0.004295182880014181, 0.004295182880014181, 0.004295182880014181]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004295182880014181

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00429518
Iteration 2/1000 | Loss: 0.00004836
Iteration 3/1000 | Loss: 0.00003025
Iteration 4/1000 | Loss: 0.00002416
Iteration 5/1000 | Loss: 0.00002165
Iteration 6/1000 | Loss: 0.00002045
Iteration 7/1000 | Loss: 0.00001953
Iteration 8/1000 | Loss: 0.00001890
Iteration 9/1000 | Loss: 0.00001839
Iteration 10/1000 | Loss: 0.00001801
Iteration 11/1000 | Loss: 0.00001770
Iteration 12/1000 | Loss: 0.00001739
Iteration 13/1000 | Loss: 0.00001720
Iteration 14/1000 | Loss: 0.00001716
Iteration 15/1000 | Loss: 0.00001705
Iteration 16/1000 | Loss: 0.00001701
Iteration 17/1000 | Loss: 0.00039033
Iteration 18/1000 | Loss: 0.00002045
Iteration 19/1000 | Loss: 0.00001759
Iteration 20/1000 | Loss: 0.00001660
Iteration 21/1000 | Loss: 0.00001610
Iteration 22/1000 | Loss: 0.00001563
Iteration 23/1000 | Loss: 0.00001539
Iteration 24/1000 | Loss: 0.00001532
Iteration 25/1000 | Loss: 0.00001531
Iteration 26/1000 | Loss: 0.00001529
Iteration 27/1000 | Loss: 0.00001529
Iteration 28/1000 | Loss: 0.00001528
Iteration 29/1000 | Loss: 0.00001527
Iteration 30/1000 | Loss: 0.00001527
Iteration 31/1000 | Loss: 0.00001527
Iteration 32/1000 | Loss: 0.00001526
Iteration 33/1000 | Loss: 0.00001526
Iteration 34/1000 | Loss: 0.00001525
Iteration 35/1000 | Loss: 0.00001525
Iteration 36/1000 | Loss: 0.00001525
Iteration 37/1000 | Loss: 0.00001524
Iteration 38/1000 | Loss: 0.00001524
Iteration 39/1000 | Loss: 0.00001524
Iteration 40/1000 | Loss: 0.00001523
Iteration 41/1000 | Loss: 0.00001523
Iteration 42/1000 | Loss: 0.00001523
Iteration 43/1000 | Loss: 0.00001522
Iteration 44/1000 | Loss: 0.00001522
Iteration 45/1000 | Loss: 0.00001521
Iteration 46/1000 | Loss: 0.00001521
Iteration 47/1000 | Loss: 0.00001521
Iteration 48/1000 | Loss: 0.00001520
Iteration 49/1000 | Loss: 0.00001520
Iteration 50/1000 | Loss: 0.00001520
Iteration 51/1000 | Loss: 0.00001518
Iteration 52/1000 | Loss: 0.00001517
Iteration 53/1000 | Loss: 0.00001510
Iteration 54/1000 | Loss: 0.00001510
Iteration 55/1000 | Loss: 0.00001509
Iteration 56/1000 | Loss: 0.00001509
Iteration 57/1000 | Loss: 0.00001509
Iteration 58/1000 | Loss: 0.00001509
Iteration 59/1000 | Loss: 0.00001509
Iteration 60/1000 | Loss: 0.00001509
Iteration 61/1000 | Loss: 0.00001508
Iteration 62/1000 | Loss: 0.00001508
Iteration 63/1000 | Loss: 0.00001508
Iteration 64/1000 | Loss: 0.00001507
Iteration 65/1000 | Loss: 0.00001506
Iteration 66/1000 | Loss: 0.00001506
Iteration 67/1000 | Loss: 0.00001506
Iteration 68/1000 | Loss: 0.00001505
Iteration 69/1000 | Loss: 0.00001505
Iteration 70/1000 | Loss: 0.00001505
Iteration 71/1000 | Loss: 0.00001505
Iteration 72/1000 | Loss: 0.00001504
Iteration 73/1000 | Loss: 0.00001504
Iteration 74/1000 | Loss: 0.00001504
Iteration 75/1000 | Loss: 0.00001503
Iteration 76/1000 | Loss: 0.00001503
Iteration 77/1000 | Loss: 0.00001502
Iteration 78/1000 | Loss: 0.00001502
Iteration 79/1000 | Loss: 0.00001502
Iteration 80/1000 | Loss: 0.00001501
Iteration 81/1000 | Loss: 0.00001501
Iteration 82/1000 | Loss: 0.00001501
Iteration 83/1000 | Loss: 0.00001501
Iteration 84/1000 | Loss: 0.00001500
Iteration 85/1000 | Loss: 0.00001500
Iteration 86/1000 | Loss: 0.00001499
Iteration 87/1000 | Loss: 0.00001499
Iteration 88/1000 | Loss: 0.00001499
Iteration 89/1000 | Loss: 0.00001498
Iteration 90/1000 | Loss: 0.00001497
Iteration 91/1000 | Loss: 0.00001497
Iteration 92/1000 | Loss: 0.00001496
Iteration 93/1000 | Loss: 0.00001496
Iteration 94/1000 | Loss: 0.00001496
Iteration 95/1000 | Loss: 0.00001495
Iteration 96/1000 | Loss: 0.00001494
Iteration 97/1000 | Loss: 0.00001494
Iteration 98/1000 | Loss: 0.00001493
Iteration 99/1000 | Loss: 0.00001493
Iteration 100/1000 | Loss: 0.00001493
Iteration 101/1000 | Loss: 0.00001493
Iteration 102/1000 | Loss: 0.00001492
Iteration 103/1000 | Loss: 0.00001492
Iteration 104/1000 | Loss: 0.00001491
Iteration 105/1000 | Loss: 0.00001491
Iteration 106/1000 | Loss: 0.00001491
Iteration 107/1000 | Loss: 0.00001490
Iteration 108/1000 | Loss: 0.00001490
Iteration 109/1000 | Loss: 0.00001490
Iteration 110/1000 | Loss: 0.00001490
Iteration 111/1000 | Loss: 0.00001490
Iteration 112/1000 | Loss: 0.00001489
Iteration 113/1000 | Loss: 0.00001489
Iteration 114/1000 | Loss: 0.00001489
Iteration 115/1000 | Loss: 0.00001489
Iteration 116/1000 | Loss: 0.00001489
Iteration 117/1000 | Loss: 0.00001489
Iteration 118/1000 | Loss: 0.00001489
Iteration 119/1000 | Loss: 0.00001489
Iteration 120/1000 | Loss: 0.00001489
Iteration 121/1000 | Loss: 0.00001489
Iteration 122/1000 | Loss: 0.00001489
Iteration 123/1000 | Loss: 0.00001489
Iteration 124/1000 | Loss: 0.00001489
Iteration 125/1000 | Loss: 0.00001489
Iteration 126/1000 | Loss: 0.00001489
Iteration 127/1000 | Loss: 0.00001489
Iteration 128/1000 | Loss: 0.00001488
Iteration 129/1000 | Loss: 0.00001488
Iteration 130/1000 | Loss: 0.00001488
Iteration 131/1000 | Loss: 0.00001488
Iteration 132/1000 | Loss: 0.00001488
Iteration 133/1000 | Loss: 0.00001488
Iteration 134/1000 | Loss: 0.00001488
Iteration 135/1000 | Loss: 0.00001487
Iteration 136/1000 | Loss: 0.00001487
Iteration 137/1000 | Loss: 0.00001487
Iteration 138/1000 | Loss: 0.00001487
Iteration 139/1000 | Loss: 0.00001487
Iteration 140/1000 | Loss: 0.00001487
Iteration 141/1000 | Loss: 0.00001487
Iteration 142/1000 | Loss: 0.00001486
Iteration 143/1000 | Loss: 0.00001486
Iteration 144/1000 | Loss: 0.00001486
Iteration 145/1000 | Loss: 0.00001486
Iteration 146/1000 | Loss: 0.00001486
Iteration 147/1000 | Loss: 0.00001486
Iteration 148/1000 | Loss: 0.00001485
Iteration 149/1000 | Loss: 0.00001485
Iteration 150/1000 | Loss: 0.00001485
Iteration 151/1000 | Loss: 0.00001485
Iteration 152/1000 | Loss: 0.00001485
Iteration 153/1000 | Loss: 0.00001484
Iteration 154/1000 | Loss: 0.00001484
Iteration 155/1000 | Loss: 0.00001484
Iteration 156/1000 | Loss: 0.00001483
Iteration 157/1000 | Loss: 0.00001483
Iteration 158/1000 | Loss: 0.00001483
Iteration 159/1000 | Loss: 0.00001483
Iteration 160/1000 | Loss: 0.00001483
Iteration 161/1000 | Loss: 0.00001483
Iteration 162/1000 | Loss: 0.00001482
Iteration 163/1000 | Loss: 0.00001482
Iteration 164/1000 | Loss: 0.00001482
Iteration 165/1000 | Loss: 0.00001482
Iteration 166/1000 | Loss: 0.00001482
Iteration 167/1000 | Loss: 0.00001482
Iteration 168/1000 | Loss: 0.00001482
Iteration 169/1000 | Loss: 0.00001481
Iteration 170/1000 | Loss: 0.00001481
Iteration 171/1000 | Loss: 0.00001481
Iteration 172/1000 | Loss: 0.00001481
Iteration 173/1000 | Loss: 0.00001481
Iteration 174/1000 | Loss: 0.00001480
Iteration 175/1000 | Loss: 0.00001480
Iteration 176/1000 | Loss: 0.00001480
Iteration 177/1000 | Loss: 0.00001480
Iteration 178/1000 | Loss: 0.00001480
Iteration 179/1000 | Loss: 0.00001480
Iteration 180/1000 | Loss: 0.00001480
Iteration 181/1000 | Loss: 0.00001480
Iteration 182/1000 | Loss: 0.00001480
Iteration 183/1000 | Loss: 0.00001480
Iteration 184/1000 | Loss: 0.00001479
Iteration 185/1000 | Loss: 0.00001479
Iteration 186/1000 | Loss: 0.00001479
Iteration 187/1000 | Loss: 0.00001479
Iteration 188/1000 | Loss: 0.00001479
Iteration 189/1000 | Loss: 0.00001479
Iteration 190/1000 | Loss: 0.00001479
Iteration 191/1000 | Loss: 0.00001478
Iteration 192/1000 | Loss: 0.00001478
Iteration 193/1000 | Loss: 0.00001478
Iteration 194/1000 | Loss: 0.00001478
Iteration 195/1000 | Loss: 0.00001478
Iteration 196/1000 | Loss: 0.00001478
Iteration 197/1000 | Loss: 0.00001478
Iteration 198/1000 | Loss: 0.00001477
Iteration 199/1000 | Loss: 0.00001477
Iteration 200/1000 | Loss: 0.00001477
Iteration 201/1000 | Loss: 0.00001477
Iteration 202/1000 | Loss: 0.00001477
Iteration 203/1000 | Loss: 0.00001477
Iteration 204/1000 | Loss: 0.00001477
Iteration 205/1000 | Loss: 0.00001477
Iteration 206/1000 | Loss: 0.00001477
Iteration 207/1000 | Loss: 0.00001477
Iteration 208/1000 | Loss: 0.00001476
Iteration 209/1000 | Loss: 0.00001476
Iteration 210/1000 | Loss: 0.00001476
Iteration 211/1000 | Loss: 0.00001476
Iteration 212/1000 | Loss: 0.00001476
Iteration 213/1000 | Loss: 0.00001476
Iteration 214/1000 | Loss: 0.00001476
Iteration 215/1000 | Loss: 0.00001476
Iteration 216/1000 | Loss: 0.00001476
Iteration 217/1000 | Loss: 0.00001476
Iteration 218/1000 | Loss: 0.00001476
Iteration 219/1000 | Loss: 0.00001475
Iteration 220/1000 | Loss: 0.00001475
Iteration 221/1000 | Loss: 0.00001475
Iteration 222/1000 | Loss: 0.00001475
Iteration 223/1000 | Loss: 0.00001475
Iteration 224/1000 | Loss: 0.00001475
Iteration 225/1000 | Loss: 0.00001475
Iteration 226/1000 | Loss: 0.00001475
Iteration 227/1000 | Loss: 0.00001475
Iteration 228/1000 | Loss: 0.00001475
Iteration 229/1000 | Loss: 0.00001475
Iteration 230/1000 | Loss: 0.00001475
Iteration 231/1000 | Loss: 0.00001475
Iteration 232/1000 | Loss: 0.00001475
Iteration 233/1000 | Loss: 0.00001475
Iteration 234/1000 | Loss: 0.00001474
Iteration 235/1000 | Loss: 0.00001474
Iteration 236/1000 | Loss: 0.00001474
Iteration 237/1000 | Loss: 0.00001474
Iteration 238/1000 | Loss: 0.00001474
Iteration 239/1000 | Loss: 0.00001474
Iteration 240/1000 | Loss: 0.00001474
Iteration 241/1000 | Loss: 0.00001474
Iteration 242/1000 | Loss: 0.00001474
Iteration 243/1000 | Loss: 0.00001474
Iteration 244/1000 | Loss: 0.00001474
Iteration 245/1000 | Loss: 0.00001474
Iteration 246/1000 | Loss: 0.00001474
Iteration 247/1000 | Loss: 0.00001474
Iteration 248/1000 | Loss: 0.00001474
Iteration 249/1000 | Loss: 0.00001474
Iteration 250/1000 | Loss: 0.00001474
Iteration 251/1000 | Loss: 0.00001474
Iteration 252/1000 | Loss: 0.00001474
Iteration 253/1000 | Loss: 0.00001474
Iteration 254/1000 | Loss: 0.00001474
Iteration 255/1000 | Loss: 0.00001474
Iteration 256/1000 | Loss: 0.00001474
Iteration 257/1000 | Loss: 0.00001473
Iteration 258/1000 | Loss: 0.00001473
Iteration 259/1000 | Loss: 0.00001473
Iteration 260/1000 | Loss: 0.00001473
Iteration 261/1000 | Loss: 0.00001473
Iteration 262/1000 | Loss: 0.00001473
Iteration 263/1000 | Loss: 0.00001473
Iteration 264/1000 | Loss: 0.00001473
Iteration 265/1000 | Loss: 0.00001473
Iteration 266/1000 | Loss: 0.00001473
Iteration 267/1000 | Loss: 0.00001473
Iteration 268/1000 | Loss: 0.00001473
Iteration 269/1000 | Loss: 0.00001473
Iteration 270/1000 | Loss: 0.00001473
Iteration 271/1000 | Loss: 0.00001473
Iteration 272/1000 | Loss: 0.00001473
Iteration 273/1000 | Loss: 0.00001473
Iteration 274/1000 | Loss: 0.00001473
Iteration 275/1000 | Loss: 0.00001473
Iteration 276/1000 | Loss: 0.00001473
Iteration 277/1000 | Loss: 0.00001472
Iteration 278/1000 | Loss: 0.00001472
Iteration 279/1000 | Loss: 0.00001472
Iteration 280/1000 | Loss: 0.00001472
Iteration 281/1000 | Loss: 0.00001472
Iteration 282/1000 | Loss: 0.00001472
Iteration 283/1000 | Loss: 0.00001472
Iteration 284/1000 | Loss: 0.00001472
Iteration 285/1000 | Loss: 0.00001472
Iteration 286/1000 | Loss: 0.00001472
Iteration 287/1000 | Loss: 0.00001472
Iteration 288/1000 | Loss: 0.00001472
Iteration 289/1000 | Loss: 0.00001472
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 289. Stopping optimization.
Last 5 losses: [1.4720756553288084e-05, 1.4720756553288084e-05, 1.4720756553288084e-05, 1.4720756553288084e-05, 1.4720756553288084e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4720756553288084e-05

Optimization complete. Final v2v error: 3.2621798515319824 mm

Highest mean error: 4.323683261871338 mm for frame 99

Lowest mean error: 2.6179254055023193 mm for frame 194

Saving results

Total time: 81.83626508712769
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01007399
Iteration 2/25 | Loss: 0.00247610
Iteration 3/25 | Loss: 0.00175504
Iteration 4/25 | Loss: 0.00170646
Iteration 5/25 | Loss: 0.00174702
Iteration 6/25 | Loss: 0.00139066
Iteration 7/25 | Loss: 0.00133623
Iteration 8/25 | Loss: 0.00130825
Iteration 9/25 | Loss: 0.00129562
Iteration 10/25 | Loss: 0.00128893
Iteration 11/25 | Loss: 0.00128989
Iteration 12/25 | Loss: 0.00128806
Iteration 13/25 | Loss: 0.00128796
Iteration 14/25 | Loss: 0.00128785
Iteration 15/25 | Loss: 0.00128775
Iteration 16/25 | Loss: 0.00128774
Iteration 17/25 | Loss: 0.00128774
Iteration 18/25 | Loss: 0.00128774
Iteration 19/25 | Loss: 0.00128774
Iteration 20/25 | Loss: 0.00128773
Iteration 21/25 | Loss: 0.00128773
Iteration 22/25 | Loss: 0.00128773
Iteration 23/25 | Loss: 0.00128773
Iteration 24/25 | Loss: 0.00128773
Iteration 25/25 | Loss: 0.00128773

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.10786188
Iteration 2/25 | Loss: 0.00452783
Iteration 3/25 | Loss: 0.00441352
Iteration 4/25 | Loss: 0.00441352
Iteration 5/25 | Loss: 0.00441352
Iteration 6/25 | Loss: 0.00441352
Iteration 7/25 | Loss: 0.00441352
Iteration 8/25 | Loss: 0.00441352
Iteration 9/25 | Loss: 0.00441352
Iteration 10/25 | Loss: 0.00441352
Iteration 11/25 | Loss: 0.00441352
Iteration 12/25 | Loss: 0.00441352
Iteration 13/25 | Loss: 0.00441352
Iteration 14/25 | Loss: 0.00441352
Iteration 15/25 | Loss: 0.00441352
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.004413520451635122, 0.004413520451635122, 0.004413520451635122, 0.004413520451635122, 0.004413520451635122]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004413520451635122

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00441352
Iteration 2/1000 | Loss: 0.00015776
Iteration 3/1000 | Loss: 0.00005948
Iteration 4/1000 | Loss: 0.00008341
Iteration 5/1000 | Loss: 0.00006731
Iteration 6/1000 | Loss: 0.00020637
Iteration 7/1000 | Loss: 0.00005228
Iteration 8/1000 | Loss: 0.00002720
Iteration 9/1000 | Loss: 0.00002312
Iteration 10/1000 | Loss: 0.00004213
Iteration 11/1000 | Loss: 0.00003933
Iteration 12/1000 | Loss: 0.00030028
Iteration 13/1000 | Loss: 0.00135231
Iteration 14/1000 | Loss: 0.00023129
Iteration 15/1000 | Loss: 0.00062452
Iteration 16/1000 | Loss: 0.00012762
Iteration 17/1000 | Loss: 0.00006245
Iteration 18/1000 | Loss: 0.00014968
Iteration 19/1000 | Loss: 0.00002227
Iteration 20/1000 | Loss: 0.00001857
Iteration 21/1000 | Loss: 0.00001784
Iteration 22/1000 | Loss: 0.00001728
Iteration 23/1000 | Loss: 0.00005656
Iteration 24/1000 | Loss: 0.00001672
Iteration 25/1000 | Loss: 0.00001647
Iteration 26/1000 | Loss: 0.00001642
Iteration 27/1000 | Loss: 0.00001622
Iteration 28/1000 | Loss: 0.00001622
Iteration 29/1000 | Loss: 0.00001621
Iteration 30/1000 | Loss: 0.00001621
Iteration 31/1000 | Loss: 0.00001616
Iteration 32/1000 | Loss: 0.00001597
Iteration 33/1000 | Loss: 0.00001594
Iteration 34/1000 | Loss: 0.00001586
Iteration 35/1000 | Loss: 0.00006235
Iteration 36/1000 | Loss: 0.00001584
Iteration 37/1000 | Loss: 0.00001577
Iteration 38/1000 | Loss: 0.00001577
Iteration 39/1000 | Loss: 0.00001575
Iteration 40/1000 | Loss: 0.00001574
Iteration 41/1000 | Loss: 0.00001573
Iteration 42/1000 | Loss: 0.00001573
Iteration 43/1000 | Loss: 0.00001572
Iteration 44/1000 | Loss: 0.00001572
Iteration 45/1000 | Loss: 0.00001572
Iteration 46/1000 | Loss: 0.00001572
Iteration 47/1000 | Loss: 0.00001571
Iteration 48/1000 | Loss: 0.00001571
Iteration 49/1000 | Loss: 0.00001571
Iteration 50/1000 | Loss: 0.00001571
Iteration 51/1000 | Loss: 0.00001571
Iteration 52/1000 | Loss: 0.00001570
Iteration 53/1000 | Loss: 0.00001569
Iteration 54/1000 | Loss: 0.00001568
Iteration 55/1000 | Loss: 0.00001566
Iteration 56/1000 | Loss: 0.00001562
Iteration 57/1000 | Loss: 0.00001562
Iteration 58/1000 | Loss: 0.00001561
Iteration 59/1000 | Loss: 0.00001561
Iteration 60/1000 | Loss: 0.00001561
Iteration 61/1000 | Loss: 0.00001561
Iteration 62/1000 | Loss: 0.00001561
Iteration 63/1000 | Loss: 0.00001561
Iteration 64/1000 | Loss: 0.00001561
Iteration 65/1000 | Loss: 0.00001560
Iteration 66/1000 | Loss: 0.00001560
Iteration 67/1000 | Loss: 0.00001559
Iteration 68/1000 | Loss: 0.00001559
Iteration 69/1000 | Loss: 0.00001558
Iteration 70/1000 | Loss: 0.00001557
Iteration 71/1000 | Loss: 0.00001556
Iteration 72/1000 | Loss: 0.00001556
Iteration 73/1000 | Loss: 0.00001555
Iteration 74/1000 | Loss: 0.00001555
Iteration 75/1000 | Loss: 0.00001554
Iteration 76/1000 | Loss: 0.00001554
Iteration 77/1000 | Loss: 0.00001553
Iteration 78/1000 | Loss: 0.00001553
Iteration 79/1000 | Loss: 0.00001552
Iteration 80/1000 | Loss: 0.00001552
Iteration 81/1000 | Loss: 0.00001552
Iteration 82/1000 | Loss: 0.00001552
Iteration 83/1000 | Loss: 0.00001552
Iteration 84/1000 | Loss: 0.00001552
Iteration 85/1000 | Loss: 0.00001552
Iteration 86/1000 | Loss: 0.00001551
Iteration 87/1000 | Loss: 0.00001551
Iteration 88/1000 | Loss: 0.00001551
Iteration 89/1000 | Loss: 0.00001551
Iteration 90/1000 | Loss: 0.00001551
Iteration 91/1000 | Loss: 0.00001550
Iteration 92/1000 | Loss: 0.00001550
Iteration 93/1000 | Loss: 0.00001550
Iteration 94/1000 | Loss: 0.00001550
Iteration 95/1000 | Loss: 0.00001550
Iteration 96/1000 | Loss: 0.00001550
Iteration 97/1000 | Loss: 0.00001550
Iteration 98/1000 | Loss: 0.00001550
Iteration 99/1000 | Loss: 0.00001549
Iteration 100/1000 | Loss: 0.00001548
Iteration 101/1000 | Loss: 0.00001548
Iteration 102/1000 | Loss: 0.00001548
Iteration 103/1000 | Loss: 0.00001547
Iteration 104/1000 | Loss: 0.00001547
Iteration 105/1000 | Loss: 0.00001547
Iteration 106/1000 | Loss: 0.00001546
Iteration 107/1000 | Loss: 0.00001546
Iteration 108/1000 | Loss: 0.00001546
Iteration 109/1000 | Loss: 0.00001546
Iteration 110/1000 | Loss: 0.00001546
Iteration 111/1000 | Loss: 0.00001545
Iteration 112/1000 | Loss: 0.00001545
Iteration 113/1000 | Loss: 0.00001545
Iteration 114/1000 | Loss: 0.00001545
Iteration 115/1000 | Loss: 0.00001544
Iteration 116/1000 | Loss: 0.00001544
Iteration 117/1000 | Loss: 0.00001544
Iteration 118/1000 | Loss: 0.00001544
Iteration 119/1000 | Loss: 0.00001544
Iteration 120/1000 | Loss: 0.00001544
Iteration 121/1000 | Loss: 0.00001543
Iteration 122/1000 | Loss: 0.00001543
Iteration 123/1000 | Loss: 0.00001543
Iteration 124/1000 | Loss: 0.00001543
Iteration 125/1000 | Loss: 0.00001543
Iteration 126/1000 | Loss: 0.00001542
Iteration 127/1000 | Loss: 0.00001542
Iteration 128/1000 | Loss: 0.00001542
Iteration 129/1000 | Loss: 0.00001541
Iteration 130/1000 | Loss: 0.00001541
Iteration 131/1000 | Loss: 0.00001541
Iteration 132/1000 | Loss: 0.00001541
Iteration 133/1000 | Loss: 0.00001541
Iteration 134/1000 | Loss: 0.00001541
Iteration 135/1000 | Loss: 0.00001541
Iteration 136/1000 | Loss: 0.00001541
Iteration 137/1000 | Loss: 0.00001541
Iteration 138/1000 | Loss: 0.00001541
Iteration 139/1000 | Loss: 0.00001541
Iteration 140/1000 | Loss: 0.00001541
Iteration 141/1000 | Loss: 0.00001541
Iteration 142/1000 | Loss: 0.00001541
Iteration 143/1000 | Loss: 0.00001541
Iteration 144/1000 | Loss: 0.00001540
Iteration 145/1000 | Loss: 0.00001540
Iteration 146/1000 | Loss: 0.00001540
Iteration 147/1000 | Loss: 0.00001540
Iteration 148/1000 | Loss: 0.00001540
Iteration 149/1000 | Loss: 0.00001540
Iteration 150/1000 | Loss: 0.00001540
Iteration 151/1000 | Loss: 0.00001540
Iteration 152/1000 | Loss: 0.00001540
Iteration 153/1000 | Loss: 0.00001539
Iteration 154/1000 | Loss: 0.00001539
Iteration 155/1000 | Loss: 0.00001539
Iteration 156/1000 | Loss: 0.00001539
Iteration 157/1000 | Loss: 0.00001539
Iteration 158/1000 | Loss: 0.00001539
Iteration 159/1000 | Loss: 0.00001538
Iteration 160/1000 | Loss: 0.00001538
Iteration 161/1000 | Loss: 0.00001538
Iteration 162/1000 | Loss: 0.00001538
Iteration 163/1000 | Loss: 0.00001538
Iteration 164/1000 | Loss: 0.00001538
Iteration 165/1000 | Loss: 0.00001538
Iteration 166/1000 | Loss: 0.00001538
Iteration 167/1000 | Loss: 0.00001538
Iteration 168/1000 | Loss: 0.00001538
Iteration 169/1000 | Loss: 0.00001538
Iteration 170/1000 | Loss: 0.00001538
Iteration 171/1000 | Loss: 0.00001538
Iteration 172/1000 | Loss: 0.00001538
Iteration 173/1000 | Loss: 0.00001538
Iteration 174/1000 | Loss: 0.00001538
Iteration 175/1000 | Loss: 0.00001538
Iteration 176/1000 | Loss: 0.00001538
Iteration 177/1000 | Loss: 0.00001538
Iteration 178/1000 | Loss: 0.00001538
Iteration 179/1000 | Loss: 0.00001538
Iteration 180/1000 | Loss: 0.00001538
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 180. Stopping optimization.
Last 5 losses: [1.5381159755634144e-05, 1.5381159755634144e-05, 1.5381159755634144e-05, 1.5381159755634144e-05, 1.5381159755634144e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5381159755634144e-05

Optimization complete. Final v2v error: 3.3312408924102783 mm

Highest mean error: 3.884134531021118 mm for frame 103

Lowest mean error: 2.8675191402435303 mm for frame 124

Saving results

Total time: 79.97608208656311
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840606
Iteration 2/25 | Loss: 0.00126802
Iteration 3/25 | Loss: 0.00118613
Iteration 4/25 | Loss: 0.00117441
Iteration 5/25 | Loss: 0.00117157
Iteration 6/25 | Loss: 0.00117072
Iteration 7/25 | Loss: 0.00117072
Iteration 8/25 | Loss: 0.00117072
Iteration 9/25 | Loss: 0.00117072
Iteration 10/25 | Loss: 0.00117072
Iteration 11/25 | Loss: 0.00117072
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0011707242811098695, 0.0011707242811098695, 0.0011707242811098695, 0.0011707242811098695, 0.0011707242811098695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011707242811098695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.00122547
Iteration 2/25 | Loss: 0.00382670
Iteration 3/25 | Loss: 0.00382669
Iteration 4/25 | Loss: 0.00382669
Iteration 5/25 | Loss: 0.00382669
Iteration 6/25 | Loss: 0.00382669
Iteration 7/25 | Loss: 0.00382669
Iteration 8/25 | Loss: 0.00382669
Iteration 9/25 | Loss: 0.00382669
Iteration 10/25 | Loss: 0.00382669
Iteration 11/25 | Loss: 0.00382669
Iteration 12/25 | Loss: 0.00382669
Iteration 13/25 | Loss: 0.00382669
Iteration 14/25 | Loss: 0.00382669
Iteration 15/25 | Loss: 0.00382669
Iteration 16/25 | Loss: 0.00382669
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.003826690837740898, 0.003826690837740898, 0.003826690837740898, 0.003826690837740898, 0.003826690837740898]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003826690837740898

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00382669
Iteration 2/1000 | Loss: 0.00002255
Iteration 3/1000 | Loss: 0.00001443
Iteration 4/1000 | Loss: 0.00001313
Iteration 5/1000 | Loss: 0.00001233
Iteration 6/1000 | Loss: 0.00001177
Iteration 7/1000 | Loss: 0.00001140
Iteration 8/1000 | Loss: 0.00001106
Iteration 9/1000 | Loss: 0.00001085
Iteration 10/1000 | Loss: 0.00001082
Iteration 11/1000 | Loss: 0.00001074
Iteration 12/1000 | Loss: 0.00001074
Iteration 13/1000 | Loss: 0.00001072
Iteration 14/1000 | Loss: 0.00001071
Iteration 15/1000 | Loss: 0.00001070
Iteration 16/1000 | Loss: 0.00001067
Iteration 17/1000 | Loss: 0.00001066
Iteration 18/1000 | Loss: 0.00001062
Iteration 19/1000 | Loss: 0.00001044
Iteration 20/1000 | Loss: 0.00001038
Iteration 21/1000 | Loss: 0.00001036
Iteration 22/1000 | Loss: 0.00001035
Iteration 23/1000 | Loss: 0.00001031
Iteration 24/1000 | Loss: 0.00001030
Iteration 25/1000 | Loss: 0.00001029
Iteration 26/1000 | Loss: 0.00001028
Iteration 27/1000 | Loss: 0.00001027
Iteration 28/1000 | Loss: 0.00001027
Iteration 29/1000 | Loss: 0.00001026
Iteration 30/1000 | Loss: 0.00001025
Iteration 31/1000 | Loss: 0.00001025
Iteration 32/1000 | Loss: 0.00001025
Iteration 33/1000 | Loss: 0.00001024
Iteration 34/1000 | Loss: 0.00001024
Iteration 35/1000 | Loss: 0.00001023
Iteration 36/1000 | Loss: 0.00001021
Iteration 37/1000 | Loss: 0.00001019
Iteration 38/1000 | Loss: 0.00001019
Iteration 39/1000 | Loss: 0.00001019
Iteration 40/1000 | Loss: 0.00001019
Iteration 41/1000 | Loss: 0.00001019
Iteration 42/1000 | Loss: 0.00001019
Iteration 43/1000 | Loss: 0.00001019
Iteration 44/1000 | Loss: 0.00001019
Iteration 45/1000 | Loss: 0.00001018
Iteration 46/1000 | Loss: 0.00001018
Iteration 47/1000 | Loss: 0.00001017
Iteration 48/1000 | Loss: 0.00001017
Iteration 49/1000 | Loss: 0.00001016
Iteration 50/1000 | Loss: 0.00001016
Iteration 51/1000 | Loss: 0.00001016
Iteration 52/1000 | Loss: 0.00001016
Iteration 53/1000 | Loss: 0.00001015
Iteration 54/1000 | Loss: 0.00001015
Iteration 55/1000 | Loss: 0.00001014
Iteration 56/1000 | Loss: 0.00001014
Iteration 57/1000 | Loss: 0.00001013
Iteration 58/1000 | Loss: 0.00001013
Iteration 59/1000 | Loss: 0.00001013
Iteration 60/1000 | Loss: 0.00001013
Iteration 61/1000 | Loss: 0.00001013
Iteration 62/1000 | Loss: 0.00001013
Iteration 63/1000 | Loss: 0.00001013
Iteration 64/1000 | Loss: 0.00001013
Iteration 65/1000 | Loss: 0.00001013
Iteration 66/1000 | Loss: 0.00001013
Iteration 67/1000 | Loss: 0.00001013
Iteration 68/1000 | Loss: 0.00001012
Iteration 69/1000 | Loss: 0.00001012
Iteration 70/1000 | Loss: 0.00001012
Iteration 71/1000 | Loss: 0.00001012
Iteration 72/1000 | Loss: 0.00001012
Iteration 73/1000 | Loss: 0.00001012
Iteration 74/1000 | Loss: 0.00001012
Iteration 75/1000 | Loss: 0.00001012
Iteration 76/1000 | Loss: 0.00001012
Iteration 77/1000 | Loss: 0.00001012
Iteration 78/1000 | Loss: 0.00001011
Iteration 79/1000 | Loss: 0.00001011
Iteration 80/1000 | Loss: 0.00001011
Iteration 81/1000 | Loss: 0.00001011
Iteration 82/1000 | Loss: 0.00001011
Iteration 83/1000 | Loss: 0.00001010
Iteration 84/1000 | Loss: 0.00001010
Iteration 85/1000 | Loss: 0.00001010
Iteration 86/1000 | Loss: 0.00001010
Iteration 87/1000 | Loss: 0.00001009
Iteration 88/1000 | Loss: 0.00001009
Iteration 89/1000 | Loss: 0.00001009
Iteration 90/1000 | Loss: 0.00001009
Iteration 91/1000 | Loss: 0.00001009
Iteration 92/1000 | Loss: 0.00001009
Iteration 93/1000 | Loss: 0.00001009
Iteration 94/1000 | Loss: 0.00001009
Iteration 95/1000 | Loss: 0.00001008
Iteration 96/1000 | Loss: 0.00001008
Iteration 97/1000 | Loss: 0.00001008
Iteration 98/1000 | Loss: 0.00001008
Iteration 99/1000 | Loss: 0.00001008
Iteration 100/1000 | Loss: 0.00001008
Iteration 101/1000 | Loss: 0.00001008
Iteration 102/1000 | Loss: 0.00001007
Iteration 103/1000 | Loss: 0.00001007
Iteration 104/1000 | Loss: 0.00001007
Iteration 105/1000 | Loss: 0.00001007
Iteration 106/1000 | Loss: 0.00001007
Iteration 107/1000 | Loss: 0.00001007
Iteration 108/1000 | Loss: 0.00001006
Iteration 109/1000 | Loss: 0.00001006
Iteration 110/1000 | Loss: 0.00001006
Iteration 111/1000 | Loss: 0.00001006
Iteration 112/1000 | Loss: 0.00001006
Iteration 113/1000 | Loss: 0.00001006
Iteration 114/1000 | Loss: 0.00001006
Iteration 115/1000 | Loss: 0.00001006
Iteration 116/1000 | Loss: 0.00001006
Iteration 117/1000 | Loss: 0.00001006
Iteration 118/1000 | Loss: 0.00001006
Iteration 119/1000 | Loss: 0.00001006
Iteration 120/1000 | Loss: 0.00001006
Iteration 121/1000 | Loss: 0.00001005
Iteration 122/1000 | Loss: 0.00001005
Iteration 123/1000 | Loss: 0.00001005
Iteration 124/1000 | Loss: 0.00001005
Iteration 125/1000 | Loss: 0.00001005
Iteration 126/1000 | Loss: 0.00001005
Iteration 127/1000 | Loss: 0.00001004
Iteration 128/1000 | Loss: 0.00001004
Iteration 129/1000 | Loss: 0.00001004
Iteration 130/1000 | Loss: 0.00001004
Iteration 131/1000 | Loss: 0.00001004
Iteration 132/1000 | Loss: 0.00001004
Iteration 133/1000 | Loss: 0.00001004
Iteration 134/1000 | Loss: 0.00001004
Iteration 135/1000 | Loss: 0.00001004
Iteration 136/1000 | Loss: 0.00001004
Iteration 137/1000 | Loss: 0.00001004
Iteration 138/1000 | Loss: 0.00001004
Iteration 139/1000 | Loss: 0.00001004
Iteration 140/1000 | Loss: 0.00001004
Iteration 141/1000 | Loss: 0.00001004
Iteration 142/1000 | Loss: 0.00001004
Iteration 143/1000 | Loss: 0.00001004
Iteration 144/1000 | Loss: 0.00001004
Iteration 145/1000 | Loss: 0.00001004
Iteration 146/1000 | Loss: 0.00001004
Iteration 147/1000 | Loss: 0.00001004
Iteration 148/1000 | Loss: 0.00001004
Iteration 149/1000 | Loss: 0.00001004
Iteration 150/1000 | Loss: 0.00001004
Iteration 151/1000 | Loss: 0.00001004
Iteration 152/1000 | Loss: 0.00001004
Iteration 153/1000 | Loss: 0.00001004
Iteration 154/1000 | Loss: 0.00001004
Iteration 155/1000 | Loss: 0.00001004
Iteration 156/1000 | Loss: 0.00001004
Iteration 157/1000 | Loss: 0.00001004
Iteration 158/1000 | Loss: 0.00001004
Iteration 159/1000 | Loss: 0.00001004
Iteration 160/1000 | Loss: 0.00001004
Iteration 161/1000 | Loss: 0.00001004
Iteration 162/1000 | Loss: 0.00001004
Iteration 163/1000 | Loss: 0.00001004
Iteration 164/1000 | Loss: 0.00001004
Iteration 165/1000 | Loss: 0.00001004
Iteration 166/1000 | Loss: 0.00001004
Iteration 167/1000 | Loss: 0.00001004
Iteration 168/1000 | Loss: 0.00001004
Iteration 169/1000 | Loss: 0.00001004
Iteration 170/1000 | Loss: 0.00001004
Iteration 171/1000 | Loss: 0.00001004
Iteration 172/1000 | Loss: 0.00001004
Iteration 173/1000 | Loss: 0.00001004
Iteration 174/1000 | Loss: 0.00001004
Iteration 175/1000 | Loss: 0.00001004
Iteration 176/1000 | Loss: 0.00001004
Iteration 177/1000 | Loss: 0.00001004
Iteration 178/1000 | Loss: 0.00001004
Iteration 179/1000 | Loss: 0.00001004
Iteration 180/1000 | Loss: 0.00001004
Iteration 181/1000 | Loss: 0.00001004
Iteration 182/1000 | Loss: 0.00001004
Iteration 183/1000 | Loss: 0.00001004
Iteration 184/1000 | Loss: 0.00001004
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 184. Stopping optimization.
Last 5 losses: [1.0039640073955525e-05, 1.0039640073955525e-05, 1.0039640073955525e-05, 1.0039640073955525e-05, 1.0039640073955525e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0039640073955525e-05

Optimization complete. Final v2v error: 2.7325658798217773 mm

Highest mean error: 3.089102029800415 mm for frame 115

Lowest mean error: 2.3925201892852783 mm for frame 139

Saving results

Total time: 34.5592041015625
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00814883
Iteration 2/25 | Loss: 0.00137315
Iteration 3/25 | Loss: 0.00121761
Iteration 4/25 | Loss: 0.00119954
Iteration 5/25 | Loss: 0.00119657
Iteration 6/25 | Loss: 0.00119624
Iteration 7/25 | Loss: 0.00119624
Iteration 8/25 | Loss: 0.00119624
Iteration 9/25 | Loss: 0.00119624
Iteration 10/25 | Loss: 0.00119624
Iteration 11/25 | Loss: 0.00119624
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001196238910779357, 0.001196238910779357, 0.001196238910779357, 0.001196238910779357, 0.001196238910779357]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001196238910779357

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.05037999
Iteration 2/25 | Loss: 0.00420781
Iteration 3/25 | Loss: 0.00420779
Iteration 4/25 | Loss: 0.00420779
Iteration 5/25 | Loss: 0.00420779
Iteration 6/25 | Loss: 0.00420779
Iteration 7/25 | Loss: 0.00420779
Iteration 8/25 | Loss: 0.00420779
Iteration 9/25 | Loss: 0.00420779
Iteration 10/25 | Loss: 0.00420779
Iteration 11/25 | Loss: 0.00420779
Iteration 12/25 | Loss: 0.00420779
Iteration 13/25 | Loss: 0.00420779
Iteration 14/25 | Loss: 0.00420779
Iteration 15/25 | Loss: 0.00420779
Iteration 16/25 | Loss: 0.00420779
Iteration 17/25 | Loss: 0.00420779
Iteration 18/25 | Loss: 0.00420779
Iteration 19/25 | Loss: 0.00420779
Iteration 20/25 | Loss: 0.00420779
Iteration 21/25 | Loss: 0.00420779
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.004207787103950977, 0.004207787103950977, 0.004207787103950977, 0.004207787103950977, 0.004207787103950977]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004207787103950977

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00420779
Iteration 2/1000 | Loss: 0.00003419
Iteration 3/1000 | Loss: 0.00002222
Iteration 4/1000 | Loss: 0.00001769
Iteration 5/1000 | Loss: 0.00001618
Iteration 6/1000 | Loss: 0.00001511
Iteration 7/1000 | Loss: 0.00001433
Iteration 8/1000 | Loss: 0.00001398
Iteration 9/1000 | Loss: 0.00001368
Iteration 10/1000 | Loss: 0.00001339
Iteration 11/1000 | Loss: 0.00001307
Iteration 12/1000 | Loss: 0.00001283
Iteration 13/1000 | Loss: 0.00001267
Iteration 14/1000 | Loss: 0.00001261
Iteration 15/1000 | Loss: 0.00001253
Iteration 16/1000 | Loss: 0.00001243
Iteration 17/1000 | Loss: 0.00001236
Iteration 18/1000 | Loss: 0.00001236
Iteration 19/1000 | Loss: 0.00001235
Iteration 20/1000 | Loss: 0.00001234
Iteration 21/1000 | Loss: 0.00001233
Iteration 22/1000 | Loss: 0.00001230
Iteration 23/1000 | Loss: 0.00001223
Iteration 24/1000 | Loss: 0.00001216
Iteration 25/1000 | Loss: 0.00001207
Iteration 26/1000 | Loss: 0.00001204
Iteration 27/1000 | Loss: 0.00001204
Iteration 28/1000 | Loss: 0.00001203
Iteration 29/1000 | Loss: 0.00001203
Iteration 30/1000 | Loss: 0.00001202
Iteration 31/1000 | Loss: 0.00001201
Iteration 32/1000 | Loss: 0.00001199
Iteration 33/1000 | Loss: 0.00001198
Iteration 34/1000 | Loss: 0.00001198
Iteration 35/1000 | Loss: 0.00001197
Iteration 36/1000 | Loss: 0.00001197
Iteration 37/1000 | Loss: 0.00001196
Iteration 38/1000 | Loss: 0.00001196
Iteration 39/1000 | Loss: 0.00001196
Iteration 40/1000 | Loss: 0.00001196
Iteration 41/1000 | Loss: 0.00001196
Iteration 42/1000 | Loss: 0.00001195
Iteration 43/1000 | Loss: 0.00001194
Iteration 44/1000 | Loss: 0.00001193
Iteration 45/1000 | Loss: 0.00001192
Iteration 46/1000 | Loss: 0.00001192
Iteration 47/1000 | Loss: 0.00001192
Iteration 48/1000 | Loss: 0.00001192
Iteration 49/1000 | Loss: 0.00001192
Iteration 50/1000 | Loss: 0.00001192
Iteration 51/1000 | Loss: 0.00001192
Iteration 52/1000 | Loss: 0.00001192
Iteration 53/1000 | Loss: 0.00001192
Iteration 54/1000 | Loss: 0.00001192
Iteration 55/1000 | Loss: 0.00001192
Iteration 56/1000 | Loss: 0.00001191
Iteration 57/1000 | Loss: 0.00001191
Iteration 58/1000 | Loss: 0.00001191
Iteration 59/1000 | Loss: 0.00001190
Iteration 60/1000 | Loss: 0.00001190
Iteration 61/1000 | Loss: 0.00001189
Iteration 62/1000 | Loss: 0.00001189
Iteration 63/1000 | Loss: 0.00001189
Iteration 64/1000 | Loss: 0.00001189
Iteration 65/1000 | Loss: 0.00001189
Iteration 66/1000 | Loss: 0.00001189
Iteration 67/1000 | Loss: 0.00001189
Iteration 68/1000 | Loss: 0.00001189
Iteration 69/1000 | Loss: 0.00001189
Iteration 70/1000 | Loss: 0.00001188
Iteration 71/1000 | Loss: 0.00001188
Iteration 72/1000 | Loss: 0.00001188
Iteration 73/1000 | Loss: 0.00001188
Iteration 74/1000 | Loss: 0.00001187
Iteration 75/1000 | Loss: 0.00001187
Iteration 76/1000 | Loss: 0.00001186
Iteration 77/1000 | Loss: 0.00001186
Iteration 78/1000 | Loss: 0.00001186
Iteration 79/1000 | Loss: 0.00001185
Iteration 80/1000 | Loss: 0.00001185
Iteration 81/1000 | Loss: 0.00001185
Iteration 82/1000 | Loss: 0.00001185
Iteration 83/1000 | Loss: 0.00001184
Iteration 84/1000 | Loss: 0.00001184
Iteration 85/1000 | Loss: 0.00001184
Iteration 86/1000 | Loss: 0.00001184
Iteration 87/1000 | Loss: 0.00001184
Iteration 88/1000 | Loss: 0.00001183
Iteration 89/1000 | Loss: 0.00001183
Iteration 90/1000 | Loss: 0.00001183
Iteration 91/1000 | Loss: 0.00001183
Iteration 92/1000 | Loss: 0.00001182
Iteration 93/1000 | Loss: 0.00001182
Iteration 94/1000 | Loss: 0.00001182
Iteration 95/1000 | Loss: 0.00001181
Iteration 96/1000 | Loss: 0.00001181
Iteration 97/1000 | Loss: 0.00001181
Iteration 98/1000 | Loss: 0.00001180
Iteration 99/1000 | Loss: 0.00001180
Iteration 100/1000 | Loss: 0.00001180
Iteration 101/1000 | Loss: 0.00001180
Iteration 102/1000 | Loss: 0.00001179
Iteration 103/1000 | Loss: 0.00001179
Iteration 104/1000 | Loss: 0.00001179
Iteration 105/1000 | Loss: 0.00001179
Iteration 106/1000 | Loss: 0.00001179
Iteration 107/1000 | Loss: 0.00001179
Iteration 108/1000 | Loss: 0.00001178
Iteration 109/1000 | Loss: 0.00001178
Iteration 110/1000 | Loss: 0.00001178
Iteration 111/1000 | Loss: 0.00001178
Iteration 112/1000 | Loss: 0.00001178
Iteration 113/1000 | Loss: 0.00001177
Iteration 114/1000 | Loss: 0.00001177
Iteration 115/1000 | Loss: 0.00001177
Iteration 116/1000 | Loss: 0.00001177
Iteration 117/1000 | Loss: 0.00001177
Iteration 118/1000 | Loss: 0.00001177
Iteration 119/1000 | Loss: 0.00001176
Iteration 120/1000 | Loss: 0.00001176
Iteration 121/1000 | Loss: 0.00001176
Iteration 122/1000 | Loss: 0.00001175
Iteration 123/1000 | Loss: 0.00001175
Iteration 124/1000 | Loss: 0.00001175
Iteration 125/1000 | Loss: 0.00001174
Iteration 126/1000 | Loss: 0.00001174
Iteration 127/1000 | Loss: 0.00001173
Iteration 128/1000 | Loss: 0.00001173
Iteration 129/1000 | Loss: 0.00001173
Iteration 130/1000 | Loss: 0.00001173
Iteration 131/1000 | Loss: 0.00001173
Iteration 132/1000 | Loss: 0.00001173
Iteration 133/1000 | Loss: 0.00001173
Iteration 134/1000 | Loss: 0.00001173
Iteration 135/1000 | Loss: 0.00001172
Iteration 136/1000 | Loss: 0.00001172
Iteration 137/1000 | Loss: 0.00001172
Iteration 138/1000 | Loss: 0.00001172
Iteration 139/1000 | Loss: 0.00001172
Iteration 140/1000 | Loss: 0.00001172
Iteration 141/1000 | Loss: 0.00001172
Iteration 142/1000 | Loss: 0.00001172
Iteration 143/1000 | Loss: 0.00001172
Iteration 144/1000 | Loss: 0.00001171
Iteration 145/1000 | Loss: 0.00001171
Iteration 146/1000 | Loss: 0.00001171
Iteration 147/1000 | Loss: 0.00001171
Iteration 148/1000 | Loss: 0.00001171
Iteration 149/1000 | Loss: 0.00001170
Iteration 150/1000 | Loss: 0.00001170
Iteration 151/1000 | Loss: 0.00001170
Iteration 152/1000 | Loss: 0.00001170
Iteration 153/1000 | Loss: 0.00001170
Iteration 154/1000 | Loss: 0.00001170
Iteration 155/1000 | Loss: 0.00001170
Iteration 156/1000 | Loss: 0.00001170
Iteration 157/1000 | Loss: 0.00001170
Iteration 158/1000 | Loss: 0.00001170
Iteration 159/1000 | Loss: 0.00001170
Iteration 160/1000 | Loss: 0.00001170
Iteration 161/1000 | Loss: 0.00001170
Iteration 162/1000 | Loss: 0.00001170
Iteration 163/1000 | Loss: 0.00001170
Iteration 164/1000 | Loss: 0.00001170
Iteration 165/1000 | Loss: 0.00001170
Iteration 166/1000 | Loss: 0.00001170
Iteration 167/1000 | Loss: 0.00001170
Iteration 168/1000 | Loss: 0.00001170
Iteration 169/1000 | Loss: 0.00001170
Iteration 170/1000 | Loss: 0.00001170
Iteration 171/1000 | Loss: 0.00001170
Iteration 172/1000 | Loss: 0.00001170
Iteration 173/1000 | Loss: 0.00001170
Iteration 174/1000 | Loss: 0.00001170
Iteration 175/1000 | Loss: 0.00001170
Iteration 176/1000 | Loss: 0.00001170
Iteration 177/1000 | Loss: 0.00001170
Iteration 178/1000 | Loss: 0.00001170
Iteration 179/1000 | Loss: 0.00001170
Iteration 180/1000 | Loss: 0.00001170
Iteration 181/1000 | Loss: 0.00001170
Iteration 182/1000 | Loss: 0.00001170
Iteration 183/1000 | Loss: 0.00001170
Iteration 184/1000 | Loss: 0.00001170
Iteration 185/1000 | Loss: 0.00001170
Iteration 186/1000 | Loss: 0.00001170
Iteration 187/1000 | Loss: 0.00001170
Iteration 188/1000 | Loss: 0.00001170
Iteration 189/1000 | Loss: 0.00001170
Iteration 190/1000 | Loss: 0.00001170
Iteration 191/1000 | Loss: 0.00001170
Iteration 192/1000 | Loss: 0.00001170
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 192. Stopping optimization.
Last 5 losses: [1.1698014532157686e-05, 1.1698014532157686e-05, 1.1698014532157686e-05, 1.1698014532157686e-05, 1.1698014532157686e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1698014532157686e-05

Optimization complete. Final v2v error: 2.817758083343506 mm

Highest mean error: 3.785665512084961 mm for frame 158

Lowest mean error: 2.1743342876434326 mm for frame 222

Saving results

Total time: 50.062021017074585
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00413368
Iteration 2/25 | Loss: 0.00128545
Iteration 3/25 | Loss: 0.00121501
Iteration 4/25 | Loss: 0.00120256
Iteration 5/25 | Loss: 0.00119879
Iteration 6/25 | Loss: 0.00119736
Iteration 7/25 | Loss: 0.00119726
Iteration 8/25 | Loss: 0.00119726
Iteration 9/25 | Loss: 0.00119726
Iteration 10/25 | Loss: 0.00119726
Iteration 11/25 | Loss: 0.00119726
Iteration 12/25 | Loss: 0.00119726
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011972628999501467, 0.0011972628999501467, 0.0011972628999501467, 0.0011972628999501467, 0.0011972628999501467]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011972628999501467

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48383462
Iteration 2/25 | Loss: 0.00398022
Iteration 3/25 | Loss: 0.00398022
Iteration 4/25 | Loss: 0.00398022
Iteration 5/25 | Loss: 0.00398021
Iteration 6/25 | Loss: 0.00398021
Iteration 7/25 | Loss: 0.00398021
Iteration 8/25 | Loss: 0.00398021
Iteration 9/25 | Loss: 0.00398021
Iteration 10/25 | Loss: 0.00398021
Iteration 11/25 | Loss: 0.00398021
Iteration 12/25 | Loss: 0.00398021
Iteration 13/25 | Loss: 0.00398021
Iteration 14/25 | Loss: 0.00398021
Iteration 15/25 | Loss: 0.00398021
Iteration 16/25 | Loss: 0.00398021
Iteration 17/25 | Loss: 0.00398021
Iteration 18/25 | Loss: 0.00398021
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00398021237924695, 0.00398021237924695, 0.00398021237924695, 0.00398021237924695, 0.00398021237924695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00398021237924695

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00398021
Iteration 2/1000 | Loss: 0.00003055
Iteration 3/1000 | Loss: 0.00001808
Iteration 4/1000 | Loss: 0.00001617
Iteration 5/1000 | Loss: 0.00001516
Iteration 6/1000 | Loss: 0.00001417
Iteration 7/1000 | Loss: 0.00001376
Iteration 8/1000 | Loss: 0.00001326
Iteration 9/1000 | Loss: 0.00001293
Iteration 10/1000 | Loss: 0.00001273
Iteration 11/1000 | Loss: 0.00001260
Iteration 12/1000 | Loss: 0.00001254
Iteration 13/1000 | Loss: 0.00001249
Iteration 14/1000 | Loss: 0.00001248
Iteration 15/1000 | Loss: 0.00001242
Iteration 16/1000 | Loss: 0.00001239
Iteration 17/1000 | Loss: 0.00001238
Iteration 18/1000 | Loss: 0.00001238
Iteration 19/1000 | Loss: 0.00001236
Iteration 20/1000 | Loss: 0.00001235
Iteration 21/1000 | Loss: 0.00001234
Iteration 22/1000 | Loss: 0.00001233
Iteration 23/1000 | Loss: 0.00001232
Iteration 24/1000 | Loss: 0.00001227
Iteration 25/1000 | Loss: 0.00001224
Iteration 26/1000 | Loss: 0.00001223
Iteration 27/1000 | Loss: 0.00001222
Iteration 28/1000 | Loss: 0.00001222
Iteration 29/1000 | Loss: 0.00001217
Iteration 30/1000 | Loss: 0.00001217
Iteration 31/1000 | Loss: 0.00001216
Iteration 32/1000 | Loss: 0.00001215
Iteration 33/1000 | Loss: 0.00001215
Iteration 34/1000 | Loss: 0.00001215
Iteration 35/1000 | Loss: 0.00001215
Iteration 36/1000 | Loss: 0.00001214
Iteration 37/1000 | Loss: 0.00001214
Iteration 38/1000 | Loss: 0.00001214
Iteration 39/1000 | Loss: 0.00001214
Iteration 40/1000 | Loss: 0.00001214
Iteration 41/1000 | Loss: 0.00001213
Iteration 42/1000 | Loss: 0.00001213
Iteration 43/1000 | Loss: 0.00001213
Iteration 44/1000 | Loss: 0.00001213
Iteration 45/1000 | Loss: 0.00001213
Iteration 46/1000 | Loss: 0.00001211
Iteration 47/1000 | Loss: 0.00001211
Iteration 48/1000 | Loss: 0.00001211
Iteration 49/1000 | Loss: 0.00001211
Iteration 50/1000 | Loss: 0.00001211
Iteration 51/1000 | Loss: 0.00001210
Iteration 52/1000 | Loss: 0.00001210
Iteration 53/1000 | Loss: 0.00001210
Iteration 54/1000 | Loss: 0.00001210
Iteration 55/1000 | Loss: 0.00001210
Iteration 56/1000 | Loss: 0.00001210
Iteration 57/1000 | Loss: 0.00001209
Iteration 58/1000 | Loss: 0.00001209
Iteration 59/1000 | Loss: 0.00001209
Iteration 60/1000 | Loss: 0.00001209
Iteration 61/1000 | Loss: 0.00001209
Iteration 62/1000 | Loss: 0.00001209
Iteration 63/1000 | Loss: 0.00001208
Iteration 64/1000 | Loss: 0.00001208
Iteration 65/1000 | Loss: 0.00001208
Iteration 66/1000 | Loss: 0.00001208
Iteration 67/1000 | Loss: 0.00001207
Iteration 68/1000 | Loss: 0.00001207
Iteration 69/1000 | Loss: 0.00001207
Iteration 70/1000 | Loss: 0.00001207
Iteration 71/1000 | Loss: 0.00001206
Iteration 72/1000 | Loss: 0.00001206
Iteration 73/1000 | Loss: 0.00001206
Iteration 74/1000 | Loss: 0.00001206
Iteration 75/1000 | Loss: 0.00001206
Iteration 76/1000 | Loss: 0.00001205
Iteration 77/1000 | Loss: 0.00001205
Iteration 78/1000 | Loss: 0.00001205
Iteration 79/1000 | Loss: 0.00001205
Iteration 80/1000 | Loss: 0.00001204
Iteration 81/1000 | Loss: 0.00001204
Iteration 82/1000 | Loss: 0.00001204
Iteration 83/1000 | Loss: 0.00001204
Iteration 84/1000 | Loss: 0.00001203
Iteration 85/1000 | Loss: 0.00001203
Iteration 86/1000 | Loss: 0.00001203
Iteration 87/1000 | Loss: 0.00001202
Iteration 88/1000 | Loss: 0.00001202
Iteration 89/1000 | Loss: 0.00001202
Iteration 90/1000 | Loss: 0.00001202
Iteration 91/1000 | Loss: 0.00001201
Iteration 92/1000 | Loss: 0.00001201
Iteration 93/1000 | Loss: 0.00001201
Iteration 94/1000 | Loss: 0.00001201
Iteration 95/1000 | Loss: 0.00001200
Iteration 96/1000 | Loss: 0.00001200
Iteration 97/1000 | Loss: 0.00001200
Iteration 98/1000 | Loss: 0.00001200
Iteration 99/1000 | Loss: 0.00001200
Iteration 100/1000 | Loss: 0.00001200
Iteration 101/1000 | Loss: 0.00001200
Iteration 102/1000 | Loss: 0.00001200
Iteration 103/1000 | Loss: 0.00001200
Iteration 104/1000 | Loss: 0.00001199
Iteration 105/1000 | Loss: 0.00001199
Iteration 106/1000 | Loss: 0.00001199
Iteration 107/1000 | Loss: 0.00001199
Iteration 108/1000 | Loss: 0.00001199
Iteration 109/1000 | Loss: 0.00001199
Iteration 110/1000 | Loss: 0.00001199
Iteration 111/1000 | Loss: 0.00001198
Iteration 112/1000 | Loss: 0.00001198
Iteration 113/1000 | Loss: 0.00001198
Iteration 114/1000 | Loss: 0.00001198
Iteration 115/1000 | Loss: 0.00001198
Iteration 116/1000 | Loss: 0.00001197
Iteration 117/1000 | Loss: 0.00001197
Iteration 118/1000 | Loss: 0.00001197
Iteration 119/1000 | Loss: 0.00001197
Iteration 120/1000 | Loss: 0.00001197
Iteration 121/1000 | Loss: 0.00001197
Iteration 122/1000 | Loss: 0.00001196
Iteration 123/1000 | Loss: 0.00001196
Iteration 124/1000 | Loss: 0.00001196
Iteration 125/1000 | Loss: 0.00001196
Iteration 126/1000 | Loss: 0.00001195
Iteration 127/1000 | Loss: 0.00001195
Iteration 128/1000 | Loss: 0.00001195
Iteration 129/1000 | Loss: 0.00001195
Iteration 130/1000 | Loss: 0.00001195
Iteration 131/1000 | Loss: 0.00001195
Iteration 132/1000 | Loss: 0.00001195
Iteration 133/1000 | Loss: 0.00001195
Iteration 134/1000 | Loss: 0.00001194
Iteration 135/1000 | Loss: 0.00001194
Iteration 136/1000 | Loss: 0.00001194
Iteration 137/1000 | Loss: 0.00001194
Iteration 138/1000 | Loss: 0.00001194
Iteration 139/1000 | Loss: 0.00001194
Iteration 140/1000 | Loss: 0.00001194
Iteration 141/1000 | Loss: 0.00001194
Iteration 142/1000 | Loss: 0.00001194
Iteration 143/1000 | Loss: 0.00001194
Iteration 144/1000 | Loss: 0.00001194
Iteration 145/1000 | Loss: 0.00001194
Iteration 146/1000 | Loss: 0.00001194
Iteration 147/1000 | Loss: 0.00001193
Iteration 148/1000 | Loss: 0.00001193
Iteration 149/1000 | Loss: 0.00001193
Iteration 150/1000 | Loss: 0.00001192
Iteration 151/1000 | Loss: 0.00001192
Iteration 152/1000 | Loss: 0.00001192
Iteration 153/1000 | Loss: 0.00001192
Iteration 154/1000 | Loss: 0.00001192
Iteration 155/1000 | Loss: 0.00001192
Iteration 156/1000 | Loss: 0.00001192
Iteration 157/1000 | Loss: 0.00001192
Iteration 158/1000 | Loss: 0.00001192
Iteration 159/1000 | Loss: 0.00001192
Iteration 160/1000 | Loss: 0.00001191
Iteration 161/1000 | Loss: 0.00001191
Iteration 162/1000 | Loss: 0.00001191
Iteration 163/1000 | Loss: 0.00001191
Iteration 164/1000 | Loss: 0.00001191
Iteration 165/1000 | Loss: 0.00001191
Iteration 166/1000 | Loss: 0.00001191
Iteration 167/1000 | Loss: 0.00001191
Iteration 168/1000 | Loss: 0.00001190
Iteration 169/1000 | Loss: 0.00001190
Iteration 170/1000 | Loss: 0.00001190
Iteration 171/1000 | Loss: 0.00001190
Iteration 172/1000 | Loss: 0.00001190
Iteration 173/1000 | Loss: 0.00001190
Iteration 174/1000 | Loss: 0.00001190
Iteration 175/1000 | Loss: 0.00001190
Iteration 176/1000 | Loss: 0.00001190
Iteration 177/1000 | Loss: 0.00001190
Iteration 178/1000 | Loss: 0.00001190
Iteration 179/1000 | Loss: 0.00001189
Iteration 180/1000 | Loss: 0.00001189
Iteration 181/1000 | Loss: 0.00001189
Iteration 182/1000 | Loss: 0.00001189
Iteration 183/1000 | Loss: 0.00001189
Iteration 184/1000 | Loss: 0.00001189
Iteration 185/1000 | Loss: 0.00001189
Iteration 186/1000 | Loss: 0.00001189
Iteration 187/1000 | Loss: 0.00001189
Iteration 188/1000 | Loss: 0.00001189
Iteration 189/1000 | Loss: 0.00001189
Iteration 190/1000 | Loss: 0.00001189
Iteration 191/1000 | Loss: 0.00001189
Iteration 192/1000 | Loss: 0.00001189
Iteration 193/1000 | Loss: 0.00001188
Iteration 194/1000 | Loss: 0.00001188
Iteration 195/1000 | Loss: 0.00001188
Iteration 196/1000 | Loss: 0.00001188
Iteration 197/1000 | Loss: 0.00001188
Iteration 198/1000 | Loss: 0.00001188
Iteration 199/1000 | Loss: 0.00001187
Iteration 200/1000 | Loss: 0.00001187
Iteration 201/1000 | Loss: 0.00001187
Iteration 202/1000 | Loss: 0.00001187
Iteration 203/1000 | Loss: 0.00001187
Iteration 204/1000 | Loss: 0.00001187
Iteration 205/1000 | Loss: 0.00001187
Iteration 206/1000 | Loss: 0.00001187
Iteration 207/1000 | Loss: 0.00001187
Iteration 208/1000 | Loss: 0.00001187
Iteration 209/1000 | Loss: 0.00001187
Iteration 210/1000 | Loss: 0.00001187
Iteration 211/1000 | Loss: 0.00001187
Iteration 212/1000 | Loss: 0.00001187
Iteration 213/1000 | Loss: 0.00001187
Iteration 214/1000 | Loss: 0.00001187
Iteration 215/1000 | Loss: 0.00001186
Iteration 216/1000 | Loss: 0.00001186
Iteration 217/1000 | Loss: 0.00001186
Iteration 218/1000 | Loss: 0.00001186
Iteration 219/1000 | Loss: 0.00001186
Iteration 220/1000 | Loss: 0.00001186
Iteration 221/1000 | Loss: 0.00001186
Iteration 222/1000 | Loss: 0.00001186
Iteration 223/1000 | Loss: 0.00001186
Iteration 224/1000 | Loss: 0.00001186
Iteration 225/1000 | Loss: 0.00001186
Iteration 226/1000 | Loss: 0.00001186
Iteration 227/1000 | Loss: 0.00001185
Iteration 228/1000 | Loss: 0.00001185
Iteration 229/1000 | Loss: 0.00001185
Iteration 230/1000 | Loss: 0.00001185
Iteration 231/1000 | Loss: 0.00001185
Iteration 232/1000 | Loss: 0.00001185
Iteration 233/1000 | Loss: 0.00001185
Iteration 234/1000 | Loss: 0.00001185
Iteration 235/1000 | Loss: 0.00001185
Iteration 236/1000 | Loss: 0.00001184
Iteration 237/1000 | Loss: 0.00001184
Iteration 238/1000 | Loss: 0.00001184
Iteration 239/1000 | Loss: 0.00001184
Iteration 240/1000 | Loss: 0.00001184
Iteration 241/1000 | Loss: 0.00001184
Iteration 242/1000 | Loss: 0.00001184
Iteration 243/1000 | Loss: 0.00001184
Iteration 244/1000 | Loss: 0.00001184
Iteration 245/1000 | Loss: 0.00001184
Iteration 246/1000 | Loss: 0.00001184
Iteration 247/1000 | Loss: 0.00001184
Iteration 248/1000 | Loss: 0.00001184
Iteration 249/1000 | Loss: 0.00001184
Iteration 250/1000 | Loss: 0.00001184
Iteration 251/1000 | Loss: 0.00001183
Iteration 252/1000 | Loss: 0.00001183
Iteration 253/1000 | Loss: 0.00001183
Iteration 254/1000 | Loss: 0.00001183
Iteration 255/1000 | Loss: 0.00001183
Iteration 256/1000 | Loss: 0.00001183
Iteration 257/1000 | Loss: 0.00001183
Iteration 258/1000 | Loss: 0.00001183
Iteration 259/1000 | Loss: 0.00001183
Iteration 260/1000 | Loss: 0.00001183
Iteration 261/1000 | Loss: 0.00001183
Iteration 262/1000 | Loss: 0.00001183
Iteration 263/1000 | Loss: 0.00001183
Iteration 264/1000 | Loss: 0.00001183
Iteration 265/1000 | Loss: 0.00001183
Iteration 266/1000 | Loss: 0.00001183
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 266. Stopping optimization.
Last 5 losses: [1.1829515642602928e-05, 1.1829515642602928e-05, 1.1829515642602928e-05, 1.1829515642602928e-05, 1.1829515642602928e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1829515642602928e-05

Optimization complete. Final v2v error: 2.970325231552124 mm

Highest mean error: 4.245187282562256 mm for frame 73

Lowest mean error: 2.4381556510925293 mm for frame 103

Saving results

Total time: 43.834513664245605
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00555563
Iteration 2/25 | Loss: 0.00133447
Iteration 3/25 | Loss: 0.00124330
Iteration 4/25 | Loss: 0.00122307
Iteration 5/25 | Loss: 0.00121691
Iteration 6/25 | Loss: 0.00121537
Iteration 7/25 | Loss: 0.00121508
Iteration 8/25 | Loss: 0.00121508
Iteration 9/25 | Loss: 0.00121508
Iteration 10/25 | Loss: 0.00121508
Iteration 11/25 | Loss: 0.00121508
Iteration 12/25 | Loss: 0.00121508
Iteration 13/25 | Loss: 0.00121508
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0012150778202340007, 0.0012150778202340007, 0.0012150778202340007, 0.0012150778202340007, 0.0012150778202340007]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012150778202340007

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.81429893
Iteration 2/25 | Loss: 0.00224289
Iteration 3/25 | Loss: 0.00224289
Iteration 4/25 | Loss: 0.00224289
Iteration 5/25 | Loss: 0.00224289
Iteration 6/25 | Loss: 0.00224289
Iteration 7/25 | Loss: 0.00224289
Iteration 8/25 | Loss: 0.00224289
Iteration 9/25 | Loss: 0.00224289
Iteration 10/25 | Loss: 0.00224289
Iteration 11/25 | Loss: 0.00224289
Iteration 12/25 | Loss: 0.00224289
Iteration 13/25 | Loss: 0.00224289
Iteration 14/25 | Loss: 0.00224289
Iteration 15/25 | Loss: 0.00224289
Iteration 16/25 | Loss: 0.00224289
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0022428890224546194, 0.0022428890224546194, 0.0022428890224546194, 0.0022428890224546194, 0.0022428890224546194]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0022428890224546194

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00224289
Iteration 2/1000 | Loss: 0.00004221
Iteration 3/1000 | Loss: 0.00003394
Iteration 4/1000 | Loss: 0.00003059
Iteration 5/1000 | Loss: 0.00002831
Iteration 6/1000 | Loss: 0.00002728
Iteration 7/1000 | Loss: 0.00002689
Iteration 8/1000 | Loss: 0.00002637
Iteration 9/1000 | Loss: 0.00002607
Iteration 10/1000 | Loss: 0.00002583
Iteration 11/1000 | Loss: 0.00002572
Iteration 12/1000 | Loss: 0.00002570
Iteration 13/1000 | Loss: 0.00002551
Iteration 14/1000 | Loss: 0.00002546
Iteration 15/1000 | Loss: 0.00002540
Iteration 16/1000 | Loss: 0.00002539
Iteration 17/1000 | Loss: 0.00002538
Iteration 18/1000 | Loss: 0.00002538
Iteration 19/1000 | Loss: 0.00002532
Iteration 20/1000 | Loss: 0.00002529
Iteration 21/1000 | Loss: 0.00002527
Iteration 22/1000 | Loss: 0.00002526
Iteration 23/1000 | Loss: 0.00002526
Iteration 24/1000 | Loss: 0.00002526
Iteration 25/1000 | Loss: 0.00002526
Iteration 26/1000 | Loss: 0.00002525
Iteration 27/1000 | Loss: 0.00002525
Iteration 28/1000 | Loss: 0.00002524
Iteration 29/1000 | Loss: 0.00002524
Iteration 30/1000 | Loss: 0.00002524
Iteration 31/1000 | Loss: 0.00002524
Iteration 32/1000 | Loss: 0.00002524
Iteration 33/1000 | Loss: 0.00002523
Iteration 34/1000 | Loss: 0.00002523
Iteration 35/1000 | Loss: 0.00002523
Iteration 36/1000 | Loss: 0.00002522
Iteration 37/1000 | Loss: 0.00002522
Iteration 38/1000 | Loss: 0.00002522
Iteration 39/1000 | Loss: 0.00002522
Iteration 40/1000 | Loss: 0.00002522
Iteration 41/1000 | Loss: 0.00002522
Iteration 42/1000 | Loss: 0.00002522
Iteration 43/1000 | Loss: 0.00002522
Iteration 44/1000 | Loss: 0.00002522
Iteration 45/1000 | Loss: 0.00002520
Iteration 46/1000 | Loss: 0.00002520
Iteration 47/1000 | Loss: 0.00002520
Iteration 48/1000 | Loss: 0.00002520
Iteration 49/1000 | Loss: 0.00002519
Iteration 50/1000 | Loss: 0.00002519
Iteration 51/1000 | Loss: 0.00002519
Iteration 52/1000 | Loss: 0.00002519
Iteration 53/1000 | Loss: 0.00002519
Iteration 54/1000 | Loss: 0.00002518
Iteration 55/1000 | Loss: 0.00002518
Iteration 56/1000 | Loss: 0.00002518
Iteration 57/1000 | Loss: 0.00002518
Iteration 58/1000 | Loss: 0.00002518
Iteration 59/1000 | Loss: 0.00002518
Iteration 60/1000 | Loss: 0.00002518
Iteration 61/1000 | Loss: 0.00002518
Iteration 62/1000 | Loss: 0.00002518
Iteration 63/1000 | Loss: 0.00002518
Iteration 64/1000 | Loss: 0.00002518
Iteration 65/1000 | Loss: 0.00002518
Iteration 66/1000 | Loss: 0.00002518
Iteration 67/1000 | Loss: 0.00002518
Iteration 68/1000 | Loss: 0.00002518
Iteration 69/1000 | Loss: 0.00002518
Iteration 70/1000 | Loss: 0.00002518
Iteration 71/1000 | Loss: 0.00002518
Iteration 72/1000 | Loss: 0.00002518
Iteration 73/1000 | Loss: 0.00002518
Iteration 74/1000 | Loss: 0.00002518
Iteration 75/1000 | Loss: 0.00002518
Iteration 76/1000 | Loss: 0.00002518
Iteration 77/1000 | Loss: 0.00002518
Iteration 78/1000 | Loss: 0.00002518
Iteration 79/1000 | Loss: 0.00002518
Iteration 80/1000 | Loss: 0.00002518
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 80. Stopping optimization.
Last 5 losses: [2.5181929231621325e-05, 2.5181929231621325e-05, 2.5181929231621325e-05, 2.5181929231621325e-05, 2.5181929231621325e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5181929231621325e-05

Optimization complete. Final v2v error: 4.348417282104492 mm

Highest mean error: 4.473721504211426 mm for frame 12

Lowest mean error: 4.204824924468994 mm for frame 143

Saving results

Total time: 30.839810609817505
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01056986
Iteration 2/25 | Loss: 0.00237277
Iteration 3/25 | Loss: 0.00177666
Iteration 4/25 | Loss: 0.00169923
Iteration 5/25 | Loss: 0.00159316
Iteration 6/25 | Loss: 0.00171768
Iteration 7/25 | Loss: 0.00164088
Iteration 8/25 | Loss: 0.00148222
Iteration 9/25 | Loss: 0.00137296
Iteration 10/25 | Loss: 0.00130746
Iteration 11/25 | Loss: 0.00135122
Iteration 12/25 | Loss: 0.00130269
Iteration 13/25 | Loss: 0.00129154
Iteration 14/25 | Loss: 0.00127412
Iteration 15/25 | Loss: 0.00127068
Iteration 16/25 | Loss: 0.00126858
Iteration 17/25 | Loss: 0.00126749
Iteration 18/25 | Loss: 0.00126670
Iteration 19/25 | Loss: 0.00126302
Iteration 20/25 | Loss: 0.00126247
Iteration 21/25 | Loss: 0.00126147
Iteration 22/25 | Loss: 0.00126179
Iteration 23/25 | Loss: 0.00125888
Iteration 24/25 | Loss: 0.00125989
Iteration 25/25 | Loss: 0.00125810

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.21434152
Iteration 2/25 | Loss: 0.00454559
Iteration 3/25 | Loss: 0.00454327
Iteration 4/25 | Loss: 0.00454326
Iteration 5/25 | Loss: 0.00454326
Iteration 6/25 | Loss: 0.00454326
Iteration 7/25 | Loss: 0.00454326
Iteration 8/25 | Loss: 0.00454326
Iteration 9/25 | Loss: 0.00454326
Iteration 10/25 | Loss: 0.00454326
Iteration 11/25 | Loss: 0.00454326
Iteration 12/25 | Loss: 0.00454326
Iteration 13/25 | Loss: 0.00454326
Iteration 14/25 | Loss: 0.00454326
Iteration 15/25 | Loss: 0.00454326
Iteration 16/25 | Loss: 0.00454326
Iteration 17/25 | Loss: 0.00454326
Iteration 18/25 | Loss: 0.00454326
Iteration 19/25 | Loss: 0.00454326
Iteration 20/25 | Loss: 0.00454326
Iteration 21/25 | Loss: 0.00454326
Iteration 22/25 | Loss: 0.00454326
Iteration 23/25 | Loss: 0.00454326
Iteration 24/25 | Loss: 0.00454326
Iteration 25/25 | Loss: 0.00454326
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.004543259274214506, 0.004543259274214506, 0.004543259274214506, 0.004543259274214506, 0.004543259274214506]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004543259274214506

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00454326
Iteration 2/1000 | Loss: 0.00031877
Iteration 3/1000 | Loss: 0.00229436
Iteration 4/1000 | Loss: 0.00022691
Iteration 5/1000 | Loss: 0.00013893
Iteration 6/1000 | Loss: 0.00023815
Iteration 7/1000 | Loss: 0.00095208
Iteration 8/1000 | Loss: 0.00070483
Iteration 9/1000 | Loss: 0.00054437
Iteration 10/1000 | Loss: 0.00096846
Iteration 11/1000 | Loss: 0.00047168
Iteration 12/1000 | Loss: 0.00055574
Iteration 13/1000 | Loss: 0.00040013
Iteration 14/1000 | Loss: 0.00023273
Iteration 15/1000 | Loss: 0.00012359
Iteration 16/1000 | Loss: 0.00039551
Iteration 17/1000 | Loss: 0.00034892
Iteration 18/1000 | Loss: 0.00016984
Iteration 19/1000 | Loss: 0.00045682
Iteration 20/1000 | Loss: 0.00027406
Iteration 21/1000 | Loss: 0.00046423
Iteration 22/1000 | Loss: 0.00040508
Iteration 23/1000 | Loss: 0.00064573
Iteration 24/1000 | Loss: 0.00064594
Iteration 25/1000 | Loss: 0.00017194
Iteration 26/1000 | Loss: 0.00020422
Iteration 27/1000 | Loss: 0.00017341
Iteration 28/1000 | Loss: 0.00022811
Iteration 29/1000 | Loss: 0.00016108
Iteration 30/1000 | Loss: 0.00017876
Iteration 31/1000 | Loss: 0.00021353
Iteration 32/1000 | Loss: 0.00021063
Iteration 33/1000 | Loss: 0.00097667
Iteration 34/1000 | Loss: 0.00019893
Iteration 35/1000 | Loss: 0.00020523
Iteration 36/1000 | Loss: 0.00077441
Iteration 37/1000 | Loss: 0.00024815
Iteration 38/1000 | Loss: 0.00008803
Iteration 39/1000 | Loss: 0.00009524
Iteration 40/1000 | Loss: 0.00005896
Iteration 41/1000 | Loss: 0.00030694
Iteration 42/1000 | Loss: 0.00057538
Iteration 43/1000 | Loss: 0.00040717
Iteration 44/1000 | Loss: 0.00037243
Iteration 45/1000 | Loss: 0.00019660
Iteration 46/1000 | Loss: 0.00005912
Iteration 47/1000 | Loss: 0.00020381
Iteration 48/1000 | Loss: 0.00007409
Iteration 49/1000 | Loss: 0.00044595
Iteration 50/1000 | Loss: 0.00063785
Iteration 51/1000 | Loss: 0.00030610
Iteration 52/1000 | Loss: 0.00007134
Iteration 53/1000 | Loss: 0.00007234
Iteration 54/1000 | Loss: 0.00016538
Iteration 55/1000 | Loss: 0.00015739
Iteration 56/1000 | Loss: 0.00007144
Iteration 57/1000 | Loss: 0.00006158
Iteration 58/1000 | Loss: 0.00024088
Iteration 59/1000 | Loss: 0.00005947
Iteration 60/1000 | Loss: 0.00005274
Iteration 61/1000 | Loss: 0.00004307
Iteration 62/1000 | Loss: 0.00020548
Iteration 63/1000 | Loss: 0.00014086
Iteration 64/1000 | Loss: 0.00005956
Iteration 65/1000 | Loss: 0.00005573
Iteration 66/1000 | Loss: 0.00018263
Iteration 67/1000 | Loss: 0.00013625
Iteration 68/1000 | Loss: 0.00008316
Iteration 69/1000 | Loss: 0.00006461
Iteration 70/1000 | Loss: 0.00006184
Iteration 71/1000 | Loss: 0.00006785
Iteration 72/1000 | Loss: 0.00005606
Iteration 73/1000 | Loss: 0.00017098
Iteration 74/1000 | Loss: 0.00048146
Iteration 75/1000 | Loss: 0.00018623
Iteration 76/1000 | Loss: 0.00007627
Iteration 77/1000 | Loss: 0.00020352
Iteration 78/1000 | Loss: 0.00007463
Iteration 79/1000 | Loss: 0.00007094
Iteration 80/1000 | Loss: 0.00005869
Iteration 81/1000 | Loss: 0.00006323
Iteration 82/1000 | Loss: 0.00005984
Iteration 83/1000 | Loss: 0.00005365
Iteration 84/1000 | Loss: 0.00005856
Iteration 85/1000 | Loss: 0.00006996
Iteration 86/1000 | Loss: 0.00005422
Iteration 87/1000 | Loss: 0.00005370
Iteration 88/1000 | Loss: 0.00006825
Iteration 89/1000 | Loss: 0.00006904
Iteration 90/1000 | Loss: 0.00007024
Iteration 91/1000 | Loss: 0.00006500
Iteration 92/1000 | Loss: 0.00005036
Iteration 93/1000 | Loss: 0.00006435
Iteration 94/1000 | Loss: 0.00005425
Iteration 95/1000 | Loss: 0.00004374
Iteration 96/1000 | Loss: 0.00005412
Iteration 97/1000 | Loss: 0.00005346
Iteration 98/1000 | Loss: 0.00005447
Iteration 99/1000 | Loss: 0.00006264
Iteration 100/1000 | Loss: 0.00005212
Iteration 101/1000 | Loss: 0.00004196
Iteration 102/1000 | Loss: 0.00005313
Iteration 103/1000 | Loss: 0.00004348
Iteration 104/1000 | Loss: 0.00005439
Iteration 105/1000 | Loss: 0.00006586
Iteration 106/1000 | Loss: 0.00005057
Iteration 107/1000 | Loss: 0.00004447
Iteration 108/1000 | Loss: 0.00005466
Iteration 109/1000 | Loss: 0.00005076
Iteration 110/1000 | Loss: 0.00004376
Iteration 111/1000 | Loss: 0.00004654
Iteration 112/1000 | Loss: 0.00004825
Iteration 113/1000 | Loss: 0.00005596
Iteration 114/1000 | Loss: 0.00004374
Iteration 115/1000 | Loss: 0.00005642
Iteration 116/1000 | Loss: 0.00004345
Iteration 117/1000 | Loss: 0.00004237
Iteration 118/1000 | Loss: 0.00004155
Iteration 119/1000 | Loss: 0.00005087
Iteration 120/1000 | Loss: 0.00005162
Iteration 121/1000 | Loss: 0.00004233
Iteration 122/1000 | Loss: 0.00005073
Iteration 123/1000 | Loss: 0.00004269
Iteration 124/1000 | Loss: 0.00004936
Iteration 125/1000 | Loss: 0.00041996
Iteration 126/1000 | Loss: 0.00064500
Iteration 127/1000 | Loss: 0.00008484
Iteration 128/1000 | Loss: 0.00007008
Iteration 129/1000 | Loss: 0.00005063
Iteration 130/1000 | Loss: 0.00005949
Iteration 131/1000 | Loss: 0.00005094
Iteration 132/1000 | Loss: 0.00003979
Iteration 133/1000 | Loss: 0.00004708
Iteration 134/1000 | Loss: 0.00004627
Iteration 135/1000 | Loss: 0.00004291
Iteration 136/1000 | Loss: 0.00003666
Iteration 137/1000 | Loss: 0.00003157
Iteration 138/1000 | Loss: 0.00003819
Iteration 139/1000 | Loss: 0.00004291
Iteration 140/1000 | Loss: 0.00004431
Iteration 141/1000 | Loss: 0.00004448
Iteration 142/1000 | Loss: 0.00004771
Iteration 143/1000 | Loss: 0.00004465
Iteration 144/1000 | Loss: 0.00004716
Iteration 145/1000 | Loss: 0.00004364
Iteration 146/1000 | Loss: 0.00004382
Iteration 147/1000 | Loss: 0.00052444
Iteration 148/1000 | Loss: 0.00005891
Iteration 149/1000 | Loss: 0.00005192
Iteration 150/1000 | Loss: 0.00004943
Iteration 151/1000 | Loss: 0.00004681
Iteration 152/1000 | Loss: 0.00003967
Iteration 153/1000 | Loss: 0.00004354
Iteration 154/1000 | Loss: 0.00003380
Iteration 155/1000 | Loss: 0.00003407
Iteration 156/1000 | Loss: 0.00003872
Iteration 157/1000 | Loss: 0.00004373
Iteration 158/1000 | Loss: 0.00004533
Iteration 159/1000 | Loss: 0.00004327
Iteration 160/1000 | Loss: 0.00003930
Iteration 161/1000 | Loss: 0.00004328
Iteration 162/1000 | Loss: 0.00003813
Iteration 163/1000 | Loss: 0.00004150
Iteration 164/1000 | Loss: 0.00004396
Iteration 165/1000 | Loss: 0.00004072
Iteration 166/1000 | Loss: 0.00004581
Iteration 167/1000 | Loss: 0.00004068
Iteration 168/1000 | Loss: 0.00003447
Iteration 169/1000 | Loss: 0.00005268
Iteration 170/1000 | Loss: 0.00004502
Iteration 171/1000 | Loss: 0.00005343
Iteration 172/1000 | Loss: 0.00004552
Iteration 173/1000 | Loss: 0.00004917
Iteration 174/1000 | Loss: 0.00004235
Iteration 175/1000 | Loss: 0.00004739
Iteration 176/1000 | Loss: 0.00003392
Iteration 177/1000 | Loss: 0.00004702
Iteration 178/1000 | Loss: 0.00004221
Iteration 179/1000 | Loss: 0.00003909
Iteration 180/1000 | Loss: 0.00003438
Iteration 181/1000 | Loss: 0.00007966
Iteration 182/1000 | Loss: 0.00004643
Iteration 183/1000 | Loss: 0.00003532
Iteration 184/1000 | Loss: 0.00004136
Iteration 185/1000 | Loss: 0.00003946
Iteration 186/1000 | Loss: 0.00004761
Iteration 187/1000 | Loss: 0.00004364
Iteration 188/1000 | Loss: 0.00004095
Iteration 189/1000 | Loss: 0.00002447
Iteration 190/1000 | Loss: 0.00003406
Iteration 191/1000 | Loss: 0.00004331
Iteration 192/1000 | Loss: 0.00002396
Iteration 193/1000 | Loss: 0.00003648
Iteration 194/1000 | Loss: 0.00003346
Iteration 195/1000 | Loss: 0.00004710
Iteration 196/1000 | Loss: 0.00003725
Iteration 197/1000 | Loss: 0.00004205
Iteration 198/1000 | Loss: 0.00003745
Iteration 199/1000 | Loss: 0.00003723
Iteration 200/1000 | Loss: 0.00003778
Iteration 201/1000 | Loss: 0.00003219
Iteration 202/1000 | Loss: 0.00003910
Iteration 203/1000 | Loss: 0.00003168
Iteration 204/1000 | Loss: 0.00004899
Iteration 205/1000 | Loss: 0.00003854
Iteration 206/1000 | Loss: 0.00004138
Iteration 207/1000 | Loss: 0.00004579
Iteration 208/1000 | Loss: 0.00003777
Iteration 209/1000 | Loss: 0.00004765
Iteration 210/1000 | Loss: 0.00002921
Iteration 211/1000 | Loss: 0.00003373
Iteration 212/1000 | Loss: 0.00004300
Iteration 213/1000 | Loss: 0.00003752
Iteration 214/1000 | Loss: 0.00003588
Iteration 215/1000 | Loss: 0.00003818
Iteration 216/1000 | Loss: 0.00004156
Iteration 217/1000 | Loss: 0.00003800
Iteration 218/1000 | Loss: 0.00004349
Iteration 219/1000 | Loss: 0.00004405
Iteration 220/1000 | Loss: 0.00004362
Iteration 221/1000 | Loss: 0.00003805
Iteration 222/1000 | Loss: 0.00003355
Iteration 223/1000 | Loss: 0.00004235
Iteration 224/1000 | Loss: 0.00003209
Iteration 225/1000 | Loss: 0.00003830
Iteration 226/1000 | Loss: 0.00004189
Iteration 227/1000 | Loss: 0.00003685
Iteration 228/1000 | Loss: 0.00004170
Iteration 229/1000 | Loss: 0.00004169
Iteration 230/1000 | Loss: 0.00003754
Iteration 231/1000 | Loss: 0.00003443
Iteration 232/1000 | Loss: 0.00004224
Iteration 233/1000 | Loss: 0.00004019
Iteration 234/1000 | Loss: 0.00003813
Iteration 235/1000 | Loss: 0.00003983
Iteration 236/1000 | Loss: 0.00004152
Iteration 237/1000 | Loss: 0.00003459
Iteration 238/1000 | Loss: 0.00005083
Iteration 239/1000 | Loss: 0.00003689
Iteration 240/1000 | Loss: 0.00003795
Iteration 241/1000 | Loss: 0.00003430
Iteration 242/1000 | Loss: 0.00003677
Iteration 243/1000 | Loss: 0.00003127
Iteration 244/1000 | Loss: 0.00003924
Iteration 245/1000 | Loss: 0.00003966
Iteration 246/1000 | Loss: 0.00003374
Iteration 247/1000 | Loss: 0.00003830
Iteration 248/1000 | Loss: 0.00003905
Iteration 249/1000 | Loss: 0.00002782
Iteration 250/1000 | Loss: 0.00002549
Iteration 251/1000 | Loss: 0.00002329
Iteration 252/1000 | Loss: 0.00002269
Iteration 253/1000 | Loss: 0.00002384
Iteration 254/1000 | Loss: 0.00002341
Iteration 255/1000 | Loss: 0.00002212
Iteration 256/1000 | Loss: 0.00002207
Iteration 257/1000 | Loss: 0.00002191
Iteration 258/1000 | Loss: 0.00002187
Iteration 259/1000 | Loss: 0.00002187
Iteration 260/1000 | Loss: 0.00002186
Iteration 261/1000 | Loss: 0.00002186
Iteration 262/1000 | Loss: 0.00002185
Iteration 263/1000 | Loss: 0.00002185
Iteration 264/1000 | Loss: 0.00002185
Iteration 265/1000 | Loss: 0.00002185
Iteration 266/1000 | Loss: 0.00002185
Iteration 267/1000 | Loss: 0.00002184
Iteration 268/1000 | Loss: 0.00002184
Iteration 269/1000 | Loss: 0.00002184
Iteration 270/1000 | Loss: 0.00002184
Iteration 271/1000 | Loss: 0.00002183
Iteration 272/1000 | Loss: 0.00002183
Iteration 273/1000 | Loss: 0.00002183
Iteration 274/1000 | Loss: 0.00002182
Iteration 275/1000 | Loss: 0.00002180
Iteration 276/1000 | Loss: 0.00002179
Iteration 277/1000 | Loss: 0.00002316
Iteration 278/1000 | Loss: 0.00002174
Iteration 279/1000 | Loss: 0.00002174
Iteration 280/1000 | Loss: 0.00002174
Iteration 281/1000 | Loss: 0.00002174
Iteration 282/1000 | Loss: 0.00002174
Iteration 283/1000 | Loss: 0.00002174
Iteration 284/1000 | Loss: 0.00002174
Iteration 285/1000 | Loss: 0.00002174
Iteration 286/1000 | Loss: 0.00002174
Iteration 287/1000 | Loss: 0.00002173
Iteration 288/1000 | Loss: 0.00002173
Iteration 289/1000 | Loss: 0.00002173
Iteration 290/1000 | Loss: 0.00002173
Iteration 291/1000 | Loss: 0.00002172
Iteration 292/1000 | Loss: 0.00002172
Iteration 293/1000 | Loss: 0.00002172
Iteration 294/1000 | Loss: 0.00002291
Iteration 295/1000 | Loss: 0.00002196
Iteration 296/1000 | Loss: 0.00002176
Iteration 297/1000 | Loss: 0.00002163
Iteration 298/1000 | Loss: 0.00002163
Iteration 299/1000 | Loss: 0.00002163
Iteration 300/1000 | Loss: 0.00002163
Iteration 301/1000 | Loss: 0.00002163
Iteration 302/1000 | Loss: 0.00002163
Iteration 303/1000 | Loss: 0.00002163
Iteration 304/1000 | Loss: 0.00002163
Iteration 305/1000 | Loss: 0.00002163
Iteration 306/1000 | Loss: 0.00002162
Iteration 307/1000 | Loss: 0.00002162
Iteration 308/1000 | Loss: 0.00002162
Iteration 309/1000 | Loss: 0.00002161
Iteration 310/1000 | Loss: 0.00002161
Iteration 311/1000 | Loss: 0.00002161
Iteration 312/1000 | Loss: 0.00002160
Iteration 313/1000 | Loss: 0.00002160
Iteration 314/1000 | Loss: 0.00002160
Iteration 315/1000 | Loss: 0.00002160
Iteration 316/1000 | Loss: 0.00002159
Iteration 317/1000 | Loss: 0.00002159
Iteration 318/1000 | Loss: 0.00002159
Iteration 319/1000 | Loss: 0.00002159
Iteration 320/1000 | Loss: 0.00002159
Iteration 321/1000 | Loss: 0.00002159
Iteration 322/1000 | Loss: 0.00002159
Iteration 323/1000 | Loss: 0.00002159
Iteration 324/1000 | Loss: 0.00002159
Iteration 325/1000 | Loss: 0.00002159
Iteration 326/1000 | Loss: 0.00002159
Iteration 327/1000 | Loss: 0.00002159
Iteration 328/1000 | Loss: 0.00002158
Iteration 329/1000 | Loss: 0.00002158
Iteration 330/1000 | Loss: 0.00002158
Iteration 331/1000 | Loss: 0.00002158
Iteration 332/1000 | Loss: 0.00002158
Iteration 333/1000 | Loss: 0.00002158
Iteration 334/1000 | Loss: 0.00002158
Iteration 335/1000 | Loss: 0.00002158
Iteration 336/1000 | Loss: 0.00002158
Iteration 337/1000 | Loss: 0.00002158
Iteration 338/1000 | Loss: 0.00002157
Iteration 339/1000 | Loss: 0.00002157
Iteration 340/1000 | Loss: 0.00002157
Iteration 341/1000 | Loss: 0.00002157
Iteration 342/1000 | Loss: 0.00002157
Iteration 343/1000 | Loss: 0.00002157
Iteration 344/1000 | Loss: 0.00002157
Iteration 345/1000 | Loss: 0.00002157
Iteration 346/1000 | Loss: 0.00002157
Iteration 347/1000 | Loss: 0.00002157
Iteration 348/1000 | Loss: 0.00002157
Iteration 349/1000 | Loss: 0.00002157
Iteration 350/1000 | Loss: 0.00002157
Iteration 351/1000 | Loss: 0.00002157
Iteration 352/1000 | Loss: 0.00002157
Iteration 353/1000 | Loss: 0.00002157
Iteration 354/1000 | Loss: 0.00002156
Iteration 355/1000 | Loss: 0.00002156
Iteration 356/1000 | Loss: 0.00002156
Iteration 357/1000 | Loss: 0.00002156
Iteration 358/1000 | Loss: 0.00002156
Iteration 359/1000 | Loss: 0.00002156
Iteration 360/1000 | Loss: 0.00002156
Iteration 361/1000 | Loss: 0.00002156
Iteration 362/1000 | Loss: 0.00002156
Iteration 363/1000 | Loss: 0.00002156
Iteration 364/1000 | Loss: 0.00002156
Iteration 365/1000 | Loss: 0.00002156
Iteration 366/1000 | Loss: 0.00002156
Iteration 367/1000 | Loss: 0.00002155
Iteration 368/1000 | Loss: 0.00002155
Iteration 369/1000 | Loss: 0.00002155
Iteration 370/1000 | Loss: 0.00002155
Iteration 371/1000 | Loss: 0.00002155
Iteration 372/1000 | Loss: 0.00002154
Iteration 373/1000 | Loss: 0.00002154
Iteration 374/1000 | Loss: 0.00002154
Iteration 375/1000 | Loss: 0.00002154
Iteration 376/1000 | Loss: 0.00002154
Iteration 377/1000 | Loss: 0.00002154
Iteration 378/1000 | Loss: 0.00002154
Iteration 379/1000 | Loss: 0.00002154
Iteration 380/1000 | Loss: 0.00002154
Iteration 381/1000 | Loss: 0.00002154
Iteration 382/1000 | Loss: 0.00002154
Iteration 383/1000 | Loss: 0.00002154
Iteration 384/1000 | Loss: 0.00002154
Iteration 385/1000 | Loss: 0.00002154
Iteration 386/1000 | Loss: 0.00002154
Iteration 387/1000 | Loss: 0.00002153
Iteration 388/1000 | Loss: 0.00002153
Iteration 389/1000 | Loss: 0.00002153
Iteration 390/1000 | Loss: 0.00002153
Iteration 391/1000 | Loss: 0.00002153
Iteration 392/1000 | Loss: 0.00002153
Iteration 393/1000 | Loss: 0.00002152
Iteration 394/1000 | Loss: 0.00002152
Iteration 395/1000 | Loss: 0.00002152
Iteration 396/1000 | Loss: 0.00002151
Iteration 397/1000 | Loss: 0.00002151
Iteration 398/1000 | Loss: 0.00002151
Iteration 399/1000 | Loss: 0.00002151
Iteration 400/1000 | Loss: 0.00002151
Iteration 401/1000 | Loss: 0.00002151
Iteration 402/1000 | Loss: 0.00002150
Iteration 403/1000 | Loss: 0.00002150
Iteration 404/1000 | Loss: 0.00002150
Iteration 405/1000 | Loss: 0.00002150
Iteration 406/1000 | Loss: 0.00002150
Iteration 407/1000 | Loss: 0.00002150
Iteration 408/1000 | Loss: 0.00002150
Iteration 409/1000 | Loss: 0.00002149
Iteration 410/1000 | Loss: 0.00002149
Iteration 411/1000 | Loss: 0.00002149
Iteration 412/1000 | Loss: 0.00002149
Iteration 413/1000 | Loss: 0.00002149
Iteration 414/1000 | Loss: 0.00002149
Iteration 415/1000 | Loss: 0.00002149
Iteration 416/1000 | Loss: 0.00002149
Iteration 417/1000 | Loss: 0.00002149
Iteration 418/1000 | Loss: 0.00002148
Iteration 419/1000 | Loss: 0.00002148
Iteration 420/1000 | Loss: 0.00002148
Iteration 421/1000 | Loss: 0.00002148
Iteration 422/1000 | Loss: 0.00002148
Iteration 423/1000 | Loss: 0.00002148
Iteration 424/1000 | Loss: 0.00002148
Iteration 425/1000 | Loss: 0.00002148
Iteration 426/1000 | Loss: 0.00002148
Iteration 427/1000 | Loss: 0.00002148
Iteration 428/1000 | Loss: 0.00002148
Iteration 429/1000 | Loss: 0.00002148
Iteration 430/1000 | Loss: 0.00002148
Iteration 431/1000 | Loss: 0.00002148
Iteration 432/1000 | Loss: 0.00002148
Iteration 433/1000 | Loss: 0.00002148
Iteration 434/1000 | Loss: 0.00002148
Iteration 435/1000 | Loss: 0.00002148
Iteration 436/1000 | Loss: 0.00002148
Iteration 437/1000 | Loss: 0.00002148
Iteration 438/1000 | Loss: 0.00002148
Iteration 439/1000 | Loss: 0.00002148
Iteration 440/1000 | Loss: 0.00002148
Iteration 441/1000 | Loss: 0.00002148
Iteration 442/1000 | Loss: 0.00002148
Iteration 443/1000 | Loss: 0.00002148
Iteration 444/1000 | Loss: 0.00002148
Iteration 445/1000 | Loss: 0.00002148
Iteration 446/1000 | Loss: 0.00002148
Iteration 447/1000 | Loss: 0.00002148
Iteration 448/1000 | Loss: 0.00002148
Iteration 449/1000 | Loss: 0.00002148
Iteration 450/1000 | Loss: 0.00002148
Iteration 451/1000 | Loss: 0.00002148
Iteration 452/1000 | Loss: 0.00002148
Iteration 453/1000 | Loss: 0.00002148
Iteration 454/1000 | Loss: 0.00002148
Iteration 455/1000 | Loss: 0.00002148
Iteration 456/1000 | Loss: 0.00002148
Iteration 457/1000 | Loss: 0.00002148
Iteration 458/1000 | Loss: 0.00002148
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 458. Stopping optimization.
Last 5 losses: [2.1481089788721874e-05, 2.1481089788721874e-05, 2.1481089788721874e-05, 2.1481089788721874e-05, 2.1481089788721874e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1481089788721874e-05

Optimization complete. Final v2v error: 2.962219715118408 mm

Highest mean error: 11.723090171813965 mm for frame 66

Lowest mean error: 2.2091519832611084 mm for frame 105

Saving results

Total time: 405.7745530605316
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_29_us_2928/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_29_us_2928/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00492380
Iteration 2/25 | Loss: 0.00154226
Iteration 3/25 | Loss: 0.00129376
Iteration 4/25 | Loss: 0.00125961
Iteration 5/25 | Loss: 0.00125422
Iteration 6/25 | Loss: 0.00125294
Iteration 7/25 | Loss: 0.00125291
Iteration 8/25 | Loss: 0.00125291
Iteration 9/25 | Loss: 0.00125291
Iteration 10/25 | Loss: 0.00125291
Iteration 11/25 | Loss: 0.00125291
Iteration 12/25 | Loss: 0.00125291
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012529101222753525, 0.0012529101222753525, 0.0012529101222753525, 0.0012529101222753525, 0.0012529101222753525]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012529101222753525

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.15860176
Iteration 2/25 | Loss: 0.00321110
Iteration 3/25 | Loss: 0.00321110
Iteration 4/25 | Loss: 0.00321110
Iteration 5/25 | Loss: 0.00321110
Iteration 6/25 | Loss: 0.00321110
Iteration 7/25 | Loss: 0.00321110
Iteration 8/25 | Loss: 0.00321110
Iteration 9/25 | Loss: 0.00321110
Iteration 10/25 | Loss: 0.00321110
Iteration 11/25 | Loss: 0.00321110
Iteration 12/25 | Loss: 0.00321110
Iteration 13/25 | Loss: 0.00321110
Iteration 14/25 | Loss: 0.00321110
Iteration 15/25 | Loss: 0.00321110
Iteration 16/25 | Loss: 0.00321110
Iteration 17/25 | Loss: 0.00321110
Iteration 18/25 | Loss: 0.00321110
Iteration 19/25 | Loss: 0.00321110
Iteration 20/25 | Loss: 0.00321110
Iteration 21/25 | Loss: 0.00321110
Iteration 22/25 | Loss: 0.00321110
Iteration 23/25 | Loss: 0.00321110
Iteration 24/25 | Loss: 0.00321110
Iteration 25/25 | Loss: 0.00321110

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00321110
Iteration 2/1000 | Loss: 0.00003014
Iteration 3/1000 | Loss: 0.00001968
Iteration 4/1000 | Loss: 0.00001814
Iteration 5/1000 | Loss: 0.00001702
Iteration 6/1000 | Loss: 0.00001631
Iteration 7/1000 | Loss: 0.00001577
Iteration 8/1000 | Loss: 0.00001528
Iteration 9/1000 | Loss: 0.00001480
Iteration 10/1000 | Loss: 0.00001453
Iteration 11/1000 | Loss: 0.00001429
Iteration 12/1000 | Loss: 0.00001411
Iteration 13/1000 | Loss: 0.00001400
Iteration 14/1000 | Loss: 0.00001399
Iteration 15/1000 | Loss: 0.00001398
Iteration 16/1000 | Loss: 0.00001388
Iteration 17/1000 | Loss: 0.00001385
Iteration 18/1000 | Loss: 0.00001385
Iteration 19/1000 | Loss: 0.00001381
Iteration 20/1000 | Loss: 0.00001376
Iteration 21/1000 | Loss: 0.00001372
Iteration 22/1000 | Loss: 0.00001371
Iteration 23/1000 | Loss: 0.00001370
Iteration 24/1000 | Loss: 0.00001370
Iteration 25/1000 | Loss: 0.00001369
Iteration 26/1000 | Loss: 0.00001368
Iteration 27/1000 | Loss: 0.00001367
Iteration 28/1000 | Loss: 0.00001367
Iteration 29/1000 | Loss: 0.00001366
Iteration 30/1000 | Loss: 0.00001366
Iteration 31/1000 | Loss: 0.00001364
Iteration 32/1000 | Loss: 0.00001364
Iteration 33/1000 | Loss: 0.00001363
Iteration 34/1000 | Loss: 0.00001363
Iteration 35/1000 | Loss: 0.00001363
Iteration 36/1000 | Loss: 0.00001363
Iteration 37/1000 | Loss: 0.00001363
Iteration 38/1000 | Loss: 0.00001362
Iteration 39/1000 | Loss: 0.00001362
Iteration 40/1000 | Loss: 0.00001362
Iteration 41/1000 | Loss: 0.00001362
Iteration 42/1000 | Loss: 0.00001362
Iteration 43/1000 | Loss: 0.00001362
Iteration 44/1000 | Loss: 0.00001362
Iteration 45/1000 | Loss: 0.00001362
Iteration 46/1000 | Loss: 0.00001362
Iteration 47/1000 | Loss: 0.00001361
Iteration 48/1000 | Loss: 0.00001361
Iteration 49/1000 | Loss: 0.00001361
Iteration 50/1000 | Loss: 0.00001359
Iteration 51/1000 | Loss: 0.00001358
Iteration 52/1000 | Loss: 0.00001358
Iteration 53/1000 | Loss: 0.00001358
Iteration 54/1000 | Loss: 0.00001357
Iteration 55/1000 | Loss: 0.00001357
Iteration 56/1000 | Loss: 0.00001357
Iteration 57/1000 | Loss: 0.00001356
Iteration 58/1000 | Loss: 0.00001356
Iteration 59/1000 | Loss: 0.00001355
Iteration 60/1000 | Loss: 0.00001355
Iteration 61/1000 | Loss: 0.00001355
Iteration 62/1000 | Loss: 0.00001354
Iteration 63/1000 | Loss: 0.00001354
Iteration 64/1000 | Loss: 0.00001353
Iteration 65/1000 | Loss: 0.00001353
Iteration 66/1000 | Loss: 0.00001352
Iteration 67/1000 | Loss: 0.00001351
Iteration 68/1000 | Loss: 0.00001351
Iteration 69/1000 | Loss: 0.00001351
Iteration 70/1000 | Loss: 0.00001351
Iteration 71/1000 | Loss: 0.00001350
Iteration 72/1000 | Loss: 0.00001350
Iteration 73/1000 | Loss: 0.00001349
Iteration 74/1000 | Loss: 0.00001349
Iteration 75/1000 | Loss: 0.00001349
Iteration 76/1000 | Loss: 0.00001349
Iteration 77/1000 | Loss: 0.00001349
Iteration 78/1000 | Loss: 0.00001348
Iteration 79/1000 | Loss: 0.00001348
Iteration 80/1000 | Loss: 0.00001348
Iteration 81/1000 | Loss: 0.00001347
Iteration 82/1000 | Loss: 0.00001347
Iteration 83/1000 | Loss: 0.00001347
Iteration 84/1000 | Loss: 0.00001347
Iteration 85/1000 | Loss: 0.00001347
Iteration 86/1000 | Loss: 0.00001347
Iteration 87/1000 | Loss: 0.00001347
Iteration 88/1000 | Loss: 0.00001346
Iteration 89/1000 | Loss: 0.00001346
Iteration 90/1000 | Loss: 0.00001346
Iteration 91/1000 | Loss: 0.00001345
Iteration 92/1000 | Loss: 0.00001345
Iteration 93/1000 | Loss: 0.00001345
Iteration 94/1000 | Loss: 0.00001345
Iteration 95/1000 | Loss: 0.00001344
Iteration 96/1000 | Loss: 0.00001344
Iteration 97/1000 | Loss: 0.00001343
Iteration 98/1000 | Loss: 0.00001343
Iteration 99/1000 | Loss: 0.00001343
Iteration 100/1000 | Loss: 0.00001343
Iteration 101/1000 | Loss: 0.00001343
Iteration 102/1000 | Loss: 0.00001343
Iteration 103/1000 | Loss: 0.00001343
Iteration 104/1000 | Loss: 0.00001342
Iteration 105/1000 | Loss: 0.00001342
Iteration 106/1000 | Loss: 0.00001342
Iteration 107/1000 | Loss: 0.00001342
Iteration 108/1000 | Loss: 0.00001342
Iteration 109/1000 | Loss: 0.00001342
Iteration 110/1000 | Loss: 0.00001342
Iteration 111/1000 | Loss: 0.00001342
Iteration 112/1000 | Loss: 0.00001342
Iteration 113/1000 | Loss: 0.00001342
Iteration 114/1000 | Loss: 0.00001342
Iteration 115/1000 | Loss: 0.00001342
Iteration 116/1000 | Loss: 0.00001342
Iteration 117/1000 | Loss: 0.00001342
Iteration 118/1000 | Loss: 0.00001342
Iteration 119/1000 | Loss: 0.00001342
Iteration 120/1000 | Loss: 0.00001342
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 120. Stopping optimization.
Last 5 losses: [1.3423234122456051e-05, 1.3423234122456051e-05, 1.3423234122456051e-05, 1.3423234122456051e-05, 1.3423234122456051e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3423234122456051e-05

Optimization complete. Final v2v error: 3.0768091678619385 mm

Highest mean error: 4.3863606452941895 mm for frame 92

Lowest mean error: 2.6423723697662354 mm for frame 44

Saving results

Total time: 39.00203323364258
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01095827
Iteration 2/25 | Loss: 0.01095827
Iteration 3/25 | Loss: 0.01095826
Iteration 4/25 | Loss: 0.01095826
Iteration 5/25 | Loss: 0.01095826
Iteration 6/25 | Loss: 0.01095826
Iteration 7/25 | Loss: 0.01095826
Iteration 8/25 | Loss: 0.01095826
Iteration 9/25 | Loss: 0.01095826
Iteration 10/25 | Loss: 0.01095825
Iteration 11/25 | Loss: 0.01095825
Iteration 12/25 | Loss: 0.01095825
Iteration 13/25 | Loss: 0.01095825
Iteration 14/25 | Loss: 0.01095825
Iteration 15/25 | Loss: 0.01095825
Iteration 16/25 | Loss: 0.01095825
Iteration 17/25 | Loss: 0.01095825
Iteration 18/25 | Loss: 0.01095824
Iteration 19/25 | Loss: 0.01095824
Iteration 20/25 | Loss: 0.01095824
Iteration 21/25 | Loss: 0.01095824
Iteration 22/25 | Loss: 0.01095824
Iteration 23/25 | Loss: 0.01095824
Iteration 24/25 | Loss: 0.01095824
Iteration 25/25 | Loss: 0.01095823

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.16699052
Iteration 2/25 | Loss: 0.07146519
Iteration 3/25 | Loss: 0.07146177
Iteration 4/25 | Loss: 0.07146177
Iteration 5/25 | Loss: 0.07146176
Iteration 6/25 | Loss: 0.07146176
Iteration 7/25 | Loss: 0.07146176
Iteration 8/25 | Loss: 0.07146176
Iteration 9/25 | Loss: 0.07146176
Iteration 10/25 | Loss: 0.07146176
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0714617595076561, 0.0714617595076561, 0.0714617595076561, 0.0714617595076561, 0.0714617595076561]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0714617595076561

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.07146176
Iteration 2/1000 | Loss: 0.00138222
Iteration 3/1000 | Loss: 0.00064866
Iteration 4/1000 | Loss: 0.00103489
Iteration 5/1000 | Loss: 0.00146098
Iteration 6/1000 | Loss: 0.00061092
Iteration 7/1000 | Loss: 0.00015064
Iteration 8/1000 | Loss: 0.00008670
Iteration 9/1000 | Loss: 0.00008996
Iteration 10/1000 | Loss: 0.00009390
Iteration 11/1000 | Loss: 0.00004052
Iteration 12/1000 | Loss: 0.00004328
Iteration 13/1000 | Loss: 0.00004054
Iteration 14/1000 | Loss: 0.00005876
Iteration 15/1000 | Loss: 0.00081873
Iteration 16/1000 | Loss: 0.00050956
Iteration 17/1000 | Loss: 0.00024351
Iteration 18/1000 | Loss: 0.00058587
Iteration 19/1000 | Loss: 0.00006561
Iteration 20/1000 | Loss: 0.00002005
Iteration 21/1000 | Loss: 0.00012002
Iteration 22/1000 | Loss: 0.00001782
Iteration 23/1000 | Loss: 0.00003197
Iteration 24/1000 | Loss: 0.00004316
Iteration 25/1000 | Loss: 0.00003324
Iteration 26/1000 | Loss: 0.00005253
Iteration 27/1000 | Loss: 0.00001449
Iteration 28/1000 | Loss: 0.00009508
Iteration 29/1000 | Loss: 0.00025314
Iteration 30/1000 | Loss: 0.00008987
Iteration 31/1000 | Loss: 0.00006161
Iteration 32/1000 | Loss: 0.00002239
Iteration 33/1000 | Loss: 0.00001248
Iteration 34/1000 | Loss: 0.00001229
Iteration 35/1000 | Loss: 0.00005169
Iteration 36/1000 | Loss: 0.00001830
Iteration 37/1000 | Loss: 0.00001160
Iteration 38/1000 | Loss: 0.00003826
Iteration 39/1000 | Loss: 0.00005245
Iteration 40/1000 | Loss: 0.00001878
Iteration 41/1000 | Loss: 0.00001093
Iteration 42/1000 | Loss: 0.00003431
Iteration 43/1000 | Loss: 0.00002264
Iteration 44/1000 | Loss: 0.00001690
Iteration 45/1000 | Loss: 0.00005845
Iteration 46/1000 | Loss: 0.00006696
Iteration 47/1000 | Loss: 0.00001647
Iteration 48/1000 | Loss: 0.00005082
Iteration 49/1000 | Loss: 0.00001724
Iteration 50/1000 | Loss: 0.00001049
Iteration 51/1000 | Loss: 0.00001030
Iteration 52/1000 | Loss: 0.00001030
Iteration 53/1000 | Loss: 0.00001030
Iteration 54/1000 | Loss: 0.00001030
Iteration 55/1000 | Loss: 0.00001030
Iteration 56/1000 | Loss: 0.00001030
Iteration 57/1000 | Loss: 0.00001030
Iteration 58/1000 | Loss: 0.00001030
Iteration 59/1000 | Loss: 0.00001030
Iteration 60/1000 | Loss: 0.00001030
Iteration 61/1000 | Loss: 0.00001030
Iteration 62/1000 | Loss: 0.00001030
Iteration 63/1000 | Loss: 0.00001030
Iteration 64/1000 | Loss: 0.00001030
Iteration 65/1000 | Loss: 0.00001030
Iteration 66/1000 | Loss: 0.00001030
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 66. Stopping optimization.
Last 5 losses: [1.0302896953362506e-05, 1.0302896953362506e-05, 1.0302896953362506e-05, 1.0302896953362506e-05, 1.0302896953362506e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0302896953362506e-05

Optimization complete. Final v2v error: 2.7126336097717285 mm

Highest mean error: 3.735136032104492 mm for frame 115

Lowest mean error: 2.0797245502471924 mm for frame 20

Saving results

Total time: 86.30761504173279
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00880501
Iteration 2/25 | Loss: 0.00116922
Iteration 3/25 | Loss: 0.00078043
Iteration 4/25 | Loss: 0.00068340
Iteration 5/25 | Loss: 0.00066146
Iteration 6/25 | Loss: 0.00065567
Iteration 7/25 | Loss: 0.00065367
Iteration 8/25 | Loss: 0.00065344
Iteration 9/25 | Loss: 0.00065344
Iteration 10/25 | Loss: 0.00065344
Iteration 11/25 | Loss: 0.00065344
Iteration 12/25 | Loss: 0.00065344
Iteration 13/25 | Loss: 0.00065344
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.00065344333415851, 0.00065344333415851, 0.00065344333415851, 0.00065344333415851, 0.00065344333415851]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00065344333415851

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48929894
Iteration 2/25 | Loss: 0.00028322
Iteration 3/25 | Loss: 0.00028320
Iteration 4/25 | Loss: 0.00028320
Iteration 5/25 | Loss: 0.00028320
Iteration 6/25 | Loss: 0.00028320
Iteration 7/25 | Loss: 0.00028320
Iteration 8/25 | Loss: 0.00028320
Iteration 9/25 | Loss: 0.00028320
Iteration 10/25 | Loss: 0.00028320
Iteration 11/25 | Loss: 0.00028320
Iteration 12/25 | Loss: 0.00028320
Iteration 13/25 | Loss: 0.00028320
Iteration 14/25 | Loss: 0.00028320
Iteration 15/25 | Loss: 0.00028320
Iteration 16/25 | Loss: 0.00028320
Iteration 17/25 | Loss: 0.00028320
Iteration 18/25 | Loss: 0.00028320
Iteration 19/25 | Loss: 0.00028320
Iteration 20/25 | Loss: 0.00028320
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0002831985766533762, 0.0002831985766533762, 0.0002831985766533762, 0.0002831985766533762, 0.0002831985766533762]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002831985766533762

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028320
Iteration 2/1000 | Loss: 0.00002318
Iteration 3/1000 | Loss: 0.00001690
Iteration 4/1000 | Loss: 0.00001559
Iteration 5/1000 | Loss: 0.00001464
Iteration 6/1000 | Loss: 0.00001396
Iteration 7/1000 | Loss: 0.00001365
Iteration 8/1000 | Loss: 0.00001345
Iteration 9/1000 | Loss: 0.00001338
Iteration 10/1000 | Loss: 0.00001338
Iteration 11/1000 | Loss: 0.00001336
Iteration 12/1000 | Loss: 0.00001336
Iteration 13/1000 | Loss: 0.00001335
Iteration 14/1000 | Loss: 0.00001334
Iteration 15/1000 | Loss: 0.00001334
Iteration 16/1000 | Loss: 0.00001333
Iteration 17/1000 | Loss: 0.00001331
Iteration 18/1000 | Loss: 0.00001331
Iteration 19/1000 | Loss: 0.00001330
Iteration 20/1000 | Loss: 0.00001329
Iteration 21/1000 | Loss: 0.00001328
Iteration 22/1000 | Loss: 0.00001327
Iteration 23/1000 | Loss: 0.00001326
Iteration 24/1000 | Loss: 0.00001325
Iteration 25/1000 | Loss: 0.00001324
Iteration 26/1000 | Loss: 0.00001324
Iteration 27/1000 | Loss: 0.00001321
Iteration 28/1000 | Loss: 0.00001321
Iteration 29/1000 | Loss: 0.00001319
Iteration 30/1000 | Loss: 0.00001319
Iteration 31/1000 | Loss: 0.00001319
Iteration 32/1000 | Loss: 0.00001318
Iteration 33/1000 | Loss: 0.00001318
Iteration 34/1000 | Loss: 0.00001318
Iteration 35/1000 | Loss: 0.00001317
Iteration 36/1000 | Loss: 0.00001317
Iteration 37/1000 | Loss: 0.00001317
Iteration 38/1000 | Loss: 0.00001316
Iteration 39/1000 | Loss: 0.00001316
Iteration 40/1000 | Loss: 0.00001316
Iteration 41/1000 | Loss: 0.00001316
Iteration 42/1000 | Loss: 0.00001315
Iteration 43/1000 | Loss: 0.00001315
Iteration 44/1000 | Loss: 0.00001315
Iteration 45/1000 | Loss: 0.00001314
Iteration 46/1000 | Loss: 0.00001314
Iteration 47/1000 | Loss: 0.00001314
Iteration 48/1000 | Loss: 0.00001313
Iteration 49/1000 | Loss: 0.00001313
Iteration 50/1000 | Loss: 0.00001313
Iteration 51/1000 | Loss: 0.00001313
Iteration 52/1000 | Loss: 0.00001313
Iteration 53/1000 | Loss: 0.00001313
Iteration 54/1000 | Loss: 0.00001313
Iteration 55/1000 | Loss: 0.00001313
Iteration 56/1000 | Loss: 0.00001313
Iteration 57/1000 | Loss: 0.00001312
Iteration 58/1000 | Loss: 0.00001312
Iteration 59/1000 | Loss: 0.00001312
Iteration 60/1000 | Loss: 0.00001312
Iteration 61/1000 | Loss: 0.00001312
Iteration 62/1000 | Loss: 0.00001312
Iteration 63/1000 | Loss: 0.00001312
Iteration 64/1000 | Loss: 0.00001312
Iteration 65/1000 | Loss: 0.00001312
Iteration 66/1000 | Loss: 0.00001312
Iteration 67/1000 | Loss: 0.00001312
Iteration 68/1000 | Loss: 0.00001312
Iteration 69/1000 | Loss: 0.00001312
Iteration 70/1000 | Loss: 0.00001311
Iteration 71/1000 | Loss: 0.00001311
Iteration 72/1000 | Loss: 0.00001311
Iteration 73/1000 | Loss: 0.00001311
Iteration 74/1000 | Loss: 0.00001311
Iteration 75/1000 | Loss: 0.00001311
Iteration 76/1000 | Loss: 0.00001311
Iteration 77/1000 | Loss: 0.00001311
Iteration 78/1000 | Loss: 0.00001311
Iteration 79/1000 | Loss: 0.00001311
Iteration 80/1000 | Loss: 0.00001311
Iteration 81/1000 | Loss: 0.00001311
Iteration 82/1000 | Loss: 0.00001311
Iteration 83/1000 | Loss: 0.00001311
Iteration 84/1000 | Loss: 0.00001311
Iteration 85/1000 | Loss: 0.00001311
Iteration 86/1000 | Loss: 0.00001311
Iteration 87/1000 | Loss: 0.00001311
Iteration 88/1000 | Loss: 0.00001311
Iteration 89/1000 | Loss: 0.00001311
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 89. Stopping optimization.
Last 5 losses: [1.3106870028423145e-05, 1.3106870028423145e-05, 1.3106870028423145e-05, 1.3106870028423145e-05, 1.3106870028423145e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3106870028423145e-05

Optimization complete. Final v2v error: 3.0344057083129883 mm

Highest mean error: 3.3321340084075928 mm for frame 207

Lowest mean error: 2.662078857421875 mm for frame 33

Saving results

Total time: 34.40757894515991
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00371637
Iteration 2/25 | Loss: 0.00072527
Iteration 3/25 | Loss: 0.00059293
Iteration 4/25 | Loss: 0.00057484
Iteration 5/25 | Loss: 0.00057179
Iteration 6/25 | Loss: 0.00057117
Iteration 7/25 | Loss: 0.00057116
Iteration 8/25 | Loss: 0.00057116
Iteration 9/25 | Loss: 0.00057116
Iteration 10/25 | Loss: 0.00057116
Iteration 11/25 | Loss: 0.00057116
Iteration 12/25 | Loss: 0.00057116
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0005711562698706985, 0.0005711562698706985, 0.0005711562698706985, 0.0005711562698706985, 0.0005711562698706985]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005711562698706985

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52261806
Iteration 2/25 | Loss: 0.00029034
Iteration 3/25 | Loss: 0.00029034
Iteration 4/25 | Loss: 0.00029033
Iteration 5/25 | Loss: 0.00029033
Iteration 6/25 | Loss: 0.00029033
Iteration 7/25 | Loss: 0.00029033
Iteration 8/25 | Loss: 0.00029033
Iteration 9/25 | Loss: 0.00029033
Iteration 10/25 | Loss: 0.00029033
Iteration 11/25 | Loss: 0.00029033
Iteration 12/25 | Loss: 0.00029033
Iteration 13/25 | Loss: 0.00029033
Iteration 14/25 | Loss: 0.00029033
Iteration 15/25 | Loss: 0.00029033
Iteration 16/25 | Loss: 0.00029033
Iteration 17/25 | Loss: 0.00029033
Iteration 18/25 | Loss: 0.00029033
Iteration 19/25 | Loss: 0.00029033
Iteration 20/25 | Loss: 0.00029033
Iteration 21/25 | Loss: 0.00029033
Iteration 22/25 | Loss: 0.00029033
Iteration 23/25 | Loss: 0.00029033
Iteration 24/25 | Loss: 0.00029033
Iteration 25/25 | Loss: 0.00029033

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029033
Iteration 2/1000 | Loss: 0.00001772
Iteration 3/1000 | Loss: 0.00001160
Iteration 4/1000 | Loss: 0.00001044
Iteration 5/1000 | Loss: 0.00000995
Iteration 6/1000 | Loss: 0.00000969
Iteration 7/1000 | Loss: 0.00000960
Iteration 8/1000 | Loss: 0.00000937
Iteration 9/1000 | Loss: 0.00000931
Iteration 10/1000 | Loss: 0.00000923
Iteration 11/1000 | Loss: 0.00000923
Iteration 12/1000 | Loss: 0.00000922
Iteration 13/1000 | Loss: 0.00000921
Iteration 14/1000 | Loss: 0.00000921
Iteration 15/1000 | Loss: 0.00000921
Iteration 16/1000 | Loss: 0.00000920
Iteration 17/1000 | Loss: 0.00000920
Iteration 18/1000 | Loss: 0.00000920
Iteration 19/1000 | Loss: 0.00000916
Iteration 20/1000 | Loss: 0.00000911
Iteration 21/1000 | Loss: 0.00000910
Iteration 22/1000 | Loss: 0.00000910
Iteration 23/1000 | Loss: 0.00000910
Iteration 24/1000 | Loss: 0.00000910
Iteration 25/1000 | Loss: 0.00000910
Iteration 26/1000 | Loss: 0.00000910
Iteration 27/1000 | Loss: 0.00000909
Iteration 28/1000 | Loss: 0.00000909
Iteration 29/1000 | Loss: 0.00000909
Iteration 30/1000 | Loss: 0.00000909
Iteration 31/1000 | Loss: 0.00000909
Iteration 32/1000 | Loss: 0.00000909
Iteration 33/1000 | Loss: 0.00000909
Iteration 34/1000 | Loss: 0.00000909
Iteration 35/1000 | Loss: 0.00000909
Iteration 36/1000 | Loss: 0.00000908
Iteration 37/1000 | Loss: 0.00000907
Iteration 38/1000 | Loss: 0.00000907
Iteration 39/1000 | Loss: 0.00000906
Iteration 40/1000 | Loss: 0.00000906
Iteration 41/1000 | Loss: 0.00000906
Iteration 42/1000 | Loss: 0.00000906
Iteration 43/1000 | Loss: 0.00000906
Iteration 44/1000 | Loss: 0.00000906
Iteration 45/1000 | Loss: 0.00000906
Iteration 46/1000 | Loss: 0.00000905
Iteration 47/1000 | Loss: 0.00000905
Iteration 48/1000 | Loss: 0.00000905
Iteration 49/1000 | Loss: 0.00000905
Iteration 50/1000 | Loss: 0.00000905
Iteration 51/1000 | Loss: 0.00000904
Iteration 52/1000 | Loss: 0.00000904
Iteration 53/1000 | Loss: 0.00000904
Iteration 54/1000 | Loss: 0.00000904
Iteration 55/1000 | Loss: 0.00000903
Iteration 56/1000 | Loss: 0.00000903
Iteration 57/1000 | Loss: 0.00000903
Iteration 58/1000 | Loss: 0.00000903
Iteration 59/1000 | Loss: 0.00000903
Iteration 60/1000 | Loss: 0.00000903
Iteration 61/1000 | Loss: 0.00000903
Iteration 62/1000 | Loss: 0.00000903
Iteration 63/1000 | Loss: 0.00000903
Iteration 64/1000 | Loss: 0.00000903
Iteration 65/1000 | Loss: 0.00000903
Iteration 66/1000 | Loss: 0.00000903
Iteration 67/1000 | Loss: 0.00000903
Iteration 68/1000 | Loss: 0.00000903
Iteration 69/1000 | Loss: 0.00000903
Iteration 70/1000 | Loss: 0.00000903
Iteration 71/1000 | Loss: 0.00000902
Iteration 72/1000 | Loss: 0.00000902
Iteration 73/1000 | Loss: 0.00000902
Iteration 74/1000 | Loss: 0.00000902
Iteration 75/1000 | Loss: 0.00000902
Iteration 76/1000 | Loss: 0.00000902
Iteration 77/1000 | Loss: 0.00000901
Iteration 78/1000 | Loss: 0.00000901
Iteration 79/1000 | Loss: 0.00000901
Iteration 80/1000 | Loss: 0.00000901
Iteration 81/1000 | Loss: 0.00000900
Iteration 82/1000 | Loss: 0.00000900
Iteration 83/1000 | Loss: 0.00000900
Iteration 84/1000 | Loss: 0.00000899
Iteration 85/1000 | Loss: 0.00000899
Iteration 86/1000 | Loss: 0.00000899
Iteration 87/1000 | Loss: 0.00000899
Iteration 88/1000 | Loss: 0.00000899
Iteration 89/1000 | Loss: 0.00000899
Iteration 90/1000 | Loss: 0.00000899
Iteration 91/1000 | Loss: 0.00000899
Iteration 92/1000 | Loss: 0.00000899
Iteration 93/1000 | Loss: 0.00000898
Iteration 94/1000 | Loss: 0.00000898
Iteration 95/1000 | Loss: 0.00000897
Iteration 96/1000 | Loss: 0.00000897
Iteration 97/1000 | Loss: 0.00000897
Iteration 98/1000 | Loss: 0.00000897
Iteration 99/1000 | Loss: 0.00000896
Iteration 100/1000 | Loss: 0.00000896
Iteration 101/1000 | Loss: 0.00000896
Iteration 102/1000 | Loss: 0.00000896
Iteration 103/1000 | Loss: 0.00000896
Iteration 104/1000 | Loss: 0.00000895
Iteration 105/1000 | Loss: 0.00000895
Iteration 106/1000 | Loss: 0.00000895
Iteration 107/1000 | Loss: 0.00000894
Iteration 108/1000 | Loss: 0.00000894
Iteration 109/1000 | Loss: 0.00000894
Iteration 110/1000 | Loss: 0.00000894
Iteration 111/1000 | Loss: 0.00000894
Iteration 112/1000 | Loss: 0.00000893
Iteration 113/1000 | Loss: 0.00000893
Iteration 114/1000 | Loss: 0.00000893
Iteration 115/1000 | Loss: 0.00000893
Iteration 116/1000 | Loss: 0.00000893
Iteration 117/1000 | Loss: 0.00000893
Iteration 118/1000 | Loss: 0.00000893
Iteration 119/1000 | Loss: 0.00000893
Iteration 120/1000 | Loss: 0.00000893
Iteration 121/1000 | Loss: 0.00000893
Iteration 122/1000 | Loss: 0.00000893
Iteration 123/1000 | Loss: 0.00000893
Iteration 124/1000 | Loss: 0.00000893
Iteration 125/1000 | Loss: 0.00000893
Iteration 126/1000 | Loss: 0.00000893
Iteration 127/1000 | Loss: 0.00000893
Iteration 128/1000 | Loss: 0.00000893
Iteration 129/1000 | Loss: 0.00000893
Iteration 130/1000 | Loss: 0.00000893
Iteration 131/1000 | Loss: 0.00000893
Iteration 132/1000 | Loss: 0.00000893
Iteration 133/1000 | Loss: 0.00000893
Iteration 134/1000 | Loss: 0.00000893
Iteration 135/1000 | Loss: 0.00000892
Iteration 136/1000 | Loss: 0.00000892
Iteration 137/1000 | Loss: 0.00000892
Iteration 138/1000 | Loss: 0.00000892
Iteration 139/1000 | Loss: 0.00000892
Iteration 140/1000 | Loss: 0.00000892
Iteration 141/1000 | Loss: 0.00000892
Iteration 142/1000 | Loss: 0.00000892
Iteration 143/1000 | Loss: 0.00000892
Iteration 144/1000 | Loss: 0.00000892
Iteration 145/1000 | Loss: 0.00000892
Iteration 146/1000 | Loss: 0.00000892
Iteration 147/1000 | Loss: 0.00000892
Iteration 148/1000 | Loss: 0.00000892
Iteration 149/1000 | Loss: 0.00000892
Iteration 150/1000 | Loss: 0.00000892
Iteration 151/1000 | Loss: 0.00000892
Iteration 152/1000 | Loss: 0.00000892
Iteration 153/1000 | Loss: 0.00000892
Iteration 154/1000 | Loss: 0.00000892
Iteration 155/1000 | Loss: 0.00000892
Iteration 156/1000 | Loss: 0.00000892
Iteration 157/1000 | Loss: 0.00000892
Iteration 158/1000 | Loss: 0.00000892
Iteration 159/1000 | Loss: 0.00000892
Iteration 160/1000 | Loss: 0.00000892
Iteration 161/1000 | Loss: 0.00000892
Iteration 162/1000 | Loss: 0.00000892
Iteration 163/1000 | Loss: 0.00000892
Iteration 164/1000 | Loss: 0.00000892
Iteration 165/1000 | Loss: 0.00000892
Iteration 166/1000 | Loss: 0.00000892
Iteration 167/1000 | Loss: 0.00000892
Iteration 168/1000 | Loss: 0.00000892
Iteration 169/1000 | Loss: 0.00000892
Iteration 170/1000 | Loss: 0.00000892
Iteration 171/1000 | Loss: 0.00000892
Iteration 172/1000 | Loss: 0.00000892
Iteration 173/1000 | Loss: 0.00000892
Iteration 174/1000 | Loss: 0.00000892
Iteration 175/1000 | Loss: 0.00000892
Iteration 176/1000 | Loss: 0.00000892
Iteration 177/1000 | Loss: 0.00000892
Iteration 178/1000 | Loss: 0.00000892
Iteration 179/1000 | Loss: 0.00000892
Iteration 180/1000 | Loss: 0.00000892
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 180. Stopping optimization.
Last 5 losses: [8.918218554754276e-06, 8.918218554754276e-06, 8.918218554754276e-06, 8.918218554754276e-06, 8.918218554754276e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.918218554754276e-06

Optimization complete. Final v2v error: 2.51153564453125 mm

Highest mean error: 2.895714282989502 mm for frame 12

Lowest mean error: 2.1719822883605957 mm for frame 0

Saving results

Total time: 30.169309377670288
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00385835
Iteration 2/25 | Loss: 0.00087778
Iteration 3/25 | Loss: 0.00066318
Iteration 4/25 | Loss: 0.00064851
Iteration 5/25 | Loss: 0.00064181
Iteration 6/25 | Loss: 0.00063983
Iteration 7/25 | Loss: 0.00063938
Iteration 8/25 | Loss: 0.00063938
Iteration 9/25 | Loss: 0.00063938
Iteration 10/25 | Loss: 0.00063938
Iteration 11/25 | Loss: 0.00063938
Iteration 12/25 | Loss: 0.00063938
Iteration 13/25 | Loss: 0.00063938
Iteration 14/25 | Loss: 0.00063938
Iteration 15/25 | Loss: 0.00063938
Iteration 16/25 | Loss: 0.00063938
Iteration 17/25 | Loss: 0.00063938
Iteration 18/25 | Loss: 0.00063938
Iteration 19/25 | Loss: 0.00063938
Iteration 20/25 | Loss: 0.00063938
Iteration 21/25 | Loss: 0.00063938
Iteration 22/25 | Loss: 0.00063938
Iteration 23/25 | Loss: 0.00063938
Iteration 24/25 | Loss: 0.00063938
Iteration 25/25 | Loss: 0.00063938

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65310395
Iteration 2/25 | Loss: 0.00035721
Iteration 3/25 | Loss: 0.00035721
Iteration 4/25 | Loss: 0.00035721
Iteration 5/25 | Loss: 0.00035721
Iteration 6/25 | Loss: 0.00035721
Iteration 7/25 | Loss: 0.00035721
Iteration 8/25 | Loss: 0.00035721
Iteration 9/25 | Loss: 0.00035721
Iteration 10/25 | Loss: 0.00035721
Iteration 11/25 | Loss: 0.00035721
Iteration 12/25 | Loss: 0.00035721
Iteration 13/25 | Loss: 0.00035721
Iteration 14/25 | Loss: 0.00035721
Iteration 15/25 | Loss: 0.00035721
Iteration 16/25 | Loss: 0.00035721
Iteration 17/25 | Loss: 0.00035721
Iteration 18/25 | Loss: 0.00035721
Iteration 19/25 | Loss: 0.00035721
Iteration 20/25 | Loss: 0.00035721
Iteration 21/25 | Loss: 0.00035721
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0003572073474060744, 0.0003572073474060744, 0.0003572073474060744, 0.0003572073474060744, 0.0003572073474060744]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003572073474060744

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035721
Iteration 2/1000 | Loss: 0.00003032
Iteration 3/1000 | Loss: 0.00001619
Iteration 4/1000 | Loss: 0.00001365
Iteration 5/1000 | Loss: 0.00001295
Iteration 6/1000 | Loss: 0.00001264
Iteration 7/1000 | Loss: 0.00001255
Iteration 8/1000 | Loss: 0.00001231
Iteration 9/1000 | Loss: 0.00001218
Iteration 10/1000 | Loss: 0.00001208
Iteration 11/1000 | Loss: 0.00001196
Iteration 12/1000 | Loss: 0.00001187
Iteration 13/1000 | Loss: 0.00001187
Iteration 14/1000 | Loss: 0.00001186
Iteration 15/1000 | Loss: 0.00001182
Iteration 16/1000 | Loss: 0.00001181
Iteration 17/1000 | Loss: 0.00001180
Iteration 18/1000 | Loss: 0.00001179
Iteration 19/1000 | Loss: 0.00001179
Iteration 20/1000 | Loss: 0.00001178
Iteration 21/1000 | Loss: 0.00001177
Iteration 22/1000 | Loss: 0.00001177
Iteration 23/1000 | Loss: 0.00001177
Iteration 24/1000 | Loss: 0.00001177
Iteration 25/1000 | Loss: 0.00001177
Iteration 26/1000 | Loss: 0.00001177
Iteration 27/1000 | Loss: 0.00001176
Iteration 28/1000 | Loss: 0.00001176
Iteration 29/1000 | Loss: 0.00001174
Iteration 30/1000 | Loss: 0.00001173
Iteration 31/1000 | Loss: 0.00001173
Iteration 32/1000 | Loss: 0.00001172
Iteration 33/1000 | Loss: 0.00001172
Iteration 34/1000 | Loss: 0.00001172
Iteration 35/1000 | Loss: 0.00001172
Iteration 36/1000 | Loss: 0.00001172
Iteration 37/1000 | Loss: 0.00001172
Iteration 38/1000 | Loss: 0.00001172
Iteration 39/1000 | Loss: 0.00001172
Iteration 40/1000 | Loss: 0.00001172
Iteration 41/1000 | Loss: 0.00001171
Iteration 42/1000 | Loss: 0.00001171
Iteration 43/1000 | Loss: 0.00001171
Iteration 44/1000 | Loss: 0.00001171
Iteration 45/1000 | Loss: 0.00001171
Iteration 46/1000 | Loss: 0.00001171
Iteration 47/1000 | Loss: 0.00001171
Iteration 48/1000 | Loss: 0.00001171
Iteration 49/1000 | Loss: 0.00001170
Iteration 50/1000 | Loss: 0.00001170
Iteration 51/1000 | Loss: 0.00001170
Iteration 52/1000 | Loss: 0.00001169
Iteration 53/1000 | Loss: 0.00001169
Iteration 54/1000 | Loss: 0.00001169
Iteration 55/1000 | Loss: 0.00001169
Iteration 56/1000 | Loss: 0.00001169
Iteration 57/1000 | Loss: 0.00001168
Iteration 58/1000 | Loss: 0.00001168
Iteration 59/1000 | Loss: 0.00001168
Iteration 60/1000 | Loss: 0.00001168
Iteration 61/1000 | Loss: 0.00001167
Iteration 62/1000 | Loss: 0.00001167
Iteration 63/1000 | Loss: 0.00001167
Iteration 64/1000 | Loss: 0.00001167
Iteration 65/1000 | Loss: 0.00001167
Iteration 66/1000 | Loss: 0.00001166
Iteration 67/1000 | Loss: 0.00001166
Iteration 68/1000 | Loss: 0.00001165
Iteration 69/1000 | Loss: 0.00001165
Iteration 70/1000 | Loss: 0.00001165
Iteration 71/1000 | Loss: 0.00001165
Iteration 72/1000 | Loss: 0.00001164
Iteration 73/1000 | Loss: 0.00001164
Iteration 74/1000 | Loss: 0.00001164
Iteration 75/1000 | Loss: 0.00001163
Iteration 76/1000 | Loss: 0.00001163
Iteration 77/1000 | Loss: 0.00001162
Iteration 78/1000 | Loss: 0.00001162
Iteration 79/1000 | Loss: 0.00001161
Iteration 80/1000 | Loss: 0.00001161
Iteration 81/1000 | Loss: 0.00001161
Iteration 82/1000 | Loss: 0.00001161
Iteration 83/1000 | Loss: 0.00001161
Iteration 84/1000 | Loss: 0.00001161
Iteration 85/1000 | Loss: 0.00001161
Iteration 86/1000 | Loss: 0.00001161
Iteration 87/1000 | Loss: 0.00001161
Iteration 88/1000 | Loss: 0.00001160
Iteration 89/1000 | Loss: 0.00001160
Iteration 90/1000 | Loss: 0.00001160
Iteration 91/1000 | Loss: 0.00001160
Iteration 92/1000 | Loss: 0.00001160
Iteration 93/1000 | Loss: 0.00001160
Iteration 94/1000 | Loss: 0.00001160
Iteration 95/1000 | Loss: 0.00001159
Iteration 96/1000 | Loss: 0.00001159
Iteration 97/1000 | Loss: 0.00001159
Iteration 98/1000 | Loss: 0.00001159
Iteration 99/1000 | Loss: 0.00001159
Iteration 100/1000 | Loss: 0.00001159
Iteration 101/1000 | Loss: 0.00001159
Iteration 102/1000 | Loss: 0.00001159
Iteration 103/1000 | Loss: 0.00001159
Iteration 104/1000 | Loss: 0.00001158
Iteration 105/1000 | Loss: 0.00001158
Iteration 106/1000 | Loss: 0.00001158
Iteration 107/1000 | Loss: 0.00001158
Iteration 108/1000 | Loss: 0.00001158
Iteration 109/1000 | Loss: 0.00001158
Iteration 110/1000 | Loss: 0.00001158
Iteration 111/1000 | Loss: 0.00001158
Iteration 112/1000 | Loss: 0.00001158
Iteration 113/1000 | Loss: 0.00001158
Iteration 114/1000 | Loss: 0.00001157
Iteration 115/1000 | Loss: 0.00001157
Iteration 116/1000 | Loss: 0.00001157
Iteration 117/1000 | Loss: 0.00001157
Iteration 118/1000 | Loss: 0.00001157
Iteration 119/1000 | Loss: 0.00001157
Iteration 120/1000 | Loss: 0.00001157
Iteration 121/1000 | Loss: 0.00001157
Iteration 122/1000 | Loss: 0.00001157
Iteration 123/1000 | Loss: 0.00001157
Iteration 124/1000 | Loss: 0.00001156
Iteration 125/1000 | Loss: 0.00001156
Iteration 126/1000 | Loss: 0.00001156
Iteration 127/1000 | Loss: 0.00001156
Iteration 128/1000 | Loss: 0.00001156
Iteration 129/1000 | Loss: 0.00001156
Iteration 130/1000 | Loss: 0.00001156
Iteration 131/1000 | Loss: 0.00001156
Iteration 132/1000 | Loss: 0.00001156
Iteration 133/1000 | Loss: 0.00001156
Iteration 134/1000 | Loss: 0.00001156
Iteration 135/1000 | Loss: 0.00001155
Iteration 136/1000 | Loss: 0.00001155
Iteration 137/1000 | Loss: 0.00001155
Iteration 138/1000 | Loss: 0.00001155
Iteration 139/1000 | Loss: 0.00001155
Iteration 140/1000 | Loss: 0.00001154
Iteration 141/1000 | Loss: 0.00001154
Iteration 142/1000 | Loss: 0.00001154
Iteration 143/1000 | Loss: 0.00001154
Iteration 144/1000 | Loss: 0.00001154
Iteration 145/1000 | Loss: 0.00001154
Iteration 146/1000 | Loss: 0.00001154
Iteration 147/1000 | Loss: 0.00001154
Iteration 148/1000 | Loss: 0.00001154
Iteration 149/1000 | Loss: 0.00001154
Iteration 150/1000 | Loss: 0.00001154
Iteration 151/1000 | Loss: 0.00001154
Iteration 152/1000 | Loss: 0.00001154
Iteration 153/1000 | Loss: 0.00001154
Iteration 154/1000 | Loss: 0.00001154
Iteration 155/1000 | Loss: 0.00001154
Iteration 156/1000 | Loss: 0.00001154
Iteration 157/1000 | Loss: 0.00001154
Iteration 158/1000 | Loss: 0.00001154
Iteration 159/1000 | Loss: 0.00001154
Iteration 160/1000 | Loss: 0.00001154
Iteration 161/1000 | Loss: 0.00001154
Iteration 162/1000 | Loss: 0.00001154
Iteration 163/1000 | Loss: 0.00001154
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [1.1537852515175473e-05, 1.1537852515175473e-05, 1.1537852515175473e-05, 1.1537852515175473e-05, 1.1537852515175473e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1537852515175473e-05

Optimization complete. Final v2v error: 2.882550001144409 mm

Highest mean error: 3.2689545154571533 mm for frame 161

Lowest mean error: 2.626737356185913 mm for frame 0

Saving results

Total time: 39.69032001495361
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01081731
Iteration 2/25 | Loss: 0.00164529
Iteration 3/25 | Loss: 0.00109257
Iteration 4/25 | Loss: 0.00078368
Iteration 5/25 | Loss: 0.00070557
Iteration 6/25 | Loss: 0.00071265
Iteration 7/25 | Loss: 0.00067912
Iteration 8/25 | Loss: 0.00065593
Iteration 9/25 | Loss: 0.00064520
Iteration 10/25 | Loss: 0.00062049
Iteration 11/25 | Loss: 0.00061367
Iteration 12/25 | Loss: 0.00060980
Iteration 13/25 | Loss: 0.00060791
Iteration 14/25 | Loss: 0.00060743
Iteration 15/25 | Loss: 0.00060732
Iteration 16/25 | Loss: 0.00060731
Iteration 17/25 | Loss: 0.00060731
Iteration 18/25 | Loss: 0.00060731
Iteration 19/25 | Loss: 0.00060731
Iteration 20/25 | Loss: 0.00060731
Iteration 21/25 | Loss: 0.00060730
Iteration 22/25 | Loss: 0.00060730
Iteration 23/25 | Loss: 0.00060730
Iteration 24/25 | Loss: 0.00060730
Iteration 25/25 | Loss: 0.00060730

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51962924
Iteration 2/25 | Loss: 0.00033674
Iteration 3/25 | Loss: 0.00026536
Iteration 4/25 | Loss: 0.00026536
Iteration 5/25 | Loss: 0.00026536
Iteration 6/25 | Loss: 0.00026536
Iteration 7/25 | Loss: 0.00026536
Iteration 8/25 | Loss: 0.00026536
Iteration 9/25 | Loss: 0.00026536
Iteration 10/25 | Loss: 0.00026536
Iteration 11/25 | Loss: 0.00026536
Iteration 12/25 | Loss: 0.00026536
Iteration 13/25 | Loss: 0.00026536
Iteration 14/25 | Loss: 0.00026536
Iteration 15/25 | Loss: 0.00026536
Iteration 16/25 | Loss: 0.00026536
Iteration 17/25 | Loss: 0.00026536
Iteration 18/25 | Loss: 0.00026536
Iteration 19/25 | Loss: 0.00026536
Iteration 20/25 | Loss: 0.00026536
Iteration 21/25 | Loss: 0.00026536
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.00026535781216807663, 0.00026535781216807663, 0.00026535781216807663, 0.00026535781216807663, 0.00026535781216807663]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00026535781216807663

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026536
Iteration 2/1000 | Loss: 0.00002909
Iteration 3/1000 | Loss: 0.00001505
Iteration 4/1000 | Loss: 0.00002733
Iteration 5/1000 | Loss: 0.00001645
Iteration 6/1000 | Loss: 0.00008354
Iteration 7/1000 | Loss: 0.00023545
Iteration 8/1000 | Loss: 0.00008525
Iteration 9/1000 | Loss: 0.00020837
Iteration 10/1000 | Loss: 0.00006504
Iteration 11/1000 | Loss: 0.00010681
Iteration 12/1000 | Loss: 0.00006949
Iteration 13/1000 | Loss: 0.00001230
Iteration 14/1000 | Loss: 0.00004722
Iteration 15/1000 | Loss: 0.00001946
Iteration 16/1000 | Loss: 0.00002545
Iteration 17/1000 | Loss: 0.00001150
Iteration 18/1000 | Loss: 0.00001149
Iteration 19/1000 | Loss: 0.00001600
Iteration 20/1000 | Loss: 0.00002455
Iteration 21/1000 | Loss: 0.00005424
Iteration 22/1000 | Loss: 0.00007049
Iteration 23/1000 | Loss: 0.00002113
Iteration 24/1000 | Loss: 0.00003707
Iteration 25/1000 | Loss: 0.00001571
Iteration 26/1000 | Loss: 0.00001582
Iteration 27/1000 | Loss: 0.00001144
Iteration 28/1000 | Loss: 0.00004103
Iteration 29/1000 | Loss: 0.00001369
Iteration 30/1000 | Loss: 0.00001152
Iteration 31/1000 | Loss: 0.00002346
Iteration 32/1000 | Loss: 0.00001600
Iteration 33/1000 | Loss: 0.00001928
Iteration 34/1000 | Loss: 0.00001140
Iteration 35/1000 | Loss: 0.00001140
Iteration 36/1000 | Loss: 0.00001140
Iteration 37/1000 | Loss: 0.00001140
Iteration 38/1000 | Loss: 0.00001140
Iteration 39/1000 | Loss: 0.00001140
Iteration 40/1000 | Loss: 0.00001140
Iteration 41/1000 | Loss: 0.00001140
Iteration 42/1000 | Loss: 0.00001140
Iteration 43/1000 | Loss: 0.00001140
Iteration 44/1000 | Loss: 0.00001140
Iteration 45/1000 | Loss: 0.00001140
Iteration 46/1000 | Loss: 0.00001140
Iteration 47/1000 | Loss: 0.00001140
Iteration 48/1000 | Loss: 0.00001140
Iteration 49/1000 | Loss: 0.00001140
Iteration 50/1000 | Loss: 0.00001140
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 50. Stopping optimization.
Last 5 losses: [1.1398237802495714e-05, 1.1398237802495714e-05, 1.1398237802495714e-05, 1.1398237802495714e-05, 1.1398237802495714e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1398237802495714e-05

Optimization complete. Final v2v error: 2.704782247543335 mm

Highest mean error: 10.186548233032227 mm for frame 104

Lowest mean error: 2.3557965755462646 mm for frame 135

Saving results

Total time: 66.59399199485779
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01116758
Iteration 2/25 | Loss: 0.00229281
Iteration 3/25 | Loss: 0.00122585
Iteration 4/25 | Loss: 0.00101433
Iteration 5/25 | Loss: 0.00095383
Iteration 6/25 | Loss: 0.00096053
Iteration 7/25 | Loss: 0.00088231
Iteration 8/25 | Loss: 0.00080821
Iteration 9/25 | Loss: 0.00079338
Iteration 10/25 | Loss: 0.00076791
Iteration 11/25 | Loss: 0.00078841
Iteration 12/25 | Loss: 0.00079017
Iteration 13/25 | Loss: 0.00076891
Iteration 14/25 | Loss: 0.00076401
Iteration 15/25 | Loss: 0.00075255
Iteration 16/25 | Loss: 0.00075070
Iteration 17/25 | Loss: 0.00075836
Iteration 18/25 | Loss: 0.00075134
Iteration 19/25 | Loss: 0.00075409
Iteration 20/25 | Loss: 0.00074870
Iteration 21/25 | Loss: 0.00075400
Iteration 22/25 | Loss: 0.00075211
Iteration 23/25 | Loss: 0.00074857
Iteration 24/25 | Loss: 0.00074552
Iteration 25/25 | Loss: 0.00074447

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65128779
Iteration 2/25 | Loss: 0.00045643
Iteration 3/25 | Loss: 0.00045643
Iteration 4/25 | Loss: 0.00045643
Iteration 5/25 | Loss: 0.00045643
Iteration 6/25 | Loss: 0.00045643
Iteration 7/25 | Loss: 0.00045643
Iteration 8/25 | Loss: 0.00045643
Iteration 9/25 | Loss: 0.00045643
Iteration 10/25 | Loss: 0.00045643
Iteration 11/25 | Loss: 0.00045643
Iteration 12/25 | Loss: 0.00045643
Iteration 13/25 | Loss: 0.00045643
Iteration 14/25 | Loss: 0.00045643
Iteration 15/25 | Loss: 0.00045643
Iteration 16/25 | Loss: 0.00045643
Iteration 17/25 | Loss: 0.00045643
Iteration 18/25 | Loss: 0.00045643
Iteration 19/25 | Loss: 0.00045643
Iteration 20/25 | Loss: 0.00045643
Iteration 21/25 | Loss: 0.00045643
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0004564255359582603, 0.0004564255359582603, 0.0004564255359582603, 0.0004564255359582603, 0.0004564255359582603]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004564255359582603

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045643
Iteration 2/1000 | Loss: 0.00006815
Iteration 3/1000 | Loss: 0.00007649
Iteration 4/1000 | Loss: 0.00005261
Iteration 5/1000 | Loss: 0.00003321
Iteration 6/1000 | Loss: 0.00004877
Iteration 7/1000 | Loss: 0.00002801
Iteration 8/1000 | Loss: 0.00002364
Iteration 9/1000 | Loss: 0.00002032
Iteration 10/1000 | Loss: 0.00001916
Iteration 11/1000 | Loss: 0.00001839
Iteration 12/1000 | Loss: 0.00001792
Iteration 13/1000 | Loss: 0.00001749
Iteration 14/1000 | Loss: 0.00001707
Iteration 15/1000 | Loss: 0.00001686
Iteration 16/1000 | Loss: 0.00001678
Iteration 17/1000 | Loss: 0.00001670
Iteration 18/1000 | Loss: 0.00001658
Iteration 19/1000 | Loss: 0.00001654
Iteration 20/1000 | Loss: 0.00001653
Iteration 21/1000 | Loss: 0.00001653
Iteration 22/1000 | Loss: 0.00001652
Iteration 23/1000 | Loss: 0.00001650
Iteration 24/1000 | Loss: 0.00001649
Iteration 25/1000 | Loss: 0.00001648
Iteration 26/1000 | Loss: 0.00001646
Iteration 27/1000 | Loss: 0.00001646
Iteration 28/1000 | Loss: 0.00001642
Iteration 29/1000 | Loss: 0.00001642
Iteration 30/1000 | Loss: 0.00001641
Iteration 31/1000 | Loss: 0.00001641
Iteration 32/1000 | Loss: 0.00001639
Iteration 33/1000 | Loss: 0.00001639
Iteration 34/1000 | Loss: 0.00001639
Iteration 35/1000 | Loss: 0.00001638
Iteration 36/1000 | Loss: 0.00001638
Iteration 37/1000 | Loss: 0.00001638
Iteration 38/1000 | Loss: 0.00001637
Iteration 39/1000 | Loss: 0.00001637
Iteration 40/1000 | Loss: 0.00001636
Iteration 41/1000 | Loss: 0.00001636
Iteration 42/1000 | Loss: 0.00001636
Iteration 43/1000 | Loss: 0.00001635
Iteration 44/1000 | Loss: 0.00001635
Iteration 45/1000 | Loss: 0.00001634
Iteration 46/1000 | Loss: 0.00001634
Iteration 47/1000 | Loss: 0.00001634
Iteration 48/1000 | Loss: 0.00001633
Iteration 49/1000 | Loss: 0.00001633
Iteration 50/1000 | Loss: 0.00001633
Iteration 51/1000 | Loss: 0.00001633
Iteration 52/1000 | Loss: 0.00001633
Iteration 53/1000 | Loss: 0.00001633
Iteration 54/1000 | Loss: 0.00001632
Iteration 55/1000 | Loss: 0.00001632
Iteration 56/1000 | Loss: 0.00001632
Iteration 57/1000 | Loss: 0.00001632
Iteration 58/1000 | Loss: 0.00001631
Iteration 59/1000 | Loss: 0.00001631
Iteration 60/1000 | Loss: 0.00001631
Iteration 61/1000 | Loss: 0.00001630
Iteration 62/1000 | Loss: 0.00001630
Iteration 63/1000 | Loss: 0.00001630
Iteration 64/1000 | Loss: 0.00001630
Iteration 65/1000 | Loss: 0.00001630
Iteration 66/1000 | Loss: 0.00001630
Iteration 67/1000 | Loss: 0.00001630
Iteration 68/1000 | Loss: 0.00001630
Iteration 69/1000 | Loss: 0.00001630
Iteration 70/1000 | Loss: 0.00001630
Iteration 71/1000 | Loss: 0.00001629
Iteration 72/1000 | Loss: 0.00001629
Iteration 73/1000 | Loss: 0.00001629
Iteration 74/1000 | Loss: 0.00001629
Iteration 75/1000 | Loss: 0.00001629
Iteration 76/1000 | Loss: 0.00001629
Iteration 77/1000 | Loss: 0.00001629
Iteration 78/1000 | Loss: 0.00001629
Iteration 79/1000 | Loss: 0.00001629
Iteration 80/1000 | Loss: 0.00001628
Iteration 81/1000 | Loss: 0.00001628
Iteration 82/1000 | Loss: 0.00001628
Iteration 83/1000 | Loss: 0.00001628
Iteration 84/1000 | Loss: 0.00001628
Iteration 85/1000 | Loss: 0.00001628
Iteration 86/1000 | Loss: 0.00001628
Iteration 87/1000 | Loss: 0.00001628
Iteration 88/1000 | Loss: 0.00001627
Iteration 89/1000 | Loss: 0.00001627
Iteration 90/1000 | Loss: 0.00001627
Iteration 91/1000 | Loss: 0.00001627
Iteration 92/1000 | Loss: 0.00001627
Iteration 93/1000 | Loss: 0.00001627
Iteration 94/1000 | Loss: 0.00001627
Iteration 95/1000 | Loss: 0.00001626
Iteration 96/1000 | Loss: 0.00001626
Iteration 97/1000 | Loss: 0.00001626
Iteration 98/1000 | Loss: 0.00001626
Iteration 99/1000 | Loss: 0.00001626
Iteration 100/1000 | Loss: 0.00001626
Iteration 101/1000 | Loss: 0.00001626
Iteration 102/1000 | Loss: 0.00001625
Iteration 103/1000 | Loss: 0.00001625
Iteration 104/1000 | Loss: 0.00001625
Iteration 105/1000 | Loss: 0.00001625
Iteration 106/1000 | Loss: 0.00001625
Iteration 107/1000 | Loss: 0.00001625
Iteration 108/1000 | Loss: 0.00001625
Iteration 109/1000 | Loss: 0.00001624
Iteration 110/1000 | Loss: 0.00001624
Iteration 111/1000 | Loss: 0.00001624
Iteration 112/1000 | Loss: 0.00001624
Iteration 113/1000 | Loss: 0.00001624
Iteration 114/1000 | Loss: 0.00001624
Iteration 115/1000 | Loss: 0.00001624
Iteration 116/1000 | Loss: 0.00001623
Iteration 117/1000 | Loss: 0.00001623
Iteration 118/1000 | Loss: 0.00001623
Iteration 119/1000 | Loss: 0.00001623
Iteration 120/1000 | Loss: 0.00001623
Iteration 121/1000 | Loss: 0.00001623
Iteration 122/1000 | Loss: 0.00001623
Iteration 123/1000 | Loss: 0.00001623
Iteration 124/1000 | Loss: 0.00001623
Iteration 125/1000 | Loss: 0.00001623
Iteration 126/1000 | Loss: 0.00001623
Iteration 127/1000 | Loss: 0.00001623
Iteration 128/1000 | Loss: 0.00001623
Iteration 129/1000 | Loss: 0.00001622
Iteration 130/1000 | Loss: 0.00001622
Iteration 131/1000 | Loss: 0.00001622
Iteration 132/1000 | Loss: 0.00001622
Iteration 133/1000 | Loss: 0.00001622
Iteration 134/1000 | Loss: 0.00001622
Iteration 135/1000 | Loss: 0.00001622
Iteration 136/1000 | Loss: 0.00001622
Iteration 137/1000 | Loss: 0.00001622
Iteration 138/1000 | Loss: 0.00001622
Iteration 139/1000 | Loss: 0.00001622
Iteration 140/1000 | Loss: 0.00001622
Iteration 141/1000 | Loss: 0.00001622
Iteration 142/1000 | Loss: 0.00001622
Iteration 143/1000 | Loss: 0.00001622
Iteration 144/1000 | Loss: 0.00001622
Iteration 145/1000 | Loss: 0.00001622
Iteration 146/1000 | Loss: 0.00001622
Iteration 147/1000 | Loss: 0.00001622
Iteration 148/1000 | Loss: 0.00001622
Iteration 149/1000 | Loss: 0.00001622
Iteration 150/1000 | Loss: 0.00001622
Iteration 151/1000 | Loss: 0.00001622
Iteration 152/1000 | Loss: 0.00001622
Iteration 153/1000 | Loss: 0.00001622
Iteration 154/1000 | Loss: 0.00001622
Iteration 155/1000 | Loss: 0.00001622
Iteration 156/1000 | Loss: 0.00001622
Iteration 157/1000 | Loss: 0.00001622
Iteration 158/1000 | Loss: 0.00001622
Iteration 159/1000 | Loss: 0.00001622
Iteration 160/1000 | Loss: 0.00001622
Iteration 161/1000 | Loss: 0.00001622
Iteration 162/1000 | Loss: 0.00001622
Iteration 163/1000 | Loss: 0.00001622
Iteration 164/1000 | Loss: 0.00001622
Iteration 165/1000 | Loss: 0.00001622
Iteration 166/1000 | Loss: 0.00001622
Iteration 167/1000 | Loss: 0.00001622
Iteration 168/1000 | Loss: 0.00001622
Iteration 169/1000 | Loss: 0.00001622
Iteration 170/1000 | Loss: 0.00001622
Iteration 171/1000 | Loss: 0.00001622
Iteration 172/1000 | Loss: 0.00001622
Iteration 173/1000 | Loss: 0.00001622
Iteration 174/1000 | Loss: 0.00001622
Iteration 175/1000 | Loss: 0.00001622
Iteration 176/1000 | Loss: 0.00001622
Iteration 177/1000 | Loss: 0.00001622
Iteration 178/1000 | Loss: 0.00001622
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [1.622094350750558e-05, 1.622094350750558e-05, 1.622094350750558e-05, 1.622094350750558e-05, 1.622094350750558e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.622094350750558e-05

Optimization complete. Final v2v error: 3.3800556659698486 mm

Highest mean error: 3.8971199989318848 mm for frame 98

Lowest mean error: 3.0712413787841797 mm for frame 50

Saving results

Total time: 77.51696991920471
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00428591
Iteration 2/25 | Loss: 0.00093546
Iteration 3/25 | Loss: 0.00066159
Iteration 4/25 | Loss: 0.00062921
Iteration 5/25 | Loss: 0.00062180
Iteration 6/25 | Loss: 0.00062005
Iteration 7/25 | Loss: 0.00061968
Iteration 8/25 | Loss: 0.00061964
Iteration 9/25 | Loss: 0.00061964
Iteration 10/25 | Loss: 0.00061964
Iteration 11/25 | Loss: 0.00061964
Iteration 12/25 | Loss: 0.00061964
Iteration 13/25 | Loss: 0.00061964
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.000619643775280565, 0.000619643775280565, 0.000619643775280565, 0.000619643775280565, 0.000619643775280565]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000619643775280565

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67309570
Iteration 2/25 | Loss: 0.00033553
Iteration 3/25 | Loss: 0.00033553
Iteration 4/25 | Loss: 0.00033552
Iteration 5/25 | Loss: 0.00033552
Iteration 6/25 | Loss: 0.00033552
Iteration 7/25 | Loss: 0.00033552
Iteration 8/25 | Loss: 0.00033552
Iteration 9/25 | Loss: 0.00033552
Iteration 10/25 | Loss: 0.00033552
Iteration 11/25 | Loss: 0.00033552
Iteration 12/25 | Loss: 0.00033552
Iteration 13/25 | Loss: 0.00033552
Iteration 14/25 | Loss: 0.00033552
Iteration 15/25 | Loss: 0.00033552
Iteration 16/25 | Loss: 0.00033552
Iteration 17/25 | Loss: 0.00033552
Iteration 18/25 | Loss: 0.00033552
Iteration 19/25 | Loss: 0.00033552
Iteration 20/25 | Loss: 0.00033552
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0003355226945132017, 0.0003355226945132017, 0.0003355226945132017, 0.0003355226945132017, 0.0003355226945132017]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003355226945132017

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033552
Iteration 2/1000 | Loss: 0.00001806
Iteration 3/1000 | Loss: 0.00001324
Iteration 4/1000 | Loss: 0.00001190
Iteration 5/1000 | Loss: 0.00001159
Iteration 6/1000 | Loss: 0.00001143
Iteration 7/1000 | Loss: 0.00001137
Iteration 8/1000 | Loss: 0.00001132
Iteration 9/1000 | Loss: 0.00001131
Iteration 10/1000 | Loss: 0.00001109
Iteration 11/1000 | Loss: 0.00001107
Iteration 12/1000 | Loss: 0.00001101
Iteration 13/1000 | Loss: 0.00001100
Iteration 14/1000 | Loss: 0.00001100
Iteration 15/1000 | Loss: 0.00001099
Iteration 16/1000 | Loss: 0.00001098
Iteration 17/1000 | Loss: 0.00001092
Iteration 18/1000 | Loss: 0.00001089
Iteration 19/1000 | Loss: 0.00001088
Iteration 20/1000 | Loss: 0.00001088
Iteration 21/1000 | Loss: 0.00001086
Iteration 22/1000 | Loss: 0.00001086
Iteration 23/1000 | Loss: 0.00001086
Iteration 24/1000 | Loss: 0.00001085
Iteration 25/1000 | Loss: 0.00001085
Iteration 26/1000 | Loss: 0.00001085
Iteration 27/1000 | Loss: 0.00001085
Iteration 28/1000 | Loss: 0.00001084
Iteration 29/1000 | Loss: 0.00001084
Iteration 30/1000 | Loss: 0.00001082
Iteration 31/1000 | Loss: 0.00001082
Iteration 32/1000 | Loss: 0.00001082
Iteration 33/1000 | Loss: 0.00001081
Iteration 34/1000 | Loss: 0.00001081
Iteration 35/1000 | Loss: 0.00001081
Iteration 36/1000 | Loss: 0.00001080
Iteration 37/1000 | Loss: 0.00001080
Iteration 38/1000 | Loss: 0.00001080
Iteration 39/1000 | Loss: 0.00001080
Iteration 40/1000 | Loss: 0.00001079
Iteration 41/1000 | Loss: 0.00001079
Iteration 42/1000 | Loss: 0.00001079
Iteration 43/1000 | Loss: 0.00001078
Iteration 44/1000 | Loss: 0.00001078
Iteration 45/1000 | Loss: 0.00001078
Iteration 46/1000 | Loss: 0.00001078
Iteration 47/1000 | Loss: 0.00001078
Iteration 48/1000 | Loss: 0.00001078
Iteration 49/1000 | Loss: 0.00001078
Iteration 50/1000 | Loss: 0.00001078
Iteration 51/1000 | Loss: 0.00001078
Iteration 52/1000 | Loss: 0.00001078
Iteration 53/1000 | Loss: 0.00001077
Iteration 54/1000 | Loss: 0.00001077
Iteration 55/1000 | Loss: 0.00001076
Iteration 56/1000 | Loss: 0.00001076
Iteration 57/1000 | Loss: 0.00001076
Iteration 58/1000 | Loss: 0.00001076
Iteration 59/1000 | Loss: 0.00001076
Iteration 60/1000 | Loss: 0.00001076
Iteration 61/1000 | Loss: 0.00001076
Iteration 62/1000 | Loss: 0.00001075
Iteration 63/1000 | Loss: 0.00001075
Iteration 64/1000 | Loss: 0.00001075
Iteration 65/1000 | Loss: 0.00001075
Iteration 66/1000 | Loss: 0.00001075
Iteration 67/1000 | Loss: 0.00001075
Iteration 68/1000 | Loss: 0.00001075
Iteration 69/1000 | Loss: 0.00001075
Iteration 70/1000 | Loss: 0.00001075
Iteration 71/1000 | Loss: 0.00001075
Iteration 72/1000 | Loss: 0.00001074
Iteration 73/1000 | Loss: 0.00001074
Iteration 74/1000 | Loss: 0.00001074
Iteration 75/1000 | Loss: 0.00001073
Iteration 76/1000 | Loss: 0.00001073
Iteration 77/1000 | Loss: 0.00001073
Iteration 78/1000 | Loss: 0.00001073
Iteration 79/1000 | Loss: 0.00001073
Iteration 80/1000 | Loss: 0.00001072
Iteration 81/1000 | Loss: 0.00001072
Iteration 82/1000 | Loss: 0.00001072
Iteration 83/1000 | Loss: 0.00001072
Iteration 84/1000 | Loss: 0.00001072
Iteration 85/1000 | Loss: 0.00001072
Iteration 86/1000 | Loss: 0.00001071
Iteration 87/1000 | Loss: 0.00001071
Iteration 88/1000 | Loss: 0.00001071
Iteration 89/1000 | Loss: 0.00001071
Iteration 90/1000 | Loss: 0.00001071
Iteration 91/1000 | Loss: 0.00001071
Iteration 92/1000 | Loss: 0.00001071
Iteration 93/1000 | Loss: 0.00001071
Iteration 94/1000 | Loss: 0.00001071
Iteration 95/1000 | Loss: 0.00001071
Iteration 96/1000 | Loss: 0.00001071
Iteration 97/1000 | Loss: 0.00001071
Iteration 98/1000 | Loss: 0.00001071
Iteration 99/1000 | Loss: 0.00001071
Iteration 100/1000 | Loss: 0.00001071
Iteration 101/1000 | Loss: 0.00001071
Iteration 102/1000 | Loss: 0.00001071
Iteration 103/1000 | Loss: 0.00001071
Iteration 104/1000 | Loss: 0.00001071
Iteration 105/1000 | Loss: 0.00001071
Iteration 106/1000 | Loss: 0.00001071
Iteration 107/1000 | Loss: 0.00001071
Iteration 108/1000 | Loss: 0.00001071
Iteration 109/1000 | Loss: 0.00001071
Iteration 110/1000 | Loss: 0.00001071
Iteration 111/1000 | Loss: 0.00001071
Iteration 112/1000 | Loss: 0.00001071
Iteration 113/1000 | Loss: 0.00001071
Iteration 114/1000 | Loss: 0.00001071
Iteration 115/1000 | Loss: 0.00001071
Iteration 116/1000 | Loss: 0.00001071
Iteration 117/1000 | Loss: 0.00001071
Iteration 118/1000 | Loss: 0.00001071
Iteration 119/1000 | Loss: 0.00001071
Iteration 120/1000 | Loss: 0.00001071
Iteration 121/1000 | Loss: 0.00001071
Iteration 122/1000 | Loss: 0.00001071
Iteration 123/1000 | Loss: 0.00001071
Iteration 124/1000 | Loss: 0.00001071
Iteration 125/1000 | Loss: 0.00001071
Iteration 126/1000 | Loss: 0.00001071
Iteration 127/1000 | Loss: 0.00001071
Iteration 128/1000 | Loss: 0.00001071
Iteration 129/1000 | Loss: 0.00001071
Iteration 130/1000 | Loss: 0.00001071
Iteration 131/1000 | Loss: 0.00001071
Iteration 132/1000 | Loss: 0.00001071
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 132. Stopping optimization.
Last 5 losses: [1.0711269169405568e-05, 1.0711269169405568e-05, 1.0711269169405568e-05, 1.0711269169405568e-05, 1.0711269169405568e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0711269169405568e-05

Optimization complete. Final v2v error: 2.77475643157959 mm

Highest mean error: 2.993906021118164 mm for frame 106

Lowest mean error: 2.620985507965088 mm for frame 38

Saving results

Total time: 28.691580057144165
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00395538
Iteration 2/25 | Loss: 0.00089121
Iteration 3/25 | Loss: 0.00070476
Iteration 4/25 | Loss: 0.00069294
Iteration 5/25 | Loss: 0.00068718
Iteration 6/25 | Loss: 0.00068580
Iteration 7/25 | Loss: 0.00068580
Iteration 8/25 | Loss: 0.00068580
Iteration 9/25 | Loss: 0.00068580
Iteration 10/25 | Loss: 0.00068580
Iteration 11/25 | Loss: 0.00068580
Iteration 12/25 | Loss: 0.00068580
Iteration 13/25 | Loss: 0.00068580
Iteration 14/25 | Loss: 0.00068580
Iteration 15/25 | Loss: 0.00068580
Iteration 16/25 | Loss: 0.00068580
Iteration 17/25 | Loss: 0.00068580
Iteration 18/25 | Loss: 0.00068580
Iteration 19/25 | Loss: 0.00068580
Iteration 20/25 | Loss: 0.00068580
Iteration 21/25 | Loss: 0.00068580
Iteration 22/25 | Loss: 0.00068580
Iteration 23/25 | Loss: 0.00068580
Iteration 24/25 | Loss: 0.00068580
Iteration 25/25 | Loss: 0.00068580

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62599850
Iteration 2/25 | Loss: 0.00039895
Iteration 3/25 | Loss: 0.00039895
Iteration 4/25 | Loss: 0.00039895
Iteration 5/25 | Loss: 0.00039895
Iteration 6/25 | Loss: 0.00039895
Iteration 7/25 | Loss: 0.00039895
Iteration 8/25 | Loss: 0.00039895
Iteration 9/25 | Loss: 0.00039895
Iteration 10/25 | Loss: 0.00039895
Iteration 11/25 | Loss: 0.00039895
Iteration 12/25 | Loss: 0.00039895
Iteration 13/25 | Loss: 0.00039895
Iteration 14/25 | Loss: 0.00039895
Iteration 15/25 | Loss: 0.00039895
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00039894928340800107, 0.00039894928340800107, 0.00039894928340800107, 0.00039894928340800107, 0.00039894928340800107]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00039894928340800107

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039895
Iteration 2/1000 | Loss: 0.00003353
Iteration 3/1000 | Loss: 0.00001992
Iteration 4/1000 | Loss: 0.00001727
Iteration 5/1000 | Loss: 0.00001651
Iteration 6/1000 | Loss: 0.00001596
Iteration 7/1000 | Loss: 0.00001565
Iteration 8/1000 | Loss: 0.00001535
Iteration 9/1000 | Loss: 0.00001511
Iteration 10/1000 | Loss: 0.00001495
Iteration 11/1000 | Loss: 0.00001495
Iteration 12/1000 | Loss: 0.00001484
Iteration 13/1000 | Loss: 0.00001478
Iteration 14/1000 | Loss: 0.00001473
Iteration 15/1000 | Loss: 0.00001472
Iteration 16/1000 | Loss: 0.00001472
Iteration 17/1000 | Loss: 0.00001472
Iteration 18/1000 | Loss: 0.00001471
Iteration 19/1000 | Loss: 0.00001470
Iteration 20/1000 | Loss: 0.00001470
Iteration 21/1000 | Loss: 0.00001469
Iteration 22/1000 | Loss: 0.00001469
Iteration 23/1000 | Loss: 0.00001468
Iteration 24/1000 | Loss: 0.00001468
Iteration 25/1000 | Loss: 0.00001467
Iteration 26/1000 | Loss: 0.00001467
Iteration 27/1000 | Loss: 0.00001460
Iteration 28/1000 | Loss: 0.00001459
Iteration 29/1000 | Loss: 0.00001459
Iteration 30/1000 | Loss: 0.00001458
Iteration 31/1000 | Loss: 0.00001458
Iteration 32/1000 | Loss: 0.00001457
Iteration 33/1000 | Loss: 0.00001457
Iteration 34/1000 | Loss: 0.00001456
Iteration 35/1000 | Loss: 0.00001455
Iteration 36/1000 | Loss: 0.00001455
Iteration 37/1000 | Loss: 0.00001455
Iteration 38/1000 | Loss: 0.00001455
Iteration 39/1000 | Loss: 0.00001454
Iteration 40/1000 | Loss: 0.00001454
Iteration 41/1000 | Loss: 0.00001454
Iteration 42/1000 | Loss: 0.00001453
Iteration 43/1000 | Loss: 0.00001453
Iteration 44/1000 | Loss: 0.00001453
Iteration 45/1000 | Loss: 0.00001453
Iteration 46/1000 | Loss: 0.00001452
Iteration 47/1000 | Loss: 0.00001452
Iteration 48/1000 | Loss: 0.00001452
Iteration 49/1000 | Loss: 0.00001452
Iteration 50/1000 | Loss: 0.00001452
Iteration 51/1000 | Loss: 0.00001452
Iteration 52/1000 | Loss: 0.00001452
Iteration 53/1000 | Loss: 0.00001451
Iteration 54/1000 | Loss: 0.00001451
Iteration 55/1000 | Loss: 0.00001451
Iteration 56/1000 | Loss: 0.00001451
Iteration 57/1000 | Loss: 0.00001451
Iteration 58/1000 | Loss: 0.00001450
Iteration 59/1000 | Loss: 0.00001450
Iteration 60/1000 | Loss: 0.00001450
Iteration 61/1000 | Loss: 0.00001450
Iteration 62/1000 | Loss: 0.00001450
Iteration 63/1000 | Loss: 0.00001450
Iteration 64/1000 | Loss: 0.00001450
Iteration 65/1000 | Loss: 0.00001450
Iteration 66/1000 | Loss: 0.00001450
Iteration 67/1000 | Loss: 0.00001450
Iteration 68/1000 | Loss: 0.00001450
Iteration 69/1000 | Loss: 0.00001450
Iteration 70/1000 | Loss: 0.00001450
Iteration 71/1000 | Loss: 0.00001450
Iteration 72/1000 | Loss: 0.00001450
Iteration 73/1000 | Loss: 0.00001450
Iteration 74/1000 | Loss: 0.00001450
Iteration 75/1000 | Loss: 0.00001450
Iteration 76/1000 | Loss: 0.00001450
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [1.4496650692308322e-05, 1.4496650692308322e-05, 1.4496650692308322e-05, 1.4496650692308322e-05, 1.4496650692308322e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4496650692308322e-05

Optimization complete. Final v2v error: 3.273949146270752 mm

Highest mean error: 3.5603363513946533 mm for frame 11

Lowest mean error: 2.976184606552124 mm for frame 262

Saving results

Total time: 35.35691165924072
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00562555
Iteration 2/25 | Loss: 0.00110534
Iteration 3/25 | Loss: 0.00080110
Iteration 4/25 | Loss: 0.00074130
Iteration 5/25 | Loss: 0.00071847
Iteration 6/25 | Loss: 0.00071698
Iteration 7/25 | Loss: 0.00069324
Iteration 8/25 | Loss: 0.00068309
Iteration 9/25 | Loss: 0.00067541
Iteration 10/25 | Loss: 0.00067475
Iteration 11/25 | Loss: 0.00067463
Iteration 12/25 | Loss: 0.00067463
Iteration 13/25 | Loss: 0.00067463
Iteration 14/25 | Loss: 0.00067462
Iteration 15/25 | Loss: 0.00067462
Iteration 16/25 | Loss: 0.00067462
Iteration 17/25 | Loss: 0.00067462
Iteration 18/25 | Loss: 0.00067462
Iteration 19/25 | Loss: 0.00067462
Iteration 20/25 | Loss: 0.00067462
Iteration 21/25 | Loss: 0.00067462
Iteration 22/25 | Loss: 0.00067462
Iteration 23/25 | Loss: 0.00067462
Iteration 24/25 | Loss: 0.00067462
Iteration 25/25 | Loss: 0.00067462

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.91091681
Iteration 2/25 | Loss: 0.00037668
Iteration 3/25 | Loss: 0.00037666
Iteration 4/25 | Loss: 0.00037666
Iteration 5/25 | Loss: 0.00037666
Iteration 6/25 | Loss: 0.00037666
Iteration 7/25 | Loss: 0.00037666
Iteration 8/25 | Loss: 0.00037666
Iteration 9/25 | Loss: 0.00037666
Iteration 10/25 | Loss: 0.00037666
Iteration 11/25 | Loss: 0.00037666
Iteration 12/25 | Loss: 0.00037666
Iteration 13/25 | Loss: 0.00037666
Iteration 14/25 | Loss: 0.00037666
Iteration 15/25 | Loss: 0.00037666
Iteration 16/25 | Loss: 0.00037666
Iteration 17/25 | Loss: 0.00037666
Iteration 18/25 | Loss: 0.00037666
Iteration 19/25 | Loss: 0.00037666
Iteration 20/25 | Loss: 0.00037666
Iteration 21/25 | Loss: 0.00037666
Iteration 22/25 | Loss: 0.00037666
Iteration 23/25 | Loss: 0.00037666
Iteration 24/25 | Loss: 0.00037666
Iteration 25/25 | Loss: 0.00037666

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00037666
Iteration 2/1000 | Loss: 0.00004429
Iteration 3/1000 | Loss: 0.00002688
Iteration 4/1000 | Loss: 0.00002353
Iteration 5/1000 | Loss: 0.00002217
Iteration 6/1000 | Loss: 0.00002121
Iteration 7/1000 | Loss: 0.00002054
Iteration 8/1000 | Loss: 0.00001990
Iteration 9/1000 | Loss: 0.00001952
Iteration 10/1000 | Loss: 0.00001920
Iteration 11/1000 | Loss: 0.00001901
Iteration 12/1000 | Loss: 0.00001899
Iteration 13/1000 | Loss: 0.00001886
Iteration 14/1000 | Loss: 0.00001883
Iteration 15/1000 | Loss: 0.00001877
Iteration 16/1000 | Loss: 0.00001873
Iteration 17/1000 | Loss: 0.00001867
Iteration 18/1000 | Loss: 0.00001867
Iteration 19/1000 | Loss: 0.00001865
Iteration 20/1000 | Loss: 0.00001865
Iteration 21/1000 | Loss: 0.00001864
Iteration 22/1000 | Loss: 0.00001864
Iteration 23/1000 | Loss: 0.00001864
Iteration 24/1000 | Loss: 0.00001862
Iteration 25/1000 | Loss: 0.00001861
Iteration 26/1000 | Loss: 0.00001861
Iteration 27/1000 | Loss: 0.00001861
Iteration 28/1000 | Loss: 0.00001861
Iteration 29/1000 | Loss: 0.00001861
Iteration 30/1000 | Loss: 0.00001861
Iteration 31/1000 | Loss: 0.00001861
Iteration 32/1000 | Loss: 0.00001861
Iteration 33/1000 | Loss: 0.00001861
Iteration 34/1000 | Loss: 0.00001861
Iteration 35/1000 | Loss: 0.00001861
Iteration 36/1000 | Loss: 0.00001861
Iteration 37/1000 | Loss: 0.00001860
Iteration 38/1000 | Loss: 0.00001860
Iteration 39/1000 | Loss: 0.00001860
Iteration 40/1000 | Loss: 0.00001860
Iteration 41/1000 | Loss: 0.00001860
Iteration 42/1000 | Loss: 0.00001859
Iteration 43/1000 | Loss: 0.00001859
Iteration 44/1000 | Loss: 0.00001858
Iteration 45/1000 | Loss: 0.00001858
Iteration 46/1000 | Loss: 0.00001858
Iteration 47/1000 | Loss: 0.00001857
Iteration 48/1000 | Loss: 0.00001857
Iteration 49/1000 | Loss: 0.00001857
Iteration 50/1000 | Loss: 0.00001857
Iteration 51/1000 | Loss: 0.00001856
Iteration 52/1000 | Loss: 0.00001856
Iteration 53/1000 | Loss: 0.00001856
Iteration 54/1000 | Loss: 0.00001855
Iteration 55/1000 | Loss: 0.00001854
Iteration 56/1000 | Loss: 0.00001854
Iteration 57/1000 | Loss: 0.00001854
Iteration 58/1000 | Loss: 0.00001854
Iteration 59/1000 | Loss: 0.00001854
Iteration 60/1000 | Loss: 0.00001854
Iteration 61/1000 | Loss: 0.00001854
Iteration 62/1000 | Loss: 0.00001854
Iteration 63/1000 | Loss: 0.00001853
Iteration 64/1000 | Loss: 0.00001853
Iteration 65/1000 | Loss: 0.00001853
Iteration 66/1000 | Loss: 0.00001853
Iteration 67/1000 | Loss: 0.00001852
Iteration 68/1000 | Loss: 0.00001852
Iteration 69/1000 | Loss: 0.00001852
Iteration 70/1000 | Loss: 0.00001852
Iteration 71/1000 | Loss: 0.00001852
Iteration 72/1000 | Loss: 0.00001852
Iteration 73/1000 | Loss: 0.00001851
Iteration 74/1000 | Loss: 0.00001851
Iteration 75/1000 | Loss: 0.00001851
Iteration 76/1000 | Loss: 0.00001851
Iteration 77/1000 | Loss: 0.00001851
Iteration 78/1000 | Loss: 0.00001851
Iteration 79/1000 | Loss: 0.00001850
Iteration 80/1000 | Loss: 0.00001850
Iteration 81/1000 | Loss: 0.00001850
Iteration 82/1000 | Loss: 0.00001850
Iteration 83/1000 | Loss: 0.00001850
Iteration 84/1000 | Loss: 0.00001850
Iteration 85/1000 | Loss: 0.00001849
Iteration 86/1000 | Loss: 0.00001849
Iteration 87/1000 | Loss: 0.00001849
Iteration 88/1000 | Loss: 0.00001849
Iteration 89/1000 | Loss: 0.00001849
Iteration 90/1000 | Loss: 0.00001849
Iteration 91/1000 | Loss: 0.00001849
Iteration 92/1000 | Loss: 0.00001848
Iteration 93/1000 | Loss: 0.00001848
Iteration 94/1000 | Loss: 0.00001848
Iteration 95/1000 | Loss: 0.00001848
Iteration 96/1000 | Loss: 0.00001848
Iteration 97/1000 | Loss: 0.00001848
Iteration 98/1000 | Loss: 0.00001848
Iteration 99/1000 | Loss: 0.00001848
Iteration 100/1000 | Loss: 0.00001848
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 100. Stopping optimization.
Last 5 losses: [1.8479009668226354e-05, 1.8479009668226354e-05, 1.8479009668226354e-05, 1.8479009668226354e-05, 1.8479009668226354e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8479009668226354e-05

Optimization complete. Final v2v error: 3.5352845191955566 mm

Highest mean error: 4.449778079986572 mm for frame 106

Lowest mean error: 2.8669490814208984 mm for frame 96

Saving results

Total time: 50.630091428756714
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00970564
Iteration 2/25 | Loss: 0.00126646
Iteration 3/25 | Loss: 0.00095195
Iteration 4/25 | Loss: 0.00079801
Iteration 5/25 | Loss: 0.00080240
Iteration 6/25 | Loss: 0.00075889
Iteration 7/25 | Loss: 0.00072151
Iteration 8/25 | Loss: 0.00070763
Iteration 9/25 | Loss: 0.00070979
Iteration 10/25 | Loss: 0.00070035
Iteration 11/25 | Loss: 0.00069676
Iteration 12/25 | Loss: 0.00069953
Iteration 13/25 | Loss: 0.00069373
Iteration 14/25 | Loss: 0.00069368
Iteration 15/25 | Loss: 0.00069367
Iteration 16/25 | Loss: 0.00069367
Iteration 17/25 | Loss: 0.00069367
Iteration 18/25 | Loss: 0.00069367
Iteration 19/25 | Loss: 0.00069367
Iteration 20/25 | Loss: 0.00069367
Iteration 21/25 | Loss: 0.00069367
Iteration 22/25 | Loss: 0.00069367
Iteration 23/25 | Loss: 0.00069367
Iteration 24/25 | Loss: 0.00069367
Iteration 25/25 | Loss: 0.00069367

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59961343
Iteration 2/25 | Loss: 0.00038182
Iteration 3/25 | Loss: 0.00038179
Iteration 4/25 | Loss: 0.00038179
Iteration 5/25 | Loss: 0.00038179
Iteration 6/25 | Loss: 0.00038179
Iteration 7/25 | Loss: 0.00038179
Iteration 8/25 | Loss: 0.00038179
Iteration 9/25 | Loss: 0.00038179
Iteration 10/25 | Loss: 0.00038179
Iteration 11/25 | Loss: 0.00038179
Iteration 12/25 | Loss: 0.00038179
Iteration 13/25 | Loss: 0.00038179
Iteration 14/25 | Loss: 0.00038179
Iteration 15/25 | Loss: 0.00038179
Iteration 16/25 | Loss: 0.00038179
Iteration 17/25 | Loss: 0.00038179
Iteration 18/25 | Loss: 0.00038179
Iteration 19/25 | Loss: 0.00038179
Iteration 20/25 | Loss: 0.00038179
Iteration 21/25 | Loss: 0.00038179
Iteration 22/25 | Loss: 0.00038179
Iteration 23/25 | Loss: 0.00038179
Iteration 24/25 | Loss: 0.00038179
Iteration 25/25 | Loss: 0.00038179

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038179
Iteration 2/1000 | Loss: 0.00011351
Iteration 3/1000 | Loss: 0.00005818
Iteration 4/1000 | Loss: 0.00002824
Iteration 5/1000 | Loss: 0.00010153
Iteration 6/1000 | Loss: 0.00002282
Iteration 7/1000 | Loss: 0.00002171
Iteration 8/1000 | Loss: 0.00002095
Iteration 9/1000 | Loss: 0.00017369
Iteration 10/1000 | Loss: 0.00010482
Iteration 11/1000 | Loss: 0.00002972
Iteration 12/1000 | Loss: 0.00002233
Iteration 13/1000 | Loss: 0.00002045
Iteration 14/1000 | Loss: 0.00001993
Iteration 15/1000 | Loss: 0.00001975
Iteration 16/1000 | Loss: 0.00001958
Iteration 17/1000 | Loss: 0.00001945
Iteration 18/1000 | Loss: 0.00001940
Iteration 19/1000 | Loss: 0.00001940
Iteration 20/1000 | Loss: 0.00001936
Iteration 21/1000 | Loss: 0.00001935
Iteration 22/1000 | Loss: 0.00001935
Iteration 23/1000 | Loss: 0.00005302
Iteration 24/1000 | Loss: 0.00001927
Iteration 25/1000 | Loss: 0.00001923
Iteration 26/1000 | Loss: 0.00001923
Iteration 27/1000 | Loss: 0.00001921
Iteration 28/1000 | Loss: 0.00001921
Iteration 29/1000 | Loss: 0.00001920
Iteration 30/1000 | Loss: 0.00001920
Iteration 31/1000 | Loss: 0.00001919
Iteration 32/1000 | Loss: 0.00001919
Iteration 33/1000 | Loss: 0.00001919
Iteration 34/1000 | Loss: 0.00001917
Iteration 35/1000 | Loss: 0.00001917
Iteration 36/1000 | Loss: 0.00001917
Iteration 37/1000 | Loss: 0.00001917
Iteration 38/1000 | Loss: 0.00001916
Iteration 39/1000 | Loss: 0.00001916
Iteration 40/1000 | Loss: 0.00001916
Iteration 41/1000 | Loss: 0.00001916
Iteration 42/1000 | Loss: 0.00001916
Iteration 43/1000 | Loss: 0.00001916
Iteration 44/1000 | Loss: 0.00001916
Iteration 45/1000 | Loss: 0.00001916
Iteration 46/1000 | Loss: 0.00001916
Iteration 47/1000 | Loss: 0.00001916
Iteration 48/1000 | Loss: 0.00001915
Iteration 49/1000 | Loss: 0.00001915
Iteration 50/1000 | Loss: 0.00001915
Iteration 51/1000 | Loss: 0.00001915
Iteration 52/1000 | Loss: 0.00001915
Iteration 53/1000 | Loss: 0.00001915
Iteration 54/1000 | Loss: 0.00001915
Iteration 55/1000 | Loss: 0.00001914
Iteration 56/1000 | Loss: 0.00001914
Iteration 57/1000 | Loss: 0.00001914
Iteration 58/1000 | Loss: 0.00001914
Iteration 59/1000 | Loss: 0.00001914
Iteration 60/1000 | Loss: 0.00001914
Iteration 61/1000 | Loss: 0.00001914
Iteration 62/1000 | Loss: 0.00001913
Iteration 63/1000 | Loss: 0.00001913
Iteration 64/1000 | Loss: 0.00001913
Iteration 65/1000 | Loss: 0.00001913
Iteration 66/1000 | Loss: 0.00001913
Iteration 67/1000 | Loss: 0.00001913
Iteration 68/1000 | Loss: 0.00001913
Iteration 69/1000 | Loss: 0.00001913
Iteration 70/1000 | Loss: 0.00001913
Iteration 71/1000 | Loss: 0.00001913
Iteration 72/1000 | Loss: 0.00001913
Iteration 73/1000 | Loss: 0.00001913
Iteration 74/1000 | Loss: 0.00001913
Iteration 75/1000 | Loss: 0.00001913
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 75. Stopping optimization.
Last 5 losses: [1.9129816791974008e-05, 1.9129816791974008e-05, 1.9129816791974008e-05, 1.9129816791974008e-05, 1.9129816791974008e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9129816791974008e-05

Optimization complete. Final v2v error: 3.551504135131836 mm

Highest mean error: 4.648299694061279 mm for frame 38

Lowest mean error: 3.0992965698242188 mm for frame 133

Saving results

Total time: 52.64379048347473
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00824712
Iteration 2/25 | Loss: 0.00115020
Iteration 3/25 | Loss: 0.00075235
Iteration 4/25 | Loss: 0.00068270
Iteration 5/25 | Loss: 0.00066687
Iteration 6/25 | Loss: 0.00065889
Iteration 7/25 | Loss: 0.00065590
Iteration 8/25 | Loss: 0.00065538
Iteration 9/25 | Loss: 0.00065530
Iteration 10/25 | Loss: 0.00065529
Iteration 11/25 | Loss: 0.00065529
Iteration 12/25 | Loss: 0.00065529
Iteration 13/25 | Loss: 0.00065529
Iteration 14/25 | Loss: 0.00065529
Iteration 15/25 | Loss: 0.00065529
Iteration 16/25 | Loss: 0.00065529
Iteration 17/25 | Loss: 0.00065529
Iteration 18/25 | Loss: 0.00065529
Iteration 19/25 | Loss: 0.00065529
Iteration 20/25 | Loss: 0.00065529
Iteration 21/25 | Loss: 0.00065529
Iteration 22/25 | Loss: 0.00065529
Iteration 23/25 | Loss: 0.00065529
Iteration 24/25 | Loss: 0.00065529
Iteration 25/25 | Loss: 0.00065529

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.74639201
Iteration 2/25 | Loss: 0.00032821
Iteration 3/25 | Loss: 0.00032821
Iteration 4/25 | Loss: 0.00032821
Iteration 5/25 | Loss: 0.00032821
Iteration 6/25 | Loss: 0.00032821
Iteration 7/25 | Loss: 0.00032821
Iteration 8/25 | Loss: 0.00032821
Iteration 9/25 | Loss: 0.00032821
Iteration 10/25 | Loss: 0.00032821
Iteration 11/25 | Loss: 0.00032821
Iteration 12/25 | Loss: 0.00032821
Iteration 13/25 | Loss: 0.00032821
Iteration 14/25 | Loss: 0.00032821
Iteration 15/25 | Loss: 0.00032821
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00032820680644363165, 0.00032820680644363165, 0.00032820680644363165, 0.00032820680644363165, 0.00032820680644363165]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00032820680644363165

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032821
Iteration 2/1000 | Loss: 0.00002918
Iteration 3/1000 | Loss: 0.00002222
Iteration 4/1000 | Loss: 0.00002109
Iteration 5/1000 | Loss: 0.00002018
Iteration 6/1000 | Loss: 0.00001966
Iteration 7/1000 | Loss: 0.00001903
Iteration 8/1000 | Loss: 0.00001870
Iteration 9/1000 | Loss: 0.00001850
Iteration 10/1000 | Loss: 0.00001836
Iteration 11/1000 | Loss: 0.00001820
Iteration 12/1000 | Loss: 0.00001812
Iteration 13/1000 | Loss: 0.00002528
Iteration 14/1000 | Loss: 0.00001837
Iteration 15/1000 | Loss: 0.00001802
Iteration 16/1000 | Loss: 0.00001802
Iteration 17/1000 | Loss: 0.00001802
Iteration 18/1000 | Loss: 0.00001897
Iteration 19/1000 | Loss: 0.00001801
Iteration 20/1000 | Loss: 0.00001800
Iteration 21/1000 | Loss: 0.00001800
Iteration 22/1000 | Loss: 0.00001800
Iteration 23/1000 | Loss: 0.00001800
Iteration 24/1000 | Loss: 0.00001800
Iteration 25/1000 | Loss: 0.00001799
Iteration 26/1000 | Loss: 0.00001799
Iteration 27/1000 | Loss: 0.00001799
Iteration 28/1000 | Loss: 0.00001799
Iteration 29/1000 | Loss: 0.00001798
Iteration 30/1000 | Loss: 0.00001798
Iteration 31/1000 | Loss: 0.00001798
Iteration 32/1000 | Loss: 0.00001798
Iteration 33/1000 | Loss: 0.00001798
Iteration 34/1000 | Loss: 0.00001797
Iteration 35/1000 | Loss: 0.00001797
Iteration 36/1000 | Loss: 0.00001797
Iteration 37/1000 | Loss: 0.00001797
Iteration 38/1000 | Loss: 0.00001797
Iteration 39/1000 | Loss: 0.00001797
Iteration 40/1000 | Loss: 0.00001797
Iteration 41/1000 | Loss: 0.00001797
Iteration 42/1000 | Loss: 0.00001797
Iteration 43/1000 | Loss: 0.00001797
Iteration 44/1000 | Loss: 0.00001796
Iteration 45/1000 | Loss: 0.00001796
Iteration 46/1000 | Loss: 0.00001796
Iteration 47/1000 | Loss: 0.00001795
Iteration 48/1000 | Loss: 0.00001795
Iteration 49/1000 | Loss: 0.00001795
Iteration 50/1000 | Loss: 0.00001795
Iteration 51/1000 | Loss: 0.00001795
Iteration 52/1000 | Loss: 0.00001794
Iteration 53/1000 | Loss: 0.00001794
Iteration 54/1000 | Loss: 0.00001794
Iteration 55/1000 | Loss: 0.00001794
Iteration 56/1000 | Loss: 0.00001794
Iteration 57/1000 | Loss: 0.00001793
Iteration 58/1000 | Loss: 0.00001793
Iteration 59/1000 | Loss: 0.00001793
Iteration 60/1000 | Loss: 0.00001793
Iteration 61/1000 | Loss: 0.00001793
Iteration 62/1000 | Loss: 0.00001793
Iteration 63/1000 | Loss: 0.00001792
Iteration 64/1000 | Loss: 0.00001792
Iteration 65/1000 | Loss: 0.00001792
Iteration 66/1000 | Loss: 0.00001792
Iteration 67/1000 | Loss: 0.00001792
Iteration 68/1000 | Loss: 0.00001791
Iteration 69/1000 | Loss: 0.00001791
Iteration 70/1000 | Loss: 0.00001791
Iteration 71/1000 | Loss: 0.00001855
Iteration 72/1000 | Loss: 0.00001788
Iteration 73/1000 | Loss: 0.00001788
Iteration 74/1000 | Loss: 0.00001788
Iteration 75/1000 | Loss: 0.00001788
Iteration 76/1000 | Loss: 0.00001788
Iteration 77/1000 | Loss: 0.00001788
Iteration 78/1000 | Loss: 0.00001788
Iteration 79/1000 | Loss: 0.00001787
Iteration 80/1000 | Loss: 0.00001787
Iteration 81/1000 | Loss: 0.00001787
Iteration 82/1000 | Loss: 0.00001787
Iteration 83/1000 | Loss: 0.00001787
Iteration 84/1000 | Loss: 0.00001787
Iteration 85/1000 | Loss: 0.00001786
Iteration 86/1000 | Loss: 0.00001786
Iteration 87/1000 | Loss: 0.00001786
Iteration 88/1000 | Loss: 0.00001786
Iteration 89/1000 | Loss: 0.00001786
Iteration 90/1000 | Loss: 0.00001786
Iteration 91/1000 | Loss: 0.00001786
Iteration 92/1000 | Loss: 0.00001786
Iteration 93/1000 | Loss: 0.00001786
Iteration 94/1000 | Loss: 0.00001786
Iteration 95/1000 | Loss: 0.00001786
Iteration 96/1000 | Loss: 0.00001786
Iteration 97/1000 | Loss: 0.00001786
Iteration 98/1000 | Loss: 0.00001785
Iteration 99/1000 | Loss: 0.00001785
Iteration 100/1000 | Loss: 0.00001785
Iteration 101/1000 | Loss: 0.00001785
Iteration 102/1000 | Loss: 0.00001785
Iteration 103/1000 | Loss: 0.00001785
Iteration 104/1000 | Loss: 0.00001785
Iteration 105/1000 | Loss: 0.00001785
Iteration 106/1000 | Loss: 0.00001785
Iteration 107/1000 | Loss: 0.00001785
Iteration 108/1000 | Loss: 0.00001785
Iteration 109/1000 | Loss: 0.00001785
Iteration 110/1000 | Loss: 0.00001785
Iteration 111/1000 | Loss: 0.00001784
Iteration 112/1000 | Loss: 0.00001784
Iteration 113/1000 | Loss: 0.00001784
Iteration 114/1000 | Loss: 0.00001784
Iteration 115/1000 | Loss: 0.00001784
Iteration 116/1000 | Loss: 0.00001784
Iteration 117/1000 | Loss: 0.00001783
Iteration 118/1000 | Loss: 0.00001783
Iteration 119/1000 | Loss: 0.00001783
Iteration 120/1000 | Loss: 0.00001783
Iteration 121/1000 | Loss: 0.00001783
Iteration 122/1000 | Loss: 0.00001783
Iteration 123/1000 | Loss: 0.00001783
Iteration 124/1000 | Loss: 0.00001783
Iteration 125/1000 | Loss: 0.00001783
Iteration 126/1000 | Loss: 0.00001783
Iteration 127/1000 | Loss: 0.00001783
Iteration 128/1000 | Loss: 0.00001783
Iteration 129/1000 | Loss: 0.00001783
Iteration 130/1000 | Loss: 0.00001783
Iteration 131/1000 | Loss: 0.00001783
Iteration 132/1000 | Loss: 0.00001783
Iteration 133/1000 | Loss: 0.00001783
Iteration 134/1000 | Loss: 0.00001783
Iteration 135/1000 | Loss: 0.00001783
Iteration 136/1000 | Loss: 0.00001783
Iteration 137/1000 | Loss: 0.00001783
Iteration 138/1000 | Loss: 0.00001783
Iteration 139/1000 | Loss: 0.00001783
Iteration 140/1000 | Loss: 0.00001783
Iteration 141/1000 | Loss: 0.00001783
Iteration 142/1000 | Loss: 0.00001783
Iteration 143/1000 | Loss: 0.00001783
Iteration 144/1000 | Loss: 0.00001783
Iteration 145/1000 | Loss: 0.00001783
Iteration 146/1000 | Loss: 0.00001783
Iteration 147/1000 | Loss: 0.00001783
Iteration 148/1000 | Loss: 0.00001783
Iteration 149/1000 | Loss: 0.00001783
Iteration 150/1000 | Loss: 0.00001783
Iteration 151/1000 | Loss: 0.00001783
Iteration 152/1000 | Loss: 0.00001783
Iteration 153/1000 | Loss: 0.00001783
Iteration 154/1000 | Loss: 0.00001783
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [1.7829643184086308e-05, 1.7829643184086308e-05, 1.7829643184086308e-05, 1.7829643184086308e-05, 1.7829643184086308e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7829643184086308e-05

Optimization complete. Final v2v error: 3.503706932067871 mm

Highest mean error: 3.799584150314331 mm for frame 51

Lowest mean error: 3.1842477321624756 mm for frame 161

Saving results

Total time: 45.38555383682251
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01095444
Iteration 2/25 | Loss: 0.00197615
Iteration 3/25 | Loss: 0.00125261
Iteration 4/25 | Loss: 0.00110263
Iteration 5/25 | Loss: 0.00112637
Iteration 6/25 | Loss: 0.00110875
Iteration 7/25 | Loss: 0.00107355
Iteration 8/25 | Loss: 0.00103970
Iteration 9/25 | Loss: 0.00095656
Iteration 10/25 | Loss: 0.00092765
Iteration 11/25 | Loss: 0.00086562
Iteration 12/25 | Loss: 0.00083071
Iteration 13/25 | Loss: 0.00084729
Iteration 14/25 | Loss: 0.00083950
Iteration 15/25 | Loss: 0.00087727
Iteration 16/25 | Loss: 0.00079887
Iteration 17/25 | Loss: 0.00077394
Iteration 18/25 | Loss: 0.00075739
Iteration 19/25 | Loss: 0.00074691
Iteration 20/25 | Loss: 0.00074669
Iteration 21/25 | Loss: 0.00073941
Iteration 22/25 | Loss: 0.00073820
Iteration 23/25 | Loss: 0.00074093
Iteration 24/25 | Loss: 0.00073954
Iteration 25/25 | Loss: 0.00074511

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.74438858
Iteration 2/25 | Loss: 0.00142731
Iteration 3/25 | Loss: 0.00142731
Iteration 4/25 | Loss: 0.00142731
Iteration 5/25 | Loss: 0.00142731
Iteration 6/25 | Loss: 0.00142731
Iteration 7/25 | Loss: 0.00142731
Iteration 8/25 | Loss: 0.00142731
Iteration 9/25 | Loss: 0.00142731
Iteration 10/25 | Loss: 0.00142731
Iteration 11/25 | Loss: 0.00142731
Iteration 12/25 | Loss: 0.00142731
Iteration 13/25 | Loss: 0.00142731
Iteration 14/25 | Loss: 0.00142731
Iteration 15/25 | Loss: 0.00142731
Iteration 16/25 | Loss: 0.00142731
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0014273058623075485, 0.0014273058623075485, 0.0014273058623075485, 0.0014273058623075485, 0.0014273058623075485]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014273058623075485

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00142731
Iteration 2/1000 | Loss: 0.00093437
Iteration 3/1000 | Loss: 0.00075921
Iteration 4/1000 | Loss: 0.00040312
Iteration 5/1000 | Loss: 0.00039940
Iteration 6/1000 | Loss: 0.00103620
Iteration 7/1000 | Loss: 0.00144050
Iteration 8/1000 | Loss: 0.00079541
Iteration 9/1000 | Loss: 0.00120806
Iteration 10/1000 | Loss: 0.00168813
Iteration 11/1000 | Loss: 0.00079964
Iteration 12/1000 | Loss: 0.00049825
Iteration 13/1000 | Loss: 0.00051252
Iteration 14/1000 | Loss: 0.00036582
Iteration 15/1000 | Loss: 0.00071068
Iteration 16/1000 | Loss: 0.00179196
Iteration 17/1000 | Loss: 0.00050873
Iteration 18/1000 | Loss: 0.00080394
Iteration 19/1000 | Loss: 0.00046433
Iteration 20/1000 | Loss: 0.00011724
Iteration 21/1000 | Loss: 0.00010125
Iteration 22/1000 | Loss: 0.00009019
Iteration 23/1000 | Loss: 0.00067767
Iteration 24/1000 | Loss: 0.00032243
Iteration 25/1000 | Loss: 0.00041518
Iteration 26/1000 | Loss: 0.00070950
Iteration 27/1000 | Loss: 0.00032971
Iteration 28/1000 | Loss: 0.00052878
Iteration 29/1000 | Loss: 0.00101724
Iteration 30/1000 | Loss: 0.00064585
Iteration 31/1000 | Loss: 0.00008151
Iteration 32/1000 | Loss: 0.00007745
Iteration 33/1000 | Loss: 0.00008015
Iteration 34/1000 | Loss: 0.00006045
Iteration 35/1000 | Loss: 0.00398134
Iteration 36/1000 | Loss: 0.00202471
Iteration 37/1000 | Loss: 0.00014449
Iteration 38/1000 | Loss: 0.00007668
Iteration 39/1000 | Loss: 0.00082035
Iteration 40/1000 | Loss: 0.00056491
Iteration 41/1000 | Loss: 0.00076602
Iteration 42/1000 | Loss: 0.00040138
Iteration 43/1000 | Loss: 0.00038002
Iteration 44/1000 | Loss: 0.00061531
Iteration 45/1000 | Loss: 0.00007794
Iteration 46/1000 | Loss: 0.00062963
Iteration 47/1000 | Loss: 0.00033591
Iteration 48/1000 | Loss: 0.00067392
Iteration 49/1000 | Loss: 0.00034512
Iteration 50/1000 | Loss: 0.00085214
Iteration 51/1000 | Loss: 0.00054486
Iteration 52/1000 | Loss: 0.00010411
Iteration 53/1000 | Loss: 0.00092983
Iteration 54/1000 | Loss: 0.00007159
Iteration 55/1000 | Loss: 0.00006107
Iteration 56/1000 | Loss: 0.00006454
Iteration 57/1000 | Loss: 0.00008814
Iteration 58/1000 | Loss: 0.00006378
Iteration 59/1000 | Loss: 0.00005786
Iteration 60/1000 | Loss: 0.00007594
Iteration 61/1000 | Loss: 0.00473536
Iteration 62/1000 | Loss: 0.00286213
Iteration 63/1000 | Loss: 0.00246176
Iteration 64/1000 | Loss: 0.00251508
Iteration 65/1000 | Loss: 0.00268951
Iteration 66/1000 | Loss: 0.00012247
Iteration 67/1000 | Loss: 0.00218216
Iteration 68/1000 | Loss: 0.00048673
Iteration 69/1000 | Loss: 0.00041645
Iteration 70/1000 | Loss: 0.00035119
Iteration 71/1000 | Loss: 0.00018726
Iteration 72/1000 | Loss: 0.00012507
Iteration 73/1000 | Loss: 0.00322740
Iteration 74/1000 | Loss: 0.00019464
Iteration 75/1000 | Loss: 0.00016828
Iteration 76/1000 | Loss: 0.00008572
Iteration 77/1000 | Loss: 0.00017493
Iteration 78/1000 | Loss: 0.00010185
Iteration 79/1000 | Loss: 0.00006202
Iteration 80/1000 | Loss: 0.00005150
Iteration 81/1000 | Loss: 0.00005470
Iteration 82/1000 | Loss: 0.00006434
Iteration 83/1000 | Loss: 0.00007373
Iteration 84/1000 | Loss: 0.00006147
Iteration 85/1000 | Loss: 0.00007022
Iteration 86/1000 | Loss: 0.00043585
Iteration 87/1000 | Loss: 0.00038019
Iteration 88/1000 | Loss: 0.00023179
Iteration 89/1000 | Loss: 0.00011959
Iteration 90/1000 | Loss: 0.00015657
Iteration 91/1000 | Loss: 0.00006011
Iteration 92/1000 | Loss: 0.00005906
Iteration 93/1000 | Loss: 0.00005587
Iteration 94/1000 | Loss: 0.00006068
Iteration 95/1000 | Loss: 0.00005137
Iteration 96/1000 | Loss: 0.00005987
Iteration 97/1000 | Loss: 0.00005033
Iteration 98/1000 | Loss: 0.00005928
Iteration 99/1000 | Loss: 0.00006154
Iteration 100/1000 | Loss: 0.00006467
Iteration 101/1000 | Loss: 0.00005881
Iteration 102/1000 | Loss: 0.00006032
Iteration 103/1000 | Loss: 0.00004213
Iteration 104/1000 | Loss: 0.00004109
Iteration 105/1000 | Loss: 0.00006065
Iteration 106/1000 | Loss: 0.00006297
Iteration 107/1000 | Loss: 0.00006716
Iteration 108/1000 | Loss: 0.00005716
Iteration 109/1000 | Loss: 0.00005898
Iteration 110/1000 | Loss: 0.00005622
Iteration 111/1000 | Loss: 0.00005887
Iteration 112/1000 | Loss: 0.00006448
Iteration 113/1000 | Loss: 0.00006078
Iteration 114/1000 | Loss: 0.00005941
Iteration 115/1000 | Loss: 0.00005166
Iteration 116/1000 | Loss: 0.00006647
Iteration 117/1000 | Loss: 0.00005939
Iteration 118/1000 | Loss: 0.00006316
Iteration 119/1000 | Loss: 0.00006253
Iteration 120/1000 | Loss: 0.00005925
Iteration 121/1000 | Loss: 0.00006273
Iteration 122/1000 | Loss: 0.00005990
Iteration 123/1000 | Loss: 0.00005289
Iteration 124/1000 | Loss: 0.00005712
Iteration 125/1000 | Loss: 0.00005620
Iteration 126/1000 | Loss: 0.00005908
Iteration 127/1000 | Loss: 0.00005763
Iteration 128/1000 | Loss: 0.00006416
Iteration 129/1000 | Loss: 0.00005475
Iteration 130/1000 | Loss: 0.00006015
Iteration 131/1000 | Loss: 0.00005579
Iteration 132/1000 | Loss: 0.00005887
Iteration 133/1000 | Loss: 0.00005165
Iteration 134/1000 | Loss: 0.00007313
Iteration 135/1000 | Loss: 0.00005734
Iteration 136/1000 | Loss: 0.00005024
Iteration 137/1000 | Loss: 0.00004972
Iteration 138/1000 | Loss: 0.00006177
Iteration 139/1000 | Loss: 0.00005449
Iteration 140/1000 | Loss: 0.00006007
Iteration 141/1000 | Loss: 0.00005483
Iteration 142/1000 | Loss: 0.00005708
Iteration 143/1000 | Loss: 0.00005142
Iteration 144/1000 | Loss: 0.00005857
Iteration 145/1000 | Loss: 0.00005788
Iteration 146/1000 | Loss: 0.00005726
Iteration 147/1000 | Loss: 0.00005585
Iteration 148/1000 | Loss: 0.00006067
Iteration 149/1000 | Loss: 0.00003230
Iteration 150/1000 | Loss: 0.00009129
Iteration 151/1000 | Loss: 0.00006020
Iteration 152/1000 | Loss: 0.00005616
Iteration 153/1000 | Loss: 0.00005773
Iteration 154/1000 | Loss: 0.00005358
Iteration 155/1000 | Loss: 0.00005803
Iteration 156/1000 | Loss: 0.00005352
Iteration 157/1000 | Loss: 0.00005369
Iteration 158/1000 | Loss: 0.00006775
Iteration 159/1000 | Loss: 0.00005639
Iteration 160/1000 | Loss: 0.00006010
Iteration 161/1000 | Loss: 0.00005628
Iteration 162/1000 | Loss: 0.00005633
Iteration 163/1000 | Loss: 0.00005718
Iteration 164/1000 | Loss: 0.00005864
Iteration 165/1000 | Loss: 0.00003780
Iteration 166/1000 | Loss: 0.00004472
Iteration 167/1000 | Loss: 0.00005796
Iteration 168/1000 | Loss: 0.00005641
Iteration 169/1000 | Loss: 0.00006005
Iteration 170/1000 | Loss: 0.00005999
Iteration 171/1000 | Loss: 0.00005705
Iteration 172/1000 | Loss: 0.00005813
Iteration 173/1000 | Loss: 0.00005600
Iteration 174/1000 | Loss: 0.00005795
Iteration 175/1000 | Loss: 0.00006159
Iteration 176/1000 | Loss: 0.00006312
Iteration 177/1000 | Loss: 0.00005410
Iteration 178/1000 | Loss: 0.00005927
Iteration 179/1000 | Loss: 0.00005443
Iteration 180/1000 | Loss: 0.00005304
Iteration 181/1000 | Loss: 0.00005206
Iteration 182/1000 | Loss: 0.00005777
Iteration 183/1000 | Loss: 0.00005411
Iteration 184/1000 | Loss: 0.00005400
Iteration 185/1000 | Loss: 0.00005334
Iteration 186/1000 | Loss: 0.00005570
Iteration 187/1000 | Loss: 0.00004422
Iteration 188/1000 | Loss: 0.00005558
Iteration 189/1000 | Loss: 0.00006318
Iteration 190/1000 | Loss: 0.00006003
Iteration 191/1000 | Loss: 0.00004486
Iteration 192/1000 | Loss: 0.00008854
Iteration 193/1000 | Loss: 0.00004691
Iteration 194/1000 | Loss: 0.00005514
Iteration 195/1000 | Loss: 0.00005227
Iteration 196/1000 | Loss: 0.00004930
Iteration 197/1000 | Loss: 0.00004697
Iteration 198/1000 | Loss: 0.00005228
Iteration 199/1000 | Loss: 0.00005281
Iteration 200/1000 | Loss: 0.00005261
Iteration 201/1000 | Loss: 0.00005647
Iteration 202/1000 | Loss: 0.00005831
Iteration 203/1000 | Loss: 0.00004762
Iteration 204/1000 | Loss: 0.00002088
Iteration 205/1000 | Loss: 0.00001835
Iteration 206/1000 | Loss: 0.00001693
Iteration 207/1000 | Loss: 0.00001619
Iteration 208/1000 | Loss: 0.00001586
Iteration 209/1000 | Loss: 0.00001576
Iteration 210/1000 | Loss: 0.00001572
Iteration 211/1000 | Loss: 0.00001558
Iteration 212/1000 | Loss: 0.00001542
Iteration 213/1000 | Loss: 0.00001542
Iteration 214/1000 | Loss: 0.00001542
Iteration 215/1000 | Loss: 0.00001541
Iteration 216/1000 | Loss: 0.00001541
Iteration 217/1000 | Loss: 0.00001540
Iteration 218/1000 | Loss: 0.00001540
Iteration 219/1000 | Loss: 0.00001540
Iteration 220/1000 | Loss: 0.00001540
Iteration 221/1000 | Loss: 0.00001539
Iteration 222/1000 | Loss: 0.00001539
Iteration 223/1000 | Loss: 0.00001538
Iteration 224/1000 | Loss: 0.00001538
Iteration 225/1000 | Loss: 0.00001538
Iteration 226/1000 | Loss: 0.00001537
Iteration 227/1000 | Loss: 0.00001537
Iteration 228/1000 | Loss: 0.00001536
Iteration 229/1000 | Loss: 0.00001536
Iteration 230/1000 | Loss: 0.00001535
Iteration 231/1000 | Loss: 0.00001535
Iteration 232/1000 | Loss: 0.00001535
Iteration 233/1000 | Loss: 0.00001534
Iteration 234/1000 | Loss: 0.00001534
Iteration 235/1000 | Loss: 0.00001534
Iteration 236/1000 | Loss: 0.00001532
Iteration 237/1000 | Loss: 0.00001529
Iteration 238/1000 | Loss: 0.00001528
Iteration 239/1000 | Loss: 0.00001528
Iteration 240/1000 | Loss: 0.00001527
Iteration 241/1000 | Loss: 0.00001527
Iteration 242/1000 | Loss: 0.00001526
Iteration 243/1000 | Loss: 0.00001522
Iteration 244/1000 | Loss: 0.00001521
Iteration 245/1000 | Loss: 0.00001521
Iteration 246/1000 | Loss: 0.00001520
Iteration 247/1000 | Loss: 0.00001519
Iteration 248/1000 | Loss: 0.00001518
Iteration 249/1000 | Loss: 0.00001516
Iteration 250/1000 | Loss: 0.00001515
Iteration 251/1000 | Loss: 0.00001515
Iteration 252/1000 | Loss: 0.00001515
Iteration 253/1000 | Loss: 0.00001514
Iteration 254/1000 | Loss: 0.00001514
Iteration 255/1000 | Loss: 0.00001514
Iteration 256/1000 | Loss: 0.00001513
Iteration 257/1000 | Loss: 0.00001513
Iteration 258/1000 | Loss: 0.00001513
Iteration 259/1000 | Loss: 0.00001513
Iteration 260/1000 | Loss: 0.00001512
Iteration 261/1000 | Loss: 0.00001512
Iteration 262/1000 | Loss: 0.00001512
Iteration 263/1000 | Loss: 0.00001512
Iteration 264/1000 | Loss: 0.00001511
Iteration 265/1000 | Loss: 0.00001511
Iteration 266/1000 | Loss: 0.00001511
Iteration 267/1000 | Loss: 0.00001511
Iteration 268/1000 | Loss: 0.00001511
Iteration 269/1000 | Loss: 0.00001511
Iteration 270/1000 | Loss: 0.00001511
Iteration 271/1000 | Loss: 0.00001511
Iteration 272/1000 | Loss: 0.00001511
Iteration 273/1000 | Loss: 0.00001511
Iteration 274/1000 | Loss: 0.00001511
Iteration 275/1000 | Loss: 0.00001511
Iteration 276/1000 | Loss: 0.00001511
Iteration 277/1000 | Loss: 0.00001511
Iteration 278/1000 | Loss: 0.00001511
Iteration 279/1000 | Loss: 0.00001511
Iteration 280/1000 | Loss: 0.00001511
Iteration 281/1000 | Loss: 0.00001511
Iteration 282/1000 | Loss: 0.00001511
Iteration 283/1000 | Loss: 0.00001511
Iteration 284/1000 | Loss: 0.00001511
Iteration 285/1000 | Loss: 0.00001511
Iteration 286/1000 | Loss: 0.00001511
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 286. Stopping optimization.
Last 5 losses: [1.510572838014923e-05, 1.510572838014923e-05, 1.510572838014923e-05, 1.510572838014923e-05, 1.510572838014923e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.510572838014923e-05

Optimization complete. Final v2v error: 3.2178399562835693 mm

Highest mean error: 5.519360542297363 mm for frame 96

Lowest mean error: 2.8310439586639404 mm for frame 158

Saving results

Total time: 340.5183935165405
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00838369
Iteration 2/25 | Loss: 0.00144371
Iteration 3/25 | Loss: 0.00088059
Iteration 4/25 | Loss: 0.00077834
Iteration 5/25 | Loss: 0.00075449
Iteration 6/25 | Loss: 0.00076072
Iteration 7/25 | Loss: 0.00075994
Iteration 8/25 | Loss: 0.00075050
Iteration 9/25 | Loss: 0.00073560
Iteration 10/25 | Loss: 0.00073342
Iteration 11/25 | Loss: 0.00073839
Iteration 12/25 | Loss: 0.00072802
Iteration 13/25 | Loss: 0.00072220
Iteration 14/25 | Loss: 0.00072297
Iteration 15/25 | Loss: 0.00072316
Iteration 16/25 | Loss: 0.00072121
Iteration 17/25 | Loss: 0.00071557
Iteration 18/25 | Loss: 0.00071674
Iteration 19/25 | Loss: 0.00071802
Iteration 20/25 | Loss: 0.00071481
Iteration 21/25 | Loss: 0.00071649
Iteration 22/25 | Loss: 0.00071454
Iteration 23/25 | Loss: 0.00071263
Iteration 24/25 | Loss: 0.00070962
Iteration 25/25 | Loss: 0.00070857

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.61870289
Iteration 2/25 | Loss: 0.00039210
Iteration 3/25 | Loss: 0.00036782
Iteration 4/25 | Loss: 0.00036782
Iteration 5/25 | Loss: 0.00036782
Iteration 6/25 | Loss: 0.00036782
Iteration 7/25 | Loss: 0.00036782
Iteration 8/25 | Loss: 0.00036782
Iteration 9/25 | Loss: 0.00036782
Iteration 10/25 | Loss: 0.00036782
Iteration 11/25 | Loss: 0.00036782
Iteration 12/25 | Loss: 0.00036782
Iteration 13/25 | Loss: 0.00036782
Iteration 14/25 | Loss: 0.00036782
Iteration 15/25 | Loss: 0.00036782
Iteration 16/25 | Loss: 0.00036782
Iteration 17/25 | Loss: 0.00036782
Iteration 18/25 | Loss: 0.00036782
Iteration 19/25 | Loss: 0.00036782
Iteration 20/25 | Loss: 0.00036782
Iteration 21/25 | Loss: 0.00036782
Iteration 22/25 | Loss: 0.00036782
Iteration 23/25 | Loss: 0.00036782
Iteration 24/25 | Loss: 0.00036782
Iteration 25/25 | Loss: 0.00036782
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00036781970993615687, 0.00036781970993615687, 0.00036781970993615687, 0.00036781970993615687, 0.00036781970993615687]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00036781970993615687

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00036782
Iteration 2/1000 | Loss: 0.00005629
Iteration 3/1000 | Loss: 0.00002377
Iteration 4/1000 | Loss: 0.00005955
Iteration 5/1000 | Loss: 0.00002026
Iteration 6/1000 | Loss: 0.00001964
Iteration 7/1000 | Loss: 0.00001897
Iteration 8/1000 | Loss: 0.00005713
Iteration 9/1000 | Loss: 0.00002178
Iteration 10/1000 | Loss: 0.00001971
Iteration 11/1000 | Loss: 0.00001818
Iteration 12/1000 | Loss: 0.00004777
Iteration 13/1000 | Loss: 0.00001797
Iteration 14/1000 | Loss: 0.00001841
Iteration 15/1000 | Loss: 0.00001820
Iteration 16/1000 | Loss: 0.00001748
Iteration 17/1000 | Loss: 0.00003042
Iteration 18/1000 | Loss: 0.00001749
Iteration 19/1000 | Loss: 0.00002059
Iteration 20/1000 | Loss: 0.00001696
Iteration 21/1000 | Loss: 0.00002194
Iteration 22/1000 | Loss: 0.00003551
Iteration 23/1000 | Loss: 0.00001675
Iteration 24/1000 | Loss: 0.00001675
Iteration 25/1000 | Loss: 0.00001675
Iteration 26/1000 | Loss: 0.00001675
Iteration 27/1000 | Loss: 0.00001675
Iteration 28/1000 | Loss: 0.00001671
Iteration 29/1000 | Loss: 0.00001669
Iteration 30/1000 | Loss: 0.00001845
Iteration 31/1000 | Loss: 0.00001659
Iteration 32/1000 | Loss: 0.00001657
Iteration 33/1000 | Loss: 0.00001916
Iteration 34/1000 | Loss: 0.00001651
Iteration 35/1000 | Loss: 0.00001651
Iteration 36/1000 | Loss: 0.00001650
Iteration 37/1000 | Loss: 0.00001648
Iteration 38/1000 | Loss: 0.00001648
Iteration 39/1000 | Loss: 0.00001645
Iteration 40/1000 | Loss: 0.00001645
Iteration 41/1000 | Loss: 0.00001644
Iteration 42/1000 | Loss: 0.00001644
Iteration 43/1000 | Loss: 0.00001643
Iteration 44/1000 | Loss: 0.00001642
Iteration 45/1000 | Loss: 0.00001642
Iteration 46/1000 | Loss: 0.00001641
Iteration 47/1000 | Loss: 0.00001641
Iteration 48/1000 | Loss: 0.00001641
Iteration 49/1000 | Loss: 0.00001641
Iteration 50/1000 | Loss: 0.00001640
Iteration 51/1000 | Loss: 0.00001640
Iteration 52/1000 | Loss: 0.00001640
Iteration 53/1000 | Loss: 0.00001640
Iteration 54/1000 | Loss: 0.00001640
Iteration 55/1000 | Loss: 0.00001639
Iteration 56/1000 | Loss: 0.00001639
Iteration 57/1000 | Loss: 0.00001639
Iteration 58/1000 | Loss: 0.00001638
Iteration 59/1000 | Loss: 0.00001638
Iteration 60/1000 | Loss: 0.00001638
Iteration 61/1000 | Loss: 0.00001638
Iteration 62/1000 | Loss: 0.00001637
Iteration 63/1000 | Loss: 0.00001637
Iteration 64/1000 | Loss: 0.00001636
Iteration 65/1000 | Loss: 0.00002981
Iteration 66/1000 | Loss: 0.00001633
Iteration 67/1000 | Loss: 0.00001633
Iteration 68/1000 | Loss: 0.00001633
Iteration 69/1000 | Loss: 0.00001633
Iteration 70/1000 | Loss: 0.00001633
Iteration 71/1000 | Loss: 0.00001632
Iteration 72/1000 | Loss: 0.00001632
Iteration 73/1000 | Loss: 0.00001632
Iteration 74/1000 | Loss: 0.00001632
Iteration 75/1000 | Loss: 0.00001632
Iteration 76/1000 | Loss: 0.00001632
Iteration 77/1000 | Loss: 0.00001632
Iteration 78/1000 | Loss: 0.00001632
Iteration 79/1000 | Loss: 0.00001632
Iteration 80/1000 | Loss: 0.00001632
Iteration 81/1000 | Loss: 0.00001632
Iteration 82/1000 | Loss: 0.00001632
Iteration 83/1000 | Loss: 0.00001632
Iteration 84/1000 | Loss: 0.00001632
Iteration 85/1000 | Loss: 0.00001632
Iteration 86/1000 | Loss: 0.00001632
Iteration 87/1000 | Loss: 0.00001632
Iteration 88/1000 | Loss: 0.00001632
Iteration 89/1000 | Loss: 0.00001632
Iteration 90/1000 | Loss: 0.00001632
Iteration 91/1000 | Loss: 0.00001632
Iteration 92/1000 | Loss: 0.00001632
Iteration 93/1000 | Loss: 0.00001632
Iteration 94/1000 | Loss: 0.00001632
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.6315376342390664e-05, 1.6315376342390664e-05, 1.6315376342390664e-05, 1.6315376342390664e-05, 1.6315376342390664e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6315376342390664e-05

Optimization complete. Final v2v error: 3.438971996307373 mm

Highest mean error: 4.3929123878479 mm for frame 108

Lowest mean error: 2.9565398693084717 mm for frame 94

Saving results

Total time: 98.11696767807007
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00988157
Iteration 2/25 | Loss: 0.00233079
Iteration 3/25 | Loss: 0.00167799
Iteration 4/25 | Loss: 0.00127343
Iteration 5/25 | Loss: 0.00153720
Iteration 6/25 | Loss: 0.00129270
Iteration 7/25 | Loss: 0.00112194
Iteration 8/25 | Loss: 0.00088834
Iteration 9/25 | Loss: 0.00079361
Iteration 10/25 | Loss: 0.00076270
Iteration 11/25 | Loss: 0.00075917
Iteration 12/25 | Loss: 0.00074400
Iteration 13/25 | Loss: 0.00074144
Iteration 14/25 | Loss: 0.00074082
Iteration 15/25 | Loss: 0.00074798
Iteration 16/25 | Loss: 0.00074077
Iteration 17/25 | Loss: 0.00073802
Iteration 18/25 | Loss: 0.00073699
Iteration 19/25 | Loss: 0.00073478
Iteration 20/25 | Loss: 0.00072587
Iteration 21/25 | Loss: 0.00072432
Iteration 22/25 | Loss: 0.00072247
Iteration 23/25 | Loss: 0.00072203
Iteration 24/25 | Loss: 0.00072163
Iteration 25/25 | Loss: 0.00072149

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51523125
Iteration 2/25 | Loss: 0.00054781
Iteration 3/25 | Loss: 0.00054780
Iteration 4/25 | Loss: 0.00054780
Iteration 5/25 | Loss: 0.00054780
Iteration 6/25 | Loss: 0.00054780
Iteration 7/25 | Loss: 0.00054780
Iteration 8/25 | Loss: 0.00054780
Iteration 9/25 | Loss: 0.00054780
Iteration 10/25 | Loss: 0.00054780
Iteration 11/25 | Loss: 0.00054780
Iteration 12/25 | Loss: 0.00054780
Iteration 13/25 | Loss: 0.00054780
Iteration 14/25 | Loss: 0.00054780
Iteration 15/25 | Loss: 0.00054780
Iteration 16/25 | Loss: 0.00054780
Iteration 17/25 | Loss: 0.00054780
Iteration 18/25 | Loss: 0.00054780
Iteration 19/25 | Loss: 0.00054780
Iteration 20/25 | Loss: 0.00054780
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0005478017847053707, 0.0005478017847053707, 0.0005478017847053707, 0.0005478017847053707, 0.0005478017847053707]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005478017847053707

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054780
Iteration 2/1000 | Loss: 0.00124392
Iteration 3/1000 | Loss: 0.00102188
Iteration 4/1000 | Loss: 0.00149536
Iteration 5/1000 | Loss: 0.00095926
Iteration 6/1000 | Loss: 0.00035237
Iteration 7/1000 | Loss: 0.00025735
Iteration 8/1000 | Loss: 0.00006127
Iteration 9/1000 | Loss: 0.00005039
Iteration 10/1000 | Loss: 0.00022048
Iteration 11/1000 | Loss: 0.00011788
Iteration 12/1000 | Loss: 0.00044678
Iteration 13/1000 | Loss: 0.00018996
Iteration 14/1000 | Loss: 0.00003294
Iteration 15/1000 | Loss: 0.00003002
Iteration 16/1000 | Loss: 0.00024765
Iteration 17/1000 | Loss: 0.00067437
Iteration 18/1000 | Loss: 0.00046712
Iteration 19/1000 | Loss: 0.00084788
Iteration 20/1000 | Loss: 0.00078404
Iteration 21/1000 | Loss: 0.00034615
Iteration 22/1000 | Loss: 0.00024616
Iteration 23/1000 | Loss: 0.00069126
Iteration 24/1000 | Loss: 0.00034782
Iteration 25/1000 | Loss: 0.00130215
Iteration 26/1000 | Loss: 0.00026421
Iteration 27/1000 | Loss: 0.00204444
Iteration 28/1000 | Loss: 0.00056022
Iteration 29/1000 | Loss: 0.00018465
Iteration 30/1000 | Loss: 0.00002985
Iteration 31/1000 | Loss: 0.00002673
Iteration 32/1000 | Loss: 0.00002429
Iteration 33/1000 | Loss: 0.00002299
Iteration 34/1000 | Loss: 0.00002183
Iteration 35/1000 | Loss: 0.00002101
Iteration 36/1000 | Loss: 0.00002020
Iteration 37/1000 | Loss: 0.00001942
Iteration 38/1000 | Loss: 0.00001907
Iteration 39/1000 | Loss: 0.00012602
Iteration 40/1000 | Loss: 0.00002031
Iteration 41/1000 | Loss: 0.00001808
Iteration 42/1000 | Loss: 0.00001684
Iteration 43/1000 | Loss: 0.00001584
Iteration 44/1000 | Loss: 0.00001509
Iteration 45/1000 | Loss: 0.00001480
Iteration 46/1000 | Loss: 0.00001446
Iteration 47/1000 | Loss: 0.00001436
Iteration 48/1000 | Loss: 0.00001432
Iteration 49/1000 | Loss: 0.00001424
Iteration 50/1000 | Loss: 0.00001422
Iteration 51/1000 | Loss: 0.00001422
Iteration 52/1000 | Loss: 0.00001421
Iteration 53/1000 | Loss: 0.00001421
Iteration 54/1000 | Loss: 0.00001420
Iteration 55/1000 | Loss: 0.00001419
Iteration 56/1000 | Loss: 0.00001418
Iteration 57/1000 | Loss: 0.00001418
Iteration 58/1000 | Loss: 0.00001416
Iteration 59/1000 | Loss: 0.00001416
Iteration 60/1000 | Loss: 0.00001416
Iteration 61/1000 | Loss: 0.00001414
Iteration 62/1000 | Loss: 0.00001414
Iteration 63/1000 | Loss: 0.00001414
Iteration 64/1000 | Loss: 0.00001414
Iteration 65/1000 | Loss: 0.00001414
Iteration 66/1000 | Loss: 0.00001414
Iteration 67/1000 | Loss: 0.00001414
Iteration 68/1000 | Loss: 0.00001414
Iteration 69/1000 | Loss: 0.00001413
Iteration 70/1000 | Loss: 0.00001413
Iteration 71/1000 | Loss: 0.00001413
Iteration 72/1000 | Loss: 0.00001412
Iteration 73/1000 | Loss: 0.00001412
Iteration 74/1000 | Loss: 0.00001411
Iteration 75/1000 | Loss: 0.00001411
Iteration 76/1000 | Loss: 0.00001411
Iteration 77/1000 | Loss: 0.00001411
Iteration 78/1000 | Loss: 0.00001411
Iteration 79/1000 | Loss: 0.00001410
Iteration 80/1000 | Loss: 0.00001410
Iteration 81/1000 | Loss: 0.00001410
Iteration 82/1000 | Loss: 0.00001410
Iteration 83/1000 | Loss: 0.00001410
Iteration 84/1000 | Loss: 0.00001410
Iteration 85/1000 | Loss: 0.00001410
Iteration 86/1000 | Loss: 0.00001410
Iteration 87/1000 | Loss: 0.00001409
Iteration 88/1000 | Loss: 0.00001409
Iteration 89/1000 | Loss: 0.00001409
Iteration 90/1000 | Loss: 0.00001409
Iteration 91/1000 | Loss: 0.00001408
Iteration 92/1000 | Loss: 0.00001408
Iteration 93/1000 | Loss: 0.00001408
Iteration 94/1000 | Loss: 0.00018899
Iteration 95/1000 | Loss: 0.00012318
Iteration 96/1000 | Loss: 0.00001570
Iteration 97/1000 | Loss: 0.00018242
Iteration 98/1000 | Loss: 0.00004543
Iteration 99/1000 | Loss: 0.00002728
Iteration 100/1000 | Loss: 0.00002125
Iteration 101/1000 | Loss: 0.00001891
Iteration 102/1000 | Loss: 0.00001802
Iteration 103/1000 | Loss: 0.00001729
Iteration 104/1000 | Loss: 0.00019933
Iteration 105/1000 | Loss: 0.00002312
Iteration 106/1000 | Loss: 0.00001598
Iteration 107/1000 | Loss: 0.00001460
Iteration 108/1000 | Loss: 0.00001423
Iteration 109/1000 | Loss: 0.00001412
Iteration 110/1000 | Loss: 0.00001404
Iteration 111/1000 | Loss: 0.00001402
Iteration 112/1000 | Loss: 0.00001394
Iteration 113/1000 | Loss: 0.00001394
Iteration 114/1000 | Loss: 0.00001393
Iteration 115/1000 | Loss: 0.00001390
Iteration 116/1000 | Loss: 0.00001388
Iteration 117/1000 | Loss: 0.00001388
Iteration 118/1000 | Loss: 0.00001382
Iteration 119/1000 | Loss: 0.00001373
Iteration 120/1000 | Loss: 0.00001372
Iteration 121/1000 | Loss: 0.00001368
Iteration 122/1000 | Loss: 0.00001368
Iteration 123/1000 | Loss: 0.00001367
Iteration 124/1000 | Loss: 0.00001367
Iteration 125/1000 | Loss: 0.00001367
Iteration 126/1000 | Loss: 0.00001367
Iteration 127/1000 | Loss: 0.00001367
Iteration 128/1000 | Loss: 0.00001367
Iteration 129/1000 | Loss: 0.00001367
Iteration 130/1000 | Loss: 0.00001367
Iteration 131/1000 | Loss: 0.00001367
Iteration 132/1000 | Loss: 0.00001367
Iteration 133/1000 | Loss: 0.00001367
Iteration 134/1000 | Loss: 0.00001367
Iteration 135/1000 | Loss: 0.00001367
Iteration 136/1000 | Loss: 0.00001367
Iteration 137/1000 | Loss: 0.00001367
Iteration 138/1000 | Loss: 0.00001366
Iteration 139/1000 | Loss: 0.00001365
Iteration 140/1000 | Loss: 0.00001365
Iteration 141/1000 | Loss: 0.00001364
Iteration 142/1000 | Loss: 0.00001364
Iteration 143/1000 | Loss: 0.00001364
Iteration 144/1000 | Loss: 0.00001364
Iteration 145/1000 | Loss: 0.00001363
Iteration 146/1000 | Loss: 0.00001361
Iteration 147/1000 | Loss: 0.00001361
Iteration 148/1000 | Loss: 0.00001361
Iteration 149/1000 | Loss: 0.00001360
Iteration 150/1000 | Loss: 0.00001360
Iteration 151/1000 | Loss: 0.00001359
Iteration 152/1000 | Loss: 0.00001359
Iteration 153/1000 | Loss: 0.00001358
Iteration 154/1000 | Loss: 0.00001358
Iteration 155/1000 | Loss: 0.00001357
Iteration 156/1000 | Loss: 0.00001357
Iteration 157/1000 | Loss: 0.00001356
Iteration 158/1000 | Loss: 0.00001356
Iteration 159/1000 | Loss: 0.00001356
Iteration 160/1000 | Loss: 0.00001356
Iteration 161/1000 | Loss: 0.00001356
Iteration 162/1000 | Loss: 0.00001355
Iteration 163/1000 | Loss: 0.00001355
Iteration 164/1000 | Loss: 0.00001354
Iteration 165/1000 | Loss: 0.00001354
Iteration 166/1000 | Loss: 0.00001354
Iteration 167/1000 | Loss: 0.00001353
Iteration 168/1000 | Loss: 0.00001353
Iteration 169/1000 | Loss: 0.00001353
Iteration 170/1000 | Loss: 0.00001353
Iteration 171/1000 | Loss: 0.00001353
Iteration 172/1000 | Loss: 0.00001352
Iteration 173/1000 | Loss: 0.00001352
Iteration 174/1000 | Loss: 0.00001352
Iteration 175/1000 | Loss: 0.00001352
Iteration 176/1000 | Loss: 0.00001352
Iteration 177/1000 | Loss: 0.00001351
Iteration 178/1000 | Loss: 0.00001351
Iteration 179/1000 | Loss: 0.00001351
Iteration 180/1000 | Loss: 0.00001351
Iteration 181/1000 | Loss: 0.00001351
Iteration 182/1000 | Loss: 0.00001350
Iteration 183/1000 | Loss: 0.00001350
Iteration 184/1000 | Loss: 0.00001350
Iteration 185/1000 | Loss: 0.00001350
Iteration 186/1000 | Loss: 0.00001350
Iteration 187/1000 | Loss: 0.00001350
Iteration 188/1000 | Loss: 0.00001349
Iteration 189/1000 | Loss: 0.00001349
Iteration 190/1000 | Loss: 0.00001349
Iteration 191/1000 | Loss: 0.00001349
Iteration 192/1000 | Loss: 0.00001349
Iteration 193/1000 | Loss: 0.00001349
Iteration 194/1000 | Loss: 0.00001349
Iteration 195/1000 | Loss: 0.00001349
Iteration 196/1000 | Loss: 0.00001349
Iteration 197/1000 | Loss: 0.00001349
Iteration 198/1000 | Loss: 0.00001349
Iteration 199/1000 | Loss: 0.00001348
Iteration 200/1000 | Loss: 0.00001348
Iteration 201/1000 | Loss: 0.00001348
Iteration 202/1000 | Loss: 0.00001348
Iteration 203/1000 | Loss: 0.00001348
Iteration 204/1000 | Loss: 0.00001348
Iteration 205/1000 | Loss: 0.00001348
Iteration 206/1000 | Loss: 0.00001348
Iteration 207/1000 | Loss: 0.00001348
Iteration 208/1000 | Loss: 0.00001348
Iteration 209/1000 | Loss: 0.00001348
Iteration 210/1000 | Loss: 0.00001347
Iteration 211/1000 | Loss: 0.00001347
Iteration 212/1000 | Loss: 0.00001347
Iteration 213/1000 | Loss: 0.00001347
Iteration 214/1000 | Loss: 0.00001347
Iteration 215/1000 | Loss: 0.00001347
Iteration 216/1000 | Loss: 0.00001347
Iteration 217/1000 | Loss: 0.00001347
Iteration 218/1000 | Loss: 0.00001347
Iteration 219/1000 | Loss: 0.00001347
Iteration 220/1000 | Loss: 0.00001347
Iteration 221/1000 | Loss: 0.00001347
Iteration 222/1000 | Loss: 0.00001347
Iteration 223/1000 | Loss: 0.00001347
Iteration 224/1000 | Loss: 0.00001347
Iteration 225/1000 | Loss: 0.00001347
Iteration 226/1000 | Loss: 0.00001347
Iteration 227/1000 | Loss: 0.00001347
Iteration 228/1000 | Loss: 0.00001347
Iteration 229/1000 | Loss: 0.00001347
Iteration 230/1000 | Loss: 0.00001347
Iteration 231/1000 | Loss: 0.00001347
Iteration 232/1000 | Loss: 0.00001347
Iteration 233/1000 | Loss: 0.00001347
Iteration 234/1000 | Loss: 0.00001347
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 234. Stopping optimization.
Last 5 losses: [1.346869976259768e-05, 1.346869976259768e-05, 1.346869976259768e-05, 1.346869976259768e-05, 1.346869976259768e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.346869976259768e-05

Optimization complete. Final v2v error: 2.951098680496216 mm

Highest mean error: 5.685540676116943 mm for frame 104

Lowest mean error: 2.6457090377807617 mm for frame 11

Saving results

Total time: 140.20487809181213
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00594801
Iteration 2/25 | Loss: 0.00106317
Iteration 3/25 | Loss: 0.00082657
Iteration 4/25 | Loss: 0.00078322
Iteration 5/25 | Loss: 0.00075701
Iteration 6/25 | Loss: 0.00075252
Iteration 7/25 | Loss: 0.00074446
Iteration 8/25 | Loss: 0.00074231
Iteration 9/25 | Loss: 0.00074195
Iteration 10/25 | Loss: 0.00074172
Iteration 11/25 | Loss: 0.00074097
Iteration 12/25 | Loss: 0.00074026
Iteration 13/25 | Loss: 0.00073993
Iteration 14/25 | Loss: 0.00073979
Iteration 15/25 | Loss: 0.00073974
Iteration 16/25 | Loss: 0.00073974
Iteration 17/25 | Loss: 0.00073973
Iteration 18/25 | Loss: 0.00073973
Iteration 19/25 | Loss: 0.00073973
Iteration 20/25 | Loss: 0.00073973
Iteration 21/25 | Loss: 0.00073973
Iteration 22/25 | Loss: 0.00073973
Iteration 23/25 | Loss: 0.00073973
Iteration 24/25 | Loss: 0.00073973
Iteration 25/25 | Loss: 0.00073973

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.21901584
Iteration 2/25 | Loss: 0.00040936
Iteration 3/25 | Loss: 0.00040930
Iteration 4/25 | Loss: 0.00040930
Iteration 5/25 | Loss: 0.00040930
Iteration 6/25 | Loss: 0.00040930
Iteration 7/25 | Loss: 0.00040930
Iteration 8/25 | Loss: 0.00040930
Iteration 9/25 | Loss: 0.00040930
Iteration 10/25 | Loss: 0.00040930
Iteration 11/25 | Loss: 0.00040930
Iteration 12/25 | Loss: 0.00040930
Iteration 13/25 | Loss: 0.00040930
Iteration 14/25 | Loss: 0.00040930
Iteration 15/25 | Loss: 0.00040930
Iteration 16/25 | Loss: 0.00040930
Iteration 17/25 | Loss: 0.00040930
Iteration 18/25 | Loss: 0.00040930
Iteration 19/25 | Loss: 0.00040930
Iteration 20/25 | Loss: 0.00040930
Iteration 21/25 | Loss: 0.00040930
Iteration 22/25 | Loss: 0.00040930
Iteration 23/25 | Loss: 0.00040930
Iteration 24/25 | Loss: 0.00040930
Iteration 25/25 | Loss: 0.00040930

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040930
Iteration 2/1000 | Loss: 0.00006133
Iteration 3/1000 | Loss: 0.00004170
Iteration 4/1000 | Loss: 0.00003739
Iteration 5/1000 | Loss: 0.00003570
Iteration 6/1000 | Loss: 0.00003409
Iteration 7/1000 | Loss: 0.00017838
Iteration 8/1000 | Loss: 0.00003343
Iteration 9/1000 | Loss: 0.00003149
Iteration 10/1000 | Loss: 0.00003046
Iteration 11/1000 | Loss: 0.00002961
Iteration 12/1000 | Loss: 0.00002906
Iteration 13/1000 | Loss: 0.00002877
Iteration 14/1000 | Loss: 0.00002855
Iteration 15/1000 | Loss: 0.00002852
Iteration 16/1000 | Loss: 0.00002851
Iteration 17/1000 | Loss: 0.00002849
Iteration 18/1000 | Loss: 0.00002846
Iteration 19/1000 | Loss: 0.00002846
Iteration 20/1000 | Loss: 0.00002832
Iteration 21/1000 | Loss: 0.00002831
Iteration 22/1000 | Loss: 0.00002820
Iteration 23/1000 | Loss: 0.00002818
Iteration 24/1000 | Loss: 0.00002815
Iteration 25/1000 | Loss: 0.00002815
Iteration 26/1000 | Loss: 0.00002814
Iteration 27/1000 | Loss: 0.00002812
Iteration 28/1000 | Loss: 0.00002811
Iteration 29/1000 | Loss: 0.00002810
Iteration 30/1000 | Loss: 0.00002810
Iteration 31/1000 | Loss: 0.00002809
Iteration 32/1000 | Loss: 0.00002808
Iteration 33/1000 | Loss: 0.00002808
Iteration 34/1000 | Loss: 0.00002807
Iteration 35/1000 | Loss: 0.00002805
Iteration 36/1000 | Loss: 0.00002805
Iteration 37/1000 | Loss: 0.00002804
Iteration 38/1000 | Loss: 0.00002804
Iteration 39/1000 | Loss: 0.00002804
Iteration 40/1000 | Loss: 0.00002804
Iteration 41/1000 | Loss: 0.00002803
Iteration 42/1000 | Loss: 0.00002803
Iteration 43/1000 | Loss: 0.00002803
Iteration 44/1000 | Loss: 0.00002802
Iteration 45/1000 | Loss: 0.00002802
Iteration 46/1000 | Loss: 0.00002802
Iteration 47/1000 | Loss: 0.00002802
Iteration 48/1000 | Loss: 0.00002802
Iteration 49/1000 | Loss: 0.00002802
Iteration 50/1000 | Loss: 0.00002802
Iteration 51/1000 | Loss: 0.00002801
Iteration 52/1000 | Loss: 0.00002801
Iteration 53/1000 | Loss: 0.00002801
Iteration 54/1000 | Loss: 0.00002800
Iteration 55/1000 | Loss: 0.00002800
Iteration 56/1000 | Loss: 0.00002800
Iteration 57/1000 | Loss: 0.00002799
Iteration 58/1000 | Loss: 0.00002799
Iteration 59/1000 | Loss: 0.00002799
Iteration 60/1000 | Loss: 0.00002798
Iteration 61/1000 | Loss: 0.00002798
Iteration 62/1000 | Loss: 0.00002798
Iteration 63/1000 | Loss: 0.00002798
Iteration 64/1000 | Loss: 0.00002798
Iteration 65/1000 | Loss: 0.00002797
Iteration 66/1000 | Loss: 0.00002797
Iteration 67/1000 | Loss: 0.00002797
Iteration 68/1000 | Loss: 0.00002797
Iteration 69/1000 | Loss: 0.00002797
Iteration 70/1000 | Loss: 0.00002796
Iteration 71/1000 | Loss: 0.00002796
Iteration 72/1000 | Loss: 0.00002796
Iteration 73/1000 | Loss: 0.00002796
Iteration 74/1000 | Loss: 0.00002796
Iteration 75/1000 | Loss: 0.00002796
Iteration 76/1000 | Loss: 0.00002796
Iteration 77/1000 | Loss: 0.00002796
Iteration 78/1000 | Loss: 0.00002796
Iteration 79/1000 | Loss: 0.00002796
Iteration 80/1000 | Loss: 0.00002796
Iteration 81/1000 | Loss: 0.00002796
Iteration 82/1000 | Loss: 0.00002796
Iteration 83/1000 | Loss: 0.00002796
Iteration 84/1000 | Loss: 0.00002796
Iteration 85/1000 | Loss: 0.00002796
Iteration 86/1000 | Loss: 0.00002795
Iteration 87/1000 | Loss: 0.00002795
Iteration 88/1000 | Loss: 0.00002795
Iteration 89/1000 | Loss: 0.00002795
Iteration 90/1000 | Loss: 0.00002795
Iteration 91/1000 | Loss: 0.00002795
Iteration 92/1000 | Loss: 0.00002795
Iteration 93/1000 | Loss: 0.00002795
Iteration 94/1000 | Loss: 0.00002795
Iteration 95/1000 | Loss: 0.00002795
Iteration 96/1000 | Loss: 0.00002795
Iteration 97/1000 | Loss: 0.00002795
Iteration 98/1000 | Loss: 0.00002795
Iteration 99/1000 | Loss: 0.00002795
Iteration 100/1000 | Loss: 0.00002795
Iteration 101/1000 | Loss: 0.00002795
Iteration 102/1000 | Loss: 0.00002795
Iteration 103/1000 | Loss: 0.00002794
Iteration 104/1000 | Loss: 0.00002794
Iteration 105/1000 | Loss: 0.00002794
Iteration 106/1000 | Loss: 0.00002794
Iteration 107/1000 | Loss: 0.00002794
Iteration 108/1000 | Loss: 0.00002794
Iteration 109/1000 | Loss: 0.00002794
Iteration 110/1000 | Loss: 0.00002794
Iteration 111/1000 | Loss: 0.00002794
Iteration 112/1000 | Loss: 0.00002794
Iteration 113/1000 | Loss: 0.00002794
Iteration 114/1000 | Loss: 0.00002794
Iteration 115/1000 | Loss: 0.00002794
Iteration 116/1000 | Loss: 0.00002794
Iteration 117/1000 | Loss: 0.00002794
Iteration 118/1000 | Loss: 0.00002794
Iteration 119/1000 | Loss: 0.00002794
Iteration 120/1000 | Loss: 0.00002794
Iteration 121/1000 | Loss: 0.00002794
Iteration 122/1000 | Loss: 0.00002794
Iteration 123/1000 | Loss: 0.00002794
Iteration 124/1000 | Loss: 0.00002794
Iteration 125/1000 | Loss: 0.00002794
Iteration 126/1000 | Loss: 0.00002794
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 126. Stopping optimization.
Last 5 losses: [2.7940841391682625e-05, 2.7940841391682625e-05, 2.7940841391682625e-05, 2.7940841391682625e-05, 2.7940841391682625e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7940841391682625e-05

Optimization complete. Final v2v error: 4.228582859039307 mm

Highest mean error: 6.100143909454346 mm for frame 114

Lowest mean error: 3.4358177185058594 mm for frame 80

Saving results

Total time: 56.076186656951904
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01018601
Iteration 2/25 | Loss: 0.00453039
Iteration 3/25 | Loss: 0.00182786
Iteration 4/25 | Loss: 0.00158485
Iteration 5/25 | Loss: 0.00137794
Iteration 6/25 | Loss: 0.00129003
Iteration 7/25 | Loss: 0.00122250
Iteration 8/25 | Loss: 0.00126426
Iteration 9/25 | Loss: 0.00122440
Iteration 10/25 | Loss: 0.00116418
Iteration 11/25 | Loss: 0.00109185
Iteration 12/25 | Loss: 0.00102001
Iteration 13/25 | Loss: 0.00094447
Iteration 14/25 | Loss: 0.00091168
Iteration 15/25 | Loss: 0.00088624
Iteration 16/25 | Loss: 0.00086469
Iteration 17/25 | Loss: 0.00085954
Iteration 18/25 | Loss: 0.00086109
Iteration 19/25 | Loss: 0.00085859
Iteration 20/25 | Loss: 0.00085376
Iteration 21/25 | Loss: 0.00084988
Iteration 22/25 | Loss: 0.00084811
Iteration 23/25 | Loss: 0.00085018
Iteration 24/25 | Loss: 0.00084788
Iteration 25/25 | Loss: 0.00084431

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51257920
Iteration 2/25 | Loss: 0.00283665
Iteration 3/25 | Loss: 0.00283665
Iteration 4/25 | Loss: 0.00280931
Iteration 5/25 | Loss: 0.00280931
Iteration 6/25 | Loss: 0.00280931
Iteration 7/25 | Loss: 0.00280931
Iteration 8/25 | Loss: 0.00280931
Iteration 9/25 | Loss: 0.00280931
Iteration 10/25 | Loss: 0.00280931
Iteration 11/25 | Loss: 0.00280931
Iteration 12/25 | Loss: 0.00280931
Iteration 13/25 | Loss: 0.00280931
Iteration 14/25 | Loss: 0.00280931
Iteration 15/25 | Loss: 0.00280931
Iteration 16/25 | Loss: 0.00280931
Iteration 17/25 | Loss: 0.00280931
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0028093073051422834, 0.0028093073051422834, 0.0028093073051422834, 0.0028093073051422834, 0.0028093073051422834]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0028093073051422834

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00280931
Iteration 2/1000 | Loss: 0.00069193
Iteration 3/1000 | Loss: 0.00252975
Iteration 4/1000 | Loss: 0.00110066
Iteration 5/1000 | Loss: 0.00026736
Iteration 6/1000 | Loss: 0.00103049
Iteration 7/1000 | Loss: 0.00138303
Iteration 8/1000 | Loss: 0.00025031
Iteration 9/1000 | Loss: 0.00018481
Iteration 10/1000 | Loss: 0.00013844
Iteration 11/1000 | Loss: 0.00014405
Iteration 12/1000 | Loss: 0.00012042
Iteration 13/1000 | Loss: 0.00012565
Iteration 14/1000 | Loss: 0.00011207
Iteration 15/1000 | Loss: 0.00026189
Iteration 16/1000 | Loss: 0.00169921
Iteration 17/1000 | Loss: 0.00150270
Iteration 18/1000 | Loss: 0.00060885
Iteration 19/1000 | Loss: 0.00048592
Iteration 20/1000 | Loss: 0.00034783
Iteration 21/1000 | Loss: 0.00010242
Iteration 22/1000 | Loss: 0.00009168
Iteration 23/1000 | Loss: 0.00014164
Iteration 24/1000 | Loss: 0.00044411
Iteration 25/1000 | Loss: 0.00004799
Iteration 26/1000 | Loss: 0.00029180
Iteration 27/1000 | Loss: 0.00006530
Iteration 28/1000 | Loss: 0.00003888
Iteration 29/1000 | Loss: 0.00005899
Iteration 30/1000 | Loss: 0.00007829
Iteration 31/1000 | Loss: 0.00006999
Iteration 32/1000 | Loss: 0.00002256
Iteration 33/1000 | Loss: 0.00011080
Iteration 34/1000 | Loss: 0.00006403
Iteration 35/1000 | Loss: 0.00008375
Iteration 36/1000 | Loss: 0.00002738
Iteration 37/1000 | Loss: 0.00001751
Iteration 38/1000 | Loss: 0.00005838
Iteration 39/1000 | Loss: 0.00009244
Iteration 40/1000 | Loss: 0.00003843
Iteration 41/1000 | Loss: 0.00001781
Iteration 42/1000 | Loss: 0.00002437
Iteration 43/1000 | Loss: 0.00001750
Iteration 44/1000 | Loss: 0.00002397
Iteration 45/1000 | Loss: 0.00002977
Iteration 46/1000 | Loss: 0.00003590
Iteration 47/1000 | Loss: 0.00008472
Iteration 48/1000 | Loss: 0.00001398
Iteration 49/1000 | Loss: 0.00003472
Iteration 50/1000 | Loss: 0.00002492
Iteration 51/1000 | Loss: 0.00001639
Iteration 52/1000 | Loss: 0.00001434
Iteration 53/1000 | Loss: 0.00002085
Iteration 54/1000 | Loss: 0.00001364
Iteration 55/1000 | Loss: 0.00002641
Iteration 56/1000 | Loss: 0.00001277
Iteration 57/1000 | Loss: 0.00001272
Iteration 58/1000 | Loss: 0.00001251
Iteration 59/1000 | Loss: 0.00002560
Iteration 60/1000 | Loss: 0.00001310
Iteration 61/1000 | Loss: 0.00001207
Iteration 62/1000 | Loss: 0.00001207
Iteration 63/1000 | Loss: 0.00002370
Iteration 64/1000 | Loss: 0.00001264
Iteration 65/1000 | Loss: 0.00001219
Iteration 66/1000 | Loss: 0.00001219
Iteration 67/1000 | Loss: 0.00001219
Iteration 68/1000 | Loss: 0.00001325
Iteration 69/1000 | Loss: 0.00001316
Iteration 70/1000 | Loss: 0.00001199
Iteration 71/1000 | Loss: 0.00001196
Iteration 72/1000 | Loss: 0.00001196
Iteration 73/1000 | Loss: 0.00001196
Iteration 74/1000 | Loss: 0.00001196
Iteration 75/1000 | Loss: 0.00001196
Iteration 76/1000 | Loss: 0.00001196
Iteration 77/1000 | Loss: 0.00001196
Iteration 78/1000 | Loss: 0.00001196
Iteration 79/1000 | Loss: 0.00001196
Iteration 80/1000 | Loss: 0.00001195
Iteration 81/1000 | Loss: 0.00001195
Iteration 82/1000 | Loss: 0.00001195
Iteration 83/1000 | Loss: 0.00001195
Iteration 84/1000 | Loss: 0.00001195
Iteration 85/1000 | Loss: 0.00001195
Iteration 86/1000 | Loss: 0.00001195
Iteration 87/1000 | Loss: 0.00001195
Iteration 88/1000 | Loss: 0.00001195
Iteration 89/1000 | Loss: 0.00001195
Iteration 90/1000 | Loss: 0.00001195
Iteration 91/1000 | Loss: 0.00001195
Iteration 92/1000 | Loss: 0.00001195
Iteration 93/1000 | Loss: 0.00001195
Iteration 94/1000 | Loss: 0.00001195
Iteration 95/1000 | Loss: 0.00001194
Iteration 96/1000 | Loss: 0.00001194
Iteration 97/1000 | Loss: 0.00001194
Iteration 98/1000 | Loss: 0.00001194
Iteration 99/1000 | Loss: 0.00001194
Iteration 100/1000 | Loss: 0.00001194
Iteration 101/1000 | Loss: 0.00001194
Iteration 102/1000 | Loss: 0.00001194
Iteration 103/1000 | Loss: 0.00001194
Iteration 104/1000 | Loss: 0.00001194
Iteration 105/1000 | Loss: 0.00001194
Iteration 106/1000 | Loss: 0.00001194
Iteration 107/1000 | Loss: 0.00001194
Iteration 108/1000 | Loss: 0.00001194
Iteration 109/1000 | Loss: 0.00001194
Iteration 110/1000 | Loss: 0.00001194
Iteration 111/1000 | Loss: 0.00001194
Iteration 112/1000 | Loss: 0.00001326
Iteration 113/1000 | Loss: 0.00001194
Iteration 114/1000 | Loss: 0.00001194
Iteration 115/1000 | Loss: 0.00001194
Iteration 116/1000 | Loss: 0.00001194
Iteration 117/1000 | Loss: 0.00001194
Iteration 118/1000 | Loss: 0.00001194
Iteration 119/1000 | Loss: 0.00001194
Iteration 120/1000 | Loss: 0.00001212
Iteration 121/1000 | Loss: 0.00001192
Iteration 122/1000 | Loss: 0.00001190
Iteration 123/1000 | Loss: 0.00001190
Iteration 124/1000 | Loss: 0.00001190
Iteration 125/1000 | Loss: 0.00001190
Iteration 126/1000 | Loss: 0.00001190
Iteration 127/1000 | Loss: 0.00001190
Iteration 128/1000 | Loss: 0.00001190
Iteration 129/1000 | Loss: 0.00001189
Iteration 130/1000 | Loss: 0.00001189
Iteration 131/1000 | Loss: 0.00001189
Iteration 132/1000 | Loss: 0.00001189
Iteration 133/1000 | Loss: 0.00001188
Iteration 134/1000 | Loss: 0.00001188
Iteration 135/1000 | Loss: 0.00001188
Iteration 136/1000 | Loss: 0.00001219
Iteration 137/1000 | Loss: 0.00001187
Iteration 138/1000 | Loss: 0.00001187
Iteration 139/1000 | Loss: 0.00001187
Iteration 140/1000 | Loss: 0.00001187
Iteration 141/1000 | Loss: 0.00001186
Iteration 142/1000 | Loss: 0.00001192
Iteration 143/1000 | Loss: 0.00001192
Iteration 144/1000 | Loss: 0.00001191
Iteration 145/1000 | Loss: 0.00001185
Iteration 146/1000 | Loss: 0.00001185
Iteration 147/1000 | Loss: 0.00001185
Iteration 148/1000 | Loss: 0.00001185
Iteration 149/1000 | Loss: 0.00001185
Iteration 150/1000 | Loss: 0.00001185
Iteration 151/1000 | Loss: 0.00001185
Iteration 152/1000 | Loss: 0.00001185
Iteration 153/1000 | Loss: 0.00001185
Iteration 154/1000 | Loss: 0.00001185
Iteration 155/1000 | Loss: 0.00001185
Iteration 156/1000 | Loss: 0.00001209
Iteration 157/1000 | Loss: 0.00001187
Iteration 158/1000 | Loss: 0.00001187
Iteration 159/1000 | Loss: 0.00001189
Iteration 160/1000 | Loss: 0.00001184
Iteration 161/1000 | Loss: 0.00001184
Iteration 162/1000 | Loss: 0.00001184
Iteration 163/1000 | Loss: 0.00001184
Iteration 164/1000 | Loss: 0.00001184
Iteration 165/1000 | Loss: 0.00001183
Iteration 166/1000 | Loss: 0.00001183
Iteration 167/1000 | Loss: 0.00001183
Iteration 168/1000 | Loss: 0.00001183
Iteration 169/1000 | Loss: 0.00001183
Iteration 170/1000 | Loss: 0.00001183
Iteration 171/1000 | Loss: 0.00001183
Iteration 172/1000 | Loss: 0.00001183
Iteration 173/1000 | Loss: 0.00001183
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 173. Stopping optimization.
Last 5 losses: [1.1828364222310483e-05, 1.1828364222310483e-05, 1.1828364222310483e-05, 1.1828364222310483e-05, 1.1828364222310483e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1828364222310483e-05

Optimization complete. Final v2v error: 2.6698944568634033 mm

Highest mean error: 14.782947540283203 mm for frame 187

Lowest mean error: 2.2117397785186768 mm for frame 98

Saving results

Total time: 163.7018620967865
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00881143
Iteration 2/25 | Loss: 0.00116953
Iteration 3/25 | Loss: 0.00087931
Iteration 4/25 | Loss: 0.00081828
Iteration 5/25 | Loss: 0.00080571
Iteration 6/25 | Loss: 0.00080310
Iteration 7/25 | Loss: 0.00080258
Iteration 8/25 | Loss: 0.00080257
Iteration 9/25 | Loss: 0.00080257
Iteration 10/25 | Loss: 0.00080257
Iteration 11/25 | Loss: 0.00080257
Iteration 12/25 | Loss: 0.00080257
Iteration 13/25 | Loss: 0.00080257
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008025704883038998, 0.0008025704883038998, 0.0008025704883038998, 0.0008025704883038998, 0.0008025704883038998]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008025704883038998

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.05714583
Iteration 2/25 | Loss: 0.00045929
Iteration 3/25 | Loss: 0.00045928
Iteration 4/25 | Loss: 0.00045928
Iteration 5/25 | Loss: 0.00045928
Iteration 6/25 | Loss: 0.00045928
Iteration 7/25 | Loss: 0.00045928
Iteration 8/25 | Loss: 0.00045928
Iteration 9/25 | Loss: 0.00045927
Iteration 10/25 | Loss: 0.00045927
Iteration 11/25 | Loss: 0.00045927
Iteration 12/25 | Loss: 0.00045927
Iteration 13/25 | Loss: 0.00045927
Iteration 14/25 | Loss: 0.00045927
Iteration 15/25 | Loss: 0.00045927
Iteration 16/25 | Loss: 0.00045927
Iteration 17/25 | Loss: 0.00045927
Iteration 18/25 | Loss: 0.00045927
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0004592744226101786, 0.0004592744226101786, 0.0004592744226101786, 0.0004592744226101786, 0.0004592744226101786]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004592744226101786

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045927
Iteration 2/1000 | Loss: 0.00007245
Iteration 3/1000 | Loss: 0.00005219
Iteration 4/1000 | Loss: 0.00004358
Iteration 5/1000 | Loss: 0.00003986
Iteration 6/1000 | Loss: 0.00003691
Iteration 7/1000 | Loss: 0.00003533
Iteration 8/1000 | Loss: 0.00003399
Iteration 9/1000 | Loss: 0.00003339
Iteration 10/1000 | Loss: 0.00003294
Iteration 11/1000 | Loss: 0.00003255
Iteration 12/1000 | Loss: 0.00003231
Iteration 13/1000 | Loss: 0.00003227
Iteration 14/1000 | Loss: 0.00003222
Iteration 15/1000 | Loss: 0.00003221
Iteration 16/1000 | Loss: 0.00003220
Iteration 17/1000 | Loss: 0.00003216
Iteration 18/1000 | Loss: 0.00003216
Iteration 19/1000 | Loss: 0.00003211
Iteration 20/1000 | Loss: 0.00003210
Iteration 21/1000 | Loss: 0.00003210
Iteration 22/1000 | Loss: 0.00003210
Iteration 23/1000 | Loss: 0.00003209
Iteration 24/1000 | Loss: 0.00003208
Iteration 25/1000 | Loss: 0.00003208
Iteration 26/1000 | Loss: 0.00003207
Iteration 27/1000 | Loss: 0.00003207
Iteration 28/1000 | Loss: 0.00003207
Iteration 29/1000 | Loss: 0.00003207
Iteration 30/1000 | Loss: 0.00003207
Iteration 31/1000 | Loss: 0.00003206
Iteration 32/1000 | Loss: 0.00003206
Iteration 33/1000 | Loss: 0.00003206
Iteration 34/1000 | Loss: 0.00003206
Iteration 35/1000 | Loss: 0.00003206
Iteration 36/1000 | Loss: 0.00003206
Iteration 37/1000 | Loss: 0.00003206
Iteration 38/1000 | Loss: 0.00003206
Iteration 39/1000 | Loss: 0.00003206
Iteration 40/1000 | Loss: 0.00003206
Iteration 41/1000 | Loss: 0.00003205
Iteration 42/1000 | Loss: 0.00003205
Iteration 43/1000 | Loss: 0.00003205
Iteration 44/1000 | Loss: 0.00003205
Iteration 45/1000 | Loss: 0.00003205
Iteration 46/1000 | Loss: 0.00003205
Iteration 47/1000 | Loss: 0.00003204
Iteration 48/1000 | Loss: 0.00003204
Iteration 49/1000 | Loss: 0.00003204
Iteration 50/1000 | Loss: 0.00003204
Iteration 51/1000 | Loss: 0.00003203
Iteration 52/1000 | Loss: 0.00003203
Iteration 53/1000 | Loss: 0.00003203
Iteration 54/1000 | Loss: 0.00003203
Iteration 55/1000 | Loss: 0.00003203
Iteration 56/1000 | Loss: 0.00003203
Iteration 57/1000 | Loss: 0.00003203
Iteration 58/1000 | Loss: 0.00003203
Iteration 59/1000 | Loss: 0.00003203
Iteration 60/1000 | Loss: 0.00003203
Iteration 61/1000 | Loss: 0.00003203
Iteration 62/1000 | Loss: 0.00003203
Iteration 63/1000 | Loss: 0.00003202
Iteration 64/1000 | Loss: 0.00003202
Iteration 65/1000 | Loss: 0.00003202
Iteration 66/1000 | Loss: 0.00003201
Iteration 67/1000 | Loss: 0.00003201
Iteration 68/1000 | Loss: 0.00003201
Iteration 69/1000 | Loss: 0.00003200
Iteration 70/1000 | Loss: 0.00003200
Iteration 71/1000 | Loss: 0.00003200
Iteration 72/1000 | Loss: 0.00003200
Iteration 73/1000 | Loss: 0.00003199
Iteration 74/1000 | Loss: 0.00003199
Iteration 75/1000 | Loss: 0.00003199
Iteration 76/1000 | Loss: 0.00003199
Iteration 77/1000 | Loss: 0.00003199
Iteration 78/1000 | Loss: 0.00003199
Iteration 79/1000 | Loss: 0.00003199
Iteration 80/1000 | Loss: 0.00003199
Iteration 81/1000 | Loss: 0.00003199
Iteration 82/1000 | Loss: 0.00003199
Iteration 83/1000 | Loss: 0.00003198
Iteration 84/1000 | Loss: 0.00003198
Iteration 85/1000 | Loss: 0.00003198
Iteration 86/1000 | Loss: 0.00003198
Iteration 87/1000 | Loss: 0.00003198
Iteration 88/1000 | Loss: 0.00003198
Iteration 89/1000 | Loss: 0.00003197
Iteration 90/1000 | Loss: 0.00003197
Iteration 91/1000 | Loss: 0.00003197
Iteration 92/1000 | Loss: 0.00003197
Iteration 93/1000 | Loss: 0.00003197
Iteration 94/1000 | Loss: 0.00003197
Iteration 95/1000 | Loss: 0.00003197
Iteration 96/1000 | Loss: 0.00003197
Iteration 97/1000 | Loss: 0.00003196
Iteration 98/1000 | Loss: 0.00003196
Iteration 99/1000 | Loss: 0.00003196
Iteration 100/1000 | Loss: 0.00003195
Iteration 101/1000 | Loss: 0.00003195
Iteration 102/1000 | Loss: 0.00003195
Iteration 103/1000 | Loss: 0.00003195
Iteration 104/1000 | Loss: 0.00003195
Iteration 105/1000 | Loss: 0.00003195
Iteration 106/1000 | Loss: 0.00003194
Iteration 107/1000 | Loss: 0.00003194
Iteration 108/1000 | Loss: 0.00003194
Iteration 109/1000 | Loss: 0.00003194
Iteration 110/1000 | Loss: 0.00003194
Iteration 111/1000 | Loss: 0.00003194
Iteration 112/1000 | Loss: 0.00003194
Iteration 113/1000 | Loss: 0.00003193
Iteration 114/1000 | Loss: 0.00003193
Iteration 115/1000 | Loss: 0.00003193
Iteration 116/1000 | Loss: 0.00003193
Iteration 117/1000 | Loss: 0.00003193
Iteration 118/1000 | Loss: 0.00003193
Iteration 119/1000 | Loss: 0.00003193
Iteration 120/1000 | Loss: 0.00003193
Iteration 121/1000 | Loss: 0.00003193
Iteration 122/1000 | Loss: 0.00003193
Iteration 123/1000 | Loss: 0.00003193
Iteration 124/1000 | Loss: 0.00003193
Iteration 125/1000 | Loss: 0.00003193
Iteration 126/1000 | Loss: 0.00003193
Iteration 127/1000 | Loss: 0.00003193
Iteration 128/1000 | Loss: 0.00003193
Iteration 129/1000 | Loss: 0.00003193
Iteration 130/1000 | Loss: 0.00003193
Iteration 131/1000 | Loss: 0.00003193
Iteration 132/1000 | Loss: 0.00003193
Iteration 133/1000 | Loss: 0.00003193
Iteration 134/1000 | Loss: 0.00003193
Iteration 135/1000 | Loss: 0.00003193
Iteration 136/1000 | Loss: 0.00003193
Iteration 137/1000 | Loss: 0.00003193
Iteration 138/1000 | Loss: 0.00003193
Iteration 139/1000 | Loss: 0.00003193
Iteration 140/1000 | Loss: 0.00003193
Iteration 141/1000 | Loss: 0.00003193
Iteration 142/1000 | Loss: 0.00003193
Iteration 143/1000 | Loss: 0.00003193
Iteration 144/1000 | Loss: 0.00003193
Iteration 145/1000 | Loss: 0.00003193
Iteration 146/1000 | Loss: 0.00003193
Iteration 147/1000 | Loss: 0.00003193
Iteration 148/1000 | Loss: 0.00003193
Iteration 149/1000 | Loss: 0.00003193
Iteration 150/1000 | Loss: 0.00003193
Iteration 151/1000 | Loss: 0.00003193
Iteration 152/1000 | Loss: 0.00003193
Iteration 153/1000 | Loss: 0.00003193
Iteration 154/1000 | Loss: 0.00003193
Iteration 155/1000 | Loss: 0.00003193
Iteration 156/1000 | Loss: 0.00003193
Iteration 157/1000 | Loss: 0.00003193
Iteration 158/1000 | Loss: 0.00003193
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 158. Stopping optimization.
Last 5 losses: [3.1928986572893336e-05, 3.1928986572893336e-05, 3.1928986572893336e-05, 3.1928986572893336e-05, 3.1928986572893336e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.1928986572893336e-05

Optimization complete. Final v2v error: 4.646123886108398 mm

Highest mean error: 5.069610595703125 mm for frame 44

Lowest mean error: 4.2197370529174805 mm for frame 116

Saving results

Total time: 36.58167815208435
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00573434
Iteration 2/25 | Loss: 0.00089274
Iteration 3/25 | Loss: 0.00075262
Iteration 4/25 | Loss: 0.00071571
Iteration 5/25 | Loss: 0.00070629
Iteration 6/25 | Loss: 0.00070404
Iteration 7/25 | Loss: 0.00070328
Iteration 8/25 | Loss: 0.00070328
Iteration 9/25 | Loss: 0.00070328
Iteration 10/25 | Loss: 0.00070328
Iteration 11/25 | Loss: 0.00070328
Iteration 12/25 | Loss: 0.00070328
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007032845169305801, 0.0007032845169305801, 0.0007032845169305801, 0.0007032845169305801, 0.0007032845169305801]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007032845169305801

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47962952
Iteration 2/25 | Loss: 0.00046702
Iteration 3/25 | Loss: 0.00046702
Iteration 4/25 | Loss: 0.00046702
Iteration 5/25 | Loss: 0.00046702
Iteration 6/25 | Loss: 0.00046701
Iteration 7/25 | Loss: 0.00046701
Iteration 8/25 | Loss: 0.00046701
Iteration 9/25 | Loss: 0.00046701
Iteration 10/25 | Loss: 0.00046701
Iteration 11/25 | Loss: 0.00046701
Iteration 12/25 | Loss: 0.00046701
Iteration 13/25 | Loss: 0.00046701
Iteration 14/25 | Loss: 0.00046701
Iteration 15/25 | Loss: 0.00046701
Iteration 16/25 | Loss: 0.00046701
Iteration 17/25 | Loss: 0.00046701
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004670140042435378, 0.0004670140042435378, 0.0004670140042435378, 0.0004670140042435378, 0.0004670140042435378]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004670140042435378

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046701
Iteration 2/1000 | Loss: 0.00004024
Iteration 3/1000 | Loss: 0.00002035
Iteration 4/1000 | Loss: 0.00001692
Iteration 5/1000 | Loss: 0.00001577
Iteration 6/1000 | Loss: 0.00001509
Iteration 7/1000 | Loss: 0.00001474
Iteration 8/1000 | Loss: 0.00001446
Iteration 9/1000 | Loss: 0.00001436
Iteration 10/1000 | Loss: 0.00001435
Iteration 11/1000 | Loss: 0.00001434
Iteration 12/1000 | Loss: 0.00001426
Iteration 13/1000 | Loss: 0.00001415
Iteration 14/1000 | Loss: 0.00001400
Iteration 15/1000 | Loss: 0.00001396
Iteration 16/1000 | Loss: 0.00001395
Iteration 17/1000 | Loss: 0.00001395
Iteration 18/1000 | Loss: 0.00001395
Iteration 19/1000 | Loss: 0.00001388
Iteration 20/1000 | Loss: 0.00001388
Iteration 21/1000 | Loss: 0.00001384
Iteration 22/1000 | Loss: 0.00001383
Iteration 23/1000 | Loss: 0.00001383
Iteration 24/1000 | Loss: 0.00001383
Iteration 25/1000 | Loss: 0.00001383
Iteration 26/1000 | Loss: 0.00001383
Iteration 27/1000 | Loss: 0.00001383
Iteration 28/1000 | Loss: 0.00001383
Iteration 29/1000 | Loss: 0.00001383
Iteration 30/1000 | Loss: 0.00001383
Iteration 31/1000 | Loss: 0.00001383
Iteration 32/1000 | Loss: 0.00001383
Iteration 33/1000 | Loss: 0.00001382
Iteration 34/1000 | Loss: 0.00001382
Iteration 35/1000 | Loss: 0.00001382
Iteration 36/1000 | Loss: 0.00001379
Iteration 37/1000 | Loss: 0.00001379
Iteration 38/1000 | Loss: 0.00001379
Iteration 39/1000 | Loss: 0.00001378
Iteration 40/1000 | Loss: 0.00001378
Iteration 41/1000 | Loss: 0.00001377
Iteration 42/1000 | Loss: 0.00001376
Iteration 43/1000 | Loss: 0.00001376
Iteration 44/1000 | Loss: 0.00001375
Iteration 45/1000 | Loss: 0.00001375
Iteration 46/1000 | Loss: 0.00001375
Iteration 47/1000 | Loss: 0.00001374
Iteration 48/1000 | Loss: 0.00001374
Iteration 49/1000 | Loss: 0.00001369
Iteration 50/1000 | Loss: 0.00001369
Iteration 51/1000 | Loss: 0.00001369
Iteration 52/1000 | Loss: 0.00001369
Iteration 53/1000 | Loss: 0.00001369
Iteration 54/1000 | Loss: 0.00001364
Iteration 55/1000 | Loss: 0.00001364
Iteration 56/1000 | Loss: 0.00001360
Iteration 57/1000 | Loss: 0.00001359
Iteration 58/1000 | Loss: 0.00001359
Iteration 59/1000 | Loss: 0.00001359
Iteration 60/1000 | Loss: 0.00001359
Iteration 61/1000 | Loss: 0.00001359
Iteration 62/1000 | Loss: 0.00001358
Iteration 63/1000 | Loss: 0.00001357
Iteration 64/1000 | Loss: 0.00001357
Iteration 65/1000 | Loss: 0.00001357
Iteration 66/1000 | Loss: 0.00001356
Iteration 67/1000 | Loss: 0.00001355
Iteration 68/1000 | Loss: 0.00001355
Iteration 69/1000 | Loss: 0.00001354
Iteration 70/1000 | Loss: 0.00001354
Iteration 71/1000 | Loss: 0.00001353
Iteration 72/1000 | Loss: 0.00001352
Iteration 73/1000 | Loss: 0.00001351
Iteration 74/1000 | Loss: 0.00001351
Iteration 75/1000 | Loss: 0.00001351
Iteration 76/1000 | Loss: 0.00001349
Iteration 77/1000 | Loss: 0.00001349
Iteration 78/1000 | Loss: 0.00001349
Iteration 79/1000 | Loss: 0.00001348
Iteration 80/1000 | Loss: 0.00001346
Iteration 81/1000 | Loss: 0.00001346
Iteration 82/1000 | Loss: 0.00001346
Iteration 83/1000 | Loss: 0.00001346
Iteration 84/1000 | Loss: 0.00001346
Iteration 85/1000 | Loss: 0.00001346
Iteration 86/1000 | Loss: 0.00001346
Iteration 87/1000 | Loss: 0.00001346
Iteration 88/1000 | Loss: 0.00001346
Iteration 89/1000 | Loss: 0.00001345
Iteration 90/1000 | Loss: 0.00001345
Iteration 91/1000 | Loss: 0.00001345
Iteration 92/1000 | Loss: 0.00001345
Iteration 93/1000 | Loss: 0.00001345
Iteration 94/1000 | Loss: 0.00001345
Iteration 95/1000 | Loss: 0.00001345
Iteration 96/1000 | Loss: 0.00001345
Iteration 97/1000 | Loss: 0.00001345
Iteration 98/1000 | Loss: 0.00001345
Iteration 99/1000 | Loss: 0.00001345
Iteration 100/1000 | Loss: 0.00001344
Iteration 101/1000 | Loss: 0.00001343
Iteration 102/1000 | Loss: 0.00001343
Iteration 103/1000 | Loss: 0.00001343
Iteration 104/1000 | Loss: 0.00001343
Iteration 105/1000 | Loss: 0.00001343
Iteration 106/1000 | Loss: 0.00001343
Iteration 107/1000 | Loss: 0.00001343
Iteration 108/1000 | Loss: 0.00001343
Iteration 109/1000 | Loss: 0.00001342
Iteration 110/1000 | Loss: 0.00001342
Iteration 111/1000 | Loss: 0.00001342
Iteration 112/1000 | Loss: 0.00001342
Iteration 113/1000 | Loss: 0.00001342
Iteration 114/1000 | Loss: 0.00001342
Iteration 115/1000 | Loss: 0.00001342
Iteration 116/1000 | Loss: 0.00001342
Iteration 117/1000 | Loss: 0.00001341
Iteration 118/1000 | Loss: 0.00001341
Iteration 119/1000 | Loss: 0.00001341
Iteration 120/1000 | Loss: 0.00001341
Iteration 121/1000 | Loss: 0.00001341
Iteration 122/1000 | Loss: 0.00001341
Iteration 123/1000 | Loss: 0.00001341
Iteration 124/1000 | Loss: 0.00001341
Iteration 125/1000 | Loss: 0.00001341
Iteration 126/1000 | Loss: 0.00001341
Iteration 127/1000 | Loss: 0.00001341
Iteration 128/1000 | Loss: 0.00001340
Iteration 129/1000 | Loss: 0.00001340
Iteration 130/1000 | Loss: 0.00001340
Iteration 131/1000 | Loss: 0.00001340
Iteration 132/1000 | Loss: 0.00001340
Iteration 133/1000 | Loss: 0.00001340
Iteration 134/1000 | Loss: 0.00001340
Iteration 135/1000 | Loss: 0.00001340
Iteration 136/1000 | Loss: 0.00001340
Iteration 137/1000 | Loss: 0.00001340
Iteration 138/1000 | Loss: 0.00001340
Iteration 139/1000 | Loss: 0.00001340
Iteration 140/1000 | Loss: 0.00001340
Iteration 141/1000 | Loss: 0.00001339
Iteration 142/1000 | Loss: 0.00001339
Iteration 143/1000 | Loss: 0.00001339
Iteration 144/1000 | Loss: 0.00001338
Iteration 145/1000 | Loss: 0.00001338
Iteration 146/1000 | Loss: 0.00001338
Iteration 147/1000 | Loss: 0.00001337
Iteration 148/1000 | Loss: 0.00001337
Iteration 149/1000 | Loss: 0.00001337
Iteration 150/1000 | Loss: 0.00001337
Iteration 151/1000 | Loss: 0.00001337
Iteration 152/1000 | Loss: 0.00001337
Iteration 153/1000 | Loss: 0.00001337
Iteration 154/1000 | Loss: 0.00001337
Iteration 155/1000 | Loss: 0.00001336
Iteration 156/1000 | Loss: 0.00001336
Iteration 157/1000 | Loss: 0.00001336
Iteration 158/1000 | Loss: 0.00001336
Iteration 159/1000 | Loss: 0.00001335
Iteration 160/1000 | Loss: 0.00001335
Iteration 161/1000 | Loss: 0.00001335
Iteration 162/1000 | Loss: 0.00001335
Iteration 163/1000 | Loss: 0.00001335
Iteration 164/1000 | Loss: 0.00001335
Iteration 165/1000 | Loss: 0.00001335
Iteration 166/1000 | Loss: 0.00001334
Iteration 167/1000 | Loss: 0.00001334
Iteration 168/1000 | Loss: 0.00001334
Iteration 169/1000 | Loss: 0.00001334
Iteration 170/1000 | Loss: 0.00001334
Iteration 171/1000 | Loss: 0.00001334
Iteration 172/1000 | Loss: 0.00001334
Iteration 173/1000 | Loss: 0.00001334
Iteration 174/1000 | Loss: 0.00001334
Iteration 175/1000 | Loss: 0.00001333
Iteration 176/1000 | Loss: 0.00001333
Iteration 177/1000 | Loss: 0.00001333
Iteration 178/1000 | Loss: 0.00001332
Iteration 179/1000 | Loss: 0.00001332
Iteration 180/1000 | Loss: 0.00001332
Iteration 181/1000 | Loss: 0.00001332
Iteration 182/1000 | Loss: 0.00001332
Iteration 183/1000 | Loss: 0.00001332
Iteration 184/1000 | Loss: 0.00001332
Iteration 185/1000 | Loss: 0.00001332
Iteration 186/1000 | Loss: 0.00001332
Iteration 187/1000 | Loss: 0.00001332
Iteration 188/1000 | Loss: 0.00001332
Iteration 189/1000 | Loss: 0.00001331
Iteration 190/1000 | Loss: 0.00001331
Iteration 191/1000 | Loss: 0.00001331
Iteration 192/1000 | Loss: 0.00001331
Iteration 193/1000 | Loss: 0.00001331
Iteration 194/1000 | Loss: 0.00001330
Iteration 195/1000 | Loss: 0.00001330
Iteration 196/1000 | Loss: 0.00001330
Iteration 197/1000 | Loss: 0.00001330
Iteration 198/1000 | Loss: 0.00001330
Iteration 199/1000 | Loss: 0.00001330
Iteration 200/1000 | Loss: 0.00001330
Iteration 201/1000 | Loss: 0.00001330
Iteration 202/1000 | Loss: 0.00001330
Iteration 203/1000 | Loss: 0.00001330
Iteration 204/1000 | Loss: 0.00001330
Iteration 205/1000 | Loss: 0.00001330
Iteration 206/1000 | Loss: 0.00001330
Iteration 207/1000 | Loss: 0.00001330
Iteration 208/1000 | Loss: 0.00001330
Iteration 209/1000 | Loss: 0.00001330
Iteration 210/1000 | Loss: 0.00001330
Iteration 211/1000 | Loss: 0.00001330
Iteration 212/1000 | Loss: 0.00001330
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 212. Stopping optimization.
Last 5 losses: [1.3302863408171106e-05, 1.3302863408171106e-05, 1.3302863408171106e-05, 1.3302863408171106e-05, 1.3302863408171106e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3302863408171106e-05

Optimization complete. Final v2v error: 3.0864388942718506 mm

Highest mean error: 3.7507455348968506 mm for frame 66

Lowest mean error: 2.5300354957580566 mm for frame 1

Saving results

Total time: 46.70247673988342
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01085765
Iteration 2/25 | Loss: 0.00209835
Iteration 3/25 | Loss: 0.00131766
Iteration 4/25 | Loss: 0.00107204
Iteration 5/25 | Loss: 0.00088026
Iteration 6/25 | Loss: 0.00083479
Iteration 7/25 | Loss: 0.00078124
Iteration 8/25 | Loss: 0.00071607
Iteration 9/25 | Loss: 0.00067785
Iteration 10/25 | Loss: 0.00065190
Iteration 11/25 | Loss: 0.00063774
Iteration 12/25 | Loss: 0.00063677
Iteration 13/25 | Loss: 0.00063421
Iteration 14/25 | Loss: 0.00063097
Iteration 15/25 | Loss: 0.00062970
Iteration 16/25 | Loss: 0.00062862
Iteration 17/25 | Loss: 0.00062807
Iteration 18/25 | Loss: 0.00063274
Iteration 19/25 | Loss: 0.00063146
Iteration 20/25 | Loss: 0.00063324
Iteration 21/25 | Loss: 0.00063272
Iteration 22/25 | Loss: 0.00063189
Iteration 23/25 | Loss: 0.00062799
Iteration 24/25 | Loss: 0.00062754
Iteration 25/25 | Loss: 0.00063227

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58554029
Iteration 2/25 | Loss: 0.00048323
Iteration 3/25 | Loss: 0.00048323
Iteration 4/25 | Loss: 0.00048323
Iteration 5/25 | Loss: 0.00048323
Iteration 6/25 | Loss: 0.00048323
Iteration 7/25 | Loss: 0.00048323
Iteration 8/25 | Loss: 0.00048323
Iteration 9/25 | Loss: 0.00048323
Iteration 10/25 | Loss: 0.00048323
Iteration 11/25 | Loss: 0.00048323
Iteration 12/25 | Loss: 0.00048323
Iteration 13/25 | Loss: 0.00048323
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.00048323036753572524, 0.00048323036753572524, 0.00048323036753572524, 0.00048323036753572524, 0.00048323036753572524]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00048323036753572524

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048323
Iteration 2/1000 | Loss: 0.00023882
Iteration 3/1000 | Loss: 0.00021962
Iteration 4/1000 | Loss: 0.00017303
Iteration 5/1000 | Loss: 0.00015016
Iteration 6/1000 | Loss: 0.00008172
Iteration 7/1000 | Loss: 0.00016555
Iteration 8/1000 | Loss: 0.00020975
Iteration 9/1000 | Loss: 0.00017267
Iteration 10/1000 | Loss: 0.00019464
Iteration 11/1000 | Loss: 0.00017162
Iteration 12/1000 | Loss: 0.00013708
Iteration 13/1000 | Loss: 0.00058125
Iteration 14/1000 | Loss: 0.00023949
Iteration 15/1000 | Loss: 0.00029402
Iteration 16/1000 | Loss: 0.00005498
Iteration 17/1000 | Loss: 0.00004459
Iteration 18/1000 | Loss: 0.00004622
Iteration 19/1000 | Loss: 0.00005440
Iteration 20/1000 | Loss: 0.00100623
Iteration 21/1000 | Loss: 0.00044219
Iteration 22/1000 | Loss: 0.00032093
Iteration 23/1000 | Loss: 0.00008801
Iteration 24/1000 | Loss: 0.00004790
Iteration 25/1000 | Loss: 0.00003197
Iteration 26/1000 | Loss: 0.00003719
Iteration 27/1000 | Loss: 0.00017781
Iteration 28/1000 | Loss: 0.00001919
Iteration 29/1000 | Loss: 0.00002955
Iteration 30/1000 | Loss: 0.00001738
Iteration 31/1000 | Loss: 0.00005408
Iteration 32/1000 | Loss: 0.00007933
Iteration 33/1000 | Loss: 0.00001615
Iteration 34/1000 | Loss: 0.00003098
Iteration 35/1000 | Loss: 0.00001544
Iteration 36/1000 | Loss: 0.00001501
Iteration 37/1000 | Loss: 0.00002101
Iteration 38/1000 | Loss: 0.00006299
Iteration 39/1000 | Loss: 0.00001499
Iteration 40/1000 | Loss: 0.00001441
Iteration 41/1000 | Loss: 0.00001440
Iteration 42/1000 | Loss: 0.00001440
Iteration 43/1000 | Loss: 0.00001433
Iteration 44/1000 | Loss: 0.00002128
Iteration 45/1000 | Loss: 0.00002175
Iteration 46/1000 | Loss: 0.00001724
Iteration 47/1000 | Loss: 0.00001435
Iteration 48/1000 | Loss: 0.00001404
Iteration 49/1000 | Loss: 0.00001404
Iteration 50/1000 | Loss: 0.00001404
Iteration 51/1000 | Loss: 0.00001404
Iteration 52/1000 | Loss: 0.00001404
Iteration 53/1000 | Loss: 0.00001404
Iteration 54/1000 | Loss: 0.00001404
Iteration 55/1000 | Loss: 0.00001404
Iteration 56/1000 | Loss: 0.00001752
Iteration 57/1000 | Loss: 0.00001453
Iteration 58/1000 | Loss: 0.00002147
Iteration 59/1000 | Loss: 0.00001450
Iteration 60/1000 | Loss: 0.00001661
Iteration 61/1000 | Loss: 0.00001395
Iteration 62/1000 | Loss: 0.00001395
Iteration 63/1000 | Loss: 0.00001395
Iteration 64/1000 | Loss: 0.00001395
Iteration 65/1000 | Loss: 0.00001394
Iteration 66/1000 | Loss: 0.00001394
Iteration 67/1000 | Loss: 0.00001394
Iteration 68/1000 | Loss: 0.00001394
Iteration 69/1000 | Loss: 0.00002101
Iteration 70/1000 | Loss: 0.00001757
Iteration 71/1000 | Loss: 0.00001466
Iteration 72/1000 | Loss: 0.00001728
Iteration 73/1000 | Loss: 0.00001727
Iteration 74/1000 | Loss: 0.00001727
Iteration 75/1000 | Loss: 0.00007112
Iteration 76/1000 | Loss: 0.00001476
Iteration 77/1000 | Loss: 0.00001392
Iteration 78/1000 | Loss: 0.00001392
Iteration 79/1000 | Loss: 0.00001391
Iteration 80/1000 | Loss: 0.00001391
Iteration 81/1000 | Loss: 0.00001391
Iteration 82/1000 | Loss: 0.00001391
Iteration 83/1000 | Loss: 0.00001391
Iteration 84/1000 | Loss: 0.00001391
Iteration 85/1000 | Loss: 0.00001391
Iteration 86/1000 | Loss: 0.00001391
Iteration 87/1000 | Loss: 0.00001391
Iteration 88/1000 | Loss: 0.00001391
Iteration 89/1000 | Loss: 0.00001391
Iteration 90/1000 | Loss: 0.00001391
Iteration 91/1000 | Loss: 0.00001391
Iteration 92/1000 | Loss: 0.00001390
Iteration 93/1000 | Loss: 0.00001390
Iteration 94/1000 | Loss: 0.00001390
Iteration 95/1000 | Loss: 0.00001389
Iteration 96/1000 | Loss: 0.00001389
Iteration 97/1000 | Loss: 0.00001389
Iteration 98/1000 | Loss: 0.00001389
Iteration 99/1000 | Loss: 0.00001389
Iteration 100/1000 | Loss: 0.00001389
Iteration 101/1000 | Loss: 0.00001389
Iteration 102/1000 | Loss: 0.00001389
Iteration 103/1000 | Loss: 0.00001389
Iteration 104/1000 | Loss: 0.00001389
Iteration 105/1000 | Loss: 0.00001389
Iteration 106/1000 | Loss: 0.00001389
Iteration 107/1000 | Loss: 0.00001389
Iteration 108/1000 | Loss: 0.00001389
Iteration 109/1000 | Loss: 0.00001389
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.3891765775042586e-05, 1.3891765775042586e-05, 1.3891765775042586e-05, 1.3891765775042586e-05, 1.3891765775042586e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3891765775042586e-05

Optimization complete. Final v2v error: 3.053929090499878 mm

Highest mean error: 8.862772941589355 mm for frame 66

Lowest mean error: 2.3169403076171875 mm for frame 143

Saving results

Total time: 118.56695532798767
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00340594
Iteration 2/25 | Loss: 0.00075605
Iteration 3/25 | Loss: 0.00061810
Iteration 4/25 | Loss: 0.00059286
Iteration 5/25 | Loss: 0.00058744
Iteration 6/25 | Loss: 0.00058577
Iteration 7/25 | Loss: 0.00058542
Iteration 8/25 | Loss: 0.00058542
Iteration 9/25 | Loss: 0.00058542
Iteration 10/25 | Loss: 0.00058542
Iteration 11/25 | Loss: 0.00058542
Iteration 12/25 | Loss: 0.00058542
Iteration 13/25 | Loss: 0.00058542
Iteration 14/25 | Loss: 0.00058542
Iteration 15/25 | Loss: 0.00058542
Iteration 16/25 | Loss: 0.00058542
Iteration 17/25 | Loss: 0.00058542
Iteration 18/25 | Loss: 0.00058542
Iteration 19/25 | Loss: 0.00058542
Iteration 20/25 | Loss: 0.00058542
Iteration 21/25 | Loss: 0.00058542
Iteration 22/25 | Loss: 0.00058542
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005854240152984858, 0.0005854240152984858, 0.0005854240152984858, 0.0005854240152984858, 0.0005854240152984858]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005854240152984858

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49633396
Iteration 2/25 | Loss: 0.00032870
Iteration 3/25 | Loss: 0.00032870
Iteration 4/25 | Loss: 0.00032870
Iteration 5/25 | Loss: 0.00032870
Iteration 6/25 | Loss: 0.00032870
Iteration 7/25 | Loss: 0.00032870
Iteration 8/25 | Loss: 0.00032869
Iteration 9/25 | Loss: 0.00032869
Iteration 10/25 | Loss: 0.00032869
Iteration 11/25 | Loss: 0.00032869
Iteration 12/25 | Loss: 0.00032869
Iteration 13/25 | Loss: 0.00032869
Iteration 14/25 | Loss: 0.00032869
Iteration 15/25 | Loss: 0.00032869
Iteration 16/25 | Loss: 0.00032869
Iteration 17/25 | Loss: 0.00032869
Iteration 18/25 | Loss: 0.00032869
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00032869429560378194, 0.00032869429560378194, 0.00032869429560378194, 0.00032869429560378194, 0.00032869429560378194]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00032869429560378194

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032869
Iteration 2/1000 | Loss: 0.00002199
Iteration 3/1000 | Loss: 0.00001243
Iteration 4/1000 | Loss: 0.00001062
Iteration 5/1000 | Loss: 0.00001000
Iteration 6/1000 | Loss: 0.00000967
Iteration 7/1000 | Loss: 0.00000935
Iteration 8/1000 | Loss: 0.00000926
Iteration 9/1000 | Loss: 0.00000925
Iteration 10/1000 | Loss: 0.00000925
Iteration 11/1000 | Loss: 0.00000920
Iteration 12/1000 | Loss: 0.00000919
Iteration 13/1000 | Loss: 0.00000919
Iteration 14/1000 | Loss: 0.00000918
Iteration 15/1000 | Loss: 0.00000918
Iteration 16/1000 | Loss: 0.00000917
Iteration 17/1000 | Loss: 0.00000911
Iteration 18/1000 | Loss: 0.00000910
Iteration 19/1000 | Loss: 0.00000904
Iteration 20/1000 | Loss: 0.00000903
Iteration 21/1000 | Loss: 0.00000901
Iteration 22/1000 | Loss: 0.00000901
Iteration 23/1000 | Loss: 0.00000901
Iteration 24/1000 | Loss: 0.00000901
Iteration 25/1000 | Loss: 0.00000901
Iteration 26/1000 | Loss: 0.00000901
Iteration 27/1000 | Loss: 0.00000901
Iteration 28/1000 | Loss: 0.00000900
Iteration 29/1000 | Loss: 0.00000900
Iteration 30/1000 | Loss: 0.00000899
Iteration 31/1000 | Loss: 0.00000899
Iteration 32/1000 | Loss: 0.00000897
Iteration 33/1000 | Loss: 0.00000897
Iteration 34/1000 | Loss: 0.00000897
Iteration 35/1000 | Loss: 0.00000896
Iteration 36/1000 | Loss: 0.00000896
Iteration 37/1000 | Loss: 0.00000896
Iteration 38/1000 | Loss: 0.00000895
Iteration 39/1000 | Loss: 0.00000893
Iteration 40/1000 | Loss: 0.00000893
Iteration 41/1000 | Loss: 0.00000892
Iteration 42/1000 | Loss: 0.00000892
Iteration 43/1000 | Loss: 0.00000890
Iteration 44/1000 | Loss: 0.00000890
Iteration 45/1000 | Loss: 0.00000889
Iteration 46/1000 | Loss: 0.00000889
Iteration 47/1000 | Loss: 0.00000888
Iteration 48/1000 | Loss: 0.00000888
Iteration 49/1000 | Loss: 0.00000887
Iteration 50/1000 | Loss: 0.00000884
Iteration 51/1000 | Loss: 0.00000883
Iteration 52/1000 | Loss: 0.00000881
Iteration 53/1000 | Loss: 0.00000881
Iteration 54/1000 | Loss: 0.00000881
Iteration 55/1000 | Loss: 0.00000881
Iteration 56/1000 | Loss: 0.00000881
Iteration 57/1000 | Loss: 0.00000880
Iteration 58/1000 | Loss: 0.00000880
Iteration 59/1000 | Loss: 0.00000880
Iteration 60/1000 | Loss: 0.00000880
Iteration 61/1000 | Loss: 0.00000880
Iteration 62/1000 | Loss: 0.00000880
Iteration 63/1000 | Loss: 0.00000880
Iteration 64/1000 | Loss: 0.00000880
Iteration 65/1000 | Loss: 0.00000880
Iteration 66/1000 | Loss: 0.00000880
Iteration 67/1000 | Loss: 0.00000879
Iteration 68/1000 | Loss: 0.00000879
Iteration 69/1000 | Loss: 0.00000879
Iteration 70/1000 | Loss: 0.00000878
Iteration 71/1000 | Loss: 0.00000878
Iteration 72/1000 | Loss: 0.00000878
Iteration 73/1000 | Loss: 0.00000878
Iteration 74/1000 | Loss: 0.00000878
Iteration 75/1000 | Loss: 0.00000878
Iteration 76/1000 | Loss: 0.00000878
Iteration 77/1000 | Loss: 0.00000878
Iteration 78/1000 | Loss: 0.00000878
Iteration 79/1000 | Loss: 0.00000878
Iteration 80/1000 | Loss: 0.00000878
Iteration 81/1000 | Loss: 0.00000878
Iteration 82/1000 | Loss: 0.00000878
Iteration 83/1000 | Loss: 0.00000877
Iteration 84/1000 | Loss: 0.00000877
Iteration 85/1000 | Loss: 0.00000877
Iteration 86/1000 | Loss: 0.00000877
Iteration 87/1000 | Loss: 0.00000877
Iteration 88/1000 | Loss: 0.00000877
Iteration 89/1000 | Loss: 0.00000877
Iteration 90/1000 | Loss: 0.00000877
Iteration 91/1000 | Loss: 0.00000877
Iteration 92/1000 | Loss: 0.00000877
Iteration 93/1000 | Loss: 0.00000877
Iteration 94/1000 | Loss: 0.00000877
Iteration 95/1000 | Loss: 0.00000877
Iteration 96/1000 | Loss: 0.00000877
Iteration 97/1000 | Loss: 0.00000877
Iteration 98/1000 | Loss: 0.00000877
Iteration 99/1000 | Loss: 0.00000877
Iteration 100/1000 | Loss: 0.00000877
Iteration 101/1000 | Loss: 0.00000876
Iteration 102/1000 | Loss: 0.00000876
Iteration 103/1000 | Loss: 0.00000876
Iteration 104/1000 | Loss: 0.00000876
Iteration 105/1000 | Loss: 0.00000876
Iteration 106/1000 | Loss: 0.00000876
Iteration 107/1000 | Loss: 0.00000875
Iteration 108/1000 | Loss: 0.00000875
Iteration 109/1000 | Loss: 0.00000875
Iteration 110/1000 | Loss: 0.00000875
Iteration 111/1000 | Loss: 0.00000875
Iteration 112/1000 | Loss: 0.00000875
Iteration 113/1000 | Loss: 0.00000875
Iteration 114/1000 | Loss: 0.00000875
Iteration 115/1000 | Loss: 0.00000875
Iteration 116/1000 | Loss: 0.00000875
Iteration 117/1000 | Loss: 0.00000875
Iteration 118/1000 | Loss: 0.00000875
Iteration 119/1000 | Loss: 0.00000875
Iteration 120/1000 | Loss: 0.00000875
Iteration 121/1000 | Loss: 0.00000875
Iteration 122/1000 | Loss: 0.00000875
Iteration 123/1000 | Loss: 0.00000874
Iteration 124/1000 | Loss: 0.00000874
Iteration 125/1000 | Loss: 0.00000874
Iteration 126/1000 | Loss: 0.00000874
Iteration 127/1000 | Loss: 0.00000874
Iteration 128/1000 | Loss: 0.00000874
Iteration 129/1000 | Loss: 0.00000874
Iteration 130/1000 | Loss: 0.00000874
Iteration 131/1000 | Loss: 0.00000874
Iteration 132/1000 | Loss: 0.00000874
Iteration 133/1000 | Loss: 0.00000874
Iteration 134/1000 | Loss: 0.00000874
Iteration 135/1000 | Loss: 0.00000873
Iteration 136/1000 | Loss: 0.00000873
Iteration 137/1000 | Loss: 0.00000873
Iteration 138/1000 | Loss: 0.00000873
Iteration 139/1000 | Loss: 0.00000872
Iteration 140/1000 | Loss: 0.00000872
Iteration 141/1000 | Loss: 0.00000872
Iteration 142/1000 | Loss: 0.00000872
Iteration 143/1000 | Loss: 0.00000872
Iteration 144/1000 | Loss: 0.00000872
Iteration 145/1000 | Loss: 0.00000872
Iteration 146/1000 | Loss: 0.00000872
Iteration 147/1000 | Loss: 0.00000872
Iteration 148/1000 | Loss: 0.00000872
Iteration 149/1000 | Loss: 0.00000872
Iteration 150/1000 | Loss: 0.00000872
Iteration 151/1000 | Loss: 0.00000872
Iteration 152/1000 | Loss: 0.00000872
Iteration 153/1000 | Loss: 0.00000872
Iteration 154/1000 | Loss: 0.00000871
Iteration 155/1000 | Loss: 0.00000871
Iteration 156/1000 | Loss: 0.00000871
Iteration 157/1000 | Loss: 0.00000871
Iteration 158/1000 | Loss: 0.00000871
Iteration 159/1000 | Loss: 0.00000871
Iteration 160/1000 | Loss: 0.00000871
Iteration 161/1000 | Loss: 0.00000871
Iteration 162/1000 | Loss: 0.00000871
Iteration 163/1000 | Loss: 0.00000870
Iteration 164/1000 | Loss: 0.00000870
Iteration 165/1000 | Loss: 0.00000870
Iteration 166/1000 | Loss: 0.00000870
Iteration 167/1000 | Loss: 0.00000870
Iteration 168/1000 | Loss: 0.00000870
Iteration 169/1000 | Loss: 0.00000870
Iteration 170/1000 | Loss: 0.00000870
Iteration 171/1000 | Loss: 0.00000870
Iteration 172/1000 | Loss: 0.00000870
Iteration 173/1000 | Loss: 0.00000870
Iteration 174/1000 | Loss: 0.00000870
Iteration 175/1000 | Loss: 0.00000870
Iteration 176/1000 | Loss: 0.00000870
Iteration 177/1000 | Loss: 0.00000870
Iteration 178/1000 | Loss: 0.00000870
Iteration 179/1000 | Loss: 0.00000870
Iteration 180/1000 | Loss: 0.00000870
Iteration 181/1000 | Loss: 0.00000870
Iteration 182/1000 | Loss: 0.00000870
Iteration 183/1000 | Loss: 0.00000870
Iteration 184/1000 | Loss: 0.00000870
Iteration 185/1000 | Loss: 0.00000870
Iteration 186/1000 | Loss: 0.00000870
Iteration 187/1000 | Loss: 0.00000870
Iteration 188/1000 | Loss: 0.00000870
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 188. Stopping optimization.
Last 5 losses: [8.69911764311837e-06, 8.69911764311837e-06, 8.69911764311837e-06, 8.69911764311837e-06, 8.69911764311837e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.69911764311837e-06

Optimization complete. Final v2v error: 2.5251855850219727 mm

Highest mean error: 3.1106269359588623 mm for frame 9

Lowest mean error: 2.1795005798339844 mm for frame 118

Saving results

Total time: 33.30849862098694
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00810381
Iteration 2/25 | Loss: 0.00131582
Iteration 3/25 | Loss: 0.00098074
Iteration 4/25 | Loss: 0.00082014
Iteration 5/25 | Loss: 0.00078035
Iteration 6/25 | Loss: 0.00077119
Iteration 7/25 | Loss: 0.00076311
Iteration 8/25 | Loss: 0.00076202
Iteration 9/25 | Loss: 0.00076161
Iteration 10/25 | Loss: 0.00076149
Iteration 11/25 | Loss: 0.00076146
Iteration 12/25 | Loss: 0.00076146
Iteration 13/25 | Loss: 0.00076145
Iteration 14/25 | Loss: 0.00076145
Iteration 15/25 | Loss: 0.00076145
Iteration 16/25 | Loss: 0.00076145
Iteration 17/25 | Loss: 0.00076145
Iteration 18/25 | Loss: 0.00076145
Iteration 19/25 | Loss: 0.00076145
Iteration 20/25 | Loss: 0.00076145
Iteration 21/25 | Loss: 0.00076145
Iteration 22/25 | Loss: 0.00076144
Iteration 23/25 | Loss: 0.00076144
Iteration 24/25 | Loss: 0.00076144
Iteration 25/25 | Loss: 0.00076144

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.19589019
Iteration 2/25 | Loss: 0.00038840
Iteration 3/25 | Loss: 0.00038840
Iteration 4/25 | Loss: 0.00038840
Iteration 5/25 | Loss: 0.00038840
Iteration 6/25 | Loss: 0.00038839
Iteration 7/25 | Loss: 0.00038839
Iteration 8/25 | Loss: 0.00038839
Iteration 9/25 | Loss: 0.00038839
Iteration 10/25 | Loss: 0.00038839
Iteration 11/25 | Loss: 0.00038839
Iteration 12/25 | Loss: 0.00038839
Iteration 13/25 | Loss: 0.00038839
Iteration 14/25 | Loss: 0.00038839
Iteration 15/25 | Loss: 0.00038839
Iteration 16/25 | Loss: 0.00038839
Iteration 17/25 | Loss: 0.00038839
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003883936151396483, 0.0003883936151396483, 0.0003883936151396483, 0.0003883936151396483, 0.0003883936151396483]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003883936151396483

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038839
Iteration 2/1000 | Loss: 0.00004089
Iteration 3/1000 | Loss: 0.00003057
Iteration 4/1000 | Loss: 0.00002873
Iteration 5/1000 | Loss: 0.00002764
Iteration 6/1000 | Loss: 0.00002670
Iteration 7/1000 | Loss: 0.00002622
Iteration 8/1000 | Loss: 0.00002583
Iteration 9/1000 | Loss: 0.00002565
Iteration 10/1000 | Loss: 0.00002554
Iteration 11/1000 | Loss: 0.00002537
Iteration 12/1000 | Loss: 0.00002526
Iteration 13/1000 | Loss: 0.00002519
Iteration 14/1000 | Loss: 0.00002514
Iteration 15/1000 | Loss: 0.00002511
Iteration 16/1000 | Loss: 0.00002511
Iteration 17/1000 | Loss: 0.00002510
Iteration 18/1000 | Loss: 0.00002510
Iteration 19/1000 | Loss: 0.00002509
Iteration 20/1000 | Loss: 0.00002508
Iteration 21/1000 | Loss: 0.00002508
Iteration 22/1000 | Loss: 0.00002503
Iteration 23/1000 | Loss: 0.00002500
Iteration 24/1000 | Loss: 0.00002500
Iteration 25/1000 | Loss: 0.00002496
Iteration 26/1000 | Loss: 0.00002496
Iteration 27/1000 | Loss: 0.00002496
Iteration 28/1000 | Loss: 0.00002495
Iteration 29/1000 | Loss: 0.00002495
Iteration 30/1000 | Loss: 0.00002495
Iteration 31/1000 | Loss: 0.00002494
Iteration 32/1000 | Loss: 0.00002494
Iteration 33/1000 | Loss: 0.00002494
Iteration 34/1000 | Loss: 0.00002493
Iteration 35/1000 | Loss: 0.00002493
Iteration 36/1000 | Loss: 0.00002493
Iteration 37/1000 | Loss: 0.00002492
Iteration 38/1000 | Loss: 0.00002492
Iteration 39/1000 | Loss: 0.00002492
Iteration 40/1000 | Loss: 0.00002492
Iteration 41/1000 | Loss: 0.00002492
Iteration 42/1000 | Loss: 0.00002492
Iteration 43/1000 | Loss: 0.00002492
Iteration 44/1000 | Loss: 0.00002492
Iteration 45/1000 | Loss: 0.00002492
Iteration 46/1000 | Loss: 0.00002492
Iteration 47/1000 | Loss: 0.00002492
Iteration 48/1000 | Loss: 0.00002492
Iteration 49/1000 | Loss: 0.00002492
Iteration 50/1000 | Loss: 0.00002492
Iteration 51/1000 | Loss: 0.00002492
Iteration 52/1000 | Loss: 0.00002492
Iteration 53/1000 | Loss: 0.00002492
Iteration 54/1000 | Loss: 0.00002492
Iteration 55/1000 | Loss: 0.00002492
Iteration 56/1000 | Loss: 0.00002492
Iteration 57/1000 | Loss: 0.00002491
Iteration 58/1000 | Loss: 0.00002491
Iteration 59/1000 | Loss: 0.00002491
Iteration 60/1000 | Loss: 0.00002491
Iteration 61/1000 | Loss: 0.00002491
Iteration 62/1000 | Loss: 0.00002491
Iteration 63/1000 | Loss: 0.00002491
Iteration 64/1000 | Loss: 0.00002491
Iteration 65/1000 | Loss: 0.00002491
Iteration 66/1000 | Loss: 0.00002491
Iteration 67/1000 | Loss: 0.00002491
Iteration 68/1000 | Loss: 0.00002491
Iteration 69/1000 | Loss: 0.00002491
Iteration 70/1000 | Loss: 0.00002491
Iteration 71/1000 | Loss: 0.00002491
Iteration 72/1000 | Loss: 0.00002491
Iteration 73/1000 | Loss: 0.00002491
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 73. Stopping optimization.
Last 5 losses: [2.491380655555986e-05, 2.491380655555986e-05, 2.491380655555986e-05, 2.491380655555986e-05, 2.491380655555986e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.491380655555986e-05

Optimization complete. Final v2v error: 4.1877336502075195 mm

Highest mean error: 4.781287670135498 mm for frame 70

Lowest mean error: 3.302905797958374 mm for frame 192

Saving results

Total time: 45.200507164001465
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01154615
Iteration 2/25 | Loss: 0.00218569
Iteration 3/25 | Loss: 0.00146666
Iteration 4/25 | Loss: 0.00125892
Iteration 5/25 | Loss: 0.00143768
Iteration 6/25 | Loss: 0.00161854
Iteration 7/25 | Loss: 0.00150565
Iteration 8/25 | Loss: 0.00131096
Iteration 9/25 | Loss: 0.00121492
Iteration 10/25 | Loss: 0.00115527
Iteration 11/25 | Loss: 0.00111516
Iteration 12/25 | Loss: 0.00112624
Iteration 13/25 | Loss: 0.00113211
Iteration 14/25 | Loss: 0.00109507
Iteration 15/25 | Loss: 0.00105140
Iteration 16/25 | Loss: 0.00104840
Iteration 17/25 | Loss: 0.00102523
Iteration 18/25 | Loss: 0.00103919
Iteration 19/25 | Loss: 0.00102187
Iteration 20/25 | Loss: 0.00100840
Iteration 21/25 | Loss: 0.00103232
Iteration 22/25 | Loss: 0.00100990
Iteration 23/25 | Loss: 0.00101339
Iteration 24/25 | Loss: 0.00100050
Iteration 25/25 | Loss: 0.00097354

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31500828
Iteration 2/25 | Loss: 0.00284489
Iteration 3/25 | Loss: 0.00247696
Iteration 4/25 | Loss: 0.00247696
Iteration 5/25 | Loss: 0.00247696
Iteration 6/25 | Loss: 0.00247696
Iteration 7/25 | Loss: 0.00247696
Iteration 8/25 | Loss: 0.00247696
Iteration 9/25 | Loss: 0.00247696
Iteration 10/25 | Loss: 0.00247696
Iteration 11/25 | Loss: 0.00247696
Iteration 12/25 | Loss: 0.00247696
Iteration 13/25 | Loss: 0.00247696
Iteration 14/25 | Loss: 0.00247696
Iteration 15/25 | Loss: 0.00247696
Iteration 16/25 | Loss: 0.00247696
Iteration 17/25 | Loss: 0.00247696
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0024769557639956474, 0.0024769557639956474, 0.0024769557639956474, 0.0024769557639956474, 0.0024769557639956474]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0024769557639956474

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00247696
Iteration 2/1000 | Loss: 0.00162078
Iteration 3/1000 | Loss: 0.00102773
Iteration 4/1000 | Loss: 0.00157529
Iteration 5/1000 | Loss: 0.00150177
Iteration 6/1000 | Loss: 0.00061199
Iteration 7/1000 | Loss: 0.00130797
Iteration 8/1000 | Loss: 0.00098422
Iteration 9/1000 | Loss: 0.00116921
Iteration 10/1000 | Loss: 0.00121860
Iteration 11/1000 | Loss: 0.00064289
Iteration 12/1000 | Loss: 0.00093955
Iteration 13/1000 | Loss: 0.00131621
Iteration 14/1000 | Loss: 0.00166462
Iteration 15/1000 | Loss: 0.00093388
Iteration 16/1000 | Loss: 0.00066506
Iteration 17/1000 | Loss: 0.00059137
Iteration 18/1000 | Loss: 0.00106866
Iteration 19/1000 | Loss: 0.00106726
Iteration 20/1000 | Loss: 0.00049277
Iteration 21/1000 | Loss: 0.00094010
Iteration 22/1000 | Loss: 0.00058166
Iteration 23/1000 | Loss: 0.00065777
Iteration 24/1000 | Loss: 0.00071668
Iteration 25/1000 | Loss: 0.00073405
Iteration 26/1000 | Loss: 0.00081498
Iteration 27/1000 | Loss: 0.00117929
Iteration 28/1000 | Loss: 0.00094792
Iteration 29/1000 | Loss: 0.00050314
Iteration 30/1000 | Loss: 0.00078029
Iteration 31/1000 | Loss: 0.00044882
Iteration 32/1000 | Loss: 0.00067704
Iteration 33/1000 | Loss: 0.00075475
Iteration 34/1000 | Loss: 0.00035977
Iteration 35/1000 | Loss: 0.00060154
Iteration 36/1000 | Loss: 0.00058194
Iteration 37/1000 | Loss: 0.00154586
Iteration 38/1000 | Loss: 0.00071967
Iteration 39/1000 | Loss: 0.00083566
Iteration 40/1000 | Loss: 0.00070516
Iteration 41/1000 | Loss: 0.00054642
Iteration 42/1000 | Loss: 0.00048423
Iteration 43/1000 | Loss: 0.00082150
Iteration 44/1000 | Loss: 0.00069312
Iteration 45/1000 | Loss: 0.00099197
Iteration 46/1000 | Loss: 0.00056986
Iteration 47/1000 | Loss: 0.00091707
Iteration 48/1000 | Loss: 0.00091906
Iteration 49/1000 | Loss: 0.00050048
Iteration 50/1000 | Loss: 0.00114001
Iteration 51/1000 | Loss: 0.00104431
Iteration 52/1000 | Loss: 0.00079442
Iteration 53/1000 | Loss: 0.00079859
Iteration 54/1000 | Loss: 0.00048202
Iteration 55/1000 | Loss: 0.00065804
Iteration 56/1000 | Loss: 0.00057525
Iteration 57/1000 | Loss: 0.00058156
Iteration 58/1000 | Loss: 0.00048609
Iteration 59/1000 | Loss: 0.00053163
Iteration 60/1000 | Loss: 0.00053105
Iteration 61/1000 | Loss: 0.00046151
Iteration 62/1000 | Loss: 0.00050335
Iteration 63/1000 | Loss: 0.00070681
Iteration 64/1000 | Loss: 0.00121746
Iteration 65/1000 | Loss: 0.00083955
Iteration 66/1000 | Loss: 0.00077080
Iteration 67/1000 | Loss: 0.00050987
Iteration 68/1000 | Loss: 0.00074172
Iteration 69/1000 | Loss: 0.00026672
Iteration 70/1000 | Loss: 0.00032582
Iteration 71/1000 | Loss: 0.00055690
Iteration 72/1000 | Loss: 0.00070625
Iteration 73/1000 | Loss: 0.00033194
Iteration 74/1000 | Loss: 0.00081684
Iteration 75/1000 | Loss: 0.00048693
Iteration 76/1000 | Loss: 0.00024256
Iteration 77/1000 | Loss: 0.00046920
Iteration 78/1000 | Loss: 0.00141558
Iteration 79/1000 | Loss: 0.00020182
Iteration 80/1000 | Loss: 0.00034358
Iteration 81/1000 | Loss: 0.00058555
Iteration 82/1000 | Loss: 0.00033509
Iteration 83/1000 | Loss: 0.00058872
Iteration 84/1000 | Loss: 0.00057898
Iteration 85/1000 | Loss: 0.00025412
Iteration 86/1000 | Loss: 0.00045842
Iteration 87/1000 | Loss: 0.00034520
Iteration 88/1000 | Loss: 0.00023313
Iteration 89/1000 | Loss: 0.00037756
Iteration 90/1000 | Loss: 0.00040787
Iteration 91/1000 | Loss: 0.00055808
Iteration 92/1000 | Loss: 0.00106624
Iteration 93/1000 | Loss: 0.00066632
Iteration 94/1000 | Loss: 0.00066732
Iteration 95/1000 | Loss: 0.00016331
Iteration 96/1000 | Loss: 0.00012636
Iteration 97/1000 | Loss: 0.00011856
Iteration 98/1000 | Loss: 0.00013131
Iteration 99/1000 | Loss: 0.00015277
Iteration 100/1000 | Loss: 0.00013802
Iteration 101/1000 | Loss: 0.00048870
Iteration 102/1000 | Loss: 0.00051520
Iteration 103/1000 | Loss: 0.00054027
Iteration 104/1000 | Loss: 0.00059602
Iteration 105/1000 | Loss: 0.00011328
Iteration 106/1000 | Loss: 0.00010207
Iteration 107/1000 | Loss: 0.00087302
Iteration 108/1000 | Loss: 0.00049263
Iteration 109/1000 | Loss: 0.00084763
Iteration 110/1000 | Loss: 0.00088112
Iteration 111/1000 | Loss: 0.00074631
Iteration 112/1000 | Loss: 0.00053279
Iteration 113/1000 | Loss: 0.00063398
Iteration 114/1000 | Loss: 0.00079459
Iteration 115/1000 | Loss: 0.00052444
Iteration 116/1000 | Loss: 0.00062689
Iteration 117/1000 | Loss: 0.00065725
Iteration 118/1000 | Loss: 0.00047600
Iteration 119/1000 | Loss: 0.00010311
Iteration 120/1000 | Loss: 0.00050636
Iteration 121/1000 | Loss: 0.00044306
Iteration 122/1000 | Loss: 0.00098600
Iteration 123/1000 | Loss: 0.00047018
Iteration 124/1000 | Loss: 0.00077271
Iteration 125/1000 | Loss: 0.00052151
Iteration 126/1000 | Loss: 0.00041335
Iteration 127/1000 | Loss: 0.00076116
Iteration 128/1000 | Loss: 0.00081728
Iteration 129/1000 | Loss: 0.00068941
Iteration 130/1000 | Loss: 0.00059449
Iteration 131/1000 | Loss: 0.00072394
Iteration 132/1000 | Loss: 0.00041077
Iteration 133/1000 | Loss: 0.00013874
Iteration 134/1000 | Loss: 0.00048996
Iteration 135/1000 | Loss: 0.00015043
Iteration 136/1000 | Loss: 0.00086564
Iteration 137/1000 | Loss: 0.00058438
Iteration 138/1000 | Loss: 0.00010676
Iteration 139/1000 | Loss: 0.00009030
Iteration 140/1000 | Loss: 0.00048576
Iteration 141/1000 | Loss: 0.00053186
Iteration 142/1000 | Loss: 0.00010821
Iteration 143/1000 | Loss: 0.00007819
Iteration 144/1000 | Loss: 0.00007541
Iteration 145/1000 | Loss: 0.00006938
Iteration 146/1000 | Loss: 0.00009089
Iteration 147/1000 | Loss: 0.00042099
Iteration 148/1000 | Loss: 0.00061154
Iteration 149/1000 | Loss: 0.00073667
Iteration 150/1000 | Loss: 0.00069024
Iteration 151/1000 | Loss: 0.00044502
Iteration 152/1000 | Loss: 0.00028447
Iteration 153/1000 | Loss: 0.00106064
Iteration 154/1000 | Loss: 0.00156326
Iteration 155/1000 | Loss: 0.00140166
Iteration 156/1000 | Loss: 0.00055985
Iteration 157/1000 | Loss: 0.00017836
Iteration 158/1000 | Loss: 0.00035122
Iteration 159/1000 | Loss: 0.00013801
Iteration 160/1000 | Loss: 0.00008569
Iteration 161/1000 | Loss: 0.00013032
Iteration 162/1000 | Loss: 0.00037217
Iteration 163/1000 | Loss: 0.00041822
Iteration 164/1000 | Loss: 0.00036782
Iteration 165/1000 | Loss: 0.00008047
Iteration 166/1000 | Loss: 0.00006674
Iteration 167/1000 | Loss: 0.00006129
Iteration 168/1000 | Loss: 0.00020952
Iteration 169/1000 | Loss: 0.00011104
Iteration 170/1000 | Loss: 0.00017169
Iteration 171/1000 | Loss: 0.00011463
Iteration 172/1000 | Loss: 0.00007325
Iteration 173/1000 | Loss: 0.00007491
Iteration 174/1000 | Loss: 0.00005800
Iteration 175/1000 | Loss: 0.00044828
Iteration 176/1000 | Loss: 0.00033787
Iteration 177/1000 | Loss: 0.00040323
Iteration 178/1000 | Loss: 0.00028276
Iteration 179/1000 | Loss: 0.00036489
Iteration 180/1000 | Loss: 0.00025229
Iteration 181/1000 | Loss: 0.00038915
Iteration 182/1000 | Loss: 0.00026033
Iteration 183/1000 | Loss: 0.00045752
Iteration 184/1000 | Loss: 0.00008697
Iteration 185/1000 | Loss: 0.00006031
Iteration 186/1000 | Loss: 0.00009060
Iteration 187/1000 | Loss: 0.00008349
Iteration 188/1000 | Loss: 0.00006832
Iteration 189/1000 | Loss: 0.00007659
Iteration 190/1000 | Loss: 0.00007201
Iteration 191/1000 | Loss: 0.00007163
Iteration 192/1000 | Loss: 0.00007722
Iteration 193/1000 | Loss: 0.00007288
Iteration 194/1000 | Loss: 0.00006442
Iteration 195/1000 | Loss: 0.00007604
Iteration 196/1000 | Loss: 0.00007876
Iteration 197/1000 | Loss: 0.00007194
Iteration 198/1000 | Loss: 0.00008692
Iteration 199/1000 | Loss: 0.00006798
Iteration 200/1000 | Loss: 0.00006189
Iteration 201/1000 | Loss: 0.00007345
Iteration 202/1000 | Loss: 0.00006078
Iteration 203/1000 | Loss: 0.00007673
Iteration 204/1000 | Loss: 0.00009861
Iteration 205/1000 | Loss: 0.00007457
Iteration 206/1000 | Loss: 0.00007990
Iteration 207/1000 | Loss: 0.00005632
Iteration 208/1000 | Loss: 0.00004236
Iteration 209/1000 | Loss: 0.00007342
Iteration 210/1000 | Loss: 0.00005770
Iteration 211/1000 | Loss: 0.00007365
Iteration 212/1000 | Loss: 0.00005719
Iteration 213/1000 | Loss: 0.00006182
Iteration 214/1000 | Loss: 0.00006635
Iteration 215/1000 | Loss: 0.00006996
Iteration 216/1000 | Loss: 0.00006272
Iteration 217/1000 | Loss: 0.00007112
Iteration 218/1000 | Loss: 0.00004347
Iteration 219/1000 | Loss: 0.00008537
Iteration 220/1000 | Loss: 0.00003945
Iteration 221/1000 | Loss: 0.00003674
Iteration 222/1000 | Loss: 0.00003483
Iteration 223/1000 | Loss: 0.00003374
Iteration 224/1000 | Loss: 0.00003308
Iteration 225/1000 | Loss: 0.00003262
Iteration 226/1000 | Loss: 0.00003197
Iteration 227/1000 | Loss: 0.00003142
Iteration 228/1000 | Loss: 0.00003106
Iteration 229/1000 | Loss: 0.00003086
Iteration 230/1000 | Loss: 0.00003072
Iteration 231/1000 | Loss: 0.00003066
Iteration 232/1000 | Loss: 0.00003066
Iteration 233/1000 | Loss: 0.00003060
Iteration 234/1000 | Loss: 0.00003059
Iteration 235/1000 | Loss: 0.00003059
Iteration 236/1000 | Loss: 0.00003054
Iteration 237/1000 | Loss: 0.00003053
Iteration 238/1000 | Loss: 0.00003053
Iteration 239/1000 | Loss: 0.00003053
Iteration 240/1000 | Loss: 0.00003052
Iteration 241/1000 | Loss: 0.00003052
Iteration 242/1000 | Loss: 0.00003052
Iteration 243/1000 | Loss: 0.00003051
Iteration 244/1000 | Loss: 0.00003050
Iteration 245/1000 | Loss: 0.00003045
Iteration 246/1000 | Loss: 0.00003041
Iteration 247/1000 | Loss: 0.00003039
Iteration 248/1000 | Loss: 0.00003039
Iteration 249/1000 | Loss: 0.00003037
Iteration 250/1000 | Loss: 0.00003037
Iteration 251/1000 | Loss: 0.00003036
Iteration 252/1000 | Loss: 0.00003036
Iteration 253/1000 | Loss: 0.00003036
Iteration 254/1000 | Loss: 0.00003036
Iteration 255/1000 | Loss: 0.00003035
Iteration 256/1000 | Loss: 0.00003035
Iteration 257/1000 | Loss: 0.00003035
Iteration 258/1000 | Loss: 0.00003035
Iteration 259/1000 | Loss: 0.00003035
Iteration 260/1000 | Loss: 0.00003034
Iteration 261/1000 | Loss: 0.00003034
Iteration 262/1000 | Loss: 0.00003034
Iteration 263/1000 | Loss: 0.00003034
Iteration 264/1000 | Loss: 0.00003034
Iteration 265/1000 | Loss: 0.00003034
Iteration 266/1000 | Loss: 0.00003034
Iteration 267/1000 | Loss: 0.00003034
Iteration 268/1000 | Loss: 0.00003034
Iteration 269/1000 | Loss: 0.00003034
Iteration 270/1000 | Loss: 0.00003034
Iteration 271/1000 | Loss: 0.00003033
Iteration 272/1000 | Loss: 0.00003033
Iteration 273/1000 | Loss: 0.00003033
Iteration 274/1000 | Loss: 0.00003033
Iteration 275/1000 | Loss: 0.00003033
Iteration 276/1000 | Loss: 0.00003033
Iteration 277/1000 | Loss: 0.00003033
Iteration 278/1000 | Loss: 0.00003032
Iteration 279/1000 | Loss: 0.00003032
Iteration 280/1000 | Loss: 0.00003031
Iteration 281/1000 | Loss: 0.00003031
Iteration 282/1000 | Loss: 0.00003031
Iteration 283/1000 | Loss: 0.00003031
Iteration 284/1000 | Loss: 0.00003031
Iteration 285/1000 | Loss: 0.00003031
Iteration 286/1000 | Loss: 0.00003031
Iteration 287/1000 | Loss: 0.00003031
Iteration 288/1000 | Loss: 0.00003031
Iteration 289/1000 | Loss: 0.00003031
Iteration 290/1000 | Loss: 0.00003031
Iteration 291/1000 | Loss: 0.00003031
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 291. Stopping optimization.
Last 5 losses: [3.0311728551168926e-05, 3.0311728551168926e-05, 3.0311728551168926e-05, 3.0311728551168926e-05, 3.0311728551168926e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.0311728551168926e-05

Optimization complete. Final v2v error: 4.109633922576904 mm

Highest mean error: 18.866506576538086 mm for frame 1

Lowest mean error: 3.7204127311706543 mm for frame 118

Saving results

Total time: 354.93602752685547
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_nl_4036/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_nl_4036/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00562491
Iteration 2/25 | Loss: 0.00100633
Iteration 3/25 | Loss: 0.00079418
Iteration 4/25 | Loss: 0.00075882
Iteration 5/25 | Loss: 0.00075133
Iteration 6/25 | Loss: 0.00075001
Iteration 7/25 | Loss: 0.00075001
Iteration 8/25 | Loss: 0.00075001
Iteration 9/25 | Loss: 0.00075001
Iteration 10/25 | Loss: 0.00075001
Iteration 11/25 | Loss: 0.00075001
Iteration 12/25 | Loss: 0.00075001
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007500062929466367, 0.0007500062929466367, 0.0007500062929466367, 0.0007500062929466367, 0.0007500062929466367]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007500062929466367

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.67336005
Iteration 2/25 | Loss: 0.00033016
Iteration 3/25 | Loss: 0.00033015
Iteration 4/25 | Loss: 0.00033015
Iteration 5/25 | Loss: 0.00033015
Iteration 6/25 | Loss: 0.00033015
Iteration 7/25 | Loss: 0.00033015
Iteration 8/25 | Loss: 0.00033015
Iteration 9/25 | Loss: 0.00033015
Iteration 10/25 | Loss: 0.00033015
Iteration 11/25 | Loss: 0.00033015
Iteration 12/25 | Loss: 0.00033015
Iteration 13/25 | Loss: 0.00033015
Iteration 14/25 | Loss: 0.00033015
Iteration 15/25 | Loss: 0.00033015
Iteration 16/25 | Loss: 0.00033015
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0003301479737274349, 0.0003301479737274349, 0.0003301479737274349, 0.0003301479737274349, 0.0003301479737274349]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003301479737274349

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033015
Iteration 2/1000 | Loss: 0.00003692
Iteration 3/1000 | Loss: 0.00002759
Iteration 4/1000 | Loss: 0.00002564
Iteration 5/1000 | Loss: 0.00002458
Iteration 6/1000 | Loss: 0.00002386
Iteration 7/1000 | Loss: 0.00002354
Iteration 8/1000 | Loss: 0.00002319
Iteration 9/1000 | Loss: 0.00002296
Iteration 10/1000 | Loss: 0.00002294
Iteration 11/1000 | Loss: 0.00002275
Iteration 12/1000 | Loss: 0.00002258
Iteration 13/1000 | Loss: 0.00002246
Iteration 14/1000 | Loss: 0.00002238
Iteration 15/1000 | Loss: 0.00002235
Iteration 16/1000 | Loss: 0.00002234
Iteration 17/1000 | Loss: 0.00002229
Iteration 18/1000 | Loss: 0.00002221
Iteration 19/1000 | Loss: 0.00002219
Iteration 20/1000 | Loss: 0.00002210
Iteration 21/1000 | Loss: 0.00002210
Iteration 22/1000 | Loss: 0.00002210
Iteration 23/1000 | Loss: 0.00002209
Iteration 24/1000 | Loss: 0.00002209
Iteration 25/1000 | Loss: 0.00002209
Iteration 26/1000 | Loss: 0.00002209
Iteration 27/1000 | Loss: 0.00002208
Iteration 28/1000 | Loss: 0.00002207
Iteration 29/1000 | Loss: 0.00002206
Iteration 30/1000 | Loss: 0.00002206
Iteration 31/1000 | Loss: 0.00002201
Iteration 32/1000 | Loss: 0.00002201
Iteration 33/1000 | Loss: 0.00002200
Iteration 34/1000 | Loss: 0.00002200
Iteration 35/1000 | Loss: 0.00002199
Iteration 36/1000 | Loss: 0.00002199
Iteration 37/1000 | Loss: 0.00002198
Iteration 38/1000 | Loss: 0.00002197
Iteration 39/1000 | Loss: 0.00002195
Iteration 40/1000 | Loss: 0.00002194
Iteration 41/1000 | Loss: 0.00002194
Iteration 42/1000 | Loss: 0.00002194
Iteration 43/1000 | Loss: 0.00002194
Iteration 44/1000 | Loss: 0.00002193
Iteration 45/1000 | Loss: 0.00002193
Iteration 46/1000 | Loss: 0.00002193
Iteration 47/1000 | Loss: 0.00002193
Iteration 48/1000 | Loss: 0.00002193
Iteration 49/1000 | Loss: 0.00002193
Iteration 50/1000 | Loss: 0.00002192
Iteration 51/1000 | Loss: 0.00002192
Iteration 52/1000 | Loss: 0.00002192
Iteration 53/1000 | Loss: 0.00002192
Iteration 54/1000 | Loss: 0.00002192
Iteration 55/1000 | Loss: 0.00002191
Iteration 56/1000 | Loss: 0.00002190
Iteration 57/1000 | Loss: 0.00002189
Iteration 58/1000 | Loss: 0.00002186
Iteration 59/1000 | Loss: 0.00002186
Iteration 60/1000 | Loss: 0.00002185
Iteration 61/1000 | Loss: 0.00002184
Iteration 62/1000 | Loss: 0.00002183
Iteration 63/1000 | Loss: 0.00002183
Iteration 64/1000 | Loss: 0.00002183
Iteration 65/1000 | Loss: 0.00002183
Iteration 66/1000 | Loss: 0.00002183
Iteration 67/1000 | Loss: 0.00002183
Iteration 68/1000 | Loss: 0.00002183
Iteration 69/1000 | Loss: 0.00002183
Iteration 70/1000 | Loss: 0.00002183
Iteration 71/1000 | Loss: 0.00002183
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 71. Stopping optimization.
Last 5 losses: [2.1830010155099444e-05, 2.1830010155099444e-05, 2.1830010155099444e-05, 2.1830010155099444e-05, 2.1830010155099444e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1830010155099444e-05

Optimization complete. Final v2v error: 3.8105239868164062 mm

Highest mean error: 4.081676483154297 mm for frame 82

Lowest mean error: 3.4460020065307617 mm for frame 264

Saving results

Total time: 40.45348143577576

Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=198, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 11088-11143
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00913017
Iteration 2/25 | Loss: 0.00146726
Iteration 3/25 | Loss: 0.00122646
Iteration 4/25 | Loss: 0.00120485
Iteration 5/25 | Loss: 0.00119997
Iteration 6/25 | Loss: 0.00119856
Iteration 7/25 | Loss: 0.00119852
Iteration 8/25 | Loss: 0.00119852
Iteration 9/25 | Loss: 0.00119852
Iteration 10/25 | Loss: 0.00119852
Iteration 11/25 | Loss: 0.00119852
Iteration 12/25 | Loss: 0.00119852
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011985189048573375, 0.0011985189048573375, 0.0011985189048573375, 0.0011985189048573375, 0.0011985189048573375]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011985189048573375

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.05749905
Iteration 2/25 | Loss: 0.00111591
Iteration 3/25 | Loss: 0.00111590
Iteration 4/25 | Loss: 0.00111590
Iteration 5/25 | Loss: 0.00111590
Iteration 6/25 | Loss: 0.00111590
Iteration 7/25 | Loss: 0.00111590
Iteration 8/25 | Loss: 0.00111590
Iteration 9/25 | Loss: 0.00111590
Iteration 10/25 | Loss: 0.00111590
Iteration 11/25 | Loss: 0.00111590
Iteration 12/25 | Loss: 0.00111590
Iteration 13/25 | Loss: 0.00111590
Iteration 14/25 | Loss: 0.00111590
Iteration 15/25 | Loss: 0.00111590
Iteration 16/25 | Loss: 0.00111590
Iteration 17/25 | Loss: 0.00111590
Iteration 18/25 | Loss: 0.00111590
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00111590011510998, 0.00111590011510998, 0.00111590011510998, 0.00111590011510998, 0.00111590011510998]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00111590011510998

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00111590
Iteration 2/1000 | Loss: 0.00005861
Iteration 3/1000 | Loss: 0.00004115
Iteration 4/1000 | Loss: 0.00003725
Iteration 5/1000 | Loss: 0.00003470
Iteration 6/1000 | Loss: 0.00003370
Iteration 7/1000 | Loss: 0.00003296
Iteration 8/1000 | Loss: 0.00003266
Iteration 9/1000 | Loss: 0.00003218
Iteration 10/1000 | Loss: 0.00003199
Iteration 11/1000 | Loss: 0.00003192
Iteration 12/1000 | Loss: 0.00003189
Iteration 13/1000 | Loss: 0.00003174
Iteration 14/1000 | Loss: 0.00003172
Iteration 15/1000 | Loss: 0.00003171
Iteration 16/1000 | Loss: 0.00003171
Iteration 17/1000 | Loss: 0.00003168
Iteration 18/1000 | Loss: 0.00003167
Iteration 19/1000 | Loss: 0.00003167
Iteration 20/1000 | Loss: 0.00003167
Iteration 21/1000 | Loss: 0.00003166
Iteration 22/1000 | Loss: 0.00003166
Iteration 23/1000 | Loss: 0.00003164
Iteration 24/1000 | Loss: 0.00003164
Iteration 25/1000 | Loss: 0.00003164
Iteration 26/1000 | Loss: 0.00003164
Iteration 27/1000 | Loss: 0.00003164
Iteration 28/1000 | Loss: 0.00003164
Iteration 29/1000 | Loss: 0.00003164
Iteration 30/1000 | Loss: 0.00003164
Iteration 31/1000 | Loss: 0.00003163
Iteration 32/1000 | Loss: 0.00003160
Iteration 33/1000 | Loss: 0.00003160
Iteration 34/1000 | Loss: 0.00003160
Iteration 35/1000 | Loss: 0.00003160
Iteration 36/1000 | Loss: 0.00003160
Iteration 37/1000 | Loss: 0.00003160
Iteration 38/1000 | Loss: 0.00003160
Iteration 39/1000 | Loss: 0.00003159
Iteration 40/1000 | Loss: 0.00003159
Iteration 41/1000 | Loss: 0.00003159
Iteration 42/1000 | Loss: 0.00003159
Iteration 43/1000 | Loss: 0.00003156
Iteration 44/1000 | Loss: 0.00003156
Iteration 45/1000 | Loss: 0.00003156
Iteration 46/1000 | Loss: 0.00003156
Iteration 47/1000 | Loss: 0.00003156
Iteration 48/1000 | Loss: 0.00003156
Iteration 49/1000 | Loss: 0.00003155
Iteration 50/1000 | Loss: 0.00003155
Iteration 51/1000 | Loss: 0.00003155
Iteration 52/1000 | Loss: 0.00003154
Iteration 53/1000 | Loss: 0.00003154
Iteration 54/1000 | Loss: 0.00003154
Iteration 55/1000 | Loss: 0.00003153
Iteration 56/1000 | Loss: 0.00003153
Iteration 57/1000 | Loss: 0.00003153
Iteration 58/1000 | Loss: 0.00003152
Iteration 59/1000 | Loss: 0.00003152
Iteration 60/1000 | Loss: 0.00003152
Iteration 61/1000 | Loss: 0.00003152
Iteration 62/1000 | Loss: 0.00003152
Iteration 63/1000 | Loss: 0.00003152
Iteration 64/1000 | Loss: 0.00003152
Iteration 65/1000 | Loss: 0.00003152
Iteration 66/1000 | Loss: 0.00003152
Iteration 67/1000 | Loss: 0.00003152
Iteration 68/1000 | Loss: 0.00003152
Iteration 69/1000 | Loss: 0.00003152
Iteration 70/1000 | Loss: 0.00003152
Iteration 71/1000 | Loss: 0.00003151
Iteration 72/1000 | Loss: 0.00003151
Iteration 73/1000 | Loss: 0.00003151
Iteration 74/1000 | Loss: 0.00003151
Iteration 75/1000 | Loss: 0.00003151
Iteration 76/1000 | Loss: 0.00003151
Iteration 77/1000 | Loss: 0.00003151
Iteration 78/1000 | Loss: 0.00003151
Iteration 79/1000 | Loss: 0.00003151
Iteration 80/1000 | Loss: 0.00003151
Iteration 81/1000 | Loss: 0.00003151
Iteration 82/1000 | Loss: 0.00003151
Iteration 83/1000 | Loss: 0.00003151
Iteration 84/1000 | Loss: 0.00003151
Iteration 85/1000 | Loss: 0.00003150
Iteration 86/1000 | Loss: 0.00003150
Iteration 87/1000 | Loss: 0.00003150
Iteration 88/1000 | Loss: 0.00003149
Iteration 89/1000 | Loss: 0.00003149
Iteration 90/1000 | Loss: 0.00003149
Iteration 91/1000 | Loss: 0.00003148
Iteration 92/1000 | Loss: 0.00003148
Iteration 93/1000 | Loss: 0.00003148
Iteration 94/1000 | Loss: 0.00003148
Iteration 95/1000 | Loss: 0.00003148
Iteration 96/1000 | Loss: 0.00003147
Iteration 97/1000 | Loss: 0.00003147
Iteration 98/1000 | Loss: 0.00003147
Iteration 99/1000 | Loss: 0.00003147
Iteration 100/1000 | Loss: 0.00003147
Iteration 101/1000 | Loss: 0.00003146
Iteration 102/1000 | Loss: 0.00003146
Iteration 103/1000 | Loss: 0.00003146
Iteration 104/1000 | Loss: 0.00003146
Iteration 105/1000 | Loss: 0.00003146
Iteration 106/1000 | Loss: 0.00003146
Iteration 107/1000 | Loss: 0.00003146
Iteration 108/1000 | Loss: 0.00003146
Iteration 109/1000 | Loss: 0.00003146
Iteration 110/1000 | Loss: 0.00003146
Iteration 111/1000 | Loss: 0.00003146
Iteration 112/1000 | Loss: 0.00003146
Iteration 113/1000 | Loss: 0.00003146
Iteration 114/1000 | Loss: 0.00003146
Iteration 115/1000 | Loss: 0.00003146
Iteration 116/1000 | Loss: 0.00003146
Iteration 117/1000 | Loss: 0.00003146
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [3.14624558086507e-05, 3.14624558086507e-05, 3.14624558086507e-05, 3.14624558086507e-05, 3.14624558086507e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.14624558086507e-05

Optimization complete. Final v2v error: 4.7707695960998535 mm

Highest mean error: 4.964790344238281 mm for frame 14

Lowest mean error: 4.444521427154541 mm for frame 77

Saving results

Total time: 35.58928608894348
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435269
Iteration 2/25 | Loss: 0.00121895
Iteration 3/25 | Loss: 0.00111933
Iteration 4/25 | Loss: 0.00110459
Iteration 5/25 | Loss: 0.00109955
Iteration 6/25 | Loss: 0.00109830
Iteration 7/25 | Loss: 0.00109797
Iteration 8/25 | Loss: 0.00109797
Iteration 9/25 | Loss: 0.00109797
Iteration 10/25 | Loss: 0.00109797
Iteration 11/25 | Loss: 0.00109797
Iteration 12/25 | Loss: 0.00109797
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010979712242260575, 0.0010979712242260575, 0.0010979712242260575, 0.0010979712242260575, 0.0010979712242260575]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010979712242260575

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.96067774
Iteration 2/25 | Loss: 0.00114577
Iteration 3/25 | Loss: 0.00114576
Iteration 4/25 | Loss: 0.00114576
Iteration 5/25 | Loss: 0.00114576
Iteration 6/25 | Loss: 0.00114576
Iteration 7/25 | Loss: 0.00114576
Iteration 8/25 | Loss: 0.00114576
Iteration 9/25 | Loss: 0.00114576
Iteration 10/25 | Loss: 0.00114576
Iteration 11/25 | Loss: 0.00114576
Iteration 12/25 | Loss: 0.00114576
Iteration 13/25 | Loss: 0.00114576
Iteration 14/25 | Loss: 0.00114576
Iteration 15/25 | Loss: 0.00114576
Iteration 16/25 | Loss: 0.00114576
Iteration 17/25 | Loss: 0.00114576
Iteration 18/25 | Loss: 0.00114576
Iteration 19/25 | Loss: 0.00114576
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.001145761925727129, 0.001145761925727129, 0.001145761925727129, 0.001145761925727129, 0.001145761925727129]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001145761925727129

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00114576
Iteration 2/1000 | Loss: 0.00003529
Iteration 3/1000 | Loss: 0.00002651
Iteration 4/1000 | Loss: 0.00002420
Iteration 5/1000 | Loss: 0.00002288
Iteration 6/1000 | Loss: 0.00002226
Iteration 7/1000 | Loss: 0.00002183
Iteration 8/1000 | Loss: 0.00002145
Iteration 9/1000 | Loss: 0.00002126
Iteration 10/1000 | Loss: 0.00002112
Iteration 11/1000 | Loss: 0.00002106
Iteration 12/1000 | Loss: 0.00002104
Iteration 13/1000 | Loss: 0.00002104
Iteration 14/1000 | Loss: 0.00002104
Iteration 15/1000 | Loss: 0.00002104
Iteration 16/1000 | Loss: 0.00002103
Iteration 17/1000 | Loss: 0.00002102
Iteration 18/1000 | Loss: 0.00002101
Iteration 19/1000 | Loss: 0.00002101
Iteration 20/1000 | Loss: 0.00002100
Iteration 21/1000 | Loss: 0.00002100
Iteration 22/1000 | Loss: 0.00002100
Iteration 23/1000 | Loss: 0.00002100
Iteration 24/1000 | Loss: 0.00002099
Iteration 25/1000 | Loss: 0.00002099
Iteration 26/1000 | Loss: 0.00002099
Iteration 27/1000 | Loss: 0.00002099
Iteration 28/1000 | Loss: 0.00002098
Iteration 29/1000 | Loss: 0.00002097
Iteration 30/1000 | Loss: 0.00002097
Iteration 31/1000 | Loss: 0.00002097
Iteration 32/1000 | Loss: 0.00002097
Iteration 33/1000 | Loss: 0.00002096
Iteration 34/1000 | Loss: 0.00002096
Iteration 35/1000 | Loss: 0.00002096
Iteration 36/1000 | Loss: 0.00002096
Iteration 37/1000 | Loss: 0.00002096
Iteration 38/1000 | Loss: 0.00002096
Iteration 39/1000 | Loss: 0.00002096
Iteration 40/1000 | Loss: 0.00002096
Iteration 41/1000 | Loss: 0.00002095
Iteration 42/1000 | Loss: 0.00002095
Iteration 43/1000 | Loss: 0.00002095
Iteration 44/1000 | Loss: 0.00002095
Iteration 45/1000 | Loss: 0.00002095
Iteration 46/1000 | Loss: 0.00002094
Iteration 47/1000 | Loss: 0.00002094
Iteration 48/1000 | Loss: 0.00002094
Iteration 49/1000 | Loss: 0.00002094
Iteration 50/1000 | Loss: 0.00002094
Iteration 51/1000 | Loss: 0.00002094
Iteration 52/1000 | Loss: 0.00002094
Iteration 53/1000 | Loss: 0.00002094
Iteration 54/1000 | Loss: 0.00002093
Iteration 55/1000 | Loss: 0.00002093
Iteration 56/1000 | Loss: 0.00002093
Iteration 57/1000 | Loss: 0.00002093
Iteration 58/1000 | Loss: 0.00002093
Iteration 59/1000 | Loss: 0.00002093
Iteration 60/1000 | Loss: 0.00002092
Iteration 61/1000 | Loss: 0.00002092
Iteration 62/1000 | Loss: 0.00002092
Iteration 63/1000 | Loss: 0.00002092
Iteration 64/1000 | Loss: 0.00002092
Iteration 65/1000 | Loss: 0.00002092
Iteration 66/1000 | Loss: 0.00002091
Iteration 67/1000 | Loss: 0.00002091
Iteration 68/1000 | Loss: 0.00002091
Iteration 69/1000 | Loss: 0.00002091
Iteration 70/1000 | Loss: 0.00002090
Iteration 71/1000 | Loss: 0.00002090
Iteration 72/1000 | Loss: 0.00002090
Iteration 73/1000 | Loss: 0.00002090
Iteration 74/1000 | Loss: 0.00002090
Iteration 75/1000 | Loss: 0.00002089
Iteration 76/1000 | Loss: 0.00002089
Iteration 77/1000 | Loss: 0.00002089
Iteration 78/1000 | Loss: 0.00002089
Iteration 79/1000 | Loss: 0.00002089
Iteration 80/1000 | Loss: 0.00002089
Iteration 81/1000 | Loss: 0.00002089
Iteration 82/1000 | Loss: 0.00002089
Iteration 83/1000 | Loss: 0.00002089
Iteration 84/1000 | Loss: 0.00002089
Iteration 85/1000 | Loss: 0.00002089
Iteration 86/1000 | Loss: 0.00002089
Iteration 87/1000 | Loss: 0.00002089
Iteration 88/1000 | Loss: 0.00002089
Iteration 89/1000 | Loss: 0.00002089
Iteration 90/1000 | Loss: 0.00002089
Iteration 91/1000 | Loss: 0.00002089
Iteration 92/1000 | Loss: 0.00002089
Iteration 93/1000 | Loss: 0.00002088
Iteration 94/1000 | Loss: 0.00002088
Iteration 95/1000 | Loss: 0.00002088
Iteration 96/1000 | Loss: 0.00002088
Iteration 97/1000 | Loss: 0.00002088
Iteration 98/1000 | Loss: 0.00002088
Iteration 99/1000 | Loss: 0.00002088
Iteration 100/1000 | Loss: 0.00002088
Iteration 101/1000 | Loss: 0.00002087
Iteration 102/1000 | Loss: 0.00002087
Iteration 103/1000 | Loss: 0.00002087
Iteration 104/1000 | Loss: 0.00002087
Iteration 105/1000 | Loss: 0.00002087
Iteration 106/1000 | Loss: 0.00002087
Iteration 107/1000 | Loss: 0.00002087
Iteration 108/1000 | Loss: 0.00002086
Iteration 109/1000 | Loss: 0.00002086
Iteration 110/1000 | Loss: 0.00002086
Iteration 111/1000 | Loss: 0.00002086
Iteration 112/1000 | Loss: 0.00002086
Iteration 113/1000 | Loss: 0.00002086
Iteration 114/1000 | Loss: 0.00002086
Iteration 115/1000 | Loss: 0.00002086
Iteration 116/1000 | Loss: 0.00002086
Iteration 117/1000 | Loss: 0.00002086
Iteration 118/1000 | Loss: 0.00002086
Iteration 119/1000 | Loss: 0.00002086
Iteration 120/1000 | Loss: 0.00002086
Iteration 121/1000 | Loss: 0.00002086
Iteration 122/1000 | Loss: 0.00002085
Iteration 123/1000 | Loss: 0.00002085
Iteration 124/1000 | Loss: 0.00002085
Iteration 125/1000 | Loss: 0.00002085
Iteration 126/1000 | Loss: 0.00002085
Iteration 127/1000 | Loss: 0.00002085
Iteration 128/1000 | Loss: 0.00002085
Iteration 129/1000 | Loss: 0.00002085
Iteration 130/1000 | Loss: 0.00002084
Iteration 131/1000 | Loss: 0.00002084
Iteration 132/1000 | Loss: 0.00002084
Iteration 133/1000 | Loss: 0.00002084
Iteration 134/1000 | Loss: 0.00002084
Iteration 135/1000 | Loss: 0.00002084
Iteration 136/1000 | Loss: 0.00002084
Iteration 137/1000 | Loss: 0.00002084
Iteration 138/1000 | Loss: 0.00002084
Iteration 139/1000 | Loss: 0.00002084
Iteration 140/1000 | Loss: 0.00002084
Iteration 141/1000 | Loss: 0.00002083
Iteration 142/1000 | Loss: 0.00002083
Iteration 143/1000 | Loss: 0.00002083
Iteration 144/1000 | Loss: 0.00002083
Iteration 145/1000 | Loss: 0.00002083
Iteration 146/1000 | Loss: 0.00002083
Iteration 147/1000 | Loss: 0.00002083
Iteration 148/1000 | Loss: 0.00002083
Iteration 149/1000 | Loss: 0.00002083
Iteration 150/1000 | Loss: 0.00002083
Iteration 151/1000 | Loss: 0.00002082
Iteration 152/1000 | Loss: 0.00002082
Iteration 153/1000 | Loss: 0.00002082
Iteration 154/1000 | Loss: 0.00002082
Iteration 155/1000 | Loss: 0.00002082
Iteration 156/1000 | Loss: 0.00002082
Iteration 157/1000 | Loss: 0.00002082
Iteration 158/1000 | Loss: 0.00002082
Iteration 159/1000 | Loss: 0.00002082
Iteration 160/1000 | Loss: 0.00002082
Iteration 161/1000 | Loss: 0.00002082
Iteration 162/1000 | Loss: 0.00002081
Iteration 163/1000 | Loss: 0.00002081
Iteration 164/1000 | Loss: 0.00002081
Iteration 165/1000 | Loss: 0.00002081
Iteration 166/1000 | Loss: 0.00002081
Iteration 167/1000 | Loss: 0.00002081
Iteration 168/1000 | Loss: 0.00002081
Iteration 169/1000 | Loss: 0.00002081
Iteration 170/1000 | Loss: 0.00002081
Iteration 171/1000 | Loss: 0.00002081
Iteration 172/1000 | Loss: 0.00002081
Iteration 173/1000 | Loss: 0.00002081
Iteration 174/1000 | Loss: 0.00002081
Iteration 175/1000 | Loss: 0.00002081
Iteration 176/1000 | Loss: 0.00002081
Iteration 177/1000 | Loss: 0.00002081
Iteration 178/1000 | Loss: 0.00002081
Iteration 179/1000 | Loss: 0.00002081
Iteration 180/1000 | Loss: 0.00002081
Iteration 181/1000 | Loss: 0.00002081
Iteration 182/1000 | Loss: 0.00002081
Iteration 183/1000 | Loss: 0.00002081
Iteration 184/1000 | Loss: 0.00002081
Iteration 185/1000 | Loss: 0.00002081
Iteration 186/1000 | Loss: 0.00002081
Iteration 187/1000 | Loss: 0.00002081
Iteration 188/1000 | Loss: 0.00002081
Iteration 189/1000 | Loss: 0.00002081
Iteration 190/1000 | Loss: 0.00002081
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 190. Stopping optimization.
Last 5 losses: [2.08133442356484e-05, 2.08133442356484e-05, 2.08133442356484e-05, 2.08133442356484e-05, 2.08133442356484e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.08133442356484e-05

Optimization complete. Final v2v error: 3.8409247398376465 mm

Highest mean error: 4.360615253448486 mm for frame 23

Lowest mean error: 3.517303466796875 mm for frame 95

Saving results

Total time: 35.36485433578491
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01115125
Iteration 2/25 | Loss: 0.00330948
Iteration 3/25 | Loss: 0.00151204
Iteration 4/25 | Loss: 0.00129916
Iteration 5/25 | Loss: 0.00124108
Iteration 6/25 | Loss: 0.00125227
Iteration 7/25 | Loss: 0.00123735
Iteration 8/25 | Loss: 0.00119894
Iteration 9/25 | Loss: 0.00117534
Iteration 10/25 | Loss: 0.00114866
Iteration 11/25 | Loss: 0.00113586
Iteration 12/25 | Loss: 0.00112166
Iteration 13/25 | Loss: 0.00111650
Iteration 14/25 | Loss: 0.00111028
Iteration 15/25 | Loss: 0.00110969
Iteration 16/25 | Loss: 0.00111328
Iteration 17/25 | Loss: 0.00111484
Iteration 18/25 | Loss: 0.00111320
Iteration 19/25 | Loss: 0.00111153
Iteration 20/25 | Loss: 0.00110964
Iteration 21/25 | Loss: 0.00111268
Iteration 22/25 | Loss: 0.00111178
Iteration 23/25 | Loss: 0.00110775
Iteration 24/25 | Loss: 0.00110664
Iteration 25/25 | Loss: 0.00110827

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55732191
Iteration 2/25 | Loss: 0.00113799
Iteration 3/25 | Loss: 0.00113799
Iteration 4/25 | Loss: 0.00113799
Iteration 5/25 | Loss: 0.00113799
Iteration 6/25 | Loss: 0.00113799
Iteration 7/25 | Loss: 0.00113799
Iteration 8/25 | Loss: 0.00113799
Iteration 9/25 | Loss: 0.00113799
Iteration 10/25 | Loss: 0.00113799
Iteration 11/25 | Loss: 0.00113799
Iteration 12/25 | Loss: 0.00113799
Iteration 13/25 | Loss: 0.00113799
Iteration 14/25 | Loss: 0.00113799
Iteration 15/25 | Loss: 0.00113799
Iteration 16/25 | Loss: 0.00113799
Iteration 17/25 | Loss: 0.00113799
Iteration 18/25 | Loss: 0.00113799
Iteration 19/25 | Loss: 0.00113799
Iteration 20/25 | Loss: 0.00113799
Iteration 21/25 | Loss: 0.00113799
Iteration 22/25 | Loss: 0.00113799
Iteration 23/25 | Loss: 0.00113799
Iteration 24/25 | Loss: 0.00113799
Iteration 25/25 | Loss: 0.00113799

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00113799
Iteration 2/1000 | Loss: 0.00032172
Iteration 3/1000 | Loss: 0.00005162
Iteration 4/1000 | Loss: 0.00034911
Iteration 5/1000 | Loss: 0.00005929
Iteration 6/1000 | Loss: 0.00005556
Iteration 7/1000 | Loss: 0.00006087
Iteration 8/1000 | Loss: 0.00015759
Iteration 9/1000 | Loss: 0.00014375
Iteration 10/1000 | Loss: 0.00012132
Iteration 11/1000 | Loss: 0.00027274
Iteration 12/1000 | Loss: 0.00004897
Iteration 13/1000 | Loss: 0.00004512
Iteration 14/1000 | Loss: 0.00005875
Iteration 15/1000 | Loss: 0.00006589
Iteration 16/1000 | Loss: 0.00003688
Iteration 17/1000 | Loss: 0.00003609
Iteration 18/1000 | Loss: 0.00005302
Iteration 19/1000 | Loss: 0.00004506
Iteration 20/1000 | Loss: 0.00003751
Iteration 21/1000 | Loss: 0.00003082
Iteration 22/1000 | Loss: 0.00002658
Iteration 23/1000 | Loss: 0.00002555
Iteration 24/1000 | Loss: 0.00002479
Iteration 25/1000 | Loss: 0.00002440
Iteration 26/1000 | Loss: 0.00002415
Iteration 27/1000 | Loss: 0.00002398
Iteration 28/1000 | Loss: 0.00002390
Iteration 29/1000 | Loss: 0.00002388
Iteration 30/1000 | Loss: 0.00002388
Iteration 31/1000 | Loss: 0.00002387
Iteration 32/1000 | Loss: 0.00002387
Iteration 33/1000 | Loss: 0.00002386
Iteration 34/1000 | Loss: 0.00002386
Iteration 35/1000 | Loss: 0.00002385
Iteration 36/1000 | Loss: 0.00002385
Iteration 37/1000 | Loss: 0.00002384
Iteration 38/1000 | Loss: 0.00002383
Iteration 39/1000 | Loss: 0.00002382
Iteration 40/1000 | Loss: 0.00002381
Iteration 41/1000 | Loss: 0.00002380
Iteration 42/1000 | Loss: 0.00002380
Iteration 43/1000 | Loss: 0.00002380
Iteration 44/1000 | Loss: 0.00002379
Iteration 45/1000 | Loss: 0.00002379
Iteration 46/1000 | Loss: 0.00002379
Iteration 47/1000 | Loss: 0.00002378
Iteration 48/1000 | Loss: 0.00002378
Iteration 49/1000 | Loss: 0.00002377
Iteration 50/1000 | Loss: 0.00002376
Iteration 51/1000 | Loss: 0.00002376
Iteration 52/1000 | Loss: 0.00002376
Iteration 53/1000 | Loss: 0.00002375
Iteration 54/1000 | Loss: 0.00002375
Iteration 55/1000 | Loss: 0.00002374
Iteration 56/1000 | Loss: 0.00002373
Iteration 57/1000 | Loss: 0.00002373
Iteration 58/1000 | Loss: 0.00002373
Iteration 59/1000 | Loss: 0.00002373
Iteration 60/1000 | Loss: 0.00002373
Iteration 61/1000 | Loss: 0.00002373
Iteration 62/1000 | Loss: 0.00017337
Iteration 63/1000 | Loss: 0.00017337
Iteration 64/1000 | Loss: 0.00003432
Iteration 65/1000 | Loss: 0.00002856
Iteration 66/1000 | Loss: 0.00002702
Iteration 67/1000 | Loss: 0.00002589
Iteration 68/1000 | Loss: 0.00002541
Iteration 69/1000 | Loss: 0.00002507
Iteration 70/1000 | Loss: 0.00002480
Iteration 71/1000 | Loss: 0.00019359
Iteration 72/1000 | Loss: 0.00003687
Iteration 73/1000 | Loss: 0.00018259
Iteration 74/1000 | Loss: 0.00022123
Iteration 75/1000 | Loss: 0.00015399
Iteration 76/1000 | Loss: 0.00018644
Iteration 77/1000 | Loss: 0.00015262
Iteration 78/1000 | Loss: 0.00018360
Iteration 79/1000 | Loss: 0.00012991
Iteration 80/1000 | Loss: 0.00012470
Iteration 81/1000 | Loss: 0.00014471
Iteration 82/1000 | Loss: 0.00019944
Iteration 83/1000 | Loss: 0.00013931
Iteration 84/1000 | Loss: 0.00022325
Iteration 85/1000 | Loss: 0.00014523
Iteration 86/1000 | Loss: 0.00011456
Iteration 87/1000 | Loss: 0.00017883
Iteration 88/1000 | Loss: 0.00011407
Iteration 89/1000 | Loss: 0.00013806
Iteration 90/1000 | Loss: 0.00010350
Iteration 91/1000 | Loss: 0.00013902
Iteration 92/1000 | Loss: 0.00008659
Iteration 93/1000 | Loss: 0.00009996
Iteration 94/1000 | Loss: 0.00003210
Iteration 95/1000 | Loss: 0.00002613
Iteration 96/1000 | Loss: 0.00002527
Iteration 97/1000 | Loss: 0.00009177
Iteration 98/1000 | Loss: 0.00002769
Iteration 99/1000 | Loss: 0.00013043
Iteration 100/1000 | Loss: 0.00002728
Iteration 101/1000 | Loss: 0.00002644
Iteration 102/1000 | Loss: 0.00008609
Iteration 103/1000 | Loss: 0.00002623
Iteration 104/1000 | Loss: 0.00002523
Iteration 105/1000 | Loss: 0.00002498
Iteration 106/1000 | Loss: 0.00002490
Iteration 107/1000 | Loss: 0.00002490
Iteration 108/1000 | Loss: 0.00018911
Iteration 109/1000 | Loss: 0.00004464
Iteration 110/1000 | Loss: 0.00002594
Iteration 111/1000 | Loss: 0.00002439
Iteration 112/1000 | Loss: 0.00002399
Iteration 113/1000 | Loss: 0.00002381
Iteration 114/1000 | Loss: 0.00002380
Iteration 115/1000 | Loss: 0.00002377
Iteration 116/1000 | Loss: 0.00002373
Iteration 117/1000 | Loss: 0.00002372
Iteration 118/1000 | Loss: 0.00002372
Iteration 119/1000 | Loss: 0.00002372
Iteration 120/1000 | Loss: 0.00002371
Iteration 121/1000 | Loss: 0.00002371
Iteration 122/1000 | Loss: 0.00002371
Iteration 123/1000 | Loss: 0.00002370
Iteration 124/1000 | Loss: 0.00002370
Iteration 125/1000 | Loss: 0.00002370
Iteration 126/1000 | Loss: 0.00002370
Iteration 127/1000 | Loss: 0.00002370
Iteration 128/1000 | Loss: 0.00002369
Iteration 129/1000 | Loss: 0.00002369
Iteration 130/1000 | Loss: 0.00002369
Iteration 131/1000 | Loss: 0.00002369
Iteration 132/1000 | Loss: 0.00002369
Iteration 133/1000 | Loss: 0.00002369
Iteration 134/1000 | Loss: 0.00002369
Iteration 135/1000 | Loss: 0.00002369
Iteration 136/1000 | Loss: 0.00002368
Iteration 137/1000 | Loss: 0.00002368
Iteration 138/1000 | Loss: 0.00002368
Iteration 139/1000 | Loss: 0.00002368
Iteration 140/1000 | Loss: 0.00002368
Iteration 141/1000 | Loss: 0.00002368
Iteration 142/1000 | Loss: 0.00002368
Iteration 143/1000 | Loss: 0.00002368
Iteration 144/1000 | Loss: 0.00002368
Iteration 145/1000 | Loss: 0.00002368
Iteration 146/1000 | Loss: 0.00002368
Iteration 147/1000 | Loss: 0.00002368
Iteration 148/1000 | Loss: 0.00002367
Iteration 149/1000 | Loss: 0.00002367
Iteration 150/1000 | Loss: 0.00002367
Iteration 151/1000 | Loss: 0.00002367
Iteration 152/1000 | Loss: 0.00002367
Iteration 153/1000 | Loss: 0.00002367
Iteration 154/1000 | Loss: 0.00002367
Iteration 155/1000 | Loss: 0.00002367
Iteration 156/1000 | Loss: 0.00002367
Iteration 157/1000 | Loss: 0.00002367
Iteration 158/1000 | Loss: 0.00002366
Iteration 159/1000 | Loss: 0.00002366
Iteration 160/1000 | Loss: 0.00002366
Iteration 161/1000 | Loss: 0.00002366
Iteration 162/1000 | Loss: 0.00002366
Iteration 163/1000 | Loss: 0.00002365
Iteration 164/1000 | Loss: 0.00002365
Iteration 165/1000 | Loss: 0.00002365
Iteration 166/1000 | Loss: 0.00002365
Iteration 167/1000 | Loss: 0.00002364
Iteration 168/1000 | Loss: 0.00002364
Iteration 169/1000 | Loss: 0.00002364
Iteration 170/1000 | Loss: 0.00002364
Iteration 171/1000 | Loss: 0.00002364
Iteration 172/1000 | Loss: 0.00002364
Iteration 173/1000 | Loss: 0.00002364
Iteration 174/1000 | Loss: 0.00002364
Iteration 175/1000 | Loss: 0.00002363
Iteration 176/1000 | Loss: 0.00002363
Iteration 177/1000 | Loss: 0.00002363
Iteration 178/1000 | Loss: 0.00002363
Iteration 179/1000 | Loss: 0.00002363
Iteration 180/1000 | Loss: 0.00002363
Iteration 181/1000 | Loss: 0.00002363
Iteration 182/1000 | Loss: 0.00002363
Iteration 183/1000 | Loss: 0.00002362
Iteration 184/1000 | Loss: 0.00002362
Iteration 185/1000 | Loss: 0.00002362
Iteration 186/1000 | Loss: 0.00002362
Iteration 187/1000 | Loss: 0.00002361
Iteration 188/1000 | Loss: 0.00002361
Iteration 189/1000 | Loss: 0.00002361
Iteration 190/1000 | Loss: 0.00002361
Iteration 191/1000 | Loss: 0.00002360
Iteration 192/1000 | Loss: 0.00002360
Iteration 193/1000 | Loss: 0.00002360
Iteration 194/1000 | Loss: 0.00002360
Iteration 195/1000 | Loss: 0.00002360
Iteration 196/1000 | Loss: 0.00002360
Iteration 197/1000 | Loss: 0.00002360
Iteration 198/1000 | Loss: 0.00002359
Iteration 199/1000 | Loss: 0.00002359
Iteration 200/1000 | Loss: 0.00002359
Iteration 201/1000 | Loss: 0.00002359
Iteration 202/1000 | Loss: 0.00002359
Iteration 203/1000 | Loss: 0.00002359
Iteration 204/1000 | Loss: 0.00002359
Iteration 205/1000 | Loss: 0.00002359
Iteration 206/1000 | Loss: 0.00002359
Iteration 207/1000 | Loss: 0.00002359
Iteration 208/1000 | Loss: 0.00002359
Iteration 209/1000 | Loss: 0.00002359
Iteration 210/1000 | Loss: 0.00002359
Iteration 211/1000 | Loss: 0.00002359
Iteration 212/1000 | Loss: 0.00002359
Iteration 213/1000 | Loss: 0.00002358
Iteration 214/1000 | Loss: 0.00002358
Iteration 215/1000 | Loss: 0.00002358
Iteration 216/1000 | Loss: 0.00002358
Iteration 217/1000 | Loss: 0.00002358
Iteration 218/1000 | Loss: 0.00002358
Iteration 219/1000 | Loss: 0.00002358
Iteration 220/1000 | Loss: 0.00002358
Iteration 221/1000 | Loss: 0.00002358
Iteration 222/1000 | Loss: 0.00002358
Iteration 223/1000 | Loss: 0.00002358
Iteration 224/1000 | Loss: 0.00002358
Iteration 225/1000 | Loss: 0.00002358
Iteration 226/1000 | Loss: 0.00002358
Iteration 227/1000 | Loss: 0.00002358
Iteration 228/1000 | Loss: 0.00002358
Iteration 229/1000 | Loss: 0.00002358
Iteration 230/1000 | Loss: 0.00002358
Iteration 231/1000 | Loss: 0.00002358
Iteration 232/1000 | Loss: 0.00002358
Iteration 233/1000 | Loss: 0.00002358
Iteration 234/1000 | Loss: 0.00002358
Iteration 235/1000 | Loss: 0.00002358
Iteration 236/1000 | Loss: 0.00002358
Iteration 237/1000 | Loss: 0.00002358
Iteration 238/1000 | Loss: 0.00002358
Iteration 239/1000 | Loss: 0.00002358
Iteration 240/1000 | Loss: 0.00002358
Iteration 241/1000 | Loss: 0.00002358
Iteration 242/1000 | Loss: 0.00002358
Iteration 243/1000 | Loss: 0.00002358
Iteration 244/1000 | Loss: 0.00002358
Iteration 245/1000 | Loss: 0.00002358
Iteration 246/1000 | Loss: 0.00002358
Iteration 247/1000 | Loss: 0.00002358
Iteration 248/1000 | Loss: 0.00002358
Iteration 249/1000 | Loss: 0.00002358
Iteration 250/1000 | Loss: 0.00002358
Iteration 251/1000 | Loss: 0.00002358
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 251. Stopping optimization.
Last 5 losses: [2.3581324057886377e-05, 2.3581324057886377e-05, 2.3581324057886377e-05, 2.3581324057886377e-05, 2.3581324057886377e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3581324057886377e-05

Optimization complete. Final v2v error: 4.0896759033203125 mm

Highest mean error: 6.939639568328857 mm for frame 188

Lowest mean error: 3.89597487449646 mm for frame 238

Saving results

Total time: 189.42518544197083
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00890717
Iteration 2/25 | Loss: 0.00198595
Iteration 3/25 | Loss: 0.00135342
Iteration 4/25 | Loss: 0.00125470
Iteration 5/25 | Loss: 0.00121874
Iteration 6/25 | Loss: 0.00119160
Iteration 7/25 | Loss: 0.00117654
Iteration 8/25 | Loss: 0.00116311
Iteration 9/25 | Loss: 0.00116103
Iteration 10/25 | Loss: 0.00116052
Iteration 11/25 | Loss: 0.00116030
Iteration 12/25 | Loss: 0.00116022
Iteration 13/25 | Loss: 0.00116022
Iteration 14/25 | Loss: 0.00116022
Iteration 15/25 | Loss: 0.00116022
Iteration 16/25 | Loss: 0.00116022
Iteration 17/25 | Loss: 0.00116022
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0011602237354964018, 0.0011602237354964018, 0.0011602237354964018, 0.0011602237354964018, 0.0011602237354964018]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011602237354964018

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.71175373
Iteration 2/25 | Loss: 0.00103144
Iteration 3/25 | Loss: 0.00103141
Iteration 4/25 | Loss: 0.00103141
Iteration 5/25 | Loss: 0.00103141
Iteration 6/25 | Loss: 0.00103141
Iteration 7/25 | Loss: 0.00103141
Iteration 8/25 | Loss: 0.00103141
Iteration 9/25 | Loss: 0.00103141
Iteration 10/25 | Loss: 0.00103141
Iteration 11/25 | Loss: 0.00103141
Iteration 12/25 | Loss: 0.00103141
Iteration 13/25 | Loss: 0.00103141
Iteration 14/25 | Loss: 0.00103141
Iteration 15/25 | Loss: 0.00103141
Iteration 16/25 | Loss: 0.00103141
Iteration 17/25 | Loss: 0.00103141
Iteration 18/25 | Loss: 0.00103141
Iteration 19/25 | Loss: 0.00103141
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.001031411113217473, 0.001031411113217473, 0.001031411113217473, 0.001031411113217473, 0.001031411113217473]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001031411113217473

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00103141
Iteration 2/1000 | Loss: 0.00004930
Iteration 3/1000 | Loss: 0.00003705
Iteration 4/1000 | Loss: 0.00003246
Iteration 5/1000 | Loss: 0.00003050
Iteration 6/1000 | Loss: 0.00002926
Iteration 7/1000 | Loss: 0.00002858
Iteration 8/1000 | Loss: 0.00002812
Iteration 9/1000 | Loss: 0.00002787
Iteration 10/1000 | Loss: 0.00002766
Iteration 11/1000 | Loss: 0.00002763
Iteration 12/1000 | Loss: 0.00002759
Iteration 13/1000 | Loss: 0.00002758
Iteration 14/1000 | Loss: 0.00002753
Iteration 15/1000 | Loss: 0.00002749
Iteration 16/1000 | Loss: 0.00002746
Iteration 17/1000 | Loss: 0.00002745
Iteration 18/1000 | Loss: 0.00002745
Iteration 19/1000 | Loss: 0.00002742
Iteration 20/1000 | Loss: 0.00002741
Iteration 21/1000 | Loss: 0.00002741
Iteration 22/1000 | Loss: 0.00002740
Iteration 23/1000 | Loss: 0.00002740
Iteration 24/1000 | Loss: 0.00002739
Iteration 25/1000 | Loss: 0.00002739
Iteration 26/1000 | Loss: 0.00002738
Iteration 27/1000 | Loss: 0.00002738
Iteration 28/1000 | Loss: 0.00002737
Iteration 29/1000 | Loss: 0.00002737
Iteration 30/1000 | Loss: 0.00002737
Iteration 31/1000 | Loss: 0.00002737
Iteration 32/1000 | Loss: 0.00002737
Iteration 33/1000 | Loss: 0.00002736
Iteration 34/1000 | Loss: 0.00002736
Iteration 35/1000 | Loss: 0.00002735
Iteration 36/1000 | Loss: 0.00002734
Iteration 37/1000 | Loss: 0.00002733
Iteration 38/1000 | Loss: 0.00002733
Iteration 39/1000 | Loss: 0.00002733
Iteration 40/1000 | Loss: 0.00002733
Iteration 41/1000 | Loss: 0.00002732
Iteration 42/1000 | Loss: 0.00002732
Iteration 43/1000 | Loss: 0.00002732
Iteration 44/1000 | Loss: 0.00002732
Iteration 45/1000 | Loss: 0.00002732
Iteration 46/1000 | Loss: 0.00002731
Iteration 47/1000 | Loss: 0.00002731
Iteration 48/1000 | Loss: 0.00002730
Iteration 49/1000 | Loss: 0.00002729
Iteration 50/1000 | Loss: 0.00002729
Iteration 51/1000 | Loss: 0.00002729
Iteration 52/1000 | Loss: 0.00002729
Iteration 53/1000 | Loss: 0.00002728
Iteration 54/1000 | Loss: 0.00002728
Iteration 55/1000 | Loss: 0.00002726
Iteration 56/1000 | Loss: 0.00002726
Iteration 57/1000 | Loss: 0.00002725
Iteration 58/1000 | Loss: 0.00002725
Iteration 59/1000 | Loss: 0.00002725
Iteration 60/1000 | Loss: 0.00002724
Iteration 61/1000 | Loss: 0.00002724
Iteration 62/1000 | Loss: 0.00002723
Iteration 63/1000 | Loss: 0.00002723
Iteration 64/1000 | Loss: 0.00002723
Iteration 65/1000 | Loss: 0.00002723
Iteration 66/1000 | Loss: 0.00002723
Iteration 67/1000 | Loss: 0.00002723
Iteration 68/1000 | Loss: 0.00002723
Iteration 69/1000 | Loss: 0.00002723
Iteration 70/1000 | Loss: 0.00002723
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 70. Stopping optimization.
Last 5 losses: [2.722550925682299e-05, 2.722550925682299e-05, 2.722550925682299e-05, 2.722550925682299e-05, 2.722550925682299e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.722550925682299e-05

Optimization complete. Final v2v error: 4.3932695388793945 mm

Highest mean error: 5.732227802276611 mm for frame 188

Lowest mean error: 3.620713710784912 mm for frame 216

Saving results

Total time: 46.336976766586304
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00927572
Iteration 2/25 | Loss: 0.00122132
Iteration 3/25 | Loss: 0.00109204
Iteration 4/25 | Loss: 0.00107964
Iteration 5/25 | Loss: 0.00107576
Iteration 6/25 | Loss: 0.00107406
Iteration 7/25 | Loss: 0.00107396
Iteration 8/25 | Loss: 0.00107396
Iteration 9/25 | Loss: 0.00107396
Iteration 10/25 | Loss: 0.00107396
Iteration 11/25 | Loss: 0.00107396
Iteration 12/25 | Loss: 0.00107396
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010739631252363324, 0.0010739631252363324, 0.0010739631252363324, 0.0010739631252363324, 0.0010739631252363324]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010739631252363324

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48914242
Iteration 2/25 | Loss: 0.00097753
Iteration 3/25 | Loss: 0.00097753
Iteration 4/25 | Loss: 0.00097753
Iteration 5/25 | Loss: 0.00097753
Iteration 6/25 | Loss: 0.00097753
Iteration 7/25 | Loss: 0.00097753
Iteration 8/25 | Loss: 0.00097753
Iteration 9/25 | Loss: 0.00097753
Iteration 10/25 | Loss: 0.00097753
Iteration 11/25 | Loss: 0.00097753
Iteration 12/25 | Loss: 0.00097753
Iteration 13/25 | Loss: 0.00097753
Iteration 14/25 | Loss: 0.00097753
Iteration 15/25 | Loss: 0.00097753
Iteration 16/25 | Loss: 0.00097753
Iteration 17/25 | Loss: 0.00097753
Iteration 18/25 | Loss: 0.00097753
Iteration 19/25 | Loss: 0.00097753
Iteration 20/25 | Loss: 0.00097753
Iteration 21/25 | Loss: 0.00097753
Iteration 22/25 | Loss: 0.00097753
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0009775256039574742, 0.0009775256039574742, 0.0009775256039574742, 0.0009775256039574742, 0.0009775256039574742]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009775256039574742

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00097753
Iteration 2/1000 | Loss: 0.00003101
Iteration 3/1000 | Loss: 0.00002427
Iteration 4/1000 | Loss: 0.00002171
Iteration 5/1000 | Loss: 0.00002094
Iteration 6/1000 | Loss: 0.00002028
Iteration 7/1000 | Loss: 0.00001982
Iteration 8/1000 | Loss: 0.00001953
Iteration 9/1000 | Loss: 0.00001935
Iteration 10/1000 | Loss: 0.00001926
Iteration 11/1000 | Loss: 0.00001924
Iteration 12/1000 | Loss: 0.00001921
Iteration 13/1000 | Loss: 0.00001920
Iteration 14/1000 | Loss: 0.00001920
Iteration 15/1000 | Loss: 0.00001919
Iteration 16/1000 | Loss: 0.00001919
Iteration 17/1000 | Loss: 0.00001919
Iteration 18/1000 | Loss: 0.00001919
Iteration 19/1000 | Loss: 0.00001918
Iteration 20/1000 | Loss: 0.00001917
Iteration 21/1000 | Loss: 0.00001916
Iteration 22/1000 | Loss: 0.00001916
Iteration 23/1000 | Loss: 0.00001915
Iteration 24/1000 | Loss: 0.00001914
Iteration 25/1000 | Loss: 0.00001914
Iteration 26/1000 | Loss: 0.00001914
Iteration 27/1000 | Loss: 0.00001913
Iteration 28/1000 | Loss: 0.00001913
Iteration 29/1000 | Loss: 0.00001913
Iteration 30/1000 | Loss: 0.00001912
Iteration 31/1000 | Loss: 0.00001912
Iteration 32/1000 | Loss: 0.00001911
Iteration 33/1000 | Loss: 0.00001911
Iteration 34/1000 | Loss: 0.00001910
Iteration 35/1000 | Loss: 0.00001910
Iteration 36/1000 | Loss: 0.00001910
Iteration 37/1000 | Loss: 0.00001910
Iteration 38/1000 | Loss: 0.00001909
Iteration 39/1000 | Loss: 0.00001909
Iteration 40/1000 | Loss: 0.00001909
Iteration 41/1000 | Loss: 0.00001909
Iteration 42/1000 | Loss: 0.00001909
Iteration 43/1000 | Loss: 0.00001909
Iteration 44/1000 | Loss: 0.00001909
Iteration 45/1000 | Loss: 0.00001909
Iteration 46/1000 | Loss: 0.00001909
Iteration 47/1000 | Loss: 0.00001909
Iteration 48/1000 | Loss: 0.00001908
Iteration 49/1000 | Loss: 0.00001908
Iteration 50/1000 | Loss: 0.00001907
Iteration 51/1000 | Loss: 0.00001907
Iteration 52/1000 | Loss: 0.00001905
Iteration 53/1000 | Loss: 0.00001905
Iteration 54/1000 | Loss: 0.00001905
Iteration 55/1000 | Loss: 0.00001905
Iteration 56/1000 | Loss: 0.00001905
Iteration 57/1000 | Loss: 0.00001905
Iteration 58/1000 | Loss: 0.00001905
Iteration 59/1000 | Loss: 0.00001905
Iteration 60/1000 | Loss: 0.00001905
Iteration 61/1000 | Loss: 0.00001903
Iteration 62/1000 | Loss: 0.00001903
Iteration 63/1000 | Loss: 0.00001902
Iteration 64/1000 | Loss: 0.00001902
Iteration 65/1000 | Loss: 0.00001902
Iteration 66/1000 | Loss: 0.00001902
Iteration 67/1000 | Loss: 0.00001901
Iteration 68/1000 | Loss: 0.00001901
Iteration 69/1000 | Loss: 0.00001901
Iteration 70/1000 | Loss: 0.00001901
Iteration 71/1000 | Loss: 0.00001901
Iteration 72/1000 | Loss: 0.00001901
Iteration 73/1000 | Loss: 0.00001901
Iteration 74/1000 | Loss: 0.00001900
Iteration 75/1000 | Loss: 0.00001900
Iteration 76/1000 | Loss: 0.00001900
Iteration 77/1000 | Loss: 0.00001900
Iteration 78/1000 | Loss: 0.00001899
Iteration 79/1000 | Loss: 0.00001899
Iteration 80/1000 | Loss: 0.00001899
Iteration 81/1000 | Loss: 0.00001899
Iteration 82/1000 | Loss: 0.00001899
Iteration 83/1000 | Loss: 0.00001899
Iteration 84/1000 | Loss: 0.00001899
Iteration 85/1000 | Loss: 0.00001899
Iteration 86/1000 | Loss: 0.00001899
Iteration 87/1000 | Loss: 0.00001899
Iteration 88/1000 | Loss: 0.00001899
Iteration 89/1000 | Loss: 0.00001899
Iteration 90/1000 | Loss: 0.00001899
Iteration 91/1000 | Loss: 0.00001899
Iteration 92/1000 | Loss: 0.00001899
Iteration 93/1000 | Loss: 0.00001899
Iteration 94/1000 | Loss: 0.00001899
Iteration 95/1000 | Loss: 0.00001899
Iteration 96/1000 | Loss: 0.00001899
Iteration 97/1000 | Loss: 0.00001899
Iteration 98/1000 | Loss: 0.00001899
Iteration 99/1000 | Loss: 0.00001899
Iteration 100/1000 | Loss: 0.00001899
Iteration 101/1000 | Loss: 0.00001899
Iteration 102/1000 | Loss: 0.00001899
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.8991160686709918e-05, 1.8991160686709918e-05, 1.8991160686709918e-05, 1.8991160686709918e-05, 1.8991160686709918e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8991160686709918e-05

Optimization complete. Final v2v error: 3.755445957183838 mm

Highest mean error: 4.275733470916748 mm for frame 170

Lowest mean error: 3.340489149093628 mm for frame 83

Saving results

Total time: 30.01349639892578
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00973335
Iteration 2/25 | Loss: 0.00165649
Iteration 3/25 | Loss: 0.00133396
Iteration 4/25 | Loss: 0.00134735
Iteration 5/25 | Loss: 0.00126935
Iteration 6/25 | Loss: 0.00124666
Iteration 7/25 | Loss: 0.00123075
Iteration 8/25 | Loss: 0.00121666
Iteration 9/25 | Loss: 0.00121483
Iteration 10/25 | Loss: 0.00121278
Iteration 11/25 | Loss: 0.00121132
Iteration 12/25 | Loss: 0.00120769
Iteration 13/25 | Loss: 0.00120700
Iteration 14/25 | Loss: 0.00120718
Iteration 15/25 | Loss: 0.00120422
Iteration 16/25 | Loss: 0.00120590
Iteration 17/25 | Loss: 0.00120356
Iteration 18/25 | Loss: 0.00120143
Iteration 19/25 | Loss: 0.00120603
Iteration 20/25 | Loss: 0.00120662
Iteration 21/25 | Loss: 0.00120482
Iteration 22/25 | Loss: 0.00120486
Iteration 23/25 | Loss: 0.00120672
Iteration 24/25 | Loss: 0.00120622
Iteration 25/25 | Loss: 0.00120279

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.96581602
Iteration 2/25 | Loss: 0.00211619
Iteration 3/25 | Loss: 0.00211610
Iteration 4/25 | Loss: 0.00211610
Iteration 5/25 | Loss: 0.00211610
Iteration 6/25 | Loss: 0.00211610
Iteration 7/25 | Loss: 0.00211610
Iteration 8/25 | Loss: 0.00211610
Iteration 9/25 | Loss: 0.00211610
Iteration 10/25 | Loss: 0.00211609
Iteration 11/25 | Loss: 0.00211609
Iteration 12/25 | Loss: 0.00211609
Iteration 13/25 | Loss: 0.00211609
Iteration 14/25 | Loss: 0.00211609
Iteration 15/25 | Loss: 0.00211610
Iteration 16/25 | Loss: 0.00211610
Iteration 17/25 | Loss: 0.00211609
Iteration 18/25 | Loss: 0.00211610
Iteration 19/25 | Loss: 0.00211610
Iteration 20/25 | Loss: 0.00211610
Iteration 21/25 | Loss: 0.00211610
Iteration 22/25 | Loss: 0.00211610
Iteration 23/25 | Loss: 0.00211610
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0021160950418561697, 0.0021160950418561697, 0.0021160950418561697, 0.0021160950418561697, 0.0021160950418561697]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0021160950418561697

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00211610
Iteration 2/1000 | Loss: 0.00070204
Iteration 3/1000 | Loss: 0.00069551
Iteration 4/1000 | Loss: 0.00068911
Iteration 5/1000 | Loss: 0.00062436
Iteration 6/1000 | Loss: 0.00038856
Iteration 7/1000 | Loss: 0.00047367
Iteration 8/1000 | Loss: 0.00029384
Iteration 9/1000 | Loss: 0.00037541
Iteration 10/1000 | Loss: 0.00010276
Iteration 11/1000 | Loss: 0.00040784
Iteration 12/1000 | Loss: 0.00071118
Iteration 13/1000 | Loss: 0.00073186
Iteration 14/1000 | Loss: 0.00055963
Iteration 15/1000 | Loss: 0.00076023
Iteration 16/1000 | Loss: 0.00053761
Iteration 17/1000 | Loss: 0.00029526
Iteration 18/1000 | Loss: 0.00046602
Iteration 19/1000 | Loss: 0.00176727
Iteration 20/1000 | Loss: 0.00131369
Iteration 21/1000 | Loss: 0.00046080
Iteration 22/1000 | Loss: 0.00044648
Iteration 23/1000 | Loss: 0.00014591
Iteration 24/1000 | Loss: 0.00038679
Iteration 25/1000 | Loss: 0.00006782
Iteration 26/1000 | Loss: 0.00014059
Iteration 27/1000 | Loss: 0.00005400
Iteration 28/1000 | Loss: 0.00031901
Iteration 29/1000 | Loss: 0.00141008
Iteration 30/1000 | Loss: 0.00063294
Iteration 31/1000 | Loss: 0.00015053
Iteration 32/1000 | Loss: 0.00017631
Iteration 33/1000 | Loss: 0.00009749
Iteration 34/1000 | Loss: 0.00015743
Iteration 35/1000 | Loss: 0.00011532
Iteration 36/1000 | Loss: 0.00012032
Iteration 37/1000 | Loss: 0.00005294
Iteration 38/1000 | Loss: 0.00004660
Iteration 39/1000 | Loss: 0.00005218
Iteration 40/1000 | Loss: 0.00004515
Iteration 41/1000 | Loss: 0.00004749
Iteration 42/1000 | Loss: 0.00015500
Iteration 43/1000 | Loss: 0.00010215
Iteration 44/1000 | Loss: 0.00010914
Iteration 45/1000 | Loss: 0.00009415
Iteration 46/1000 | Loss: 0.00014131
Iteration 47/1000 | Loss: 0.00018023
Iteration 48/1000 | Loss: 0.00007045
Iteration 49/1000 | Loss: 0.00010492
Iteration 50/1000 | Loss: 0.00011109
Iteration 51/1000 | Loss: 0.00004535
Iteration 52/1000 | Loss: 0.00004174
Iteration 53/1000 | Loss: 0.00012061
Iteration 54/1000 | Loss: 0.00013140
Iteration 55/1000 | Loss: 0.00013900
Iteration 56/1000 | Loss: 0.00018084
Iteration 57/1000 | Loss: 0.00005666
Iteration 58/1000 | Loss: 0.00004533
Iteration 59/1000 | Loss: 0.00004139
Iteration 60/1000 | Loss: 0.00003980
Iteration 61/1000 | Loss: 0.00003905
Iteration 62/1000 | Loss: 0.00003833
Iteration 63/1000 | Loss: 0.00003689
Iteration 64/1000 | Loss: 0.00003532
Iteration 65/1000 | Loss: 0.00003431
Iteration 66/1000 | Loss: 0.00003376
Iteration 67/1000 | Loss: 0.00003353
Iteration 68/1000 | Loss: 0.00003335
Iteration 69/1000 | Loss: 0.00003321
Iteration 70/1000 | Loss: 0.00003319
Iteration 71/1000 | Loss: 0.00003319
Iteration 72/1000 | Loss: 0.00003315
Iteration 73/1000 | Loss: 0.00003315
Iteration 74/1000 | Loss: 0.00003315
Iteration 75/1000 | Loss: 0.00003314
Iteration 76/1000 | Loss: 0.00003312
Iteration 77/1000 | Loss: 0.00003311
Iteration 78/1000 | Loss: 0.00003311
Iteration 79/1000 | Loss: 0.00003310
Iteration 80/1000 | Loss: 0.00003309
Iteration 81/1000 | Loss: 0.00003309
Iteration 82/1000 | Loss: 0.00003308
Iteration 83/1000 | Loss: 0.00003308
Iteration 84/1000 | Loss: 0.00003307
Iteration 85/1000 | Loss: 0.00003307
Iteration 86/1000 | Loss: 0.00003307
Iteration 87/1000 | Loss: 0.00003306
Iteration 88/1000 | Loss: 0.00003302
Iteration 89/1000 | Loss: 0.00003302
Iteration 90/1000 | Loss: 0.00003298
Iteration 91/1000 | Loss: 0.00003298
Iteration 92/1000 | Loss: 0.00003297
Iteration 93/1000 | Loss: 0.00003297
Iteration 94/1000 | Loss: 0.00003296
Iteration 95/1000 | Loss: 0.00003296
Iteration 96/1000 | Loss: 0.00003295
Iteration 97/1000 | Loss: 0.00003295
Iteration 98/1000 | Loss: 0.00003295
Iteration 99/1000 | Loss: 0.00003295
Iteration 100/1000 | Loss: 0.00003294
Iteration 101/1000 | Loss: 0.00003294
Iteration 102/1000 | Loss: 0.00003294
Iteration 103/1000 | Loss: 0.00003293
Iteration 104/1000 | Loss: 0.00003293
Iteration 105/1000 | Loss: 0.00003293
Iteration 106/1000 | Loss: 0.00003292
Iteration 107/1000 | Loss: 0.00003292
Iteration 108/1000 | Loss: 0.00003292
Iteration 109/1000 | Loss: 0.00003292
Iteration 110/1000 | Loss: 0.00003292
Iteration 111/1000 | Loss: 0.00003291
Iteration 112/1000 | Loss: 0.00003291
Iteration 113/1000 | Loss: 0.00003291
Iteration 114/1000 | Loss: 0.00003291
Iteration 115/1000 | Loss: 0.00003290
Iteration 116/1000 | Loss: 0.00003290
Iteration 117/1000 | Loss: 0.00003290
Iteration 118/1000 | Loss: 0.00003289
Iteration 119/1000 | Loss: 0.00003289
Iteration 120/1000 | Loss: 0.00003289
Iteration 121/1000 | Loss: 0.00003289
Iteration 122/1000 | Loss: 0.00003289
Iteration 123/1000 | Loss: 0.00003288
Iteration 124/1000 | Loss: 0.00003288
Iteration 125/1000 | Loss: 0.00003288
Iteration 126/1000 | Loss: 0.00003287
Iteration 127/1000 | Loss: 0.00003287
Iteration 128/1000 | Loss: 0.00003287
Iteration 129/1000 | Loss: 0.00003287
Iteration 130/1000 | Loss: 0.00003287
Iteration 131/1000 | Loss: 0.00003286
Iteration 132/1000 | Loss: 0.00003286
Iteration 133/1000 | Loss: 0.00003286
Iteration 134/1000 | Loss: 0.00003286
Iteration 135/1000 | Loss: 0.00003285
Iteration 136/1000 | Loss: 0.00003285
Iteration 137/1000 | Loss: 0.00003285
Iteration 138/1000 | Loss: 0.00003285
Iteration 139/1000 | Loss: 0.00003285
Iteration 140/1000 | Loss: 0.00003285
Iteration 141/1000 | Loss: 0.00003284
Iteration 142/1000 | Loss: 0.00003284
Iteration 143/1000 | Loss: 0.00003284
Iteration 144/1000 | Loss: 0.00003283
Iteration 145/1000 | Loss: 0.00003282
Iteration 146/1000 | Loss: 0.00003282
Iteration 147/1000 | Loss: 0.00003281
Iteration 148/1000 | Loss: 0.00003280
Iteration 149/1000 | Loss: 0.00003280
Iteration 150/1000 | Loss: 0.00003279
Iteration 151/1000 | Loss: 0.00003279
Iteration 152/1000 | Loss: 0.00003279
Iteration 153/1000 | Loss: 0.00003279
Iteration 154/1000 | Loss: 0.00003279
Iteration 155/1000 | Loss: 0.00003279
Iteration 156/1000 | Loss: 0.00003278
Iteration 157/1000 | Loss: 0.00003278
Iteration 158/1000 | Loss: 0.00003278
Iteration 159/1000 | Loss: 0.00003278
Iteration 160/1000 | Loss: 0.00003278
Iteration 161/1000 | Loss: 0.00003278
Iteration 162/1000 | Loss: 0.00003277
Iteration 163/1000 | Loss: 0.00003277
Iteration 164/1000 | Loss: 0.00003277
Iteration 165/1000 | Loss: 0.00003277
Iteration 166/1000 | Loss: 0.00003277
Iteration 167/1000 | Loss: 0.00003277
Iteration 168/1000 | Loss: 0.00003277
Iteration 169/1000 | Loss: 0.00003277
Iteration 170/1000 | Loss: 0.00003277
Iteration 171/1000 | Loss: 0.00003277
Iteration 172/1000 | Loss: 0.00003277
Iteration 173/1000 | Loss: 0.00003276
Iteration 174/1000 | Loss: 0.00003276
Iteration 175/1000 | Loss: 0.00003276
Iteration 176/1000 | Loss: 0.00003276
Iteration 177/1000 | Loss: 0.00003276
Iteration 178/1000 | Loss: 0.00003276
Iteration 179/1000 | Loss: 0.00003276
Iteration 180/1000 | Loss: 0.00003275
Iteration 181/1000 | Loss: 0.00003275
Iteration 182/1000 | Loss: 0.00003275
Iteration 183/1000 | Loss: 0.00003275
Iteration 184/1000 | Loss: 0.00003275
Iteration 185/1000 | Loss: 0.00003275
Iteration 186/1000 | Loss: 0.00003275
Iteration 187/1000 | Loss: 0.00003274
Iteration 188/1000 | Loss: 0.00003274
Iteration 189/1000 | Loss: 0.00003274
Iteration 190/1000 | Loss: 0.00003274
Iteration 191/1000 | Loss: 0.00003274
Iteration 192/1000 | Loss: 0.00003274
Iteration 193/1000 | Loss: 0.00003274
Iteration 194/1000 | Loss: 0.00003274
Iteration 195/1000 | Loss: 0.00003274
Iteration 196/1000 | Loss: 0.00003274
Iteration 197/1000 | Loss: 0.00003274
Iteration 198/1000 | Loss: 0.00003273
Iteration 199/1000 | Loss: 0.00003273
Iteration 200/1000 | Loss: 0.00003272
Iteration 201/1000 | Loss: 0.00003272
Iteration 202/1000 | Loss: 0.00003272
Iteration 203/1000 | Loss: 0.00003272
Iteration 204/1000 | Loss: 0.00003272
Iteration 205/1000 | Loss: 0.00003272
Iteration 206/1000 | Loss: 0.00003272
Iteration 207/1000 | Loss: 0.00003272
Iteration 208/1000 | Loss: 0.00003272
Iteration 209/1000 | Loss: 0.00003272
Iteration 210/1000 | Loss: 0.00003272
Iteration 211/1000 | Loss: 0.00003271
Iteration 212/1000 | Loss: 0.00003271
Iteration 213/1000 | Loss: 0.00003271
Iteration 214/1000 | Loss: 0.00003271
Iteration 215/1000 | Loss: 0.00003271
Iteration 216/1000 | Loss: 0.00004414
Iteration 217/1000 | Loss: 0.00004414
Iteration 218/1000 | Loss: 0.00003682
Iteration 219/1000 | Loss: 0.00004065
Iteration 220/1000 | Loss: 0.00004371
Iteration 221/1000 | Loss: 0.00003806
Iteration 222/1000 | Loss: 0.00003268
Iteration 223/1000 | Loss: 0.00003267
Iteration 224/1000 | Loss: 0.00003267
Iteration 225/1000 | Loss: 0.00004301
Iteration 226/1000 | Loss: 0.00003477
Iteration 227/1000 | Loss: 0.00003266
Iteration 228/1000 | Loss: 0.00003266
Iteration 229/1000 | Loss: 0.00003266
Iteration 230/1000 | Loss: 0.00003266
Iteration 231/1000 | Loss: 0.00003266
Iteration 232/1000 | Loss: 0.00003266
Iteration 233/1000 | Loss: 0.00003266
Iteration 234/1000 | Loss: 0.00003266
Iteration 235/1000 | Loss: 0.00003266
Iteration 236/1000 | Loss: 0.00003266
Iteration 237/1000 | Loss: 0.00003266
Iteration 238/1000 | Loss: 0.00003266
Iteration 239/1000 | Loss: 0.00003266
Iteration 240/1000 | Loss: 0.00003266
Iteration 241/1000 | Loss: 0.00003266
Iteration 242/1000 | Loss: 0.00003266
Iteration 243/1000 | Loss: 0.00003266
Iteration 244/1000 | Loss: 0.00003266
Iteration 245/1000 | Loss: 0.00003266
Iteration 246/1000 | Loss: 0.00003266
Iteration 247/1000 | Loss: 0.00003266
Iteration 248/1000 | Loss: 0.00003266
Iteration 249/1000 | Loss: 0.00003266
Iteration 250/1000 | Loss: 0.00003266
Iteration 251/1000 | Loss: 0.00003266
Iteration 252/1000 | Loss: 0.00003266
Iteration 253/1000 | Loss: 0.00003266
Iteration 254/1000 | Loss: 0.00003266
Iteration 255/1000 | Loss: 0.00003266
Iteration 256/1000 | Loss: 0.00003266
Iteration 257/1000 | Loss: 0.00003266
Iteration 258/1000 | Loss: 0.00003266
Iteration 259/1000 | Loss: 0.00003266
Iteration 260/1000 | Loss: 0.00003266
Iteration 261/1000 | Loss: 0.00003266
Iteration 262/1000 | Loss: 0.00003266
Iteration 263/1000 | Loss: 0.00003266
Iteration 264/1000 | Loss: 0.00003266
Iteration 265/1000 | Loss: 0.00003266
Iteration 266/1000 | Loss: 0.00003266
Iteration 267/1000 | Loss: 0.00003266
Iteration 268/1000 | Loss: 0.00003266
Iteration 269/1000 | Loss: 0.00003266
Iteration 270/1000 | Loss: 0.00003266
Iteration 271/1000 | Loss: 0.00003266
Iteration 272/1000 | Loss: 0.00003266
Iteration 273/1000 | Loss: 0.00003266
Iteration 274/1000 | Loss: 0.00003266
Iteration 275/1000 | Loss: 0.00003266
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 275. Stopping optimization.
Last 5 losses: [3.265520354034379e-05, 3.265520354034379e-05, 3.265520354034379e-05, 3.265520354034379e-05, 3.265520354034379e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.265520354034379e-05

Optimization complete. Final v2v error: 4.711638927459717 mm

Highest mean error: 12.259485244750977 mm for frame 147

Lowest mean error: 3.4100654125213623 mm for frame 83

Saving results

Total time: 190.04164290428162
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00859737
Iteration 2/25 | Loss: 0.00164950
Iteration 3/25 | Loss: 0.00126765
Iteration 4/25 | Loss: 0.00119953
Iteration 5/25 | Loss: 0.00119238
Iteration 6/25 | Loss: 0.00116088
Iteration 7/25 | Loss: 0.00114893
Iteration 8/25 | Loss: 0.00114698
Iteration 9/25 | Loss: 0.00114627
Iteration 10/25 | Loss: 0.00114596
Iteration 11/25 | Loss: 0.00114582
Iteration 12/25 | Loss: 0.00114582
Iteration 13/25 | Loss: 0.00114582
Iteration 14/25 | Loss: 0.00114582
Iteration 15/25 | Loss: 0.00114582
Iteration 16/25 | Loss: 0.00114582
Iteration 17/25 | Loss: 0.00114581
Iteration 18/25 | Loss: 0.00114581
Iteration 19/25 | Loss: 0.00114581
Iteration 20/25 | Loss: 0.00114581
Iteration 21/25 | Loss: 0.00114581
Iteration 22/25 | Loss: 0.00114581
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0011458147782832384, 0.0011458147782832384, 0.0011458147782832384, 0.0011458147782832384, 0.0011458147782832384]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011458147782832384

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.70822442
Iteration 2/25 | Loss: 0.00107742
Iteration 3/25 | Loss: 0.00107741
Iteration 4/25 | Loss: 0.00107741
Iteration 5/25 | Loss: 0.00107741
Iteration 6/25 | Loss: 0.00107741
Iteration 7/25 | Loss: 0.00107741
Iteration 8/25 | Loss: 0.00107741
Iteration 9/25 | Loss: 0.00107741
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 9. Stopping optimization.
Last 5 losses: [0.0010774122783914208, 0.0010774122783914208, 0.0010774122783914208, 0.0010774122783914208, 0.0010774122783914208]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010774122783914208

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00107741
Iteration 2/1000 | Loss: 0.00004263
Iteration 3/1000 | Loss: 0.00003146
Iteration 4/1000 | Loss: 0.00002761
Iteration 5/1000 | Loss: 0.00002596
Iteration 6/1000 | Loss: 0.00002481
Iteration 7/1000 | Loss: 0.00002418
Iteration 8/1000 | Loss: 0.00002382
Iteration 9/1000 | Loss: 0.00002371
Iteration 10/1000 | Loss: 0.00002351
Iteration 11/1000 | Loss: 0.00002340
Iteration 12/1000 | Loss: 0.00002339
Iteration 13/1000 | Loss: 0.00002338
Iteration 14/1000 | Loss: 0.00002336
Iteration 15/1000 | Loss: 0.00002334
Iteration 16/1000 | Loss: 0.00002333
Iteration 17/1000 | Loss: 0.00002333
Iteration 18/1000 | Loss: 0.00002332
Iteration 19/1000 | Loss: 0.00002332
Iteration 20/1000 | Loss: 0.00002331
Iteration 21/1000 | Loss: 0.00002330
Iteration 22/1000 | Loss: 0.00002330
Iteration 23/1000 | Loss: 0.00002328
Iteration 24/1000 | Loss: 0.00002327
Iteration 25/1000 | Loss: 0.00002327
Iteration 26/1000 | Loss: 0.00002327
Iteration 27/1000 | Loss: 0.00002324
Iteration 28/1000 | Loss: 0.00002322
Iteration 29/1000 | Loss: 0.00002322
Iteration 30/1000 | Loss: 0.00002318
Iteration 31/1000 | Loss: 0.00002318
Iteration 32/1000 | Loss: 0.00002318
Iteration 33/1000 | Loss: 0.00002317
Iteration 34/1000 | Loss: 0.00002317
Iteration 35/1000 | Loss: 0.00002316
Iteration 36/1000 | Loss: 0.00002314
Iteration 37/1000 | Loss: 0.00002314
Iteration 38/1000 | Loss: 0.00002313
Iteration 39/1000 | Loss: 0.00002313
Iteration 40/1000 | Loss: 0.00002313
Iteration 41/1000 | Loss: 0.00002313
Iteration 42/1000 | Loss: 0.00002312
Iteration 43/1000 | Loss: 0.00002311
Iteration 44/1000 | Loss: 0.00002311
Iteration 45/1000 | Loss: 0.00002310
Iteration 46/1000 | Loss: 0.00002310
Iteration 47/1000 | Loss: 0.00002310
Iteration 48/1000 | Loss: 0.00002309
Iteration 49/1000 | Loss: 0.00002309
Iteration 50/1000 | Loss: 0.00002309
Iteration 51/1000 | Loss: 0.00002308
Iteration 52/1000 | Loss: 0.00002308
Iteration 53/1000 | Loss: 0.00002307
Iteration 54/1000 | Loss: 0.00002307
Iteration 55/1000 | Loss: 0.00002307
Iteration 56/1000 | Loss: 0.00002307
Iteration 57/1000 | Loss: 0.00002307
Iteration 58/1000 | Loss: 0.00002307
Iteration 59/1000 | Loss: 0.00002307
Iteration 60/1000 | Loss: 0.00002306
Iteration 61/1000 | Loss: 0.00002306
Iteration 62/1000 | Loss: 0.00002306
Iteration 63/1000 | Loss: 0.00002305
Iteration 64/1000 | Loss: 0.00002305
Iteration 65/1000 | Loss: 0.00002305
Iteration 66/1000 | Loss: 0.00002305
Iteration 67/1000 | Loss: 0.00002305
Iteration 68/1000 | Loss: 0.00002305
Iteration 69/1000 | Loss: 0.00002305
Iteration 70/1000 | Loss: 0.00002304
Iteration 71/1000 | Loss: 0.00002304
Iteration 72/1000 | Loss: 0.00002304
Iteration 73/1000 | Loss: 0.00002304
Iteration 74/1000 | Loss: 0.00002304
Iteration 75/1000 | Loss: 0.00002304
Iteration 76/1000 | Loss: 0.00002304
Iteration 77/1000 | Loss: 0.00002304
Iteration 78/1000 | Loss: 0.00002304
Iteration 79/1000 | Loss: 0.00002304
Iteration 80/1000 | Loss: 0.00002303
Iteration 81/1000 | Loss: 0.00002303
Iteration 82/1000 | Loss: 0.00002303
Iteration 83/1000 | Loss: 0.00002303
Iteration 84/1000 | Loss: 0.00002303
Iteration 85/1000 | Loss: 0.00002303
Iteration 86/1000 | Loss: 0.00002302
Iteration 87/1000 | Loss: 0.00002302
Iteration 88/1000 | Loss: 0.00002302
Iteration 89/1000 | Loss: 0.00002302
Iteration 90/1000 | Loss: 0.00002302
Iteration 91/1000 | Loss: 0.00002302
Iteration 92/1000 | Loss: 0.00002302
Iteration 93/1000 | Loss: 0.00002301
Iteration 94/1000 | Loss: 0.00002301
Iteration 95/1000 | Loss: 0.00002301
Iteration 96/1000 | Loss: 0.00002301
Iteration 97/1000 | Loss: 0.00002301
Iteration 98/1000 | Loss: 0.00002301
Iteration 99/1000 | Loss: 0.00002301
Iteration 100/1000 | Loss: 0.00002301
Iteration 101/1000 | Loss: 0.00002301
Iteration 102/1000 | Loss: 0.00002301
Iteration 103/1000 | Loss: 0.00002301
Iteration 104/1000 | Loss: 0.00002300
Iteration 105/1000 | Loss: 0.00002300
Iteration 106/1000 | Loss: 0.00002300
Iteration 107/1000 | Loss: 0.00002300
Iteration 108/1000 | Loss: 0.00002300
Iteration 109/1000 | Loss: 0.00002300
Iteration 110/1000 | Loss: 0.00002300
Iteration 111/1000 | Loss: 0.00002300
Iteration 112/1000 | Loss: 0.00002300
Iteration 113/1000 | Loss: 0.00002300
Iteration 114/1000 | Loss: 0.00002300
Iteration 115/1000 | Loss: 0.00002300
Iteration 116/1000 | Loss: 0.00002300
Iteration 117/1000 | Loss: 0.00002299
Iteration 118/1000 | Loss: 0.00002299
Iteration 119/1000 | Loss: 0.00002299
Iteration 120/1000 | Loss: 0.00002299
Iteration 121/1000 | Loss: 0.00002299
Iteration 122/1000 | Loss: 0.00002299
Iteration 123/1000 | Loss: 0.00002299
Iteration 124/1000 | Loss: 0.00002299
Iteration 125/1000 | Loss: 0.00002299
Iteration 126/1000 | Loss: 0.00002299
Iteration 127/1000 | Loss: 0.00002299
Iteration 128/1000 | Loss: 0.00002299
Iteration 129/1000 | Loss: 0.00002299
Iteration 130/1000 | Loss: 0.00002299
Iteration 131/1000 | Loss: 0.00002299
Iteration 132/1000 | Loss: 0.00002299
Iteration 133/1000 | Loss: 0.00002299
Iteration 134/1000 | Loss: 0.00002299
Iteration 135/1000 | Loss: 0.00002299
Iteration 136/1000 | Loss: 0.00002299
Iteration 137/1000 | Loss: 0.00002299
Iteration 138/1000 | Loss: 0.00002299
Iteration 139/1000 | Loss: 0.00002299
Iteration 140/1000 | Loss: 0.00002299
Iteration 141/1000 | Loss: 0.00002299
Iteration 142/1000 | Loss: 0.00002299
Iteration 143/1000 | Loss: 0.00002299
Iteration 144/1000 | Loss: 0.00002299
Iteration 145/1000 | Loss: 0.00002299
Iteration 146/1000 | Loss: 0.00002299
Iteration 147/1000 | Loss: 0.00002299
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 147. Stopping optimization.
Last 5 losses: [2.2992298909230158e-05, 2.2992298909230158e-05, 2.2992298909230158e-05, 2.2992298909230158e-05, 2.2992298909230158e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2992298909230158e-05

Optimization complete. Final v2v error: 4.040874004364014 mm

Highest mean error: 5.717967510223389 mm for frame 40

Lowest mean error: 3.3630049228668213 mm for frame 164

Saving results

Total time: 48.4991090297699
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00914586
Iteration 2/25 | Loss: 0.00118787
Iteration 3/25 | Loss: 0.00108271
Iteration 4/25 | Loss: 0.00106729
Iteration 5/25 | Loss: 0.00106472
Iteration 6/25 | Loss: 0.00106378
Iteration 7/25 | Loss: 0.00106378
Iteration 8/25 | Loss: 0.00106378
Iteration 9/25 | Loss: 0.00106378
Iteration 10/25 | Loss: 0.00106378
Iteration 11/25 | Loss: 0.00106378
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0010637784143909812, 0.0010637784143909812, 0.0010637784143909812, 0.0010637784143909812, 0.0010637784143909812]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010637784143909812

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.26764774
Iteration 2/25 | Loss: 0.00096394
Iteration 3/25 | Loss: 0.00096392
Iteration 4/25 | Loss: 0.00096392
Iteration 5/25 | Loss: 0.00096392
Iteration 6/25 | Loss: 0.00096392
Iteration 7/25 | Loss: 0.00096392
Iteration 8/25 | Loss: 0.00096392
Iteration 9/25 | Loss: 0.00096392
Iteration 10/25 | Loss: 0.00096392
Iteration 11/25 | Loss: 0.00096392
Iteration 12/25 | Loss: 0.00096392
Iteration 13/25 | Loss: 0.00096392
Iteration 14/25 | Loss: 0.00096392
Iteration 15/25 | Loss: 0.00096392
Iteration 16/25 | Loss: 0.00096392
Iteration 17/25 | Loss: 0.00096392
Iteration 18/25 | Loss: 0.00096392
Iteration 19/25 | Loss: 0.00096392
Iteration 20/25 | Loss: 0.00096392
Iteration 21/25 | Loss: 0.00096392
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0009639210184104741, 0.0009639210184104741, 0.0009639210184104741, 0.0009639210184104741, 0.0009639210184104741]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009639210184104741

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00096392
Iteration 2/1000 | Loss: 0.00003239
Iteration 3/1000 | Loss: 0.00002608
Iteration 4/1000 | Loss: 0.00002425
Iteration 5/1000 | Loss: 0.00002367
Iteration 6/1000 | Loss: 0.00002315
Iteration 7/1000 | Loss: 0.00002280
Iteration 8/1000 | Loss: 0.00002273
Iteration 9/1000 | Loss: 0.00002265
Iteration 10/1000 | Loss: 0.00002248
Iteration 11/1000 | Loss: 0.00002247
Iteration 12/1000 | Loss: 0.00002241
Iteration 13/1000 | Loss: 0.00002241
Iteration 14/1000 | Loss: 0.00002240
Iteration 15/1000 | Loss: 0.00002240
Iteration 16/1000 | Loss: 0.00002239
Iteration 17/1000 | Loss: 0.00002239
Iteration 18/1000 | Loss: 0.00002238
Iteration 19/1000 | Loss: 0.00002238
Iteration 20/1000 | Loss: 0.00002237
Iteration 21/1000 | Loss: 0.00002237
Iteration 22/1000 | Loss: 0.00002237
Iteration 23/1000 | Loss: 0.00002236
Iteration 24/1000 | Loss: 0.00002236
Iteration 25/1000 | Loss: 0.00002236
Iteration 26/1000 | Loss: 0.00002236
Iteration 27/1000 | Loss: 0.00002236
Iteration 28/1000 | Loss: 0.00002236
Iteration 29/1000 | Loss: 0.00002236
Iteration 30/1000 | Loss: 0.00002236
Iteration 31/1000 | Loss: 0.00002235
Iteration 32/1000 | Loss: 0.00002235
Iteration 33/1000 | Loss: 0.00002235
Iteration 34/1000 | Loss: 0.00002235
Iteration 35/1000 | Loss: 0.00002234
Iteration 36/1000 | Loss: 0.00002234
Iteration 37/1000 | Loss: 0.00002234
Iteration 38/1000 | Loss: 0.00002234
Iteration 39/1000 | Loss: 0.00002234
Iteration 40/1000 | Loss: 0.00002233
Iteration 41/1000 | Loss: 0.00002233
Iteration 42/1000 | Loss: 0.00002233
Iteration 43/1000 | Loss: 0.00002232
Iteration 44/1000 | Loss: 0.00002232
Iteration 45/1000 | Loss: 0.00002232
Iteration 46/1000 | Loss: 0.00002231
Iteration 47/1000 | Loss: 0.00002231
Iteration 48/1000 | Loss: 0.00002231
Iteration 49/1000 | Loss: 0.00002231
Iteration 50/1000 | Loss: 0.00002230
Iteration 51/1000 | Loss: 0.00002230
Iteration 52/1000 | Loss: 0.00002230
Iteration 53/1000 | Loss: 0.00002230
Iteration 54/1000 | Loss: 0.00002229
Iteration 55/1000 | Loss: 0.00002229
Iteration 56/1000 | Loss: 0.00002229
Iteration 57/1000 | Loss: 0.00002229
Iteration 58/1000 | Loss: 0.00002229
Iteration 59/1000 | Loss: 0.00002229
Iteration 60/1000 | Loss: 0.00002229
Iteration 61/1000 | Loss: 0.00002229
Iteration 62/1000 | Loss: 0.00002228
Iteration 63/1000 | Loss: 0.00002228
Iteration 64/1000 | Loss: 0.00002228
Iteration 65/1000 | Loss: 0.00002228
Iteration 66/1000 | Loss: 0.00002228
Iteration 67/1000 | Loss: 0.00002228
Iteration 68/1000 | Loss: 0.00002228
Iteration 69/1000 | Loss: 0.00002228
Iteration 70/1000 | Loss: 0.00002228
Iteration 71/1000 | Loss: 0.00002228
Iteration 72/1000 | Loss: 0.00002227
Iteration 73/1000 | Loss: 0.00002227
Iteration 74/1000 | Loss: 0.00002227
Iteration 75/1000 | Loss: 0.00002227
Iteration 76/1000 | Loss: 0.00002227
Iteration 77/1000 | Loss: 0.00002227
Iteration 78/1000 | Loss: 0.00002227
Iteration 79/1000 | Loss: 0.00002227
Iteration 80/1000 | Loss: 0.00002227
Iteration 81/1000 | Loss: 0.00002227
Iteration 82/1000 | Loss: 0.00002227
Iteration 83/1000 | Loss: 0.00002227
Iteration 84/1000 | Loss: 0.00002227
Iteration 85/1000 | Loss: 0.00002227
Iteration 86/1000 | Loss: 0.00002227
Iteration 87/1000 | Loss: 0.00002227
Iteration 88/1000 | Loss: 0.00002227
Iteration 89/1000 | Loss: 0.00002227
Iteration 90/1000 | Loss: 0.00002227
Iteration 91/1000 | Loss: 0.00002227
Iteration 92/1000 | Loss: 0.00002227
Iteration 93/1000 | Loss: 0.00002227
Iteration 94/1000 | Loss: 0.00002227
Iteration 95/1000 | Loss: 0.00002227
Iteration 96/1000 | Loss: 0.00002227
Iteration 97/1000 | Loss: 0.00002227
Iteration 98/1000 | Loss: 0.00002227
Iteration 99/1000 | Loss: 0.00002227
Iteration 100/1000 | Loss: 0.00002227
Iteration 101/1000 | Loss: 0.00002227
Iteration 102/1000 | Loss: 0.00002227
Iteration 103/1000 | Loss: 0.00002227
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [2.2265898223849945e-05, 2.2265898223849945e-05, 2.2265898223849945e-05, 2.2265898223849945e-05, 2.2265898223849945e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2265898223849945e-05

Optimization complete. Final v2v error: 4.037274360656738 mm

Highest mean error: 4.331528663635254 mm for frame 119

Lowest mean error: 3.6632823944091797 mm for frame 100

Saving results

Total time: 28.39513874053955
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00783661
Iteration 2/25 | Loss: 0.00171442
Iteration 3/25 | Loss: 0.00125375
Iteration 4/25 | Loss: 0.00121131
Iteration 5/25 | Loss: 0.00119886
Iteration 6/25 | Loss: 0.00120552
Iteration 7/25 | Loss: 0.00118212
Iteration 8/25 | Loss: 0.00117437
Iteration 9/25 | Loss: 0.00117264
Iteration 10/25 | Loss: 0.00117104
Iteration 11/25 | Loss: 0.00116839
Iteration 12/25 | Loss: 0.00116692
Iteration 13/25 | Loss: 0.00116621
Iteration 14/25 | Loss: 0.00116593
Iteration 15/25 | Loss: 0.00116585
Iteration 16/25 | Loss: 0.00116585
Iteration 17/25 | Loss: 0.00116585
Iteration 18/25 | Loss: 0.00116585
Iteration 19/25 | Loss: 0.00116585
Iteration 20/25 | Loss: 0.00116584
Iteration 21/25 | Loss: 0.00116584
Iteration 22/25 | Loss: 0.00116584
Iteration 23/25 | Loss: 0.00116584
Iteration 24/25 | Loss: 0.00116584
Iteration 25/25 | Loss: 0.00116584

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44065976
Iteration 2/25 | Loss: 0.00118568
Iteration 3/25 | Loss: 0.00116924
Iteration 4/25 | Loss: 0.00116924
Iteration 5/25 | Loss: 0.00116924
Iteration 6/25 | Loss: 0.00116924
Iteration 7/25 | Loss: 0.00116924
Iteration 8/25 | Loss: 0.00116924
Iteration 9/25 | Loss: 0.00116924
Iteration 10/25 | Loss: 0.00116924
Iteration 11/25 | Loss: 0.00116924
Iteration 12/25 | Loss: 0.00116924
Iteration 13/25 | Loss: 0.00116924
Iteration 14/25 | Loss: 0.00116924
Iteration 15/25 | Loss: 0.00116924
Iteration 16/25 | Loss: 0.00116924
Iteration 17/25 | Loss: 0.00116924
Iteration 18/25 | Loss: 0.00116924
Iteration 19/25 | Loss: 0.00116924
Iteration 20/25 | Loss: 0.00116924
Iteration 21/25 | Loss: 0.00116924
Iteration 22/25 | Loss: 0.00116924
Iteration 23/25 | Loss: 0.00116924
Iteration 24/25 | Loss: 0.00116924
Iteration 25/25 | Loss: 0.00116924
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0011692416155710816, 0.0011692416155710816, 0.0011692416155710816, 0.0011692416155710816, 0.0011692416155710816]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011692416155710816

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00116924
Iteration 2/1000 | Loss: 0.00005600
Iteration 3/1000 | Loss: 0.00004116
Iteration 4/1000 | Loss: 0.00003177
Iteration 5/1000 | Loss: 0.00003101
Iteration 6/1000 | Loss: 0.00005602
Iteration 7/1000 | Loss: 0.00002715
Iteration 8/1000 | Loss: 0.00002714
Iteration 9/1000 | Loss: 0.00002634
Iteration 10/1000 | Loss: 0.00002605
Iteration 11/1000 | Loss: 0.00002587
Iteration 12/1000 | Loss: 0.00004181
Iteration 13/1000 | Loss: 0.00002564
Iteration 14/1000 | Loss: 0.00002558
Iteration 15/1000 | Loss: 0.00002558
Iteration 16/1000 | Loss: 0.00002558
Iteration 17/1000 | Loss: 0.00002557
Iteration 18/1000 | Loss: 0.00002556
Iteration 19/1000 | Loss: 0.00002555
Iteration 20/1000 | Loss: 0.00002555
Iteration 21/1000 | Loss: 0.00002554
Iteration 22/1000 | Loss: 0.00002554
Iteration 23/1000 | Loss: 0.00002554
Iteration 24/1000 | Loss: 0.00002553
Iteration 25/1000 | Loss: 0.00002553
Iteration 26/1000 | Loss: 0.00002553
Iteration 27/1000 | Loss: 0.00002553
Iteration 28/1000 | Loss: 0.00002553
Iteration 29/1000 | Loss: 0.00002553
Iteration 30/1000 | Loss: 0.00002552
Iteration 31/1000 | Loss: 0.00002552
Iteration 32/1000 | Loss: 0.00002552
Iteration 33/1000 | Loss: 0.00002552
Iteration 34/1000 | Loss: 0.00002551
Iteration 35/1000 | Loss: 0.00002551
Iteration 36/1000 | Loss: 0.00002551
Iteration 37/1000 | Loss: 0.00002551
Iteration 38/1000 | Loss: 0.00002551
Iteration 39/1000 | Loss: 0.00002551
Iteration 40/1000 | Loss: 0.00002550
Iteration 41/1000 | Loss: 0.00002550
Iteration 42/1000 | Loss: 0.00002550
Iteration 43/1000 | Loss: 0.00002550
Iteration 44/1000 | Loss: 0.00002549
Iteration 45/1000 | Loss: 0.00002548
Iteration 46/1000 | Loss: 0.00002548
Iteration 47/1000 | Loss: 0.00002548
Iteration 48/1000 | Loss: 0.00002548
Iteration 49/1000 | Loss: 0.00002548
Iteration 50/1000 | Loss: 0.00002547
Iteration 51/1000 | Loss: 0.00002547
Iteration 52/1000 | Loss: 0.00002547
Iteration 53/1000 | Loss: 0.00002547
Iteration 54/1000 | Loss: 0.00002547
Iteration 55/1000 | Loss: 0.00002547
Iteration 56/1000 | Loss: 0.00002547
Iteration 57/1000 | Loss: 0.00002547
Iteration 58/1000 | Loss: 0.00002547
Iteration 59/1000 | Loss: 0.00002547
Iteration 60/1000 | Loss: 0.00002547
Iteration 61/1000 | Loss: 0.00002547
Iteration 62/1000 | Loss: 0.00002546
Iteration 63/1000 | Loss: 0.00002546
Iteration 64/1000 | Loss: 0.00002545
Iteration 65/1000 | Loss: 0.00002545
Iteration 66/1000 | Loss: 0.00002545
Iteration 67/1000 | Loss: 0.00002545
Iteration 68/1000 | Loss: 0.00002545
Iteration 69/1000 | Loss: 0.00002545
Iteration 70/1000 | Loss: 0.00002544
Iteration 71/1000 | Loss: 0.00002544
Iteration 72/1000 | Loss: 0.00002544
Iteration 73/1000 | Loss: 0.00002543
Iteration 74/1000 | Loss: 0.00002543
Iteration 75/1000 | Loss: 0.00002542
Iteration 76/1000 | Loss: 0.00002542
Iteration 77/1000 | Loss: 0.00002542
Iteration 78/1000 | Loss: 0.00002541
Iteration 79/1000 | Loss: 0.00002541
Iteration 80/1000 | Loss: 0.00002541
Iteration 81/1000 | Loss: 0.00002540
Iteration 82/1000 | Loss: 0.00002540
Iteration 83/1000 | Loss: 0.00002540
Iteration 84/1000 | Loss: 0.00002539
Iteration 85/1000 | Loss: 0.00002539
Iteration 86/1000 | Loss: 0.00002539
Iteration 87/1000 | Loss: 0.00002539
Iteration 88/1000 | Loss: 0.00002539
Iteration 89/1000 | Loss: 0.00002539
Iteration 90/1000 | Loss: 0.00002539
Iteration 91/1000 | Loss: 0.00002539
Iteration 92/1000 | Loss: 0.00002539
Iteration 93/1000 | Loss: 0.00002539
Iteration 94/1000 | Loss: 0.00002538
Iteration 95/1000 | Loss: 0.00002538
Iteration 96/1000 | Loss: 0.00002538
Iteration 97/1000 | Loss: 0.00002536
Iteration 98/1000 | Loss: 0.00002536
Iteration 99/1000 | Loss: 0.00002535
Iteration 100/1000 | Loss: 0.00002535
Iteration 101/1000 | Loss: 0.00002535
Iteration 102/1000 | Loss: 0.00002535
Iteration 103/1000 | Loss: 0.00002535
Iteration 104/1000 | Loss: 0.00002534
Iteration 105/1000 | Loss: 0.00002534
Iteration 106/1000 | Loss: 0.00002534
Iteration 107/1000 | Loss: 0.00002533
Iteration 108/1000 | Loss: 0.00002533
Iteration 109/1000 | Loss: 0.00002533
Iteration 110/1000 | Loss: 0.00002533
Iteration 111/1000 | Loss: 0.00002533
Iteration 112/1000 | Loss: 0.00002533
Iteration 113/1000 | Loss: 0.00002533
Iteration 114/1000 | Loss: 0.00002533
Iteration 115/1000 | Loss: 0.00002533
Iteration 116/1000 | Loss: 0.00002533
Iteration 117/1000 | Loss: 0.00002533
Iteration 118/1000 | Loss: 0.00002533
Iteration 119/1000 | Loss: 0.00002533
Iteration 120/1000 | Loss: 0.00002532
Iteration 121/1000 | Loss: 0.00002532
Iteration 122/1000 | Loss: 0.00002532
Iteration 123/1000 | Loss: 0.00002532
Iteration 124/1000 | Loss: 0.00002532
Iteration 125/1000 | Loss: 0.00002531
Iteration 126/1000 | Loss: 0.00002531
Iteration 127/1000 | Loss: 0.00002531
Iteration 128/1000 | Loss: 0.00002531
Iteration 129/1000 | Loss: 0.00002531
Iteration 130/1000 | Loss: 0.00002531
Iteration 131/1000 | Loss: 0.00002531
Iteration 132/1000 | Loss: 0.00002531
Iteration 133/1000 | Loss: 0.00002530
Iteration 134/1000 | Loss: 0.00002530
Iteration 135/1000 | Loss: 0.00002530
Iteration 136/1000 | Loss: 0.00002530
Iteration 137/1000 | Loss: 0.00002530
Iteration 138/1000 | Loss: 0.00002530
Iteration 139/1000 | Loss: 0.00002530
Iteration 140/1000 | Loss: 0.00002530
Iteration 141/1000 | Loss: 0.00002530
Iteration 142/1000 | Loss: 0.00002530
Iteration 143/1000 | Loss: 0.00002530
Iteration 144/1000 | Loss: 0.00002530
Iteration 145/1000 | Loss: 0.00002530
Iteration 146/1000 | Loss: 0.00002530
Iteration 147/1000 | Loss: 0.00002530
Iteration 148/1000 | Loss: 0.00002530
Iteration 149/1000 | Loss: 0.00002530
Iteration 150/1000 | Loss: 0.00002530
Iteration 151/1000 | Loss: 0.00002530
Iteration 152/1000 | Loss: 0.00002530
Iteration 153/1000 | Loss: 0.00002530
Iteration 154/1000 | Loss: 0.00002530
Iteration 155/1000 | Loss: 0.00002530
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 155. Stopping optimization.
Last 5 losses: [2.5298742912127636e-05, 2.5298742912127636e-05, 2.5298742912127636e-05, 2.5298742912127636e-05, 2.5298742912127636e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5298742912127636e-05

Optimization complete. Final v2v error: 4.294584274291992 mm

Highest mean error: 4.742062091827393 mm for frame 124

Lowest mean error: 3.7835769653320312 mm for frame 50

Saving results

Total time: 63.07989501953125
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00890153
Iteration 2/25 | Loss: 0.00205832
Iteration 3/25 | Loss: 0.00132371
Iteration 4/25 | Loss: 0.00121344
Iteration 5/25 | Loss: 0.00119577
Iteration 6/25 | Loss: 0.00117836
Iteration 7/25 | Loss: 0.00117507
Iteration 8/25 | Loss: 0.00117419
Iteration 9/25 | Loss: 0.00117391
Iteration 10/25 | Loss: 0.00117390
Iteration 11/25 | Loss: 0.00117390
Iteration 12/25 | Loss: 0.00117390
Iteration 13/25 | Loss: 0.00117390
Iteration 14/25 | Loss: 0.00117390
Iteration 15/25 | Loss: 0.00117390
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0011739006731659174, 0.0011739006731659174, 0.0011739006731659174, 0.0011739006731659174, 0.0011739006731659174]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011739006731659174

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50326526
Iteration 2/25 | Loss: 0.00093788
Iteration 3/25 | Loss: 0.00093788
Iteration 4/25 | Loss: 0.00093788
Iteration 5/25 | Loss: 0.00093788
Iteration 6/25 | Loss: 0.00093788
Iteration 7/25 | Loss: 0.00093788
Iteration 8/25 | Loss: 0.00093787
Iteration 9/25 | Loss: 0.00093787
Iteration 10/25 | Loss: 0.00093787
Iteration 11/25 | Loss: 0.00093787
Iteration 12/25 | Loss: 0.00093787
Iteration 13/25 | Loss: 0.00093787
Iteration 14/25 | Loss: 0.00093787
Iteration 15/25 | Loss: 0.00093787
Iteration 16/25 | Loss: 0.00093787
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0009378739050589502, 0.0009378739050589502, 0.0009378739050589502, 0.0009378739050589502, 0.0009378739050589502]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009378739050589502

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00093787
Iteration 2/1000 | Loss: 0.00005035
Iteration 3/1000 | Loss: 0.00003845
Iteration 4/1000 | Loss: 0.00003381
Iteration 5/1000 | Loss: 0.00003142
Iteration 6/1000 | Loss: 0.00003047
Iteration 7/1000 | Loss: 0.00002976
Iteration 8/1000 | Loss: 0.00002937
Iteration 9/1000 | Loss: 0.00002916
Iteration 10/1000 | Loss: 0.00002898
Iteration 11/1000 | Loss: 0.00002889
Iteration 12/1000 | Loss: 0.00002888
Iteration 13/1000 | Loss: 0.00002888
Iteration 14/1000 | Loss: 0.00002888
Iteration 15/1000 | Loss: 0.00002888
Iteration 16/1000 | Loss: 0.00002888
Iteration 17/1000 | Loss: 0.00002888
Iteration 18/1000 | Loss: 0.00002888
Iteration 19/1000 | Loss: 0.00002887
Iteration 20/1000 | Loss: 0.00002887
Iteration 21/1000 | Loss: 0.00002886
Iteration 22/1000 | Loss: 0.00002885
Iteration 23/1000 | Loss: 0.00002884
Iteration 24/1000 | Loss: 0.00002884
Iteration 25/1000 | Loss: 0.00002884
Iteration 26/1000 | Loss: 0.00002884
Iteration 27/1000 | Loss: 0.00002883
Iteration 28/1000 | Loss: 0.00002882
Iteration 29/1000 | Loss: 0.00002881
Iteration 30/1000 | Loss: 0.00002881
Iteration 31/1000 | Loss: 0.00002881
Iteration 32/1000 | Loss: 0.00002881
Iteration 33/1000 | Loss: 0.00002881
Iteration 34/1000 | Loss: 0.00002881
Iteration 35/1000 | Loss: 0.00002880
Iteration 36/1000 | Loss: 0.00002880
Iteration 37/1000 | Loss: 0.00002878
Iteration 38/1000 | Loss: 0.00002877
Iteration 39/1000 | Loss: 0.00002877
Iteration 40/1000 | Loss: 0.00002877
Iteration 41/1000 | Loss: 0.00002877
Iteration 42/1000 | Loss: 0.00002877
Iteration 43/1000 | Loss: 0.00002877
Iteration 44/1000 | Loss: 0.00002877
Iteration 45/1000 | Loss: 0.00002875
Iteration 46/1000 | Loss: 0.00002875
Iteration 47/1000 | Loss: 0.00002874
Iteration 48/1000 | Loss: 0.00002874
Iteration 49/1000 | Loss: 0.00002873
Iteration 50/1000 | Loss: 0.00002873
Iteration 51/1000 | Loss: 0.00002873
Iteration 52/1000 | Loss: 0.00002873
Iteration 53/1000 | Loss: 0.00002872
Iteration 54/1000 | Loss: 0.00002872
Iteration 55/1000 | Loss: 0.00002872
Iteration 56/1000 | Loss: 0.00002872
Iteration 57/1000 | Loss: 0.00002872
Iteration 58/1000 | Loss: 0.00002872
Iteration 59/1000 | Loss: 0.00002872
Iteration 60/1000 | Loss: 0.00002872
Iteration 61/1000 | Loss: 0.00002872
Iteration 62/1000 | Loss: 0.00002872
Iteration 63/1000 | Loss: 0.00002872
Iteration 64/1000 | Loss: 0.00002872
Iteration 65/1000 | Loss: 0.00002872
Iteration 66/1000 | Loss: 0.00002872
Iteration 67/1000 | Loss: 0.00002872
Iteration 68/1000 | Loss: 0.00002872
Iteration 69/1000 | Loss: 0.00002872
Iteration 70/1000 | Loss: 0.00002872
Iteration 71/1000 | Loss: 0.00002872
Iteration 72/1000 | Loss: 0.00002872
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [2.871537253668066e-05, 2.871537253668066e-05, 2.871537253668066e-05, 2.871537253668066e-05, 2.871537253668066e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.871537253668066e-05

Optimization complete. Final v2v error: 4.604489326477051 mm

Highest mean error: 5.147719860076904 mm for frame 53

Lowest mean error: 4.244994163513184 mm for frame 43

Saving results

Total time: 38.26467680931091
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00527973
Iteration 2/25 | Loss: 0.00140719
Iteration 3/25 | Loss: 0.00126669
Iteration 4/25 | Loss: 0.00122448
Iteration 5/25 | Loss: 0.00121163
Iteration 6/25 | Loss: 0.00120744
Iteration 7/25 | Loss: 0.00120600
Iteration 8/25 | Loss: 0.00120600
Iteration 9/25 | Loss: 0.00120600
Iteration 10/25 | Loss: 0.00120600
Iteration 11/25 | Loss: 0.00120600
Iteration 12/25 | Loss: 0.00120600
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012060027802363038, 0.0012060027802363038, 0.0012060027802363038, 0.0012060027802363038, 0.0012060027802363038]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012060027802363038

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.75267780
Iteration 2/25 | Loss: 0.00165287
Iteration 3/25 | Loss: 0.00165287
Iteration 4/25 | Loss: 0.00165287
Iteration 5/25 | Loss: 0.00165287
Iteration 6/25 | Loss: 0.00165286
Iteration 7/25 | Loss: 0.00165286
Iteration 8/25 | Loss: 0.00165286
Iteration 9/25 | Loss: 0.00165286
Iteration 10/25 | Loss: 0.00165286
Iteration 11/25 | Loss: 0.00165286
Iteration 12/25 | Loss: 0.00165286
Iteration 13/25 | Loss: 0.00165286
Iteration 14/25 | Loss: 0.00165286
Iteration 15/25 | Loss: 0.00165286
Iteration 16/25 | Loss: 0.00165286
Iteration 17/25 | Loss: 0.00165286
Iteration 18/25 | Loss: 0.00165286
Iteration 19/25 | Loss: 0.00165286
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0016528633423149586, 0.0016528633423149586, 0.0016528633423149586, 0.0016528633423149586, 0.0016528633423149586]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016528633423149586

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00165286
Iteration 2/1000 | Loss: 0.00006425
Iteration 3/1000 | Loss: 0.00004102
Iteration 4/1000 | Loss: 0.00003418
Iteration 5/1000 | Loss: 0.00003119
Iteration 6/1000 | Loss: 0.00002948
Iteration 7/1000 | Loss: 0.00002806
Iteration 8/1000 | Loss: 0.00002690
Iteration 9/1000 | Loss: 0.00002617
Iteration 10/1000 | Loss: 0.00002558
Iteration 11/1000 | Loss: 0.00002518
Iteration 12/1000 | Loss: 0.00002487
Iteration 13/1000 | Loss: 0.00002465
Iteration 14/1000 | Loss: 0.00002445
Iteration 15/1000 | Loss: 0.00002439
Iteration 16/1000 | Loss: 0.00002436
Iteration 17/1000 | Loss: 0.00002435
Iteration 18/1000 | Loss: 0.00002434
Iteration 19/1000 | Loss: 0.00002434
Iteration 20/1000 | Loss: 0.00002433
Iteration 21/1000 | Loss: 0.00002432
Iteration 22/1000 | Loss: 0.00002431
Iteration 23/1000 | Loss: 0.00002429
Iteration 24/1000 | Loss: 0.00002424
Iteration 25/1000 | Loss: 0.00002422
Iteration 26/1000 | Loss: 0.00002421
Iteration 27/1000 | Loss: 0.00002417
Iteration 28/1000 | Loss: 0.00002417
Iteration 29/1000 | Loss: 0.00002413
Iteration 30/1000 | Loss: 0.00002411
Iteration 31/1000 | Loss: 0.00002410
Iteration 32/1000 | Loss: 0.00002410
Iteration 33/1000 | Loss: 0.00002410
Iteration 34/1000 | Loss: 0.00002409
Iteration 35/1000 | Loss: 0.00002409
Iteration 36/1000 | Loss: 0.00002409
Iteration 37/1000 | Loss: 0.00002408
Iteration 38/1000 | Loss: 0.00002408
Iteration 39/1000 | Loss: 0.00002408
Iteration 40/1000 | Loss: 0.00002407
Iteration 41/1000 | Loss: 0.00002407
Iteration 42/1000 | Loss: 0.00002406
Iteration 43/1000 | Loss: 0.00002406
Iteration 44/1000 | Loss: 0.00002406
Iteration 45/1000 | Loss: 0.00002405
Iteration 46/1000 | Loss: 0.00002405
Iteration 47/1000 | Loss: 0.00002404
Iteration 48/1000 | Loss: 0.00002404
Iteration 49/1000 | Loss: 0.00002404
Iteration 50/1000 | Loss: 0.00002403
Iteration 51/1000 | Loss: 0.00002403
Iteration 52/1000 | Loss: 0.00002402
Iteration 53/1000 | Loss: 0.00002402
Iteration 54/1000 | Loss: 0.00002402
Iteration 55/1000 | Loss: 0.00002401
Iteration 56/1000 | Loss: 0.00002401
Iteration 57/1000 | Loss: 0.00002400
Iteration 58/1000 | Loss: 0.00002400
Iteration 59/1000 | Loss: 0.00002400
Iteration 60/1000 | Loss: 0.00002399
Iteration 61/1000 | Loss: 0.00002399
Iteration 62/1000 | Loss: 0.00002398
Iteration 63/1000 | Loss: 0.00002398
Iteration 64/1000 | Loss: 0.00002398
Iteration 65/1000 | Loss: 0.00002397
Iteration 66/1000 | Loss: 0.00002397
Iteration 67/1000 | Loss: 0.00002397
Iteration 68/1000 | Loss: 0.00002397
Iteration 69/1000 | Loss: 0.00002396
Iteration 70/1000 | Loss: 0.00002396
Iteration 71/1000 | Loss: 0.00002396
Iteration 72/1000 | Loss: 0.00002396
Iteration 73/1000 | Loss: 0.00002396
Iteration 74/1000 | Loss: 0.00002396
Iteration 75/1000 | Loss: 0.00002396
Iteration 76/1000 | Loss: 0.00002396
Iteration 77/1000 | Loss: 0.00002396
Iteration 78/1000 | Loss: 0.00002396
Iteration 79/1000 | Loss: 0.00002395
Iteration 80/1000 | Loss: 0.00002395
Iteration 81/1000 | Loss: 0.00002395
Iteration 82/1000 | Loss: 0.00002395
Iteration 83/1000 | Loss: 0.00002394
Iteration 84/1000 | Loss: 0.00002394
Iteration 85/1000 | Loss: 0.00002394
Iteration 86/1000 | Loss: 0.00002394
Iteration 87/1000 | Loss: 0.00002394
Iteration 88/1000 | Loss: 0.00002393
Iteration 89/1000 | Loss: 0.00002393
Iteration 90/1000 | Loss: 0.00002393
Iteration 91/1000 | Loss: 0.00002393
Iteration 92/1000 | Loss: 0.00002393
Iteration 93/1000 | Loss: 0.00002393
Iteration 94/1000 | Loss: 0.00002393
Iteration 95/1000 | Loss: 0.00002393
Iteration 96/1000 | Loss: 0.00002393
Iteration 97/1000 | Loss: 0.00002393
Iteration 98/1000 | Loss: 0.00002392
Iteration 99/1000 | Loss: 0.00002392
Iteration 100/1000 | Loss: 0.00002392
Iteration 101/1000 | Loss: 0.00002391
Iteration 102/1000 | Loss: 0.00002391
Iteration 103/1000 | Loss: 0.00002391
Iteration 104/1000 | Loss: 0.00002391
Iteration 105/1000 | Loss: 0.00002391
Iteration 106/1000 | Loss: 0.00002390
Iteration 107/1000 | Loss: 0.00002390
Iteration 108/1000 | Loss: 0.00002390
Iteration 109/1000 | Loss: 0.00002390
Iteration 110/1000 | Loss: 0.00002390
Iteration 111/1000 | Loss: 0.00002390
Iteration 112/1000 | Loss: 0.00002390
Iteration 113/1000 | Loss: 0.00002390
Iteration 114/1000 | Loss: 0.00002390
Iteration 115/1000 | Loss: 0.00002389
Iteration 116/1000 | Loss: 0.00002389
Iteration 117/1000 | Loss: 0.00002389
Iteration 118/1000 | Loss: 0.00002389
Iteration 119/1000 | Loss: 0.00002389
Iteration 120/1000 | Loss: 0.00002389
Iteration 121/1000 | Loss: 0.00002389
Iteration 122/1000 | Loss: 0.00002389
Iteration 123/1000 | Loss: 0.00002388
Iteration 124/1000 | Loss: 0.00002388
Iteration 125/1000 | Loss: 0.00002388
Iteration 126/1000 | Loss: 0.00002388
Iteration 127/1000 | Loss: 0.00002388
Iteration 128/1000 | Loss: 0.00002388
Iteration 129/1000 | Loss: 0.00002387
Iteration 130/1000 | Loss: 0.00002387
Iteration 131/1000 | Loss: 0.00002387
Iteration 132/1000 | Loss: 0.00002387
Iteration 133/1000 | Loss: 0.00002387
Iteration 134/1000 | Loss: 0.00002387
Iteration 135/1000 | Loss: 0.00002387
Iteration 136/1000 | Loss: 0.00002387
Iteration 137/1000 | Loss: 0.00002387
Iteration 138/1000 | Loss: 0.00002387
Iteration 139/1000 | Loss: 0.00002387
Iteration 140/1000 | Loss: 0.00002387
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [2.3869219148764387e-05, 2.3869219148764387e-05, 2.3869219148764387e-05, 2.3869219148764387e-05, 2.3869219148764387e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3869219148764387e-05

Optimization complete. Final v2v error: 4.1470232009887695 mm

Highest mean error: 5.581751346588135 mm for frame 39

Lowest mean error: 3.5399253368377686 mm for frame 234

Saving results

Total time: 47.77934789657593
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_36_us_1840/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_36_us_1840/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00605921
Iteration 2/25 | Loss: 0.00132603
Iteration 3/25 | Loss: 0.00116785
Iteration 4/25 | Loss: 0.00114457
Iteration 5/25 | Loss: 0.00113506
Iteration 6/25 | Loss: 0.00113198
Iteration 7/25 | Loss: 0.00113108
Iteration 8/25 | Loss: 0.00113108
Iteration 9/25 | Loss: 0.00113108
Iteration 10/25 | Loss: 0.00113108
Iteration 11/25 | Loss: 0.00113108
Iteration 12/25 | Loss: 0.00113108
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001131084281951189, 0.001131084281951189, 0.001131084281951189, 0.001131084281951189, 0.001131084281951189]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001131084281951189

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 11.94059277
Iteration 2/25 | Loss: 0.00109645
Iteration 3/25 | Loss: 0.00109596
Iteration 4/25 | Loss: 0.00109596
Iteration 5/25 | Loss: 0.00109596
Iteration 6/25 | Loss: 0.00109596
Iteration 7/25 | Loss: 0.00109596
Iteration 8/25 | Loss: 0.00109596
Iteration 9/25 | Loss: 0.00109596
Iteration 10/25 | Loss: 0.00109596
Iteration 11/25 | Loss: 0.00109596
Iteration 12/25 | Loss: 0.00109596
Iteration 13/25 | Loss: 0.00109596
Iteration 14/25 | Loss: 0.00109596
Iteration 15/25 | Loss: 0.00109596
Iteration 16/25 | Loss: 0.00109596
Iteration 17/25 | Loss: 0.00109596
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0010959573555737734, 0.0010959573555737734, 0.0010959573555737734, 0.0010959573555737734, 0.0010959573555737734]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010959573555737734

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00109596
Iteration 2/1000 | Loss: 0.00003012
Iteration 3/1000 | Loss: 0.00002457
Iteration 4/1000 | Loss: 0.00002363
Iteration 5/1000 | Loss: 0.00002283
Iteration 6/1000 | Loss: 0.00002245
Iteration 7/1000 | Loss: 0.00002223
Iteration 8/1000 | Loss: 0.00002198
Iteration 9/1000 | Loss: 0.00002194
Iteration 10/1000 | Loss: 0.00002190
Iteration 11/1000 | Loss: 0.00002188
Iteration 12/1000 | Loss: 0.00002187
Iteration 13/1000 | Loss: 0.00002187
Iteration 14/1000 | Loss: 0.00002187
Iteration 15/1000 | Loss: 0.00002187
Iteration 16/1000 | Loss: 0.00002187
Iteration 17/1000 | Loss: 0.00002186
Iteration 18/1000 | Loss: 0.00002186
Iteration 19/1000 | Loss: 0.00002186
Iteration 20/1000 | Loss: 0.00002184
Iteration 21/1000 | Loss: 0.00002183
Iteration 22/1000 | Loss: 0.00002183
Iteration 23/1000 | Loss: 0.00002182
Iteration 24/1000 | Loss: 0.00002182
Iteration 25/1000 | Loss: 0.00002182
Iteration 26/1000 | Loss: 0.00002182
Iteration 27/1000 | Loss: 0.00002182
Iteration 28/1000 | Loss: 0.00002182
Iteration 29/1000 | Loss: 0.00002181
Iteration 30/1000 | Loss: 0.00002181
Iteration 31/1000 | Loss: 0.00002181
Iteration 32/1000 | Loss: 0.00002180
Iteration 33/1000 | Loss: 0.00002180
Iteration 34/1000 | Loss: 0.00002179
Iteration 35/1000 | Loss: 0.00002179
Iteration 36/1000 | Loss: 0.00002179
Iteration 37/1000 | Loss: 0.00002178
Iteration 38/1000 | Loss: 0.00002178
Iteration 39/1000 | Loss: 0.00002178
Iteration 40/1000 | Loss: 0.00002178
Iteration 41/1000 | Loss: 0.00002178
Iteration 42/1000 | Loss: 0.00002178
Iteration 43/1000 | Loss: 0.00002178
Iteration 44/1000 | Loss: 0.00002176
Iteration 45/1000 | Loss: 0.00002175
Iteration 46/1000 | Loss: 0.00002175
Iteration 47/1000 | Loss: 0.00002175
Iteration 48/1000 | Loss: 0.00002175
Iteration 49/1000 | Loss: 0.00002175
Iteration 50/1000 | Loss: 0.00002175
Iteration 51/1000 | Loss: 0.00002174
Iteration 52/1000 | Loss: 0.00002174
Iteration 53/1000 | Loss: 0.00002174
Iteration 54/1000 | Loss: 0.00002174
Iteration 55/1000 | Loss: 0.00002174
Iteration 56/1000 | Loss: 0.00002174
Iteration 57/1000 | Loss: 0.00002174
Iteration 58/1000 | Loss: 0.00002174
Iteration 59/1000 | Loss: 0.00002174
Iteration 60/1000 | Loss: 0.00002174
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 60. Stopping optimization.
Last 5 losses: [2.1741181626566686e-05, 2.1741181626566686e-05, 2.1741181626566686e-05, 2.1741181626566686e-05, 2.1741181626566686e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1741181626566686e-05

Optimization complete. Final v2v error: 4.037012577056885 mm

Highest mean error: 4.548068046569824 mm for frame 239

Lowest mean error: 3.5158910751342773 mm for frame 86

Saving results

Total time: 29.477779626846313
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1030
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00534106
Iteration 2/25 | Loss: 0.00115199
Iteration 3/25 | Loss: 0.00091791
Iteration 4/25 | Loss: 0.00089302
Iteration 5/25 | Loss: 0.00088457
Iteration 6/25 | Loss: 0.00088294
Iteration 7/25 | Loss: 0.00088274
Iteration 8/25 | Loss: 0.00088274
Iteration 9/25 | Loss: 0.00088274
Iteration 10/25 | Loss: 0.00088274
Iteration 11/25 | Loss: 0.00088274
Iteration 12/25 | Loss: 0.00088274
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008827446727082133, 0.0008827446727082133, 0.0008827446727082133, 0.0008827446727082133, 0.0008827446727082133]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008827446727082133

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49166405
Iteration 2/25 | Loss: 0.00064797
Iteration 3/25 | Loss: 0.00064795
Iteration 4/25 | Loss: 0.00064795
Iteration 5/25 | Loss: 0.00064795
Iteration 6/25 | Loss: 0.00064795
Iteration 7/25 | Loss: 0.00064795
Iteration 8/25 | Loss: 0.00064795
Iteration 9/25 | Loss: 0.00064795
Iteration 10/25 | Loss: 0.00064795
Iteration 11/25 | Loss: 0.00064795
Iteration 12/25 | Loss: 0.00064795
Iteration 13/25 | Loss: 0.00064794
Iteration 14/25 | Loss: 0.00064794
Iteration 15/25 | Loss: 0.00064794
Iteration 16/25 | Loss: 0.00064794
Iteration 17/25 | Loss: 0.00064794
Iteration 18/25 | Loss: 0.00064794
Iteration 19/25 | Loss: 0.00064794
Iteration 20/25 | Loss: 0.00064794
Iteration 21/25 | Loss: 0.00064794
Iteration 22/25 | Loss: 0.00064794
Iteration 23/25 | Loss: 0.00064794
Iteration 24/25 | Loss: 0.00064794
Iteration 25/25 | Loss: 0.00064794

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00064794
Iteration 2/1000 | Loss: 0.00003528
Iteration 3/1000 | Loss: 0.00002703
Iteration 4/1000 | Loss: 0.00002436
Iteration 5/1000 | Loss: 0.00002296
Iteration 6/1000 | Loss: 0.00002211
Iteration 7/1000 | Loss: 0.00002145
Iteration 8/1000 | Loss: 0.00002102
Iteration 9/1000 | Loss: 0.00002067
Iteration 10/1000 | Loss: 0.00002046
Iteration 11/1000 | Loss: 0.00002023
Iteration 12/1000 | Loss: 0.00002005
Iteration 13/1000 | Loss: 0.00002002
Iteration 14/1000 | Loss: 0.00002001
Iteration 15/1000 | Loss: 0.00002000
Iteration 16/1000 | Loss: 0.00001995
Iteration 17/1000 | Loss: 0.00001994
Iteration 18/1000 | Loss: 0.00001993
Iteration 19/1000 | Loss: 0.00001992
Iteration 20/1000 | Loss: 0.00001992
Iteration 21/1000 | Loss: 0.00001992
Iteration 22/1000 | Loss: 0.00001991
Iteration 23/1000 | Loss: 0.00001991
Iteration 24/1000 | Loss: 0.00001991
Iteration 25/1000 | Loss: 0.00001990
Iteration 26/1000 | Loss: 0.00001990
Iteration 27/1000 | Loss: 0.00001990
Iteration 28/1000 | Loss: 0.00001990
Iteration 29/1000 | Loss: 0.00001990
Iteration 30/1000 | Loss: 0.00001989
Iteration 31/1000 | Loss: 0.00001989
Iteration 32/1000 | Loss: 0.00001989
Iteration 33/1000 | Loss: 0.00001989
Iteration 34/1000 | Loss: 0.00001989
Iteration 35/1000 | Loss: 0.00001989
Iteration 36/1000 | Loss: 0.00001989
Iteration 37/1000 | Loss: 0.00001988
Iteration 38/1000 | Loss: 0.00001988
Iteration 39/1000 | Loss: 0.00001988
Iteration 40/1000 | Loss: 0.00001988
Iteration 41/1000 | Loss: 0.00001988
Iteration 42/1000 | Loss: 0.00001987
Iteration 43/1000 | Loss: 0.00001987
Iteration 44/1000 | Loss: 0.00001987
Iteration 45/1000 | Loss: 0.00001987
Iteration 46/1000 | Loss: 0.00001987
Iteration 47/1000 | Loss: 0.00001987
Iteration 48/1000 | Loss: 0.00001987
Iteration 49/1000 | Loss: 0.00001987
Iteration 50/1000 | Loss: 0.00001987
Iteration 51/1000 | Loss: 0.00001987
Iteration 52/1000 | Loss: 0.00001987
Iteration 53/1000 | Loss: 0.00001987
Iteration 54/1000 | Loss: 0.00001986
Iteration 55/1000 | Loss: 0.00001986
Iteration 56/1000 | Loss: 0.00001986
Iteration 57/1000 | Loss: 0.00001986
Iteration 58/1000 | Loss: 0.00001986
Iteration 59/1000 | Loss: 0.00001985
Iteration 60/1000 | Loss: 0.00001985
Iteration 61/1000 | Loss: 0.00001984
Iteration 62/1000 | Loss: 0.00001984
Iteration 63/1000 | Loss: 0.00001984
Iteration 64/1000 | Loss: 0.00001984
Iteration 65/1000 | Loss: 0.00001984
Iteration 66/1000 | Loss: 0.00001984
Iteration 67/1000 | Loss: 0.00001984
Iteration 68/1000 | Loss: 0.00001984
Iteration 69/1000 | Loss: 0.00001984
Iteration 70/1000 | Loss: 0.00001984
Iteration 71/1000 | Loss: 0.00001984
Iteration 72/1000 | Loss: 0.00001983
Iteration 73/1000 | Loss: 0.00001983
Iteration 74/1000 | Loss: 0.00001983
Iteration 75/1000 | Loss: 0.00001981
Iteration 76/1000 | Loss: 0.00001981
Iteration 77/1000 | Loss: 0.00001981
Iteration 78/1000 | Loss: 0.00001981
Iteration 79/1000 | Loss: 0.00001980
Iteration 80/1000 | Loss: 0.00001980
Iteration 81/1000 | Loss: 0.00001980
Iteration 82/1000 | Loss: 0.00001980
Iteration 83/1000 | Loss: 0.00001980
Iteration 84/1000 | Loss: 0.00001980
Iteration 85/1000 | Loss: 0.00001979
Iteration 86/1000 | Loss: 0.00001979
Iteration 87/1000 | Loss: 0.00001979
Iteration 88/1000 | Loss: 0.00001979
Iteration 89/1000 | Loss: 0.00001979
Iteration 90/1000 | Loss: 0.00001979
Iteration 91/1000 | Loss: 0.00001979
Iteration 92/1000 | Loss: 0.00001978
Iteration 93/1000 | Loss: 0.00001978
Iteration 94/1000 | Loss: 0.00001977
Iteration 95/1000 | Loss: 0.00001977
Iteration 96/1000 | Loss: 0.00001977
Iteration 97/1000 | Loss: 0.00001977
Iteration 98/1000 | Loss: 0.00001977
Iteration 99/1000 | Loss: 0.00001977
Iteration 100/1000 | Loss: 0.00001976
Iteration 101/1000 | Loss: 0.00001976
Iteration 102/1000 | Loss: 0.00001976
Iteration 103/1000 | Loss: 0.00001976
Iteration 104/1000 | Loss: 0.00001976
Iteration 105/1000 | Loss: 0.00001976
Iteration 106/1000 | Loss: 0.00001976
Iteration 107/1000 | Loss: 0.00001976
Iteration 108/1000 | Loss: 0.00001975
Iteration 109/1000 | Loss: 0.00001975
Iteration 110/1000 | Loss: 0.00001975
Iteration 111/1000 | Loss: 0.00001975
Iteration 112/1000 | Loss: 0.00001975
Iteration 113/1000 | Loss: 0.00001975
Iteration 114/1000 | Loss: 0.00001975
Iteration 115/1000 | Loss: 0.00001975
Iteration 116/1000 | Loss: 0.00001975
Iteration 117/1000 | Loss: 0.00001975
Iteration 118/1000 | Loss: 0.00001975
Iteration 119/1000 | Loss: 0.00001974
Iteration 120/1000 | Loss: 0.00001974
Iteration 121/1000 | Loss: 0.00001974
Iteration 122/1000 | Loss: 0.00001974
Iteration 123/1000 | Loss: 0.00001974
Iteration 124/1000 | Loss: 0.00001974
Iteration 125/1000 | Loss: 0.00001974
Iteration 126/1000 | Loss: 0.00001974
Iteration 127/1000 | Loss: 0.00001974
Iteration 128/1000 | Loss: 0.00001974
Iteration 129/1000 | Loss: 0.00001974
Iteration 130/1000 | Loss: 0.00001974
Iteration 131/1000 | Loss: 0.00001974
Iteration 132/1000 | Loss: 0.00001974
Iteration 133/1000 | Loss: 0.00001974
Iteration 134/1000 | Loss: 0.00001974
Iteration 135/1000 | Loss: 0.00001974
Iteration 136/1000 | Loss: 0.00001974
Iteration 137/1000 | Loss: 0.00001974
Iteration 138/1000 | Loss: 0.00001974
Iteration 139/1000 | Loss: 0.00001974
Iteration 140/1000 | Loss: 0.00001974
Iteration 141/1000 | Loss: 0.00001974
Iteration 142/1000 | Loss: 0.00001974
Iteration 143/1000 | Loss: 0.00001974
Iteration 144/1000 | Loss: 0.00001974
Iteration 145/1000 | Loss: 0.00001974
Iteration 146/1000 | Loss: 0.00001974
Iteration 147/1000 | Loss: 0.00001974
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 147. Stopping optimization.
Last 5 losses: [1.973823964362964e-05, 1.973823964362964e-05, 1.973823964362964e-05, 1.973823964362964e-05, 1.973823964362964e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.973823964362964e-05

Optimization complete. Final v2v error: 3.7020199298858643 mm

Highest mean error: 4.0525665283203125 mm for frame 80

Lowest mean error: 3.2802724838256836 mm for frame 102

Saving results

Total time: 35.74116015434265
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435489
Iteration 2/25 | Loss: 0.00095561
Iteration 3/25 | Loss: 0.00085909
Iteration 4/25 | Loss: 0.00083820
Iteration 5/25 | Loss: 0.00083072
Iteration 6/25 | Loss: 0.00082885
Iteration 7/25 | Loss: 0.00082814
Iteration 8/25 | Loss: 0.00082810
Iteration 9/25 | Loss: 0.00082810
Iteration 10/25 | Loss: 0.00082810
Iteration 11/25 | Loss: 0.00082810
Iteration 12/25 | Loss: 0.00082810
Iteration 13/25 | Loss: 0.00082810
Iteration 14/25 | Loss: 0.00082810
Iteration 15/25 | Loss: 0.00082810
Iteration 16/25 | Loss: 0.00082810
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008281042682938278, 0.0008281042682938278, 0.0008281042682938278, 0.0008281042682938278, 0.0008281042682938278]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008281042682938278

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.99745893
Iteration 2/25 | Loss: 0.00063884
Iteration 3/25 | Loss: 0.00063882
Iteration 4/25 | Loss: 0.00063882
Iteration 5/25 | Loss: 0.00063881
Iteration 6/25 | Loss: 0.00063881
Iteration 7/25 | Loss: 0.00063881
Iteration 8/25 | Loss: 0.00063881
Iteration 9/25 | Loss: 0.00063881
Iteration 10/25 | Loss: 0.00063881
Iteration 11/25 | Loss: 0.00063881
Iteration 12/25 | Loss: 0.00063881
Iteration 13/25 | Loss: 0.00063881
Iteration 14/25 | Loss: 0.00063881
Iteration 15/25 | Loss: 0.00063881
Iteration 16/25 | Loss: 0.00063881
Iteration 17/25 | Loss: 0.00063881
Iteration 18/25 | Loss: 0.00063881
Iteration 19/25 | Loss: 0.00063881
Iteration 20/25 | Loss: 0.00063881
Iteration 21/25 | Loss: 0.00063881
Iteration 22/25 | Loss: 0.00063881
Iteration 23/25 | Loss: 0.00063881
Iteration 24/25 | Loss: 0.00063881
Iteration 25/25 | Loss: 0.00063881

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00063881
Iteration 2/1000 | Loss: 0.00003424
Iteration 3/1000 | Loss: 0.00002087
Iteration 4/1000 | Loss: 0.00001863
Iteration 5/1000 | Loss: 0.00001774
Iteration 6/1000 | Loss: 0.00001699
Iteration 7/1000 | Loss: 0.00001652
Iteration 8/1000 | Loss: 0.00001612
Iteration 9/1000 | Loss: 0.00001581
Iteration 10/1000 | Loss: 0.00001557
Iteration 11/1000 | Loss: 0.00001536
Iteration 12/1000 | Loss: 0.00001533
Iteration 13/1000 | Loss: 0.00001518
Iteration 14/1000 | Loss: 0.00001513
Iteration 15/1000 | Loss: 0.00001512
Iteration 16/1000 | Loss: 0.00001512
Iteration 17/1000 | Loss: 0.00001512
Iteration 18/1000 | Loss: 0.00001511
Iteration 19/1000 | Loss: 0.00001511
Iteration 20/1000 | Loss: 0.00001511
Iteration 21/1000 | Loss: 0.00001510
Iteration 22/1000 | Loss: 0.00001509
Iteration 23/1000 | Loss: 0.00001508
Iteration 24/1000 | Loss: 0.00001507
Iteration 25/1000 | Loss: 0.00001507
Iteration 26/1000 | Loss: 0.00001507
Iteration 27/1000 | Loss: 0.00001503
Iteration 28/1000 | Loss: 0.00001503
Iteration 29/1000 | Loss: 0.00001501
Iteration 30/1000 | Loss: 0.00001501
Iteration 31/1000 | Loss: 0.00001501
Iteration 32/1000 | Loss: 0.00001500
Iteration 33/1000 | Loss: 0.00001500
Iteration 34/1000 | Loss: 0.00001498
Iteration 35/1000 | Loss: 0.00001497
Iteration 36/1000 | Loss: 0.00001497
Iteration 37/1000 | Loss: 0.00001495
Iteration 38/1000 | Loss: 0.00001494
Iteration 39/1000 | Loss: 0.00001493
Iteration 40/1000 | Loss: 0.00001493
Iteration 41/1000 | Loss: 0.00001493
Iteration 42/1000 | Loss: 0.00001492
Iteration 43/1000 | Loss: 0.00001492
Iteration 44/1000 | Loss: 0.00001491
Iteration 45/1000 | Loss: 0.00001490
Iteration 46/1000 | Loss: 0.00001490
Iteration 47/1000 | Loss: 0.00001487
Iteration 48/1000 | Loss: 0.00001487
Iteration 49/1000 | Loss: 0.00001484
Iteration 50/1000 | Loss: 0.00001483
Iteration 51/1000 | Loss: 0.00001483
Iteration 52/1000 | Loss: 0.00001483
Iteration 53/1000 | Loss: 0.00001483
Iteration 54/1000 | Loss: 0.00001482
Iteration 55/1000 | Loss: 0.00001482
Iteration 56/1000 | Loss: 0.00001482
Iteration 57/1000 | Loss: 0.00001482
Iteration 58/1000 | Loss: 0.00001482
Iteration 59/1000 | Loss: 0.00001482
Iteration 60/1000 | Loss: 0.00001481
Iteration 61/1000 | Loss: 0.00001481
Iteration 62/1000 | Loss: 0.00001481
Iteration 63/1000 | Loss: 0.00001480
Iteration 64/1000 | Loss: 0.00001480
Iteration 65/1000 | Loss: 0.00001480
Iteration 66/1000 | Loss: 0.00001480
Iteration 67/1000 | Loss: 0.00001480
Iteration 68/1000 | Loss: 0.00001479
Iteration 69/1000 | Loss: 0.00001479
Iteration 70/1000 | Loss: 0.00001479
Iteration 71/1000 | Loss: 0.00001479
Iteration 72/1000 | Loss: 0.00001479
Iteration 73/1000 | Loss: 0.00001479
Iteration 74/1000 | Loss: 0.00001479
Iteration 75/1000 | Loss: 0.00001479
Iteration 76/1000 | Loss: 0.00001479
Iteration 77/1000 | Loss: 0.00001479
Iteration 78/1000 | Loss: 0.00001479
Iteration 79/1000 | Loss: 0.00001479
Iteration 80/1000 | Loss: 0.00001479
Iteration 81/1000 | Loss: 0.00001479
Iteration 82/1000 | Loss: 0.00001479
Iteration 83/1000 | Loss: 0.00001479
Iteration 84/1000 | Loss: 0.00001479
Iteration 85/1000 | Loss: 0.00001479
Iteration 86/1000 | Loss: 0.00001479
Iteration 87/1000 | Loss: 0.00001479
Iteration 88/1000 | Loss: 0.00001479
Iteration 89/1000 | Loss: 0.00001479
Iteration 90/1000 | Loss: 0.00001479
Iteration 91/1000 | Loss: 0.00001479
Iteration 92/1000 | Loss: 0.00001479
Iteration 93/1000 | Loss: 0.00001479
Iteration 94/1000 | Loss: 0.00001479
Iteration 95/1000 | Loss: 0.00001479
Iteration 96/1000 | Loss: 0.00001479
Iteration 97/1000 | Loss: 0.00001479
Iteration 98/1000 | Loss: 0.00001479
Iteration 99/1000 | Loss: 0.00001479
Iteration 100/1000 | Loss: 0.00001479
Iteration 101/1000 | Loss: 0.00001479
Iteration 102/1000 | Loss: 0.00001479
Iteration 103/1000 | Loss: 0.00001479
Iteration 104/1000 | Loss: 0.00001479
Iteration 105/1000 | Loss: 0.00001479
Iteration 106/1000 | Loss: 0.00001479
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.4788384760322515e-05, 1.4788384760322515e-05, 1.4788384760322515e-05, 1.4788384760322515e-05, 1.4788384760322515e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4788384760322515e-05

Optimization complete. Final v2v error: 3.2630109786987305 mm

Highest mean error: 3.5616581439971924 mm for frame 101

Lowest mean error: 2.9199624061584473 mm for frame 119

Saving results

Total time: 36.36457872390747
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00389515
Iteration 2/25 | Loss: 0.00104820
Iteration 3/25 | Loss: 0.00087730
Iteration 4/25 | Loss: 0.00084418
Iteration 5/25 | Loss: 0.00083454
Iteration 6/25 | Loss: 0.00083214
Iteration 7/25 | Loss: 0.00083140
Iteration 8/25 | Loss: 0.00083119
Iteration 9/25 | Loss: 0.00083119
Iteration 10/25 | Loss: 0.00083119
Iteration 11/25 | Loss: 0.00083119
Iteration 12/25 | Loss: 0.00083119
Iteration 13/25 | Loss: 0.00083119
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008311928831972182, 0.0008311928831972182, 0.0008311928831972182, 0.0008311928831972182, 0.0008311928831972182]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008311928831972182

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.95291758
Iteration 2/25 | Loss: 0.00074647
Iteration 3/25 | Loss: 0.00074641
Iteration 4/25 | Loss: 0.00074641
Iteration 5/25 | Loss: 0.00074641
Iteration 6/25 | Loss: 0.00074641
Iteration 7/25 | Loss: 0.00074641
Iteration 8/25 | Loss: 0.00074641
Iteration 9/25 | Loss: 0.00074641
Iteration 10/25 | Loss: 0.00074641
Iteration 11/25 | Loss: 0.00074641
Iteration 12/25 | Loss: 0.00074641
Iteration 13/25 | Loss: 0.00074641
Iteration 14/25 | Loss: 0.00074641
Iteration 15/25 | Loss: 0.00074641
Iteration 16/25 | Loss: 0.00074641
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007464116206392646, 0.0007464116206392646, 0.0007464116206392646, 0.0007464116206392646, 0.0007464116206392646]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007464116206392646

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00074641
Iteration 2/1000 | Loss: 0.00003474
Iteration 3/1000 | Loss: 0.00002519
Iteration 4/1000 | Loss: 0.00001981
Iteration 5/1000 | Loss: 0.00001760
Iteration 6/1000 | Loss: 0.00001670
Iteration 7/1000 | Loss: 0.00001597
Iteration 8/1000 | Loss: 0.00001550
Iteration 9/1000 | Loss: 0.00001512
Iteration 10/1000 | Loss: 0.00001483
Iteration 11/1000 | Loss: 0.00001461
Iteration 12/1000 | Loss: 0.00001453
Iteration 13/1000 | Loss: 0.00001452
Iteration 14/1000 | Loss: 0.00001451
Iteration 15/1000 | Loss: 0.00001451
Iteration 16/1000 | Loss: 0.00001451
Iteration 17/1000 | Loss: 0.00001450
Iteration 18/1000 | Loss: 0.00001450
Iteration 19/1000 | Loss: 0.00001448
Iteration 20/1000 | Loss: 0.00001448
Iteration 21/1000 | Loss: 0.00001447
Iteration 22/1000 | Loss: 0.00001446
Iteration 23/1000 | Loss: 0.00001446
Iteration 24/1000 | Loss: 0.00001445
Iteration 25/1000 | Loss: 0.00001440
Iteration 26/1000 | Loss: 0.00001435
Iteration 27/1000 | Loss: 0.00001434
Iteration 28/1000 | Loss: 0.00001433
Iteration 29/1000 | Loss: 0.00001433
Iteration 30/1000 | Loss: 0.00001432
Iteration 31/1000 | Loss: 0.00001427
Iteration 32/1000 | Loss: 0.00001424
Iteration 33/1000 | Loss: 0.00001423
Iteration 34/1000 | Loss: 0.00001422
Iteration 35/1000 | Loss: 0.00001421
Iteration 36/1000 | Loss: 0.00001420
Iteration 37/1000 | Loss: 0.00001420
Iteration 38/1000 | Loss: 0.00001419
Iteration 39/1000 | Loss: 0.00001419
Iteration 40/1000 | Loss: 0.00001415
Iteration 41/1000 | Loss: 0.00001413
Iteration 42/1000 | Loss: 0.00001410
Iteration 43/1000 | Loss: 0.00001408
Iteration 44/1000 | Loss: 0.00001408
Iteration 45/1000 | Loss: 0.00001405
Iteration 46/1000 | Loss: 0.00001405
Iteration 47/1000 | Loss: 0.00001403
Iteration 48/1000 | Loss: 0.00001403
Iteration 49/1000 | Loss: 0.00001402
Iteration 50/1000 | Loss: 0.00001402
Iteration 51/1000 | Loss: 0.00001401
Iteration 52/1000 | Loss: 0.00001401
Iteration 53/1000 | Loss: 0.00001401
Iteration 54/1000 | Loss: 0.00001400
Iteration 55/1000 | Loss: 0.00001400
Iteration 56/1000 | Loss: 0.00001399
Iteration 57/1000 | Loss: 0.00001399
Iteration 58/1000 | Loss: 0.00001399
Iteration 59/1000 | Loss: 0.00001398
Iteration 60/1000 | Loss: 0.00001398
Iteration 61/1000 | Loss: 0.00001397
Iteration 62/1000 | Loss: 0.00001397
Iteration 63/1000 | Loss: 0.00001397
Iteration 64/1000 | Loss: 0.00001396
Iteration 65/1000 | Loss: 0.00001396
Iteration 66/1000 | Loss: 0.00001396
Iteration 67/1000 | Loss: 0.00001395
Iteration 68/1000 | Loss: 0.00001395
Iteration 69/1000 | Loss: 0.00001395
Iteration 70/1000 | Loss: 0.00001394
Iteration 71/1000 | Loss: 0.00001394
Iteration 72/1000 | Loss: 0.00001394
Iteration 73/1000 | Loss: 0.00001394
Iteration 74/1000 | Loss: 0.00001393
Iteration 75/1000 | Loss: 0.00001393
Iteration 76/1000 | Loss: 0.00001393
Iteration 77/1000 | Loss: 0.00001393
Iteration 78/1000 | Loss: 0.00001393
Iteration 79/1000 | Loss: 0.00001393
Iteration 80/1000 | Loss: 0.00001393
Iteration 81/1000 | Loss: 0.00001393
Iteration 82/1000 | Loss: 0.00001392
Iteration 83/1000 | Loss: 0.00001392
Iteration 84/1000 | Loss: 0.00001392
Iteration 85/1000 | Loss: 0.00001392
Iteration 86/1000 | Loss: 0.00001392
Iteration 87/1000 | Loss: 0.00001392
Iteration 88/1000 | Loss: 0.00001392
Iteration 89/1000 | Loss: 0.00001392
Iteration 90/1000 | Loss: 0.00001392
Iteration 91/1000 | Loss: 0.00001391
Iteration 92/1000 | Loss: 0.00001391
Iteration 93/1000 | Loss: 0.00001391
Iteration 94/1000 | Loss: 0.00001391
Iteration 95/1000 | Loss: 0.00001391
Iteration 96/1000 | Loss: 0.00001390
Iteration 97/1000 | Loss: 0.00001390
Iteration 98/1000 | Loss: 0.00001390
Iteration 99/1000 | Loss: 0.00001390
Iteration 100/1000 | Loss: 0.00001390
Iteration 101/1000 | Loss: 0.00001390
Iteration 102/1000 | Loss: 0.00001390
Iteration 103/1000 | Loss: 0.00001390
Iteration 104/1000 | Loss: 0.00001389
Iteration 105/1000 | Loss: 0.00001389
Iteration 106/1000 | Loss: 0.00001389
Iteration 107/1000 | Loss: 0.00001389
Iteration 108/1000 | Loss: 0.00001389
Iteration 109/1000 | Loss: 0.00001389
Iteration 110/1000 | Loss: 0.00001389
Iteration 111/1000 | Loss: 0.00001389
Iteration 112/1000 | Loss: 0.00001389
Iteration 113/1000 | Loss: 0.00001389
Iteration 114/1000 | Loss: 0.00001388
Iteration 115/1000 | Loss: 0.00001388
Iteration 116/1000 | Loss: 0.00001388
Iteration 117/1000 | Loss: 0.00001388
Iteration 118/1000 | Loss: 0.00001388
Iteration 119/1000 | Loss: 0.00001388
Iteration 120/1000 | Loss: 0.00001388
Iteration 121/1000 | Loss: 0.00001387
Iteration 122/1000 | Loss: 0.00001387
Iteration 123/1000 | Loss: 0.00001387
Iteration 124/1000 | Loss: 0.00001387
Iteration 125/1000 | Loss: 0.00001387
Iteration 126/1000 | Loss: 0.00001387
Iteration 127/1000 | Loss: 0.00001387
Iteration 128/1000 | Loss: 0.00001387
Iteration 129/1000 | Loss: 0.00001387
Iteration 130/1000 | Loss: 0.00001387
Iteration 131/1000 | Loss: 0.00001387
Iteration 132/1000 | Loss: 0.00001387
Iteration 133/1000 | Loss: 0.00001387
Iteration 134/1000 | Loss: 0.00001387
Iteration 135/1000 | Loss: 0.00001386
Iteration 136/1000 | Loss: 0.00001386
Iteration 137/1000 | Loss: 0.00001386
Iteration 138/1000 | Loss: 0.00001386
Iteration 139/1000 | Loss: 0.00001386
Iteration 140/1000 | Loss: 0.00001386
Iteration 141/1000 | Loss: 0.00001386
Iteration 142/1000 | Loss: 0.00001386
Iteration 143/1000 | Loss: 0.00001385
Iteration 144/1000 | Loss: 0.00001385
Iteration 145/1000 | Loss: 0.00001385
Iteration 146/1000 | Loss: 0.00001385
Iteration 147/1000 | Loss: 0.00001385
Iteration 148/1000 | Loss: 0.00001385
Iteration 149/1000 | Loss: 0.00001385
Iteration 150/1000 | Loss: 0.00001385
Iteration 151/1000 | Loss: 0.00001384
Iteration 152/1000 | Loss: 0.00001384
Iteration 153/1000 | Loss: 0.00001384
Iteration 154/1000 | Loss: 0.00001384
Iteration 155/1000 | Loss: 0.00001384
Iteration 156/1000 | Loss: 0.00001384
Iteration 157/1000 | Loss: 0.00001384
Iteration 158/1000 | Loss: 0.00001384
Iteration 159/1000 | Loss: 0.00001384
Iteration 160/1000 | Loss: 0.00001384
Iteration 161/1000 | Loss: 0.00001384
Iteration 162/1000 | Loss: 0.00001384
Iteration 163/1000 | Loss: 0.00001384
Iteration 164/1000 | Loss: 0.00001384
Iteration 165/1000 | Loss: 0.00001383
Iteration 166/1000 | Loss: 0.00001383
Iteration 167/1000 | Loss: 0.00001383
Iteration 168/1000 | Loss: 0.00001383
Iteration 169/1000 | Loss: 0.00001383
Iteration 170/1000 | Loss: 0.00001383
Iteration 171/1000 | Loss: 0.00001383
Iteration 172/1000 | Loss: 0.00001383
Iteration 173/1000 | Loss: 0.00001383
Iteration 174/1000 | Loss: 0.00001383
Iteration 175/1000 | Loss: 0.00001383
Iteration 176/1000 | Loss: 0.00001383
Iteration 177/1000 | Loss: 0.00001383
Iteration 178/1000 | Loss: 0.00001383
Iteration 179/1000 | Loss: 0.00001383
Iteration 180/1000 | Loss: 0.00001383
Iteration 181/1000 | Loss: 0.00001383
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.3828014743921813e-05, 1.3828014743921813e-05, 1.3828014743921813e-05, 1.3828014743921813e-05, 1.3828014743921813e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3828014743921813e-05

Optimization complete. Final v2v error: 3.1566405296325684 mm

Highest mean error: 3.7068843841552734 mm for frame 10

Lowest mean error: 2.629451274871826 mm for frame 102

Saving results

Total time: 43.31617832183838
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00998544
Iteration 2/25 | Loss: 0.00153269
Iteration 3/25 | Loss: 0.00095141
Iteration 4/25 | Loss: 0.00087788
Iteration 5/25 | Loss: 0.00085073
Iteration 6/25 | Loss: 0.00084439
Iteration 7/25 | Loss: 0.00084578
Iteration 8/25 | Loss: 0.00084270
Iteration 9/25 | Loss: 0.00084101
Iteration 10/25 | Loss: 0.00083902
Iteration 11/25 | Loss: 0.00083827
Iteration 12/25 | Loss: 0.00083989
Iteration 13/25 | Loss: 0.00083765
Iteration 14/25 | Loss: 0.00084039
Iteration 15/25 | Loss: 0.00083759
Iteration 16/25 | Loss: 0.00083759
Iteration 17/25 | Loss: 0.00083758
Iteration 18/25 | Loss: 0.00083758
Iteration 19/25 | Loss: 0.00083758
Iteration 20/25 | Loss: 0.00083758
Iteration 21/25 | Loss: 0.00083758
Iteration 22/25 | Loss: 0.00083758
Iteration 23/25 | Loss: 0.00083758
Iteration 24/25 | Loss: 0.00083757
Iteration 25/25 | Loss: 0.00083757

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.01181364
Iteration 2/25 | Loss: 0.00062448
Iteration 3/25 | Loss: 0.00062439
Iteration 4/25 | Loss: 0.00062438
Iteration 5/25 | Loss: 0.00062438
Iteration 6/25 | Loss: 0.00062438
Iteration 7/25 | Loss: 0.00062438
Iteration 8/25 | Loss: 0.00062438
Iteration 9/25 | Loss: 0.00062438
Iteration 10/25 | Loss: 0.00062438
Iteration 11/25 | Loss: 0.00062438
Iteration 12/25 | Loss: 0.00062438
Iteration 13/25 | Loss: 0.00062438
Iteration 14/25 | Loss: 0.00062438
Iteration 15/25 | Loss: 0.00062438
Iteration 16/25 | Loss: 0.00062438
Iteration 17/25 | Loss: 0.00062438
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006243822281248868, 0.0006243822281248868, 0.0006243822281248868, 0.0006243822281248868, 0.0006243822281248868]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006243822281248868

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062438
Iteration 2/1000 | Loss: 0.00003676
Iteration 3/1000 | Loss: 0.00002596
Iteration 4/1000 | Loss: 0.00002328
Iteration 5/1000 | Loss: 0.00002215
Iteration 6/1000 | Loss: 0.00002066
Iteration 7/1000 | Loss: 0.00002004
Iteration 8/1000 | Loss: 0.00001943
Iteration 9/1000 | Loss: 0.00001908
Iteration 10/1000 | Loss: 0.00001885
Iteration 11/1000 | Loss: 0.00001861
Iteration 12/1000 | Loss: 0.00001849
Iteration 13/1000 | Loss: 0.00001832
Iteration 14/1000 | Loss: 0.00001819
Iteration 15/1000 | Loss: 0.00001814
Iteration 16/1000 | Loss: 0.00004768
Iteration 17/1000 | Loss: 0.00001810
Iteration 18/1000 | Loss: 0.00001802
Iteration 19/1000 | Loss: 0.00001802
Iteration 20/1000 | Loss: 0.00001802
Iteration 21/1000 | Loss: 0.00001802
Iteration 22/1000 | Loss: 0.00001802
Iteration 23/1000 | Loss: 0.00001802
Iteration 24/1000 | Loss: 0.00001802
Iteration 25/1000 | Loss: 0.00001802
Iteration 26/1000 | Loss: 0.00001802
Iteration 27/1000 | Loss: 0.00001801
Iteration 28/1000 | Loss: 0.00001801
Iteration 29/1000 | Loss: 0.00001801
Iteration 30/1000 | Loss: 0.00001798
Iteration 31/1000 | Loss: 0.00001798
Iteration 32/1000 | Loss: 0.00001796
Iteration 33/1000 | Loss: 0.00001795
Iteration 34/1000 | Loss: 0.00001795
Iteration 35/1000 | Loss: 0.00001795
Iteration 36/1000 | Loss: 0.00001795
Iteration 37/1000 | Loss: 0.00001795
Iteration 38/1000 | Loss: 0.00001795
Iteration 39/1000 | Loss: 0.00001795
Iteration 40/1000 | Loss: 0.00001795
Iteration 41/1000 | Loss: 0.00001795
Iteration 42/1000 | Loss: 0.00003476
Iteration 43/1000 | Loss: 0.00002249
Iteration 44/1000 | Loss: 0.00001794
Iteration 45/1000 | Loss: 0.00001792
Iteration 46/1000 | Loss: 0.00001792
Iteration 47/1000 | Loss: 0.00001792
Iteration 48/1000 | Loss: 0.00001792
Iteration 49/1000 | Loss: 0.00001792
Iteration 50/1000 | Loss: 0.00001791
Iteration 51/1000 | Loss: 0.00001791
Iteration 52/1000 | Loss: 0.00001791
Iteration 53/1000 | Loss: 0.00001791
Iteration 54/1000 | Loss: 0.00001791
Iteration 55/1000 | Loss: 0.00001791
Iteration 56/1000 | Loss: 0.00001791
Iteration 57/1000 | Loss: 0.00001791
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 57. Stopping optimization.
Last 5 losses: [1.791394424799364e-05, 1.791394424799364e-05, 1.791394424799364e-05, 1.791394424799364e-05, 1.791394424799364e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.791394424799364e-05

Optimization complete. Final v2v error: 3.4980926513671875 mm

Highest mean error: 6.270601272583008 mm for frame 131

Lowest mean error: 3.009291648864746 mm for frame 142

Saving results

Total time: 60.361883878707886
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01082804
Iteration 2/25 | Loss: 0.00215795
Iteration 3/25 | Loss: 0.00155395
Iteration 4/25 | Loss: 0.00160343
Iteration 5/25 | Loss: 0.00134273
Iteration 6/25 | Loss: 0.00114710
Iteration 7/25 | Loss: 0.00116325
Iteration 8/25 | Loss: 0.00113547
Iteration 9/25 | Loss: 0.00106124
Iteration 10/25 | Loss: 0.00102350
Iteration 11/25 | Loss: 0.00102131
Iteration 12/25 | Loss: 0.00100847
Iteration 13/25 | Loss: 0.00100142
Iteration 14/25 | Loss: 0.00100040
Iteration 15/25 | Loss: 0.00100026
Iteration 16/25 | Loss: 0.00100025
Iteration 17/25 | Loss: 0.00100025
Iteration 18/25 | Loss: 0.00100025
Iteration 19/25 | Loss: 0.00100025
Iteration 20/25 | Loss: 0.00100025
Iteration 21/25 | Loss: 0.00100025
Iteration 22/25 | Loss: 0.00100025
Iteration 23/25 | Loss: 0.00100024
Iteration 24/25 | Loss: 0.00100024
Iteration 25/25 | Loss: 0.00100024

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.90957284
Iteration 2/25 | Loss: 0.00085767
Iteration 3/25 | Loss: 0.00085742
Iteration 4/25 | Loss: 0.00085742
Iteration 5/25 | Loss: 0.00085742
Iteration 6/25 | Loss: 0.00085742
Iteration 7/25 | Loss: 0.00085742
Iteration 8/25 | Loss: 0.00085742
Iteration 9/25 | Loss: 0.00085742
Iteration 10/25 | Loss: 0.00085742
Iteration 11/25 | Loss: 0.00085742
Iteration 12/25 | Loss: 0.00085742
Iteration 13/25 | Loss: 0.00085742
Iteration 14/25 | Loss: 0.00085742
Iteration 15/25 | Loss: 0.00085742
Iteration 16/25 | Loss: 0.00085742
Iteration 17/25 | Loss: 0.00085742
Iteration 18/25 | Loss: 0.00085742
Iteration 19/25 | Loss: 0.00085742
Iteration 20/25 | Loss: 0.00085742
Iteration 21/25 | Loss: 0.00085742
Iteration 22/25 | Loss: 0.00085742
Iteration 23/25 | Loss: 0.00085742
Iteration 24/25 | Loss: 0.00085742
Iteration 25/25 | Loss: 0.00085742

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085742
Iteration 2/1000 | Loss: 0.00009508
Iteration 3/1000 | Loss: 0.00006930
Iteration 4/1000 | Loss: 0.00005447
Iteration 5/1000 | Loss: 0.00004993
Iteration 6/1000 | Loss: 0.00004710
Iteration 7/1000 | Loss: 0.00004547
Iteration 8/1000 | Loss: 0.00004422
Iteration 9/1000 | Loss: 0.00004322
Iteration 10/1000 | Loss: 0.00004250
Iteration 11/1000 | Loss: 0.00004176
Iteration 12/1000 | Loss: 0.00004119
Iteration 13/1000 | Loss: 0.00004085
Iteration 14/1000 | Loss: 0.00004051
Iteration 15/1000 | Loss: 0.00004023
Iteration 16/1000 | Loss: 0.00003995
Iteration 17/1000 | Loss: 0.00003974
Iteration 18/1000 | Loss: 0.00003958
Iteration 19/1000 | Loss: 0.00003942
Iteration 20/1000 | Loss: 0.00003925
Iteration 21/1000 | Loss: 0.00003911
Iteration 22/1000 | Loss: 0.00003902
Iteration 23/1000 | Loss: 0.00003898
Iteration 24/1000 | Loss: 0.00003898
Iteration 25/1000 | Loss: 0.00003897
Iteration 26/1000 | Loss: 0.00003896
Iteration 27/1000 | Loss: 0.00003896
Iteration 28/1000 | Loss: 0.00003895
Iteration 29/1000 | Loss: 0.00003893
Iteration 30/1000 | Loss: 0.00003893
Iteration 31/1000 | Loss: 0.00003893
Iteration 32/1000 | Loss: 0.00003892
Iteration 33/1000 | Loss: 0.00003892
Iteration 34/1000 | Loss: 0.00003891
Iteration 35/1000 | Loss: 0.00003890
Iteration 36/1000 | Loss: 0.00003890
Iteration 37/1000 | Loss: 0.00003890
Iteration 38/1000 | Loss: 0.00003889
Iteration 39/1000 | Loss: 0.00003889
Iteration 40/1000 | Loss: 0.00003889
Iteration 41/1000 | Loss: 0.00003888
Iteration 42/1000 | Loss: 0.00003888
Iteration 43/1000 | Loss: 0.00003887
Iteration 44/1000 | Loss: 0.00003887
Iteration 45/1000 | Loss: 0.00003887
Iteration 46/1000 | Loss: 0.00003886
Iteration 47/1000 | Loss: 0.00003886
Iteration 48/1000 | Loss: 0.00003886
Iteration 49/1000 | Loss: 0.00003886
Iteration 50/1000 | Loss: 0.00003886
Iteration 51/1000 | Loss: 0.00003886
Iteration 52/1000 | Loss: 0.00003885
Iteration 53/1000 | Loss: 0.00003885
Iteration 54/1000 | Loss: 0.00003884
Iteration 55/1000 | Loss: 0.00003884
Iteration 56/1000 | Loss: 0.00003883
Iteration 57/1000 | Loss: 0.00003883
Iteration 58/1000 | Loss: 0.00003882
Iteration 59/1000 | Loss: 0.00003882
Iteration 60/1000 | Loss: 0.00003882
Iteration 61/1000 | Loss: 0.00003882
Iteration 62/1000 | Loss: 0.00003881
Iteration 63/1000 | Loss: 0.00003881
Iteration 64/1000 | Loss: 0.00003880
Iteration 65/1000 | Loss: 0.00003880
Iteration 66/1000 | Loss: 0.00003880
Iteration 67/1000 | Loss: 0.00003880
Iteration 68/1000 | Loss: 0.00003879
Iteration 69/1000 | Loss: 0.00003879
Iteration 70/1000 | Loss: 0.00003879
Iteration 71/1000 | Loss: 0.00003878
Iteration 72/1000 | Loss: 0.00003878
Iteration 73/1000 | Loss: 0.00003877
Iteration 74/1000 | Loss: 0.00003877
Iteration 75/1000 | Loss: 0.00003877
Iteration 76/1000 | Loss: 0.00003877
Iteration 77/1000 | Loss: 0.00003877
Iteration 78/1000 | Loss: 0.00003877
Iteration 79/1000 | Loss: 0.00003876
Iteration 80/1000 | Loss: 0.00003876
Iteration 81/1000 | Loss: 0.00003876
Iteration 82/1000 | Loss: 0.00003876
Iteration 83/1000 | Loss: 0.00003876
Iteration 84/1000 | Loss: 0.00003875
Iteration 85/1000 | Loss: 0.00003875
Iteration 86/1000 | Loss: 0.00003875
Iteration 87/1000 | Loss: 0.00003874
Iteration 88/1000 | Loss: 0.00003874
Iteration 89/1000 | Loss: 0.00003874
Iteration 90/1000 | Loss: 0.00003874
Iteration 91/1000 | Loss: 0.00003873
Iteration 92/1000 | Loss: 0.00003873
Iteration 93/1000 | Loss: 0.00003873
Iteration 94/1000 | Loss: 0.00003873
Iteration 95/1000 | Loss: 0.00003873
Iteration 96/1000 | Loss: 0.00003872
Iteration 97/1000 | Loss: 0.00003872
Iteration 98/1000 | Loss: 0.00003872
Iteration 99/1000 | Loss: 0.00003872
Iteration 100/1000 | Loss: 0.00003871
Iteration 101/1000 | Loss: 0.00003871
Iteration 102/1000 | Loss: 0.00003871
Iteration 103/1000 | Loss: 0.00003871
Iteration 104/1000 | Loss: 0.00003871
Iteration 105/1000 | Loss: 0.00003871
Iteration 106/1000 | Loss: 0.00003870
Iteration 107/1000 | Loss: 0.00003870
Iteration 108/1000 | Loss: 0.00003870
Iteration 109/1000 | Loss: 0.00003870
Iteration 110/1000 | Loss: 0.00003870
Iteration 111/1000 | Loss: 0.00003870
Iteration 112/1000 | Loss: 0.00003869
Iteration 113/1000 | Loss: 0.00003869
Iteration 114/1000 | Loss: 0.00003869
Iteration 115/1000 | Loss: 0.00003869
Iteration 116/1000 | Loss: 0.00003868
Iteration 117/1000 | Loss: 0.00003868
Iteration 118/1000 | Loss: 0.00003868
Iteration 119/1000 | Loss: 0.00003868
Iteration 120/1000 | Loss: 0.00003868
Iteration 121/1000 | Loss: 0.00003868
Iteration 122/1000 | Loss: 0.00003867
Iteration 123/1000 | Loss: 0.00003867
Iteration 124/1000 | Loss: 0.00003867
Iteration 125/1000 | Loss: 0.00003867
Iteration 126/1000 | Loss: 0.00003867
Iteration 127/1000 | Loss: 0.00003867
Iteration 128/1000 | Loss: 0.00003867
Iteration 129/1000 | Loss: 0.00003867
Iteration 130/1000 | Loss: 0.00003867
Iteration 131/1000 | Loss: 0.00003866
Iteration 132/1000 | Loss: 0.00003866
Iteration 133/1000 | Loss: 0.00003866
Iteration 134/1000 | Loss: 0.00003866
Iteration 135/1000 | Loss: 0.00003866
Iteration 136/1000 | Loss: 0.00003866
Iteration 137/1000 | Loss: 0.00003866
Iteration 138/1000 | Loss: 0.00003866
Iteration 139/1000 | Loss: 0.00003865
Iteration 140/1000 | Loss: 0.00003865
Iteration 141/1000 | Loss: 0.00003865
Iteration 142/1000 | Loss: 0.00003865
Iteration 143/1000 | Loss: 0.00003865
Iteration 144/1000 | Loss: 0.00003865
Iteration 145/1000 | Loss: 0.00003865
Iteration 146/1000 | Loss: 0.00003865
Iteration 147/1000 | Loss: 0.00003865
Iteration 148/1000 | Loss: 0.00003865
Iteration 149/1000 | Loss: 0.00003865
Iteration 150/1000 | Loss: 0.00003865
Iteration 151/1000 | Loss: 0.00003865
Iteration 152/1000 | Loss: 0.00003864
Iteration 153/1000 | Loss: 0.00003864
Iteration 154/1000 | Loss: 0.00003864
Iteration 155/1000 | Loss: 0.00003864
Iteration 156/1000 | Loss: 0.00003864
Iteration 157/1000 | Loss: 0.00003864
Iteration 158/1000 | Loss: 0.00003864
Iteration 159/1000 | Loss: 0.00003864
Iteration 160/1000 | Loss: 0.00003864
Iteration 161/1000 | Loss: 0.00003864
Iteration 162/1000 | Loss: 0.00003863
Iteration 163/1000 | Loss: 0.00003863
Iteration 164/1000 | Loss: 0.00003863
Iteration 165/1000 | Loss: 0.00003863
Iteration 166/1000 | Loss: 0.00003863
Iteration 167/1000 | Loss: 0.00003863
Iteration 168/1000 | Loss: 0.00003863
Iteration 169/1000 | Loss: 0.00003863
Iteration 170/1000 | Loss: 0.00003862
Iteration 171/1000 | Loss: 0.00003862
Iteration 172/1000 | Loss: 0.00003862
Iteration 173/1000 | Loss: 0.00003862
Iteration 174/1000 | Loss: 0.00003862
Iteration 175/1000 | Loss: 0.00003862
Iteration 176/1000 | Loss: 0.00003862
Iteration 177/1000 | Loss: 0.00003862
Iteration 178/1000 | Loss: 0.00003862
Iteration 179/1000 | Loss: 0.00003862
Iteration 180/1000 | Loss: 0.00003862
Iteration 181/1000 | Loss: 0.00003862
Iteration 182/1000 | Loss: 0.00003862
Iteration 183/1000 | Loss: 0.00003862
Iteration 184/1000 | Loss: 0.00003861
Iteration 185/1000 | Loss: 0.00003861
Iteration 186/1000 | Loss: 0.00003861
Iteration 187/1000 | Loss: 0.00003861
Iteration 188/1000 | Loss: 0.00003861
Iteration 189/1000 | Loss: 0.00003861
Iteration 190/1000 | Loss: 0.00003861
Iteration 191/1000 | Loss: 0.00003861
Iteration 192/1000 | Loss: 0.00003861
Iteration 193/1000 | Loss: 0.00003861
Iteration 194/1000 | Loss: 0.00003861
Iteration 195/1000 | Loss: 0.00003861
Iteration 196/1000 | Loss: 0.00003861
Iteration 197/1000 | Loss: 0.00003861
Iteration 198/1000 | Loss: 0.00003861
Iteration 199/1000 | Loss: 0.00003861
Iteration 200/1000 | Loss: 0.00003861
Iteration 201/1000 | Loss: 0.00003861
Iteration 202/1000 | Loss: 0.00003861
Iteration 203/1000 | Loss: 0.00003861
Iteration 204/1000 | Loss: 0.00003861
Iteration 205/1000 | Loss: 0.00003861
Iteration 206/1000 | Loss: 0.00003861
Iteration 207/1000 | Loss: 0.00003861
Iteration 208/1000 | Loss: 0.00003861
Iteration 209/1000 | Loss: 0.00003861
Iteration 210/1000 | Loss: 0.00003861
Iteration 211/1000 | Loss: 0.00003861
Iteration 212/1000 | Loss: 0.00003861
Iteration 213/1000 | Loss: 0.00003861
Iteration 214/1000 | Loss: 0.00003861
Iteration 215/1000 | Loss: 0.00003861
Iteration 216/1000 | Loss: 0.00003861
Iteration 217/1000 | Loss: 0.00003861
Iteration 218/1000 | Loss: 0.00003861
Iteration 219/1000 | Loss: 0.00003861
Iteration 220/1000 | Loss: 0.00003861
Iteration 221/1000 | Loss: 0.00003861
Iteration 222/1000 | Loss: 0.00003861
Iteration 223/1000 | Loss: 0.00003861
Iteration 224/1000 | Loss: 0.00003861
Iteration 225/1000 | Loss: 0.00003861
Iteration 226/1000 | Loss: 0.00003861
Iteration 227/1000 | Loss: 0.00003861
Iteration 228/1000 | Loss: 0.00003861
Iteration 229/1000 | Loss: 0.00003861
Iteration 230/1000 | Loss: 0.00003861
Iteration 231/1000 | Loss: 0.00003861
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 231. Stopping optimization.
Last 5 losses: [3.8610138290096074e-05, 3.8610138290096074e-05, 3.8610138290096074e-05, 3.8610138290096074e-05, 3.8610138290096074e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.8610138290096074e-05

Optimization complete. Final v2v error: 5.018772602081299 mm

Highest mean error: 6.529595851898193 mm for frame 87

Lowest mean error: 3.5076301097869873 mm for frame 124

Saving results

Total time: 70.67500805854797
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1037/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1037.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1037
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01160697
Iteration 2/25 | Loss: 0.00209537
Iteration 3/25 | Loss: 0.00137957
Iteration 4/25 | Loss: 0.00119836
Iteration 5/25 | Loss: 0.00113491
Iteration 6/25 | Loss: 0.00109965
Iteration 7/25 | Loss: 0.00107478
Iteration 8/25 | Loss: 0.00107622
Iteration 9/25 | Loss: 0.00106458
Iteration 10/25 | Loss: 0.00106159
Iteration 11/25 | Loss: 0.00105794
Iteration 12/25 | Loss: 0.00105786
Iteration 13/25 | Loss: 0.00105776
Iteration 14/25 | Loss: 0.00105468
Iteration 15/25 | Loss: 0.00105353
Iteration 16/25 | Loss: 0.00105292
Iteration 17/25 | Loss: 0.00105275
Iteration 18/25 | Loss: 0.00105273
Iteration 19/25 | Loss: 0.00105273
Iteration 20/25 | Loss: 0.00105273
Iteration 21/25 | Loss: 0.00105273
Iteration 22/25 | Loss: 0.00105273
Iteration 23/25 | Loss: 0.00105273
Iteration 24/25 | Loss: 0.00105273
Iteration 25/25 | Loss: 0.00105273

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.89934427
Iteration 2/25 | Loss: 0.00071506
Iteration 3/25 | Loss: 0.00071506
Iteration 4/25 | Loss: 0.00071506
Iteration 5/25 | Loss: 0.00071506
Iteration 6/25 | Loss: 0.00071506
Iteration 7/25 | Loss: 0.00071506
Iteration 8/25 | Loss: 0.00071506
Iteration 9/25 | Loss: 0.00071506
Iteration 10/25 | Loss: 0.00071506
Iteration 11/25 | Loss: 0.00071506
Iteration 12/25 | Loss: 0.00071506
Iteration 13/25 | Loss: 0.00071506
Iteration 14/25 | Loss: 0.00071506
Iteration 15/25 | Loss: 0.00071506
Iteration 16/25 | Loss: 0.00071506
Iteration 17/25 | Loss: 0.00071506
Iteration 18/25 | Loss: 0.00071506
Iteration 19/25 | Loss: 0.00071506
Iteration 20/25 | Loss: 0.00071506
Iteration 21/25 | Loss: 0.00071506
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007150605088099837, 0.0007150605088099837, 0.0007150605088099837, 0.0007150605088099837, 0.0007150605088099837]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007150605088099837

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071506
Iteration 2/1000 | Loss: 0.00008150
Iteration 3/1000 | Loss: 0.00037692
Iteration 4/1000 | Loss: 0.00006474
Iteration 5/1000 | Loss: 0.00041160
Iteration 6/1000 | Loss: 0.00042286
Iteration 7/1000 | Loss: 0.00006485
Iteration 8/1000 | Loss: 0.00005371
Iteration 9/1000 | Loss: 0.00004978
Iteration 10/1000 | Loss: 0.00004590
Iteration 11/1000 | Loss: 0.00004428
Iteration 12/1000 | Loss: 0.00004359
Iteration 13/1000 | Loss: 0.00004281
Iteration 14/1000 | Loss: 0.00004244
Iteration 15/1000 | Loss: 0.00004195
Iteration 16/1000 | Loss: 0.00004154
Iteration 17/1000 | Loss: 0.00004130
Iteration 18/1000 | Loss: 0.00004105
Iteration 19/1000 | Loss: 0.00004083
Iteration 20/1000 | Loss: 0.00004068
Iteration 21/1000 | Loss: 0.00004067
Iteration 22/1000 | Loss: 0.00004055
Iteration 23/1000 | Loss: 0.00004045
Iteration 24/1000 | Loss: 0.00004044
Iteration 25/1000 | Loss: 0.00004044
Iteration 26/1000 | Loss: 0.00004037
Iteration 27/1000 | Loss: 0.00004033
Iteration 28/1000 | Loss: 0.00004032
Iteration 29/1000 | Loss: 0.00004026
Iteration 30/1000 | Loss: 0.00004011
Iteration 31/1000 | Loss: 0.00004005
Iteration 32/1000 | Loss: 0.00003996
Iteration 33/1000 | Loss: 0.00003996
Iteration 34/1000 | Loss: 0.00003994
Iteration 35/1000 | Loss: 0.00003994
Iteration 36/1000 | Loss: 0.00003994
Iteration 37/1000 | Loss: 0.00003994
Iteration 38/1000 | Loss: 0.00003993
Iteration 39/1000 | Loss: 0.00003993
Iteration 40/1000 | Loss: 0.00003993
Iteration 41/1000 | Loss: 0.00003993
Iteration 42/1000 | Loss: 0.00003993
Iteration 43/1000 | Loss: 0.00003992
Iteration 44/1000 | Loss: 0.00003992
Iteration 45/1000 | Loss: 0.00003992
Iteration 46/1000 | Loss: 0.00003991
Iteration 47/1000 | Loss: 0.00003991
Iteration 48/1000 | Loss: 0.00003991
Iteration 49/1000 | Loss: 0.00003991
Iteration 50/1000 | Loss: 0.00003991
Iteration 51/1000 | Loss: 0.00003991
Iteration 52/1000 | Loss: 0.00003990
Iteration 53/1000 | Loss: 0.00003990
Iteration 54/1000 | Loss: 0.00003990
Iteration 55/1000 | Loss: 0.00003990
Iteration 56/1000 | Loss: 0.00003990
Iteration 57/1000 | Loss: 0.00003990
Iteration 58/1000 | Loss: 0.00003990
Iteration 59/1000 | Loss: 0.00003990
Iteration 60/1000 | Loss: 0.00003990
Iteration 61/1000 | Loss: 0.00003990
Iteration 62/1000 | Loss: 0.00003990
Iteration 63/1000 | Loss: 0.00003990
Iteration 64/1000 | Loss: 0.00003989
Iteration 65/1000 | Loss: 0.00003989
Iteration 66/1000 | Loss: 0.00003989
Iteration 67/1000 | Loss: 0.00003989
Iteration 68/1000 | Loss: 0.00003989
Iteration 69/1000 | Loss: 0.00003986
Iteration 70/1000 | Loss: 0.00003985
Iteration 71/1000 | Loss: 0.00003985
Iteration 72/1000 | Loss: 0.00003984
Iteration 73/1000 | Loss: 0.00003984
Iteration 74/1000 | Loss: 0.00003982
Iteration 75/1000 | Loss: 0.00003982
Iteration 76/1000 | Loss: 0.00003982
Iteration 77/1000 | Loss: 0.00003982
Iteration 78/1000 | Loss: 0.00003982
Iteration 79/1000 | Loss: 0.00003982
Iteration 80/1000 | Loss: 0.00003982
Iteration 81/1000 | Loss: 0.00003982
Iteration 82/1000 | Loss: 0.00003981
Iteration 83/1000 | Loss: 0.00003981
Iteration 84/1000 | Loss: 0.00003981
Iteration 85/1000 | Loss: 0.00003981
Iteration 86/1000 | Loss: 0.00003981
Iteration 87/1000 | Loss: 0.00003980
Iteration 88/1000 | Loss: 0.00003980
Iteration 89/1000 | Loss: 0.00003979
Iteration 90/1000 | Loss: 0.00003979
Iteration 91/1000 | Loss: 0.00003979
Iteration 92/1000 | Loss: 0.00003978
Iteration 93/1000 | Loss: 0.00003978
Iteration 94/1000 | Loss: 0.00003978
Iteration 95/1000 | Loss: 0.00003978
Iteration 96/1000 | Loss: 0.00003978
Iteration 97/1000 | Loss: 0.00003978
Iteration 98/1000 | Loss: 0.00003978
Iteration 99/1000 | Loss: 0.00003978
Iteration 100/1000 | Loss: 0.00003978
Iteration 101/1000 | Loss: 0.00003977
Iteration 102/1000 | Loss: 0.00003977
Iteration 103/1000 | Loss: 0.00003977
Iteration 104/1000 | Loss: 0.00003977
Iteration 105/1000 | Loss: 0.00003977
Iteration 106/1000 | Loss: 0.00003977
Iteration 107/1000 | Loss: 0.00003977
Iteration 108/1000 | Loss: 0.00003977
Iteration 109/1000 | Loss: 0.00003977
Iteration 110/1000 | Loss: 0.00003977
Iteration 111/1000 | Loss: 0.00003976
Iteration 112/1000 | Loss: 0.00003976
Iteration 113/1000 | Loss: 0.00003976
Iteration 114/1000 | Loss: 0.00003976
Iteration 115/1000 | Loss: 0.00003976
Iteration 116/1000 | Loss: 0.00003976
Iteration 117/1000 | Loss: 0.00003976
Iteration 118/1000 | Loss: 0.00003976
Iteration 119/1000 | Loss: 0.00003976
Iteration 120/1000 | Loss: 0.00003976
Iteration 121/1000 | Loss: 0.00003976
Iteration 122/1000 | Loss: 0.00003975
Iteration 123/1000 | Loss: 0.00003975
Iteration 124/1000 | Loss: 0.00003975
Iteration 125/1000 | Loss: 0.00003975
Iteration 126/1000 | Loss: 0.00003975
Iteration 127/1000 | Loss: 0.00003975
Iteration 128/1000 | Loss: 0.00003974
Iteration 129/1000 | Loss: 0.00003974
Iteration 130/1000 | Loss: 0.00003974
Iteration 131/1000 | Loss: 0.00003974
Iteration 132/1000 | Loss: 0.00003974
Iteration 133/1000 | Loss: 0.00003974
Iteration 134/1000 | Loss: 0.00003973
Iteration 135/1000 | Loss: 0.00003973
Iteration 136/1000 | Loss: 0.00003973
Iteration 137/1000 | Loss: 0.00003973
Iteration 138/1000 | Loss: 0.00003973
Iteration 139/1000 | Loss: 0.00003973
Iteration 140/1000 | Loss: 0.00003973
Iteration 141/1000 | Loss: 0.00003972
Iteration 142/1000 | Loss: 0.00003972
Iteration 143/1000 | Loss: 0.00003972
Iteration 144/1000 | Loss: 0.00003972
Iteration 145/1000 | Loss: 0.00003972
Iteration 146/1000 | Loss: 0.00003972
Iteration 147/1000 | Loss: 0.00003972
Iteration 148/1000 | Loss: 0.00003972
Iteration 149/1000 | Loss: 0.00003972
Iteration 150/1000 | Loss: 0.00003971
Iteration 151/1000 | Loss: 0.00003971
Iteration 152/1000 | Loss: 0.00003971
Iteration 153/1000 | Loss: 0.00003971
Iteration 154/1000 | Loss: 0.00003971
Iteration 155/1000 | Loss: 0.00003971
Iteration 156/1000 | Loss: 0.00003971
Iteration 157/1000 | Loss: 0.00003971
Iteration 158/1000 | Loss: 0.00003971
Iteration 159/1000 | Loss: 0.00003971
Iteration 160/1000 | Loss: 0.00003970
Iteration 161/1000 | Loss: 0.00003970
Iteration 162/1000 | Loss: 0.00003970
Iteration 163/1000 | Loss: 0.00003970
Iteration 164/1000 | Loss: 0.00003970
Iteration 165/1000 | Loss: 0.00003970
Iteration 166/1000 | Loss: 0.00003970
Iteration 167/1000 | Loss: 0.00003970
Iteration 168/1000 | Loss: 0.00003970
Iteration 169/1000 | Loss: 0.00003970
Iteration 170/1000 | Loss: 0.00003970
Iteration 171/1000 | Loss: 0.00003970
Iteration 172/1000 | Loss: 0.00003970
Iteration 173/1000 | Loss: 0.00003970
Iteration 174/1000 | Loss: 0.00003970
Iteration 175/1000 | Loss: 0.00003970
Iteration 176/1000 | Loss: 0.00003970
Iteration 177/1000 | Loss: 0.00003970
Iteration 178/1000 | Loss: 0.00003970
Iteration 179/1000 | Loss: 0.00003970
Iteration 180/1000 | Loss: 0.00003970
Iteration 181/1000 | Loss: 0.00003970
Iteration 182/1000 | Loss: 0.00003970
Iteration 183/1000 | Loss: 0.00003970
Iteration 184/1000 | Loss: 0.00003970
Iteration 185/1000 | Loss: 0.00003970
Iteration 186/1000 | Loss: 0.00003970
Iteration 187/1000 | Loss: 0.00003970
Iteration 188/1000 | Loss: 0.00003970
Iteration 189/1000 | Loss: 0.00003970
Iteration 190/1000 | Loss: 0.00003970
Iteration 191/1000 | Loss: 0.00003970
Iteration 192/1000 | Loss: 0.00003970
Iteration 193/1000 | Loss: 0.00003970
Iteration 194/1000 | Loss: 0.00003970
Iteration 195/1000 | Loss: 0.00003970
Iteration 196/1000 | Loss: 0.00003970
Iteration 197/1000 | Loss: 0.00003970
Iteration 198/1000 | Loss: 0.00003970
Iteration 199/1000 | Loss: 0.00003970
Iteration 200/1000 | Loss: 0.00003970
Iteration 201/1000 | Loss: 0.00003970
Iteration 202/1000 | Loss: 0.00003970
Iteration 203/1000 | Loss: 0.00003970
Iteration 204/1000 | Loss: 0.00003970
Iteration 205/1000 | Loss: 0.00003970
Iteration 206/1000 | Loss: 0.00003970
Iteration 207/1000 | Loss: 0.00003970
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [3.969849058194086e-05, 3.969849058194086e-05, 3.969849058194086e-05, 3.969849058194086e-05, 3.969849058194086e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.969849058194086e-05

Optimization complete. Final v2v error: 4.992659568786621 mm

Highest mean error: 5.356354713439941 mm for frame 217

Lowest mean error: 4.371016502380371 mm for frame 129

Saving results

Total time: 87.69920420646667
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1075/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1075.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1075
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468381
Iteration 2/25 | Loss: 0.00127561
Iteration 3/25 | Loss: 0.00090917
Iteration 4/25 | Loss: 0.00084404
Iteration 5/25 | Loss: 0.00082860
Iteration 6/25 | Loss: 0.00082406
Iteration 7/25 | Loss: 0.00082268
Iteration 8/25 | Loss: 0.00082239
Iteration 9/25 | Loss: 0.00082239
Iteration 10/25 | Loss: 0.00082239
Iteration 11/25 | Loss: 0.00082239
Iteration 12/25 | Loss: 0.00082239
Iteration 13/25 | Loss: 0.00082239
Iteration 14/25 | Loss: 0.00082239
Iteration 15/25 | Loss: 0.00082239
Iteration 16/25 | Loss: 0.00082239
Iteration 17/25 | Loss: 0.00082239
Iteration 18/25 | Loss: 0.00082239
Iteration 19/25 | Loss: 0.00082239
Iteration 20/25 | Loss: 0.00082239
Iteration 21/25 | Loss: 0.00082239
Iteration 22/25 | Loss: 0.00082239
Iteration 23/25 | Loss: 0.00082239
Iteration 24/25 | Loss: 0.00082239
Iteration 25/25 | Loss: 0.00082239

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51778865
Iteration 2/25 | Loss: 0.00056845
Iteration 3/25 | Loss: 0.00056845
Iteration 4/25 | Loss: 0.00056845
Iteration 5/25 | Loss: 0.00056845
Iteration 6/25 | Loss: 0.00056845
Iteration 7/25 | Loss: 0.00056845
Iteration 8/25 | Loss: 0.00056845
Iteration 9/25 | Loss: 0.00056845
Iteration 10/25 | Loss: 0.00056845
Iteration 11/25 | Loss: 0.00056845
Iteration 12/25 | Loss: 0.00056845
Iteration 13/25 | Loss: 0.00056845
Iteration 14/25 | Loss: 0.00056845
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0005684487405233085, 0.0005684487405233085, 0.0005684487405233085, 0.0005684487405233085, 0.0005684487405233085]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005684487405233085

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056845
Iteration 2/1000 | Loss: 0.00002245
Iteration 3/1000 | Loss: 0.00001567
Iteration 4/1000 | Loss: 0.00001415
Iteration 5/1000 | Loss: 0.00001340
Iteration 6/1000 | Loss: 0.00001268
Iteration 7/1000 | Loss: 0.00001232
Iteration 8/1000 | Loss: 0.00001205
Iteration 9/1000 | Loss: 0.00001204
Iteration 10/1000 | Loss: 0.00001199
Iteration 11/1000 | Loss: 0.00001188
Iteration 12/1000 | Loss: 0.00001179
Iteration 13/1000 | Loss: 0.00001172
Iteration 14/1000 | Loss: 0.00001167
Iteration 15/1000 | Loss: 0.00001165
Iteration 16/1000 | Loss: 0.00001165
Iteration 17/1000 | Loss: 0.00001162
Iteration 18/1000 | Loss: 0.00001161
Iteration 19/1000 | Loss: 0.00001160
Iteration 20/1000 | Loss: 0.00001160
Iteration 21/1000 | Loss: 0.00001159
Iteration 22/1000 | Loss: 0.00001158
Iteration 23/1000 | Loss: 0.00001158
Iteration 24/1000 | Loss: 0.00001157
Iteration 25/1000 | Loss: 0.00001157
Iteration 26/1000 | Loss: 0.00001156
Iteration 27/1000 | Loss: 0.00001156
Iteration 28/1000 | Loss: 0.00001155
Iteration 29/1000 | Loss: 0.00001155
Iteration 30/1000 | Loss: 0.00001154
Iteration 31/1000 | Loss: 0.00001153
Iteration 32/1000 | Loss: 0.00001152
Iteration 33/1000 | Loss: 0.00001152
Iteration 34/1000 | Loss: 0.00001152
Iteration 35/1000 | Loss: 0.00001152
Iteration 36/1000 | Loss: 0.00001152
Iteration 37/1000 | Loss: 0.00001151
Iteration 38/1000 | Loss: 0.00001151
Iteration 39/1000 | Loss: 0.00001151
Iteration 40/1000 | Loss: 0.00001150
Iteration 41/1000 | Loss: 0.00001150
Iteration 42/1000 | Loss: 0.00001150
Iteration 43/1000 | Loss: 0.00001150
Iteration 44/1000 | Loss: 0.00001150
Iteration 45/1000 | Loss: 0.00001149
Iteration 46/1000 | Loss: 0.00001149
Iteration 47/1000 | Loss: 0.00001149
Iteration 48/1000 | Loss: 0.00001149
Iteration 49/1000 | Loss: 0.00001149
Iteration 50/1000 | Loss: 0.00001149
Iteration 51/1000 | Loss: 0.00001148
Iteration 52/1000 | Loss: 0.00001148
Iteration 53/1000 | Loss: 0.00001148
Iteration 54/1000 | Loss: 0.00001148
Iteration 55/1000 | Loss: 0.00001148
Iteration 56/1000 | Loss: 0.00001148
Iteration 57/1000 | Loss: 0.00001147
Iteration 58/1000 | Loss: 0.00001147
Iteration 59/1000 | Loss: 0.00001147
Iteration 60/1000 | Loss: 0.00001147
Iteration 61/1000 | Loss: 0.00001147
Iteration 62/1000 | Loss: 0.00001147
Iteration 63/1000 | Loss: 0.00001147
Iteration 64/1000 | Loss: 0.00001147
Iteration 65/1000 | Loss: 0.00001146
Iteration 66/1000 | Loss: 0.00001146
Iteration 67/1000 | Loss: 0.00001146
Iteration 68/1000 | Loss: 0.00001146
Iteration 69/1000 | Loss: 0.00001145
Iteration 70/1000 | Loss: 0.00001145
Iteration 71/1000 | Loss: 0.00001145
Iteration 72/1000 | Loss: 0.00001145
Iteration 73/1000 | Loss: 0.00001145
Iteration 74/1000 | Loss: 0.00001144
Iteration 75/1000 | Loss: 0.00001144
Iteration 76/1000 | Loss: 0.00001144
Iteration 77/1000 | Loss: 0.00001144
Iteration 78/1000 | Loss: 0.00001143
Iteration 79/1000 | Loss: 0.00001143
Iteration 80/1000 | Loss: 0.00001143
Iteration 81/1000 | Loss: 0.00001143
Iteration 82/1000 | Loss: 0.00001143
Iteration 83/1000 | Loss: 0.00001143
Iteration 84/1000 | Loss: 0.00001143
Iteration 85/1000 | Loss: 0.00001143
Iteration 86/1000 | Loss: 0.00001142
Iteration 87/1000 | Loss: 0.00001142
Iteration 88/1000 | Loss: 0.00001142
Iteration 89/1000 | Loss: 0.00001142
Iteration 90/1000 | Loss: 0.00001141
Iteration 91/1000 | Loss: 0.00001141
Iteration 92/1000 | Loss: 0.00001141
Iteration 93/1000 | Loss: 0.00001141
Iteration 94/1000 | Loss: 0.00001141
Iteration 95/1000 | Loss: 0.00001140
Iteration 96/1000 | Loss: 0.00001140
Iteration 97/1000 | Loss: 0.00001140
Iteration 98/1000 | Loss: 0.00001140
Iteration 99/1000 | Loss: 0.00001139
Iteration 100/1000 | Loss: 0.00001139
Iteration 101/1000 | Loss: 0.00001138
Iteration 102/1000 | Loss: 0.00001138
Iteration 103/1000 | Loss: 0.00001138
Iteration 104/1000 | Loss: 0.00001138
Iteration 105/1000 | Loss: 0.00001138
Iteration 106/1000 | Loss: 0.00001138
Iteration 107/1000 | Loss: 0.00001138
Iteration 108/1000 | Loss: 0.00001138
Iteration 109/1000 | Loss: 0.00001138
Iteration 110/1000 | Loss: 0.00001138
Iteration 111/1000 | Loss: 0.00001138
Iteration 112/1000 | Loss: 0.00001137
Iteration 113/1000 | Loss: 0.00001137
Iteration 114/1000 | Loss: 0.00001136
Iteration 115/1000 | Loss: 0.00001136
Iteration 116/1000 | Loss: 0.00001136
Iteration 117/1000 | Loss: 0.00001135
Iteration 118/1000 | Loss: 0.00001135
Iteration 119/1000 | Loss: 0.00001135
Iteration 120/1000 | Loss: 0.00001135
Iteration 121/1000 | Loss: 0.00001135
Iteration 122/1000 | Loss: 0.00001134
Iteration 123/1000 | Loss: 0.00001134
Iteration 124/1000 | Loss: 0.00001134
Iteration 125/1000 | Loss: 0.00001133
Iteration 126/1000 | Loss: 0.00001133
Iteration 127/1000 | Loss: 0.00001133
Iteration 128/1000 | Loss: 0.00001133
Iteration 129/1000 | Loss: 0.00001133
Iteration 130/1000 | Loss: 0.00001133
Iteration 131/1000 | Loss: 0.00001133
Iteration 132/1000 | Loss: 0.00001133
Iteration 133/1000 | Loss: 0.00001133
Iteration 134/1000 | Loss: 0.00001133
Iteration 135/1000 | Loss: 0.00001133
Iteration 136/1000 | Loss: 0.00001133
Iteration 137/1000 | Loss: 0.00001133
Iteration 138/1000 | Loss: 0.00001133
Iteration 139/1000 | Loss: 0.00001133
Iteration 140/1000 | Loss: 0.00001133
Iteration 141/1000 | Loss: 0.00001132
Iteration 142/1000 | Loss: 0.00001132
Iteration 143/1000 | Loss: 0.00001132
Iteration 144/1000 | Loss: 0.00001132
Iteration 145/1000 | Loss: 0.00001132
Iteration 146/1000 | Loss: 0.00001132
Iteration 147/1000 | Loss: 0.00001132
Iteration 148/1000 | Loss: 0.00001132
Iteration 149/1000 | Loss: 0.00001132
Iteration 150/1000 | Loss: 0.00001131
Iteration 151/1000 | Loss: 0.00001131
Iteration 152/1000 | Loss: 0.00001131
Iteration 153/1000 | Loss: 0.00001131
Iteration 154/1000 | Loss: 0.00001131
Iteration 155/1000 | Loss: 0.00001131
Iteration 156/1000 | Loss: 0.00001131
Iteration 157/1000 | Loss: 0.00001131
Iteration 158/1000 | Loss: 0.00001131
Iteration 159/1000 | Loss: 0.00001131
Iteration 160/1000 | Loss: 0.00001131
Iteration 161/1000 | Loss: 0.00001131
Iteration 162/1000 | Loss: 0.00001131
Iteration 163/1000 | Loss: 0.00001131
Iteration 164/1000 | Loss: 0.00001131
Iteration 165/1000 | Loss: 0.00001131
Iteration 166/1000 | Loss: 0.00001131
Iteration 167/1000 | Loss: 0.00001131
Iteration 168/1000 | Loss: 0.00001131
Iteration 169/1000 | Loss: 0.00001131
Iteration 170/1000 | Loss: 0.00001131
Iteration 171/1000 | Loss: 0.00001131
Iteration 172/1000 | Loss: 0.00001131
Iteration 173/1000 | Loss: 0.00001131
Iteration 174/1000 | Loss: 0.00001131
Iteration 175/1000 | Loss: 0.00001131
Iteration 176/1000 | Loss: 0.00001131
Iteration 177/1000 | Loss: 0.00001131
Iteration 178/1000 | Loss: 0.00001131
Iteration 179/1000 | Loss: 0.00001131
Iteration 180/1000 | Loss: 0.00001131
Iteration 181/1000 | Loss: 0.00001131
Iteration 182/1000 | Loss: 0.00001131
Iteration 183/1000 | Loss: 0.00001131
Iteration 184/1000 | Loss: 0.00001131
Iteration 185/1000 | Loss: 0.00001131
Iteration 186/1000 | Loss: 0.00001131
Iteration 187/1000 | Loss: 0.00001131
Iteration 188/1000 | Loss: 0.00001131
Iteration 189/1000 | Loss: 0.00001131
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 189. Stopping optimization.
Last 5 losses: [1.1305395673844032e-05, 1.1305395673844032e-05, 1.1305395673844032e-05, 1.1305395673844032e-05, 1.1305395673844032e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1305395673844032e-05

Optimization complete. Final v2v error: 2.8289763927459717 mm

Highest mean error: 3.5405313968658447 mm for frame 73

Lowest mean error: 2.554936408996582 mm for frame 129

Saving results

Total time: 38.77741861343384
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1051/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1051.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1051
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00392319
Iteration 2/25 | Loss: 0.00091175
Iteration 3/25 | Loss: 0.00081377
Iteration 4/25 | Loss: 0.00079724
Iteration 5/25 | Loss: 0.00079486
Iteration 6/25 | Loss: 0.00079454
Iteration 7/25 | Loss: 0.00079454
Iteration 8/25 | Loss: 0.00079454
Iteration 9/25 | Loss: 0.00079454
Iteration 10/25 | Loss: 0.00079454
Iteration 11/25 | Loss: 0.00079454
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007945403340272605, 0.0007945403340272605, 0.0007945403340272605, 0.0007945403340272605, 0.0007945403340272605]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007945403340272605

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.51683974
Iteration 2/25 | Loss: 0.00060467
Iteration 3/25 | Loss: 0.00060467
Iteration 4/25 | Loss: 0.00060467
Iteration 5/25 | Loss: 0.00060467
Iteration 6/25 | Loss: 0.00060467
Iteration 7/25 | Loss: 0.00060467
Iteration 8/25 | Loss: 0.00060467
Iteration 9/25 | Loss: 0.00060467
Iteration 10/25 | Loss: 0.00060467
Iteration 11/25 | Loss: 0.00060467
Iteration 12/25 | Loss: 0.00060467
Iteration 13/25 | Loss: 0.00060467
Iteration 14/25 | Loss: 0.00060467
Iteration 15/25 | Loss: 0.00060467
Iteration 16/25 | Loss: 0.00060467
Iteration 17/25 | Loss: 0.00060467
Iteration 18/25 | Loss: 0.00060467
Iteration 19/25 | Loss: 0.00060467
Iteration 20/25 | Loss: 0.00060467
Iteration 21/25 | Loss: 0.00060467
Iteration 22/25 | Loss: 0.00060467
Iteration 23/25 | Loss: 0.00060467
Iteration 24/25 | Loss: 0.00060467
Iteration 25/25 | Loss: 0.00060467

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060467
Iteration 2/1000 | Loss: 0.00002499
Iteration 3/1000 | Loss: 0.00001639
Iteration 4/1000 | Loss: 0.00001514
Iteration 5/1000 | Loss: 0.00001422
Iteration 6/1000 | Loss: 0.00001384
Iteration 7/1000 | Loss: 0.00001353
Iteration 8/1000 | Loss: 0.00001335
Iteration 9/1000 | Loss: 0.00001311
Iteration 10/1000 | Loss: 0.00001295
Iteration 11/1000 | Loss: 0.00001292
Iteration 12/1000 | Loss: 0.00001283
Iteration 13/1000 | Loss: 0.00001275
Iteration 14/1000 | Loss: 0.00001268
Iteration 15/1000 | Loss: 0.00001267
Iteration 16/1000 | Loss: 0.00001266
Iteration 17/1000 | Loss: 0.00001266
Iteration 18/1000 | Loss: 0.00001265
Iteration 19/1000 | Loss: 0.00001264
Iteration 20/1000 | Loss: 0.00001262
Iteration 21/1000 | Loss: 0.00001262
Iteration 22/1000 | Loss: 0.00001261
Iteration 23/1000 | Loss: 0.00001261
Iteration 24/1000 | Loss: 0.00001260
Iteration 25/1000 | Loss: 0.00001260
Iteration 26/1000 | Loss: 0.00001260
Iteration 27/1000 | Loss: 0.00001260
Iteration 28/1000 | Loss: 0.00001256
Iteration 29/1000 | Loss: 0.00001255
Iteration 30/1000 | Loss: 0.00001254
Iteration 31/1000 | Loss: 0.00001252
Iteration 32/1000 | Loss: 0.00001251
Iteration 33/1000 | Loss: 0.00001249
Iteration 34/1000 | Loss: 0.00001248
Iteration 35/1000 | Loss: 0.00001247
Iteration 36/1000 | Loss: 0.00001247
Iteration 37/1000 | Loss: 0.00001246
Iteration 38/1000 | Loss: 0.00001242
Iteration 39/1000 | Loss: 0.00001241
Iteration 40/1000 | Loss: 0.00001240
Iteration 41/1000 | Loss: 0.00001238
Iteration 42/1000 | Loss: 0.00001236
Iteration 43/1000 | Loss: 0.00001236
Iteration 44/1000 | Loss: 0.00001235
Iteration 45/1000 | Loss: 0.00001235
Iteration 46/1000 | Loss: 0.00001235
Iteration 47/1000 | Loss: 0.00001234
Iteration 48/1000 | Loss: 0.00001234
Iteration 49/1000 | Loss: 0.00001234
Iteration 50/1000 | Loss: 0.00001234
Iteration 51/1000 | Loss: 0.00001233
Iteration 52/1000 | Loss: 0.00001233
Iteration 53/1000 | Loss: 0.00001233
Iteration 54/1000 | Loss: 0.00001232
Iteration 55/1000 | Loss: 0.00001232
Iteration 56/1000 | Loss: 0.00001232
Iteration 57/1000 | Loss: 0.00001231
Iteration 58/1000 | Loss: 0.00001231
Iteration 59/1000 | Loss: 0.00001231
Iteration 60/1000 | Loss: 0.00001231
Iteration 61/1000 | Loss: 0.00001231
Iteration 62/1000 | Loss: 0.00001230
Iteration 63/1000 | Loss: 0.00001230
Iteration 64/1000 | Loss: 0.00001230
Iteration 65/1000 | Loss: 0.00001230
Iteration 66/1000 | Loss: 0.00001230
Iteration 67/1000 | Loss: 0.00001230
Iteration 68/1000 | Loss: 0.00001230
Iteration 69/1000 | Loss: 0.00001230
Iteration 70/1000 | Loss: 0.00001230
Iteration 71/1000 | Loss: 0.00001230
Iteration 72/1000 | Loss: 0.00001230
Iteration 73/1000 | Loss: 0.00001229
Iteration 74/1000 | Loss: 0.00001229
Iteration 75/1000 | Loss: 0.00001229
Iteration 76/1000 | Loss: 0.00001229
Iteration 77/1000 | Loss: 0.00001229
Iteration 78/1000 | Loss: 0.00001229
Iteration 79/1000 | Loss: 0.00001228
Iteration 80/1000 | Loss: 0.00001228
Iteration 81/1000 | Loss: 0.00001228
Iteration 82/1000 | Loss: 0.00001228
Iteration 83/1000 | Loss: 0.00001228
Iteration 84/1000 | Loss: 0.00001228
Iteration 85/1000 | Loss: 0.00001228
Iteration 86/1000 | Loss: 0.00001228
Iteration 87/1000 | Loss: 0.00001228
Iteration 88/1000 | Loss: 0.00001228
Iteration 89/1000 | Loss: 0.00001227
Iteration 90/1000 | Loss: 0.00001227
Iteration 91/1000 | Loss: 0.00001227
Iteration 92/1000 | Loss: 0.00001227
Iteration 93/1000 | Loss: 0.00001227
Iteration 94/1000 | Loss: 0.00001227
Iteration 95/1000 | Loss: 0.00001227
Iteration 96/1000 | Loss: 0.00001227
Iteration 97/1000 | Loss: 0.00001227
Iteration 98/1000 | Loss: 0.00001226
Iteration 99/1000 | Loss: 0.00001226
Iteration 100/1000 | Loss: 0.00001226
Iteration 101/1000 | Loss: 0.00001226
Iteration 102/1000 | Loss: 0.00001226
Iteration 103/1000 | Loss: 0.00001226
Iteration 104/1000 | Loss: 0.00001226
Iteration 105/1000 | Loss: 0.00001226
Iteration 106/1000 | Loss: 0.00001226
Iteration 107/1000 | Loss: 0.00001226
Iteration 108/1000 | Loss: 0.00001226
Iteration 109/1000 | Loss: 0.00001226
Iteration 110/1000 | Loss: 0.00001226
Iteration 111/1000 | Loss: 0.00001226
Iteration 112/1000 | Loss: 0.00001226
Iteration 113/1000 | Loss: 0.00001226
Iteration 114/1000 | Loss: 0.00001226
Iteration 115/1000 | Loss: 0.00001226
Iteration 116/1000 | Loss: 0.00001226
Iteration 117/1000 | Loss: 0.00001226
Iteration 118/1000 | Loss: 0.00001226
Iteration 119/1000 | Loss: 0.00001226
Iteration 120/1000 | Loss: 0.00001226
Iteration 121/1000 | Loss: 0.00001226
Iteration 122/1000 | Loss: 0.00001226
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [1.2255874935362954e-05, 1.2255874935362954e-05, 1.2255874935362954e-05, 1.2255874935362954e-05, 1.2255874935362954e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2255874935362954e-05

Optimization complete. Final v2v error: 2.995473861694336 mm

Highest mean error: 3.2735488414764404 mm for frame 98

Lowest mean error: 2.8683300018310547 mm for frame 120

Saving results

Total time: 38.064451932907104
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00417833
Iteration 2/25 | Loss: 0.00125741
Iteration 3/25 | Loss: 0.00093529
Iteration 4/25 | Loss: 0.00085603
Iteration 5/25 | Loss: 0.00083619
Iteration 6/25 | Loss: 0.00083293
Iteration 7/25 | Loss: 0.00083209
Iteration 8/25 | Loss: 0.00083184
Iteration 9/25 | Loss: 0.00083184
Iteration 10/25 | Loss: 0.00083184
Iteration 11/25 | Loss: 0.00083184
Iteration 12/25 | Loss: 0.00083184
Iteration 13/25 | Loss: 0.00083184
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008318430627696216, 0.0008318430627696216, 0.0008318430627696216, 0.0008318430627696216, 0.0008318430627696216]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008318430627696216

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50996566
Iteration 2/25 | Loss: 0.00062937
Iteration 3/25 | Loss: 0.00062936
Iteration 4/25 | Loss: 0.00062936
Iteration 5/25 | Loss: 0.00062936
Iteration 6/25 | Loss: 0.00062936
Iteration 7/25 | Loss: 0.00062936
Iteration 8/25 | Loss: 0.00062936
Iteration 9/25 | Loss: 0.00062936
Iteration 10/25 | Loss: 0.00062936
Iteration 11/25 | Loss: 0.00062936
Iteration 12/25 | Loss: 0.00062936
Iteration 13/25 | Loss: 0.00062936
Iteration 14/25 | Loss: 0.00062936
Iteration 15/25 | Loss: 0.00062936
Iteration 16/25 | Loss: 0.00062936
Iteration 17/25 | Loss: 0.00062936
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.000629361835308373, 0.000629361835308373, 0.000629361835308373, 0.000629361835308373, 0.000629361835308373]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000629361835308373

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062936
Iteration 2/1000 | Loss: 0.00002927
Iteration 3/1000 | Loss: 0.00002123
Iteration 4/1000 | Loss: 0.00001868
Iteration 5/1000 | Loss: 0.00001750
Iteration 6/1000 | Loss: 0.00001650
Iteration 7/1000 | Loss: 0.00001599
Iteration 8/1000 | Loss: 0.00001558
Iteration 9/1000 | Loss: 0.00001530
Iteration 10/1000 | Loss: 0.00001517
Iteration 11/1000 | Loss: 0.00001506
Iteration 12/1000 | Loss: 0.00001482
Iteration 13/1000 | Loss: 0.00001462
Iteration 14/1000 | Loss: 0.00001461
Iteration 15/1000 | Loss: 0.00001459
Iteration 16/1000 | Loss: 0.00001456
Iteration 17/1000 | Loss: 0.00001451
Iteration 18/1000 | Loss: 0.00001447
Iteration 19/1000 | Loss: 0.00001444
Iteration 20/1000 | Loss: 0.00001441
Iteration 21/1000 | Loss: 0.00001441
Iteration 22/1000 | Loss: 0.00001441
Iteration 23/1000 | Loss: 0.00001440
Iteration 24/1000 | Loss: 0.00001440
Iteration 25/1000 | Loss: 0.00001439
Iteration 26/1000 | Loss: 0.00001436
Iteration 27/1000 | Loss: 0.00001436
Iteration 28/1000 | Loss: 0.00001435
Iteration 29/1000 | Loss: 0.00001435
Iteration 30/1000 | Loss: 0.00001432
Iteration 31/1000 | Loss: 0.00001432
Iteration 32/1000 | Loss: 0.00001432
Iteration 33/1000 | Loss: 0.00001432
Iteration 34/1000 | Loss: 0.00001432
Iteration 35/1000 | Loss: 0.00001432
Iteration 36/1000 | Loss: 0.00001431
Iteration 37/1000 | Loss: 0.00001431
Iteration 38/1000 | Loss: 0.00001431
Iteration 39/1000 | Loss: 0.00001431
Iteration 40/1000 | Loss: 0.00001431
Iteration 41/1000 | Loss: 0.00001430
Iteration 42/1000 | Loss: 0.00001430
Iteration 43/1000 | Loss: 0.00001430
Iteration 44/1000 | Loss: 0.00001429
Iteration 45/1000 | Loss: 0.00001429
Iteration 46/1000 | Loss: 0.00001429
Iteration 47/1000 | Loss: 0.00001428
Iteration 48/1000 | Loss: 0.00001428
Iteration 49/1000 | Loss: 0.00001428
Iteration 50/1000 | Loss: 0.00001428
Iteration 51/1000 | Loss: 0.00001428
Iteration 52/1000 | Loss: 0.00001427
Iteration 53/1000 | Loss: 0.00001427
Iteration 54/1000 | Loss: 0.00001427
Iteration 55/1000 | Loss: 0.00001426
Iteration 56/1000 | Loss: 0.00001426
Iteration 57/1000 | Loss: 0.00001426
Iteration 58/1000 | Loss: 0.00001426
Iteration 59/1000 | Loss: 0.00001425
Iteration 60/1000 | Loss: 0.00001425
Iteration 61/1000 | Loss: 0.00001425
Iteration 62/1000 | Loss: 0.00001425
Iteration 63/1000 | Loss: 0.00001425
Iteration 64/1000 | Loss: 0.00001425
Iteration 65/1000 | Loss: 0.00001424
Iteration 66/1000 | Loss: 0.00001424
Iteration 67/1000 | Loss: 0.00001424
Iteration 68/1000 | Loss: 0.00001424
Iteration 69/1000 | Loss: 0.00001424
Iteration 70/1000 | Loss: 0.00001424
Iteration 71/1000 | Loss: 0.00001424
Iteration 72/1000 | Loss: 0.00001424
Iteration 73/1000 | Loss: 0.00001424
Iteration 74/1000 | Loss: 0.00001424
Iteration 75/1000 | Loss: 0.00001424
Iteration 76/1000 | Loss: 0.00001424
Iteration 77/1000 | Loss: 0.00001423
Iteration 78/1000 | Loss: 0.00001423
Iteration 79/1000 | Loss: 0.00001423
Iteration 80/1000 | Loss: 0.00001423
Iteration 81/1000 | Loss: 0.00001423
Iteration 82/1000 | Loss: 0.00001423
Iteration 83/1000 | Loss: 0.00001423
Iteration 84/1000 | Loss: 0.00001423
Iteration 85/1000 | Loss: 0.00001423
Iteration 86/1000 | Loss: 0.00001422
Iteration 87/1000 | Loss: 0.00001422
Iteration 88/1000 | Loss: 0.00001422
Iteration 89/1000 | Loss: 0.00001422
Iteration 90/1000 | Loss: 0.00001421
Iteration 91/1000 | Loss: 0.00001421
Iteration 92/1000 | Loss: 0.00001421
Iteration 93/1000 | Loss: 0.00001421
Iteration 94/1000 | Loss: 0.00001420
Iteration 95/1000 | Loss: 0.00001420
Iteration 96/1000 | Loss: 0.00001420
Iteration 97/1000 | Loss: 0.00001420
Iteration 98/1000 | Loss: 0.00001419
Iteration 99/1000 | Loss: 0.00001419
Iteration 100/1000 | Loss: 0.00001419
Iteration 101/1000 | Loss: 0.00001419
Iteration 102/1000 | Loss: 0.00001418
Iteration 103/1000 | Loss: 0.00001418
Iteration 104/1000 | Loss: 0.00001418
Iteration 105/1000 | Loss: 0.00001418
Iteration 106/1000 | Loss: 0.00001418
Iteration 107/1000 | Loss: 0.00001418
Iteration 108/1000 | Loss: 0.00001418
Iteration 109/1000 | Loss: 0.00001418
Iteration 110/1000 | Loss: 0.00001418
Iteration 111/1000 | Loss: 0.00001418
Iteration 112/1000 | Loss: 0.00001418
Iteration 113/1000 | Loss: 0.00001418
Iteration 114/1000 | Loss: 0.00001418
Iteration 115/1000 | Loss: 0.00001418
Iteration 116/1000 | Loss: 0.00001418
Iteration 117/1000 | Loss: 0.00001417
Iteration 118/1000 | Loss: 0.00001417
Iteration 119/1000 | Loss: 0.00001417
Iteration 120/1000 | Loss: 0.00001417
Iteration 121/1000 | Loss: 0.00001416
Iteration 122/1000 | Loss: 0.00001416
Iteration 123/1000 | Loss: 0.00001416
Iteration 124/1000 | Loss: 0.00001416
Iteration 125/1000 | Loss: 0.00001416
Iteration 126/1000 | Loss: 0.00001416
Iteration 127/1000 | Loss: 0.00001416
Iteration 128/1000 | Loss: 0.00001416
Iteration 129/1000 | Loss: 0.00001416
Iteration 130/1000 | Loss: 0.00001416
Iteration 131/1000 | Loss: 0.00001416
Iteration 132/1000 | Loss: 0.00001416
Iteration 133/1000 | Loss: 0.00001416
Iteration 134/1000 | Loss: 0.00001416
Iteration 135/1000 | Loss: 0.00001416
Iteration 136/1000 | Loss: 0.00001415
Iteration 137/1000 | Loss: 0.00001415
Iteration 138/1000 | Loss: 0.00001415
Iteration 139/1000 | Loss: 0.00001415
Iteration 140/1000 | Loss: 0.00001415
Iteration 141/1000 | Loss: 0.00001415
Iteration 142/1000 | Loss: 0.00001415
Iteration 143/1000 | Loss: 0.00001415
Iteration 144/1000 | Loss: 0.00001415
Iteration 145/1000 | Loss: 0.00001415
Iteration 146/1000 | Loss: 0.00001415
Iteration 147/1000 | Loss: 0.00001415
Iteration 148/1000 | Loss: 0.00001415
Iteration 149/1000 | Loss: 0.00001414
Iteration 150/1000 | Loss: 0.00001414
Iteration 151/1000 | Loss: 0.00001414
Iteration 152/1000 | Loss: 0.00001414
Iteration 153/1000 | Loss: 0.00001414
Iteration 154/1000 | Loss: 0.00001414
Iteration 155/1000 | Loss: 0.00001414
Iteration 156/1000 | Loss: 0.00001414
Iteration 157/1000 | Loss: 0.00001414
Iteration 158/1000 | Loss: 0.00001414
Iteration 159/1000 | Loss: 0.00001414
Iteration 160/1000 | Loss: 0.00001414
Iteration 161/1000 | Loss: 0.00001414
Iteration 162/1000 | Loss: 0.00001414
Iteration 163/1000 | Loss: 0.00001414
Iteration 164/1000 | Loss: 0.00001414
Iteration 165/1000 | Loss: 0.00001414
Iteration 166/1000 | Loss: 0.00001414
Iteration 167/1000 | Loss: 0.00001414
Iteration 168/1000 | Loss: 0.00001414
Iteration 169/1000 | Loss: 0.00001414
Iteration 170/1000 | Loss: 0.00001414
Iteration 171/1000 | Loss: 0.00001414
Iteration 172/1000 | Loss: 0.00001414
Iteration 173/1000 | Loss: 0.00001414
Iteration 174/1000 | Loss: 0.00001414
Iteration 175/1000 | Loss: 0.00001414
Iteration 176/1000 | Loss: 0.00001414
Iteration 177/1000 | Loss: 0.00001414
Iteration 178/1000 | Loss: 0.00001414
Iteration 179/1000 | Loss: 0.00001414
Iteration 180/1000 | Loss: 0.00001414
Iteration 181/1000 | Loss: 0.00001414
Iteration 182/1000 | Loss: 0.00001414
Iteration 183/1000 | Loss: 0.00001414
Iteration 184/1000 | Loss: 0.00001414
Iteration 185/1000 | Loss: 0.00001414
Iteration 186/1000 | Loss: 0.00001414
Iteration 187/1000 | Loss: 0.00001414
Iteration 188/1000 | Loss: 0.00001414
Iteration 189/1000 | Loss: 0.00001414
Iteration 190/1000 | Loss: 0.00001414
Iteration 191/1000 | Loss: 0.00001414
Iteration 192/1000 | Loss: 0.00001414
Iteration 193/1000 | Loss: 0.00001414
Iteration 194/1000 | Loss: 0.00001414
Iteration 195/1000 | Loss: 0.00001414
Iteration 196/1000 | Loss: 0.00001414
Iteration 197/1000 | Loss: 0.00001414
Iteration 198/1000 | Loss: 0.00001414
Iteration 199/1000 | Loss: 0.00001414
Iteration 200/1000 | Loss: 0.00001414
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 200. Stopping optimization.
Last 5 losses: [1.413812606188003e-05, 1.413812606188003e-05, 1.413812606188003e-05, 1.413812606188003e-05, 1.413812606188003e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.413812606188003e-05

Optimization complete. Final v2v error: 3.2115185260772705 mm

Highest mean error: 3.9163599014282227 mm for frame 72

Lowest mean error: 2.845301866531372 mm for frame 105

Saving results

Total time: 41.188955783843994
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1043/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1043.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1043
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00535885
Iteration 2/25 | Loss: 0.00113904
Iteration 3/25 | Loss: 0.00097216
Iteration 4/25 | Loss: 0.00094991
Iteration 5/25 | Loss: 0.00094490
Iteration 6/25 | Loss: 0.00094470
Iteration 7/25 | Loss: 0.00094470
Iteration 8/25 | Loss: 0.00094470
Iteration 9/25 | Loss: 0.00094470
Iteration 10/25 | Loss: 0.00094470
Iteration 11/25 | Loss: 0.00094470
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009446994517929852, 0.0009446994517929852, 0.0009446994517929852, 0.0009446994517929852, 0.0009446994517929852]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009446994517929852

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.81663239
Iteration 2/25 | Loss: 0.00048847
Iteration 3/25 | Loss: 0.00048846
Iteration 4/25 | Loss: 0.00048846
Iteration 5/25 | Loss: 0.00048846
Iteration 6/25 | Loss: 0.00048846
Iteration 7/25 | Loss: 0.00048846
Iteration 8/25 | Loss: 0.00048846
Iteration 9/25 | Loss: 0.00048846
Iteration 10/25 | Loss: 0.00048846
Iteration 11/25 | Loss: 0.00048846
Iteration 12/25 | Loss: 0.00048846
Iteration 13/25 | Loss: 0.00048846
Iteration 14/25 | Loss: 0.00048846
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0004884593072347343, 0.0004884593072347343, 0.0004884593072347343, 0.0004884593072347343, 0.0004884593072347343]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004884593072347343

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048846
Iteration 2/1000 | Loss: 0.00004442
Iteration 3/1000 | Loss: 0.00003802
Iteration 4/1000 | Loss: 0.00003598
Iteration 5/1000 | Loss: 0.00003504
Iteration 6/1000 | Loss: 0.00003404
Iteration 7/1000 | Loss: 0.00003363
Iteration 8/1000 | Loss: 0.00003326
Iteration 9/1000 | Loss: 0.00003291
Iteration 10/1000 | Loss: 0.00003270
Iteration 11/1000 | Loss: 0.00003248
Iteration 12/1000 | Loss: 0.00003224
Iteration 13/1000 | Loss: 0.00003200
Iteration 14/1000 | Loss: 0.00003185
Iteration 15/1000 | Loss: 0.00003179
Iteration 16/1000 | Loss: 0.00003178
Iteration 17/1000 | Loss: 0.00003178
Iteration 18/1000 | Loss: 0.00003178
Iteration 19/1000 | Loss: 0.00003177
Iteration 20/1000 | Loss: 0.00003177
Iteration 21/1000 | Loss: 0.00003177
Iteration 22/1000 | Loss: 0.00003176
Iteration 23/1000 | Loss: 0.00003176
Iteration 24/1000 | Loss: 0.00003176
Iteration 25/1000 | Loss: 0.00003176
Iteration 26/1000 | Loss: 0.00003176
Iteration 27/1000 | Loss: 0.00003176
Iteration 28/1000 | Loss: 0.00003176
Iteration 29/1000 | Loss: 0.00003176
Iteration 30/1000 | Loss: 0.00003176
Iteration 31/1000 | Loss: 0.00003175
Iteration 32/1000 | Loss: 0.00003175
Iteration 33/1000 | Loss: 0.00003175
Iteration 34/1000 | Loss: 0.00003174
Iteration 35/1000 | Loss: 0.00003174
Iteration 36/1000 | Loss: 0.00003174
Iteration 37/1000 | Loss: 0.00003173
Iteration 38/1000 | Loss: 0.00003173
Iteration 39/1000 | Loss: 0.00003171
Iteration 40/1000 | Loss: 0.00003171
Iteration 41/1000 | Loss: 0.00003171
Iteration 42/1000 | Loss: 0.00003171
Iteration 43/1000 | Loss: 0.00003171
Iteration 44/1000 | Loss: 0.00003170
Iteration 45/1000 | Loss: 0.00003170
Iteration 46/1000 | Loss: 0.00003170
Iteration 47/1000 | Loss: 0.00003170
Iteration 48/1000 | Loss: 0.00003170
Iteration 49/1000 | Loss: 0.00003170
Iteration 50/1000 | Loss: 0.00003169
Iteration 51/1000 | Loss: 0.00003169
Iteration 52/1000 | Loss: 0.00003167
Iteration 53/1000 | Loss: 0.00003167
Iteration 54/1000 | Loss: 0.00003167
Iteration 55/1000 | Loss: 0.00003167
Iteration 56/1000 | Loss: 0.00003167
Iteration 57/1000 | Loss: 0.00003167
Iteration 58/1000 | Loss: 0.00003167
Iteration 59/1000 | Loss: 0.00003167
Iteration 60/1000 | Loss: 0.00003166
Iteration 61/1000 | Loss: 0.00003166
Iteration 62/1000 | Loss: 0.00003166
Iteration 63/1000 | Loss: 0.00003166
Iteration 64/1000 | Loss: 0.00003166
Iteration 65/1000 | Loss: 0.00003166
Iteration 66/1000 | Loss: 0.00003166
Iteration 67/1000 | Loss: 0.00003165
Iteration 68/1000 | Loss: 0.00003165
Iteration 69/1000 | Loss: 0.00003165
Iteration 70/1000 | Loss: 0.00003165
Iteration 71/1000 | Loss: 0.00003164
Iteration 72/1000 | Loss: 0.00003164
Iteration 73/1000 | Loss: 0.00003163
Iteration 74/1000 | Loss: 0.00003162
Iteration 75/1000 | Loss: 0.00003161
Iteration 76/1000 | Loss: 0.00003161
Iteration 77/1000 | Loss: 0.00003161
Iteration 78/1000 | Loss: 0.00003161
Iteration 79/1000 | Loss: 0.00003161
Iteration 80/1000 | Loss: 0.00003161
Iteration 81/1000 | Loss: 0.00003160
Iteration 82/1000 | Loss: 0.00003160
Iteration 83/1000 | Loss: 0.00003160
Iteration 84/1000 | Loss: 0.00003160
Iteration 85/1000 | Loss: 0.00003160
Iteration 86/1000 | Loss: 0.00003160
Iteration 87/1000 | Loss: 0.00003160
Iteration 88/1000 | Loss: 0.00003160
Iteration 89/1000 | Loss: 0.00003160
Iteration 90/1000 | Loss: 0.00003160
Iteration 91/1000 | Loss: 0.00003160
Iteration 92/1000 | Loss: 0.00003160
Iteration 93/1000 | Loss: 0.00003160
Iteration 94/1000 | Loss: 0.00003160
Iteration 95/1000 | Loss: 0.00003160
Iteration 96/1000 | Loss: 0.00003159
Iteration 97/1000 | Loss: 0.00003159
Iteration 98/1000 | Loss: 0.00003159
Iteration 99/1000 | Loss: 0.00003159
Iteration 100/1000 | Loss: 0.00003159
Iteration 101/1000 | Loss: 0.00003158
Iteration 102/1000 | Loss: 0.00003158
Iteration 103/1000 | Loss: 0.00003158
Iteration 104/1000 | Loss: 0.00003158
Iteration 105/1000 | Loss: 0.00003158
Iteration 106/1000 | Loss: 0.00003158
Iteration 107/1000 | Loss: 0.00003158
Iteration 108/1000 | Loss: 0.00003157
Iteration 109/1000 | Loss: 0.00003157
Iteration 110/1000 | Loss: 0.00003157
Iteration 111/1000 | Loss: 0.00003157
Iteration 112/1000 | Loss: 0.00003157
Iteration 113/1000 | Loss: 0.00003157
Iteration 114/1000 | Loss: 0.00003157
Iteration 115/1000 | Loss: 0.00003157
Iteration 116/1000 | Loss: 0.00003157
Iteration 117/1000 | Loss: 0.00003157
Iteration 118/1000 | Loss: 0.00003157
Iteration 119/1000 | Loss: 0.00003157
Iteration 120/1000 | Loss: 0.00003157
Iteration 121/1000 | Loss: 0.00003157
Iteration 122/1000 | Loss: 0.00003157
Iteration 123/1000 | Loss: 0.00003157
Iteration 124/1000 | Loss: 0.00003157
Iteration 125/1000 | Loss: 0.00003156
Iteration 126/1000 | Loss: 0.00003156
Iteration 127/1000 | Loss: 0.00003156
Iteration 128/1000 | Loss: 0.00003156
Iteration 129/1000 | Loss: 0.00003156
Iteration 130/1000 | Loss: 0.00003156
Iteration 131/1000 | Loss: 0.00003156
Iteration 132/1000 | Loss: 0.00003156
Iteration 133/1000 | Loss: 0.00003156
Iteration 134/1000 | Loss: 0.00003156
Iteration 135/1000 | Loss: 0.00003156
Iteration 136/1000 | Loss: 0.00003156
Iteration 137/1000 | Loss: 0.00003156
Iteration 138/1000 | Loss: 0.00003156
Iteration 139/1000 | Loss: 0.00003156
Iteration 140/1000 | Loss: 0.00003156
Iteration 141/1000 | Loss: 0.00003156
Iteration 142/1000 | Loss: 0.00003156
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [3.155566082568839e-05, 3.155566082568839e-05, 3.155566082568839e-05, 3.155566082568839e-05, 3.155566082568839e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.155566082568839e-05

Optimization complete. Final v2v error: 4.5833563804626465 mm

Highest mean error: 4.611410140991211 mm for frame 219

Lowest mean error: 4.509366989135742 mm for frame 58

Saving results

Total time: 41.950241804122925
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1085
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00548080
Iteration 2/25 | Loss: 0.00126284
Iteration 3/25 | Loss: 0.00096044
Iteration 4/25 | Loss: 0.00093698
Iteration 5/25 | Loss: 0.00093135
Iteration 6/25 | Loss: 0.00093045
Iteration 7/25 | Loss: 0.00093031
Iteration 8/25 | Loss: 0.00093031
Iteration 9/25 | Loss: 0.00093031
Iteration 10/25 | Loss: 0.00093031
Iteration 11/25 | Loss: 0.00093031
Iteration 12/25 | Loss: 0.00093031
Iteration 13/25 | Loss: 0.00093031
Iteration 14/25 | Loss: 0.00093031
Iteration 15/25 | Loss: 0.00093031
Iteration 16/25 | Loss: 0.00093031
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0009303133701905608, 0.0009303133701905608, 0.0009303133701905608, 0.0009303133701905608, 0.0009303133701905608]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009303133701905608

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52341413
Iteration 2/25 | Loss: 0.00062567
Iteration 3/25 | Loss: 0.00062567
Iteration 4/25 | Loss: 0.00062567
Iteration 5/25 | Loss: 0.00062567
Iteration 6/25 | Loss: 0.00062567
Iteration 7/25 | Loss: 0.00062567
Iteration 8/25 | Loss: 0.00062567
Iteration 9/25 | Loss: 0.00062567
Iteration 10/25 | Loss: 0.00062567
Iteration 11/25 | Loss: 0.00062567
Iteration 12/25 | Loss: 0.00062567
Iteration 13/25 | Loss: 0.00062567
Iteration 14/25 | Loss: 0.00062567
Iteration 15/25 | Loss: 0.00062567
Iteration 16/25 | Loss: 0.00062567
Iteration 17/25 | Loss: 0.00062567
Iteration 18/25 | Loss: 0.00062567
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006256675696931779, 0.0006256675696931779, 0.0006256675696931779, 0.0006256675696931779, 0.0006256675696931779]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006256675696931779

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062567
Iteration 2/1000 | Loss: 0.00003381
Iteration 3/1000 | Loss: 0.00002595
Iteration 4/1000 | Loss: 0.00002420
Iteration 5/1000 | Loss: 0.00002316
Iteration 6/1000 | Loss: 0.00002221
Iteration 7/1000 | Loss: 0.00002165
Iteration 8/1000 | Loss: 0.00002125
Iteration 9/1000 | Loss: 0.00002098
Iteration 10/1000 | Loss: 0.00002074
Iteration 11/1000 | Loss: 0.00002052
Iteration 12/1000 | Loss: 0.00002049
Iteration 13/1000 | Loss: 0.00002033
Iteration 14/1000 | Loss: 0.00002031
Iteration 15/1000 | Loss: 0.00002031
Iteration 16/1000 | Loss: 0.00002021
Iteration 17/1000 | Loss: 0.00002017
Iteration 18/1000 | Loss: 0.00002017
Iteration 19/1000 | Loss: 0.00002017
Iteration 20/1000 | Loss: 0.00002011
Iteration 21/1000 | Loss: 0.00002006
Iteration 22/1000 | Loss: 0.00002006
Iteration 23/1000 | Loss: 0.00002005
Iteration 24/1000 | Loss: 0.00002005
Iteration 25/1000 | Loss: 0.00002005
Iteration 26/1000 | Loss: 0.00002005
Iteration 27/1000 | Loss: 0.00002005
Iteration 28/1000 | Loss: 0.00002005
Iteration 29/1000 | Loss: 0.00002005
Iteration 30/1000 | Loss: 0.00002005
Iteration 31/1000 | Loss: 0.00002004
Iteration 32/1000 | Loss: 0.00002003
Iteration 33/1000 | Loss: 0.00002002
Iteration 34/1000 | Loss: 0.00002002
Iteration 35/1000 | Loss: 0.00002001
Iteration 36/1000 | Loss: 0.00002001
Iteration 37/1000 | Loss: 0.00002001
Iteration 38/1000 | Loss: 0.00002000
Iteration 39/1000 | Loss: 0.00002000
Iteration 40/1000 | Loss: 0.00001999
Iteration 41/1000 | Loss: 0.00001999
Iteration 42/1000 | Loss: 0.00001999
Iteration 43/1000 | Loss: 0.00001999
Iteration 44/1000 | Loss: 0.00001999
Iteration 45/1000 | Loss: 0.00001999
Iteration 46/1000 | Loss: 0.00001999
Iteration 47/1000 | Loss: 0.00001999
Iteration 48/1000 | Loss: 0.00001999
Iteration 49/1000 | Loss: 0.00001999
Iteration 50/1000 | Loss: 0.00001998
Iteration 51/1000 | Loss: 0.00001998
Iteration 52/1000 | Loss: 0.00001998
Iteration 53/1000 | Loss: 0.00001998
Iteration 54/1000 | Loss: 0.00001998
Iteration 55/1000 | Loss: 0.00001998
Iteration 56/1000 | Loss: 0.00001997
Iteration 57/1000 | Loss: 0.00001997
Iteration 58/1000 | Loss: 0.00001997
Iteration 59/1000 | Loss: 0.00001997
Iteration 60/1000 | Loss: 0.00001997
Iteration 61/1000 | Loss: 0.00001997
Iteration 62/1000 | Loss: 0.00001997
Iteration 63/1000 | Loss: 0.00001996
Iteration 64/1000 | Loss: 0.00001996
Iteration 65/1000 | Loss: 0.00001996
Iteration 66/1000 | Loss: 0.00001996
Iteration 67/1000 | Loss: 0.00001996
Iteration 68/1000 | Loss: 0.00001996
Iteration 69/1000 | Loss: 0.00001995
Iteration 70/1000 | Loss: 0.00001995
Iteration 71/1000 | Loss: 0.00001995
Iteration 72/1000 | Loss: 0.00001994
Iteration 73/1000 | Loss: 0.00001994
Iteration 74/1000 | Loss: 0.00001994
Iteration 75/1000 | Loss: 0.00001994
Iteration 76/1000 | Loss: 0.00001993
Iteration 77/1000 | Loss: 0.00001993
Iteration 78/1000 | Loss: 0.00001993
Iteration 79/1000 | Loss: 0.00001993
Iteration 80/1000 | Loss: 0.00001993
Iteration 81/1000 | Loss: 0.00001992
Iteration 82/1000 | Loss: 0.00001992
Iteration 83/1000 | Loss: 0.00001992
Iteration 84/1000 | Loss: 0.00001992
Iteration 85/1000 | Loss: 0.00001992
Iteration 86/1000 | Loss: 0.00001992
Iteration 87/1000 | Loss: 0.00001992
Iteration 88/1000 | Loss: 0.00001992
Iteration 89/1000 | Loss: 0.00001992
Iteration 90/1000 | Loss: 0.00001992
Iteration 91/1000 | Loss: 0.00001992
Iteration 92/1000 | Loss: 0.00001992
Iteration 93/1000 | Loss: 0.00001992
Iteration 94/1000 | Loss: 0.00001992
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.99223304662155e-05, 1.99223304662155e-05, 1.99223304662155e-05, 1.99223304662155e-05, 1.99223304662155e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.99223304662155e-05

Optimization complete. Final v2v error: 3.7743618488311768 mm

Highest mean error: 3.9941320419311523 mm for frame 55

Lowest mean error: 3.2513484954833984 mm for frame 12

Saving results

Total time: 34.559261322021484
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00617703
Iteration 2/25 | Loss: 0.00094169
Iteration 3/25 | Loss: 0.00084165
Iteration 4/25 | Loss: 0.00082665
Iteration 5/25 | Loss: 0.00082213
Iteration 6/25 | Loss: 0.00082080
Iteration 7/25 | Loss: 0.00082068
Iteration 8/25 | Loss: 0.00082068
Iteration 9/25 | Loss: 0.00082068
Iteration 10/25 | Loss: 0.00082066
Iteration 11/25 | Loss: 0.00082066
Iteration 12/25 | Loss: 0.00082066
Iteration 13/25 | Loss: 0.00082066
Iteration 14/25 | Loss: 0.00082066
Iteration 15/25 | Loss: 0.00082066
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008206568891182542, 0.0008206568891182542, 0.0008206568891182542, 0.0008206568891182542, 0.0008206568891182542]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008206568891182542

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.86829853
Iteration 2/25 | Loss: 0.00068759
Iteration 3/25 | Loss: 0.00068756
Iteration 4/25 | Loss: 0.00068756
Iteration 5/25 | Loss: 0.00068756
Iteration 6/25 | Loss: 0.00068755
Iteration 7/25 | Loss: 0.00068755
Iteration 8/25 | Loss: 0.00068755
Iteration 9/25 | Loss: 0.00068755
Iteration 10/25 | Loss: 0.00068755
Iteration 11/25 | Loss: 0.00068755
Iteration 12/25 | Loss: 0.00068755
Iteration 13/25 | Loss: 0.00068755
Iteration 14/25 | Loss: 0.00068755
Iteration 15/25 | Loss: 0.00068755
Iteration 16/25 | Loss: 0.00068755
Iteration 17/25 | Loss: 0.00068755
Iteration 18/25 | Loss: 0.00068755
Iteration 19/25 | Loss: 0.00068755
Iteration 20/25 | Loss: 0.00068755
Iteration 21/25 | Loss: 0.00068755
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0006875533726997674, 0.0006875533726997674, 0.0006875533726997674, 0.0006875533726997674, 0.0006875533726997674]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006875533726997674

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00068755
Iteration 2/1000 | Loss: 0.00002531
Iteration 3/1000 | Loss: 0.00001641
Iteration 4/1000 | Loss: 0.00001500
Iteration 5/1000 | Loss: 0.00001405
Iteration 6/1000 | Loss: 0.00001370
Iteration 7/1000 | Loss: 0.00001343
Iteration 8/1000 | Loss: 0.00001323
Iteration 9/1000 | Loss: 0.00001308
Iteration 10/1000 | Loss: 0.00001293
Iteration 11/1000 | Loss: 0.00001292
Iteration 12/1000 | Loss: 0.00001283
Iteration 13/1000 | Loss: 0.00001280
Iteration 14/1000 | Loss: 0.00001277
Iteration 15/1000 | Loss: 0.00001276
Iteration 16/1000 | Loss: 0.00001270
Iteration 17/1000 | Loss: 0.00001270
Iteration 18/1000 | Loss: 0.00001268
Iteration 19/1000 | Loss: 0.00001268
Iteration 20/1000 | Loss: 0.00001267
Iteration 21/1000 | Loss: 0.00001267
Iteration 22/1000 | Loss: 0.00001267
Iteration 23/1000 | Loss: 0.00001266
Iteration 24/1000 | Loss: 0.00001266
Iteration 25/1000 | Loss: 0.00001266
Iteration 26/1000 | Loss: 0.00001265
Iteration 27/1000 | Loss: 0.00001265
Iteration 28/1000 | Loss: 0.00001265
Iteration 29/1000 | Loss: 0.00001265
Iteration 30/1000 | Loss: 0.00001265
Iteration 31/1000 | Loss: 0.00001264
Iteration 32/1000 | Loss: 0.00001264
Iteration 33/1000 | Loss: 0.00001264
Iteration 34/1000 | Loss: 0.00001264
Iteration 35/1000 | Loss: 0.00001264
Iteration 36/1000 | Loss: 0.00001263
Iteration 37/1000 | Loss: 0.00001263
Iteration 38/1000 | Loss: 0.00001262
Iteration 39/1000 | Loss: 0.00001261
Iteration 40/1000 | Loss: 0.00001261
Iteration 41/1000 | Loss: 0.00001261
Iteration 42/1000 | Loss: 0.00001261
Iteration 43/1000 | Loss: 0.00001261
Iteration 44/1000 | Loss: 0.00001261
Iteration 45/1000 | Loss: 0.00001261
Iteration 46/1000 | Loss: 0.00001260
Iteration 47/1000 | Loss: 0.00001258
Iteration 48/1000 | Loss: 0.00001258
Iteration 49/1000 | Loss: 0.00001257
Iteration 50/1000 | Loss: 0.00001257
Iteration 51/1000 | Loss: 0.00001257
Iteration 52/1000 | Loss: 0.00001256
Iteration 53/1000 | Loss: 0.00001256
Iteration 54/1000 | Loss: 0.00001256
Iteration 55/1000 | Loss: 0.00001256
Iteration 56/1000 | Loss: 0.00001255
Iteration 57/1000 | Loss: 0.00001254
Iteration 58/1000 | Loss: 0.00001254
Iteration 59/1000 | Loss: 0.00001253
Iteration 60/1000 | Loss: 0.00001251
Iteration 61/1000 | Loss: 0.00001251
Iteration 62/1000 | Loss: 0.00001251
Iteration 63/1000 | Loss: 0.00001250
Iteration 64/1000 | Loss: 0.00001250
Iteration 65/1000 | Loss: 0.00001249
Iteration 66/1000 | Loss: 0.00001249
Iteration 67/1000 | Loss: 0.00001247
Iteration 68/1000 | Loss: 0.00001247
Iteration 69/1000 | Loss: 0.00001246
Iteration 70/1000 | Loss: 0.00001246
Iteration 71/1000 | Loss: 0.00001246
Iteration 72/1000 | Loss: 0.00001246
Iteration 73/1000 | Loss: 0.00001246
Iteration 74/1000 | Loss: 0.00001246
Iteration 75/1000 | Loss: 0.00001246
Iteration 76/1000 | Loss: 0.00001245
Iteration 77/1000 | Loss: 0.00001245
Iteration 78/1000 | Loss: 0.00001245
Iteration 79/1000 | Loss: 0.00001244
Iteration 80/1000 | Loss: 0.00001244
Iteration 81/1000 | Loss: 0.00001244
Iteration 82/1000 | Loss: 0.00001244
Iteration 83/1000 | Loss: 0.00001244
Iteration 84/1000 | Loss: 0.00001244
Iteration 85/1000 | Loss: 0.00001244
Iteration 86/1000 | Loss: 0.00001244
Iteration 87/1000 | Loss: 0.00001244
Iteration 88/1000 | Loss: 0.00001244
Iteration 89/1000 | Loss: 0.00001244
Iteration 90/1000 | Loss: 0.00001243
Iteration 91/1000 | Loss: 0.00001243
Iteration 92/1000 | Loss: 0.00001243
Iteration 93/1000 | Loss: 0.00001243
Iteration 94/1000 | Loss: 0.00001243
Iteration 95/1000 | Loss: 0.00001243
Iteration 96/1000 | Loss: 0.00001243
Iteration 97/1000 | Loss: 0.00001243
Iteration 98/1000 | Loss: 0.00001243
Iteration 99/1000 | Loss: 0.00001243
Iteration 100/1000 | Loss: 0.00001242
Iteration 101/1000 | Loss: 0.00001242
Iteration 102/1000 | Loss: 0.00001242
Iteration 103/1000 | Loss: 0.00001242
Iteration 104/1000 | Loss: 0.00001242
Iteration 105/1000 | Loss: 0.00001242
Iteration 106/1000 | Loss: 0.00001242
Iteration 107/1000 | Loss: 0.00001242
Iteration 108/1000 | Loss: 0.00001242
Iteration 109/1000 | Loss: 0.00001242
Iteration 110/1000 | Loss: 0.00001242
Iteration 111/1000 | Loss: 0.00001242
Iteration 112/1000 | Loss: 0.00001242
Iteration 113/1000 | Loss: 0.00001242
Iteration 114/1000 | Loss: 0.00001242
Iteration 115/1000 | Loss: 0.00001242
Iteration 116/1000 | Loss: 0.00001242
Iteration 117/1000 | Loss: 0.00001242
Iteration 118/1000 | Loss: 0.00001242
Iteration 119/1000 | Loss: 0.00001242
Iteration 120/1000 | Loss: 0.00001242
Iteration 121/1000 | Loss: 0.00001242
Iteration 122/1000 | Loss: 0.00001242
Iteration 123/1000 | Loss: 0.00001242
Iteration 124/1000 | Loss: 0.00001242
Iteration 125/1000 | Loss: 0.00001242
Iteration 126/1000 | Loss: 0.00001242
Iteration 127/1000 | Loss: 0.00001242
Iteration 128/1000 | Loss: 0.00001242
Iteration 129/1000 | Loss: 0.00001242
Iteration 130/1000 | Loss: 0.00001242
Iteration 131/1000 | Loss: 0.00001242
Iteration 132/1000 | Loss: 0.00001242
Iteration 133/1000 | Loss: 0.00001242
Iteration 134/1000 | Loss: 0.00001241
Iteration 135/1000 | Loss: 0.00001241
Iteration 136/1000 | Loss: 0.00001241
Iteration 137/1000 | Loss: 0.00001241
Iteration 138/1000 | Loss: 0.00001241
Iteration 139/1000 | Loss: 0.00001241
Iteration 140/1000 | Loss: 0.00001241
Iteration 141/1000 | Loss: 0.00001241
Iteration 142/1000 | Loss: 0.00001241
Iteration 143/1000 | Loss: 0.00001241
Iteration 144/1000 | Loss: 0.00001241
Iteration 145/1000 | Loss: 0.00001241
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [1.2414775483193807e-05, 1.2414775483193807e-05, 1.2414775483193807e-05, 1.2414775483193807e-05, 1.2414775483193807e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2414775483193807e-05

Optimization complete. Final v2v error: 3.003868818283081 mm

Highest mean error: 3.299769163131714 mm for frame 117

Lowest mean error: 2.8052852153778076 mm for frame 21

Saving results

Total time: 40.12056493759155
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1038/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1038.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1038
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01122472
Iteration 2/25 | Loss: 0.01122472
Iteration 3/25 | Loss: 0.00421386
Iteration 4/25 | Loss: 0.00293701
Iteration 5/25 | Loss: 0.00274236
Iteration 6/25 | Loss: 0.00247268
Iteration 7/25 | Loss: 0.00224780
Iteration 8/25 | Loss: 0.00210030
Iteration 9/25 | Loss: 0.00196483
Iteration 10/25 | Loss: 0.00173580
Iteration 11/25 | Loss: 0.00165091
Iteration 12/25 | Loss: 0.00157338
Iteration 13/25 | Loss: 0.00152881
Iteration 14/25 | Loss: 0.00148696
Iteration 15/25 | Loss: 0.00145773
Iteration 16/25 | Loss: 0.00142857
Iteration 17/25 | Loss: 0.00141687
Iteration 18/25 | Loss: 0.00138124
Iteration 19/25 | Loss: 0.00135980
Iteration 20/25 | Loss: 0.00135169
Iteration 21/25 | Loss: 0.00131808
Iteration 22/25 | Loss: 0.00131705
Iteration 23/25 | Loss: 0.00128264
Iteration 24/25 | Loss: 0.00127055
Iteration 25/25 | Loss: 0.00126656

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29034030
Iteration 2/25 | Loss: 0.00339864
Iteration 3/25 | Loss: 0.00338586
Iteration 4/25 | Loss: 0.00338586
Iteration 5/25 | Loss: 0.00338586
Iteration 6/25 | Loss: 0.00338586
Iteration 7/25 | Loss: 0.00338585
Iteration 8/25 | Loss: 0.00338585
Iteration 9/25 | Loss: 0.00338585
Iteration 10/25 | Loss: 0.00338585
Iteration 11/25 | Loss: 0.00338585
Iteration 12/25 | Loss: 0.00338585
Iteration 13/25 | Loss: 0.00338585
Iteration 14/25 | Loss: 0.00338585
Iteration 15/25 | Loss: 0.00338585
Iteration 16/25 | Loss: 0.00338585
Iteration 17/25 | Loss: 0.00338585
Iteration 18/25 | Loss: 0.00338585
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.003385852789506316, 0.003385852789506316, 0.003385852789506316, 0.003385852789506316, 0.003385852789506316]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003385852789506316

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00338585
Iteration 2/1000 | Loss: 0.00081627
Iteration 3/1000 | Loss: 0.00069542
Iteration 4/1000 | Loss: 0.00050388
Iteration 5/1000 | Loss: 0.00028084
Iteration 6/1000 | Loss: 0.00066503
Iteration 7/1000 | Loss: 0.00057667
Iteration 8/1000 | Loss: 0.00048094
Iteration 9/1000 | Loss: 0.00036194
Iteration 10/1000 | Loss: 0.00056737
Iteration 11/1000 | Loss: 0.00021144
Iteration 12/1000 | Loss: 0.00043021
Iteration 13/1000 | Loss: 0.00047774
Iteration 14/1000 | Loss: 0.00033743
Iteration 15/1000 | Loss: 0.00021382
Iteration 16/1000 | Loss: 0.00018203
Iteration 17/1000 | Loss: 0.00026893
Iteration 18/1000 | Loss: 0.00020967
Iteration 19/1000 | Loss: 0.00095355
Iteration 20/1000 | Loss: 0.00065071
Iteration 21/1000 | Loss: 0.00032629
Iteration 22/1000 | Loss: 0.00019487
Iteration 23/1000 | Loss: 0.00201825
Iteration 24/1000 | Loss: 0.00439351
Iteration 25/1000 | Loss: 0.00710137
Iteration 26/1000 | Loss: 0.00113575
Iteration 27/1000 | Loss: 0.00023429
Iteration 28/1000 | Loss: 0.00067700
Iteration 29/1000 | Loss: 0.00047539
Iteration 30/1000 | Loss: 0.00026333
Iteration 31/1000 | Loss: 0.00095606
Iteration 32/1000 | Loss: 0.00016684
Iteration 33/1000 | Loss: 0.00011429
Iteration 34/1000 | Loss: 0.00025648
Iteration 35/1000 | Loss: 0.00009738
Iteration 36/1000 | Loss: 0.00009162
Iteration 37/1000 | Loss: 0.00007735
Iteration 38/1000 | Loss: 0.00023362
Iteration 39/1000 | Loss: 0.00021764
Iteration 40/1000 | Loss: 0.00014984
Iteration 41/1000 | Loss: 0.00014966
Iteration 42/1000 | Loss: 0.00050256
Iteration 43/1000 | Loss: 0.00012482
Iteration 44/1000 | Loss: 0.00007499
Iteration 45/1000 | Loss: 0.00006859
Iteration 46/1000 | Loss: 0.00009022
Iteration 47/1000 | Loss: 0.00020298
Iteration 48/1000 | Loss: 0.00006319
Iteration 49/1000 | Loss: 0.00005260
Iteration 50/1000 | Loss: 0.00005023
Iteration 51/1000 | Loss: 0.00006878
Iteration 52/1000 | Loss: 0.00007617
Iteration 53/1000 | Loss: 0.00007293
Iteration 54/1000 | Loss: 0.00003929
Iteration 55/1000 | Loss: 0.00004495
Iteration 56/1000 | Loss: 0.00015149
Iteration 57/1000 | Loss: 0.00005254
Iteration 58/1000 | Loss: 0.00004101
Iteration 59/1000 | Loss: 0.00004452
Iteration 60/1000 | Loss: 0.00005292
Iteration 61/1000 | Loss: 0.00004473
Iteration 62/1000 | Loss: 0.00006784
Iteration 63/1000 | Loss: 0.00004501
Iteration 64/1000 | Loss: 0.00003920
Iteration 65/1000 | Loss: 0.00006422
Iteration 66/1000 | Loss: 0.00004203
Iteration 67/1000 | Loss: 0.00006457
Iteration 68/1000 | Loss: 0.00004609
Iteration 69/1000 | Loss: 0.00005753
Iteration 70/1000 | Loss: 0.00005072
Iteration 71/1000 | Loss: 0.00004159
Iteration 72/1000 | Loss: 0.00003264
Iteration 73/1000 | Loss: 0.00003697
Iteration 74/1000 | Loss: 0.00020992
Iteration 75/1000 | Loss: 0.00007551
Iteration 76/1000 | Loss: 0.00005995
Iteration 77/1000 | Loss: 0.00049319
Iteration 78/1000 | Loss: 0.00007049
Iteration 79/1000 | Loss: 0.00006247
Iteration 80/1000 | Loss: 0.00005823
Iteration 81/1000 | Loss: 0.00004628
Iteration 82/1000 | Loss: 0.00004912
Iteration 83/1000 | Loss: 0.00027410
Iteration 84/1000 | Loss: 0.00028011
Iteration 85/1000 | Loss: 0.00005951
Iteration 86/1000 | Loss: 0.00004055
Iteration 87/1000 | Loss: 0.00005307
Iteration 88/1000 | Loss: 0.00003170
Iteration 89/1000 | Loss: 0.00003215
Iteration 90/1000 | Loss: 0.00003752
Iteration 91/1000 | Loss: 0.00005064
Iteration 92/1000 | Loss: 0.00004263
Iteration 93/1000 | Loss: 0.00004532
Iteration 94/1000 | Loss: 0.00004698
Iteration 95/1000 | Loss: 0.00004555
Iteration 96/1000 | Loss: 0.00003783
Iteration 97/1000 | Loss: 0.00005726
Iteration 98/1000 | Loss: 0.00003371
Iteration 99/1000 | Loss: 0.00004072
Iteration 100/1000 | Loss: 0.00003165
Iteration 101/1000 | Loss: 0.00004848
Iteration 102/1000 | Loss: 0.00002940
Iteration 103/1000 | Loss: 0.00004549
Iteration 104/1000 | Loss: 0.00004028
Iteration 105/1000 | Loss: 0.00007196
Iteration 106/1000 | Loss: 0.00014489
Iteration 107/1000 | Loss: 0.00022217
Iteration 108/1000 | Loss: 0.00018055
Iteration 109/1000 | Loss: 0.00003172
Iteration 110/1000 | Loss: 0.00002984
Iteration 111/1000 | Loss: 0.00004481
Iteration 112/1000 | Loss: 0.00025366
Iteration 113/1000 | Loss: 0.00014304
Iteration 114/1000 | Loss: 0.00050823
Iteration 115/1000 | Loss: 0.00094683
Iteration 116/1000 | Loss: 0.00072458
Iteration 117/1000 | Loss: 0.00060361
Iteration 118/1000 | Loss: 0.00063842
Iteration 119/1000 | Loss: 0.00070030
Iteration 120/1000 | Loss: 0.00019564
Iteration 121/1000 | Loss: 0.00004292
Iteration 122/1000 | Loss: 0.00004240
Iteration 123/1000 | Loss: 0.00012979
Iteration 124/1000 | Loss: 0.00013533
Iteration 125/1000 | Loss: 0.00003472
Iteration 126/1000 | Loss: 0.00002926
Iteration 127/1000 | Loss: 0.00002825
Iteration 128/1000 | Loss: 0.00002742
Iteration 129/1000 | Loss: 0.00008911
Iteration 130/1000 | Loss: 0.00002643
Iteration 131/1000 | Loss: 0.00002502
Iteration 132/1000 | Loss: 0.00002453
Iteration 133/1000 | Loss: 0.00002493
Iteration 134/1000 | Loss: 0.00002443
Iteration 135/1000 | Loss: 0.00002404
Iteration 136/1000 | Loss: 0.00002444
Iteration 137/1000 | Loss: 0.00002395
Iteration 138/1000 | Loss: 0.00002392
Iteration 139/1000 | Loss: 0.00002388
Iteration 140/1000 | Loss: 0.00002381
Iteration 141/1000 | Loss: 0.00002380
Iteration 142/1000 | Loss: 0.00002379
Iteration 143/1000 | Loss: 0.00002378
Iteration 144/1000 | Loss: 0.00002378
Iteration 145/1000 | Loss: 0.00002378
Iteration 146/1000 | Loss: 0.00002377
Iteration 147/1000 | Loss: 0.00002377
Iteration 148/1000 | Loss: 0.00002377
Iteration 149/1000 | Loss: 0.00002376
Iteration 150/1000 | Loss: 0.00002372
Iteration 151/1000 | Loss: 0.00002371
Iteration 152/1000 | Loss: 0.00002370
Iteration 153/1000 | Loss: 0.00002367
Iteration 154/1000 | Loss: 0.00004210
Iteration 155/1000 | Loss: 0.00002371
Iteration 156/1000 | Loss: 0.00002361
Iteration 157/1000 | Loss: 0.00002358
Iteration 158/1000 | Loss: 0.00002357
Iteration 159/1000 | Loss: 0.00002357
Iteration 160/1000 | Loss: 0.00003849
Iteration 161/1000 | Loss: 0.00002360
Iteration 162/1000 | Loss: 0.00003950
Iteration 163/1000 | Loss: 0.00004122
Iteration 164/1000 | Loss: 0.00002690
Iteration 165/1000 | Loss: 0.00004000
Iteration 166/1000 | Loss: 0.00002601
Iteration 167/1000 | Loss: 0.00004556
Iteration 168/1000 | Loss: 0.00004040
Iteration 169/1000 | Loss: 0.00004207
Iteration 170/1000 | Loss: 0.00003954
Iteration 171/1000 | Loss: 0.00004048
Iteration 172/1000 | Loss: 0.00002375
Iteration 173/1000 | Loss: 0.00002345
Iteration 174/1000 | Loss: 0.00002345
Iteration 175/1000 | Loss: 0.00002344
Iteration 176/1000 | Loss: 0.00002338
Iteration 177/1000 | Loss: 0.00002326
Iteration 178/1000 | Loss: 0.00003845
Iteration 179/1000 | Loss: 0.00002323
Iteration 180/1000 | Loss: 0.00002320
Iteration 181/1000 | Loss: 0.00002320
Iteration 182/1000 | Loss: 0.00002320
Iteration 183/1000 | Loss: 0.00002320
Iteration 184/1000 | Loss: 0.00002320
Iteration 185/1000 | Loss: 0.00002319
Iteration 186/1000 | Loss: 0.00002319
Iteration 187/1000 | Loss: 0.00002319
Iteration 188/1000 | Loss: 0.00002319
Iteration 189/1000 | Loss: 0.00002319
Iteration 190/1000 | Loss: 0.00002319
Iteration 191/1000 | Loss: 0.00002319
Iteration 192/1000 | Loss: 0.00002319
Iteration 193/1000 | Loss: 0.00002318
Iteration 194/1000 | Loss: 0.00002318
Iteration 195/1000 | Loss: 0.00002318
Iteration 196/1000 | Loss: 0.00002318
Iteration 197/1000 | Loss: 0.00002318
Iteration 198/1000 | Loss: 0.00002318
Iteration 199/1000 | Loss: 0.00002317
Iteration 200/1000 | Loss: 0.00002317
Iteration 201/1000 | Loss: 0.00002317
Iteration 202/1000 | Loss: 0.00002317
Iteration 203/1000 | Loss: 0.00002317
Iteration 204/1000 | Loss: 0.00002317
Iteration 205/1000 | Loss: 0.00002317
Iteration 206/1000 | Loss: 0.00002317
Iteration 207/1000 | Loss: 0.00002317
Iteration 208/1000 | Loss: 0.00002317
Iteration 209/1000 | Loss: 0.00002316
Iteration 210/1000 | Loss: 0.00002316
Iteration 211/1000 | Loss: 0.00002316
Iteration 212/1000 | Loss: 0.00002316
Iteration 213/1000 | Loss: 0.00002316
Iteration 214/1000 | Loss: 0.00002316
Iteration 215/1000 | Loss: 0.00002316
Iteration 216/1000 | Loss: 0.00002316
Iteration 217/1000 | Loss: 0.00002315
Iteration 218/1000 | Loss: 0.00002315
Iteration 219/1000 | Loss: 0.00002315
Iteration 220/1000 | Loss: 0.00002314
Iteration 221/1000 | Loss: 0.00002314
Iteration 222/1000 | Loss: 0.00002313
Iteration 223/1000 | Loss: 0.00002313
Iteration 224/1000 | Loss: 0.00002313
Iteration 225/1000 | Loss: 0.00003596
Iteration 226/1000 | Loss: 0.00003596
Iteration 227/1000 | Loss: 0.00003650
Iteration 228/1000 | Loss: 0.00002551
Iteration 229/1000 | Loss: 0.00002314
Iteration 230/1000 | Loss: 0.00002314
Iteration 231/1000 | Loss: 0.00002314
Iteration 232/1000 | Loss: 0.00002314
Iteration 233/1000 | Loss: 0.00002313
Iteration 234/1000 | Loss: 0.00002313
Iteration 235/1000 | Loss: 0.00002312
Iteration 236/1000 | Loss: 0.00002311
Iteration 237/1000 | Loss: 0.00002311
Iteration 238/1000 | Loss: 0.00002311
Iteration 239/1000 | Loss: 0.00002311
Iteration 240/1000 | Loss: 0.00002311
Iteration 241/1000 | Loss: 0.00002311
Iteration 242/1000 | Loss: 0.00002311
Iteration 243/1000 | Loss: 0.00002311
Iteration 244/1000 | Loss: 0.00002311
Iteration 245/1000 | Loss: 0.00002310
Iteration 246/1000 | Loss: 0.00002310
Iteration 247/1000 | Loss: 0.00002310
Iteration 248/1000 | Loss: 0.00002310
Iteration 249/1000 | Loss: 0.00002310
Iteration 250/1000 | Loss: 0.00002310
Iteration 251/1000 | Loss: 0.00002310
Iteration 252/1000 | Loss: 0.00002310
Iteration 253/1000 | Loss: 0.00002310
Iteration 254/1000 | Loss: 0.00002310
Iteration 255/1000 | Loss: 0.00002310
Iteration 256/1000 | Loss: 0.00002310
Iteration 257/1000 | Loss: 0.00002310
Iteration 258/1000 | Loss: 0.00002310
Iteration 259/1000 | Loss: 0.00002310
Iteration 260/1000 | Loss: 0.00002310
Iteration 261/1000 | Loss: 0.00002310
Iteration 262/1000 | Loss: 0.00002310
Iteration 263/1000 | Loss: 0.00002310
Iteration 264/1000 | Loss: 0.00002310
Iteration 265/1000 | Loss: 0.00002310
Iteration 266/1000 | Loss: 0.00002310
Iteration 267/1000 | Loss: 0.00002310
Iteration 268/1000 | Loss: 0.00002310
Iteration 269/1000 | Loss: 0.00002309
Iteration 270/1000 | Loss: 0.00002309
Iteration 271/1000 | Loss: 0.00002309
Iteration 272/1000 | Loss: 0.00002309
Iteration 273/1000 | Loss: 0.00002309
Iteration 274/1000 | Loss: 0.00002309
Iteration 275/1000 | Loss: 0.00002309
Iteration 276/1000 | Loss: 0.00002309
Iteration 277/1000 | Loss: 0.00002309
Iteration 278/1000 | Loss: 0.00002309
Iteration 279/1000 | Loss: 0.00002309
Iteration 280/1000 | Loss: 0.00002309
Iteration 281/1000 | Loss: 0.00002309
Iteration 282/1000 | Loss: 0.00002309
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 282. Stopping optimization.
Last 5 losses: [2.3094224161468446e-05, 2.3094224161468446e-05, 2.3094224161468446e-05, 2.3094224161468446e-05, 2.3094224161468446e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3094224161468446e-05

Optimization complete. Final v2v error: 3.860196113586426 mm

Highest mean error: 6.184427261352539 mm for frame 29

Lowest mean error: 3.45212721824646 mm for frame 19

Saving results

Total time: 312.021457195282
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1025
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00397079
Iteration 2/25 | Loss: 0.00098800
Iteration 3/25 | Loss: 0.00086107
Iteration 4/25 | Loss: 0.00084858
Iteration 5/25 | Loss: 0.00084228
Iteration 6/25 | Loss: 0.00084079
Iteration 7/25 | Loss: 0.00084079
Iteration 8/25 | Loss: 0.00084079
Iteration 9/25 | Loss: 0.00084079
Iteration 10/25 | Loss: 0.00084079
Iteration 11/25 | Loss: 0.00084079
Iteration 12/25 | Loss: 0.00084079
Iteration 13/25 | Loss: 0.00084079
Iteration 14/25 | Loss: 0.00084079
Iteration 15/25 | Loss: 0.00084079
Iteration 16/25 | Loss: 0.00084079
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008407882414758205, 0.0008407882414758205, 0.0008407882414758205, 0.0008407882414758205, 0.0008407882414758205]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008407882414758205

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.77299654
Iteration 2/25 | Loss: 0.00072383
Iteration 3/25 | Loss: 0.00072383
Iteration 4/25 | Loss: 0.00072383
Iteration 5/25 | Loss: 0.00072383
Iteration 6/25 | Loss: 0.00072383
Iteration 7/25 | Loss: 0.00072383
Iteration 8/25 | Loss: 0.00072383
Iteration 9/25 | Loss: 0.00072382
Iteration 10/25 | Loss: 0.00072382
Iteration 11/25 | Loss: 0.00072382
Iteration 12/25 | Loss: 0.00072382
Iteration 13/25 | Loss: 0.00072382
Iteration 14/25 | Loss: 0.00072382
Iteration 15/25 | Loss: 0.00072382
Iteration 16/25 | Loss: 0.00072382
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00072382454527542, 0.00072382454527542, 0.00072382454527542, 0.00072382454527542, 0.00072382454527542]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00072382454527542

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00072382
Iteration 2/1000 | Loss: 0.00003102
Iteration 3/1000 | Loss: 0.00001988
Iteration 4/1000 | Loss: 0.00001746
Iteration 5/1000 | Loss: 0.00001628
Iteration 6/1000 | Loss: 0.00001529
Iteration 7/1000 | Loss: 0.00001493
Iteration 8/1000 | Loss: 0.00001462
Iteration 9/1000 | Loss: 0.00001442
Iteration 10/1000 | Loss: 0.00001438
Iteration 11/1000 | Loss: 0.00001414
Iteration 12/1000 | Loss: 0.00001399
Iteration 13/1000 | Loss: 0.00001395
Iteration 14/1000 | Loss: 0.00001389
Iteration 15/1000 | Loss: 0.00001388
Iteration 16/1000 | Loss: 0.00001387
Iteration 17/1000 | Loss: 0.00001387
Iteration 18/1000 | Loss: 0.00001382
Iteration 19/1000 | Loss: 0.00001381
Iteration 20/1000 | Loss: 0.00001381
Iteration 21/1000 | Loss: 0.00001380
Iteration 22/1000 | Loss: 0.00001379
Iteration 23/1000 | Loss: 0.00001371
Iteration 24/1000 | Loss: 0.00001370
Iteration 25/1000 | Loss: 0.00001370
Iteration 26/1000 | Loss: 0.00001368
Iteration 27/1000 | Loss: 0.00001366
Iteration 28/1000 | Loss: 0.00001366
Iteration 29/1000 | Loss: 0.00001365
Iteration 30/1000 | Loss: 0.00001365
Iteration 31/1000 | Loss: 0.00001361
Iteration 32/1000 | Loss: 0.00001361
Iteration 33/1000 | Loss: 0.00001360
Iteration 34/1000 | Loss: 0.00001360
Iteration 35/1000 | Loss: 0.00001360
Iteration 36/1000 | Loss: 0.00001360
Iteration 37/1000 | Loss: 0.00001359
Iteration 38/1000 | Loss: 0.00001359
Iteration 39/1000 | Loss: 0.00001358
Iteration 40/1000 | Loss: 0.00001358
Iteration 41/1000 | Loss: 0.00001357
Iteration 42/1000 | Loss: 0.00001357
Iteration 43/1000 | Loss: 0.00001356
Iteration 44/1000 | Loss: 0.00001356
Iteration 45/1000 | Loss: 0.00001356
Iteration 46/1000 | Loss: 0.00001356
Iteration 47/1000 | Loss: 0.00001355
Iteration 48/1000 | Loss: 0.00001355
Iteration 49/1000 | Loss: 0.00001355
Iteration 50/1000 | Loss: 0.00001354
Iteration 51/1000 | Loss: 0.00001354
Iteration 52/1000 | Loss: 0.00001354
Iteration 53/1000 | Loss: 0.00001353
Iteration 54/1000 | Loss: 0.00001353
Iteration 55/1000 | Loss: 0.00001353
Iteration 56/1000 | Loss: 0.00001353
Iteration 57/1000 | Loss: 0.00001353
Iteration 58/1000 | Loss: 0.00001353
Iteration 59/1000 | Loss: 0.00001353
Iteration 60/1000 | Loss: 0.00001353
Iteration 61/1000 | Loss: 0.00001353
Iteration 62/1000 | Loss: 0.00001353
Iteration 63/1000 | Loss: 0.00001353
Iteration 64/1000 | Loss: 0.00001353
Iteration 65/1000 | Loss: 0.00001352
Iteration 66/1000 | Loss: 0.00001352
Iteration 67/1000 | Loss: 0.00001352
Iteration 68/1000 | Loss: 0.00001352
Iteration 69/1000 | Loss: 0.00001352
Iteration 70/1000 | Loss: 0.00001352
Iteration 71/1000 | Loss: 0.00001352
Iteration 72/1000 | Loss: 0.00001352
Iteration 73/1000 | Loss: 0.00001352
Iteration 74/1000 | Loss: 0.00001352
Iteration 75/1000 | Loss: 0.00001352
Iteration 76/1000 | Loss: 0.00001351
Iteration 77/1000 | Loss: 0.00001351
Iteration 78/1000 | Loss: 0.00001351
Iteration 79/1000 | Loss: 0.00001351
Iteration 80/1000 | Loss: 0.00001350
Iteration 81/1000 | Loss: 0.00001350
Iteration 82/1000 | Loss: 0.00001350
Iteration 83/1000 | Loss: 0.00001350
Iteration 84/1000 | Loss: 0.00001350
Iteration 85/1000 | Loss: 0.00001350
Iteration 86/1000 | Loss: 0.00001349
Iteration 87/1000 | Loss: 0.00001349
Iteration 88/1000 | Loss: 0.00001349
Iteration 89/1000 | Loss: 0.00001349
Iteration 90/1000 | Loss: 0.00001349
Iteration 91/1000 | Loss: 0.00001349
Iteration 92/1000 | Loss: 0.00001349
Iteration 93/1000 | Loss: 0.00001349
Iteration 94/1000 | Loss: 0.00001349
Iteration 95/1000 | Loss: 0.00001349
Iteration 96/1000 | Loss: 0.00001349
Iteration 97/1000 | Loss: 0.00001349
Iteration 98/1000 | Loss: 0.00001349
Iteration 99/1000 | Loss: 0.00001349
Iteration 100/1000 | Loss: 0.00001349
Iteration 101/1000 | Loss: 0.00001349
Iteration 102/1000 | Loss: 0.00001349
Iteration 103/1000 | Loss: 0.00001349
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.3492376638168935e-05, 1.3492376638168935e-05, 1.3492376638168935e-05, 1.3492376638168935e-05, 1.3492376638168935e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3492376638168935e-05

Optimization complete. Final v2v error: 3.127082109451294 mm

Highest mean error: 3.377437114715576 mm for frame 62

Lowest mean error: 2.9100685119628906 mm for frame 263

Saving results

Total time: 37.804434061050415
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00838555
Iteration 2/25 | Loss: 0.00118624
Iteration 3/25 | Loss: 0.00093331
Iteration 4/25 | Loss: 0.00090430
Iteration 5/25 | Loss: 0.00089865
Iteration 6/25 | Loss: 0.00089707
Iteration 7/25 | Loss: 0.00089697
Iteration 8/25 | Loss: 0.00089697
Iteration 9/25 | Loss: 0.00089697
Iteration 10/25 | Loss: 0.00089697
Iteration 11/25 | Loss: 0.00089697
Iteration 12/25 | Loss: 0.00089697
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008969735354185104, 0.0008969735354185104, 0.0008969735354185104, 0.0008969735354185104, 0.0008969735354185104]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008969735354185104

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.01982260
Iteration 2/25 | Loss: 0.00056709
Iteration 3/25 | Loss: 0.00056708
Iteration 4/25 | Loss: 0.00056708
Iteration 5/25 | Loss: 0.00056708
Iteration 6/25 | Loss: 0.00056708
Iteration 7/25 | Loss: 0.00056708
Iteration 8/25 | Loss: 0.00056708
Iteration 9/25 | Loss: 0.00056708
Iteration 10/25 | Loss: 0.00056708
Iteration 11/25 | Loss: 0.00056708
Iteration 12/25 | Loss: 0.00056708
Iteration 13/25 | Loss: 0.00056708
Iteration 14/25 | Loss: 0.00056708
Iteration 15/25 | Loss: 0.00056708
Iteration 16/25 | Loss: 0.00056708
Iteration 17/25 | Loss: 0.00056708
Iteration 18/25 | Loss: 0.00056708
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005670813843607903, 0.0005670813843607903, 0.0005670813843607903, 0.0005670813843607903, 0.0005670813843607903]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005670813843607903

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056708
Iteration 2/1000 | Loss: 0.00002840
Iteration 3/1000 | Loss: 0.00002381
Iteration 4/1000 | Loss: 0.00002252
Iteration 5/1000 | Loss: 0.00002116
Iteration 6/1000 | Loss: 0.00002059
Iteration 7/1000 | Loss: 0.00002019
Iteration 8/1000 | Loss: 0.00002017
Iteration 9/1000 | Loss: 0.00001993
Iteration 10/1000 | Loss: 0.00001984
Iteration 11/1000 | Loss: 0.00001984
Iteration 12/1000 | Loss: 0.00001983
Iteration 13/1000 | Loss: 0.00001971
Iteration 14/1000 | Loss: 0.00001962
Iteration 15/1000 | Loss: 0.00001960
Iteration 16/1000 | Loss: 0.00001957
Iteration 17/1000 | Loss: 0.00001957
Iteration 18/1000 | Loss: 0.00001957
Iteration 19/1000 | Loss: 0.00001957
Iteration 20/1000 | Loss: 0.00001957
Iteration 21/1000 | Loss: 0.00001957
Iteration 22/1000 | Loss: 0.00001956
Iteration 23/1000 | Loss: 0.00001956
Iteration 24/1000 | Loss: 0.00001956
Iteration 25/1000 | Loss: 0.00001956
Iteration 26/1000 | Loss: 0.00001956
Iteration 27/1000 | Loss: 0.00001956
Iteration 28/1000 | Loss: 0.00001956
Iteration 29/1000 | Loss: 0.00001955
Iteration 30/1000 | Loss: 0.00001955
Iteration 31/1000 | Loss: 0.00001954
Iteration 32/1000 | Loss: 0.00001954
Iteration 33/1000 | Loss: 0.00001954
Iteration 34/1000 | Loss: 0.00001954
Iteration 35/1000 | Loss: 0.00001952
Iteration 36/1000 | Loss: 0.00001952
Iteration 37/1000 | Loss: 0.00001952
Iteration 38/1000 | Loss: 0.00001952
Iteration 39/1000 | Loss: 0.00001952
Iteration 40/1000 | Loss: 0.00001951
Iteration 41/1000 | Loss: 0.00001951
Iteration 42/1000 | Loss: 0.00001951
Iteration 43/1000 | Loss: 0.00001951
Iteration 44/1000 | Loss: 0.00001950
Iteration 45/1000 | Loss: 0.00001950
Iteration 46/1000 | Loss: 0.00001950
Iteration 47/1000 | Loss: 0.00001950
Iteration 48/1000 | Loss: 0.00001950
Iteration 49/1000 | Loss: 0.00001949
Iteration 50/1000 | Loss: 0.00001949
Iteration 51/1000 | Loss: 0.00001948
Iteration 52/1000 | Loss: 0.00001948
Iteration 53/1000 | Loss: 0.00001948
Iteration 54/1000 | Loss: 0.00001948
Iteration 55/1000 | Loss: 0.00001948
Iteration 56/1000 | Loss: 0.00001948
Iteration 57/1000 | Loss: 0.00001947
Iteration 58/1000 | Loss: 0.00001947
Iteration 59/1000 | Loss: 0.00001947
Iteration 60/1000 | Loss: 0.00001947
Iteration 61/1000 | Loss: 0.00001947
Iteration 62/1000 | Loss: 0.00001947
Iteration 63/1000 | Loss: 0.00001947
Iteration 64/1000 | Loss: 0.00001947
Iteration 65/1000 | Loss: 0.00001947
Iteration 66/1000 | Loss: 0.00001947
Iteration 67/1000 | Loss: 0.00001947
Iteration 68/1000 | Loss: 0.00001947
Iteration 69/1000 | Loss: 0.00001947
Iteration 70/1000 | Loss: 0.00001947
Iteration 71/1000 | Loss: 0.00001947
Iteration 72/1000 | Loss: 0.00001947
Iteration 73/1000 | Loss: 0.00001946
Iteration 74/1000 | Loss: 0.00001946
Iteration 75/1000 | Loss: 0.00001946
Iteration 76/1000 | Loss: 0.00001946
Iteration 77/1000 | Loss: 0.00001946
Iteration 78/1000 | Loss: 0.00001946
Iteration 79/1000 | Loss: 0.00001946
Iteration 80/1000 | Loss: 0.00001946
Iteration 81/1000 | Loss: 0.00001946
Iteration 82/1000 | Loss: 0.00001946
Iteration 83/1000 | Loss: 0.00001946
Iteration 84/1000 | Loss: 0.00001945
Iteration 85/1000 | Loss: 0.00001945
Iteration 86/1000 | Loss: 0.00001945
Iteration 87/1000 | Loss: 0.00001945
Iteration 88/1000 | Loss: 0.00001945
Iteration 89/1000 | Loss: 0.00001945
Iteration 90/1000 | Loss: 0.00001945
Iteration 91/1000 | Loss: 0.00001945
Iteration 92/1000 | Loss: 0.00001945
Iteration 93/1000 | Loss: 0.00001945
Iteration 94/1000 | Loss: 0.00001945
Iteration 95/1000 | Loss: 0.00001945
Iteration 96/1000 | Loss: 0.00001945
Iteration 97/1000 | Loss: 0.00001945
Iteration 98/1000 | Loss: 0.00001945
Iteration 99/1000 | Loss: 0.00001945
Iteration 100/1000 | Loss: 0.00001945
Iteration 101/1000 | Loss: 0.00001945
Iteration 102/1000 | Loss: 0.00001945
Iteration 103/1000 | Loss: 0.00001945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.9449444152996875e-05, 1.9449444152996875e-05, 1.9449444152996875e-05, 1.9449444152996875e-05, 1.9449444152996875e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9449444152996875e-05

Optimization complete. Final v2v error: 3.768077850341797 mm

Highest mean error: 3.98553204536438 mm for frame 122

Lowest mean error: 3.630307674407959 mm for frame 135

Saving results

Total time: 30.041579723358154
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1062/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1062.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1062
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00476611
Iteration 2/25 | Loss: 0.00108383
Iteration 3/25 | Loss: 0.00090934
Iteration 4/25 | Loss: 0.00089208
Iteration 5/25 | Loss: 0.00088611
Iteration 6/25 | Loss: 0.00088423
Iteration 7/25 | Loss: 0.00088397
Iteration 8/25 | Loss: 0.00088397
Iteration 9/25 | Loss: 0.00088397
Iteration 10/25 | Loss: 0.00088397
Iteration 11/25 | Loss: 0.00088397
Iteration 12/25 | Loss: 0.00088397
Iteration 13/25 | Loss: 0.00088397
Iteration 14/25 | Loss: 0.00088397
Iteration 15/25 | Loss: 0.00088397
Iteration 16/25 | Loss: 0.00088397
Iteration 17/25 | Loss: 0.00088397
Iteration 18/25 | Loss: 0.00088397
Iteration 19/25 | Loss: 0.00088397
Iteration 20/25 | Loss: 0.00088397
Iteration 21/25 | Loss: 0.00088397
Iteration 22/25 | Loss: 0.00088397
Iteration 23/25 | Loss: 0.00088397
Iteration 24/25 | Loss: 0.00088397
Iteration 25/25 | Loss: 0.00088397

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49418354
Iteration 2/25 | Loss: 0.00061370
Iteration 3/25 | Loss: 0.00061368
Iteration 4/25 | Loss: 0.00061368
Iteration 5/25 | Loss: 0.00061368
Iteration 6/25 | Loss: 0.00061368
Iteration 7/25 | Loss: 0.00061368
Iteration 8/25 | Loss: 0.00061368
Iteration 9/25 | Loss: 0.00061368
Iteration 10/25 | Loss: 0.00061368
Iteration 11/25 | Loss: 0.00061368
Iteration 12/25 | Loss: 0.00061368
Iteration 13/25 | Loss: 0.00061368
Iteration 14/25 | Loss: 0.00061368
Iteration 15/25 | Loss: 0.00061368
Iteration 16/25 | Loss: 0.00061368
Iteration 17/25 | Loss: 0.00061368
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006136758020147681, 0.0006136758020147681, 0.0006136758020147681, 0.0006136758020147681, 0.0006136758020147681]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006136758020147681

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061368
Iteration 2/1000 | Loss: 0.00003060
Iteration 3/1000 | Loss: 0.00002002
Iteration 4/1000 | Loss: 0.00001815
Iteration 5/1000 | Loss: 0.00001694
Iteration 6/1000 | Loss: 0.00001615
Iteration 7/1000 | Loss: 0.00001566
Iteration 8/1000 | Loss: 0.00001532
Iteration 9/1000 | Loss: 0.00001504
Iteration 10/1000 | Loss: 0.00001485
Iteration 11/1000 | Loss: 0.00001475
Iteration 12/1000 | Loss: 0.00001471
Iteration 13/1000 | Loss: 0.00001470
Iteration 14/1000 | Loss: 0.00001467
Iteration 15/1000 | Loss: 0.00001466
Iteration 16/1000 | Loss: 0.00001464
Iteration 17/1000 | Loss: 0.00001463
Iteration 18/1000 | Loss: 0.00001462
Iteration 19/1000 | Loss: 0.00001462
Iteration 20/1000 | Loss: 0.00001460
Iteration 21/1000 | Loss: 0.00001460
Iteration 22/1000 | Loss: 0.00001459
Iteration 23/1000 | Loss: 0.00001458
Iteration 24/1000 | Loss: 0.00001458
Iteration 25/1000 | Loss: 0.00001457
Iteration 26/1000 | Loss: 0.00001457
Iteration 27/1000 | Loss: 0.00001456
Iteration 28/1000 | Loss: 0.00001455
Iteration 29/1000 | Loss: 0.00001454
Iteration 30/1000 | Loss: 0.00001452
Iteration 31/1000 | Loss: 0.00001450
Iteration 32/1000 | Loss: 0.00001450
Iteration 33/1000 | Loss: 0.00001450
Iteration 34/1000 | Loss: 0.00001449
Iteration 35/1000 | Loss: 0.00001449
Iteration 36/1000 | Loss: 0.00001449
Iteration 37/1000 | Loss: 0.00001449
Iteration 38/1000 | Loss: 0.00001448
Iteration 39/1000 | Loss: 0.00001448
Iteration 40/1000 | Loss: 0.00001448
Iteration 41/1000 | Loss: 0.00001448
Iteration 42/1000 | Loss: 0.00001448
Iteration 43/1000 | Loss: 0.00001447
Iteration 44/1000 | Loss: 0.00001447
Iteration 45/1000 | Loss: 0.00001447
Iteration 46/1000 | Loss: 0.00001447
Iteration 47/1000 | Loss: 0.00001447
Iteration 48/1000 | Loss: 0.00001447
Iteration 49/1000 | Loss: 0.00001447
Iteration 50/1000 | Loss: 0.00001446
Iteration 51/1000 | Loss: 0.00001446
Iteration 52/1000 | Loss: 0.00001446
Iteration 53/1000 | Loss: 0.00001446
Iteration 54/1000 | Loss: 0.00001445
Iteration 55/1000 | Loss: 0.00001445
Iteration 56/1000 | Loss: 0.00001445
Iteration 57/1000 | Loss: 0.00001445
Iteration 58/1000 | Loss: 0.00001445
Iteration 59/1000 | Loss: 0.00001445
Iteration 60/1000 | Loss: 0.00001445
Iteration 61/1000 | Loss: 0.00001444
Iteration 62/1000 | Loss: 0.00001444
Iteration 63/1000 | Loss: 0.00001444
Iteration 64/1000 | Loss: 0.00001444
Iteration 65/1000 | Loss: 0.00001444
Iteration 66/1000 | Loss: 0.00001444
Iteration 67/1000 | Loss: 0.00001444
Iteration 68/1000 | Loss: 0.00001443
Iteration 69/1000 | Loss: 0.00001443
Iteration 70/1000 | Loss: 0.00001443
Iteration 71/1000 | Loss: 0.00001443
Iteration 72/1000 | Loss: 0.00001443
Iteration 73/1000 | Loss: 0.00001443
Iteration 74/1000 | Loss: 0.00001443
Iteration 75/1000 | Loss: 0.00001442
Iteration 76/1000 | Loss: 0.00001442
Iteration 77/1000 | Loss: 0.00001442
Iteration 78/1000 | Loss: 0.00001441
Iteration 79/1000 | Loss: 0.00001441
Iteration 80/1000 | Loss: 0.00001441
Iteration 81/1000 | Loss: 0.00001441
Iteration 82/1000 | Loss: 0.00001441
Iteration 83/1000 | Loss: 0.00001441
Iteration 84/1000 | Loss: 0.00001441
Iteration 85/1000 | Loss: 0.00001441
Iteration 86/1000 | Loss: 0.00001441
Iteration 87/1000 | Loss: 0.00001441
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 87. Stopping optimization.
Last 5 losses: [1.441270887880819e-05, 1.441270887880819e-05, 1.441270887880819e-05, 1.441270887880819e-05, 1.441270887880819e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.441270887880819e-05

Optimization complete. Final v2v error: 3.217710256576538 mm

Highest mean error: 3.6034929752349854 mm for frame 93

Lowest mean error: 2.868790626525879 mm for frame 139

Saving results

Total time: 36.09602975845337
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1032/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1032.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1032
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00386368
Iteration 2/25 | Loss: 0.00102095
Iteration 3/25 | Loss: 0.00088696
Iteration 4/25 | Loss: 0.00086004
Iteration 5/25 | Loss: 0.00085187
Iteration 6/25 | Loss: 0.00085003
Iteration 7/25 | Loss: 0.00084945
Iteration 8/25 | Loss: 0.00084945
Iteration 9/25 | Loss: 0.00084945
Iteration 10/25 | Loss: 0.00084945
Iteration 11/25 | Loss: 0.00084945
Iteration 12/25 | Loss: 0.00084945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008494487265124917, 0.0008494487265124917, 0.0008494487265124917, 0.0008494487265124917, 0.0008494487265124917]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008494487265124917

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49662924
Iteration 2/25 | Loss: 0.00065743
Iteration 3/25 | Loss: 0.00065742
Iteration 4/25 | Loss: 0.00065742
Iteration 5/25 | Loss: 0.00065742
Iteration 6/25 | Loss: 0.00065742
Iteration 7/25 | Loss: 0.00065742
Iteration 8/25 | Loss: 0.00065742
Iteration 9/25 | Loss: 0.00065742
Iteration 10/25 | Loss: 0.00065742
Iteration 11/25 | Loss: 0.00065742
Iteration 12/25 | Loss: 0.00065742
Iteration 13/25 | Loss: 0.00065742
Iteration 14/25 | Loss: 0.00065742
Iteration 15/25 | Loss: 0.00065742
Iteration 16/25 | Loss: 0.00065742
Iteration 17/25 | Loss: 0.00065742
Iteration 18/25 | Loss: 0.00065742
Iteration 19/25 | Loss: 0.00065742
Iteration 20/25 | Loss: 0.00065742
Iteration 21/25 | Loss: 0.00065742
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0006574224680662155, 0.0006574224680662155, 0.0006574224680662155, 0.0006574224680662155, 0.0006574224680662155]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006574224680662155

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065742
Iteration 2/1000 | Loss: 0.00005292
Iteration 3/1000 | Loss: 0.00003701
Iteration 4/1000 | Loss: 0.00003097
Iteration 5/1000 | Loss: 0.00002864
Iteration 6/1000 | Loss: 0.00002713
Iteration 7/1000 | Loss: 0.00002590
Iteration 8/1000 | Loss: 0.00002517
Iteration 9/1000 | Loss: 0.00002455
Iteration 10/1000 | Loss: 0.00002404
Iteration 11/1000 | Loss: 0.00002373
Iteration 12/1000 | Loss: 0.00002350
Iteration 13/1000 | Loss: 0.00002326
Iteration 14/1000 | Loss: 0.00002309
Iteration 15/1000 | Loss: 0.00002299
Iteration 16/1000 | Loss: 0.00002285
Iteration 17/1000 | Loss: 0.00002281
Iteration 18/1000 | Loss: 0.00002274
Iteration 19/1000 | Loss: 0.00002273
Iteration 20/1000 | Loss: 0.00002273
Iteration 21/1000 | Loss: 0.00002272
Iteration 22/1000 | Loss: 0.00002271
Iteration 23/1000 | Loss: 0.00002271
Iteration 24/1000 | Loss: 0.00002270
Iteration 25/1000 | Loss: 0.00002270
Iteration 26/1000 | Loss: 0.00002269
Iteration 27/1000 | Loss: 0.00002269
Iteration 28/1000 | Loss: 0.00002269
Iteration 29/1000 | Loss: 0.00002268
Iteration 30/1000 | Loss: 0.00002268
Iteration 31/1000 | Loss: 0.00002267
Iteration 32/1000 | Loss: 0.00002266
Iteration 33/1000 | Loss: 0.00002265
Iteration 34/1000 | Loss: 0.00002265
Iteration 35/1000 | Loss: 0.00002264
Iteration 36/1000 | Loss: 0.00002264
Iteration 37/1000 | Loss: 0.00002263
Iteration 38/1000 | Loss: 0.00002262
Iteration 39/1000 | Loss: 0.00002261
Iteration 40/1000 | Loss: 0.00002261
Iteration 41/1000 | Loss: 0.00002260
Iteration 42/1000 | Loss: 0.00002260
Iteration 43/1000 | Loss: 0.00002259
Iteration 44/1000 | Loss: 0.00002259
Iteration 45/1000 | Loss: 0.00002256
Iteration 46/1000 | Loss: 0.00002255
Iteration 47/1000 | Loss: 0.00002254
Iteration 48/1000 | Loss: 0.00002254
Iteration 49/1000 | Loss: 0.00002254
Iteration 50/1000 | Loss: 0.00002254
Iteration 51/1000 | Loss: 0.00002253
Iteration 52/1000 | Loss: 0.00002253
Iteration 53/1000 | Loss: 0.00002253
Iteration 54/1000 | Loss: 0.00002253
Iteration 55/1000 | Loss: 0.00002253
Iteration 56/1000 | Loss: 0.00002253
Iteration 57/1000 | Loss: 0.00002253
Iteration 58/1000 | Loss: 0.00002252
Iteration 59/1000 | Loss: 0.00002252
Iteration 60/1000 | Loss: 0.00002252
Iteration 61/1000 | Loss: 0.00002251
Iteration 62/1000 | Loss: 0.00002251
Iteration 63/1000 | Loss: 0.00002250
Iteration 64/1000 | Loss: 0.00002250
Iteration 65/1000 | Loss: 0.00002250
Iteration 66/1000 | Loss: 0.00002249
Iteration 67/1000 | Loss: 0.00002249
Iteration 68/1000 | Loss: 0.00002249
Iteration 69/1000 | Loss: 0.00002248
Iteration 70/1000 | Loss: 0.00002248
Iteration 71/1000 | Loss: 0.00002248
Iteration 72/1000 | Loss: 0.00002247
Iteration 73/1000 | Loss: 0.00002247
Iteration 74/1000 | Loss: 0.00002247
Iteration 75/1000 | Loss: 0.00002246
Iteration 76/1000 | Loss: 0.00002246
Iteration 77/1000 | Loss: 0.00002246
Iteration 78/1000 | Loss: 0.00002246
Iteration 79/1000 | Loss: 0.00002245
Iteration 80/1000 | Loss: 0.00002245
Iteration 81/1000 | Loss: 0.00002245
Iteration 82/1000 | Loss: 0.00002245
Iteration 83/1000 | Loss: 0.00002244
Iteration 84/1000 | Loss: 0.00002244
Iteration 85/1000 | Loss: 0.00002244
Iteration 86/1000 | Loss: 0.00002244
Iteration 87/1000 | Loss: 0.00002244
Iteration 88/1000 | Loss: 0.00002244
Iteration 89/1000 | Loss: 0.00002244
Iteration 90/1000 | Loss: 0.00002244
Iteration 91/1000 | Loss: 0.00002244
Iteration 92/1000 | Loss: 0.00002244
Iteration 93/1000 | Loss: 0.00002243
Iteration 94/1000 | Loss: 0.00002243
Iteration 95/1000 | Loss: 0.00002243
Iteration 96/1000 | Loss: 0.00002243
Iteration 97/1000 | Loss: 0.00002243
Iteration 98/1000 | Loss: 0.00002243
Iteration 99/1000 | Loss: 0.00002243
Iteration 100/1000 | Loss: 0.00002243
Iteration 101/1000 | Loss: 0.00002243
Iteration 102/1000 | Loss: 0.00002243
Iteration 103/1000 | Loss: 0.00002243
Iteration 104/1000 | Loss: 0.00002243
Iteration 105/1000 | Loss: 0.00002243
Iteration 106/1000 | Loss: 0.00002243
Iteration 107/1000 | Loss: 0.00002242
Iteration 108/1000 | Loss: 0.00002242
Iteration 109/1000 | Loss: 0.00002242
Iteration 110/1000 | Loss: 0.00002242
Iteration 111/1000 | Loss: 0.00002242
Iteration 112/1000 | Loss: 0.00002242
Iteration 113/1000 | Loss: 0.00002242
Iteration 114/1000 | Loss: 0.00002242
Iteration 115/1000 | Loss: 0.00002242
Iteration 116/1000 | Loss: 0.00002242
Iteration 117/1000 | Loss: 0.00002242
Iteration 118/1000 | Loss: 0.00002241
Iteration 119/1000 | Loss: 0.00002241
Iteration 120/1000 | Loss: 0.00002241
Iteration 121/1000 | Loss: 0.00002241
Iteration 122/1000 | Loss: 0.00002241
Iteration 123/1000 | Loss: 0.00002241
Iteration 124/1000 | Loss: 0.00002240
Iteration 125/1000 | Loss: 0.00002240
Iteration 126/1000 | Loss: 0.00002240
Iteration 127/1000 | Loss: 0.00002240
Iteration 128/1000 | Loss: 0.00002240
Iteration 129/1000 | Loss: 0.00002240
Iteration 130/1000 | Loss: 0.00002240
Iteration 131/1000 | Loss: 0.00002240
Iteration 132/1000 | Loss: 0.00002240
Iteration 133/1000 | Loss: 0.00002240
Iteration 134/1000 | Loss: 0.00002240
Iteration 135/1000 | Loss: 0.00002240
Iteration 136/1000 | Loss: 0.00002240
Iteration 137/1000 | Loss: 0.00002240
Iteration 138/1000 | Loss: 0.00002239
Iteration 139/1000 | Loss: 0.00002239
Iteration 140/1000 | Loss: 0.00002239
Iteration 141/1000 | Loss: 0.00002239
Iteration 142/1000 | Loss: 0.00002239
Iteration 143/1000 | Loss: 0.00002239
Iteration 144/1000 | Loss: 0.00002239
Iteration 145/1000 | Loss: 0.00002239
Iteration 146/1000 | Loss: 0.00002239
Iteration 147/1000 | Loss: 0.00002239
Iteration 148/1000 | Loss: 0.00002239
Iteration 149/1000 | Loss: 0.00002239
Iteration 150/1000 | Loss: 0.00002239
Iteration 151/1000 | Loss: 0.00002239
Iteration 152/1000 | Loss: 0.00002239
Iteration 153/1000 | Loss: 0.00002239
Iteration 154/1000 | Loss: 0.00002238
Iteration 155/1000 | Loss: 0.00002238
Iteration 156/1000 | Loss: 0.00002238
Iteration 157/1000 | Loss: 0.00002238
Iteration 158/1000 | Loss: 0.00002238
Iteration 159/1000 | Loss: 0.00002238
Iteration 160/1000 | Loss: 0.00002238
Iteration 161/1000 | Loss: 0.00002238
Iteration 162/1000 | Loss: 0.00002238
Iteration 163/1000 | Loss: 0.00002238
Iteration 164/1000 | Loss: 0.00002238
Iteration 165/1000 | Loss: 0.00002238
Iteration 166/1000 | Loss: 0.00002238
Iteration 167/1000 | Loss: 0.00002238
Iteration 168/1000 | Loss: 0.00002238
Iteration 169/1000 | Loss: 0.00002238
Iteration 170/1000 | Loss: 0.00002238
Iteration 171/1000 | Loss: 0.00002238
Iteration 172/1000 | Loss: 0.00002238
Iteration 173/1000 | Loss: 0.00002238
Iteration 174/1000 | Loss: 0.00002237
Iteration 175/1000 | Loss: 0.00002237
Iteration 176/1000 | Loss: 0.00002237
Iteration 177/1000 | Loss: 0.00002237
Iteration 178/1000 | Loss: 0.00002237
Iteration 179/1000 | Loss: 0.00002237
Iteration 180/1000 | Loss: 0.00002237
Iteration 181/1000 | Loss: 0.00002237
Iteration 182/1000 | Loss: 0.00002237
Iteration 183/1000 | Loss: 0.00002237
Iteration 184/1000 | Loss: 0.00002237
Iteration 185/1000 | Loss: 0.00002237
Iteration 186/1000 | Loss: 0.00002237
Iteration 187/1000 | Loss: 0.00002237
Iteration 188/1000 | Loss: 0.00002237
Iteration 189/1000 | Loss: 0.00002237
Iteration 190/1000 | Loss: 0.00002237
Iteration 191/1000 | Loss: 0.00002237
Iteration 192/1000 | Loss: 0.00002236
Iteration 193/1000 | Loss: 0.00002236
Iteration 194/1000 | Loss: 0.00002236
Iteration 195/1000 | Loss: 0.00002236
Iteration 196/1000 | Loss: 0.00002236
Iteration 197/1000 | Loss: 0.00002236
Iteration 198/1000 | Loss: 0.00002236
Iteration 199/1000 | Loss: 0.00002236
Iteration 200/1000 | Loss: 0.00002236
Iteration 201/1000 | Loss: 0.00002236
Iteration 202/1000 | Loss: 0.00002236
Iteration 203/1000 | Loss: 0.00002236
Iteration 204/1000 | Loss: 0.00002236
Iteration 205/1000 | Loss: 0.00002236
Iteration 206/1000 | Loss: 0.00002236
Iteration 207/1000 | Loss: 0.00002236
Iteration 208/1000 | Loss: 0.00002236
Iteration 209/1000 | Loss: 0.00002236
Iteration 210/1000 | Loss: 0.00002236
Iteration 211/1000 | Loss: 0.00002235
Iteration 212/1000 | Loss: 0.00002235
Iteration 213/1000 | Loss: 0.00002235
Iteration 214/1000 | Loss: 0.00002235
Iteration 215/1000 | Loss: 0.00002235
Iteration 216/1000 | Loss: 0.00002235
Iteration 217/1000 | Loss: 0.00002235
Iteration 218/1000 | Loss: 0.00002235
Iteration 219/1000 | Loss: 0.00002235
Iteration 220/1000 | Loss: 0.00002235
Iteration 221/1000 | Loss: 0.00002235
Iteration 222/1000 | Loss: 0.00002235
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 222. Stopping optimization.
Last 5 losses: [2.2353167878463864e-05, 2.2353167878463864e-05, 2.2353167878463864e-05, 2.2353167878463864e-05, 2.2353167878463864e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2353167878463864e-05

Optimization complete. Final v2v error: 3.916381359100342 mm

Highest mean error: 4.1346235275268555 mm for frame 50

Lowest mean error: 3.2901408672332764 mm for frame 11

Saving results

Total time: 48.75438070297241
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1040/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1040.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1040
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00818080
Iteration 2/25 | Loss: 0.00119933
Iteration 3/25 | Loss: 0.00088504
Iteration 4/25 | Loss: 0.00084652
Iteration 5/25 | Loss: 0.00083454
Iteration 6/25 | Loss: 0.00083178
Iteration 7/25 | Loss: 0.00083119
Iteration 8/25 | Loss: 0.00083119
Iteration 9/25 | Loss: 0.00083119
Iteration 10/25 | Loss: 0.00083119
Iteration 11/25 | Loss: 0.00083119
Iteration 12/25 | Loss: 0.00083119
Iteration 13/25 | Loss: 0.00083119
Iteration 14/25 | Loss: 0.00083119
Iteration 15/25 | Loss: 0.00083119
Iteration 16/25 | Loss: 0.00083119
Iteration 17/25 | Loss: 0.00083119
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0008311946294270456, 0.0008311946294270456, 0.0008311946294270456, 0.0008311946294270456, 0.0008311946294270456]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008311946294270456

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29130185
Iteration 2/25 | Loss: 0.00055829
Iteration 3/25 | Loss: 0.00055828
Iteration 4/25 | Loss: 0.00055828
Iteration 5/25 | Loss: 0.00055828
Iteration 6/25 | Loss: 0.00055828
Iteration 7/25 | Loss: 0.00055828
Iteration 8/25 | Loss: 0.00055828
Iteration 9/25 | Loss: 0.00055828
Iteration 10/25 | Loss: 0.00055828
Iteration 11/25 | Loss: 0.00055828
Iteration 12/25 | Loss: 0.00055828
Iteration 13/25 | Loss: 0.00055828
Iteration 14/25 | Loss: 0.00055828
Iteration 15/25 | Loss: 0.00055828
Iteration 16/25 | Loss: 0.00055828
Iteration 17/25 | Loss: 0.00055828
Iteration 18/25 | Loss: 0.00055828
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005582811427302659, 0.0005582811427302659, 0.0005582811427302659, 0.0005582811427302659, 0.0005582811427302659]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005582811427302659

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055828
Iteration 2/1000 | Loss: 0.00004301
Iteration 3/1000 | Loss: 0.00002783
Iteration 4/1000 | Loss: 0.00002433
Iteration 5/1000 | Loss: 0.00002258
Iteration 6/1000 | Loss: 0.00002108
Iteration 7/1000 | Loss: 0.00002042
Iteration 8/1000 | Loss: 0.00001986
Iteration 9/1000 | Loss: 0.00001951
Iteration 10/1000 | Loss: 0.00001927
Iteration 11/1000 | Loss: 0.00001908
Iteration 12/1000 | Loss: 0.00001892
Iteration 13/1000 | Loss: 0.00001886
Iteration 14/1000 | Loss: 0.00001871
Iteration 15/1000 | Loss: 0.00001865
Iteration 16/1000 | Loss: 0.00001855
Iteration 17/1000 | Loss: 0.00001852
Iteration 18/1000 | Loss: 0.00001851
Iteration 19/1000 | Loss: 0.00001850
Iteration 20/1000 | Loss: 0.00001849
Iteration 21/1000 | Loss: 0.00001849
Iteration 22/1000 | Loss: 0.00001843
Iteration 23/1000 | Loss: 0.00001843
Iteration 24/1000 | Loss: 0.00001842
Iteration 25/1000 | Loss: 0.00001840
Iteration 26/1000 | Loss: 0.00001840
Iteration 27/1000 | Loss: 0.00001840
Iteration 28/1000 | Loss: 0.00001840
Iteration 29/1000 | Loss: 0.00001840
Iteration 30/1000 | Loss: 0.00001840
Iteration 31/1000 | Loss: 0.00001840
Iteration 32/1000 | Loss: 0.00001840
Iteration 33/1000 | Loss: 0.00001840
Iteration 34/1000 | Loss: 0.00001840
Iteration 35/1000 | Loss: 0.00001839
Iteration 36/1000 | Loss: 0.00001839
Iteration 37/1000 | Loss: 0.00001839
Iteration 38/1000 | Loss: 0.00001839
Iteration 39/1000 | Loss: 0.00001838
Iteration 40/1000 | Loss: 0.00001838
Iteration 41/1000 | Loss: 0.00001838
Iteration 42/1000 | Loss: 0.00001837
Iteration 43/1000 | Loss: 0.00001837
Iteration 44/1000 | Loss: 0.00001837
Iteration 45/1000 | Loss: 0.00001836
Iteration 46/1000 | Loss: 0.00001835
Iteration 47/1000 | Loss: 0.00001835
Iteration 48/1000 | Loss: 0.00001835
Iteration 49/1000 | Loss: 0.00001834
Iteration 50/1000 | Loss: 0.00001832
Iteration 51/1000 | Loss: 0.00001832
Iteration 52/1000 | Loss: 0.00001830
Iteration 53/1000 | Loss: 0.00001830
Iteration 54/1000 | Loss: 0.00001829
Iteration 55/1000 | Loss: 0.00001829
Iteration 56/1000 | Loss: 0.00001829
Iteration 57/1000 | Loss: 0.00001828
Iteration 58/1000 | Loss: 0.00001823
Iteration 59/1000 | Loss: 0.00001823
Iteration 60/1000 | Loss: 0.00001822
Iteration 61/1000 | Loss: 0.00001821
Iteration 62/1000 | Loss: 0.00001821
Iteration 63/1000 | Loss: 0.00001821
Iteration 64/1000 | Loss: 0.00001820
Iteration 65/1000 | Loss: 0.00001819
Iteration 66/1000 | Loss: 0.00001819
Iteration 67/1000 | Loss: 0.00001818
Iteration 68/1000 | Loss: 0.00001818
Iteration 69/1000 | Loss: 0.00001818
Iteration 70/1000 | Loss: 0.00001817
Iteration 71/1000 | Loss: 0.00001817
Iteration 72/1000 | Loss: 0.00001817
Iteration 73/1000 | Loss: 0.00001816
Iteration 74/1000 | Loss: 0.00001815
Iteration 75/1000 | Loss: 0.00001815
Iteration 76/1000 | Loss: 0.00001814
Iteration 77/1000 | Loss: 0.00001814
Iteration 78/1000 | Loss: 0.00001814
Iteration 79/1000 | Loss: 0.00001814
Iteration 80/1000 | Loss: 0.00001813
Iteration 81/1000 | Loss: 0.00001813
Iteration 82/1000 | Loss: 0.00001813
Iteration 83/1000 | Loss: 0.00001813
Iteration 84/1000 | Loss: 0.00001813
Iteration 85/1000 | Loss: 0.00001813
Iteration 86/1000 | Loss: 0.00001813
Iteration 87/1000 | Loss: 0.00001813
Iteration 88/1000 | Loss: 0.00001813
Iteration 89/1000 | Loss: 0.00001813
Iteration 90/1000 | Loss: 0.00001812
Iteration 91/1000 | Loss: 0.00001812
Iteration 92/1000 | Loss: 0.00001812
Iteration 93/1000 | Loss: 0.00001812
Iteration 94/1000 | Loss: 0.00001812
Iteration 95/1000 | Loss: 0.00001812
Iteration 96/1000 | Loss: 0.00001812
Iteration 97/1000 | Loss: 0.00001812
Iteration 98/1000 | Loss: 0.00001812
Iteration 99/1000 | Loss: 0.00001811
Iteration 100/1000 | Loss: 0.00001811
Iteration 101/1000 | Loss: 0.00001811
Iteration 102/1000 | Loss: 0.00001811
Iteration 103/1000 | Loss: 0.00001811
Iteration 104/1000 | Loss: 0.00001811
Iteration 105/1000 | Loss: 0.00001811
Iteration 106/1000 | Loss: 0.00001811
Iteration 107/1000 | Loss: 0.00001811
Iteration 108/1000 | Loss: 0.00001811
Iteration 109/1000 | Loss: 0.00001811
Iteration 110/1000 | Loss: 0.00001811
Iteration 111/1000 | Loss: 0.00001811
Iteration 112/1000 | Loss: 0.00001811
Iteration 113/1000 | Loss: 0.00001811
Iteration 114/1000 | Loss: 0.00001811
Iteration 115/1000 | Loss: 0.00001811
Iteration 116/1000 | Loss: 0.00001811
Iteration 117/1000 | Loss: 0.00001811
Iteration 118/1000 | Loss: 0.00001811
Iteration 119/1000 | Loss: 0.00001811
Iteration 120/1000 | Loss: 0.00001811
Iteration 121/1000 | Loss: 0.00001811
Iteration 122/1000 | Loss: 0.00001811
Iteration 123/1000 | Loss: 0.00001811
Iteration 124/1000 | Loss: 0.00001811
Iteration 125/1000 | Loss: 0.00001811
Iteration 126/1000 | Loss: 0.00001811
Iteration 127/1000 | Loss: 0.00001811
Iteration 128/1000 | Loss: 0.00001811
Iteration 129/1000 | Loss: 0.00001811
Iteration 130/1000 | Loss: 0.00001811
Iteration 131/1000 | Loss: 0.00001811
Iteration 132/1000 | Loss: 0.00001811
Iteration 133/1000 | Loss: 0.00001811
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [1.8106964489561506e-05, 1.8106964489561506e-05, 1.8106964489561506e-05, 1.8106964489561506e-05, 1.8106964489561506e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8106964489561506e-05

Optimization complete. Final v2v error: 3.5526692867279053 mm

Highest mean error: 5.045761585235596 mm for frame 65

Lowest mean error: 2.9129433631896973 mm for frame 95

Saving results

Total time: 41.28711676597595
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01036419
Iteration 2/25 | Loss: 0.00239490
Iteration 3/25 | Loss: 0.00222250
Iteration 4/25 | Loss: 0.00147728
Iteration 5/25 | Loss: 0.00127438
Iteration 6/25 | Loss: 0.00119589
Iteration 7/25 | Loss: 0.00114982
Iteration 8/25 | Loss: 0.00111094
Iteration 9/25 | Loss: 0.00104964
Iteration 10/25 | Loss: 0.00103929
Iteration 11/25 | Loss: 0.00096156
Iteration 12/25 | Loss: 0.00099203
Iteration 13/25 | Loss: 0.00095092
Iteration 14/25 | Loss: 0.00092853
Iteration 15/25 | Loss: 0.00091241
Iteration 16/25 | Loss: 0.00090617
Iteration 17/25 | Loss: 0.00090731
Iteration 18/25 | Loss: 0.00090064
Iteration 19/25 | Loss: 0.00089967
Iteration 20/25 | Loss: 0.00090055
Iteration 21/25 | Loss: 0.00089078
Iteration 22/25 | Loss: 0.00088597
Iteration 23/25 | Loss: 0.00088110
Iteration 24/25 | Loss: 0.00088333
Iteration 25/25 | Loss: 0.00087337

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59203994
Iteration 2/25 | Loss: 0.00101809
Iteration 3/25 | Loss: 0.00101809
Iteration 4/25 | Loss: 0.00101809
Iteration 5/25 | Loss: 0.00101809
Iteration 6/25 | Loss: 0.00101809
Iteration 7/25 | Loss: 0.00101809
Iteration 8/25 | Loss: 0.00101809
Iteration 9/25 | Loss: 0.00101809
Iteration 10/25 | Loss: 0.00101808
Iteration 11/25 | Loss: 0.00101808
Iteration 12/25 | Loss: 0.00101808
Iteration 13/25 | Loss: 0.00101808
Iteration 14/25 | Loss: 0.00101808
Iteration 15/25 | Loss: 0.00101808
Iteration 16/25 | Loss: 0.00101808
Iteration 17/25 | Loss: 0.00101808
Iteration 18/25 | Loss: 0.00101808
Iteration 19/25 | Loss: 0.00101808
Iteration 20/25 | Loss: 0.00101808
Iteration 21/25 | Loss: 0.00101808
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.001018084934912622, 0.001018084934912622, 0.001018084934912622, 0.001018084934912622, 0.001018084934912622]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001018084934912622

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00101808
Iteration 2/1000 | Loss: 0.00063561
Iteration 3/1000 | Loss: 0.00049584
Iteration 4/1000 | Loss: 0.00059705
Iteration 5/1000 | Loss: 0.00093136
Iteration 6/1000 | Loss: 0.00088299
Iteration 7/1000 | Loss: 0.00057427
Iteration 8/1000 | Loss: 0.00070903
Iteration 9/1000 | Loss: 0.00044144
Iteration 10/1000 | Loss: 0.00053033
Iteration 11/1000 | Loss: 0.00056106
Iteration 12/1000 | Loss: 0.00069364
Iteration 13/1000 | Loss: 0.00085092
Iteration 14/1000 | Loss: 0.00049334
Iteration 15/1000 | Loss: 0.00061949
Iteration 16/1000 | Loss: 0.00048253
Iteration 17/1000 | Loss: 0.00068772
Iteration 18/1000 | Loss: 0.00060852
Iteration 19/1000 | Loss: 0.00066467
Iteration 20/1000 | Loss: 0.00045264
Iteration 21/1000 | Loss: 0.00024818
Iteration 22/1000 | Loss: 0.00018111
Iteration 23/1000 | Loss: 0.00012513
Iteration 24/1000 | Loss: 0.00026758
Iteration 25/1000 | Loss: 0.00026149
Iteration 26/1000 | Loss: 0.00024347
Iteration 27/1000 | Loss: 0.00027615
Iteration 28/1000 | Loss: 0.00019135
Iteration 29/1000 | Loss: 0.00007040
Iteration 30/1000 | Loss: 0.00038550
Iteration 31/1000 | Loss: 0.00061078
Iteration 32/1000 | Loss: 0.00062172
Iteration 33/1000 | Loss: 0.00103495
Iteration 34/1000 | Loss: 0.00054850
Iteration 35/1000 | Loss: 0.00072341
Iteration 36/1000 | Loss: 0.00084936
Iteration 37/1000 | Loss: 0.00048942
Iteration 38/1000 | Loss: 0.00068659
Iteration 39/1000 | Loss: 0.00080780
Iteration 40/1000 | Loss: 0.00003001
Iteration 41/1000 | Loss: 0.00002507
Iteration 42/1000 | Loss: 0.00002269
Iteration 43/1000 | Loss: 0.00002720
Iteration 44/1000 | Loss: 0.00058612
Iteration 45/1000 | Loss: 0.00061004
Iteration 46/1000 | Loss: 0.00008721
Iteration 47/1000 | Loss: 0.00003933
Iteration 48/1000 | Loss: 0.00002957
Iteration 49/1000 | Loss: 0.00002332
Iteration 50/1000 | Loss: 0.00004519
Iteration 51/1000 | Loss: 0.00013978
Iteration 52/1000 | Loss: 0.00008734
Iteration 53/1000 | Loss: 0.00002206
Iteration 54/1000 | Loss: 0.00002385
Iteration 55/1000 | Loss: 0.00006362
Iteration 56/1000 | Loss: 0.00013519
Iteration 57/1000 | Loss: 0.00006921
Iteration 58/1000 | Loss: 0.00002094
Iteration 59/1000 | Loss: 0.00002050
Iteration 60/1000 | Loss: 0.00002047
Iteration 61/1000 | Loss: 0.00002120
Iteration 62/1000 | Loss: 0.00003998
Iteration 63/1000 | Loss: 0.00001764
Iteration 64/1000 | Loss: 0.00001748
Iteration 65/1000 | Loss: 0.00002725
Iteration 66/1000 | Loss: 0.00001742
Iteration 67/1000 | Loss: 0.00001934
Iteration 68/1000 | Loss: 0.00001934
Iteration 69/1000 | Loss: 0.00002417
Iteration 70/1000 | Loss: 0.00001748
Iteration 71/1000 | Loss: 0.00001739
Iteration 72/1000 | Loss: 0.00001739
Iteration 73/1000 | Loss: 0.00001739
Iteration 74/1000 | Loss: 0.00001739
Iteration 75/1000 | Loss: 0.00001739
Iteration 76/1000 | Loss: 0.00001739
Iteration 77/1000 | Loss: 0.00001739
Iteration 78/1000 | Loss: 0.00001739
Iteration 79/1000 | Loss: 0.00001744
Iteration 80/1000 | Loss: 0.00001715
Iteration 81/1000 | Loss: 0.00001714
Iteration 82/1000 | Loss: 0.00001714
Iteration 83/1000 | Loss: 0.00001714
Iteration 84/1000 | Loss: 0.00001714
Iteration 85/1000 | Loss: 0.00001714
Iteration 86/1000 | Loss: 0.00001714
Iteration 87/1000 | Loss: 0.00001714
Iteration 88/1000 | Loss: 0.00001714
Iteration 89/1000 | Loss: 0.00001715
Iteration 90/1000 | Loss: 0.00001778
Iteration 91/1000 | Loss: 0.00001711
Iteration 92/1000 | Loss: 0.00001711
Iteration 93/1000 | Loss: 0.00001711
Iteration 94/1000 | Loss: 0.00001711
Iteration 95/1000 | Loss: 0.00001711
Iteration 96/1000 | Loss: 0.00001711
Iteration 97/1000 | Loss: 0.00001710
Iteration 98/1000 | Loss: 0.00001710
Iteration 99/1000 | Loss: 0.00001710
Iteration 100/1000 | Loss: 0.00001710
Iteration 101/1000 | Loss: 0.00001709
Iteration 102/1000 | Loss: 0.00001705
Iteration 103/1000 | Loss: 0.00001704
Iteration 104/1000 | Loss: 0.00001751
Iteration 105/1000 | Loss: 0.00001730
Iteration 106/1000 | Loss: 0.00001710
Iteration 107/1000 | Loss: 0.00001709
Iteration 108/1000 | Loss: 0.00001709
Iteration 109/1000 | Loss: 0.00001709
Iteration 110/1000 | Loss: 0.00001709
Iteration 111/1000 | Loss: 0.00001708
Iteration 112/1000 | Loss: 0.00001708
Iteration 113/1000 | Loss: 0.00001698
Iteration 114/1000 | Loss: 0.00002073
Iteration 115/1000 | Loss: 0.00001694
Iteration 116/1000 | Loss: 0.00001694
Iteration 117/1000 | Loss: 0.00001694
Iteration 118/1000 | Loss: 0.00001693
Iteration 119/1000 | Loss: 0.00001693
Iteration 120/1000 | Loss: 0.00001693
Iteration 121/1000 | Loss: 0.00001692
Iteration 122/1000 | Loss: 0.00001692
Iteration 123/1000 | Loss: 0.00001692
Iteration 124/1000 | Loss: 0.00001692
Iteration 125/1000 | Loss: 0.00001692
Iteration 126/1000 | Loss: 0.00001691
Iteration 127/1000 | Loss: 0.00001691
Iteration 128/1000 | Loss: 0.00001690
Iteration 129/1000 | Loss: 0.00001694
Iteration 130/1000 | Loss: 0.00001694
Iteration 131/1000 | Loss: 0.00001694
Iteration 132/1000 | Loss: 0.00001694
Iteration 133/1000 | Loss: 0.00001689
Iteration 134/1000 | Loss: 0.00001689
Iteration 135/1000 | Loss: 0.00001689
Iteration 136/1000 | Loss: 0.00001689
Iteration 137/1000 | Loss: 0.00001689
Iteration 138/1000 | Loss: 0.00001688
Iteration 139/1000 | Loss: 0.00001688
Iteration 140/1000 | Loss: 0.00001688
Iteration 141/1000 | Loss: 0.00001688
Iteration 142/1000 | Loss: 0.00001688
Iteration 143/1000 | Loss: 0.00001688
Iteration 144/1000 | Loss: 0.00001688
Iteration 145/1000 | Loss: 0.00001688
Iteration 146/1000 | Loss: 0.00001688
Iteration 147/1000 | Loss: 0.00001688
Iteration 148/1000 | Loss: 0.00001688
Iteration 149/1000 | Loss: 0.00001688
Iteration 150/1000 | Loss: 0.00001688
Iteration 151/1000 | Loss: 0.00001688
Iteration 152/1000 | Loss: 0.00001688
Iteration 153/1000 | Loss: 0.00001688
Iteration 154/1000 | Loss: 0.00001688
Iteration 155/1000 | Loss: 0.00001688
Iteration 156/1000 | Loss: 0.00001688
Iteration 157/1000 | Loss: 0.00001688
Iteration 158/1000 | Loss: 0.00001688
Iteration 159/1000 | Loss: 0.00001688
Iteration 160/1000 | Loss: 0.00001688
Iteration 161/1000 | Loss: 0.00001688
Iteration 162/1000 | Loss: 0.00001688
Iteration 163/1000 | Loss: 0.00001688
Iteration 164/1000 | Loss: 0.00001688
Iteration 165/1000 | Loss: 0.00001688
Iteration 166/1000 | Loss: 0.00001688
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 166. Stopping optimization.
Last 5 losses: [1.6879816030268557e-05, 1.6879816030268557e-05, 1.6879816030268557e-05, 1.6879816030268557e-05, 1.6879816030268557e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6879816030268557e-05

Optimization complete. Final v2v error: 3.448216438293457 mm

Highest mean error: 4.5214338302612305 mm for frame 68

Lowest mean error: 2.98600435256958 mm for frame 20

Saving results

Total time: 156.85340428352356
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1077
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00997692
Iteration 2/25 | Loss: 0.00308602
Iteration 3/25 | Loss: 0.00205609
Iteration 4/25 | Loss: 0.00187321
Iteration 5/25 | Loss: 0.00181418
Iteration 6/25 | Loss: 0.00179133
Iteration 7/25 | Loss: 0.00174073
Iteration 8/25 | Loss: 0.00171233
Iteration 9/25 | Loss: 0.00170058
Iteration 10/25 | Loss: 0.00169168
Iteration 11/25 | Loss: 0.00168251
Iteration 12/25 | Loss: 0.00167837
Iteration 13/25 | Loss: 0.00166785
Iteration 14/25 | Loss: 0.00166320
Iteration 15/25 | Loss: 0.00166040
Iteration 16/25 | Loss: 0.00166543
Iteration 17/25 | Loss: 0.00166166
Iteration 18/25 | Loss: 0.00165864
Iteration 19/25 | Loss: 0.00165817
Iteration 20/25 | Loss: 0.00165735
Iteration 21/25 | Loss: 0.00165711
Iteration 22/25 | Loss: 0.00165706
Iteration 23/25 | Loss: 0.00165706
Iteration 24/25 | Loss: 0.00165705
Iteration 25/25 | Loss: 0.00165705

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49830639
Iteration 2/25 | Loss: 0.00719263
Iteration 3/25 | Loss: 0.00719262
Iteration 4/25 | Loss: 0.00719262
Iteration 5/25 | Loss: 0.00719262
Iteration 6/25 | Loss: 0.00719261
Iteration 7/25 | Loss: 0.00719261
Iteration 8/25 | Loss: 0.00719261
Iteration 9/25 | Loss: 0.00719261
Iteration 10/25 | Loss: 0.00719261
Iteration 11/25 | Loss: 0.00719261
Iteration 12/25 | Loss: 0.00719261
Iteration 13/25 | Loss: 0.00719261
Iteration 14/25 | Loss: 0.00719261
Iteration 15/25 | Loss: 0.00719261
Iteration 16/25 | Loss: 0.00719261
Iteration 17/25 | Loss: 0.00719261
Iteration 18/25 | Loss: 0.00719261
Iteration 19/25 | Loss: 0.00719261
Iteration 20/25 | Loss: 0.00719261
Iteration 21/25 | Loss: 0.00719261
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.007192612625658512, 0.007192612625658512, 0.007192612625658512, 0.007192612625658512, 0.007192612625658512]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.007192612625658512

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00719261
Iteration 2/1000 | Loss: 0.00102638
Iteration 3/1000 | Loss: 0.00080385
Iteration 4/1000 | Loss: 0.00064473
Iteration 5/1000 | Loss: 0.00055508
Iteration 6/1000 | Loss: 0.00048760
Iteration 7/1000 | Loss: 0.00042319
Iteration 8/1000 | Loss: 0.00039173
Iteration 9/1000 | Loss: 0.00159093
Iteration 10/1000 | Loss: 0.04601633
Iteration 11/1000 | Loss: 0.00241052
Iteration 12/1000 | Loss: 0.00113485
Iteration 13/1000 | Loss: 0.00040554
Iteration 14/1000 | Loss: 0.00027564
Iteration 15/1000 | Loss: 0.00017637
Iteration 16/1000 | Loss: 0.00011325
Iteration 17/1000 | Loss: 0.00007245
Iteration 18/1000 | Loss: 0.00005010
Iteration 19/1000 | Loss: 0.00003951
Iteration 20/1000 | Loss: 0.00003318
Iteration 21/1000 | Loss: 0.00002779
Iteration 22/1000 | Loss: 0.00002389
Iteration 23/1000 | Loss: 0.00002185
Iteration 24/1000 | Loss: 0.00002070
Iteration 25/1000 | Loss: 0.00001981
Iteration 26/1000 | Loss: 0.00001917
Iteration 27/1000 | Loss: 0.00001838
Iteration 28/1000 | Loss: 0.00001778
Iteration 29/1000 | Loss: 0.00001736
Iteration 30/1000 | Loss: 0.00001715
Iteration 31/1000 | Loss: 0.00001698
Iteration 32/1000 | Loss: 0.00001693
Iteration 33/1000 | Loss: 0.00001689
Iteration 34/1000 | Loss: 0.00001688
Iteration 35/1000 | Loss: 0.00001687
Iteration 36/1000 | Loss: 0.00001687
Iteration 37/1000 | Loss: 0.00001684
Iteration 38/1000 | Loss: 0.00001683
Iteration 39/1000 | Loss: 0.00001682
Iteration 40/1000 | Loss: 0.00001682
Iteration 41/1000 | Loss: 0.00001681
Iteration 42/1000 | Loss: 0.00001681
Iteration 43/1000 | Loss: 0.00001681
Iteration 44/1000 | Loss: 0.00001680
Iteration 45/1000 | Loss: 0.00001679
Iteration 46/1000 | Loss: 0.00001679
Iteration 47/1000 | Loss: 0.00001678
Iteration 48/1000 | Loss: 0.00001678
Iteration 49/1000 | Loss: 0.00001678
Iteration 50/1000 | Loss: 0.00001678
Iteration 51/1000 | Loss: 0.00001678
Iteration 52/1000 | Loss: 0.00001678
Iteration 53/1000 | Loss: 0.00001677
Iteration 54/1000 | Loss: 0.00001677
Iteration 55/1000 | Loss: 0.00001677
Iteration 56/1000 | Loss: 0.00001676
Iteration 57/1000 | Loss: 0.00001676
Iteration 58/1000 | Loss: 0.00001675
Iteration 59/1000 | Loss: 0.00001675
Iteration 60/1000 | Loss: 0.00001675
Iteration 61/1000 | Loss: 0.00001675
Iteration 62/1000 | Loss: 0.00001674
Iteration 63/1000 | Loss: 0.00001674
Iteration 64/1000 | Loss: 0.00001674
Iteration 65/1000 | Loss: 0.00001674
Iteration 66/1000 | Loss: 0.00001673
Iteration 67/1000 | Loss: 0.00001673
Iteration 68/1000 | Loss: 0.00001673
Iteration 69/1000 | Loss: 0.00001673
Iteration 70/1000 | Loss: 0.00001673
Iteration 71/1000 | Loss: 0.00001673
Iteration 72/1000 | Loss: 0.00001673
Iteration 73/1000 | Loss: 0.00001673
Iteration 74/1000 | Loss: 0.00001673
Iteration 75/1000 | Loss: 0.00001672
Iteration 76/1000 | Loss: 0.00001672
Iteration 77/1000 | Loss: 0.00001672
Iteration 78/1000 | Loss: 0.00001672
Iteration 79/1000 | Loss: 0.00001672
Iteration 80/1000 | Loss: 0.00001672
Iteration 81/1000 | Loss: 0.00001672
Iteration 82/1000 | Loss: 0.00001672
Iteration 83/1000 | Loss: 0.00001672
Iteration 84/1000 | Loss: 0.00001672
Iteration 85/1000 | Loss: 0.00001672
Iteration 86/1000 | Loss: 0.00001672
Iteration 87/1000 | Loss: 0.00001672
Iteration 88/1000 | Loss: 0.00001672
Iteration 89/1000 | Loss: 0.00001672
Iteration 90/1000 | Loss: 0.00001672
Iteration 91/1000 | Loss: 0.00001672
Iteration 92/1000 | Loss: 0.00001672
Iteration 93/1000 | Loss: 0.00001672
Iteration 94/1000 | Loss: 0.00001672
Iteration 95/1000 | Loss: 0.00001672
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 95. Stopping optimization.
Last 5 losses: [1.6722018699510954e-05, 1.6722018699510954e-05, 1.6722018699510954e-05, 1.6722018699510954e-05, 1.6722018699510954e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6722018699510954e-05

Optimization complete. Final v2v error: 3.5057833194732666 mm

Highest mean error: 3.6636290550231934 mm for frame 58

Lowest mean error: 3.424259901046753 mm for frame 117

Saving results

Total time: 86.20484209060669
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1073/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1073.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1073
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00832893
Iteration 2/25 | Loss: 0.00152845
Iteration 3/25 | Loss: 0.00114824
Iteration 4/25 | Loss: 0.00106798
Iteration 5/25 | Loss: 0.00105818
Iteration 6/25 | Loss: 0.00105116
Iteration 7/25 | Loss: 0.00104777
Iteration 8/25 | Loss: 0.00104625
Iteration 9/25 | Loss: 0.00104529
Iteration 10/25 | Loss: 0.00104447
Iteration 11/25 | Loss: 0.00104392
Iteration 12/25 | Loss: 0.00104328
Iteration 13/25 | Loss: 0.00104248
Iteration 14/25 | Loss: 0.00104176
Iteration 15/25 | Loss: 0.00104092
Iteration 16/25 | Loss: 0.00104021
Iteration 17/25 | Loss: 0.00103960
Iteration 18/25 | Loss: 0.00103909
Iteration 19/25 | Loss: 0.00103706
Iteration 20/25 | Loss: 0.00103638
Iteration 21/25 | Loss: 0.00103608
Iteration 22/25 | Loss: 0.00103590
Iteration 23/25 | Loss: 0.00103580
Iteration 24/25 | Loss: 0.00103578
Iteration 25/25 | Loss: 0.00103578

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.65537548
Iteration 2/25 | Loss: 0.00260244
Iteration 3/25 | Loss: 0.00260239
Iteration 4/25 | Loss: 0.00260239
Iteration 5/25 | Loss: 0.00260239
Iteration 6/25 | Loss: 0.00260239
Iteration 7/25 | Loss: 0.00260239
Iteration 8/25 | Loss: 0.00260239
Iteration 9/25 | Loss: 0.00260239
Iteration 10/25 | Loss: 0.00260239
Iteration 11/25 | Loss: 0.00260239
Iteration 12/25 | Loss: 0.00260239
Iteration 13/25 | Loss: 0.00260239
Iteration 14/25 | Loss: 0.00260239
Iteration 15/25 | Loss: 0.00260239
Iteration 16/25 | Loss: 0.00260239
Iteration 17/25 | Loss: 0.00260239
Iteration 18/25 | Loss: 0.00260239
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0026023872196674347, 0.0026023872196674347, 0.0026023872196674347, 0.0026023872196674347, 0.0026023872196674347]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0026023872196674347

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00260239
Iteration 2/1000 | Loss: 0.00977640
Iteration 3/1000 | Loss: 0.00105708
Iteration 4/1000 | Loss: 0.00032641
Iteration 5/1000 | Loss: 0.00046906
Iteration 6/1000 | Loss: 0.00026794
Iteration 7/1000 | Loss: 0.00038758
Iteration 8/1000 | Loss: 0.00007082
Iteration 9/1000 | Loss: 0.00031433
Iteration 10/1000 | Loss: 0.00144063
Iteration 11/1000 | Loss: 0.00004249
Iteration 12/1000 | Loss: 0.00017523
Iteration 13/1000 | Loss: 0.00003162
Iteration 14/1000 | Loss: 0.00002907
Iteration 15/1000 | Loss: 0.00002703
Iteration 16/1000 | Loss: 0.00002571
Iteration 17/1000 | Loss: 0.00053538
Iteration 18/1000 | Loss: 0.00038547
Iteration 19/1000 | Loss: 0.00061652
Iteration 20/1000 | Loss: 0.00047446
Iteration 21/1000 | Loss: 0.00021354
Iteration 22/1000 | Loss: 0.00105277
Iteration 23/1000 | Loss: 0.00041899
Iteration 24/1000 | Loss: 0.00003427
Iteration 25/1000 | Loss: 0.00002795
Iteration 26/1000 | Loss: 0.00002528
Iteration 27/1000 | Loss: 0.00002441
Iteration 28/1000 | Loss: 0.00053873
Iteration 29/1000 | Loss: 0.00028666
Iteration 30/1000 | Loss: 0.00038750
Iteration 31/1000 | Loss: 0.00112531
Iteration 32/1000 | Loss: 0.00043966
Iteration 33/1000 | Loss: 0.00028192
Iteration 34/1000 | Loss: 0.00038419
Iteration 35/1000 | Loss: 0.00004369
Iteration 36/1000 | Loss: 0.00002639
Iteration 37/1000 | Loss: 0.00002404
Iteration 38/1000 | Loss: 0.00002288
Iteration 39/1000 | Loss: 0.00002201
Iteration 40/1000 | Loss: 0.00108435
Iteration 41/1000 | Loss: 0.00003790
Iteration 42/1000 | Loss: 0.00002646
Iteration 43/1000 | Loss: 0.00002377
Iteration 44/1000 | Loss: 0.00002107
Iteration 45/1000 | Loss: 0.00001864
Iteration 46/1000 | Loss: 0.00001760
Iteration 47/1000 | Loss: 0.00001715
Iteration 48/1000 | Loss: 0.00001697
Iteration 49/1000 | Loss: 0.00001693
Iteration 50/1000 | Loss: 0.00001692
Iteration 51/1000 | Loss: 0.00001691
Iteration 52/1000 | Loss: 0.00001682
Iteration 53/1000 | Loss: 0.00001675
Iteration 54/1000 | Loss: 0.00001674
Iteration 55/1000 | Loss: 0.00001673
Iteration 56/1000 | Loss: 0.00001673
Iteration 57/1000 | Loss: 0.00001672
Iteration 58/1000 | Loss: 0.00001672
Iteration 59/1000 | Loss: 0.00001671
Iteration 60/1000 | Loss: 0.00001665
Iteration 61/1000 | Loss: 0.00001665
Iteration 62/1000 | Loss: 0.00001665
Iteration 63/1000 | Loss: 0.00001665
Iteration 64/1000 | Loss: 0.00001665
Iteration 65/1000 | Loss: 0.00001665
Iteration 66/1000 | Loss: 0.00001664
Iteration 67/1000 | Loss: 0.00001663
Iteration 68/1000 | Loss: 0.00001663
Iteration 69/1000 | Loss: 0.00001661
Iteration 70/1000 | Loss: 0.00001660
Iteration 71/1000 | Loss: 0.00001659
Iteration 72/1000 | Loss: 0.00001658
Iteration 73/1000 | Loss: 0.00001657
Iteration 74/1000 | Loss: 0.00001655
Iteration 75/1000 | Loss: 0.00001655
Iteration 76/1000 | Loss: 0.00001654
Iteration 77/1000 | Loss: 0.00001653
Iteration 78/1000 | Loss: 0.00001652
Iteration 79/1000 | Loss: 0.00001649
Iteration 80/1000 | Loss: 0.00001649
Iteration 81/1000 | Loss: 0.00001649
Iteration 82/1000 | Loss: 0.00001649
Iteration 83/1000 | Loss: 0.00001649
Iteration 84/1000 | Loss: 0.00001649
Iteration 85/1000 | Loss: 0.00001649
Iteration 86/1000 | Loss: 0.00001649
Iteration 87/1000 | Loss: 0.00001649
Iteration 88/1000 | Loss: 0.00001649
Iteration 89/1000 | Loss: 0.00001648
Iteration 90/1000 | Loss: 0.00001647
Iteration 91/1000 | Loss: 0.00001646
Iteration 92/1000 | Loss: 0.00001645
Iteration 93/1000 | Loss: 0.00001645
Iteration 94/1000 | Loss: 0.00001645
Iteration 95/1000 | Loss: 0.00001645
Iteration 96/1000 | Loss: 0.00001645
Iteration 97/1000 | Loss: 0.00001644
Iteration 98/1000 | Loss: 0.00001644
Iteration 99/1000 | Loss: 0.00001644
Iteration 100/1000 | Loss: 0.00001643
Iteration 101/1000 | Loss: 0.00001643
Iteration 102/1000 | Loss: 0.00001643
Iteration 103/1000 | Loss: 0.00001642
Iteration 104/1000 | Loss: 0.00001642
Iteration 105/1000 | Loss: 0.00001642
Iteration 106/1000 | Loss: 0.00001642
Iteration 107/1000 | Loss: 0.00001642
Iteration 108/1000 | Loss: 0.00001641
Iteration 109/1000 | Loss: 0.00001641
Iteration 110/1000 | Loss: 0.00001641
Iteration 111/1000 | Loss: 0.00001641
Iteration 112/1000 | Loss: 0.00001641
Iteration 113/1000 | Loss: 0.00001641
Iteration 114/1000 | Loss: 0.00001641
Iteration 115/1000 | Loss: 0.00001641
Iteration 116/1000 | Loss: 0.00001641
Iteration 117/1000 | Loss: 0.00001641
Iteration 118/1000 | Loss: 0.00001641
Iteration 119/1000 | Loss: 0.00001640
Iteration 120/1000 | Loss: 0.00001640
Iteration 121/1000 | Loss: 0.00001640
Iteration 122/1000 | Loss: 0.00001640
Iteration 123/1000 | Loss: 0.00001640
Iteration 124/1000 | Loss: 0.00001640
Iteration 125/1000 | Loss: 0.00001640
Iteration 126/1000 | Loss: 0.00001640
Iteration 127/1000 | Loss: 0.00001640
Iteration 128/1000 | Loss: 0.00001640
Iteration 129/1000 | Loss: 0.00001640
Iteration 130/1000 | Loss: 0.00001640
Iteration 131/1000 | Loss: 0.00001640
Iteration 132/1000 | Loss: 0.00001640
Iteration 133/1000 | Loss: 0.00001639
Iteration 134/1000 | Loss: 0.00001639
Iteration 135/1000 | Loss: 0.00001639
Iteration 136/1000 | Loss: 0.00001639
Iteration 137/1000 | Loss: 0.00001639
Iteration 138/1000 | Loss: 0.00001639
Iteration 139/1000 | Loss: 0.00001639
Iteration 140/1000 | Loss: 0.00001639
Iteration 141/1000 | Loss: 0.00001639
Iteration 142/1000 | Loss: 0.00001639
Iteration 143/1000 | Loss: 0.00001638
Iteration 144/1000 | Loss: 0.00001638
Iteration 145/1000 | Loss: 0.00001638
Iteration 146/1000 | Loss: 0.00001638
Iteration 147/1000 | Loss: 0.00001638
Iteration 148/1000 | Loss: 0.00001638
Iteration 149/1000 | Loss: 0.00001637
Iteration 150/1000 | Loss: 0.00001637
Iteration 151/1000 | Loss: 0.00001637
Iteration 152/1000 | Loss: 0.00001637
Iteration 153/1000 | Loss: 0.00001637
Iteration 154/1000 | Loss: 0.00001637
Iteration 155/1000 | Loss: 0.00001637
Iteration 156/1000 | Loss: 0.00001637
Iteration 157/1000 | Loss: 0.00001637
Iteration 158/1000 | Loss: 0.00001637
Iteration 159/1000 | Loss: 0.00001637
Iteration 160/1000 | Loss: 0.00001637
Iteration 161/1000 | Loss: 0.00001637
Iteration 162/1000 | Loss: 0.00001636
Iteration 163/1000 | Loss: 0.00001636
Iteration 164/1000 | Loss: 0.00001636
Iteration 165/1000 | Loss: 0.00001636
Iteration 166/1000 | Loss: 0.00001636
Iteration 167/1000 | Loss: 0.00001636
Iteration 168/1000 | Loss: 0.00001636
Iteration 169/1000 | Loss: 0.00001636
Iteration 170/1000 | Loss: 0.00001636
Iteration 171/1000 | Loss: 0.00001636
Iteration 172/1000 | Loss: 0.00001636
Iteration 173/1000 | Loss: 0.00001636
Iteration 174/1000 | Loss: 0.00001636
Iteration 175/1000 | Loss: 0.00001636
Iteration 176/1000 | Loss: 0.00001635
Iteration 177/1000 | Loss: 0.00001635
Iteration 178/1000 | Loss: 0.00001634
Iteration 179/1000 | Loss: 0.00001634
Iteration 180/1000 | Loss: 0.00001634
Iteration 181/1000 | Loss: 0.00001634
Iteration 182/1000 | Loss: 0.00001634
Iteration 183/1000 | Loss: 0.00001634
Iteration 184/1000 | Loss: 0.00001634
Iteration 185/1000 | Loss: 0.00001634
Iteration 186/1000 | Loss: 0.00001634
Iteration 187/1000 | Loss: 0.00001634
Iteration 188/1000 | Loss: 0.00001634
Iteration 189/1000 | Loss: 0.00001634
Iteration 190/1000 | Loss: 0.00001634
Iteration 191/1000 | Loss: 0.00001634
Iteration 192/1000 | Loss: 0.00001634
Iteration 193/1000 | Loss: 0.00001634
Iteration 194/1000 | Loss: 0.00001634
Iteration 195/1000 | Loss: 0.00001634
Iteration 196/1000 | Loss: 0.00001634
Iteration 197/1000 | Loss: 0.00001634
Iteration 198/1000 | Loss: 0.00001634
Iteration 199/1000 | Loss: 0.00001634
Iteration 200/1000 | Loss: 0.00001634
Iteration 201/1000 | Loss: 0.00001634
Iteration 202/1000 | Loss: 0.00001634
Iteration 203/1000 | Loss: 0.00001633
Iteration 204/1000 | Loss: 0.00001633
Iteration 205/1000 | Loss: 0.00001633
Iteration 206/1000 | Loss: 0.00001633
Iteration 207/1000 | Loss: 0.00001633
Iteration 208/1000 | Loss: 0.00001633
Iteration 209/1000 | Loss: 0.00001633
Iteration 210/1000 | Loss: 0.00001633
Iteration 211/1000 | Loss: 0.00001633
Iteration 212/1000 | Loss: 0.00001633
Iteration 213/1000 | Loss: 0.00001633
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 213. Stopping optimization.
Last 5 losses: [1.633451938687358e-05, 1.633451938687358e-05, 1.633451938687358e-05, 1.633451938687358e-05, 1.633451938687358e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.633451938687358e-05

Optimization complete. Final v2v error: 3.4286062717437744 mm

Highest mean error: 3.9556379318237305 mm for frame 60

Lowest mean error: 3.145949125289917 mm for frame 46

Saving results

Total time: 139.84972476959229
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1094
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00822536
Iteration 2/25 | Loss: 0.00096951
Iteration 3/25 | Loss: 0.00082112
Iteration 4/25 | Loss: 0.00080520
Iteration 5/25 | Loss: 0.00080079
Iteration 6/25 | Loss: 0.00079934
Iteration 7/25 | Loss: 0.00079919
Iteration 8/25 | Loss: 0.00079919
Iteration 9/25 | Loss: 0.00079919
Iteration 10/25 | Loss: 0.00079919
Iteration 11/25 | Loss: 0.00079919
Iteration 12/25 | Loss: 0.00079919
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007991946185939014, 0.0007991946185939014, 0.0007991946185939014, 0.0007991946185939014, 0.0007991946185939014]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007991946185939014

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52532566
Iteration 2/25 | Loss: 0.00057658
Iteration 3/25 | Loss: 0.00057657
Iteration 4/25 | Loss: 0.00057657
Iteration 5/25 | Loss: 0.00057657
Iteration 6/25 | Loss: 0.00057657
Iteration 7/25 | Loss: 0.00057657
Iteration 8/25 | Loss: 0.00057657
Iteration 9/25 | Loss: 0.00057657
Iteration 10/25 | Loss: 0.00057657
Iteration 11/25 | Loss: 0.00057657
Iteration 12/25 | Loss: 0.00057657
Iteration 13/25 | Loss: 0.00057657
Iteration 14/25 | Loss: 0.00057657
Iteration 15/25 | Loss: 0.00057657
Iteration 16/25 | Loss: 0.00057657
Iteration 17/25 | Loss: 0.00057657
Iteration 18/25 | Loss: 0.00057657
Iteration 19/25 | Loss: 0.00057657
Iteration 20/25 | Loss: 0.00057657
Iteration 21/25 | Loss: 0.00057657
Iteration 22/25 | Loss: 0.00057657
Iteration 23/25 | Loss: 0.00057657
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0005765696405433118, 0.0005765696405433118, 0.0005765696405433118, 0.0005765696405433118, 0.0005765696405433118]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005765696405433118

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00057657
Iteration 2/1000 | Loss: 0.00002052
Iteration 3/1000 | Loss: 0.00001367
Iteration 4/1000 | Loss: 0.00001245
Iteration 5/1000 | Loss: 0.00001152
Iteration 6/1000 | Loss: 0.00001105
Iteration 7/1000 | Loss: 0.00001075
Iteration 8/1000 | Loss: 0.00001062
Iteration 9/1000 | Loss: 0.00001059
Iteration 10/1000 | Loss: 0.00001058
Iteration 11/1000 | Loss: 0.00001052
Iteration 12/1000 | Loss: 0.00001052
Iteration 13/1000 | Loss: 0.00001051
Iteration 14/1000 | Loss: 0.00001049
Iteration 15/1000 | Loss: 0.00001048
Iteration 16/1000 | Loss: 0.00001048
Iteration 17/1000 | Loss: 0.00001047
Iteration 18/1000 | Loss: 0.00001047
Iteration 19/1000 | Loss: 0.00001045
Iteration 20/1000 | Loss: 0.00001045
Iteration 21/1000 | Loss: 0.00001045
Iteration 22/1000 | Loss: 0.00001044
Iteration 23/1000 | Loss: 0.00001044
Iteration 24/1000 | Loss: 0.00001043
Iteration 25/1000 | Loss: 0.00001043
Iteration 26/1000 | Loss: 0.00001043
Iteration 27/1000 | Loss: 0.00001042
Iteration 28/1000 | Loss: 0.00001041
Iteration 29/1000 | Loss: 0.00001040
Iteration 30/1000 | Loss: 0.00001039
Iteration 31/1000 | Loss: 0.00001038
Iteration 32/1000 | Loss: 0.00001038
Iteration 33/1000 | Loss: 0.00001038
Iteration 34/1000 | Loss: 0.00001037
Iteration 35/1000 | Loss: 0.00001036
Iteration 36/1000 | Loss: 0.00001034
Iteration 37/1000 | Loss: 0.00001033
Iteration 38/1000 | Loss: 0.00001033
Iteration 39/1000 | Loss: 0.00001032
Iteration 40/1000 | Loss: 0.00001032
Iteration 41/1000 | Loss: 0.00001029
Iteration 42/1000 | Loss: 0.00001029
Iteration 43/1000 | Loss: 0.00001029
Iteration 44/1000 | Loss: 0.00001028
Iteration 45/1000 | Loss: 0.00001028
Iteration 46/1000 | Loss: 0.00001028
Iteration 47/1000 | Loss: 0.00001028
Iteration 48/1000 | Loss: 0.00001028
Iteration 49/1000 | Loss: 0.00001028
Iteration 50/1000 | Loss: 0.00001028
Iteration 51/1000 | Loss: 0.00001028
Iteration 52/1000 | Loss: 0.00001028
Iteration 53/1000 | Loss: 0.00001028
Iteration 54/1000 | Loss: 0.00001028
Iteration 55/1000 | Loss: 0.00001028
Iteration 56/1000 | Loss: 0.00001028
Iteration 57/1000 | Loss: 0.00001028
Iteration 58/1000 | Loss: 0.00001028
Iteration 59/1000 | Loss: 0.00001028
Iteration 60/1000 | Loss: 0.00001028
Iteration 61/1000 | Loss: 0.00001028
Iteration 62/1000 | Loss: 0.00001028
Iteration 63/1000 | Loss: 0.00001028
Iteration 64/1000 | Loss: 0.00001028
Iteration 65/1000 | Loss: 0.00001028
Iteration 66/1000 | Loss: 0.00001028
Iteration 67/1000 | Loss: 0.00001028
Iteration 68/1000 | Loss: 0.00001028
Iteration 69/1000 | Loss: 0.00001028
Iteration 70/1000 | Loss: 0.00001028
Iteration 71/1000 | Loss: 0.00001028
Iteration 72/1000 | Loss: 0.00001028
Iteration 73/1000 | Loss: 0.00001028
Iteration 74/1000 | Loss: 0.00001028
Iteration 75/1000 | Loss: 0.00001028
Iteration 76/1000 | Loss: 0.00001028
Iteration 77/1000 | Loss: 0.00001028
Iteration 78/1000 | Loss: 0.00001028
Iteration 79/1000 | Loss: 0.00001028
Iteration 80/1000 | Loss: 0.00001028
Iteration 81/1000 | Loss: 0.00001028
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 81. Stopping optimization.
Last 5 losses: [1.0279649359290488e-05, 1.0279649359290488e-05, 1.0279649359290488e-05, 1.0279649359290488e-05, 1.0279649359290488e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0279649359290488e-05

Optimization complete. Final v2v error: 2.7299423217773438 mm

Highest mean error: 2.859684467315674 mm for frame 41

Lowest mean error: 2.632070541381836 mm for frame 15

Saving results

Total time: 27.571622133255005
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1084/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1084.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1084
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00824510
Iteration 2/25 | Loss: 0.00136352
Iteration 3/25 | Loss: 0.00100644
Iteration 4/25 | Loss: 0.00092623
Iteration 5/25 | Loss: 0.00089949
Iteration 6/25 | Loss: 0.00087798
Iteration 7/25 | Loss: 0.00087384
Iteration 8/25 | Loss: 0.00087231
Iteration 9/25 | Loss: 0.00086510
Iteration 10/25 | Loss: 0.00085620
Iteration 11/25 | Loss: 0.00085265
Iteration 12/25 | Loss: 0.00085416
Iteration 13/25 | Loss: 0.00085360
Iteration 14/25 | Loss: 0.00085099
Iteration 15/25 | Loss: 0.00085068
Iteration 16/25 | Loss: 0.00085055
Iteration 17/25 | Loss: 0.00085049
Iteration 18/25 | Loss: 0.00085048
Iteration 19/25 | Loss: 0.00085048
Iteration 20/25 | Loss: 0.00085047
Iteration 21/25 | Loss: 0.00085046
Iteration 22/25 | Loss: 0.00085046
Iteration 23/25 | Loss: 0.00085046
Iteration 24/25 | Loss: 0.00085046
Iteration 25/25 | Loss: 0.00085046

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.96033370
Iteration 2/25 | Loss: 0.00080775
Iteration 3/25 | Loss: 0.00079444
Iteration 4/25 | Loss: 0.00079444
Iteration 5/25 | Loss: 0.00079444
Iteration 6/25 | Loss: 0.00079444
Iteration 7/25 | Loss: 0.00079443
Iteration 8/25 | Loss: 0.00079443
Iteration 9/25 | Loss: 0.00079443
Iteration 10/25 | Loss: 0.00079443
Iteration 11/25 | Loss: 0.00079443
Iteration 12/25 | Loss: 0.00079443
Iteration 13/25 | Loss: 0.00079443
Iteration 14/25 | Loss: 0.00079443
Iteration 15/25 | Loss: 0.00079443
Iteration 16/25 | Loss: 0.00079443
Iteration 17/25 | Loss: 0.00079443
Iteration 18/25 | Loss: 0.00079443
Iteration 19/25 | Loss: 0.00079443
Iteration 20/25 | Loss: 0.00079443
Iteration 21/25 | Loss: 0.00079443
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007944334065541625, 0.0007944334065541625, 0.0007944334065541625, 0.0007944334065541625, 0.0007944334065541625]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007944334065541625

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079443
Iteration 2/1000 | Loss: 0.00006994
Iteration 3/1000 | Loss: 0.00011513
Iteration 4/1000 | Loss: 0.00004722
Iteration 5/1000 | Loss: 0.00003780
Iteration 6/1000 | Loss: 0.00004093
Iteration 7/1000 | Loss: 0.00002813
Iteration 8/1000 | Loss: 0.00002658
Iteration 9/1000 | Loss: 0.00002581
Iteration 10/1000 | Loss: 0.00002530
Iteration 11/1000 | Loss: 0.00002488
Iteration 12/1000 | Loss: 0.00002460
Iteration 13/1000 | Loss: 0.00002435
Iteration 14/1000 | Loss: 0.00002416
Iteration 15/1000 | Loss: 0.00002402
Iteration 16/1000 | Loss: 0.00085865
Iteration 17/1000 | Loss: 0.00039712
Iteration 18/1000 | Loss: 0.00003407
Iteration 19/1000 | Loss: 0.00076992
Iteration 20/1000 | Loss: 0.00014492
Iteration 21/1000 | Loss: 0.00004294
Iteration 22/1000 | Loss: 0.00002563
Iteration 23/1000 | Loss: 0.00002390
Iteration 24/1000 | Loss: 0.00002245
Iteration 25/1000 | Loss: 0.00002169
Iteration 26/1000 | Loss: 0.00002130
Iteration 27/1000 | Loss: 0.00002094
Iteration 28/1000 | Loss: 0.00002063
Iteration 29/1000 | Loss: 0.00002036
Iteration 30/1000 | Loss: 0.00002000
Iteration 31/1000 | Loss: 0.00001972
Iteration 32/1000 | Loss: 0.00001949
Iteration 33/1000 | Loss: 0.00001943
Iteration 34/1000 | Loss: 0.00001937
Iteration 35/1000 | Loss: 0.00001930
Iteration 36/1000 | Loss: 0.00001926
Iteration 37/1000 | Loss: 0.00001920
Iteration 38/1000 | Loss: 0.00001919
Iteration 39/1000 | Loss: 0.00001918
Iteration 40/1000 | Loss: 0.00001914
Iteration 41/1000 | Loss: 0.00001913
Iteration 42/1000 | Loss: 0.00001913
Iteration 43/1000 | Loss: 0.00001912
Iteration 44/1000 | Loss: 0.00001912
Iteration 45/1000 | Loss: 0.00001912
Iteration 46/1000 | Loss: 0.00001911
Iteration 47/1000 | Loss: 0.00001909
Iteration 48/1000 | Loss: 0.00001906
Iteration 49/1000 | Loss: 0.00001906
Iteration 50/1000 | Loss: 0.00001906
Iteration 51/1000 | Loss: 0.00001906
Iteration 52/1000 | Loss: 0.00001906
Iteration 53/1000 | Loss: 0.00001906
Iteration 54/1000 | Loss: 0.00001906
Iteration 55/1000 | Loss: 0.00001906
Iteration 56/1000 | Loss: 0.00001906
Iteration 57/1000 | Loss: 0.00001906
Iteration 58/1000 | Loss: 0.00001906
Iteration 59/1000 | Loss: 0.00001906
Iteration 60/1000 | Loss: 0.00001906
Iteration 61/1000 | Loss: 0.00001905
Iteration 62/1000 | Loss: 0.00001905
Iteration 63/1000 | Loss: 0.00001905
Iteration 64/1000 | Loss: 0.00001905
Iteration 65/1000 | Loss: 0.00001904
Iteration 66/1000 | Loss: 0.00001904
Iteration 67/1000 | Loss: 0.00001903
Iteration 68/1000 | Loss: 0.00001903
Iteration 69/1000 | Loss: 0.00001903
Iteration 70/1000 | Loss: 0.00001902
Iteration 71/1000 | Loss: 0.00001902
Iteration 72/1000 | Loss: 0.00001902
Iteration 73/1000 | Loss: 0.00001902
Iteration 74/1000 | Loss: 0.00001902
Iteration 75/1000 | Loss: 0.00001901
Iteration 76/1000 | Loss: 0.00001901
Iteration 77/1000 | Loss: 0.00001901
Iteration 78/1000 | Loss: 0.00001901
Iteration 79/1000 | Loss: 0.00001901
Iteration 80/1000 | Loss: 0.00001901
Iteration 81/1000 | Loss: 0.00001900
Iteration 82/1000 | Loss: 0.00001900
Iteration 83/1000 | Loss: 0.00001900
Iteration 84/1000 | Loss: 0.00001900
Iteration 85/1000 | Loss: 0.00001900
Iteration 86/1000 | Loss: 0.00001900
Iteration 87/1000 | Loss: 0.00001900
Iteration 88/1000 | Loss: 0.00001900
Iteration 89/1000 | Loss: 0.00001900
Iteration 90/1000 | Loss: 0.00001900
Iteration 91/1000 | Loss: 0.00001900
Iteration 92/1000 | Loss: 0.00001900
Iteration 93/1000 | Loss: 0.00001900
Iteration 94/1000 | Loss: 0.00001900
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.8995990103576332e-05, 1.8995990103576332e-05, 1.8995990103576332e-05, 1.8995990103576332e-05, 1.8995990103576332e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8995990103576332e-05

Optimization complete. Final v2v error: 3.4143707752227783 mm

Highest mean error: 12.172996520996094 mm for frame 48

Lowest mean error: 3.0876331329345703 mm for frame 35

Saving results

Total time: 82.93310332298279
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00488456
Iteration 2/25 | Loss: 0.00098289
Iteration 3/25 | Loss: 0.00084790
Iteration 4/25 | Loss: 0.00083062
Iteration 5/25 | Loss: 0.00082525
Iteration 6/25 | Loss: 0.00082453
Iteration 7/25 | Loss: 0.00082453
Iteration 8/25 | Loss: 0.00082453
Iteration 9/25 | Loss: 0.00082453
Iteration 10/25 | Loss: 0.00082453
Iteration 11/25 | Loss: 0.00082453
Iteration 12/25 | Loss: 0.00082453
Iteration 13/25 | Loss: 0.00082453
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008245276403613389, 0.0008245276403613389, 0.0008245276403613389, 0.0008245276403613389, 0.0008245276403613389]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008245276403613389

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.81175470
Iteration 2/25 | Loss: 0.00055447
Iteration 3/25 | Loss: 0.00055446
Iteration 4/25 | Loss: 0.00055446
Iteration 5/25 | Loss: 0.00055446
Iteration 6/25 | Loss: 0.00055446
Iteration 7/25 | Loss: 0.00055446
Iteration 8/25 | Loss: 0.00055446
Iteration 9/25 | Loss: 0.00055446
Iteration 10/25 | Loss: 0.00055446
Iteration 11/25 | Loss: 0.00055446
Iteration 12/25 | Loss: 0.00055446
Iteration 13/25 | Loss: 0.00055446
Iteration 14/25 | Loss: 0.00055446
Iteration 15/25 | Loss: 0.00055446
Iteration 16/25 | Loss: 0.00055446
Iteration 17/25 | Loss: 0.00055446
Iteration 18/25 | Loss: 0.00055446
Iteration 19/25 | Loss: 0.00055446
Iteration 20/25 | Loss: 0.00055446
Iteration 21/25 | Loss: 0.00055446
Iteration 22/25 | Loss: 0.00055446
Iteration 23/25 | Loss: 0.00055446
Iteration 24/25 | Loss: 0.00055446
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0005544553860090673, 0.0005544553860090673, 0.0005544553860090673, 0.0005544553860090673, 0.0005544553860090673]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005544553860090673

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055446
Iteration 2/1000 | Loss: 0.00002717
Iteration 3/1000 | Loss: 0.00001777
Iteration 4/1000 | Loss: 0.00001582
Iteration 5/1000 | Loss: 0.00001462
Iteration 6/1000 | Loss: 0.00001429
Iteration 7/1000 | Loss: 0.00001395
Iteration 8/1000 | Loss: 0.00001373
Iteration 9/1000 | Loss: 0.00001356
Iteration 10/1000 | Loss: 0.00001342
Iteration 11/1000 | Loss: 0.00001337
Iteration 12/1000 | Loss: 0.00001335
Iteration 13/1000 | Loss: 0.00001333
Iteration 14/1000 | Loss: 0.00001332
Iteration 15/1000 | Loss: 0.00001320
Iteration 16/1000 | Loss: 0.00001319
Iteration 17/1000 | Loss: 0.00001316
Iteration 18/1000 | Loss: 0.00001316
Iteration 19/1000 | Loss: 0.00001315
Iteration 20/1000 | Loss: 0.00001315
Iteration 21/1000 | Loss: 0.00001314
Iteration 22/1000 | Loss: 0.00001313
Iteration 23/1000 | Loss: 0.00001312
Iteration 24/1000 | Loss: 0.00001312
Iteration 25/1000 | Loss: 0.00001311
Iteration 26/1000 | Loss: 0.00001311
Iteration 27/1000 | Loss: 0.00001311
Iteration 28/1000 | Loss: 0.00001311
Iteration 29/1000 | Loss: 0.00001310
Iteration 30/1000 | Loss: 0.00001309
Iteration 31/1000 | Loss: 0.00001309
Iteration 32/1000 | Loss: 0.00001308
Iteration 33/1000 | Loss: 0.00001308
Iteration 34/1000 | Loss: 0.00001308
Iteration 35/1000 | Loss: 0.00001307
Iteration 36/1000 | Loss: 0.00001307
Iteration 37/1000 | Loss: 0.00001307
Iteration 38/1000 | Loss: 0.00001307
Iteration 39/1000 | Loss: 0.00001306
Iteration 40/1000 | Loss: 0.00001306
Iteration 41/1000 | Loss: 0.00001306
Iteration 42/1000 | Loss: 0.00001305
Iteration 43/1000 | Loss: 0.00001305
Iteration 44/1000 | Loss: 0.00001305
Iteration 45/1000 | Loss: 0.00001304
Iteration 46/1000 | Loss: 0.00001304
Iteration 47/1000 | Loss: 0.00001304
Iteration 48/1000 | Loss: 0.00001304
Iteration 49/1000 | Loss: 0.00001304
Iteration 50/1000 | Loss: 0.00001303
Iteration 51/1000 | Loss: 0.00001303
Iteration 52/1000 | Loss: 0.00001303
Iteration 53/1000 | Loss: 0.00001303
Iteration 54/1000 | Loss: 0.00001302
Iteration 55/1000 | Loss: 0.00001302
Iteration 56/1000 | Loss: 0.00001302
Iteration 57/1000 | Loss: 0.00001301
Iteration 58/1000 | Loss: 0.00001301
Iteration 59/1000 | Loss: 0.00001301
Iteration 60/1000 | Loss: 0.00001300
Iteration 61/1000 | Loss: 0.00001300
Iteration 62/1000 | Loss: 0.00001299
Iteration 63/1000 | Loss: 0.00001299
Iteration 64/1000 | Loss: 0.00001298
Iteration 65/1000 | Loss: 0.00001298
Iteration 66/1000 | Loss: 0.00001297
Iteration 67/1000 | Loss: 0.00001297
Iteration 68/1000 | Loss: 0.00001297
Iteration 69/1000 | Loss: 0.00001296
Iteration 70/1000 | Loss: 0.00001296
Iteration 71/1000 | Loss: 0.00001295
Iteration 72/1000 | Loss: 0.00001293
Iteration 73/1000 | Loss: 0.00001293
Iteration 74/1000 | Loss: 0.00001293
Iteration 75/1000 | Loss: 0.00001292
Iteration 76/1000 | Loss: 0.00001292
Iteration 77/1000 | Loss: 0.00001289
Iteration 78/1000 | Loss: 0.00001288
Iteration 79/1000 | Loss: 0.00001288
Iteration 80/1000 | Loss: 0.00001287
Iteration 81/1000 | Loss: 0.00001287
Iteration 82/1000 | Loss: 0.00001287
Iteration 83/1000 | Loss: 0.00001287
Iteration 84/1000 | Loss: 0.00001286
Iteration 85/1000 | Loss: 0.00001285
Iteration 86/1000 | Loss: 0.00001285
Iteration 87/1000 | Loss: 0.00001284
Iteration 88/1000 | Loss: 0.00001284
Iteration 89/1000 | Loss: 0.00001284
Iteration 90/1000 | Loss: 0.00001283
Iteration 91/1000 | Loss: 0.00001283
Iteration 92/1000 | Loss: 0.00001283
Iteration 93/1000 | Loss: 0.00001283
Iteration 94/1000 | Loss: 0.00001282
Iteration 95/1000 | Loss: 0.00001282
Iteration 96/1000 | Loss: 0.00001282
Iteration 97/1000 | Loss: 0.00001281
Iteration 98/1000 | Loss: 0.00001281
Iteration 99/1000 | Loss: 0.00001281
Iteration 100/1000 | Loss: 0.00001281
Iteration 101/1000 | Loss: 0.00001281
Iteration 102/1000 | Loss: 0.00001280
Iteration 103/1000 | Loss: 0.00001280
Iteration 104/1000 | Loss: 0.00001280
Iteration 105/1000 | Loss: 0.00001280
Iteration 106/1000 | Loss: 0.00001280
Iteration 107/1000 | Loss: 0.00001280
Iteration 108/1000 | Loss: 0.00001280
Iteration 109/1000 | Loss: 0.00001280
Iteration 110/1000 | Loss: 0.00001280
Iteration 111/1000 | Loss: 0.00001280
Iteration 112/1000 | Loss: 0.00001279
Iteration 113/1000 | Loss: 0.00001279
Iteration 114/1000 | Loss: 0.00001279
Iteration 115/1000 | Loss: 0.00001279
Iteration 116/1000 | Loss: 0.00001279
Iteration 117/1000 | Loss: 0.00001279
Iteration 118/1000 | Loss: 0.00001279
Iteration 119/1000 | Loss: 0.00001279
Iteration 120/1000 | Loss: 0.00001279
Iteration 121/1000 | Loss: 0.00001279
Iteration 122/1000 | Loss: 0.00001279
Iteration 123/1000 | Loss: 0.00001279
Iteration 124/1000 | Loss: 0.00001279
Iteration 125/1000 | Loss: 0.00001279
Iteration 126/1000 | Loss: 0.00001279
Iteration 127/1000 | Loss: 0.00001279
Iteration 128/1000 | Loss: 0.00001278
Iteration 129/1000 | Loss: 0.00001278
Iteration 130/1000 | Loss: 0.00001278
Iteration 131/1000 | Loss: 0.00001278
Iteration 132/1000 | Loss: 0.00001278
Iteration 133/1000 | Loss: 0.00001278
Iteration 134/1000 | Loss: 0.00001278
Iteration 135/1000 | Loss: 0.00001278
Iteration 136/1000 | Loss: 0.00001278
Iteration 137/1000 | Loss: 0.00001278
Iteration 138/1000 | Loss: 0.00001278
Iteration 139/1000 | Loss: 0.00001278
Iteration 140/1000 | Loss: 0.00001277
Iteration 141/1000 | Loss: 0.00001277
Iteration 142/1000 | Loss: 0.00001277
Iteration 143/1000 | Loss: 0.00001277
Iteration 144/1000 | Loss: 0.00001277
Iteration 145/1000 | Loss: 0.00001277
Iteration 146/1000 | Loss: 0.00001277
Iteration 147/1000 | Loss: 0.00001277
Iteration 148/1000 | Loss: 0.00001277
Iteration 149/1000 | Loss: 0.00001277
Iteration 150/1000 | Loss: 0.00001277
Iteration 151/1000 | Loss: 0.00001277
Iteration 152/1000 | Loss: 0.00001277
Iteration 153/1000 | Loss: 0.00001277
Iteration 154/1000 | Loss: 0.00001277
Iteration 155/1000 | Loss: 0.00001277
Iteration 156/1000 | Loss: 0.00001277
Iteration 157/1000 | Loss: 0.00001277
Iteration 158/1000 | Loss: 0.00001277
Iteration 159/1000 | Loss: 0.00001277
Iteration 160/1000 | Loss: 0.00001277
Iteration 161/1000 | Loss: 0.00001277
Iteration 162/1000 | Loss: 0.00001277
Iteration 163/1000 | Loss: 0.00001277
Iteration 164/1000 | Loss: 0.00001277
Iteration 165/1000 | Loss: 0.00001277
Iteration 166/1000 | Loss: 0.00001277
Iteration 167/1000 | Loss: 0.00001277
Iteration 168/1000 | Loss: 0.00001277
Iteration 169/1000 | Loss: 0.00001277
Iteration 170/1000 | Loss: 0.00001277
Iteration 171/1000 | Loss: 0.00001277
Iteration 172/1000 | Loss: 0.00001277
Iteration 173/1000 | Loss: 0.00001277
Iteration 174/1000 | Loss: 0.00001277
Iteration 175/1000 | Loss: 0.00001277
Iteration 176/1000 | Loss: 0.00001277
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 176. Stopping optimization.
Last 5 losses: [1.2774435163009912e-05, 1.2774435163009912e-05, 1.2774435163009912e-05, 1.2774435163009912e-05, 1.2774435163009912e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2774435163009912e-05

Optimization complete. Final v2v error: 3.060072183609009 mm

Highest mean error: 3.336538553237915 mm for frame 218

Lowest mean error: 2.8148834705352783 mm for frame 161

Saving results

Total time: 40.52694034576416
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1086
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01006853
Iteration 2/25 | Loss: 0.00429844
Iteration 3/25 | Loss: 0.00297023
Iteration 4/25 | Loss: 0.00226259
Iteration 5/25 | Loss: 0.00215984
Iteration 6/25 | Loss: 0.00205513
Iteration 7/25 | Loss: 0.00204533
Iteration 8/25 | Loss: 0.00203040
Iteration 9/25 | Loss: 0.00176630
Iteration 10/25 | Loss: 0.00168308
Iteration 11/25 | Loss: 0.00169821
Iteration 12/25 | Loss: 0.00162732
Iteration 13/25 | Loss: 0.00160302
Iteration 14/25 | Loss: 0.00155987
Iteration 15/25 | Loss: 0.00159848
Iteration 16/25 | Loss: 0.00148171
Iteration 17/25 | Loss: 0.00143280
Iteration 18/25 | Loss: 0.00151419
Iteration 19/25 | Loss: 0.00146647
Iteration 20/25 | Loss: 0.00143093
Iteration 21/25 | Loss: 0.00144525
Iteration 22/25 | Loss: 0.00143357
Iteration 23/25 | Loss: 0.00143127
Iteration 24/25 | Loss: 0.00141769
Iteration 25/25 | Loss: 0.00144066

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.13074589
Iteration 2/25 | Loss: 0.02339157
Iteration 3/25 | Loss: 0.00709249
Iteration 4/25 | Loss: 0.00709220
Iteration 5/25 | Loss: 0.00709220
Iteration 6/25 | Loss: 0.00709220
Iteration 7/25 | Loss: 0.00709220
Iteration 8/25 | Loss: 0.00709220
Iteration 9/25 | Loss: 0.00709220
Iteration 10/25 | Loss: 0.00709220
Iteration 11/25 | Loss: 0.00709220
Iteration 12/25 | Loss: 0.00709220
Iteration 13/25 | Loss: 0.00709220
Iteration 14/25 | Loss: 0.00709220
Iteration 15/25 | Loss: 0.00709220
Iteration 16/25 | Loss: 0.00709220
Iteration 17/25 | Loss: 0.00709220
Iteration 18/25 | Loss: 0.00709220
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.007092198822647333, 0.007092198822647333, 0.007092198822647333, 0.007092198822647333, 0.007092198822647333]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.007092198822647333

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00709220
Iteration 2/1000 | Loss: 0.00314947
Iteration 3/1000 | Loss: 0.00579735
Iteration 4/1000 | Loss: 0.00751047
Iteration 5/1000 | Loss: 0.00863902
Iteration 6/1000 | Loss: 0.00688491
Iteration 7/1000 | Loss: 0.00362433
Iteration 8/1000 | Loss: 0.01228865
Iteration 9/1000 | Loss: 0.00611650
Iteration 10/1000 | Loss: 0.00392166
Iteration 11/1000 | Loss: 0.00688319
Iteration 12/1000 | Loss: 0.00527078
Iteration 13/1000 | Loss: 0.00472925
Iteration 14/1000 | Loss: 0.01225875
Iteration 15/1000 | Loss: 0.00879120
Iteration 16/1000 | Loss: 0.00496634
Iteration 17/1000 | Loss: 0.00417522
Iteration 18/1000 | Loss: 0.01100669
Iteration 19/1000 | Loss: 0.00357414
Iteration 20/1000 | Loss: 0.00830486
Iteration 21/1000 | Loss: 0.00490226
Iteration 22/1000 | Loss: 0.00935605
Iteration 23/1000 | Loss: 0.00300622
Iteration 24/1000 | Loss: 0.00896156
Iteration 25/1000 | Loss: 0.00281895
Iteration 26/1000 | Loss: 0.00333510
Iteration 27/1000 | Loss: 0.00249583
Iteration 28/1000 | Loss: 0.00332688
Iteration 29/1000 | Loss: 0.00227589
Iteration 30/1000 | Loss: 0.00273073
Iteration 31/1000 | Loss: 0.00564765
Iteration 32/1000 | Loss: 0.00336266
Iteration 33/1000 | Loss: 0.00375099
Iteration 34/1000 | Loss: 0.00405393
Iteration 35/1000 | Loss: 0.00209591
Iteration 36/1000 | Loss: 0.00254217
Iteration 37/1000 | Loss: 0.00207175
Iteration 38/1000 | Loss: 0.00212983
Iteration 39/1000 | Loss: 0.00267115
Iteration 40/1000 | Loss: 0.00392807
Iteration 41/1000 | Loss: 0.00322685
Iteration 42/1000 | Loss: 0.00194496
Iteration 43/1000 | Loss: 0.00698986
Iteration 44/1000 | Loss: 0.00353223
Iteration 45/1000 | Loss: 0.00219520
Iteration 46/1000 | Loss: 0.00704930
Iteration 47/1000 | Loss: 0.00176297
Iteration 48/1000 | Loss: 0.00054257
Iteration 49/1000 | Loss: 0.00070984
Iteration 50/1000 | Loss: 0.00237523
Iteration 51/1000 | Loss: 0.00038337
Iteration 52/1000 | Loss: 0.00068288
Iteration 53/1000 | Loss: 0.00910528
Iteration 54/1000 | Loss: 0.00423777
Iteration 55/1000 | Loss: 0.00194658
Iteration 56/1000 | Loss: 0.00036057
Iteration 57/1000 | Loss: 0.00169859
Iteration 58/1000 | Loss: 0.00028902
Iteration 59/1000 | Loss: 0.00180156
Iteration 60/1000 | Loss: 0.00122817
Iteration 61/1000 | Loss: 0.00191526
Iteration 62/1000 | Loss: 0.00503914
Iteration 63/1000 | Loss: 0.00022142
Iteration 64/1000 | Loss: 0.00028616
Iteration 65/1000 | Loss: 0.00013317
Iteration 66/1000 | Loss: 0.00017634
Iteration 67/1000 | Loss: 0.00022101
Iteration 68/1000 | Loss: 0.00140047
Iteration 69/1000 | Loss: 0.00542143
Iteration 70/1000 | Loss: 0.00042073
Iteration 71/1000 | Loss: 0.00007785
Iteration 72/1000 | Loss: 0.00007949
Iteration 73/1000 | Loss: 0.00148801
Iteration 74/1000 | Loss: 0.00424851
Iteration 75/1000 | Loss: 0.00114340
Iteration 76/1000 | Loss: 0.00005807
Iteration 77/1000 | Loss: 0.00208936
Iteration 78/1000 | Loss: 0.00014464
Iteration 79/1000 | Loss: 0.00005005
Iteration 80/1000 | Loss: 0.00151648
Iteration 81/1000 | Loss: 0.00009856
Iteration 82/1000 | Loss: 0.00109549
Iteration 83/1000 | Loss: 0.00012030
Iteration 84/1000 | Loss: 0.00004802
Iteration 85/1000 | Loss: 0.00095362
Iteration 86/1000 | Loss: 0.00051400
Iteration 87/1000 | Loss: 0.00025750
Iteration 88/1000 | Loss: 0.00044091
Iteration 89/1000 | Loss: 0.00008353
Iteration 90/1000 | Loss: 0.00030804
Iteration 91/1000 | Loss: 0.00016172
Iteration 92/1000 | Loss: 0.00105184
Iteration 93/1000 | Loss: 0.00074484
Iteration 94/1000 | Loss: 0.00017341
Iteration 95/1000 | Loss: 0.00080584
Iteration 96/1000 | Loss: 0.00045879
Iteration 97/1000 | Loss: 0.00014384
Iteration 98/1000 | Loss: 0.00052165
Iteration 99/1000 | Loss: 0.00087461
Iteration 100/1000 | Loss: 0.00445271
Iteration 101/1000 | Loss: 0.00105659
Iteration 102/1000 | Loss: 0.00039692
Iteration 103/1000 | Loss: 0.00004864
Iteration 104/1000 | Loss: 0.00037812
Iteration 105/1000 | Loss: 0.00036030
Iteration 106/1000 | Loss: 0.00019988
Iteration 107/1000 | Loss: 0.00006391
Iteration 108/1000 | Loss: 0.00004039
Iteration 109/1000 | Loss: 0.00003229
Iteration 110/1000 | Loss: 0.00002973
Iteration 111/1000 | Loss: 0.00002838
Iteration 112/1000 | Loss: 0.00002723
Iteration 113/1000 | Loss: 0.00002620
Iteration 114/1000 | Loss: 0.00002545
Iteration 115/1000 | Loss: 0.00002499
Iteration 116/1000 | Loss: 0.00002461
Iteration 117/1000 | Loss: 0.00002425
Iteration 118/1000 | Loss: 0.00002419
Iteration 119/1000 | Loss: 0.00002380
Iteration 120/1000 | Loss: 0.00280544
Iteration 121/1000 | Loss: 0.00025428
Iteration 122/1000 | Loss: 0.00008920
Iteration 123/1000 | Loss: 0.00002763
Iteration 124/1000 | Loss: 0.00164892
Iteration 125/1000 | Loss: 0.00008613
Iteration 126/1000 | Loss: 0.00077525
Iteration 127/1000 | Loss: 0.00007936
Iteration 128/1000 | Loss: 0.00016774
Iteration 129/1000 | Loss: 0.00002777
Iteration 130/1000 | Loss: 0.00002561
Iteration 131/1000 | Loss: 0.00002404
Iteration 132/1000 | Loss: 0.00002340
Iteration 133/1000 | Loss: 0.00002315
Iteration 134/1000 | Loss: 0.00002300
Iteration 135/1000 | Loss: 0.00002298
Iteration 136/1000 | Loss: 0.00002294
Iteration 137/1000 | Loss: 0.00002292
Iteration 138/1000 | Loss: 0.00002287
Iteration 139/1000 | Loss: 0.00002285
Iteration 140/1000 | Loss: 0.00002285
Iteration 141/1000 | Loss: 0.00002277
Iteration 142/1000 | Loss: 0.00002276
Iteration 143/1000 | Loss: 0.00002273
Iteration 144/1000 | Loss: 0.00002270
Iteration 145/1000 | Loss: 0.00002264
Iteration 146/1000 | Loss: 0.00002264
Iteration 147/1000 | Loss: 0.00002262
Iteration 148/1000 | Loss: 0.00002262
Iteration 149/1000 | Loss: 0.00002262
Iteration 150/1000 | Loss: 0.00002262
Iteration 151/1000 | Loss: 0.00002262
Iteration 152/1000 | Loss: 0.00002262
Iteration 153/1000 | Loss: 0.00002261
Iteration 154/1000 | Loss: 0.00002261
Iteration 155/1000 | Loss: 0.00002260
Iteration 156/1000 | Loss: 0.00002260
Iteration 157/1000 | Loss: 0.00002260
Iteration 158/1000 | Loss: 0.00002258
Iteration 159/1000 | Loss: 0.00002257
Iteration 160/1000 | Loss: 0.00002255
Iteration 161/1000 | Loss: 0.00002254
Iteration 162/1000 | Loss: 0.00002254
Iteration 163/1000 | Loss: 0.00002252
Iteration 164/1000 | Loss: 0.00002252
Iteration 165/1000 | Loss: 0.00002251
Iteration 166/1000 | Loss: 0.00002250
Iteration 167/1000 | Loss: 0.00002250
Iteration 168/1000 | Loss: 0.00002249
Iteration 169/1000 | Loss: 0.00002249
Iteration 170/1000 | Loss: 0.00002248
Iteration 171/1000 | Loss: 0.00002247
Iteration 172/1000 | Loss: 0.00002246
Iteration 173/1000 | Loss: 0.00002245
Iteration 174/1000 | Loss: 0.00002245
Iteration 175/1000 | Loss: 0.00002244
Iteration 176/1000 | Loss: 0.00002244
Iteration 177/1000 | Loss: 0.00002243
Iteration 178/1000 | Loss: 0.00002243
Iteration 179/1000 | Loss: 0.00002242
Iteration 180/1000 | Loss: 0.00002242
Iteration 181/1000 | Loss: 0.00002242
Iteration 182/1000 | Loss: 0.00002241
Iteration 183/1000 | Loss: 0.00002241
Iteration 184/1000 | Loss: 0.00002241
Iteration 185/1000 | Loss: 0.00002240
Iteration 186/1000 | Loss: 0.00002239
Iteration 187/1000 | Loss: 0.00002239
Iteration 188/1000 | Loss: 0.00002239
Iteration 189/1000 | Loss: 0.00002239
Iteration 190/1000 | Loss: 0.00002239
Iteration 191/1000 | Loss: 0.00002239
Iteration 192/1000 | Loss: 0.00002239
Iteration 193/1000 | Loss: 0.00002239
Iteration 194/1000 | Loss: 0.00002239
Iteration 195/1000 | Loss: 0.00002239
Iteration 196/1000 | Loss: 0.00002238
Iteration 197/1000 | Loss: 0.00002238
Iteration 198/1000 | Loss: 0.00002238
Iteration 199/1000 | Loss: 0.00002238
Iteration 200/1000 | Loss: 0.00002236
Iteration 201/1000 | Loss: 0.00002236
Iteration 202/1000 | Loss: 0.00002236
Iteration 203/1000 | Loss: 0.00002235
Iteration 204/1000 | Loss: 0.00002235
Iteration 205/1000 | Loss: 0.00002235
Iteration 206/1000 | Loss: 0.00002235
Iteration 207/1000 | Loss: 0.00002235
Iteration 208/1000 | Loss: 0.00002234
Iteration 209/1000 | Loss: 0.00002234
Iteration 210/1000 | Loss: 0.00002234
Iteration 211/1000 | Loss: 0.00002234
Iteration 212/1000 | Loss: 0.00002234
Iteration 213/1000 | Loss: 0.00002233
Iteration 214/1000 | Loss: 0.00002233
Iteration 215/1000 | Loss: 0.00002232
Iteration 216/1000 | Loss: 0.00002232
Iteration 217/1000 | Loss: 0.00002232
Iteration 218/1000 | Loss: 0.00002232
Iteration 219/1000 | Loss: 0.00002231
Iteration 220/1000 | Loss: 0.00002231
Iteration 221/1000 | Loss: 0.00002230
Iteration 222/1000 | Loss: 0.00002230
Iteration 223/1000 | Loss: 0.00002230
Iteration 224/1000 | Loss: 0.00002230
Iteration 225/1000 | Loss: 0.00002230
Iteration 226/1000 | Loss: 0.00002230
Iteration 227/1000 | Loss: 0.00002230
Iteration 228/1000 | Loss: 0.00002229
Iteration 229/1000 | Loss: 0.00002229
Iteration 230/1000 | Loss: 0.00002229
Iteration 231/1000 | Loss: 0.00002229
Iteration 232/1000 | Loss: 0.00002229
Iteration 233/1000 | Loss: 0.00002229
Iteration 234/1000 | Loss: 0.00002229
Iteration 235/1000 | Loss: 0.00002228
Iteration 236/1000 | Loss: 0.00002228
Iteration 237/1000 | Loss: 0.00002228
Iteration 238/1000 | Loss: 0.00002228
Iteration 239/1000 | Loss: 0.00002228
Iteration 240/1000 | Loss: 0.00002227
Iteration 241/1000 | Loss: 0.00002227
Iteration 242/1000 | Loss: 0.00002227
Iteration 243/1000 | Loss: 0.00002227
Iteration 244/1000 | Loss: 0.00002226
Iteration 245/1000 | Loss: 0.00002226
Iteration 246/1000 | Loss: 0.00002226
Iteration 247/1000 | Loss: 0.00002226
Iteration 248/1000 | Loss: 0.00002225
Iteration 249/1000 | Loss: 0.00002225
Iteration 250/1000 | Loss: 0.00002225
Iteration 251/1000 | Loss: 0.00002225
Iteration 252/1000 | Loss: 0.00002225
Iteration 253/1000 | Loss: 0.00002225
Iteration 254/1000 | Loss: 0.00002225
Iteration 255/1000 | Loss: 0.00002224
Iteration 256/1000 | Loss: 0.00002224
Iteration 257/1000 | Loss: 0.00002224
Iteration 258/1000 | Loss: 0.00002224
Iteration 259/1000 | Loss: 0.00002224
Iteration 260/1000 | Loss: 0.00002224
Iteration 261/1000 | Loss: 0.00002224
Iteration 262/1000 | Loss: 0.00002224
Iteration 263/1000 | Loss: 0.00002224
Iteration 264/1000 | Loss: 0.00002224
Iteration 265/1000 | Loss: 0.00002224
Iteration 266/1000 | Loss: 0.00002223
Iteration 267/1000 | Loss: 0.00002223
Iteration 268/1000 | Loss: 0.00002223
Iteration 269/1000 | Loss: 0.00002223
Iteration 270/1000 | Loss: 0.00002223
Iteration 271/1000 | Loss: 0.00002222
Iteration 272/1000 | Loss: 0.00002222
Iteration 273/1000 | Loss: 0.00002222
Iteration 274/1000 | Loss: 0.00002222
Iteration 275/1000 | Loss: 0.00002222
Iteration 276/1000 | Loss: 0.00002222
Iteration 277/1000 | Loss: 0.00002221
Iteration 278/1000 | Loss: 0.00002221
Iteration 279/1000 | Loss: 0.00002221
Iteration 280/1000 | Loss: 0.00002221
Iteration 281/1000 | Loss: 0.00002221
Iteration 282/1000 | Loss: 0.00002221
Iteration 283/1000 | Loss: 0.00002221
Iteration 284/1000 | Loss: 0.00002221
Iteration 285/1000 | Loss: 0.00002220
Iteration 286/1000 | Loss: 0.00002220
Iteration 287/1000 | Loss: 0.00002220
Iteration 288/1000 | Loss: 0.00002220
Iteration 289/1000 | Loss: 0.00002220
Iteration 290/1000 | Loss: 0.00002220
Iteration 291/1000 | Loss: 0.00002220
Iteration 292/1000 | Loss: 0.00002220
Iteration 293/1000 | Loss: 0.00002220
Iteration 294/1000 | Loss: 0.00002220
Iteration 295/1000 | Loss: 0.00002220
Iteration 296/1000 | Loss: 0.00002220
Iteration 297/1000 | Loss: 0.00002220
Iteration 298/1000 | Loss: 0.00002220
Iteration 299/1000 | Loss: 0.00002220
Iteration 300/1000 | Loss: 0.00002220
Iteration 301/1000 | Loss: 0.00002220
Iteration 302/1000 | Loss: 0.00002220
Iteration 303/1000 | Loss: 0.00002220
Iteration 304/1000 | Loss: 0.00002220
Iteration 305/1000 | Loss: 0.00002220
Iteration 306/1000 | Loss: 0.00002220
Iteration 307/1000 | Loss: 0.00002220
Iteration 308/1000 | Loss: 0.00002220
Iteration 309/1000 | Loss: 0.00002219
Iteration 310/1000 | Loss: 0.00002219
Iteration 311/1000 | Loss: 0.00002219
Iteration 312/1000 | Loss: 0.00002219
Iteration 313/1000 | Loss: 0.00002219
Iteration 314/1000 | Loss: 0.00002219
Iteration 315/1000 | Loss: 0.00002219
Iteration 316/1000 | Loss: 0.00002219
Iteration 317/1000 | Loss: 0.00002219
Iteration 318/1000 | Loss: 0.00002219
Iteration 319/1000 | Loss: 0.00002219
Iteration 320/1000 | Loss: 0.00002219
Iteration 321/1000 | Loss: 0.00002218
Iteration 322/1000 | Loss: 0.00002218
Iteration 323/1000 | Loss: 0.00002218
Iteration 324/1000 | Loss: 0.00002218
Iteration 325/1000 | Loss: 0.00002218
Iteration 326/1000 | Loss: 0.00002218
Iteration 327/1000 | Loss: 0.00002218
Iteration 328/1000 | Loss: 0.00002218
Iteration 329/1000 | Loss: 0.00002218
Iteration 330/1000 | Loss: 0.00002218
Iteration 331/1000 | Loss: 0.00002218
Iteration 332/1000 | Loss: 0.00002218
Iteration 333/1000 | Loss: 0.00002218
Iteration 334/1000 | Loss: 0.00002218
Iteration 335/1000 | Loss: 0.00002218
Iteration 336/1000 | Loss: 0.00002218
Iteration 337/1000 | Loss: 0.00002218
Iteration 338/1000 | Loss: 0.00002218
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 338. Stopping optimization.
Last 5 losses: [2.2183805413078517e-05, 2.2183805413078517e-05, 2.2183805413078517e-05, 2.2183805413078517e-05, 2.2183805413078517e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2183805413078517e-05

Optimization complete. Final v2v error: 3.875662326812744 mm

Highest mean error: 5.4859724044799805 mm for frame 45

Lowest mean error: 2.9685354232788086 mm for frame 91

Saving results

Total time: 255.08824634552002
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1066
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00834117
Iteration 2/25 | Loss: 0.00122211
Iteration 3/25 | Loss: 0.00087699
Iteration 4/25 | Loss: 0.00082952
Iteration 5/25 | Loss: 0.00082374
Iteration 6/25 | Loss: 0.00082228
Iteration 7/25 | Loss: 0.00082166
Iteration 8/25 | Loss: 0.00082153
Iteration 9/25 | Loss: 0.00082153
Iteration 10/25 | Loss: 0.00082153
Iteration 11/25 | Loss: 0.00082153
Iteration 12/25 | Loss: 0.00082153
Iteration 13/25 | Loss: 0.00082153
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008215319830924273, 0.0008215319830924273, 0.0008215319830924273, 0.0008215319830924273, 0.0008215319830924273]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008215319830924273

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52186346
Iteration 2/25 | Loss: 0.00060689
Iteration 3/25 | Loss: 0.00060689
Iteration 4/25 | Loss: 0.00060689
Iteration 5/25 | Loss: 0.00060689
Iteration 6/25 | Loss: 0.00060689
Iteration 7/25 | Loss: 0.00060689
Iteration 8/25 | Loss: 0.00060689
Iteration 9/25 | Loss: 0.00060689
Iteration 10/25 | Loss: 0.00060689
Iteration 11/25 | Loss: 0.00060689
Iteration 12/25 | Loss: 0.00060689
Iteration 13/25 | Loss: 0.00060689
Iteration 14/25 | Loss: 0.00060689
Iteration 15/25 | Loss: 0.00060689
Iteration 16/25 | Loss: 0.00060689
Iteration 17/25 | Loss: 0.00060689
Iteration 18/25 | Loss: 0.00060689
Iteration 19/25 | Loss: 0.00060689
Iteration 20/25 | Loss: 0.00060689
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0006068878574296832, 0.0006068878574296832, 0.0006068878574296832, 0.0006068878574296832, 0.0006068878574296832]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006068878574296832

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060689
Iteration 2/1000 | Loss: 0.00001976
Iteration 3/1000 | Loss: 0.00001456
Iteration 4/1000 | Loss: 0.00001338
Iteration 5/1000 | Loss: 0.00001254
Iteration 6/1000 | Loss: 0.00001212
Iteration 7/1000 | Loss: 0.00001186
Iteration 8/1000 | Loss: 0.00001171
Iteration 9/1000 | Loss: 0.00001167
Iteration 10/1000 | Loss: 0.00001161
Iteration 11/1000 | Loss: 0.00001160
Iteration 12/1000 | Loss: 0.00001160
Iteration 13/1000 | Loss: 0.00001150
Iteration 14/1000 | Loss: 0.00001145
Iteration 15/1000 | Loss: 0.00001134
Iteration 16/1000 | Loss: 0.00001131
Iteration 17/1000 | Loss: 0.00001127
Iteration 18/1000 | Loss: 0.00001127
Iteration 19/1000 | Loss: 0.00001126
Iteration 20/1000 | Loss: 0.00001126
Iteration 21/1000 | Loss: 0.00001125
Iteration 22/1000 | Loss: 0.00001125
Iteration 23/1000 | Loss: 0.00001124
Iteration 24/1000 | Loss: 0.00001123
Iteration 25/1000 | Loss: 0.00001123
Iteration 26/1000 | Loss: 0.00001122
Iteration 27/1000 | Loss: 0.00001122
Iteration 28/1000 | Loss: 0.00001122
Iteration 29/1000 | Loss: 0.00001122
Iteration 30/1000 | Loss: 0.00001121
Iteration 31/1000 | Loss: 0.00001121
Iteration 32/1000 | Loss: 0.00001121
Iteration 33/1000 | Loss: 0.00001121
Iteration 34/1000 | Loss: 0.00001120
Iteration 35/1000 | Loss: 0.00001120
Iteration 36/1000 | Loss: 0.00001120
Iteration 37/1000 | Loss: 0.00001120
Iteration 38/1000 | Loss: 0.00001119
Iteration 39/1000 | Loss: 0.00001119
Iteration 40/1000 | Loss: 0.00001118
Iteration 41/1000 | Loss: 0.00001118
Iteration 42/1000 | Loss: 0.00001118
Iteration 43/1000 | Loss: 0.00001118
Iteration 44/1000 | Loss: 0.00001117
Iteration 45/1000 | Loss: 0.00001116
Iteration 46/1000 | Loss: 0.00001116
Iteration 47/1000 | Loss: 0.00001116
Iteration 48/1000 | Loss: 0.00001116
Iteration 49/1000 | Loss: 0.00001116
Iteration 50/1000 | Loss: 0.00001116
Iteration 51/1000 | Loss: 0.00001116
Iteration 52/1000 | Loss: 0.00001116
Iteration 53/1000 | Loss: 0.00001116
Iteration 54/1000 | Loss: 0.00001116
Iteration 55/1000 | Loss: 0.00001116
Iteration 56/1000 | Loss: 0.00001116
Iteration 57/1000 | Loss: 0.00001116
Iteration 58/1000 | Loss: 0.00001115
Iteration 59/1000 | Loss: 0.00001115
Iteration 60/1000 | Loss: 0.00001115
Iteration 61/1000 | Loss: 0.00001115
Iteration 62/1000 | Loss: 0.00001115
Iteration 63/1000 | Loss: 0.00001115
Iteration 64/1000 | Loss: 0.00001115
Iteration 65/1000 | Loss: 0.00001114
Iteration 66/1000 | Loss: 0.00001114
Iteration 67/1000 | Loss: 0.00001114
Iteration 68/1000 | Loss: 0.00001114
Iteration 69/1000 | Loss: 0.00001114
Iteration 70/1000 | Loss: 0.00001114
Iteration 71/1000 | Loss: 0.00001114
Iteration 72/1000 | Loss: 0.00001114
Iteration 73/1000 | Loss: 0.00001114
Iteration 74/1000 | Loss: 0.00001114
Iteration 75/1000 | Loss: 0.00001114
Iteration 76/1000 | Loss: 0.00001114
Iteration 77/1000 | Loss: 0.00001114
Iteration 78/1000 | Loss: 0.00001114
Iteration 79/1000 | Loss: 0.00001114
Iteration 80/1000 | Loss: 0.00001114
Iteration 81/1000 | Loss: 0.00001114
Iteration 82/1000 | Loss: 0.00001114
Iteration 83/1000 | Loss: 0.00001114
Iteration 84/1000 | Loss: 0.00001114
Iteration 85/1000 | Loss: 0.00001114
Iteration 86/1000 | Loss: 0.00001114
Iteration 87/1000 | Loss: 0.00001114
Iteration 88/1000 | Loss: 0.00001114
Iteration 89/1000 | Loss: 0.00001114
Iteration 90/1000 | Loss: 0.00001114
Iteration 91/1000 | Loss: 0.00001114
Iteration 92/1000 | Loss: 0.00001114
Iteration 93/1000 | Loss: 0.00001114
Iteration 94/1000 | Loss: 0.00001114
Iteration 95/1000 | Loss: 0.00001114
Iteration 96/1000 | Loss: 0.00001114
Iteration 97/1000 | Loss: 0.00001114
Iteration 98/1000 | Loss: 0.00001114
Iteration 99/1000 | Loss: 0.00001114
Iteration 100/1000 | Loss: 0.00001114
Iteration 101/1000 | Loss: 0.00001114
Iteration 102/1000 | Loss: 0.00001114
Iteration 103/1000 | Loss: 0.00001114
Iteration 104/1000 | Loss: 0.00001114
Iteration 105/1000 | Loss: 0.00001114
Iteration 106/1000 | Loss: 0.00001114
Iteration 107/1000 | Loss: 0.00001114
Iteration 108/1000 | Loss: 0.00001114
Iteration 109/1000 | Loss: 0.00001114
Iteration 110/1000 | Loss: 0.00001114
Iteration 111/1000 | Loss: 0.00001114
Iteration 112/1000 | Loss: 0.00001114
Iteration 113/1000 | Loss: 0.00001114
Iteration 114/1000 | Loss: 0.00001114
Iteration 115/1000 | Loss: 0.00001114
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 115. Stopping optimization.
Last 5 losses: [1.1140449714730494e-05, 1.1140449714730494e-05, 1.1140449714730494e-05, 1.1140449714730494e-05, 1.1140449714730494e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1140449714730494e-05

Optimization complete. Final v2v error: 2.8251595497131348 mm

Highest mean error: 3.142350435256958 mm for frame 85

Lowest mean error: 2.6863837242126465 mm for frame 0

Saving results

Total time: 33.79028916358948
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00395256
Iteration 2/25 | Loss: 0.00098705
Iteration 3/25 | Loss: 0.00082279
Iteration 4/25 | Loss: 0.00080295
Iteration 5/25 | Loss: 0.00079712
Iteration 6/25 | Loss: 0.00079558
Iteration 7/25 | Loss: 0.00079510
Iteration 8/25 | Loss: 0.00079510
Iteration 9/25 | Loss: 0.00079510
Iteration 10/25 | Loss: 0.00079510
Iteration 11/25 | Loss: 0.00079510
Iteration 12/25 | Loss: 0.00079510
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007951048901304603, 0.0007951048901304603, 0.0007951048901304603, 0.0007951048901304603, 0.0007951048901304603]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007951048901304603

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50542140
Iteration 2/25 | Loss: 0.00055819
Iteration 3/25 | Loss: 0.00055819
Iteration 4/25 | Loss: 0.00055819
Iteration 5/25 | Loss: 0.00055819
Iteration 6/25 | Loss: 0.00055819
Iteration 7/25 | Loss: 0.00055819
Iteration 8/25 | Loss: 0.00055819
Iteration 9/25 | Loss: 0.00055819
Iteration 10/25 | Loss: 0.00055819
Iteration 11/25 | Loss: 0.00055819
Iteration 12/25 | Loss: 0.00055819
Iteration 13/25 | Loss: 0.00055819
Iteration 14/25 | Loss: 0.00055819
Iteration 15/25 | Loss: 0.00055819
Iteration 16/25 | Loss: 0.00055819
Iteration 17/25 | Loss: 0.00055819
Iteration 18/25 | Loss: 0.00055819
Iteration 19/25 | Loss: 0.00055819
Iteration 20/25 | Loss: 0.00055819
Iteration 21/25 | Loss: 0.00055819
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0005581861478276551, 0.0005581861478276551, 0.0005581861478276551, 0.0005581861478276551, 0.0005581861478276551]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005581861478276551

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055819
Iteration 2/1000 | Loss: 0.00002482
Iteration 3/1000 | Loss: 0.00001916
Iteration 4/1000 | Loss: 0.00001750
Iteration 5/1000 | Loss: 0.00001625
Iteration 6/1000 | Loss: 0.00001532
Iteration 7/1000 | Loss: 0.00001487
Iteration 8/1000 | Loss: 0.00001461
Iteration 9/1000 | Loss: 0.00001453
Iteration 10/1000 | Loss: 0.00001452
Iteration 11/1000 | Loss: 0.00001452
Iteration 12/1000 | Loss: 0.00001452
Iteration 13/1000 | Loss: 0.00001451
Iteration 14/1000 | Loss: 0.00001451
Iteration 15/1000 | Loss: 0.00001447
Iteration 16/1000 | Loss: 0.00001429
Iteration 17/1000 | Loss: 0.00001426
Iteration 18/1000 | Loss: 0.00001416
Iteration 19/1000 | Loss: 0.00001414
Iteration 20/1000 | Loss: 0.00001404
Iteration 21/1000 | Loss: 0.00001400
Iteration 22/1000 | Loss: 0.00001392
Iteration 23/1000 | Loss: 0.00001391
Iteration 24/1000 | Loss: 0.00001389
Iteration 25/1000 | Loss: 0.00001388
Iteration 26/1000 | Loss: 0.00001388
Iteration 27/1000 | Loss: 0.00001388
Iteration 28/1000 | Loss: 0.00001387
Iteration 29/1000 | Loss: 0.00001387
Iteration 30/1000 | Loss: 0.00001387
Iteration 31/1000 | Loss: 0.00001386
Iteration 32/1000 | Loss: 0.00001386
Iteration 33/1000 | Loss: 0.00001386
Iteration 34/1000 | Loss: 0.00001385
Iteration 35/1000 | Loss: 0.00001385
Iteration 36/1000 | Loss: 0.00001385
Iteration 37/1000 | Loss: 0.00001384
Iteration 38/1000 | Loss: 0.00001384
Iteration 39/1000 | Loss: 0.00001384
Iteration 40/1000 | Loss: 0.00001383
Iteration 41/1000 | Loss: 0.00001383
Iteration 42/1000 | Loss: 0.00001383
Iteration 43/1000 | Loss: 0.00001383
Iteration 44/1000 | Loss: 0.00001383
Iteration 45/1000 | Loss: 0.00001383
Iteration 46/1000 | Loss: 0.00001383
Iteration 47/1000 | Loss: 0.00001383
Iteration 48/1000 | Loss: 0.00001383
Iteration 49/1000 | Loss: 0.00001383
Iteration 50/1000 | Loss: 0.00001382
Iteration 51/1000 | Loss: 0.00001382
Iteration 52/1000 | Loss: 0.00001381
Iteration 53/1000 | Loss: 0.00001381
Iteration 54/1000 | Loss: 0.00001381
Iteration 55/1000 | Loss: 0.00001380
Iteration 56/1000 | Loss: 0.00001380
Iteration 57/1000 | Loss: 0.00001380
Iteration 58/1000 | Loss: 0.00001380
Iteration 59/1000 | Loss: 0.00001380
Iteration 60/1000 | Loss: 0.00001380
Iteration 61/1000 | Loss: 0.00001380
Iteration 62/1000 | Loss: 0.00001380
Iteration 63/1000 | Loss: 0.00001377
Iteration 64/1000 | Loss: 0.00001377
Iteration 65/1000 | Loss: 0.00001377
Iteration 66/1000 | Loss: 0.00001376
Iteration 67/1000 | Loss: 0.00001376
Iteration 68/1000 | Loss: 0.00001375
Iteration 69/1000 | Loss: 0.00001375
Iteration 70/1000 | Loss: 0.00001373
Iteration 71/1000 | Loss: 0.00001373
Iteration 72/1000 | Loss: 0.00001373
Iteration 73/1000 | Loss: 0.00001372
Iteration 74/1000 | Loss: 0.00001372
Iteration 75/1000 | Loss: 0.00001370
Iteration 76/1000 | Loss: 0.00001370
Iteration 77/1000 | Loss: 0.00001370
Iteration 78/1000 | Loss: 0.00001370
Iteration 79/1000 | Loss: 0.00001370
Iteration 80/1000 | Loss: 0.00001370
Iteration 81/1000 | Loss: 0.00001370
Iteration 82/1000 | Loss: 0.00001370
Iteration 83/1000 | Loss: 0.00001369
Iteration 84/1000 | Loss: 0.00001369
Iteration 85/1000 | Loss: 0.00001369
Iteration 86/1000 | Loss: 0.00001369
Iteration 87/1000 | Loss: 0.00001369
Iteration 88/1000 | Loss: 0.00001369
Iteration 89/1000 | Loss: 0.00001369
Iteration 90/1000 | Loss: 0.00001369
Iteration 91/1000 | Loss: 0.00001369
Iteration 92/1000 | Loss: 0.00001368
Iteration 93/1000 | Loss: 0.00001368
Iteration 94/1000 | Loss: 0.00001367
Iteration 95/1000 | Loss: 0.00001367
Iteration 96/1000 | Loss: 0.00001367
Iteration 97/1000 | Loss: 0.00001367
Iteration 98/1000 | Loss: 0.00001367
Iteration 99/1000 | Loss: 0.00001367
Iteration 100/1000 | Loss: 0.00001367
Iteration 101/1000 | Loss: 0.00001367
Iteration 102/1000 | Loss: 0.00001367
Iteration 103/1000 | Loss: 0.00001366
Iteration 104/1000 | Loss: 0.00001366
Iteration 105/1000 | Loss: 0.00001366
Iteration 106/1000 | Loss: 0.00001366
Iteration 107/1000 | Loss: 0.00001366
Iteration 108/1000 | Loss: 0.00001365
Iteration 109/1000 | Loss: 0.00001365
Iteration 110/1000 | Loss: 0.00001365
Iteration 111/1000 | Loss: 0.00001365
Iteration 112/1000 | Loss: 0.00001364
Iteration 113/1000 | Loss: 0.00001364
Iteration 114/1000 | Loss: 0.00001364
Iteration 115/1000 | Loss: 0.00001364
Iteration 116/1000 | Loss: 0.00001364
Iteration 117/1000 | Loss: 0.00001364
Iteration 118/1000 | Loss: 0.00001364
Iteration 119/1000 | Loss: 0.00001364
Iteration 120/1000 | Loss: 0.00001364
Iteration 121/1000 | Loss: 0.00001364
Iteration 122/1000 | Loss: 0.00001364
Iteration 123/1000 | Loss: 0.00001364
Iteration 124/1000 | Loss: 0.00001363
Iteration 125/1000 | Loss: 0.00001363
Iteration 126/1000 | Loss: 0.00001363
Iteration 127/1000 | Loss: 0.00001363
Iteration 128/1000 | Loss: 0.00001363
Iteration 129/1000 | Loss: 0.00001363
Iteration 130/1000 | Loss: 0.00001363
Iteration 131/1000 | Loss: 0.00001363
Iteration 132/1000 | Loss: 0.00001363
Iteration 133/1000 | Loss: 0.00001363
Iteration 134/1000 | Loss: 0.00001363
Iteration 135/1000 | Loss: 0.00001363
Iteration 136/1000 | Loss: 0.00001363
Iteration 137/1000 | Loss: 0.00001363
Iteration 138/1000 | Loss: 0.00001363
Iteration 139/1000 | Loss: 0.00001363
Iteration 140/1000 | Loss: 0.00001363
Iteration 141/1000 | Loss: 0.00001363
Iteration 142/1000 | Loss: 0.00001363
Iteration 143/1000 | Loss: 0.00001363
Iteration 144/1000 | Loss: 0.00001363
Iteration 145/1000 | Loss: 0.00001363
Iteration 146/1000 | Loss: 0.00001363
Iteration 147/1000 | Loss: 0.00001363
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 147. Stopping optimization.
Last 5 losses: [1.3627073712996207e-05, 1.3627073712996207e-05, 1.3627073712996207e-05, 1.3627073712996207e-05, 1.3627073712996207e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3627073712996207e-05

Optimization complete. Final v2v error: 3.128925085067749 mm

Highest mean error: 3.513897657394409 mm for frame 84

Lowest mean error: 2.909470558166504 mm for frame 20

Saving results

Total time: 36.94168448448181
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1096
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00647166
Iteration 2/25 | Loss: 0.00124182
Iteration 3/25 | Loss: 0.00098565
Iteration 4/25 | Loss: 0.00094813
Iteration 5/25 | Loss: 0.00092536
Iteration 6/25 | Loss: 0.00092887
Iteration 7/25 | Loss: 0.00091420
Iteration 8/25 | Loss: 0.00091340
Iteration 9/25 | Loss: 0.00091319
Iteration 10/25 | Loss: 0.00091308
Iteration 11/25 | Loss: 0.00091303
Iteration 12/25 | Loss: 0.00091303
Iteration 13/25 | Loss: 0.00091303
Iteration 14/25 | Loss: 0.00091302
Iteration 15/25 | Loss: 0.00091302
Iteration 16/25 | Loss: 0.00091302
Iteration 17/25 | Loss: 0.00091302
Iteration 18/25 | Loss: 0.00091302
Iteration 19/25 | Loss: 0.00091302
Iteration 20/25 | Loss: 0.00091302
Iteration 21/25 | Loss: 0.00091302
Iteration 22/25 | Loss: 0.00091302
Iteration 23/25 | Loss: 0.00091302
Iteration 24/25 | Loss: 0.00091302
Iteration 25/25 | Loss: 0.00091301

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80807388
Iteration 2/25 | Loss: 0.00093212
Iteration 3/25 | Loss: 0.00093212
Iteration 4/25 | Loss: 0.00093211
Iteration 5/25 | Loss: 0.00093211
Iteration 6/25 | Loss: 0.00093211
Iteration 7/25 | Loss: 0.00093211
Iteration 8/25 | Loss: 0.00093211
Iteration 9/25 | Loss: 0.00093211
Iteration 10/25 | Loss: 0.00093211
Iteration 11/25 | Loss: 0.00093211
Iteration 12/25 | Loss: 0.00093211
Iteration 13/25 | Loss: 0.00093211
Iteration 14/25 | Loss: 0.00093211
Iteration 15/25 | Loss: 0.00093211
Iteration 16/25 | Loss: 0.00093211
Iteration 17/25 | Loss: 0.00093211
Iteration 18/25 | Loss: 0.00093211
Iteration 19/25 | Loss: 0.00093211
Iteration 20/25 | Loss: 0.00093211
Iteration 21/25 | Loss: 0.00093211
Iteration 22/25 | Loss: 0.00093211
Iteration 23/25 | Loss: 0.00093211
Iteration 24/25 | Loss: 0.00093211
Iteration 25/25 | Loss: 0.00093211

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00093211
Iteration 2/1000 | Loss: 0.00010624
Iteration 3/1000 | Loss: 0.00010846
Iteration 4/1000 | Loss: 0.00005901
Iteration 5/1000 | Loss: 0.00004520
Iteration 6/1000 | Loss: 0.00004010
Iteration 7/1000 | Loss: 0.00003741
Iteration 8/1000 | Loss: 0.00034341
Iteration 9/1000 | Loss: 0.00065994
Iteration 10/1000 | Loss: 0.00015269
Iteration 11/1000 | Loss: 0.00011774
Iteration 12/1000 | Loss: 0.00003573
Iteration 13/1000 | Loss: 0.00003306
Iteration 14/1000 | Loss: 0.00003116
Iteration 15/1000 | Loss: 0.00003029
Iteration 16/1000 | Loss: 0.00002960
Iteration 17/1000 | Loss: 0.00002895
Iteration 18/1000 | Loss: 0.00002847
Iteration 19/1000 | Loss: 0.00002810
Iteration 20/1000 | Loss: 0.00002789
Iteration 21/1000 | Loss: 0.00002768
Iteration 22/1000 | Loss: 0.00002763
Iteration 23/1000 | Loss: 0.00002740
Iteration 24/1000 | Loss: 0.00002722
Iteration 25/1000 | Loss: 0.00002704
Iteration 26/1000 | Loss: 0.00002687
Iteration 27/1000 | Loss: 0.00002682
Iteration 28/1000 | Loss: 0.00002680
Iteration 29/1000 | Loss: 0.00002679
Iteration 30/1000 | Loss: 0.00044185
Iteration 31/1000 | Loss: 0.00003812
Iteration 32/1000 | Loss: 0.00003294
Iteration 33/1000 | Loss: 0.00003157
Iteration 34/1000 | Loss: 0.00005001
Iteration 35/1000 | Loss: 0.00003901
Iteration 36/1000 | Loss: 0.00003089
Iteration 37/1000 | Loss: 0.00002765
Iteration 38/1000 | Loss: 0.00002662
Iteration 39/1000 | Loss: 0.00002623
Iteration 40/1000 | Loss: 0.00002599
Iteration 41/1000 | Loss: 0.00002585
Iteration 42/1000 | Loss: 0.00002580
Iteration 43/1000 | Loss: 0.00002560
Iteration 44/1000 | Loss: 0.00002551
Iteration 45/1000 | Loss: 0.00002550
Iteration 46/1000 | Loss: 0.00002546
Iteration 47/1000 | Loss: 0.00002541
Iteration 48/1000 | Loss: 0.00002541
Iteration 49/1000 | Loss: 0.00002540
Iteration 50/1000 | Loss: 0.00002536
Iteration 51/1000 | Loss: 0.00002533
Iteration 52/1000 | Loss: 0.00002533
Iteration 53/1000 | Loss: 0.00002533
Iteration 54/1000 | Loss: 0.00002528
Iteration 55/1000 | Loss: 0.00002527
Iteration 56/1000 | Loss: 0.00002527
Iteration 57/1000 | Loss: 0.00002524
Iteration 58/1000 | Loss: 0.00002523
Iteration 59/1000 | Loss: 0.00002522
Iteration 60/1000 | Loss: 0.00002522
Iteration 61/1000 | Loss: 0.00002522
Iteration 62/1000 | Loss: 0.00002521
Iteration 63/1000 | Loss: 0.00002521
Iteration 64/1000 | Loss: 0.00002521
Iteration 65/1000 | Loss: 0.00002520
Iteration 66/1000 | Loss: 0.00002520
Iteration 67/1000 | Loss: 0.00002520
Iteration 68/1000 | Loss: 0.00002520
Iteration 69/1000 | Loss: 0.00002519
Iteration 70/1000 | Loss: 0.00002519
Iteration 71/1000 | Loss: 0.00002519
Iteration 72/1000 | Loss: 0.00002518
Iteration 73/1000 | Loss: 0.00002518
Iteration 74/1000 | Loss: 0.00002518
Iteration 75/1000 | Loss: 0.00002518
Iteration 76/1000 | Loss: 0.00002517
Iteration 77/1000 | Loss: 0.00002517
Iteration 78/1000 | Loss: 0.00002517
Iteration 79/1000 | Loss: 0.00002517
Iteration 80/1000 | Loss: 0.00002516
Iteration 81/1000 | Loss: 0.00002516
Iteration 82/1000 | Loss: 0.00002516
Iteration 83/1000 | Loss: 0.00002516
Iteration 84/1000 | Loss: 0.00002515
Iteration 85/1000 | Loss: 0.00002515
Iteration 86/1000 | Loss: 0.00002515
Iteration 87/1000 | Loss: 0.00002515
Iteration 88/1000 | Loss: 0.00002515
Iteration 89/1000 | Loss: 0.00002515
Iteration 90/1000 | Loss: 0.00002515
Iteration 91/1000 | Loss: 0.00002515
Iteration 92/1000 | Loss: 0.00002514
Iteration 93/1000 | Loss: 0.00002514
Iteration 94/1000 | Loss: 0.00002514
Iteration 95/1000 | Loss: 0.00002514
Iteration 96/1000 | Loss: 0.00002514
Iteration 97/1000 | Loss: 0.00002514
Iteration 98/1000 | Loss: 0.00002514
Iteration 99/1000 | Loss: 0.00002514
Iteration 100/1000 | Loss: 0.00002513
Iteration 101/1000 | Loss: 0.00002513
Iteration 102/1000 | Loss: 0.00002513
Iteration 103/1000 | Loss: 0.00002513
Iteration 104/1000 | Loss: 0.00002513
Iteration 105/1000 | Loss: 0.00002513
Iteration 106/1000 | Loss: 0.00002513
Iteration 107/1000 | Loss: 0.00002513
Iteration 108/1000 | Loss: 0.00002513
Iteration 109/1000 | Loss: 0.00002513
Iteration 110/1000 | Loss: 0.00002513
Iteration 111/1000 | Loss: 0.00002513
Iteration 112/1000 | Loss: 0.00002513
Iteration 113/1000 | Loss: 0.00002513
Iteration 114/1000 | Loss: 0.00002513
Iteration 115/1000 | Loss: 0.00002513
Iteration 116/1000 | Loss: 0.00002513
Iteration 117/1000 | Loss: 0.00002513
Iteration 118/1000 | Loss: 0.00002513
Iteration 119/1000 | Loss: 0.00002513
Iteration 120/1000 | Loss: 0.00002513
Iteration 121/1000 | Loss: 0.00002513
Iteration 122/1000 | Loss: 0.00002513
Iteration 123/1000 | Loss: 0.00002513
Iteration 124/1000 | Loss: 0.00002513
Iteration 125/1000 | Loss: 0.00002513
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [2.513000617909711e-05, 2.513000617909711e-05, 2.513000617909711e-05, 2.513000617909711e-05, 2.513000617909711e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.513000617909711e-05

Optimization complete. Final v2v error: 4.230310440063477 mm

Highest mean error: 5.621382236480713 mm for frame 63

Lowest mean error: 3.555438995361328 mm for frame 73

Saving results

Total time: 81.43424940109253
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00786417
Iteration 2/25 | Loss: 0.00128468
Iteration 3/25 | Loss: 0.00106015
Iteration 4/25 | Loss: 0.00099314
Iteration 5/25 | Loss: 0.00096511
Iteration 6/25 | Loss: 0.00096285
Iteration 7/25 | Loss: 0.00095743
Iteration 8/25 | Loss: 0.00095567
Iteration 9/25 | Loss: 0.00095514
Iteration 10/25 | Loss: 0.00095502
Iteration 11/25 | Loss: 0.00095501
Iteration 12/25 | Loss: 0.00095500
Iteration 13/25 | Loss: 0.00095500
Iteration 14/25 | Loss: 0.00095500
Iteration 15/25 | Loss: 0.00095500
Iteration 16/25 | Loss: 0.00095500
Iteration 17/25 | Loss: 0.00095500
Iteration 18/25 | Loss: 0.00095500
Iteration 19/25 | Loss: 0.00095500
Iteration 20/25 | Loss: 0.00095500
Iteration 21/25 | Loss: 0.00095500
Iteration 22/25 | Loss: 0.00095499
Iteration 23/25 | Loss: 0.00095499
Iteration 24/25 | Loss: 0.00095499
Iteration 25/25 | Loss: 0.00095499

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.00990319
Iteration 2/25 | Loss: 0.00077419
Iteration 3/25 | Loss: 0.00077401
Iteration 4/25 | Loss: 0.00077400
Iteration 5/25 | Loss: 0.00077400
Iteration 6/25 | Loss: 0.00077400
Iteration 7/25 | Loss: 0.00077400
Iteration 8/25 | Loss: 0.00077400
Iteration 9/25 | Loss: 0.00077400
Iteration 10/25 | Loss: 0.00077400
Iteration 11/25 | Loss: 0.00077400
Iteration 12/25 | Loss: 0.00077400
Iteration 13/25 | Loss: 0.00077400
Iteration 14/25 | Loss: 0.00077400
Iteration 15/25 | Loss: 0.00077400
Iteration 16/25 | Loss: 0.00077400
Iteration 17/25 | Loss: 0.00077400
Iteration 18/25 | Loss: 0.00077400
Iteration 19/25 | Loss: 0.00077400
Iteration 20/25 | Loss: 0.00077400
Iteration 21/25 | Loss: 0.00077400
Iteration 22/25 | Loss: 0.00077400
Iteration 23/25 | Loss: 0.00077400
Iteration 24/25 | Loss: 0.00077400
Iteration 25/25 | Loss: 0.00077400

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00077400
Iteration 2/1000 | Loss: 0.00007317
Iteration 3/1000 | Loss: 0.00005017
Iteration 4/1000 | Loss: 0.00004330
Iteration 5/1000 | Loss: 0.00004015
Iteration 6/1000 | Loss: 0.00003817
Iteration 7/1000 | Loss: 0.00003678
Iteration 8/1000 | Loss: 0.00003574
Iteration 9/1000 | Loss: 0.00003490
Iteration 10/1000 | Loss: 0.00003430
Iteration 11/1000 | Loss: 0.00003385
Iteration 12/1000 | Loss: 0.00003347
Iteration 13/1000 | Loss: 0.00003312
Iteration 14/1000 | Loss: 0.00003285
Iteration 15/1000 | Loss: 0.00003261
Iteration 16/1000 | Loss: 0.00003240
Iteration 17/1000 | Loss: 0.00003223
Iteration 18/1000 | Loss: 0.00019182
Iteration 19/1000 | Loss: 0.00003200
Iteration 20/1000 | Loss: 0.00003146
Iteration 21/1000 | Loss: 0.00003097
Iteration 22/1000 | Loss: 0.00003061
Iteration 23/1000 | Loss: 0.00003030
Iteration 24/1000 | Loss: 0.00003013
Iteration 25/1000 | Loss: 0.00003006
Iteration 26/1000 | Loss: 0.00002999
Iteration 27/1000 | Loss: 0.00002998
Iteration 28/1000 | Loss: 0.00002996
Iteration 29/1000 | Loss: 0.00002996
Iteration 30/1000 | Loss: 0.00002996
Iteration 31/1000 | Loss: 0.00002995
Iteration 32/1000 | Loss: 0.00002995
Iteration 33/1000 | Loss: 0.00002994
Iteration 34/1000 | Loss: 0.00002992
Iteration 35/1000 | Loss: 0.00002992
Iteration 36/1000 | Loss: 0.00002991
Iteration 37/1000 | Loss: 0.00002991
Iteration 38/1000 | Loss: 0.00002991
Iteration 39/1000 | Loss: 0.00002988
Iteration 40/1000 | Loss: 0.00002988
Iteration 41/1000 | Loss: 0.00002988
Iteration 42/1000 | Loss: 0.00002987
Iteration 43/1000 | Loss: 0.00002986
Iteration 44/1000 | Loss: 0.00002986
Iteration 45/1000 | Loss: 0.00002986
Iteration 46/1000 | Loss: 0.00002986
Iteration 47/1000 | Loss: 0.00002986
Iteration 48/1000 | Loss: 0.00002986
Iteration 49/1000 | Loss: 0.00002986
Iteration 50/1000 | Loss: 0.00002985
Iteration 51/1000 | Loss: 0.00002985
Iteration 52/1000 | Loss: 0.00002985
Iteration 53/1000 | Loss: 0.00002985
Iteration 54/1000 | Loss: 0.00002985
Iteration 55/1000 | Loss: 0.00002985
Iteration 56/1000 | Loss: 0.00002984
Iteration 57/1000 | Loss: 0.00002984
Iteration 58/1000 | Loss: 0.00002984
Iteration 59/1000 | Loss: 0.00002984
Iteration 60/1000 | Loss: 0.00002984
Iteration 61/1000 | Loss: 0.00002983
Iteration 62/1000 | Loss: 0.00002983
Iteration 63/1000 | Loss: 0.00002983
Iteration 64/1000 | Loss: 0.00002983
Iteration 65/1000 | Loss: 0.00002983
Iteration 66/1000 | Loss: 0.00002983
Iteration 67/1000 | Loss: 0.00002983
Iteration 68/1000 | Loss: 0.00002983
Iteration 69/1000 | Loss: 0.00002982
Iteration 70/1000 | Loss: 0.00002982
Iteration 71/1000 | Loss: 0.00002982
Iteration 72/1000 | Loss: 0.00002982
Iteration 73/1000 | Loss: 0.00002981
Iteration 74/1000 | Loss: 0.00002981
Iteration 75/1000 | Loss: 0.00002981
Iteration 76/1000 | Loss: 0.00002980
Iteration 77/1000 | Loss: 0.00002980
Iteration 78/1000 | Loss: 0.00002980
Iteration 79/1000 | Loss: 0.00002980
Iteration 80/1000 | Loss: 0.00002979
Iteration 81/1000 | Loss: 0.00002979
Iteration 82/1000 | Loss: 0.00002979
Iteration 83/1000 | Loss: 0.00002979
Iteration 84/1000 | Loss: 0.00002978
Iteration 85/1000 | Loss: 0.00002978
Iteration 86/1000 | Loss: 0.00002978
Iteration 87/1000 | Loss: 0.00002978
Iteration 88/1000 | Loss: 0.00002978
Iteration 89/1000 | Loss: 0.00002978
Iteration 90/1000 | Loss: 0.00002978
Iteration 91/1000 | Loss: 0.00002977
Iteration 92/1000 | Loss: 0.00002977
Iteration 93/1000 | Loss: 0.00002977
Iteration 94/1000 | Loss: 0.00002977
Iteration 95/1000 | Loss: 0.00002977
Iteration 96/1000 | Loss: 0.00002977
Iteration 97/1000 | Loss: 0.00002977
Iteration 98/1000 | Loss: 0.00002977
Iteration 99/1000 | Loss: 0.00002976
Iteration 100/1000 | Loss: 0.00002976
Iteration 101/1000 | Loss: 0.00002976
Iteration 102/1000 | Loss: 0.00002976
Iteration 103/1000 | Loss: 0.00002975
Iteration 104/1000 | Loss: 0.00002975
Iteration 105/1000 | Loss: 0.00002975
Iteration 106/1000 | Loss: 0.00002975
Iteration 107/1000 | Loss: 0.00002975
Iteration 108/1000 | Loss: 0.00002975
Iteration 109/1000 | Loss: 0.00002975
Iteration 110/1000 | Loss: 0.00002975
Iteration 111/1000 | Loss: 0.00002974
Iteration 112/1000 | Loss: 0.00002974
Iteration 113/1000 | Loss: 0.00002974
Iteration 114/1000 | Loss: 0.00002974
Iteration 115/1000 | Loss: 0.00002974
Iteration 116/1000 | Loss: 0.00002974
Iteration 117/1000 | Loss: 0.00002974
Iteration 118/1000 | Loss: 0.00002974
Iteration 119/1000 | Loss: 0.00002974
Iteration 120/1000 | Loss: 0.00002974
Iteration 121/1000 | Loss: 0.00002974
Iteration 122/1000 | Loss: 0.00002974
Iteration 123/1000 | Loss: 0.00002973
Iteration 124/1000 | Loss: 0.00002973
Iteration 125/1000 | Loss: 0.00002973
Iteration 126/1000 | Loss: 0.00002973
Iteration 127/1000 | Loss: 0.00002973
Iteration 128/1000 | Loss: 0.00002973
Iteration 129/1000 | Loss: 0.00002973
Iteration 130/1000 | Loss: 0.00002973
Iteration 131/1000 | Loss: 0.00002972
Iteration 132/1000 | Loss: 0.00002972
Iteration 133/1000 | Loss: 0.00002972
Iteration 134/1000 | Loss: 0.00002972
Iteration 135/1000 | Loss: 0.00002972
Iteration 136/1000 | Loss: 0.00002972
Iteration 137/1000 | Loss: 0.00002972
Iteration 138/1000 | Loss: 0.00002972
Iteration 139/1000 | Loss: 0.00002972
Iteration 140/1000 | Loss: 0.00002972
Iteration 141/1000 | Loss: 0.00002972
Iteration 142/1000 | Loss: 0.00002972
Iteration 143/1000 | Loss: 0.00002972
Iteration 144/1000 | Loss: 0.00002972
Iteration 145/1000 | Loss: 0.00002972
Iteration 146/1000 | Loss: 0.00002972
Iteration 147/1000 | Loss: 0.00002972
Iteration 148/1000 | Loss: 0.00002972
Iteration 149/1000 | Loss: 0.00002972
Iteration 150/1000 | Loss: 0.00002972
Iteration 151/1000 | Loss: 0.00002972
Iteration 152/1000 | Loss: 0.00002972
Iteration 153/1000 | Loss: 0.00002972
Iteration 154/1000 | Loss: 0.00002972
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [2.9718299629166722e-05, 2.9718299629166722e-05, 2.9718299629166722e-05, 2.9718299629166722e-05, 2.9718299629166722e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9718299629166722e-05

Optimization complete. Final v2v error: 4.497516632080078 mm

Highest mean error: 6.325551509857178 mm for frame 106

Lowest mean error: 3.413957357406616 mm for frame 230

Saving results

Total time: 71.20074009895325
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1097/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1097.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1097
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00790283
Iteration 2/25 | Loss: 0.00131227
Iteration 3/25 | Loss: 0.00091666
Iteration 4/25 | Loss: 0.00087968
Iteration 5/25 | Loss: 0.00085683
Iteration 6/25 | Loss: 0.00085125
Iteration 7/25 | Loss: 0.00085154
Iteration 8/25 | Loss: 0.00085018
Iteration 9/25 | Loss: 0.00085006
Iteration 10/25 | Loss: 0.00084999
Iteration 11/25 | Loss: 0.00084999
Iteration 12/25 | Loss: 0.00084999
Iteration 13/25 | Loss: 0.00084999
Iteration 14/25 | Loss: 0.00084999
Iteration 15/25 | Loss: 0.00084999
Iteration 16/25 | Loss: 0.00084999
Iteration 17/25 | Loss: 0.00084999
Iteration 18/25 | Loss: 0.00084999
Iteration 19/25 | Loss: 0.00084999
Iteration 20/25 | Loss: 0.00084998
Iteration 21/25 | Loss: 0.00084998
Iteration 22/25 | Loss: 0.00084997
Iteration 23/25 | Loss: 0.00084997
Iteration 24/25 | Loss: 0.00084997
Iteration 25/25 | Loss: 0.00084997

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.84314585
Iteration 2/25 | Loss: 0.00067762
Iteration 3/25 | Loss: 0.00068228
Iteration 4/25 | Loss: 0.00067761
Iteration 5/25 | Loss: 0.00067760
Iteration 6/25 | Loss: 0.00067760
Iteration 7/25 | Loss: 0.00067760
Iteration 8/25 | Loss: 0.00067760
Iteration 9/25 | Loss: 0.00067760
Iteration 10/25 | Loss: 0.00067760
Iteration 11/25 | Loss: 0.00067760
Iteration 12/25 | Loss: 0.00067760
Iteration 13/25 | Loss: 0.00067760
Iteration 14/25 | Loss: 0.00067760
Iteration 15/25 | Loss: 0.00067760
Iteration 16/25 | Loss: 0.00067760
Iteration 17/25 | Loss: 0.00067760
Iteration 18/25 | Loss: 0.00067760
Iteration 19/25 | Loss: 0.00067760
Iteration 20/25 | Loss: 0.00067760
Iteration 21/25 | Loss: 0.00067760
Iteration 22/25 | Loss: 0.00067760
Iteration 23/25 | Loss: 0.00067760
Iteration 24/25 | Loss: 0.00067760
Iteration 25/25 | Loss: 0.00067760

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00067760
Iteration 2/1000 | Loss: 0.00002644
Iteration 3/1000 | Loss: 0.00002817
Iteration 4/1000 | Loss: 0.00001808
Iteration 5/1000 | Loss: 0.00002376
Iteration 6/1000 | Loss: 0.00001633
Iteration 7/1000 | Loss: 0.00001861
Iteration 8/1000 | Loss: 0.00001676
Iteration 9/1000 | Loss: 0.00001545
Iteration 10/1000 | Loss: 0.00001708
Iteration 11/1000 | Loss: 0.00001516
Iteration 12/1000 | Loss: 0.00001515
Iteration 13/1000 | Loss: 0.00001514
Iteration 14/1000 | Loss: 0.00001514
Iteration 15/1000 | Loss: 0.00001509
Iteration 16/1000 | Loss: 0.00001690
Iteration 17/1000 | Loss: 0.00001488
Iteration 18/1000 | Loss: 0.00001488
Iteration 19/1000 | Loss: 0.00001488
Iteration 20/1000 | Loss: 0.00001488
Iteration 21/1000 | Loss: 0.00001488
Iteration 22/1000 | Loss: 0.00001488
Iteration 23/1000 | Loss: 0.00001487
Iteration 24/1000 | Loss: 0.00001487
Iteration 25/1000 | Loss: 0.00001487
Iteration 26/1000 | Loss: 0.00001476
Iteration 27/1000 | Loss: 0.00001474
Iteration 28/1000 | Loss: 0.00001474
Iteration 29/1000 | Loss: 0.00001474
Iteration 30/1000 | Loss: 0.00001473
Iteration 31/1000 | Loss: 0.00001473
Iteration 32/1000 | Loss: 0.00001473
Iteration 33/1000 | Loss: 0.00001472
Iteration 34/1000 | Loss: 0.00001472
Iteration 35/1000 | Loss: 0.00001470
Iteration 36/1000 | Loss: 0.00001469
Iteration 37/1000 | Loss: 0.00001467
Iteration 38/1000 | Loss: 0.00001467
Iteration 39/1000 | Loss: 0.00001467
Iteration 40/1000 | Loss: 0.00001466
Iteration 41/1000 | Loss: 0.00001466
Iteration 42/1000 | Loss: 0.00001464
Iteration 43/1000 | Loss: 0.00001464
Iteration 44/1000 | Loss: 0.00001464
Iteration 45/1000 | Loss: 0.00001463
Iteration 46/1000 | Loss: 0.00001463
Iteration 47/1000 | Loss: 0.00001463
Iteration 48/1000 | Loss: 0.00001462
Iteration 49/1000 | Loss: 0.00001462
Iteration 50/1000 | Loss: 0.00001462
Iteration 51/1000 | Loss: 0.00001462
Iteration 52/1000 | Loss: 0.00001461
Iteration 53/1000 | Loss: 0.00001461
Iteration 54/1000 | Loss: 0.00001461
Iteration 55/1000 | Loss: 0.00001856
Iteration 56/1000 | Loss: 0.00001481
Iteration 57/1000 | Loss: 0.00001458
Iteration 58/1000 | Loss: 0.00001457
Iteration 59/1000 | Loss: 0.00001457
Iteration 60/1000 | Loss: 0.00001457
Iteration 61/1000 | Loss: 0.00001457
Iteration 62/1000 | Loss: 0.00001457
Iteration 63/1000 | Loss: 0.00001456
Iteration 64/1000 | Loss: 0.00001456
Iteration 65/1000 | Loss: 0.00001456
Iteration 66/1000 | Loss: 0.00001456
Iteration 67/1000 | Loss: 0.00001456
Iteration 68/1000 | Loss: 0.00001456
Iteration 69/1000 | Loss: 0.00001456
Iteration 70/1000 | Loss: 0.00001456
Iteration 71/1000 | Loss: 0.00001456
Iteration 72/1000 | Loss: 0.00001456
Iteration 73/1000 | Loss: 0.00001456
Iteration 74/1000 | Loss: 0.00001456
Iteration 75/1000 | Loss: 0.00001455
Iteration 76/1000 | Loss: 0.00001455
Iteration 77/1000 | Loss: 0.00001501
Iteration 78/1000 | Loss: 0.00001453
Iteration 79/1000 | Loss: 0.00001453
Iteration 80/1000 | Loss: 0.00001823
Iteration 81/1000 | Loss: 0.00001485
Iteration 82/1000 | Loss: 0.00001451
Iteration 83/1000 | Loss: 0.00001451
Iteration 84/1000 | Loss: 0.00001450
Iteration 85/1000 | Loss: 0.00001450
Iteration 86/1000 | Loss: 0.00001450
Iteration 87/1000 | Loss: 0.00001450
Iteration 88/1000 | Loss: 0.00001450
Iteration 89/1000 | Loss: 0.00001450
Iteration 90/1000 | Loss: 0.00001450
Iteration 91/1000 | Loss: 0.00001450
Iteration 92/1000 | Loss: 0.00001450
Iteration 93/1000 | Loss: 0.00001450
Iteration 94/1000 | Loss: 0.00001450
Iteration 95/1000 | Loss: 0.00001450
Iteration 96/1000 | Loss: 0.00001450
Iteration 97/1000 | Loss: 0.00001450
Iteration 98/1000 | Loss: 0.00001450
Iteration 99/1000 | Loss: 0.00001450
Iteration 100/1000 | Loss: 0.00001450
Iteration 101/1000 | Loss: 0.00001450
Iteration 102/1000 | Loss: 0.00001450
Iteration 103/1000 | Loss: 0.00001450
Iteration 104/1000 | Loss: 0.00001450
Iteration 105/1000 | Loss: 0.00001450
Iteration 106/1000 | Loss: 0.00001450
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.4499990356853232e-05, 1.4499990356853232e-05, 1.4499990356853232e-05, 1.4499990356853232e-05, 1.4499990356853232e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4499990356853232e-05

Optimization complete. Final v2v error: 3.2107527256011963 mm

Highest mean error: 3.5918004512786865 mm for frame 230

Lowest mean error: 2.899895429611206 mm for frame 32

Saving results

Total time: 51.227508306503296
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00871813
Iteration 2/25 | Loss: 0.00162701
Iteration 3/25 | Loss: 0.00126744
Iteration 4/25 | Loss: 0.00121070
Iteration 5/25 | Loss: 0.00119303
Iteration 6/25 | Loss: 0.00119271
Iteration 7/25 | Loss: 0.00118512
Iteration 8/25 | Loss: 0.00119422
Iteration 9/25 | Loss: 0.00118577
Iteration 10/25 | Loss: 0.00117667
Iteration 11/25 | Loss: 0.00117154
Iteration 12/25 | Loss: 0.00117017
Iteration 13/25 | Loss: 0.00117050
Iteration 14/25 | Loss: 0.00116913
Iteration 15/25 | Loss: 0.00116236
Iteration 16/25 | Loss: 0.00115956
Iteration 17/25 | Loss: 0.00116364
Iteration 18/25 | Loss: 0.00116285
Iteration 19/25 | Loss: 0.00115141
Iteration 20/25 | Loss: 0.00114871
Iteration 21/25 | Loss: 0.00114800
Iteration 22/25 | Loss: 0.00114765
Iteration 23/25 | Loss: 0.00114750
Iteration 24/25 | Loss: 0.00114749
Iteration 25/25 | Loss: 0.00114749

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45994639
Iteration 2/25 | Loss: 0.00236087
Iteration 3/25 | Loss: 0.00236081
Iteration 4/25 | Loss: 0.00236081
Iteration 5/25 | Loss: 0.00236081
Iteration 6/25 | Loss: 0.00236081
Iteration 7/25 | Loss: 0.00236081
Iteration 8/25 | Loss: 0.00236081
Iteration 9/25 | Loss: 0.00236081
Iteration 10/25 | Loss: 0.00236081
Iteration 11/25 | Loss: 0.00236081
Iteration 12/25 | Loss: 0.00236081
Iteration 13/25 | Loss: 0.00236081
Iteration 14/25 | Loss: 0.00236081
Iteration 15/25 | Loss: 0.00236081
Iteration 16/25 | Loss: 0.00236081
Iteration 17/25 | Loss: 0.00236081
Iteration 18/25 | Loss: 0.00236081
Iteration 19/25 | Loss: 0.00236081
Iteration 20/25 | Loss: 0.00236081
Iteration 21/25 | Loss: 0.00236081
Iteration 22/25 | Loss: 0.00236081
Iteration 23/25 | Loss: 0.00236081
Iteration 24/25 | Loss: 0.00236081
Iteration 25/25 | Loss: 0.00236081

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00236081
Iteration 2/1000 | Loss: 0.00040906
Iteration 3/1000 | Loss: 0.00029992
Iteration 4/1000 | Loss: 0.00024910
Iteration 5/1000 | Loss: 0.00043946
Iteration 6/1000 | Loss: 0.00027637
Iteration 7/1000 | Loss: 0.00017367
Iteration 8/1000 | Loss: 0.00148028
Iteration 9/1000 | Loss: 0.00180760
Iteration 10/1000 | Loss: 0.00040127
Iteration 11/1000 | Loss: 0.00015367
Iteration 12/1000 | Loss: 0.00013585
Iteration 13/1000 | Loss: 0.00012501
Iteration 14/1000 | Loss: 0.00011727
Iteration 15/1000 | Loss: 0.00085431
Iteration 16/1000 | Loss: 0.00011609
Iteration 17/1000 | Loss: 0.00010856
Iteration 18/1000 | Loss: 0.00010475
Iteration 19/1000 | Loss: 0.00010091
Iteration 20/1000 | Loss: 0.00009840
Iteration 21/1000 | Loss: 0.00074666
Iteration 22/1000 | Loss: 0.00009921
Iteration 23/1000 | Loss: 0.00009371
Iteration 24/1000 | Loss: 0.00108540
Iteration 25/1000 | Loss: 0.00009040
Iteration 26/1000 | Loss: 0.00214488
Iteration 27/1000 | Loss: 0.00416288
Iteration 28/1000 | Loss: 0.00222761
Iteration 29/1000 | Loss: 0.00009801
Iteration 30/1000 | Loss: 0.00008105
Iteration 31/1000 | Loss: 0.00007239
Iteration 32/1000 | Loss: 0.00108312
Iteration 33/1000 | Loss: 0.00101868
Iteration 34/1000 | Loss: 0.00007007
Iteration 35/1000 | Loss: 0.00006134
Iteration 36/1000 | Loss: 0.00195031
Iteration 37/1000 | Loss: 0.00006492
Iteration 38/1000 | Loss: 0.00005587
Iteration 39/1000 | Loss: 0.00004966
Iteration 40/1000 | Loss: 0.00095676
Iteration 41/1000 | Loss: 0.00004747
Iteration 42/1000 | Loss: 0.00085134
Iteration 43/1000 | Loss: 0.00004664
Iteration 44/1000 | Loss: 0.00004184
Iteration 45/1000 | Loss: 0.00003820
Iteration 46/1000 | Loss: 0.00003571
Iteration 47/1000 | Loss: 0.00003360
Iteration 48/1000 | Loss: 0.00003213
Iteration 49/1000 | Loss: 0.00003148
Iteration 50/1000 | Loss: 0.00003094
Iteration 51/1000 | Loss: 0.00003042
Iteration 52/1000 | Loss: 0.00003004
Iteration 53/1000 | Loss: 0.00002967
Iteration 54/1000 | Loss: 0.00088505
Iteration 55/1000 | Loss: 0.00003435
Iteration 56/1000 | Loss: 0.00002918
Iteration 57/1000 | Loss: 0.00002791
Iteration 58/1000 | Loss: 0.00002720
Iteration 59/1000 | Loss: 0.00002649
Iteration 60/1000 | Loss: 0.00002612
Iteration 61/1000 | Loss: 0.00002585
Iteration 62/1000 | Loss: 0.00002581
Iteration 63/1000 | Loss: 0.00002567
Iteration 64/1000 | Loss: 0.00002554
Iteration 65/1000 | Loss: 0.00002553
Iteration 66/1000 | Loss: 0.00002552
Iteration 67/1000 | Loss: 0.00002551
Iteration 68/1000 | Loss: 0.00002550
Iteration 69/1000 | Loss: 0.00002550
Iteration 70/1000 | Loss: 0.00002549
Iteration 71/1000 | Loss: 0.00002548
Iteration 72/1000 | Loss: 0.00002547
Iteration 73/1000 | Loss: 0.00002547
Iteration 74/1000 | Loss: 0.00002546
Iteration 75/1000 | Loss: 0.00002546
Iteration 76/1000 | Loss: 0.00002544
Iteration 77/1000 | Loss: 0.00002544
Iteration 78/1000 | Loss: 0.00002544
Iteration 79/1000 | Loss: 0.00002543
Iteration 80/1000 | Loss: 0.00002543
Iteration 81/1000 | Loss: 0.00002543
Iteration 82/1000 | Loss: 0.00002543
Iteration 83/1000 | Loss: 0.00002542
Iteration 84/1000 | Loss: 0.00002541
Iteration 85/1000 | Loss: 0.00002541
Iteration 86/1000 | Loss: 0.00002541
Iteration 87/1000 | Loss: 0.00002539
Iteration 88/1000 | Loss: 0.00002538
Iteration 89/1000 | Loss: 0.00002538
Iteration 90/1000 | Loss: 0.00002537
Iteration 91/1000 | Loss: 0.00002536
Iteration 92/1000 | Loss: 0.00002536
Iteration 93/1000 | Loss: 0.00002535
Iteration 94/1000 | Loss: 0.00002535
Iteration 95/1000 | Loss: 0.00002535
Iteration 96/1000 | Loss: 0.00002534
Iteration 97/1000 | Loss: 0.00002534
Iteration 98/1000 | Loss: 0.00002534
Iteration 99/1000 | Loss: 0.00002534
Iteration 100/1000 | Loss: 0.00002533
Iteration 101/1000 | Loss: 0.00002533
Iteration 102/1000 | Loss: 0.00002533
Iteration 103/1000 | Loss: 0.00002533
Iteration 104/1000 | Loss: 0.00002533
Iteration 105/1000 | Loss: 0.00002533
Iteration 106/1000 | Loss: 0.00002533
Iteration 107/1000 | Loss: 0.00002533
Iteration 108/1000 | Loss: 0.00002532
Iteration 109/1000 | Loss: 0.00002532
Iteration 110/1000 | Loss: 0.00002532
Iteration 111/1000 | Loss: 0.00002532
Iteration 112/1000 | Loss: 0.00002532
Iteration 113/1000 | Loss: 0.00002532
Iteration 114/1000 | Loss: 0.00002532
Iteration 115/1000 | Loss: 0.00002531
Iteration 116/1000 | Loss: 0.00002531
Iteration 117/1000 | Loss: 0.00002531
Iteration 118/1000 | Loss: 0.00002531
Iteration 119/1000 | Loss: 0.00002531
Iteration 120/1000 | Loss: 0.00002531
Iteration 121/1000 | Loss: 0.00002531
Iteration 122/1000 | Loss: 0.00002531
Iteration 123/1000 | Loss: 0.00002531
Iteration 124/1000 | Loss: 0.00002531
Iteration 125/1000 | Loss: 0.00002531
Iteration 126/1000 | Loss: 0.00002530
Iteration 127/1000 | Loss: 0.00002530
Iteration 128/1000 | Loss: 0.00002530
Iteration 129/1000 | Loss: 0.00002530
Iteration 130/1000 | Loss: 0.00002530
Iteration 131/1000 | Loss: 0.00002530
Iteration 132/1000 | Loss: 0.00002530
Iteration 133/1000 | Loss: 0.00002530
Iteration 134/1000 | Loss: 0.00002530
Iteration 135/1000 | Loss: 0.00002530
Iteration 136/1000 | Loss: 0.00002529
Iteration 137/1000 | Loss: 0.00002529
Iteration 138/1000 | Loss: 0.00002529
Iteration 139/1000 | Loss: 0.00002529
Iteration 140/1000 | Loss: 0.00002529
Iteration 141/1000 | Loss: 0.00002529
Iteration 142/1000 | Loss: 0.00002529
Iteration 143/1000 | Loss: 0.00002528
Iteration 144/1000 | Loss: 0.00002528
Iteration 145/1000 | Loss: 0.00002528
Iteration 146/1000 | Loss: 0.00002528
Iteration 147/1000 | Loss: 0.00002528
Iteration 148/1000 | Loss: 0.00002527
Iteration 149/1000 | Loss: 0.00002527
Iteration 150/1000 | Loss: 0.00002527
Iteration 151/1000 | Loss: 0.00002527
Iteration 152/1000 | Loss: 0.00002527
Iteration 153/1000 | Loss: 0.00002526
Iteration 154/1000 | Loss: 0.00002526
Iteration 155/1000 | Loss: 0.00002526
Iteration 156/1000 | Loss: 0.00002526
Iteration 157/1000 | Loss: 0.00002526
Iteration 158/1000 | Loss: 0.00002526
Iteration 159/1000 | Loss: 0.00002526
Iteration 160/1000 | Loss: 0.00002526
Iteration 161/1000 | Loss: 0.00002526
Iteration 162/1000 | Loss: 0.00002526
Iteration 163/1000 | Loss: 0.00002526
Iteration 164/1000 | Loss: 0.00002525
Iteration 165/1000 | Loss: 0.00002525
Iteration 166/1000 | Loss: 0.00002525
Iteration 167/1000 | Loss: 0.00002525
Iteration 168/1000 | Loss: 0.00002525
Iteration 169/1000 | Loss: 0.00002525
Iteration 170/1000 | Loss: 0.00002524
Iteration 171/1000 | Loss: 0.00002524
Iteration 172/1000 | Loss: 0.00002524
Iteration 173/1000 | Loss: 0.00002524
Iteration 174/1000 | Loss: 0.00002524
Iteration 175/1000 | Loss: 0.00002524
Iteration 176/1000 | Loss: 0.00002523
Iteration 177/1000 | Loss: 0.00002523
Iteration 178/1000 | Loss: 0.00002523
Iteration 179/1000 | Loss: 0.00002523
Iteration 180/1000 | Loss: 0.00002523
Iteration 181/1000 | Loss: 0.00002523
Iteration 182/1000 | Loss: 0.00002523
Iteration 183/1000 | Loss: 0.00002523
Iteration 184/1000 | Loss: 0.00002523
Iteration 185/1000 | Loss: 0.00002523
Iteration 186/1000 | Loss: 0.00002523
Iteration 187/1000 | Loss: 0.00002522
Iteration 188/1000 | Loss: 0.00002522
Iteration 189/1000 | Loss: 0.00002522
Iteration 190/1000 | Loss: 0.00002522
Iteration 191/1000 | Loss: 0.00002522
Iteration 192/1000 | Loss: 0.00002522
Iteration 193/1000 | Loss: 0.00002522
Iteration 194/1000 | Loss: 0.00002522
Iteration 195/1000 | Loss: 0.00002522
Iteration 196/1000 | Loss: 0.00002522
Iteration 197/1000 | Loss: 0.00002522
Iteration 198/1000 | Loss: 0.00002522
Iteration 199/1000 | Loss: 0.00002522
Iteration 200/1000 | Loss: 0.00002522
Iteration 201/1000 | Loss: 0.00002522
Iteration 202/1000 | Loss: 0.00002522
Iteration 203/1000 | Loss: 0.00002522
Iteration 204/1000 | Loss: 0.00002522
Iteration 205/1000 | Loss: 0.00002522
Iteration 206/1000 | Loss: 0.00002522
Iteration 207/1000 | Loss: 0.00002522
Iteration 208/1000 | Loss: 0.00002522
Iteration 209/1000 | Loss: 0.00002522
Iteration 210/1000 | Loss: 0.00002522
Iteration 211/1000 | Loss: 0.00002522
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 211. Stopping optimization.
Last 5 losses: [2.5221675969078206e-05, 2.5221675969078206e-05, 2.5221675969078206e-05, 2.5221675969078206e-05, 2.5221675969078206e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5221675969078206e-05

Optimization complete. Final v2v error: 4.108335494995117 mm

Highest mean error: 5.373263835906982 mm for frame 96

Lowest mean error: 3.0309972763061523 mm for frame 6

Saving results

Total time: 137.43418860435486
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1039
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00401150
Iteration 2/25 | Loss: 0.00110562
Iteration 3/25 | Loss: 0.00088305
Iteration 4/25 | Loss: 0.00084332
Iteration 5/25 | Loss: 0.00083039
Iteration 6/25 | Loss: 0.00082701
Iteration 7/25 | Loss: 0.00082587
Iteration 8/25 | Loss: 0.00082574
Iteration 9/25 | Loss: 0.00082574
Iteration 10/25 | Loss: 0.00082574
Iteration 11/25 | Loss: 0.00082574
Iteration 12/25 | Loss: 0.00082574
Iteration 13/25 | Loss: 0.00082574
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008257428999058902, 0.0008257428999058902, 0.0008257428999058902, 0.0008257428999058902, 0.0008257428999058902]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008257428999058902

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56118441
Iteration 2/25 | Loss: 0.00070660
Iteration 3/25 | Loss: 0.00070660
Iteration 4/25 | Loss: 0.00070659
Iteration 5/25 | Loss: 0.00070659
Iteration 6/25 | Loss: 0.00070659
Iteration 7/25 | Loss: 0.00070659
Iteration 8/25 | Loss: 0.00070659
Iteration 9/25 | Loss: 0.00070659
Iteration 10/25 | Loss: 0.00070659
Iteration 11/25 | Loss: 0.00070659
Iteration 12/25 | Loss: 0.00070659
Iteration 13/25 | Loss: 0.00070659
Iteration 14/25 | Loss: 0.00070659
Iteration 15/25 | Loss: 0.00070659
Iteration 16/25 | Loss: 0.00070659
Iteration 17/25 | Loss: 0.00070659
Iteration 18/25 | Loss: 0.00070659
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007065913523547351, 0.0007065913523547351, 0.0007065913523547351, 0.0007065913523547351, 0.0007065913523547351]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007065913523547351

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00070659
Iteration 2/1000 | Loss: 0.00004273
Iteration 3/1000 | Loss: 0.00003082
Iteration 4/1000 | Loss: 0.00002604
Iteration 5/1000 | Loss: 0.00002374
Iteration 6/1000 | Loss: 0.00002205
Iteration 7/1000 | Loss: 0.00002099
Iteration 8/1000 | Loss: 0.00002028
Iteration 9/1000 | Loss: 0.00001964
Iteration 10/1000 | Loss: 0.00001930
Iteration 11/1000 | Loss: 0.00001896
Iteration 12/1000 | Loss: 0.00001870
Iteration 13/1000 | Loss: 0.00001843
Iteration 14/1000 | Loss: 0.00001820
Iteration 15/1000 | Loss: 0.00001807
Iteration 16/1000 | Loss: 0.00001802
Iteration 17/1000 | Loss: 0.00001797
Iteration 18/1000 | Loss: 0.00001794
Iteration 19/1000 | Loss: 0.00001794
Iteration 20/1000 | Loss: 0.00001791
Iteration 21/1000 | Loss: 0.00001790
Iteration 22/1000 | Loss: 0.00001789
Iteration 23/1000 | Loss: 0.00001788
Iteration 24/1000 | Loss: 0.00001788
Iteration 25/1000 | Loss: 0.00001787
Iteration 26/1000 | Loss: 0.00001786
Iteration 27/1000 | Loss: 0.00001785
Iteration 28/1000 | Loss: 0.00001782
Iteration 29/1000 | Loss: 0.00001781
Iteration 30/1000 | Loss: 0.00001781
Iteration 31/1000 | Loss: 0.00001778
Iteration 32/1000 | Loss: 0.00001778
Iteration 33/1000 | Loss: 0.00001777
Iteration 34/1000 | Loss: 0.00001777
Iteration 35/1000 | Loss: 0.00001777
Iteration 36/1000 | Loss: 0.00001776
Iteration 37/1000 | Loss: 0.00001775
Iteration 38/1000 | Loss: 0.00001775
Iteration 39/1000 | Loss: 0.00001774
Iteration 40/1000 | Loss: 0.00001774
Iteration 41/1000 | Loss: 0.00001773
Iteration 42/1000 | Loss: 0.00001773
Iteration 43/1000 | Loss: 0.00001772
Iteration 44/1000 | Loss: 0.00001772
Iteration 45/1000 | Loss: 0.00001772
Iteration 46/1000 | Loss: 0.00001771
Iteration 47/1000 | Loss: 0.00001771
Iteration 48/1000 | Loss: 0.00001771
Iteration 49/1000 | Loss: 0.00001771
Iteration 50/1000 | Loss: 0.00001770
Iteration 51/1000 | Loss: 0.00001770
Iteration 52/1000 | Loss: 0.00001770
Iteration 53/1000 | Loss: 0.00001770
Iteration 54/1000 | Loss: 0.00001769
Iteration 55/1000 | Loss: 0.00001769
Iteration 56/1000 | Loss: 0.00001769
Iteration 57/1000 | Loss: 0.00001769
Iteration 58/1000 | Loss: 0.00001769
Iteration 59/1000 | Loss: 0.00001768
Iteration 60/1000 | Loss: 0.00001768
Iteration 61/1000 | Loss: 0.00001768
Iteration 62/1000 | Loss: 0.00001767
Iteration 63/1000 | Loss: 0.00001767
Iteration 64/1000 | Loss: 0.00001767
Iteration 65/1000 | Loss: 0.00001766
Iteration 66/1000 | Loss: 0.00001766
Iteration 67/1000 | Loss: 0.00001766
Iteration 68/1000 | Loss: 0.00001766
Iteration 69/1000 | Loss: 0.00001765
Iteration 70/1000 | Loss: 0.00001765
Iteration 71/1000 | Loss: 0.00001765
Iteration 72/1000 | Loss: 0.00001765
Iteration 73/1000 | Loss: 0.00001764
Iteration 74/1000 | Loss: 0.00001764
Iteration 75/1000 | Loss: 0.00001764
Iteration 76/1000 | Loss: 0.00001764
Iteration 77/1000 | Loss: 0.00001764
Iteration 78/1000 | Loss: 0.00001764
Iteration 79/1000 | Loss: 0.00001764
Iteration 80/1000 | Loss: 0.00001764
Iteration 81/1000 | Loss: 0.00001763
Iteration 82/1000 | Loss: 0.00001763
Iteration 83/1000 | Loss: 0.00001763
Iteration 84/1000 | Loss: 0.00001763
Iteration 85/1000 | Loss: 0.00001763
Iteration 86/1000 | Loss: 0.00001763
Iteration 87/1000 | Loss: 0.00001762
Iteration 88/1000 | Loss: 0.00001762
Iteration 89/1000 | Loss: 0.00001762
Iteration 90/1000 | Loss: 0.00001762
Iteration 91/1000 | Loss: 0.00001762
Iteration 92/1000 | Loss: 0.00001762
Iteration 93/1000 | Loss: 0.00001762
Iteration 94/1000 | Loss: 0.00001762
Iteration 95/1000 | Loss: 0.00001761
Iteration 96/1000 | Loss: 0.00001761
Iteration 97/1000 | Loss: 0.00001761
Iteration 98/1000 | Loss: 0.00001761
Iteration 99/1000 | Loss: 0.00001761
Iteration 100/1000 | Loss: 0.00001760
Iteration 101/1000 | Loss: 0.00001760
Iteration 102/1000 | Loss: 0.00001760
Iteration 103/1000 | Loss: 0.00001760
Iteration 104/1000 | Loss: 0.00001759
Iteration 105/1000 | Loss: 0.00001759
Iteration 106/1000 | Loss: 0.00001759
Iteration 107/1000 | Loss: 0.00001759
Iteration 108/1000 | Loss: 0.00001758
Iteration 109/1000 | Loss: 0.00001758
Iteration 110/1000 | Loss: 0.00001758
Iteration 111/1000 | Loss: 0.00001758
Iteration 112/1000 | Loss: 0.00001757
Iteration 113/1000 | Loss: 0.00001757
Iteration 114/1000 | Loss: 0.00001757
Iteration 115/1000 | Loss: 0.00001757
Iteration 116/1000 | Loss: 0.00001757
Iteration 117/1000 | Loss: 0.00001757
Iteration 118/1000 | Loss: 0.00001757
Iteration 119/1000 | Loss: 0.00001757
Iteration 120/1000 | Loss: 0.00001757
Iteration 121/1000 | Loss: 0.00001757
Iteration 122/1000 | Loss: 0.00001757
Iteration 123/1000 | Loss: 0.00001756
Iteration 124/1000 | Loss: 0.00001756
Iteration 125/1000 | Loss: 0.00001756
Iteration 126/1000 | Loss: 0.00001756
Iteration 127/1000 | Loss: 0.00001756
Iteration 128/1000 | Loss: 0.00001756
Iteration 129/1000 | Loss: 0.00001756
Iteration 130/1000 | Loss: 0.00001756
Iteration 131/1000 | Loss: 0.00001756
Iteration 132/1000 | Loss: 0.00001755
Iteration 133/1000 | Loss: 0.00001755
Iteration 134/1000 | Loss: 0.00001755
Iteration 135/1000 | Loss: 0.00001755
Iteration 136/1000 | Loss: 0.00001755
Iteration 137/1000 | Loss: 0.00001755
Iteration 138/1000 | Loss: 0.00001755
Iteration 139/1000 | Loss: 0.00001755
Iteration 140/1000 | Loss: 0.00001755
Iteration 141/1000 | Loss: 0.00001755
Iteration 142/1000 | Loss: 0.00001755
Iteration 143/1000 | Loss: 0.00001755
Iteration 144/1000 | Loss: 0.00001755
Iteration 145/1000 | Loss: 0.00001755
Iteration 146/1000 | Loss: 0.00001754
Iteration 147/1000 | Loss: 0.00001754
Iteration 148/1000 | Loss: 0.00001754
Iteration 149/1000 | Loss: 0.00001754
Iteration 150/1000 | Loss: 0.00001754
Iteration 151/1000 | Loss: 0.00001754
Iteration 152/1000 | Loss: 0.00001754
Iteration 153/1000 | Loss: 0.00001754
Iteration 154/1000 | Loss: 0.00001754
Iteration 155/1000 | Loss: 0.00001754
Iteration 156/1000 | Loss: 0.00001754
Iteration 157/1000 | Loss: 0.00001754
Iteration 158/1000 | Loss: 0.00001753
Iteration 159/1000 | Loss: 0.00001753
Iteration 160/1000 | Loss: 0.00001753
Iteration 161/1000 | Loss: 0.00001753
Iteration 162/1000 | Loss: 0.00001753
Iteration 163/1000 | Loss: 0.00001753
Iteration 164/1000 | Loss: 0.00001753
Iteration 165/1000 | Loss: 0.00001753
Iteration 166/1000 | Loss: 0.00001753
Iteration 167/1000 | Loss: 0.00001753
Iteration 168/1000 | Loss: 0.00001752
Iteration 169/1000 | Loss: 0.00001752
Iteration 170/1000 | Loss: 0.00001752
Iteration 171/1000 | Loss: 0.00001752
Iteration 172/1000 | Loss: 0.00001752
Iteration 173/1000 | Loss: 0.00001752
Iteration 174/1000 | Loss: 0.00001752
Iteration 175/1000 | Loss: 0.00001752
Iteration 176/1000 | Loss: 0.00001752
Iteration 177/1000 | Loss: 0.00001752
Iteration 178/1000 | Loss: 0.00001752
Iteration 179/1000 | Loss: 0.00001752
Iteration 180/1000 | Loss: 0.00001752
Iteration 181/1000 | Loss: 0.00001752
Iteration 182/1000 | Loss: 0.00001752
Iteration 183/1000 | Loss: 0.00001752
Iteration 184/1000 | Loss: 0.00001752
Iteration 185/1000 | Loss: 0.00001752
Iteration 186/1000 | Loss: 0.00001751
Iteration 187/1000 | Loss: 0.00001751
Iteration 188/1000 | Loss: 0.00001751
Iteration 189/1000 | Loss: 0.00001751
Iteration 190/1000 | Loss: 0.00001751
Iteration 191/1000 | Loss: 0.00001751
Iteration 192/1000 | Loss: 0.00001751
Iteration 193/1000 | Loss: 0.00001751
Iteration 194/1000 | Loss: 0.00001751
Iteration 195/1000 | Loss: 0.00001751
Iteration 196/1000 | Loss: 0.00001751
Iteration 197/1000 | Loss: 0.00001751
Iteration 198/1000 | Loss: 0.00001751
Iteration 199/1000 | Loss: 0.00001751
Iteration 200/1000 | Loss: 0.00001751
Iteration 201/1000 | Loss: 0.00001750
Iteration 202/1000 | Loss: 0.00001750
Iteration 203/1000 | Loss: 0.00001750
Iteration 204/1000 | Loss: 0.00001750
Iteration 205/1000 | Loss: 0.00001750
Iteration 206/1000 | Loss: 0.00001750
Iteration 207/1000 | Loss: 0.00001750
Iteration 208/1000 | Loss: 0.00001750
Iteration 209/1000 | Loss: 0.00001750
Iteration 210/1000 | Loss: 0.00001750
Iteration 211/1000 | Loss: 0.00001750
Iteration 212/1000 | Loss: 0.00001750
Iteration 213/1000 | Loss: 0.00001750
Iteration 214/1000 | Loss: 0.00001750
Iteration 215/1000 | Loss: 0.00001750
Iteration 216/1000 | Loss: 0.00001750
Iteration 217/1000 | Loss: 0.00001750
Iteration 218/1000 | Loss: 0.00001750
Iteration 219/1000 | Loss: 0.00001750
Iteration 220/1000 | Loss: 0.00001750
Iteration 221/1000 | Loss: 0.00001750
Iteration 222/1000 | Loss: 0.00001750
Iteration 223/1000 | Loss: 0.00001750
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 223. Stopping optimization.
Last 5 losses: [1.7496582586318254e-05, 1.7496582586318254e-05, 1.7496582586318254e-05, 1.7496582586318254e-05, 1.7496582586318254e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7496582586318254e-05

Optimization complete. Final v2v error: 3.501680612564087 mm

Highest mean error: 4.42017126083374 mm for frame 5

Lowest mean error: 2.889319896697998 mm for frame 130

Saving results

Total time: 54.882713079452515
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00768290
Iteration 2/25 | Loss: 0.00173621
Iteration 3/25 | Loss: 0.00103110
Iteration 4/25 | Loss: 0.00093850
Iteration 5/25 | Loss: 0.00087946
Iteration 6/25 | Loss: 0.00086280
Iteration 7/25 | Loss: 0.00087086
Iteration 8/25 | Loss: 0.00085569
Iteration 9/25 | Loss: 0.00085286
Iteration 10/25 | Loss: 0.00083343
Iteration 11/25 | Loss: 0.00082510
Iteration 12/25 | Loss: 0.00082105
Iteration 13/25 | Loss: 0.00082329
Iteration 14/25 | Loss: 0.00081875
Iteration 15/25 | Loss: 0.00081698
Iteration 16/25 | Loss: 0.00081562
Iteration 17/25 | Loss: 0.00081569
Iteration 18/25 | Loss: 0.00081515
Iteration 19/25 | Loss: 0.00081512
Iteration 20/25 | Loss: 0.00081512
Iteration 21/25 | Loss: 0.00081505
Iteration 22/25 | Loss: 0.00081505
Iteration 23/25 | Loss: 0.00081505
Iteration 24/25 | Loss: 0.00081504
Iteration 25/25 | Loss: 0.00081504

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.22962904
Iteration 2/25 | Loss: 0.00057427
Iteration 3/25 | Loss: 0.00056852
Iteration 4/25 | Loss: 0.00056852
Iteration 5/25 | Loss: 0.00056852
Iteration 6/25 | Loss: 0.00056852
Iteration 7/25 | Loss: 0.00056852
Iteration 8/25 | Loss: 0.00056852
Iteration 9/25 | Loss: 0.00056852
Iteration 10/25 | Loss: 0.00056852
Iteration 11/25 | Loss: 0.00056852
Iteration 12/25 | Loss: 0.00056851
Iteration 13/25 | Loss: 0.00056851
Iteration 14/25 | Loss: 0.00056851
Iteration 15/25 | Loss: 0.00056851
Iteration 16/25 | Loss: 0.00056851
Iteration 17/25 | Loss: 0.00056851
Iteration 18/25 | Loss: 0.00056851
Iteration 19/25 | Loss: 0.00056851
Iteration 20/25 | Loss: 0.00056851
Iteration 21/25 | Loss: 0.00056851
Iteration 22/25 | Loss: 0.00056851
Iteration 23/25 | Loss: 0.00056851
Iteration 24/25 | Loss: 0.00056851
Iteration 25/25 | Loss: 0.00056851

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056851
Iteration 2/1000 | Loss: 0.00003511
Iteration 3/1000 | Loss: 0.00002053
Iteration 4/1000 | Loss: 0.00008242
Iteration 5/1000 | Loss: 0.00001802
Iteration 6/1000 | Loss: 0.00001755
Iteration 7/1000 | Loss: 0.00002060
Iteration 8/1000 | Loss: 0.00001675
Iteration 9/1000 | Loss: 0.00003232
Iteration 10/1000 | Loss: 0.00001631
Iteration 11/1000 | Loss: 0.00008405
Iteration 12/1000 | Loss: 0.00003962
Iteration 13/1000 | Loss: 0.00001610
Iteration 14/1000 | Loss: 0.00001758
Iteration 15/1000 | Loss: 0.00001594
Iteration 16/1000 | Loss: 0.00001593
Iteration 17/1000 | Loss: 0.00001587
Iteration 18/1000 | Loss: 0.00001580
Iteration 19/1000 | Loss: 0.00001580
Iteration 20/1000 | Loss: 0.00001580
Iteration 21/1000 | Loss: 0.00001579
Iteration 22/1000 | Loss: 0.00001938
Iteration 23/1000 | Loss: 0.00001571
Iteration 24/1000 | Loss: 0.00001569
Iteration 25/1000 | Loss: 0.00001569
Iteration 26/1000 | Loss: 0.00001569
Iteration 27/1000 | Loss: 0.00001569
Iteration 28/1000 | Loss: 0.00001569
Iteration 29/1000 | Loss: 0.00001569
Iteration 30/1000 | Loss: 0.00001569
Iteration 31/1000 | Loss: 0.00001569
Iteration 32/1000 | Loss: 0.00001569
Iteration 33/1000 | Loss: 0.00001569
Iteration 34/1000 | Loss: 0.00001568
Iteration 35/1000 | Loss: 0.00001568
Iteration 36/1000 | Loss: 0.00001567
Iteration 37/1000 | Loss: 0.00001565
Iteration 38/1000 | Loss: 0.00001565
Iteration 39/1000 | Loss: 0.00001565
Iteration 40/1000 | Loss: 0.00001565
Iteration 41/1000 | Loss: 0.00001565
Iteration 42/1000 | Loss: 0.00001565
Iteration 43/1000 | Loss: 0.00001565
Iteration 44/1000 | Loss: 0.00001564
Iteration 45/1000 | Loss: 0.00001564
Iteration 46/1000 | Loss: 0.00001561
Iteration 47/1000 | Loss: 0.00001557
Iteration 48/1000 | Loss: 0.00001550
Iteration 49/1000 | Loss: 0.00001549
Iteration 50/1000 | Loss: 0.00001549
Iteration 51/1000 | Loss: 0.00001548
Iteration 52/1000 | Loss: 0.00001547
Iteration 53/1000 | Loss: 0.00001547
Iteration 54/1000 | Loss: 0.00001547
Iteration 55/1000 | Loss: 0.00001547
Iteration 56/1000 | Loss: 0.00001546
Iteration 57/1000 | Loss: 0.00001545
Iteration 58/1000 | Loss: 0.00001545
Iteration 59/1000 | Loss: 0.00001545
Iteration 60/1000 | Loss: 0.00001545
Iteration 61/1000 | Loss: 0.00001545
Iteration 62/1000 | Loss: 0.00002966
Iteration 63/1000 | Loss: 0.00001543
Iteration 64/1000 | Loss: 0.00001543
Iteration 65/1000 | Loss: 0.00001543
Iteration 66/1000 | Loss: 0.00001543
Iteration 67/1000 | Loss: 0.00001543
Iteration 68/1000 | Loss: 0.00001543
Iteration 69/1000 | Loss: 0.00001543
Iteration 70/1000 | Loss: 0.00001543
Iteration 71/1000 | Loss: 0.00001543
Iteration 72/1000 | Loss: 0.00001543
Iteration 73/1000 | Loss: 0.00001543
Iteration 74/1000 | Loss: 0.00001542
Iteration 75/1000 | Loss: 0.00001542
Iteration 76/1000 | Loss: 0.00001542
Iteration 77/1000 | Loss: 0.00001542
Iteration 78/1000 | Loss: 0.00001542
Iteration 79/1000 | Loss: 0.00001541
Iteration 80/1000 | Loss: 0.00001541
Iteration 81/1000 | Loss: 0.00001541
Iteration 82/1000 | Loss: 0.00001541
Iteration 83/1000 | Loss: 0.00001541
Iteration 84/1000 | Loss: 0.00001541
Iteration 85/1000 | Loss: 0.00001541
Iteration 86/1000 | Loss: 0.00001541
Iteration 87/1000 | Loss: 0.00001541
Iteration 88/1000 | Loss: 0.00001541
Iteration 89/1000 | Loss: 0.00001540
Iteration 90/1000 | Loss: 0.00001540
Iteration 91/1000 | Loss: 0.00001540
Iteration 92/1000 | Loss: 0.00001540
Iteration 93/1000 | Loss: 0.00001540
Iteration 94/1000 | Loss: 0.00001540
Iteration 95/1000 | Loss: 0.00001540
Iteration 96/1000 | Loss: 0.00001539
Iteration 97/1000 | Loss: 0.00001539
Iteration 98/1000 | Loss: 0.00001539
Iteration 99/1000 | Loss: 0.00001539
Iteration 100/1000 | Loss: 0.00001539
Iteration 101/1000 | Loss: 0.00001539
Iteration 102/1000 | Loss: 0.00001539
Iteration 103/1000 | Loss: 0.00001539
Iteration 104/1000 | Loss: 0.00001539
Iteration 105/1000 | Loss: 0.00001539
Iteration 106/1000 | Loss: 0.00001539
Iteration 107/1000 | Loss: 0.00001539
Iteration 108/1000 | Loss: 0.00001539
Iteration 109/1000 | Loss: 0.00001539
Iteration 110/1000 | Loss: 0.00001538
Iteration 111/1000 | Loss: 0.00001538
Iteration 112/1000 | Loss: 0.00001538
Iteration 113/1000 | Loss: 0.00001538
Iteration 114/1000 | Loss: 0.00001538
Iteration 115/1000 | Loss: 0.00001538
Iteration 116/1000 | Loss: 0.00001538
Iteration 117/1000 | Loss: 0.00001538
Iteration 118/1000 | Loss: 0.00001538
Iteration 119/1000 | Loss: 0.00001538
Iteration 120/1000 | Loss: 0.00001538
Iteration 121/1000 | Loss: 0.00001538
Iteration 122/1000 | Loss: 0.00001537
Iteration 123/1000 | Loss: 0.00001537
Iteration 124/1000 | Loss: 0.00001537
Iteration 125/1000 | Loss: 0.00001537
Iteration 126/1000 | Loss: 0.00001537
Iteration 127/1000 | Loss: 0.00001537
Iteration 128/1000 | Loss: 0.00001537
Iteration 129/1000 | Loss: 0.00002079
Iteration 130/1000 | Loss: 0.00001536
Iteration 131/1000 | Loss: 0.00001536
Iteration 132/1000 | Loss: 0.00001536
Iteration 133/1000 | Loss: 0.00001536
Iteration 134/1000 | Loss: 0.00001535
Iteration 135/1000 | Loss: 0.00001535
Iteration 136/1000 | Loss: 0.00001535
Iteration 137/1000 | Loss: 0.00001535
Iteration 138/1000 | Loss: 0.00001535
Iteration 139/1000 | Loss: 0.00001535
Iteration 140/1000 | Loss: 0.00001535
Iteration 141/1000 | Loss: 0.00001535
Iteration 142/1000 | Loss: 0.00001535
Iteration 143/1000 | Loss: 0.00001535
Iteration 144/1000 | Loss: 0.00001535
Iteration 145/1000 | Loss: 0.00001535
Iteration 146/1000 | Loss: 0.00001535
Iteration 147/1000 | Loss: 0.00001535
Iteration 148/1000 | Loss: 0.00001534
Iteration 149/1000 | Loss: 0.00001534
Iteration 150/1000 | Loss: 0.00001534
Iteration 151/1000 | Loss: 0.00001534
Iteration 152/1000 | Loss: 0.00001534
Iteration 153/1000 | Loss: 0.00001534
Iteration 154/1000 | Loss: 0.00001534
Iteration 155/1000 | Loss: 0.00001534
Iteration 156/1000 | Loss: 0.00001534
Iteration 157/1000 | Loss: 0.00001534
Iteration 158/1000 | Loss: 0.00001534
Iteration 159/1000 | Loss: 0.00001534
Iteration 160/1000 | Loss: 0.00001534
Iteration 161/1000 | Loss: 0.00001534
Iteration 162/1000 | Loss: 0.00001534
Iteration 163/1000 | Loss: 0.00001534
Iteration 164/1000 | Loss: 0.00001534
Iteration 165/1000 | Loss: 0.00001534
Iteration 166/1000 | Loss: 0.00001534
Iteration 167/1000 | Loss: 0.00001533
Iteration 168/1000 | Loss: 0.00001533
Iteration 169/1000 | Loss: 0.00001533
Iteration 170/1000 | Loss: 0.00001533
Iteration 171/1000 | Loss: 0.00001533
Iteration 172/1000 | Loss: 0.00001533
Iteration 173/1000 | Loss: 0.00001533
Iteration 174/1000 | Loss: 0.00001533
Iteration 175/1000 | Loss: 0.00001533
Iteration 176/1000 | Loss: 0.00001533
Iteration 177/1000 | Loss: 0.00001533
Iteration 178/1000 | Loss: 0.00001533
Iteration 179/1000 | Loss: 0.00001533
Iteration 180/1000 | Loss: 0.00001533
Iteration 181/1000 | Loss: 0.00001533
Iteration 182/1000 | Loss: 0.00001533
Iteration 183/1000 | Loss: 0.00001533
Iteration 184/1000 | Loss: 0.00001533
Iteration 185/1000 | Loss: 0.00001533
Iteration 186/1000 | Loss: 0.00001533
Iteration 187/1000 | Loss: 0.00001533
Iteration 188/1000 | Loss: 0.00001533
Iteration 189/1000 | Loss: 0.00001533
Iteration 190/1000 | Loss: 0.00001533
Iteration 191/1000 | Loss: 0.00001533
Iteration 192/1000 | Loss: 0.00001533
Iteration 193/1000 | Loss: 0.00001533
Iteration 194/1000 | Loss: 0.00001533
Iteration 195/1000 | Loss: 0.00001533
Iteration 196/1000 | Loss: 0.00001533
Iteration 197/1000 | Loss: 0.00001533
Iteration 198/1000 | Loss: 0.00001533
Iteration 199/1000 | Loss: 0.00001533
Iteration 200/1000 | Loss: 0.00001533
Iteration 201/1000 | Loss: 0.00001533
Iteration 202/1000 | Loss: 0.00001533
Iteration 203/1000 | Loss: 0.00001533
Iteration 204/1000 | Loss: 0.00001533
Iteration 205/1000 | Loss: 0.00001533
Iteration 206/1000 | Loss: 0.00001533
Iteration 207/1000 | Loss: 0.00001533
Iteration 208/1000 | Loss: 0.00001533
Iteration 209/1000 | Loss: 0.00001533
Iteration 210/1000 | Loss: 0.00001533
Iteration 211/1000 | Loss: 0.00001533
Iteration 212/1000 | Loss: 0.00001533
Iteration 213/1000 | Loss: 0.00001533
Iteration 214/1000 | Loss: 0.00001533
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 214. Stopping optimization.
Last 5 losses: [1.5330415408243425e-05, 1.5330415408243425e-05, 1.5330415408243425e-05, 1.5330415408243425e-05, 1.5330415408243425e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5330415408243425e-05

Optimization complete. Final v2v error: 3.344933032989502 mm

Highest mean error: 3.7140936851501465 mm for frame 101

Lowest mean error: 3.0468037128448486 mm for frame 4

Saving results

Total time: 76.7646598815918
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1046
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01094349
Iteration 2/25 | Loss: 0.00158558
Iteration 3/25 | Loss: 0.00089482
Iteration 4/25 | Loss: 0.00083758
Iteration 5/25 | Loss: 0.00082459
Iteration 6/25 | Loss: 0.00082336
Iteration 7/25 | Loss: 0.00082336
Iteration 8/25 | Loss: 0.00082336
Iteration 9/25 | Loss: 0.00082336
Iteration 10/25 | Loss: 0.00082336
Iteration 11/25 | Loss: 0.00082336
Iteration 12/25 | Loss: 0.00082336
Iteration 13/25 | Loss: 0.00082336
Iteration 14/25 | Loss: 0.00082336
Iteration 15/25 | Loss: 0.00082336
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008233620901592076, 0.0008233620901592076, 0.0008233620901592076, 0.0008233620901592076, 0.0008233620901592076]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008233620901592076

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.35190940
Iteration 2/25 | Loss: 0.00050702
Iteration 3/25 | Loss: 0.00050702
Iteration 4/25 | Loss: 0.00050702
Iteration 5/25 | Loss: 0.00050702
Iteration 6/25 | Loss: 0.00050702
Iteration 7/25 | Loss: 0.00050702
Iteration 8/25 | Loss: 0.00050702
Iteration 9/25 | Loss: 0.00050702
Iteration 10/25 | Loss: 0.00050702
Iteration 11/25 | Loss: 0.00050702
Iteration 12/25 | Loss: 0.00050702
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0005070182960480452, 0.0005070182960480452, 0.0005070182960480452, 0.0005070182960480452, 0.0005070182960480452]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005070182960480452

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050702
Iteration 2/1000 | Loss: 0.00002247
Iteration 3/1000 | Loss: 0.00001670
Iteration 4/1000 | Loss: 0.00001522
Iteration 5/1000 | Loss: 0.00001375
Iteration 6/1000 | Loss: 0.00001329
Iteration 7/1000 | Loss: 0.00001288
Iteration 8/1000 | Loss: 0.00001254
Iteration 9/1000 | Loss: 0.00001237
Iteration 10/1000 | Loss: 0.00001213
Iteration 11/1000 | Loss: 0.00001198
Iteration 12/1000 | Loss: 0.00001191
Iteration 13/1000 | Loss: 0.00001190
Iteration 14/1000 | Loss: 0.00001190
Iteration 15/1000 | Loss: 0.00001189
Iteration 16/1000 | Loss: 0.00001188
Iteration 17/1000 | Loss: 0.00001188
Iteration 18/1000 | Loss: 0.00001187
Iteration 19/1000 | Loss: 0.00001186
Iteration 20/1000 | Loss: 0.00001185
Iteration 21/1000 | Loss: 0.00001185
Iteration 22/1000 | Loss: 0.00001185
Iteration 23/1000 | Loss: 0.00001184
Iteration 24/1000 | Loss: 0.00001184
Iteration 25/1000 | Loss: 0.00001184
Iteration 26/1000 | Loss: 0.00001184
Iteration 27/1000 | Loss: 0.00001183
Iteration 28/1000 | Loss: 0.00001183
Iteration 29/1000 | Loss: 0.00001182
Iteration 30/1000 | Loss: 0.00001182
Iteration 31/1000 | Loss: 0.00001182
Iteration 32/1000 | Loss: 0.00001182
Iteration 33/1000 | Loss: 0.00001181
Iteration 34/1000 | Loss: 0.00001181
Iteration 35/1000 | Loss: 0.00001180
Iteration 36/1000 | Loss: 0.00001180
Iteration 37/1000 | Loss: 0.00001180
Iteration 38/1000 | Loss: 0.00001180
Iteration 39/1000 | Loss: 0.00001177
Iteration 40/1000 | Loss: 0.00001176
Iteration 41/1000 | Loss: 0.00001176
Iteration 42/1000 | Loss: 0.00001175
Iteration 43/1000 | Loss: 0.00001175
Iteration 44/1000 | Loss: 0.00001175
Iteration 45/1000 | Loss: 0.00001175
Iteration 46/1000 | Loss: 0.00001175
Iteration 47/1000 | Loss: 0.00001174
Iteration 48/1000 | Loss: 0.00001174
Iteration 49/1000 | Loss: 0.00001174
Iteration 50/1000 | Loss: 0.00001174
Iteration 51/1000 | Loss: 0.00001173
Iteration 52/1000 | Loss: 0.00001173
Iteration 53/1000 | Loss: 0.00001173
Iteration 54/1000 | Loss: 0.00001173
Iteration 55/1000 | Loss: 0.00001173
Iteration 56/1000 | Loss: 0.00001173
Iteration 57/1000 | Loss: 0.00001173
Iteration 58/1000 | Loss: 0.00001173
Iteration 59/1000 | Loss: 0.00001173
Iteration 60/1000 | Loss: 0.00001173
Iteration 61/1000 | Loss: 0.00001173
Iteration 62/1000 | Loss: 0.00001172
Iteration 63/1000 | Loss: 0.00001172
Iteration 64/1000 | Loss: 0.00001172
Iteration 65/1000 | Loss: 0.00001172
Iteration 66/1000 | Loss: 0.00001171
Iteration 67/1000 | Loss: 0.00001171
Iteration 68/1000 | Loss: 0.00001171
Iteration 69/1000 | Loss: 0.00001171
Iteration 70/1000 | Loss: 0.00001171
Iteration 71/1000 | Loss: 0.00001171
Iteration 72/1000 | Loss: 0.00001171
Iteration 73/1000 | Loss: 0.00001171
Iteration 74/1000 | Loss: 0.00001171
Iteration 75/1000 | Loss: 0.00001170
Iteration 76/1000 | Loss: 0.00001170
Iteration 77/1000 | Loss: 0.00001170
Iteration 78/1000 | Loss: 0.00001170
Iteration 79/1000 | Loss: 0.00001170
Iteration 80/1000 | Loss: 0.00001170
Iteration 81/1000 | Loss: 0.00001170
Iteration 82/1000 | Loss: 0.00001170
Iteration 83/1000 | Loss: 0.00001170
Iteration 84/1000 | Loss: 0.00001170
Iteration 85/1000 | Loss: 0.00001170
Iteration 86/1000 | Loss: 0.00001170
Iteration 87/1000 | Loss: 0.00001170
Iteration 88/1000 | Loss: 0.00001170
Iteration 89/1000 | Loss: 0.00001170
Iteration 90/1000 | Loss: 0.00001170
Iteration 91/1000 | Loss: 0.00001170
Iteration 92/1000 | Loss: 0.00001170
Iteration 93/1000 | Loss: 0.00001169
Iteration 94/1000 | Loss: 0.00001169
Iteration 95/1000 | Loss: 0.00001169
Iteration 96/1000 | Loss: 0.00001169
Iteration 97/1000 | Loss: 0.00001169
Iteration 98/1000 | Loss: 0.00001169
Iteration 99/1000 | Loss: 0.00001169
Iteration 100/1000 | Loss: 0.00001168
Iteration 101/1000 | Loss: 0.00001168
Iteration 102/1000 | Loss: 0.00001168
Iteration 103/1000 | Loss: 0.00001168
Iteration 104/1000 | Loss: 0.00001168
Iteration 105/1000 | Loss: 0.00001168
Iteration 106/1000 | Loss: 0.00001168
Iteration 107/1000 | Loss: 0.00001168
Iteration 108/1000 | Loss: 0.00001168
Iteration 109/1000 | Loss: 0.00001168
Iteration 110/1000 | Loss: 0.00001168
Iteration 111/1000 | Loss: 0.00001168
Iteration 112/1000 | Loss: 0.00001168
Iteration 113/1000 | Loss: 0.00001168
Iteration 114/1000 | Loss: 0.00001167
Iteration 115/1000 | Loss: 0.00001167
Iteration 116/1000 | Loss: 0.00001167
Iteration 117/1000 | Loss: 0.00001167
Iteration 118/1000 | Loss: 0.00001167
Iteration 119/1000 | Loss: 0.00001166
Iteration 120/1000 | Loss: 0.00001166
Iteration 121/1000 | Loss: 0.00001166
Iteration 122/1000 | Loss: 0.00001166
Iteration 123/1000 | Loss: 0.00001166
Iteration 124/1000 | Loss: 0.00001166
Iteration 125/1000 | Loss: 0.00001166
Iteration 126/1000 | Loss: 0.00001166
Iteration 127/1000 | Loss: 0.00001166
Iteration 128/1000 | Loss: 0.00001166
Iteration 129/1000 | Loss: 0.00001166
Iteration 130/1000 | Loss: 0.00001166
Iteration 131/1000 | Loss: 0.00001166
Iteration 132/1000 | Loss: 0.00001166
Iteration 133/1000 | Loss: 0.00001166
Iteration 134/1000 | Loss: 0.00001165
Iteration 135/1000 | Loss: 0.00001165
Iteration 136/1000 | Loss: 0.00001165
Iteration 137/1000 | Loss: 0.00001165
Iteration 138/1000 | Loss: 0.00001165
Iteration 139/1000 | Loss: 0.00001165
Iteration 140/1000 | Loss: 0.00001165
Iteration 141/1000 | Loss: 0.00001165
Iteration 142/1000 | Loss: 0.00001165
Iteration 143/1000 | Loss: 0.00001165
Iteration 144/1000 | Loss: 0.00001164
Iteration 145/1000 | Loss: 0.00001164
Iteration 146/1000 | Loss: 0.00001164
Iteration 147/1000 | Loss: 0.00001164
Iteration 148/1000 | Loss: 0.00001164
Iteration 149/1000 | Loss: 0.00001164
Iteration 150/1000 | Loss: 0.00001164
Iteration 151/1000 | Loss: 0.00001164
Iteration 152/1000 | Loss: 0.00001164
Iteration 153/1000 | Loss: 0.00001164
Iteration 154/1000 | Loss: 0.00001164
Iteration 155/1000 | Loss: 0.00001164
Iteration 156/1000 | Loss: 0.00001163
Iteration 157/1000 | Loss: 0.00001163
Iteration 158/1000 | Loss: 0.00001163
Iteration 159/1000 | Loss: 0.00001163
Iteration 160/1000 | Loss: 0.00001163
Iteration 161/1000 | Loss: 0.00001163
Iteration 162/1000 | Loss: 0.00001163
Iteration 163/1000 | Loss: 0.00001163
Iteration 164/1000 | Loss: 0.00001163
Iteration 165/1000 | Loss: 0.00001163
Iteration 166/1000 | Loss: 0.00001163
Iteration 167/1000 | Loss: 0.00001163
Iteration 168/1000 | Loss: 0.00001163
Iteration 169/1000 | Loss: 0.00001163
Iteration 170/1000 | Loss: 0.00001163
Iteration 171/1000 | Loss: 0.00001163
Iteration 172/1000 | Loss: 0.00001163
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 172. Stopping optimization.
Last 5 losses: [1.1625388651737012e-05, 1.1625388651737012e-05, 1.1625388651737012e-05, 1.1625388651737012e-05, 1.1625388651737012e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1625388651737012e-05

Optimization complete. Final v2v error: 2.9014203548431396 mm

Highest mean error: 3.0660150051116943 mm for frame 68

Lowest mean error: 2.7804341316223145 mm for frame 171

Saving results

Total time: 39.5891695022583
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00401574
Iteration 2/25 | Loss: 0.00092037
Iteration 3/25 | Loss: 0.00083143
Iteration 4/25 | Loss: 0.00081281
Iteration 5/25 | Loss: 0.00081014
Iteration 6/25 | Loss: 0.00080913
Iteration 7/25 | Loss: 0.00080902
Iteration 8/25 | Loss: 0.00080902
Iteration 9/25 | Loss: 0.00080902
Iteration 10/25 | Loss: 0.00080902
Iteration 11/25 | Loss: 0.00080902
Iteration 12/25 | Loss: 0.00080902
Iteration 13/25 | Loss: 0.00080902
Iteration 14/25 | Loss: 0.00080902
Iteration 15/25 | Loss: 0.00080902
Iteration 16/25 | Loss: 0.00080902
Iteration 17/25 | Loss: 0.00080902
Iteration 18/25 | Loss: 0.00080902
Iteration 19/25 | Loss: 0.00080902
Iteration 20/25 | Loss: 0.00080902
Iteration 21/25 | Loss: 0.00080902
Iteration 22/25 | Loss: 0.00080902
Iteration 23/25 | Loss: 0.00080902
Iteration 24/25 | Loss: 0.00080902
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.000809017161373049, 0.000809017161373049, 0.000809017161373049, 0.000809017161373049, 0.000809017161373049]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000809017161373049

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.97457647
Iteration 2/25 | Loss: 0.00061013
Iteration 3/25 | Loss: 0.00061012
Iteration 4/25 | Loss: 0.00061012
Iteration 5/25 | Loss: 0.00061012
Iteration 6/25 | Loss: 0.00061012
Iteration 7/25 | Loss: 0.00061012
Iteration 8/25 | Loss: 0.00061012
Iteration 9/25 | Loss: 0.00061012
Iteration 10/25 | Loss: 0.00061012
Iteration 11/25 | Loss: 0.00061012
Iteration 12/25 | Loss: 0.00061012
Iteration 13/25 | Loss: 0.00061012
Iteration 14/25 | Loss: 0.00061012
Iteration 15/25 | Loss: 0.00061012
Iteration 16/25 | Loss: 0.00061012
Iteration 17/25 | Loss: 0.00061012
Iteration 18/25 | Loss: 0.00061012
Iteration 19/25 | Loss: 0.00061012
Iteration 20/25 | Loss: 0.00061012
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0006101170438341796, 0.0006101170438341796, 0.0006101170438341796, 0.0006101170438341796, 0.0006101170438341796]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006101170438341796

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061012
Iteration 2/1000 | Loss: 0.00002914
Iteration 3/1000 | Loss: 0.00001861
Iteration 4/1000 | Loss: 0.00001665
Iteration 5/1000 | Loss: 0.00001568
Iteration 6/1000 | Loss: 0.00001511
Iteration 7/1000 | Loss: 0.00001473
Iteration 8/1000 | Loss: 0.00001452
Iteration 9/1000 | Loss: 0.00001447
Iteration 10/1000 | Loss: 0.00001443
Iteration 11/1000 | Loss: 0.00001428
Iteration 12/1000 | Loss: 0.00001418
Iteration 13/1000 | Loss: 0.00001414
Iteration 14/1000 | Loss: 0.00001410
Iteration 15/1000 | Loss: 0.00001409
Iteration 16/1000 | Loss: 0.00001405
Iteration 17/1000 | Loss: 0.00001404
Iteration 18/1000 | Loss: 0.00001404
Iteration 19/1000 | Loss: 0.00001403
Iteration 20/1000 | Loss: 0.00001403
Iteration 21/1000 | Loss: 0.00001402
Iteration 22/1000 | Loss: 0.00001388
Iteration 23/1000 | Loss: 0.00001387
Iteration 24/1000 | Loss: 0.00001386
Iteration 25/1000 | Loss: 0.00001383
Iteration 26/1000 | Loss: 0.00001383
Iteration 27/1000 | Loss: 0.00001383
Iteration 28/1000 | Loss: 0.00001383
Iteration 29/1000 | Loss: 0.00001383
Iteration 30/1000 | Loss: 0.00001382
Iteration 31/1000 | Loss: 0.00001382
Iteration 32/1000 | Loss: 0.00001382
Iteration 33/1000 | Loss: 0.00001381
Iteration 34/1000 | Loss: 0.00001381
Iteration 35/1000 | Loss: 0.00001381
Iteration 36/1000 | Loss: 0.00001381
Iteration 37/1000 | Loss: 0.00001381
Iteration 38/1000 | Loss: 0.00001381
Iteration 39/1000 | Loss: 0.00001381
Iteration 40/1000 | Loss: 0.00001381
Iteration 41/1000 | Loss: 0.00001380
Iteration 42/1000 | Loss: 0.00001380
Iteration 43/1000 | Loss: 0.00001379
Iteration 44/1000 | Loss: 0.00001378
Iteration 45/1000 | Loss: 0.00001378
Iteration 46/1000 | Loss: 0.00001378
Iteration 47/1000 | Loss: 0.00001377
Iteration 48/1000 | Loss: 0.00001377
Iteration 49/1000 | Loss: 0.00001377
Iteration 50/1000 | Loss: 0.00001376
Iteration 51/1000 | Loss: 0.00001372
Iteration 52/1000 | Loss: 0.00001372
Iteration 53/1000 | Loss: 0.00001370
Iteration 54/1000 | Loss: 0.00001369
Iteration 55/1000 | Loss: 0.00001368
Iteration 56/1000 | Loss: 0.00001367
Iteration 57/1000 | Loss: 0.00001367
Iteration 58/1000 | Loss: 0.00001367
Iteration 59/1000 | Loss: 0.00001367
Iteration 60/1000 | Loss: 0.00001365
Iteration 61/1000 | Loss: 0.00001364
Iteration 62/1000 | Loss: 0.00001364
Iteration 63/1000 | Loss: 0.00001363
Iteration 64/1000 | Loss: 0.00001363
Iteration 65/1000 | Loss: 0.00001363
Iteration 66/1000 | Loss: 0.00001363
Iteration 67/1000 | Loss: 0.00001362
Iteration 68/1000 | Loss: 0.00001361
Iteration 69/1000 | Loss: 0.00001361
Iteration 70/1000 | Loss: 0.00001361
Iteration 71/1000 | Loss: 0.00001360
Iteration 72/1000 | Loss: 0.00001360
Iteration 73/1000 | Loss: 0.00001360
Iteration 74/1000 | Loss: 0.00001360
Iteration 75/1000 | Loss: 0.00001360
Iteration 76/1000 | Loss: 0.00001359
Iteration 77/1000 | Loss: 0.00001359
Iteration 78/1000 | Loss: 0.00001359
Iteration 79/1000 | Loss: 0.00001358
Iteration 80/1000 | Loss: 0.00001358
Iteration 81/1000 | Loss: 0.00001358
Iteration 82/1000 | Loss: 0.00001358
Iteration 83/1000 | Loss: 0.00001357
Iteration 84/1000 | Loss: 0.00001357
Iteration 85/1000 | Loss: 0.00001357
Iteration 86/1000 | Loss: 0.00001357
Iteration 87/1000 | Loss: 0.00001356
Iteration 88/1000 | Loss: 0.00001356
Iteration 89/1000 | Loss: 0.00001356
Iteration 90/1000 | Loss: 0.00001356
Iteration 91/1000 | Loss: 0.00001356
Iteration 92/1000 | Loss: 0.00001356
Iteration 93/1000 | Loss: 0.00001356
Iteration 94/1000 | Loss: 0.00001356
Iteration 95/1000 | Loss: 0.00001355
Iteration 96/1000 | Loss: 0.00001355
Iteration 97/1000 | Loss: 0.00001355
Iteration 98/1000 | Loss: 0.00001355
Iteration 99/1000 | Loss: 0.00001355
Iteration 100/1000 | Loss: 0.00001355
Iteration 101/1000 | Loss: 0.00001355
Iteration 102/1000 | Loss: 0.00001355
Iteration 103/1000 | Loss: 0.00001355
Iteration 104/1000 | Loss: 0.00001354
Iteration 105/1000 | Loss: 0.00001354
Iteration 106/1000 | Loss: 0.00001354
Iteration 107/1000 | Loss: 0.00001354
Iteration 108/1000 | Loss: 0.00001354
Iteration 109/1000 | Loss: 0.00001354
Iteration 110/1000 | Loss: 0.00001354
Iteration 111/1000 | Loss: 0.00001354
Iteration 112/1000 | Loss: 0.00001354
Iteration 113/1000 | Loss: 0.00001354
Iteration 114/1000 | Loss: 0.00001354
Iteration 115/1000 | Loss: 0.00001354
Iteration 116/1000 | Loss: 0.00001353
Iteration 117/1000 | Loss: 0.00001353
Iteration 118/1000 | Loss: 0.00001353
Iteration 119/1000 | Loss: 0.00001353
Iteration 120/1000 | Loss: 0.00001353
Iteration 121/1000 | Loss: 0.00001353
Iteration 122/1000 | Loss: 0.00001353
Iteration 123/1000 | Loss: 0.00001353
Iteration 124/1000 | Loss: 0.00001352
Iteration 125/1000 | Loss: 0.00001352
Iteration 126/1000 | Loss: 0.00001352
Iteration 127/1000 | Loss: 0.00001352
Iteration 128/1000 | Loss: 0.00001352
Iteration 129/1000 | Loss: 0.00001352
Iteration 130/1000 | Loss: 0.00001352
Iteration 131/1000 | Loss: 0.00001352
Iteration 132/1000 | Loss: 0.00001352
Iteration 133/1000 | Loss: 0.00001352
Iteration 134/1000 | Loss: 0.00001352
Iteration 135/1000 | Loss: 0.00001352
Iteration 136/1000 | Loss: 0.00001352
Iteration 137/1000 | Loss: 0.00001352
Iteration 138/1000 | Loss: 0.00001351
Iteration 139/1000 | Loss: 0.00001351
Iteration 140/1000 | Loss: 0.00001351
Iteration 141/1000 | Loss: 0.00001351
Iteration 142/1000 | Loss: 0.00001351
Iteration 143/1000 | Loss: 0.00001351
Iteration 144/1000 | Loss: 0.00001351
Iteration 145/1000 | Loss: 0.00001351
Iteration 146/1000 | Loss: 0.00001351
Iteration 147/1000 | Loss: 0.00001351
Iteration 148/1000 | Loss: 0.00001351
Iteration 149/1000 | Loss: 0.00001351
Iteration 150/1000 | Loss: 0.00001351
Iteration 151/1000 | Loss: 0.00001351
Iteration 152/1000 | Loss: 0.00001351
Iteration 153/1000 | Loss: 0.00001351
Iteration 154/1000 | Loss: 0.00001351
Iteration 155/1000 | Loss: 0.00001351
Iteration 156/1000 | Loss: 0.00001351
Iteration 157/1000 | Loss: 0.00001350
Iteration 158/1000 | Loss: 0.00001350
Iteration 159/1000 | Loss: 0.00001350
Iteration 160/1000 | Loss: 0.00001350
Iteration 161/1000 | Loss: 0.00001350
Iteration 162/1000 | Loss: 0.00001350
Iteration 163/1000 | Loss: 0.00001350
Iteration 164/1000 | Loss: 0.00001350
Iteration 165/1000 | Loss: 0.00001350
Iteration 166/1000 | Loss: 0.00001350
Iteration 167/1000 | Loss: 0.00001350
Iteration 168/1000 | Loss: 0.00001350
Iteration 169/1000 | Loss: 0.00001350
Iteration 170/1000 | Loss: 0.00001350
Iteration 171/1000 | Loss: 0.00001350
Iteration 172/1000 | Loss: 0.00001350
Iteration 173/1000 | Loss: 0.00001350
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 173. Stopping optimization.
Last 5 losses: [1.3502452929969877e-05, 1.3502452929969877e-05, 1.3502452929969877e-05, 1.3502452929969877e-05, 1.3502452929969877e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3502452929969877e-05

Optimization complete. Final v2v error: 3.1615405082702637 mm

Highest mean error: 3.4043638706207275 mm for frame 46

Lowest mean error: 2.972806692123413 mm for frame 88

Saving results

Total time: 38.06032705307007
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1057
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00951358
Iteration 2/25 | Loss: 0.00209760
Iteration 3/25 | Loss: 0.00111619
Iteration 4/25 | Loss: 0.00107568
Iteration 5/25 | Loss: 0.00106700
Iteration 6/25 | Loss: 0.00106468
Iteration 7/25 | Loss: 0.00106458
Iteration 8/25 | Loss: 0.00106458
Iteration 9/25 | Loss: 0.00106458
Iteration 10/25 | Loss: 0.00106458
Iteration 11/25 | Loss: 0.00106458
Iteration 12/25 | Loss: 0.00106458
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010645835427567363, 0.0010645835427567363, 0.0010645835427567363, 0.0010645835427567363, 0.0010645835427567363]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010645835427567363

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.55216336
Iteration 2/25 | Loss: 0.00041521
Iteration 3/25 | Loss: 0.00041521
Iteration 4/25 | Loss: 0.00041521
Iteration 5/25 | Loss: 0.00041521
Iteration 6/25 | Loss: 0.00041521
Iteration 7/25 | Loss: 0.00041521
Iteration 8/25 | Loss: 0.00041521
Iteration 9/25 | Loss: 0.00041521
Iteration 10/25 | Loss: 0.00041521
Iteration 11/25 | Loss: 0.00041521
Iteration 12/25 | Loss: 0.00041521
Iteration 13/25 | Loss: 0.00041521
Iteration 14/25 | Loss: 0.00041521
Iteration 15/25 | Loss: 0.00041521
Iteration 16/25 | Loss: 0.00041521
Iteration 17/25 | Loss: 0.00041521
Iteration 18/25 | Loss: 0.00041521
Iteration 19/25 | Loss: 0.00041521
Iteration 20/25 | Loss: 0.00041521
Iteration 21/25 | Loss: 0.00041521
Iteration 22/25 | Loss: 0.00041521
Iteration 23/25 | Loss: 0.00041521
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.000415207032347098, 0.000415207032347098, 0.000415207032347098, 0.000415207032347098, 0.000415207032347098]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000415207032347098

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041521
Iteration 2/1000 | Loss: 0.00006178
Iteration 3/1000 | Loss: 0.00004617
Iteration 4/1000 | Loss: 0.00004142
Iteration 5/1000 | Loss: 0.00003962
Iteration 6/1000 | Loss: 0.00003832
Iteration 7/1000 | Loss: 0.00003694
Iteration 8/1000 | Loss: 0.00003617
Iteration 9/1000 | Loss: 0.00003555
Iteration 10/1000 | Loss: 0.00003508
Iteration 11/1000 | Loss: 0.00003474
Iteration 12/1000 | Loss: 0.00003440
Iteration 13/1000 | Loss: 0.00003411
Iteration 14/1000 | Loss: 0.00003392
Iteration 15/1000 | Loss: 0.00003368
Iteration 16/1000 | Loss: 0.00003345
Iteration 17/1000 | Loss: 0.00003331
Iteration 18/1000 | Loss: 0.00003314
Iteration 19/1000 | Loss: 0.00003302
Iteration 20/1000 | Loss: 0.00003293
Iteration 21/1000 | Loss: 0.00003292
Iteration 22/1000 | Loss: 0.00003290
Iteration 23/1000 | Loss: 0.00003290
Iteration 24/1000 | Loss: 0.00003286
Iteration 25/1000 | Loss: 0.00003281
Iteration 26/1000 | Loss: 0.00003281
Iteration 27/1000 | Loss: 0.00003281
Iteration 28/1000 | Loss: 0.00003281
Iteration 29/1000 | Loss: 0.00003281
Iteration 30/1000 | Loss: 0.00003280
Iteration 31/1000 | Loss: 0.00003280
Iteration 32/1000 | Loss: 0.00003280
Iteration 33/1000 | Loss: 0.00003279
Iteration 34/1000 | Loss: 0.00003279
Iteration 35/1000 | Loss: 0.00003279
Iteration 36/1000 | Loss: 0.00003279
Iteration 37/1000 | Loss: 0.00003279
Iteration 38/1000 | Loss: 0.00003279
Iteration 39/1000 | Loss: 0.00003279
Iteration 40/1000 | Loss: 0.00003278
Iteration 41/1000 | Loss: 0.00003274
Iteration 42/1000 | Loss: 0.00003272
Iteration 43/1000 | Loss: 0.00003272
Iteration 44/1000 | Loss: 0.00003272
Iteration 45/1000 | Loss: 0.00003272
Iteration 46/1000 | Loss: 0.00003272
Iteration 47/1000 | Loss: 0.00003272
Iteration 48/1000 | Loss: 0.00003272
Iteration 49/1000 | Loss: 0.00003272
Iteration 50/1000 | Loss: 0.00003272
Iteration 51/1000 | Loss: 0.00003272
Iteration 52/1000 | Loss: 0.00003271
Iteration 53/1000 | Loss: 0.00003271
Iteration 54/1000 | Loss: 0.00003271
Iteration 55/1000 | Loss: 0.00003271
Iteration 56/1000 | Loss: 0.00003270
Iteration 57/1000 | Loss: 0.00003270
Iteration 58/1000 | Loss: 0.00003270
Iteration 59/1000 | Loss: 0.00003270
Iteration 60/1000 | Loss: 0.00003270
Iteration 61/1000 | Loss: 0.00003270
Iteration 62/1000 | Loss: 0.00003270
Iteration 63/1000 | Loss: 0.00003270
Iteration 64/1000 | Loss: 0.00003270
Iteration 65/1000 | Loss: 0.00003269
Iteration 66/1000 | Loss: 0.00003269
Iteration 67/1000 | Loss: 0.00003269
Iteration 68/1000 | Loss: 0.00003269
Iteration 69/1000 | Loss: 0.00003269
Iteration 70/1000 | Loss: 0.00003268
Iteration 71/1000 | Loss: 0.00003268
Iteration 72/1000 | Loss: 0.00003267
Iteration 73/1000 | Loss: 0.00003267
Iteration 74/1000 | Loss: 0.00003267
Iteration 75/1000 | Loss: 0.00003267
Iteration 76/1000 | Loss: 0.00003267
Iteration 77/1000 | Loss: 0.00003267
Iteration 78/1000 | Loss: 0.00003267
Iteration 79/1000 | Loss: 0.00003266
Iteration 80/1000 | Loss: 0.00003266
Iteration 81/1000 | Loss: 0.00003266
Iteration 82/1000 | Loss: 0.00003266
Iteration 83/1000 | Loss: 0.00003266
Iteration 84/1000 | Loss: 0.00003266
Iteration 85/1000 | Loss: 0.00003265
Iteration 86/1000 | Loss: 0.00003265
Iteration 87/1000 | Loss: 0.00003265
Iteration 88/1000 | Loss: 0.00003265
Iteration 89/1000 | Loss: 0.00003265
Iteration 90/1000 | Loss: 0.00003265
Iteration 91/1000 | Loss: 0.00003265
Iteration 92/1000 | Loss: 0.00003264
Iteration 93/1000 | Loss: 0.00003264
Iteration 94/1000 | Loss: 0.00003264
Iteration 95/1000 | Loss: 0.00003264
Iteration 96/1000 | Loss: 0.00003264
Iteration 97/1000 | Loss: 0.00003264
Iteration 98/1000 | Loss: 0.00003264
Iteration 99/1000 | Loss: 0.00003264
Iteration 100/1000 | Loss: 0.00003264
Iteration 101/1000 | Loss: 0.00003264
Iteration 102/1000 | Loss: 0.00003264
Iteration 103/1000 | Loss: 0.00003264
Iteration 104/1000 | Loss: 0.00003264
Iteration 105/1000 | Loss: 0.00003264
Iteration 106/1000 | Loss: 0.00003264
Iteration 107/1000 | Loss: 0.00003264
Iteration 108/1000 | Loss: 0.00003264
Iteration 109/1000 | Loss: 0.00003264
Iteration 110/1000 | Loss: 0.00003264
Iteration 111/1000 | Loss: 0.00003264
Iteration 112/1000 | Loss: 0.00003264
Iteration 113/1000 | Loss: 0.00003264
Iteration 114/1000 | Loss: 0.00003264
Iteration 115/1000 | Loss: 0.00003264
Iteration 116/1000 | Loss: 0.00003264
Iteration 117/1000 | Loss: 0.00003264
Iteration 118/1000 | Loss: 0.00003264
Iteration 119/1000 | Loss: 0.00003264
Iteration 120/1000 | Loss: 0.00003264
Iteration 121/1000 | Loss: 0.00003264
Iteration 122/1000 | Loss: 0.00003264
Iteration 123/1000 | Loss: 0.00003264
Iteration 124/1000 | Loss: 0.00003264
Iteration 125/1000 | Loss: 0.00003264
Iteration 126/1000 | Loss: 0.00003264
Iteration 127/1000 | Loss: 0.00003264
Iteration 128/1000 | Loss: 0.00003264
Iteration 129/1000 | Loss: 0.00003264
Iteration 130/1000 | Loss: 0.00003264
Iteration 131/1000 | Loss: 0.00003264
Iteration 132/1000 | Loss: 0.00003264
Iteration 133/1000 | Loss: 0.00003264
Iteration 134/1000 | Loss: 0.00003264
Iteration 135/1000 | Loss: 0.00003264
Iteration 136/1000 | Loss: 0.00003264
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 136. Stopping optimization.
Last 5 losses: [3.263609323767014e-05, 3.263609323767014e-05, 3.263609323767014e-05, 3.263609323767014e-05, 3.263609323767014e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.263609323767014e-05

Optimization complete. Final v2v error: 4.797024726867676 mm

Highest mean error: 5.222013473510742 mm for frame 70

Lowest mean error: 4.381136417388916 mm for frame 183

Saving results

Total time: 51.96208453178406
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1058/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1058.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1058
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01044101
Iteration 2/25 | Loss: 0.00178426
Iteration 3/25 | Loss: 0.00118058
Iteration 4/25 | Loss: 0.00101750
Iteration 5/25 | Loss: 0.00093223
Iteration 6/25 | Loss: 0.00090248
Iteration 7/25 | Loss: 0.00089724
Iteration 8/25 | Loss: 0.00089583
Iteration 9/25 | Loss: 0.00089567
Iteration 10/25 | Loss: 0.00089567
Iteration 11/25 | Loss: 0.00089567
Iteration 12/25 | Loss: 0.00089567
Iteration 13/25 | Loss: 0.00089567
Iteration 14/25 | Loss: 0.00089567
Iteration 15/25 | Loss: 0.00089567
Iteration 16/25 | Loss: 0.00089567
Iteration 17/25 | Loss: 0.00089567
Iteration 18/25 | Loss: 0.00089567
Iteration 19/25 | Loss: 0.00089567
Iteration 20/25 | Loss: 0.00089567
Iteration 21/25 | Loss: 0.00089567
Iteration 22/25 | Loss: 0.00089567
Iteration 23/25 | Loss: 0.00089567
Iteration 24/25 | Loss: 0.00089567
Iteration 25/25 | Loss: 0.00089567

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51924849
Iteration 2/25 | Loss: 0.00064318
Iteration 3/25 | Loss: 0.00064318
Iteration 4/25 | Loss: 0.00064318
Iteration 5/25 | Loss: 0.00064318
Iteration 6/25 | Loss: 0.00064318
Iteration 7/25 | Loss: 0.00064318
Iteration 8/25 | Loss: 0.00064318
Iteration 9/25 | Loss: 0.00064318
Iteration 10/25 | Loss: 0.00064318
Iteration 11/25 | Loss: 0.00064318
Iteration 12/25 | Loss: 0.00064318
Iteration 13/25 | Loss: 0.00064318
Iteration 14/25 | Loss: 0.00064318
Iteration 15/25 | Loss: 0.00064318
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0006431783549487591, 0.0006431783549487591, 0.0006431783549487591, 0.0006431783549487591, 0.0006431783549487591]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006431783549487591

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00064318
Iteration 2/1000 | Loss: 0.00002836
Iteration 3/1000 | Loss: 0.00002165
Iteration 4/1000 | Loss: 0.00001997
Iteration 5/1000 | Loss: 0.00001929
Iteration 6/1000 | Loss: 0.00001879
Iteration 7/1000 | Loss: 0.00001838
Iteration 8/1000 | Loss: 0.00001807
Iteration 9/1000 | Loss: 0.00001782
Iteration 10/1000 | Loss: 0.00001773
Iteration 11/1000 | Loss: 0.00001773
Iteration 12/1000 | Loss: 0.00001773
Iteration 13/1000 | Loss: 0.00001764
Iteration 14/1000 | Loss: 0.00001754
Iteration 15/1000 | Loss: 0.00001752
Iteration 16/1000 | Loss: 0.00001747
Iteration 17/1000 | Loss: 0.00001747
Iteration 18/1000 | Loss: 0.00001747
Iteration 19/1000 | Loss: 0.00001747
Iteration 20/1000 | Loss: 0.00001746
Iteration 21/1000 | Loss: 0.00001746
Iteration 22/1000 | Loss: 0.00001746
Iteration 23/1000 | Loss: 0.00001745
Iteration 24/1000 | Loss: 0.00001744
Iteration 25/1000 | Loss: 0.00001744
Iteration 26/1000 | Loss: 0.00001743
Iteration 27/1000 | Loss: 0.00001743
Iteration 28/1000 | Loss: 0.00001743
Iteration 29/1000 | Loss: 0.00001743
Iteration 30/1000 | Loss: 0.00001743
Iteration 31/1000 | Loss: 0.00001742
Iteration 32/1000 | Loss: 0.00001742
Iteration 33/1000 | Loss: 0.00001742
Iteration 34/1000 | Loss: 0.00001741
Iteration 35/1000 | Loss: 0.00001741
Iteration 36/1000 | Loss: 0.00001741
Iteration 37/1000 | Loss: 0.00001741
Iteration 38/1000 | Loss: 0.00001741
Iteration 39/1000 | Loss: 0.00001741
Iteration 40/1000 | Loss: 0.00001741
Iteration 41/1000 | Loss: 0.00001741
Iteration 42/1000 | Loss: 0.00001741
Iteration 43/1000 | Loss: 0.00001741
Iteration 44/1000 | Loss: 0.00001741
Iteration 45/1000 | Loss: 0.00001741
Iteration 46/1000 | Loss: 0.00001740
Iteration 47/1000 | Loss: 0.00001740
Iteration 48/1000 | Loss: 0.00001740
Iteration 49/1000 | Loss: 0.00001740
Iteration 50/1000 | Loss: 0.00001740
Iteration 51/1000 | Loss: 0.00001740
Iteration 52/1000 | Loss: 0.00001740
Iteration 53/1000 | Loss: 0.00001740
Iteration 54/1000 | Loss: 0.00001740
Iteration 55/1000 | Loss: 0.00001740
Iteration 56/1000 | Loss: 0.00001740
Iteration 57/1000 | Loss: 0.00001739
Iteration 58/1000 | Loss: 0.00001739
Iteration 59/1000 | Loss: 0.00001739
Iteration 60/1000 | Loss: 0.00001739
Iteration 61/1000 | Loss: 0.00001739
Iteration 62/1000 | Loss: 0.00001739
Iteration 63/1000 | Loss: 0.00001739
Iteration 64/1000 | Loss: 0.00001739
Iteration 65/1000 | Loss: 0.00001739
Iteration 66/1000 | Loss: 0.00001739
Iteration 67/1000 | Loss: 0.00001739
Iteration 68/1000 | Loss: 0.00001739
Iteration 69/1000 | Loss: 0.00001739
Iteration 70/1000 | Loss: 0.00001739
Iteration 71/1000 | Loss: 0.00001739
Iteration 72/1000 | Loss: 0.00001739
Iteration 73/1000 | Loss: 0.00001738
Iteration 74/1000 | Loss: 0.00001738
Iteration 75/1000 | Loss: 0.00001738
Iteration 76/1000 | Loss: 0.00001738
Iteration 77/1000 | Loss: 0.00001738
Iteration 78/1000 | Loss: 0.00001738
Iteration 79/1000 | Loss: 0.00001738
Iteration 80/1000 | Loss: 0.00001737
Iteration 81/1000 | Loss: 0.00001737
Iteration 82/1000 | Loss: 0.00001737
Iteration 83/1000 | Loss: 0.00001737
Iteration 84/1000 | Loss: 0.00001737
Iteration 85/1000 | Loss: 0.00001737
Iteration 86/1000 | Loss: 0.00001737
Iteration 87/1000 | Loss: 0.00001737
Iteration 88/1000 | Loss: 0.00001737
Iteration 89/1000 | Loss: 0.00001737
Iteration 90/1000 | Loss: 0.00001737
Iteration 91/1000 | Loss: 0.00001737
Iteration 92/1000 | Loss: 0.00001737
Iteration 93/1000 | Loss: 0.00001737
Iteration 94/1000 | Loss: 0.00001737
Iteration 95/1000 | Loss: 0.00001737
Iteration 96/1000 | Loss: 0.00001737
Iteration 97/1000 | Loss: 0.00001737
Iteration 98/1000 | Loss: 0.00001736
Iteration 99/1000 | Loss: 0.00001736
Iteration 100/1000 | Loss: 0.00001736
Iteration 101/1000 | Loss: 0.00001736
Iteration 102/1000 | Loss: 0.00001736
Iteration 103/1000 | Loss: 0.00001736
Iteration 104/1000 | Loss: 0.00001736
Iteration 105/1000 | Loss: 0.00001736
Iteration 106/1000 | Loss: 0.00001736
Iteration 107/1000 | Loss: 0.00001736
Iteration 108/1000 | Loss: 0.00001736
Iteration 109/1000 | Loss: 0.00001736
Iteration 110/1000 | Loss: 0.00001736
Iteration 111/1000 | Loss: 0.00001736
Iteration 112/1000 | Loss: 0.00001736
Iteration 113/1000 | Loss: 0.00001736
Iteration 114/1000 | Loss: 0.00001736
Iteration 115/1000 | Loss: 0.00001736
Iteration 116/1000 | Loss: 0.00001736
Iteration 117/1000 | Loss: 0.00001736
Iteration 118/1000 | Loss: 0.00001736
Iteration 119/1000 | Loss: 0.00001736
Iteration 120/1000 | Loss: 0.00001736
Iteration 121/1000 | Loss: 0.00001736
Iteration 122/1000 | Loss: 0.00001736
Iteration 123/1000 | Loss: 0.00001736
Iteration 124/1000 | Loss: 0.00001736
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [1.7362384824082255e-05, 1.7362384824082255e-05, 1.7362384824082255e-05, 1.7362384824082255e-05, 1.7362384824082255e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7362384824082255e-05

Optimization complete. Final v2v error: 3.4300901889801025 mm

Highest mean error: 3.525416135787964 mm for frame 21

Lowest mean error: 3.360835552215576 mm for frame 106

Saving results

Total time: 36.44344687461853
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1091/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1091.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1091
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00821228
Iteration 2/25 | Loss: 0.00110824
Iteration 3/25 | Loss: 0.00087924
Iteration 4/25 | Loss: 0.00082413
Iteration 5/25 | Loss: 0.00081048
Iteration 6/25 | Loss: 0.00080707
Iteration 7/25 | Loss: 0.00080685
Iteration 8/25 | Loss: 0.00080685
Iteration 9/25 | Loss: 0.00080685
Iteration 10/25 | Loss: 0.00080685
Iteration 11/25 | Loss: 0.00080685
Iteration 12/25 | Loss: 0.00080685
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008068541064858437, 0.0008068541064858437, 0.0008068541064858437, 0.0008068541064858437, 0.0008068541064858437]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008068541064858437

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52564538
Iteration 2/25 | Loss: 0.00059535
Iteration 3/25 | Loss: 0.00059535
Iteration 4/25 | Loss: 0.00059535
Iteration 5/25 | Loss: 0.00059535
Iteration 6/25 | Loss: 0.00059535
Iteration 7/25 | Loss: 0.00059535
Iteration 8/25 | Loss: 0.00059535
Iteration 9/25 | Loss: 0.00059535
Iteration 10/25 | Loss: 0.00059535
Iteration 11/25 | Loss: 0.00059535
Iteration 12/25 | Loss: 0.00059535
Iteration 13/25 | Loss: 0.00059535
Iteration 14/25 | Loss: 0.00059535
Iteration 15/25 | Loss: 0.00059535
Iteration 16/25 | Loss: 0.00059535
Iteration 17/25 | Loss: 0.00059535
Iteration 18/25 | Loss: 0.00059535
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005953478976152837, 0.0005953478976152837, 0.0005953478976152837, 0.0005953478976152837, 0.0005953478976152837]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005953478976152837

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059535
Iteration 2/1000 | Loss: 0.00002683
Iteration 3/1000 | Loss: 0.00001668
Iteration 4/1000 | Loss: 0.00001498
Iteration 5/1000 | Loss: 0.00001387
Iteration 6/1000 | Loss: 0.00001305
Iteration 7/1000 | Loss: 0.00001269
Iteration 8/1000 | Loss: 0.00001239
Iteration 9/1000 | Loss: 0.00001214
Iteration 10/1000 | Loss: 0.00001194
Iteration 11/1000 | Loss: 0.00001188
Iteration 12/1000 | Loss: 0.00001184
Iteration 13/1000 | Loss: 0.00001181
Iteration 14/1000 | Loss: 0.00001163
Iteration 15/1000 | Loss: 0.00001163
Iteration 16/1000 | Loss: 0.00001161
Iteration 17/1000 | Loss: 0.00001160
Iteration 18/1000 | Loss: 0.00001160
Iteration 19/1000 | Loss: 0.00001159
Iteration 20/1000 | Loss: 0.00001158
Iteration 21/1000 | Loss: 0.00001157
Iteration 22/1000 | Loss: 0.00001157
Iteration 23/1000 | Loss: 0.00001154
Iteration 24/1000 | Loss: 0.00001152
Iteration 25/1000 | Loss: 0.00001152
Iteration 26/1000 | Loss: 0.00001151
Iteration 27/1000 | Loss: 0.00001151
Iteration 28/1000 | Loss: 0.00001150
Iteration 29/1000 | Loss: 0.00001149
Iteration 30/1000 | Loss: 0.00001149
Iteration 31/1000 | Loss: 0.00001146
Iteration 32/1000 | Loss: 0.00001145
Iteration 33/1000 | Loss: 0.00001144
Iteration 34/1000 | Loss: 0.00001144
Iteration 35/1000 | Loss: 0.00001144
Iteration 36/1000 | Loss: 0.00001143
Iteration 37/1000 | Loss: 0.00001143
Iteration 38/1000 | Loss: 0.00001143
Iteration 39/1000 | Loss: 0.00001143
Iteration 40/1000 | Loss: 0.00001142
Iteration 41/1000 | Loss: 0.00001142
Iteration 42/1000 | Loss: 0.00001142
Iteration 43/1000 | Loss: 0.00001142
Iteration 44/1000 | Loss: 0.00001142
Iteration 45/1000 | Loss: 0.00001142
Iteration 46/1000 | Loss: 0.00001142
Iteration 47/1000 | Loss: 0.00001141
Iteration 48/1000 | Loss: 0.00001141
Iteration 49/1000 | Loss: 0.00001141
Iteration 50/1000 | Loss: 0.00001141
Iteration 51/1000 | Loss: 0.00001141
Iteration 52/1000 | Loss: 0.00001141
Iteration 53/1000 | Loss: 0.00001141
Iteration 54/1000 | Loss: 0.00001141
Iteration 55/1000 | Loss: 0.00001141
Iteration 56/1000 | Loss: 0.00001140
Iteration 57/1000 | Loss: 0.00001140
Iteration 58/1000 | Loss: 0.00001140
Iteration 59/1000 | Loss: 0.00001140
Iteration 60/1000 | Loss: 0.00001140
Iteration 61/1000 | Loss: 0.00001140
Iteration 62/1000 | Loss: 0.00001140
Iteration 63/1000 | Loss: 0.00001139
Iteration 64/1000 | Loss: 0.00001139
Iteration 65/1000 | Loss: 0.00001139
Iteration 66/1000 | Loss: 0.00001139
Iteration 67/1000 | Loss: 0.00001139
Iteration 68/1000 | Loss: 0.00001139
Iteration 69/1000 | Loss: 0.00001139
Iteration 70/1000 | Loss: 0.00001138
Iteration 71/1000 | Loss: 0.00001138
Iteration 72/1000 | Loss: 0.00001138
Iteration 73/1000 | Loss: 0.00001138
Iteration 74/1000 | Loss: 0.00001138
Iteration 75/1000 | Loss: 0.00001138
Iteration 76/1000 | Loss: 0.00001138
Iteration 77/1000 | Loss: 0.00001138
Iteration 78/1000 | Loss: 0.00001138
Iteration 79/1000 | Loss: 0.00001137
Iteration 80/1000 | Loss: 0.00001137
Iteration 81/1000 | Loss: 0.00001137
Iteration 82/1000 | Loss: 0.00001137
Iteration 83/1000 | Loss: 0.00001136
Iteration 84/1000 | Loss: 0.00001136
Iteration 85/1000 | Loss: 0.00001136
Iteration 86/1000 | Loss: 0.00001135
Iteration 87/1000 | Loss: 0.00001135
Iteration 88/1000 | Loss: 0.00001135
Iteration 89/1000 | Loss: 0.00001135
Iteration 90/1000 | Loss: 0.00001134
Iteration 91/1000 | Loss: 0.00001134
Iteration 92/1000 | Loss: 0.00001134
Iteration 93/1000 | Loss: 0.00001134
Iteration 94/1000 | Loss: 0.00001134
Iteration 95/1000 | Loss: 0.00001133
Iteration 96/1000 | Loss: 0.00001133
Iteration 97/1000 | Loss: 0.00001133
Iteration 98/1000 | Loss: 0.00001133
Iteration 99/1000 | Loss: 0.00001133
Iteration 100/1000 | Loss: 0.00001133
Iteration 101/1000 | Loss: 0.00001133
Iteration 102/1000 | Loss: 0.00001133
Iteration 103/1000 | Loss: 0.00001133
Iteration 104/1000 | Loss: 0.00001133
Iteration 105/1000 | Loss: 0.00001133
Iteration 106/1000 | Loss: 0.00001133
Iteration 107/1000 | Loss: 0.00001133
Iteration 108/1000 | Loss: 0.00001133
Iteration 109/1000 | Loss: 0.00001133
Iteration 110/1000 | Loss: 0.00001133
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [1.1326184903737158e-05, 1.1326184903737158e-05, 1.1326184903737158e-05, 1.1326184903737158e-05, 1.1326184903737158e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1326184903737158e-05

Optimization complete. Final v2v error: 2.8757951259613037 mm

Highest mean error: 3.0092194080352783 mm for frame 107

Lowest mean error: 2.785707473754883 mm for frame 206

Saving results

Total time: 37.86421990394592
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01055469
Iteration 2/25 | Loss: 0.00193366
Iteration 3/25 | Loss: 0.00157798
Iteration 4/25 | Loss: 0.00096221
Iteration 5/25 | Loss: 0.00088917
Iteration 6/25 | Loss: 0.00087179
Iteration 7/25 | Loss: 0.00087084
Iteration 8/25 | Loss: 0.00087062
Iteration 9/25 | Loss: 0.00086692
Iteration 10/25 | Loss: 0.00086495
Iteration 11/25 | Loss: 0.00086428
Iteration 12/25 | Loss: 0.00086410
Iteration 13/25 | Loss: 0.00086399
Iteration 14/25 | Loss: 0.00086397
Iteration 15/25 | Loss: 0.00086397
Iteration 16/25 | Loss: 0.00086397
Iteration 17/25 | Loss: 0.00086397
Iteration 18/25 | Loss: 0.00086396
Iteration 19/25 | Loss: 0.00086396
Iteration 20/25 | Loss: 0.00086396
Iteration 21/25 | Loss: 0.00086396
Iteration 22/25 | Loss: 0.00086396
Iteration 23/25 | Loss: 0.00086396
Iteration 24/25 | Loss: 0.00086395
Iteration 25/25 | Loss: 0.00086395

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52924407
Iteration 2/25 | Loss: 0.00061858
Iteration 3/25 | Loss: 0.00061857
Iteration 4/25 | Loss: 0.00061857
Iteration 5/25 | Loss: 0.00061857
Iteration 6/25 | Loss: 0.00061857
Iteration 7/25 | Loss: 0.00061857
Iteration 8/25 | Loss: 0.00061857
Iteration 9/25 | Loss: 0.00061857
Iteration 10/25 | Loss: 0.00061857
Iteration 11/25 | Loss: 0.00061857
Iteration 12/25 | Loss: 0.00061857
Iteration 13/25 | Loss: 0.00061857
Iteration 14/25 | Loss: 0.00061857
Iteration 15/25 | Loss: 0.00061857
Iteration 16/25 | Loss: 0.00061857
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006185711827129126, 0.0006185711827129126, 0.0006185711827129126, 0.0006185711827129126, 0.0006185711827129126]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006185711827129126

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061857
Iteration 2/1000 | Loss: 0.00020921
Iteration 3/1000 | Loss: 0.00049378
Iteration 4/1000 | Loss: 0.00052056
Iteration 5/1000 | Loss: 0.00017839
Iteration 6/1000 | Loss: 0.00012262
Iteration 7/1000 | Loss: 0.00003424
Iteration 8/1000 | Loss: 0.00004259
Iteration 9/1000 | Loss: 0.00002129
Iteration 10/1000 | Loss: 0.00031561
Iteration 11/1000 | Loss: 0.00017499
Iteration 12/1000 | Loss: 0.00003386
Iteration 13/1000 | Loss: 0.00004131
Iteration 14/1000 | Loss: 0.00002424
Iteration 15/1000 | Loss: 0.00002015
Iteration 16/1000 | Loss: 0.00007024
Iteration 17/1000 | Loss: 0.00001732
Iteration 18/1000 | Loss: 0.00001634
Iteration 19/1000 | Loss: 0.00004224
Iteration 20/1000 | Loss: 0.00001576
Iteration 21/1000 | Loss: 0.00006487
Iteration 22/1000 | Loss: 0.00002750
Iteration 23/1000 | Loss: 0.00001523
Iteration 24/1000 | Loss: 0.00001522
Iteration 25/1000 | Loss: 0.00008677
Iteration 26/1000 | Loss: 0.00001495
Iteration 27/1000 | Loss: 0.00001481
Iteration 28/1000 | Loss: 0.00001481
Iteration 29/1000 | Loss: 0.00001480
Iteration 30/1000 | Loss: 0.00001480
Iteration 31/1000 | Loss: 0.00001480
Iteration 32/1000 | Loss: 0.00001480
Iteration 33/1000 | Loss: 0.00001480
Iteration 34/1000 | Loss: 0.00001480
Iteration 35/1000 | Loss: 0.00001480
Iteration 36/1000 | Loss: 0.00001480
Iteration 37/1000 | Loss: 0.00001480
Iteration 38/1000 | Loss: 0.00001480
Iteration 39/1000 | Loss: 0.00001479
Iteration 40/1000 | Loss: 0.00001479
Iteration 41/1000 | Loss: 0.00001477
Iteration 42/1000 | Loss: 0.00013000
Iteration 43/1000 | Loss: 0.00001469
Iteration 44/1000 | Loss: 0.00001462
Iteration 45/1000 | Loss: 0.00008677
Iteration 46/1000 | Loss: 0.00001475
Iteration 47/1000 | Loss: 0.00001456
Iteration 48/1000 | Loss: 0.00001456
Iteration 49/1000 | Loss: 0.00001456
Iteration 50/1000 | Loss: 0.00001455
Iteration 51/1000 | Loss: 0.00001455
Iteration 52/1000 | Loss: 0.00001454
Iteration 53/1000 | Loss: 0.00001453
Iteration 54/1000 | Loss: 0.00001453
Iteration 55/1000 | Loss: 0.00001453
Iteration 56/1000 | Loss: 0.00001453
Iteration 57/1000 | Loss: 0.00001452
Iteration 58/1000 | Loss: 0.00001452
Iteration 59/1000 | Loss: 0.00001452
Iteration 60/1000 | Loss: 0.00001452
Iteration 61/1000 | Loss: 0.00001452
Iteration 62/1000 | Loss: 0.00001452
Iteration 63/1000 | Loss: 0.00001452
Iteration 64/1000 | Loss: 0.00001452
Iteration 65/1000 | Loss: 0.00001451
Iteration 66/1000 | Loss: 0.00001449
Iteration 67/1000 | Loss: 0.00001449
Iteration 68/1000 | Loss: 0.00001449
Iteration 69/1000 | Loss: 0.00001448
Iteration 70/1000 | Loss: 0.00001448
Iteration 71/1000 | Loss: 0.00001448
Iteration 72/1000 | Loss: 0.00001448
Iteration 73/1000 | Loss: 0.00001448
Iteration 74/1000 | Loss: 0.00001448
Iteration 75/1000 | Loss: 0.00001447
Iteration 76/1000 | Loss: 0.00001447
Iteration 77/1000 | Loss: 0.00001447
Iteration 78/1000 | Loss: 0.00001447
Iteration 79/1000 | Loss: 0.00001446
Iteration 80/1000 | Loss: 0.00001446
Iteration 81/1000 | Loss: 0.00001446
Iteration 82/1000 | Loss: 0.00001445
Iteration 83/1000 | Loss: 0.00001445
Iteration 84/1000 | Loss: 0.00001445
Iteration 85/1000 | Loss: 0.00001445
Iteration 86/1000 | Loss: 0.00001445
Iteration 87/1000 | Loss: 0.00001445
Iteration 88/1000 | Loss: 0.00001444
Iteration 89/1000 | Loss: 0.00001444
Iteration 90/1000 | Loss: 0.00001444
Iteration 91/1000 | Loss: 0.00001444
Iteration 92/1000 | Loss: 0.00001444
Iteration 93/1000 | Loss: 0.00001444
Iteration 94/1000 | Loss: 0.00001444
Iteration 95/1000 | Loss: 0.00001444
Iteration 96/1000 | Loss: 0.00001444
Iteration 97/1000 | Loss: 0.00001444
Iteration 98/1000 | Loss: 0.00001444
Iteration 99/1000 | Loss: 0.00001444
Iteration 100/1000 | Loss: 0.00001444
Iteration 101/1000 | Loss: 0.00001444
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [1.4439838196267374e-05, 1.4439838196267374e-05, 1.4439838196267374e-05, 1.4439838196267374e-05, 1.4439838196267374e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4439838196267374e-05

Optimization complete. Final v2v error: 3.261885404586792 mm

Highest mean error: 3.847900390625 mm for frame 57

Lowest mean error: 2.960698127746582 mm for frame 134

Saving results

Total time: 68.10737419128418
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1029/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1029.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1029
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00843374
Iteration 2/25 | Loss: 0.00094994
Iteration 3/25 | Loss: 0.00082254
Iteration 4/25 | Loss: 0.00080442
Iteration 5/25 | Loss: 0.00079997
Iteration 6/25 | Loss: 0.00079864
Iteration 7/25 | Loss: 0.00079864
Iteration 8/25 | Loss: 0.00079864
Iteration 9/25 | Loss: 0.00079864
Iteration 10/25 | Loss: 0.00079864
Iteration 11/25 | Loss: 0.00079864
Iteration 12/25 | Loss: 0.00079864
Iteration 13/25 | Loss: 0.00079864
Iteration 14/25 | Loss: 0.00079864
Iteration 15/25 | Loss: 0.00079864
Iteration 16/25 | Loss: 0.00079864
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007986410055309534, 0.0007986410055309534, 0.0007986410055309534, 0.0007986410055309534, 0.0007986410055309534]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007986410055309534

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51555824
Iteration 2/25 | Loss: 0.00055736
Iteration 3/25 | Loss: 0.00055736
Iteration 4/25 | Loss: 0.00055736
Iteration 5/25 | Loss: 0.00055736
Iteration 6/25 | Loss: 0.00055736
Iteration 7/25 | Loss: 0.00055736
Iteration 8/25 | Loss: 0.00055736
Iteration 9/25 | Loss: 0.00055735
Iteration 10/25 | Loss: 0.00055735
Iteration 11/25 | Loss: 0.00055735
Iteration 12/25 | Loss: 0.00055735
Iteration 13/25 | Loss: 0.00055735
Iteration 14/25 | Loss: 0.00055735
Iteration 15/25 | Loss: 0.00055735
Iteration 16/25 | Loss: 0.00055735
Iteration 17/25 | Loss: 0.00055735
Iteration 18/25 | Loss: 0.00055735
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005573542439378798, 0.0005573542439378798, 0.0005573542439378798, 0.0005573542439378798, 0.0005573542439378798]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005573542439378798

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055735
Iteration 2/1000 | Loss: 0.00002284
Iteration 3/1000 | Loss: 0.00001549
Iteration 4/1000 | Loss: 0.00001412
Iteration 5/1000 | Loss: 0.00001303
Iteration 6/1000 | Loss: 0.00001241
Iteration 7/1000 | Loss: 0.00001210
Iteration 8/1000 | Loss: 0.00001196
Iteration 9/1000 | Loss: 0.00001179
Iteration 10/1000 | Loss: 0.00001177
Iteration 11/1000 | Loss: 0.00001174
Iteration 12/1000 | Loss: 0.00001167
Iteration 13/1000 | Loss: 0.00001149
Iteration 14/1000 | Loss: 0.00001147
Iteration 15/1000 | Loss: 0.00001146
Iteration 16/1000 | Loss: 0.00001138
Iteration 17/1000 | Loss: 0.00001134
Iteration 18/1000 | Loss: 0.00001134
Iteration 19/1000 | Loss: 0.00001132
Iteration 20/1000 | Loss: 0.00001129
Iteration 21/1000 | Loss: 0.00001128
Iteration 22/1000 | Loss: 0.00001128
Iteration 23/1000 | Loss: 0.00001127
Iteration 24/1000 | Loss: 0.00001124
Iteration 25/1000 | Loss: 0.00001123
Iteration 26/1000 | Loss: 0.00001122
Iteration 27/1000 | Loss: 0.00001122
Iteration 28/1000 | Loss: 0.00001122
Iteration 29/1000 | Loss: 0.00001121
Iteration 30/1000 | Loss: 0.00001120
Iteration 31/1000 | Loss: 0.00001120
Iteration 32/1000 | Loss: 0.00001120
Iteration 33/1000 | Loss: 0.00001120
Iteration 34/1000 | Loss: 0.00001119
Iteration 35/1000 | Loss: 0.00001119
Iteration 36/1000 | Loss: 0.00001119
Iteration 37/1000 | Loss: 0.00001119
Iteration 38/1000 | Loss: 0.00001118
Iteration 39/1000 | Loss: 0.00001118
Iteration 40/1000 | Loss: 0.00001116
Iteration 41/1000 | Loss: 0.00001115
Iteration 42/1000 | Loss: 0.00001115
Iteration 43/1000 | Loss: 0.00001115
Iteration 44/1000 | Loss: 0.00001115
Iteration 45/1000 | Loss: 0.00001114
Iteration 46/1000 | Loss: 0.00001113
Iteration 47/1000 | Loss: 0.00001108
Iteration 48/1000 | Loss: 0.00001104
Iteration 49/1000 | Loss: 0.00001104
Iteration 50/1000 | Loss: 0.00001104
Iteration 51/1000 | Loss: 0.00001104
Iteration 52/1000 | Loss: 0.00001103
Iteration 53/1000 | Loss: 0.00001102
Iteration 54/1000 | Loss: 0.00001102
Iteration 55/1000 | Loss: 0.00001102
Iteration 56/1000 | Loss: 0.00001101
Iteration 57/1000 | Loss: 0.00001101
Iteration 58/1000 | Loss: 0.00001101
Iteration 59/1000 | Loss: 0.00001100
Iteration 60/1000 | Loss: 0.00001100
Iteration 61/1000 | Loss: 0.00001099
Iteration 62/1000 | Loss: 0.00001099
Iteration 63/1000 | Loss: 0.00001099
Iteration 64/1000 | Loss: 0.00001099
Iteration 65/1000 | Loss: 0.00001099
Iteration 66/1000 | Loss: 0.00001099
Iteration 67/1000 | Loss: 0.00001098
Iteration 68/1000 | Loss: 0.00001098
Iteration 69/1000 | Loss: 0.00001098
Iteration 70/1000 | Loss: 0.00001098
Iteration 71/1000 | Loss: 0.00001098
Iteration 72/1000 | Loss: 0.00001098
Iteration 73/1000 | Loss: 0.00001098
Iteration 74/1000 | Loss: 0.00001098
Iteration 75/1000 | Loss: 0.00001098
Iteration 76/1000 | Loss: 0.00001098
Iteration 77/1000 | Loss: 0.00001098
Iteration 78/1000 | Loss: 0.00001098
Iteration 79/1000 | Loss: 0.00001098
Iteration 80/1000 | Loss: 0.00001097
Iteration 81/1000 | Loss: 0.00001097
Iteration 82/1000 | Loss: 0.00001097
Iteration 83/1000 | Loss: 0.00001097
Iteration 84/1000 | Loss: 0.00001097
Iteration 85/1000 | Loss: 0.00001096
Iteration 86/1000 | Loss: 0.00001096
Iteration 87/1000 | Loss: 0.00001096
Iteration 88/1000 | Loss: 0.00001095
Iteration 89/1000 | Loss: 0.00001095
Iteration 90/1000 | Loss: 0.00001095
Iteration 91/1000 | Loss: 0.00001095
Iteration 92/1000 | Loss: 0.00001094
Iteration 93/1000 | Loss: 0.00001094
Iteration 94/1000 | Loss: 0.00001094
Iteration 95/1000 | Loss: 0.00001094
Iteration 96/1000 | Loss: 0.00001094
Iteration 97/1000 | Loss: 0.00001094
Iteration 98/1000 | Loss: 0.00001094
Iteration 99/1000 | Loss: 0.00001094
Iteration 100/1000 | Loss: 0.00001094
Iteration 101/1000 | Loss: 0.00001094
Iteration 102/1000 | Loss: 0.00001094
Iteration 103/1000 | Loss: 0.00001094
Iteration 104/1000 | Loss: 0.00001094
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 104. Stopping optimization.
Last 5 losses: [1.094055642170133e-05, 1.094055642170133e-05, 1.094055642170133e-05, 1.094055642170133e-05, 1.094055642170133e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.094055642170133e-05

Optimization complete. Final v2v error: 2.7949140071868896 mm

Highest mean error: 3.034487009048462 mm for frame 104

Lowest mean error: 2.6241843700408936 mm for frame 222

Saving results

Total time: 37.20566415786743
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1033/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1033.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1033
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00491140
Iteration 2/25 | Loss: 0.00100627
Iteration 3/25 | Loss: 0.00086932
Iteration 4/25 | Loss: 0.00083954
Iteration 5/25 | Loss: 0.00083122
Iteration 6/25 | Loss: 0.00082928
Iteration 7/25 | Loss: 0.00082892
Iteration 8/25 | Loss: 0.00082892
Iteration 9/25 | Loss: 0.00082892
Iteration 10/25 | Loss: 0.00082888
Iteration 11/25 | Loss: 0.00082888
Iteration 12/25 | Loss: 0.00082888
Iteration 13/25 | Loss: 0.00082888
Iteration 14/25 | Loss: 0.00082888
Iteration 15/25 | Loss: 0.00082888
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008288808749057353, 0.0008288808749057353, 0.0008288808749057353, 0.0008288808749057353, 0.0008288808749057353]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008288808749057353

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56537640
Iteration 2/25 | Loss: 0.00058748
Iteration 3/25 | Loss: 0.00058747
Iteration 4/25 | Loss: 0.00058747
Iteration 5/25 | Loss: 0.00058746
Iteration 6/25 | Loss: 0.00058746
Iteration 7/25 | Loss: 0.00058746
Iteration 8/25 | Loss: 0.00058746
Iteration 9/25 | Loss: 0.00058746
Iteration 10/25 | Loss: 0.00058746
Iteration 11/25 | Loss: 0.00058746
Iteration 12/25 | Loss: 0.00058746
Iteration 13/25 | Loss: 0.00058746
Iteration 14/25 | Loss: 0.00058746
Iteration 15/25 | Loss: 0.00058746
Iteration 16/25 | Loss: 0.00058746
Iteration 17/25 | Loss: 0.00058746
Iteration 18/25 | Loss: 0.00058746
Iteration 19/25 | Loss: 0.00058746
Iteration 20/25 | Loss: 0.00058746
Iteration 21/25 | Loss: 0.00058746
Iteration 22/25 | Loss: 0.00058746
Iteration 23/25 | Loss: 0.00058746
Iteration 24/25 | Loss: 0.00058746
Iteration 25/25 | Loss: 0.00058746
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0005874625639989972, 0.0005874625639989972, 0.0005874625639989972, 0.0005874625639989972, 0.0005874625639989972]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005874625639989972

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00058746
Iteration 2/1000 | Loss: 0.00002614
Iteration 3/1000 | Loss: 0.00001988
Iteration 4/1000 | Loss: 0.00001849
Iteration 5/1000 | Loss: 0.00001741
Iteration 6/1000 | Loss: 0.00001694
Iteration 7/1000 | Loss: 0.00001655
Iteration 8/1000 | Loss: 0.00001628
Iteration 9/1000 | Loss: 0.00001625
Iteration 10/1000 | Loss: 0.00001600
Iteration 11/1000 | Loss: 0.00001589
Iteration 12/1000 | Loss: 0.00001580
Iteration 13/1000 | Loss: 0.00001576
Iteration 14/1000 | Loss: 0.00001570
Iteration 15/1000 | Loss: 0.00001567
Iteration 16/1000 | Loss: 0.00001567
Iteration 17/1000 | Loss: 0.00001566
Iteration 18/1000 | Loss: 0.00001565
Iteration 19/1000 | Loss: 0.00001565
Iteration 20/1000 | Loss: 0.00001564
Iteration 21/1000 | Loss: 0.00001564
Iteration 22/1000 | Loss: 0.00001561
Iteration 23/1000 | Loss: 0.00001559
Iteration 24/1000 | Loss: 0.00001558
Iteration 25/1000 | Loss: 0.00001558
Iteration 26/1000 | Loss: 0.00001557
Iteration 27/1000 | Loss: 0.00001557
Iteration 28/1000 | Loss: 0.00001557
Iteration 29/1000 | Loss: 0.00001557
Iteration 30/1000 | Loss: 0.00001556
Iteration 31/1000 | Loss: 0.00001556
Iteration 32/1000 | Loss: 0.00001555
Iteration 33/1000 | Loss: 0.00001555
Iteration 34/1000 | Loss: 0.00001555
Iteration 35/1000 | Loss: 0.00001554
Iteration 36/1000 | Loss: 0.00001554
Iteration 37/1000 | Loss: 0.00001553
Iteration 38/1000 | Loss: 0.00001553
Iteration 39/1000 | Loss: 0.00001553
Iteration 40/1000 | Loss: 0.00001552
Iteration 41/1000 | Loss: 0.00001552
Iteration 42/1000 | Loss: 0.00001552
Iteration 43/1000 | Loss: 0.00001552
Iteration 44/1000 | Loss: 0.00001551
Iteration 45/1000 | Loss: 0.00001551
Iteration 46/1000 | Loss: 0.00001550
Iteration 47/1000 | Loss: 0.00001550
Iteration 48/1000 | Loss: 0.00001550
Iteration 49/1000 | Loss: 0.00001550
Iteration 50/1000 | Loss: 0.00001549
Iteration 51/1000 | Loss: 0.00001549
Iteration 52/1000 | Loss: 0.00001549
Iteration 53/1000 | Loss: 0.00001549
Iteration 54/1000 | Loss: 0.00001549
Iteration 55/1000 | Loss: 0.00001549
Iteration 56/1000 | Loss: 0.00001549
Iteration 57/1000 | Loss: 0.00001548
Iteration 58/1000 | Loss: 0.00001548
Iteration 59/1000 | Loss: 0.00001547
Iteration 60/1000 | Loss: 0.00001547
Iteration 61/1000 | Loss: 0.00001546
Iteration 62/1000 | Loss: 0.00001546
Iteration 63/1000 | Loss: 0.00001546
Iteration 64/1000 | Loss: 0.00001545
Iteration 65/1000 | Loss: 0.00001545
Iteration 66/1000 | Loss: 0.00001545
Iteration 67/1000 | Loss: 0.00001544
Iteration 68/1000 | Loss: 0.00001542
Iteration 69/1000 | Loss: 0.00001542
Iteration 70/1000 | Loss: 0.00001542
Iteration 71/1000 | Loss: 0.00001542
Iteration 72/1000 | Loss: 0.00001542
Iteration 73/1000 | Loss: 0.00001542
Iteration 74/1000 | Loss: 0.00001542
Iteration 75/1000 | Loss: 0.00001541
Iteration 76/1000 | Loss: 0.00001541
Iteration 77/1000 | Loss: 0.00001540
Iteration 78/1000 | Loss: 0.00001540
Iteration 79/1000 | Loss: 0.00001540
Iteration 80/1000 | Loss: 0.00001539
Iteration 81/1000 | Loss: 0.00001539
Iteration 82/1000 | Loss: 0.00001538
Iteration 83/1000 | Loss: 0.00001538
Iteration 84/1000 | Loss: 0.00001538
Iteration 85/1000 | Loss: 0.00001537
Iteration 86/1000 | Loss: 0.00001537
Iteration 87/1000 | Loss: 0.00001537
Iteration 88/1000 | Loss: 0.00001537
Iteration 89/1000 | Loss: 0.00001537
Iteration 90/1000 | Loss: 0.00001536
Iteration 91/1000 | Loss: 0.00001536
Iteration 92/1000 | Loss: 0.00001536
Iteration 93/1000 | Loss: 0.00001536
Iteration 94/1000 | Loss: 0.00001536
Iteration 95/1000 | Loss: 0.00001535
Iteration 96/1000 | Loss: 0.00001535
Iteration 97/1000 | Loss: 0.00001535
Iteration 98/1000 | Loss: 0.00001535
Iteration 99/1000 | Loss: 0.00001535
Iteration 100/1000 | Loss: 0.00001535
Iteration 101/1000 | Loss: 0.00001535
Iteration 102/1000 | Loss: 0.00001535
Iteration 103/1000 | Loss: 0.00001535
Iteration 104/1000 | Loss: 0.00001535
Iteration 105/1000 | Loss: 0.00001535
Iteration 106/1000 | Loss: 0.00001535
Iteration 107/1000 | Loss: 0.00001535
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.535292722110171e-05, 1.535292722110171e-05, 1.535292722110171e-05, 1.535292722110171e-05, 1.535292722110171e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.535292722110171e-05

Optimization complete. Final v2v error: 3.316232681274414 mm

Highest mean error: 4.254295349121094 mm for frame 47

Lowest mean error: 2.9187450408935547 mm for frame 67

Saving results

Total time: 38.52148938179016
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1036/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1036.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1036
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00876956
Iteration 2/25 | Loss: 0.00144132
Iteration 3/25 | Loss: 0.00124361
Iteration 4/25 | Loss: 0.00117033
Iteration 5/25 | Loss: 0.00114499
Iteration 6/25 | Loss: 0.00115635
Iteration 7/25 | Loss: 0.00115878
Iteration 8/25 | Loss: 0.00113227
Iteration 9/25 | Loss: 0.00111240
Iteration 10/25 | Loss: 0.00110077
Iteration 11/25 | Loss: 0.00109025
Iteration 12/25 | Loss: 0.00108008
Iteration 13/25 | Loss: 0.00107521
Iteration 14/25 | Loss: 0.00107372
Iteration 15/25 | Loss: 0.00106972
Iteration 16/25 | Loss: 0.00106541
Iteration 17/25 | Loss: 0.00105977
Iteration 18/25 | Loss: 0.00105800
Iteration 19/25 | Loss: 0.00105843
Iteration 20/25 | Loss: 0.00105688
Iteration 21/25 | Loss: 0.00105671
Iteration 22/25 | Loss: 0.00105600
Iteration 23/25 | Loss: 0.00105572
Iteration 24/25 | Loss: 0.00105706
Iteration 25/25 | Loss: 0.00105818

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51384521
Iteration 2/25 | Loss: 0.00272054
Iteration 3/25 | Loss: 0.00272052
Iteration 4/25 | Loss: 0.00272052
Iteration 5/25 | Loss: 0.00272052
Iteration 6/25 | Loss: 0.00272052
Iteration 7/25 | Loss: 0.00272052
Iteration 8/25 | Loss: 0.00272052
Iteration 9/25 | Loss: 0.00272052
Iteration 10/25 | Loss: 0.00272052
Iteration 11/25 | Loss: 0.00272052
Iteration 12/25 | Loss: 0.00272052
Iteration 13/25 | Loss: 0.00272052
Iteration 14/25 | Loss: 0.00272052
Iteration 15/25 | Loss: 0.00272052
Iteration 16/25 | Loss: 0.00272052
Iteration 17/25 | Loss: 0.00272052
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0027205178048461676, 0.0027205178048461676, 0.0027205178048461676, 0.0027205178048461676, 0.0027205178048461676]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0027205178048461676

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00272052
Iteration 2/1000 | Loss: 0.00028992
Iteration 3/1000 | Loss: 0.00022391
Iteration 4/1000 | Loss: 0.00020043
Iteration 5/1000 | Loss: 0.00018942
Iteration 6/1000 | Loss: 0.00017911
Iteration 7/1000 | Loss: 0.00021605
Iteration 8/1000 | Loss: 0.00016399
Iteration 9/1000 | Loss: 0.00015517
Iteration 10/1000 | Loss: 0.00014836
Iteration 11/1000 | Loss: 0.00023155
Iteration 12/1000 | Loss: 0.00014138
Iteration 13/1000 | Loss: 0.00013667
Iteration 14/1000 | Loss: 0.00035204
Iteration 15/1000 | Loss: 0.00014216
Iteration 16/1000 | Loss: 0.00013438
Iteration 17/1000 | Loss: 0.00013154
Iteration 18/1000 | Loss: 0.00067010
Iteration 19/1000 | Loss: 0.00023883
Iteration 20/1000 | Loss: 0.00012736
Iteration 21/1000 | Loss: 0.00012506
Iteration 22/1000 | Loss: 0.00143729
Iteration 23/1000 | Loss: 0.00034457
Iteration 24/1000 | Loss: 0.00015129
Iteration 25/1000 | Loss: 0.00077368
Iteration 26/1000 | Loss: 0.00015913
Iteration 27/1000 | Loss: 0.00012671
Iteration 28/1000 | Loss: 0.00012296
Iteration 29/1000 | Loss: 0.00144044
Iteration 30/1000 | Loss: 0.00053631
Iteration 31/1000 | Loss: 0.00024979
Iteration 32/1000 | Loss: 0.00013427
Iteration 33/1000 | Loss: 0.00024420
Iteration 34/1000 | Loss: 0.00012149
Iteration 35/1000 | Loss: 0.00210812
Iteration 36/1000 | Loss: 0.00057970
Iteration 37/1000 | Loss: 0.00016586
Iteration 38/1000 | Loss: 0.00123241
Iteration 39/1000 | Loss: 0.00043281
Iteration 40/1000 | Loss: 0.00012767
Iteration 41/1000 | Loss: 0.00012300
Iteration 42/1000 | Loss: 0.00176203
Iteration 43/1000 | Loss: 0.00039910
Iteration 44/1000 | Loss: 0.00012759
Iteration 45/1000 | Loss: 0.00011785
Iteration 46/1000 | Loss: 0.00130676
Iteration 47/1000 | Loss: 0.00295171
Iteration 48/1000 | Loss: 0.00099888
Iteration 49/1000 | Loss: 0.00051764
Iteration 50/1000 | Loss: 0.00062669
Iteration 51/1000 | Loss: 0.00014230
Iteration 52/1000 | Loss: 0.00062975
Iteration 53/1000 | Loss: 0.00031606
Iteration 54/1000 | Loss: 0.00013404
Iteration 55/1000 | Loss: 0.00011397
Iteration 56/1000 | Loss: 0.00010546
Iteration 57/1000 | Loss: 0.00010158
Iteration 58/1000 | Loss: 0.00067402
Iteration 59/1000 | Loss: 0.00033785
Iteration 60/1000 | Loss: 0.00010715
Iteration 61/1000 | Loss: 0.00010065
Iteration 62/1000 | Loss: 0.00091636
Iteration 63/1000 | Loss: 0.00018589
Iteration 64/1000 | Loss: 0.00024068
Iteration 65/1000 | Loss: 0.00032539
Iteration 66/1000 | Loss: 0.00010054
Iteration 67/1000 | Loss: 0.00128541
Iteration 68/1000 | Loss: 0.00066670
Iteration 69/1000 | Loss: 0.00029411
Iteration 70/1000 | Loss: 0.00041673
Iteration 71/1000 | Loss: 0.00130525
Iteration 72/1000 | Loss: 0.00084790
Iteration 73/1000 | Loss: 0.00068655
Iteration 74/1000 | Loss: 0.00059117
Iteration 75/1000 | Loss: 0.00052777
Iteration 76/1000 | Loss: 0.00055582
Iteration 77/1000 | Loss: 0.00027389
Iteration 78/1000 | Loss: 0.00011103
Iteration 79/1000 | Loss: 0.00058794
Iteration 80/1000 | Loss: 0.00053565
Iteration 81/1000 | Loss: 0.00013736
Iteration 82/1000 | Loss: 0.00061920
Iteration 83/1000 | Loss: 0.00076285
Iteration 84/1000 | Loss: 0.00066965
Iteration 85/1000 | Loss: 0.00063326
Iteration 86/1000 | Loss: 0.00011787
Iteration 87/1000 | Loss: 0.00025697
Iteration 88/1000 | Loss: 0.00012817
Iteration 89/1000 | Loss: 0.00010582
Iteration 90/1000 | Loss: 0.00009543
Iteration 91/1000 | Loss: 0.00009189
Iteration 92/1000 | Loss: 0.00009041
Iteration 93/1000 | Loss: 0.00008932
Iteration 94/1000 | Loss: 0.00008857
Iteration 95/1000 | Loss: 0.00008774
Iteration 96/1000 | Loss: 0.00008708
Iteration 97/1000 | Loss: 0.00008650
Iteration 98/1000 | Loss: 0.00008604
Iteration 99/1000 | Loss: 0.00079304
Iteration 100/1000 | Loss: 0.00029666
Iteration 101/1000 | Loss: 0.00011128
Iteration 102/1000 | Loss: 0.00009604
Iteration 103/1000 | Loss: 0.00009078
Iteration 104/1000 | Loss: 0.00008854
Iteration 105/1000 | Loss: 0.00008757
Iteration 106/1000 | Loss: 0.00025953
Iteration 107/1000 | Loss: 0.00037661
Iteration 108/1000 | Loss: 0.00012325
Iteration 109/1000 | Loss: 0.00024699
Iteration 110/1000 | Loss: 0.00010654
Iteration 111/1000 | Loss: 0.00009236
Iteration 112/1000 | Loss: 0.00019894
Iteration 113/1000 | Loss: 0.00074282
Iteration 114/1000 | Loss: 0.00026452
Iteration 115/1000 | Loss: 0.00009806
Iteration 116/1000 | Loss: 0.00025445
Iteration 117/1000 | Loss: 0.00029346
Iteration 118/1000 | Loss: 0.00060388
Iteration 119/1000 | Loss: 0.00010880
Iteration 120/1000 | Loss: 0.00009384
Iteration 121/1000 | Loss: 0.00012795
Iteration 122/1000 | Loss: 0.00013348
Iteration 123/1000 | Loss: 0.00010478
Iteration 124/1000 | Loss: 0.00012841
Iteration 125/1000 | Loss: 0.00031410
Iteration 126/1000 | Loss: 0.00021699
Iteration 127/1000 | Loss: 0.00061339
Iteration 128/1000 | Loss: 0.00017842
Iteration 129/1000 | Loss: 0.00016808
Iteration 130/1000 | Loss: 0.00009283
Iteration 131/1000 | Loss: 0.00031271
Iteration 132/1000 | Loss: 0.00016169
Iteration 133/1000 | Loss: 0.00014356
Iteration 134/1000 | Loss: 0.00019052
Iteration 135/1000 | Loss: 0.00011665
Iteration 136/1000 | Loss: 0.00013989
Iteration 137/1000 | Loss: 0.00036364
Iteration 138/1000 | Loss: 0.00058119
Iteration 139/1000 | Loss: 0.00044691
Iteration 140/1000 | Loss: 0.00040550
Iteration 141/1000 | Loss: 0.00043437
Iteration 142/1000 | Loss: 0.00083521
Iteration 143/1000 | Loss: 0.00038017
Iteration 144/1000 | Loss: 0.00024781
Iteration 145/1000 | Loss: 0.00056208
Iteration 146/1000 | Loss: 0.00011329
Iteration 147/1000 | Loss: 0.00010162
Iteration 148/1000 | Loss: 0.00009669
Iteration 149/1000 | Loss: 0.00009401
Iteration 150/1000 | Loss: 0.00009052
Iteration 151/1000 | Loss: 0.00008637
Iteration 152/1000 | Loss: 0.00008486
Iteration 153/1000 | Loss: 0.00008421
Iteration 154/1000 | Loss: 0.00008370
Iteration 155/1000 | Loss: 0.00008335
Iteration 156/1000 | Loss: 0.00008300
Iteration 157/1000 | Loss: 0.00008286
Iteration 158/1000 | Loss: 0.00008277
Iteration 159/1000 | Loss: 0.00008260
Iteration 160/1000 | Loss: 0.00008248
Iteration 161/1000 | Loss: 0.00008248
Iteration 162/1000 | Loss: 0.00008247
Iteration 163/1000 | Loss: 0.00008247
Iteration 164/1000 | Loss: 0.00008247
Iteration 165/1000 | Loss: 0.00008246
Iteration 166/1000 | Loss: 0.00008246
Iteration 167/1000 | Loss: 0.00008246
Iteration 168/1000 | Loss: 0.00008245
Iteration 169/1000 | Loss: 0.00008245
Iteration 170/1000 | Loss: 0.00008245
Iteration 171/1000 | Loss: 0.00008245
Iteration 172/1000 | Loss: 0.00008245
Iteration 173/1000 | Loss: 0.00008244
Iteration 174/1000 | Loss: 0.00008244
Iteration 175/1000 | Loss: 0.00008244
Iteration 176/1000 | Loss: 0.00008244
Iteration 177/1000 | Loss: 0.00008244
Iteration 178/1000 | Loss: 0.00008244
Iteration 179/1000 | Loss: 0.00008244
Iteration 180/1000 | Loss: 0.00008244
Iteration 181/1000 | Loss: 0.00008244
Iteration 182/1000 | Loss: 0.00008243
Iteration 183/1000 | Loss: 0.00008243
Iteration 184/1000 | Loss: 0.00008243
Iteration 185/1000 | Loss: 0.00008243
Iteration 186/1000 | Loss: 0.00008243
Iteration 187/1000 | Loss: 0.00008243
Iteration 188/1000 | Loss: 0.00008243
Iteration 189/1000 | Loss: 0.00008242
Iteration 190/1000 | Loss: 0.00008242
Iteration 191/1000 | Loss: 0.00008242
Iteration 192/1000 | Loss: 0.00008242
Iteration 193/1000 | Loss: 0.00008242
Iteration 194/1000 | Loss: 0.00008242
Iteration 195/1000 | Loss: 0.00008242
Iteration 196/1000 | Loss: 0.00008242
Iteration 197/1000 | Loss: 0.00008242
Iteration 198/1000 | Loss: 0.00008241
Iteration 199/1000 | Loss: 0.00008241
Iteration 200/1000 | Loss: 0.00008240
Iteration 201/1000 | Loss: 0.00008239
Iteration 202/1000 | Loss: 0.00008239
Iteration 203/1000 | Loss: 0.00008239
Iteration 204/1000 | Loss: 0.00008239
Iteration 205/1000 | Loss: 0.00008238
Iteration 206/1000 | Loss: 0.00008238
Iteration 207/1000 | Loss: 0.00008238
Iteration 208/1000 | Loss: 0.00008238
Iteration 209/1000 | Loss: 0.00008238
Iteration 210/1000 | Loss: 0.00008238
Iteration 211/1000 | Loss: 0.00008238
Iteration 212/1000 | Loss: 0.00008238
Iteration 213/1000 | Loss: 0.00008238
Iteration 214/1000 | Loss: 0.00008238
Iteration 215/1000 | Loss: 0.00008238
Iteration 216/1000 | Loss: 0.00008238
Iteration 217/1000 | Loss: 0.00008238
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 217. Stopping optimization.
Last 5 losses: [8.23765221866779e-05, 8.23765221866779e-05, 8.23765221866779e-05, 8.23765221866779e-05, 8.23765221866779e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.23765221866779e-05

Optimization complete. Final v2v error: 4.908379077911377 mm

Highest mean error: 12.107888221740723 mm for frame 67

Lowest mean error: 3.3323216438293457 mm for frame 128

Saving results

Total time: 281.57213830947876
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00452186
Iteration 2/25 | Loss: 0.00097575
Iteration 3/25 | Loss: 0.00087036
Iteration 4/25 | Loss: 0.00085002
Iteration 5/25 | Loss: 0.00084710
Iteration 6/25 | Loss: 0.00084582
Iteration 7/25 | Loss: 0.00084557
Iteration 8/25 | Loss: 0.00084557
Iteration 9/25 | Loss: 0.00084557
Iteration 10/25 | Loss: 0.00084557
Iteration 11/25 | Loss: 0.00084557
Iteration 12/25 | Loss: 0.00084557
Iteration 13/25 | Loss: 0.00084557
Iteration 14/25 | Loss: 0.00084557
Iteration 15/25 | Loss: 0.00084557
Iteration 16/25 | Loss: 0.00084557
Iteration 17/25 | Loss: 0.00084557
Iteration 18/25 | Loss: 0.00084557
Iteration 19/25 | Loss: 0.00084557
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0008455743081867695, 0.0008455743081867695, 0.0008455743081867695, 0.0008455743081867695, 0.0008455743081867695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008455743081867695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51797581
Iteration 2/25 | Loss: 0.00061495
Iteration 3/25 | Loss: 0.00061495
Iteration 4/25 | Loss: 0.00061495
Iteration 5/25 | Loss: 0.00061495
Iteration 6/25 | Loss: 0.00061495
Iteration 7/25 | Loss: 0.00061495
Iteration 8/25 | Loss: 0.00061495
Iteration 9/25 | Loss: 0.00061495
Iteration 10/25 | Loss: 0.00061495
Iteration 11/25 | Loss: 0.00061495
Iteration 12/25 | Loss: 0.00061495
Iteration 13/25 | Loss: 0.00061495
Iteration 14/25 | Loss: 0.00061495
Iteration 15/25 | Loss: 0.00061495
Iteration 16/25 | Loss: 0.00061495
Iteration 17/25 | Loss: 0.00061495
Iteration 18/25 | Loss: 0.00061495
Iteration 19/25 | Loss: 0.00061495
Iteration 20/25 | Loss: 0.00061495
Iteration 21/25 | Loss: 0.00061495
Iteration 22/25 | Loss: 0.00061495
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0006149497930891812, 0.0006149497930891812, 0.0006149497930891812, 0.0006149497930891812, 0.0006149497930891812]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006149497930891812

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061495
Iteration 2/1000 | Loss: 0.00003010
Iteration 3/1000 | Loss: 0.00002104
Iteration 4/1000 | Loss: 0.00001960
Iteration 5/1000 | Loss: 0.00001881
Iteration 6/1000 | Loss: 0.00001835
Iteration 7/1000 | Loss: 0.00001794
Iteration 8/1000 | Loss: 0.00001753
Iteration 9/1000 | Loss: 0.00001733
Iteration 10/1000 | Loss: 0.00001727
Iteration 11/1000 | Loss: 0.00001724
Iteration 12/1000 | Loss: 0.00001721
Iteration 13/1000 | Loss: 0.00001707
Iteration 14/1000 | Loss: 0.00001696
Iteration 15/1000 | Loss: 0.00001683
Iteration 16/1000 | Loss: 0.00001682
Iteration 17/1000 | Loss: 0.00001680
Iteration 18/1000 | Loss: 0.00001680
Iteration 19/1000 | Loss: 0.00001680
Iteration 20/1000 | Loss: 0.00001679
Iteration 21/1000 | Loss: 0.00001679
Iteration 22/1000 | Loss: 0.00001677
Iteration 23/1000 | Loss: 0.00001677
Iteration 24/1000 | Loss: 0.00001676
Iteration 25/1000 | Loss: 0.00001675
Iteration 26/1000 | Loss: 0.00001675
Iteration 27/1000 | Loss: 0.00001675
Iteration 28/1000 | Loss: 0.00001674
Iteration 29/1000 | Loss: 0.00001670
Iteration 30/1000 | Loss: 0.00001670
Iteration 31/1000 | Loss: 0.00001669
Iteration 32/1000 | Loss: 0.00001668
Iteration 33/1000 | Loss: 0.00001668
Iteration 34/1000 | Loss: 0.00001668
Iteration 35/1000 | Loss: 0.00001665
Iteration 36/1000 | Loss: 0.00001665
Iteration 37/1000 | Loss: 0.00001664
Iteration 38/1000 | Loss: 0.00001664
Iteration 39/1000 | Loss: 0.00001664
Iteration 40/1000 | Loss: 0.00001663
Iteration 41/1000 | Loss: 0.00001661
Iteration 42/1000 | Loss: 0.00001659
Iteration 43/1000 | Loss: 0.00001658
Iteration 44/1000 | Loss: 0.00001657
Iteration 45/1000 | Loss: 0.00001654
Iteration 46/1000 | Loss: 0.00001654
Iteration 47/1000 | Loss: 0.00001654
Iteration 48/1000 | Loss: 0.00001654
Iteration 49/1000 | Loss: 0.00001653
Iteration 50/1000 | Loss: 0.00001653
Iteration 51/1000 | Loss: 0.00001653
Iteration 52/1000 | Loss: 0.00001653
Iteration 53/1000 | Loss: 0.00001653
Iteration 54/1000 | Loss: 0.00001653
Iteration 55/1000 | Loss: 0.00001653
Iteration 56/1000 | Loss: 0.00001653
Iteration 57/1000 | Loss: 0.00001653
Iteration 58/1000 | Loss: 0.00001653
Iteration 59/1000 | Loss: 0.00001653
Iteration 60/1000 | Loss: 0.00001652
Iteration 61/1000 | Loss: 0.00001652
Iteration 62/1000 | Loss: 0.00001652
Iteration 63/1000 | Loss: 0.00001652
Iteration 64/1000 | Loss: 0.00001652
Iteration 65/1000 | Loss: 0.00001652
Iteration 66/1000 | Loss: 0.00001652
Iteration 67/1000 | Loss: 0.00001652
Iteration 68/1000 | Loss: 0.00001652
Iteration 69/1000 | Loss: 0.00001652
Iteration 70/1000 | Loss: 0.00001652
Iteration 71/1000 | Loss: 0.00001652
Iteration 72/1000 | Loss: 0.00001651
Iteration 73/1000 | Loss: 0.00001651
Iteration 74/1000 | Loss: 0.00001651
Iteration 75/1000 | Loss: 0.00001651
Iteration 76/1000 | Loss: 0.00001651
Iteration 77/1000 | Loss: 0.00001651
Iteration 78/1000 | Loss: 0.00001651
Iteration 79/1000 | Loss: 0.00001651
Iteration 80/1000 | Loss: 0.00001650
Iteration 81/1000 | Loss: 0.00001650
Iteration 82/1000 | Loss: 0.00001650
Iteration 83/1000 | Loss: 0.00001650
Iteration 84/1000 | Loss: 0.00001650
Iteration 85/1000 | Loss: 0.00001650
Iteration 86/1000 | Loss: 0.00001650
Iteration 87/1000 | Loss: 0.00001650
Iteration 88/1000 | Loss: 0.00001650
Iteration 89/1000 | Loss: 0.00001650
Iteration 90/1000 | Loss: 0.00001650
Iteration 91/1000 | Loss: 0.00001650
Iteration 92/1000 | Loss: 0.00001650
Iteration 93/1000 | Loss: 0.00001650
Iteration 94/1000 | Loss: 0.00001650
Iteration 95/1000 | Loss: 0.00001650
Iteration 96/1000 | Loss: 0.00001650
Iteration 97/1000 | Loss: 0.00001650
Iteration 98/1000 | Loss: 0.00001650
Iteration 99/1000 | Loss: 0.00001650
Iteration 100/1000 | Loss: 0.00001650
Iteration 101/1000 | Loss: 0.00001650
Iteration 102/1000 | Loss: 0.00001650
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.6499488992849365e-05, 1.6499488992849365e-05, 1.6499488992849365e-05, 1.6499488992849365e-05, 1.6499488992849365e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6499488992849365e-05

Optimization complete. Final v2v error: 3.447768449783325 mm

Highest mean error: 3.7420146465301514 mm for frame 133

Lowest mean error: 3.310058116912842 mm for frame 12

Saving results

Total time: 34.271398305892944
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_006/1072/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1072.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_006/1072
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00819203
Iteration 2/25 | Loss: 0.00122934
Iteration 3/25 | Loss: 0.00089109
Iteration 4/25 | Loss: 0.00085455
Iteration 5/25 | Loss: 0.00084290
Iteration 6/25 | Loss: 0.00084018
Iteration 7/25 | Loss: 0.00083990
Iteration 8/25 | Loss: 0.00083990
Iteration 9/25 | Loss: 0.00083990
Iteration 10/25 | Loss: 0.00083990
Iteration 11/25 | Loss: 0.00083990
Iteration 12/25 | Loss: 0.00083990
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008398988284170628, 0.0008398988284170628, 0.0008398988284170628, 0.0008398988284170628, 0.0008398988284170628]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008398988284170628

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25034559
Iteration 2/25 | Loss: 0.00056257
Iteration 3/25 | Loss: 0.00056257
Iteration 4/25 | Loss: 0.00056256
Iteration 5/25 | Loss: 0.00056256
Iteration 6/25 | Loss: 0.00056256
Iteration 7/25 | Loss: 0.00056256
Iteration 8/25 | Loss: 0.00056256
Iteration 9/25 | Loss: 0.00056256
Iteration 10/25 | Loss: 0.00056256
Iteration 11/25 | Loss: 0.00056256
Iteration 12/25 | Loss: 0.00056256
Iteration 13/25 | Loss: 0.00056256
Iteration 14/25 | Loss: 0.00056256
Iteration 15/25 | Loss: 0.00056256
Iteration 16/25 | Loss: 0.00056256
Iteration 17/25 | Loss: 0.00056256
Iteration 18/25 | Loss: 0.00056256
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005625623743981123, 0.0005625623743981123, 0.0005625623743981123, 0.0005625623743981123, 0.0005625623743981123]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005625623743981123

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056256
Iteration 2/1000 | Loss: 0.00003871
Iteration 3/1000 | Loss: 0.00002788
Iteration 4/1000 | Loss: 0.00002530
Iteration 5/1000 | Loss: 0.00002378
Iteration 6/1000 | Loss: 0.00002223
Iteration 7/1000 | Loss: 0.00002149
Iteration 8/1000 | Loss: 0.00002089
Iteration 9/1000 | Loss: 0.00002048
Iteration 10/1000 | Loss: 0.00002024
Iteration 11/1000 | Loss: 0.00002009
Iteration 12/1000 | Loss: 0.00001991
Iteration 13/1000 | Loss: 0.00001975
Iteration 14/1000 | Loss: 0.00001958
Iteration 15/1000 | Loss: 0.00001949
Iteration 16/1000 | Loss: 0.00001948
Iteration 17/1000 | Loss: 0.00001946
Iteration 18/1000 | Loss: 0.00001946
Iteration 19/1000 | Loss: 0.00001944
Iteration 20/1000 | Loss: 0.00001940
Iteration 21/1000 | Loss: 0.00001938
Iteration 22/1000 | Loss: 0.00001936
Iteration 23/1000 | Loss: 0.00001933
Iteration 24/1000 | Loss: 0.00001932
Iteration 25/1000 | Loss: 0.00001932
Iteration 26/1000 | Loss: 0.00001931
Iteration 27/1000 | Loss: 0.00001928
Iteration 28/1000 | Loss: 0.00001926
Iteration 29/1000 | Loss: 0.00001926
Iteration 30/1000 | Loss: 0.00001922
Iteration 31/1000 | Loss: 0.00001922
Iteration 32/1000 | Loss: 0.00001921
Iteration 33/1000 | Loss: 0.00001921
Iteration 34/1000 | Loss: 0.00001920
Iteration 35/1000 | Loss: 0.00001920
Iteration 36/1000 | Loss: 0.00001920
Iteration 37/1000 | Loss: 0.00001919
Iteration 38/1000 | Loss: 0.00001917
Iteration 39/1000 | Loss: 0.00001917
Iteration 40/1000 | Loss: 0.00001916
Iteration 41/1000 | Loss: 0.00001916
Iteration 42/1000 | Loss: 0.00001915
Iteration 43/1000 | Loss: 0.00001915
Iteration 44/1000 | Loss: 0.00001914
Iteration 45/1000 | Loss: 0.00001913
Iteration 46/1000 | Loss: 0.00001913
Iteration 47/1000 | Loss: 0.00001913
Iteration 48/1000 | Loss: 0.00001912
Iteration 49/1000 | Loss: 0.00001911
Iteration 50/1000 | Loss: 0.00001911
Iteration 51/1000 | Loss: 0.00001910
Iteration 52/1000 | Loss: 0.00001909
Iteration 53/1000 | Loss: 0.00001908
Iteration 54/1000 | Loss: 0.00001908
Iteration 55/1000 | Loss: 0.00001907
Iteration 56/1000 | Loss: 0.00001907
Iteration 57/1000 | Loss: 0.00001906
Iteration 58/1000 | Loss: 0.00001905
Iteration 59/1000 | Loss: 0.00001904
Iteration 60/1000 | Loss: 0.00001904
Iteration 61/1000 | Loss: 0.00001904
Iteration 62/1000 | Loss: 0.00001904
Iteration 63/1000 | Loss: 0.00001903
Iteration 64/1000 | Loss: 0.00001903
Iteration 65/1000 | Loss: 0.00001903
Iteration 66/1000 | Loss: 0.00001903
Iteration 67/1000 | Loss: 0.00001903
Iteration 68/1000 | Loss: 0.00001903
Iteration 69/1000 | Loss: 0.00001903
Iteration 70/1000 | Loss: 0.00001902
Iteration 71/1000 | Loss: 0.00001902
Iteration 72/1000 | Loss: 0.00001902
Iteration 73/1000 | Loss: 0.00001902
Iteration 74/1000 | Loss: 0.00001902
Iteration 75/1000 | Loss: 0.00001901
Iteration 76/1000 | Loss: 0.00001901
Iteration 77/1000 | Loss: 0.00001901
Iteration 78/1000 | Loss: 0.00001901
Iteration 79/1000 | Loss: 0.00001901
Iteration 80/1000 | Loss: 0.00001901
Iteration 81/1000 | Loss: 0.00001901
Iteration 82/1000 | Loss: 0.00001901
Iteration 83/1000 | Loss: 0.00001901
Iteration 84/1000 | Loss: 0.00001900
Iteration 85/1000 | Loss: 0.00001900
Iteration 86/1000 | Loss: 0.00001900
Iteration 87/1000 | Loss: 0.00001900
Iteration 88/1000 | Loss: 0.00001900
Iteration 89/1000 | Loss: 0.00001900
Iteration 90/1000 | Loss: 0.00001900
Iteration 91/1000 | Loss: 0.00001900
Iteration 92/1000 | Loss: 0.00001899
Iteration 93/1000 | Loss: 0.00001899
Iteration 94/1000 | Loss: 0.00001899
Iteration 95/1000 | Loss: 0.00001899
Iteration 96/1000 | Loss: 0.00001899
Iteration 97/1000 | Loss: 0.00001899
Iteration 98/1000 | Loss: 0.00001899
Iteration 99/1000 | Loss: 0.00001898
Iteration 100/1000 | Loss: 0.00001898
Iteration 101/1000 | Loss: 0.00001898
Iteration 102/1000 | Loss: 0.00001897
Iteration 103/1000 | Loss: 0.00001897
Iteration 104/1000 | Loss: 0.00001897
Iteration 105/1000 | Loss: 0.00001897
Iteration 106/1000 | Loss: 0.00001896
Iteration 107/1000 | Loss: 0.00001896
Iteration 108/1000 | Loss: 0.00001896
Iteration 109/1000 | Loss: 0.00001896
Iteration 110/1000 | Loss: 0.00001896
Iteration 111/1000 | Loss: 0.00001895
Iteration 112/1000 | Loss: 0.00001895
Iteration 113/1000 | Loss: 0.00001895
Iteration 114/1000 | Loss: 0.00001894
Iteration 115/1000 | Loss: 0.00001894
Iteration 116/1000 | Loss: 0.00001894
Iteration 117/1000 | Loss: 0.00001893
Iteration 118/1000 | Loss: 0.00001893
Iteration 119/1000 | Loss: 0.00001893
Iteration 120/1000 | Loss: 0.00001893
Iteration 121/1000 | Loss: 0.00001892
Iteration 122/1000 | Loss: 0.00001892
Iteration 123/1000 | Loss: 0.00001892
Iteration 124/1000 | Loss: 0.00001892
Iteration 125/1000 | Loss: 0.00001892
Iteration 126/1000 | Loss: 0.00001891
Iteration 127/1000 | Loss: 0.00001891
Iteration 128/1000 | Loss: 0.00001891
Iteration 129/1000 | Loss: 0.00001891
Iteration 130/1000 | Loss: 0.00001891
Iteration 131/1000 | Loss: 0.00001890
Iteration 132/1000 | Loss: 0.00001890
Iteration 133/1000 | Loss: 0.00001890
Iteration 134/1000 | Loss: 0.00001890
Iteration 135/1000 | Loss: 0.00001890
Iteration 136/1000 | Loss: 0.00001889
Iteration 137/1000 | Loss: 0.00001889
Iteration 138/1000 | Loss: 0.00001889
Iteration 139/1000 | Loss: 0.00001889
Iteration 140/1000 | Loss: 0.00001889
Iteration 141/1000 | Loss: 0.00001889
Iteration 142/1000 | Loss: 0.00001889
Iteration 143/1000 | Loss: 0.00001888
Iteration 144/1000 | Loss: 0.00001888
Iteration 145/1000 | Loss: 0.00001888
Iteration 146/1000 | Loss: 0.00001888
Iteration 147/1000 | Loss: 0.00001888
Iteration 148/1000 | Loss: 0.00001888
Iteration 149/1000 | Loss: 0.00001888
Iteration 150/1000 | Loss: 0.00001888
Iteration 151/1000 | Loss: 0.00001888
Iteration 152/1000 | Loss: 0.00001888
Iteration 153/1000 | Loss: 0.00001888
Iteration 154/1000 | Loss: 0.00001887
Iteration 155/1000 | Loss: 0.00001887
Iteration 156/1000 | Loss: 0.00001887
Iteration 157/1000 | Loss: 0.00001887
Iteration 158/1000 | Loss: 0.00001887
Iteration 159/1000 | Loss: 0.00001887
Iteration 160/1000 | Loss: 0.00001887
Iteration 161/1000 | Loss: 0.00001887
Iteration 162/1000 | Loss: 0.00001886
Iteration 163/1000 | Loss: 0.00001886
Iteration 164/1000 | Loss: 0.00001886
Iteration 165/1000 | Loss: 0.00001886
Iteration 166/1000 | Loss: 0.00001886
Iteration 167/1000 | Loss: 0.00001886
Iteration 168/1000 | Loss: 0.00001886
Iteration 169/1000 | Loss: 0.00001886
Iteration 170/1000 | Loss: 0.00001885
Iteration 171/1000 | Loss: 0.00001885
Iteration 172/1000 | Loss: 0.00001885
Iteration 173/1000 | Loss: 0.00001885
Iteration 174/1000 | Loss: 0.00001885
Iteration 175/1000 | Loss: 0.00001885
Iteration 176/1000 | Loss: 0.00001885
Iteration 177/1000 | Loss: 0.00001885
Iteration 178/1000 | Loss: 0.00001885
Iteration 179/1000 | Loss: 0.00001885
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.8853257643058896e-05, 1.8853257643058896e-05, 1.8853257643058896e-05, 1.8853257643058896e-05, 1.8853257643058896e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8853257643058896e-05

Optimization complete. Final v2v error: 3.633746385574341 mm

Highest mean error: 4.993261337280273 mm for frame 82

Lowest mean error: 2.852574348449707 mm for frame 197

Saving results

Total time: 50.943891763687134

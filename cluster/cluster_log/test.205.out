Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=205, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 11480-11535
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1052/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1052.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1052
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00854594
Iteration 2/25 | Loss: 0.00127031
Iteration 3/25 | Loss: 0.00084047
Iteration 4/25 | Loss: 0.00080213
Iteration 5/25 | Loss: 0.00078768
Iteration 6/25 | Loss: 0.00078413
Iteration 7/25 | Loss: 0.00078358
Iteration 8/25 | Loss: 0.00078358
Iteration 9/25 | Loss: 0.00078358
Iteration 10/25 | Loss: 0.00078358
Iteration 11/25 | Loss: 0.00078358
Iteration 12/25 | Loss: 0.00078358
Iteration 13/25 | Loss: 0.00078358
Iteration 14/25 | Loss: 0.00078358
Iteration 15/25 | Loss: 0.00078358
Iteration 16/25 | Loss: 0.00078358
Iteration 17/25 | Loss: 0.00078358
Iteration 18/25 | Loss: 0.00078358
Iteration 19/25 | Loss: 0.00078358
Iteration 20/25 | Loss: 0.00078358
Iteration 21/25 | Loss: 0.00078358
Iteration 22/25 | Loss: 0.00078358
Iteration 23/25 | Loss: 0.00078358
Iteration 24/25 | Loss: 0.00078358
Iteration 25/25 | Loss: 0.00078358

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.14821315
Iteration 2/25 | Loss: 0.00022117
Iteration 3/25 | Loss: 0.00022113
Iteration 4/25 | Loss: 0.00022113
Iteration 5/25 | Loss: 0.00022113
Iteration 6/25 | Loss: 0.00022113
Iteration 7/25 | Loss: 0.00022113
Iteration 8/25 | Loss: 0.00022113
Iteration 9/25 | Loss: 0.00022113
Iteration 10/25 | Loss: 0.00022113
Iteration 11/25 | Loss: 0.00022113
Iteration 12/25 | Loss: 0.00022113
Iteration 13/25 | Loss: 0.00022113
Iteration 14/25 | Loss: 0.00022113
Iteration 15/25 | Loss: 0.00022113
Iteration 16/25 | Loss: 0.00022113
Iteration 17/25 | Loss: 0.00022113
Iteration 18/25 | Loss: 0.00022113
Iteration 19/25 | Loss: 0.00022113
Iteration 20/25 | Loss: 0.00022113
Iteration 21/25 | Loss: 0.00022113
Iteration 22/25 | Loss: 0.00022113
Iteration 23/25 | Loss: 0.00022113
Iteration 24/25 | Loss: 0.00022113
Iteration 25/25 | Loss: 0.00022113

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00022113
Iteration 2/1000 | Loss: 0.00004048
Iteration 3/1000 | Loss: 0.00003106
Iteration 4/1000 | Loss: 0.00002803
Iteration 5/1000 | Loss: 0.00002697
Iteration 6/1000 | Loss: 0.00002589
Iteration 7/1000 | Loss: 0.00002515
Iteration 8/1000 | Loss: 0.00002464
Iteration 9/1000 | Loss: 0.00002435
Iteration 10/1000 | Loss: 0.00002416
Iteration 11/1000 | Loss: 0.00002412
Iteration 12/1000 | Loss: 0.00002396
Iteration 13/1000 | Loss: 0.00002394
Iteration 14/1000 | Loss: 0.00002385
Iteration 15/1000 | Loss: 0.00002385
Iteration 16/1000 | Loss: 0.00002384
Iteration 17/1000 | Loss: 0.00002383
Iteration 18/1000 | Loss: 0.00002383
Iteration 19/1000 | Loss: 0.00002383
Iteration 20/1000 | Loss: 0.00002383
Iteration 21/1000 | Loss: 0.00002383
Iteration 22/1000 | Loss: 0.00002383
Iteration 23/1000 | Loss: 0.00002382
Iteration 24/1000 | Loss: 0.00002382
Iteration 25/1000 | Loss: 0.00002382
Iteration 26/1000 | Loss: 0.00002382
Iteration 27/1000 | Loss: 0.00002381
Iteration 28/1000 | Loss: 0.00002381
Iteration 29/1000 | Loss: 0.00002381
Iteration 30/1000 | Loss: 0.00002380
Iteration 31/1000 | Loss: 0.00002380
Iteration 32/1000 | Loss: 0.00002380
Iteration 33/1000 | Loss: 0.00002380
Iteration 34/1000 | Loss: 0.00002380
Iteration 35/1000 | Loss: 0.00002380
Iteration 36/1000 | Loss: 0.00002380
Iteration 37/1000 | Loss: 0.00002380
Iteration 38/1000 | Loss: 0.00002379
Iteration 39/1000 | Loss: 0.00002379
Iteration 40/1000 | Loss: 0.00002379
Iteration 41/1000 | Loss: 0.00002379
Iteration 42/1000 | Loss: 0.00002379
Iteration 43/1000 | Loss: 0.00002378
Iteration 44/1000 | Loss: 0.00002376
Iteration 45/1000 | Loss: 0.00002376
Iteration 46/1000 | Loss: 0.00002376
Iteration 47/1000 | Loss: 0.00002375
Iteration 48/1000 | Loss: 0.00002375
Iteration 49/1000 | Loss: 0.00002375
Iteration 50/1000 | Loss: 0.00002375
Iteration 51/1000 | Loss: 0.00002375
Iteration 52/1000 | Loss: 0.00002375
Iteration 53/1000 | Loss: 0.00002375
Iteration 54/1000 | Loss: 0.00002375
Iteration 55/1000 | Loss: 0.00002375
Iteration 56/1000 | Loss: 0.00002375
Iteration 57/1000 | Loss: 0.00002373
Iteration 58/1000 | Loss: 0.00002373
Iteration 59/1000 | Loss: 0.00002372
Iteration 60/1000 | Loss: 0.00002372
Iteration 61/1000 | Loss: 0.00002372
Iteration 62/1000 | Loss: 0.00002372
Iteration 63/1000 | Loss: 0.00002372
Iteration 64/1000 | Loss: 0.00002372
Iteration 65/1000 | Loss: 0.00002372
Iteration 66/1000 | Loss: 0.00002372
Iteration 67/1000 | Loss: 0.00002371
Iteration 68/1000 | Loss: 0.00002371
Iteration 69/1000 | Loss: 0.00002371
Iteration 70/1000 | Loss: 0.00002371
Iteration 71/1000 | Loss: 0.00002371
Iteration 72/1000 | Loss: 0.00002371
Iteration 73/1000 | Loss: 0.00002370
Iteration 74/1000 | Loss: 0.00002370
Iteration 75/1000 | Loss: 0.00002370
Iteration 76/1000 | Loss: 0.00002370
Iteration 77/1000 | Loss: 0.00002369
Iteration 78/1000 | Loss: 0.00002369
Iteration 79/1000 | Loss: 0.00002369
Iteration 80/1000 | Loss: 0.00002369
Iteration 81/1000 | Loss: 0.00002369
Iteration 82/1000 | Loss: 0.00002368
Iteration 83/1000 | Loss: 0.00002368
Iteration 84/1000 | Loss: 0.00002368
Iteration 85/1000 | Loss: 0.00002367
Iteration 86/1000 | Loss: 0.00002367
Iteration 87/1000 | Loss: 0.00002367
Iteration 88/1000 | Loss: 0.00002366
Iteration 89/1000 | Loss: 0.00002366
Iteration 90/1000 | Loss: 0.00002366
Iteration 91/1000 | Loss: 0.00002365
Iteration 92/1000 | Loss: 0.00002365
Iteration 93/1000 | Loss: 0.00002365
Iteration 94/1000 | Loss: 0.00002364
Iteration 95/1000 | Loss: 0.00002364
Iteration 96/1000 | Loss: 0.00002363
Iteration 97/1000 | Loss: 0.00002363
Iteration 98/1000 | Loss: 0.00002363
Iteration 99/1000 | Loss: 0.00002363
Iteration 100/1000 | Loss: 0.00002362
Iteration 101/1000 | Loss: 0.00002362
Iteration 102/1000 | Loss: 0.00002362
Iteration 103/1000 | Loss: 0.00002361
Iteration 104/1000 | Loss: 0.00002361
Iteration 105/1000 | Loss: 0.00002360
Iteration 106/1000 | Loss: 0.00002360
Iteration 107/1000 | Loss: 0.00002360
Iteration 108/1000 | Loss: 0.00002360
Iteration 109/1000 | Loss: 0.00002359
Iteration 110/1000 | Loss: 0.00002359
Iteration 111/1000 | Loss: 0.00002359
Iteration 112/1000 | Loss: 0.00002359
Iteration 113/1000 | Loss: 0.00002358
Iteration 114/1000 | Loss: 0.00002358
Iteration 115/1000 | Loss: 0.00002358
Iteration 116/1000 | Loss: 0.00002358
Iteration 117/1000 | Loss: 0.00002357
Iteration 118/1000 | Loss: 0.00002357
Iteration 119/1000 | Loss: 0.00002357
Iteration 120/1000 | Loss: 0.00002356
Iteration 121/1000 | Loss: 0.00002356
Iteration 122/1000 | Loss: 0.00002356
Iteration 123/1000 | Loss: 0.00002356
Iteration 124/1000 | Loss: 0.00002356
Iteration 125/1000 | Loss: 0.00002356
Iteration 126/1000 | Loss: 0.00002356
Iteration 127/1000 | Loss: 0.00002355
Iteration 128/1000 | Loss: 0.00002355
Iteration 129/1000 | Loss: 0.00002355
Iteration 130/1000 | Loss: 0.00002355
Iteration 131/1000 | Loss: 0.00002355
Iteration 132/1000 | Loss: 0.00002355
Iteration 133/1000 | Loss: 0.00002355
Iteration 134/1000 | Loss: 0.00002354
Iteration 135/1000 | Loss: 0.00002354
Iteration 136/1000 | Loss: 0.00002354
Iteration 137/1000 | Loss: 0.00002354
Iteration 138/1000 | Loss: 0.00002354
Iteration 139/1000 | Loss: 0.00002354
Iteration 140/1000 | Loss: 0.00002354
Iteration 141/1000 | Loss: 0.00002354
Iteration 142/1000 | Loss: 0.00002354
Iteration 143/1000 | Loss: 0.00002354
Iteration 144/1000 | Loss: 0.00002354
Iteration 145/1000 | Loss: 0.00002354
Iteration 146/1000 | Loss: 0.00002354
Iteration 147/1000 | Loss: 0.00002353
Iteration 148/1000 | Loss: 0.00002353
Iteration 149/1000 | Loss: 0.00002353
Iteration 150/1000 | Loss: 0.00002353
Iteration 151/1000 | Loss: 0.00002353
Iteration 152/1000 | Loss: 0.00002353
Iteration 153/1000 | Loss: 0.00002353
Iteration 154/1000 | Loss: 0.00002353
Iteration 155/1000 | Loss: 0.00002353
Iteration 156/1000 | Loss: 0.00002352
Iteration 157/1000 | Loss: 0.00002352
Iteration 158/1000 | Loss: 0.00002352
Iteration 159/1000 | Loss: 0.00002352
Iteration 160/1000 | Loss: 0.00002352
Iteration 161/1000 | Loss: 0.00002352
Iteration 162/1000 | Loss: 0.00002352
Iteration 163/1000 | Loss: 0.00002352
Iteration 164/1000 | Loss: 0.00002352
Iteration 165/1000 | Loss: 0.00002352
Iteration 166/1000 | Loss: 0.00002352
Iteration 167/1000 | Loss: 0.00002352
Iteration 168/1000 | Loss: 0.00002352
Iteration 169/1000 | Loss: 0.00002352
Iteration 170/1000 | Loss: 0.00002352
Iteration 171/1000 | Loss: 0.00002352
Iteration 172/1000 | Loss: 0.00002352
Iteration 173/1000 | Loss: 0.00002352
Iteration 174/1000 | Loss: 0.00002351
Iteration 175/1000 | Loss: 0.00002351
Iteration 176/1000 | Loss: 0.00002351
Iteration 177/1000 | Loss: 0.00002351
Iteration 178/1000 | Loss: 0.00002351
Iteration 179/1000 | Loss: 0.00002351
Iteration 180/1000 | Loss: 0.00002351
Iteration 181/1000 | Loss: 0.00002351
Iteration 182/1000 | Loss: 0.00002351
Iteration 183/1000 | Loss: 0.00002351
Iteration 184/1000 | Loss: 0.00002351
Iteration 185/1000 | Loss: 0.00002351
Iteration 186/1000 | Loss: 0.00002351
Iteration 187/1000 | Loss: 0.00002351
Iteration 188/1000 | Loss: 0.00002351
Iteration 189/1000 | Loss: 0.00002351
Iteration 190/1000 | Loss: 0.00002351
Iteration 191/1000 | Loss: 0.00002351
Iteration 192/1000 | Loss: 0.00002351
Iteration 193/1000 | Loss: 0.00002351
Iteration 194/1000 | Loss: 0.00002351
Iteration 195/1000 | Loss: 0.00002351
Iteration 196/1000 | Loss: 0.00002351
Iteration 197/1000 | Loss: 0.00002351
Iteration 198/1000 | Loss: 0.00002351
Iteration 199/1000 | Loss: 0.00002351
Iteration 200/1000 | Loss: 0.00002351
Iteration 201/1000 | Loss: 0.00002351
Iteration 202/1000 | Loss: 0.00002351
Iteration 203/1000 | Loss: 0.00002351
Iteration 204/1000 | Loss: 0.00002351
Iteration 205/1000 | Loss: 0.00002351
Iteration 206/1000 | Loss: 0.00002351
Iteration 207/1000 | Loss: 0.00002351
Iteration 208/1000 | Loss: 0.00002351
Iteration 209/1000 | Loss: 0.00002351
Iteration 210/1000 | Loss: 0.00002351
Iteration 211/1000 | Loss: 0.00002351
Iteration 212/1000 | Loss: 0.00002351
Iteration 213/1000 | Loss: 0.00002351
Iteration 214/1000 | Loss: 0.00002351
Iteration 215/1000 | Loss: 0.00002351
Iteration 216/1000 | Loss: 0.00002351
Iteration 217/1000 | Loss: 0.00002351
Iteration 218/1000 | Loss: 0.00002351
Iteration 219/1000 | Loss: 0.00002351
Iteration 220/1000 | Loss: 0.00002351
Iteration 221/1000 | Loss: 0.00002351
Iteration 222/1000 | Loss: 0.00002351
Iteration 223/1000 | Loss: 0.00002351
Iteration 224/1000 | Loss: 0.00002351
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 224. Stopping optimization.
Last 5 losses: [2.3506212528445758e-05, 2.3506212528445758e-05, 2.3506212528445758e-05, 2.3506212528445758e-05, 2.3506212528445758e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3506212528445758e-05

Optimization complete. Final v2v error: 3.8927574157714844 mm

Highest mean error: 4.784128665924072 mm for frame 82

Lowest mean error: 3.2108328342437744 mm for frame 10

Saving results

Total time: 853.8613030910492
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1050/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1050.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1050
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00465426
Iteration 2/25 | Loss: 0.00080870
Iteration 3/25 | Loss: 0.00066148
Iteration 4/25 | Loss: 0.00062588
Iteration 5/25 | Loss: 0.00061626
Iteration 6/25 | Loss: 0.00061479
Iteration 7/25 | Loss: 0.00061479
Iteration 8/25 | Loss: 0.00061479
Iteration 9/25 | Loss: 0.00061479
Iteration 10/25 | Loss: 0.00061479
Iteration 11/25 | Loss: 0.00061479
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0006147883832454681, 0.0006147883832454681, 0.0006147883832454681, 0.0006147883832454681, 0.0006147883832454681]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006147883832454681

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57100689
Iteration 2/25 | Loss: 0.00024210
Iteration 3/25 | Loss: 0.00024209
Iteration 4/25 | Loss: 0.00024209
Iteration 5/25 | Loss: 0.00024209
Iteration 6/25 | Loss: 0.00024209
Iteration 7/25 | Loss: 0.00024209
Iteration 8/25 | Loss: 0.00024209
Iteration 9/25 | Loss: 0.00024209
Iteration 10/25 | Loss: 0.00024209
Iteration 11/25 | Loss: 0.00024209
Iteration 12/25 | Loss: 0.00024209
Iteration 13/25 | Loss: 0.00024209
Iteration 14/25 | Loss: 0.00024209
Iteration 15/25 | Loss: 0.00024209
Iteration 16/25 | Loss: 0.00024209
Iteration 17/25 | Loss: 0.00024209
Iteration 18/25 | Loss: 0.00024209
Iteration 19/25 | Loss: 0.00024209
Iteration 20/25 | Loss: 0.00024209
Iteration 21/25 | Loss: 0.00024209
Iteration 22/25 | Loss: 0.00024209
Iteration 23/25 | Loss: 0.00024209
Iteration 24/25 | Loss: 0.00024209
Iteration 25/25 | Loss: 0.00024209

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00024209
Iteration 2/1000 | Loss: 0.00002416
Iteration 3/1000 | Loss: 0.00001766
Iteration 4/1000 | Loss: 0.00001657
Iteration 5/1000 | Loss: 0.00001552
Iteration 6/1000 | Loss: 0.00001500
Iteration 7/1000 | Loss: 0.00001464
Iteration 8/1000 | Loss: 0.00001443
Iteration 9/1000 | Loss: 0.00001433
Iteration 10/1000 | Loss: 0.00001432
Iteration 11/1000 | Loss: 0.00001423
Iteration 12/1000 | Loss: 0.00001423
Iteration 13/1000 | Loss: 0.00001418
Iteration 14/1000 | Loss: 0.00001417
Iteration 15/1000 | Loss: 0.00001411
Iteration 16/1000 | Loss: 0.00001410
Iteration 17/1000 | Loss: 0.00001404
Iteration 18/1000 | Loss: 0.00001400
Iteration 19/1000 | Loss: 0.00001400
Iteration 20/1000 | Loss: 0.00001400
Iteration 21/1000 | Loss: 0.00001400
Iteration 22/1000 | Loss: 0.00001399
Iteration 23/1000 | Loss: 0.00001399
Iteration 24/1000 | Loss: 0.00001399
Iteration 25/1000 | Loss: 0.00001399
Iteration 26/1000 | Loss: 0.00001399
Iteration 27/1000 | Loss: 0.00001399
Iteration 28/1000 | Loss: 0.00001399
Iteration 29/1000 | Loss: 0.00001399
Iteration 30/1000 | Loss: 0.00001399
Iteration 31/1000 | Loss: 0.00001398
Iteration 32/1000 | Loss: 0.00001397
Iteration 33/1000 | Loss: 0.00001396
Iteration 34/1000 | Loss: 0.00001396
Iteration 35/1000 | Loss: 0.00001395
Iteration 36/1000 | Loss: 0.00001395
Iteration 37/1000 | Loss: 0.00001394
Iteration 38/1000 | Loss: 0.00001394
Iteration 39/1000 | Loss: 0.00001393
Iteration 40/1000 | Loss: 0.00001393
Iteration 41/1000 | Loss: 0.00001392
Iteration 42/1000 | Loss: 0.00001392
Iteration 43/1000 | Loss: 0.00001392
Iteration 44/1000 | Loss: 0.00001392
Iteration 45/1000 | Loss: 0.00001392
Iteration 46/1000 | Loss: 0.00001392
Iteration 47/1000 | Loss: 0.00001391
Iteration 48/1000 | Loss: 0.00001391
Iteration 49/1000 | Loss: 0.00001390
Iteration 50/1000 | Loss: 0.00001387
Iteration 51/1000 | Loss: 0.00001387
Iteration 52/1000 | Loss: 0.00001387
Iteration 53/1000 | Loss: 0.00001387
Iteration 54/1000 | Loss: 0.00001387
Iteration 55/1000 | Loss: 0.00001387
Iteration 56/1000 | Loss: 0.00001387
Iteration 57/1000 | Loss: 0.00001386
Iteration 58/1000 | Loss: 0.00001386
Iteration 59/1000 | Loss: 0.00001386
Iteration 60/1000 | Loss: 0.00001386
Iteration 61/1000 | Loss: 0.00001386
Iteration 62/1000 | Loss: 0.00001386
Iteration 63/1000 | Loss: 0.00001386
Iteration 64/1000 | Loss: 0.00001385
Iteration 65/1000 | Loss: 0.00001385
Iteration 66/1000 | Loss: 0.00001382
Iteration 67/1000 | Loss: 0.00001381
Iteration 68/1000 | Loss: 0.00001379
Iteration 69/1000 | Loss: 0.00001378
Iteration 70/1000 | Loss: 0.00001377
Iteration 71/1000 | Loss: 0.00001377
Iteration 72/1000 | Loss: 0.00001377
Iteration 73/1000 | Loss: 0.00001377
Iteration 74/1000 | Loss: 0.00001377
Iteration 75/1000 | Loss: 0.00001377
Iteration 76/1000 | Loss: 0.00001377
Iteration 77/1000 | Loss: 0.00001377
Iteration 78/1000 | Loss: 0.00001377
Iteration 79/1000 | Loss: 0.00001376
Iteration 80/1000 | Loss: 0.00001376
Iteration 81/1000 | Loss: 0.00001376
Iteration 82/1000 | Loss: 0.00001376
Iteration 83/1000 | Loss: 0.00001376
Iteration 84/1000 | Loss: 0.00001375
Iteration 85/1000 | Loss: 0.00001375
Iteration 86/1000 | Loss: 0.00001374
Iteration 87/1000 | Loss: 0.00001373
Iteration 88/1000 | Loss: 0.00001373
Iteration 89/1000 | Loss: 0.00001373
Iteration 90/1000 | Loss: 0.00001373
Iteration 91/1000 | Loss: 0.00001373
Iteration 92/1000 | Loss: 0.00001373
Iteration 93/1000 | Loss: 0.00001373
Iteration 94/1000 | Loss: 0.00001373
Iteration 95/1000 | Loss: 0.00001373
Iteration 96/1000 | Loss: 0.00001373
Iteration 97/1000 | Loss: 0.00001373
Iteration 98/1000 | Loss: 0.00001373
Iteration 99/1000 | Loss: 0.00001372
Iteration 100/1000 | Loss: 0.00001372
Iteration 101/1000 | Loss: 0.00001372
Iteration 102/1000 | Loss: 0.00001372
Iteration 103/1000 | Loss: 0.00001372
Iteration 104/1000 | Loss: 0.00001372
Iteration 105/1000 | Loss: 0.00001372
Iteration 106/1000 | Loss: 0.00001372
Iteration 107/1000 | Loss: 0.00001372
Iteration 108/1000 | Loss: 0.00001372
Iteration 109/1000 | Loss: 0.00001371
Iteration 110/1000 | Loss: 0.00001371
Iteration 111/1000 | Loss: 0.00001371
Iteration 112/1000 | Loss: 0.00001371
Iteration 113/1000 | Loss: 0.00001371
Iteration 114/1000 | Loss: 0.00001371
Iteration 115/1000 | Loss: 0.00001371
Iteration 116/1000 | Loss: 0.00001371
Iteration 117/1000 | Loss: 0.00001371
Iteration 118/1000 | Loss: 0.00001371
Iteration 119/1000 | Loss: 0.00001371
Iteration 120/1000 | Loss: 0.00001371
Iteration 121/1000 | Loss: 0.00001371
Iteration 122/1000 | Loss: 0.00001371
Iteration 123/1000 | Loss: 0.00001371
Iteration 124/1000 | Loss: 0.00001371
Iteration 125/1000 | Loss: 0.00001371
Iteration 126/1000 | Loss: 0.00001371
Iteration 127/1000 | Loss: 0.00001371
Iteration 128/1000 | Loss: 0.00001371
Iteration 129/1000 | Loss: 0.00001371
Iteration 130/1000 | Loss: 0.00001371
Iteration 131/1000 | Loss: 0.00001371
Iteration 132/1000 | Loss: 0.00001371
Iteration 133/1000 | Loss: 0.00001371
Iteration 134/1000 | Loss: 0.00001371
Iteration 135/1000 | Loss: 0.00001371
Iteration 136/1000 | Loss: 0.00001371
Iteration 137/1000 | Loss: 0.00001371
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 137. Stopping optimization.
Last 5 losses: [1.3706448953598738e-05, 1.3706448953598738e-05, 1.3706448953598738e-05, 1.3706448953598738e-05, 1.3706448953598738e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3706448953598738e-05

Optimization complete. Final v2v error: 3.169229507446289 mm

Highest mean error: 3.511061191558838 mm for frame 24

Lowest mean error: 3.02313494682312 mm for frame 12

Saving results

Total time: 940.3739106655121
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1089/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1089.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1089
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00371945
Iteration 2/25 | Loss: 0.00070015
Iteration 3/25 | Loss: 0.00060753
Iteration 4/25 | Loss: 0.00058928
Iteration 5/25 | Loss: 0.00058354
Iteration 6/25 | Loss: 0.00058245
Iteration 7/25 | Loss: 0.00058243
Iteration 8/25 | Loss: 0.00058243
Iteration 9/25 | Loss: 0.00058243
Iteration 10/25 | Loss: 0.00058243
Iteration 11/25 | Loss: 0.00058243
Iteration 12/25 | Loss: 0.00058243
Iteration 13/25 | Loss: 0.00058243
Iteration 14/25 | Loss: 0.00058243
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0005824278923682868, 0.0005824278923682868, 0.0005824278923682868, 0.0005824278923682868, 0.0005824278923682868]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005824278923682868

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53367889
Iteration 2/25 | Loss: 0.00026278
Iteration 3/25 | Loss: 0.00026278
Iteration 4/25 | Loss: 0.00026278
Iteration 5/25 | Loss: 0.00026278
Iteration 6/25 | Loss: 0.00026278
Iteration 7/25 | Loss: 0.00026278
Iteration 8/25 | Loss: 0.00026278
Iteration 9/25 | Loss: 0.00026278
Iteration 10/25 | Loss: 0.00026278
Iteration 11/25 | Loss: 0.00026278
Iteration 12/25 | Loss: 0.00026278
Iteration 13/25 | Loss: 0.00026278
Iteration 14/25 | Loss: 0.00026278
Iteration 15/25 | Loss: 0.00026278
Iteration 16/25 | Loss: 0.00026278
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00026277650613337755, 0.00026277650613337755, 0.00026277650613337755, 0.00026277650613337755, 0.00026277650613337755]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00026277650613337755

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026278
Iteration 2/1000 | Loss: 0.00002129
Iteration 3/1000 | Loss: 0.00001350
Iteration 4/1000 | Loss: 0.00001245
Iteration 5/1000 | Loss: 0.00001176
Iteration 6/1000 | Loss: 0.00001176
Iteration 7/1000 | Loss: 0.00001176
Iteration 8/1000 | Loss: 0.00001129
Iteration 9/1000 | Loss: 0.00001110
Iteration 10/1000 | Loss: 0.00001107
Iteration 11/1000 | Loss: 0.00001098
Iteration 12/1000 | Loss: 0.00001097
Iteration 13/1000 | Loss: 0.00001096
Iteration 14/1000 | Loss: 0.00001096
Iteration 15/1000 | Loss: 0.00001094
Iteration 16/1000 | Loss: 0.00001090
Iteration 17/1000 | Loss: 0.00001089
Iteration 18/1000 | Loss: 0.00001089
Iteration 19/1000 | Loss: 0.00001088
Iteration 20/1000 | Loss: 0.00001084
Iteration 21/1000 | Loss: 0.00001084
Iteration 22/1000 | Loss: 0.00001083
Iteration 23/1000 | Loss: 0.00001083
Iteration 24/1000 | Loss: 0.00001083
Iteration 25/1000 | Loss: 0.00001083
Iteration 26/1000 | Loss: 0.00001082
Iteration 27/1000 | Loss: 0.00001082
Iteration 28/1000 | Loss: 0.00001079
Iteration 29/1000 | Loss: 0.00001079
Iteration 30/1000 | Loss: 0.00001078
Iteration 31/1000 | Loss: 0.00001078
Iteration 32/1000 | Loss: 0.00001078
Iteration 33/1000 | Loss: 0.00001077
Iteration 34/1000 | Loss: 0.00001077
Iteration 35/1000 | Loss: 0.00001077
Iteration 36/1000 | Loss: 0.00001076
Iteration 37/1000 | Loss: 0.00001076
Iteration 38/1000 | Loss: 0.00001076
Iteration 39/1000 | Loss: 0.00001075
Iteration 40/1000 | Loss: 0.00001075
Iteration 41/1000 | Loss: 0.00001074
Iteration 42/1000 | Loss: 0.00001074
Iteration 43/1000 | Loss: 0.00001074
Iteration 44/1000 | Loss: 0.00001073
Iteration 45/1000 | Loss: 0.00001073
Iteration 46/1000 | Loss: 0.00001072
Iteration 47/1000 | Loss: 0.00001072
Iteration 48/1000 | Loss: 0.00001072
Iteration 49/1000 | Loss: 0.00001072
Iteration 50/1000 | Loss: 0.00001072
Iteration 51/1000 | Loss: 0.00001071
Iteration 52/1000 | Loss: 0.00001068
Iteration 53/1000 | Loss: 0.00001068
Iteration 54/1000 | Loss: 0.00001067
Iteration 55/1000 | Loss: 0.00001067
Iteration 56/1000 | Loss: 0.00001066
Iteration 57/1000 | Loss: 0.00001066
Iteration 58/1000 | Loss: 0.00001066
Iteration 59/1000 | Loss: 0.00001066
Iteration 60/1000 | Loss: 0.00001065
Iteration 61/1000 | Loss: 0.00001065
Iteration 62/1000 | Loss: 0.00001065
Iteration 63/1000 | Loss: 0.00001065
Iteration 64/1000 | Loss: 0.00001065
Iteration 65/1000 | Loss: 0.00001065
Iteration 66/1000 | Loss: 0.00001065
Iteration 67/1000 | Loss: 0.00001065
Iteration 68/1000 | Loss: 0.00001065
Iteration 69/1000 | Loss: 0.00001064
Iteration 70/1000 | Loss: 0.00001064
Iteration 71/1000 | Loss: 0.00001064
Iteration 72/1000 | Loss: 0.00001064
Iteration 73/1000 | Loss: 0.00001064
Iteration 74/1000 | Loss: 0.00001063
Iteration 75/1000 | Loss: 0.00001063
Iteration 76/1000 | Loss: 0.00001062
Iteration 77/1000 | Loss: 0.00001062
Iteration 78/1000 | Loss: 0.00001062
Iteration 79/1000 | Loss: 0.00001062
Iteration 80/1000 | Loss: 0.00001061
Iteration 81/1000 | Loss: 0.00001061
Iteration 82/1000 | Loss: 0.00001061
Iteration 83/1000 | Loss: 0.00001061
Iteration 84/1000 | Loss: 0.00001061
Iteration 85/1000 | Loss: 0.00001061
Iteration 86/1000 | Loss: 0.00001061
Iteration 87/1000 | Loss: 0.00001060
Iteration 88/1000 | Loss: 0.00001060
Iteration 89/1000 | Loss: 0.00001060
Iteration 90/1000 | Loss: 0.00001060
Iteration 91/1000 | Loss: 0.00001060
Iteration 92/1000 | Loss: 0.00001060
Iteration 93/1000 | Loss: 0.00001059
Iteration 94/1000 | Loss: 0.00001059
Iteration 95/1000 | Loss: 0.00001059
Iteration 96/1000 | Loss: 0.00001059
Iteration 97/1000 | Loss: 0.00001058
Iteration 98/1000 | Loss: 0.00001058
Iteration 99/1000 | Loss: 0.00001058
Iteration 100/1000 | Loss: 0.00001058
Iteration 101/1000 | Loss: 0.00001057
Iteration 102/1000 | Loss: 0.00001057
Iteration 103/1000 | Loss: 0.00001057
Iteration 104/1000 | Loss: 0.00001056
Iteration 105/1000 | Loss: 0.00001056
Iteration 106/1000 | Loss: 0.00001056
Iteration 107/1000 | Loss: 0.00001055
Iteration 108/1000 | Loss: 0.00001055
Iteration 109/1000 | Loss: 0.00001055
Iteration 110/1000 | Loss: 0.00001054
Iteration 111/1000 | Loss: 0.00001054
Iteration 112/1000 | Loss: 0.00001053
Iteration 113/1000 | Loss: 0.00001053
Iteration 114/1000 | Loss: 0.00001053
Iteration 115/1000 | Loss: 0.00001052
Iteration 116/1000 | Loss: 0.00001052
Iteration 117/1000 | Loss: 0.00001052
Iteration 118/1000 | Loss: 0.00001052
Iteration 119/1000 | Loss: 0.00001052
Iteration 120/1000 | Loss: 0.00001052
Iteration 121/1000 | Loss: 0.00001051
Iteration 122/1000 | Loss: 0.00001051
Iteration 123/1000 | Loss: 0.00001051
Iteration 124/1000 | Loss: 0.00001051
Iteration 125/1000 | Loss: 0.00001051
Iteration 126/1000 | Loss: 0.00001051
Iteration 127/1000 | Loss: 0.00001051
Iteration 128/1000 | Loss: 0.00001051
Iteration 129/1000 | Loss: 0.00001051
Iteration 130/1000 | Loss: 0.00001051
Iteration 131/1000 | Loss: 0.00001051
Iteration 132/1000 | Loss: 0.00001050
Iteration 133/1000 | Loss: 0.00001050
Iteration 134/1000 | Loss: 0.00001050
Iteration 135/1000 | Loss: 0.00001050
Iteration 136/1000 | Loss: 0.00001049
Iteration 137/1000 | Loss: 0.00001049
Iteration 138/1000 | Loss: 0.00001049
Iteration 139/1000 | Loss: 0.00001049
Iteration 140/1000 | Loss: 0.00001049
Iteration 141/1000 | Loss: 0.00001049
Iteration 142/1000 | Loss: 0.00001048
Iteration 143/1000 | Loss: 0.00001048
Iteration 144/1000 | Loss: 0.00001048
Iteration 145/1000 | Loss: 0.00001048
Iteration 146/1000 | Loss: 0.00001048
Iteration 147/1000 | Loss: 0.00001048
Iteration 148/1000 | Loss: 0.00001048
Iteration 149/1000 | Loss: 0.00001048
Iteration 150/1000 | Loss: 0.00001047
Iteration 151/1000 | Loss: 0.00001047
Iteration 152/1000 | Loss: 0.00001047
Iteration 153/1000 | Loss: 0.00001047
Iteration 154/1000 | Loss: 0.00001047
Iteration 155/1000 | Loss: 0.00001046
Iteration 156/1000 | Loss: 0.00001046
Iteration 157/1000 | Loss: 0.00001046
Iteration 158/1000 | Loss: 0.00001046
Iteration 159/1000 | Loss: 0.00001046
Iteration 160/1000 | Loss: 0.00001046
Iteration 161/1000 | Loss: 0.00001046
Iteration 162/1000 | Loss: 0.00001046
Iteration 163/1000 | Loss: 0.00001046
Iteration 164/1000 | Loss: 0.00001046
Iteration 165/1000 | Loss: 0.00001046
Iteration 166/1000 | Loss: 0.00001046
Iteration 167/1000 | Loss: 0.00001046
Iteration 168/1000 | Loss: 0.00001046
Iteration 169/1000 | Loss: 0.00001046
Iteration 170/1000 | Loss: 0.00001045
Iteration 171/1000 | Loss: 0.00001045
Iteration 172/1000 | Loss: 0.00001045
Iteration 173/1000 | Loss: 0.00001045
Iteration 174/1000 | Loss: 0.00001045
Iteration 175/1000 | Loss: 0.00001045
Iteration 176/1000 | Loss: 0.00001045
Iteration 177/1000 | Loss: 0.00001044
Iteration 178/1000 | Loss: 0.00001044
Iteration 179/1000 | Loss: 0.00001044
Iteration 180/1000 | Loss: 0.00001044
Iteration 181/1000 | Loss: 0.00001044
Iteration 182/1000 | Loss: 0.00001044
Iteration 183/1000 | Loss: 0.00001044
Iteration 184/1000 | Loss: 0.00001044
Iteration 185/1000 | Loss: 0.00001044
Iteration 186/1000 | Loss: 0.00001044
Iteration 187/1000 | Loss: 0.00001044
Iteration 188/1000 | Loss: 0.00001044
Iteration 189/1000 | Loss: 0.00001044
Iteration 190/1000 | Loss: 0.00001044
Iteration 191/1000 | Loss: 0.00001044
Iteration 192/1000 | Loss: 0.00001044
Iteration 193/1000 | Loss: 0.00001044
Iteration 194/1000 | Loss: 0.00001043
Iteration 195/1000 | Loss: 0.00001043
Iteration 196/1000 | Loss: 0.00001043
Iteration 197/1000 | Loss: 0.00001043
Iteration 198/1000 | Loss: 0.00001043
Iteration 199/1000 | Loss: 0.00001043
Iteration 200/1000 | Loss: 0.00001043
Iteration 201/1000 | Loss: 0.00001043
Iteration 202/1000 | Loss: 0.00001043
Iteration 203/1000 | Loss: 0.00001043
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 203. Stopping optimization.
Last 5 losses: [1.0433704119350296e-05, 1.0433704119350296e-05, 1.0433704119350296e-05, 1.0433704119350296e-05, 1.0433704119350296e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0433704119350296e-05

Optimization complete. Final v2v error: 2.7642807960510254 mm

Highest mean error: 2.8803670406341553 mm for frame 24

Lowest mean error: 2.668015956878662 mm for frame 161

Saving results

Total time: 1026.263129234314
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1088/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1088.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1088
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00820559
Iteration 2/25 | Loss: 0.00116638
Iteration 3/25 | Loss: 0.00081784
Iteration 4/25 | Loss: 0.00074527
Iteration 5/25 | Loss: 0.00073157
Iteration 6/25 | Loss: 0.00072967
Iteration 7/25 | Loss: 0.00072953
Iteration 8/25 | Loss: 0.00072953
Iteration 9/25 | Loss: 0.00072953
Iteration 10/25 | Loss: 0.00072953
Iteration 11/25 | Loss: 0.00072953
Iteration 12/25 | Loss: 0.00072953
Iteration 13/25 | Loss: 0.00072953
Iteration 14/25 | Loss: 0.00072953
Iteration 15/25 | Loss: 0.00072953
Iteration 16/25 | Loss: 0.00072953
Iteration 17/25 | Loss: 0.00072953
Iteration 18/25 | Loss: 0.00072953
Iteration 19/25 | Loss: 0.00072953
Iteration 20/25 | Loss: 0.00072953
Iteration 21/25 | Loss: 0.00072953
Iteration 22/25 | Loss: 0.00072953
Iteration 23/25 | Loss: 0.00072953
Iteration 24/25 | Loss: 0.00072953
Iteration 25/25 | Loss: 0.00072953

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47239399
Iteration 2/25 | Loss: 0.00039541
Iteration 3/25 | Loss: 0.00039535
Iteration 4/25 | Loss: 0.00039534
Iteration 5/25 | Loss: 0.00039534
Iteration 6/25 | Loss: 0.00039534
Iteration 7/25 | Loss: 0.00039534
Iteration 8/25 | Loss: 0.00039534
Iteration 9/25 | Loss: 0.00039534
Iteration 10/25 | Loss: 0.00039534
Iteration 11/25 | Loss: 0.00039534
Iteration 12/25 | Loss: 0.00039534
Iteration 13/25 | Loss: 0.00039534
Iteration 14/25 | Loss: 0.00039534
Iteration 15/25 | Loss: 0.00039534
Iteration 16/25 | Loss: 0.00039534
Iteration 17/25 | Loss: 0.00039534
Iteration 18/25 | Loss: 0.00039534
Iteration 19/25 | Loss: 0.00039534
Iteration 20/25 | Loss: 0.00039534
Iteration 21/25 | Loss: 0.00039534
Iteration 22/25 | Loss: 0.00039534
Iteration 23/25 | Loss: 0.00039534
Iteration 24/25 | Loss: 0.00039534
Iteration 25/25 | Loss: 0.00039534

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039534
Iteration 2/1000 | Loss: 0.00004965
Iteration 3/1000 | Loss: 0.00002997
Iteration 4/1000 | Loss: 0.00002404
Iteration 5/1000 | Loss: 0.00002174
Iteration 6/1000 | Loss: 0.00002046
Iteration 7/1000 | Loss: 0.00001960
Iteration 8/1000 | Loss: 0.00001903
Iteration 9/1000 | Loss: 0.00001863
Iteration 10/1000 | Loss: 0.00001832
Iteration 11/1000 | Loss: 0.00001804
Iteration 12/1000 | Loss: 0.00001781
Iteration 13/1000 | Loss: 0.00001753
Iteration 14/1000 | Loss: 0.00001750
Iteration 15/1000 | Loss: 0.00001742
Iteration 16/1000 | Loss: 0.00001742
Iteration 17/1000 | Loss: 0.00001737
Iteration 18/1000 | Loss: 0.00001731
Iteration 19/1000 | Loss: 0.00001726
Iteration 20/1000 | Loss: 0.00001726
Iteration 21/1000 | Loss: 0.00001721
Iteration 22/1000 | Loss: 0.00001715
Iteration 23/1000 | Loss: 0.00001714
Iteration 24/1000 | Loss: 0.00001714
Iteration 25/1000 | Loss: 0.00001713
Iteration 26/1000 | Loss: 0.00001713
Iteration 27/1000 | Loss: 0.00001712
Iteration 28/1000 | Loss: 0.00001711
Iteration 29/1000 | Loss: 0.00001711
Iteration 30/1000 | Loss: 0.00001711
Iteration 31/1000 | Loss: 0.00001710
Iteration 32/1000 | Loss: 0.00001710
Iteration 33/1000 | Loss: 0.00001709
Iteration 34/1000 | Loss: 0.00001709
Iteration 35/1000 | Loss: 0.00001709
Iteration 36/1000 | Loss: 0.00001708
Iteration 37/1000 | Loss: 0.00001706
Iteration 38/1000 | Loss: 0.00001706
Iteration 39/1000 | Loss: 0.00001706
Iteration 40/1000 | Loss: 0.00001706
Iteration 41/1000 | Loss: 0.00001706
Iteration 42/1000 | Loss: 0.00001706
Iteration 43/1000 | Loss: 0.00001706
Iteration 44/1000 | Loss: 0.00001706
Iteration 45/1000 | Loss: 0.00001706
Iteration 46/1000 | Loss: 0.00001706
Iteration 47/1000 | Loss: 0.00001706
Iteration 48/1000 | Loss: 0.00001705
Iteration 49/1000 | Loss: 0.00001705
Iteration 50/1000 | Loss: 0.00001705
Iteration 51/1000 | Loss: 0.00001704
Iteration 52/1000 | Loss: 0.00001704
Iteration 53/1000 | Loss: 0.00001704
Iteration 54/1000 | Loss: 0.00001704
Iteration 55/1000 | Loss: 0.00001704
Iteration 56/1000 | Loss: 0.00001704
Iteration 57/1000 | Loss: 0.00001703
Iteration 58/1000 | Loss: 0.00001703
Iteration 59/1000 | Loss: 0.00001703
Iteration 60/1000 | Loss: 0.00001703
Iteration 61/1000 | Loss: 0.00001703
Iteration 62/1000 | Loss: 0.00001703
Iteration 63/1000 | Loss: 0.00001703
Iteration 64/1000 | Loss: 0.00001702
Iteration 65/1000 | Loss: 0.00001702
Iteration 66/1000 | Loss: 0.00001702
Iteration 67/1000 | Loss: 0.00001701
Iteration 68/1000 | Loss: 0.00001701
Iteration 69/1000 | Loss: 0.00001701
Iteration 70/1000 | Loss: 0.00001701
Iteration 71/1000 | Loss: 0.00001700
Iteration 72/1000 | Loss: 0.00001700
Iteration 73/1000 | Loss: 0.00001700
Iteration 74/1000 | Loss: 0.00001700
Iteration 75/1000 | Loss: 0.00001699
Iteration 76/1000 | Loss: 0.00001699
Iteration 77/1000 | Loss: 0.00001699
Iteration 78/1000 | Loss: 0.00001699
Iteration 79/1000 | Loss: 0.00001698
Iteration 80/1000 | Loss: 0.00001698
Iteration 81/1000 | Loss: 0.00001698
Iteration 82/1000 | Loss: 0.00001698
Iteration 83/1000 | Loss: 0.00001698
Iteration 84/1000 | Loss: 0.00001698
Iteration 85/1000 | Loss: 0.00001698
Iteration 86/1000 | Loss: 0.00001698
Iteration 87/1000 | Loss: 0.00001698
Iteration 88/1000 | Loss: 0.00001698
Iteration 89/1000 | Loss: 0.00001697
Iteration 90/1000 | Loss: 0.00001697
Iteration 91/1000 | Loss: 0.00001697
Iteration 92/1000 | Loss: 0.00001697
Iteration 93/1000 | Loss: 0.00001697
Iteration 94/1000 | Loss: 0.00001697
Iteration 95/1000 | Loss: 0.00001697
Iteration 96/1000 | Loss: 0.00001697
Iteration 97/1000 | Loss: 0.00001697
Iteration 98/1000 | Loss: 0.00001697
Iteration 99/1000 | Loss: 0.00001697
Iteration 100/1000 | Loss: 0.00001697
Iteration 101/1000 | Loss: 0.00001697
Iteration 102/1000 | Loss: 0.00001697
Iteration 103/1000 | Loss: 0.00001697
Iteration 104/1000 | Loss: 0.00001697
Iteration 105/1000 | Loss: 0.00001697
Iteration 106/1000 | Loss: 0.00001696
Iteration 107/1000 | Loss: 0.00001696
Iteration 108/1000 | Loss: 0.00001696
Iteration 109/1000 | Loss: 0.00001696
Iteration 110/1000 | Loss: 0.00001696
Iteration 111/1000 | Loss: 0.00001696
Iteration 112/1000 | Loss: 0.00001696
Iteration 113/1000 | Loss: 0.00001696
Iteration 114/1000 | Loss: 0.00001696
Iteration 115/1000 | Loss: 0.00001696
Iteration 116/1000 | Loss: 0.00001696
Iteration 117/1000 | Loss: 0.00001696
Iteration 118/1000 | Loss: 0.00001696
Iteration 119/1000 | Loss: 0.00001696
Iteration 120/1000 | Loss: 0.00001696
Iteration 121/1000 | Loss: 0.00001696
Iteration 122/1000 | Loss: 0.00001696
Iteration 123/1000 | Loss: 0.00001695
Iteration 124/1000 | Loss: 0.00001695
Iteration 125/1000 | Loss: 0.00001695
Iteration 126/1000 | Loss: 0.00001695
Iteration 127/1000 | Loss: 0.00001695
Iteration 128/1000 | Loss: 0.00001695
Iteration 129/1000 | Loss: 0.00001695
Iteration 130/1000 | Loss: 0.00001695
Iteration 131/1000 | Loss: 0.00001695
Iteration 132/1000 | Loss: 0.00001695
Iteration 133/1000 | Loss: 0.00001695
Iteration 134/1000 | Loss: 0.00001695
Iteration 135/1000 | Loss: 0.00001695
Iteration 136/1000 | Loss: 0.00001695
Iteration 137/1000 | Loss: 0.00001695
Iteration 138/1000 | Loss: 0.00001695
Iteration 139/1000 | Loss: 0.00001695
Iteration 140/1000 | Loss: 0.00001695
Iteration 141/1000 | Loss: 0.00001695
Iteration 142/1000 | Loss: 0.00001695
Iteration 143/1000 | Loss: 0.00001695
Iteration 144/1000 | Loss: 0.00001695
Iteration 145/1000 | Loss: 0.00001695
Iteration 146/1000 | Loss: 0.00001695
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 146. Stopping optimization.
Last 5 losses: [1.694802995189093e-05, 1.694802995189093e-05, 1.694802995189093e-05, 1.694802995189093e-05, 1.694802995189093e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.694802995189093e-05

Optimization complete. Final v2v error: 3.506138563156128 mm

Highest mean error: 3.8501696586608887 mm for frame 29

Lowest mean error: 3.248427391052246 mm for frame 119

Saving results

Total time: 644.8174085617065
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1017
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00572048
Iteration 2/25 | Loss: 0.00095117
Iteration 3/25 | Loss: 0.00077229
Iteration 4/25 | Loss: 0.00072492
Iteration 5/25 | Loss: 0.00071553
Iteration 6/25 | Loss: 0.00071325
Iteration 7/25 | Loss: 0.00071260
Iteration 8/25 | Loss: 0.00071260
Iteration 9/25 | Loss: 0.00071260
Iteration 10/25 | Loss: 0.00071260
Iteration 11/25 | Loss: 0.00071260
Iteration 12/25 | Loss: 0.00071260
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007126046693883836, 0.0007126046693883836, 0.0007126046693883836, 0.0007126046693883836, 0.0007126046693883836]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007126046693883836

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44102812
Iteration 2/25 | Loss: 0.00046678
Iteration 3/25 | Loss: 0.00046678
Iteration 4/25 | Loss: 0.00046678
Iteration 5/25 | Loss: 0.00046678
Iteration 6/25 | Loss: 0.00046678
Iteration 7/25 | Loss: 0.00046678
Iteration 8/25 | Loss: 0.00046678
Iteration 9/25 | Loss: 0.00046678
Iteration 10/25 | Loss: 0.00046678
Iteration 11/25 | Loss: 0.00046678
Iteration 12/25 | Loss: 0.00046678
Iteration 13/25 | Loss: 0.00046678
Iteration 14/25 | Loss: 0.00046678
Iteration 15/25 | Loss: 0.00046678
Iteration 16/25 | Loss: 0.00046678
Iteration 17/25 | Loss: 0.00046678
Iteration 18/25 | Loss: 0.00046678
Iteration 19/25 | Loss: 0.00046678
Iteration 20/25 | Loss: 0.00046678
Iteration 21/25 | Loss: 0.00046678
Iteration 22/25 | Loss: 0.00046678
Iteration 23/25 | Loss: 0.00046678
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00046677945647388697, 0.00046677945647388697, 0.00046677945647388697, 0.00046677945647388697, 0.00046677945647388697]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00046677945647388697

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046678
Iteration 2/1000 | Loss: 0.00004118
Iteration 3/1000 | Loss: 0.00002372
Iteration 4/1000 | Loss: 0.00001979
Iteration 5/1000 | Loss: 0.00001851
Iteration 6/1000 | Loss: 0.00001767
Iteration 7/1000 | Loss: 0.00001716
Iteration 8/1000 | Loss: 0.00001683
Iteration 9/1000 | Loss: 0.00001661
Iteration 10/1000 | Loss: 0.00001646
Iteration 11/1000 | Loss: 0.00001637
Iteration 12/1000 | Loss: 0.00001626
Iteration 13/1000 | Loss: 0.00001625
Iteration 14/1000 | Loss: 0.00001622
Iteration 15/1000 | Loss: 0.00001621
Iteration 16/1000 | Loss: 0.00001620
Iteration 17/1000 | Loss: 0.00001619
Iteration 18/1000 | Loss: 0.00001619
Iteration 19/1000 | Loss: 0.00001616
Iteration 20/1000 | Loss: 0.00001616
Iteration 21/1000 | Loss: 0.00001614
Iteration 22/1000 | Loss: 0.00001613
Iteration 23/1000 | Loss: 0.00001608
Iteration 24/1000 | Loss: 0.00001608
Iteration 25/1000 | Loss: 0.00001605
Iteration 26/1000 | Loss: 0.00001605
Iteration 27/1000 | Loss: 0.00001605
Iteration 28/1000 | Loss: 0.00001605
Iteration 29/1000 | Loss: 0.00001605
Iteration 30/1000 | Loss: 0.00001605
Iteration 31/1000 | Loss: 0.00001604
Iteration 32/1000 | Loss: 0.00001604
Iteration 33/1000 | Loss: 0.00001604
Iteration 34/1000 | Loss: 0.00001604
Iteration 35/1000 | Loss: 0.00001604
Iteration 36/1000 | Loss: 0.00001602
Iteration 37/1000 | Loss: 0.00001602
Iteration 38/1000 | Loss: 0.00001601
Iteration 39/1000 | Loss: 0.00001601
Iteration 40/1000 | Loss: 0.00001600
Iteration 41/1000 | Loss: 0.00001600
Iteration 42/1000 | Loss: 0.00001600
Iteration 43/1000 | Loss: 0.00001599
Iteration 44/1000 | Loss: 0.00001599
Iteration 45/1000 | Loss: 0.00001599
Iteration 46/1000 | Loss: 0.00001598
Iteration 47/1000 | Loss: 0.00001598
Iteration 48/1000 | Loss: 0.00001598
Iteration 49/1000 | Loss: 0.00001597
Iteration 50/1000 | Loss: 0.00001597
Iteration 51/1000 | Loss: 0.00001597
Iteration 52/1000 | Loss: 0.00001597
Iteration 53/1000 | Loss: 0.00001596
Iteration 54/1000 | Loss: 0.00001596
Iteration 55/1000 | Loss: 0.00001595
Iteration 56/1000 | Loss: 0.00001595
Iteration 57/1000 | Loss: 0.00001595
Iteration 58/1000 | Loss: 0.00001595
Iteration 59/1000 | Loss: 0.00001595
Iteration 60/1000 | Loss: 0.00001594
Iteration 61/1000 | Loss: 0.00001594
Iteration 62/1000 | Loss: 0.00001594
Iteration 63/1000 | Loss: 0.00001594
Iteration 64/1000 | Loss: 0.00001594
Iteration 65/1000 | Loss: 0.00001594
Iteration 66/1000 | Loss: 0.00001593
Iteration 67/1000 | Loss: 0.00001593
Iteration 68/1000 | Loss: 0.00001593
Iteration 69/1000 | Loss: 0.00001593
Iteration 70/1000 | Loss: 0.00001593
Iteration 71/1000 | Loss: 0.00001593
Iteration 72/1000 | Loss: 0.00001593
Iteration 73/1000 | Loss: 0.00001592
Iteration 74/1000 | Loss: 0.00001592
Iteration 75/1000 | Loss: 0.00001592
Iteration 76/1000 | Loss: 0.00001592
Iteration 77/1000 | Loss: 0.00001591
Iteration 78/1000 | Loss: 0.00001591
Iteration 79/1000 | Loss: 0.00001591
Iteration 80/1000 | Loss: 0.00001590
Iteration 81/1000 | Loss: 0.00001590
Iteration 82/1000 | Loss: 0.00001590
Iteration 83/1000 | Loss: 0.00001589
Iteration 84/1000 | Loss: 0.00001589
Iteration 85/1000 | Loss: 0.00001588
Iteration 86/1000 | Loss: 0.00001588
Iteration 87/1000 | Loss: 0.00001588
Iteration 88/1000 | Loss: 0.00001588
Iteration 89/1000 | Loss: 0.00001588
Iteration 90/1000 | Loss: 0.00001588
Iteration 91/1000 | Loss: 0.00001588
Iteration 92/1000 | Loss: 0.00001588
Iteration 93/1000 | Loss: 0.00001588
Iteration 94/1000 | Loss: 0.00001587
Iteration 95/1000 | Loss: 0.00001587
Iteration 96/1000 | Loss: 0.00001587
Iteration 97/1000 | Loss: 0.00001586
Iteration 98/1000 | Loss: 0.00001586
Iteration 99/1000 | Loss: 0.00001585
Iteration 100/1000 | Loss: 0.00001585
Iteration 101/1000 | Loss: 0.00001585
Iteration 102/1000 | Loss: 0.00001585
Iteration 103/1000 | Loss: 0.00001585
Iteration 104/1000 | Loss: 0.00001584
Iteration 105/1000 | Loss: 0.00001584
Iteration 106/1000 | Loss: 0.00001584
Iteration 107/1000 | Loss: 0.00001584
Iteration 108/1000 | Loss: 0.00001584
Iteration 109/1000 | Loss: 0.00001583
Iteration 110/1000 | Loss: 0.00001583
Iteration 111/1000 | Loss: 0.00001583
Iteration 112/1000 | Loss: 0.00001583
Iteration 113/1000 | Loss: 0.00001583
Iteration 114/1000 | Loss: 0.00001583
Iteration 115/1000 | Loss: 0.00001582
Iteration 116/1000 | Loss: 0.00001582
Iteration 117/1000 | Loss: 0.00001582
Iteration 118/1000 | Loss: 0.00001582
Iteration 119/1000 | Loss: 0.00001582
Iteration 120/1000 | Loss: 0.00001582
Iteration 121/1000 | Loss: 0.00001582
Iteration 122/1000 | Loss: 0.00001581
Iteration 123/1000 | Loss: 0.00001581
Iteration 124/1000 | Loss: 0.00001581
Iteration 125/1000 | Loss: 0.00001581
Iteration 126/1000 | Loss: 0.00001581
Iteration 127/1000 | Loss: 0.00001581
Iteration 128/1000 | Loss: 0.00001580
Iteration 129/1000 | Loss: 0.00001580
Iteration 130/1000 | Loss: 0.00001580
Iteration 131/1000 | Loss: 0.00001580
Iteration 132/1000 | Loss: 0.00001580
Iteration 133/1000 | Loss: 0.00001580
Iteration 134/1000 | Loss: 0.00001580
Iteration 135/1000 | Loss: 0.00001580
Iteration 136/1000 | Loss: 0.00001580
Iteration 137/1000 | Loss: 0.00001580
Iteration 138/1000 | Loss: 0.00001580
Iteration 139/1000 | Loss: 0.00001580
Iteration 140/1000 | Loss: 0.00001579
Iteration 141/1000 | Loss: 0.00001579
Iteration 142/1000 | Loss: 0.00001579
Iteration 143/1000 | Loss: 0.00001579
Iteration 144/1000 | Loss: 0.00001579
Iteration 145/1000 | Loss: 0.00001579
Iteration 146/1000 | Loss: 0.00001579
Iteration 147/1000 | Loss: 0.00001579
Iteration 148/1000 | Loss: 0.00001579
Iteration 149/1000 | Loss: 0.00001579
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 149. Stopping optimization.
Last 5 losses: [1.5791763871675357e-05, 1.5791763871675357e-05, 1.5791763871675357e-05, 1.5791763871675357e-05, 1.5791763871675357e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5791763871675357e-05

Optimization complete. Final v2v error: 3.373305559158325 mm

Highest mean error: 4.1896209716796875 mm for frame 67

Lowest mean error: 2.9377896785736084 mm for frame 230

Saving results

Total time: 1301.4670445919037
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1011
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01071345
Iteration 2/25 | Loss: 0.00234399
Iteration 3/25 | Loss: 0.00222906
Iteration 4/25 | Loss: 0.00125123
Iteration 5/25 | Loss: 0.00117760
Iteration 6/25 | Loss: 0.00109497
Iteration 7/25 | Loss: 0.00107766
Iteration 8/25 | Loss: 0.00094859
Iteration 9/25 | Loss: 0.00091358
Iteration 10/25 | Loss: 0.00089190
Iteration 11/25 | Loss: 0.00086836
Iteration 12/25 | Loss: 0.00085920
Iteration 13/25 | Loss: 0.00084426
Iteration 14/25 | Loss: 0.00084249
Iteration 15/25 | Loss: 0.00084375
Iteration 16/25 | Loss: 0.00082461
Iteration 17/25 | Loss: 0.00081663
Iteration 18/25 | Loss: 0.00081443
Iteration 19/25 | Loss: 0.00081278
Iteration 20/25 | Loss: 0.00080949
Iteration 21/25 | Loss: 0.00080436
Iteration 22/25 | Loss: 0.00080162
Iteration 23/25 | Loss: 0.00080437
Iteration 24/25 | Loss: 0.00080172
Iteration 25/25 | Loss: 0.00080024

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42259157
Iteration 2/25 | Loss: 0.00074267
Iteration 3/25 | Loss: 0.00069423
Iteration 4/25 | Loss: 0.00069423
Iteration 5/25 | Loss: 0.00069423
Iteration 6/25 | Loss: 0.00069423
Iteration 7/25 | Loss: 0.00069422
Iteration 8/25 | Loss: 0.00069422
Iteration 9/25 | Loss: 0.00069422
Iteration 10/25 | Loss: 0.00069422
Iteration 11/25 | Loss: 0.00069422
Iteration 12/25 | Loss: 0.00069422
Iteration 13/25 | Loss: 0.00069422
Iteration 14/25 | Loss: 0.00069422
Iteration 15/25 | Loss: 0.00069422
Iteration 16/25 | Loss: 0.00069422
Iteration 17/25 | Loss: 0.00069422
Iteration 18/25 | Loss: 0.00069422
Iteration 19/25 | Loss: 0.00069422
Iteration 20/25 | Loss: 0.00069422
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0006942231557331979, 0.0006942231557331979, 0.0006942231557331979, 0.0006942231557331979, 0.0006942231557331979]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006942231557331979

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00069422
Iteration 2/1000 | Loss: 0.00016390
Iteration 3/1000 | Loss: 0.00025308
Iteration 4/1000 | Loss: 0.00019062
Iteration 5/1000 | Loss: 0.00039975
Iteration 6/1000 | Loss: 0.00009728
Iteration 7/1000 | Loss: 0.00004590
Iteration 8/1000 | Loss: 0.00009871
Iteration 9/1000 | Loss: 0.00005458
Iteration 10/1000 | Loss: 0.00011610
Iteration 11/1000 | Loss: 0.00015709
Iteration 12/1000 | Loss: 0.00005841
Iteration 13/1000 | Loss: 0.00004525
Iteration 14/1000 | Loss: 0.00004084
Iteration 15/1000 | Loss: 0.00012580
Iteration 16/1000 | Loss: 0.00004197
Iteration 17/1000 | Loss: 0.00003869
Iteration 18/1000 | Loss: 0.00013382
Iteration 19/1000 | Loss: 0.00004381
Iteration 20/1000 | Loss: 0.00016348
Iteration 21/1000 | Loss: 0.00003623
Iteration 22/1000 | Loss: 0.00003572
Iteration 23/1000 | Loss: 0.00003536
Iteration 24/1000 | Loss: 0.00003505
Iteration 25/1000 | Loss: 0.00003487
Iteration 26/1000 | Loss: 0.00003469
Iteration 27/1000 | Loss: 0.00003467
Iteration 28/1000 | Loss: 0.00003457
Iteration 29/1000 | Loss: 0.00003455
Iteration 30/1000 | Loss: 0.00003455
Iteration 31/1000 | Loss: 0.00003453
Iteration 32/1000 | Loss: 0.00003453
Iteration 33/1000 | Loss: 0.00003453
Iteration 34/1000 | Loss: 0.00003453
Iteration 35/1000 | Loss: 0.00003451
Iteration 36/1000 | Loss: 0.00003451
Iteration 37/1000 | Loss: 0.00003450
Iteration 38/1000 | Loss: 0.00003449
Iteration 39/1000 | Loss: 0.00003449
Iteration 40/1000 | Loss: 0.00003449
Iteration 41/1000 | Loss: 0.00003449
Iteration 42/1000 | Loss: 0.00003448
Iteration 43/1000 | Loss: 0.00003448
Iteration 44/1000 | Loss: 0.00003448
Iteration 45/1000 | Loss: 0.00003447
Iteration 46/1000 | Loss: 0.00003447
Iteration 47/1000 | Loss: 0.00003447
Iteration 48/1000 | Loss: 0.00003447
Iteration 49/1000 | Loss: 0.00003447
Iteration 50/1000 | Loss: 0.00003447
Iteration 51/1000 | Loss: 0.00003447
Iteration 52/1000 | Loss: 0.00003446
Iteration 53/1000 | Loss: 0.00003446
Iteration 54/1000 | Loss: 0.00003446
Iteration 55/1000 | Loss: 0.00003446
Iteration 56/1000 | Loss: 0.00003446
Iteration 57/1000 | Loss: 0.00003446
Iteration 58/1000 | Loss: 0.00003446
Iteration 59/1000 | Loss: 0.00003445
Iteration 60/1000 | Loss: 0.00003445
Iteration 61/1000 | Loss: 0.00003445
Iteration 62/1000 | Loss: 0.00003444
Iteration 63/1000 | Loss: 0.00003444
Iteration 64/1000 | Loss: 0.00003444
Iteration 65/1000 | Loss: 0.00003444
Iteration 66/1000 | Loss: 0.00003443
Iteration 67/1000 | Loss: 0.00003443
Iteration 68/1000 | Loss: 0.00003443
Iteration 69/1000 | Loss: 0.00003443
Iteration 70/1000 | Loss: 0.00003443
Iteration 71/1000 | Loss: 0.00003443
Iteration 72/1000 | Loss: 0.00003443
Iteration 73/1000 | Loss: 0.00003443
Iteration 74/1000 | Loss: 0.00003443
Iteration 75/1000 | Loss: 0.00003443
Iteration 76/1000 | Loss: 0.00003442
Iteration 77/1000 | Loss: 0.00003442
Iteration 78/1000 | Loss: 0.00003442
Iteration 79/1000 | Loss: 0.00003442
Iteration 80/1000 | Loss: 0.00003441
Iteration 81/1000 | Loss: 0.00003441
Iteration 82/1000 | Loss: 0.00003441
Iteration 83/1000 | Loss: 0.00003441
Iteration 84/1000 | Loss: 0.00003441
Iteration 85/1000 | Loss: 0.00003441
Iteration 86/1000 | Loss: 0.00003441
Iteration 87/1000 | Loss: 0.00003441
Iteration 88/1000 | Loss: 0.00003441
Iteration 89/1000 | Loss: 0.00003440
Iteration 90/1000 | Loss: 0.00003440
Iteration 91/1000 | Loss: 0.00003440
Iteration 92/1000 | Loss: 0.00003440
Iteration 93/1000 | Loss: 0.00003440
Iteration 94/1000 | Loss: 0.00003439
Iteration 95/1000 | Loss: 0.00003439
Iteration 96/1000 | Loss: 0.00003439
Iteration 97/1000 | Loss: 0.00003439
Iteration 98/1000 | Loss: 0.00003438
Iteration 99/1000 | Loss: 0.00003438
Iteration 100/1000 | Loss: 0.00003438
Iteration 101/1000 | Loss: 0.00003438
Iteration 102/1000 | Loss: 0.00003438
Iteration 103/1000 | Loss: 0.00003438
Iteration 104/1000 | Loss: 0.00003438
Iteration 105/1000 | Loss: 0.00003438
Iteration 106/1000 | Loss: 0.00003438
Iteration 107/1000 | Loss: 0.00003438
Iteration 108/1000 | Loss: 0.00003437
Iteration 109/1000 | Loss: 0.00003437
Iteration 110/1000 | Loss: 0.00003437
Iteration 111/1000 | Loss: 0.00003437
Iteration 112/1000 | Loss: 0.00003437
Iteration 113/1000 | Loss: 0.00003437
Iteration 114/1000 | Loss: 0.00003437
Iteration 115/1000 | Loss: 0.00003437
Iteration 116/1000 | Loss: 0.00003436
Iteration 117/1000 | Loss: 0.00003436
Iteration 118/1000 | Loss: 0.00003436
Iteration 119/1000 | Loss: 0.00003436
Iteration 120/1000 | Loss: 0.00003435
Iteration 121/1000 | Loss: 0.00003435
Iteration 122/1000 | Loss: 0.00003435
Iteration 123/1000 | Loss: 0.00003435
Iteration 124/1000 | Loss: 0.00003435
Iteration 125/1000 | Loss: 0.00003435
Iteration 126/1000 | Loss: 0.00003435
Iteration 127/1000 | Loss: 0.00003435
Iteration 128/1000 | Loss: 0.00003435
Iteration 129/1000 | Loss: 0.00003435
Iteration 130/1000 | Loss: 0.00003435
Iteration 131/1000 | Loss: 0.00003435
Iteration 132/1000 | Loss: 0.00003435
Iteration 133/1000 | Loss: 0.00003435
Iteration 134/1000 | Loss: 0.00003435
Iteration 135/1000 | Loss: 0.00003435
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [3.434754762565717e-05, 3.434754762565717e-05, 3.434754762565717e-05, 3.434754762565717e-05, 3.434754762565717e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.434754762565717e-05

Optimization complete. Final v2v error: 4.113894462585449 mm

Highest mean error: 12.265758514404297 mm for frame 214

Lowest mean error: 3.217477798461914 mm for frame 154

Saving results

Total time: 3623.2239162921906
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1099
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00393917
Iteration 2/25 | Loss: 0.00071382
Iteration 3/25 | Loss: 0.00062384
Iteration 4/25 | Loss: 0.00060752
Iteration 5/25 | Loss: 0.00060093
Iteration 6/25 | Loss: 0.00059957
Iteration 7/25 | Loss: 0.00059915
Iteration 8/25 | Loss: 0.00059915
Iteration 9/25 | Loss: 0.00059915
Iteration 10/25 | Loss: 0.00059915
Iteration 11/25 | Loss: 0.00059915
Iteration 12/25 | Loss: 0.00059915
Iteration 13/25 | Loss: 0.00059915
Iteration 14/25 | Loss: 0.00059915
Iteration 15/25 | Loss: 0.00059915
Iteration 16/25 | Loss: 0.00059915
Iteration 17/25 | Loss: 0.00059915
Iteration 18/25 | Loss: 0.00059915
Iteration 19/25 | Loss: 0.00059915
Iteration 20/25 | Loss: 0.00059915
Iteration 21/25 | Loss: 0.00059915
Iteration 22/25 | Loss: 0.00059915
Iteration 23/25 | Loss: 0.00059915
Iteration 24/25 | Loss: 0.00059915
Iteration 25/25 | Loss: 0.00059915

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.40822613
Iteration 2/25 | Loss: 0.00027277
Iteration 3/25 | Loss: 0.00027277
Iteration 4/25 | Loss: 0.00027277
Iteration 5/25 | Loss: 0.00027277
Iteration 6/25 | Loss: 0.00027277
Iteration 7/25 | Loss: 0.00027277
Iteration 8/25 | Loss: 0.00027277
Iteration 9/25 | Loss: 0.00027277
Iteration 10/25 | Loss: 0.00027277
Iteration 11/25 | Loss: 0.00027277
Iteration 12/25 | Loss: 0.00027277
Iteration 13/25 | Loss: 0.00027277
Iteration 14/25 | Loss: 0.00027277
Iteration 15/25 | Loss: 0.00027277
Iteration 16/25 | Loss: 0.00027277
Iteration 17/25 | Loss: 0.00027277
Iteration 18/25 | Loss: 0.00027277
Iteration 19/25 | Loss: 0.00027277
Iteration 20/25 | Loss: 0.00027277
Iteration 21/25 | Loss: 0.00027277
Iteration 22/25 | Loss: 0.00027277
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00027276610489934683, 0.00027276610489934683, 0.00027276610489934683, 0.00027276610489934683, 0.00027276610489934683]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00027276610489934683

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027277
Iteration 2/1000 | Loss: 0.00002134
Iteration 3/1000 | Loss: 0.00001484
Iteration 4/1000 | Loss: 0.00001379
Iteration 5/1000 | Loss: 0.00001310
Iteration 6/1000 | Loss: 0.00001256
Iteration 7/1000 | Loss: 0.00001236
Iteration 8/1000 | Loss: 0.00001232
Iteration 9/1000 | Loss: 0.00001217
Iteration 10/1000 | Loss: 0.00001212
Iteration 11/1000 | Loss: 0.00001200
Iteration 12/1000 | Loss: 0.00001198
Iteration 13/1000 | Loss: 0.00001197
Iteration 14/1000 | Loss: 0.00001197
Iteration 15/1000 | Loss: 0.00001196
Iteration 16/1000 | Loss: 0.00001196
Iteration 17/1000 | Loss: 0.00001188
Iteration 18/1000 | Loss: 0.00001188
Iteration 19/1000 | Loss: 0.00001188
Iteration 20/1000 | Loss: 0.00001188
Iteration 21/1000 | Loss: 0.00001188
Iteration 22/1000 | Loss: 0.00001188
Iteration 23/1000 | Loss: 0.00001188
Iteration 24/1000 | Loss: 0.00001187
Iteration 25/1000 | Loss: 0.00001187
Iteration 26/1000 | Loss: 0.00001187
Iteration 27/1000 | Loss: 0.00001187
Iteration 28/1000 | Loss: 0.00001187
Iteration 29/1000 | Loss: 0.00001186
Iteration 30/1000 | Loss: 0.00001182
Iteration 31/1000 | Loss: 0.00001180
Iteration 32/1000 | Loss: 0.00001180
Iteration 33/1000 | Loss: 0.00001179
Iteration 34/1000 | Loss: 0.00001179
Iteration 35/1000 | Loss: 0.00001178
Iteration 36/1000 | Loss: 0.00001178
Iteration 37/1000 | Loss: 0.00001178
Iteration 38/1000 | Loss: 0.00001177
Iteration 39/1000 | Loss: 0.00001177
Iteration 40/1000 | Loss: 0.00001176
Iteration 41/1000 | Loss: 0.00001176
Iteration 42/1000 | Loss: 0.00001176
Iteration 43/1000 | Loss: 0.00001175
Iteration 44/1000 | Loss: 0.00001175
Iteration 45/1000 | Loss: 0.00001175
Iteration 46/1000 | Loss: 0.00001174
Iteration 47/1000 | Loss: 0.00001174
Iteration 48/1000 | Loss: 0.00001173
Iteration 49/1000 | Loss: 0.00001173
Iteration 50/1000 | Loss: 0.00001173
Iteration 51/1000 | Loss: 0.00001173
Iteration 52/1000 | Loss: 0.00001173
Iteration 53/1000 | Loss: 0.00001173
Iteration 54/1000 | Loss: 0.00001172
Iteration 55/1000 | Loss: 0.00001172
Iteration 56/1000 | Loss: 0.00001172
Iteration 57/1000 | Loss: 0.00001172
Iteration 58/1000 | Loss: 0.00001171
Iteration 59/1000 | Loss: 0.00001171
Iteration 60/1000 | Loss: 0.00001171
Iteration 61/1000 | Loss: 0.00001170
Iteration 62/1000 | Loss: 0.00001170
Iteration 63/1000 | Loss: 0.00001170
Iteration 64/1000 | Loss: 0.00001170
Iteration 65/1000 | Loss: 0.00001170
Iteration 66/1000 | Loss: 0.00001170
Iteration 67/1000 | Loss: 0.00001169
Iteration 68/1000 | Loss: 0.00001169
Iteration 69/1000 | Loss: 0.00001168
Iteration 70/1000 | Loss: 0.00001168
Iteration 71/1000 | Loss: 0.00001168
Iteration 72/1000 | Loss: 0.00001167
Iteration 73/1000 | Loss: 0.00001167
Iteration 74/1000 | Loss: 0.00001167
Iteration 75/1000 | Loss: 0.00001167
Iteration 76/1000 | Loss: 0.00001167
Iteration 77/1000 | Loss: 0.00001167
Iteration 78/1000 | Loss: 0.00001167
Iteration 79/1000 | Loss: 0.00001167
Iteration 80/1000 | Loss: 0.00001167
Iteration 81/1000 | Loss: 0.00001166
Iteration 82/1000 | Loss: 0.00001166
Iteration 83/1000 | Loss: 0.00001166
Iteration 84/1000 | Loss: 0.00001166
Iteration 85/1000 | Loss: 0.00001166
Iteration 86/1000 | Loss: 0.00001166
Iteration 87/1000 | Loss: 0.00001166
Iteration 88/1000 | Loss: 0.00001166
Iteration 89/1000 | Loss: 0.00001166
Iteration 90/1000 | Loss: 0.00001165
Iteration 91/1000 | Loss: 0.00001163
Iteration 92/1000 | Loss: 0.00001163
Iteration 93/1000 | Loss: 0.00001162
Iteration 94/1000 | Loss: 0.00001162
Iteration 95/1000 | Loss: 0.00001161
Iteration 96/1000 | Loss: 0.00001161
Iteration 97/1000 | Loss: 0.00001161
Iteration 98/1000 | Loss: 0.00001161
Iteration 99/1000 | Loss: 0.00001160
Iteration 100/1000 | Loss: 0.00001160
Iteration 101/1000 | Loss: 0.00001160
Iteration 102/1000 | Loss: 0.00001160
Iteration 103/1000 | Loss: 0.00001160
Iteration 104/1000 | Loss: 0.00001159
Iteration 105/1000 | Loss: 0.00001159
Iteration 106/1000 | Loss: 0.00001159
Iteration 107/1000 | Loss: 0.00001159
Iteration 108/1000 | Loss: 0.00001159
Iteration 109/1000 | Loss: 0.00001159
Iteration 110/1000 | Loss: 0.00001159
Iteration 111/1000 | Loss: 0.00001158
Iteration 112/1000 | Loss: 0.00001158
Iteration 113/1000 | Loss: 0.00001158
Iteration 114/1000 | Loss: 0.00001158
Iteration 115/1000 | Loss: 0.00001158
Iteration 116/1000 | Loss: 0.00001157
Iteration 117/1000 | Loss: 0.00001157
Iteration 118/1000 | Loss: 0.00001157
Iteration 119/1000 | Loss: 0.00001157
Iteration 120/1000 | Loss: 0.00001157
Iteration 121/1000 | Loss: 0.00001157
Iteration 122/1000 | Loss: 0.00001157
Iteration 123/1000 | Loss: 0.00001157
Iteration 124/1000 | Loss: 0.00001157
Iteration 125/1000 | Loss: 0.00001156
Iteration 126/1000 | Loss: 0.00001156
Iteration 127/1000 | Loss: 0.00001156
Iteration 128/1000 | Loss: 0.00001156
Iteration 129/1000 | Loss: 0.00001156
Iteration 130/1000 | Loss: 0.00001156
Iteration 131/1000 | Loss: 0.00001156
Iteration 132/1000 | Loss: 0.00001156
Iteration 133/1000 | Loss: 0.00001156
Iteration 134/1000 | Loss: 0.00001156
Iteration 135/1000 | Loss: 0.00001156
Iteration 136/1000 | Loss: 0.00001156
Iteration 137/1000 | Loss: 0.00001156
Iteration 138/1000 | Loss: 0.00001156
Iteration 139/1000 | Loss: 0.00001156
Iteration 140/1000 | Loss: 0.00001156
Iteration 141/1000 | Loss: 0.00001156
Iteration 142/1000 | Loss: 0.00001156
Iteration 143/1000 | Loss: 0.00001156
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 143. Stopping optimization.
Last 5 losses: [1.1560784514585976e-05, 1.1560784514585976e-05, 1.1560784514585976e-05, 1.1560784514585976e-05, 1.1560784514585976e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1560784514585976e-05

Optimization complete. Final v2v error: 2.8936076164245605 mm

Highest mean error: 3.0175352096557617 mm for frame 77

Lowest mean error: 2.8098697662353516 mm for frame 120

Saving results

Total time: 767.1935362815857
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1042/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1042.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1042
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00784661
Iteration 2/25 | Loss: 0.00142259
Iteration 3/25 | Loss: 0.00084145
Iteration 4/25 | Loss: 0.00100287
Iteration 5/25 | Loss: 0.00075409
Iteration 6/25 | Loss: 0.00071336
Iteration 7/25 | Loss: 0.00070548
Iteration 8/25 | Loss: 0.00070362
Iteration 9/25 | Loss: 0.00070338
Iteration 10/25 | Loss: 0.00070337
Iteration 11/25 | Loss: 0.00070337
Iteration 12/25 | Loss: 0.00070337
Iteration 13/25 | Loss: 0.00070337
Iteration 14/25 | Loss: 0.00070329
Iteration 15/25 | Loss: 0.00070328
Iteration 16/25 | Loss: 0.00070328
Iteration 17/25 | Loss: 0.00070328
Iteration 18/25 | Loss: 0.00070328
Iteration 19/25 | Loss: 0.00070328
Iteration 20/25 | Loss: 0.00070328
Iteration 21/25 | Loss: 0.00070328
Iteration 22/25 | Loss: 0.00070328
Iteration 23/25 | Loss: 0.00070327
Iteration 24/25 | Loss: 0.00070327
Iteration 25/25 | Loss: 0.00070327

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.88043976
Iteration 2/25 | Loss: 0.00034002
Iteration 3/25 | Loss: 0.00034001
Iteration 4/25 | Loss: 0.00034001
Iteration 5/25 | Loss: 0.00034001
Iteration 6/25 | Loss: 0.00034001
Iteration 7/25 | Loss: 0.00034001
Iteration 8/25 | Loss: 0.00034001
Iteration 9/25 | Loss: 0.00034001
Iteration 10/25 | Loss: 0.00034001
Iteration 11/25 | Loss: 0.00034001
Iteration 12/25 | Loss: 0.00034001
Iteration 13/25 | Loss: 0.00034001
Iteration 14/25 | Loss: 0.00034001
Iteration 15/25 | Loss: 0.00034001
Iteration 16/25 | Loss: 0.00034001
Iteration 17/25 | Loss: 0.00034001
Iteration 18/25 | Loss: 0.00034001
Iteration 19/25 | Loss: 0.00034001
Iteration 20/25 | Loss: 0.00034001
Iteration 21/25 | Loss: 0.00034001
Iteration 22/25 | Loss: 0.00034001
Iteration 23/25 | Loss: 0.00034001
Iteration 24/25 | Loss: 0.00034001
Iteration 25/25 | Loss: 0.00034001

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034001
Iteration 2/1000 | Loss: 0.00003723
Iteration 3/1000 | Loss: 0.00002744
Iteration 4/1000 | Loss: 0.00002453
Iteration 5/1000 | Loss: 0.00002292
Iteration 6/1000 | Loss: 0.00002184
Iteration 7/1000 | Loss: 0.00002125
Iteration 8/1000 | Loss: 0.00002070
Iteration 9/1000 | Loss: 0.00002035
Iteration 10/1000 | Loss: 0.00002006
Iteration 11/1000 | Loss: 0.00001995
Iteration 12/1000 | Loss: 0.00001977
Iteration 13/1000 | Loss: 0.00001962
Iteration 14/1000 | Loss: 0.00001961
Iteration 15/1000 | Loss: 0.00001955
Iteration 16/1000 | Loss: 0.00001953
Iteration 17/1000 | Loss: 0.00001948
Iteration 18/1000 | Loss: 0.00001948
Iteration 19/1000 | Loss: 0.00001943
Iteration 20/1000 | Loss: 0.00001943
Iteration 21/1000 | Loss: 0.00001941
Iteration 22/1000 | Loss: 0.00001941
Iteration 23/1000 | Loss: 0.00001940
Iteration 24/1000 | Loss: 0.00001940
Iteration 25/1000 | Loss: 0.00001939
Iteration 26/1000 | Loss: 0.00001939
Iteration 27/1000 | Loss: 0.00001938
Iteration 28/1000 | Loss: 0.00001938
Iteration 29/1000 | Loss: 0.00001938
Iteration 30/1000 | Loss: 0.00001938
Iteration 31/1000 | Loss: 0.00001937
Iteration 32/1000 | Loss: 0.00001936
Iteration 33/1000 | Loss: 0.00001936
Iteration 34/1000 | Loss: 0.00001935
Iteration 35/1000 | Loss: 0.00001935
Iteration 36/1000 | Loss: 0.00001935
Iteration 37/1000 | Loss: 0.00001935
Iteration 38/1000 | Loss: 0.00001934
Iteration 39/1000 | Loss: 0.00001934
Iteration 40/1000 | Loss: 0.00001934
Iteration 41/1000 | Loss: 0.00001933
Iteration 42/1000 | Loss: 0.00001933
Iteration 43/1000 | Loss: 0.00001933
Iteration 44/1000 | Loss: 0.00001933
Iteration 45/1000 | Loss: 0.00001933
Iteration 46/1000 | Loss: 0.00001932
Iteration 47/1000 | Loss: 0.00001932
Iteration 48/1000 | Loss: 0.00001932
Iteration 49/1000 | Loss: 0.00001932
Iteration 50/1000 | Loss: 0.00001931
Iteration 51/1000 | Loss: 0.00001931
Iteration 52/1000 | Loss: 0.00001931
Iteration 53/1000 | Loss: 0.00001931
Iteration 54/1000 | Loss: 0.00001930
Iteration 55/1000 | Loss: 0.00001930
Iteration 56/1000 | Loss: 0.00001930
Iteration 57/1000 | Loss: 0.00001930
Iteration 58/1000 | Loss: 0.00001930
Iteration 59/1000 | Loss: 0.00001929
Iteration 60/1000 | Loss: 0.00001929
Iteration 61/1000 | Loss: 0.00001929
Iteration 62/1000 | Loss: 0.00001929
Iteration 63/1000 | Loss: 0.00001928
Iteration 64/1000 | Loss: 0.00001928
Iteration 65/1000 | Loss: 0.00001928
Iteration 66/1000 | Loss: 0.00001928
Iteration 67/1000 | Loss: 0.00001928
Iteration 68/1000 | Loss: 0.00001928
Iteration 69/1000 | Loss: 0.00001928
Iteration 70/1000 | Loss: 0.00001927
Iteration 71/1000 | Loss: 0.00001927
Iteration 72/1000 | Loss: 0.00001927
Iteration 73/1000 | Loss: 0.00001927
Iteration 74/1000 | Loss: 0.00001927
Iteration 75/1000 | Loss: 0.00001926
Iteration 76/1000 | Loss: 0.00001926
Iteration 77/1000 | Loss: 0.00001926
Iteration 78/1000 | Loss: 0.00001926
Iteration 79/1000 | Loss: 0.00001926
Iteration 80/1000 | Loss: 0.00001926
Iteration 81/1000 | Loss: 0.00001926
Iteration 82/1000 | Loss: 0.00001926
Iteration 83/1000 | Loss: 0.00001926
Iteration 84/1000 | Loss: 0.00001926
Iteration 85/1000 | Loss: 0.00001925
Iteration 86/1000 | Loss: 0.00001925
Iteration 87/1000 | Loss: 0.00001925
Iteration 88/1000 | Loss: 0.00001925
Iteration 89/1000 | Loss: 0.00001925
Iteration 90/1000 | Loss: 0.00001925
Iteration 91/1000 | Loss: 0.00001925
Iteration 92/1000 | Loss: 0.00001925
Iteration 93/1000 | Loss: 0.00001925
Iteration 94/1000 | Loss: 0.00001925
Iteration 95/1000 | Loss: 0.00001925
Iteration 96/1000 | Loss: 0.00001925
Iteration 97/1000 | Loss: 0.00001925
Iteration 98/1000 | Loss: 0.00001924
Iteration 99/1000 | Loss: 0.00001924
Iteration 100/1000 | Loss: 0.00001924
Iteration 101/1000 | Loss: 0.00001924
Iteration 102/1000 | Loss: 0.00001924
Iteration 103/1000 | Loss: 0.00001924
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.924494790728204e-05, 1.924494790728204e-05, 1.924494790728204e-05, 1.924494790728204e-05, 1.924494790728204e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.924494790728204e-05

Optimization complete. Final v2v error: 3.590240001678467 mm

Highest mean error: 4.720127105712891 mm for frame 27

Lowest mean error: 2.8152170181274414 mm for frame 47

Saving results

Total time: 1634.2033305168152
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1044/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1044.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1044
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01046391
Iteration 2/25 | Loss: 0.00342271
Iteration 3/25 | Loss: 0.00220052
Iteration 4/25 | Loss: 0.00201279
Iteration 5/25 | Loss: 0.00184518
Iteration 6/25 | Loss: 0.00187007
Iteration 7/25 | Loss: 0.00172382
Iteration 8/25 | Loss: 0.00165334
Iteration 9/25 | Loss: 0.00166253
Iteration 10/25 | Loss: 0.00165150
Iteration 11/25 | Loss: 0.00159809
Iteration 12/25 | Loss: 0.00157460
Iteration 13/25 | Loss: 0.00152630
Iteration 14/25 | Loss: 0.00149112
Iteration 15/25 | Loss: 0.00148346
Iteration 16/25 | Loss: 0.00147420
Iteration 17/25 | Loss: 0.00146339
Iteration 18/25 | Loss: 0.00145222
Iteration 19/25 | Loss: 0.00144168
Iteration 20/25 | Loss: 0.00143740
Iteration 21/25 | Loss: 0.00143125
Iteration 22/25 | Loss: 0.00142858
Iteration 23/25 | Loss: 0.00142524
Iteration 24/25 | Loss: 0.00142859
Iteration 25/25 | Loss: 0.00143012

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.40256345
Iteration 2/25 | Loss: 0.00751548
Iteration 3/25 | Loss: 0.00679492
Iteration 4/25 | Loss: 0.00679492
Iteration 5/25 | Loss: 0.00679492
Iteration 6/25 | Loss: 0.00679492
Iteration 7/25 | Loss: 0.00679492
Iteration 8/25 | Loss: 0.00679492
Iteration 9/25 | Loss: 0.00679492
Iteration 10/25 | Loss: 0.00679492
Iteration 11/25 | Loss: 0.00679492
Iteration 12/25 | Loss: 0.00679492
Iteration 13/25 | Loss: 0.00679492
Iteration 14/25 | Loss: 0.00679492
Iteration 15/25 | Loss: 0.00679492
Iteration 16/25 | Loss: 0.00679492
Iteration 17/25 | Loss: 0.00679492
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.006794918328523636, 0.006794918328523636, 0.006794918328523636, 0.006794918328523636, 0.006794918328523636]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006794918328523636

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00679492
Iteration 2/1000 | Loss: 0.00455709
Iteration 3/1000 | Loss: 0.00215043
Iteration 4/1000 | Loss: 0.01897304
Iteration 5/1000 | Loss: 0.00232374
Iteration 6/1000 | Loss: 0.00410315
Iteration 7/1000 | Loss: 0.00330961
Iteration 8/1000 | Loss: 0.00189747
Iteration 9/1000 | Loss: 0.00131936
Iteration 10/1000 | Loss: 0.00101944
Iteration 11/1000 | Loss: 0.00083417
Iteration 12/1000 | Loss: 0.00076808
Iteration 13/1000 | Loss: 0.00058595
Iteration 14/1000 | Loss: 0.00044685
Iteration 15/1000 | Loss: 0.00079807
Iteration 16/1000 | Loss: 0.00031897
Iteration 17/1000 | Loss: 0.00095232
Iteration 18/1000 | Loss: 0.00074844
Iteration 19/1000 | Loss: 0.00103795
Iteration 20/1000 | Loss: 0.00344508
Iteration 21/1000 | Loss: 0.00036961
Iteration 22/1000 | Loss: 0.00186707
Iteration 23/1000 | Loss: 0.00029512
Iteration 24/1000 | Loss: 0.00019475
Iteration 25/1000 | Loss: 0.00040428
Iteration 26/1000 | Loss: 0.00095114
Iteration 27/1000 | Loss: 0.00169248
Iteration 28/1000 | Loss: 0.00378696
Iteration 29/1000 | Loss: 0.00068044
Iteration 30/1000 | Loss: 0.00114089
Iteration 31/1000 | Loss: 0.00046010
Iteration 32/1000 | Loss: 0.00055279
Iteration 33/1000 | Loss: 0.00017165
Iteration 34/1000 | Loss: 0.00021410
Iteration 35/1000 | Loss: 0.00005943
Iteration 36/1000 | Loss: 0.00013992
Iteration 37/1000 | Loss: 0.00004408
Iteration 38/1000 | Loss: 0.00016801
Iteration 39/1000 | Loss: 0.00007759
Iteration 40/1000 | Loss: 0.00039688
Iteration 41/1000 | Loss: 0.00012013
Iteration 42/1000 | Loss: 0.00004363
Iteration 43/1000 | Loss: 0.00003605
Iteration 44/1000 | Loss: 0.00004535
Iteration 45/1000 | Loss: 0.00006307
Iteration 46/1000 | Loss: 0.00003107
Iteration 47/1000 | Loss: 0.00031110
Iteration 48/1000 | Loss: 0.00004964
Iteration 49/1000 | Loss: 0.00043300
Iteration 50/1000 | Loss: 0.00012965
Iteration 51/1000 | Loss: 0.00005132
Iteration 52/1000 | Loss: 0.00035793
Iteration 53/1000 | Loss: 0.00031874
Iteration 54/1000 | Loss: 0.00035277
Iteration 55/1000 | Loss: 0.00003502
Iteration 56/1000 | Loss: 0.00045324
Iteration 57/1000 | Loss: 0.00031150
Iteration 58/1000 | Loss: 0.00011441
Iteration 59/1000 | Loss: 0.00003533
Iteration 60/1000 | Loss: 0.00003580
Iteration 61/1000 | Loss: 0.00003038
Iteration 62/1000 | Loss: 0.00003256
Iteration 63/1000 | Loss: 0.00003209
Iteration 64/1000 | Loss: 0.00017087
Iteration 65/1000 | Loss: 0.00041730
Iteration 66/1000 | Loss: 0.00005458
Iteration 67/1000 | Loss: 0.00015589
Iteration 68/1000 | Loss: 0.00018250
Iteration 69/1000 | Loss: 0.00006829
Iteration 70/1000 | Loss: 0.00024689
Iteration 71/1000 | Loss: 0.00032499
Iteration 72/1000 | Loss: 0.00018720
Iteration 73/1000 | Loss: 0.00018061
Iteration 74/1000 | Loss: 0.00021237
Iteration 75/1000 | Loss: 0.00012798
Iteration 76/1000 | Loss: 0.00017741
Iteration 77/1000 | Loss: 0.00011186
Iteration 78/1000 | Loss: 0.00016256
Iteration 79/1000 | Loss: 0.00009745
Iteration 80/1000 | Loss: 0.00004048
Iteration 81/1000 | Loss: 0.00015106
Iteration 82/1000 | Loss: 0.00008085
Iteration 83/1000 | Loss: 0.00015013
Iteration 84/1000 | Loss: 0.00007930
Iteration 85/1000 | Loss: 0.00014177
Iteration 86/1000 | Loss: 0.00004854
Iteration 87/1000 | Loss: 0.00013055
Iteration 88/1000 | Loss: 0.00005236
Iteration 89/1000 | Loss: 0.00002457
Iteration 90/1000 | Loss: 0.00013915
Iteration 91/1000 | Loss: 0.00004616
Iteration 92/1000 | Loss: 0.00014868
Iteration 93/1000 | Loss: 0.00004613
Iteration 94/1000 | Loss: 0.00012312
Iteration 95/1000 | Loss: 0.00005894
Iteration 96/1000 | Loss: 0.00004046
Iteration 97/1000 | Loss: 0.00013371
Iteration 98/1000 | Loss: 0.00005301
Iteration 99/1000 | Loss: 0.00010290
Iteration 100/1000 | Loss: 0.00004746
Iteration 101/1000 | Loss: 0.00003116
Iteration 102/1000 | Loss: 0.00011315
Iteration 103/1000 | Loss: 0.00004115
Iteration 104/1000 | Loss: 0.00005327
Iteration 105/1000 | Loss: 0.00002525
Iteration 106/1000 | Loss: 0.00002978
Iteration 107/1000 | Loss: 0.00012250
Iteration 108/1000 | Loss: 0.00012532
Iteration 109/1000 | Loss: 0.00004719
Iteration 110/1000 | Loss: 0.00031426
Iteration 111/1000 | Loss: 0.00016968
Iteration 112/1000 | Loss: 0.00002788
Iteration 113/1000 | Loss: 0.00003266
Iteration 114/1000 | Loss: 0.00004145
Iteration 115/1000 | Loss: 0.00002816
Iteration 116/1000 | Loss: 0.00015357
Iteration 117/1000 | Loss: 0.00018949
Iteration 118/1000 | Loss: 0.00002948
Iteration 119/1000 | Loss: 0.00004196
Iteration 120/1000 | Loss: 0.00015219
Iteration 121/1000 | Loss: 0.00012991
Iteration 122/1000 | Loss: 0.00002436
Iteration 123/1000 | Loss: 0.00015779
Iteration 124/1000 | Loss: 0.00030914
Iteration 125/1000 | Loss: 0.00014013
Iteration 126/1000 | Loss: 0.00011173
Iteration 127/1000 | Loss: 0.00013723
Iteration 128/1000 | Loss: 0.00008485
Iteration 129/1000 | Loss: 0.00011810
Iteration 130/1000 | Loss: 0.00015440
Iteration 131/1000 | Loss: 0.00003121
Iteration 132/1000 | Loss: 0.00002903
Iteration 133/1000 | Loss: 0.00013034
Iteration 134/1000 | Loss: 0.00009005
Iteration 135/1000 | Loss: 0.00024100
Iteration 136/1000 | Loss: 0.00017733
Iteration 137/1000 | Loss: 0.00034726
Iteration 138/1000 | Loss: 0.00004146
Iteration 139/1000 | Loss: 0.00002638
Iteration 140/1000 | Loss: 0.00007054
Iteration 141/1000 | Loss: 0.00002289
Iteration 142/1000 | Loss: 0.00003156
Iteration 143/1000 | Loss: 0.00002668
Iteration 144/1000 | Loss: 0.00002742
Iteration 145/1000 | Loss: 0.00003375
Iteration 146/1000 | Loss: 0.00004659
Iteration 147/1000 | Loss: 0.00002500
Iteration 148/1000 | Loss: 0.00003118
Iteration 149/1000 | Loss: 0.00003665
Iteration 150/1000 | Loss: 0.00002879
Iteration 151/1000 | Loss: 0.00002438
Iteration 152/1000 | Loss: 0.00002285
Iteration 153/1000 | Loss: 0.00002285
Iteration 154/1000 | Loss: 0.00005113
Iteration 155/1000 | Loss: 0.00003795
Iteration 156/1000 | Loss: 0.00002493
Iteration 157/1000 | Loss: 0.00003651
Iteration 158/1000 | Loss: 0.00004938
Iteration 159/1000 | Loss: 0.00003661
Iteration 160/1000 | Loss: 0.00003883
Iteration 161/1000 | Loss: 0.00005191
Iteration 162/1000 | Loss: 0.00002431
Iteration 163/1000 | Loss: 0.00003026
Iteration 164/1000 | Loss: 0.00003834
Iteration 165/1000 | Loss: 0.00003431
Iteration 166/1000 | Loss: 0.00002192
Iteration 167/1000 | Loss: 0.00004101
Iteration 168/1000 | Loss: 0.00003745
Iteration 169/1000 | Loss: 0.00006373
Iteration 170/1000 | Loss: 0.00002723
Iteration 171/1000 | Loss: 0.00003329
Iteration 172/1000 | Loss: 0.00002980
Iteration 173/1000 | Loss: 0.00003492
Iteration 174/1000 | Loss: 0.00003182
Iteration 175/1000 | Loss: 0.00004108
Iteration 176/1000 | Loss: 0.00003340
Iteration 177/1000 | Loss: 0.00004029
Iteration 178/1000 | Loss: 0.00005341
Iteration 179/1000 | Loss: 0.00003335
Iteration 180/1000 | Loss: 0.00003248
Iteration 181/1000 | Loss: 0.00003311
Iteration 182/1000 | Loss: 0.00003558
Iteration 183/1000 | Loss: 0.00002847
Iteration 184/1000 | Loss: 0.00003039
Iteration 185/1000 | Loss: 0.00004137
Iteration 186/1000 | Loss: 0.00002310
Iteration 187/1000 | Loss: 0.00003934
Iteration 188/1000 | Loss: 0.00002107
Iteration 189/1000 | Loss: 0.00002177
Iteration 190/1000 | Loss: 0.00002127
Iteration 191/1000 | Loss: 0.00002263
Iteration 192/1000 | Loss: 0.00002080
Iteration 193/1000 | Loss: 0.00002832
Iteration 194/1000 | Loss: 0.00002846
Iteration 195/1000 | Loss: 0.00002187
Iteration 196/1000 | Loss: 0.00002049
Iteration 197/1000 | Loss: 0.00002401
Iteration 198/1000 | Loss: 0.00004763
Iteration 199/1000 | Loss: 0.00002217
Iteration 200/1000 | Loss: 0.00002327
Iteration 201/1000 | Loss: 0.00002068
Iteration 202/1000 | Loss: 0.00002117
Iteration 203/1000 | Loss: 0.00002369
Iteration 204/1000 | Loss: 0.00002261
Iteration 205/1000 | Loss: 0.00003147
Iteration 206/1000 | Loss: 0.00002284
Iteration 207/1000 | Loss: 0.00002112
Iteration 208/1000 | Loss: 0.00002609
Iteration 209/1000 | Loss: 0.00004856
Iteration 210/1000 | Loss: 0.00003552
Iteration 211/1000 | Loss: 0.00002211
Iteration 212/1000 | Loss: 0.00003798
Iteration 213/1000 | Loss: 0.00002532
Iteration 214/1000 | Loss: 0.00003912
Iteration 215/1000 | Loss: 0.00002367
Iteration 216/1000 | Loss: 0.00002464
Iteration 217/1000 | Loss: 0.00002115
Iteration 218/1000 | Loss: 0.00002052
Iteration 219/1000 | Loss: 0.00002421
Iteration 220/1000 | Loss: 0.00002333
Iteration 221/1000 | Loss: 0.00002962
Iteration 222/1000 | Loss: 0.00002840
Iteration 223/1000 | Loss: 0.00006214
Iteration 224/1000 | Loss: 0.00002072
Iteration 225/1000 | Loss: 0.00002472
Iteration 226/1000 | Loss: 0.00003602
Iteration 227/1000 | Loss: 0.00002358
Iteration 228/1000 | Loss: 0.00002131
Iteration 229/1000 | Loss: 0.00002076
Iteration 230/1000 | Loss: 0.00002108
Iteration 231/1000 | Loss: 0.00002041
Iteration 232/1000 | Loss: 0.00002041
Iteration 233/1000 | Loss: 0.00002041
Iteration 234/1000 | Loss: 0.00002041
Iteration 235/1000 | Loss: 0.00002041
Iteration 236/1000 | Loss: 0.00002041
Iteration 237/1000 | Loss: 0.00002041
Iteration 238/1000 | Loss: 0.00002041
Iteration 239/1000 | Loss: 0.00002041
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 239. Stopping optimization.
Last 5 losses: [2.041452898993157e-05, 2.041452898993157e-05, 2.041452898993157e-05, 2.041452898993157e-05, 2.041452898993157e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.041452898993157e-05

Optimization complete. Final v2v error: 3.818631887435913 mm

Highest mean error: 4.401836395263672 mm for frame 177

Lowest mean error: 3.502943277359009 mm for frame 37

Saving results

Total time: 10515.59520149231
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1024
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00782486
Iteration 2/25 | Loss: 0.00101558
Iteration 3/25 | Loss: 0.00077012
Iteration 4/25 | Loss: 0.00073145
Iteration 5/25 | Loss: 0.00071928
Iteration 6/25 | Loss: 0.00071632
Iteration 7/25 | Loss: 0.00071545
Iteration 8/25 | Loss: 0.00071534
Iteration 9/25 | Loss: 0.00071534
Iteration 10/25 | Loss: 0.00071534
Iteration 11/25 | Loss: 0.00071534
Iteration 12/25 | Loss: 0.00071534
Iteration 13/25 | Loss: 0.00071534
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007153405458666384, 0.0007153405458666384, 0.0007153405458666384, 0.0007153405458666384, 0.0007153405458666384]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007153405458666384

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.71579695
Iteration 2/25 | Loss: 0.00043440
Iteration 3/25 | Loss: 0.00043437
Iteration 4/25 | Loss: 0.00043437
Iteration 5/25 | Loss: 0.00043437
Iteration 6/25 | Loss: 0.00043437
Iteration 7/25 | Loss: 0.00043437
Iteration 8/25 | Loss: 0.00043437
Iteration 9/25 | Loss: 0.00043437
Iteration 10/25 | Loss: 0.00043437
Iteration 11/25 | Loss: 0.00043437
Iteration 12/25 | Loss: 0.00043437
Iteration 13/25 | Loss: 0.00043437
Iteration 14/25 | Loss: 0.00043437
Iteration 15/25 | Loss: 0.00043437
Iteration 16/25 | Loss: 0.00043437
Iteration 17/25 | Loss: 0.00043437
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00043436550186015666, 0.00043436550186015666, 0.00043436550186015666, 0.00043436550186015666, 0.00043436550186015666]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00043436550186015666

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043437
Iteration 2/1000 | Loss: 0.00004799
Iteration 3/1000 | Loss: 0.00002762
Iteration 4/1000 | Loss: 0.00002086
Iteration 5/1000 | Loss: 0.00001931
Iteration 6/1000 | Loss: 0.00001854
Iteration 7/1000 | Loss: 0.00001818
Iteration 8/1000 | Loss: 0.00001789
Iteration 9/1000 | Loss: 0.00001762
Iteration 10/1000 | Loss: 0.00001755
Iteration 11/1000 | Loss: 0.00001754
Iteration 12/1000 | Loss: 0.00001747
Iteration 13/1000 | Loss: 0.00001746
Iteration 14/1000 | Loss: 0.00001745
Iteration 15/1000 | Loss: 0.00001741
Iteration 16/1000 | Loss: 0.00001740
Iteration 17/1000 | Loss: 0.00001736
Iteration 18/1000 | Loss: 0.00001736
Iteration 19/1000 | Loss: 0.00001735
Iteration 20/1000 | Loss: 0.00001735
Iteration 21/1000 | Loss: 0.00001735
Iteration 22/1000 | Loss: 0.00001733
Iteration 23/1000 | Loss: 0.00001732
Iteration 24/1000 | Loss: 0.00001732
Iteration 25/1000 | Loss: 0.00001732
Iteration 26/1000 | Loss: 0.00001731
Iteration 27/1000 | Loss: 0.00001731
Iteration 28/1000 | Loss: 0.00001730
Iteration 29/1000 | Loss: 0.00001729
Iteration 30/1000 | Loss: 0.00001729
Iteration 31/1000 | Loss: 0.00001728
Iteration 32/1000 | Loss: 0.00001728
Iteration 33/1000 | Loss: 0.00001727
Iteration 34/1000 | Loss: 0.00001726
Iteration 35/1000 | Loss: 0.00001726
Iteration 36/1000 | Loss: 0.00001726
Iteration 37/1000 | Loss: 0.00001726
Iteration 38/1000 | Loss: 0.00001725
Iteration 39/1000 | Loss: 0.00001725
Iteration 40/1000 | Loss: 0.00001725
Iteration 41/1000 | Loss: 0.00001724
Iteration 42/1000 | Loss: 0.00001723
Iteration 43/1000 | Loss: 0.00001723
Iteration 44/1000 | Loss: 0.00001722
Iteration 45/1000 | Loss: 0.00001722
Iteration 46/1000 | Loss: 0.00001722
Iteration 47/1000 | Loss: 0.00001721
Iteration 48/1000 | Loss: 0.00001721
Iteration 49/1000 | Loss: 0.00001721
Iteration 50/1000 | Loss: 0.00001721
Iteration 51/1000 | Loss: 0.00001720
Iteration 52/1000 | Loss: 0.00001720
Iteration 53/1000 | Loss: 0.00001720
Iteration 54/1000 | Loss: 0.00001720
Iteration 55/1000 | Loss: 0.00001720
Iteration 56/1000 | Loss: 0.00001720
Iteration 57/1000 | Loss: 0.00001720
Iteration 58/1000 | Loss: 0.00001720
Iteration 59/1000 | Loss: 0.00001720
Iteration 60/1000 | Loss: 0.00001720
Iteration 61/1000 | Loss: 0.00001719
Iteration 62/1000 | Loss: 0.00001719
Iteration 63/1000 | Loss: 0.00001719
Iteration 64/1000 | Loss: 0.00001719
Iteration 65/1000 | Loss: 0.00001719
Iteration 66/1000 | Loss: 0.00001719
Iteration 67/1000 | Loss: 0.00001719
Iteration 68/1000 | Loss: 0.00001718
Iteration 69/1000 | Loss: 0.00001718
Iteration 70/1000 | Loss: 0.00001718
Iteration 71/1000 | Loss: 0.00001718
Iteration 72/1000 | Loss: 0.00001718
Iteration 73/1000 | Loss: 0.00001718
Iteration 74/1000 | Loss: 0.00001718
Iteration 75/1000 | Loss: 0.00001717
Iteration 76/1000 | Loss: 0.00001717
Iteration 77/1000 | Loss: 0.00001717
Iteration 78/1000 | Loss: 0.00001717
Iteration 79/1000 | Loss: 0.00001717
Iteration 80/1000 | Loss: 0.00001717
Iteration 81/1000 | Loss: 0.00001717
Iteration 82/1000 | Loss: 0.00001717
Iteration 83/1000 | Loss: 0.00001717
Iteration 84/1000 | Loss: 0.00001716
Iteration 85/1000 | Loss: 0.00001716
Iteration 86/1000 | Loss: 0.00001716
Iteration 87/1000 | Loss: 0.00001716
Iteration 88/1000 | Loss: 0.00001716
Iteration 89/1000 | Loss: 0.00001716
Iteration 90/1000 | Loss: 0.00001716
Iteration 91/1000 | Loss: 0.00001716
Iteration 92/1000 | Loss: 0.00001716
Iteration 93/1000 | Loss: 0.00001716
Iteration 94/1000 | Loss: 0.00001716
Iteration 95/1000 | Loss: 0.00001715
Iteration 96/1000 | Loss: 0.00001715
Iteration 97/1000 | Loss: 0.00001715
Iteration 98/1000 | Loss: 0.00001715
Iteration 99/1000 | Loss: 0.00001715
Iteration 100/1000 | Loss: 0.00001714
Iteration 101/1000 | Loss: 0.00001714
Iteration 102/1000 | Loss: 0.00001714
Iteration 103/1000 | Loss: 0.00001714
Iteration 104/1000 | Loss: 0.00001714
Iteration 105/1000 | Loss: 0.00001714
Iteration 106/1000 | Loss: 0.00001714
Iteration 107/1000 | Loss: 0.00001714
Iteration 108/1000 | Loss: 0.00001714
Iteration 109/1000 | Loss: 0.00001714
Iteration 110/1000 | Loss: 0.00001713
Iteration 111/1000 | Loss: 0.00001713
Iteration 112/1000 | Loss: 0.00001713
Iteration 113/1000 | Loss: 0.00001713
Iteration 114/1000 | Loss: 0.00001713
Iteration 115/1000 | Loss: 0.00001713
Iteration 116/1000 | Loss: 0.00001712
Iteration 117/1000 | Loss: 0.00001712
Iteration 118/1000 | Loss: 0.00001712
Iteration 119/1000 | Loss: 0.00001712
Iteration 120/1000 | Loss: 0.00001712
Iteration 121/1000 | Loss: 0.00001712
Iteration 122/1000 | Loss: 0.00001712
Iteration 123/1000 | Loss: 0.00001712
Iteration 124/1000 | Loss: 0.00001712
Iteration 125/1000 | Loss: 0.00001712
Iteration 126/1000 | Loss: 0.00001712
Iteration 127/1000 | Loss: 0.00001711
Iteration 128/1000 | Loss: 0.00001711
Iteration 129/1000 | Loss: 0.00001711
Iteration 130/1000 | Loss: 0.00001711
Iteration 131/1000 | Loss: 0.00001711
Iteration 132/1000 | Loss: 0.00001711
Iteration 133/1000 | Loss: 0.00001711
Iteration 134/1000 | Loss: 0.00001711
Iteration 135/1000 | Loss: 0.00001711
Iteration 136/1000 | Loss: 0.00001711
Iteration 137/1000 | Loss: 0.00001710
Iteration 138/1000 | Loss: 0.00001710
Iteration 139/1000 | Loss: 0.00001710
Iteration 140/1000 | Loss: 0.00001710
Iteration 141/1000 | Loss: 0.00001710
Iteration 142/1000 | Loss: 0.00001710
Iteration 143/1000 | Loss: 0.00001710
Iteration 144/1000 | Loss: 0.00001710
Iteration 145/1000 | Loss: 0.00001710
Iteration 146/1000 | Loss: 0.00001710
Iteration 147/1000 | Loss: 0.00001710
Iteration 148/1000 | Loss: 0.00001709
Iteration 149/1000 | Loss: 0.00001709
Iteration 150/1000 | Loss: 0.00001709
Iteration 151/1000 | Loss: 0.00001709
Iteration 152/1000 | Loss: 0.00001709
Iteration 153/1000 | Loss: 0.00001709
Iteration 154/1000 | Loss: 0.00001709
Iteration 155/1000 | Loss: 0.00001709
Iteration 156/1000 | Loss: 0.00001709
Iteration 157/1000 | Loss: 0.00001709
Iteration 158/1000 | Loss: 0.00001709
Iteration 159/1000 | Loss: 0.00001709
Iteration 160/1000 | Loss: 0.00001709
Iteration 161/1000 | Loss: 0.00001708
Iteration 162/1000 | Loss: 0.00001708
Iteration 163/1000 | Loss: 0.00001708
Iteration 164/1000 | Loss: 0.00001708
Iteration 165/1000 | Loss: 0.00001708
Iteration 166/1000 | Loss: 0.00001708
Iteration 167/1000 | Loss: 0.00001708
Iteration 168/1000 | Loss: 0.00001708
Iteration 169/1000 | Loss: 0.00001708
Iteration 170/1000 | Loss: 0.00001707
Iteration 171/1000 | Loss: 0.00001707
Iteration 172/1000 | Loss: 0.00001707
Iteration 173/1000 | Loss: 0.00001707
Iteration 174/1000 | Loss: 0.00001707
Iteration 175/1000 | Loss: 0.00001707
Iteration 176/1000 | Loss: 0.00001707
Iteration 177/1000 | Loss: 0.00001707
Iteration 178/1000 | Loss: 0.00001707
Iteration 179/1000 | Loss: 0.00001707
Iteration 180/1000 | Loss: 0.00001707
Iteration 181/1000 | Loss: 0.00001706
Iteration 182/1000 | Loss: 0.00001706
Iteration 183/1000 | Loss: 0.00001706
Iteration 184/1000 | Loss: 0.00001706
Iteration 185/1000 | Loss: 0.00001706
Iteration 186/1000 | Loss: 0.00001706
Iteration 187/1000 | Loss: 0.00001706
Iteration 188/1000 | Loss: 0.00001706
Iteration 189/1000 | Loss: 0.00001706
Iteration 190/1000 | Loss: 0.00001706
Iteration 191/1000 | Loss: 0.00001706
Iteration 192/1000 | Loss: 0.00001706
Iteration 193/1000 | Loss: 0.00001706
Iteration 194/1000 | Loss: 0.00001706
Iteration 195/1000 | Loss: 0.00001706
Iteration 196/1000 | Loss: 0.00001706
Iteration 197/1000 | Loss: 0.00001706
Iteration 198/1000 | Loss: 0.00001706
Iteration 199/1000 | Loss: 0.00001706
Iteration 200/1000 | Loss: 0.00001706
Iteration 201/1000 | Loss: 0.00001706
Iteration 202/1000 | Loss: 0.00001706
Iteration 203/1000 | Loss: 0.00001706
Iteration 204/1000 | Loss: 0.00001706
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 204. Stopping optimization.
Last 5 losses: [1.705644535832107e-05, 1.705644535832107e-05, 1.705644535832107e-05, 1.705644535832107e-05, 1.705644535832107e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.705644535832107e-05

Optimization complete. Final v2v error: 3.520357131958008 mm

Highest mean error: 3.979841709136963 mm for frame 48

Lowest mean error: 3.002619504928589 mm for frame 5

Saving results

Total time: 671.7593727111816
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1028
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00477523
Iteration 2/25 | Loss: 0.00078267
Iteration 3/25 | Loss: 0.00066927
Iteration 4/25 | Loss: 0.00065031
Iteration 5/25 | Loss: 0.00064428
Iteration 6/25 | Loss: 0.00064289
Iteration 7/25 | Loss: 0.00064243
Iteration 8/25 | Loss: 0.00064240
Iteration 9/25 | Loss: 0.00064240
Iteration 10/25 | Loss: 0.00064240
Iteration 11/25 | Loss: 0.00064240
Iteration 12/25 | Loss: 0.00064240
Iteration 13/25 | Loss: 0.00064240
Iteration 14/25 | Loss: 0.00064240
Iteration 15/25 | Loss: 0.00064240
Iteration 16/25 | Loss: 0.00064240
Iteration 17/25 | Loss: 0.00064240
Iteration 18/25 | Loss: 0.00064240
Iteration 19/25 | Loss: 0.00064240
Iteration 20/25 | Loss: 0.00064240
Iteration 21/25 | Loss: 0.00064240
Iteration 22/25 | Loss: 0.00064240
Iteration 23/25 | Loss: 0.00064240
Iteration 24/25 | Loss: 0.00064240
Iteration 25/25 | Loss: 0.00064240

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.91260481
Iteration 2/25 | Loss: 0.00032453
Iteration 3/25 | Loss: 0.00032453
Iteration 4/25 | Loss: 0.00032453
Iteration 5/25 | Loss: 0.00032453
Iteration 6/25 | Loss: 0.00032453
Iteration 7/25 | Loss: 0.00032453
Iteration 8/25 | Loss: 0.00032453
Iteration 9/25 | Loss: 0.00032453
Iteration 10/25 | Loss: 0.00032453
Iteration 11/25 | Loss: 0.00032453
Iteration 12/25 | Loss: 0.00032452
Iteration 13/25 | Loss: 0.00032452
Iteration 14/25 | Loss: 0.00032452
Iteration 15/25 | Loss: 0.00032452
Iteration 16/25 | Loss: 0.00032452
Iteration 17/25 | Loss: 0.00032452
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00032452488085255027, 0.00032452488085255027, 0.00032452488085255027, 0.00032452488085255027, 0.00032452488085255027]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00032452488085255027

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032452
Iteration 2/1000 | Loss: 0.00003471
Iteration 3/1000 | Loss: 0.00001958
Iteration 4/1000 | Loss: 0.00001769
Iteration 5/1000 | Loss: 0.00001658
Iteration 6/1000 | Loss: 0.00001599
Iteration 7/1000 | Loss: 0.00001552
Iteration 8/1000 | Loss: 0.00001526
Iteration 9/1000 | Loss: 0.00001518
Iteration 10/1000 | Loss: 0.00001512
Iteration 11/1000 | Loss: 0.00001511
Iteration 12/1000 | Loss: 0.00001506
Iteration 13/1000 | Loss: 0.00001504
Iteration 14/1000 | Loss: 0.00001498
Iteration 15/1000 | Loss: 0.00001490
Iteration 16/1000 | Loss: 0.00001488
Iteration 17/1000 | Loss: 0.00001487
Iteration 18/1000 | Loss: 0.00001487
Iteration 19/1000 | Loss: 0.00001487
Iteration 20/1000 | Loss: 0.00001486
Iteration 21/1000 | Loss: 0.00001486
Iteration 22/1000 | Loss: 0.00001485
Iteration 23/1000 | Loss: 0.00001483
Iteration 24/1000 | Loss: 0.00001483
Iteration 25/1000 | Loss: 0.00001483
Iteration 26/1000 | Loss: 0.00001482
Iteration 27/1000 | Loss: 0.00001482
Iteration 28/1000 | Loss: 0.00001481
Iteration 29/1000 | Loss: 0.00001481
Iteration 30/1000 | Loss: 0.00001480
Iteration 31/1000 | Loss: 0.00001480
Iteration 32/1000 | Loss: 0.00001479
Iteration 33/1000 | Loss: 0.00001479
Iteration 34/1000 | Loss: 0.00001479
Iteration 35/1000 | Loss: 0.00001479
Iteration 36/1000 | Loss: 0.00001479
Iteration 37/1000 | Loss: 0.00001479
Iteration 38/1000 | Loss: 0.00001479
Iteration 39/1000 | Loss: 0.00001478
Iteration 40/1000 | Loss: 0.00001478
Iteration 41/1000 | Loss: 0.00001477
Iteration 42/1000 | Loss: 0.00001477
Iteration 43/1000 | Loss: 0.00001477
Iteration 44/1000 | Loss: 0.00001476
Iteration 45/1000 | Loss: 0.00001476
Iteration 46/1000 | Loss: 0.00001476
Iteration 47/1000 | Loss: 0.00001475
Iteration 48/1000 | Loss: 0.00001475
Iteration 49/1000 | Loss: 0.00001475
Iteration 50/1000 | Loss: 0.00001475
Iteration 51/1000 | Loss: 0.00001475
Iteration 52/1000 | Loss: 0.00001474
Iteration 53/1000 | Loss: 0.00001473
Iteration 54/1000 | Loss: 0.00001473
Iteration 55/1000 | Loss: 0.00001473
Iteration 56/1000 | Loss: 0.00001473
Iteration 57/1000 | Loss: 0.00001473
Iteration 58/1000 | Loss: 0.00001472
Iteration 59/1000 | Loss: 0.00001472
Iteration 60/1000 | Loss: 0.00001471
Iteration 61/1000 | Loss: 0.00001471
Iteration 62/1000 | Loss: 0.00001471
Iteration 63/1000 | Loss: 0.00001471
Iteration 64/1000 | Loss: 0.00001470
Iteration 65/1000 | Loss: 0.00001470
Iteration 66/1000 | Loss: 0.00001470
Iteration 67/1000 | Loss: 0.00001469
Iteration 68/1000 | Loss: 0.00001469
Iteration 69/1000 | Loss: 0.00001469
Iteration 70/1000 | Loss: 0.00001468
Iteration 71/1000 | Loss: 0.00001468
Iteration 72/1000 | Loss: 0.00001467
Iteration 73/1000 | Loss: 0.00001467
Iteration 74/1000 | Loss: 0.00001467
Iteration 75/1000 | Loss: 0.00001467
Iteration 76/1000 | Loss: 0.00001467
Iteration 77/1000 | Loss: 0.00001467
Iteration 78/1000 | Loss: 0.00001466
Iteration 79/1000 | Loss: 0.00001466
Iteration 80/1000 | Loss: 0.00001466
Iteration 81/1000 | Loss: 0.00001465
Iteration 82/1000 | Loss: 0.00001465
Iteration 83/1000 | Loss: 0.00001465
Iteration 84/1000 | Loss: 0.00001464
Iteration 85/1000 | Loss: 0.00001464
Iteration 86/1000 | Loss: 0.00001464
Iteration 87/1000 | Loss: 0.00001464
Iteration 88/1000 | Loss: 0.00001463
Iteration 89/1000 | Loss: 0.00001463
Iteration 90/1000 | Loss: 0.00001463
Iteration 91/1000 | Loss: 0.00001463
Iteration 92/1000 | Loss: 0.00001462
Iteration 93/1000 | Loss: 0.00001462
Iteration 94/1000 | Loss: 0.00001461
Iteration 95/1000 | Loss: 0.00001461
Iteration 96/1000 | Loss: 0.00001460
Iteration 97/1000 | Loss: 0.00001460
Iteration 98/1000 | Loss: 0.00001460
Iteration 99/1000 | Loss: 0.00001460
Iteration 100/1000 | Loss: 0.00001459
Iteration 101/1000 | Loss: 0.00001459
Iteration 102/1000 | Loss: 0.00001459
Iteration 103/1000 | Loss: 0.00001458
Iteration 104/1000 | Loss: 0.00001458
Iteration 105/1000 | Loss: 0.00001457
Iteration 106/1000 | Loss: 0.00001457
Iteration 107/1000 | Loss: 0.00001457
Iteration 108/1000 | Loss: 0.00001456
Iteration 109/1000 | Loss: 0.00001456
Iteration 110/1000 | Loss: 0.00001456
Iteration 111/1000 | Loss: 0.00001456
Iteration 112/1000 | Loss: 0.00001455
Iteration 113/1000 | Loss: 0.00001455
Iteration 114/1000 | Loss: 0.00001455
Iteration 115/1000 | Loss: 0.00001455
Iteration 116/1000 | Loss: 0.00001455
Iteration 117/1000 | Loss: 0.00001455
Iteration 118/1000 | Loss: 0.00001455
Iteration 119/1000 | Loss: 0.00001455
Iteration 120/1000 | Loss: 0.00001454
Iteration 121/1000 | Loss: 0.00001454
Iteration 122/1000 | Loss: 0.00001454
Iteration 123/1000 | Loss: 0.00001454
Iteration 124/1000 | Loss: 0.00001454
Iteration 125/1000 | Loss: 0.00001454
Iteration 126/1000 | Loss: 0.00001454
Iteration 127/1000 | Loss: 0.00001454
Iteration 128/1000 | Loss: 0.00001453
Iteration 129/1000 | Loss: 0.00001453
Iteration 130/1000 | Loss: 0.00001453
Iteration 131/1000 | Loss: 0.00001453
Iteration 132/1000 | Loss: 0.00001453
Iteration 133/1000 | Loss: 0.00001453
Iteration 134/1000 | Loss: 0.00001453
Iteration 135/1000 | Loss: 0.00001453
Iteration 136/1000 | Loss: 0.00001453
Iteration 137/1000 | Loss: 0.00001453
Iteration 138/1000 | Loss: 0.00001453
Iteration 139/1000 | Loss: 0.00001453
Iteration 140/1000 | Loss: 0.00001453
Iteration 141/1000 | Loss: 0.00001453
Iteration 142/1000 | Loss: 0.00001453
Iteration 143/1000 | Loss: 0.00001453
Iteration 144/1000 | Loss: 0.00001453
Iteration 145/1000 | Loss: 0.00001453
Iteration 146/1000 | Loss: 0.00001453
Iteration 147/1000 | Loss: 0.00001453
Iteration 148/1000 | Loss: 0.00001453
Iteration 149/1000 | Loss: 0.00001453
Iteration 150/1000 | Loss: 0.00001453
Iteration 151/1000 | Loss: 0.00001453
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [1.4526842278428376e-05, 1.4526842278428376e-05, 1.4526842278428376e-05, 1.4526842278428376e-05, 1.4526842278428376e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4526842278428376e-05

Optimization complete. Final v2v error: 3.23905873298645 mm

Highest mean error: 3.660682201385498 mm for frame 115

Lowest mean error: 3.01081919670105 mm for frame 61

Saving results

Total time: 898.595151424408
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1059/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1059.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1059
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00424809
Iteration 2/25 | Loss: 0.00077911
Iteration 3/25 | Loss: 0.00064187
Iteration 4/25 | Loss: 0.00062465
Iteration 5/25 | Loss: 0.00061893
Iteration 6/25 | Loss: 0.00061724
Iteration 7/25 | Loss: 0.00061709
Iteration 8/25 | Loss: 0.00061709
Iteration 9/25 | Loss: 0.00061709
Iteration 10/25 | Loss: 0.00061709
Iteration 11/25 | Loss: 0.00061709
Iteration 12/25 | Loss: 0.00061709
Iteration 13/25 | Loss: 0.00061709
Iteration 14/25 | Loss: 0.00061709
Iteration 15/25 | Loss: 0.00061709
Iteration 16/25 | Loss: 0.00061709
Iteration 17/25 | Loss: 0.00061709
Iteration 18/25 | Loss: 0.00061709
Iteration 19/25 | Loss: 0.00061709
Iteration 20/25 | Loss: 0.00061709
Iteration 21/25 | Loss: 0.00061709
Iteration 22/25 | Loss: 0.00061709
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0006170865963213146, 0.0006170865963213146, 0.0006170865963213146, 0.0006170865963213146, 0.0006170865963213146]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006170865963213146

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46309388
Iteration 2/25 | Loss: 0.00035977
Iteration 3/25 | Loss: 0.00035976
Iteration 4/25 | Loss: 0.00035976
Iteration 5/25 | Loss: 0.00035976
Iteration 6/25 | Loss: 0.00035976
Iteration 7/25 | Loss: 0.00035976
Iteration 8/25 | Loss: 0.00035976
Iteration 9/25 | Loss: 0.00035976
Iteration 10/25 | Loss: 0.00035976
Iteration 11/25 | Loss: 0.00035976
Iteration 12/25 | Loss: 0.00035976
Iteration 13/25 | Loss: 0.00035976
Iteration 14/25 | Loss: 0.00035976
Iteration 15/25 | Loss: 0.00035976
Iteration 16/25 | Loss: 0.00035976
Iteration 17/25 | Loss: 0.00035976
Iteration 18/25 | Loss: 0.00035976
Iteration 19/25 | Loss: 0.00035976
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003597587638068944, 0.0003597587638068944, 0.0003597587638068944, 0.0003597587638068944, 0.0003597587638068944]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003597587638068944

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035976
Iteration 2/1000 | Loss: 0.00001908
Iteration 3/1000 | Loss: 0.00001303
Iteration 4/1000 | Loss: 0.00001207
Iteration 5/1000 | Loss: 0.00001157
Iteration 6/1000 | Loss: 0.00001127
Iteration 7/1000 | Loss: 0.00001121
Iteration 8/1000 | Loss: 0.00001107
Iteration 9/1000 | Loss: 0.00001098
Iteration 10/1000 | Loss: 0.00001095
Iteration 11/1000 | Loss: 0.00001095
Iteration 12/1000 | Loss: 0.00001093
Iteration 13/1000 | Loss: 0.00001091
Iteration 14/1000 | Loss: 0.00001088
Iteration 15/1000 | Loss: 0.00001088
Iteration 16/1000 | Loss: 0.00001087
Iteration 17/1000 | Loss: 0.00001087
Iteration 18/1000 | Loss: 0.00001086
Iteration 19/1000 | Loss: 0.00001083
Iteration 20/1000 | Loss: 0.00001083
Iteration 21/1000 | Loss: 0.00001082
Iteration 22/1000 | Loss: 0.00001081
Iteration 23/1000 | Loss: 0.00001078
Iteration 24/1000 | Loss: 0.00001077
Iteration 25/1000 | Loss: 0.00001077
Iteration 26/1000 | Loss: 0.00001076
Iteration 27/1000 | Loss: 0.00001076
Iteration 28/1000 | Loss: 0.00001076
Iteration 29/1000 | Loss: 0.00001076
Iteration 30/1000 | Loss: 0.00001076
Iteration 31/1000 | Loss: 0.00001075
Iteration 32/1000 | Loss: 0.00001075
Iteration 33/1000 | Loss: 0.00001075
Iteration 34/1000 | Loss: 0.00001075
Iteration 35/1000 | Loss: 0.00001075
Iteration 36/1000 | Loss: 0.00001075
Iteration 37/1000 | Loss: 0.00001075
Iteration 38/1000 | Loss: 0.00001075
Iteration 39/1000 | Loss: 0.00001075
Iteration 40/1000 | Loss: 0.00001074
Iteration 41/1000 | Loss: 0.00001074
Iteration 42/1000 | Loss: 0.00001074
Iteration 43/1000 | Loss: 0.00001074
Iteration 44/1000 | Loss: 0.00001073
Iteration 45/1000 | Loss: 0.00001072
Iteration 46/1000 | Loss: 0.00001072
Iteration 47/1000 | Loss: 0.00001071
Iteration 48/1000 | Loss: 0.00001071
Iteration 49/1000 | Loss: 0.00001071
Iteration 50/1000 | Loss: 0.00001071
Iteration 51/1000 | Loss: 0.00001070
Iteration 52/1000 | Loss: 0.00001070
Iteration 53/1000 | Loss: 0.00001070
Iteration 54/1000 | Loss: 0.00001069
Iteration 55/1000 | Loss: 0.00001068
Iteration 56/1000 | Loss: 0.00001068
Iteration 57/1000 | Loss: 0.00001068
Iteration 58/1000 | Loss: 0.00001068
Iteration 59/1000 | Loss: 0.00001068
Iteration 60/1000 | Loss: 0.00001068
Iteration 61/1000 | Loss: 0.00001068
Iteration 62/1000 | Loss: 0.00001068
Iteration 63/1000 | Loss: 0.00001068
Iteration 64/1000 | Loss: 0.00001068
Iteration 65/1000 | Loss: 0.00001068
Iteration 66/1000 | Loss: 0.00001068
Iteration 67/1000 | Loss: 0.00001068
Iteration 68/1000 | Loss: 0.00001068
Iteration 69/1000 | Loss: 0.00001068
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 69. Stopping optimization.
Last 5 losses: [1.0677101272449363e-05, 1.0677101272449363e-05, 1.0677101272449363e-05, 1.0677101272449363e-05, 1.0677101272449363e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0677101272449363e-05

Optimization complete. Final v2v error: 2.762561798095703 mm

Highest mean error: 2.990912675857544 mm for frame 14

Lowest mean error: 2.534158706665039 mm for frame 141

Saving results

Total time: 1040.4645493030548
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1079
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01075121
Iteration 2/25 | Loss: 0.00188843
Iteration 3/25 | Loss: 0.00089118
Iteration 4/25 | Loss: 0.00078787
Iteration 5/25 | Loss: 0.00073501
Iteration 6/25 | Loss: 0.00069431
Iteration 7/25 | Loss: 0.00068046
Iteration 8/25 | Loss: 0.00067105
Iteration 9/25 | Loss: 0.00066070
Iteration 10/25 | Loss: 0.00065465
Iteration 11/25 | Loss: 0.00065283
Iteration 12/25 | Loss: 0.00065171
Iteration 13/25 | Loss: 0.00064808
Iteration 14/25 | Loss: 0.00064426
Iteration 15/25 | Loss: 0.00064591
Iteration 16/25 | Loss: 0.00064991
Iteration 17/25 | Loss: 0.00064693
Iteration 18/25 | Loss: 0.00064363
Iteration 19/25 | Loss: 0.00064316
Iteration 20/25 | Loss: 0.00064537
Iteration 21/25 | Loss: 0.00064189
Iteration 22/25 | Loss: 0.00064418
Iteration 23/25 | Loss: 0.00064392
Iteration 24/25 | Loss: 0.00064392
Iteration 25/25 | Loss: 0.00064662

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52070677
Iteration 2/25 | Loss: 0.00037679
Iteration 3/25 | Loss: 0.00037679
Iteration 4/25 | Loss: 0.00037678
Iteration 5/25 | Loss: 0.00037678
Iteration 6/25 | Loss: 0.00037678
Iteration 7/25 | Loss: 0.00037678
Iteration 8/25 | Loss: 0.00037678
Iteration 9/25 | Loss: 0.00037678
Iteration 10/25 | Loss: 0.00037678
Iteration 11/25 | Loss: 0.00037678
Iteration 12/25 | Loss: 0.00037678
Iteration 13/25 | Loss: 0.00037678
Iteration 14/25 | Loss: 0.00037678
Iteration 15/25 | Loss: 0.00037678
Iteration 16/25 | Loss: 0.00037678
Iteration 17/25 | Loss: 0.00037678
Iteration 18/25 | Loss: 0.00037678
Iteration 19/25 | Loss: 0.00037678
Iteration 20/25 | Loss: 0.00037678
Iteration 21/25 | Loss: 0.00037678
Iteration 22/25 | Loss: 0.00037678
Iteration 23/25 | Loss: 0.00037678
Iteration 24/25 | Loss: 0.00037678
Iteration 25/25 | Loss: 0.00037678

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00037678
Iteration 2/1000 | Loss: 0.00002698
Iteration 3/1000 | Loss: 0.00001775
Iteration 4/1000 | Loss: 0.00001836
Iteration 5/1000 | Loss: 0.00008195
Iteration 6/1000 | Loss: 0.00001673
Iteration 7/1000 | Loss: 0.00002410
Iteration 8/1000 | Loss: 0.00001575
Iteration 9/1000 | Loss: 0.00001513
Iteration 10/1000 | Loss: 0.00002072
Iteration 11/1000 | Loss: 0.00003677
Iteration 12/1000 | Loss: 0.00018938
Iteration 13/1000 | Loss: 0.00009885
Iteration 14/1000 | Loss: 0.00001414
Iteration 15/1000 | Loss: 0.00002893
Iteration 16/1000 | Loss: 0.00003781
Iteration 17/1000 | Loss: 0.00001454
Iteration 18/1000 | Loss: 0.00001095
Iteration 19/1000 | Loss: 0.00002225
Iteration 20/1000 | Loss: 0.00001090
Iteration 21/1000 | Loss: 0.00001089
Iteration 22/1000 | Loss: 0.00001089
Iteration 23/1000 | Loss: 0.00001087
Iteration 24/1000 | Loss: 0.00001086
Iteration 25/1000 | Loss: 0.00001086
Iteration 26/1000 | Loss: 0.00001086
Iteration 27/1000 | Loss: 0.00001085
Iteration 28/1000 | Loss: 0.00001085
Iteration 29/1000 | Loss: 0.00001085
Iteration 30/1000 | Loss: 0.00001085
Iteration 31/1000 | Loss: 0.00001085
Iteration 32/1000 | Loss: 0.00001085
Iteration 33/1000 | Loss: 0.00001085
Iteration 34/1000 | Loss: 0.00001085
Iteration 35/1000 | Loss: 0.00001084
Iteration 36/1000 | Loss: 0.00001084
Iteration 37/1000 | Loss: 0.00001084
Iteration 38/1000 | Loss: 0.00001084
Iteration 39/1000 | Loss: 0.00001084
Iteration 40/1000 | Loss: 0.00001084
Iteration 41/1000 | Loss: 0.00001084
Iteration 42/1000 | Loss: 0.00001083
Iteration 43/1000 | Loss: 0.00001083
Iteration 44/1000 | Loss: 0.00001177
Iteration 45/1000 | Loss: 0.00001793
Iteration 46/1000 | Loss: 0.00002565
Iteration 47/1000 | Loss: 0.00001083
Iteration 48/1000 | Loss: 0.00001083
Iteration 49/1000 | Loss: 0.00001082
Iteration 50/1000 | Loss: 0.00001082
Iteration 51/1000 | Loss: 0.00001080
Iteration 52/1000 | Loss: 0.00001080
Iteration 53/1000 | Loss: 0.00001080
Iteration 54/1000 | Loss: 0.00001080
Iteration 55/1000 | Loss: 0.00001080
Iteration 56/1000 | Loss: 0.00001303
Iteration 57/1000 | Loss: 0.00001096
Iteration 58/1000 | Loss: 0.00003742
Iteration 59/1000 | Loss: 0.00004154
Iteration 60/1000 | Loss: 0.00006588
Iteration 61/1000 | Loss: 0.00001836
Iteration 62/1000 | Loss: 0.00001079
Iteration 63/1000 | Loss: 0.00001104
Iteration 64/1000 | Loss: 0.00002929
Iteration 65/1000 | Loss: 0.00053427
Iteration 66/1000 | Loss: 0.00003444
Iteration 67/1000 | Loss: 0.00027658
Iteration 68/1000 | Loss: 0.00003513
Iteration 69/1000 | Loss: 0.00012050
Iteration 70/1000 | Loss: 0.00001286
Iteration 71/1000 | Loss: 0.00001073
Iteration 72/1000 | Loss: 0.00001073
Iteration 73/1000 | Loss: 0.00001073
Iteration 74/1000 | Loss: 0.00001073
Iteration 75/1000 | Loss: 0.00001073
Iteration 76/1000 | Loss: 0.00001073
Iteration 77/1000 | Loss: 0.00001073
Iteration 78/1000 | Loss: 0.00001073
Iteration 79/1000 | Loss: 0.00001073
Iteration 80/1000 | Loss: 0.00001073
Iteration 81/1000 | Loss: 0.00001072
Iteration 82/1000 | Loss: 0.00001072
Iteration 83/1000 | Loss: 0.00002346
Iteration 84/1000 | Loss: 0.00001072
Iteration 85/1000 | Loss: 0.00001071
Iteration 86/1000 | Loss: 0.00001070
Iteration 87/1000 | Loss: 0.00001070
Iteration 88/1000 | Loss: 0.00001070
Iteration 89/1000 | Loss: 0.00001070
Iteration 90/1000 | Loss: 0.00001070
Iteration 91/1000 | Loss: 0.00001070
Iteration 92/1000 | Loss: 0.00001070
Iteration 93/1000 | Loss: 0.00001070
Iteration 94/1000 | Loss: 0.00001069
Iteration 95/1000 | Loss: 0.00001069
Iteration 96/1000 | Loss: 0.00001069
Iteration 97/1000 | Loss: 0.00001069
Iteration 98/1000 | Loss: 0.00001069
Iteration 99/1000 | Loss: 0.00001069
Iteration 100/1000 | Loss: 0.00001069
Iteration 101/1000 | Loss: 0.00001069
Iteration 102/1000 | Loss: 0.00001069
Iteration 103/1000 | Loss: 0.00001069
Iteration 104/1000 | Loss: 0.00001069
Iteration 105/1000 | Loss: 0.00001069
Iteration 106/1000 | Loss: 0.00001069
Iteration 107/1000 | Loss: 0.00001069
Iteration 108/1000 | Loss: 0.00001069
Iteration 109/1000 | Loss: 0.00001069
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.0688381735235453e-05, 1.0688381735235453e-05, 1.0688381735235453e-05, 1.0688381735235453e-05, 1.0688381735235453e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0688381735235453e-05

Optimization complete. Final v2v error: 2.6472744941711426 mm

Highest mean error: 9.433356285095215 mm for frame 88

Lowest mean error: 2.424192190170288 mm for frame 38

Saving results

Total time: 2089.740200996399
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1012
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00692999
Iteration 2/25 | Loss: 0.00081364
Iteration 3/25 | Loss: 0.00064559
Iteration 4/25 | Loss: 0.00062089
Iteration 5/25 | Loss: 0.00061212
Iteration 6/25 | Loss: 0.00061043
Iteration 7/25 | Loss: 0.00060997
Iteration 8/25 | Loss: 0.00060994
Iteration 9/25 | Loss: 0.00060994
Iteration 10/25 | Loss: 0.00060994
Iteration 11/25 | Loss: 0.00060994
Iteration 12/25 | Loss: 0.00060994
Iteration 13/25 | Loss: 0.00060994
Iteration 14/25 | Loss: 0.00060994
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0006099434685893357, 0.0006099434685893357, 0.0006099434685893357, 0.0006099434685893357, 0.0006099434685893357]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006099434685893357

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56185102
Iteration 2/25 | Loss: 0.00029801
Iteration 3/25 | Loss: 0.00029801
Iteration 4/25 | Loss: 0.00029801
Iteration 5/25 | Loss: 0.00029801
Iteration 6/25 | Loss: 0.00029801
Iteration 7/25 | Loss: 0.00029801
Iteration 8/25 | Loss: 0.00029801
Iteration 9/25 | Loss: 0.00029801
Iteration 10/25 | Loss: 0.00029801
Iteration 11/25 | Loss: 0.00029801
Iteration 12/25 | Loss: 0.00029801
Iteration 13/25 | Loss: 0.00029801
Iteration 14/25 | Loss: 0.00029801
Iteration 15/25 | Loss: 0.00029801
Iteration 16/25 | Loss: 0.00029801
Iteration 17/25 | Loss: 0.00029801
Iteration 18/25 | Loss: 0.00029801
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0002980097779072821, 0.0002980097779072821, 0.0002980097779072821, 0.0002980097779072821, 0.0002980097779072821]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002980097779072821

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029801
Iteration 2/1000 | Loss: 0.00002453
Iteration 3/1000 | Loss: 0.00001619
Iteration 4/1000 | Loss: 0.00001448
Iteration 5/1000 | Loss: 0.00001357
Iteration 6/1000 | Loss: 0.00001317
Iteration 7/1000 | Loss: 0.00001287
Iteration 8/1000 | Loss: 0.00001271
Iteration 9/1000 | Loss: 0.00001259
Iteration 10/1000 | Loss: 0.00001252
Iteration 11/1000 | Loss: 0.00001251
Iteration 12/1000 | Loss: 0.00001251
Iteration 13/1000 | Loss: 0.00001250
Iteration 14/1000 | Loss: 0.00001250
Iteration 15/1000 | Loss: 0.00001250
Iteration 16/1000 | Loss: 0.00001247
Iteration 17/1000 | Loss: 0.00001246
Iteration 18/1000 | Loss: 0.00001243
Iteration 19/1000 | Loss: 0.00001239
Iteration 20/1000 | Loss: 0.00001239
Iteration 21/1000 | Loss: 0.00001239
Iteration 22/1000 | Loss: 0.00001239
Iteration 23/1000 | Loss: 0.00001239
Iteration 24/1000 | Loss: 0.00001239
Iteration 25/1000 | Loss: 0.00001237
Iteration 26/1000 | Loss: 0.00001235
Iteration 27/1000 | Loss: 0.00001235
Iteration 28/1000 | Loss: 0.00001235
Iteration 29/1000 | Loss: 0.00001234
Iteration 30/1000 | Loss: 0.00001234
Iteration 31/1000 | Loss: 0.00001233
Iteration 32/1000 | Loss: 0.00001232
Iteration 33/1000 | Loss: 0.00001232
Iteration 34/1000 | Loss: 0.00001232
Iteration 35/1000 | Loss: 0.00001232
Iteration 36/1000 | Loss: 0.00001231
Iteration 37/1000 | Loss: 0.00001231
Iteration 38/1000 | Loss: 0.00001231
Iteration 39/1000 | Loss: 0.00001231
Iteration 40/1000 | Loss: 0.00001231
Iteration 41/1000 | Loss: 0.00001231
Iteration 42/1000 | Loss: 0.00001231
Iteration 43/1000 | Loss: 0.00001231
Iteration 44/1000 | Loss: 0.00001231
Iteration 45/1000 | Loss: 0.00001231
Iteration 46/1000 | Loss: 0.00001231
Iteration 47/1000 | Loss: 0.00001230
Iteration 48/1000 | Loss: 0.00001230
Iteration 49/1000 | Loss: 0.00001230
Iteration 50/1000 | Loss: 0.00001230
Iteration 51/1000 | Loss: 0.00001228
Iteration 52/1000 | Loss: 0.00001227
Iteration 53/1000 | Loss: 0.00001227
Iteration 54/1000 | Loss: 0.00001227
Iteration 55/1000 | Loss: 0.00001226
Iteration 56/1000 | Loss: 0.00001224
Iteration 57/1000 | Loss: 0.00001223
Iteration 58/1000 | Loss: 0.00001223
Iteration 59/1000 | Loss: 0.00001223
Iteration 60/1000 | Loss: 0.00001223
Iteration 61/1000 | Loss: 0.00001223
Iteration 62/1000 | Loss: 0.00001223
Iteration 63/1000 | Loss: 0.00001223
Iteration 64/1000 | Loss: 0.00001223
Iteration 65/1000 | Loss: 0.00001223
Iteration 66/1000 | Loss: 0.00001223
Iteration 67/1000 | Loss: 0.00001223
Iteration 68/1000 | Loss: 0.00001223
Iteration 69/1000 | Loss: 0.00001222
Iteration 70/1000 | Loss: 0.00001222
Iteration 71/1000 | Loss: 0.00001221
Iteration 72/1000 | Loss: 0.00001220
Iteration 73/1000 | Loss: 0.00001220
Iteration 74/1000 | Loss: 0.00001220
Iteration 75/1000 | Loss: 0.00001219
Iteration 76/1000 | Loss: 0.00001219
Iteration 77/1000 | Loss: 0.00001219
Iteration 78/1000 | Loss: 0.00001218
Iteration 79/1000 | Loss: 0.00001218
Iteration 80/1000 | Loss: 0.00001218
Iteration 81/1000 | Loss: 0.00001217
Iteration 82/1000 | Loss: 0.00001217
Iteration 83/1000 | Loss: 0.00001217
Iteration 84/1000 | Loss: 0.00001216
Iteration 85/1000 | Loss: 0.00001216
Iteration 86/1000 | Loss: 0.00001216
Iteration 87/1000 | Loss: 0.00001216
Iteration 88/1000 | Loss: 0.00001216
Iteration 89/1000 | Loss: 0.00001215
Iteration 90/1000 | Loss: 0.00001215
Iteration 91/1000 | Loss: 0.00001215
Iteration 92/1000 | Loss: 0.00001215
Iteration 93/1000 | Loss: 0.00001214
Iteration 94/1000 | Loss: 0.00001214
Iteration 95/1000 | Loss: 0.00001214
Iteration 96/1000 | Loss: 0.00001213
Iteration 97/1000 | Loss: 0.00001213
Iteration 98/1000 | Loss: 0.00001213
Iteration 99/1000 | Loss: 0.00001212
Iteration 100/1000 | Loss: 0.00001212
Iteration 101/1000 | Loss: 0.00001211
Iteration 102/1000 | Loss: 0.00001211
Iteration 103/1000 | Loss: 0.00001210
Iteration 104/1000 | Loss: 0.00001210
Iteration 105/1000 | Loss: 0.00001210
Iteration 106/1000 | Loss: 0.00001210
Iteration 107/1000 | Loss: 0.00001210
Iteration 108/1000 | Loss: 0.00001210
Iteration 109/1000 | Loss: 0.00001210
Iteration 110/1000 | Loss: 0.00001209
Iteration 111/1000 | Loss: 0.00001209
Iteration 112/1000 | Loss: 0.00001209
Iteration 113/1000 | Loss: 0.00001209
Iteration 114/1000 | Loss: 0.00001209
Iteration 115/1000 | Loss: 0.00001209
Iteration 116/1000 | Loss: 0.00001209
Iteration 117/1000 | Loss: 0.00001209
Iteration 118/1000 | Loss: 0.00001209
Iteration 119/1000 | Loss: 0.00001209
Iteration 120/1000 | Loss: 0.00001208
Iteration 121/1000 | Loss: 0.00001208
Iteration 122/1000 | Loss: 0.00001208
Iteration 123/1000 | Loss: 0.00001207
Iteration 124/1000 | Loss: 0.00001207
Iteration 125/1000 | Loss: 0.00001207
Iteration 126/1000 | Loss: 0.00001207
Iteration 127/1000 | Loss: 0.00001207
Iteration 128/1000 | Loss: 0.00001207
Iteration 129/1000 | Loss: 0.00001207
Iteration 130/1000 | Loss: 0.00001206
Iteration 131/1000 | Loss: 0.00001206
Iteration 132/1000 | Loss: 0.00001206
Iteration 133/1000 | Loss: 0.00001206
Iteration 134/1000 | Loss: 0.00001205
Iteration 135/1000 | Loss: 0.00001205
Iteration 136/1000 | Loss: 0.00001205
Iteration 137/1000 | Loss: 0.00001205
Iteration 138/1000 | Loss: 0.00001205
Iteration 139/1000 | Loss: 0.00001205
Iteration 140/1000 | Loss: 0.00001205
Iteration 141/1000 | Loss: 0.00001205
Iteration 142/1000 | Loss: 0.00001205
Iteration 143/1000 | Loss: 0.00001205
Iteration 144/1000 | Loss: 0.00001205
Iteration 145/1000 | Loss: 0.00001205
Iteration 146/1000 | Loss: 0.00001205
Iteration 147/1000 | Loss: 0.00001205
Iteration 148/1000 | Loss: 0.00001205
Iteration 149/1000 | Loss: 0.00001205
Iteration 150/1000 | Loss: 0.00001205
Iteration 151/1000 | Loss: 0.00001205
Iteration 152/1000 | Loss: 0.00001205
Iteration 153/1000 | Loss: 0.00001205
Iteration 154/1000 | Loss: 0.00001204
Iteration 155/1000 | Loss: 0.00001204
Iteration 156/1000 | Loss: 0.00001204
Iteration 157/1000 | Loss: 0.00001204
Iteration 158/1000 | Loss: 0.00001204
Iteration 159/1000 | Loss: 0.00001204
Iteration 160/1000 | Loss: 0.00001204
Iteration 161/1000 | Loss: 0.00001204
Iteration 162/1000 | Loss: 0.00001204
Iteration 163/1000 | Loss: 0.00001204
Iteration 164/1000 | Loss: 0.00001204
Iteration 165/1000 | Loss: 0.00001204
Iteration 166/1000 | Loss: 0.00001204
Iteration 167/1000 | Loss: 0.00001204
Iteration 168/1000 | Loss: 0.00001204
Iteration 169/1000 | Loss: 0.00001203
Iteration 170/1000 | Loss: 0.00001203
Iteration 171/1000 | Loss: 0.00001203
Iteration 172/1000 | Loss: 0.00001203
Iteration 173/1000 | Loss: 0.00001203
Iteration 174/1000 | Loss: 0.00001203
Iteration 175/1000 | Loss: 0.00001203
Iteration 176/1000 | Loss: 0.00001203
Iteration 177/1000 | Loss: 0.00001203
Iteration 178/1000 | Loss: 0.00001203
Iteration 179/1000 | Loss: 0.00001203
Iteration 180/1000 | Loss: 0.00001203
Iteration 181/1000 | Loss: 0.00001203
Iteration 182/1000 | Loss: 0.00001203
Iteration 183/1000 | Loss: 0.00001203
Iteration 184/1000 | Loss: 0.00001203
Iteration 185/1000 | Loss: 0.00001203
Iteration 186/1000 | Loss: 0.00001203
Iteration 187/1000 | Loss: 0.00001203
Iteration 188/1000 | Loss: 0.00001203
Iteration 189/1000 | Loss: 0.00001203
Iteration 190/1000 | Loss: 0.00001203
Iteration 191/1000 | Loss: 0.00001203
Iteration 192/1000 | Loss: 0.00001203
Iteration 193/1000 | Loss: 0.00001203
Iteration 194/1000 | Loss: 0.00001203
Iteration 195/1000 | Loss: 0.00001203
Iteration 196/1000 | Loss: 0.00001203
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [1.2028750461468007e-05, 1.2028750461468007e-05, 1.2028750461468007e-05, 1.2028750461468007e-05, 1.2028750461468007e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2028750461468007e-05

Optimization complete. Final v2v error: 2.9610843658447266 mm

Highest mean error: 3.587675094604492 mm for frame 73

Lowest mean error: 2.7576491832733154 mm for frame 6

Saving results

Total time: 677.9847099781036
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1002
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00777292
Iteration 2/25 | Loss: 0.00114239
Iteration 3/25 | Loss: 0.00072851
Iteration 4/25 | Loss: 0.00066928
Iteration 5/25 | Loss: 0.00065929
Iteration 6/25 | Loss: 0.00065663
Iteration 7/25 | Loss: 0.00065610
Iteration 8/25 | Loss: 0.00065609
Iteration 9/25 | Loss: 0.00065609
Iteration 10/25 | Loss: 0.00065609
Iteration 11/25 | Loss: 0.00065609
Iteration 12/25 | Loss: 0.00065609
Iteration 13/25 | Loss: 0.00065609
Iteration 14/25 | Loss: 0.00065609
Iteration 15/25 | Loss: 0.00065609
Iteration 16/25 | Loss: 0.00065609
Iteration 17/25 | Loss: 0.00065609
Iteration 18/25 | Loss: 0.00065609
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006560937035828829, 0.0006560937035828829, 0.0006560937035828829, 0.0006560937035828829, 0.0006560937035828829]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006560937035828829

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45298827
Iteration 2/25 | Loss: 0.00031240
Iteration 3/25 | Loss: 0.00031238
Iteration 4/25 | Loss: 0.00031238
Iteration 5/25 | Loss: 0.00031238
Iteration 6/25 | Loss: 0.00031238
Iteration 7/25 | Loss: 0.00031238
Iteration 8/25 | Loss: 0.00031238
Iteration 9/25 | Loss: 0.00031238
Iteration 10/25 | Loss: 0.00031238
Iteration 11/25 | Loss: 0.00031238
Iteration 12/25 | Loss: 0.00031238
Iteration 13/25 | Loss: 0.00031238
Iteration 14/25 | Loss: 0.00031238
Iteration 15/25 | Loss: 0.00031238
Iteration 16/25 | Loss: 0.00031238
Iteration 17/25 | Loss: 0.00031238
Iteration 18/25 | Loss: 0.00031238
Iteration 19/25 | Loss: 0.00031238
Iteration 20/25 | Loss: 0.00031238
Iteration 21/25 | Loss: 0.00031238
Iteration 22/25 | Loss: 0.00031238
Iteration 23/25 | Loss: 0.00031238
Iteration 24/25 | Loss: 0.00031238
Iteration 25/25 | Loss: 0.00031238
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00031237772782333195, 0.00031237772782333195, 0.00031237772782333195, 0.00031237772782333195, 0.00031237772782333195]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031237772782333195

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031238
Iteration 2/1000 | Loss: 0.00002276
Iteration 3/1000 | Loss: 0.00001730
Iteration 4/1000 | Loss: 0.00001477
Iteration 5/1000 | Loss: 0.00001378
Iteration 6/1000 | Loss: 0.00001324
Iteration 7/1000 | Loss: 0.00001293
Iteration 8/1000 | Loss: 0.00001262
Iteration 9/1000 | Loss: 0.00001254
Iteration 10/1000 | Loss: 0.00001254
Iteration 11/1000 | Loss: 0.00001253
Iteration 12/1000 | Loss: 0.00001241
Iteration 13/1000 | Loss: 0.00001238
Iteration 14/1000 | Loss: 0.00001238
Iteration 15/1000 | Loss: 0.00001234
Iteration 16/1000 | Loss: 0.00001233
Iteration 17/1000 | Loss: 0.00001225
Iteration 18/1000 | Loss: 0.00001225
Iteration 19/1000 | Loss: 0.00001224
Iteration 20/1000 | Loss: 0.00001224
Iteration 21/1000 | Loss: 0.00001222
Iteration 22/1000 | Loss: 0.00001221
Iteration 23/1000 | Loss: 0.00001221
Iteration 24/1000 | Loss: 0.00001221
Iteration 25/1000 | Loss: 0.00001221
Iteration 26/1000 | Loss: 0.00001220
Iteration 27/1000 | Loss: 0.00001219
Iteration 28/1000 | Loss: 0.00001219
Iteration 29/1000 | Loss: 0.00001219
Iteration 30/1000 | Loss: 0.00001218
Iteration 31/1000 | Loss: 0.00001218
Iteration 32/1000 | Loss: 0.00001218
Iteration 33/1000 | Loss: 0.00001217
Iteration 34/1000 | Loss: 0.00001217
Iteration 35/1000 | Loss: 0.00001217
Iteration 36/1000 | Loss: 0.00001216
Iteration 37/1000 | Loss: 0.00001216
Iteration 38/1000 | Loss: 0.00001216
Iteration 39/1000 | Loss: 0.00001216
Iteration 40/1000 | Loss: 0.00001216
Iteration 41/1000 | Loss: 0.00001216
Iteration 42/1000 | Loss: 0.00001215
Iteration 43/1000 | Loss: 0.00001215
Iteration 44/1000 | Loss: 0.00001215
Iteration 45/1000 | Loss: 0.00001214
Iteration 46/1000 | Loss: 0.00001214
Iteration 47/1000 | Loss: 0.00001214
Iteration 48/1000 | Loss: 0.00001214
Iteration 49/1000 | Loss: 0.00001214
Iteration 50/1000 | Loss: 0.00001213
Iteration 51/1000 | Loss: 0.00001213
Iteration 52/1000 | Loss: 0.00001213
Iteration 53/1000 | Loss: 0.00001212
Iteration 54/1000 | Loss: 0.00001212
Iteration 55/1000 | Loss: 0.00001212
Iteration 56/1000 | Loss: 0.00001211
Iteration 57/1000 | Loss: 0.00001211
Iteration 58/1000 | Loss: 0.00001211
Iteration 59/1000 | Loss: 0.00001211
Iteration 60/1000 | Loss: 0.00001210
Iteration 61/1000 | Loss: 0.00001210
Iteration 62/1000 | Loss: 0.00001210
Iteration 63/1000 | Loss: 0.00001210
Iteration 64/1000 | Loss: 0.00001210
Iteration 65/1000 | Loss: 0.00001210
Iteration 66/1000 | Loss: 0.00001210
Iteration 67/1000 | Loss: 0.00001209
Iteration 68/1000 | Loss: 0.00001209
Iteration 69/1000 | Loss: 0.00001209
Iteration 70/1000 | Loss: 0.00001209
Iteration 71/1000 | Loss: 0.00001209
Iteration 72/1000 | Loss: 0.00001208
Iteration 73/1000 | Loss: 0.00001208
Iteration 74/1000 | Loss: 0.00001208
Iteration 75/1000 | Loss: 0.00001208
Iteration 76/1000 | Loss: 0.00001208
Iteration 77/1000 | Loss: 0.00001208
Iteration 78/1000 | Loss: 0.00001207
Iteration 79/1000 | Loss: 0.00001207
Iteration 80/1000 | Loss: 0.00001207
Iteration 81/1000 | Loss: 0.00001206
Iteration 82/1000 | Loss: 0.00001206
Iteration 83/1000 | Loss: 0.00001206
Iteration 84/1000 | Loss: 0.00001206
Iteration 85/1000 | Loss: 0.00001205
Iteration 86/1000 | Loss: 0.00001205
Iteration 87/1000 | Loss: 0.00001204
Iteration 88/1000 | Loss: 0.00001204
Iteration 89/1000 | Loss: 0.00001204
Iteration 90/1000 | Loss: 0.00001204
Iteration 91/1000 | Loss: 0.00001204
Iteration 92/1000 | Loss: 0.00001204
Iteration 93/1000 | Loss: 0.00001203
Iteration 94/1000 | Loss: 0.00001203
Iteration 95/1000 | Loss: 0.00001202
Iteration 96/1000 | Loss: 0.00001202
Iteration 97/1000 | Loss: 0.00001202
Iteration 98/1000 | Loss: 0.00001202
Iteration 99/1000 | Loss: 0.00001202
Iteration 100/1000 | Loss: 0.00001202
Iteration 101/1000 | Loss: 0.00001202
Iteration 102/1000 | Loss: 0.00001202
Iteration 103/1000 | Loss: 0.00001202
Iteration 104/1000 | Loss: 0.00001201
Iteration 105/1000 | Loss: 0.00001201
Iteration 106/1000 | Loss: 0.00001201
Iteration 107/1000 | Loss: 0.00001201
Iteration 108/1000 | Loss: 0.00001201
Iteration 109/1000 | Loss: 0.00001201
Iteration 110/1000 | Loss: 0.00001201
Iteration 111/1000 | Loss: 0.00001201
Iteration 112/1000 | Loss: 0.00001201
Iteration 113/1000 | Loss: 0.00001200
Iteration 114/1000 | Loss: 0.00001200
Iteration 115/1000 | Loss: 0.00001200
Iteration 116/1000 | Loss: 0.00001200
Iteration 117/1000 | Loss: 0.00001200
Iteration 118/1000 | Loss: 0.00001200
Iteration 119/1000 | Loss: 0.00001200
Iteration 120/1000 | Loss: 0.00001200
Iteration 121/1000 | Loss: 0.00001200
Iteration 122/1000 | Loss: 0.00001200
Iteration 123/1000 | Loss: 0.00001200
Iteration 124/1000 | Loss: 0.00001200
Iteration 125/1000 | Loss: 0.00001200
Iteration 126/1000 | Loss: 0.00001200
Iteration 127/1000 | Loss: 0.00001200
Iteration 128/1000 | Loss: 0.00001199
Iteration 129/1000 | Loss: 0.00001199
Iteration 130/1000 | Loss: 0.00001199
Iteration 131/1000 | Loss: 0.00001199
Iteration 132/1000 | Loss: 0.00001199
Iteration 133/1000 | Loss: 0.00001199
Iteration 134/1000 | Loss: 0.00001199
Iteration 135/1000 | Loss: 0.00001199
Iteration 136/1000 | Loss: 0.00001199
Iteration 137/1000 | Loss: 0.00001199
Iteration 138/1000 | Loss: 0.00001199
Iteration 139/1000 | Loss: 0.00001199
Iteration 140/1000 | Loss: 0.00001199
Iteration 141/1000 | Loss: 0.00001199
Iteration 142/1000 | Loss: 0.00001199
Iteration 143/1000 | Loss: 0.00001199
Iteration 144/1000 | Loss: 0.00001199
Iteration 145/1000 | Loss: 0.00001199
Iteration 146/1000 | Loss: 0.00001199
Iteration 147/1000 | Loss: 0.00001199
Iteration 148/1000 | Loss: 0.00001199
Iteration 149/1000 | Loss: 0.00001199
Iteration 150/1000 | Loss: 0.00001199
Iteration 151/1000 | Loss: 0.00001199
Iteration 152/1000 | Loss: 0.00001199
Iteration 153/1000 | Loss: 0.00001199
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 153. Stopping optimization.
Last 5 losses: [1.198590689455159e-05, 1.198590689455159e-05, 1.198590689455159e-05, 1.198590689455159e-05, 1.198590689455159e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.198590689455159e-05

Optimization complete. Final v2v error: 2.9866597652435303 mm

Highest mean error: 3.326174020767212 mm for frame 109

Lowest mean error: 2.7017741203308105 mm for frame 20

Saving results

Total time: 690.3672020435333
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1064/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1064.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1064
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00606975
Iteration 2/25 | Loss: 0.00092696
Iteration 3/25 | Loss: 0.00073253
Iteration 4/25 | Loss: 0.00068383
Iteration 5/25 | Loss: 0.00067666
Iteration 6/25 | Loss: 0.00067487
Iteration 7/25 | Loss: 0.00067477
Iteration 8/25 | Loss: 0.00067477
Iteration 9/25 | Loss: 0.00067477
Iteration 10/25 | Loss: 0.00067477
Iteration 11/25 | Loss: 0.00067477
Iteration 12/25 | Loss: 0.00067477
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006747723673470318, 0.0006747723673470318, 0.0006747723673470318, 0.0006747723673470318, 0.0006747723673470318]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006747723673470318

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.86765862
Iteration 2/25 | Loss: 0.00031021
Iteration 3/25 | Loss: 0.00031021
Iteration 4/25 | Loss: 0.00031021
Iteration 5/25 | Loss: 0.00031021
Iteration 6/25 | Loss: 0.00031021
Iteration 7/25 | Loss: 0.00031021
Iteration 8/25 | Loss: 0.00031021
Iteration 9/25 | Loss: 0.00031020
Iteration 10/25 | Loss: 0.00031020
Iteration 11/25 | Loss: 0.00031020
Iteration 12/25 | Loss: 0.00031020
Iteration 13/25 | Loss: 0.00031020
Iteration 14/25 | Loss: 0.00031020
Iteration 15/25 | Loss: 0.00031020
Iteration 16/25 | Loss: 0.00031020
Iteration 17/25 | Loss: 0.00031020
Iteration 18/25 | Loss: 0.00031020
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00031020469032227993, 0.00031020469032227993, 0.00031020469032227993, 0.00031020469032227993, 0.00031020469032227993]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031020469032227993

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031020
Iteration 2/1000 | Loss: 0.00002849
Iteration 3/1000 | Loss: 0.00002132
Iteration 4/1000 | Loss: 0.00001963
Iteration 5/1000 | Loss: 0.00001855
Iteration 6/1000 | Loss: 0.00001754
Iteration 7/1000 | Loss: 0.00001694
Iteration 8/1000 | Loss: 0.00001651
Iteration 9/1000 | Loss: 0.00001623
Iteration 10/1000 | Loss: 0.00001605
Iteration 11/1000 | Loss: 0.00001592
Iteration 12/1000 | Loss: 0.00001592
Iteration 13/1000 | Loss: 0.00001588
Iteration 14/1000 | Loss: 0.00001587
Iteration 15/1000 | Loss: 0.00001587
Iteration 16/1000 | Loss: 0.00001587
Iteration 17/1000 | Loss: 0.00001587
Iteration 18/1000 | Loss: 0.00001585
Iteration 19/1000 | Loss: 0.00001584
Iteration 20/1000 | Loss: 0.00001582
Iteration 21/1000 | Loss: 0.00001581
Iteration 22/1000 | Loss: 0.00001581
Iteration 23/1000 | Loss: 0.00001578
Iteration 24/1000 | Loss: 0.00001573
Iteration 25/1000 | Loss: 0.00001570
Iteration 26/1000 | Loss: 0.00001570
Iteration 27/1000 | Loss: 0.00001570
Iteration 28/1000 | Loss: 0.00001570
Iteration 29/1000 | Loss: 0.00001569
Iteration 30/1000 | Loss: 0.00001569
Iteration 31/1000 | Loss: 0.00001569
Iteration 32/1000 | Loss: 0.00001569
Iteration 33/1000 | Loss: 0.00001569
Iteration 34/1000 | Loss: 0.00001569
Iteration 35/1000 | Loss: 0.00001568
Iteration 36/1000 | Loss: 0.00001568
Iteration 37/1000 | Loss: 0.00001568
Iteration 38/1000 | Loss: 0.00001568
Iteration 39/1000 | Loss: 0.00001568
Iteration 40/1000 | Loss: 0.00001568
Iteration 41/1000 | Loss: 0.00001568
Iteration 42/1000 | Loss: 0.00001567
Iteration 43/1000 | Loss: 0.00001567
Iteration 44/1000 | Loss: 0.00001567
Iteration 45/1000 | Loss: 0.00001567
Iteration 46/1000 | Loss: 0.00001567
Iteration 47/1000 | Loss: 0.00001567
Iteration 48/1000 | Loss: 0.00001567
Iteration 49/1000 | Loss: 0.00001567
Iteration 50/1000 | Loss: 0.00001567
Iteration 51/1000 | Loss: 0.00001566
Iteration 52/1000 | Loss: 0.00001566
Iteration 53/1000 | Loss: 0.00001566
Iteration 54/1000 | Loss: 0.00001566
Iteration 55/1000 | Loss: 0.00001566
Iteration 56/1000 | Loss: 0.00001566
Iteration 57/1000 | Loss: 0.00001566
Iteration 58/1000 | Loss: 0.00001566
Iteration 59/1000 | Loss: 0.00001565
Iteration 60/1000 | Loss: 0.00001565
Iteration 61/1000 | Loss: 0.00001565
Iteration 62/1000 | Loss: 0.00001565
Iteration 63/1000 | Loss: 0.00001565
Iteration 64/1000 | Loss: 0.00001565
Iteration 65/1000 | Loss: 0.00001565
Iteration 66/1000 | Loss: 0.00001565
Iteration 67/1000 | Loss: 0.00001565
Iteration 68/1000 | Loss: 0.00001565
Iteration 69/1000 | Loss: 0.00001565
Iteration 70/1000 | Loss: 0.00001564
Iteration 71/1000 | Loss: 0.00001564
Iteration 72/1000 | Loss: 0.00001564
Iteration 73/1000 | Loss: 0.00001564
Iteration 74/1000 | Loss: 0.00001564
Iteration 75/1000 | Loss: 0.00001564
Iteration 76/1000 | Loss: 0.00001564
Iteration 77/1000 | Loss: 0.00001564
Iteration 78/1000 | Loss: 0.00001564
Iteration 79/1000 | Loss: 0.00001564
Iteration 80/1000 | Loss: 0.00001563
Iteration 81/1000 | Loss: 0.00001563
Iteration 82/1000 | Loss: 0.00001563
Iteration 83/1000 | Loss: 0.00001562
Iteration 84/1000 | Loss: 0.00001562
Iteration 85/1000 | Loss: 0.00001562
Iteration 86/1000 | Loss: 0.00001562
Iteration 87/1000 | Loss: 0.00001562
Iteration 88/1000 | Loss: 0.00001562
Iteration 89/1000 | Loss: 0.00001562
Iteration 90/1000 | Loss: 0.00001562
Iteration 91/1000 | Loss: 0.00001561
Iteration 92/1000 | Loss: 0.00001561
Iteration 93/1000 | Loss: 0.00001561
Iteration 94/1000 | Loss: 0.00001561
Iteration 95/1000 | Loss: 0.00001561
Iteration 96/1000 | Loss: 0.00001561
Iteration 97/1000 | Loss: 0.00001561
Iteration 98/1000 | Loss: 0.00001561
Iteration 99/1000 | Loss: 0.00001560
Iteration 100/1000 | Loss: 0.00001560
Iteration 101/1000 | Loss: 0.00001560
Iteration 102/1000 | Loss: 0.00001560
Iteration 103/1000 | Loss: 0.00001560
Iteration 104/1000 | Loss: 0.00001560
Iteration 105/1000 | Loss: 0.00001560
Iteration 106/1000 | Loss: 0.00001560
Iteration 107/1000 | Loss: 0.00001560
Iteration 108/1000 | Loss: 0.00001560
Iteration 109/1000 | Loss: 0.00001560
Iteration 110/1000 | Loss: 0.00001560
Iteration 111/1000 | Loss: 0.00001560
Iteration 112/1000 | Loss: 0.00001560
Iteration 113/1000 | Loss: 0.00001559
Iteration 114/1000 | Loss: 0.00001559
Iteration 115/1000 | Loss: 0.00001559
Iteration 116/1000 | Loss: 0.00001559
Iteration 117/1000 | Loss: 0.00001559
Iteration 118/1000 | Loss: 0.00001559
Iteration 119/1000 | Loss: 0.00001559
Iteration 120/1000 | Loss: 0.00001559
Iteration 121/1000 | Loss: 0.00001559
Iteration 122/1000 | Loss: 0.00001558
Iteration 123/1000 | Loss: 0.00001558
Iteration 124/1000 | Loss: 0.00001558
Iteration 125/1000 | Loss: 0.00001558
Iteration 126/1000 | Loss: 0.00001558
Iteration 127/1000 | Loss: 0.00001558
Iteration 128/1000 | Loss: 0.00001557
Iteration 129/1000 | Loss: 0.00001557
Iteration 130/1000 | Loss: 0.00001557
Iteration 131/1000 | Loss: 0.00001556
Iteration 132/1000 | Loss: 0.00001556
Iteration 133/1000 | Loss: 0.00001556
Iteration 134/1000 | Loss: 0.00001556
Iteration 135/1000 | Loss: 0.00001556
Iteration 136/1000 | Loss: 0.00001556
Iteration 137/1000 | Loss: 0.00001556
Iteration 138/1000 | Loss: 0.00001556
Iteration 139/1000 | Loss: 0.00001556
Iteration 140/1000 | Loss: 0.00001556
Iteration 141/1000 | Loss: 0.00001556
Iteration 142/1000 | Loss: 0.00001556
Iteration 143/1000 | Loss: 0.00001555
Iteration 144/1000 | Loss: 0.00001555
Iteration 145/1000 | Loss: 0.00001555
Iteration 146/1000 | Loss: 0.00001555
Iteration 147/1000 | Loss: 0.00001555
Iteration 148/1000 | Loss: 0.00001555
Iteration 149/1000 | Loss: 0.00001555
Iteration 150/1000 | Loss: 0.00001555
Iteration 151/1000 | Loss: 0.00001555
Iteration 152/1000 | Loss: 0.00001555
Iteration 153/1000 | Loss: 0.00001554
Iteration 154/1000 | Loss: 0.00001554
Iteration 155/1000 | Loss: 0.00001554
Iteration 156/1000 | Loss: 0.00001554
Iteration 157/1000 | Loss: 0.00001554
Iteration 158/1000 | Loss: 0.00001554
Iteration 159/1000 | Loss: 0.00001554
Iteration 160/1000 | Loss: 0.00001554
Iteration 161/1000 | Loss: 0.00001554
Iteration 162/1000 | Loss: 0.00001554
Iteration 163/1000 | Loss: 0.00001554
Iteration 164/1000 | Loss: 0.00001554
Iteration 165/1000 | Loss: 0.00001554
Iteration 166/1000 | Loss: 0.00001554
Iteration 167/1000 | Loss: 0.00001553
Iteration 168/1000 | Loss: 0.00001553
Iteration 169/1000 | Loss: 0.00001553
Iteration 170/1000 | Loss: 0.00001553
Iteration 171/1000 | Loss: 0.00001553
Iteration 172/1000 | Loss: 0.00001553
Iteration 173/1000 | Loss: 0.00001552
Iteration 174/1000 | Loss: 0.00001552
Iteration 175/1000 | Loss: 0.00001552
Iteration 176/1000 | Loss: 0.00001552
Iteration 177/1000 | Loss: 0.00001552
Iteration 178/1000 | Loss: 0.00001552
Iteration 179/1000 | Loss: 0.00001552
Iteration 180/1000 | Loss: 0.00001552
Iteration 181/1000 | Loss: 0.00001552
Iteration 182/1000 | Loss: 0.00001551
Iteration 183/1000 | Loss: 0.00001551
Iteration 184/1000 | Loss: 0.00001551
Iteration 185/1000 | Loss: 0.00001551
Iteration 186/1000 | Loss: 0.00001551
Iteration 187/1000 | Loss: 0.00001551
Iteration 188/1000 | Loss: 0.00001550
Iteration 189/1000 | Loss: 0.00001550
Iteration 190/1000 | Loss: 0.00001550
Iteration 191/1000 | Loss: 0.00001550
Iteration 192/1000 | Loss: 0.00001550
Iteration 193/1000 | Loss: 0.00001550
Iteration 194/1000 | Loss: 0.00001550
Iteration 195/1000 | Loss: 0.00001550
Iteration 196/1000 | Loss: 0.00001550
Iteration 197/1000 | Loss: 0.00001550
Iteration 198/1000 | Loss: 0.00001549
Iteration 199/1000 | Loss: 0.00001549
Iteration 200/1000 | Loss: 0.00001549
Iteration 201/1000 | Loss: 0.00001549
Iteration 202/1000 | Loss: 0.00001549
Iteration 203/1000 | Loss: 0.00001549
Iteration 204/1000 | Loss: 0.00001549
Iteration 205/1000 | Loss: 0.00001549
Iteration 206/1000 | Loss: 0.00001549
Iteration 207/1000 | Loss: 0.00001549
Iteration 208/1000 | Loss: 0.00001549
Iteration 209/1000 | Loss: 0.00001549
Iteration 210/1000 | Loss: 0.00001548
Iteration 211/1000 | Loss: 0.00001548
Iteration 212/1000 | Loss: 0.00001548
Iteration 213/1000 | Loss: 0.00001548
Iteration 214/1000 | Loss: 0.00001548
Iteration 215/1000 | Loss: 0.00001548
Iteration 216/1000 | Loss: 0.00001548
Iteration 217/1000 | Loss: 0.00001547
Iteration 218/1000 | Loss: 0.00001547
Iteration 219/1000 | Loss: 0.00001547
Iteration 220/1000 | Loss: 0.00001547
Iteration 221/1000 | Loss: 0.00001547
Iteration 222/1000 | Loss: 0.00001547
Iteration 223/1000 | Loss: 0.00001547
Iteration 224/1000 | Loss: 0.00001547
Iteration 225/1000 | Loss: 0.00001547
Iteration 226/1000 | Loss: 0.00001547
Iteration 227/1000 | Loss: 0.00001547
Iteration 228/1000 | Loss: 0.00001547
Iteration 229/1000 | Loss: 0.00001547
Iteration 230/1000 | Loss: 0.00001547
Iteration 231/1000 | Loss: 0.00001547
Iteration 232/1000 | Loss: 0.00001547
Iteration 233/1000 | Loss: 0.00001547
Iteration 234/1000 | Loss: 0.00001547
Iteration 235/1000 | Loss: 0.00001546
Iteration 236/1000 | Loss: 0.00001546
Iteration 237/1000 | Loss: 0.00001546
Iteration 238/1000 | Loss: 0.00001546
Iteration 239/1000 | Loss: 0.00001546
Iteration 240/1000 | Loss: 0.00001546
Iteration 241/1000 | Loss: 0.00001546
Iteration 242/1000 | Loss: 0.00001546
Iteration 243/1000 | Loss: 0.00001546
Iteration 244/1000 | Loss: 0.00001546
Iteration 245/1000 | Loss: 0.00001546
Iteration 246/1000 | Loss: 0.00001546
Iteration 247/1000 | Loss: 0.00001546
Iteration 248/1000 | Loss: 0.00001546
Iteration 249/1000 | Loss: 0.00001546
Iteration 250/1000 | Loss: 0.00001546
Iteration 251/1000 | Loss: 0.00001545
Iteration 252/1000 | Loss: 0.00001545
Iteration 253/1000 | Loss: 0.00001545
Iteration 254/1000 | Loss: 0.00001545
Iteration 255/1000 | Loss: 0.00001545
Iteration 256/1000 | Loss: 0.00001545
Iteration 257/1000 | Loss: 0.00001545
Iteration 258/1000 | Loss: 0.00001545
Iteration 259/1000 | Loss: 0.00001545
Iteration 260/1000 | Loss: 0.00001545
Iteration 261/1000 | Loss: 0.00001545
Iteration 262/1000 | Loss: 0.00001545
Iteration 263/1000 | Loss: 0.00001545
Iteration 264/1000 | Loss: 0.00001545
Iteration 265/1000 | Loss: 0.00001545
Iteration 266/1000 | Loss: 0.00001545
Iteration 267/1000 | Loss: 0.00001545
Iteration 268/1000 | Loss: 0.00001544
Iteration 269/1000 | Loss: 0.00001544
Iteration 270/1000 | Loss: 0.00001544
Iteration 271/1000 | Loss: 0.00001544
Iteration 272/1000 | Loss: 0.00001544
Iteration 273/1000 | Loss: 0.00001544
Iteration 274/1000 | Loss: 0.00001544
Iteration 275/1000 | Loss: 0.00001544
Iteration 276/1000 | Loss: 0.00001544
Iteration 277/1000 | Loss: 0.00001544
Iteration 278/1000 | Loss: 0.00001544
Iteration 279/1000 | Loss: 0.00001544
Iteration 280/1000 | Loss: 0.00001543
Iteration 281/1000 | Loss: 0.00001543
Iteration 282/1000 | Loss: 0.00001543
Iteration 283/1000 | Loss: 0.00001543
Iteration 284/1000 | Loss: 0.00001543
Iteration 285/1000 | Loss: 0.00001543
Iteration 286/1000 | Loss: 0.00001543
Iteration 287/1000 | Loss: 0.00001543
Iteration 288/1000 | Loss: 0.00001543
Iteration 289/1000 | Loss: 0.00001543
Iteration 290/1000 | Loss: 0.00001543
Iteration 291/1000 | Loss: 0.00001542
Iteration 292/1000 | Loss: 0.00001542
Iteration 293/1000 | Loss: 0.00001542
Iteration 294/1000 | Loss: 0.00001542
Iteration 295/1000 | Loss: 0.00001542
Iteration 296/1000 | Loss: 0.00001542
Iteration 297/1000 | Loss: 0.00001542
Iteration 298/1000 | Loss: 0.00001542
Iteration 299/1000 | Loss: 0.00001542
Iteration 300/1000 | Loss: 0.00001542
Iteration 301/1000 | Loss: 0.00001542
Iteration 302/1000 | Loss: 0.00001542
Iteration 303/1000 | Loss: 0.00001542
Iteration 304/1000 | Loss: 0.00001542
Iteration 305/1000 | Loss: 0.00001542
Iteration 306/1000 | Loss: 0.00001542
Iteration 307/1000 | Loss: 0.00001542
Iteration 308/1000 | Loss: 0.00001542
Iteration 309/1000 | Loss: 0.00001542
Iteration 310/1000 | Loss: 0.00001542
Iteration 311/1000 | Loss: 0.00001542
Iteration 312/1000 | Loss: 0.00001542
Iteration 313/1000 | Loss: 0.00001541
Iteration 314/1000 | Loss: 0.00001541
Iteration 315/1000 | Loss: 0.00001541
Iteration 316/1000 | Loss: 0.00001541
Iteration 317/1000 | Loss: 0.00001541
Iteration 318/1000 | Loss: 0.00001541
Iteration 319/1000 | Loss: 0.00001541
Iteration 320/1000 | Loss: 0.00001541
Iteration 321/1000 | Loss: 0.00001541
Iteration 322/1000 | Loss: 0.00001541
Iteration 323/1000 | Loss: 0.00001541
Iteration 324/1000 | Loss: 0.00001541
Iteration 325/1000 | Loss: 0.00001541
Iteration 326/1000 | Loss: 0.00001541
Iteration 327/1000 | Loss: 0.00001541
Iteration 328/1000 | Loss: 0.00001541
Iteration 329/1000 | Loss: 0.00001541
Iteration 330/1000 | Loss: 0.00001541
Iteration 331/1000 | Loss: 0.00001541
Iteration 332/1000 | Loss: 0.00001541
Iteration 333/1000 | Loss: 0.00001541
Iteration 334/1000 | Loss: 0.00001541
Iteration 335/1000 | Loss: 0.00001540
Iteration 336/1000 | Loss: 0.00001540
Iteration 337/1000 | Loss: 0.00001540
Iteration 338/1000 | Loss: 0.00001540
Iteration 339/1000 | Loss: 0.00001540
Iteration 340/1000 | Loss: 0.00001540
Iteration 341/1000 | Loss: 0.00001540
Iteration 342/1000 | Loss: 0.00001540
Iteration 343/1000 | Loss: 0.00001540
Iteration 344/1000 | Loss: 0.00001540
Iteration 345/1000 | Loss: 0.00001540
Iteration 346/1000 | Loss: 0.00001540
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 346. Stopping optimization.
Last 5 losses: [1.540274388389662e-05, 1.540274388389662e-05, 1.540274388389662e-05, 1.540274388389662e-05, 1.540274388389662e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.540274388389662e-05

Optimization complete. Final v2v error: 3.3162341117858887 mm

Highest mean error: 3.7130095958709717 mm for frame 167

Lowest mean error: 3.053969621658325 mm for frame 119

Saving results

Total time: 1613.070594072342
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1027/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1027.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1027
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00911624
Iteration 2/25 | Loss: 0.00134750
Iteration 3/25 | Loss: 0.00075235
Iteration 4/25 | Loss: 0.00070838
Iteration 5/25 | Loss: 0.00067823
Iteration 6/25 | Loss: 0.00066485
Iteration 7/25 | Loss: 0.00066062
Iteration 8/25 | Loss: 0.00065487
Iteration 9/25 | Loss: 0.00065292
Iteration 10/25 | Loss: 0.00065180
Iteration 11/25 | Loss: 0.00065091
Iteration 12/25 | Loss: 0.00065055
Iteration 13/25 | Loss: 0.00065031
Iteration 14/25 | Loss: 0.00065019
Iteration 15/25 | Loss: 0.00065019
Iteration 16/25 | Loss: 0.00065018
Iteration 17/25 | Loss: 0.00065018
Iteration 18/25 | Loss: 0.00065018
Iteration 19/25 | Loss: 0.00065018
Iteration 20/25 | Loss: 0.00065018
Iteration 21/25 | Loss: 0.00065018
Iteration 22/25 | Loss: 0.00065018
Iteration 23/25 | Loss: 0.00065018
Iteration 24/25 | Loss: 0.00065018
Iteration 25/25 | Loss: 0.00065018

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.15270019
Iteration 2/25 | Loss: 0.00033665
Iteration 3/25 | Loss: 0.00033665
Iteration 4/25 | Loss: 0.00033665
Iteration 5/25 | Loss: 0.00033665
Iteration 6/25 | Loss: 0.00033665
Iteration 7/25 | Loss: 0.00033665
Iteration 8/25 | Loss: 0.00033665
Iteration 9/25 | Loss: 0.00033664
Iteration 10/25 | Loss: 0.00033664
Iteration 11/25 | Loss: 0.00033664
Iteration 12/25 | Loss: 0.00033664
Iteration 13/25 | Loss: 0.00033664
Iteration 14/25 | Loss: 0.00033664
Iteration 15/25 | Loss: 0.00033664
Iteration 16/25 | Loss: 0.00033664
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00033664467628113925, 0.00033664467628113925, 0.00033664467628113925, 0.00033664467628113925, 0.00033664467628113925]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00033664467628113925

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033664
Iteration 2/1000 | Loss: 0.00002508
Iteration 3/1000 | Loss: 0.00001864
Iteration 4/1000 | Loss: 0.00001737
Iteration 5/1000 | Loss: 0.00001670
Iteration 6/1000 | Loss: 0.00001614
Iteration 7/1000 | Loss: 0.00001580
Iteration 8/1000 | Loss: 0.00001556
Iteration 9/1000 | Loss: 0.00001551
Iteration 10/1000 | Loss: 0.00001550
Iteration 11/1000 | Loss: 0.00001543
Iteration 12/1000 | Loss: 0.00001535
Iteration 13/1000 | Loss: 0.00001534
Iteration 14/1000 | Loss: 0.00001530
Iteration 15/1000 | Loss: 0.00001529
Iteration 16/1000 | Loss: 0.00001529
Iteration 17/1000 | Loss: 0.00001529
Iteration 18/1000 | Loss: 0.00001528
Iteration 19/1000 | Loss: 0.00001528
Iteration 20/1000 | Loss: 0.00001528
Iteration 21/1000 | Loss: 0.00001528
Iteration 22/1000 | Loss: 0.00001522
Iteration 23/1000 | Loss: 0.00001522
Iteration 24/1000 | Loss: 0.00001521
Iteration 25/1000 | Loss: 0.00001520
Iteration 26/1000 | Loss: 0.00001517
Iteration 27/1000 | Loss: 0.00001517
Iteration 28/1000 | Loss: 0.00001517
Iteration 29/1000 | Loss: 0.00001516
Iteration 30/1000 | Loss: 0.00001516
Iteration 31/1000 | Loss: 0.00001515
Iteration 32/1000 | Loss: 0.00001515
Iteration 33/1000 | Loss: 0.00001515
Iteration 34/1000 | Loss: 0.00001515
Iteration 35/1000 | Loss: 0.00001514
Iteration 36/1000 | Loss: 0.00001514
Iteration 37/1000 | Loss: 0.00001514
Iteration 38/1000 | Loss: 0.00001514
Iteration 39/1000 | Loss: 0.00001514
Iteration 40/1000 | Loss: 0.00001513
Iteration 41/1000 | Loss: 0.00001513
Iteration 42/1000 | Loss: 0.00001513
Iteration 43/1000 | Loss: 0.00001513
Iteration 44/1000 | Loss: 0.00001513
Iteration 45/1000 | Loss: 0.00001513
Iteration 46/1000 | Loss: 0.00001513
Iteration 47/1000 | Loss: 0.00001512
Iteration 48/1000 | Loss: 0.00001512
Iteration 49/1000 | Loss: 0.00001512
Iteration 50/1000 | Loss: 0.00001512
Iteration 51/1000 | Loss: 0.00001512
Iteration 52/1000 | Loss: 0.00001512
Iteration 53/1000 | Loss: 0.00001512
Iteration 54/1000 | Loss: 0.00001511
Iteration 55/1000 | Loss: 0.00001511
Iteration 56/1000 | Loss: 0.00001511
Iteration 57/1000 | Loss: 0.00001511
Iteration 58/1000 | Loss: 0.00001510
Iteration 59/1000 | Loss: 0.00001510
Iteration 60/1000 | Loss: 0.00001510
Iteration 61/1000 | Loss: 0.00001509
Iteration 62/1000 | Loss: 0.00001509
Iteration 63/1000 | Loss: 0.00001509
Iteration 64/1000 | Loss: 0.00001509
Iteration 65/1000 | Loss: 0.00001509
Iteration 66/1000 | Loss: 0.00001509
Iteration 67/1000 | Loss: 0.00001509
Iteration 68/1000 | Loss: 0.00001508
Iteration 69/1000 | Loss: 0.00001508
Iteration 70/1000 | Loss: 0.00001508
Iteration 71/1000 | Loss: 0.00001508
Iteration 72/1000 | Loss: 0.00001507
Iteration 73/1000 | Loss: 0.00001505
Iteration 74/1000 | Loss: 0.00001505
Iteration 75/1000 | Loss: 0.00001505
Iteration 76/1000 | Loss: 0.00001505
Iteration 77/1000 | Loss: 0.00001505
Iteration 78/1000 | Loss: 0.00001504
Iteration 79/1000 | Loss: 0.00001504
Iteration 80/1000 | Loss: 0.00001504
Iteration 81/1000 | Loss: 0.00001503
Iteration 82/1000 | Loss: 0.00001503
Iteration 83/1000 | Loss: 0.00001503
Iteration 84/1000 | Loss: 0.00001500
Iteration 85/1000 | Loss: 0.00001500
Iteration 86/1000 | Loss: 0.00001500
Iteration 87/1000 | Loss: 0.00001499
Iteration 88/1000 | Loss: 0.00001499
Iteration 89/1000 | Loss: 0.00001498
Iteration 90/1000 | Loss: 0.00001498
Iteration 91/1000 | Loss: 0.00001498
Iteration 92/1000 | Loss: 0.00001497
Iteration 93/1000 | Loss: 0.00001497
Iteration 94/1000 | Loss: 0.00001497
Iteration 95/1000 | Loss: 0.00001496
Iteration 96/1000 | Loss: 0.00001496
Iteration 97/1000 | Loss: 0.00001496
Iteration 98/1000 | Loss: 0.00001496
Iteration 99/1000 | Loss: 0.00001496
Iteration 100/1000 | Loss: 0.00001496
Iteration 101/1000 | Loss: 0.00001496
Iteration 102/1000 | Loss: 0.00001496
Iteration 103/1000 | Loss: 0.00001496
Iteration 104/1000 | Loss: 0.00001496
Iteration 105/1000 | Loss: 0.00001496
Iteration 106/1000 | Loss: 0.00001496
Iteration 107/1000 | Loss: 0.00001495
Iteration 108/1000 | Loss: 0.00001495
Iteration 109/1000 | Loss: 0.00001495
Iteration 110/1000 | Loss: 0.00001495
Iteration 111/1000 | Loss: 0.00001495
Iteration 112/1000 | Loss: 0.00001494
Iteration 113/1000 | Loss: 0.00001494
Iteration 114/1000 | Loss: 0.00001494
Iteration 115/1000 | Loss: 0.00001493
Iteration 116/1000 | Loss: 0.00001493
Iteration 117/1000 | Loss: 0.00001493
Iteration 118/1000 | Loss: 0.00001493
Iteration 119/1000 | Loss: 0.00001493
Iteration 120/1000 | Loss: 0.00001492
Iteration 121/1000 | Loss: 0.00001492
Iteration 122/1000 | Loss: 0.00001492
Iteration 123/1000 | Loss: 0.00001492
Iteration 124/1000 | Loss: 0.00001492
Iteration 125/1000 | Loss: 0.00001492
Iteration 126/1000 | Loss: 0.00001492
Iteration 127/1000 | Loss: 0.00001492
Iteration 128/1000 | Loss: 0.00001491
Iteration 129/1000 | Loss: 0.00001491
Iteration 130/1000 | Loss: 0.00001491
Iteration 131/1000 | Loss: 0.00001491
Iteration 132/1000 | Loss: 0.00001491
Iteration 133/1000 | Loss: 0.00001491
Iteration 134/1000 | Loss: 0.00001490
Iteration 135/1000 | Loss: 0.00001490
Iteration 136/1000 | Loss: 0.00001490
Iteration 137/1000 | Loss: 0.00001490
Iteration 138/1000 | Loss: 0.00001490
Iteration 139/1000 | Loss: 0.00001490
Iteration 140/1000 | Loss: 0.00001490
Iteration 141/1000 | Loss: 0.00001490
Iteration 142/1000 | Loss: 0.00001490
Iteration 143/1000 | Loss: 0.00001490
Iteration 144/1000 | Loss: 0.00001490
Iteration 145/1000 | Loss: 0.00001490
Iteration 146/1000 | Loss: 0.00001490
Iteration 147/1000 | Loss: 0.00001489
Iteration 148/1000 | Loss: 0.00001489
Iteration 149/1000 | Loss: 0.00001489
Iteration 150/1000 | Loss: 0.00001489
Iteration 151/1000 | Loss: 0.00001489
Iteration 152/1000 | Loss: 0.00001488
Iteration 153/1000 | Loss: 0.00001488
Iteration 154/1000 | Loss: 0.00001488
Iteration 155/1000 | Loss: 0.00001488
Iteration 156/1000 | Loss: 0.00001488
Iteration 157/1000 | Loss: 0.00001488
Iteration 158/1000 | Loss: 0.00001487
Iteration 159/1000 | Loss: 0.00001487
Iteration 160/1000 | Loss: 0.00001487
Iteration 161/1000 | Loss: 0.00001487
Iteration 162/1000 | Loss: 0.00001487
Iteration 163/1000 | Loss: 0.00001487
Iteration 164/1000 | Loss: 0.00001487
Iteration 165/1000 | Loss: 0.00001486
Iteration 166/1000 | Loss: 0.00001486
Iteration 167/1000 | Loss: 0.00001486
Iteration 168/1000 | Loss: 0.00001486
Iteration 169/1000 | Loss: 0.00001486
Iteration 170/1000 | Loss: 0.00001486
Iteration 171/1000 | Loss: 0.00001486
Iteration 172/1000 | Loss: 0.00001486
Iteration 173/1000 | Loss: 0.00001486
Iteration 174/1000 | Loss: 0.00001486
Iteration 175/1000 | Loss: 0.00001486
Iteration 176/1000 | Loss: 0.00001486
Iteration 177/1000 | Loss: 0.00001486
Iteration 178/1000 | Loss: 0.00001486
Iteration 179/1000 | Loss: 0.00001485
Iteration 180/1000 | Loss: 0.00001485
Iteration 181/1000 | Loss: 0.00001485
Iteration 182/1000 | Loss: 0.00001485
Iteration 183/1000 | Loss: 0.00001485
Iteration 184/1000 | Loss: 0.00001485
Iteration 185/1000 | Loss: 0.00001485
Iteration 186/1000 | Loss: 0.00001485
Iteration 187/1000 | Loss: 0.00001485
Iteration 188/1000 | Loss: 0.00001485
Iteration 189/1000 | Loss: 0.00001485
Iteration 190/1000 | Loss: 0.00001485
Iteration 191/1000 | Loss: 0.00001485
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 191. Stopping optimization.
Last 5 losses: [1.4854199434921611e-05, 1.4854199434921611e-05, 1.4854199434921611e-05, 1.4854199434921611e-05, 1.4854199434921611e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4854199434921611e-05

Optimization complete. Final v2v error: 3.2615044116973877 mm

Highest mean error: 3.4777348041534424 mm for frame 173

Lowest mean error: 3.0197153091430664 mm for frame 221

Saving results

Total time: 1902.1517717838287
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1070
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00802162
Iteration 2/25 | Loss: 0.00143344
Iteration 3/25 | Loss: 0.00101241
Iteration 4/25 | Loss: 0.00085261
Iteration 5/25 | Loss: 0.00078667
Iteration 6/25 | Loss: 0.00075106
Iteration 7/25 | Loss: 0.00074081
Iteration 8/25 | Loss: 0.00073843
Iteration 9/25 | Loss: 0.00073995
Iteration 10/25 | Loss: 0.00073871
Iteration 11/25 | Loss: 0.00074062
Iteration 12/25 | Loss: 0.00073704
Iteration 13/25 | Loss: 0.00073502
Iteration 14/25 | Loss: 0.00073163
Iteration 15/25 | Loss: 0.00073279
Iteration 16/25 | Loss: 0.00073320
Iteration 17/25 | Loss: 0.00073146
Iteration 18/25 | Loss: 0.00072966
Iteration 19/25 | Loss: 0.00072955
Iteration 20/25 | Loss: 0.00072956
Iteration 21/25 | Loss: 0.00072921
Iteration 22/25 | Loss: 0.00072887
Iteration 23/25 | Loss: 0.00072949
Iteration 24/25 | Loss: 0.00072873
Iteration 25/25 | Loss: 0.00072902

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45964658
Iteration 2/25 | Loss: 0.00039916
Iteration 3/25 | Loss: 0.00039914
Iteration 4/25 | Loss: 0.00039914
Iteration 5/25 | Loss: 0.00039914
Iteration 6/25 | Loss: 0.00039914
Iteration 7/25 | Loss: 0.00039914
Iteration 8/25 | Loss: 0.00039914
Iteration 9/25 | Loss: 0.00039914
Iteration 10/25 | Loss: 0.00039914
Iteration 11/25 | Loss: 0.00039914
Iteration 12/25 | Loss: 0.00039914
Iteration 13/25 | Loss: 0.00039914
Iteration 14/25 | Loss: 0.00039914
Iteration 15/25 | Loss: 0.00039914
Iteration 16/25 | Loss: 0.00039914
Iteration 17/25 | Loss: 0.00039914
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00039913677028380334, 0.00039913677028380334, 0.00039913677028380334, 0.00039913677028380334, 0.00039913677028380334]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00039913677028380334

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039914
Iteration 2/1000 | Loss: 0.00004384
Iteration 3/1000 | Loss: 0.00004132
Iteration 4/1000 | Loss: 0.00006097
Iteration 5/1000 | Loss: 0.00005182
Iteration 6/1000 | Loss: 0.00005795
Iteration 7/1000 | Loss: 0.00004360
Iteration 8/1000 | Loss: 0.00004073
Iteration 9/1000 | Loss: 0.00003672
Iteration 10/1000 | Loss: 0.00004110
Iteration 11/1000 | Loss: 0.00004954
Iteration 12/1000 | Loss: 0.00003608
Iteration 13/1000 | Loss: 0.00004931
Iteration 14/1000 | Loss: 0.00004428
Iteration 15/1000 | Loss: 0.00003911
Iteration 16/1000 | Loss: 0.00003249
Iteration 17/1000 | Loss: 0.00005358
Iteration 18/1000 | Loss: 0.00005539
Iteration 19/1000 | Loss: 0.00005417
Iteration 20/1000 | Loss: 0.00004299
Iteration 21/1000 | Loss: 0.00002637
Iteration 22/1000 | Loss: 0.00003210
Iteration 23/1000 | Loss: 0.00002998
Iteration 24/1000 | Loss: 0.00003542
Iteration 25/1000 | Loss: 0.00002669
Iteration 26/1000 | Loss: 0.00002689
Iteration 27/1000 | Loss: 0.00003284
Iteration 28/1000 | Loss: 0.00003497
Iteration 29/1000 | Loss: 0.00003679
Iteration 30/1000 | Loss: 0.00003549
Iteration 31/1000 | Loss: 0.00003769
Iteration 32/1000 | Loss: 0.00003499
Iteration 33/1000 | Loss: 0.00003392
Iteration 34/1000 | Loss: 0.00003632
Iteration 35/1000 | Loss: 0.00003624
Iteration 36/1000 | Loss: 0.00003248
Iteration 37/1000 | Loss: 0.00003444
Iteration 38/1000 | Loss: 0.00003362
Iteration 39/1000 | Loss: 0.00003533
Iteration 40/1000 | Loss: 0.00003343
Iteration 41/1000 | Loss: 0.00003133
Iteration 42/1000 | Loss: 0.00003631
Iteration 43/1000 | Loss: 0.00003212
Iteration 44/1000 | Loss: 0.00003684
Iteration 45/1000 | Loss: 0.00004054
Iteration 46/1000 | Loss: 0.00003428
Iteration 47/1000 | Loss: 0.00003492
Iteration 48/1000 | Loss: 0.00003356
Iteration 49/1000 | Loss: 0.00003430
Iteration 50/1000 | Loss: 0.00003096
Iteration 51/1000 | Loss: 0.00003640
Iteration 52/1000 | Loss: 0.00003572
Iteration 53/1000 | Loss: 0.00003713
Iteration 54/1000 | Loss: 0.00003680
Iteration 55/1000 | Loss: 0.00004924
Iteration 56/1000 | Loss: 0.00004875
Iteration 57/1000 | Loss: 0.00004465
Iteration 58/1000 | Loss: 0.00003472
Iteration 59/1000 | Loss: 0.00003525
Iteration 60/1000 | Loss: 0.00003348
Iteration 61/1000 | Loss: 0.00003206
Iteration 62/1000 | Loss: 0.00002932
Iteration 63/1000 | Loss: 0.00003389
Iteration 64/1000 | Loss: 0.00003472
Iteration 65/1000 | Loss: 0.00003749
Iteration 66/1000 | Loss: 0.00003274
Iteration 67/1000 | Loss: 0.00003335
Iteration 68/1000 | Loss: 0.00003414
Iteration 69/1000 | Loss: 0.00004212
Iteration 70/1000 | Loss: 0.00003457
Iteration 71/1000 | Loss: 0.00003188
Iteration 72/1000 | Loss: 0.00002868
Iteration 73/1000 | Loss: 0.00003110
Iteration 74/1000 | Loss: 0.00004182
Iteration 75/1000 | Loss: 0.00003092
Iteration 76/1000 | Loss: 0.00003019
Iteration 77/1000 | Loss: 0.00003057
Iteration 78/1000 | Loss: 0.00003269
Iteration 79/1000 | Loss: 0.00003195
Iteration 80/1000 | Loss: 0.00003753
Iteration 81/1000 | Loss: 0.00004089
Iteration 82/1000 | Loss: 0.00003199
Iteration 83/1000 | Loss: 0.00003326
Iteration 84/1000 | Loss: 0.00003291
Iteration 85/1000 | Loss: 0.00003818
Iteration 86/1000 | Loss: 0.00003427
Iteration 87/1000 | Loss: 0.00004518
Iteration 88/1000 | Loss: 0.00004388
Iteration 89/1000 | Loss: 0.00017845
Iteration 90/1000 | Loss: 0.00002567
Iteration 91/1000 | Loss: 0.00002344
Iteration 92/1000 | Loss: 0.00002289
Iteration 93/1000 | Loss: 0.00002252
Iteration 94/1000 | Loss: 0.00002248
Iteration 95/1000 | Loss: 0.00002211
Iteration 96/1000 | Loss: 0.00002178
Iteration 97/1000 | Loss: 0.00002143
Iteration 98/1000 | Loss: 0.00002124
Iteration 99/1000 | Loss: 0.00002098
Iteration 100/1000 | Loss: 0.00002077
Iteration 101/1000 | Loss: 0.00002063
Iteration 102/1000 | Loss: 0.00002056
Iteration 103/1000 | Loss: 0.00002050
Iteration 104/1000 | Loss: 0.00002046
Iteration 105/1000 | Loss: 0.00002045
Iteration 106/1000 | Loss: 0.00002044
Iteration 107/1000 | Loss: 0.00002043
Iteration 108/1000 | Loss: 0.00002041
Iteration 109/1000 | Loss: 0.00002040
Iteration 110/1000 | Loss: 0.00002039
Iteration 111/1000 | Loss: 0.00002039
Iteration 112/1000 | Loss: 0.00002039
Iteration 113/1000 | Loss: 0.00002039
Iteration 114/1000 | Loss: 0.00002039
Iteration 115/1000 | Loss: 0.00002039
Iteration 116/1000 | Loss: 0.00002039
Iteration 117/1000 | Loss: 0.00002038
Iteration 118/1000 | Loss: 0.00002037
Iteration 119/1000 | Loss: 0.00002033
Iteration 120/1000 | Loss: 0.00002031
Iteration 121/1000 | Loss: 0.00002031
Iteration 122/1000 | Loss: 0.00002031
Iteration 123/1000 | Loss: 0.00002031
Iteration 124/1000 | Loss: 0.00002031
Iteration 125/1000 | Loss: 0.00002031
Iteration 126/1000 | Loss: 0.00002030
Iteration 127/1000 | Loss: 0.00002030
Iteration 128/1000 | Loss: 0.00002030
Iteration 129/1000 | Loss: 0.00002029
Iteration 130/1000 | Loss: 0.00002029
Iteration 131/1000 | Loss: 0.00002029
Iteration 132/1000 | Loss: 0.00002028
Iteration 133/1000 | Loss: 0.00002028
Iteration 134/1000 | Loss: 0.00002027
Iteration 135/1000 | Loss: 0.00002027
Iteration 136/1000 | Loss: 0.00002027
Iteration 137/1000 | Loss: 0.00002027
Iteration 138/1000 | Loss: 0.00002027
Iteration 139/1000 | Loss: 0.00002026
Iteration 140/1000 | Loss: 0.00002026
Iteration 141/1000 | Loss: 0.00002026
Iteration 142/1000 | Loss: 0.00002026
Iteration 143/1000 | Loss: 0.00002026
Iteration 144/1000 | Loss: 0.00002025
Iteration 145/1000 | Loss: 0.00002025
Iteration 146/1000 | Loss: 0.00002025
Iteration 147/1000 | Loss: 0.00002025
Iteration 148/1000 | Loss: 0.00002025
Iteration 149/1000 | Loss: 0.00002025
Iteration 150/1000 | Loss: 0.00002025
Iteration 151/1000 | Loss: 0.00002025
Iteration 152/1000 | Loss: 0.00002025
Iteration 153/1000 | Loss: 0.00002025
Iteration 154/1000 | Loss: 0.00002025
Iteration 155/1000 | Loss: 0.00002024
Iteration 156/1000 | Loss: 0.00002024
Iteration 157/1000 | Loss: 0.00002024
Iteration 158/1000 | Loss: 0.00002024
Iteration 159/1000 | Loss: 0.00002024
Iteration 160/1000 | Loss: 0.00002024
Iteration 161/1000 | Loss: 0.00002024
Iteration 162/1000 | Loss: 0.00002024
Iteration 163/1000 | Loss: 0.00002024
Iteration 164/1000 | Loss: 0.00002024
Iteration 165/1000 | Loss: 0.00002024
Iteration 166/1000 | Loss: 0.00002024
Iteration 167/1000 | Loss: 0.00002024
Iteration 168/1000 | Loss: 0.00002023
Iteration 169/1000 | Loss: 0.00002023
Iteration 170/1000 | Loss: 0.00002023
Iteration 171/1000 | Loss: 0.00002023
Iteration 172/1000 | Loss: 0.00002023
Iteration 173/1000 | Loss: 0.00002023
Iteration 174/1000 | Loss: 0.00002023
Iteration 175/1000 | Loss: 0.00002023
Iteration 176/1000 | Loss: 0.00002023
Iteration 177/1000 | Loss: 0.00002023
Iteration 178/1000 | Loss: 0.00002023
Iteration 179/1000 | Loss: 0.00002023
Iteration 180/1000 | Loss: 0.00002023
Iteration 181/1000 | Loss: 0.00002023
Iteration 182/1000 | Loss: 0.00002023
Iteration 183/1000 | Loss: 0.00002023
Iteration 184/1000 | Loss: 0.00002023
Iteration 185/1000 | Loss: 0.00002023
Iteration 186/1000 | Loss: 0.00002023
Iteration 187/1000 | Loss: 0.00002023
Iteration 188/1000 | Loss: 0.00002023
Iteration 189/1000 | Loss: 0.00002023
Iteration 190/1000 | Loss: 0.00002023
Iteration 191/1000 | Loss: 0.00002023
Iteration 192/1000 | Loss: 0.00002023
Iteration 193/1000 | Loss: 0.00002023
Iteration 194/1000 | Loss: 0.00002023
Iteration 195/1000 | Loss: 0.00002023
Iteration 196/1000 | Loss: 0.00002023
Iteration 197/1000 | Loss: 0.00002023
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [2.0225321350153536e-05, 2.0225321350153536e-05, 2.0225321350153536e-05, 2.0225321350153536e-05, 2.0225321350153536e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0225321350153536e-05

Optimization complete. Final v2v error: 3.8670878410339355 mm

Highest mean error: 4.630545616149902 mm for frame 178

Lowest mean error: 3.6310935020446777 mm for frame 9

Saving results

Total time: 6306.149315834045
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1045
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00860312
Iteration 2/25 | Loss: 0.00102133
Iteration 3/25 | Loss: 0.00068801
Iteration 4/25 | Loss: 0.00062324
Iteration 5/25 | Loss: 0.00061481
Iteration 6/25 | Loss: 0.00061272
Iteration 7/25 | Loss: 0.00061105
Iteration 8/25 | Loss: 0.00061116
Iteration 9/25 | Loss: 0.00061098
Iteration 10/25 | Loss: 0.00061109
Iteration 11/25 | Loss: 0.00061065
Iteration 12/25 | Loss: 0.00061065
Iteration 13/25 | Loss: 0.00061065
Iteration 14/25 | Loss: 0.00061065
Iteration 15/25 | Loss: 0.00061065
Iteration 16/25 | Loss: 0.00061065
Iteration 17/25 | Loss: 0.00061065
Iteration 18/25 | Loss: 0.00061065
Iteration 19/25 | Loss: 0.00061065
Iteration 20/25 | Loss: 0.00061065
Iteration 21/25 | Loss: 0.00061065
Iteration 22/25 | Loss: 0.00061065
Iteration 23/25 | Loss: 0.00061064
Iteration 24/25 | Loss: 0.00061064
Iteration 25/25 | Loss: 0.00061064

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.83302188
Iteration 2/25 | Loss: 0.00032200
Iteration 3/25 | Loss: 0.00032200
Iteration 4/25 | Loss: 0.00032200
Iteration 5/25 | Loss: 0.00032200
Iteration 6/25 | Loss: 0.00032200
Iteration 7/25 | Loss: 0.00032200
Iteration 8/25 | Loss: 0.00032200
Iteration 9/25 | Loss: 0.00032200
Iteration 10/25 | Loss: 0.00032200
Iteration 11/25 | Loss: 0.00032200
Iteration 12/25 | Loss: 0.00032200
Iteration 13/25 | Loss: 0.00032200
Iteration 14/25 | Loss: 0.00032200
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0003219983191229403, 0.0003219983191229403, 0.0003219983191229403, 0.0003219983191229403, 0.0003219983191229403]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003219983191229403

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032200
Iteration 2/1000 | Loss: 0.00001977
Iteration 3/1000 | Loss: 0.00001545
Iteration 4/1000 | Loss: 0.00001430
Iteration 5/1000 | Loss: 0.00001347
Iteration 6/1000 | Loss: 0.00001383
Iteration 7/1000 | Loss: 0.00001286
Iteration 8/1000 | Loss: 0.00001280
Iteration 9/1000 | Loss: 0.00001279
Iteration 10/1000 | Loss: 0.00001279
Iteration 11/1000 | Loss: 0.00001278
Iteration 12/1000 | Loss: 0.00001278
Iteration 13/1000 | Loss: 0.00001277
Iteration 14/1000 | Loss: 0.00001329
Iteration 15/1000 | Loss: 0.00001245
Iteration 16/1000 | Loss: 0.00001236
Iteration 17/1000 | Loss: 0.00001236
Iteration 18/1000 | Loss: 0.00001229
Iteration 19/1000 | Loss: 0.00001420
Iteration 20/1000 | Loss: 0.00001420
Iteration 21/1000 | Loss: 0.00001217
Iteration 22/1000 | Loss: 0.00001209
Iteration 23/1000 | Loss: 0.00001209
Iteration 24/1000 | Loss: 0.00001209
Iteration 25/1000 | Loss: 0.00001209
Iteration 26/1000 | Loss: 0.00001209
Iteration 27/1000 | Loss: 0.00001208
Iteration 28/1000 | Loss: 0.00001208
Iteration 29/1000 | Loss: 0.00001208
Iteration 30/1000 | Loss: 0.00001208
Iteration 31/1000 | Loss: 0.00001207
Iteration 32/1000 | Loss: 0.00001207
Iteration 33/1000 | Loss: 0.00001206
Iteration 34/1000 | Loss: 0.00001206
Iteration 35/1000 | Loss: 0.00001205
Iteration 36/1000 | Loss: 0.00001200
Iteration 37/1000 | Loss: 0.00001200
Iteration 38/1000 | Loss: 0.00001200
Iteration 39/1000 | Loss: 0.00001200
Iteration 40/1000 | Loss: 0.00001200
Iteration 41/1000 | Loss: 0.00001200
Iteration 42/1000 | Loss: 0.00001200
Iteration 43/1000 | Loss: 0.00001200
Iteration 44/1000 | Loss: 0.00001200
Iteration 45/1000 | Loss: 0.00001200
Iteration 46/1000 | Loss: 0.00001199
Iteration 47/1000 | Loss: 0.00001199
Iteration 48/1000 | Loss: 0.00001199
Iteration 49/1000 | Loss: 0.00001199
Iteration 50/1000 | Loss: 0.00001198
Iteration 51/1000 | Loss: 0.00001197
Iteration 52/1000 | Loss: 0.00001196
Iteration 53/1000 | Loss: 0.00001195
Iteration 54/1000 | Loss: 0.00001194
Iteration 55/1000 | Loss: 0.00001194
Iteration 56/1000 | Loss: 0.00001194
Iteration 57/1000 | Loss: 0.00001193
Iteration 58/1000 | Loss: 0.00001192
Iteration 59/1000 | Loss: 0.00001192
Iteration 60/1000 | Loss: 0.00001191
Iteration 61/1000 | Loss: 0.00001190
Iteration 62/1000 | Loss: 0.00001190
Iteration 63/1000 | Loss: 0.00001190
Iteration 64/1000 | Loss: 0.00001190
Iteration 65/1000 | Loss: 0.00001189
Iteration 66/1000 | Loss: 0.00001189
Iteration 67/1000 | Loss: 0.00001189
Iteration 68/1000 | Loss: 0.00001188
Iteration 69/1000 | Loss: 0.00001188
Iteration 70/1000 | Loss: 0.00001187
Iteration 71/1000 | Loss: 0.00001187
Iteration 72/1000 | Loss: 0.00001186
Iteration 73/1000 | Loss: 0.00001186
Iteration 74/1000 | Loss: 0.00001185
Iteration 75/1000 | Loss: 0.00001185
Iteration 76/1000 | Loss: 0.00001185
Iteration 77/1000 | Loss: 0.00001184
Iteration 78/1000 | Loss: 0.00001184
Iteration 79/1000 | Loss: 0.00001184
Iteration 80/1000 | Loss: 0.00001184
Iteration 81/1000 | Loss: 0.00001184
Iteration 82/1000 | Loss: 0.00001183
Iteration 83/1000 | Loss: 0.00001183
Iteration 84/1000 | Loss: 0.00001318
Iteration 85/1000 | Loss: 0.00001191
Iteration 86/1000 | Loss: 0.00001181
Iteration 87/1000 | Loss: 0.00001181
Iteration 88/1000 | Loss: 0.00001181
Iteration 89/1000 | Loss: 0.00001180
Iteration 90/1000 | Loss: 0.00001180
Iteration 91/1000 | Loss: 0.00001180
Iteration 92/1000 | Loss: 0.00001180
Iteration 93/1000 | Loss: 0.00001180
Iteration 94/1000 | Loss: 0.00001180
Iteration 95/1000 | Loss: 0.00001180
Iteration 96/1000 | Loss: 0.00001180
Iteration 97/1000 | Loss: 0.00001180
Iteration 98/1000 | Loss: 0.00001180
Iteration 99/1000 | Loss: 0.00001180
Iteration 100/1000 | Loss: 0.00001180
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 100. Stopping optimization.
Last 5 losses: [1.1804896530520637e-05, 1.1804896530520637e-05, 1.1804896530520637e-05, 1.1804896530520637e-05, 1.1804896530520637e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1804896530520637e-05

Optimization complete. Final v2v error: 2.9296114444732666 mm

Highest mean error: 3.1677138805389404 mm for frame 18

Lowest mean error: 2.7366535663604736 mm for frame 1

Saving results

Total time: 1619.726719379425
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_015/1048/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1048.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_015/1048
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01028302
Iteration 2/25 | Loss: 0.00156500
Iteration 3/25 | Loss: 0.00098488
Iteration 4/25 | Loss: 0.00098852
Iteration 5/25 | Loss: 0.00089702
Iteration 6/25 | Loss: 0.00085739
Iteration 7/25 | Loss: 0.00082821
Iteration 8/25 | Loss: 0.00078365
Iteration 9/25 | Loss: 0.00075080
Iteration 10/25 | Loss: 0.00074363
Iteration 11/25 | Loss: 0.00078762
Iteration 12/25 | Loss: 0.00072870
Iteration 13/25 | Loss: 0.00071499
Iteration 14/25 | Loss: 0.00071024
Iteration 15/25 | Loss: 0.00070895
Iteration 16/25 | Loss: 0.00070888
Iteration 17/25 | Loss: 0.00070888
Iteration 18/25 | Loss: 0.00070887
Iteration 19/25 | Loss: 0.00070887
Iteration 20/25 | Loss: 0.00070887
Iteration 21/25 | Loss: 0.00070887
Iteration 22/25 | Loss: 0.00070887
Iteration 23/25 | Loss: 0.00070887
Iteration 24/25 | Loss: 0.00070887
Iteration 25/25 | Loss: 0.00070887

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.01821494
Iteration 2/25 | Loss: 0.00038578
Iteration 3/25 | Loss: 0.00038577
Iteration 4/25 | Loss: 0.00038577
Iteration 5/25 | Loss: 0.00038577
Iteration 6/25 | Loss: 0.00038577
Iteration 7/25 | Loss: 0.00038577
Iteration 8/25 | Loss: 0.00038577
Iteration 9/25 | Loss: 0.00038577
Iteration 10/25 | Loss: 0.00038577
Iteration 11/25 | Loss: 0.00038577
Iteration 12/25 | Loss: 0.00038577
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.00038577127270400524, 0.00038577127270400524, 0.00038577127270400524, 0.00038577127270400524, 0.00038577127270400524]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00038577127270400524

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038577
Iteration 2/1000 | Loss: 0.00004155
Iteration 3/1000 | Loss: 0.00002401
Iteration 4/1000 | Loss: 0.00002153
Iteration 5/1000 | Loss: 0.00002020
Iteration 6/1000 | Loss: 0.00001951
Iteration 7/1000 | Loss: 0.00001909
Iteration 8/1000 | Loss: 0.00001870
Iteration 9/1000 | Loss: 0.00001836
Iteration 10/1000 | Loss: 0.00055480
Iteration 11/1000 | Loss: 0.00002561
Iteration 12/1000 | Loss: 0.00002026
Iteration 13/1000 | Loss: 0.00001841
Iteration 14/1000 | Loss: 0.00001720
Iteration 15/1000 | Loss: 0.00001646
Iteration 16/1000 | Loss: 0.00001588
Iteration 17/1000 | Loss: 0.00001557
Iteration 18/1000 | Loss: 0.00001556
Iteration 19/1000 | Loss: 0.00001550
Iteration 20/1000 | Loss: 0.00001547
Iteration 21/1000 | Loss: 0.00001544
Iteration 22/1000 | Loss: 0.00001544
Iteration 23/1000 | Loss: 0.00001543
Iteration 24/1000 | Loss: 0.00001543
Iteration 25/1000 | Loss: 0.00001542
Iteration 26/1000 | Loss: 0.00001538
Iteration 27/1000 | Loss: 0.00001533
Iteration 28/1000 | Loss: 0.00001531
Iteration 29/1000 | Loss: 0.00001530
Iteration 30/1000 | Loss: 0.00001529
Iteration 31/1000 | Loss: 0.00001528
Iteration 32/1000 | Loss: 0.00001528
Iteration 33/1000 | Loss: 0.00001528
Iteration 34/1000 | Loss: 0.00001527
Iteration 35/1000 | Loss: 0.00001527
Iteration 36/1000 | Loss: 0.00001527
Iteration 37/1000 | Loss: 0.00001527
Iteration 38/1000 | Loss: 0.00001526
Iteration 39/1000 | Loss: 0.00001525
Iteration 40/1000 | Loss: 0.00001525
Iteration 41/1000 | Loss: 0.00001525
Iteration 42/1000 | Loss: 0.00001524
Iteration 43/1000 | Loss: 0.00001524
Iteration 44/1000 | Loss: 0.00001523
Iteration 45/1000 | Loss: 0.00001523
Iteration 46/1000 | Loss: 0.00001523
Iteration 47/1000 | Loss: 0.00001523
Iteration 48/1000 | Loss: 0.00001522
Iteration 49/1000 | Loss: 0.00001522
Iteration 50/1000 | Loss: 0.00001522
Iteration 51/1000 | Loss: 0.00001522
Iteration 52/1000 | Loss: 0.00001522
Iteration 53/1000 | Loss: 0.00001522
Iteration 54/1000 | Loss: 0.00001522
Iteration 55/1000 | Loss: 0.00001522
Iteration 56/1000 | Loss: 0.00001522
Iteration 57/1000 | Loss: 0.00001522
Iteration 58/1000 | Loss: 0.00001522
Iteration 59/1000 | Loss: 0.00001522
Iteration 60/1000 | Loss: 0.00001521
Iteration 61/1000 | Loss: 0.00001521
Iteration 62/1000 | Loss: 0.00001521
Iteration 63/1000 | Loss: 0.00001520
Iteration 64/1000 | Loss: 0.00001520
Iteration 65/1000 | Loss: 0.00001520
Iteration 66/1000 | Loss: 0.00001520
Iteration 67/1000 | Loss: 0.00001519
Iteration 68/1000 | Loss: 0.00001519
Iteration 69/1000 | Loss: 0.00001519
Iteration 70/1000 | Loss: 0.00001519
Iteration 71/1000 | Loss: 0.00001518
Iteration 72/1000 | Loss: 0.00001518
Iteration 73/1000 | Loss: 0.00001518
Iteration 74/1000 | Loss: 0.00001518
Iteration 75/1000 | Loss: 0.00001518
Iteration 76/1000 | Loss: 0.00001518
Iteration 77/1000 | Loss: 0.00001518
Iteration 78/1000 | Loss: 0.00001518
Iteration 79/1000 | Loss: 0.00001517
Iteration 80/1000 | Loss: 0.00001517
Iteration 81/1000 | Loss: 0.00001517
Iteration 82/1000 | Loss: 0.00001517
Iteration 83/1000 | Loss: 0.00001517
Iteration 84/1000 | Loss: 0.00001517
Iteration 85/1000 | Loss: 0.00001517
Iteration 86/1000 | Loss: 0.00001517
Iteration 87/1000 | Loss: 0.00001517
Iteration 88/1000 | Loss: 0.00001517
Iteration 89/1000 | Loss: 0.00001517
Iteration 90/1000 | Loss: 0.00001517
Iteration 91/1000 | Loss: 0.00001517
Iteration 92/1000 | Loss: 0.00001517
Iteration 93/1000 | Loss: 0.00001517
Iteration 94/1000 | Loss: 0.00001517
Iteration 95/1000 | Loss: 0.00001517
Iteration 96/1000 | Loss: 0.00001517
Iteration 97/1000 | Loss: 0.00001517
Iteration 98/1000 | Loss: 0.00001517
Iteration 99/1000 | Loss: 0.00001517
Iteration 100/1000 | Loss: 0.00001517
Iteration 101/1000 | Loss: 0.00001517
Iteration 102/1000 | Loss: 0.00001517
Iteration 103/1000 | Loss: 0.00001517
Iteration 104/1000 | Loss: 0.00001517
Iteration 105/1000 | Loss: 0.00001517
Iteration 106/1000 | Loss: 0.00001517
Iteration 107/1000 | Loss: 0.00001517
Iteration 108/1000 | Loss: 0.00001517
Iteration 109/1000 | Loss: 0.00001517
Iteration 110/1000 | Loss: 0.00001517
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [1.5167679521255195e-05, 1.5167679521255195e-05, 1.5167679521255195e-05, 1.5167679521255195e-05, 1.5167679521255195e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5167679521255195e-05

Optimization complete. Final v2v error: 3.3034472465515137 mm

Highest mean error: 4.575884819030762 mm for frame 73

Lowest mean error: 2.8769192695617676 mm for frame 120

Saving results

Total time: 995.3470418453217
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1030
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00298242
Iteration 2/25 | Loss: 0.00135017
Iteration 3/25 | Loss: 0.00128939
Iteration 4/25 | Loss: 0.00126972
Iteration 5/25 | Loss: 0.00126196
Iteration 6/25 | Loss: 0.00126025
Iteration 7/25 | Loss: 0.00125920
Iteration 8/25 | Loss: 0.00125913
Iteration 9/25 | Loss: 0.00125913
Iteration 10/25 | Loss: 0.00125913
Iteration 11/25 | Loss: 0.00125913
Iteration 12/25 | Loss: 0.00125913
Iteration 13/25 | Loss: 0.00125913
Iteration 14/25 | Loss: 0.00125913
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0012591335689648986, 0.0012591335689648986, 0.0012591335689648986, 0.0012591335689648986, 0.0012591335689648986]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012591335689648986

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25978768
Iteration 2/25 | Loss: 0.00104119
Iteration 3/25 | Loss: 0.00104119
Iteration 4/25 | Loss: 0.00104119
Iteration 5/25 | Loss: 0.00104119
Iteration 6/25 | Loss: 0.00104119
Iteration 7/25 | Loss: 0.00104119
Iteration 8/25 | Loss: 0.00104119
Iteration 9/25 | Loss: 0.00104119
Iteration 10/25 | Loss: 0.00104119
Iteration 11/25 | Loss: 0.00104119
Iteration 12/25 | Loss: 0.00104119
Iteration 13/25 | Loss: 0.00104119
Iteration 14/25 | Loss: 0.00104119
Iteration 15/25 | Loss: 0.00104119
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00104118837043643, 0.00104118837043643, 0.00104118837043643, 0.00104118837043643, 0.00104118837043643]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00104118837043643

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00104119
Iteration 2/1000 | Loss: 0.00004774
Iteration 3/1000 | Loss: 0.00003094
Iteration 4/1000 | Loss: 0.00002434
Iteration 5/1000 | Loss: 0.00002266
Iteration 6/1000 | Loss: 0.00002157
Iteration 7/1000 | Loss: 0.00002096
Iteration 8/1000 | Loss: 0.00002045
Iteration 9/1000 | Loss: 0.00002007
Iteration 10/1000 | Loss: 0.00001979
Iteration 11/1000 | Loss: 0.00001956
Iteration 12/1000 | Loss: 0.00001930
Iteration 13/1000 | Loss: 0.00001927
Iteration 14/1000 | Loss: 0.00001921
Iteration 15/1000 | Loss: 0.00001920
Iteration 16/1000 | Loss: 0.00001920
Iteration 17/1000 | Loss: 0.00001903
Iteration 18/1000 | Loss: 0.00001901
Iteration 19/1000 | Loss: 0.00001900
Iteration 20/1000 | Loss: 0.00001890
Iteration 21/1000 | Loss: 0.00001882
Iteration 22/1000 | Loss: 0.00001878
Iteration 23/1000 | Loss: 0.00001878
Iteration 24/1000 | Loss: 0.00001878
Iteration 25/1000 | Loss: 0.00001877
Iteration 26/1000 | Loss: 0.00001877
Iteration 27/1000 | Loss: 0.00001876
Iteration 28/1000 | Loss: 0.00001876
Iteration 29/1000 | Loss: 0.00001875
Iteration 30/1000 | Loss: 0.00001874
Iteration 31/1000 | Loss: 0.00001874
Iteration 32/1000 | Loss: 0.00001873
Iteration 33/1000 | Loss: 0.00001873
Iteration 34/1000 | Loss: 0.00001873
Iteration 35/1000 | Loss: 0.00001873
Iteration 36/1000 | Loss: 0.00001873
Iteration 37/1000 | Loss: 0.00001873
Iteration 38/1000 | Loss: 0.00001873
Iteration 39/1000 | Loss: 0.00001872
Iteration 40/1000 | Loss: 0.00001868
Iteration 41/1000 | Loss: 0.00001868
Iteration 42/1000 | Loss: 0.00001868
Iteration 43/1000 | Loss: 0.00001868
Iteration 44/1000 | Loss: 0.00001868
Iteration 45/1000 | Loss: 0.00001868
Iteration 46/1000 | Loss: 0.00001868
Iteration 47/1000 | Loss: 0.00001867
Iteration 48/1000 | Loss: 0.00001867
Iteration 49/1000 | Loss: 0.00001867
Iteration 50/1000 | Loss: 0.00001867
Iteration 51/1000 | Loss: 0.00001867
Iteration 52/1000 | Loss: 0.00001867
Iteration 53/1000 | Loss: 0.00001867
Iteration 54/1000 | Loss: 0.00001867
Iteration 55/1000 | Loss: 0.00001867
Iteration 56/1000 | Loss: 0.00001867
Iteration 57/1000 | Loss: 0.00001866
Iteration 58/1000 | Loss: 0.00001866
Iteration 59/1000 | Loss: 0.00001863
Iteration 60/1000 | Loss: 0.00001863
Iteration 61/1000 | Loss: 0.00001862
Iteration 62/1000 | Loss: 0.00001862
Iteration 63/1000 | Loss: 0.00001862
Iteration 64/1000 | Loss: 0.00001861
Iteration 65/1000 | Loss: 0.00001861
Iteration 66/1000 | Loss: 0.00001861
Iteration 67/1000 | Loss: 0.00001861
Iteration 68/1000 | Loss: 0.00001861
Iteration 69/1000 | Loss: 0.00001860
Iteration 70/1000 | Loss: 0.00001860
Iteration 71/1000 | Loss: 0.00001860
Iteration 72/1000 | Loss: 0.00001860
Iteration 73/1000 | Loss: 0.00001860
Iteration 74/1000 | Loss: 0.00001860
Iteration 75/1000 | Loss: 0.00001860
Iteration 76/1000 | Loss: 0.00001860
Iteration 77/1000 | Loss: 0.00001860
Iteration 78/1000 | Loss: 0.00001859
Iteration 79/1000 | Loss: 0.00001859
Iteration 80/1000 | Loss: 0.00001859
Iteration 81/1000 | Loss: 0.00001859
Iteration 82/1000 | Loss: 0.00001859
Iteration 83/1000 | Loss: 0.00001859
Iteration 84/1000 | Loss: 0.00001859
Iteration 85/1000 | Loss: 0.00001858
Iteration 86/1000 | Loss: 0.00001858
Iteration 87/1000 | Loss: 0.00001858
Iteration 88/1000 | Loss: 0.00001858
Iteration 89/1000 | Loss: 0.00001858
Iteration 90/1000 | Loss: 0.00001857
Iteration 91/1000 | Loss: 0.00001857
Iteration 92/1000 | Loss: 0.00001857
Iteration 93/1000 | Loss: 0.00001857
Iteration 94/1000 | Loss: 0.00001856
Iteration 95/1000 | Loss: 0.00001856
Iteration 96/1000 | Loss: 0.00001856
Iteration 97/1000 | Loss: 0.00001856
Iteration 98/1000 | Loss: 0.00001856
Iteration 99/1000 | Loss: 0.00001856
Iteration 100/1000 | Loss: 0.00001856
Iteration 101/1000 | Loss: 0.00001856
Iteration 102/1000 | Loss: 0.00001856
Iteration 103/1000 | Loss: 0.00001856
Iteration 104/1000 | Loss: 0.00001855
Iteration 105/1000 | Loss: 0.00001855
Iteration 106/1000 | Loss: 0.00001855
Iteration 107/1000 | Loss: 0.00001854
Iteration 108/1000 | Loss: 0.00001853
Iteration 109/1000 | Loss: 0.00001853
Iteration 110/1000 | Loss: 0.00001853
Iteration 111/1000 | Loss: 0.00001853
Iteration 112/1000 | Loss: 0.00001853
Iteration 113/1000 | Loss: 0.00001853
Iteration 114/1000 | Loss: 0.00001853
Iteration 115/1000 | Loss: 0.00001853
Iteration 116/1000 | Loss: 0.00001853
Iteration 117/1000 | Loss: 0.00001852
Iteration 118/1000 | Loss: 0.00001852
Iteration 119/1000 | Loss: 0.00001852
Iteration 120/1000 | Loss: 0.00001851
Iteration 121/1000 | Loss: 0.00001851
Iteration 122/1000 | Loss: 0.00001851
Iteration 123/1000 | Loss: 0.00001851
Iteration 124/1000 | Loss: 0.00001851
Iteration 125/1000 | Loss: 0.00001851
Iteration 126/1000 | Loss: 0.00001851
Iteration 127/1000 | Loss: 0.00001851
Iteration 128/1000 | Loss: 0.00001851
Iteration 129/1000 | Loss: 0.00001851
Iteration 130/1000 | Loss: 0.00001851
Iteration 131/1000 | Loss: 0.00001851
Iteration 132/1000 | Loss: 0.00001851
Iteration 133/1000 | Loss: 0.00001851
Iteration 134/1000 | Loss: 0.00001851
Iteration 135/1000 | Loss: 0.00001850
Iteration 136/1000 | Loss: 0.00001850
Iteration 137/1000 | Loss: 0.00001850
Iteration 138/1000 | Loss: 0.00001850
Iteration 139/1000 | Loss: 0.00001850
Iteration 140/1000 | Loss: 0.00001850
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [1.8504986655898392e-05, 1.8504986655898392e-05, 1.8504986655898392e-05, 1.8504986655898392e-05, 1.8504986655898392e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8504986655898392e-05

Optimization complete. Final v2v error: 3.650078296661377 mm

Highest mean error: 4.072338104248047 mm for frame 136

Lowest mean error: 3.405813694000244 mm for frame 154

Saving results

Total time: 1038.0534098148346
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1078
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00845981
Iteration 2/25 | Loss: 0.00169659
Iteration 3/25 | Loss: 0.00141414
Iteration 4/25 | Loss: 0.00138874
Iteration 5/25 | Loss: 0.00137975
Iteration 6/25 | Loss: 0.00137706
Iteration 7/25 | Loss: 0.00137617
Iteration 8/25 | Loss: 0.00137592
Iteration 9/25 | Loss: 0.00137592
Iteration 10/25 | Loss: 0.00137592
Iteration 11/25 | Loss: 0.00137592
Iteration 12/25 | Loss: 0.00137592
Iteration 13/25 | Loss: 0.00137592
Iteration 14/25 | Loss: 0.00137592
Iteration 15/25 | Loss: 0.00137592
Iteration 16/25 | Loss: 0.00137592
Iteration 17/25 | Loss: 0.00137592
Iteration 18/25 | Loss: 0.00137592
Iteration 19/25 | Loss: 0.00137592
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0013759176945313811, 0.0013759176945313811, 0.0013759176945313811, 0.0013759176945313811, 0.0013759176945313811]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013759176945313811

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.20036411
Iteration 2/25 | Loss: 0.00100071
Iteration 3/25 | Loss: 0.00100070
Iteration 4/25 | Loss: 0.00100070
Iteration 5/25 | Loss: 0.00100070
Iteration 6/25 | Loss: 0.00100070
Iteration 7/25 | Loss: 0.00100070
Iteration 8/25 | Loss: 0.00100070
Iteration 9/25 | Loss: 0.00100070
Iteration 10/25 | Loss: 0.00100070
Iteration 11/25 | Loss: 0.00100070
Iteration 12/25 | Loss: 0.00100070
Iteration 13/25 | Loss: 0.00100070
Iteration 14/25 | Loss: 0.00100070
Iteration 15/25 | Loss: 0.00100070
Iteration 16/25 | Loss: 0.00100070
Iteration 17/25 | Loss: 0.00100070
Iteration 18/25 | Loss: 0.00100070
Iteration 19/25 | Loss: 0.00100070
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.001000701915472746, 0.001000701915472746, 0.001000701915472746, 0.001000701915472746, 0.001000701915472746]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001000701915472746

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00100070
Iteration 2/1000 | Loss: 0.00006195
Iteration 3/1000 | Loss: 0.00004045
Iteration 4/1000 | Loss: 0.00003201
Iteration 5/1000 | Loss: 0.00002941
Iteration 6/1000 | Loss: 0.00002764
Iteration 7/1000 | Loss: 0.00002645
Iteration 8/1000 | Loss: 0.00002578
Iteration 9/1000 | Loss: 0.00002522
Iteration 10/1000 | Loss: 0.00002473
Iteration 11/1000 | Loss: 0.00002444
Iteration 12/1000 | Loss: 0.00002417
Iteration 13/1000 | Loss: 0.00002394
Iteration 14/1000 | Loss: 0.00002373
Iteration 15/1000 | Loss: 0.00002360
Iteration 16/1000 | Loss: 0.00002347
Iteration 17/1000 | Loss: 0.00002342
Iteration 18/1000 | Loss: 0.00002329
Iteration 19/1000 | Loss: 0.00002322
Iteration 20/1000 | Loss: 0.00002319
Iteration 21/1000 | Loss: 0.00002317
Iteration 22/1000 | Loss: 0.00002314
Iteration 23/1000 | Loss: 0.00002313
Iteration 24/1000 | Loss: 0.00002310
Iteration 25/1000 | Loss: 0.00002310
Iteration 26/1000 | Loss: 0.00002310
Iteration 27/1000 | Loss: 0.00002310
Iteration 28/1000 | Loss: 0.00002310
Iteration 29/1000 | Loss: 0.00002310
Iteration 30/1000 | Loss: 0.00002310
Iteration 31/1000 | Loss: 0.00002310
Iteration 32/1000 | Loss: 0.00002309
Iteration 33/1000 | Loss: 0.00002309
Iteration 34/1000 | Loss: 0.00002309
Iteration 35/1000 | Loss: 0.00002309
Iteration 36/1000 | Loss: 0.00002309
Iteration 37/1000 | Loss: 0.00002308
Iteration 38/1000 | Loss: 0.00002308
Iteration 39/1000 | Loss: 0.00002305
Iteration 40/1000 | Loss: 0.00002305
Iteration 41/1000 | Loss: 0.00002305
Iteration 42/1000 | Loss: 0.00002305
Iteration 43/1000 | Loss: 0.00002305
Iteration 44/1000 | Loss: 0.00002305
Iteration 45/1000 | Loss: 0.00002304
Iteration 46/1000 | Loss: 0.00002304
Iteration 47/1000 | Loss: 0.00002304
Iteration 48/1000 | Loss: 0.00002304
Iteration 49/1000 | Loss: 0.00002304
Iteration 50/1000 | Loss: 0.00002304
Iteration 51/1000 | Loss: 0.00002302
Iteration 52/1000 | Loss: 0.00002302
Iteration 53/1000 | Loss: 0.00002301
Iteration 54/1000 | Loss: 0.00002301
Iteration 55/1000 | Loss: 0.00002301
Iteration 56/1000 | Loss: 0.00002300
Iteration 57/1000 | Loss: 0.00002300
Iteration 58/1000 | Loss: 0.00002300
Iteration 59/1000 | Loss: 0.00002300
Iteration 60/1000 | Loss: 0.00002299
Iteration 61/1000 | Loss: 0.00002299
Iteration 62/1000 | Loss: 0.00002299
Iteration 63/1000 | Loss: 0.00002298
Iteration 64/1000 | Loss: 0.00002298
Iteration 65/1000 | Loss: 0.00002297
Iteration 66/1000 | Loss: 0.00002297
Iteration 67/1000 | Loss: 0.00002297
Iteration 68/1000 | Loss: 0.00002297
Iteration 69/1000 | Loss: 0.00002297
Iteration 70/1000 | Loss: 0.00002297
Iteration 71/1000 | Loss: 0.00002297
Iteration 72/1000 | Loss: 0.00002297
Iteration 73/1000 | Loss: 0.00002297
Iteration 74/1000 | Loss: 0.00002296
Iteration 75/1000 | Loss: 0.00002296
Iteration 76/1000 | Loss: 0.00002296
Iteration 77/1000 | Loss: 0.00002296
Iteration 78/1000 | Loss: 0.00002295
Iteration 79/1000 | Loss: 0.00002295
Iteration 80/1000 | Loss: 0.00002295
Iteration 81/1000 | Loss: 0.00002295
Iteration 82/1000 | Loss: 0.00002295
Iteration 83/1000 | Loss: 0.00002295
Iteration 84/1000 | Loss: 0.00002295
Iteration 85/1000 | Loss: 0.00002295
Iteration 86/1000 | Loss: 0.00002294
Iteration 87/1000 | Loss: 0.00002294
Iteration 88/1000 | Loss: 0.00002294
Iteration 89/1000 | Loss: 0.00002294
Iteration 90/1000 | Loss: 0.00002294
Iteration 91/1000 | Loss: 0.00002294
Iteration 92/1000 | Loss: 0.00002294
Iteration 93/1000 | Loss: 0.00002294
Iteration 94/1000 | Loss: 0.00002294
Iteration 95/1000 | Loss: 0.00002294
Iteration 96/1000 | Loss: 0.00002294
Iteration 97/1000 | Loss: 0.00002293
Iteration 98/1000 | Loss: 0.00002293
Iteration 99/1000 | Loss: 0.00002293
Iteration 100/1000 | Loss: 0.00002292
Iteration 101/1000 | Loss: 0.00002292
Iteration 102/1000 | Loss: 0.00002292
Iteration 103/1000 | Loss: 0.00002292
Iteration 104/1000 | Loss: 0.00002292
Iteration 105/1000 | Loss: 0.00002292
Iteration 106/1000 | Loss: 0.00002292
Iteration 107/1000 | Loss: 0.00002292
Iteration 108/1000 | Loss: 0.00002291
Iteration 109/1000 | Loss: 0.00002291
Iteration 110/1000 | Loss: 0.00002291
Iteration 111/1000 | Loss: 0.00002291
Iteration 112/1000 | Loss: 0.00002290
Iteration 113/1000 | Loss: 0.00002290
Iteration 114/1000 | Loss: 0.00002290
Iteration 115/1000 | Loss: 0.00002290
Iteration 116/1000 | Loss: 0.00002289
Iteration 117/1000 | Loss: 0.00002289
Iteration 118/1000 | Loss: 0.00002289
Iteration 119/1000 | Loss: 0.00002289
Iteration 120/1000 | Loss: 0.00002289
Iteration 121/1000 | Loss: 0.00002289
Iteration 122/1000 | Loss: 0.00002289
Iteration 123/1000 | Loss: 0.00002289
Iteration 124/1000 | Loss: 0.00002289
Iteration 125/1000 | Loss: 0.00002289
Iteration 126/1000 | Loss: 0.00002289
Iteration 127/1000 | Loss: 0.00002289
Iteration 128/1000 | Loss: 0.00002289
Iteration 129/1000 | Loss: 0.00002289
Iteration 130/1000 | Loss: 0.00002289
Iteration 131/1000 | Loss: 0.00002288
Iteration 132/1000 | Loss: 0.00002288
Iteration 133/1000 | Loss: 0.00002288
Iteration 134/1000 | Loss: 0.00002288
Iteration 135/1000 | Loss: 0.00002287
Iteration 136/1000 | Loss: 0.00002287
Iteration 137/1000 | Loss: 0.00002287
Iteration 138/1000 | Loss: 0.00002287
Iteration 139/1000 | Loss: 0.00002287
Iteration 140/1000 | Loss: 0.00002287
Iteration 141/1000 | Loss: 0.00002287
Iteration 142/1000 | Loss: 0.00002286
Iteration 143/1000 | Loss: 0.00002286
Iteration 144/1000 | Loss: 0.00002286
Iteration 145/1000 | Loss: 0.00002286
Iteration 146/1000 | Loss: 0.00002285
Iteration 147/1000 | Loss: 0.00002285
Iteration 148/1000 | Loss: 0.00002285
Iteration 149/1000 | Loss: 0.00002285
Iteration 150/1000 | Loss: 0.00002285
Iteration 151/1000 | Loss: 0.00002285
Iteration 152/1000 | Loss: 0.00002284
Iteration 153/1000 | Loss: 0.00002284
Iteration 154/1000 | Loss: 0.00002284
Iteration 155/1000 | Loss: 0.00002284
Iteration 156/1000 | Loss: 0.00002284
Iteration 157/1000 | Loss: 0.00002284
Iteration 158/1000 | Loss: 0.00002284
Iteration 159/1000 | Loss: 0.00002284
Iteration 160/1000 | Loss: 0.00002284
Iteration 161/1000 | Loss: 0.00002284
Iteration 162/1000 | Loss: 0.00002284
Iteration 163/1000 | Loss: 0.00002284
Iteration 164/1000 | Loss: 0.00002284
Iteration 165/1000 | Loss: 0.00002283
Iteration 166/1000 | Loss: 0.00002283
Iteration 167/1000 | Loss: 0.00002283
Iteration 168/1000 | Loss: 0.00002283
Iteration 169/1000 | Loss: 0.00002283
Iteration 170/1000 | Loss: 0.00002283
Iteration 171/1000 | Loss: 0.00002283
Iteration 172/1000 | Loss: 0.00002283
Iteration 173/1000 | Loss: 0.00002282
Iteration 174/1000 | Loss: 0.00002282
Iteration 175/1000 | Loss: 0.00002282
Iteration 176/1000 | Loss: 0.00002282
Iteration 177/1000 | Loss: 0.00002281
Iteration 178/1000 | Loss: 0.00002281
Iteration 179/1000 | Loss: 0.00002281
Iteration 180/1000 | Loss: 0.00002281
Iteration 181/1000 | Loss: 0.00002281
Iteration 182/1000 | Loss: 0.00002281
Iteration 183/1000 | Loss: 0.00002280
Iteration 184/1000 | Loss: 0.00002280
Iteration 185/1000 | Loss: 0.00002280
Iteration 186/1000 | Loss: 0.00002280
Iteration 187/1000 | Loss: 0.00002280
Iteration 188/1000 | Loss: 0.00002279
Iteration 189/1000 | Loss: 0.00002279
Iteration 190/1000 | Loss: 0.00002279
Iteration 191/1000 | Loss: 0.00002279
Iteration 192/1000 | Loss: 0.00002279
Iteration 193/1000 | Loss: 0.00002279
Iteration 194/1000 | Loss: 0.00002279
Iteration 195/1000 | Loss: 0.00002279
Iteration 196/1000 | Loss: 0.00002278
Iteration 197/1000 | Loss: 0.00002278
Iteration 198/1000 | Loss: 0.00002278
Iteration 199/1000 | Loss: 0.00002278
Iteration 200/1000 | Loss: 0.00002278
Iteration 201/1000 | Loss: 0.00002278
Iteration 202/1000 | Loss: 0.00002278
Iteration 203/1000 | Loss: 0.00002278
Iteration 204/1000 | Loss: 0.00002278
Iteration 205/1000 | Loss: 0.00002278
Iteration 206/1000 | Loss: 0.00002278
Iteration 207/1000 | Loss: 0.00002278
Iteration 208/1000 | Loss: 0.00002277
Iteration 209/1000 | Loss: 0.00002277
Iteration 210/1000 | Loss: 0.00002277
Iteration 211/1000 | Loss: 0.00002277
Iteration 212/1000 | Loss: 0.00002277
Iteration 213/1000 | Loss: 0.00002277
Iteration 214/1000 | Loss: 0.00002277
Iteration 215/1000 | Loss: 0.00002277
Iteration 216/1000 | Loss: 0.00002277
Iteration 217/1000 | Loss: 0.00002277
Iteration 218/1000 | Loss: 0.00002276
Iteration 219/1000 | Loss: 0.00002276
Iteration 220/1000 | Loss: 0.00002276
Iteration 221/1000 | Loss: 0.00002276
Iteration 222/1000 | Loss: 0.00002276
Iteration 223/1000 | Loss: 0.00002276
Iteration 224/1000 | Loss: 0.00002276
Iteration 225/1000 | Loss: 0.00002276
Iteration 226/1000 | Loss: 0.00002275
Iteration 227/1000 | Loss: 0.00002275
Iteration 228/1000 | Loss: 0.00002275
Iteration 229/1000 | Loss: 0.00002275
Iteration 230/1000 | Loss: 0.00002275
Iteration 231/1000 | Loss: 0.00002275
Iteration 232/1000 | Loss: 0.00002275
Iteration 233/1000 | Loss: 0.00002275
Iteration 234/1000 | Loss: 0.00002275
Iteration 235/1000 | Loss: 0.00002275
Iteration 236/1000 | Loss: 0.00002275
Iteration 237/1000 | Loss: 0.00002275
Iteration 238/1000 | Loss: 0.00002275
Iteration 239/1000 | Loss: 0.00002275
Iteration 240/1000 | Loss: 0.00002275
Iteration 241/1000 | Loss: 0.00002275
Iteration 242/1000 | Loss: 0.00002275
Iteration 243/1000 | Loss: 0.00002275
Iteration 244/1000 | Loss: 0.00002274
Iteration 245/1000 | Loss: 0.00002274
Iteration 246/1000 | Loss: 0.00002274
Iteration 247/1000 | Loss: 0.00002274
Iteration 248/1000 | Loss: 0.00002274
Iteration 249/1000 | Loss: 0.00002274
Iteration 250/1000 | Loss: 0.00002274
Iteration 251/1000 | Loss: 0.00002274
Iteration 252/1000 | Loss: 0.00002274
Iteration 253/1000 | Loss: 0.00002274
Iteration 254/1000 | Loss: 0.00002274
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 254. Stopping optimization.
Last 5 losses: [2.2742307919543236e-05, 2.2742307919543236e-05, 2.2742307919543236e-05, 2.2742307919543236e-05, 2.2742307919543236e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2742307919543236e-05

Optimization complete. Final v2v error: 3.9304280281066895 mm

Highest mean error: 5.820779800415039 mm for frame 91

Lowest mean error: 3.0237467288970947 mm for frame 13

Saving results

Total time: 886.8187770843506
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1013
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01032281
Iteration 2/25 | Loss: 0.01032280
Iteration 3/25 | Loss: 0.01032280
Iteration 4/25 | Loss: 0.01032280
Iteration 5/25 | Loss: 0.01032280
Iteration 6/25 | Loss: 0.01032280
Iteration 7/25 | Loss: 0.01032280
Iteration 8/25 | Loss: 0.01032280
Iteration 9/25 | Loss: 0.01032280
Iteration 10/25 | Loss: 0.01032280
Iteration 11/25 | Loss: 0.01032280
Iteration 12/25 | Loss: 0.01032279
Iteration 13/25 | Loss: 0.01032279
Iteration 14/25 | Loss: 0.01032279
Iteration 15/25 | Loss: 0.01032279
Iteration 16/25 | Loss: 0.01032279
Iteration 17/25 | Loss: 0.01032279
Iteration 18/25 | Loss: 0.01032279
Iteration 19/25 | Loss: 0.01032279
Iteration 20/25 | Loss: 0.01032279
Iteration 21/25 | Loss: 0.01032279
Iteration 22/25 | Loss: 0.01032279
Iteration 23/25 | Loss: 0.01032278
Iteration 24/25 | Loss: 0.01032278
Iteration 25/25 | Loss: 0.01032278

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.72591484
Iteration 2/25 | Loss: 0.08577651
Iteration 3/25 | Loss: 0.08577601
Iteration 4/25 | Loss: 0.08577599
Iteration 5/25 | Loss: 0.08577599
Iteration 6/25 | Loss: 0.08577599
Iteration 7/25 | Loss: 0.08577599
Iteration 8/25 | Loss: 0.08577598
Iteration 9/25 | Loss: 0.08577598
Iteration 10/25 | Loss: 0.08577598
Iteration 11/25 | Loss: 0.08577598
Iteration 12/25 | Loss: 0.08577598
Iteration 13/25 | Loss: 0.08577598
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.08577597886323929, 0.08577597886323929, 0.08577597886323929, 0.08577597886323929, 0.08577597886323929]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.08577597886323929

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.08577598
Iteration 2/1000 | Loss: 0.00772219
Iteration 3/1000 | Loss: 0.00308703
Iteration 4/1000 | Loss: 0.00177162
Iteration 5/1000 | Loss: 0.00144937
Iteration 6/1000 | Loss: 0.00131733
Iteration 7/1000 | Loss: 0.00129794
Iteration 8/1000 | Loss: 0.00048717
Iteration 9/1000 | Loss: 0.00187163
Iteration 10/1000 | Loss: 0.00048529
Iteration 11/1000 | Loss: 0.00023057
Iteration 12/1000 | Loss: 0.00062674
Iteration 13/1000 | Loss: 0.00018722
Iteration 14/1000 | Loss: 0.00015656
Iteration 15/1000 | Loss: 0.00074390
Iteration 16/1000 | Loss: 0.00013166
Iteration 17/1000 | Loss: 0.00016723
Iteration 18/1000 | Loss: 0.00014128
Iteration 19/1000 | Loss: 0.00050210
Iteration 20/1000 | Loss: 0.00461539
Iteration 21/1000 | Loss: 0.00240269
Iteration 22/1000 | Loss: 0.00051670
Iteration 23/1000 | Loss: 0.00037123
Iteration 24/1000 | Loss: 0.00189077
Iteration 25/1000 | Loss: 0.00005893
Iteration 26/1000 | Loss: 0.00005380
Iteration 27/1000 | Loss: 0.00008526
Iteration 28/1000 | Loss: 0.00005018
Iteration 29/1000 | Loss: 0.00004539
Iteration 30/1000 | Loss: 0.00004387
Iteration 31/1000 | Loss: 0.00004230
Iteration 32/1000 | Loss: 0.00025148
Iteration 33/1000 | Loss: 0.00004653
Iteration 34/1000 | Loss: 0.00004003
Iteration 35/1000 | Loss: 0.00003877
Iteration 36/1000 | Loss: 0.00003796
Iteration 37/1000 | Loss: 0.00006189
Iteration 38/1000 | Loss: 0.00038977
Iteration 39/1000 | Loss: 0.00007114
Iteration 40/1000 | Loss: 0.00003915
Iteration 41/1000 | Loss: 0.00003714
Iteration 42/1000 | Loss: 0.00003955
Iteration 43/1000 | Loss: 0.00003784
Iteration 44/1000 | Loss: 0.00003818
Iteration 45/1000 | Loss: 0.00003801
Iteration 46/1000 | Loss: 0.00004088
Iteration 47/1000 | Loss: 0.00003771
Iteration 48/1000 | Loss: 0.00004298
Iteration 49/1000 | Loss: 0.00003828
Iteration 50/1000 | Loss: 0.00003991
Iteration 51/1000 | Loss: 0.00004002
Iteration 52/1000 | Loss: 0.00004100
Iteration 53/1000 | Loss: 0.00004120
Iteration 54/1000 | Loss: 0.00012146
Iteration 55/1000 | Loss: 0.00004297
Iteration 56/1000 | Loss: 0.00003591
Iteration 57/1000 | Loss: 0.00003487
Iteration 58/1000 | Loss: 0.00010541
Iteration 59/1000 | Loss: 0.00003368
Iteration 60/1000 | Loss: 0.00003285
Iteration 61/1000 | Loss: 0.00003250
Iteration 62/1000 | Loss: 0.00003233
Iteration 63/1000 | Loss: 0.00003226
Iteration 64/1000 | Loss: 0.00003205
Iteration 65/1000 | Loss: 0.00025690
Iteration 66/1000 | Loss: 0.00003302
Iteration 67/1000 | Loss: 0.00003192
Iteration 68/1000 | Loss: 0.00003158
Iteration 69/1000 | Loss: 0.00003141
Iteration 70/1000 | Loss: 0.00003130
Iteration 71/1000 | Loss: 0.00003121
Iteration 72/1000 | Loss: 0.00003118
Iteration 73/1000 | Loss: 0.00003117
Iteration 74/1000 | Loss: 0.00003117
Iteration 75/1000 | Loss: 0.00003116
Iteration 76/1000 | Loss: 0.00003116
Iteration 77/1000 | Loss: 0.00003115
Iteration 78/1000 | Loss: 0.00003115
Iteration 79/1000 | Loss: 0.00003115
Iteration 80/1000 | Loss: 0.00003098
Iteration 81/1000 | Loss: 0.00003092
Iteration 82/1000 | Loss: 0.00003091
Iteration 83/1000 | Loss: 0.00003089
Iteration 84/1000 | Loss: 0.00003089
Iteration 85/1000 | Loss: 0.00003089
Iteration 86/1000 | Loss: 0.00003088
Iteration 87/1000 | Loss: 0.00003088
Iteration 88/1000 | Loss: 0.00003088
Iteration 89/1000 | Loss: 0.00003088
Iteration 90/1000 | Loss: 0.00003088
Iteration 91/1000 | Loss: 0.00003088
Iteration 92/1000 | Loss: 0.00003088
Iteration 93/1000 | Loss: 0.00003088
Iteration 94/1000 | Loss: 0.00003088
Iteration 95/1000 | Loss: 0.00003088
Iteration 96/1000 | Loss: 0.00003087
Iteration 97/1000 | Loss: 0.00003087
Iteration 98/1000 | Loss: 0.00003087
Iteration 99/1000 | Loss: 0.00003087
Iteration 100/1000 | Loss: 0.00003087
Iteration 101/1000 | Loss: 0.00003086
Iteration 102/1000 | Loss: 0.00003086
Iteration 103/1000 | Loss: 0.00003086
Iteration 104/1000 | Loss: 0.00003086
Iteration 105/1000 | Loss: 0.00003086
Iteration 106/1000 | Loss: 0.00003086
Iteration 107/1000 | Loss: 0.00003086
Iteration 108/1000 | Loss: 0.00003086
Iteration 109/1000 | Loss: 0.00003086
Iteration 110/1000 | Loss: 0.00003086
Iteration 111/1000 | Loss: 0.00003086
Iteration 112/1000 | Loss: 0.00003086
Iteration 113/1000 | Loss: 0.00003086
Iteration 114/1000 | Loss: 0.00003086
Iteration 115/1000 | Loss: 0.00003086
Iteration 116/1000 | Loss: 0.00003086
Iteration 117/1000 | Loss: 0.00003086
Iteration 118/1000 | Loss: 0.00003086
Iteration 119/1000 | Loss: 0.00003086
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [3.085822027060203e-05, 3.085822027060203e-05, 3.085822027060203e-05, 3.085822027060203e-05, 3.085822027060203e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.085822027060203e-05

Optimization complete. Final v2v error: 4.271674156188965 mm

Highest mean error: 7.078850269317627 mm for frame 39

Lowest mean error: 3.331134796142578 mm for frame 85

Saving results

Total time: 3132.8214836120605
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1020
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00485881
Iteration 2/25 | Loss: 0.00141536
Iteration 3/25 | Loss: 0.00132199
Iteration 4/25 | Loss: 0.00130950
Iteration 5/25 | Loss: 0.00130710
Iteration 6/25 | Loss: 0.00130710
Iteration 7/25 | Loss: 0.00130710
Iteration 8/25 | Loss: 0.00130710
Iteration 9/25 | Loss: 0.00130710
Iteration 10/25 | Loss: 0.00130710
Iteration 11/25 | Loss: 0.00130710
Iteration 12/25 | Loss: 0.00130710
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001307099126279354, 0.001307099126279354, 0.001307099126279354, 0.001307099126279354, 0.001307099126279354]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001307099126279354

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.92969418
Iteration 2/25 | Loss: 0.00089486
Iteration 3/25 | Loss: 0.00089486
Iteration 4/25 | Loss: 0.00089486
Iteration 5/25 | Loss: 0.00089486
Iteration 6/25 | Loss: 0.00089486
Iteration 7/25 | Loss: 0.00089486
Iteration 8/25 | Loss: 0.00089486
Iteration 9/25 | Loss: 0.00089486
Iteration 10/25 | Loss: 0.00089486
Iteration 11/25 | Loss: 0.00089486
Iteration 12/25 | Loss: 0.00089486
Iteration 13/25 | Loss: 0.00089486
Iteration 14/25 | Loss: 0.00089486
Iteration 15/25 | Loss: 0.00089486
Iteration 16/25 | Loss: 0.00089486
Iteration 17/25 | Loss: 0.00089486
Iteration 18/25 | Loss: 0.00089486
Iteration 19/25 | Loss: 0.00089486
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0008948587928898633, 0.0008948587928898633, 0.0008948587928898633, 0.0008948587928898633, 0.0008948587928898633]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008948587928898633

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00089486
Iteration 2/1000 | Loss: 0.00002520
Iteration 3/1000 | Loss: 0.00002027
Iteration 4/1000 | Loss: 0.00001903
Iteration 5/1000 | Loss: 0.00001799
Iteration 6/1000 | Loss: 0.00001745
Iteration 7/1000 | Loss: 0.00001697
Iteration 8/1000 | Loss: 0.00001652
Iteration 9/1000 | Loss: 0.00001629
Iteration 10/1000 | Loss: 0.00001604
Iteration 11/1000 | Loss: 0.00001600
Iteration 12/1000 | Loss: 0.00001580
Iteration 13/1000 | Loss: 0.00001566
Iteration 14/1000 | Loss: 0.00001548
Iteration 15/1000 | Loss: 0.00001539
Iteration 16/1000 | Loss: 0.00001535
Iteration 17/1000 | Loss: 0.00001534
Iteration 18/1000 | Loss: 0.00001527
Iteration 19/1000 | Loss: 0.00001527
Iteration 20/1000 | Loss: 0.00001526
Iteration 21/1000 | Loss: 0.00001526
Iteration 22/1000 | Loss: 0.00001522
Iteration 23/1000 | Loss: 0.00001521
Iteration 24/1000 | Loss: 0.00001521
Iteration 25/1000 | Loss: 0.00001520
Iteration 26/1000 | Loss: 0.00001515
Iteration 27/1000 | Loss: 0.00001515
Iteration 28/1000 | Loss: 0.00001515
Iteration 29/1000 | Loss: 0.00001515
Iteration 30/1000 | Loss: 0.00001514
Iteration 31/1000 | Loss: 0.00001514
Iteration 32/1000 | Loss: 0.00001512
Iteration 33/1000 | Loss: 0.00001511
Iteration 34/1000 | Loss: 0.00001511
Iteration 35/1000 | Loss: 0.00001510
Iteration 36/1000 | Loss: 0.00001509
Iteration 37/1000 | Loss: 0.00001506
Iteration 38/1000 | Loss: 0.00001503
Iteration 39/1000 | Loss: 0.00001503
Iteration 40/1000 | Loss: 0.00001502
Iteration 41/1000 | Loss: 0.00001502
Iteration 42/1000 | Loss: 0.00001501
Iteration 43/1000 | Loss: 0.00001500
Iteration 44/1000 | Loss: 0.00001498
Iteration 45/1000 | Loss: 0.00001498
Iteration 46/1000 | Loss: 0.00001497
Iteration 47/1000 | Loss: 0.00001497
Iteration 48/1000 | Loss: 0.00001497
Iteration 49/1000 | Loss: 0.00001495
Iteration 50/1000 | Loss: 0.00001495
Iteration 51/1000 | Loss: 0.00001493
Iteration 52/1000 | Loss: 0.00001493
Iteration 53/1000 | Loss: 0.00001493
Iteration 54/1000 | Loss: 0.00001492
Iteration 55/1000 | Loss: 0.00001492
Iteration 56/1000 | Loss: 0.00001492
Iteration 57/1000 | Loss: 0.00001492
Iteration 58/1000 | Loss: 0.00001492
Iteration 59/1000 | Loss: 0.00001492
Iteration 60/1000 | Loss: 0.00001492
Iteration 61/1000 | Loss: 0.00001492
Iteration 62/1000 | Loss: 0.00001491
Iteration 63/1000 | Loss: 0.00001491
Iteration 64/1000 | Loss: 0.00001489
Iteration 65/1000 | Loss: 0.00001489
Iteration 66/1000 | Loss: 0.00001489
Iteration 67/1000 | Loss: 0.00001488
Iteration 68/1000 | Loss: 0.00001488
Iteration 69/1000 | Loss: 0.00001488
Iteration 70/1000 | Loss: 0.00001488
Iteration 71/1000 | Loss: 0.00001487
Iteration 72/1000 | Loss: 0.00001487
Iteration 73/1000 | Loss: 0.00001487
Iteration 74/1000 | Loss: 0.00001487
Iteration 75/1000 | Loss: 0.00001487
Iteration 76/1000 | Loss: 0.00001486
Iteration 77/1000 | Loss: 0.00001486
Iteration 78/1000 | Loss: 0.00001486
Iteration 79/1000 | Loss: 0.00001485
Iteration 80/1000 | Loss: 0.00001485
Iteration 81/1000 | Loss: 0.00001485
Iteration 82/1000 | Loss: 0.00001485
Iteration 83/1000 | Loss: 0.00001485
Iteration 84/1000 | Loss: 0.00001485
Iteration 85/1000 | Loss: 0.00001485
Iteration 86/1000 | Loss: 0.00001485
Iteration 87/1000 | Loss: 0.00001485
Iteration 88/1000 | Loss: 0.00001484
Iteration 89/1000 | Loss: 0.00001484
Iteration 90/1000 | Loss: 0.00001484
Iteration 91/1000 | Loss: 0.00001484
Iteration 92/1000 | Loss: 0.00001484
Iteration 93/1000 | Loss: 0.00001484
Iteration 94/1000 | Loss: 0.00001484
Iteration 95/1000 | Loss: 0.00001484
Iteration 96/1000 | Loss: 0.00001484
Iteration 97/1000 | Loss: 0.00001484
Iteration 98/1000 | Loss: 0.00001484
Iteration 99/1000 | Loss: 0.00001484
Iteration 100/1000 | Loss: 0.00001484
Iteration 101/1000 | Loss: 0.00001484
Iteration 102/1000 | Loss: 0.00001484
Iteration 103/1000 | Loss: 0.00001483
Iteration 104/1000 | Loss: 0.00001483
Iteration 105/1000 | Loss: 0.00001483
Iteration 106/1000 | Loss: 0.00001483
Iteration 107/1000 | Loss: 0.00001483
Iteration 108/1000 | Loss: 0.00001483
Iteration 109/1000 | Loss: 0.00001483
Iteration 110/1000 | Loss: 0.00001483
Iteration 111/1000 | Loss: 0.00001483
Iteration 112/1000 | Loss: 0.00001483
Iteration 113/1000 | Loss: 0.00001483
Iteration 114/1000 | Loss: 0.00001483
Iteration 115/1000 | Loss: 0.00001483
Iteration 116/1000 | Loss: 0.00001483
Iteration 117/1000 | Loss: 0.00001483
Iteration 118/1000 | Loss: 0.00001483
Iteration 119/1000 | Loss: 0.00001483
Iteration 120/1000 | Loss: 0.00001483
Iteration 121/1000 | Loss: 0.00001483
Iteration 122/1000 | Loss: 0.00001483
Iteration 123/1000 | Loss: 0.00001483
Iteration 124/1000 | Loss: 0.00001483
Iteration 125/1000 | Loss: 0.00001483
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [1.4829470273980405e-05, 1.4829470273980405e-05, 1.4829470273980405e-05, 1.4829470273980405e-05, 1.4829470273980405e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4829470273980405e-05

Optimization complete. Final v2v error: 3.2853729724884033 mm

Highest mean error: 3.496072292327881 mm for frame 32

Lowest mean error: 3.069103717803955 mm for frame 265

Saving results

Total time: 1396.4177701473236
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1009
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00408656
Iteration 2/25 | Loss: 0.00140730
Iteration 3/25 | Loss: 0.00129642
Iteration 4/25 | Loss: 0.00128310
Iteration 5/25 | Loss: 0.00127983
Iteration 6/25 | Loss: 0.00127887
Iteration 7/25 | Loss: 0.00127886
Iteration 8/25 | Loss: 0.00127886
Iteration 9/25 | Loss: 0.00127886
Iteration 10/25 | Loss: 0.00127886
Iteration 11/25 | Loss: 0.00127886
Iteration 12/25 | Loss: 0.00127886
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001278859213925898, 0.001278859213925898, 0.001278859213925898, 0.001278859213925898, 0.001278859213925898]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001278859213925898

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.38849592
Iteration 2/25 | Loss: 0.00074707
Iteration 3/25 | Loss: 0.00074707
Iteration 4/25 | Loss: 0.00074707
Iteration 5/25 | Loss: 0.00074707
Iteration 6/25 | Loss: 0.00074707
Iteration 7/25 | Loss: 0.00074707
Iteration 8/25 | Loss: 0.00074707
Iteration 9/25 | Loss: 0.00074707
Iteration 10/25 | Loss: 0.00074707
Iteration 11/25 | Loss: 0.00074707
Iteration 12/25 | Loss: 0.00074707
Iteration 13/25 | Loss: 0.00074707
Iteration 14/25 | Loss: 0.00074707
Iteration 15/25 | Loss: 0.00074707
Iteration 16/25 | Loss: 0.00074707
Iteration 17/25 | Loss: 0.00074707
Iteration 18/25 | Loss: 0.00074707
Iteration 19/25 | Loss: 0.00074707
Iteration 20/25 | Loss: 0.00074707
Iteration 21/25 | Loss: 0.00074707
Iteration 22/25 | Loss: 0.00074707
Iteration 23/25 | Loss: 0.00074707
Iteration 24/25 | Loss: 0.00074707
Iteration 25/25 | Loss: 0.00074707

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00074707
Iteration 2/1000 | Loss: 0.00004137
Iteration 3/1000 | Loss: 0.00002660
Iteration 4/1000 | Loss: 0.00002227
Iteration 5/1000 | Loss: 0.00002042
Iteration 6/1000 | Loss: 0.00001959
Iteration 7/1000 | Loss: 0.00001864
Iteration 8/1000 | Loss: 0.00001807
Iteration 9/1000 | Loss: 0.00001757
Iteration 10/1000 | Loss: 0.00001733
Iteration 11/1000 | Loss: 0.00001710
Iteration 12/1000 | Loss: 0.00001694
Iteration 13/1000 | Loss: 0.00001688
Iteration 14/1000 | Loss: 0.00001682
Iteration 15/1000 | Loss: 0.00001682
Iteration 16/1000 | Loss: 0.00001678
Iteration 17/1000 | Loss: 0.00001676
Iteration 18/1000 | Loss: 0.00001672
Iteration 19/1000 | Loss: 0.00001671
Iteration 20/1000 | Loss: 0.00001671
Iteration 21/1000 | Loss: 0.00001669
Iteration 22/1000 | Loss: 0.00001669
Iteration 23/1000 | Loss: 0.00001668
Iteration 24/1000 | Loss: 0.00001668
Iteration 25/1000 | Loss: 0.00001667
Iteration 26/1000 | Loss: 0.00001667
Iteration 27/1000 | Loss: 0.00001667
Iteration 28/1000 | Loss: 0.00001667
Iteration 29/1000 | Loss: 0.00001667
Iteration 30/1000 | Loss: 0.00001666
Iteration 31/1000 | Loss: 0.00001666
Iteration 32/1000 | Loss: 0.00001665
Iteration 33/1000 | Loss: 0.00001665
Iteration 34/1000 | Loss: 0.00001662
Iteration 35/1000 | Loss: 0.00001661
Iteration 36/1000 | Loss: 0.00001661
Iteration 37/1000 | Loss: 0.00001660
Iteration 38/1000 | Loss: 0.00001660
Iteration 39/1000 | Loss: 0.00001659
Iteration 40/1000 | Loss: 0.00001659
Iteration 41/1000 | Loss: 0.00001658
Iteration 42/1000 | Loss: 0.00001658
Iteration 43/1000 | Loss: 0.00001658
Iteration 44/1000 | Loss: 0.00001657
Iteration 45/1000 | Loss: 0.00001657
Iteration 46/1000 | Loss: 0.00001657
Iteration 47/1000 | Loss: 0.00001657
Iteration 48/1000 | Loss: 0.00001657
Iteration 49/1000 | Loss: 0.00001656
Iteration 50/1000 | Loss: 0.00001656
Iteration 51/1000 | Loss: 0.00001656
Iteration 52/1000 | Loss: 0.00001656
Iteration 53/1000 | Loss: 0.00001656
Iteration 54/1000 | Loss: 0.00001656
Iteration 55/1000 | Loss: 0.00001655
Iteration 56/1000 | Loss: 0.00001655
Iteration 57/1000 | Loss: 0.00001654
Iteration 58/1000 | Loss: 0.00001654
Iteration 59/1000 | Loss: 0.00001654
Iteration 60/1000 | Loss: 0.00001654
Iteration 61/1000 | Loss: 0.00001653
Iteration 62/1000 | Loss: 0.00001653
Iteration 63/1000 | Loss: 0.00001653
Iteration 64/1000 | Loss: 0.00001653
Iteration 65/1000 | Loss: 0.00001653
Iteration 66/1000 | Loss: 0.00001653
Iteration 67/1000 | Loss: 0.00001653
Iteration 68/1000 | Loss: 0.00001653
Iteration 69/1000 | Loss: 0.00001653
Iteration 70/1000 | Loss: 0.00001653
Iteration 71/1000 | Loss: 0.00001652
Iteration 72/1000 | Loss: 0.00001652
Iteration 73/1000 | Loss: 0.00001652
Iteration 74/1000 | Loss: 0.00001652
Iteration 75/1000 | Loss: 0.00001652
Iteration 76/1000 | Loss: 0.00001651
Iteration 77/1000 | Loss: 0.00001651
Iteration 78/1000 | Loss: 0.00001651
Iteration 79/1000 | Loss: 0.00001651
Iteration 80/1000 | Loss: 0.00001650
Iteration 81/1000 | Loss: 0.00001650
Iteration 82/1000 | Loss: 0.00001650
Iteration 83/1000 | Loss: 0.00001650
Iteration 84/1000 | Loss: 0.00001649
Iteration 85/1000 | Loss: 0.00001649
Iteration 86/1000 | Loss: 0.00001648
Iteration 87/1000 | Loss: 0.00001648
Iteration 88/1000 | Loss: 0.00001647
Iteration 89/1000 | Loss: 0.00001647
Iteration 90/1000 | Loss: 0.00001646
Iteration 91/1000 | Loss: 0.00001646
Iteration 92/1000 | Loss: 0.00001646
Iteration 93/1000 | Loss: 0.00001645
Iteration 94/1000 | Loss: 0.00001645
Iteration 95/1000 | Loss: 0.00001645
Iteration 96/1000 | Loss: 0.00001645
Iteration 97/1000 | Loss: 0.00001645
Iteration 98/1000 | Loss: 0.00001644
Iteration 99/1000 | Loss: 0.00001644
Iteration 100/1000 | Loss: 0.00001644
Iteration 101/1000 | Loss: 0.00001644
Iteration 102/1000 | Loss: 0.00001643
Iteration 103/1000 | Loss: 0.00001643
Iteration 104/1000 | Loss: 0.00001642
Iteration 105/1000 | Loss: 0.00001642
Iteration 106/1000 | Loss: 0.00001642
Iteration 107/1000 | Loss: 0.00001642
Iteration 108/1000 | Loss: 0.00001642
Iteration 109/1000 | Loss: 0.00001641
Iteration 110/1000 | Loss: 0.00001641
Iteration 111/1000 | Loss: 0.00001640
Iteration 112/1000 | Loss: 0.00001640
Iteration 113/1000 | Loss: 0.00001639
Iteration 114/1000 | Loss: 0.00001639
Iteration 115/1000 | Loss: 0.00001639
Iteration 116/1000 | Loss: 0.00001638
Iteration 117/1000 | Loss: 0.00001638
Iteration 118/1000 | Loss: 0.00001638
Iteration 119/1000 | Loss: 0.00001638
Iteration 120/1000 | Loss: 0.00001638
Iteration 121/1000 | Loss: 0.00001638
Iteration 122/1000 | Loss: 0.00001638
Iteration 123/1000 | Loss: 0.00001638
Iteration 124/1000 | Loss: 0.00001638
Iteration 125/1000 | Loss: 0.00001637
Iteration 126/1000 | Loss: 0.00001637
Iteration 127/1000 | Loss: 0.00001636
Iteration 128/1000 | Loss: 0.00001636
Iteration 129/1000 | Loss: 0.00001636
Iteration 130/1000 | Loss: 0.00001636
Iteration 131/1000 | Loss: 0.00001636
Iteration 132/1000 | Loss: 0.00001636
Iteration 133/1000 | Loss: 0.00001636
Iteration 134/1000 | Loss: 0.00001636
Iteration 135/1000 | Loss: 0.00001635
Iteration 136/1000 | Loss: 0.00001635
Iteration 137/1000 | Loss: 0.00001635
Iteration 138/1000 | Loss: 0.00001635
Iteration 139/1000 | Loss: 0.00001635
Iteration 140/1000 | Loss: 0.00001635
Iteration 141/1000 | Loss: 0.00001635
Iteration 142/1000 | Loss: 0.00001635
Iteration 143/1000 | Loss: 0.00001635
Iteration 144/1000 | Loss: 0.00001635
Iteration 145/1000 | Loss: 0.00001635
Iteration 146/1000 | Loss: 0.00001635
Iteration 147/1000 | Loss: 0.00001635
Iteration 148/1000 | Loss: 0.00001634
Iteration 149/1000 | Loss: 0.00001634
Iteration 150/1000 | Loss: 0.00001634
Iteration 151/1000 | Loss: 0.00001634
Iteration 152/1000 | Loss: 0.00001634
Iteration 153/1000 | Loss: 0.00001634
Iteration 154/1000 | Loss: 0.00001634
Iteration 155/1000 | Loss: 0.00001634
Iteration 156/1000 | Loss: 0.00001633
Iteration 157/1000 | Loss: 0.00001633
Iteration 158/1000 | Loss: 0.00001633
Iteration 159/1000 | Loss: 0.00001633
Iteration 160/1000 | Loss: 0.00001632
Iteration 161/1000 | Loss: 0.00001632
Iteration 162/1000 | Loss: 0.00001632
Iteration 163/1000 | Loss: 0.00001632
Iteration 164/1000 | Loss: 0.00001631
Iteration 165/1000 | Loss: 0.00001631
Iteration 166/1000 | Loss: 0.00001631
Iteration 167/1000 | Loss: 0.00001630
Iteration 168/1000 | Loss: 0.00001630
Iteration 169/1000 | Loss: 0.00001629
Iteration 170/1000 | Loss: 0.00001629
Iteration 171/1000 | Loss: 0.00001629
Iteration 172/1000 | Loss: 0.00001629
Iteration 173/1000 | Loss: 0.00001629
Iteration 174/1000 | Loss: 0.00001629
Iteration 175/1000 | Loss: 0.00001628
Iteration 176/1000 | Loss: 0.00001628
Iteration 177/1000 | Loss: 0.00001628
Iteration 178/1000 | Loss: 0.00001628
Iteration 179/1000 | Loss: 0.00001628
Iteration 180/1000 | Loss: 0.00001627
Iteration 181/1000 | Loss: 0.00001627
Iteration 182/1000 | Loss: 0.00001627
Iteration 183/1000 | Loss: 0.00001627
Iteration 184/1000 | Loss: 0.00001627
Iteration 185/1000 | Loss: 0.00001627
Iteration 186/1000 | Loss: 0.00001627
Iteration 187/1000 | Loss: 0.00001627
Iteration 188/1000 | Loss: 0.00001627
Iteration 189/1000 | Loss: 0.00001627
Iteration 190/1000 | Loss: 0.00001627
Iteration 191/1000 | Loss: 0.00001626
Iteration 192/1000 | Loss: 0.00001626
Iteration 193/1000 | Loss: 0.00001626
Iteration 194/1000 | Loss: 0.00001626
Iteration 195/1000 | Loss: 0.00001625
Iteration 196/1000 | Loss: 0.00001625
Iteration 197/1000 | Loss: 0.00001625
Iteration 198/1000 | Loss: 0.00001625
Iteration 199/1000 | Loss: 0.00001625
Iteration 200/1000 | Loss: 0.00001625
Iteration 201/1000 | Loss: 0.00001625
Iteration 202/1000 | Loss: 0.00001625
Iteration 203/1000 | Loss: 0.00001625
Iteration 204/1000 | Loss: 0.00001624
Iteration 205/1000 | Loss: 0.00001624
Iteration 206/1000 | Loss: 0.00001624
Iteration 207/1000 | Loss: 0.00001624
Iteration 208/1000 | Loss: 0.00001624
Iteration 209/1000 | Loss: 0.00001623
Iteration 210/1000 | Loss: 0.00001623
Iteration 211/1000 | Loss: 0.00001623
Iteration 212/1000 | Loss: 0.00001623
Iteration 213/1000 | Loss: 0.00001623
Iteration 214/1000 | Loss: 0.00001623
Iteration 215/1000 | Loss: 0.00001623
Iteration 216/1000 | Loss: 0.00001623
Iteration 217/1000 | Loss: 0.00001623
Iteration 218/1000 | Loss: 0.00001623
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 218. Stopping optimization.
Last 5 losses: [1.622927993594203e-05, 1.622927993594203e-05, 1.622927993594203e-05, 1.622927993594203e-05, 1.622927993594203e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.622927993594203e-05

Optimization complete. Final v2v error: 3.3674678802490234 mm

Highest mean error: 3.931504249572754 mm for frame 68

Lowest mean error: 3.0547714233398438 mm for frame 135

Saving results

Total time: 901.0714933872223
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1037/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1037.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1037
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00407462
Iteration 2/25 | Loss: 0.00130847
Iteration 3/25 | Loss: 0.00125980
Iteration 4/25 | Loss: 0.00125255
Iteration 5/25 | Loss: 0.00125040
Iteration 6/25 | Loss: 0.00125040
Iteration 7/25 | Loss: 0.00125040
Iteration 8/25 | Loss: 0.00125040
Iteration 9/25 | Loss: 0.00125040
Iteration 10/25 | Loss: 0.00125040
Iteration 11/25 | Loss: 0.00125040
Iteration 12/25 | Loss: 0.00125040
Iteration 13/25 | Loss: 0.00125040
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0012504017213359475, 0.0012504017213359475, 0.0012504017213359475, 0.0012504017213359475, 0.0012504017213359475]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012504017213359475

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.31441450
Iteration 2/25 | Loss: 0.00086365
Iteration 3/25 | Loss: 0.00086365
Iteration 4/25 | Loss: 0.00086365
Iteration 5/25 | Loss: 0.00086365
Iteration 6/25 | Loss: 0.00086365
Iteration 7/25 | Loss: 0.00086365
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 7. Stopping optimization.
Last 5 losses: [0.0008636469137854874, 0.0008636469137854874, 0.0008636469137854874, 0.0008636469137854874, 0.0008636469137854874]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008636469137854874

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00086365
Iteration 2/1000 | Loss: 0.00002826
Iteration 3/1000 | Loss: 0.00001951
Iteration 4/1000 | Loss: 0.00001646
Iteration 5/1000 | Loss: 0.00001540
Iteration 6/1000 | Loss: 0.00001476
Iteration 7/1000 | Loss: 0.00001414
Iteration 8/1000 | Loss: 0.00001386
Iteration 9/1000 | Loss: 0.00001363
Iteration 10/1000 | Loss: 0.00001334
Iteration 11/1000 | Loss: 0.00001317
Iteration 12/1000 | Loss: 0.00001315
Iteration 13/1000 | Loss: 0.00001309
Iteration 14/1000 | Loss: 0.00001303
Iteration 15/1000 | Loss: 0.00001299
Iteration 16/1000 | Loss: 0.00001294
Iteration 17/1000 | Loss: 0.00001290
Iteration 18/1000 | Loss: 0.00001282
Iteration 19/1000 | Loss: 0.00001282
Iteration 20/1000 | Loss: 0.00001282
Iteration 21/1000 | Loss: 0.00001281
Iteration 22/1000 | Loss: 0.00001277
Iteration 23/1000 | Loss: 0.00001276
Iteration 24/1000 | Loss: 0.00001275
Iteration 25/1000 | Loss: 0.00001274
Iteration 26/1000 | Loss: 0.00001273
Iteration 27/1000 | Loss: 0.00001273
Iteration 28/1000 | Loss: 0.00001273
Iteration 29/1000 | Loss: 0.00001273
Iteration 30/1000 | Loss: 0.00001273
Iteration 31/1000 | Loss: 0.00001273
Iteration 32/1000 | Loss: 0.00001272
Iteration 33/1000 | Loss: 0.00001271
Iteration 34/1000 | Loss: 0.00001270
Iteration 35/1000 | Loss: 0.00001267
Iteration 36/1000 | Loss: 0.00001267
Iteration 37/1000 | Loss: 0.00001267
Iteration 38/1000 | Loss: 0.00001266
Iteration 39/1000 | Loss: 0.00001265
Iteration 40/1000 | Loss: 0.00001265
Iteration 41/1000 | Loss: 0.00001265
Iteration 42/1000 | Loss: 0.00001265
Iteration 43/1000 | Loss: 0.00001263
Iteration 44/1000 | Loss: 0.00001259
Iteration 45/1000 | Loss: 0.00001258
Iteration 46/1000 | Loss: 0.00001258
Iteration 47/1000 | Loss: 0.00001257
Iteration 48/1000 | Loss: 0.00001255
Iteration 49/1000 | Loss: 0.00001255
Iteration 50/1000 | Loss: 0.00001254
Iteration 51/1000 | Loss: 0.00001253
Iteration 52/1000 | Loss: 0.00001253
Iteration 53/1000 | Loss: 0.00001252
Iteration 54/1000 | Loss: 0.00001250
Iteration 55/1000 | Loss: 0.00001246
Iteration 56/1000 | Loss: 0.00001245
Iteration 57/1000 | Loss: 0.00001245
Iteration 58/1000 | Loss: 0.00001245
Iteration 59/1000 | Loss: 0.00001244
Iteration 60/1000 | Loss: 0.00001244
Iteration 61/1000 | Loss: 0.00001243
Iteration 62/1000 | Loss: 0.00001243
Iteration 63/1000 | Loss: 0.00001242
Iteration 64/1000 | Loss: 0.00001242
Iteration 65/1000 | Loss: 0.00001240
Iteration 66/1000 | Loss: 0.00001240
Iteration 67/1000 | Loss: 0.00001240
Iteration 68/1000 | Loss: 0.00001240
Iteration 69/1000 | Loss: 0.00001240
Iteration 70/1000 | Loss: 0.00001240
Iteration 71/1000 | Loss: 0.00001240
Iteration 72/1000 | Loss: 0.00001239
Iteration 73/1000 | Loss: 0.00001239
Iteration 74/1000 | Loss: 0.00001239
Iteration 75/1000 | Loss: 0.00001237
Iteration 76/1000 | Loss: 0.00001236
Iteration 77/1000 | Loss: 0.00001236
Iteration 78/1000 | Loss: 0.00001236
Iteration 79/1000 | Loss: 0.00001236
Iteration 80/1000 | Loss: 0.00001236
Iteration 81/1000 | Loss: 0.00001236
Iteration 82/1000 | Loss: 0.00001235
Iteration 83/1000 | Loss: 0.00001235
Iteration 84/1000 | Loss: 0.00001235
Iteration 85/1000 | Loss: 0.00001235
Iteration 86/1000 | Loss: 0.00001235
Iteration 87/1000 | Loss: 0.00001235
Iteration 88/1000 | Loss: 0.00001234
Iteration 89/1000 | Loss: 0.00001234
Iteration 90/1000 | Loss: 0.00001234
Iteration 91/1000 | Loss: 0.00001233
Iteration 92/1000 | Loss: 0.00001233
Iteration 93/1000 | Loss: 0.00001232
Iteration 94/1000 | Loss: 0.00001232
Iteration 95/1000 | Loss: 0.00001232
Iteration 96/1000 | Loss: 0.00001231
Iteration 97/1000 | Loss: 0.00001231
Iteration 98/1000 | Loss: 0.00001231
Iteration 99/1000 | Loss: 0.00001231
Iteration 100/1000 | Loss: 0.00001231
Iteration 101/1000 | Loss: 0.00001231
Iteration 102/1000 | Loss: 0.00001230
Iteration 103/1000 | Loss: 0.00001230
Iteration 104/1000 | Loss: 0.00001230
Iteration 105/1000 | Loss: 0.00001230
Iteration 106/1000 | Loss: 0.00001229
Iteration 107/1000 | Loss: 0.00001229
Iteration 108/1000 | Loss: 0.00001229
Iteration 109/1000 | Loss: 0.00001229
Iteration 110/1000 | Loss: 0.00001229
Iteration 111/1000 | Loss: 0.00001229
Iteration 112/1000 | Loss: 0.00001229
Iteration 113/1000 | Loss: 0.00001229
Iteration 114/1000 | Loss: 0.00001229
Iteration 115/1000 | Loss: 0.00001229
Iteration 116/1000 | Loss: 0.00001229
Iteration 117/1000 | Loss: 0.00001229
Iteration 118/1000 | Loss: 0.00001229
Iteration 119/1000 | Loss: 0.00001229
Iteration 120/1000 | Loss: 0.00001229
Iteration 121/1000 | Loss: 0.00001229
Iteration 122/1000 | Loss: 0.00001228
Iteration 123/1000 | Loss: 0.00001228
Iteration 124/1000 | Loss: 0.00001228
Iteration 125/1000 | Loss: 0.00001228
Iteration 126/1000 | Loss: 0.00001228
Iteration 127/1000 | Loss: 0.00001228
Iteration 128/1000 | Loss: 0.00001228
Iteration 129/1000 | Loss: 0.00001228
Iteration 130/1000 | Loss: 0.00001227
Iteration 131/1000 | Loss: 0.00001227
Iteration 132/1000 | Loss: 0.00001227
Iteration 133/1000 | Loss: 0.00001227
Iteration 134/1000 | Loss: 0.00001227
Iteration 135/1000 | Loss: 0.00001227
Iteration 136/1000 | Loss: 0.00001227
Iteration 137/1000 | Loss: 0.00001227
Iteration 138/1000 | Loss: 0.00001227
Iteration 139/1000 | Loss: 0.00001227
Iteration 140/1000 | Loss: 0.00001227
Iteration 141/1000 | Loss: 0.00001227
Iteration 142/1000 | Loss: 0.00001227
Iteration 143/1000 | Loss: 0.00001226
Iteration 144/1000 | Loss: 0.00001226
Iteration 145/1000 | Loss: 0.00001226
Iteration 146/1000 | Loss: 0.00001226
Iteration 147/1000 | Loss: 0.00001226
Iteration 148/1000 | Loss: 0.00001226
Iteration 149/1000 | Loss: 0.00001226
Iteration 150/1000 | Loss: 0.00001225
Iteration 151/1000 | Loss: 0.00001225
Iteration 152/1000 | Loss: 0.00001225
Iteration 153/1000 | Loss: 0.00001225
Iteration 154/1000 | Loss: 0.00001225
Iteration 155/1000 | Loss: 0.00001225
Iteration 156/1000 | Loss: 0.00001225
Iteration 157/1000 | Loss: 0.00001225
Iteration 158/1000 | Loss: 0.00001225
Iteration 159/1000 | Loss: 0.00001225
Iteration 160/1000 | Loss: 0.00001225
Iteration 161/1000 | Loss: 0.00001225
Iteration 162/1000 | Loss: 0.00001225
Iteration 163/1000 | Loss: 0.00001225
Iteration 164/1000 | Loss: 0.00001225
Iteration 165/1000 | Loss: 0.00001225
Iteration 166/1000 | Loss: 0.00001225
Iteration 167/1000 | Loss: 0.00001225
Iteration 168/1000 | Loss: 0.00001225
Iteration 169/1000 | Loss: 0.00001225
Iteration 170/1000 | Loss: 0.00001225
Iteration 171/1000 | Loss: 0.00001225
Iteration 172/1000 | Loss: 0.00001225
Iteration 173/1000 | Loss: 0.00001225
Iteration 174/1000 | Loss: 0.00001225
Iteration 175/1000 | Loss: 0.00001225
Iteration 176/1000 | Loss: 0.00001225
Iteration 177/1000 | Loss: 0.00001225
Iteration 178/1000 | Loss: 0.00001225
Iteration 179/1000 | Loss: 0.00001225
Iteration 180/1000 | Loss: 0.00001225
Iteration 181/1000 | Loss: 0.00001225
Iteration 182/1000 | Loss: 0.00001225
Iteration 183/1000 | Loss: 0.00001225
Iteration 184/1000 | Loss: 0.00001225
Iteration 185/1000 | Loss: 0.00001225
Iteration 186/1000 | Loss: 0.00001225
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 186. Stopping optimization.
Last 5 losses: [1.2252407032065094e-05, 1.2252407032065094e-05, 1.2252407032065094e-05, 1.2252407032065094e-05, 1.2252407032065094e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2252407032065094e-05

Optimization complete. Final v2v error: 3.010559558868408 mm

Highest mean error: 3.231722354888916 mm for frame 102

Lowest mean error: 2.8498737812042236 mm for frame 69

Saving results

Total time: 908.7381682395935
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1075/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1075.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1075
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00773538
Iteration 2/25 | Loss: 0.00160495
Iteration 3/25 | Loss: 0.00144996
Iteration 4/25 | Loss: 0.00141731
Iteration 5/25 | Loss: 0.00141347
Iteration 6/25 | Loss: 0.00139280
Iteration 7/25 | Loss: 0.00139004
Iteration 8/25 | Loss: 0.00138662
Iteration 9/25 | Loss: 0.00138529
Iteration 10/25 | Loss: 0.00137996
Iteration 11/25 | Loss: 0.00137862
Iteration 12/25 | Loss: 0.00137822
Iteration 13/25 | Loss: 0.00137807
Iteration 14/25 | Loss: 0.00137797
Iteration 15/25 | Loss: 0.00137791
Iteration 16/25 | Loss: 0.00137791
Iteration 17/25 | Loss: 0.00137790
Iteration 18/25 | Loss: 0.00137789
Iteration 19/25 | Loss: 0.00137789
Iteration 20/25 | Loss: 0.00137789
Iteration 21/25 | Loss: 0.00137788
Iteration 22/25 | Loss: 0.00137788
Iteration 23/25 | Loss: 0.00137788
Iteration 24/25 | Loss: 0.00137788
Iteration 25/25 | Loss: 0.00137788

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39038301
Iteration 2/25 | Loss: 0.00152690
Iteration 3/25 | Loss: 0.00152687
Iteration 4/25 | Loss: 0.00152687
Iteration 5/25 | Loss: 0.00152687
Iteration 6/25 | Loss: 0.00152686
Iteration 7/25 | Loss: 0.00152686
Iteration 8/25 | Loss: 0.00152686
Iteration 9/25 | Loss: 0.00152686
Iteration 10/25 | Loss: 0.00152686
Iteration 11/25 | Loss: 0.00152686
Iteration 12/25 | Loss: 0.00152686
Iteration 13/25 | Loss: 0.00152686
Iteration 14/25 | Loss: 0.00152686
Iteration 15/25 | Loss: 0.00152686
Iteration 16/25 | Loss: 0.00152686
Iteration 17/25 | Loss: 0.00152686
Iteration 18/25 | Loss: 0.00152686
Iteration 19/25 | Loss: 0.00152686
Iteration 20/25 | Loss: 0.00152686
Iteration 21/25 | Loss: 0.00152686
Iteration 22/25 | Loss: 0.00152686
Iteration 23/25 | Loss: 0.00152686
Iteration 24/25 | Loss: 0.00152686
Iteration 25/25 | Loss: 0.00152686

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00152686
Iteration 2/1000 | Loss: 0.00023600
Iteration 3/1000 | Loss: 0.00020431
Iteration 4/1000 | Loss: 0.00012277
Iteration 5/1000 | Loss: 0.00008373
Iteration 6/1000 | Loss: 0.00008905
Iteration 7/1000 | Loss: 0.00005797
Iteration 8/1000 | Loss: 0.00005262
Iteration 9/1000 | Loss: 0.00036237
Iteration 10/1000 | Loss: 0.00015067
Iteration 11/1000 | Loss: 0.00033083
Iteration 12/1000 | Loss: 0.00021858
Iteration 13/1000 | Loss: 0.00034802
Iteration 14/1000 | Loss: 0.00025641
Iteration 15/1000 | Loss: 0.00016618
Iteration 16/1000 | Loss: 0.00009007
Iteration 17/1000 | Loss: 0.00013450
Iteration 18/1000 | Loss: 0.00013210
Iteration 19/1000 | Loss: 0.00012810
Iteration 20/1000 | Loss: 0.00004712
Iteration 21/1000 | Loss: 0.00012290
Iteration 22/1000 | Loss: 0.00010097
Iteration 23/1000 | Loss: 0.00004134
Iteration 24/1000 | Loss: 0.00019211
Iteration 25/1000 | Loss: 0.00023422
Iteration 26/1000 | Loss: 0.00005761
Iteration 27/1000 | Loss: 0.00004454
Iteration 28/1000 | Loss: 0.00004073
Iteration 29/1000 | Loss: 0.00010293
Iteration 30/1000 | Loss: 0.00004152
Iteration 31/1000 | Loss: 0.00011193
Iteration 32/1000 | Loss: 0.00030777
Iteration 33/1000 | Loss: 0.00020847
Iteration 34/1000 | Loss: 0.00027211
Iteration 35/1000 | Loss: 0.00005752
Iteration 36/1000 | Loss: 0.00004171
Iteration 37/1000 | Loss: 0.00003816
Iteration 38/1000 | Loss: 0.00003705
Iteration 39/1000 | Loss: 0.00003640
Iteration 40/1000 | Loss: 0.00003987
Iteration 41/1000 | Loss: 0.00016275
Iteration 42/1000 | Loss: 0.00004558
Iteration 43/1000 | Loss: 0.00003834
Iteration 44/1000 | Loss: 0.00003546
Iteration 45/1000 | Loss: 0.00003416
Iteration 46/1000 | Loss: 0.00003373
Iteration 47/1000 | Loss: 0.00003344
Iteration 48/1000 | Loss: 0.00003319
Iteration 49/1000 | Loss: 0.00003311
Iteration 50/1000 | Loss: 0.00003293
Iteration 51/1000 | Loss: 0.00003264
Iteration 52/1000 | Loss: 0.00003239
Iteration 53/1000 | Loss: 0.00015044
Iteration 54/1000 | Loss: 0.00060619
Iteration 55/1000 | Loss: 0.00021932
Iteration 56/1000 | Loss: 0.00019713
Iteration 57/1000 | Loss: 0.00022749
Iteration 58/1000 | Loss: 0.00003617
Iteration 59/1000 | Loss: 0.00003417
Iteration 60/1000 | Loss: 0.00003313
Iteration 61/1000 | Loss: 0.00003185
Iteration 62/1000 | Loss: 0.00003096
Iteration 63/1000 | Loss: 0.00003055
Iteration 64/1000 | Loss: 0.00003026
Iteration 65/1000 | Loss: 0.00003024
Iteration 66/1000 | Loss: 0.00003018
Iteration 67/1000 | Loss: 0.00003018
Iteration 68/1000 | Loss: 0.00003018
Iteration 69/1000 | Loss: 0.00003017
Iteration 70/1000 | Loss: 0.00003017
Iteration 71/1000 | Loss: 0.00003017
Iteration 72/1000 | Loss: 0.00003017
Iteration 73/1000 | Loss: 0.00003017
Iteration 74/1000 | Loss: 0.00003017
Iteration 75/1000 | Loss: 0.00003017
Iteration 76/1000 | Loss: 0.00003012
Iteration 77/1000 | Loss: 0.00003010
Iteration 78/1000 | Loss: 0.00003009
Iteration 79/1000 | Loss: 0.00003009
Iteration 80/1000 | Loss: 0.00003008
Iteration 81/1000 | Loss: 0.00003008
Iteration 82/1000 | Loss: 0.00003006
Iteration 83/1000 | Loss: 0.00003006
Iteration 84/1000 | Loss: 0.00003006
Iteration 85/1000 | Loss: 0.00003006
Iteration 86/1000 | Loss: 0.00003006
Iteration 87/1000 | Loss: 0.00003006
Iteration 88/1000 | Loss: 0.00003005
Iteration 89/1000 | Loss: 0.00003004
Iteration 90/1000 | Loss: 0.00003004
Iteration 91/1000 | Loss: 0.00003004
Iteration 92/1000 | Loss: 0.00003004
Iteration 93/1000 | Loss: 0.00003004
Iteration 94/1000 | Loss: 0.00003004
Iteration 95/1000 | Loss: 0.00003003
Iteration 96/1000 | Loss: 0.00003003
Iteration 97/1000 | Loss: 0.00003003
Iteration 98/1000 | Loss: 0.00003003
Iteration 99/1000 | Loss: 0.00003002
Iteration 100/1000 | Loss: 0.00003002
Iteration 101/1000 | Loss: 0.00003002
Iteration 102/1000 | Loss: 0.00003002
Iteration 103/1000 | Loss: 0.00003002
Iteration 104/1000 | Loss: 0.00003001
Iteration 105/1000 | Loss: 0.00003001
Iteration 106/1000 | Loss: 0.00003001
Iteration 107/1000 | Loss: 0.00003000
Iteration 108/1000 | Loss: 0.00003000
Iteration 109/1000 | Loss: 0.00003000
Iteration 110/1000 | Loss: 0.00003000
Iteration 111/1000 | Loss: 0.00003000
Iteration 112/1000 | Loss: 0.00003000
Iteration 113/1000 | Loss: 0.00003000
Iteration 114/1000 | Loss: 0.00003000
Iteration 115/1000 | Loss: 0.00002999
Iteration 116/1000 | Loss: 0.00002999
Iteration 117/1000 | Loss: 0.00002999
Iteration 118/1000 | Loss: 0.00002998
Iteration 119/1000 | Loss: 0.00002998
Iteration 120/1000 | Loss: 0.00002998
Iteration 121/1000 | Loss: 0.00002997
Iteration 122/1000 | Loss: 0.00002997
Iteration 123/1000 | Loss: 0.00002997
Iteration 124/1000 | Loss: 0.00002997
Iteration 125/1000 | Loss: 0.00002996
Iteration 126/1000 | Loss: 0.00002996
Iteration 127/1000 | Loss: 0.00002996
Iteration 128/1000 | Loss: 0.00002996
Iteration 129/1000 | Loss: 0.00002995
Iteration 130/1000 | Loss: 0.00002995
Iteration 131/1000 | Loss: 0.00002995
Iteration 132/1000 | Loss: 0.00002995
Iteration 133/1000 | Loss: 0.00002994
Iteration 134/1000 | Loss: 0.00002994
Iteration 135/1000 | Loss: 0.00002993
Iteration 136/1000 | Loss: 0.00002992
Iteration 137/1000 | Loss: 0.00002991
Iteration 138/1000 | Loss: 0.00002991
Iteration 139/1000 | Loss: 0.00002991
Iteration 140/1000 | Loss: 0.00002990
Iteration 141/1000 | Loss: 0.00002990
Iteration 142/1000 | Loss: 0.00002990
Iteration 143/1000 | Loss: 0.00002990
Iteration 144/1000 | Loss: 0.00002989
Iteration 145/1000 | Loss: 0.00002989
Iteration 146/1000 | Loss: 0.00002989
Iteration 147/1000 | Loss: 0.00002988
Iteration 148/1000 | Loss: 0.00002988
Iteration 149/1000 | Loss: 0.00002988
Iteration 150/1000 | Loss: 0.00002988
Iteration 151/1000 | Loss: 0.00002987
Iteration 152/1000 | Loss: 0.00002987
Iteration 153/1000 | Loss: 0.00002987
Iteration 154/1000 | Loss: 0.00002987
Iteration 155/1000 | Loss: 0.00002987
Iteration 156/1000 | Loss: 0.00002987
Iteration 157/1000 | Loss: 0.00002986
Iteration 158/1000 | Loss: 0.00002986
Iteration 159/1000 | Loss: 0.00002986
Iteration 160/1000 | Loss: 0.00002986
Iteration 161/1000 | Loss: 0.00002986
Iteration 162/1000 | Loss: 0.00002986
Iteration 163/1000 | Loss: 0.00002986
Iteration 164/1000 | Loss: 0.00002986
Iteration 165/1000 | Loss: 0.00002986
Iteration 166/1000 | Loss: 0.00002985
Iteration 167/1000 | Loss: 0.00002985
Iteration 168/1000 | Loss: 0.00002985
Iteration 169/1000 | Loss: 0.00002985
Iteration 170/1000 | Loss: 0.00002985
Iteration 171/1000 | Loss: 0.00002985
Iteration 172/1000 | Loss: 0.00002985
Iteration 173/1000 | Loss: 0.00002984
Iteration 174/1000 | Loss: 0.00002984
Iteration 175/1000 | Loss: 0.00002984
Iteration 176/1000 | Loss: 0.00002984
Iteration 177/1000 | Loss: 0.00002984
Iteration 178/1000 | Loss: 0.00002984
Iteration 179/1000 | Loss: 0.00002983
Iteration 180/1000 | Loss: 0.00002983
Iteration 181/1000 | Loss: 0.00002983
Iteration 182/1000 | Loss: 0.00002983
Iteration 183/1000 | Loss: 0.00002983
Iteration 184/1000 | Loss: 0.00002983
Iteration 185/1000 | Loss: 0.00002982
Iteration 186/1000 | Loss: 0.00002982
Iteration 187/1000 | Loss: 0.00002982
Iteration 188/1000 | Loss: 0.00002982
Iteration 189/1000 | Loss: 0.00002982
Iteration 190/1000 | Loss: 0.00002981
Iteration 191/1000 | Loss: 0.00002981
Iteration 192/1000 | Loss: 0.00002981
Iteration 193/1000 | Loss: 0.00002980
Iteration 194/1000 | Loss: 0.00002980
Iteration 195/1000 | Loss: 0.00002980
Iteration 196/1000 | Loss: 0.00002980
Iteration 197/1000 | Loss: 0.00002979
Iteration 198/1000 | Loss: 0.00002979
Iteration 199/1000 | Loss: 0.00002979
Iteration 200/1000 | Loss: 0.00002979
Iteration 201/1000 | Loss: 0.00002979
Iteration 202/1000 | Loss: 0.00002978
Iteration 203/1000 | Loss: 0.00002978
Iteration 204/1000 | Loss: 0.00002978
Iteration 205/1000 | Loss: 0.00002978
Iteration 206/1000 | Loss: 0.00002978
Iteration 207/1000 | Loss: 0.00002978
Iteration 208/1000 | Loss: 0.00002978
Iteration 209/1000 | Loss: 0.00002978
Iteration 210/1000 | Loss: 0.00002977
Iteration 211/1000 | Loss: 0.00002977
Iteration 212/1000 | Loss: 0.00002977
Iteration 213/1000 | Loss: 0.00002977
Iteration 214/1000 | Loss: 0.00002977
Iteration 215/1000 | Loss: 0.00002977
Iteration 216/1000 | Loss: 0.00002977
Iteration 217/1000 | Loss: 0.00002977
Iteration 218/1000 | Loss: 0.00002977
Iteration 219/1000 | Loss: 0.00002977
Iteration 220/1000 | Loss: 0.00002977
Iteration 221/1000 | Loss: 0.00002977
Iteration 222/1000 | Loss: 0.00002977
Iteration 223/1000 | Loss: 0.00002977
Iteration 224/1000 | Loss: 0.00002977
Iteration 225/1000 | Loss: 0.00002977
Iteration 226/1000 | Loss: 0.00002977
Iteration 227/1000 | Loss: 0.00002977
Iteration 228/1000 | Loss: 0.00002977
Iteration 229/1000 | Loss: 0.00002977
Iteration 230/1000 | Loss: 0.00002977
Iteration 231/1000 | Loss: 0.00002976
Iteration 232/1000 | Loss: 0.00002976
Iteration 233/1000 | Loss: 0.00002976
Iteration 234/1000 | Loss: 0.00002976
Iteration 235/1000 | Loss: 0.00002976
Iteration 236/1000 | Loss: 0.00002976
Iteration 237/1000 | Loss: 0.00002976
Iteration 238/1000 | Loss: 0.00002976
Iteration 239/1000 | Loss: 0.00002976
Iteration 240/1000 | Loss: 0.00002976
Iteration 241/1000 | Loss: 0.00002976
Iteration 242/1000 | Loss: 0.00002976
Iteration 243/1000 | Loss: 0.00002976
Iteration 244/1000 | Loss: 0.00002976
Iteration 245/1000 | Loss: 0.00002976
Iteration 246/1000 | Loss: 0.00002976
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 246. Stopping optimization.
Last 5 losses: [2.976397445308976e-05, 2.976397445308976e-05, 2.976397445308976e-05, 2.976397445308976e-05, 2.976397445308976e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.976397445308976e-05

Optimization complete. Final v2v error: 4.056425094604492 mm

Highest mean error: 11.352898597717285 mm for frame 25

Lowest mean error: 3.3137292861938477 mm for frame 210

Saving results

Total time: 4321.87103676796
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1051/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1051.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1051
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00894391
Iteration 2/25 | Loss: 0.00164569
Iteration 3/25 | Loss: 0.00144176
Iteration 4/25 | Loss: 0.00141833
Iteration 5/25 | Loss: 0.00141100
Iteration 6/25 | Loss: 0.00140931
Iteration 7/25 | Loss: 0.00140931
Iteration 8/25 | Loss: 0.00140931
Iteration 9/25 | Loss: 0.00140931
Iteration 10/25 | Loss: 0.00140931
Iteration 11/25 | Loss: 0.00140931
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0014093092177063227, 0.0014093092177063227, 0.0014093092177063227, 0.0014093092177063227, 0.0014093092177063227]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014093092177063227

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.09225965
Iteration 2/25 | Loss: 0.00090154
Iteration 3/25 | Loss: 0.00090152
Iteration 4/25 | Loss: 0.00090152
Iteration 5/25 | Loss: 0.00090152
Iteration 6/25 | Loss: 0.00090152
Iteration 7/25 | Loss: 0.00090152
Iteration 8/25 | Loss: 0.00090152
Iteration 9/25 | Loss: 0.00090152
Iteration 10/25 | Loss: 0.00090152
Iteration 11/25 | Loss: 0.00090152
Iteration 12/25 | Loss: 0.00090152
Iteration 13/25 | Loss: 0.00090152
Iteration 14/25 | Loss: 0.00090152
Iteration 15/25 | Loss: 0.00090152
Iteration 16/25 | Loss: 0.00090152
Iteration 17/25 | Loss: 0.00090152
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0009015210089273751, 0.0009015210089273751, 0.0009015210089273751, 0.0009015210089273751, 0.0009015210089273751]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009015210089273751

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00090152
Iteration 2/1000 | Loss: 0.00005543
Iteration 3/1000 | Loss: 0.00003777
Iteration 4/1000 | Loss: 0.00003223
Iteration 5/1000 | Loss: 0.00003038
Iteration 6/1000 | Loss: 0.00002936
Iteration 7/1000 | Loss: 0.00002857
Iteration 8/1000 | Loss: 0.00002779
Iteration 9/1000 | Loss: 0.00002745
Iteration 10/1000 | Loss: 0.00002708
Iteration 11/1000 | Loss: 0.00002678
Iteration 12/1000 | Loss: 0.00002658
Iteration 13/1000 | Loss: 0.00002639
Iteration 14/1000 | Loss: 0.00002614
Iteration 15/1000 | Loss: 0.00002595
Iteration 16/1000 | Loss: 0.00002576
Iteration 17/1000 | Loss: 0.00002557
Iteration 18/1000 | Loss: 0.00002541
Iteration 19/1000 | Loss: 0.00002537
Iteration 20/1000 | Loss: 0.00002531
Iteration 21/1000 | Loss: 0.00002528
Iteration 22/1000 | Loss: 0.00002524
Iteration 23/1000 | Loss: 0.00002524
Iteration 24/1000 | Loss: 0.00002524
Iteration 25/1000 | Loss: 0.00002524
Iteration 26/1000 | Loss: 0.00002522
Iteration 27/1000 | Loss: 0.00002522
Iteration 28/1000 | Loss: 0.00002521
Iteration 29/1000 | Loss: 0.00002519
Iteration 30/1000 | Loss: 0.00002519
Iteration 31/1000 | Loss: 0.00002515
Iteration 32/1000 | Loss: 0.00002514
Iteration 33/1000 | Loss: 0.00002511
Iteration 34/1000 | Loss: 0.00002511
Iteration 35/1000 | Loss: 0.00002511
Iteration 36/1000 | Loss: 0.00002510
Iteration 37/1000 | Loss: 0.00002509
Iteration 38/1000 | Loss: 0.00002509
Iteration 39/1000 | Loss: 0.00002509
Iteration 40/1000 | Loss: 0.00002509
Iteration 41/1000 | Loss: 0.00002508
Iteration 42/1000 | Loss: 0.00002508
Iteration 43/1000 | Loss: 0.00002508
Iteration 44/1000 | Loss: 0.00002508
Iteration 45/1000 | Loss: 0.00002507
Iteration 46/1000 | Loss: 0.00002507
Iteration 47/1000 | Loss: 0.00002507
Iteration 48/1000 | Loss: 0.00002507
Iteration 49/1000 | Loss: 0.00002507
Iteration 50/1000 | Loss: 0.00002507
Iteration 51/1000 | Loss: 0.00002507
Iteration 52/1000 | Loss: 0.00002507
Iteration 53/1000 | Loss: 0.00002507
Iteration 54/1000 | Loss: 0.00002507
Iteration 55/1000 | Loss: 0.00002507
Iteration 56/1000 | Loss: 0.00002507
Iteration 57/1000 | Loss: 0.00002507
Iteration 58/1000 | Loss: 0.00002507
Iteration 59/1000 | Loss: 0.00002506
Iteration 60/1000 | Loss: 0.00002506
Iteration 61/1000 | Loss: 0.00002506
Iteration 62/1000 | Loss: 0.00002505
Iteration 63/1000 | Loss: 0.00002505
Iteration 64/1000 | Loss: 0.00002505
Iteration 65/1000 | Loss: 0.00002505
Iteration 66/1000 | Loss: 0.00002504
Iteration 67/1000 | Loss: 0.00002504
Iteration 68/1000 | Loss: 0.00002504
Iteration 69/1000 | Loss: 0.00002503
Iteration 70/1000 | Loss: 0.00002503
Iteration 71/1000 | Loss: 0.00002503
Iteration 72/1000 | Loss: 0.00002502
Iteration 73/1000 | Loss: 0.00002502
Iteration 74/1000 | Loss: 0.00002502
Iteration 75/1000 | Loss: 0.00002502
Iteration 76/1000 | Loss: 0.00002502
Iteration 77/1000 | Loss: 0.00002502
Iteration 78/1000 | Loss: 0.00002502
Iteration 79/1000 | Loss: 0.00002502
Iteration 80/1000 | Loss: 0.00002501
Iteration 81/1000 | Loss: 0.00002501
Iteration 82/1000 | Loss: 0.00002501
Iteration 83/1000 | Loss: 0.00002501
Iteration 84/1000 | Loss: 0.00002501
Iteration 85/1000 | Loss: 0.00002501
Iteration 86/1000 | Loss: 0.00002501
Iteration 87/1000 | Loss: 0.00002501
Iteration 88/1000 | Loss: 0.00002501
Iteration 89/1000 | Loss: 0.00002501
Iteration 90/1000 | Loss: 0.00002501
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 90. Stopping optimization.
Last 5 losses: [2.5012986952788197e-05, 2.5012986952788197e-05, 2.5012986952788197e-05, 2.5012986952788197e-05, 2.5012986952788197e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5012986952788197e-05

Optimization complete. Final v2v error: 4.178281307220459 mm

Highest mean error: 5.3733086585998535 mm for frame 103

Lowest mean error: 3.456505060195923 mm for frame 119

Saving results

Total time: 882.970575094223
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1055
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00587578
Iteration 2/25 | Loss: 0.00160764
Iteration 3/25 | Loss: 0.00141541
Iteration 4/25 | Loss: 0.00139992
Iteration 5/25 | Loss: 0.00139661
Iteration 6/25 | Loss: 0.00139576
Iteration 7/25 | Loss: 0.00139576
Iteration 8/25 | Loss: 0.00139576
Iteration 9/25 | Loss: 0.00139576
Iteration 10/25 | Loss: 0.00139576
Iteration 11/25 | Loss: 0.00139576
Iteration 12/25 | Loss: 0.00139576
Iteration 13/25 | Loss: 0.00139576
Iteration 14/25 | Loss: 0.00139576
Iteration 15/25 | Loss: 0.00139576
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013957587070763111, 0.0013957587070763111, 0.0013957587070763111, 0.0013957587070763111, 0.0013957587070763111]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013957587070763111

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43002725
Iteration 2/25 | Loss: 0.00076248
Iteration 3/25 | Loss: 0.00076246
Iteration 4/25 | Loss: 0.00076246
Iteration 5/25 | Loss: 0.00076246
Iteration 6/25 | Loss: 0.00076246
Iteration 7/25 | Loss: 0.00076246
Iteration 8/25 | Loss: 0.00076246
Iteration 9/25 | Loss: 0.00076246
Iteration 10/25 | Loss: 0.00076246
Iteration 11/25 | Loss: 0.00076246
Iteration 12/25 | Loss: 0.00076246
Iteration 13/25 | Loss: 0.00076246
Iteration 14/25 | Loss: 0.00076246
Iteration 15/25 | Loss: 0.00076246
Iteration 16/25 | Loss: 0.00076246
Iteration 17/25 | Loss: 0.00076246
Iteration 18/25 | Loss: 0.00076246
Iteration 19/25 | Loss: 0.00076246
Iteration 20/25 | Loss: 0.00076246
Iteration 21/25 | Loss: 0.00076246
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.000762461218982935, 0.000762461218982935, 0.000762461218982935, 0.000762461218982935, 0.000762461218982935]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000762461218982935

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00076246
Iteration 2/1000 | Loss: 0.00004924
Iteration 3/1000 | Loss: 0.00003337
Iteration 4/1000 | Loss: 0.00002896
Iteration 5/1000 | Loss: 0.00002649
Iteration 6/1000 | Loss: 0.00002528
Iteration 7/1000 | Loss: 0.00002446
Iteration 8/1000 | Loss: 0.00002378
Iteration 9/1000 | Loss: 0.00002340
Iteration 10/1000 | Loss: 0.00002300
Iteration 11/1000 | Loss: 0.00002277
Iteration 12/1000 | Loss: 0.00002255
Iteration 13/1000 | Loss: 0.00002249
Iteration 14/1000 | Loss: 0.00002232
Iteration 15/1000 | Loss: 0.00002227
Iteration 16/1000 | Loss: 0.00002214
Iteration 17/1000 | Loss: 0.00002210
Iteration 18/1000 | Loss: 0.00002210
Iteration 19/1000 | Loss: 0.00002209
Iteration 20/1000 | Loss: 0.00002209
Iteration 21/1000 | Loss: 0.00002203
Iteration 22/1000 | Loss: 0.00002199
Iteration 23/1000 | Loss: 0.00002199
Iteration 24/1000 | Loss: 0.00002198
Iteration 25/1000 | Loss: 0.00002197
Iteration 26/1000 | Loss: 0.00002197
Iteration 27/1000 | Loss: 0.00002196
Iteration 28/1000 | Loss: 0.00002195
Iteration 29/1000 | Loss: 0.00002195
Iteration 30/1000 | Loss: 0.00002194
Iteration 31/1000 | Loss: 0.00002194
Iteration 32/1000 | Loss: 0.00002194
Iteration 33/1000 | Loss: 0.00002193
Iteration 34/1000 | Loss: 0.00002193
Iteration 35/1000 | Loss: 0.00002192
Iteration 36/1000 | Loss: 0.00002191
Iteration 37/1000 | Loss: 0.00002191
Iteration 38/1000 | Loss: 0.00002190
Iteration 39/1000 | Loss: 0.00002189
Iteration 40/1000 | Loss: 0.00002189
Iteration 41/1000 | Loss: 0.00002189
Iteration 42/1000 | Loss: 0.00002189
Iteration 43/1000 | Loss: 0.00002189
Iteration 44/1000 | Loss: 0.00002189
Iteration 45/1000 | Loss: 0.00002189
Iteration 46/1000 | Loss: 0.00002186
Iteration 47/1000 | Loss: 0.00002186
Iteration 48/1000 | Loss: 0.00002186
Iteration 49/1000 | Loss: 0.00002186
Iteration 50/1000 | Loss: 0.00002186
Iteration 51/1000 | Loss: 0.00002186
Iteration 52/1000 | Loss: 0.00002186
Iteration 53/1000 | Loss: 0.00002185
Iteration 54/1000 | Loss: 0.00002185
Iteration 55/1000 | Loss: 0.00002185
Iteration 56/1000 | Loss: 0.00002185
Iteration 57/1000 | Loss: 0.00002185
Iteration 58/1000 | Loss: 0.00002185
Iteration 59/1000 | Loss: 0.00002185
Iteration 60/1000 | Loss: 0.00002185
Iteration 61/1000 | Loss: 0.00002185
Iteration 62/1000 | Loss: 0.00002185
Iteration 63/1000 | Loss: 0.00002185
Iteration 64/1000 | Loss: 0.00002185
Iteration 65/1000 | Loss: 0.00002184
Iteration 66/1000 | Loss: 0.00002184
Iteration 67/1000 | Loss: 0.00002184
Iteration 68/1000 | Loss: 0.00002184
Iteration 69/1000 | Loss: 0.00002183
Iteration 70/1000 | Loss: 0.00002182
Iteration 71/1000 | Loss: 0.00002182
Iteration 72/1000 | Loss: 0.00002182
Iteration 73/1000 | Loss: 0.00002182
Iteration 74/1000 | Loss: 0.00002182
Iteration 75/1000 | Loss: 0.00002182
Iteration 76/1000 | Loss: 0.00002182
Iteration 77/1000 | Loss: 0.00002182
Iteration 78/1000 | Loss: 0.00002181
Iteration 79/1000 | Loss: 0.00002181
Iteration 80/1000 | Loss: 0.00002181
Iteration 81/1000 | Loss: 0.00002180
Iteration 82/1000 | Loss: 0.00002180
Iteration 83/1000 | Loss: 0.00002180
Iteration 84/1000 | Loss: 0.00002180
Iteration 85/1000 | Loss: 0.00002180
Iteration 86/1000 | Loss: 0.00002179
Iteration 87/1000 | Loss: 0.00002179
Iteration 88/1000 | Loss: 0.00002179
Iteration 89/1000 | Loss: 0.00002179
Iteration 90/1000 | Loss: 0.00002179
Iteration 91/1000 | Loss: 0.00002178
Iteration 92/1000 | Loss: 0.00002178
Iteration 93/1000 | Loss: 0.00002178
Iteration 94/1000 | Loss: 0.00002178
Iteration 95/1000 | Loss: 0.00002178
Iteration 96/1000 | Loss: 0.00002177
Iteration 97/1000 | Loss: 0.00002177
Iteration 98/1000 | Loss: 0.00002177
Iteration 99/1000 | Loss: 0.00002177
Iteration 100/1000 | Loss: 0.00002177
Iteration 101/1000 | Loss: 0.00002176
Iteration 102/1000 | Loss: 0.00002176
Iteration 103/1000 | Loss: 0.00002176
Iteration 104/1000 | Loss: 0.00002176
Iteration 105/1000 | Loss: 0.00002176
Iteration 106/1000 | Loss: 0.00002176
Iteration 107/1000 | Loss: 0.00002175
Iteration 108/1000 | Loss: 0.00002175
Iteration 109/1000 | Loss: 0.00002175
Iteration 110/1000 | Loss: 0.00002174
Iteration 111/1000 | Loss: 0.00002174
Iteration 112/1000 | Loss: 0.00002174
Iteration 113/1000 | Loss: 0.00002174
Iteration 114/1000 | Loss: 0.00002174
Iteration 115/1000 | Loss: 0.00002173
Iteration 116/1000 | Loss: 0.00002173
Iteration 117/1000 | Loss: 0.00002173
Iteration 118/1000 | Loss: 0.00002173
Iteration 119/1000 | Loss: 0.00002173
Iteration 120/1000 | Loss: 0.00002173
Iteration 121/1000 | Loss: 0.00002173
Iteration 122/1000 | Loss: 0.00002173
Iteration 123/1000 | Loss: 0.00002173
Iteration 124/1000 | Loss: 0.00002172
Iteration 125/1000 | Loss: 0.00002172
Iteration 126/1000 | Loss: 0.00002172
Iteration 127/1000 | Loss: 0.00002172
Iteration 128/1000 | Loss: 0.00002172
Iteration 129/1000 | Loss: 0.00002172
Iteration 130/1000 | Loss: 0.00002172
Iteration 131/1000 | Loss: 0.00002172
Iteration 132/1000 | Loss: 0.00002172
Iteration 133/1000 | Loss: 0.00002171
Iteration 134/1000 | Loss: 0.00002171
Iteration 135/1000 | Loss: 0.00002171
Iteration 136/1000 | Loss: 0.00002171
Iteration 137/1000 | Loss: 0.00002171
Iteration 138/1000 | Loss: 0.00002171
Iteration 139/1000 | Loss: 0.00002171
Iteration 140/1000 | Loss: 0.00002171
Iteration 141/1000 | Loss: 0.00002171
Iteration 142/1000 | Loss: 0.00002171
Iteration 143/1000 | Loss: 0.00002171
Iteration 144/1000 | Loss: 0.00002170
Iteration 145/1000 | Loss: 0.00002170
Iteration 146/1000 | Loss: 0.00002170
Iteration 147/1000 | Loss: 0.00002170
Iteration 148/1000 | Loss: 0.00002170
Iteration 149/1000 | Loss: 0.00002170
Iteration 150/1000 | Loss: 0.00002170
Iteration 151/1000 | Loss: 0.00002170
Iteration 152/1000 | Loss: 0.00002170
Iteration 153/1000 | Loss: 0.00002170
Iteration 154/1000 | Loss: 0.00002170
Iteration 155/1000 | Loss: 0.00002170
Iteration 156/1000 | Loss: 0.00002170
Iteration 157/1000 | Loss: 0.00002170
Iteration 158/1000 | Loss: 0.00002170
Iteration 159/1000 | Loss: 0.00002170
Iteration 160/1000 | Loss: 0.00002170
Iteration 161/1000 | Loss: 0.00002170
Iteration 162/1000 | Loss: 0.00002170
Iteration 163/1000 | Loss: 0.00002170
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [2.1695068426197395e-05, 2.1695068426197395e-05, 2.1695068426197395e-05, 2.1695068426197395e-05, 2.1695068426197395e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1695068426197395e-05

Optimization complete. Final v2v error: 3.881396770477295 mm

Highest mean error: 4.424938201904297 mm for frame 75

Lowest mean error: 3.4748620986938477 mm for frame 117

Saving results

Total time: 802.3948791027069
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1043/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1043.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1043
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00439431
Iteration 2/25 | Loss: 0.00143920
Iteration 3/25 | Loss: 0.00135635
Iteration 4/25 | Loss: 0.00133977
Iteration 5/25 | Loss: 0.00133375
Iteration 6/25 | Loss: 0.00133257
Iteration 7/25 | Loss: 0.00133257
Iteration 8/25 | Loss: 0.00133257
Iteration 9/25 | Loss: 0.00133257
Iteration 10/25 | Loss: 0.00133257
Iteration 11/25 | Loss: 0.00133257
Iteration 12/25 | Loss: 0.00133257
Iteration 13/25 | Loss: 0.00133257
Iteration 14/25 | Loss: 0.00133257
Iteration 15/25 | Loss: 0.00133257
Iteration 16/25 | Loss: 0.00133257
Iteration 17/25 | Loss: 0.00133257
Iteration 18/25 | Loss: 0.00133257
Iteration 19/25 | Loss: 0.00133257
Iteration 20/25 | Loss: 0.00133257
Iteration 21/25 | Loss: 0.00133257
Iteration 22/25 | Loss: 0.00133257
Iteration 23/25 | Loss: 0.00133257
Iteration 24/25 | Loss: 0.00133257
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.001332570449449122, 0.001332570449449122, 0.001332570449449122, 0.001332570449449122, 0.001332570449449122]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001332570449449122

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.81190741
Iteration 2/25 | Loss: 0.00101601
Iteration 3/25 | Loss: 0.00101601
Iteration 4/25 | Loss: 0.00101601
Iteration 5/25 | Loss: 0.00101601
Iteration 6/25 | Loss: 0.00101601
Iteration 7/25 | Loss: 0.00101601
Iteration 8/25 | Loss: 0.00101601
Iteration 9/25 | Loss: 0.00101601
Iteration 10/25 | Loss: 0.00101601
Iteration 11/25 | Loss: 0.00101601
Iteration 12/25 | Loss: 0.00101601
Iteration 13/25 | Loss: 0.00101600
Iteration 14/25 | Loss: 0.00101601
Iteration 15/25 | Loss: 0.00101601
Iteration 16/25 | Loss: 0.00101601
Iteration 17/25 | Loss: 0.00101601
Iteration 18/25 | Loss: 0.00101600
Iteration 19/25 | Loss: 0.00101600
Iteration 20/25 | Loss: 0.00101600
Iteration 21/25 | Loss: 0.00101601
Iteration 22/25 | Loss: 0.00101601
Iteration 23/25 | Loss: 0.00101601
Iteration 24/25 | Loss: 0.00101601
Iteration 25/25 | Loss: 0.00101601

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00101601
Iteration 2/1000 | Loss: 0.00003052
Iteration 3/1000 | Loss: 0.00002315
Iteration 4/1000 | Loss: 0.00002174
Iteration 5/1000 | Loss: 0.00002114
Iteration 6/1000 | Loss: 0.00002076
Iteration 7/1000 | Loss: 0.00002050
Iteration 8/1000 | Loss: 0.00002050
Iteration 9/1000 | Loss: 0.00002031
Iteration 10/1000 | Loss: 0.00002007
Iteration 11/1000 | Loss: 0.00002000
Iteration 12/1000 | Loss: 0.00001995
Iteration 13/1000 | Loss: 0.00001993
Iteration 14/1000 | Loss: 0.00001989
Iteration 15/1000 | Loss: 0.00001989
Iteration 16/1000 | Loss: 0.00001988
Iteration 17/1000 | Loss: 0.00001988
Iteration 18/1000 | Loss: 0.00001987
Iteration 19/1000 | Loss: 0.00001987
Iteration 20/1000 | Loss: 0.00001985
Iteration 21/1000 | Loss: 0.00001985
Iteration 22/1000 | Loss: 0.00001983
Iteration 23/1000 | Loss: 0.00001983
Iteration 24/1000 | Loss: 0.00001979
Iteration 25/1000 | Loss: 0.00001976
Iteration 26/1000 | Loss: 0.00001958
Iteration 27/1000 | Loss: 0.00001955
Iteration 28/1000 | Loss: 0.00001955
Iteration 29/1000 | Loss: 0.00001955
Iteration 30/1000 | Loss: 0.00001953
Iteration 31/1000 | Loss: 0.00001952
Iteration 32/1000 | Loss: 0.00001952
Iteration 33/1000 | Loss: 0.00001952
Iteration 34/1000 | Loss: 0.00001951
Iteration 35/1000 | Loss: 0.00001951
Iteration 36/1000 | Loss: 0.00001950
Iteration 37/1000 | Loss: 0.00001950
Iteration 38/1000 | Loss: 0.00001949
Iteration 39/1000 | Loss: 0.00001949
Iteration 40/1000 | Loss: 0.00001948
Iteration 41/1000 | Loss: 0.00001948
Iteration 42/1000 | Loss: 0.00001947
Iteration 43/1000 | Loss: 0.00001947
Iteration 44/1000 | Loss: 0.00001946
Iteration 45/1000 | Loss: 0.00001946
Iteration 46/1000 | Loss: 0.00001945
Iteration 47/1000 | Loss: 0.00001945
Iteration 48/1000 | Loss: 0.00001944
Iteration 49/1000 | Loss: 0.00001943
Iteration 50/1000 | Loss: 0.00001943
Iteration 51/1000 | Loss: 0.00001943
Iteration 52/1000 | Loss: 0.00001943
Iteration 53/1000 | Loss: 0.00001942
Iteration 54/1000 | Loss: 0.00001942
Iteration 55/1000 | Loss: 0.00001942
Iteration 56/1000 | Loss: 0.00001942
Iteration 57/1000 | Loss: 0.00001942
Iteration 58/1000 | Loss: 0.00001941
Iteration 59/1000 | Loss: 0.00001941
Iteration 60/1000 | Loss: 0.00001939
Iteration 61/1000 | Loss: 0.00001939
Iteration 62/1000 | Loss: 0.00001939
Iteration 63/1000 | Loss: 0.00001938
Iteration 64/1000 | Loss: 0.00001938
Iteration 65/1000 | Loss: 0.00001938
Iteration 66/1000 | Loss: 0.00001937
Iteration 67/1000 | Loss: 0.00001937
Iteration 68/1000 | Loss: 0.00001936
Iteration 69/1000 | Loss: 0.00001936
Iteration 70/1000 | Loss: 0.00001935
Iteration 71/1000 | Loss: 0.00001935
Iteration 72/1000 | Loss: 0.00001935
Iteration 73/1000 | Loss: 0.00001935
Iteration 74/1000 | Loss: 0.00001935
Iteration 75/1000 | Loss: 0.00001935
Iteration 76/1000 | Loss: 0.00001935
Iteration 77/1000 | Loss: 0.00001935
Iteration 78/1000 | Loss: 0.00001935
Iteration 79/1000 | Loss: 0.00001934
Iteration 80/1000 | Loss: 0.00001934
Iteration 81/1000 | Loss: 0.00001934
Iteration 82/1000 | Loss: 0.00001934
Iteration 83/1000 | Loss: 0.00001934
Iteration 84/1000 | Loss: 0.00001933
Iteration 85/1000 | Loss: 0.00001933
Iteration 86/1000 | Loss: 0.00001933
Iteration 87/1000 | Loss: 0.00001933
Iteration 88/1000 | Loss: 0.00001933
Iteration 89/1000 | Loss: 0.00001933
Iteration 90/1000 | Loss: 0.00001932
Iteration 91/1000 | Loss: 0.00001932
Iteration 92/1000 | Loss: 0.00001932
Iteration 93/1000 | Loss: 0.00001932
Iteration 94/1000 | Loss: 0.00001931
Iteration 95/1000 | Loss: 0.00001931
Iteration 96/1000 | Loss: 0.00001931
Iteration 97/1000 | Loss: 0.00001931
Iteration 98/1000 | Loss: 0.00001931
Iteration 99/1000 | Loss: 0.00001931
Iteration 100/1000 | Loss: 0.00001930
Iteration 101/1000 | Loss: 0.00001930
Iteration 102/1000 | Loss: 0.00001930
Iteration 103/1000 | Loss: 0.00001929
Iteration 104/1000 | Loss: 0.00001929
Iteration 105/1000 | Loss: 0.00001928
Iteration 106/1000 | Loss: 0.00001928
Iteration 107/1000 | Loss: 0.00001928
Iteration 108/1000 | Loss: 0.00001927
Iteration 109/1000 | Loss: 0.00001927
Iteration 110/1000 | Loss: 0.00001927
Iteration 111/1000 | Loss: 0.00001927
Iteration 112/1000 | Loss: 0.00001926
Iteration 113/1000 | Loss: 0.00001926
Iteration 114/1000 | Loss: 0.00001925
Iteration 115/1000 | Loss: 0.00001925
Iteration 116/1000 | Loss: 0.00001925
Iteration 117/1000 | Loss: 0.00001925
Iteration 118/1000 | Loss: 0.00001925
Iteration 119/1000 | Loss: 0.00001924
Iteration 120/1000 | Loss: 0.00001924
Iteration 121/1000 | Loss: 0.00001924
Iteration 122/1000 | Loss: 0.00001923
Iteration 123/1000 | Loss: 0.00001923
Iteration 124/1000 | Loss: 0.00001923
Iteration 125/1000 | Loss: 0.00001923
Iteration 126/1000 | Loss: 0.00001923
Iteration 127/1000 | Loss: 0.00001922
Iteration 128/1000 | Loss: 0.00001922
Iteration 129/1000 | Loss: 0.00001922
Iteration 130/1000 | Loss: 0.00001922
Iteration 131/1000 | Loss: 0.00001921
Iteration 132/1000 | Loss: 0.00001921
Iteration 133/1000 | Loss: 0.00001921
Iteration 134/1000 | Loss: 0.00001920
Iteration 135/1000 | Loss: 0.00001920
Iteration 136/1000 | Loss: 0.00001920
Iteration 137/1000 | Loss: 0.00001920
Iteration 138/1000 | Loss: 0.00001919
Iteration 139/1000 | Loss: 0.00001919
Iteration 140/1000 | Loss: 0.00001919
Iteration 141/1000 | Loss: 0.00001918
Iteration 142/1000 | Loss: 0.00001918
Iteration 143/1000 | Loss: 0.00001918
Iteration 144/1000 | Loss: 0.00001918
Iteration 145/1000 | Loss: 0.00001918
Iteration 146/1000 | Loss: 0.00001918
Iteration 147/1000 | Loss: 0.00001918
Iteration 148/1000 | Loss: 0.00001918
Iteration 149/1000 | Loss: 0.00001918
Iteration 150/1000 | Loss: 0.00001918
Iteration 151/1000 | Loss: 0.00001918
Iteration 152/1000 | Loss: 0.00001917
Iteration 153/1000 | Loss: 0.00001917
Iteration 154/1000 | Loss: 0.00001917
Iteration 155/1000 | Loss: 0.00001917
Iteration 156/1000 | Loss: 0.00001917
Iteration 157/1000 | Loss: 0.00001916
Iteration 158/1000 | Loss: 0.00001916
Iteration 159/1000 | Loss: 0.00001916
Iteration 160/1000 | Loss: 0.00001916
Iteration 161/1000 | Loss: 0.00001916
Iteration 162/1000 | Loss: 0.00001916
Iteration 163/1000 | Loss: 0.00001916
Iteration 164/1000 | Loss: 0.00001916
Iteration 165/1000 | Loss: 0.00001916
Iteration 166/1000 | Loss: 0.00001916
Iteration 167/1000 | Loss: 0.00001916
Iteration 168/1000 | Loss: 0.00001916
Iteration 169/1000 | Loss: 0.00001916
Iteration 170/1000 | Loss: 0.00001916
Iteration 171/1000 | Loss: 0.00001916
Iteration 172/1000 | Loss: 0.00001916
Iteration 173/1000 | Loss: 0.00001916
Iteration 174/1000 | Loss: 0.00001916
Iteration 175/1000 | Loss: 0.00001916
Iteration 176/1000 | Loss: 0.00001916
Iteration 177/1000 | Loss: 0.00001916
Iteration 178/1000 | Loss: 0.00001916
Iteration 179/1000 | Loss: 0.00001916
Iteration 180/1000 | Loss: 0.00001916
Iteration 181/1000 | Loss: 0.00001916
Iteration 182/1000 | Loss: 0.00001916
Iteration 183/1000 | Loss: 0.00001916
Iteration 184/1000 | Loss: 0.00001916
Iteration 185/1000 | Loss: 0.00001916
Iteration 186/1000 | Loss: 0.00001916
Iteration 187/1000 | Loss: 0.00001916
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 187. Stopping optimization.
Last 5 losses: [1.9164648620062508e-05, 1.9164648620062508e-05, 1.9164648620062508e-05, 1.9164648620062508e-05, 1.9164648620062508e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9164648620062508e-05

Optimization complete. Final v2v error: 3.701488971710205 mm

Highest mean error: 4.308477401733398 mm for frame 158

Lowest mean error: 3.581650733947754 mm for frame 62

Saving results

Total time: 1295.7449922561646
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1085
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00656802
Iteration 2/25 | Loss: 0.00137196
Iteration 3/25 | Loss: 0.00129085
Iteration 4/25 | Loss: 0.00128242
Iteration 5/25 | Loss: 0.00127942
Iteration 6/25 | Loss: 0.00127876
Iteration 7/25 | Loss: 0.00127876
Iteration 8/25 | Loss: 0.00127876
Iteration 9/25 | Loss: 0.00127876
Iteration 10/25 | Loss: 0.00127876
Iteration 11/25 | Loss: 0.00127876
Iteration 12/25 | Loss: 0.00127876
Iteration 13/25 | Loss: 0.00127876
Iteration 14/25 | Loss: 0.00127876
Iteration 15/25 | Loss: 0.00127876
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0012787594459950924, 0.0012787594459950924, 0.0012787594459950924, 0.0012787594459950924, 0.0012787594459950924]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012787594459950924

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.62315536
Iteration 2/25 | Loss: 0.00090718
Iteration 3/25 | Loss: 0.00090717
Iteration 4/25 | Loss: 0.00090717
Iteration 5/25 | Loss: 0.00090717
Iteration 6/25 | Loss: 0.00090717
Iteration 7/25 | Loss: 0.00090717
Iteration 8/25 | Loss: 0.00090717
Iteration 9/25 | Loss: 0.00090717
Iteration 10/25 | Loss: 0.00090717
Iteration 11/25 | Loss: 0.00090717
Iteration 12/25 | Loss: 0.00090717
Iteration 13/25 | Loss: 0.00090717
Iteration 14/25 | Loss: 0.00090717
Iteration 15/25 | Loss: 0.00090717
Iteration 16/25 | Loss: 0.00090717
Iteration 17/25 | Loss: 0.00090717
Iteration 18/25 | Loss: 0.00090717
Iteration 19/25 | Loss: 0.00090717
Iteration 20/25 | Loss: 0.00090717
Iteration 21/25 | Loss: 0.00090717
Iteration 22/25 | Loss: 0.00090717
Iteration 23/25 | Loss: 0.00090717
Iteration 24/25 | Loss: 0.00090717
Iteration 25/25 | Loss: 0.00090717

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00090717
Iteration 2/1000 | Loss: 0.00003712
Iteration 3/1000 | Loss: 0.00002019
Iteration 4/1000 | Loss: 0.00001574
Iteration 5/1000 | Loss: 0.00001469
Iteration 6/1000 | Loss: 0.00001387
Iteration 7/1000 | Loss: 0.00001339
Iteration 8/1000 | Loss: 0.00001312
Iteration 9/1000 | Loss: 0.00001302
Iteration 10/1000 | Loss: 0.00001281
Iteration 11/1000 | Loss: 0.00001271
Iteration 12/1000 | Loss: 0.00001271
Iteration 13/1000 | Loss: 0.00001264
Iteration 14/1000 | Loss: 0.00001263
Iteration 15/1000 | Loss: 0.00001262
Iteration 16/1000 | Loss: 0.00001255
Iteration 17/1000 | Loss: 0.00001246
Iteration 18/1000 | Loss: 0.00001240
Iteration 19/1000 | Loss: 0.00001239
Iteration 20/1000 | Loss: 0.00001233
Iteration 21/1000 | Loss: 0.00001231
Iteration 22/1000 | Loss: 0.00001228
Iteration 23/1000 | Loss: 0.00001228
Iteration 24/1000 | Loss: 0.00001226
Iteration 25/1000 | Loss: 0.00001226
Iteration 26/1000 | Loss: 0.00001226
Iteration 27/1000 | Loss: 0.00001225
Iteration 28/1000 | Loss: 0.00001224
Iteration 29/1000 | Loss: 0.00001221
Iteration 30/1000 | Loss: 0.00001220
Iteration 31/1000 | Loss: 0.00001220
Iteration 32/1000 | Loss: 0.00001219
Iteration 33/1000 | Loss: 0.00001218
Iteration 34/1000 | Loss: 0.00001218
Iteration 35/1000 | Loss: 0.00001215
Iteration 36/1000 | Loss: 0.00001214
Iteration 37/1000 | Loss: 0.00001214
Iteration 38/1000 | Loss: 0.00001214
Iteration 39/1000 | Loss: 0.00001213
Iteration 40/1000 | Loss: 0.00001211
Iteration 41/1000 | Loss: 0.00001210
Iteration 42/1000 | Loss: 0.00001210
Iteration 43/1000 | Loss: 0.00001210
Iteration 44/1000 | Loss: 0.00001209
Iteration 45/1000 | Loss: 0.00001209
Iteration 46/1000 | Loss: 0.00001209
Iteration 47/1000 | Loss: 0.00001209
Iteration 48/1000 | Loss: 0.00001208
Iteration 49/1000 | Loss: 0.00001208
Iteration 50/1000 | Loss: 0.00001208
Iteration 51/1000 | Loss: 0.00001207
Iteration 52/1000 | Loss: 0.00001207
Iteration 53/1000 | Loss: 0.00001207
Iteration 54/1000 | Loss: 0.00001207
Iteration 55/1000 | Loss: 0.00001207
Iteration 56/1000 | Loss: 0.00001207
Iteration 57/1000 | Loss: 0.00001207
Iteration 58/1000 | Loss: 0.00001207
Iteration 59/1000 | Loss: 0.00001206
Iteration 60/1000 | Loss: 0.00001206
Iteration 61/1000 | Loss: 0.00001206
Iteration 62/1000 | Loss: 0.00001205
Iteration 63/1000 | Loss: 0.00001205
Iteration 64/1000 | Loss: 0.00001205
Iteration 65/1000 | Loss: 0.00001205
Iteration 66/1000 | Loss: 0.00001204
Iteration 67/1000 | Loss: 0.00001204
Iteration 68/1000 | Loss: 0.00001203
Iteration 69/1000 | Loss: 0.00001203
Iteration 70/1000 | Loss: 0.00001203
Iteration 71/1000 | Loss: 0.00001203
Iteration 72/1000 | Loss: 0.00001203
Iteration 73/1000 | Loss: 0.00001203
Iteration 74/1000 | Loss: 0.00001202
Iteration 75/1000 | Loss: 0.00001202
Iteration 76/1000 | Loss: 0.00001202
Iteration 77/1000 | Loss: 0.00001202
Iteration 78/1000 | Loss: 0.00001202
Iteration 79/1000 | Loss: 0.00001202
Iteration 80/1000 | Loss: 0.00001201
Iteration 81/1000 | Loss: 0.00001201
Iteration 82/1000 | Loss: 0.00001201
Iteration 83/1000 | Loss: 0.00001201
Iteration 84/1000 | Loss: 0.00001201
Iteration 85/1000 | Loss: 0.00001201
Iteration 86/1000 | Loss: 0.00001200
Iteration 87/1000 | Loss: 0.00001200
Iteration 88/1000 | Loss: 0.00001200
Iteration 89/1000 | Loss: 0.00001200
Iteration 90/1000 | Loss: 0.00001200
Iteration 91/1000 | Loss: 0.00001199
Iteration 92/1000 | Loss: 0.00001199
Iteration 93/1000 | Loss: 0.00001199
Iteration 94/1000 | Loss: 0.00001198
Iteration 95/1000 | Loss: 0.00001198
Iteration 96/1000 | Loss: 0.00001198
Iteration 97/1000 | Loss: 0.00001197
Iteration 98/1000 | Loss: 0.00001197
Iteration 99/1000 | Loss: 0.00001197
Iteration 100/1000 | Loss: 0.00001197
Iteration 101/1000 | Loss: 0.00001197
Iteration 102/1000 | Loss: 0.00001197
Iteration 103/1000 | Loss: 0.00001197
Iteration 104/1000 | Loss: 0.00001197
Iteration 105/1000 | Loss: 0.00001197
Iteration 106/1000 | Loss: 0.00001197
Iteration 107/1000 | Loss: 0.00001197
Iteration 108/1000 | Loss: 0.00001197
Iteration 109/1000 | Loss: 0.00001197
Iteration 110/1000 | Loss: 0.00001197
Iteration 111/1000 | Loss: 0.00001197
Iteration 112/1000 | Loss: 0.00001197
Iteration 113/1000 | Loss: 0.00001197
Iteration 114/1000 | Loss: 0.00001197
Iteration 115/1000 | Loss: 0.00001197
Iteration 116/1000 | Loss: 0.00001197
Iteration 117/1000 | Loss: 0.00001197
Iteration 118/1000 | Loss: 0.00001197
Iteration 119/1000 | Loss: 0.00001197
Iteration 120/1000 | Loss: 0.00001197
Iteration 121/1000 | Loss: 0.00001197
Iteration 122/1000 | Loss: 0.00001197
Iteration 123/1000 | Loss: 0.00001197
Iteration 124/1000 | Loss: 0.00001197
Iteration 125/1000 | Loss: 0.00001197
Iteration 126/1000 | Loss: 0.00001197
Iteration 127/1000 | Loss: 0.00001197
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [1.1970397281402256e-05, 1.1970397281402256e-05, 1.1970397281402256e-05, 1.1970397281402256e-05, 1.1970397281402256e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1970397281402256e-05

Optimization complete. Final v2v error: 2.9951791763305664 mm

Highest mean error: 3.187944173812866 mm for frame 43

Lowest mean error: 2.8068673610687256 mm for frame 136

Saving results

Total time: 726.7341890335083
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1000
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01001397
Iteration 2/25 | Loss: 0.00244632
Iteration 3/25 | Loss: 0.00282862
Iteration 4/25 | Loss: 0.00168314
Iteration 5/25 | Loss: 0.00151343
Iteration 6/25 | Loss: 0.00142239
Iteration 7/25 | Loss: 0.00139606
Iteration 8/25 | Loss: 0.00137848
Iteration 9/25 | Loss: 0.00136741
Iteration 10/25 | Loss: 0.00136344
Iteration 11/25 | Loss: 0.00136169
Iteration 12/25 | Loss: 0.00136112
Iteration 13/25 | Loss: 0.00136080
Iteration 14/25 | Loss: 0.00138745
Iteration 15/25 | Loss: 0.00135069
Iteration 16/25 | Loss: 0.00135130
Iteration 17/25 | Loss: 0.00135009
Iteration 18/25 | Loss: 0.00134752
Iteration 19/25 | Loss: 0.00137853
Iteration 20/25 | Loss: 0.00133892
Iteration 21/25 | Loss: 0.00133661
Iteration 22/25 | Loss: 0.00134237
Iteration 23/25 | Loss: 0.00134236
Iteration 24/25 | Loss: 0.00134216
Iteration 25/25 | Loss: 0.00134166

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50500846
Iteration 2/25 | Loss: 0.00109608
Iteration 3/25 | Loss: 0.00109608
Iteration 4/25 | Loss: 0.00109607
Iteration 5/25 | Loss: 0.00109607
Iteration 6/25 | Loss: 0.00109607
Iteration 7/25 | Loss: 0.00109607
Iteration 8/25 | Loss: 0.00109607
Iteration 9/25 | Loss: 0.00109607
Iteration 10/25 | Loss: 0.00109607
Iteration 11/25 | Loss: 0.00109607
Iteration 12/25 | Loss: 0.00109607
Iteration 13/25 | Loss: 0.00109607
Iteration 14/25 | Loss: 0.00109607
Iteration 15/25 | Loss: 0.00109607
Iteration 16/25 | Loss: 0.00109607
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010960731888189912, 0.0010960731888189912, 0.0010960731888189912, 0.0010960731888189912, 0.0010960731888189912]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010960731888189912

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00109607
Iteration 2/1000 | Loss: 0.00394527
Iteration 3/1000 | Loss: 0.00024827
Iteration 4/1000 | Loss: 0.00037158
Iteration 5/1000 | Loss: 0.00022695
Iteration 6/1000 | Loss: 0.00013756
Iteration 7/1000 | Loss: 0.00015887
Iteration 8/1000 | Loss: 0.00032225
Iteration 9/1000 | Loss: 0.00029399
Iteration 10/1000 | Loss: 0.00061454
Iteration 11/1000 | Loss: 0.00053662
Iteration 12/1000 | Loss: 0.00026984
Iteration 13/1000 | Loss: 0.00043016
Iteration 14/1000 | Loss: 0.00033924
Iteration 15/1000 | Loss: 0.00022326
Iteration 16/1000 | Loss: 0.00039579
Iteration 17/1000 | Loss: 0.00024024
Iteration 18/1000 | Loss: 0.00004900
Iteration 19/1000 | Loss: 0.00088029
Iteration 20/1000 | Loss: 0.00081662
Iteration 21/1000 | Loss: 0.00108217
Iteration 22/1000 | Loss: 0.00044976
Iteration 23/1000 | Loss: 0.00047300
Iteration 24/1000 | Loss: 0.00037372
Iteration 25/1000 | Loss: 0.00023309
Iteration 26/1000 | Loss: 0.00019390
Iteration 27/1000 | Loss: 0.00059716
Iteration 28/1000 | Loss: 0.00032833
Iteration 29/1000 | Loss: 0.00009931
Iteration 30/1000 | Loss: 0.00025810
Iteration 31/1000 | Loss: 0.00064956
Iteration 32/1000 | Loss: 0.00013925
Iteration 33/1000 | Loss: 0.00030801
Iteration 34/1000 | Loss: 0.00038175
Iteration 35/1000 | Loss: 0.00005774
Iteration 36/1000 | Loss: 0.00004446
Iteration 37/1000 | Loss: 0.00008457
Iteration 38/1000 | Loss: 0.00008759
Iteration 39/1000 | Loss: 0.00008330
Iteration 40/1000 | Loss: 0.00003112
Iteration 41/1000 | Loss: 0.00002919
Iteration 42/1000 | Loss: 0.00030295
Iteration 43/1000 | Loss: 0.00026616
Iteration 44/1000 | Loss: 0.00008030
Iteration 45/1000 | Loss: 0.00010151
Iteration 46/1000 | Loss: 0.00002975
Iteration 47/1000 | Loss: 0.00002754
Iteration 48/1000 | Loss: 0.00002635
Iteration 49/1000 | Loss: 0.00036963
Iteration 50/1000 | Loss: 0.00033650
Iteration 51/1000 | Loss: 0.00020740
Iteration 52/1000 | Loss: 0.00055831
Iteration 53/1000 | Loss: 0.00063727
Iteration 54/1000 | Loss: 0.00006192
Iteration 55/1000 | Loss: 0.00087569
Iteration 56/1000 | Loss: 0.00004943
Iteration 57/1000 | Loss: 0.00003528
Iteration 58/1000 | Loss: 0.00003092
Iteration 59/1000 | Loss: 0.00002897
Iteration 60/1000 | Loss: 0.00026369
Iteration 61/1000 | Loss: 0.00031876
Iteration 62/1000 | Loss: 0.00033984
Iteration 63/1000 | Loss: 0.00041225
Iteration 64/1000 | Loss: 0.00058190
Iteration 65/1000 | Loss: 0.00039892
Iteration 66/1000 | Loss: 0.00073727
Iteration 67/1000 | Loss: 0.00017300
Iteration 68/1000 | Loss: 0.00006970
Iteration 69/1000 | Loss: 0.00014816
Iteration 70/1000 | Loss: 0.00009275
Iteration 71/1000 | Loss: 0.00009808
Iteration 72/1000 | Loss: 0.00011687
Iteration 73/1000 | Loss: 0.00023695
Iteration 74/1000 | Loss: 0.00006999
Iteration 75/1000 | Loss: 0.00022946
Iteration 76/1000 | Loss: 0.00006292
Iteration 77/1000 | Loss: 0.00011144
Iteration 78/1000 | Loss: 0.00003057
Iteration 79/1000 | Loss: 0.00002794
Iteration 80/1000 | Loss: 0.00002730
Iteration 81/1000 | Loss: 0.00004780
Iteration 82/1000 | Loss: 0.00031683
Iteration 83/1000 | Loss: 0.00040547
Iteration 84/1000 | Loss: 0.00061613
Iteration 85/1000 | Loss: 0.00006797
Iteration 86/1000 | Loss: 0.00039425
Iteration 87/1000 | Loss: 0.00004606
Iteration 88/1000 | Loss: 0.00039094
Iteration 89/1000 | Loss: 0.00019786
Iteration 90/1000 | Loss: 0.00011826
Iteration 91/1000 | Loss: 0.00116372
Iteration 92/1000 | Loss: 0.00032156
Iteration 93/1000 | Loss: 0.00025009
Iteration 94/1000 | Loss: 0.00003903
Iteration 95/1000 | Loss: 0.00022672
Iteration 96/1000 | Loss: 0.00003416
Iteration 97/1000 | Loss: 0.00019292
Iteration 98/1000 | Loss: 0.00002685
Iteration 99/1000 | Loss: 0.00005767
Iteration 100/1000 | Loss: 0.00021003
Iteration 101/1000 | Loss: 0.00003152
Iteration 102/1000 | Loss: 0.00019202
Iteration 103/1000 | Loss: 0.00002771
Iteration 104/1000 | Loss: 0.00029275
Iteration 105/1000 | Loss: 0.00003094
Iteration 106/1000 | Loss: 0.00021458
Iteration 107/1000 | Loss: 0.00040658
Iteration 108/1000 | Loss: 0.00034565
Iteration 109/1000 | Loss: 0.00024933
Iteration 110/1000 | Loss: 0.00017374
Iteration 111/1000 | Loss: 0.00012979
Iteration 112/1000 | Loss: 0.00022204
Iteration 113/1000 | Loss: 0.00020902
Iteration 114/1000 | Loss: 0.00036544
Iteration 115/1000 | Loss: 0.00018715
Iteration 116/1000 | Loss: 0.00013915
Iteration 117/1000 | Loss: 0.00025277
Iteration 118/1000 | Loss: 0.00012218
Iteration 119/1000 | Loss: 0.00014663
Iteration 120/1000 | Loss: 0.00005140
Iteration 121/1000 | Loss: 0.00017648
Iteration 122/1000 | Loss: 0.00022698
Iteration 123/1000 | Loss: 0.00026918
Iteration 124/1000 | Loss: 0.00062290
Iteration 125/1000 | Loss: 0.00112613
Iteration 126/1000 | Loss: 0.00044352
Iteration 127/1000 | Loss: 0.00003757
Iteration 128/1000 | Loss: 0.00002754
Iteration 129/1000 | Loss: 0.00017718
Iteration 130/1000 | Loss: 0.00009838
Iteration 131/1000 | Loss: 0.00002336
Iteration 132/1000 | Loss: 0.00002272
Iteration 133/1000 | Loss: 0.00016477
Iteration 134/1000 | Loss: 0.00021512
Iteration 135/1000 | Loss: 0.00002217
Iteration 136/1000 | Loss: 0.00016920
Iteration 137/1000 | Loss: 0.00027059
Iteration 138/1000 | Loss: 0.00003046
Iteration 139/1000 | Loss: 0.00002616
Iteration 140/1000 | Loss: 0.00009118
Iteration 141/1000 | Loss: 0.00002628
Iteration 142/1000 | Loss: 0.00002194
Iteration 143/1000 | Loss: 0.00002090
Iteration 144/1000 | Loss: 0.00001976
Iteration 145/1000 | Loss: 0.00002329
Iteration 146/1000 | Loss: 0.00002000
Iteration 147/1000 | Loss: 0.00001867
Iteration 148/1000 | Loss: 0.00001819
Iteration 149/1000 | Loss: 0.00001785
Iteration 150/1000 | Loss: 0.00001766
Iteration 151/1000 | Loss: 0.00002188
Iteration 152/1000 | Loss: 0.00001756
Iteration 153/1000 | Loss: 0.00001722
Iteration 154/1000 | Loss: 0.00001701
Iteration 155/1000 | Loss: 0.00001699
Iteration 156/1000 | Loss: 0.00001698
Iteration 157/1000 | Loss: 0.00001697
Iteration 158/1000 | Loss: 0.00001688
Iteration 159/1000 | Loss: 0.00001687
Iteration 160/1000 | Loss: 0.00001686
Iteration 161/1000 | Loss: 0.00001685
Iteration 162/1000 | Loss: 0.00001684
Iteration 163/1000 | Loss: 0.00001683
Iteration 164/1000 | Loss: 0.00001682
Iteration 165/1000 | Loss: 0.00001681
Iteration 166/1000 | Loss: 0.00001681
Iteration 167/1000 | Loss: 0.00001681
Iteration 168/1000 | Loss: 0.00001679
Iteration 169/1000 | Loss: 0.00001672
Iteration 170/1000 | Loss: 0.00001671
Iteration 171/1000 | Loss: 0.00001670
Iteration 172/1000 | Loss: 0.00001668
Iteration 173/1000 | Loss: 0.00001667
Iteration 174/1000 | Loss: 0.00001665
Iteration 175/1000 | Loss: 0.00001664
Iteration 176/1000 | Loss: 0.00001664
Iteration 177/1000 | Loss: 0.00001663
Iteration 178/1000 | Loss: 0.00001663
Iteration 179/1000 | Loss: 0.00001662
Iteration 180/1000 | Loss: 0.00001662
Iteration 181/1000 | Loss: 0.00001662
Iteration 182/1000 | Loss: 0.00001661
Iteration 183/1000 | Loss: 0.00001661
Iteration 184/1000 | Loss: 0.00001661
Iteration 185/1000 | Loss: 0.00001661
Iteration 186/1000 | Loss: 0.00001660
Iteration 187/1000 | Loss: 0.00001659
Iteration 188/1000 | Loss: 0.00001659
Iteration 189/1000 | Loss: 0.00001659
Iteration 190/1000 | Loss: 0.00001659
Iteration 191/1000 | Loss: 0.00001659
Iteration 192/1000 | Loss: 0.00001659
Iteration 193/1000 | Loss: 0.00001659
Iteration 194/1000 | Loss: 0.00001658
Iteration 195/1000 | Loss: 0.00001658
Iteration 196/1000 | Loss: 0.00001658
Iteration 197/1000 | Loss: 0.00001658
Iteration 198/1000 | Loss: 0.00001658
Iteration 199/1000 | Loss: 0.00001658
Iteration 200/1000 | Loss: 0.00001658
Iteration 201/1000 | Loss: 0.00001658
Iteration 202/1000 | Loss: 0.00001658
Iteration 203/1000 | Loss: 0.00001658
Iteration 204/1000 | Loss: 0.00001657
Iteration 205/1000 | Loss: 0.00001657
Iteration 206/1000 | Loss: 0.00001657
Iteration 207/1000 | Loss: 0.00001657
Iteration 208/1000 | Loss: 0.00001657
Iteration 209/1000 | Loss: 0.00001657
Iteration 210/1000 | Loss: 0.00001657
Iteration 211/1000 | Loss: 0.00001657
Iteration 212/1000 | Loss: 0.00001656
Iteration 213/1000 | Loss: 0.00001656
Iteration 214/1000 | Loss: 0.00001656
Iteration 215/1000 | Loss: 0.00001656
Iteration 216/1000 | Loss: 0.00001656
Iteration 217/1000 | Loss: 0.00001655
Iteration 218/1000 | Loss: 0.00001655
Iteration 219/1000 | Loss: 0.00001655
Iteration 220/1000 | Loss: 0.00001655
Iteration 221/1000 | Loss: 0.00001654
Iteration 222/1000 | Loss: 0.00001654
Iteration 223/1000 | Loss: 0.00001654
Iteration 224/1000 | Loss: 0.00001654
Iteration 225/1000 | Loss: 0.00001654
Iteration 226/1000 | Loss: 0.00001654
Iteration 227/1000 | Loss: 0.00001654
Iteration 228/1000 | Loss: 0.00001654
Iteration 229/1000 | Loss: 0.00001654
Iteration 230/1000 | Loss: 0.00001654
Iteration 231/1000 | Loss: 0.00001653
Iteration 232/1000 | Loss: 0.00001653
Iteration 233/1000 | Loss: 0.00001653
Iteration 234/1000 | Loss: 0.00001653
Iteration 235/1000 | Loss: 0.00001653
Iteration 236/1000 | Loss: 0.00001653
Iteration 237/1000 | Loss: 0.00001652
Iteration 238/1000 | Loss: 0.00001652
Iteration 239/1000 | Loss: 0.00001652
Iteration 240/1000 | Loss: 0.00001652
Iteration 241/1000 | Loss: 0.00001652
Iteration 242/1000 | Loss: 0.00001652
Iteration 243/1000 | Loss: 0.00001652
Iteration 244/1000 | Loss: 0.00001652
Iteration 245/1000 | Loss: 0.00001652
Iteration 246/1000 | Loss: 0.00001652
Iteration 247/1000 | Loss: 0.00001652
Iteration 248/1000 | Loss: 0.00001652
Iteration 249/1000 | Loss: 0.00001652
Iteration 250/1000 | Loss: 0.00001652
Iteration 251/1000 | Loss: 0.00001652
Iteration 252/1000 | Loss: 0.00001652
Iteration 253/1000 | Loss: 0.00001652
Iteration 254/1000 | Loss: 0.00001652
Iteration 255/1000 | Loss: 0.00001652
Iteration 256/1000 | Loss: 0.00001652
Iteration 257/1000 | Loss: 0.00001652
Iteration 258/1000 | Loss: 0.00001652
Iteration 259/1000 | Loss: 0.00001652
Iteration 260/1000 | Loss: 0.00001652
Iteration 261/1000 | Loss: 0.00001652
Iteration 262/1000 | Loss: 0.00001652
Iteration 263/1000 | Loss: 0.00001652
Iteration 264/1000 | Loss: 0.00001652
Iteration 265/1000 | Loss: 0.00001652
Iteration 266/1000 | Loss: 0.00001652
Iteration 267/1000 | Loss: 0.00001652
Iteration 268/1000 | Loss: 0.00001652
Iteration 269/1000 | Loss: 0.00001652
Iteration 270/1000 | Loss: 0.00001652
Iteration 271/1000 | Loss: 0.00001652
Iteration 272/1000 | Loss: 0.00001652
Iteration 273/1000 | Loss: 0.00001652
Iteration 274/1000 | Loss: 0.00001652
Iteration 275/1000 | Loss: 0.00001652
Iteration 276/1000 | Loss: 0.00001652
Iteration 277/1000 | Loss: 0.00001652
Iteration 278/1000 | Loss: 0.00001652
Iteration 279/1000 | Loss: 0.00001652
Iteration 280/1000 | Loss: 0.00001652
Iteration 281/1000 | Loss: 0.00001652
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 281. Stopping optimization.
Last 5 losses: [1.6515059542143717e-05, 1.6515059542143717e-05, 1.6515059542143717e-05, 1.6515059542143717e-05, 1.6515059542143717e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6515059542143717e-05

Optimization complete. Final v2v error: 3.322685718536377 mm

Highest mean error: 5.585496425628662 mm for frame 101

Lowest mean error: 2.925112724304199 mm for frame 124

Saving results

Total time: 4486.766370296478
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1038/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1038.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1038
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00869215
Iteration 2/25 | Loss: 0.00137673
Iteration 3/25 | Loss: 0.00129213
Iteration 4/25 | Loss: 0.00128184
Iteration 5/25 | Loss: 0.00127907
Iteration 6/25 | Loss: 0.00127907
Iteration 7/25 | Loss: 0.00127907
Iteration 8/25 | Loss: 0.00127907
Iteration 9/25 | Loss: 0.00127907
Iteration 10/25 | Loss: 0.00127907
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0012790715554729104, 0.0012790715554729104, 0.0012790715554729104, 0.0012790715554729104, 0.0012790715554729104]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012790715554729104

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.82016349
Iteration 2/25 | Loss: 0.00088750
Iteration 3/25 | Loss: 0.00088750
Iteration 4/25 | Loss: 0.00088749
Iteration 5/25 | Loss: 0.00088749
Iteration 6/25 | Loss: 0.00088749
Iteration 7/25 | Loss: 0.00088749
Iteration 8/25 | Loss: 0.00088749
Iteration 9/25 | Loss: 0.00088749
Iteration 10/25 | Loss: 0.00088749
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0008874924387782812, 0.0008874924387782812, 0.0008874924387782812, 0.0008874924387782812, 0.0008874924387782812]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008874924387782812

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00088749
Iteration 2/1000 | Loss: 0.00002964
Iteration 3/1000 | Loss: 0.00001830
Iteration 4/1000 | Loss: 0.00001565
Iteration 5/1000 | Loss: 0.00001444
Iteration 6/1000 | Loss: 0.00001363
Iteration 7/1000 | Loss: 0.00001320
Iteration 8/1000 | Loss: 0.00001306
Iteration 9/1000 | Loss: 0.00001275
Iteration 10/1000 | Loss: 0.00001244
Iteration 11/1000 | Loss: 0.00001232
Iteration 12/1000 | Loss: 0.00001227
Iteration 13/1000 | Loss: 0.00001222
Iteration 14/1000 | Loss: 0.00001214
Iteration 15/1000 | Loss: 0.00001210
Iteration 16/1000 | Loss: 0.00001208
Iteration 17/1000 | Loss: 0.00001207
Iteration 18/1000 | Loss: 0.00001205
Iteration 19/1000 | Loss: 0.00001202
Iteration 20/1000 | Loss: 0.00001200
Iteration 21/1000 | Loss: 0.00001200
Iteration 22/1000 | Loss: 0.00001197
Iteration 23/1000 | Loss: 0.00001196
Iteration 24/1000 | Loss: 0.00001196
Iteration 25/1000 | Loss: 0.00001195
Iteration 26/1000 | Loss: 0.00001195
Iteration 27/1000 | Loss: 0.00001192
Iteration 28/1000 | Loss: 0.00001191
Iteration 29/1000 | Loss: 0.00001190
Iteration 30/1000 | Loss: 0.00001189
Iteration 31/1000 | Loss: 0.00001185
Iteration 32/1000 | Loss: 0.00001181
Iteration 33/1000 | Loss: 0.00001177
Iteration 34/1000 | Loss: 0.00001172
Iteration 35/1000 | Loss: 0.00001171
Iteration 36/1000 | Loss: 0.00001167
Iteration 37/1000 | Loss: 0.00001166
Iteration 38/1000 | Loss: 0.00001166
Iteration 39/1000 | Loss: 0.00001166
Iteration 40/1000 | Loss: 0.00001166
Iteration 41/1000 | Loss: 0.00001164
Iteration 42/1000 | Loss: 0.00001161
Iteration 43/1000 | Loss: 0.00001161
Iteration 44/1000 | Loss: 0.00001159
Iteration 45/1000 | Loss: 0.00001159
Iteration 46/1000 | Loss: 0.00001157
Iteration 47/1000 | Loss: 0.00001157
Iteration 48/1000 | Loss: 0.00001156
Iteration 49/1000 | Loss: 0.00001155
Iteration 50/1000 | Loss: 0.00001155
Iteration 51/1000 | Loss: 0.00001153
Iteration 52/1000 | Loss: 0.00001153
Iteration 53/1000 | Loss: 0.00001152
Iteration 54/1000 | Loss: 0.00001151
Iteration 55/1000 | Loss: 0.00001150
Iteration 56/1000 | Loss: 0.00001150
Iteration 57/1000 | Loss: 0.00001149
Iteration 58/1000 | Loss: 0.00001149
Iteration 59/1000 | Loss: 0.00001148
Iteration 60/1000 | Loss: 0.00001148
Iteration 61/1000 | Loss: 0.00001147
Iteration 62/1000 | Loss: 0.00001147
Iteration 63/1000 | Loss: 0.00001146
Iteration 64/1000 | Loss: 0.00001146
Iteration 65/1000 | Loss: 0.00001145
Iteration 66/1000 | Loss: 0.00001145
Iteration 67/1000 | Loss: 0.00001145
Iteration 68/1000 | Loss: 0.00001144
Iteration 69/1000 | Loss: 0.00001144
Iteration 70/1000 | Loss: 0.00001143
Iteration 71/1000 | Loss: 0.00001143
Iteration 72/1000 | Loss: 0.00001142
Iteration 73/1000 | Loss: 0.00001141
Iteration 74/1000 | Loss: 0.00001141
Iteration 75/1000 | Loss: 0.00001141
Iteration 76/1000 | Loss: 0.00001140
Iteration 77/1000 | Loss: 0.00001140
Iteration 78/1000 | Loss: 0.00001140
Iteration 79/1000 | Loss: 0.00001140
Iteration 80/1000 | Loss: 0.00001140
Iteration 81/1000 | Loss: 0.00001140
Iteration 82/1000 | Loss: 0.00001140
Iteration 83/1000 | Loss: 0.00001139
Iteration 84/1000 | Loss: 0.00001139
Iteration 85/1000 | Loss: 0.00001139
Iteration 86/1000 | Loss: 0.00001139
Iteration 87/1000 | Loss: 0.00001139
Iteration 88/1000 | Loss: 0.00001138
Iteration 89/1000 | Loss: 0.00001138
Iteration 90/1000 | Loss: 0.00001138
Iteration 91/1000 | Loss: 0.00001138
Iteration 92/1000 | Loss: 0.00001138
Iteration 93/1000 | Loss: 0.00001138
Iteration 94/1000 | Loss: 0.00001138
Iteration 95/1000 | Loss: 0.00001137
Iteration 96/1000 | Loss: 0.00001137
Iteration 97/1000 | Loss: 0.00001137
Iteration 98/1000 | Loss: 0.00001137
Iteration 99/1000 | Loss: 0.00001137
Iteration 100/1000 | Loss: 0.00001137
Iteration 101/1000 | Loss: 0.00001137
Iteration 102/1000 | Loss: 0.00001137
Iteration 103/1000 | Loss: 0.00001136
Iteration 104/1000 | Loss: 0.00001136
Iteration 105/1000 | Loss: 0.00001136
Iteration 106/1000 | Loss: 0.00001136
Iteration 107/1000 | Loss: 0.00001136
Iteration 108/1000 | Loss: 0.00001136
Iteration 109/1000 | Loss: 0.00001136
Iteration 110/1000 | Loss: 0.00001136
Iteration 111/1000 | Loss: 0.00001136
Iteration 112/1000 | Loss: 0.00001136
Iteration 113/1000 | Loss: 0.00001135
Iteration 114/1000 | Loss: 0.00001135
Iteration 115/1000 | Loss: 0.00001135
Iteration 116/1000 | Loss: 0.00001135
Iteration 117/1000 | Loss: 0.00001135
Iteration 118/1000 | Loss: 0.00001135
Iteration 119/1000 | Loss: 0.00001135
Iteration 120/1000 | Loss: 0.00001135
Iteration 121/1000 | Loss: 0.00001135
Iteration 122/1000 | Loss: 0.00001135
Iteration 123/1000 | Loss: 0.00001134
Iteration 124/1000 | Loss: 0.00001134
Iteration 125/1000 | Loss: 0.00001134
Iteration 126/1000 | Loss: 0.00001134
Iteration 127/1000 | Loss: 0.00001134
Iteration 128/1000 | Loss: 0.00001134
Iteration 129/1000 | Loss: 0.00001134
Iteration 130/1000 | Loss: 0.00001134
Iteration 131/1000 | Loss: 0.00001134
Iteration 132/1000 | Loss: 0.00001133
Iteration 133/1000 | Loss: 0.00001133
Iteration 134/1000 | Loss: 0.00001133
Iteration 135/1000 | Loss: 0.00001133
Iteration 136/1000 | Loss: 0.00001133
Iteration 137/1000 | Loss: 0.00001133
Iteration 138/1000 | Loss: 0.00001133
Iteration 139/1000 | Loss: 0.00001133
Iteration 140/1000 | Loss: 0.00001133
Iteration 141/1000 | Loss: 0.00001133
Iteration 142/1000 | Loss: 0.00001133
Iteration 143/1000 | Loss: 0.00001133
Iteration 144/1000 | Loss: 0.00001132
Iteration 145/1000 | Loss: 0.00001132
Iteration 146/1000 | Loss: 0.00001132
Iteration 147/1000 | Loss: 0.00001132
Iteration 148/1000 | Loss: 0.00001132
Iteration 149/1000 | Loss: 0.00001132
Iteration 150/1000 | Loss: 0.00001132
Iteration 151/1000 | Loss: 0.00001132
Iteration 152/1000 | Loss: 0.00001131
Iteration 153/1000 | Loss: 0.00001131
Iteration 154/1000 | Loss: 0.00001131
Iteration 155/1000 | Loss: 0.00001130
Iteration 156/1000 | Loss: 0.00001130
Iteration 157/1000 | Loss: 0.00001130
Iteration 158/1000 | Loss: 0.00001130
Iteration 159/1000 | Loss: 0.00001130
Iteration 160/1000 | Loss: 0.00001130
Iteration 161/1000 | Loss: 0.00001130
Iteration 162/1000 | Loss: 0.00001130
Iteration 163/1000 | Loss: 0.00001130
Iteration 164/1000 | Loss: 0.00001130
Iteration 165/1000 | Loss: 0.00001130
Iteration 166/1000 | Loss: 0.00001130
Iteration 167/1000 | Loss: 0.00001130
Iteration 168/1000 | Loss: 0.00001130
Iteration 169/1000 | Loss: 0.00001130
Iteration 170/1000 | Loss: 0.00001130
Iteration 171/1000 | Loss: 0.00001130
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 171. Stopping optimization.
Last 5 losses: [1.1300660844426602e-05, 1.1300660844426602e-05, 1.1300660844426602e-05, 1.1300660844426602e-05, 1.1300660844426602e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1300660844426602e-05

Optimization complete. Final v2v error: 2.8700733184814453 mm

Highest mean error: 3.240600824356079 mm for frame 231

Lowest mean error: 2.6685731410980225 mm for frame 75

Saving results

Total time: 1333.2074522972107
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1025
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00489429
Iteration 2/25 | Loss: 0.00136823
Iteration 3/25 | Loss: 0.00129371
Iteration 4/25 | Loss: 0.00127997
Iteration 5/25 | Loss: 0.00127485
Iteration 6/25 | Loss: 0.00127424
Iteration 7/25 | Loss: 0.00127424
Iteration 8/25 | Loss: 0.00127424
Iteration 9/25 | Loss: 0.00127424
Iteration 10/25 | Loss: 0.00127424
Iteration 11/25 | Loss: 0.00127424
Iteration 12/25 | Loss: 0.00127424
Iteration 13/25 | Loss: 0.00127424
Iteration 14/25 | Loss: 0.00127424
Iteration 15/25 | Loss: 0.00127424
Iteration 16/25 | Loss: 0.00127424
Iteration 17/25 | Loss: 0.00127424
Iteration 18/25 | Loss: 0.00127424
Iteration 19/25 | Loss: 0.00127424
Iteration 20/25 | Loss: 0.00127424
Iteration 21/25 | Loss: 0.00127424
Iteration 22/25 | Loss: 0.00127424
Iteration 23/25 | Loss: 0.00127424
Iteration 24/25 | Loss: 0.00127424
Iteration 25/25 | Loss: 0.00127424

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.50654507
Iteration 2/25 | Loss: 0.00085338
Iteration 3/25 | Loss: 0.00085338
Iteration 4/25 | Loss: 0.00085338
Iteration 5/25 | Loss: 0.00085338
Iteration 6/25 | Loss: 0.00085338
Iteration 7/25 | Loss: 0.00085338
Iteration 8/25 | Loss: 0.00085338
Iteration 9/25 | Loss: 0.00085338
Iteration 10/25 | Loss: 0.00085338
Iteration 11/25 | Loss: 0.00085338
Iteration 12/25 | Loss: 0.00085338
Iteration 13/25 | Loss: 0.00085338
Iteration 14/25 | Loss: 0.00085338
Iteration 15/25 | Loss: 0.00085338
Iteration 16/25 | Loss: 0.00085338
Iteration 17/25 | Loss: 0.00085338
Iteration 18/25 | Loss: 0.00085338
Iteration 19/25 | Loss: 0.00085338
Iteration 20/25 | Loss: 0.00085338
Iteration 21/25 | Loss: 0.00085338
Iteration 22/25 | Loss: 0.00085338
Iteration 23/25 | Loss: 0.00085338
Iteration 24/25 | Loss: 0.00085338
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0008533798973076046, 0.0008533798973076046, 0.0008533798973076046, 0.0008533798973076046, 0.0008533798973076046]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008533798973076046

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085338
Iteration 2/1000 | Loss: 0.00002993
Iteration 3/1000 | Loss: 0.00001882
Iteration 4/1000 | Loss: 0.00001734
Iteration 5/1000 | Loss: 0.00001644
Iteration 6/1000 | Loss: 0.00001593
Iteration 7/1000 | Loss: 0.00001550
Iteration 8/1000 | Loss: 0.00001512
Iteration 9/1000 | Loss: 0.00001486
Iteration 10/1000 | Loss: 0.00001468
Iteration 11/1000 | Loss: 0.00001462
Iteration 12/1000 | Loss: 0.00001462
Iteration 13/1000 | Loss: 0.00001458
Iteration 14/1000 | Loss: 0.00001441
Iteration 15/1000 | Loss: 0.00001435
Iteration 16/1000 | Loss: 0.00001434
Iteration 17/1000 | Loss: 0.00001427
Iteration 18/1000 | Loss: 0.00001417
Iteration 19/1000 | Loss: 0.00001414
Iteration 20/1000 | Loss: 0.00001412
Iteration 21/1000 | Loss: 0.00001411
Iteration 22/1000 | Loss: 0.00001411
Iteration 23/1000 | Loss: 0.00001409
Iteration 24/1000 | Loss: 0.00001408
Iteration 25/1000 | Loss: 0.00001407
Iteration 26/1000 | Loss: 0.00001406
Iteration 27/1000 | Loss: 0.00001406
Iteration 28/1000 | Loss: 0.00001404
Iteration 29/1000 | Loss: 0.00001402
Iteration 30/1000 | Loss: 0.00001402
Iteration 31/1000 | Loss: 0.00001400
Iteration 32/1000 | Loss: 0.00001400
Iteration 33/1000 | Loss: 0.00001399
Iteration 34/1000 | Loss: 0.00001399
Iteration 35/1000 | Loss: 0.00001399
Iteration 36/1000 | Loss: 0.00001399
Iteration 37/1000 | Loss: 0.00001399
Iteration 38/1000 | Loss: 0.00001398
Iteration 39/1000 | Loss: 0.00001396
Iteration 40/1000 | Loss: 0.00001396
Iteration 41/1000 | Loss: 0.00001394
Iteration 42/1000 | Loss: 0.00001394
Iteration 43/1000 | Loss: 0.00001394
Iteration 44/1000 | Loss: 0.00001393
Iteration 45/1000 | Loss: 0.00001391
Iteration 46/1000 | Loss: 0.00001389
Iteration 47/1000 | Loss: 0.00001389
Iteration 48/1000 | Loss: 0.00001388
Iteration 49/1000 | Loss: 0.00001388
Iteration 50/1000 | Loss: 0.00001388
Iteration 51/1000 | Loss: 0.00001387
Iteration 52/1000 | Loss: 0.00001387
Iteration 53/1000 | Loss: 0.00001386
Iteration 54/1000 | Loss: 0.00001386
Iteration 55/1000 | Loss: 0.00001386
Iteration 56/1000 | Loss: 0.00001386
Iteration 57/1000 | Loss: 0.00001386
Iteration 58/1000 | Loss: 0.00001385
Iteration 59/1000 | Loss: 0.00001385
Iteration 60/1000 | Loss: 0.00001385
Iteration 61/1000 | Loss: 0.00001385
Iteration 62/1000 | Loss: 0.00001385
Iteration 63/1000 | Loss: 0.00001385
Iteration 64/1000 | Loss: 0.00001385
Iteration 65/1000 | Loss: 0.00001384
Iteration 66/1000 | Loss: 0.00001384
Iteration 67/1000 | Loss: 0.00001384
Iteration 68/1000 | Loss: 0.00001383
Iteration 69/1000 | Loss: 0.00001383
Iteration 70/1000 | Loss: 0.00001383
Iteration 71/1000 | Loss: 0.00001383
Iteration 72/1000 | Loss: 0.00001382
Iteration 73/1000 | Loss: 0.00001382
Iteration 74/1000 | Loss: 0.00001382
Iteration 75/1000 | Loss: 0.00001382
Iteration 76/1000 | Loss: 0.00001382
Iteration 77/1000 | Loss: 0.00001382
Iteration 78/1000 | Loss: 0.00001382
Iteration 79/1000 | Loss: 0.00001382
Iteration 80/1000 | Loss: 0.00001382
Iteration 81/1000 | Loss: 0.00001382
Iteration 82/1000 | Loss: 0.00001382
Iteration 83/1000 | Loss: 0.00001382
Iteration 84/1000 | Loss: 0.00001382
Iteration 85/1000 | Loss: 0.00001382
Iteration 86/1000 | Loss: 0.00001382
Iteration 87/1000 | Loss: 0.00001382
Iteration 88/1000 | Loss: 0.00001382
Iteration 89/1000 | Loss: 0.00001382
Iteration 90/1000 | Loss: 0.00001382
Iteration 91/1000 | Loss: 0.00001382
Iteration 92/1000 | Loss: 0.00001382
Iteration 93/1000 | Loss: 0.00001382
Iteration 94/1000 | Loss: 0.00001382
Iteration 95/1000 | Loss: 0.00001382
Iteration 96/1000 | Loss: 0.00001382
Iteration 97/1000 | Loss: 0.00001382
Iteration 98/1000 | Loss: 0.00001382
Iteration 99/1000 | Loss: 0.00001382
Iteration 100/1000 | Loss: 0.00001382
Iteration 101/1000 | Loss: 0.00001382
Iteration 102/1000 | Loss: 0.00001382
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.382104164804332e-05, 1.382104164804332e-05, 1.382104164804332e-05, 1.382104164804332e-05, 1.382104164804332e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.382104164804332e-05

Optimization complete. Final v2v error: 3.216637372970581 mm

Highest mean error: 3.433151960372925 mm for frame 169

Lowest mean error: 3.1227400302886963 mm for frame 99

Saving results

Total time: 1048.6245610713959
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1008
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00969784
Iteration 2/25 | Loss: 0.00231552
Iteration 3/25 | Loss: 0.00180225
Iteration 4/25 | Loss: 0.00169610
Iteration 5/25 | Loss: 0.00169277
Iteration 6/25 | Loss: 0.00167112
Iteration 7/25 | Loss: 0.00172610
Iteration 8/25 | Loss: 0.00165148
Iteration 9/25 | Loss: 0.00153997
Iteration 10/25 | Loss: 0.00146361
Iteration 11/25 | Loss: 0.00143324
Iteration 12/25 | Loss: 0.00143604
Iteration 13/25 | Loss: 0.00144803
Iteration 14/25 | Loss: 0.00143046
Iteration 15/25 | Loss: 0.00141330
Iteration 16/25 | Loss: 0.00140264
Iteration 17/25 | Loss: 0.00139341
Iteration 18/25 | Loss: 0.00139114
Iteration 19/25 | Loss: 0.00139114
Iteration 20/25 | Loss: 0.00138645
Iteration 21/25 | Loss: 0.00137481
Iteration 22/25 | Loss: 0.00136589
Iteration 23/25 | Loss: 0.00136428
Iteration 24/25 | Loss: 0.00136699
Iteration 25/25 | Loss: 0.00136556

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42412007
Iteration 2/25 | Loss: 0.00119718
Iteration 3/25 | Loss: 0.00106262
Iteration 4/25 | Loss: 0.00106262
Iteration 5/25 | Loss: 0.00106262
Iteration 6/25 | Loss: 0.00106262
Iteration 7/25 | Loss: 0.00106262
Iteration 8/25 | Loss: 0.00106262
Iteration 9/25 | Loss: 0.00106262
Iteration 10/25 | Loss: 0.00106262
Iteration 11/25 | Loss: 0.00106262
Iteration 12/25 | Loss: 0.00106262
Iteration 13/25 | Loss: 0.00106262
Iteration 14/25 | Loss: 0.00106262
Iteration 15/25 | Loss: 0.00106262
Iteration 16/25 | Loss: 0.00106262
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010626158909872174, 0.0010626158909872174, 0.0010626158909872174, 0.0010626158909872174, 0.0010626158909872174]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010626158909872174

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00106262
Iteration 2/1000 | Loss: 0.00005741
Iteration 3/1000 | Loss: 0.00004931
Iteration 4/1000 | Loss: 0.00005862
Iteration 5/1000 | Loss: 0.00019931
Iteration 6/1000 | Loss: 0.00006790
Iteration 7/1000 | Loss: 0.00006881
Iteration 8/1000 | Loss: 0.00004680
Iteration 9/1000 | Loss: 0.00004746
Iteration 10/1000 | Loss: 0.00005027
Iteration 11/1000 | Loss: 0.00004151
Iteration 12/1000 | Loss: 0.00004668
Iteration 13/1000 | Loss: 0.00004109
Iteration 14/1000 | Loss: 0.00003641
Iteration 15/1000 | Loss: 0.00003489
Iteration 16/1000 | Loss: 0.00003599
Iteration 17/1000 | Loss: 0.00003744
Iteration 18/1000 | Loss: 0.00003331
Iteration 19/1000 | Loss: 0.00004449
Iteration 20/1000 | Loss: 0.00003413
Iteration 21/1000 | Loss: 0.00004997
Iteration 22/1000 | Loss: 0.00003106
Iteration 23/1000 | Loss: 0.00002809
Iteration 24/1000 | Loss: 0.00002672
Iteration 25/1000 | Loss: 0.00004315
Iteration 26/1000 | Loss: 0.00002753
Iteration 27/1000 | Loss: 0.00032258
Iteration 28/1000 | Loss: 0.00015680
Iteration 29/1000 | Loss: 0.00003639
Iteration 30/1000 | Loss: 0.00003035
Iteration 31/1000 | Loss: 0.00003003
Iteration 32/1000 | Loss: 0.00002797
Iteration 33/1000 | Loss: 0.00030524
Iteration 34/1000 | Loss: 0.00003596
Iteration 35/1000 | Loss: 0.00002458
Iteration 36/1000 | Loss: 0.00002282
Iteration 37/1000 | Loss: 0.00002205
Iteration 38/1000 | Loss: 0.00002134
Iteration 39/1000 | Loss: 0.00002060
Iteration 40/1000 | Loss: 0.00002017
Iteration 41/1000 | Loss: 0.00001994
Iteration 42/1000 | Loss: 0.00001972
Iteration 43/1000 | Loss: 0.00001962
Iteration 44/1000 | Loss: 0.00003477
Iteration 45/1000 | Loss: 0.00002406
Iteration 46/1000 | Loss: 0.00012615
Iteration 47/1000 | Loss: 0.00003974
Iteration 48/1000 | Loss: 0.00003470
Iteration 49/1000 | Loss: 0.00002928
Iteration 50/1000 | Loss: 0.00003499
Iteration 51/1000 | Loss: 0.00002139
Iteration 52/1000 | Loss: 0.00002256
Iteration 53/1000 | Loss: 0.00003286
Iteration 54/1000 | Loss: 0.00002120
Iteration 55/1000 | Loss: 0.00002005
Iteration 56/1000 | Loss: 0.00001925
Iteration 57/1000 | Loss: 0.00001906
Iteration 58/1000 | Loss: 0.00001906
Iteration 59/1000 | Loss: 0.00001906
Iteration 60/1000 | Loss: 0.00001905
Iteration 61/1000 | Loss: 0.00001904
Iteration 62/1000 | Loss: 0.00001904
Iteration 63/1000 | Loss: 0.00001903
Iteration 64/1000 | Loss: 0.00001903
Iteration 65/1000 | Loss: 0.00001901
Iteration 66/1000 | Loss: 0.00001900
Iteration 67/1000 | Loss: 0.00001900
Iteration 68/1000 | Loss: 0.00001900
Iteration 69/1000 | Loss: 0.00001899
Iteration 70/1000 | Loss: 0.00001899
Iteration 71/1000 | Loss: 0.00001899
Iteration 72/1000 | Loss: 0.00001896
Iteration 73/1000 | Loss: 0.00001896
Iteration 74/1000 | Loss: 0.00001895
Iteration 75/1000 | Loss: 0.00001895
Iteration 76/1000 | Loss: 0.00001894
Iteration 77/1000 | Loss: 0.00001894
Iteration 78/1000 | Loss: 0.00001894
Iteration 79/1000 | Loss: 0.00001894
Iteration 80/1000 | Loss: 0.00001894
Iteration 81/1000 | Loss: 0.00001894
Iteration 82/1000 | Loss: 0.00001893
Iteration 83/1000 | Loss: 0.00001893
Iteration 84/1000 | Loss: 0.00001893
Iteration 85/1000 | Loss: 0.00001893
Iteration 86/1000 | Loss: 0.00001893
Iteration 87/1000 | Loss: 0.00001892
Iteration 88/1000 | Loss: 0.00001892
Iteration 89/1000 | Loss: 0.00001892
Iteration 90/1000 | Loss: 0.00001892
Iteration 91/1000 | Loss: 0.00001891
Iteration 92/1000 | Loss: 0.00001891
Iteration 93/1000 | Loss: 0.00001889
Iteration 94/1000 | Loss: 0.00001889
Iteration 95/1000 | Loss: 0.00001888
Iteration 96/1000 | Loss: 0.00001887
Iteration 97/1000 | Loss: 0.00001886
Iteration 98/1000 | Loss: 0.00001886
Iteration 99/1000 | Loss: 0.00001886
Iteration 100/1000 | Loss: 0.00001886
Iteration 101/1000 | Loss: 0.00001886
Iteration 102/1000 | Loss: 0.00001885
Iteration 103/1000 | Loss: 0.00001885
Iteration 104/1000 | Loss: 0.00001885
Iteration 105/1000 | Loss: 0.00001884
Iteration 106/1000 | Loss: 0.00001883
Iteration 107/1000 | Loss: 0.00001882
Iteration 108/1000 | Loss: 0.00001882
Iteration 109/1000 | Loss: 0.00001882
Iteration 110/1000 | Loss: 0.00001882
Iteration 111/1000 | Loss: 0.00001881
Iteration 112/1000 | Loss: 0.00001881
Iteration 113/1000 | Loss: 0.00001881
Iteration 114/1000 | Loss: 0.00001881
Iteration 115/1000 | Loss: 0.00001881
Iteration 116/1000 | Loss: 0.00001880
Iteration 117/1000 | Loss: 0.00001880
Iteration 118/1000 | Loss: 0.00001880
Iteration 119/1000 | Loss: 0.00001880
Iteration 120/1000 | Loss: 0.00001879
Iteration 121/1000 | Loss: 0.00001879
Iteration 122/1000 | Loss: 0.00001879
Iteration 123/1000 | Loss: 0.00001879
Iteration 124/1000 | Loss: 0.00001879
Iteration 125/1000 | Loss: 0.00001879
Iteration 126/1000 | Loss: 0.00001879
Iteration 127/1000 | Loss: 0.00001879
Iteration 128/1000 | Loss: 0.00001879
Iteration 129/1000 | Loss: 0.00001879
Iteration 130/1000 | Loss: 0.00001879
Iteration 131/1000 | Loss: 0.00001878
Iteration 132/1000 | Loss: 0.00001878
Iteration 133/1000 | Loss: 0.00001878
Iteration 134/1000 | Loss: 0.00001878
Iteration 135/1000 | Loss: 0.00001878
Iteration 136/1000 | Loss: 0.00001878
Iteration 137/1000 | Loss: 0.00001878
Iteration 138/1000 | Loss: 0.00001878
Iteration 139/1000 | Loss: 0.00001877
Iteration 140/1000 | Loss: 0.00001877
Iteration 141/1000 | Loss: 0.00001877
Iteration 142/1000 | Loss: 0.00001877
Iteration 143/1000 | Loss: 0.00001876
Iteration 144/1000 | Loss: 0.00001876
Iteration 145/1000 | Loss: 0.00001876
Iteration 146/1000 | Loss: 0.00001876
Iteration 147/1000 | Loss: 0.00001875
Iteration 148/1000 | Loss: 0.00001875
Iteration 149/1000 | Loss: 0.00001875
Iteration 150/1000 | Loss: 0.00001874
Iteration 151/1000 | Loss: 0.00001874
Iteration 152/1000 | Loss: 0.00001874
Iteration 153/1000 | Loss: 0.00001874
Iteration 154/1000 | Loss: 0.00001874
Iteration 155/1000 | Loss: 0.00001874
Iteration 156/1000 | Loss: 0.00001874
Iteration 157/1000 | Loss: 0.00001874
Iteration 158/1000 | Loss: 0.00001874
Iteration 159/1000 | Loss: 0.00001874
Iteration 160/1000 | Loss: 0.00001874
Iteration 161/1000 | Loss: 0.00001874
Iteration 162/1000 | Loss: 0.00001874
Iteration 163/1000 | Loss: 0.00001874
Iteration 164/1000 | Loss: 0.00001874
Iteration 165/1000 | Loss: 0.00001874
Iteration 166/1000 | Loss: 0.00001874
Iteration 167/1000 | Loss: 0.00001874
Iteration 168/1000 | Loss: 0.00001874
Iteration 169/1000 | Loss: 0.00001874
Iteration 170/1000 | Loss: 0.00001874
Iteration 171/1000 | Loss: 0.00001874
Iteration 172/1000 | Loss: 0.00001874
Iteration 173/1000 | Loss: 0.00001874
Iteration 174/1000 | Loss: 0.00001874
Iteration 175/1000 | Loss: 0.00001874
Iteration 176/1000 | Loss: 0.00001874
Iteration 177/1000 | Loss: 0.00001874
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.873598012025468e-05, 1.873598012025468e-05, 1.873598012025468e-05, 1.873598012025468e-05, 1.873598012025468e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.873598012025468e-05

Optimization complete. Final v2v error: 3.685936212539673 mm

Highest mean error: 4.546224594116211 mm for frame 69

Lowest mean error: 3.279512643814087 mm for frame 5

Saving results

Total time: 4669.2553033828735
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1062/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1062.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1062
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00779693
Iteration 2/25 | Loss: 0.00151952
Iteration 3/25 | Loss: 0.00140966
Iteration 4/25 | Loss: 0.00137667
Iteration 5/25 | Loss: 0.00137239
Iteration 6/25 | Loss: 0.00138243
Iteration 7/25 | Loss: 0.00136733
Iteration 8/25 | Loss: 0.00137618
Iteration 9/25 | Loss: 0.00136304
Iteration 10/25 | Loss: 0.00136171
Iteration 11/25 | Loss: 0.00136113
Iteration 12/25 | Loss: 0.00136044
Iteration 13/25 | Loss: 0.00135996
Iteration 14/25 | Loss: 0.00135984
Iteration 15/25 | Loss: 0.00135980
Iteration 16/25 | Loss: 0.00135979
Iteration 17/25 | Loss: 0.00135979
Iteration 18/25 | Loss: 0.00135975
Iteration 19/25 | Loss: 0.00135973
Iteration 20/25 | Loss: 0.00135973
Iteration 21/25 | Loss: 0.00135973
Iteration 22/25 | Loss: 0.00135973
Iteration 23/25 | Loss: 0.00135973
Iteration 24/25 | Loss: 0.00135973
Iteration 25/25 | Loss: 0.00135973

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 7.93976498
Iteration 2/25 | Loss: 0.00085788
Iteration 3/25 | Loss: 0.00085781
Iteration 4/25 | Loss: 0.00085781
Iteration 5/25 | Loss: 0.00085781
Iteration 6/25 | Loss: 0.00085781
Iteration 7/25 | Loss: 0.00085781
Iteration 8/25 | Loss: 0.00085781
Iteration 9/25 | Loss: 0.00085781
Iteration 10/25 | Loss: 0.00085781
Iteration 11/25 | Loss: 0.00085781
Iteration 12/25 | Loss: 0.00085781
Iteration 13/25 | Loss: 0.00085781
Iteration 14/25 | Loss: 0.00085781
Iteration 15/25 | Loss: 0.00085781
Iteration 16/25 | Loss: 0.00085781
Iteration 17/25 | Loss: 0.00085781
Iteration 18/25 | Loss: 0.00085781
Iteration 19/25 | Loss: 0.00085781
Iteration 20/25 | Loss: 0.00085781
Iteration 21/25 | Loss: 0.00085781
Iteration 22/25 | Loss: 0.00085781
Iteration 23/25 | Loss: 0.00085781
Iteration 24/25 | Loss: 0.00085781
Iteration 25/25 | Loss: 0.00085781

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085781
Iteration 2/1000 | Loss: 0.00003778
Iteration 3/1000 | Loss: 0.00002535
Iteration 4/1000 | Loss: 0.00002265
Iteration 5/1000 | Loss: 0.00002131
Iteration 6/1000 | Loss: 0.00002054
Iteration 7/1000 | Loss: 0.00001989
Iteration 8/1000 | Loss: 0.00001962
Iteration 9/1000 | Loss: 0.00001927
Iteration 10/1000 | Loss: 0.00001894
Iteration 11/1000 | Loss: 0.00001873
Iteration 12/1000 | Loss: 0.00001865
Iteration 13/1000 | Loss: 0.00001852
Iteration 14/1000 | Loss: 0.00001850
Iteration 15/1000 | Loss: 0.00001836
Iteration 16/1000 | Loss: 0.00001835
Iteration 17/1000 | Loss: 0.00001830
Iteration 18/1000 | Loss: 0.00001828
Iteration 19/1000 | Loss: 0.00001828
Iteration 20/1000 | Loss: 0.00001827
Iteration 21/1000 | Loss: 0.00001823
Iteration 22/1000 | Loss: 0.00001817
Iteration 23/1000 | Loss: 0.00001817
Iteration 24/1000 | Loss: 0.00001816
Iteration 25/1000 | Loss: 0.00001816
Iteration 26/1000 | Loss: 0.00001816
Iteration 27/1000 | Loss: 0.00001815
Iteration 28/1000 | Loss: 0.00001814
Iteration 29/1000 | Loss: 0.00001814
Iteration 30/1000 | Loss: 0.00001813
Iteration 31/1000 | Loss: 0.00001812
Iteration 32/1000 | Loss: 0.00001812
Iteration 33/1000 | Loss: 0.00001811
Iteration 34/1000 | Loss: 0.00001811
Iteration 35/1000 | Loss: 0.00001810
Iteration 36/1000 | Loss: 0.00001810
Iteration 37/1000 | Loss: 0.00001809
Iteration 38/1000 | Loss: 0.00001809
Iteration 39/1000 | Loss: 0.00001809
Iteration 40/1000 | Loss: 0.00001808
Iteration 41/1000 | Loss: 0.00001808
Iteration 42/1000 | Loss: 0.00001807
Iteration 43/1000 | Loss: 0.00001807
Iteration 44/1000 | Loss: 0.00001806
Iteration 45/1000 | Loss: 0.00001806
Iteration 46/1000 | Loss: 0.00001805
Iteration 47/1000 | Loss: 0.00001805
Iteration 48/1000 | Loss: 0.00001802
Iteration 49/1000 | Loss: 0.00001802
Iteration 50/1000 | Loss: 0.00001802
Iteration 51/1000 | Loss: 0.00001801
Iteration 52/1000 | Loss: 0.00001801
Iteration 53/1000 | Loss: 0.00001801
Iteration 54/1000 | Loss: 0.00001800
Iteration 55/1000 | Loss: 0.00001799
Iteration 56/1000 | Loss: 0.00001799
Iteration 57/1000 | Loss: 0.00001798
Iteration 58/1000 | Loss: 0.00001798
Iteration 59/1000 | Loss: 0.00001798
Iteration 60/1000 | Loss: 0.00001797
Iteration 61/1000 | Loss: 0.00001797
Iteration 62/1000 | Loss: 0.00001797
Iteration 63/1000 | Loss: 0.00001796
Iteration 64/1000 | Loss: 0.00001796
Iteration 65/1000 | Loss: 0.00001795
Iteration 66/1000 | Loss: 0.00001794
Iteration 67/1000 | Loss: 0.00001794
Iteration 68/1000 | Loss: 0.00001793
Iteration 69/1000 | Loss: 0.00001793
Iteration 70/1000 | Loss: 0.00001793
Iteration 71/1000 | Loss: 0.00001793
Iteration 72/1000 | Loss: 0.00001792
Iteration 73/1000 | Loss: 0.00001792
Iteration 74/1000 | Loss: 0.00001792
Iteration 75/1000 | Loss: 0.00001791
Iteration 76/1000 | Loss: 0.00001791
Iteration 77/1000 | Loss: 0.00001789
Iteration 78/1000 | Loss: 0.00001789
Iteration 79/1000 | Loss: 0.00001789
Iteration 80/1000 | Loss: 0.00001789
Iteration 81/1000 | Loss: 0.00001789
Iteration 82/1000 | Loss: 0.00001789
Iteration 83/1000 | Loss: 0.00001789
Iteration 84/1000 | Loss: 0.00001789
Iteration 85/1000 | Loss: 0.00001789
Iteration 86/1000 | Loss: 0.00001787
Iteration 87/1000 | Loss: 0.00001787
Iteration 88/1000 | Loss: 0.00001787
Iteration 89/1000 | Loss: 0.00001787
Iteration 90/1000 | Loss: 0.00001787
Iteration 91/1000 | Loss: 0.00001787
Iteration 92/1000 | Loss: 0.00001786
Iteration 93/1000 | Loss: 0.00001786
Iteration 94/1000 | Loss: 0.00001786
Iteration 95/1000 | Loss: 0.00001786
Iteration 96/1000 | Loss: 0.00001786
Iteration 97/1000 | Loss: 0.00001786
Iteration 98/1000 | Loss: 0.00001785
Iteration 99/1000 | Loss: 0.00001785
Iteration 100/1000 | Loss: 0.00001785
Iteration 101/1000 | Loss: 0.00001785
Iteration 102/1000 | Loss: 0.00001785
Iteration 103/1000 | Loss: 0.00001784
Iteration 104/1000 | Loss: 0.00001784
Iteration 105/1000 | Loss: 0.00001784
Iteration 106/1000 | Loss: 0.00001783
Iteration 107/1000 | Loss: 0.00001783
Iteration 108/1000 | Loss: 0.00001783
Iteration 109/1000 | Loss: 0.00001783
Iteration 110/1000 | Loss: 0.00001783
Iteration 111/1000 | Loss: 0.00001782
Iteration 112/1000 | Loss: 0.00001782
Iteration 113/1000 | Loss: 0.00001782
Iteration 114/1000 | Loss: 0.00001782
Iteration 115/1000 | Loss: 0.00001781
Iteration 116/1000 | Loss: 0.00001781
Iteration 117/1000 | Loss: 0.00001780
Iteration 118/1000 | Loss: 0.00001780
Iteration 119/1000 | Loss: 0.00001780
Iteration 120/1000 | Loss: 0.00001780
Iteration 121/1000 | Loss: 0.00001780
Iteration 122/1000 | Loss: 0.00001780
Iteration 123/1000 | Loss: 0.00001780
Iteration 124/1000 | Loss: 0.00001779
Iteration 125/1000 | Loss: 0.00001779
Iteration 126/1000 | Loss: 0.00001779
Iteration 127/1000 | Loss: 0.00001779
Iteration 128/1000 | Loss: 0.00001778
Iteration 129/1000 | Loss: 0.00001778
Iteration 130/1000 | Loss: 0.00001778
Iteration 131/1000 | Loss: 0.00001778
Iteration 132/1000 | Loss: 0.00001778
Iteration 133/1000 | Loss: 0.00001778
Iteration 134/1000 | Loss: 0.00001778
Iteration 135/1000 | Loss: 0.00001778
Iteration 136/1000 | Loss: 0.00001778
Iteration 137/1000 | Loss: 0.00001778
Iteration 138/1000 | Loss: 0.00001778
Iteration 139/1000 | Loss: 0.00001778
Iteration 140/1000 | Loss: 0.00001778
Iteration 141/1000 | Loss: 0.00001778
Iteration 142/1000 | Loss: 0.00001778
Iteration 143/1000 | Loss: 0.00001778
Iteration 144/1000 | Loss: 0.00001778
Iteration 145/1000 | Loss: 0.00001778
Iteration 146/1000 | Loss: 0.00001778
Iteration 147/1000 | Loss: 0.00001778
Iteration 148/1000 | Loss: 0.00001778
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.777507713995874e-05, 1.777507713995874e-05, 1.777507713995874e-05, 1.777507713995874e-05, 1.777507713995874e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.777507713995874e-05

Optimization complete. Final v2v error: 3.522946834564209 mm

Highest mean error: 4.077796936035156 mm for frame 165

Lowest mean error: 3.018934488296509 mm for frame 94

Saving results

Total time: 1863.8986186981201
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1032/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1032.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1032
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00824577
Iteration 2/25 | Loss: 0.00194049
Iteration 3/25 | Loss: 0.00165848
Iteration 4/25 | Loss: 0.00164639
Iteration 5/25 | Loss: 0.00164458
Iteration 6/25 | Loss: 0.00164458
Iteration 7/25 | Loss: 0.00164458
Iteration 8/25 | Loss: 0.00164458
Iteration 9/25 | Loss: 0.00164458
Iteration 10/25 | Loss: 0.00164458
Iteration 11/25 | Loss: 0.00164458
Iteration 12/25 | Loss: 0.00164458
Iteration 13/25 | Loss: 0.00164458
Iteration 14/25 | Loss: 0.00164458
Iteration 15/25 | Loss: 0.00164458
Iteration 16/25 | Loss: 0.00164458
Iteration 17/25 | Loss: 0.00164458
Iteration 18/25 | Loss: 0.00164458
Iteration 19/25 | Loss: 0.00164458
Iteration 20/25 | Loss: 0.00164458
Iteration 21/25 | Loss: 0.00164458
Iteration 22/25 | Loss: 0.00164458
Iteration 23/25 | Loss: 0.00164458
Iteration 24/25 | Loss: 0.00164458
Iteration 25/25 | Loss: 0.00164458

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.38411358
Iteration 2/25 | Loss: 0.00126181
Iteration 3/25 | Loss: 0.00126181
Iteration 4/25 | Loss: 0.00126180
Iteration 5/25 | Loss: 0.00126180
Iteration 6/25 | Loss: 0.00126180
Iteration 7/25 | Loss: 0.00126180
Iteration 8/25 | Loss: 0.00126180
Iteration 9/25 | Loss: 0.00126180
Iteration 10/25 | Loss: 0.00126180
Iteration 11/25 | Loss: 0.00126180
Iteration 12/25 | Loss: 0.00126180
Iteration 13/25 | Loss: 0.00126180
Iteration 14/25 | Loss: 0.00126180
Iteration 15/25 | Loss: 0.00126180
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0012618028558790684, 0.0012618028558790684, 0.0012618028558790684, 0.0012618028558790684, 0.0012618028558790684]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012618028558790684

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00126180
Iteration 2/1000 | Loss: 0.00011122
Iteration 3/1000 | Loss: 0.00007061
Iteration 4/1000 | Loss: 0.00005518
Iteration 5/1000 | Loss: 0.00005169
Iteration 6/1000 | Loss: 0.00004970
Iteration 7/1000 | Loss: 0.00004836
Iteration 8/1000 | Loss: 0.00004627
Iteration 9/1000 | Loss: 0.00004531
Iteration 10/1000 | Loss: 0.00004479
Iteration 11/1000 | Loss: 0.00004412
Iteration 12/1000 | Loss: 0.00004359
Iteration 13/1000 | Loss: 0.00004300
Iteration 14/1000 | Loss: 0.00004254
Iteration 15/1000 | Loss: 0.00004219
Iteration 16/1000 | Loss: 0.00004201
Iteration 17/1000 | Loss: 0.00004180
Iteration 18/1000 | Loss: 0.00004175
Iteration 19/1000 | Loss: 0.00004161
Iteration 20/1000 | Loss: 0.00004161
Iteration 21/1000 | Loss: 0.00004153
Iteration 22/1000 | Loss: 0.00004150
Iteration 23/1000 | Loss: 0.00004148
Iteration 24/1000 | Loss: 0.00004147
Iteration 25/1000 | Loss: 0.00004147
Iteration 26/1000 | Loss: 0.00004147
Iteration 27/1000 | Loss: 0.00004147
Iteration 28/1000 | Loss: 0.00004144
Iteration 29/1000 | Loss: 0.00004140
Iteration 30/1000 | Loss: 0.00004139
Iteration 31/1000 | Loss: 0.00004138
Iteration 32/1000 | Loss: 0.00004125
Iteration 33/1000 | Loss: 0.00004124
Iteration 34/1000 | Loss: 0.00004121
Iteration 35/1000 | Loss: 0.00004119
Iteration 36/1000 | Loss: 0.00004118
Iteration 37/1000 | Loss: 0.00004118
Iteration 38/1000 | Loss: 0.00004118
Iteration 39/1000 | Loss: 0.00004118
Iteration 40/1000 | Loss: 0.00004118
Iteration 41/1000 | Loss: 0.00004118
Iteration 42/1000 | Loss: 0.00004118
Iteration 43/1000 | Loss: 0.00004118
Iteration 44/1000 | Loss: 0.00004117
Iteration 45/1000 | Loss: 0.00004117
Iteration 46/1000 | Loss: 0.00004117
Iteration 47/1000 | Loss: 0.00004117
Iteration 48/1000 | Loss: 0.00004116
Iteration 49/1000 | Loss: 0.00004116
Iteration 50/1000 | Loss: 0.00004115
Iteration 51/1000 | Loss: 0.00004114
Iteration 52/1000 | Loss: 0.00004114
Iteration 53/1000 | Loss: 0.00004113
Iteration 54/1000 | Loss: 0.00004112
Iteration 55/1000 | Loss: 0.00004112
Iteration 56/1000 | Loss: 0.00004111
Iteration 57/1000 | Loss: 0.00004111
Iteration 58/1000 | Loss: 0.00004110
Iteration 59/1000 | Loss: 0.00004109
Iteration 60/1000 | Loss: 0.00004109
Iteration 61/1000 | Loss: 0.00004109
Iteration 62/1000 | Loss: 0.00004109
Iteration 63/1000 | Loss: 0.00004109
Iteration 64/1000 | Loss: 0.00004108
Iteration 65/1000 | Loss: 0.00004108
Iteration 66/1000 | Loss: 0.00004108
Iteration 67/1000 | Loss: 0.00004108
Iteration 68/1000 | Loss: 0.00004108
Iteration 69/1000 | Loss: 0.00004107
Iteration 70/1000 | Loss: 0.00004107
Iteration 71/1000 | Loss: 0.00004107
Iteration 72/1000 | Loss: 0.00004107
Iteration 73/1000 | Loss: 0.00004107
Iteration 74/1000 | Loss: 0.00004107
Iteration 75/1000 | Loss: 0.00004107
Iteration 76/1000 | Loss: 0.00004107
Iteration 77/1000 | Loss: 0.00004107
Iteration 78/1000 | Loss: 0.00004107
Iteration 79/1000 | Loss: 0.00004107
Iteration 80/1000 | Loss: 0.00004106
Iteration 81/1000 | Loss: 0.00004106
Iteration 82/1000 | Loss: 0.00004106
Iteration 83/1000 | Loss: 0.00004106
Iteration 84/1000 | Loss: 0.00004106
Iteration 85/1000 | Loss: 0.00004106
Iteration 86/1000 | Loss: 0.00004106
Iteration 87/1000 | Loss: 0.00004105
Iteration 88/1000 | Loss: 0.00004105
Iteration 89/1000 | Loss: 0.00004105
Iteration 90/1000 | Loss: 0.00004105
Iteration 91/1000 | Loss: 0.00004105
Iteration 92/1000 | Loss: 0.00004105
Iteration 93/1000 | Loss: 0.00004104
Iteration 94/1000 | Loss: 0.00004104
Iteration 95/1000 | Loss: 0.00004104
Iteration 96/1000 | Loss: 0.00004104
Iteration 97/1000 | Loss: 0.00004104
Iteration 98/1000 | Loss: 0.00004104
Iteration 99/1000 | Loss: 0.00004104
Iteration 100/1000 | Loss: 0.00004104
Iteration 101/1000 | Loss: 0.00004104
Iteration 102/1000 | Loss: 0.00004103
Iteration 103/1000 | Loss: 0.00004103
Iteration 104/1000 | Loss: 0.00004103
Iteration 105/1000 | Loss: 0.00004103
Iteration 106/1000 | Loss: 0.00004103
Iteration 107/1000 | Loss: 0.00004102
Iteration 108/1000 | Loss: 0.00004102
Iteration 109/1000 | Loss: 0.00004102
Iteration 110/1000 | Loss: 0.00004102
Iteration 111/1000 | Loss: 0.00004102
Iteration 112/1000 | Loss: 0.00004102
Iteration 113/1000 | Loss: 0.00004102
Iteration 114/1000 | Loss: 0.00004102
Iteration 115/1000 | Loss: 0.00004101
Iteration 116/1000 | Loss: 0.00004101
Iteration 117/1000 | Loss: 0.00004101
Iteration 118/1000 | Loss: 0.00004101
Iteration 119/1000 | Loss: 0.00004101
Iteration 120/1000 | Loss: 0.00004101
Iteration 121/1000 | Loss: 0.00004101
Iteration 122/1000 | Loss: 0.00004101
Iteration 123/1000 | Loss: 0.00004101
Iteration 124/1000 | Loss: 0.00004101
Iteration 125/1000 | Loss: 0.00004101
Iteration 126/1000 | Loss: 0.00004101
Iteration 127/1000 | Loss: 0.00004101
Iteration 128/1000 | Loss: 0.00004100
Iteration 129/1000 | Loss: 0.00004100
Iteration 130/1000 | Loss: 0.00004100
Iteration 131/1000 | Loss: 0.00004100
Iteration 132/1000 | Loss: 0.00004100
Iteration 133/1000 | Loss: 0.00004100
Iteration 134/1000 | Loss: 0.00004100
Iteration 135/1000 | Loss: 0.00004099
Iteration 136/1000 | Loss: 0.00004099
Iteration 137/1000 | Loss: 0.00004099
Iteration 138/1000 | Loss: 0.00004099
Iteration 139/1000 | Loss: 0.00004099
Iteration 140/1000 | Loss: 0.00004099
Iteration 141/1000 | Loss: 0.00004099
Iteration 142/1000 | Loss: 0.00004099
Iteration 143/1000 | Loss: 0.00004099
Iteration 144/1000 | Loss: 0.00004099
Iteration 145/1000 | Loss: 0.00004099
Iteration 146/1000 | Loss: 0.00004098
Iteration 147/1000 | Loss: 0.00004098
Iteration 148/1000 | Loss: 0.00004098
Iteration 149/1000 | Loss: 0.00004098
Iteration 150/1000 | Loss: 0.00004098
Iteration 151/1000 | Loss: 0.00004098
Iteration 152/1000 | Loss: 0.00004098
Iteration 153/1000 | Loss: 0.00004098
Iteration 154/1000 | Loss: 0.00004097
Iteration 155/1000 | Loss: 0.00004097
Iteration 156/1000 | Loss: 0.00004097
Iteration 157/1000 | Loss: 0.00004097
Iteration 158/1000 | Loss: 0.00004097
Iteration 159/1000 | Loss: 0.00004097
Iteration 160/1000 | Loss: 0.00004096
Iteration 161/1000 | Loss: 0.00004096
Iteration 162/1000 | Loss: 0.00004096
Iteration 163/1000 | Loss: 0.00004096
Iteration 164/1000 | Loss: 0.00004095
Iteration 165/1000 | Loss: 0.00004095
Iteration 166/1000 | Loss: 0.00004095
Iteration 167/1000 | Loss: 0.00004095
Iteration 168/1000 | Loss: 0.00004095
Iteration 169/1000 | Loss: 0.00004095
Iteration 170/1000 | Loss: 0.00004094
Iteration 171/1000 | Loss: 0.00004094
Iteration 172/1000 | Loss: 0.00004094
Iteration 173/1000 | Loss: 0.00004094
Iteration 174/1000 | Loss: 0.00004094
Iteration 175/1000 | Loss: 0.00004094
Iteration 176/1000 | Loss: 0.00004094
Iteration 177/1000 | Loss: 0.00004094
Iteration 178/1000 | Loss: 0.00004094
Iteration 179/1000 | Loss: 0.00004094
Iteration 180/1000 | Loss: 0.00004094
Iteration 181/1000 | Loss: 0.00004093
Iteration 182/1000 | Loss: 0.00004093
Iteration 183/1000 | Loss: 0.00004093
Iteration 184/1000 | Loss: 0.00004093
Iteration 185/1000 | Loss: 0.00004093
Iteration 186/1000 | Loss: 0.00004093
Iteration 187/1000 | Loss: 0.00004093
Iteration 188/1000 | Loss: 0.00004093
Iteration 189/1000 | Loss: 0.00004093
Iteration 190/1000 | Loss: 0.00004093
Iteration 191/1000 | Loss: 0.00004093
Iteration 192/1000 | Loss: 0.00004093
Iteration 193/1000 | Loss: 0.00004093
Iteration 194/1000 | Loss: 0.00004093
Iteration 195/1000 | Loss: 0.00004093
Iteration 196/1000 | Loss: 0.00004092
Iteration 197/1000 | Loss: 0.00004092
Iteration 198/1000 | Loss: 0.00004092
Iteration 199/1000 | Loss: 0.00004092
Iteration 200/1000 | Loss: 0.00004092
Iteration 201/1000 | Loss: 0.00004092
Iteration 202/1000 | Loss: 0.00004091
Iteration 203/1000 | Loss: 0.00004091
Iteration 204/1000 | Loss: 0.00004091
Iteration 205/1000 | Loss: 0.00004091
Iteration 206/1000 | Loss: 0.00004091
Iteration 207/1000 | Loss: 0.00004091
Iteration 208/1000 | Loss: 0.00004091
Iteration 209/1000 | Loss: 0.00004091
Iteration 210/1000 | Loss: 0.00004091
Iteration 211/1000 | Loss: 0.00004091
Iteration 212/1000 | Loss: 0.00004090
Iteration 213/1000 | Loss: 0.00004090
Iteration 214/1000 | Loss: 0.00004090
Iteration 215/1000 | Loss: 0.00004090
Iteration 216/1000 | Loss: 0.00004090
Iteration 217/1000 | Loss: 0.00004090
Iteration 218/1000 | Loss: 0.00004090
Iteration 219/1000 | Loss: 0.00004090
Iteration 220/1000 | Loss: 0.00004090
Iteration 221/1000 | Loss: 0.00004090
Iteration 222/1000 | Loss: 0.00004090
Iteration 223/1000 | Loss: 0.00004090
Iteration 224/1000 | Loss: 0.00004089
Iteration 225/1000 | Loss: 0.00004089
Iteration 226/1000 | Loss: 0.00004089
Iteration 227/1000 | Loss: 0.00004089
Iteration 228/1000 | Loss: 0.00004089
Iteration 229/1000 | Loss: 0.00004089
Iteration 230/1000 | Loss: 0.00004089
Iteration 231/1000 | Loss: 0.00004089
Iteration 232/1000 | Loss: 0.00004088
Iteration 233/1000 | Loss: 0.00004088
Iteration 234/1000 | Loss: 0.00004088
Iteration 235/1000 | Loss: 0.00004088
Iteration 236/1000 | Loss: 0.00004088
Iteration 237/1000 | Loss: 0.00004088
Iteration 238/1000 | Loss: 0.00004088
Iteration 239/1000 | Loss: 0.00004088
Iteration 240/1000 | Loss: 0.00004088
Iteration 241/1000 | Loss: 0.00004088
Iteration 242/1000 | Loss: 0.00004088
Iteration 243/1000 | Loss: 0.00004088
Iteration 244/1000 | Loss: 0.00004088
Iteration 245/1000 | Loss: 0.00004088
Iteration 246/1000 | Loss: 0.00004088
Iteration 247/1000 | Loss: 0.00004088
Iteration 248/1000 | Loss: 0.00004088
Iteration 249/1000 | Loss: 0.00004088
Iteration 250/1000 | Loss: 0.00004088
Iteration 251/1000 | Loss: 0.00004088
Iteration 252/1000 | Loss: 0.00004088
Iteration 253/1000 | Loss: 0.00004088
Iteration 254/1000 | Loss: 0.00004088
Iteration 255/1000 | Loss: 0.00004088
Iteration 256/1000 | Loss: 0.00004088
Iteration 257/1000 | Loss: 0.00004088
Iteration 258/1000 | Loss: 0.00004088
Iteration 259/1000 | Loss: 0.00004088
Iteration 260/1000 | Loss: 0.00004088
Iteration 261/1000 | Loss: 0.00004088
Iteration 262/1000 | Loss: 0.00004088
Iteration 263/1000 | Loss: 0.00004088
Iteration 264/1000 | Loss: 0.00004088
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 264. Stopping optimization.
Last 5 losses: [4.088290734216571e-05, 4.088290734216571e-05, 4.088290734216571e-05, 4.088290734216571e-05, 4.088290734216571e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.088290734216571e-05

Optimization complete. Final v2v error: 5.2159929275512695 mm

Highest mean error: 5.369459629058838 mm for frame 92

Lowest mean error: 5.096903324127197 mm for frame 75

Saving results

Total time: 983.7620799541473
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1040/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1040.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1040
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00807413
Iteration 2/25 | Loss: 0.00134938
Iteration 3/25 | Loss: 0.00127073
Iteration 4/25 | Loss: 0.00126256
Iteration 5/25 | Loss: 0.00126080
Iteration 6/25 | Loss: 0.00126080
Iteration 7/25 | Loss: 0.00126080
Iteration 8/25 | Loss: 0.00126080
Iteration 9/25 | Loss: 0.00126080
Iteration 10/25 | Loss: 0.00126080
Iteration 11/25 | Loss: 0.00126080
Iteration 12/25 | Loss: 0.00126080
Iteration 13/25 | Loss: 0.00126080
Iteration 14/25 | Loss: 0.00126080
Iteration 15/25 | Loss: 0.00126080
Iteration 16/25 | Loss: 0.00126080
Iteration 17/25 | Loss: 0.00126080
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012608036631718278, 0.0012608036631718278, 0.0012608036631718278, 0.0012608036631718278, 0.0012608036631718278]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012608036631718278

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39460325
Iteration 2/25 | Loss: 0.00078346
Iteration 3/25 | Loss: 0.00078346
Iteration 4/25 | Loss: 0.00078346
Iteration 5/25 | Loss: 0.00078345
Iteration 6/25 | Loss: 0.00078345
Iteration 7/25 | Loss: 0.00078345
Iteration 8/25 | Loss: 0.00078345
Iteration 9/25 | Loss: 0.00078345
Iteration 10/25 | Loss: 0.00078345
Iteration 11/25 | Loss: 0.00078345
Iteration 12/25 | Loss: 0.00078345
Iteration 13/25 | Loss: 0.00078345
Iteration 14/25 | Loss: 0.00078345
Iteration 15/25 | Loss: 0.00078345
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0007834532880224288, 0.0007834532880224288, 0.0007834532880224288, 0.0007834532880224288, 0.0007834532880224288]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007834532880224288

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078345
Iteration 2/1000 | Loss: 0.00002911
Iteration 3/1000 | Loss: 0.00001906
Iteration 4/1000 | Loss: 0.00001691
Iteration 5/1000 | Loss: 0.00001572
Iteration 6/1000 | Loss: 0.00001471
Iteration 7/1000 | Loss: 0.00001405
Iteration 8/1000 | Loss: 0.00001365
Iteration 9/1000 | Loss: 0.00001334
Iteration 10/1000 | Loss: 0.00001303
Iteration 11/1000 | Loss: 0.00001300
Iteration 12/1000 | Loss: 0.00001292
Iteration 13/1000 | Loss: 0.00001289
Iteration 14/1000 | Loss: 0.00001284
Iteration 15/1000 | Loss: 0.00001282
Iteration 16/1000 | Loss: 0.00001282
Iteration 17/1000 | Loss: 0.00001281
Iteration 18/1000 | Loss: 0.00001280
Iteration 19/1000 | Loss: 0.00001279
Iteration 20/1000 | Loss: 0.00001278
Iteration 21/1000 | Loss: 0.00001274
Iteration 22/1000 | Loss: 0.00001274
Iteration 23/1000 | Loss: 0.00001274
Iteration 24/1000 | Loss: 0.00001273
Iteration 25/1000 | Loss: 0.00001273
Iteration 26/1000 | Loss: 0.00001273
Iteration 27/1000 | Loss: 0.00001272
Iteration 28/1000 | Loss: 0.00001271
Iteration 29/1000 | Loss: 0.00001269
Iteration 30/1000 | Loss: 0.00001268
Iteration 31/1000 | Loss: 0.00001267
Iteration 32/1000 | Loss: 0.00001267
Iteration 33/1000 | Loss: 0.00001267
Iteration 34/1000 | Loss: 0.00001266
Iteration 35/1000 | Loss: 0.00001266
Iteration 36/1000 | Loss: 0.00001265
Iteration 37/1000 | Loss: 0.00001265
Iteration 38/1000 | Loss: 0.00001258
Iteration 39/1000 | Loss: 0.00001258
Iteration 40/1000 | Loss: 0.00001258
Iteration 41/1000 | Loss: 0.00001258
Iteration 42/1000 | Loss: 0.00001254
Iteration 43/1000 | Loss: 0.00001253
Iteration 44/1000 | Loss: 0.00001252
Iteration 45/1000 | Loss: 0.00001252
Iteration 46/1000 | Loss: 0.00001251
Iteration 47/1000 | Loss: 0.00001245
Iteration 48/1000 | Loss: 0.00001243
Iteration 49/1000 | Loss: 0.00001241
Iteration 50/1000 | Loss: 0.00001240
Iteration 51/1000 | Loss: 0.00001239
Iteration 52/1000 | Loss: 0.00001238
Iteration 53/1000 | Loss: 0.00001230
Iteration 54/1000 | Loss: 0.00001227
Iteration 55/1000 | Loss: 0.00001227
Iteration 56/1000 | Loss: 0.00001226
Iteration 57/1000 | Loss: 0.00001226
Iteration 58/1000 | Loss: 0.00001225
Iteration 59/1000 | Loss: 0.00001221
Iteration 60/1000 | Loss: 0.00001221
Iteration 61/1000 | Loss: 0.00001220
Iteration 62/1000 | Loss: 0.00001220
Iteration 63/1000 | Loss: 0.00001220
Iteration 64/1000 | Loss: 0.00001219
Iteration 65/1000 | Loss: 0.00001219
Iteration 66/1000 | Loss: 0.00001216
Iteration 67/1000 | Loss: 0.00001216
Iteration 68/1000 | Loss: 0.00001216
Iteration 69/1000 | Loss: 0.00001216
Iteration 70/1000 | Loss: 0.00001214
Iteration 71/1000 | Loss: 0.00001214
Iteration 72/1000 | Loss: 0.00001213
Iteration 73/1000 | Loss: 0.00001212
Iteration 74/1000 | Loss: 0.00001212
Iteration 75/1000 | Loss: 0.00001211
Iteration 76/1000 | Loss: 0.00001211
Iteration 77/1000 | Loss: 0.00001211
Iteration 78/1000 | Loss: 0.00001211
Iteration 79/1000 | Loss: 0.00001211
Iteration 80/1000 | Loss: 0.00001211
Iteration 81/1000 | Loss: 0.00001210
Iteration 82/1000 | Loss: 0.00001210
Iteration 83/1000 | Loss: 0.00001210
Iteration 84/1000 | Loss: 0.00001210
Iteration 85/1000 | Loss: 0.00001210
Iteration 86/1000 | Loss: 0.00001210
Iteration 87/1000 | Loss: 0.00001209
Iteration 88/1000 | Loss: 0.00001209
Iteration 89/1000 | Loss: 0.00001209
Iteration 90/1000 | Loss: 0.00001208
Iteration 91/1000 | Loss: 0.00001208
Iteration 92/1000 | Loss: 0.00001208
Iteration 93/1000 | Loss: 0.00001207
Iteration 94/1000 | Loss: 0.00001207
Iteration 95/1000 | Loss: 0.00001207
Iteration 96/1000 | Loss: 0.00001207
Iteration 97/1000 | Loss: 0.00001207
Iteration 98/1000 | Loss: 0.00001207
Iteration 99/1000 | Loss: 0.00001207
Iteration 100/1000 | Loss: 0.00001207
Iteration 101/1000 | Loss: 0.00001206
Iteration 102/1000 | Loss: 0.00001206
Iteration 103/1000 | Loss: 0.00001206
Iteration 104/1000 | Loss: 0.00001205
Iteration 105/1000 | Loss: 0.00001205
Iteration 106/1000 | Loss: 0.00001204
Iteration 107/1000 | Loss: 0.00001203
Iteration 108/1000 | Loss: 0.00001203
Iteration 109/1000 | Loss: 0.00001203
Iteration 110/1000 | Loss: 0.00001203
Iteration 111/1000 | Loss: 0.00001202
Iteration 112/1000 | Loss: 0.00001202
Iteration 113/1000 | Loss: 0.00001202
Iteration 114/1000 | Loss: 0.00001201
Iteration 115/1000 | Loss: 0.00001200
Iteration 116/1000 | Loss: 0.00001200
Iteration 117/1000 | Loss: 0.00001199
Iteration 118/1000 | Loss: 0.00001199
Iteration 119/1000 | Loss: 0.00001199
Iteration 120/1000 | Loss: 0.00001199
Iteration 121/1000 | Loss: 0.00001199
Iteration 122/1000 | Loss: 0.00001199
Iteration 123/1000 | Loss: 0.00001198
Iteration 124/1000 | Loss: 0.00001198
Iteration 125/1000 | Loss: 0.00001198
Iteration 126/1000 | Loss: 0.00001198
Iteration 127/1000 | Loss: 0.00001198
Iteration 128/1000 | Loss: 0.00001198
Iteration 129/1000 | Loss: 0.00001198
Iteration 130/1000 | Loss: 0.00001198
Iteration 131/1000 | Loss: 0.00001198
Iteration 132/1000 | Loss: 0.00001198
Iteration 133/1000 | Loss: 0.00001197
Iteration 134/1000 | Loss: 0.00001197
Iteration 135/1000 | Loss: 0.00001197
Iteration 136/1000 | Loss: 0.00001197
Iteration 137/1000 | Loss: 0.00001196
Iteration 138/1000 | Loss: 0.00001196
Iteration 139/1000 | Loss: 0.00001196
Iteration 140/1000 | Loss: 0.00001196
Iteration 141/1000 | Loss: 0.00001196
Iteration 142/1000 | Loss: 0.00001195
Iteration 143/1000 | Loss: 0.00001195
Iteration 144/1000 | Loss: 0.00001195
Iteration 145/1000 | Loss: 0.00001195
Iteration 146/1000 | Loss: 0.00001195
Iteration 147/1000 | Loss: 0.00001195
Iteration 148/1000 | Loss: 0.00001195
Iteration 149/1000 | Loss: 0.00001195
Iteration 150/1000 | Loss: 0.00001195
Iteration 151/1000 | Loss: 0.00001194
Iteration 152/1000 | Loss: 0.00001194
Iteration 153/1000 | Loss: 0.00001194
Iteration 154/1000 | Loss: 0.00001194
Iteration 155/1000 | Loss: 0.00001194
Iteration 156/1000 | Loss: 0.00001194
Iteration 157/1000 | Loss: 0.00001194
Iteration 158/1000 | Loss: 0.00001194
Iteration 159/1000 | Loss: 0.00001194
Iteration 160/1000 | Loss: 0.00001193
Iteration 161/1000 | Loss: 0.00001193
Iteration 162/1000 | Loss: 0.00001192
Iteration 163/1000 | Loss: 0.00001192
Iteration 164/1000 | Loss: 0.00001192
Iteration 165/1000 | Loss: 0.00001192
Iteration 166/1000 | Loss: 0.00001191
Iteration 167/1000 | Loss: 0.00001191
Iteration 168/1000 | Loss: 0.00001191
Iteration 169/1000 | Loss: 0.00001191
Iteration 170/1000 | Loss: 0.00001191
Iteration 171/1000 | Loss: 0.00001191
Iteration 172/1000 | Loss: 0.00001190
Iteration 173/1000 | Loss: 0.00001190
Iteration 174/1000 | Loss: 0.00001190
Iteration 175/1000 | Loss: 0.00001190
Iteration 176/1000 | Loss: 0.00001190
Iteration 177/1000 | Loss: 0.00001190
Iteration 178/1000 | Loss: 0.00001190
Iteration 179/1000 | Loss: 0.00001189
Iteration 180/1000 | Loss: 0.00001189
Iteration 181/1000 | Loss: 0.00001189
Iteration 182/1000 | Loss: 0.00001189
Iteration 183/1000 | Loss: 0.00001189
Iteration 184/1000 | Loss: 0.00001189
Iteration 185/1000 | Loss: 0.00001188
Iteration 186/1000 | Loss: 0.00001188
Iteration 187/1000 | Loss: 0.00001188
Iteration 188/1000 | Loss: 0.00001188
Iteration 189/1000 | Loss: 0.00001188
Iteration 190/1000 | Loss: 0.00001188
Iteration 191/1000 | Loss: 0.00001188
Iteration 192/1000 | Loss: 0.00001188
Iteration 193/1000 | Loss: 0.00001188
Iteration 194/1000 | Loss: 0.00001188
Iteration 195/1000 | Loss: 0.00001188
Iteration 196/1000 | Loss: 0.00001188
Iteration 197/1000 | Loss: 0.00001188
Iteration 198/1000 | Loss: 0.00001188
Iteration 199/1000 | Loss: 0.00001188
Iteration 200/1000 | Loss: 0.00001188
Iteration 201/1000 | Loss: 0.00001188
Iteration 202/1000 | Loss: 0.00001188
Iteration 203/1000 | Loss: 0.00001187
Iteration 204/1000 | Loss: 0.00001187
Iteration 205/1000 | Loss: 0.00001187
Iteration 206/1000 | Loss: 0.00001187
Iteration 207/1000 | Loss: 0.00001187
Iteration 208/1000 | Loss: 0.00001187
Iteration 209/1000 | Loss: 0.00001187
Iteration 210/1000 | Loss: 0.00001187
Iteration 211/1000 | Loss: 0.00001187
Iteration 212/1000 | Loss: 0.00001187
Iteration 213/1000 | Loss: 0.00001187
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 213. Stopping optimization.
Last 5 losses: [1.1874411939061247e-05, 1.1874411939061247e-05, 1.1874411939061247e-05, 1.1874411939061247e-05, 1.1874411939061247e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1874411939061247e-05

Optimization complete. Final v2v error: 2.9521291255950928 mm

Highest mean error: 3.1842031478881836 mm for frame 57

Lowest mean error: 2.7491767406463623 mm for frame 201

Saving results

Total time: 1296.2435774803162
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1006
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00764294
Iteration 2/25 | Loss: 0.00138535
Iteration 3/25 | Loss: 0.00128220
Iteration 4/25 | Loss: 0.00127402
Iteration 5/25 | Loss: 0.00127398
Iteration 6/25 | Loss: 0.00127398
Iteration 7/25 | Loss: 0.00127398
Iteration 8/25 | Loss: 0.00127398
Iteration 9/25 | Loss: 0.00127398
Iteration 10/25 | Loss: 0.00127398
Iteration 11/25 | Loss: 0.00127398
Iteration 12/25 | Loss: 0.00127398
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012739760568365455, 0.0012739760568365455, 0.0012739760568365455, 0.0012739760568365455, 0.0012739760568365455]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012739760568365455

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39879441
Iteration 2/25 | Loss: 0.00078145
Iteration 3/25 | Loss: 0.00078144
Iteration 4/25 | Loss: 0.00078144
Iteration 5/25 | Loss: 0.00078144
Iteration 6/25 | Loss: 0.00078144
Iteration 7/25 | Loss: 0.00078144
Iteration 8/25 | Loss: 0.00078144
Iteration 9/25 | Loss: 0.00078144
Iteration 10/25 | Loss: 0.00078144
Iteration 11/25 | Loss: 0.00078144
Iteration 12/25 | Loss: 0.00078144
Iteration 13/25 | Loss: 0.00078144
Iteration 14/25 | Loss: 0.00078144
Iteration 15/25 | Loss: 0.00078144
Iteration 16/25 | Loss: 0.00078144
Iteration 17/25 | Loss: 0.00078144
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007814412238076329, 0.0007814412238076329, 0.0007814412238076329, 0.0007814412238076329, 0.0007814412238076329]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007814412238076329

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078144
Iteration 2/1000 | Loss: 0.00002603
Iteration 3/1000 | Loss: 0.00001925
Iteration 4/1000 | Loss: 0.00001694
Iteration 5/1000 | Loss: 0.00001601
Iteration 6/1000 | Loss: 0.00001535
Iteration 7/1000 | Loss: 0.00001485
Iteration 8/1000 | Loss: 0.00001446
Iteration 9/1000 | Loss: 0.00001406
Iteration 10/1000 | Loss: 0.00001392
Iteration 11/1000 | Loss: 0.00001376
Iteration 12/1000 | Loss: 0.00001360
Iteration 13/1000 | Loss: 0.00001359
Iteration 14/1000 | Loss: 0.00001352
Iteration 15/1000 | Loss: 0.00001342
Iteration 16/1000 | Loss: 0.00001338
Iteration 17/1000 | Loss: 0.00001337
Iteration 18/1000 | Loss: 0.00001337
Iteration 19/1000 | Loss: 0.00001337
Iteration 20/1000 | Loss: 0.00001336
Iteration 21/1000 | Loss: 0.00001336
Iteration 22/1000 | Loss: 0.00001336
Iteration 23/1000 | Loss: 0.00001335
Iteration 24/1000 | Loss: 0.00001334
Iteration 25/1000 | Loss: 0.00001333
Iteration 26/1000 | Loss: 0.00001333
Iteration 27/1000 | Loss: 0.00001332
Iteration 28/1000 | Loss: 0.00001331
Iteration 29/1000 | Loss: 0.00001330
Iteration 30/1000 | Loss: 0.00001330
Iteration 31/1000 | Loss: 0.00001329
Iteration 32/1000 | Loss: 0.00001329
Iteration 33/1000 | Loss: 0.00001314
Iteration 34/1000 | Loss: 0.00001308
Iteration 35/1000 | Loss: 0.00001305
Iteration 36/1000 | Loss: 0.00001298
Iteration 37/1000 | Loss: 0.00001293
Iteration 38/1000 | Loss: 0.00001292
Iteration 39/1000 | Loss: 0.00001291
Iteration 40/1000 | Loss: 0.00001289
Iteration 41/1000 | Loss: 0.00001289
Iteration 42/1000 | Loss: 0.00001288
Iteration 43/1000 | Loss: 0.00001288
Iteration 44/1000 | Loss: 0.00001288
Iteration 45/1000 | Loss: 0.00001287
Iteration 46/1000 | Loss: 0.00001286
Iteration 47/1000 | Loss: 0.00001286
Iteration 48/1000 | Loss: 0.00001286
Iteration 49/1000 | Loss: 0.00001285
Iteration 50/1000 | Loss: 0.00001284
Iteration 51/1000 | Loss: 0.00001284
Iteration 52/1000 | Loss: 0.00001283
Iteration 53/1000 | Loss: 0.00001283
Iteration 54/1000 | Loss: 0.00001282
Iteration 55/1000 | Loss: 0.00001282
Iteration 56/1000 | Loss: 0.00001281
Iteration 57/1000 | Loss: 0.00001280
Iteration 58/1000 | Loss: 0.00001279
Iteration 59/1000 | Loss: 0.00001279
Iteration 60/1000 | Loss: 0.00001279
Iteration 61/1000 | Loss: 0.00001279
Iteration 62/1000 | Loss: 0.00001279
Iteration 63/1000 | Loss: 0.00001279
Iteration 64/1000 | Loss: 0.00001278
Iteration 65/1000 | Loss: 0.00001278
Iteration 66/1000 | Loss: 0.00001273
Iteration 67/1000 | Loss: 0.00001272
Iteration 68/1000 | Loss: 0.00001272
Iteration 69/1000 | Loss: 0.00001270
Iteration 70/1000 | Loss: 0.00001270
Iteration 71/1000 | Loss: 0.00001269
Iteration 72/1000 | Loss: 0.00001269
Iteration 73/1000 | Loss: 0.00001269
Iteration 74/1000 | Loss: 0.00001269
Iteration 75/1000 | Loss: 0.00001268
Iteration 76/1000 | Loss: 0.00001268
Iteration 77/1000 | Loss: 0.00001268
Iteration 78/1000 | Loss: 0.00001267
Iteration 79/1000 | Loss: 0.00001267
Iteration 80/1000 | Loss: 0.00001266
Iteration 81/1000 | Loss: 0.00001266
Iteration 82/1000 | Loss: 0.00001266
Iteration 83/1000 | Loss: 0.00001266
Iteration 84/1000 | Loss: 0.00001265
Iteration 85/1000 | Loss: 0.00001265
Iteration 86/1000 | Loss: 0.00001265
Iteration 87/1000 | Loss: 0.00001265
Iteration 88/1000 | Loss: 0.00001264
Iteration 89/1000 | Loss: 0.00001264
Iteration 90/1000 | Loss: 0.00001264
Iteration 91/1000 | Loss: 0.00001264
Iteration 92/1000 | Loss: 0.00001264
Iteration 93/1000 | Loss: 0.00001264
Iteration 94/1000 | Loss: 0.00001264
Iteration 95/1000 | Loss: 0.00001263
Iteration 96/1000 | Loss: 0.00001263
Iteration 97/1000 | Loss: 0.00001263
Iteration 98/1000 | Loss: 0.00001263
Iteration 99/1000 | Loss: 0.00001263
Iteration 100/1000 | Loss: 0.00001263
Iteration 101/1000 | Loss: 0.00001263
Iteration 102/1000 | Loss: 0.00001262
Iteration 103/1000 | Loss: 0.00001262
Iteration 104/1000 | Loss: 0.00001262
Iteration 105/1000 | Loss: 0.00001262
Iteration 106/1000 | Loss: 0.00001261
Iteration 107/1000 | Loss: 0.00001261
Iteration 108/1000 | Loss: 0.00001261
Iteration 109/1000 | Loss: 0.00001261
Iteration 110/1000 | Loss: 0.00001261
Iteration 111/1000 | Loss: 0.00001260
Iteration 112/1000 | Loss: 0.00001260
Iteration 113/1000 | Loss: 0.00001260
Iteration 114/1000 | Loss: 0.00001260
Iteration 115/1000 | Loss: 0.00001260
Iteration 116/1000 | Loss: 0.00001260
Iteration 117/1000 | Loss: 0.00001260
Iteration 118/1000 | Loss: 0.00001260
Iteration 119/1000 | Loss: 0.00001260
Iteration 120/1000 | Loss: 0.00001260
Iteration 121/1000 | Loss: 0.00001260
Iteration 122/1000 | Loss: 0.00001260
Iteration 123/1000 | Loss: 0.00001260
Iteration 124/1000 | Loss: 0.00001259
Iteration 125/1000 | Loss: 0.00001259
Iteration 126/1000 | Loss: 0.00001259
Iteration 127/1000 | Loss: 0.00001259
Iteration 128/1000 | Loss: 0.00001259
Iteration 129/1000 | Loss: 0.00001259
Iteration 130/1000 | Loss: 0.00001258
Iteration 131/1000 | Loss: 0.00001258
Iteration 132/1000 | Loss: 0.00001258
Iteration 133/1000 | Loss: 0.00001258
Iteration 134/1000 | Loss: 0.00001258
Iteration 135/1000 | Loss: 0.00001257
Iteration 136/1000 | Loss: 0.00001257
Iteration 137/1000 | Loss: 0.00001257
Iteration 138/1000 | Loss: 0.00001257
Iteration 139/1000 | Loss: 0.00001257
Iteration 140/1000 | Loss: 0.00001257
Iteration 141/1000 | Loss: 0.00001257
Iteration 142/1000 | Loss: 0.00001257
Iteration 143/1000 | Loss: 0.00001257
Iteration 144/1000 | Loss: 0.00001257
Iteration 145/1000 | Loss: 0.00001256
Iteration 146/1000 | Loss: 0.00001256
Iteration 147/1000 | Loss: 0.00001256
Iteration 148/1000 | Loss: 0.00001256
Iteration 149/1000 | Loss: 0.00001256
Iteration 150/1000 | Loss: 0.00001255
Iteration 151/1000 | Loss: 0.00001255
Iteration 152/1000 | Loss: 0.00001255
Iteration 153/1000 | Loss: 0.00001255
Iteration 154/1000 | Loss: 0.00001255
Iteration 155/1000 | Loss: 0.00001255
Iteration 156/1000 | Loss: 0.00001255
Iteration 157/1000 | Loss: 0.00001254
Iteration 158/1000 | Loss: 0.00001254
Iteration 159/1000 | Loss: 0.00001254
Iteration 160/1000 | Loss: 0.00001254
Iteration 161/1000 | Loss: 0.00001254
Iteration 162/1000 | Loss: 0.00001253
Iteration 163/1000 | Loss: 0.00001253
Iteration 164/1000 | Loss: 0.00001253
Iteration 165/1000 | Loss: 0.00001253
Iteration 166/1000 | Loss: 0.00001253
Iteration 167/1000 | Loss: 0.00001253
Iteration 168/1000 | Loss: 0.00001253
Iteration 169/1000 | Loss: 0.00001253
Iteration 170/1000 | Loss: 0.00001253
Iteration 171/1000 | Loss: 0.00001253
Iteration 172/1000 | Loss: 0.00001252
Iteration 173/1000 | Loss: 0.00001252
Iteration 174/1000 | Loss: 0.00001252
Iteration 175/1000 | Loss: 0.00001252
Iteration 176/1000 | Loss: 0.00001252
Iteration 177/1000 | Loss: 0.00001252
Iteration 178/1000 | Loss: 0.00001252
Iteration 179/1000 | Loss: 0.00001252
Iteration 180/1000 | Loss: 0.00001252
Iteration 181/1000 | Loss: 0.00001252
Iteration 182/1000 | Loss: 0.00001252
Iteration 183/1000 | Loss: 0.00001252
Iteration 184/1000 | Loss: 0.00001252
Iteration 185/1000 | Loss: 0.00001252
Iteration 186/1000 | Loss: 0.00001252
Iteration 187/1000 | Loss: 0.00001251
Iteration 188/1000 | Loss: 0.00001251
Iteration 189/1000 | Loss: 0.00001251
Iteration 190/1000 | Loss: 0.00001251
Iteration 191/1000 | Loss: 0.00001251
Iteration 192/1000 | Loss: 0.00001251
Iteration 193/1000 | Loss: 0.00001251
Iteration 194/1000 | Loss: 0.00001251
Iteration 195/1000 | Loss: 0.00001250
Iteration 196/1000 | Loss: 0.00001250
Iteration 197/1000 | Loss: 0.00001250
Iteration 198/1000 | Loss: 0.00001250
Iteration 199/1000 | Loss: 0.00001250
Iteration 200/1000 | Loss: 0.00001250
Iteration 201/1000 | Loss: 0.00001250
Iteration 202/1000 | Loss: 0.00001250
Iteration 203/1000 | Loss: 0.00001250
Iteration 204/1000 | Loss: 0.00001250
Iteration 205/1000 | Loss: 0.00001250
Iteration 206/1000 | Loss: 0.00001250
Iteration 207/1000 | Loss: 0.00001250
Iteration 208/1000 | Loss: 0.00001250
Iteration 209/1000 | Loss: 0.00001250
Iteration 210/1000 | Loss: 0.00001250
Iteration 211/1000 | Loss: 0.00001250
Iteration 212/1000 | Loss: 0.00001250
Iteration 213/1000 | Loss: 0.00001250
Iteration 214/1000 | Loss: 0.00001250
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 214. Stopping optimization.
Last 5 losses: [1.2503691323217936e-05, 1.2503691323217936e-05, 1.2503691323217936e-05, 1.2503691323217936e-05, 1.2503691323217936e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2503691323217936e-05

Optimization complete. Final v2v error: 3.002871513366699 mm

Highest mean error: 3.175727128982544 mm for frame 80

Lowest mean error: 2.831458806991577 mm for frame 253

Saving results

Total time: 1499.9566082954407
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1077
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00550073
Iteration 2/25 | Loss: 0.00147654
Iteration 3/25 | Loss: 0.00137745
Iteration 4/25 | Loss: 0.00136624
Iteration 5/25 | Loss: 0.00136309
Iteration 6/25 | Loss: 0.00136309
Iteration 7/25 | Loss: 0.00136309
Iteration 8/25 | Loss: 0.00136309
Iteration 9/25 | Loss: 0.00136309
Iteration 10/25 | Loss: 0.00136309
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0013630875619128346, 0.0013630875619128346, 0.0013630875619128346, 0.0013630875619128346, 0.0013630875619128346]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013630875619128346

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30600119
Iteration 2/25 | Loss: 0.00104731
Iteration 3/25 | Loss: 0.00104730
Iteration 4/25 | Loss: 0.00104730
Iteration 5/25 | Loss: 0.00104730
Iteration 6/25 | Loss: 0.00104729
Iteration 7/25 | Loss: 0.00104729
Iteration 8/25 | Loss: 0.00104729
Iteration 9/25 | Loss: 0.00104729
Iteration 10/25 | Loss: 0.00104729
Iteration 11/25 | Loss: 0.00104729
Iteration 12/25 | Loss: 0.00104729
Iteration 13/25 | Loss: 0.00104729
Iteration 14/25 | Loss: 0.00104729
Iteration 15/25 | Loss: 0.00104729
Iteration 16/25 | Loss: 0.00104729
Iteration 17/25 | Loss: 0.00104729
Iteration 18/25 | Loss: 0.00104729
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0010472936555743217, 0.0010472936555743217, 0.0010472936555743217, 0.0010472936555743217, 0.0010472936555743217]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010472936555743217

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00104729
Iteration 2/1000 | Loss: 0.00004582
Iteration 3/1000 | Loss: 0.00002833
Iteration 4/1000 | Loss: 0.00002500
Iteration 5/1000 | Loss: 0.00002341
Iteration 6/1000 | Loss: 0.00002239
Iteration 7/1000 | Loss: 0.00002168
Iteration 8/1000 | Loss: 0.00002114
Iteration 9/1000 | Loss: 0.00002075
Iteration 10/1000 | Loss: 0.00002034
Iteration 11/1000 | Loss: 0.00002010
Iteration 12/1000 | Loss: 0.00001994
Iteration 13/1000 | Loss: 0.00001992
Iteration 14/1000 | Loss: 0.00001981
Iteration 15/1000 | Loss: 0.00001967
Iteration 16/1000 | Loss: 0.00001966
Iteration 17/1000 | Loss: 0.00001964
Iteration 18/1000 | Loss: 0.00001958
Iteration 19/1000 | Loss: 0.00001954
Iteration 20/1000 | Loss: 0.00001953
Iteration 21/1000 | Loss: 0.00001952
Iteration 22/1000 | Loss: 0.00001952
Iteration 23/1000 | Loss: 0.00001951
Iteration 24/1000 | Loss: 0.00001951
Iteration 25/1000 | Loss: 0.00001942
Iteration 26/1000 | Loss: 0.00001942
Iteration 27/1000 | Loss: 0.00001941
Iteration 28/1000 | Loss: 0.00001940
Iteration 29/1000 | Loss: 0.00001937
Iteration 30/1000 | Loss: 0.00001937
Iteration 31/1000 | Loss: 0.00001936
Iteration 32/1000 | Loss: 0.00001936
Iteration 33/1000 | Loss: 0.00001936
Iteration 34/1000 | Loss: 0.00001936
Iteration 35/1000 | Loss: 0.00001936
Iteration 36/1000 | Loss: 0.00001936
Iteration 37/1000 | Loss: 0.00001933
Iteration 38/1000 | Loss: 0.00001933
Iteration 39/1000 | Loss: 0.00001933
Iteration 40/1000 | Loss: 0.00001933
Iteration 41/1000 | Loss: 0.00001933
Iteration 42/1000 | Loss: 0.00001933
Iteration 43/1000 | Loss: 0.00001933
Iteration 44/1000 | Loss: 0.00001932
Iteration 45/1000 | Loss: 0.00001932
Iteration 46/1000 | Loss: 0.00001932
Iteration 47/1000 | Loss: 0.00001932
Iteration 48/1000 | Loss: 0.00001930
Iteration 49/1000 | Loss: 0.00001930
Iteration 50/1000 | Loss: 0.00001929
Iteration 51/1000 | Loss: 0.00001929
Iteration 52/1000 | Loss: 0.00001929
Iteration 53/1000 | Loss: 0.00001928
Iteration 54/1000 | Loss: 0.00001928
Iteration 55/1000 | Loss: 0.00001927
Iteration 56/1000 | Loss: 0.00001926
Iteration 57/1000 | Loss: 0.00001926
Iteration 58/1000 | Loss: 0.00001926
Iteration 59/1000 | Loss: 0.00001926
Iteration 60/1000 | Loss: 0.00001926
Iteration 61/1000 | Loss: 0.00001926
Iteration 62/1000 | Loss: 0.00001926
Iteration 63/1000 | Loss: 0.00001926
Iteration 64/1000 | Loss: 0.00001926
Iteration 65/1000 | Loss: 0.00001926
Iteration 66/1000 | Loss: 0.00001926
Iteration 67/1000 | Loss: 0.00001926
Iteration 68/1000 | Loss: 0.00001926
Iteration 69/1000 | Loss: 0.00001926
Iteration 70/1000 | Loss: 0.00001926
Iteration 71/1000 | Loss: 0.00001926
Iteration 72/1000 | Loss: 0.00001926
Iteration 73/1000 | Loss: 0.00001926
Iteration 74/1000 | Loss: 0.00001926
Iteration 75/1000 | Loss: 0.00001926
Iteration 76/1000 | Loss: 0.00001926
Iteration 77/1000 | Loss: 0.00001926
Iteration 78/1000 | Loss: 0.00001926
Iteration 79/1000 | Loss: 0.00001926
Iteration 80/1000 | Loss: 0.00001926
Iteration 81/1000 | Loss: 0.00001926
Iteration 82/1000 | Loss: 0.00001926
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 82. Stopping optimization.
Last 5 losses: [1.9257338863098994e-05, 1.9257338863098994e-05, 1.9257338863098994e-05, 1.9257338863098994e-05, 1.9257338863098994e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9257338863098994e-05

Optimization complete. Final v2v error: 3.6762948036193848 mm

Highest mean error: 4.5697407722473145 mm for frame 143

Lowest mean error: 2.9732863903045654 mm for frame 30

Saving results

Total time: 1058.0567228794098
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1073/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1073.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1073
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00946903
Iteration 2/25 | Loss: 0.00227048
Iteration 3/25 | Loss: 0.00154482
Iteration 4/25 | Loss: 0.00147332
Iteration 5/25 | Loss: 0.00145183
Iteration 6/25 | Loss: 0.00142743
Iteration 7/25 | Loss: 0.00139243
Iteration 8/25 | Loss: 0.00137334
Iteration 9/25 | Loss: 0.00136461
Iteration 10/25 | Loss: 0.00137228
Iteration 11/25 | Loss: 0.00136987
Iteration 12/25 | Loss: 0.00136448
Iteration 13/25 | Loss: 0.00136070
Iteration 14/25 | Loss: 0.00136005
Iteration 15/25 | Loss: 0.00136292
Iteration 16/25 | Loss: 0.00136291
Iteration 17/25 | Loss: 0.00136291
Iteration 18/25 | Loss: 0.00136271
Iteration 19/25 | Loss: 0.00136150
Iteration 20/25 | Loss: 0.00136077
Iteration 21/25 | Loss: 0.00136228
Iteration 22/25 | Loss: 0.00136188
Iteration 23/25 | Loss: 0.00136156
Iteration 24/25 | Loss: 0.00136256
Iteration 25/25 | Loss: 0.00136201

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39208019
Iteration 2/25 | Loss: 0.00078291
Iteration 3/25 | Loss: 0.00078291
Iteration 4/25 | Loss: 0.00078291
Iteration 5/25 | Loss: 0.00078291
Iteration 6/25 | Loss: 0.00078291
Iteration 7/25 | Loss: 0.00078291
Iteration 8/25 | Loss: 0.00078291
Iteration 9/25 | Loss: 0.00078291
Iteration 10/25 | Loss: 0.00078291
Iteration 11/25 | Loss: 0.00078291
Iteration 12/25 | Loss: 0.00078291
Iteration 13/25 | Loss: 0.00078291
Iteration 14/25 | Loss: 0.00078291
Iteration 15/25 | Loss: 0.00078291
Iteration 16/25 | Loss: 0.00078291
Iteration 17/25 | Loss: 0.00078291
Iteration 18/25 | Loss: 0.00078291
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007829111418686807, 0.0007829111418686807, 0.0007829111418686807, 0.0007829111418686807, 0.0007829111418686807]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007829111418686807

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078291
Iteration 2/1000 | Loss: 0.00004346
Iteration 3/1000 | Loss: 0.00002893
Iteration 4/1000 | Loss: 0.00002489
Iteration 5/1000 | Loss: 0.00007600
Iteration 6/1000 | Loss: 0.00002498
Iteration 7/1000 | Loss: 0.00002162
Iteration 8/1000 | Loss: 0.00002128
Iteration 9/1000 | Loss: 0.00002085
Iteration 10/1000 | Loss: 0.00010140
Iteration 11/1000 | Loss: 0.00023617
Iteration 12/1000 | Loss: 0.00008743
Iteration 13/1000 | Loss: 0.00008575
Iteration 14/1000 | Loss: 0.00005293
Iteration 15/1000 | Loss: 0.00002231
Iteration 16/1000 | Loss: 0.00006765
Iteration 17/1000 | Loss: 0.00002044
Iteration 18/1000 | Loss: 0.00002007
Iteration 19/1000 | Loss: 0.00001989
Iteration 20/1000 | Loss: 0.00001977
Iteration 21/1000 | Loss: 0.00001974
Iteration 22/1000 | Loss: 0.00001970
Iteration 23/1000 | Loss: 0.00001969
Iteration 24/1000 | Loss: 0.00001968
Iteration 25/1000 | Loss: 0.00001967
Iteration 26/1000 | Loss: 0.00001966
Iteration 27/1000 | Loss: 0.00001965
Iteration 28/1000 | Loss: 0.00001965
Iteration 29/1000 | Loss: 0.00001961
Iteration 30/1000 | Loss: 0.00001961
Iteration 31/1000 | Loss: 0.00001960
Iteration 32/1000 | Loss: 0.00001959
Iteration 33/1000 | Loss: 0.00001959
Iteration 34/1000 | Loss: 0.00001959
Iteration 35/1000 | Loss: 0.00001958
Iteration 36/1000 | Loss: 0.00001957
Iteration 37/1000 | Loss: 0.00001956
Iteration 38/1000 | Loss: 0.00001956
Iteration 39/1000 | Loss: 0.00001955
Iteration 40/1000 | Loss: 0.00001955
Iteration 41/1000 | Loss: 0.00001954
Iteration 42/1000 | Loss: 0.00001953
Iteration 43/1000 | Loss: 0.00001952
Iteration 44/1000 | Loss: 0.00001950
Iteration 45/1000 | Loss: 0.00001950
Iteration 46/1000 | Loss: 0.00001950
Iteration 47/1000 | Loss: 0.00001949
Iteration 48/1000 | Loss: 0.00001949
Iteration 49/1000 | Loss: 0.00007882
Iteration 50/1000 | Loss: 0.00002169
Iteration 51/1000 | Loss: 0.00001976
Iteration 52/1000 | Loss: 0.00001947
Iteration 53/1000 | Loss: 0.00001933
Iteration 54/1000 | Loss: 0.00001933
Iteration 55/1000 | Loss: 0.00001933
Iteration 56/1000 | Loss: 0.00001932
Iteration 57/1000 | Loss: 0.00001932
Iteration 58/1000 | Loss: 0.00007013
Iteration 59/1000 | Loss: 0.00001932
Iteration 60/1000 | Loss: 0.00001931
Iteration 61/1000 | Loss: 0.00001931
Iteration 62/1000 | Loss: 0.00001929
Iteration 63/1000 | Loss: 0.00001928
Iteration 64/1000 | Loss: 0.00001928
Iteration 65/1000 | Loss: 0.00001928
Iteration 66/1000 | Loss: 0.00004014
Iteration 67/1000 | Loss: 0.00003485
Iteration 68/1000 | Loss: 0.00002643
Iteration 69/1000 | Loss: 0.00001928
Iteration 70/1000 | Loss: 0.00001928
Iteration 71/1000 | Loss: 0.00001928
Iteration 72/1000 | Loss: 0.00001928
Iteration 73/1000 | Loss: 0.00001928
Iteration 74/1000 | Loss: 0.00001928
Iteration 75/1000 | Loss: 0.00001928
Iteration 76/1000 | Loss: 0.00001928
Iteration 77/1000 | Loss: 0.00001927
Iteration 78/1000 | Loss: 0.00001927
Iteration 79/1000 | Loss: 0.00001927
Iteration 80/1000 | Loss: 0.00001927
Iteration 81/1000 | Loss: 0.00001927
Iteration 82/1000 | Loss: 0.00001927
Iteration 83/1000 | Loss: 0.00001927
Iteration 84/1000 | Loss: 0.00001927
Iteration 85/1000 | Loss: 0.00001927
Iteration 86/1000 | Loss: 0.00001927
Iteration 87/1000 | Loss: 0.00001927
Iteration 88/1000 | Loss: 0.00001927
Iteration 89/1000 | Loss: 0.00001927
Iteration 90/1000 | Loss: 0.00001927
Iteration 91/1000 | Loss: 0.00001927
Iteration 92/1000 | Loss: 0.00001927
Iteration 93/1000 | Loss: 0.00001927
Iteration 94/1000 | Loss: 0.00001927
Iteration 95/1000 | Loss: 0.00001926
Iteration 96/1000 | Loss: 0.00001926
Iteration 97/1000 | Loss: 0.00001926
Iteration 98/1000 | Loss: 0.00003304
Iteration 99/1000 | Loss: 0.00001927
Iteration 100/1000 | Loss: 0.00001926
Iteration 101/1000 | Loss: 0.00001926
Iteration 102/1000 | Loss: 0.00001926
Iteration 103/1000 | Loss: 0.00001926
Iteration 104/1000 | Loss: 0.00001926
Iteration 105/1000 | Loss: 0.00001926
Iteration 106/1000 | Loss: 0.00001926
Iteration 107/1000 | Loss: 0.00001926
Iteration 108/1000 | Loss: 0.00001926
Iteration 109/1000 | Loss: 0.00001926
Iteration 110/1000 | Loss: 0.00001926
Iteration 111/1000 | Loss: 0.00001925
Iteration 112/1000 | Loss: 0.00001924
Iteration 113/1000 | Loss: 0.00001923
Iteration 114/1000 | Loss: 0.00001921
Iteration 115/1000 | Loss: 0.00001918
Iteration 116/1000 | Loss: 0.00001914
Iteration 117/1000 | Loss: 0.00001914
Iteration 118/1000 | Loss: 0.00001914
Iteration 119/1000 | Loss: 0.00001914
Iteration 120/1000 | Loss: 0.00001914
Iteration 121/1000 | Loss: 0.00001914
Iteration 122/1000 | Loss: 0.00001914
Iteration 123/1000 | Loss: 0.00001914
Iteration 124/1000 | Loss: 0.00001914
Iteration 125/1000 | Loss: 0.00001914
Iteration 126/1000 | Loss: 0.00001914
Iteration 127/1000 | Loss: 0.00001913
Iteration 128/1000 | Loss: 0.00001913
Iteration 129/1000 | Loss: 0.00001913
Iteration 130/1000 | Loss: 0.00001913
Iteration 131/1000 | Loss: 0.00001913
Iteration 132/1000 | Loss: 0.00001913
Iteration 133/1000 | Loss: 0.00001912
Iteration 134/1000 | Loss: 0.00001912
Iteration 135/1000 | Loss: 0.00001912
Iteration 136/1000 | Loss: 0.00001910
Iteration 137/1000 | Loss: 0.00001910
Iteration 138/1000 | Loss: 0.00001909
Iteration 139/1000 | Loss: 0.00001909
Iteration 140/1000 | Loss: 0.00001909
Iteration 141/1000 | Loss: 0.00001908
Iteration 142/1000 | Loss: 0.00001908
Iteration 143/1000 | Loss: 0.00001907
Iteration 144/1000 | Loss: 0.00001906
Iteration 145/1000 | Loss: 0.00001903
Iteration 146/1000 | Loss: 0.00001903
Iteration 147/1000 | Loss: 0.00001903
Iteration 148/1000 | Loss: 0.00001903
Iteration 149/1000 | Loss: 0.00001903
Iteration 150/1000 | Loss: 0.00001903
Iteration 151/1000 | Loss: 0.00001903
Iteration 152/1000 | Loss: 0.00001903
Iteration 153/1000 | Loss: 0.00001903
Iteration 154/1000 | Loss: 0.00023666
Iteration 155/1000 | Loss: 0.00016788
Iteration 156/1000 | Loss: 0.00020169
Iteration 157/1000 | Loss: 0.00008658
Iteration 158/1000 | Loss: 0.00020265
Iteration 159/1000 | Loss: 0.00003196
Iteration 160/1000 | Loss: 0.00002325
Iteration 161/1000 | Loss: 0.00001979
Iteration 162/1000 | Loss: 0.00001925
Iteration 163/1000 | Loss: 0.00001886
Iteration 164/1000 | Loss: 0.00004616
Iteration 165/1000 | Loss: 0.00002188
Iteration 166/1000 | Loss: 0.00001924
Iteration 167/1000 | Loss: 0.00001866
Iteration 168/1000 | Loss: 0.00001855
Iteration 169/1000 | Loss: 0.00001855
Iteration 170/1000 | Loss: 0.00001855
Iteration 171/1000 | Loss: 0.00001855
Iteration 172/1000 | Loss: 0.00001855
Iteration 173/1000 | Loss: 0.00001855
Iteration 174/1000 | Loss: 0.00001855
Iteration 175/1000 | Loss: 0.00001855
Iteration 176/1000 | Loss: 0.00001854
Iteration 177/1000 | Loss: 0.00001854
Iteration 178/1000 | Loss: 0.00001854
Iteration 179/1000 | Loss: 0.00001854
Iteration 180/1000 | Loss: 0.00001854
Iteration 181/1000 | Loss: 0.00001854
Iteration 182/1000 | Loss: 0.00001854
Iteration 183/1000 | Loss: 0.00001854
Iteration 184/1000 | Loss: 0.00001853
Iteration 185/1000 | Loss: 0.00001853
Iteration 186/1000 | Loss: 0.00001853
Iteration 187/1000 | Loss: 0.00001853
Iteration 188/1000 | Loss: 0.00001853
Iteration 189/1000 | Loss: 0.00001853
Iteration 190/1000 | Loss: 0.00001852
Iteration 191/1000 | Loss: 0.00001852
Iteration 192/1000 | Loss: 0.00001852
Iteration 193/1000 | Loss: 0.00001851
Iteration 194/1000 | Loss: 0.00001849
Iteration 195/1000 | Loss: 0.00001849
Iteration 196/1000 | Loss: 0.00001848
Iteration 197/1000 | Loss: 0.00001848
Iteration 198/1000 | Loss: 0.00001848
Iteration 199/1000 | Loss: 0.00001847
Iteration 200/1000 | Loss: 0.00001847
Iteration 201/1000 | Loss: 0.00001847
Iteration 202/1000 | Loss: 0.00001847
Iteration 203/1000 | Loss: 0.00001847
Iteration 204/1000 | Loss: 0.00001847
Iteration 205/1000 | Loss: 0.00001846
Iteration 206/1000 | Loss: 0.00001846
Iteration 207/1000 | Loss: 0.00001846
Iteration 208/1000 | Loss: 0.00001846
Iteration 209/1000 | Loss: 0.00006944
Iteration 210/1000 | Loss: 0.00002052
Iteration 211/1000 | Loss: 0.00001881
Iteration 212/1000 | Loss: 0.00001849
Iteration 213/1000 | Loss: 0.00001844
Iteration 214/1000 | Loss: 0.00001844
Iteration 215/1000 | Loss: 0.00001844
Iteration 216/1000 | Loss: 0.00001844
Iteration 217/1000 | Loss: 0.00001844
Iteration 218/1000 | Loss: 0.00001844
Iteration 219/1000 | Loss: 0.00001844
Iteration 220/1000 | Loss: 0.00001844
Iteration 221/1000 | Loss: 0.00001844
Iteration 222/1000 | Loss: 0.00001844
Iteration 223/1000 | Loss: 0.00001843
Iteration 224/1000 | Loss: 0.00001843
Iteration 225/1000 | Loss: 0.00001843
Iteration 226/1000 | Loss: 0.00001843
Iteration 227/1000 | Loss: 0.00001843
Iteration 228/1000 | Loss: 0.00001842
Iteration 229/1000 | Loss: 0.00001842
Iteration 230/1000 | Loss: 0.00001841
Iteration 231/1000 | Loss: 0.00001841
Iteration 232/1000 | Loss: 0.00001841
Iteration 233/1000 | Loss: 0.00001841
Iteration 234/1000 | Loss: 0.00001841
Iteration 235/1000 | Loss: 0.00001841
Iteration 236/1000 | Loss: 0.00001841
Iteration 237/1000 | Loss: 0.00001841
Iteration 238/1000 | Loss: 0.00001841
Iteration 239/1000 | Loss: 0.00001841
Iteration 240/1000 | Loss: 0.00001840
Iteration 241/1000 | Loss: 0.00001840
Iteration 242/1000 | Loss: 0.00001840
Iteration 243/1000 | Loss: 0.00001840
Iteration 244/1000 | Loss: 0.00001840
Iteration 245/1000 | Loss: 0.00001840
Iteration 246/1000 | Loss: 0.00001839
Iteration 247/1000 | Loss: 0.00001839
Iteration 248/1000 | Loss: 0.00001839
Iteration 249/1000 | Loss: 0.00001839
Iteration 250/1000 | Loss: 0.00001839
Iteration 251/1000 | Loss: 0.00001839
Iteration 252/1000 | Loss: 0.00001839
Iteration 253/1000 | Loss: 0.00001839
Iteration 254/1000 | Loss: 0.00001838
Iteration 255/1000 | Loss: 0.00001838
Iteration 256/1000 | Loss: 0.00001838
Iteration 257/1000 | Loss: 0.00001838
Iteration 258/1000 | Loss: 0.00001838
Iteration 259/1000 | Loss: 0.00006140
Iteration 260/1000 | Loss: 0.00006140
Iteration 261/1000 | Loss: 0.00005338
Iteration 262/1000 | Loss: 0.00001864
Iteration 263/1000 | Loss: 0.00001847
Iteration 264/1000 | Loss: 0.00001843
Iteration 265/1000 | Loss: 0.00001843
Iteration 266/1000 | Loss: 0.00001842
Iteration 267/1000 | Loss: 0.00001841
Iteration 268/1000 | Loss: 0.00001841
Iteration 269/1000 | Loss: 0.00001840
Iteration 270/1000 | Loss: 0.00001840
Iteration 271/1000 | Loss: 0.00001840
Iteration 272/1000 | Loss: 0.00001840
Iteration 273/1000 | Loss: 0.00001840
Iteration 274/1000 | Loss: 0.00001839
Iteration 275/1000 | Loss: 0.00001839
Iteration 276/1000 | Loss: 0.00001839
Iteration 277/1000 | Loss: 0.00001839
Iteration 278/1000 | Loss: 0.00001839
Iteration 279/1000 | Loss: 0.00001839
Iteration 280/1000 | Loss: 0.00001839
Iteration 281/1000 | Loss: 0.00001839
Iteration 282/1000 | Loss: 0.00001839
Iteration 283/1000 | Loss: 0.00001839
Iteration 284/1000 | Loss: 0.00001839
Iteration 285/1000 | Loss: 0.00001838
Iteration 286/1000 | Loss: 0.00001838
Iteration 287/1000 | Loss: 0.00001838
Iteration 288/1000 | Loss: 0.00001838
Iteration 289/1000 | Loss: 0.00001838
Iteration 290/1000 | Loss: 0.00001838
Iteration 291/1000 | Loss: 0.00001838
Iteration 292/1000 | Loss: 0.00001838
Iteration 293/1000 | Loss: 0.00001838
Iteration 294/1000 | Loss: 0.00001838
Iteration 295/1000 | Loss: 0.00001837
Iteration 296/1000 | Loss: 0.00001837
Iteration 297/1000 | Loss: 0.00001837
Iteration 298/1000 | Loss: 0.00001837
Iteration 299/1000 | Loss: 0.00001837
Iteration 300/1000 | Loss: 0.00001837
Iteration 301/1000 | Loss: 0.00001837
Iteration 302/1000 | Loss: 0.00001837
Iteration 303/1000 | Loss: 0.00001837
Iteration 304/1000 | Loss: 0.00001837
Iteration 305/1000 | Loss: 0.00006677
Iteration 306/1000 | Loss: 0.00002160
Iteration 307/1000 | Loss: 0.00002518
Iteration 308/1000 | Loss: 0.00002156
Iteration 309/1000 | Loss: 0.00001925
Iteration 310/1000 | Loss: 0.00001893
Iteration 311/1000 | Loss: 0.00001839
Iteration 312/1000 | Loss: 0.00001839
Iteration 313/1000 | Loss: 0.00001839
Iteration 314/1000 | Loss: 0.00001839
Iteration 315/1000 | Loss: 0.00001839
Iteration 316/1000 | Loss: 0.00001839
Iteration 317/1000 | Loss: 0.00001839
Iteration 318/1000 | Loss: 0.00001839
Iteration 319/1000 | Loss: 0.00001839
Iteration 320/1000 | Loss: 0.00001839
Iteration 321/1000 | Loss: 0.00001839
Iteration 322/1000 | Loss: 0.00001839
Iteration 323/1000 | Loss: 0.00001838
Iteration 324/1000 | Loss: 0.00002581
Iteration 325/1000 | Loss: 0.00002581
Iteration 326/1000 | Loss: 0.00002044
Iteration 327/1000 | Loss: 0.00001842
Iteration 328/1000 | Loss: 0.00001842
Iteration 329/1000 | Loss: 0.00001841
Iteration 330/1000 | Loss: 0.00001841
Iteration 331/1000 | Loss: 0.00001841
Iteration 332/1000 | Loss: 0.00001841
Iteration 333/1000 | Loss: 0.00001841
Iteration 334/1000 | Loss: 0.00001891
Iteration 335/1000 | Loss: 0.00001931
Iteration 336/1000 | Loss: 0.00001841
Iteration 337/1000 | Loss: 0.00001841
Iteration 338/1000 | Loss: 0.00001841
Iteration 339/1000 | Loss: 0.00001840
Iteration 340/1000 | Loss: 0.00001840
Iteration 341/1000 | Loss: 0.00001840
Iteration 342/1000 | Loss: 0.00001882
Iteration 343/1000 | Loss: 0.00001844
Iteration 344/1000 | Loss: 0.00001844
Iteration 345/1000 | Loss: 0.00001842
Iteration 346/1000 | Loss: 0.00001841
Iteration 347/1000 | Loss: 0.00001841
Iteration 348/1000 | Loss: 0.00001841
Iteration 349/1000 | Loss: 0.00001841
Iteration 350/1000 | Loss: 0.00001841
Iteration 351/1000 | Loss: 0.00001841
Iteration 352/1000 | Loss: 0.00001841
Iteration 353/1000 | Loss: 0.00001841
Iteration 354/1000 | Loss: 0.00001841
Iteration 355/1000 | Loss: 0.00001841
Iteration 356/1000 | Loss: 0.00001841
Iteration 357/1000 | Loss: 0.00001841
Iteration 358/1000 | Loss: 0.00001841
Iteration 359/1000 | Loss: 0.00001841
Iteration 360/1000 | Loss: 0.00001841
Iteration 361/1000 | Loss: 0.00001841
Iteration 362/1000 | Loss: 0.00001841
Iteration 363/1000 | Loss: 0.00001841
Iteration 364/1000 | Loss: 0.00001841
Iteration 365/1000 | Loss: 0.00001841
Iteration 366/1000 | Loss: 0.00001841
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 366. Stopping optimization.
Last 5 losses: [1.8406595700071193e-05, 1.8406595700071193e-05, 1.8406595700071193e-05, 1.8406595700071193e-05, 1.8406595700071193e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8406595700071193e-05

Optimization complete. Final v2v error: 3.5643484592437744 mm

Highest mean error: 4.789155006408691 mm for frame 85

Lowest mean error: 3.0665249824523926 mm for frame 203

Saving results

Total time: 5128.952398777008
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1094
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00414898
Iteration 2/25 | Loss: 0.00135933
Iteration 3/25 | Loss: 0.00129616
Iteration 4/25 | Loss: 0.00128800
Iteration 5/25 | Loss: 0.00128602
Iteration 6/25 | Loss: 0.00128554
Iteration 7/25 | Loss: 0.00128551
Iteration 8/25 | Loss: 0.00128551
Iteration 9/25 | Loss: 0.00128551
Iteration 10/25 | Loss: 0.00128551
Iteration 11/25 | Loss: 0.00128551
Iteration 12/25 | Loss: 0.00128551
Iteration 13/25 | Loss: 0.00128551
Iteration 14/25 | Loss: 0.00128551
Iteration 15/25 | Loss: 0.00128551
Iteration 16/25 | Loss: 0.00128551
Iteration 17/25 | Loss: 0.00128551
Iteration 18/25 | Loss: 0.00128551
Iteration 19/25 | Loss: 0.00128551
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0012855050154030323, 0.0012855050154030323, 0.0012855050154030323, 0.0012855050154030323, 0.0012855050154030323]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012855050154030323

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47872090
Iteration 2/25 | Loss: 0.00091882
Iteration 3/25 | Loss: 0.00091882
Iteration 4/25 | Loss: 0.00091882
Iteration 5/25 | Loss: 0.00091882
Iteration 6/25 | Loss: 0.00091882
Iteration 7/25 | Loss: 0.00091882
Iteration 8/25 | Loss: 0.00091881
Iteration 9/25 | Loss: 0.00091881
Iteration 10/25 | Loss: 0.00091881
Iteration 11/25 | Loss: 0.00091881
Iteration 12/25 | Loss: 0.00091881
Iteration 13/25 | Loss: 0.00091881
Iteration 14/25 | Loss: 0.00091881
Iteration 15/25 | Loss: 0.00091881
Iteration 16/25 | Loss: 0.00091881
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0009188143885694444, 0.0009188143885694444, 0.0009188143885694444, 0.0009188143885694444, 0.0009188143885694444]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009188143885694444

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00091881
Iteration 2/1000 | Loss: 0.00002537
Iteration 3/1000 | Loss: 0.00001762
Iteration 4/1000 | Loss: 0.00001608
Iteration 5/1000 | Loss: 0.00001514
Iteration 6/1000 | Loss: 0.00001455
Iteration 7/1000 | Loss: 0.00001413
Iteration 8/1000 | Loss: 0.00001378
Iteration 9/1000 | Loss: 0.00001359
Iteration 10/1000 | Loss: 0.00001346
Iteration 11/1000 | Loss: 0.00001326
Iteration 12/1000 | Loss: 0.00001305
Iteration 13/1000 | Loss: 0.00001291
Iteration 14/1000 | Loss: 0.00001288
Iteration 15/1000 | Loss: 0.00001287
Iteration 16/1000 | Loss: 0.00001275
Iteration 17/1000 | Loss: 0.00001268
Iteration 18/1000 | Loss: 0.00001266
Iteration 19/1000 | Loss: 0.00001265
Iteration 20/1000 | Loss: 0.00001265
Iteration 21/1000 | Loss: 0.00001263
Iteration 22/1000 | Loss: 0.00001262
Iteration 23/1000 | Loss: 0.00001261
Iteration 24/1000 | Loss: 0.00001261
Iteration 25/1000 | Loss: 0.00001261
Iteration 26/1000 | Loss: 0.00001260
Iteration 27/1000 | Loss: 0.00001259
Iteration 28/1000 | Loss: 0.00001259
Iteration 29/1000 | Loss: 0.00001259
Iteration 30/1000 | Loss: 0.00001257
Iteration 31/1000 | Loss: 0.00001257
Iteration 32/1000 | Loss: 0.00001257
Iteration 33/1000 | Loss: 0.00001257
Iteration 34/1000 | Loss: 0.00001257
Iteration 35/1000 | Loss: 0.00001257
Iteration 36/1000 | Loss: 0.00001257
Iteration 37/1000 | Loss: 0.00001257
Iteration 38/1000 | Loss: 0.00001257
Iteration 39/1000 | Loss: 0.00001257
Iteration 40/1000 | Loss: 0.00001257
Iteration 41/1000 | Loss: 0.00001257
Iteration 42/1000 | Loss: 0.00001257
Iteration 43/1000 | Loss: 0.00001257
Iteration 44/1000 | Loss: 0.00001257
Iteration 45/1000 | Loss: 0.00001257
Iteration 46/1000 | Loss: 0.00001257
Iteration 47/1000 | Loss: 0.00001257
Iteration 48/1000 | Loss: 0.00001257
Iteration 49/1000 | Loss: 0.00001257
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 49. Stopping optimization.
Last 5 losses: [1.2565954421006609e-05, 1.2565954421006609e-05, 1.2565954421006609e-05, 1.2565954421006609e-05, 1.2565954421006609e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2565954421006609e-05

Optimization complete. Final v2v error: 3.000779628753662 mm

Highest mean error: 3.8987741470336914 mm for frame 74

Lowest mean error: 2.770028829574585 mm for frame 121

Saving results

Total time: 539.0521245002747
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1084/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1084.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1084
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00823594
Iteration 2/25 | Loss: 0.00159529
Iteration 3/25 | Loss: 0.00143442
Iteration 4/25 | Loss: 0.00140723
Iteration 5/25 | Loss: 0.00140164
Iteration 6/25 | Loss: 0.00140049
Iteration 7/25 | Loss: 0.00140049
Iteration 8/25 | Loss: 0.00140049
Iteration 9/25 | Loss: 0.00140049
Iteration 10/25 | Loss: 0.00140049
Iteration 11/25 | Loss: 0.00140049
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001400494365952909, 0.001400494365952909, 0.001400494365952909, 0.001400494365952909, 0.001400494365952909]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001400494365952909

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35294151
Iteration 2/25 | Loss: 0.00079536
Iteration 3/25 | Loss: 0.00079527
Iteration 4/25 | Loss: 0.00079527
Iteration 5/25 | Loss: 0.00079527
Iteration 6/25 | Loss: 0.00079527
Iteration 7/25 | Loss: 0.00079527
Iteration 8/25 | Loss: 0.00079527
Iteration 9/25 | Loss: 0.00079527
Iteration 10/25 | Loss: 0.00079527
Iteration 11/25 | Loss: 0.00079527
Iteration 12/25 | Loss: 0.00079527
Iteration 13/25 | Loss: 0.00079527
Iteration 14/25 | Loss: 0.00079527
Iteration 15/25 | Loss: 0.00079527
Iteration 16/25 | Loss: 0.00079527
Iteration 17/25 | Loss: 0.00079527
Iteration 18/25 | Loss: 0.00079527
Iteration 19/25 | Loss: 0.00079527
Iteration 20/25 | Loss: 0.00079527
Iteration 21/25 | Loss: 0.00079527
Iteration 22/25 | Loss: 0.00079527
Iteration 23/25 | Loss: 0.00079527
Iteration 24/25 | Loss: 0.00079527
Iteration 25/25 | Loss: 0.00079527

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079527
Iteration 2/1000 | Loss: 0.00005750
Iteration 3/1000 | Loss: 0.00004009
Iteration 4/1000 | Loss: 0.00003602
Iteration 5/1000 | Loss: 0.00003458
Iteration 6/1000 | Loss: 0.00003368
Iteration 7/1000 | Loss: 0.00003296
Iteration 8/1000 | Loss: 0.00003229
Iteration 9/1000 | Loss: 0.00003170
Iteration 10/1000 | Loss: 0.00003134
Iteration 11/1000 | Loss: 0.00003106
Iteration 12/1000 | Loss: 0.00003086
Iteration 13/1000 | Loss: 0.00003068
Iteration 14/1000 | Loss: 0.00003065
Iteration 15/1000 | Loss: 0.00003058
Iteration 16/1000 | Loss: 0.00003053
Iteration 17/1000 | Loss: 0.00003044
Iteration 18/1000 | Loss: 0.00003036
Iteration 19/1000 | Loss: 0.00003032
Iteration 20/1000 | Loss: 0.00003032
Iteration 21/1000 | Loss: 0.00003032
Iteration 22/1000 | Loss: 0.00003029
Iteration 23/1000 | Loss: 0.00003027
Iteration 24/1000 | Loss: 0.00003027
Iteration 25/1000 | Loss: 0.00003026
Iteration 26/1000 | Loss: 0.00003023
Iteration 27/1000 | Loss: 0.00003023
Iteration 28/1000 | Loss: 0.00003023
Iteration 29/1000 | Loss: 0.00003023
Iteration 30/1000 | Loss: 0.00003021
Iteration 31/1000 | Loss: 0.00003020
Iteration 32/1000 | Loss: 0.00003020
Iteration 33/1000 | Loss: 0.00003020
Iteration 34/1000 | Loss: 0.00003019
Iteration 35/1000 | Loss: 0.00003019
Iteration 36/1000 | Loss: 0.00003019
Iteration 37/1000 | Loss: 0.00003019
Iteration 38/1000 | Loss: 0.00003019
Iteration 39/1000 | Loss: 0.00003019
Iteration 40/1000 | Loss: 0.00003019
Iteration 41/1000 | Loss: 0.00003018
Iteration 42/1000 | Loss: 0.00003018
Iteration 43/1000 | Loss: 0.00003018
Iteration 44/1000 | Loss: 0.00003018
Iteration 45/1000 | Loss: 0.00003018
Iteration 46/1000 | Loss: 0.00003018
Iteration 47/1000 | Loss: 0.00003017
Iteration 48/1000 | Loss: 0.00003017
Iteration 49/1000 | Loss: 0.00003017
Iteration 50/1000 | Loss: 0.00003016
Iteration 51/1000 | Loss: 0.00003016
Iteration 52/1000 | Loss: 0.00003016
Iteration 53/1000 | Loss: 0.00003016
Iteration 54/1000 | Loss: 0.00003016
Iteration 55/1000 | Loss: 0.00003016
Iteration 56/1000 | Loss: 0.00003016
Iteration 57/1000 | Loss: 0.00003016
Iteration 58/1000 | Loss: 0.00003016
Iteration 59/1000 | Loss: 0.00003016
Iteration 60/1000 | Loss: 0.00003016
Iteration 61/1000 | Loss: 0.00003015
Iteration 62/1000 | Loss: 0.00003015
Iteration 63/1000 | Loss: 0.00003015
Iteration 64/1000 | Loss: 0.00003013
Iteration 65/1000 | Loss: 0.00003013
Iteration 66/1000 | Loss: 0.00003013
Iteration 67/1000 | Loss: 0.00003013
Iteration 68/1000 | Loss: 0.00003013
Iteration 69/1000 | Loss: 0.00003013
Iteration 70/1000 | Loss: 0.00003013
Iteration 71/1000 | Loss: 0.00003013
Iteration 72/1000 | Loss: 0.00003013
Iteration 73/1000 | Loss: 0.00003012
Iteration 74/1000 | Loss: 0.00003012
Iteration 75/1000 | Loss: 0.00003012
Iteration 76/1000 | Loss: 0.00003012
Iteration 77/1000 | Loss: 0.00003012
Iteration 78/1000 | Loss: 0.00003012
Iteration 79/1000 | Loss: 0.00003012
Iteration 80/1000 | Loss: 0.00003012
Iteration 81/1000 | Loss: 0.00003011
Iteration 82/1000 | Loss: 0.00003010
Iteration 83/1000 | Loss: 0.00003010
Iteration 84/1000 | Loss: 0.00003009
Iteration 85/1000 | Loss: 0.00003009
Iteration 86/1000 | Loss: 0.00003009
Iteration 87/1000 | Loss: 0.00003009
Iteration 88/1000 | Loss: 0.00003009
Iteration 89/1000 | Loss: 0.00003009
Iteration 90/1000 | Loss: 0.00003008
Iteration 91/1000 | Loss: 0.00003008
Iteration 92/1000 | Loss: 0.00003008
Iteration 93/1000 | Loss: 0.00003008
Iteration 94/1000 | Loss: 0.00003008
Iteration 95/1000 | Loss: 0.00003007
Iteration 96/1000 | Loss: 0.00003007
Iteration 97/1000 | Loss: 0.00003007
Iteration 98/1000 | Loss: 0.00003006
Iteration 99/1000 | Loss: 0.00003006
Iteration 100/1000 | Loss: 0.00003006
Iteration 101/1000 | Loss: 0.00003006
Iteration 102/1000 | Loss: 0.00003006
Iteration 103/1000 | Loss: 0.00003005
Iteration 104/1000 | Loss: 0.00003005
Iteration 105/1000 | Loss: 0.00003005
Iteration 106/1000 | Loss: 0.00003005
Iteration 107/1000 | Loss: 0.00003005
Iteration 108/1000 | Loss: 0.00003005
Iteration 109/1000 | Loss: 0.00003005
Iteration 110/1000 | Loss: 0.00003005
Iteration 111/1000 | Loss: 0.00003005
Iteration 112/1000 | Loss: 0.00003004
Iteration 113/1000 | Loss: 0.00003004
Iteration 114/1000 | Loss: 0.00003004
Iteration 115/1000 | Loss: 0.00003004
Iteration 116/1000 | Loss: 0.00003003
Iteration 117/1000 | Loss: 0.00003003
Iteration 118/1000 | Loss: 0.00003003
Iteration 119/1000 | Loss: 0.00003003
Iteration 120/1000 | Loss: 0.00003003
Iteration 121/1000 | Loss: 0.00003002
Iteration 122/1000 | Loss: 0.00003002
Iteration 123/1000 | Loss: 0.00003002
Iteration 124/1000 | Loss: 0.00003002
Iteration 125/1000 | Loss: 0.00003002
Iteration 126/1000 | Loss: 0.00003002
Iteration 127/1000 | Loss: 0.00003002
Iteration 128/1000 | Loss: 0.00003002
Iteration 129/1000 | Loss: 0.00003002
Iteration 130/1000 | Loss: 0.00003002
Iteration 131/1000 | Loss: 0.00003001
Iteration 132/1000 | Loss: 0.00003001
Iteration 133/1000 | Loss: 0.00003001
Iteration 134/1000 | Loss: 0.00003001
Iteration 135/1000 | Loss: 0.00003001
Iteration 136/1000 | Loss: 0.00003001
Iteration 137/1000 | Loss: 0.00003001
Iteration 138/1000 | Loss: 0.00003001
Iteration 139/1000 | Loss: 0.00003001
Iteration 140/1000 | Loss: 0.00003001
Iteration 141/1000 | Loss: 0.00003001
Iteration 142/1000 | Loss: 0.00003001
Iteration 143/1000 | Loss: 0.00003001
Iteration 144/1000 | Loss: 0.00003001
Iteration 145/1000 | Loss: 0.00003001
Iteration 146/1000 | Loss: 0.00003001
Iteration 147/1000 | Loss: 0.00003001
Iteration 148/1000 | Loss: 0.00003001
Iteration 149/1000 | Loss: 0.00003001
Iteration 150/1000 | Loss: 0.00003001
Iteration 151/1000 | Loss: 0.00003001
Iteration 152/1000 | Loss: 0.00003001
Iteration 153/1000 | Loss: 0.00003001
Iteration 154/1000 | Loss: 0.00003001
Iteration 155/1000 | Loss: 0.00003001
Iteration 156/1000 | Loss: 0.00003001
Iteration 157/1000 | Loss: 0.00003001
Iteration 158/1000 | Loss: 0.00003001
Iteration 159/1000 | Loss: 0.00003001
Iteration 160/1000 | Loss: 0.00003001
Iteration 161/1000 | Loss: 0.00003001
Iteration 162/1000 | Loss: 0.00003001
Iteration 163/1000 | Loss: 0.00003001
Iteration 164/1000 | Loss: 0.00003001
Iteration 165/1000 | Loss: 0.00003001
Iteration 166/1000 | Loss: 0.00003001
Iteration 167/1000 | Loss: 0.00003001
Iteration 168/1000 | Loss: 0.00003001
Iteration 169/1000 | Loss: 0.00003001
Iteration 170/1000 | Loss: 0.00003001
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 170. Stopping optimization.
Last 5 losses: [3.0011879061930813e-05, 3.0011879061930813e-05, 3.0011879061930813e-05, 3.0011879061930813e-05, 3.0011879061930813e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.0011879061930813e-05

Optimization complete. Final v2v error: 4.552572250366211 mm

Highest mean error: 4.806529521942139 mm for frame 24

Lowest mean error: 4.264886379241943 mm for frame 120

Saving results

Total time: 918.3173446655273
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1004
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402474
Iteration 2/25 | Loss: 0.00141832
Iteration 3/25 | Loss: 0.00131701
Iteration 4/25 | Loss: 0.00129861
Iteration 5/25 | Loss: 0.00129238
Iteration 6/25 | Loss: 0.00129193
Iteration 7/25 | Loss: 0.00129193
Iteration 8/25 | Loss: 0.00129193
Iteration 9/25 | Loss: 0.00129193
Iteration 10/25 | Loss: 0.00129193
Iteration 11/25 | Loss: 0.00129193
Iteration 12/25 | Loss: 0.00129193
Iteration 13/25 | Loss: 0.00129193
Iteration 14/25 | Loss: 0.00129193
Iteration 15/25 | Loss: 0.00129193
Iteration 16/25 | Loss: 0.00129193
Iteration 17/25 | Loss: 0.00129193
Iteration 18/25 | Loss: 0.00129193
Iteration 19/25 | Loss: 0.00129193
Iteration 20/25 | Loss: 0.00129193
Iteration 21/25 | Loss: 0.00129193
Iteration 22/25 | Loss: 0.00129193
Iteration 23/25 | Loss: 0.00129193
Iteration 24/25 | Loss: 0.00129193
Iteration 25/25 | Loss: 0.00129193

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35887086
Iteration 2/25 | Loss: 0.00079898
Iteration 3/25 | Loss: 0.00079898
Iteration 4/25 | Loss: 0.00079898
Iteration 5/25 | Loss: 0.00079898
Iteration 6/25 | Loss: 0.00079898
Iteration 7/25 | Loss: 0.00079898
Iteration 8/25 | Loss: 0.00079898
Iteration 9/25 | Loss: 0.00079898
Iteration 10/25 | Loss: 0.00079898
Iteration 11/25 | Loss: 0.00079898
Iteration 12/25 | Loss: 0.00079898
Iteration 13/25 | Loss: 0.00079898
Iteration 14/25 | Loss: 0.00079898
Iteration 15/25 | Loss: 0.00079898
Iteration 16/25 | Loss: 0.00079898
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007989809382706881, 0.0007989809382706881, 0.0007989809382706881, 0.0007989809382706881, 0.0007989809382706881]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007989809382706881

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079898
Iteration 2/1000 | Loss: 0.00004658
Iteration 3/1000 | Loss: 0.00003519
Iteration 4/1000 | Loss: 0.00003219
Iteration 5/1000 | Loss: 0.00003031
Iteration 6/1000 | Loss: 0.00002881
Iteration 7/1000 | Loss: 0.00002801
Iteration 8/1000 | Loss: 0.00002743
Iteration 9/1000 | Loss: 0.00002684
Iteration 10/1000 | Loss: 0.00002639
Iteration 11/1000 | Loss: 0.00002612
Iteration 12/1000 | Loss: 0.00002579
Iteration 13/1000 | Loss: 0.00002552
Iteration 14/1000 | Loss: 0.00002531
Iteration 15/1000 | Loss: 0.00002524
Iteration 16/1000 | Loss: 0.00002518
Iteration 17/1000 | Loss: 0.00002504
Iteration 18/1000 | Loss: 0.00002504
Iteration 19/1000 | Loss: 0.00002502
Iteration 20/1000 | Loss: 0.00002502
Iteration 21/1000 | Loss: 0.00002501
Iteration 22/1000 | Loss: 0.00002501
Iteration 23/1000 | Loss: 0.00002499
Iteration 24/1000 | Loss: 0.00002499
Iteration 25/1000 | Loss: 0.00002499
Iteration 26/1000 | Loss: 0.00002498
Iteration 27/1000 | Loss: 0.00002498
Iteration 28/1000 | Loss: 0.00002497
Iteration 29/1000 | Loss: 0.00002497
Iteration 30/1000 | Loss: 0.00002495
Iteration 31/1000 | Loss: 0.00002494
Iteration 32/1000 | Loss: 0.00002494
Iteration 33/1000 | Loss: 0.00002493
Iteration 34/1000 | Loss: 0.00002493
Iteration 35/1000 | Loss: 0.00002493
Iteration 36/1000 | Loss: 0.00002492
Iteration 37/1000 | Loss: 0.00002492
Iteration 38/1000 | Loss: 0.00002491
Iteration 39/1000 | Loss: 0.00002491
Iteration 40/1000 | Loss: 0.00002491
Iteration 41/1000 | Loss: 0.00002490
Iteration 42/1000 | Loss: 0.00002490
Iteration 43/1000 | Loss: 0.00002490
Iteration 44/1000 | Loss: 0.00002490
Iteration 45/1000 | Loss: 0.00002489
Iteration 46/1000 | Loss: 0.00002489
Iteration 47/1000 | Loss: 0.00002489
Iteration 48/1000 | Loss: 0.00002488
Iteration 49/1000 | Loss: 0.00002488
Iteration 50/1000 | Loss: 0.00002488
Iteration 51/1000 | Loss: 0.00002487
Iteration 52/1000 | Loss: 0.00002487
Iteration 53/1000 | Loss: 0.00002487
Iteration 54/1000 | Loss: 0.00002487
Iteration 55/1000 | Loss: 0.00002486
Iteration 56/1000 | Loss: 0.00002486
Iteration 57/1000 | Loss: 0.00002486
Iteration 58/1000 | Loss: 0.00002486
Iteration 59/1000 | Loss: 0.00002486
Iteration 60/1000 | Loss: 0.00002486
Iteration 61/1000 | Loss: 0.00002485
Iteration 62/1000 | Loss: 0.00002485
Iteration 63/1000 | Loss: 0.00002484
Iteration 64/1000 | Loss: 0.00002484
Iteration 65/1000 | Loss: 0.00002484
Iteration 66/1000 | Loss: 0.00002484
Iteration 67/1000 | Loss: 0.00002484
Iteration 68/1000 | Loss: 0.00002483
Iteration 69/1000 | Loss: 0.00002483
Iteration 70/1000 | Loss: 0.00002483
Iteration 71/1000 | Loss: 0.00002483
Iteration 72/1000 | Loss: 0.00002483
Iteration 73/1000 | Loss: 0.00002483
Iteration 74/1000 | Loss: 0.00002483
Iteration 75/1000 | Loss: 0.00002482
Iteration 76/1000 | Loss: 0.00002482
Iteration 77/1000 | Loss: 0.00002482
Iteration 78/1000 | Loss: 0.00002482
Iteration 79/1000 | Loss: 0.00002482
Iteration 80/1000 | Loss: 0.00002482
Iteration 81/1000 | Loss: 0.00002481
Iteration 82/1000 | Loss: 0.00002481
Iteration 83/1000 | Loss: 0.00002481
Iteration 84/1000 | Loss: 0.00002481
Iteration 85/1000 | Loss: 0.00002481
Iteration 86/1000 | Loss: 0.00002481
Iteration 87/1000 | Loss: 0.00002481
Iteration 88/1000 | Loss: 0.00002481
Iteration 89/1000 | Loss: 0.00002481
Iteration 90/1000 | Loss: 0.00002480
Iteration 91/1000 | Loss: 0.00002480
Iteration 92/1000 | Loss: 0.00002480
Iteration 93/1000 | Loss: 0.00002480
Iteration 94/1000 | Loss: 0.00002480
Iteration 95/1000 | Loss: 0.00002479
Iteration 96/1000 | Loss: 0.00002479
Iteration 97/1000 | Loss: 0.00002479
Iteration 98/1000 | Loss: 0.00002479
Iteration 99/1000 | Loss: 0.00002479
Iteration 100/1000 | Loss: 0.00002478
Iteration 101/1000 | Loss: 0.00002478
Iteration 102/1000 | Loss: 0.00002478
Iteration 103/1000 | Loss: 0.00002478
Iteration 104/1000 | Loss: 0.00002477
Iteration 105/1000 | Loss: 0.00002477
Iteration 106/1000 | Loss: 0.00002477
Iteration 107/1000 | Loss: 0.00002476
Iteration 108/1000 | Loss: 0.00002476
Iteration 109/1000 | Loss: 0.00002476
Iteration 110/1000 | Loss: 0.00002475
Iteration 111/1000 | Loss: 0.00002475
Iteration 112/1000 | Loss: 0.00002475
Iteration 113/1000 | Loss: 0.00002474
Iteration 114/1000 | Loss: 0.00002473
Iteration 115/1000 | Loss: 0.00002473
Iteration 116/1000 | Loss: 0.00002473
Iteration 117/1000 | Loss: 0.00002472
Iteration 118/1000 | Loss: 0.00002472
Iteration 119/1000 | Loss: 0.00002472
Iteration 120/1000 | Loss: 0.00002471
Iteration 121/1000 | Loss: 0.00002471
Iteration 122/1000 | Loss: 0.00002470
Iteration 123/1000 | Loss: 0.00002470
Iteration 124/1000 | Loss: 0.00002470
Iteration 125/1000 | Loss: 0.00002470
Iteration 126/1000 | Loss: 0.00002470
Iteration 127/1000 | Loss: 0.00002470
Iteration 128/1000 | Loss: 0.00002469
Iteration 129/1000 | Loss: 0.00002469
Iteration 130/1000 | Loss: 0.00002469
Iteration 131/1000 | Loss: 0.00002469
Iteration 132/1000 | Loss: 0.00002469
Iteration 133/1000 | Loss: 0.00002468
Iteration 134/1000 | Loss: 0.00002468
Iteration 135/1000 | Loss: 0.00002468
Iteration 136/1000 | Loss: 0.00002468
Iteration 137/1000 | Loss: 0.00002468
Iteration 138/1000 | Loss: 0.00002468
Iteration 139/1000 | Loss: 0.00002468
Iteration 140/1000 | Loss: 0.00002468
Iteration 141/1000 | Loss: 0.00002468
Iteration 142/1000 | Loss: 0.00002468
Iteration 143/1000 | Loss: 0.00002467
Iteration 144/1000 | Loss: 0.00002467
Iteration 145/1000 | Loss: 0.00002467
Iteration 146/1000 | Loss: 0.00002467
Iteration 147/1000 | Loss: 0.00002467
Iteration 148/1000 | Loss: 0.00002467
Iteration 149/1000 | Loss: 0.00002467
Iteration 150/1000 | Loss: 0.00002467
Iteration 151/1000 | Loss: 0.00002467
Iteration 152/1000 | Loss: 0.00002467
Iteration 153/1000 | Loss: 0.00002467
Iteration 154/1000 | Loss: 0.00002466
Iteration 155/1000 | Loss: 0.00002466
Iteration 156/1000 | Loss: 0.00002466
Iteration 157/1000 | Loss: 0.00002466
Iteration 158/1000 | Loss: 0.00002466
Iteration 159/1000 | Loss: 0.00002466
Iteration 160/1000 | Loss: 0.00002466
Iteration 161/1000 | Loss: 0.00002466
Iteration 162/1000 | Loss: 0.00002466
Iteration 163/1000 | Loss: 0.00002466
Iteration 164/1000 | Loss: 0.00002466
Iteration 165/1000 | Loss: 0.00002466
Iteration 166/1000 | Loss: 0.00002466
Iteration 167/1000 | Loss: 0.00002466
Iteration 168/1000 | Loss: 0.00002466
Iteration 169/1000 | Loss: 0.00002466
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 169. Stopping optimization.
Last 5 losses: [2.4663911972311325e-05, 2.4663911972311325e-05, 2.4663911972311325e-05, 2.4663911972311325e-05, 2.4663911972311325e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4663911972311325e-05

Optimization complete. Final v2v error: 4.062843322753906 mm

Highest mean error: 4.550609111785889 mm for frame 82

Lowest mean error: 3.547239303588867 mm for frame 209

Saving results

Total time: 1392.9062356948853
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1086
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00939162
Iteration 2/25 | Loss: 0.00291314
Iteration 3/25 | Loss: 0.00235763
Iteration 4/25 | Loss: 0.00231403
Iteration 5/25 | Loss: 0.00183794
Iteration 6/25 | Loss: 0.00169030
Iteration 7/25 | Loss: 0.00160023
Iteration 8/25 | Loss: 0.00161365
Iteration 9/25 | Loss: 0.00159363
Iteration 10/25 | Loss: 0.00152460
Iteration 11/25 | Loss: 0.00150945
Iteration 12/25 | Loss: 0.00149069
Iteration 13/25 | Loss: 0.00149622
Iteration 14/25 | Loss: 0.00148688
Iteration 15/25 | Loss: 0.00149912
Iteration 16/25 | Loss: 0.00149505
Iteration 17/25 | Loss: 0.00148558
Iteration 18/25 | Loss: 0.00148444
Iteration 19/25 | Loss: 0.00148392
Iteration 20/25 | Loss: 0.00148362
Iteration 21/25 | Loss: 0.00148325
Iteration 22/25 | Loss: 0.00148310
Iteration 23/25 | Loss: 0.00148280
Iteration 24/25 | Loss: 0.00148239
Iteration 25/25 | Loss: 0.00148219

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39157104
Iteration 2/25 | Loss: 0.00115155
Iteration 3/25 | Loss: 0.00115155
Iteration 4/25 | Loss: 0.00115155
Iteration 5/25 | Loss: 0.00115155
Iteration 6/25 | Loss: 0.00115155
Iteration 7/25 | Loss: 0.00115155
Iteration 8/25 | Loss: 0.00115155
Iteration 9/25 | Loss: 0.00115155
Iteration 10/25 | Loss: 0.00115155
Iteration 11/25 | Loss: 0.00115155
Iteration 12/25 | Loss: 0.00115154
Iteration 13/25 | Loss: 0.00115154
Iteration 14/25 | Loss: 0.00115154
Iteration 15/25 | Loss: 0.00115154
Iteration 16/25 | Loss: 0.00115154
Iteration 17/25 | Loss: 0.00115154
Iteration 18/25 | Loss: 0.00115154
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0011515446240082383, 0.0011515446240082383, 0.0011515446240082383, 0.0011515446240082383, 0.0011515446240082383]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011515446240082383

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00115154
Iteration 2/1000 | Loss: 0.00129186
Iteration 3/1000 | Loss: 0.00065202
Iteration 4/1000 | Loss: 0.00070320
Iteration 5/1000 | Loss: 0.00107108
Iteration 6/1000 | Loss: 0.00075310
Iteration 7/1000 | Loss: 0.00041307
Iteration 8/1000 | Loss: 0.00043735
Iteration 9/1000 | Loss: 0.00032422
Iteration 10/1000 | Loss: 0.00020156
Iteration 11/1000 | Loss: 0.00038605
Iteration 12/1000 | Loss: 0.00026640
Iteration 13/1000 | Loss: 0.00045739
Iteration 14/1000 | Loss: 0.00059519
Iteration 15/1000 | Loss: 0.00023123
Iteration 16/1000 | Loss: 0.00023343
Iteration 17/1000 | Loss: 0.00115915
Iteration 18/1000 | Loss: 0.00021350
Iteration 19/1000 | Loss: 0.00018940
Iteration 20/1000 | Loss: 0.00007849
Iteration 21/1000 | Loss: 0.00018888
Iteration 22/1000 | Loss: 0.00006248
Iteration 23/1000 | Loss: 0.00015896
Iteration 24/1000 | Loss: 0.00059005
Iteration 25/1000 | Loss: 0.00033385
Iteration 26/1000 | Loss: 0.00039432
Iteration 27/1000 | Loss: 0.00020241
Iteration 28/1000 | Loss: 0.00009176
Iteration 29/1000 | Loss: 0.00010540
Iteration 30/1000 | Loss: 0.00035269
Iteration 31/1000 | Loss: 0.00017965
Iteration 32/1000 | Loss: 0.00005195
Iteration 33/1000 | Loss: 0.00033327
Iteration 34/1000 | Loss: 0.00068045
Iteration 35/1000 | Loss: 0.00020250
Iteration 36/1000 | Loss: 0.00089818
Iteration 37/1000 | Loss: 0.00005359
Iteration 38/1000 | Loss: 0.00015970
Iteration 39/1000 | Loss: 0.00010911
Iteration 40/1000 | Loss: 0.00005947
Iteration 41/1000 | Loss: 0.00004971
Iteration 42/1000 | Loss: 0.00033734
Iteration 43/1000 | Loss: 0.00042190
Iteration 44/1000 | Loss: 0.00009944
Iteration 45/1000 | Loss: 0.00011250
Iteration 46/1000 | Loss: 0.00015299
Iteration 47/1000 | Loss: 0.00048202
Iteration 48/1000 | Loss: 0.00005313
Iteration 49/1000 | Loss: 0.00035958
Iteration 50/1000 | Loss: 0.00084189
Iteration 51/1000 | Loss: 0.00076072
Iteration 52/1000 | Loss: 0.00025445
Iteration 53/1000 | Loss: 0.00018095
Iteration 54/1000 | Loss: 0.00007820
Iteration 55/1000 | Loss: 0.00010354
Iteration 56/1000 | Loss: 0.00011801
Iteration 57/1000 | Loss: 0.00013045
Iteration 58/1000 | Loss: 0.00016958
Iteration 59/1000 | Loss: 0.00010848
Iteration 60/1000 | Loss: 0.00013366
Iteration 61/1000 | Loss: 0.00011172
Iteration 62/1000 | Loss: 0.00011645
Iteration 63/1000 | Loss: 0.00014690
Iteration 64/1000 | Loss: 0.00030609
Iteration 65/1000 | Loss: 0.00011699
Iteration 66/1000 | Loss: 0.00010972
Iteration 67/1000 | Loss: 0.00003685
Iteration 68/1000 | Loss: 0.00012694
Iteration 69/1000 | Loss: 0.00010882
Iteration 70/1000 | Loss: 0.00008361
Iteration 71/1000 | Loss: 0.00010221
Iteration 72/1000 | Loss: 0.00010610
Iteration 73/1000 | Loss: 0.00012024
Iteration 74/1000 | Loss: 0.00066502
Iteration 75/1000 | Loss: 0.00011973
Iteration 76/1000 | Loss: 0.00012284
Iteration 77/1000 | Loss: 0.00009652
Iteration 78/1000 | Loss: 0.00015206
Iteration 79/1000 | Loss: 0.00018210
Iteration 80/1000 | Loss: 0.00016075
Iteration 81/1000 | Loss: 0.00013169
Iteration 82/1000 | Loss: 0.00004776
Iteration 83/1000 | Loss: 0.00003939
Iteration 84/1000 | Loss: 0.00003508
Iteration 85/1000 | Loss: 0.00003335
Iteration 86/1000 | Loss: 0.00003259
Iteration 87/1000 | Loss: 0.00003179
Iteration 88/1000 | Loss: 0.00003138
Iteration 89/1000 | Loss: 0.00003102
Iteration 90/1000 | Loss: 0.00003077
Iteration 91/1000 | Loss: 0.00005000
Iteration 92/1000 | Loss: 0.00003194
Iteration 93/1000 | Loss: 0.00003124
Iteration 94/1000 | Loss: 0.00003081
Iteration 95/1000 | Loss: 0.00003044
Iteration 96/1000 | Loss: 0.00003014
Iteration 97/1000 | Loss: 0.00002998
Iteration 98/1000 | Loss: 0.00002981
Iteration 99/1000 | Loss: 0.00002976
Iteration 100/1000 | Loss: 0.00002970
Iteration 101/1000 | Loss: 0.00002953
Iteration 102/1000 | Loss: 0.00002949
Iteration 103/1000 | Loss: 0.00002945
Iteration 104/1000 | Loss: 0.00002944
Iteration 105/1000 | Loss: 0.00002943
Iteration 106/1000 | Loss: 0.00002941
Iteration 107/1000 | Loss: 0.00002941
Iteration 108/1000 | Loss: 0.00002941
Iteration 109/1000 | Loss: 0.00002941
Iteration 110/1000 | Loss: 0.00002941
Iteration 111/1000 | Loss: 0.00002941
Iteration 112/1000 | Loss: 0.00002941
Iteration 113/1000 | Loss: 0.00002941
Iteration 114/1000 | Loss: 0.00002941
Iteration 115/1000 | Loss: 0.00002941
Iteration 116/1000 | Loss: 0.00002940
Iteration 117/1000 | Loss: 0.00002940
Iteration 118/1000 | Loss: 0.00002940
Iteration 119/1000 | Loss: 0.00002940
Iteration 120/1000 | Loss: 0.00002939
Iteration 121/1000 | Loss: 0.00002937
Iteration 122/1000 | Loss: 0.00002933
Iteration 123/1000 | Loss: 0.00002927
Iteration 124/1000 | Loss: 0.00002919
Iteration 125/1000 | Loss: 0.00002919
Iteration 126/1000 | Loss: 0.00002917
Iteration 127/1000 | Loss: 0.00002917
Iteration 128/1000 | Loss: 0.00002917
Iteration 129/1000 | Loss: 0.00002917
Iteration 130/1000 | Loss: 0.00002917
Iteration 131/1000 | Loss: 0.00002917
Iteration 132/1000 | Loss: 0.00002917
Iteration 133/1000 | Loss: 0.00002917
Iteration 134/1000 | Loss: 0.00002917
Iteration 135/1000 | Loss: 0.00002917
Iteration 136/1000 | Loss: 0.00002916
Iteration 137/1000 | Loss: 0.00002916
Iteration 138/1000 | Loss: 0.00002915
Iteration 139/1000 | Loss: 0.00002915
Iteration 140/1000 | Loss: 0.00002914
Iteration 141/1000 | Loss: 0.00002914
Iteration 142/1000 | Loss: 0.00002914
Iteration 143/1000 | Loss: 0.00002914
Iteration 144/1000 | Loss: 0.00002914
Iteration 145/1000 | Loss: 0.00002914
Iteration 146/1000 | Loss: 0.00002914
Iteration 147/1000 | Loss: 0.00002914
Iteration 148/1000 | Loss: 0.00002914
Iteration 149/1000 | Loss: 0.00002914
Iteration 150/1000 | Loss: 0.00002914
Iteration 151/1000 | Loss: 0.00002914
Iteration 152/1000 | Loss: 0.00002914
Iteration 153/1000 | Loss: 0.00002913
Iteration 154/1000 | Loss: 0.00002913
Iteration 155/1000 | Loss: 0.00002913
Iteration 156/1000 | Loss: 0.00002913
Iteration 157/1000 | Loss: 0.00002913
Iteration 158/1000 | Loss: 0.00002913
Iteration 159/1000 | Loss: 0.00002913
Iteration 160/1000 | Loss: 0.00002913
Iteration 161/1000 | Loss: 0.00002912
Iteration 162/1000 | Loss: 0.00002912
Iteration 163/1000 | Loss: 0.00002912
Iteration 164/1000 | Loss: 0.00002912
Iteration 165/1000 | Loss: 0.00002912
Iteration 166/1000 | Loss: 0.00002912
Iteration 167/1000 | Loss: 0.00002912
Iteration 168/1000 | Loss: 0.00002912
Iteration 169/1000 | Loss: 0.00002912
Iteration 170/1000 | Loss: 0.00002912
Iteration 171/1000 | Loss: 0.00002911
Iteration 172/1000 | Loss: 0.00002911
Iteration 173/1000 | Loss: 0.00002911
Iteration 174/1000 | Loss: 0.00002910
Iteration 175/1000 | Loss: 0.00002910
Iteration 176/1000 | Loss: 0.00002910
Iteration 177/1000 | Loss: 0.00002910
Iteration 178/1000 | Loss: 0.00002910
Iteration 179/1000 | Loss: 0.00002910
Iteration 180/1000 | Loss: 0.00002910
Iteration 181/1000 | Loss: 0.00002910
Iteration 182/1000 | Loss: 0.00002909
Iteration 183/1000 | Loss: 0.00002909
Iteration 184/1000 | Loss: 0.00002909
Iteration 185/1000 | Loss: 0.00002909
Iteration 186/1000 | Loss: 0.00002909
Iteration 187/1000 | Loss: 0.00002909
Iteration 188/1000 | Loss: 0.00002909
Iteration 189/1000 | Loss: 0.00002908
Iteration 190/1000 | Loss: 0.00002908
Iteration 191/1000 | Loss: 0.00002908
Iteration 192/1000 | Loss: 0.00002908
Iteration 193/1000 | Loss: 0.00002908
Iteration 194/1000 | Loss: 0.00002908
Iteration 195/1000 | Loss: 0.00002908
Iteration 196/1000 | Loss: 0.00002907
Iteration 197/1000 | Loss: 0.00002907
Iteration 198/1000 | Loss: 0.00002907
Iteration 199/1000 | Loss: 0.00002907
Iteration 200/1000 | Loss: 0.00002907
Iteration 201/1000 | Loss: 0.00002907
Iteration 202/1000 | Loss: 0.00002907
Iteration 203/1000 | Loss: 0.00002907
Iteration 204/1000 | Loss: 0.00002907
Iteration 205/1000 | Loss: 0.00002907
Iteration 206/1000 | Loss: 0.00002907
Iteration 207/1000 | Loss: 0.00002907
Iteration 208/1000 | Loss: 0.00002906
Iteration 209/1000 | Loss: 0.00002905
Iteration 210/1000 | Loss: 0.00002905
Iteration 211/1000 | Loss: 0.00002905
Iteration 212/1000 | Loss: 0.00002905
Iteration 213/1000 | Loss: 0.00002905
Iteration 214/1000 | Loss: 0.00002905
Iteration 215/1000 | Loss: 0.00002905
Iteration 216/1000 | Loss: 0.00002905
Iteration 217/1000 | Loss: 0.00002905
Iteration 218/1000 | Loss: 0.00002905
Iteration 219/1000 | Loss: 0.00002905
Iteration 220/1000 | Loss: 0.00002905
Iteration 221/1000 | Loss: 0.00002905
Iteration 222/1000 | Loss: 0.00002905
Iteration 223/1000 | Loss: 0.00002905
Iteration 224/1000 | Loss: 0.00002905
Iteration 225/1000 | Loss: 0.00002905
Iteration 226/1000 | Loss: 0.00002905
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 226. Stopping optimization.
Last 5 losses: [2.9047776479274035e-05, 2.9047776479274035e-05, 2.9047776479274035e-05, 2.9047776479274035e-05, 2.9047776479274035e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9047776479274035e-05

Optimization complete. Final v2v error: 4.355596542358398 mm

Highest mean error: 11.484543800354004 mm for frame 129

Lowest mean error: 4.112696170806885 mm for frame 98

Saving results

Total time: 3152.019581079483
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1066
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00928741
Iteration 2/25 | Loss: 0.00220765
Iteration 3/25 | Loss: 0.00169008
Iteration 4/25 | Loss: 0.00157956
Iteration 5/25 | Loss: 0.00154452
Iteration 6/25 | Loss: 0.00152762
Iteration 7/25 | Loss: 0.00148839
Iteration 8/25 | Loss: 0.00147205
Iteration 9/25 | Loss: 0.00146711
Iteration 10/25 | Loss: 0.00143321
Iteration 11/25 | Loss: 0.00142204
Iteration 12/25 | Loss: 0.00142052
Iteration 13/25 | Loss: 0.00142111
Iteration 14/25 | Loss: 0.00141726
Iteration 15/25 | Loss: 0.00141252
Iteration 16/25 | Loss: 0.00141013
Iteration 17/25 | Loss: 0.00141002
Iteration 18/25 | Loss: 0.00141009
Iteration 19/25 | Loss: 0.00141038
Iteration 20/25 | Loss: 0.00140956
Iteration 21/25 | Loss: 0.00141029
Iteration 22/25 | Loss: 0.00140989
Iteration 23/25 | Loss: 0.00140980
Iteration 24/25 | Loss: 0.00141013
Iteration 25/25 | Loss: 0.00140956

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43927836
Iteration 2/25 | Loss: 0.00103304
Iteration 3/25 | Loss: 0.00103113
Iteration 4/25 | Loss: 0.00103113
Iteration 5/25 | Loss: 0.00103113
Iteration 6/25 | Loss: 0.00103113
Iteration 7/25 | Loss: 0.00103113
Iteration 8/25 | Loss: 0.00103113
Iteration 9/25 | Loss: 0.00103113
Iteration 10/25 | Loss: 0.00103113
Iteration 11/25 | Loss: 0.00103113
Iteration 12/25 | Loss: 0.00103113
Iteration 13/25 | Loss: 0.00103113
Iteration 14/25 | Loss: 0.00103113
Iteration 15/25 | Loss: 0.00103113
Iteration 16/25 | Loss: 0.00103113
Iteration 17/25 | Loss: 0.00103113
Iteration 18/25 | Loss: 0.00103113
Iteration 19/25 | Loss: 0.00103113
Iteration 20/25 | Loss: 0.00103113
Iteration 21/25 | Loss: 0.00103113
Iteration 22/25 | Loss: 0.00103113
Iteration 23/25 | Loss: 0.00103113
Iteration 24/25 | Loss: 0.00103113
Iteration 25/25 | Loss: 0.00103113

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00103113
Iteration 2/1000 | Loss: 0.00008881
Iteration 3/1000 | Loss: 0.00019137
Iteration 4/1000 | Loss: 0.00031300
Iteration 5/1000 | Loss: 0.00027374
Iteration 6/1000 | Loss: 0.00052608
Iteration 7/1000 | Loss: 0.00062293
Iteration 8/1000 | Loss: 0.00046274
Iteration 9/1000 | Loss: 0.00007699
Iteration 10/1000 | Loss: 0.00034938
Iteration 11/1000 | Loss: 0.00006745
Iteration 12/1000 | Loss: 0.00040951
Iteration 13/1000 | Loss: 0.00015944
Iteration 14/1000 | Loss: 0.00027170
Iteration 15/1000 | Loss: 0.00025440
Iteration 16/1000 | Loss: 0.00027386
Iteration 17/1000 | Loss: 0.00022797
Iteration 18/1000 | Loss: 0.00015140
Iteration 19/1000 | Loss: 0.00014552
Iteration 20/1000 | Loss: 0.00030858
Iteration 21/1000 | Loss: 0.00022003
Iteration 22/1000 | Loss: 0.00058186
Iteration 23/1000 | Loss: 0.00038100
Iteration 24/1000 | Loss: 0.00036800
Iteration 25/1000 | Loss: 0.00010295
Iteration 26/1000 | Loss: 0.00009208
Iteration 27/1000 | Loss: 0.00010746
Iteration 28/1000 | Loss: 0.00005834
Iteration 29/1000 | Loss: 0.00007963
Iteration 30/1000 | Loss: 0.00027959
Iteration 31/1000 | Loss: 0.00020604
Iteration 32/1000 | Loss: 0.00018543
Iteration 33/1000 | Loss: 0.00045411
Iteration 34/1000 | Loss: 0.00025849
Iteration 35/1000 | Loss: 0.00038893
Iteration 36/1000 | Loss: 0.00034476
Iteration 37/1000 | Loss: 0.00014846
Iteration 38/1000 | Loss: 0.00012368
Iteration 39/1000 | Loss: 0.00052576
Iteration 40/1000 | Loss: 0.00031149
Iteration 41/1000 | Loss: 0.00022387
Iteration 42/1000 | Loss: 0.00007343
Iteration 43/1000 | Loss: 0.00005364
Iteration 44/1000 | Loss: 0.00005612
Iteration 45/1000 | Loss: 0.00005598
Iteration 46/1000 | Loss: 0.00025085
Iteration 47/1000 | Loss: 0.00063894
Iteration 48/1000 | Loss: 0.00021943
Iteration 49/1000 | Loss: 0.00006246
Iteration 50/1000 | Loss: 0.00062915
Iteration 51/1000 | Loss: 0.00054253
Iteration 52/1000 | Loss: 0.00054582
Iteration 53/1000 | Loss: 0.00029521
Iteration 54/1000 | Loss: 0.00014504
Iteration 55/1000 | Loss: 0.00041756
Iteration 56/1000 | Loss: 0.00037324
Iteration 57/1000 | Loss: 0.00011641
Iteration 58/1000 | Loss: 0.00022048
Iteration 59/1000 | Loss: 0.00037907
Iteration 60/1000 | Loss: 0.00035027
Iteration 61/1000 | Loss: 0.00032046
Iteration 62/1000 | Loss: 0.00038060
Iteration 63/1000 | Loss: 0.00043055
Iteration 64/1000 | Loss: 0.00013248
Iteration 65/1000 | Loss: 0.00007622
Iteration 66/1000 | Loss: 0.00006841
Iteration 67/1000 | Loss: 0.00035515
Iteration 68/1000 | Loss: 0.00166631
Iteration 69/1000 | Loss: 0.00049646
Iteration 70/1000 | Loss: 0.00050764
Iteration 71/1000 | Loss: 0.00020406
Iteration 72/1000 | Loss: 0.00032327
Iteration 73/1000 | Loss: 0.00066880
Iteration 74/1000 | Loss: 0.00029076
Iteration 75/1000 | Loss: 0.00063970
Iteration 76/1000 | Loss: 0.00069522
Iteration 77/1000 | Loss: 0.00025703
Iteration 78/1000 | Loss: 0.00006403
Iteration 79/1000 | Loss: 0.00028499
Iteration 80/1000 | Loss: 0.00058689
Iteration 81/1000 | Loss: 0.00024702
Iteration 82/1000 | Loss: 0.00046177
Iteration 83/1000 | Loss: 0.00062431
Iteration 84/1000 | Loss: 0.00035003
Iteration 85/1000 | Loss: 0.00090806
Iteration 86/1000 | Loss: 0.00043336
Iteration 87/1000 | Loss: 0.00057546
Iteration 88/1000 | Loss: 0.00091995
Iteration 89/1000 | Loss: 0.00087947
Iteration 90/1000 | Loss: 0.00063144
Iteration 91/1000 | Loss: 0.00050861
Iteration 92/1000 | Loss: 0.00021642
Iteration 93/1000 | Loss: 0.00024794
Iteration 94/1000 | Loss: 0.00006626
Iteration 95/1000 | Loss: 0.00006321
Iteration 96/1000 | Loss: 0.00027760
Iteration 97/1000 | Loss: 0.00022286
Iteration 98/1000 | Loss: 0.00013293
Iteration 99/1000 | Loss: 0.00005307
Iteration 100/1000 | Loss: 0.00005981
Iteration 101/1000 | Loss: 0.00021935
Iteration 102/1000 | Loss: 0.00004065
Iteration 103/1000 | Loss: 0.00004116
Iteration 104/1000 | Loss: 0.00016433
Iteration 105/1000 | Loss: 0.00088749
Iteration 106/1000 | Loss: 0.00027351
Iteration 107/1000 | Loss: 0.00024348
Iteration 108/1000 | Loss: 0.00006499
Iteration 109/1000 | Loss: 0.00005076
Iteration 110/1000 | Loss: 0.00004484
Iteration 111/1000 | Loss: 0.00020100
Iteration 112/1000 | Loss: 0.00036778
Iteration 113/1000 | Loss: 0.00031582
Iteration 114/1000 | Loss: 0.00045069
Iteration 115/1000 | Loss: 0.00031584
Iteration 116/1000 | Loss: 0.00012726
Iteration 117/1000 | Loss: 0.00004225
Iteration 118/1000 | Loss: 0.00003909
Iteration 119/1000 | Loss: 0.00004764
Iteration 120/1000 | Loss: 0.00004042
Iteration 121/1000 | Loss: 0.00019139
Iteration 122/1000 | Loss: 0.00017247
Iteration 123/1000 | Loss: 0.00021398
Iteration 124/1000 | Loss: 0.00008720
Iteration 125/1000 | Loss: 0.00018895
Iteration 126/1000 | Loss: 0.00004479
Iteration 127/1000 | Loss: 0.00004697
Iteration 128/1000 | Loss: 0.00004656
Iteration 129/1000 | Loss: 0.00004024
Iteration 130/1000 | Loss: 0.00003627
Iteration 131/1000 | Loss: 0.00003617
Iteration 132/1000 | Loss: 0.00004471
Iteration 133/1000 | Loss: 0.00003747
Iteration 134/1000 | Loss: 0.00004306
Iteration 135/1000 | Loss: 0.00004311
Iteration 136/1000 | Loss: 0.00003961
Iteration 137/1000 | Loss: 0.00004098
Iteration 138/1000 | Loss: 0.00003358
Iteration 139/1000 | Loss: 0.00003851
Iteration 140/1000 | Loss: 0.00003853
Iteration 141/1000 | Loss: 0.00018221
Iteration 142/1000 | Loss: 0.00014228
Iteration 143/1000 | Loss: 0.00016080
Iteration 144/1000 | Loss: 0.00019229
Iteration 145/1000 | Loss: 0.00016515
Iteration 146/1000 | Loss: 0.00012295
Iteration 147/1000 | Loss: 0.00016313
Iteration 148/1000 | Loss: 0.00019653
Iteration 149/1000 | Loss: 0.00004424
Iteration 150/1000 | Loss: 0.00004107
Iteration 151/1000 | Loss: 0.00009404
Iteration 152/1000 | Loss: 0.00004164
Iteration 153/1000 | Loss: 0.00004162
Iteration 154/1000 | Loss: 0.00018043
Iteration 155/1000 | Loss: 0.00013705
Iteration 156/1000 | Loss: 0.00012459
Iteration 157/1000 | Loss: 0.00014149
Iteration 158/1000 | Loss: 0.00015349
Iteration 159/1000 | Loss: 0.00009632
Iteration 160/1000 | Loss: 0.00012136
Iteration 161/1000 | Loss: 0.00004097
Iteration 162/1000 | Loss: 0.00004038
Iteration 163/1000 | Loss: 0.00003950
Iteration 164/1000 | Loss: 0.00003287
Iteration 165/1000 | Loss: 0.00003850
Iteration 166/1000 | Loss: 0.00004552
Iteration 167/1000 | Loss: 0.00004796
Iteration 168/1000 | Loss: 0.00043846
Iteration 169/1000 | Loss: 0.00004542
Iteration 170/1000 | Loss: 0.00004522
Iteration 171/1000 | Loss: 0.00003257
Iteration 172/1000 | Loss: 0.00011849
Iteration 173/1000 | Loss: 0.00015805
Iteration 174/1000 | Loss: 0.00008079
Iteration 175/1000 | Loss: 0.00002866
Iteration 176/1000 | Loss: 0.00002761
Iteration 177/1000 | Loss: 0.00002701
Iteration 178/1000 | Loss: 0.00002639
Iteration 179/1000 | Loss: 0.00002597
Iteration 180/1000 | Loss: 0.00002565
Iteration 181/1000 | Loss: 0.00002535
Iteration 182/1000 | Loss: 0.00034097
Iteration 183/1000 | Loss: 0.00060022
Iteration 184/1000 | Loss: 0.00026858
Iteration 185/1000 | Loss: 0.00022476
Iteration 186/1000 | Loss: 0.00021907
Iteration 187/1000 | Loss: 0.00022133
Iteration 188/1000 | Loss: 0.00024157
Iteration 189/1000 | Loss: 0.00004040
Iteration 190/1000 | Loss: 0.00041122
Iteration 191/1000 | Loss: 0.00052283
Iteration 192/1000 | Loss: 0.00036078
Iteration 193/1000 | Loss: 0.00021714
Iteration 194/1000 | Loss: 0.00041109
Iteration 195/1000 | Loss: 0.00032324
Iteration 196/1000 | Loss: 0.00054756
Iteration 197/1000 | Loss: 0.00029263
Iteration 198/1000 | Loss: 0.00012054
Iteration 199/1000 | Loss: 0.00017382
Iteration 200/1000 | Loss: 0.00020205
Iteration 201/1000 | Loss: 0.00028336
Iteration 202/1000 | Loss: 0.00003720
Iteration 203/1000 | Loss: 0.00003466
Iteration 204/1000 | Loss: 0.00030163
Iteration 205/1000 | Loss: 0.00027905
Iteration 206/1000 | Loss: 0.00008439
Iteration 207/1000 | Loss: 0.00035737
Iteration 208/1000 | Loss: 0.00048996
Iteration 209/1000 | Loss: 0.00017438
Iteration 210/1000 | Loss: 0.00032172
Iteration 211/1000 | Loss: 0.00037261
Iteration 212/1000 | Loss: 0.00017526
Iteration 213/1000 | Loss: 0.00007222
Iteration 214/1000 | Loss: 0.00003927
Iteration 215/1000 | Loss: 0.00003442
Iteration 216/1000 | Loss: 0.00003189
Iteration 217/1000 | Loss: 0.00003021
Iteration 218/1000 | Loss: 0.00002918
Iteration 219/1000 | Loss: 0.00002823
Iteration 220/1000 | Loss: 0.00026030
Iteration 221/1000 | Loss: 0.00010306
Iteration 222/1000 | Loss: 0.00003241
Iteration 223/1000 | Loss: 0.00020901
Iteration 224/1000 | Loss: 0.00003272
Iteration 225/1000 | Loss: 0.00002851
Iteration 226/1000 | Loss: 0.00015466
Iteration 227/1000 | Loss: 0.00015129
Iteration 228/1000 | Loss: 0.00014870
Iteration 229/1000 | Loss: 0.00003987
Iteration 230/1000 | Loss: 0.00002795
Iteration 231/1000 | Loss: 0.00002594
Iteration 232/1000 | Loss: 0.00002495
Iteration 233/1000 | Loss: 0.00002429
Iteration 234/1000 | Loss: 0.00002354
Iteration 235/1000 | Loss: 0.00002318
Iteration 236/1000 | Loss: 0.00002289
Iteration 237/1000 | Loss: 0.00014031
Iteration 238/1000 | Loss: 0.00007489
Iteration 239/1000 | Loss: 0.00002694
Iteration 240/1000 | Loss: 0.00002434
Iteration 241/1000 | Loss: 0.00002278
Iteration 242/1000 | Loss: 0.00002228
Iteration 243/1000 | Loss: 0.00002219
Iteration 244/1000 | Loss: 0.00002213
Iteration 245/1000 | Loss: 0.00019341
Iteration 246/1000 | Loss: 0.00007918
Iteration 247/1000 | Loss: 0.00003013
Iteration 248/1000 | Loss: 0.00002631
Iteration 249/1000 | Loss: 0.00002433
Iteration 250/1000 | Loss: 0.00002307
Iteration 251/1000 | Loss: 0.00003344
Iteration 252/1000 | Loss: 0.00003347
Iteration 253/1000 | Loss: 0.00003048
Iteration 254/1000 | Loss: 0.00002378
Iteration 255/1000 | Loss: 0.00002226
Iteration 256/1000 | Loss: 0.00002173
Iteration 257/1000 | Loss: 0.00002147
Iteration 258/1000 | Loss: 0.00002137
Iteration 259/1000 | Loss: 0.00002134
Iteration 260/1000 | Loss: 0.00002134
Iteration 261/1000 | Loss: 0.00002134
Iteration 262/1000 | Loss: 0.00002133
Iteration 263/1000 | Loss: 0.00002133
Iteration 264/1000 | Loss: 0.00002133
Iteration 265/1000 | Loss: 0.00002132
Iteration 266/1000 | Loss: 0.00002131
Iteration 267/1000 | Loss: 0.00002131
Iteration 268/1000 | Loss: 0.00002130
Iteration 269/1000 | Loss: 0.00002130
Iteration 270/1000 | Loss: 0.00002130
Iteration 271/1000 | Loss: 0.00002129
Iteration 272/1000 | Loss: 0.00002129
Iteration 273/1000 | Loss: 0.00002127
Iteration 274/1000 | Loss: 0.00002591
Iteration 275/1000 | Loss: 0.00002161
Iteration 276/1000 | Loss: 0.00002333
Iteration 277/1000 | Loss: 0.00002542
Iteration 278/1000 | Loss: 0.00002288
Iteration 279/1000 | Loss: 0.00002357
Iteration 280/1000 | Loss: 0.00002255
Iteration 281/1000 | Loss: 0.00002296
Iteration 282/1000 | Loss: 0.00002113
Iteration 283/1000 | Loss: 0.00002108
Iteration 284/1000 | Loss: 0.00002106
Iteration 285/1000 | Loss: 0.00002106
Iteration 286/1000 | Loss: 0.00002104
Iteration 287/1000 | Loss: 0.00002103
Iteration 288/1000 | Loss: 0.00002100
Iteration 289/1000 | Loss: 0.00002100
Iteration 290/1000 | Loss: 0.00002098
Iteration 291/1000 | Loss: 0.00002092
Iteration 292/1000 | Loss: 0.00002087
Iteration 293/1000 | Loss: 0.00002085
Iteration 294/1000 | Loss: 0.00002084
Iteration 295/1000 | Loss: 0.00002084
Iteration 296/1000 | Loss: 0.00002084
Iteration 297/1000 | Loss: 0.00002083
Iteration 298/1000 | Loss: 0.00002083
Iteration 299/1000 | Loss: 0.00002082
Iteration 300/1000 | Loss: 0.00002082
Iteration 301/1000 | Loss: 0.00002081
Iteration 302/1000 | Loss: 0.00002081
Iteration 303/1000 | Loss: 0.00002081
Iteration 304/1000 | Loss: 0.00002081
Iteration 305/1000 | Loss: 0.00002080
Iteration 306/1000 | Loss: 0.00002080
Iteration 307/1000 | Loss: 0.00002079
Iteration 308/1000 | Loss: 0.00002079
Iteration 309/1000 | Loss: 0.00002078
Iteration 310/1000 | Loss: 0.00002077
Iteration 311/1000 | Loss: 0.00002077
Iteration 312/1000 | Loss: 0.00002076
Iteration 313/1000 | Loss: 0.00002076
Iteration 314/1000 | Loss: 0.00002075
Iteration 315/1000 | Loss: 0.00002075
Iteration 316/1000 | Loss: 0.00002075
Iteration 317/1000 | Loss: 0.00002075
Iteration 318/1000 | Loss: 0.00002075
Iteration 319/1000 | Loss: 0.00002074
Iteration 320/1000 | Loss: 0.00002074
Iteration 321/1000 | Loss: 0.00002074
Iteration 322/1000 | Loss: 0.00002074
Iteration 323/1000 | Loss: 0.00002074
Iteration 324/1000 | Loss: 0.00002074
Iteration 325/1000 | Loss: 0.00002074
Iteration 326/1000 | Loss: 0.00002074
Iteration 327/1000 | Loss: 0.00002074
Iteration 328/1000 | Loss: 0.00002074
Iteration 329/1000 | Loss: 0.00002074
Iteration 330/1000 | Loss: 0.00002073
Iteration 331/1000 | Loss: 0.00002073
Iteration 332/1000 | Loss: 0.00002073
Iteration 333/1000 | Loss: 0.00002073
Iteration 334/1000 | Loss: 0.00002073
Iteration 335/1000 | Loss: 0.00002073
Iteration 336/1000 | Loss: 0.00002072
Iteration 337/1000 | Loss: 0.00002072
Iteration 338/1000 | Loss: 0.00002072
Iteration 339/1000 | Loss: 0.00002071
Iteration 340/1000 | Loss: 0.00002071
Iteration 341/1000 | Loss: 0.00002071
Iteration 342/1000 | Loss: 0.00002071
Iteration 343/1000 | Loss: 0.00002071
Iteration 344/1000 | Loss: 0.00002071
Iteration 345/1000 | Loss: 0.00002071
Iteration 346/1000 | Loss: 0.00002070
Iteration 347/1000 | Loss: 0.00002070
Iteration 348/1000 | Loss: 0.00002070
Iteration 349/1000 | Loss: 0.00002070
Iteration 350/1000 | Loss: 0.00002070
Iteration 351/1000 | Loss: 0.00002070
Iteration 352/1000 | Loss: 0.00002070
Iteration 353/1000 | Loss: 0.00002070
Iteration 354/1000 | Loss: 0.00002070
Iteration 355/1000 | Loss: 0.00002070
Iteration 356/1000 | Loss: 0.00002070
Iteration 357/1000 | Loss: 0.00002070
Iteration 358/1000 | Loss: 0.00002069
Iteration 359/1000 | Loss: 0.00002069
Iteration 360/1000 | Loss: 0.00002069
Iteration 361/1000 | Loss: 0.00002069
Iteration 362/1000 | Loss: 0.00002069
Iteration 363/1000 | Loss: 0.00002069
Iteration 364/1000 | Loss: 0.00002069
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 364. Stopping optimization.
Last 5 losses: [2.0694400518550538e-05, 2.0694400518550538e-05, 2.0694400518550538e-05, 2.0694400518550538e-05, 2.0694400518550538e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0694400518550538e-05

Optimization complete. Final v2v error: 3.614678382873535 mm

Highest mean error: 5.83414888381958 mm for frame 156

Lowest mean error: 3.0613491535186768 mm for frame 40

Saving results

Total time: 12210.3903362751
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1005
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00899153
Iteration 2/25 | Loss: 0.00200721
Iteration 3/25 | Loss: 0.00165437
Iteration 4/25 | Loss: 0.00158629
Iteration 5/25 | Loss: 0.00158903
Iteration 6/25 | Loss: 0.00151646
Iteration 7/25 | Loss: 0.00146890
Iteration 8/25 | Loss: 0.00144941
Iteration 9/25 | Loss: 0.00145118
Iteration 10/25 | Loss: 0.00146902
Iteration 11/25 | Loss: 0.00144160
Iteration 12/25 | Loss: 0.00142927
Iteration 13/25 | Loss: 0.00141952
Iteration 14/25 | Loss: 0.00141711
Iteration 15/25 | Loss: 0.00141979
Iteration 16/25 | Loss: 0.00141924
Iteration 17/25 | Loss: 0.00142074
Iteration 18/25 | Loss: 0.00141710
Iteration 19/25 | Loss: 0.00141396
Iteration 20/25 | Loss: 0.00141329
Iteration 21/25 | Loss: 0.00141306
Iteration 22/25 | Loss: 0.00141295
Iteration 23/25 | Loss: 0.00141292
Iteration 24/25 | Loss: 0.00141292
Iteration 25/25 | Loss: 0.00141292

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.35436296
Iteration 2/25 | Loss: 0.00105943
Iteration 3/25 | Loss: 0.00105697
Iteration 4/25 | Loss: 0.00105697
Iteration 5/25 | Loss: 0.00105696
Iteration 6/25 | Loss: 0.00105696
Iteration 7/25 | Loss: 0.00105696
Iteration 8/25 | Loss: 0.00105696
Iteration 9/25 | Loss: 0.00105696
Iteration 10/25 | Loss: 0.00105696
Iteration 11/25 | Loss: 0.00105696
Iteration 12/25 | Loss: 0.00105696
Iteration 13/25 | Loss: 0.00105696
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0010569629957899451, 0.0010569629957899451, 0.0010569629957899451, 0.0010569629957899451, 0.0010569629957899451]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010569629957899451

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00105696
Iteration 2/1000 | Loss: 0.00032209
Iteration 3/1000 | Loss: 0.00041129
Iteration 4/1000 | Loss: 0.00040683
Iteration 5/1000 | Loss: 0.00024383
Iteration 6/1000 | Loss: 0.00015680
Iteration 7/1000 | Loss: 0.00011295
Iteration 8/1000 | Loss: 0.00009355
Iteration 9/1000 | Loss: 0.00008228
Iteration 10/1000 | Loss: 0.00007531
Iteration 11/1000 | Loss: 0.00010079
Iteration 12/1000 | Loss: 0.00021905
Iteration 13/1000 | Loss: 0.00018623
Iteration 14/1000 | Loss: 0.00011774
Iteration 15/1000 | Loss: 0.00010295
Iteration 16/1000 | Loss: 0.00011864
Iteration 17/1000 | Loss: 0.00012286
Iteration 18/1000 | Loss: 0.00020227
Iteration 19/1000 | Loss: 0.00014907
Iteration 20/1000 | Loss: 0.00011613
Iteration 21/1000 | Loss: 0.00009051
Iteration 22/1000 | Loss: 0.00007654
Iteration 23/1000 | Loss: 0.00006816
Iteration 24/1000 | Loss: 0.00006168
Iteration 25/1000 | Loss: 0.00005609
Iteration 26/1000 | Loss: 0.00005144
Iteration 27/1000 | Loss: 0.00005447
Iteration 28/1000 | Loss: 0.00005003
Iteration 29/1000 | Loss: 0.00005754
Iteration 30/1000 | Loss: 0.00004755
Iteration 31/1000 | Loss: 0.00004462
Iteration 32/1000 | Loss: 0.00004151
Iteration 33/1000 | Loss: 0.00003968
Iteration 34/1000 | Loss: 0.00003799
Iteration 35/1000 | Loss: 0.00003616
Iteration 36/1000 | Loss: 0.00003469
Iteration 37/1000 | Loss: 0.00003380
Iteration 38/1000 | Loss: 0.00004070
Iteration 39/1000 | Loss: 0.00003706
Iteration 40/1000 | Loss: 0.00003584
Iteration 41/1000 | Loss: 0.00003477
Iteration 42/1000 | Loss: 0.00003387
Iteration 43/1000 | Loss: 0.00003310
Iteration 44/1000 | Loss: 0.00003273
Iteration 45/1000 | Loss: 0.00003981
Iteration 46/1000 | Loss: 0.00006546
Iteration 47/1000 | Loss: 0.00007858
Iteration 48/1000 | Loss: 0.00017649
Iteration 49/1000 | Loss: 0.00015432
Iteration 50/1000 | Loss: 0.00007260
Iteration 51/1000 | Loss: 0.00005850
Iteration 52/1000 | Loss: 0.00004303
Iteration 53/1000 | Loss: 0.00003953
Iteration 54/1000 | Loss: 0.00003797
Iteration 55/1000 | Loss: 0.00003625
Iteration 56/1000 | Loss: 0.00003417
Iteration 57/1000 | Loss: 0.00003266
Iteration 58/1000 | Loss: 0.00003164
Iteration 59/1000 | Loss: 0.00011910
Iteration 60/1000 | Loss: 0.00007896
Iteration 61/1000 | Loss: 0.00005906
Iteration 62/1000 | Loss: 0.00005266
Iteration 63/1000 | Loss: 0.00003062
Iteration 64/1000 | Loss: 0.00005869
Iteration 65/1000 | Loss: 0.00005195
Iteration 66/1000 | Loss: 0.00006901
Iteration 67/1000 | Loss: 0.00005677
Iteration 68/1000 | Loss: 0.00003690
Iteration 69/1000 | Loss: 0.00003263
Iteration 70/1000 | Loss: 0.00003200
Iteration 71/1000 | Loss: 0.00004722
Iteration 72/1000 | Loss: 0.00006935
Iteration 73/1000 | Loss: 0.00007072
Iteration 74/1000 | Loss: 0.00005812
Iteration 75/1000 | Loss: 0.00003790
Iteration 76/1000 | Loss: 0.00005088
Iteration 77/1000 | Loss: 0.00006561
Iteration 78/1000 | Loss: 0.00006368
Iteration 79/1000 | Loss: 0.00003680
Iteration 80/1000 | Loss: 0.00004176
Iteration 81/1000 | Loss: 0.00003688
Iteration 82/1000 | Loss: 0.00004574
Iteration 83/1000 | Loss: 0.00004035
Iteration 84/1000 | Loss: 0.00003221
Iteration 85/1000 | Loss: 0.00003155
Iteration 86/1000 | Loss: 0.00003842
Iteration 87/1000 | Loss: 0.00005015
Iteration 88/1000 | Loss: 0.00004911
Iteration 89/1000 | Loss: 0.00007985
Iteration 90/1000 | Loss: 0.00005822
Iteration 91/1000 | Loss: 0.00004907
Iteration 92/1000 | Loss: 0.00003721
Iteration 93/1000 | Loss: 0.00011238
Iteration 94/1000 | Loss: 0.00009469
Iteration 95/1000 | Loss: 0.00003970
Iteration 96/1000 | Loss: 0.00003278
Iteration 97/1000 | Loss: 0.00003116
Iteration 98/1000 | Loss: 0.00002974
Iteration 99/1000 | Loss: 0.00005131
Iteration 100/1000 | Loss: 0.00003817
Iteration 101/1000 | Loss: 0.00002845
Iteration 102/1000 | Loss: 0.00004431
Iteration 103/1000 | Loss: 0.00003675
Iteration 104/1000 | Loss: 0.00002758
Iteration 105/1000 | Loss: 0.00002754
Iteration 106/1000 | Loss: 0.00005635
Iteration 107/1000 | Loss: 0.00006259
Iteration 108/1000 | Loss: 0.00007439
Iteration 109/1000 | Loss: 0.00002898
Iteration 110/1000 | Loss: 0.00002733
Iteration 111/1000 | Loss: 0.00002719
Iteration 112/1000 | Loss: 0.00002719
Iteration 113/1000 | Loss: 0.00002718
Iteration 114/1000 | Loss: 0.00002718
Iteration 115/1000 | Loss: 0.00002718
Iteration 116/1000 | Loss: 0.00002717
Iteration 117/1000 | Loss: 0.00002717
Iteration 118/1000 | Loss: 0.00002717
Iteration 119/1000 | Loss: 0.00002717
Iteration 120/1000 | Loss: 0.00002717
Iteration 121/1000 | Loss: 0.00002717
Iteration 122/1000 | Loss: 0.00002717
Iteration 123/1000 | Loss: 0.00002717
Iteration 124/1000 | Loss: 0.00002717
Iteration 125/1000 | Loss: 0.00002716
Iteration 126/1000 | Loss: 0.00002716
Iteration 127/1000 | Loss: 0.00002716
Iteration 128/1000 | Loss: 0.00002716
Iteration 129/1000 | Loss: 0.00002716
Iteration 130/1000 | Loss: 0.00002716
Iteration 131/1000 | Loss: 0.00002716
Iteration 132/1000 | Loss: 0.00002716
Iteration 133/1000 | Loss: 0.00002715
Iteration 134/1000 | Loss: 0.00002715
Iteration 135/1000 | Loss: 0.00002715
Iteration 136/1000 | Loss: 0.00002714
Iteration 137/1000 | Loss: 0.00002714
Iteration 138/1000 | Loss: 0.00002714
Iteration 139/1000 | Loss: 0.00002714
Iteration 140/1000 | Loss: 0.00002714
Iteration 141/1000 | Loss: 0.00002713
Iteration 142/1000 | Loss: 0.00002713
Iteration 143/1000 | Loss: 0.00002713
Iteration 144/1000 | Loss: 0.00002712
Iteration 145/1000 | Loss: 0.00002712
Iteration 146/1000 | Loss: 0.00002712
Iteration 147/1000 | Loss: 0.00002712
Iteration 148/1000 | Loss: 0.00002712
Iteration 149/1000 | Loss: 0.00002712
Iteration 150/1000 | Loss: 0.00002711
Iteration 151/1000 | Loss: 0.00002711
Iteration 152/1000 | Loss: 0.00002711
Iteration 153/1000 | Loss: 0.00002711
Iteration 154/1000 | Loss: 0.00002711
Iteration 155/1000 | Loss: 0.00002711
Iteration 156/1000 | Loss: 0.00002711
Iteration 157/1000 | Loss: 0.00002711
Iteration 158/1000 | Loss: 0.00002711
Iteration 159/1000 | Loss: 0.00002711
Iteration 160/1000 | Loss: 0.00002711
Iteration 161/1000 | Loss: 0.00002711
Iteration 162/1000 | Loss: 0.00002711
Iteration 163/1000 | Loss: 0.00002711
Iteration 164/1000 | Loss: 0.00002711
Iteration 165/1000 | Loss: 0.00002711
Iteration 166/1000 | Loss: 0.00002711
Iteration 167/1000 | Loss: 0.00002711
Iteration 168/1000 | Loss: 0.00002711
Iteration 169/1000 | Loss: 0.00002711
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 169. Stopping optimization.
Last 5 losses: [2.7107344067189842e-05, 2.7107344067189842e-05, 2.7107344067189842e-05, 2.7107344067189842e-05, 2.7107344067189842e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7107344067189842e-05

Optimization complete. Final v2v error: 4.230544567108154 mm

Highest mean error: 6.949949741363525 mm for frame 107

Lowest mean error: 3.3235697746276855 mm for frame 74

Saving results

Total time: 5043.821640491486
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1096
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00998060
Iteration 2/25 | Loss: 0.00998060
Iteration 3/25 | Loss: 0.00998060
Iteration 4/25 | Loss: 0.00998059
Iteration 5/25 | Loss: 0.00998059
Iteration 6/25 | Loss: 0.00998059
Iteration 7/25 | Loss: 0.00998059
Iteration 8/25 | Loss: 0.00998059
Iteration 9/25 | Loss: 0.00998059
Iteration 10/25 | Loss: 0.00998059
Iteration 11/25 | Loss: 0.00998059
Iteration 12/25 | Loss: 0.00998059
Iteration 13/25 | Loss: 0.00998059
Iteration 14/25 | Loss: 0.00998059
Iteration 15/25 | Loss: 0.00998059
Iteration 16/25 | Loss: 0.00998059
Iteration 17/25 | Loss: 0.00998059
Iteration 18/25 | Loss: 0.00998059
Iteration 19/25 | Loss: 0.00998058
Iteration 20/25 | Loss: 0.00998058
Iteration 21/25 | Loss: 0.00998058
Iteration 22/25 | Loss: 0.00998058
Iteration 23/25 | Loss: 0.00998058
Iteration 24/25 | Loss: 0.00998058
Iteration 25/25 | Loss: 0.00998058

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.04775262
Iteration 2/25 | Loss: 0.00443737
Iteration 3/25 | Loss: 0.00443733
Iteration 4/25 | Loss: 0.00443733
Iteration 5/25 | Loss: 0.00443733
Iteration 6/25 | Loss: 0.00443733
Iteration 7/25 | Loss: 0.00443733
Iteration 8/25 | Loss: 0.00443733
Iteration 9/25 | Loss: 0.00443733
Iteration 10/25 | Loss: 0.00443733
Iteration 11/25 | Loss: 0.00443733
Iteration 12/25 | Loss: 0.00443733
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0044373259879648685, 0.0044373259879648685, 0.0044373259879648685, 0.0044373259879648685, 0.0044373259879648685]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0044373259879648685

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00443733
Iteration 2/1000 | Loss: 0.00874259
Iteration 3/1000 | Loss: 0.00107613
Iteration 4/1000 | Loss: 0.00037420
Iteration 5/1000 | Loss: 0.00048805
Iteration 6/1000 | Loss: 0.00012668
Iteration 7/1000 | Loss: 0.00126667
Iteration 8/1000 | Loss: 0.00107202
Iteration 9/1000 | Loss: 0.00036395
Iteration 10/1000 | Loss: 0.00005666
Iteration 11/1000 | Loss: 0.00072561
Iteration 12/1000 | Loss: 0.00023498
Iteration 13/1000 | Loss: 0.00019885
Iteration 14/1000 | Loss: 0.00011197
Iteration 15/1000 | Loss: 0.00003353
Iteration 16/1000 | Loss: 0.00017059
Iteration 17/1000 | Loss: 0.00023479
Iteration 18/1000 | Loss: 0.00174149
Iteration 19/1000 | Loss: 0.00016490
Iteration 20/1000 | Loss: 0.00017890
Iteration 21/1000 | Loss: 0.00086832
Iteration 22/1000 | Loss: 0.00017321
Iteration 23/1000 | Loss: 0.00033568
Iteration 24/1000 | Loss: 0.00007918
Iteration 25/1000 | Loss: 0.00002757
Iteration 26/1000 | Loss: 0.00007741
Iteration 27/1000 | Loss: 0.00019769
Iteration 28/1000 | Loss: 0.00066597
Iteration 29/1000 | Loss: 0.00006501
Iteration 30/1000 | Loss: 0.00011372
Iteration 31/1000 | Loss: 0.00039165
Iteration 32/1000 | Loss: 0.00015443
Iteration 33/1000 | Loss: 0.00071582
Iteration 34/1000 | Loss: 0.00007514
Iteration 35/1000 | Loss: 0.00036808
Iteration 36/1000 | Loss: 0.00007295
Iteration 37/1000 | Loss: 0.00024672
Iteration 38/1000 | Loss: 0.00011025
Iteration 39/1000 | Loss: 0.00017630
Iteration 40/1000 | Loss: 0.00009282
Iteration 41/1000 | Loss: 0.00013099
Iteration 42/1000 | Loss: 0.00009609
Iteration 43/1000 | Loss: 0.00025560
Iteration 44/1000 | Loss: 0.00124509
Iteration 45/1000 | Loss: 0.00044696
Iteration 46/1000 | Loss: 0.00020213
Iteration 47/1000 | Loss: 0.00134600
Iteration 48/1000 | Loss: 0.00010957
Iteration 49/1000 | Loss: 0.00003332
Iteration 50/1000 | Loss: 0.00009217
Iteration 51/1000 | Loss: 0.00013842
Iteration 52/1000 | Loss: 0.00013481
Iteration 53/1000 | Loss: 0.00020947
Iteration 54/1000 | Loss: 0.00028280
Iteration 55/1000 | Loss: 0.00005865
Iteration 56/1000 | Loss: 0.00002684
Iteration 57/1000 | Loss: 0.00020718
Iteration 58/1000 | Loss: 0.00005995
Iteration 59/1000 | Loss: 0.00004902
Iteration 60/1000 | Loss: 0.00002810
Iteration 61/1000 | Loss: 0.00024614
Iteration 62/1000 | Loss: 0.00004251
Iteration 63/1000 | Loss: 0.00005911
Iteration 64/1000 | Loss: 0.00008630
Iteration 65/1000 | Loss: 0.00015870
Iteration 66/1000 | Loss: 0.00047780
Iteration 67/1000 | Loss: 0.00055215
Iteration 68/1000 | Loss: 0.00036630
Iteration 69/1000 | Loss: 0.00010163
Iteration 70/1000 | Loss: 0.00017285
Iteration 71/1000 | Loss: 0.00003517
Iteration 72/1000 | Loss: 0.00009603
Iteration 73/1000 | Loss: 0.00010849
Iteration 74/1000 | Loss: 0.00006996
Iteration 75/1000 | Loss: 0.00002877
Iteration 76/1000 | Loss: 0.00004046
Iteration 77/1000 | Loss: 0.00002334
Iteration 78/1000 | Loss: 0.00010442
Iteration 79/1000 | Loss: 0.00003402
Iteration 80/1000 | Loss: 0.00003860
Iteration 81/1000 | Loss: 0.00102882
Iteration 82/1000 | Loss: 0.00004494
Iteration 83/1000 | Loss: 0.00007119
Iteration 84/1000 | Loss: 0.00002991
Iteration 85/1000 | Loss: 0.00006064
Iteration 86/1000 | Loss: 0.00001974
Iteration 87/1000 | Loss: 0.00005383
Iteration 88/1000 | Loss: 0.00007744
Iteration 89/1000 | Loss: 0.00004894
Iteration 90/1000 | Loss: 0.00002637
Iteration 91/1000 | Loss: 0.00002696
Iteration 92/1000 | Loss: 0.00012959
Iteration 93/1000 | Loss: 0.00003206
Iteration 94/1000 | Loss: 0.00008819
Iteration 95/1000 | Loss: 0.00002438
Iteration 96/1000 | Loss: 0.00018764
Iteration 97/1000 | Loss: 0.00004251
Iteration 98/1000 | Loss: 0.00010193
Iteration 99/1000 | Loss: 0.00016771
Iteration 100/1000 | Loss: 0.00033260
Iteration 101/1000 | Loss: 0.00014199
Iteration 102/1000 | Loss: 0.00008987
Iteration 103/1000 | Loss: 0.00002336
Iteration 104/1000 | Loss: 0.00003701
Iteration 105/1000 | Loss: 0.00005222
Iteration 106/1000 | Loss: 0.00007193
Iteration 107/1000 | Loss: 0.00003195
Iteration 108/1000 | Loss: 0.00010156
Iteration 109/1000 | Loss: 0.00002388
Iteration 110/1000 | Loss: 0.00005480
Iteration 111/1000 | Loss: 0.00004273
Iteration 112/1000 | Loss: 0.00002012
Iteration 113/1000 | Loss: 0.00004640
Iteration 114/1000 | Loss: 0.00006015
Iteration 115/1000 | Loss: 0.00002393
Iteration 116/1000 | Loss: 0.00003620
Iteration 117/1000 | Loss: 0.00001811
Iteration 118/1000 | Loss: 0.00001810
Iteration 119/1000 | Loss: 0.00001810
Iteration 120/1000 | Loss: 0.00001810
Iteration 121/1000 | Loss: 0.00001810
Iteration 122/1000 | Loss: 0.00001810
Iteration 123/1000 | Loss: 0.00001810
Iteration 124/1000 | Loss: 0.00001810
Iteration 125/1000 | Loss: 0.00001810
Iteration 126/1000 | Loss: 0.00001810
Iteration 127/1000 | Loss: 0.00001810
Iteration 128/1000 | Loss: 0.00001810
Iteration 129/1000 | Loss: 0.00001809
Iteration 130/1000 | Loss: 0.00001809
Iteration 131/1000 | Loss: 0.00001809
Iteration 132/1000 | Loss: 0.00001809
Iteration 133/1000 | Loss: 0.00001808
Iteration 134/1000 | Loss: 0.00001808
Iteration 135/1000 | Loss: 0.00001808
Iteration 136/1000 | Loss: 0.00007436
Iteration 137/1000 | Loss: 0.00024970
Iteration 138/1000 | Loss: 0.00002506
Iteration 139/1000 | Loss: 0.00004130
Iteration 140/1000 | Loss: 0.00010733
Iteration 141/1000 | Loss: 0.00002721
Iteration 142/1000 | Loss: 0.00001800
Iteration 143/1000 | Loss: 0.00001799
Iteration 144/1000 | Loss: 0.00001799
Iteration 145/1000 | Loss: 0.00001798
Iteration 146/1000 | Loss: 0.00001798
Iteration 147/1000 | Loss: 0.00001797
Iteration 148/1000 | Loss: 0.00002774
Iteration 149/1000 | Loss: 0.00001797
Iteration 150/1000 | Loss: 0.00001797
Iteration 151/1000 | Loss: 0.00001796
Iteration 152/1000 | Loss: 0.00001796
Iteration 153/1000 | Loss: 0.00001796
Iteration 154/1000 | Loss: 0.00001796
Iteration 155/1000 | Loss: 0.00001796
Iteration 156/1000 | Loss: 0.00001796
Iteration 157/1000 | Loss: 0.00001796
Iteration 158/1000 | Loss: 0.00001796
Iteration 159/1000 | Loss: 0.00001796
Iteration 160/1000 | Loss: 0.00001796
Iteration 161/1000 | Loss: 0.00001796
Iteration 162/1000 | Loss: 0.00001796
Iteration 163/1000 | Loss: 0.00001796
Iteration 164/1000 | Loss: 0.00001795
Iteration 165/1000 | Loss: 0.00001795
Iteration 166/1000 | Loss: 0.00001795
Iteration 167/1000 | Loss: 0.00001794
Iteration 168/1000 | Loss: 0.00001794
Iteration 169/1000 | Loss: 0.00001794
Iteration 170/1000 | Loss: 0.00001793
Iteration 171/1000 | Loss: 0.00001793
Iteration 172/1000 | Loss: 0.00001793
Iteration 173/1000 | Loss: 0.00001793
Iteration 174/1000 | Loss: 0.00001793
Iteration 175/1000 | Loss: 0.00001793
Iteration 176/1000 | Loss: 0.00001792
Iteration 177/1000 | Loss: 0.00001792
Iteration 178/1000 | Loss: 0.00001792
Iteration 179/1000 | Loss: 0.00001792
Iteration 180/1000 | Loss: 0.00001791
Iteration 181/1000 | Loss: 0.00001791
Iteration 182/1000 | Loss: 0.00001791
Iteration 183/1000 | Loss: 0.00001791
Iteration 184/1000 | Loss: 0.00001790
Iteration 185/1000 | Loss: 0.00001790
Iteration 186/1000 | Loss: 0.00001790
Iteration 187/1000 | Loss: 0.00001790
Iteration 188/1000 | Loss: 0.00001790
Iteration 189/1000 | Loss: 0.00001790
Iteration 190/1000 | Loss: 0.00001790
Iteration 191/1000 | Loss: 0.00001790
Iteration 192/1000 | Loss: 0.00001790
Iteration 193/1000 | Loss: 0.00007486
Iteration 194/1000 | Loss: 0.00007268
Iteration 195/1000 | Loss: 0.00013350
Iteration 196/1000 | Loss: 0.00014966
Iteration 197/1000 | Loss: 0.00005201
Iteration 198/1000 | Loss: 0.00008587
Iteration 199/1000 | Loss: 0.00030268
Iteration 200/1000 | Loss: 0.00004269
Iteration 201/1000 | Loss: 0.00007113
Iteration 202/1000 | Loss: 0.00031689
Iteration 203/1000 | Loss: 0.00003531
Iteration 204/1000 | Loss: 0.00002541
Iteration 205/1000 | Loss: 0.00004985
Iteration 206/1000 | Loss: 0.00003448
Iteration 207/1000 | Loss: 0.00017123
Iteration 208/1000 | Loss: 0.00172951
Iteration 209/1000 | Loss: 0.00008803
Iteration 210/1000 | Loss: 0.00024871
Iteration 211/1000 | Loss: 0.00004014
Iteration 212/1000 | Loss: 0.00004906
Iteration 213/1000 | Loss: 0.00004207
Iteration 214/1000 | Loss: 0.00002964
Iteration 215/1000 | Loss: 0.00008455
Iteration 216/1000 | Loss: 0.00002087
Iteration 217/1000 | Loss: 0.00002775
Iteration 218/1000 | Loss: 0.00003160
Iteration 219/1000 | Loss: 0.00001792
Iteration 220/1000 | Loss: 0.00001792
Iteration 221/1000 | Loss: 0.00001792
Iteration 222/1000 | Loss: 0.00001792
Iteration 223/1000 | Loss: 0.00001792
Iteration 224/1000 | Loss: 0.00001792
Iteration 225/1000 | Loss: 0.00001792
Iteration 226/1000 | Loss: 0.00001792
Iteration 227/1000 | Loss: 0.00001792
Iteration 228/1000 | Loss: 0.00001792
Iteration 229/1000 | Loss: 0.00001792
Iteration 230/1000 | Loss: 0.00001791
Iteration 231/1000 | Loss: 0.00001791
Iteration 232/1000 | Loss: 0.00001791
Iteration 233/1000 | Loss: 0.00004831
Iteration 234/1000 | Loss: 0.00078501
Iteration 235/1000 | Loss: 0.00005578
Iteration 236/1000 | Loss: 0.00011092
Iteration 237/1000 | Loss: 0.00003003
Iteration 238/1000 | Loss: 0.00003470
Iteration 239/1000 | Loss: 0.00002325
Iteration 240/1000 | Loss: 0.00001800
Iteration 241/1000 | Loss: 0.00007697
Iteration 242/1000 | Loss: 0.00018280
Iteration 243/1000 | Loss: 0.00003061
Iteration 244/1000 | Loss: 0.00005487
Iteration 245/1000 | Loss: 0.00002736
Iteration 246/1000 | Loss: 0.00003879
Iteration 247/1000 | Loss: 0.00002632
Iteration 248/1000 | Loss: 0.00001794
Iteration 249/1000 | Loss: 0.00001791
Iteration 250/1000 | Loss: 0.00001790
Iteration 251/1000 | Loss: 0.00001790
Iteration 252/1000 | Loss: 0.00001789
Iteration 253/1000 | Loss: 0.00001789
Iteration 254/1000 | Loss: 0.00001788
Iteration 255/1000 | Loss: 0.00001788
Iteration 256/1000 | Loss: 0.00001787
Iteration 257/1000 | Loss: 0.00001787
Iteration 258/1000 | Loss: 0.00001787
Iteration 259/1000 | Loss: 0.00001786
Iteration 260/1000 | Loss: 0.00001786
Iteration 261/1000 | Loss: 0.00001785
Iteration 262/1000 | Loss: 0.00001785
Iteration 263/1000 | Loss: 0.00001785
Iteration 264/1000 | Loss: 0.00001785
Iteration 265/1000 | Loss: 0.00001785
Iteration 266/1000 | Loss: 0.00001785
Iteration 267/1000 | Loss: 0.00001785
Iteration 268/1000 | Loss: 0.00001785
Iteration 269/1000 | Loss: 0.00001785
Iteration 270/1000 | Loss: 0.00001785
Iteration 271/1000 | Loss: 0.00001784
Iteration 272/1000 | Loss: 0.00001784
Iteration 273/1000 | Loss: 0.00001784
Iteration 274/1000 | Loss: 0.00001783
Iteration 275/1000 | Loss: 0.00001783
Iteration 276/1000 | Loss: 0.00001783
Iteration 277/1000 | Loss: 0.00001783
Iteration 278/1000 | Loss: 0.00001783
Iteration 279/1000 | Loss: 0.00001783
Iteration 280/1000 | Loss: 0.00001782
Iteration 281/1000 | Loss: 0.00001782
Iteration 282/1000 | Loss: 0.00001782
Iteration 283/1000 | Loss: 0.00001782
Iteration 284/1000 | Loss: 0.00001782
Iteration 285/1000 | Loss: 0.00001782
Iteration 286/1000 | Loss: 0.00001782
Iteration 287/1000 | Loss: 0.00001782
Iteration 288/1000 | Loss: 0.00001782
Iteration 289/1000 | Loss: 0.00001782
Iteration 290/1000 | Loss: 0.00001781
Iteration 291/1000 | Loss: 0.00001781
Iteration 292/1000 | Loss: 0.00001781
Iteration 293/1000 | Loss: 0.00001781
Iteration 294/1000 | Loss: 0.00001781
Iteration 295/1000 | Loss: 0.00001781
Iteration 296/1000 | Loss: 0.00001781
Iteration 297/1000 | Loss: 0.00001781
Iteration 298/1000 | Loss: 0.00001781
Iteration 299/1000 | Loss: 0.00001781
Iteration 300/1000 | Loss: 0.00001781
Iteration 301/1000 | Loss: 0.00001781
Iteration 302/1000 | Loss: 0.00001781
Iteration 303/1000 | Loss: 0.00001781
Iteration 304/1000 | Loss: 0.00001781
Iteration 305/1000 | Loss: 0.00001781
Iteration 306/1000 | Loss: 0.00001781
Iteration 307/1000 | Loss: 0.00001781
Iteration 308/1000 | Loss: 0.00001781
Iteration 309/1000 | Loss: 0.00001781
Iteration 310/1000 | Loss: 0.00001781
Iteration 311/1000 | Loss: 0.00001781
Iteration 312/1000 | Loss: 0.00001781
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 312. Stopping optimization.
Last 5 losses: [1.7805314200813882e-05, 1.7805314200813882e-05, 1.7805314200813882e-05, 1.7805314200813882e-05, 1.7805314200813882e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7805314200813882e-05

Optimization complete. Final v2v error: 3.6312026977539062 mm

Highest mean error: 3.8943138122558594 mm for frame 2

Lowest mean error: 3.4116358757019043 mm for frame 106

Saving results

Total time: 4218.7186596393585
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1010
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01048851
Iteration 2/25 | Loss: 0.00165939
Iteration 3/25 | Loss: 0.00139375
Iteration 4/25 | Loss: 0.00136779
Iteration 5/25 | Loss: 0.00136046
Iteration 6/25 | Loss: 0.00136237
Iteration 7/25 | Loss: 0.00135625
Iteration 8/25 | Loss: 0.00135507
Iteration 9/25 | Loss: 0.00135485
Iteration 10/25 | Loss: 0.00135469
Iteration 11/25 | Loss: 0.00135460
Iteration 12/25 | Loss: 0.00135457
Iteration 13/25 | Loss: 0.00135457
Iteration 14/25 | Loss: 0.00135457
Iteration 15/25 | Loss: 0.00135457
Iteration 16/25 | Loss: 0.00135457
Iteration 17/25 | Loss: 0.00135457
Iteration 18/25 | Loss: 0.00135457
Iteration 19/25 | Loss: 0.00135456
Iteration 20/25 | Loss: 0.00135456
Iteration 21/25 | Loss: 0.00135456
Iteration 22/25 | Loss: 0.00135456
Iteration 23/25 | Loss: 0.00135456
Iteration 24/25 | Loss: 0.00135456
Iteration 25/25 | Loss: 0.00135456

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41627407
Iteration 2/25 | Loss: 0.00108883
Iteration 3/25 | Loss: 0.00108882
Iteration 4/25 | Loss: 0.00108882
Iteration 5/25 | Loss: 0.00108882
Iteration 6/25 | Loss: 0.00108882
Iteration 7/25 | Loss: 0.00108882
Iteration 8/25 | Loss: 0.00108882
Iteration 9/25 | Loss: 0.00108882
Iteration 10/25 | Loss: 0.00108882
Iteration 11/25 | Loss: 0.00108882
Iteration 12/25 | Loss: 0.00108882
Iteration 13/25 | Loss: 0.00108882
Iteration 14/25 | Loss: 0.00108882
Iteration 15/25 | Loss: 0.00108882
Iteration 16/25 | Loss: 0.00108882
Iteration 17/25 | Loss: 0.00108882
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001088821329176426, 0.001088821329176426, 0.001088821329176426, 0.001088821329176426, 0.001088821329176426]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001088821329176426

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00108882
Iteration 2/1000 | Loss: 0.00003306
Iteration 3/1000 | Loss: 0.00051952
Iteration 4/1000 | Loss: 0.00007957
Iteration 5/1000 | Loss: 0.00002038
Iteration 6/1000 | Loss: 0.00022397
Iteration 7/1000 | Loss: 0.00015014
Iteration 8/1000 | Loss: 0.00016213
Iteration 9/1000 | Loss: 0.00020585
Iteration 10/1000 | Loss: 0.00009933
Iteration 11/1000 | Loss: 0.00002171
Iteration 12/1000 | Loss: 0.00001956
Iteration 13/1000 | Loss: 0.00001842
Iteration 14/1000 | Loss: 0.00001808
Iteration 15/1000 | Loss: 0.00001776
Iteration 16/1000 | Loss: 0.00001755
Iteration 17/1000 | Loss: 0.00001743
Iteration 18/1000 | Loss: 0.00001739
Iteration 19/1000 | Loss: 0.00001732
Iteration 20/1000 | Loss: 0.00001716
Iteration 21/1000 | Loss: 0.00001711
Iteration 22/1000 | Loss: 0.00001708
Iteration 23/1000 | Loss: 0.00001707
Iteration 24/1000 | Loss: 0.00001706
Iteration 25/1000 | Loss: 0.00001706
Iteration 26/1000 | Loss: 0.00001705
Iteration 27/1000 | Loss: 0.00001705
Iteration 28/1000 | Loss: 0.00001698
Iteration 29/1000 | Loss: 0.00001695
Iteration 30/1000 | Loss: 0.00001695
Iteration 31/1000 | Loss: 0.00001693
Iteration 32/1000 | Loss: 0.00001692
Iteration 33/1000 | Loss: 0.00001692
Iteration 34/1000 | Loss: 0.00001692
Iteration 35/1000 | Loss: 0.00001690
Iteration 36/1000 | Loss: 0.00001690
Iteration 37/1000 | Loss: 0.00001690
Iteration 38/1000 | Loss: 0.00001688
Iteration 39/1000 | Loss: 0.00001688
Iteration 40/1000 | Loss: 0.00001687
Iteration 41/1000 | Loss: 0.00001682
Iteration 42/1000 | Loss: 0.00001682
Iteration 43/1000 | Loss: 0.00001682
Iteration 44/1000 | Loss: 0.00001680
Iteration 45/1000 | Loss: 0.00001680
Iteration 46/1000 | Loss: 0.00001680
Iteration 47/1000 | Loss: 0.00001680
Iteration 48/1000 | Loss: 0.00001680
Iteration 49/1000 | Loss: 0.00001680
Iteration 50/1000 | Loss: 0.00001680
Iteration 51/1000 | Loss: 0.00001679
Iteration 52/1000 | Loss: 0.00001679
Iteration 53/1000 | Loss: 0.00001679
Iteration 54/1000 | Loss: 0.00001679
Iteration 55/1000 | Loss: 0.00001679
Iteration 56/1000 | Loss: 0.00001679
Iteration 57/1000 | Loss: 0.00001679
Iteration 58/1000 | Loss: 0.00001679
Iteration 59/1000 | Loss: 0.00001678
Iteration 60/1000 | Loss: 0.00001678
Iteration 61/1000 | Loss: 0.00001678
Iteration 62/1000 | Loss: 0.00001678
Iteration 63/1000 | Loss: 0.00001677
Iteration 64/1000 | Loss: 0.00001677
Iteration 65/1000 | Loss: 0.00001677
Iteration 66/1000 | Loss: 0.00001676
Iteration 67/1000 | Loss: 0.00001676
Iteration 68/1000 | Loss: 0.00001676
Iteration 69/1000 | Loss: 0.00001676
Iteration 70/1000 | Loss: 0.00001675
Iteration 71/1000 | Loss: 0.00001675
Iteration 72/1000 | Loss: 0.00001675
Iteration 73/1000 | Loss: 0.00001675
Iteration 74/1000 | Loss: 0.00001675
Iteration 75/1000 | Loss: 0.00001675
Iteration 76/1000 | Loss: 0.00001675
Iteration 77/1000 | Loss: 0.00001675
Iteration 78/1000 | Loss: 0.00001675
Iteration 79/1000 | Loss: 0.00001675
Iteration 80/1000 | Loss: 0.00001674
Iteration 81/1000 | Loss: 0.00001674
Iteration 82/1000 | Loss: 0.00001674
Iteration 83/1000 | Loss: 0.00001673
Iteration 84/1000 | Loss: 0.00001673
Iteration 85/1000 | Loss: 0.00001673
Iteration 86/1000 | Loss: 0.00001673
Iteration 87/1000 | Loss: 0.00001673
Iteration 88/1000 | Loss: 0.00001672
Iteration 89/1000 | Loss: 0.00001672
Iteration 90/1000 | Loss: 0.00001672
Iteration 91/1000 | Loss: 0.00001672
Iteration 92/1000 | Loss: 0.00001672
Iteration 93/1000 | Loss: 0.00001672
Iteration 94/1000 | Loss: 0.00001672
Iteration 95/1000 | Loss: 0.00001672
Iteration 96/1000 | Loss: 0.00001672
Iteration 97/1000 | Loss: 0.00001672
Iteration 98/1000 | Loss: 0.00001672
Iteration 99/1000 | Loss: 0.00001671
Iteration 100/1000 | Loss: 0.00001671
Iteration 101/1000 | Loss: 0.00001671
Iteration 102/1000 | Loss: 0.00001671
Iteration 103/1000 | Loss: 0.00001671
Iteration 104/1000 | Loss: 0.00001670
Iteration 105/1000 | Loss: 0.00001670
Iteration 106/1000 | Loss: 0.00001670
Iteration 107/1000 | Loss: 0.00001670
Iteration 108/1000 | Loss: 0.00001670
Iteration 109/1000 | Loss: 0.00001670
Iteration 110/1000 | Loss: 0.00001670
Iteration 111/1000 | Loss: 0.00001669
Iteration 112/1000 | Loss: 0.00001669
Iteration 113/1000 | Loss: 0.00001669
Iteration 114/1000 | Loss: 0.00001669
Iteration 115/1000 | Loss: 0.00001669
Iteration 116/1000 | Loss: 0.00001669
Iteration 117/1000 | Loss: 0.00001669
Iteration 118/1000 | Loss: 0.00001668
Iteration 119/1000 | Loss: 0.00001668
Iteration 120/1000 | Loss: 0.00001668
Iteration 121/1000 | Loss: 0.00001668
Iteration 122/1000 | Loss: 0.00001668
Iteration 123/1000 | Loss: 0.00001668
Iteration 124/1000 | Loss: 0.00001668
Iteration 125/1000 | Loss: 0.00001667
Iteration 126/1000 | Loss: 0.00001667
Iteration 127/1000 | Loss: 0.00001667
Iteration 128/1000 | Loss: 0.00001667
Iteration 129/1000 | Loss: 0.00001667
Iteration 130/1000 | Loss: 0.00001666
Iteration 131/1000 | Loss: 0.00001666
Iteration 132/1000 | Loss: 0.00001666
Iteration 133/1000 | Loss: 0.00001666
Iteration 134/1000 | Loss: 0.00001665
Iteration 135/1000 | Loss: 0.00001665
Iteration 136/1000 | Loss: 0.00001665
Iteration 137/1000 | Loss: 0.00001665
Iteration 138/1000 | Loss: 0.00001665
Iteration 139/1000 | Loss: 0.00001665
Iteration 140/1000 | Loss: 0.00001665
Iteration 141/1000 | Loss: 0.00001664
Iteration 142/1000 | Loss: 0.00001664
Iteration 143/1000 | Loss: 0.00001664
Iteration 144/1000 | Loss: 0.00001664
Iteration 145/1000 | Loss: 0.00001664
Iteration 146/1000 | Loss: 0.00001664
Iteration 147/1000 | Loss: 0.00001664
Iteration 148/1000 | Loss: 0.00001664
Iteration 149/1000 | Loss: 0.00001663
Iteration 150/1000 | Loss: 0.00001663
Iteration 151/1000 | Loss: 0.00001663
Iteration 152/1000 | Loss: 0.00001663
Iteration 153/1000 | Loss: 0.00001663
Iteration 154/1000 | Loss: 0.00001663
Iteration 155/1000 | Loss: 0.00001663
Iteration 156/1000 | Loss: 0.00001662
Iteration 157/1000 | Loss: 0.00001662
Iteration 158/1000 | Loss: 0.00001662
Iteration 159/1000 | Loss: 0.00001662
Iteration 160/1000 | Loss: 0.00001662
Iteration 161/1000 | Loss: 0.00001662
Iteration 162/1000 | Loss: 0.00001662
Iteration 163/1000 | Loss: 0.00001662
Iteration 164/1000 | Loss: 0.00001662
Iteration 165/1000 | Loss: 0.00001662
Iteration 166/1000 | Loss: 0.00001661
Iteration 167/1000 | Loss: 0.00001661
Iteration 168/1000 | Loss: 0.00001661
Iteration 169/1000 | Loss: 0.00001661
Iteration 170/1000 | Loss: 0.00001661
Iteration 171/1000 | Loss: 0.00001661
Iteration 172/1000 | Loss: 0.00001660
Iteration 173/1000 | Loss: 0.00001660
Iteration 174/1000 | Loss: 0.00001660
Iteration 175/1000 | Loss: 0.00001659
Iteration 176/1000 | Loss: 0.00001659
Iteration 177/1000 | Loss: 0.00001659
Iteration 178/1000 | Loss: 0.00001659
Iteration 179/1000 | Loss: 0.00001659
Iteration 180/1000 | Loss: 0.00001659
Iteration 181/1000 | Loss: 0.00001659
Iteration 182/1000 | Loss: 0.00001659
Iteration 183/1000 | Loss: 0.00001659
Iteration 184/1000 | Loss: 0.00001658
Iteration 185/1000 | Loss: 0.00001658
Iteration 186/1000 | Loss: 0.00001658
Iteration 187/1000 | Loss: 0.00001658
Iteration 188/1000 | Loss: 0.00001658
Iteration 189/1000 | Loss: 0.00001658
Iteration 190/1000 | Loss: 0.00001658
Iteration 191/1000 | Loss: 0.00001658
Iteration 192/1000 | Loss: 0.00001658
Iteration 193/1000 | Loss: 0.00001658
Iteration 194/1000 | Loss: 0.00001658
Iteration 195/1000 | Loss: 0.00001658
Iteration 196/1000 | Loss: 0.00001658
Iteration 197/1000 | Loss: 0.00001658
Iteration 198/1000 | Loss: 0.00001658
Iteration 199/1000 | Loss: 0.00001657
Iteration 200/1000 | Loss: 0.00001657
Iteration 201/1000 | Loss: 0.00001657
Iteration 202/1000 | Loss: 0.00001657
Iteration 203/1000 | Loss: 0.00001657
Iteration 204/1000 | Loss: 0.00001657
Iteration 205/1000 | Loss: 0.00001657
Iteration 206/1000 | Loss: 0.00001657
Iteration 207/1000 | Loss: 0.00001657
Iteration 208/1000 | Loss: 0.00001657
Iteration 209/1000 | Loss: 0.00001657
Iteration 210/1000 | Loss: 0.00001657
Iteration 211/1000 | Loss: 0.00001657
Iteration 212/1000 | Loss: 0.00001657
Iteration 213/1000 | Loss: 0.00001657
Iteration 214/1000 | Loss: 0.00001657
Iteration 215/1000 | Loss: 0.00001657
Iteration 216/1000 | Loss: 0.00001657
Iteration 217/1000 | Loss: 0.00001656
Iteration 218/1000 | Loss: 0.00001656
Iteration 219/1000 | Loss: 0.00001656
Iteration 220/1000 | Loss: 0.00001656
Iteration 221/1000 | Loss: 0.00001656
Iteration 222/1000 | Loss: 0.00001656
Iteration 223/1000 | Loss: 0.00001656
Iteration 224/1000 | Loss: 0.00001656
Iteration 225/1000 | Loss: 0.00001656
Iteration 226/1000 | Loss: 0.00001656
Iteration 227/1000 | Loss: 0.00001656
Iteration 228/1000 | Loss: 0.00001656
Iteration 229/1000 | Loss: 0.00001656
Iteration 230/1000 | Loss: 0.00001656
Iteration 231/1000 | Loss: 0.00001656
Iteration 232/1000 | Loss: 0.00001656
Iteration 233/1000 | Loss: 0.00001656
Iteration 234/1000 | Loss: 0.00001656
Iteration 235/1000 | Loss: 0.00001656
Iteration 236/1000 | Loss: 0.00001656
Iteration 237/1000 | Loss: 0.00001656
Iteration 238/1000 | Loss: 0.00001656
Iteration 239/1000 | Loss: 0.00001656
Iteration 240/1000 | Loss: 0.00001656
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 240. Stopping optimization.
Last 5 losses: [1.6559883079025894e-05, 1.6559883079025894e-05, 1.6559883079025894e-05, 1.6559883079025894e-05, 1.6559883079025894e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6559883079025894e-05

Optimization complete. Final v2v error: 3.385096311569214 mm

Highest mean error: 4.007992744445801 mm for frame 8

Lowest mean error: 2.9874563217163086 mm for frame 74

Saving results

Total time: 1389.3715541362762
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1097/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1097.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1097
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01037431
Iteration 2/25 | Loss: 0.01037431
Iteration 3/25 | Loss: 0.00282197
Iteration 4/25 | Loss: 0.00264926
Iteration 5/25 | Loss: 0.00240913
Iteration 6/25 | Loss: 0.00181452
Iteration 7/25 | Loss: 0.00157367
Iteration 8/25 | Loss: 0.00140119
Iteration 9/25 | Loss: 0.00134984
Iteration 10/25 | Loss: 0.00131729
Iteration 11/25 | Loss: 0.00129375
Iteration 12/25 | Loss: 0.00129090
Iteration 13/25 | Loss: 0.00129005
Iteration 14/25 | Loss: 0.00128981
Iteration 15/25 | Loss: 0.00128972
Iteration 16/25 | Loss: 0.00128968
Iteration 17/25 | Loss: 0.00128968
Iteration 18/25 | Loss: 0.00128967
Iteration 19/25 | Loss: 0.00128967
Iteration 20/25 | Loss: 0.00128967
Iteration 21/25 | Loss: 0.00128967
Iteration 22/25 | Loss: 0.00128967
Iteration 23/25 | Loss: 0.00128967
Iteration 24/25 | Loss: 0.00128967
Iteration 25/25 | Loss: 0.00128967

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35143971
Iteration 2/25 | Loss: 0.00093437
Iteration 3/25 | Loss: 0.00093437
Iteration 4/25 | Loss: 0.00093437
Iteration 5/25 | Loss: 0.00093437
Iteration 6/25 | Loss: 0.00093437
Iteration 7/25 | Loss: 0.00093437
Iteration 8/25 | Loss: 0.00093437
Iteration 9/25 | Loss: 0.00093437
Iteration 10/25 | Loss: 0.00093437
Iteration 11/25 | Loss: 0.00093437
Iteration 12/25 | Loss: 0.00093437
Iteration 13/25 | Loss: 0.00093437
Iteration 14/25 | Loss: 0.00093437
Iteration 15/25 | Loss: 0.00093437
Iteration 16/25 | Loss: 0.00093437
Iteration 17/25 | Loss: 0.00093437
Iteration 18/25 | Loss: 0.00093437
Iteration 19/25 | Loss: 0.00093437
Iteration 20/25 | Loss: 0.00093437
Iteration 21/25 | Loss: 0.00093437
Iteration 22/25 | Loss: 0.00093437
Iteration 23/25 | Loss: 0.00093437
Iteration 24/25 | Loss: 0.00093437
Iteration 25/25 | Loss: 0.00093437
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0009343652636744082, 0.0009343652636744082, 0.0009343652636744082, 0.0009343652636744082, 0.0009343652636744082]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009343652636744082

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00093437
Iteration 2/1000 | Loss: 0.00004972
Iteration 3/1000 | Loss: 0.00003528
Iteration 4/1000 | Loss: 0.00003077
Iteration 5/1000 | Loss: 0.00002941
Iteration 6/1000 | Loss: 0.00002823
Iteration 7/1000 | Loss: 0.00002725
Iteration 8/1000 | Loss: 0.00002652
Iteration 9/1000 | Loss: 0.00002596
Iteration 10/1000 | Loss: 0.00045072
Iteration 11/1000 | Loss: 0.00081774
Iteration 12/1000 | Loss: 0.00002662
Iteration 13/1000 | Loss: 0.00002311
Iteration 14/1000 | Loss: 0.00002054
Iteration 15/1000 | Loss: 0.00001947
Iteration 16/1000 | Loss: 0.00001861
Iteration 17/1000 | Loss: 0.00001803
Iteration 18/1000 | Loss: 0.00001760
Iteration 19/1000 | Loss: 0.00001728
Iteration 20/1000 | Loss: 0.00001698
Iteration 21/1000 | Loss: 0.00001679
Iteration 22/1000 | Loss: 0.00001652
Iteration 23/1000 | Loss: 0.00001636
Iteration 24/1000 | Loss: 0.00001635
Iteration 25/1000 | Loss: 0.00001633
Iteration 26/1000 | Loss: 0.00001633
Iteration 27/1000 | Loss: 0.00001632
Iteration 28/1000 | Loss: 0.00001632
Iteration 29/1000 | Loss: 0.00001632
Iteration 30/1000 | Loss: 0.00001631
Iteration 31/1000 | Loss: 0.00001631
Iteration 32/1000 | Loss: 0.00001630
Iteration 33/1000 | Loss: 0.00001629
Iteration 34/1000 | Loss: 0.00001628
Iteration 35/1000 | Loss: 0.00001628
Iteration 36/1000 | Loss: 0.00001627
Iteration 37/1000 | Loss: 0.00001627
Iteration 38/1000 | Loss: 0.00001627
Iteration 39/1000 | Loss: 0.00001627
Iteration 40/1000 | Loss: 0.00001626
Iteration 41/1000 | Loss: 0.00001626
Iteration 42/1000 | Loss: 0.00001626
Iteration 43/1000 | Loss: 0.00001626
Iteration 44/1000 | Loss: 0.00001626
Iteration 45/1000 | Loss: 0.00001626
Iteration 46/1000 | Loss: 0.00001626
Iteration 47/1000 | Loss: 0.00001625
Iteration 48/1000 | Loss: 0.00001625
Iteration 49/1000 | Loss: 0.00001625
Iteration 50/1000 | Loss: 0.00001624
Iteration 51/1000 | Loss: 0.00001624
Iteration 52/1000 | Loss: 0.00001624
Iteration 53/1000 | Loss: 0.00001624
Iteration 54/1000 | Loss: 0.00001624
Iteration 55/1000 | Loss: 0.00001623
Iteration 56/1000 | Loss: 0.00001623
Iteration 57/1000 | Loss: 0.00001623
Iteration 58/1000 | Loss: 0.00001623
Iteration 59/1000 | Loss: 0.00001623
Iteration 60/1000 | Loss: 0.00001622
Iteration 61/1000 | Loss: 0.00001622
Iteration 62/1000 | Loss: 0.00001622
Iteration 63/1000 | Loss: 0.00001622
Iteration 64/1000 | Loss: 0.00001622
Iteration 65/1000 | Loss: 0.00001622
Iteration 66/1000 | Loss: 0.00001621
Iteration 67/1000 | Loss: 0.00001621
Iteration 68/1000 | Loss: 0.00001621
Iteration 69/1000 | Loss: 0.00001621
Iteration 70/1000 | Loss: 0.00001621
Iteration 71/1000 | Loss: 0.00001621
Iteration 72/1000 | Loss: 0.00001621
Iteration 73/1000 | Loss: 0.00001621
Iteration 74/1000 | Loss: 0.00001621
Iteration 75/1000 | Loss: 0.00001621
Iteration 76/1000 | Loss: 0.00001621
Iteration 77/1000 | Loss: 0.00001621
Iteration 78/1000 | Loss: 0.00001620
Iteration 79/1000 | Loss: 0.00001620
Iteration 80/1000 | Loss: 0.00001620
Iteration 81/1000 | Loss: 0.00001620
Iteration 82/1000 | Loss: 0.00001620
Iteration 83/1000 | Loss: 0.00001620
Iteration 84/1000 | Loss: 0.00001619
Iteration 85/1000 | Loss: 0.00001619
Iteration 86/1000 | Loss: 0.00001619
Iteration 87/1000 | Loss: 0.00001619
Iteration 88/1000 | Loss: 0.00001619
Iteration 89/1000 | Loss: 0.00001619
Iteration 90/1000 | Loss: 0.00001618
Iteration 91/1000 | Loss: 0.00001618
Iteration 92/1000 | Loss: 0.00001618
Iteration 93/1000 | Loss: 0.00001618
Iteration 94/1000 | Loss: 0.00001617
Iteration 95/1000 | Loss: 0.00001617
Iteration 96/1000 | Loss: 0.00001617
Iteration 97/1000 | Loss: 0.00001617
Iteration 98/1000 | Loss: 0.00001617
Iteration 99/1000 | Loss: 0.00001617
Iteration 100/1000 | Loss: 0.00001616
Iteration 101/1000 | Loss: 0.00001616
Iteration 102/1000 | Loss: 0.00001615
Iteration 103/1000 | Loss: 0.00001615
Iteration 104/1000 | Loss: 0.00001615
Iteration 105/1000 | Loss: 0.00001615
Iteration 106/1000 | Loss: 0.00001615
Iteration 107/1000 | Loss: 0.00001615
Iteration 108/1000 | Loss: 0.00001615
Iteration 109/1000 | Loss: 0.00001614
Iteration 110/1000 | Loss: 0.00001614
Iteration 111/1000 | Loss: 0.00001614
Iteration 112/1000 | Loss: 0.00001614
Iteration 113/1000 | Loss: 0.00001614
Iteration 114/1000 | Loss: 0.00001614
Iteration 115/1000 | Loss: 0.00001614
Iteration 116/1000 | Loss: 0.00001614
Iteration 117/1000 | Loss: 0.00001614
Iteration 118/1000 | Loss: 0.00001614
Iteration 119/1000 | Loss: 0.00001614
Iteration 120/1000 | Loss: 0.00001614
Iteration 121/1000 | Loss: 0.00001614
Iteration 122/1000 | Loss: 0.00001614
Iteration 123/1000 | Loss: 0.00001613
Iteration 124/1000 | Loss: 0.00001613
Iteration 125/1000 | Loss: 0.00001613
Iteration 126/1000 | Loss: 0.00001613
Iteration 127/1000 | Loss: 0.00001613
Iteration 128/1000 | Loss: 0.00001613
Iteration 129/1000 | Loss: 0.00001613
Iteration 130/1000 | Loss: 0.00001613
Iteration 131/1000 | Loss: 0.00001613
Iteration 132/1000 | Loss: 0.00001613
Iteration 133/1000 | Loss: 0.00001613
Iteration 134/1000 | Loss: 0.00001613
Iteration 135/1000 | Loss: 0.00001613
Iteration 136/1000 | Loss: 0.00001613
Iteration 137/1000 | Loss: 0.00001612
Iteration 138/1000 | Loss: 0.00001612
Iteration 139/1000 | Loss: 0.00001612
Iteration 140/1000 | Loss: 0.00001612
Iteration 141/1000 | Loss: 0.00001612
Iteration 142/1000 | Loss: 0.00001612
Iteration 143/1000 | Loss: 0.00001612
Iteration 144/1000 | Loss: 0.00001612
Iteration 145/1000 | Loss: 0.00001612
Iteration 146/1000 | Loss: 0.00001612
Iteration 147/1000 | Loss: 0.00001612
Iteration 148/1000 | Loss: 0.00001612
Iteration 149/1000 | Loss: 0.00001612
Iteration 150/1000 | Loss: 0.00001612
Iteration 151/1000 | Loss: 0.00001612
Iteration 152/1000 | Loss: 0.00001612
Iteration 153/1000 | Loss: 0.00001611
Iteration 154/1000 | Loss: 0.00001611
Iteration 155/1000 | Loss: 0.00001611
Iteration 156/1000 | Loss: 0.00001611
Iteration 157/1000 | Loss: 0.00001611
Iteration 158/1000 | Loss: 0.00001611
Iteration 159/1000 | Loss: 0.00001611
Iteration 160/1000 | Loss: 0.00001611
Iteration 161/1000 | Loss: 0.00001611
Iteration 162/1000 | Loss: 0.00001611
Iteration 163/1000 | Loss: 0.00001611
Iteration 164/1000 | Loss: 0.00001611
Iteration 165/1000 | Loss: 0.00001611
Iteration 166/1000 | Loss: 0.00001611
Iteration 167/1000 | Loss: 0.00001611
Iteration 168/1000 | Loss: 0.00001611
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 168. Stopping optimization.
Last 5 losses: [1.6109359421534464e-05, 1.6109359421534464e-05, 1.6109359421534464e-05, 1.6109359421534464e-05, 1.6109359421534464e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6109359421534464e-05

Optimization complete. Final v2v error: 3.407921552658081 mm

Highest mean error: 3.7358453273773193 mm for frame 143

Lowest mean error: 3.263540506362915 mm for frame 99

Saving results

Total time: 1832.6105816364288
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1049
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00924275
Iteration 2/25 | Loss: 0.00219254
Iteration 3/25 | Loss: 0.00202260
Iteration 4/25 | Loss: 0.00182136
Iteration 5/25 | Loss: 0.00171984
Iteration 6/25 | Loss: 0.00161740
Iteration 7/25 | Loss: 0.00152154
Iteration 8/25 | Loss: 0.00150425
Iteration 9/25 | Loss: 0.00148626
Iteration 10/25 | Loss: 0.00147759
Iteration 11/25 | Loss: 0.00147515
Iteration 12/25 | Loss: 0.00147469
Iteration 13/25 | Loss: 0.00147463
Iteration 14/25 | Loss: 0.00147463
Iteration 15/25 | Loss: 0.00147463
Iteration 16/25 | Loss: 0.00147463
Iteration 17/25 | Loss: 0.00147463
Iteration 18/25 | Loss: 0.00147463
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0014746260130777955, 0.0014746260130777955, 0.0014746260130777955, 0.0014746260130777955, 0.0014746260130777955]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014746260130777955

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29022694
Iteration 2/25 | Loss: 0.00084283
Iteration 3/25 | Loss: 0.00084283
Iteration 4/25 | Loss: 0.00084283
Iteration 5/25 | Loss: 0.00084282
Iteration 6/25 | Loss: 0.00084282
Iteration 7/25 | Loss: 0.00084282
Iteration 8/25 | Loss: 0.00084282
Iteration 9/25 | Loss: 0.00084282
Iteration 10/25 | Loss: 0.00084282
Iteration 11/25 | Loss: 0.00084282
Iteration 12/25 | Loss: 0.00084282
Iteration 13/25 | Loss: 0.00084282
Iteration 14/25 | Loss: 0.00084282
Iteration 15/25 | Loss: 0.00084282
Iteration 16/25 | Loss: 0.00084282
Iteration 17/25 | Loss: 0.00084282
Iteration 18/25 | Loss: 0.00084282
Iteration 19/25 | Loss: 0.00084282
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0008428235887549818, 0.0008428235887549818, 0.0008428235887549818, 0.0008428235887549818, 0.0008428235887549818]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008428235887549818

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00084282
Iteration 2/1000 | Loss: 0.00006961
Iteration 3/1000 | Loss: 0.00042700
Iteration 4/1000 | Loss: 0.00004078
Iteration 5/1000 | Loss: 0.00041074
Iteration 6/1000 | Loss: 0.00007152
Iteration 7/1000 | Loss: 0.00004417
Iteration 8/1000 | Loss: 0.00003805
Iteration 9/1000 | Loss: 0.00034105
Iteration 10/1000 | Loss: 0.00005947
Iteration 11/1000 | Loss: 0.00007211
Iteration 12/1000 | Loss: 0.00003573
Iteration 13/1000 | Loss: 0.00003503
Iteration 14/1000 | Loss: 0.00067884
Iteration 15/1000 | Loss: 0.00010197
Iteration 16/1000 | Loss: 0.00067147
Iteration 17/1000 | Loss: 0.00006257
Iteration 18/1000 | Loss: 0.00011155
Iteration 19/1000 | Loss: 0.00003756
Iteration 20/1000 | Loss: 0.00003523
Iteration 21/1000 | Loss: 0.00003436
Iteration 22/1000 | Loss: 0.00003401
Iteration 23/1000 | Loss: 0.00003368
Iteration 24/1000 | Loss: 0.00003354
Iteration 25/1000 | Loss: 0.00003341
Iteration 26/1000 | Loss: 0.00003340
Iteration 27/1000 | Loss: 0.00003321
Iteration 28/1000 | Loss: 0.00003304
Iteration 29/1000 | Loss: 0.00003303
Iteration 30/1000 | Loss: 0.00003297
Iteration 31/1000 | Loss: 0.00003296
Iteration 32/1000 | Loss: 0.00003295
Iteration 33/1000 | Loss: 0.00003295
Iteration 34/1000 | Loss: 0.00003293
Iteration 35/1000 | Loss: 0.00003292
Iteration 36/1000 | Loss: 0.00003290
Iteration 37/1000 | Loss: 0.00003289
Iteration 38/1000 | Loss: 0.00003289
Iteration 39/1000 | Loss: 0.00003286
Iteration 40/1000 | Loss: 0.00003286
Iteration 41/1000 | Loss: 0.00003285
Iteration 42/1000 | Loss: 0.00003285
Iteration 43/1000 | Loss: 0.00003285
Iteration 44/1000 | Loss: 0.00003285
Iteration 45/1000 | Loss: 0.00003284
Iteration 46/1000 | Loss: 0.00003284
Iteration 47/1000 | Loss: 0.00003284
Iteration 48/1000 | Loss: 0.00003283
Iteration 49/1000 | Loss: 0.00003283
Iteration 50/1000 | Loss: 0.00003283
Iteration 51/1000 | Loss: 0.00003283
Iteration 52/1000 | Loss: 0.00003282
Iteration 53/1000 | Loss: 0.00003281
Iteration 54/1000 | Loss: 0.00003281
Iteration 55/1000 | Loss: 0.00003280
Iteration 56/1000 | Loss: 0.00003280
Iteration 57/1000 | Loss: 0.00003279
Iteration 58/1000 | Loss: 0.00003279
Iteration 59/1000 | Loss: 0.00003279
Iteration 60/1000 | Loss: 0.00003279
Iteration 61/1000 | Loss: 0.00003279
Iteration 62/1000 | Loss: 0.00003278
Iteration 63/1000 | Loss: 0.00003278
Iteration 64/1000 | Loss: 0.00003278
Iteration 65/1000 | Loss: 0.00003278
Iteration 66/1000 | Loss: 0.00003278
Iteration 67/1000 | Loss: 0.00003278
Iteration 68/1000 | Loss: 0.00003278
Iteration 69/1000 | Loss: 0.00003277
Iteration 70/1000 | Loss: 0.00003277
Iteration 71/1000 | Loss: 0.00003277
Iteration 72/1000 | Loss: 0.00003277
Iteration 73/1000 | Loss: 0.00003277
Iteration 74/1000 | Loss: 0.00003277
Iteration 75/1000 | Loss: 0.00003276
Iteration 76/1000 | Loss: 0.00003276
Iteration 77/1000 | Loss: 0.00003276
Iteration 78/1000 | Loss: 0.00003276
Iteration 79/1000 | Loss: 0.00003276
Iteration 80/1000 | Loss: 0.00003276
Iteration 81/1000 | Loss: 0.00003276
Iteration 82/1000 | Loss: 0.00003276
Iteration 83/1000 | Loss: 0.00003276
Iteration 84/1000 | Loss: 0.00003276
Iteration 85/1000 | Loss: 0.00003276
Iteration 86/1000 | Loss: 0.00003275
Iteration 87/1000 | Loss: 0.00003275
Iteration 88/1000 | Loss: 0.00003275
Iteration 89/1000 | Loss: 0.00003275
Iteration 90/1000 | Loss: 0.00003275
Iteration 91/1000 | Loss: 0.00003275
Iteration 92/1000 | Loss: 0.00003275
Iteration 93/1000 | Loss: 0.00003275
Iteration 94/1000 | Loss: 0.00003274
Iteration 95/1000 | Loss: 0.00003274
Iteration 96/1000 | Loss: 0.00003274
Iteration 97/1000 | Loss: 0.00003274
Iteration 98/1000 | Loss: 0.00003274
Iteration 99/1000 | Loss: 0.00003274
Iteration 100/1000 | Loss: 0.00003274
Iteration 101/1000 | Loss: 0.00003274
Iteration 102/1000 | Loss: 0.00003274
Iteration 103/1000 | Loss: 0.00003274
Iteration 104/1000 | Loss: 0.00003273
Iteration 105/1000 | Loss: 0.00003273
Iteration 106/1000 | Loss: 0.00003273
Iteration 107/1000 | Loss: 0.00003273
Iteration 108/1000 | Loss: 0.00003273
Iteration 109/1000 | Loss: 0.00003272
Iteration 110/1000 | Loss: 0.00003272
Iteration 111/1000 | Loss: 0.00003272
Iteration 112/1000 | Loss: 0.00003272
Iteration 113/1000 | Loss: 0.00003272
Iteration 114/1000 | Loss: 0.00003272
Iteration 115/1000 | Loss: 0.00003272
Iteration 116/1000 | Loss: 0.00003272
Iteration 117/1000 | Loss: 0.00003271
Iteration 118/1000 | Loss: 0.00003271
Iteration 119/1000 | Loss: 0.00003271
Iteration 120/1000 | Loss: 0.00003271
Iteration 121/1000 | Loss: 0.00003271
Iteration 122/1000 | Loss: 0.00003270
Iteration 123/1000 | Loss: 0.00003270
Iteration 124/1000 | Loss: 0.00003270
Iteration 125/1000 | Loss: 0.00003270
Iteration 126/1000 | Loss: 0.00003270
Iteration 127/1000 | Loss: 0.00003270
Iteration 128/1000 | Loss: 0.00003270
Iteration 129/1000 | Loss: 0.00003270
Iteration 130/1000 | Loss: 0.00003270
Iteration 131/1000 | Loss: 0.00003270
Iteration 132/1000 | Loss: 0.00003269
Iteration 133/1000 | Loss: 0.00003269
Iteration 134/1000 | Loss: 0.00003269
Iteration 135/1000 | Loss: 0.00003269
Iteration 136/1000 | Loss: 0.00003269
Iteration 137/1000 | Loss: 0.00003269
Iteration 138/1000 | Loss: 0.00003269
Iteration 139/1000 | Loss: 0.00003269
Iteration 140/1000 | Loss: 0.00003269
Iteration 141/1000 | Loss: 0.00003269
Iteration 142/1000 | Loss: 0.00003269
Iteration 143/1000 | Loss: 0.00003269
Iteration 144/1000 | Loss: 0.00003269
Iteration 145/1000 | Loss: 0.00003269
Iteration 146/1000 | Loss: 0.00003269
Iteration 147/1000 | Loss: 0.00003269
Iteration 148/1000 | Loss: 0.00003269
Iteration 149/1000 | Loss: 0.00003269
Iteration 150/1000 | Loss: 0.00003269
Iteration 151/1000 | Loss: 0.00003268
Iteration 152/1000 | Loss: 0.00003268
Iteration 153/1000 | Loss: 0.00003268
Iteration 154/1000 | Loss: 0.00003268
Iteration 155/1000 | Loss: 0.00003268
Iteration 156/1000 | Loss: 0.00003268
Iteration 157/1000 | Loss: 0.00003268
Iteration 158/1000 | Loss: 0.00003268
Iteration 159/1000 | Loss: 0.00003268
Iteration 160/1000 | Loss: 0.00003268
Iteration 161/1000 | Loss: 0.00003268
Iteration 162/1000 | Loss: 0.00003268
Iteration 163/1000 | Loss: 0.00003268
Iteration 164/1000 | Loss: 0.00003268
Iteration 165/1000 | Loss: 0.00003268
Iteration 166/1000 | Loss: 0.00003268
Iteration 167/1000 | Loss: 0.00003268
Iteration 168/1000 | Loss: 0.00003268
Iteration 169/1000 | Loss: 0.00003268
Iteration 170/1000 | Loss: 0.00003268
Iteration 171/1000 | Loss: 0.00003268
Iteration 172/1000 | Loss: 0.00003268
Iteration 173/1000 | Loss: 0.00003268
Iteration 174/1000 | Loss: 0.00003268
Iteration 175/1000 | Loss: 0.00003268
Iteration 176/1000 | Loss: 0.00003268
Iteration 177/1000 | Loss: 0.00003268
Iteration 178/1000 | Loss: 0.00003268
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [3.26849112752825e-05, 3.26849112752825e-05, 3.26849112752825e-05, 3.26849112752825e-05, 3.26849112752825e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.26849112752825e-05

Optimization complete. Final v2v error: 4.8575849533081055 mm

Highest mean error: 5.289959907531738 mm for frame 144

Lowest mean error: 4.433008193969727 mm for frame 204

Saving results

Total time: 2323.7605786323547
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1039
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00598273
Iteration 2/25 | Loss: 0.00134563
Iteration 3/25 | Loss: 0.00127994
Iteration 4/25 | Loss: 0.00126861
Iteration 5/25 | Loss: 0.00126468
Iteration 6/25 | Loss: 0.00126407
Iteration 7/25 | Loss: 0.00126407
Iteration 8/25 | Loss: 0.00126407
Iteration 9/25 | Loss: 0.00126407
Iteration 10/25 | Loss: 0.00126407
Iteration 11/25 | Loss: 0.00126407
Iteration 12/25 | Loss: 0.00126407
Iteration 13/25 | Loss: 0.00126407
Iteration 14/25 | Loss: 0.00126407
Iteration 15/25 | Loss: 0.00126407
Iteration 16/25 | Loss: 0.00126407
Iteration 17/25 | Loss: 0.00126407
Iteration 18/25 | Loss: 0.00126407
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0012640691129490733, 0.0012640691129490733, 0.0012640691129490733, 0.0012640691129490733, 0.0012640691129490733]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012640691129490733

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.13338685
Iteration 2/25 | Loss: 0.00090234
Iteration 3/25 | Loss: 0.00090234
Iteration 4/25 | Loss: 0.00090234
Iteration 5/25 | Loss: 0.00090234
Iteration 6/25 | Loss: 0.00090234
Iteration 7/25 | Loss: 0.00090234
Iteration 8/25 | Loss: 0.00090234
Iteration 9/25 | Loss: 0.00090234
Iteration 10/25 | Loss: 0.00090234
Iteration 11/25 | Loss: 0.00090234
Iteration 12/25 | Loss: 0.00090234
Iteration 13/25 | Loss: 0.00090234
Iteration 14/25 | Loss: 0.00090234
Iteration 15/25 | Loss: 0.00090234
Iteration 16/25 | Loss: 0.00090234
Iteration 17/25 | Loss: 0.00090234
Iteration 18/25 | Loss: 0.00090234
Iteration 19/25 | Loss: 0.00090234
Iteration 20/25 | Loss: 0.00090234
Iteration 21/25 | Loss: 0.00090234
Iteration 22/25 | Loss: 0.00090234
Iteration 23/25 | Loss: 0.00090234
Iteration 24/25 | Loss: 0.00090234
Iteration 25/25 | Loss: 0.00090234

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00090234
Iteration 2/1000 | Loss: 0.00002858
Iteration 3/1000 | Loss: 0.00001942
Iteration 4/1000 | Loss: 0.00001688
Iteration 5/1000 | Loss: 0.00001565
Iteration 6/1000 | Loss: 0.00001499
Iteration 7/1000 | Loss: 0.00001445
Iteration 8/1000 | Loss: 0.00001406
Iteration 9/1000 | Loss: 0.00001389
Iteration 10/1000 | Loss: 0.00001383
Iteration 11/1000 | Loss: 0.00001364
Iteration 12/1000 | Loss: 0.00001356
Iteration 13/1000 | Loss: 0.00001339
Iteration 14/1000 | Loss: 0.00001339
Iteration 15/1000 | Loss: 0.00001338
Iteration 16/1000 | Loss: 0.00001334
Iteration 17/1000 | Loss: 0.00001329
Iteration 18/1000 | Loss: 0.00001326
Iteration 19/1000 | Loss: 0.00001324
Iteration 20/1000 | Loss: 0.00001323
Iteration 21/1000 | Loss: 0.00001315
Iteration 22/1000 | Loss: 0.00001313
Iteration 23/1000 | Loss: 0.00001309
Iteration 24/1000 | Loss: 0.00001308
Iteration 25/1000 | Loss: 0.00001308
Iteration 26/1000 | Loss: 0.00001306
Iteration 27/1000 | Loss: 0.00001301
Iteration 28/1000 | Loss: 0.00001298
Iteration 29/1000 | Loss: 0.00001298
Iteration 30/1000 | Loss: 0.00001297
Iteration 31/1000 | Loss: 0.00001293
Iteration 32/1000 | Loss: 0.00001293
Iteration 33/1000 | Loss: 0.00001292
Iteration 34/1000 | Loss: 0.00001291
Iteration 35/1000 | Loss: 0.00001290
Iteration 36/1000 | Loss: 0.00001289
Iteration 37/1000 | Loss: 0.00001289
Iteration 38/1000 | Loss: 0.00001289
Iteration 39/1000 | Loss: 0.00001288
Iteration 40/1000 | Loss: 0.00001288
Iteration 41/1000 | Loss: 0.00001288
Iteration 42/1000 | Loss: 0.00001287
Iteration 43/1000 | Loss: 0.00001286
Iteration 44/1000 | Loss: 0.00001286
Iteration 45/1000 | Loss: 0.00001285
Iteration 46/1000 | Loss: 0.00001285
Iteration 47/1000 | Loss: 0.00001284
Iteration 48/1000 | Loss: 0.00001284
Iteration 49/1000 | Loss: 0.00001283
Iteration 50/1000 | Loss: 0.00001283
Iteration 51/1000 | Loss: 0.00001282
Iteration 52/1000 | Loss: 0.00001282
Iteration 53/1000 | Loss: 0.00001281
Iteration 54/1000 | Loss: 0.00001281
Iteration 55/1000 | Loss: 0.00001281
Iteration 56/1000 | Loss: 0.00001281
Iteration 57/1000 | Loss: 0.00001280
Iteration 58/1000 | Loss: 0.00001280
Iteration 59/1000 | Loss: 0.00001280
Iteration 60/1000 | Loss: 0.00001279
Iteration 61/1000 | Loss: 0.00001278
Iteration 62/1000 | Loss: 0.00001278
Iteration 63/1000 | Loss: 0.00001277
Iteration 64/1000 | Loss: 0.00001277
Iteration 65/1000 | Loss: 0.00001276
Iteration 66/1000 | Loss: 0.00001275
Iteration 67/1000 | Loss: 0.00001275
Iteration 68/1000 | Loss: 0.00001275
Iteration 69/1000 | Loss: 0.00001275
Iteration 70/1000 | Loss: 0.00001274
Iteration 71/1000 | Loss: 0.00001273
Iteration 72/1000 | Loss: 0.00001270
Iteration 73/1000 | Loss: 0.00001270
Iteration 74/1000 | Loss: 0.00001270
Iteration 75/1000 | Loss: 0.00001270
Iteration 76/1000 | Loss: 0.00001270
Iteration 77/1000 | Loss: 0.00001270
Iteration 78/1000 | Loss: 0.00001270
Iteration 79/1000 | Loss: 0.00001270
Iteration 80/1000 | Loss: 0.00001269
Iteration 81/1000 | Loss: 0.00001269
Iteration 82/1000 | Loss: 0.00001268
Iteration 83/1000 | Loss: 0.00001268
Iteration 84/1000 | Loss: 0.00001267
Iteration 85/1000 | Loss: 0.00001267
Iteration 86/1000 | Loss: 0.00001267
Iteration 87/1000 | Loss: 0.00001266
Iteration 88/1000 | Loss: 0.00001266
Iteration 89/1000 | Loss: 0.00001266
Iteration 90/1000 | Loss: 0.00001266
Iteration 91/1000 | Loss: 0.00001265
Iteration 92/1000 | Loss: 0.00001265
Iteration 93/1000 | Loss: 0.00001265
Iteration 94/1000 | Loss: 0.00001265
Iteration 95/1000 | Loss: 0.00001265
Iteration 96/1000 | Loss: 0.00001264
Iteration 97/1000 | Loss: 0.00001264
Iteration 98/1000 | Loss: 0.00001264
Iteration 99/1000 | Loss: 0.00001264
Iteration 100/1000 | Loss: 0.00001264
Iteration 101/1000 | Loss: 0.00001264
Iteration 102/1000 | Loss: 0.00001264
Iteration 103/1000 | Loss: 0.00001263
Iteration 104/1000 | Loss: 0.00001263
Iteration 105/1000 | Loss: 0.00001263
Iteration 106/1000 | Loss: 0.00001263
Iteration 107/1000 | Loss: 0.00001263
Iteration 108/1000 | Loss: 0.00001263
Iteration 109/1000 | Loss: 0.00001262
Iteration 110/1000 | Loss: 0.00001262
Iteration 111/1000 | Loss: 0.00001262
Iteration 112/1000 | Loss: 0.00001262
Iteration 113/1000 | Loss: 0.00001262
Iteration 114/1000 | Loss: 0.00001262
Iteration 115/1000 | Loss: 0.00001262
Iteration 116/1000 | Loss: 0.00001262
Iteration 117/1000 | Loss: 0.00001262
Iteration 118/1000 | Loss: 0.00001261
Iteration 119/1000 | Loss: 0.00001261
Iteration 120/1000 | Loss: 0.00001261
Iteration 121/1000 | Loss: 0.00001261
Iteration 122/1000 | Loss: 0.00001261
Iteration 123/1000 | Loss: 0.00001261
Iteration 124/1000 | Loss: 0.00001261
Iteration 125/1000 | Loss: 0.00001261
Iteration 126/1000 | Loss: 0.00001261
Iteration 127/1000 | Loss: 0.00001261
Iteration 128/1000 | Loss: 0.00001261
Iteration 129/1000 | Loss: 0.00001261
Iteration 130/1000 | Loss: 0.00001260
Iteration 131/1000 | Loss: 0.00001260
Iteration 132/1000 | Loss: 0.00001260
Iteration 133/1000 | Loss: 0.00001260
Iteration 134/1000 | Loss: 0.00001260
Iteration 135/1000 | Loss: 0.00001260
Iteration 136/1000 | Loss: 0.00001260
Iteration 137/1000 | Loss: 0.00001260
Iteration 138/1000 | Loss: 0.00001260
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [1.2597414752235636e-05, 1.2597414752235636e-05, 1.2597414752235636e-05, 1.2597414752235636e-05, 1.2597414752235636e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2597414752235636e-05

Optimization complete. Final v2v error: 3.0355212688446045 mm

Highest mean error: 3.3446590900421143 mm for frame 60

Lowest mean error: 2.8636984825134277 mm for frame 118

Saving results

Total time: 746.6051774024963
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1056
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00934159
Iteration 2/25 | Loss: 0.00231888
Iteration 3/25 | Loss: 0.00181498
Iteration 4/25 | Loss: 0.00177038
Iteration 5/25 | Loss: 0.00162501
Iteration 6/25 | Loss: 0.00158089
Iteration 7/25 | Loss: 0.00159009
Iteration 8/25 | Loss: 0.00146464
Iteration 9/25 | Loss: 0.00142293
Iteration 10/25 | Loss: 0.00140569
Iteration 11/25 | Loss: 0.00141023
Iteration 12/25 | Loss: 0.00142847
Iteration 13/25 | Loss: 0.00142552
Iteration 14/25 | Loss: 0.00142165
Iteration 15/25 | Loss: 0.00142289
Iteration 16/25 | Loss: 0.00142336
Iteration 17/25 | Loss: 0.00141683
Iteration 18/25 | Loss: 0.00142821
Iteration 19/25 | Loss: 0.00141662
Iteration 20/25 | Loss: 0.00139403
Iteration 21/25 | Loss: 0.00138858
Iteration 22/25 | Loss: 0.00139404
Iteration 23/25 | Loss: 0.00138466
Iteration 24/25 | Loss: 0.00137498
Iteration 25/25 | Loss: 0.00137297

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.38350534
Iteration 2/25 | Loss: 0.00104298
Iteration 3/25 | Loss: 0.00104298
Iteration 4/25 | Loss: 0.00104298
Iteration 5/25 | Loss: 0.00104298
Iteration 6/25 | Loss: 0.00104298
Iteration 7/25 | Loss: 0.00104298
Iteration 8/25 | Loss: 0.00104298
Iteration 9/25 | Loss: 0.00104298
Iteration 10/25 | Loss: 0.00104298
Iteration 11/25 | Loss: 0.00104298
Iteration 12/25 | Loss: 0.00104298
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010429775575175881, 0.0010429775575175881, 0.0010429775575175881, 0.0010429775575175881, 0.0010429775575175881]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010429775575175881

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00104298
Iteration 2/1000 | Loss: 0.00009497
Iteration 3/1000 | Loss: 0.00010093
Iteration 4/1000 | Loss: 0.00008036
Iteration 5/1000 | Loss: 0.00006756
Iteration 6/1000 | Loss: 0.00007233
Iteration 7/1000 | Loss: 0.00006335
Iteration 8/1000 | Loss: 0.00005899
Iteration 9/1000 | Loss: 0.00005409
Iteration 10/1000 | Loss: 0.00007001
Iteration 11/1000 | Loss: 0.00005984
Iteration 12/1000 | Loss: 0.00007142
Iteration 13/1000 | Loss: 0.00004690
Iteration 14/1000 | Loss: 0.00007079
Iteration 15/1000 | Loss: 0.00008086
Iteration 16/1000 | Loss: 0.00005986
Iteration 17/1000 | Loss: 0.00007208
Iteration 18/1000 | Loss: 0.00008679
Iteration 19/1000 | Loss: 0.00005516
Iteration 20/1000 | Loss: 0.00006750
Iteration 21/1000 | Loss: 0.00006304
Iteration 22/1000 | Loss: 0.00005258
Iteration 23/1000 | Loss: 0.00005182
Iteration 24/1000 | Loss: 0.00006445
Iteration 25/1000 | Loss: 0.00006308
Iteration 26/1000 | Loss: 0.00006546
Iteration 27/1000 | Loss: 0.00006193
Iteration 28/1000 | Loss: 0.00007717
Iteration 29/1000 | Loss: 0.00007148
Iteration 30/1000 | Loss: 0.00007270
Iteration 31/1000 | Loss: 0.00007890
Iteration 32/1000 | Loss: 0.00006423
Iteration 33/1000 | Loss: 0.00007411
Iteration 34/1000 | Loss: 0.00006595
Iteration 35/1000 | Loss: 0.00006339
Iteration 36/1000 | Loss: 0.00006608
Iteration 37/1000 | Loss: 0.00008173
Iteration 38/1000 | Loss: 0.00008249
Iteration 39/1000 | Loss: 0.00008009
Iteration 40/1000 | Loss: 0.00025877
Iteration 41/1000 | Loss: 0.00008072
Iteration 42/1000 | Loss: 0.00007282
Iteration 43/1000 | Loss: 0.00007510
Iteration 44/1000 | Loss: 0.00006953
Iteration 45/1000 | Loss: 0.00006420
Iteration 46/1000 | Loss: 0.00005898
Iteration 47/1000 | Loss: 0.00006653
Iteration 48/1000 | Loss: 0.00006290
Iteration 49/1000 | Loss: 0.00006861
Iteration 50/1000 | Loss: 0.00006148
Iteration 51/1000 | Loss: 0.00006475
Iteration 52/1000 | Loss: 0.00006775
Iteration 53/1000 | Loss: 0.00007239
Iteration 54/1000 | Loss: 0.00007792
Iteration 55/1000 | Loss: 0.00004662
Iteration 56/1000 | Loss: 0.00005153
Iteration 57/1000 | Loss: 0.00007157
Iteration 58/1000 | Loss: 0.00006991
Iteration 59/1000 | Loss: 0.00005284
Iteration 60/1000 | Loss: 0.00005402
Iteration 61/1000 | Loss: 0.00004400
Iteration 62/1000 | Loss: 0.00005390
Iteration 63/1000 | Loss: 0.00004754
Iteration 64/1000 | Loss: 0.00003736
Iteration 65/1000 | Loss: 0.00003340
Iteration 66/1000 | Loss: 0.00004563
Iteration 67/1000 | Loss: 0.00003861
Iteration 68/1000 | Loss: 0.00003518
Iteration 69/1000 | Loss: 0.00003165
Iteration 70/1000 | Loss: 0.00003007
Iteration 71/1000 | Loss: 0.00002922
Iteration 72/1000 | Loss: 0.00002882
Iteration 73/1000 | Loss: 0.00002857
Iteration 74/1000 | Loss: 0.00002831
Iteration 75/1000 | Loss: 0.00002805
Iteration 76/1000 | Loss: 0.00002797
Iteration 77/1000 | Loss: 0.00002786
Iteration 78/1000 | Loss: 0.00002783
Iteration 79/1000 | Loss: 0.00002783
Iteration 80/1000 | Loss: 0.00002783
Iteration 81/1000 | Loss: 0.00002782
Iteration 82/1000 | Loss: 0.00002780
Iteration 83/1000 | Loss: 0.00002768
Iteration 84/1000 | Loss: 0.00002765
Iteration 85/1000 | Loss: 0.00002765
Iteration 86/1000 | Loss: 0.00002763
Iteration 87/1000 | Loss: 0.00002762
Iteration 88/1000 | Loss: 0.00002761
Iteration 89/1000 | Loss: 0.00002759
Iteration 90/1000 | Loss: 0.00002758
Iteration 91/1000 | Loss: 0.00002758
Iteration 92/1000 | Loss: 0.00002757
Iteration 93/1000 | Loss: 0.00002756
Iteration 94/1000 | Loss: 0.00002754
Iteration 95/1000 | Loss: 0.00002753
Iteration 96/1000 | Loss: 0.00002753
Iteration 97/1000 | Loss: 0.00002752
Iteration 98/1000 | Loss: 0.00002752
Iteration 99/1000 | Loss: 0.00002751
Iteration 100/1000 | Loss: 0.00002751
Iteration 101/1000 | Loss: 0.00002751
Iteration 102/1000 | Loss: 0.00002750
Iteration 103/1000 | Loss: 0.00002748
Iteration 104/1000 | Loss: 0.00002747
Iteration 105/1000 | Loss: 0.00002746
Iteration 106/1000 | Loss: 0.00002745
Iteration 107/1000 | Loss: 0.00002745
Iteration 108/1000 | Loss: 0.00002745
Iteration 109/1000 | Loss: 0.00002745
Iteration 110/1000 | Loss: 0.00002744
Iteration 111/1000 | Loss: 0.00002744
Iteration 112/1000 | Loss: 0.00002743
Iteration 113/1000 | Loss: 0.00002743
Iteration 114/1000 | Loss: 0.00002742
Iteration 115/1000 | Loss: 0.00002742
Iteration 116/1000 | Loss: 0.00002742
Iteration 117/1000 | Loss: 0.00002741
Iteration 118/1000 | Loss: 0.00002741
Iteration 119/1000 | Loss: 0.00002741
Iteration 120/1000 | Loss: 0.00002740
Iteration 121/1000 | Loss: 0.00002740
Iteration 122/1000 | Loss: 0.00002740
Iteration 123/1000 | Loss: 0.00003579
Iteration 124/1000 | Loss: 0.00002738
Iteration 125/1000 | Loss: 0.00002733
Iteration 126/1000 | Loss: 0.00002732
Iteration 127/1000 | Loss: 0.00002732
Iteration 128/1000 | Loss: 0.00002732
Iteration 129/1000 | Loss: 0.00002732
Iteration 130/1000 | Loss: 0.00002732
Iteration 131/1000 | Loss: 0.00002732
Iteration 132/1000 | Loss: 0.00002732
Iteration 133/1000 | Loss: 0.00002732
Iteration 134/1000 | Loss: 0.00002731
Iteration 135/1000 | Loss: 0.00002731
Iteration 136/1000 | Loss: 0.00002730
Iteration 137/1000 | Loss: 0.00002730
Iteration 138/1000 | Loss: 0.00002730
Iteration 139/1000 | Loss: 0.00002730
Iteration 140/1000 | Loss: 0.00002730
Iteration 141/1000 | Loss: 0.00002730
Iteration 142/1000 | Loss: 0.00002730
Iteration 143/1000 | Loss: 0.00002729
Iteration 144/1000 | Loss: 0.00002729
Iteration 145/1000 | Loss: 0.00002729
Iteration 146/1000 | Loss: 0.00002729
Iteration 147/1000 | Loss: 0.00002729
Iteration 148/1000 | Loss: 0.00002729
Iteration 149/1000 | Loss: 0.00002729
Iteration 150/1000 | Loss: 0.00002729
Iteration 151/1000 | Loss: 0.00002729
Iteration 152/1000 | Loss: 0.00002729
Iteration 153/1000 | Loss: 0.00002728
Iteration 154/1000 | Loss: 0.00002728
Iteration 155/1000 | Loss: 0.00002728
Iteration 156/1000 | Loss: 0.00002728
Iteration 157/1000 | Loss: 0.00002728
Iteration 158/1000 | Loss: 0.00002727
Iteration 159/1000 | Loss: 0.00002727
Iteration 160/1000 | Loss: 0.00002726
Iteration 161/1000 | Loss: 0.00002725
Iteration 162/1000 | Loss: 0.00002725
Iteration 163/1000 | Loss: 0.00002724
Iteration 164/1000 | Loss: 0.00002724
Iteration 165/1000 | Loss: 0.00002724
Iteration 166/1000 | Loss: 0.00002723
Iteration 167/1000 | Loss: 0.00002723
Iteration 168/1000 | Loss: 0.00002722
Iteration 169/1000 | Loss: 0.00002721
Iteration 170/1000 | Loss: 0.00002721
Iteration 171/1000 | Loss: 0.00002721
Iteration 172/1000 | Loss: 0.00002720
Iteration 173/1000 | Loss: 0.00002720
Iteration 174/1000 | Loss: 0.00002720
Iteration 175/1000 | Loss: 0.00002719
Iteration 176/1000 | Loss: 0.00002719
Iteration 177/1000 | Loss: 0.00002719
Iteration 178/1000 | Loss: 0.00002719
Iteration 179/1000 | Loss: 0.00002718
Iteration 180/1000 | Loss: 0.00002718
Iteration 181/1000 | Loss: 0.00002718
Iteration 182/1000 | Loss: 0.00002718
Iteration 183/1000 | Loss: 0.00002718
Iteration 184/1000 | Loss: 0.00002718
Iteration 185/1000 | Loss: 0.00002717
Iteration 186/1000 | Loss: 0.00002717
Iteration 187/1000 | Loss: 0.00002717
Iteration 188/1000 | Loss: 0.00002717
Iteration 189/1000 | Loss: 0.00002717
Iteration 190/1000 | Loss: 0.00002717
Iteration 191/1000 | Loss: 0.00002717
Iteration 192/1000 | Loss: 0.00002717
Iteration 193/1000 | Loss: 0.00002717
Iteration 194/1000 | Loss: 0.00002716
Iteration 195/1000 | Loss: 0.00002716
Iteration 196/1000 | Loss: 0.00002716
Iteration 197/1000 | Loss: 0.00002716
Iteration 198/1000 | Loss: 0.00002716
Iteration 199/1000 | Loss: 0.00002716
Iteration 200/1000 | Loss: 0.00002716
Iteration 201/1000 | Loss: 0.00002716
Iteration 202/1000 | Loss: 0.00002716
Iteration 203/1000 | Loss: 0.00002716
Iteration 204/1000 | Loss: 0.00002716
Iteration 205/1000 | Loss: 0.00002716
Iteration 206/1000 | Loss: 0.00002716
Iteration 207/1000 | Loss: 0.00002716
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [2.715874870773405e-05, 2.715874870773405e-05, 2.715874870773405e-05, 2.715874870773405e-05, 2.715874870773405e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.715874870773405e-05

Optimization complete. Final v2v error: 4.067274570465088 mm

Highest mean error: 10.785322189331055 mm for frame 21

Lowest mean error: 2.855154275894165 mm for frame 13

Saving results

Total time: 2813.6337871551514
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1046
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00422402
Iteration 2/25 | Loss: 0.00145946
Iteration 3/25 | Loss: 0.00133746
Iteration 4/25 | Loss: 0.00131761
Iteration 5/25 | Loss: 0.00131271
Iteration 6/25 | Loss: 0.00131137
Iteration 7/25 | Loss: 0.00131103
Iteration 8/25 | Loss: 0.00131103
Iteration 9/25 | Loss: 0.00131103
Iteration 10/25 | Loss: 0.00131103
Iteration 11/25 | Loss: 0.00131103
Iteration 12/25 | Loss: 0.00131103
Iteration 13/25 | Loss: 0.00131103
Iteration 14/25 | Loss: 0.00131103
Iteration 15/25 | Loss: 0.00131103
Iteration 16/25 | Loss: 0.00131103
Iteration 17/25 | Loss: 0.00131103
Iteration 18/25 | Loss: 0.00131103
Iteration 19/25 | Loss: 0.00131103
Iteration 20/25 | Loss: 0.00131103
Iteration 21/25 | Loss: 0.00131103
Iteration 22/25 | Loss: 0.00131103
Iteration 23/25 | Loss: 0.00131103
Iteration 24/25 | Loss: 0.00131103
Iteration 25/25 | Loss: 0.00131103

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42520106
Iteration 2/25 | Loss: 0.00085108
Iteration 3/25 | Loss: 0.00085108
Iteration 4/25 | Loss: 0.00085108
Iteration 5/25 | Loss: 0.00085108
Iteration 6/25 | Loss: 0.00085108
Iteration 7/25 | Loss: 0.00085108
Iteration 8/25 | Loss: 0.00085108
Iteration 9/25 | Loss: 0.00085108
Iteration 10/25 | Loss: 0.00085108
Iteration 11/25 | Loss: 0.00085107
Iteration 12/25 | Loss: 0.00085107
Iteration 13/25 | Loss: 0.00085107
Iteration 14/25 | Loss: 0.00085107
Iteration 15/25 | Loss: 0.00085107
Iteration 16/25 | Loss: 0.00085107
Iteration 17/25 | Loss: 0.00085107
Iteration 18/25 | Loss: 0.00085107
Iteration 19/25 | Loss: 0.00085107
Iteration 20/25 | Loss: 0.00085107
Iteration 21/25 | Loss: 0.00085107
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0008510745828971267, 0.0008510745828971267, 0.0008510745828971267, 0.0008510745828971267, 0.0008510745828971267]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008510745828971267

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085107
Iteration 2/1000 | Loss: 0.00004382
Iteration 3/1000 | Loss: 0.00002991
Iteration 4/1000 | Loss: 0.00002340
Iteration 5/1000 | Loss: 0.00002141
Iteration 6/1000 | Loss: 0.00002023
Iteration 7/1000 | Loss: 0.00001952
Iteration 8/1000 | Loss: 0.00001906
Iteration 9/1000 | Loss: 0.00001858
Iteration 10/1000 | Loss: 0.00001824
Iteration 11/1000 | Loss: 0.00001800
Iteration 12/1000 | Loss: 0.00001782
Iteration 13/1000 | Loss: 0.00001762
Iteration 14/1000 | Loss: 0.00001752
Iteration 15/1000 | Loss: 0.00001747
Iteration 16/1000 | Loss: 0.00001743
Iteration 17/1000 | Loss: 0.00001739
Iteration 18/1000 | Loss: 0.00001736
Iteration 19/1000 | Loss: 0.00001735
Iteration 20/1000 | Loss: 0.00001734
Iteration 21/1000 | Loss: 0.00001734
Iteration 22/1000 | Loss: 0.00001733
Iteration 23/1000 | Loss: 0.00001732
Iteration 24/1000 | Loss: 0.00001732
Iteration 25/1000 | Loss: 0.00001723
Iteration 26/1000 | Loss: 0.00001720
Iteration 27/1000 | Loss: 0.00001720
Iteration 28/1000 | Loss: 0.00001720
Iteration 29/1000 | Loss: 0.00001719
Iteration 30/1000 | Loss: 0.00001719
Iteration 31/1000 | Loss: 0.00001718
Iteration 32/1000 | Loss: 0.00001718
Iteration 33/1000 | Loss: 0.00001718
Iteration 34/1000 | Loss: 0.00001717
Iteration 35/1000 | Loss: 0.00001717
Iteration 36/1000 | Loss: 0.00001716
Iteration 37/1000 | Loss: 0.00001716
Iteration 38/1000 | Loss: 0.00001715
Iteration 39/1000 | Loss: 0.00001715
Iteration 40/1000 | Loss: 0.00001715
Iteration 41/1000 | Loss: 0.00001714
Iteration 42/1000 | Loss: 0.00001714
Iteration 43/1000 | Loss: 0.00001714
Iteration 44/1000 | Loss: 0.00001713
Iteration 45/1000 | Loss: 0.00001713
Iteration 46/1000 | Loss: 0.00001712
Iteration 47/1000 | Loss: 0.00001712
Iteration 48/1000 | Loss: 0.00001712
Iteration 49/1000 | Loss: 0.00001712
Iteration 50/1000 | Loss: 0.00001712
Iteration 51/1000 | Loss: 0.00001711
Iteration 52/1000 | Loss: 0.00001711
Iteration 53/1000 | Loss: 0.00001711
Iteration 54/1000 | Loss: 0.00001711
Iteration 55/1000 | Loss: 0.00001711
Iteration 56/1000 | Loss: 0.00001711
Iteration 57/1000 | Loss: 0.00001711
Iteration 58/1000 | Loss: 0.00001710
Iteration 59/1000 | Loss: 0.00001710
Iteration 60/1000 | Loss: 0.00001710
Iteration 61/1000 | Loss: 0.00001710
Iteration 62/1000 | Loss: 0.00001710
Iteration 63/1000 | Loss: 0.00001710
Iteration 64/1000 | Loss: 0.00001709
Iteration 65/1000 | Loss: 0.00001709
Iteration 66/1000 | Loss: 0.00001709
Iteration 67/1000 | Loss: 0.00001708
Iteration 68/1000 | Loss: 0.00001708
Iteration 69/1000 | Loss: 0.00001707
Iteration 70/1000 | Loss: 0.00001707
Iteration 71/1000 | Loss: 0.00001707
Iteration 72/1000 | Loss: 0.00001706
Iteration 73/1000 | Loss: 0.00001706
Iteration 74/1000 | Loss: 0.00001705
Iteration 75/1000 | Loss: 0.00001705
Iteration 76/1000 | Loss: 0.00001705
Iteration 77/1000 | Loss: 0.00001704
Iteration 78/1000 | Loss: 0.00001704
Iteration 79/1000 | Loss: 0.00001703
Iteration 80/1000 | Loss: 0.00001703
Iteration 81/1000 | Loss: 0.00001703
Iteration 82/1000 | Loss: 0.00001703
Iteration 83/1000 | Loss: 0.00001702
Iteration 84/1000 | Loss: 0.00001702
Iteration 85/1000 | Loss: 0.00001702
Iteration 86/1000 | Loss: 0.00001701
Iteration 87/1000 | Loss: 0.00001701
Iteration 88/1000 | Loss: 0.00001701
Iteration 89/1000 | Loss: 0.00001700
Iteration 90/1000 | Loss: 0.00001700
Iteration 91/1000 | Loss: 0.00001700
Iteration 92/1000 | Loss: 0.00001700
Iteration 93/1000 | Loss: 0.00001700
Iteration 94/1000 | Loss: 0.00001700
Iteration 95/1000 | Loss: 0.00001699
Iteration 96/1000 | Loss: 0.00001699
Iteration 97/1000 | Loss: 0.00001698
Iteration 98/1000 | Loss: 0.00001698
Iteration 99/1000 | Loss: 0.00001698
Iteration 100/1000 | Loss: 0.00001698
Iteration 101/1000 | Loss: 0.00001698
Iteration 102/1000 | Loss: 0.00001697
Iteration 103/1000 | Loss: 0.00001697
Iteration 104/1000 | Loss: 0.00001697
Iteration 105/1000 | Loss: 0.00001697
Iteration 106/1000 | Loss: 0.00001697
Iteration 107/1000 | Loss: 0.00001696
Iteration 108/1000 | Loss: 0.00001696
Iteration 109/1000 | Loss: 0.00001696
Iteration 110/1000 | Loss: 0.00001696
Iteration 111/1000 | Loss: 0.00001695
Iteration 112/1000 | Loss: 0.00001695
Iteration 113/1000 | Loss: 0.00001695
Iteration 114/1000 | Loss: 0.00001695
Iteration 115/1000 | Loss: 0.00001694
Iteration 116/1000 | Loss: 0.00001694
Iteration 117/1000 | Loss: 0.00001694
Iteration 118/1000 | Loss: 0.00001694
Iteration 119/1000 | Loss: 0.00001693
Iteration 120/1000 | Loss: 0.00001693
Iteration 121/1000 | Loss: 0.00001693
Iteration 122/1000 | Loss: 0.00001693
Iteration 123/1000 | Loss: 0.00001693
Iteration 124/1000 | Loss: 0.00001693
Iteration 125/1000 | Loss: 0.00001693
Iteration 126/1000 | Loss: 0.00001693
Iteration 127/1000 | Loss: 0.00001693
Iteration 128/1000 | Loss: 0.00001692
Iteration 129/1000 | Loss: 0.00001692
Iteration 130/1000 | Loss: 0.00001692
Iteration 131/1000 | Loss: 0.00001692
Iteration 132/1000 | Loss: 0.00001692
Iteration 133/1000 | Loss: 0.00001692
Iteration 134/1000 | Loss: 0.00001692
Iteration 135/1000 | Loss: 0.00001692
Iteration 136/1000 | Loss: 0.00001692
Iteration 137/1000 | Loss: 0.00001691
Iteration 138/1000 | Loss: 0.00001691
Iteration 139/1000 | Loss: 0.00001691
Iteration 140/1000 | Loss: 0.00001691
Iteration 141/1000 | Loss: 0.00001691
Iteration 142/1000 | Loss: 0.00001691
Iteration 143/1000 | Loss: 0.00001691
Iteration 144/1000 | Loss: 0.00001690
Iteration 145/1000 | Loss: 0.00001690
Iteration 146/1000 | Loss: 0.00001690
Iteration 147/1000 | Loss: 0.00001690
Iteration 148/1000 | Loss: 0.00001690
Iteration 149/1000 | Loss: 0.00001690
Iteration 150/1000 | Loss: 0.00001690
Iteration 151/1000 | Loss: 0.00001690
Iteration 152/1000 | Loss: 0.00001690
Iteration 153/1000 | Loss: 0.00001690
Iteration 154/1000 | Loss: 0.00001690
Iteration 155/1000 | Loss: 0.00001689
Iteration 156/1000 | Loss: 0.00001689
Iteration 157/1000 | Loss: 0.00001689
Iteration 158/1000 | Loss: 0.00001689
Iteration 159/1000 | Loss: 0.00001689
Iteration 160/1000 | Loss: 0.00001689
Iteration 161/1000 | Loss: 0.00001689
Iteration 162/1000 | Loss: 0.00001689
Iteration 163/1000 | Loss: 0.00001689
Iteration 164/1000 | Loss: 0.00001689
Iteration 165/1000 | Loss: 0.00001689
Iteration 166/1000 | Loss: 0.00001689
Iteration 167/1000 | Loss: 0.00001688
Iteration 168/1000 | Loss: 0.00001688
Iteration 169/1000 | Loss: 0.00001688
Iteration 170/1000 | Loss: 0.00001688
Iteration 171/1000 | Loss: 0.00001688
Iteration 172/1000 | Loss: 0.00001688
Iteration 173/1000 | Loss: 0.00001688
Iteration 174/1000 | Loss: 0.00001688
Iteration 175/1000 | Loss: 0.00001688
Iteration 176/1000 | Loss: 0.00001688
Iteration 177/1000 | Loss: 0.00001688
Iteration 178/1000 | Loss: 0.00001688
Iteration 179/1000 | Loss: 0.00001687
Iteration 180/1000 | Loss: 0.00001687
Iteration 181/1000 | Loss: 0.00001687
Iteration 182/1000 | Loss: 0.00001687
Iteration 183/1000 | Loss: 0.00001687
Iteration 184/1000 | Loss: 0.00001687
Iteration 185/1000 | Loss: 0.00001687
Iteration 186/1000 | Loss: 0.00001687
Iteration 187/1000 | Loss: 0.00001687
Iteration 188/1000 | Loss: 0.00001687
Iteration 189/1000 | Loss: 0.00001687
Iteration 190/1000 | Loss: 0.00001687
Iteration 191/1000 | Loss: 0.00001687
Iteration 192/1000 | Loss: 0.00001687
Iteration 193/1000 | Loss: 0.00001687
Iteration 194/1000 | Loss: 0.00001687
Iteration 195/1000 | Loss: 0.00001687
Iteration 196/1000 | Loss: 0.00001687
Iteration 197/1000 | Loss: 0.00001687
Iteration 198/1000 | Loss: 0.00001687
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 198. Stopping optimization.
Last 5 losses: [1.6867325030034408e-05, 1.6867325030034408e-05, 1.6867325030034408e-05, 1.6867325030034408e-05, 1.6867325030034408e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6867325030034408e-05

Optimization complete. Final v2v error: 3.4293408393859863 mm

Highest mean error: 4.709519863128662 mm for frame 54

Lowest mean error: 2.881977081298828 mm for frame 114

Saving results

Total time: 765.7208232879639
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1001
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00794139
Iteration 2/25 | Loss: 0.00146997
Iteration 3/25 | Loss: 0.00132459
Iteration 4/25 | Loss: 0.00130912
Iteration 5/25 | Loss: 0.00130505
Iteration 6/25 | Loss: 0.00130434
Iteration 7/25 | Loss: 0.00130434
Iteration 8/25 | Loss: 0.00130434
Iteration 9/25 | Loss: 0.00130434
Iteration 10/25 | Loss: 0.00130434
Iteration 11/25 | Loss: 0.00130434
Iteration 12/25 | Loss: 0.00130434
Iteration 13/25 | Loss: 0.00130434
Iteration 14/25 | Loss: 0.00130434
Iteration 15/25 | Loss: 0.00130434
Iteration 16/25 | Loss: 0.00130434
Iteration 17/25 | Loss: 0.00130434
Iteration 18/25 | Loss: 0.00130434
Iteration 19/25 | Loss: 0.00130434
Iteration 20/25 | Loss: 0.00130434
Iteration 21/25 | Loss: 0.00130434
Iteration 22/25 | Loss: 0.00130434
Iteration 23/25 | Loss: 0.00130434
Iteration 24/25 | Loss: 0.00130434
Iteration 25/25 | Loss: 0.00130434

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31371975
Iteration 2/25 | Loss: 0.00072248
Iteration 3/25 | Loss: 0.00072244
Iteration 4/25 | Loss: 0.00072244
Iteration 5/25 | Loss: 0.00072244
Iteration 6/25 | Loss: 0.00072244
Iteration 7/25 | Loss: 0.00072244
Iteration 8/25 | Loss: 0.00072244
Iteration 9/25 | Loss: 0.00072244
Iteration 10/25 | Loss: 0.00072244
Iteration 11/25 | Loss: 0.00072244
Iteration 12/25 | Loss: 0.00072244
Iteration 13/25 | Loss: 0.00072244
Iteration 14/25 | Loss: 0.00072244
Iteration 15/25 | Loss: 0.00072244
Iteration 16/25 | Loss: 0.00072244
Iteration 17/25 | Loss: 0.00072244
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007224403088912368, 0.0007224403088912368, 0.0007224403088912368, 0.0007224403088912368, 0.0007224403088912368]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007224403088912368

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00072244
Iteration 2/1000 | Loss: 0.00004642
Iteration 3/1000 | Loss: 0.00002956
Iteration 4/1000 | Loss: 0.00002424
Iteration 5/1000 | Loss: 0.00002252
Iteration 6/1000 | Loss: 0.00002147
Iteration 7/1000 | Loss: 0.00002069
Iteration 8/1000 | Loss: 0.00001999
Iteration 9/1000 | Loss: 0.00001952
Iteration 10/1000 | Loss: 0.00001916
Iteration 11/1000 | Loss: 0.00001886
Iteration 12/1000 | Loss: 0.00001853
Iteration 13/1000 | Loss: 0.00001834
Iteration 14/1000 | Loss: 0.00001816
Iteration 15/1000 | Loss: 0.00001808
Iteration 16/1000 | Loss: 0.00001792
Iteration 17/1000 | Loss: 0.00001789
Iteration 18/1000 | Loss: 0.00001785
Iteration 19/1000 | Loss: 0.00001780
Iteration 20/1000 | Loss: 0.00001775
Iteration 21/1000 | Loss: 0.00001775
Iteration 22/1000 | Loss: 0.00001775
Iteration 23/1000 | Loss: 0.00001775
Iteration 24/1000 | Loss: 0.00001775
Iteration 25/1000 | Loss: 0.00001774
Iteration 26/1000 | Loss: 0.00001773
Iteration 27/1000 | Loss: 0.00001773
Iteration 28/1000 | Loss: 0.00001772
Iteration 29/1000 | Loss: 0.00001771
Iteration 30/1000 | Loss: 0.00001771
Iteration 31/1000 | Loss: 0.00001770
Iteration 32/1000 | Loss: 0.00001770
Iteration 33/1000 | Loss: 0.00001770
Iteration 34/1000 | Loss: 0.00001769
Iteration 35/1000 | Loss: 0.00001768
Iteration 36/1000 | Loss: 0.00001768
Iteration 37/1000 | Loss: 0.00001768
Iteration 38/1000 | Loss: 0.00001767
Iteration 39/1000 | Loss: 0.00001767
Iteration 40/1000 | Loss: 0.00001766
Iteration 41/1000 | Loss: 0.00001766
Iteration 42/1000 | Loss: 0.00001765
Iteration 43/1000 | Loss: 0.00001765
Iteration 44/1000 | Loss: 0.00001765
Iteration 45/1000 | Loss: 0.00001764
Iteration 46/1000 | Loss: 0.00001764
Iteration 47/1000 | Loss: 0.00001764
Iteration 48/1000 | Loss: 0.00001763
Iteration 49/1000 | Loss: 0.00001763
Iteration 50/1000 | Loss: 0.00001763
Iteration 51/1000 | Loss: 0.00001763
Iteration 52/1000 | Loss: 0.00001763
Iteration 53/1000 | Loss: 0.00001763
Iteration 54/1000 | Loss: 0.00001763
Iteration 55/1000 | Loss: 0.00001763
Iteration 56/1000 | Loss: 0.00001763
Iteration 57/1000 | Loss: 0.00001763
Iteration 58/1000 | Loss: 0.00001763
Iteration 59/1000 | Loss: 0.00001763
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 59. Stopping optimization.
Last 5 losses: [1.763000909704715e-05, 1.763000909704715e-05, 1.763000909704715e-05, 1.763000909704715e-05, 1.763000909704715e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.763000909704715e-05

Optimization complete. Final v2v error: 3.5182271003723145 mm

Highest mean error: 3.9726877212524414 mm for frame 91

Lowest mean error: 3.154245138168335 mm for frame 171

Saving results

Total time: 852.6437256336212
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_025/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_025/1057
Device is either invalid or not available. Using CPU.
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01022734
Iteration 2/25 | Loss: 0.00321389
Iteration 3/25 | Loss: 0.00251230
Iteration 4/25 | Loss: 0.00225539
Iteration 5/25 | Loss: 0.00218721
Iteration 6/25 | Loss: 0.00216680
Iteration 7/25 | Loss: 0.00213587
Iteration 8/25 | Loss: 0.00209990
Iteration 9/25 | Loss: 0.00205407
Iteration 10/25 | Loss: 0.00204173
Iteration 11/25 | Loss: 0.00204453
Iteration 12/25 | Loss: 0.00202768
Iteration 13/25 | Loss: 0.00202220
Iteration 14/25 | Loss: 0.00201339
Iteration 15/25 | Loss: 0.00201391
Iteration 16/25 | Loss: 0.00201155
Iteration 17/25 | Loss: 0.00201561
Iteration 18/25 | Loss: 0.00198890
Iteration 19/25 | Loss: 0.00197905
Iteration 20/25 | Loss: 0.00197536
Iteration 21/25 | Loss: 0.00197653
Iteration 22/25 | Loss: 0.00196971
Iteration 23/25 | Loss: 0.00196872
Iteration 24/25 | Loss: 0.00196794
Iteration 25/25 | Loss: 0.00197460

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.41948414
Iteration 2/25 | Loss: 0.00807296
Iteration 3/25 | Loss: 0.00807295
Iteration 4/25 | Loss: 0.00807295
Iteration 5/25 | Loss: 0.00807295
Iteration 6/25 | Loss: 0.00807295
Iteration 7/25 | Loss: 0.00807295
Iteration 8/25 | Loss: 0.00807295
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 8. Stopping optimization.
Last 5 losses: [0.008072949014604092, 0.008072949014604092, 0.008072949014604092, 0.008072949014604092, 0.008072949014604092]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.008072949014604092

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00807295
Iteration 2/1000 | Loss: 0.00078790
Iteration 3/1000 | Loss: 0.00051453
Iteration 4/1000 | Loss: 0.00043003
Iteration 5/1000 | Loss: 0.00038961
Iteration 6/1000 | Loss: 0.00033431
Iteration 7/1000 | Loss: 0.00614715
Iteration 8/1000 | Loss: 0.00143315
Iteration 9/1000 | Loss: 0.00091866
Iteration 10/1000 | Loss: 0.00108446
Iteration 11/1000 | Loss: 0.00018574
Iteration 12/1000 | Loss: 0.00013763
Iteration 13/1000 | Loss: 0.00015966
Iteration 14/1000 | Loss: 0.00008184
Iteration 15/1000 | Loss: 0.00079554
Iteration 16/1000 | Loss: 0.00263988
Iteration 17/1000 | Loss: 0.00070479
Iteration 18/1000 | Loss: 0.00004886
Iteration 19/1000 | Loss: 0.00003849
Iteration 20/1000 | Loss: 0.00003341
Iteration 21/1000 | Loss: 0.00002894
Iteration 22/1000 | Loss: 0.00002581
Iteration 23/1000 | Loss: 0.00002389
Iteration 24/1000 | Loss: 0.00002274
Iteration 25/1000 | Loss: 0.00002163
Iteration 26/1000 | Loss: 0.00002086
Iteration 27/1000 | Loss: 0.00002032
Iteration 28/1000 | Loss: 0.00001983
Iteration 29/1000 | Loss: 0.00001945
Iteration 30/1000 | Loss: 0.00001917
Iteration 31/1000 | Loss: 0.00001904
Iteration 32/1000 | Loss: 0.00001885
Iteration 33/1000 | Loss: 0.00001872
Iteration 34/1000 | Loss: 0.00001866
Iteration 35/1000 | Loss: 0.00001865
Iteration 36/1000 | Loss: 0.00001864
Iteration 37/1000 | Loss: 0.00001864
Iteration 38/1000 | Loss: 0.00001862
Iteration 39/1000 | Loss: 0.00001862
Iteration 40/1000 | Loss: 0.00001857
Iteration 41/1000 | Loss: 0.00001855
Iteration 42/1000 | Loss: 0.00001854
Iteration 43/1000 | Loss: 0.00001849
Iteration 44/1000 | Loss: 0.00001841
Iteration 45/1000 | Loss: 0.00001840
Iteration 46/1000 | Loss: 0.00001840
Iteration 47/1000 | Loss: 0.00001840
Iteration 48/1000 | Loss: 0.00001838
Iteration 49/1000 | Loss: 0.00001838
Iteration 50/1000 | Loss: 0.00001838
Iteration 51/1000 | Loss: 0.00001838
Iteration 52/1000 | Loss: 0.00001837
Iteration 53/1000 | Loss: 0.00001837
Iteration 54/1000 | Loss: 0.00001836
Iteration 55/1000 | Loss: 0.00001836
Iteration 56/1000 | Loss: 0.00001836
Iteration 57/1000 | Loss: 0.00001835
Iteration 58/1000 | Loss: 0.00001835
Iteration 59/1000 | Loss: 0.00001835
Iteration 60/1000 | Loss: 0.00001834
Iteration 61/1000 | Loss: 0.00001834
Iteration 62/1000 | Loss: 0.00001834
Iteration 63/1000 | Loss: 0.00001834
Iteration 64/1000 | Loss: 0.00001834
Iteration 65/1000 | Loss: 0.00001833
Iteration 66/1000 | Loss: 0.00001833
Iteration 67/1000 | Loss: 0.00001832
Iteration 68/1000 | Loss: 0.00001832
Iteration 69/1000 | Loss: 0.00001832
Iteration 70/1000 | Loss: 0.00001831
Iteration 71/1000 | Loss: 0.00001831
Iteration 72/1000 | Loss: 0.00001831
Iteration 73/1000 | Loss: 0.00001831
Iteration 74/1000 | Loss: 0.00001830
Iteration 75/1000 | Loss: 0.00001830
Iteration 76/1000 | Loss: 0.00001830
Iteration 77/1000 | Loss: 0.00001830
Iteration 78/1000 | Loss: 0.00001830
Iteration 79/1000 | Loss: 0.00001829
Iteration 80/1000 | Loss: 0.00001829
Iteration 81/1000 | Loss: 0.00001829
Iteration 82/1000 | Loss: 0.00001829
Iteration 83/1000 | Loss: 0.00001829
Iteration 84/1000 | Loss: 0.00001829
Iteration 85/1000 | Loss: 0.00001828
Iteration 86/1000 | Loss: 0.00001828
Iteration 87/1000 | Loss: 0.00001828
Iteration 88/1000 | Loss: 0.00001828
Iteration 89/1000 | Loss: 0.00001828
Iteration 90/1000 | Loss: 0.00001828
Iteration 91/1000 | Loss: 0.00001828
Iteration 92/1000 | Loss: 0.00001827
Iteration 93/1000 | Loss: 0.00001827
Iteration 94/1000 | Loss: 0.00001827
Iteration 95/1000 | Loss: 0.00001827
Iteration 96/1000 | Loss: 0.00001827
Iteration 97/1000 | Loss: 0.00001827
Iteration 98/1000 | Loss: 0.00001827
Iteration 99/1000 | Loss: 0.00001826
Iteration 100/1000 | Loss: 0.00001826
Iteration 101/1000 | Loss: 0.00001826
Iteration 102/1000 | Loss: 0.00001825
Iteration 103/1000 | Loss: 0.00001825
Iteration 104/1000 | Loss: 0.00001825
Iteration 105/1000 | Loss: 0.00001825
Iteration 106/1000 | Loss: 0.00001825
Iteration 107/1000 | Loss: 0.00001825
Iteration 108/1000 | Loss: 0.00001825
Iteration 109/1000 | Loss: 0.00001825
Iteration 110/1000 | Loss: 0.00001825
Iteration 111/1000 | Loss: 0.00001824
Iteration 112/1000 | Loss: 0.00001824
Iteration 113/1000 | Loss: 0.00001824
Iteration 114/1000 | Loss: 0.00001823
Iteration 115/1000 | Loss: 0.00001823
Iteration 116/1000 | Loss: 0.00001823
Iteration 117/1000 | Loss: 0.00001822
Iteration 118/1000 | Loss: 0.00001822
Iteration 119/1000 | Loss: 0.00001822
Iteration 120/1000 | Loss: 0.00001822
Iteration 121/1000 | Loss: 0.00001822
Iteration 122/1000 | Loss: 0.00001821
Iteration 123/1000 | Loss: 0.00001821
Iteration 124/1000 | Loss: 0.00001821
Iteration 125/1000 | Loss: 0.00001821
Iteration 126/1000 | Loss: 0.00001821
Iteration 127/1000 | Loss: 0.00001821
Iteration 128/1000 | Loss: 0.00001821
Iteration 129/1000 | Loss: 0.00001821
Iteration 130/1000 | Loss: 0.00001821
Iteration 131/1000 | Loss: 0.00001821
Iteration 132/1000 | Loss: 0.00001821
Iteration 133/1000 | Loss: 0.00001820
Iteration 134/1000 | Loss: 0.00001820
Iteration 135/1000 | Loss: 0.00001820
Iteration 136/1000 | Loss: 0.00001820
Iteration 137/1000 | Loss: 0.00001820
Iteration 138/1000 | Loss: 0.00001820
Iteration 139/1000 | Loss: 0.00001820
Iteration 140/1000 | Loss: 0.00001820
Iteration 141/1000 | Loss: 0.00001820
Iteration 142/1000 | Loss: 0.00001820
Iteration 143/1000 | Loss: 0.00001820
Iteration 144/1000 | Loss: 0.00001820
Iteration 145/1000 | Loss: 0.00001819
Iteration 146/1000 | Loss: 0.00001819
Iteration 147/1000 | Loss: 0.00001819
Iteration 148/1000 | Loss: 0.00001819
Iteration 149/1000 | Loss: 0.00001819
Iteration 150/1000 | Loss: 0.00001819
Iteration 151/1000 | Loss: 0.00001819
Iteration 152/1000 | Loss: 0.00001818
Iteration 153/1000 | Loss: 0.00001818
Iteration 154/1000 | Loss: 0.00001818
Iteration 155/1000 | Loss: 0.00001818
Iteration 156/1000 | Loss: 0.00001818
Iteration 157/1000 | Loss: 0.00001818
Iteration 158/1000 | Loss: 0.00001818
Iteration 159/1000 | Loss: 0.00001818
Iteration 160/1000 | Loss: 0.00001818
Iteration 161/1000 | Loss: 0.00001818
Iteration 162/1000 | Loss: 0.00001818
Iteration 163/1000 | Loss: 0.00001818
Iteration 164/1000 | Loss: 0.00001818
Iteration 165/1000 | Loss: 0.00001818
Iteration 166/1000 | Loss: 0.00001817
Iteration 167/1000 | Loss: 0.00001817
Iteration 168/1000 | Loss: 0.00001817
Iteration 169/1000 | Loss: 0.00001817
Iteration 170/1000 | Loss: 0.00001817
Iteration 171/1000 | Loss: 0.00001817
Iteration 172/1000 | Loss: 0.00001817
Iteration 173/1000 | Loss: 0.00001816
Iteration 174/1000 | Loss: 0.00001816
Iteration 175/1000 | Loss: 0.00001816
Iteration 176/1000 | Loss: 0.00001816
Iteration 177/1000 | Loss: 0.00001816
Iteration 178/1000 | Loss: 0.00001816
Iteration 179/1000 | Loss: 0.00001816
Iteration 180/1000 | Loss: 0.00001816
Iteration 181/1000 | Loss: 0.00001816
Iteration 182/1000 | Loss: 0.00001816
Iteration 183/1000 | Loss: 0.00001816
Iteration 184/1000 | Loss: 0.00001816
Iteration 185/1000 | Loss: 0.00001816
Iteration 186/1000 | Loss: 0.00001816
Iteration 187/1000 | Loss: 0.00001815
Iteration 188/1000 | Loss: 0.00001815
Iteration 189/1000 | Loss: 0.00001815
Iteration 190/1000 | Loss: 0.00001815
Iteration 191/1000 | Loss: 0.00001815
Iteration 192/1000 | Loss: 0.00001815
Iteration 193/1000 | Loss: 0.00001815
Iteration 194/1000 | Loss: 0.00001815
Iteration 195/1000 | Loss: 0.00001815
Iteration 196/1000 | Loss: 0.00001815
Iteration 197/1000 | Loss: 0.00001815
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [1.8150636606151238e-05, 1.8150636606151238e-05, 1.8150636606151238e-05, 1.8150636606151238e-05, 1.8150636606151238e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8150636606151238e-05

Optimization complete. Final v2v error: 3.5792365074157715 mm

Highest mean error: 4.1057209968566895 mm for frame 50

Lowest mean error: 3.1985340118408203 mm for frame 4

Saving results

Total time: 2980.7596168518066

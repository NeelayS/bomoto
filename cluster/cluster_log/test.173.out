Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=173, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 9688-9743
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00385542
Iteration 2/25 | Loss: 0.00105772
Iteration 3/25 | Loss: 0.00096073
Iteration 4/25 | Loss: 0.00092672
Iteration 5/25 | Loss: 0.00091751
Iteration 6/25 | Loss: 0.00091551
Iteration 7/25 | Loss: 0.00091477
Iteration 8/25 | Loss: 0.00091477
Iteration 9/25 | Loss: 0.00091477
Iteration 10/25 | Loss: 0.00091477
Iteration 11/25 | Loss: 0.00091477
Iteration 12/25 | Loss: 0.00091477
Iteration 13/25 | Loss: 0.00091477
Iteration 14/25 | Loss: 0.00091477
Iteration 15/25 | Loss: 0.00091477
Iteration 16/25 | Loss: 0.00091477
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0009147708769887686, 0.0009147708769887686, 0.0009147708769887686, 0.0009147708769887686, 0.0009147708769887686]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009147708769887686

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51926422
Iteration 2/25 | Loss: 0.00089319
Iteration 3/25 | Loss: 0.00089319
Iteration 4/25 | Loss: 0.00089319
Iteration 5/25 | Loss: 0.00089319
Iteration 6/25 | Loss: 0.00089319
Iteration 7/25 | Loss: 0.00089319
Iteration 8/25 | Loss: 0.00089319
Iteration 9/25 | Loss: 0.00089319
Iteration 10/25 | Loss: 0.00089319
Iteration 11/25 | Loss: 0.00089318
Iteration 12/25 | Loss: 0.00089318
Iteration 13/25 | Loss: 0.00089318
Iteration 14/25 | Loss: 0.00089318
Iteration 15/25 | Loss: 0.00089318
Iteration 16/25 | Loss: 0.00089318
Iteration 17/25 | Loss: 0.00089318
Iteration 18/25 | Loss: 0.00089318
Iteration 19/25 | Loss: 0.00089318
Iteration 20/25 | Loss: 0.00089318
Iteration 21/25 | Loss: 0.00089318
Iteration 22/25 | Loss: 0.00089318
Iteration 23/25 | Loss: 0.00089318
Iteration 24/25 | Loss: 0.00089318
Iteration 25/25 | Loss: 0.00089318

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00089318
Iteration 2/1000 | Loss: 0.00002930
Iteration 3/1000 | Loss: 0.00002235
Iteration 4/1000 | Loss: 0.00002077
Iteration 5/1000 | Loss: 0.00001965
Iteration 6/1000 | Loss: 0.00001927
Iteration 7/1000 | Loss: 0.00001893
Iteration 8/1000 | Loss: 0.00001877
Iteration 9/1000 | Loss: 0.00001872
Iteration 10/1000 | Loss: 0.00001871
Iteration 11/1000 | Loss: 0.00001870
Iteration 12/1000 | Loss: 0.00001869
Iteration 13/1000 | Loss: 0.00001866
Iteration 14/1000 | Loss: 0.00001865
Iteration 15/1000 | Loss: 0.00001851
Iteration 16/1000 | Loss: 0.00001847
Iteration 17/1000 | Loss: 0.00001844
Iteration 18/1000 | Loss: 0.00001844
Iteration 19/1000 | Loss: 0.00001843
Iteration 20/1000 | Loss: 0.00001843
Iteration 21/1000 | Loss: 0.00001842
Iteration 22/1000 | Loss: 0.00001842
Iteration 23/1000 | Loss: 0.00001842
Iteration 24/1000 | Loss: 0.00001841
Iteration 25/1000 | Loss: 0.00001841
Iteration 26/1000 | Loss: 0.00001841
Iteration 27/1000 | Loss: 0.00001841
Iteration 28/1000 | Loss: 0.00001841
Iteration 29/1000 | Loss: 0.00001841
Iteration 30/1000 | Loss: 0.00001841
Iteration 31/1000 | Loss: 0.00001841
Iteration 32/1000 | Loss: 0.00001841
Iteration 33/1000 | Loss: 0.00001841
Iteration 34/1000 | Loss: 0.00001840
Iteration 35/1000 | Loss: 0.00001840
Iteration 36/1000 | Loss: 0.00001840
Iteration 37/1000 | Loss: 0.00001840
Iteration 38/1000 | Loss: 0.00001840
Iteration 39/1000 | Loss: 0.00001840
Iteration 40/1000 | Loss: 0.00001840
Iteration 41/1000 | Loss: 0.00001840
Iteration 42/1000 | Loss: 0.00001840
Iteration 43/1000 | Loss: 0.00001839
Iteration 44/1000 | Loss: 0.00001839
Iteration 45/1000 | Loss: 0.00001839
Iteration 46/1000 | Loss: 0.00001839
Iteration 47/1000 | Loss: 0.00001838
Iteration 48/1000 | Loss: 0.00001838
Iteration 49/1000 | Loss: 0.00001838
Iteration 50/1000 | Loss: 0.00001838
Iteration 51/1000 | Loss: 0.00001838
Iteration 52/1000 | Loss: 0.00001838
Iteration 53/1000 | Loss: 0.00001838
Iteration 54/1000 | Loss: 0.00001837
Iteration 55/1000 | Loss: 0.00001837
Iteration 56/1000 | Loss: 0.00001837
Iteration 57/1000 | Loss: 0.00001837
Iteration 58/1000 | Loss: 0.00001837
Iteration 59/1000 | Loss: 0.00001837
Iteration 60/1000 | Loss: 0.00001836
Iteration 61/1000 | Loss: 0.00001836
Iteration 62/1000 | Loss: 0.00001836
Iteration 63/1000 | Loss: 0.00001836
Iteration 64/1000 | Loss: 0.00001835
Iteration 65/1000 | Loss: 0.00001835
Iteration 66/1000 | Loss: 0.00001835
Iteration 67/1000 | Loss: 0.00001835
Iteration 68/1000 | Loss: 0.00001835
Iteration 69/1000 | Loss: 0.00001835
Iteration 70/1000 | Loss: 0.00001835
Iteration 71/1000 | Loss: 0.00001835
Iteration 72/1000 | Loss: 0.00001835
Iteration 73/1000 | Loss: 0.00001835
Iteration 74/1000 | Loss: 0.00001835
Iteration 75/1000 | Loss: 0.00001834
Iteration 76/1000 | Loss: 0.00001834
Iteration 77/1000 | Loss: 0.00001834
Iteration 78/1000 | Loss: 0.00001834
Iteration 79/1000 | Loss: 0.00001834
Iteration 80/1000 | Loss: 0.00001834
Iteration 81/1000 | Loss: 0.00001834
Iteration 82/1000 | Loss: 0.00001834
Iteration 83/1000 | Loss: 0.00001834
Iteration 84/1000 | Loss: 0.00001834
Iteration 85/1000 | Loss: 0.00001834
Iteration 86/1000 | Loss: 0.00001834
Iteration 87/1000 | Loss: 0.00001834
Iteration 88/1000 | Loss: 0.00001834
Iteration 89/1000 | Loss: 0.00001834
Iteration 90/1000 | Loss: 0.00001834
Iteration 91/1000 | Loss: 0.00001834
Iteration 92/1000 | Loss: 0.00001834
Iteration 93/1000 | Loss: 0.00001834
Iteration 94/1000 | Loss: 0.00001834
Iteration 95/1000 | Loss: 0.00001834
Iteration 96/1000 | Loss: 0.00001834
Iteration 97/1000 | Loss: 0.00001834
Iteration 98/1000 | Loss: 0.00001834
Iteration 99/1000 | Loss: 0.00001834
Iteration 100/1000 | Loss: 0.00001834
Iteration 101/1000 | Loss: 0.00001834
Iteration 102/1000 | Loss: 0.00001834
Iteration 103/1000 | Loss: 0.00001834
Iteration 104/1000 | Loss: 0.00001834
Iteration 105/1000 | Loss: 0.00001834
Iteration 106/1000 | Loss: 0.00001834
Iteration 107/1000 | Loss: 0.00001834
Iteration 108/1000 | Loss: 0.00001834
Iteration 109/1000 | Loss: 0.00001834
Iteration 110/1000 | Loss: 0.00001834
Iteration 111/1000 | Loss: 0.00001834
Iteration 112/1000 | Loss: 0.00001834
Iteration 113/1000 | Loss: 0.00001834
Iteration 114/1000 | Loss: 0.00001834
Iteration 115/1000 | Loss: 0.00001834
Iteration 116/1000 | Loss: 0.00001834
Iteration 117/1000 | Loss: 0.00001834
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [1.8343180272495374e-05, 1.8343180272495374e-05, 1.8343180272495374e-05, 1.8343180272495374e-05, 1.8343180272495374e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8343180272495374e-05

Optimization complete. Final v2v error: 3.6974310874938965 mm

Highest mean error: 4.003953456878662 mm for frame 15

Lowest mean error: 3.34083890914917 mm for frame 101

Saving results

Total time: 30.87704873085022
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00566578
Iteration 2/25 | Loss: 0.00117541
Iteration 3/25 | Loss: 0.00099942
Iteration 4/25 | Loss: 0.00096460
Iteration 5/25 | Loss: 0.00095597
Iteration 6/25 | Loss: 0.00095351
Iteration 7/25 | Loss: 0.00095292
Iteration 8/25 | Loss: 0.00095292
Iteration 9/25 | Loss: 0.00095292
Iteration 10/25 | Loss: 0.00095292
Iteration 11/25 | Loss: 0.00095292
Iteration 12/25 | Loss: 0.00095292
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.00095292495097965, 0.00095292495097965, 0.00095292495097965, 0.00095292495097965, 0.00095292495097965]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00095292495097965

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.78574175
Iteration 2/25 | Loss: 0.00083244
Iteration 3/25 | Loss: 0.00083244
Iteration 4/25 | Loss: 0.00083243
Iteration 5/25 | Loss: 0.00083243
Iteration 6/25 | Loss: 0.00083243
Iteration 7/25 | Loss: 0.00083243
Iteration 8/25 | Loss: 0.00083243
Iteration 9/25 | Loss: 0.00083243
Iteration 10/25 | Loss: 0.00083243
Iteration 11/25 | Loss: 0.00083243
Iteration 12/25 | Loss: 0.00083243
Iteration 13/25 | Loss: 0.00083243
Iteration 14/25 | Loss: 0.00083243
Iteration 15/25 | Loss: 0.00083243
Iteration 16/25 | Loss: 0.00083243
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008324326481670141, 0.0008324326481670141, 0.0008324326481670141, 0.0008324326481670141, 0.0008324326481670141]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008324326481670141

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00083243
Iteration 2/1000 | Loss: 0.00003047
Iteration 3/1000 | Loss: 0.00002458
Iteration 4/1000 | Loss: 0.00002327
Iteration 5/1000 | Loss: 0.00002243
Iteration 6/1000 | Loss: 0.00002211
Iteration 7/1000 | Loss: 0.00002156
Iteration 8/1000 | Loss: 0.00002128
Iteration 9/1000 | Loss: 0.00002109
Iteration 10/1000 | Loss: 0.00002108
Iteration 11/1000 | Loss: 0.00002102
Iteration 12/1000 | Loss: 0.00002101
Iteration 13/1000 | Loss: 0.00002099
Iteration 14/1000 | Loss: 0.00002096
Iteration 15/1000 | Loss: 0.00002095
Iteration 16/1000 | Loss: 0.00002095
Iteration 17/1000 | Loss: 0.00002094
Iteration 18/1000 | Loss: 0.00002094
Iteration 19/1000 | Loss: 0.00002090
Iteration 20/1000 | Loss: 0.00002088
Iteration 21/1000 | Loss: 0.00002088
Iteration 22/1000 | Loss: 0.00002088
Iteration 23/1000 | Loss: 0.00002088
Iteration 24/1000 | Loss: 0.00002088
Iteration 25/1000 | Loss: 0.00002088
Iteration 26/1000 | Loss: 0.00002088
Iteration 27/1000 | Loss: 0.00002088
Iteration 28/1000 | Loss: 0.00002088
Iteration 29/1000 | Loss: 0.00002088
Iteration 30/1000 | Loss: 0.00002088
Iteration 31/1000 | Loss: 0.00002088
Iteration 32/1000 | Loss: 0.00002088
Iteration 33/1000 | Loss: 0.00002088
Iteration 34/1000 | Loss: 0.00002088
Iteration 35/1000 | Loss: 0.00002088
Iteration 36/1000 | Loss: 0.00002088
Iteration 37/1000 | Loss: 0.00002088
Iteration 38/1000 | Loss: 0.00002088
Iteration 39/1000 | Loss: 0.00002088
Iteration 40/1000 | Loss: 0.00002088
Iteration 41/1000 | Loss: 0.00002088
Iteration 42/1000 | Loss: 0.00002088
Iteration 43/1000 | Loss: 0.00002088
Iteration 44/1000 | Loss: 0.00002088
Iteration 45/1000 | Loss: 0.00002088
Iteration 46/1000 | Loss: 0.00002088
Iteration 47/1000 | Loss: 0.00002088
Iteration 48/1000 | Loss: 0.00002088
Iteration 49/1000 | Loss: 0.00002088
Iteration 50/1000 | Loss: 0.00002088
Iteration 51/1000 | Loss: 0.00002088
Iteration 52/1000 | Loss: 0.00002088
Iteration 53/1000 | Loss: 0.00002088
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 53. Stopping optimization.
Last 5 losses: [2.0879788280581124e-05, 2.0879788280581124e-05, 2.0879788280581124e-05, 2.0879788280581124e-05, 2.0879788280581124e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0879788280581124e-05

Optimization complete. Final v2v error: 3.846182107925415 mm

Highest mean error: 4.1872334480285645 mm for frame 90

Lowest mean error: 3.519092559814453 mm for frame 2

Saving results

Total time: 26.703421115875244
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01002542
Iteration 2/25 | Loss: 0.00123126
Iteration 3/25 | Loss: 0.00105098
Iteration 4/25 | Loss: 0.00101065
Iteration 5/25 | Loss: 0.00099201
Iteration 6/25 | Loss: 0.00098781
Iteration 7/25 | Loss: 0.00098709
Iteration 8/25 | Loss: 0.00098709
Iteration 9/25 | Loss: 0.00098709
Iteration 10/25 | Loss: 0.00098709
Iteration 11/25 | Loss: 0.00098709
Iteration 12/25 | Loss: 0.00098709
Iteration 13/25 | Loss: 0.00098709
Iteration 14/25 | Loss: 0.00098709
Iteration 15/25 | Loss: 0.00098709
Iteration 16/25 | Loss: 0.00098709
Iteration 17/25 | Loss: 0.00098709
Iteration 18/25 | Loss: 0.00098709
Iteration 19/25 | Loss: 0.00098709
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0009870872600004077, 0.0009870872600004077, 0.0009870872600004077, 0.0009870872600004077, 0.0009870872600004077]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009870872600004077

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50498497
Iteration 2/25 | Loss: 0.00081466
Iteration 3/25 | Loss: 0.00081464
Iteration 4/25 | Loss: 0.00081464
Iteration 5/25 | Loss: 0.00081464
Iteration 6/25 | Loss: 0.00081464
Iteration 7/25 | Loss: 0.00081464
Iteration 8/25 | Loss: 0.00081464
Iteration 9/25 | Loss: 0.00081464
Iteration 10/25 | Loss: 0.00081464
Iteration 11/25 | Loss: 0.00081464
Iteration 12/25 | Loss: 0.00081464
Iteration 13/25 | Loss: 0.00081464
Iteration 14/25 | Loss: 0.00081464
Iteration 15/25 | Loss: 0.00081464
Iteration 16/25 | Loss: 0.00081464
Iteration 17/25 | Loss: 0.00081464
Iteration 18/25 | Loss: 0.00081464
Iteration 19/25 | Loss: 0.00081464
Iteration 20/25 | Loss: 0.00081464
Iteration 21/25 | Loss: 0.00081464
Iteration 22/25 | Loss: 0.00081464
Iteration 23/25 | Loss: 0.00081464
Iteration 24/25 | Loss: 0.00081464
Iteration 25/25 | Loss: 0.00081464

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00081464
Iteration 2/1000 | Loss: 0.00005195
Iteration 3/1000 | Loss: 0.00003957
Iteration 4/1000 | Loss: 0.00003475
Iteration 5/1000 | Loss: 0.00003285
Iteration 6/1000 | Loss: 0.00003138
Iteration 7/1000 | Loss: 0.00003032
Iteration 8/1000 | Loss: 0.00002952
Iteration 9/1000 | Loss: 0.00002897
Iteration 10/1000 | Loss: 0.00002867
Iteration 11/1000 | Loss: 0.00002851
Iteration 12/1000 | Loss: 0.00002845
Iteration 13/1000 | Loss: 0.00002842
Iteration 14/1000 | Loss: 0.00002842
Iteration 15/1000 | Loss: 0.00002842
Iteration 16/1000 | Loss: 0.00002839
Iteration 17/1000 | Loss: 0.00002837
Iteration 18/1000 | Loss: 0.00002837
Iteration 19/1000 | Loss: 0.00002836
Iteration 20/1000 | Loss: 0.00002836
Iteration 21/1000 | Loss: 0.00002835
Iteration 22/1000 | Loss: 0.00002834
Iteration 23/1000 | Loss: 0.00002832
Iteration 24/1000 | Loss: 0.00002831
Iteration 25/1000 | Loss: 0.00002831
Iteration 26/1000 | Loss: 0.00002830
Iteration 27/1000 | Loss: 0.00002830
Iteration 28/1000 | Loss: 0.00002829
Iteration 29/1000 | Loss: 0.00002829
Iteration 30/1000 | Loss: 0.00002829
Iteration 31/1000 | Loss: 0.00002829
Iteration 32/1000 | Loss: 0.00002828
Iteration 33/1000 | Loss: 0.00002828
Iteration 34/1000 | Loss: 0.00002828
Iteration 35/1000 | Loss: 0.00002828
Iteration 36/1000 | Loss: 0.00002828
Iteration 37/1000 | Loss: 0.00002828
Iteration 38/1000 | Loss: 0.00002828
Iteration 39/1000 | Loss: 0.00002828
Iteration 40/1000 | Loss: 0.00002828
Iteration 41/1000 | Loss: 0.00002828
Iteration 42/1000 | Loss: 0.00002827
Iteration 43/1000 | Loss: 0.00002827
Iteration 44/1000 | Loss: 0.00002827
Iteration 45/1000 | Loss: 0.00002826
Iteration 46/1000 | Loss: 0.00002826
Iteration 47/1000 | Loss: 0.00002826
Iteration 48/1000 | Loss: 0.00002826
Iteration 49/1000 | Loss: 0.00002825
Iteration 50/1000 | Loss: 0.00002825
Iteration 51/1000 | Loss: 0.00002825
Iteration 52/1000 | Loss: 0.00002824
Iteration 53/1000 | Loss: 0.00002824
Iteration 54/1000 | Loss: 0.00002824
Iteration 55/1000 | Loss: 0.00002823
Iteration 56/1000 | Loss: 0.00002823
Iteration 57/1000 | Loss: 0.00002823
Iteration 58/1000 | Loss: 0.00002823
Iteration 59/1000 | Loss: 0.00002823
Iteration 60/1000 | Loss: 0.00002822
Iteration 61/1000 | Loss: 0.00002822
Iteration 62/1000 | Loss: 0.00002822
Iteration 63/1000 | Loss: 0.00002822
Iteration 64/1000 | Loss: 0.00002822
Iteration 65/1000 | Loss: 0.00002822
Iteration 66/1000 | Loss: 0.00002821
Iteration 67/1000 | Loss: 0.00002821
Iteration 68/1000 | Loss: 0.00002821
Iteration 69/1000 | Loss: 0.00002821
Iteration 70/1000 | Loss: 0.00002820
Iteration 71/1000 | Loss: 0.00002820
Iteration 72/1000 | Loss: 0.00002820
Iteration 73/1000 | Loss: 0.00002820
Iteration 74/1000 | Loss: 0.00002819
Iteration 75/1000 | Loss: 0.00002819
Iteration 76/1000 | Loss: 0.00002819
Iteration 77/1000 | Loss: 0.00002819
Iteration 78/1000 | Loss: 0.00002819
Iteration 79/1000 | Loss: 0.00002819
Iteration 80/1000 | Loss: 0.00002819
Iteration 81/1000 | Loss: 0.00002819
Iteration 82/1000 | Loss: 0.00002819
Iteration 83/1000 | Loss: 0.00002818
Iteration 84/1000 | Loss: 0.00002818
Iteration 85/1000 | Loss: 0.00002818
Iteration 86/1000 | Loss: 0.00002818
Iteration 87/1000 | Loss: 0.00002818
Iteration 88/1000 | Loss: 0.00002818
Iteration 89/1000 | Loss: 0.00002818
Iteration 90/1000 | Loss: 0.00002818
Iteration 91/1000 | Loss: 0.00002818
Iteration 92/1000 | Loss: 0.00002818
Iteration 93/1000 | Loss: 0.00002818
Iteration 94/1000 | Loss: 0.00002817
Iteration 95/1000 | Loss: 0.00002817
Iteration 96/1000 | Loss: 0.00002817
Iteration 97/1000 | Loss: 0.00002817
Iteration 98/1000 | Loss: 0.00002817
Iteration 99/1000 | Loss: 0.00002817
Iteration 100/1000 | Loss: 0.00002817
Iteration 101/1000 | Loss: 0.00002817
Iteration 102/1000 | Loss: 0.00002817
Iteration 103/1000 | Loss: 0.00002817
Iteration 104/1000 | Loss: 0.00002817
Iteration 105/1000 | Loss: 0.00002817
Iteration 106/1000 | Loss: 0.00002816
Iteration 107/1000 | Loss: 0.00002816
Iteration 108/1000 | Loss: 0.00002816
Iteration 109/1000 | Loss: 0.00002816
Iteration 110/1000 | Loss: 0.00002815
Iteration 111/1000 | Loss: 0.00002815
Iteration 112/1000 | Loss: 0.00002815
Iteration 113/1000 | Loss: 0.00002815
Iteration 114/1000 | Loss: 0.00002815
Iteration 115/1000 | Loss: 0.00002815
Iteration 116/1000 | Loss: 0.00002815
Iteration 117/1000 | Loss: 0.00002815
Iteration 118/1000 | Loss: 0.00002815
Iteration 119/1000 | Loss: 0.00002815
Iteration 120/1000 | Loss: 0.00002815
Iteration 121/1000 | Loss: 0.00002815
Iteration 122/1000 | Loss: 0.00002814
Iteration 123/1000 | Loss: 0.00002814
Iteration 124/1000 | Loss: 0.00002814
Iteration 125/1000 | Loss: 0.00002814
Iteration 126/1000 | Loss: 0.00002814
Iteration 127/1000 | Loss: 0.00002814
Iteration 128/1000 | Loss: 0.00002814
Iteration 129/1000 | Loss: 0.00002814
Iteration 130/1000 | Loss: 0.00002814
Iteration 131/1000 | Loss: 0.00002814
Iteration 132/1000 | Loss: 0.00002814
Iteration 133/1000 | Loss: 0.00002814
Iteration 134/1000 | Loss: 0.00002814
Iteration 135/1000 | Loss: 0.00002814
Iteration 136/1000 | Loss: 0.00002813
Iteration 137/1000 | Loss: 0.00002813
Iteration 138/1000 | Loss: 0.00002813
Iteration 139/1000 | Loss: 0.00002813
Iteration 140/1000 | Loss: 0.00002813
Iteration 141/1000 | Loss: 0.00002813
Iteration 142/1000 | Loss: 0.00002813
Iteration 143/1000 | Loss: 0.00002813
Iteration 144/1000 | Loss: 0.00002813
Iteration 145/1000 | Loss: 0.00002813
Iteration 146/1000 | Loss: 0.00002813
Iteration 147/1000 | Loss: 0.00002813
Iteration 148/1000 | Loss: 0.00002813
Iteration 149/1000 | Loss: 0.00002813
Iteration 150/1000 | Loss: 0.00002812
Iteration 151/1000 | Loss: 0.00002812
Iteration 152/1000 | Loss: 0.00002812
Iteration 153/1000 | Loss: 0.00002812
Iteration 154/1000 | Loss: 0.00002812
Iteration 155/1000 | Loss: 0.00002812
Iteration 156/1000 | Loss: 0.00002812
Iteration 157/1000 | Loss: 0.00002812
Iteration 158/1000 | Loss: 0.00002812
Iteration 159/1000 | Loss: 0.00002812
Iteration 160/1000 | Loss: 0.00002812
Iteration 161/1000 | Loss: 0.00002811
Iteration 162/1000 | Loss: 0.00002811
Iteration 163/1000 | Loss: 0.00002811
Iteration 164/1000 | Loss: 0.00002811
Iteration 165/1000 | Loss: 0.00002811
Iteration 166/1000 | Loss: 0.00002811
Iteration 167/1000 | Loss: 0.00002811
Iteration 168/1000 | Loss: 0.00002811
Iteration 169/1000 | Loss: 0.00002811
Iteration 170/1000 | Loss: 0.00002811
Iteration 171/1000 | Loss: 0.00002811
Iteration 172/1000 | Loss: 0.00002811
Iteration 173/1000 | Loss: 0.00002810
Iteration 174/1000 | Loss: 0.00002810
Iteration 175/1000 | Loss: 0.00002810
Iteration 176/1000 | Loss: 0.00002810
Iteration 177/1000 | Loss: 0.00002810
Iteration 178/1000 | Loss: 0.00002810
Iteration 179/1000 | Loss: 0.00002810
Iteration 180/1000 | Loss: 0.00002810
Iteration 181/1000 | Loss: 0.00002810
Iteration 182/1000 | Loss: 0.00002810
Iteration 183/1000 | Loss: 0.00002810
Iteration 184/1000 | Loss: 0.00002810
Iteration 185/1000 | Loss: 0.00002810
Iteration 186/1000 | Loss: 0.00002810
Iteration 187/1000 | Loss: 0.00002810
Iteration 188/1000 | Loss: 0.00002810
Iteration 189/1000 | Loss: 0.00002810
Iteration 190/1000 | Loss: 0.00002809
Iteration 191/1000 | Loss: 0.00002809
Iteration 192/1000 | Loss: 0.00002809
Iteration 193/1000 | Loss: 0.00002809
Iteration 194/1000 | Loss: 0.00002809
Iteration 195/1000 | Loss: 0.00002809
Iteration 196/1000 | Loss: 0.00002809
Iteration 197/1000 | Loss: 0.00002809
Iteration 198/1000 | Loss: 0.00002809
Iteration 199/1000 | Loss: 0.00002809
Iteration 200/1000 | Loss: 0.00002809
Iteration 201/1000 | Loss: 0.00002809
Iteration 202/1000 | Loss: 0.00002809
Iteration 203/1000 | Loss: 0.00002809
Iteration 204/1000 | Loss: 0.00002809
Iteration 205/1000 | Loss: 0.00002809
Iteration 206/1000 | Loss: 0.00002809
Iteration 207/1000 | Loss: 0.00002809
Iteration 208/1000 | Loss: 0.00002809
Iteration 209/1000 | Loss: 0.00002809
Iteration 210/1000 | Loss: 0.00002809
Iteration 211/1000 | Loss: 0.00002809
Iteration 212/1000 | Loss: 0.00002809
Iteration 213/1000 | Loss: 0.00002809
Iteration 214/1000 | Loss: 0.00002809
Iteration 215/1000 | Loss: 0.00002808
Iteration 216/1000 | Loss: 0.00002808
Iteration 217/1000 | Loss: 0.00002808
Iteration 218/1000 | Loss: 0.00002808
Iteration 219/1000 | Loss: 0.00002808
Iteration 220/1000 | Loss: 0.00002808
Iteration 221/1000 | Loss: 0.00002808
Iteration 222/1000 | Loss: 0.00002808
Iteration 223/1000 | Loss: 0.00002808
Iteration 224/1000 | Loss: 0.00002808
Iteration 225/1000 | Loss: 0.00002808
Iteration 226/1000 | Loss: 0.00002808
Iteration 227/1000 | Loss: 0.00002808
Iteration 228/1000 | Loss: 0.00002808
Iteration 229/1000 | Loss: 0.00002808
Iteration 230/1000 | Loss: 0.00002808
Iteration 231/1000 | Loss: 0.00002808
Iteration 232/1000 | Loss: 0.00002808
Iteration 233/1000 | Loss: 0.00002808
Iteration 234/1000 | Loss: 0.00002808
Iteration 235/1000 | Loss: 0.00002808
Iteration 236/1000 | Loss: 0.00002808
Iteration 237/1000 | Loss: 0.00002808
Iteration 238/1000 | Loss: 0.00002808
Iteration 239/1000 | Loss: 0.00002808
Iteration 240/1000 | Loss: 0.00002808
Iteration 241/1000 | Loss: 0.00002808
Iteration 242/1000 | Loss: 0.00002808
Iteration 243/1000 | Loss: 0.00002808
Iteration 244/1000 | Loss: 0.00002808
Iteration 245/1000 | Loss: 0.00002808
Iteration 246/1000 | Loss: 0.00002808
Iteration 247/1000 | Loss: 0.00002808
Iteration 248/1000 | Loss: 0.00002808
Iteration 249/1000 | Loss: 0.00002808
Iteration 250/1000 | Loss: 0.00002808
Iteration 251/1000 | Loss: 0.00002808
Iteration 252/1000 | Loss: 0.00002808
Iteration 253/1000 | Loss: 0.00002808
Iteration 254/1000 | Loss: 0.00002808
Iteration 255/1000 | Loss: 0.00002808
Iteration 256/1000 | Loss: 0.00002808
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 256. Stopping optimization.
Last 5 losses: [2.8076297894585878e-05, 2.8076297894585878e-05, 2.8076297894585878e-05, 2.8076297894585878e-05, 2.8076297894585878e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8076297894585878e-05

Optimization complete. Final v2v error: 4.370249271392822 mm

Highest mean error: 6.422191619873047 mm for frame 70

Lowest mean error: 3.733826160430908 mm for frame 95

Saving results

Total time: 41.93501663208008
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00526075
Iteration 2/25 | Loss: 0.00137301
Iteration 3/25 | Loss: 0.00102287
Iteration 4/25 | Loss: 0.00094770
Iteration 5/25 | Loss: 0.00093690
Iteration 6/25 | Loss: 0.00093521
Iteration 7/25 | Loss: 0.00093491
Iteration 8/25 | Loss: 0.00093491
Iteration 9/25 | Loss: 0.00093491
Iteration 10/25 | Loss: 0.00093491
Iteration 11/25 | Loss: 0.00093491
Iteration 12/25 | Loss: 0.00093491
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009349061292596161, 0.0009349061292596161, 0.0009349061292596161, 0.0009349061292596161, 0.0009349061292596161]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009349061292596161

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51692486
Iteration 2/25 | Loss: 0.00081001
Iteration 3/25 | Loss: 0.00081001
Iteration 4/25 | Loss: 0.00081001
Iteration 5/25 | Loss: 0.00081001
Iteration 6/25 | Loss: 0.00081001
Iteration 7/25 | Loss: 0.00081001
Iteration 8/25 | Loss: 0.00081001
Iteration 9/25 | Loss: 0.00081001
Iteration 10/25 | Loss: 0.00081001
Iteration 11/25 | Loss: 0.00081001
Iteration 12/25 | Loss: 0.00081001
Iteration 13/25 | Loss: 0.00081001
Iteration 14/25 | Loss: 0.00081001
Iteration 15/25 | Loss: 0.00081001
Iteration 16/25 | Loss: 0.00081001
Iteration 17/25 | Loss: 0.00081001
Iteration 18/25 | Loss: 0.00081001
Iteration 19/25 | Loss: 0.00081001
Iteration 20/25 | Loss: 0.00081001
Iteration 21/25 | Loss: 0.00081001
Iteration 22/25 | Loss: 0.00081001
Iteration 23/25 | Loss: 0.00081001
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0008100114646367729, 0.0008100114646367729, 0.0008100114646367729, 0.0008100114646367729, 0.0008100114646367729]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008100114646367729

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00081001
Iteration 2/1000 | Loss: 0.00002863
Iteration 3/1000 | Loss: 0.00002220
Iteration 4/1000 | Loss: 0.00002015
Iteration 5/1000 | Loss: 0.00001929
Iteration 6/1000 | Loss: 0.00001876
Iteration 7/1000 | Loss: 0.00001826
Iteration 8/1000 | Loss: 0.00001790
Iteration 9/1000 | Loss: 0.00001773
Iteration 10/1000 | Loss: 0.00001767
Iteration 11/1000 | Loss: 0.00001767
Iteration 12/1000 | Loss: 0.00001761
Iteration 13/1000 | Loss: 0.00001760
Iteration 14/1000 | Loss: 0.00001760
Iteration 15/1000 | Loss: 0.00001759
Iteration 16/1000 | Loss: 0.00001757
Iteration 17/1000 | Loss: 0.00001756
Iteration 18/1000 | Loss: 0.00001755
Iteration 19/1000 | Loss: 0.00001755
Iteration 20/1000 | Loss: 0.00001754
Iteration 21/1000 | Loss: 0.00001753
Iteration 22/1000 | Loss: 0.00001753
Iteration 23/1000 | Loss: 0.00001752
Iteration 24/1000 | Loss: 0.00001752
Iteration 25/1000 | Loss: 0.00001751
Iteration 26/1000 | Loss: 0.00001751
Iteration 27/1000 | Loss: 0.00001751
Iteration 28/1000 | Loss: 0.00001750
Iteration 29/1000 | Loss: 0.00001749
Iteration 30/1000 | Loss: 0.00001748
Iteration 31/1000 | Loss: 0.00001748
Iteration 32/1000 | Loss: 0.00001748
Iteration 33/1000 | Loss: 0.00001747
Iteration 34/1000 | Loss: 0.00001747
Iteration 35/1000 | Loss: 0.00001746
Iteration 36/1000 | Loss: 0.00001746
Iteration 37/1000 | Loss: 0.00001746
Iteration 38/1000 | Loss: 0.00001745
Iteration 39/1000 | Loss: 0.00001744
Iteration 40/1000 | Loss: 0.00001744
Iteration 41/1000 | Loss: 0.00001744
Iteration 42/1000 | Loss: 0.00001743
Iteration 43/1000 | Loss: 0.00001743
Iteration 44/1000 | Loss: 0.00001743
Iteration 45/1000 | Loss: 0.00001743
Iteration 46/1000 | Loss: 0.00001742
Iteration 47/1000 | Loss: 0.00001742
Iteration 48/1000 | Loss: 0.00001741
Iteration 49/1000 | Loss: 0.00001741
Iteration 50/1000 | Loss: 0.00001741
Iteration 51/1000 | Loss: 0.00001741
Iteration 52/1000 | Loss: 0.00001740
Iteration 53/1000 | Loss: 0.00001740
Iteration 54/1000 | Loss: 0.00001740
Iteration 55/1000 | Loss: 0.00001740
Iteration 56/1000 | Loss: 0.00001740
Iteration 57/1000 | Loss: 0.00001740
Iteration 58/1000 | Loss: 0.00001740
Iteration 59/1000 | Loss: 0.00001740
Iteration 60/1000 | Loss: 0.00001740
Iteration 61/1000 | Loss: 0.00001739
Iteration 62/1000 | Loss: 0.00001739
Iteration 63/1000 | Loss: 0.00001739
Iteration 64/1000 | Loss: 0.00001739
Iteration 65/1000 | Loss: 0.00001739
Iteration 66/1000 | Loss: 0.00001738
Iteration 67/1000 | Loss: 0.00001738
Iteration 68/1000 | Loss: 0.00001738
Iteration 69/1000 | Loss: 0.00001738
Iteration 70/1000 | Loss: 0.00001737
Iteration 71/1000 | Loss: 0.00001737
Iteration 72/1000 | Loss: 0.00001737
Iteration 73/1000 | Loss: 0.00001737
Iteration 74/1000 | Loss: 0.00001736
Iteration 75/1000 | Loss: 0.00001736
Iteration 76/1000 | Loss: 0.00001736
Iteration 77/1000 | Loss: 0.00001736
Iteration 78/1000 | Loss: 0.00001736
Iteration 79/1000 | Loss: 0.00001736
Iteration 80/1000 | Loss: 0.00001736
Iteration 81/1000 | Loss: 0.00001735
Iteration 82/1000 | Loss: 0.00001735
Iteration 83/1000 | Loss: 0.00001735
Iteration 84/1000 | Loss: 0.00001735
Iteration 85/1000 | Loss: 0.00001735
Iteration 86/1000 | Loss: 0.00001735
Iteration 87/1000 | Loss: 0.00001735
Iteration 88/1000 | Loss: 0.00001734
Iteration 89/1000 | Loss: 0.00001734
Iteration 90/1000 | Loss: 0.00001734
Iteration 91/1000 | Loss: 0.00001734
Iteration 92/1000 | Loss: 0.00001734
Iteration 93/1000 | Loss: 0.00001734
Iteration 94/1000 | Loss: 0.00001734
Iteration 95/1000 | Loss: 0.00001734
Iteration 96/1000 | Loss: 0.00001734
Iteration 97/1000 | Loss: 0.00001733
Iteration 98/1000 | Loss: 0.00001733
Iteration 99/1000 | Loss: 0.00001733
Iteration 100/1000 | Loss: 0.00001733
Iteration 101/1000 | Loss: 0.00001733
Iteration 102/1000 | Loss: 0.00001733
Iteration 103/1000 | Loss: 0.00001733
Iteration 104/1000 | Loss: 0.00001733
Iteration 105/1000 | Loss: 0.00001733
Iteration 106/1000 | Loss: 0.00001733
Iteration 107/1000 | Loss: 0.00001733
Iteration 108/1000 | Loss: 0.00001733
Iteration 109/1000 | Loss: 0.00001733
Iteration 110/1000 | Loss: 0.00001733
Iteration 111/1000 | Loss: 0.00001733
Iteration 112/1000 | Loss: 0.00001733
Iteration 113/1000 | Loss: 0.00001733
Iteration 114/1000 | Loss: 0.00001733
Iteration 115/1000 | Loss: 0.00001733
Iteration 116/1000 | Loss: 0.00001733
Iteration 117/1000 | Loss: 0.00001733
Iteration 118/1000 | Loss: 0.00001733
Iteration 119/1000 | Loss: 0.00001733
Iteration 120/1000 | Loss: 0.00001733
Iteration 121/1000 | Loss: 0.00001733
Iteration 122/1000 | Loss: 0.00001733
Iteration 123/1000 | Loss: 0.00001733
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.7327589375781827e-05, 1.7327589375781827e-05, 1.7327589375781827e-05, 1.7327589375781827e-05, 1.7327589375781827e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7327589375781827e-05

Optimization complete. Final v2v error: 3.5267863273620605 mm

Highest mean error: 4.616370677947998 mm for frame 90

Lowest mean error: 3.2305514812469482 mm for frame 114

Saving results

Total time: 33.620530128479004
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01104585
Iteration 2/25 | Loss: 0.00386602
Iteration 3/25 | Loss: 0.00227979
Iteration 4/25 | Loss: 0.00165086
Iteration 5/25 | Loss: 0.00152278
Iteration 6/25 | Loss: 0.00144771
Iteration 7/25 | Loss: 0.00144690
Iteration 8/25 | Loss: 0.00141612
Iteration 9/25 | Loss: 0.00139602
Iteration 10/25 | Loss: 0.00141741
Iteration 11/25 | Loss: 0.00138285
Iteration 12/25 | Loss: 0.00136557
Iteration 13/25 | Loss: 0.00136855
Iteration 14/25 | Loss: 0.00135684
Iteration 15/25 | Loss: 0.00134452
Iteration 16/25 | Loss: 0.00133999
Iteration 17/25 | Loss: 0.00134341
Iteration 18/25 | Loss: 0.00133357
Iteration 19/25 | Loss: 0.00133722
Iteration 20/25 | Loss: 0.00133482
Iteration 21/25 | Loss: 0.00133249
Iteration 22/25 | Loss: 0.00132977
Iteration 23/25 | Loss: 0.00133492
Iteration 24/25 | Loss: 0.00133419
Iteration 25/25 | Loss: 0.00133826

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.12025070
Iteration 2/25 | Loss: 0.00582729
Iteration 3/25 | Loss: 0.00557668
Iteration 4/25 | Loss: 0.00557668
Iteration 5/25 | Loss: 0.00557668
Iteration 6/25 | Loss: 0.00557668
Iteration 7/25 | Loss: 0.00557668
Iteration 8/25 | Loss: 0.00557668
Iteration 9/25 | Loss: 0.00557668
Iteration 10/25 | Loss: 0.00557668
Iteration 11/25 | Loss: 0.00557668
Iteration 12/25 | Loss: 0.00557668
Iteration 13/25 | Loss: 0.00557668
Iteration 14/25 | Loss: 0.00557668
Iteration 15/25 | Loss: 0.00557668
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.005576679948717356, 0.005576679948717356, 0.005576679948717356, 0.005576679948717356, 0.005576679948717356]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005576679948717356

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00557668
Iteration 2/1000 | Loss: 0.00233836
Iteration 3/1000 | Loss: 0.00861151
Iteration 4/1000 | Loss: 0.00346128
Iteration 5/1000 | Loss: 0.00626392
Iteration 6/1000 | Loss: 0.00378232
Iteration 7/1000 | Loss: 0.00072178
Iteration 8/1000 | Loss: 0.00637177
Iteration 9/1000 | Loss: 0.00423723
Iteration 10/1000 | Loss: 0.00256395
Iteration 11/1000 | Loss: 0.00299678
Iteration 12/1000 | Loss: 0.00075523
Iteration 13/1000 | Loss: 0.00141077
Iteration 14/1000 | Loss: 0.00076325
Iteration 15/1000 | Loss: 0.00193520
Iteration 16/1000 | Loss: 0.00130099
Iteration 17/1000 | Loss: 0.00170326
Iteration 18/1000 | Loss: 0.00079734
Iteration 19/1000 | Loss: 0.00098995
Iteration 20/1000 | Loss: 0.00025870
Iteration 21/1000 | Loss: 0.00014434
Iteration 22/1000 | Loss: 0.00011891
Iteration 23/1000 | Loss: 0.00073959
Iteration 24/1000 | Loss: 0.00042647
Iteration 25/1000 | Loss: 0.00028296
Iteration 26/1000 | Loss: 0.00066928
Iteration 27/1000 | Loss: 0.00160215
Iteration 28/1000 | Loss: 0.00105235
Iteration 29/1000 | Loss: 0.00059765
Iteration 30/1000 | Loss: 0.00074551
Iteration 31/1000 | Loss: 0.00107869
Iteration 32/1000 | Loss: 0.00091950
Iteration 33/1000 | Loss: 0.00183103
Iteration 34/1000 | Loss: 0.00249645
Iteration 35/1000 | Loss: 0.00262478
Iteration 36/1000 | Loss: 0.00065174
Iteration 37/1000 | Loss: 0.00322865
Iteration 38/1000 | Loss: 0.00064549
Iteration 39/1000 | Loss: 0.00040635
Iteration 40/1000 | Loss: 0.00068272
Iteration 41/1000 | Loss: 0.00118559
Iteration 42/1000 | Loss: 0.00029864
Iteration 43/1000 | Loss: 0.00088240
Iteration 44/1000 | Loss: 0.00042491
Iteration 45/1000 | Loss: 0.00048456
Iteration 46/1000 | Loss: 0.00018965
Iteration 47/1000 | Loss: 0.00035112
Iteration 48/1000 | Loss: 0.00174597
Iteration 49/1000 | Loss: 0.00090407
Iteration 50/1000 | Loss: 0.00028721
Iteration 51/1000 | Loss: 0.00009318
Iteration 52/1000 | Loss: 0.00008265
Iteration 53/1000 | Loss: 0.00007689
Iteration 54/1000 | Loss: 0.00111472
Iteration 55/1000 | Loss: 0.00119095
Iteration 56/1000 | Loss: 0.00079995
Iteration 57/1000 | Loss: 0.00093633
Iteration 58/1000 | Loss: 0.00078176
Iteration 59/1000 | Loss: 0.00106494
Iteration 60/1000 | Loss: 0.00312518
Iteration 61/1000 | Loss: 0.00200876
Iteration 62/1000 | Loss: 0.00124540
Iteration 63/1000 | Loss: 0.00125341
Iteration 64/1000 | Loss: 0.00008075
Iteration 65/1000 | Loss: 0.00006861
Iteration 66/1000 | Loss: 0.00029639
Iteration 67/1000 | Loss: 0.00054769
Iteration 68/1000 | Loss: 0.00011147
Iteration 69/1000 | Loss: 0.00012336
Iteration 70/1000 | Loss: 0.00006590
Iteration 71/1000 | Loss: 0.00021623
Iteration 72/1000 | Loss: 0.00008121
Iteration 73/1000 | Loss: 0.00006798
Iteration 74/1000 | Loss: 0.00006648
Iteration 75/1000 | Loss: 0.00005380
Iteration 76/1000 | Loss: 0.00005271
Iteration 77/1000 | Loss: 0.00147322
Iteration 78/1000 | Loss: 0.00025797
Iteration 79/1000 | Loss: 0.00007162
Iteration 80/1000 | Loss: 0.00021106
Iteration 81/1000 | Loss: 0.00021643
Iteration 82/1000 | Loss: 0.00019174
Iteration 83/1000 | Loss: 0.00108957
Iteration 84/1000 | Loss: 0.00064441
Iteration 85/1000 | Loss: 0.00386142
Iteration 86/1000 | Loss: 0.00133735
Iteration 87/1000 | Loss: 0.00147498
Iteration 88/1000 | Loss: 0.00082840
Iteration 89/1000 | Loss: 0.00029973
Iteration 90/1000 | Loss: 0.00093730
Iteration 91/1000 | Loss: 0.00116675
Iteration 92/1000 | Loss: 0.00111836
Iteration 93/1000 | Loss: 0.00314476
Iteration 94/1000 | Loss: 0.00125472
Iteration 95/1000 | Loss: 0.00155234
Iteration 96/1000 | Loss: 0.00030984
Iteration 97/1000 | Loss: 0.00059841
Iteration 98/1000 | Loss: 0.00006295
Iteration 99/1000 | Loss: 0.00069116
Iteration 100/1000 | Loss: 0.00134128
Iteration 101/1000 | Loss: 0.00041217
Iteration 102/1000 | Loss: 0.00040705
Iteration 103/1000 | Loss: 0.00032914
Iteration 104/1000 | Loss: 0.00060368
Iteration 105/1000 | Loss: 0.00054036
Iteration 106/1000 | Loss: 0.00007735
Iteration 107/1000 | Loss: 0.00005572
Iteration 108/1000 | Loss: 0.00004901
Iteration 109/1000 | Loss: 0.00004469
Iteration 110/1000 | Loss: 0.00029880
Iteration 111/1000 | Loss: 0.00024995
Iteration 112/1000 | Loss: 0.00015649
Iteration 113/1000 | Loss: 0.00006491
Iteration 114/1000 | Loss: 0.00021166
Iteration 115/1000 | Loss: 0.00008774
Iteration 116/1000 | Loss: 0.00028735
Iteration 117/1000 | Loss: 0.00009429
Iteration 118/1000 | Loss: 0.00010513
Iteration 119/1000 | Loss: 0.00026777
Iteration 120/1000 | Loss: 0.00060759
Iteration 121/1000 | Loss: 0.00309877
Iteration 122/1000 | Loss: 0.00088976
Iteration 123/1000 | Loss: 0.00078131
Iteration 124/1000 | Loss: 0.00064332
Iteration 125/1000 | Loss: 0.00033034
Iteration 126/1000 | Loss: 0.00021031
Iteration 127/1000 | Loss: 0.00050502
Iteration 128/1000 | Loss: 0.00053340
Iteration 129/1000 | Loss: 0.00140223
Iteration 130/1000 | Loss: 0.00006371
Iteration 131/1000 | Loss: 0.00021986
Iteration 132/1000 | Loss: 0.00007142
Iteration 133/1000 | Loss: 0.00046378
Iteration 134/1000 | Loss: 0.00031801
Iteration 135/1000 | Loss: 0.00077110
Iteration 136/1000 | Loss: 0.00042737
Iteration 137/1000 | Loss: 0.00030646
Iteration 138/1000 | Loss: 0.00018169
Iteration 139/1000 | Loss: 0.00004406
Iteration 140/1000 | Loss: 0.00051978
Iteration 141/1000 | Loss: 0.00005815
Iteration 142/1000 | Loss: 0.00016389
Iteration 143/1000 | Loss: 0.00003986
Iteration 144/1000 | Loss: 0.00072442
Iteration 145/1000 | Loss: 0.00024674
Iteration 146/1000 | Loss: 0.00092508
Iteration 147/1000 | Loss: 0.00080914
Iteration 148/1000 | Loss: 0.00028983
Iteration 149/1000 | Loss: 0.00041038
Iteration 150/1000 | Loss: 0.00042795
Iteration 151/1000 | Loss: 0.00063506
Iteration 152/1000 | Loss: 0.00040375
Iteration 153/1000 | Loss: 0.00022696
Iteration 154/1000 | Loss: 0.00065680
Iteration 155/1000 | Loss: 0.00025591
Iteration 156/1000 | Loss: 0.00032026
Iteration 157/1000 | Loss: 0.00005021
Iteration 158/1000 | Loss: 0.00004303
Iteration 159/1000 | Loss: 0.00027058
Iteration 160/1000 | Loss: 0.00032810
Iteration 161/1000 | Loss: 0.00017653
Iteration 162/1000 | Loss: 0.00069215
Iteration 163/1000 | Loss: 0.00031379
Iteration 164/1000 | Loss: 0.00004055
Iteration 165/1000 | Loss: 0.00014041
Iteration 166/1000 | Loss: 0.00027872
Iteration 167/1000 | Loss: 0.00036096
Iteration 168/1000 | Loss: 0.00054077
Iteration 169/1000 | Loss: 0.00025580
Iteration 170/1000 | Loss: 0.00250021
Iteration 171/1000 | Loss: 0.00120533
Iteration 172/1000 | Loss: 0.00015518
Iteration 173/1000 | Loss: 0.00015975
Iteration 174/1000 | Loss: 0.00013840
Iteration 175/1000 | Loss: 0.00003954
Iteration 176/1000 | Loss: 0.00003430
Iteration 177/1000 | Loss: 0.00005739
Iteration 178/1000 | Loss: 0.00003254
Iteration 179/1000 | Loss: 0.00004493
Iteration 180/1000 | Loss: 0.00005083
Iteration 181/1000 | Loss: 0.00010061
Iteration 182/1000 | Loss: 0.00008581
Iteration 183/1000 | Loss: 0.00007880
Iteration 184/1000 | Loss: 0.00010365
Iteration 185/1000 | Loss: 0.00015370
Iteration 186/1000 | Loss: 0.00024548
Iteration 187/1000 | Loss: 0.00007091
Iteration 188/1000 | Loss: 0.00028324
Iteration 189/1000 | Loss: 0.00016893
Iteration 190/1000 | Loss: 0.00022445
Iteration 191/1000 | Loss: 0.00029060
Iteration 192/1000 | Loss: 0.00017233
Iteration 193/1000 | Loss: 0.00254236
Iteration 194/1000 | Loss: 0.00062540
Iteration 195/1000 | Loss: 0.00004336
Iteration 196/1000 | Loss: 0.00003390
Iteration 197/1000 | Loss: 0.00003014
Iteration 198/1000 | Loss: 0.00002848
Iteration 199/1000 | Loss: 0.00002766
Iteration 200/1000 | Loss: 0.00002725
Iteration 201/1000 | Loss: 0.00045354
Iteration 202/1000 | Loss: 0.00016572
Iteration 203/1000 | Loss: 0.00004581
Iteration 204/1000 | Loss: 0.00003357
Iteration 205/1000 | Loss: 0.00003020
Iteration 206/1000 | Loss: 0.00002860
Iteration 207/1000 | Loss: 0.00002758
Iteration 208/1000 | Loss: 0.00002680
Iteration 209/1000 | Loss: 0.00002638
Iteration 210/1000 | Loss: 0.00002614
Iteration 211/1000 | Loss: 0.00002588
Iteration 212/1000 | Loss: 0.00002565
Iteration 213/1000 | Loss: 0.00002551
Iteration 214/1000 | Loss: 0.00002534
Iteration 215/1000 | Loss: 0.00002531
Iteration 216/1000 | Loss: 0.00002529
Iteration 217/1000 | Loss: 0.00002521
Iteration 218/1000 | Loss: 0.00002518
Iteration 219/1000 | Loss: 0.00002516
Iteration 220/1000 | Loss: 0.00002516
Iteration 221/1000 | Loss: 0.00002516
Iteration 222/1000 | Loss: 0.00002515
Iteration 223/1000 | Loss: 0.00002515
Iteration 224/1000 | Loss: 0.00002515
Iteration 225/1000 | Loss: 0.00002515
Iteration 226/1000 | Loss: 0.00002515
Iteration 227/1000 | Loss: 0.00002515
Iteration 228/1000 | Loss: 0.00002515
Iteration 229/1000 | Loss: 0.00002514
Iteration 230/1000 | Loss: 0.00002514
Iteration 231/1000 | Loss: 0.00002514
Iteration 232/1000 | Loss: 0.00002514
Iteration 233/1000 | Loss: 0.00002513
Iteration 234/1000 | Loss: 0.00002513
Iteration 235/1000 | Loss: 0.00002513
Iteration 236/1000 | Loss: 0.00002513
Iteration 237/1000 | Loss: 0.00002513
Iteration 238/1000 | Loss: 0.00002513
Iteration 239/1000 | Loss: 0.00002512
Iteration 240/1000 | Loss: 0.00002512
Iteration 241/1000 | Loss: 0.00002512
Iteration 242/1000 | Loss: 0.00002512
Iteration 243/1000 | Loss: 0.00002512
Iteration 244/1000 | Loss: 0.00002512
Iteration 245/1000 | Loss: 0.00002512
Iteration 246/1000 | Loss: 0.00002512
Iteration 247/1000 | Loss: 0.00002512
Iteration 248/1000 | Loss: 0.00002512
Iteration 249/1000 | Loss: 0.00002512
Iteration 250/1000 | Loss: 0.00002512
Iteration 251/1000 | Loss: 0.00002512
Iteration 252/1000 | Loss: 0.00002512
Iteration 253/1000 | Loss: 0.00002512
Iteration 254/1000 | Loss: 0.00002512
Iteration 255/1000 | Loss: 0.00002511
Iteration 256/1000 | Loss: 0.00002511
Iteration 257/1000 | Loss: 0.00002511
Iteration 258/1000 | Loss: 0.00002511
Iteration 259/1000 | Loss: 0.00002511
Iteration 260/1000 | Loss: 0.00002511
Iteration 261/1000 | Loss: 0.00002511
Iteration 262/1000 | Loss: 0.00002511
Iteration 263/1000 | Loss: 0.00002511
Iteration 264/1000 | Loss: 0.00002511
Iteration 265/1000 | Loss: 0.00002511
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 265. Stopping optimization.
Last 5 losses: [2.5111916329478845e-05, 2.5111916329478845e-05, 2.5111916329478845e-05, 2.5111916329478845e-05, 2.5111916329478845e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5111916329478845e-05

Optimization complete. Final v2v error: 3.999361276626587 mm

Highest mean error: 9.232336044311523 mm for frame 43

Lowest mean error: 2.6200613975524902 mm for frame 0

Saving results

Total time: 358.8285617828369
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00875200
Iteration 2/25 | Loss: 0.00147670
Iteration 3/25 | Loss: 0.00109810
Iteration 4/25 | Loss: 0.00103148
Iteration 5/25 | Loss: 0.00101059
Iteration 6/25 | Loss: 0.00101015
Iteration 7/25 | Loss: 0.00099625
Iteration 8/25 | Loss: 0.00099709
Iteration 9/25 | Loss: 0.00099483
Iteration 10/25 | Loss: 0.00099740
Iteration 11/25 | Loss: 0.00099472
Iteration 12/25 | Loss: 0.00099469
Iteration 13/25 | Loss: 0.00099469
Iteration 14/25 | Loss: 0.00099469
Iteration 15/25 | Loss: 0.00099469
Iteration 16/25 | Loss: 0.00099468
Iteration 17/25 | Loss: 0.00099468
Iteration 18/25 | Loss: 0.00099468
Iteration 19/25 | Loss: 0.00099468
Iteration 20/25 | Loss: 0.00099468
Iteration 21/25 | Loss: 0.00099468
Iteration 22/25 | Loss: 0.00099468
Iteration 23/25 | Loss: 0.00099468
Iteration 24/25 | Loss: 0.00099468
Iteration 25/25 | Loss: 0.00099468

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65877914
Iteration 2/25 | Loss: 0.00116196
Iteration 3/25 | Loss: 0.00116196
Iteration 4/25 | Loss: 0.00116196
Iteration 5/25 | Loss: 0.00116196
Iteration 6/25 | Loss: 0.00116196
Iteration 7/25 | Loss: 0.00116196
Iteration 8/25 | Loss: 0.00116196
Iteration 9/25 | Loss: 0.00116196
Iteration 10/25 | Loss: 0.00116196
Iteration 11/25 | Loss: 0.00116196
Iteration 12/25 | Loss: 0.00116196
Iteration 13/25 | Loss: 0.00116196
Iteration 14/25 | Loss: 0.00116196
Iteration 15/25 | Loss: 0.00116196
Iteration 16/25 | Loss: 0.00116196
Iteration 17/25 | Loss: 0.00116196
Iteration 18/25 | Loss: 0.00116196
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0011619585566222668, 0.0011619585566222668, 0.0011619585566222668, 0.0011619585566222668, 0.0011619585566222668]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011619585566222668

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00116196
Iteration 2/1000 | Loss: 0.00004380
Iteration 3/1000 | Loss: 0.00002670
Iteration 4/1000 | Loss: 0.00002330
Iteration 5/1000 | Loss: 0.00002128
Iteration 6/1000 | Loss: 0.00002011
Iteration 7/1000 | Loss: 0.00001938
Iteration 8/1000 | Loss: 0.00001889
Iteration 9/1000 | Loss: 0.00001848
Iteration 10/1000 | Loss: 0.00001822
Iteration 11/1000 | Loss: 0.00001804
Iteration 12/1000 | Loss: 0.00001799
Iteration 13/1000 | Loss: 0.00001794
Iteration 14/1000 | Loss: 0.00001790
Iteration 15/1000 | Loss: 0.00001785
Iteration 16/1000 | Loss: 0.00001782
Iteration 17/1000 | Loss: 0.00001779
Iteration 18/1000 | Loss: 0.00001778
Iteration 19/1000 | Loss: 0.00001778
Iteration 20/1000 | Loss: 0.00001777
Iteration 21/1000 | Loss: 0.00001777
Iteration 22/1000 | Loss: 0.00001777
Iteration 23/1000 | Loss: 0.00001776
Iteration 24/1000 | Loss: 0.00001776
Iteration 25/1000 | Loss: 0.00001776
Iteration 26/1000 | Loss: 0.00001776
Iteration 27/1000 | Loss: 0.00001775
Iteration 28/1000 | Loss: 0.00001775
Iteration 29/1000 | Loss: 0.00001775
Iteration 30/1000 | Loss: 0.00001775
Iteration 31/1000 | Loss: 0.00001774
Iteration 32/1000 | Loss: 0.00001774
Iteration 33/1000 | Loss: 0.00001774
Iteration 34/1000 | Loss: 0.00001773
Iteration 35/1000 | Loss: 0.00001772
Iteration 36/1000 | Loss: 0.00001772
Iteration 37/1000 | Loss: 0.00001772
Iteration 38/1000 | Loss: 0.00001771
Iteration 39/1000 | Loss: 0.00001771
Iteration 40/1000 | Loss: 0.00001771
Iteration 41/1000 | Loss: 0.00001770
Iteration 42/1000 | Loss: 0.00001770
Iteration 43/1000 | Loss: 0.00001770
Iteration 44/1000 | Loss: 0.00001769
Iteration 45/1000 | Loss: 0.00001769
Iteration 46/1000 | Loss: 0.00001769
Iteration 47/1000 | Loss: 0.00001768
Iteration 48/1000 | Loss: 0.00001768
Iteration 49/1000 | Loss: 0.00001768
Iteration 50/1000 | Loss: 0.00001767
Iteration 51/1000 | Loss: 0.00001767
Iteration 52/1000 | Loss: 0.00005464
Iteration 53/1000 | Loss: 0.00005464
Iteration 54/1000 | Loss: 0.00002513
Iteration 55/1000 | Loss: 0.00001931
Iteration 56/1000 | Loss: 0.00001765
Iteration 57/1000 | Loss: 0.00001761
Iteration 58/1000 | Loss: 0.00001759
Iteration 59/1000 | Loss: 0.00001759
Iteration 60/1000 | Loss: 0.00001759
Iteration 61/1000 | Loss: 0.00001759
Iteration 62/1000 | Loss: 0.00001758
Iteration 63/1000 | Loss: 0.00001758
Iteration 64/1000 | Loss: 0.00001758
Iteration 65/1000 | Loss: 0.00001758
Iteration 66/1000 | Loss: 0.00001758
Iteration 67/1000 | Loss: 0.00001758
Iteration 68/1000 | Loss: 0.00001757
Iteration 69/1000 | Loss: 0.00001757
Iteration 70/1000 | Loss: 0.00001757
Iteration 71/1000 | Loss: 0.00001757
Iteration 72/1000 | Loss: 0.00001757
Iteration 73/1000 | Loss: 0.00001757
Iteration 74/1000 | Loss: 0.00001757
Iteration 75/1000 | Loss: 0.00001757
Iteration 76/1000 | Loss: 0.00001757
Iteration 77/1000 | Loss: 0.00001757
Iteration 78/1000 | Loss: 0.00001757
Iteration 79/1000 | Loss: 0.00001757
Iteration 80/1000 | Loss: 0.00001757
Iteration 81/1000 | Loss: 0.00001757
Iteration 82/1000 | Loss: 0.00001757
Iteration 83/1000 | Loss: 0.00001757
Iteration 84/1000 | Loss: 0.00001756
Iteration 85/1000 | Loss: 0.00001756
Iteration 86/1000 | Loss: 0.00001756
Iteration 87/1000 | Loss: 0.00001756
Iteration 88/1000 | Loss: 0.00001756
Iteration 89/1000 | Loss: 0.00001756
Iteration 90/1000 | Loss: 0.00001756
Iteration 91/1000 | Loss: 0.00001755
Iteration 92/1000 | Loss: 0.00001755
Iteration 93/1000 | Loss: 0.00001755
Iteration 94/1000 | Loss: 0.00001755
Iteration 95/1000 | Loss: 0.00001755
Iteration 96/1000 | Loss: 0.00001754
Iteration 97/1000 | Loss: 0.00001754
Iteration 98/1000 | Loss: 0.00001754
Iteration 99/1000 | Loss: 0.00001754
Iteration 100/1000 | Loss: 0.00001754
Iteration 101/1000 | Loss: 0.00001754
Iteration 102/1000 | Loss: 0.00001753
Iteration 103/1000 | Loss: 0.00001753
Iteration 104/1000 | Loss: 0.00001753
Iteration 105/1000 | Loss: 0.00001753
Iteration 106/1000 | Loss: 0.00001752
Iteration 107/1000 | Loss: 0.00001752
Iteration 108/1000 | Loss: 0.00001752
Iteration 109/1000 | Loss: 0.00001752
Iteration 110/1000 | Loss: 0.00001751
Iteration 111/1000 | Loss: 0.00001751
Iteration 112/1000 | Loss: 0.00001751
Iteration 113/1000 | Loss: 0.00001751
Iteration 114/1000 | Loss: 0.00001750
Iteration 115/1000 | Loss: 0.00001750
Iteration 116/1000 | Loss: 0.00001750
Iteration 117/1000 | Loss: 0.00001750
Iteration 118/1000 | Loss: 0.00006210
Iteration 119/1000 | Loss: 0.00002246
Iteration 120/1000 | Loss: 0.00001764
Iteration 121/1000 | Loss: 0.00001751
Iteration 122/1000 | Loss: 0.00001751
Iteration 123/1000 | Loss: 0.00001751
Iteration 124/1000 | Loss: 0.00001751
Iteration 125/1000 | Loss: 0.00001751
Iteration 126/1000 | Loss: 0.00001751
Iteration 127/1000 | Loss: 0.00001751
Iteration 128/1000 | Loss: 0.00001751
Iteration 129/1000 | Loss: 0.00001751
Iteration 130/1000 | Loss: 0.00001750
Iteration 131/1000 | Loss: 0.00001750
Iteration 132/1000 | Loss: 0.00001750
Iteration 133/1000 | Loss: 0.00001750
Iteration 134/1000 | Loss: 0.00005085
Iteration 135/1000 | Loss: 0.00002835
Iteration 136/1000 | Loss: 0.00001753
Iteration 137/1000 | Loss: 0.00003057
Iteration 138/1000 | Loss: 0.00002910
Iteration 139/1000 | Loss: 0.00002932
Iteration 140/1000 | Loss: 0.00004768
Iteration 141/1000 | Loss: 0.00002209
Iteration 142/1000 | Loss: 0.00001753
Iteration 143/1000 | Loss: 0.00004257
Iteration 144/1000 | Loss: 0.00002117
Iteration 145/1000 | Loss: 0.00001754
Iteration 146/1000 | Loss: 0.00001749
Iteration 147/1000 | Loss: 0.00001749
Iteration 148/1000 | Loss: 0.00001749
Iteration 149/1000 | Loss: 0.00001749
Iteration 150/1000 | Loss: 0.00001749
Iteration 151/1000 | Loss: 0.00001748
Iteration 152/1000 | Loss: 0.00001748
Iteration 153/1000 | Loss: 0.00001748
Iteration 154/1000 | Loss: 0.00001748
Iteration 155/1000 | Loss: 0.00001748
Iteration 156/1000 | Loss: 0.00001748
Iteration 157/1000 | Loss: 0.00001748
Iteration 158/1000 | Loss: 0.00001748
Iteration 159/1000 | Loss: 0.00001747
Iteration 160/1000 | Loss: 0.00001747
Iteration 161/1000 | Loss: 0.00001747
Iteration 162/1000 | Loss: 0.00001747
Iteration 163/1000 | Loss: 0.00001747
Iteration 164/1000 | Loss: 0.00001747
Iteration 165/1000 | Loss: 0.00001747
Iteration 166/1000 | Loss: 0.00001747
Iteration 167/1000 | Loss: 0.00001747
Iteration 168/1000 | Loss: 0.00001747
Iteration 169/1000 | Loss: 0.00001747
Iteration 170/1000 | Loss: 0.00001747
Iteration 171/1000 | Loss: 0.00001747
Iteration 172/1000 | Loss: 0.00001747
Iteration 173/1000 | Loss: 0.00001747
Iteration 174/1000 | Loss: 0.00001747
Iteration 175/1000 | Loss: 0.00001747
Iteration 176/1000 | Loss: 0.00001747
Iteration 177/1000 | Loss: 0.00001747
Iteration 178/1000 | Loss: 0.00001747
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [1.7468250007368624e-05, 1.7468250007368624e-05, 1.7468250007368624e-05, 1.7468250007368624e-05, 1.7468250007368624e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7468250007368624e-05

Optimization complete. Final v2v error: 3.6590285301208496 mm

Highest mean error: 4.352084159851074 mm for frame 16

Lowest mean error: 3.1658554077148438 mm for frame 232

Saving results

Total time: 79.97149705886841
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00428828
Iteration 2/25 | Loss: 0.00098237
Iteration 3/25 | Loss: 0.00087173
Iteration 4/25 | Loss: 0.00085879
Iteration 5/25 | Loss: 0.00085336
Iteration 6/25 | Loss: 0.00085226
Iteration 7/25 | Loss: 0.00085214
Iteration 8/25 | Loss: 0.00085214
Iteration 9/25 | Loss: 0.00085214
Iteration 10/25 | Loss: 0.00085214
Iteration 11/25 | Loss: 0.00085214
Iteration 12/25 | Loss: 0.00085214
Iteration 13/25 | Loss: 0.00085214
Iteration 14/25 | Loss: 0.00085214
Iteration 15/25 | Loss: 0.00085214
Iteration 16/25 | Loss: 0.00085214
Iteration 17/25 | Loss: 0.00085214
Iteration 18/25 | Loss: 0.00085214
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0008521386189386249, 0.0008521386189386249, 0.0008521386189386249, 0.0008521386189386249, 0.0008521386189386249]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008521386189386249

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51554430
Iteration 2/25 | Loss: 0.00076570
Iteration 3/25 | Loss: 0.00076570
Iteration 4/25 | Loss: 0.00076570
Iteration 5/25 | Loss: 0.00076570
Iteration 6/25 | Loss: 0.00076570
Iteration 7/25 | Loss: 0.00076570
Iteration 8/25 | Loss: 0.00076570
Iteration 9/25 | Loss: 0.00076570
Iteration 10/25 | Loss: 0.00076570
Iteration 11/25 | Loss: 0.00076570
Iteration 12/25 | Loss: 0.00076570
Iteration 13/25 | Loss: 0.00076570
Iteration 14/25 | Loss: 0.00076570
Iteration 15/25 | Loss: 0.00076570
Iteration 16/25 | Loss: 0.00076570
Iteration 17/25 | Loss: 0.00076570
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007656996604055166, 0.0007656996604055166, 0.0007656996604055166, 0.0007656996604055166, 0.0007656996604055166]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007656996604055166

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00076570
Iteration 2/1000 | Loss: 0.00002331
Iteration 3/1000 | Loss: 0.00001816
Iteration 4/1000 | Loss: 0.00001738
Iteration 5/1000 | Loss: 0.00001685
Iteration 6/1000 | Loss: 0.00001646
Iteration 7/1000 | Loss: 0.00001635
Iteration 8/1000 | Loss: 0.00001630
Iteration 9/1000 | Loss: 0.00001618
Iteration 10/1000 | Loss: 0.00001618
Iteration 11/1000 | Loss: 0.00001618
Iteration 12/1000 | Loss: 0.00001617
Iteration 13/1000 | Loss: 0.00001617
Iteration 14/1000 | Loss: 0.00001616
Iteration 15/1000 | Loss: 0.00001614
Iteration 16/1000 | Loss: 0.00001614
Iteration 17/1000 | Loss: 0.00001613
Iteration 18/1000 | Loss: 0.00001612
Iteration 19/1000 | Loss: 0.00001612
Iteration 20/1000 | Loss: 0.00001611
Iteration 21/1000 | Loss: 0.00001611
Iteration 22/1000 | Loss: 0.00001611
Iteration 23/1000 | Loss: 0.00001611
Iteration 24/1000 | Loss: 0.00001610
Iteration 25/1000 | Loss: 0.00001610
Iteration 26/1000 | Loss: 0.00001610
Iteration 27/1000 | Loss: 0.00001609
Iteration 28/1000 | Loss: 0.00001608
Iteration 29/1000 | Loss: 0.00001607
Iteration 30/1000 | Loss: 0.00001606
Iteration 31/1000 | Loss: 0.00001605
Iteration 32/1000 | Loss: 0.00001605
Iteration 33/1000 | Loss: 0.00001605
Iteration 34/1000 | Loss: 0.00001604
Iteration 35/1000 | Loss: 0.00001604
Iteration 36/1000 | Loss: 0.00001604
Iteration 37/1000 | Loss: 0.00001603
Iteration 38/1000 | Loss: 0.00001603
Iteration 39/1000 | Loss: 0.00001603
Iteration 40/1000 | Loss: 0.00001602
Iteration 41/1000 | Loss: 0.00001602
Iteration 42/1000 | Loss: 0.00001602
Iteration 43/1000 | Loss: 0.00001601
Iteration 44/1000 | Loss: 0.00001601
Iteration 45/1000 | Loss: 0.00001600
Iteration 46/1000 | Loss: 0.00001599
Iteration 47/1000 | Loss: 0.00001599
Iteration 48/1000 | Loss: 0.00001598
Iteration 49/1000 | Loss: 0.00001598
Iteration 50/1000 | Loss: 0.00001598
Iteration 51/1000 | Loss: 0.00001597
Iteration 52/1000 | Loss: 0.00001597
Iteration 53/1000 | Loss: 0.00001597
Iteration 54/1000 | Loss: 0.00001597
Iteration 55/1000 | Loss: 0.00001597
Iteration 56/1000 | Loss: 0.00001596
Iteration 57/1000 | Loss: 0.00001596
Iteration 58/1000 | Loss: 0.00001596
Iteration 59/1000 | Loss: 0.00001596
Iteration 60/1000 | Loss: 0.00001595
Iteration 61/1000 | Loss: 0.00001595
Iteration 62/1000 | Loss: 0.00001595
Iteration 63/1000 | Loss: 0.00001595
Iteration 64/1000 | Loss: 0.00001595
Iteration 65/1000 | Loss: 0.00001595
Iteration 66/1000 | Loss: 0.00001595
Iteration 67/1000 | Loss: 0.00001595
Iteration 68/1000 | Loss: 0.00001595
Iteration 69/1000 | Loss: 0.00001594
Iteration 70/1000 | Loss: 0.00001594
Iteration 71/1000 | Loss: 0.00001594
Iteration 72/1000 | Loss: 0.00001593
Iteration 73/1000 | Loss: 0.00001593
Iteration 74/1000 | Loss: 0.00001593
Iteration 75/1000 | Loss: 0.00001593
Iteration 76/1000 | Loss: 0.00001593
Iteration 77/1000 | Loss: 0.00001593
Iteration 78/1000 | Loss: 0.00001593
Iteration 79/1000 | Loss: 0.00001592
Iteration 80/1000 | Loss: 0.00001592
Iteration 81/1000 | Loss: 0.00001592
Iteration 82/1000 | Loss: 0.00001592
Iteration 83/1000 | Loss: 0.00001592
Iteration 84/1000 | Loss: 0.00001592
Iteration 85/1000 | Loss: 0.00001592
Iteration 86/1000 | Loss: 0.00001591
Iteration 87/1000 | Loss: 0.00001591
Iteration 88/1000 | Loss: 0.00001591
Iteration 89/1000 | Loss: 0.00001591
Iteration 90/1000 | Loss: 0.00001591
Iteration 91/1000 | Loss: 0.00001591
Iteration 92/1000 | Loss: 0.00001591
Iteration 93/1000 | Loss: 0.00001591
Iteration 94/1000 | Loss: 0.00001591
Iteration 95/1000 | Loss: 0.00001591
Iteration 96/1000 | Loss: 0.00001591
Iteration 97/1000 | Loss: 0.00001591
Iteration 98/1000 | Loss: 0.00001591
Iteration 99/1000 | Loss: 0.00001591
Iteration 100/1000 | Loss: 0.00001591
Iteration 101/1000 | Loss: 0.00001590
Iteration 102/1000 | Loss: 0.00001590
Iteration 103/1000 | Loss: 0.00001590
Iteration 104/1000 | Loss: 0.00001590
Iteration 105/1000 | Loss: 0.00001590
Iteration 106/1000 | Loss: 0.00001590
Iteration 107/1000 | Loss: 0.00001590
Iteration 108/1000 | Loss: 0.00001590
Iteration 109/1000 | Loss: 0.00001590
Iteration 110/1000 | Loss: 0.00001590
Iteration 111/1000 | Loss: 0.00001590
Iteration 112/1000 | Loss: 0.00001590
Iteration 113/1000 | Loss: 0.00001590
Iteration 114/1000 | Loss: 0.00001590
Iteration 115/1000 | Loss: 0.00001590
Iteration 116/1000 | Loss: 0.00001590
Iteration 117/1000 | Loss: 0.00001590
Iteration 118/1000 | Loss: 0.00001589
Iteration 119/1000 | Loss: 0.00001589
Iteration 120/1000 | Loss: 0.00001589
Iteration 121/1000 | Loss: 0.00001589
Iteration 122/1000 | Loss: 0.00001589
Iteration 123/1000 | Loss: 0.00001589
Iteration 124/1000 | Loss: 0.00001589
Iteration 125/1000 | Loss: 0.00001589
Iteration 126/1000 | Loss: 0.00001589
Iteration 127/1000 | Loss: 0.00001589
Iteration 128/1000 | Loss: 0.00001589
Iteration 129/1000 | Loss: 0.00001589
Iteration 130/1000 | Loss: 0.00001589
Iteration 131/1000 | Loss: 0.00001589
Iteration 132/1000 | Loss: 0.00001589
Iteration 133/1000 | Loss: 0.00001589
Iteration 134/1000 | Loss: 0.00001589
Iteration 135/1000 | Loss: 0.00001589
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [1.5888548659859225e-05, 1.5888548659859225e-05, 1.5888548659859225e-05, 1.5888548659859225e-05, 1.5888548659859225e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5888548659859225e-05

Optimization complete. Final v2v error: 3.5100619792938232 mm

Highest mean error: 3.704864025115967 mm for frame 33

Lowest mean error: 3.330064535140991 mm for frame 21

Saving results

Total time: 27.46312713623047
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01125549
Iteration 2/25 | Loss: 0.01125549
Iteration 3/25 | Loss: 0.00207141
Iteration 4/25 | Loss: 0.00162695
Iteration 5/25 | Loss: 0.00133551
Iteration 6/25 | Loss: 0.00123232
Iteration 7/25 | Loss: 0.00113921
Iteration 8/25 | Loss: 0.00112578
Iteration 9/25 | Loss: 0.00113320
Iteration 10/25 | Loss: 0.00111974
Iteration 11/25 | Loss: 0.00109796
Iteration 12/25 | Loss: 0.00109767
Iteration 13/25 | Loss: 0.00109214
Iteration 14/25 | Loss: 0.00109213
Iteration 15/25 | Loss: 0.00108425
Iteration 16/25 | Loss: 0.00108133
Iteration 17/25 | Loss: 0.00106365
Iteration 18/25 | Loss: 0.00106900
Iteration 19/25 | Loss: 0.00107156
Iteration 20/25 | Loss: 0.00105378
Iteration 21/25 | Loss: 0.00103614
Iteration 22/25 | Loss: 0.00101936
Iteration 23/25 | Loss: 0.00100942
Iteration 24/25 | Loss: 0.00100612
Iteration 25/25 | Loss: 0.00100487

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56306016
Iteration 2/25 | Loss: 0.00133782
Iteration 3/25 | Loss: 0.00133782
Iteration 4/25 | Loss: 0.00133782
Iteration 5/25 | Loss: 0.00133781
Iteration 6/25 | Loss: 0.00133781
Iteration 7/25 | Loss: 0.00133781
Iteration 8/25 | Loss: 0.00133781
Iteration 9/25 | Loss: 0.00133781
Iteration 10/25 | Loss: 0.00133781
Iteration 11/25 | Loss: 0.00133781
Iteration 12/25 | Loss: 0.00133781
Iteration 13/25 | Loss: 0.00133781
Iteration 14/25 | Loss: 0.00133781
Iteration 15/25 | Loss: 0.00133781
Iteration 16/25 | Loss: 0.00133781
Iteration 17/25 | Loss: 0.00133781
Iteration 18/25 | Loss: 0.00133781
Iteration 19/25 | Loss: 0.00133781
Iteration 20/25 | Loss: 0.00133781
Iteration 21/25 | Loss: 0.00133781
Iteration 22/25 | Loss: 0.00133781
Iteration 23/25 | Loss: 0.00133781
Iteration 24/25 | Loss: 0.00133781
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0013378135627135634, 0.0013378135627135634, 0.0013378135627135634, 0.0013378135627135634, 0.0013378135627135634]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013378135627135634

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00133781
Iteration 2/1000 | Loss: 0.00009151
Iteration 3/1000 | Loss: 0.00006852
Iteration 4/1000 | Loss: 0.00067519
Iteration 5/1000 | Loss: 0.00025777
Iteration 6/1000 | Loss: 0.00006375
Iteration 7/1000 | Loss: 0.00005715
Iteration 8/1000 | Loss: 0.00005135
Iteration 9/1000 | Loss: 0.00004717
Iteration 10/1000 | Loss: 0.00029601
Iteration 11/1000 | Loss: 0.00005153
Iteration 12/1000 | Loss: 0.00004629
Iteration 13/1000 | Loss: 0.00004330
Iteration 14/1000 | Loss: 0.00004148
Iteration 15/1000 | Loss: 0.00004055
Iteration 16/1000 | Loss: 0.00003996
Iteration 17/1000 | Loss: 0.00003966
Iteration 18/1000 | Loss: 0.00003932
Iteration 19/1000 | Loss: 0.00003903
Iteration 20/1000 | Loss: 0.00003881
Iteration 21/1000 | Loss: 0.00003880
Iteration 22/1000 | Loss: 0.00003880
Iteration 23/1000 | Loss: 0.00003878
Iteration 24/1000 | Loss: 0.00003877
Iteration 25/1000 | Loss: 0.00003876
Iteration 26/1000 | Loss: 0.00003875
Iteration 27/1000 | Loss: 0.00003874
Iteration 28/1000 | Loss: 0.00003873
Iteration 29/1000 | Loss: 0.00003873
Iteration 30/1000 | Loss: 0.00003872
Iteration 31/1000 | Loss: 0.00003871
Iteration 32/1000 | Loss: 0.00003871
Iteration 33/1000 | Loss: 0.00003870
Iteration 34/1000 | Loss: 0.00003870
Iteration 35/1000 | Loss: 0.00003869
Iteration 36/1000 | Loss: 0.00003868
Iteration 37/1000 | Loss: 0.00003860
Iteration 38/1000 | Loss: 0.00003854
Iteration 39/1000 | Loss: 0.00003851
Iteration 40/1000 | Loss: 0.00003849
Iteration 41/1000 | Loss: 0.00003847
Iteration 42/1000 | Loss: 0.00003847
Iteration 43/1000 | Loss: 0.00003847
Iteration 44/1000 | Loss: 0.00003847
Iteration 45/1000 | Loss: 0.00003847
Iteration 46/1000 | Loss: 0.00003847
Iteration 47/1000 | Loss: 0.00003847
Iteration 48/1000 | Loss: 0.00003846
Iteration 49/1000 | Loss: 0.00003846
Iteration 50/1000 | Loss: 0.00003846
Iteration 51/1000 | Loss: 0.00003846
Iteration 52/1000 | Loss: 0.00003846
Iteration 53/1000 | Loss: 0.00003846
Iteration 54/1000 | Loss: 0.00003846
Iteration 55/1000 | Loss: 0.00003846
Iteration 56/1000 | Loss: 0.00003846
Iteration 57/1000 | Loss: 0.00003845
Iteration 58/1000 | Loss: 0.00003845
Iteration 59/1000 | Loss: 0.00003843
Iteration 60/1000 | Loss: 0.00003843
Iteration 61/1000 | Loss: 0.00003843
Iteration 62/1000 | Loss: 0.00003842
Iteration 63/1000 | Loss: 0.00003842
Iteration 64/1000 | Loss: 0.00003842
Iteration 65/1000 | Loss: 0.00003842
Iteration 66/1000 | Loss: 0.00003841
Iteration 67/1000 | Loss: 0.00003840
Iteration 68/1000 | Loss: 0.00003840
Iteration 69/1000 | Loss: 0.00003839
Iteration 70/1000 | Loss: 0.00003839
Iteration 71/1000 | Loss: 0.00003839
Iteration 72/1000 | Loss: 0.00003838
Iteration 73/1000 | Loss: 0.00003838
Iteration 74/1000 | Loss: 0.00003838
Iteration 75/1000 | Loss: 0.00003837
Iteration 76/1000 | Loss: 0.00003837
Iteration 77/1000 | Loss: 0.00003837
Iteration 78/1000 | Loss: 0.00003836
Iteration 79/1000 | Loss: 0.00003836
Iteration 80/1000 | Loss: 0.00003835
Iteration 81/1000 | Loss: 0.00003835
Iteration 82/1000 | Loss: 0.00003835
Iteration 83/1000 | Loss: 0.00003834
Iteration 84/1000 | Loss: 0.00003834
Iteration 85/1000 | Loss: 0.00003834
Iteration 86/1000 | Loss: 0.00003834
Iteration 87/1000 | Loss: 0.00003834
Iteration 88/1000 | Loss: 0.00003834
Iteration 89/1000 | Loss: 0.00003834
Iteration 90/1000 | Loss: 0.00003833
Iteration 91/1000 | Loss: 0.00003833
Iteration 92/1000 | Loss: 0.00003833
Iteration 93/1000 | Loss: 0.00003833
Iteration 94/1000 | Loss: 0.00003833
Iteration 95/1000 | Loss: 0.00003833
Iteration 96/1000 | Loss: 0.00003833
Iteration 97/1000 | Loss: 0.00003832
Iteration 98/1000 | Loss: 0.00003832
Iteration 99/1000 | Loss: 0.00003832
Iteration 100/1000 | Loss: 0.00003832
Iteration 101/1000 | Loss: 0.00003832
Iteration 102/1000 | Loss: 0.00003832
Iteration 103/1000 | Loss: 0.00003832
Iteration 104/1000 | Loss: 0.00003832
Iteration 105/1000 | Loss: 0.00003832
Iteration 106/1000 | Loss: 0.00003832
Iteration 107/1000 | Loss: 0.00003832
Iteration 108/1000 | Loss: 0.00003832
Iteration 109/1000 | Loss: 0.00003832
Iteration 110/1000 | Loss: 0.00003832
Iteration 111/1000 | Loss: 0.00003832
Iteration 112/1000 | Loss: 0.00003832
Iteration 113/1000 | Loss: 0.00003832
Iteration 114/1000 | Loss: 0.00003832
Iteration 115/1000 | Loss: 0.00003831
Iteration 116/1000 | Loss: 0.00003831
Iteration 117/1000 | Loss: 0.00003831
Iteration 118/1000 | Loss: 0.00003831
Iteration 119/1000 | Loss: 0.00003831
Iteration 120/1000 | Loss: 0.00003831
Iteration 121/1000 | Loss: 0.00003831
Iteration 122/1000 | Loss: 0.00003831
Iteration 123/1000 | Loss: 0.00003831
Iteration 124/1000 | Loss: 0.00003831
Iteration 125/1000 | Loss: 0.00003831
Iteration 126/1000 | Loss: 0.00003831
Iteration 127/1000 | Loss: 0.00003831
Iteration 128/1000 | Loss: 0.00003831
Iteration 129/1000 | Loss: 0.00003830
Iteration 130/1000 | Loss: 0.00003830
Iteration 131/1000 | Loss: 0.00003830
Iteration 132/1000 | Loss: 0.00003830
Iteration 133/1000 | Loss: 0.00003830
Iteration 134/1000 | Loss: 0.00003830
Iteration 135/1000 | Loss: 0.00003830
Iteration 136/1000 | Loss: 0.00003830
Iteration 137/1000 | Loss: 0.00003830
Iteration 138/1000 | Loss: 0.00003830
Iteration 139/1000 | Loss: 0.00003830
Iteration 140/1000 | Loss: 0.00003830
Iteration 141/1000 | Loss: 0.00003830
Iteration 142/1000 | Loss: 0.00003830
Iteration 143/1000 | Loss: 0.00003830
Iteration 144/1000 | Loss: 0.00003830
Iteration 145/1000 | Loss: 0.00003830
Iteration 146/1000 | Loss: 0.00003830
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 146. Stopping optimization.
Last 5 losses: [3.8303278415696695e-05, 3.8303278415696695e-05, 3.8303278415696695e-05, 3.8303278415696695e-05, 3.8303278415696695e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.8303278415696695e-05

Optimization complete. Final v2v error: 4.465704917907715 mm

Highest mean error: 22.402856826782227 mm for frame 77

Lowest mean error: 3.5848894119262695 mm for frame 153

Saving results

Total time: 87.2278790473938
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00416523
Iteration 2/25 | Loss: 0.00102474
Iteration 3/25 | Loss: 0.00092996
Iteration 4/25 | Loss: 0.00090479
Iteration 5/25 | Loss: 0.00089693
Iteration 6/25 | Loss: 0.00089476
Iteration 7/25 | Loss: 0.00089458
Iteration 8/25 | Loss: 0.00089458
Iteration 9/25 | Loss: 0.00089458
Iteration 10/25 | Loss: 0.00089458
Iteration 11/25 | Loss: 0.00089447
Iteration 12/25 | Loss: 0.00089447
Iteration 13/25 | Loss: 0.00089447
Iteration 14/25 | Loss: 0.00089447
Iteration 15/25 | Loss: 0.00089447
Iteration 16/25 | Loss: 0.00089447
Iteration 17/25 | Loss: 0.00089447
Iteration 18/25 | Loss: 0.00089447
Iteration 19/25 | Loss: 0.00089447
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0008944685105234385, 0.0008944685105234385, 0.0008944685105234385, 0.0008944685105234385, 0.0008944685105234385]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008944685105234385

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.97463012
Iteration 2/25 | Loss: 0.00074046
Iteration 3/25 | Loss: 0.00074046
Iteration 4/25 | Loss: 0.00074046
Iteration 5/25 | Loss: 0.00074046
Iteration 6/25 | Loss: 0.00074046
Iteration 7/25 | Loss: 0.00074046
Iteration 8/25 | Loss: 0.00074046
Iteration 9/25 | Loss: 0.00074046
Iteration 10/25 | Loss: 0.00074046
Iteration 11/25 | Loss: 0.00074046
Iteration 12/25 | Loss: 0.00074046
Iteration 13/25 | Loss: 0.00074046
Iteration 14/25 | Loss: 0.00074046
Iteration 15/25 | Loss: 0.00074046
Iteration 16/25 | Loss: 0.00074046
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007404551724903286, 0.0007404551724903286, 0.0007404551724903286, 0.0007404551724903286, 0.0007404551724903286]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007404551724903286

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00074046
Iteration 2/1000 | Loss: 0.00002243
Iteration 3/1000 | Loss: 0.00001831
Iteration 4/1000 | Loss: 0.00001725
Iteration 5/1000 | Loss: 0.00001659
Iteration 6/1000 | Loss: 0.00001606
Iteration 7/1000 | Loss: 0.00001584
Iteration 8/1000 | Loss: 0.00001568
Iteration 9/1000 | Loss: 0.00001568
Iteration 10/1000 | Loss: 0.00001568
Iteration 11/1000 | Loss: 0.00001568
Iteration 12/1000 | Loss: 0.00001568
Iteration 13/1000 | Loss: 0.00001568
Iteration 14/1000 | Loss: 0.00001568
Iteration 15/1000 | Loss: 0.00001567
Iteration 16/1000 | Loss: 0.00001567
Iteration 17/1000 | Loss: 0.00001567
Iteration 18/1000 | Loss: 0.00001567
Iteration 19/1000 | Loss: 0.00001567
Iteration 20/1000 | Loss: 0.00001566
Iteration 21/1000 | Loss: 0.00001565
Iteration 22/1000 | Loss: 0.00001565
Iteration 23/1000 | Loss: 0.00001565
Iteration 24/1000 | Loss: 0.00001564
Iteration 25/1000 | Loss: 0.00001564
Iteration 26/1000 | Loss: 0.00001564
Iteration 27/1000 | Loss: 0.00001564
Iteration 28/1000 | Loss: 0.00001563
Iteration 29/1000 | Loss: 0.00001563
Iteration 30/1000 | Loss: 0.00001562
Iteration 31/1000 | Loss: 0.00001562
Iteration 32/1000 | Loss: 0.00001562
Iteration 33/1000 | Loss: 0.00001562
Iteration 34/1000 | Loss: 0.00001562
Iteration 35/1000 | Loss: 0.00001561
Iteration 36/1000 | Loss: 0.00001561
Iteration 37/1000 | Loss: 0.00001561
Iteration 38/1000 | Loss: 0.00001560
Iteration 39/1000 | Loss: 0.00001560
Iteration 40/1000 | Loss: 0.00001560
Iteration 41/1000 | Loss: 0.00001559
Iteration 42/1000 | Loss: 0.00001559
Iteration 43/1000 | Loss: 0.00001559
Iteration 44/1000 | Loss: 0.00001557
Iteration 45/1000 | Loss: 0.00001557
Iteration 46/1000 | Loss: 0.00001557
Iteration 47/1000 | Loss: 0.00001557
Iteration 48/1000 | Loss: 0.00001557
Iteration 49/1000 | Loss: 0.00001557
Iteration 50/1000 | Loss: 0.00001557
Iteration 51/1000 | Loss: 0.00001557
Iteration 52/1000 | Loss: 0.00001557
Iteration 53/1000 | Loss: 0.00001557
Iteration 54/1000 | Loss: 0.00001557
Iteration 55/1000 | Loss: 0.00001557
Iteration 56/1000 | Loss: 0.00001556
Iteration 57/1000 | Loss: 0.00001556
Iteration 58/1000 | Loss: 0.00001556
Iteration 59/1000 | Loss: 0.00001556
Iteration 60/1000 | Loss: 0.00001556
Iteration 61/1000 | Loss: 0.00001556
Iteration 62/1000 | Loss: 0.00001556
Iteration 63/1000 | Loss: 0.00001556
Iteration 64/1000 | Loss: 0.00001556
Iteration 65/1000 | Loss: 0.00001556
Iteration 66/1000 | Loss: 0.00001556
Iteration 67/1000 | Loss: 0.00001556
Iteration 68/1000 | Loss: 0.00001556
Iteration 69/1000 | Loss: 0.00001556
Iteration 70/1000 | Loss: 0.00001556
Iteration 71/1000 | Loss: 0.00001556
Iteration 72/1000 | Loss: 0.00001556
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [1.555587732582353e-05, 1.555587732582353e-05, 1.555587732582353e-05, 1.555587732582353e-05, 1.555587732582353e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.555587732582353e-05

Optimization complete. Final v2v error: 3.385910987854004 mm

Highest mean error: 3.6620137691497803 mm for frame 218

Lowest mean error: 2.9899001121520996 mm for frame 74

Saving results

Total time: 27.972840785980225
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01185919
Iteration 2/25 | Loss: 0.00350278
Iteration 3/25 | Loss: 0.00219808
Iteration 4/25 | Loss: 0.00129324
Iteration 5/25 | Loss: 0.00117273
Iteration 6/25 | Loss: 0.00121398
Iteration 7/25 | Loss: 0.00117814
Iteration 8/25 | Loss: 0.00118311
Iteration 9/25 | Loss: 0.00112226
Iteration 10/25 | Loss: 0.00110389
Iteration 11/25 | Loss: 0.00109396
Iteration 12/25 | Loss: 0.00109149
Iteration 13/25 | Loss: 0.00109450
Iteration 14/25 | Loss: 0.00109286
Iteration 15/25 | Loss: 0.00110975
Iteration 16/25 | Loss: 0.00111668
Iteration 17/25 | Loss: 0.00111948
Iteration 18/25 | Loss: 0.00112195
Iteration 19/25 | Loss: 0.00110850
Iteration 20/25 | Loss: 0.00108812
Iteration 21/25 | Loss: 0.00108345
Iteration 22/25 | Loss: 0.00107696
Iteration 23/25 | Loss: 0.00107559
Iteration 24/25 | Loss: 0.00107760
Iteration 25/25 | Loss: 0.00107731

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.97290730
Iteration 2/25 | Loss: 0.00085547
Iteration 3/25 | Loss: 0.00085547
Iteration 4/25 | Loss: 0.00085547
Iteration 5/25 | Loss: 0.00085547
Iteration 6/25 | Loss: 0.00085547
Iteration 7/25 | Loss: 0.00085547
Iteration 8/25 | Loss: 0.00085547
Iteration 9/25 | Loss: 0.00085547
Iteration 10/25 | Loss: 0.00085547
Iteration 11/25 | Loss: 0.00085547
Iteration 12/25 | Loss: 0.00085547
Iteration 13/25 | Loss: 0.00085547
Iteration 14/25 | Loss: 0.00085547
Iteration 15/25 | Loss: 0.00085547
Iteration 16/25 | Loss: 0.00085547
Iteration 17/25 | Loss: 0.00085547
Iteration 18/25 | Loss: 0.00085547
Iteration 19/25 | Loss: 0.00085547
Iteration 20/25 | Loss: 0.00085547
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0008554672822356224, 0.0008554672822356224, 0.0008554672822356224, 0.0008554672822356224, 0.0008554672822356224]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008554672822356224

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085547
Iteration 2/1000 | Loss: 0.00009626
Iteration 3/1000 | Loss: 0.00030279
Iteration 4/1000 | Loss: 0.00023095
Iteration 5/1000 | Loss: 0.00024305
Iteration 6/1000 | Loss: 0.00007824
Iteration 7/1000 | Loss: 0.00007895
Iteration 8/1000 | Loss: 0.00043857
Iteration 9/1000 | Loss: 0.00033835
Iteration 10/1000 | Loss: 0.00041054
Iteration 11/1000 | Loss: 0.00016913
Iteration 12/1000 | Loss: 0.00019694
Iteration 13/1000 | Loss: 0.00079529
Iteration 14/1000 | Loss: 0.00006192
Iteration 15/1000 | Loss: 0.00006711
Iteration 16/1000 | Loss: 0.00006278
Iteration 17/1000 | Loss: 0.00007355
Iteration 18/1000 | Loss: 0.00005082
Iteration 19/1000 | Loss: 0.00005193
Iteration 20/1000 | Loss: 0.00005520
Iteration 21/1000 | Loss: 0.00007737
Iteration 22/1000 | Loss: 0.00004792
Iteration 23/1000 | Loss: 0.00048634
Iteration 24/1000 | Loss: 0.00024596
Iteration 25/1000 | Loss: 0.00043139
Iteration 26/1000 | Loss: 0.00038105
Iteration 27/1000 | Loss: 0.00004175
Iteration 28/1000 | Loss: 0.00041918
Iteration 29/1000 | Loss: 0.00035535
Iteration 30/1000 | Loss: 0.00019747
Iteration 31/1000 | Loss: 0.00005232
Iteration 32/1000 | Loss: 0.00028024
Iteration 33/1000 | Loss: 0.00019355
Iteration 34/1000 | Loss: 0.00004833
Iteration 35/1000 | Loss: 0.00004513
Iteration 36/1000 | Loss: 0.00004386
Iteration 37/1000 | Loss: 0.00004275
Iteration 38/1000 | Loss: 0.00029159
Iteration 39/1000 | Loss: 0.00010827
Iteration 40/1000 | Loss: 0.00026431
Iteration 41/1000 | Loss: 0.00009648
Iteration 42/1000 | Loss: 0.00023458
Iteration 43/1000 | Loss: 0.00005613
Iteration 44/1000 | Loss: 0.00004883
Iteration 45/1000 | Loss: 0.00040739
Iteration 46/1000 | Loss: 0.00004309
Iteration 47/1000 | Loss: 0.00004183
Iteration 48/1000 | Loss: 0.00003958
Iteration 49/1000 | Loss: 0.00003791
Iteration 50/1000 | Loss: 0.00003724
Iteration 51/1000 | Loss: 0.00003651
Iteration 52/1000 | Loss: 0.00003625
Iteration 53/1000 | Loss: 0.00003625
Iteration 54/1000 | Loss: 0.00003621
Iteration 55/1000 | Loss: 0.00003620
Iteration 56/1000 | Loss: 0.00003618
Iteration 57/1000 | Loss: 0.00003617
Iteration 58/1000 | Loss: 0.00003608
Iteration 59/1000 | Loss: 0.00003604
Iteration 60/1000 | Loss: 0.00003603
Iteration 61/1000 | Loss: 0.00003602
Iteration 62/1000 | Loss: 0.00003600
Iteration 63/1000 | Loss: 0.00003600
Iteration 64/1000 | Loss: 0.00003596
Iteration 65/1000 | Loss: 0.00003596
Iteration 66/1000 | Loss: 0.00003595
Iteration 67/1000 | Loss: 0.00003595
Iteration 68/1000 | Loss: 0.00003594
Iteration 69/1000 | Loss: 0.00003594
Iteration 70/1000 | Loss: 0.00003594
Iteration 71/1000 | Loss: 0.00003594
Iteration 72/1000 | Loss: 0.00003593
Iteration 73/1000 | Loss: 0.00003593
Iteration 74/1000 | Loss: 0.00003593
Iteration 75/1000 | Loss: 0.00003593
Iteration 76/1000 | Loss: 0.00003593
Iteration 77/1000 | Loss: 0.00003593
Iteration 78/1000 | Loss: 0.00003593
Iteration 79/1000 | Loss: 0.00003593
Iteration 80/1000 | Loss: 0.00003593
Iteration 81/1000 | Loss: 0.00003593
Iteration 82/1000 | Loss: 0.00003593
Iteration 83/1000 | Loss: 0.00003593
Iteration 84/1000 | Loss: 0.00003593
Iteration 85/1000 | Loss: 0.00003592
Iteration 86/1000 | Loss: 0.00003592
Iteration 87/1000 | Loss: 0.00003592
Iteration 88/1000 | Loss: 0.00003592
Iteration 89/1000 | Loss: 0.00003592
Iteration 90/1000 | Loss: 0.00003592
Iteration 91/1000 | Loss: 0.00003592
Iteration 92/1000 | Loss: 0.00003592
Iteration 93/1000 | Loss: 0.00003592
Iteration 94/1000 | Loss: 0.00003592
Iteration 95/1000 | Loss: 0.00003591
Iteration 96/1000 | Loss: 0.00003591
Iteration 97/1000 | Loss: 0.00003591
Iteration 98/1000 | Loss: 0.00003591
Iteration 99/1000 | Loss: 0.00003591
Iteration 100/1000 | Loss: 0.00003591
Iteration 101/1000 | Loss: 0.00003591
Iteration 102/1000 | Loss: 0.00003591
Iteration 103/1000 | Loss: 0.00003591
Iteration 104/1000 | Loss: 0.00003590
Iteration 105/1000 | Loss: 0.00003590
Iteration 106/1000 | Loss: 0.00003590
Iteration 107/1000 | Loss: 0.00003590
Iteration 108/1000 | Loss: 0.00003590
Iteration 109/1000 | Loss: 0.00003590
Iteration 110/1000 | Loss: 0.00003589
Iteration 111/1000 | Loss: 0.00003589
Iteration 112/1000 | Loss: 0.00003589
Iteration 113/1000 | Loss: 0.00003589
Iteration 114/1000 | Loss: 0.00003589
Iteration 115/1000 | Loss: 0.00003589
Iteration 116/1000 | Loss: 0.00003589
Iteration 117/1000 | Loss: 0.00003589
Iteration 118/1000 | Loss: 0.00003589
Iteration 119/1000 | Loss: 0.00003589
Iteration 120/1000 | Loss: 0.00003588
Iteration 121/1000 | Loss: 0.00003588
Iteration 122/1000 | Loss: 0.00003588
Iteration 123/1000 | Loss: 0.00003588
Iteration 124/1000 | Loss: 0.00003588
Iteration 125/1000 | Loss: 0.00003588
Iteration 126/1000 | Loss: 0.00003587
Iteration 127/1000 | Loss: 0.00003587
Iteration 128/1000 | Loss: 0.00003587
Iteration 129/1000 | Loss: 0.00003587
Iteration 130/1000 | Loss: 0.00003587
Iteration 131/1000 | Loss: 0.00003587
Iteration 132/1000 | Loss: 0.00003587
Iteration 133/1000 | Loss: 0.00003587
Iteration 134/1000 | Loss: 0.00003586
Iteration 135/1000 | Loss: 0.00003586
Iteration 136/1000 | Loss: 0.00003586
Iteration 137/1000 | Loss: 0.00003586
Iteration 138/1000 | Loss: 0.00003586
Iteration 139/1000 | Loss: 0.00003586
Iteration 140/1000 | Loss: 0.00003586
Iteration 141/1000 | Loss: 0.00003586
Iteration 142/1000 | Loss: 0.00003586
Iteration 143/1000 | Loss: 0.00003586
Iteration 144/1000 | Loss: 0.00003586
Iteration 145/1000 | Loss: 0.00003586
Iteration 146/1000 | Loss: 0.00003586
Iteration 147/1000 | Loss: 0.00003586
Iteration 148/1000 | Loss: 0.00003586
Iteration 149/1000 | Loss: 0.00003586
Iteration 150/1000 | Loss: 0.00003586
Iteration 151/1000 | Loss: 0.00003586
Iteration 152/1000 | Loss: 0.00003586
Iteration 153/1000 | Loss: 0.00003586
Iteration 154/1000 | Loss: 0.00003586
Iteration 155/1000 | Loss: 0.00003586
Iteration 156/1000 | Loss: 0.00003586
Iteration 157/1000 | Loss: 0.00003586
Iteration 158/1000 | Loss: 0.00003586
Iteration 159/1000 | Loss: 0.00003586
Iteration 160/1000 | Loss: 0.00003586
Iteration 161/1000 | Loss: 0.00003586
Iteration 162/1000 | Loss: 0.00003586
Iteration 163/1000 | Loss: 0.00003586
Iteration 164/1000 | Loss: 0.00003586
Iteration 165/1000 | Loss: 0.00003586
Iteration 166/1000 | Loss: 0.00003586
Iteration 167/1000 | Loss: 0.00003586
Iteration 168/1000 | Loss: 0.00003586
Iteration 169/1000 | Loss: 0.00003586
Iteration 170/1000 | Loss: 0.00003586
Iteration 171/1000 | Loss: 0.00003586
Iteration 172/1000 | Loss: 0.00003586
Iteration 173/1000 | Loss: 0.00003586
Iteration 174/1000 | Loss: 0.00003586
Iteration 175/1000 | Loss: 0.00003586
Iteration 176/1000 | Loss: 0.00003586
Iteration 177/1000 | Loss: 0.00003586
Iteration 178/1000 | Loss: 0.00003586
Iteration 179/1000 | Loss: 0.00003586
Iteration 180/1000 | Loss: 0.00003586
Iteration 181/1000 | Loss: 0.00003586
Iteration 182/1000 | Loss: 0.00003586
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 182. Stopping optimization.
Last 5 losses: [3.585877493605949e-05, 3.585877493605949e-05, 3.585877493605949e-05, 3.585877493605949e-05, 3.585877493605949e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.585877493605949e-05

Optimization complete. Final v2v error: 4.94228458404541 mm

Highest mean error: 5.739259719848633 mm for frame 116

Lowest mean error: 4.038923740386963 mm for frame 42

Saving results

Total time: 128.19099521636963
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01067163
Iteration 2/25 | Loss: 0.00310492
Iteration 3/25 | Loss: 0.00229298
Iteration 4/25 | Loss: 0.00192156
Iteration 5/25 | Loss: 0.00181054
Iteration 6/25 | Loss: 0.00178490
Iteration 7/25 | Loss: 0.00173930
Iteration 8/25 | Loss: 0.00167996
Iteration 9/25 | Loss: 0.00158540
Iteration 10/25 | Loss: 0.00152126
Iteration 11/25 | Loss: 0.00147424
Iteration 12/25 | Loss: 0.00145081
Iteration 13/25 | Loss: 0.00144904
Iteration 14/25 | Loss: 0.00143785
Iteration 15/25 | Loss: 0.00142490
Iteration 16/25 | Loss: 0.00142206
Iteration 17/25 | Loss: 0.00141904
Iteration 18/25 | Loss: 0.00140931
Iteration 19/25 | Loss: 0.00140758
Iteration 20/25 | Loss: 0.00140662
Iteration 21/25 | Loss: 0.00140601
Iteration 22/25 | Loss: 0.00140473
Iteration 23/25 | Loss: 0.00140597
Iteration 24/25 | Loss: 0.00140049
Iteration 25/25 | Loss: 0.00139937

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48877692
Iteration 2/25 | Loss: 0.01102449
Iteration 3/25 | Loss: 0.01102448
Iteration 4/25 | Loss: 0.00967084
Iteration 5/25 | Loss: 0.01196344
Iteration 6/25 | Loss: 0.00680327
Iteration 7/25 | Loss: 0.00631048
Iteration 8/25 | Loss: 0.00644877
Iteration 9/25 | Loss: 0.00629716
Iteration 10/25 | Loss: 0.00630121
Iteration 11/25 | Loss: 0.00617229
Iteration 12/25 | Loss: 0.00617229
Iteration 13/25 | Loss: 0.00617229
Iteration 14/25 | Loss: 0.00617229
Iteration 15/25 | Loss: 0.00617229
Iteration 16/25 | Loss: 0.00617229
Iteration 17/25 | Loss: 0.00617229
Iteration 18/25 | Loss: 0.00617229
Iteration 19/25 | Loss: 0.00617229
Iteration 20/25 | Loss: 0.00617229
Iteration 21/25 | Loss: 0.00617229
Iteration 22/25 | Loss: 0.00617229
Iteration 23/25 | Loss: 0.00617229
Iteration 24/25 | Loss: 0.00617229
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.006172289606183767, 0.006172289606183767, 0.006172289606183767, 0.006172289606183767, 0.006172289606183767]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006172289606183767

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00617229
Iteration 2/1000 | Loss: 0.00645295
Iteration 3/1000 | Loss: 0.00203870
Iteration 4/1000 | Loss: 0.00128223
Iteration 5/1000 | Loss: 0.00072098
Iteration 6/1000 | Loss: 0.00082516
Iteration 7/1000 | Loss: 0.00055981
Iteration 8/1000 | Loss: 0.00032415
Iteration 9/1000 | Loss: 0.00027719
Iteration 10/1000 | Loss: 0.00088996
Iteration 11/1000 | Loss: 0.00024732
Iteration 12/1000 | Loss: 0.00037287
Iteration 13/1000 | Loss: 0.00022423
Iteration 14/1000 | Loss: 0.00055879
Iteration 15/1000 | Loss: 0.00021724
Iteration 16/1000 | Loss: 0.00020272
Iteration 17/1000 | Loss: 0.00053635
Iteration 18/1000 | Loss: 0.00096971
Iteration 19/1000 | Loss: 0.00056852
Iteration 20/1000 | Loss: 0.00038249
Iteration 21/1000 | Loss: 0.00087459
Iteration 22/1000 | Loss: 0.00038616
Iteration 23/1000 | Loss: 0.00019006
Iteration 24/1000 | Loss: 0.00018173
Iteration 25/1000 | Loss: 0.00028652
Iteration 26/1000 | Loss: 0.00018056
Iteration 27/1000 | Loss: 0.00030478
Iteration 28/1000 | Loss: 0.00019425
Iteration 29/1000 | Loss: 0.00029631
Iteration 30/1000 | Loss: 0.00030989
Iteration 31/1000 | Loss: 0.00021398
Iteration 32/1000 | Loss: 0.00033434
Iteration 33/1000 | Loss: 0.00018934
Iteration 34/1000 | Loss: 0.00017195
Iteration 35/1000 | Loss: 0.00016614
Iteration 36/1000 | Loss: 0.00016242
Iteration 37/1000 | Loss: 0.00015954
Iteration 38/1000 | Loss: 0.00015771
Iteration 39/1000 | Loss: 0.00015591
Iteration 40/1000 | Loss: 0.00015528
Iteration 41/1000 | Loss: 0.00015474
Iteration 42/1000 | Loss: 0.00015426
Iteration 43/1000 | Loss: 0.00051423
Iteration 44/1000 | Loss: 0.00025613
Iteration 45/1000 | Loss: 0.00015437
Iteration 46/1000 | Loss: 0.00015378
Iteration 47/1000 | Loss: 0.00015361
Iteration 48/1000 | Loss: 0.00015365
Iteration 49/1000 | Loss: 0.00015331
Iteration 50/1000 | Loss: 0.00015311
Iteration 51/1000 | Loss: 0.00015309
Iteration 52/1000 | Loss: 0.00015329
Iteration 53/1000 | Loss: 0.00015304
Iteration 54/1000 | Loss: 0.00015294
Iteration 55/1000 | Loss: 0.00015291
Iteration 56/1000 | Loss: 0.00015290
Iteration 57/1000 | Loss: 0.00015289
Iteration 58/1000 | Loss: 0.00015296
Iteration 59/1000 | Loss: 0.00015296
Iteration 60/1000 | Loss: 0.00015279
Iteration 61/1000 | Loss: 0.00015277
Iteration 62/1000 | Loss: 0.00015276
Iteration 63/1000 | Loss: 0.00015276
Iteration 64/1000 | Loss: 0.00015276
Iteration 65/1000 | Loss: 0.00015276
Iteration 66/1000 | Loss: 0.00015276
Iteration 67/1000 | Loss: 0.00015276
Iteration 68/1000 | Loss: 0.00015276
Iteration 69/1000 | Loss: 0.00015276
Iteration 70/1000 | Loss: 0.00015275
Iteration 71/1000 | Loss: 0.00015275
Iteration 72/1000 | Loss: 0.00015274
Iteration 73/1000 | Loss: 0.00015269
Iteration 74/1000 | Loss: 0.00015268
Iteration 75/1000 | Loss: 0.00015268
Iteration 76/1000 | Loss: 0.00031474
Iteration 77/1000 | Loss: 0.00015804
Iteration 78/1000 | Loss: 0.00015477
Iteration 79/1000 | Loss: 0.00015358
Iteration 80/1000 | Loss: 0.00015212
Iteration 81/1000 | Loss: 0.00015137
Iteration 82/1000 | Loss: 0.00015104
Iteration 83/1000 | Loss: 0.00015094
Iteration 84/1000 | Loss: 0.00015074
Iteration 85/1000 | Loss: 0.00015068
Iteration 86/1000 | Loss: 0.00015067
Iteration 87/1000 | Loss: 0.00015069
Iteration 88/1000 | Loss: 0.00015069
Iteration 89/1000 | Loss: 0.00015065
Iteration 90/1000 | Loss: 0.00015065
Iteration 91/1000 | Loss: 0.00015059
Iteration 92/1000 | Loss: 0.00015059
Iteration 93/1000 | Loss: 0.00015059
Iteration 94/1000 | Loss: 0.00015059
Iteration 95/1000 | Loss: 0.00015054
Iteration 96/1000 | Loss: 0.00015054
Iteration 97/1000 | Loss: 0.00015053
Iteration 98/1000 | Loss: 0.00015053
Iteration 99/1000 | Loss: 0.00015052
Iteration 100/1000 | Loss: 0.00015052
Iteration 101/1000 | Loss: 0.00015051
Iteration 102/1000 | Loss: 0.00015051
Iteration 103/1000 | Loss: 0.00015051
Iteration 104/1000 | Loss: 0.00015058
Iteration 105/1000 | Loss: 0.00015057
Iteration 106/1000 | Loss: 0.00015057
Iteration 107/1000 | Loss: 0.00015057
Iteration 108/1000 | Loss: 0.00015057
Iteration 109/1000 | Loss: 0.00015056
Iteration 110/1000 | Loss: 0.00015056
Iteration 111/1000 | Loss: 0.00015056
Iteration 112/1000 | Loss: 0.00015056
Iteration 113/1000 | Loss: 0.00015056
Iteration 114/1000 | Loss: 0.00015055
Iteration 115/1000 | Loss: 0.00015055
Iteration 116/1000 | Loss: 0.00015048
Iteration 117/1000 | Loss: 0.00015048
Iteration 118/1000 | Loss: 0.00015048
Iteration 119/1000 | Loss: 0.00015048
Iteration 120/1000 | Loss: 0.00015048
Iteration 121/1000 | Loss: 0.00015048
Iteration 122/1000 | Loss: 0.00015047
Iteration 123/1000 | Loss: 0.00015047
Iteration 124/1000 | Loss: 0.00015047
Iteration 125/1000 | Loss: 0.00015047
Iteration 126/1000 | Loss: 0.00015047
Iteration 127/1000 | Loss: 0.00015047
Iteration 128/1000 | Loss: 0.00015047
Iteration 129/1000 | Loss: 0.00015047
Iteration 130/1000 | Loss: 0.00015047
Iteration 131/1000 | Loss: 0.00015047
Iteration 132/1000 | Loss: 0.00015047
Iteration 133/1000 | Loss: 0.00015047
Iteration 134/1000 | Loss: 0.00015052
Iteration 135/1000 | Loss: 0.00015052
Iteration 136/1000 | Loss: 0.00015052
Iteration 137/1000 | Loss: 0.00015052
Iteration 138/1000 | Loss: 0.00015052
Iteration 139/1000 | Loss: 0.00015052
Iteration 140/1000 | Loss: 0.00015052
Iteration 141/1000 | Loss: 0.00015052
Iteration 142/1000 | Loss: 0.00015052
Iteration 143/1000 | Loss: 0.00015052
Iteration 144/1000 | Loss: 0.00015051
Iteration 145/1000 | Loss: 0.00015046
Iteration 146/1000 | Loss: 0.00015046
Iteration 147/1000 | Loss: 0.00015046
Iteration 148/1000 | Loss: 0.00015046
Iteration 149/1000 | Loss: 0.00015046
Iteration 150/1000 | Loss: 0.00015046
Iteration 151/1000 | Loss: 0.00015046
Iteration 152/1000 | Loss: 0.00015046
Iteration 153/1000 | Loss: 0.00015046
Iteration 154/1000 | Loss: 0.00015046
Iteration 155/1000 | Loss: 0.00015046
Iteration 156/1000 | Loss: 0.00015046
Iteration 157/1000 | Loss: 0.00015051
Iteration 158/1000 | Loss: 0.00015051
Iteration 159/1000 | Loss: 0.00015051
Iteration 160/1000 | Loss: 0.00015051
Iteration 161/1000 | Loss: 0.00015050
Iteration 162/1000 | Loss: 0.00015050
Iteration 163/1000 | Loss: 0.00015050
Iteration 164/1000 | Loss: 0.00015050
Iteration 165/1000 | Loss: 0.00015050
Iteration 166/1000 | Loss: 0.00015050
Iteration 167/1000 | Loss: 0.00015050
Iteration 168/1000 | Loss: 0.00015050
Iteration 169/1000 | Loss: 0.00015050
Iteration 170/1000 | Loss: 0.00015050
Iteration 171/1000 | Loss: 0.00015050
Iteration 172/1000 | Loss: 0.00015050
Iteration 173/1000 | Loss: 0.00015050
Iteration 174/1000 | Loss: 0.00015050
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 174. Stopping optimization.
Last 5 losses: [0.00015050341608002782, 0.00015050341608002782, 0.00015050341608002782, 0.00015050341608002782, 0.00015050341608002782]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00015050341608002782

Optimization complete. Final v2v error: 6.089334487915039 mm

Highest mean error: 21.96630859375 mm for frame 222

Lowest mean error: 3.820486545562744 mm for frame 59

Saving results

Total time: 175.35333704948425
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01152760
Iteration 2/25 | Loss: 0.00206089
Iteration 3/25 | Loss: 0.00153167
Iteration 4/25 | Loss: 0.00122206
Iteration 5/25 | Loss: 0.00117553
Iteration 6/25 | Loss: 0.00116780
Iteration 7/25 | Loss: 0.00105480
Iteration 8/25 | Loss: 0.00106408
Iteration 9/25 | Loss: 0.00106964
Iteration 10/25 | Loss: 0.00103831
Iteration 11/25 | Loss: 0.00099637
Iteration 12/25 | Loss: 0.00097822
Iteration 13/25 | Loss: 0.00097298
Iteration 14/25 | Loss: 0.00097174
Iteration 15/25 | Loss: 0.00097101
Iteration 16/25 | Loss: 0.00097071
Iteration 17/25 | Loss: 0.00097041
Iteration 18/25 | Loss: 0.00097027
Iteration 19/25 | Loss: 0.00097027
Iteration 20/25 | Loss: 0.00097027
Iteration 21/25 | Loss: 0.00097026
Iteration 22/25 | Loss: 0.00097026
Iteration 23/25 | Loss: 0.00097026
Iteration 24/25 | Loss: 0.00097026
Iteration 25/25 | Loss: 0.00097026

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47355318
Iteration 2/25 | Loss: 0.00072420
Iteration 3/25 | Loss: 0.00072420
Iteration 4/25 | Loss: 0.00072420
Iteration 5/25 | Loss: 0.00072420
Iteration 6/25 | Loss: 0.00072420
Iteration 7/25 | Loss: 0.00072420
Iteration 8/25 | Loss: 0.00072420
Iteration 9/25 | Loss: 0.00072420
Iteration 10/25 | Loss: 0.00072420
Iteration 11/25 | Loss: 0.00072420
Iteration 12/25 | Loss: 0.00072420
Iteration 13/25 | Loss: 0.00072420
Iteration 14/25 | Loss: 0.00072420
Iteration 15/25 | Loss: 0.00072420
Iteration 16/25 | Loss: 0.00072420
Iteration 17/25 | Loss: 0.00072420
Iteration 18/25 | Loss: 0.00072420
Iteration 19/25 | Loss: 0.00072420
Iteration 20/25 | Loss: 0.00072420
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0007242023712024093, 0.0007242023712024093, 0.0007242023712024093, 0.0007242023712024093, 0.0007242023712024093]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007242023712024093

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00072420
Iteration 2/1000 | Loss: 0.00004592
Iteration 3/1000 | Loss: 0.00003371
Iteration 4/1000 | Loss: 0.00003182
Iteration 5/1000 | Loss: 0.00003036
Iteration 6/1000 | Loss: 0.00002961
Iteration 7/1000 | Loss: 0.00002892
Iteration 8/1000 | Loss: 0.00002854
Iteration 9/1000 | Loss: 0.00002833
Iteration 10/1000 | Loss: 0.00002830
Iteration 11/1000 | Loss: 0.00002829
Iteration 12/1000 | Loss: 0.00002822
Iteration 13/1000 | Loss: 0.00002822
Iteration 14/1000 | Loss: 0.00002822
Iteration 15/1000 | Loss: 0.00002822
Iteration 16/1000 | Loss: 0.00002822
Iteration 17/1000 | Loss: 0.00002822
Iteration 18/1000 | Loss: 0.00002821
Iteration 19/1000 | Loss: 0.00002821
Iteration 20/1000 | Loss: 0.00002821
Iteration 21/1000 | Loss: 0.00002821
Iteration 22/1000 | Loss: 0.00002821
Iteration 23/1000 | Loss: 0.00002820
Iteration 24/1000 | Loss: 0.00002820
Iteration 25/1000 | Loss: 0.00002820
Iteration 26/1000 | Loss: 0.00002820
Iteration 27/1000 | Loss: 0.00002820
Iteration 28/1000 | Loss: 0.00002820
Iteration 29/1000 | Loss: 0.00002820
Iteration 30/1000 | Loss: 0.00002819
Iteration 31/1000 | Loss: 0.00002819
Iteration 32/1000 | Loss: 0.00002819
Iteration 33/1000 | Loss: 0.00002819
Iteration 34/1000 | Loss: 0.00002819
Iteration 35/1000 | Loss: 0.00002819
Iteration 36/1000 | Loss: 0.00002819
Iteration 37/1000 | Loss: 0.00002819
Iteration 38/1000 | Loss: 0.00002818
Iteration 39/1000 | Loss: 0.00002818
Iteration 40/1000 | Loss: 0.00002818
Iteration 41/1000 | Loss: 0.00002818
Iteration 42/1000 | Loss: 0.00002818
Iteration 43/1000 | Loss: 0.00002818
Iteration 44/1000 | Loss: 0.00002818
Iteration 45/1000 | Loss: 0.00002818
Iteration 46/1000 | Loss: 0.00002818
Iteration 47/1000 | Loss: 0.00002818
Iteration 48/1000 | Loss: 0.00002817
Iteration 49/1000 | Loss: 0.00002817
Iteration 50/1000 | Loss: 0.00002817
Iteration 51/1000 | Loss: 0.00002817
Iteration 52/1000 | Loss: 0.00002817
Iteration 53/1000 | Loss: 0.00002817
Iteration 54/1000 | Loss: 0.00002817
Iteration 55/1000 | Loss: 0.00002817
Iteration 56/1000 | Loss: 0.00002817
Iteration 57/1000 | Loss: 0.00002817
Iteration 58/1000 | Loss: 0.00002817
Iteration 59/1000 | Loss: 0.00002817
Iteration 60/1000 | Loss: 0.00002817
Iteration 61/1000 | Loss: 0.00002817
Iteration 62/1000 | Loss: 0.00002817
Iteration 63/1000 | Loss: 0.00002817
Iteration 64/1000 | Loss: 0.00002817
Iteration 65/1000 | Loss: 0.00002817
Iteration 66/1000 | Loss: 0.00002817
Iteration 67/1000 | Loss: 0.00002817
Iteration 68/1000 | Loss: 0.00002817
Iteration 69/1000 | Loss: 0.00002816
Iteration 70/1000 | Loss: 0.00002816
Iteration 71/1000 | Loss: 0.00002816
Iteration 72/1000 | Loss: 0.00002816
Iteration 73/1000 | Loss: 0.00002816
Iteration 74/1000 | Loss: 0.00002816
Iteration 75/1000 | Loss: 0.00002816
Iteration 76/1000 | Loss: 0.00002816
Iteration 77/1000 | Loss: 0.00002816
Iteration 78/1000 | Loss: 0.00002816
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 78. Stopping optimization.
Last 5 losses: [2.8164895411464386e-05, 2.8164895411464386e-05, 2.8164895411464386e-05, 2.8164895411464386e-05, 2.8164895411464386e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8164895411464386e-05

Optimization complete. Final v2v error: 4.4233012199401855 mm

Highest mean error: 4.966952800750732 mm for frame 239

Lowest mean error: 4.040929794311523 mm for frame 172

Saving results

Total time: 54.34112787246704
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1042/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1042.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1042
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00429832
Iteration 2/25 | Loss: 0.00112150
Iteration 3/25 | Loss: 0.00084133
Iteration 4/25 | Loss: 0.00079265
Iteration 5/25 | Loss: 0.00077712
Iteration 6/25 | Loss: 0.00077481
Iteration 7/25 | Loss: 0.00077401
Iteration 8/25 | Loss: 0.00077401
Iteration 9/25 | Loss: 0.00077401
Iteration 10/25 | Loss: 0.00077401
Iteration 11/25 | Loss: 0.00077401
Iteration 12/25 | Loss: 0.00077401
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007740131695754826, 0.0007740131695754826, 0.0007740131695754826, 0.0007740131695754826, 0.0007740131695754826]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007740131695754826

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66164088
Iteration 2/25 | Loss: 0.00117396
Iteration 3/25 | Loss: 0.00117396
Iteration 4/25 | Loss: 0.00117395
Iteration 5/25 | Loss: 0.00117395
Iteration 6/25 | Loss: 0.00117395
Iteration 7/25 | Loss: 0.00117395
Iteration 8/25 | Loss: 0.00117395
Iteration 9/25 | Loss: 0.00117395
Iteration 10/25 | Loss: 0.00117395
Iteration 11/25 | Loss: 0.00117395
Iteration 12/25 | Loss: 0.00117395
Iteration 13/25 | Loss: 0.00117395
Iteration 14/25 | Loss: 0.00117395
Iteration 15/25 | Loss: 0.00117395
Iteration 16/25 | Loss: 0.00117395
Iteration 17/25 | Loss: 0.00117395
Iteration 18/25 | Loss: 0.00117395
Iteration 19/25 | Loss: 0.00117395
Iteration 20/25 | Loss: 0.00117395
Iteration 21/25 | Loss: 0.00117395
Iteration 22/25 | Loss: 0.00117395
Iteration 23/25 | Loss: 0.00117395
Iteration 24/25 | Loss: 0.00117395
Iteration 25/25 | Loss: 0.00117395

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00117395
Iteration 2/1000 | Loss: 0.00003345
Iteration 3/1000 | Loss: 0.00002169
Iteration 4/1000 | Loss: 0.00002005
Iteration 5/1000 | Loss: 0.00001917
Iteration 6/1000 | Loss: 0.00001848
Iteration 7/1000 | Loss: 0.00001821
Iteration 8/1000 | Loss: 0.00001782
Iteration 9/1000 | Loss: 0.00001758
Iteration 10/1000 | Loss: 0.00001734
Iteration 11/1000 | Loss: 0.00001727
Iteration 12/1000 | Loss: 0.00001712
Iteration 13/1000 | Loss: 0.00001710
Iteration 14/1000 | Loss: 0.00001707
Iteration 15/1000 | Loss: 0.00001707
Iteration 16/1000 | Loss: 0.00001707
Iteration 17/1000 | Loss: 0.00001706
Iteration 18/1000 | Loss: 0.00001706
Iteration 19/1000 | Loss: 0.00001704
Iteration 20/1000 | Loss: 0.00001703
Iteration 21/1000 | Loss: 0.00001703
Iteration 22/1000 | Loss: 0.00001703
Iteration 23/1000 | Loss: 0.00001703
Iteration 24/1000 | Loss: 0.00001703
Iteration 25/1000 | Loss: 0.00001703
Iteration 26/1000 | Loss: 0.00001702
Iteration 27/1000 | Loss: 0.00001702
Iteration 28/1000 | Loss: 0.00001701
Iteration 29/1000 | Loss: 0.00001701
Iteration 30/1000 | Loss: 0.00001701
Iteration 31/1000 | Loss: 0.00001700
Iteration 32/1000 | Loss: 0.00001700
Iteration 33/1000 | Loss: 0.00001700
Iteration 34/1000 | Loss: 0.00001700
Iteration 35/1000 | Loss: 0.00001700
Iteration 36/1000 | Loss: 0.00001700
Iteration 37/1000 | Loss: 0.00001700
Iteration 38/1000 | Loss: 0.00001700
Iteration 39/1000 | Loss: 0.00001699
Iteration 40/1000 | Loss: 0.00001699
Iteration 41/1000 | Loss: 0.00001699
Iteration 42/1000 | Loss: 0.00001699
Iteration 43/1000 | Loss: 0.00001699
Iteration 44/1000 | Loss: 0.00001699
Iteration 45/1000 | Loss: 0.00001698
Iteration 46/1000 | Loss: 0.00001698
Iteration 47/1000 | Loss: 0.00001698
Iteration 48/1000 | Loss: 0.00001698
Iteration 49/1000 | Loss: 0.00001698
Iteration 50/1000 | Loss: 0.00001697
Iteration 51/1000 | Loss: 0.00001697
Iteration 52/1000 | Loss: 0.00001697
Iteration 53/1000 | Loss: 0.00001697
Iteration 54/1000 | Loss: 0.00001697
Iteration 55/1000 | Loss: 0.00001697
Iteration 56/1000 | Loss: 0.00001696
Iteration 57/1000 | Loss: 0.00001696
Iteration 58/1000 | Loss: 0.00001696
Iteration 59/1000 | Loss: 0.00001696
Iteration 60/1000 | Loss: 0.00001696
Iteration 61/1000 | Loss: 0.00001696
Iteration 62/1000 | Loss: 0.00001695
Iteration 63/1000 | Loss: 0.00001695
Iteration 64/1000 | Loss: 0.00001695
Iteration 65/1000 | Loss: 0.00001694
Iteration 66/1000 | Loss: 0.00001694
Iteration 67/1000 | Loss: 0.00001694
Iteration 68/1000 | Loss: 0.00001694
Iteration 69/1000 | Loss: 0.00001694
Iteration 70/1000 | Loss: 0.00001694
Iteration 71/1000 | Loss: 0.00001694
Iteration 72/1000 | Loss: 0.00001693
Iteration 73/1000 | Loss: 0.00001693
Iteration 74/1000 | Loss: 0.00001693
Iteration 75/1000 | Loss: 0.00001693
Iteration 76/1000 | Loss: 0.00001693
Iteration 77/1000 | Loss: 0.00001693
Iteration 78/1000 | Loss: 0.00001693
Iteration 79/1000 | Loss: 0.00001693
Iteration 80/1000 | Loss: 0.00001691
Iteration 81/1000 | Loss: 0.00001691
Iteration 82/1000 | Loss: 0.00001691
Iteration 83/1000 | Loss: 0.00001690
Iteration 84/1000 | Loss: 0.00001690
Iteration 85/1000 | Loss: 0.00001690
Iteration 86/1000 | Loss: 0.00001689
Iteration 87/1000 | Loss: 0.00001689
Iteration 88/1000 | Loss: 0.00001689
Iteration 89/1000 | Loss: 0.00001688
Iteration 90/1000 | Loss: 0.00001688
Iteration 91/1000 | Loss: 0.00001688
Iteration 92/1000 | Loss: 0.00001687
Iteration 93/1000 | Loss: 0.00001687
Iteration 94/1000 | Loss: 0.00001686
Iteration 95/1000 | Loss: 0.00001686
Iteration 96/1000 | Loss: 0.00001686
Iteration 97/1000 | Loss: 0.00001686
Iteration 98/1000 | Loss: 0.00001686
Iteration 99/1000 | Loss: 0.00001686
Iteration 100/1000 | Loss: 0.00001686
Iteration 101/1000 | Loss: 0.00001686
Iteration 102/1000 | Loss: 0.00001686
Iteration 103/1000 | Loss: 0.00001686
Iteration 104/1000 | Loss: 0.00001686
Iteration 105/1000 | Loss: 0.00001685
Iteration 106/1000 | Loss: 0.00001685
Iteration 107/1000 | Loss: 0.00001685
Iteration 108/1000 | Loss: 0.00001685
Iteration 109/1000 | Loss: 0.00001685
Iteration 110/1000 | Loss: 0.00001685
Iteration 111/1000 | Loss: 0.00001685
Iteration 112/1000 | Loss: 0.00001684
Iteration 113/1000 | Loss: 0.00001684
Iteration 114/1000 | Loss: 0.00001684
Iteration 115/1000 | Loss: 0.00001684
Iteration 116/1000 | Loss: 0.00001684
Iteration 117/1000 | Loss: 0.00001683
Iteration 118/1000 | Loss: 0.00001683
Iteration 119/1000 | Loss: 0.00001683
Iteration 120/1000 | Loss: 0.00001683
Iteration 121/1000 | Loss: 0.00001683
Iteration 122/1000 | Loss: 0.00001683
Iteration 123/1000 | Loss: 0.00001683
Iteration 124/1000 | Loss: 0.00001683
Iteration 125/1000 | Loss: 0.00001683
Iteration 126/1000 | Loss: 0.00001683
Iteration 127/1000 | Loss: 0.00001682
Iteration 128/1000 | Loss: 0.00001682
Iteration 129/1000 | Loss: 0.00001682
Iteration 130/1000 | Loss: 0.00001682
Iteration 131/1000 | Loss: 0.00001682
Iteration 132/1000 | Loss: 0.00001681
Iteration 133/1000 | Loss: 0.00001681
Iteration 134/1000 | Loss: 0.00001681
Iteration 135/1000 | Loss: 0.00001681
Iteration 136/1000 | Loss: 0.00001681
Iteration 137/1000 | Loss: 0.00001681
Iteration 138/1000 | Loss: 0.00001681
Iteration 139/1000 | Loss: 0.00001681
Iteration 140/1000 | Loss: 0.00001681
Iteration 141/1000 | Loss: 0.00001681
Iteration 142/1000 | Loss: 0.00001681
Iteration 143/1000 | Loss: 0.00001681
Iteration 144/1000 | Loss: 0.00001681
Iteration 145/1000 | Loss: 0.00001681
Iteration 146/1000 | Loss: 0.00001681
Iteration 147/1000 | Loss: 0.00001681
Iteration 148/1000 | Loss: 0.00001681
Iteration 149/1000 | Loss: 0.00001681
Iteration 150/1000 | Loss: 0.00001681
Iteration 151/1000 | Loss: 0.00001681
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [1.6806283383630216e-05, 1.6806283383630216e-05, 1.6806283383630216e-05, 1.6806283383630216e-05, 1.6806283383630216e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6806283383630216e-05

Optimization complete. Final v2v error: 3.43575119972229 mm

Highest mean error: 4.100114822387695 mm for frame 80

Lowest mean error: 2.871856927871704 mm for frame 164

Saving results

Total time: 42.359466552734375
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00431067
Iteration 2/25 | Loss: 0.00112883
Iteration 3/25 | Loss: 0.00089193
Iteration 4/25 | Loss: 0.00085720
Iteration 5/25 | Loss: 0.00084451
Iteration 6/25 | Loss: 0.00084167
Iteration 7/25 | Loss: 0.00084079
Iteration 8/25 | Loss: 0.00084066
Iteration 9/25 | Loss: 0.00084066
Iteration 10/25 | Loss: 0.00084066
Iteration 11/25 | Loss: 0.00084066
Iteration 12/25 | Loss: 0.00084066
Iteration 13/25 | Loss: 0.00084066
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008406579727306962, 0.0008406579727306962, 0.0008406579727306962, 0.0008406579727306962, 0.0008406579727306962]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008406579727306962

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.54391479
Iteration 2/25 | Loss: 0.00128772
Iteration 3/25 | Loss: 0.00128768
Iteration 4/25 | Loss: 0.00128768
Iteration 5/25 | Loss: 0.00128768
Iteration 6/25 | Loss: 0.00128768
Iteration 7/25 | Loss: 0.00128768
Iteration 8/25 | Loss: 0.00128768
Iteration 9/25 | Loss: 0.00128768
Iteration 10/25 | Loss: 0.00128768
Iteration 11/25 | Loss: 0.00128768
Iteration 12/25 | Loss: 0.00128768
Iteration 13/25 | Loss: 0.00128768
Iteration 14/25 | Loss: 0.00128768
Iteration 15/25 | Loss: 0.00128768
Iteration 16/25 | Loss: 0.00128768
Iteration 17/25 | Loss: 0.00128768
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012876774417236447, 0.0012876774417236447, 0.0012876774417236447, 0.0012876774417236447, 0.0012876774417236447]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012876774417236447

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00128768
Iteration 2/1000 | Loss: 0.00003806
Iteration 3/1000 | Loss: 0.00002802
Iteration 4/1000 | Loss: 0.00002656
Iteration 5/1000 | Loss: 0.00002524
Iteration 6/1000 | Loss: 0.00002476
Iteration 7/1000 | Loss: 0.00002422
Iteration 8/1000 | Loss: 0.00002389
Iteration 9/1000 | Loss: 0.00002368
Iteration 10/1000 | Loss: 0.00002350
Iteration 11/1000 | Loss: 0.00002343
Iteration 12/1000 | Loss: 0.00002342
Iteration 13/1000 | Loss: 0.00002340
Iteration 14/1000 | Loss: 0.00002336
Iteration 15/1000 | Loss: 0.00002334
Iteration 16/1000 | Loss: 0.00002333
Iteration 17/1000 | Loss: 0.00002333
Iteration 18/1000 | Loss: 0.00002331
Iteration 19/1000 | Loss: 0.00002331
Iteration 20/1000 | Loss: 0.00002331
Iteration 21/1000 | Loss: 0.00002330
Iteration 22/1000 | Loss: 0.00002330
Iteration 23/1000 | Loss: 0.00002330
Iteration 24/1000 | Loss: 0.00002330
Iteration 25/1000 | Loss: 0.00002330
Iteration 26/1000 | Loss: 0.00002330
Iteration 27/1000 | Loss: 0.00002330
Iteration 28/1000 | Loss: 0.00002330
Iteration 29/1000 | Loss: 0.00002330
Iteration 30/1000 | Loss: 0.00002329
Iteration 31/1000 | Loss: 0.00002329
Iteration 32/1000 | Loss: 0.00002329
Iteration 33/1000 | Loss: 0.00002328
Iteration 34/1000 | Loss: 0.00002328
Iteration 35/1000 | Loss: 0.00002328
Iteration 36/1000 | Loss: 0.00002328
Iteration 37/1000 | Loss: 0.00002327
Iteration 38/1000 | Loss: 0.00002327
Iteration 39/1000 | Loss: 0.00002327
Iteration 40/1000 | Loss: 0.00002327
Iteration 41/1000 | Loss: 0.00002326
Iteration 42/1000 | Loss: 0.00002326
Iteration 43/1000 | Loss: 0.00002325
Iteration 44/1000 | Loss: 0.00002325
Iteration 45/1000 | Loss: 0.00002325
Iteration 46/1000 | Loss: 0.00002325
Iteration 47/1000 | Loss: 0.00002324
Iteration 48/1000 | Loss: 0.00002324
Iteration 49/1000 | Loss: 0.00002324
Iteration 50/1000 | Loss: 0.00002323
Iteration 51/1000 | Loss: 0.00002323
Iteration 52/1000 | Loss: 0.00002323
Iteration 53/1000 | Loss: 0.00002322
Iteration 54/1000 | Loss: 0.00002322
Iteration 55/1000 | Loss: 0.00002322
Iteration 56/1000 | Loss: 0.00002322
Iteration 57/1000 | Loss: 0.00002322
Iteration 58/1000 | Loss: 0.00002322
Iteration 59/1000 | Loss: 0.00002322
Iteration 60/1000 | Loss: 0.00002321
Iteration 61/1000 | Loss: 0.00002321
Iteration 62/1000 | Loss: 0.00002321
Iteration 63/1000 | Loss: 0.00002321
Iteration 64/1000 | Loss: 0.00002320
Iteration 65/1000 | Loss: 0.00002320
Iteration 66/1000 | Loss: 0.00002320
Iteration 67/1000 | Loss: 0.00002320
Iteration 68/1000 | Loss: 0.00002319
Iteration 69/1000 | Loss: 0.00002319
Iteration 70/1000 | Loss: 0.00002318
Iteration 71/1000 | Loss: 0.00002318
Iteration 72/1000 | Loss: 0.00002318
Iteration 73/1000 | Loss: 0.00002318
Iteration 74/1000 | Loss: 0.00002317
Iteration 75/1000 | Loss: 0.00002317
Iteration 76/1000 | Loss: 0.00002317
Iteration 77/1000 | Loss: 0.00002317
Iteration 78/1000 | Loss: 0.00002316
Iteration 79/1000 | Loss: 0.00002316
Iteration 80/1000 | Loss: 0.00002316
Iteration 81/1000 | Loss: 0.00002315
Iteration 82/1000 | Loss: 0.00002315
Iteration 83/1000 | Loss: 0.00002315
Iteration 84/1000 | Loss: 0.00002314
Iteration 85/1000 | Loss: 0.00002314
Iteration 86/1000 | Loss: 0.00002314
Iteration 87/1000 | Loss: 0.00002314
Iteration 88/1000 | Loss: 0.00002313
Iteration 89/1000 | Loss: 0.00002313
Iteration 90/1000 | Loss: 0.00002313
Iteration 91/1000 | Loss: 0.00002312
Iteration 92/1000 | Loss: 0.00002312
Iteration 93/1000 | Loss: 0.00002312
Iteration 94/1000 | Loss: 0.00002312
Iteration 95/1000 | Loss: 0.00002312
Iteration 96/1000 | Loss: 0.00002312
Iteration 97/1000 | Loss: 0.00002311
Iteration 98/1000 | Loss: 0.00002311
Iteration 99/1000 | Loss: 0.00002311
Iteration 100/1000 | Loss: 0.00002311
Iteration 101/1000 | Loss: 0.00002311
Iteration 102/1000 | Loss: 0.00002311
Iteration 103/1000 | Loss: 0.00002311
Iteration 104/1000 | Loss: 0.00002311
Iteration 105/1000 | Loss: 0.00002311
Iteration 106/1000 | Loss: 0.00002311
Iteration 107/1000 | Loss: 0.00002311
Iteration 108/1000 | Loss: 0.00002311
Iteration 109/1000 | Loss: 0.00002311
Iteration 110/1000 | Loss: 0.00002311
Iteration 111/1000 | Loss: 0.00002311
Iteration 112/1000 | Loss: 0.00002311
Iteration 113/1000 | Loss: 0.00002311
Iteration 114/1000 | Loss: 0.00002311
Iteration 115/1000 | Loss: 0.00002311
Iteration 116/1000 | Loss: 0.00002311
Iteration 117/1000 | Loss: 0.00002311
Iteration 118/1000 | Loss: 0.00002311
Iteration 119/1000 | Loss: 0.00002311
Iteration 120/1000 | Loss: 0.00002311
Iteration 121/1000 | Loss: 0.00002311
Iteration 122/1000 | Loss: 0.00002311
Iteration 123/1000 | Loss: 0.00002311
Iteration 124/1000 | Loss: 0.00002311
Iteration 125/1000 | Loss: 0.00002311
Iteration 126/1000 | Loss: 0.00002311
Iteration 127/1000 | Loss: 0.00002311
Iteration 128/1000 | Loss: 0.00002311
Iteration 129/1000 | Loss: 0.00002311
Iteration 130/1000 | Loss: 0.00002311
Iteration 131/1000 | Loss: 0.00002311
Iteration 132/1000 | Loss: 0.00002311
Iteration 133/1000 | Loss: 0.00002311
Iteration 134/1000 | Loss: 0.00002311
Iteration 135/1000 | Loss: 0.00002311
Iteration 136/1000 | Loss: 0.00002311
Iteration 137/1000 | Loss: 0.00002311
Iteration 138/1000 | Loss: 0.00002311
Iteration 139/1000 | Loss: 0.00002311
Iteration 140/1000 | Loss: 0.00002311
Iteration 141/1000 | Loss: 0.00002311
Iteration 142/1000 | Loss: 0.00002311
Iteration 143/1000 | Loss: 0.00002311
Iteration 144/1000 | Loss: 0.00002311
Iteration 145/1000 | Loss: 0.00002311
Iteration 146/1000 | Loss: 0.00002311
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 146. Stopping optimization.
Last 5 losses: [2.3112192138796672e-05, 2.3112192138796672e-05, 2.3112192138796672e-05, 2.3112192138796672e-05, 2.3112192138796672e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3112192138796672e-05

Optimization complete. Final v2v error: 4.013342380523682 mm

Highest mean error: 4.765063762664795 mm for frame 116

Lowest mean error: 3.64208722114563 mm for frame 152

Saving results

Total time: 36.60935831069946
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01080791
Iteration 2/25 | Loss: 0.00277616
Iteration 3/25 | Loss: 0.00208887
Iteration 4/25 | Loss: 0.00127623
Iteration 5/25 | Loss: 0.00122904
Iteration 6/25 | Loss: 0.00119753
Iteration 7/25 | Loss: 0.00104852
Iteration 8/25 | Loss: 0.00103149
Iteration 9/25 | Loss: 0.00095405
Iteration 10/25 | Loss: 0.00093173
Iteration 11/25 | Loss: 0.00091687
Iteration 12/25 | Loss: 0.00090138
Iteration 13/25 | Loss: 0.00090732
Iteration 14/25 | Loss: 0.00088947
Iteration 15/25 | Loss: 0.00088465
Iteration 16/25 | Loss: 0.00087969
Iteration 17/25 | Loss: 0.00088002
Iteration 18/25 | Loss: 0.00087719
Iteration 19/25 | Loss: 0.00087488
Iteration 20/25 | Loss: 0.00087296
Iteration 21/25 | Loss: 0.00086973
Iteration 22/25 | Loss: 0.00087089
Iteration 23/25 | Loss: 0.00087171
Iteration 24/25 | Loss: 0.00087580
Iteration 25/25 | Loss: 0.00087803

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58201587
Iteration 2/25 | Loss: 0.00128989
Iteration 3/25 | Loss: 0.00128989
Iteration 4/25 | Loss: 0.00128988
Iteration 5/25 | Loss: 0.00127701
Iteration 6/25 | Loss: 0.00127700
Iteration 7/25 | Loss: 0.00127700
Iteration 8/25 | Loss: 0.00127700
Iteration 9/25 | Loss: 0.00127700
Iteration 10/25 | Loss: 0.00127700
Iteration 11/25 | Loss: 0.00127700
Iteration 12/25 | Loss: 0.00127700
Iteration 13/25 | Loss: 0.00127700
Iteration 14/25 | Loss: 0.00127700
Iteration 15/25 | Loss: 0.00127700
Iteration 16/25 | Loss: 0.00127700
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012769992463290691, 0.0012769992463290691, 0.0012769992463290691, 0.0012769992463290691, 0.0012769992463290691]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012769992463290691

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00127700
Iteration 2/1000 | Loss: 0.00026150
Iteration 3/1000 | Loss: 0.00033154
Iteration 4/1000 | Loss: 0.00030314
Iteration 5/1000 | Loss: 0.00036383
Iteration 6/1000 | Loss: 0.00012157
Iteration 7/1000 | Loss: 0.00007207
Iteration 8/1000 | Loss: 0.00005416
Iteration 9/1000 | Loss: 0.00018387
Iteration 10/1000 | Loss: 0.00012913
Iteration 11/1000 | Loss: 0.00024063
Iteration 12/1000 | Loss: 0.00012212
Iteration 13/1000 | Loss: 0.00015264
Iteration 14/1000 | Loss: 0.00009503
Iteration 15/1000 | Loss: 0.00006891
Iteration 16/1000 | Loss: 0.00005064
Iteration 17/1000 | Loss: 0.00004574
Iteration 18/1000 | Loss: 0.00006272
Iteration 19/1000 | Loss: 0.00004954
Iteration 20/1000 | Loss: 0.00006377
Iteration 21/1000 | Loss: 0.00043143
Iteration 22/1000 | Loss: 0.00012790
Iteration 23/1000 | Loss: 0.00008799
Iteration 24/1000 | Loss: 0.00012549
Iteration 25/1000 | Loss: 0.00007730
Iteration 26/1000 | Loss: 0.00005949
Iteration 27/1000 | Loss: 0.00007774
Iteration 28/1000 | Loss: 0.00005796
Iteration 29/1000 | Loss: 0.00007644
Iteration 30/1000 | Loss: 0.00005535
Iteration 31/1000 | Loss: 0.00014059
Iteration 32/1000 | Loss: 0.00004575
Iteration 33/1000 | Loss: 0.00003229
Iteration 34/1000 | Loss: 0.00002988
Iteration 35/1000 | Loss: 0.00002861
Iteration 36/1000 | Loss: 0.00002805
Iteration 37/1000 | Loss: 0.00002764
Iteration 38/1000 | Loss: 0.00002731
Iteration 39/1000 | Loss: 0.00002686
Iteration 40/1000 | Loss: 0.00002644
Iteration 41/1000 | Loss: 0.00087897
Iteration 42/1000 | Loss: 0.00065843
Iteration 43/1000 | Loss: 0.00005547
Iteration 44/1000 | Loss: 0.00004015
Iteration 45/1000 | Loss: 0.00002616
Iteration 46/1000 | Loss: 0.00002336
Iteration 47/1000 | Loss: 0.00002198
Iteration 48/1000 | Loss: 0.00002133
Iteration 49/1000 | Loss: 0.00002091
Iteration 50/1000 | Loss: 0.00002061
Iteration 51/1000 | Loss: 0.00002051
Iteration 52/1000 | Loss: 0.00002044
Iteration 53/1000 | Loss: 0.00002041
Iteration 54/1000 | Loss: 0.00002040
Iteration 55/1000 | Loss: 0.00002039
Iteration 56/1000 | Loss: 0.00002036
Iteration 57/1000 | Loss: 0.00002035
Iteration 58/1000 | Loss: 0.00002035
Iteration 59/1000 | Loss: 0.00002035
Iteration 60/1000 | Loss: 0.00002034
Iteration 61/1000 | Loss: 0.00002034
Iteration 62/1000 | Loss: 0.00002033
Iteration 63/1000 | Loss: 0.00002033
Iteration 64/1000 | Loss: 0.00002033
Iteration 65/1000 | Loss: 0.00002032
Iteration 66/1000 | Loss: 0.00002032
Iteration 67/1000 | Loss: 0.00002031
Iteration 68/1000 | Loss: 0.00002031
Iteration 69/1000 | Loss: 0.00002031
Iteration 70/1000 | Loss: 0.00002031
Iteration 71/1000 | Loss: 0.00002031
Iteration 72/1000 | Loss: 0.00002030
Iteration 73/1000 | Loss: 0.00002030
Iteration 74/1000 | Loss: 0.00002030
Iteration 75/1000 | Loss: 0.00002030
Iteration 76/1000 | Loss: 0.00002030
Iteration 77/1000 | Loss: 0.00002029
Iteration 78/1000 | Loss: 0.00002029
Iteration 79/1000 | Loss: 0.00002029
Iteration 80/1000 | Loss: 0.00002029
Iteration 81/1000 | Loss: 0.00002029
Iteration 82/1000 | Loss: 0.00002028
Iteration 83/1000 | Loss: 0.00002028
Iteration 84/1000 | Loss: 0.00002027
Iteration 85/1000 | Loss: 0.00002027
Iteration 86/1000 | Loss: 0.00002027
Iteration 87/1000 | Loss: 0.00002027
Iteration 88/1000 | Loss: 0.00002027
Iteration 89/1000 | Loss: 0.00002027
Iteration 90/1000 | Loss: 0.00002026
Iteration 91/1000 | Loss: 0.00002026
Iteration 92/1000 | Loss: 0.00002026
Iteration 93/1000 | Loss: 0.00002026
Iteration 94/1000 | Loss: 0.00002026
Iteration 95/1000 | Loss: 0.00002026
Iteration 96/1000 | Loss: 0.00002026
Iteration 97/1000 | Loss: 0.00002026
Iteration 98/1000 | Loss: 0.00002025
Iteration 99/1000 | Loss: 0.00002025
Iteration 100/1000 | Loss: 0.00002025
Iteration 101/1000 | Loss: 0.00002025
Iteration 102/1000 | Loss: 0.00002025
Iteration 103/1000 | Loss: 0.00002025
Iteration 104/1000 | Loss: 0.00002025
Iteration 105/1000 | Loss: 0.00002024
Iteration 106/1000 | Loss: 0.00002024
Iteration 107/1000 | Loss: 0.00002024
Iteration 108/1000 | Loss: 0.00002024
Iteration 109/1000 | Loss: 0.00002024
Iteration 110/1000 | Loss: 0.00002024
Iteration 111/1000 | Loss: 0.00002024
Iteration 112/1000 | Loss: 0.00002023
Iteration 113/1000 | Loss: 0.00002023
Iteration 114/1000 | Loss: 0.00002023
Iteration 115/1000 | Loss: 0.00002023
Iteration 116/1000 | Loss: 0.00002023
Iteration 117/1000 | Loss: 0.00002023
Iteration 118/1000 | Loss: 0.00002023
Iteration 119/1000 | Loss: 0.00002023
Iteration 120/1000 | Loss: 0.00002023
Iteration 121/1000 | Loss: 0.00002023
Iteration 122/1000 | Loss: 0.00002023
Iteration 123/1000 | Loss: 0.00002023
Iteration 124/1000 | Loss: 0.00002023
Iteration 125/1000 | Loss: 0.00002023
Iteration 126/1000 | Loss: 0.00002023
Iteration 127/1000 | Loss: 0.00002022
Iteration 128/1000 | Loss: 0.00002022
Iteration 129/1000 | Loss: 0.00002022
Iteration 130/1000 | Loss: 0.00002022
Iteration 131/1000 | Loss: 0.00002022
Iteration 132/1000 | Loss: 0.00002022
Iteration 133/1000 | Loss: 0.00002022
Iteration 134/1000 | Loss: 0.00002022
Iteration 135/1000 | Loss: 0.00002022
Iteration 136/1000 | Loss: 0.00002022
Iteration 137/1000 | Loss: 0.00002022
Iteration 138/1000 | Loss: 0.00002021
Iteration 139/1000 | Loss: 0.00002021
Iteration 140/1000 | Loss: 0.00002021
Iteration 141/1000 | Loss: 0.00002021
Iteration 142/1000 | Loss: 0.00002021
Iteration 143/1000 | Loss: 0.00002021
Iteration 144/1000 | Loss: 0.00002021
Iteration 145/1000 | Loss: 0.00002021
Iteration 146/1000 | Loss: 0.00002021
Iteration 147/1000 | Loss: 0.00002021
Iteration 148/1000 | Loss: 0.00002021
Iteration 149/1000 | Loss: 0.00002021
Iteration 150/1000 | Loss: 0.00002021
Iteration 151/1000 | Loss: 0.00002021
Iteration 152/1000 | Loss: 0.00002021
Iteration 153/1000 | Loss: 0.00002021
Iteration 154/1000 | Loss: 0.00002021
Iteration 155/1000 | Loss: 0.00002021
Iteration 156/1000 | Loss: 0.00002021
Iteration 157/1000 | Loss: 0.00002021
Iteration 158/1000 | Loss: 0.00002021
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 158. Stopping optimization.
Last 5 losses: [2.021112413785886e-05, 2.021112413785886e-05, 2.021112413785886e-05, 2.021112413785886e-05, 2.021112413785886e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.021112413785886e-05

Optimization complete. Final v2v error: 3.7907538414001465 mm

Highest mean error: 6.296526908874512 mm for frame 148

Lowest mean error: 3.3398027420043945 mm for frame 51

Saving results

Total time: 144.69179010391235
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00407875
Iteration 2/25 | Loss: 0.00094099
Iteration 3/25 | Loss: 0.00077422
Iteration 4/25 | Loss: 0.00074768
Iteration 5/25 | Loss: 0.00073905
Iteration 6/25 | Loss: 0.00073640
Iteration 7/25 | Loss: 0.00073553
Iteration 8/25 | Loss: 0.00073553
Iteration 9/25 | Loss: 0.00073553
Iteration 10/25 | Loss: 0.00073553
Iteration 11/25 | Loss: 0.00073553
Iteration 12/25 | Loss: 0.00073553
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007355297566391528, 0.0007355297566391528, 0.0007355297566391528, 0.0007355297566391528, 0.0007355297566391528]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007355297566391528

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46517503
Iteration 2/25 | Loss: 0.00111326
Iteration 3/25 | Loss: 0.00111324
Iteration 4/25 | Loss: 0.00111324
Iteration 5/25 | Loss: 0.00111324
Iteration 6/25 | Loss: 0.00111324
Iteration 7/25 | Loss: 0.00111324
Iteration 8/25 | Loss: 0.00111324
Iteration 9/25 | Loss: 0.00111324
Iteration 10/25 | Loss: 0.00111324
Iteration 11/25 | Loss: 0.00111324
Iteration 12/25 | Loss: 0.00111324
Iteration 13/25 | Loss: 0.00111324
Iteration 14/25 | Loss: 0.00111324
Iteration 15/25 | Loss: 0.00111324
Iteration 16/25 | Loss: 0.00111324
Iteration 17/25 | Loss: 0.00111324
Iteration 18/25 | Loss: 0.00111324
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0011132358340546489, 0.0011132358340546489, 0.0011132358340546489, 0.0011132358340546489, 0.0011132358340546489]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011132358340546489

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00111324
Iteration 2/1000 | Loss: 0.00003429
Iteration 3/1000 | Loss: 0.00002319
Iteration 4/1000 | Loss: 0.00001745
Iteration 5/1000 | Loss: 0.00001614
Iteration 6/1000 | Loss: 0.00001557
Iteration 7/1000 | Loss: 0.00001490
Iteration 8/1000 | Loss: 0.00001453
Iteration 9/1000 | Loss: 0.00001416
Iteration 10/1000 | Loss: 0.00001395
Iteration 11/1000 | Loss: 0.00001394
Iteration 12/1000 | Loss: 0.00001386
Iteration 13/1000 | Loss: 0.00001382
Iteration 14/1000 | Loss: 0.00001377
Iteration 15/1000 | Loss: 0.00001377
Iteration 16/1000 | Loss: 0.00001376
Iteration 17/1000 | Loss: 0.00001376
Iteration 18/1000 | Loss: 0.00001375
Iteration 19/1000 | Loss: 0.00001374
Iteration 20/1000 | Loss: 0.00001368
Iteration 21/1000 | Loss: 0.00001368
Iteration 22/1000 | Loss: 0.00001368
Iteration 23/1000 | Loss: 0.00001368
Iteration 24/1000 | Loss: 0.00001368
Iteration 25/1000 | Loss: 0.00001368
Iteration 26/1000 | Loss: 0.00001368
Iteration 27/1000 | Loss: 0.00001367
Iteration 28/1000 | Loss: 0.00001367
Iteration 29/1000 | Loss: 0.00001366
Iteration 30/1000 | Loss: 0.00001365
Iteration 31/1000 | Loss: 0.00001360
Iteration 32/1000 | Loss: 0.00001356
Iteration 33/1000 | Loss: 0.00001356
Iteration 34/1000 | Loss: 0.00001355
Iteration 35/1000 | Loss: 0.00001354
Iteration 36/1000 | Loss: 0.00001354
Iteration 37/1000 | Loss: 0.00001353
Iteration 38/1000 | Loss: 0.00001352
Iteration 39/1000 | Loss: 0.00001352
Iteration 40/1000 | Loss: 0.00001352
Iteration 41/1000 | Loss: 0.00001351
Iteration 42/1000 | Loss: 0.00001351
Iteration 43/1000 | Loss: 0.00001351
Iteration 44/1000 | Loss: 0.00001350
Iteration 45/1000 | Loss: 0.00001350
Iteration 46/1000 | Loss: 0.00001350
Iteration 47/1000 | Loss: 0.00001350
Iteration 48/1000 | Loss: 0.00001349
Iteration 49/1000 | Loss: 0.00001349
Iteration 50/1000 | Loss: 0.00001349
Iteration 51/1000 | Loss: 0.00001349
Iteration 52/1000 | Loss: 0.00001348
Iteration 53/1000 | Loss: 0.00001348
Iteration 54/1000 | Loss: 0.00001347
Iteration 55/1000 | Loss: 0.00001347
Iteration 56/1000 | Loss: 0.00001346
Iteration 57/1000 | Loss: 0.00001346
Iteration 58/1000 | Loss: 0.00001346
Iteration 59/1000 | Loss: 0.00001345
Iteration 60/1000 | Loss: 0.00001345
Iteration 61/1000 | Loss: 0.00001345
Iteration 62/1000 | Loss: 0.00001345
Iteration 63/1000 | Loss: 0.00001344
Iteration 64/1000 | Loss: 0.00001344
Iteration 65/1000 | Loss: 0.00001344
Iteration 66/1000 | Loss: 0.00001343
Iteration 67/1000 | Loss: 0.00001343
Iteration 68/1000 | Loss: 0.00001342
Iteration 69/1000 | Loss: 0.00001342
Iteration 70/1000 | Loss: 0.00001342
Iteration 71/1000 | Loss: 0.00001342
Iteration 72/1000 | Loss: 0.00001341
Iteration 73/1000 | Loss: 0.00001341
Iteration 74/1000 | Loss: 0.00001340
Iteration 75/1000 | Loss: 0.00001340
Iteration 76/1000 | Loss: 0.00001340
Iteration 77/1000 | Loss: 0.00001340
Iteration 78/1000 | Loss: 0.00001340
Iteration 79/1000 | Loss: 0.00001339
Iteration 80/1000 | Loss: 0.00001339
Iteration 81/1000 | Loss: 0.00001338
Iteration 82/1000 | Loss: 0.00001338
Iteration 83/1000 | Loss: 0.00001338
Iteration 84/1000 | Loss: 0.00001338
Iteration 85/1000 | Loss: 0.00001338
Iteration 86/1000 | Loss: 0.00001338
Iteration 87/1000 | Loss: 0.00001337
Iteration 88/1000 | Loss: 0.00001336
Iteration 89/1000 | Loss: 0.00001336
Iteration 90/1000 | Loss: 0.00001336
Iteration 91/1000 | Loss: 0.00001336
Iteration 92/1000 | Loss: 0.00001335
Iteration 93/1000 | Loss: 0.00001335
Iteration 94/1000 | Loss: 0.00001335
Iteration 95/1000 | Loss: 0.00001335
Iteration 96/1000 | Loss: 0.00001334
Iteration 97/1000 | Loss: 0.00001334
Iteration 98/1000 | Loss: 0.00001333
Iteration 99/1000 | Loss: 0.00001333
Iteration 100/1000 | Loss: 0.00001333
Iteration 101/1000 | Loss: 0.00001333
Iteration 102/1000 | Loss: 0.00001333
Iteration 103/1000 | Loss: 0.00001332
Iteration 104/1000 | Loss: 0.00001332
Iteration 105/1000 | Loss: 0.00001332
Iteration 106/1000 | Loss: 0.00001332
Iteration 107/1000 | Loss: 0.00001332
Iteration 108/1000 | Loss: 0.00001332
Iteration 109/1000 | Loss: 0.00001332
Iteration 110/1000 | Loss: 0.00001332
Iteration 111/1000 | Loss: 0.00001332
Iteration 112/1000 | Loss: 0.00001332
Iteration 113/1000 | Loss: 0.00001332
Iteration 114/1000 | Loss: 0.00001332
Iteration 115/1000 | Loss: 0.00001332
Iteration 116/1000 | Loss: 0.00001332
Iteration 117/1000 | Loss: 0.00001331
Iteration 118/1000 | Loss: 0.00001331
Iteration 119/1000 | Loss: 0.00001331
Iteration 120/1000 | Loss: 0.00001331
Iteration 121/1000 | Loss: 0.00001331
Iteration 122/1000 | Loss: 0.00001331
Iteration 123/1000 | Loss: 0.00001331
Iteration 124/1000 | Loss: 0.00001331
Iteration 125/1000 | Loss: 0.00001330
Iteration 126/1000 | Loss: 0.00001330
Iteration 127/1000 | Loss: 0.00001330
Iteration 128/1000 | Loss: 0.00001330
Iteration 129/1000 | Loss: 0.00001330
Iteration 130/1000 | Loss: 0.00001330
Iteration 131/1000 | Loss: 0.00001329
Iteration 132/1000 | Loss: 0.00001329
Iteration 133/1000 | Loss: 0.00001329
Iteration 134/1000 | Loss: 0.00001329
Iteration 135/1000 | Loss: 0.00001329
Iteration 136/1000 | Loss: 0.00001329
Iteration 137/1000 | Loss: 0.00001329
Iteration 138/1000 | Loss: 0.00001329
Iteration 139/1000 | Loss: 0.00001329
Iteration 140/1000 | Loss: 0.00001329
Iteration 141/1000 | Loss: 0.00001329
Iteration 142/1000 | Loss: 0.00001329
Iteration 143/1000 | Loss: 0.00001329
Iteration 144/1000 | Loss: 0.00001329
Iteration 145/1000 | Loss: 0.00001329
Iteration 146/1000 | Loss: 0.00001329
Iteration 147/1000 | Loss: 0.00001329
Iteration 148/1000 | Loss: 0.00001329
Iteration 149/1000 | Loss: 0.00001329
Iteration 150/1000 | Loss: 0.00001329
Iteration 151/1000 | Loss: 0.00001329
Iteration 152/1000 | Loss: 0.00001329
Iteration 153/1000 | Loss: 0.00001329
Iteration 154/1000 | Loss: 0.00001329
Iteration 155/1000 | Loss: 0.00001329
Iteration 156/1000 | Loss: 0.00001329
Iteration 157/1000 | Loss: 0.00001329
Iteration 158/1000 | Loss: 0.00001329
Iteration 159/1000 | Loss: 0.00001329
Iteration 160/1000 | Loss: 0.00001329
Iteration 161/1000 | Loss: 0.00001329
Iteration 162/1000 | Loss: 0.00001329
Iteration 163/1000 | Loss: 0.00001329
Iteration 164/1000 | Loss: 0.00001329
Iteration 165/1000 | Loss: 0.00001329
Iteration 166/1000 | Loss: 0.00001329
Iteration 167/1000 | Loss: 0.00001329
Iteration 168/1000 | Loss: 0.00001329
Iteration 169/1000 | Loss: 0.00001329
Iteration 170/1000 | Loss: 0.00001329
Iteration 171/1000 | Loss: 0.00001329
Iteration 172/1000 | Loss: 0.00001329
Iteration 173/1000 | Loss: 0.00001329
Iteration 174/1000 | Loss: 0.00001329
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 174. Stopping optimization.
Last 5 losses: [1.3291676623339299e-05, 1.3291676623339299e-05, 1.3291676623339299e-05, 1.3291676623339299e-05, 1.3291676623339299e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3291676623339299e-05

Optimization complete. Final v2v error: 2.964942216873169 mm

Highest mean error: 4.938536167144775 mm for frame 81

Lowest mean error: 2.4294211864471436 mm for frame 118

Saving results

Total time: 39.93847894668579
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1084/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1084.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1084
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01062729
Iteration 2/25 | Loss: 0.00280630
Iteration 3/25 | Loss: 0.00173786
Iteration 4/25 | Loss: 0.00140422
Iteration 5/25 | Loss: 0.00118480
Iteration 6/25 | Loss: 0.00108295
Iteration 7/25 | Loss: 0.00105371
Iteration 8/25 | Loss: 0.00104620
Iteration 9/25 | Loss: 0.00098568
Iteration 10/25 | Loss: 0.00099495
Iteration 11/25 | Loss: 0.00098987
Iteration 12/25 | Loss: 0.00098058
Iteration 13/25 | Loss: 0.00097256
Iteration 14/25 | Loss: 0.00095754
Iteration 15/25 | Loss: 0.00095126
Iteration 16/25 | Loss: 0.00096291
Iteration 17/25 | Loss: 0.00095005
Iteration 18/25 | Loss: 0.00094358
Iteration 19/25 | Loss: 0.00094095
Iteration 20/25 | Loss: 0.00094680
Iteration 21/25 | Loss: 0.00093650
Iteration 22/25 | Loss: 0.00093390
Iteration 23/25 | Loss: 0.00093509
Iteration 24/25 | Loss: 0.00093005
Iteration 25/25 | Loss: 0.00092920

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.63579190
Iteration 2/25 | Loss: 0.00215405
Iteration 3/25 | Loss: 0.00206191
Iteration 4/25 | Loss: 0.00206191
Iteration 5/25 | Loss: 0.00206191
Iteration 6/25 | Loss: 0.00206191
Iteration 7/25 | Loss: 0.00206191
Iteration 8/25 | Loss: 0.00206191
Iteration 9/25 | Loss: 0.00206191
Iteration 10/25 | Loss: 0.00206191
Iteration 11/25 | Loss: 0.00206191
Iteration 12/25 | Loss: 0.00206191
Iteration 13/25 | Loss: 0.00206191
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.002061908133327961, 0.002061908133327961, 0.002061908133327961, 0.002061908133327961, 0.002061908133327961]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002061908133327961

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00206191
Iteration 2/1000 | Loss: 0.00025821
Iteration 3/1000 | Loss: 0.00016717
Iteration 4/1000 | Loss: 0.00012779
Iteration 5/1000 | Loss: 0.00019652
Iteration 6/1000 | Loss: 0.00008102
Iteration 7/1000 | Loss: 0.00010685
Iteration 8/1000 | Loss: 0.00046815
Iteration 9/1000 | Loss: 0.00038701
Iteration 10/1000 | Loss: 0.00034489
Iteration 11/1000 | Loss: 0.00007137
Iteration 12/1000 | Loss: 0.00043750
Iteration 13/1000 | Loss: 0.00014754
Iteration 14/1000 | Loss: 0.00018950
Iteration 15/1000 | Loss: 0.00007214
Iteration 16/1000 | Loss: 0.00031830
Iteration 17/1000 | Loss: 0.00063379
Iteration 18/1000 | Loss: 0.00371637
Iteration 19/1000 | Loss: 0.00060303
Iteration 20/1000 | Loss: 0.00017640
Iteration 21/1000 | Loss: 0.00010305
Iteration 22/1000 | Loss: 0.00011948
Iteration 23/1000 | Loss: 0.00005904
Iteration 24/1000 | Loss: 0.00009059
Iteration 25/1000 | Loss: 0.00004376
Iteration 26/1000 | Loss: 0.00023957
Iteration 27/1000 | Loss: 0.00004320
Iteration 28/1000 | Loss: 0.00003475
Iteration 29/1000 | Loss: 0.00002948
Iteration 30/1000 | Loss: 0.00007804
Iteration 31/1000 | Loss: 0.00005897
Iteration 32/1000 | Loss: 0.00008547
Iteration 33/1000 | Loss: 0.00002310
Iteration 34/1000 | Loss: 0.00006547
Iteration 35/1000 | Loss: 0.00006595
Iteration 36/1000 | Loss: 0.00002122
Iteration 37/1000 | Loss: 0.00041738
Iteration 38/1000 | Loss: 0.00021850
Iteration 39/1000 | Loss: 0.00004793
Iteration 40/1000 | Loss: 0.00003457
Iteration 41/1000 | Loss: 0.00033404
Iteration 42/1000 | Loss: 0.00038857
Iteration 43/1000 | Loss: 0.00039448
Iteration 44/1000 | Loss: 0.00027814
Iteration 45/1000 | Loss: 0.00035270
Iteration 46/1000 | Loss: 0.00005244
Iteration 47/1000 | Loss: 0.00002661
Iteration 48/1000 | Loss: 0.00002408
Iteration 49/1000 | Loss: 0.00005035
Iteration 50/1000 | Loss: 0.00002278
Iteration 51/1000 | Loss: 0.00005644
Iteration 52/1000 | Loss: 0.00002451
Iteration 53/1000 | Loss: 0.00004278
Iteration 54/1000 | Loss: 0.00002218
Iteration 55/1000 | Loss: 0.00004788
Iteration 56/1000 | Loss: 0.00002395
Iteration 57/1000 | Loss: 0.00002165
Iteration 58/1000 | Loss: 0.00002162
Iteration 59/1000 | Loss: 0.00002161
Iteration 60/1000 | Loss: 0.00002161
Iteration 61/1000 | Loss: 0.00002160
Iteration 62/1000 | Loss: 0.00004214
Iteration 63/1000 | Loss: 0.00002140
Iteration 64/1000 | Loss: 0.00002557
Iteration 65/1000 | Loss: 0.00002122
Iteration 66/1000 | Loss: 0.00002122
Iteration 67/1000 | Loss: 0.00002121
Iteration 68/1000 | Loss: 0.00005802
Iteration 69/1000 | Loss: 0.00002128
Iteration 70/1000 | Loss: 0.00003278
Iteration 71/1000 | Loss: 0.00002100
Iteration 72/1000 | Loss: 0.00002099
Iteration 73/1000 | Loss: 0.00002099
Iteration 74/1000 | Loss: 0.00002099
Iteration 75/1000 | Loss: 0.00002099
Iteration 76/1000 | Loss: 0.00002099
Iteration 77/1000 | Loss: 0.00002099
Iteration 78/1000 | Loss: 0.00002099
Iteration 79/1000 | Loss: 0.00002099
Iteration 80/1000 | Loss: 0.00002099
Iteration 81/1000 | Loss: 0.00002098
Iteration 82/1000 | Loss: 0.00002098
Iteration 83/1000 | Loss: 0.00002098
Iteration 84/1000 | Loss: 0.00002098
Iteration 85/1000 | Loss: 0.00002098
Iteration 86/1000 | Loss: 0.00002098
Iteration 87/1000 | Loss: 0.00002098
Iteration 88/1000 | Loss: 0.00002097
Iteration 89/1000 | Loss: 0.00002097
Iteration 90/1000 | Loss: 0.00002097
Iteration 91/1000 | Loss: 0.00002097
Iteration 92/1000 | Loss: 0.00002096
Iteration 93/1000 | Loss: 0.00002096
Iteration 94/1000 | Loss: 0.00002095
Iteration 95/1000 | Loss: 0.00002095
Iteration 96/1000 | Loss: 0.00002094
Iteration 97/1000 | Loss: 0.00002093
Iteration 98/1000 | Loss: 0.00002093
Iteration 99/1000 | Loss: 0.00002088
Iteration 100/1000 | Loss: 0.00002086
Iteration 101/1000 | Loss: 0.00002086
Iteration 102/1000 | Loss: 0.00002086
Iteration 103/1000 | Loss: 0.00002085
Iteration 104/1000 | Loss: 0.00002085
Iteration 105/1000 | Loss: 0.00002084
Iteration 106/1000 | Loss: 0.00002084
Iteration 107/1000 | Loss: 0.00002083
Iteration 108/1000 | Loss: 0.00002083
Iteration 109/1000 | Loss: 0.00002083
Iteration 110/1000 | Loss: 0.00002083
Iteration 111/1000 | Loss: 0.00003538
Iteration 112/1000 | Loss: 0.00002082
Iteration 113/1000 | Loss: 0.00002082
Iteration 114/1000 | Loss: 0.00002081
Iteration 115/1000 | Loss: 0.00002080
Iteration 116/1000 | Loss: 0.00002080
Iteration 117/1000 | Loss: 0.00002080
Iteration 118/1000 | Loss: 0.00002080
Iteration 119/1000 | Loss: 0.00002080
Iteration 120/1000 | Loss: 0.00002080
Iteration 121/1000 | Loss: 0.00002080
Iteration 122/1000 | Loss: 0.00002080
Iteration 123/1000 | Loss: 0.00002080
Iteration 124/1000 | Loss: 0.00002080
Iteration 125/1000 | Loss: 0.00002080
Iteration 126/1000 | Loss: 0.00002080
Iteration 127/1000 | Loss: 0.00002080
Iteration 128/1000 | Loss: 0.00002080
Iteration 129/1000 | Loss: 0.00002080
Iteration 130/1000 | Loss: 0.00002080
Iteration 131/1000 | Loss: 0.00002080
Iteration 132/1000 | Loss: 0.00002080
Iteration 133/1000 | Loss: 0.00002080
Iteration 134/1000 | Loss: 0.00002080
Iteration 135/1000 | Loss: 0.00002080
Iteration 136/1000 | Loss: 0.00002080
Iteration 137/1000 | Loss: 0.00002080
Iteration 138/1000 | Loss: 0.00002080
Iteration 139/1000 | Loss: 0.00002080
Iteration 140/1000 | Loss: 0.00002080
Iteration 141/1000 | Loss: 0.00002080
Iteration 142/1000 | Loss: 0.00002080
Iteration 143/1000 | Loss: 0.00002080
Iteration 144/1000 | Loss: 0.00002080
Iteration 145/1000 | Loss: 0.00002080
Iteration 146/1000 | Loss: 0.00002080
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 146. Stopping optimization.
Last 5 losses: [2.079603109450545e-05, 2.079603109450545e-05, 2.079603109450545e-05, 2.079603109450545e-05, 2.079603109450545e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.079603109450545e-05

Optimization complete. Final v2v error: 3.5888514518737793 mm

Highest mean error: 11.397717475891113 mm for frame 40

Lowest mean error: 3.171949863433838 mm for frame 101

Saving results

Total time: 141.42281079292297
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1048/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1048.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1048
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00950012
Iteration 2/25 | Loss: 0.00143316
Iteration 3/25 | Loss: 0.00097655
Iteration 4/25 | Loss: 0.00092219
Iteration 5/25 | Loss: 0.00089927
Iteration 6/25 | Loss: 0.00089225
Iteration 7/25 | Loss: 0.00089139
Iteration 8/25 | Loss: 0.00089137
Iteration 9/25 | Loss: 0.00089137
Iteration 10/25 | Loss: 0.00089137
Iteration 11/25 | Loss: 0.00089137
Iteration 12/25 | Loss: 0.00089137
Iteration 13/25 | Loss: 0.00089137
Iteration 14/25 | Loss: 0.00089137
Iteration 15/25 | Loss: 0.00089137
Iteration 16/25 | Loss: 0.00089137
Iteration 17/25 | Loss: 0.00089137
Iteration 18/25 | Loss: 0.00089137
Iteration 19/25 | Loss: 0.00089137
Iteration 20/25 | Loss: 0.00089137
Iteration 21/25 | Loss: 0.00089137
Iteration 22/25 | Loss: 0.00089137
Iteration 23/25 | Loss: 0.00089137
Iteration 24/25 | Loss: 0.00089137
Iteration 25/25 | Loss: 0.00089137

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.19167411
Iteration 2/25 | Loss: 0.00094307
Iteration 3/25 | Loss: 0.00094305
Iteration 4/25 | Loss: 0.00094305
Iteration 5/25 | Loss: 0.00094305
Iteration 6/25 | Loss: 0.00094305
Iteration 7/25 | Loss: 0.00094305
Iteration 8/25 | Loss: 0.00094305
Iteration 9/25 | Loss: 0.00094305
Iteration 10/25 | Loss: 0.00094305
Iteration 11/25 | Loss: 0.00094305
Iteration 12/25 | Loss: 0.00094305
Iteration 13/25 | Loss: 0.00094305
Iteration 14/25 | Loss: 0.00094305
Iteration 15/25 | Loss: 0.00094305
Iteration 16/25 | Loss: 0.00094305
Iteration 17/25 | Loss: 0.00094305
Iteration 18/25 | Loss: 0.00094305
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009430503123439848, 0.0009430503123439848, 0.0009430503123439848, 0.0009430503123439848, 0.0009430503123439848]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009430503123439848

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00094305
Iteration 2/1000 | Loss: 0.00005160
Iteration 3/1000 | Loss: 0.00003917
Iteration 4/1000 | Loss: 0.00003560
Iteration 5/1000 | Loss: 0.00003318
Iteration 6/1000 | Loss: 0.00003171
Iteration 7/1000 | Loss: 0.00003068
Iteration 8/1000 | Loss: 0.00002983
Iteration 9/1000 | Loss: 0.00002938
Iteration 10/1000 | Loss: 0.00002911
Iteration 11/1000 | Loss: 0.00002886
Iteration 12/1000 | Loss: 0.00002867
Iteration 13/1000 | Loss: 0.00002853
Iteration 14/1000 | Loss: 0.00002852
Iteration 15/1000 | Loss: 0.00002848
Iteration 16/1000 | Loss: 0.00002842
Iteration 17/1000 | Loss: 0.00002839
Iteration 18/1000 | Loss: 0.00002834
Iteration 19/1000 | Loss: 0.00002834
Iteration 20/1000 | Loss: 0.00002830
Iteration 21/1000 | Loss: 0.00002829
Iteration 22/1000 | Loss: 0.00002828
Iteration 23/1000 | Loss: 0.00002824
Iteration 24/1000 | Loss: 0.00002823
Iteration 25/1000 | Loss: 0.00002818
Iteration 26/1000 | Loss: 0.00002817
Iteration 27/1000 | Loss: 0.00002817
Iteration 28/1000 | Loss: 0.00002815
Iteration 29/1000 | Loss: 0.00002811
Iteration 30/1000 | Loss: 0.00002807
Iteration 31/1000 | Loss: 0.00002807
Iteration 32/1000 | Loss: 0.00002807
Iteration 33/1000 | Loss: 0.00002806
Iteration 34/1000 | Loss: 0.00002804
Iteration 35/1000 | Loss: 0.00002804
Iteration 36/1000 | Loss: 0.00002803
Iteration 37/1000 | Loss: 0.00002798
Iteration 38/1000 | Loss: 0.00002794
Iteration 39/1000 | Loss: 0.00002793
Iteration 40/1000 | Loss: 0.00002793
Iteration 41/1000 | Loss: 0.00002793
Iteration 42/1000 | Loss: 0.00002793
Iteration 43/1000 | Loss: 0.00002793
Iteration 44/1000 | Loss: 0.00002792
Iteration 45/1000 | Loss: 0.00002790
Iteration 46/1000 | Loss: 0.00002790
Iteration 47/1000 | Loss: 0.00002790
Iteration 48/1000 | Loss: 0.00002789
Iteration 49/1000 | Loss: 0.00002789
Iteration 50/1000 | Loss: 0.00002787
Iteration 51/1000 | Loss: 0.00002787
Iteration 52/1000 | Loss: 0.00002786
Iteration 53/1000 | Loss: 0.00002786
Iteration 54/1000 | Loss: 0.00002786
Iteration 55/1000 | Loss: 0.00002785
Iteration 56/1000 | Loss: 0.00002785
Iteration 57/1000 | Loss: 0.00002785
Iteration 58/1000 | Loss: 0.00002784
Iteration 59/1000 | Loss: 0.00002784
Iteration 60/1000 | Loss: 0.00002783
Iteration 61/1000 | Loss: 0.00002783
Iteration 62/1000 | Loss: 0.00002783
Iteration 63/1000 | Loss: 0.00002783
Iteration 64/1000 | Loss: 0.00002783
Iteration 65/1000 | Loss: 0.00002783
Iteration 66/1000 | Loss: 0.00002783
Iteration 67/1000 | Loss: 0.00002783
Iteration 68/1000 | Loss: 0.00002783
Iteration 69/1000 | Loss: 0.00002783
Iteration 70/1000 | Loss: 0.00002783
Iteration 71/1000 | Loss: 0.00002782
Iteration 72/1000 | Loss: 0.00002782
Iteration 73/1000 | Loss: 0.00002782
Iteration 74/1000 | Loss: 0.00002782
Iteration 75/1000 | Loss: 0.00002782
Iteration 76/1000 | Loss: 0.00002782
Iteration 77/1000 | Loss: 0.00002781
Iteration 78/1000 | Loss: 0.00002781
Iteration 79/1000 | Loss: 0.00002781
Iteration 80/1000 | Loss: 0.00002781
Iteration 81/1000 | Loss: 0.00002781
Iteration 82/1000 | Loss: 0.00002780
Iteration 83/1000 | Loss: 0.00002780
Iteration 84/1000 | Loss: 0.00002780
Iteration 85/1000 | Loss: 0.00002779
Iteration 86/1000 | Loss: 0.00002779
Iteration 87/1000 | Loss: 0.00002779
Iteration 88/1000 | Loss: 0.00002779
Iteration 89/1000 | Loss: 0.00002779
Iteration 90/1000 | Loss: 0.00002779
Iteration 91/1000 | Loss: 0.00002778
Iteration 92/1000 | Loss: 0.00002778
Iteration 93/1000 | Loss: 0.00002778
Iteration 94/1000 | Loss: 0.00002778
Iteration 95/1000 | Loss: 0.00002778
Iteration 96/1000 | Loss: 0.00002778
Iteration 97/1000 | Loss: 0.00002778
Iteration 98/1000 | Loss: 0.00002778
Iteration 99/1000 | Loss: 0.00002778
Iteration 100/1000 | Loss: 0.00002778
Iteration 101/1000 | Loss: 0.00002778
Iteration 102/1000 | Loss: 0.00002778
Iteration 103/1000 | Loss: 0.00002778
Iteration 104/1000 | Loss: 0.00002777
Iteration 105/1000 | Loss: 0.00002777
Iteration 106/1000 | Loss: 0.00002777
Iteration 107/1000 | Loss: 0.00002777
Iteration 108/1000 | Loss: 0.00002777
Iteration 109/1000 | Loss: 0.00002777
Iteration 110/1000 | Loss: 0.00002776
Iteration 111/1000 | Loss: 0.00002776
Iteration 112/1000 | Loss: 0.00002776
Iteration 113/1000 | Loss: 0.00002776
Iteration 114/1000 | Loss: 0.00002776
Iteration 115/1000 | Loss: 0.00002776
Iteration 116/1000 | Loss: 0.00002776
Iteration 117/1000 | Loss: 0.00002776
Iteration 118/1000 | Loss: 0.00002776
Iteration 119/1000 | Loss: 0.00002776
Iteration 120/1000 | Loss: 0.00002776
Iteration 121/1000 | Loss: 0.00002776
Iteration 122/1000 | Loss: 0.00002776
Iteration 123/1000 | Loss: 0.00002775
Iteration 124/1000 | Loss: 0.00002775
Iteration 125/1000 | Loss: 0.00002775
Iteration 126/1000 | Loss: 0.00002775
Iteration 127/1000 | Loss: 0.00002775
Iteration 128/1000 | Loss: 0.00002775
Iteration 129/1000 | Loss: 0.00002775
Iteration 130/1000 | Loss: 0.00002775
Iteration 131/1000 | Loss: 0.00002774
Iteration 132/1000 | Loss: 0.00002774
Iteration 133/1000 | Loss: 0.00002774
Iteration 134/1000 | Loss: 0.00002774
Iteration 135/1000 | Loss: 0.00002774
Iteration 136/1000 | Loss: 0.00002774
Iteration 137/1000 | Loss: 0.00002774
Iteration 138/1000 | Loss: 0.00002774
Iteration 139/1000 | Loss: 0.00002774
Iteration 140/1000 | Loss: 0.00002774
Iteration 141/1000 | Loss: 0.00002774
Iteration 142/1000 | Loss: 0.00002774
Iteration 143/1000 | Loss: 0.00002773
Iteration 144/1000 | Loss: 0.00002773
Iteration 145/1000 | Loss: 0.00002773
Iteration 146/1000 | Loss: 0.00002773
Iteration 147/1000 | Loss: 0.00002773
Iteration 148/1000 | Loss: 0.00002773
Iteration 149/1000 | Loss: 0.00002772
Iteration 150/1000 | Loss: 0.00002772
Iteration 151/1000 | Loss: 0.00002772
Iteration 152/1000 | Loss: 0.00002772
Iteration 153/1000 | Loss: 0.00002772
Iteration 154/1000 | Loss: 0.00002772
Iteration 155/1000 | Loss: 0.00002772
Iteration 156/1000 | Loss: 0.00002772
Iteration 157/1000 | Loss: 0.00002772
Iteration 158/1000 | Loss: 0.00002772
Iteration 159/1000 | Loss: 0.00002772
Iteration 160/1000 | Loss: 0.00002772
Iteration 161/1000 | Loss: 0.00002771
Iteration 162/1000 | Loss: 0.00002771
Iteration 163/1000 | Loss: 0.00002771
Iteration 164/1000 | Loss: 0.00002771
Iteration 165/1000 | Loss: 0.00002771
Iteration 166/1000 | Loss: 0.00002771
Iteration 167/1000 | Loss: 0.00002771
Iteration 168/1000 | Loss: 0.00002771
Iteration 169/1000 | Loss: 0.00002770
Iteration 170/1000 | Loss: 0.00002770
Iteration 171/1000 | Loss: 0.00002770
Iteration 172/1000 | Loss: 0.00002770
Iteration 173/1000 | Loss: 0.00002770
Iteration 174/1000 | Loss: 0.00002770
Iteration 175/1000 | Loss: 0.00002770
Iteration 176/1000 | Loss: 0.00002770
Iteration 177/1000 | Loss: 0.00002770
Iteration 178/1000 | Loss: 0.00002770
Iteration 179/1000 | Loss: 0.00002770
Iteration 180/1000 | Loss: 0.00002770
Iteration 181/1000 | Loss: 0.00002770
Iteration 182/1000 | Loss: 0.00002769
Iteration 183/1000 | Loss: 0.00002769
Iteration 184/1000 | Loss: 0.00002769
Iteration 185/1000 | Loss: 0.00002769
Iteration 186/1000 | Loss: 0.00002769
Iteration 187/1000 | Loss: 0.00002769
Iteration 188/1000 | Loss: 0.00002769
Iteration 189/1000 | Loss: 0.00002769
Iteration 190/1000 | Loss: 0.00002769
Iteration 191/1000 | Loss: 0.00002769
Iteration 192/1000 | Loss: 0.00002768
Iteration 193/1000 | Loss: 0.00002768
Iteration 194/1000 | Loss: 0.00002768
Iteration 195/1000 | Loss: 0.00002768
Iteration 196/1000 | Loss: 0.00002768
Iteration 197/1000 | Loss: 0.00002768
Iteration 198/1000 | Loss: 0.00002768
Iteration 199/1000 | Loss: 0.00002768
Iteration 200/1000 | Loss: 0.00002768
Iteration 201/1000 | Loss: 0.00002768
Iteration 202/1000 | Loss: 0.00002768
Iteration 203/1000 | Loss: 0.00002768
Iteration 204/1000 | Loss: 0.00002768
Iteration 205/1000 | Loss: 0.00002768
Iteration 206/1000 | Loss: 0.00002768
Iteration 207/1000 | Loss: 0.00002768
Iteration 208/1000 | Loss: 0.00002768
Iteration 209/1000 | Loss: 0.00002768
Iteration 210/1000 | Loss: 0.00002768
Iteration 211/1000 | Loss: 0.00002768
Iteration 212/1000 | Loss: 0.00002768
Iteration 213/1000 | Loss: 0.00002768
Iteration 214/1000 | Loss: 0.00002768
Iteration 215/1000 | Loss: 0.00002768
Iteration 216/1000 | Loss: 0.00002768
Iteration 217/1000 | Loss: 0.00002768
Iteration 218/1000 | Loss: 0.00002768
Iteration 219/1000 | Loss: 0.00002768
Iteration 220/1000 | Loss: 0.00002768
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 220. Stopping optimization.
Last 5 losses: [2.7683658117894083e-05, 2.7683658117894083e-05, 2.7683658117894083e-05, 2.7683658117894083e-05, 2.7683658117894083e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7683658117894083e-05

Optimization complete. Final v2v error: 4.278252601623535 mm

Highest mean error: 5.460450172424316 mm for frame 103

Lowest mean error: 3.493147850036621 mm for frame 39

Saving results

Total time: 48.13108420372009
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840672
Iteration 2/25 | Loss: 0.00108726
Iteration 3/25 | Loss: 0.00084054
Iteration 4/25 | Loss: 0.00079360
Iteration 5/25 | Loss: 0.00078464
Iteration 6/25 | Loss: 0.00078200
Iteration 7/25 | Loss: 0.00078175
Iteration 8/25 | Loss: 0.00078175
Iteration 9/25 | Loss: 0.00078175
Iteration 10/25 | Loss: 0.00078175
Iteration 11/25 | Loss: 0.00078175
Iteration 12/25 | Loss: 0.00078175
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007817483274266124, 0.0007817483274266124, 0.0007817483274266124, 0.0007817483274266124, 0.0007817483274266124]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007817483274266124

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55688822
Iteration 2/25 | Loss: 0.00130798
Iteration 3/25 | Loss: 0.00130792
Iteration 4/25 | Loss: 0.00130792
Iteration 5/25 | Loss: 0.00130792
Iteration 6/25 | Loss: 0.00130792
Iteration 7/25 | Loss: 0.00130792
Iteration 8/25 | Loss: 0.00130792
Iteration 9/25 | Loss: 0.00130792
Iteration 10/25 | Loss: 0.00130792
Iteration 11/25 | Loss: 0.00130792
Iteration 12/25 | Loss: 0.00130792
Iteration 13/25 | Loss: 0.00130792
Iteration 14/25 | Loss: 0.00130792
Iteration 15/25 | Loss: 0.00130792
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013079204363748431, 0.0013079204363748431, 0.0013079204363748431, 0.0013079204363748431, 0.0013079204363748431]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013079204363748431

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00130792
Iteration 2/1000 | Loss: 0.00003428
Iteration 3/1000 | Loss: 0.00002478
Iteration 4/1000 | Loss: 0.00002090
Iteration 5/1000 | Loss: 0.00001935
Iteration 6/1000 | Loss: 0.00001817
Iteration 7/1000 | Loss: 0.00001745
Iteration 8/1000 | Loss: 0.00001704
Iteration 9/1000 | Loss: 0.00001669
Iteration 10/1000 | Loss: 0.00001645
Iteration 11/1000 | Loss: 0.00001637
Iteration 12/1000 | Loss: 0.00001620
Iteration 13/1000 | Loss: 0.00001619
Iteration 14/1000 | Loss: 0.00001615
Iteration 15/1000 | Loss: 0.00001614
Iteration 16/1000 | Loss: 0.00001612
Iteration 17/1000 | Loss: 0.00001610
Iteration 18/1000 | Loss: 0.00001609
Iteration 19/1000 | Loss: 0.00001604
Iteration 20/1000 | Loss: 0.00001595
Iteration 21/1000 | Loss: 0.00001590
Iteration 22/1000 | Loss: 0.00001589
Iteration 23/1000 | Loss: 0.00001589
Iteration 24/1000 | Loss: 0.00001588
Iteration 25/1000 | Loss: 0.00001587
Iteration 26/1000 | Loss: 0.00001587
Iteration 27/1000 | Loss: 0.00001586
Iteration 28/1000 | Loss: 0.00001586
Iteration 29/1000 | Loss: 0.00001586
Iteration 30/1000 | Loss: 0.00001585
Iteration 31/1000 | Loss: 0.00001585
Iteration 32/1000 | Loss: 0.00001583
Iteration 33/1000 | Loss: 0.00001583
Iteration 34/1000 | Loss: 0.00001582
Iteration 35/1000 | Loss: 0.00001582
Iteration 36/1000 | Loss: 0.00001581
Iteration 37/1000 | Loss: 0.00001581
Iteration 38/1000 | Loss: 0.00001580
Iteration 39/1000 | Loss: 0.00001579
Iteration 40/1000 | Loss: 0.00001579
Iteration 41/1000 | Loss: 0.00001578
Iteration 42/1000 | Loss: 0.00001577
Iteration 43/1000 | Loss: 0.00001577
Iteration 44/1000 | Loss: 0.00001577
Iteration 45/1000 | Loss: 0.00001576
Iteration 46/1000 | Loss: 0.00001576
Iteration 47/1000 | Loss: 0.00001576
Iteration 48/1000 | Loss: 0.00001575
Iteration 49/1000 | Loss: 0.00001575
Iteration 50/1000 | Loss: 0.00001575
Iteration 51/1000 | Loss: 0.00001574
Iteration 52/1000 | Loss: 0.00001574
Iteration 53/1000 | Loss: 0.00001573
Iteration 54/1000 | Loss: 0.00001573
Iteration 55/1000 | Loss: 0.00001573
Iteration 56/1000 | Loss: 0.00001573
Iteration 57/1000 | Loss: 0.00001573
Iteration 58/1000 | Loss: 0.00001572
Iteration 59/1000 | Loss: 0.00001572
Iteration 60/1000 | Loss: 0.00001572
Iteration 61/1000 | Loss: 0.00001572
Iteration 62/1000 | Loss: 0.00001572
Iteration 63/1000 | Loss: 0.00001572
Iteration 64/1000 | Loss: 0.00001572
Iteration 65/1000 | Loss: 0.00001572
Iteration 66/1000 | Loss: 0.00001572
Iteration 67/1000 | Loss: 0.00001571
Iteration 68/1000 | Loss: 0.00001571
Iteration 69/1000 | Loss: 0.00001571
Iteration 70/1000 | Loss: 0.00001571
Iteration 71/1000 | Loss: 0.00001571
Iteration 72/1000 | Loss: 0.00001571
Iteration 73/1000 | Loss: 0.00001571
Iteration 74/1000 | Loss: 0.00001571
Iteration 75/1000 | Loss: 0.00001571
Iteration 76/1000 | Loss: 0.00001571
Iteration 77/1000 | Loss: 0.00001570
Iteration 78/1000 | Loss: 0.00001570
Iteration 79/1000 | Loss: 0.00001570
Iteration 80/1000 | Loss: 0.00001570
Iteration 81/1000 | Loss: 0.00001570
Iteration 82/1000 | Loss: 0.00001570
Iteration 83/1000 | Loss: 0.00001570
Iteration 84/1000 | Loss: 0.00001569
Iteration 85/1000 | Loss: 0.00001569
Iteration 86/1000 | Loss: 0.00001569
Iteration 87/1000 | Loss: 0.00001569
Iteration 88/1000 | Loss: 0.00001568
Iteration 89/1000 | Loss: 0.00001568
Iteration 90/1000 | Loss: 0.00001568
Iteration 91/1000 | Loss: 0.00001568
Iteration 92/1000 | Loss: 0.00001567
Iteration 93/1000 | Loss: 0.00001567
Iteration 94/1000 | Loss: 0.00001567
Iteration 95/1000 | Loss: 0.00001567
Iteration 96/1000 | Loss: 0.00001567
Iteration 97/1000 | Loss: 0.00001567
Iteration 98/1000 | Loss: 0.00001566
Iteration 99/1000 | Loss: 0.00001566
Iteration 100/1000 | Loss: 0.00001566
Iteration 101/1000 | Loss: 0.00001565
Iteration 102/1000 | Loss: 0.00001565
Iteration 103/1000 | Loss: 0.00001565
Iteration 104/1000 | Loss: 0.00001565
Iteration 105/1000 | Loss: 0.00001565
Iteration 106/1000 | Loss: 0.00001565
Iteration 107/1000 | Loss: 0.00001565
Iteration 108/1000 | Loss: 0.00001564
Iteration 109/1000 | Loss: 0.00001564
Iteration 110/1000 | Loss: 0.00001564
Iteration 111/1000 | Loss: 0.00001564
Iteration 112/1000 | Loss: 0.00001564
Iteration 113/1000 | Loss: 0.00001564
Iteration 114/1000 | Loss: 0.00001564
Iteration 115/1000 | Loss: 0.00001564
Iteration 116/1000 | Loss: 0.00001564
Iteration 117/1000 | Loss: 0.00001564
Iteration 118/1000 | Loss: 0.00001564
Iteration 119/1000 | Loss: 0.00001564
Iteration 120/1000 | Loss: 0.00001563
Iteration 121/1000 | Loss: 0.00001563
Iteration 122/1000 | Loss: 0.00001563
Iteration 123/1000 | Loss: 0.00001563
Iteration 124/1000 | Loss: 0.00001563
Iteration 125/1000 | Loss: 0.00001563
Iteration 126/1000 | Loss: 0.00001563
Iteration 127/1000 | Loss: 0.00001563
Iteration 128/1000 | Loss: 0.00001563
Iteration 129/1000 | Loss: 0.00001563
Iteration 130/1000 | Loss: 0.00001563
Iteration 131/1000 | Loss: 0.00001563
Iteration 132/1000 | Loss: 0.00001563
Iteration 133/1000 | Loss: 0.00001563
Iteration 134/1000 | Loss: 0.00001563
Iteration 135/1000 | Loss: 0.00001563
Iteration 136/1000 | Loss: 0.00001563
Iteration 137/1000 | Loss: 0.00001563
Iteration 138/1000 | Loss: 0.00001563
Iteration 139/1000 | Loss: 0.00001563
Iteration 140/1000 | Loss: 0.00001563
Iteration 141/1000 | Loss: 0.00001563
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [1.5629690096830018e-05, 1.5629690096830018e-05, 1.5629690096830018e-05, 1.5629690096830018e-05, 1.5629690096830018e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5629690096830018e-05

Optimization complete. Final v2v error: 3.3325679302215576 mm

Highest mean error: 4.6170654296875 mm for frame 116

Lowest mean error: 2.8577487468719482 mm for frame 184

Saving results

Total time: 42.17740201950073
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1073/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1073.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1073
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01020686
Iteration 2/25 | Loss: 0.00257482
Iteration 3/25 | Loss: 0.00195952
Iteration 4/25 | Loss: 0.00183076
Iteration 5/25 | Loss: 0.00174438
Iteration 6/25 | Loss: 0.00159838
Iteration 7/25 | Loss: 0.00154908
Iteration 8/25 | Loss: 0.00150978
Iteration 9/25 | Loss: 0.00148467
Iteration 10/25 | Loss: 0.00148033
Iteration 11/25 | Loss: 0.00146631
Iteration 12/25 | Loss: 0.00144946
Iteration 13/25 | Loss: 0.00144560
Iteration 14/25 | Loss: 0.00143986
Iteration 15/25 | Loss: 0.00143402
Iteration 16/25 | Loss: 0.00143144
Iteration 17/25 | Loss: 0.00142853
Iteration 18/25 | Loss: 0.00142507
Iteration 19/25 | Loss: 0.00142430
Iteration 20/25 | Loss: 0.00142392
Iteration 21/25 | Loss: 0.00142263
Iteration 22/25 | Loss: 0.00144079
Iteration 23/25 | Loss: 0.00144299
Iteration 24/25 | Loss: 0.00141361
Iteration 25/25 | Loss: 0.00139950

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58600771
Iteration 2/25 | Loss: 0.00444719
Iteration 3/25 | Loss: 0.00444719
Iteration 4/25 | Loss: 0.00444719
Iteration 5/25 | Loss: 0.00444719
Iteration 6/25 | Loss: 0.00444719
Iteration 7/25 | Loss: 0.00444718
Iteration 8/25 | Loss: 0.00444718
Iteration 9/25 | Loss: 0.00444718
Iteration 10/25 | Loss: 0.00444718
Iteration 11/25 | Loss: 0.00444718
Iteration 12/25 | Loss: 0.00444718
Iteration 13/25 | Loss: 0.00444718
Iteration 14/25 | Loss: 0.00444718
Iteration 15/25 | Loss: 0.00444718
Iteration 16/25 | Loss: 0.00444718
Iteration 17/25 | Loss: 0.00444718
Iteration 18/25 | Loss: 0.00444718
Iteration 19/25 | Loss: 0.00444718
Iteration 20/25 | Loss: 0.00444718
Iteration 21/25 | Loss: 0.00444718
Iteration 22/25 | Loss: 0.00444718
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.004447183106094599, 0.004447183106094599, 0.004447183106094599, 0.004447183106094599, 0.004447183106094599]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004447183106094599

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00444718
Iteration 2/1000 | Loss: 0.01045672
Iteration 3/1000 | Loss: 0.00097080
Iteration 4/1000 | Loss: 0.00056190
Iteration 5/1000 | Loss: 0.00039157
Iteration 6/1000 | Loss: 0.00023412
Iteration 7/1000 | Loss: 0.00013519
Iteration 8/1000 | Loss: 0.00008508
Iteration 9/1000 | Loss: 0.00005929
Iteration 10/1000 | Loss: 0.00004777
Iteration 11/1000 | Loss: 0.00004188
Iteration 12/1000 | Loss: 0.00003571
Iteration 13/1000 | Loss: 0.00003238
Iteration 14/1000 | Loss: 0.00023222
Iteration 15/1000 | Loss: 0.00025107
Iteration 16/1000 | Loss: 0.00003636
Iteration 17/1000 | Loss: 0.00002989
Iteration 18/1000 | Loss: 0.00002762
Iteration 19/1000 | Loss: 0.00022639
Iteration 20/1000 | Loss: 0.00003032
Iteration 21/1000 | Loss: 0.00002432
Iteration 22/1000 | Loss: 0.00002323
Iteration 23/1000 | Loss: 0.00002190
Iteration 24/1000 | Loss: 0.00002032
Iteration 25/1000 | Loss: 0.00001973
Iteration 26/1000 | Loss: 0.00001938
Iteration 27/1000 | Loss: 0.00001929
Iteration 28/1000 | Loss: 0.00001920
Iteration 29/1000 | Loss: 0.00001902
Iteration 30/1000 | Loss: 0.00001887
Iteration 31/1000 | Loss: 0.00001884
Iteration 32/1000 | Loss: 0.00001875
Iteration 33/1000 | Loss: 0.00001875
Iteration 34/1000 | Loss: 0.00001872
Iteration 35/1000 | Loss: 0.00001872
Iteration 36/1000 | Loss: 0.00001872
Iteration 37/1000 | Loss: 0.00001872
Iteration 38/1000 | Loss: 0.00001872
Iteration 39/1000 | Loss: 0.00001871
Iteration 40/1000 | Loss: 0.00001871
Iteration 41/1000 | Loss: 0.00001871
Iteration 42/1000 | Loss: 0.00001871
Iteration 43/1000 | Loss: 0.00001871
Iteration 44/1000 | Loss: 0.00001871
Iteration 45/1000 | Loss: 0.00001871
Iteration 46/1000 | Loss: 0.00001871
Iteration 47/1000 | Loss: 0.00001870
Iteration 48/1000 | Loss: 0.00001870
Iteration 49/1000 | Loss: 0.00001870
Iteration 50/1000 | Loss: 0.00001869
Iteration 51/1000 | Loss: 0.00001868
Iteration 52/1000 | Loss: 0.00001868
Iteration 53/1000 | Loss: 0.00001868
Iteration 54/1000 | Loss: 0.00001868
Iteration 55/1000 | Loss: 0.00001868
Iteration 56/1000 | Loss: 0.00001867
Iteration 57/1000 | Loss: 0.00001867
Iteration 58/1000 | Loss: 0.00001867
Iteration 59/1000 | Loss: 0.00001867
Iteration 60/1000 | Loss: 0.00001866
Iteration 61/1000 | Loss: 0.00001866
Iteration 62/1000 | Loss: 0.00001865
Iteration 63/1000 | Loss: 0.00001865
Iteration 64/1000 | Loss: 0.00001864
Iteration 65/1000 | Loss: 0.00001864
Iteration 66/1000 | Loss: 0.00001864
Iteration 67/1000 | Loss: 0.00001863
Iteration 68/1000 | Loss: 0.00001863
Iteration 69/1000 | Loss: 0.00001863
Iteration 70/1000 | Loss: 0.00001863
Iteration 71/1000 | Loss: 0.00001863
Iteration 72/1000 | Loss: 0.00001862
Iteration 73/1000 | Loss: 0.00001862
Iteration 74/1000 | Loss: 0.00001862
Iteration 75/1000 | Loss: 0.00001862
Iteration 76/1000 | Loss: 0.00001862
Iteration 77/1000 | Loss: 0.00001861
Iteration 78/1000 | Loss: 0.00001861
Iteration 79/1000 | Loss: 0.00001861
Iteration 80/1000 | Loss: 0.00001861
Iteration 81/1000 | Loss: 0.00001860
Iteration 82/1000 | Loss: 0.00001860
Iteration 83/1000 | Loss: 0.00001860
Iteration 84/1000 | Loss: 0.00001860
Iteration 85/1000 | Loss: 0.00001860
Iteration 86/1000 | Loss: 0.00001859
Iteration 87/1000 | Loss: 0.00001859
Iteration 88/1000 | Loss: 0.00001859
Iteration 89/1000 | Loss: 0.00001859
Iteration 90/1000 | Loss: 0.00001859
Iteration 91/1000 | Loss: 0.00001859
Iteration 92/1000 | Loss: 0.00001859
Iteration 93/1000 | Loss: 0.00001859
Iteration 94/1000 | Loss: 0.00001859
Iteration 95/1000 | Loss: 0.00001858
Iteration 96/1000 | Loss: 0.00001858
Iteration 97/1000 | Loss: 0.00001858
Iteration 98/1000 | Loss: 0.00001858
Iteration 99/1000 | Loss: 0.00001858
Iteration 100/1000 | Loss: 0.00001858
Iteration 101/1000 | Loss: 0.00001857
Iteration 102/1000 | Loss: 0.00001857
Iteration 103/1000 | Loss: 0.00001857
Iteration 104/1000 | Loss: 0.00001857
Iteration 105/1000 | Loss: 0.00001857
Iteration 106/1000 | Loss: 0.00001857
Iteration 107/1000 | Loss: 0.00001857
Iteration 108/1000 | Loss: 0.00001857
Iteration 109/1000 | Loss: 0.00001857
Iteration 110/1000 | Loss: 0.00001857
Iteration 111/1000 | Loss: 0.00001857
Iteration 112/1000 | Loss: 0.00001857
Iteration 113/1000 | Loss: 0.00001857
Iteration 114/1000 | Loss: 0.00001857
Iteration 115/1000 | Loss: 0.00001857
Iteration 116/1000 | Loss: 0.00001857
Iteration 117/1000 | Loss: 0.00001856
Iteration 118/1000 | Loss: 0.00001856
Iteration 119/1000 | Loss: 0.00001856
Iteration 120/1000 | Loss: 0.00001856
Iteration 121/1000 | Loss: 0.00001856
Iteration 122/1000 | Loss: 0.00001856
Iteration 123/1000 | Loss: 0.00001856
Iteration 124/1000 | Loss: 0.00001856
Iteration 125/1000 | Loss: 0.00001856
Iteration 126/1000 | Loss: 0.00001856
Iteration 127/1000 | Loss: 0.00001855
Iteration 128/1000 | Loss: 0.00001855
Iteration 129/1000 | Loss: 0.00001855
Iteration 130/1000 | Loss: 0.00001855
Iteration 131/1000 | Loss: 0.00001855
Iteration 132/1000 | Loss: 0.00001855
Iteration 133/1000 | Loss: 0.00001855
Iteration 134/1000 | Loss: 0.00001855
Iteration 135/1000 | Loss: 0.00001855
Iteration 136/1000 | Loss: 0.00001855
Iteration 137/1000 | Loss: 0.00001855
Iteration 138/1000 | Loss: 0.00001855
Iteration 139/1000 | Loss: 0.00001855
Iteration 140/1000 | Loss: 0.00001855
Iteration 141/1000 | Loss: 0.00001855
Iteration 142/1000 | Loss: 0.00001855
Iteration 143/1000 | Loss: 0.00001855
Iteration 144/1000 | Loss: 0.00001855
Iteration 145/1000 | Loss: 0.00001855
Iteration 146/1000 | Loss: 0.00001855
Iteration 147/1000 | Loss: 0.00001855
Iteration 148/1000 | Loss: 0.00001855
Iteration 149/1000 | Loss: 0.00001855
Iteration 150/1000 | Loss: 0.00001855
Iteration 151/1000 | Loss: 0.00001855
Iteration 152/1000 | Loss: 0.00001855
Iteration 153/1000 | Loss: 0.00001855
Iteration 154/1000 | Loss: 0.00001855
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [1.854957918112632e-05, 1.854957918112632e-05, 1.854957918112632e-05, 1.854957918112632e-05, 1.854957918112632e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.854957918112632e-05

Optimization complete. Final v2v error: 3.5639779567718506 mm

Highest mean error: 4.151971340179443 mm for frame 37

Lowest mean error: 3.3366167545318604 mm for frame 56

Saving results

Total time: 109.66699457168579
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1081/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1081.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1081
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00835628
Iteration 2/25 | Loss: 0.00110350
Iteration 3/25 | Loss: 0.00083388
Iteration 4/25 | Loss: 0.00079131
Iteration 5/25 | Loss: 0.00078295
Iteration 6/25 | Loss: 0.00076609
Iteration 7/25 | Loss: 0.00076266
Iteration 8/25 | Loss: 0.00076161
Iteration 9/25 | Loss: 0.00076150
Iteration 10/25 | Loss: 0.00076150
Iteration 11/25 | Loss: 0.00076150
Iteration 12/25 | Loss: 0.00076150
Iteration 13/25 | Loss: 0.00076150
Iteration 14/25 | Loss: 0.00076150
Iteration 15/25 | Loss: 0.00076150
Iteration 16/25 | Loss: 0.00076150
Iteration 17/25 | Loss: 0.00076150
Iteration 18/25 | Loss: 0.00076150
Iteration 19/25 | Loss: 0.00076150
Iteration 20/25 | Loss: 0.00076150
Iteration 21/25 | Loss: 0.00076150
Iteration 22/25 | Loss: 0.00076149
Iteration 23/25 | Loss: 0.00076149
Iteration 24/25 | Loss: 0.00076149
Iteration 25/25 | Loss: 0.00076149

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.74499249
Iteration 2/25 | Loss: 0.00124395
Iteration 3/25 | Loss: 0.00124395
Iteration 4/25 | Loss: 0.00124395
Iteration 5/25 | Loss: 0.00124395
Iteration 6/25 | Loss: 0.00124395
Iteration 7/25 | Loss: 0.00124395
Iteration 8/25 | Loss: 0.00124395
Iteration 9/25 | Loss: 0.00124395
Iteration 10/25 | Loss: 0.00124395
Iteration 11/25 | Loss: 0.00124395
Iteration 12/25 | Loss: 0.00124395
Iteration 13/25 | Loss: 0.00124395
Iteration 14/25 | Loss: 0.00124395
Iteration 15/25 | Loss: 0.00124395
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0012439452111721039, 0.0012439452111721039, 0.0012439452111721039, 0.0012439452111721039, 0.0012439452111721039]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012439452111721039

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00124395
Iteration 2/1000 | Loss: 0.00002223
Iteration 3/1000 | Loss: 0.00001771
Iteration 4/1000 | Loss: 0.00001676
Iteration 5/1000 | Loss: 0.00001595
Iteration 6/1000 | Loss: 0.00001568
Iteration 7/1000 | Loss: 0.00001529
Iteration 8/1000 | Loss: 0.00001502
Iteration 9/1000 | Loss: 0.00001483
Iteration 10/1000 | Loss: 0.00001480
Iteration 11/1000 | Loss: 0.00001478
Iteration 12/1000 | Loss: 0.00001462
Iteration 13/1000 | Loss: 0.00001461
Iteration 14/1000 | Loss: 0.00001460
Iteration 15/1000 | Loss: 0.00001455
Iteration 16/1000 | Loss: 0.00001455
Iteration 17/1000 | Loss: 0.00001455
Iteration 18/1000 | Loss: 0.00001455
Iteration 19/1000 | Loss: 0.00001455
Iteration 20/1000 | Loss: 0.00001454
Iteration 21/1000 | Loss: 0.00001454
Iteration 22/1000 | Loss: 0.00001452
Iteration 23/1000 | Loss: 0.00001452
Iteration 24/1000 | Loss: 0.00001452
Iteration 25/1000 | Loss: 0.00001451
Iteration 26/1000 | Loss: 0.00001451
Iteration 27/1000 | Loss: 0.00001450
Iteration 28/1000 | Loss: 0.00001450
Iteration 29/1000 | Loss: 0.00001449
Iteration 30/1000 | Loss: 0.00001449
Iteration 31/1000 | Loss: 0.00001449
Iteration 32/1000 | Loss: 0.00001448
Iteration 33/1000 | Loss: 0.00001448
Iteration 34/1000 | Loss: 0.00001447
Iteration 35/1000 | Loss: 0.00001447
Iteration 36/1000 | Loss: 0.00001447
Iteration 37/1000 | Loss: 0.00001447
Iteration 38/1000 | Loss: 0.00001447
Iteration 39/1000 | Loss: 0.00001446
Iteration 40/1000 | Loss: 0.00001446
Iteration 41/1000 | Loss: 0.00001446
Iteration 42/1000 | Loss: 0.00001446
Iteration 43/1000 | Loss: 0.00001446
Iteration 44/1000 | Loss: 0.00001446
Iteration 45/1000 | Loss: 0.00001446
Iteration 46/1000 | Loss: 0.00001446
Iteration 47/1000 | Loss: 0.00001446
Iteration 48/1000 | Loss: 0.00001445
Iteration 49/1000 | Loss: 0.00001443
Iteration 50/1000 | Loss: 0.00001442
Iteration 51/1000 | Loss: 0.00001442
Iteration 52/1000 | Loss: 0.00001442
Iteration 53/1000 | Loss: 0.00001441
Iteration 54/1000 | Loss: 0.00001441
Iteration 55/1000 | Loss: 0.00001440
Iteration 56/1000 | Loss: 0.00001440
Iteration 57/1000 | Loss: 0.00001439
Iteration 58/1000 | Loss: 0.00001439
Iteration 59/1000 | Loss: 0.00001438
Iteration 60/1000 | Loss: 0.00001438
Iteration 61/1000 | Loss: 0.00001438
Iteration 62/1000 | Loss: 0.00001438
Iteration 63/1000 | Loss: 0.00001438
Iteration 64/1000 | Loss: 0.00001438
Iteration 65/1000 | Loss: 0.00001438
Iteration 66/1000 | Loss: 0.00001436
Iteration 67/1000 | Loss: 0.00001435
Iteration 68/1000 | Loss: 0.00001435
Iteration 69/1000 | Loss: 0.00001435
Iteration 70/1000 | Loss: 0.00001434
Iteration 71/1000 | Loss: 0.00001434
Iteration 72/1000 | Loss: 0.00001433
Iteration 73/1000 | Loss: 0.00001432
Iteration 74/1000 | Loss: 0.00001432
Iteration 75/1000 | Loss: 0.00001432
Iteration 76/1000 | Loss: 0.00001432
Iteration 77/1000 | Loss: 0.00001431
Iteration 78/1000 | Loss: 0.00001431
Iteration 79/1000 | Loss: 0.00001430
Iteration 80/1000 | Loss: 0.00001430
Iteration 81/1000 | Loss: 0.00001429
Iteration 82/1000 | Loss: 0.00001429
Iteration 83/1000 | Loss: 0.00001428
Iteration 84/1000 | Loss: 0.00001428
Iteration 85/1000 | Loss: 0.00001427
Iteration 86/1000 | Loss: 0.00001427
Iteration 87/1000 | Loss: 0.00001427
Iteration 88/1000 | Loss: 0.00001427
Iteration 89/1000 | Loss: 0.00001426
Iteration 90/1000 | Loss: 0.00001426
Iteration 91/1000 | Loss: 0.00001426
Iteration 92/1000 | Loss: 0.00001426
Iteration 93/1000 | Loss: 0.00001426
Iteration 94/1000 | Loss: 0.00001425
Iteration 95/1000 | Loss: 0.00001425
Iteration 96/1000 | Loss: 0.00001425
Iteration 97/1000 | Loss: 0.00001424
Iteration 98/1000 | Loss: 0.00001424
Iteration 99/1000 | Loss: 0.00001424
Iteration 100/1000 | Loss: 0.00001424
Iteration 101/1000 | Loss: 0.00001424
Iteration 102/1000 | Loss: 0.00001424
Iteration 103/1000 | Loss: 0.00001424
Iteration 104/1000 | Loss: 0.00001423
Iteration 105/1000 | Loss: 0.00001423
Iteration 106/1000 | Loss: 0.00001423
Iteration 107/1000 | Loss: 0.00001423
Iteration 108/1000 | Loss: 0.00001423
Iteration 109/1000 | Loss: 0.00001423
Iteration 110/1000 | Loss: 0.00001423
Iteration 111/1000 | Loss: 0.00001423
Iteration 112/1000 | Loss: 0.00001423
Iteration 113/1000 | Loss: 0.00001422
Iteration 114/1000 | Loss: 0.00001422
Iteration 115/1000 | Loss: 0.00001422
Iteration 116/1000 | Loss: 0.00001422
Iteration 117/1000 | Loss: 0.00001422
Iteration 118/1000 | Loss: 0.00001422
Iteration 119/1000 | Loss: 0.00001422
Iteration 120/1000 | Loss: 0.00001422
Iteration 121/1000 | Loss: 0.00001422
Iteration 122/1000 | Loss: 0.00001422
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [1.4224518054106738e-05, 1.4224518054106738e-05, 1.4224518054106738e-05, 1.4224518054106738e-05, 1.4224518054106738e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4224518054106738e-05

Optimization complete. Final v2v error: 3.207811117172241 mm

Highest mean error: 3.55063796043396 mm for frame 125

Lowest mean error: 2.773740291595459 mm for frame 238

Saving results

Total time: 43.679033517837524
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1038/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1038.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1038
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00943721
Iteration 2/25 | Loss: 0.00110866
Iteration 3/25 | Loss: 0.00084707
Iteration 4/25 | Loss: 0.00079368
Iteration 5/25 | Loss: 0.00078037
Iteration 6/25 | Loss: 0.00077809
Iteration 7/25 | Loss: 0.00077786
Iteration 8/25 | Loss: 0.00077786
Iteration 9/25 | Loss: 0.00077786
Iteration 10/25 | Loss: 0.00077786
Iteration 11/25 | Loss: 0.00077786
Iteration 12/25 | Loss: 0.00077786
Iteration 13/25 | Loss: 0.00077786
Iteration 14/25 | Loss: 0.00077786
Iteration 15/25 | Loss: 0.00077786
Iteration 16/25 | Loss: 0.00077786
Iteration 17/25 | Loss: 0.00077786
Iteration 18/25 | Loss: 0.00077786
Iteration 19/25 | Loss: 0.00077786
Iteration 20/25 | Loss: 0.00077786
Iteration 21/25 | Loss: 0.00077786
Iteration 22/25 | Loss: 0.00077786
Iteration 23/25 | Loss: 0.00077786
Iteration 24/25 | Loss: 0.00077786
Iteration 25/25 | Loss: 0.00077786

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58399820
Iteration 2/25 | Loss: 0.00099290
Iteration 3/25 | Loss: 0.00099286
Iteration 4/25 | Loss: 0.00099286
Iteration 5/25 | Loss: 0.00099286
Iteration 6/25 | Loss: 0.00099286
Iteration 7/25 | Loss: 0.00099286
Iteration 8/25 | Loss: 0.00099286
Iteration 9/25 | Loss: 0.00099286
Iteration 10/25 | Loss: 0.00099286
Iteration 11/25 | Loss: 0.00099286
Iteration 12/25 | Loss: 0.00099286
Iteration 13/25 | Loss: 0.00099286
Iteration 14/25 | Loss: 0.00099286
Iteration 15/25 | Loss: 0.00099286
Iteration 16/25 | Loss: 0.00099286
Iteration 17/25 | Loss: 0.00099286
Iteration 18/25 | Loss: 0.00099286
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009928609943017364, 0.0009928609943017364, 0.0009928609943017364, 0.0009928609943017364, 0.0009928609943017364]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009928609943017364

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00099286
Iteration 2/1000 | Loss: 0.00002992
Iteration 3/1000 | Loss: 0.00002079
Iteration 4/1000 | Loss: 0.00001725
Iteration 5/1000 | Loss: 0.00001575
Iteration 6/1000 | Loss: 0.00001487
Iteration 7/1000 | Loss: 0.00001442
Iteration 8/1000 | Loss: 0.00001407
Iteration 9/1000 | Loss: 0.00001386
Iteration 10/1000 | Loss: 0.00001371
Iteration 11/1000 | Loss: 0.00001368
Iteration 12/1000 | Loss: 0.00001363
Iteration 13/1000 | Loss: 0.00001363
Iteration 14/1000 | Loss: 0.00001359
Iteration 15/1000 | Loss: 0.00001358
Iteration 16/1000 | Loss: 0.00001357
Iteration 17/1000 | Loss: 0.00001357
Iteration 18/1000 | Loss: 0.00001356
Iteration 19/1000 | Loss: 0.00001353
Iteration 20/1000 | Loss: 0.00001352
Iteration 21/1000 | Loss: 0.00001351
Iteration 22/1000 | Loss: 0.00001350
Iteration 23/1000 | Loss: 0.00001350
Iteration 24/1000 | Loss: 0.00001348
Iteration 25/1000 | Loss: 0.00001348
Iteration 26/1000 | Loss: 0.00001345
Iteration 27/1000 | Loss: 0.00001345
Iteration 28/1000 | Loss: 0.00001341
Iteration 29/1000 | Loss: 0.00001340
Iteration 30/1000 | Loss: 0.00001340
Iteration 31/1000 | Loss: 0.00001340
Iteration 32/1000 | Loss: 0.00001340
Iteration 33/1000 | Loss: 0.00001340
Iteration 34/1000 | Loss: 0.00001340
Iteration 35/1000 | Loss: 0.00001340
Iteration 36/1000 | Loss: 0.00001340
Iteration 37/1000 | Loss: 0.00001340
Iteration 38/1000 | Loss: 0.00001340
Iteration 39/1000 | Loss: 0.00001340
Iteration 40/1000 | Loss: 0.00001340
Iteration 41/1000 | Loss: 0.00001340
Iteration 42/1000 | Loss: 0.00001337
Iteration 43/1000 | Loss: 0.00001337
Iteration 44/1000 | Loss: 0.00001337
Iteration 45/1000 | Loss: 0.00001337
Iteration 46/1000 | Loss: 0.00001337
Iteration 47/1000 | Loss: 0.00001337
Iteration 48/1000 | Loss: 0.00001337
Iteration 49/1000 | Loss: 0.00001337
Iteration 50/1000 | Loss: 0.00001337
Iteration 51/1000 | Loss: 0.00001336
Iteration 52/1000 | Loss: 0.00001336
Iteration 53/1000 | Loss: 0.00001336
Iteration 54/1000 | Loss: 0.00001336
Iteration 55/1000 | Loss: 0.00001336
Iteration 56/1000 | Loss: 0.00001336
Iteration 57/1000 | Loss: 0.00001336
Iteration 58/1000 | Loss: 0.00001336
Iteration 59/1000 | Loss: 0.00001335
Iteration 60/1000 | Loss: 0.00001335
Iteration 61/1000 | Loss: 0.00001335
Iteration 62/1000 | Loss: 0.00001333
Iteration 63/1000 | Loss: 0.00001333
Iteration 64/1000 | Loss: 0.00001333
Iteration 65/1000 | Loss: 0.00001333
Iteration 66/1000 | Loss: 0.00001333
Iteration 67/1000 | Loss: 0.00001333
Iteration 68/1000 | Loss: 0.00001333
Iteration 69/1000 | Loss: 0.00001332
Iteration 70/1000 | Loss: 0.00001332
Iteration 71/1000 | Loss: 0.00001332
Iteration 72/1000 | Loss: 0.00001331
Iteration 73/1000 | Loss: 0.00001331
Iteration 74/1000 | Loss: 0.00001331
Iteration 75/1000 | Loss: 0.00001331
Iteration 76/1000 | Loss: 0.00001331
Iteration 77/1000 | Loss: 0.00001331
Iteration 78/1000 | Loss: 0.00001330
Iteration 79/1000 | Loss: 0.00001330
Iteration 80/1000 | Loss: 0.00001330
Iteration 81/1000 | Loss: 0.00001329
Iteration 82/1000 | Loss: 0.00001329
Iteration 83/1000 | Loss: 0.00001329
Iteration 84/1000 | Loss: 0.00001328
Iteration 85/1000 | Loss: 0.00001327
Iteration 86/1000 | Loss: 0.00001327
Iteration 87/1000 | Loss: 0.00001326
Iteration 88/1000 | Loss: 0.00001326
Iteration 89/1000 | Loss: 0.00001326
Iteration 90/1000 | Loss: 0.00001325
Iteration 91/1000 | Loss: 0.00001325
Iteration 92/1000 | Loss: 0.00001325
Iteration 93/1000 | Loss: 0.00001325
Iteration 94/1000 | Loss: 0.00001325
Iteration 95/1000 | Loss: 0.00001325
Iteration 96/1000 | Loss: 0.00001325
Iteration 97/1000 | Loss: 0.00001325
Iteration 98/1000 | Loss: 0.00001324
Iteration 99/1000 | Loss: 0.00001324
Iteration 100/1000 | Loss: 0.00001324
Iteration 101/1000 | Loss: 0.00001324
Iteration 102/1000 | Loss: 0.00001324
Iteration 103/1000 | Loss: 0.00001323
Iteration 104/1000 | Loss: 0.00001323
Iteration 105/1000 | Loss: 0.00001323
Iteration 106/1000 | Loss: 0.00001323
Iteration 107/1000 | Loss: 0.00001323
Iteration 108/1000 | Loss: 0.00001323
Iteration 109/1000 | Loss: 0.00001323
Iteration 110/1000 | Loss: 0.00001322
Iteration 111/1000 | Loss: 0.00001321
Iteration 112/1000 | Loss: 0.00001321
Iteration 113/1000 | Loss: 0.00001321
Iteration 114/1000 | Loss: 0.00001321
Iteration 115/1000 | Loss: 0.00001321
Iteration 116/1000 | Loss: 0.00001321
Iteration 117/1000 | Loss: 0.00001320
Iteration 118/1000 | Loss: 0.00001320
Iteration 119/1000 | Loss: 0.00001320
Iteration 120/1000 | Loss: 0.00001320
Iteration 121/1000 | Loss: 0.00001320
Iteration 122/1000 | Loss: 0.00001319
Iteration 123/1000 | Loss: 0.00001319
Iteration 124/1000 | Loss: 0.00001319
Iteration 125/1000 | Loss: 0.00001318
Iteration 126/1000 | Loss: 0.00001318
Iteration 127/1000 | Loss: 0.00001318
Iteration 128/1000 | Loss: 0.00001318
Iteration 129/1000 | Loss: 0.00001318
Iteration 130/1000 | Loss: 0.00001318
Iteration 131/1000 | Loss: 0.00001318
Iteration 132/1000 | Loss: 0.00001318
Iteration 133/1000 | Loss: 0.00001318
Iteration 134/1000 | Loss: 0.00001318
Iteration 135/1000 | Loss: 0.00001317
Iteration 136/1000 | Loss: 0.00001317
Iteration 137/1000 | Loss: 0.00001317
Iteration 138/1000 | Loss: 0.00001317
Iteration 139/1000 | Loss: 0.00001317
Iteration 140/1000 | Loss: 0.00001317
Iteration 141/1000 | Loss: 0.00001317
Iteration 142/1000 | Loss: 0.00001317
Iteration 143/1000 | Loss: 0.00001317
Iteration 144/1000 | Loss: 0.00001317
Iteration 145/1000 | Loss: 0.00001317
Iteration 146/1000 | Loss: 0.00001317
Iteration 147/1000 | Loss: 0.00001317
Iteration 148/1000 | Loss: 0.00001317
Iteration 149/1000 | Loss: 0.00001317
Iteration 150/1000 | Loss: 0.00001317
Iteration 151/1000 | Loss: 0.00001317
Iteration 152/1000 | Loss: 0.00001317
Iteration 153/1000 | Loss: 0.00001317
Iteration 154/1000 | Loss: 0.00001316
Iteration 155/1000 | Loss: 0.00001316
Iteration 156/1000 | Loss: 0.00001316
Iteration 157/1000 | Loss: 0.00001316
Iteration 158/1000 | Loss: 0.00001316
Iteration 159/1000 | Loss: 0.00001316
Iteration 160/1000 | Loss: 0.00001316
Iteration 161/1000 | Loss: 0.00001316
Iteration 162/1000 | Loss: 0.00001316
Iteration 163/1000 | Loss: 0.00001316
Iteration 164/1000 | Loss: 0.00001316
Iteration 165/1000 | Loss: 0.00001316
Iteration 166/1000 | Loss: 0.00001316
Iteration 167/1000 | Loss: 0.00001316
Iteration 168/1000 | Loss: 0.00001316
Iteration 169/1000 | Loss: 0.00001316
Iteration 170/1000 | Loss: 0.00001316
Iteration 171/1000 | Loss: 0.00001316
Iteration 172/1000 | Loss: 0.00001316
Iteration 173/1000 | Loss: 0.00001316
Iteration 174/1000 | Loss: 0.00001316
Iteration 175/1000 | Loss: 0.00001316
Iteration 176/1000 | Loss: 0.00001316
Iteration 177/1000 | Loss: 0.00001316
Iteration 178/1000 | Loss: 0.00001316
Iteration 179/1000 | Loss: 0.00001316
Iteration 180/1000 | Loss: 0.00001316
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 180. Stopping optimization.
Last 5 losses: [1.3160816706658807e-05, 1.3160816706658807e-05, 1.3160816706658807e-05, 1.3160816706658807e-05, 1.3160816706658807e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3160816706658807e-05

Optimization complete. Final v2v error: 3.1227989196777344 mm

Highest mean error: 3.3006792068481445 mm for frame 52

Lowest mean error: 2.880143404006958 mm for frame 145

Saving results

Total time: 44.62090754508972
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00582708
Iteration 2/25 | Loss: 0.00100156
Iteration 3/25 | Loss: 0.00085140
Iteration 4/25 | Loss: 0.00081775
Iteration 5/25 | Loss: 0.00081339
Iteration 6/25 | Loss: 0.00081230
Iteration 7/25 | Loss: 0.00081230
Iteration 8/25 | Loss: 0.00081230
Iteration 9/25 | Loss: 0.00081230
Iteration 10/25 | Loss: 0.00081230
Iteration 11/25 | Loss: 0.00081230
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008123004226945341, 0.0008123004226945341, 0.0008123004226945341, 0.0008123004226945341, 0.0008123004226945341]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008123004226945341

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.49387956
Iteration 2/25 | Loss: 0.00126089
Iteration 3/25 | Loss: 0.00126088
Iteration 4/25 | Loss: 0.00126088
Iteration 5/25 | Loss: 0.00126087
Iteration 6/25 | Loss: 0.00126087
Iteration 7/25 | Loss: 0.00126087
Iteration 8/25 | Loss: 0.00126087
Iteration 9/25 | Loss: 0.00126087
Iteration 10/25 | Loss: 0.00126087
Iteration 11/25 | Loss: 0.00126087
Iteration 12/25 | Loss: 0.00126087
Iteration 13/25 | Loss: 0.00126087
Iteration 14/25 | Loss: 0.00126087
Iteration 15/25 | Loss: 0.00126087
Iteration 16/25 | Loss: 0.00126087
Iteration 17/25 | Loss: 0.00126087
Iteration 18/25 | Loss: 0.00126087
Iteration 19/25 | Loss: 0.00126087
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0012608733959496021, 0.0012608733959496021, 0.0012608733959496021, 0.0012608733959496021, 0.0012608733959496021]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012608733959496021

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00126087
Iteration 2/1000 | Loss: 0.00004552
Iteration 3/1000 | Loss: 0.00002798
Iteration 4/1000 | Loss: 0.00002580
Iteration 5/1000 | Loss: 0.00002427
Iteration 6/1000 | Loss: 0.00002360
Iteration 7/1000 | Loss: 0.00002288
Iteration 8/1000 | Loss: 0.00002246
Iteration 9/1000 | Loss: 0.00002217
Iteration 10/1000 | Loss: 0.00002197
Iteration 11/1000 | Loss: 0.00002183
Iteration 12/1000 | Loss: 0.00002179
Iteration 13/1000 | Loss: 0.00002172
Iteration 14/1000 | Loss: 0.00002170
Iteration 15/1000 | Loss: 0.00002170
Iteration 16/1000 | Loss: 0.00002170
Iteration 17/1000 | Loss: 0.00002170
Iteration 18/1000 | Loss: 0.00002170
Iteration 19/1000 | Loss: 0.00002170
Iteration 20/1000 | Loss: 0.00002170
Iteration 21/1000 | Loss: 0.00002170
Iteration 22/1000 | Loss: 0.00002170
Iteration 23/1000 | Loss: 0.00002169
Iteration 24/1000 | Loss: 0.00002169
Iteration 25/1000 | Loss: 0.00002169
Iteration 26/1000 | Loss: 0.00002169
Iteration 27/1000 | Loss: 0.00002169
Iteration 28/1000 | Loss: 0.00002169
Iteration 29/1000 | Loss: 0.00002169
Iteration 30/1000 | Loss: 0.00002169
Iteration 31/1000 | Loss: 0.00002169
Iteration 32/1000 | Loss: 0.00002169
Iteration 33/1000 | Loss: 0.00002169
Iteration 34/1000 | Loss: 0.00002168
Iteration 35/1000 | Loss: 0.00002167
Iteration 36/1000 | Loss: 0.00002167
Iteration 37/1000 | Loss: 0.00002166
Iteration 38/1000 | Loss: 0.00002166
Iteration 39/1000 | Loss: 0.00002166
Iteration 40/1000 | Loss: 0.00002166
Iteration 41/1000 | Loss: 0.00002166
Iteration 42/1000 | Loss: 0.00002165
Iteration 43/1000 | Loss: 0.00002165
Iteration 44/1000 | Loss: 0.00002165
Iteration 45/1000 | Loss: 0.00002164
Iteration 46/1000 | Loss: 0.00002164
Iteration 47/1000 | Loss: 0.00002164
Iteration 48/1000 | Loss: 0.00002164
Iteration 49/1000 | Loss: 0.00002164
Iteration 50/1000 | Loss: 0.00002164
Iteration 51/1000 | Loss: 0.00002163
Iteration 52/1000 | Loss: 0.00002163
Iteration 53/1000 | Loss: 0.00002163
Iteration 54/1000 | Loss: 0.00002163
Iteration 55/1000 | Loss: 0.00002162
Iteration 56/1000 | Loss: 0.00002162
Iteration 57/1000 | Loss: 0.00002162
Iteration 58/1000 | Loss: 0.00002162
Iteration 59/1000 | Loss: 0.00002162
Iteration 60/1000 | Loss: 0.00002162
Iteration 61/1000 | Loss: 0.00002162
Iteration 62/1000 | Loss: 0.00002162
Iteration 63/1000 | Loss: 0.00002161
Iteration 64/1000 | Loss: 0.00002161
Iteration 65/1000 | Loss: 0.00002161
Iteration 66/1000 | Loss: 0.00002161
Iteration 67/1000 | Loss: 0.00002161
Iteration 68/1000 | Loss: 0.00002161
Iteration 69/1000 | Loss: 0.00002161
Iteration 70/1000 | Loss: 0.00002160
Iteration 71/1000 | Loss: 0.00002160
Iteration 72/1000 | Loss: 0.00002160
Iteration 73/1000 | Loss: 0.00002160
Iteration 74/1000 | Loss: 0.00002159
Iteration 75/1000 | Loss: 0.00002159
Iteration 76/1000 | Loss: 0.00002159
Iteration 77/1000 | Loss: 0.00002159
Iteration 78/1000 | Loss: 0.00002158
Iteration 79/1000 | Loss: 0.00002158
Iteration 80/1000 | Loss: 0.00002158
Iteration 81/1000 | Loss: 0.00002158
Iteration 82/1000 | Loss: 0.00002158
Iteration 83/1000 | Loss: 0.00002158
Iteration 84/1000 | Loss: 0.00002157
Iteration 85/1000 | Loss: 0.00002157
Iteration 86/1000 | Loss: 0.00002157
Iteration 87/1000 | Loss: 0.00002157
Iteration 88/1000 | Loss: 0.00002156
Iteration 89/1000 | Loss: 0.00002155
Iteration 90/1000 | Loss: 0.00002155
Iteration 91/1000 | Loss: 0.00002155
Iteration 92/1000 | Loss: 0.00002155
Iteration 93/1000 | Loss: 0.00002155
Iteration 94/1000 | Loss: 0.00002155
Iteration 95/1000 | Loss: 0.00002154
Iteration 96/1000 | Loss: 0.00002154
Iteration 97/1000 | Loss: 0.00002154
Iteration 98/1000 | Loss: 0.00002154
Iteration 99/1000 | Loss: 0.00002154
Iteration 100/1000 | Loss: 0.00002154
Iteration 101/1000 | Loss: 0.00002154
Iteration 102/1000 | Loss: 0.00002154
Iteration 103/1000 | Loss: 0.00002153
Iteration 104/1000 | Loss: 0.00002153
Iteration 105/1000 | Loss: 0.00002153
Iteration 106/1000 | Loss: 0.00002153
Iteration 107/1000 | Loss: 0.00002153
Iteration 108/1000 | Loss: 0.00002153
Iteration 109/1000 | Loss: 0.00002153
Iteration 110/1000 | Loss: 0.00002153
Iteration 111/1000 | Loss: 0.00002153
Iteration 112/1000 | Loss: 0.00002153
Iteration 113/1000 | Loss: 0.00002153
Iteration 114/1000 | Loss: 0.00002153
Iteration 115/1000 | Loss: 0.00002153
Iteration 116/1000 | Loss: 0.00002153
Iteration 117/1000 | Loss: 0.00002153
Iteration 118/1000 | Loss: 0.00002153
Iteration 119/1000 | Loss: 0.00002153
Iteration 120/1000 | Loss: 0.00002153
Iteration 121/1000 | Loss: 0.00002153
Iteration 122/1000 | Loss: 0.00002153
Iteration 123/1000 | Loss: 0.00002153
Iteration 124/1000 | Loss: 0.00002153
Iteration 125/1000 | Loss: 0.00002153
Iteration 126/1000 | Loss: 0.00002153
Iteration 127/1000 | Loss: 0.00002153
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [2.1530768208322115e-05, 2.1530768208322115e-05, 2.1530768208322115e-05, 2.1530768208322115e-05, 2.1530768208322115e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1530768208322115e-05

Optimization complete. Final v2v error: 3.848548650741577 mm

Highest mean error: 4.326902389526367 mm for frame 31

Lowest mean error: 3.2768938541412354 mm for frame 105

Saving results

Total time: 36.83603572845459
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00395905
Iteration 2/25 | Loss: 0.00096292
Iteration 3/25 | Loss: 0.00077920
Iteration 4/25 | Loss: 0.00074068
Iteration 5/25 | Loss: 0.00073333
Iteration 6/25 | Loss: 0.00073176
Iteration 7/25 | Loss: 0.00073133
Iteration 8/25 | Loss: 0.00073133
Iteration 9/25 | Loss: 0.00073133
Iteration 10/25 | Loss: 0.00073133
Iteration 11/25 | Loss: 0.00073133
Iteration 12/25 | Loss: 0.00073133
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007313291425816715, 0.0007313291425816715, 0.0007313291425816715, 0.0007313291425816715, 0.0007313291425816715]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007313291425816715

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57778084
Iteration 2/25 | Loss: 0.00118063
Iteration 3/25 | Loss: 0.00118063
Iteration 4/25 | Loss: 0.00118063
Iteration 5/25 | Loss: 0.00118063
Iteration 6/25 | Loss: 0.00118063
Iteration 7/25 | Loss: 0.00118063
Iteration 8/25 | Loss: 0.00118062
Iteration 9/25 | Loss: 0.00118062
Iteration 10/25 | Loss: 0.00118062
Iteration 11/25 | Loss: 0.00118062
Iteration 12/25 | Loss: 0.00118062
Iteration 13/25 | Loss: 0.00118062
Iteration 14/25 | Loss: 0.00118062
Iteration 15/25 | Loss: 0.00118062
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.001180624240078032, 0.001180624240078032, 0.001180624240078032, 0.001180624240078032, 0.001180624240078032]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001180624240078032

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118062
Iteration 2/1000 | Loss: 0.00002322
Iteration 3/1000 | Loss: 0.00001739
Iteration 4/1000 | Loss: 0.00001622
Iteration 5/1000 | Loss: 0.00001531
Iteration 6/1000 | Loss: 0.00001467
Iteration 7/1000 | Loss: 0.00001428
Iteration 8/1000 | Loss: 0.00001410
Iteration 9/1000 | Loss: 0.00001400
Iteration 10/1000 | Loss: 0.00001390
Iteration 11/1000 | Loss: 0.00001378
Iteration 12/1000 | Loss: 0.00001367
Iteration 13/1000 | Loss: 0.00001364
Iteration 14/1000 | Loss: 0.00001358
Iteration 15/1000 | Loss: 0.00001357
Iteration 16/1000 | Loss: 0.00001356
Iteration 17/1000 | Loss: 0.00001355
Iteration 18/1000 | Loss: 0.00001354
Iteration 19/1000 | Loss: 0.00001353
Iteration 20/1000 | Loss: 0.00001353
Iteration 21/1000 | Loss: 0.00001352
Iteration 22/1000 | Loss: 0.00001352
Iteration 23/1000 | Loss: 0.00001349
Iteration 24/1000 | Loss: 0.00001348
Iteration 25/1000 | Loss: 0.00001348
Iteration 26/1000 | Loss: 0.00001348
Iteration 27/1000 | Loss: 0.00001347
Iteration 28/1000 | Loss: 0.00001347
Iteration 29/1000 | Loss: 0.00001347
Iteration 30/1000 | Loss: 0.00001346
Iteration 31/1000 | Loss: 0.00001346
Iteration 32/1000 | Loss: 0.00001346
Iteration 33/1000 | Loss: 0.00001346
Iteration 34/1000 | Loss: 0.00001346
Iteration 35/1000 | Loss: 0.00001345
Iteration 36/1000 | Loss: 0.00001345
Iteration 37/1000 | Loss: 0.00001345
Iteration 38/1000 | Loss: 0.00001345
Iteration 39/1000 | Loss: 0.00001345
Iteration 40/1000 | Loss: 0.00001345
Iteration 41/1000 | Loss: 0.00001345
Iteration 42/1000 | Loss: 0.00001345
Iteration 43/1000 | Loss: 0.00001344
Iteration 44/1000 | Loss: 0.00001344
Iteration 45/1000 | Loss: 0.00001343
Iteration 46/1000 | Loss: 0.00001343
Iteration 47/1000 | Loss: 0.00001343
Iteration 48/1000 | Loss: 0.00001343
Iteration 49/1000 | Loss: 0.00001343
Iteration 50/1000 | Loss: 0.00001343
Iteration 51/1000 | Loss: 0.00001343
Iteration 52/1000 | Loss: 0.00001343
Iteration 53/1000 | Loss: 0.00001343
Iteration 54/1000 | Loss: 0.00001343
Iteration 55/1000 | Loss: 0.00001343
Iteration 56/1000 | Loss: 0.00001342
Iteration 57/1000 | Loss: 0.00001342
Iteration 58/1000 | Loss: 0.00001342
Iteration 59/1000 | Loss: 0.00001341
Iteration 60/1000 | Loss: 0.00001341
Iteration 61/1000 | Loss: 0.00001341
Iteration 62/1000 | Loss: 0.00001341
Iteration 63/1000 | Loss: 0.00001341
Iteration 64/1000 | Loss: 0.00001340
Iteration 65/1000 | Loss: 0.00001340
Iteration 66/1000 | Loss: 0.00001340
Iteration 67/1000 | Loss: 0.00001340
Iteration 68/1000 | Loss: 0.00001340
Iteration 69/1000 | Loss: 0.00001339
Iteration 70/1000 | Loss: 0.00001339
Iteration 71/1000 | Loss: 0.00001338
Iteration 72/1000 | Loss: 0.00001338
Iteration 73/1000 | Loss: 0.00001337
Iteration 74/1000 | Loss: 0.00001337
Iteration 75/1000 | Loss: 0.00001337
Iteration 76/1000 | Loss: 0.00001337
Iteration 77/1000 | Loss: 0.00001337
Iteration 78/1000 | Loss: 0.00001337
Iteration 79/1000 | Loss: 0.00001337
Iteration 80/1000 | Loss: 0.00001337
Iteration 81/1000 | Loss: 0.00001337
Iteration 82/1000 | Loss: 0.00001336
Iteration 83/1000 | Loss: 0.00001336
Iteration 84/1000 | Loss: 0.00001336
Iteration 85/1000 | Loss: 0.00001336
Iteration 86/1000 | Loss: 0.00001336
Iteration 87/1000 | Loss: 0.00001335
Iteration 88/1000 | Loss: 0.00001335
Iteration 89/1000 | Loss: 0.00001335
Iteration 90/1000 | Loss: 0.00001335
Iteration 91/1000 | Loss: 0.00001335
Iteration 92/1000 | Loss: 0.00001335
Iteration 93/1000 | Loss: 0.00001334
Iteration 94/1000 | Loss: 0.00001334
Iteration 95/1000 | Loss: 0.00001334
Iteration 96/1000 | Loss: 0.00001334
Iteration 97/1000 | Loss: 0.00001334
Iteration 98/1000 | Loss: 0.00001334
Iteration 99/1000 | Loss: 0.00001334
Iteration 100/1000 | Loss: 0.00001333
Iteration 101/1000 | Loss: 0.00001333
Iteration 102/1000 | Loss: 0.00001333
Iteration 103/1000 | Loss: 0.00001333
Iteration 104/1000 | Loss: 0.00001333
Iteration 105/1000 | Loss: 0.00001333
Iteration 106/1000 | Loss: 0.00001333
Iteration 107/1000 | Loss: 0.00001333
Iteration 108/1000 | Loss: 0.00001333
Iteration 109/1000 | Loss: 0.00001332
Iteration 110/1000 | Loss: 0.00001332
Iteration 111/1000 | Loss: 0.00001332
Iteration 112/1000 | Loss: 0.00001332
Iteration 113/1000 | Loss: 0.00001332
Iteration 114/1000 | Loss: 0.00001332
Iteration 115/1000 | Loss: 0.00001332
Iteration 116/1000 | Loss: 0.00001332
Iteration 117/1000 | Loss: 0.00001332
Iteration 118/1000 | Loss: 0.00001332
Iteration 119/1000 | Loss: 0.00001332
Iteration 120/1000 | Loss: 0.00001332
Iteration 121/1000 | Loss: 0.00001332
Iteration 122/1000 | Loss: 0.00001332
Iteration 123/1000 | Loss: 0.00001332
Iteration 124/1000 | Loss: 0.00001332
Iteration 125/1000 | Loss: 0.00001332
Iteration 126/1000 | Loss: 0.00001332
Iteration 127/1000 | Loss: 0.00001332
Iteration 128/1000 | Loss: 0.00001332
Iteration 129/1000 | Loss: 0.00001332
Iteration 130/1000 | Loss: 0.00001332
Iteration 131/1000 | Loss: 0.00001332
Iteration 132/1000 | Loss: 0.00001332
Iteration 133/1000 | Loss: 0.00001332
Iteration 134/1000 | Loss: 0.00001332
Iteration 135/1000 | Loss: 0.00001332
Iteration 136/1000 | Loss: 0.00001332
Iteration 137/1000 | Loss: 0.00001332
Iteration 138/1000 | Loss: 0.00001332
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [1.3320341167855076e-05, 1.3320341167855076e-05, 1.3320341167855076e-05, 1.3320341167855076e-05, 1.3320341167855076e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3320341167855076e-05

Optimization complete. Final v2v error: 3.0788280963897705 mm

Highest mean error: 3.4689865112304688 mm for frame 74

Lowest mean error: 2.857079267501831 mm for frame 25

Saving results

Total time: 35.02270579338074
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1031/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1031.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1031
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00440035
Iteration 2/25 | Loss: 0.00112771
Iteration 3/25 | Loss: 0.00082448
Iteration 4/25 | Loss: 0.00079405
Iteration 5/25 | Loss: 0.00078551
Iteration 6/25 | Loss: 0.00078364
Iteration 7/25 | Loss: 0.00078334
Iteration 8/25 | Loss: 0.00078334
Iteration 9/25 | Loss: 0.00078334
Iteration 10/25 | Loss: 0.00078334
Iteration 11/25 | Loss: 0.00078334
Iteration 12/25 | Loss: 0.00078334
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000783344148658216, 0.000783344148658216, 0.000783344148658216, 0.000783344148658216, 0.000783344148658216]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000783344148658216

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59948182
Iteration 2/25 | Loss: 0.00135414
Iteration 3/25 | Loss: 0.00135413
Iteration 4/25 | Loss: 0.00135413
Iteration 5/25 | Loss: 0.00135413
Iteration 6/25 | Loss: 0.00135413
Iteration 7/25 | Loss: 0.00135413
Iteration 8/25 | Loss: 0.00135413
Iteration 9/25 | Loss: 0.00135413
Iteration 10/25 | Loss: 0.00135413
Iteration 11/25 | Loss: 0.00135413
Iteration 12/25 | Loss: 0.00135413
Iteration 13/25 | Loss: 0.00135413
Iteration 14/25 | Loss: 0.00135413
Iteration 15/25 | Loss: 0.00135413
Iteration 16/25 | Loss: 0.00135413
Iteration 17/25 | Loss: 0.00135413
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0013541291700676084, 0.0013541291700676084, 0.0013541291700676084, 0.0013541291700676084, 0.0013541291700676084]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013541291700676084

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00135413
Iteration 2/1000 | Loss: 0.00002693
Iteration 3/1000 | Loss: 0.00002072
Iteration 4/1000 | Loss: 0.00001722
Iteration 5/1000 | Loss: 0.00001608
Iteration 6/1000 | Loss: 0.00001528
Iteration 7/1000 | Loss: 0.00001476
Iteration 8/1000 | Loss: 0.00001448
Iteration 9/1000 | Loss: 0.00001421
Iteration 10/1000 | Loss: 0.00001408
Iteration 11/1000 | Loss: 0.00001399
Iteration 12/1000 | Loss: 0.00001382
Iteration 13/1000 | Loss: 0.00001373
Iteration 14/1000 | Loss: 0.00001371
Iteration 15/1000 | Loss: 0.00001369
Iteration 16/1000 | Loss: 0.00001369
Iteration 17/1000 | Loss: 0.00001355
Iteration 18/1000 | Loss: 0.00001351
Iteration 19/1000 | Loss: 0.00001350
Iteration 20/1000 | Loss: 0.00001349
Iteration 21/1000 | Loss: 0.00001348
Iteration 22/1000 | Loss: 0.00001348
Iteration 23/1000 | Loss: 0.00001348
Iteration 24/1000 | Loss: 0.00001347
Iteration 25/1000 | Loss: 0.00001346
Iteration 26/1000 | Loss: 0.00001346
Iteration 27/1000 | Loss: 0.00001345
Iteration 28/1000 | Loss: 0.00001345
Iteration 29/1000 | Loss: 0.00001345
Iteration 30/1000 | Loss: 0.00001344
Iteration 31/1000 | Loss: 0.00001344
Iteration 32/1000 | Loss: 0.00001343
Iteration 33/1000 | Loss: 0.00001343
Iteration 34/1000 | Loss: 0.00001343
Iteration 35/1000 | Loss: 0.00001342
Iteration 36/1000 | Loss: 0.00001340
Iteration 37/1000 | Loss: 0.00001339
Iteration 38/1000 | Loss: 0.00001338
Iteration 39/1000 | Loss: 0.00001337
Iteration 40/1000 | Loss: 0.00001337
Iteration 41/1000 | Loss: 0.00001336
Iteration 42/1000 | Loss: 0.00001336
Iteration 43/1000 | Loss: 0.00001336
Iteration 44/1000 | Loss: 0.00001336
Iteration 45/1000 | Loss: 0.00001336
Iteration 46/1000 | Loss: 0.00001336
Iteration 47/1000 | Loss: 0.00001336
Iteration 48/1000 | Loss: 0.00001336
Iteration 49/1000 | Loss: 0.00001336
Iteration 50/1000 | Loss: 0.00001336
Iteration 51/1000 | Loss: 0.00001335
Iteration 52/1000 | Loss: 0.00001335
Iteration 53/1000 | Loss: 0.00001335
Iteration 54/1000 | Loss: 0.00001335
Iteration 55/1000 | Loss: 0.00001334
Iteration 56/1000 | Loss: 0.00001334
Iteration 57/1000 | Loss: 0.00001333
Iteration 58/1000 | Loss: 0.00001333
Iteration 59/1000 | Loss: 0.00001333
Iteration 60/1000 | Loss: 0.00001333
Iteration 61/1000 | Loss: 0.00001332
Iteration 62/1000 | Loss: 0.00001332
Iteration 63/1000 | Loss: 0.00001332
Iteration 64/1000 | Loss: 0.00001332
Iteration 65/1000 | Loss: 0.00001332
Iteration 66/1000 | Loss: 0.00001332
Iteration 67/1000 | Loss: 0.00001332
Iteration 68/1000 | Loss: 0.00001331
Iteration 69/1000 | Loss: 0.00001331
Iteration 70/1000 | Loss: 0.00001331
Iteration 71/1000 | Loss: 0.00001331
Iteration 72/1000 | Loss: 0.00001330
Iteration 73/1000 | Loss: 0.00001330
Iteration 74/1000 | Loss: 0.00001330
Iteration 75/1000 | Loss: 0.00001330
Iteration 76/1000 | Loss: 0.00001330
Iteration 77/1000 | Loss: 0.00001330
Iteration 78/1000 | Loss: 0.00001329
Iteration 79/1000 | Loss: 0.00001329
Iteration 80/1000 | Loss: 0.00001329
Iteration 81/1000 | Loss: 0.00001329
Iteration 82/1000 | Loss: 0.00001329
Iteration 83/1000 | Loss: 0.00001329
Iteration 84/1000 | Loss: 0.00001329
Iteration 85/1000 | Loss: 0.00001329
Iteration 86/1000 | Loss: 0.00001328
Iteration 87/1000 | Loss: 0.00001328
Iteration 88/1000 | Loss: 0.00001328
Iteration 89/1000 | Loss: 0.00001328
Iteration 90/1000 | Loss: 0.00001328
Iteration 91/1000 | Loss: 0.00001328
Iteration 92/1000 | Loss: 0.00001328
Iteration 93/1000 | Loss: 0.00001328
Iteration 94/1000 | Loss: 0.00001328
Iteration 95/1000 | Loss: 0.00001328
Iteration 96/1000 | Loss: 0.00001327
Iteration 97/1000 | Loss: 0.00001327
Iteration 98/1000 | Loss: 0.00001327
Iteration 99/1000 | Loss: 0.00001327
Iteration 100/1000 | Loss: 0.00001327
Iteration 101/1000 | Loss: 0.00001326
Iteration 102/1000 | Loss: 0.00001326
Iteration 103/1000 | Loss: 0.00001326
Iteration 104/1000 | Loss: 0.00001326
Iteration 105/1000 | Loss: 0.00001326
Iteration 106/1000 | Loss: 0.00001326
Iteration 107/1000 | Loss: 0.00001326
Iteration 108/1000 | Loss: 0.00001325
Iteration 109/1000 | Loss: 0.00001325
Iteration 110/1000 | Loss: 0.00001325
Iteration 111/1000 | Loss: 0.00001325
Iteration 112/1000 | Loss: 0.00001325
Iteration 113/1000 | Loss: 0.00001325
Iteration 114/1000 | Loss: 0.00001324
Iteration 115/1000 | Loss: 0.00001324
Iteration 116/1000 | Loss: 0.00001324
Iteration 117/1000 | Loss: 0.00001324
Iteration 118/1000 | Loss: 0.00001324
Iteration 119/1000 | Loss: 0.00001324
Iteration 120/1000 | Loss: 0.00001324
Iteration 121/1000 | Loss: 0.00001324
Iteration 122/1000 | Loss: 0.00001324
Iteration 123/1000 | Loss: 0.00001324
Iteration 124/1000 | Loss: 0.00001323
Iteration 125/1000 | Loss: 0.00001323
Iteration 126/1000 | Loss: 0.00001323
Iteration 127/1000 | Loss: 0.00001323
Iteration 128/1000 | Loss: 0.00001323
Iteration 129/1000 | Loss: 0.00001323
Iteration 130/1000 | Loss: 0.00001323
Iteration 131/1000 | Loss: 0.00001323
Iteration 132/1000 | Loss: 0.00001322
Iteration 133/1000 | Loss: 0.00001322
Iteration 134/1000 | Loss: 0.00001322
Iteration 135/1000 | Loss: 0.00001322
Iteration 136/1000 | Loss: 0.00001322
Iteration 137/1000 | Loss: 0.00001322
Iteration 138/1000 | Loss: 0.00001322
Iteration 139/1000 | Loss: 0.00001322
Iteration 140/1000 | Loss: 0.00001322
Iteration 141/1000 | Loss: 0.00001322
Iteration 142/1000 | Loss: 0.00001321
Iteration 143/1000 | Loss: 0.00001321
Iteration 144/1000 | Loss: 0.00001321
Iteration 145/1000 | Loss: 0.00001321
Iteration 146/1000 | Loss: 0.00001321
Iteration 147/1000 | Loss: 0.00001321
Iteration 148/1000 | Loss: 0.00001321
Iteration 149/1000 | Loss: 0.00001321
Iteration 150/1000 | Loss: 0.00001321
Iteration 151/1000 | Loss: 0.00001321
Iteration 152/1000 | Loss: 0.00001321
Iteration 153/1000 | Loss: 0.00001321
Iteration 154/1000 | Loss: 0.00001321
Iteration 155/1000 | Loss: 0.00001321
Iteration 156/1000 | Loss: 0.00001321
Iteration 157/1000 | Loss: 0.00001321
Iteration 158/1000 | Loss: 0.00001321
Iteration 159/1000 | Loss: 0.00001321
Iteration 160/1000 | Loss: 0.00001320
Iteration 161/1000 | Loss: 0.00001320
Iteration 162/1000 | Loss: 0.00001320
Iteration 163/1000 | Loss: 0.00001320
Iteration 164/1000 | Loss: 0.00001320
Iteration 165/1000 | Loss: 0.00001320
Iteration 166/1000 | Loss: 0.00001320
Iteration 167/1000 | Loss: 0.00001320
Iteration 168/1000 | Loss: 0.00001320
Iteration 169/1000 | Loss: 0.00001320
Iteration 170/1000 | Loss: 0.00001320
Iteration 171/1000 | Loss: 0.00001319
Iteration 172/1000 | Loss: 0.00001319
Iteration 173/1000 | Loss: 0.00001319
Iteration 174/1000 | Loss: 0.00001319
Iteration 175/1000 | Loss: 0.00001319
Iteration 176/1000 | Loss: 0.00001319
Iteration 177/1000 | Loss: 0.00001319
Iteration 178/1000 | Loss: 0.00001319
Iteration 179/1000 | Loss: 0.00001319
Iteration 180/1000 | Loss: 0.00001319
Iteration 181/1000 | Loss: 0.00001318
Iteration 182/1000 | Loss: 0.00001318
Iteration 183/1000 | Loss: 0.00001318
Iteration 184/1000 | Loss: 0.00001318
Iteration 185/1000 | Loss: 0.00001318
Iteration 186/1000 | Loss: 0.00001318
Iteration 187/1000 | Loss: 0.00001318
Iteration 188/1000 | Loss: 0.00001318
Iteration 189/1000 | Loss: 0.00001318
Iteration 190/1000 | Loss: 0.00001318
Iteration 191/1000 | Loss: 0.00001318
Iteration 192/1000 | Loss: 0.00001318
Iteration 193/1000 | Loss: 0.00001318
Iteration 194/1000 | Loss: 0.00001318
Iteration 195/1000 | Loss: 0.00001318
Iteration 196/1000 | Loss: 0.00001318
Iteration 197/1000 | Loss: 0.00001318
Iteration 198/1000 | Loss: 0.00001317
Iteration 199/1000 | Loss: 0.00001317
Iteration 200/1000 | Loss: 0.00001317
Iteration 201/1000 | Loss: 0.00001317
Iteration 202/1000 | Loss: 0.00001317
Iteration 203/1000 | Loss: 0.00001317
Iteration 204/1000 | Loss: 0.00001317
Iteration 205/1000 | Loss: 0.00001317
Iteration 206/1000 | Loss: 0.00001317
Iteration 207/1000 | Loss: 0.00001317
Iteration 208/1000 | Loss: 0.00001317
Iteration 209/1000 | Loss: 0.00001317
Iteration 210/1000 | Loss: 0.00001317
Iteration 211/1000 | Loss: 0.00001317
Iteration 212/1000 | Loss: 0.00001317
Iteration 213/1000 | Loss: 0.00001317
Iteration 214/1000 | Loss: 0.00001317
Iteration 215/1000 | Loss: 0.00001317
Iteration 216/1000 | Loss: 0.00001317
Iteration 217/1000 | Loss: 0.00001317
Iteration 218/1000 | Loss: 0.00001317
Iteration 219/1000 | Loss: 0.00001317
Iteration 220/1000 | Loss: 0.00001317
Iteration 221/1000 | Loss: 0.00001317
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 221. Stopping optimization.
Last 5 losses: [1.3165692507755011e-05, 1.3165692507755011e-05, 1.3165692507755011e-05, 1.3165692507755011e-05, 1.3165692507755011e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3165692507755011e-05

Optimization complete. Final v2v error: 2.9966795444488525 mm

Highest mean error: 4.4182562828063965 mm for frame 239

Lowest mean error: 2.736583948135376 mm for frame 68

Saving results

Total time: 48.77290344238281
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1039
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00494444
Iteration 2/25 | Loss: 0.00127548
Iteration 3/25 | Loss: 0.00105059
Iteration 4/25 | Loss: 0.00100255
Iteration 5/25 | Loss: 0.00098459
Iteration 6/25 | Loss: 0.00098033
Iteration 7/25 | Loss: 0.00097825
Iteration 8/25 | Loss: 0.00098179
Iteration 9/25 | Loss: 0.00098122
Iteration 10/25 | Loss: 0.00097757
Iteration 11/25 | Loss: 0.00097377
Iteration 12/25 | Loss: 0.00096976
Iteration 13/25 | Loss: 0.00096849
Iteration 14/25 | Loss: 0.00096834
Iteration 15/25 | Loss: 0.00096833
Iteration 16/25 | Loss: 0.00096832
Iteration 17/25 | Loss: 0.00096832
Iteration 18/25 | Loss: 0.00096832
Iteration 19/25 | Loss: 0.00096832
Iteration 20/25 | Loss: 0.00096832
Iteration 21/25 | Loss: 0.00096832
Iteration 22/25 | Loss: 0.00096832
Iteration 23/25 | Loss: 0.00096832
Iteration 24/25 | Loss: 0.00096832
Iteration 25/25 | Loss: 0.00096832

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56453753
Iteration 2/25 | Loss: 0.00294217
Iteration 3/25 | Loss: 0.00294217
Iteration 4/25 | Loss: 0.00294217
Iteration 5/25 | Loss: 0.00294217
Iteration 6/25 | Loss: 0.00294217
Iteration 7/25 | Loss: 0.00294217
Iteration 8/25 | Loss: 0.00294217
Iteration 9/25 | Loss: 0.00294217
Iteration 10/25 | Loss: 0.00294217
Iteration 11/25 | Loss: 0.00294217
Iteration 12/25 | Loss: 0.00294217
Iteration 13/25 | Loss: 0.00294217
Iteration 14/25 | Loss: 0.00294217
Iteration 15/25 | Loss: 0.00294217
Iteration 16/25 | Loss: 0.00294217
Iteration 17/25 | Loss: 0.00294217
Iteration 18/25 | Loss: 0.00294217
Iteration 19/25 | Loss: 0.00294217
Iteration 20/25 | Loss: 0.00294217
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.002942165592685342, 0.002942165592685342, 0.002942165592685342, 0.002942165592685342, 0.002942165592685342]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002942165592685342

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00294217
Iteration 2/1000 | Loss: 0.00028954
Iteration 3/1000 | Loss: 0.00019319
Iteration 4/1000 | Loss: 0.00016311
Iteration 5/1000 | Loss: 0.00014631
Iteration 6/1000 | Loss: 0.00013611
Iteration 7/1000 | Loss: 0.00012809
Iteration 8/1000 | Loss: 0.00012024
Iteration 9/1000 | Loss: 0.00011435
Iteration 10/1000 | Loss: 0.00011138
Iteration 11/1000 | Loss: 0.00010939
Iteration 12/1000 | Loss: 0.00010798
Iteration 13/1000 | Loss: 0.00010662
Iteration 14/1000 | Loss: 0.00010514
Iteration 15/1000 | Loss: 0.00010366
Iteration 16/1000 | Loss: 0.00010251
Iteration 17/1000 | Loss: 0.00073830
Iteration 18/1000 | Loss: 0.00370198
Iteration 19/1000 | Loss: 0.00954945
Iteration 20/1000 | Loss: 0.00601614
Iteration 21/1000 | Loss: 0.00310383
Iteration 22/1000 | Loss: 0.00351028
Iteration 23/1000 | Loss: 0.00064451
Iteration 24/1000 | Loss: 0.00051409
Iteration 25/1000 | Loss: 0.00012924
Iteration 26/1000 | Loss: 0.00074329
Iteration 27/1000 | Loss: 0.00010410
Iteration 28/1000 | Loss: 0.00328787
Iteration 29/1000 | Loss: 0.00020607
Iteration 30/1000 | Loss: 0.00013032
Iteration 31/1000 | Loss: 0.00288277
Iteration 32/1000 | Loss: 0.00111739
Iteration 33/1000 | Loss: 0.00013208
Iteration 34/1000 | Loss: 0.00009367
Iteration 35/1000 | Loss: 0.00006980
Iteration 36/1000 | Loss: 0.00006529
Iteration 37/1000 | Loss: 0.00273826
Iteration 38/1000 | Loss: 0.00008039
Iteration 39/1000 | Loss: 0.00006197
Iteration 40/1000 | Loss: 0.00092491
Iteration 41/1000 | Loss: 0.00005953
Iteration 42/1000 | Loss: 0.00005363
Iteration 43/1000 | Loss: 0.00004889
Iteration 44/1000 | Loss: 0.00004647
Iteration 45/1000 | Loss: 0.00004492
Iteration 46/1000 | Loss: 0.00004332
Iteration 47/1000 | Loss: 0.00092879
Iteration 48/1000 | Loss: 0.00258438
Iteration 49/1000 | Loss: 0.00061272
Iteration 50/1000 | Loss: 0.00004888
Iteration 51/1000 | Loss: 0.00004084
Iteration 52/1000 | Loss: 0.00049181
Iteration 53/1000 | Loss: 0.00004572
Iteration 54/1000 | Loss: 0.00004042
Iteration 55/1000 | Loss: 0.00068401
Iteration 56/1000 | Loss: 0.00006156
Iteration 57/1000 | Loss: 0.00070334
Iteration 58/1000 | Loss: 0.00005209
Iteration 59/1000 | Loss: 0.00003968
Iteration 60/1000 | Loss: 0.00003568
Iteration 61/1000 | Loss: 0.00003392
Iteration 62/1000 | Loss: 0.00003240
Iteration 63/1000 | Loss: 0.00003159
Iteration 64/1000 | Loss: 0.00003093
Iteration 65/1000 | Loss: 0.00003034
Iteration 66/1000 | Loss: 0.00002984
Iteration 67/1000 | Loss: 0.00002935
Iteration 68/1000 | Loss: 0.00002897
Iteration 69/1000 | Loss: 0.00002871
Iteration 70/1000 | Loss: 0.00002847
Iteration 71/1000 | Loss: 0.00002826
Iteration 72/1000 | Loss: 0.00002808
Iteration 73/1000 | Loss: 0.00002797
Iteration 74/1000 | Loss: 0.00002794
Iteration 75/1000 | Loss: 0.00002791
Iteration 76/1000 | Loss: 0.00002791
Iteration 77/1000 | Loss: 0.00002790
Iteration 78/1000 | Loss: 0.00002790
Iteration 79/1000 | Loss: 0.00002790
Iteration 80/1000 | Loss: 0.00002789
Iteration 81/1000 | Loss: 0.00002788
Iteration 82/1000 | Loss: 0.00002787
Iteration 83/1000 | Loss: 0.00002786
Iteration 84/1000 | Loss: 0.00002785
Iteration 85/1000 | Loss: 0.00002784
Iteration 86/1000 | Loss: 0.00002784
Iteration 87/1000 | Loss: 0.00002783
Iteration 88/1000 | Loss: 0.00002783
Iteration 89/1000 | Loss: 0.00002779
Iteration 90/1000 | Loss: 0.00002779
Iteration 91/1000 | Loss: 0.00002776
Iteration 92/1000 | Loss: 0.00002776
Iteration 93/1000 | Loss: 0.00002776
Iteration 94/1000 | Loss: 0.00002776
Iteration 95/1000 | Loss: 0.00002775
Iteration 96/1000 | Loss: 0.00002774
Iteration 97/1000 | Loss: 0.00002774
Iteration 98/1000 | Loss: 0.00002774
Iteration 99/1000 | Loss: 0.00002774
Iteration 100/1000 | Loss: 0.00002774
Iteration 101/1000 | Loss: 0.00002771
Iteration 102/1000 | Loss: 0.00002767
Iteration 103/1000 | Loss: 0.00002765
Iteration 104/1000 | Loss: 0.00002764
Iteration 105/1000 | Loss: 0.00002764
Iteration 106/1000 | Loss: 0.00002764
Iteration 107/1000 | Loss: 0.00002763
Iteration 108/1000 | Loss: 0.00002763
Iteration 109/1000 | Loss: 0.00002763
Iteration 110/1000 | Loss: 0.00002763
Iteration 111/1000 | Loss: 0.00002763
Iteration 112/1000 | Loss: 0.00002763
Iteration 113/1000 | Loss: 0.00002763
Iteration 114/1000 | Loss: 0.00002762
Iteration 115/1000 | Loss: 0.00002762
Iteration 116/1000 | Loss: 0.00002762
Iteration 117/1000 | Loss: 0.00002762
Iteration 118/1000 | Loss: 0.00002762
Iteration 119/1000 | Loss: 0.00002761
Iteration 120/1000 | Loss: 0.00002761
Iteration 121/1000 | Loss: 0.00002761
Iteration 122/1000 | Loss: 0.00002761
Iteration 123/1000 | Loss: 0.00002760
Iteration 124/1000 | Loss: 0.00002760
Iteration 125/1000 | Loss: 0.00002760
Iteration 126/1000 | Loss: 0.00002759
Iteration 127/1000 | Loss: 0.00002759
Iteration 128/1000 | Loss: 0.00002759
Iteration 129/1000 | Loss: 0.00002758
Iteration 130/1000 | Loss: 0.00002758
Iteration 131/1000 | Loss: 0.00002758
Iteration 132/1000 | Loss: 0.00002757
Iteration 133/1000 | Loss: 0.00002757
Iteration 134/1000 | Loss: 0.00002757
Iteration 135/1000 | Loss: 0.00002756
Iteration 136/1000 | Loss: 0.00002756
Iteration 137/1000 | Loss: 0.00002756
Iteration 138/1000 | Loss: 0.00002755
Iteration 139/1000 | Loss: 0.00002755
Iteration 140/1000 | Loss: 0.00077240
Iteration 141/1000 | Loss: 0.00077240
Iteration 142/1000 | Loss: 0.00004379
Iteration 143/1000 | Loss: 0.00002812
Iteration 144/1000 | Loss: 0.00002658
Iteration 145/1000 | Loss: 0.00002604
Iteration 146/1000 | Loss: 0.00002572
Iteration 147/1000 | Loss: 0.00002553
Iteration 148/1000 | Loss: 0.00002542
Iteration 149/1000 | Loss: 0.00002539
Iteration 150/1000 | Loss: 0.00002538
Iteration 151/1000 | Loss: 0.00002524
Iteration 152/1000 | Loss: 0.00002521
Iteration 153/1000 | Loss: 0.00002516
Iteration 154/1000 | Loss: 0.00002516
Iteration 155/1000 | Loss: 0.00002515
Iteration 156/1000 | Loss: 0.00002515
Iteration 157/1000 | Loss: 0.00002514
Iteration 158/1000 | Loss: 0.00002514
Iteration 159/1000 | Loss: 0.00002514
Iteration 160/1000 | Loss: 0.00002513
Iteration 161/1000 | Loss: 0.00002513
Iteration 162/1000 | Loss: 0.00002513
Iteration 163/1000 | Loss: 0.00002513
Iteration 164/1000 | Loss: 0.00002512
Iteration 165/1000 | Loss: 0.00002512
Iteration 166/1000 | Loss: 0.00002512
Iteration 167/1000 | Loss: 0.00002512
Iteration 168/1000 | Loss: 0.00002512
Iteration 169/1000 | Loss: 0.00002512
Iteration 170/1000 | Loss: 0.00002512
Iteration 171/1000 | Loss: 0.00002512
Iteration 172/1000 | Loss: 0.00002512
Iteration 173/1000 | Loss: 0.00002511
Iteration 174/1000 | Loss: 0.00002511
Iteration 175/1000 | Loss: 0.00002511
Iteration 176/1000 | Loss: 0.00002511
Iteration 177/1000 | Loss: 0.00002511
Iteration 178/1000 | Loss: 0.00002511
Iteration 179/1000 | Loss: 0.00002511
Iteration 180/1000 | Loss: 0.00002511
Iteration 181/1000 | Loss: 0.00002511
Iteration 182/1000 | Loss: 0.00002511
Iteration 183/1000 | Loss: 0.00002510
Iteration 184/1000 | Loss: 0.00002510
Iteration 185/1000 | Loss: 0.00002510
Iteration 186/1000 | Loss: 0.00002510
Iteration 187/1000 | Loss: 0.00002510
Iteration 188/1000 | Loss: 0.00002510
Iteration 189/1000 | Loss: 0.00002510
Iteration 190/1000 | Loss: 0.00002510
Iteration 191/1000 | Loss: 0.00002510
Iteration 192/1000 | Loss: 0.00002509
Iteration 193/1000 | Loss: 0.00002509
Iteration 194/1000 | Loss: 0.00002509
Iteration 195/1000 | Loss: 0.00002509
Iteration 196/1000 | Loss: 0.00002509
Iteration 197/1000 | Loss: 0.00002509
Iteration 198/1000 | Loss: 0.00002509
Iteration 199/1000 | Loss: 0.00002509
Iteration 200/1000 | Loss: 0.00002508
Iteration 201/1000 | Loss: 0.00002508
Iteration 202/1000 | Loss: 0.00002508
Iteration 203/1000 | Loss: 0.00002508
Iteration 204/1000 | Loss: 0.00002508
Iteration 205/1000 | Loss: 0.00002508
Iteration 206/1000 | Loss: 0.00002507
Iteration 207/1000 | Loss: 0.00002507
Iteration 208/1000 | Loss: 0.00002507
Iteration 209/1000 | Loss: 0.00002507
Iteration 210/1000 | Loss: 0.00002506
Iteration 211/1000 | Loss: 0.00002506
Iteration 212/1000 | Loss: 0.00002506
Iteration 213/1000 | Loss: 0.00002506
Iteration 214/1000 | Loss: 0.00002506
Iteration 215/1000 | Loss: 0.00002506
Iteration 216/1000 | Loss: 0.00002505
Iteration 217/1000 | Loss: 0.00002505
Iteration 218/1000 | Loss: 0.00002505
Iteration 219/1000 | Loss: 0.00002505
Iteration 220/1000 | Loss: 0.00002505
Iteration 221/1000 | Loss: 0.00002505
Iteration 222/1000 | Loss: 0.00002505
Iteration 223/1000 | Loss: 0.00002505
Iteration 224/1000 | Loss: 0.00002504
Iteration 225/1000 | Loss: 0.00002504
Iteration 226/1000 | Loss: 0.00002504
Iteration 227/1000 | Loss: 0.00002504
Iteration 228/1000 | Loss: 0.00002504
Iteration 229/1000 | Loss: 0.00002504
Iteration 230/1000 | Loss: 0.00002504
Iteration 231/1000 | Loss: 0.00002504
Iteration 232/1000 | Loss: 0.00002504
Iteration 233/1000 | Loss: 0.00002503
Iteration 234/1000 | Loss: 0.00002503
Iteration 235/1000 | Loss: 0.00002503
Iteration 236/1000 | Loss: 0.00002503
Iteration 237/1000 | Loss: 0.00002503
Iteration 238/1000 | Loss: 0.00002503
Iteration 239/1000 | Loss: 0.00002503
Iteration 240/1000 | Loss: 0.00002503
Iteration 241/1000 | Loss: 0.00002503
Iteration 242/1000 | Loss: 0.00002503
Iteration 243/1000 | Loss: 0.00002503
Iteration 244/1000 | Loss: 0.00002503
Iteration 245/1000 | Loss: 0.00002502
Iteration 246/1000 | Loss: 0.00002502
Iteration 247/1000 | Loss: 0.00002502
Iteration 248/1000 | Loss: 0.00002502
Iteration 249/1000 | Loss: 0.00002502
Iteration 250/1000 | Loss: 0.00002501
Iteration 251/1000 | Loss: 0.00002501
Iteration 252/1000 | Loss: 0.00002501
Iteration 253/1000 | Loss: 0.00002501
Iteration 254/1000 | Loss: 0.00002501
Iteration 255/1000 | Loss: 0.00002501
Iteration 256/1000 | Loss: 0.00002501
Iteration 257/1000 | Loss: 0.00002501
Iteration 258/1000 | Loss: 0.00002501
Iteration 259/1000 | Loss: 0.00002501
Iteration 260/1000 | Loss: 0.00002501
Iteration 261/1000 | Loss: 0.00002501
Iteration 262/1000 | Loss: 0.00002501
Iteration 263/1000 | Loss: 0.00002501
Iteration 264/1000 | Loss: 0.00002501
Iteration 265/1000 | Loss: 0.00002501
Iteration 266/1000 | Loss: 0.00002501
Iteration 267/1000 | Loss: 0.00002501
Iteration 268/1000 | Loss: 0.00002501
Iteration 269/1000 | Loss: 0.00002501
Iteration 270/1000 | Loss: 0.00002501
Iteration 271/1000 | Loss: 0.00002501
Iteration 272/1000 | Loss: 0.00002501
Iteration 273/1000 | Loss: 0.00002501
Iteration 274/1000 | Loss: 0.00002501
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 274. Stopping optimization.
Last 5 losses: [2.5012212063302286e-05, 2.5012212063302286e-05, 2.5012212063302286e-05, 2.5012212063302286e-05, 2.5012212063302286e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5012212063302286e-05

Optimization complete. Final v2v error: 4.080161094665527 mm

Highest mean error: 6.093662738800049 mm for frame 56

Lowest mean error: 3.3730876445770264 mm for frame 26

Saving results

Total time: 161.4556987285614
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1092/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1092.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1092
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00849776
Iteration 2/25 | Loss: 0.00132116
Iteration 3/25 | Loss: 0.00089978
Iteration 4/25 | Loss: 0.00084830
Iteration 5/25 | Loss: 0.00083208
Iteration 6/25 | Loss: 0.00083605
Iteration 7/25 | Loss: 0.00083941
Iteration 8/25 | Loss: 0.00083108
Iteration 9/25 | Loss: 0.00082505
Iteration 10/25 | Loss: 0.00081990
Iteration 11/25 | Loss: 0.00081727
Iteration 12/25 | Loss: 0.00081694
Iteration 13/25 | Loss: 0.00081424
Iteration 14/25 | Loss: 0.00081262
Iteration 15/25 | Loss: 0.00081189
Iteration 16/25 | Loss: 0.00081170
Iteration 17/25 | Loss: 0.00081164
Iteration 18/25 | Loss: 0.00081164
Iteration 19/25 | Loss: 0.00081164
Iteration 20/25 | Loss: 0.00081164
Iteration 21/25 | Loss: 0.00081164
Iteration 22/25 | Loss: 0.00081164
Iteration 23/25 | Loss: 0.00081163
Iteration 24/25 | Loss: 0.00081163
Iteration 25/25 | Loss: 0.00081163

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.74271154
Iteration 2/25 | Loss: 0.00129362
Iteration 3/25 | Loss: 0.00129361
Iteration 4/25 | Loss: 0.00129361
Iteration 5/25 | Loss: 0.00129361
Iteration 6/25 | Loss: 0.00129361
Iteration 7/25 | Loss: 0.00129361
Iteration 8/25 | Loss: 0.00129361
Iteration 9/25 | Loss: 0.00129361
Iteration 10/25 | Loss: 0.00129361
Iteration 11/25 | Loss: 0.00129360
Iteration 12/25 | Loss: 0.00129360
Iteration 13/25 | Loss: 0.00129360
Iteration 14/25 | Loss: 0.00129360
Iteration 15/25 | Loss: 0.00129360
Iteration 16/25 | Loss: 0.00129360
Iteration 17/25 | Loss: 0.00129360
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001293604844249785, 0.001293604844249785, 0.001293604844249785, 0.001293604844249785, 0.001293604844249785]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001293604844249785

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00129360
Iteration 2/1000 | Loss: 0.00003876
Iteration 3/1000 | Loss: 0.00003103
Iteration 4/1000 | Loss: 0.00002803
Iteration 5/1000 | Loss: 0.00023535
Iteration 6/1000 | Loss: 0.00002912
Iteration 7/1000 | Loss: 0.00002544
Iteration 8/1000 | Loss: 0.00002375
Iteration 9/1000 | Loss: 0.00002283
Iteration 10/1000 | Loss: 0.00002219
Iteration 11/1000 | Loss: 0.00002192
Iteration 12/1000 | Loss: 0.00002169
Iteration 13/1000 | Loss: 0.00002152
Iteration 14/1000 | Loss: 0.00002149
Iteration 15/1000 | Loss: 0.00002130
Iteration 16/1000 | Loss: 0.00002130
Iteration 17/1000 | Loss: 0.00002129
Iteration 18/1000 | Loss: 0.00002127
Iteration 19/1000 | Loss: 0.00002127
Iteration 20/1000 | Loss: 0.00002123
Iteration 21/1000 | Loss: 0.00002119
Iteration 22/1000 | Loss: 0.00002119
Iteration 23/1000 | Loss: 0.00002118
Iteration 24/1000 | Loss: 0.00002118
Iteration 25/1000 | Loss: 0.00002118
Iteration 26/1000 | Loss: 0.00002118
Iteration 27/1000 | Loss: 0.00002118
Iteration 28/1000 | Loss: 0.00002118
Iteration 29/1000 | Loss: 0.00002118
Iteration 30/1000 | Loss: 0.00002118
Iteration 31/1000 | Loss: 0.00002118
Iteration 32/1000 | Loss: 0.00002118
Iteration 33/1000 | Loss: 0.00002118
Iteration 34/1000 | Loss: 0.00002118
Iteration 35/1000 | Loss: 0.00002117
Iteration 36/1000 | Loss: 0.00002117
Iteration 37/1000 | Loss: 0.00002117
Iteration 38/1000 | Loss: 0.00002117
Iteration 39/1000 | Loss: 0.00002117
Iteration 40/1000 | Loss: 0.00002115
Iteration 41/1000 | Loss: 0.00002115
Iteration 42/1000 | Loss: 0.00002114
Iteration 43/1000 | Loss: 0.00002114
Iteration 44/1000 | Loss: 0.00002114
Iteration 45/1000 | Loss: 0.00002114
Iteration 46/1000 | Loss: 0.00002114
Iteration 47/1000 | Loss: 0.00002114
Iteration 48/1000 | Loss: 0.00002113
Iteration 49/1000 | Loss: 0.00002113
Iteration 50/1000 | Loss: 0.00002112
Iteration 51/1000 | Loss: 0.00002112
Iteration 52/1000 | Loss: 0.00002112
Iteration 53/1000 | Loss: 0.00002112
Iteration 54/1000 | Loss: 0.00002112
Iteration 55/1000 | Loss: 0.00002111
Iteration 56/1000 | Loss: 0.00002111
Iteration 57/1000 | Loss: 0.00002111
Iteration 58/1000 | Loss: 0.00002111
Iteration 59/1000 | Loss: 0.00002111
Iteration 60/1000 | Loss: 0.00002111
Iteration 61/1000 | Loss: 0.00002111
Iteration 62/1000 | Loss: 0.00002111
Iteration 63/1000 | Loss: 0.00002110
Iteration 64/1000 | Loss: 0.00002110
Iteration 65/1000 | Loss: 0.00002110
Iteration 66/1000 | Loss: 0.00002109
Iteration 67/1000 | Loss: 0.00002109
Iteration 68/1000 | Loss: 0.00002109
Iteration 69/1000 | Loss: 0.00002109
Iteration 70/1000 | Loss: 0.00002109
Iteration 71/1000 | Loss: 0.00002109
Iteration 72/1000 | Loss: 0.00002109
Iteration 73/1000 | Loss: 0.00002109
Iteration 74/1000 | Loss: 0.00002109
Iteration 75/1000 | Loss: 0.00002109
Iteration 76/1000 | Loss: 0.00002109
Iteration 77/1000 | Loss: 0.00002108
Iteration 78/1000 | Loss: 0.00002108
Iteration 79/1000 | Loss: 0.00002108
Iteration 80/1000 | Loss: 0.00002108
Iteration 81/1000 | Loss: 0.00002107
Iteration 82/1000 | Loss: 0.00002107
Iteration 83/1000 | Loss: 0.00002107
Iteration 84/1000 | Loss: 0.00002107
Iteration 85/1000 | Loss: 0.00002107
Iteration 86/1000 | Loss: 0.00002107
Iteration 87/1000 | Loss: 0.00002107
Iteration 88/1000 | Loss: 0.00002107
Iteration 89/1000 | Loss: 0.00002106
Iteration 90/1000 | Loss: 0.00002106
Iteration 91/1000 | Loss: 0.00002106
Iteration 92/1000 | Loss: 0.00002106
Iteration 93/1000 | Loss: 0.00002106
Iteration 94/1000 | Loss: 0.00002106
Iteration 95/1000 | Loss: 0.00002106
Iteration 96/1000 | Loss: 0.00002106
Iteration 97/1000 | Loss: 0.00002106
Iteration 98/1000 | Loss: 0.00002106
Iteration 99/1000 | Loss: 0.00002106
Iteration 100/1000 | Loss: 0.00002106
Iteration 101/1000 | Loss: 0.00002106
Iteration 102/1000 | Loss: 0.00002106
Iteration 103/1000 | Loss: 0.00002106
Iteration 104/1000 | Loss: 0.00002106
Iteration 105/1000 | Loss: 0.00002106
Iteration 106/1000 | Loss: 0.00002106
Iteration 107/1000 | Loss: 0.00002106
Iteration 108/1000 | Loss: 0.00002106
Iteration 109/1000 | Loss: 0.00002106
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [2.1063187887193635e-05, 2.1063187887193635e-05, 2.1063187887193635e-05, 2.1063187887193635e-05, 2.1063187887193635e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1063187887193635e-05

Optimization complete. Final v2v error: 3.8391244411468506 mm

Highest mean error: 4.5131025314331055 mm for frame 108

Lowest mean error: 3.117324113845825 mm for frame 70

Saving results

Total time: 60.949711561203
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1091/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1091.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1091
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00970026
Iteration 2/25 | Loss: 0.00208575
Iteration 3/25 | Loss: 0.00115765
Iteration 4/25 | Loss: 0.00094420
Iteration 5/25 | Loss: 0.00090090
Iteration 6/25 | Loss: 0.00089091
Iteration 7/25 | Loss: 0.00088420
Iteration 8/25 | Loss: 0.00087477
Iteration 9/25 | Loss: 0.00087304
Iteration 10/25 | Loss: 0.00086794
Iteration 11/25 | Loss: 0.00086962
Iteration 12/25 | Loss: 0.00086798
Iteration 13/25 | Loss: 0.00085984
Iteration 14/25 | Loss: 0.00085892
Iteration 15/25 | Loss: 0.00085346
Iteration 16/25 | Loss: 0.00085781
Iteration 17/25 | Loss: 0.00085546
Iteration 18/25 | Loss: 0.00086020
Iteration 19/25 | Loss: 0.00086471
Iteration 20/25 | Loss: 0.00086792
Iteration 21/25 | Loss: 0.00086597
Iteration 22/25 | Loss: 0.00086409
Iteration 23/25 | Loss: 0.00086430
Iteration 24/25 | Loss: 0.00086194
Iteration 25/25 | Loss: 0.00086813

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52275813
Iteration 2/25 | Loss: 0.00213269
Iteration 3/25 | Loss: 0.00198162
Iteration 4/25 | Loss: 0.00198162
Iteration 5/25 | Loss: 0.00198162
Iteration 6/25 | Loss: 0.00198162
Iteration 7/25 | Loss: 0.00198162
Iteration 8/25 | Loss: 0.00198162
Iteration 9/25 | Loss: 0.00198162
Iteration 10/25 | Loss: 0.00198162
Iteration 11/25 | Loss: 0.00198162
Iteration 12/25 | Loss: 0.00198162
Iteration 13/25 | Loss: 0.00198162
Iteration 14/25 | Loss: 0.00198162
Iteration 15/25 | Loss: 0.00198162
Iteration 16/25 | Loss: 0.00198162
Iteration 17/25 | Loss: 0.00198162
Iteration 18/25 | Loss: 0.00198162
Iteration 19/25 | Loss: 0.00198162
Iteration 20/25 | Loss: 0.00198162
Iteration 21/25 | Loss: 0.00198162
Iteration 22/25 | Loss: 0.00198162
Iteration 23/25 | Loss: 0.00198162
Iteration 24/25 | Loss: 0.00198162
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0019816160202026367, 0.0019816160202026367, 0.0019816160202026367, 0.0019816160202026367, 0.0019816160202026367]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019816160202026367

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00198162
Iteration 2/1000 | Loss: 0.00129289
Iteration 3/1000 | Loss: 0.00044778
Iteration 4/1000 | Loss: 0.00045960
Iteration 5/1000 | Loss: 0.00049978
Iteration 6/1000 | Loss: 0.00047571
Iteration 7/1000 | Loss: 0.00030849
Iteration 8/1000 | Loss: 0.00019763
Iteration 9/1000 | Loss: 0.00027683
Iteration 10/1000 | Loss: 0.00054640
Iteration 11/1000 | Loss: 0.00021400
Iteration 12/1000 | Loss: 0.00005387
Iteration 13/1000 | Loss: 0.00025098
Iteration 14/1000 | Loss: 0.00029094
Iteration 15/1000 | Loss: 0.00024453
Iteration 16/1000 | Loss: 0.00006069
Iteration 17/1000 | Loss: 0.00004621
Iteration 18/1000 | Loss: 0.00014444
Iteration 19/1000 | Loss: 0.00026725
Iteration 20/1000 | Loss: 0.00015367
Iteration 21/1000 | Loss: 0.00009596
Iteration 22/1000 | Loss: 0.00020485
Iteration 23/1000 | Loss: 0.00016024
Iteration 24/1000 | Loss: 0.00019539
Iteration 25/1000 | Loss: 0.00016189
Iteration 26/1000 | Loss: 0.00016562
Iteration 27/1000 | Loss: 0.00022425
Iteration 28/1000 | Loss: 0.00024455
Iteration 29/1000 | Loss: 0.00026690
Iteration 30/1000 | Loss: 0.00019467
Iteration 31/1000 | Loss: 0.00017569
Iteration 32/1000 | Loss: 0.00021536
Iteration 33/1000 | Loss: 0.00011424
Iteration 34/1000 | Loss: 0.00002714
Iteration 35/1000 | Loss: 0.00010598
Iteration 36/1000 | Loss: 0.00002569
Iteration 37/1000 | Loss: 0.00002348
Iteration 38/1000 | Loss: 0.00002205
Iteration 39/1000 | Loss: 0.00002138
Iteration 40/1000 | Loss: 0.00002084
Iteration 41/1000 | Loss: 0.00011702
Iteration 42/1000 | Loss: 0.00001972
Iteration 43/1000 | Loss: 0.00001893
Iteration 44/1000 | Loss: 0.00001844
Iteration 45/1000 | Loss: 0.00001801
Iteration 46/1000 | Loss: 0.00001766
Iteration 47/1000 | Loss: 0.00001749
Iteration 48/1000 | Loss: 0.00001731
Iteration 49/1000 | Loss: 0.00001726
Iteration 50/1000 | Loss: 0.00001721
Iteration 51/1000 | Loss: 0.00001721
Iteration 52/1000 | Loss: 0.00001720
Iteration 53/1000 | Loss: 0.00001717
Iteration 54/1000 | Loss: 0.00001716
Iteration 55/1000 | Loss: 0.00001715
Iteration 56/1000 | Loss: 0.00001714
Iteration 57/1000 | Loss: 0.00001713
Iteration 58/1000 | Loss: 0.00001712
Iteration 59/1000 | Loss: 0.00001712
Iteration 60/1000 | Loss: 0.00001711
Iteration 61/1000 | Loss: 0.00001711
Iteration 62/1000 | Loss: 0.00001710
Iteration 63/1000 | Loss: 0.00001709
Iteration 64/1000 | Loss: 0.00001708
Iteration 65/1000 | Loss: 0.00001708
Iteration 66/1000 | Loss: 0.00001708
Iteration 67/1000 | Loss: 0.00001708
Iteration 68/1000 | Loss: 0.00001708
Iteration 69/1000 | Loss: 0.00001708
Iteration 70/1000 | Loss: 0.00001708
Iteration 71/1000 | Loss: 0.00001708
Iteration 72/1000 | Loss: 0.00001708
Iteration 73/1000 | Loss: 0.00001707
Iteration 74/1000 | Loss: 0.00001706
Iteration 75/1000 | Loss: 0.00001706
Iteration 76/1000 | Loss: 0.00001706
Iteration 77/1000 | Loss: 0.00001706
Iteration 78/1000 | Loss: 0.00001705
Iteration 79/1000 | Loss: 0.00001705
Iteration 80/1000 | Loss: 0.00001705
Iteration 81/1000 | Loss: 0.00001705
Iteration 82/1000 | Loss: 0.00001705
Iteration 83/1000 | Loss: 0.00001705
Iteration 84/1000 | Loss: 0.00001705
Iteration 85/1000 | Loss: 0.00001705
Iteration 86/1000 | Loss: 0.00001704
Iteration 87/1000 | Loss: 0.00001704
Iteration 88/1000 | Loss: 0.00001703
Iteration 89/1000 | Loss: 0.00001703
Iteration 90/1000 | Loss: 0.00001703
Iteration 91/1000 | Loss: 0.00001702
Iteration 92/1000 | Loss: 0.00001702
Iteration 93/1000 | Loss: 0.00001702
Iteration 94/1000 | Loss: 0.00001701
Iteration 95/1000 | Loss: 0.00001701
Iteration 96/1000 | Loss: 0.00001701
Iteration 97/1000 | Loss: 0.00001701
Iteration 98/1000 | Loss: 0.00001700
Iteration 99/1000 | Loss: 0.00001700
Iteration 100/1000 | Loss: 0.00001700
Iteration 101/1000 | Loss: 0.00001700
Iteration 102/1000 | Loss: 0.00001700
Iteration 103/1000 | Loss: 0.00001700
Iteration 104/1000 | Loss: 0.00001700
Iteration 105/1000 | Loss: 0.00001700
Iteration 106/1000 | Loss: 0.00001700
Iteration 107/1000 | Loss: 0.00001700
Iteration 108/1000 | Loss: 0.00001700
Iteration 109/1000 | Loss: 0.00001700
Iteration 110/1000 | Loss: 0.00001700
Iteration 111/1000 | Loss: 0.00001700
Iteration 112/1000 | Loss: 0.00001700
Iteration 113/1000 | Loss: 0.00001700
Iteration 114/1000 | Loss: 0.00001700
Iteration 115/1000 | Loss: 0.00001700
Iteration 116/1000 | Loss: 0.00001700
Iteration 117/1000 | Loss: 0.00001700
Iteration 118/1000 | Loss: 0.00001699
Iteration 119/1000 | Loss: 0.00001699
Iteration 120/1000 | Loss: 0.00001699
Iteration 121/1000 | Loss: 0.00001699
Iteration 122/1000 | Loss: 0.00001699
Iteration 123/1000 | Loss: 0.00001699
Iteration 124/1000 | Loss: 0.00001699
Iteration 125/1000 | Loss: 0.00001699
Iteration 126/1000 | Loss: 0.00001699
Iteration 127/1000 | Loss: 0.00001699
Iteration 128/1000 | Loss: 0.00001699
Iteration 129/1000 | Loss: 0.00001699
Iteration 130/1000 | Loss: 0.00001698
Iteration 131/1000 | Loss: 0.00001698
Iteration 132/1000 | Loss: 0.00001698
Iteration 133/1000 | Loss: 0.00001698
Iteration 134/1000 | Loss: 0.00001698
Iteration 135/1000 | Loss: 0.00001698
Iteration 136/1000 | Loss: 0.00001698
Iteration 137/1000 | Loss: 0.00001697
Iteration 138/1000 | Loss: 0.00001697
Iteration 139/1000 | Loss: 0.00001697
Iteration 140/1000 | Loss: 0.00001697
Iteration 141/1000 | Loss: 0.00001697
Iteration 142/1000 | Loss: 0.00001696
Iteration 143/1000 | Loss: 0.00001696
Iteration 144/1000 | Loss: 0.00001696
Iteration 145/1000 | Loss: 0.00001696
Iteration 146/1000 | Loss: 0.00001696
Iteration 147/1000 | Loss: 0.00001696
Iteration 148/1000 | Loss: 0.00001696
Iteration 149/1000 | Loss: 0.00001696
Iteration 150/1000 | Loss: 0.00001696
Iteration 151/1000 | Loss: 0.00001695
Iteration 152/1000 | Loss: 0.00001695
Iteration 153/1000 | Loss: 0.00001695
Iteration 154/1000 | Loss: 0.00001694
Iteration 155/1000 | Loss: 0.00001694
Iteration 156/1000 | Loss: 0.00001694
Iteration 157/1000 | Loss: 0.00001694
Iteration 158/1000 | Loss: 0.00001694
Iteration 159/1000 | Loss: 0.00001694
Iteration 160/1000 | Loss: 0.00001694
Iteration 161/1000 | Loss: 0.00001694
Iteration 162/1000 | Loss: 0.00001694
Iteration 163/1000 | Loss: 0.00001694
Iteration 164/1000 | Loss: 0.00001694
Iteration 165/1000 | Loss: 0.00001693
Iteration 166/1000 | Loss: 0.00001693
Iteration 167/1000 | Loss: 0.00001693
Iteration 168/1000 | Loss: 0.00001693
Iteration 169/1000 | Loss: 0.00001693
Iteration 170/1000 | Loss: 0.00001693
Iteration 171/1000 | Loss: 0.00001693
Iteration 172/1000 | Loss: 0.00001693
Iteration 173/1000 | Loss: 0.00001693
Iteration 174/1000 | Loss: 0.00001693
Iteration 175/1000 | Loss: 0.00001693
Iteration 176/1000 | Loss: 0.00001693
Iteration 177/1000 | Loss: 0.00001693
Iteration 178/1000 | Loss: 0.00001693
Iteration 179/1000 | Loss: 0.00001693
Iteration 180/1000 | Loss: 0.00001693
Iteration 181/1000 | Loss: 0.00001693
Iteration 182/1000 | Loss: 0.00001693
Iteration 183/1000 | Loss: 0.00001693
Iteration 184/1000 | Loss: 0.00001693
Iteration 185/1000 | Loss: 0.00001693
Iteration 186/1000 | Loss: 0.00001693
Iteration 187/1000 | Loss: 0.00001693
Iteration 188/1000 | Loss: 0.00001693
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 188. Stopping optimization.
Last 5 losses: [1.693063495622482e-05, 1.693063495622482e-05, 1.693063495622482e-05, 1.693063495622482e-05, 1.693063495622482e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.693063495622482e-05

Optimization complete. Final v2v error: 3.465376853942871 mm

Highest mean error: 4.349612236022949 mm for frame 97

Lowest mean error: 2.973902463912964 mm for frame 44

Saving results

Total time: 133.32133316993713
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1040/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1040.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1040
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00880921
Iteration 2/25 | Loss: 0.00121284
Iteration 3/25 | Loss: 0.00104252
Iteration 4/25 | Loss: 0.00099622
Iteration 5/25 | Loss: 0.00098315
Iteration 6/25 | Loss: 0.00098003
Iteration 7/25 | Loss: 0.00097841
Iteration 8/25 | Loss: 0.00097839
Iteration 9/25 | Loss: 0.00097839
Iteration 10/25 | Loss: 0.00097839
Iteration 11/25 | Loss: 0.00097839
Iteration 12/25 | Loss: 0.00097839
Iteration 13/25 | Loss: 0.00097839
Iteration 14/25 | Loss: 0.00097839
Iteration 15/25 | Loss: 0.00097839
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0009783949935808778, 0.0009783949935808778, 0.0009783949935808778, 0.0009783949935808778, 0.0009783949935808778]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009783949935808778

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54310179
Iteration 2/25 | Loss: 0.00134601
Iteration 3/25 | Loss: 0.00134590
Iteration 4/25 | Loss: 0.00134590
Iteration 5/25 | Loss: 0.00134590
Iteration 6/25 | Loss: 0.00134590
Iteration 7/25 | Loss: 0.00134590
Iteration 8/25 | Loss: 0.00134590
Iteration 9/25 | Loss: 0.00134590
Iteration 10/25 | Loss: 0.00134590
Iteration 11/25 | Loss: 0.00134590
Iteration 12/25 | Loss: 0.00134590
Iteration 13/25 | Loss: 0.00134590
Iteration 14/25 | Loss: 0.00134590
Iteration 15/25 | Loss: 0.00134590
Iteration 16/25 | Loss: 0.00134590
Iteration 17/25 | Loss: 0.00134590
Iteration 18/25 | Loss: 0.00134590
Iteration 19/25 | Loss: 0.00134590
Iteration 20/25 | Loss: 0.00134590
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.001345897908322513, 0.001345897908322513, 0.001345897908322513, 0.001345897908322513, 0.001345897908322513]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001345897908322513

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00134590
Iteration 2/1000 | Loss: 0.00006758
Iteration 3/1000 | Loss: 0.00005381
Iteration 4/1000 | Loss: 0.00004966
Iteration 5/1000 | Loss: 0.00004719
Iteration 6/1000 | Loss: 0.00004598
Iteration 7/1000 | Loss: 0.00004483
Iteration 8/1000 | Loss: 0.00004417
Iteration 9/1000 | Loss: 0.00004380
Iteration 10/1000 | Loss: 0.00004350
Iteration 11/1000 | Loss: 0.00004309
Iteration 12/1000 | Loss: 0.00004273
Iteration 13/1000 | Loss: 0.00004254
Iteration 14/1000 | Loss: 0.00004249
Iteration 15/1000 | Loss: 0.00004247
Iteration 16/1000 | Loss: 0.00004243
Iteration 17/1000 | Loss: 0.00004237
Iteration 18/1000 | Loss: 0.00004237
Iteration 19/1000 | Loss: 0.00004237
Iteration 20/1000 | Loss: 0.00004237
Iteration 21/1000 | Loss: 0.00004237
Iteration 22/1000 | Loss: 0.00004237
Iteration 23/1000 | Loss: 0.00004237
Iteration 24/1000 | Loss: 0.00004237
Iteration 25/1000 | Loss: 0.00004236
Iteration 26/1000 | Loss: 0.00004236
Iteration 27/1000 | Loss: 0.00004236
Iteration 28/1000 | Loss: 0.00004236
Iteration 29/1000 | Loss: 0.00004236
Iteration 30/1000 | Loss: 0.00004235
Iteration 31/1000 | Loss: 0.00004233
Iteration 32/1000 | Loss: 0.00004232
Iteration 33/1000 | Loss: 0.00004231
Iteration 34/1000 | Loss: 0.00004230
Iteration 35/1000 | Loss: 0.00004230
Iteration 36/1000 | Loss: 0.00004227
Iteration 37/1000 | Loss: 0.00004227
Iteration 38/1000 | Loss: 0.00004227
Iteration 39/1000 | Loss: 0.00004227
Iteration 40/1000 | Loss: 0.00004226
Iteration 41/1000 | Loss: 0.00004226
Iteration 42/1000 | Loss: 0.00004226
Iteration 43/1000 | Loss: 0.00004226
Iteration 44/1000 | Loss: 0.00004226
Iteration 45/1000 | Loss: 0.00004226
Iteration 46/1000 | Loss: 0.00004225
Iteration 47/1000 | Loss: 0.00004225
Iteration 48/1000 | Loss: 0.00004224
Iteration 49/1000 | Loss: 0.00004224
Iteration 50/1000 | Loss: 0.00004224
Iteration 51/1000 | Loss: 0.00004224
Iteration 52/1000 | Loss: 0.00004224
Iteration 53/1000 | Loss: 0.00004224
Iteration 54/1000 | Loss: 0.00004223
Iteration 55/1000 | Loss: 0.00004223
Iteration 56/1000 | Loss: 0.00004223
Iteration 57/1000 | Loss: 0.00004223
Iteration 58/1000 | Loss: 0.00004222
Iteration 59/1000 | Loss: 0.00004222
Iteration 60/1000 | Loss: 0.00004222
Iteration 61/1000 | Loss: 0.00004219
Iteration 62/1000 | Loss: 0.00004219
Iteration 63/1000 | Loss: 0.00004216
Iteration 64/1000 | Loss: 0.00004216
Iteration 65/1000 | Loss: 0.00004215
Iteration 66/1000 | Loss: 0.00004214
Iteration 67/1000 | Loss: 0.00004214
Iteration 68/1000 | Loss: 0.00004214
Iteration 69/1000 | Loss: 0.00004214
Iteration 70/1000 | Loss: 0.00004214
Iteration 71/1000 | Loss: 0.00004214
Iteration 72/1000 | Loss: 0.00004213
Iteration 73/1000 | Loss: 0.00004213
Iteration 74/1000 | Loss: 0.00004213
Iteration 75/1000 | Loss: 0.00004212
Iteration 76/1000 | Loss: 0.00004212
Iteration 77/1000 | Loss: 0.00004211
Iteration 78/1000 | Loss: 0.00004211
Iteration 79/1000 | Loss: 0.00004211
Iteration 80/1000 | Loss: 0.00004211
Iteration 81/1000 | Loss: 0.00004211
Iteration 82/1000 | Loss: 0.00004211
Iteration 83/1000 | Loss: 0.00004211
Iteration 84/1000 | Loss: 0.00004211
Iteration 85/1000 | Loss: 0.00004211
Iteration 86/1000 | Loss: 0.00004211
Iteration 87/1000 | Loss: 0.00004211
Iteration 88/1000 | Loss: 0.00004211
Iteration 89/1000 | Loss: 0.00004211
Iteration 90/1000 | Loss: 0.00004211
Iteration 91/1000 | Loss: 0.00004211
Iteration 92/1000 | Loss: 0.00004211
Iteration 93/1000 | Loss: 0.00004211
Iteration 94/1000 | Loss: 0.00004211
Iteration 95/1000 | Loss: 0.00004211
Iteration 96/1000 | Loss: 0.00004211
Iteration 97/1000 | Loss: 0.00004211
Iteration 98/1000 | Loss: 0.00004211
Iteration 99/1000 | Loss: 0.00004211
Iteration 100/1000 | Loss: 0.00004211
Iteration 101/1000 | Loss: 0.00004211
Iteration 102/1000 | Loss: 0.00004211
Iteration 103/1000 | Loss: 0.00004211
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [4.210844781482592e-05, 4.210844781482592e-05, 4.210844781482592e-05, 4.210844781482592e-05, 4.210844781482592e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.210844781482592e-05

Optimization complete. Final v2v error: 5.0688676834106445 mm

Highest mean error: 5.419530868530273 mm for frame 22

Lowest mean error: 4.704059600830078 mm for frame 120

Saving results

Total time: 38.02754998207092
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1060/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1060.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1060
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00820399
Iteration 2/25 | Loss: 0.00091785
Iteration 3/25 | Loss: 0.00076191
Iteration 4/25 | Loss: 0.00073777
Iteration 5/25 | Loss: 0.00073185
Iteration 6/25 | Loss: 0.00073036
Iteration 7/25 | Loss: 0.00073027
Iteration 8/25 | Loss: 0.00073027
Iteration 9/25 | Loss: 0.00073027
Iteration 10/25 | Loss: 0.00073027
Iteration 11/25 | Loss: 0.00073027
Iteration 12/25 | Loss: 0.00073027
Iteration 13/25 | Loss: 0.00073027
Iteration 14/25 | Loss: 0.00073027
Iteration 15/25 | Loss: 0.00073027
Iteration 16/25 | Loss: 0.00073027
Iteration 17/25 | Loss: 0.00073027
Iteration 18/25 | Loss: 0.00073027
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.000730272673536092, 0.000730272673536092, 0.000730272673536092, 0.000730272673536092, 0.000730272673536092]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000730272673536092

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59071815
Iteration 2/25 | Loss: 0.00119148
Iteration 3/25 | Loss: 0.00119148
Iteration 4/25 | Loss: 0.00119148
Iteration 5/25 | Loss: 0.00119148
Iteration 6/25 | Loss: 0.00119148
Iteration 7/25 | Loss: 0.00119148
Iteration 8/25 | Loss: 0.00119148
Iteration 9/25 | Loss: 0.00119148
Iteration 10/25 | Loss: 0.00119148
Iteration 11/25 | Loss: 0.00119148
Iteration 12/25 | Loss: 0.00119148
Iteration 13/25 | Loss: 0.00119148
Iteration 14/25 | Loss: 0.00119148
Iteration 15/25 | Loss: 0.00119148
Iteration 16/25 | Loss: 0.00119148
Iteration 17/25 | Loss: 0.00119148
Iteration 18/25 | Loss: 0.00119148
Iteration 19/25 | Loss: 0.00119148
Iteration 20/25 | Loss: 0.00119148
Iteration 21/25 | Loss: 0.00119148
Iteration 22/25 | Loss: 0.00119148
Iteration 23/25 | Loss: 0.00119148
Iteration 24/25 | Loss: 0.00119148
Iteration 25/25 | Loss: 0.00119148

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00119148
Iteration 2/1000 | Loss: 0.00002279
Iteration 3/1000 | Loss: 0.00001379
Iteration 4/1000 | Loss: 0.00001240
Iteration 5/1000 | Loss: 0.00001140
Iteration 6/1000 | Loss: 0.00001109
Iteration 7/1000 | Loss: 0.00001085
Iteration 8/1000 | Loss: 0.00001081
Iteration 9/1000 | Loss: 0.00001077
Iteration 10/1000 | Loss: 0.00001077
Iteration 11/1000 | Loss: 0.00001076
Iteration 12/1000 | Loss: 0.00001075
Iteration 13/1000 | Loss: 0.00001070
Iteration 14/1000 | Loss: 0.00001069
Iteration 15/1000 | Loss: 0.00001068
Iteration 16/1000 | Loss: 0.00001068
Iteration 17/1000 | Loss: 0.00001068
Iteration 18/1000 | Loss: 0.00001067
Iteration 19/1000 | Loss: 0.00001055
Iteration 20/1000 | Loss: 0.00001052
Iteration 21/1000 | Loss: 0.00001052
Iteration 22/1000 | Loss: 0.00001048
Iteration 23/1000 | Loss: 0.00001047
Iteration 24/1000 | Loss: 0.00001043
Iteration 25/1000 | Loss: 0.00001042
Iteration 26/1000 | Loss: 0.00001042
Iteration 27/1000 | Loss: 0.00001041
Iteration 28/1000 | Loss: 0.00001041
Iteration 29/1000 | Loss: 0.00001040
Iteration 30/1000 | Loss: 0.00001038
Iteration 31/1000 | Loss: 0.00001037
Iteration 32/1000 | Loss: 0.00001037
Iteration 33/1000 | Loss: 0.00001037
Iteration 34/1000 | Loss: 0.00001036
Iteration 35/1000 | Loss: 0.00001036
Iteration 36/1000 | Loss: 0.00001036
Iteration 37/1000 | Loss: 0.00001036
Iteration 38/1000 | Loss: 0.00001036
Iteration 39/1000 | Loss: 0.00001035
Iteration 40/1000 | Loss: 0.00001035
Iteration 41/1000 | Loss: 0.00001034
Iteration 42/1000 | Loss: 0.00001034
Iteration 43/1000 | Loss: 0.00001033
Iteration 44/1000 | Loss: 0.00001033
Iteration 45/1000 | Loss: 0.00001033
Iteration 46/1000 | Loss: 0.00001033
Iteration 47/1000 | Loss: 0.00001032
Iteration 48/1000 | Loss: 0.00001032
Iteration 49/1000 | Loss: 0.00001032
Iteration 50/1000 | Loss: 0.00001032
Iteration 51/1000 | Loss: 0.00001032
Iteration 52/1000 | Loss: 0.00001031
Iteration 53/1000 | Loss: 0.00001031
Iteration 54/1000 | Loss: 0.00001030
Iteration 55/1000 | Loss: 0.00001029
Iteration 56/1000 | Loss: 0.00001029
Iteration 57/1000 | Loss: 0.00001029
Iteration 58/1000 | Loss: 0.00001027
Iteration 59/1000 | Loss: 0.00001027
Iteration 60/1000 | Loss: 0.00001027
Iteration 61/1000 | Loss: 0.00001026
Iteration 62/1000 | Loss: 0.00001026
Iteration 63/1000 | Loss: 0.00001026
Iteration 64/1000 | Loss: 0.00001026
Iteration 65/1000 | Loss: 0.00001026
Iteration 66/1000 | Loss: 0.00001026
Iteration 67/1000 | Loss: 0.00001026
Iteration 68/1000 | Loss: 0.00001026
Iteration 69/1000 | Loss: 0.00001025
Iteration 70/1000 | Loss: 0.00001025
Iteration 71/1000 | Loss: 0.00001025
Iteration 72/1000 | Loss: 0.00001025
Iteration 73/1000 | Loss: 0.00001025
Iteration 74/1000 | Loss: 0.00001025
Iteration 75/1000 | Loss: 0.00001025
Iteration 76/1000 | Loss: 0.00001025
Iteration 77/1000 | Loss: 0.00001024
Iteration 78/1000 | Loss: 0.00001024
Iteration 79/1000 | Loss: 0.00001024
Iteration 80/1000 | Loss: 0.00001024
Iteration 81/1000 | Loss: 0.00001024
Iteration 82/1000 | Loss: 0.00001024
Iteration 83/1000 | Loss: 0.00001024
Iteration 84/1000 | Loss: 0.00001024
Iteration 85/1000 | Loss: 0.00001024
Iteration 86/1000 | Loss: 0.00001024
Iteration 87/1000 | Loss: 0.00001024
Iteration 88/1000 | Loss: 0.00001024
Iteration 89/1000 | Loss: 0.00001023
Iteration 90/1000 | Loss: 0.00001023
Iteration 91/1000 | Loss: 0.00001023
Iteration 92/1000 | Loss: 0.00001023
Iteration 93/1000 | Loss: 0.00001023
Iteration 94/1000 | Loss: 0.00001023
Iteration 95/1000 | Loss: 0.00001023
Iteration 96/1000 | Loss: 0.00001023
Iteration 97/1000 | Loss: 0.00001023
Iteration 98/1000 | Loss: 0.00001023
Iteration 99/1000 | Loss: 0.00001022
Iteration 100/1000 | Loss: 0.00001022
Iteration 101/1000 | Loss: 0.00001022
Iteration 102/1000 | Loss: 0.00001022
Iteration 103/1000 | Loss: 0.00001022
Iteration 104/1000 | Loss: 0.00001022
Iteration 105/1000 | Loss: 0.00001021
Iteration 106/1000 | Loss: 0.00001021
Iteration 107/1000 | Loss: 0.00001021
Iteration 108/1000 | Loss: 0.00001021
Iteration 109/1000 | Loss: 0.00001021
Iteration 110/1000 | Loss: 0.00001021
Iteration 111/1000 | Loss: 0.00001021
Iteration 112/1000 | Loss: 0.00001021
Iteration 113/1000 | Loss: 0.00001020
Iteration 114/1000 | Loss: 0.00001020
Iteration 115/1000 | Loss: 0.00001020
Iteration 116/1000 | Loss: 0.00001020
Iteration 117/1000 | Loss: 0.00001020
Iteration 118/1000 | Loss: 0.00001019
Iteration 119/1000 | Loss: 0.00001019
Iteration 120/1000 | Loss: 0.00001019
Iteration 121/1000 | Loss: 0.00001019
Iteration 122/1000 | Loss: 0.00001019
Iteration 123/1000 | Loss: 0.00001019
Iteration 124/1000 | Loss: 0.00001019
Iteration 125/1000 | Loss: 0.00001019
Iteration 126/1000 | Loss: 0.00001019
Iteration 127/1000 | Loss: 0.00001019
Iteration 128/1000 | Loss: 0.00001019
Iteration 129/1000 | Loss: 0.00001019
Iteration 130/1000 | Loss: 0.00001019
Iteration 131/1000 | Loss: 0.00001019
Iteration 132/1000 | Loss: 0.00001018
Iteration 133/1000 | Loss: 0.00001018
Iteration 134/1000 | Loss: 0.00001018
Iteration 135/1000 | Loss: 0.00001018
Iteration 136/1000 | Loss: 0.00001017
Iteration 137/1000 | Loss: 0.00001017
Iteration 138/1000 | Loss: 0.00001017
Iteration 139/1000 | Loss: 0.00001017
Iteration 140/1000 | Loss: 0.00001017
Iteration 141/1000 | Loss: 0.00001017
Iteration 142/1000 | Loss: 0.00001017
Iteration 143/1000 | Loss: 0.00001017
Iteration 144/1000 | Loss: 0.00001016
Iteration 145/1000 | Loss: 0.00001016
Iteration 146/1000 | Loss: 0.00001016
Iteration 147/1000 | Loss: 0.00001016
Iteration 148/1000 | Loss: 0.00001016
Iteration 149/1000 | Loss: 0.00001016
Iteration 150/1000 | Loss: 0.00001016
Iteration 151/1000 | Loss: 0.00001016
Iteration 152/1000 | Loss: 0.00001015
Iteration 153/1000 | Loss: 0.00001015
Iteration 154/1000 | Loss: 0.00001015
Iteration 155/1000 | Loss: 0.00001015
Iteration 156/1000 | Loss: 0.00001015
Iteration 157/1000 | Loss: 0.00001014
Iteration 158/1000 | Loss: 0.00001014
Iteration 159/1000 | Loss: 0.00001014
Iteration 160/1000 | Loss: 0.00001014
Iteration 161/1000 | Loss: 0.00001014
Iteration 162/1000 | Loss: 0.00001014
Iteration 163/1000 | Loss: 0.00001014
Iteration 164/1000 | Loss: 0.00001014
Iteration 165/1000 | Loss: 0.00001014
Iteration 166/1000 | Loss: 0.00001014
Iteration 167/1000 | Loss: 0.00001014
Iteration 168/1000 | Loss: 0.00001014
Iteration 169/1000 | Loss: 0.00001014
Iteration 170/1000 | Loss: 0.00001014
Iteration 171/1000 | Loss: 0.00001014
Iteration 172/1000 | Loss: 0.00001014
Iteration 173/1000 | Loss: 0.00001013
Iteration 174/1000 | Loss: 0.00001013
Iteration 175/1000 | Loss: 0.00001013
Iteration 176/1000 | Loss: 0.00001013
Iteration 177/1000 | Loss: 0.00001013
Iteration 178/1000 | Loss: 0.00001013
Iteration 179/1000 | Loss: 0.00001013
Iteration 180/1000 | Loss: 0.00001013
Iteration 181/1000 | Loss: 0.00001013
Iteration 182/1000 | Loss: 0.00001013
Iteration 183/1000 | Loss: 0.00001013
Iteration 184/1000 | Loss: 0.00001013
Iteration 185/1000 | Loss: 0.00001013
Iteration 186/1000 | Loss: 0.00001013
Iteration 187/1000 | Loss: 0.00001013
Iteration 188/1000 | Loss: 0.00001013
Iteration 189/1000 | Loss: 0.00001013
Iteration 190/1000 | Loss: 0.00001012
Iteration 191/1000 | Loss: 0.00001012
Iteration 192/1000 | Loss: 0.00001012
Iteration 193/1000 | Loss: 0.00001012
Iteration 194/1000 | Loss: 0.00001012
Iteration 195/1000 | Loss: 0.00001012
Iteration 196/1000 | Loss: 0.00001012
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [1.0124889740836807e-05, 1.0124889740836807e-05, 1.0124889740836807e-05, 1.0124889740836807e-05, 1.0124889740836807e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0124889740836807e-05

Optimization complete. Final v2v error: 2.6973636150360107 mm

Highest mean error: 2.89290189743042 mm for frame 56

Lowest mean error: 2.556168794631958 mm for frame 194

Saving results

Total time: 37.735344648361206
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00176016
Iteration 2/25 | Loss: 0.00086837
Iteration 3/25 | Loss: 0.00077623
Iteration 4/25 | Loss: 0.00074747
Iteration 5/25 | Loss: 0.00074097
Iteration 6/25 | Loss: 0.00073914
Iteration 7/25 | Loss: 0.00073866
Iteration 8/25 | Loss: 0.00073866
Iteration 9/25 | Loss: 0.00073866
Iteration 10/25 | Loss: 0.00073866
Iteration 11/25 | Loss: 0.00073866
Iteration 12/25 | Loss: 0.00073866
Iteration 13/25 | Loss: 0.00073866
Iteration 14/25 | Loss: 0.00073866
Iteration 15/25 | Loss: 0.00073866
Iteration 16/25 | Loss: 0.00073866
Iteration 17/25 | Loss: 0.00073866
Iteration 18/25 | Loss: 0.00073866
Iteration 19/25 | Loss: 0.00073866
Iteration 20/25 | Loss: 0.00073866
Iteration 21/25 | Loss: 0.00073866
Iteration 22/25 | Loss: 0.00073866
Iteration 23/25 | Loss: 0.00073866
Iteration 24/25 | Loss: 0.00073866
Iteration 25/25 | Loss: 0.00073866

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64556992
Iteration 2/25 | Loss: 0.00155555
Iteration 3/25 | Loss: 0.00155555
Iteration 4/25 | Loss: 0.00155555
Iteration 5/25 | Loss: 0.00155555
Iteration 6/25 | Loss: 0.00155555
Iteration 7/25 | Loss: 0.00155555
Iteration 8/25 | Loss: 0.00155555
Iteration 9/25 | Loss: 0.00155554
Iteration 10/25 | Loss: 0.00155554
Iteration 11/25 | Loss: 0.00155554
Iteration 12/25 | Loss: 0.00155554
Iteration 13/25 | Loss: 0.00155554
Iteration 14/25 | Loss: 0.00155554
Iteration 15/25 | Loss: 0.00155554
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0015555445570498705, 0.0015555445570498705, 0.0015555445570498705, 0.0015555445570498705, 0.0015555445570498705]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015555445570498705

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00155554
Iteration 2/1000 | Loss: 0.00003168
Iteration 3/1000 | Loss: 0.00001918
Iteration 4/1000 | Loss: 0.00001509
Iteration 5/1000 | Loss: 0.00001403
Iteration 6/1000 | Loss: 0.00001316
Iteration 7/1000 | Loss: 0.00001282
Iteration 8/1000 | Loss: 0.00001243
Iteration 9/1000 | Loss: 0.00001232
Iteration 10/1000 | Loss: 0.00001231
Iteration 11/1000 | Loss: 0.00001225
Iteration 12/1000 | Loss: 0.00001222
Iteration 13/1000 | Loss: 0.00001219
Iteration 14/1000 | Loss: 0.00001212
Iteration 15/1000 | Loss: 0.00001203
Iteration 16/1000 | Loss: 0.00001203
Iteration 17/1000 | Loss: 0.00001203
Iteration 18/1000 | Loss: 0.00001203
Iteration 19/1000 | Loss: 0.00001202
Iteration 20/1000 | Loss: 0.00001197
Iteration 21/1000 | Loss: 0.00001195
Iteration 22/1000 | Loss: 0.00001195
Iteration 23/1000 | Loss: 0.00001190
Iteration 24/1000 | Loss: 0.00001185
Iteration 25/1000 | Loss: 0.00001180
Iteration 26/1000 | Loss: 0.00001180
Iteration 27/1000 | Loss: 0.00001178
Iteration 28/1000 | Loss: 0.00001178
Iteration 29/1000 | Loss: 0.00001177
Iteration 30/1000 | Loss: 0.00001177
Iteration 31/1000 | Loss: 0.00001176
Iteration 32/1000 | Loss: 0.00001176
Iteration 33/1000 | Loss: 0.00001176
Iteration 34/1000 | Loss: 0.00001176
Iteration 35/1000 | Loss: 0.00001176
Iteration 36/1000 | Loss: 0.00001176
Iteration 37/1000 | Loss: 0.00001176
Iteration 38/1000 | Loss: 0.00001176
Iteration 39/1000 | Loss: 0.00001176
Iteration 40/1000 | Loss: 0.00001175
Iteration 41/1000 | Loss: 0.00001175
Iteration 42/1000 | Loss: 0.00001175
Iteration 43/1000 | Loss: 0.00001175
Iteration 44/1000 | Loss: 0.00001175
Iteration 45/1000 | Loss: 0.00001175
Iteration 46/1000 | Loss: 0.00001175
Iteration 47/1000 | Loss: 0.00001175
Iteration 48/1000 | Loss: 0.00001175
Iteration 49/1000 | Loss: 0.00001175
Iteration 50/1000 | Loss: 0.00001175
Iteration 51/1000 | Loss: 0.00001174
Iteration 52/1000 | Loss: 0.00001174
Iteration 53/1000 | Loss: 0.00001174
Iteration 54/1000 | Loss: 0.00001173
Iteration 55/1000 | Loss: 0.00001173
Iteration 56/1000 | Loss: 0.00001173
Iteration 57/1000 | Loss: 0.00001173
Iteration 58/1000 | Loss: 0.00001173
Iteration 59/1000 | Loss: 0.00001173
Iteration 60/1000 | Loss: 0.00001173
Iteration 61/1000 | Loss: 0.00001173
Iteration 62/1000 | Loss: 0.00001173
Iteration 63/1000 | Loss: 0.00001173
Iteration 64/1000 | Loss: 0.00001173
Iteration 65/1000 | Loss: 0.00001173
Iteration 66/1000 | Loss: 0.00001173
Iteration 67/1000 | Loss: 0.00001173
Iteration 68/1000 | Loss: 0.00001173
Iteration 69/1000 | Loss: 0.00001173
Iteration 70/1000 | Loss: 0.00001173
Iteration 71/1000 | Loss: 0.00001173
Iteration 72/1000 | Loss: 0.00001173
Iteration 73/1000 | Loss: 0.00001173
Iteration 74/1000 | Loss: 0.00001173
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 74. Stopping optimization.
Last 5 losses: [1.1732226084859576e-05, 1.1732226084859576e-05, 1.1732226084859576e-05, 1.1732226084859576e-05, 1.1732226084859576e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1732226084859576e-05

Optimization complete. Final v2v error: 2.961203098297119 mm

Highest mean error: 3.2517342567443848 mm for frame 21

Lowest mean error: 2.748975992202759 mm for frame 204

Saving results

Total time: 35.004186391830444
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1072/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1072.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1072
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00950357
Iteration 2/25 | Loss: 0.00152601
Iteration 3/25 | Loss: 0.00098432
Iteration 4/25 | Loss: 0.00091858
Iteration 5/25 | Loss: 0.00089495
Iteration 6/25 | Loss: 0.00088706
Iteration 7/25 | Loss: 0.00088604
Iteration 8/25 | Loss: 0.00088599
Iteration 9/25 | Loss: 0.00088599
Iteration 10/25 | Loss: 0.00088599
Iteration 11/25 | Loss: 0.00088599
Iteration 12/25 | Loss: 0.00088599
Iteration 13/25 | Loss: 0.00088599
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008859930094331503, 0.0008859930094331503, 0.0008859930094331503, 0.0008859930094331503, 0.0008859930094331503]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008859930094331503

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.18590426
Iteration 2/25 | Loss: 0.00093280
Iteration 3/25 | Loss: 0.00093278
Iteration 4/25 | Loss: 0.00093278
Iteration 5/25 | Loss: 0.00093278
Iteration 6/25 | Loss: 0.00093278
Iteration 7/25 | Loss: 0.00093278
Iteration 8/25 | Loss: 0.00093278
Iteration 9/25 | Loss: 0.00093278
Iteration 10/25 | Loss: 0.00093278
Iteration 11/25 | Loss: 0.00093278
Iteration 12/25 | Loss: 0.00093278
Iteration 13/25 | Loss: 0.00093278
Iteration 14/25 | Loss: 0.00093278
Iteration 15/25 | Loss: 0.00093278
Iteration 16/25 | Loss: 0.00093278
Iteration 17/25 | Loss: 0.00093278
Iteration 18/25 | Loss: 0.00093278
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009327751467935741, 0.0009327751467935741, 0.0009327751467935741, 0.0009327751467935741, 0.0009327751467935741]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009327751467935741

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00093278
Iteration 2/1000 | Loss: 0.00005604
Iteration 3/1000 | Loss: 0.00003928
Iteration 4/1000 | Loss: 0.00003477
Iteration 5/1000 | Loss: 0.00003288
Iteration 6/1000 | Loss: 0.00003116
Iteration 7/1000 | Loss: 0.00002996
Iteration 8/1000 | Loss: 0.00002917
Iteration 9/1000 | Loss: 0.00002872
Iteration 10/1000 | Loss: 0.00002841
Iteration 11/1000 | Loss: 0.00002818
Iteration 12/1000 | Loss: 0.00002799
Iteration 13/1000 | Loss: 0.00002790
Iteration 14/1000 | Loss: 0.00002784
Iteration 15/1000 | Loss: 0.00002777
Iteration 16/1000 | Loss: 0.00002777
Iteration 17/1000 | Loss: 0.00002768
Iteration 18/1000 | Loss: 0.00002765
Iteration 19/1000 | Loss: 0.00002765
Iteration 20/1000 | Loss: 0.00002765
Iteration 21/1000 | Loss: 0.00002764
Iteration 22/1000 | Loss: 0.00002764
Iteration 23/1000 | Loss: 0.00002763
Iteration 24/1000 | Loss: 0.00002762
Iteration 25/1000 | Loss: 0.00002761
Iteration 26/1000 | Loss: 0.00002761
Iteration 27/1000 | Loss: 0.00002760
Iteration 28/1000 | Loss: 0.00002754
Iteration 29/1000 | Loss: 0.00002753
Iteration 30/1000 | Loss: 0.00002749
Iteration 31/1000 | Loss: 0.00002748
Iteration 32/1000 | Loss: 0.00002743
Iteration 33/1000 | Loss: 0.00002736
Iteration 34/1000 | Loss: 0.00002732
Iteration 35/1000 | Loss: 0.00002731
Iteration 36/1000 | Loss: 0.00002730
Iteration 37/1000 | Loss: 0.00002730
Iteration 38/1000 | Loss: 0.00002730
Iteration 39/1000 | Loss: 0.00002729
Iteration 40/1000 | Loss: 0.00002729
Iteration 41/1000 | Loss: 0.00002727
Iteration 42/1000 | Loss: 0.00002727
Iteration 43/1000 | Loss: 0.00002725
Iteration 44/1000 | Loss: 0.00002724
Iteration 45/1000 | Loss: 0.00002724
Iteration 46/1000 | Loss: 0.00002721
Iteration 47/1000 | Loss: 0.00002720
Iteration 48/1000 | Loss: 0.00002720
Iteration 49/1000 | Loss: 0.00002720
Iteration 50/1000 | Loss: 0.00002720
Iteration 51/1000 | Loss: 0.00002720
Iteration 52/1000 | Loss: 0.00002720
Iteration 53/1000 | Loss: 0.00002720
Iteration 54/1000 | Loss: 0.00002720
Iteration 55/1000 | Loss: 0.00002720
Iteration 56/1000 | Loss: 0.00002720
Iteration 57/1000 | Loss: 0.00002719
Iteration 58/1000 | Loss: 0.00002719
Iteration 59/1000 | Loss: 0.00002717
Iteration 60/1000 | Loss: 0.00002717
Iteration 61/1000 | Loss: 0.00002716
Iteration 62/1000 | Loss: 0.00002716
Iteration 63/1000 | Loss: 0.00002716
Iteration 64/1000 | Loss: 0.00002716
Iteration 65/1000 | Loss: 0.00002715
Iteration 66/1000 | Loss: 0.00002715
Iteration 67/1000 | Loss: 0.00002715
Iteration 68/1000 | Loss: 0.00002714
Iteration 69/1000 | Loss: 0.00002714
Iteration 70/1000 | Loss: 0.00002714
Iteration 71/1000 | Loss: 0.00002714
Iteration 72/1000 | Loss: 0.00002713
Iteration 73/1000 | Loss: 0.00002713
Iteration 74/1000 | Loss: 0.00002713
Iteration 75/1000 | Loss: 0.00002713
Iteration 76/1000 | Loss: 0.00002713
Iteration 77/1000 | Loss: 0.00002713
Iteration 78/1000 | Loss: 0.00002712
Iteration 79/1000 | Loss: 0.00002712
Iteration 80/1000 | Loss: 0.00002712
Iteration 81/1000 | Loss: 0.00002712
Iteration 82/1000 | Loss: 0.00002711
Iteration 83/1000 | Loss: 0.00002711
Iteration 84/1000 | Loss: 0.00002711
Iteration 85/1000 | Loss: 0.00002711
Iteration 86/1000 | Loss: 0.00002710
Iteration 87/1000 | Loss: 0.00002710
Iteration 88/1000 | Loss: 0.00002710
Iteration 89/1000 | Loss: 0.00002710
Iteration 90/1000 | Loss: 0.00002709
Iteration 91/1000 | Loss: 0.00002709
Iteration 92/1000 | Loss: 0.00002709
Iteration 93/1000 | Loss: 0.00002709
Iteration 94/1000 | Loss: 0.00002709
Iteration 95/1000 | Loss: 0.00002709
Iteration 96/1000 | Loss: 0.00002709
Iteration 97/1000 | Loss: 0.00002708
Iteration 98/1000 | Loss: 0.00002708
Iteration 99/1000 | Loss: 0.00002708
Iteration 100/1000 | Loss: 0.00002708
Iteration 101/1000 | Loss: 0.00002708
Iteration 102/1000 | Loss: 0.00002708
Iteration 103/1000 | Loss: 0.00002708
Iteration 104/1000 | Loss: 0.00002708
Iteration 105/1000 | Loss: 0.00002708
Iteration 106/1000 | Loss: 0.00002708
Iteration 107/1000 | Loss: 0.00002708
Iteration 108/1000 | Loss: 0.00002708
Iteration 109/1000 | Loss: 0.00002708
Iteration 110/1000 | Loss: 0.00002708
Iteration 111/1000 | Loss: 0.00002707
Iteration 112/1000 | Loss: 0.00002707
Iteration 113/1000 | Loss: 0.00002707
Iteration 114/1000 | Loss: 0.00002707
Iteration 115/1000 | Loss: 0.00002707
Iteration 116/1000 | Loss: 0.00002707
Iteration 117/1000 | Loss: 0.00002707
Iteration 118/1000 | Loss: 0.00002706
Iteration 119/1000 | Loss: 0.00002706
Iteration 120/1000 | Loss: 0.00002706
Iteration 121/1000 | Loss: 0.00002706
Iteration 122/1000 | Loss: 0.00002706
Iteration 123/1000 | Loss: 0.00002706
Iteration 124/1000 | Loss: 0.00002706
Iteration 125/1000 | Loss: 0.00002705
Iteration 126/1000 | Loss: 0.00002705
Iteration 127/1000 | Loss: 0.00002705
Iteration 128/1000 | Loss: 0.00002705
Iteration 129/1000 | Loss: 0.00002705
Iteration 130/1000 | Loss: 0.00002705
Iteration 131/1000 | Loss: 0.00002705
Iteration 132/1000 | Loss: 0.00002705
Iteration 133/1000 | Loss: 0.00002704
Iteration 134/1000 | Loss: 0.00002704
Iteration 135/1000 | Loss: 0.00002704
Iteration 136/1000 | Loss: 0.00002704
Iteration 137/1000 | Loss: 0.00002704
Iteration 138/1000 | Loss: 0.00002704
Iteration 139/1000 | Loss: 0.00002704
Iteration 140/1000 | Loss: 0.00002703
Iteration 141/1000 | Loss: 0.00002703
Iteration 142/1000 | Loss: 0.00002703
Iteration 143/1000 | Loss: 0.00002703
Iteration 144/1000 | Loss: 0.00002703
Iteration 145/1000 | Loss: 0.00002703
Iteration 146/1000 | Loss: 0.00002702
Iteration 147/1000 | Loss: 0.00002702
Iteration 148/1000 | Loss: 0.00002702
Iteration 149/1000 | Loss: 0.00002702
Iteration 150/1000 | Loss: 0.00002701
Iteration 151/1000 | Loss: 0.00002701
Iteration 152/1000 | Loss: 0.00002701
Iteration 153/1000 | Loss: 0.00002701
Iteration 154/1000 | Loss: 0.00002701
Iteration 155/1000 | Loss: 0.00002701
Iteration 156/1000 | Loss: 0.00002700
Iteration 157/1000 | Loss: 0.00002700
Iteration 158/1000 | Loss: 0.00002700
Iteration 159/1000 | Loss: 0.00002700
Iteration 160/1000 | Loss: 0.00002700
Iteration 161/1000 | Loss: 0.00002700
Iteration 162/1000 | Loss: 0.00002700
Iteration 163/1000 | Loss: 0.00002700
Iteration 164/1000 | Loss: 0.00002700
Iteration 165/1000 | Loss: 0.00002700
Iteration 166/1000 | Loss: 0.00002700
Iteration 167/1000 | Loss: 0.00002700
Iteration 168/1000 | Loss: 0.00002700
Iteration 169/1000 | Loss: 0.00002700
Iteration 170/1000 | Loss: 0.00002700
Iteration 171/1000 | Loss: 0.00002699
Iteration 172/1000 | Loss: 0.00002699
Iteration 173/1000 | Loss: 0.00002699
Iteration 174/1000 | Loss: 0.00002699
Iteration 175/1000 | Loss: 0.00002699
Iteration 176/1000 | Loss: 0.00002699
Iteration 177/1000 | Loss: 0.00002699
Iteration 178/1000 | Loss: 0.00002699
Iteration 179/1000 | Loss: 0.00002699
Iteration 180/1000 | Loss: 0.00002699
Iteration 181/1000 | Loss: 0.00002699
Iteration 182/1000 | Loss: 0.00002699
Iteration 183/1000 | Loss: 0.00002699
Iteration 184/1000 | Loss: 0.00002698
Iteration 185/1000 | Loss: 0.00002698
Iteration 186/1000 | Loss: 0.00002698
Iteration 187/1000 | Loss: 0.00002698
Iteration 188/1000 | Loss: 0.00002698
Iteration 189/1000 | Loss: 0.00002698
Iteration 190/1000 | Loss: 0.00002698
Iteration 191/1000 | Loss: 0.00002698
Iteration 192/1000 | Loss: 0.00002698
Iteration 193/1000 | Loss: 0.00002698
Iteration 194/1000 | Loss: 0.00002698
Iteration 195/1000 | Loss: 0.00002698
Iteration 196/1000 | Loss: 0.00002698
Iteration 197/1000 | Loss: 0.00002698
Iteration 198/1000 | Loss: 0.00002698
Iteration 199/1000 | Loss: 0.00002698
Iteration 200/1000 | Loss: 0.00002698
Iteration 201/1000 | Loss: 0.00002698
Iteration 202/1000 | Loss: 0.00002698
Iteration 203/1000 | Loss: 0.00002698
Iteration 204/1000 | Loss: 0.00002698
Iteration 205/1000 | Loss: 0.00002698
Iteration 206/1000 | Loss: 0.00002698
Iteration 207/1000 | Loss: 0.00002698
Iteration 208/1000 | Loss: 0.00002698
Iteration 209/1000 | Loss: 0.00002698
Iteration 210/1000 | Loss: 0.00002698
Iteration 211/1000 | Loss: 0.00002698
Iteration 212/1000 | Loss: 0.00002698
Iteration 213/1000 | Loss: 0.00002698
Iteration 214/1000 | Loss: 0.00002698
Iteration 215/1000 | Loss: 0.00002698
Iteration 216/1000 | Loss: 0.00002698
Iteration 217/1000 | Loss: 0.00002698
Iteration 218/1000 | Loss: 0.00002698
Iteration 219/1000 | Loss: 0.00002698
Iteration 220/1000 | Loss: 0.00002698
Iteration 221/1000 | Loss: 0.00002698
Iteration 222/1000 | Loss: 0.00002698
Iteration 223/1000 | Loss: 0.00002698
Iteration 224/1000 | Loss: 0.00002698
Iteration 225/1000 | Loss: 0.00002698
Iteration 226/1000 | Loss: 0.00002698
Iteration 227/1000 | Loss: 0.00002698
Iteration 228/1000 | Loss: 0.00002698
Iteration 229/1000 | Loss: 0.00002698
Iteration 230/1000 | Loss: 0.00002698
Iteration 231/1000 | Loss: 0.00002698
Iteration 232/1000 | Loss: 0.00002698
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 232. Stopping optimization.
Last 5 losses: [2.697580748645123e-05, 2.697580748645123e-05, 2.697580748645123e-05, 2.697580748645123e-05, 2.697580748645123e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.697580748645123e-05

Optimization complete. Final v2v error: 4.208613395690918 mm

Highest mean error: 5.354835510253906 mm for frame 103

Lowest mean error: 3.4296884536743164 mm for frame 41

Saving results

Total time: 48.40751123428345
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1030
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00810960
Iteration 2/25 | Loss: 0.00104428
Iteration 3/25 | Loss: 0.00078562
Iteration 4/25 | Loss: 0.00075516
Iteration 5/25 | Loss: 0.00074995
Iteration 6/25 | Loss: 0.00074791
Iteration 7/25 | Loss: 0.00074727
Iteration 8/25 | Loss: 0.00074727
Iteration 9/25 | Loss: 0.00074727
Iteration 10/25 | Loss: 0.00074727
Iteration 11/25 | Loss: 0.00074727
Iteration 12/25 | Loss: 0.00074727
Iteration 13/25 | Loss: 0.00074727
Iteration 14/25 | Loss: 0.00074727
Iteration 15/25 | Loss: 0.00074727
Iteration 16/25 | Loss: 0.00074727
Iteration 17/25 | Loss: 0.00074727
Iteration 18/25 | Loss: 0.00074727
Iteration 19/25 | Loss: 0.00074727
Iteration 20/25 | Loss: 0.00074727
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0007472736178897321, 0.0007472736178897321, 0.0007472736178897321, 0.0007472736178897321, 0.0007472736178897321]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007472736178897321

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60245061
Iteration 2/25 | Loss: 0.00128117
Iteration 3/25 | Loss: 0.00128117
Iteration 4/25 | Loss: 0.00128117
Iteration 5/25 | Loss: 0.00128117
Iteration 6/25 | Loss: 0.00128117
Iteration 7/25 | Loss: 0.00128117
Iteration 8/25 | Loss: 0.00128117
Iteration 9/25 | Loss: 0.00128117
Iteration 10/25 | Loss: 0.00128117
Iteration 11/25 | Loss: 0.00128117
Iteration 12/25 | Loss: 0.00128117
Iteration 13/25 | Loss: 0.00128117
Iteration 14/25 | Loss: 0.00128117
Iteration 15/25 | Loss: 0.00128117
Iteration 16/25 | Loss: 0.00128117
Iteration 17/25 | Loss: 0.00128117
Iteration 18/25 | Loss: 0.00128117
Iteration 19/25 | Loss: 0.00128117
Iteration 20/25 | Loss: 0.00128117
Iteration 21/25 | Loss: 0.00128117
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.001281167147681117, 0.001281167147681117, 0.001281167147681117, 0.001281167147681117, 0.001281167147681117]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001281167147681117

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00128117
Iteration 2/1000 | Loss: 0.00002487
Iteration 3/1000 | Loss: 0.00001550
Iteration 4/1000 | Loss: 0.00001416
Iteration 5/1000 | Loss: 0.00001334
Iteration 6/1000 | Loss: 0.00001249
Iteration 7/1000 | Loss: 0.00001214
Iteration 8/1000 | Loss: 0.00001193
Iteration 9/1000 | Loss: 0.00001176
Iteration 10/1000 | Loss: 0.00001174
Iteration 11/1000 | Loss: 0.00001156
Iteration 12/1000 | Loss: 0.00001155
Iteration 13/1000 | Loss: 0.00001154
Iteration 14/1000 | Loss: 0.00001145
Iteration 15/1000 | Loss: 0.00001139
Iteration 16/1000 | Loss: 0.00001139
Iteration 17/1000 | Loss: 0.00001138
Iteration 18/1000 | Loss: 0.00001135
Iteration 19/1000 | Loss: 0.00001135
Iteration 20/1000 | Loss: 0.00001135
Iteration 21/1000 | Loss: 0.00001134
Iteration 22/1000 | Loss: 0.00001133
Iteration 23/1000 | Loss: 0.00001133
Iteration 24/1000 | Loss: 0.00001133
Iteration 25/1000 | Loss: 0.00001133
Iteration 26/1000 | Loss: 0.00001132
Iteration 27/1000 | Loss: 0.00001131
Iteration 28/1000 | Loss: 0.00001131
Iteration 29/1000 | Loss: 0.00001131
Iteration 30/1000 | Loss: 0.00001131
Iteration 31/1000 | Loss: 0.00001130
Iteration 32/1000 | Loss: 0.00001129
Iteration 33/1000 | Loss: 0.00001129
Iteration 34/1000 | Loss: 0.00001129
Iteration 35/1000 | Loss: 0.00001127
Iteration 36/1000 | Loss: 0.00001125
Iteration 37/1000 | Loss: 0.00001123
Iteration 38/1000 | Loss: 0.00001122
Iteration 39/1000 | Loss: 0.00001121
Iteration 40/1000 | Loss: 0.00001121
Iteration 41/1000 | Loss: 0.00001120
Iteration 42/1000 | Loss: 0.00001120
Iteration 43/1000 | Loss: 0.00001120
Iteration 44/1000 | Loss: 0.00001120
Iteration 45/1000 | Loss: 0.00001120
Iteration 46/1000 | Loss: 0.00001120
Iteration 47/1000 | Loss: 0.00001119
Iteration 48/1000 | Loss: 0.00001119
Iteration 49/1000 | Loss: 0.00001119
Iteration 50/1000 | Loss: 0.00001118
Iteration 51/1000 | Loss: 0.00001118
Iteration 52/1000 | Loss: 0.00001118
Iteration 53/1000 | Loss: 0.00001118
Iteration 54/1000 | Loss: 0.00001117
Iteration 55/1000 | Loss: 0.00001117
Iteration 56/1000 | Loss: 0.00001117
Iteration 57/1000 | Loss: 0.00001117
Iteration 58/1000 | Loss: 0.00001117
Iteration 59/1000 | Loss: 0.00001117
Iteration 60/1000 | Loss: 0.00001116
Iteration 61/1000 | Loss: 0.00001116
Iteration 62/1000 | Loss: 0.00001116
Iteration 63/1000 | Loss: 0.00001116
Iteration 64/1000 | Loss: 0.00001116
Iteration 65/1000 | Loss: 0.00001116
Iteration 66/1000 | Loss: 0.00001116
Iteration 67/1000 | Loss: 0.00001116
Iteration 68/1000 | Loss: 0.00001115
Iteration 69/1000 | Loss: 0.00001115
Iteration 70/1000 | Loss: 0.00001115
Iteration 71/1000 | Loss: 0.00001115
Iteration 72/1000 | Loss: 0.00001115
Iteration 73/1000 | Loss: 0.00001115
Iteration 74/1000 | Loss: 0.00001115
Iteration 75/1000 | Loss: 0.00001114
Iteration 76/1000 | Loss: 0.00001114
Iteration 77/1000 | Loss: 0.00001114
Iteration 78/1000 | Loss: 0.00001114
Iteration 79/1000 | Loss: 0.00001113
Iteration 80/1000 | Loss: 0.00001113
Iteration 81/1000 | Loss: 0.00001113
Iteration 82/1000 | Loss: 0.00001113
Iteration 83/1000 | Loss: 0.00001113
Iteration 84/1000 | Loss: 0.00001113
Iteration 85/1000 | Loss: 0.00001112
Iteration 86/1000 | Loss: 0.00001112
Iteration 87/1000 | Loss: 0.00001112
Iteration 88/1000 | Loss: 0.00001112
Iteration 89/1000 | Loss: 0.00001112
Iteration 90/1000 | Loss: 0.00001112
Iteration 91/1000 | Loss: 0.00001112
Iteration 92/1000 | Loss: 0.00001112
Iteration 93/1000 | Loss: 0.00001112
Iteration 94/1000 | Loss: 0.00001111
Iteration 95/1000 | Loss: 0.00001111
Iteration 96/1000 | Loss: 0.00001111
Iteration 97/1000 | Loss: 0.00001111
Iteration 98/1000 | Loss: 0.00001111
Iteration 99/1000 | Loss: 0.00001111
Iteration 100/1000 | Loss: 0.00001111
Iteration 101/1000 | Loss: 0.00001111
Iteration 102/1000 | Loss: 0.00001111
Iteration 103/1000 | Loss: 0.00001111
Iteration 104/1000 | Loss: 0.00001111
Iteration 105/1000 | Loss: 0.00001111
Iteration 106/1000 | Loss: 0.00001111
Iteration 107/1000 | Loss: 0.00001110
Iteration 108/1000 | Loss: 0.00001110
Iteration 109/1000 | Loss: 0.00001110
Iteration 110/1000 | Loss: 0.00001110
Iteration 111/1000 | Loss: 0.00001110
Iteration 112/1000 | Loss: 0.00001110
Iteration 113/1000 | Loss: 0.00001110
Iteration 114/1000 | Loss: 0.00001110
Iteration 115/1000 | Loss: 0.00001110
Iteration 116/1000 | Loss: 0.00001110
Iteration 117/1000 | Loss: 0.00001110
Iteration 118/1000 | Loss: 0.00001110
Iteration 119/1000 | Loss: 0.00001110
Iteration 120/1000 | Loss: 0.00001109
Iteration 121/1000 | Loss: 0.00001109
Iteration 122/1000 | Loss: 0.00001109
Iteration 123/1000 | Loss: 0.00001109
Iteration 124/1000 | Loss: 0.00001109
Iteration 125/1000 | Loss: 0.00001109
Iteration 126/1000 | Loss: 0.00001109
Iteration 127/1000 | Loss: 0.00001109
Iteration 128/1000 | Loss: 0.00001109
Iteration 129/1000 | Loss: 0.00001109
Iteration 130/1000 | Loss: 0.00001109
Iteration 131/1000 | Loss: 0.00001109
Iteration 132/1000 | Loss: 0.00001109
Iteration 133/1000 | Loss: 0.00001109
Iteration 134/1000 | Loss: 0.00001109
Iteration 135/1000 | Loss: 0.00001108
Iteration 136/1000 | Loss: 0.00001108
Iteration 137/1000 | Loss: 0.00001108
Iteration 138/1000 | Loss: 0.00001108
Iteration 139/1000 | Loss: 0.00001108
Iteration 140/1000 | Loss: 0.00001108
Iteration 141/1000 | Loss: 0.00001108
Iteration 142/1000 | Loss: 0.00001108
Iteration 143/1000 | Loss: 0.00001108
Iteration 144/1000 | Loss: 0.00001108
Iteration 145/1000 | Loss: 0.00001108
Iteration 146/1000 | Loss: 0.00001108
Iteration 147/1000 | Loss: 0.00001108
Iteration 148/1000 | Loss: 0.00001108
Iteration 149/1000 | Loss: 0.00001108
Iteration 150/1000 | Loss: 0.00001108
Iteration 151/1000 | Loss: 0.00001108
Iteration 152/1000 | Loss: 0.00001107
Iteration 153/1000 | Loss: 0.00001107
Iteration 154/1000 | Loss: 0.00001107
Iteration 155/1000 | Loss: 0.00001107
Iteration 156/1000 | Loss: 0.00001107
Iteration 157/1000 | Loss: 0.00001107
Iteration 158/1000 | Loss: 0.00001107
Iteration 159/1000 | Loss: 0.00001107
Iteration 160/1000 | Loss: 0.00001107
Iteration 161/1000 | Loss: 0.00001107
Iteration 162/1000 | Loss: 0.00001107
Iteration 163/1000 | Loss: 0.00001107
Iteration 164/1000 | Loss: 0.00001107
Iteration 165/1000 | Loss: 0.00001107
Iteration 166/1000 | Loss: 0.00001107
Iteration 167/1000 | Loss: 0.00001107
Iteration 168/1000 | Loss: 0.00001107
Iteration 169/1000 | Loss: 0.00001107
Iteration 170/1000 | Loss: 0.00001107
Iteration 171/1000 | Loss: 0.00001107
Iteration 172/1000 | Loss: 0.00001107
Iteration 173/1000 | Loss: 0.00001107
Iteration 174/1000 | Loss: 0.00001107
Iteration 175/1000 | Loss: 0.00001107
Iteration 176/1000 | Loss: 0.00001107
Iteration 177/1000 | Loss: 0.00001107
Iteration 178/1000 | Loss: 0.00001107
Iteration 179/1000 | Loss: 0.00001107
Iteration 180/1000 | Loss: 0.00001107
Iteration 181/1000 | Loss: 0.00001107
Iteration 182/1000 | Loss: 0.00001107
Iteration 183/1000 | Loss: 0.00001107
Iteration 184/1000 | Loss: 0.00001107
Iteration 185/1000 | Loss: 0.00001107
Iteration 186/1000 | Loss: 0.00001107
Iteration 187/1000 | Loss: 0.00001107
Iteration 188/1000 | Loss: 0.00001107
Iteration 189/1000 | Loss: 0.00001107
Iteration 190/1000 | Loss: 0.00001107
Iteration 191/1000 | Loss: 0.00001107
Iteration 192/1000 | Loss: 0.00001107
Iteration 193/1000 | Loss: 0.00001107
Iteration 194/1000 | Loss: 0.00001107
Iteration 195/1000 | Loss: 0.00001107
Iteration 196/1000 | Loss: 0.00001107
Iteration 197/1000 | Loss: 0.00001107
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [1.1068211279052775e-05, 1.1068211279052775e-05, 1.1068211279052775e-05, 1.1068211279052775e-05, 1.1068211279052775e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1068211279052775e-05

Optimization complete. Final v2v error: 2.8135695457458496 mm

Highest mean error: 3.151951313018799 mm for frame 85

Lowest mean error: 2.6757068634033203 mm for frame 163

Saving results

Total time: 39.16463494300842
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1061/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1061.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1061
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00878836
Iteration 2/25 | Loss: 0.00104833
Iteration 3/25 | Loss: 0.00088161
Iteration 4/25 | Loss: 0.00084257
Iteration 5/25 | Loss: 0.00082999
Iteration 6/25 | Loss: 0.00082700
Iteration 7/25 | Loss: 0.00082657
Iteration 8/25 | Loss: 0.00082657
Iteration 9/25 | Loss: 0.00082657
Iteration 10/25 | Loss: 0.00082657
Iteration 11/25 | Loss: 0.00082657
Iteration 12/25 | Loss: 0.00082657
Iteration 13/25 | Loss: 0.00082657
Iteration 14/25 | Loss: 0.00082657
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0008265734650194645, 0.0008265734650194645, 0.0008265734650194645, 0.0008265734650194645, 0.0008265734650194645]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008265734650194645

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52936888
Iteration 2/25 | Loss: 0.00148400
Iteration 3/25 | Loss: 0.00148399
Iteration 4/25 | Loss: 0.00148399
Iteration 5/25 | Loss: 0.00148399
Iteration 6/25 | Loss: 0.00148399
Iteration 7/25 | Loss: 0.00148399
Iteration 8/25 | Loss: 0.00148399
Iteration 9/25 | Loss: 0.00148399
Iteration 10/25 | Loss: 0.00148399
Iteration 11/25 | Loss: 0.00148399
Iteration 12/25 | Loss: 0.00148399
Iteration 13/25 | Loss: 0.00148399
Iteration 14/25 | Loss: 0.00148399
Iteration 15/25 | Loss: 0.00148399
Iteration 16/25 | Loss: 0.00148399
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001483985222876072, 0.001483985222876072, 0.001483985222876072, 0.001483985222876072, 0.001483985222876072]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001483985222876072

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00148399
Iteration 2/1000 | Loss: 0.00004849
Iteration 3/1000 | Loss: 0.00003414
Iteration 4/1000 | Loss: 0.00002873
Iteration 5/1000 | Loss: 0.00002692
Iteration 6/1000 | Loss: 0.00002563
Iteration 7/1000 | Loss: 0.00002473
Iteration 8/1000 | Loss: 0.00002396
Iteration 9/1000 | Loss: 0.00002348
Iteration 10/1000 | Loss: 0.00002310
Iteration 11/1000 | Loss: 0.00002282
Iteration 12/1000 | Loss: 0.00002260
Iteration 13/1000 | Loss: 0.00002240
Iteration 14/1000 | Loss: 0.00002239
Iteration 15/1000 | Loss: 0.00002224
Iteration 16/1000 | Loss: 0.00002223
Iteration 17/1000 | Loss: 0.00002218
Iteration 18/1000 | Loss: 0.00002217
Iteration 19/1000 | Loss: 0.00002216
Iteration 20/1000 | Loss: 0.00002207
Iteration 21/1000 | Loss: 0.00002204
Iteration 22/1000 | Loss: 0.00002204
Iteration 23/1000 | Loss: 0.00002200
Iteration 24/1000 | Loss: 0.00002198
Iteration 25/1000 | Loss: 0.00002197
Iteration 26/1000 | Loss: 0.00002196
Iteration 27/1000 | Loss: 0.00002196
Iteration 28/1000 | Loss: 0.00002193
Iteration 29/1000 | Loss: 0.00002193
Iteration 30/1000 | Loss: 0.00002191
Iteration 31/1000 | Loss: 0.00002191
Iteration 32/1000 | Loss: 0.00002190
Iteration 33/1000 | Loss: 0.00002190
Iteration 34/1000 | Loss: 0.00002190
Iteration 35/1000 | Loss: 0.00002187
Iteration 36/1000 | Loss: 0.00002187
Iteration 37/1000 | Loss: 0.00002187
Iteration 38/1000 | Loss: 0.00002186
Iteration 39/1000 | Loss: 0.00002186
Iteration 40/1000 | Loss: 0.00002186
Iteration 41/1000 | Loss: 0.00002186
Iteration 42/1000 | Loss: 0.00002186
Iteration 43/1000 | Loss: 0.00002186
Iteration 44/1000 | Loss: 0.00002186
Iteration 45/1000 | Loss: 0.00002186
Iteration 46/1000 | Loss: 0.00002186
Iteration 47/1000 | Loss: 0.00002186
Iteration 48/1000 | Loss: 0.00002186
Iteration 49/1000 | Loss: 0.00002185
Iteration 50/1000 | Loss: 0.00002185
Iteration 51/1000 | Loss: 0.00002185
Iteration 52/1000 | Loss: 0.00002185
Iteration 53/1000 | Loss: 0.00002185
Iteration 54/1000 | Loss: 0.00002185
Iteration 55/1000 | Loss: 0.00002185
Iteration 56/1000 | Loss: 0.00002185
Iteration 57/1000 | Loss: 0.00002185
Iteration 58/1000 | Loss: 0.00002184
Iteration 59/1000 | Loss: 0.00002183
Iteration 60/1000 | Loss: 0.00002183
Iteration 61/1000 | Loss: 0.00002183
Iteration 62/1000 | Loss: 0.00002182
Iteration 63/1000 | Loss: 0.00002182
Iteration 64/1000 | Loss: 0.00002182
Iteration 65/1000 | Loss: 0.00002182
Iteration 66/1000 | Loss: 0.00002182
Iteration 67/1000 | Loss: 0.00002182
Iteration 68/1000 | Loss: 0.00002181
Iteration 69/1000 | Loss: 0.00002181
Iteration 70/1000 | Loss: 0.00002181
Iteration 71/1000 | Loss: 0.00002181
Iteration 72/1000 | Loss: 0.00002181
Iteration 73/1000 | Loss: 0.00002181
Iteration 74/1000 | Loss: 0.00002181
Iteration 75/1000 | Loss: 0.00002181
Iteration 76/1000 | Loss: 0.00002181
Iteration 77/1000 | Loss: 0.00002181
Iteration 78/1000 | Loss: 0.00002181
Iteration 79/1000 | Loss: 0.00002181
Iteration 80/1000 | Loss: 0.00002181
Iteration 81/1000 | Loss: 0.00002181
Iteration 82/1000 | Loss: 0.00002181
Iteration 83/1000 | Loss: 0.00002181
Iteration 84/1000 | Loss: 0.00002181
Iteration 85/1000 | Loss: 0.00002181
Iteration 86/1000 | Loss: 0.00002181
Iteration 87/1000 | Loss: 0.00002181
Iteration 88/1000 | Loss: 0.00002181
Iteration 89/1000 | Loss: 0.00002181
Iteration 90/1000 | Loss: 0.00002181
Iteration 91/1000 | Loss: 0.00002181
Iteration 92/1000 | Loss: 0.00002181
Iteration 93/1000 | Loss: 0.00002181
Iteration 94/1000 | Loss: 0.00002181
Iteration 95/1000 | Loss: 0.00002181
Iteration 96/1000 | Loss: 0.00002181
Iteration 97/1000 | Loss: 0.00002181
Iteration 98/1000 | Loss: 0.00002181
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 98. Stopping optimization.
Last 5 losses: [2.18103396036895e-05, 2.18103396036895e-05, 2.18103396036895e-05, 2.18103396036895e-05, 2.18103396036895e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.18103396036895e-05

Optimization complete. Final v2v error: 3.8527345657348633 mm

Highest mean error: 5.1234259605407715 mm for frame 173

Lowest mean error: 2.930583953857422 mm for frame 124

Saving results

Total time: 42.40106701850891
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1082/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1082.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1082
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00797071
Iteration 2/25 | Loss: 0.00110707
Iteration 3/25 | Loss: 0.00088960
Iteration 4/25 | Loss: 0.00084488
Iteration 5/25 | Loss: 0.00082780
Iteration 6/25 | Loss: 0.00082490
Iteration 7/25 | Loss: 0.00082427
Iteration 8/25 | Loss: 0.00082427
Iteration 9/25 | Loss: 0.00082427
Iteration 10/25 | Loss: 0.00082427
Iteration 11/25 | Loss: 0.00082427
Iteration 12/25 | Loss: 0.00082427
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008242695475928485, 0.0008242695475928485, 0.0008242695475928485, 0.0008242695475928485, 0.0008242695475928485]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008242695475928485

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67011762
Iteration 2/25 | Loss: 0.00130949
Iteration 3/25 | Loss: 0.00130949
Iteration 4/25 | Loss: 0.00130949
Iteration 5/25 | Loss: 0.00130949
Iteration 6/25 | Loss: 0.00130949
Iteration 7/25 | Loss: 0.00130949
Iteration 8/25 | Loss: 0.00130949
Iteration 9/25 | Loss: 0.00130949
Iteration 10/25 | Loss: 0.00130949
Iteration 11/25 | Loss: 0.00130949
Iteration 12/25 | Loss: 0.00130949
Iteration 13/25 | Loss: 0.00130949
Iteration 14/25 | Loss: 0.00130949
Iteration 15/25 | Loss: 0.00130949
Iteration 16/25 | Loss: 0.00130949
Iteration 17/25 | Loss: 0.00130949
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0013094854075461626, 0.0013094854075461626, 0.0013094854075461626, 0.0013094854075461626, 0.0013094854075461626]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013094854075461626

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00130949
Iteration 2/1000 | Loss: 0.00004341
Iteration 3/1000 | Loss: 0.00003021
Iteration 4/1000 | Loss: 0.00002683
Iteration 5/1000 | Loss: 0.00002562
Iteration 6/1000 | Loss: 0.00002432
Iteration 7/1000 | Loss: 0.00002366
Iteration 8/1000 | Loss: 0.00002303
Iteration 9/1000 | Loss: 0.00002259
Iteration 10/1000 | Loss: 0.00002224
Iteration 11/1000 | Loss: 0.00002197
Iteration 12/1000 | Loss: 0.00002176
Iteration 13/1000 | Loss: 0.00002160
Iteration 14/1000 | Loss: 0.00002152
Iteration 15/1000 | Loss: 0.00002150
Iteration 16/1000 | Loss: 0.00002146
Iteration 17/1000 | Loss: 0.00002142
Iteration 18/1000 | Loss: 0.00002141
Iteration 19/1000 | Loss: 0.00002140
Iteration 20/1000 | Loss: 0.00002139
Iteration 21/1000 | Loss: 0.00002138
Iteration 22/1000 | Loss: 0.00002138
Iteration 23/1000 | Loss: 0.00002137
Iteration 24/1000 | Loss: 0.00002137
Iteration 25/1000 | Loss: 0.00002136
Iteration 26/1000 | Loss: 0.00002136
Iteration 27/1000 | Loss: 0.00002136
Iteration 28/1000 | Loss: 0.00002135
Iteration 29/1000 | Loss: 0.00002135
Iteration 30/1000 | Loss: 0.00002135
Iteration 31/1000 | Loss: 0.00002134
Iteration 32/1000 | Loss: 0.00002134
Iteration 33/1000 | Loss: 0.00002134
Iteration 34/1000 | Loss: 0.00002133
Iteration 35/1000 | Loss: 0.00002133
Iteration 36/1000 | Loss: 0.00002133
Iteration 37/1000 | Loss: 0.00002133
Iteration 38/1000 | Loss: 0.00002132
Iteration 39/1000 | Loss: 0.00002132
Iteration 40/1000 | Loss: 0.00002132
Iteration 41/1000 | Loss: 0.00002132
Iteration 42/1000 | Loss: 0.00002132
Iteration 43/1000 | Loss: 0.00002132
Iteration 44/1000 | Loss: 0.00002132
Iteration 45/1000 | Loss: 0.00002132
Iteration 46/1000 | Loss: 0.00002132
Iteration 47/1000 | Loss: 0.00002132
Iteration 48/1000 | Loss: 0.00002132
Iteration 49/1000 | Loss: 0.00002131
Iteration 50/1000 | Loss: 0.00002131
Iteration 51/1000 | Loss: 0.00002131
Iteration 52/1000 | Loss: 0.00002131
Iteration 53/1000 | Loss: 0.00002131
Iteration 54/1000 | Loss: 0.00002131
Iteration 55/1000 | Loss: 0.00002131
Iteration 56/1000 | Loss: 0.00002130
Iteration 57/1000 | Loss: 0.00002130
Iteration 58/1000 | Loss: 0.00002130
Iteration 59/1000 | Loss: 0.00002130
Iteration 60/1000 | Loss: 0.00002130
Iteration 61/1000 | Loss: 0.00002130
Iteration 62/1000 | Loss: 0.00002130
Iteration 63/1000 | Loss: 0.00002130
Iteration 64/1000 | Loss: 0.00002130
Iteration 65/1000 | Loss: 0.00002129
Iteration 66/1000 | Loss: 0.00002129
Iteration 67/1000 | Loss: 0.00002129
Iteration 68/1000 | Loss: 0.00002129
Iteration 69/1000 | Loss: 0.00002129
Iteration 70/1000 | Loss: 0.00002129
Iteration 71/1000 | Loss: 0.00002129
Iteration 72/1000 | Loss: 0.00002129
Iteration 73/1000 | Loss: 0.00002129
Iteration 74/1000 | Loss: 0.00002129
Iteration 75/1000 | Loss: 0.00002129
Iteration 76/1000 | Loss: 0.00002129
Iteration 77/1000 | Loss: 0.00002128
Iteration 78/1000 | Loss: 0.00002128
Iteration 79/1000 | Loss: 0.00002128
Iteration 80/1000 | Loss: 0.00002128
Iteration 81/1000 | Loss: 0.00002128
Iteration 82/1000 | Loss: 0.00002128
Iteration 83/1000 | Loss: 0.00002128
Iteration 84/1000 | Loss: 0.00002128
Iteration 85/1000 | Loss: 0.00002128
Iteration 86/1000 | Loss: 0.00002128
Iteration 87/1000 | Loss: 0.00002128
Iteration 88/1000 | Loss: 0.00002128
Iteration 89/1000 | Loss: 0.00002128
Iteration 90/1000 | Loss: 0.00002127
Iteration 91/1000 | Loss: 0.00002127
Iteration 92/1000 | Loss: 0.00002127
Iteration 93/1000 | Loss: 0.00002127
Iteration 94/1000 | Loss: 0.00002127
Iteration 95/1000 | Loss: 0.00002127
Iteration 96/1000 | Loss: 0.00002127
Iteration 97/1000 | Loss: 0.00002127
Iteration 98/1000 | Loss: 0.00002127
Iteration 99/1000 | Loss: 0.00002127
Iteration 100/1000 | Loss: 0.00002127
Iteration 101/1000 | Loss: 0.00002127
Iteration 102/1000 | Loss: 0.00002126
Iteration 103/1000 | Loss: 0.00002126
Iteration 104/1000 | Loss: 0.00002126
Iteration 105/1000 | Loss: 0.00002126
Iteration 106/1000 | Loss: 0.00002126
Iteration 107/1000 | Loss: 0.00002126
Iteration 108/1000 | Loss: 0.00002126
Iteration 109/1000 | Loss: 0.00002126
Iteration 110/1000 | Loss: 0.00002126
Iteration 111/1000 | Loss: 0.00002126
Iteration 112/1000 | Loss: 0.00002126
Iteration 113/1000 | Loss: 0.00002126
Iteration 114/1000 | Loss: 0.00002126
Iteration 115/1000 | Loss: 0.00002125
Iteration 116/1000 | Loss: 0.00002125
Iteration 117/1000 | Loss: 0.00002125
Iteration 118/1000 | Loss: 0.00002125
Iteration 119/1000 | Loss: 0.00002125
Iteration 120/1000 | Loss: 0.00002125
Iteration 121/1000 | Loss: 0.00002125
Iteration 122/1000 | Loss: 0.00002125
Iteration 123/1000 | Loss: 0.00002125
Iteration 124/1000 | Loss: 0.00002125
Iteration 125/1000 | Loss: 0.00002124
Iteration 126/1000 | Loss: 0.00002124
Iteration 127/1000 | Loss: 0.00002124
Iteration 128/1000 | Loss: 0.00002124
Iteration 129/1000 | Loss: 0.00002124
Iteration 130/1000 | Loss: 0.00002124
Iteration 131/1000 | Loss: 0.00002124
Iteration 132/1000 | Loss: 0.00002124
Iteration 133/1000 | Loss: 0.00002124
Iteration 134/1000 | Loss: 0.00002124
Iteration 135/1000 | Loss: 0.00002124
Iteration 136/1000 | Loss: 0.00002124
Iteration 137/1000 | Loss: 0.00002124
Iteration 138/1000 | Loss: 0.00002124
Iteration 139/1000 | Loss: 0.00002124
Iteration 140/1000 | Loss: 0.00002123
Iteration 141/1000 | Loss: 0.00002123
Iteration 142/1000 | Loss: 0.00002123
Iteration 143/1000 | Loss: 0.00002123
Iteration 144/1000 | Loss: 0.00002123
Iteration 145/1000 | Loss: 0.00002123
Iteration 146/1000 | Loss: 0.00002123
Iteration 147/1000 | Loss: 0.00002123
Iteration 148/1000 | Loss: 0.00002123
Iteration 149/1000 | Loss: 0.00002123
Iteration 150/1000 | Loss: 0.00002123
Iteration 151/1000 | Loss: 0.00002123
Iteration 152/1000 | Loss: 0.00002123
Iteration 153/1000 | Loss: 0.00002122
Iteration 154/1000 | Loss: 0.00002122
Iteration 155/1000 | Loss: 0.00002122
Iteration 156/1000 | Loss: 0.00002122
Iteration 157/1000 | Loss: 0.00002122
Iteration 158/1000 | Loss: 0.00002122
Iteration 159/1000 | Loss: 0.00002122
Iteration 160/1000 | Loss: 0.00002122
Iteration 161/1000 | Loss: 0.00002122
Iteration 162/1000 | Loss: 0.00002122
Iteration 163/1000 | Loss: 0.00002122
Iteration 164/1000 | Loss: 0.00002122
Iteration 165/1000 | Loss: 0.00002121
Iteration 166/1000 | Loss: 0.00002121
Iteration 167/1000 | Loss: 0.00002121
Iteration 168/1000 | Loss: 0.00002121
Iteration 169/1000 | Loss: 0.00002121
Iteration 170/1000 | Loss: 0.00002121
Iteration 171/1000 | Loss: 0.00002121
Iteration 172/1000 | Loss: 0.00002121
Iteration 173/1000 | Loss: 0.00002121
Iteration 174/1000 | Loss: 0.00002121
Iteration 175/1000 | Loss: 0.00002121
Iteration 176/1000 | Loss: 0.00002121
Iteration 177/1000 | Loss: 0.00002121
Iteration 178/1000 | Loss: 0.00002121
Iteration 179/1000 | Loss: 0.00002121
Iteration 180/1000 | Loss: 0.00002121
Iteration 181/1000 | Loss: 0.00002121
Iteration 182/1000 | Loss: 0.00002121
Iteration 183/1000 | Loss: 0.00002121
Iteration 184/1000 | Loss: 0.00002121
Iteration 185/1000 | Loss: 0.00002121
Iteration 186/1000 | Loss: 0.00002121
Iteration 187/1000 | Loss: 0.00002121
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 187. Stopping optimization.
Last 5 losses: [2.1212057617958635e-05, 2.1212057617958635e-05, 2.1212057617958635e-05, 2.1212057617958635e-05, 2.1212057617958635e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1212057617958635e-05

Optimization complete. Final v2v error: 3.7870914936065674 mm

Highest mean error: 4.277033805847168 mm for frame 24

Lowest mean error: 3.053640365600586 mm for frame 172

Saving results

Total time: 45.3720543384552
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1067/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1067.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1067
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00401885
Iteration 2/25 | Loss: 0.00098422
Iteration 3/25 | Loss: 0.00078799
Iteration 4/25 | Loss: 0.00075403
Iteration 5/25 | Loss: 0.00074328
Iteration 6/25 | Loss: 0.00073980
Iteration 7/25 | Loss: 0.00073873
Iteration 8/25 | Loss: 0.00073872
Iteration 9/25 | Loss: 0.00073872
Iteration 10/25 | Loss: 0.00073872
Iteration 11/25 | Loss: 0.00073872
Iteration 12/25 | Loss: 0.00073872
Iteration 13/25 | Loss: 0.00073872
Iteration 14/25 | Loss: 0.00073872
Iteration 15/25 | Loss: 0.00073872
Iteration 16/25 | Loss: 0.00073872
Iteration 17/25 | Loss: 0.00073872
Iteration 18/25 | Loss: 0.00073872
Iteration 19/25 | Loss: 0.00073872
Iteration 20/25 | Loss: 0.00073872
Iteration 21/25 | Loss: 0.00073872
Iteration 22/25 | Loss: 0.00073872
Iteration 23/25 | Loss: 0.00073872
Iteration 24/25 | Loss: 0.00073872
Iteration 25/25 | Loss: 0.00073872

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45316160
Iteration 2/25 | Loss: 0.00112811
Iteration 3/25 | Loss: 0.00112808
Iteration 4/25 | Loss: 0.00112808
Iteration 5/25 | Loss: 0.00112808
Iteration 6/25 | Loss: 0.00112808
Iteration 7/25 | Loss: 0.00112808
Iteration 8/25 | Loss: 0.00112808
Iteration 9/25 | Loss: 0.00112808
Iteration 10/25 | Loss: 0.00112808
Iteration 11/25 | Loss: 0.00112808
Iteration 12/25 | Loss: 0.00112808
Iteration 13/25 | Loss: 0.00112808
Iteration 14/25 | Loss: 0.00112808
Iteration 15/25 | Loss: 0.00112808
Iteration 16/25 | Loss: 0.00112808
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011280804174020886, 0.0011280804174020886, 0.0011280804174020886, 0.0011280804174020886, 0.0011280804174020886]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011280804174020886

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112808
Iteration 2/1000 | Loss: 0.00003586
Iteration 3/1000 | Loss: 0.00002483
Iteration 4/1000 | Loss: 0.00001890
Iteration 5/1000 | Loss: 0.00001722
Iteration 6/1000 | Loss: 0.00001649
Iteration 7/1000 | Loss: 0.00001574
Iteration 8/1000 | Loss: 0.00001540
Iteration 9/1000 | Loss: 0.00001504
Iteration 10/1000 | Loss: 0.00001480
Iteration 11/1000 | Loss: 0.00001476
Iteration 12/1000 | Loss: 0.00001470
Iteration 13/1000 | Loss: 0.00001462
Iteration 14/1000 | Loss: 0.00001461
Iteration 15/1000 | Loss: 0.00001460
Iteration 16/1000 | Loss: 0.00001460
Iteration 17/1000 | Loss: 0.00001459
Iteration 18/1000 | Loss: 0.00001456
Iteration 19/1000 | Loss: 0.00001455
Iteration 20/1000 | Loss: 0.00001452
Iteration 21/1000 | Loss: 0.00001452
Iteration 22/1000 | Loss: 0.00001451
Iteration 23/1000 | Loss: 0.00001451
Iteration 24/1000 | Loss: 0.00001448
Iteration 25/1000 | Loss: 0.00001447
Iteration 26/1000 | Loss: 0.00001447
Iteration 27/1000 | Loss: 0.00001446
Iteration 28/1000 | Loss: 0.00001446
Iteration 29/1000 | Loss: 0.00001445
Iteration 30/1000 | Loss: 0.00001442
Iteration 31/1000 | Loss: 0.00001441
Iteration 32/1000 | Loss: 0.00001439
Iteration 33/1000 | Loss: 0.00001439
Iteration 34/1000 | Loss: 0.00001438
Iteration 35/1000 | Loss: 0.00001438
Iteration 36/1000 | Loss: 0.00001437
Iteration 37/1000 | Loss: 0.00001437
Iteration 38/1000 | Loss: 0.00001436
Iteration 39/1000 | Loss: 0.00001436
Iteration 40/1000 | Loss: 0.00001436
Iteration 41/1000 | Loss: 0.00001435
Iteration 42/1000 | Loss: 0.00001435
Iteration 43/1000 | Loss: 0.00001434
Iteration 44/1000 | Loss: 0.00001434
Iteration 45/1000 | Loss: 0.00001433
Iteration 46/1000 | Loss: 0.00001433
Iteration 47/1000 | Loss: 0.00001433
Iteration 48/1000 | Loss: 0.00001433
Iteration 49/1000 | Loss: 0.00001432
Iteration 50/1000 | Loss: 0.00001432
Iteration 51/1000 | Loss: 0.00001432
Iteration 52/1000 | Loss: 0.00001431
Iteration 53/1000 | Loss: 0.00001431
Iteration 54/1000 | Loss: 0.00001431
Iteration 55/1000 | Loss: 0.00001431
Iteration 56/1000 | Loss: 0.00001430
Iteration 57/1000 | Loss: 0.00001430
Iteration 58/1000 | Loss: 0.00001429
Iteration 59/1000 | Loss: 0.00001429
Iteration 60/1000 | Loss: 0.00001429
Iteration 61/1000 | Loss: 0.00001429
Iteration 62/1000 | Loss: 0.00001428
Iteration 63/1000 | Loss: 0.00001428
Iteration 64/1000 | Loss: 0.00001428
Iteration 65/1000 | Loss: 0.00001428
Iteration 66/1000 | Loss: 0.00001428
Iteration 67/1000 | Loss: 0.00001427
Iteration 68/1000 | Loss: 0.00001427
Iteration 69/1000 | Loss: 0.00001425
Iteration 70/1000 | Loss: 0.00001425
Iteration 71/1000 | Loss: 0.00001424
Iteration 72/1000 | Loss: 0.00001424
Iteration 73/1000 | Loss: 0.00001424
Iteration 74/1000 | Loss: 0.00001424
Iteration 75/1000 | Loss: 0.00001423
Iteration 76/1000 | Loss: 0.00001423
Iteration 77/1000 | Loss: 0.00001423
Iteration 78/1000 | Loss: 0.00001423
Iteration 79/1000 | Loss: 0.00001422
Iteration 80/1000 | Loss: 0.00001422
Iteration 81/1000 | Loss: 0.00001422
Iteration 82/1000 | Loss: 0.00001422
Iteration 83/1000 | Loss: 0.00001422
Iteration 84/1000 | Loss: 0.00001422
Iteration 85/1000 | Loss: 0.00001422
Iteration 86/1000 | Loss: 0.00001422
Iteration 87/1000 | Loss: 0.00001422
Iteration 88/1000 | Loss: 0.00001421
Iteration 89/1000 | Loss: 0.00001421
Iteration 90/1000 | Loss: 0.00001421
Iteration 91/1000 | Loss: 0.00001421
Iteration 92/1000 | Loss: 0.00001421
Iteration 93/1000 | Loss: 0.00001421
Iteration 94/1000 | Loss: 0.00001421
Iteration 95/1000 | Loss: 0.00001421
Iteration 96/1000 | Loss: 0.00001421
Iteration 97/1000 | Loss: 0.00001420
Iteration 98/1000 | Loss: 0.00001420
Iteration 99/1000 | Loss: 0.00001420
Iteration 100/1000 | Loss: 0.00001420
Iteration 101/1000 | Loss: 0.00001420
Iteration 102/1000 | Loss: 0.00001420
Iteration 103/1000 | Loss: 0.00001420
Iteration 104/1000 | Loss: 0.00001420
Iteration 105/1000 | Loss: 0.00001419
Iteration 106/1000 | Loss: 0.00001419
Iteration 107/1000 | Loss: 0.00001419
Iteration 108/1000 | Loss: 0.00001419
Iteration 109/1000 | Loss: 0.00001418
Iteration 110/1000 | Loss: 0.00001418
Iteration 111/1000 | Loss: 0.00001418
Iteration 112/1000 | Loss: 0.00001418
Iteration 113/1000 | Loss: 0.00001418
Iteration 114/1000 | Loss: 0.00001418
Iteration 115/1000 | Loss: 0.00001418
Iteration 116/1000 | Loss: 0.00001417
Iteration 117/1000 | Loss: 0.00001417
Iteration 118/1000 | Loss: 0.00001417
Iteration 119/1000 | Loss: 0.00001417
Iteration 120/1000 | Loss: 0.00001417
Iteration 121/1000 | Loss: 0.00001417
Iteration 122/1000 | Loss: 0.00001417
Iteration 123/1000 | Loss: 0.00001417
Iteration 124/1000 | Loss: 0.00001417
Iteration 125/1000 | Loss: 0.00001417
Iteration 126/1000 | Loss: 0.00001416
Iteration 127/1000 | Loss: 0.00001416
Iteration 128/1000 | Loss: 0.00001415
Iteration 129/1000 | Loss: 0.00001415
Iteration 130/1000 | Loss: 0.00001415
Iteration 131/1000 | Loss: 0.00001415
Iteration 132/1000 | Loss: 0.00001415
Iteration 133/1000 | Loss: 0.00001415
Iteration 134/1000 | Loss: 0.00001415
Iteration 135/1000 | Loss: 0.00001415
Iteration 136/1000 | Loss: 0.00001414
Iteration 137/1000 | Loss: 0.00001414
Iteration 138/1000 | Loss: 0.00001414
Iteration 139/1000 | Loss: 0.00001414
Iteration 140/1000 | Loss: 0.00001414
Iteration 141/1000 | Loss: 0.00001414
Iteration 142/1000 | Loss: 0.00001414
Iteration 143/1000 | Loss: 0.00001414
Iteration 144/1000 | Loss: 0.00001414
Iteration 145/1000 | Loss: 0.00001414
Iteration 146/1000 | Loss: 0.00001414
Iteration 147/1000 | Loss: 0.00001414
Iteration 148/1000 | Loss: 0.00001414
Iteration 149/1000 | Loss: 0.00001414
Iteration 150/1000 | Loss: 0.00001414
Iteration 151/1000 | Loss: 0.00001413
Iteration 152/1000 | Loss: 0.00001413
Iteration 153/1000 | Loss: 0.00001413
Iteration 154/1000 | Loss: 0.00001413
Iteration 155/1000 | Loss: 0.00001413
Iteration 156/1000 | Loss: 0.00001413
Iteration 157/1000 | Loss: 0.00001413
Iteration 158/1000 | Loss: 0.00001413
Iteration 159/1000 | Loss: 0.00001413
Iteration 160/1000 | Loss: 0.00001413
Iteration 161/1000 | Loss: 0.00001413
Iteration 162/1000 | Loss: 0.00001413
Iteration 163/1000 | Loss: 0.00001413
Iteration 164/1000 | Loss: 0.00001413
Iteration 165/1000 | Loss: 0.00001413
Iteration 166/1000 | Loss: 0.00001413
Iteration 167/1000 | Loss: 0.00001413
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 167. Stopping optimization.
Last 5 losses: [1.4130680938251317e-05, 1.4130680938251317e-05, 1.4130680938251317e-05, 1.4130680938251317e-05, 1.4130680938251317e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4130680938251317e-05

Optimization complete. Final v2v error: 3.010507345199585 mm

Highest mean error: 5.157793045043945 mm for frame 89

Lowest mean error: 2.38421630859375 mm for frame 126

Saving results

Total time: 40.56575536727905
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1057
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00422575
Iteration 2/25 | Loss: 0.00109512
Iteration 3/25 | Loss: 0.00089216
Iteration 4/25 | Loss: 0.00085980
Iteration 5/25 | Loss: 0.00084678
Iteration 6/25 | Loss: 0.00084460
Iteration 7/25 | Loss: 0.00084376
Iteration 8/25 | Loss: 0.00084361
Iteration 9/25 | Loss: 0.00084361
Iteration 10/25 | Loss: 0.00084361
Iteration 11/25 | Loss: 0.00084361
Iteration 12/25 | Loss: 0.00084361
Iteration 13/25 | Loss: 0.00084361
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008436071802861989, 0.0008436071802861989, 0.0008436071802861989, 0.0008436071802861989, 0.0008436071802861989]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008436071802861989

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.07399654
Iteration 2/25 | Loss: 0.00131162
Iteration 3/25 | Loss: 0.00131160
Iteration 4/25 | Loss: 0.00131159
Iteration 5/25 | Loss: 0.00131159
Iteration 6/25 | Loss: 0.00131159
Iteration 7/25 | Loss: 0.00131159
Iteration 8/25 | Loss: 0.00131159
Iteration 9/25 | Loss: 0.00131159
Iteration 10/25 | Loss: 0.00131159
Iteration 11/25 | Loss: 0.00131159
Iteration 12/25 | Loss: 0.00131159
Iteration 13/25 | Loss: 0.00131159
Iteration 14/25 | Loss: 0.00131159
Iteration 15/25 | Loss: 0.00131159
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013115914771333337, 0.0013115914771333337, 0.0013115914771333337, 0.0013115914771333337, 0.0013115914771333337]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013115914771333337

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00131159
Iteration 2/1000 | Loss: 0.00004430
Iteration 3/1000 | Loss: 0.00002868
Iteration 4/1000 | Loss: 0.00002683
Iteration 5/1000 | Loss: 0.00002564
Iteration 6/1000 | Loss: 0.00002490
Iteration 7/1000 | Loss: 0.00002423
Iteration 8/1000 | Loss: 0.00002388
Iteration 9/1000 | Loss: 0.00002359
Iteration 10/1000 | Loss: 0.00002340
Iteration 11/1000 | Loss: 0.00002323
Iteration 12/1000 | Loss: 0.00002320
Iteration 13/1000 | Loss: 0.00002316
Iteration 14/1000 | Loss: 0.00002316
Iteration 15/1000 | Loss: 0.00002315
Iteration 16/1000 | Loss: 0.00002315
Iteration 17/1000 | Loss: 0.00002312
Iteration 18/1000 | Loss: 0.00002312
Iteration 19/1000 | Loss: 0.00002312
Iteration 20/1000 | Loss: 0.00002312
Iteration 21/1000 | Loss: 0.00002311
Iteration 22/1000 | Loss: 0.00002311
Iteration 23/1000 | Loss: 0.00002311
Iteration 24/1000 | Loss: 0.00002310
Iteration 25/1000 | Loss: 0.00002309
Iteration 26/1000 | Loss: 0.00002309
Iteration 27/1000 | Loss: 0.00002309
Iteration 28/1000 | Loss: 0.00002308
Iteration 29/1000 | Loss: 0.00002308
Iteration 30/1000 | Loss: 0.00002307
Iteration 31/1000 | Loss: 0.00002307
Iteration 32/1000 | Loss: 0.00002307
Iteration 33/1000 | Loss: 0.00002306
Iteration 34/1000 | Loss: 0.00002306
Iteration 35/1000 | Loss: 0.00002305
Iteration 36/1000 | Loss: 0.00002305
Iteration 37/1000 | Loss: 0.00002304
Iteration 38/1000 | Loss: 0.00002304
Iteration 39/1000 | Loss: 0.00002303
Iteration 40/1000 | Loss: 0.00002303
Iteration 41/1000 | Loss: 0.00002303
Iteration 42/1000 | Loss: 0.00002302
Iteration 43/1000 | Loss: 0.00002302
Iteration 44/1000 | Loss: 0.00002302
Iteration 45/1000 | Loss: 0.00002302
Iteration 46/1000 | Loss: 0.00002302
Iteration 47/1000 | Loss: 0.00002301
Iteration 48/1000 | Loss: 0.00002301
Iteration 49/1000 | Loss: 0.00002301
Iteration 50/1000 | Loss: 0.00002300
Iteration 51/1000 | Loss: 0.00002300
Iteration 52/1000 | Loss: 0.00002300
Iteration 53/1000 | Loss: 0.00002299
Iteration 54/1000 | Loss: 0.00002299
Iteration 55/1000 | Loss: 0.00002299
Iteration 56/1000 | Loss: 0.00002299
Iteration 57/1000 | Loss: 0.00002298
Iteration 58/1000 | Loss: 0.00002298
Iteration 59/1000 | Loss: 0.00002297
Iteration 60/1000 | Loss: 0.00002297
Iteration 61/1000 | Loss: 0.00002297
Iteration 62/1000 | Loss: 0.00002297
Iteration 63/1000 | Loss: 0.00002296
Iteration 64/1000 | Loss: 0.00002295
Iteration 65/1000 | Loss: 0.00002294
Iteration 66/1000 | Loss: 0.00002294
Iteration 67/1000 | Loss: 0.00002293
Iteration 68/1000 | Loss: 0.00002293
Iteration 69/1000 | Loss: 0.00002293
Iteration 70/1000 | Loss: 0.00002292
Iteration 71/1000 | Loss: 0.00002292
Iteration 72/1000 | Loss: 0.00002292
Iteration 73/1000 | Loss: 0.00002291
Iteration 74/1000 | Loss: 0.00002291
Iteration 75/1000 | Loss: 0.00002291
Iteration 76/1000 | Loss: 0.00002290
Iteration 77/1000 | Loss: 0.00002290
Iteration 78/1000 | Loss: 0.00002290
Iteration 79/1000 | Loss: 0.00002290
Iteration 80/1000 | Loss: 0.00002290
Iteration 81/1000 | Loss: 0.00002290
Iteration 82/1000 | Loss: 0.00002290
Iteration 83/1000 | Loss: 0.00002289
Iteration 84/1000 | Loss: 0.00002289
Iteration 85/1000 | Loss: 0.00002289
Iteration 86/1000 | Loss: 0.00002289
Iteration 87/1000 | Loss: 0.00002289
Iteration 88/1000 | Loss: 0.00002289
Iteration 89/1000 | Loss: 0.00002289
Iteration 90/1000 | Loss: 0.00002289
Iteration 91/1000 | Loss: 0.00002288
Iteration 92/1000 | Loss: 0.00002288
Iteration 93/1000 | Loss: 0.00002288
Iteration 94/1000 | Loss: 0.00002288
Iteration 95/1000 | Loss: 0.00002288
Iteration 96/1000 | Loss: 0.00002288
Iteration 97/1000 | Loss: 0.00002288
Iteration 98/1000 | Loss: 0.00002288
Iteration 99/1000 | Loss: 0.00002288
Iteration 100/1000 | Loss: 0.00002288
Iteration 101/1000 | Loss: 0.00002287
Iteration 102/1000 | Loss: 0.00002287
Iteration 103/1000 | Loss: 0.00002287
Iteration 104/1000 | Loss: 0.00002287
Iteration 105/1000 | Loss: 0.00002287
Iteration 106/1000 | Loss: 0.00002287
Iteration 107/1000 | Loss: 0.00002287
Iteration 108/1000 | Loss: 0.00002287
Iteration 109/1000 | Loss: 0.00002287
Iteration 110/1000 | Loss: 0.00002287
Iteration 111/1000 | Loss: 0.00002286
Iteration 112/1000 | Loss: 0.00002286
Iteration 113/1000 | Loss: 0.00002286
Iteration 114/1000 | Loss: 0.00002286
Iteration 115/1000 | Loss: 0.00002286
Iteration 116/1000 | Loss: 0.00002286
Iteration 117/1000 | Loss: 0.00002286
Iteration 118/1000 | Loss: 0.00002286
Iteration 119/1000 | Loss: 0.00002286
Iteration 120/1000 | Loss: 0.00002286
Iteration 121/1000 | Loss: 0.00002286
Iteration 122/1000 | Loss: 0.00002286
Iteration 123/1000 | Loss: 0.00002285
Iteration 124/1000 | Loss: 0.00002285
Iteration 125/1000 | Loss: 0.00002285
Iteration 126/1000 | Loss: 0.00002285
Iteration 127/1000 | Loss: 0.00002285
Iteration 128/1000 | Loss: 0.00002285
Iteration 129/1000 | Loss: 0.00002285
Iteration 130/1000 | Loss: 0.00002285
Iteration 131/1000 | Loss: 0.00002285
Iteration 132/1000 | Loss: 0.00002285
Iteration 133/1000 | Loss: 0.00002285
Iteration 134/1000 | Loss: 0.00002285
Iteration 135/1000 | Loss: 0.00002285
Iteration 136/1000 | Loss: 0.00002285
Iteration 137/1000 | Loss: 0.00002285
Iteration 138/1000 | Loss: 0.00002285
Iteration 139/1000 | Loss: 0.00002284
Iteration 140/1000 | Loss: 0.00002284
Iteration 141/1000 | Loss: 0.00002284
Iteration 142/1000 | Loss: 0.00002284
Iteration 143/1000 | Loss: 0.00002284
Iteration 144/1000 | Loss: 0.00002284
Iteration 145/1000 | Loss: 0.00002284
Iteration 146/1000 | Loss: 0.00002284
Iteration 147/1000 | Loss: 0.00002284
Iteration 148/1000 | Loss: 0.00002284
Iteration 149/1000 | Loss: 0.00002284
Iteration 150/1000 | Loss: 0.00002284
Iteration 151/1000 | Loss: 0.00002284
Iteration 152/1000 | Loss: 0.00002283
Iteration 153/1000 | Loss: 0.00002283
Iteration 154/1000 | Loss: 0.00002283
Iteration 155/1000 | Loss: 0.00002283
Iteration 156/1000 | Loss: 0.00002283
Iteration 157/1000 | Loss: 0.00002283
Iteration 158/1000 | Loss: 0.00002283
Iteration 159/1000 | Loss: 0.00002283
Iteration 160/1000 | Loss: 0.00002283
Iteration 161/1000 | Loss: 0.00002283
Iteration 162/1000 | Loss: 0.00002283
Iteration 163/1000 | Loss: 0.00002283
Iteration 164/1000 | Loss: 0.00002282
Iteration 165/1000 | Loss: 0.00002282
Iteration 166/1000 | Loss: 0.00002282
Iteration 167/1000 | Loss: 0.00002282
Iteration 168/1000 | Loss: 0.00002282
Iteration 169/1000 | Loss: 0.00002282
Iteration 170/1000 | Loss: 0.00002282
Iteration 171/1000 | Loss: 0.00002282
Iteration 172/1000 | Loss: 0.00002282
Iteration 173/1000 | Loss: 0.00002282
Iteration 174/1000 | Loss: 0.00002282
Iteration 175/1000 | Loss: 0.00002282
Iteration 176/1000 | Loss: 0.00002281
Iteration 177/1000 | Loss: 0.00002281
Iteration 178/1000 | Loss: 0.00002281
Iteration 179/1000 | Loss: 0.00002281
Iteration 180/1000 | Loss: 0.00002281
Iteration 181/1000 | Loss: 0.00002281
Iteration 182/1000 | Loss: 0.00002281
Iteration 183/1000 | Loss: 0.00002280
Iteration 184/1000 | Loss: 0.00002280
Iteration 185/1000 | Loss: 0.00002280
Iteration 186/1000 | Loss: 0.00002280
Iteration 187/1000 | Loss: 0.00002279
Iteration 188/1000 | Loss: 0.00002279
Iteration 189/1000 | Loss: 0.00002279
Iteration 190/1000 | Loss: 0.00002279
Iteration 191/1000 | Loss: 0.00002279
Iteration 192/1000 | Loss: 0.00002279
Iteration 193/1000 | Loss: 0.00002279
Iteration 194/1000 | Loss: 0.00002279
Iteration 195/1000 | Loss: 0.00002279
Iteration 196/1000 | Loss: 0.00002279
Iteration 197/1000 | Loss: 0.00002279
Iteration 198/1000 | Loss: 0.00002279
Iteration 199/1000 | Loss: 0.00002279
Iteration 200/1000 | Loss: 0.00002278
Iteration 201/1000 | Loss: 0.00002278
Iteration 202/1000 | Loss: 0.00002278
Iteration 203/1000 | Loss: 0.00002278
Iteration 204/1000 | Loss: 0.00002278
Iteration 205/1000 | Loss: 0.00002278
Iteration 206/1000 | Loss: 0.00002278
Iteration 207/1000 | Loss: 0.00002278
Iteration 208/1000 | Loss: 0.00002278
Iteration 209/1000 | Loss: 0.00002278
Iteration 210/1000 | Loss: 0.00002278
Iteration 211/1000 | Loss: 0.00002278
Iteration 212/1000 | Loss: 0.00002278
Iteration 213/1000 | Loss: 0.00002278
Iteration 214/1000 | Loss: 0.00002278
Iteration 215/1000 | Loss: 0.00002278
Iteration 216/1000 | Loss: 0.00002278
Iteration 217/1000 | Loss: 0.00002278
Iteration 218/1000 | Loss: 0.00002278
Iteration 219/1000 | Loss: 0.00002278
Iteration 220/1000 | Loss: 0.00002278
Iteration 221/1000 | Loss: 0.00002278
Iteration 222/1000 | Loss: 0.00002278
Iteration 223/1000 | Loss: 0.00002278
Iteration 224/1000 | Loss: 0.00002278
Iteration 225/1000 | Loss: 0.00002278
Iteration 226/1000 | Loss: 0.00002278
Iteration 227/1000 | Loss: 0.00002278
Iteration 228/1000 | Loss: 0.00002278
Iteration 229/1000 | Loss: 0.00002278
Iteration 230/1000 | Loss: 0.00002278
Iteration 231/1000 | Loss: 0.00002278
Iteration 232/1000 | Loss: 0.00002278
Iteration 233/1000 | Loss: 0.00002278
Iteration 234/1000 | Loss: 0.00002278
Iteration 235/1000 | Loss: 0.00002278
Iteration 236/1000 | Loss: 0.00002278
Iteration 237/1000 | Loss: 0.00002278
Iteration 238/1000 | Loss: 0.00002278
Iteration 239/1000 | Loss: 0.00002278
Iteration 240/1000 | Loss: 0.00002278
Iteration 241/1000 | Loss: 0.00002278
Iteration 242/1000 | Loss: 0.00002278
Iteration 243/1000 | Loss: 0.00002278
Iteration 244/1000 | Loss: 0.00002278
Iteration 245/1000 | Loss: 0.00002278
Iteration 246/1000 | Loss: 0.00002278
Iteration 247/1000 | Loss: 0.00002278
Iteration 248/1000 | Loss: 0.00002278
Iteration 249/1000 | Loss: 0.00002278
Iteration 250/1000 | Loss: 0.00002278
Iteration 251/1000 | Loss: 0.00002278
Iteration 252/1000 | Loss: 0.00002278
Iteration 253/1000 | Loss: 0.00002278
Iteration 254/1000 | Loss: 0.00002278
Iteration 255/1000 | Loss: 0.00002278
Iteration 256/1000 | Loss: 0.00002278
Iteration 257/1000 | Loss: 0.00002278
Iteration 258/1000 | Loss: 0.00002278
Iteration 259/1000 | Loss: 0.00002278
Iteration 260/1000 | Loss: 0.00002278
Iteration 261/1000 | Loss: 0.00002278
Iteration 262/1000 | Loss: 0.00002278
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 262. Stopping optimization.
Last 5 losses: [2.2776770492782816e-05, 2.2776770492782816e-05, 2.2776770492782816e-05, 2.2776770492782816e-05, 2.2776770492782816e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2776770492782816e-05

Optimization complete. Final v2v error: 3.9777169227600098 mm

Highest mean error: 4.552985191345215 mm for frame 49

Lowest mean error: 3.591407537460327 mm for frame 56

Saving results

Total time: 42.561755657196045
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1025
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01060333
Iteration 2/25 | Loss: 0.00205587
Iteration 3/25 | Loss: 0.00178205
Iteration 4/25 | Loss: 0.00171238
Iteration 5/25 | Loss: 0.00159216
Iteration 6/25 | Loss: 0.00133744
Iteration 7/25 | Loss: 0.00119717
Iteration 8/25 | Loss: 0.00105804
Iteration 9/25 | Loss: 0.00095707
Iteration 10/25 | Loss: 0.00093503
Iteration 11/25 | Loss: 0.00093289
Iteration 12/25 | Loss: 0.00093226
Iteration 13/25 | Loss: 0.00093225
Iteration 14/25 | Loss: 0.00093225
Iteration 15/25 | Loss: 0.00093225
Iteration 16/25 | Loss: 0.00093225
Iteration 17/25 | Loss: 0.00093225
Iteration 18/25 | Loss: 0.00093225
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009322473197244108, 0.0009322473197244108, 0.0009322473197244108, 0.0009322473197244108, 0.0009322473197244108]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009322473197244108

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55321097
Iteration 2/25 | Loss: 0.00123201
Iteration 3/25 | Loss: 0.00123199
Iteration 4/25 | Loss: 0.00123199
Iteration 5/25 | Loss: 0.00123199
Iteration 6/25 | Loss: 0.00123199
Iteration 7/25 | Loss: 0.00123199
Iteration 8/25 | Loss: 0.00123199
Iteration 9/25 | Loss: 0.00123199
Iteration 10/25 | Loss: 0.00123199
Iteration 11/25 | Loss: 0.00123199
Iteration 12/25 | Loss: 0.00123199
Iteration 13/25 | Loss: 0.00123199
Iteration 14/25 | Loss: 0.00123199
Iteration 15/25 | Loss: 0.00123199
Iteration 16/25 | Loss: 0.00123199
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012319900561124086, 0.0012319900561124086, 0.0012319900561124086, 0.0012319900561124086, 0.0012319900561124086]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012319900561124086

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00123199
Iteration 2/1000 | Loss: 0.00003864
Iteration 3/1000 | Loss: 0.00002910
Iteration 4/1000 | Loss: 0.00002708
Iteration 5/1000 | Loss: 0.00002575
Iteration 6/1000 | Loss: 0.00002501
Iteration 7/1000 | Loss: 0.00002448
Iteration 8/1000 | Loss: 0.00002425
Iteration 9/1000 | Loss: 0.00002417
Iteration 10/1000 | Loss: 0.00002413
Iteration 11/1000 | Loss: 0.00002413
Iteration 12/1000 | Loss: 0.00002404
Iteration 13/1000 | Loss: 0.00002403
Iteration 14/1000 | Loss: 0.00002398
Iteration 15/1000 | Loss: 0.00002391
Iteration 16/1000 | Loss: 0.00002391
Iteration 17/1000 | Loss: 0.00002391
Iteration 18/1000 | Loss: 0.00002391
Iteration 19/1000 | Loss: 0.00002391
Iteration 20/1000 | Loss: 0.00002391
Iteration 21/1000 | Loss: 0.00002391
Iteration 22/1000 | Loss: 0.00002391
Iteration 23/1000 | Loss: 0.00002390
Iteration 24/1000 | Loss: 0.00002390
Iteration 25/1000 | Loss: 0.00002390
Iteration 26/1000 | Loss: 0.00002390
Iteration 27/1000 | Loss: 0.00002390
Iteration 28/1000 | Loss: 0.00002390
Iteration 29/1000 | Loss: 0.00002390
Iteration 30/1000 | Loss: 0.00002387
Iteration 31/1000 | Loss: 0.00002387
Iteration 32/1000 | Loss: 0.00002387
Iteration 33/1000 | Loss: 0.00002387
Iteration 34/1000 | Loss: 0.00002387
Iteration 35/1000 | Loss: 0.00002386
Iteration 36/1000 | Loss: 0.00002386
Iteration 37/1000 | Loss: 0.00002386
Iteration 38/1000 | Loss: 0.00002384
Iteration 39/1000 | Loss: 0.00002381
Iteration 40/1000 | Loss: 0.00002381
Iteration 41/1000 | Loss: 0.00002381
Iteration 42/1000 | Loss: 0.00002381
Iteration 43/1000 | Loss: 0.00002381
Iteration 44/1000 | Loss: 0.00002381
Iteration 45/1000 | Loss: 0.00002381
Iteration 46/1000 | Loss: 0.00002381
Iteration 47/1000 | Loss: 0.00002381
Iteration 48/1000 | Loss: 0.00002380
Iteration 49/1000 | Loss: 0.00002380
Iteration 50/1000 | Loss: 0.00002380
Iteration 51/1000 | Loss: 0.00002379
Iteration 52/1000 | Loss: 0.00002378
Iteration 53/1000 | Loss: 0.00002378
Iteration 54/1000 | Loss: 0.00002378
Iteration 55/1000 | Loss: 0.00002378
Iteration 56/1000 | Loss: 0.00002377
Iteration 57/1000 | Loss: 0.00002377
Iteration 58/1000 | Loss: 0.00002377
Iteration 59/1000 | Loss: 0.00002376
Iteration 60/1000 | Loss: 0.00002376
Iteration 61/1000 | Loss: 0.00002376
Iteration 62/1000 | Loss: 0.00002376
Iteration 63/1000 | Loss: 0.00002376
Iteration 64/1000 | Loss: 0.00002376
Iteration 65/1000 | Loss: 0.00002376
Iteration 66/1000 | Loss: 0.00002375
Iteration 67/1000 | Loss: 0.00002375
Iteration 68/1000 | Loss: 0.00002375
Iteration 69/1000 | Loss: 0.00002374
Iteration 70/1000 | Loss: 0.00002374
Iteration 71/1000 | Loss: 0.00002374
Iteration 72/1000 | Loss: 0.00002374
Iteration 73/1000 | Loss: 0.00002374
Iteration 74/1000 | Loss: 0.00002374
Iteration 75/1000 | Loss: 0.00002374
Iteration 76/1000 | Loss: 0.00002373
Iteration 77/1000 | Loss: 0.00002373
Iteration 78/1000 | Loss: 0.00002373
Iteration 79/1000 | Loss: 0.00002373
Iteration 80/1000 | Loss: 0.00002372
Iteration 81/1000 | Loss: 0.00002372
Iteration 82/1000 | Loss: 0.00002372
Iteration 83/1000 | Loss: 0.00002372
Iteration 84/1000 | Loss: 0.00002371
Iteration 85/1000 | Loss: 0.00002371
Iteration 86/1000 | Loss: 0.00002371
Iteration 87/1000 | Loss: 0.00002371
Iteration 88/1000 | Loss: 0.00002371
Iteration 89/1000 | Loss: 0.00002371
Iteration 90/1000 | Loss: 0.00002371
Iteration 91/1000 | Loss: 0.00002370
Iteration 92/1000 | Loss: 0.00002370
Iteration 93/1000 | Loss: 0.00002369
Iteration 94/1000 | Loss: 0.00002369
Iteration 95/1000 | Loss: 0.00002369
Iteration 96/1000 | Loss: 0.00002369
Iteration 97/1000 | Loss: 0.00002369
Iteration 98/1000 | Loss: 0.00002368
Iteration 99/1000 | Loss: 0.00002368
Iteration 100/1000 | Loss: 0.00002368
Iteration 101/1000 | Loss: 0.00002368
Iteration 102/1000 | Loss: 0.00002368
Iteration 103/1000 | Loss: 0.00002368
Iteration 104/1000 | Loss: 0.00002368
Iteration 105/1000 | Loss: 0.00002368
Iteration 106/1000 | Loss: 0.00002368
Iteration 107/1000 | Loss: 0.00002368
Iteration 108/1000 | Loss: 0.00002368
Iteration 109/1000 | Loss: 0.00002367
Iteration 110/1000 | Loss: 0.00002367
Iteration 111/1000 | Loss: 0.00002367
Iteration 112/1000 | Loss: 0.00002367
Iteration 113/1000 | Loss: 0.00002367
Iteration 114/1000 | Loss: 0.00002367
Iteration 115/1000 | Loss: 0.00002367
Iteration 116/1000 | Loss: 0.00002367
Iteration 117/1000 | Loss: 0.00002367
Iteration 118/1000 | Loss: 0.00002367
Iteration 119/1000 | Loss: 0.00002367
Iteration 120/1000 | Loss: 0.00002367
Iteration 121/1000 | Loss: 0.00002367
Iteration 122/1000 | Loss: 0.00002367
Iteration 123/1000 | Loss: 0.00002367
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [2.36740852415096e-05, 2.36740852415096e-05, 2.36740852415096e-05, 2.36740852415096e-05, 2.36740852415096e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.36740852415096e-05

Optimization complete. Final v2v error: 4.090637683868408 mm

Highest mean error: 4.379903316497803 mm for frame 183

Lowest mean error: 3.93815016746521 mm for frame 16

Saving results

Total time: 48.76082897186279
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435866
Iteration 2/25 | Loss: 0.00114094
Iteration 3/25 | Loss: 0.00082992
Iteration 4/25 | Loss: 0.00078312
Iteration 5/25 | Loss: 0.00077790
Iteration 6/25 | Loss: 0.00077596
Iteration 7/25 | Loss: 0.00077526
Iteration 8/25 | Loss: 0.00077520
Iteration 9/25 | Loss: 0.00077520
Iteration 10/25 | Loss: 0.00077520
Iteration 11/25 | Loss: 0.00077520
Iteration 12/25 | Loss: 0.00077520
Iteration 13/25 | Loss: 0.00077520
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.000775196822360158, 0.000775196822360158, 0.000775196822360158, 0.000775196822360158, 0.000775196822360158]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000775196822360158

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 7.48147249
Iteration 2/25 | Loss: 0.00122895
Iteration 3/25 | Loss: 0.00122895
Iteration 4/25 | Loss: 0.00122895
Iteration 5/25 | Loss: 0.00122895
Iteration 6/25 | Loss: 0.00122895
Iteration 7/25 | Loss: 0.00122895
Iteration 8/25 | Loss: 0.00122895
Iteration 9/25 | Loss: 0.00122895
Iteration 10/25 | Loss: 0.00122895
Iteration 11/25 | Loss: 0.00122895
Iteration 12/25 | Loss: 0.00122895
Iteration 13/25 | Loss: 0.00122895
Iteration 14/25 | Loss: 0.00122895
Iteration 15/25 | Loss: 0.00122895
Iteration 16/25 | Loss: 0.00122895
Iteration 17/25 | Loss: 0.00122895
Iteration 18/25 | Loss: 0.00122895
Iteration 19/25 | Loss: 0.00122895
Iteration 20/25 | Loss: 0.00122895
Iteration 21/25 | Loss: 0.00122895
Iteration 22/25 | Loss: 0.00122895
Iteration 23/25 | Loss: 0.00122895
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0012289463775232434, 0.0012289463775232434, 0.0012289463775232434, 0.0012289463775232434, 0.0012289463775232434]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012289463775232434

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00122895
Iteration 2/1000 | Loss: 0.00002811
Iteration 3/1000 | Loss: 0.00001807
Iteration 4/1000 | Loss: 0.00001603
Iteration 5/1000 | Loss: 0.00001530
Iteration 6/1000 | Loss: 0.00001472
Iteration 7/1000 | Loss: 0.00001435
Iteration 8/1000 | Loss: 0.00001409
Iteration 9/1000 | Loss: 0.00001396
Iteration 10/1000 | Loss: 0.00001388
Iteration 11/1000 | Loss: 0.00001383
Iteration 12/1000 | Loss: 0.00001381
Iteration 13/1000 | Loss: 0.00001379
Iteration 14/1000 | Loss: 0.00001374
Iteration 15/1000 | Loss: 0.00001367
Iteration 16/1000 | Loss: 0.00001362
Iteration 17/1000 | Loss: 0.00001361
Iteration 18/1000 | Loss: 0.00001360
Iteration 19/1000 | Loss: 0.00001359
Iteration 20/1000 | Loss: 0.00001356
Iteration 21/1000 | Loss: 0.00001356
Iteration 22/1000 | Loss: 0.00001355
Iteration 23/1000 | Loss: 0.00001354
Iteration 24/1000 | Loss: 0.00001354
Iteration 25/1000 | Loss: 0.00001351
Iteration 26/1000 | Loss: 0.00001345
Iteration 27/1000 | Loss: 0.00001345
Iteration 28/1000 | Loss: 0.00001345
Iteration 29/1000 | Loss: 0.00001345
Iteration 30/1000 | Loss: 0.00001345
Iteration 31/1000 | Loss: 0.00001345
Iteration 32/1000 | Loss: 0.00001343
Iteration 33/1000 | Loss: 0.00001343
Iteration 34/1000 | Loss: 0.00001342
Iteration 35/1000 | Loss: 0.00001342
Iteration 36/1000 | Loss: 0.00001342
Iteration 37/1000 | Loss: 0.00001342
Iteration 38/1000 | Loss: 0.00001342
Iteration 39/1000 | Loss: 0.00001341
Iteration 40/1000 | Loss: 0.00001341
Iteration 41/1000 | Loss: 0.00001341
Iteration 42/1000 | Loss: 0.00001340
Iteration 43/1000 | Loss: 0.00001340
Iteration 44/1000 | Loss: 0.00001340
Iteration 45/1000 | Loss: 0.00001340
Iteration 46/1000 | Loss: 0.00001340
Iteration 47/1000 | Loss: 0.00001339
Iteration 48/1000 | Loss: 0.00001339
Iteration 49/1000 | Loss: 0.00001339
Iteration 50/1000 | Loss: 0.00001339
Iteration 51/1000 | Loss: 0.00001339
Iteration 52/1000 | Loss: 0.00001339
Iteration 53/1000 | Loss: 0.00001339
Iteration 54/1000 | Loss: 0.00001338
Iteration 55/1000 | Loss: 0.00001338
Iteration 56/1000 | Loss: 0.00001338
Iteration 57/1000 | Loss: 0.00001338
Iteration 58/1000 | Loss: 0.00001337
Iteration 59/1000 | Loss: 0.00001337
Iteration 60/1000 | Loss: 0.00001337
Iteration 61/1000 | Loss: 0.00001337
Iteration 62/1000 | Loss: 0.00001337
Iteration 63/1000 | Loss: 0.00001337
Iteration 64/1000 | Loss: 0.00001336
Iteration 65/1000 | Loss: 0.00001336
Iteration 66/1000 | Loss: 0.00001336
Iteration 67/1000 | Loss: 0.00001336
Iteration 68/1000 | Loss: 0.00001336
Iteration 69/1000 | Loss: 0.00001336
Iteration 70/1000 | Loss: 0.00001335
Iteration 71/1000 | Loss: 0.00001335
Iteration 72/1000 | Loss: 0.00001335
Iteration 73/1000 | Loss: 0.00001335
Iteration 74/1000 | Loss: 0.00001335
Iteration 75/1000 | Loss: 0.00001335
Iteration 76/1000 | Loss: 0.00001335
Iteration 77/1000 | Loss: 0.00001335
Iteration 78/1000 | Loss: 0.00001335
Iteration 79/1000 | Loss: 0.00001334
Iteration 80/1000 | Loss: 0.00001334
Iteration 81/1000 | Loss: 0.00001334
Iteration 82/1000 | Loss: 0.00001334
Iteration 83/1000 | Loss: 0.00001334
Iteration 84/1000 | Loss: 0.00001334
Iteration 85/1000 | Loss: 0.00001333
Iteration 86/1000 | Loss: 0.00001333
Iteration 87/1000 | Loss: 0.00001333
Iteration 88/1000 | Loss: 0.00001333
Iteration 89/1000 | Loss: 0.00001332
Iteration 90/1000 | Loss: 0.00001332
Iteration 91/1000 | Loss: 0.00001332
Iteration 92/1000 | Loss: 0.00001331
Iteration 93/1000 | Loss: 0.00001331
Iteration 94/1000 | Loss: 0.00001331
Iteration 95/1000 | Loss: 0.00001331
Iteration 96/1000 | Loss: 0.00001331
Iteration 97/1000 | Loss: 0.00001331
Iteration 98/1000 | Loss: 0.00001331
Iteration 99/1000 | Loss: 0.00001331
Iteration 100/1000 | Loss: 0.00001330
Iteration 101/1000 | Loss: 0.00001330
Iteration 102/1000 | Loss: 0.00001330
Iteration 103/1000 | Loss: 0.00001330
Iteration 104/1000 | Loss: 0.00001330
Iteration 105/1000 | Loss: 0.00001330
Iteration 106/1000 | Loss: 0.00001330
Iteration 107/1000 | Loss: 0.00001330
Iteration 108/1000 | Loss: 0.00001329
Iteration 109/1000 | Loss: 0.00001329
Iteration 110/1000 | Loss: 0.00001329
Iteration 111/1000 | Loss: 0.00001329
Iteration 112/1000 | Loss: 0.00001329
Iteration 113/1000 | Loss: 0.00001329
Iteration 114/1000 | Loss: 0.00001329
Iteration 115/1000 | Loss: 0.00001328
Iteration 116/1000 | Loss: 0.00001328
Iteration 117/1000 | Loss: 0.00001328
Iteration 118/1000 | Loss: 0.00001328
Iteration 119/1000 | Loss: 0.00001328
Iteration 120/1000 | Loss: 0.00001328
Iteration 121/1000 | Loss: 0.00001328
Iteration 122/1000 | Loss: 0.00001328
Iteration 123/1000 | Loss: 0.00001328
Iteration 124/1000 | Loss: 0.00001328
Iteration 125/1000 | Loss: 0.00001328
Iteration 126/1000 | Loss: 0.00001327
Iteration 127/1000 | Loss: 0.00001327
Iteration 128/1000 | Loss: 0.00001327
Iteration 129/1000 | Loss: 0.00001327
Iteration 130/1000 | Loss: 0.00001327
Iteration 131/1000 | Loss: 0.00001327
Iteration 132/1000 | Loss: 0.00001327
Iteration 133/1000 | Loss: 0.00001327
Iteration 134/1000 | Loss: 0.00001327
Iteration 135/1000 | Loss: 0.00001327
Iteration 136/1000 | Loss: 0.00001327
Iteration 137/1000 | Loss: 0.00001327
Iteration 138/1000 | Loss: 0.00001327
Iteration 139/1000 | Loss: 0.00001326
Iteration 140/1000 | Loss: 0.00001326
Iteration 141/1000 | Loss: 0.00001326
Iteration 142/1000 | Loss: 0.00001326
Iteration 143/1000 | Loss: 0.00001326
Iteration 144/1000 | Loss: 0.00001326
Iteration 145/1000 | Loss: 0.00001326
Iteration 146/1000 | Loss: 0.00001326
Iteration 147/1000 | Loss: 0.00001326
Iteration 148/1000 | Loss: 0.00001326
Iteration 149/1000 | Loss: 0.00001326
Iteration 150/1000 | Loss: 0.00001326
Iteration 151/1000 | Loss: 0.00001326
Iteration 152/1000 | Loss: 0.00001325
Iteration 153/1000 | Loss: 0.00001325
Iteration 154/1000 | Loss: 0.00001325
Iteration 155/1000 | Loss: 0.00001325
Iteration 156/1000 | Loss: 0.00001325
Iteration 157/1000 | Loss: 0.00001325
Iteration 158/1000 | Loss: 0.00001325
Iteration 159/1000 | Loss: 0.00001325
Iteration 160/1000 | Loss: 0.00001325
Iteration 161/1000 | Loss: 0.00001325
Iteration 162/1000 | Loss: 0.00001324
Iteration 163/1000 | Loss: 0.00001324
Iteration 164/1000 | Loss: 0.00001324
Iteration 165/1000 | Loss: 0.00001324
Iteration 166/1000 | Loss: 0.00001324
Iteration 167/1000 | Loss: 0.00001324
Iteration 168/1000 | Loss: 0.00001324
Iteration 169/1000 | Loss: 0.00001324
Iteration 170/1000 | Loss: 0.00001324
Iteration 171/1000 | Loss: 0.00001324
Iteration 172/1000 | Loss: 0.00001324
Iteration 173/1000 | Loss: 0.00001324
Iteration 174/1000 | Loss: 0.00001324
Iteration 175/1000 | Loss: 0.00001324
Iteration 176/1000 | Loss: 0.00001324
Iteration 177/1000 | Loss: 0.00001324
Iteration 178/1000 | Loss: 0.00001324
Iteration 179/1000 | Loss: 0.00001324
Iteration 180/1000 | Loss: 0.00001324
Iteration 181/1000 | Loss: 0.00001324
Iteration 182/1000 | Loss: 0.00001324
Iteration 183/1000 | Loss: 0.00001324
Iteration 184/1000 | Loss: 0.00001324
Iteration 185/1000 | Loss: 0.00001324
Iteration 186/1000 | Loss: 0.00001324
Iteration 187/1000 | Loss: 0.00001324
Iteration 188/1000 | Loss: 0.00001324
Iteration 189/1000 | Loss: 0.00001324
Iteration 190/1000 | Loss: 0.00001324
Iteration 191/1000 | Loss: 0.00001324
Iteration 192/1000 | Loss: 0.00001324
Iteration 193/1000 | Loss: 0.00001324
Iteration 194/1000 | Loss: 0.00001324
Iteration 195/1000 | Loss: 0.00001324
Iteration 196/1000 | Loss: 0.00001324
Iteration 197/1000 | Loss: 0.00001324
Iteration 198/1000 | Loss: 0.00001324
Iteration 199/1000 | Loss: 0.00001324
Iteration 200/1000 | Loss: 0.00001324
Iteration 201/1000 | Loss: 0.00001324
Iteration 202/1000 | Loss: 0.00001324
Iteration 203/1000 | Loss: 0.00001324
Iteration 204/1000 | Loss: 0.00001324
Iteration 205/1000 | Loss: 0.00001324
Iteration 206/1000 | Loss: 0.00001324
Iteration 207/1000 | Loss: 0.00001324
Iteration 208/1000 | Loss: 0.00001324
Iteration 209/1000 | Loss: 0.00001324
Iteration 210/1000 | Loss: 0.00001324
Iteration 211/1000 | Loss: 0.00001324
Iteration 212/1000 | Loss: 0.00001324
Iteration 213/1000 | Loss: 0.00001324
Iteration 214/1000 | Loss: 0.00001324
Iteration 215/1000 | Loss: 0.00001324
Iteration 216/1000 | Loss: 0.00001324
Iteration 217/1000 | Loss: 0.00001324
Iteration 218/1000 | Loss: 0.00001324
Iteration 219/1000 | Loss: 0.00001324
Iteration 220/1000 | Loss: 0.00001324
Iteration 221/1000 | Loss: 0.00001324
Iteration 222/1000 | Loss: 0.00001324
Iteration 223/1000 | Loss: 0.00001324
Iteration 224/1000 | Loss: 0.00001324
Iteration 225/1000 | Loss: 0.00001324
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 225. Stopping optimization.
Last 5 losses: [1.3239037798484787e-05, 1.3239037798484787e-05, 1.3239037798484787e-05, 1.3239037798484787e-05, 1.3239037798484787e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3239037798484787e-05

Optimization complete. Final v2v error: 3.102428436279297 mm

Highest mean error: 3.6544528007507324 mm for frame 71

Lowest mean error: 2.786311388015747 mm for frame 11

Saving results

Total time: 38.79843068122864
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00292244
Iteration 2/25 | Loss: 0.00108254
Iteration 3/25 | Loss: 0.00086434
Iteration 4/25 | Loss: 0.00081402
Iteration 5/25 | Loss: 0.00079459
Iteration 6/25 | Loss: 0.00079155
Iteration 7/25 | Loss: 0.00079067
Iteration 8/25 | Loss: 0.00079055
Iteration 9/25 | Loss: 0.00079055
Iteration 10/25 | Loss: 0.00079055
Iteration 11/25 | Loss: 0.00079055
Iteration 12/25 | Loss: 0.00079055
Iteration 13/25 | Loss: 0.00079055
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007905515958555043, 0.0007905515958555043, 0.0007905515958555043, 0.0007905515958555043, 0.0007905515958555043]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007905515958555043

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65469456
Iteration 2/25 | Loss: 0.00159082
Iteration 3/25 | Loss: 0.00159082
Iteration 4/25 | Loss: 0.00159082
Iteration 5/25 | Loss: 0.00159081
Iteration 6/25 | Loss: 0.00159081
Iteration 7/25 | Loss: 0.00159081
Iteration 8/25 | Loss: 0.00159081
Iteration 9/25 | Loss: 0.00159081
Iteration 10/25 | Loss: 0.00159081
Iteration 11/25 | Loss: 0.00159081
Iteration 12/25 | Loss: 0.00159081
Iteration 13/25 | Loss: 0.00159081
Iteration 14/25 | Loss: 0.00159081
Iteration 15/25 | Loss: 0.00159081
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.001590813510119915, 0.001590813510119915, 0.001590813510119915, 0.001590813510119915, 0.001590813510119915]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001590813510119915

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00159081
Iteration 2/1000 | Loss: 0.00004230
Iteration 3/1000 | Loss: 0.00002777
Iteration 4/1000 | Loss: 0.00002411
Iteration 5/1000 | Loss: 0.00002294
Iteration 6/1000 | Loss: 0.00002197
Iteration 7/1000 | Loss: 0.00002152
Iteration 8/1000 | Loss: 0.00002103
Iteration 9/1000 | Loss: 0.00002069
Iteration 10/1000 | Loss: 0.00002038
Iteration 11/1000 | Loss: 0.00002011
Iteration 12/1000 | Loss: 0.00001991
Iteration 13/1000 | Loss: 0.00001978
Iteration 14/1000 | Loss: 0.00001976
Iteration 15/1000 | Loss: 0.00001973
Iteration 16/1000 | Loss: 0.00001970
Iteration 17/1000 | Loss: 0.00001970
Iteration 18/1000 | Loss: 0.00001970
Iteration 19/1000 | Loss: 0.00001969
Iteration 20/1000 | Loss: 0.00001968
Iteration 21/1000 | Loss: 0.00001963
Iteration 22/1000 | Loss: 0.00001960
Iteration 23/1000 | Loss: 0.00001960
Iteration 24/1000 | Loss: 0.00001956
Iteration 25/1000 | Loss: 0.00001956
Iteration 26/1000 | Loss: 0.00001956
Iteration 27/1000 | Loss: 0.00001955
Iteration 28/1000 | Loss: 0.00001955
Iteration 29/1000 | Loss: 0.00001954
Iteration 30/1000 | Loss: 0.00001954
Iteration 31/1000 | Loss: 0.00001953
Iteration 32/1000 | Loss: 0.00001953
Iteration 33/1000 | Loss: 0.00001952
Iteration 34/1000 | Loss: 0.00001952
Iteration 35/1000 | Loss: 0.00001952
Iteration 36/1000 | Loss: 0.00001952
Iteration 37/1000 | Loss: 0.00001951
Iteration 38/1000 | Loss: 0.00001951
Iteration 39/1000 | Loss: 0.00001951
Iteration 40/1000 | Loss: 0.00001950
Iteration 41/1000 | Loss: 0.00001950
Iteration 42/1000 | Loss: 0.00001950
Iteration 43/1000 | Loss: 0.00001950
Iteration 44/1000 | Loss: 0.00001949
Iteration 45/1000 | Loss: 0.00001949
Iteration 46/1000 | Loss: 0.00001949
Iteration 47/1000 | Loss: 0.00001949
Iteration 48/1000 | Loss: 0.00001949
Iteration 49/1000 | Loss: 0.00001949
Iteration 50/1000 | Loss: 0.00001949
Iteration 51/1000 | Loss: 0.00001949
Iteration 52/1000 | Loss: 0.00001949
Iteration 53/1000 | Loss: 0.00001949
Iteration 54/1000 | Loss: 0.00001949
Iteration 55/1000 | Loss: 0.00001948
Iteration 56/1000 | Loss: 0.00001948
Iteration 57/1000 | Loss: 0.00001948
Iteration 58/1000 | Loss: 0.00001948
Iteration 59/1000 | Loss: 0.00001948
Iteration 60/1000 | Loss: 0.00001948
Iteration 61/1000 | Loss: 0.00001948
Iteration 62/1000 | Loss: 0.00001948
Iteration 63/1000 | Loss: 0.00001948
Iteration 64/1000 | Loss: 0.00001948
Iteration 65/1000 | Loss: 0.00001947
Iteration 66/1000 | Loss: 0.00001947
Iteration 67/1000 | Loss: 0.00001947
Iteration 68/1000 | Loss: 0.00001947
Iteration 69/1000 | Loss: 0.00001947
Iteration 70/1000 | Loss: 0.00001947
Iteration 71/1000 | Loss: 0.00001947
Iteration 72/1000 | Loss: 0.00001947
Iteration 73/1000 | Loss: 0.00001947
Iteration 74/1000 | Loss: 0.00001947
Iteration 75/1000 | Loss: 0.00001947
Iteration 76/1000 | Loss: 0.00001947
Iteration 77/1000 | Loss: 0.00001947
Iteration 78/1000 | Loss: 0.00001947
Iteration 79/1000 | Loss: 0.00001947
Iteration 80/1000 | Loss: 0.00001946
Iteration 81/1000 | Loss: 0.00001946
Iteration 82/1000 | Loss: 0.00001946
Iteration 83/1000 | Loss: 0.00001946
Iteration 84/1000 | Loss: 0.00001946
Iteration 85/1000 | Loss: 0.00001946
Iteration 86/1000 | Loss: 0.00001945
Iteration 87/1000 | Loss: 0.00001945
Iteration 88/1000 | Loss: 0.00001945
Iteration 89/1000 | Loss: 0.00001945
Iteration 90/1000 | Loss: 0.00001945
Iteration 91/1000 | Loss: 0.00001944
Iteration 92/1000 | Loss: 0.00001944
Iteration 93/1000 | Loss: 0.00001944
Iteration 94/1000 | Loss: 0.00001943
Iteration 95/1000 | Loss: 0.00001943
Iteration 96/1000 | Loss: 0.00001943
Iteration 97/1000 | Loss: 0.00001943
Iteration 98/1000 | Loss: 0.00001943
Iteration 99/1000 | Loss: 0.00001943
Iteration 100/1000 | Loss: 0.00001942
Iteration 101/1000 | Loss: 0.00001942
Iteration 102/1000 | Loss: 0.00001942
Iteration 103/1000 | Loss: 0.00001942
Iteration 104/1000 | Loss: 0.00001942
Iteration 105/1000 | Loss: 0.00001942
Iteration 106/1000 | Loss: 0.00001942
Iteration 107/1000 | Loss: 0.00001941
Iteration 108/1000 | Loss: 0.00001941
Iteration 109/1000 | Loss: 0.00001941
Iteration 110/1000 | Loss: 0.00001941
Iteration 111/1000 | Loss: 0.00001941
Iteration 112/1000 | Loss: 0.00001941
Iteration 113/1000 | Loss: 0.00001941
Iteration 114/1000 | Loss: 0.00001941
Iteration 115/1000 | Loss: 0.00001941
Iteration 116/1000 | Loss: 0.00001941
Iteration 117/1000 | Loss: 0.00001941
Iteration 118/1000 | Loss: 0.00001941
Iteration 119/1000 | Loss: 0.00001941
Iteration 120/1000 | Loss: 0.00001941
Iteration 121/1000 | Loss: 0.00001941
Iteration 122/1000 | Loss: 0.00001941
Iteration 123/1000 | Loss: 0.00001941
Iteration 124/1000 | Loss: 0.00001941
Iteration 125/1000 | Loss: 0.00001941
Iteration 126/1000 | Loss: 0.00001941
Iteration 127/1000 | Loss: 0.00001941
Iteration 128/1000 | Loss: 0.00001941
Iteration 129/1000 | Loss: 0.00001941
Iteration 130/1000 | Loss: 0.00001941
Iteration 131/1000 | Loss: 0.00001941
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.941053596965503e-05, 1.941053596965503e-05, 1.941053596965503e-05, 1.941053596965503e-05, 1.941053596965503e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.941053596965503e-05

Optimization complete. Final v2v error: 3.6229777336120605 mm

Highest mean error: 3.9540576934814453 mm for frame 209

Lowest mean error: 3.291961193084717 mm for frame 7

Saving results

Total time: 45.044821977615356
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00397219
Iteration 2/25 | Loss: 0.00083508
Iteration 3/25 | Loss: 0.00074228
Iteration 4/25 | Loss: 0.00072448
Iteration 5/25 | Loss: 0.00071863
Iteration 6/25 | Loss: 0.00071708
Iteration 7/25 | Loss: 0.00071667
Iteration 8/25 | Loss: 0.00071667
Iteration 9/25 | Loss: 0.00071667
Iteration 10/25 | Loss: 0.00071667
Iteration 11/25 | Loss: 0.00071667
Iteration 12/25 | Loss: 0.00071667
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007166681461967528, 0.0007166681461967528, 0.0007166681461967528, 0.0007166681461967528, 0.0007166681461967528]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007166681461967528

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.49780130
Iteration 2/25 | Loss: 0.00119956
Iteration 3/25 | Loss: 0.00119956
Iteration 4/25 | Loss: 0.00119956
Iteration 5/25 | Loss: 0.00119956
Iteration 6/25 | Loss: 0.00119956
Iteration 7/25 | Loss: 0.00119955
Iteration 8/25 | Loss: 0.00119955
Iteration 9/25 | Loss: 0.00119955
Iteration 10/25 | Loss: 0.00119955
Iteration 11/25 | Loss: 0.00119955
Iteration 12/25 | Loss: 0.00119955
Iteration 13/25 | Loss: 0.00119955
Iteration 14/25 | Loss: 0.00119955
Iteration 15/25 | Loss: 0.00119955
Iteration 16/25 | Loss: 0.00119955
Iteration 17/25 | Loss: 0.00119955
Iteration 18/25 | Loss: 0.00119955
Iteration 19/25 | Loss: 0.00119955
Iteration 20/25 | Loss: 0.00119955
Iteration 21/25 | Loss: 0.00119955
Iteration 22/25 | Loss: 0.00119955
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0011995536042377353, 0.0011995536042377353, 0.0011995536042377353, 0.0011995536042377353, 0.0011995536042377353]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011995536042377353

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00119955
Iteration 2/1000 | Loss: 0.00002585
Iteration 3/1000 | Loss: 0.00001608
Iteration 4/1000 | Loss: 0.00001455
Iteration 5/1000 | Loss: 0.00001377
Iteration 6/1000 | Loss: 0.00001340
Iteration 7/1000 | Loss: 0.00001305
Iteration 8/1000 | Loss: 0.00001301
Iteration 9/1000 | Loss: 0.00001288
Iteration 10/1000 | Loss: 0.00001284
Iteration 11/1000 | Loss: 0.00001278
Iteration 12/1000 | Loss: 0.00001277
Iteration 13/1000 | Loss: 0.00001268
Iteration 14/1000 | Loss: 0.00001267
Iteration 15/1000 | Loss: 0.00001256
Iteration 16/1000 | Loss: 0.00001252
Iteration 17/1000 | Loss: 0.00001252
Iteration 18/1000 | Loss: 0.00001251
Iteration 19/1000 | Loss: 0.00001246
Iteration 20/1000 | Loss: 0.00001245
Iteration 21/1000 | Loss: 0.00001245
Iteration 22/1000 | Loss: 0.00001235
Iteration 23/1000 | Loss: 0.00001232
Iteration 24/1000 | Loss: 0.00001232
Iteration 25/1000 | Loss: 0.00001231
Iteration 26/1000 | Loss: 0.00001231
Iteration 27/1000 | Loss: 0.00001231
Iteration 28/1000 | Loss: 0.00001231
Iteration 29/1000 | Loss: 0.00001231
Iteration 30/1000 | Loss: 0.00001231
Iteration 31/1000 | Loss: 0.00001231
Iteration 32/1000 | Loss: 0.00001231
Iteration 33/1000 | Loss: 0.00001231
Iteration 34/1000 | Loss: 0.00001231
Iteration 35/1000 | Loss: 0.00001230
Iteration 36/1000 | Loss: 0.00001230
Iteration 37/1000 | Loss: 0.00001230
Iteration 38/1000 | Loss: 0.00001230
Iteration 39/1000 | Loss: 0.00001230
Iteration 40/1000 | Loss: 0.00001230
Iteration 41/1000 | Loss: 0.00001230
Iteration 42/1000 | Loss: 0.00001229
Iteration 43/1000 | Loss: 0.00001229
Iteration 44/1000 | Loss: 0.00001229
Iteration 45/1000 | Loss: 0.00001228
Iteration 46/1000 | Loss: 0.00001228
Iteration 47/1000 | Loss: 0.00001227
Iteration 48/1000 | Loss: 0.00001227
Iteration 49/1000 | Loss: 0.00001227
Iteration 50/1000 | Loss: 0.00001226
Iteration 51/1000 | Loss: 0.00001226
Iteration 52/1000 | Loss: 0.00001226
Iteration 53/1000 | Loss: 0.00001225
Iteration 54/1000 | Loss: 0.00001225
Iteration 55/1000 | Loss: 0.00001225
Iteration 56/1000 | Loss: 0.00001225
Iteration 57/1000 | Loss: 0.00001225
Iteration 58/1000 | Loss: 0.00001224
Iteration 59/1000 | Loss: 0.00001224
Iteration 60/1000 | Loss: 0.00001224
Iteration 61/1000 | Loss: 0.00001222
Iteration 62/1000 | Loss: 0.00001222
Iteration 63/1000 | Loss: 0.00001222
Iteration 64/1000 | Loss: 0.00001222
Iteration 65/1000 | Loss: 0.00001222
Iteration 66/1000 | Loss: 0.00001222
Iteration 67/1000 | Loss: 0.00001221
Iteration 68/1000 | Loss: 0.00001221
Iteration 69/1000 | Loss: 0.00001221
Iteration 70/1000 | Loss: 0.00001221
Iteration 71/1000 | Loss: 0.00001221
Iteration 72/1000 | Loss: 0.00001221
Iteration 73/1000 | Loss: 0.00001218
Iteration 74/1000 | Loss: 0.00001218
Iteration 75/1000 | Loss: 0.00001217
Iteration 76/1000 | Loss: 0.00001217
Iteration 77/1000 | Loss: 0.00001217
Iteration 78/1000 | Loss: 0.00001216
Iteration 79/1000 | Loss: 0.00001216
Iteration 80/1000 | Loss: 0.00001216
Iteration 81/1000 | Loss: 0.00001216
Iteration 82/1000 | Loss: 0.00001214
Iteration 83/1000 | Loss: 0.00001214
Iteration 84/1000 | Loss: 0.00001214
Iteration 85/1000 | Loss: 0.00001214
Iteration 86/1000 | Loss: 0.00001213
Iteration 87/1000 | Loss: 0.00001213
Iteration 88/1000 | Loss: 0.00001213
Iteration 89/1000 | Loss: 0.00001213
Iteration 90/1000 | Loss: 0.00001213
Iteration 91/1000 | Loss: 0.00001212
Iteration 92/1000 | Loss: 0.00001212
Iteration 93/1000 | Loss: 0.00001212
Iteration 94/1000 | Loss: 0.00001211
Iteration 95/1000 | Loss: 0.00001211
Iteration 96/1000 | Loss: 0.00001211
Iteration 97/1000 | Loss: 0.00001211
Iteration 98/1000 | Loss: 0.00001211
Iteration 99/1000 | Loss: 0.00001211
Iteration 100/1000 | Loss: 0.00001210
Iteration 101/1000 | Loss: 0.00001210
Iteration 102/1000 | Loss: 0.00001210
Iteration 103/1000 | Loss: 0.00001210
Iteration 104/1000 | Loss: 0.00001210
Iteration 105/1000 | Loss: 0.00001210
Iteration 106/1000 | Loss: 0.00001210
Iteration 107/1000 | Loss: 0.00001210
Iteration 108/1000 | Loss: 0.00001210
Iteration 109/1000 | Loss: 0.00001210
Iteration 110/1000 | Loss: 0.00001210
Iteration 111/1000 | Loss: 0.00001210
Iteration 112/1000 | Loss: 0.00001210
Iteration 113/1000 | Loss: 0.00001210
Iteration 114/1000 | Loss: 0.00001210
Iteration 115/1000 | Loss: 0.00001210
Iteration 116/1000 | Loss: 0.00001210
Iteration 117/1000 | Loss: 0.00001210
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [1.2103471817681566e-05, 1.2103471817681566e-05, 1.2103471817681566e-05, 1.2103471817681566e-05, 1.2103471817681566e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2103471817681566e-05

Optimization complete. Final v2v error: 2.987427234649658 mm

Highest mean error: 3.182194948196411 mm for frame 81

Lowest mean error: 2.8424482345581055 mm for frame 66

Saving results

Total time: 33.84718728065491
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00494405
Iteration 2/25 | Loss: 0.00102128
Iteration 3/25 | Loss: 0.00080556
Iteration 4/25 | Loss: 0.00077000
Iteration 5/25 | Loss: 0.00076107
Iteration 6/25 | Loss: 0.00075885
Iteration 7/25 | Loss: 0.00075847
Iteration 8/25 | Loss: 0.00075847
Iteration 9/25 | Loss: 0.00075847
Iteration 10/25 | Loss: 0.00075847
Iteration 11/25 | Loss: 0.00075847
Iteration 12/25 | Loss: 0.00075847
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007584702107124031, 0.0007584702107124031, 0.0007584702107124031, 0.0007584702107124031, 0.0007584702107124031]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007584702107124031

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.93593740
Iteration 2/25 | Loss: 0.00096821
Iteration 3/25 | Loss: 0.00096821
Iteration 4/25 | Loss: 0.00096821
Iteration 5/25 | Loss: 0.00096821
Iteration 6/25 | Loss: 0.00096821
Iteration 7/25 | Loss: 0.00096821
Iteration 8/25 | Loss: 0.00096821
Iteration 9/25 | Loss: 0.00096821
Iteration 10/25 | Loss: 0.00096821
Iteration 11/25 | Loss: 0.00096821
Iteration 12/25 | Loss: 0.00096821
Iteration 13/25 | Loss: 0.00096821
Iteration 14/25 | Loss: 0.00096821
Iteration 15/25 | Loss: 0.00096821
Iteration 16/25 | Loss: 0.00096821
Iteration 17/25 | Loss: 0.00096821
Iteration 18/25 | Loss: 0.00096821
Iteration 19/25 | Loss: 0.00096821
Iteration 20/25 | Loss: 0.00096821
Iteration 21/25 | Loss: 0.00096821
Iteration 22/25 | Loss: 0.00096821
Iteration 23/25 | Loss: 0.00096821
Iteration 24/25 | Loss: 0.00096821
Iteration 25/25 | Loss: 0.00096821

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00096821
Iteration 2/1000 | Loss: 0.00003157
Iteration 3/1000 | Loss: 0.00002147
Iteration 4/1000 | Loss: 0.00001990
Iteration 5/1000 | Loss: 0.00001874
Iteration 6/1000 | Loss: 0.00001809
Iteration 7/1000 | Loss: 0.00001752
Iteration 8/1000 | Loss: 0.00001713
Iteration 9/1000 | Loss: 0.00001688
Iteration 10/1000 | Loss: 0.00001670
Iteration 11/1000 | Loss: 0.00001652
Iteration 12/1000 | Loss: 0.00001638
Iteration 13/1000 | Loss: 0.00001623
Iteration 14/1000 | Loss: 0.00001620
Iteration 15/1000 | Loss: 0.00001619
Iteration 16/1000 | Loss: 0.00001614
Iteration 17/1000 | Loss: 0.00001614
Iteration 18/1000 | Loss: 0.00001612
Iteration 19/1000 | Loss: 0.00001611
Iteration 20/1000 | Loss: 0.00001611
Iteration 21/1000 | Loss: 0.00001610
Iteration 22/1000 | Loss: 0.00001610
Iteration 23/1000 | Loss: 0.00001609
Iteration 24/1000 | Loss: 0.00001609
Iteration 25/1000 | Loss: 0.00001609
Iteration 26/1000 | Loss: 0.00001609
Iteration 27/1000 | Loss: 0.00001608
Iteration 28/1000 | Loss: 0.00001608
Iteration 29/1000 | Loss: 0.00001606
Iteration 30/1000 | Loss: 0.00001602
Iteration 31/1000 | Loss: 0.00001602
Iteration 32/1000 | Loss: 0.00001601
Iteration 33/1000 | Loss: 0.00001600
Iteration 34/1000 | Loss: 0.00001600
Iteration 35/1000 | Loss: 0.00001594
Iteration 36/1000 | Loss: 0.00001594
Iteration 37/1000 | Loss: 0.00001594
Iteration 38/1000 | Loss: 0.00001594
Iteration 39/1000 | Loss: 0.00001593
Iteration 40/1000 | Loss: 0.00001593
Iteration 41/1000 | Loss: 0.00001593
Iteration 42/1000 | Loss: 0.00001593
Iteration 43/1000 | Loss: 0.00001593
Iteration 44/1000 | Loss: 0.00001593
Iteration 45/1000 | Loss: 0.00001593
Iteration 46/1000 | Loss: 0.00001592
Iteration 47/1000 | Loss: 0.00001592
Iteration 48/1000 | Loss: 0.00001592
Iteration 49/1000 | Loss: 0.00001591
Iteration 50/1000 | Loss: 0.00001590
Iteration 51/1000 | Loss: 0.00001590
Iteration 52/1000 | Loss: 0.00001589
Iteration 53/1000 | Loss: 0.00001589
Iteration 54/1000 | Loss: 0.00001588
Iteration 55/1000 | Loss: 0.00001588
Iteration 56/1000 | Loss: 0.00001588
Iteration 57/1000 | Loss: 0.00001588
Iteration 58/1000 | Loss: 0.00001588
Iteration 59/1000 | Loss: 0.00001587
Iteration 60/1000 | Loss: 0.00001587
Iteration 61/1000 | Loss: 0.00001587
Iteration 62/1000 | Loss: 0.00001587
Iteration 63/1000 | Loss: 0.00001587
Iteration 64/1000 | Loss: 0.00001587
Iteration 65/1000 | Loss: 0.00001586
Iteration 66/1000 | Loss: 0.00001586
Iteration 67/1000 | Loss: 0.00001586
Iteration 68/1000 | Loss: 0.00001585
Iteration 69/1000 | Loss: 0.00001585
Iteration 70/1000 | Loss: 0.00001585
Iteration 71/1000 | Loss: 0.00001585
Iteration 72/1000 | Loss: 0.00001584
Iteration 73/1000 | Loss: 0.00001584
Iteration 74/1000 | Loss: 0.00001584
Iteration 75/1000 | Loss: 0.00001584
Iteration 76/1000 | Loss: 0.00001584
Iteration 77/1000 | Loss: 0.00001584
Iteration 78/1000 | Loss: 0.00001583
Iteration 79/1000 | Loss: 0.00001583
Iteration 80/1000 | Loss: 0.00001583
Iteration 81/1000 | Loss: 0.00001583
Iteration 82/1000 | Loss: 0.00001583
Iteration 83/1000 | Loss: 0.00001583
Iteration 84/1000 | Loss: 0.00001583
Iteration 85/1000 | Loss: 0.00001582
Iteration 86/1000 | Loss: 0.00001582
Iteration 87/1000 | Loss: 0.00001582
Iteration 88/1000 | Loss: 0.00001582
Iteration 89/1000 | Loss: 0.00001582
Iteration 90/1000 | Loss: 0.00001582
Iteration 91/1000 | Loss: 0.00001582
Iteration 92/1000 | Loss: 0.00001581
Iteration 93/1000 | Loss: 0.00001581
Iteration 94/1000 | Loss: 0.00001581
Iteration 95/1000 | Loss: 0.00001581
Iteration 96/1000 | Loss: 0.00001580
Iteration 97/1000 | Loss: 0.00001580
Iteration 98/1000 | Loss: 0.00001580
Iteration 99/1000 | Loss: 0.00001580
Iteration 100/1000 | Loss: 0.00001580
Iteration 101/1000 | Loss: 0.00001579
Iteration 102/1000 | Loss: 0.00001579
Iteration 103/1000 | Loss: 0.00001579
Iteration 104/1000 | Loss: 0.00001579
Iteration 105/1000 | Loss: 0.00001579
Iteration 106/1000 | Loss: 0.00001579
Iteration 107/1000 | Loss: 0.00001579
Iteration 108/1000 | Loss: 0.00001578
Iteration 109/1000 | Loss: 0.00001578
Iteration 110/1000 | Loss: 0.00001578
Iteration 111/1000 | Loss: 0.00001578
Iteration 112/1000 | Loss: 0.00001578
Iteration 113/1000 | Loss: 0.00001578
Iteration 114/1000 | Loss: 0.00001578
Iteration 115/1000 | Loss: 0.00001577
Iteration 116/1000 | Loss: 0.00001577
Iteration 117/1000 | Loss: 0.00001577
Iteration 118/1000 | Loss: 0.00001577
Iteration 119/1000 | Loss: 0.00001577
Iteration 120/1000 | Loss: 0.00001577
Iteration 121/1000 | Loss: 0.00001577
Iteration 122/1000 | Loss: 0.00001576
Iteration 123/1000 | Loss: 0.00001576
Iteration 124/1000 | Loss: 0.00001576
Iteration 125/1000 | Loss: 0.00001576
Iteration 126/1000 | Loss: 0.00001576
Iteration 127/1000 | Loss: 0.00001576
Iteration 128/1000 | Loss: 0.00001575
Iteration 129/1000 | Loss: 0.00001575
Iteration 130/1000 | Loss: 0.00001575
Iteration 131/1000 | Loss: 0.00001575
Iteration 132/1000 | Loss: 0.00001575
Iteration 133/1000 | Loss: 0.00001575
Iteration 134/1000 | Loss: 0.00001575
Iteration 135/1000 | Loss: 0.00001575
Iteration 136/1000 | Loss: 0.00001575
Iteration 137/1000 | Loss: 0.00001575
Iteration 138/1000 | Loss: 0.00001575
Iteration 139/1000 | Loss: 0.00001575
Iteration 140/1000 | Loss: 0.00001574
Iteration 141/1000 | Loss: 0.00001574
Iteration 142/1000 | Loss: 0.00001574
Iteration 143/1000 | Loss: 0.00001574
Iteration 144/1000 | Loss: 0.00001574
Iteration 145/1000 | Loss: 0.00001574
Iteration 146/1000 | Loss: 0.00001574
Iteration 147/1000 | Loss: 0.00001574
Iteration 148/1000 | Loss: 0.00001574
Iteration 149/1000 | Loss: 0.00001573
Iteration 150/1000 | Loss: 0.00001573
Iteration 151/1000 | Loss: 0.00001573
Iteration 152/1000 | Loss: 0.00001573
Iteration 153/1000 | Loss: 0.00001573
Iteration 154/1000 | Loss: 0.00001573
Iteration 155/1000 | Loss: 0.00001573
Iteration 156/1000 | Loss: 0.00001573
Iteration 157/1000 | Loss: 0.00001573
Iteration 158/1000 | Loss: 0.00001573
Iteration 159/1000 | Loss: 0.00001573
Iteration 160/1000 | Loss: 0.00001572
Iteration 161/1000 | Loss: 0.00001572
Iteration 162/1000 | Loss: 0.00001572
Iteration 163/1000 | Loss: 0.00001572
Iteration 164/1000 | Loss: 0.00001572
Iteration 165/1000 | Loss: 0.00001572
Iteration 166/1000 | Loss: 0.00001572
Iteration 167/1000 | Loss: 0.00001572
Iteration 168/1000 | Loss: 0.00001572
Iteration 169/1000 | Loss: 0.00001572
Iteration 170/1000 | Loss: 0.00001572
Iteration 171/1000 | Loss: 0.00001572
Iteration 172/1000 | Loss: 0.00001572
Iteration 173/1000 | Loss: 0.00001572
Iteration 174/1000 | Loss: 0.00001572
Iteration 175/1000 | Loss: 0.00001572
Iteration 176/1000 | Loss: 0.00001572
Iteration 177/1000 | Loss: 0.00001572
Iteration 178/1000 | Loss: 0.00001572
Iteration 179/1000 | Loss: 0.00001571
Iteration 180/1000 | Loss: 0.00001571
Iteration 181/1000 | Loss: 0.00001571
Iteration 182/1000 | Loss: 0.00001571
Iteration 183/1000 | Loss: 0.00001571
Iteration 184/1000 | Loss: 0.00001571
Iteration 185/1000 | Loss: 0.00001571
Iteration 186/1000 | Loss: 0.00001571
Iteration 187/1000 | Loss: 0.00001571
Iteration 188/1000 | Loss: 0.00001571
Iteration 189/1000 | Loss: 0.00001571
Iteration 190/1000 | Loss: 0.00001571
Iteration 191/1000 | Loss: 0.00001571
Iteration 192/1000 | Loss: 0.00001571
Iteration 193/1000 | Loss: 0.00001571
Iteration 194/1000 | Loss: 0.00001571
Iteration 195/1000 | Loss: 0.00001571
Iteration 196/1000 | Loss: 0.00001571
Iteration 197/1000 | Loss: 0.00001571
Iteration 198/1000 | Loss: 0.00001571
Iteration 199/1000 | Loss: 0.00001571
Iteration 200/1000 | Loss: 0.00001571
Iteration 201/1000 | Loss: 0.00001571
Iteration 202/1000 | Loss: 0.00001571
Iteration 203/1000 | Loss: 0.00001571
Iteration 204/1000 | Loss: 0.00001571
Iteration 205/1000 | Loss: 0.00001571
Iteration 206/1000 | Loss: 0.00001571
Iteration 207/1000 | Loss: 0.00001571
Iteration 208/1000 | Loss: 0.00001571
Iteration 209/1000 | Loss: 0.00001571
Iteration 210/1000 | Loss: 0.00001571
Iteration 211/1000 | Loss: 0.00001571
Iteration 212/1000 | Loss: 0.00001571
Iteration 213/1000 | Loss: 0.00001571
Iteration 214/1000 | Loss: 0.00001571
Iteration 215/1000 | Loss: 0.00001571
Iteration 216/1000 | Loss: 0.00001571
Iteration 217/1000 | Loss: 0.00001571
Iteration 218/1000 | Loss: 0.00001571
Iteration 219/1000 | Loss: 0.00001571
Iteration 220/1000 | Loss: 0.00001571
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 220. Stopping optimization.
Last 5 losses: [1.5705611076555215e-05, 1.5705611076555215e-05, 1.5705611076555215e-05, 1.5705611076555215e-05, 1.5705611076555215e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5705611076555215e-05

Optimization complete. Final v2v error: 3.3514044284820557 mm

Highest mean error: 3.8402199745178223 mm for frame 4

Lowest mean error: 3.2615344524383545 mm for frame 103

Saving results

Total time: 51.91970348358154
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00360764
Iteration 2/25 | Loss: 0.00079581
Iteration 3/25 | Loss: 0.00071013
Iteration 4/25 | Loss: 0.00069712
Iteration 5/25 | Loss: 0.00069325
Iteration 6/25 | Loss: 0.00069183
Iteration 7/25 | Loss: 0.00069153
Iteration 8/25 | Loss: 0.00069151
Iteration 9/25 | Loss: 0.00069151
Iteration 10/25 | Loss: 0.00069151
Iteration 11/25 | Loss: 0.00069151
Iteration 12/25 | Loss: 0.00069151
Iteration 13/25 | Loss: 0.00069151
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006915091653354466, 0.0006915091653354466, 0.0006915091653354466, 0.0006915091653354466, 0.0006915091653354466]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006915091653354466

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66597414
Iteration 2/25 | Loss: 0.00121286
Iteration 3/25 | Loss: 0.00121286
Iteration 4/25 | Loss: 0.00121286
Iteration 5/25 | Loss: 0.00121286
Iteration 6/25 | Loss: 0.00121286
Iteration 7/25 | Loss: 0.00121286
Iteration 8/25 | Loss: 0.00121286
Iteration 9/25 | Loss: 0.00121286
Iteration 10/25 | Loss: 0.00121286
Iteration 11/25 | Loss: 0.00121286
Iteration 12/25 | Loss: 0.00121285
Iteration 13/25 | Loss: 0.00121285
Iteration 14/25 | Loss: 0.00121285
Iteration 15/25 | Loss: 0.00121285
Iteration 16/25 | Loss: 0.00121285
Iteration 17/25 | Loss: 0.00121285
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012128549860790372, 0.0012128549860790372, 0.0012128549860790372, 0.0012128549860790372, 0.0012128549860790372]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012128549860790372

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00121285
Iteration 2/1000 | Loss: 0.00002018
Iteration 3/1000 | Loss: 0.00001300
Iteration 4/1000 | Loss: 0.00001199
Iteration 5/1000 | Loss: 0.00001123
Iteration 6/1000 | Loss: 0.00001100
Iteration 7/1000 | Loss: 0.00001065
Iteration 8/1000 | Loss: 0.00001057
Iteration 9/1000 | Loss: 0.00001053
Iteration 10/1000 | Loss: 0.00001051
Iteration 11/1000 | Loss: 0.00001041
Iteration 12/1000 | Loss: 0.00001041
Iteration 13/1000 | Loss: 0.00001041
Iteration 14/1000 | Loss: 0.00001035
Iteration 15/1000 | Loss: 0.00001034
Iteration 16/1000 | Loss: 0.00001025
Iteration 17/1000 | Loss: 0.00001024
Iteration 18/1000 | Loss: 0.00001024
Iteration 19/1000 | Loss: 0.00001024
Iteration 20/1000 | Loss: 0.00001023
Iteration 21/1000 | Loss: 0.00001022
Iteration 22/1000 | Loss: 0.00001021
Iteration 23/1000 | Loss: 0.00001018
Iteration 24/1000 | Loss: 0.00001018
Iteration 25/1000 | Loss: 0.00001018
Iteration 26/1000 | Loss: 0.00001018
Iteration 27/1000 | Loss: 0.00001018
Iteration 28/1000 | Loss: 0.00001018
Iteration 29/1000 | Loss: 0.00001018
Iteration 30/1000 | Loss: 0.00001017
Iteration 31/1000 | Loss: 0.00001017
Iteration 32/1000 | Loss: 0.00001014
Iteration 33/1000 | Loss: 0.00001013
Iteration 34/1000 | Loss: 0.00001013
Iteration 35/1000 | Loss: 0.00001013
Iteration 36/1000 | Loss: 0.00001013
Iteration 37/1000 | Loss: 0.00001013
Iteration 38/1000 | Loss: 0.00001012
Iteration 39/1000 | Loss: 0.00001012
Iteration 40/1000 | Loss: 0.00001010
Iteration 41/1000 | Loss: 0.00001009
Iteration 42/1000 | Loss: 0.00001009
Iteration 43/1000 | Loss: 0.00001009
Iteration 44/1000 | Loss: 0.00001008
Iteration 45/1000 | Loss: 0.00001008
Iteration 46/1000 | Loss: 0.00001007
Iteration 47/1000 | Loss: 0.00001007
Iteration 48/1000 | Loss: 0.00001006
Iteration 49/1000 | Loss: 0.00001006
Iteration 50/1000 | Loss: 0.00001006
Iteration 51/1000 | Loss: 0.00001006
Iteration 52/1000 | Loss: 0.00001006
Iteration 53/1000 | Loss: 0.00001005
Iteration 54/1000 | Loss: 0.00001005
Iteration 55/1000 | Loss: 0.00001004
Iteration 56/1000 | Loss: 0.00001004
Iteration 57/1000 | Loss: 0.00001003
Iteration 58/1000 | Loss: 0.00001003
Iteration 59/1000 | Loss: 0.00001002
Iteration 60/1000 | Loss: 0.00001002
Iteration 61/1000 | Loss: 0.00001002
Iteration 62/1000 | Loss: 0.00001001
Iteration 63/1000 | Loss: 0.00001001
Iteration 64/1000 | Loss: 0.00001001
Iteration 65/1000 | Loss: 0.00001001
Iteration 66/1000 | Loss: 0.00001000
Iteration 67/1000 | Loss: 0.00001000
Iteration 68/1000 | Loss: 0.00001000
Iteration 69/1000 | Loss: 0.00001000
Iteration 70/1000 | Loss: 0.00000999
Iteration 71/1000 | Loss: 0.00000999
Iteration 72/1000 | Loss: 0.00000999
Iteration 73/1000 | Loss: 0.00000999
Iteration 74/1000 | Loss: 0.00000999
Iteration 75/1000 | Loss: 0.00000999
Iteration 76/1000 | Loss: 0.00000999
Iteration 77/1000 | Loss: 0.00000998
Iteration 78/1000 | Loss: 0.00000998
Iteration 79/1000 | Loss: 0.00000998
Iteration 80/1000 | Loss: 0.00000998
Iteration 81/1000 | Loss: 0.00000998
Iteration 82/1000 | Loss: 0.00000997
Iteration 83/1000 | Loss: 0.00000997
Iteration 84/1000 | Loss: 0.00000997
Iteration 85/1000 | Loss: 0.00000997
Iteration 86/1000 | Loss: 0.00000997
Iteration 87/1000 | Loss: 0.00000997
Iteration 88/1000 | Loss: 0.00000997
Iteration 89/1000 | Loss: 0.00000997
Iteration 90/1000 | Loss: 0.00000997
Iteration 91/1000 | Loss: 0.00000996
Iteration 92/1000 | Loss: 0.00000996
Iteration 93/1000 | Loss: 0.00000996
Iteration 94/1000 | Loss: 0.00000996
Iteration 95/1000 | Loss: 0.00000996
Iteration 96/1000 | Loss: 0.00000996
Iteration 97/1000 | Loss: 0.00000996
Iteration 98/1000 | Loss: 0.00000996
Iteration 99/1000 | Loss: 0.00000996
Iteration 100/1000 | Loss: 0.00000995
Iteration 101/1000 | Loss: 0.00000995
Iteration 102/1000 | Loss: 0.00000995
Iteration 103/1000 | Loss: 0.00000995
Iteration 104/1000 | Loss: 0.00000994
Iteration 105/1000 | Loss: 0.00000994
Iteration 106/1000 | Loss: 0.00000994
Iteration 107/1000 | Loss: 0.00000994
Iteration 108/1000 | Loss: 0.00000994
Iteration 109/1000 | Loss: 0.00000994
Iteration 110/1000 | Loss: 0.00000994
Iteration 111/1000 | Loss: 0.00000994
Iteration 112/1000 | Loss: 0.00000994
Iteration 113/1000 | Loss: 0.00000993
Iteration 114/1000 | Loss: 0.00000993
Iteration 115/1000 | Loss: 0.00000993
Iteration 116/1000 | Loss: 0.00000993
Iteration 117/1000 | Loss: 0.00000992
Iteration 118/1000 | Loss: 0.00000992
Iteration 119/1000 | Loss: 0.00000992
Iteration 120/1000 | Loss: 0.00000992
Iteration 121/1000 | Loss: 0.00000992
Iteration 122/1000 | Loss: 0.00000992
Iteration 123/1000 | Loss: 0.00000992
Iteration 124/1000 | Loss: 0.00000992
Iteration 125/1000 | Loss: 0.00000992
Iteration 126/1000 | Loss: 0.00000992
Iteration 127/1000 | Loss: 0.00000991
Iteration 128/1000 | Loss: 0.00000991
Iteration 129/1000 | Loss: 0.00000991
Iteration 130/1000 | Loss: 0.00000991
Iteration 131/1000 | Loss: 0.00000990
Iteration 132/1000 | Loss: 0.00000990
Iteration 133/1000 | Loss: 0.00000990
Iteration 134/1000 | Loss: 0.00000990
Iteration 135/1000 | Loss: 0.00000989
Iteration 136/1000 | Loss: 0.00000989
Iteration 137/1000 | Loss: 0.00000989
Iteration 138/1000 | Loss: 0.00000989
Iteration 139/1000 | Loss: 0.00000989
Iteration 140/1000 | Loss: 0.00000989
Iteration 141/1000 | Loss: 0.00000988
Iteration 142/1000 | Loss: 0.00000988
Iteration 143/1000 | Loss: 0.00000988
Iteration 144/1000 | Loss: 0.00000988
Iteration 145/1000 | Loss: 0.00000988
Iteration 146/1000 | Loss: 0.00000988
Iteration 147/1000 | Loss: 0.00000988
Iteration 148/1000 | Loss: 0.00000988
Iteration 149/1000 | Loss: 0.00000988
Iteration 150/1000 | Loss: 0.00000988
Iteration 151/1000 | Loss: 0.00000988
Iteration 152/1000 | Loss: 0.00000988
Iteration 153/1000 | Loss: 0.00000988
Iteration 154/1000 | Loss: 0.00000988
Iteration 155/1000 | Loss: 0.00000987
Iteration 156/1000 | Loss: 0.00000987
Iteration 157/1000 | Loss: 0.00000987
Iteration 158/1000 | Loss: 0.00000987
Iteration 159/1000 | Loss: 0.00000987
Iteration 160/1000 | Loss: 0.00000987
Iteration 161/1000 | Loss: 0.00000987
Iteration 162/1000 | Loss: 0.00000987
Iteration 163/1000 | Loss: 0.00000987
Iteration 164/1000 | Loss: 0.00000987
Iteration 165/1000 | Loss: 0.00000987
Iteration 166/1000 | Loss: 0.00000987
Iteration 167/1000 | Loss: 0.00000987
Iteration 168/1000 | Loss: 0.00000987
Iteration 169/1000 | Loss: 0.00000987
Iteration 170/1000 | Loss: 0.00000987
Iteration 171/1000 | Loss: 0.00000987
Iteration 172/1000 | Loss: 0.00000987
Iteration 173/1000 | Loss: 0.00000987
Iteration 174/1000 | Loss: 0.00000987
Iteration 175/1000 | Loss: 0.00000987
Iteration 176/1000 | Loss: 0.00000987
Iteration 177/1000 | Loss: 0.00000986
Iteration 178/1000 | Loss: 0.00000986
Iteration 179/1000 | Loss: 0.00000986
Iteration 180/1000 | Loss: 0.00000986
Iteration 181/1000 | Loss: 0.00000986
Iteration 182/1000 | Loss: 0.00000986
Iteration 183/1000 | Loss: 0.00000986
Iteration 184/1000 | Loss: 0.00000986
Iteration 185/1000 | Loss: 0.00000986
Iteration 186/1000 | Loss: 0.00000986
Iteration 187/1000 | Loss: 0.00000986
Iteration 188/1000 | Loss: 0.00000986
Iteration 189/1000 | Loss: 0.00000986
Iteration 190/1000 | Loss: 0.00000985
Iteration 191/1000 | Loss: 0.00000985
Iteration 192/1000 | Loss: 0.00000985
Iteration 193/1000 | Loss: 0.00000985
Iteration 194/1000 | Loss: 0.00000985
Iteration 195/1000 | Loss: 0.00000985
Iteration 196/1000 | Loss: 0.00000985
Iteration 197/1000 | Loss: 0.00000985
Iteration 198/1000 | Loss: 0.00000985
Iteration 199/1000 | Loss: 0.00000985
Iteration 200/1000 | Loss: 0.00000985
Iteration 201/1000 | Loss: 0.00000985
Iteration 202/1000 | Loss: 0.00000985
Iteration 203/1000 | Loss: 0.00000985
Iteration 204/1000 | Loss: 0.00000985
Iteration 205/1000 | Loss: 0.00000985
Iteration 206/1000 | Loss: 0.00000985
Iteration 207/1000 | Loss: 0.00000985
Iteration 208/1000 | Loss: 0.00000985
Iteration 209/1000 | Loss: 0.00000985
Iteration 210/1000 | Loss: 0.00000985
Iteration 211/1000 | Loss: 0.00000985
Iteration 212/1000 | Loss: 0.00000985
Iteration 213/1000 | Loss: 0.00000985
Iteration 214/1000 | Loss: 0.00000985
Iteration 215/1000 | Loss: 0.00000985
Iteration 216/1000 | Loss: 0.00000985
Iteration 217/1000 | Loss: 0.00000985
Iteration 218/1000 | Loss: 0.00000985
Iteration 219/1000 | Loss: 0.00000985
Iteration 220/1000 | Loss: 0.00000985
Iteration 221/1000 | Loss: 0.00000985
Iteration 222/1000 | Loss: 0.00000985
Iteration 223/1000 | Loss: 0.00000985
Iteration 224/1000 | Loss: 0.00000985
Iteration 225/1000 | Loss: 0.00000985
Iteration 226/1000 | Loss: 0.00000985
Iteration 227/1000 | Loss: 0.00000985
Iteration 228/1000 | Loss: 0.00000985
Iteration 229/1000 | Loss: 0.00000985
Iteration 230/1000 | Loss: 0.00000985
Iteration 231/1000 | Loss: 0.00000985
Iteration 232/1000 | Loss: 0.00000985
Iteration 233/1000 | Loss: 0.00000985
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 233. Stopping optimization.
Last 5 losses: [9.85233964456711e-06, 9.85233964456711e-06, 9.85233964456711e-06, 9.85233964456711e-06, 9.85233964456711e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.85233964456711e-06

Optimization complete. Final v2v error: 2.6913909912109375 mm

Highest mean error: 2.933647871017456 mm for frame 115

Lowest mean error: 2.6479287147521973 mm for frame 0

Saving results

Total time: 38.247384548187256
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00390651
Iteration 2/25 | Loss: 0.00086701
Iteration 3/25 | Loss: 0.00074940
Iteration 4/25 | Loss: 0.00073000
Iteration 5/25 | Loss: 0.00072414
Iteration 6/25 | Loss: 0.00072200
Iteration 7/25 | Loss: 0.00072157
Iteration 8/25 | Loss: 0.00072157
Iteration 9/25 | Loss: 0.00072157
Iteration 10/25 | Loss: 0.00072157
Iteration 11/25 | Loss: 0.00072157
Iteration 12/25 | Loss: 0.00072157
Iteration 13/25 | Loss: 0.00072157
Iteration 14/25 | Loss: 0.00072157
Iteration 15/25 | Loss: 0.00072157
Iteration 16/25 | Loss: 0.00072157
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007215691148303449, 0.0007215691148303449, 0.0007215691148303449, 0.0007215691148303449, 0.0007215691148303449]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007215691148303449

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58435845
Iteration 2/25 | Loss: 0.00123843
Iteration 3/25 | Loss: 0.00123843
Iteration 4/25 | Loss: 0.00123843
Iteration 5/25 | Loss: 0.00123843
Iteration 6/25 | Loss: 0.00123843
Iteration 7/25 | Loss: 0.00123843
Iteration 8/25 | Loss: 0.00123843
Iteration 9/25 | Loss: 0.00123843
Iteration 10/25 | Loss: 0.00123843
Iteration 11/25 | Loss: 0.00123843
Iteration 12/25 | Loss: 0.00123843
Iteration 13/25 | Loss: 0.00123843
Iteration 14/25 | Loss: 0.00123843
Iteration 15/25 | Loss: 0.00123843
Iteration 16/25 | Loss: 0.00123843
Iteration 17/25 | Loss: 0.00123843
Iteration 18/25 | Loss: 0.00123843
Iteration 19/25 | Loss: 0.00123843
Iteration 20/25 | Loss: 0.00123843
Iteration 21/25 | Loss: 0.00123843
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.001238425960764289, 0.001238425960764289, 0.001238425960764289, 0.001238425960764289, 0.001238425960764289]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001238425960764289

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00123843
Iteration 2/1000 | Loss: 0.00002323
Iteration 3/1000 | Loss: 0.00001664
Iteration 4/1000 | Loss: 0.00001520
Iteration 5/1000 | Loss: 0.00001414
Iteration 6/1000 | Loss: 0.00001377
Iteration 7/1000 | Loss: 0.00001339
Iteration 8/1000 | Loss: 0.00001328
Iteration 9/1000 | Loss: 0.00001302
Iteration 10/1000 | Loss: 0.00001282
Iteration 11/1000 | Loss: 0.00001274
Iteration 12/1000 | Loss: 0.00001272
Iteration 13/1000 | Loss: 0.00001271
Iteration 14/1000 | Loss: 0.00001261
Iteration 15/1000 | Loss: 0.00001258
Iteration 16/1000 | Loss: 0.00001258
Iteration 17/1000 | Loss: 0.00001258
Iteration 18/1000 | Loss: 0.00001257
Iteration 19/1000 | Loss: 0.00001254
Iteration 20/1000 | Loss: 0.00001254
Iteration 21/1000 | Loss: 0.00001252
Iteration 22/1000 | Loss: 0.00001252
Iteration 23/1000 | Loss: 0.00001251
Iteration 24/1000 | Loss: 0.00001250
Iteration 25/1000 | Loss: 0.00001249
Iteration 26/1000 | Loss: 0.00001248
Iteration 27/1000 | Loss: 0.00001248
Iteration 28/1000 | Loss: 0.00001248
Iteration 29/1000 | Loss: 0.00001247
Iteration 30/1000 | Loss: 0.00001247
Iteration 31/1000 | Loss: 0.00001247
Iteration 32/1000 | Loss: 0.00001247
Iteration 33/1000 | Loss: 0.00001247
Iteration 34/1000 | Loss: 0.00001247
Iteration 35/1000 | Loss: 0.00001246
Iteration 36/1000 | Loss: 0.00001246
Iteration 37/1000 | Loss: 0.00001245
Iteration 38/1000 | Loss: 0.00001244
Iteration 39/1000 | Loss: 0.00001244
Iteration 40/1000 | Loss: 0.00001244
Iteration 41/1000 | Loss: 0.00001244
Iteration 42/1000 | Loss: 0.00001244
Iteration 43/1000 | Loss: 0.00001244
Iteration 44/1000 | Loss: 0.00001244
Iteration 45/1000 | Loss: 0.00001244
Iteration 46/1000 | Loss: 0.00001244
Iteration 47/1000 | Loss: 0.00001244
Iteration 48/1000 | Loss: 0.00001244
Iteration 49/1000 | Loss: 0.00001244
Iteration 50/1000 | Loss: 0.00001244
Iteration 51/1000 | Loss: 0.00001244
Iteration 52/1000 | Loss: 0.00001244
Iteration 53/1000 | Loss: 0.00001244
Iteration 54/1000 | Loss: 0.00001244
Iteration 55/1000 | Loss: 0.00001244
Iteration 56/1000 | Loss: 0.00001244
Iteration 57/1000 | Loss: 0.00001244
Iteration 58/1000 | Loss: 0.00001244
Iteration 59/1000 | Loss: 0.00001244
Iteration 60/1000 | Loss: 0.00001244
Iteration 61/1000 | Loss: 0.00001244
Iteration 62/1000 | Loss: 0.00001244
Iteration 63/1000 | Loss: 0.00001244
Iteration 64/1000 | Loss: 0.00001244
Iteration 65/1000 | Loss: 0.00001244
Iteration 66/1000 | Loss: 0.00001244
Iteration 67/1000 | Loss: 0.00001244
Iteration 68/1000 | Loss: 0.00001244
Iteration 69/1000 | Loss: 0.00001244
Iteration 70/1000 | Loss: 0.00001244
Iteration 71/1000 | Loss: 0.00001244
Iteration 72/1000 | Loss: 0.00001244
Iteration 73/1000 | Loss: 0.00001244
Iteration 74/1000 | Loss: 0.00001244
Iteration 75/1000 | Loss: 0.00001244
Iteration 76/1000 | Loss: 0.00001244
Iteration 77/1000 | Loss: 0.00001244
Iteration 78/1000 | Loss: 0.00001244
Iteration 79/1000 | Loss: 0.00001244
Iteration 80/1000 | Loss: 0.00001244
Iteration 81/1000 | Loss: 0.00001244
Iteration 82/1000 | Loss: 0.00001244
Iteration 83/1000 | Loss: 0.00001244
Iteration 84/1000 | Loss: 0.00001244
Iteration 85/1000 | Loss: 0.00001244
Iteration 86/1000 | Loss: 0.00001244
Iteration 87/1000 | Loss: 0.00001244
Iteration 88/1000 | Loss: 0.00001244
Iteration 89/1000 | Loss: 0.00001244
Iteration 90/1000 | Loss: 0.00001244
Iteration 91/1000 | Loss: 0.00001244
Iteration 92/1000 | Loss: 0.00001244
Iteration 93/1000 | Loss: 0.00001244
Iteration 94/1000 | Loss: 0.00001244
Iteration 95/1000 | Loss: 0.00001244
Iteration 96/1000 | Loss: 0.00001244
Iteration 97/1000 | Loss: 0.00001244
Iteration 98/1000 | Loss: 0.00001244
Iteration 99/1000 | Loss: 0.00001244
Iteration 100/1000 | Loss: 0.00001244
Iteration 101/1000 | Loss: 0.00001244
Iteration 102/1000 | Loss: 0.00001244
Iteration 103/1000 | Loss: 0.00001244
Iteration 104/1000 | Loss: 0.00001244
Iteration 105/1000 | Loss: 0.00001244
Iteration 106/1000 | Loss: 0.00001244
Iteration 107/1000 | Loss: 0.00001244
Iteration 108/1000 | Loss: 0.00001244
Iteration 109/1000 | Loss: 0.00001244
Iteration 110/1000 | Loss: 0.00001244
Iteration 111/1000 | Loss: 0.00001244
Iteration 112/1000 | Loss: 0.00001244
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 112. Stopping optimization.
Last 5 losses: [1.2438899830158334e-05, 1.2438899830158334e-05, 1.2438899830158334e-05, 1.2438899830158334e-05, 1.2438899830158334e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2438899830158334e-05

Optimization complete. Final v2v error: 2.975924015045166 mm

Highest mean error: 3.1955435276031494 mm for frame 153

Lowest mean error: 2.823261260986328 mm for frame 258

Saving results

Total time: 35.59760117530823
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1028
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01058602
Iteration 2/25 | Loss: 0.01058602
Iteration 3/25 | Loss: 0.00325645
Iteration 4/25 | Loss: 0.00184673
Iteration 5/25 | Loss: 0.00158782
Iteration 6/25 | Loss: 0.00155678
Iteration 7/25 | Loss: 0.00161838
Iteration 8/25 | Loss: 0.00158484
Iteration 9/25 | Loss: 0.00149796
Iteration 10/25 | Loss: 0.00140531
Iteration 11/25 | Loss: 0.00134746
Iteration 12/25 | Loss: 0.00128244
Iteration 13/25 | Loss: 0.00123216
Iteration 14/25 | Loss: 0.00120792
Iteration 15/25 | Loss: 0.00121508
Iteration 16/25 | Loss: 0.00126202
Iteration 17/25 | Loss: 0.00125189
Iteration 18/25 | Loss: 0.00119469
Iteration 19/25 | Loss: 0.00115796
Iteration 20/25 | Loss: 0.00114052
Iteration 21/25 | Loss: 0.00112557
Iteration 22/25 | Loss: 0.00112815
Iteration 23/25 | Loss: 0.00113667
Iteration 24/25 | Loss: 0.00111528
Iteration 25/25 | Loss: 0.00110836

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58396494
Iteration 2/25 | Loss: 0.00344338
Iteration 3/25 | Loss: 0.00326797
Iteration 4/25 | Loss: 0.00326797
Iteration 5/25 | Loss: 0.00326797
Iteration 6/25 | Loss: 0.00326797
Iteration 7/25 | Loss: 0.00326797
Iteration 8/25 | Loss: 0.00326797
Iteration 9/25 | Loss: 0.00326797
Iteration 10/25 | Loss: 0.00326797
Iteration 11/25 | Loss: 0.00326797
Iteration 12/25 | Loss: 0.00326797
Iteration 13/25 | Loss: 0.00326797
Iteration 14/25 | Loss: 0.00326797
Iteration 15/25 | Loss: 0.00326797
Iteration 16/25 | Loss: 0.00326797
Iteration 17/25 | Loss: 0.00326797
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.003267967374995351, 0.003267967374995351, 0.003267967374995351, 0.003267967374995351, 0.003267967374995351]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003267967374995351

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00326797
Iteration 2/1000 | Loss: 0.00475930
Iteration 3/1000 | Loss: 0.00077511
Iteration 4/1000 | Loss: 0.00069514
Iteration 5/1000 | Loss: 0.00031223
Iteration 6/1000 | Loss: 0.00049673
Iteration 7/1000 | Loss: 0.00041462
Iteration 8/1000 | Loss: 0.00067763
Iteration 9/1000 | Loss: 0.00206077
Iteration 10/1000 | Loss: 0.00206980
Iteration 11/1000 | Loss: 0.00666640
Iteration 12/1000 | Loss: 0.00300176
Iteration 13/1000 | Loss: 0.00141313
Iteration 14/1000 | Loss: 0.00593202
Iteration 15/1000 | Loss: 0.00065723
Iteration 16/1000 | Loss: 0.00101078
Iteration 17/1000 | Loss: 0.00093699
Iteration 18/1000 | Loss: 0.00039194
Iteration 19/1000 | Loss: 0.00081856
Iteration 20/1000 | Loss: 0.00057175
Iteration 21/1000 | Loss: 0.00017623
Iteration 22/1000 | Loss: 0.00029138
Iteration 23/1000 | Loss: 0.00029526
Iteration 24/1000 | Loss: 0.00029713
Iteration 25/1000 | Loss: 0.00142143
Iteration 26/1000 | Loss: 0.00084912
Iteration 27/1000 | Loss: 0.00113995
Iteration 28/1000 | Loss: 0.00127955
Iteration 29/1000 | Loss: 0.00043436
Iteration 30/1000 | Loss: 0.00063437
Iteration 31/1000 | Loss: 0.00013095
Iteration 32/1000 | Loss: 0.00013923
Iteration 33/1000 | Loss: 0.00013373
Iteration 34/1000 | Loss: 0.00067921
Iteration 35/1000 | Loss: 0.00134644
Iteration 36/1000 | Loss: 0.00034332
Iteration 37/1000 | Loss: 0.00053350
Iteration 38/1000 | Loss: 0.00023379
Iteration 39/1000 | Loss: 0.00029610
Iteration 40/1000 | Loss: 0.00009424
Iteration 41/1000 | Loss: 0.00019607
Iteration 42/1000 | Loss: 0.00090644
Iteration 43/1000 | Loss: 0.00043818
Iteration 44/1000 | Loss: 0.00017039
Iteration 45/1000 | Loss: 0.00017339
Iteration 46/1000 | Loss: 0.00013229
Iteration 47/1000 | Loss: 0.00038458
Iteration 48/1000 | Loss: 0.00014644
Iteration 49/1000 | Loss: 0.00019026
Iteration 50/1000 | Loss: 0.00024474
Iteration 51/1000 | Loss: 0.00006960
Iteration 52/1000 | Loss: 0.00009869
Iteration 53/1000 | Loss: 0.00005302
Iteration 54/1000 | Loss: 0.00021208
Iteration 55/1000 | Loss: 0.00019412
Iteration 56/1000 | Loss: 0.00013472
Iteration 57/1000 | Loss: 0.00016916
Iteration 58/1000 | Loss: 0.00003837
Iteration 59/1000 | Loss: 0.00040594
Iteration 60/1000 | Loss: 0.00005627
Iteration 61/1000 | Loss: 0.00004608
Iteration 62/1000 | Loss: 0.00022585
Iteration 63/1000 | Loss: 0.00006252
Iteration 64/1000 | Loss: 0.00004789
Iteration 65/1000 | Loss: 0.00004571
Iteration 66/1000 | Loss: 0.00004282
Iteration 67/1000 | Loss: 0.00025801
Iteration 68/1000 | Loss: 0.00004611
Iteration 69/1000 | Loss: 0.00004196
Iteration 70/1000 | Loss: 0.00004151
Iteration 71/1000 | Loss: 0.00036835
Iteration 72/1000 | Loss: 0.00051633
Iteration 73/1000 | Loss: 0.00026473
Iteration 74/1000 | Loss: 0.00020797
Iteration 75/1000 | Loss: 0.00025094
Iteration 76/1000 | Loss: 0.00006207
Iteration 77/1000 | Loss: 0.00005031
Iteration 78/1000 | Loss: 0.00004901
Iteration 79/1000 | Loss: 0.00004756
Iteration 80/1000 | Loss: 0.00004359
Iteration 81/1000 | Loss: 0.00031353
Iteration 82/1000 | Loss: 0.00004884
Iteration 83/1000 | Loss: 0.00004399
Iteration 84/1000 | Loss: 0.00036751
Iteration 85/1000 | Loss: 0.00005401
Iteration 86/1000 | Loss: 0.00005650
Iteration 87/1000 | Loss: 0.00004182
Iteration 88/1000 | Loss: 0.00004037
Iteration 89/1000 | Loss: 0.00004221
Iteration 90/1000 | Loss: 0.00003716
Iteration 91/1000 | Loss: 0.00003771
Iteration 92/1000 | Loss: 0.00003354
Iteration 93/1000 | Loss: 0.00003174
Iteration 94/1000 | Loss: 0.00003220
Iteration 95/1000 | Loss: 0.00003217
Iteration 96/1000 | Loss: 0.00003024
Iteration 97/1000 | Loss: 0.00003786
Iteration 98/1000 | Loss: 0.00003638
Iteration 99/1000 | Loss: 0.00003325
Iteration 100/1000 | Loss: 0.00003270
Iteration 101/1000 | Loss: 0.00003710
Iteration 102/1000 | Loss: 0.00003162
Iteration 103/1000 | Loss: 0.00003605
Iteration 104/1000 | Loss: 0.00003809
Iteration 105/1000 | Loss: 0.00003335
Iteration 106/1000 | Loss: 0.00003821
Iteration 107/1000 | Loss: 0.00003236
Iteration 108/1000 | Loss: 0.00003133
Iteration 109/1000 | Loss: 0.00002301
Iteration 110/1000 | Loss: 0.00002126
Iteration 111/1000 | Loss: 0.00002071
Iteration 112/1000 | Loss: 0.00002022
Iteration 113/1000 | Loss: 0.00001993
Iteration 114/1000 | Loss: 0.00001975
Iteration 115/1000 | Loss: 0.00001975
Iteration 116/1000 | Loss: 0.00001971
Iteration 117/1000 | Loss: 0.00001971
Iteration 118/1000 | Loss: 0.00001970
Iteration 119/1000 | Loss: 0.00001970
Iteration 120/1000 | Loss: 0.00001969
Iteration 121/1000 | Loss: 0.00001969
Iteration 122/1000 | Loss: 0.00001968
Iteration 123/1000 | Loss: 0.00001967
Iteration 124/1000 | Loss: 0.00001967
Iteration 125/1000 | Loss: 0.00001967
Iteration 126/1000 | Loss: 0.00001967
Iteration 127/1000 | Loss: 0.00001966
Iteration 128/1000 | Loss: 0.00001966
Iteration 129/1000 | Loss: 0.00001966
Iteration 130/1000 | Loss: 0.00001966
Iteration 131/1000 | Loss: 0.00001966
Iteration 132/1000 | Loss: 0.00001966
Iteration 133/1000 | Loss: 0.00001966
Iteration 134/1000 | Loss: 0.00001966
Iteration 135/1000 | Loss: 0.00001966
Iteration 136/1000 | Loss: 0.00001966
Iteration 137/1000 | Loss: 0.00001965
Iteration 138/1000 | Loss: 0.00001965
Iteration 139/1000 | Loss: 0.00001965
Iteration 140/1000 | Loss: 0.00001965
Iteration 141/1000 | Loss: 0.00001965
Iteration 142/1000 | Loss: 0.00001965
Iteration 143/1000 | Loss: 0.00001965
Iteration 144/1000 | Loss: 0.00001965
Iteration 145/1000 | Loss: 0.00001965
Iteration 146/1000 | Loss: 0.00001965
Iteration 147/1000 | Loss: 0.00001964
Iteration 148/1000 | Loss: 0.00001962
Iteration 149/1000 | Loss: 0.00001962
Iteration 150/1000 | Loss: 0.00001962
Iteration 151/1000 | Loss: 0.00001961
Iteration 152/1000 | Loss: 0.00001961
Iteration 153/1000 | Loss: 0.00001961
Iteration 154/1000 | Loss: 0.00001960
Iteration 155/1000 | Loss: 0.00001960
Iteration 156/1000 | Loss: 0.00001960
Iteration 157/1000 | Loss: 0.00001959
Iteration 158/1000 | Loss: 0.00001959
Iteration 159/1000 | Loss: 0.00001958
Iteration 160/1000 | Loss: 0.00001957
Iteration 161/1000 | Loss: 0.00001957
Iteration 162/1000 | Loss: 0.00001956
Iteration 163/1000 | Loss: 0.00001956
Iteration 164/1000 | Loss: 0.00001955
Iteration 165/1000 | Loss: 0.00001953
Iteration 166/1000 | Loss: 0.00001953
Iteration 167/1000 | Loss: 0.00001953
Iteration 168/1000 | Loss: 0.00001953
Iteration 169/1000 | Loss: 0.00001953
Iteration 170/1000 | Loss: 0.00001952
Iteration 171/1000 | Loss: 0.00001950
Iteration 172/1000 | Loss: 0.00001950
Iteration 173/1000 | Loss: 0.00001949
Iteration 174/1000 | Loss: 0.00001948
Iteration 175/1000 | Loss: 0.00001948
Iteration 176/1000 | Loss: 0.00001948
Iteration 177/1000 | Loss: 0.00001947
Iteration 178/1000 | Loss: 0.00001947
Iteration 179/1000 | Loss: 0.00001947
Iteration 180/1000 | Loss: 0.00001946
Iteration 181/1000 | Loss: 0.00001946
Iteration 182/1000 | Loss: 0.00001945
Iteration 183/1000 | Loss: 0.00001945
Iteration 184/1000 | Loss: 0.00001945
Iteration 185/1000 | Loss: 0.00001945
Iteration 186/1000 | Loss: 0.00001945
Iteration 187/1000 | Loss: 0.00001945
Iteration 188/1000 | Loss: 0.00001945
Iteration 189/1000 | Loss: 0.00001945
Iteration 190/1000 | Loss: 0.00001944
Iteration 191/1000 | Loss: 0.00001944
Iteration 192/1000 | Loss: 0.00001944
Iteration 193/1000 | Loss: 0.00001944
Iteration 194/1000 | Loss: 0.00001944
Iteration 195/1000 | Loss: 0.00001943
Iteration 196/1000 | Loss: 0.00001943
Iteration 197/1000 | Loss: 0.00001943
Iteration 198/1000 | Loss: 0.00001943
Iteration 199/1000 | Loss: 0.00001943
Iteration 200/1000 | Loss: 0.00001943
Iteration 201/1000 | Loss: 0.00001943
Iteration 202/1000 | Loss: 0.00001943
Iteration 203/1000 | Loss: 0.00001942
Iteration 204/1000 | Loss: 0.00001942
Iteration 205/1000 | Loss: 0.00001942
Iteration 206/1000 | Loss: 0.00001942
Iteration 207/1000 | Loss: 0.00001942
Iteration 208/1000 | Loss: 0.00001942
Iteration 209/1000 | Loss: 0.00001942
Iteration 210/1000 | Loss: 0.00001942
Iteration 211/1000 | Loss: 0.00001942
Iteration 212/1000 | Loss: 0.00001942
Iteration 213/1000 | Loss: 0.00001942
Iteration 214/1000 | Loss: 0.00001942
Iteration 215/1000 | Loss: 0.00001941
Iteration 216/1000 | Loss: 0.00001941
Iteration 217/1000 | Loss: 0.00001941
Iteration 218/1000 | Loss: 0.00001941
Iteration 219/1000 | Loss: 0.00001941
Iteration 220/1000 | Loss: 0.00001941
Iteration 221/1000 | Loss: 0.00001941
Iteration 222/1000 | Loss: 0.00001941
Iteration 223/1000 | Loss: 0.00001941
Iteration 224/1000 | Loss: 0.00001941
Iteration 225/1000 | Loss: 0.00001941
Iteration 226/1000 | Loss: 0.00001941
Iteration 227/1000 | Loss: 0.00001941
Iteration 228/1000 | Loss: 0.00001941
Iteration 229/1000 | Loss: 0.00001941
Iteration 230/1000 | Loss: 0.00001941
Iteration 231/1000 | Loss: 0.00001941
Iteration 232/1000 | Loss: 0.00001941
Iteration 233/1000 | Loss: 0.00001941
Iteration 234/1000 | Loss: 0.00001941
Iteration 235/1000 | Loss: 0.00001940
Iteration 236/1000 | Loss: 0.00001940
Iteration 237/1000 | Loss: 0.00001940
Iteration 238/1000 | Loss: 0.00001940
Iteration 239/1000 | Loss: 0.00001940
Iteration 240/1000 | Loss: 0.00001940
Iteration 241/1000 | Loss: 0.00001940
Iteration 242/1000 | Loss: 0.00001940
Iteration 243/1000 | Loss: 0.00001939
Iteration 244/1000 | Loss: 0.00001939
Iteration 245/1000 | Loss: 0.00001939
Iteration 246/1000 | Loss: 0.00001939
Iteration 247/1000 | Loss: 0.00001939
Iteration 248/1000 | Loss: 0.00001939
Iteration 249/1000 | Loss: 0.00001939
Iteration 250/1000 | Loss: 0.00001939
Iteration 251/1000 | Loss: 0.00001939
Iteration 252/1000 | Loss: 0.00001939
Iteration 253/1000 | Loss: 0.00001939
Iteration 254/1000 | Loss: 0.00001939
Iteration 255/1000 | Loss: 0.00001939
Iteration 256/1000 | Loss: 0.00001939
Iteration 257/1000 | Loss: 0.00001938
Iteration 258/1000 | Loss: 0.00001938
Iteration 259/1000 | Loss: 0.00001938
Iteration 260/1000 | Loss: 0.00001938
Iteration 261/1000 | Loss: 0.00001938
Iteration 262/1000 | Loss: 0.00001938
Iteration 263/1000 | Loss: 0.00001938
Iteration 264/1000 | Loss: 0.00001938
Iteration 265/1000 | Loss: 0.00001938
Iteration 266/1000 | Loss: 0.00001938
Iteration 267/1000 | Loss: 0.00001938
Iteration 268/1000 | Loss: 0.00001938
Iteration 269/1000 | Loss: 0.00001938
Iteration 270/1000 | Loss: 0.00001938
Iteration 271/1000 | Loss: 0.00001938
Iteration 272/1000 | Loss: 0.00001938
Iteration 273/1000 | Loss: 0.00001938
Iteration 274/1000 | Loss: 0.00001938
Iteration 275/1000 | Loss: 0.00001938
Iteration 276/1000 | Loss: 0.00001938
Iteration 277/1000 | Loss: 0.00001938
Iteration 278/1000 | Loss: 0.00001938
Iteration 279/1000 | Loss: 0.00001938
Iteration 280/1000 | Loss: 0.00001938
Iteration 281/1000 | Loss: 0.00001937
Iteration 282/1000 | Loss: 0.00001937
Iteration 283/1000 | Loss: 0.00001937
Iteration 284/1000 | Loss: 0.00001937
Iteration 285/1000 | Loss: 0.00001937
Iteration 286/1000 | Loss: 0.00001937
Iteration 287/1000 | Loss: 0.00001937
Iteration 288/1000 | Loss: 0.00001937
Iteration 289/1000 | Loss: 0.00001937
Iteration 290/1000 | Loss: 0.00001937
Iteration 291/1000 | Loss: 0.00001937
Iteration 292/1000 | Loss: 0.00001937
Iteration 293/1000 | Loss: 0.00001937
Iteration 294/1000 | Loss: 0.00001937
Iteration 295/1000 | Loss: 0.00001937
Iteration 296/1000 | Loss: 0.00001936
Iteration 297/1000 | Loss: 0.00001936
Iteration 298/1000 | Loss: 0.00001936
Iteration 299/1000 | Loss: 0.00001936
Iteration 300/1000 | Loss: 0.00001936
Iteration 301/1000 | Loss: 0.00001936
Iteration 302/1000 | Loss: 0.00001936
Iteration 303/1000 | Loss: 0.00001936
Iteration 304/1000 | Loss: 0.00001936
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 304. Stopping optimization.
Last 5 losses: [1.9362774764886126e-05, 1.9362774764886126e-05, 1.9362774764886126e-05, 1.9362774764886126e-05, 1.9362774764886126e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9362774764886126e-05

Optimization complete. Final v2v error: 3.669302463531494 mm

Highest mean error: 4.426926612854004 mm for frame 140

Lowest mean error: 3.3999853134155273 mm for frame 201

Saving results

Total time: 245.9975187778473
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1071/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1071.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1071
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00425822
Iteration 2/25 | Loss: 0.00098569
Iteration 3/25 | Loss: 0.00077590
Iteration 4/25 | Loss: 0.00074319
Iteration 5/25 | Loss: 0.00073777
Iteration 6/25 | Loss: 0.00073624
Iteration 7/25 | Loss: 0.00073582
Iteration 8/25 | Loss: 0.00073582
Iteration 9/25 | Loss: 0.00073582
Iteration 10/25 | Loss: 0.00073582
Iteration 11/25 | Loss: 0.00073582
Iteration 12/25 | Loss: 0.00073582
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007358247530646622, 0.0007358247530646622, 0.0007358247530646622, 0.0007358247530646622, 0.0007358247530646622]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007358247530646622

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60616302
Iteration 2/25 | Loss: 0.00117321
Iteration 3/25 | Loss: 0.00117321
Iteration 4/25 | Loss: 0.00117320
Iteration 5/25 | Loss: 0.00117320
Iteration 6/25 | Loss: 0.00117320
Iteration 7/25 | Loss: 0.00117320
Iteration 8/25 | Loss: 0.00117320
Iteration 9/25 | Loss: 0.00117320
Iteration 10/25 | Loss: 0.00117320
Iteration 11/25 | Loss: 0.00117320
Iteration 12/25 | Loss: 0.00117320
Iteration 13/25 | Loss: 0.00117320
Iteration 14/25 | Loss: 0.00117320
Iteration 15/25 | Loss: 0.00117320
Iteration 16/25 | Loss: 0.00117320
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001173202646896243, 0.001173202646896243, 0.001173202646896243, 0.001173202646896243, 0.001173202646896243]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001173202646896243

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00117320
Iteration 2/1000 | Loss: 0.00002733
Iteration 3/1000 | Loss: 0.00001646
Iteration 4/1000 | Loss: 0.00001433
Iteration 5/1000 | Loss: 0.00001346
Iteration 6/1000 | Loss: 0.00001295
Iteration 7/1000 | Loss: 0.00001259
Iteration 8/1000 | Loss: 0.00001229
Iteration 9/1000 | Loss: 0.00001208
Iteration 10/1000 | Loss: 0.00001208
Iteration 11/1000 | Loss: 0.00001197
Iteration 12/1000 | Loss: 0.00001187
Iteration 13/1000 | Loss: 0.00001183
Iteration 14/1000 | Loss: 0.00001182
Iteration 15/1000 | Loss: 0.00001182
Iteration 16/1000 | Loss: 0.00001181
Iteration 17/1000 | Loss: 0.00001178
Iteration 18/1000 | Loss: 0.00001178
Iteration 19/1000 | Loss: 0.00001177
Iteration 20/1000 | Loss: 0.00001176
Iteration 21/1000 | Loss: 0.00001174
Iteration 22/1000 | Loss: 0.00001173
Iteration 23/1000 | Loss: 0.00001173
Iteration 24/1000 | Loss: 0.00001172
Iteration 25/1000 | Loss: 0.00001172
Iteration 26/1000 | Loss: 0.00001171
Iteration 27/1000 | Loss: 0.00001171
Iteration 28/1000 | Loss: 0.00001170
Iteration 29/1000 | Loss: 0.00001170
Iteration 30/1000 | Loss: 0.00001169
Iteration 31/1000 | Loss: 0.00001169
Iteration 32/1000 | Loss: 0.00001168
Iteration 33/1000 | Loss: 0.00001168
Iteration 34/1000 | Loss: 0.00001167
Iteration 35/1000 | Loss: 0.00001167
Iteration 36/1000 | Loss: 0.00001166
Iteration 37/1000 | Loss: 0.00001166
Iteration 38/1000 | Loss: 0.00001166
Iteration 39/1000 | Loss: 0.00001165
Iteration 40/1000 | Loss: 0.00001165
Iteration 41/1000 | Loss: 0.00001165
Iteration 42/1000 | Loss: 0.00001165
Iteration 43/1000 | Loss: 0.00001164
Iteration 44/1000 | Loss: 0.00001164
Iteration 45/1000 | Loss: 0.00001164
Iteration 46/1000 | Loss: 0.00001163
Iteration 47/1000 | Loss: 0.00001163
Iteration 48/1000 | Loss: 0.00001163
Iteration 49/1000 | Loss: 0.00001162
Iteration 50/1000 | Loss: 0.00001162
Iteration 51/1000 | Loss: 0.00001162
Iteration 52/1000 | Loss: 0.00001161
Iteration 53/1000 | Loss: 0.00001161
Iteration 54/1000 | Loss: 0.00001161
Iteration 55/1000 | Loss: 0.00001160
Iteration 56/1000 | Loss: 0.00001160
Iteration 57/1000 | Loss: 0.00001159
Iteration 58/1000 | Loss: 0.00001159
Iteration 59/1000 | Loss: 0.00001159
Iteration 60/1000 | Loss: 0.00001159
Iteration 61/1000 | Loss: 0.00001158
Iteration 62/1000 | Loss: 0.00001158
Iteration 63/1000 | Loss: 0.00001158
Iteration 64/1000 | Loss: 0.00001157
Iteration 65/1000 | Loss: 0.00001157
Iteration 66/1000 | Loss: 0.00001157
Iteration 67/1000 | Loss: 0.00001156
Iteration 68/1000 | Loss: 0.00001156
Iteration 69/1000 | Loss: 0.00001156
Iteration 70/1000 | Loss: 0.00001155
Iteration 71/1000 | Loss: 0.00001155
Iteration 72/1000 | Loss: 0.00001155
Iteration 73/1000 | Loss: 0.00001155
Iteration 74/1000 | Loss: 0.00001154
Iteration 75/1000 | Loss: 0.00001154
Iteration 76/1000 | Loss: 0.00001153
Iteration 77/1000 | Loss: 0.00001153
Iteration 78/1000 | Loss: 0.00001153
Iteration 79/1000 | Loss: 0.00001153
Iteration 80/1000 | Loss: 0.00001152
Iteration 81/1000 | Loss: 0.00001152
Iteration 82/1000 | Loss: 0.00001152
Iteration 83/1000 | Loss: 0.00001152
Iteration 84/1000 | Loss: 0.00001151
Iteration 85/1000 | Loss: 0.00001151
Iteration 86/1000 | Loss: 0.00001151
Iteration 87/1000 | Loss: 0.00001151
Iteration 88/1000 | Loss: 0.00001151
Iteration 89/1000 | Loss: 0.00001151
Iteration 90/1000 | Loss: 0.00001151
Iteration 91/1000 | Loss: 0.00001151
Iteration 92/1000 | Loss: 0.00001151
Iteration 93/1000 | Loss: 0.00001151
Iteration 94/1000 | Loss: 0.00001151
Iteration 95/1000 | Loss: 0.00001151
Iteration 96/1000 | Loss: 0.00001150
Iteration 97/1000 | Loss: 0.00001150
Iteration 98/1000 | Loss: 0.00001150
Iteration 99/1000 | Loss: 0.00001150
Iteration 100/1000 | Loss: 0.00001150
Iteration 101/1000 | Loss: 0.00001150
Iteration 102/1000 | Loss: 0.00001149
Iteration 103/1000 | Loss: 0.00001149
Iteration 104/1000 | Loss: 0.00001149
Iteration 105/1000 | Loss: 0.00001149
Iteration 106/1000 | Loss: 0.00001148
Iteration 107/1000 | Loss: 0.00001148
Iteration 108/1000 | Loss: 0.00001147
Iteration 109/1000 | Loss: 0.00001147
Iteration 110/1000 | Loss: 0.00001147
Iteration 111/1000 | Loss: 0.00001147
Iteration 112/1000 | Loss: 0.00001147
Iteration 113/1000 | Loss: 0.00001147
Iteration 114/1000 | Loss: 0.00001146
Iteration 115/1000 | Loss: 0.00001146
Iteration 116/1000 | Loss: 0.00001145
Iteration 117/1000 | Loss: 0.00001145
Iteration 118/1000 | Loss: 0.00001145
Iteration 119/1000 | Loss: 0.00001144
Iteration 120/1000 | Loss: 0.00001144
Iteration 121/1000 | Loss: 0.00001144
Iteration 122/1000 | Loss: 0.00001144
Iteration 123/1000 | Loss: 0.00001144
Iteration 124/1000 | Loss: 0.00001144
Iteration 125/1000 | Loss: 0.00001144
Iteration 126/1000 | Loss: 0.00001143
Iteration 127/1000 | Loss: 0.00001143
Iteration 128/1000 | Loss: 0.00001143
Iteration 129/1000 | Loss: 0.00001143
Iteration 130/1000 | Loss: 0.00001143
Iteration 131/1000 | Loss: 0.00001143
Iteration 132/1000 | Loss: 0.00001143
Iteration 133/1000 | Loss: 0.00001143
Iteration 134/1000 | Loss: 0.00001142
Iteration 135/1000 | Loss: 0.00001142
Iteration 136/1000 | Loss: 0.00001142
Iteration 137/1000 | Loss: 0.00001142
Iteration 138/1000 | Loss: 0.00001142
Iteration 139/1000 | Loss: 0.00001142
Iteration 140/1000 | Loss: 0.00001142
Iteration 141/1000 | Loss: 0.00001142
Iteration 142/1000 | Loss: 0.00001142
Iteration 143/1000 | Loss: 0.00001142
Iteration 144/1000 | Loss: 0.00001142
Iteration 145/1000 | Loss: 0.00001142
Iteration 146/1000 | Loss: 0.00001142
Iteration 147/1000 | Loss: 0.00001142
Iteration 148/1000 | Loss: 0.00001142
Iteration 149/1000 | Loss: 0.00001142
Iteration 150/1000 | Loss: 0.00001141
Iteration 151/1000 | Loss: 0.00001141
Iteration 152/1000 | Loss: 0.00001141
Iteration 153/1000 | Loss: 0.00001141
Iteration 154/1000 | Loss: 0.00001141
Iteration 155/1000 | Loss: 0.00001141
Iteration 156/1000 | Loss: 0.00001141
Iteration 157/1000 | Loss: 0.00001141
Iteration 158/1000 | Loss: 0.00001141
Iteration 159/1000 | Loss: 0.00001141
Iteration 160/1000 | Loss: 0.00001141
Iteration 161/1000 | Loss: 0.00001141
Iteration 162/1000 | Loss: 0.00001141
Iteration 163/1000 | Loss: 0.00001141
Iteration 164/1000 | Loss: 0.00001141
Iteration 165/1000 | Loss: 0.00001141
Iteration 166/1000 | Loss: 0.00001140
Iteration 167/1000 | Loss: 0.00001140
Iteration 168/1000 | Loss: 0.00001140
Iteration 169/1000 | Loss: 0.00001140
Iteration 170/1000 | Loss: 0.00001140
Iteration 171/1000 | Loss: 0.00001140
Iteration 172/1000 | Loss: 0.00001140
Iteration 173/1000 | Loss: 0.00001140
Iteration 174/1000 | Loss: 0.00001140
Iteration 175/1000 | Loss: 0.00001140
Iteration 176/1000 | Loss: 0.00001140
Iteration 177/1000 | Loss: 0.00001140
Iteration 178/1000 | Loss: 0.00001140
Iteration 179/1000 | Loss: 0.00001140
Iteration 180/1000 | Loss: 0.00001140
Iteration 181/1000 | Loss: 0.00001140
Iteration 182/1000 | Loss: 0.00001140
Iteration 183/1000 | Loss: 0.00001140
Iteration 184/1000 | Loss: 0.00001139
Iteration 185/1000 | Loss: 0.00001139
Iteration 186/1000 | Loss: 0.00001139
Iteration 187/1000 | Loss: 0.00001139
Iteration 188/1000 | Loss: 0.00001139
Iteration 189/1000 | Loss: 0.00001139
Iteration 190/1000 | Loss: 0.00001139
Iteration 191/1000 | Loss: 0.00001139
Iteration 192/1000 | Loss: 0.00001139
Iteration 193/1000 | Loss: 0.00001139
Iteration 194/1000 | Loss: 0.00001139
Iteration 195/1000 | Loss: 0.00001139
Iteration 196/1000 | Loss: 0.00001139
Iteration 197/1000 | Loss: 0.00001139
Iteration 198/1000 | Loss: 0.00001139
Iteration 199/1000 | Loss: 0.00001139
Iteration 200/1000 | Loss: 0.00001139
Iteration 201/1000 | Loss: 0.00001139
Iteration 202/1000 | Loss: 0.00001139
Iteration 203/1000 | Loss: 0.00001139
Iteration 204/1000 | Loss: 0.00001139
Iteration 205/1000 | Loss: 0.00001139
Iteration 206/1000 | Loss: 0.00001139
Iteration 207/1000 | Loss: 0.00001139
Iteration 208/1000 | Loss: 0.00001139
Iteration 209/1000 | Loss: 0.00001139
Iteration 210/1000 | Loss: 0.00001139
Iteration 211/1000 | Loss: 0.00001139
Iteration 212/1000 | Loss: 0.00001139
Iteration 213/1000 | Loss: 0.00001139
Iteration 214/1000 | Loss: 0.00001139
Iteration 215/1000 | Loss: 0.00001139
Iteration 216/1000 | Loss: 0.00001139
Iteration 217/1000 | Loss: 0.00001139
Iteration 218/1000 | Loss: 0.00001139
Iteration 219/1000 | Loss: 0.00001139
Iteration 220/1000 | Loss: 0.00001139
Iteration 221/1000 | Loss: 0.00001139
Iteration 222/1000 | Loss: 0.00001139
Iteration 223/1000 | Loss: 0.00001139
Iteration 224/1000 | Loss: 0.00001139
Iteration 225/1000 | Loss: 0.00001139
Iteration 226/1000 | Loss: 0.00001139
Iteration 227/1000 | Loss: 0.00001139
Iteration 228/1000 | Loss: 0.00001139
Iteration 229/1000 | Loss: 0.00001139
Iteration 230/1000 | Loss: 0.00001139
Iteration 231/1000 | Loss: 0.00001139
Iteration 232/1000 | Loss: 0.00001139
Iteration 233/1000 | Loss: 0.00001139
Iteration 234/1000 | Loss: 0.00001139
Iteration 235/1000 | Loss: 0.00001139
Iteration 236/1000 | Loss: 0.00001139
Iteration 237/1000 | Loss: 0.00001139
Iteration 238/1000 | Loss: 0.00001139
Iteration 239/1000 | Loss: 0.00001139
Iteration 240/1000 | Loss: 0.00001139
Iteration 241/1000 | Loss: 0.00001139
Iteration 242/1000 | Loss: 0.00001139
Iteration 243/1000 | Loss: 0.00001139
Iteration 244/1000 | Loss: 0.00001139
Iteration 245/1000 | Loss: 0.00001139
Iteration 246/1000 | Loss: 0.00001139
Iteration 247/1000 | Loss: 0.00001139
Iteration 248/1000 | Loss: 0.00001139
Iteration 249/1000 | Loss: 0.00001139
Iteration 250/1000 | Loss: 0.00001139
Iteration 251/1000 | Loss: 0.00001139
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 251. Stopping optimization.
Last 5 losses: [1.138857624027878e-05, 1.138857624027878e-05, 1.138857624027878e-05, 1.138857624027878e-05, 1.138857624027878e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.138857624027878e-05

Optimization complete. Final v2v error: 2.838604688644409 mm

Highest mean error: 4.094664096832275 mm for frame 55

Lowest mean error: 2.4768059253692627 mm for frame 36

Saving results

Total time: 39.70248365402222
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1085
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01111356
Iteration 2/25 | Loss: 0.00308108
Iteration 3/25 | Loss: 0.00180388
Iteration 4/25 | Loss: 0.00152127
Iteration 5/25 | Loss: 0.00144507
Iteration 6/25 | Loss: 0.00142289
Iteration 7/25 | Loss: 0.00139899
Iteration 8/25 | Loss: 0.00132555
Iteration 9/25 | Loss: 0.00132487
Iteration 10/25 | Loss: 0.00129976
Iteration 11/25 | Loss: 0.00128069
Iteration 12/25 | Loss: 0.00126506
Iteration 13/25 | Loss: 0.00125926
Iteration 14/25 | Loss: 0.00125428
Iteration 15/25 | Loss: 0.00124893
Iteration 16/25 | Loss: 0.00123479
Iteration 17/25 | Loss: 0.00122995
Iteration 18/25 | Loss: 0.00122848
Iteration 19/25 | Loss: 0.00122719
Iteration 20/25 | Loss: 0.00122687
Iteration 21/25 | Loss: 0.00122648
Iteration 22/25 | Loss: 0.00122621
Iteration 23/25 | Loss: 0.00122600
Iteration 24/25 | Loss: 0.00122578
Iteration 25/25 | Loss: 0.00122542

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.34661388
Iteration 2/25 | Loss: 0.00587003
Iteration 3/25 | Loss: 0.00483608
Iteration 4/25 | Loss: 0.00483608
Iteration 5/25 | Loss: 0.00483608
Iteration 6/25 | Loss: 0.00483607
Iteration 7/25 | Loss: 0.00483607
Iteration 8/25 | Loss: 0.00483607
Iteration 9/25 | Loss: 0.00483607
Iteration 10/25 | Loss: 0.00483607
Iteration 11/25 | Loss: 0.00483607
Iteration 12/25 | Loss: 0.00483607
Iteration 13/25 | Loss: 0.00483607
Iteration 14/25 | Loss: 0.00483607
Iteration 15/25 | Loss: 0.00483607
Iteration 16/25 | Loss: 0.00483607
Iteration 17/25 | Loss: 0.00483607
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00483607267960906, 0.00483607267960906, 0.00483607267960906, 0.00483607267960906, 0.00483607267960906]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00483607267960906

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00483607
Iteration 2/1000 | Loss: 0.00254266
Iteration 3/1000 | Loss: 0.00883209
Iteration 4/1000 | Loss: 0.00477178
Iteration 5/1000 | Loss: 0.00200055
Iteration 6/1000 | Loss: 0.00180887
Iteration 7/1000 | Loss: 0.00164117
Iteration 8/1000 | Loss: 0.00103244
Iteration 9/1000 | Loss: 0.00296234
Iteration 10/1000 | Loss: 0.00883018
Iteration 11/1000 | Loss: 0.00160689
Iteration 12/1000 | Loss: 0.00416790
Iteration 13/1000 | Loss: 0.00177481
Iteration 14/1000 | Loss: 0.00156299
Iteration 15/1000 | Loss: 0.00230686
Iteration 16/1000 | Loss: 0.00318579
Iteration 17/1000 | Loss: 0.00091807
Iteration 18/1000 | Loss: 0.00262721
Iteration 19/1000 | Loss: 0.00041495
Iteration 20/1000 | Loss: 0.00018746
Iteration 21/1000 | Loss: 0.00038767
Iteration 22/1000 | Loss: 0.00095130
Iteration 23/1000 | Loss: 0.00043888
Iteration 24/1000 | Loss: 0.00155859
Iteration 25/1000 | Loss: 0.00162039
Iteration 26/1000 | Loss: 0.00033932
Iteration 27/1000 | Loss: 0.00337696
Iteration 28/1000 | Loss: 0.00613266
Iteration 29/1000 | Loss: 0.00536617
Iteration 30/1000 | Loss: 0.00261462
Iteration 31/1000 | Loss: 0.00203324
Iteration 32/1000 | Loss: 0.00044455
Iteration 33/1000 | Loss: 0.00254620
Iteration 34/1000 | Loss: 0.00283924
Iteration 35/1000 | Loss: 0.00280437
Iteration 36/1000 | Loss: 0.00334925
Iteration 37/1000 | Loss: 0.00341004
Iteration 38/1000 | Loss: 0.00209099
Iteration 39/1000 | Loss: 0.00061271
Iteration 40/1000 | Loss: 0.00056924
Iteration 41/1000 | Loss: 0.00147560
Iteration 42/1000 | Loss: 0.00195393
Iteration 43/1000 | Loss: 0.00172574
Iteration 44/1000 | Loss: 0.00185333
Iteration 45/1000 | Loss: 0.00155977
Iteration 46/1000 | Loss: 0.00201009
Iteration 47/1000 | Loss: 0.00228094
Iteration 48/1000 | Loss: 0.00083780
Iteration 49/1000 | Loss: 0.00072674
Iteration 50/1000 | Loss: 0.00070496
Iteration 51/1000 | Loss: 0.00027626
Iteration 52/1000 | Loss: 0.00185380
Iteration 53/1000 | Loss: 0.00076099
Iteration 54/1000 | Loss: 0.00240907
Iteration 55/1000 | Loss: 0.00177326
Iteration 56/1000 | Loss: 0.00202478
Iteration 57/1000 | Loss: 0.00332513
Iteration 58/1000 | Loss: 0.00119209
Iteration 59/1000 | Loss: 0.00097202
Iteration 60/1000 | Loss: 0.00093036
Iteration 61/1000 | Loss: 0.00139065
Iteration 62/1000 | Loss: 0.00072256
Iteration 63/1000 | Loss: 0.00011510
Iteration 64/1000 | Loss: 0.00144179
Iteration 65/1000 | Loss: 0.00085628
Iteration 66/1000 | Loss: 0.00117075
Iteration 67/1000 | Loss: 0.00068678
Iteration 68/1000 | Loss: 0.00092971
Iteration 69/1000 | Loss: 0.00090184
Iteration 70/1000 | Loss: 0.00140145
Iteration 71/1000 | Loss: 0.00076847
Iteration 72/1000 | Loss: 0.00132816
Iteration 73/1000 | Loss: 0.00068897
Iteration 74/1000 | Loss: 0.00009235
Iteration 75/1000 | Loss: 0.00047476
Iteration 76/1000 | Loss: 0.00036909
Iteration 77/1000 | Loss: 0.00038065
Iteration 78/1000 | Loss: 0.00071448
Iteration 79/1000 | Loss: 0.00011717
Iteration 80/1000 | Loss: 0.00006227
Iteration 81/1000 | Loss: 0.00025667
Iteration 82/1000 | Loss: 0.00024130
Iteration 83/1000 | Loss: 0.00035258
Iteration 84/1000 | Loss: 0.00027054
Iteration 85/1000 | Loss: 0.00053869
Iteration 86/1000 | Loss: 0.00037039
Iteration 87/1000 | Loss: 0.00092859
Iteration 88/1000 | Loss: 0.00097847
Iteration 89/1000 | Loss: 0.00091978
Iteration 90/1000 | Loss: 0.00075169
Iteration 91/1000 | Loss: 0.00126751
Iteration 92/1000 | Loss: 0.00083556
Iteration 93/1000 | Loss: 0.00009730
Iteration 94/1000 | Loss: 0.00006560
Iteration 95/1000 | Loss: 0.00005283
Iteration 96/1000 | Loss: 0.00004848
Iteration 97/1000 | Loss: 0.00064322
Iteration 98/1000 | Loss: 0.00091017
Iteration 99/1000 | Loss: 0.00045624
Iteration 100/1000 | Loss: 0.00015333
Iteration 101/1000 | Loss: 0.00047161
Iteration 102/1000 | Loss: 0.00048751
Iteration 103/1000 | Loss: 0.00049269
Iteration 104/1000 | Loss: 0.00008816
Iteration 105/1000 | Loss: 0.00067159
Iteration 106/1000 | Loss: 0.00022100
Iteration 107/1000 | Loss: 0.00006451
Iteration 108/1000 | Loss: 0.00095175
Iteration 109/1000 | Loss: 0.00073536
Iteration 110/1000 | Loss: 0.00026382
Iteration 111/1000 | Loss: 0.00080425
Iteration 112/1000 | Loss: 0.00103670
Iteration 113/1000 | Loss: 0.00037780
Iteration 114/1000 | Loss: 0.00026879
Iteration 115/1000 | Loss: 0.00053779
Iteration 116/1000 | Loss: 0.00123140
Iteration 117/1000 | Loss: 0.00109257
Iteration 118/1000 | Loss: 0.00122894
Iteration 119/1000 | Loss: 0.00105135
Iteration 120/1000 | Loss: 0.00006323
Iteration 121/1000 | Loss: 0.00011464
Iteration 122/1000 | Loss: 0.00042972
Iteration 123/1000 | Loss: 0.00077231
Iteration 124/1000 | Loss: 0.00057590
Iteration 125/1000 | Loss: 0.00063418
Iteration 126/1000 | Loss: 0.00022956
Iteration 127/1000 | Loss: 0.00073352
Iteration 128/1000 | Loss: 0.00070944
Iteration 129/1000 | Loss: 0.00065251
Iteration 130/1000 | Loss: 0.00055883
Iteration 131/1000 | Loss: 0.00009385
Iteration 132/1000 | Loss: 0.00044251
Iteration 133/1000 | Loss: 0.00020231
Iteration 134/1000 | Loss: 0.00026672
Iteration 135/1000 | Loss: 0.00056128
Iteration 136/1000 | Loss: 0.00068243
Iteration 137/1000 | Loss: 0.00074109
Iteration 138/1000 | Loss: 0.00008336
Iteration 139/1000 | Loss: 0.00065619
Iteration 140/1000 | Loss: 0.00040841
Iteration 141/1000 | Loss: 0.00006380
Iteration 142/1000 | Loss: 0.00040448
Iteration 143/1000 | Loss: 0.00042583
Iteration 144/1000 | Loss: 0.00038012
Iteration 145/1000 | Loss: 0.00059264
Iteration 146/1000 | Loss: 0.00041360
Iteration 147/1000 | Loss: 0.00055845
Iteration 148/1000 | Loss: 0.00070844
Iteration 149/1000 | Loss: 0.00071674
Iteration 150/1000 | Loss: 0.00069355
Iteration 151/1000 | Loss: 0.00007329
Iteration 152/1000 | Loss: 0.00057720
Iteration 153/1000 | Loss: 0.00010466
Iteration 154/1000 | Loss: 0.00050872
Iteration 155/1000 | Loss: 0.00069598
Iteration 156/1000 | Loss: 0.00070637
Iteration 157/1000 | Loss: 0.00070327
Iteration 158/1000 | Loss: 0.00086964
Iteration 159/1000 | Loss: 0.00037419
Iteration 160/1000 | Loss: 0.00055977
Iteration 161/1000 | Loss: 0.00031756
Iteration 162/1000 | Loss: 0.00023453
Iteration 163/1000 | Loss: 0.00023134
Iteration 164/1000 | Loss: 0.00020349
Iteration 165/1000 | Loss: 0.00033458
Iteration 166/1000 | Loss: 0.00020197
Iteration 167/1000 | Loss: 0.00039413
Iteration 168/1000 | Loss: 0.00034036
Iteration 169/1000 | Loss: 0.00041739
Iteration 170/1000 | Loss: 0.00052092
Iteration 171/1000 | Loss: 0.00053424
Iteration 172/1000 | Loss: 0.00065273
Iteration 173/1000 | Loss: 0.00044201
Iteration 174/1000 | Loss: 0.00011232
Iteration 175/1000 | Loss: 0.00038403
Iteration 176/1000 | Loss: 0.00004022
Iteration 177/1000 | Loss: 0.00039985
Iteration 178/1000 | Loss: 0.00030889
Iteration 179/1000 | Loss: 0.00003689
Iteration 180/1000 | Loss: 0.00051266
Iteration 181/1000 | Loss: 0.00013164
Iteration 182/1000 | Loss: 0.00024139
Iteration 183/1000 | Loss: 0.00059068
Iteration 184/1000 | Loss: 0.00051295
Iteration 185/1000 | Loss: 0.00030037
Iteration 186/1000 | Loss: 0.00055099
Iteration 187/1000 | Loss: 0.00051891
Iteration 188/1000 | Loss: 0.00045222
Iteration 189/1000 | Loss: 0.00058704
Iteration 190/1000 | Loss: 0.00058720
Iteration 191/1000 | Loss: 0.00021800
Iteration 192/1000 | Loss: 0.00020147
Iteration 193/1000 | Loss: 0.00060055
Iteration 194/1000 | Loss: 0.00014680
Iteration 195/1000 | Loss: 0.00063492
Iteration 196/1000 | Loss: 0.00067319
Iteration 197/1000 | Loss: 0.00033719
Iteration 198/1000 | Loss: 0.00034165
Iteration 199/1000 | Loss: 0.00060327
Iteration 200/1000 | Loss: 0.00054835
Iteration 201/1000 | Loss: 0.00043234
Iteration 202/1000 | Loss: 0.00088234
Iteration 203/1000 | Loss: 0.00090944
Iteration 204/1000 | Loss: 0.00035578
Iteration 205/1000 | Loss: 0.00084406
Iteration 206/1000 | Loss: 0.00005239
Iteration 207/1000 | Loss: 0.00004446
Iteration 208/1000 | Loss: 0.00051973
Iteration 209/1000 | Loss: 0.00003787
Iteration 210/1000 | Loss: 0.00003385
Iteration 211/1000 | Loss: 0.00003195
Iteration 212/1000 | Loss: 0.00003055
Iteration 213/1000 | Loss: 0.00029951
Iteration 214/1000 | Loss: 0.00004052
Iteration 215/1000 | Loss: 0.00035928
Iteration 216/1000 | Loss: 0.00029431
Iteration 217/1000 | Loss: 0.00034265
Iteration 218/1000 | Loss: 0.00039943
Iteration 219/1000 | Loss: 0.00004401
Iteration 220/1000 | Loss: 0.00003758
Iteration 221/1000 | Loss: 0.00003368
Iteration 222/1000 | Loss: 0.00003246
Iteration 223/1000 | Loss: 0.00003159
Iteration 224/1000 | Loss: 0.00003094
Iteration 225/1000 | Loss: 0.00003044
Iteration 226/1000 | Loss: 0.00003005
Iteration 227/1000 | Loss: 0.00002953
Iteration 228/1000 | Loss: 0.00002877
Iteration 229/1000 | Loss: 0.00002792
Iteration 230/1000 | Loss: 0.00002755
Iteration 231/1000 | Loss: 0.00002728
Iteration 232/1000 | Loss: 0.00002688
Iteration 233/1000 | Loss: 0.00002655
Iteration 234/1000 | Loss: 0.00002643
Iteration 235/1000 | Loss: 0.00002641
Iteration 236/1000 | Loss: 0.00002641
Iteration 237/1000 | Loss: 0.00002640
Iteration 238/1000 | Loss: 0.00002639
Iteration 239/1000 | Loss: 0.00002638
Iteration 240/1000 | Loss: 0.00002638
Iteration 241/1000 | Loss: 0.00002638
Iteration 242/1000 | Loss: 0.00002637
Iteration 243/1000 | Loss: 0.00002637
Iteration 244/1000 | Loss: 0.00002636
Iteration 245/1000 | Loss: 0.00002636
Iteration 246/1000 | Loss: 0.00002636
Iteration 247/1000 | Loss: 0.00002635
Iteration 248/1000 | Loss: 0.00002635
Iteration 249/1000 | Loss: 0.00002635
Iteration 250/1000 | Loss: 0.00002635
Iteration 251/1000 | Loss: 0.00002634
Iteration 252/1000 | Loss: 0.00002634
Iteration 253/1000 | Loss: 0.00002634
Iteration 254/1000 | Loss: 0.00002633
Iteration 255/1000 | Loss: 0.00002633
Iteration 256/1000 | Loss: 0.00002627
Iteration 257/1000 | Loss: 0.00002627
Iteration 258/1000 | Loss: 0.00002621
Iteration 259/1000 | Loss: 0.00002619
Iteration 260/1000 | Loss: 0.00002618
Iteration 261/1000 | Loss: 0.00002616
Iteration 262/1000 | Loss: 0.00002613
Iteration 263/1000 | Loss: 0.00002610
Iteration 264/1000 | Loss: 0.00002607
Iteration 265/1000 | Loss: 0.00002606
Iteration 266/1000 | Loss: 0.00002606
Iteration 267/1000 | Loss: 0.00002605
Iteration 268/1000 | Loss: 0.00002604
Iteration 269/1000 | Loss: 0.00002604
Iteration 270/1000 | Loss: 0.00002603
Iteration 271/1000 | Loss: 0.00002603
Iteration 272/1000 | Loss: 0.00002603
Iteration 273/1000 | Loss: 0.00002602
Iteration 274/1000 | Loss: 0.00002602
Iteration 275/1000 | Loss: 0.00002601
Iteration 276/1000 | Loss: 0.00002599
Iteration 277/1000 | Loss: 0.00002599
Iteration 278/1000 | Loss: 0.00002599
Iteration 279/1000 | Loss: 0.00002599
Iteration 280/1000 | Loss: 0.00002598
Iteration 281/1000 | Loss: 0.00002597
Iteration 282/1000 | Loss: 0.00002597
Iteration 283/1000 | Loss: 0.00002596
Iteration 284/1000 | Loss: 0.00002595
Iteration 285/1000 | Loss: 0.00002595
Iteration 286/1000 | Loss: 0.00002595
Iteration 287/1000 | Loss: 0.00002594
Iteration 288/1000 | Loss: 0.00002594
Iteration 289/1000 | Loss: 0.00002594
Iteration 290/1000 | Loss: 0.00002594
Iteration 291/1000 | Loss: 0.00002593
Iteration 292/1000 | Loss: 0.00002593
Iteration 293/1000 | Loss: 0.00002593
Iteration 294/1000 | Loss: 0.00002593
Iteration 295/1000 | Loss: 0.00002592
Iteration 296/1000 | Loss: 0.00002592
Iteration 297/1000 | Loss: 0.00002592
Iteration 298/1000 | Loss: 0.00002592
Iteration 299/1000 | Loss: 0.00002591
Iteration 300/1000 | Loss: 0.00002591
Iteration 301/1000 | Loss: 0.00002591
Iteration 302/1000 | Loss: 0.00002591
Iteration 303/1000 | Loss: 0.00002591
Iteration 304/1000 | Loss: 0.00002591
Iteration 305/1000 | Loss: 0.00002591
Iteration 306/1000 | Loss: 0.00002591
Iteration 307/1000 | Loss: 0.00002591
Iteration 308/1000 | Loss: 0.00002591
Iteration 309/1000 | Loss: 0.00002590
Iteration 310/1000 | Loss: 0.00002590
Iteration 311/1000 | Loss: 0.00002590
Iteration 312/1000 | Loss: 0.00002590
Iteration 313/1000 | Loss: 0.00002590
Iteration 314/1000 | Loss: 0.00002590
Iteration 315/1000 | Loss: 0.00002590
Iteration 316/1000 | Loss: 0.00002590
Iteration 317/1000 | Loss: 0.00002590
Iteration 318/1000 | Loss: 0.00002590
Iteration 319/1000 | Loss: 0.00002590
Iteration 320/1000 | Loss: 0.00002590
Iteration 321/1000 | Loss: 0.00002590
Iteration 322/1000 | Loss: 0.00002590
Iteration 323/1000 | Loss: 0.00002590
Iteration 324/1000 | Loss: 0.00002590
Iteration 325/1000 | Loss: 0.00002590
Iteration 326/1000 | Loss: 0.00002590
Iteration 327/1000 | Loss: 0.00002590
Iteration 328/1000 | Loss: 0.00002590
Iteration 329/1000 | Loss: 0.00002590
Iteration 330/1000 | Loss: 0.00002590
Iteration 331/1000 | Loss: 0.00002589
Iteration 332/1000 | Loss: 0.00002589
Iteration 333/1000 | Loss: 0.00002589
Iteration 334/1000 | Loss: 0.00002589
Iteration 335/1000 | Loss: 0.00002589
Iteration 336/1000 | Loss: 0.00002589
Iteration 337/1000 | Loss: 0.00002589
Iteration 338/1000 | Loss: 0.00002589
Iteration 339/1000 | Loss: 0.00002589
Iteration 340/1000 | Loss: 0.00002589
Iteration 341/1000 | Loss: 0.00002589
Iteration 342/1000 | Loss: 0.00002589
Iteration 343/1000 | Loss: 0.00002589
Iteration 344/1000 | Loss: 0.00002589
Iteration 345/1000 | Loss: 0.00002589
Iteration 346/1000 | Loss: 0.00002589
Iteration 347/1000 | Loss: 0.00002589
Iteration 348/1000 | Loss: 0.00002589
Iteration 349/1000 | Loss: 0.00002589
Iteration 350/1000 | Loss: 0.00002589
Iteration 351/1000 | Loss: 0.00002589
Iteration 352/1000 | Loss: 0.00002589
Iteration 353/1000 | Loss: 0.00002589
Iteration 354/1000 | Loss: 0.00002589
Iteration 355/1000 | Loss: 0.00002589
Iteration 356/1000 | Loss: 0.00002589
Iteration 357/1000 | Loss: 0.00002589
Iteration 358/1000 | Loss: 0.00002589
Iteration 359/1000 | Loss: 0.00002589
Iteration 360/1000 | Loss: 0.00002589
Iteration 361/1000 | Loss: 0.00002589
Iteration 362/1000 | Loss: 0.00002589
Iteration 363/1000 | Loss: 0.00002589
Iteration 364/1000 | Loss: 0.00002589
Iteration 365/1000 | Loss: 0.00002589
Iteration 366/1000 | Loss: 0.00002589
Iteration 367/1000 | Loss: 0.00002589
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 367. Stopping optimization.
Last 5 losses: [2.5887278752634302e-05, 2.5887278752634302e-05, 2.5887278752634302e-05, 2.5887278752634302e-05, 2.5887278752634302e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5887278752634302e-05

Optimization complete. Final v2v error: 4.102724075317383 mm

Highest mean error: 6.113712787628174 mm for frame 32

Lowest mean error: 3.2489359378814697 mm for frame 133

Saving results

Total time: 382.1365420818329
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01000526
Iteration 2/25 | Loss: 0.00212778
Iteration 3/25 | Loss: 0.00144711
Iteration 4/25 | Loss: 0.00130535
Iteration 5/25 | Loss: 0.00129275
Iteration 6/25 | Loss: 0.00121139
Iteration 7/25 | Loss: 0.00120129
Iteration 8/25 | Loss: 0.00117130
Iteration 9/25 | Loss: 0.00115801
Iteration 10/25 | Loss: 0.00108504
Iteration 11/25 | Loss: 0.00105845
Iteration 12/25 | Loss: 0.00101397
Iteration 13/25 | Loss: 0.00100015
Iteration 14/25 | Loss: 0.00100090
Iteration 15/25 | Loss: 0.00099833
Iteration 16/25 | Loss: 0.00100975
Iteration 17/25 | Loss: 0.00101302
Iteration 18/25 | Loss: 0.00100598
Iteration 19/25 | Loss: 0.00100441
Iteration 20/25 | Loss: 0.00099652
Iteration 21/25 | Loss: 0.00098863
Iteration 22/25 | Loss: 0.00098496
Iteration 23/25 | Loss: 0.00098397
Iteration 24/25 | Loss: 0.00099007
Iteration 25/25 | Loss: 0.00099353

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66195035
Iteration 2/25 | Loss: 0.00331692
Iteration 3/25 | Loss: 0.00330594
Iteration 4/25 | Loss: 0.00330594
Iteration 5/25 | Loss: 0.00330594
Iteration 6/25 | Loss: 0.00330594
Iteration 7/25 | Loss: 0.00330594
Iteration 8/25 | Loss: 0.00330594
Iteration 9/25 | Loss: 0.00330594
Iteration 10/25 | Loss: 0.00330594
Iteration 11/25 | Loss: 0.00330594
Iteration 12/25 | Loss: 0.00330594
Iteration 13/25 | Loss: 0.00330594
Iteration 14/25 | Loss: 0.00330594
Iteration 15/25 | Loss: 0.00330594
Iteration 16/25 | Loss: 0.00330594
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0033059357665479183, 0.0033059357665479183, 0.0033059357665479183, 0.0033059357665479183, 0.0033059357665479183]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0033059357665479183

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00330594
Iteration 2/1000 | Loss: 0.00073608
Iteration 3/1000 | Loss: 0.00019426
Iteration 4/1000 | Loss: 0.00047360
Iteration 5/1000 | Loss: 0.00038279
Iteration 6/1000 | Loss: 0.00049775
Iteration 7/1000 | Loss: 0.00011373
Iteration 8/1000 | Loss: 0.00039002
Iteration 9/1000 | Loss: 0.00054737
Iteration 10/1000 | Loss: 0.00014698
Iteration 11/1000 | Loss: 0.00018841
Iteration 12/1000 | Loss: 0.00009093
Iteration 13/1000 | Loss: 0.00008822
Iteration 14/1000 | Loss: 0.00007983
Iteration 15/1000 | Loss: 0.00007573
Iteration 16/1000 | Loss: 0.00007292
Iteration 17/1000 | Loss: 0.00007096
Iteration 18/1000 | Loss: 0.00009098
Iteration 19/1000 | Loss: 0.00298697
Iteration 20/1000 | Loss: 0.00143380
Iteration 21/1000 | Loss: 0.00139524
Iteration 22/1000 | Loss: 0.00008997
Iteration 23/1000 | Loss: 0.00084429
Iteration 24/1000 | Loss: 0.00007903
Iteration 25/1000 | Loss: 0.00301169
Iteration 26/1000 | Loss: 0.00117737
Iteration 27/1000 | Loss: 0.00174335
Iteration 28/1000 | Loss: 0.00163698
Iteration 29/1000 | Loss: 0.00145816
Iteration 30/1000 | Loss: 0.00181787
Iteration 31/1000 | Loss: 0.00107321
Iteration 32/1000 | Loss: 0.00217594
Iteration 33/1000 | Loss: 0.00123987
Iteration 34/1000 | Loss: 0.00126629
Iteration 35/1000 | Loss: 0.00008295
Iteration 36/1000 | Loss: 0.00021488
Iteration 37/1000 | Loss: 0.00007300
Iteration 38/1000 | Loss: 0.00115594
Iteration 39/1000 | Loss: 0.00037861
Iteration 40/1000 | Loss: 0.00007023
Iteration 41/1000 | Loss: 0.00008357
Iteration 42/1000 | Loss: 0.00010973
Iteration 43/1000 | Loss: 0.00004970
Iteration 44/1000 | Loss: 0.00004803
Iteration 45/1000 | Loss: 0.00004461
Iteration 46/1000 | Loss: 0.00008944
Iteration 47/1000 | Loss: 0.00060437
Iteration 48/1000 | Loss: 0.00027087
Iteration 49/1000 | Loss: 0.00004430
Iteration 50/1000 | Loss: 0.00004258
Iteration 51/1000 | Loss: 0.00004100
Iteration 52/1000 | Loss: 0.00068067
Iteration 53/1000 | Loss: 0.00013709
Iteration 54/1000 | Loss: 0.00004118
Iteration 55/1000 | Loss: 0.00003924
Iteration 56/1000 | Loss: 0.00006574
Iteration 57/1000 | Loss: 0.00103417
Iteration 58/1000 | Loss: 0.00095230
Iteration 59/1000 | Loss: 0.00088977
Iteration 60/1000 | Loss: 0.00061742
Iteration 61/1000 | Loss: 0.00004787
Iteration 62/1000 | Loss: 0.00005309
Iteration 63/1000 | Loss: 0.00074579
Iteration 64/1000 | Loss: 0.00035469
Iteration 65/1000 | Loss: 0.00005592
Iteration 66/1000 | Loss: 0.00003792
Iteration 67/1000 | Loss: 0.00003746
Iteration 68/1000 | Loss: 0.00062665
Iteration 69/1000 | Loss: 0.00028964
Iteration 70/1000 | Loss: 0.00004414
Iteration 71/1000 | Loss: 0.00004810
Iteration 72/1000 | Loss: 0.00003679
Iteration 73/1000 | Loss: 0.00074418
Iteration 74/1000 | Loss: 0.00021451
Iteration 75/1000 | Loss: 0.00005723
Iteration 76/1000 | Loss: 0.00084142
Iteration 77/1000 | Loss: 0.00016730
Iteration 78/1000 | Loss: 0.00111690
Iteration 79/1000 | Loss: 0.00095651
Iteration 80/1000 | Loss: 0.00023622
Iteration 81/1000 | Loss: 0.00033220
Iteration 82/1000 | Loss: 0.00039636
Iteration 83/1000 | Loss: 0.00057397
Iteration 84/1000 | Loss: 0.00029787
Iteration 85/1000 | Loss: 0.00047198
Iteration 86/1000 | Loss: 0.00004862
Iteration 87/1000 | Loss: 0.00004244
Iteration 88/1000 | Loss: 0.00003975
Iteration 89/1000 | Loss: 0.00003805
Iteration 90/1000 | Loss: 0.00003665
Iteration 91/1000 | Loss: 0.00003555
Iteration 92/1000 | Loss: 0.00016499
Iteration 93/1000 | Loss: 0.00003382
Iteration 94/1000 | Loss: 0.00003185
Iteration 95/1000 | Loss: 0.00003140
Iteration 96/1000 | Loss: 0.00003105
Iteration 97/1000 | Loss: 0.00003091
Iteration 98/1000 | Loss: 0.00003078
Iteration 99/1000 | Loss: 0.00003069
Iteration 100/1000 | Loss: 0.00003064
Iteration 101/1000 | Loss: 0.00003064
Iteration 102/1000 | Loss: 0.00003059
Iteration 103/1000 | Loss: 0.00003053
Iteration 104/1000 | Loss: 0.00003040
Iteration 105/1000 | Loss: 0.00003035
Iteration 106/1000 | Loss: 0.00003031
Iteration 107/1000 | Loss: 0.00003030
Iteration 108/1000 | Loss: 0.00003029
Iteration 109/1000 | Loss: 0.00003028
Iteration 110/1000 | Loss: 0.00003028
Iteration 111/1000 | Loss: 0.00003027
Iteration 112/1000 | Loss: 0.00003026
Iteration 113/1000 | Loss: 0.00003026
Iteration 114/1000 | Loss: 0.00003026
Iteration 115/1000 | Loss: 0.00003025
Iteration 116/1000 | Loss: 0.00003025
Iteration 117/1000 | Loss: 0.00003025
Iteration 118/1000 | Loss: 0.00003025
Iteration 119/1000 | Loss: 0.00003025
Iteration 120/1000 | Loss: 0.00003025
Iteration 121/1000 | Loss: 0.00003022
Iteration 122/1000 | Loss: 0.00003021
Iteration 123/1000 | Loss: 0.00003021
Iteration 124/1000 | Loss: 0.00003021
Iteration 125/1000 | Loss: 0.00003021
Iteration 126/1000 | Loss: 0.00003021
Iteration 127/1000 | Loss: 0.00003021
Iteration 128/1000 | Loss: 0.00003021
Iteration 129/1000 | Loss: 0.00003020
Iteration 130/1000 | Loss: 0.00003020
Iteration 131/1000 | Loss: 0.00003020
Iteration 132/1000 | Loss: 0.00003020
Iteration 133/1000 | Loss: 0.00003019
Iteration 134/1000 | Loss: 0.00003019
Iteration 135/1000 | Loss: 0.00003019
Iteration 136/1000 | Loss: 0.00003019
Iteration 137/1000 | Loss: 0.00003019
Iteration 138/1000 | Loss: 0.00003019
Iteration 139/1000 | Loss: 0.00003019
Iteration 140/1000 | Loss: 0.00003019
Iteration 141/1000 | Loss: 0.00003019
Iteration 142/1000 | Loss: 0.00003019
Iteration 143/1000 | Loss: 0.00003018
Iteration 144/1000 | Loss: 0.00003018
Iteration 145/1000 | Loss: 0.00003018
Iteration 146/1000 | Loss: 0.00003017
Iteration 147/1000 | Loss: 0.00003017
Iteration 148/1000 | Loss: 0.00003016
Iteration 149/1000 | Loss: 0.00003016
Iteration 150/1000 | Loss: 0.00003015
Iteration 151/1000 | Loss: 0.00003015
Iteration 152/1000 | Loss: 0.00003015
Iteration 153/1000 | Loss: 0.00003015
Iteration 154/1000 | Loss: 0.00003014
Iteration 155/1000 | Loss: 0.00003014
Iteration 156/1000 | Loss: 0.00003014
Iteration 157/1000 | Loss: 0.00003013
Iteration 158/1000 | Loss: 0.00003013
Iteration 159/1000 | Loss: 0.00003013
Iteration 160/1000 | Loss: 0.00003012
Iteration 161/1000 | Loss: 0.00003012
Iteration 162/1000 | Loss: 0.00003012
Iteration 163/1000 | Loss: 0.00003012
Iteration 164/1000 | Loss: 0.00003011
Iteration 165/1000 | Loss: 0.00003011
Iteration 166/1000 | Loss: 0.00003011
Iteration 167/1000 | Loss: 0.00003011
Iteration 168/1000 | Loss: 0.00003010
Iteration 169/1000 | Loss: 0.00003010
Iteration 170/1000 | Loss: 0.00003010
Iteration 171/1000 | Loss: 0.00003010
Iteration 172/1000 | Loss: 0.00003010
Iteration 173/1000 | Loss: 0.00003009
Iteration 174/1000 | Loss: 0.00003009
Iteration 175/1000 | Loss: 0.00003009
Iteration 176/1000 | Loss: 0.00003008
Iteration 177/1000 | Loss: 0.00003008
Iteration 178/1000 | Loss: 0.00003008
Iteration 179/1000 | Loss: 0.00003008
Iteration 180/1000 | Loss: 0.00003008
Iteration 181/1000 | Loss: 0.00003008
Iteration 182/1000 | Loss: 0.00003008
Iteration 183/1000 | Loss: 0.00003008
Iteration 184/1000 | Loss: 0.00003008
Iteration 185/1000 | Loss: 0.00003008
Iteration 186/1000 | Loss: 0.00003008
Iteration 187/1000 | Loss: 0.00003008
Iteration 188/1000 | Loss: 0.00003008
Iteration 189/1000 | Loss: 0.00003008
Iteration 190/1000 | Loss: 0.00003008
Iteration 191/1000 | Loss: 0.00003008
Iteration 192/1000 | Loss: 0.00003008
Iteration 193/1000 | Loss: 0.00003008
Iteration 194/1000 | Loss: 0.00003008
Iteration 195/1000 | Loss: 0.00003008
Iteration 196/1000 | Loss: 0.00003008
Iteration 197/1000 | Loss: 0.00003007
Iteration 198/1000 | Loss: 0.00003007
Iteration 199/1000 | Loss: 0.00003007
Iteration 200/1000 | Loss: 0.00003007
Iteration 201/1000 | Loss: 0.00003007
Iteration 202/1000 | Loss: 0.00003007
Iteration 203/1000 | Loss: 0.00003007
Iteration 204/1000 | Loss: 0.00003007
Iteration 205/1000 | Loss: 0.00003007
Iteration 206/1000 | Loss: 0.00003007
Iteration 207/1000 | Loss: 0.00003007
Iteration 208/1000 | Loss: 0.00003007
Iteration 209/1000 | Loss: 0.00003007
Iteration 210/1000 | Loss: 0.00003007
Iteration 211/1000 | Loss: 0.00003007
Iteration 212/1000 | Loss: 0.00003007
Iteration 213/1000 | Loss: 0.00003007
Iteration 214/1000 | Loss: 0.00003007
Iteration 215/1000 | Loss: 0.00003007
Iteration 216/1000 | Loss: 0.00003007
Iteration 217/1000 | Loss: 0.00003007
Iteration 218/1000 | Loss: 0.00003007
Iteration 219/1000 | Loss: 0.00003007
Iteration 220/1000 | Loss: 0.00003007
Iteration 221/1000 | Loss: 0.00003006
Iteration 222/1000 | Loss: 0.00003006
Iteration 223/1000 | Loss: 0.00003006
Iteration 224/1000 | Loss: 0.00003006
Iteration 225/1000 | Loss: 0.00003006
Iteration 226/1000 | Loss: 0.00003006
Iteration 227/1000 | Loss: 0.00003006
Iteration 228/1000 | Loss: 0.00003006
Iteration 229/1000 | Loss: 0.00003006
Iteration 230/1000 | Loss: 0.00003006
Iteration 231/1000 | Loss: 0.00003006
Iteration 232/1000 | Loss: 0.00003006
Iteration 233/1000 | Loss: 0.00003006
Iteration 234/1000 | Loss: 0.00003006
Iteration 235/1000 | Loss: 0.00003006
Iteration 236/1000 | Loss: 0.00003006
Iteration 237/1000 | Loss: 0.00003006
Iteration 238/1000 | Loss: 0.00003005
Iteration 239/1000 | Loss: 0.00003005
Iteration 240/1000 | Loss: 0.00003005
Iteration 241/1000 | Loss: 0.00003005
Iteration 242/1000 | Loss: 0.00003005
Iteration 243/1000 | Loss: 0.00003005
Iteration 244/1000 | Loss: 0.00003005
Iteration 245/1000 | Loss: 0.00003005
Iteration 246/1000 | Loss: 0.00003005
Iteration 247/1000 | Loss: 0.00003005
Iteration 248/1000 | Loss: 0.00003005
Iteration 249/1000 | Loss: 0.00003005
Iteration 250/1000 | Loss: 0.00003005
Iteration 251/1000 | Loss: 0.00003005
Iteration 252/1000 | Loss: 0.00003005
Iteration 253/1000 | Loss: 0.00003005
Iteration 254/1000 | Loss: 0.00003005
Iteration 255/1000 | Loss: 0.00003005
Iteration 256/1000 | Loss: 0.00003005
Iteration 257/1000 | Loss: 0.00003005
Iteration 258/1000 | Loss: 0.00003005
Iteration 259/1000 | Loss: 0.00003005
Iteration 260/1000 | Loss: 0.00003005
Iteration 261/1000 | Loss: 0.00003005
Iteration 262/1000 | Loss: 0.00003005
Iteration 263/1000 | Loss: 0.00003005
Iteration 264/1000 | Loss: 0.00003005
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 264. Stopping optimization.
Last 5 losses: [3.0049841370782815e-05, 3.0049841370782815e-05, 3.0049841370782815e-05, 3.0049841370782815e-05, 3.0049841370782815e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.0049841370782815e-05

Optimization complete. Final v2v error: 4.413207530975342 mm

Highest mean error: 6.065986633300781 mm for frame 83

Lowest mean error: 3.206352472305298 mm for frame 5

Saving results

Total time: 192.37556648254395
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1070
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01060401
Iteration 2/25 | Loss: 0.01060400
Iteration 3/25 | Loss: 0.01060400
Iteration 4/25 | Loss: 0.01060400
Iteration 5/25 | Loss: 0.00306823
Iteration 6/25 | Loss: 0.00186079
Iteration 7/25 | Loss: 0.00162336
Iteration 8/25 | Loss: 0.00141075
Iteration 9/25 | Loss: 0.00136640
Iteration 10/25 | Loss: 0.00124921
Iteration 11/25 | Loss: 0.00114961
Iteration 12/25 | Loss: 0.00108458
Iteration 13/25 | Loss: 0.00107014
Iteration 14/25 | Loss: 0.00106587
Iteration 15/25 | Loss: 0.00104863
Iteration 16/25 | Loss: 0.00103507
Iteration 17/25 | Loss: 0.00103490
Iteration 18/25 | Loss: 0.00103072
Iteration 19/25 | Loss: 0.00102482
Iteration 20/25 | Loss: 0.00101804
Iteration 21/25 | Loss: 0.00101412
Iteration 22/25 | Loss: 0.00100932
Iteration 23/25 | Loss: 0.00101581
Iteration 24/25 | Loss: 0.00101236
Iteration 25/25 | Loss: 0.00101022

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56794500
Iteration 2/25 | Loss: 0.00269809
Iteration 3/25 | Loss: 0.00226286
Iteration 4/25 | Loss: 0.00226286
Iteration 5/25 | Loss: 0.00226286
Iteration 6/25 | Loss: 0.00226286
Iteration 7/25 | Loss: 0.00226286
Iteration 8/25 | Loss: 0.00226286
Iteration 9/25 | Loss: 0.00226286
Iteration 10/25 | Loss: 0.00226286
Iteration 11/25 | Loss: 0.00226286
Iteration 12/25 | Loss: 0.00226286
Iteration 13/25 | Loss: 0.00226286
Iteration 14/25 | Loss: 0.00226286
Iteration 15/25 | Loss: 0.00226286
Iteration 16/25 | Loss: 0.00226286
Iteration 17/25 | Loss: 0.00226286
Iteration 18/25 | Loss: 0.00226286
Iteration 19/25 | Loss: 0.00226286
Iteration 20/25 | Loss: 0.00226286
Iteration 21/25 | Loss: 0.00226286
Iteration 22/25 | Loss: 0.00226286
Iteration 23/25 | Loss: 0.00226286
Iteration 24/25 | Loss: 0.00226286
Iteration 25/25 | Loss: 0.00226286
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.002262860769405961, 0.002262860769405961, 0.002262860769405961, 0.002262860769405961, 0.002262860769405961]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002262860769405961

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00226286
Iteration 2/1000 | Loss: 0.00300189
Iteration 3/1000 | Loss: 0.00160101
Iteration 4/1000 | Loss: 0.00032920
Iteration 5/1000 | Loss: 0.00016981
Iteration 6/1000 | Loss: 0.00030987
Iteration 7/1000 | Loss: 0.00052452
Iteration 8/1000 | Loss: 0.00013309
Iteration 9/1000 | Loss: 0.00014142
Iteration 10/1000 | Loss: 0.00009414
Iteration 11/1000 | Loss: 0.00046859
Iteration 12/1000 | Loss: 0.00032288
Iteration 13/1000 | Loss: 0.00051800
Iteration 14/1000 | Loss: 0.00069244
Iteration 15/1000 | Loss: 0.00039184
Iteration 16/1000 | Loss: 0.00058298
Iteration 17/1000 | Loss: 0.00029381
Iteration 18/1000 | Loss: 0.00051023
Iteration 19/1000 | Loss: 0.00021452
Iteration 20/1000 | Loss: 0.00039131
Iteration 21/1000 | Loss: 0.00019023
Iteration 22/1000 | Loss: 0.00034457
Iteration 23/1000 | Loss: 0.00094334
Iteration 24/1000 | Loss: 0.00128083
Iteration 25/1000 | Loss: 0.00018627
Iteration 26/1000 | Loss: 0.00014951
Iteration 27/1000 | Loss: 0.00032580
Iteration 28/1000 | Loss: 0.00023438
Iteration 29/1000 | Loss: 0.00039518
Iteration 30/1000 | Loss: 0.00153029
Iteration 31/1000 | Loss: 0.00004399
Iteration 32/1000 | Loss: 0.00034543
Iteration 33/1000 | Loss: 0.00004135
Iteration 34/1000 | Loss: 0.00003276
Iteration 35/1000 | Loss: 0.00007497
Iteration 36/1000 | Loss: 0.00005218
Iteration 37/1000 | Loss: 0.00002787
Iteration 38/1000 | Loss: 0.00002375
Iteration 39/1000 | Loss: 0.00002177
Iteration 40/1000 | Loss: 0.00002050
Iteration 41/1000 | Loss: 0.00001977
Iteration 42/1000 | Loss: 0.00001904
Iteration 43/1000 | Loss: 0.00003966
Iteration 44/1000 | Loss: 0.00003447
Iteration 45/1000 | Loss: 0.00003873
Iteration 46/1000 | Loss: 0.00002373
Iteration 47/1000 | Loss: 0.00002155
Iteration 48/1000 | Loss: 0.00003219
Iteration 49/1000 | Loss: 0.00002330
Iteration 50/1000 | Loss: 0.00002242
Iteration 51/1000 | Loss: 0.00003317
Iteration 52/1000 | Loss: 0.00002165
Iteration 53/1000 | Loss: 0.00002013
Iteration 54/1000 | Loss: 0.00001902
Iteration 55/1000 | Loss: 0.00001813
Iteration 56/1000 | Loss: 0.00001773
Iteration 57/1000 | Loss: 0.00001759
Iteration 58/1000 | Loss: 0.00001757
Iteration 59/1000 | Loss: 0.00001756
Iteration 60/1000 | Loss: 0.00001756
Iteration 61/1000 | Loss: 0.00001756
Iteration 62/1000 | Loss: 0.00001755
Iteration 63/1000 | Loss: 0.00001754
Iteration 64/1000 | Loss: 0.00001753
Iteration 65/1000 | Loss: 0.00001753
Iteration 66/1000 | Loss: 0.00001749
Iteration 67/1000 | Loss: 0.00001747
Iteration 68/1000 | Loss: 0.00001747
Iteration 69/1000 | Loss: 0.00001746
Iteration 70/1000 | Loss: 0.00001745
Iteration 71/1000 | Loss: 0.00001745
Iteration 72/1000 | Loss: 0.00001745
Iteration 73/1000 | Loss: 0.00001745
Iteration 74/1000 | Loss: 0.00001745
Iteration 75/1000 | Loss: 0.00001744
Iteration 76/1000 | Loss: 0.00001744
Iteration 77/1000 | Loss: 0.00001743
Iteration 78/1000 | Loss: 0.00001743
Iteration 79/1000 | Loss: 0.00001743
Iteration 80/1000 | Loss: 0.00001742
Iteration 81/1000 | Loss: 0.00001742
Iteration 82/1000 | Loss: 0.00001741
Iteration 83/1000 | Loss: 0.00001741
Iteration 84/1000 | Loss: 0.00001741
Iteration 85/1000 | Loss: 0.00001740
Iteration 86/1000 | Loss: 0.00001740
Iteration 87/1000 | Loss: 0.00001739
Iteration 88/1000 | Loss: 0.00001739
Iteration 89/1000 | Loss: 0.00001739
Iteration 90/1000 | Loss: 0.00001738
Iteration 91/1000 | Loss: 0.00001738
Iteration 92/1000 | Loss: 0.00001738
Iteration 93/1000 | Loss: 0.00001738
Iteration 94/1000 | Loss: 0.00001738
Iteration 95/1000 | Loss: 0.00001738
Iteration 96/1000 | Loss: 0.00001737
Iteration 97/1000 | Loss: 0.00001737
Iteration 98/1000 | Loss: 0.00001737
Iteration 99/1000 | Loss: 0.00001737
Iteration 100/1000 | Loss: 0.00001737
Iteration 101/1000 | Loss: 0.00001737
Iteration 102/1000 | Loss: 0.00001737
Iteration 103/1000 | Loss: 0.00001737
Iteration 104/1000 | Loss: 0.00001737
Iteration 105/1000 | Loss: 0.00001737
Iteration 106/1000 | Loss: 0.00001736
Iteration 107/1000 | Loss: 0.00001736
Iteration 108/1000 | Loss: 0.00001736
Iteration 109/1000 | Loss: 0.00001736
Iteration 110/1000 | Loss: 0.00001736
Iteration 111/1000 | Loss: 0.00001736
Iteration 112/1000 | Loss: 0.00001736
Iteration 113/1000 | Loss: 0.00001735
Iteration 114/1000 | Loss: 0.00001735
Iteration 115/1000 | Loss: 0.00001735
Iteration 116/1000 | Loss: 0.00001735
Iteration 117/1000 | Loss: 0.00001734
Iteration 118/1000 | Loss: 0.00001734
Iteration 119/1000 | Loss: 0.00001734
Iteration 120/1000 | Loss: 0.00001733
Iteration 121/1000 | Loss: 0.00001733
Iteration 122/1000 | Loss: 0.00001733
Iteration 123/1000 | Loss: 0.00001732
Iteration 124/1000 | Loss: 0.00001732
Iteration 125/1000 | Loss: 0.00001732
Iteration 126/1000 | Loss: 0.00001732
Iteration 127/1000 | Loss: 0.00001731
Iteration 128/1000 | Loss: 0.00001731
Iteration 129/1000 | Loss: 0.00001731
Iteration 130/1000 | Loss: 0.00001731
Iteration 131/1000 | Loss: 0.00001730
Iteration 132/1000 | Loss: 0.00001730
Iteration 133/1000 | Loss: 0.00001730
Iteration 134/1000 | Loss: 0.00001730
Iteration 135/1000 | Loss: 0.00001730
Iteration 136/1000 | Loss: 0.00001730
Iteration 137/1000 | Loss: 0.00001729
Iteration 138/1000 | Loss: 0.00001729
Iteration 139/1000 | Loss: 0.00001729
Iteration 140/1000 | Loss: 0.00001729
Iteration 141/1000 | Loss: 0.00001729
Iteration 142/1000 | Loss: 0.00001729
Iteration 143/1000 | Loss: 0.00001729
Iteration 144/1000 | Loss: 0.00001729
Iteration 145/1000 | Loss: 0.00001729
Iteration 146/1000 | Loss: 0.00001729
Iteration 147/1000 | Loss: 0.00001729
Iteration 148/1000 | Loss: 0.00001729
Iteration 149/1000 | Loss: 0.00001728
Iteration 150/1000 | Loss: 0.00001728
Iteration 151/1000 | Loss: 0.00001728
Iteration 152/1000 | Loss: 0.00001728
Iteration 153/1000 | Loss: 0.00001728
Iteration 154/1000 | Loss: 0.00001728
Iteration 155/1000 | Loss: 0.00001728
Iteration 156/1000 | Loss: 0.00001728
Iteration 157/1000 | Loss: 0.00001728
Iteration 158/1000 | Loss: 0.00001728
Iteration 159/1000 | Loss: 0.00001728
Iteration 160/1000 | Loss: 0.00001728
Iteration 161/1000 | Loss: 0.00001728
Iteration 162/1000 | Loss: 0.00001728
Iteration 163/1000 | Loss: 0.00001727
Iteration 164/1000 | Loss: 0.00001727
Iteration 165/1000 | Loss: 0.00001727
Iteration 166/1000 | Loss: 0.00001727
Iteration 167/1000 | Loss: 0.00001727
Iteration 168/1000 | Loss: 0.00001727
Iteration 169/1000 | Loss: 0.00001727
Iteration 170/1000 | Loss: 0.00001727
Iteration 171/1000 | Loss: 0.00001727
Iteration 172/1000 | Loss: 0.00001727
Iteration 173/1000 | Loss: 0.00001727
Iteration 174/1000 | Loss: 0.00001727
Iteration 175/1000 | Loss: 0.00001727
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 175. Stopping optimization.
Last 5 losses: [1.7271891920245253e-05, 1.7271891920245253e-05, 1.7271891920245253e-05, 1.7271891920245253e-05, 1.7271891920245253e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7271891920245253e-05

Optimization complete. Final v2v error: 3.5368666648864746 mm

Highest mean error: 3.9993085861206055 mm for frame 17

Lowest mean error: 3.226318359375 mm for frame 231

Saving results

Total time: 149.42128586769104
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00419423
Iteration 2/25 | Loss: 0.00094868
Iteration 3/25 | Loss: 0.00085064
Iteration 4/25 | Loss: 0.00082365
Iteration 5/25 | Loss: 0.00081716
Iteration 6/25 | Loss: 0.00081580
Iteration 7/25 | Loss: 0.00081541
Iteration 8/25 | Loss: 0.00081541
Iteration 9/25 | Loss: 0.00081541
Iteration 10/25 | Loss: 0.00081541
Iteration 11/25 | Loss: 0.00081541
Iteration 12/25 | Loss: 0.00081541
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008154096431098878, 0.0008154096431098878, 0.0008154096431098878, 0.0008154096431098878, 0.0008154096431098878]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008154096431098878

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58919954
Iteration 2/25 | Loss: 0.00123059
Iteration 3/25 | Loss: 0.00123059
Iteration 4/25 | Loss: 0.00123059
Iteration 5/25 | Loss: 0.00123059
Iteration 6/25 | Loss: 0.00123059
Iteration 7/25 | Loss: 0.00123059
Iteration 8/25 | Loss: 0.00123059
Iteration 9/25 | Loss: 0.00123059
Iteration 10/25 | Loss: 0.00123059
Iteration 11/25 | Loss: 0.00123059
Iteration 12/25 | Loss: 0.00123059
Iteration 13/25 | Loss: 0.00123059
Iteration 14/25 | Loss: 0.00123059
Iteration 15/25 | Loss: 0.00123059
Iteration 16/25 | Loss: 0.00123059
Iteration 17/25 | Loss: 0.00123059
Iteration 18/25 | Loss: 0.00123059
Iteration 19/25 | Loss: 0.00123059
Iteration 20/25 | Loss: 0.00123059
Iteration 21/25 | Loss: 0.00123059
Iteration 22/25 | Loss: 0.00123059
Iteration 23/25 | Loss: 0.00123059
Iteration 24/25 | Loss: 0.00123059
Iteration 25/25 | Loss: 0.00123059
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0012305896962061524, 0.0012305896962061524, 0.0012305896962061524, 0.0012305896962061524, 0.0012305896962061524]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012305896962061524

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00123059
Iteration 2/1000 | Loss: 0.00005495
Iteration 3/1000 | Loss: 0.00003209
Iteration 4/1000 | Loss: 0.00002943
Iteration 5/1000 | Loss: 0.00002823
Iteration 6/1000 | Loss: 0.00002739
Iteration 7/1000 | Loss: 0.00002679
Iteration 8/1000 | Loss: 0.00002631
Iteration 9/1000 | Loss: 0.00002594
Iteration 10/1000 | Loss: 0.00002569
Iteration 11/1000 | Loss: 0.00002556
Iteration 12/1000 | Loss: 0.00002555
Iteration 13/1000 | Loss: 0.00002544
Iteration 14/1000 | Loss: 0.00002528
Iteration 15/1000 | Loss: 0.00002527
Iteration 16/1000 | Loss: 0.00002524
Iteration 17/1000 | Loss: 0.00002521
Iteration 18/1000 | Loss: 0.00002516
Iteration 19/1000 | Loss: 0.00002516
Iteration 20/1000 | Loss: 0.00002513
Iteration 21/1000 | Loss: 0.00002512
Iteration 22/1000 | Loss: 0.00002512
Iteration 23/1000 | Loss: 0.00002511
Iteration 24/1000 | Loss: 0.00002506
Iteration 25/1000 | Loss: 0.00002497
Iteration 26/1000 | Loss: 0.00002494
Iteration 27/1000 | Loss: 0.00002492
Iteration 28/1000 | Loss: 0.00002492
Iteration 29/1000 | Loss: 0.00002492
Iteration 30/1000 | Loss: 0.00002491
Iteration 31/1000 | Loss: 0.00002491
Iteration 32/1000 | Loss: 0.00002491
Iteration 33/1000 | Loss: 0.00002490
Iteration 34/1000 | Loss: 0.00002490
Iteration 35/1000 | Loss: 0.00002490
Iteration 36/1000 | Loss: 0.00002490
Iteration 37/1000 | Loss: 0.00002489
Iteration 38/1000 | Loss: 0.00002489
Iteration 39/1000 | Loss: 0.00002489
Iteration 40/1000 | Loss: 0.00002489
Iteration 41/1000 | Loss: 0.00002489
Iteration 42/1000 | Loss: 0.00002489
Iteration 43/1000 | Loss: 0.00002489
Iteration 44/1000 | Loss: 0.00002489
Iteration 45/1000 | Loss: 0.00002489
Iteration 46/1000 | Loss: 0.00002488
Iteration 47/1000 | Loss: 0.00002488
Iteration 48/1000 | Loss: 0.00002488
Iteration 49/1000 | Loss: 0.00002487
Iteration 50/1000 | Loss: 0.00002487
Iteration 51/1000 | Loss: 0.00002487
Iteration 52/1000 | Loss: 0.00002487
Iteration 53/1000 | Loss: 0.00002486
Iteration 54/1000 | Loss: 0.00002486
Iteration 55/1000 | Loss: 0.00002486
Iteration 56/1000 | Loss: 0.00002486
Iteration 57/1000 | Loss: 0.00002486
Iteration 58/1000 | Loss: 0.00002485
Iteration 59/1000 | Loss: 0.00002485
Iteration 60/1000 | Loss: 0.00002485
Iteration 61/1000 | Loss: 0.00002485
Iteration 62/1000 | Loss: 0.00002485
Iteration 63/1000 | Loss: 0.00002484
Iteration 64/1000 | Loss: 0.00002484
Iteration 65/1000 | Loss: 0.00002484
Iteration 66/1000 | Loss: 0.00002484
Iteration 67/1000 | Loss: 0.00002484
Iteration 68/1000 | Loss: 0.00002484
Iteration 69/1000 | Loss: 0.00002484
Iteration 70/1000 | Loss: 0.00002484
Iteration 71/1000 | Loss: 0.00002484
Iteration 72/1000 | Loss: 0.00002484
Iteration 73/1000 | Loss: 0.00002483
Iteration 74/1000 | Loss: 0.00002483
Iteration 75/1000 | Loss: 0.00002483
Iteration 76/1000 | Loss: 0.00002483
Iteration 77/1000 | Loss: 0.00002483
Iteration 78/1000 | Loss: 0.00002483
Iteration 79/1000 | Loss: 0.00002483
Iteration 80/1000 | Loss: 0.00002482
Iteration 81/1000 | Loss: 0.00002482
Iteration 82/1000 | Loss: 0.00002482
Iteration 83/1000 | Loss: 0.00002482
Iteration 84/1000 | Loss: 0.00002482
Iteration 85/1000 | Loss: 0.00002482
Iteration 86/1000 | Loss: 0.00002482
Iteration 87/1000 | Loss: 0.00002482
Iteration 88/1000 | Loss: 0.00002482
Iteration 89/1000 | Loss: 0.00002482
Iteration 90/1000 | Loss: 0.00002481
Iteration 91/1000 | Loss: 0.00002481
Iteration 92/1000 | Loss: 0.00002481
Iteration 93/1000 | Loss: 0.00002481
Iteration 94/1000 | Loss: 0.00002481
Iteration 95/1000 | Loss: 0.00002480
Iteration 96/1000 | Loss: 0.00002480
Iteration 97/1000 | Loss: 0.00002480
Iteration 98/1000 | Loss: 0.00002480
Iteration 99/1000 | Loss: 0.00002480
Iteration 100/1000 | Loss: 0.00002480
Iteration 101/1000 | Loss: 0.00002480
Iteration 102/1000 | Loss: 0.00002480
Iteration 103/1000 | Loss: 0.00002480
Iteration 104/1000 | Loss: 0.00002480
Iteration 105/1000 | Loss: 0.00002480
Iteration 106/1000 | Loss: 0.00002480
Iteration 107/1000 | Loss: 0.00002480
Iteration 108/1000 | Loss: 0.00002480
Iteration 109/1000 | Loss: 0.00002480
Iteration 110/1000 | Loss: 0.00002480
Iteration 111/1000 | Loss: 0.00002479
Iteration 112/1000 | Loss: 0.00002479
Iteration 113/1000 | Loss: 0.00002479
Iteration 114/1000 | Loss: 0.00002479
Iteration 115/1000 | Loss: 0.00002479
Iteration 116/1000 | Loss: 0.00002479
Iteration 117/1000 | Loss: 0.00002479
Iteration 118/1000 | Loss: 0.00002479
Iteration 119/1000 | Loss: 0.00002479
Iteration 120/1000 | Loss: 0.00002479
Iteration 121/1000 | Loss: 0.00002478
Iteration 122/1000 | Loss: 0.00002478
Iteration 123/1000 | Loss: 0.00002478
Iteration 124/1000 | Loss: 0.00002478
Iteration 125/1000 | Loss: 0.00002478
Iteration 126/1000 | Loss: 0.00002478
Iteration 127/1000 | Loss: 0.00002478
Iteration 128/1000 | Loss: 0.00002478
Iteration 129/1000 | Loss: 0.00002478
Iteration 130/1000 | Loss: 0.00002478
Iteration 131/1000 | Loss: 0.00002478
Iteration 132/1000 | Loss: 0.00002478
Iteration 133/1000 | Loss: 0.00002478
Iteration 134/1000 | Loss: 0.00002478
Iteration 135/1000 | Loss: 0.00002478
Iteration 136/1000 | Loss: 0.00002478
Iteration 137/1000 | Loss: 0.00002478
Iteration 138/1000 | Loss: 0.00002478
Iteration 139/1000 | Loss: 0.00002478
Iteration 140/1000 | Loss: 0.00002478
Iteration 141/1000 | Loss: 0.00002478
Iteration 142/1000 | Loss: 0.00002478
Iteration 143/1000 | Loss: 0.00002478
Iteration 144/1000 | Loss: 0.00002478
Iteration 145/1000 | Loss: 0.00002478
Iteration 146/1000 | Loss: 0.00002478
Iteration 147/1000 | Loss: 0.00002478
Iteration 148/1000 | Loss: 0.00002478
Iteration 149/1000 | Loss: 0.00002478
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 149. Stopping optimization.
Last 5 losses: [2.4784196284599602e-05, 2.4784196284599602e-05, 2.4784196284599602e-05, 2.4784196284599602e-05, 2.4784196284599602e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4784196284599602e-05

Optimization complete. Final v2v error: 4.133115768432617 mm

Highest mean error: 4.433162689208984 mm for frame 25

Lowest mean error: 3.6632256507873535 mm for frame 46

Saving results

Total time: 39.11845541000366
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1068/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1068.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1068
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00540055
Iteration 2/25 | Loss: 0.00103647
Iteration 3/25 | Loss: 0.00082596
Iteration 4/25 | Loss: 0.00079876
Iteration 5/25 | Loss: 0.00079331
Iteration 6/25 | Loss: 0.00079132
Iteration 7/25 | Loss: 0.00079078
Iteration 8/25 | Loss: 0.00079078
Iteration 9/25 | Loss: 0.00079078
Iteration 10/25 | Loss: 0.00079078
Iteration 11/25 | Loss: 0.00079078
Iteration 12/25 | Loss: 0.00079078
Iteration 13/25 | Loss: 0.00079078
Iteration 14/25 | Loss: 0.00079078
Iteration 15/25 | Loss: 0.00079078
Iteration 16/25 | Loss: 0.00079078
Iteration 17/25 | Loss: 0.00079078
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007907788385637105, 0.0007907788385637105, 0.0007907788385637105, 0.0007907788385637105, 0.0007907788385637105]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007907788385637105

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.62480927
Iteration 2/25 | Loss: 0.00133754
Iteration 3/25 | Loss: 0.00133753
Iteration 4/25 | Loss: 0.00133753
Iteration 5/25 | Loss: 0.00133753
Iteration 6/25 | Loss: 0.00133753
Iteration 7/25 | Loss: 0.00133753
Iteration 8/25 | Loss: 0.00133753
Iteration 9/25 | Loss: 0.00133753
Iteration 10/25 | Loss: 0.00133753
Iteration 11/25 | Loss: 0.00133753
Iteration 12/25 | Loss: 0.00133753
Iteration 13/25 | Loss: 0.00133753
Iteration 14/25 | Loss: 0.00133753
Iteration 15/25 | Loss: 0.00133753
Iteration 16/25 | Loss: 0.00133753
Iteration 17/25 | Loss: 0.00133753
Iteration 18/25 | Loss: 0.00133753
Iteration 19/25 | Loss: 0.00133753
Iteration 20/25 | Loss: 0.00133753
Iteration 21/25 | Loss: 0.00133753
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0013375254347920418, 0.0013375254347920418, 0.0013375254347920418, 0.0013375254347920418, 0.0013375254347920418]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013375254347920418

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00133753
Iteration 2/1000 | Loss: 0.00002700
Iteration 3/1000 | Loss: 0.00001899
Iteration 4/1000 | Loss: 0.00001804
Iteration 5/1000 | Loss: 0.00001724
Iteration 6/1000 | Loss: 0.00001684
Iteration 7/1000 | Loss: 0.00001647
Iteration 8/1000 | Loss: 0.00001620
Iteration 9/1000 | Loss: 0.00001600
Iteration 10/1000 | Loss: 0.00001589
Iteration 11/1000 | Loss: 0.00001581
Iteration 12/1000 | Loss: 0.00001574
Iteration 13/1000 | Loss: 0.00001568
Iteration 14/1000 | Loss: 0.00001567
Iteration 15/1000 | Loss: 0.00001566
Iteration 16/1000 | Loss: 0.00001564
Iteration 17/1000 | Loss: 0.00001564
Iteration 18/1000 | Loss: 0.00001563
Iteration 19/1000 | Loss: 0.00001563
Iteration 20/1000 | Loss: 0.00001562
Iteration 21/1000 | Loss: 0.00001562
Iteration 22/1000 | Loss: 0.00001562
Iteration 23/1000 | Loss: 0.00001561
Iteration 24/1000 | Loss: 0.00001561
Iteration 25/1000 | Loss: 0.00001560
Iteration 26/1000 | Loss: 0.00001560
Iteration 27/1000 | Loss: 0.00001559
Iteration 28/1000 | Loss: 0.00001559
Iteration 29/1000 | Loss: 0.00001559
Iteration 30/1000 | Loss: 0.00001558
Iteration 31/1000 | Loss: 0.00001558
Iteration 32/1000 | Loss: 0.00001557
Iteration 33/1000 | Loss: 0.00001557
Iteration 34/1000 | Loss: 0.00001556
Iteration 35/1000 | Loss: 0.00001556
Iteration 36/1000 | Loss: 0.00001556
Iteration 37/1000 | Loss: 0.00001556
Iteration 38/1000 | Loss: 0.00001555
Iteration 39/1000 | Loss: 0.00001555
Iteration 40/1000 | Loss: 0.00001554
Iteration 41/1000 | Loss: 0.00001554
Iteration 42/1000 | Loss: 0.00001554
Iteration 43/1000 | Loss: 0.00001553
Iteration 44/1000 | Loss: 0.00001553
Iteration 45/1000 | Loss: 0.00001553
Iteration 46/1000 | Loss: 0.00001553
Iteration 47/1000 | Loss: 0.00001552
Iteration 48/1000 | Loss: 0.00001552
Iteration 49/1000 | Loss: 0.00001552
Iteration 50/1000 | Loss: 0.00001551
Iteration 51/1000 | Loss: 0.00001551
Iteration 52/1000 | Loss: 0.00001550
Iteration 53/1000 | Loss: 0.00001550
Iteration 54/1000 | Loss: 0.00001550
Iteration 55/1000 | Loss: 0.00001550
Iteration 56/1000 | Loss: 0.00001550
Iteration 57/1000 | Loss: 0.00001550
Iteration 58/1000 | Loss: 0.00001550
Iteration 59/1000 | Loss: 0.00001550
Iteration 60/1000 | Loss: 0.00001550
Iteration 61/1000 | Loss: 0.00001550
Iteration 62/1000 | Loss: 0.00001549
Iteration 63/1000 | Loss: 0.00001549
Iteration 64/1000 | Loss: 0.00001548
Iteration 65/1000 | Loss: 0.00001548
Iteration 66/1000 | Loss: 0.00001547
Iteration 67/1000 | Loss: 0.00001547
Iteration 68/1000 | Loss: 0.00001547
Iteration 69/1000 | Loss: 0.00001547
Iteration 70/1000 | Loss: 0.00001547
Iteration 71/1000 | Loss: 0.00001546
Iteration 72/1000 | Loss: 0.00001546
Iteration 73/1000 | Loss: 0.00001546
Iteration 74/1000 | Loss: 0.00001546
Iteration 75/1000 | Loss: 0.00001546
Iteration 76/1000 | Loss: 0.00001546
Iteration 77/1000 | Loss: 0.00001545
Iteration 78/1000 | Loss: 0.00001545
Iteration 79/1000 | Loss: 0.00001545
Iteration 80/1000 | Loss: 0.00001544
Iteration 81/1000 | Loss: 0.00001544
Iteration 82/1000 | Loss: 0.00001544
Iteration 83/1000 | Loss: 0.00001544
Iteration 84/1000 | Loss: 0.00001544
Iteration 85/1000 | Loss: 0.00001544
Iteration 86/1000 | Loss: 0.00001544
Iteration 87/1000 | Loss: 0.00001544
Iteration 88/1000 | Loss: 0.00001544
Iteration 89/1000 | Loss: 0.00001544
Iteration 90/1000 | Loss: 0.00001544
Iteration 91/1000 | Loss: 0.00001544
Iteration 92/1000 | Loss: 0.00001543
Iteration 93/1000 | Loss: 0.00001543
Iteration 94/1000 | Loss: 0.00001543
Iteration 95/1000 | Loss: 0.00001543
Iteration 96/1000 | Loss: 0.00001543
Iteration 97/1000 | Loss: 0.00001543
Iteration 98/1000 | Loss: 0.00001543
Iteration 99/1000 | Loss: 0.00001542
Iteration 100/1000 | Loss: 0.00001542
Iteration 101/1000 | Loss: 0.00001542
Iteration 102/1000 | Loss: 0.00001542
Iteration 103/1000 | Loss: 0.00001542
Iteration 104/1000 | Loss: 0.00001542
Iteration 105/1000 | Loss: 0.00001542
Iteration 106/1000 | Loss: 0.00001542
Iteration 107/1000 | Loss: 0.00001542
Iteration 108/1000 | Loss: 0.00001542
Iteration 109/1000 | Loss: 0.00001542
Iteration 110/1000 | Loss: 0.00001542
Iteration 111/1000 | Loss: 0.00001542
Iteration 112/1000 | Loss: 0.00001541
Iteration 113/1000 | Loss: 0.00001541
Iteration 114/1000 | Loss: 0.00001541
Iteration 115/1000 | Loss: 0.00001541
Iteration 116/1000 | Loss: 0.00001541
Iteration 117/1000 | Loss: 0.00001541
Iteration 118/1000 | Loss: 0.00001541
Iteration 119/1000 | Loss: 0.00001541
Iteration 120/1000 | Loss: 0.00001540
Iteration 121/1000 | Loss: 0.00001540
Iteration 122/1000 | Loss: 0.00001540
Iteration 123/1000 | Loss: 0.00001540
Iteration 124/1000 | Loss: 0.00001540
Iteration 125/1000 | Loss: 0.00001540
Iteration 126/1000 | Loss: 0.00001540
Iteration 127/1000 | Loss: 0.00001540
Iteration 128/1000 | Loss: 0.00001540
Iteration 129/1000 | Loss: 0.00001540
Iteration 130/1000 | Loss: 0.00001540
Iteration 131/1000 | Loss: 0.00001539
Iteration 132/1000 | Loss: 0.00001539
Iteration 133/1000 | Loss: 0.00001539
Iteration 134/1000 | Loss: 0.00001539
Iteration 135/1000 | Loss: 0.00001539
Iteration 136/1000 | Loss: 0.00001539
Iteration 137/1000 | Loss: 0.00001539
Iteration 138/1000 | Loss: 0.00001539
Iteration 139/1000 | Loss: 0.00001539
Iteration 140/1000 | Loss: 0.00001539
Iteration 141/1000 | Loss: 0.00001539
Iteration 142/1000 | Loss: 0.00001539
Iteration 143/1000 | Loss: 0.00001539
Iteration 144/1000 | Loss: 0.00001538
Iteration 145/1000 | Loss: 0.00001538
Iteration 146/1000 | Loss: 0.00001538
Iteration 147/1000 | Loss: 0.00001538
Iteration 148/1000 | Loss: 0.00001538
Iteration 149/1000 | Loss: 0.00001538
Iteration 150/1000 | Loss: 0.00001538
Iteration 151/1000 | Loss: 0.00001538
Iteration 152/1000 | Loss: 0.00001538
Iteration 153/1000 | Loss: 0.00001538
Iteration 154/1000 | Loss: 0.00001537
Iteration 155/1000 | Loss: 0.00001537
Iteration 156/1000 | Loss: 0.00001537
Iteration 157/1000 | Loss: 0.00001537
Iteration 158/1000 | Loss: 0.00001537
Iteration 159/1000 | Loss: 0.00001537
Iteration 160/1000 | Loss: 0.00001537
Iteration 161/1000 | Loss: 0.00001537
Iteration 162/1000 | Loss: 0.00001537
Iteration 163/1000 | Loss: 0.00001537
Iteration 164/1000 | Loss: 0.00001537
Iteration 165/1000 | Loss: 0.00001537
Iteration 166/1000 | Loss: 0.00001536
Iteration 167/1000 | Loss: 0.00001536
Iteration 168/1000 | Loss: 0.00001536
Iteration 169/1000 | Loss: 0.00001536
Iteration 170/1000 | Loss: 0.00001536
Iteration 171/1000 | Loss: 0.00001536
Iteration 172/1000 | Loss: 0.00001536
Iteration 173/1000 | Loss: 0.00001535
Iteration 174/1000 | Loss: 0.00001535
Iteration 175/1000 | Loss: 0.00001535
Iteration 176/1000 | Loss: 0.00001535
Iteration 177/1000 | Loss: 0.00001535
Iteration 178/1000 | Loss: 0.00001535
Iteration 179/1000 | Loss: 0.00001535
Iteration 180/1000 | Loss: 0.00001535
Iteration 181/1000 | Loss: 0.00001535
Iteration 182/1000 | Loss: 0.00001535
Iteration 183/1000 | Loss: 0.00001535
Iteration 184/1000 | Loss: 0.00001535
Iteration 185/1000 | Loss: 0.00001535
Iteration 186/1000 | Loss: 0.00001535
Iteration 187/1000 | Loss: 0.00001535
Iteration 188/1000 | Loss: 0.00001534
Iteration 189/1000 | Loss: 0.00001534
Iteration 190/1000 | Loss: 0.00001534
Iteration 191/1000 | Loss: 0.00001534
Iteration 192/1000 | Loss: 0.00001534
Iteration 193/1000 | Loss: 0.00001534
Iteration 194/1000 | Loss: 0.00001534
Iteration 195/1000 | Loss: 0.00001534
Iteration 196/1000 | Loss: 0.00001534
Iteration 197/1000 | Loss: 0.00001534
Iteration 198/1000 | Loss: 0.00001534
Iteration 199/1000 | Loss: 0.00001534
Iteration 200/1000 | Loss: 0.00001534
Iteration 201/1000 | Loss: 0.00001534
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 201. Stopping optimization.
Last 5 losses: [1.53419441630831e-05, 1.53419441630831e-05, 1.53419441630831e-05, 1.53419441630831e-05, 1.53419441630831e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.53419441630831e-05

Optimization complete. Final v2v error: 3.3050193786621094 mm

Highest mean error: 4.074976444244385 mm for frame 68

Lowest mean error: 2.9413492679595947 mm for frame 112

Saving results

Total time: 38.5278959274292
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1079
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00409348
Iteration 2/25 | Loss: 0.00097682
Iteration 3/25 | Loss: 0.00078885
Iteration 4/25 | Loss: 0.00077283
Iteration 5/25 | Loss: 0.00076544
Iteration 6/25 | Loss: 0.00076307
Iteration 7/25 | Loss: 0.00076256
Iteration 8/25 | Loss: 0.00076256
Iteration 9/25 | Loss: 0.00076256
Iteration 10/25 | Loss: 0.00076256
Iteration 11/25 | Loss: 0.00076256
Iteration 12/25 | Loss: 0.00076256
Iteration 13/25 | Loss: 0.00076256
Iteration 14/25 | Loss: 0.00076256
Iteration 15/25 | Loss: 0.00076256
Iteration 16/25 | Loss: 0.00076256
Iteration 17/25 | Loss: 0.00076256
Iteration 18/25 | Loss: 0.00076256
Iteration 19/25 | Loss: 0.00076256
Iteration 20/25 | Loss: 0.00076256
Iteration 21/25 | Loss: 0.00076256
Iteration 22/25 | Loss: 0.00076256
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0007625564467161894, 0.0007625564467161894, 0.0007625564467161894, 0.0007625564467161894, 0.0007625564467161894]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007625564467161894

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.89783573
Iteration 2/25 | Loss: 0.00139529
Iteration 3/25 | Loss: 0.00139527
Iteration 4/25 | Loss: 0.00139527
Iteration 5/25 | Loss: 0.00139527
Iteration 6/25 | Loss: 0.00139527
Iteration 7/25 | Loss: 0.00139527
Iteration 8/25 | Loss: 0.00139527
Iteration 9/25 | Loss: 0.00139527
Iteration 10/25 | Loss: 0.00139527
Iteration 11/25 | Loss: 0.00139527
Iteration 12/25 | Loss: 0.00139527
Iteration 13/25 | Loss: 0.00139527
Iteration 14/25 | Loss: 0.00139527
Iteration 15/25 | Loss: 0.00139527
Iteration 16/25 | Loss: 0.00139527
Iteration 17/25 | Loss: 0.00139527
Iteration 18/25 | Loss: 0.00139527
Iteration 19/25 | Loss: 0.00139527
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0013952698791399598, 0.0013952698791399598, 0.0013952698791399598, 0.0013952698791399598, 0.0013952698791399598]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013952698791399598

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00139527
Iteration 2/1000 | Loss: 0.00002564
Iteration 3/1000 | Loss: 0.00001690
Iteration 4/1000 | Loss: 0.00001468
Iteration 5/1000 | Loss: 0.00001356
Iteration 6/1000 | Loss: 0.00001307
Iteration 7/1000 | Loss: 0.00001274
Iteration 8/1000 | Loss: 0.00001253
Iteration 9/1000 | Loss: 0.00001226
Iteration 10/1000 | Loss: 0.00001220
Iteration 11/1000 | Loss: 0.00001199
Iteration 12/1000 | Loss: 0.00001190
Iteration 13/1000 | Loss: 0.00001188
Iteration 14/1000 | Loss: 0.00001188
Iteration 15/1000 | Loss: 0.00001186
Iteration 16/1000 | Loss: 0.00001180
Iteration 17/1000 | Loss: 0.00001172
Iteration 18/1000 | Loss: 0.00001164
Iteration 19/1000 | Loss: 0.00001162
Iteration 20/1000 | Loss: 0.00001162
Iteration 21/1000 | Loss: 0.00001162
Iteration 22/1000 | Loss: 0.00001162
Iteration 23/1000 | Loss: 0.00001161
Iteration 24/1000 | Loss: 0.00001161
Iteration 25/1000 | Loss: 0.00001161
Iteration 26/1000 | Loss: 0.00001161
Iteration 27/1000 | Loss: 0.00001161
Iteration 28/1000 | Loss: 0.00001161
Iteration 29/1000 | Loss: 0.00001161
Iteration 30/1000 | Loss: 0.00001160
Iteration 31/1000 | Loss: 0.00001160
Iteration 32/1000 | Loss: 0.00001159
Iteration 33/1000 | Loss: 0.00001159
Iteration 34/1000 | Loss: 0.00001158
Iteration 35/1000 | Loss: 0.00001158
Iteration 36/1000 | Loss: 0.00001158
Iteration 37/1000 | Loss: 0.00001158
Iteration 38/1000 | Loss: 0.00001158
Iteration 39/1000 | Loss: 0.00001158
Iteration 40/1000 | Loss: 0.00001158
Iteration 41/1000 | Loss: 0.00001158
Iteration 42/1000 | Loss: 0.00001158
Iteration 43/1000 | Loss: 0.00001158
Iteration 44/1000 | Loss: 0.00001157
Iteration 45/1000 | Loss: 0.00001157
Iteration 46/1000 | Loss: 0.00001157
Iteration 47/1000 | Loss: 0.00001156
Iteration 48/1000 | Loss: 0.00001156
Iteration 49/1000 | Loss: 0.00001155
Iteration 50/1000 | Loss: 0.00001155
Iteration 51/1000 | Loss: 0.00001155
Iteration 52/1000 | Loss: 0.00001155
Iteration 53/1000 | Loss: 0.00001155
Iteration 54/1000 | Loss: 0.00001155
Iteration 55/1000 | Loss: 0.00001155
Iteration 56/1000 | Loss: 0.00001155
Iteration 57/1000 | Loss: 0.00001155
Iteration 58/1000 | Loss: 0.00001155
Iteration 59/1000 | Loss: 0.00001154
Iteration 60/1000 | Loss: 0.00001154
Iteration 61/1000 | Loss: 0.00001154
Iteration 62/1000 | Loss: 0.00001154
Iteration 63/1000 | Loss: 0.00001154
Iteration 64/1000 | Loss: 0.00001154
Iteration 65/1000 | Loss: 0.00001154
Iteration 66/1000 | Loss: 0.00001154
Iteration 67/1000 | Loss: 0.00001153
Iteration 68/1000 | Loss: 0.00001153
Iteration 69/1000 | Loss: 0.00001153
Iteration 70/1000 | Loss: 0.00001153
Iteration 71/1000 | Loss: 0.00001153
Iteration 72/1000 | Loss: 0.00001153
Iteration 73/1000 | Loss: 0.00001153
Iteration 74/1000 | Loss: 0.00001153
Iteration 75/1000 | Loss: 0.00001153
Iteration 76/1000 | Loss: 0.00001153
Iteration 77/1000 | Loss: 0.00001153
Iteration 78/1000 | Loss: 0.00001153
Iteration 79/1000 | Loss: 0.00001153
Iteration 80/1000 | Loss: 0.00001153
Iteration 81/1000 | Loss: 0.00001153
Iteration 82/1000 | Loss: 0.00001153
Iteration 83/1000 | Loss: 0.00001153
Iteration 84/1000 | Loss: 0.00001153
Iteration 85/1000 | Loss: 0.00001153
Iteration 86/1000 | Loss: 0.00001153
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 86. Stopping optimization.
Last 5 losses: [1.1526039088494144e-05, 1.1526039088494144e-05, 1.1526039088494144e-05, 1.1526039088494144e-05, 1.1526039088494144e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1526039088494144e-05

Optimization complete. Final v2v error: 2.901576280593872 mm

Highest mean error: 3.217839241027832 mm for frame 40

Lowest mean error: 2.7516543865203857 mm for frame 266

Saving results

Total time: 38.46737360954285
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01075136
Iteration 2/25 | Loss: 0.00288210
Iteration 3/25 | Loss: 0.00237548
Iteration 4/25 | Loss: 0.00216065
Iteration 5/25 | Loss: 0.00202382
Iteration 6/25 | Loss: 0.00196428
Iteration 7/25 | Loss: 0.00198431
Iteration 8/25 | Loss: 0.00183985
Iteration 9/25 | Loss: 0.00174781
Iteration 10/25 | Loss: 0.00167870
Iteration 11/25 | Loss: 0.00166472
Iteration 12/25 | Loss: 0.00165085
Iteration 13/25 | Loss: 0.00162641
Iteration 14/25 | Loss: 0.00159356
Iteration 15/25 | Loss: 0.00157302
Iteration 16/25 | Loss: 0.00156759
Iteration 17/25 | Loss: 0.00156174
Iteration 18/25 | Loss: 0.00155961
Iteration 19/25 | Loss: 0.00155841
Iteration 20/25 | Loss: 0.00155930
Iteration 21/25 | Loss: 0.00155489
Iteration 22/25 | Loss: 0.00155398
Iteration 23/25 | Loss: 0.00155368
Iteration 24/25 | Loss: 0.00155345
Iteration 25/25 | Loss: 0.00155333

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57166100
Iteration 2/25 | Loss: 0.00762769
Iteration 3/25 | Loss: 0.00762767
Iteration 4/25 | Loss: 0.00762766
Iteration 5/25 | Loss: 0.00762766
Iteration 6/25 | Loss: 0.00762766
Iteration 7/25 | Loss: 0.00762766
Iteration 8/25 | Loss: 0.00762766
Iteration 9/25 | Loss: 0.00762766
Iteration 10/25 | Loss: 0.00762766
Iteration 11/25 | Loss: 0.00762766
Iteration 12/25 | Loss: 0.00762766
Iteration 13/25 | Loss: 0.00762766
Iteration 14/25 | Loss: 0.00762766
Iteration 15/25 | Loss: 0.00762766
Iteration 16/25 | Loss: 0.00762766
Iteration 17/25 | Loss: 0.00762766
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.007627660874277353, 0.007627660874277353, 0.007627660874277353, 0.007627660874277353, 0.007627660874277353]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.007627660874277353

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00762766
Iteration 2/1000 | Loss: 0.01383227
Iteration 3/1000 | Loss: 0.00122068
Iteration 4/1000 | Loss: 0.00087219
Iteration 5/1000 | Loss: 0.00072133
Iteration 6/1000 | Loss: 0.00103789
Iteration 7/1000 | Loss: 0.00047519
Iteration 8/1000 | Loss: 0.00062532
Iteration 9/1000 | Loss: 0.00038413
Iteration 10/1000 | Loss: 0.00034155
Iteration 11/1000 | Loss: 0.00030250
Iteration 12/1000 | Loss: 0.00027875
Iteration 13/1000 | Loss: 0.00025651
Iteration 14/1000 | Loss: 0.00023813
Iteration 15/1000 | Loss: 0.00449989
Iteration 16/1000 | Loss: 0.00485560
Iteration 17/1000 | Loss: 0.00109207
Iteration 18/1000 | Loss: 0.00047010
Iteration 19/1000 | Loss: 0.00036419
Iteration 20/1000 | Loss: 0.00029313
Iteration 21/1000 | Loss: 0.00027161
Iteration 22/1000 | Loss: 0.00047591
Iteration 23/1000 | Loss: 0.00024792
Iteration 24/1000 | Loss: 0.00033523
Iteration 25/1000 | Loss: 0.00038965
Iteration 26/1000 | Loss: 0.00079701
Iteration 27/1000 | Loss: 0.00017920
Iteration 28/1000 | Loss: 0.00053517
Iteration 29/1000 | Loss: 0.00041732
Iteration 30/1000 | Loss: 0.00027738
Iteration 31/1000 | Loss: 0.00030540
Iteration 32/1000 | Loss: 0.00014969
Iteration 33/1000 | Loss: 0.00013717
Iteration 34/1000 | Loss: 0.00078697
Iteration 35/1000 | Loss: 0.00030696
Iteration 36/1000 | Loss: 0.00015749
Iteration 37/1000 | Loss: 0.00013329
Iteration 38/1000 | Loss: 0.00051981
Iteration 39/1000 | Loss: 0.00241363
Iteration 40/1000 | Loss: 0.00123488
Iteration 41/1000 | Loss: 0.00109410
Iteration 42/1000 | Loss: 0.00055139
Iteration 43/1000 | Loss: 0.00018713
Iteration 44/1000 | Loss: 0.00014843
Iteration 45/1000 | Loss: 0.00044523
Iteration 46/1000 | Loss: 0.00017034
Iteration 47/1000 | Loss: 0.00013904
Iteration 48/1000 | Loss: 0.00087569
Iteration 49/1000 | Loss: 0.00022667
Iteration 50/1000 | Loss: 0.00016988
Iteration 51/1000 | Loss: 0.00014188
Iteration 52/1000 | Loss: 0.00013938
Iteration 53/1000 | Loss: 0.00011548
Iteration 54/1000 | Loss: 0.00010686
Iteration 55/1000 | Loss: 0.00076174
Iteration 56/1000 | Loss: 0.00044837
Iteration 57/1000 | Loss: 0.00050469
Iteration 58/1000 | Loss: 0.00060451
Iteration 59/1000 | Loss: 0.00013817
Iteration 60/1000 | Loss: 0.00010791
Iteration 61/1000 | Loss: 0.00010030
Iteration 62/1000 | Loss: 0.00044648
Iteration 63/1000 | Loss: 0.00083123
Iteration 64/1000 | Loss: 0.00054021
Iteration 65/1000 | Loss: 0.00041007
Iteration 66/1000 | Loss: 0.00018429
Iteration 67/1000 | Loss: 0.00044241
Iteration 68/1000 | Loss: 0.00013486
Iteration 69/1000 | Loss: 0.00042725
Iteration 70/1000 | Loss: 0.00010014
Iteration 71/1000 | Loss: 0.00008587
Iteration 72/1000 | Loss: 0.00007980
Iteration 73/1000 | Loss: 0.00007468
Iteration 74/1000 | Loss: 0.00007190
Iteration 75/1000 | Loss: 0.00006931
Iteration 76/1000 | Loss: 0.00006797
Iteration 77/1000 | Loss: 0.00006706
Iteration 78/1000 | Loss: 0.00006621
Iteration 79/1000 | Loss: 0.00006561
Iteration 80/1000 | Loss: 0.00006522
Iteration 81/1000 | Loss: 0.00006499
Iteration 82/1000 | Loss: 0.00006481
Iteration 83/1000 | Loss: 0.00006476
Iteration 84/1000 | Loss: 0.00006471
Iteration 85/1000 | Loss: 0.00006471
Iteration 86/1000 | Loss: 0.00006471
Iteration 87/1000 | Loss: 0.00006471
Iteration 88/1000 | Loss: 0.00006470
Iteration 89/1000 | Loss: 0.00006469
Iteration 90/1000 | Loss: 0.00006463
Iteration 91/1000 | Loss: 0.00006460
Iteration 92/1000 | Loss: 0.00006460
Iteration 93/1000 | Loss: 0.00006459
Iteration 94/1000 | Loss: 0.00006459
Iteration 95/1000 | Loss: 0.00006458
Iteration 96/1000 | Loss: 0.00006458
Iteration 97/1000 | Loss: 0.00006458
Iteration 98/1000 | Loss: 0.00006457
Iteration 99/1000 | Loss: 0.00006456
Iteration 100/1000 | Loss: 0.00006456
Iteration 101/1000 | Loss: 0.00006455
Iteration 102/1000 | Loss: 0.00006455
Iteration 103/1000 | Loss: 0.00006455
Iteration 104/1000 | Loss: 0.00006455
Iteration 105/1000 | Loss: 0.00006454
Iteration 106/1000 | Loss: 0.00006454
Iteration 107/1000 | Loss: 0.00006453
Iteration 108/1000 | Loss: 0.00006453
Iteration 109/1000 | Loss: 0.00006453
Iteration 110/1000 | Loss: 0.00006452
Iteration 111/1000 | Loss: 0.00006451
Iteration 112/1000 | Loss: 0.00006451
Iteration 113/1000 | Loss: 0.00006451
Iteration 114/1000 | Loss: 0.00006451
Iteration 115/1000 | Loss: 0.00006451
Iteration 116/1000 | Loss: 0.00006451
Iteration 117/1000 | Loss: 0.00006451
Iteration 118/1000 | Loss: 0.00006451
Iteration 119/1000 | Loss: 0.00006451
Iteration 120/1000 | Loss: 0.00006451
Iteration 121/1000 | Loss: 0.00006450
Iteration 122/1000 | Loss: 0.00006450
Iteration 123/1000 | Loss: 0.00006449
Iteration 124/1000 | Loss: 0.00006449
Iteration 125/1000 | Loss: 0.00006449
Iteration 126/1000 | Loss: 0.00006449
Iteration 127/1000 | Loss: 0.00006449
Iteration 128/1000 | Loss: 0.00006449
Iteration 129/1000 | Loss: 0.00006449
Iteration 130/1000 | Loss: 0.00006448
Iteration 131/1000 | Loss: 0.00006448
Iteration 132/1000 | Loss: 0.00006448
Iteration 133/1000 | Loss: 0.00006448
Iteration 134/1000 | Loss: 0.00006448
Iteration 135/1000 | Loss: 0.00006448
Iteration 136/1000 | Loss: 0.00006448
Iteration 137/1000 | Loss: 0.00006448
Iteration 138/1000 | Loss: 0.00006448
Iteration 139/1000 | Loss: 0.00006448
Iteration 140/1000 | Loss: 0.00006448
Iteration 141/1000 | Loss: 0.00006448
Iteration 142/1000 | Loss: 0.00006448
Iteration 143/1000 | Loss: 0.00006448
Iteration 144/1000 | Loss: 0.00006448
Iteration 145/1000 | Loss: 0.00006447
Iteration 146/1000 | Loss: 0.00006447
Iteration 147/1000 | Loss: 0.00006447
Iteration 148/1000 | Loss: 0.00006447
Iteration 149/1000 | Loss: 0.00006447
Iteration 150/1000 | Loss: 0.00006447
Iteration 151/1000 | Loss: 0.00006447
Iteration 152/1000 | Loss: 0.00006447
Iteration 153/1000 | Loss: 0.00006447
Iteration 154/1000 | Loss: 0.00006447
Iteration 155/1000 | Loss: 0.00006447
Iteration 156/1000 | Loss: 0.00006447
Iteration 157/1000 | Loss: 0.00006447
Iteration 158/1000 | Loss: 0.00006447
Iteration 159/1000 | Loss: 0.00006446
Iteration 160/1000 | Loss: 0.00006446
Iteration 161/1000 | Loss: 0.00006446
Iteration 162/1000 | Loss: 0.00006446
Iteration 163/1000 | Loss: 0.00006446
Iteration 164/1000 | Loss: 0.00006446
Iteration 165/1000 | Loss: 0.00006446
Iteration 166/1000 | Loss: 0.00006446
Iteration 167/1000 | Loss: 0.00006446
Iteration 168/1000 | Loss: 0.00006446
Iteration 169/1000 | Loss: 0.00006446
Iteration 170/1000 | Loss: 0.00006446
Iteration 171/1000 | Loss: 0.00006446
Iteration 172/1000 | Loss: 0.00006445
Iteration 173/1000 | Loss: 0.00006445
Iteration 174/1000 | Loss: 0.00006445
Iteration 175/1000 | Loss: 0.00006445
Iteration 176/1000 | Loss: 0.00006445
Iteration 177/1000 | Loss: 0.00006445
Iteration 178/1000 | Loss: 0.00006445
Iteration 179/1000 | Loss: 0.00006445
Iteration 180/1000 | Loss: 0.00006445
Iteration 181/1000 | Loss: 0.00006445
Iteration 182/1000 | Loss: 0.00006445
Iteration 183/1000 | Loss: 0.00006444
Iteration 184/1000 | Loss: 0.00006444
Iteration 185/1000 | Loss: 0.00006444
Iteration 186/1000 | Loss: 0.00006444
Iteration 187/1000 | Loss: 0.00006444
Iteration 188/1000 | Loss: 0.00006444
Iteration 189/1000 | Loss: 0.00006444
Iteration 190/1000 | Loss: 0.00006444
Iteration 191/1000 | Loss: 0.00006444
Iteration 192/1000 | Loss: 0.00006444
Iteration 193/1000 | Loss: 0.00006444
Iteration 194/1000 | Loss: 0.00006444
Iteration 195/1000 | Loss: 0.00006444
Iteration 196/1000 | Loss: 0.00006444
Iteration 197/1000 | Loss: 0.00006444
Iteration 198/1000 | Loss: 0.00006444
Iteration 199/1000 | Loss: 0.00006444
Iteration 200/1000 | Loss: 0.00006444
Iteration 201/1000 | Loss: 0.00006444
Iteration 202/1000 | Loss: 0.00006444
Iteration 203/1000 | Loss: 0.00006444
Iteration 204/1000 | Loss: 0.00006444
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 204. Stopping optimization.
Last 5 losses: [6.443841994041577e-05, 6.443841994041577e-05, 6.443841994041577e-05, 6.443841994041577e-05, 6.443841994041577e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 6.443841994041577e-05

Optimization complete. Final v2v error: 4.374976634979248 mm

Highest mean error: 10.591452598571777 mm for frame 128

Lowest mean error: 3.147491693496704 mm for frame 157

Saving results

Total time: 169.7785346508026
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00473332
Iteration 2/25 | Loss: 0.00112412
Iteration 3/25 | Loss: 0.00086181
Iteration 4/25 | Loss: 0.00082442
Iteration 5/25 | Loss: 0.00081466
Iteration 6/25 | Loss: 0.00081292
Iteration 7/25 | Loss: 0.00081292
Iteration 8/25 | Loss: 0.00081292
Iteration 9/25 | Loss: 0.00081292
Iteration 10/25 | Loss: 0.00081292
Iteration 11/25 | Loss: 0.00081292
Iteration 12/25 | Loss: 0.00081292
Iteration 13/25 | Loss: 0.00081292
Iteration 14/25 | Loss: 0.00081292
Iteration 15/25 | Loss: 0.00081292
Iteration 16/25 | Loss: 0.00081292
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008129235939122736, 0.0008129235939122736, 0.0008129235939122736, 0.0008129235939122736, 0.0008129235939122736]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008129235939122736

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60104561
Iteration 2/25 | Loss: 0.00118759
Iteration 3/25 | Loss: 0.00118758
Iteration 4/25 | Loss: 0.00118758
Iteration 5/25 | Loss: 0.00118758
Iteration 6/25 | Loss: 0.00118758
Iteration 7/25 | Loss: 0.00118758
Iteration 8/25 | Loss: 0.00118757
Iteration 9/25 | Loss: 0.00118757
Iteration 10/25 | Loss: 0.00118757
Iteration 11/25 | Loss: 0.00118757
Iteration 12/25 | Loss: 0.00118757
Iteration 13/25 | Loss: 0.00118757
Iteration 14/25 | Loss: 0.00118757
Iteration 15/25 | Loss: 0.00118757
Iteration 16/25 | Loss: 0.00118757
Iteration 17/25 | Loss: 0.00118757
Iteration 18/25 | Loss: 0.00118757
Iteration 19/25 | Loss: 0.00118757
Iteration 20/25 | Loss: 0.00118757
Iteration 21/25 | Loss: 0.00118757
Iteration 22/25 | Loss: 0.00118757
Iteration 23/25 | Loss: 0.00118757
Iteration 24/25 | Loss: 0.00118757
Iteration 25/25 | Loss: 0.00118757

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118757
Iteration 2/1000 | Loss: 0.00003155
Iteration 3/1000 | Loss: 0.00002131
Iteration 4/1000 | Loss: 0.00001960
Iteration 5/1000 | Loss: 0.00001842
Iteration 6/1000 | Loss: 0.00001776
Iteration 7/1000 | Loss: 0.00001730
Iteration 8/1000 | Loss: 0.00001689
Iteration 9/1000 | Loss: 0.00001661
Iteration 10/1000 | Loss: 0.00001641
Iteration 11/1000 | Loss: 0.00001627
Iteration 12/1000 | Loss: 0.00001624
Iteration 13/1000 | Loss: 0.00001622
Iteration 14/1000 | Loss: 0.00001618
Iteration 15/1000 | Loss: 0.00001616
Iteration 16/1000 | Loss: 0.00001615
Iteration 17/1000 | Loss: 0.00001614
Iteration 18/1000 | Loss: 0.00001614
Iteration 19/1000 | Loss: 0.00001614
Iteration 20/1000 | Loss: 0.00001613
Iteration 21/1000 | Loss: 0.00001613
Iteration 22/1000 | Loss: 0.00001613
Iteration 23/1000 | Loss: 0.00001612
Iteration 24/1000 | Loss: 0.00001611
Iteration 25/1000 | Loss: 0.00001611
Iteration 26/1000 | Loss: 0.00001610
Iteration 27/1000 | Loss: 0.00001609
Iteration 28/1000 | Loss: 0.00001609
Iteration 29/1000 | Loss: 0.00001608
Iteration 30/1000 | Loss: 0.00001608
Iteration 31/1000 | Loss: 0.00001608
Iteration 32/1000 | Loss: 0.00001607
Iteration 33/1000 | Loss: 0.00001607
Iteration 34/1000 | Loss: 0.00001606
Iteration 35/1000 | Loss: 0.00001606
Iteration 36/1000 | Loss: 0.00001605
Iteration 37/1000 | Loss: 0.00001603
Iteration 38/1000 | Loss: 0.00001603
Iteration 39/1000 | Loss: 0.00001602
Iteration 40/1000 | Loss: 0.00001601
Iteration 41/1000 | Loss: 0.00001600
Iteration 42/1000 | Loss: 0.00001600
Iteration 43/1000 | Loss: 0.00001600
Iteration 44/1000 | Loss: 0.00001599
Iteration 45/1000 | Loss: 0.00001599
Iteration 46/1000 | Loss: 0.00001599
Iteration 47/1000 | Loss: 0.00001599
Iteration 48/1000 | Loss: 0.00001599
Iteration 49/1000 | Loss: 0.00001599
Iteration 50/1000 | Loss: 0.00001599
Iteration 51/1000 | Loss: 0.00001599
Iteration 52/1000 | Loss: 0.00001599
Iteration 53/1000 | Loss: 0.00001599
Iteration 54/1000 | Loss: 0.00001599
Iteration 55/1000 | Loss: 0.00001599
Iteration 56/1000 | Loss: 0.00001599
Iteration 57/1000 | Loss: 0.00001599
Iteration 58/1000 | Loss: 0.00001599
Iteration 59/1000 | Loss: 0.00001599
Iteration 60/1000 | Loss: 0.00001599
Iteration 61/1000 | Loss: 0.00001599
Iteration 62/1000 | Loss: 0.00001599
Iteration 63/1000 | Loss: 0.00001599
Iteration 64/1000 | Loss: 0.00001599
Iteration 65/1000 | Loss: 0.00001599
Iteration 66/1000 | Loss: 0.00001599
Iteration 67/1000 | Loss: 0.00001599
Iteration 68/1000 | Loss: 0.00001599
Iteration 69/1000 | Loss: 0.00001599
Iteration 70/1000 | Loss: 0.00001599
Iteration 71/1000 | Loss: 0.00001599
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 71. Stopping optimization.
Last 5 losses: [1.598513699718751e-05, 1.598513699718751e-05, 1.598513699718751e-05, 1.598513699718751e-05, 1.598513699718751e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.598513699718751e-05

Optimization complete. Final v2v error: 3.3391449451446533 mm

Highest mean error: 3.5673420429229736 mm for frame 231

Lowest mean error: 3.0495808124542236 mm for frame 150

Saving results

Total time: 34.11958622932434
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00694693
Iteration 2/25 | Loss: 0.00122468
Iteration 3/25 | Loss: 0.00088910
Iteration 4/25 | Loss: 0.00084198
Iteration 5/25 | Loss: 0.00083355
Iteration 6/25 | Loss: 0.00083181
Iteration 7/25 | Loss: 0.00083181
Iteration 8/25 | Loss: 0.00083181
Iteration 9/25 | Loss: 0.00083181
Iteration 10/25 | Loss: 0.00083181
Iteration 11/25 | Loss: 0.00083181
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008318073814734817, 0.0008318073814734817, 0.0008318073814734817, 0.0008318073814734817, 0.0008318073814734817]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008318073814734817

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.02249813
Iteration 2/25 | Loss: 0.00107438
Iteration 3/25 | Loss: 0.00107435
Iteration 4/25 | Loss: 0.00107435
Iteration 5/25 | Loss: 0.00107435
Iteration 6/25 | Loss: 0.00107435
Iteration 7/25 | Loss: 0.00107435
Iteration 8/25 | Loss: 0.00107435
Iteration 9/25 | Loss: 0.00107435
Iteration 10/25 | Loss: 0.00107435
Iteration 11/25 | Loss: 0.00107435
Iteration 12/25 | Loss: 0.00107435
Iteration 13/25 | Loss: 0.00107435
Iteration 14/25 | Loss: 0.00107435
Iteration 15/25 | Loss: 0.00107435
Iteration 16/25 | Loss: 0.00107435
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010743506718426943, 0.0010743506718426943, 0.0010743506718426943, 0.0010743506718426943, 0.0010743506718426943]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010743506718426943

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00107435
Iteration 2/1000 | Loss: 0.00004375
Iteration 3/1000 | Loss: 0.00002556
Iteration 4/1000 | Loss: 0.00002368
Iteration 5/1000 | Loss: 0.00002261
Iteration 6/1000 | Loss: 0.00002159
Iteration 7/1000 | Loss: 0.00002107
Iteration 8/1000 | Loss: 0.00002060
Iteration 9/1000 | Loss: 0.00002034
Iteration 10/1000 | Loss: 0.00002030
Iteration 11/1000 | Loss: 0.00002028
Iteration 12/1000 | Loss: 0.00002014
Iteration 13/1000 | Loss: 0.00002011
Iteration 14/1000 | Loss: 0.00002011
Iteration 15/1000 | Loss: 0.00002008
Iteration 16/1000 | Loss: 0.00002008
Iteration 17/1000 | Loss: 0.00002008
Iteration 18/1000 | Loss: 0.00002007
Iteration 19/1000 | Loss: 0.00002006
Iteration 20/1000 | Loss: 0.00002006
Iteration 21/1000 | Loss: 0.00002005
Iteration 22/1000 | Loss: 0.00002004
Iteration 23/1000 | Loss: 0.00002003
Iteration 24/1000 | Loss: 0.00001999
Iteration 25/1000 | Loss: 0.00001996
Iteration 26/1000 | Loss: 0.00001996
Iteration 27/1000 | Loss: 0.00001995
Iteration 28/1000 | Loss: 0.00001994
Iteration 29/1000 | Loss: 0.00001994
Iteration 30/1000 | Loss: 0.00001993
Iteration 31/1000 | Loss: 0.00001993
Iteration 32/1000 | Loss: 0.00001992
Iteration 33/1000 | Loss: 0.00001992
Iteration 34/1000 | Loss: 0.00001992
Iteration 35/1000 | Loss: 0.00001991
Iteration 36/1000 | Loss: 0.00001991
Iteration 37/1000 | Loss: 0.00001991
Iteration 38/1000 | Loss: 0.00001991
Iteration 39/1000 | Loss: 0.00001991
Iteration 40/1000 | Loss: 0.00001990
Iteration 41/1000 | Loss: 0.00001990
Iteration 42/1000 | Loss: 0.00001989
Iteration 43/1000 | Loss: 0.00001989
Iteration 44/1000 | Loss: 0.00001989
Iteration 45/1000 | Loss: 0.00001989
Iteration 46/1000 | Loss: 0.00001989
Iteration 47/1000 | Loss: 0.00001989
Iteration 48/1000 | Loss: 0.00001989
Iteration 49/1000 | Loss: 0.00001988
Iteration 50/1000 | Loss: 0.00001988
Iteration 51/1000 | Loss: 0.00001988
Iteration 52/1000 | Loss: 0.00001988
Iteration 53/1000 | Loss: 0.00001988
Iteration 54/1000 | Loss: 0.00001988
Iteration 55/1000 | Loss: 0.00001987
Iteration 56/1000 | Loss: 0.00001987
Iteration 57/1000 | Loss: 0.00001987
Iteration 58/1000 | Loss: 0.00001987
Iteration 59/1000 | Loss: 0.00001987
Iteration 60/1000 | Loss: 0.00001987
Iteration 61/1000 | Loss: 0.00001986
Iteration 62/1000 | Loss: 0.00001986
Iteration 63/1000 | Loss: 0.00001985
Iteration 64/1000 | Loss: 0.00001985
Iteration 65/1000 | Loss: 0.00001985
Iteration 66/1000 | Loss: 0.00001984
Iteration 67/1000 | Loss: 0.00001984
Iteration 68/1000 | Loss: 0.00001984
Iteration 69/1000 | Loss: 0.00001984
Iteration 70/1000 | Loss: 0.00001984
Iteration 71/1000 | Loss: 0.00001984
Iteration 72/1000 | Loss: 0.00001984
Iteration 73/1000 | Loss: 0.00001984
Iteration 74/1000 | Loss: 0.00001983
Iteration 75/1000 | Loss: 0.00001983
Iteration 76/1000 | Loss: 0.00001983
Iteration 77/1000 | Loss: 0.00001983
Iteration 78/1000 | Loss: 0.00001982
Iteration 79/1000 | Loss: 0.00001982
Iteration 80/1000 | Loss: 0.00001982
Iteration 81/1000 | Loss: 0.00001982
Iteration 82/1000 | Loss: 0.00001982
Iteration 83/1000 | Loss: 0.00001982
Iteration 84/1000 | Loss: 0.00001981
Iteration 85/1000 | Loss: 0.00001981
Iteration 86/1000 | Loss: 0.00001981
Iteration 87/1000 | Loss: 0.00001981
Iteration 88/1000 | Loss: 0.00001981
Iteration 89/1000 | Loss: 0.00001981
Iteration 90/1000 | Loss: 0.00001981
Iteration 91/1000 | Loss: 0.00001981
Iteration 92/1000 | Loss: 0.00001981
Iteration 93/1000 | Loss: 0.00001980
Iteration 94/1000 | Loss: 0.00001980
Iteration 95/1000 | Loss: 0.00001980
Iteration 96/1000 | Loss: 0.00001979
Iteration 97/1000 | Loss: 0.00001979
Iteration 98/1000 | Loss: 0.00001979
Iteration 99/1000 | Loss: 0.00001979
Iteration 100/1000 | Loss: 0.00001979
Iteration 101/1000 | Loss: 0.00001979
Iteration 102/1000 | Loss: 0.00001979
Iteration 103/1000 | Loss: 0.00001979
Iteration 104/1000 | Loss: 0.00001979
Iteration 105/1000 | Loss: 0.00001978
Iteration 106/1000 | Loss: 0.00001978
Iteration 107/1000 | Loss: 0.00001978
Iteration 108/1000 | Loss: 0.00001978
Iteration 109/1000 | Loss: 0.00001978
Iteration 110/1000 | Loss: 0.00001978
Iteration 111/1000 | Loss: 0.00001978
Iteration 112/1000 | Loss: 0.00001978
Iteration 113/1000 | Loss: 0.00001978
Iteration 114/1000 | Loss: 0.00001978
Iteration 115/1000 | Loss: 0.00001977
Iteration 116/1000 | Loss: 0.00001977
Iteration 117/1000 | Loss: 0.00001977
Iteration 118/1000 | Loss: 0.00001977
Iteration 119/1000 | Loss: 0.00001977
Iteration 120/1000 | Loss: 0.00001977
Iteration 121/1000 | Loss: 0.00001977
Iteration 122/1000 | Loss: 0.00001977
Iteration 123/1000 | Loss: 0.00001977
Iteration 124/1000 | Loss: 0.00001976
Iteration 125/1000 | Loss: 0.00001976
Iteration 126/1000 | Loss: 0.00001976
Iteration 127/1000 | Loss: 0.00001976
Iteration 128/1000 | Loss: 0.00001975
Iteration 129/1000 | Loss: 0.00001975
Iteration 130/1000 | Loss: 0.00001975
Iteration 131/1000 | Loss: 0.00001975
Iteration 132/1000 | Loss: 0.00001974
Iteration 133/1000 | Loss: 0.00001974
Iteration 134/1000 | Loss: 0.00001974
Iteration 135/1000 | Loss: 0.00001974
Iteration 136/1000 | Loss: 0.00001974
Iteration 137/1000 | Loss: 0.00001974
Iteration 138/1000 | Loss: 0.00001974
Iteration 139/1000 | Loss: 0.00001973
Iteration 140/1000 | Loss: 0.00001973
Iteration 141/1000 | Loss: 0.00001973
Iteration 142/1000 | Loss: 0.00001973
Iteration 143/1000 | Loss: 0.00001972
Iteration 144/1000 | Loss: 0.00001972
Iteration 145/1000 | Loss: 0.00001972
Iteration 146/1000 | Loss: 0.00001972
Iteration 147/1000 | Loss: 0.00001972
Iteration 148/1000 | Loss: 0.00001972
Iteration 149/1000 | Loss: 0.00001972
Iteration 150/1000 | Loss: 0.00001972
Iteration 151/1000 | Loss: 0.00001971
Iteration 152/1000 | Loss: 0.00001971
Iteration 153/1000 | Loss: 0.00001971
Iteration 154/1000 | Loss: 0.00001971
Iteration 155/1000 | Loss: 0.00001971
Iteration 156/1000 | Loss: 0.00001971
Iteration 157/1000 | Loss: 0.00001971
Iteration 158/1000 | Loss: 0.00001971
Iteration 159/1000 | Loss: 0.00001970
Iteration 160/1000 | Loss: 0.00001970
Iteration 161/1000 | Loss: 0.00001970
Iteration 162/1000 | Loss: 0.00001970
Iteration 163/1000 | Loss: 0.00001970
Iteration 164/1000 | Loss: 0.00001970
Iteration 165/1000 | Loss: 0.00001970
Iteration 166/1000 | Loss: 0.00001969
Iteration 167/1000 | Loss: 0.00001969
Iteration 168/1000 | Loss: 0.00001969
Iteration 169/1000 | Loss: 0.00001969
Iteration 170/1000 | Loss: 0.00001969
Iteration 171/1000 | Loss: 0.00001969
Iteration 172/1000 | Loss: 0.00001969
Iteration 173/1000 | Loss: 0.00001969
Iteration 174/1000 | Loss: 0.00001969
Iteration 175/1000 | Loss: 0.00001969
Iteration 176/1000 | Loss: 0.00001969
Iteration 177/1000 | Loss: 0.00001969
Iteration 178/1000 | Loss: 0.00001969
Iteration 179/1000 | Loss: 0.00001969
Iteration 180/1000 | Loss: 0.00001968
Iteration 181/1000 | Loss: 0.00001968
Iteration 182/1000 | Loss: 0.00001968
Iteration 183/1000 | Loss: 0.00001968
Iteration 184/1000 | Loss: 0.00001968
Iteration 185/1000 | Loss: 0.00001968
Iteration 186/1000 | Loss: 0.00001968
Iteration 187/1000 | Loss: 0.00001968
Iteration 188/1000 | Loss: 0.00001968
Iteration 189/1000 | Loss: 0.00001968
Iteration 190/1000 | Loss: 0.00001968
Iteration 191/1000 | Loss: 0.00001968
Iteration 192/1000 | Loss: 0.00001967
Iteration 193/1000 | Loss: 0.00001967
Iteration 194/1000 | Loss: 0.00001967
Iteration 195/1000 | Loss: 0.00001967
Iteration 196/1000 | Loss: 0.00001967
Iteration 197/1000 | Loss: 0.00001967
Iteration 198/1000 | Loss: 0.00001967
Iteration 199/1000 | Loss: 0.00001967
Iteration 200/1000 | Loss: 0.00001967
Iteration 201/1000 | Loss: 0.00001967
Iteration 202/1000 | Loss: 0.00001967
Iteration 203/1000 | Loss: 0.00001967
Iteration 204/1000 | Loss: 0.00001967
Iteration 205/1000 | Loss: 0.00001967
Iteration 206/1000 | Loss: 0.00001966
Iteration 207/1000 | Loss: 0.00001966
Iteration 208/1000 | Loss: 0.00001966
Iteration 209/1000 | Loss: 0.00001966
Iteration 210/1000 | Loss: 0.00001966
Iteration 211/1000 | Loss: 0.00001966
Iteration 212/1000 | Loss: 0.00001966
Iteration 213/1000 | Loss: 0.00001966
Iteration 214/1000 | Loss: 0.00001966
Iteration 215/1000 | Loss: 0.00001966
Iteration 216/1000 | Loss: 0.00001966
Iteration 217/1000 | Loss: 0.00001966
Iteration 218/1000 | Loss: 0.00001966
Iteration 219/1000 | Loss: 0.00001966
Iteration 220/1000 | Loss: 0.00001966
Iteration 221/1000 | Loss: 0.00001966
Iteration 222/1000 | Loss: 0.00001966
Iteration 223/1000 | Loss: 0.00001965
Iteration 224/1000 | Loss: 0.00001965
Iteration 225/1000 | Loss: 0.00001965
Iteration 226/1000 | Loss: 0.00001965
Iteration 227/1000 | Loss: 0.00001965
Iteration 228/1000 | Loss: 0.00001965
Iteration 229/1000 | Loss: 0.00001965
Iteration 230/1000 | Loss: 0.00001965
Iteration 231/1000 | Loss: 0.00001965
Iteration 232/1000 | Loss: 0.00001965
Iteration 233/1000 | Loss: 0.00001965
Iteration 234/1000 | Loss: 0.00001965
Iteration 235/1000 | Loss: 0.00001965
Iteration 236/1000 | Loss: 0.00001965
Iteration 237/1000 | Loss: 0.00001965
Iteration 238/1000 | Loss: 0.00001965
Iteration 239/1000 | Loss: 0.00001965
Iteration 240/1000 | Loss: 0.00001965
Iteration 241/1000 | Loss: 0.00001965
Iteration 242/1000 | Loss: 0.00001965
Iteration 243/1000 | Loss: 0.00001965
Iteration 244/1000 | Loss: 0.00001965
Iteration 245/1000 | Loss: 0.00001965
Iteration 246/1000 | Loss: 0.00001965
Iteration 247/1000 | Loss: 0.00001965
Iteration 248/1000 | Loss: 0.00001965
Iteration 249/1000 | Loss: 0.00001965
Iteration 250/1000 | Loss: 0.00001965
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 250. Stopping optimization.
Last 5 losses: [1.9649367459351197e-05, 1.9649367459351197e-05, 1.9649367459351197e-05, 1.9649367459351197e-05, 1.9649367459351197e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9649367459351197e-05

Optimization complete. Final v2v error: 3.640944004058838 mm

Highest mean error: 4.780826091766357 mm for frame 92

Lowest mean error: 2.9390835762023926 mm for frame 7

Saving results

Total time: 46.4868950843811
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_002/1034/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1034.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_002/1034
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00869535
Iteration 2/25 | Loss: 0.00223869
Iteration 3/25 | Loss: 0.00127805
Iteration 4/25 | Loss: 0.00113024
Iteration 5/25 | Loss: 0.00108836
Iteration 6/25 | Loss: 0.00107445
Iteration 7/25 | Loss: 0.00099064
Iteration 8/25 | Loss: 0.00095985
Iteration 9/25 | Loss: 0.00095666
Iteration 10/25 | Loss: 0.00093998
Iteration 11/25 | Loss: 0.00093190
Iteration 12/25 | Loss: 0.00092281
Iteration 13/25 | Loss: 0.00092228
Iteration 14/25 | Loss: 0.00091949
Iteration 15/25 | Loss: 0.00091740
Iteration 16/25 | Loss: 0.00091673
Iteration 17/25 | Loss: 0.00091622
Iteration 18/25 | Loss: 0.00091549
Iteration 19/25 | Loss: 0.00091318
Iteration 20/25 | Loss: 0.00091670
Iteration 21/25 | Loss: 0.00091789
Iteration 22/25 | Loss: 0.00091265
Iteration 23/25 | Loss: 0.00091441
Iteration 24/25 | Loss: 0.00091189
Iteration 25/25 | Loss: 0.00091297

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.63675761
Iteration 2/25 | Loss: 0.00168944
Iteration 3/25 | Loss: 0.00168939
Iteration 4/25 | Loss: 0.00168939
Iteration 5/25 | Loss: 0.00168939
Iteration 6/25 | Loss: 0.00168939
Iteration 7/25 | Loss: 0.00168939
Iteration 8/25 | Loss: 0.00168939
Iteration 9/25 | Loss: 0.00168939
Iteration 10/25 | Loss: 0.00168939
Iteration 11/25 | Loss: 0.00168939
Iteration 12/25 | Loss: 0.00168939
Iteration 13/25 | Loss: 0.00168939
Iteration 14/25 | Loss: 0.00168939
Iteration 15/25 | Loss: 0.00168939
Iteration 16/25 | Loss: 0.00168939
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0016893905121833086, 0.0016893905121833086, 0.0016893905121833086, 0.0016893905121833086, 0.0016893905121833086]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016893905121833086

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00168939
Iteration 2/1000 | Loss: 0.00014065
Iteration 3/1000 | Loss: 0.00011083
Iteration 4/1000 | Loss: 0.00012340
Iteration 5/1000 | Loss: 0.00008042
Iteration 6/1000 | Loss: 0.00017130
Iteration 7/1000 | Loss: 0.00012729
Iteration 8/1000 | Loss: 0.00013748
Iteration 9/1000 | Loss: 0.00010653
Iteration 10/1000 | Loss: 0.00016343
Iteration 11/1000 | Loss: 0.00013710
Iteration 12/1000 | Loss: 0.00007837
Iteration 13/1000 | Loss: 0.00010380
Iteration 14/1000 | Loss: 0.00011148
Iteration 15/1000 | Loss: 0.00012434
Iteration 16/1000 | Loss: 0.00017321
Iteration 17/1000 | Loss: 0.00017251
Iteration 18/1000 | Loss: 0.00012857
Iteration 19/1000 | Loss: 0.00009558
Iteration 20/1000 | Loss: 0.00019940
Iteration 21/1000 | Loss: 0.00012973
Iteration 22/1000 | Loss: 0.00011406
Iteration 23/1000 | Loss: 0.00012686
Iteration 24/1000 | Loss: 0.00013565
Iteration 25/1000 | Loss: 0.00012212
Iteration 26/1000 | Loss: 0.00014603
Iteration 27/1000 | Loss: 0.00014851
Iteration 28/1000 | Loss: 0.00014718
Iteration 29/1000 | Loss: 0.00014950
Iteration 30/1000 | Loss: 0.00014051
Iteration 31/1000 | Loss: 0.00019817
Iteration 32/1000 | Loss: 0.00015394
Iteration 33/1000 | Loss: 0.00014801
Iteration 34/1000 | Loss: 0.00009962
Iteration 35/1000 | Loss: 0.00015238
Iteration 36/1000 | Loss: 0.00015332
Iteration 37/1000 | Loss: 0.00012793
Iteration 38/1000 | Loss: 0.00010737
Iteration 39/1000 | Loss: 0.00010523
Iteration 40/1000 | Loss: 0.00011643
Iteration 41/1000 | Loss: 0.00012075
Iteration 42/1000 | Loss: 0.00013152
Iteration 43/1000 | Loss: 0.00015671
Iteration 44/1000 | Loss: 0.00022371
Iteration 45/1000 | Loss: 0.00012112
Iteration 46/1000 | Loss: 0.00018265
Iteration 47/1000 | Loss: 0.00010971
Iteration 48/1000 | Loss: 0.00013715
Iteration 49/1000 | Loss: 0.00014485
Iteration 50/1000 | Loss: 0.00008676
Iteration 51/1000 | Loss: 0.00011701
Iteration 52/1000 | Loss: 0.00017700
Iteration 53/1000 | Loss: 0.00016052
Iteration 54/1000 | Loss: 0.00014836
Iteration 55/1000 | Loss: 0.00012540
Iteration 56/1000 | Loss: 0.00013082
Iteration 57/1000 | Loss: 0.00013800
Iteration 58/1000 | Loss: 0.00011607
Iteration 59/1000 | Loss: 0.00010103
Iteration 60/1000 | Loss: 0.00016786
Iteration 61/1000 | Loss: 0.00013539
Iteration 62/1000 | Loss: 0.00011410
Iteration 63/1000 | Loss: 0.00013960
Iteration 64/1000 | Loss: 0.00012653
Iteration 65/1000 | Loss: 0.00017730
Iteration 66/1000 | Loss: 0.00012964
Iteration 67/1000 | Loss: 0.00012900
Iteration 68/1000 | Loss: 0.00013616
Iteration 69/1000 | Loss: 0.00012041
Iteration 70/1000 | Loss: 0.00012709
Iteration 71/1000 | Loss: 0.00011977
Iteration 72/1000 | Loss: 0.00020600
Iteration 73/1000 | Loss: 0.00013670
Iteration 74/1000 | Loss: 0.00016375
Iteration 75/1000 | Loss: 0.00015640
Iteration 76/1000 | Loss: 0.00016799
Iteration 77/1000 | Loss: 0.00013676
Iteration 78/1000 | Loss: 0.00010764
Iteration 79/1000 | Loss: 0.00014493
Iteration 80/1000 | Loss: 0.00012192
Iteration 81/1000 | Loss: 0.00010548
Iteration 82/1000 | Loss: 0.00009067
Iteration 83/1000 | Loss: 0.00014681
Iteration 84/1000 | Loss: 0.00015579
Iteration 85/1000 | Loss: 0.00015064
Iteration 86/1000 | Loss: 0.00014648
Iteration 87/1000 | Loss: 0.00014573
Iteration 88/1000 | Loss: 0.00009380
Iteration 89/1000 | Loss: 0.00008702
Iteration 90/1000 | Loss: 0.00008673
Iteration 91/1000 | Loss: 0.00014753
Iteration 92/1000 | Loss: 0.00015402
Iteration 93/1000 | Loss: 0.00011616
Iteration 94/1000 | Loss: 0.00011086
Iteration 95/1000 | Loss: 0.00013573
Iteration 96/1000 | Loss: 0.00012976
Iteration 97/1000 | Loss: 0.00015633
Iteration 98/1000 | Loss: 0.00013822
Iteration 99/1000 | Loss: 0.00014240
Iteration 100/1000 | Loss: 0.00010889
Iteration 101/1000 | Loss: 0.00011149
Iteration 102/1000 | Loss: 0.00011907
Iteration 103/1000 | Loss: 0.00010616
Iteration 104/1000 | Loss: 0.00009472
Iteration 105/1000 | Loss: 0.00010947
Iteration 106/1000 | Loss: 0.00010474
Iteration 107/1000 | Loss: 0.00010110
Iteration 108/1000 | Loss: 0.00015898
Iteration 109/1000 | Loss: 0.00017245
Iteration 110/1000 | Loss: 0.00014376
Iteration 111/1000 | Loss: 0.00017167
Iteration 112/1000 | Loss: 0.00015473
Iteration 113/1000 | Loss: 0.00017294
Iteration 114/1000 | Loss: 0.00017438
Iteration 115/1000 | Loss: 0.00015545
Iteration 116/1000 | Loss: 0.00011990
Iteration 117/1000 | Loss: 0.00012158
Iteration 118/1000 | Loss: 0.00009609
Iteration 119/1000 | Loss: 0.00008319
Iteration 120/1000 | Loss: 0.00010735
Iteration 121/1000 | Loss: 0.00010408
Iteration 122/1000 | Loss: 0.00012893
Iteration 123/1000 | Loss: 0.00013514
Iteration 124/1000 | Loss: 0.00010700
Iteration 125/1000 | Loss: 0.00010845
Iteration 126/1000 | Loss: 0.00011592
Iteration 127/1000 | Loss: 0.00012530
Iteration 128/1000 | Loss: 0.00012633
Iteration 129/1000 | Loss: 0.00011304
Iteration 130/1000 | Loss: 0.00013754
Iteration 131/1000 | Loss: 0.00010950
Iteration 132/1000 | Loss: 0.00012583
Iteration 133/1000 | Loss: 0.00007573
Iteration 134/1000 | Loss: 0.00007043
Iteration 135/1000 | Loss: 0.00005665
Iteration 136/1000 | Loss: 0.00008907
Iteration 137/1000 | Loss: 0.00005218
Iteration 138/1000 | Loss: 0.00008488
Iteration 139/1000 | Loss: 0.00011181
Iteration 140/1000 | Loss: 0.00007394
Iteration 141/1000 | Loss: 0.00007606
Iteration 142/1000 | Loss: 0.00005548
Iteration 143/1000 | Loss: 0.00009232
Iteration 144/1000 | Loss: 0.00009777
Iteration 145/1000 | Loss: 0.00011602
Iteration 146/1000 | Loss: 0.00008949
Iteration 147/1000 | Loss: 0.00007790
Iteration 148/1000 | Loss: 0.00006895
Iteration 149/1000 | Loss: 0.00010034
Iteration 150/1000 | Loss: 0.00007099
Iteration 151/1000 | Loss: 0.00010435
Iteration 152/1000 | Loss: 0.00012796
Iteration 153/1000 | Loss: 0.00009529
Iteration 154/1000 | Loss: 0.00013667
Iteration 155/1000 | Loss: 0.00008962
Iteration 156/1000 | Loss: 0.00006269
Iteration 157/1000 | Loss: 0.00006455
Iteration 158/1000 | Loss: 0.00006806
Iteration 159/1000 | Loss: 0.00007600
Iteration 160/1000 | Loss: 0.00007586
Iteration 161/1000 | Loss: 0.00003806
Iteration 162/1000 | Loss: 0.00006457
Iteration 163/1000 | Loss: 0.00008379
Iteration 164/1000 | Loss: 0.00007507
Iteration 165/1000 | Loss: 0.00007029
Iteration 166/1000 | Loss: 0.00006647
Iteration 167/1000 | Loss: 0.00008069
Iteration 168/1000 | Loss: 0.00006937
Iteration 169/1000 | Loss: 0.00007842
Iteration 170/1000 | Loss: 0.00006802
Iteration 171/1000 | Loss: 0.00006572
Iteration 172/1000 | Loss: 0.00006288
Iteration 173/1000 | Loss: 0.00005187
Iteration 174/1000 | Loss: 0.00007604
Iteration 175/1000 | Loss: 0.00007720
Iteration 176/1000 | Loss: 0.00006334
Iteration 177/1000 | Loss: 0.00006447
Iteration 178/1000 | Loss: 0.00006614
Iteration 179/1000 | Loss: 0.00005558
Iteration 180/1000 | Loss: 0.00004938
Iteration 181/1000 | Loss: 0.00005109
Iteration 182/1000 | Loss: 0.00004774
Iteration 183/1000 | Loss: 0.00007594
Iteration 184/1000 | Loss: 0.00005410
Iteration 185/1000 | Loss: 0.00005272
Iteration 186/1000 | Loss: 0.00006664
Iteration 187/1000 | Loss: 0.00005834
Iteration 188/1000 | Loss: 0.00006106
Iteration 189/1000 | Loss: 0.00005365
Iteration 190/1000 | Loss: 0.00006368
Iteration 191/1000 | Loss: 0.00007651
Iteration 192/1000 | Loss: 0.00005656
Iteration 193/1000 | Loss: 0.00007587
Iteration 194/1000 | Loss: 0.00007180
Iteration 195/1000 | Loss: 0.00003139
Iteration 196/1000 | Loss: 0.00003541
Iteration 197/1000 | Loss: 0.00002440
Iteration 198/1000 | Loss: 0.00004221
Iteration 199/1000 | Loss: 0.00003455
Iteration 200/1000 | Loss: 0.00003266
Iteration 201/1000 | Loss: 0.00003216
Iteration 202/1000 | Loss: 0.00003275
Iteration 203/1000 | Loss: 0.00003360
Iteration 204/1000 | Loss: 0.00002735
Iteration 205/1000 | Loss: 0.00002140
Iteration 206/1000 | Loss: 0.00002791
Iteration 207/1000 | Loss: 0.00002701
Iteration 208/1000 | Loss: 0.00002929
Iteration 209/1000 | Loss: 0.00003495
Iteration 210/1000 | Loss: 0.00003342
Iteration 211/1000 | Loss: 0.00003262
Iteration 212/1000 | Loss: 0.00003237
Iteration 213/1000 | Loss: 0.00003232
Iteration 214/1000 | Loss: 0.00003347
Iteration 215/1000 | Loss: 0.00003429
Iteration 216/1000 | Loss: 0.00002699
Iteration 217/1000 | Loss: 0.00003348
Iteration 218/1000 | Loss: 0.00002957
Iteration 219/1000 | Loss: 0.00003000
Iteration 220/1000 | Loss: 0.00003456
Iteration 221/1000 | Loss: 0.00002861
Iteration 222/1000 | Loss: 0.00003294
Iteration 223/1000 | Loss: 0.00002642
Iteration 224/1000 | Loss: 0.00002599
Iteration 225/1000 | Loss: 0.00003043
Iteration 226/1000 | Loss: 0.00003506
Iteration 227/1000 | Loss: 0.00002741
Iteration 228/1000 | Loss: 0.00003433
Iteration 229/1000 | Loss: 0.00003009
Iteration 230/1000 | Loss: 0.00002449
Iteration 231/1000 | Loss: 0.00002228
Iteration 232/1000 | Loss: 0.00002071
Iteration 233/1000 | Loss: 0.00002006
Iteration 234/1000 | Loss: 0.00001946
Iteration 235/1000 | Loss: 0.00001918
Iteration 236/1000 | Loss: 0.00001914
Iteration 237/1000 | Loss: 0.00001911
Iteration 238/1000 | Loss: 0.00001909
Iteration 239/1000 | Loss: 0.00001908
Iteration 240/1000 | Loss: 0.00001904
Iteration 241/1000 | Loss: 0.00001898
Iteration 242/1000 | Loss: 0.00001892
Iteration 243/1000 | Loss: 0.00001892
Iteration 244/1000 | Loss: 0.00001881
Iteration 245/1000 | Loss: 0.00001880
Iteration 246/1000 | Loss: 0.00001878
Iteration 247/1000 | Loss: 0.00001873
Iteration 248/1000 | Loss: 0.00001873
Iteration 249/1000 | Loss: 0.00001872
Iteration 250/1000 | Loss: 0.00001872
Iteration 251/1000 | Loss: 0.00001871
Iteration 252/1000 | Loss: 0.00001871
Iteration 253/1000 | Loss: 0.00001871
Iteration 254/1000 | Loss: 0.00001871
Iteration 255/1000 | Loss: 0.00001871
Iteration 256/1000 | Loss: 0.00001870
Iteration 257/1000 | Loss: 0.00001870
Iteration 258/1000 | Loss: 0.00001870
Iteration 259/1000 | Loss: 0.00001870
Iteration 260/1000 | Loss: 0.00001870
Iteration 261/1000 | Loss: 0.00001870
Iteration 262/1000 | Loss: 0.00001869
Iteration 263/1000 | Loss: 0.00001869
Iteration 264/1000 | Loss: 0.00001869
Iteration 265/1000 | Loss: 0.00001869
Iteration 266/1000 | Loss: 0.00001868
Iteration 267/1000 | Loss: 0.00001868
Iteration 268/1000 | Loss: 0.00001868
Iteration 269/1000 | Loss: 0.00001868
Iteration 270/1000 | Loss: 0.00001867
Iteration 271/1000 | Loss: 0.00001866
Iteration 272/1000 | Loss: 0.00001866
Iteration 273/1000 | Loss: 0.00001866
Iteration 274/1000 | Loss: 0.00001865
Iteration 275/1000 | Loss: 0.00001865
Iteration 276/1000 | Loss: 0.00001865
Iteration 277/1000 | Loss: 0.00001865
Iteration 278/1000 | Loss: 0.00001865
Iteration 279/1000 | Loss: 0.00001865
Iteration 280/1000 | Loss: 0.00001865
Iteration 281/1000 | Loss: 0.00001864
Iteration 282/1000 | Loss: 0.00001864
Iteration 283/1000 | Loss: 0.00001864
Iteration 284/1000 | Loss: 0.00001864
Iteration 285/1000 | Loss: 0.00001864
Iteration 286/1000 | Loss: 0.00001864
Iteration 287/1000 | Loss: 0.00001864
Iteration 288/1000 | Loss: 0.00001864
Iteration 289/1000 | Loss: 0.00001864
Iteration 290/1000 | Loss: 0.00001864
Iteration 291/1000 | Loss: 0.00001863
Iteration 292/1000 | Loss: 0.00001863
Iteration 293/1000 | Loss: 0.00001863
Iteration 294/1000 | Loss: 0.00001863
Iteration 295/1000 | Loss: 0.00001863
Iteration 296/1000 | Loss: 0.00001863
Iteration 297/1000 | Loss: 0.00001863
Iteration 298/1000 | Loss: 0.00001863
Iteration 299/1000 | Loss: 0.00001863
Iteration 300/1000 | Loss: 0.00001863
Iteration 301/1000 | Loss: 0.00001863
Iteration 302/1000 | Loss: 0.00001863
Iteration 303/1000 | Loss: 0.00001863
Iteration 304/1000 | Loss: 0.00001863
Iteration 305/1000 | Loss: 0.00001863
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 305. Stopping optimization.
Last 5 losses: [1.8630233171279542e-05, 1.8630233171279542e-05, 1.8630233171279542e-05, 1.8630233171279542e-05, 1.8630233171279542e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8630233171279542e-05

Optimization complete. Final v2v error: 3.6244075298309326 mm

Highest mean error: 4.513150215148926 mm for frame 195

Lowest mean error: 3.1593899726867676 mm for frame 100

Saving results

Total time: 438.29433274269104

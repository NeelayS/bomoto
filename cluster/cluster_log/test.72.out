Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=72, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 4032-4087
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1064/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1064.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1064
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00973825
Iteration 2/25 | Loss: 0.00973825
Iteration 3/25 | Loss: 0.00264789
Iteration 4/25 | Loss: 0.00186299
Iteration 5/25 | Loss: 0.00163197
Iteration 6/25 | Loss: 0.00135533
Iteration 7/25 | Loss: 0.00116168
Iteration 8/25 | Loss: 0.00106796
Iteration 9/25 | Loss: 0.00102169
Iteration 10/25 | Loss: 0.00097965
Iteration 11/25 | Loss: 0.00097428
Iteration 12/25 | Loss: 0.00095541
Iteration 13/25 | Loss: 0.00095250
Iteration 14/25 | Loss: 0.00094310
Iteration 15/25 | Loss: 0.00093823
Iteration 16/25 | Loss: 0.00093121
Iteration 17/25 | Loss: 0.00092387
Iteration 18/25 | Loss: 0.00091855
Iteration 19/25 | Loss: 0.00091183
Iteration 20/25 | Loss: 0.00091066
Iteration 21/25 | Loss: 0.00090957
Iteration 22/25 | Loss: 0.00091281
Iteration 23/25 | Loss: 0.00091035
Iteration 24/25 | Loss: 0.00091093
Iteration 25/25 | Loss: 0.00090921

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51296914
Iteration 2/25 | Loss: 0.00359075
Iteration 3/25 | Loss: 0.00167623
Iteration 4/25 | Loss: 0.00167615
Iteration 5/25 | Loss: 0.00167615
Iteration 6/25 | Loss: 0.00167615
Iteration 7/25 | Loss: 0.00167615
Iteration 8/25 | Loss: 0.00167615
Iteration 9/25 | Loss: 0.00167615
Iteration 10/25 | Loss: 0.00167615
Iteration 11/25 | Loss: 0.00167615
Iteration 12/25 | Loss: 0.00167615
Iteration 13/25 | Loss: 0.00167615
Iteration 14/25 | Loss: 0.00167615
Iteration 15/25 | Loss: 0.00167615
Iteration 16/25 | Loss: 0.00167615
Iteration 17/25 | Loss: 0.00167615
Iteration 18/25 | Loss: 0.00167615
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.001676149433478713, 0.001676149433478713, 0.001676149433478713, 0.001676149433478713, 0.001676149433478713]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001676149433478713

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00167615
Iteration 2/1000 | Loss: 0.00189169
Iteration 3/1000 | Loss: 0.00057842
Iteration 4/1000 | Loss: 0.00067731
Iteration 5/1000 | Loss: 0.00062793
Iteration 6/1000 | Loss: 0.00105011
Iteration 7/1000 | Loss: 0.00019781
Iteration 8/1000 | Loss: 0.00063845
Iteration 9/1000 | Loss: 0.00055908
Iteration 10/1000 | Loss: 0.00010859
Iteration 11/1000 | Loss: 0.00007540
Iteration 12/1000 | Loss: 0.00051345
Iteration 13/1000 | Loss: 0.00253380
Iteration 14/1000 | Loss: 0.00056269
Iteration 15/1000 | Loss: 0.00173130
Iteration 16/1000 | Loss: 0.00011635
Iteration 17/1000 | Loss: 0.00025896
Iteration 18/1000 | Loss: 0.00016478
Iteration 19/1000 | Loss: 0.00007412
Iteration 20/1000 | Loss: 0.00006106
Iteration 21/1000 | Loss: 0.00071388
Iteration 22/1000 | Loss: 0.00022374
Iteration 23/1000 | Loss: 0.00126794
Iteration 24/1000 | Loss: 0.00014922
Iteration 25/1000 | Loss: 0.00020567
Iteration 26/1000 | Loss: 0.00025934
Iteration 27/1000 | Loss: 0.00034158
Iteration 28/1000 | Loss: 0.00161107
Iteration 29/1000 | Loss: 0.00044901
Iteration 30/1000 | Loss: 0.00109535
Iteration 31/1000 | Loss: 0.00109524
Iteration 32/1000 | Loss: 0.00026055
Iteration 33/1000 | Loss: 0.00035860
Iteration 34/1000 | Loss: 0.00025225
Iteration 35/1000 | Loss: 0.00019766
Iteration 36/1000 | Loss: 0.00017587
Iteration 37/1000 | Loss: 0.00012695
Iteration 38/1000 | Loss: 0.00006086
Iteration 39/1000 | Loss: 0.00005041
Iteration 40/1000 | Loss: 0.00005861
Iteration 41/1000 | Loss: 0.00015385
Iteration 42/1000 | Loss: 0.00004545
Iteration 43/1000 | Loss: 0.00037108
Iteration 44/1000 | Loss: 0.00028089
Iteration 45/1000 | Loss: 0.00028143
Iteration 46/1000 | Loss: 0.00160987
Iteration 47/1000 | Loss: 0.00023730
Iteration 48/1000 | Loss: 0.00169977
Iteration 49/1000 | Loss: 0.00151470
Iteration 50/1000 | Loss: 0.00008520
Iteration 51/1000 | Loss: 0.00041088
Iteration 52/1000 | Loss: 0.00033957
Iteration 53/1000 | Loss: 0.00005189
Iteration 54/1000 | Loss: 0.00024495
Iteration 55/1000 | Loss: 0.00009120
Iteration 56/1000 | Loss: 0.00029501
Iteration 57/1000 | Loss: 0.00035721
Iteration 58/1000 | Loss: 0.00016938
Iteration 59/1000 | Loss: 0.00019054
Iteration 60/1000 | Loss: 0.00150952
Iteration 61/1000 | Loss: 0.00010155
Iteration 62/1000 | Loss: 0.00030581
Iteration 63/1000 | Loss: 0.00007715
Iteration 64/1000 | Loss: 0.00044312
Iteration 65/1000 | Loss: 0.00013929
Iteration 66/1000 | Loss: 0.00049196
Iteration 67/1000 | Loss: 0.00055175
Iteration 68/1000 | Loss: 0.00034932
Iteration 69/1000 | Loss: 0.00018472
Iteration 70/1000 | Loss: 0.00018116
Iteration 71/1000 | Loss: 0.00049069
Iteration 72/1000 | Loss: 0.00009418
Iteration 73/1000 | Loss: 0.00014619
Iteration 74/1000 | Loss: 0.00057810
Iteration 75/1000 | Loss: 0.00012862
Iteration 76/1000 | Loss: 0.00013568
Iteration 77/1000 | Loss: 0.00018096
Iteration 78/1000 | Loss: 0.00050294
Iteration 79/1000 | Loss: 0.00035011
Iteration 80/1000 | Loss: 0.00073473
Iteration 81/1000 | Loss: 0.00039599
Iteration 82/1000 | Loss: 0.00027380
Iteration 83/1000 | Loss: 0.00011051
Iteration 84/1000 | Loss: 0.00005657
Iteration 85/1000 | Loss: 0.00011886
Iteration 86/1000 | Loss: 0.00019290
Iteration 87/1000 | Loss: 0.00018810
Iteration 88/1000 | Loss: 0.00027008
Iteration 89/1000 | Loss: 0.00025963
Iteration 90/1000 | Loss: 0.00017100
Iteration 91/1000 | Loss: 0.00005960
Iteration 92/1000 | Loss: 0.00005885
Iteration 93/1000 | Loss: 0.00009965
Iteration 94/1000 | Loss: 0.00003702
Iteration 95/1000 | Loss: 0.00015770
Iteration 96/1000 | Loss: 0.00014496
Iteration 97/1000 | Loss: 0.00012848
Iteration 98/1000 | Loss: 0.00011227
Iteration 99/1000 | Loss: 0.00013177
Iteration 100/1000 | Loss: 0.00062915
Iteration 101/1000 | Loss: 0.00069655
Iteration 102/1000 | Loss: 0.00021832
Iteration 103/1000 | Loss: 0.00002685
Iteration 104/1000 | Loss: 0.00009936
Iteration 105/1000 | Loss: 0.00010591
Iteration 106/1000 | Loss: 0.00026791
Iteration 107/1000 | Loss: 0.00003608
Iteration 108/1000 | Loss: 0.00010175
Iteration 109/1000 | Loss: 0.00009862
Iteration 110/1000 | Loss: 0.00002650
Iteration 111/1000 | Loss: 0.00005189
Iteration 112/1000 | Loss: 0.00012789
Iteration 113/1000 | Loss: 0.00006935
Iteration 114/1000 | Loss: 0.00015956
Iteration 115/1000 | Loss: 0.00006677
Iteration 116/1000 | Loss: 0.00004372
Iteration 117/1000 | Loss: 0.00027085
Iteration 118/1000 | Loss: 0.00009513
Iteration 119/1000 | Loss: 0.00004987
Iteration 120/1000 | Loss: 0.00009431
Iteration 121/1000 | Loss: 0.00011222
Iteration 122/1000 | Loss: 0.00006581
Iteration 123/1000 | Loss: 0.00004560
Iteration 124/1000 | Loss: 0.00012444
Iteration 125/1000 | Loss: 0.00008298
Iteration 126/1000 | Loss: 0.00005476
Iteration 127/1000 | Loss: 0.00011126
Iteration 128/1000 | Loss: 0.00011142
Iteration 129/1000 | Loss: 0.00005588
Iteration 130/1000 | Loss: 0.00004912
Iteration 131/1000 | Loss: 0.00008117
Iteration 132/1000 | Loss: 0.00016205
Iteration 133/1000 | Loss: 0.00014096
Iteration 134/1000 | Loss: 0.00023530
Iteration 135/1000 | Loss: 0.00032262
Iteration 136/1000 | Loss: 0.00058883
Iteration 137/1000 | Loss: 0.00004566
Iteration 138/1000 | Loss: 0.00008823
Iteration 139/1000 | Loss: 0.00004435
Iteration 140/1000 | Loss: 0.00005291
Iteration 141/1000 | Loss: 0.00006000
Iteration 142/1000 | Loss: 0.00005500
Iteration 143/1000 | Loss: 0.00004587
Iteration 144/1000 | Loss: 0.00004713
Iteration 145/1000 | Loss: 0.00005890
Iteration 146/1000 | Loss: 0.00004758
Iteration 147/1000 | Loss: 0.00004728
Iteration 148/1000 | Loss: 0.00004351
Iteration 149/1000 | Loss: 0.00004224
Iteration 150/1000 | Loss: 0.00011609
Iteration 151/1000 | Loss: 0.00004864
Iteration 152/1000 | Loss: 0.00085101
Iteration 153/1000 | Loss: 0.00006472
Iteration 154/1000 | Loss: 0.00014549
Iteration 155/1000 | Loss: 0.00023928
Iteration 156/1000 | Loss: 0.00016415
Iteration 157/1000 | Loss: 0.00007157
Iteration 158/1000 | Loss: 0.00007034
Iteration 159/1000 | Loss: 0.00013060
Iteration 160/1000 | Loss: 0.00006932
Iteration 161/1000 | Loss: 0.00004230
Iteration 162/1000 | Loss: 0.00036858
Iteration 163/1000 | Loss: 0.00004101
Iteration 164/1000 | Loss: 0.00011490
Iteration 165/1000 | Loss: 0.00022713
Iteration 166/1000 | Loss: 0.00019563
Iteration 167/1000 | Loss: 0.00069178
Iteration 168/1000 | Loss: 0.00067707
Iteration 169/1000 | Loss: 0.00071091
Iteration 170/1000 | Loss: 0.00003113
Iteration 171/1000 | Loss: 0.00002533
Iteration 172/1000 | Loss: 0.00002319
Iteration 173/1000 | Loss: 0.00002176
Iteration 174/1000 | Loss: 0.00002059
Iteration 175/1000 | Loss: 0.00022570
Iteration 176/1000 | Loss: 0.00018318
Iteration 177/1000 | Loss: 0.00028496
Iteration 178/1000 | Loss: 0.00018462
Iteration 179/1000 | Loss: 0.00002239
Iteration 180/1000 | Loss: 0.00001978
Iteration 181/1000 | Loss: 0.00005771
Iteration 182/1000 | Loss: 0.00001964
Iteration 183/1000 | Loss: 0.00019880
Iteration 184/1000 | Loss: 0.00010001
Iteration 185/1000 | Loss: 0.00011250
Iteration 186/1000 | Loss: 0.00002086
Iteration 187/1000 | Loss: 0.00001955
Iteration 188/1000 | Loss: 0.00001919
Iteration 189/1000 | Loss: 0.00001895
Iteration 190/1000 | Loss: 0.00001889
Iteration 191/1000 | Loss: 0.00001889
Iteration 192/1000 | Loss: 0.00001886
Iteration 193/1000 | Loss: 0.00001886
Iteration 194/1000 | Loss: 0.00001885
Iteration 195/1000 | Loss: 0.00001885
Iteration 196/1000 | Loss: 0.00001885
Iteration 197/1000 | Loss: 0.00001882
Iteration 198/1000 | Loss: 0.00022925
Iteration 199/1000 | Loss: 0.00002407
Iteration 200/1000 | Loss: 0.00001887
Iteration 201/1000 | Loss: 0.00012507
Iteration 202/1000 | Loss: 0.00002295
Iteration 203/1000 | Loss: 0.00002028
Iteration 204/1000 | Loss: 0.00001889
Iteration 205/1000 | Loss: 0.00001866
Iteration 206/1000 | Loss: 0.00001865
Iteration 207/1000 | Loss: 0.00001865
Iteration 208/1000 | Loss: 0.00001865
Iteration 209/1000 | Loss: 0.00001864
Iteration 210/1000 | Loss: 0.00001864
Iteration 211/1000 | Loss: 0.00001864
Iteration 212/1000 | Loss: 0.00001864
Iteration 213/1000 | Loss: 0.00001864
Iteration 214/1000 | Loss: 0.00001863
Iteration 215/1000 | Loss: 0.00001863
Iteration 216/1000 | Loss: 0.00001863
Iteration 217/1000 | Loss: 0.00001863
Iteration 218/1000 | Loss: 0.00001863
Iteration 219/1000 | Loss: 0.00001863
Iteration 220/1000 | Loss: 0.00001862
Iteration 221/1000 | Loss: 0.00001862
Iteration 222/1000 | Loss: 0.00001861
Iteration 223/1000 | Loss: 0.00001861
Iteration 224/1000 | Loss: 0.00001860
Iteration 225/1000 | Loss: 0.00001860
Iteration 226/1000 | Loss: 0.00001860
Iteration 227/1000 | Loss: 0.00001859
Iteration 228/1000 | Loss: 0.00001859
Iteration 229/1000 | Loss: 0.00001859
Iteration 230/1000 | Loss: 0.00001859
Iteration 231/1000 | Loss: 0.00001859
Iteration 232/1000 | Loss: 0.00001859
Iteration 233/1000 | Loss: 0.00001858
Iteration 234/1000 | Loss: 0.00001858
Iteration 235/1000 | Loss: 0.00001858
Iteration 236/1000 | Loss: 0.00001858
Iteration 237/1000 | Loss: 0.00001857
Iteration 238/1000 | Loss: 0.00001857
Iteration 239/1000 | Loss: 0.00001857
Iteration 240/1000 | Loss: 0.00001857
Iteration 241/1000 | Loss: 0.00001857
Iteration 242/1000 | Loss: 0.00001857
Iteration 243/1000 | Loss: 0.00001856
Iteration 244/1000 | Loss: 0.00001856
Iteration 245/1000 | Loss: 0.00001856
Iteration 246/1000 | Loss: 0.00001856
Iteration 247/1000 | Loss: 0.00001856
Iteration 248/1000 | Loss: 0.00001856
Iteration 249/1000 | Loss: 0.00001856
Iteration 250/1000 | Loss: 0.00001856
Iteration 251/1000 | Loss: 0.00001855
Iteration 252/1000 | Loss: 0.00001855
Iteration 253/1000 | Loss: 0.00001855
Iteration 254/1000 | Loss: 0.00001855
Iteration 255/1000 | Loss: 0.00001854
Iteration 256/1000 | Loss: 0.00001854
Iteration 257/1000 | Loss: 0.00001854
Iteration 258/1000 | Loss: 0.00001853
Iteration 259/1000 | Loss: 0.00001853
Iteration 260/1000 | Loss: 0.00001853
Iteration 261/1000 | Loss: 0.00001852
Iteration 262/1000 | Loss: 0.00001852
Iteration 263/1000 | Loss: 0.00001852
Iteration 264/1000 | Loss: 0.00001852
Iteration 265/1000 | Loss: 0.00001852
Iteration 266/1000 | Loss: 0.00001852
Iteration 267/1000 | Loss: 0.00001852
Iteration 268/1000 | Loss: 0.00001852
Iteration 269/1000 | Loss: 0.00001852
Iteration 270/1000 | Loss: 0.00001852
Iteration 271/1000 | Loss: 0.00001852
Iteration 272/1000 | Loss: 0.00001851
Iteration 273/1000 | Loss: 0.00001851
Iteration 274/1000 | Loss: 0.00001851
Iteration 275/1000 | Loss: 0.00001850
Iteration 276/1000 | Loss: 0.00001850
Iteration 277/1000 | Loss: 0.00001850
Iteration 278/1000 | Loss: 0.00001849
Iteration 279/1000 | Loss: 0.00001849
Iteration 280/1000 | Loss: 0.00001849
Iteration 281/1000 | Loss: 0.00001849
Iteration 282/1000 | Loss: 0.00001848
Iteration 283/1000 | Loss: 0.00001848
Iteration 284/1000 | Loss: 0.00001847
Iteration 285/1000 | Loss: 0.00001847
Iteration 286/1000 | Loss: 0.00001846
Iteration 287/1000 | Loss: 0.00001846
Iteration 288/1000 | Loss: 0.00001846
Iteration 289/1000 | Loss: 0.00001846
Iteration 290/1000 | Loss: 0.00001845
Iteration 291/1000 | Loss: 0.00001845
Iteration 292/1000 | Loss: 0.00001845
Iteration 293/1000 | Loss: 0.00001845
Iteration 294/1000 | Loss: 0.00001844
Iteration 295/1000 | Loss: 0.00001844
Iteration 296/1000 | Loss: 0.00001844
Iteration 297/1000 | Loss: 0.00001844
Iteration 298/1000 | Loss: 0.00001843
Iteration 299/1000 | Loss: 0.00001843
Iteration 300/1000 | Loss: 0.00001843
Iteration 301/1000 | Loss: 0.00001843
Iteration 302/1000 | Loss: 0.00001843
Iteration 303/1000 | Loss: 0.00001843
Iteration 304/1000 | Loss: 0.00001842
Iteration 305/1000 | Loss: 0.00001842
Iteration 306/1000 | Loss: 0.00001842
Iteration 307/1000 | Loss: 0.00001842
Iteration 308/1000 | Loss: 0.00001842
Iteration 309/1000 | Loss: 0.00001842
Iteration 310/1000 | Loss: 0.00001842
Iteration 311/1000 | Loss: 0.00001842
Iteration 312/1000 | Loss: 0.00001842
Iteration 313/1000 | Loss: 0.00001842
Iteration 314/1000 | Loss: 0.00001842
Iteration 315/1000 | Loss: 0.00001841
Iteration 316/1000 | Loss: 0.00001841
Iteration 317/1000 | Loss: 0.00001841
Iteration 318/1000 | Loss: 0.00001841
Iteration 319/1000 | Loss: 0.00001841
Iteration 320/1000 | Loss: 0.00001841
Iteration 321/1000 | Loss: 0.00001841
Iteration 322/1000 | Loss: 0.00001841
Iteration 323/1000 | Loss: 0.00001841
Iteration 324/1000 | Loss: 0.00001841
Iteration 325/1000 | Loss: 0.00001841
Iteration 326/1000 | Loss: 0.00001841
Iteration 327/1000 | Loss: 0.00001841
Iteration 328/1000 | Loss: 0.00001841
Iteration 329/1000 | Loss: 0.00001841
Iteration 330/1000 | Loss: 0.00001841
Iteration 331/1000 | Loss: 0.00001841
Iteration 332/1000 | Loss: 0.00001841
Iteration 333/1000 | Loss: 0.00001841
Iteration 334/1000 | Loss: 0.00001841
Iteration 335/1000 | Loss: 0.00001841
Iteration 336/1000 | Loss: 0.00001840
Iteration 337/1000 | Loss: 0.00001840
Iteration 338/1000 | Loss: 0.00001840
Iteration 339/1000 | Loss: 0.00001840
Iteration 340/1000 | Loss: 0.00001840
Iteration 341/1000 | Loss: 0.00001840
Iteration 342/1000 | Loss: 0.00001840
Iteration 343/1000 | Loss: 0.00001840
Iteration 344/1000 | Loss: 0.00001840
Iteration 345/1000 | Loss: 0.00001840
Iteration 346/1000 | Loss: 0.00001840
Iteration 347/1000 | Loss: 0.00001840
Iteration 348/1000 | Loss: 0.00001840
Iteration 349/1000 | Loss: 0.00001840
Iteration 350/1000 | Loss: 0.00001840
Iteration 351/1000 | Loss: 0.00001840
Iteration 352/1000 | Loss: 0.00001840
Iteration 353/1000 | Loss: 0.00001840
Iteration 354/1000 | Loss: 0.00001840
Iteration 355/1000 | Loss: 0.00001840
Iteration 356/1000 | Loss: 0.00001840
Iteration 357/1000 | Loss: 0.00001840
Iteration 358/1000 | Loss: 0.00001840
Iteration 359/1000 | Loss: 0.00001840
Iteration 360/1000 | Loss: 0.00001840
Iteration 361/1000 | Loss: 0.00001840
Iteration 362/1000 | Loss: 0.00001840
Iteration 363/1000 | Loss: 0.00001840
Iteration 364/1000 | Loss: 0.00001840
Iteration 365/1000 | Loss: 0.00001840
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 365. Stopping optimization.
Last 5 losses: [1.839722244767472e-05, 1.839722244767472e-05, 1.839722244767472e-05, 1.839722244767472e-05, 1.839722244767472e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.839722244767472e-05

Optimization complete. Final v2v error: 3.478057622909546 mm

Highest mean error: 11.494664192199707 mm for frame 10

Lowest mean error: 3.140770196914673 mm for frame 201

Saving results

Total time: 379.3483159542084
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00805467
Iteration 2/25 | Loss: 0.00080920
Iteration 3/25 | Loss: 0.00072046
Iteration 4/25 | Loss: 0.00070618
Iteration 5/25 | Loss: 0.00070299
Iteration 6/25 | Loss: 0.00070202
Iteration 7/25 | Loss: 0.00070176
Iteration 8/25 | Loss: 0.00070176
Iteration 9/25 | Loss: 0.00070176
Iteration 10/25 | Loss: 0.00070176
Iteration 11/25 | Loss: 0.00070176
Iteration 12/25 | Loss: 0.00070176
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007017589523456991, 0.0007017589523456991, 0.0007017589523456991, 0.0007017589523456991, 0.0007017589523456991]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007017589523456991

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51990938
Iteration 2/25 | Loss: 0.00030599
Iteration 3/25 | Loss: 0.00030599
Iteration 4/25 | Loss: 0.00030599
Iteration 5/25 | Loss: 0.00030599
Iteration 6/25 | Loss: 0.00030599
Iteration 7/25 | Loss: 0.00030599
Iteration 8/25 | Loss: 0.00030599
Iteration 9/25 | Loss: 0.00030599
Iteration 10/25 | Loss: 0.00030599
Iteration 11/25 | Loss: 0.00030599
Iteration 12/25 | Loss: 0.00030599
Iteration 13/25 | Loss: 0.00030599
Iteration 14/25 | Loss: 0.00030599
Iteration 15/25 | Loss: 0.00030599
Iteration 16/25 | Loss: 0.00030599
Iteration 17/25 | Loss: 0.00030599
Iteration 18/25 | Loss: 0.00030599
Iteration 19/25 | Loss: 0.00030599
Iteration 20/25 | Loss: 0.00030599
Iteration 21/25 | Loss: 0.00030599
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0003059914743062109, 0.0003059914743062109, 0.0003059914743062109, 0.0003059914743062109, 0.0003059914743062109]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003059914743062109

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030599
Iteration 2/1000 | Loss: 0.00002110
Iteration 3/1000 | Loss: 0.00001535
Iteration 4/1000 | Loss: 0.00001432
Iteration 5/1000 | Loss: 0.00001331
Iteration 6/1000 | Loss: 0.00001278
Iteration 7/1000 | Loss: 0.00001247
Iteration 8/1000 | Loss: 0.00001227
Iteration 9/1000 | Loss: 0.00001222
Iteration 10/1000 | Loss: 0.00001216
Iteration 11/1000 | Loss: 0.00001213
Iteration 12/1000 | Loss: 0.00001213
Iteration 13/1000 | Loss: 0.00001207
Iteration 14/1000 | Loss: 0.00001205
Iteration 15/1000 | Loss: 0.00001205
Iteration 16/1000 | Loss: 0.00001205
Iteration 17/1000 | Loss: 0.00001203
Iteration 18/1000 | Loss: 0.00001198
Iteration 19/1000 | Loss: 0.00001198
Iteration 20/1000 | Loss: 0.00001197
Iteration 21/1000 | Loss: 0.00001197
Iteration 22/1000 | Loss: 0.00001196
Iteration 23/1000 | Loss: 0.00001195
Iteration 24/1000 | Loss: 0.00001194
Iteration 25/1000 | Loss: 0.00001193
Iteration 26/1000 | Loss: 0.00001192
Iteration 27/1000 | Loss: 0.00001192
Iteration 28/1000 | Loss: 0.00001192
Iteration 29/1000 | Loss: 0.00001192
Iteration 30/1000 | Loss: 0.00001191
Iteration 31/1000 | Loss: 0.00001191
Iteration 32/1000 | Loss: 0.00001191
Iteration 33/1000 | Loss: 0.00001190
Iteration 34/1000 | Loss: 0.00001189
Iteration 35/1000 | Loss: 0.00001188
Iteration 36/1000 | Loss: 0.00001188
Iteration 37/1000 | Loss: 0.00001188
Iteration 38/1000 | Loss: 0.00001187
Iteration 39/1000 | Loss: 0.00001187
Iteration 40/1000 | Loss: 0.00001186
Iteration 41/1000 | Loss: 0.00001186
Iteration 42/1000 | Loss: 0.00001183
Iteration 43/1000 | Loss: 0.00001181
Iteration 44/1000 | Loss: 0.00001181
Iteration 45/1000 | Loss: 0.00001181
Iteration 46/1000 | Loss: 0.00001181
Iteration 47/1000 | Loss: 0.00001181
Iteration 48/1000 | Loss: 0.00001181
Iteration 49/1000 | Loss: 0.00001181
Iteration 50/1000 | Loss: 0.00001181
Iteration 51/1000 | Loss: 0.00001180
Iteration 52/1000 | Loss: 0.00001179
Iteration 53/1000 | Loss: 0.00001179
Iteration 54/1000 | Loss: 0.00001179
Iteration 55/1000 | Loss: 0.00001178
Iteration 56/1000 | Loss: 0.00001178
Iteration 57/1000 | Loss: 0.00001177
Iteration 58/1000 | Loss: 0.00001177
Iteration 59/1000 | Loss: 0.00001176
Iteration 60/1000 | Loss: 0.00001176
Iteration 61/1000 | Loss: 0.00001176
Iteration 62/1000 | Loss: 0.00001175
Iteration 63/1000 | Loss: 0.00001175
Iteration 64/1000 | Loss: 0.00001175
Iteration 65/1000 | Loss: 0.00001175
Iteration 66/1000 | Loss: 0.00001175
Iteration 67/1000 | Loss: 0.00001175
Iteration 68/1000 | Loss: 0.00001175
Iteration 69/1000 | Loss: 0.00001174
Iteration 70/1000 | Loss: 0.00001174
Iteration 71/1000 | Loss: 0.00001174
Iteration 72/1000 | Loss: 0.00001174
Iteration 73/1000 | Loss: 0.00001174
Iteration 74/1000 | Loss: 0.00001174
Iteration 75/1000 | Loss: 0.00001173
Iteration 76/1000 | Loss: 0.00001173
Iteration 77/1000 | Loss: 0.00001173
Iteration 78/1000 | Loss: 0.00001173
Iteration 79/1000 | Loss: 0.00001173
Iteration 80/1000 | Loss: 0.00001173
Iteration 81/1000 | Loss: 0.00001173
Iteration 82/1000 | Loss: 0.00001173
Iteration 83/1000 | Loss: 0.00001173
Iteration 84/1000 | Loss: 0.00001173
Iteration 85/1000 | Loss: 0.00001173
Iteration 86/1000 | Loss: 0.00001172
Iteration 87/1000 | Loss: 0.00001172
Iteration 88/1000 | Loss: 0.00001172
Iteration 89/1000 | Loss: 0.00001172
Iteration 90/1000 | Loss: 0.00001172
Iteration 91/1000 | Loss: 0.00001172
Iteration 92/1000 | Loss: 0.00001172
Iteration 93/1000 | Loss: 0.00001171
Iteration 94/1000 | Loss: 0.00001171
Iteration 95/1000 | Loss: 0.00001171
Iteration 96/1000 | Loss: 0.00001171
Iteration 97/1000 | Loss: 0.00001170
Iteration 98/1000 | Loss: 0.00001170
Iteration 99/1000 | Loss: 0.00001170
Iteration 100/1000 | Loss: 0.00001170
Iteration 101/1000 | Loss: 0.00001170
Iteration 102/1000 | Loss: 0.00001170
Iteration 103/1000 | Loss: 0.00001170
Iteration 104/1000 | Loss: 0.00001170
Iteration 105/1000 | Loss: 0.00001170
Iteration 106/1000 | Loss: 0.00001170
Iteration 107/1000 | Loss: 0.00001169
Iteration 108/1000 | Loss: 0.00001169
Iteration 109/1000 | Loss: 0.00001168
Iteration 110/1000 | Loss: 0.00001168
Iteration 111/1000 | Loss: 0.00001168
Iteration 112/1000 | Loss: 0.00001168
Iteration 113/1000 | Loss: 0.00001167
Iteration 114/1000 | Loss: 0.00001167
Iteration 115/1000 | Loss: 0.00001167
Iteration 116/1000 | Loss: 0.00001166
Iteration 117/1000 | Loss: 0.00001166
Iteration 118/1000 | Loss: 0.00001166
Iteration 119/1000 | Loss: 0.00001165
Iteration 120/1000 | Loss: 0.00001165
Iteration 121/1000 | Loss: 0.00001165
Iteration 122/1000 | Loss: 0.00001165
Iteration 123/1000 | Loss: 0.00001165
Iteration 124/1000 | Loss: 0.00001165
Iteration 125/1000 | Loss: 0.00001165
Iteration 126/1000 | Loss: 0.00001165
Iteration 127/1000 | Loss: 0.00001164
Iteration 128/1000 | Loss: 0.00001163
Iteration 129/1000 | Loss: 0.00001163
Iteration 130/1000 | Loss: 0.00001163
Iteration 131/1000 | Loss: 0.00001163
Iteration 132/1000 | Loss: 0.00001163
Iteration 133/1000 | Loss: 0.00001162
Iteration 134/1000 | Loss: 0.00001162
Iteration 135/1000 | Loss: 0.00001162
Iteration 136/1000 | Loss: 0.00001162
Iteration 137/1000 | Loss: 0.00001162
Iteration 138/1000 | Loss: 0.00001162
Iteration 139/1000 | Loss: 0.00001161
Iteration 140/1000 | Loss: 0.00001161
Iteration 141/1000 | Loss: 0.00001161
Iteration 142/1000 | Loss: 0.00001161
Iteration 143/1000 | Loss: 0.00001161
Iteration 144/1000 | Loss: 0.00001161
Iteration 145/1000 | Loss: 0.00001160
Iteration 146/1000 | Loss: 0.00001160
Iteration 147/1000 | Loss: 0.00001160
Iteration 148/1000 | Loss: 0.00001160
Iteration 149/1000 | Loss: 0.00001160
Iteration 150/1000 | Loss: 0.00001160
Iteration 151/1000 | Loss: 0.00001160
Iteration 152/1000 | Loss: 0.00001160
Iteration 153/1000 | Loss: 0.00001160
Iteration 154/1000 | Loss: 0.00001160
Iteration 155/1000 | Loss: 0.00001160
Iteration 156/1000 | Loss: 0.00001159
Iteration 157/1000 | Loss: 0.00001159
Iteration 158/1000 | Loss: 0.00001159
Iteration 159/1000 | Loss: 0.00001159
Iteration 160/1000 | Loss: 0.00001159
Iteration 161/1000 | Loss: 0.00001159
Iteration 162/1000 | Loss: 0.00001158
Iteration 163/1000 | Loss: 0.00001158
Iteration 164/1000 | Loss: 0.00001158
Iteration 165/1000 | Loss: 0.00001158
Iteration 166/1000 | Loss: 0.00001158
Iteration 167/1000 | Loss: 0.00001158
Iteration 168/1000 | Loss: 0.00001158
Iteration 169/1000 | Loss: 0.00001158
Iteration 170/1000 | Loss: 0.00001158
Iteration 171/1000 | Loss: 0.00001158
Iteration 172/1000 | Loss: 0.00001158
Iteration 173/1000 | Loss: 0.00001158
Iteration 174/1000 | Loss: 0.00001158
Iteration 175/1000 | Loss: 0.00001158
Iteration 176/1000 | Loss: 0.00001158
Iteration 177/1000 | Loss: 0.00001158
Iteration 178/1000 | Loss: 0.00001158
Iteration 179/1000 | Loss: 0.00001157
Iteration 180/1000 | Loss: 0.00001157
Iteration 181/1000 | Loss: 0.00001157
Iteration 182/1000 | Loss: 0.00001157
Iteration 183/1000 | Loss: 0.00001157
Iteration 184/1000 | Loss: 0.00001157
Iteration 185/1000 | Loss: 0.00001157
Iteration 186/1000 | Loss: 0.00001157
Iteration 187/1000 | Loss: 0.00001157
Iteration 188/1000 | Loss: 0.00001157
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 188. Stopping optimization.
Last 5 losses: [1.1574707968975417e-05, 1.1574707968975417e-05, 1.1574707968975417e-05, 1.1574707968975417e-05, 1.1574707968975417e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1574707968975417e-05

Optimization complete. Final v2v error: 2.920154333114624 mm

Highest mean error: 3.0595760345458984 mm for frame 115

Lowest mean error: 2.780764102935791 mm for frame 43

Saving results

Total time: 36.56055545806885
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00600834
Iteration 2/25 | Loss: 0.00123749
Iteration 3/25 | Loss: 0.00083295
Iteration 4/25 | Loss: 0.00076881
Iteration 5/25 | Loss: 0.00075461
Iteration 6/25 | Loss: 0.00075220
Iteration 7/25 | Loss: 0.00075186
Iteration 8/25 | Loss: 0.00075186
Iteration 9/25 | Loss: 0.00075186
Iteration 10/25 | Loss: 0.00075186
Iteration 11/25 | Loss: 0.00075186
Iteration 12/25 | Loss: 0.00075186
Iteration 13/25 | Loss: 0.00075186
Iteration 14/25 | Loss: 0.00075186
Iteration 15/25 | Loss: 0.00075186
Iteration 16/25 | Loss: 0.00075186
Iteration 17/25 | Loss: 0.00075186
Iteration 18/25 | Loss: 0.00075186
Iteration 19/25 | Loss: 0.00075186
Iteration 20/25 | Loss: 0.00075186
Iteration 21/25 | Loss: 0.00075186
Iteration 22/25 | Loss: 0.00075186
Iteration 23/25 | Loss: 0.00075186
Iteration 24/25 | Loss: 0.00075186
Iteration 25/25 | Loss: 0.00075186

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32689321
Iteration 2/25 | Loss: 0.00031560
Iteration 3/25 | Loss: 0.00031557
Iteration 4/25 | Loss: 0.00031557
Iteration 5/25 | Loss: 0.00031557
Iteration 6/25 | Loss: 0.00031557
Iteration 7/25 | Loss: 0.00031557
Iteration 8/25 | Loss: 0.00031557
Iteration 9/25 | Loss: 0.00031557
Iteration 10/25 | Loss: 0.00031557
Iteration 11/25 | Loss: 0.00031557
Iteration 12/25 | Loss: 0.00031557
Iteration 13/25 | Loss: 0.00031557
Iteration 14/25 | Loss: 0.00031557
Iteration 15/25 | Loss: 0.00031557
Iteration 16/25 | Loss: 0.00031557
Iteration 17/25 | Loss: 0.00031557
Iteration 18/25 | Loss: 0.00031557
Iteration 19/25 | Loss: 0.00031557
Iteration 20/25 | Loss: 0.00031557
Iteration 21/25 | Loss: 0.00031557
Iteration 22/25 | Loss: 0.00031557
Iteration 23/25 | Loss: 0.00031557
Iteration 24/25 | Loss: 0.00031557
Iteration 25/25 | Loss: 0.00031557

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031557
Iteration 2/1000 | Loss: 0.00002543
Iteration 3/1000 | Loss: 0.00001870
Iteration 4/1000 | Loss: 0.00001627
Iteration 5/1000 | Loss: 0.00001544
Iteration 6/1000 | Loss: 0.00001482
Iteration 7/1000 | Loss: 0.00001452
Iteration 8/1000 | Loss: 0.00001418
Iteration 9/1000 | Loss: 0.00001397
Iteration 10/1000 | Loss: 0.00001394
Iteration 11/1000 | Loss: 0.00001393
Iteration 12/1000 | Loss: 0.00001377
Iteration 13/1000 | Loss: 0.00001376
Iteration 14/1000 | Loss: 0.00001375
Iteration 15/1000 | Loss: 0.00001372
Iteration 16/1000 | Loss: 0.00001359
Iteration 17/1000 | Loss: 0.00001359
Iteration 18/1000 | Loss: 0.00001357
Iteration 19/1000 | Loss: 0.00001356
Iteration 20/1000 | Loss: 0.00001355
Iteration 21/1000 | Loss: 0.00001354
Iteration 22/1000 | Loss: 0.00001353
Iteration 23/1000 | Loss: 0.00001352
Iteration 24/1000 | Loss: 0.00001352
Iteration 25/1000 | Loss: 0.00001350
Iteration 26/1000 | Loss: 0.00001349
Iteration 27/1000 | Loss: 0.00001347
Iteration 28/1000 | Loss: 0.00001347
Iteration 29/1000 | Loss: 0.00001347
Iteration 30/1000 | Loss: 0.00001346
Iteration 31/1000 | Loss: 0.00001346
Iteration 32/1000 | Loss: 0.00001346
Iteration 33/1000 | Loss: 0.00001345
Iteration 34/1000 | Loss: 0.00001344
Iteration 35/1000 | Loss: 0.00001344
Iteration 36/1000 | Loss: 0.00001344
Iteration 37/1000 | Loss: 0.00001344
Iteration 38/1000 | Loss: 0.00001344
Iteration 39/1000 | Loss: 0.00001343
Iteration 40/1000 | Loss: 0.00001343
Iteration 41/1000 | Loss: 0.00001343
Iteration 42/1000 | Loss: 0.00001343
Iteration 43/1000 | Loss: 0.00001342
Iteration 44/1000 | Loss: 0.00001342
Iteration 45/1000 | Loss: 0.00001342
Iteration 46/1000 | Loss: 0.00001342
Iteration 47/1000 | Loss: 0.00001342
Iteration 48/1000 | Loss: 0.00001342
Iteration 49/1000 | Loss: 0.00001342
Iteration 50/1000 | Loss: 0.00001342
Iteration 51/1000 | Loss: 0.00001342
Iteration 52/1000 | Loss: 0.00001342
Iteration 53/1000 | Loss: 0.00001342
Iteration 54/1000 | Loss: 0.00001342
Iteration 55/1000 | Loss: 0.00001342
Iteration 56/1000 | Loss: 0.00001342
Iteration 57/1000 | Loss: 0.00001342
Iteration 58/1000 | Loss: 0.00001342
Iteration 59/1000 | Loss: 0.00001342
Iteration 60/1000 | Loss: 0.00001341
Iteration 61/1000 | Loss: 0.00001341
Iteration 62/1000 | Loss: 0.00001341
Iteration 63/1000 | Loss: 0.00001341
Iteration 64/1000 | Loss: 0.00001341
Iteration 65/1000 | Loss: 0.00001341
Iteration 66/1000 | Loss: 0.00001341
Iteration 67/1000 | Loss: 0.00001341
Iteration 68/1000 | Loss: 0.00001341
Iteration 69/1000 | Loss: 0.00001341
Iteration 70/1000 | Loss: 0.00001340
Iteration 71/1000 | Loss: 0.00001340
Iteration 72/1000 | Loss: 0.00001340
Iteration 73/1000 | Loss: 0.00001340
Iteration 74/1000 | Loss: 0.00001340
Iteration 75/1000 | Loss: 0.00001340
Iteration 76/1000 | Loss: 0.00001339
Iteration 77/1000 | Loss: 0.00001339
Iteration 78/1000 | Loss: 0.00001339
Iteration 79/1000 | Loss: 0.00001339
Iteration 80/1000 | Loss: 0.00001339
Iteration 81/1000 | Loss: 0.00001339
Iteration 82/1000 | Loss: 0.00001339
Iteration 83/1000 | Loss: 0.00001339
Iteration 84/1000 | Loss: 0.00001339
Iteration 85/1000 | Loss: 0.00001339
Iteration 86/1000 | Loss: 0.00001339
Iteration 87/1000 | Loss: 0.00001338
Iteration 88/1000 | Loss: 0.00001338
Iteration 89/1000 | Loss: 0.00001338
Iteration 90/1000 | Loss: 0.00001338
Iteration 91/1000 | Loss: 0.00001338
Iteration 92/1000 | Loss: 0.00001338
Iteration 93/1000 | Loss: 0.00001338
Iteration 94/1000 | Loss: 0.00001338
Iteration 95/1000 | Loss: 0.00001338
Iteration 96/1000 | Loss: 0.00001338
Iteration 97/1000 | Loss: 0.00001338
Iteration 98/1000 | Loss: 0.00001338
Iteration 99/1000 | Loss: 0.00001337
Iteration 100/1000 | Loss: 0.00001337
Iteration 101/1000 | Loss: 0.00001337
Iteration 102/1000 | Loss: 0.00001337
Iteration 103/1000 | Loss: 0.00001337
Iteration 104/1000 | Loss: 0.00001337
Iteration 105/1000 | Loss: 0.00001337
Iteration 106/1000 | Loss: 0.00001337
Iteration 107/1000 | Loss: 0.00001337
Iteration 108/1000 | Loss: 0.00001337
Iteration 109/1000 | Loss: 0.00001337
Iteration 110/1000 | Loss: 0.00001337
Iteration 111/1000 | Loss: 0.00001337
Iteration 112/1000 | Loss: 0.00001337
Iteration 113/1000 | Loss: 0.00001337
Iteration 114/1000 | Loss: 0.00001337
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 114. Stopping optimization.
Last 5 losses: [1.3374505215324461e-05, 1.3374505215324461e-05, 1.3374505215324461e-05, 1.3374505215324461e-05, 1.3374505215324461e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3374505215324461e-05

Optimization complete. Final v2v error: 3.108614921569824 mm

Highest mean error: 3.7761070728302 mm for frame 80

Lowest mean error: 2.9708263874053955 mm for frame 7

Saving results

Total time: 34.912485122680664
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1065/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1065.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1065
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00953687
Iteration 2/25 | Loss: 0.00217844
Iteration 3/25 | Loss: 0.00126687
Iteration 4/25 | Loss: 0.00113129
Iteration 5/25 | Loss: 0.00106589
Iteration 6/25 | Loss: 0.00107593
Iteration 7/25 | Loss: 0.00105733
Iteration 8/25 | Loss: 0.00104866
Iteration 9/25 | Loss: 0.00101688
Iteration 10/25 | Loss: 0.00099769
Iteration 11/25 | Loss: 0.00098926
Iteration 12/25 | Loss: 0.00098631
Iteration 13/25 | Loss: 0.00098322
Iteration 14/25 | Loss: 0.00097851
Iteration 15/25 | Loss: 0.00096946
Iteration 16/25 | Loss: 0.00096563
Iteration 17/25 | Loss: 0.00096142
Iteration 18/25 | Loss: 0.00096432
Iteration 19/25 | Loss: 0.00096694
Iteration 20/25 | Loss: 0.00096769
Iteration 21/25 | Loss: 0.00096734
Iteration 22/25 | Loss: 0.00096121
Iteration 23/25 | Loss: 0.00095894
Iteration 24/25 | Loss: 0.00095895
Iteration 25/25 | Loss: 0.00095577

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.47202444
Iteration 2/25 | Loss: 0.00235337
Iteration 3/25 | Loss: 0.00235337
Iteration 4/25 | Loss: 0.00235337
Iteration 5/25 | Loss: 0.00235337
Iteration 6/25 | Loss: 0.00235337
Iteration 7/25 | Loss: 0.00235337
Iteration 8/25 | Loss: 0.00235337
Iteration 9/25 | Loss: 0.00235337
Iteration 10/25 | Loss: 0.00235337
Iteration 11/25 | Loss: 0.00235337
Iteration 12/25 | Loss: 0.00235337
Iteration 13/25 | Loss: 0.00235337
Iteration 14/25 | Loss: 0.00235337
Iteration 15/25 | Loss: 0.00235337
Iteration 16/25 | Loss: 0.00235337
Iteration 17/25 | Loss: 0.00235337
Iteration 18/25 | Loss: 0.00235337
Iteration 19/25 | Loss: 0.00235337
Iteration 20/25 | Loss: 0.00235337
Iteration 21/25 | Loss: 0.00235337
Iteration 22/25 | Loss: 0.00235337
Iteration 23/25 | Loss: 0.00235337
Iteration 24/25 | Loss: 0.00235337
Iteration 25/25 | Loss: 0.00235337
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0023533671628683805, 0.0023533671628683805, 0.0023533671628683805, 0.0023533671628683805, 0.0023533671628683805]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0023533671628683805

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00235337
Iteration 2/1000 | Loss: 0.00034176
Iteration 3/1000 | Loss: 0.00316440
Iteration 4/1000 | Loss: 0.00218487
Iteration 5/1000 | Loss: 0.00576203
Iteration 6/1000 | Loss: 0.00294591
Iteration 7/1000 | Loss: 0.00538533
Iteration 8/1000 | Loss: 0.00019113
Iteration 9/1000 | Loss: 0.00374111
Iteration 10/1000 | Loss: 0.00481794
Iteration 11/1000 | Loss: 0.00017369
Iteration 12/1000 | Loss: 0.00010548
Iteration 13/1000 | Loss: 0.00007389
Iteration 14/1000 | Loss: 0.00006107
Iteration 15/1000 | Loss: 0.00004978
Iteration 16/1000 | Loss: 0.00004453
Iteration 17/1000 | Loss: 0.00013789
Iteration 18/1000 | Loss: 0.00094889
Iteration 19/1000 | Loss: 0.00060778
Iteration 20/1000 | Loss: 0.00028116
Iteration 21/1000 | Loss: 0.00017967
Iteration 22/1000 | Loss: 0.00014148
Iteration 23/1000 | Loss: 0.00005250
Iteration 24/1000 | Loss: 0.00013614
Iteration 25/1000 | Loss: 0.00009535
Iteration 26/1000 | Loss: 0.00010834
Iteration 27/1000 | Loss: 0.00008786
Iteration 28/1000 | Loss: 0.00010944
Iteration 29/1000 | Loss: 0.00007729
Iteration 30/1000 | Loss: 0.00004264
Iteration 31/1000 | Loss: 0.00004067
Iteration 32/1000 | Loss: 0.00095574
Iteration 33/1000 | Loss: 0.00013280
Iteration 34/1000 | Loss: 0.00006246
Iteration 35/1000 | Loss: 0.00004073
Iteration 36/1000 | Loss: 0.00004778
Iteration 37/1000 | Loss: 0.00003788
Iteration 38/1000 | Loss: 0.00003601
Iteration 39/1000 | Loss: 0.00003506
Iteration 40/1000 | Loss: 0.00077525
Iteration 41/1000 | Loss: 0.00078680
Iteration 42/1000 | Loss: 0.00003714
Iteration 43/1000 | Loss: 0.00003391
Iteration 44/1000 | Loss: 0.00003127
Iteration 45/1000 | Loss: 0.00002865
Iteration 46/1000 | Loss: 0.00108068
Iteration 47/1000 | Loss: 0.00034772
Iteration 48/1000 | Loss: 0.00011465
Iteration 49/1000 | Loss: 0.00026137
Iteration 50/1000 | Loss: 0.00004137
Iteration 51/1000 | Loss: 0.00003502
Iteration 52/1000 | Loss: 0.00003100
Iteration 53/1000 | Loss: 0.00002854
Iteration 54/1000 | Loss: 0.00002716
Iteration 55/1000 | Loss: 0.00002641
Iteration 56/1000 | Loss: 0.00002599
Iteration 57/1000 | Loss: 0.00002555
Iteration 58/1000 | Loss: 0.00002528
Iteration 59/1000 | Loss: 0.00002497
Iteration 60/1000 | Loss: 0.00002475
Iteration 61/1000 | Loss: 0.00002462
Iteration 62/1000 | Loss: 0.00002461
Iteration 63/1000 | Loss: 0.00002460
Iteration 64/1000 | Loss: 0.00002446
Iteration 65/1000 | Loss: 0.00002444
Iteration 66/1000 | Loss: 0.00002439
Iteration 67/1000 | Loss: 0.00002437
Iteration 68/1000 | Loss: 0.00002431
Iteration 69/1000 | Loss: 0.00002415
Iteration 70/1000 | Loss: 0.00002413
Iteration 71/1000 | Loss: 0.00002395
Iteration 72/1000 | Loss: 0.00113199
Iteration 73/1000 | Loss: 0.00018677
Iteration 74/1000 | Loss: 0.00003903
Iteration 75/1000 | Loss: 0.00003045
Iteration 76/1000 | Loss: 0.00002632
Iteration 77/1000 | Loss: 0.00002421
Iteration 78/1000 | Loss: 0.00002237
Iteration 79/1000 | Loss: 0.00002138
Iteration 80/1000 | Loss: 0.00031716
Iteration 81/1000 | Loss: 0.00004311
Iteration 82/1000 | Loss: 0.00003798
Iteration 83/1000 | Loss: 0.00003297
Iteration 84/1000 | Loss: 0.00002147
Iteration 85/1000 | Loss: 0.00002057
Iteration 86/1000 | Loss: 0.00001980
Iteration 87/1000 | Loss: 0.00001900
Iteration 88/1000 | Loss: 0.00001848
Iteration 89/1000 | Loss: 0.00001830
Iteration 90/1000 | Loss: 0.00001814
Iteration 91/1000 | Loss: 0.00001797
Iteration 92/1000 | Loss: 0.00001784
Iteration 93/1000 | Loss: 0.00001783
Iteration 94/1000 | Loss: 0.00001782
Iteration 95/1000 | Loss: 0.00001782
Iteration 96/1000 | Loss: 0.00001781
Iteration 97/1000 | Loss: 0.00001780
Iteration 98/1000 | Loss: 0.00001780
Iteration 99/1000 | Loss: 0.00001779
Iteration 100/1000 | Loss: 0.00001779
Iteration 101/1000 | Loss: 0.00001778
Iteration 102/1000 | Loss: 0.00001778
Iteration 103/1000 | Loss: 0.00001776
Iteration 104/1000 | Loss: 0.00001775
Iteration 105/1000 | Loss: 0.00001775
Iteration 106/1000 | Loss: 0.00001774
Iteration 107/1000 | Loss: 0.00001773
Iteration 108/1000 | Loss: 0.00001773
Iteration 109/1000 | Loss: 0.00001773
Iteration 110/1000 | Loss: 0.00001772
Iteration 111/1000 | Loss: 0.00001772
Iteration 112/1000 | Loss: 0.00001772
Iteration 113/1000 | Loss: 0.00001772
Iteration 114/1000 | Loss: 0.00001772
Iteration 115/1000 | Loss: 0.00001771
Iteration 116/1000 | Loss: 0.00001771
Iteration 117/1000 | Loss: 0.00001771
Iteration 118/1000 | Loss: 0.00001770
Iteration 119/1000 | Loss: 0.00001770
Iteration 120/1000 | Loss: 0.00001770
Iteration 121/1000 | Loss: 0.00001770
Iteration 122/1000 | Loss: 0.00001769
Iteration 123/1000 | Loss: 0.00001769
Iteration 124/1000 | Loss: 0.00001769
Iteration 125/1000 | Loss: 0.00001769
Iteration 126/1000 | Loss: 0.00001769
Iteration 127/1000 | Loss: 0.00001768
Iteration 128/1000 | Loss: 0.00001768
Iteration 129/1000 | Loss: 0.00001768
Iteration 130/1000 | Loss: 0.00001768
Iteration 131/1000 | Loss: 0.00001767
Iteration 132/1000 | Loss: 0.00001767
Iteration 133/1000 | Loss: 0.00001767
Iteration 134/1000 | Loss: 0.00001767
Iteration 135/1000 | Loss: 0.00001767
Iteration 136/1000 | Loss: 0.00001767
Iteration 137/1000 | Loss: 0.00001767
Iteration 138/1000 | Loss: 0.00001767
Iteration 139/1000 | Loss: 0.00001767
Iteration 140/1000 | Loss: 0.00001767
Iteration 141/1000 | Loss: 0.00001767
Iteration 142/1000 | Loss: 0.00001766
Iteration 143/1000 | Loss: 0.00001766
Iteration 144/1000 | Loss: 0.00001766
Iteration 145/1000 | Loss: 0.00001766
Iteration 146/1000 | Loss: 0.00001766
Iteration 147/1000 | Loss: 0.00001766
Iteration 148/1000 | Loss: 0.00001766
Iteration 149/1000 | Loss: 0.00001766
Iteration 150/1000 | Loss: 0.00001766
Iteration 151/1000 | Loss: 0.00001766
Iteration 152/1000 | Loss: 0.00001766
Iteration 153/1000 | Loss: 0.00001766
Iteration 154/1000 | Loss: 0.00001766
Iteration 155/1000 | Loss: 0.00001766
Iteration 156/1000 | Loss: 0.00001765
Iteration 157/1000 | Loss: 0.00001765
Iteration 158/1000 | Loss: 0.00001765
Iteration 159/1000 | Loss: 0.00001765
Iteration 160/1000 | Loss: 0.00001765
Iteration 161/1000 | Loss: 0.00001765
Iteration 162/1000 | Loss: 0.00001765
Iteration 163/1000 | Loss: 0.00001765
Iteration 164/1000 | Loss: 0.00001765
Iteration 165/1000 | Loss: 0.00001765
Iteration 166/1000 | Loss: 0.00001765
Iteration 167/1000 | Loss: 0.00001765
Iteration 168/1000 | Loss: 0.00001764
Iteration 169/1000 | Loss: 0.00001764
Iteration 170/1000 | Loss: 0.00001764
Iteration 171/1000 | Loss: 0.00001764
Iteration 172/1000 | Loss: 0.00001764
Iteration 173/1000 | Loss: 0.00001764
Iteration 174/1000 | Loss: 0.00001764
Iteration 175/1000 | Loss: 0.00001764
Iteration 176/1000 | Loss: 0.00001764
Iteration 177/1000 | Loss: 0.00001764
Iteration 178/1000 | Loss: 0.00001764
Iteration 179/1000 | Loss: 0.00001764
Iteration 180/1000 | Loss: 0.00001763
Iteration 181/1000 | Loss: 0.00001763
Iteration 182/1000 | Loss: 0.00001763
Iteration 183/1000 | Loss: 0.00001763
Iteration 184/1000 | Loss: 0.00001763
Iteration 185/1000 | Loss: 0.00001763
Iteration 186/1000 | Loss: 0.00001763
Iteration 187/1000 | Loss: 0.00001763
Iteration 188/1000 | Loss: 0.00001763
Iteration 189/1000 | Loss: 0.00001763
Iteration 190/1000 | Loss: 0.00001763
Iteration 191/1000 | Loss: 0.00001763
Iteration 192/1000 | Loss: 0.00001763
Iteration 193/1000 | Loss: 0.00001763
Iteration 194/1000 | Loss: 0.00001763
Iteration 195/1000 | Loss: 0.00001763
Iteration 196/1000 | Loss: 0.00001763
Iteration 197/1000 | Loss: 0.00001763
Iteration 198/1000 | Loss: 0.00001763
Iteration 199/1000 | Loss: 0.00001763
Iteration 200/1000 | Loss: 0.00001763
Iteration 201/1000 | Loss: 0.00001763
Iteration 202/1000 | Loss: 0.00001763
Iteration 203/1000 | Loss: 0.00001763
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 203. Stopping optimization.
Last 5 losses: [1.7632493836572394e-05, 1.7632493836572394e-05, 1.7632493836572394e-05, 1.7632493836572394e-05, 1.7632493836572394e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7632493836572394e-05

Optimization complete. Final v2v error: 3.4148988723754883 mm

Highest mean error: 5.689091205596924 mm for frame 62

Lowest mean error: 2.7274763584136963 mm for frame 119

Saving results

Total time: 176.5441324710846
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1069/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1069.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1069
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01070486
Iteration 2/25 | Loss: 0.00163635
Iteration 3/25 | Loss: 0.00094912
Iteration 4/25 | Loss: 0.00089541
Iteration 5/25 | Loss: 0.00087973
Iteration 6/25 | Loss: 0.00087570
Iteration 7/25 | Loss: 0.00087452
Iteration 8/25 | Loss: 0.00087452
Iteration 9/25 | Loss: 0.00087452
Iteration 10/25 | Loss: 0.00087452
Iteration 11/25 | Loss: 0.00087452
Iteration 12/25 | Loss: 0.00087452
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008745169616304338, 0.0008745169616304338, 0.0008745169616304338, 0.0008745169616304338, 0.0008745169616304338]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008745169616304338

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.39764652
Iteration 2/25 | Loss: 0.00039433
Iteration 3/25 | Loss: 0.00039433
Iteration 4/25 | Loss: 0.00039432
Iteration 5/25 | Loss: 0.00039432
Iteration 6/25 | Loss: 0.00039432
Iteration 7/25 | Loss: 0.00039432
Iteration 8/25 | Loss: 0.00039432
Iteration 9/25 | Loss: 0.00039432
Iteration 10/25 | Loss: 0.00039432
Iteration 11/25 | Loss: 0.00039432
Iteration 12/25 | Loss: 0.00039432
Iteration 13/25 | Loss: 0.00039432
Iteration 14/25 | Loss: 0.00039432
Iteration 15/25 | Loss: 0.00039432
Iteration 16/25 | Loss: 0.00039432
Iteration 17/25 | Loss: 0.00039432
Iteration 18/25 | Loss: 0.00039432
Iteration 19/25 | Loss: 0.00039432
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003943227347917855, 0.0003943227347917855, 0.0003943227347917855, 0.0003943227347917855, 0.0003943227347917855]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003943227347917855

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039432
Iteration 2/1000 | Loss: 0.00004602
Iteration 3/1000 | Loss: 0.00003203
Iteration 4/1000 | Loss: 0.00002933
Iteration 5/1000 | Loss: 0.00002777
Iteration 6/1000 | Loss: 0.00002642
Iteration 7/1000 | Loss: 0.00002510
Iteration 8/1000 | Loss: 0.00002433
Iteration 9/1000 | Loss: 0.00002376
Iteration 10/1000 | Loss: 0.00002343
Iteration 11/1000 | Loss: 0.00002316
Iteration 12/1000 | Loss: 0.00002293
Iteration 13/1000 | Loss: 0.00002276
Iteration 14/1000 | Loss: 0.00002260
Iteration 15/1000 | Loss: 0.00002259
Iteration 16/1000 | Loss: 0.00002254
Iteration 17/1000 | Loss: 0.00002254
Iteration 18/1000 | Loss: 0.00002248
Iteration 19/1000 | Loss: 0.00002245
Iteration 20/1000 | Loss: 0.00002245
Iteration 21/1000 | Loss: 0.00002244
Iteration 22/1000 | Loss: 0.00002244
Iteration 23/1000 | Loss: 0.00002244
Iteration 24/1000 | Loss: 0.00002244
Iteration 25/1000 | Loss: 0.00002243
Iteration 26/1000 | Loss: 0.00002243
Iteration 27/1000 | Loss: 0.00002242
Iteration 28/1000 | Loss: 0.00002242
Iteration 29/1000 | Loss: 0.00002242
Iteration 30/1000 | Loss: 0.00002241
Iteration 31/1000 | Loss: 0.00002241
Iteration 32/1000 | Loss: 0.00002241
Iteration 33/1000 | Loss: 0.00002241
Iteration 34/1000 | Loss: 0.00002240
Iteration 35/1000 | Loss: 0.00002240
Iteration 36/1000 | Loss: 0.00002240
Iteration 37/1000 | Loss: 0.00002238
Iteration 38/1000 | Loss: 0.00002238
Iteration 39/1000 | Loss: 0.00002237
Iteration 40/1000 | Loss: 0.00002237
Iteration 41/1000 | Loss: 0.00002237
Iteration 42/1000 | Loss: 0.00002236
Iteration 43/1000 | Loss: 0.00002236
Iteration 44/1000 | Loss: 0.00002235
Iteration 45/1000 | Loss: 0.00002235
Iteration 46/1000 | Loss: 0.00002235
Iteration 47/1000 | Loss: 0.00002235
Iteration 48/1000 | Loss: 0.00002234
Iteration 49/1000 | Loss: 0.00002234
Iteration 50/1000 | Loss: 0.00002234
Iteration 51/1000 | Loss: 0.00002234
Iteration 52/1000 | Loss: 0.00002234
Iteration 53/1000 | Loss: 0.00002234
Iteration 54/1000 | Loss: 0.00002234
Iteration 55/1000 | Loss: 0.00002234
Iteration 56/1000 | Loss: 0.00002233
Iteration 57/1000 | Loss: 0.00002233
Iteration 58/1000 | Loss: 0.00002233
Iteration 59/1000 | Loss: 0.00002233
Iteration 60/1000 | Loss: 0.00002233
Iteration 61/1000 | Loss: 0.00002232
Iteration 62/1000 | Loss: 0.00002232
Iteration 63/1000 | Loss: 0.00002232
Iteration 64/1000 | Loss: 0.00002231
Iteration 65/1000 | Loss: 0.00002231
Iteration 66/1000 | Loss: 0.00002231
Iteration 67/1000 | Loss: 0.00002231
Iteration 68/1000 | Loss: 0.00002231
Iteration 69/1000 | Loss: 0.00002230
Iteration 70/1000 | Loss: 0.00002230
Iteration 71/1000 | Loss: 0.00002230
Iteration 72/1000 | Loss: 0.00002230
Iteration 73/1000 | Loss: 0.00002230
Iteration 74/1000 | Loss: 0.00002230
Iteration 75/1000 | Loss: 0.00002230
Iteration 76/1000 | Loss: 0.00002229
Iteration 77/1000 | Loss: 0.00002229
Iteration 78/1000 | Loss: 0.00002229
Iteration 79/1000 | Loss: 0.00002229
Iteration 80/1000 | Loss: 0.00002229
Iteration 81/1000 | Loss: 0.00002229
Iteration 82/1000 | Loss: 0.00002229
Iteration 83/1000 | Loss: 0.00002229
Iteration 84/1000 | Loss: 0.00002229
Iteration 85/1000 | Loss: 0.00002229
Iteration 86/1000 | Loss: 0.00002229
Iteration 87/1000 | Loss: 0.00002229
Iteration 88/1000 | Loss: 0.00002229
Iteration 89/1000 | Loss: 0.00002229
Iteration 90/1000 | Loss: 0.00002229
Iteration 91/1000 | Loss: 0.00002229
Iteration 92/1000 | Loss: 0.00002229
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [2.2285366867436096e-05, 2.2285366867436096e-05, 2.2285366867436096e-05, 2.2285366867436096e-05, 2.2285366867436096e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2285366867436096e-05

Optimization complete. Final v2v error: 3.8321621417999268 mm

Highest mean error: 4.856207370758057 mm for frame 27

Lowest mean error: 2.922947645187378 mm for frame 0

Saving results

Total time: 39.87008213996887
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01105946
Iteration 2/25 | Loss: 0.01105946
Iteration 3/25 | Loss: 0.01105946
Iteration 4/25 | Loss: 0.01105946
Iteration 5/25 | Loss: 0.01105946
Iteration 6/25 | Loss: 0.01105945
Iteration 7/25 | Loss: 0.01105945
Iteration 8/25 | Loss: 0.01105945
Iteration 9/25 | Loss: 0.01105945
Iteration 10/25 | Loss: 0.00202711
Iteration 11/25 | Loss: 0.00111200
Iteration 12/25 | Loss: 0.00099935
Iteration 13/25 | Loss: 0.00098688
Iteration 14/25 | Loss: 0.00096874
Iteration 15/25 | Loss: 0.00095292
Iteration 16/25 | Loss: 0.00095549
Iteration 17/25 | Loss: 0.00092492
Iteration 18/25 | Loss: 0.00092104
Iteration 19/25 | Loss: 0.00093268
Iteration 20/25 | Loss: 0.00090338
Iteration 21/25 | Loss: 0.00090242
Iteration 22/25 | Loss: 0.00089924
Iteration 23/25 | Loss: 0.00090021
Iteration 24/25 | Loss: 0.00089884
Iteration 25/25 | Loss: 0.00089686

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79773283
Iteration 2/25 | Loss: 0.00041283
Iteration 3/25 | Loss: 0.00041282
Iteration 4/25 | Loss: 0.00041282
Iteration 5/25 | Loss: 0.00041282
Iteration 6/25 | Loss: 0.00041282
Iteration 7/25 | Loss: 0.00041282
Iteration 8/25 | Loss: 0.00041282
Iteration 9/25 | Loss: 0.00041282
Iteration 10/25 | Loss: 0.00041282
Iteration 11/25 | Loss: 0.00041282
Iteration 12/25 | Loss: 0.00041282
Iteration 13/25 | Loss: 0.00041282
Iteration 14/25 | Loss: 0.00041282
Iteration 15/25 | Loss: 0.00041282
Iteration 16/25 | Loss: 0.00041282
Iteration 17/25 | Loss: 0.00041282
Iteration 18/25 | Loss: 0.00041282
Iteration 19/25 | Loss: 0.00041282
Iteration 20/25 | Loss: 0.00041282
Iteration 21/25 | Loss: 0.00041282
Iteration 22/25 | Loss: 0.00041282
Iteration 23/25 | Loss: 0.00041282
Iteration 24/25 | Loss: 0.00041282
Iteration 25/25 | Loss: 0.00041282
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0004128220898564905, 0.0004128220898564905, 0.0004128220898564905, 0.0004128220898564905, 0.0004128220898564905]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004128220898564905

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041282
Iteration 2/1000 | Loss: 0.00003632
Iteration 3/1000 | Loss: 0.00002604
Iteration 4/1000 | Loss: 0.00002410
Iteration 5/1000 | Loss: 0.00002317
Iteration 6/1000 | Loss: 0.00002244
Iteration 7/1000 | Loss: 0.00002190
Iteration 8/1000 | Loss: 0.00002153
Iteration 9/1000 | Loss: 0.00002126
Iteration 10/1000 | Loss: 0.00002105
Iteration 11/1000 | Loss: 0.00002087
Iteration 12/1000 | Loss: 0.00002070
Iteration 13/1000 | Loss: 0.00002063
Iteration 14/1000 | Loss: 0.00002059
Iteration 15/1000 | Loss: 0.00002057
Iteration 16/1000 | Loss: 0.00002054
Iteration 17/1000 | Loss: 0.00002050
Iteration 18/1000 | Loss: 0.00002047
Iteration 19/1000 | Loss: 0.00002046
Iteration 20/1000 | Loss: 0.00002046
Iteration 21/1000 | Loss: 0.00002045
Iteration 22/1000 | Loss: 0.00002044
Iteration 23/1000 | Loss: 0.00002043
Iteration 24/1000 | Loss: 0.00002038
Iteration 25/1000 | Loss: 0.00002038
Iteration 26/1000 | Loss: 0.00002036
Iteration 27/1000 | Loss: 0.00002035
Iteration 28/1000 | Loss: 0.00002034
Iteration 29/1000 | Loss: 0.00025559
Iteration 30/1000 | Loss: 0.00002444
Iteration 31/1000 | Loss: 0.00002288
Iteration 32/1000 | Loss: 0.00002212
Iteration 33/1000 | Loss: 0.00002168
Iteration 34/1000 | Loss: 0.00002143
Iteration 35/1000 | Loss: 0.00025358
Iteration 36/1000 | Loss: 0.00003347
Iteration 37/1000 | Loss: 0.00002500
Iteration 38/1000 | Loss: 0.00002252
Iteration 39/1000 | Loss: 0.00002130
Iteration 40/1000 | Loss: 0.00002063
Iteration 41/1000 | Loss: 0.00002023
Iteration 42/1000 | Loss: 0.00002020
Iteration 43/1000 | Loss: 0.00002019
Iteration 44/1000 | Loss: 0.00002015
Iteration 45/1000 | Loss: 0.00002013
Iteration 46/1000 | Loss: 0.00002010
Iteration 47/1000 | Loss: 0.00001995
Iteration 48/1000 | Loss: 0.00001994
Iteration 49/1000 | Loss: 0.00001994
Iteration 50/1000 | Loss: 0.00001993
Iteration 51/1000 | Loss: 0.00001993
Iteration 52/1000 | Loss: 0.00001992
Iteration 53/1000 | Loss: 0.00001992
Iteration 54/1000 | Loss: 0.00001991
Iteration 55/1000 | Loss: 0.00001991
Iteration 56/1000 | Loss: 0.00001991
Iteration 57/1000 | Loss: 0.00001990
Iteration 58/1000 | Loss: 0.00001990
Iteration 59/1000 | Loss: 0.00001990
Iteration 60/1000 | Loss: 0.00001989
Iteration 61/1000 | Loss: 0.00001989
Iteration 62/1000 | Loss: 0.00001986
Iteration 63/1000 | Loss: 0.00001984
Iteration 64/1000 | Loss: 0.00001983
Iteration 65/1000 | Loss: 0.00001983
Iteration 66/1000 | Loss: 0.00001983
Iteration 67/1000 | Loss: 0.00001983
Iteration 68/1000 | Loss: 0.00001982
Iteration 69/1000 | Loss: 0.00001982
Iteration 70/1000 | Loss: 0.00001982
Iteration 71/1000 | Loss: 0.00001979
Iteration 72/1000 | Loss: 0.00001979
Iteration 73/1000 | Loss: 0.00001979
Iteration 74/1000 | Loss: 0.00001979
Iteration 75/1000 | Loss: 0.00001979
Iteration 76/1000 | Loss: 0.00001978
Iteration 77/1000 | Loss: 0.00001978
Iteration 78/1000 | Loss: 0.00001978
Iteration 79/1000 | Loss: 0.00001978
Iteration 80/1000 | Loss: 0.00001978
Iteration 81/1000 | Loss: 0.00001977
Iteration 82/1000 | Loss: 0.00001977
Iteration 83/1000 | Loss: 0.00001977
Iteration 84/1000 | Loss: 0.00001977
Iteration 85/1000 | Loss: 0.00001977
Iteration 86/1000 | Loss: 0.00001977
Iteration 87/1000 | Loss: 0.00001977
Iteration 88/1000 | Loss: 0.00001977
Iteration 89/1000 | Loss: 0.00001977
Iteration 90/1000 | Loss: 0.00001976
Iteration 91/1000 | Loss: 0.00001976
Iteration 92/1000 | Loss: 0.00001976
Iteration 93/1000 | Loss: 0.00001976
Iteration 94/1000 | Loss: 0.00001976
Iteration 95/1000 | Loss: 0.00001975
Iteration 96/1000 | Loss: 0.00001975
Iteration 97/1000 | Loss: 0.00001975
Iteration 98/1000 | Loss: 0.00001975
Iteration 99/1000 | Loss: 0.00001975
Iteration 100/1000 | Loss: 0.00001975
Iteration 101/1000 | Loss: 0.00001974
Iteration 102/1000 | Loss: 0.00001974
Iteration 103/1000 | Loss: 0.00001974
Iteration 104/1000 | Loss: 0.00001974
Iteration 105/1000 | Loss: 0.00001974
Iteration 106/1000 | Loss: 0.00001974
Iteration 107/1000 | Loss: 0.00001974
Iteration 108/1000 | Loss: 0.00001974
Iteration 109/1000 | Loss: 0.00001974
Iteration 110/1000 | Loss: 0.00001974
Iteration 111/1000 | Loss: 0.00001974
Iteration 112/1000 | Loss: 0.00001974
Iteration 113/1000 | Loss: 0.00001974
Iteration 114/1000 | Loss: 0.00001974
Iteration 115/1000 | Loss: 0.00001974
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 115. Stopping optimization.
Last 5 losses: [1.9738246919587255e-05, 1.9738246919587255e-05, 1.9738246919587255e-05, 1.9738246919587255e-05, 1.9738246919587255e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9738246919587255e-05

Optimization complete. Final v2v error: 3.5985569953918457 mm

Highest mean error: 8.778511047363281 mm for frame 228

Lowest mean error: 3.1382815837860107 mm for frame 112

Saving results

Total time: 91.33071303367615
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1027/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1027.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1027
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00797022
Iteration 2/25 | Loss: 0.00131500
Iteration 3/25 | Loss: 0.00096779
Iteration 4/25 | Loss: 0.00088181
Iteration 5/25 | Loss: 0.00085490
Iteration 6/25 | Loss: 0.00084691
Iteration 7/25 | Loss: 0.00084382
Iteration 8/25 | Loss: 0.00084280
Iteration 9/25 | Loss: 0.00084256
Iteration 10/25 | Loss: 0.00084255
Iteration 11/25 | Loss: 0.00084255
Iteration 12/25 | Loss: 0.00084255
Iteration 13/25 | Loss: 0.00084255
Iteration 14/25 | Loss: 0.00084255
Iteration 15/25 | Loss: 0.00084255
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008425459964200854, 0.0008425459964200854, 0.0008425459964200854, 0.0008425459964200854, 0.0008425459964200854]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008425459964200854

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49304283
Iteration 2/25 | Loss: 0.00041420
Iteration 3/25 | Loss: 0.00041419
Iteration 4/25 | Loss: 0.00041419
Iteration 5/25 | Loss: 0.00041419
Iteration 6/25 | Loss: 0.00041419
Iteration 7/25 | Loss: 0.00041419
Iteration 8/25 | Loss: 0.00041419
Iteration 9/25 | Loss: 0.00041419
Iteration 10/25 | Loss: 0.00041419
Iteration 11/25 | Loss: 0.00041419
Iteration 12/25 | Loss: 0.00041419
Iteration 13/25 | Loss: 0.00041419
Iteration 14/25 | Loss: 0.00041419
Iteration 15/25 | Loss: 0.00041419
Iteration 16/25 | Loss: 0.00041419
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00041418676846660674, 0.00041418676846660674, 0.00041418676846660674, 0.00041418676846660674, 0.00041418676846660674]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00041418676846660674

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041419
Iteration 2/1000 | Loss: 0.00006736
Iteration 3/1000 | Loss: 0.00004817
Iteration 4/1000 | Loss: 0.00004291
Iteration 5/1000 | Loss: 0.00004012
Iteration 6/1000 | Loss: 0.00003778
Iteration 7/1000 | Loss: 0.00003650
Iteration 8/1000 | Loss: 0.00003540
Iteration 9/1000 | Loss: 0.00003438
Iteration 10/1000 | Loss: 0.00003366
Iteration 11/1000 | Loss: 0.00003316
Iteration 12/1000 | Loss: 0.00003275
Iteration 13/1000 | Loss: 0.00003238
Iteration 14/1000 | Loss: 0.00003218
Iteration 15/1000 | Loss: 0.00003197
Iteration 16/1000 | Loss: 0.00003192
Iteration 17/1000 | Loss: 0.00003188
Iteration 18/1000 | Loss: 0.00003182
Iteration 19/1000 | Loss: 0.00003178
Iteration 20/1000 | Loss: 0.00003176
Iteration 21/1000 | Loss: 0.00003175
Iteration 22/1000 | Loss: 0.00003174
Iteration 23/1000 | Loss: 0.00003174
Iteration 24/1000 | Loss: 0.00003174
Iteration 25/1000 | Loss: 0.00003173
Iteration 26/1000 | Loss: 0.00003173
Iteration 27/1000 | Loss: 0.00003172
Iteration 28/1000 | Loss: 0.00003172
Iteration 29/1000 | Loss: 0.00003172
Iteration 30/1000 | Loss: 0.00003171
Iteration 31/1000 | Loss: 0.00003171
Iteration 32/1000 | Loss: 0.00003170
Iteration 33/1000 | Loss: 0.00003170
Iteration 34/1000 | Loss: 0.00003169
Iteration 35/1000 | Loss: 0.00003169
Iteration 36/1000 | Loss: 0.00003169
Iteration 37/1000 | Loss: 0.00003168
Iteration 38/1000 | Loss: 0.00003168
Iteration 39/1000 | Loss: 0.00003168
Iteration 40/1000 | Loss: 0.00003167
Iteration 41/1000 | Loss: 0.00003167
Iteration 42/1000 | Loss: 0.00003167
Iteration 43/1000 | Loss: 0.00003166
Iteration 44/1000 | Loss: 0.00003166
Iteration 45/1000 | Loss: 0.00003166
Iteration 46/1000 | Loss: 0.00003166
Iteration 47/1000 | Loss: 0.00003165
Iteration 48/1000 | Loss: 0.00003165
Iteration 49/1000 | Loss: 0.00003165
Iteration 50/1000 | Loss: 0.00003165
Iteration 51/1000 | Loss: 0.00003165
Iteration 52/1000 | Loss: 0.00003165
Iteration 53/1000 | Loss: 0.00003164
Iteration 54/1000 | Loss: 0.00003164
Iteration 55/1000 | Loss: 0.00003164
Iteration 56/1000 | Loss: 0.00003164
Iteration 57/1000 | Loss: 0.00003164
Iteration 58/1000 | Loss: 0.00003164
Iteration 59/1000 | Loss: 0.00003163
Iteration 60/1000 | Loss: 0.00003163
Iteration 61/1000 | Loss: 0.00003163
Iteration 62/1000 | Loss: 0.00003163
Iteration 63/1000 | Loss: 0.00003163
Iteration 64/1000 | Loss: 0.00003163
Iteration 65/1000 | Loss: 0.00003162
Iteration 66/1000 | Loss: 0.00003162
Iteration 67/1000 | Loss: 0.00003162
Iteration 68/1000 | Loss: 0.00003161
Iteration 69/1000 | Loss: 0.00003161
Iteration 70/1000 | Loss: 0.00003161
Iteration 71/1000 | Loss: 0.00003160
Iteration 72/1000 | Loss: 0.00003160
Iteration 73/1000 | Loss: 0.00003160
Iteration 74/1000 | Loss: 0.00003160
Iteration 75/1000 | Loss: 0.00003159
Iteration 76/1000 | Loss: 0.00003159
Iteration 77/1000 | Loss: 0.00003159
Iteration 78/1000 | Loss: 0.00003159
Iteration 79/1000 | Loss: 0.00003159
Iteration 80/1000 | Loss: 0.00003158
Iteration 81/1000 | Loss: 0.00003158
Iteration 82/1000 | Loss: 0.00003158
Iteration 83/1000 | Loss: 0.00003158
Iteration 84/1000 | Loss: 0.00003158
Iteration 85/1000 | Loss: 0.00003157
Iteration 86/1000 | Loss: 0.00003157
Iteration 87/1000 | Loss: 0.00003157
Iteration 88/1000 | Loss: 0.00003157
Iteration 89/1000 | Loss: 0.00003157
Iteration 90/1000 | Loss: 0.00003157
Iteration 91/1000 | Loss: 0.00003157
Iteration 92/1000 | Loss: 0.00003157
Iteration 93/1000 | Loss: 0.00003157
Iteration 94/1000 | Loss: 0.00003157
Iteration 95/1000 | Loss: 0.00003156
Iteration 96/1000 | Loss: 0.00003156
Iteration 97/1000 | Loss: 0.00003156
Iteration 98/1000 | Loss: 0.00003156
Iteration 99/1000 | Loss: 0.00003156
Iteration 100/1000 | Loss: 0.00003156
Iteration 101/1000 | Loss: 0.00003155
Iteration 102/1000 | Loss: 0.00003155
Iteration 103/1000 | Loss: 0.00003155
Iteration 104/1000 | Loss: 0.00003155
Iteration 105/1000 | Loss: 0.00003155
Iteration 106/1000 | Loss: 0.00003155
Iteration 107/1000 | Loss: 0.00003155
Iteration 108/1000 | Loss: 0.00003155
Iteration 109/1000 | Loss: 0.00003155
Iteration 110/1000 | Loss: 0.00003155
Iteration 111/1000 | Loss: 0.00003155
Iteration 112/1000 | Loss: 0.00003155
Iteration 113/1000 | Loss: 0.00003155
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [3.1552528525935486e-05, 3.1552528525935486e-05, 3.1552528525935486e-05, 3.1552528525935486e-05, 3.1552528525935486e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.1552528525935486e-05

Optimization complete. Final v2v error: 4.556983470916748 mm

Highest mean error: 6.201225757598877 mm for frame 13

Lowest mean error: 3.5573041439056396 mm for frame 4

Saving results

Total time: 51.20116138458252
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00576349
Iteration 2/25 | Loss: 0.00093292
Iteration 3/25 | Loss: 0.00079079
Iteration 4/25 | Loss: 0.00076379
Iteration 5/25 | Loss: 0.00075936
Iteration 6/25 | Loss: 0.00075780
Iteration 7/25 | Loss: 0.00075749
Iteration 8/25 | Loss: 0.00075749
Iteration 9/25 | Loss: 0.00075749
Iteration 10/25 | Loss: 0.00075749
Iteration 11/25 | Loss: 0.00075749
Iteration 12/25 | Loss: 0.00075749
Iteration 13/25 | Loss: 0.00075749
Iteration 14/25 | Loss: 0.00075749
Iteration 15/25 | Loss: 0.00075749
Iteration 16/25 | Loss: 0.00075749
Iteration 17/25 | Loss: 0.00075749
Iteration 18/25 | Loss: 0.00075749
Iteration 19/25 | Loss: 0.00075749
Iteration 20/25 | Loss: 0.00075749
Iteration 21/25 | Loss: 0.00075749
Iteration 22/25 | Loss: 0.00075749
Iteration 23/25 | Loss: 0.00075749
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.000757486151997, 0.000757486151997, 0.000757486151997, 0.000757486151997, 0.000757486151997]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000757486151997

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59377539
Iteration 2/25 | Loss: 0.00033560
Iteration 3/25 | Loss: 0.00033559
Iteration 4/25 | Loss: 0.00033559
Iteration 5/25 | Loss: 0.00033559
Iteration 6/25 | Loss: 0.00033559
Iteration 7/25 | Loss: 0.00033559
Iteration 8/25 | Loss: 0.00033559
Iteration 9/25 | Loss: 0.00033559
Iteration 10/25 | Loss: 0.00033559
Iteration 11/25 | Loss: 0.00033559
Iteration 12/25 | Loss: 0.00033559
Iteration 13/25 | Loss: 0.00033559
Iteration 14/25 | Loss: 0.00033559
Iteration 15/25 | Loss: 0.00033559
Iteration 16/25 | Loss: 0.00033559
Iteration 17/25 | Loss: 0.00033559
Iteration 18/25 | Loss: 0.00033559
Iteration 19/25 | Loss: 0.00033559
Iteration 20/25 | Loss: 0.00033559
Iteration 21/25 | Loss: 0.00033559
Iteration 22/25 | Loss: 0.00033559
Iteration 23/25 | Loss: 0.00033559
Iteration 24/25 | Loss: 0.00033559
Iteration 25/25 | Loss: 0.00033559

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033559
Iteration 2/1000 | Loss: 0.00003204
Iteration 3/1000 | Loss: 0.00001950
Iteration 4/1000 | Loss: 0.00001764
Iteration 5/1000 | Loss: 0.00001672
Iteration 6/1000 | Loss: 0.00001621
Iteration 7/1000 | Loss: 0.00001587
Iteration 8/1000 | Loss: 0.00001574
Iteration 9/1000 | Loss: 0.00001572
Iteration 10/1000 | Loss: 0.00001555
Iteration 11/1000 | Loss: 0.00001552
Iteration 12/1000 | Loss: 0.00001550
Iteration 13/1000 | Loss: 0.00001549
Iteration 14/1000 | Loss: 0.00001543
Iteration 15/1000 | Loss: 0.00001532
Iteration 16/1000 | Loss: 0.00001530
Iteration 17/1000 | Loss: 0.00001529
Iteration 18/1000 | Loss: 0.00001528
Iteration 19/1000 | Loss: 0.00001528
Iteration 20/1000 | Loss: 0.00001523
Iteration 21/1000 | Loss: 0.00001509
Iteration 22/1000 | Loss: 0.00001508
Iteration 23/1000 | Loss: 0.00001500
Iteration 24/1000 | Loss: 0.00001496
Iteration 25/1000 | Loss: 0.00001495
Iteration 26/1000 | Loss: 0.00001495
Iteration 27/1000 | Loss: 0.00001490
Iteration 28/1000 | Loss: 0.00001487
Iteration 29/1000 | Loss: 0.00001487
Iteration 30/1000 | Loss: 0.00001486
Iteration 31/1000 | Loss: 0.00001485
Iteration 32/1000 | Loss: 0.00001485
Iteration 33/1000 | Loss: 0.00001484
Iteration 34/1000 | Loss: 0.00001483
Iteration 35/1000 | Loss: 0.00001483
Iteration 36/1000 | Loss: 0.00001482
Iteration 37/1000 | Loss: 0.00001482
Iteration 38/1000 | Loss: 0.00001481
Iteration 39/1000 | Loss: 0.00001481
Iteration 40/1000 | Loss: 0.00001480
Iteration 41/1000 | Loss: 0.00001480
Iteration 42/1000 | Loss: 0.00001479
Iteration 43/1000 | Loss: 0.00001479
Iteration 44/1000 | Loss: 0.00001479
Iteration 45/1000 | Loss: 0.00001478
Iteration 46/1000 | Loss: 0.00001478
Iteration 47/1000 | Loss: 0.00001478
Iteration 48/1000 | Loss: 0.00001477
Iteration 49/1000 | Loss: 0.00001476
Iteration 50/1000 | Loss: 0.00001475
Iteration 51/1000 | Loss: 0.00001474
Iteration 52/1000 | Loss: 0.00001474
Iteration 53/1000 | Loss: 0.00001473
Iteration 54/1000 | Loss: 0.00001473
Iteration 55/1000 | Loss: 0.00001472
Iteration 56/1000 | Loss: 0.00001471
Iteration 57/1000 | Loss: 0.00001471
Iteration 58/1000 | Loss: 0.00001470
Iteration 59/1000 | Loss: 0.00001470
Iteration 60/1000 | Loss: 0.00001470
Iteration 61/1000 | Loss: 0.00001469
Iteration 62/1000 | Loss: 0.00001469
Iteration 63/1000 | Loss: 0.00001469
Iteration 64/1000 | Loss: 0.00001469
Iteration 65/1000 | Loss: 0.00001469
Iteration 66/1000 | Loss: 0.00001469
Iteration 67/1000 | Loss: 0.00001469
Iteration 68/1000 | Loss: 0.00001469
Iteration 69/1000 | Loss: 0.00001469
Iteration 70/1000 | Loss: 0.00001469
Iteration 71/1000 | Loss: 0.00001469
Iteration 72/1000 | Loss: 0.00001468
Iteration 73/1000 | Loss: 0.00001468
Iteration 74/1000 | Loss: 0.00001468
Iteration 75/1000 | Loss: 0.00001468
Iteration 76/1000 | Loss: 0.00001467
Iteration 77/1000 | Loss: 0.00001467
Iteration 78/1000 | Loss: 0.00001467
Iteration 79/1000 | Loss: 0.00001466
Iteration 80/1000 | Loss: 0.00001466
Iteration 81/1000 | Loss: 0.00001466
Iteration 82/1000 | Loss: 0.00001466
Iteration 83/1000 | Loss: 0.00001466
Iteration 84/1000 | Loss: 0.00001466
Iteration 85/1000 | Loss: 0.00001466
Iteration 86/1000 | Loss: 0.00001466
Iteration 87/1000 | Loss: 0.00001466
Iteration 88/1000 | Loss: 0.00001466
Iteration 89/1000 | Loss: 0.00001466
Iteration 90/1000 | Loss: 0.00001465
Iteration 91/1000 | Loss: 0.00001465
Iteration 92/1000 | Loss: 0.00001465
Iteration 93/1000 | Loss: 0.00001465
Iteration 94/1000 | Loss: 0.00001465
Iteration 95/1000 | Loss: 0.00001465
Iteration 96/1000 | Loss: 0.00001465
Iteration 97/1000 | Loss: 0.00001465
Iteration 98/1000 | Loss: 0.00001465
Iteration 99/1000 | Loss: 0.00001465
Iteration 100/1000 | Loss: 0.00001465
Iteration 101/1000 | Loss: 0.00001465
Iteration 102/1000 | Loss: 0.00001465
Iteration 103/1000 | Loss: 0.00001465
Iteration 104/1000 | Loss: 0.00001465
Iteration 105/1000 | Loss: 0.00001465
Iteration 106/1000 | Loss: 0.00001465
Iteration 107/1000 | Loss: 0.00001465
Iteration 108/1000 | Loss: 0.00001465
Iteration 109/1000 | Loss: 0.00001465
Iteration 110/1000 | Loss: 0.00001465
Iteration 111/1000 | Loss: 0.00001465
Iteration 112/1000 | Loss: 0.00001465
Iteration 113/1000 | Loss: 0.00001465
Iteration 114/1000 | Loss: 0.00001465
Iteration 115/1000 | Loss: 0.00001465
Iteration 116/1000 | Loss: 0.00001465
Iteration 117/1000 | Loss: 0.00001465
Iteration 118/1000 | Loss: 0.00001465
Iteration 119/1000 | Loss: 0.00001465
Iteration 120/1000 | Loss: 0.00001465
Iteration 121/1000 | Loss: 0.00001465
Iteration 122/1000 | Loss: 0.00001465
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [1.4645674127677921e-05, 1.4645674127677921e-05, 1.4645674127677921e-05, 1.4645674127677921e-05, 1.4645674127677921e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4645674127677921e-05

Optimization complete. Final v2v error: 3.260178804397583 mm

Highest mean error: 3.630063772201538 mm for frame 9

Lowest mean error: 3.0191762447357178 mm for frame 98

Saving results

Total time: 35.66634392738342
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1086
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01048763
Iteration 2/25 | Loss: 0.00376231
Iteration 3/25 | Loss: 0.00281117
Iteration 4/25 | Loss: 0.00209615
Iteration 5/25 | Loss: 0.00152763
Iteration 6/25 | Loss: 0.00115674
Iteration 7/25 | Loss: 0.00104012
Iteration 8/25 | Loss: 0.00093164
Iteration 9/25 | Loss: 0.00088177
Iteration 10/25 | Loss: 0.00087126
Iteration 11/25 | Loss: 0.00087055
Iteration 12/25 | Loss: 0.00086785
Iteration 13/25 | Loss: 0.00086220
Iteration 14/25 | Loss: 0.00085955
Iteration 15/25 | Loss: 0.00085912
Iteration 16/25 | Loss: 0.00085898
Iteration 17/25 | Loss: 0.00086535
Iteration 18/25 | Loss: 0.00086851
Iteration 19/25 | Loss: 0.00085930
Iteration 20/25 | Loss: 0.00085437
Iteration 21/25 | Loss: 0.00085050
Iteration 22/25 | Loss: 0.00084942
Iteration 23/25 | Loss: 0.00084913
Iteration 24/25 | Loss: 0.00084908
Iteration 25/25 | Loss: 0.00084908

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46608222
Iteration 2/25 | Loss: 0.00060592
Iteration 3/25 | Loss: 0.00060592
Iteration 4/25 | Loss: 0.00060592
Iteration 5/25 | Loss: 0.00060592
Iteration 6/25 | Loss: 0.00060592
Iteration 7/25 | Loss: 0.00060592
Iteration 8/25 | Loss: 0.00060592
Iteration 9/25 | Loss: 0.00060592
Iteration 10/25 | Loss: 0.00060592
Iteration 11/25 | Loss: 0.00060592
Iteration 12/25 | Loss: 0.00060592
Iteration 13/25 | Loss: 0.00060592
Iteration 14/25 | Loss: 0.00060592
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0006059195729903877, 0.0006059195729903877, 0.0006059195729903877, 0.0006059195729903877, 0.0006059195729903877]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006059195729903877

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060592
Iteration 2/1000 | Loss: 0.00007829
Iteration 3/1000 | Loss: 0.00005742
Iteration 4/1000 | Loss: 0.00005049
Iteration 5/1000 | Loss: 0.00012784
Iteration 6/1000 | Loss: 0.00004226
Iteration 7/1000 | Loss: 0.00007604
Iteration 8/1000 | Loss: 0.00003904
Iteration 9/1000 | Loss: 0.00003786
Iteration 10/1000 | Loss: 0.00159109
Iteration 11/1000 | Loss: 0.00034771
Iteration 12/1000 | Loss: 0.00008321
Iteration 13/1000 | Loss: 0.00004518
Iteration 14/1000 | Loss: 0.00003329
Iteration 15/1000 | Loss: 0.00002729
Iteration 16/1000 | Loss: 0.00002285
Iteration 17/1000 | Loss: 0.00001978
Iteration 18/1000 | Loss: 0.00001842
Iteration 19/1000 | Loss: 0.00001758
Iteration 20/1000 | Loss: 0.00001699
Iteration 21/1000 | Loss: 0.00001650
Iteration 22/1000 | Loss: 0.00001620
Iteration 23/1000 | Loss: 0.00001598
Iteration 24/1000 | Loss: 0.00001581
Iteration 25/1000 | Loss: 0.00001580
Iteration 26/1000 | Loss: 0.00001576
Iteration 27/1000 | Loss: 0.00001575
Iteration 28/1000 | Loss: 0.00001575
Iteration 29/1000 | Loss: 0.00001575
Iteration 30/1000 | Loss: 0.00001574
Iteration 31/1000 | Loss: 0.00001571
Iteration 32/1000 | Loss: 0.00001571
Iteration 33/1000 | Loss: 0.00001570
Iteration 34/1000 | Loss: 0.00001570
Iteration 35/1000 | Loss: 0.00001569
Iteration 36/1000 | Loss: 0.00001568
Iteration 37/1000 | Loss: 0.00001567
Iteration 38/1000 | Loss: 0.00001566
Iteration 39/1000 | Loss: 0.00001566
Iteration 40/1000 | Loss: 0.00001565
Iteration 41/1000 | Loss: 0.00001565
Iteration 42/1000 | Loss: 0.00001564
Iteration 43/1000 | Loss: 0.00001564
Iteration 44/1000 | Loss: 0.00001563
Iteration 45/1000 | Loss: 0.00001562
Iteration 46/1000 | Loss: 0.00001562
Iteration 47/1000 | Loss: 0.00001561
Iteration 48/1000 | Loss: 0.00001561
Iteration 49/1000 | Loss: 0.00001561
Iteration 50/1000 | Loss: 0.00001561
Iteration 51/1000 | Loss: 0.00001560
Iteration 52/1000 | Loss: 0.00001559
Iteration 53/1000 | Loss: 0.00001559
Iteration 54/1000 | Loss: 0.00001559
Iteration 55/1000 | Loss: 0.00001558
Iteration 56/1000 | Loss: 0.00001558
Iteration 57/1000 | Loss: 0.00001558
Iteration 58/1000 | Loss: 0.00001558
Iteration 59/1000 | Loss: 0.00001558
Iteration 60/1000 | Loss: 0.00001558
Iteration 61/1000 | Loss: 0.00001558
Iteration 62/1000 | Loss: 0.00001558
Iteration 63/1000 | Loss: 0.00001558
Iteration 64/1000 | Loss: 0.00001558
Iteration 65/1000 | Loss: 0.00001557
Iteration 66/1000 | Loss: 0.00001557
Iteration 67/1000 | Loss: 0.00001557
Iteration 68/1000 | Loss: 0.00001557
Iteration 69/1000 | Loss: 0.00001557
Iteration 70/1000 | Loss: 0.00001556
Iteration 71/1000 | Loss: 0.00001556
Iteration 72/1000 | Loss: 0.00001556
Iteration 73/1000 | Loss: 0.00001556
Iteration 74/1000 | Loss: 0.00001556
Iteration 75/1000 | Loss: 0.00001556
Iteration 76/1000 | Loss: 0.00001556
Iteration 77/1000 | Loss: 0.00001556
Iteration 78/1000 | Loss: 0.00001555
Iteration 79/1000 | Loss: 0.00001555
Iteration 80/1000 | Loss: 0.00001555
Iteration 81/1000 | Loss: 0.00001555
Iteration 82/1000 | Loss: 0.00001555
Iteration 83/1000 | Loss: 0.00001555
Iteration 84/1000 | Loss: 0.00001555
Iteration 85/1000 | Loss: 0.00001555
Iteration 86/1000 | Loss: 0.00001555
Iteration 87/1000 | Loss: 0.00001555
Iteration 88/1000 | Loss: 0.00001555
Iteration 89/1000 | Loss: 0.00001555
Iteration 90/1000 | Loss: 0.00001555
Iteration 91/1000 | Loss: 0.00001555
Iteration 92/1000 | Loss: 0.00001555
Iteration 93/1000 | Loss: 0.00001555
Iteration 94/1000 | Loss: 0.00001555
Iteration 95/1000 | Loss: 0.00001555
Iteration 96/1000 | Loss: 0.00001554
Iteration 97/1000 | Loss: 0.00001554
Iteration 98/1000 | Loss: 0.00001554
Iteration 99/1000 | Loss: 0.00001554
Iteration 100/1000 | Loss: 0.00001554
Iteration 101/1000 | Loss: 0.00001554
Iteration 102/1000 | Loss: 0.00001554
Iteration 103/1000 | Loss: 0.00001554
Iteration 104/1000 | Loss: 0.00001554
Iteration 105/1000 | Loss: 0.00001554
Iteration 106/1000 | Loss: 0.00001554
Iteration 107/1000 | Loss: 0.00001554
Iteration 108/1000 | Loss: 0.00001554
Iteration 109/1000 | Loss: 0.00001554
Iteration 110/1000 | Loss: 0.00001554
Iteration 111/1000 | Loss: 0.00001554
Iteration 112/1000 | Loss: 0.00001554
Iteration 113/1000 | Loss: 0.00001554
Iteration 114/1000 | Loss: 0.00001553
Iteration 115/1000 | Loss: 0.00001553
Iteration 116/1000 | Loss: 0.00001553
Iteration 117/1000 | Loss: 0.00001552
Iteration 118/1000 | Loss: 0.00001552
Iteration 119/1000 | Loss: 0.00001552
Iteration 120/1000 | Loss: 0.00001552
Iteration 121/1000 | Loss: 0.00001552
Iteration 122/1000 | Loss: 0.00001552
Iteration 123/1000 | Loss: 0.00001552
Iteration 124/1000 | Loss: 0.00001552
Iteration 125/1000 | Loss: 0.00001552
Iteration 126/1000 | Loss: 0.00001552
Iteration 127/1000 | Loss: 0.00001552
Iteration 128/1000 | Loss: 0.00001552
Iteration 129/1000 | Loss: 0.00001551
Iteration 130/1000 | Loss: 0.00001551
Iteration 131/1000 | Loss: 0.00001551
Iteration 132/1000 | Loss: 0.00001551
Iteration 133/1000 | Loss: 0.00001551
Iteration 134/1000 | Loss: 0.00001551
Iteration 135/1000 | Loss: 0.00001551
Iteration 136/1000 | Loss: 0.00001551
Iteration 137/1000 | Loss: 0.00001551
Iteration 138/1000 | Loss: 0.00001551
Iteration 139/1000 | Loss: 0.00001551
Iteration 140/1000 | Loss: 0.00001551
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [1.5511886886088178e-05, 1.5511886886088178e-05, 1.5511886886088178e-05, 1.5511886886088178e-05, 1.5511886886088178e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5511886886088178e-05

Optimization complete. Final v2v error: 3.315168619155884 mm

Highest mean error: 3.51480770111084 mm for frame 16

Lowest mean error: 3.0939762592315674 mm for frame 69

Saving results

Total time: 82.72377061843872
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00475999
Iteration 2/25 | Loss: 0.00092821
Iteration 3/25 | Loss: 0.00079179
Iteration 4/25 | Loss: 0.00077320
Iteration 5/25 | Loss: 0.00076697
Iteration 6/25 | Loss: 0.00076514
Iteration 7/25 | Loss: 0.00076482
Iteration 8/25 | Loss: 0.00076482
Iteration 9/25 | Loss: 0.00076482
Iteration 10/25 | Loss: 0.00076482
Iteration 11/25 | Loss: 0.00076482
Iteration 12/25 | Loss: 0.00076482
Iteration 13/25 | Loss: 0.00076482
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007648183964192867, 0.0007648183964192867, 0.0007648183964192867, 0.0007648183964192867, 0.0007648183964192867]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007648183964192867

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49450171
Iteration 2/25 | Loss: 0.00036997
Iteration 3/25 | Loss: 0.00036996
Iteration 4/25 | Loss: 0.00036996
Iteration 5/25 | Loss: 0.00036996
Iteration 6/25 | Loss: 0.00036996
Iteration 7/25 | Loss: 0.00036996
Iteration 8/25 | Loss: 0.00036996
Iteration 9/25 | Loss: 0.00036996
Iteration 10/25 | Loss: 0.00036996
Iteration 11/25 | Loss: 0.00036996
Iteration 12/25 | Loss: 0.00036996
Iteration 13/25 | Loss: 0.00036996
Iteration 14/25 | Loss: 0.00036996
Iteration 15/25 | Loss: 0.00036996
Iteration 16/25 | Loss: 0.00036996
Iteration 17/25 | Loss: 0.00036996
Iteration 18/25 | Loss: 0.00036996
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003699588996823877, 0.0003699588996823877, 0.0003699588996823877, 0.0003699588996823877, 0.0003699588996823877]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003699588996823877

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00036996
Iteration 2/1000 | Loss: 0.00002999
Iteration 3/1000 | Loss: 0.00002069
Iteration 4/1000 | Loss: 0.00001936
Iteration 5/1000 | Loss: 0.00001832
Iteration 6/1000 | Loss: 0.00001766
Iteration 7/1000 | Loss: 0.00001721
Iteration 8/1000 | Loss: 0.00001691
Iteration 9/1000 | Loss: 0.00001689
Iteration 10/1000 | Loss: 0.00001675
Iteration 11/1000 | Loss: 0.00001660
Iteration 12/1000 | Loss: 0.00001646
Iteration 13/1000 | Loss: 0.00001645
Iteration 14/1000 | Loss: 0.00001639
Iteration 15/1000 | Loss: 0.00001639
Iteration 16/1000 | Loss: 0.00001639
Iteration 17/1000 | Loss: 0.00001639
Iteration 18/1000 | Loss: 0.00001633
Iteration 19/1000 | Loss: 0.00001629
Iteration 20/1000 | Loss: 0.00001629
Iteration 21/1000 | Loss: 0.00001629
Iteration 22/1000 | Loss: 0.00001629
Iteration 23/1000 | Loss: 0.00001629
Iteration 24/1000 | Loss: 0.00001629
Iteration 25/1000 | Loss: 0.00001629
Iteration 26/1000 | Loss: 0.00001629
Iteration 27/1000 | Loss: 0.00001628
Iteration 28/1000 | Loss: 0.00001627
Iteration 29/1000 | Loss: 0.00001626
Iteration 30/1000 | Loss: 0.00001626
Iteration 31/1000 | Loss: 0.00001626
Iteration 32/1000 | Loss: 0.00001625
Iteration 33/1000 | Loss: 0.00001625
Iteration 34/1000 | Loss: 0.00001625
Iteration 35/1000 | Loss: 0.00001624
Iteration 36/1000 | Loss: 0.00001624
Iteration 37/1000 | Loss: 0.00001624
Iteration 38/1000 | Loss: 0.00001624
Iteration 39/1000 | Loss: 0.00001623
Iteration 40/1000 | Loss: 0.00001622
Iteration 41/1000 | Loss: 0.00001622
Iteration 42/1000 | Loss: 0.00001622
Iteration 43/1000 | Loss: 0.00001622
Iteration 44/1000 | Loss: 0.00001622
Iteration 45/1000 | Loss: 0.00001621
Iteration 46/1000 | Loss: 0.00001621
Iteration 47/1000 | Loss: 0.00001620
Iteration 48/1000 | Loss: 0.00001620
Iteration 49/1000 | Loss: 0.00001619
Iteration 50/1000 | Loss: 0.00001619
Iteration 51/1000 | Loss: 0.00001619
Iteration 52/1000 | Loss: 0.00001619
Iteration 53/1000 | Loss: 0.00001619
Iteration 54/1000 | Loss: 0.00001619
Iteration 55/1000 | Loss: 0.00001619
Iteration 56/1000 | Loss: 0.00001618
Iteration 57/1000 | Loss: 0.00001617
Iteration 58/1000 | Loss: 0.00001616
Iteration 59/1000 | Loss: 0.00001616
Iteration 60/1000 | Loss: 0.00001616
Iteration 61/1000 | Loss: 0.00001616
Iteration 62/1000 | Loss: 0.00001616
Iteration 63/1000 | Loss: 0.00001616
Iteration 64/1000 | Loss: 0.00001616
Iteration 65/1000 | Loss: 0.00001616
Iteration 66/1000 | Loss: 0.00001613
Iteration 67/1000 | Loss: 0.00001613
Iteration 68/1000 | Loss: 0.00001613
Iteration 69/1000 | Loss: 0.00001613
Iteration 70/1000 | Loss: 0.00001613
Iteration 71/1000 | Loss: 0.00001613
Iteration 72/1000 | Loss: 0.00001613
Iteration 73/1000 | Loss: 0.00001613
Iteration 74/1000 | Loss: 0.00001613
Iteration 75/1000 | Loss: 0.00001613
Iteration 76/1000 | Loss: 0.00001612
Iteration 77/1000 | Loss: 0.00001612
Iteration 78/1000 | Loss: 0.00001612
Iteration 79/1000 | Loss: 0.00001610
Iteration 80/1000 | Loss: 0.00001609
Iteration 81/1000 | Loss: 0.00001608
Iteration 82/1000 | Loss: 0.00001608
Iteration 83/1000 | Loss: 0.00001607
Iteration 84/1000 | Loss: 0.00001607
Iteration 85/1000 | Loss: 0.00001607
Iteration 86/1000 | Loss: 0.00001607
Iteration 87/1000 | Loss: 0.00001606
Iteration 88/1000 | Loss: 0.00001606
Iteration 89/1000 | Loss: 0.00001606
Iteration 90/1000 | Loss: 0.00001606
Iteration 91/1000 | Loss: 0.00001604
Iteration 92/1000 | Loss: 0.00001604
Iteration 93/1000 | Loss: 0.00001604
Iteration 94/1000 | Loss: 0.00001603
Iteration 95/1000 | Loss: 0.00001603
Iteration 96/1000 | Loss: 0.00001603
Iteration 97/1000 | Loss: 0.00001603
Iteration 98/1000 | Loss: 0.00001603
Iteration 99/1000 | Loss: 0.00001603
Iteration 100/1000 | Loss: 0.00001603
Iteration 101/1000 | Loss: 0.00001603
Iteration 102/1000 | Loss: 0.00001603
Iteration 103/1000 | Loss: 0.00001603
Iteration 104/1000 | Loss: 0.00001602
Iteration 105/1000 | Loss: 0.00001602
Iteration 106/1000 | Loss: 0.00001602
Iteration 107/1000 | Loss: 0.00001602
Iteration 108/1000 | Loss: 0.00001602
Iteration 109/1000 | Loss: 0.00001602
Iteration 110/1000 | Loss: 0.00001602
Iteration 111/1000 | Loss: 0.00001602
Iteration 112/1000 | Loss: 0.00001601
Iteration 113/1000 | Loss: 0.00001600
Iteration 114/1000 | Loss: 0.00001600
Iteration 115/1000 | Loss: 0.00001600
Iteration 116/1000 | Loss: 0.00001600
Iteration 117/1000 | Loss: 0.00001600
Iteration 118/1000 | Loss: 0.00001600
Iteration 119/1000 | Loss: 0.00001600
Iteration 120/1000 | Loss: 0.00001600
Iteration 121/1000 | Loss: 0.00001600
Iteration 122/1000 | Loss: 0.00001600
Iteration 123/1000 | Loss: 0.00001600
Iteration 124/1000 | Loss: 0.00001600
Iteration 125/1000 | Loss: 0.00001599
Iteration 126/1000 | Loss: 0.00001599
Iteration 127/1000 | Loss: 0.00001599
Iteration 128/1000 | Loss: 0.00001599
Iteration 129/1000 | Loss: 0.00001599
Iteration 130/1000 | Loss: 0.00001599
Iteration 131/1000 | Loss: 0.00001599
Iteration 132/1000 | Loss: 0.00001599
Iteration 133/1000 | Loss: 0.00001599
Iteration 134/1000 | Loss: 0.00001599
Iteration 135/1000 | Loss: 0.00001599
Iteration 136/1000 | Loss: 0.00001598
Iteration 137/1000 | Loss: 0.00001598
Iteration 138/1000 | Loss: 0.00001598
Iteration 139/1000 | Loss: 0.00001598
Iteration 140/1000 | Loss: 0.00001598
Iteration 141/1000 | Loss: 0.00001598
Iteration 142/1000 | Loss: 0.00001598
Iteration 143/1000 | Loss: 0.00001598
Iteration 144/1000 | Loss: 0.00001598
Iteration 145/1000 | Loss: 0.00001598
Iteration 146/1000 | Loss: 0.00001598
Iteration 147/1000 | Loss: 0.00001598
Iteration 148/1000 | Loss: 0.00001598
Iteration 149/1000 | Loss: 0.00001597
Iteration 150/1000 | Loss: 0.00001597
Iteration 151/1000 | Loss: 0.00001597
Iteration 152/1000 | Loss: 0.00001597
Iteration 153/1000 | Loss: 0.00001597
Iteration 154/1000 | Loss: 0.00001597
Iteration 155/1000 | Loss: 0.00001596
Iteration 156/1000 | Loss: 0.00001596
Iteration 157/1000 | Loss: 0.00001596
Iteration 158/1000 | Loss: 0.00001596
Iteration 159/1000 | Loss: 0.00001596
Iteration 160/1000 | Loss: 0.00001596
Iteration 161/1000 | Loss: 0.00001596
Iteration 162/1000 | Loss: 0.00001596
Iteration 163/1000 | Loss: 0.00001596
Iteration 164/1000 | Loss: 0.00001596
Iteration 165/1000 | Loss: 0.00001596
Iteration 166/1000 | Loss: 0.00001596
Iteration 167/1000 | Loss: 0.00001596
Iteration 168/1000 | Loss: 0.00001596
Iteration 169/1000 | Loss: 0.00001596
Iteration 170/1000 | Loss: 0.00001595
Iteration 171/1000 | Loss: 0.00001595
Iteration 172/1000 | Loss: 0.00001595
Iteration 173/1000 | Loss: 0.00001595
Iteration 174/1000 | Loss: 0.00001595
Iteration 175/1000 | Loss: 0.00001595
Iteration 176/1000 | Loss: 0.00001595
Iteration 177/1000 | Loss: 0.00001595
Iteration 178/1000 | Loss: 0.00001595
Iteration 179/1000 | Loss: 0.00001595
Iteration 180/1000 | Loss: 0.00001594
Iteration 181/1000 | Loss: 0.00001594
Iteration 182/1000 | Loss: 0.00001594
Iteration 183/1000 | Loss: 0.00001594
Iteration 184/1000 | Loss: 0.00001594
Iteration 185/1000 | Loss: 0.00001594
Iteration 186/1000 | Loss: 0.00001594
Iteration 187/1000 | Loss: 0.00001594
Iteration 188/1000 | Loss: 0.00001594
Iteration 189/1000 | Loss: 0.00001594
Iteration 190/1000 | Loss: 0.00001594
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 190. Stopping optimization.
Last 5 losses: [1.593835258972831e-05, 1.593835258972831e-05, 1.593835258972831e-05, 1.593835258972831e-05, 1.593835258972831e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.593835258972831e-05

Optimization complete. Final v2v error: 3.3650360107421875 mm

Highest mean error: 3.8617498874664307 mm for frame 102

Lowest mean error: 2.895446538925171 mm for frame 161

Saving results

Total time: 43.76991677284241
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00377718
Iteration 2/25 | Loss: 0.00132999
Iteration 3/25 | Loss: 0.00089048
Iteration 4/25 | Loss: 0.00077851
Iteration 5/25 | Loss: 0.00075277
Iteration 6/25 | Loss: 0.00074783
Iteration 7/25 | Loss: 0.00074679
Iteration 8/25 | Loss: 0.00074656
Iteration 9/25 | Loss: 0.00074656
Iteration 10/25 | Loss: 0.00074656
Iteration 11/25 | Loss: 0.00074656
Iteration 12/25 | Loss: 0.00074656
Iteration 13/25 | Loss: 0.00074656
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007465569651685655, 0.0007465569651685655, 0.0007465569651685655, 0.0007465569651685655, 0.0007465569651685655]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007465569651685655

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49114537
Iteration 2/25 | Loss: 0.00031056
Iteration 3/25 | Loss: 0.00031056
Iteration 4/25 | Loss: 0.00031056
Iteration 5/25 | Loss: 0.00031056
Iteration 6/25 | Loss: 0.00031056
Iteration 7/25 | Loss: 0.00031056
Iteration 8/25 | Loss: 0.00031056
Iteration 9/25 | Loss: 0.00031056
Iteration 10/25 | Loss: 0.00031056
Iteration 11/25 | Loss: 0.00031056
Iteration 12/25 | Loss: 0.00031056
Iteration 13/25 | Loss: 0.00031056
Iteration 14/25 | Loss: 0.00031056
Iteration 15/25 | Loss: 0.00031056
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00031055891304276884, 0.00031055891304276884, 0.00031055891304276884, 0.00031055891304276884, 0.00031055891304276884]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031055891304276884

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031056
Iteration 2/1000 | Loss: 0.00002862
Iteration 3/1000 | Loss: 0.00002120
Iteration 4/1000 | Loss: 0.00001791
Iteration 5/1000 | Loss: 0.00001589
Iteration 6/1000 | Loss: 0.00001523
Iteration 7/1000 | Loss: 0.00001479
Iteration 8/1000 | Loss: 0.00001436
Iteration 9/1000 | Loss: 0.00001410
Iteration 10/1000 | Loss: 0.00001388
Iteration 11/1000 | Loss: 0.00001369
Iteration 12/1000 | Loss: 0.00001366
Iteration 13/1000 | Loss: 0.00001362
Iteration 14/1000 | Loss: 0.00001355
Iteration 15/1000 | Loss: 0.00001355
Iteration 16/1000 | Loss: 0.00001349
Iteration 17/1000 | Loss: 0.00001348
Iteration 18/1000 | Loss: 0.00001347
Iteration 19/1000 | Loss: 0.00001347
Iteration 20/1000 | Loss: 0.00001346
Iteration 21/1000 | Loss: 0.00001345
Iteration 22/1000 | Loss: 0.00001345
Iteration 23/1000 | Loss: 0.00001345
Iteration 24/1000 | Loss: 0.00001345
Iteration 25/1000 | Loss: 0.00001345
Iteration 26/1000 | Loss: 0.00001344
Iteration 27/1000 | Loss: 0.00001344
Iteration 28/1000 | Loss: 0.00001344
Iteration 29/1000 | Loss: 0.00001344
Iteration 30/1000 | Loss: 0.00001344
Iteration 31/1000 | Loss: 0.00001344
Iteration 32/1000 | Loss: 0.00001344
Iteration 33/1000 | Loss: 0.00001344
Iteration 34/1000 | Loss: 0.00001344
Iteration 35/1000 | Loss: 0.00001343
Iteration 36/1000 | Loss: 0.00001342
Iteration 37/1000 | Loss: 0.00001341
Iteration 38/1000 | Loss: 0.00001341
Iteration 39/1000 | Loss: 0.00001341
Iteration 40/1000 | Loss: 0.00001341
Iteration 41/1000 | Loss: 0.00001341
Iteration 42/1000 | Loss: 0.00001341
Iteration 43/1000 | Loss: 0.00001341
Iteration 44/1000 | Loss: 0.00001341
Iteration 45/1000 | Loss: 0.00001341
Iteration 46/1000 | Loss: 0.00001341
Iteration 47/1000 | Loss: 0.00001340
Iteration 48/1000 | Loss: 0.00001340
Iteration 49/1000 | Loss: 0.00001339
Iteration 50/1000 | Loss: 0.00001339
Iteration 51/1000 | Loss: 0.00001339
Iteration 52/1000 | Loss: 0.00001339
Iteration 53/1000 | Loss: 0.00001339
Iteration 54/1000 | Loss: 0.00001339
Iteration 55/1000 | Loss: 0.00001338
Iteration 56/1000 | Loss: 0.00001338
Iteration 57/1000 | Loss: 0.00001338
Iteration 58/1000 | Loss: 0.00001338
Iteration 59/1000 | Loss: 0.00001338
Iteration 60/1000 | Loss: 0.00001338
Iteration 61/1000 | Loss: 0.00001338
Iteration 62/1000 | Loss: 0.00001338
Iteration 63/1000 | Loss: 0.00001338
Iteration 64/1000 | Loss: 0.00001338
Iteration 65/1000 | Loss: 0.00001338
Iteration 66/1000 | Loss: 0.00001337
Iteration 67/1000 | Loss: 0.00001337
Iteration 68/1000 | Loss: 0.00001337
Iteration 69/1000 | Loss: 0.00001336
Iteration 70/1000 | Loss: 0.00001336
Iteration 71/1000 | Loss: 0.00001336
Iteration 72/1000 | Loss: 0.00001336
Iteration 73/1000 | Loss: 0.00001335
Iteration 74/1000 | Loss: 0.00001335
Iteration 75/1000 | Loss: 0.00001335
Iteration 76/1000 | Loss: 0.00001335
Iteration 77/1000 | Loss: 0.00001335
Iteration 78/1000 | Loss: 0.00001335
Iteration 79/1000 | Loss: 0.00001335
Iteration 80/1000 | Loss: 0.00001335
Iteration 81/1000 | Loss: 0.00001335
Iteration 82/1000 | Loss: 0.00001335
Iteration 83/1000 | Loss: 0.00001335
Iteration 84/1000 | Loss: 0.00001335
Iteration 85/1000 | Loss: 0.00001334
Iteration 86/1000 | Loss: 0.00001334
Iteration 87/1000 | Loss: 0.00001334
Iteration 88/1000 | Loss: 0.00001334
Iteration 89/1000 | Loss: 0.00001334
Iteration 90/1000 | Loss: 0.00001334
Iteration 91/1000 | Loss: 0.00001334
Iteration 92/1000 | Loss: 0.00001334
Iteration 93/1000 | Loss: 0.00001334
Iteration 94/1000 | Loss: 0.00001334
Iteration 95/1000 | Loss: 0.00001334
Iteration 96/1000 | Loss: 0.00001334
Iteration 97/1000 | Loss: 0.00001334
Iteration 98/1000 | Loss: 0.00001334
Iteration 99/1000 | Loss: 0.00001334
Iteration 100/1000 | Loss: 0.00001334
Iteration 101/1000 | Loss: 0.00001334
Iteration 102/1000 | Loss: 0.00001334
Iteration 103/1000 | Loss: 0.00001334
Iteration 104/1000 | Loss: 0.00001334
Iteration 105/1000 | Loss: 0.00001334
Iteration 106/1000 | Loss: 0.00001334
Iteration 107/1000 | Loss: 0.00001334
Iteration 108/1000 | Loss: 0.00001334
Iteration 109/1000 | Loss: 0.00001334
Iteration 110/1000 | Loss: 0.00001334
Iteration 111/1000 | Loss: 0.00001334
Iteration 112/1000 | Loss: 0.00001334
Iteration 113/1000 | Loss: 0.00001334
Iteration 114/1000 | Loss: 0.00001334
Iteration 115/1000 | Loss: 0.00001334
Iteration 116/1000 | Loss: 0.00001334
Iteration 117/1000 | Loss: 0.00001334
Iteration 118/1000 | Loss: 0.00001334
Iteration 119/1000 | Loss: 0.00001334
Iteration 120/1000 | Loss: 0.00001334
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 120. Stopping optimization.
Last 5 losses: [1.3338721146283206e-05, 1.3338721146283206e-05, 1.3338721146283206e-05, 1.3338721146283206e-05, 1.3338721146283206e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3338721146283206e-05

Optimization complete. Final v2v error: 3.135025978088379 mm

Highest mean error: 3.4682939052581787 mm for frame 103

Lowest mean error: 2.926734209060669 mm for frame 24

Saving results

Total time: 34.88252592086792
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1089/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1089.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1089
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00546290
Iteration 2/25 | Loss: 0.00114993
Iteration 3/25 | Loss: 0.00086990
Iteration 4/25 | Loss: 0.00084266
Iteration 5/25 | Loss: 0.00083663
Iteration 6/25 | Loss: 0.00083567
Iteration 7/25 | Loss: 0.00083561
Iteration 8/25 | Loss: 0.00083561
Iteration 9/25 | Loss: 0.00083561
Iteration 10/25 | Loss: 0.00083561
Iteration 11/25 | Loss: 0.00083561
Iteration 12/25 | Loss: 0.00083561
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008356072939932346, 0.0008356072939932346, 0.0008356072939932346, 0.0008356072939932346, 0.0008356072939932346]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008356072939932346

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48131251
Iteration 2/25 | Loss: 0.00033620
Iteration 3/25 | Loss: 0.00033620
Iteration 4/25 | Loss: 0.00033620
Iteration 5/25 | Loss: 0.00033620
Iteration 6/25 | Loss: 0.00033620
Iteration 7/25 | Loss: 0.00033620
Iteration 8/25 | Loss: 0.00033620
Iteration 9/25 | Loss: 0.00033620
Iteration 10/25 | Loss: 0.00033620
Iteration 11/25 | Loss: 0.00033620
Iteration 12/25 | Loss: 0.00033620
Iteration 13/25 | Loss: 0.00033620
Iteration 14/25 | Loss: 0.00033620
Iteration 15/25 | Loss: 0.00033620
Iteration 16/25 | Loss: 0.00033620
Iteration 17/25 | Loss: 0.00033620
Iteration 18/25 | Loss: 0.00033620
Iteration 19/25 | Loss: 0.00033620
Iteration 20/25 | Loss: 0.00033620
Iteration 21/25 | Loss: 0.00033620
Iteration 22/25 | Loss: 0.00033620
Iteration 23/25 | Loss: 0.00033620
Iteration 24/25 | Loss: 0.00033620
Iteration 25/25 | Loss: 0.00033620

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033620
Iteration 2/1000 | Loss: 0.00003417
Iteration 3/1000 | Loss: 0.00002582
Iteration 4/1000 | Loss: 0.00002394
Iteration 5/1000 | Loss: 0.00002285
Iteration 6/1000 | Loss: 0.00002180
Iteration 7/1000 | Loss: 0.00002123
Iteration 8/1000 | Loss: 0.00002083
Iteration 9/1000 | Loss: 0.00002050
Iteration 10/1000 | Loss: 0.00002023
Iteration 11/1000 | Loss: 0.00002003
Iteration 12/1000 | Loss: 0.00001994
Iteration 13/1000 | Loss: 0.00001980
Iteration 14/1000 | Loss: 0.00001978
Iteration 15/1000 | Loss: 0.00001978
Iteration 16/1000 | Loss: 0.00001977
Iteration 17/1000 | Loss: 0.00001977
Iteration 18/1000 | Loss: 0.00001966
Iteration 19/1000 | Loss: 0.00001961
Iteration 20/1000 | Loss: 0.00001955
Iteration 21/1000 | Loss: 0.00001955
Iteration 22/1000 | Loss: 0.00001954
Iteration 23/1000 | Loss: 0.00001954
Iteration 24/1000 | Loss: 0.00001953
Iteration 25/1000 | Loss: 0.00001953
Iteration 26/1000 | Loss: 0.00001951
Iteration 27/1000 | Loss: 0.00001951
Iteration 28/1000 | Loss: 0.00001951
Iteration 29/1000 | Loss: 0.00001950
Iteration 30/1000 | Loss: 0.00001950
Iteration 31/1000 | Loss: 0.00001949
Iteration 32/1000 | Loss: 0.00001948
Iteration 33/1000 | Loss: 0.00001948
Iteration 34/1000 | Loss: 0.00001948
Iteration 35/1000 | Loss: 0.00001947
Iteration 36/1000 | Loss: 0.00001947
Iteration 37/1000 | Loss: 0.00001947
Iteration 38/1000 | Loss: 0.00001947
Iteration 39/1000 | Loss: 0.00001947
Iteration 40/1000 | Loss: 0.00001947
Iteration 41/1000 | Loss: 0.00001947
Iteration 42/1000 | Loss: 0.00001947
Iteration 43/1000 | Loss: 0.00001946
Iteration 44/1000 | Loss: 0.00001946
Iteration 45/1000 | Loss: 0.00001946
Iteration 46/1000 | Loss: 0.00001946
Iteration 47/1000 | Loss: 0.00001946
Iteration 48/1000 | Loss: 0.00001946
Iteration 49/1000 | Loss: 0.00001946
Iteration 50/1000 | Loss: 0.00001946
Iteration 51/1000 | Loss: 0.00001946
Iteration 52/1000 | Loss: 0.00001945
Iteration 53/1000 | Loss: 0.00001945
Iteration 54/1000 | Loss: 0.00001945
Iteration 55/1000 | Loss: 0.00001944
Iteration 56/1000 | Loss: 0.00001944
Iteration 57/1000 | Loss: 0.00001944
Iteration 58/1000 | Loss: 0.00001944
Iteration 59/1000 | Loss: 0.00001944
Iteration 60/1000 | Loss: 0.00001943
Iteration 61/1000 | Loss: 0.00001943
Iteration 62/1000 | Loss: 0.00001942
Iteration 63/1000 | Loss: 0.00001942
Iteration 64/1000 | Loss: 0.00001942
Iteration 65/1000 | Loss: 0.00001942
Iteration 66/1000 | Loss: 0.00001942
Iteration 67/1000 | Loss: 0.00001942
Iteration 68/1000 | Loss: 0.00001942
Iteration 69/1000 | Loss: 0.00001942
Iteration 70/1000 | Loss: 0.00001941
Iteration 71/1000 | Loss: 0.00001941
Iteration 72/1000 | Loss: 0.00001941
Iteration 73/1000 | Loss: 0.00001940
Iteration 74/1000 | Loss: 0.00001940
Iteration 75/1000 | Loss: 0.00001940
Iteration 76/1000 | Loss: 0.00001940
Iteration 77/1000 | Loss: 0.00001940
Iteration 78/1000 | Loss: 0.00001940
Iteration 79/1000 | Loss: 0.00001940
Iteration 80/1000 | Loss: 0.00001940
Iteration 81/1000 | Loss: 0.00001940
Iteration 82/1000 | Loss: 0.00001940
Iteration 83/1000 | Loss: 0.00001940
Iteration 84/1000 | Loss: 0.00001940
Iteration 85/1000 | Loss: 0.00001940
Iteration 86/1000 | Loss: 0.00001940
Iteration 87/1000 | Loss: 0.00001939
Iteration 88/1000 | Loss: 0.00001939
Iteration 89/1000 | Loss: 0.00001939
Iteration 90/1000 | Loss: 0.00001939
Iteration 91/1000 | Loss: 0.00001939
Iteration 92/1000 | Loss: 0.00001939
Iteration 93/1000 | Loss: 0.00001939
Iteration 94/1000 | Loss: 0.00001939
Iteration 95/1000 | Loss: 0.00001939
Iteration 96/1000 | Loss: 0.00001938
Iteration 97/1000 | Loss: 0.00001938
Iteration 98/1000 | Loss: 0.00001938
Iteration 99/1000 | Loss: 0.00001938
Iteration 100/1000 | Loss: 0.00001938
Iteration 101/1000 | Loss: 0.00001938
Iteration 102/1000 | Loss: 0.00001938
Iteration 103/1000 | Loss: 0.00001938
Iteration 104/1000 | Loss: 0.00001938
Iteration 105/1000 | Loss: 0.00001938
Iteration 106/1000 | Loss: 0.00001938
Iteration 107/1000 | Loss: 0.00001937
Iteration 108/1000 | Loss: 0.00001937
Iteration 109/1000 | Loss: 0.00001937
Iteration 110/1000 | Loss: 0.00001937
Iteration 111/1000 | Loss: 0.00001937
Iteration 112/1000 | Loss: 0.00001937
Iteration 113/1000 | Loss: 0.00001937
Iteration 114/1000 | Loss: 0.00001937
Iteration 115/1000 | Loss: 0.00001937
Iteration 116/1000 | Loss: 0.00001937
Iteration 117/1000 | Loss: 0.00001937
Iteration 118/1000 | Loss: 0.00001937
Iteration 119/1000 | Loss: 0.00001936
Iteration 120/1000 | Loss: 0.00001936
Iteration 121/1000 | Loss: 0.00001936
Iteration 122/1000 | Loss: 0.00001936
Iteration 123/1000 | Loss: 0.00001936
Iteration 124/1000 | Loss: 0.00001936
Iteration 125/1000 | Loss: 0.00001936
Iteration 126/1000 | Loss: 0.00001936
Iteration 127/1000 | Loss: 0.00001936
Iteration 128/1000 | Loss: 0.00001936
Iteration 129/1000 | Loss: 0.00001936
Iteration 130/1000 | Loss: 0.00001936
Iteration 131/1000 | Loss: 0.00001936
Iteration 132/1000 | Loss: 0.00001936
Iteration 133/1000 | Loss: 0.00001936
Iteration 134/1000 | Loss: 0.00001936
Iteration 135/1000 | Loss: 0.00001936
Iteration 136/1000 | Loss: 0.00001936
Iteration 137/1000 | Loss: 0.00001935
Iteration 138/1000 | Loss: 0.00001935
Iteration 139/1000 | Loss: 0.00001935
Iteration 140/1000 | Loss: 0.00001935
Iteration 141/1000 | Loss: 0.00001935
Iteration 142/1000 | Loss: 0.00001935
Iteration 143/1000 | Loss: 0.00001935
Iteration 144/1000 | Loss: 0.00001934
Iteration 145/1000 | Loss: 0.00001934
Iteration 146/1000 | Loss: 0.00001934
Iteration 147/1000 | Loss: 0.00001934
Iteration 148/1000 | Loss: 0.00001934
Iteration 149/1000 | Loss: 0.00001934
Iteration 150/1000 | Loss: 0.00001934
Iteration 151/1000 | Loss: 0.00001934
Iteration 152/1000 | Loss: 0.00001934
Iteration 153/1000 | Loss: 0.00001934
Iteration 154/1000 | Loss: 0.00001934
Iteration 155/1000 | Loss: 0.00001934
Iteration 156/1000 | Loss: 0.00001934
Iteration 157/1000 | Loss: 0.00001933
Iteration 158/1000 | Loss: 0.00001933
Iteration 159/1000 | Loss: 0.00001933
Iteration 160/1000 | Loss: 0.00001933
Iteration 161/1000 | Loss: 0.00001933
Iteration 162/1000 | Loss: 0.00001933
Iteration 163/1000 | Loss: 0.00001933
Iteration 164/1000 | Loss: 0.00001932
Iteration 165/1000 | Loss: 0.00001932
Iteration 166/1000 | Loss: 0.00001932
Iteration 167/1000 | Loss: 0.00001932
Iteration 168/1000 | Loss: 0.00001932
Iteration 169/1000 | Loss: 0.00001932
Iteration 170/1000 | Loss: 0.00001931
Iteration 171/1000 | Loss: 0.00001931
Iteration 172/1000 | Loss: 0.00001931
Iteration 173/1000 | Loss: 0.00001931
Iteration 174/1000 | Loss: 0.00001931
Iteration 175/1000 | Loss: 0.00001931
Iteration 176/1000 | Loss: 0.00001931
Iteration 177/1000 | Loss: 0.00001931
Iteration 178/1000 | Loss: 0.00001931
Iteration 179/1000 | Loss: 0.00001931
Iteration 180/1000 | Loss: 0.00001931
Iteration 181/1000 | Loss: 0.00001931
Iteration 182/1000 | Loss: 0.00001931
Iteration 183/1000 | Loss: 0.00001931
Iteration 184/1000 | Loss: 0.00001930
Iteration 185/1000 | Loss: 0.00001930
Iteration 186/1000 | Loss: 0.00001930
Iteration 187/1000 | Loss: 0.00001930
Iteration 188/1000 | Loss: 0.00001930
Iteration 189/1000 | Loss: 0.00001930
Iteration 190/1000 | Loss: 0.00001930
Iteration 191/1000 | Loss: 0.00001930
Iteration 192/1000 | Loss: 0.00001930
Iteration 193/1000 | Loss: 0.00001930
Iteration 194/1000 | Loss: 0.00001930
Iteration 195/1000 | Loss: 0.00001930
Iteration 196/1000 | Loss: 0.00001930
Iteration 197/1000 | Loss: 0.00001930
Iteration 198/1000 | Loss: 0.00001930
Iteration 199/1000 | Loss: 0.00001930
Iteration 200/1000 | Loss: 0.00001930
Iteration 201/1000 | Loss: 0.00001930
Iteration 202/1000 | Loss: 0.00001930
Iteration 203/1000 | Loss: 0.00001930
Iteration 204/1000 | Loss: 0.00001930
Iteration 205/1000 | Loss: 0.00001930
Iteration 206/1000 | Loss: 0.00001930
Iteration 207/1000 | Loss: 0.00001930
Iteration 208/1000 | Loss: 0.00001930
Iteration 209/1000 | Loss: 0.00001930
Iteration 210/1000 | Loss: 0.00001930
Iteration 211/1000 | Loss: 0.00001930
Iteration 212/1000 | Loss: 0.00001930
Iteration 213/1000 | Loss: 0.00001930
Iteration 214/1000 | Loss: 0.00001930
Iteration 215/1000 | Loss: 0.00001930
Iteration 216/1000 | Loss: 0.00001930
Iteration 217/1000 | Loss: 0.00001930
Iteration 218/1000 | Loss: 0.00001930
Iteration 219/1000 | Loss: 0.00001930
Iteration 220/1000 | Loss: 0.00001930
Iteration 221/1000 | Loss: 0.00001930
Iteration 222/1000 | Loss: 0.00001930
Iteration 223/1000 | Loss: 0.00001930
Iteration 224/1000 | Loss: 0.00001930
Iteration 225/1000 | Loss: 0.00001930
Iteration 226/1000 | Loss: 0.00001930
Iteration 227/1000 | Loss: 0.00001930
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 227. Stopping optimization.
Last 5 losses: [1.9296328900964e-05, 1.9296328900964e-05, 1.9296328900964e-05, 1.9296328900964e-05, 1.9296328900964e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9296328900964e-05

Optimization complete. Final v2v error: 3.717705011367798 mm

Highest mean error: 3.9213783740997314 mm for frame 55

Lowest mean error: 3.20135760307312 mm for frame 12

Saving results

Total time: 41.61461782455444
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1036/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1036.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1036
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00465498
Iteration 2/25 | Loss: 0.00115033
Iteration 3/25 | Loss: 0.00085801
Iteration 4/25 | Loss: 0.00079990
Iteration 5/25 | Loss: 0.00078866
Iteration 6/25 | Loss: 0.00078557
Iteration 7/25 | Loss: 0.00078544
Iteration 8/25 | Loss: 0.00078544
Iteration 9/25 | Loss: 0.00078544
Iteration 10/25 | Loss: 0.00078544
Iteration 11/25 | Loss: 0.00078544
Iteration 12/25 | Loss: 0.00078544
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007854432915337384, 0.0007854432915337384, 0.0007854432915337384, 0.0007854432915337384, 0.0007854432915337384]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007854432915337384

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49495709
Iteration 2/25 | Loss: 0.00031222
Iteration 3/25 | Loss: 0.00031221
Iteration 4/25 | Loss: 0.00031221
Iteration 5/25 | Loss: 0.00031221
Iteration 6/25 | Loss: 0.00031221
Iteration 7/25 | Loss: 0.00031221
Iteration 8/25 | Loss: 0.00031221
Iteration 9/25 | Loss: 0.00031221
Iteration 10/25 | Loss: 0.00031221
Iteration 11/25 | Loss: 0.00031221
Iteration 12/25 | Loss: 0.00031221
Iteration 13/25 | Loss: 0.00031221
Iteration 14/25 | Loss: 0.00031221
Iteration 15/25 | Loss: 0.00031221
Iteration 16/25 | Loss: 0.00031221
Iteration 17/25 | Loss: 0.00031221
Iteration 18/25 | Loss: 0.00031221
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003122083144262433, 0.0003122083144262433, 0.0003122083144262433, 0.0003122083144262433, 0.0003122083144262433]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003122083144262433

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031221
Iteration 2/1000 | Loss: 0.00002827
Iteration 3/1000 | Loss: 0.00002115
Iteration 4/1000 | Loss: 0.00001931
Iteration 5/1000 | Loss: 0.00001825
Iteration 6/1000 | Loss: 0.00001756
Iteration 7/1000 | Loss: 0.00001711
Iteration 8/1000 | Loss: 0.00001666
Iteration 9/1000 | Loss: 0.00001636
Iteration 10/1000 | Loss: 0.00001616
Iteration 11/1000 | Loss: 0.00001609
Iteration 12/1000 | Loss: 0.00001600
Iteration 13/1000 | Loss: 0.00001594
Iteration 14/1000 | Loss: 0.00001591
Iteration 15/1000 | Loss: 0.00001589
Iteration 16/1000 | Loss: 0.00001588
Iteration 17/1000 | Loss: 0.00001588
Iteration 18/1000 | Loss: 0.00001588
Iteration 19/1000 | Loss: 0.00001587
Iteration 20/1000 | Loss: 0.00001587
Iteration 21/1000 | Loss: 0.00001583
Iteration 22/1000 | Loss: 0.00001581
Iteration 23/1000 | Loss: 0.00001580
Iteration 24/1000 | Loss: 0.00001579
Iteration 25/1000 | Loss: 0.00001579
Iteration 26/1000 | Loss: 0.00001578
Iteration 27/1000 | Loss: 0.00001577
Iteration 28/1000 | Loss: 0.00001576
Iteration 29/1000 | Loss: 0.00001576
Iteration 30/1000 | Loss: 0.00001575
Iteration 31/1000 | Loss: 0.00001575
Iteration 32/1000 | Loss: 0.00001574
Iteration 33/1000 | Loss: 0.00001572
Iteration 34/1000 | Loss: 0.00001572
Iteration 35/1000 | Loss: 0.00001571
Iteration 36/1000 | Loss: 0.00001570
Iteration 37/1000 | Loss: 0.00001570
Iteration 38/1000 | Loss: 0.00001569
Iteration 39/1000 | Loss: 0.00001569
Iteration 40/1000 | Loss: 0.00001568
Iteration 41/1000 | Loss: 0.00001567
Iteration 42/1000 | Loss: 0.00001566
Iteration 43/1000 | Loss: 0.00001566
Iteration 44/1000 | Loss: 0.00001565
Iteration 45/1000 | Loss: 0.00001565
Iteration 46/1000 | Loss: 0.00001564
Iteration 47/1000 | Loss: 0.00001564
Iteration 48/1000 | Loss: 0.00001564
Iteration 49/1000 | Loss: 0.00001564
Iteration 50/1000 | Loss: 0.00001563
Iteration 51/1000 | Loss: 0.00001562
Iteration 52/1000 | Loss: 0.00001562
Iteration 53/1000 | Loss: 0.00001562
Iteration 54/1000 | Loss: 0.00001561
Iteration 55/1000 | Loss: 0.00001561
Iteration 56/1000 | Loss: 0.00001561
Iteration 57/1000 | Loss: 0.00001560
Iteration 58/1000 | Loss: 0.00001560
Iteration 59/1000 | Loss: 0.00001559
Iteration 60/1000 | Loss: 0.00001559
Iteration 61/1000 | Loss: 0.00001559
Iteration 62/1000 | Loss: 0.00001558
Iteration 63/1000 | Loss: 0.00001558
Iteration 64/1000 | Loss: 0.00001558
Iteration 65/1000 | Loss: 0.00001557
Iteration 66/1000 | Loss: 0.00001557
Iteration 67/1000 | Loss: 0.00001557
Iteration 68/1000 | Loss: 0.00001557
Iteration 69/1000 | Loss: 0.00001556
Iteration 70/1000 | Loss: 0.00001556
Iteration 71/1000 | Loss: 0.00001555
Iteration 72/1000 | Loss: 0.00001555
Iteration 73/1000 | Loss: 0.00001555
Iteration 74/1000 | Loss: 0.00001555
Iteration 75/1000 | Loss: 0.00001555
Iteration 76/1000 | Loss: 0.00001554
Iteration 77/1000 | Loss: 0.00001554
Iteration 78/1000 | Loss: 0.00001554
Iteration 79/1000 | Loss: 0.00001554
Iteration 80/1000 | Loss: 0.00001554
Iteration 81/1000 | Loss: 0.00001553
Iteration 82/1000 | Loss: 0.00001553
Iteration 83/1000 | Loss: 0.00001553
Iteration 84/1000 | Loss: 0.00001553
Iteration 85/1000 | Loss: 0.00001552
Iteration 86/1000 | Loss: 0.00001552
Iteration 87/1000 | Loss: 0.00001552
Iteration 88/1000 | Loss: 0.00001551
Iteration 89/1000 | Loss: 0.00001551
Iteration 90/1000 | Loss: 0.00001551
Iteration 91/1000 | Loss: 0.00001551
Iteration 92/1000 | Loss: 0.00001551
Iteration 93/1000 | Loss: 0.00001550
Iteration 94/1000 | Loss: 0.00001550
Iteration 95/1000 | Loss: 0.00001550
Iteration 96/1000 | Loss: 0.00001550
Iteration 97/1000 | Loss: 0.00001550
Iteration 98/1000 | Loss: 0.00001549
Iteration 99/1000 | Loss: 0.00001549
Iteration 100/1000 | Loss: 0.00001549
Iteration 101/1000 | Loss: 0.00001549
Iteration 102/1000 | Loss: 0.00001549
Iteration 103/1000 | Loss: 0.00001549
Iteration 104/1000 | Loss: 0.00001549
Iteration 105/1000 | Loss: 0.00001549
Iteration 106/1000 | Loss: 0.00001549
Iteration 107/1000 | Loss: 0.00001549
Iteration 108/1000 | Loss: 0.00001549
Iteration 109/1000 | Loss: 0.00001549
Iteration 110/1000 | Loss: 0.00001548
Iteration 111/1000 | Loss: 0.00001548
Iteration 112/1000 | Loss: 0.00001548
Iteration 113/1000 | Loss: 0.00001548
Iteration 114/1000 | Loss: 0.00001548
Iteration 115/1000 | Loss: 0.00001548
Iteration 116/1000 | Loss: 0.00001548
Iteration 117/1000 | Loss: 0.00001548
Iteration 118/1000 | Loss: 0.00001548
Iteration 119/1000 | Loss: 0.00001547
Iteration 120/1000 | Loss: 0.00001547
Iteration 121/1000 | Loss: 0.00001547
Iteration 122/1000 | Loss: 0.00001547
Iteration 123/1000 | Loss: 0.00001546
Iteration 124/1000 | Loss: 0.00001546
Iteration 125/1000 | Loss: 0.00001546
Iteration 126/1000 | Loss: 0.00001546
Iteration 127/1000 | Loss: 0.00001546
Iteration 128/1000 | Loss: 0.00001546
Iteration 129/1000 | Loss: 0.00001546
Iteration 130/1000 | Loss: 0.00001546
Iteration 131/1000 | Loss: 0.00001546
Iteration 132/1000 | Loss: 0.00001546
Iteration 133/1000 | Loss: 0.00001545
Iteration 134/1000 | Loss: 0.00001545
Iteration 135/1000 | Loss: 0.00001545
Iteration 136/1000 | Loss: 0.00001545
Iteration 137/1000 | Loss: 0.00001545
Iteration 138/1000 | Loss: 0.00001545
Iteration 139/1000 | Loss: 0.00001545
Iteration 140/1000 | Loss: 0.00001545
Iteration 141/1000 | Loss: 0.00001545
Iteration 142/1000 | Loss: 0.00001545
Iteration 143/1000 | Loss: 0.00001545
Iteration 144/1000 | Loss: 0.00001545
Iteration 145/1000 | Loss: 0.00001545
Iteration 146/1000 | Loss: 0.00001545
Iteration 147/1000 | Loss: 0.00001545
Iteration 148/1000 | Loss: 0.00001545
Iteration 149/1000 | Loss: 0.00001545
Iteration 150/1000 | Loss: 0.00001545
Iteration 151/1000 | Loss: 0.00001545
Iteration 152/1000 | Loss: 0.00001545
Iteration 153/1000 | Loss: 0.00001545
Iteration 154/1000 | Loss: 0.00001545
Iteration 155/1000 | Loss: 0.00001545
Iteration 156/1000 | Loss: 0.00001545
Iteration 157/1000 | Loss: 0.00001545
Iteration 158/1000 | Loss: 0.00001545
Iteration 159/1000 | Loss: 0.00001545
Iteration 160/1000 | Loss: 0.00001545
Iteration 161/1000 | Loss: 0.00001545
Iteration 162/1000 | Loss: 0.00001545
Iteration 163/1000 | Loss: 0.00001545
Iteration 164/1000 | Loss: 0.00001545
Iteration 165/1000 | Loss: 0.00001545
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [1.5449393686139956e-05, 1.5449393686139956e-05, 1.5449393686139956e-05, 1.5449393686139956e-05, 1.5449393686139956e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5449393686139956e-05

Optimization complete. Final v2v error: 3.2733821868896484 mm

Highest mean error: 3.490959882736206 mm for frame 163

Lowest mean error: 2.9616544246673584 mm for frame 147

Saving results

Total time: 42.89068102836609
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1054/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1054.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1054
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00375687
Iteration 2/25 | Loss: 0.00080911
Iteration 3/25 | Loss: 0.00073445
Iteration 4/25 | Loss: 0.00071829
Iteration 5/25 | Loss: 0.00071283
Iteration 6/25 | Loss: 0.00071177
Iteration 7/25 | Loss: 0.00071177
Iteration 8/25 | Loss: 0.00071177
Iteration 9/25 | Loss: 0.00071177
Iteration 10/25 | Loss: 0.00071177
Iteration 11/25 | Loss: 0.00071177
Iteration 12/25 | Loss: 0.00071177
Iteration 13/25 | Loss: 0.00071177
Iteration 14/25 | Loss: 0.00071177
Iteration 15/25 | Loss: 0.00071177
Iteration 16/25 | Loss: 0.00071177
Iteration 17/25 | Loss: 0.00071177
Iteration 18/25 | Loss: 0.00071177
Iteration 19/25 | Loss: 0.00071177
Iteration 20/25 | Loss: 0.00071177
Iteration 21/25 | Loss: 0.00071177
Iteration 22/25 | Loss: 0.00071177
Iteration 23/25 | Loss: 0.00071177
Iteration 24/25 | Loss: 0.00071177
Iteration 25/25 | Loss: 0.00071177

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.02186775
Iteration 2/25 | Loss: 0.00031978
Iteration 3/25 | Loss: 0.00031978
Iteration 4/25 | Loss: 0.00031978
Iteration 5/25 | Loss: 0.00031978
Iteration 6/25 | Loss: 0.00031978
Iteration 7/25 | Loss: 0.00031978
Iteration 8/25 | Loss: 0.00031978
Iteration 9/25 | Loss: 0.00031978
Iteration 10/25 | Loss: 0.00031978
Iteration 11/25 | Loss: 0.00031978
Iteration 12/25 | Loss: 0.00031978
Iteration 13/25 | Loss: 0.00031978
Iteration 14/25 | Loss: 0.00031978
Iteration 15/25 | Loss: 0.00031978
Iteration 16/25 | Loss: 0.00031978
Iteration 17/25 | Loss: 0.00031978
Iteration 18/25 | Loss: 0.00031978
Iteration 19/25 | Loss: 0.00031978
Iteration 20/25 | Loss: 0.00031978
Iteration 21/25 | Loss: 0.00031978
Iteration 22/25 | Loss: 0.00031978
Iteration 23/25 | Loss: 0.00031978
Iteration 24/25 | Loss: 0.00031978
Iteration 25/25 | Loss: 0.00031978

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031978
Iteration 2/1000 | Loss: 0.00002092
Iteration 3/1000 | Loss: 0.00001525
Iteration 4/1000 | Loss: 0.00001442
Iteration 5/1000 | Loss: 0.00001363
Iteration 6/1000 | Loss: 0.00001317
Iteration 7/1000 | Loss: 0.00001295
Iteration 8/1000 | Loss: 0.00001293
Iteration 9/1000 | Loss: 0.00001283
Iteration 10/1000 | Loss: 0.00001262
Iteration 11/1000 | Loss: 0.00001258
Iteration 12/1000 | Loss: 0.00001253
Iteration 13/1000 | Loss: 0.00001253
Iteration 14/1000 | Loss: 0.00001248
Iteration 15/1000 | Loss: 0.00001248
Iteration 16/1000 | Loss: 0.00001247
Iteration 17/1000 | Loss: 0.00001247
Iteration 18/1000 | Loss: 0.00001247
Iteration 19/1000 | Loss: 0.00001246
Iteration 20/1000 | Loss: 0.00001246
Iteration 21/1000 | Loss: 0.00001236
Iteration 22/1000 | Loss: 0.00001232
Iteration 23/1000 | Loss: 0.00001231
Iteration 24/1000 | Loss: 0.00001229
Iteration 25/1000 | Loss: 0.00001228
Iteration 26/1000 | Loss: 0.00001226
Iteration 27/1000 | Loss: 0.00001226
Iteration 28/1000 | Loss: 0.00001225
Iteration 29/1000 | Loss: 0.00001225
Iteration 30/1000 | Loss: 0.00001224
Iteration 31/1000 | Loss: 0.00001222
Iteration 32/1000 | Loss: 0.00001222
Iteration 33/1000 | Loss: 0.00001222
Iteration 34/1000 | Loss: 0.00001222
Iteration 35/1000 | Loss: 0.00001221
Iteration 36/1000 | Loss: 0.00001221
Iteration 37/1000 | Loss: 0.00001221
Iteration 38/1000 | Loss: 0.00001221
Iteration 39/1000 | Loss: 0.00001221
Iteration 40/1000 | Loss: 0.00001220
Iteration 41/1000 | Loss: 0.00001216
Iteration 42/1000 | Loss: 0.00001216
Iteration 43/1000 | Loss: 0.00001215
Iteration 44/1000 | Loss: 0.00001213
Iteration 45/1000 | Loss: 0.00001212
Iteration 46/1000 | Loss: 0.00001211
Iteration 47/1000 | Loss: 0.00001211
Iteration 48/1000 | Loss: 0.00001210
Iteration 49/1000 | Loss: 0.00001209
Iteration 50/1000 | Loss: 0.00001208
Iteration 51/1000 | Loss: 0.00001207
Iteration 52/1000 | Loss: 0.00001206
Iteration 53/1000 | Loss: 0.00001206
Iteration 54/1000 | Loss: 0.00001206
Iteration 55/1000 | Loss: 0.00001202
Iteration 56/1000 | Loss: 0.00001202
Iteration 57/1000 | Loss: 0.00001202
Iteration 58/1000 | Loss: 0.00001201
Iteration 59/1000 | Loss: 0.00001201
Iteration 60/1000 | Loss: 0.00001201
Iteration 61/1000 | Loss: 0.00001200
Iteration 62/1000 | Loss: 0.00001200
Iteration 63/1000 | Loss: 0.00001199
Iteration 64/1000 | Loss: 0.00001199
Iteration 65/1000 | Loss: 0.00001199
Iteration 66/1000 | Loss: 0.00001199
Iteration 67/1000 | Loss: 0.00001199
Iteration 68/1000 | Loss: 0.00001199
Iteration 69/1000 | Loss: 0.00001199
Iteration 70/1000 | Loss: 0.00001199
Iteration 71/1000 | Loss: 0.00001199
Iteration 72/1000 | Loss: 0.00001199
Iteration 73/1000 | Loss: 0.00001199
Iteration 74/1000 | Loss: 0.00001199
Iteration 75/1000 | Loss: 0.00001198
Iteration 76/1000 | Loss: 0.00001198
Iteration 77/1000 | Loss: 0.00001198
Iteration 78/1000 | Loss: 0.00001198
Iteration 79/1000 | Loss: 0.00001198
Iteration 80/1000 | Loss: 0.00001198
Iteration 81/1000 | Loss: 0.00001198
Iteration 82/1000 | Loss: 0.00001198
Iteration 83/1000 | Loss: 0.00001197
Iteration 84/1000 | Loss: 0.00001197
Iteration 85/1000 | Loss: 0.00001197
Iteration 86/1000 | Loss: 0.00001197
Iteration 87/1000 | Loss: 0.00001197
Iteration 88/1000 | Loss: 0.00001197
Iteration 89/1000 | Loss: 0.00001197
Iteration 90/1000 | Loss: 0.00001197
Iteration 91/1000 | Loss: 0.00001197
Iteration 92/1000 | Loss: 0.00001197
Iteration 93/1000 | Loss: 0.00001197
Iteration 94/1000 | Loss: 0.00001197
Iteration 95/1000 | Loss: 0.00001197
Iteration 96/1000 | Loss: 0.00001197
Iteration 97/1000 | Loss: 0.00001197
Iteration 98/1000 | Loss: 0.00001197
Iteration 99/1000 | Loss: 0.00001197
Iteration 100/1000 | Loss: 0.00001197
Iteration 101/1000 | Loss: 0.00001197
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [1.1967999853368383e-05, 1.1967999853368383e-05, 1.1967999853368383e-05, 1.1967999853368383e-05, 1.1967999853368383e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1967999853368383e-05

Optimization complete. Final v2v error: 2.9412267208099365 mm

Highest mean error: 3.0692408084869385 mm for frame 114

Lowest mean error: 2.794844388961792 mm for frame 45

Saving results

Total time: 33.40822649002075
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00349976
Iteration 2/25 | Loss: 0.00076549
Iteration 3/25 | Loss: 0.00068394
Iteration 4/25 | Loss: 0.00066960
Iteration 5/25 | Loss: 0.00066497
Iteration 6/25 | Loss: 0.00066364
Iteration 7/25 | Loss: 0.00066325
Iteration 8/25 | Loss: 0.00066325
Iteration 9/25 | Loss: 0.00066325
Iteration 10/25 | Loss: 0.00066325
Iteration 11/25 | Loss: 0.00066325
Iteration 12/25 | Loss: 0.00066325
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006632537115365267, 0.0006632537115365267, 0.0006632537115365267, 0.0006632537115365267, 0.0006632537115365267]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006632537115365267

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54126203
Iteration 2/25 | Loss: 0.00028757
Iteration 3/25 | Loss: 0.00028757
Iteration 4/25 | Loss: 0.00028757
Iteration 5/25 | Loss: 0.00028757
Iteration 6/25 | Loss: 0.00028757
Iteration 7/25 | Loss: 0.00028757
Iteration 8/25 | Loss: 0.00028757
Iteration 9/25 | Loss: 0.00028757
Iteration 10/25 | Loss: 0.00028757
Iteration 11/25 | Loss: 0.00028756
Iteration 12/25 | Loss: 0.00028756
Iteration 13/25 | Loss: 0.00028756
Iteration 14/25 | Loss: 0.00028756
Iteration 15/25 | Loss: 0.00028756
Iteration 16/25 | Loss: 0.00028756
Iteration 17/25 | Loss: 0.00028756
Iteration 18/25 | Loss: 0.00028756
Iteration 19/25 | Loss: 0.00028756
Iteration 20/25 | Loss: 0.00028756
Iteration 21/25 | Loss: 0.00028756
Iteration 22/25 | Loss: 0.00028756
Iteration 23/25 | Loss: 0.00028756
Iteration 24/25 | Loss: 0.00028756
Iteration 25/25 | Loss: 0.00028756

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028756
Iteration 2/1000 | Loss: 0.00001613
Iteration 3/1000 | Loss: 0.00001206
Iteration 4/1000 | Loss: 0.00001112
Iteration 5/1000 | Loss: 0.00001043
Iteration 6/1000 | Loss: 0.00001000
Iteration 7/1000 | Loss: 0.00000988
Iteration 8/1000 | Loss: 0.00000984
Iteration 9/1000 | Loss: 0.00000984
Iteration 10/1000 | Loss: 0.00000977
Iteration 11/1000 | Loss: 0.00000977
Iteration 12/1000 | Loss: 0.00000976
Iteration 13/1000 | Loss: 0.00000972
Iteration 14/1000 | Loss: 0.00000972
Iteration 15/1000 | Loss: 0.00000972
Iteration 16/1000 | Loss: 0.00000970
Iteration 17/1000 | Loss: 0.00000967
Iteration 18/1000 | Loss: 0.00000965
Iteration 19/1000 | Loss: 0.00000963
Iteration 20/1000 | Loss: 0.00000962
Iteration 21/1000 | Loss: 0.00000957
Iteration 22/1000 | Loss: 0.00000957
Iteration 23/1000 | Loss: 0.00000956
Iteration 24/1000 | Loss: 0.00000955
Iteration 25/1000 | Loss: 0.00000955
Iteration 26/1000 | Loss: 0.00000954
Iteration 27/1000 | Loss: 0.00000952
Iteration 28/1000 | Loss: 0.00000951
Iteration 29/1000 | Loss: 0.00000950
Iteration 30/1000 | Loss: 0.00000949
Iteration 31/1000 | Loss: 0.00000949
Iteration 32/1000 | Loss: 0.00000946
Iteration 33/1000 | Loss: 0.00000946
Iteration 34/1000 | Loss: 0.00000941
Iteration 35/1000 | Loss: 0.00000940
Iteration 36/1000 | Loss: 0.00000938
Iteration 37/1000 | Loss: 0.00000935
Iteration 38/1000 | Loss: 0.00000935
Iteration 39/1000 | Loss: 0.00000934
Iteration 40/1000 | Loss: 0.00000934
Iteration 41/1000 | Loss: 0.00000934
Iteration 42/1000 | Loss: 0.00000932
Iteration 43/1000 | Loss: 0.00000932
Iteration 44/1000 | Loss: 0.00000932
Iteration 45/1000 | Loss: 0.00000932
Iteration 46/1000 | Loss: 0.00000932
Iteration 47/1000 | Loss: 0.00000931
Iteration 48/1000 | Loss: 0.00000931
Iteration 49/1000 | Loss: 0.00000930
Iteration 50/1000 | Loss: 0.00000930
Iteration 51/1000 | Loss: 0.00000930
Iteration 52/1000 | Loss: 0.00000930
Iteration 53/1000 | Loss: 0.00000929
Iteration 54/1000 | Loss: 0.00000929
Iteration 55/1000 | Loss: 0.00000929
Iteration 56/1000 | Loss: 0.00000928
Iteration 57/1000 | Loss: 0.00000928
Iteration 58/1000 | Loss: 0.00000928
Iteration 59/1000 | Loss: 0.00000927
Iteration 60/1000 | Loss: 0.00000927
Iteration 61/1000 | Loss: 0.00000927
Iteration 62/1000 | Loss: 0.00000927
Iteration 63/1000 | Loss: 0.00000927
Iteration 64/1000 | Loss: 0.00000927
Iteration 65/1000 | Loss: 0.00000926
Iteration 66/1000 | Loss: 0.00000926
Iteration 67/1000 | Loss: 0.00000926
Iteration 68/1000 | Loss: 0.00000925
Iteration 69/1000 | Loss: 0.00000925
Iteration 70/1000 | Loss: 0.00000925
Iteration 71/1000 | Loss: 0.00000925
Iteration 72/1000 | Loss: 0.00000925
Iteration 73/1000 | Loss: 0.00000924
Iteration 74/1000 | Loss: 0.00000924
Iteration 75/1000 | Loss: 0.00000924
Iteration 76/1000 | Loss: 0.00000923
Iteration 77/1000 | Loss: 0.00000922
Iteration 78/1000 | Loss: 0.00000922
Iteration 79/1000 | Loss: 0.00000922
Iteration 80/1000 | Loss: 0.00000922
Iteration 81/1000 | Loss: 0.00000922
Iteration 82/1000 | Loss: 0.00000922
Iteration 83/1000 | Loss: 0.00000922
Iteration 84/1000 | Loss: 0.00000922
Iteration 85/1000 | Loss: 0.00000922
Iteration 86/1000 | Loss: 0.00000922
Iteration 87/1000 | Loss: 0.00000922
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 87. Stopping optimization.
Last 5 losses: [9.21603714232333e-06, 9.21603714232333e-06, 9.21603714232333e-06, 9.21603714232333e-06, 9.21603714232333e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.21603714232333e-06

Optimization complete. Final v2v error: 2.609022378921509 mm

Highest mean error: 2.8541698455810547 mm for frame 131

Lowest mean error: 2.536447286605835 mm for frame 0

Saving results

Total time: 30.552522897720337
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1053/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1053.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1053
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00854439
Iteration 2/25 | Loss: 0.00117080
Iteration 3/25 | Loss: 0.00080717
Iteration 4/25 | Loss: 0.00076637
Iteration 5/25 | Loss: 0.00074605
Iteration 6/25 | Loss: 0.00073951
Iteration 7/25 | Loss: 0.00073475
Iteration 8/25 | Loss: 0.00073408
Iteration 9/25 | Loss: 0.00073246
Iteration 10/25 | Loss: 0.00073244
Iteration 11/25 | Loss: 0.00073173
Iteration 12/25 | Loss: 0.00073664
Iteration 13/25 | Loss: 0.00073469
Iteration 14/25 | Loss: 0.00073554
Iteration 15/25 | Loss: 0.00073272
Iteration 16/25 | Loss: 0.00073225
Iteration 17/25 | Loss: 0.00073163
Iteration 18/25 | Loss: 0.00073140
Iteration 19/25 | Loss: 0.00073109
Iteration 20/25 | Loss: 0.00073099
Iteration 21/25 | Loss: 0.00073097
Iteration 22/25 | Loss: 0.00073096
Iteration 23/25 | Loss: 0.00073096
Iteration 24/25 | Loss: 0.00073096
Iteration 25/25 | Loss: 0.00073096

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.81742954
Iteration 2/25 | Loss: 0.00035536
Iteration 3/25 | Loss: 0.00035535
Iteration 4/25 | Loss: 0.00035535
Iteration 5/25 | Loss: 0.00035535
Iteration 6/25 | Loss: 0.00035535
Iteration 7/25 | Loss: 0.00035535
Iteration 8/25 | Loss: 0.00035121
Iteration 9/25 | Loss: 0.00035121
Iteration 10/25 | Loss: 0.00035121
Iteration 11/25 | Loss: 0.00035121
Iteration 12/25 | Loss: 0.00035121
Iteration 13/25 | Loss: 0.00035121
Iteration 14/25 | Loss: 0.00035121
Iteration 15/25 | Loss: 0.00035121
Iteration 16/25 | Loss: 0.00035121
Iteration 17/25 | Loss: 0.00035121
Iteration 18/25 | Loss: 0.00035121
Iteration 19/25 | Loss: 0.00035121
Iteration 20/25 | Loss: 0.00035121
Iteration 21/25 | Loss: 0.00035121
Iteration 22/25 | Loss: 0.00035121
Iteration 23/25 | Loss: 0.00035121
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0003512108523864299, 0.0003512108523864299, 0.0003512108523864299, 0.0003512108523864299, 0.0003512108523864299]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003512108523864299

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035121
Iteration 2/1000 | Loss: 0.00002457
Iteration 3/1000 | Loss: 0.00001529
Iteration 4/1000 | Loss: 0.00001583
Iteration 5/1000 | Loss: 0.00001362
Iteration 6/1000 | Loss: 0.00001435
Iteration 7/1000 | Loss: 0.00001336
Iteration 8/1000 | Loss: 0.00001565
Iteration 9/1000 | Loss: 0.00001287
Iteration 10/1000 | Loss: 0.00001274
Iteration 11/1000 | Loss: 0.00001263
Iteration 12/1000 | Loss: 0.00001253
Iteration 13/1000 | Loss: 0.00001253
Iteration 14/1000 | Loss: 0.00001248
Iteration 15/1000 | Loss: 0.00001248
Iteration 16/1000 | Loss: 0.00001277
Iteration 17/1000 | Loss: 0.00001234
Iteration 18/1000 | Loss: 0.00001233
Iteration 19/1000 | Loss: 0.00001233
Iteration 20/1000 | Loss: 0.00001233
Iteration 21/1000 | Loss: 0.00001232
Iteration 22/1000 | Loss: 0.00001232
Iteration 23/1000 | Loss: 0.00001232
Iteration 24/1000 | Loss: 0.00001229
Iteration 25/1000 | Loss: 0.00001221
Iteration 26/1000 | Loss: 0.00001300
Iteration 27/1000 | Loss: 0.00001283
Iteration 28/1000 | Loss: 0.00001205
Iteration 29/1000 | Loss: 0.00001205
Iteration 30/1000 | Loss: 0.00001204
Iteration 31/1000 | Loss: 0.00001204
Iteration 32/1000 | Loss: 0.00001204
Iteration 33/1000 | Loss: 0.00001308
Iteration 34/1000 | Loss: 0.00001207
Iteration 35/1000 | Loss: 0.00001200
Iteration 36/1000 | Loss: 0.00001200
Iteration 37/1000 | Loss: 0.00001200
Iteration 38/1000 | Loss: 0.00001200
Iteration 39/1000 | Loss: 0.00001199
Iteration 40/1000 | Loss: 0.00001199
Iteration 41/1000 | Loss: 0.00001199
Iteration 42/1000 | Loss: 0.00001199
Iteration 43/1000 | Loss: 0.00001199
Iteration 44/1000 | Loss: 0.00001257
Iteration 45/1000 | Loss: 0.00001193
Iteration 46/1000 | Loss: 0.00001193
Iteration 47/1000 | Loss: 0.00001193
Iteration 48/1000 | Loss: 0.00001193
Iteration 49/1000 | Loss: 0.00001193
Iteration 50/1000 | Loss: 0.00001193
Iteration 51/1000 | Loss: 0.00001193
Iteration 52/1000 | Loss: 0.00001193
Iteration 53/1000 | Loss: 0.00001193
Iteration 54/1000 | Loss: 0.00001193
Iteration 55/1000 | Loss: 0.00001193
Iteration 56/1000 | Loss: 0.00001193
Iteration 57/1000 | Loss: 0.00001193
Iteration 58/1000 | Loss: 0.00001193
Iteration 59/1000 | Loss: 0.00001193
Iteration 60/1000 | Loss: 0.00001193
Iteration 61/1000 | Loss: 0.00001193
Iteration 62/1000 | Loss: 0.00001193
Iteration 63/1000 | Loss: 0.00001193
Iteration 64/1000 | Loss: 0.00001193
Iteration 65/1000 | Loss: 0.00001193
Iteration 66/1000 | Loss: 0.00001193
Iteration 67/1000 | Loss: 0.00001193
Iteration 68/1000 | Loss: 0.00001193
Iteration 69/1000 | Loss: 0.00001193
Iteration 70/1000 | Loss: 0.00001193
Iteration 71/1000 | Loss: 0.00001193
Iteration 72/1000 | Loss: 0.00001193
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [1.1927930245292373e-05, 1.1927930245292373e-05, 1.1927930245292373e-05, 1.1927930245292373e-05, 1.1927930245292373e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1927930245292373e-05

Optimization complete. Final v2v error: 2.9221420288085938 mm

Highest mean error: 8.994110107421875 mm for frame 22

Lowest mean error: 2.5193235874176025 mm for frame 20

Saving results

Total time: 72.53100252151489
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1037/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1037.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1037
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00399210
Iteration 2/25 | Loss: 0.00090413
Iteration 3/25 | Loss: 0.00074010
Iteration 4/25 | Loss: 0.00072052
Iteration 5/25 | Loss: 0.00071505
Iteration 6/25 | Loss: 0.00071367
Iteration 7/25 | Loss: 0.00071367
Iteration 8/25 | Loss: 0.00071367
Iteration 9/25 | Loss: 0.00071367
Iteration 10/25 | Loss: 0.00071367
Iteration 11/25 | Loss: 0.00071367
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.000713671266566962, 0.000713671266566962, 0.000713671266566962, 0.000713671266566962, 0.000713671266566962]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000713671266566962

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46781194
Iteration 2/25 | Loss: 0.00027882
Iteration 3/25 | Loss: 0.00027882
Iteration 4/25 | Loss: 0.00027882
Iteration 5/25 | Loss: 0.00027882
Iteration 6/25 | Loss: 0.00027882
Iteration 7/25 | Loss: 0.00027882
Iteration 8/25 | Loss: 0.00027882
Iteration 9/25 | Loss: 0.00027882
Iteration 10/25 | Loss: 0.00027882
Iteration 11/25 | Loss: 0.00027882
Iteration 12/25 | Loss: 0.00027881
Iteration 13/25 | Loss: 0.00027881
Iteration 14/25 | Loss: 0.00027882
Iteration 15/25 | Loss: 0.00027882
Iteration 16/25 | Loss: 0.00027881
Iteration 17/25 | Loss: 0.00027882
Iteration 18/25 | Loss: 0.00027881
Iteration 19/25 | Loss: 0.00027881
Iteration 20/25 | Loss: 0.00027882
Iteration 21/25 | Loss: 0.00027881
Iteration 22/25 | Loss: 0.00027881
Iteration 23/25 | Loss: 0.00027881
Iteration 24/25 | Loss: 0.00027882
Iteration 25/25 | Loss: 0.00027881

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027881
Iteration 2/1000 | Loss: 0.00002522
Iteration 3/1000 | Loss: 0.00001976
Iteration 4/1000 | Loss: 0.00001810
Iteration 5/1000 | Loss: 0.00001661
Iteration 6/1000 | Loss: 0.00001593
Iteration 7/1000 | Loss: 0.00001547
Iteration 8/1000 | Loss: 0.00001524
Iteration 9/1000 | Loss: 0.00001514
Iteration 10/1000 | Loss: 0.00001512
Iteration 11/1000 | Loss: 0.00001487
Iteration 12/1000 | Loss: 0.00001478
Iteration 13/1000 | Loss: 0.00001471
Iteration 14/1000 | Loss: 0.00001460
Iteration 15/1000 | Loss: 0.00001458
Iteration 16/1000 | Loss: 0.00001458
Iteration 17/1000 | Loss: 0.00001456
Iteration 18/1000 | Loss: 0.00001447
Iteration 19/1000 | Loss: 0.00001444
Iteration 20/1000 | Loss: 0.00001443
Iteration 21/1000 | Loss: 0.00001442
Iteration 22/1000 | Loss: 0.00001442
Iteration 23/1000 | Loss: 0.00001441
Iteration 24/1000 | Loss: 0.00001440
Iteration 25/1000 | Loss: 0.00001440
Iteration 26/1000 | Loss: 0.00001439
Iteration 27/1000 | Loss: 0.00001436
Iteration 28/1000 | Loss: 0.00001436
Iteration 29/1000 | Loss: 0.00001434
Iteration 30/1000 | Loss: 0.00001434
Iteration 31/1000 | Loss: 0.00001433
Iteration 32/1000 | Loss: 0.00001433
Iteration 33/1000 | Loss: 0.00001433
Iteration 34/1000 | Loss: 0.00001433
Iteration 35/1000 | Loss: 0.00001433
Iteration 36/1000 | Loss: 0.00001432
Iteration 37/1000 | Loss: 0.00001432
Iteration 38/1000 | Loss: 0.00001431
Iteration 39/1000 | Loss: 0.00001430
Iteration 40/1000 | Loss: 0.00001430
Iteration 41/1000 | Loss: 0.00001429
Iteration 42/1000 | Loss: 0.00001429
Iteration 43/1000 | Loss: 0.00001428
Iteration 44/1000 | Loss: 0.00001428
Iteration 45/1000 | Loss: 0.00001428
Iteration 46/1000 | Loss: 0.00001427
Iteration 47/1000 | Loss: 0.00001427
Iteration 48/1000 | Loss: 0.00001427
Iteration 49/1000 | Loss: 0.00001426
Iteration 50/1000 | Loss: 0.00001426
Iteration 51/1000 | Loss: 0.00001425
Iteration 52/1000 | Loss: 0.00001424
Iteration 53/1000 | Loss: 0.00001423
Iteration 54/1000 | Loss: 0.00001423
Iteration 55/1000 | Loss: 0.00001422
Iteration 56/1000 | Loss: 0.00001422
Iteration 57/1000 | Loss: 0.00001422
Iteration 58/1000 | Loss: 0.00001422
Iteration 59/1000 | Loss: 0.00001421
Iteration 60/1000 | Loss: 0.00001421
Iteration 61/1000 | Loss: 0.00001421
Iteration 62/1000 | Loss: 0.00001420
Iteration 63/1000 | Loss: 0.00001419
Iteration 64/1000 | Loss: 0.00001418
Iteration 65/1000 | Loss: 0.00001418
Iteration 66/1000 | Loss: 0.00001418
Iteration 67/1000 | Loss: 0.00001417
Iteration 68/1000 | Loss: 0.00001417
Iteration 69/1000 | Loss: 0.00001417
Iteration 70/1000 | Loss: 0.00001416
Iteration 71/1000 | Loss: 0.00001416
Iteration 72/1000 | Loss: 0.00001416
Iteration 73/1000 | Loss: 0.00001416
Iteration 74/1000 | Loss: 0.00001416
Iteration 75/1000 | Loss: 0.00001415
Iteration 76/1000 | Loss: 0.00001415
Iteration 77/1000 | Loss: 0.00001415
Iteration 78/1000 | Loss: 0.00001415
Iteration 79/1000 | Loss: 0.00001415
Iteration 80/1000 | Loss: 0.00001415
Iteration 81/1000 | Loss: 0.00001415
Iteration 82/1000 | Loss: 0.00001415
Iteration 83/1000 | Loss: 0.00001415
Iteration 84/1000 | Loss: 0.00001414
Iteration 85/1000 | Loss: 0.00001414
Iteration 86/1000 | Loss: 0.00001414
Iteration 87/1000 | Loss: 0.00001414
Iteration 88/1000 | Loss: 0.00001414
Iteration 89/1000 | Loss: 0.00001414
Iteration 90/1000 | Loss: 0.00001414
Iteration 91/1000 | Loss: 0.00001414
Iteration 92/1000 | Loss: 0.00001413
Iteration 93/1000 | Loss: 0.00001413
Iteration 94/1000 | Loss: 0.00001413
Iteration 95/1000 | Loss: 0.00001412
Iteration 96/1000 | Loss: 0.00001412
Iteration 97/1000 | Loss: 0.00001412
Iteration 98/1000 | Loss: 0.00001412
Iteration 99/1000 | Loss: 0.00001412
Iteration 100/1000 | Loss: 0.00001412
Iteration 101/1000 | Loss: 0.00001412
Iteration 102/1000 | Loss: 0.00001411
Iteration 103/1000 | Loss: 0.00001411
Iteration 104/1000 | Loss: 0.00001411
Iteration 105/1000 | Loss: 0.00001411
Iteration 106/1000 | Loss: 0.00001411
Iteration 107/1000 | Loss: 0.00001411
Iteration 108/1000 | Loss: 0.00001410
Iteration 109/1000 | Loss: 0.00001410
Iteration 110/1000 | Loss: 0.00001410
Iteration 111/1000 | Loss: 0.00001410
Iteration 112/1000 | Loss: 0.00001409
Iteration 113/1000 | Loss: 0.00001409
Iteration 114/1000 | Loss: 0.00001409
Iteration 115/1000 | Loss: 0.00001409
Iteration 116/1000 | Loss: 0.00001409
Iteration 117/1000 | Loss: 0.00001409
Iteration 118/1000 | Loss: 0.00001409
Iteration 119/1000 | Loss: 0.00001409
Iteration 120/1000 | Loss: 0.00001409
Iteration 121/1000 | Loss: 0.00001409
Iteration 122/1000 | Loss: 0.00001409
Iteration 123/1000 | Loss: 0.00001409
Iteration 124/1000 | Loss: 0.00001409
Iteration 125/1000 | Loss: 0.00001409
Iteration 126/1000 | Loss: 0.00001408
Iteration 127/1000 | Loss: 0.00001408
Iteration 128/1000 | Loss: 0.00001408
Iteration 129/1000 | Loss: 0.00001408
Iteration 130/1000 | Loss: 0.00001408
Iteration 131/1000 | Loss: 0.00001408
Iteration 132/1000 | Loss: 0.00001408
Iteration 133/1000 | Loss: 0.00001408
Iteration 134/1000 | Loss: 0.00001408
Iteration 135/1000 | Loss: 0.00001408
Iteration 136/1000 | Loss: 0.00001408
Iteration 137/1000 | Loss: 0.00001408
Iteration 138/1000 | Loss: 0.00001408
Iteration 139/1000 | Loss: 0.00001408
Iteration 140/1000 | Loss: 0.00001408
Iteration 141/1000 | Loss: 0.00001408
Iteration 142/1000 | Loss: 0.00001408
Iteration 143/1000 | Loss: 0.00001408
Iteration 144/1000 | Loss: 0.00001408
Iteration 145/1000 | Loss: 0.00001408
Iteration 146/1000 | Loss: 0.00001408
Iteration 147/1000 | Loss: 0.00001408
Iteration 148/1000 | Loss: 0.00001407
Iteration 149/1000 | Loss: 0.00001407
Iteration 150/1000 | Loss: 0.00001407
Iteration 151/1000 | Loss: 0.00001407
Iteration 152/1000 | Loss: 0.00001407
Iteration 153/1000 | Loss: 0.00001407
Iteration 154/1000 | Loss: 0.00001407
Iteration 155/1000 | Loss: 0.00001407
Iteration 156/1000 | Loss: 0.00001407
Iteration 157/1000 | Loss: 0.00001407
Iteration 158/1000 | Loss: 0.00001407
Iteration 159/1000 | Loss: 0.00001406
Iteration 160/1000 | Loss: 0.00001406
Iteration 161/1000 | Loss: 0.00001406
Iteration 162/1000 | Loss: 0.00001406
Iteration 163/1000 | Loss: 0.00001406
Iteration 164/1000 | Loss: 0.00001406
Iteration 165/1000 | Loss: 0.00001406
Iteration 166/1000 | Loss: 0.00001406
Iteration 167/1000 | Loss: 0.00001406
Iteration 168/1000 | Loss: 0.00001406
Iteration 169/1000 | Loss: 0.00001405
Iteration 170/1000 | Loss: 0.00001405
Iteration 171/1000 | Loss: 0.00001405
Iteration 172/1000 | Loss: 0.00001405
Iteration 173/1000 | Loss: 0.00001405
Iteration 174/1000 | Loss: 0.00001405
Iteration 175/1000 | Loss: 0.00001405
Iteration 176/1000 | Loss: 0.00001405
Iteration 177/1000 | Loss: 0.00001405
Iteration 178/1000 | Loss: 0.00001405
Iteration 179/1000 | Loss: 0.00001405
Iteration 180/1000 | Loss: 0.00001405
Iteration 181/1000 | Loss: 0.00001405
Iteration 182/1000 | Loss: 0.00001404
Iteration 183/1000 | Loss: 0.00001404
Iteration 184/1000 | Loss: 0.00001404
Iteration 185/1000 | Loss: 0.00001404
Iteration 186/1000 | Loss: 0.00001404
Iteration 187/1000 | Loss: 0.00001404
Iteration 188/1000 | Loss: 0.00001404
Iteration 189/1000 | Loss: 0.00001404
Iteration 190/1000 | Loss: 0.00001404
Iteration 191/1000 | Loss: 0.00001404
Iteration 192/1000 | Loss: 0.00001404
Iteration 193/1000 | Loss: 0.00001404
Iteration 194/1000 | Loss: 0.00001404
Iteration 195/1000 | Loss: 0.00001404
Iteration 196/1000 | Loss: 0.00001403
Iteration 197/1000 | Loss: 0.00001403
Iteration 198/1000 | Loss: 0.00001403
Iteration 199/1000 | Loss: 0.00001403
Iteration 200/1000 | Loss: 0.00001403
Iteration 201/1000 | Loss: 0.00001403
Iteration 202/1000 | Loss: 0.00001403
Iteration 203/1000 | Loss: 0.00001403
Iteration 204/1000 | Loss: 0.00001403
Iteration 205/1000 | Loss: 0.00001403
Iteration 206/1000 | Loss: 0.00001403
Iteration 207/1000 | Loss: 0.00001403
Iteration 208/1000 | Loss: 0.00001403
Iteration 209/1000 | Loss: 0.00001403
Iteration 210/1000 | Loss: 0.00001403
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 210. Stopping optimization.
Last 5 losses: [1.403104488417739e-05, 1.403104488417739e-05, 1.403104488417739e-05, 1.403104488417739e-05, 1.403104488417739e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.403104488417739e-05

Optimization complete. Final v2v error: 3.1448323726654053 mm

Highest mean error: 3.5264995098114014 mm for frame 105

Lowest mean error: 2.85166335105896 mm for frame 19

Saving results

Total time: 41.79069924354553
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1051/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1051.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1051
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00859369
Iteration 2/25 | Loss: 0.00091730
Iteration 3/25 | Loss: 0.00073285
Iteration 4/25 | Loss: 0.00071646
Iteration 5/25 | Loss: 0.00071199
Iteration 6/25 | Loss: 0.00071070
Iteration 7/25 | Loss: 0.00071070
Iteration 8/25 | Loss: 0.00071070
Iteration 9/25 | Loss: 0.00071070
Iteration 10/25 | Loss: 0.00071070
Iteration 11/25 | Loss: 0.00071070
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007106992416083813, 0.0007106992416083813, 0.0007106992416083813, 0.0007106992416083813, 0.0007106992416083813]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007106992416083813

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46995175
Iteration 2/25 | Loss: 0.00029402
Iteration 3/25 | Loss: 0.00029400
Iteration 4/25 | Loss: 0.00029400
Iteration 5/25 | Loss: 0.00029400
Iteration 6/25 | Loss: 0.00029400
Iteration 7/25 | Loss: 0.00029399
Iteration 8/25 | Loss: 0.00029399
Iteration 9/25 | Loss: 0.00029399
Iteration 10/25 | Loss: 0.00029399
Iteration 11/25 | Loss: 0.00029399
Iteration 12/25 | Loss: 0.00029399
Iteration 13/25 | Loss: 0.00029399
Iteration 14/25 | Loss: 0.00029399
Iteration 15/25 | Loss: 0.00029399
Iteration 16/25 | Loss: 0.00029399
Iteration 17/25 | Loss: 0.00029399
Iteration 18/25 | Loss: 0.00029399
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0002939937694463879, 0.0002939937694463879, 0.0002939937694463879, 0.0002939937694463879, 0.0002939937694463879]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002939937694463879

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029399
Iteration 2/1000 | Loss: 0.00002009
Iteration 3/1000 | Loss: 0.00001504
Iteration 4/1000 | Loss: 0.00001348
Iteration 5/1000 | Loss: 0.00001255
Iteration 6/1000 | Loss: 0.00001183
Iteration 7/1000 | Loss: 0.00001147
Iteration 8/1000 | Loss: 0.00001111
Iteration 9/1000 | Loss: 0.00001101
Iteration 10/1000 | Loss: 0.00001101
Iteration 11/1000 | Loss: 0.00001099
Iteration 12/1000 | Loss: 0.00001094
Iteration 13/1000 | Loss: 0.00001093
Iteration 14/1000 | Loss: 0.00001087
Iteration 15/1000 | Loss: 0.00001081
Iteration 16/1000 | Loss: 0.00001080
Iteration 17/1000 | Loss: 0.00001077
Iteration 18/1000 | Loss: 0.00001077
Iteration 19/1000 | Loss: 0.00001076
Iteration 20/1000 | Loss: 0.00001075
Iteration 21/1000 | Loss: 0.00001075
Iteration 22/1000 | Loss: 0.00001074
Iteration 23/1000 | Loss: 0.00001070
Iteration 24/1000 | Loss: 0.00001070
Iteration 25/1000 | Loss: 0.00001069
Iteration 26/1000 | Loss: 0.00001069
Iteration 27/1000 | Loss: 0.00001067
Iteration 28/1000 | Loss: 0.00001066
Iteration 29/1000 | Loss: 0.00001065
Iteration 30/1000 | Loss: 0.00001064
Iteration 31/1000 | Loss: 0.00001064
Iteration 32/1000 | Loss: 0.00001064
Iteration 33/1000 | Loss: 0.00001064
Iteration 34/1000 | Loss: 0.00001063
Iteration 35/1000 | Loss: 0.00001063
Iteration 36/1000 | Loss: 0.00001062
Iteration 37/1000 | Loss: 0.00001062
Iteration 38/1000 | Loss: 0.00001062
Iteration 39/1000 | Loss: 0.00001061
Iteration 40/1000 | Loss: 0.00001061
Iteration 41/1000 | Loss: 0.00001060
Iteration 42/1000 | Loss: 0.00001060
Iteration 43/1000 | Loss: 0.00001060
Iteration 44/1000 | Loss: 0.00001060
Iteration 45/1000 | Loss: 0.00001059
Iteration 46/1000 | Loss: 0.00001059
Iteration 47/1000 | Loss: 0.00001059
Iteration 48/1000 | Loss: 0.00001059
Iteration 49/1000 | Loss: 0.00001059
Iteration 50/1000 | Loss: 0.00001058
Iteration 51/1000 | Loss: 0.00001058
Iteration 52/1000 | Loss: 0.00001058
Iteration 53/1000 | Loss: 0.00001057
Iteration 54/1000 | Loss: 0.00001057
Iteration 55/1000 | Loss: 0.00001057
Iteration 56/1000 | Loss: 0.00001057
Iteration 57/1000 | Loss: 0.00001057
Iteration 58/1000 | Loss: 0.00001057
Iteration 59/1000 | Loss: 0.00001057
Iteration 60/1000 | Loss: 0.00001056
Iteration 61/1000 | Loss: 0.00001056
Iteration 62/1000 | Loss: 0.00001056
Iteration 63/1000 | Loss: 0.00001056
Iteration 64/1000 | Loss: 0.00001056
Iteration 65/1000 | Loss: 0.00001056
Iteration 66/1000 | Loss: 0.00001056
Iteration 67/1000 | Loss: 0.00001056
Iteration 68/1000 | Loss: 0.00001056
Iteration 69/1000 | Loss: 0.00001056
Iteration 70/1000 | Loss: 0.00001056
Iteration 71/1000 | Loss: 0.00001056
Iteration 72/1000 | Loss: 0.00001056
Iteration 73/1000 | Loss: 0.00001056
Iteration 74/1000 | Loss: 0.00001055
Iteration 75/1000 | Loss: 0.00001055
Iteration 76/1000 | Loss: 0.00001055
Iteration 77/1000 | Loss: 0.00001055
Iteration 78/1000 | Loss: 0.00001055
Iteration 79/1000 | Loss: 0.00001055
Iteration 80/1000 | Loss: 0.00001055
Iteration 81/1000 | Loss: 0.00001054
Iteration 82/1000 | Loss: 0.00001054
Iteration 83/1000 | Loss: 0.00001054
Iteration 84/1000 | Loss: 0.00001054
Iteration 85/1000 | Loss: 0.00001054
Iteration 86/1000 | Loss: 0.00001054
Iteration 87/1000 | Loss: 0.00001054
Iteration 88/1000 | Loss: 0.00001054
Iteration 89/1000 | Loss: 0.00001054
Iteration 90/1000 | Loss: 0.00001054
Iteration 91/1000 | Loss: 0.00001054
Iteration 92/1000 | Loss: 0.00001053
Iteration 93/1000 | Loss: 0.00001053
Iteration 94/1000 | Loss: 0.00001053
Iteration 95/1000 | Loss: 0.00001053
Iteration 96/1000 | Loss: 0.00001052
Iteration 97/1000 | Loss: 0.00001052
Iteration 98/1000 | Loss: 0.00001052
Iteration 99/1000 | Loss: 0.00001052
Iteration 100/1000 | Loss: 0.00001052
Iteration 101/1000 | Loss: 0.00001052
Iteration 102/1000 | Loss: 0.00001052
Iteration 103/1000 | Loss: 0.00001052
Iteration 104/1000 | Loss: 0.00001052
Iteration 105/1000 | Loss: 0.00001052
Iteration 106/1000 | Loss: 0.00001052
Iteration 107/1000 | Loss: 0.00001052
Iteration 108/1000 | Loss: 0.00001052
Iteration 109/1000 | Loss: 0.00001052
Iteration 110/1000 | Loss: 0.00001052
Iteration 111/1000 | Loss: 0.00001052
Iteration 112/1000 | Loss: 0.00001052
Iteration 113/1000 | Loss: 0.00001052
Iteration 114/1000 | Loss: 0.00001052
Iteration 115/1000 | Loss: 0.00001051
Iteration 116/1000 | Loss: 0.00001051
Iteration 117/1000 | Loss: 0.00001051
Iteration 118/1000 | Loss: 0.00001051
Iteration 119/1000 | Loss: 0.00001051
Iteration 120/1000 | Loss: 0.00001051
Iteration 121/1000 | Loss: 0.00001051
Iteration 122/1000 | Loss: 0.00001051
Iteration 123/1000 | Loss: 0.00001051
Iteration 124/1000 | Loss: 0.00001051
Iteration 125/1000 | Loss: 0.00001051
Iteration 126/1000 | Loss: 0.00001051
Iteration 127/1000 | Loss: 0.00001051
Iteration 128/1000 | Loss: 0.00001051
Iteration 129/1000 | Loss: 0.00001051
Iteration 130/1000 | Loss: 0.00001051
Iteration 131/1000 | Loss: 0.00001051
Iteration 132/1000 | Loss: 0.00001051
Iteration 133/1000 | Loss: 0.00001051
Iteration 134/1000 | Loss: 0.00001051
Iteration 135/1000 | Loss: 0.00001051
Iteration 136/1000 | Loss: 0.00001051
Iteration 137/1000 | Loss: 0.00001051
Iteration 138/1000 | Loss: 0.00001051
Iteration 139/1000 | Loss: 0.00001051
Iteration 140/1000 | Loss: 0.00001051
Iteration 141/1000 | Loss: 0.00001051
Iteration 142/1000 | Loss: 0.00001051
Iteration 143/1000 | Loss: 0.00001051
Iteration 144/1000 | Loss: 0.00001051
Iteration 145/1000 | Loss: 0.00001051
Iteration 146/1000 | Loss: 0.00001051
Iteration 147/1000 | Loss: 0.00001051
Iteration 148/1000 | Loss: 0.00001051
Iteration 149/1000 | Loss: 0.00001051
Iteration 150/1000 | Loss: 0.00001051
Iteration 151/1000 | Loss: 0.00001051
Iteration 152/1000 | Loss: 0.00001051
Iteration 153/1000 | Loss: 0.00001051
Iteration 154/1000 | Loss: 0.00001051
Iteration 155/1000 | Loss: 0.00001051
Iteration 156/1000 | Loss: 0.00001051
Iteration 157/1000 | Loss: 0.00001051
Iteration 158/1000 | Loss: 0.00001051
Iteration 159/1000 | Loss: 0.00001051
Iteration 160/1000 | Loss: 0.00001051
Iteration 161/1000 | Loss: 0.00001051
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 161. Stopping optimization.
Last 5 losses: [1.0505840691621415e-05, 1.0505840691621415e-05, 1.0505840691621415e-05, 1.0505840691621415e-05, 1.0505840691621415e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0505840691621415e-05

Optimization complete. Final v2v error: 2.7507286071777344 mm

Highest mean error: 2.992443799972534 mm for frame 34

Lowest mean error: 2.6234562397003174 mm for frame 140

Saving results

Total time: 33.75895929336548
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00449416
Iteration 2/25 | Loss: 0.00108116
Iteration 3/25 | Loss: 0.00100236
Iteration 4/25 | Loss: 0.00097117
Iteration 5/25 | Loss: 0.00095986
Iteration 6/25 | Loss: 0.00095771
Iteration 7/25 | Loss: 0.00095734
Iteration 8/25 | Loss: 0.00095734
Iteration 9/25 | Loss: 0.00095734
Iteration 10/25 | Loss: 0.00095734
Iteration 11/25 | Loss: 0.00095734
Iteration 12/25 | Loss: 0.00095734
Iteration 13/25 | Loss: 0.00095734
Iteration 14/25 | Loss: 0.00095734
Iteration 15/25 | Loss: 0.00095734
Iteration 16/25 | Loss: 0.00095734
Iteration 17/25 | Loss: 0.00095734
Iteration 18/25 | Loss: 0.00095734
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009573409333825111, 0.0009573409333825111, 0.0009573409333825111, 0.0009573409333825111, 0.0009573409333825111]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009573409333825111

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61346948
Iteration 2/25 | Loss: 0.00065916
Iteration 3/25 | Loss: 0.00065916
Iteration 4/25 | Loss: 0.00065916
Iteration 5/25 | Loss: 0.00065916
Iteration 6/25 | Loss: 0.00065916
Iteration 7/25 | Loss: 0.00065916
Iteration 8/25 | Loss: 0.00065916
Iteration 9/25 | Loss: 0.00065916
Iteration 10/25 | Loss: 0.00065916
Iteration 11/25 | Loss: 0.00065916
Iteration 12/25 | Loss: 0.00065916
Iteration 13/25 | Loss: 0.00065916
Iteration 14/25 | Loss: 0.00065916
Iteration 15/25 | Loss: 0.00065916
Iteration 16/25 | Loss: 0.00065916
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006591567071154714, 0.0006591567071154714, 0.0006591567071154714, 0.0006591567071154714, 0.0006591567071154714]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006591567071154714

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065916
Iteration 2/1000 | Loss: 0.00004140
Iteration 3/1000 | Loss: 0.00002713
Iteration 4/1000 | Loss: 0.00002496
Iteration 5/1000 | Loss: 0.00002326
Iteration 6/1000 | Loss: 0.00002270
Iteration 7/1000 | Loss: 0.00002209
Iteration 8/1000 | Loss: 0.00002176
Iteration 9/1000 | Loss: 0.00002157
Iteration 10/1000 | Loss: 0.00002144
Iteration 11/1000 | Loss: 0.00002139
Iteration 12/1000 | Loss: 0.00002139
Iteration 13/1000 | Loss: 0.00002138
Iteration 14/1000 | Loss: 0.00002138
Iteration 15/1000 | Loss: 0.00002137
Iteration 16/1000 | Loss: 0.00002136
Iteration 17/1000 | Loss: 0.00002136
Iteration 18/1000 | Loss: 0.00002136
Iteration 19/1000 | Loss: 0.00002136
Iteration 20/1000 | Loss: 0.00002136
Iteration 21/1000 | Loss: 0.00002135
Iteration 22/1000 | Loss: 0.00002135
Iteration 23/1000 | Loss: 0.00002135
Iteration 24/1000 | Loss: 0.00002135
Iteration 25/1000 | Loss: 0.00002135
Iteration 26/1000 | Loss: 0.00002135
Iteration 27/1000 | Loss: 0.00002134
Iteration 28/1000 | Loss: 0.00002134
Iteration 29/1000 | Loss: 0.00002134
Iteration 30/1000 | Loss: 0.00002134
Iteration 31/1000 | Loss: 0.00002134
Iteration 32/1000 | Loss: 0.00002133
Iteration 33/1000 | Loss: 0.00002133
Iteration 34/1000 | Loss: 0.00002133
Iteration 35/1000 | Loss: 0.00002133
Iteration 36/1000 | Loss: 0.00002133
Iteration 37/1000 | Loss: 0.00002133
Iteration 38/1000 | Loss: 0.00002133
Iteration 39/1000 | Loss: 0.00002132
Iteration 40/1000 | Loss: 0.00002132
Iteration 41/1000 | Loss: 0.00002132
Iteration 42/1000 | Loss: 0.00002132
Iteration 43/1000 | Loss: 0.00002132
Iteration 44/1000 | Loss: 0.00002132
Iteration 45/1000 | Loss: 0.00002132
Iteration 46/1000 | Loss: 0.00002131
Iteration 47/1000 | Loss: 0.00002131
Iteration 48/1000 | Loss: 0.00002131
Iteration 49/1000 | Loss: 0.00002131
Iteration 50/1000 | Loss: 0.00002131
Iteration 51/1000 | Loss: 0.00002131
Iteration 52/1000 | Loss: 0.00002131
Iteration 53/1000 | Loss: 0.00002131
Iteration 54/1000 | Loss: 0.00002131
Iteration 55/1000 | Loss: 0.00002131
Iteration 56/1000 | Loss: 0.00002131
Iteration 57/1000 | Loss: 0.00002131
Iteration 58/1000 | Loss: 0.00002131
Iteration 59/1000 | Loss: 0.00002131
Iteration 60/1000 | Loss: 0.00002131
Iteration 61/1000 | Loss: 0.00002130
Iteration 62/1000 | Loss: 0.00002130
Iteration 63/1000 | Loss: 0.00002130
Iteration 64/1000 | Loss: 0.00002130
Iteration 65/1000 | Loss: 0.00002130
Iteration 66/1000 | Loss: 0.00002130
Iteration 67/1000 | Loss: 0.00002130
Iteration 68/1000 | Loss: 0.00002130
Iteration 69/1000 | Loss: 0.00002130
Iteration 70/1000 | Loss: 0.00002130
Iteration 71/1000 | Loss: 0.00002130
Iteration 72/1000 | Loss: 0.00002130
Iteration 73/1000 | Loss: 0.00002129
Iteration 74/1000 | Loss: 0.00002129
Iteration 75/1000 | Loss: 0.00002129
Iteration 76/1000 | Loss: 0.00002129
Iteration 77/1000 | Loss: 0.00002129
Iteration 78/1000 | Loss: 0.00002129
Iteration 79/1000 | Loss: 0.00002129
Iteration 80/1000 | Loss: 0.00002129
Iteration 81/1000 | Loss: 0.00002129
Iteration 82/1000 | Loss: 0.00002129
Iteration 83/1000 | Loss: 0.00002128
Iteration 84/1000 | Loss: 0.00002128
Iteration 85/1000 | Loss: 0.00002128
Iteration 86/1000 | Loss: 0.00002128
Iteration 87/1000 | Loss: 0.00002128
Iteration 88/1000 | Loss: 0.00002128
Iteration 89/1000 | Loss: 0.00002128
Iteration 90/1000 | Loss: 0.00002128
Iteration 91/1000 | Loss: 0.00002128
Iteration 92/1000 | Loss: 0.00002128
Iteration 93/1000 | Loss: 0.00002128
Iteration 94/1000 | Loss: 0.00002128
Iteration 95/1000 | Loss: 0.00002128
Iteration 96/1000 | Loss: 0.00002128
Iteration 97/1000 | Loss: 0.00002128
Iteration 98/1000 | Loss: 0.00002128
Iteration 99/1000 | Loss: 0.00002128
Iteration 100/1000 | Loss: 0.00002127
Iteration 101/1000 | Loss: 0.00002127
Iteration 102/1000 | Loss: 0.00002127
Iteration 103/1000 | Loss: 0.00002127
Iteration 104/1000 | Loss: 0.00002127
Iteration 105/1000 | Loss: 0.00002127
Iteration 106/1000 | Loss: 0.00002127
Iteration 107/1000 | Loss: 0.00002127
Iteration 108/1000 | Loss: 0.00002126
Iteration 109/1000 | Loss: 0.00002126
Iteration 110/1000 | Loss: 0.00002126
Iteration 111/1000 | Loss: 0.00002126
Iteration 112/1000 | Loss: 0.00002126
Iteration 113/1000 | Loss: 0.00002126
Iteration 114/1000 | Loss: 0.00002126
Iteration 115/1000 | Loss: 0.00002126
Iteration 116/1000 | Loss: 0.00002126
Iteration 117/1000 | Loss: 0.00002126
Iteration 118/1000 | Loss: 0.00002125
Iteration 119/1000 | Loss: 0.00002125
Iteration 120/1000 | Loss: 0.00002125
Iteration 121/1000 | Loss: 0.00002125
Iteration 122/1000 | Loss: 0.00002125
Iteration 123/1000 | Loss: 0.00002125
Iteration 124/1000 | Loss: 0.00002125
Iteration 125/1000 | Loss: 0.00002125
Iteration 126/1000 | Loss: 0.00002125
Iteration 127/1000 | Loss: 0.00002125
Iteration 128/1000 | Loss: 0.00002125
Iteration 129/1000 | Loss: 0.00002125
Iteration 130/1000 | Loss: 0.00002125
Iteration 131/1000 | Loss: 0.00002125
Iteration 132/1000 | Loss: 0.00002125
Iteration 133/1000 | Loss: 0.00002124
Iteration 134/1000 | Loss: 0.00002124
Iteration 135/1000 | Loss: 0.00002124
Iteration 136/1000 | Loss: 0.00002124
Iteration 137/1000 | Loss: 0.00002124
Iteration 138/1000 | Loss: 0.00002124
Iteration 139/1000 | Loss: 0.00002124
Iteration 140/1000 | Loss: 0.00002124
Iteration 141/1000 | Loss: 0.00002124
Iteration 142/1000 | Loss: 0.00002124
Iteration 143/1000 | Loss: 0.00002124
Iteration 144/1000 | Loss: 0.00002124
Iteration 145/1000 | Loss: 0.00002124
Iteration 146/1000 | Loss: 0.00002124
Iteration 147/1000 | Loss: 0.00002124
Iteration 148/1000 | Loss: 0.00002124
Iteration 149/1000 | Loss: 0.00002124
Iteration 150/1000 | Loss: 0.00002124
Iteration 151/1000 | Loss: 0.00002124
Iteration 152/1000 | Loss: 0.00002124
Iteration 153/1000 | Loss: 0.00002124
Iteration 154/1000 | Loss: 0.00002124
Iteration 155/1000 | Loss: 0.00002124
Iteration 156/1000 | Loss: 0.00002124
Iteration 157/1000 | Loss: 0.00002124
Iteration 158/1000 | Loss: 0.00002124
Iteration 159/1000 | Loss: 0.00002124
Iteration 160/1000 | Loss: 0.00002124
Iteration 161/1000 | Loss: 0.00002124
Iteration 162/1000 | Loss: 0.00002124
Iteration 163/1000 | Loss: 0.00002124
Iteration 164/1000 | Loss: 0.00002124
Iteration 165/1000 | Loss: 0.00002124
Iteration 166/1000 | Loss: 0.00002124
Iteration 167/1000 | Loss: 0.00002124
Iteration 168/1000 | Loss: 0.00002124
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 168. Stopping optimization.
Last 5 losses: [2.123661761288531e-05, 2.123661761288531e-05, 2.123661761288531e-05, 2.123661761288531e-05, 2.123661761288531e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.123661761288531e-05

Optimization complete. Final v2v error: 3.888087749481201 mm

Highest mean error: 4.152955055236816 mm for frame 9

Lowest mean error: 3.468529462814331 mm for frame 2

Saving results

Total time: 33.07473301887512
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01101338
Iteration 2/25 | Loss: 0.00159455
Iteration 3/25 | Loss: 0.00119235
Iteration 4/25 | Loss: 0.00090778
Iteration 5/25 | Loss: 0.00085356
Iteration 6/25 | Loss: 0.00079886
Iteration 7/25 | Loss: 0.00077807
Iteration 8/25 | Loss: 0.00076907
Iteration 9/25 | Loss: 0.00076329
Iteration 10/25 | Loss: 0.00075497
Iteration 11/25 | Loss: 0.00075007
Iteration 12/25 | Loss: 0.00074986
Iteration 13/25 | Loss: 0.00074670
Iteration 14/25 | Loss: 0.00074616
Iteration 15/25 | Loss: 0.00074586
Iteration 16/25 | Loss: 0.00074859
Iteration 17/25 | Loss: 0.00074752
Iteration 18/25 | Loss: 0.00074571
Iteration 19/25 | Loss: 0.00074881
Iteration 20/25 | Loss: 0.00074446
Iteration 21/25 | Loss: 0.00074696
Iteration 22/25 | Loss: 0.00074910
Iteration 23/25 | Loss: 0.00074702
Iteration 24/25 | Loss: 0.00074459
Iteration 25/25 | Loss: 0.00074213

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51844311
Iteration 2/25 | Loss: 0.00043455
Iteration 3/25 | Loss: 0.00043455
Iteration 4/25 | Loss: 0.00043455
Iteration 5/25 | Loss: 0.00043455
Iteration 6/25 | Loss: 0.00043455
Iteration 7/25 | Loss: 0.00043455
Iteration 8/25 | Loss: 0.00043455
Iteration 9/25 | Loss: 0.00043455
Iteration 10/25 | Loss: 0.00043455
Iteration 11/25 | Loss: 0.00043455
Iteration 12/25 | Loss: 0.00043455
Iteration 13/25 | Loss: 0.00043455
Iteration 14/25 | Loss: 0.00043455
Iteration 15/25 | Loss: 0.00043455
Iteration 16/25 | Loss: 0.00043455
Iteration 17/25 | Loss: 0.00043455
Iteration 18/25 | Loss: 0.00043455
Iteration 19/25 | Loss: 0.00043455
Iteration 20/25 | Loss: 0.00043455
Iteration 21/25 | Loss: 0.00043455
Iteration 22/25 | Loss: 0.00043455
Iteration 23/25 | Loss: 0.00043455
Iteration 24/25 | Loss: 0.00043455
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00043454597471281886, 0.00043454597471281886, 0.00043454597471281886, 0.00043454597471281886, 0.00043454597471281886]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00043454597471281886

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043455
Iteration 2/1000 | Loss: 0.00009178
Iteration 3/1000 | Loss: 0.00002081
Iteration 4/1000 | Loss: 0.00005725
Iteration 5/1000 | Loss: 0.00001797
Iteration 6/1000 | Loss: 0.00005910
Iteration 7/1000 | Loss: 0.00001745
Iteration 8/1000 | Loss: 0.00001713
Iteration 9/1000 | Loss: 0.00001688
Iteration 10/1000 | Loss: 0.00001677
Iteration 11/1000 | Loss: 0.00001676
Iteration 12/1000 | Loss: 0.00001676
Iteration 13/1000 | Loss: 0.00001672
Iteration 14/1000 | Loss: 0.00001672
Iteration 15/1000 | Loss: 0.00001671
Iteration 16/1000 | Loss: 0.00001667
Iteration 17/1000 | Loss: 0.00001666
Iteration 18/1000 | Loss: 0.00001665
Iteration 19/1000 | Loss: 0.00001661
Iteration 20/1000 | Loss: 0.00004849
Iteration 21/1000 | Loss: 0.00038958
Iteration 22/1000 | Loss: 0.00008832
Iteration 23/1000 | Loss: 0.00005592
Iteration 24/1000 | Loss: 0.00003619
Iteration 25/1000 | Loss: 0.00002491
Iteration 26/1000 | Loss: 0.00003013
Iteration 27/1000 | Loss: 0.00002254
Iteration 28/1000 | Loss: 0.00008947
Iteration 29/1000 | Loss: 0.00001790
Iteration 30/1000 | Loss: 0.00001947
Iteration 31/1000 | Loss: 0.00001720
Iteration 32/1000 | Loss: 0.00001684
Iteration 33/1000 | Loss: 0.00001678
Iteration 34/1000 | Loss: 0.00001661
Iteration 35/1000 | Loss: 0.00009184
Iteration 36/1000 | Loss: 0.00001708
Iteration 37/1000 | Loss: 0.00001651
Iteration 38/1000 | Loss: 0.00001649
Iteration 39/1000 | Loss: 0.00001646
Iteration 40/1000 | Loss: 0.00001646
Iteration 41/1000 | Loss: 0.00001645
Iteration 42/1000 | Loss: 0.00001645
Iteration 43/1000 | Loss: 0.00001644
Iteration 44/1000 | Loss: 0.00001644
Iteration 45/1000 | Loss: 0.00001643
Iteration 46/1000 | Loss: 0.00001643
Iteration 47/1000 | Loss: 0.00001643
Iteration 48/1000 | Loss: 0.00001642
Iteration 49/1000 | Loss: 0.00001642
Iteration 50/1000 | Loss: 0.00001642
Iteration 51/1000 | Loss: 0.00001642
Iteration 52/1000 | Loss: 0.00001642
Iteration 53/1000 | Loss: 0.00001642
Iteration 54/1000 | Loss: 0.00001641
Iteration 55/1000 | Loss: 0.00001641
Iteration 56/1000 | Loss: 0.00001641
Iteration 57/1000 | Loss: 0.00001641
Iteration 58/1000 | Loss: 0.00001641
Iteration 59/1000 | Loss: 0.00001641
Iteration 60/1000 | Loss: 0.00001640
Iteration 61/1000 | Loss: 0.00001640
Iteration 62/1000 | Loss: 0.00001639
Iteration 63/1000 | Loss: 0.00001639
Iteration 64/1000 | Loss: 0.00001639
Iteration 65/1000 | Loss: 0.00001638
Iteration 66/1000 | Loss: 0.00001638
Iteration 67/1000 | Loss: 0.00001638
Iteration 68/1000 | Loss: 0.00001638
Iteration 69/1000 | Loss: 0.00001638
Iteration 70/1000 | Loss: 0.00001637
Iteration 71/1000 | Loss: 0.00001637
Iteration 72/1000 | Loss: 0.00001637
Iteration 73/1000 | Loss: 0.00001637
Iteration 74/1000 | Loss: 0.00001636
Iteration 75/1000 | Loss: 0.00001636
Iteration 76/1000 | Loss: 0.00001636
Iteration 77/1000 | Loss: 0.00001635
Iteration 78/1000 | Loss: 0.00001635
Iteration 79/1000 | Loss: 0.00001635
Iteration 80/1000 | Loss: 0.00001635
Iteration 81/1000 | Loss: 0.00001635
Iteration 82/1000 | Loss: 0.00001635
Iteration 83/1000 | Loss: 0.00001635
Iteration 84/1000 | Loss: 0.00001635
Iteration 85/1000 | Loss: 0.00001635
Iteration 86/1000 | Loss: 0.00001635
Iteration 87/1000 | Loss: 0.00001635
Iteration 88/1000 | Loss: 0.00001634
Iteration 89/1000 | Loss: 0.00001634
Iteration 90/1000 | Loss: 0.00001634
Iteration 91/1000 | Loss: 0.00001634
Iteration 92/1000 | Loss: 0.00001634
Iteration 93/1000 | Loss: 0.00001634
Iteration 94/1000 | Loss: 0.00001634
Iteration 95/1000 | Loss: 0.00001634
Iteration 96/1000 | Loss: 0.00001634
Iteration 97/1000 | Loss: 0.00001634
Iteration 98/1000 | Loss: 0.00001634
Iteration 99/1000 | Loss: 0.00001634
Iteration 100/1000 | Loss: 0.00001634
Iteration 101/1000 | Loss: 0.00001634
Iteration 102/1000 | Loss: 0.00001634
Iteration 103/1000 | Loss: 0.00001634
Iteration 104/1000 | Loss: 0.00001634
Iteration 105/1000 | Loss: 0.00001634
Iteration 106/1000 | Loss: 0.00001634
Iteration 107/1000 | Loss: 0.00001634
Iteration 108/1000 | Loss: 0.00001634
Iteration 109/1000 | Loss: 0.00001634
Iteration 110/1000 | Loss: 0.00001634
Iteration 111/1000 | Loss: 0.00001634
Iteration 112/1000 | Loss: 0.00001634
Iteration 113/1000 | Loss: 0.00001634
Iteration 114/1000 | Loss: 0.00001634
Iteration 115/1000 | Loss: 0.00001634
Iteration 116/1000 | Loss: 0.00001634
Iteration 117/1000 | Loss: 0.00001634
Iteration 118/1000 | Loss: 0.00001634
Iteration 119/1000 | Loss: 0.00001634
Iteration 120/1000 | Loss: 0.00001634
Iteration 121/1000 | Loss: 0.00001634
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 121. Stopping optimization.
Last 5 losses: [1.6343874449376017e-05, 1.6343874449376017e-05, 1.6343874449376017e-05, 1.6343874449376017e-05, 1.6343874449376017e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6343874449376017e-05

Optimization complete. Final v2v error: 3.2234628200531006 mm

Highest mean error: 10.126017570495605 mm for frame 90

Lowest mean error: 2.6589412689208984 mm for frame 85

Saving results

Total time: 88.6532142162323
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01149147
Iteration 2/25 | Loss: 0.00249430
Iteration 3/25 | Loss: 0.00156560
Iteration 4/25 | Loss: 0.00130220
Iteration 5/25 | Loss: 0.00126480
Iteration 6/25 | Loss: 0.00120918
Iteration 7/25 | Loss: 0.00113685
Iteration 8/25 | Loss: 0.00110430
Iteration 9/25 | Loss: 0.00110642
Iteration 10/25 | Loss: 0.00109302
Iteration 11/25 | Loss: 0.00108858
Iteration 12/25 | Loss: 0.00108714
Iteration 13/25 | Loss: 0.00108478
Iteration 14/25 | Loss: 0.00108342
Iteration 15/25 | Loss: 0.00108228
Iteration 16/25 | Loss: 0.00108227
Iteration 17/25 | Loss: 0.00108227
Iteration 18/25 | Loss: 0.00108227
Iteration 19/25 | Loss: 0.00108227
Iteration 20/25 | Loss: 0.00108227
Iteration 21/25 | Loss: 0.00108227
Iteration 22/25 | Loss: 0.00108227
Iteration 23/25 | Loss: 0.00108227
Iteration 24/25 | Loss: 0.00108227
Iteration 25/25 | Loss: 0.00108227

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48383296
Iteration 2/25 | Loss: 0.00090807
Iteration 3/25 | Loss: 0.00075504
Iteration 4/25 | Loss: 0.00075504
Iteration 5/25 | Loss: 0.00075504
Iteration 6/25 | Loss: 0.00075504
Iteration 7/25 | Loss: 0.00075504
Iteration 8/25 | Loss: 0.00075504
Iteration 9/25 | Loss: 0.00075504
Iteration 10/25 | Loss: 0.00075504
Iteration 11/25 | Loss: 0.00075504
Iteration 12/25 | Loss: 0.00075504
Iteration 13/25 | Loss: 0.00075504
Iteration 14/25 | Loss: 0.00075504
Iteration 15/25 | Loss: 0.00075504
Iteration 16/25 | Loss: 0.00075504
Iteration 17/25 | Loss: 0.00075504
Iteration 18/25 | Loss: 0.00075504
Iteration 19/25 | Loss: 0.00075504
Iteration 20/25 | Loss: 0.00075504
Iteration 21/25 | Loss: 0.00075504
Iteration 22/25 | Loss: 0.00075504
Iteration 23/25 | Loss: 0.00075504
Iteration 24/25 | Loss: 0.00075504
Iteration 25/25 | Loss: 0.00075504

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075504
Iteration 2/1000 | Loss: 0.00025472
Iteration 3/1000 | Loss: 0.00005768
Iteration 4/1000 | Loss: 0.00006556
Iteration 5/1000 | Loss: 0.00021197
Iteration 6/1000 | Loss: 0.00004038
Iteration 7/1000 | Loss: 0.00004857
Iteration 8/1000 | Loss: 0.00005668
Iteration 9/1000 | Loss: 0.00013207
Iteration 10/1000 | Loss: 0.00005717
Iteration 11/1000 | Loss: 0.00004771
Iteration 12/1000 | Loss: 0.00004136
Iteration 13/1000 | Loss: 0.00004709
Iteration 14/1000 | Loss: 0.00003741
Iteration 15/1000 | Loss: 0.00003710
Iteration 16/1000 | Loss: 0.00005967
Iteration 17/1000 | Loss: 0.00005238
Iteration 18/1000 | Loss: 0.00009723
Iteration 19/1000 | Loss: 0.00004559
Iteration 20/1000 | Loss: 0.00004607
Iteration 21/1000 | Loss: 0.00003664
Iteration 22/1000 | Loss: 0.00003662
Iteration 23/1000 | Loss: 0.00003662
Iteration 24/1000 | Loss: 0.00003662
Iteration 25/1000 | Loss: 0.00003662
Iteration 26/1000 | Loss: 0.00003662
Iteration 27/1000 | Loss: 0.00003662
Iteration 28/1000 | Loss: 0.00003662
Iteration 29/1000 | Loss: 0.00003661
Iteration 30/1000 | Loss: 0.00003661
Iteration 31/1000 | Loss: 0.00003661
Iteration 32/1000 | Loss: 0.00003661
Iteration 33/1000 | Loss: 0.00003661
Iteration 34/1000 | Loss: 0.00003661
Iteration 35/1000 | Loss: 0.00003660
Iteration 36/1000 | Loss: 0.00003660
Iteration 37/1000 | Loss: 0.00003660
Iteration 38/1000 | Loss: 0.00003660
Iteration 39/1000 | Loss: 0.00003660
Iteration 40/1000 | Loss: 0.00003659
Iteration 41/1000 | Loss: 0.00006827
Iteration 42/1000 | Loss: 0.00007684
Iteration 43/1000 | Loss: 0.00003660
Iteration 44/1000 | Loss: 0.00003651
Iteration 45/1000 | Loss: 0.00004661
Iteration 46/1000 | Loss: 0.00003645
Iteration 47/1000 | Loss: 0.00003645
Iteration 48/1000 | Loss: 0.00003645
Iteration 49/1000 | Loss: 0.00003645
Iteration 50/1000 | Loss: 0.00003645
Iteration 51/1000 | Loss: 0.00003645
Iteration 52/1000 | Loss: 0.00003645
Iteration 53/1000 | Loss: 0.00003645
Iteration 54/1000 | Loss: 0.00003645
Iteration 55/1000 | Loss: 0.00003645
Iteration 56/1000 | Loss: 0.00003644
Iteration 57/1000 | Loss: 0.00003644
Iteration 58/1000 | Loss: 0.00003644
Iteration 59/1000 | Loss: 0.00003644
Iteration 60/1000 | Loss: 0.00003644
Iteration 61/1000 | Loss: 0.00003644
Iteration 62/1000 | Loss: 0.00003644
Iteration 63/1000 | Loss: 0.00003644
Iteration 64/1000 | Loss: 0.00003644
Iteration 65/1000 | Loss: 0.00003644
Iteration 66/1000 | Loss: 0.00003644
Iteration 67/1000 | Loss: 0.00003643
Iteration 68/1000 | Loss: 0.00003643
Iteration 69/1000 | Loss: 0.00003643
Iteration 70/1000 | Loss: 0.00003643
Iteration 71/1000 | Loss: 0.00003643
Iteration 72/1000 | Loss: 0.00003643
Iteration 73/1000 | Loss: 0.00003643
Iteration 74/1000 | Loss: 0.00003643
Iteration 75/1000 | Loss: 0.00003643
Iteration 76/1000 | Loss: 0.00003643
Iteration 77/1000 | Loss: 0.00003643
Iteration 78/1000 | Loss: 0.00003643
Iteration 79/1000 | Loss: 0.00003643
Iteration 80/1000 | Loss: 0.00003643
Iteration 81/1000 | Loss: 0.00003643
Iteration 82/1000 | Loss: 0.00003643
Iteration 83/1000 | Loss: 0.00003643
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 83. Stopping optimization.
Last 5 losses: [3.643408854259178e-05, 3.643408854259178e-05, 3.643408854259178e-05, 3.643408854259178e-05, 3.643408854259178e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.643408854259178e-05

Optimization complete. Final v2v error: 5.144345283508301 mm

Highest mean error: 9.978266716003418 mm for frame 8

Lowest mean error: 4.651353359222412 mm for frame 4

Saving results

Total time: 63.553144216537476
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00936616
Iteration 2/25 | Loss: 0.00110572
Iteration 3/25 | Loss: 0.00098973
Iteration 4/25 | Loss: 0.00095978
Iteration 5/25 | Loss: 0.00094758
Iteration 6/25 | Loss: 0.00094584
Iteration 7/25 | Loss: 0.00094577
Iteration 8/25 | Loss: 0.00094577
Iteration 9/25 | Loss: 0.00094577
Iteration 10/25 | Loss: 0.00094577
Iteration 11/25 | Loss: 0.00094577
Iteration 12/25 | Loss: 0.00094577
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000945771113038063, 0.000945771113038063, 0.000945771113038063, 0.000945771113038063, 0.000945771113038063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000945771113038063

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47479773
Iteration 2/25 | Loss: 0.00065118
Iteration 3/25 | Loss: 0.00065118
Iteration 4/25 | Loss: 0.00065118
Iteration 5/25 | Loss: 0.00065118
Iteration 6/25 | Loss: 0.00065117
Iteration 7/25 | Loss: 0.00065117
Iteration 8/25 | Loss: 0.00065117
Iteration 9/25 | Loss: 0.00065117
Iteration 10/25 | Loss: 0.00065117
Iteration 11/25 | Loss: 0.00065117
Iteration 12/25 | Loss: 0.00065117
Iteration 13/25 | Loss: 0.00065117
Iteration 14/25 | Loss: 0.00065117
Iteration 15/25 | Loss: 0.00065117
Iteration 16/25 | Loss: 0.00065117
Iteration 17/25 | Loss: 0.00065117
Iteration 18/25 | Loss: 0.00065117
Iteration 19/25 | Loss: 0.00065117
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0006511734682135284, 0.0006511734682135284, 0.0006511734682135284, 0.0006511734682135284, 0.0006511734682135284]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006511734682135284

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065117
Iteration 2/1000 | Loss: 0.00003120
Iteration 3/1000 | Loss: 0.00002214
Iteration 4/1000 | Loss: 0.00002015
Iteration 5/1000 | Loss: 0.00001936
Iteration 6/1000 | Loss: 0.00001884
Iteration 7/1000 | Loss: 0.00001846
Iteration 8/1000 | Loss: 0.00001826
Iteration 9/1000 | Loss: 0.00001823
Iteration 10/1000 | Loss: 0.00001820
Iteration 11/1000 | Loss: 0.00001818
Iteration 12/1000 | Loss: 0.00001799
Iteration 13/1000 | Loss: 0.00001792
Iteration 14/1000 | Loss: 0.00001790
Iteration 15/1000 | Loss: 0.00001789
Iteration 16/1000 | Loss: 0.00001789
Iteration 17/1000 | Loss: 0.00001783
Iteration 18/1000 | Loss: 0.00001782
Iteration 19/1000 | Loss: 0.00001780
Iteration 20/1000 | Loss: 0.00001780
Iteration 21/1000 | Loss: 0.00001780
Iteration 22/1000 | Loss: 0.00001779
Iteration 23/1000 | Loss: 0.00001779
Iteration 24/1000 | Loss: 0.00001777
Iteration 25/1000 | Loss: 0.00001777
Iteration 26/1000 | Loss: 0.00001777
Iteration 27/1000 | Loss: 0.00001777
Iteration 28/1000 | Loss: 0.00001776
Iteration 29/1000 | Loss: 0.00001776
Iteration 30/1000 | Loss: 0.00001776
Iteration 31/1000 | Loss: 0.00001775
Iteration 32/1000 | Loss: 0.00001774
Iteration 33/1000 | Loss: 0.00001774
Iteration 34/1000 | Loss: 0.00001774
Iteration 35/1000 | Loss: 0.00001774
Iteration 36/1000 | Loss: 0.00001774
Iteration 37/1000 | Loss: 0.00001774
Iteration 38/1000 | Loss: 0.00001774
Iteration 39/1000 | Loss: 0.00001774
Iteration 40/1000 | Loss: 0.00001774
Iteration 41/1000 | Loss: 0.00001774
Iteration 42/1000 | Loss: 0.00001773
Iteration 43/1000 | Loss: 0.00001773
Iteration 44/1000 | Loss: 0.00001772
Iteration 45/1000 | Loss: 0.00001772
Iteration 46/1000 | Loss: 0.00001770
Iteration 47/1000 | Loss: 0.00001770
Iteration 48/1000 | Loss: 0.00001770
Iteration 49/1000 | Loss: 0.00001770
Iteration 50/1000 | Loss: 0.00001770
Iteration 51/1000 | Loss: 0.00001770
Iteration 52/1000 | Loss: 0.00001770
Iteration 53/1000 | Loss: 0.00001769
Iteration 54/1000 | Loss: 0.00001768
Iteration 55/1000 | Loss: 0.00001768
Iteration 56/1000 | Loss: 0.00001768
Iteration 57/1000 | Loss: 0.00001768
Iteration 58/1000 | Loss: 0.00001768
Iteration 59/1000 | Loss: 0.00001767
Iteration 60/1000 | Loss: 0.00001767
Iteration 61/1000 | Loss: 0.00001767
Iteration 62/1000 | Loss: 0.00001767
Iteration 63/1000 | Loss: 0.00001767
Iteration 64/1000 | Loss: 0.00001767
Iteration 65/1000 | Loss: 0.00001767
Iteration 66/1000 | Loss: 0.00001766
Iteration 67/1000 | Loss: 0.00001765
Iteration 68/1000 | Loss: 0.00001765
Iteration 69/1000 | Loss: 0.00001764
Iteration 70/1000 | Loss: 0.00001764
Iteration 71/1000 | Loss: 0.00001764
Iteration 72/1000 | Loss: 0.00001764
Iteration 73/1000 | Loss: 0.00001764
Iteration 74/1000 | Loss: 0.00001764
Iteration 75/1000 | Loss: 0.00001764
Iteration 76/1000 | Loss: 0.00001764
Iteration 77/1000 | Loss: 0.00001764
Iteration 78/1000 | Loss: 0.00001764
Iteration 79/1000 | Loss: 0.00001764
Iteration 80/1000 | Loss: 0.00001764
Iteration 81/1000 | Loss: 0.00001764
Iteration 82/1000 | Loss: 0.00001764
Iteration 83/1000 | Loss: 0.00001764
Iteration 84/1000 | Loss: 0.00001764
Iteration 85/1000 | Loss: 0.00001764
Iteration 86/1000 | Loss: 0.00001764
Iteration 87/1000 | Loss: 0.00001764
Iteration 88/1000 | Loss: 0.00001764
Iteration 89/1000 | Loss: 0.00001764
Iteration 90/1000 | Loss: 0.00001764
Iteration 91/1000 | Loss: 0.00001764
Iteration 92/1000 | Loss: 0.00001764
Iteration 93/1000 | Loss: 0.00001764
Iteration 94/1000 | Loss: 0.00001764
Iteration 95/1000 | Loss: 0.00001764
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 95. Stopping optimization.
Last 5 losses: [1.7638491044635884e-05, 1.7638491044635884e-05, 1.7638491044635884e-05, 1.7638491044635884e-05, 1.7638491044635884e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7638491044635884e-05

Optimization complete. Final v2v error: 3.6141276359558105 mm

Highest mean error: 4.306604385375977 mm for frame 167

Lowest mean error: 3.221599578857422 mm for frame 31

Saving results

Total time: 31.254384994506836
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00475682
Iteration 2/25 | Loss: 0.00116701
Iteration 3/25 | Loss: 0.00098996
Iteration 4/25 | Loss: 0.00094981
Iteration 5/25 | Loss: 0.00094083
Iteration 6/25 | Loss: 0.00093983
Iteration 7/25 | Loss: 0.00093978
Iteration 8/25 | Loss: 0.00093978
Iteration 9/25 | Loss: 0.00093978
Iteration 10/25 | Loss: 0.00093978
Iteration 11/25 | Loss: 0.00093978
Iteration 12/25 | Loss: 0.00093978
Iteration 13/25 | Loss: 0.00093978
Iteration 14/25 | Loss: 0.00093978
Iteration 15/25 | Loss: 0.00093978
Iteration 16/25 | Loss: 0.00093978
Iteration 17/25 | Loss: 0.00093978
Iteration 18/25 | Loss: 0.00093978
Iteration 19/25 | Loss: 0.00093978
Iteration 20/25 | Loss: 0.00093978
Iteration 21/25 | Loss: 0.00093978
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0009397804969921708, 0.0009397804969921708, 0.0009397804969921708, 0.0009397804969921708, 0.0009397804969921708]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009397804969921708

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54382551
Iteration 2/25 | Loss: 0.00069860
Iteration 3/25 | Loss: 0.00069860
Iteration 4/25 | Loss: 0.00069860
Iteration 5/25 | Loss: 0.00069860
Iteration 6/25 | Loss: 0.00069860
Iteration 7/25 | Loss: 0.00069859
Iteration 8/25 | Loss: 0.00069859
Iteration 9/25 | Loss: 0.00069859
Iteration 10/25 | Loss: 0.00069859
Iteration 11/25 | Loss: 0.00069859
Iteration 12/25 | Loss: 0.00069859
Iteration 13/25 | Loss: 0.00069859
Iteration 14/25 | Loss: 0.00069859
Iteration 15/25 | Loss: 0.00069859
Iteration 16/25 | Loss: 0.00069859
Iteration 17/25 | Loss: 0.00069859
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006985937361605465, 0.0006985937361605465, 0.0006985937361605465, 0.0006985937361605465, 0.0006985937361605465]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006985937361605465

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00069859
Iteration 2/1000 | Loss: 0.00004162
Iteration 3/1000 | Loss: 0.00002555
Iteration 4/1000 | Loss: 0.00002253
Iteration 5/1000 | Loss: 0.00002108
Iteration 6/1000 | Loss: 0.00002035
Iteration 7/1000 | Loss: 0.00001991
Iteration 8/1000 | Loss: 0.00001961
Iteration 9/1000 | Loss: 0.00001937
Iteration 10/1000 | Loss: 0.00001925
Iteration 11/1000 | Loss: 0.00001925
Iteration 12/1000 | Loss: 0.00001924
Iteration 13/1000 | Loss: 0.00001923
Iteration 14/1000 | Loss: 0.00001923
Iteration 15/1000 | Loss: 0.00001922
Iteration 16/1000 | Loss: 0.00001922
Iteration 17/1000 | Loss: 0.00001922
Iteration 18/1000 | Loss: 0.00001921
Iteration 19/1000 | Loss: 0.00001920
Iteration 20/1000 | Loss: 0.00001920
Iteration 21/1000 | Loss: 0.00001920
Iteration 22/1000 | Loss: 0.00001920
Iteration 23/1000 | Loss: 0.00001920
Iteration 24/1000 | Loss: 0.00001920
Iteration 25/1000 | Loss: 0.00001920
Iteration 26/1000 | Loss: 0.00001920
Iteration 27/1000 | Loss: 0.00001920
Iteration 28/1000 | Loss: 0.00001920
Iteration 29/1000 | Loss: 0.00001920
Iteration 30/1000 | Loss: 0.00001920
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 30. Stopping optimization.
Last 5 losses: [1.920180511660874e-05, 1.920180511660874e-05, 1.920180511660874e-05, 1.920180511660874e-05, 1.920180511660874e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.920180511660874e-05

Optimization complete. Final v2v error: 3.680274724960327 mm

Highest mean error: 4.981553554534912 mm for frame 160

Lowest mean error: 3.150705099105835 mm for frame 219

Saving results

Total time: 26.995615005493164
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00433101
Iteration 2/25 | Loss: 0.00104970
Iteration 3/25 | Loss: 0.00095306
Iteration 4/25 | Loss: 0.00093427
Iteration 5/25 | Loss: 0.00092562
Iteration 6/25 | Loss: 0.00092400
Iteration 7/25 | Loss: 0.00092363
Iteration 8/25 | Loss: 0.00092363
Iteration 9/25 | Loss: 0.00092363
Iteration 10/25 | Loss: 0.00092363
Iteration 11/25 | Loss: 0.00092363
Iteration 12/25 | Loss: 0.00092363
Iteration 13/25 | Loss: 0.00092363
Iteration 14/25 | Loss: 0.00092363
Iteration 15/25 | Loss: 0.00092363
Iteration 16/25 | Loss: 0.00092363
Iteration 17/25 | Loss: 0.00092363
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0009236311307176948, 0.0009236311307176948, 0.0009236311307176948, 0.0009236311307176948, 0.0009236311307176948]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009236311307176948

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42637026
Iteration 2/25 | Loss: 0.00062554
Iteration 3/25 | Loss: 0.00062553
Iteration 4/25 | Loss: 0.00062553
Iteration 5/25 | Loss: 0.00062553
Iteration 6/25 | Loss: 0.00062553
Iteration 7/25 | Loss: 0.00062553
Iteration 8/25 | Loss: 0.00062553
Iteration 9/25 | Loss: 0.00062553
Iteration 10/25 | Loss: 0.00062553
Iteration 11/25 | Loss: 0.00062553
Iteration 12/25 | Loss: 0.00062553
Iteration 13/25 | Loss: 0.00062553
Iteration 14/25 | Loss: 0.00062553
Iteration 15/25 | Loss: 0.00062553
Iteration 16/25 | Loss: 0.00062553
Iteration 17/25 | Loss: 0.00062553
Iteration 18/25 | Loss: 0.00062553
Iteration 19/25 | Loss: 0.00062553
Iteration 20/25 | Loss: 0.00062553
Iteration 21/25 | Loss: 0.00062553
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0006255306070670485, 0.0006255306070670485, 0.0006255306070670485, 0.0006255306070670485, 0.0006255306070670485]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006255306070670485

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062553
Iteration 2/1000 | Loss: 0.00003661
Iteration 3/1000 | Loss: 0.00002115
Iteration 4/1000 | Loss: 0.00002008
Iteration 5/1000 | Loss: 0.00001938
Iteration 6/1000 | Loss: 0.00001884
Iteration 7/1000 | Loss: 0.00001852
Iteration 8/1000 | Loss: 0.00001833
Iteration 9/1000 | Loss: 0.00001823
Iteration 10/1000 | Loss: 0.00001821
Iteration 11/1000 | Loss: 0.00001817
Iteration 12/1000 | Loss: 0.00001817
Iteration 13/1000 | Loss: 0.00001816
Iteration 14/1000 | Loss: 0.00001816
Iteration 15/1000 | Loss: 0.00001815
Iteration 16/1000 | Loss: 0.00001815
Iteration 17/1000 | Loss: 0.00001812
Iteration 18/1000 | Loss: 0.00001811
Iteration 19/1000 | Loss: 0.00001811
Iteration 20/1000 | Loss: 0.00001811
Iteration 21/1000 | Loss: 0.00001811
Iteration 22/1000 | Loss: 0.00001811
Iteration 23/1000 | Loss: 0.00001811
Iteration 24/1000 | Loss: 0.00001811
Iteration 25/1000 | Loss: 0.00001809
Iteration 26/1000 | Loss: 0.00001809
Iteration 27/1000 | Loss: 0.00001808
Iteration 28/1000 | Loss: 0.00001808
Iteration 29/1000 | Loss: 0.00001808
Iteration 30/1000 | Loss: 0.00001808
Iteration 31/1000 | Loss: 0.00001808
Iteration 32/1000 | Loss: 0.00001808
Iteration 33/1000 | Loss: 0.00001808
Iteration 34/1000 | Loss: 0.00001808
Iteration 35/1000 | Loss: 0.00001808
Iteration 36/1000 | Loss: 0.00001808
Iteration 37/1000 | Loss: 0.00001807
Iteration 38/1000 | Loss: 0.00001807
Iteration 39/1000 | Loss: 0.00001807
Iteration 40/1000 | Loss: 0.00001807
Iteration 41/1000 | Loss: 0.00001807
Iteration 42/1000 | Loss: 0.00001807
Iteration 43/1000 | Loss: 0.00001807
Iteration 44/1000 | Loss: 0.00001807
Iteration 45/1000 | Loss: 0.00001806
Iteration 46/1000 | Loss: 0.00001806
Iteration 47/1000 | Loss: 0.00001805
Iteration 48/1000 | Loss: 0.00001805
Iteration 49/1000 | Loss: 0.00001805
Iteration 50/1000 | Loss: 0.00001805
Iteration 51/1000 | Loss: 0.00001805
Iteration 52/1000 | Loss: 0.00001805
Iteration 53/1000 | Loss: 0.00001805
Iteration 54/1000 | Loss: 0.00001805
Iteration 55/1000 | Loss: 0.00001805
Iteration 56/1000 | Loss: 0.00001805
Iteration 57/1000 | Loss: 0.00001805
Iteration 58/1000 | Loss: 0.00001805
Iteration 59/1000 | Loss: 0.00001805
Iteration 60/1000 | Loss: 0.00001805
Iteration 61/1000 | Loss: 0.00001805
Iteration 62/1000 | Loss: 0.00001805
Iteration 63/1000 | Loss: 0.00001805
Iteration 64/1000 | Loss: 0.00001805
Iteration 65/1000 | Loss: 0.00001805
Iteration 66/1000 | Loss: 0.00001805
Iteration 67/1000 | Loss: 0.00001805
Iteration 68/1000 | Loss: 0.00001805
Iteration 69/1000 | Loss: 0.00001805
Iteration 70/1000 | Loss: 0.00001805
Iteration 71/1000 | Loss: 0.00001805
Iteration 72/1000 | Loss: 0.00001805
Iteration 73/1000 | Loss: 0.00001805
Iteration 74/1000 | Loss: 0.00001805
Iteration 75/1000 | Loss: 0.00001805
Iteration 76/1000 | Loss: 0.00001805
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [1.8046624973067082e-05, 1.8046624973067082e-05, 1.8046624973067082e-05, 1.8046624973067082e-05, 1.8046624973067082e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8046624973067082e-05

Optimization complete. Final v2v error: 3.6825969219207764 mm

Highest mean error: 3.9852652549743652 mm for frame 99

Lowest mean error: 3.4041895866394043 mm for frame 61

Saving results

Total time: 25.177139282226562
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01032268
Iteration 2/25 | Loss: 0.00189506
Iteration 3/25 | Loss: 0.00123237
Iteration 4/25 | Loss: 0.00117116
Iteration 5/25 | Loss: 0.00114754
Iteration 6/25 | Loss: 0.00113917
Iteration 7/25 | Loss: 0.00113760
Iteration 8/25 | Loss: 0.00113720
Iteration 9/25 | Loss: 0.00113720
Iteration 10/25 | Loss: 0.00113720
Iteration 11/25 | Loss: 0.00113720
Iteration 12/25 | Loss: 0.00113720
Iteration 13/25 | Loss: 0.00113720
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0011371950386092067, 0.0011371950386092067, 0.0011371950386092067, 0.0011371950386092067, 0.0011371950386092067]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011371950386092067

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.99592161
Iteration 2/25 | Loss: 0.00070522
Iteration 3/25 | Loss: 0.00070522
Iteration 4/25 | Loss: 0.00070522
Iteration 5/25 | Loss: 0.00070521
Iteration 6/25 | Loss: 0.00070521
Iteration 7/25 | Loss: 0.00070521
Iteration 8/25 | Loss: 0.00070521
Iteration 9/25 | Loss: 0.00070521
Iteration 10/25 | Loss: 0.00070521
Iteration 11/25 | Loss: 0.00070521
Iteration 12/25 | Loss: 0.00070521
Iteration 13/25 | Loss: 0.00070521
Iteration 14/25 | Loss: 0.00070521
Iteration 15/25 | Loss: 0.00070521
Iteration 16/25 | Loss: 0.00070521
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.000705213169567287, 0.000705213169567287, 0.000705213169567287, 0.000705213169567287, 0.000705213169567287]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000705213169567287

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00070521
Iteration 2/1000 | Loss: 0.00007960
Iteration 3/1000 | Loss: 0.00005917
Iteration 4/1000 | Loss: 0.00005562
Iteration 5/1000 | Loss: 0.00005303
Iteration 6/1000 | Loss: 0.00005131
Iteration 7/1000 | Loss: 0.00005024
Iteration 8/1000 | Loss: 0.00004956
Iteration 9/1000 | Loss: 0.00004906
Iteration 10/1000 | Loss: 0.00004863
Iteration 11/1000 | Loss: 0.00004839
Iteration 12/1000 | Loss: 0.00004837
Iteration 13/1000 | Loss: 0.00004819
Iteration 14/1000 | Loss: 0.00004817
Iteration 15/1000 | Loss: 0.00004804
Iteration 16/1000 | Loss: 0.00004799
Iteration 17/1000 | Loss: 0.00004793
Iteration 18/1000 | Loss: 0.00004781
Iteration 19/1000 | Loss: 0.00004777
Iteration 20/1000 | Loss: 0.00004773
Iteration 21/1000 | Loss: 0.00004767
Iteration 22/1000 | Loss: 0.00004767
Iteration 23/1000 | Loss: 0.00004767
Iteration 24/1000 | Loss: 0.00004766
Iteration 25/1000 | Loss: 0.00004760
Iteration 26/1000 | Loss: 0.00004759
Iteration 27/1000 | Loss: 0.00004756
Iteration 28/1000 | Loss: 0.00004756
Iteration 29/1000 | Loss: 0.00004755
Iteration 30/1000 | Loss: 0.00004752
Iteration 31/1000 | Loss: 0.00004752
Iteration 32/1000 | Loss: 0.00004751
Iteration 33/1000 | Loss: 0.00004751
Iteration 34/1000 | Loss: 0.00004750
Iteration 35/1000 | Loss: 0.00004750
Iteration 36/1000 | Loss: 0.00004749
Iteration 37/1000 | Loss: 0.00004749
Iteration 38/1000 | Loss: 0.00004749
Iteration 39/1000 | Loss: 0.00004749
Iteration 40/1000 | Loss: 0.00004748
Iteration 41/1000 | Loss: 0.00004748
Iteration 42/1000 | Loss: 0.00004748
Iteration 43/1000 | Loss: 0.00004748
Iteration 44/1000 | Loss: 0.00004747
Iteration 45/1000 | Loss: 0.00004747
Iteration 46/1000 | Loss: 0.00004746
Iteration 47/1000 | Loss: 0.00004745
Iteration 48/1000 | Loss: 0.00004744
Iteration 49/1000 | Loss: 0.00004744
Iteration 50/1000 | Loss: 0.00004742
Iteration 51/1000 | Loss: 0.00004742
Iteration 52/1000 | Loss: 0.00004741
Iteration 53/1000 | Loss: 0.00004741
Iteration 54/1000 | Loss: 0.00004741
Iteration 55/1000 | Loss: 0.00004740
Iteration 56/1000 | Loss: 0.00004740
Iteration 57/1000 | Loss: 0.00004739
Iteration 58/1000 | Loss: 0.00004739
Iteration 59/1000 | Loss: 0.00004739
Iteration 60/1000 | Loss: 0.00004739
Iteration 61/1000 | Loss: 0.00004739
Iteration 62/1000 | Loss: 0.00004738
Iteration 63/1000 | Loss: 0.00004738
Iteration 64/1000 | Loss: 0.00004738
Iteration 65/1000 | Loss: 0.00004737
Iteration 66/1000 | Loss: 0.00004737
Iteration 67/1000 | Loss: 0.00004737
Iteration 68/1000 | Loss: 0.00004736
Iteration 69/1000 | Loss: 0.00004736
Iteration 70/1000 | Loss: 0.00004736
Iteration 71/1000 | Loss: 0.00004736
Iteration 72/1000 | Loss: 0.00004735
Iteration 73/1000 | Loss: 0.00004735
Iteration 74/1000 | Loss: 0.00004735
Iteration 75/1000 | Loss: 0.00004734
Iteration 76/1000 | Loss: 0.00004734
Iteration 77/1000 | Loss: 0.00004734
Iteration 78/1000 | Loss: 0.00004733
Iteration 79/1000 | Loss: 0.00004733
Iteration 80/1000 | Loss: 0.00004733
Iteration 81/1000 | Loss: 0.00004733
Iteration 82/1000 | Loss: 0.00004733
Iteration 83/1000 | Loss: 0.00004733
Iteration 84/1000 | Loss: 0.00004733
Iteration 85/1000 | Loss: 0.00004733
Iteration 86/1000 | Loss: 0.00004732
Iteration 87/1000 | Loss: 0.00004732
Iteration 88/1000 | Loss: 0.00004732
Iteration 89/1000 | Loss: 0.00004732
Iteration 90/1000 | Loss: 0.00004732
Iteration 91/1000 | Loss: 0.00004732
Iteration 92/1000 | Loss: 0.00004732
Iteration 93/1000 | Loss: 0.00004732
Iteration 94/1000 | Loss: 0.00004732
Iteration 95/1000 | Loss: 0.00004732
Iteration 96/1000 | Loss: 0.00004732
Iteration 97/1000 | Loss: 0.00004731
Iteration 98/1000 | Loss: 0.00004731
Iteration 99/1000 | Loss: 0.00004731
Iteration 100/1000 | Loss: 0.00004731
Iteration 101/1000 | Loss: 0.00004730
Iteration 102/1000 | Loss: 0.00004730
Iteration 103/1000 | Loss: 0.00004730
Iteration 104/1000 | Loss: 0.00004730
Iteration 105/1000 | Loss: 0.00004730
Iteration 106/1000 | Loss: 0.00004729
Iteration 107/1000 | Loss: 0.00004729
Iteration 108/1000 | Loss: 0.00004729
Iteration 109/1000 | Loss: 0.00004729
Iteration 110/1000 | Loss: 0.00004729
Iteration 111/1000 | Loss: 0.00004729
Iteration 112/1000 | Loss: 0.00004729
Iteration 113/1000 | Loss: 0.00004729
Iteration 114/1000 | Loss: 0.00004728
Iteration 115/1000 | Loss: 0.00004728
Iteration 116/1000 | Loss: 0.00004728
Iteration 117/1000 | Loss: 0.00004728
Iteration 118/1000 | Loss: 0.00004728
Iteration 119/1000 | Loss: 0.00004728
Iteration 120/1000 | Loss: 0.00004728
Iteration 121/1000 | Loss: 0.00004728
Iteration 122/1000 | Loss: 0.00004728
Iteration 123/1000 | Loss: 0.00004728
Iteration 124/1000 | Loss: 0.00004728
Iteration 125/1000 | Loss: 0.00004727
Iteration 126/1000 | Loss: 0.00004727
Iteration 127/1000 | Loss: 0.00004727
Iteration 128/1000 | Loss: 0.00004727
Iteration 129/1000 | Loss: 0.00004727
Iteration 130/1000 | Loss: 0.00004727
Iteration 131/1000 | Loss: 0.00004727
Iteration 132/1000 | Loss: 0.00004727
Iteration 133/1000 | Loss: 0.00004726
Iteration 134/1000 | Loss: 0.00004726
Iteration 135/1000 | Loss: 0.00004726
Iteration 136/1000 | Loss: 0.00004726
Iteration 137/1000 | Loss: 0.00004725
Iteration 138/1000 | Loss: 0.00004725
Iteration 139/1000 | Loss: 0.00004725
Iteration 140/1000 | Loss: 0.00004725
Iteration 141/1000 | Loss: 0.00004725
Iteration 142/1000 | Loss: 0.00004725
Iteration 143/1000 | Loss: 0.00004725
Iteration 144/1000 | Loss: 0.00004725
Iteration 145/1000 | Loss: 0.00004724
Iteration 146/1000 | Loss: 0.00004724
Iteration 147/1000 | Loss: 0.00004724
Iteration 148/1000 | Loss: 0.00004724
Iteration 149/1000 | Loss: 0.00004724
Iteration 150/1000 | Loss: 0.00004724
Iteration 151/1000 | Loss: 0.00004724
Iteration 152/1000 | Loss: 0.00004723
Iteration 153/1000 | Loss: 0.00004723
Iteration 154/1000 | Loss: 0.00004723
Iteration 155/1000 | Loss: 0.00004723
Iteration 156/1000 | Loss: 0.00004723
Iteration 157/1000 | Loss: 0.00004723
Iteration 158/1000 | Loss: 0.00004722
Iteration 159/1000 | Loss: 0.00004722
Iteration 160/1000 | Loss: 0.00004721
Iteration 161/1000 | Loss: 0.00004721
Iteration 162/1000 | Loss: 0.00004721
Iteration 163/1000 | Loss: 0.00004721
Iteration 164/1000 | Loss: 0.00004721
Iteration 165/1000 | Loss: 0.00004721
Iteration 166/1000 | Loss: 0.00004721
Iteration 167/1000 | Loss: 0.00004721
Iteration 168/1000 | Loss: 0.00004721
Iteration 169/1000 | Loss: 0.00004721
Iteration 170/1000 | Loss: 0.00004720
Iteration 171/1000 | Loss: 0.00004720
Iteration 172/1000 | Loss: 0.00004720
Iteration 173/1000 | Loss: 0.00004719
Iteration 174/1000 | Loss: 0.00004719
Iteration 175/1000 | Loss: 0.00004719
Iteration 176/1000 | Loss: 0.00004719
Iteration 177/1000 | Loss: 0.00004719
Iteration 178/1000 | Loss: 0.00004719
Iteration 179/1000 | Loss: 0.00004718
Iteration 180/1000 | Loss: 0.00004718
Iteration 181/1000 | Loss: 0.00004718
Iteration 182/1000 | Loss: 0.00004718
Iteration 183/1000 | Loss: 0.00004718
Iteration 184/1000 | Loss: 0.00004718
Iteration 185/1000 | Loss: 0.00004718
Iteration 186/1000 | Loss: 0.00004717
Iteration 187/1000 | Loss: 0.00004717
Iteration 188/1000 | Loss: 0.00004717
Iteration 189/1000 | Loss: 0.00004717
Iteration 190/1000 | Loss: 0.00004717
Iteration 191/1000 | Loss: 0.00004716
Iteration 192/1000 | Loss: 0.00004716
Iteration 193/1000 | Loss: 0.00004716
Iteration 194/1000 | Loss: 0.00004716
Iteration 195/1000 | Loss: 0.00004716
Iteration 196/1000 | Loss: 0.00004716
Iteration 197/1000 | Loss: 0.00004716
Iteration 198/1000 | Loss: 0.00004715
Iteration 199/1000 | Loss: 0.00004715
Iteration 200/1000 | Loss: 0.00004715
Iteration 201/1000 | Loss: 0.00004715
Iteration 202/1000 | Loss: 0.00004715
Iteration 203/1000 | Loss: 0.00004715
Iteration 204/1000 | Loss: 0.00004715
Iteration 205/1000 | Loss: 0.00004715
Iteration 206/1000 | Loss: 0.00004714
Iteration 207/1000 | Loss: 0.00004714
Iteration 208/1000 | Loss: 0.00004714
Iteration 209/1000 | Loss: 0.00004714
Iteration 210/1000 | Loss: 0.00004713
Iteration 211/1000 | Loss: 0.00004713
Iteration 212/1000 | Loss: 0.00004713
Iteration 213/1000 | Loss: 0.00004713
Iteration 214/1000 | Loss: 0.00004713
Iteration 215/1000 | Loss: 0.00004712
Iteration 216/1000 | Loss: 0.00004712
Iteration 217/1000 | Loss: 0.00004712
Iteration 218/1000 | Loss: 0.00004712
Iteration 219/1000 | Loss: 0.00004712
Iteration 220/1000 | Loss: 0.00004712
Iteration 221/1000 | Loss: 0.00004711
Iteration 222/1000 | Loss: 0.00004711
Iteration 223/1000 | Loss: 0.00004711
Iteration 224/1000 | Loss: 0.00004711
Iteration 225/1000 | Loss: 0.00004711
Iteration 226/1000 | Loss: 0.00004711
Iteration 227/1000 | Loss: 0.00004711
Iteration 228/1000 | Loss: 0.00004711
Iteration 229/1000 | Loss: 0.00004711
Iteration 230/1000 | Loss: 0.00004711
Iteration 231/1000 | Loss: 0.00004711
Iteration 232/1000 | Loss: 0.00004711
Iteration 233/1000 | Loss: 0.00004711
Iteration 234/1000 | Loss: 0.00004711
Iteration 235/1000 | Loss: 0.00004711
Iteration 236/1000 | Loss: 0.00004711
Iteration 237/1000 | Loss: 0.00004710
Iteration 238/1000 | Loss: 0.00004710
Iteration 239/1000 | Loss: 0.00004710
Iteration 240/1000 | Loss: 0.00004710
Iteration 241/1000 | Loss: 0.00004710
Iteration 242/1000 | Loss: 0.00004710
Iteration 243/1000 | Loss: 0.00004710
Iteration 244/1000 | Loss: 0.00004710
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 244. Stopping optimization.
Last 5 losses: [4.71046005259268e-05, 4.71046005259268e-05, 4.71046005259268e-05, 4.71046005259268e-05, 4.71046005259268e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.71046005259268e-05

Optimization complete. Final v2v error: 5.540703296661377 mm

Highest mean error: 7.011594295501709 mm for frame 117

Lowest mean error: 4.329105377197266 mm for frame 0

Saving results

Total time: 58.47480750083923
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00473053
Iteration 2/25 | Loss: 0.00125199
Iteration 3/25 | Loss: 0.00108630
Iteration 4/25 | Loss: 0.00105742
Iteration 5/25 | Loss: 0.00104958
Iteration 6/25 | Loss: 0.00104867
Iteration 7/25 | Loss: 0.00104867
Iteration 8/25 | Loss: 0.00104867
Iteration 9/25 | Loss: 0.00104864
Iteration 10/25 | Loss: 0.00104864
Iteration 11/25 | Loss: 0.00104864
Iteration 12/25 | Loss: 0.00104864
Iteration 13/25 | Loss: 0.00104864
Iteration 14/25 | Loss: 0.00104864
Iteration 15/25 | Loss: 0.00104864
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0010486352257430553, 0.0010486352257430553, 0.0010486352257430553, 0.0010486352257430553, 0.0010486352257430553]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010486352257430553

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43185103
Iteration 2/25 | Loss: 0.00079773
Iteration 3/25 | Loss: 0.00079773
Iteration 4/25 | Loss: 0.00079773
Iteration 5/25 | Loss: 0.00079773
Iteration 6/25 | Loss: 0.00079773
Iteration 7/25 | Loss: 0.00079773
Iteration 8/25 | Loss: 0.00079773
Iteration 9/25 | Loss: 0.00079773
Iteration 10/25 | Loss: 0.00079773
Iteration 11/25 | Loss: 0.00079773
Iteration 12/25 | Loss: 0.00079773
Iteration 13/25 | Loss: 0.00079773
Iteration 14/25 | Loss: 0.00079773
Iteration 15/25 | Loss: 0.00079773
Iteration 16/25 | Loss: 0.00079773
Iteration 17/25 | Loss: 0.00079773
Iteration 18/25 | Loss: 0.00079773
Iteration 19/25 | Loss: 0.00079773
Iteration 20/25 | Loss: 0.00079773
Iteration 21/25 | Loss: 0.00079773
Iteration 22/25 | Loss: 0.00079773
Iteration 23/25 | Loss: 0.00079773
Iteration 24/25 | Loss: 0.00079773
Iteration 25/25 | Loss: 0.00079773

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079773
Iteration 2/1000 | Loss: 0.00006432
Iteration 3/1000 | Loss: 0.00004290
Iteration 4/1000 | Loss: 0.00004004
Iteration 5/1000 | Loss: 0.00003782
Iteration 6/1000 | Loss: 0.00003606
Iteration 7/1000 | Loss: 0.00003494
Iteration 8/1000 | Loss: 0.00003417
Iteration 9/1000 | Loss: 0.00003368
Iteration 10/1000 | Loss: 0.00003334
Iteration 11/1000 | Loss: 0.00003316
Iteration 12/1000 | Loss: 0.00003315
Iteration 13/1000 | Loss: 0.00003314
Iteration 14/1000 | Loss: 0.00003314
Iteration 15/1000 | Loss: 0.00003309
Iteration 16/1000 | Loss: 0.00003309
Iteration 17/1000 | Loss: 0.00003307
Iteration 18/1000 | Loss: 0.00003305
Iteration 19/1000 | Loss: 0.00003305
Iteration 20/1000 | Loss: 0.00003304
Iteration 21/1000 | Loss: 0.00003304
Iteration 22/1000 | Loss: 0.00003303
Iteration 23/1000 | Loss: 0.00003303
Iteration 24/1000 | Loss: 0.00003302
Iteration 25/1000 | Loss: 0.00003302
Iteration 26/1000 | Loss: 0.00003301
Iteration 27/1000 | Loss: 0.00003301
Iteration 28/1000 | Loss: 0.00003301
Iteration 29/1000 | Loss: 0.00003301
Iteration 30/1000 | Loss: 0.00003301
Iteration 31/1000 | Loss: 0.00003301
Iteration 32/1000 | Loss: 0.00003301
Iteration 33/1000 | Loss: 0.00003301
Iteration 34/1000 | Loss: 0.00003301
Iteration 35/1000 | Loss: 0.00003301
Iteration 36/1000 | Loss: 0.00003301
Iteration 37/1000 | Loss: 0.00003301
Iteration 38/1000 | Loss: 0.00003301
Iteration 39/1000 | Loss: 0.00003301
Iteration 40/1000 | Loss: 0.00003301
Iteration 41/1000 | Loss: 0.00003300
Iteration 42/1000 | Loss: 0.00003300
Iteration 43/1000 | Loss: 0.00003300
Iteration 44/1000 | Loss: 0.00003299
Iteration 45/1000 | Loss: 0.00003299
Iteration 46/1000 | Loss: 0.00003299
Iteration 47/1000 | Loss: 0.00003299
Iteration 48/1000 | Loss: 0.00003299
Iteration 49/1000 | Loss: 0.00003299
Iteration 50/1000 | Loss: 0.00003299
Iteration 51/1000 | Loss: 0.00003299
Iteration 52/1000 | Loss: 0.00003299
Iteration 53/1000 | Loss: 0.00003299
Iteration 54/1000 | Loss: 0.00003299
Iteration 55/1000 | Loss: 0.00003299
Iteration 56/1000 | Loss: 0.00003299
Iteration 57/1000 | Loss: 0.00003299
Iteration 58/1000 | Loss: 0.00003299
Iteration 59/1000 | Loss: 0.00003299
Iteration 60/1000 | Loss: 0.00003299
Iteration 61/1000 | Loss: 0.00003299
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 61. Stopping optimization.
Last 5 losses: [3.298735464341007e-05, 3.298735464341007e-05, 3.298735464341007e-05, 3.298735464341007e-05, 3.298735464341007e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.298735464341007e-05

Optimization complete. Final v2v error: 4.855129241943359 mm

Highest mean error: 5.422906875610352 mm for frame 176

Lowest mean error: 4.333724498748779 mm for frame 214

Saving results

Total time: 31.196453094482422
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00813911
Iteration 2/25 | Loss: 0.00202094
Iteration 3/25 | Loss: 0.00147157
Iteration 4/25 | Loss: 0.00126277
Iteration 5/25 | Loss: 0.00110816
Iteration 6/25 | Loss: 0.00106697
Iteration 7/25 | Loss: 0.00105822
Iteration 8/25 | Loss: 0.00105665
Iteration 9/25 | Loss: 0.00105851
Iteration 10/25 | Loss: 0.00105389
Iteration 11/25 | Loss: 0.00105045
Iteration 12/25 | Loss: 0.00104965
Iteration 13/25 | Loss: 0.00104835
Iteration 14/25 | Loss: 0.00104738
Iteration 15/25 | Loss: 0.00104625
Iteration 16/25 | Loss: 0.00104555
Iteration 17/25 | Loss: 0.00104550
Iteration 18/25 | Loss: 0.00104550
Iteration 19/25 | Loss: 0.00104550
Iteration 20/25 | Loss: 0.00104550
Iteration 21/25 | Loss: 0.00104550
Iteration 22/25 | Loss: 0.00104549
Iteration 23/25 | Loss: 0.00104549
Iteration 24/25 | Loss: 0.00104549
Iteration 25/25 | Loss: 0.00104549

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50614941
Iteration 2/25 | Loss: 0.00090872
Iteration 3/25 | Loss: 0.00090872
Iteration 4/25 | Loss: 0.00090872
Iteration 5/25 | Loss: 0.00090872
Iteration 6/25 | Loss: 0.00090872
Iteration 7/25 | Loss: 0.00090872
Iteration 8/25 | Loss: 0.00090872
Iteration 9/25 | Loss: 0.00090872
Iteration 10/25 | Loss: 0.00090872
Iteration 11/25 | Loss: 0.00090872
Iteration 12/25 | Loss: 0.00090872
Iteration 13/25 | Loss: 0.00090872
Iteration 14/25 | Loss: 0.00090872
Iteration 15/25 | Loss: 0.00090872
Iteration 16/25 | Loss: 0.00090872
Iteration 17/25 | Loss: 0.00090872
Iteration 18/25 | Loss: 0.00090872
Iteration 19/25 | Loss: 0.00090872
Iteration 20/25 | Loss: 0.00090872
Iteration 21/25 | Loss: 0.00090872
Iteration 22/25 | Loss: 0.00090872
Iteration 23/25 | Loss: 0.00090872
Iteration 24/25 | Loss: 0.00090872
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0009087196085602045, 0.0009087196085602045, 0.0009087196085602045, 0.0009087196085602045, 0.0009087196085602045]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009087196085602045

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00090872
Iteration 2/1000 | Loss: 0.00005747
Iteration 3/1000 | Loss: 0.00003609
Iteration 4/1000 | Loss: 0.00003052
Iteration 5/1000 | Loss: 0.00002839
Iteration 6/1000 | Loss: 0.00002743
Iteration 7/1000 | Loss: 0.00002685
Iteration 8/1000 | Loss: 0.00002637
Iteration 9/1000 | Loss: 0.00002603
Iteration 10/1000 | Loss: 0.00002573
Iteration 11/1000 | Loss: 0.00002553
Iteration 12/1000 | Loss: 0.00002538
Iteration 13/1000 | Loss: 0.00002537
Iteration 14/1000 | Loss: 0.00002531
Iteration 15/1000 | Loss: 0.00002528
Iteration 16/1000 | Loss: 0.00002527
Iteration 17/1000 | Loss: 0.00002526
Iteration 18/1000 | Loss: 0.00002524
Iteration 19/1000 | Loss: 0.00002522
Iteration 20/1000 | Loss: 0.00002522
Iteration 21/1000 | Loss: 0.00002522
Iteration 22/1000 | Loss: 0.00002521
Iteration 23/1000 | Loss: 0.00002521
Iteration 24/1000 | Loss: 0.00002520
Iteration 25/1000 | Loss: 0.00002519
Iteration 26/1000 | Loss: 0.00002519
Iteration 27/1000 | Loss: 0.00002519
Iteration 28/1000 | Loss: 0.00002518
Iteration 29/1000 | Loss: 0.00002518
Iteration 30/1000 | Loss: 0.00002517
Iteration 31/1000 | Loss: 0.00002517
Iteration 32/1000 | Loss: 0.00002517
Iteration 33/1000 | Loss: 0.00002517
Iteration 34/1000 | Loss: 0.00002517
Iteration 35/1000 | Loss: 0.00002516
Iteration 36/1000 | Loss: 0.00002516
Iteration 37/1000 | Loss: 0.00002516
Iteration 38/1000 | Loss: 0.00002516
Iteration 39/1000 | Loss: 0.00002516
Iteration 40/1000 | Loss: 0.00002515
Iteration 41/1000 | Loss: 0.00002515
Iteration 42/1000 | Loss: 0.00002515
Iteration 43/1000 | Loss: 0.00002514
Iteration 44/1000 | Loss: 0.00002514
Iteration 45/1000 | Loss: 0.00002514
Iteration 46/1000 | Loss: 0.00002514
Iteration 47/1000 | Loss: 0.00002514
Iteration 48/1000 | Loss: 0.00002514
Iteration 49/1000 | Loss: 0.00002514
Iteration 50/1000 | Loss: 0.00002514
Iteration 51/1000 | Loss: 0.00002513
Iteration 52/1000 | Loss: 0.00002513
Iteration 53/1000 | Loss: 0.00002513
Iteration 54/1000 | Loss: 0.00002513
Iteration 55/1000 | Loss: 0.00002513
Iteration 56/1000 | Loss: 0.00002513
Iteration 57/1000 | Loss: 0.00002512
Iteration 58/1000 | Loss: 0.00002512
Iteration 59/1000 | Loss: 0.00002512
Iteration 60/1000 | Loss: 0.00002512
Iteration 61/1000 | Loss: 0.00002512
Iteration 62/1000 | Loss: 0.00002512
Iteration 63/1000 | Loss: 0.00002512
Iteration 64/1000 | Loss: 0.00002512
Iteration 65/1000 | Loss: 0.00002512
Iteration 66/1000 | Loss: 0.00002512
Iteration 67/1000 | Loss: 0.00002512
Iteration 68/1000 | Loss: 0.00002512
Iteration 69/1000 | Loss: 0.00002512
Iteration 70/1000 | Loss: 0.00002512
Iteration 71/1000 | Loss: 0.00002512
Iteration 72/1000 | Loss: 0.00002512
Iteration 73/1000 | Loss: 0.00002512
Iteration 74/1000 | Loss: 0.00002512
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 74. Stopping optimization.
Last 5 losses: [2.5120145437540486e-05, 2.5120145437540486e-05, 2.5120145437540486e-05, 2.5120145437540486e-05, 2.5120145437540486e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5120145437540486e-05

Optimization complete. Final v2v error: 4.239411354064941 mm

Highest mean error: 5.22601318359375 mm for frame 129

Lowest mean error: 3.7983250617980957 mm for frame 1

Saving results

Total time: 57.273295164108276
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01183656
Iteration 2/25 | Loss: 0.00477238
Iteration 3/25 | Loss: 0.00304906
Iteration 4/25 | Loss: 0.00292925
Iteration 5/25 | Loss: 0.00231461
Iteration 6/25 | Loss: 0.00187039
Iteration 7/25 | Loss: 0.00154771
Iteration 8/25 | Loss: 0.00140827
Iteration 9/25 | Loss: 0.00125968
Iteration 10/25 | Loss: 0.00122052
Iteration 11/25 | Loss: 0.00119561
Iteration 12/25 | Loss: 0.00117642
Iteration 13/25 | Loss: 0.00116237
Iteration 14/25 | Loss: 0.00115388
Iteration 15/25 | Loss: 0.00114382
Iteration 16/25 | Loss: 0.00113531
Iteration 17/25 | Loss: 0.00112863
Iteration 18/25 | Loss: 0.00113020
Iteration 19/25 | Loss: 0.00112533
Iteration 20/25 | Loss: 0.00112325
Iteration 21/25 | Loss: 0.00112104
Iteration 22/25 | Loss: 0.00111964
Iteration 23/25 | Loss: 0.00111809
Iteration 24/25 | Loss: 0.00111830
Iteration 25/25 | Loss: 0.00111814

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.56964904
Iteration 2/25 | Loss: 0.00075634
Iteration 3/25 | Loss: 0.00075634
Iteration 4/25 | Loss: 0.00075634
Iteration 5/25 | Loss: 0.00075634
Iteration 6/25 | Loss: 0.00075633
Iteration 7/25 | Loss: 0.00075633
Iteration 8/25 | Loss: 0.00075633
Iteration 9/25 | Loss: 0.00075633
Iteration 10/25 | Loss: 0.00075633
Iteration 11/25 | Loss: 0.00075633
Iteration 12/25 | Loss: 0.00075633
Iteration 13/25 | Loss: 0.00075633
Iteration 14/25 | Loss: 0.00075633
Iteration 15/25 | Loss: 0.00075633
Iteration 16/25 | Loss: 0.00075633
Iteration 17/25 | Loss: 0.00075633
Iteration 18/25 | Loss: 0.00075633
Iteration 19/25 | Loss: 0.00075633
Iteration 20/25 | Loss: 0.00075633
Iteration 21/25 | Loss: 0.00075633
Iteration 22/25 | Loss: 0.00075633
Iteration 23/25 | Loss: 0.00075633
Iteration 24/25 | Loss: 0.00075633
Iteration 25/25 | Loss: 0.00075633

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075633
Iteration 2/1000 | Loss: 0.00007054
Iteration 3/1000 | Loss: 0.00005187
Iteration 4/1000 | Loss: 0.00004381
Iteration 5/1000 | Loss: 0.00006626
Iteration 6/1000 | Loss: 0.00005275
Iteration 7/1000 | Loss: 0.00004179
Iteration 8/1000 | Loss: 0.00005194
Iteration 9/1000 | Loss: 0.00206854
Iteration 10/1000 | Loss: 0.00020856
Iteration 11/1000 | Loss: 0.00004497
Iteration 12/1000 | Loss: 0.00013297
Iteration 13/1000 | Loss: 0.00003343
Iteration 14/1000 | Loss: 0.00006844
Iteration 15/1000 | Loss: 0.00005559
Iteration 16/1000 | Loss: 0.00002938
Iteration 17/1000 | Loss: 0.00003102
Iteration 18/1000 | Loss: 0.00002894
Iteration 19/1000 | Loss: 0.00002997
Iteration 20/1000 | Loss: 0.00002772
Iteration 21/1000 | Loss: 0.00002725
Iteration 22/1000 | Loss: 0.00002703
Iteration 23/1000 | Loss: 0.00002696
Iteration 24/1000 | Loss: 0.00002695
Iteration 25/1000 | Loss: 0.00002683
Iteration 26/1000 | Loss: 0.00002682
Iteration 27/1000 | Loss: 0.00002682
Iteration 28/1000 | Loss: 0.00002680
Iteration 29/1000 | Loss: 0.00002673
Iteration 30/1000 | Loss: 0.00002673
Iteration 31/1000 | Loss: 0.00002673
Iteration 32/1000 | Loss: 0.00002672
Iteration 33/1000 | Loss: 0.00002672
Iteration 34/1000 | Loss: 0.00002672
Iteration 35/1000 | Loss: 0.00002672
Iteration 36/1000 | Loss: 0.00002672
Iteration 37/1000 | Loss: 0.00002671
Iteration 38/1000 | Loss: 0.00002670
Iteration 39/1000 | Loss: 0.00002670
Iteration 40/1000 | Loss: 0.00002670
Iteration 41/1000 | Loss: 0.00002670
Iteration 42/1000 | Loss: 0.00002670
Iteration 43/1000 | Loss: 0.00002669
Iteration 44/1000 | Loss: 0.00002669
Iteration 45/1000 | Loss: 0.00002669
Iteration 46/1000 | Loss: 0.00002669
Iteration 47/1000 | Loss: 0.00002669
Iteration 48/1000 | Loss: 0.00002669
Iteration 49/1000 | Loss: 0.00002669
Iteration 50/1000 | Loss: 0.00002669
Iteration 51/1000 | Loss: 0.00002669
Iteration 52/1000 | Loss: 0.00002669
Iteration 53/1000 | Loss: 0.00002668
Iteration 54/1000 | Loss: 0.00002668
Iteration 55/1000 | Loss: 0.00002668
Iteration 56/1000 | Loss: 0.00002668
Iteration 57/1000 | Loss: 0.00002668
Iteration 58/1000 | Loss: 0.00002668
Iteration 59/1000 | Loss: 0.00002668
Iteration 60/1000 | Loss: 0.00002668
Iteration 61/1000 | Loss: 0.00002668
Iteration 62/1000 | Loss: 0.00002668
Iteration 63/1000 | Loss: 0.00002668
Iteration 64/1000 | Loss: 0.00002668
Iteration 65/1000 | Loss: 0.00002668
Iteration 66/1000 | Loss: 0.00002668
Iteration 67/1000 | Loss: 0.00002668
Iteration 68/1000 | Loss: 0.00002668
Iteration 69/1000 | Loss: 0.00002668
Iteration 70/1000 | Loss: 0.00002668
Iteration 71/1000 | Loss: 0.00002668
Iteration 72/1000 | Loss: 0.00002668
Iteration 73/1000 | Loss: 0.00002668
Iteration 74/1000 | Loss: 0.00002668
Iteration 75/1000 | Loss: 0.00002668
Iteration 76/1000 | Loss: 0.00002668
Iteration 77/1000 | Loss: 0.00002668
Iteration 78/1000 | Loss: 0.00002668
Iteration 79/1000 | Loss: 0.00002668
Iteration 80/1000 | Loss: 0.00002668
Iteration 81/1000 | Loss: 0.00002668
Iteration 82/1000 | Loss: 0.00002668
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 82. Stopping optimization.
Last 5 losses: [2.6680849259719253e-05, 2.6680849259719253e-05, 2.6680849259719253e-05, 2.6680849259719253e-05, 2.6680849259719253e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6680849259719253e-05

Optimization complete. Final v2v error: 4.4623613357543945 mm

Highest mean error: 9.21621036529541 mm for frame 98

Lowest mean error: 4.247495651245117 mm for frame 175

Saving results

Total time: 91.15744137763977
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01143463
Iteration 2/25 | Loss: 0.00202865
Iteration 3/25 | Loss: 0.00127128
Iteration 4/25 | Loss: 0.00112629
Iteration 5/25 | Loss: 0.00110357
Iteration 6/25 | Loss: 0.00109795
Iteration 7/25 | Loss: 0.00109712
Iteration 8/25 | Loss: 0.00109712
Iteration 9/25 | Loss: 0.00109712
Iteration 10/25 | Loss: 0.00109712
Iteration 11/25 | Loss: 0.00109712
Iteration 12/25 | Loss: 0.00109712
Iteration 13/25 | Loss: 0.00109712
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0010971209267154336, 0.0010971209267154336, 0.0010971209267154336, 0.0010971209267154336, 0.0010971209267154336]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010971209267154336

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.93738586
Iteration 2/25 | Loss: 0.00108891
Iteration 3/25 | Loss: 0.00108890
Iteration 4/25 | Loss: 0.00108890
Iteration 5/25 | Loss: 0.00108890
Iteration 6/25 | Loss: 0.00108890
Iteration 7/25 | Loss: 0.00108890
Iteration 8/25 | Loss: 0.00108890
Iteration 9/25 | Loss: 0.00108890
Iteration 10/25 | Loss: 0.00108890
Iteration 11/25 | Loss: 0.00108890
Iteration 12/25 | Loss: 0.00108890
Iteration 13/25 | Loss: 0.00108890
Iteration 14/25 | Loss: 0.00108890
Iteration 15/25 | Loss: 0.00108890
Iteration 16/25 | Loss: 0.00108890
Iteration 17/25 | Loss: 0.00108890
Iteration 18/25 | Loss: 0.00108890
Iteration 19/25 | Loss: 0.00108890
Iteration 20/25 | Loss: 0.00108890
Iteration 21/25 | Loss: 0.00108890
Iteration 22/25 | Loss: 0.00108890
Iteration 23/25 | Loss: 0.00108890
Iteration 24/25 | Loss: 0.00108890
Iteration 25/25 | Loss: 0.00108890

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00108890
Iteration 2/1000 | Loss: 0.00005344
Iteration 3/1000 | Loss: 0.00004224
Iteration 4/1000 | Loss: 0.00003932
Iteration 5/1000 | Loss: 0.00003785
Iteration 6/1000 | Loss: 0.00003686
Iteration 7/1000 | Loss: 0.00003640
Iteration 8/1000 | Loss: 0.00003605
Iteration 9/1000 | Loss: 0.00003583
Iteration 10/1000 | Loss: 0.00003559
Iteration 11/1000 | Loss: 0.00003536
Iteration 12/1000 | Loss: 0.00003524
Iteration 13/1000 | Loss: 0.00003512
Iteration 14/1000 | Loss: 0.00003501
Iteration 15/1000 | Loss: 0.00003494
Iteration 16/1000 | Loss: 0.00003494
Iteration 17/1000 | Loss: 0.00003492
Iteration 18/1000 | Loss: 0.00003488
Iteration 19/1000 | Loss: 0.00003488
Iteration 20/1000 | Loss: 0.00003486
Iteration 21/1000 | Loss: 0.00003485
Iteration 22/1000 | Loss: 0.00003485
Iteration 23/1000 | Loss: 0.00003485
Iteration 24/1000 | Loss: 0.00003485
Iteration 25/1000 | Loss: 0.00003485
Iteration 26/1000 | Loss: 0.00003485
Iteration 27/1000 | Loss: 0.00003485
Iteration 28/1000 | Loss: 0.00003485
Iteration 29/1000 | Loss: 0.00003484
Iteration 30/1000 | Loss: 0.00003484
Iteration 31/1000 | Loss: 0.00003484
Iteration 32/1000 | Loss: 0.00003482
Iteration 33/1000 | Loss: 0.00003482
Iteration 34/1000 | Loss: 0.00003482
Iteration 35/1000 | Loss: 0.00003481
Iteration 36/1000 | Loss: 0.00003479
Iteration 37/1000 | Loss: 0.00003477
Iteration 38/1000 | Loss: 0.00003475
Iteration 39/1000 | Loss: 0.00003473
Iteration 40/1000 | Loss: 0.00003473
Iteration 41/1000 | Loss: 0.00003473
Iteration 42/1000 | Loss: 0.00003473
Iteration 43/1000 | Loss: 0.00003472
Iteration 44/1000 | Loss: 0.00003472
Iteration 45/1000 | Loss: 0.00003472
Iteration 46/1000 | Loss: 0.00003472
Iteration 47/1000 | Loss: 0.00003472
Iteration 48/1000 | Loss: 0.00003472
Iteration 49/1000 | Loss: 0.00003472
Iteration 50/1000 | Loss: 0.00003472
Iteration 51/1000 | Loss: 0.00003472
Iteration 52/1000 | Loss: 0.00003472
Iteration 53/1000 | Loss: 0.00003471
Iteration 54/1000 | Loss: 0.00003471
Iteration 55/1000 | Loss: 0.00003470
Iteration 56/1000 | Loss: 0.00003469
Iteration 57/1000 | Loss: 0.00003469
Iteration 58/1000 | Loss: 0.00003468
Iteration 59/1000 | Loss: 0.00003467
Iteration 60/1000 | Loss: 0.00003467
Iteration 61/1000 | Loss: 0.00003466
Iteration 62/1000 | Loss: 0.00003466
Iteration 63/1000 | Loss: 0.00003465
Iteration 64/1000 | Loss: 0.00003465
Iteration 65/1000 | Loss: 0.00003463
Iteration 66/1000 | Loss: 0.00003462
Iteration 67/1000 | Loss: 0.00003462
Iteration 68/1000 | Loss: 0.00003462
Iteration 69/1000 | Loss: 0.00003462
Iteration 70/1000 | Loss: 0.00003462
Iteration 71/1000 | Loss: 0.00003461
Iteration 72/1000 | Loss: 0.00003458
Iteration 73/1000 | Loss: 0.00003458
Iteration 74/1000 | Loss: 0.00003458
Iteration 75/1000 | Loss: 0.00003458
Iteration 76/1000 | Loss: 0.00003458
Iteration 77/1000 | Loss: 0.00003458
Iteration 78/1000 | Loss: 0.00003458
Iteration 79/1000 | Loss: 0.00003458
Iteration 80/1000 | Loss: 0.00003458
Iteration 81/1000 | Loss: 0.00003457
Iteration 82/1000 | Loss: 0.00003457
Iteration 83/1000 | Loss: 0.00003457
Iteration 84/1000 | Loss: 0.00003454
Iteration 85/1000 | Loss: 0.00003451
Iteration 86/1000 | Loss: 0.00003451
Iteration 87/1000 | Loss: 0.00003446
Iteration 88/1000 | Loss: 0.00003446
Iteration 89/1000 | Loss: 0.00003446
Iteration 90/1000 | Loss: 0.00003446
Iteration 91/1000 | Loss: 0.00003446
Iteration 92/1000 | Loss: 0.00003446
Iteration 93/1000 | Loss: 0.00003446
Iteration 94/1000 | Loss: 0.00003446
Iteration 95/1000 | Loss: 0.00003446
Iteration 96/1000 | Loss: 0.00003446
Iteration 97/1000 | Loss: 0.00003446
Iteration 98/1000 | Loss: 0.00003445
Iteration 99/1000 | Loss: 0.00003445
Iteration 100/1000 | Loss: 0.00003443
Iteration 101/1000 | Loss: 0.00003443
Iteration 102/1000 | Loss: 0.00003443
Iteration 103/1000 | Loss: 0.00003443
Iteration 104/1000 | Loss: 0.00003443
Iteration 105/1000 | Loss: 0.00003443
Iteration 106/1000 | Loss: 0.00003443
Iteration 107/1000 | Loss: 0.00003442
Iteration 108/1000 | Loss: 0.00003442
Iteration 109/1000 | Loss: 0.00003442
Iteration 110/1000 | Loss: 0.00003442
Iteration 111/1000 | Loss: 0.00003442
Iteration 112/1000 | Loss: 0.00003441
Iteration 113/1000 | Loss: 0.00003441
Iteration 114/1000 | Loss: 0.00003441
Iteration 115/1000 | Loss: 0.00003441
Iteration 116/1000 | Loss: 0.00003440
Iteration 117/1000 | Loss: 0.00003440
Iteration 118/1000 | Loss: 0.00003440
Iteration 119/1000 | Loss: 0.00003439
Iteration 120/1000 | Loss: 0.00003439
Iteration 121/1000 | Loss: 0.00003439
Iteration 122/1000 | Loss: 0.00003439
Iteration 123/1000 | Loss: 0.00003439
Iteration 124/1000 | Loss: 0.00003439
Iteration 125/1000 | Loss: 0.00003439
Iteration 126/1000 | Loss: 0.00003439
Iteration 127/1000 | Loss: 0.00003438
Iteration 128/1000 | Loss: 0.00003438
Iteration 129/1000 | Loss: 0.00003438
Iteration 130/1000 | Loss: 0.00003437
Iteration 131/1000 | Loss: 0.00003437
Iteration 132/1000 | Loss: 0.00003437
Iteration 133/1000 | Loss: 0.00003436
Iteration 134/1000 | Loss: 0.00003436
Iteration 135/1000 | Loss: 0.00003436
Iteration 136/1000 | Loss: 0.00003435
Iteration 137/1000 | Loss: 0.00003435
Iteration 138/1000 | Loss: 0.00003435
Iteration 139/1000 | Loss: 0.00003435
Iteration 140/1000 | Loss: 0.00003435
Iteration 141/1000 | Loss: 0.00003435
Iteration 142/1000 | Loss: 0.00003435
Iteration 143/1000 | Loss: 0.00003435
Iteration 144/1000 | Loss: 0.00003435
Iteration 145/1000 | Loss: 0.00003435
Iteration 146/1000 | Loss: 0.00003435
Iteration 147/1000 | Loss: 0.00003435
Iteration 148/1000 | Loss: 0.00003435
Iteration 149/1000 | Loss: 0.00003434
Iteration 150/1000 | Loss: 0.00003433
Iteration 151/1000 | Loss: 0.00003433
Iteration 152/1000 | Loss: 0.00003433
Iteration 153/1000 | Loss: 0.00003432
Iteration 154/1000 | Loss: 0.00003432
Iteration 155/1000 | Loss: 0.00003432
Iteration 156/1000 | Loss: 0.00003432
Iteration 157/1000 | Loss: 0.00003432
Iteration 158/1000 | Loss: 0.00003432
Iteration 159/1000 | Loss: 0.00003432
Iteration 160/1000 | Loss: 0.00003432
Iteration 161/1000 | Loss: 0.00003431
Iteration 162/1000 | Loss: 0.00003431
Iteration 163/1000 | Loss: 0.00003431
Iteration 164/1000 | Loss: 0.00003431
Iteration 165/1000 | Loss: 0.00003431
Iteration 166/1000 | Loss: 0.00003431
Iteration 167/1000 | Loss: 0.00003431
Iteration 168/1000 | Loss: 0.00003431
Iteration 169/1000 | Loss: 0.00003431
Iteration 170/1000 | Loss: 0.00003431
Iteration 171/1000 | Loss: 0.00003430
Iteration 172/1000 | Loss: 0.00003430
Iteration 173/1000 | Loss: 0.00003430
Iteration 174/1000 | Loss: 0.00003430
Iteration 175/1000 | Loss: 0.00003430
Iteration 176/1000 | Loss: 0.00003430
Iteration 177/1000 | Loss: 0.00003430
Iteration 178/1000 | Loss: 0.00003430
Iteration 179/1000 | Loss: 0.00003430
Iteration 180/1000 | Loss: 0.00003429
Iteration 181/1000 | Loss: 0.00003429
Iteration 182/1000 | Loss: 0.00003429
Iteration 183/1000 | Loss: 0.00003429
Iteration 184/1000 | Loss: 0.00003429
Iteration 185/1000 | Loss: 0.00003429
Iteration 186/1000 | Loss: 0.00003428
Iteration 187/1000 | Loss: 0.00003428
Iteration 188/1000 | Loss: 0.00003427
Iteration 189/1000 | Loss: 0.00003427
Iteration 190/1000 | Loss: 0.00003427
Iteration 191/1000 | Loss: 0.00003427
Iteration 192/1000 | Loss: 0.00003427
Iteration 193/1000 | Loss: 0.00003427
Iteration 194/1000 | Loss: 0.00003426
Iteration 195/1000 | Loss: 0.00003426
Iteration 196/1000 | Loss: 0.00003426
Iteration 197/1000 | Loss: 0.00003426
Iteration 198/1000 | Loss: 0.00003426
Iteration 199/1000 | Loss: 0.00003426
Iteration 200/1000 | Loss: 0.00003426
Iteration 201/1000 | Loss: 0.00003425
Iteration 202/1000 | Loss: 0.00003425
Iteration 203/1000 | Loss: 0.00003425
Iteration 204/1000 | Loss: 0.00003425
Iteration 205/1000 | Loss: 0.00003425
Iteration 206/1000 | Loss: 0.00003424
Iteration 207/1000 | Loss: 0.00003424
Iteration 208/1000 | Loss: 0.00003423
Iteration 209/1000 | Loss: 0.00003423
Iteration 210/1000 | Loss: 0.00003423
Iteration 211/1000 | Loss: 0.00003422
Iteration 212/1000 | Loss: 0.00003422
Iteration 213/1000 | Loss: 0.00003422
Iteration 214/1000 | Loss: 0.00003422
Iteration 215/1000 | Loss: 0.00003422
Iteration 216/1000 | Loss: 0.00003421
Iteration 217/1000 | Loss: 0.00003420
Iteration 218/1000 | Loss: 0.00003420
Iteration 219/1000 | Loss: 0.00003420
Iteration 220/1000 | Loss: 0.00003420
Iteration 221/1000 | Loss: 0.00003420
Iteration 222/1000 | Loss: 0.00003420
Iteration 223/1000 | Loss: 0.00003420
Iteration 224/1000 | Loss: 0.00003420
Iteration 225/1000 | Loss: 0.00003420
Iteration 226/1000 | Loss: 0.00003420
Iteration 227/1000 | Loss: 0.00003420
Iteration 228/1000 | Loss: 0.00003419
Iteration 229/1000 | Loss: 0.00003419
Iteration 230/1000 | Loss: 0.00003419
Iteration 231/1000 | Loss: 0.00003419
Iteration 232/1000 | Loss: 0.00003419
Iteration 233/1000 | Loss: 0.00003419
Iteration 234/1000 | Loss: 0.00003418
Iteration 235/1000 | Loss: 0.00003418
Iteration 236/1000 | Loss: 0.00003418
Iteration 237/1000 | Loss: 0.00003417
Iteration 238/1000 | Loss: 0.00003417
Iteration 239/1000 | Loss: 0.00003417
Iteration 240/1000 | Loss: 0.00003417
Iteration 241/1000 | Loss: 0.00003417
Iteration 242/1000 | Loss: 0.00003417
Iteration 243/1000 | Loss: 0.00003417
Iteration 244/1000 | Loss: 0.00003417
Iteration 245/1000 | Loss: 0.00003417
Iteration 246/1000 | Loss: 0.00003417
Iteration 247/1000 | Loss: 0.00003417
Iteration 248/1000 | Loss: 0.00003417
Iteration 249/1000 | Loss: 0.00003417
Iteration 250/1000 | Loss: 0.00003417
Iteration 251/1000 | Loss: 0.00003417
Iteration 252/1000 | Loss: 0.00003417
Iteration 253/1000 | Loss: 0.00003417
Iteration 254/1000 | Loss: 0.00003417
Iteration 255/1000 | Loss: 0.00003417
Iteration 256/1000 | Loss: 0.00003417
Iteration 257/1000 | Loss: 0.00003417
Iteration 258/1000 | Loss: 0.00003417
Iteration 259/1000 | Loss: 0.00003417
Iteration 260/1000 | Loss: 0.00003417
Iteration 261/1000 | Loss: 0.00003417
Iteration 262/1000 | Loss: 0.00003417
Iteration 263/1000 | Loss: 0.00003417
Iteration 264/1000 | Loss: 0.00003417
Iteration 265/1000 | Loss: 0.00003417
Iteration 266/1000 | Loss: 0.00003417
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 266. Stopping optimization.
Last 5 losses: [3.416701656533405e-05, 3.416701656533405e-05, 3.416701656533405e-05, 3.416701656533405e-05, 3.416701656533405e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.416701656533405e-05

Optimization complete. Final v2v error: 4.854121208190918 mm

Highest mean error: 5.486517906188965 mm for frame 11

Lowest mean error: 4.257331371307373 mm for frame 155

Saving results

Total time: 57.887492656707764
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00919821
Iteration 2/25 | Loss: 0.00124568
Iteration 3/25 | Loss: 0.00095432
Iteration 4/25 | Loss: 0.00085410
Iteration 5/25 | Loss: 0.00084357
Iteration 6/25 | Loss: 0.00083580
Iteration 7/25 | Loss: 0.00083818
Iteration 8/25 | Loss: 0.00083507
Iteration 9/25 | Loss: 0.00083797
Iteration 10/25 | Loss: 0.00083379
Iteration 11/25 | Loss: 0.00083711
Iteration 12/25 | Loss: 0.00083251
Iteration 13/25 | Loss: 0.00083321
Iteration 14/25 | Loss: 0.00083213
Iteration 15/25 | Loss: 0.00083228
Iteration 16/25 | Loss: 0.00083219
Iteration 17/25 | Loss: 0.00083162
Iteration 18/25 | Loss: 0.00083223
Iteration 19/25 | Loss: 0.00083175
Iteration 20/25 | Loss: 0.00083223
Iteration 21/25 | Loss: 0.00083172
Iteration 22/25 | Loss: 0.00083233
Iteration 23/25 | Loss: 0.00083187
Iteration 24/25 | Loss: 0.00083247
Iteration 25/25 | Loss: 0.00083195

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.58158541
Iteration 2/25 | Loss: 0.00051874
Iteration 3/25 | Loss: 0.00051872
Iteration 4/25 | Loss: 0.00051872
Iteration 5/25 | Loss: 0.00051872
Iteration 6/25 | Loss: 0.00051872
Iteration 7/25 | Loss: 0.00051872
Iteration 8/25 | Loss: 0.00051872
Iteration 9/25 | Loss: 0.00051872
Iteration 10/25 | Loss: 0.00051872
Iteration 11/25 | Loss: 0.00051871
Iteration 12/25 | Loss: 0.00051871
Iteration 13/25 | Loss: 0.00051871
Iteration 14/25 | Loss: 0.00051871
Iteration 15/25 | Loss: 0.00051871
Iteration 16/25 | Loss: 0.00051871
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0005187148926779628, 0.0005187148926779628, 0.0005187148926779628, 0.0005187148926779628, 0.0005187148926779628]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005187148926779628

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00051871
Iteration 2/1000 | Loss: 0.00002270
Iteration 3/1000 | Loss: 0.00001710
Iteration 4/1000 | Loss: 0.00001601
Iteration 5/1000 | Loss: 0.00001612
Iteration 6/1000 | Loss: 0.00001559
Iteration 7/1000 | Loss: 0.00001543
Iteration 8/1000 | Loss: 0.00001505
Iteration 9/1000 | Loss: 0.00001504
Iteration 10/1000 | Loss: 0.00001504
Iteration 11/1000 | Loss: 0.00001532
Iteration 12/1000 | Loss: 0.00001480
Iteration 13/1000 | Loss: 0.00001489
Iteration 14/1000 | Loss: 0.00001510
Iteration 15/1000 | Loss: 0.00001495
Iteration 16/1000 | Loss: 0.00001522
Iteration 17/1000 | Loss: 0.00001523
Iteration 18/1000 | Loss: 0.00001506
Iteration 19/1000 | Loss: 0.00001548
Iteration 20/1000 | Loss: 0.00001490
Iteration 21/1000 | Loss: 0.00001473
Iteration 22/1000 | Loss: 0.00001473
Iteration 23/1000 | Loss: 0.00001473
Iteration 24/1000 | Loss: 0.00001464
Iteration 25/1000 | Loss: 0.00001476
Iteration 26/1000 | Loss: 0.00001468
Iteration 27/1000 | Loss: 0.00001494
Iteration 28/1000 | Loss: 0.00001480
Iteration 29/1000 | Loss: 0.00001499
Iteration 30/1000 | Loss: 0.00001498
Iteration 31/1000 | Loss: 0.00001497
Iteration 32/1000 | Loss: 0.00001509
Iteration 33/1000 | Loss: 0.00001497
Iteration 34/1000 | Loss: 0.00001512
Iteration 35/1000 | Loss: 0.00001510
Iteration 36/1000 | Loss: 0.00001519
Iteration 37/1000 | Loss: 0.00001513
Iteration 38/1000 | Loss: 0.00001529
Iteration 39/1000 | Loss: 0.00001513
Iteration 40/1000 | Loss: 0.00001511
Iteration 41/1000 | Loss: 0.00001505
Iteration 42/1000 | Loss: 0.00001536
Iteration 43/1000 | Loss: 0.00001505
Iteration 44/1000 | Loss: 0.00001515
Iteration 45/1000 | Loss: 0.00001517
Iteration 46/1000 | Loss: 0.00001516
Iteration 47/1000 | Loss: 0.00001539
Iteration 48/1000 | Loss: 0.00001514
Iteration 49/1000 | Loss: 0.00001522
Iteration 50/1000 | Loss: 0.00001532
Iteration 51/1000 | Loss: 0.00001516
Iteration 52/1000 | Loss: 0.00001527
Iteration 53/1000 | Loss: 0.00001522
Iteration 54/1000 | Loss: 0.00001527
Iteration 55/1000 | Loss: 0.00001527
Iteration 56/1000 | Loss: 0.00001536
Iteration 57/1000 | Loss: 0.00001535
Iteration 58/1000 | Loss: 0.00001513
Iteration 59/1000 | Loss: 0.00001505
Iteration 60/1000 | Loss: 0.00001516
Iteration 61/1000 | Loss: 0.00001501
Iteration 62/1000 | Loss: 0.00001495
Iteration 63/1000 | Loss: 0.00001505
Iteration 64/1000 | Loss: 0.00001495
Iteration 65/1000 | Loss: 0.00001502
Iteration 66/1000 | Loss: 0.00001505
Iteration 67/1000 | Loss: 0.00001501
Iteration 68/1000 | Loss: 0.00001520
Iteration 69/1000 | Loss: 0.00001493
Iteration 70/1000 | Loss: 0.00001505
Iteration 71/1000 | Loss: 0.00001504
Iteration 72/1000 | Loss: 0.00001526
Iteration 73/1000 | Loss: 0.00001504
Iteration 74/1000 | Loss: 0.00001515
Iteration 75/1000 | Loss: 0.00001494
Iteration 76/1000 | Loss: 0.00001515
Iteration 77/1000 | Loss: 0.00001500
Iteration 78/1000 | Loss: 0.00001499
Iteration 79/1000 | Loss: 0.00001468
Iteration 80/1000 | Loss: 0.00001461
Iteration 81/1000 | Loss: 0.00001471
Iteration 82/1000 | Loss: 0.00001484
Iteration 83/1000 | Loss: 0.00001449
Iteration 84/1000 | Loss: 0.00001436
Iteration 85/1000 | Loss: 0.00001440
Iteration 86/1000 | Loss: 0.00001488
Iteration 87/1000 | Loss: 0.00001489
Iteration 88/1000 | Loss: 0.00001497
Iteration 89/1000 | Loss: 0.00001515
Iteration 90/1000 | Loss: 0.00001501
Iteration 91/1000 | Loss: 0.00001512
Iteration 92/1000 | Loss: 0.00001512
Iteration 93/1000 | Loss: 0.00001516
Iteration 94/1000 | Loss: 0.00001512
Iteration 95/1000 | Loss: 0.00001497
Iteration 96/1000 | Loss: 0.00001476
Iteration 97/1000 | Loss: 0.00001476
Iteration 98/1000 | Loss: 0.00001466
Iteration 99/1000 | Loss: 0.00001492
Iteration 100/1000 | Loss: 0.00001498
Iteration 101/1000 | Loss: 0.00001507
Iteration 102/1000 | Loss: 0.00001516
Iteration 103/1000 | Loss: 0.00001515
Iteration 104/1000 | Loss: 0.00001509
Iteration 105/1000 | Loss: 0.00001511
Iteration 106/1000 | Loss: 0.00001507
Iteration 107/1000 | Loss: 0.00001517
Iteration 108/1000 | Loss: 0.00001509
Iteration 109/1000 | Loss: 0.00001509
Iteration 110/1000 | Loss: 0.00001474
Iteration 111/1000 | Loss: 0.00001455
Iteration 112/1000 | Loss: 0.00001501
Iteration 113/1000 | Loss: 0.00001507
Iteration 114/1000 | Loss: 0.00001503
Iteration 115/1000 | Loss: 0.00001505
Iteration 116/1000 | Loss: 0.00001481
Iteration 117/1000 | Loss: 0.00001456
Iteration 118/1000 | Loss: 0.00001470
Iteration 119/1000 | Loss: 0.00001498
Iteration 120/1000 | Loss: 0.00001495
Iteration 121/1000 | Loss: 0.00001515
Iteration 122/1000 | Loss: 0.00001467
Iteration 123/1000 | Loss: 0.00001467
Iteration 124/1000 | Loss: 0.00001467
Iteration 125/1000 | Loss: 0.00001511
Iteration 126/1000 | Loss: 0.00001509
Iteration 127/1000 | Loss: 0.00001515
Iteration 128/1000 | Loss: 0.00001526
Iteration 129/1000 | Loss: 0.00001510
Iteration 130/1000 | Loss: 0.00001521
Iteration 131/1000 | Loss: 0.00001442
Iteration 132/1000 | Loss: 0.00001423
Iteration 133/1000 | Loss: 0.00001422
Iteration 134/1000 | Loss: 0.00001422
Iteration 135/1000 | Loss: 0.00001422
Iteration 136/1000 | Loss: 0.00001481
Iteration 137/1000 | Loss: 0.00001481
Iteration 138/1000 | Loss: 0.00001488
Iteration 139/1000 | Loss: 0.00001422
Iteration 140/1000 | Loss: 0.00001421
Iteration 141/1000 | Loss: 0.00001421
Iteration 142/1000 | Loss: 0.00001420
Iteration 143/1000 | Loss: 0.00001420
Iteration 144/1000 | Loss: 0.00001420
Iteration 145/1000 | Loss: 0.00001419
Iteration 146/1000 | Loss: 0.00001419
Iteration 147/1000 | Loss: 0.00001419
Iteration 148/1000 | Loss: 0.00001419
Iteration 149/1000 | Loss: 0.00001419
Iteration 150/1000 | Loss: 0.00001419
Iteration 151/1000 | Loss: 0.00001419
Iteration 152/1000 | Loss: 0.00001419
Iteration 153/1000 | Loss: 0.00001419
Iteration 154/1000 | Loss: 0.00001419
Iteration 155/1000 | Loss: 0.00001418
Iteration 156/1000 | Loss: 0.00001418
Iteration 157/1000 | Loss: 0.00001418
Iteration 158/1000 | Loss: 0.00001418
Iteration 159/1000 | Loss: 0.00001418
Iteration 160/1000 | Loss: 0.00001418
Iteration 161/1000 | Loss: 0.00001418
Iteration 162/1000 | Loss: 0.00001418
Iteration 163/1000 | Loss: 0.00001418
Iteration 164/1000 | Loss: 0.00001418
Iteration 165/1000 | Loss: 0.00001417
Iteration 166/1000 | Loss: 0.00001417
Iteration 167/1000 | Loss: 0.00001417
Iteration 168/1000 | Loss: 0.00001417
Iteration 169/1000 | Loss: 0.00001417
Iteration 170/1000 | Loss: 0.00001417
Iteration 171/1000 | Loss: 0.00001417
Iteration 172/1000 | Loss: 0.00001417
Iteration 173/1000 | Loss: 0.00001417
Iteration 174/1000 | Loss: 0.00001417
Iteration 175/1000 | Loss: 0.00001417
Iteration 176/1000 | Loss: 0.00001417
Iteration 177/1000 | Loss: 0.00001417
Iteration 178/1000 | Loss: 0.00001417
Iteration 179/1000 | Loss: 0.00001417
Iteration 180/1000 | Loss: 0.00001417
Iteration 181/1000 | Loss: 0.00001417
Iteration 182/1000 | Loss: 0.00001417
Iteration 183/1000 | Loss: 0.00001417
Iteration 184/1000 | Loss: 0.00001417
Iteration 185/1000 | Loss: 0.00001416
Iteration 186/1000 | Loss: 0.00001416
Iteration 187/1000 | Loss: 0.00001416
Iteration 188/1000 | Loss: 0.00001416
Iteration 189/1000 | Loss: 0.00001416
Iteration 190/1000 | Loss: 0.00001416
Iteration 191/1000 | Loss: 0.00001416
Iteration 192/1000 | Loss: 0.00001416
Iteration 193/1000 | Loss: 0.00001416
Iteration 194/1000 | Loss: 0.00001416
Iteration 195/1000 | Loss: 0.00001416
Iteration 196/1000 | Loss: 0.00001416
Iteration 197/1000 | Loss: 0.00001416
Iteration 198/1000 | Loss: 0.00001416
Iteration 199/1000 | Loss: 0.00001416
Iteration 200/1000 | Loss: 0.00001416
Iteration 201/1000 | Loss: 0.00001416
Iteration 202/1000 | Loss: 0.00001416
Iteration 203/1000 | Loss: 0.00001416
Iteration 204/1000 | Loss: 0.00001416
Iteration 205/1000 | Loss: 0.00001416
Iteration 206/1000 | Loss: 0.00001416
Iteration 207/1000 | Loss: 0.00001416
Iteration 208/1000 | Loss: 0.00001416
Iteration 209/1000 | Loss: 0.00001416
Iteration 210/1000 | Loss: 0.00001416
Iteration 211/1000 | Loss: 0.00001416
Iteration 212/1000 | Loss: 0.00001416
Iteration 213/1000 | Loss: 0.00001416
Iteration 214/1000 | Loss: 0.00001416
Iteration 215/1000 | Loss: 0.00001416
Iteration 216/1000 | Loss: 0.00001416
Iteration 217/1000 | Loss: 0.00001416
Iteration 218/1000 | Loss: 0.00001416
Iteration 219/1000 | Loss: 0.00001416
Iteration 220/1000 | Loss: 0.00001416
Iteration 221/1000 | Loss: 0.00001416
Iteration 222/1000 | Loss: 0.00001416
Iteration 223/1000 | Loss: 0.00001416
Iteration 224/1000 | Loss: 0.00001416
Iteration 225/1000 | Loss: 0.00001416
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 225. Stopping optimization.
Last 5 losses: [1.4157622899801936e-05, 1.4157622899801936e-05, 1.4157622899801936e-05, 1.4157622899801936e-05, 1.4157622899801936e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4157622899801936e-05

Optimization complete. Final v2v error: 3.223837375640869 mm

Highest mean error: 9.447712898254395 mm for frame 79

Lowest mean error: 2.757871627807617 mm for frame 78

Saving results

Total time: 216.73137760162354
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00554480
Iteration 2/25 | Loss: 0.00134219
Iteration 3/25 | Loss: 0.00120949
Iteration 4/25 | Loss: 0.00116746
Iteration 5/25 | Loss: 0.00115604
Iteration 6/25 | Loss: 0.00115374
Iteration 7/25 | Loss: 0.00115374
Iteration 8/25 | Loss: 0.00115374
Iteration 9/25 | Loss: 0.00115374
Iteration 10/25 | Loss: 0.00115374
Iteration 11/25 | Loss: 0.00115374
Iteration 12/25 | Loss: 0.00115374
Iteration 13/25 | Loss: 0.00115374
Iteration 14/25 | Loss: 0.00115374
Iteration 15/25 | Loss: 0.00115374
Iteration 16/25 | Loss: 0.00115374
Iteration 17/25 | Loss: 0.00115374
Iteration 18/25 | Loss: 0.00115374
Iteration 19/25 | Loss: 0.00115374
Iteration 20/25 | Loss: 0.00115374
Iteration 21/25 | Loss: 0.00115374
Iteration 22/25 | Loss: 0.00115374
Iteration 23/25 | Loss: 0.00115374
Iteration 24/25 | Loss: 0.00115374
Iteration 25/25 | Loss: 0.00115374

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.06174994
Iteration 2/25 | Loss: 0.00093098
Iteration 3/25 | Loss: 0.00093095
Iteration 4/25 | Loss: 0.00093095
Iteration 5/25 | Loss: 0.00093095
Iteration 6/25 | Loss: 0.00093095
Iteration 7/25 | Loss: 0.00093095
Iteration 8/25 | Loss: 0.00093095
Iteration 9/25 | Loss: 0.00093095
Iteration 10/25 | Loss: 0.00093095
Iteration 11/25 | Loss: 0.00093095
Iteration 12/25 | Loss: 0.00093095
Iteration 13/25 | Loss: 0.00093095
Iteration 14/25 | Loss: 0.00093095
Iteration 15/25 | Loss: 0.00093095
Iteration 16/25 | Loss: 0.00093095
Iteration 17/25 | Loss: 0.00093095
Iteration 18/25 | Loss: 0.00093095
Iteration 19/25 | Loss: 0.00093095
Iteration 20/25 | Loss: 0.00093095
Iteration 21/25 | Loss: 0.00093095
Iteration 22/25 | Loss: 0.00093095
Iteration 23/25 | Loss: 0.00093095
Iteration 24/25 | Loss: 0.00093095
Iteration 25/25 | Loss: 0.00093095

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00093095
Iteration 2/1000 | Loss: 0.00005546
Iteration 3/1000 | Loss: 0.00004507
Iteration 4/1000 | Loss: 0.00004016
Iteration 5/1000 | Loss: 0.00003724
Iteration 6/1000 | Loss: 0.00003550
Iteration 7/1000 | Loss: 0.00003484
Iteration 8/1000 | Loss: 0.00003435
Iteration 9/1000 | Loss: 0.00003398
Iteration 10/1000 | Loss: 0.00003378
Iteration 11/1000 | Loss: 0.00003376
Iteration 12/1000 | Loss: 0.00003373
Iteration 13/1000 | Loss: 0.00003373
Iteration 14/1000 | Loss: 0.00003373
Iteration 15/1000 | Loss: 0.00003373
Iteration 16/1000 | Loss: 0.00003372
Iteration 17/1000 | Loss: 0.00003369
Iteration 18/1000 | Loss: 0.00003368
Iteration 19/1000 | Loss: 0.00003368
Iteration 20/1000 | Loss: 0.00003367
Iteration 21/1000 | Loss: 0.00003364
Iteration 22/1000 | Loss: 0.00003363
Iteration 23/1000 | Loss: 0.00003363
Iteration 24/1000 | Loss: 0.00003363
Iteration 25/1000 | Loss: 0.00003362
Iteration 26/1000 | Loss: 0.00003361
Iteration 27/1000 | Loss: 0.00003360
Iteration 28/1000 | Loss: 0.00003360
Iteration 29/1000 | Loss: 0.00003360
Iteration 30/1000 | Loss: 0.00003360
Iteration 31/1000 | Loss: 0.00003360
Iteration 32/1000 | Loss: 0.00003360
Iteration 33/1000 | Loss: 0.00003360
Iteration 34/1000 | Loss: 0.00003360
Iteration 35/1000 | Loss: 0.00003359
Iteration 36/1000 | Loss: 0.00003359
Iteration 37/1000 | Loss: 0.00003359
Iteration 38/1000 | Loss: 0.00003359
Iteration 39/1000 | Loss: 0.00003358
Iteration 40/1000 | Loss: 0.00003358
Iteration 41/1000 | Loss: 0.00003358
Iteration 42/1000 | Loss: 0.00003358
Iteration 43/1000 | Loss: 0.00003358
Iteration 44/1000 | Loss: 0.00003358
Iteration 45/1000 | Loss: 0.00003358
Iteration 46/1000 | Loss: 0.00003358
Iteration 47/1000 | Loss: 0.00003357
Iteration 48/1000 | Loss: 0.00003355
Iteration 49/1000 | Loss: 0.00003355
Iteration 50/1000 | Loss: 0.00003355
Iteration 51/1000 | Loss: 0.00003354
Iteration 52/1000 | Loss: 0.00003354
Iteration 53/1000 | Loss: 0.00003354
Iteration 54/1000 | Loss: 0.00003354
Iteration 55/1000 | Loss: 0.00003354
Iteration 56/1000 | Loss: 0.00003353
Iteration 57/1000 | Loss: 0.00003352
Iteration 58/1000 | Loss: 0.00003351
Iteration 59/1000 | Loss: 0.00003351
Iteration 60/1000 | Loss: 0.00003351
Iteration 61/1000 | Loss: 0.00003351
Iteration 62/1000 | Loss: 0.00003351
Iteration 63/1000 | Loss: 0.00003351
Iteration 64/1000 | Loss: 0.00003351
Iteration 65/1000 | Loss: 0.00003351
Iteration 66/1000 | Loss: 0.00003351
Iteration 67/1000 | Loss: 0.00003351
Iteration 68/1000 | Loss: 0.00003351
Iteration 69/1000 | Loss: 0.00003351
Iteration 70/1000 | Loss: 0.00003351
Iteration 71/1000 | Loss: 0.00003350
Iteration 72/1000 | Loss: 0.00003350
Iteration 73/1000 | Loss: 0.00003350
Iteration 74/1000 | Loss: 0.00003350
Iteration 75/1000 | Loss: 0.00003350
Iteration 76/1000 | Loss: 0.00003350
Iteration 77/1000 | Loss: 0.00003350
Iteration 78/1000 | Loss: 0.00003350
Iteration 79/1000 | Loss: 0.00003350
Iteration 80/1000 | Loss: 0.00003350
Iteration 81/1000 | Loss: 0.00003350
Iteration 82/1000 | Loss: 0.00003350
Iteration 83/1000 | Loss: 0.00003350
Iteration 84/1000 | Loss: 0.00003350
Iteration 85/1000 | Loss: 0.00003350
Iteration 86/1000 | Loss: 0.00003350
Iteration 87/1000 | Loss: 0.00003350
Iteration 88/1000 | Loss: 0.00003350
Iteration 89/1000 | Loss: 0.00003350
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 89. Stopping optimization.
Last 5 losses: [3.3498457923997194e-05, 3.3498457923997194e-05, 3.3498457923997194e-05, 3.3498457923997194e-05, 3.3498457923997194e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.3498457923997194e-05

Optimization complete. Final v2v error: 4.798022270202637 mm

Highest mean error: 5.138427734375 mm for frame 82

Lowest mean error: 4.675445079803467 mm for frame 155

Saving results

Total time: 34.33841371536255
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00951528
Iteration 2/25 | Loss: 0.00117320
Iteration 3/25 | Loss: 0.00105364
Iteration 4/25 | Loss: 0.00101249
Iteration 5/25 | Loss: 0.00100706
Iteration 6/25 | Loss: 0.00100706
Iteration 7/25 | Loss: 0.00100706
Iteration 8/25 | Loss: 0.00100706
Iteration 9/25 | Loss: 0.00100706
Iteration 10/25 | Loss: 0.00100706
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0010070629650726914, 0.0010070629650726914, 0.0010070629650726914, 0.0010070629650726914, 0.0010070629650726914]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010070629650726914

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57099104
Iteration 2/25 | Loss: 0.00069143
Iteration 3/25 | Loss: 0.00069142
Iteration 4/25 | Loss: 0.00069142
Iteration 5/25 | Loss: 0.00069142
Iteration 6/25 | Loss: 0.00069142
Iteration 7/25 | Loss: 0.00069142
Iteration 8/25 | Loss: 0.00069142
Iteration 9/25 | Loss: 0.00069142
Iteration 10/25 | Loss: 0.00069142
Iteration 11/25 | Loss: 0.00069142
Iteration 12/25 | Loss: 0.00069142
Iteration 13/25 | Loss: 0.00069142
Iteration 14/25 | Loss: 0.00069142
Iteration 15/25 | Loss: 0.00069142
Iteration 16/25 | Loss: 0.00069142
Iteration 17/25 | Loss: 0.00069142
Iteration 18/25 | Loss: 0.00069142
Iteration 19/25 | Loss: 0.00069142
Iteration 20/25 | Loss: 0.00069142
Iteration 21/25 | Loss: 0.00069142
Iteration 22/25 | Loss: 0.00069142
Iteration 23/25 | Loss: 0.00069142
Iteration 24/25 | Loss: 0.00069142
Iteration 25/25 | Loss: 0.00069142

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00069142
Iteration 2/1000 | Loss: 0.00005065
Iteration 3/1000 | Loss: 0.00003634
Iteration 4/1000 | Loss: 0.00003243
Iteration 5/1000 | Loss: 0.00003093
Iteration 6/1000 | Loss: 0.00002940
Iteration 7/1000 | Loss: 0.00002834
Iteration 8/1000 | Loss: 0.00002758
Iteration 9/1000 | Loss: 0.00002718
Iteration 10/1000 | Loss: 0.00002695
Iteration 11/1000 | Loss: 0.00002693
Iteration 12/1000 | Loss: 0.00002677
Iteration 13/1000 | Loss: 0.00002673
Iteration 14/1000 | Loss: 0.00002672
Iteration 15/1000 | Loss: 0.00002672
Iteration 16/1000 | Loss: 0.00002671
Iteration 17/1000 | Loss: 0.00002669
Iteration 18/1000 | Loss: 0.00002669
Iteration 19/1000 | Loss: 0.00002669
Iteration 20/1000 | Loss: 0.00002669
Iteration 21/1000 | Loss: 0.00002668
Iteration 22/1000 | Loss: 0.00002668
Iteration 23/1000 | Loss: 0.00002667
Iteration 24/1000 | Loss: 0.00002666
Iteration 25/1000 | Loss: 0.00002665
Iteration 26/1000 | Loss: 0.00002665
Iteration 27/1000 | Loss: 0.00002665
Iteration 28/1000 | Loss: 0.00002664
Iteration 29/1000 | Loss: 0.00002664
Iteration 30/1000 | Loss: 0.00002664
Iteration 31/1000 | Loss: 0.00002663
Iteration 32/1000 | Loss: 0.00002663
Iteration 33/1000 | Loss: 0.00002662
Iteration 34/1000 | Loss: 0.00002660
Iteration 35/1000 | Loss: 0.00002660
Iteration 36/1000 | Loss: 0.00002660
Iteration 37/1000 | Loss: 0.00002659
Iteration 38/1000 | Loss: 0.00002659
Iteration 39/1000 | Loss: 0.00002658
Iteration 40/1000 | Loss: 0.00002658
Iteration 41/1000 | Loss: 0.00002657
Iteration 42/1000 | Loss: 0.00002657
Iteration 43/1000 | Loss: 0.00002657
Iteration 44/1000 | Loss: 0.00002656
Iteration 45/1000 | Loss: 0.00002656
Iteration 46/1000 | Loss: 0.00002656
Iteration 47/1000 | Loss: 0.00002656
Iteration 48/1000 | Loss: 0.00002656
Iteration 49/1000 | Loss: 0.00002656
Iteration 50/1000 | Loss: 0.00002656
Iteration 51/1000 | Loss: 0.00002655
Iteration 52/1000 | Loss: 0.00002655
Iteration 53/1000 | Loss: 0.00002655
Iteration 54/1000 | Loss: 0.00002655
Iteration 55/1000 | Loss: 0.00002655
Iteration 56/1000 | Loss: 0.00002654
Iteration 57/1000 | Loss: 0.00002654
Iteration 58/1000 | Loss: 0.00002654
Iteration 59/1000 | Loss: 0.00002654
Iteration 60/1000 | Loss: 0.00002654
Iteration 61/1000 | Loss: 0.00002653
Iteration 62/1000 | Loss: 0.00002653
Iteration 63/1000 | Loss: 0.00002653
Iteration 64/1000 | Loss: 0.00002653
Iteration 65/1000 | Loss: 0.00002653
Iteration 66/1000 | Loss: 0.00002653
Iteration 67/1000 | Loss: 0.00002653
Iteration 68/1000 | Loss: 0.00002653
Iteration 69/1000 | Loss: 0.00002653
Iteration 70/1000 | Loss: 0.00002652
Iteration 71/1000 | Loss: 0.00002650
Iteration 72/1000 | Loss: 0.00002650
Iteration 73/1000 | Loss: 0.00002650
Iteration 74/1000 | Loss: 0.00002650
Iteration 75/1000 | Loss: 0.00002650
Iteration 76/1000 | Loss: 0.00002650
Iteration 77/1000 | Loss: 0.00002650
Iteration 78/1000 | Loss: 0.00002650
Iteration 79/1000 | Loss: 0.00002650
Iteration 80/1000 | Loss: 0.00002650
Iteration 81/1000 | Loss: 0.00002650
Iteration 82/1000 | Loss: 0.00002650
Iteration 83/1000 | Loss: 0.00002649
Iteration 84/1000 | Loss: 0.00002649
Iteration 85/1000 | Loss: 0.00002649
Iteration 86/1000 | Loss: 0.00002648
Iteration 87/1000 | Loss: 0.00002648
Iteration 88/1000 | Loss: 0.00002648
Iteration 89/1000 | Loss: 0.00002648
Iteration 90/1000 | Loss: 0.00002648
Iteration 91/1000 | Loss: 0.00002647
Iteration 92/1000 | Loss: 0.00002647
Iteration 93/1000 | Loss: 0.00002647
Iteration 94/1000 | Loss: 0.00002647
Iteration 95/1000 | Loss: 0.00002647
Iteration 96/1000 | Loss: 0.00002647
Iteration 97/1000 | Loss: 0.00002647
Iteration 98/1000 | Loss: 0.00002647
Iteration 99/1000 | Loss: 0.00002647
Iteration 100/1000 | Loss: 0.00002647
Iteration 101/1000 | Loss: 0.00002647
Iteration 102/1000 | Loss: 0.00002647
Iteration 103/1000 | Loss: 0.00002647
Iteration 104/1000 | Loss: 0.00002647
Iteration 105/1000 | Loss: 0.00002647
Iteration 106/1000 | Loss: 0.00002647
Iteration 107/1000 | Loss: 0.00002647
Iteration 108/1000 | Loss: 0.00002647
Iteration 109/1000 | Loss: 0.00002647
Iteration 110/1000 | Loss: 0.00002647
Iteration 111/1000 | Loss: 0.00002647
Iteration 112/1000 | Loss: 0.00002647
Iteration 113/1000 | Loss: 0.00002647
Iteration 114/1000 | Loss: 0.00002647
Iteration 115/1000 | Loss: 0.00002647
Iteration 116/1000 | Loss: 0.00002647
Iteration 117/1000 | Loss: 0.00002647
Iteration 118/1000 | Loss: 0.00002647
Iteration 119/1000 | Loss: 0.00002647
Iteration 120/1000 | Loss: 0.00002647
Iteration 121/1000 | Loss: 0.00002647
Iteration 122/1000 | Loss: 0.00002647
Iteration 123/1000 | Loss: 0.00002647
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [2.6469750082469545e-05, 2.6469750082469545e-05, 2.6469750082469545e-05, 2.6469750082469545e-05, 2.6469750082469545e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6469750082469545e-05

Optimization complete. Final v2v error: 4.374969959259033 mm

Highest mean error: 5.328326225280762 mm for frame 93

Lowest mean error: 3.909416437149048 mm for frame 68

Saving results

Total time: 32.79528260231018
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00725357
Iteration 2/25 | Loss: 0.00177806
Iteration 3/25 | Loss: 0.00120289
Iteration 4/25 | Loss: 0.00106906
Iteration 5/25 | Loss: 0.00103691
Iteration 6/25 | Loss: 0.00101789
Iteration 7/25 | Loss: 0.00101427
Iteration 8/25 | Loss: 0.00100075
Iteration 9/25 | Loss: 0.00100491
Iteration 10/25 | Loss: 0.00099340
Iteration 11/25 | Loss: 0.00100203
Iteration 12/25 | Loss: 0.00099087
Iteration 13/25 | Loss: 0.00099041
Iteration 14/25 | Loss: 0.00099029
Iteration 15/25 | Loss: 0.00099014
Iteration 16/25 | Loss: 0.00099005
Iteration 17/25 | Loss: 0.00098993
Iteration 18/25 | Loss: 0.00098979
Iteration 19/25 | Loss: 0.00098963
Iteration 20/25 | Loss: 0.00099295
Iteration 21/25 | Loss: 0.00098852
Iteration 22/25 | Loss: 0.00098710
Iteration 23/25 | Loss: 0.00098649
Iteration 24/25 | Loss: 0.00098631
Iteration 25/25 | Loss: 0.00098631

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.65480280
Iteration 2/25 | Loss: 0.00070230
Iteration 3/25 | Loss: 0.00070213
Iteration 4/25 | Loss: 0.00070213
Iteration 5/25 | Loss: 0.00070213
Iteration 6/25 | Loss: 0.00070213
Iteration 7/25 | Loss: 0.00070213
Iteration 8/25 | Loss: 0.00070213
Iteration 9/25 | Loss: 0.00070213
Iteration 10/25 | Loss: 0.00070213
Iteration 11/25 | Loss: 0.00070213
Iteration 12/25 | Loss: 0.00070213
Iteration 13/25 | Loss: 0.00070213
Iteration 14/25 | Loss: 0.00070213
Iteration 15/25 | Loss: 0.00070213
Iteration 16/25 | Loss: 0.00070213
Iteration 17/25 | Loss: 0.00070213
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007021251367405057, 0.0007021251367405057, 0.0007021251367405057, 0.0007021251367405057, 0.0007021251367405057]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007021251367405057

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00070213
Iteration 2/1000 | Loss: 0.00003578
Iteration 3/1000 | Loss: 0.00002709
Iteration 4/1000 | Loss: 0.00002508
Iteration 5/1000 | Loss: 0.00002365
Iteration 6/1000 | Loss: 0.00002316
Iteration 7/1000 | Loss: 0.00002268
Iteration 8/1000 | Loss: 0.00002229
Iteration 9/1000 | Loss: 0.00002207
Iteration 10/1000 | Loss: 0.00002203
Iteration 11/1000 | Loss: 0.00002194
Iteration 12/1000 | Loss: 0.00002179
Iteration 13/1000 | Loss: 0.00002178
Iteration 14/1000 | Loss: 0.00002175
Iteration 15/1000 | Loss: 0.00002175
Iteration 16/1000 | Loss: 0.00002175
Iteration 17/1000 | Loss: 0.00002175
Iteration 18/1000 | Loss: 0.00002175
Iteration 19/1000 | Loss: 0.00002175
Iteration 20/1000 | Loss: 0.00002175
Iteration 21/1000 | Loss: 0.00002175
Iteration 22/1000 | Loss: 0.00002175
Iteration 23/1000 | Loss: 0.00002174
Iteration 24/1000 | Loss: 0.00002174
Iteration 25/1000 | Loss: 0.00002174
Iteration 26/1000 | Loss: 0.00002174
Iteration 27/1000 | Loss: 0.00002174
Iteration 28/1000 | Loss: 0.00002173
Iteration 29/1000 | Loss: 0.00002173
Iteration 30/1000 | Loss: 0.00002173
Iteration 31/1000 | Loss: 0.00002173
Iteration 32/1000 | Loss: 0.00002173
Iteration 33/1000 | Loss: 0.00002173
Iteration 34/1000 | Loss: 0.00002173
Iteration 35/1000 | Loss: 0.00002173
Iteration 36/1000 | Loss: 0.00002172
Iteration 37/1000 | Loss: 0.00002172
Iteration 38/1000 | Loss: 0.00002171
Iteration 39/1000 | Loss: 0.00002171
Iteration 40/1000 | Loss: 0.00002171
Iteration 41/1000 | Loss: 0.00002171
Iteration 42/1000 | Loss: 0.00002170
Iteration 43/1000 | Loss: 0.00002170
Iteration 44/1000 | Loss: 0.00002170
Iteration 45/1000 | Loss: 0.00002170
Iteration 46/1000 | Loss: 0.00002170
Iteration 47/1000 | Loss: 0.00002170
Iteration 48/1000 | Loss: 0.00002169
Iteration 49/1000 | Loss: 0.00002169
Iteration 50/1000 | Loss: 0.00002169
Iteration 51/1000 | Loss: 0.00002169
Iteration 52/1000 | Loss: 0.00002168
Iteration 53/1000 | Loss: 0.00002168
Iteration 54/1000 | Loss: 0.00002168
Iteration 55/1000 | Loss: 0.00002168
Iteration 56/1000 | Loss: 0.00002167
Iteration 57/1000 | Loss: 0.00002167
Iteration 58/1000 | Loss: 0.00002167
Iteration 59/1000 | Loss: 0.00002167
Iteration 60/1000 | Loss: 0.00002166
Iteration 61/1000 | Loss: 0.00002166
Iteration 62/1000 | Loss: 0.00002166
Iteration 63/1000 | Loss: 0.00002166
Iteration 64/1000 | Loss: 0.00002166
Iteration 65/1000 | Loss: 0.00002166
Iteration 66/1000 | Loss: 0.00002166
Iteration 67/1000 | Loss: 0.00002166
Iteration 68/1000 | Loss: 0.00002166
Iteration 69/1000 | Loss: 0.00002165
Iteration 70/1000 | Loss: 0.00002165
Iteration 71/1000 | Loss: 0.00002164
Iteration 72/1000 | Loss: 0.00002163
Iteration 73/1000 | Loss: 0.00002163
Iteration 74/1000 | Loss: 0.00002163
Iteration 75/1000 | Loss: 0.00002163
Iteration 76/1000 | Loss: 0.00002162
Iteration 77/1000 | Loss: 0.00002162
Iteration 78/1000 | Loss: 0.00002161
Iteration 79/1000 | Loss: 0.00002161
Iteration 80/1000 | Loss: 0.00002160
Iteration 81/1000 | Loss: 0.00002160
Iteration 82/1000 | Loss: 0.00002160
Iteration 83/1000 | Loss: 0.00002159
Iteration 84/1000 | Loss: 0.00002159
Iteration 85/1000 | Loss: 0.00002159
Iteration 86/1000 | Loss: 0.00002159
Iteration 87/1000 | Loss: 0.00002158
Iteration 88/1000 | Loss: 0.00002158
Iteration 89/1000 | Loss: 0.00002157
Iteration 90/1000 | Loss: 0.00002157
Iteration 91/1000 | Loss: 0.00002157
Iteration 92/1000 | Loss: 0.00002156
Iteration 93/1000 | Loss: 0.00002156
Iteration 94/1000 | Loss: 0.00002156
Iteration 95/1000 | Loss: 0.00002156
Iteration 96/1000 | Loss: 0.00002155
Iteration 97/1000 | Loss: 0.00002155
Iteration 98/1000 | Loss: 0.00002155
Iteration 99/1000 | Loss: 0.00002155
Iteration 100/1000 | Loss: 0.00002155
Iteration 101/1000 | Loss: 0.00002154
Iteration 102/1000 | Loss: 0.00002154
Iteration 103/1000 | Loss: 0.00002154
Iteration 104/1000 | Loss: 0.00002153
Iteration 105/1000 | Loss: 0.00002153
Iteration 106/1000 | Loss: 0.00002153
Iteration 107/1000 | Loss: 0.00002153
Iteration 108/1000 | Loss: 0.00002152
Iteration 109/1000 | Loss: 0.00002152
Iteration 110/1000 | Loss: 0.00002152
Iteration 111/1000 | Loss: 0.00002152
Iteration 112/1000 | Loss: 0.00002151
Iteration 113/1000 | Loss: 0.00002151
Iteration 114/1000 | Loss: 0.00002151
Iteration 115/1000 | Loss: 0.00002150
Iteration 116/1000 | Loss: 0.00002150
Iteration 117/1000 | Loss: 0.00002150
Iteration 118/1000 | Loss: 0.00002149
Iteration 119/1000 | Loss: 0.00002149
Iteration 120/1000 | Loss: 0.00002149
Iteration 121/1000 | Loss: 0.00002149
Iteration 122/1000 | Loss: 0.00002149
Iteration 123/1000 | Loss: 0.00002149
Iteration 124/1000 | Loss: 0.00002149
Iteration 125/1000 | Loss: 0.00002148
Iteration 126/1000 | Loss: 0.00002148
Iteration 127/1000 | Loss: 0.00002148
Iteration 128/1000 | Loss: 0.00002148
Iteration 129/1000 | Loss: 0.00002147
Iteration 130/1000 | Loss: 0.00002147
Iteration 131/1000 | Loss: 0.00002147
Iteration 132/1000 | Loss: 0.00002147
Iteration 133/1000 | Loss: 0.00002147
Iteration 134/1000 | Loss: 0.00002147
Iteration 135/1000 | Loss: 0.00002147
Iteration 136/1000 | Loss: 0.00002147
Iteration 137/1000 | Loss: 0.00002147
Iteration 138/1000 | Loss: 0.00002147
Iteration 139/1000 | Loss: 0.00002147
Iteration 140/1000 | Loss: 0.00002146
Iteration 141/1000 | Loss: 0.00002146
Iteration 142/1000 | Loss: 0.00002146
Iteration 143/1000 | Loss: 0.00002146
Iteration 144/1000 | Loss: 0.00002145
Iteration 145/1000 | Loss: 0.00002145
Iteration 146/1000 | Loss: 0.00002145
Iteration 147/1000 | Loss: 0.00002145
Iteration 148/1000 | Loss: 0.00002145
Iteration 149/1000 | Loss: 0.00002145
Iteration 150/1000 | Loss: 0.00002145
Iteration 151/1000 | Loss: 0.00002145
Iteration 152/1000 | Loss: 0.00002145
Iteration 153/1000 | Loss: 0.00002145
Iteration 154/1000 | Loss: 0.00002145
Iteration 155/1000 | Loss: 0.00002145
Iteration 156/1000 | Loss: 0.00002145
Iteration 157/1000 | Loss: 0.00002145
Iteration 158/1000 | Loss: 0.00002145
Iteration 159/1000 | Loss: 0.00002145
Iteration 160/1000 | Loss: 0.00002145
Iteration 161/1000 | Loss: 0.00002145
Iteration 162/1000 | Loss: 0.00002145
Iteration 163/1000 | Loss: 0.00002145
Iteration 164/1000 | Loss: 0.00002145
Iteration 165/1000 | Loss: 0.00002145
Iteration 166/1000 | Loss: 0.00002145
Iteration 167/1000 | Loss: 0.00002145
Iteration 168/1000 | Loss: 0.00002145
Iteration 169/1000 | Loss: 0.00002145
Iteration 170/1000 | Loss: 0.00002145
Iteration 171/1000 | Loss: 0.00002145
Iteration 172/1000 | Loss: 0.00002145
Iteration 173/1000 | Loss: 0.00002145
Iteration 174/1000 | Loss: 0.00002145
Iteration 175/1000 | Loss: 0.00002145
Iteration 176/1000 | Loss: 0.00002145
Iteration 177/1000 | Loss: 0.00002145
Iteration 178/1000 | Loss: 0.00002145
Iteration 179/1000 | Loss: 0.00002145
Iteration 180/1000 | Loss: 0.00002145
Iteration 181/1000 | Loss: 0.00002145
Iteration 182/1000 | Loss: 0.00002145
Iteration 183/1000 | Loss: 0.00002145
Iteration 184/1000 | Loss: 0.00002145
Iteration 185/1000 | Loss: 0.00002145
Iteration 186/1000 | Loss: 0.00002145
Iteration 187/1000 | Loss: 0.00002145
Iteration 188/1000 | Loss: 0.00002145
Iteration 189/1000 | Loss: 0.00002145
Iteration 190/1000 | Loss: 0.00002145
Iteration 191/1000 | Loss: 0.00002145
Iteration 192/1000 | Loss: 0.00002145
Iteration 193/1000 | Loss: 0.00002145
Iteration 194/1000 | Loss: 0.00002145
Iteration 195/1000 | Loss: 0.00002145
Iteration 196/1000 | Loss: 0.00002145
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [2.144769132428337e-05, 2.144769132428337e-05, 2.144769132428337e-05, 2.144769132428337e-05, 2.144769132428337e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.144769132428337e-05

Optimization complete. Final v2v error: 3.908069372177124 mm

Highest mean error: 4.332276344299316 mm for frame 193

Lowest mean error: 3.421360969543457 mm for frame 76

Saving results

Total time: 76.83789849281311
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00977139
Iteration 2/25 | Loss: 0.00168473
Iteration 3/25 | Loss: 0.00127782
Iteration 4/25 | Loss: 0.00120113
Iteration 5/25 | Loss: 0.00116293
Iteration 6/25 | Loss: 0.00115431
Iteration 7/25 | Loss: 0.00115176
Iteration 8/25 | Loss: 0.00115088
Iteration 9/25 | Loss: 0.00115088
Iteration 10/25 | Loss: 0.00115088
Iteration 11/25 | Loss: 0.00115088
Iteration 12/25 | Loss: 0.00115088
Iteration 13/25 | Loss: 0.00115088
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0011508783791214228, 0.0011508783791214228, 0.0011508783791214228, 0.0011508783791214228, 0.0011508783791214228]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011508783791214228

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48360515
Iteration 2/25 | Loss: 0.00075973
Iteration 3/25 | Loss: 0.00075973
Iteration 4/25 | Loss: 0.00075973
Iteration 5/25 | Loss: 0.00075973
Iteration 6/25 | Loss: 0.00075973
Iteration 7/25 | Loss: 0.00075973
Iteration 8/25 | Loss: 0.00075973
Iteration 9/25 | Loss: 0.00075973
Iteration 10/25 | Loss: 0.00075973
Iteration 11/25 | Loss: 0.00075973
Iteration 12/25 | Loss: 0.00075973
Iteration 13/25 | Loss: 0.00075973
Iteration 14/25 | Loss: 0.00075973
Iteration 15/25 | Loss: 0.00075973
Iteration 16/25 | Loss: 0.00075973
Iteration 17/25 | Loss: 0.00075973
Iteration 18/25 | Loss: 0.00075973
Iteration 19/25 | Loss: 0.00075973
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0007597309304401278, 0.0007597309304401278, 0.0007597309304401278, 0.0007597309304401278, 0.0007597309304401278]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007597309304401278

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075973
Iteration 2/1000 | Loss: 0.00008431
Iteration 3/1000 | Loss: 0.00005610
Iteration 4/1000 | Loss: 0.00004738
Iteration 5/1000 | Loss: 0.00004339
Iteration 6/1000 | Loss: 0.00004146
Iteration 7/1000 | Loss: 0.00004001
Iteration 8/1000 | Loss: 0.00003919
Iteration 9/1000 | Loss: 0.00003852
Iteration 10/1000 | Loss: 0.00003794
Iteration 11/1000 | Loss: 0.00003760
Iteration 12/1000 | Loss: 0.00003730
Iteration 13/1000 | Loss: 0.00003701
Iteration 14/1000 | Loss: 0.00003673
Iteration 15/1000 | Loss: 0.00003656
Iteration 16/1000 | Loss: 0.00003643
Iteration 17/1000 | Loss: 0.00003638
Iteration 18/1000 | Loss: 0.00003635
Iteration 19/1000 | Loss: 0.00003634
Iteration 20/1000 | Loss: 0.00003634
Iteration 21/1000 | Loss: 0.00003634
Iteration 22/1000 | Loss: 0.00003633
Iteration 23/1000 | Loss: 0.00003633
Iteration 24/1000 | Loss: 0.00003631
Iteration 25/1000 | Loss: 0.00003631
Iteration 26/1000 | Loss: 0.00003630
Iteration 27/1000 | Loss: 0.00003630
Iteration 28/1000 | Loss: 0.00003630
Iteration 29/1000 | Loss: 0.00003629
Iteration 30/1000 | Loss: 0.00003629
Iteration 31/1000 | Loss: 0.00003628
Iteration 32/1000 | Loss: 0.00003628
Iteration 33/1000 | Loss: 0.00003627
Iteration 34/1000 | Loss: 0.00003627
Iteration 35/1000 | Loss: 0.00003627
Iteration 36/1000 | Loss: 0.00003626
Iteration 37/1000 | Loss: 0.00003626
Iteration 38/1000 | Loss: 0.00003625
Iteration 39/1000 | Loss: 0.00003625
Iteration 40/1000 | Loss: 0.00003625
Iteration 41/1000 | Loss: 0.00003625
Iteration 42/1000 | Loss: 0.00003624
Iteration 43/1000 | Loss: 0.00003624
Iteration 44/1000 | Loss: 0.00003624
Iteration 45/1000 | Loss: 0.00003623
Iteration 46/1000 | Loss: 0.00003623
Iteration 47/1000 | Loss: 0.00003623
Iteration 48/1000 | Loss: 0.00003623
Iteration 49/1000 | Loss: 0.00003622
Iteration 50/1000 | Loss: 0.00003621
Iteration 51/1000 | Loss: 0.00003621
Iteration 52/1000 | Loss: 0.00003621
Iteration 53/1000 | Loss: 0.00003621
Iteration 54/1000 | Loss: 0.00003621
Iteration 55/1000 | Loss: 0.00003621
Iteration 56/1000 | Loss: 0.00003621
Iteration 57/1000 | Loss: 0.00003621
Iteration 58/1000 | Loss: 0.00003621
Iteration 59/1000 | Loss: 0.00003621
Iteration 60/1000 | Loss: 0.00003621
Iteration 61/1000 | Loss: 0.00003621
Iteration 62/1000 | Loss: 0.00003620
Iteration 63/1000 | Loss: 0.00003620
Iteration 64/1000 | Loss: 0.00003620
Iteration 65/1000 | Loss: 0.00003619
Iteration 66/1000 | Loss: 0.00003619
Iteration 67/1000 | Loss: 0.00003619
Iteration 68/1000 | Loss: 0.00003618
Iteration 69/1000 | Loss: 0.00003618
Iteration 70/1000 | Loss: 0.00003618
Iteration 71/1000 | Loss: 0.00003617
Iteration 72/1000 | Loss: 0.00003617
Iteration 73/1000 | Loss: 0.00003617
Iteration 74/1000 | Loss: 0.00003617
Iteration 75/1000 | Loss: 0.00003617
Iteration 76/1000 | Loss: 0.00003617
Iteration 77/1000 | Loss: 0.00003617
Iteration 78/1000 | Loss: 0.00003617
Iteration 79/1000 | Loss: 0.00003616
Iteration 80/1000 | Loss: 0.00003616
Iteration 81/1000 | Loss: 0.00003616
Iteration 82/1000 | Loss: 0.00003616
Iteration 83/1000 | Loss: 0.00003616
Iteration 84/1000 | Loss: 0.00003615
Iteration 85/1000 | Loss: 0.00003615
Iteration 86/1000 | Loss: 0.00003615
Iteration 87/1000 | Loss: 0.00003615
Iteration 88/1000 | Loss: 0.00003615
Iteration 89/1000 | Loss: 0.00003615
Iteration 90/1000 | Loss: 0.00003614
Iteration 91/1000 | Loss: 0.00003614
Iteration 92/1000 | Loss: 0.00003614
Iteration 93/1000 | Loss: 0.00003614
Iteration 94/1000 | Loss: 0.00003613
Iteration 95/1000 | Loss: 0.00003613
Iteration 96/1000 | Loss: 0.00003613
Iteration 97/1000 | Loss: 0.00003613
Iteration 98/1000 | Loss: 0.00003613
Iteration 99/1000 | Loss: 0.00003613
Iteration 100/1000 | Loss: 0.00003612
Iteration 101/1000 | Loss: 0.00003612
Iteration 102/1000 | Loss: 0.00003612
Iteration 103/1000 | Loss: 0.00003612
Iteration 104/1000 | Loss: 0.00003612
Iteration 105/1000 | Loss: 0.00003612
Iteration 106/1000 | Loss: 0.00003612
Iteration 107/1000 | Loss: 0.00003612
Iteration 108/1000 | Loss: 0.00003611
Iteration 109/1000 | Loss: 0.00003611
Iteration 110/1000 | Loss: 0.00003610
Iteration 111/1000 | Loss: 0.00003610
Iteration 112/1000 | Loss: 0.00003609
Iteration 113/1000 | Loss: 0.00003609
Iteration 114/1000 | Loss: 0.00003609
Iteration 115/1000 | Loss: 0.00003609
Iteration 116/1000 | Loss: 0.00003609
Iteration 117/1000 | Loss: 0.00003608
Iteration 118/1000 | Loss: 0.00003608
Iteration 119/1000 | Loss: 0.00003608
Iteration 120/1000 | Loss: 0.00003608
Iteration 121/1000 | Loss: 0.00003608
Iteration 122/1000 | Loss: 0.00003608
Iteration 123/1000 | Loss: 0.00003607
Iteration 124/1000 | Loss: 0.00003607
Iteration 125/1000 | Loss: 0.00003607
Iteration 126/1000 | Loss: 0.00003607
Iteration 127/1000 | Loss: 0.00003607
Iteration 128/1000 | Loss: 0.00003607
Iteration 129/1000 | Loss: 0.00003607
Iteration 130/1000 | Loss: 0.00003607
Iteration 131/1000 | Loss: 0.00003607
Iteration 132/1000 | Loss: 0.00003606
Iteration 133/1000 | Loss: 0.00003606
Iteration 134/1000 | Loss: 0.00003606
Iteration 135/1000 | Loss: 0.00003606
Iteration 136/1000 | Loss: 0.00003606
Iteration 137/1000 | Loss: 0.00003606
Iteration 138/1000 | Loss: 0.00003606
Iteration 139/1000 | Loss: 0.00003605
Iteration 140/1000 | Loss: 0.00003605
Iteration 141/1000 | Loss: 0.00003605
Iteration 142/1000 | Loss: 0.00003605
Iteration 143/1000 | Loss: 0.00003605
Iteration 144/1000 | Loss: 0.00003605
Iteration 145/1000 | Loss: 0.00003605
Iteration 146/1000 | Loss: 0.00003604
Iteration 147/1000 | Loss: 0.00003604
Iteration 148/1000 | Loss: 0.00003604
Iteration 149/1000 | Loss: 0.00003604
Iteration 150/1000 | Loss: 0.00003604
Iteration 151/1000 | Loss: 0.00003604
Iteration 152/1000 | Loss: 0.00003603
Iteration 153/1000 | Loss: 0.00003603
Iteration 154/1000 | Loss: 0.00003603
Iteration 155/1000 | Loss: 0.00003603
Iteration 156/1000 | Loss: 0.00003603
Iteration 157/1000 | Loss: 0.00003603
Iteration 158/1000 | Loss: 0.00003602
Iteration 159/1000 | Loss: 0.00003602
Iteration 160/1000 | Loss: 0.00003602
Iteration 161/1000 | Loss: 0.00003602
Iteration 162/1000 | Loss: 0.00003602
Iteration 163/1000 | Loss: 0.00003602
Iteration 164/1000 | Loss: 0.00003602
Iteration 165/1000 | Loss: 0.00003602
Iteration 166/1000 | Loss: 0.00003602
Iteration 167/1000 | Loss: 0.00003602
Iteration 168/1000 | Loss: 0.00003602
Iteration 169/1000 | Loss: 0.00003601
Iteration 170/1000 | Loss: 0.00003601
Iteration 171/1000 | Loss: 0.00003601
Iteration 172/1000 | Loss: 0.00003601
Iteration 173/1000 | Loss: 0.00003601
Iteration 174/1000 | Loss: 0.00003601
Iteration 175/1000 | Loss: 0.00003601
Iteration 176/1000 | Loss: 0.00003601
Iteration 177/1000 | Loss: 0.00003601
Iteration 178/1000 | Loss: 0.00003601
Iteration 179/1000 | Loss: 0.00003601
Iteration 180/1000 | Loss: 0.00003600
Iteration 181/1000 | Loss: 0.00003600
Iteration 182/1000 | Loss: 0.00003600
Iteration 183/1000 | Loss: 0.00003600
Iteration 184/1000 | Loss: 0.00003600
Iteration 185/1000 | Loss: 0.00003600
Iteration 186/1000 | Loss: 0.00003599
Iteration 187/1000 | Loss: 0.00003599
Iteration 188/1000 | Loss: 0.00003599
Iteration 189/1000 | Loss: 0.00003599
Iteration 190/1000 | Loss: 0.00003599
Iteration 191/1000 | Loss: 0.00003599
Iteration 192/1000 | Loss: 0.00003599
Iteration 193/1000 | Loss: 0.00003599
Iteration 194/1000 | Loss: 0.00003598
Iteration 195/1000 | Loss: 0.00003598
Iteration 196/1000 | Loss: 0.00003598
Iteration 197/1000 | Loss: 0.00003598
Iteration 198/1000 | Loss: 0.00003597
Iteration 199/1000 | Loss: 0.00003597
Iteration 200/1000 | Loss: 0.00003597
Iteration 201/1000 | Loss: 0.00003597
Iteration 202/1000 | Loss: 0.00003597
Iteration 203/1000 | Loss: 0.00003596
Iteration 204/1000 | Loss: 0.00003596
Iteration 205/1000 | Loss: 0.00003596
Iteration 206/1000 | Loss: 0.00003596
Iteration 207/1000 | Loss: 0.00003596
Iteration 208/1000 | Loss: 0.00003595
Iteration 209/1000 | Loss: 0.00003595
Iteration 210/1000 | Loss: 0.00003595
Iteration 211/1000 | Loss: 0.00003595
Iteration 212/1000 | Loss: 0.00003595
Iteration 213/1000 | Loss: 0.00003595
Iteration 214/1000 | Loss: 0.00003595
Iteration 215/1000 | Loss: 0.00003595
Iteration 216/1000 | Loss: 0.00003595
Iteration 217/1000 | Loss: 0.00003595
Iteration 218/1000 | Loss: 0.00003595
Iteration 219/1000 | Loss: 0.00003595
Iteration 220/1000 | Loss: 0.00003594
Iteration 221/1000 | Loss: 0.00003594
Iteration 222/1000 | Loss: 0.00003594
Iteration 223/1000 | Loss: 0.00003594
Iteration 224/1000 | Loss: 0.00003594
Iteration 225/1000 | Loss: 0.00003594
Iteration 226/1000 | Loss: 0.00003594
Iteration 227/1000 | Loss: 0.00003594
Iteration 228/1000 | Loss: 0.00003594
Iteration 229/1000 | Loss: 0.00003594
Iteration 230/1000 | Loss: 0.00003594
Iteration 231/1000 | Loss: 0.00003594
Iteration 232/1000 | Loss: 0.00003593
Iteration 233/1000 | Loss: 0.00003593
Iteration 234/1000 | Loss: 0.00003593
Iteration 235/1000 | Loss: 0.00003593
Iteration 236/1000 | Loss: 0.00003593
Iteration 237/1000 | Loss: 0.00003593
Iteration 238/1000 | Loss: 0.00003593
Iteration 239/1000 | Loss: 0.00003593
Iteration 240/1000 | Loss: 0.00003593
Iteration 241/1000 | Loss: 0.00003593
Iteration 242/1000 | Loss: 0.00003593
Iteration 243/1000 | Loss: 0.00003593
Iteration 244/1000 | Loss: 0.00003593
Iteration 245/1000 | Loss: 0.00003593
Iteration 246/1000 | Loss: 0.00003593
Iteration 247/1000 | Loss: 0.00003593
Iteration 248/1000 | Loss: 0.00003593
Iteration 249/1000 | Loss: 0.00003593
Iteration 250/1000 | Loss: 0.00003592
Iteration 251/1000 | Loss: 0.00003592
Iteration 252/1000 | Loss: 0.00003592
Iteration 253/1000 | Loss: 0.00003592
Iteration 254/1000 | Loss: 0.00003592
Iteration 255/1000 | Loss: 0.00003592
Iteration 256/1000 | Loss: 0.00003592
Iteration 257/1000 | Loss: 0.00003592
Iteration 258/1000 | Loss: 0.00003592
Iteration 259/1000 | Loss: 0.00003592
Iteration 260/1000 | Loss: 0.00003592
Iteration 261/1000 | Loss: 0.00003592
Iteration 262/1000 | Loss: 0.00003592
Iteration 263/1000 | Loss: 0.00003592
Iteration 264/1000 | Loss: 0.00003592
Iteration 265/1000 | Loss: 0.00003592
Iteration 266/1000 | Loss: 0.00003592
Iteration 267/1000 | Loss: 0.00003592
Iteration 268/1000 | Loss: 0.00003592
Iteration 269/1000 | Loss: 0.00003592
Iteration 270/1000 | Loss: 0.00003592
Iteration 271/1000 | Loss: 0.00003592
Iteration 272/1000 | Loss: 0.00003592
Iteration 273/1000 | Loss: 0.00003592
Iteration 274/1000 | Loss: 0.00003592
Iteration 275/1000 | Loss: 0.00003592
Iteration 276/1000 | Loss: 0.00003592
Iteration 277/1000 | Loss: 0.00003592
Iteration 278/1000 | Loss: 0.00003592
Iteration 279/1000 | Loss: 0.00003592
Iteration 280/1000 | Loss: 0.00003592
Iteration 281/1000 | Loss: 0.00003592
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 281. Stopping optimization.
Last 5 losses: [3.591908171074465e-05, 3.591908171074465e-05, 3.591908171074465e-05, 3.591908171074465e-05, 3.591908171074465e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.591908171074465e-05

Optimization complete. Final v2v error: 4.790152549743652 mm

Highest mean error: 7.123528003692627 mm for frame 117

Lowest mean error: 3.333470106124878 mm for frame 3

Saving results

Total time: 52.16146183013916
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00407408
Iteration 2/25 | Loss: 0.00106483
Iteration 3/25 | Loss: 0.00091600
Iteration 4/25 | Loss: 0.00089237
Iteration 5/25 | Loss: 0.00088614
Iteration 6/25 | Loss: 0.00088486
Iteration 7/25 | Loss: 0.00088476
Iteration 8/25 | Loss: 0.00088476
Iteration 9/25 | Loss: 0.00088476
Iteration 10/25 | Loss: 0.00088476
Iteration 11/25 | Loss: 0.00088476
Iteration 12/25 | Loss: 0.00088476
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008847586577758193, 0.0008847586577758193, 0.0008847586577758193, 0.0008847586577758193, 0.0008847586577758193]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008847586577758193

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50595760
Iteration 2/25 | Loss: 0.00059301
Iteration 3/25 | Loss: 0.00059301
Iteration 4/25 | Loss: 0.00059301
Iteration 5/25 | Loss: 0.00059301
Iteration 6/25 | Loss: 0.00059301
Iteration 7/25 | Loss: 0.00059301
Iteration 8/25 | Loss: 0.00059301
Iteration 9/25 | Loss: 0.00059301
Iteration 10/25 | Loss: 0.00059301
Iteration 11/25 | Loss: 0.00059301
Iteration 12/25 | Loss: 0.00059301
Iteration 13/25 | Loss: 0.00059301
Iteration 14/25 | Loss: 0.00059301
Iteration 15/25 | Loss: 0.00059301
Iteration 16/25 | Loss: 0.00059301
Iteration 17/25 | Loss: 0.00059301
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0005930070183239877, 0.0005930070183239877, 0.0005930070183239877, 0.0005930070183239877, 0.0005930070183239877]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005930070183239877

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059301
Iteration 2/1000 | Loss: 0.00003639
Iteration 3/1000 | Loss: 0.00002037
Iteration 4/1000 | Loss: 0.00001787
Iteration 5/1000 | Loss: 0.00001690
Iteration 6/1000 | Loss: 0.00001610
Iteration 7/1000 | Loss: 0.00001581
Iteration 8/1000 | Loss: 0.00001551
Iteration 9/1000 | Loss: 0.00001532
Iteration 10/1000 | Loss: 0.00001530
Iteration 11/1000 | Loss: 0.00001527
Iteration 12/1000 | Loss: 0.00001523
Iteration 13/1000 | Loss: 0.00001522
Iteration 14/1000 | Loss: 0.00001520
Iteration 15/1000 | Loss: 0.00001518
Iteration 16/1000 | Loss: 0.00001515
Iteration 17/1000 | Loss: 0.00001515
Iteration 18/1000 | Loss: 0.00001514
Iteration 19/1000 | Loss: 0.00001504
Iteration 20/1000 | Loss: 0.00001498
Iteration 21/1000 | Loss: 0.00001495
Iteration 22/1000 | Loss: 0.00001495
Iteration 23/1000 | Loss: 0.00001494
Iteration 24/1000 | Loss: 0.00001490
Iteration 25/1000 | Loss: 0.00001490
Iteration 26/1000 | Loss: 0.00001490
Iteration 27/1000 | Loss: 0.00001490
Iteration 28/1000 | Loss: 0.00001490
Iteration 29/1000 | Loss: 0.00001490
Iteration 30/1000 | Loss: 0.00001490
Iteration 31/1000 | Loss: 0.00001490
Iteration 32/1000 | Loss: 0.00001489
Iteration 33/1000 | Loss: 0.00001489
Iteration 34/1000 | Loss: 0.00001489
Iteration 35/1000 | Loss: 0.00001489
Iteration 36/1000 | Loss: 0.00001489
Iteration 37/1000 | Loss: 0.00001487
Iteration 38/1000 | Loss: 0.00001487
Iteration 39/1000 | Loss: 0.00001487
Iteration 40/1000 | Loss: 0.00001486
Iteration 41/1000 | Loss: 0.00001486
Iteration 42/1000 | Loss: 0.00001486
Iteration 43/1000 | Loss: 0.00001486
Iteration 44/1000 | Loss: 0.00001486
Iteration 45/1000 | Loss: 0.00001486
Iteration 46/1000 | Loss: 0.00001486
Iteration 47/1000 | Loss: 0.00001486
Iteration 48/1000 | Loss: 0.00001486
Iteration 49/1000 | Loss: 0.00001486
Iteration 50/1000 | Loss: 0.00001486
Iteration 51/1000 | Loss: 0.00001486
Iteration 52/1000 | Loss: 0.00001484
Iteration 53/1000 | Loss: 0.00001484
Iteration 54/1000 | Loss: 0.00001483
Iteration 55/1000 | Loss: 0.00001483
Iteration 56/1000 | Loss: 0.00001483
Iteration 57/1000 | Loss: 0.00001483
Iteration 58/1000 | Loss: 0.00001483
Iteration 59/1000 | Loss: 0.00001482
Iteration 60/1000 | Loss: 0.00001482
Iteration 61/1000 | Loss: 0.00001482
Iteration 62/1000 | Loss: 0.00001482
Iteration 63/1000 | Loss: 0.00001482
Iteration 64/1000 | Loss: 0.00001480
Iteration 65/1000 | Loss: 0.00001480
Iteration 66/1000 | Loss: 0.00001480
Iteration 67/1000 | Loss: 0.00001480
Iteration 68/1000 | Loss: 0.00001480
Iteration 69/1000 | Loss: 0.00001480
Iteration 70/1000 | Loss: 0.00001480
Iteration 71/1000 | Loss: 0.00001480
Iteration 72/1000 | Loss: 0.00001480
Iteration 73/1000 | Loss: 0.00001480
Iteration 74/1000 | Loss: 0.00001480
Iteration 75/1000 | Loss: 0.00001479
Iteration 76/1000 | Loss: 0.00001479
Iteration 77/1000 | Loss: 0.00001479
Iteration 78/1000 | Loss: 0.00001479
Iteration 79/1000 | Loss: 0.00001478
Iteration 80/1000 | Loss: 0.00001478
Iteration 81/1000 | Loss: 0.00001478
Iteration 82/1000 | Loss: 0.00001477
Iteration 83/1000 | Loss: 0.00001477
Iteration 84/1000 | Loss: 0.00001477
Iteration 85/1000 | Loss: 0.00001477
Iteration 86/1000 | Loss: 0.00001477
Iteration 87/1000 | Loss: 0.00001477
Iteration 88/1000 | Loss: 0.00001476
Iteration 89/1000 | Loss: 0.00001476
Iteration 90/1000 | Loss: 0.00001476
Iteration 91/1000 | Loss: 0.00001476
Iteration 92/1000 | Loss: 0.00001475
Iteration 93/1000 | Loss: 0.00001475
Iteration 94/1000 | Loss: 0.00001475
Iteration 95/1000 | Loss: 0.00001475
Iteration 96/1000 | Loss: 0.00001475
Iteration 97/1000 | Loss: 0.00001475
Iteration 98/1000 | Loss: 0.00001475
Iteration 99/1000 | Loss: 0.00001475
Iteration 100/1000 | Loss: 0.00001475
Iteration 101/1000 | Loss: 0.00001475
Iteration 102/1000 | Loss: 0.00001474
Iteration 103/1000 | Loss: 0.00001474
Iteration 104/1000 | Loss: 0.00001474
Iteration 105/1000 | Loss: 0.00001474
Iteration 106/1000 | Loss: 0.00001474
Iteration 107/1000 | Loss: 0.00001474
Iteration 108/1000 | Loss: 0.00001474
Iteration 109/1000 | Loss: 0.00001474
Iteration 110/1000 | Loss: 0.00001474
Iteration 111/1000 | Loss: 0.00001474
Iteration 112/1000 | Loss: 0.00001474
Iteration 113/1000 | Loss: 0.00001474
Iteration 114/1000 | Loss: 0.00001474
Iteration 115/1000 | Loss: 0.00001474
Iteration 116/1000 | Loss: 0.00001473
Iteration 117/1000 | Loss: 0.00001473
Iteration 118/1000 | Loss: 0.00001473
Iteration 119/1000 | Loss: 0.00001473
Iteration 120/1000 | Loss: 0.00001473
Iteration 121/1000 | Loss: 0.00001473
Iteration 122/1000 | Loss: 0.00001473
Iteration 123/1000 | Loss: 0.00001473
Iteration 124/1000 | Loss: 0.00001473
Iteration 125/1000 | Loss: 0.00001473
Iteration 126/1000 | Loss: 0.00001473
Iteration 127/1000 | Loss: 0.00001473
Iteration 128/1000 | Loss: 0.00001473
Iteration 129/1000 | Loss: 0.00001472
Iteration 130/1000 | Loss: 0.00001472
Iteration 131/1000 | Loss: 0.00001472
Iteration 132/1000 | Loss: 0.00001472
Iteration 133/1000 | Loss: 0.00001472
Iteration 134/1000 | Loss: 0.00001472
Iteration 135/1000 | Loss: 0.00001472
Iteration 136/1000 | Loss: 0.00001472
Iteration 137/1000 | Loss: 0.00001472
Iteration 138/1000 | Loss: 0.00001472
Iteration 139/1000 | Loss: 0.00001472
Iteration 140/1000 | Loss: 0.00001472
Iteration 141/1000 | Loss: 0.00001472
Iteration 142/1000 | Loss: 0.00001472
Iteration 143/1000 | Loss: 0.00001472
Iteration 144/1000 | Loss: 0.00001472
Iteration 145/1000 | Loss: 0.00001472
Iteration 146/1000 | Loss: 0.00001472
Iteration 147/1000 | Loss: 0.00001472
Iteration 148/1000 | Loss: 0.00001471
Iteration 149/1000 | Loss: 0.00001471
Iteration 150/1000 | Loss: 0.00001471
Iteration 151/1000 | Loss: 0.00001471
Iteration 152/1000 | Loss: 0.00001471
Iteration 153/1000 | Loss: 0.00001471
Iteration 154/1000 | Loss: 0.00001471
Iteration 155/1000 | Loss: 0.00001471
Iteration 156/1000 | Loss: 0.00001471
Iteration 157/1000 | Loss: 0.00001471
Iteration 158/1000 | Loss: 0.00001471
Iteration 159/1000 | Loss: 0.00001471
Iteration 160/1000 | Loss: 0.00001471
Iteration 161/1000 | Loss: 0.00001471
Iteration 162/1000 | Loss: 0.00001471
Iteration 163/1000 | Loss: 0.00001471
Iteration 164/1000 | Loss: 0.00001471
Iteration 165/1000 | Loss: 0.00001471
Iteration 166/1000 | Loss: 0.00001471
Iteration 167/1000 | Loss: 0.00001471
Iteration 168/1000 | Loss: 0.00001471
Iteration 169/1000 | Loss: 0.00001471
Iteration 170/1000 | Loss: 0.00001471
Iteration 171/1000 | Loss: 0.00001471
Iteration 172/1000 | Loss: 0.00001471
Iteration 173/1000 | Loss: 0.00001471
Iteration 174/1000 | Loss: 0.00001471
Iteration 175/1000 | Loss: 0.00001471
Iteration 176/1000 | Loss: 0.00001471
Iteration 177/1000 | Loss: 0.00001471
Iteration 178/1000 | Loss: 0.00001471
Iteration 179/1000 | Loss: 0.00001471
Iteration 180/1000 | Loss: 0.00001471
Iteration 181/1000 | Loss: 0.00001471
Iteration 182/1000 | Loss: 0.00001471
Iteration 183/1000 | Loss: 0.00001471
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 183. Stopping optimization.
Last 5 losses: [1.4709092283737846e-05, 1.4709092283737846e-05, 1.4709092283737846e-05, 1.4709092283737846e-05, 1.4709092283737846e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4709092283737846e-05

Optimization complete. Final v2v error: 3.3466198444366455 mm

Highest mean error: 4.480425834655762 mm for frame 39

Lowest mean error: 3.0327138900756836 mm for frame 68

Saving results

Total time: 35.241507053375244
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00428124
Iteration 2/25 | Loss: 0.00113887
Iteration 3/25 | Loss: 0.00097099
Iteration 4/25 | Loss: 0.00094356
Iteration 5/25 | Loss: 0.00093396
Iteration 6/25 | Loss: 0.00093139
Iteration 7/25 | Loss: 0.00093087
Iteration 8/25 | Loss: 0.00093087
Iteration 9/25 | Loss: 0.00093087
Iteration 10/25 | Loss: 0.00093087
Iteration 11/25 | Loss: 0.00093087
Iteration 12/25 | Loss: 0.00093087
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009308696608059108, 0.0009308696608059108, 0.0009308696608059108, 0.0009308696608059108, 0.0009308696608059108]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009308696608059108

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47403169
Iteration 2/25 | Loss: 0.00065729
Iteration 3/25 | Loss: 0.00065729
Iteration 4/25 | Loss: 0.00065729
Iteration 5/25 | Loss: 0.00065729
Iteration 6/25 | Loss: 0.00065729
Iteration 7/25 | Loss: 0.00065729
Iteration 8/25 | Loss: 0.00065729
Iteration 9/25 | Loss: 0.00065729
Iteration 10/25 | Loss: 0.00065729
Iteration 11/25 | Loss: 0.00065729
Iteration 12/25 | Loss: 0.00065729
Iteration 13/25 | Loss: 0.00065729
Iteration 14/25 | Loss: 0.00065729
Iteration 15/25 | Loss: 0.00065729
Iteration 16/25 | Loss: 0.00065729
Iteration 17/25 | Loss: 0.00065729
Iteration 18/25 | Loss: 0.00065729
Iteration 19/25 | Loss: 0.00065729
Iteration 20/25 | Loss: 0.00065729
Iteration 21/25 | Loss: 0.00065729
Iteration 22/25 | Loss: 0.00065729
Iteration 23/25 | Loss: 0.00065729
Iteration 24/25 | Loss: 0.00065729
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0006572857964783907, 0.0006572857964783907, 0.0006572857964783907, 0.0006572857964783907, 0.0006572857964783907]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006572857964783907

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065729
Iteration 2/1000 | Loss: 0.00002805
Iteration 3/1000 | Loss: 0.00001960
Iteration 4/1000 | Loss: 0.00001845
Iteration 5/1000 | Loss: 0.00001763
Iteration 6/1000 | Loss: 0.00001720
Iteration 7/1000 | Loss: 0.00001691
Iteration 8/1000 | Loss: 0.00001672
Iteration 9/1000 | Loss: 0.00001669
Iteration 10/1000 | Loss: 0.00001668
Iteration 11/1000 | Loss: 0.00001667
Iteration 12/1000 | Loss: 0.00001667
Iteration 13/1000 | Loss: 0.00001666
Iteration 14/1000 | Loss: 0.00001662
Iteration 15/1000 | Loss: 0.00001661
Iteration 16/1000 | Loss: 0.00001661
Iteration 17/1000 | Loss: 0.00001660
Iteration 18/1000 | Loss: 0.00001660
Iteration 19/1000 | Loss: 0.00001660
Iteration 20/1000 | Loss: 0.00001659
Iteration 21/1000 | Loss: 0.00001659
Iteration 22/1000 | Loss: 0.00001658
Iteration 23/1000 | Loss: 0.00001658
Iteration 24/1000 | Loss: 0.00001658
Iteration 25/1000 | Loss: 0.00001657
Iteration 26/1000 | Loss: 0.00001657
Iteration 27/1000 | Loss: 0.00001657
Iteration 28/1000 | Loss: 0.00001657
Iteration 29/1000 | Loss: 0.00001657
Iteration 30/1000 | Loss: 0.00001657
Iteration 31/1000 | Loss: 0.00001657
Iteration 32/1000 | Loss: 0.00001657
Iteration 33/1000 | Loss: 0.00001657
Iteration 34/1000 | Loss: 0.00001657
Iteration 35/1000 | Loss: 0.00001657
Iteration 36/1000 | Loss: 0.00001657
Iteration 37/1000 | Loss: 0.00001657
Iteration 38/1000 | Loss: 0.00001656
Iteration 39/1000 | Loss: 0.00001656
Iteration 40/1000 | Loss: 0.00001654
Iteration 41/1000 | Loss: 0.00001654
Iteration 42/1000 | Loss: 0.00001654
Iteration 43/1000 | Loss: 0.00001654
Iteration 44/1000 | Loss: 0.00001653
Iteration 45/1000 | Loss: 0.00001653
Iteration 46/1000 | Loss: 0.00001652
Iteration 47/1000 | Loss: 0.00001652
Iteration 48/1000 | Loss: 0.00001651
Iteration 49/1000 | Loss: 0.00001651
Iteration 50/1000 | Loss: 0.00001651
Iteration 51/1000 | Loss: 0.00001651
Iteration 52/1000 | Loss: 0.00001651
Iteration 53/1000 | Loss: 0.00001651
Iteration 54/1000 | Loss: 0.00001651
Iteration 55/1000 | Loss: 0.00001651
Iteration 56/1000 | Loss: 0.00001650
Iteration 57/1000 | Loss: 0.00001650
Iteration 58/1000 | Loss: 0.00001650
Iteration 59/1000 | Loss: 0.00001650
Iteration 60/1000 | Loss: 0.00001649
Iteration 61/1000 | Loss: 0.00001649
Iteration 62/1000 | Loss: 0.00001649
Iteration 63/1000 | Loss: 0.00001649
Iteration 64/1000 | Loss: 0.00001649
Iteration 65/1000 | Loss: 0.00001649
Iteration 66/1000 | Loss: 0.00001649
Iteration 67/1000 | Loss: 0.00001648
Iteration 68/1000 | Loss: 0.00001648
Iteration 69/1000 | Loss: 0.00001648
Iteration 70/1000 | Loss: 0.00001648
Iteration 71/1000 | Loss: 0.00001648
Iteration 72/1000 | Loss: 0.00001648
Iteration 73/1000 | Loss: 0.00001648
Iteration 74/1000 | Loss: 0.00001647
Iteration 75/1000 | Loss: 0.00001647
Iteration 76/1000 | Loss: 0.00001647
Iteration 77/1000 | Loss: 0.00001647
Iteration 78/1000 | Loss: 0.00001647
Iteration 79/1000 | Loss: 0.00001647
Iteration 80/1000 | Loss: 0.00001647
Iteration 81/1000 | Loss: 0.00001646
Iteration 82/1000 | Loss: 0.00001646
Iteration 83/1000 | Loss: 0.00001646
Iteration 84/1000 | Loss: 0.00001646
Iteration 85/1000 | Loss: 0.00001646
Iteration 86/1000 | Loss: 0.00001646
Iteration 87/1000 | Loss: 0.00001646
Iteration 88/1000 | Loss: 0.00001646
Iteration 89/1000 | Loss: 0.00001645
Iteration 90/1000 | Loss: 0.00001645
Iteration 91/1000 | Loss: 0.00001645
Iteration 92/1000 | Loss: 0.00001645
Iteration 93/1000 | Loss: 0.00001645
Iteration 94/1000 | Loss: 0.00001645
Iteration 95/1000 | Loss: 0.00001645
Iteration 96/1000 | Loss: 0.00001645
Iteration 97/1000 | Loss: 0.00001645
Iteration 98/1000 | Loss: 0.00001645
Iteration 99/1000 | Loss: 0.00001644
Iteration 100/1000 | Loss: 0.00001644
Iteration 101/1000 | Loss: 0.00001644
Iteration 102/1000 | Loss: 0.00001644
Iteration 103/1000 | Loss: 0.00001644
Iteration 104/1000 | Loss: 0.00001644
Iteration 105/1000 | Loss: 0.00001643
Iteration 106/1000 | Loss: 0.00001643
Iteration 107/1000 | Loss: 0.00001643
Iteration 108/1000 | Loss: 0.00001643
Iteration 109/1000 | Loss: 0.00001643
Iteration 110/1000 | Loss: 0.00001643
Iteration 111/1000 | Loss: 0.00001643
Iteration 112/1000 | Loss: 0.00001643
Iteration 113/1000 | Loss: 0.00001643
Iteration 114/1000 | Loss: 0.00001643
Iteration 115/1000 | Loss: 0.00001643
Iteration 116/1000 | Loss: 0.00001643
Iteration 117/1000 | Loss: 0.00001643
Iteration 118/1000 | Loss: 0.00001642
Iteration 119/1000 | Loss: 0.00001642
Iteration 120/1000 | Loss: 0.00001642
Iteration 121/1000 | Loss: 0.00001642
Iteration 122/1000 | Loss: 0.00001642
Iteration 123/1000 | Loss: 0.00001642
Iteration 124/1000 | Loss: 0.00001642
Iteration 125/1000 | Loss: 0.00001642
Iteration 126/1000 | Loss: 0.00001642
Iteration 127/1000 | Loss: 0.00001642
Iteration 128/1000 | Loss: 0.00001642
Iteration 129/1000 | Loss: 0.00001642
Iteration 130/1000 | Loss: 0.00001642
Iteration 131/1000 | Loss: 0.00001642
Iteration 132/1000 | Loss: 0.00001642
Iteration 133/1000 | Loss: 0.00001642
Iteration 134/1000 | Loss: 0.00001642
Iteration 135/1000 | Loss: 0.00001642
Iteration 136/1000 | Loss: 0.00001642
Iteration 137/1000 | Loss: 0.00001642
Iteration 138/1000 | Loss: 0.00001642
Iteration 139/1000 | Loss: 0.00001642
Iteration 140/1000 | Loss: 0.00001642
Iteration 141/1000 | Loss: 0.00001642
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [1.641993185330648e-05, 1.641993185330648e-05, 1.641993185330648e-05, 1.641993185330648e-05, 1.641993185330648e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.641993185330648e-05

Optimization complete. Final v2v error: 3.441011428833008 mm

Highest mean error: 3.8220674991607666 mm for frame 124

Lowest mean error: 3.1666903495788574 mm for frame 13

Saving results

Total time: 30.669406175613403
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01125239
Iteration 2/25 | Loss: 0.00228678
Iteration 3/25 | Loss: 0.00163593
Iteration 4/25 | Loss: 0.00150317
Iteration 5/25 | Loss: 0.00135134
Iteration 6/25 | Loss: 0.00131098
Iteration 7/25 | Loss: 0.00120158
Iteration 8/25 | Loss: 0.00110988
Iteration 9/25 | Loss: 0.00121925
Iteration 10/25 | Loss: 0.00106991
Iteration 11/25 | Loss: 0.00103215
Iteration 12/25 | Loss: 0.00102891
Iteration 13/25 | Loss: 0.00102574
Iteration 14/25 | Loss: 0.00102618
Iteration 15/25 | Loss: 0.00102507
Iteration 16/25 | Loss: 0.00103616
Iteration 17/25 | Loss: 0.00103094
Iteration 18/25 | Loss: 0.00102041
Iteration 19/25 | Loss: 0.00101563
Iteration 20/25 | Loss: 0.00101550
Iteration 21/25 | Loss: 0.00101386
Iteration 22/25 | Loss: 0.00101282
Iteration 23/25 | Loss: 0.00101855
Iteration 24/25 | Loss: 0.00101726
Iteration 25/25 | Loss: 0.00101641

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52135801
Iteration 2/25 | Loss: 0.00215855
Iteration 3/25 | Loss: 0.00176268
Iteration 4/25 | Loss: 0.00176268
Iteration 5/25 | Loss: 0.00176268
Iteration 6/25 | Loss: 0.00176268
Iteration 7/25 | Loss: 0.00176268
Iteration 8/25 | Loss: 0.00176268
Iteration 9/25 | Loss: 0.00176268
Iteration 10/25 | Loss: 0.00176268
Iteration 11/25 | Loss: 0.00176268
Iteration 12/25 | Loss: 0.00176268
Iteration 13/25 | Loss: 0.00176268
Iteration 14/25 | Loss: 0.00176268
Iteration 15/25 | Loss: 0.00176268
Iteration 16/25 | Loss: 0.00176268
Iteration 17/25 | Loss: 0.00176268
Iteration 18/25 | Loss: 0.00176268
Iteration 19/25 | Loss: 0.00176268
Iteration 20/25 | Loss: 0.00176268
Iteration 21/25 | Loss: 0.00176268
Iteration 22/25 | Loss: 0.00176268
Iteration 23/25 | Loss: 0.00176268
Iteration 24/25 | Loss: 0.00176268
Iteration 25/25 | Loss: 0.00176268

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00176268
Iteration 2/1000 | Loss: 0.00061281
Iteration 3/1000 | Loss: 0.00050127
Iteration 4/1000 | Loss: 0.00021478
Iteration 5/1000 | Loss: 0.00017560
Iteration 6/1000 | Loss: 0.00094004
Iteration 7/1000 | Loss: 0.00023869
Iteration 8/1000 | Loss: 0.00059709
Iteration 9/1000 | Loss: 0.00101198
Iteration 10/1000 | Loss: 0.00160351
Iteration 11/1000 | Loss: 0.00442865
Iteration 12/1000 | Loss: 0.00327696
Iteration 13/1000 | Loss: 0.00193119
Iteration 14/1000 | Loss: 0.00293046
Iteration 15/1000 | Loss: 0.00217872
Iteration 16/1000 | Loss: 0.00200253
Iteration 17/1000 | Loss: 0.00111818
Iteration 18/1000 | Loss: 0.00157073
Iteration 19/1000 | Loss: 0.00184721
Iteration 20/1000 | Loss: 0.00152579
Iteration 21/1000 | Loss: 0.00140343
Iteration 22/1000 | Loss: 0.00119856
Iteration 23/1000 | Loss: 0.00069596
Iteration 24/1000 | Loss: 0.00040927
Iteration 25/1000 | Loss: 0.00194706
Iteration 26/1000 | Loss: 0.00119064
Iteration 27/1000 | Loss: 0.00192970
Iteration 28/1000 | Loss: 0.00158252
Iteration 29/1000 | Loss: 0.00197799
Iteration 30/1000 | Loss: 0.00254492
Iteration 31/1000 | Loss: 0.00263065
Iteration 32/1000 | Loss: 0.00155156
Iteration 33/1000 | Loss: 0.00141150
Iteration 34/1000 | Loss: 0.00256357
Iteration 35/1000 | Loss: 0.00081374
Iteration 36/1000 | Loss: 0.00051070
Iteration 37/1000 | Loss: 0.00012252
Iteration 38/1000 | Loss: 0.00077810
Iteration 39/1000 | Loss: 0.00095936
Iteration 40/1000 | Loss: 0.00045487
Iteration 41/1000 | Loss: 0.00008867
Iteration 42/1000 | Loss: 0.00038027
Iteration 43/1000 | Loss: 0.00007254
Iteration 44/1000 | Loss: 0.00068350
Iteration 45/1000 | Loss: 0.00013346
Iteration 46/1000 | Loss: 0.00026368
Iteration 47/1000 | Loss: 0.00007438
Iteration 48/1000 | Loss: 0.00005903
Iteration 49/1000 | Loss: 0.00005356
Iteration 50/1000 | Loss: 0.00004788
Iteration 51/1000 | Loss: 0.00009801
Iteration 52/1000 | Loss: 0.00008723
Iteration 53/1000 | Loss: 0.00009424
Iteration 54/1000 | Loss: 0.00007578
Iteration 55/1000 | Loss: 0.00009136
Iteration 56/1000 | Loss: 0.00046123
Iteration 57/1000 | Loss: 0.00008649
Iteration 58/1000 | Loss: 0.00005889
Iteration 59/1000 | Loss: 0.00004218
Iteration 60/1000 | Loss: 0.00003854
Iteration 61/1000 | Loss: 0.00003628
Iteration 62/1000 | Loss: 0.00003475
Iteration 63/1000 | Loss: 0.00041571
Iteration 64/1000 | Loss: 0.00005283
Iteration 65/1000 | Loss: 0.00003799
Iteration 66/1000 | Loss: 0.00003422
Iteration 67/1000 | Loss: 0.00003129
Iteration 68/1000 | Loss: 0.00003137
Iteration 69/1000 | Loss: 0.00002971
Iteration 70/1000 | Loss: 0.00002939
Iteration 71/1000 | Loss: 0.00002916
Iteration 72/1000 | Loss: 0.00002926
Iteration 73/1000 | Loss: 0.00002891
Iteration 74/1000 | Loss: 0.00002891
Iteration 75/1000 | Loss: 0.00002890
Iteration 76/1000 | Loss: 0.00002890
Iteration 77/1000 | Loss: 0.00002889
Iteration 78/1000 | Loss: 0.00002889
Iteration 79/1000 | Loss: 0.00002888
Iteration 80/1000 | Loss: 0.00002888
Iteration 81/1000 | Loss: 0.00002887
Iteration 82/1000 | Loss: 0.00002875
Iteration 83/1000 | Loss: 0.00002870
Iteration 84/1000 | Loss: 0.00002869
Iteration 85/1000 | Loss: 0.00002865
Iteration 86/1000 | Loss: 0.00002865
Iteration 87/1000 | Loss: 0.00002864
Iteration 88/1000 | Loss: 0.00007722
Iteration 89/1000 | Loss: 0.00007722
Iteration 90/1000 | Loss: 0.00010211
Iteration 91/1000 | Loss: 0.00002894
Iteration 92/1000 | Loss: 0.00007797
Iteration 93/1000 | Loss: 0.00006323
Iteration 94/1000 | Loss: 0.00003997
Iteration 95/1000 | Loss: 0.00003401
Iteration 96/1000 | Loss: 0.00003372
Iteration 97/1000 | Loss: 0.00002931
Iteration 98/1000 | Loss: 0.00002862
Iteration 99/1000 | Loss: 0.00002857
Iteration 100/1000 | Loss: 0.00002855
Iteration 101/1000 | Loss: 0.00002855
Iteration 102/1000 | Loss: 0.00002855
Iteration 103/1000 | Loss: 0.00003015
Iteration 104/1000 | Loss: 0.00002904
Iteration 105/1000 | Loss: 0.00003037
Iteration 106/1000 | Loss: 0.00002896
Iteration 107/1000 | Loss: 0.00002851
Iteration 108/1000 | Loss: 0.00003014
Iteration 109/1000 | Loss: 0.00002889
Iteration 110/1000 | Loss: 0.00003020
Iteration 111/1000 | Loss: 0.00002878
Iteration 112/1000 | Loss: 0.00002850
Iteration 113/1000 | Loss: 0.00003003
Iteration 114/1000 | Loss: 0.00002880
Iteration 115/1000 | Loss: 0.00002880
Iteration 116/1000 | Loss: 0.00002880
Iteration 117/1000 | Loss: 0.00002880
Iteration 118/1000 | Loss: 0.00002880
Iteration 119/1000 | Loss: 0.00002879
Iteration 120/1000 | Loss: 0.00002878
Iteration 121/1000 | Loss: 0.00002870
Iteration 122/1000 | Loss: 0.00007880
Iteration 123/1000 | Loss: 0.00004250
Iteration 124/1000 | Loss: 0.00007641
Iteration 125/1000 | Loss: 0.00006877
Iteration 126/1000 | Loss: 0.00007650
Iteration 127/1000 | Loss: 0.00007650
Iteration 128/1000 | Loss: 0.00007650
Iteration 129/1000 | Loss: 0.00007650
Iteration 130/1000 | Loss: 0.00006083
Iteration 131/1000 | Loss: 0.00007162
Iteration 132/1000 | Loss: 0.00008213
Iteration 133/1000 | Loss: 0.00009584
Iteration 134/1000 | Loss: 0.00007988
Iteration 135/1000 | Loss: 0.00003420
Iteration 136/1000 | Loss: 0.00003213
Iteration 137/1000 | Loss: 0.00003099
Iteration 138/1000 | Loss: 0.00003742
Iteration 139/1000 | Loss: 0.00006082
Iteration 140/1000 | Loss: 0.00003670
Iteration 141/1000 | Loss: 0.00007376
Iteration 142/1000 | Loss: 0.00004259
Iteration 143/1000 | Loss: 0.00007109
Iteration 144/1000 | Loss: 0.00003468
Iteration 145/1000 | Loss: 0.00003186
Iteration 146/1000 | Loss: 0.00002988
Iteration 147/1000 | Loss: 0.00002939
Iteration 148/1000 | Loss: 0.00002914
Iteration 149/1000 | Loss: 0.00031040
Iteration 150/1000 | Loss: 0.00006951
Iteration 151/1000 | Loss: 0.00011422
Iteration 152/1000 | Loss: 0.00002980
Iteration 153/1000 | Loss: 0.00002805
Iteration 154/1000 | Loss: 0.00002749
Iteration 155/1000 | Loss: 0.00002705
Iteration 156/1000 | Loss: 0.00002679
Iteration 157/1000 | Loss: 0.00002680
Iteration 158/1000 | Loss: 0.00002650
Iteration 159/1000 | Loss: 0.00002650
Iteration 160/1000 | Loss: 0.00002648
Iteration 161/1000 | Loss: 0.00002644
Iteration 162/1000 | Loss: 0.00002644
Iteration 163/1000 | Loss: 0.00002642
Iteration 164/1000 | Loss: 0.00002640
Iteration 165/1000 | Loss: 0.00002636
Iteration 166/1000 | Loss: 0.00002634
Iteration 167/1000 | Loss: 0.00002634
Iteration 168/1000 | Loss: 0.00002634
Iteration 169/1000 | Loss: 0.00002634
Iteration 170/1000 | Loss: 0.00002634
Iteration 171/1000 | Loss: 0.00002634
Iteration 172/1000 | Loss: 0.00002634
Iteration 173/1000 | Loss: 0.00002634
Iteration 174/1000 | Loss: 0.00002633
Iteration 175/1000 | Loss: 0.00002632
Iteration 176/1000 | Loss: 0.00002632
Iteration 177/1000 | Loss: 0.00002632
Iteration 178/1000 | Loss: 0.00002632
Iteration 179/1000 | Loss: 0.00002631
Iteration 180/1000 | Loss: 0.00002631
Iteration 181/1000 | Loss: 0.00002631
Iteration 182/1000 | Loss: 0.00002631
Iteration 183/1000 | Loss: 0.00002630
Iteration 184/1000 | Loss: 0.00002630
Iteration 185/1000 | Loss: 0.00002630
Iteration 186/1000 | Loss: 0.00002630
Iteration 187/1000 | Loss: 0.00002630
Iteration 188/1000 | Loss: 0.00002630
Iteration 189/1000 | Loss: 0.00002629
Iteration 190/1000 | Loss: 0.00002629
Iteration 191/1000 | Loss: 0.00002629
Iteration 192/1000 | Loss: 0.00002629
Iteration 193/1000 | Loss: 0.00002629
Iteration 194/1000 | Loss: 0.00002629
Iteration 195/1000 | Loss: 0.00002629
Iteration 196/1000 | Loss: 0.00002628
Iteration 197/1000 | Loss: 0.00002628
Iteration 198/1000 | Loss: 0.00002628
Iteration 199/1000 | Loss: 0.00002628
Iteration 200/1000 | Loss: 0.00002627
Iteration 201/1000 | Loss: 0.00002627
Iteration 202/1000 | Loss: 0.00002627
Iteration 203/1000 | Loss: 0.00002626
Iteration 204/1000 | Loss: 0.00002626
Iteration 205/1000 | Loss: 0.00002626
Iteration 206/1000 | Loss: 0.00002625
Iteration 207/1000 | Loss: 0.00002625
Iteration 208/1000 | Loss: 0.00002625
Iteration 209/1000 | Loss: 0.00002625
Iteration 210/1000 | Loss: 0.00002624
Iteration 211/1000 | Loss: 0.00002624
Iteration 212/1000 | Loss: 0.00002623
Iteration 213/1000 | Loss: 0.00002623
Iteration 214/1000 | Loss: 0.00002623
Iteration 215/1000 | Loss: 0.00002622
Iteration 216/1000 | Loss: 0.00002622
Iteration 217/1000 | Loss: 0.00002622
Iteration 218/1000 | Loss: 0.00002621
Iteration 219/1000 | Loss: 0.00002621
Iteration 220/1000 | Loss: 0.00002621
Iteration 221/1000 | Loss: 0.00002621
Iteration 222/1000 | Loss: 0.00002620
Iteration 223/1000 | Loss: 0.00002620
Iteration 224/1000 | Loss: 0.00002620
Iteration 225/1000 | Loss: 0.00002620
Iteration 226/1000 | Loss: 0.00002620
Iteration 227/1000 | Loss: 0.00002620
Iteration 228/1000 | Loss: 0.00002620
Iteration 229/1000 | Loss: 0.00002620
Iteration 230/1000 | Loss: 0.00002620
Iteration 231/1000 | Loss: 0.00002620
Iteration 232/1000 | Loss: 0.00002620
Iteration 233/1000 | Loss: 0.00002620
Iteration 234/1000 | Loss: 0.00002620
Iteration 235/1000 | Loss: 0.00002620
Iteration 236/1000 | Loss: 0.00002620
Iteration 237/1000 | Loss: 0.00002620
Iteration 238/1000 | Loss: 0.00002620
Iteration 239/1000 | Loss: 0.00002620
Iteration 240/1000 | Loss: 0.00002620
Iteration 241/1000 | Loss: 0.00002620
Iteration 242/1000 | Loss: 0.00002620
Iteration 243/1000 | Loss: 0.00002620
Iteration 244/1000 | Loss: 0.00002620
Iteration 245/1000 | Loss: 0.00002620
Iteration 246/1000 | Loss: 0.00002620
Iteration 247/1000 | Loss: 0.00002620
Iteration 248/1000 | Loss: 0.00002620
Iteration 249/1000 | Loss: 0.00002620
Iteration 250/1000 | Loss: 0.00002620
Iteration 251/1000 | Loss: 0.00002620
Iteration 252/1000 | Loss: 0.00002620
Iteration 253/1000 | Loss: 0.00002620
Iteration 254/1000 | Loss: 0.00002620
Iteration 255/1000 | Loss: 0.00002620
Iteration 256/1000 | Loss: 0.00002620
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 256. Stopping optimization.
Last 5 losses: [2.6202191293123178e-05, 2.6202191293123178e-05, 2.6202191293123178e-05, 2.6202191293123178e-05, 2.6202191293123178e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6202191293123178e-05

Optimization complete. Final v2v error: 3.8654794692993164 mm

Highest mean error: 12.733190536499023 mm for frame 105

Lowest mean error: 3.3911964893341064 mm for frame 22

Saving results

Total time: 221.8979811668396
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01185123
Iteration 2/25 | Loss: 0.00254552
Iteration 3/25 | Loss: 0.00263016
Iteration 4/25 | Loss: 0.00197555
Iteration 5/25 | Loss: 0.00172278
Iteration 6/25 | Loss: 0.00161528
Iteration 7/25 | Loss: 0.00142026
Iteration 8/25 | Loss: 0.00124013
Iteration 9/25 | Loss: 0.00118936
Iteration 10/25 | Loss: 0.00110272
Iteration 11/25 | Loss: 0.00108019
Iteration 12/25 | Loss: 0.00108335
Iteration 13/25 | Loss: 0.00107607
Iteration 14/25 | Loss: 0.00106935
Iteration 15/25 | Loss: 0.00105897
Iteration 16/25 | Loss: 0.00106255
Iteration 17/25 | Loss: 0.00105988
Iteration 18/25 | Loss: 0.00109793
Iteration 19/25 | Loss: 0.00105946
Iteration 20/25 | Loss: 0.00106506
Iteration 21/25 | Loss: 0.00103120
Iteration 22/25 | Loss: 0.00106157
Iteration 23/25 | Loss: 0.00105915
Iteration 24/25 | Loss: 0.00106513
Iteration 25/25 | Loss: 0.00105693

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60691953
Iteration 2/25 | Loss: 0.00159351
Iteration 3/25 | Loss: 0.00159350
Iteration 4/25 | Loss: 0.00159350
Iteration 5/25 | Loss: 0.00159350
Iteration 6/25 | Loss: 0.00159350
Iteration 7/25 | Loss: 0.00159350
Iteration 8/25 | Loss: 0.00159350
Iteration 9/25 | Loss: 0.00159350
Iteration 10/25 | Loss: 0.00159350
Iteration 11/25 | Loss: 0.00159350
Iteration 12/25 | Loss: 0.00159350
Iteration 13/25 | Loss: 0.00159350
Iteration 14/25 | Loss: 0.00159350
Iteration 15/25 | Loss: 0.00159350
Iteration 16/25 | Loss: 0.00159350
Iteration 17/25 | Loss: 0.00159350
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0015935020055621862, 0.0015935020055621862, 0.0015935020055621862, 0.0015935020055621862, 0.0015935020055621862]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015935020055621862

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00159350
Iteration 2/1000 | Loss: 0.00487417
Iteration 3/1000 | Loss: 0.00410381
Iteration 4/1000 | Loss: 0.00196237
Iteration 5/1000 | Loss: 0.00218746
Iteration 6/1000 | Loss: 0.00182407
Iteration 7/1000 | Loss: 0.00178494
Iteration 8/1000 | Loss: 0.00420643
Iteration 9/1000 | Loss: 0.00311307
Iteration 10/1000 | Loss: 0.00455050
Iteration 11/1000 | Loss: 0.00389490
Iteration 12/1000 | Loss: 0.00364237
Iteration 13/1000 | Loss: 0.00405380
Iteration 14/1000 | Loss: 0.00279270
Iteration 15/1000 | Loss: 0.00224465
Iteration 16/1000 | Loss: 0.00307009
Iteration 17/1000 | Loss: 0.00258838
Iteration 18/1000 | Loss: 0.00314979
Iteration 19/1000 | Loss: 0.00259780
Iteration 20/1000 | Loss: 0.00484695
Iteration 21/1000 | Loss: 0.00360664
Iteration 22/1000 | Loss: 0.00461637
Iteration 23/1000 | Loss: 0.00213863
Iteration 24/1000 | Loss: 0.00068396
Iteration 25/1000 | Loss: 0.00343379
Iteration 26/1000 | Loss: 0.00279241
Iteration 27/1000 | Loss: 0.00257653
Iteration 28/1000 | Loss: 0.00320359
Iteration 29/1000 | Loss: 0.00362002
Iteration 30/1000 | Loss: 0.00009925
Iteration 31/1000 | Loss: 0.00103144
Iteration 32/1000 | Loss: 0.00102814
Iteration 33/1000 | Loss: 0.00237816
Iteration 34/1000 | Loss: 0.00349924
Iteration 35/1000 | Loss: 0.00438949
Iteration 36/1000 | Loss: 0.00139602
Iteration 37/1000 | Loss: 0.00537397
Iteration 38/1000 | Loss: 0.00103153
Iteration 39/1000 | Loss: 0.00139547
Iteration 40/1000 | Loss: 0.00080981
Iteration 41/1000 | Loss: 0.00007790
Iteration 42/1000 | Loss: 0.00162622
Iteration 43/1000 | Loss: 0.00367615
Iteration 44/1000 | Loss: 0.00179022
Iteration 45/1000 | Loss: 0.00006202
Iteration 46/1000 | Loss: 0.00098351
Iteration 47/1000 | Loss: 0.00012243
Iteration 48/1000 | Loss: 0.00125576
Iteration 49/1000 | Loss: 0.00129581
Iteration 50/1000 | Loss: 0.00145564
Iteration 51/1000 | Loss: 0.00139676
Iteration 52/1000 | Loss: 0.00129592
Iteration 53/1000 | Loss: 0.00294125
Iteration 54/1000 | Loss: 0.00255628
Iteration 55/1000 | Loss: 0.00323968
Iteration 56/1000 | Loss: 0.00037010
Iteration 57/1000 | Loss: 0.00215919
Iteration 58/1000 | Loss: 0.00019966
Iteration 59/1000 | Loss: 0.00014925
Iteration 60/1000 | Loss: 0.00007241
Iteration 61/1000 | Loss: 0.00138947
Iteration 62/1000 | Loss: 0.00005308
Iteration 63/1000 | Loss: 0.00267149
Iteration 64/1000 | Loss: 0.00171361
Iteration 65/1000 | Loss: 0.00008431
Iteration 66/1000 | Loss: 0.00359482
Iteration 67/1000 | Loss: 0.00260432
Iteration 68/1000 | Loss: 0.00225158
Iteration 69/1000 | Loss: 0.00036216
Iteration 70/1000 | Loss: 0.00005452
Iteration 71/1000 | Loss: 0.00004123
Iteration 72/1000 | Loss: 0.00003143
Iteration 73/1000 | Loss: 0.00002932
Iteration 74/1000 | Loss: 0.00002778
Iteration 75/1000 | Loss: 0.00002687
Iteration 76/1000 | Loss: 0.00002636
Iteration 77/1000 | Loss: 0.00002608
Iteration 78/1000 | Loss: 0.00002582
Iteration 79/1000 | Loss: 0.00002557
Iteration 80/1000 | Loss: 0.00002543
Iteration 81/1000 | Loss: 0.00002543
Iteration 82/1000 | Loss: 0.00002542
Iteration 83/1000 | Loss: 0.00002542
Iteration 84/1000 | Loss: 0.00002540
Iteration 85/1000 | Loss: 0.00002539
Iteration 86/1000 | Loss: 0.00002538
Iteration 87/1000 | Loss: 0.00002538
Iteration 88/1000 | Loss: 0.00002537
Iteration 89/1000 | Loss: 0.00002537
Iteration 90/1000 | Loss: 0.00002537
Iteration 91/1000 | Loss: 0.00002536
Iteration 92/1000 | Loss: 0.00002536
Iteration 93/1000 | Loss: 0.00002536
Iteration 94/1000 | Loss: 0.00002535
Iteration 95/1000 | Loss: 0.00002533
Iteration 96/1000 | Loss: 0.00002533
Iteration 97/1000 | Loss: 0.00002531
Iteration 98/1000 | Loss: 0.00002531
Iteration 99/1000 | Loss: 0.00002531
Iteration 100/1000 | Loss: 0.00002530
Iteration 101/1000 | Loss: 0.00002530
Iteration 102/1000 | Loss: 0.00002530
Iteration 103/1000 | Loss: 0.00002529
Iteration 104/1000 | Loss: 0.00002529
Iteration 105/1000 | Loss: 0.00002529
Iteration 106/1000 | Loss: 0.00002528
Iteration 107/1000 | Loss: 0.00002528
Iteration 108/1000 | Loss: 0.00002527
Iteration 109/1000 | Loss: 0.00002526
Iteration 110/1000 | Loss: 0.00002526
Iteration 111/1000 | Loss: 0.00002525
Iteration 112/1000 | Loss: 0.00002525
Iteration 113/1000 | Loss: 0.00002525
Iteration 114/1000 | Loss: 0.00002525
Iteration 115/1000 | Loss: 0.00002524
Iteration 116/1000 | Loss: 0.00002524
Iteration 117/1000 | Loss: 0.00002524
Iteration 118/1000 | Loss: 0.00002524
Iteration 119/1000 | Loss: 0.00002524
Iteration 120/1000 | Loss: 0.00002523
Iteration 121/1000 | Loss: 0.00002523
Iteration 122/1000 | Loss: 0.00002522
Iteration 123/1000 | Loss: 0.00002522
Iteration 124/1000 | Loss: 0.00002522
Iteration 125/1000 | Loss: 0.00002522
Iteration 126/1000 | Loss: 0.00002521
Iteration 127/1000 | Loss: 0.00002521
Iteration 128/1000 | Loss: 0.00002521
Iteration 129/1000 | Loss: 0.00002521
Iteration 130/1000 | Loss: 0.00002521
Iteration 131/1000 | Loss: 0.00002521
Iteration 132/1000 | Loss: 0.00002521
Iteration 133/1000 | Loss: 0.00002521
Iteration 134/1000 | Loss: 0.00002520
Iteration 135/1000 | Loss: 0.00002520
Iteration 136/1000 | Loss: 0.00002520
Iteration 137/1000 | Loss: 0.00002520
Iteration 138/1000 | Loss: 0.00002520
Iteration 139/1000 | Loss: 0.00002520
Iteration 140/1000 | Loss: 0.00002520
Iteration 141/1000 | Loss: 0.00002520
Iteration 142/1000 | Loss: 0.00002520
Iteration 143/1000 | Loss: 0.00002520
Iteration 144/1000 | Loss: 0.00002519
Iteration 145/1000 | Loss: 0.00002519
Iteration 146/1000 | Loss: 0.00002519
Iteration 147/1000 | Loss: 0.00002519
Iteration 148/1000 | Loss: 0.00002519
Iteration 149/1000 | Loss: 0.00002519
Iteration 150/1000 | Loss: 0.00002519
Iteration 151/1000 | Loss: 0.00002519
Iteration 152/1000 | Loss: 0.00002519
Iteration 153/1000 | Loss: 0.00002519
Iteration 154/1000 | Loss: 0.00002518
Iteration 155/1000 | Loss: 0.00002518
Iteration 156/1000 | Loss: 0.00002518
Iteration 157/1000 | Loss: 0.00002518
Iteration 158/1000 | Loss: 0.00002518
Iteration 159/1000 | Loss: 0.00002518
Iteration 160/1000 | Loss: 0.00002518
Iteration 161/1000 | Loss: 0.00002518
Iteration 162/1000 | Loss: 0.00002518
Iteration 163/1000 | Loss: 0.00002518
Iteration 164/1000 | Loss: 0.00002518
Iteration 165/1000 | Loss: 0.00002518
Iteration 166/1000 | Loss: 0.00002518
Iteration 167/1000 | Loss: 0.00002518
Iteration 168/1000 | Loss: 0.00002518
Iteration 169/1000 | Loss: 0.00002518
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 169. Stopping optimization.
Last 5 losses: [2.51821729762014e-05, 2.51821729762014e-05, 2.51821729762014e-05, 2.51821729762014e-05, 2.51821729762014e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.51821729762014e-05

Optimization complete. Final v2v error: 4.2314677238464355 mm

Highest mean error: 6.083775997161865 mm for frame 72

Lowest mean error: 3.437211275100708 mm for frame 0

Saving results

Total time: 163.44637966156006
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00720609
Iteration 2/25 | Loss: 0.00118225
Iteration 3/25 | Loss: 0.00097525
Iteration 4/25 | Loss: 0.00094435
Iteration 5/25 | Loss: 0.00093016
Iteration 6/25 | Loss: 0.00092740
Iteration 7/25 | Loss: 0.00092680
Iteration 8/25 | Loss: 0.00092672
Iteration 9/25 | Loss: 0.00092672
Iteration 10/25 | Loss: 0.00092672
Iteration 11/25 | Loss: 0.00092672
Iteration 12/25 | Loss: 0.00092672
Iteration 13/25 | Loss: 0.00092672
Iteration 14/25 | Loss: 0.00092672
Iteration 15/25 | Loss: 0.00092672
Iteration 16/25 | Loss: 0.00092672
Iteration 17/25 | Loss: 0.00092672
Iteration 18/25 | Loss: 0.00092672
Iteration 19/25 | Loss: 0.00092672
Iteration 20/25 | Loss: 0.00092672
Iteration 21/25 | Loss: 0.00092672
Iteration 22/25 | Loss: 0.00092672
Iteration 23/25 | Loss: 0.00092672
Iteration 24/25 | Loss: 0.00092672
Iteration 25/25 | Loss: 0.00092672

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58841038
Iteration 2/25 | Loss: 0.00064311
Iteration 3/25 | Loss: 0.00064311
Iteration 4/25 | Loss: 0.00064311
Iteration 5/25 | Loss: 0.00064311
Iteration 6/25 | Loss: 0.00064311
Iteration 7/25 | Loss: 0.00064311
Iteration 8/25 | Loss: 0.00064311
Iteration 9/25 | Loss: 0.00064311
Iteration 10/25 | Loss: 0.00064311
Iteration 11/25 | Loss: 0.00064311
Iteration 12/25 | Loss: 0.00064311
Iteration 13/25 | Loss: 0.00064311
Iteration 14/25 | Loss: 0.00064311
Iteration 15/25 | Loss: 0.00064311
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0006431062356568873, 0.0006431062356568873, 0.0006431062356568873, 0.0006431062356568873, 0.0006431062356568873]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006431062356568873

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00064311
Iteration 2/1000 | Loss: 0.00004503
Iteration 3/1000 | Loss: 0.00002659
Iteration 4/1000 | Loss: 0.00002204
Iteration 5/1000 | Loss: 0.00002125
Iteration 6/1000 | Loss: 0.00002029
Iteration 7/1000 | Loss: 0.00001986
Iteration 8/1000 | Loss: 0.00001964
Iteration 9/1000 | Loss: 0.00001945
Iteration 10/1000 | Loss: 0.00001931
Iteration 11/1000 | Loss: 0.00001930
Iteration 12/1000 | Loss: 0.00001926
Iteration 13/1000 | Loss: 0.00001925
Iteration 14/1000 | Loss: 0.00001925
Iteration 15/1000 | Loss: 0.00001925
Iteration 16/1000 | Loss: 0.00001925
Iteration 17/1000 | Loss: 0.00001924
Iteration 18/1000 | Loss: 0.00001923
Iteration 19/1000 | Loss: 0.00001920
Iteration 20/1000 | Loss: 0.00001917
Iteration 21/1000 | Loss: 0.00001914
Iteration 22/1000 | Loss: 0.00001913
Iteration 23/1000 | Loss: 0.00001913
Iteration 24/1000 | Loss: 0.00001913
Iteration 25/1000 | Loss: 0.00001913
Iteration 26/1000 | Loss: 0.00001912
Iteration 27/1000 | Loss: 0.00001911
Iteration 28/1000 | Loss: 0.00001911
Iteration 29/1000 | Loss: 0.00001911
Iteration 30/1000 | Loss: 0.00001910
Iteration 31/1000 | Loss: 0.00001910
Iteration 32/1000 | Loss: 0.00001910
Iteration 33/1000 | Loss: 0.00001910
Iteration 34/1000 | Loss: 0.00001909
Iteration 35/1000 | Loss: 0.00001909
Iteration 36/1000 | Loss: 0.00001909
Iteration 37/1000 | Loss: 0.00001909
Iteration 38/1000 | Loss: 0.00001908
Iteration 39/1000 | Loss: 0.00001908
Iteration 40/1000 | Loss: 0.00001908
Iteration 41/1000 | Loss: 0.00001907
Iteration 42/1000 | Loss: 0.00001907
Iteration 43/1000 | Loss: 0.00001907
Iteration 44/1000 | Loss: 0.00001907
Iteration 45/1000 | Loss: 0.00001906
Iteration 46/1000 | Loss: 0.00001906
Iteration 47/1000 | Loss: 0.00001906
Iteration 48/1000 | Loss: 0.00001906
Iteration 49/1000 | Loss: 0.00001906
Iteration 50/1000 | Loss: 0.00001906
Iteration 51/1000 | Loss: 0.00001905
Iteration 52/1000 | Loss: 0.00001905
Iteration 53/1000 | Loss: 0.00001905
Iteration 54/1000 | Loss: 0.00001905
Iteration 55/1000 | Loss: 0.00001905
Iteration 56/1000 | Loss: 0.00001905
Iteration 57/1000 | Loss: 0.00001905
Iteration 58/1000 | Loss: 0.00001905
Iteration 59/1000 | Loss: 0.00001905
Iteration 60/1000 | Loss: 0.00001905
Iteration 61/1000 | Loss: 0.00001904
Iteration 62/1000 | Loss: 0.00001904
Iteration 63/1000 | Loss: 0.00001904
Iteration 64/1000 | Loss: 0.00001904
Iteration 65/1000 | Loss: 0.00001904
Iteration 66/1000 | Loss: 0.00001904
Iteration 67/1000 | Loss: 0.00001904
Iteration 68/1000 | Loss: 0.00001904
Iteration 69/1000 | Loss: 0.00001904
Iteration 70/1000 | Loss: 0.00001904
Iteration 71/1000 | Loss: 0.00001904
Iteration 72/1000 | Loss: 0.00001904
Iteration 73/1000 | Loss: 0.00001903
Iteration 74/1000 | Loss: 0.00001903
Iteration 75/1000 | Loss: 0.00001903
Iteration 76/1000 | Loss: 0.00001903
Iteration 77/1000 | Loss: 0.00001903
Iteration 78/1000 | Loss: 0.00001903
Iteration 79/1000 | Loss: 0.00001903
Iteration 80/1000 | Loss: 0.00001903
Iteration 81/1000 | Loss: 0.00001903
Iteration 82/1000 | Loss: 0.00001903
Iteration 83/1000 | Loss: 0.00001903
Iteration 84/1000 | Loss: 0.00001903
Iteration 85/1000 | Loss: 0.00001903
Iteration 86/1000 | Loss: 0.00001903
Iteration 87/1000 | Loss: 0.00001903
Iteration 88/1000 | Loss: 0.00001903
Iteration 89/1000 | Loss: 0.00001903
Iteration 90/1000 | Loss: 0.00001903
Iteration 91/1000 | Loss: 0.00001903
Iteration 92/1000 | Loss: 0.00001902
Iteration 93/1000 | Loss: 0.00001902
Iteration 94/1000 | Loss: 0.00001902
Iteration 95/1000 | Loss: 0.00001902
Iteration 96/1000 | Loss: 0.00001902
Iteration 97/1000 | Loss: 0.00001902
Iteration 98/1000 | Loss: 0.00001902
Iteration 99/1000 | Loss: 0.00001902
Iteration 100/1000 | Loss: 0.00001902
Iteration 101/1000 | Loss: 0.00001902
Iteration 102/1000 | Loss: 0.00001902
Iteration 103/1000 | Loss: 0.00001902
Iteration 104/1000 | Loss: 0.00001902
Iteration 105/1000 | Loss: 0.00001902
Iteration 106/1000 | Loss: 0.00001902
Iteration 107/1000 | Loss: 0.00001902
Iteration 108/1000 | Loss: 0.00001902
Iteration 109/1000 | Loss: 0.00001902
Iteration 110/1000 | Loss: 0.00001902
Iteration 111/1000 | Loss: 0.00001902
Iteration 112/1000 | Loss: 0.00001902
Iteration 113/1000 | Loss: 0.00001902
Iteration 114/1000 | Loss: 0.00001902
Iteration 115/1000 | Loss: 0.00001902
Iteration 116/1000 | Loss: 0.00001902
Iteration 117/1000 | Loss: 0.00001902
Iteration 118/1000 | Loss: 0.00001902
Iteration 119/1000 | Loss: 0.00001902
Iteration 120/1000 | Loss: 0.00001902
Iteration 121/1000 | Loss: 0.00001902
Iteration 122/1000 | Loss: 0.00001902
Iteration 123/1000 | Loss: 0.00001902
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.9020775653189048e-05, 1.9020775653189048e-05, 1.9020775653189048e-05, 1.9020775653189048e-05, 1.9020775653189048e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9020775653189048e-05

Optimization complete. Final v2v error: 3.761641025543213 mm

Highest mean error: 4.803956508636475 mm for frame 73

Lowest mean error: 3.2730681896209717 mm for frame 134

Saving results

Total time: 31.861011743545532
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01064249
Iteration 2/25 | Loss: 0.00280060
Iteration 3/25 | Loss: 0.00155413
Iteration 4/25 | Loss: 0.00140642
Iteration 5/25 | Loss: 0.00138405
Iteration 6/25 | Loss: 0.00125458
Iteration 7/25 | Loss: 0.00121537
Iteration 8/25 | Loss: 0.00108726
Iteration 9/25 | Loss: 0.00096608
Iteration 10/25 | Loss: 0.00088979
Iteration 11/25 | Loss: 0.00086886
Iteration 12/25 | Loss: 0.00088371
Iteration 13/25 | Loss: 0.00086503
Iteration 14/25 | Loss: 0.00082830
Iteration 15/25 | Loss: 0.00082404
Iteration 16/25 | Loss: 0.00081268
Iteration 17/25 | Loss: 0.00080783
Iteration 18/25 | Loss: 0.00080819
Iteration 19/25 | Loss: 0.00080888
Iteration 20/25 | Loss: 0.00080618
Iteration 21/25 | Loss: 0.00080618
Iteration 22/25 | Loss: 0.00080618
Iteration 23/25 | Loss: 0.00080618
Iteration 24/25 | Loss: 0.00080618
Iteration 25/25 | Loss: 0.00080618

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50441432
Iteration 2/25 | Loss: 0.00075097
Iteration 3/25 | Loss: 0.00059027
Iteration 4/25 | Loss: 0.00059027
Iteration 5/25 | Loss: 0.00059027
Iteration 6/25 | Loss: 0.00059027
Iteration 7/25 | Loss: 0.00059027
Iteration 8/25 | Loss: 0.00059027
Iteration 9/25 | Loss: 0.00059027
Iteration 10/25 | Loss: 0.00059027
Iteration 11/25 | Loss: 0.00059027
Iteration 12/25 | Loss: 0.00059027
Iteration 13/25 | Loss: 0.00059027
Iteration 14/25 | Loss: 0.00059027
Iteration 15/25 | Loss: 0.00059027
Iteration 16/25 | Loss: 0.00059027
Iteration 17/25 | Loss: 0.00059027
Iteration 18/25 | Loss: 0.00059027
Iteration 19/25 | Loss: 0.00059027
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000590265728533268, 0.000590265728533268, 0.000590265728533268, 0.000590265728533268, 0.000590265728533268]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000590265728533268

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059027
Iteration 2/1000 | Loss: 0.00015728
Iteration 3/1000 | Loss: 0.00005926
Iteration 4/1000 | Loss: 0.00014230
Iteration 5/1000 | Loss: 0.00011609
Iteration 6/1000 | Loss: 0.00008701
Iteration 7/1000 | Loss: 0.00021214
Iteration 8/1000 | Loss: 0.00005623
Iteration 9/1000 | Loss: 0.00004853
Iteration 10/1000 | Loss: 0.00001809
Iteration 11/1000 | Loss: 0.00004055
Iteration 12/1000 | Loss: 0.00002083
Iteration 13/1000 | Loss: 0.00002211
Iteration 14/1000 | Loss: 0.00001728
Iteration 15/1000 | Loss: 0.00009210
Iteration 16/1000 | Loss: 0.00061217
Iteration 17/1000 | Loss: 0.00055874
Iteration 18/1000 | Loss: 0.00016452
Iteration 19/1000 | Loss: 0.00020501
Iteration 20/1000 | Loss: 0.00008858
Iteration 21/1000 | Loss: 0.00005440
Iteration 22/1000 | Loss: 0.00004038
Iteration 23/1000 | Loss: 0.00010143
Iteration 24/1000 | Loss: 0.00088241
Iteration 25/1000 | Loss: 0.00004033
Iteration 26/1000 | Loss: 0.00002047
Iteration 27/1000 | Loss: 0.00001704
Iteration 28/1000 | Loss: 0.00001704
Iteration 29/1000 | Loss: 0.00001875
Iteration 30/1000 | Loss: 0.00001703
Iteration 31/1000 | Loss: 0.00001703
Iteration 32/1000 | Loss: 0.00001703
Iteration 33/1000 | Loss: 0.00001703
Iteration 34/1000 | Loss: 0.00001703
Iteration 35/1000 | Loss: 0.00001703
Iteration 36/1000 | Loss: 0.00001703
Iteration 37/1000 | Loss: 0.00001703
Iteration 38/1000 | Loss: 0.00001702
Iteration 39/1000 | Loss: 0.00001698
Iteration 40/1000 | Loss: 0.00001952
Iteration 41/1000 | Loss: 0.00001696
Iteration 42/1000 | Loss: 0.00001696
Iteration 43/1000 | Loss: 0.00001695
Iteration 44/1000 | Loss: 0.00001692
Iteration 45/1000 | Loss: 0.00001692
Iteration 46/1000 | Loss: 0.00001691
Iteration 47/1000 | Loss: 0.00001690
Iteration 48/1000 | Loss: 0.00001690
Iteration 49/1000 | Loss: 0.00001690
Iteration 50/1000 | Loss: 0.00001690
Iteration 51/1000 | Loss: 0.00001690
Iteration 52/1000 | Loss: 0.00001690
Iteration 53/1000 | Loss: 0.00001689
Iteration 54/1000 | Loss: 0.00001689
Iteration 55/1000 | Loss: 0.00001689
Iteration 56/1000 | Loss: 0.00001689
Iteration 57/1000 | Loss: 0.00001689
Iteration 58/1000 | Loss: 0.00001688
Iteration 59/1000 | Loss: 0.00001688
Iteration 60/1000 | Loss: 0.00001688
Iteration 61/1000 | Loss: 0.00001688
Iteration 62/1000 | Loss: 0.00001688
Iteration 63/1000 | Loss: 0.00001688
Iteration 64/1000 | Loss: 0.00001688
Iteration 65/1000 | Loss: 0.00001688
Iteration 66/1000 | Loss: 0.00001688
Iteration 67/1000 | Loss: 0.00001688
Iteration 68/1000 | Loss: 0.00001687
Iteration 69/1000 | Loss: 0.00001687
Iteration 70/1000 | Loss: 0.00001687
Iteration 71/1000 | Loss: 0.00001687
Iteration 72/1000 | Loss: 0.00001687
Iteration 73/1000 | Loss: 0.00001687
Iteration 74/1000 | Loss: 0.00001687
Iteration 75/1000 | Loss: 0.00001687
Iteration 76/1000 | Loss: 0.00001687
Iteration 77/1000 | Loss: 0.00001686
Iteration 78/1000 | Loss: 0.00001686
Iteration 79/1000 | Loss: 0.00001686
Iteration 80/1000 | Loss: 0.00001686
Iteration 81/1000 | Loss: 0.00001686
Iteration 82/1000 | Loss: 0.00001685
Iteration 83/1000 | Loss: 0.00001685
Iteration 84/1000 | Loss: 0.00001685
Iteration 85/1000 | Loss: 0.00001685
Iteration 86/1000 | Loss: 0.00001685
Iteration 87/1000 | Loss: 0.00001685
Iteration 88/1000 | Loss: 0.00001685
Iteration 89/1000 | Loss: 0.00001685
Iteration 90/1000 | Loss: 0.00001685
Iteration 91/1000 | Loss: 0.00001684
Iteration 92/1000 | Loss: 0.00001684
Iteration 93/1000 | Loss: 0.00001684
Iteration 94/1000 | Loss: 0.00001684
Iteration 95/1000 | Loss: 0.00001684
Iteration 96/1000 | Loss: 0.00001684
Iteration 97/1000 | Loss: 0.00001684
Iteration 98/1000 | Loss: 0.00001683
Iteration 99/1000 | Loss: 0.00001683
Iteration 100/1000 | Loss: 0.00001683
Iteration 101/1000 | Loss: 0.00001683
Iteration 102/1000 | Loss: 0.00001683
Iteration 103/1000 | Loss: 0.00001683
Iteration 104/1000 | Loss: 0.00001683
Iteration 105/1000 | Loss: 0.00001683
Iteration 106/1000 | Loss: 0.00001683
Iteration 107/1000 | Loss: 0.00001683
Iteration 108/1000 | Loss: 0.00001683
Iteration 109/1000 | Loss: 0.00001683
Iteration 110/1000 | Loss: 0.00001683
Iteration 111/1000 | Loss: 0.00001683
Iteration 112/1000 | Loss: 0.00001683
Iteration 113/1000 | Loss: 0.00001683
Iteration 114/1000 | Loss: 0.00001683
Iteration 115/1000 | Loss: 0.00001683
Iteration 116/1000 | Loss: 0.00001683
Iteration 117/1000 | Loss: 0.00001683
Iteration 118/1000 | Loss: 0.00001682
Iteration 119/1000 | Loss: 0.00001682
Iteration 120/1000 | Loss: 0.00001682
Iteration 121/1000 | Loss: 0.00001682
Iteration 122/1000 | Loss: 0.00001682
Iteration 123/1000 | Loss: 0.00001682
Iteration 124/1000 | Loss: 0.00001682
Iteration 125/1000 | Loss: 0.00001682
Iteration 126/1000 | Loss: 0.00001682
Iteration 127/1000 | Loss: 0.00001682
Iteration 128/1000 | Loss: 0.00001682
Iteration 129/1000 | Loss: 0.00001682
Iteration 130/1000 | Loss: 0.00001682
Iteration 131/1000 | Loss: 0.00001682
Iteration 132/1000 | Loss: 0.00001682
Iteration 133/1000 | Loss: 0.00001682
Iteration 134/1000 | Loss: 0.00001682
Iteration 135/1000 | Loss: 0.00001682
Iteration 136/1000 | Loss: 0.00001681
Iteration 137/1000 | Loss: 0.00001681
Iteration 138/1000 | Loss: 0.00001681
Iteration 139/1000 | Loss: 0.00001681
Iteration 140/1000 | Loss: 0.00001681
Iteration 141/1000 | Loss: 0.00001681
Iteration 142/1000 | Loss: 0.00001681
Iteration 143/1000 | Loss: 0.00001681
Iteration 144/1000 | Loss: 0.00001681
Iteration 145/1000 | Loss: 0.00001681
Iteration 146/1000 | Loss: 0.00001681
Iteration 147/1000 | Loss: 0.00001681
Iteration 148/1000 | Loss: 0.00001681
Iteration 149/1000 | Loss: 0.00001681
Iteration 150/1000 | Loss: 0.00001681
Iteration 151/1000 | Loss: 0.00005314
Iteration 152/1000 | Loss: 0.00007065
Iteration 153/1000 | Loss: 0.00007825
Iteration 154/1000 | Loss: 0.00116005
Iteration 155/1000 | Loss: 0.00035227
Iteration 156/1000 | Loss: 0.00028907
Iteration 157/1000 | Loss: 0.00002684
Iteration 158/1000 | Loss: 0.00001815
Iteration 159/1000 | Loss: 0.00004108
Iteration 160/1000 | Loss: 0.00008301
Iteration 161/1000 | Loss: 0.00001988
Iteration 162/1000 | Loss: 0.00002605
Iteration 163/1000 | Loss: 0.00001697
Iteration 164/1000 | Loss: 0.00002506
Iteration 165/1000 | Loss: 0.00002658
Iteration 166/1000 | Loss: 0.00001890
Iteration 167/1000 | Loss: 0.00001718
Iteration 168/1000 | Loss: 0.00001897
Iteration 169/1000 | Loss: 0.00001694
Iteration 170/1000 | Loss: 0.00001694
Iteration 171/1000 | Loss: 0.00001693
Iteration 172/1000 | Loss: 0.00001693
Iteration 173/1000 | Loss: 0.00001693
Iteration 174/1000 | Loss: 0.00001692
Iteration 175/1000 | Loss: 0.00001691
Iteration 176/1000 | Loss: 0.00001691
Iteration 177/1000 | Loss: 0.00001691
Iteration 178/1000 | Loss: 0.00001690
Iteration 179/1000 | Loss: 0.00001690
Iteration 180/1000 | Loss: 0.00001689
Iteration 181/1000 | Loss: 0.00001689
Iteration 182/1000 | Loss: 0.00001689
Iteration 183/1000 | Loss: 0.00001689
Iteration 184/1000 | Loss: 0.00001689
Iteration 185/1000 | Loss: 0.00001688
Iteration 186/1000 | Loss: 0.00001688
Iteration 187/1000 | Loss: 0.00001687
Iteration 188/1000 | Loss: 0.00001687
Iteration 189/1000 | Loss: 0.00001687
Iteration 190/1000 | Loss: 0.00001686
Iteration 191/1000 | Loss: 0.00001686
Iteration 192/1000 | Loss: 0.00001686
Iteration 193/1000 | Loss: 0.00001686
Iteration 194/1000 | Loss: 0.00001686
Iteration 195/1000 | Loss: 0.00001686
Iteration 196/1000 | Loss: 0.00001686
Iteration 197/1000 | Loss: 0.00001686
Iteration 198/1000 | Loss: 0.00001686
Iteration 199/1000 | Loss: 0.00001685
Iteration 200/1000 | Loss: 0.00001685
Iteration 201/1000 | Loss: 0.00001685
Iteration 202/1000 | Loss: 0.00001685
Iteration 203/1000 | Loss: 0.00001685
Iteration 204/1000 | Loss: 0.00001685
Iteration 205/1000 | Loss: 0.00001685
Iteration 206/1000 | Loss: 0.00001684
Iteration 207/1000 | Loss: 0.00001684
Iteration 208/1000 | Loss: 0.00001684
Iteration 209/1000 | Loss: 0.00001684
Iteration 210/1000 | Loss: 0.00001684
Iteration 211/1000 | Loss: 0.00001684
Iteration 212/1000 | Loss: 0.00001683
Iteration 213/1000 | Loss: 0.00001683
Iteration 214/1000 | Loss: 0.00001683
Iteration 215/1000 | Loss: 0.00001683
Iteration 216/1000 | Loss: 0.00001683
Iteration 217/1000 | Loss: 0.00001683
Iteration 218/1000 | Loss: 0.00001683
Iteration 219/1000 | Loss: 0.00001683
Iteration 220/1000 | Loss: 0.00001683
Iteration 221/1000 | Loss: 0.00001683
Iteration 222/1000 | Loss: 0.00001683
Iteration 223/1000 | Loss: 0.00001683
Iteration 224/1000 | Loss: 0.00001683
Iteration 225/1000 | Loss: 0.00001683
Iteration 226/1000 | Loss: 0.00001683
Iteration 227/1000 | Loss: 0.00001683
Iteration 228/1000 | Loss: 0.00001683
Iteration 229/1000 | Loss: 0.00001683
Iteration 230/1000 | Loss: 0.00001683
Iteration 231/1000 | Loss: 0.00001683
Iteration 232/1000 | Loss: 0.00001683
Iteration 233/1000 | Loss: 0.00001683
Iteration 234/1000 | Loss: 0.00001683
Iteration 235/1000 | Loss: 0.00001682
Iteration 236/1000 | Loss: 0.00001682
Iteration 237/1000 | Loss: 0.00001682
Iteration 238/1000 | Loss: 0.00001682
Iteration 239/1000 | Loss: 0.00001682
Iteration 240/1000 | Loss: 0.00001682
Iteration 241/1000 | Loss: 0.00001682
Iteration 242/1000 | Loss: 0.00001682
Iteration 243/1000 | Loss: 0.00001682
Iteration 244/1000 | Loss: 0.00001682
Iteration 245/1000 | Loss: 0.00001682
Iteration 246/1000 | Loss: 0.00001682
Iteration 247/1000 | Loss: 0.00001682
Iteration 248/1000 | Loss: 0.00001682
Iteration 249/1000 | Loss: 0.00001682
Iteration 250/1000 | Loss: 0.00001682
Iteration 251/1000 | Loss: 0.00001682
Iteration 252/1000 | Loss: 0.00001682
Iteration 253/1000 | Loss: 0.00001682
Iteration 254/1000 | Loss: 0.00001682
Iteration 255/1000 | Loss: 0.00001682
Iteration 256/1000 | Loss: 0.00001682
Iteration 257/1000 | Loss: 0.00001682
Iteration 258/1000 | Loss: 0.00001682
Iteration 259/1000 | Loss: 0.00001682
Iteration 260/1000 | Loss: 0.00001682
Iteration 261/1000 | Loss: 0.00001682
Iteration 262/1000 | Loss: 0.00001682
Iteration 263/1000 | Loss: 0.00001682
Iteration 264/1000 | Loss: 0.00001682
Iteration 265/1000 | Loss: 0.00001682
Iteration 266/1000 | Loss: 0.00001682
Iteration 267/1000 | Loss: 0.00001682
Iteration 268/1000 | Loss: 0.00001682
Iteration 269/1000 | Loss: 0.00001682
Iteration 270/1000 | Loss: 0.00001682
Iteration 271/1000 | Loss: 0.00001682
Iteration 272/1000 | Loss: 0.00001682
Iteration 273/1000 | Loss: 0.00001682
Iteration 274/1000 | Loss: 0.00001682
Iteration 275/1000 | Loss: 0.00001682
Iteration 276/1000 | Loss: 0.00001682
Iteration 277/1000 | Loss: 0.00001682
Iteration 278/1000 | Loss: 0.00001682
Iteration 279/1000 | Loss: 0.00001682
Iteration 280/1000 | Loss: 0.00001682
Iteration 281/1000 | Loss: 0.00001682
Iteration 282/1000 | Loss: 0.00001682
Iteration 283/1000 | Loss: 0.00001682
Iteration 284/1000 | Loss: 0.00001682
Iteration 285/1000 | Loss: 0.00001682
Iteration 286/1000 | Loss: 0.00001682
Iteration 287/1000 | Loss: 0.00001682
Iteration 288/1000 | Loss: 0.00001682
Iteration 289/1000 | Loss: 0.00001682
Iteration 290/1000 | Loss: 0.00001682
Iteration 291/1000 | Loss: 0.00001682
Iteration 292/1000 | Loss: 0.00001682
Iteration 293/1000 | Loss: 0.00001682
Iteration 294/1000 | Loss: 0.00001682
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 294. Stopping optimization.
Last 5 losses: [1.681650974205695e-05, 1.681650974205695e-05, 1.681650974205695e-05, 1.681650974205695e-05, 1.681650974205695e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.681650974205695e-05

Optimization complete. Final v2v error: 3.256614923477173 mm

Highest mean error: 11.420778274536133 mm for frame 44

Lowest mean error: 2.6374988555908203 mm for frame 7

Saving results

Total time: 109.25003242492676
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01118505
Iteration 2/25 | Loss: 0.00271885
Iteration 3/25 | Loss: 0.00209122
Iteration 4/25 | Loss: 0.00167956
Iteration 5/25 | Loss: 0.00135294
Iteration 6/25 | Loss: 0.00133278
Iteration 7/25 | Loss: 0.00130485
Iteration 8/25 | Loss: 0.00124085
Iteration 9/25 | Loss: 0.00113815
Iteration 10/25 | Loss: 0.00108355
Iteration 11/25 | Loss: 0.00102151
Iteration 12/25 | Loss: 0.00098507
Iteration 13/25 | Loss: 0.00094293
Iteration 14/25 | Loss: 0.00091949
Iteration 15/25 | Loss: 0.00090587
Iteration 16/25 | Loss: 0.00089707
Iteration 17/25 | Loss: 0.00089096
Iteration 18/25 | Loss: 0.00089157
Iteration 19/25 | Loss: 0.00089333
Iteration 20/25 | Loss: 0.00088702
Iteration 21/25 | Loss: 0.00088717
Iteration 22/25 | Loss: 0.00088586
Iteration 23/25 | Loss: 0.00089052
Iteration 24/25 | Loss: 0.00090361
Iteration 25/25 | Loss: 0.00090044

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64009607
Iteration 2/25 | Loss: 0.00118123
Iteration 3/25 | Loss: 0.00092160
Iteration 4/25 | Loss: 0.00092160
Iteration 5/25 | Loss: 0.00092160
Iteration 6/25 | Loss: 0.00092160
Iteration 7/25 | Loss: 0.00092159
Iteration 8/25 | Loss: 0.00092159
Iteration 9/25 | Loss: 0.00092159
Iteration 10/25 | Loss: 0.00092159
Iteration 11/25 | Loss: 0.00092159
Iteration 12/25 | Loss: 0.00092159
Iteration 13/25 | Loss: 0.00092159
Iteration 14/25 | Loss: 0.00092159
Iteration 15/25 | Loss: 0.00092159
Iteration 16/25 | Loss: 0.00092159
Iteration 17/25 | Loss: 0.00092159
Iteration 18/25 | Loss: 0.00092159
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009215938043780625, 0.0009215938043780625, 0.0009215938043780625, 0.0009215938043780625, 0.0009215938043780625]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009215938043780625

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00092159
Iteration 2/1000 | Loss: 0.00021690
Iteration 3/1000 | Loss: 0.00044252
Iteration 4/1000 | Loss: 0.00019176
Iteration 5/1000 | Loss: 0.00012302
Iteration 6/1000 | Loss: 0.00014702
Iteration 7/1000 | Loss: 0.00048186
Iteration 8/1000 | Loss: 0.00028454
Iteration 9/1000 | Loss: 0.00014501
Iteration 10/1000 | Loss: 0.00032923
Iteration 11/1000 | Loss: 0.00035895
Iteration 12/1000 | Loss: 0.00020187
Iteration 13/1000 | Loss: 0.00036835
Iteration 14/1000 | Loss: 0.00018804
Iteration 15/1000 | Loss: 0.00014240
Iteration 16/1000 | Loss: 0.00022583
Iteration 17/1000 | Loss: 0.00006464
Iteration 18/1000 | Loss: 0.00005534
Iteration 19/1000 | Loss: 0.00008273
Iteration 20/1000 | Loss: 0.00006664
Iteration 21/1000 | Loss: 0.00043846
Iteration 22/1000 | Loss: 0.00005820
Iteration 23/1000 | Loss: 0.00025100
Iteration 24/1000 | Loss: 0.00009226
Iteration 25/1000 | Loss: 0.00022991
Iteration 26/1000 | Loss: 0.00023134
Iteration 27/1000 | Loss: 0.00006782
Iteration 28/1000 | Loss: 0.00049820
Iteration 29/1000 | Loss: 0.00057522
Iteration 30/1000 | Loss: 0.00012838
Iteration 31/1000 | Loss: 0.00015588
Iteration 32/1000 | Loss: 0.00011815
Iteration 33/1000 | Loss: 0.00048251
Iteration 34/1000 | Loss: 0.00034474
Iteration 35/1000 | Loss: 0.00026985
Iteration 36/1000 | Loss: 0.00021735
Iteration 37/1000 | Loss: 0.00018895
Iteration 38/1000 | Loss: 0.00057106
Iteration 39/1000 | Loss: 0.00042517
Iteration 40/1000 | Loss: 0.00024310
Iteration 41/1000 | Loss: 0.00017931
Iteration 42/1000 | Loss: 0.00019594
Iteration 43/1000 | Loss: 0.00017240
Iteration 44/1000 | Loss: 0.00013854
Iteration 45/1000 | Loss: 0.00007797
Iteration 46/1000 | Loss: 0.00033420
Iteration 47/1000 | Loss: 0.00021092
Iteration 48/1000 | Loss: 0.00006200
Iteration 49/1000 | Loss: 0.00004865
Iteration 50/1000 | Loss: 0.00020505
Iteration 51/1000 | Loss: 0.00066287
Iteration 52/1000 | Loss: 0.00040556
Iteration 53/1000 | Loss: 0.00046644
Iteration 54/1000 | Loss: 0.00011762
Iteration 55/1000 | Loss: 0.00006103
Iteration 56/1000 | Loss: 0.00018525
Iteration 57/1000 | Loss: 0.00014023
Iteration 58/1000 | Loss: 0.00009154
Iteration 59/1000 | Loss: 0.00006182
Iteration 60/1000 | Loss: 0.00007533
Iteration 61/1000 | Loss: 0.00023154
Iteration 62/1000 | Loss: 0.00026425
Iteration 63/1000 | Loss: 0.00030090
Iteration 64/1000 | Loss: 0.00011956
Iteration 65/1000 | Loss: 0.00008018
Iteration 66/1000 | Loss: 0.00039430
Iteration 67/1000 | Loss: 0.00005062
Iteration 68/1000 | Loss: 0.00005365
Iteration 69/1000 | Loss: 0.00024959
Iteration 70/1000 | Loss: 0.00017675
Iteration 71/1000 | Loss: 0.00007007
Iteration 72/1000 | Loss: 0.00007438
Iteration 73/1000 | Loss: 0.00011419
Iteration 74/1000 | Loss: 0.00006301
Iteration 75/1000 | Loss: 0.00028094
Iteration 76/1000 | Loss: 0.00034459
Iteration 77/1000 | Loss: 0.00041912
Iteration 78/1000 | Loss: 0.00015951
Iteration 79/1000 | Loss: 0.00005873
Iteration 80/1000 | Loss: 0.00004442
Iteration 81/1000 | Loss: 0.00006116
Iteration 82/1000 | Loss: 0.00024957
Iteration 83/1000 | Loss: 0.00029910
Iteration 84/1000 | Loss: 0.00005646
Iteration 85/1000 | Loss: 0.00005609
Iteration 86/1000 | Loss: 0.00020905
Iteration 87/1000 | Loss: 0.00005402
Iteration 88/1000 | Loss: 0.00005650
Iteration 89/1000 | Loss: 0.00005330
Iteration 90/1000 | Loss: 0.00006520
Iteration 91/1000 | Loss: 0.00006159
Iteration 92/1000 | Loss: 0.00006244
Iteration 93/1000 | Loss: 0.00003650
Iteration 94/1000 | Loss: 0.00004026
Iteration 95/1000 | Loss: 0.00005727
Iteration 96/1000 | Loss: 0.00004363
Iteration 97/1000 | Loss: 0.00008130
Iteration 98/1000 | Loss: 0.00045112
Iteration 99/1000 | Loss: 0.00027557
Iteration 100/1000 | Loss: 0.00021405
Iteration 101/1000 | Loss: 0.00017005
Iteration 102/1000 | Loss: 0.00004886
Iteration 103/1000 | Loss: 0.00022256
Iteration 104/1000 | Loss: 0.00009392
Iteration 105/1000 | Loss: 0.00024086
Iteration 106/1000 | Loss: 0.00062245
Iteration 107/1000 | Loss: 0.00043189
Iteration 108/1000 | Loss: 0.00024079
Iteration 109/1000 | Loss: 0.00006022
Iteration 110/1000 | Loss: 0.00005565
Iteration 111/1000 | Loss: 0.00016049
Iteration 112/1000 | Loss: 0.00012481
Iteration 113/1000 | Loss: 0.00015511
Iteration 114/1000 | Loss: 0.00012953
Iteration 115/1000 | Loss: 0.00005820
Iteration 116/1000 | Loss: 0.00005182
Iteration 117/1000 | Loss: 0.00003851
Iteration 118/1000 | Loss: 0.00009533
Iteration 119/1000 | Loss: 0.00012128
Iteration 120/1000 | Loss: 0.00003541
Iteration 121/1000 | Loss: 0.00003510
Iteration 122/1000 | Loss: 0.00002898
Iteration 123/1000 | Loss: 0.00006312
Iteration 124/1000 | Loss: 0.00004815
Iteration 125/1000 | Loss: 0.00003549
Iteration 126/1000 | Loss: 0.00004305
Iteration 127/1000 | Loss: 0.00004868
Iteration 128/1000 | Loss: 0.00004498
Iteration 129/1000 | Loss: 0.00004434
Iteration 130/1000 | Loss: 0.00003820
Iteration 131/1000 | Loss: 0.00002818
Iteration 132/1000 | Loss: 0.00004283
Iteration 133/1000 | Loss: 0.00003005
Iteration 134/1000 | Loss: 0.00003359
Iteration 135/1000 | Loss: 0.00003516
Iteration 136/1000 | Loss: 0.00002826
Iteration 137/1000 | Loss: 0.00003691
Iteration 138/1000 | Loss: 0.00002812
Iteration 139/1000 | Loss: 0.00004015
Iteration 140/1000 | Loss: 0.00003164
Iteration 141/1000 | Loss: 0.00003402
Iteration 142/1000 | Loss: 0.00002895
Iteration 143/1000 | Loss: 0.00003952
Iteration 144/1000 | Loss: 0.00003132
Iteration 145/1000 | Loss: 0.00002735
Iteration 146/1000 | Loss: 0.00002897
Iteration 147/1000 | Loss: 0.00003489
Iteration 148/1000 | Loss: 0.00003274
Iteration 149/1000 | Loss: 0.00003381
Iteration 150/1000 | Loss: 0.00003256
Iteration 151/1000 | Loss: 0.00003247
Iteration 152/1000 | Loss: 0.00003164
Iteration 153/1000 | Loss: 0.00003040
Iteration 154/1000 | Loss: 0.00003177
Iteration 155/1000 | Loss: 0.00003142
Iteration 156/1000 | Loss: 0.00003096
Iteration 157/1000 | Loss: 0.00003811
Iteration 158/1000 | Loss: 0.00003076
Iteration 159/1000 | Loss: 0.00003610
Iteration 160/1000 | Loss: 0.00003055
Iteration 161/1000 | Loss: 0.00003868
Iteration 162/1000 | Loss: 0.00003193
Iteration 163/1000 | Loss: 0.00003295
Iteration 164/1000 | Loss: 0.00002778
Iteration 165/1000 | Loss: 0.00002872
Iteration 166/1000 | Loss: 0.00002980
Iteration 167/1000 | Loss: 0.00002901
Iteration 168/1000 | Loss: 0.00003013
Iteration 169/1000 | Loss: 0.00003350
Iteration 170/1000 | Loss: 0.00002988
Iteration 171/1000 | Loss: 0.00002713
Iteration 172/1000 | Loss: 0.00002510
Iteration 173/1000 | Loss: 0.00002377
Iteration 174/1000 | Loss: 0.00002303
Iteration 175/1000 | Loss: 0.00002260
Iteration 176/1000 | Loss: 0.00002251
Iteration 177/1000 | Loss: 0.00002222
Iteration 178/1000 | Loss: 0.00002201
Iteration 179/1000 | Loss: 0.00002197
Iteration 180/1000 | Loss: 0.00002194
Iteration 181/1000 | Loss: 0.00002192
Iteration 182/1000 | Loss: 0.00002192
Iteration 183/1000 | Loss: 0.00002192
Iteration 184/1000 | Loss: 0.00002192
Iteration 185/1000 | Loss: 0.00002192
Iteration 186/1000 | Loss: 0.00002192
Iteration 187/1000 | Loss: 0.00002191
Iteration 188/1000 | Loss: 0.00002191
Iteration 189/1000 | Loss: 0.00002191
Iteration 190/1000 | Loss: 0.00002191
Iteration 191/1000 | Loss: 0.00002191
Iteration 192/1000 | Loss: 0.00002191
Iteration 193/1000 | Loss: 0.00002191
Iteration 194/1000 | Loss: 0.00002191
Iteration 195/1000 | Loss: 0.00002191
Iteration 196/1000 | Loss: 0.00002191
Iteration 197/1000 | Loss: 0.00002190
Iteration 198/1000 | Loss: 0.00002190
Iteration 199/1000 | Loss: 0.00002187
Iteration 200/1000 | Loss: 0.00002187
Iteration 201/1000 | Loss: 0.00002187
Iteration 202/1000 | Loss: 0.00002186
Iteration 203/1000 | Loss: 0.00002186
Iteration 204/1000 | Loss: 0.00002185
Iteration 205/1000 | Loss: 0.00002185
Iteration 206/1000 | Loss: 0.00002185
Iteration 207/1000 | Loss: 0.00002185
Iteration 208/1000 | Loss: 0.00002185
Iteration 209/1000 | Loss: 0.00002185
Iteration 210/1000 | Loss: 0.00002185
Iteration 211/1000 | Loss: 0.00002184
Iteration 212/1000 | Loss: 0.00002184
Iteration 213/1000 | Loss: 0.00002184
Iteration 214/1000 | Loss: 0.00002184
Iteration 215/1000 | Loss: 0.00002184
Iteration 216/1000 | Loss: 0.00002183
Iteration 217/1000 | Loss: 0.00002183
Iteration 218/1000 | Loss: 0.00002183
Iteration 219/1000 | Loss: 0.00002183
Iteration 220/1000 | Loss: 0.00002183
Iteration 221/1000 | Loss: 0.00002182
Iteration 222/1000 | Loss: 0.00002182
Iteration 223/1000 | Loss: 0.00002182
Iteration 224/1000 | Loss: 0.00002182
Iteration 225/1000 | Loss: 0.00002182
Iteration 226/1000 | Loss: 0.00002181
Iteration 227/1000 | Loss: 0.00002181
Iteration 228/1000 | Loss: 0.00002181
Iteration 229/1000 | Loss: 0.00002181
Iteration 230/1000 | Loss: 0.00002181
Iteration 231/1000 | Loss: 0.00002181
Iteration 232/1000 | Loss: 0.00002180
Iteration 233/1000 | Loss: 0.00002180
Iteration 234/1000 | Loss: 0.00002180
Iteration 235/1000 | Loss: 0.00002180
Iteration 236/1000 | Loss: 0.00002179
Iteration 237/1000 | Loss: 0.00002179
Iteration 238/1000 | Loss: 0.00002179
Iteration 239/1000 | Loss: 0.00002179
Iteration 240/1000 | Loss: 0.00002178
Iteration 241/1000 | Loss: 0.00002178
Iteration 242/1000 | Loss: 0.00002178
Iteration 243/1000 | Loss: 0.00002178
Iteration 244/1000 | Loss: 0.00002178
Iteration 245/1000 | Loss: 0.00002178
Iteration 246/1000 | Loss: 0.00002178
Iteration 247/1000 | Loss: 0.00002178
Iteration 248/1000 | Loss: 0.00002178
Iteration 249/1000 | Loss: 0.00002178
Iteration 250/1000 | Loss: 0.00002178
Iteration 251/1000 | Loss: 0.00002178
Iteration 252/1000 | Loss: 0.00002177
Iteration 253/1000 | Loss: 0.00002177
Iteration 254/1000 | Loss: 0.00002177
Iteration 255/1000 | Loss: 0.00002177
Iteration 256/1000 | Loss: 0.00002177
Iteration 257/1000 | Loss: 0.00002177
Iteration 258/1000 | Loss: 0.00002177
Iteration 259/1000 | Loss: 0.00002177
Iteration 260/1000 | Loss: 0.00002177
Iteration 261/1000 | Loss: 0.00002177
Iteration 262/1000 | Loss: 0.00002177
Iteration 263/1000 | Loss: 0.00002177
Iteration 264/1000 | Loss: 0.00002177
Iteration 265/1000 | Loss: 0.00002177
Iteration 266/1000 | Loss: 0.00002177
Iteration 267/1000 | Loss: 0.00002177
Iteration 268/1000 | Loss: 0.00002176
Iteration 269/1000 | Loss: 0.00002176
Iteration 270/1000 | Loss: 0.00002176
Iteration 271/1000 | Loss: 0.00002176
Iteration 272/1000 | Loss: 0.00002176
Iteration 273/1000 | Loss: 0.00002176
Iteration 274/1000 | Loss: 0.00002176
Iteration 275/1000 | Loss: 0.00002176
Iteration 276/1000 | Loss: 0.00002176
Iteration 277/1000 | Loss: 0.00002176
Iteration 278/1000 | Loss: 0.00002176
Iteration 279/1000 | Loss: 0.00002176
Iteration 280/1000 | Loss: 0.00002176
Iteration 281/1000 | Loss: 0.00002176
Iteration 282/1000 | Loss: 0.00002175
Iteration 283/1000 | Loss: 0.00002175
Iteration 284/1000 | Loss: 0.00002175
Iteration 285/1000 | Loss: 0.00002175
Iteration 286/1000 | Loss: 0.00002175
Iteration 287/1000 | Loss: 0.00002175
Iteration 288/1000 | Loss: 0.00002175
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 288. Stopping optimization.
Last 5 losses: [2.175459849240724e-05, 2.175459849240724e-05, 2.175459849240724e-05, 2.175459849240724e-05, 2.175459849240724e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.175459849240724e-05

Optimization complete. Final v2v error: 3.752567768096924 mm

Highest mean error: 10.103431701660156 mm for frame 103

Lowest mean error: 3.2482316493988037 mm for frame 181

Saving results

Total time: 340.70768642425537
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00906760
Iteration 2/25 | Loss: 0.00112830
Iteration 3/25 | Loss: 0.00097497
Iteration 4/25 | Loss: 0.00094249
Iteration 5/25 | Loss: 0.00093125
Iteration 6/25 | Loss: 0.00092922
Iteration 7/25 | Loss: 0.00092877
Iteration 8/25 | Loss: 0.00092877
Iteration 9/25 | Loss: 0.00092877
Iteration 10/25 | Loss: 0.00092877
Iteration 11/25 | Loss: 0.00092877
Iteration 12/25 | Loss: 0.00092877
Iteration 13/25 | Loss: 0.00092877
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0009287658613175154, 0.0009287658613175154, 0.0009287658613175154, 0.0009287658613175154, 0.0009287658613175154]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009287658613175154

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.30000210
Iteration 2/25 | Loss: 0.00062798
Iteration 3/25 | Loss: 0.00062798
Iteration 4/25 | Loss: 0.00062797
Iteration 5/25 | Loss: 0.00062797
Iteration 6/25 | Loss: 0.00062797
Iteration 7/25 | Loss: 0.00062797
Iteration 8/25 | Loss: 0.00062797
Iteration 9/25 | Loss: 0.00062797
Iteration 10/25 | Loss: 0.00062797
Iteration 11/25 | Loss: 0.00062797
Iteration 12/25 | Loss: 0.00062797
Iteration 13/25 | Loss: 0.00062797
Iteration 14/25 | Loss: 0.00062797
Iteration 15/25 | Loss: 0.00062797
Iteration 16/25 | Loss: 0.00062797
Iteration 17/25 | Loss: 0.00062797
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006279729423113167, 0.0006279729423113167, 0.0006279729423113167, 0.0006279729423113167, 0.0006279729423113167]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006279729423113167

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062797
Iteration 2/1000 | Loss: 0.00003533
Iteration 3/1000 | Loss: 0.00002346
Iteration 4/1000 | Loss: 0.00002066
Iteration 5/1000 | Loss: 0.00001951
Iteration 6/1000 | Loss: 0.00001900
Iteration 7/1000 | Loss: 0.00001864
Iteration 8/1000 | Loss: 0.00001835
Iteration 9/1000 | Loss: 0.00001821
Iteration 10/1000 | Loss: 0.00001815
Iteration 11/1000 | Loss: 0.00001815
Iteration 12/1000 | Loss: 0.00001812
Iteration 13/1000 | Loss: 0.00001811
Iteration 14/1000 | Loss: 0.00001811
Iteration 15/1000 | Loss: 0.00001811
Iteration 16/1000 | Loss: 0.00001811
Iteration 17/1000 | Loss: 0.00001810
Iteration 18/1000 | Loss: 0.00001810
Iteration 19/1000 | Loss: 0.00001809
Iteration 20/1000 | Loss: 0.00001809
Iteration 21/1000 | Loss: 0.00001806
Iteration 22/1000 | Loss: 0.00001803
Iteration 23/1000 | Loss: 0.00001802
Iteration 24/1000 | Loss: 0.00001801
Iteration 25/1000 | Loss: 0.00001801
Iteration 26/1000 | Loss: 0.00001801
Iteration 27/1000 | Loss: 0.00001800
Iteration 28/1000 | Loss: 0.00001800
Iteration 29/1000 | Loss: 0.00001799
Iteration 30/1000 | Loss: 0.00001799
Iteration 31/1000 | Loss: 0.00001798
Iteration 32/1000 | Loss: 0.00001798
Iteration 33/1000 | Loss: 0.00001798
Iteration 34/1000 | Loss: 0.00001798
Iteration 35/1000 | Loss: 0.00001797
Iteration 36/1000 | Loss: 0.00001797
Iteration 37/1000 | Loss: 0.00001797
Iteration 38/1000 | Loss: 0.00001797
Iteration 39/1000 | Loss: 0.00001796
Iteration 40/1000 | Loss: 0.00001796
Iteration 41/1000 | Loss: 0.00001796
Iteration 42/1000 | Loss: 0.00001796
Iteration 43/1000 | Loss: 0.00001796
Iteration 44/1000 | Loss: 0.00001796
Iteration 45/1000 | Loss: 0.00001796
Iteration 46/1000 | Loss: 0.00001796
Iteration 47/1000 | Loss: 0.00001796
Iteration 48/1000 | Loss: 0.00001796
Iteration 49/1000 | Loss: 0.00001796
Iteration 50/1000 | Loss: 0.00001796
Iteration 51/1000 | Loss: 0.00001796
Iteration 52/1000 | Loss: 0.00001796
Iteration 53/1000 | Loss: 0.00001796
Iteration 54/1000 | Loss: 0.00001796
Iteration 55/1000 | Loss: 0.00001796
Iteration 56/1000 | Loss: 0.00001796
Iteration 57/1000 | Loss: 0.00001796
Iteration 58/1000 | Loss: 0.00001796
Iteration 59/1000 | Loss: 0.00001796
Iteration 60/1000 | Loss: 0.00001796
Iteration 61/1000 | Loss: 0.00001796
Iteration 62/1000 | Loss: 0.00001796
Iteration 63/1000 | Loss: 0.00001796
Iteration 64/1000 | Loss: 0.00001796
Iteration 65/1000 | Loss: 0.00001796
Iteration 66/1000 | Loss: 0.00001796
Iteration 67/1000 | Loss: 0.00001796
Iteration 68/1000 | Loss: 0.00001796
Iteration 69/1000 | Loss: 0.00001796
Iteration 70/1000 | Loss: 0.00001796
Iteration 71/1000 | Loss: 0.00001796
Iteration 72/1000 | Loss: 0.00001796
Iteration 73/1000 | Loss: 0.00001796
Iteration 74/1000 | Loss: 0.00001796
Iteration 75/1000 | Loss: 0.00001796
Iteration 76/1000 | Loss: 0.00001796
Iteration 77/1000 | Loss: 0.00001796
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [1.795512616808992e-05, 1.795512616808992e-05, 1.795512616808992e-05, 1.795512616808992e-05, 1.795512616808992e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.795512616808992e-05

Optimization complete. Final v2v error: 3.6364235877990723 mm

Highest mean error: 4.46198034286499 mm for frame 45

Lowest mean error: 3.344794273376465 mm for frame 117

Saving results

Total time: 27.52570915222168
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_35_us_1286/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_35_us_1286/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00375300
Iteration 2/25 | Loss: 0.00112692
Iteration 3/25 | Loss: 0.00100792
Iteration 4/25 | Loss: 0.00097057
Iteration 5/25 | Loss: 0.00095765
Iteration 6/25 | Loss: 0.00095444
Iteration 7/25 | Loss: 0.00095280
Iteration 8/25 | Loss: 0.00095238
Iteration 9/25 | Loss: 0.00095238
Iteration 10/25 | Loss: 0.00095238
Iteration 11/25 | Loss: 0.00095238
Iteration 12/25 | Loss: 0.00095238
Iteration 13/25 | Loss: 0.00095238
Iteration 14/25 | Loss: 0.00095238
Iteration 15/25 | Loss: 0.00095238
Iteration 16/25 | Loss: 0.00095238
Iteration 17/25 | Loss: 0.00095238
Iteration 18/25 | Loss: 0.00095238
Iteration 19/25 | Loss: 0.00095238
Iteration 20/25 | Loss: 0.00095238
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0009523808839730918, 0.0009523808839730918, 0.0009523808839730918, 0.0009523808839730918, 0.0009523808839730918]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009523808839730918

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51229799
Iteration 2/25 | Loss: 0.00082706
Iteration 3/25 | Loss: 0.00082706
Iteration 4/25 | Loss: 0.00082706
Iteration 5/25 | Loss: 0.00082706
Iteration 6/25 | Loss: 0.00082706
Iteration 7/25 | Loss: 0.00082706
Iteration 8/25 | Loss: 0.00082706
Iteration 9/25 | Loss: 0.00082706
Iteration 10/25 | Loss: 0.00082706
Iteration 11/25 | Loss: 0.00082706
Iteration 12/25 | Loss: 0.00082706
Iteration 13/25 | Loss: 0.00082706
Iteration 14/25 | Loss: 0.00082706
Iteration 15/25 | Loss: 0.00082706
Iteration 16/25 | Loss: 0.00082706
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008270593243651092, 0.0008270593243651092, 0.0008270593243651092, 0.0008270593243651092, 0.0008270593243651092]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008270593243651092

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00082706
Iteration 2/1000 | Loss: 0.00005376
Iteration 3/1000 | Loss: 0.00003234
Iteration 4/1000 | Loss: 0.00002553
Iteration 5/1000 | Loss: 0.00002224
Iteration 6/1000 | Loss: 0.00002085
Iteration 7/1000 | Loss: 0.00001972
Iteration 8/1000 | Loss: 0.00001902
Iteration 9/1000 | Loss: 0.00001849
Iteration 10/1000 | Loss: 0.00001806
Iteration 11/1000 | Loss: 0.00001770
Iteration 12/1000 | Loss: 0.00001744
Iteration 13/1000 | Loss: 0.00001722
Iteration 14/1000 | Loss: 0.00001720
Iteration 15/1000 | Loss: 0.00001709
Iteration 16/1000 | Loss: 0.00001702
Iteration 17/1000 | Loss: 0.00001696
Iteration 18/1000 | Loss: 0.00001695
Iteration 19/1000 | Loss: 0.00001693
Iteration 20/1000 | Loss: 0.00001692
Iteration 21/1000 | Loss: 0.00001689
Iteration 22/1000 | Loss: 0.00001682
Iteration 23/1000 | Loss: 0.00001676
Iteration 24/1000 | Loss: 0.00001674
Iteration 25/1000 | Loss: 0.00001674
Iteration 26/1000 | Loss: 0.00001673
Iteration 27/1000 | Loss: 0.00001672
Iteration 28/1000 | Loss: 0.00001671
Iteration 29/1000 | Loss: 0.00001668
Iteration 30/1000 | Loss: 0.00001667
Iteration 31/1000 | Loss: 0.00001667
Iteration 32/1000 | Loss: 0.00001666
Iteration 33/1000 | Loss: 0.00001666
Iteration 34/1000 | Loss: 0.00001665
Iteration 35/1000 | Loss: 0.00001665
Iteration 36/1000 | Loss: 0.00001665
Iteration 37/1000 | Loss: 0.00001664
Iteration 38/1000 | Loss: 0.00001664
Iteration 39/1000 | Loss: 0.00001662
Iteration 40/1000 | Loss: 0.00001662
Iteration 41/1000 | Loss: 0.00001662
Iteration 42/1000 | Loss: 0.00001662
Iteration 43/1000 | Loss: 0.00001662
Iteration 44/1000 | Loss: 0.00001661
Iteration 45/1000 | Loss: 0.00001661
Iteration 46/1000 | Loss: 0.00001661
Iteration 47/1000 | Loss: 0.00001660
Iteration 48/1000 | Loss: 0.00001659
Iteration 49/1000 | Loss: 0.00001659
Iteration 50/1000 | Loss: 0.00001659
Iteration 51/1000 | Loss: 0.00001659
Iteration 52/1000 | Loss: 0.00001659
Iteration 53/1000 | Loss: 0.00001659
Iteration 54/1000 | Loss: 0.00001659
Iteration 55/1000 | Loss: 0.00001659
Iteration 56/1000 | Loss: 0.00001659
Iteration 57/1000 | Loss: 0.00001659
Iteration 58/1000 | Loss: 0.00001659
Iteration 59/1000 | Loss: 0.00001659
Iteration 60/1000 | Loss: 0.00001658
Iteration 61/1000 | Loss: 0.00001658
Iteration 62/1000 | Loss: 0.00001658
Iteration 63/1000 | Loss: 0.00001657
Iteration 64/1000 | Loss: 0.00001657
Iteration 65/1000 | Loss: 0.00001656
Iteration 66/1000 | Loss: 0.00001656
Iteration 67/1000 | Loss: 0.00001656
Iteration 68/1000 | Loss: 0.00001655
Iteration 69/1000 | Loss: 0.00001655
Iteration 70/1000 | Loss: 0.00001655
Iteration 71/1000 | Loss: 0.00001654
Iteration 72/1000 | Loss: 0.00001654
Iteration 73/1000 | Loss: 0.00001654
Iteration 74/1000 | Loss: 0.00001653
Iteration 75/1000 | Loss: 0.00001653
Iteration 76/1000 | Loss: 0.00001653
Iteration 77/1000 | Loss: 0.00001652
Iteration 78/1000 | Loss: 0.00001652
Iteration 79/1000 | Loss: 0.00001652
Iteration 80/1000 | Loss: 0.00001652
Iteration 81/1000 | Loss: 0.00001651
Iteration 82/1000 | Loss: 0.00001651
Iteration 83/1000 | Loss: 0.00001651
Iteration 84/1000 | Loss: 0.00001651
Iteration 85/1000 | Loss: 0.00001651
Iteration 86/1000 | Loss: 0.00001651
Iteration 87/1000 | Loss: 0.00001651
Iteration 88/1000 | Loss: 0.00001651
Iteration 89/1000 | Loss: 0.00001651
Iteration 90/1000 | Loss: 0.00001650
Iteration 91/1000 | Loss: 0.00001650
Iteration 92/1000 | Loss: 0.00001650
Iteration 93/1000 | Loss: 0.00001650
Iteration 94/1000 | Loss: 0.00001650
Iteration 95/1000 | Loss: 0.00001649
Iteration 96/1000 | Loss: 0.00001649
Iteration 97/1000 | Loss: 0.00001649
Iteration 98/1000 | Loss: 0.00001649
Iteration 99/1000 | Loss: 0.00001648
Iteration 100/1000 | Loss: 0.00001648
Iteration 101/1000 | Loss: 0.00001648
Iteration 102/1000 | Loss: 0.00001648
Iteration 103/1000 | Loss: 0.00001648
Iteration 104/1000 | Loss: 0.00001648
Iteration 105/1000 | Loss: 0.00001648
Iteration 106/1000 | Loss: 0.00001647
Iteration 107/1000 | Loss: 0.00001647
Iteration 108/1000 | Loss: 0.00001647
Iteration 109/1000 | Loss: 0.00001647
Iteration 110/1000 | Loss: 0.00001647
Iteration 111/1000 | Loss: 0.00001647
Iteration 112/1000 | Loss: 0.00001647
Iteration 113/1000 | Loss: 0.00001647
Iteration 114/1000 | Loss: 0.00001647
Iteration 115/1000 | Loss: 0.00001646
Iteration 116/1000 | Loss: 0.00001646
Iteration 117/1000 | Loss: 0.00001646
Iteration 118/1000 | Loss: 0.00001646
Iteration 119/1000 | Loss: 0.00001646
Iteration 120/1000 | Loss: 0.00001646
Iteration 121/1000 | Loss: 0.00001646
Iteration 122/1000 | Loss: 0.00001646
Iteration 123/1000 | Loss: 0.00001646
Iteration 124/1000 | Loss: 0.00001646
Iteration 125/1000 | Loss: 0.00001646
Iteration 126/1000 | Loss: 0.00001646
Iteration 127/1000 | Loss: 0.00001646
Iteration 128/1000 | Loss: 0.00001646
Iteration 129/1000 | Loss: 0.00001646
Iteration 130/1000 | Loss: 0.00001646
Iteration 131/1000 | Loss: 0.00001646
Iteration 132/1000 | Loss: 0.00001645
Iteration 133/1000 | Loss: 0.00001645
Iteration 134/1000 | Loss: 0.00001645
Iteration 135/1000 | Loss: 0.00001645
Iteration 136/1000 | Loss: 0.00001645
Iteration 137/1000 | Loss: 0.00001645
Iteration 138/1000 | Loss: 0.00001645
Iteration 139/1000 | Loss: 0.00001645
Iteration 140/1000 | Loss: 0.00001645
Iteration 141/1000 | Loss: 0.00001645
Iteration 142/1000 | Loss: 0.00001645
Iteration 143/1000 | Loss: 0.00001645
Iteration 144/1000 | Loss: 0.00001645
Iteration 145/1000 | Loss: 0.00001645
Iteration 146/1000 | Loss: 0.00001644
Iteration 147/1000 | Loss: 0.00001644
Iteration 148/1000 | Loss: 0.00001644
Iteration 149/1000 | Loss: 0.00001644
Iteration 150/1000 | Loss: 0.00001644
Iteration 151/1000 | Loss: 0.00001644
Iteration 152/1000 | Loss: 0.00001644
Iteration 153/1000 | Loss: 0.00001644
Iteration 154/1000 | Loss: 0.00001644
Iteration 155/1000 | Loss: 0.00001644
Iteration 156/1000 | Loss: 0.00001644
Iteration 157/1000 | Loss: 0.00001644
Iteration 158/1000 | Loss: 0.00001644
Iteration 159/1000 | Loss: 0.00001644
Iteration 160/1000 | Loss: 0.00001644
Iteration 161/1000 | Loss: 0.00001644
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 161. Stopping optimization.
Last 5 losses: [1.644082658458501e-05, 1.644082658458501e-05, 1.644082658458501e-05, 1.644082658458501e-05, 1.644082658458501e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.644082658458501e-05

Optimization complete. Final v2v error: 3.5085034370422363 mm

Highest mean error: 3.934128761291504 mm for frame 73

Lowest mean error: 2.9956891536712646 mm for frame 181

Saving results

Total time: 49.052958965301514
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01170003
Iteration 2/25 | Loss: 0.00310306
Iteration 3/25 | Loss: 0.00209938
Iteration 4/25 | Loss: 0.00191830
Iteration 5/25 | Loss: 0.00182472
Iteration 6/25 | Loss: 0.00180525
Iteration 7/25 | Loss: 0.00176476
Iteration 8/25 | Loss: 0.00173170
Iteration 9/25 | Loss: 0.00174773
Iteration 10/25 | Loss: 0.00176555
Iteration 11/25 | Loss: 0.00163410
Iteration 12/25 | Loss: 0.00155564
Iteration 13/25 | Loss: 0.00154847
Iteration 14/25 | Loss: 0.00152358
Iteration 15/25 | Loss: 0.00149063
Iteration 16/25 | Loss: 0.00147634
Iteration 17/25 | Loss: 0.00146474
Iteration 18/25 | Loss: 0.00144552
Iteration 19/25 | Loss: 0.00144288
Iteration 20/25 | Loss: 0.00142466
Iteration 21/25 | Loss: 0.00141871
Iteration 22/25 | Loss: 0.00141369
Iteration 23/25 | Loss: 0.00141058
Iteration 24/25 | Loss: 0.00140442
Iteration 25/25 | Loss: 0.00140164

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31487322
Iteration 2/25 | Loss: 0.00384680
Iteration 3/25 | Loss: 0.00380841
Iteration 4/25 | Loss: 0.00380841
Iteration 5/25 | Loss: 0.00380841
Iteration 6/25 | Loss: 0.00380841
Iteration 7/25 | Loss: 0.00380841
Iteration 8/25 | Loss: 0.00380841
Iteration 9/25 | Loss: 0.00380841
Iteration 10/25 | Loss: 0.00380841
Iteration 11/25 | Loss: 0.00380841
Iteration 12/25 | Loss: 0.00380841
Iteration 13/25 | Loss: 0.00380841
Iteration 14/25 | Loss: 0.00380841
Iteration 15/25 | Loss: 0.00380841
Iteration 16/25 | Loss: 0.00380841
Iteration 17/25 | Loss: 0.00380841
Iteration 18/25 | Loss: 0.00380841
Iteration 19/25 | Loss: 0.00380841
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.003808407112956047, 0.003808407112956047, 0.003808407112956047, 0.003808407112956047, 0.003808407112956047]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003808407112956047

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00380841
Iteration 2/1000 | Loss: 0.00037201
Iteration 3/1000 | Loss: 0.00055421
Iteration 4/1000 | Loss: 0.00028510
Iteration 5/1000 | Loss: 0.00038714
Iteration 6/1000 | Loss: 0.00070326
Iteration 7/1000 | Loss: 0.00042984
Iteration 8/1000 | Loss: 0.00044994
Iteration 9/1000 | Loss: 0.00031728
Iteration 10/1000 | Loss: 0.00058256
Iteration 11/1000 | Loss: 0.00019314
Iteration 12/1000 | Loss: 0.00160112
Iteration 13/1000 | Loss: 0.00200753
Iteration 14/1000 | Loss: 0.00811025
Iteration 15/1000 | Loss: 0.00128612
Iteration 16/1000 | Loss: 0.00076801
Iteration 17/1000 | Loss: 0.00046794
Iteration 18/1000 | Loss: 0.00036186
Iteration 19/1000 | Loss: 0.00027344
Iteration 20/1000 | Loss: 0.00017958
Iteration 21/1000 | Loss: 0.00040380
Iteration 22/1000 | Loss: 0.00013657
Iteration 23/1000 | Loss: 0.00062030
Iteration 24/1000 | Loss: 0.00041733
Iteration 25/1000 | Loss: 0.00014363
Iteration 26/1000 | Loss: 0.00031594
Iteration 27/1000 | Loss: 0.00019008
Iteration 28/1000 | Loss: 0.00014693
Iteration 29/1000 | Loss: 0.00012763
Iteration 30/1000 | Loss: 0.00012622
Iteration 31/1000 | Loss: 0.00012726
Iteration 32/1000 | Loss: 0.00013520
Iteration 33/1000 | Loss: 0.00013450
Iteration 34/1000 | Loss: 0.00011035
Iteration 35/1000 | Loss: 0.00077715
Iteration 36/1000 | Loss: 0.00017176
Iteration 37/1000 | Loss: 0.00012994
Iteration 38/1000 | Loss: 0.00052411
Iteration 39/1000 | Loss: 0.00046577
Iteration 40/1000 | Loss: 0.00098118
Iteration 41/1000 | Loss: 0.00024385
Iteration 42/1000 | Loss: 0.00048819
Iteration 43/1000 | Loss: 0.00009432
Iteration 44/1000 | Loss: 0.00008284
Iteration 45/1000 | Loss: 0.00012858
Iteration 46/1000 | Loss: 0.00007799
Iteration 47/1000 | Loss: 0.00010277
Iteration 48/1000 | Loss: 0.00007003
Iteration 49/1000 | Loss: 0.00043978
Iteration 50/1000 | Loss: 0.00013775
Iteration 51/1000 | Loss: 0.00049471
Iteration 52/1000 | Loss: 0.00051823
Iteration 53/1000 | Loss: 0.00059742
Iteration 54/1000 | Loss: 0.00011275
Iteration 55/1000 | Loss: 0.00012640
Iteration 56/1000 | Loss: 0.00009597
Iteration 57/1000 | Loss: 0.00015411
Iteration 58/1000 | Loss: 0.00011844
Iteration 59/1000 | Loss: 0.00007234
Iteration 60/1000 | Loss: 0.00013285
Iteration 61/1000 | Loss: 0.00007353
Iteration 62/1000 | Loss: 0.00006894
Iteration 63/1000 | Loss: 0.00006231
Iteration 64/1000 | Loss: 0.00006134
Iteration 65/1000 | Loss: 0.00008395
Iteration 66/1000 | Loss: 0.00006073
Iteration 67/1000 | Loss: 0.00005999
Iteration 68/1000 | Loss: 0.00005969
Iteration 69/1000 | Loss: 0.00010655
Iteration 70/1000 | Loss: 0.00006698
Iteration 71/1000 | Loss: 0.00006791
Iteration 72/1000 | Loss: 0.00006086
Iteration 73/1000 | Loss: 0.00006021
Iteration 74/1000 | Loss: 0.00005973
Iteration 75/1000 | Loss: 0.00006099
Iteration 76/1000 | Loss: 0.00007368
Iteration 77/1000 | Loss: 0.00006652
Iteration 78/1000 | Loss: 0.00015371
Iteration 79/1000 | Loss: 0.00007174
Iteration 80/1000 | Loss: 0.00018305
Iteration 81/1000 | Loss: 0.00008652
Iteration 82/1000 | Loss: 0.00009874
Iteration 83/1000 | Loss: 0.00013809
Iteration 84/1000 | Loss: 0.00009135
Iteration 85/1000 | Loss: 0.00005730
Iteration 86/1000 | Loss: 0.00005616
Iteration 87/1000 | Loss: 0.00007706
Iteration 88/1000 | Loss: 0.00005532
Iteration 89/1000 | Loss: 0.00005508
Iteration 90/1000 | Loss: 0.00019233
Iteration 91/1000 | Loss: 0.00006028
Iteration 92/1000 | Loss: 0.00009013
Iteration 93/1000 | Loss: 0.00005445
Iteration 94/1000 | Loss: 0.00007060
Iteration 95/1000 | Loss: 0.00005467
Iteration 96/1000 | Loss: 0.00014643
Iteration 97/1000 | Loss: 0.00006358
Iteration 98/1000 | Loss: 0.00008417
Iteration 99/1000 | Loss: 0.00005369
Iteration 100/1000 | Loss: 0.00005359
Iteration 101/1000 | Loss: 0.00005358
Iteration 102/1000 | Loss: 0.00005357
Iteration 103/1000 | Loss: 0.00005357
Iteration 104/1000 | Loss: 0.00005356
Iteration 105/1000 | Loss: 0.00005356
Iteration 106/1000 | Loss: 0.00005356
Iteration 107/1000 | Loss: 0.00005355
Iteration 108/1000 | Loss: 0.00005354
Iteration 109/1000 | Loss: 0.00005350
Iteration 110/1000 | Loss: 0.00005346
Iteration 111/1000 | Loss: 0.00005345
Iteration 112/1000 | Loss: 0.00005345
Iteration 113/1000 | Loss: 0.00040414
Iteration 114/1000 | Loss: 0.00041914
Iteration 115/1000 | Loss: 0.00005550
Iteration 116/1000 | Loss: 0.00009635
Iteration 117/1000 | Loss: 0.00007779
Iteration 118/1000 | Loss: 0.00005165
Iteration 119/1000 | Loss: 0.00005073
Iteration 120/1000 | Loss: 0.00008688
Iteration 121/1000 | Loss: 0.00009150
Iteration 122/1000 | Loss: 0.00005013
Iteration 123/1000 | Loss: 0.00011211
Iteration 124/1000 | Loss: 0.00006081
Iteration 125/1000 | Loss: 0.00004988
Iteration 126/1000 | Loss: 0.00004981
Iteration 127/1000 | Loss: 0.00006952
Iteration 128/1000 | Loss: 0.00005342
Iteration 129/1000 | Loss: 0.00005056
Iteration 130/1000 | Loss: 0.00004967
Iteration 131/1000 | Loss: 0.00004962
Iteration 132/1000 | Loss: 0.00004962
Iteration 133/1000 | Loss: 0.00004962
Iteration 134/1000 | Loss: 0.00004962
Iteration 135/1000 | Loss: 0.00004962
Iteration 136/1000 | Loss: 0.00004962
Iteration 137/1000 | Loss: 0.00004962
Iteration 138/1000 | Loss: 0.00004962
Iteration 139/1000 | Loss: 0.00004962
Iteration 140/1000 | Loss: 0.00004962
Iteration 141/1000 | Loss: 0.00004962
Iteration 142/1000 | Loss: 0.00006167
Iteration 143/1000 | Loss: 0.00004980
Iteration 144/1000 | Loss: 0.00004963
Iteration 145/1000 | Loss: 0.00004963
Iteration 146/1000 | Loss: 0.00004963
Iteration 147/1000 | Loss: 0.00004963
Iteration 148/1000 | Loss: 0.00004962
Iteration 149/1000 | Loss: 0.00004962
Iteration 150/1000 | Loss: 0.00005461
Iteration 151/1000 | Loss: 0.00005031
Iteration 152/1000 | Loss: 0.00004963
Iteration 153/1000 | Loss: 0.00004963
Iteration 154/1000 | Loss: 0.00004963
Iteration 155/1000 | Loss: 0.00004963
Iteration 156/1000 | Loss: 0.00004963
Iteration 157/1000 | Loss: 0.00004963
Iteration 158/1000 | Loss: 0.00004963
Iteration 159/1000 | Loss: 0.00004963
Iteration 160/1000 | Loss: 0.00004963
Iteration 161/1000 | Loss: 0.00004963
Iteration 162/1000 | Loss: 0.00004963
Iteration 163/1000 | Loss: 0.00004963
Iteration 164/1000 | Loss: 0.00004963
Iteration 165/1000 | Loss: 0.00004962
Iteration 166/1000 | Loss: 0.00004961
Iteration 167/1000 | Loss: 0.00004961
Iteration 168/1000 | Loss: 0.00004961
Iteration 169/1000 | Loss: 0.00004961
Iteration 170/1000 | Loss: 0.00004961
Iteration 171/1000 | Loss: 0.00004961
Iteration 172/1000 | Loss: 0.00004961
Iteration 173/1000 | Loss: 0.00004961
Iteration 174/1000 | Loss: 0.00004961
Iteration 175/1000 | Loss: 0.00004961
Iteration 176/1000 | Loss: 0.00004961
Iteration 177/1000 | Loss: 0.00004960
Iteration 178/1000 | Loss: 0.00004960
Iteration 179/1000 | Loss: 0.00004960
Iteration 180/1000 | Loss: 0.00004960
Iteration 181/1000 | Loss: 0.00004960
Iteration 182/1000 | Loss: 0.00004960
Iteration 183/1000 | Loss: 0.00004960
Iteration 184/1000 | Loss: 0.00004960
Iteration 185/1000 | Loss: 0.00004960
Iteration 186/1000 | Loss: 0.00004959
Iteration 187/1000 | Loss: 0.00004959
Iteration 188/1000 | Loss: 0.00004959
Iteration 189/1000 | Loss: 0.00004959
Iteration 190/1000 | Loss: 0.00004959
Iteration 191/1000 | Loss: 0.00004959
Iteration 192/1000 | Loss: 0.00004959
Iteration 193/1000 | Loss: 0.00004959
Iteration 194/1000 | Loss: 0.00004959
Iteration 195/1000 | Loss: 0.00004959
Iteration 196/1000 | Loss: 0.00004959
Iteration 197/1000 | Loss: 0.00004959
Iteration 198/1000 | Loss: 0.00004959
Iteration 199/1000 | Loss: 0.00004959
Iteration 200/1000 | Loss: 0.00004959
Iteration 201/1000 | Loss: 0.00004959
Iteration 202/1000 | Loss: 0.00004959
Iteration 203/1000 | Loss: 0.00004959
Iteration 204/1000 | Loss: 0.00004959
Iteration 205/1000 | Loss: 0.00004959
Iteration 206/1000 | Loss: 0.00004959
Iteration 207/1000 | Loss: 0.00004959
Iteration 208/1000 | Loss: 0.00004959
Iteration 209/1000 | Loss: 0.00004959
Iteration 210/1000 | Loss: 0.00004959
Iteration 211/1000 | Loss: 0.00004959
Iteration 212/1000 | Loss: 0.00004959
Iteration 213/1000 | Loss: 0.00004959
Iteration 214/1000 | Loss: 0.00004959
Iteration 215/1000 | Loss: 0.00004959
Iteration 216/1000 | Loss: 0.00004959
Iteration 217/1000 | Loss: 0.00004959
Iteration 218/1000 | Loss: 0.00004959
Iteration 219/1000 | Loss: 0.00004959
Iteration 220/1000 | Loss: 0.00004959
Iteration 221/1000 | Loss: 0.00004959
Iteration 222/1000 | Loss: 0.00004959
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 222. Stopping optimization.
Last 5 losses: [4.959167563356459e-05, 4.959167563356459e-05, 4.959167563356459e-05, 4.959167563356459e-05, 4.959167563356459e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.959167563356459e-05

Optimization complete. Final v2v error: 5.0321173667907715 mm

Highest mean error: 14.116021156311035 mm for frame 113

Lowest mean error: 4.091848850250244 mm for frame 67

Saving results

Total time: 209.6102089881897
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00568213
Iteration 2/25 | Loss: 0.00138843
Iteration 3/25 | Loss: 0.00112227
Iteration 4/25 | Loss: 0.00107685
Iteration 5/25 | Loss: 0.00106809
Iteration 6/25 | Loss: 0.00106592
Iteration 7/25 | Loss: 0.00106586
Iteration 8/25 | Loss: 0.00106586
Iteration 9/25 | Loss: 0.00106586
Iteration 10/25 | Loss: 0.00106586
Iteration 11/25 | Loss: 0.00106586
Iteration 12/25 | Loss: 0.00106586
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010658627143129706, 0.0010658627143129706, 0.0010658627143129706, 0.0010658627143129706, 0.0010658627143129706]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010658627143129706

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.83961588
Iteration 2/25 | Loss: 0.00171933
Iteration 3/25 | Loss: 0.00171933
Iteration 4/25 | Loss: 0.00171933
Iteration 5/25 | Loss: 0.00171933
Iteration 6/25 | Loss: 0.00171933
Iteration 7/25 | Loss: 0.00171933
Iteration 8/25 | Loss: 0.00171933
Iteration 9/25 | Loss: 0.00171933
Iteration 10/25 | Loss: 0.00171933
Iteration 11/25 | Loss: 0.00171933
Iteration 12/25 | Loss: 0.00171933
Iteration 13/25 | Loss: 0.00171933
Iteration 14/25 | Loss: 0.00171933
Iteration 15/25 | Loss: 0.00171933
Iteration 16/25 | Loss: 0.00171933
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0017193298554047942, 0.0017193298554047942, 0.0017193298554047942, 0.0017193298554047942, 0.0017193298554047942]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017193298554047942

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00171933
Iteration 2/1000 | Loss: 0.00004830
Iteration 3/1000 | Loss: 0.00003543
Iteration 4/1000 | Loss: 0.00003293
Iteration 5/1000 | Loss: 0.00003138
Iteration 6/1000 | Loss: 0.00003033
Iteration 7/1000 | Loss: 0.00002942
Iteration 8/1000 | Loss: 0.00002886
Iteration 9/1000 | Loss: 0.00002852
Iteration 10/1000 | Loss: 0.00002830
Iteration 11/1000 | Loss: 0.00002819
Iteration 12/1000 | Loss: 0.00002816
Iteration 13/1000 | Loss: 0.00002814
Iteration 14/1000 | Loss: 0.00002813
Iteration 15/1000 | Loss: 0.00002813
Iteration 16/1000 | Loss: 0.00002812
Iteration 17/1000 | Loss: 0.00002812
Iteration 18/1000 | Loss: 0.00002812
Iteration 19/1000 | Loss: 0.00002811
Iteration 20/1000 | Loss: 0.00002811
Iteration 21/1000 | Loss: 0.00002811
Iteration 22/1000 | Loss: 0.00002811
Iteration 23/1000 | Loss: 0.00002811
Iteration 24/1000 | Loss: 0.00002811
Iteration 25/1000 | Loss: 0.00002810
Iteration 26/1000 | Loss: 0.00002810
Iteration 27/1000 | Loss: 0.00002805
Iteration 28/1000 | Loss: 0.00002805
Iteration 29/1000 | Loss: 0.00002797
Iteration 30/1000 | Loss: 0.00002794
Iteration 31/1000 | Loss: 0.00002793
Iteration 32/1000 | Loss: 0.00002792
Iteration 33/1000 | Loss: 0.00002792
Iteration 34/1000 | Loss: 0.00002788
Iteration 35/1000 | Loss: 0.00002787
Iteration 36/1000 | Loss: 0.00002787
Iteration 37/1000 | Loss: 0.00002786
Iteration 38/1000 | Loss: 0.00002786
Iteration 39/1000 | Loss: 0.00002786
Iteration 40/1000 | Loss: 0.00002786
Iteration 41/1000 | Loss: 0.00002785
Iteration 42/1000 | Loss: 0.00002784
Iteration 43/1000 | Loss: 0.00002784
Iteration 44/1000 | Loss: 0.00002784
Iteration 45/1000 | Loss: 0.00002783
Iteration 46/1000 | Loss: 0.00002779
Iteration 47/1000 | Loss: 0.00002779
Iteration 48/1000 | Loss: 0.00002775
Iteration 49/1000 | Loss: 0.00002775
Iteration 50/1000 | Loss: 0.00002775
Iteration 51/1000 | Loss: 0.00002775
Iteration 52/1000 | Loss: 0.00002775
Iteration 53/1000 | Loss: 0.00002775
Iteration 54/1000 | Loss: 0.00002775
Iteration 55/1000 | Loss: 0.00002775
Iteration 56/1000 | Loss: 0.00002775
Iteration 57/1000 | Loss: 0.00002775
Iteration 58/1000 | Loss: 0.00002774
Iteration 59/1000 | Loss: 0.00002774
Iteration 60/1000 | Loss: 0.00002774
Iteration 61/1000 | Loss: 0.00002774
Iteration 62/1000 | Loss: 0.00002774
Iteration 63/1000 | Loss: 0.00002773
Iteration 64/1000 | Loss: 0.00002773
Iteration 65/1000 | Loss: 0.00002773
Iteration 66/1000 | Loss: 0.00002772
Iteration 67/1000 | Loss: 0.00002772
Iteration 68/1000 | Loss: 0.00002772
Iteration 69/1000 | Loss: 0.00002772
Iteration 70/1000 | Loss: 0.00002771
Iteration 71/1000 | Loss: 0.00002771
Iteration 72/1000 | Loss: 0.00002771
Iteration 73/1000 | Loss: 0.00002771
Iteration 74/1000 | Loss: 0.00002771
Iteration 75/1000 | Loss: 0.00002771
Iteration 76/1000 | Loss: 0.00002771
Iteration 77/1000 | Loss: 0.00002771
Iteration 78/1000 | Loss: 0.00002771
Iteration 79/1000 | Loss: 0.00002770
Iteration 80/1000 | Loss: 0.00002770
Iteration 81/1000 | Loss: 0.00002770
Iteration 82/1000 | Loss: 0.00002770
Iteration 83/1000 | Loss: 0.00002770
Iteration 84/1000 | Loss: 0.00002770
Iteration 85/1000 | Loss: 0.00002770
Iteration 86/1000 | Loss: 0.00002769
Iteration 87/1000 | Loss: 0.00002769
Iteration 88/1000 | Loss: 0.00002769
Iteration 89/1000 | Loss: 0.00002769
Iteration 90/1000 | Loss: 0.00002769
Iteration 91/1000 | Loss: 0.00002769
Iteration 92/1000 | Loss: 0.00002769
Iteration 93/1000 | Loss: 0.00002769
Iteration 94/1000 | Loss: 0.00002769
Iteration 95/1000 | Loss: 0.00002769
Iteration 96/1000 | Loss: 0.00002769
Iteration 97/1000 | Loss: 0.00002769
Iteration 98/1000 | Loss: 0.00002769
Iteration 99/1000 | Loss: 0.00002769
Iteration 100/1000 | Loss: 0.00002769
Iteration 101/1000 | Loss: 0.00002769
Iteration 102/1000 | Loss: 0.00002769
Iteration 103/1000 | Loss: 0.00002769
Iteration 104/1000 | Loss: 0.00002769
Iteration 105/1000 | Loss: 0.00002769
Iteration 106/1000 | Loss: 0.00002769
Iteration 107/1000 | Loss: 0.00002769
Iteration 108/1000 | Loss: 0.00002769
Iteration 109/1000 | Loss: 0.00002769
Iteration 110/1000 | Loss: 0.00002769
Iteration 111/1000 | Loss: 0.00002769
Iteration 112/1000 | Loss: 0.00002769
Iteration 113/1000 | Loss: 0.00002769
Iteration 114/1000 | Loss: 0.00002769
Iteration 115/1000 | Loss: 0.00002769
Iteration 116/1000 | Loss: 0.00002769
Iteration 117/1000 | Loss: 0.00002769
Iteration 118/1000 | Loss: 0.00002769
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [2.7693795345840044e-05, 2.7693795345840044e-05, 2.7693795345840044e-05, 2.7693795345840044e-05, 2.7693795345840044e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7693795345840044e-05

Optimization complete. Final v2v error: 4.403049945831299 mm

Highest mean error: 4.606474876403809 mm for frame 57

Lowest mean error: 4.246118545532227 mm for frame 236

Saving results

Total time: 40.685157775878906
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00645345
Iteration 2/25 | Loss: 0.00136821
Iteration 3/25 | Loss: 0.00112508
Iteration 4/25 | Loss: 0.00101296
Iteration 5/25 | Loss: 0.00096274
Iteration 6/25 | Loss: 0.00095858
Iteration 7/25 | Loss: 0.00095447
Iteration 8/25 | Loss: 0.00095463
Iteration 9/25 | Loss: 0.00095255
Iteration 10/25 | Loss: 0.00095143
Iteration 11/25 | Loss: 0.00095091
Iteration 12/25 | Loss: 0.00095063
Iteration 13/25 | Loss: 0.00095028
Iteration 14/25 | Loss: 0.00095005
Iteration 15/25 | Loss: 0.00094986
Iteration 16/25 | Loss: 0.00095388
Iteration 17/25 | Loss: 0.00094782
Iteration 18/25 | Loss: 0.00094666
Iteration 19/25 | Loss: 0.00094628
Iteration 20/25 | Loss: 0.00094618
Iteration 21/25 | Loss: 0.00094617
Iteration 22/25 | Loss: 0.00094614
Iteration 23/25 | Loss: 0.00094613
Iteration 24/25 | Loss: 0.00094612
Iteration 25/25 | Loss: 0.00094612

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.45871735
Iteration 2/25 | Loss: 0.00177157
Iteration 3/25 | Loss: 0.00177156
Iteration 4/25 | Loss: 0.00177156
Iteration 5/25 | Loss: 0.00177156
Iteration 6/25 | Loss: 0.00177156
Iteration 7/25 | Loss: 0.00177156
Iteration 8/25 | Loss: 0.00177156
Iteration 9/25 | Loss: 0.00177156
Iteration 10/25 | Loss: 0.00177156
Iteration 11/25 | Loss: 0.00177156
Iteration 12/25 | Loss: 0.00177156
Iteration 13/25 | Loss: 0.00177156
Iteration 14/25 | Loss: 0.00177156
Iteration 15/25 | Loss: 0.00177156
Iteration 16/25 | Loss: 0.00177156
Iteration 17/25 | Loss: 0.00177156
Iteration 18/25 | Loss: 0.00177156
Iteration 19/25 | Loss: 0.00177156
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0017715624999254942, 0.0017715624999254942, 0.0017715624999254942, 0.0017715624999254942, 0.0017715624999254942]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017715624999254942

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00177156
Iteration 2/1000 | Loss: 0.00001921
Iteration 3/1000 | Loss: 0.00001605
Iteration 4/1000 | Loss: 0.00001441
Iteration 5/1000 | Loss: 0.00001366
Iteration 6/1000 | Loss: 0.00001316
Iteration 7/1000 | Loss: 0.00001281
Iteration 8/1000 | Loss: 0.00001244
Iteration 9/1000 | Loss: 0.00001229
Iteration 10/1000 | Loss: 0.00001221
Iteration 11/1000 | Loss: 0.00001219
Iteration 12/1000 | Loss: 0.00001215
Iteration 13/1000 | Loss: 0.00001215
Iteration 14/1000 | Loss: 0.00001214
Iteration 15/1000 | Loss: 0.00001210
Iteration 16/1000 | Loss: 0.00001208
Iteration 17/1000 | Loss: 0.00001208
Iteration 18/1000 | Loss: 0.00001207
Iteration 19/1000 | Loss: 0.00001207
Iteration 20/1000 | Loss: 0.00001206
Iteration 21/1000 | Loss: 0.00001203
Iteration 22/1000 | Loss: 0.00001202
Iteration 23/1000 | Loss: 0.00001200
Iteration 24/1000 | Loss: 0.00001200
Iteration 25/1000 | Loss: 0.00001200
Iteration 26/1000 | Loss: 0.00001199
Iteration 27/1000 | Loss: 0.00001197
Iteration 28/1000 | Loss: 0.00001196
Iteration 29/1000 | Loss: 0.00001196
Iteration 30/1000 | Loss: 0.00001195
Iteration 31/1000 | Loss: 0.00001195
Iteration 32/1000 | Loss: 0.00001195
Iteration 33/1000 | Loss: 0.00001195
Iteration 34/1000 | Loss: 0.00001195
Iteration 35/1000 | Loss: 0.00001195
Iteration 36/1000 | Loss: 0.00001195
Iteration 37/1000 | Loss: 0.00001193
Iteration 38/1000 | Loss: 0.00001193
Iteration 39/1000 | Loss: 0.00001193
Iteration 40/1000 | Loss: 0.00001193
Iteration 41/1000 | Loss: 0.00001193
Iteration 42/1000 | Loss: 0.00001193
Iteration 43/1000 | Loss: 0.00001192
Iteration 44/1000 | Loss: 0.00001192
Iteration 45/1000 | Loss: 0.00001192
Iteration 46/1000 | Loss: 0.00001192
Iteration 47/1000 | Loss: 0.00001191
Iteration 48/1000 | Loss: 0.00001191
Iteration 49/1000 | Loss: 0.00001191
Iteration 50/1000 | Loss: 0.00001191
Iteration 51/1000 | Loss: 0.00001191
Iteration 52/1000 | Loss: 0.00001190
Iteration 53/1000 | Loss: 0.00001190
Iteration 54/1000 | Loss: 0.00001190
Iteration 55/1000 | Loss: 0.00001190
Iteration 56/1000 | Loss: 0.00001190
Iteration 57/1000 | Loss: 0.00001190
Iteration 58/1000 | Loss: 0.00001190
Iteration 59/1000 | Loss: 0.00001189
Iteration 60/1000 | Loss: 0.00001189
Iteration 61/1000 | Loss: 0.00001189
Iteration 62/1000 | Loss: 0.00001189
Iteration 63/1000 | Loss: 0.00001189
Iteration 64/1000 | Loss: 0.00001189
Iteration 65/1000 | Loss: 0.00001189
Iteration 66/1000 | Loss: 0.00001189
Iteration 67/1000 | Loss: 0.00001189
Iteration 68/1000 | Loss: 0.00001188
Iteration 69/1000 | Loss: 0.00001188
Iteration 70/1000 | Loss: 0.00001188
Iteration 71/1000 | Loss: 0.00001188
Iteration 72/1000 | Loss: 0.00001188
Iteration 73/1000 | Loss: 0.00001187
Iteration 74/1000 | Loss: 0.00001187
Iteration 75/1000 | Loss: 0.00001187
Iteration 76/1000 | Loss: 0.00001187
Iteration 77/1000 | Loss: 0.00001187
Iteration 78/1000 | Loss: 0.00001187
Iteration 79/1000 | Loss: 0.00001187
Iteration 80/1000 | Loss: 0.00001186
Iteration 81/1000 | Loss: 0.00001186
Iteration 82/1000 | Loss: 0.00001186
Iteration 83/1000 | Loss: 0.00001186
Iteration 84/1000 | Loss: 0.00001185
Iteration 85/1000 | Loss: 0.00001185
Iteration 86/1000 | Loss: 0.00001185
Iteration 87/1000 | Loss: 0.00001184
Iteration 88/1000 | Loss: 0.00001184
Iteration 89/1000 | Loss: 0.00001184
Iteration 90/1000 | Loss: 0.00001184
Iteration 91/1000 | Loss: 0.00001184
Iteration 92/1000 | Loss: 0.00001184
Iteration 93/1000 | Loss: 0.00001183
Iteration 94/1000 | Loss: 0.00001183
Iteration 95/1000 | Loss: 0.00001183
Iteration 96/1000 | Loss: 0.00001183
Iteration 97/1000 | Loss: 0.00001183
Iteration 98/1000 | Loss: 0.00001182
Iteration 99/1000 | Loss: 0.00001182
Iteration 100/1000 | Loss: 0.00001182
Iteration 101/1000 | Loss: 0.00001182
Iteration 102/1000 | Loss: 0.00001182
Iteration 103/1000 | Loss: 0.00001182
Iteration 104/1000 | Loss: 0.00001182
Iteration 105/1000 | Loss: 0.00001182
Iteration 106/1000 | Loss: 0.00001182
Iteration 107/1000 | Loss: 0.00001181
Iteration 108/1000 | Loss: 0.00001181
Iteration 109/1000 | Loss: 0.00001181
Iteration 110/1000 | Loss: 0.00001181
Iteration 111/1000 | Loss: 0.00001181
Iteration 112/1000 | Loss: 0.00001181
Iteration 113/1000 | Loss: 0.00001180
Iteration 114/1000 | Loss: 0.00001180
Iteration 115/1000 | Loss: 0.00001180
Iteration 116/1000 | Loss: 0.00001180
Iteration 117/1000 | Loss: 0.00001180
Iteration 118/1000 | Loss: 0.00001180
Iteration 119/1000 | Loss: 0.00001180
Iteration 120/1000 | Loss: 0.00001180
Iteration 121/1000 | Loss: 0.00001180
Iteration 122/1000 | Loss: 0.00001180
Iteration 123/1000 | Loss: 0.00001180
Iteration 124/1000 | Loss: 0.00001180
Iteration 125/1000 | Loss: 0.00001180
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [1.1803036613855511e-05, 1.1803036613855511e-05, 1.1803036613855511e-05, 1.1803036613855511e-05, 1.1803036613855511e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1803036613855511e-05

Optimization complete. Final v2v error: 2.9690825939178467 mm

Highest mean error: 3.466883420944214 mm for frame 168

Lowest mean error: 2.686368942260742 mm for frame 109

Saving results

Total time: 64.79516863822937
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00510274
Iteration 2/25 | Loss: 0.00109126
Iteration 3/25 | Loss: 0.00097841
Iteration 4/25 | Loss: 0.00096612
Iteration 5/25 | Loss: 0.00096209
Iteration 6/25 | Loss: 0.00096100
Iteration 7/25 | Loss: 0.00096091
Iteration 8/25 | Loss: 0.00096091
Iteration 9/25 | Loss: 0.00096091
Iteration 10/25 | Loss: 0.00096091
Iteration 11/25 | Loss: 0.00096091
Iteration 12/25 | Loss: 0.00096091
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009609134867787361, 0.0009609134867787361, 0.0009609134867787361, 0.0009609134867787361, 0.0009609134867787361]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009609134867787361

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.33981419
Iteration 2/25 | Loss: 0.00171295
Iteration 3/25 | Loss: 0.00171294
Iteration 4/25 | Loss: 0.00171294
Iteration 5/25 | Loss: 0.00171294
Iteration 6/25 | Loss: 0.00171294
Iteration 7/25 | Loss: 0.00171294
Iteration 8/25 | Loss: 0.00171294
Iteration 9/25 | Loss: 0.00171294
Iteration 10/25 | Loss: 0.00171294
Iteration 11/25 | Loss: 0.00171294
Iteration 12/25 | Loss: 0.00171294
Iteration 13/25 | Loss: 0.00171294
Iteration 14/25 | Loss: 0.00171294
Iteration 15/25 | Loss: 0.00171294
Iteration 16/25 | Loss: 0.00171294
Iteration 17/25 | Loss: 0.00171294
Iteration 18/25 | Loss: 0.00171294
Iteration 19/25 | Loss: 0.00171294
Iteration 20/25 | Loss: 0.00171294
Iteration 21/25 | Loss: 0.00171294
Iteration 22/25 | Loss: 0.00171294
Iteration 23/25 | Loss: 0.00171294
Iteration 24/25 | Loss: 0.00171294
Iteration 25/25 | Loss: 0.00171294

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00171294
Iteration 2/1000 | Loss: 0.00002172
Iteration 3/1000 | Loss: 0.00001793
Iteration 4/1000 | Loss: 0.00001658
Iteration 5/1000 | Loss: 0.00001587
Iteration 6/1000 | Loss: 0.00001532
Iteration 7/1000 | Loss: 0.00001497
Iteration 8/1000 | Loss: 0.00001482
Iteration 9/1000 | Loss: 0.00001481
Iteration 10/1000 | Loss: 0.00001479
Iteration 11/1000 | Loss: 0.00001477
Iteration 12/1000 | Loss: 0.00001476
Iteration 13/1000 | Loss: 0.00001472
Iteration 14/1000 | Loss: 0.00001469
Iteration 15/1000 | Loss: 0.00001468
Iteration 16/1000 | Loss: 0.00001468
Iteration 17/1000 | Loss: 0.00001467
Iteration 18/1000 | Loss: 0.00001467
Iteration 19/1000 | Loss: 0.00001466
Iteration 20/1000 | Loss: 0.00001466
Iteration 21/1000 | Loss: 0.00001465
Iteration 22/1000 | Loss: 0.00001465
Iteration 23/1000 | Loss: 0.00001464
Iteration 24/1000 | Loss: 0.00001464
Iteration 25/1000 | Loss: 0.00001464
Iteration 26/1000 | Loss: 0.00001464
Iteration 27/1000 | Loss: 0.00001464
Iteration 28/1000 | Loss: 0.00001463
Iteration 29/1000 | Loss: 0.00001463
Iteration 30/1000 | Loss: 0.00001462
Iteration 31/1000 | Loss: 0.00001461
Iteration 32/1000 | Loss: 0.00001461
Iteration 33/1000 | Loss: 0.00001460
Iteration 34/1000 | Loss: 0.00001460
Iteration 35/1000 | Loss: 0.00001460
Iteration 36/1000 | Loss: 0.00001460
Iteration 37/1000 | Loss: 0.00001460
Iteration 38/1000 | Loss: 0.00001460
Iteration 39/1000 | Loss: 0.00001460
Iteration 40/1000 | Loss: 0.00001457
Iteration 41/1000 | Loss: 0.00001457
Iteration 42/1000 | Loss: 0.00001457
Iteration 43/1000 | Loss: 0.00001456
Iteration 44/1000 | Loss: 0.00001456
Iteration 45/1000 | Loss: 0.00001455
Iteration 46/1000 | Loss: 0.00001455
Iteration 47/1000 | Loss: 0.00001455
Iteration 48/1000 | Loss: 0.00001455
Iteration 49/1000 | Loss: 0.00001455
Iteration 50/1000 | Loss: 0.00001455
Iteration 51/1000 | Loss: 0.00001455
Iteration 52/1000 | Loss: 0.00001455
Iteration 53/1000 | Loss: 0.00001454
Iteration 54/1000 | Loss: 0.00001454
Iteration 55/1000 | Loss: 0.00001454
Iteration 56/1000 | Loss: 0.00001454
Iteration 57/1000 | Loss: 0.00001453
Iteration 58/1000 | Loss: 0.00001453
Iteration 59/1000 | Loss: 0.00001453
Iteration 60/1000 | Loss: 0.00001453
Iteration 61/1000 | Loss: 0.00001453
Iteration 62/1000 | Loss: 0.00001453
Iteration 63/1000 | Loss: 0.00001453
Iteration 64/1000 | Loss: 0.00001453
Iteration 65/1000 | Loss: 0.00001453
Iteration 66/1000 | Loss: 0.00001453
Iteration 67/1000 | Loss: 0.00001453
Iteration 68/1000 | Loss: 0.00001453
Iteration 69/1000 | Loss: 0.00001453
Iteration 70/1000 | Loss: 0.00001452
Iteration 71/1000 | Loss: 0.00001452
Iteration 72/1000 | Loss: 0.00001452
Iteration 73/1000 | Loss: 0.00001451
Iteration 74/1000 | Loss: 0.00001451
Iteration 75/1000 | Loss: 0.00001451
Iteration 76/1000 | Loss: 0.00001450
Iteration 77/1000 | Loss: 0.00001450
Iteration 78/1000 | Loss: 0.00001450
Iteration 79/1000 | Loss: 0.00001450
Iteration 80/1000 | Loss: 0.00001450
Iteration 81/1000 | Loss: 0.00001450
Iteration 82/1000 | Loss: 0.00001450
Iteration 83/1000 | Loss: 0.00001450
Iteration 84/1000 | Loss: 0.00001450
Iteration 85/1000 | Loss: 0.00001450
Iteration 86/1000 | Loss: 0.00001450
Iteration 87/1000 | Loss: 0.00001449
Iteration 88/1000 | Loss: 0.00001449
Iteration 89/1000 | Loss: 0.00001449
Iteration 90/1000 | Loss: 0.00001449
Iteration 91/1000 | Loss: 0.00001449
Iteration 92/1000 | Loss: 0.00001449
Iteration 93/1000 | Loss: 0.00001449
Iteration 94/1000 | Loss: 0.00001449
Iteration 95/1000 | Loss: 0.00001449
Iteration 96/1000 | Loss: 0.00001449
Iteration 97/1000 | Loss: 0.00001448
Iteration 98/1000 | Loss: 0.00001448
Iteration 99/1000 | Loss: 0.00001448
Iteration 100/1000 | Loss: 0.00001448
Iteration 101/1000 | Loss: 0.00001448
Iteration 102/1000 | Loss: 0.00001448
Iteration 103/1000 | Loss: 0.00001448
Iteration 104/1000 | Loss: 0.00001448
Iteration 105/1000 | Loss: 0.00001448
Iteration 106/1000 | Loss: 0.00001448
Iteration 107/1000 | Loss: 0.00001448
Iteration 108/1000 | Loss: 0.00001448
Iteration 109/1000 | Loss: 0.00001448
Iteration 110/1000 | Loss: 0.00001448
Iteration 111/1000 | Loss: 0.00001448
Iteration 112/1000 | Loss: 0.00001448
Iteration 113/1000 | Loss: 0.00001448
Iteration 114/1000 | Loss: 0.00001448
Iteration 115/1000 | Loss: 0.00001448
Iteration 116/1000 | Loss: 0.00001448
Iteration 117/1000 | Loss: 0.00001448
Iteration 118/1000 | Loss: 0.00001448
Iteration 119/1000 | Loss: 0.00001448
Iteration 120/1000 | Loss: 0.00001447
Iteration 121/1000 | Loss: 0.00001447
Iteration 122/1000 | Loss: 0.00001447
Iteration 123/1000 | Loss: 0.00001447
Iteration 124/1000 | Loss: 0.00001447
Iteration 125/1000 | Loss: 0.00001447
Iteration 126/1000 | Loss: 0.00001447
Iteration 127/1000 | Loss: 0.00001447
Iteration 128/1000 | Loss: 0.00001447
Iteration 129/1000 | Loss: 0.00001447
Iteration 130/1000 | Loss: 0.00001447
Iteration 131/1000 | Loss: 0.00001447
Iteration 132/1000 | Loss: 0.00001447
Iteration 133/1000 | Loss: 0.00001447
Iteration 134/1000 | Loss: 0.00001447
Iteration 135/1000 | Loss: 0.00001447
Iteration 136/1000 | Loss: 0.00001447
Iteration 137/1000 | Loss: 0.00001447
Iteration 138/1000 | Loss: 0.00001447
Iteration 139/1000 | Loss: 0.00001447
Iteration 140/1000 | Loss: 0.00001447
Iteration 141/1000 | Loss: 0.00001447
Iteration 142/1000 | Loss: 0.00001447
Iteration 143/1000 | Loss: 0.00001447
Iteration 144/1000 | Loss: 0.00001447
Iteration 145/1000 | Loss: 0.00001447
Iteration 146/1000 | Loss: 0.00001447
Iteration 147/1000 | Loss: 0.00001447
Iteration 148/1000 | Loss: 0.00001447
Iteration 149/1000 | Loss: 0.00001447
Iteration 150/1000 | Loss: 0.00001447
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [1.4466597349382937e-05, 1.4466597349382937e-05, 1.4466597349382937e-05, 1.4466597349382937e-05, 1.4466597349382937e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4466597349382937e-05

Optimization complete. Final v2v error: 3.254556894302368 mm

Highest mean error: 3.6355204582214355 mm for frame 92

Lowest mean error: 2.8701045513153076 mm for frame 29

Saving results

Total time: 29.70823335647583
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00658290
Iteration 2/25 | Loss: 0.00169587
Iteration 3/25 | Loss: 0.00114688
Iteration 4/25 | Loss: 0.00111716
Iteration 5/25 | Loss: 0.00111000
Iteration 6/25 | Loss: 0.00110843
Iteration 7/25 | Loss: 0.00110800
Iteration 8/25 | Loss: 0.00110800
Iteration 9/25 | Loss: 0.00110800
Iteration 10/25 | Loss: 0.00110800
Iteration 11/25 | Loss: 0.00110800
Iteration 12/25 | Loss: 0.00110800
Iteration 13/25 | Loss: 0.00110800
Iteration 14/25 | Loss: 0.00110800
Iteration 15/25 | Loss: 0.00110800
Iteration 16/25 | Loss: 0.00110800
Iteration 17/25 | Loss: 0.00110800
Iteration 18/25 | Loss: 0.00110800
Iteration 19/25 | Loss: 0.00110800
Iteration 20/25 | Loss: 0.00110800
Iteration 21/25 | Loss: 0.00110800
Iteration 22/25 | Loss: 0.00110800
Iteration 23/25 | Loss: 0.00110800
Iteration 24/25 | Loss: 0.00110800
Iteration 25/25 | Loss: 0.00110800

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.04033804
Iteration 2/25 | Loss: 0.00150510
Iteration 3/25 | Loss: 0.00150509
Iteration 4/25 | Loss: 0.00150509
Iteration 5/25 | Loss: 0.00150509
Iteration 6/25 | Loss: 0.00150509
Iteration 7/25 | Loss: 0.00150509
Iteration 8/25 | Loss: 0.00150509
Iteration 9/25 | Loss: 0.00150509
Iteration 10/25 | Loss: 0.00150509
Iteration 11/25 | Loss: 0.00150509
Iteration 12/25 | Loss: 0.00150509
Iteration 13/25 | Loss: 0.00150509
Iteration 14/25 | Loss: 0.00150509
Iteration 15/25 | Loss: 0.00150509
Iteration 16/25 | Loss: 0.00150509
Iteration 17/25 | Loss: 0.00150509
Iteration 18/25 | Loss: 0.00150509
Iteration 19/25 | Loss: 0.00150509
Iteration 20/25 | Loss: 0.00150509
Iteration 21/25 | Loss: 0.00150509
Iteration 22/25 | Loss: 0.00150509
Iteration 23/25 | Loss: 0.00150509
Iteration 24/25 | Loss: 0.00150509
Iteration 25/25 | Loss: 0.00150509

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00150509
Iteration 2/1000 | Loss: 0.00006472
Iteration 3/1000 | Loss: 0.00004934
Iteration 4/1000 | Loss: 0.00004601
Iteration 5/1000 | Loss: 0.00004427
Iteration 6/1000 | Loss: 0.00004292
Iteration 7/1000 | Loss: 0.00004186
Iteration 8/1000 | Loss: 0.00004121
Iteration 9/1000 | Loss: 0.00004076
Iteration 10/1000 | Loss: 0.00004040
Iteration 11/1000 | Loss: 0.00004009
Iteration 12/1000 | Loss: 0.00003990
Iteration 13/1000 | Loss: 0.00003975
Iteration 14/1000 | Loss: 0.00003969
Iteration 15/1000 | Loss: 0.00003959
Iteration 16/1000 | Loss: 0.00003955
Iteration 17/1000 | Loss: 0.00003948
Iteration 18/1000 | Loss: 0.00003932
Iteration 19/1000 | Loss: 0.00003920
Iteration 20/1000 | Loss: 0.00003920
Iteration 21/1000 | Loss: 0.00003912
Iteration 22/1000 | Loss: 0.00003911
Iteration 23/1000 | Loss: 0.00003909
Iteration 24/1000 | Loss: 0.00003909
Iteration 25/1000 | Loss: 0.00003908
Iteration 26/1000 | Loss: 0.00003908
Iteration 27/1000 | Loss: 0.00003906
Iteration 28/1000 | Loss: 0.00003906
Iteration 29/1000 | Loss: 0.00003906
Iteration 30/1000 | Loss: 0.00003906
Iteration 31/1000 | Loss: 0.00003906
Iteration 32/1000 | Loss: 0.00003905
Iteration 33/1000 | Loss: 0.00003905
Iteration 34/1000 | Loss: 0.00003905
Iteration 35/1000 | Loss: 0.00003904
Iteration 36/1000 | Loss: 0.00003903
Iteration 37/1000 | Loss: 0.00003903
Iteration 38/1000 | Loss: 0.00003903
Iteration 39/1000 | Loss: 0.00003903
Iteration 40/1000 | Loss: 0.00003903
Iteration 41/1000 | Loss: 0.00003903
Iteration 42/1000 | Loss: 0.00003903
Iteration 43/1000 | Loss: 0.00003903
Iteration 44/1000 | Loss: 0.00003903
Iteration 45/1000 | Loss: 0.00003902
Iteration 46/1000 | Loss: 0.00003902
Iteration 47/1000 | Loss: 0.00003902
Iteration 48/1000 | Loss: 0.00003902
Iteration 49/1000 | Loss: 0.00003902
Iteration 50/1000 | Loss: 0.00003901
Iteration 51/1000 | Loss: 0.00003901
Iteration 52/1000 | Loss: 0.00003901
Iteration 53/1000 | Loss: 0.00003900
Iteration 54/1000 | Loss: 0.00003899
Iteration 55/1000 | Loss: 0.00003899
Iteration 56/1000 | Loss: 0.00003899
Iteration 57/1000 | Loss: 0.00003898
Iteration 58/1000 | Loss: 0.00003897
Iteration 59/1000 | Loss: 0.00003896
Iteration 60/1000 | Loss: 0.00003896
Iteration 61/1000 | Loss: 0.00003896
Iteration 62/1000 | Loss: 0.00003896
Iteration 63/1000 | Loss: 0.00003896
Iteration 64/1000 | Loss: 0.00003896
Iteration 65/1000 | Loss: 0.00003896
Iteration 66/1000 | Loss: 0.00003896
Iteration 67/1000 | Loss: 0.00003895
Iteration 68/1000 | Loss: 0.00003895
Iteration 69/1000 | Loss: 0.00003895
Iteration 70/1000 | Loss: 0.00003895
Iteration 71/1000 | Loss: 0.00003893
Iteration 72/1000 | Loss: 0.00003893
Iteration 73/1000 | Loss: 0.00003893
Iteration 74/1000 | Loss: 0.00003893
Iteration 75/1000 | Loss: 0.00003893
Iteration 76/1000 | Loss: 0.00003893
Iteration 77/1000 | Loss: 0.00003893
Iteration 78/1000 | Loss: 0.00003893
Iteration 79/1000 | Loss: 0.00003892
Iteration 80/1000 | Loss: 0.00003892
Iteration 81/1000 | Loss: 0.00003892
Iteration 82/1000 | Loss: 0.00003892
Iteration 83/1000 | Loss: 0.00003892
Iteration 84/1000 | Loss: 0.00003892
Iteration 85/1000 | Loss: 0.00003892
Iteration 86/1000 | Loss: 0.00003892
Iteration 87/1000 | Loss: 0.00003892
Iteration 88/1000 | Loss: 0.00003892
Iteration 89/1000 | Loss: 0.00003891
Iteration 90/1000 | Loss: 0.00003890
Iteration 91/1000 | Loss: 0.00003890
Iteration 92/1000 | Loss: 0.00003890
Iteration 93/1000 | Loss: 0.00003890
Iteration 94/1000 | Loss: 0.00003890
Iteration 95/1000 | Loss: 0.00003890
Iteration 96/1000 | Loss: 0.00003890
Iteration 97/1000 | Loss: 0.00003890
Iteration 98/1000 | Loss: 0.00003890
Iteration 99/1000 | Loss: 0.00003889
Iteration 100/1000 | Loss: 0.00003889
Iteration 101/1000 | Loss: 0.00003889
Iteration 102/1000 | Loss: 0.00003889
Iteration 103/1000 | Loss: 0.00003889
Iteration 104/1000 | Loss: 0.00003888
Iteration 105/1000 | Loss: 0.00003888
Iteration 106/1000 | Loss: 0.00003888
Iteration 107/1000 | Loss: 0.00003888
Iteration 108/1000 | Loss: 0.00003888
Iteration 109/1000 | Loss: 0.00003887
Iteration 110/1000 | Loss: 0.00003887
Iteration 111/1000 | Loss: 0.00003887
Iteration 112/1000 | Loss: 0.00003887
Iteration 113/1000 | Loss: 0.00003887
Iteration 114/1000 | Loss: 0.00003887
Iteration 115/1000 | Loss: 0.00003887
Iteration 116/1000 | Loss: 0.00003887
Iteration 117/1000 | Loss: 0.00003887
Iteration 118/1000 | Loss: 0.00003887
Iteration 119/1000 | Loss: 0.00003886
Iteration 120/1000 | Loss: 0.00003886
Iteration 121/1000 | Loss: 0.00003886
Iteration 122/1000 | Loss: 0.00003886
Iteration 123/1000 | Loss: 0.00003886
Iteration 124/1000 | Loss: 0.00003886
Iteration 125/1000 | Loss: 0.00003886
Iteration 126/1000 | Loss: 0.00003886
Iteration 127/1000 | Loss: 0.00003886
Iteration 128/1000 | Loss: 0.00003885
Iteration 129/1000 | Loss: 0.00003885
Iteration 130/1000 | Loss: 0.00003885
Iteration 131/1000 | Loss: 0.00003885
Iteration 132/1000 | Loss: 0.00003885
Iteration 133/1000 | Loss: 0.00003885
Iteration 134/1000 | Loss: 0.00003885
Iteration 135/1000 | Loss: 0.00003885
Iteration 136/1000 | Loss: 0.00003885
Iteration 137/1000 | Loss: 0.00003885
Iteration 138/1000 | Loss: 0.00003885
Iteration 139/1000 | Loss: 0.00003885
Iteration 140/1000 | Loss: 0.00003885
Iteration 141/1000 | Loss: 0.00003885
Iteration 142/1000 | Loss: 0.00003885
Iteration 143/1000 | Loss: 0.00003885
Iteration 144/1000 | Loss: 0.00003885
Iteration 145/1000 | Loss: 0.00003885
Iteration 146/1000 | Loss: 0.00003885
Iteration 147/1000 | Loss: 0.00003884
Iteration 148/1000 | Loss: 0.00003884
Iteration 149/1000 | Loss: 0.00003884
Iteration 150/1000 | Loss: 0.00003884
Iteration 151/1000 | Loss: 0.00003884
Iteration 152/1000 | Loss: 0.00003884
Iteration 153/1000 | Loss: 0.00003884
Iteration 154/1000 | Loss: 0.00003884
Iteration 155/1000 | Loss: 0.00003883
Iteration 156/1000 | Loss: 0.00003883
Iteration 157/1000 | Loss: 0.00003883
Iteration 158/1000 | Loss: 0.00003883
Iteration 159/1000 | Loss: 0.00003883
Iteration 160/1000 | Loss: 0.00003883
Iteration 161/1000 | Loss: 0.00003883
Iteration 162/1000 | Loss: 0.00003883
Iteration 163/1000 | Loss: 0.00003883
Iteration 164/1000 | Loss: 0.00003883
Iteration 165/1000 | Loss: 0.00003883
Iteration 166/1000 | Loss: 0.00003882
Iteration 167/1000 | Loss: 0.00003882
Iteration 168/1000 | Loss: 0.00003882
Iteration 169/1000 | Loss: 0.00003882
Iteration 170/1000 | Loss: 0.00003882
Iteration 171/1000 | Loss: 0.00003882
Iteration 172/1000 | Loss: 0.00003882
Iteration 173/1000 | Loss: 0.00003882
Iteration 174/1000 | Loss: 0.00003882
Iteration 175/1000 | Loss: 0.00003882
Iteration 176/1000 | Loss: 0.00003882
Iteration 177/1000 | Loss: 0.00003882
Iteration 178/1000 | Loss: 0.00003882
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [3.882117380271666e-05, 3.882117380271666e-05, 3.882117380271666e-05, 3.882117380271666e-05, 3.882117380271666e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.882117380271666e-05

Optimization complete. Final v2v error: 4.968721389770508 mm

Highest mean error: 6.219331741333008 mm for frame 127

Lowest mean error: 3.7624287605285645 mm for frame 45

Saving results

Total time: 45.94601893424988
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00475997
Iteration 2/25 | Loss: 0.00116544
Iteration 3/25 | Loss: 0.00108180
Iteration 4/25 | Loss: 0.00106294
Iteration 5/25 | Loss: 0.00105843
Iteration 6/25 | Loss: 0.00105750
Iteration 7/25 | Loss: 0.00105728
Iteration 8/25 | Loss: 0.00105728
Iteration 9/25 | Loss: 0.00105728
Iteration 10/25 | Loss: 0.00105726
Iteration 11/25 | Loss: 0.00105726
Iteration 12/25 | Loss: 0.00105726
Iteration 13/25 | Loss: 0.00105726
Iteration 14/25 | Loss: 0.00105726
Iteration 15/25 | Loss: 0.00105726
Iteration 16/25 | Loss: 0.00105726
Iteration 17/25 | Loss: 0.00105726
Iteration 18/25 | Loss: 0.00105726
Iteration 19/25 | Loss: 0.00105726
Iteration 20/25 | Loss: 0.00105726
Iteration 21/25 | Loss: 0.00105726
Iteration 22/25 | Loss: 0.00105726
Iteration 23/25 | Loss: 0.00105726
Iteration 24/25 | Loss: 0.00105726
Iteration 25/25 | Loss: 0.00105726

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57325637
Iteration 2/25 | Loss: 0.00172862
Iteration 3/25 | Loss: 0.00172861
Iteration 4/25 | Loss: 0.00172861
Iteration 5/25 | Loss: 0.00172861
Iteration 6/25 | Loss: 0.00172861
Iteration 7/25 | Loss: 0.00172861
Iteration 8/25 | Loss: 0.00172861
Iteration 9/25 | Loss: 0.00172861
Iteration 10/25 | Loss: 0.00172861
Iteration 11/25 | Loss: 0.00172861
Iteration 12/25 | Loss: 0.00172861
Iteration 13/25 | Loss: 0.00172861
Iteration 14/25 | Loss: 0.00172861
Iteration 15/25 | Loss: 0.00172861
Iteration 16/25 | Loss: 0.00172861
Iteration 17/25 | Loss: 0.00172861
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0017286093207076192, 0.0017286093207076192, 0.0017286093207076192, 0.0017286093207076192, 0.0017286093207076192]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017286093207076192

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00172861
Iteration 2/1000 | Loss: 0.00005015
Iteration 3/1000 | Loss: 0.00004105
Iteration 4/1000 | Loss: 0.00003786
Iteration 5/1000 | Loss: 0.00003607
Iteration 6/1000 | Loss: 0.00003486
Iteration 7/1000 | Loss: 0.00003377
Iteration 8/1000 | Loss: 0.00003329
Iteration 9/1000 | Loss: 0.00003317
Iteration 10/1000 | Loss: 0.00003296
Iteration 11/1000 | Loss: 0.00003292
Iteration 12/1000 | Loss: 0.00003290
Iteration 13/1000 | Loss: 0.00003289
Iteration 14/1000 | Loss: 0.00003288
Iteration 15/1000 | Loss: 0.00003288
Iteration 16/1000 | Loss: 0.00003287
Iteration 17/1000 | Loss: 0.00003287
Iteration 18/1000 | Loss: 0.00003285
Iteration 19/1000 | Loss: 0.00003285
Iteration 20/1000 | Loss: 0.00003285
Iteration 21/1000 | Loss: 0.00003285
Iteration 22/1000 | Loss: 0.00003285
Iteration 23/1000 | Loss: 0.00003285
Iteration 24/1000 | Loss: 0.00003285
Iteration 25/1000 | Loss: 0.00003284
Iteration 26/1000 | Loss: 0.00003284
Iteration 27/1000 | Loss: 0.00003284
Iteration 28/1000 | Loss: 0.00003284
Iteration 29/1000 | Loss: 0.00003284
Iteration 30/1000 | Loss: 0.00003284
Iteration 31/1000 | Loss: 0.00003283
Iteration 32/1000 | Loss: 0.00003283
Iteration 33/1000 | Loss: 0.00003283
Iteration 34/1000 | Loss: 0.00003282
Iteration 35/1000 | Loss: 0.00003282
Iteration 36/1000 | Loss: 0.00003282
Iteration 37/1000 | Loss: 0.00003282
Iteration 38/1000 | Loss: 0.00003282
Iteration 39/1000 | Loss: 0.00003282
Iteration 40/1000 | Loss: 0.00003282
Iteration 41/1000 | Loss: 0.00003282
Iteration 42/1000 | Loss: 0.00003282
Iteration 43/1000 | Loss: 0.00003282
Iteration 44/1000 | Loss: 0.00003281
Iteration 45/1000 | Loss: 0.00003281
Iteration 46/1000 | Loss: 0.00003281
Iteration 47/1000 | Loss: 0.00003281
Iteration 48/1000 | Loss: 0.00003281
Iteration 49/1000 | Loss: 0.00003280
Iteration 50/1000 | Loss: 0.00003280
Iteration 51/1000 | Loss: 0.00003280
Iteration 52/1000 | Loss: 0.00003280
Iteration 53/1000 | Loss: 0.00003280
Iteration 54/1000 | Loss: 0.00003280
Iteration 55/1000 | Loss: 0.00003280
Iteration 56/1000 | Loss: 0.00003280
Iteration 57/1000 | Loss: 0.00003279
Iteration 58/1000 | Loss: 0.00003279
Iteration 59/1000 | Loss: 0.00003279
Iteration 60/1000 | Loss: 0.00003279
Iteration 61/1000 | Loss: 0.00003279
Iteration 62/1000 | Loss: 0.00003279
Iteration 63/1000 | Loss: 0.00003279
Iteration 64/1000 | Loss: 0.00003279
Iteration 65/1000 | Loss: 0.00003279
Iteration 66/1000 | Loss: 0.00003278
Iteration 67/1000 | Loss: 0.00003278
Iteration 68/1000 | Loss: 0.00003278
Iteration 69/1000 | Loss: 0.00003278
Iteration 70/1000 | Loss: 0.00003278
Iteration 71/1000 | Loss: 0.00003278
Iteration 72/1000 | Loss: 0.00003278
Iteration 73/1000 | Loss: 0.00003278
Iteration 74/1000 | Loss: 0.00003278
Iteration 75/1000 | Loss: 0.00003278
Iteration 76/1000 | Loss: 0.00003278
Iteration 77/1000 | Loss: 0.00003278
Iteration 78/1000 | Loss: 0.00003278
Iteration 79/1000 | Loss: 0.00003278
Iteration 80/1000 | Loss: 0.00003277
Iteration 81/1000 | Loss: 0.00003277
Iteration 82/1000 | Loss: 0.00003277
Iteration 83/1000 | Loss: 0.00003277
Iteration 84/1000 | Loss: 0.00003277
Iteration 85/1000 | Loss: 0.00003277
Iteration 86/1000 | Loss: 0.00003277
Iteration 87/1000 | Loss: 0.00003277
Iteration 88/1000 | Loss: 0.00003277
Iteration 89/1000 | Loss: 0.00003276
Iteration 90/1000 | Loss: 0.00003276
Iteration 91/1000 | Loss: 0.00003276
Iteration 92/1000 | Loss: 0.00003276
Iteration 93/1000 | Loss: 0.00003276
Iteration 94/1000 | Loss: 0.00003276
Iteration 95/1000 | Loss: 0.00003276
Iteration 96/1000 | Loss: 0.00003276
Iteration 97/1000 | Loss: 0.00003275
Iteration 98/1000 | Loss: 0.00003275
Iteration 99/1000 | Loss: 0.00003275
Iteration 100/1000 | Loss: 0.00003275
Iteration 101/1000 | Loss: 0.00003274
Iteration 102/1000 | Loss: 0.00003274
Iteration 103/1000 | Loss: 0.00003274
Iteration 104/1000 | Loss: 0.00003274
Iteration 105/1000 | Loss: 0.00003274
Iteration 106/1000 | Loss: 0.00003274
Iteration 107/1000 | Loss: 0.00003273
Iteration 108/1000 | Loss: 0.00003273
Iteration 109/1000 | Loss: 0.00003273
Iteration 110/1000 | Loss: 0.00003273
Iteration 111/1000 | Loss: 0.00003273
Iteration 112/1000 | Loss: 0.00003273
Iteration 113/1000 | Loss: 0.00003273
Iteration 114/1000 | Loss: 0.00003273
Iteration 115/1000 | Loss: 0.00003272
Iteration 116/1000 | Loss: 0.00003272
Iteration 117/1000 | Loss: 0.00003272
Iteration 118/1000 | Loss: 0.00003272
Iteration 119/1000 | Loss: 0.00003272
Iteration 120/1000 | Loss: 0.00003272
Iteration 121/1000 | Loss: 0.00003272
Iteration 122/1000 | Loss: 0.00003272
Iteration 123/1000 | Loss: 0.00003272
Iteration 124/1000 | Loss: 0.00003272
Iteration 125/1000 | Loss: 0.00003272
Iteration 126/1000 | Loss: 0.00003272
Iteration 127/1000 | Loss: 0.00003272
Iteration 128/1000 | Loss: 0.00003272
Iteration 129/1000 | Loss: 0.00003272
Iteration 130/1000 | Loss: 0.00003272
Iteration 131/1000 | Loss: 0.00003272
Iteration 132/1000 | Loss: 0.00003272
Iteration 133/1000 | Loss: 0.00003271
Iteration 134/1000 | Loss: 0.00003271
Iteration 135/1000 | Loss: 0.00003271
Iteration 136/1000 | Loss: 0.00003271
Iteration 137/1000 | Loss: 0.00003271
Iteration 138/1000 | Loss: 0.00003271
Iteration 139/1000 | Loss: 0.00003271
Iteration 140/1000 | Loss: 0.00003271
Iteration 141/1000 | Loss: 0.00003271
Iteration 142/1000 | Loss: 0.00003271
Iteration 143/1000 | Loss: 0.00003271
Iteration 144/1000 | Loss: 0.00003271
Iteration 145/1000 | Loss: 0.00003271
Iteration 146/1000 | Loss: 0.00003270
Iteration 147/1000 | Loss: 0.00003270
Iteration 148/1000 | Loss: 0.00003270
Iteration 149/1000 | Loss: 0.00003270
Iteration 150/1000 | Loss: 0.00003270
Iteration 151/1000 | Loss: 0.00003270
Iteration 152/1000 | Loss: 0.00003270
Iteration 153/1000 | Loss: 0.00003270
Iteration 154/1000 | Loss: 0.00003270
Iteration 155/1000 | Loss: 0.00003270
Iteration 156/1000 | Loss: 0.00003270
Iteration 157/1000 | Loss: 0.00003270
Iteration 158/1000 | Loss: 0.00003270
Iteration 159/1000 | Loss: 0.00003270
Iteration 160/1000 | Loss: 0.00003270
Iteration 161/1000 | Loss: 0.00003270
Iteration 162/1000 | Loss: 0.00003270
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [3.269996159360744e-05, 3.269996159360744e-05, 3.269996159360744e-05, 3.269996159360744e-05, 3.269996159360744e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.269996159360744e-05

Optimization complete. Final v2v error: 4.722008228302002 mm

Highest mean error: 5.24891471862793 mm for frame 105

Lowest mean error: 4.191714763641357 mm for frame 65

Saving results

Total time: 32.18570399284363
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00379864
Iteration 2/25 | Loss: 0.00115618
Iteration 3/25 | Loss: 0.00104209
Iteration 4/25 | Loss: 0.00101240
Iteration 5/25 | Loss: 0.00100308
Iteration 6/25 | Loss: 0.00100044
Iteration 7/25 | Loss: 0.00099920
Iteration 8/25 | Loss: 0.00099920
Iteration 9/25 | Loss: 0.00099920
Iteration 10/25 | Loss: 0.00099920
Iteration 11/25 | Loss: 0.00099920
Iteration 12/25 | Loss: 0.00099920
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009992000414058566, 0.0009992000414058566, 0.0009992000414058566, 0.0009992000414058566, 0.0009992000414058566]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009992000414058566

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66086340
Iteration 2/25 | Loss: 0.00255468
Iteration 3/25 | Loss: 0.00255468
Iteration 4/25 | Loss: 0.00255468
Iteration 5/25 | Loss: 0.00255468
Iteration 6/25 | Loss: 0.00255468
Iteration 7/25 | Loss: 0.00255468
Iteration 8/25 | Loss: 0.00255468
Iteration 9/25 | Loss: 0.00255468
Iteration 10/25 | Loss: 0.00255468
Iteration 11/25 | Loss: 0.00255468
Iteration 12/25 | Loss: 0.00255468
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0025546750985085964, 0.0025546750985085964, 0.0025546750985085964, 0.0025546750985085964, 0.0025546750985085964]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0025546750985085964

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00255468
Iteration 2/1000 | Loss: 0.00003931
Iteration 3/1000 | Loss: 0.00002821
Iteration 4/1000 | Loss: 0.00002349
Iteration 5/1000 | Loss: 0.00002133
Iteration 6/1000 | Loss: 0.00002037
Iteration 7/1000 | Loss: 0.00001958
Iteration 8/1000 | Loss: 0.00001911
Iteration 9/1000 | Loss: 0.00001865
Iteration 10/1000 | Loss: 0.00001821
Iteration 11/1000 | Loss: 0.00001807
Iteration 12/1000 | Loss: 0.00001800
Iteration 13/1000 | Loss: 0.00001781
Iteration 14/1000 | Loss: 0.00001762
Iteration 15/1000 | Loss: 0.00001755
Iteration 16/1000 | Loss: 0.00001754
Iteration 17/1000 | Loss: 0.00001753
Iteration 18/1000 | Loss: 0.00001748
Iteration 19/1000 | Loss: 0.00001734
Iteration 20/1000 | Loss: 0.00001733
Iteration 21/1000 | Loss: 0.00001732
Iteration 22/1000 | Loss: 0.00001728
Iteration 23/1000 | Loss: 0.00001725
Iteration 24/1000 | Loss: 0.00001722
Iteration 25/1000 | Loss: 0.00001719
Iteration 26/1000 | Loss: 0.00001714
Iteration 27/1000 | Loss: 0.00001711
Iteration 28/1000 | Loss: 0.00001710
Iteration 29/1000 | Loss: 0.00001710
Iteration 30/1000 | Loss: 0.00001709
Iteration 31/1000 | Loss: 0.00001709
Iteration 32/1000 | Loss: 0.00001708
Iteration 33/1000 | Loss: 0.00001708
Iteration 34/1000 | Loss: 0.00001707
Iteration 35/1000 | Loss: 0.00001706
Iteration 36/1000 | Loss: 0.00001706
Iteration 37/1000 | Loss: 0.00001706
Iteration 38/1000 | Loss: 0.00001705
Iteration 39/1000 | Loss: 0.00001705
Iteration 40/1000 | Loss: 0.00001704
Iteration 41/1000 | Loss: 0.00001704
Iteration 42/1000 | Loss: 0.00001703
Iteration 43/1000 | Loss: 0.00001703
Iteration 44/1000 | Loss: 0.00001702
Iteration 45/1000 | Loss: 0.00001700
Iteration 46/1000 | Loss: 0.00001700
Iteration 47/1000 | Loss: 0.00001699
Iteration 48/1000 | Loss: 0.00001697
Iteration 49/1000 | Loss: 0.00001696
Iteration 50/1000 | Loss: 0.00001696
Iteration 51/1000 | Loss: 0.00001696
Iteration 52/1000 | Loss: 0.00001693
Iteration 53/1000 | Loss: 0.00001693
Iteration 54/1000 | Loss: 0.00001692
Iteration 55/1000 | Loss: 0.00001692
Iteration 56/1000 | Loss: 0.00001691
Iteration 57/1000 | Loss: 0.00001691
Iteration 58/1000 | Loss: 0.00001691
Iteration 59/1000 | Loss: 0.00001690
Iteration 60/1000 | Loss: 0.00001690
Iteration 61/1000 | Loss: 0.00001690
Iteration 62/1000 | Loss: 0.00001689
Iteration 63/1000 | Loss: 0.00001689
Iteration 64/1000 | Loss: 0.00001688
Iteration 65/1000 | Loss: 0.00001688
Iteration 66/1000 | Loss: 0.00001688
Iteration 67/1000 | Loss: 0.00001687
Iteration 68/1000 | Loss: 0.00001687
Iteration 69/1000 | Loss: 0.00001687
Iteration 70/1000 | Loss: 0.00001686
Iteration 71/1000 | Loss: 0.00001686
Iteration 72/1000 | Loss: 0.00001686
Iteration 73/1000 | Loss: 0.00001685
Iteration 74/1000 | Loss: 0.00001685
Iteration 75/1000 | Loss: 0.00001685
Iteration 76/1000 | Loss: 0.00001685
Iteration 77/1000 | Loss: 0.00001685
Iteration 78/1000 | Loss: 0.00001684
Iteration 79/1000 | Loss: 0.00001684
Iteration 80/1000 | Loss: 0.00001684
Iteration 81/1000 | Loss: 0.00001684
Iteration 82/1000 | Loss: 0.00001684
Iteration 83/1000 | Loss: 0.00001684
Iteration 84/1000 | Loss: 0.00001683
Iteration 85/1000 | Loss: 0.00001683
Iteration 86/1000 | Loss: 0.00001683
Iteration 87/1000 | Loss: 0.00001683
Iteration 88/1000 | Loss: 0.00001683
Iteration 89/1000 | Loss: 0.00001683
Iteration 90/1000 | Loss: 0.00001683
Iteration 91/1000 | Loss: 0.00001682
Iteration 92/1000 | Loss: 0.00001682
Iteration 93/1000 | Loss: 0.00001682
Iteration 94/1000 | Loss: 0.00001682
Iteration 95/1000 | Loss: 0.00001682
Iteration 96/1000 | Loss: 0.00001682
Iteration 97/1000 | Loss: 0.00001682
Iteration 98/1000 | Loss: 0.00001682
Iteration 99/1000 | Loss: 0.00001682
Iteration 100/1000 | Loss: 0.00001682
Iteration 101/1000 | Loss: 0.00001682
Iteration 102/1000 | Loss: 0.00001682
Iteration 103/1000 | Loss: 0.00001682
Iteration 104/1000 | Loss: 0.00001682
Iteration 105/1000 | Loss: 0.00001681
Iteration 106/1000 | Loss: 0.00001681
Iteration 107/1000 | Loss: 0.00001681
Iteration 108/1000 | Loss: 0.00001681
Iteration 109/1000 | Loss: 0.00001681
Iteration 110/1000 | Loss: 0.00001680
Iteration 111/1000 | Loss: 0.00001680
Iteration 112/1000 | Loss: 0.00001680
Iteration 113/1000 | Loss: 0.00001680
Iteration 114/1000 | Loss: 0.00001680
Iteration 115/1000 | Loss: 0.00001680
Iteration 116/1000 | Loss: 0.00001680
Iteration 117/1000 | Loss: 0.00001680
Iteration 118/1000 | Loss: 0.00001680
Iteration 119/1000 | Loss: 0.00001680
Iteration 120/1000 | Loss: 0.00001680
Iteration 121/1000 | Loss: 0.00001680
Iteration 122/1000 | Loss: 0.00001680
Iteration 123/1000 | Loss: 0.00001680
Iteration 124/1000 | Loss: 0.00001680
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [1.6802254322101362e-05, 1.6802254322101362e-05, 1.6802254322101362e-05, 1.6802254322101362e-05, 1.6802254322101362e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6802254322101362e-05

Optimization complete. Final v2v error: 3.542017936706543 mm

Highest mean error: 3.9655914306640625 mm for frame 130

Lowest mean error: 2.975165367126465 mm for frame 181

Saving results

Total time: 47.14074516296387
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00576152
Iteration 2/25 | Loss: 0.00129319
Iteration 3/25 | Loss: 0.00103815
Iteration 4/25 | Loss: 0.00099714
Iteration 5/25 | Loss: 0.00098620
Iteration 6/25 | Loss: 0.00098362
Iteration 7/25 | Loss: 0.00098300
Iteration 8/25 | Loss: 0.00098300
Iteration 9/25 | Loss: 0.00098300
Iteration 10/25 | Loss: 0.00098300
Iteration 11/25 | Loss: 0.00098300
Iteration 12/25 | Loss: 0.00098300
Iteration 13/25 | Loss: 0.00098300
Iteration 14/25 | Loss: 0.00098300
Iteration 15/25 | Loss: 0.00098300
Iteration 16/25 | Loss: 0.00098300
Iteration 17/25 | Loss: 0.00098300
Iteration 18/25 | Loss: 0.00098300
Iteration 19/25 | Loss: 0.00098300
Iteration 20/25 | Loss: 0.00098300
Iteration 21/25 | Loss: 0.00098300
Iteration 22/25 | Loss: 0.00098300
Iteration 23/25 | Loss: 0.00098300
Iteration 24/25 | Loss: 0.00098300
Iteration 25/25 | Loss: 0.00098300

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.69015121
Iteration 2/25 | Loss: 0.00167073
Iteration 3/25 | Loss: 0.00167072
Iteration 4/25 | Loss: 0.00167072
Iteration 5/25 | Loss: 0.00167072
Iteration 6/25 | Loss: 0.00167071
Iteration 7/25 | Loss: 0.00167071
Iteration 8/25 | Loss: 0.00167071
Iteration 9/25 | Loss: 0.00167071
Iteration 10/25 | Loss: 0.00167071
Iteration 11/25 | Loss: 0.00167071
Iteration 12/25 | Loss: 0.00167071
Iteration 13/25 | Loss: 0.00167071
Iteration 14/25 | Loss: 0.00167071
Iteration 15/25 | Loss: 0.00167071
Iteration 16/25 | Loss: 0.00167071
Iteration 17/25 | Loss: 0.00167071
Iteration 18/25 | Loss: 0.00167071
Iteration 19/25 | Loss: 0.00167071
Iteration 20/25 | Loss: 0.00167071
Iteration 21/25 | Loss: 0.00167071
Iteration 22/25 | Loss: 0.00167071
Iteration 23/25 | Loss: 0.00167071
Iteration 24/25 | Loss: 0.00167071
Iteration 25/25 | Loss: 0.00167071

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00167071
Iteration 2/1000 | Loss: 0.00003132
Iteration 3/1000 | Loss: 0.00002560
Iteration 4/1000 | Loss: 0.00002313
Iteration 5/1000 | Loss: 0.00002191
Iteration 6/1000 | Loss: 0.00002114
Iteration 7/1000 | Loss: 0.00002053
Iteration 8/1000 | Loss: 0.00002020
Iteration 9/1000 | Loss: 0.00002001
Iteration 10/1000 | Loss: 0.00001987
Iteration 11/1000 | Loss: 0.00001980
Iteration 12/1000 | Loss: 0.00001972
Iteration 13/1000 | Loss: 0.00001968
Iteration 14/1000 | Loss: 0.00001967
Iteration 15/1000 | Loss: 0.00001967
Iteration 16/1000 | Loss: 0.00001966
Iteration 17/1000 | Loss: 0.00001965
Iteration 18/1000 | Loss: 0.00001965
Iteration 19/1000 | Loss: 0.00001965
Iteration 20/1000 | Loss: 0.00001964
Iteration 21/1000 | Loss: 0.00001964
Iteration 22/1000 | Loss: 0.00001964
Iteration 23/1000 | Loss: 0.00001963
Iteration 24/1000 | Loss: 0.00001962
Iteration 25/1000 | Loss: 0.00001962
Iteration 26/1000 | Loss: 0.00001962
Iteration 27/1000 | Loss: 0.00001962
Iteration 28/1000 | Loss: 0.00001962
Iteration 29/1000 | Loss: 0.00001962
Iteration 30/1000 | Loss: 0.00001962
Iteration 31/1000 | Loss: 0.00001962
Iteration 32/1000 | Loss: 0.00001962
Iteration 33/1000 | Loss: 0.00001962
Iteration 34/1000 | Loss: 0.00001961
Iteration 35/1000 | Loss: 0.00001961
Iteration 36/1000 | Loss: 0.00001960
Iteration 37/1000 | Loss: 0.00001960
Iteration 38/1000 | Loss: 0.00001960
Iteration 39/1000 | Loss: 0.00001960
Iteration 40/1000 | Loss: 0.00001959
Iteration 41/1000 | Loss: 0.00001959
Iteration 42/1000 | Loss: 0.00001959
Iteration 43/1000 | Loss: 0.00001959
Iteration 44/1000 | Loss: 0.00001959
Iteration 45/1000 | Loss: 0.00001959
Iteration 46/1000 | Loss: 0.00001959
Iteration 47/1000 | Loss: 0.00001959
Iteration 48/1000 | Loss: 0.00001959
Iteration 49/1000 | Loss: 0.00001959
Iteration 50/1000 | Loss: 0.00001959
Iteration 51/1000 | Loss: 0.00001959
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 51. Stopping optimization.
Last 5 losses: [1.9590721421991475e-05, 1.9590721421991475e-05, 1.9590721421991475e-05, 1.9590721421991475e-05, 1.9590721421991475e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9590721421991475e-05

Optimization complete. Final v2v error: 3.7237303256988525 mm

Highest mean error: 4.260880470275879 mm for frame 133

Lowest mean error: 3.2686142921447754 mm for frame 120

Saving results

Total time: 28.67854619026184
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01118366
Iteration 2/25 | Loss: 0.00176394
Iteration 3/25 | Loss: 0.00130625
Iteration 4/25 | Loss: 0.00110254
Iteration 5/25 | Loss: 0.00112402
Iteration 6/25 | Loss: 0.00108034
Iteration 7/25 | Loss: 0.00103533
Iteration 8/25 | Loss: 0.00102241
Iteration 9/25 | Loss: 0.00102068
Iteration 10/25 | Loss: 0.00101931
Iteration 11/25 | Loss: 0.00102301
Iteration 12/25 | Loss: 0.00103015
Iteration 13/25 | Loss: 0.00102671
Iteration 14/25 | Loss: 0.00101928
Iteration 15/25 | Loss: 0.00101904
Iteration 16/25 | Loss: 0.00101304
Iteration 17/25 | Loss: 0.00101044
Iteration 18/25 | Loss: 0.00100947
Iteration 19/25 | Loss: 0.00100919
Iteration 20/25 | Loss: 0.00100913
Iteration 21/25 | Loss: 0.00100912
Iteration 22/25 | Loss: 0.00100912
Iteration 23/25 | Loss: 0.00100912
Iteration 24/25 | Loss: 0.00100912
Iteration 25/25 | Loss: 0.00100912

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.85093844
Iteration 2/25 | Loss: 0.00201219
Iteration 3/25 | Loss: 0.00201219
Iteration 4/25 | Loss: 0.00201219
Iteration 5/25 | Loss: 0.00201219
Iteration 6/25 | Loss: 0.00201219
Iteration 7/25 | Loss: 0.00201218
Iteration 8/25 | Loss: 0.00201218
Iteration 9/25 | Loss: 0.00201218
Iteration 10/25 | Loss: 0.00201218
Iteration 11/25 | Loss: 0.00201218
Iteration 12/25 | Loss: 0.00201218
Iteration 13/25 | Loss: 0.00201218
Iteration 14/25 | Loss: 0.00201218
Iteration 15/25 | Loss: 0.00201218
Iteration 16/25 | Loss: 0.00201218
Iteration 17/25 | Loss: 0.00201218
Iteration 18/25 | Loss: 0.00201218
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0020121836569160223, 0.0020121836569160223, 0.0020121836569160223, 0.0020121836569160223, 0.0020121836569160223]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020121836569160223

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00201218
Iteration 2/1000 | Loss: 0.00011932
Iteration 3/1000 | Loss: 0.00004422
Iteration 4/1000 | Loss: 0.00003160
Iteration 5/1000 | Loss: 0.00002759
Iteration 6/1000 | Loss: 0.00041539
Iteration 7/1000 | Loss: 0.00005024
Iteration 8/1000 | Loss: 0.00003305
Iteration 9/1000 | Loss: 0.00002379
Iteration 10/1000 | Loss: 0.00024812
Iteration 11/1000 | Loss: 0.00003020
Iteration 12/1000 | Loss: 0.00002364
Iteration 13/1000 | Loss: 0.00044966
Iteration 14/1000 | Loss: 0.00002221
Iteration 15/1000 | Loss: 0.00002156
Iteration 16/1000 | Loss: 0.00002111
Iteration 17/1000 | Loss: 0.00002085
Iteration 18/1000 | Loss: 0.00002058
Iteration 19/1000 | Loss: 0.00002041
Iteration 20/1000 | Loss: 0.00002039
Iteration 21/1000 | Loss: 0.00002033
Iteration 22/1000 | Loss: 0.00002032
Iteration 23/1000 | Loss: 0.00002032
Iteration 24/1000 | Loss: 0.00002029
Iteration 25/1000 | Loss: 0.00002028
Iteration 26/1000 | Loss: 0.00002028
Iteration 27/1000 | Loss: 0.00002027
Iteration 28/1000 | Loss: 0.00002027
Iteration 29/1000 | Loss: 0.00002026
Iteration 30/1000 | Loss: 0.00002025
Iteration 31/1000 | Loss: 0.00002025
Iteration 32/1000 | Loss: 0.00002025
Iteration 33/1000 | Loss: 0.00002025
Iteration 34/1000 | Loss: 0.00002024
Iteration 35/1000 | Loss: 0.00002023
Iteration 36/1000 | Loss: 0.00002022
Iteration 37/1000 | Loss: 0.00002021
Iteration 38/1000 | Loss: 0.00002021
Iteration 39/1000 | Loss: 0.00002021
Iteration 40/1000 | Loss: 0.00002020
Iteration 41/1000 | Loss: 0.00002020
Iteration 42/1000 | Loss: 0.00002019
Iteration 43/1000 | Loss: 0.00002019
Iteration 44/1000 | Loss: 0.00002018
Iteration 45/1000 | Loss: 0.00002018
Iteration 46/1000 | Loss: 0.00002018
Iteration 47/1000 | Loss: 0.00002018
Iteration 48/1000 | Loss: 0.00002018
Iteration 49/1000 | Loss: 0.00002017
Iteration 50/1000 | Loss: 0.00002017
Iteration 51/1000 | Loss: 0.00002017
Iteration 52/1000 | Loss: 0.00002017
Iteration 53/1000 | Loss: 0.00002017
Iteration 54/1000 | Loss: 0.00002017
Iteration 55/1000 | Loss: 0.00002017
Iteration 56/1000 | Loss: 0.00002016
Iteration 57/1000 | Loss: 0.00002016
Iteration 58/1000 | Loss: 0.00002016
Iteration 59/1000 | Loss: 0.00002016
Iteration 60/1000 | Loss: 0.00002016
Iteration 61/1000 | Loss: 0.00002016
Iteration 62/1000 | Loss: 0.00002016
Iteration 63/1000 | Loss: 0.00002015
Iteration 64/1000 | Loss: 0.00002015
Iteration 65/1000 | Loss: 0.00002015
Iteration 66/1000 | Loss: 0.00002015
Iteration 67/1000 | Loss: 0.00002015
Iteration 68/1000 | Loss: 0.00002015
Iteration 69/1000 | Loss: 0.00002015
Iteration 70/1000 | Loss: 0.00002014
Iteration 71/1000 | Loss: 0.00002014
Iteration 72/1000 | Loss: 0.00002014
Iteration 73/1000 | Loss: 0.00002014
Iteration 74/1000 | Loss: 0.00002013
Iteration 75/1000 | Loss: 0.00002013
Iteration 76/1000 | Loss: 0.00002013
Iteration 77/1000 | Loss: 0.00002013
Iteration 78/1000 | Loss: 0.00002013
Iteration 79/1000 | Loss: 0.00002013
Iteration 80/1000 | Loss: 0.00002012
Iteration 81/1000 | Loss: 0.00002012
Iteration 82/1000 | Loss: 0.00002012
Iteration 83/1000 | Loss: 0.00002012
Iteration 84/1000 | Loss: 0.00002012
Iteration 85/1000 | Loss: 0.00002011
Iteration 86/1000 | Loss: 0.00002011
Iteration 87/1000 | Loss: 0.00002011
Iteration 88/1000 | Loss: 0.00002011
Iteration 89/1000 | Loss: 0.00002011
Iteration 90/1000 | Loss: 0.00002011
Iteration 91/1000 | Loss: 0.00002011
Iteration 92/1000 | Loss: 0.00002011
Iteration 93/1000 | Loss: 0.00002011
Iteration 94/1000 | Loss: 0.00002011
Iteration 95/1000 | Loss: 0.00002011
Iteration 96/1000 | Loss: 0.00002010
Iteration 97/1000 | Loss: 0.00002010
Iteration 98/1000 | Loss: 0.00002010
Iteration 99/1000 | Loss: 0.00002010
Iteration 100/1000 | Loss: 0.00002010
Iteration 101/1000 | Loss: 0.00002010
Iteration 102/1000 | Loss: 0.00002010
Iteration 103/1000 | Loss: 0.00002010
Iteration 104/1000 | Loss: 0.00002010
Iteration 105/1000 | Loss: 0.00002010
Iteration 106/1000 | Loss: 0.00002009
Iteration 107/1000 | Loss: 0.00002009
Iteration 108/1000 | Loss: 0.00002009
Iteration 109/1000 | Loss: 0.00002009
Iteration 110/1000 | Loss: 0.00002009
Iteration 111/1000 | Loss: 0.00002009
Iteration 112/1000 | Loss: 0.00002009
Iteration 113/1000 | Loss: 0.00002009
Iteration 114/1000 | Loss: 0.00002009
Iteration 115/1000 | Loss: 0.00002008
Iteration 116/1000 | Loss: 0.00002008
Iteration 117/1000 | Loss: 0.00002008
Iteration 118/1000 | Loss: 0.00002008
Iteration 119/1000 | Loss: 0.00002008
Iteration 120/1000 | Loss: 0.00002008
Iteration 121/1000 | Loss: 0.00002008
Iteration 122/1000 | Loss: 0.00002008
Iteration 123/1000 | Loss: 0.00002007
Iteration 124/1000 | Loss: 0.00002007
Iteration 125/1000 | Loss: 0.00002007
Iteration 126/1000 | Loss: 0.00002007
Iteration 127/1000 | Loss: 0.00002007
Iteration 128/1000 | Loss: 0.00002007
Iteration 129/1000 | Loss: 0.00002007
Iteration 130/1000 | Loss: 0.00002007
Iteration 131/1000 | Loss: 0.00002007
Iteration 132/1000 | Loss: 0.00002007
Iteration 133/1000 | Loss: 0.00002007
Iteration 134/1000 | Loss: 0.00002007
Iteration 135/1000 | Loss: 0.00002007
Iteration 136/1000 | Loss: 0.00002007
Iteration 137/1000 | Loss: 0.00002007
Iteration 138/1000 | Loss: 0.00002007
Iteration 139/1000 | Loss: 0.00002007
Iteration 140/1000 | Loss: 0.00002007
Iteration 141/1000 | Loss: 0.00002007
Iteration 142/1000 | Loss: 0.00002007
Iteration 143/1000 | Loss: 0.00002007
Iteration 144/1000 | Loss: 0.00002007
Iteration 145/1000 | Loss: 0.00002007
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [2.0065437638550065e-05, 2.0065437638550065e-05, 2.0065437638550065e-05, 2.0065437638550065e-05, 2.0065437638550065e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0065437638550065e-05

Optimization complete. Final v2v error: 3.8237977027893066 mm

Highest mean error: 6.066155433654785 mm for frame 125

Lowest mean error: 3.389087677001953 mm for frame 1

Saving results

Total time: 70.28776931762695
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00643827
Iteration 2/25 | Loss: 0.00144340
Iteration 3/25 | Loss: 0.00116705
Iteration 4/25 | Loss: 0.00114521
Iteration 5/25 | Loss: 0.00114213
Iteration 6/25 | Loss: 0.00114164
Iteration 7/25 | Loss: 0.00114164
Iteration 8/25 | Loss: 0.00114164
Iteration 9/25 | Loss: 0.00114164
Iteration 10/25 | Loss: 0.00114164
Iteration 11/25 | Loss: 0.00114164
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0011416373308748007, 0.0011416373308748007, 0.0011416373308748007, 0.0011416373308748007, 0.0011416373308748007]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011416373308748007

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.21978033
Iteration 2/25 | Loss: 0.00178350
Iteration 3/25 | Loss: 0.00178350
Iteration 4/25 | Loss: 0.00178350
Iteration 5/25 | Loss: 0.00178350
Iteration 6/25 | Loss: 0.00178350
Iteration 7/25 | Loss: 0.00178350
Iteration 8/25 | Loss: 0.00178350
Iteration 9/25 | Loss: 0.00178350
Iteration 10/25 | Loss: 0.00178350
Iteration 11/25 | Loss: 0.00178350
Iteration 12/25 | Loss: 0.00178350
Iteration 13/25 | Loss: 0.00178350
Iteration 14/25 | Loss: 0.00178350
Iteration 15/25 | Loss: 0.00178350
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0017834968166425824, 0.0017834968166425824, 0.0017834968166425824, 0.0017834968166425824, 0.0017834968166425824]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017834968166425824

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00178350
Iteration 2/1000 | Loss: 0.00005071
Iteration 3/1000 | Loss: 0.00003801
Iteration 4/1000 | Loss: 0.00003432
Iteration 5/1000 | Loss: 0.00003238
Iteration 6/1000 | Loss: 0.00003138
Iteration 7/1000 | Loss: 0.00003065
Iteration 8/1000 | Loss: 0.00003017
Iteration 9/1000 | Loss: 0.00003002
Iteration 10/1000 | Loss: 0.00003002
Iteration 11/1000 | Loss: 0.00002978
Iteration 12/1000 | Loss: 0.00002970
Iteration 13/1000 | Loss: 0.00002967
Iteration 14/1000 | Loss: 0.00002966
Iteration 15/1000 | Loss: 0.00002966
Iteration 16/1000 | Loss: 0.00002965
Iteration 17/1000 | Loss: 0.00002956
Iteration 18/1000 | Loss: 0.00002956
Iteration 19/1000 | Loss: 0.00002956
Iteration 20/1000 | Loss: 0.00002956
Iteration 21/1000 | Loss: 0.00002956
Iteration 22/1000 | Loss: 0.00002956
Iteration 23/1000 | Loss: 0.00002956
Iteration 24/1000 | Loss: 0.00002955
Iteration 25/1000 | Loss: 0.00002955
Iteration 26/1000 | Loss: 0.00002948
Iteration 27/1000 | Loss: 0.00002948
Iteration 28/1000 | Loss: 0.00002948
Iteration 29/1000 | Loss: 0.00002947
Iteration 30/1000 | Loss: 0.00002947
Iteration 31/1000 | Loss: 0.00002947
Iteration 32/1000 | Loss: 0.00002947
Iteration 33/1000 | Loss: 0.00002947
Iteration 34/1000 | Loss: 0.00002947
Iteration 35/1000 | Loss: 0.00002947
Iteration 36/1000 | Loss: 0.00002947
Iteration 37/1000 | Loss: 0.00002947
Iteration 38/1000 | Loss: 0.00002947
Iteration 39/1000 | Loss: 0.00002947
Iteration 40/1000 | Loss: 0.00002947
Iteration 41/1000 | Loss: 0.00002947
Iteration 42/1000 | Loss: 0.00002947
Iteration 43/1000 | Loss: 0.00002946
Iteration 44/1000 | Loss: 0.00002945
Iteration 45/1000 | Loss: 0.00002945
Iteration 46/1000 | Loss: 0.00002945
Iteration 47/1000 | Loss: 0.00002945
Iteration 48/1000 | Loss: 0.00002944
Iteration 49/1000 | Loss: 0.00002944
Iteration 50/1000 | Loss: 0.00002943
Iteration 51/1000 | Loss: 0.00002943
Iteration 52/1000 | Loss: 0.00002943
Iteration 53/1000 | Loss: 0.00002942
Iteration 54/1000 | Loss: 0.00002942
Iteration 55/1000 | Loss: 0.00002941
Iteration 56/1000 | Loss: 0.00002941
Iteration 57/1000 | Loss: 0.00002941
Iteration 58/1000 | Loss: 0.00002941
Iteration 59/1000 | Loss: 0.00002941
Iteration 60/1000 | Loss: 0.00002941
Iteration 61/1000 | Loss: 0.00002941
Iteration 62/1000 | Loss: 0.00002941
Iteration 63/1000 | Loss: 0.00002941
Iteration 64/1000 | Loss: 0.00002941
Iteration 65/1000 | Loss: 0.00002940
Iteration 66/1000 | Loss: 0.00002940
Iteration 67/1000 | Loss: 0.00002940
Iteration 68/1000 | Loss: 0.00002940
Iteration 69/1000 | Loss: 0.00002940
Iteration 70/1000 | Loss: 0.00002940
Iteration 71/1000 | Loss: 0.00002940
Iteration 72/1000 | Loss: 0.00002940
Iteration 73/1000 | Loss: 0.00002940
Iteration 74/1000 | Loss: 0.00002940
Iteration 75/1000 | Loss: 0.00002940
Iteration 76/1000 | Loss: 0.00002940
Iteration 77/1000 | Loss: 0.00002940
Iteration 78/1000 | Loss: 0.00002939
Iteration 79/1000 | Loss: 0.00002939
Iteration 80/1000 | Loss: 0.00002939
Iteration 81/1000 | Loss: 0.00002939
Iteration 82/1000 | Loss: 0.00002939
Iteration 83/1000 | Loss: 0.00002939
Iteration 84/1000 | Loss: 0.00002939
Iteration 85/1000 | Loss: 0.00002939
Iteration 86/1000 | Loss: 0.00002939
Iteration 87/1000 | Loss: 0.00002939
Iteration 88/1000 | Loss: 0.00002939
Iteration 89/1000 | Loss: 0.00002939
Iteration 90/1000 | Loss: 0.00002939
Iteration 91/1000 | Loss: 0.00002939
Iteration 92/1000 | Loss: 0.00002939
Iteration 93/1000 | Loss: 0.00002939
Iteration 94/1000 | Loss: 0.00002939
Iteration 95/1000 | Loss: 0.00002939
Iteration 96/1000 | Loss: 0.00002939
Iteration 97/1000 | Loss: 0.00002939
Iteration 98/1000 | Loss: 0.00002939
Iteration 99/1000 | Loss: 0.00002939
Iteration 100/1000 | Loss: 0.00002939
Iteration 101/1000 | Loss: 0.00002939
Iteration 102/1000 | Loss: 0.00002939
Iteration 103/1000 | Loss: 0.00002939
Iteration 104/1000 | Loss: 0.00002939
Iteration 105/1000 | Loss: 0.00002939
Iteration 106/1000 | Loss: 0.00002939
Iteration 107/1000 | Loss: 0.00002939
Iteration 108/1000 | Loss: 0.00002939
Iteration 109/1000 | Loss: 0.00002939
Iteration 110/1000 | Loss: 0.00002939
Iteration 111/1000 | Loss: 0.00002939
Iteration 112/1000 | Loss: 0.00002939
Iteration 113/1000 | Loss: 0.00002939
Iteration 114/1000 | Loss: 0.00002939
Iteration 115/1000 | Loss: 0.00002939
Iteration 116/1000 | Loss: 0.00002939
Iteration 117/1000 | Loss: 0.00002939
Iteration 118/1000 | Loss: 0.00002939
Iteration 119/1000 | Loss: 0.00002939
Iteration 120/1000 | Loss: 0.00002939
Iteration 121/1000 | Loss: 0.00002939
Iteration 122/1000 | Loss: 0.00002939
Iteration 123/1000 | Loss: 0.00002939
Iteration 124/1000 | Loss: 0.00002939
Iteration 125/1000 | Loss: 0.00002939
Iteration 126/1000 | Loss: 0.00002939
Iteration 127/1000 | Loss: 0.00002939
Iteration 128/1000 | Loss: 0.00002939
Iteration 129/1000 | Loss: 0.00002939
Iteration 130/1000 | Loss: 0.00002939
Iteration 131/1000 | Loss: 0.00002939
Iteration 132/1000 | Loss: 0.00002939
Iteration 133/1000 | Loss: 0.00002939
Iteration 134/1000 | Loss: 0.00002939
Iteration 135/1000 | Loss: 0.00002939
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [2.9391992939054035e-05, 2.9391992939054035e-05, 2.9391992939054035e-05, 2.9391992939054035e-05, 2.9391992939054035e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9391992939054035e-05

Optimization complete. Final v2v error: 4.559694766998291 mm

Highest mean error: 4.650340557098389 mm for frame 42

Lowest mean error: 4.477486610412598 mm for frame 98

Saving results

Total time: 34.04234957695007
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01087895
Iteration 2/25 | Loss: 0.00311367
Iteration 3/25 | Loss: 0.00211934
Iteration 4/25 | Loss: 0.00219560
Iteration 5/25 | Loss: 0.00197204
Iteration 6/25 | Loss: 0.00188227
Iteration 7/25 | Loss: 0.00183200
Iteration 8/25 | Loss: 0.00175595
Iteration 9/25 | Loss: 0.00171772
Iteration 10/25 | Loss: 0.00171782
Iteration 11/25 | Loss: 0.00163506
Iteration 12/25 | Loss: 0.00163649
Iteration 13/25 | Loss: 0.00156136
Iteration 14/25 | Loss: 0.00154305
Iteration 15/25 | Loss: 0.00151345
Iteration 16/25 | Loss: 0.00149151
Iteration 17/25 | Loss: 0.00146596
Iteration 18/25 | Loss: 0.00145229
Iteration 19/25 | Loss: 0.00145096
Iteration 20/25 | Loss: 0.00144602
Iteration 21/25 | Loss: 0.00142933
Iteration 22/25 | Loss: 0.00142622
Iteration 23/25 | Loss: 0.00143409
Iteration 24/25 | Loss: 0.00142622
Iteration 25/25 | Loss: 0.00142786

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65408587
Iteration 2/25 | Loss: 0.00880265
Iteration 3/25 | Loss: 0.00639324
Iteration 4/25 | Loss: 0.00631404
Iteration 5/25 | Loss: 0.00631404
Iteration 6/25 | Loss: 0.00631404
Iteration 7/25 | Loss: 0.00631404
Iteration 8/25 | Loss: 0.00631404
Iteration 9/25 | Loss: 0.00631404
Iteration 10/25 | Loss: 0.00631404
Iteration 11/25 | Loss: 0.00631404
Iteration 12/25 | Loss: 0.00631404
Iteration 13/25 | Loss: 0.00631404
Iteration 14/25 | Loss: 0.00631404
Iteration 15/25 | Loss: 0.00631404
Iteration 16/25 | Loss: 0.00631404
Iteration 17/25 | Loss: 0.00631404
Iteration 18/25 | Loss: 0.00631404
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.006314035039395094, 0.006314035039395094, 0.006314035039395094, 0.006314035039395094, 0.006314035039395094]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006314035039395094

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00631404
Iteration 2/1000 | Loss: 0.00411910
Iteration 3/1000 | Loss: 0.01202535
Iteration 4/1000 | Loss: 0.00286783
Iteration 5/1000 | Loss: 0.00421570
Iteration 6/1000 | Loss: 0.00487162
Iteration 7/1000 | Loss: 0.00294018
Iteration 8/1000 | Loss: 0.00679812
Iteration 9/1000 | Loss: 0.00383815
Iteration 10/1000 | Loss: 0.00559070
Iteration 11/1000 | Loss: 0.00788216
Iteration 12/1000 | Loss: 0.00590529
Iteration 13/1000 | Loss: 0.00765958
Iteration 14/1000 | Loss: 0.00568242
Iteration 15/1000 | Loss: 0.00434477
Iteration 16/1000 | Loss: 0.00357932
Iteration 17/1000 | Loss: 0.00354638
Iteration 18/1000 | Loss: 0.00292871
Iteration 19/1000 | Loss: 0.00520686
Iteration 20/1000 | Loss: 0.00097849
Iteration 21/1000 | Loss: 0.00107816
Iteration 22/1000 | Loss: 0.00063869
Iteration 23/1000 | Loss: 0.00137472
Iteration 24/1000 | Loss: 0.00253450
Iteration 25/1000 | Loss: 0.00064037
Iteration 26/1000 | Loss: 0.00197198
Iteration 27/1000 | Loss: 0.00234548
Iteration 28/1000 | Loss: 0.00264049
Iteration 29/1000 | Loss: 0.00357752
Iteration 30/1000 | Loss: 0.00246193
Iteration 31/1000 | Loss: 0.00079245
Iteration 32/1000 | Loss: 0.00072913
Iteration 33/1000 | Loss: 0.00078447
Iteration 34/1000 | Loss: 0.00056004
Iteration 35/1000 | Loss: 0.00144890
Iteration 36/1000 | Loss: 0.00034101
Iteration 37/1000 | Loss: 0.00105247
Iteration 38/1000 | Loss: 0.00073139
Iteration 39/1000 | Loss: 0.00059429
Iteration 40/1000 | Loss: 0.00307827
Iteration 41/1000 | Loss: 0.00041380
Iteration 42/1000 | Loss: 0.00138484
Iteration 43/1000 | Loss: 0.00042805
Iteration 44/1000 | Loss: 0.00168996
Iteration 45/1000 | Loss: 0.00411396
Iteration 46/1000 | Loss: 0.00295455
Iteration 47/1000 | Loss: 0.00167215
Iteration 48/1000 | Loss: 0.00367354
Iteration 49/1000 | Loss: 0.00284300
Iteration 50/1000 | Loss: 0.00199963
Iteration 51/1000 | Loss: 0.00396494
Iteration 52/1000 | Loss: 0.00086384
Iteration 53/1000 | Loss: 0.00112059
Iteration 54/1000 | Loss: 0.00058689
Iteration 55/1000 | Loss: 0.00061403
Iteration 56/1000 | Loss: 0.00083551
Iteration 57/1000 | Loss: 0.00109654
Iteration 58/1000 | Loss: 0.00099210
Iteration 59/1000 | Loss: 0.00075552
Iteration 60/1000 | Loss: 0.00074473
Iteration 61/1000 | Loss: 0.00023201
Iteration 62/1000 | Loss: 0.00117049
Iteration 63/1000 | Loss: 0.00054376
Iteration 64/1000 | Loss: 0.00037521
Iteration 65/1000 | Loss: 0.00070317
Iteration 66/1000 | Loss: 0.00033846
Iteration 67/1000 | Loss: 0.00126345
Iteration 68/1000 | Loss: 0.00024110
Iteration 69/1000 | Loss: 0.00038337
Iteration 70/1000 | Loss: 0.00023968
Iteration 71/1000 | Loss: 0.00123063
Iteration 72/1000 | Loss: 0.00071049
Iteration 73/1000 | Loss: 0.00093762
Iteration 74/1000 | Loss: 0.00096845
Iteration 75/1000 | Loss: 0.00112173
Iteration 76/1000 | Loss: 0.00051792
Iteration 77/1000 | Loss: 0.00085207
Iteration 78/1000 | Loss: 0.00083489
Iteration 79/1000 | Loss: 0.00010517
Iteration 80/1000 | Loss: 0.00046690
Iteration 81/1000 | Loss: 0.00015387
Iteration 82/1000 | Loss: 0.00035660
Iteration 83/1000 | Loss: 0.00053209
Iteration 84/1000 | Loss: 0.00040741
Iteration 85/1000 | Loss: 0.00025017
Iteration 86/1000 | Loss: 0.00008272
Iteration 87/1000 | Loss: 0.00013787
Iteration 88/1000 | Loss: 0.00006569
Iteration 89/1000 | Loss: 0.00025643
Iteration 90/1000 | Loss: 0.00021640
Iteration 91/1000 | Loss: 0.00026479
Iteration 92/1000 | Loss: 0.00007717
Iteration 93/1000 | Loss: 0.00012264
Iteration 94/1000 | Loss: 0.00029004
Iteration 95/1000 | Loss: 0.00041582
Iteration 96/1000 | Loss: 0.00044159
Iteration 97/1000 | Loss: 0.00094072
Iteration 98/1000 | Loss: 0.00053025
Iteration 99/1000 | Loss: 0.00045239
Iteration 100/1000 | Loss: 0.00194259
Iteration 101/1000 | Loss: 0.00094651
Iteration 102/1000 | Loss: 0.00071960
Iteration 103/1000 | Loss: 0.00048459
Iteration 104/1000 | Loss: 0.00062308
Iteration 105/1000 | Loss: 0.00012014
Iteration 106/1000 | Loss: 0.00016863
Iteration 107/1000 | Loss: 0.00013324
Iteration 108/1000 | Loss: 0.00006448
Iteration 109/1000 | Loss: 0.00027858
Iteration 110/1000 | Loss: 0.00015193
Iteration 111/1000 | Loss: 0.00004522
Iteration 112/1000 | Loss: 0.00009262
Iteration 113/1000 | Loss: 0.00005044
Iteration 114/1000 | Loss: 0.00026973
Iteration 115/1000 | Loss: 0.00005056
Iteration 116/1000 | Loss: 0.00007127
Iteration 117/1000 | Loss: 0.00003991
Iteration 118/1000 | Loss: 0.00022573
Iteration 119/1000 | Loss: 0.00007630
Iteration 120/1000 | Loss: 0.00013773
Iteration 121/1000 | Loss: 0.00005272
Iteration 122/1000 | Loss: 0.00027338
Iteration 123/1000 | Loss: 0.00063192
Iteration 124/1000 | Loss: 0.00041731
Iteration 125/1000 | Loss: 0.00051152
Iteration 126/1000 | Loss: 0.00070512
Iteration 127/1000 | Loss: 0.00016367
Iteration 128/1000 | Loss: 0.00024069
Iteration 129/1000 | Loss: 0.00007792
Iteration 130/1000 | Loss: 0.00036674
Iteration 131/1000 | Loss: 0.00023923
Iteration 132/1000 | Loss: 0.00006003
Iteration 133/1000 | Loss: 0.00017566
Iteration 134/1000 | Loss: 0.00017660
Iteration 135/1000 | Loss: 0.00038366
Iteration 136/1000 | Loss: 0.00038551
Iteration 137/1000 | Loss: 0.00004118
Iteration 138/1000 | Loss: 0.00003089
Iteration 139/1000 | Loss: 0.00007742
Iteration 140/1000 | Loss: 0.00019285
Iteration 141/1000 | Loss: 0.00004245
Iteration 142/1000 | Loss: 0.00018263
Iteration 143/1000 | Loss: 0.00014114
Iteration 144/1000 | Loss: 0.00017176
Iteration 145/1000 | Loss: 0.00014136
Iteration 146/1000 | Loss: 0.00006640
Iteration 147/1000 | Loss: 0.00012200
Iteration 148/1000 | Loss: 0.00029103
Iteration 149/1000 | Loss: 0.00067675
Iteration 150/1000 | Loss: 0.00094343
Iteration 151/1000 | Loss: 0.00071045
Iteration 152/1000 | Loss: 0.00021225
Iteration 153/1000 | Loss: 0.00047493
Iteration 154/1000 | Loss: 0.00040893
Iteration 155/1000 | Loss: 0.00047839
Iteration 156/1000 | Loss: 0.00038660
Iteration 157/1000 | Loss: 0.00011065
Iteration 158/1000 | Loss: 0.00005633
Iteration 159/1000 | Loss: 0.00004281
Iteration 160/1000 | Loss: 0.00003907
Iteration 161/1000 | Loss: 0.00004171
Iteration 162/1000 | Loss: 0.00007763
Iteration 163/1000 | Loss: 0.00054711
Iteration 164/1000 | Loss: 0.00048935
Iteration 165/1000 | Loss: 0.00030024
Iteration 166/1000 | Loss: 0.00030297
Iteration 167/1000 | Loss: 0.00018898
Iteration 168/1000 | Loss: 0.00013754
Iteration 169/1000 | Loss: 0.00016101
Iteration 170/1000 | Loss: 0.00016828
Iteration 171/1000 | Loss: 0.00017089
Iteration 172/1000 | Loss: 0.00015222
Iteration 173/1000 | Loss: 0.00016328
Iteration 174/1000 | Loss: 0.00016990
Iteration 175/1000 | Loss: 0.00033215
Iteration 176/1000 | Loss: 0.00011116
Iteration 177/1000 | Loss: 0.00010070
Iteration 178/1000 | Loss: 0.00006704
Iteration 179/1000 | Loss: 0.00018580
Iteration 180/1000 | Loss: 0.00012496
Iteration 181/1000 | Loss: 0.00005168
Iteration 182/1000 | Loss: 0.00004524
Iteration 183/1000 | Loss: 0.00011681
Iteration 184/1000 | Loss: 0.00005438
Iteration 185/1000 | Loss: 0.00011852
Iteration 186/1000 | Loss: 0.00006480
Iteration 187/1000 | Loss: 0.00006697
Iteration 188/1000 | Loss: 0.00004468
Iteration 189/1000 | Loss: 0.00003935
Iteration 190/1000 | Loss: 0.00010597
Iteration 191/1000 | Loss: 0.00013003
Iteration 192/1000 | Loss: 0.00006763
Iteration 193/1000 | Loss: 0.00005274
Iteration 194/1000 | Loss: 0.00023636
Iteration 195/1000 | Loss: 0.00005480
Iteration 196/1000 | Loss: 0.00011644
Iteration 197/1000 | Loss: 0.00003250
Iteration 198/1000 | Loss: 0.00009236
Iteration 199/1000 | Loss: 0.00006259
Iteration 200/1000 | Loss: 0.00003139
Iteration 201/1000 | Loss: 0.00010742
Iteration 202/1000 | Loss: 0.00002378
Iteration 203/1000 | Loss: 0.00004557
Iteration 204/1000 | Loss: 0.00002135
Iteration 205/1000 | Loss: 0.00008622
Iteration 206/1000 | Loss: 0.00002644
Iteration 207/1000 | Loss: 0.00003699
Iteration 208/1000 | Loss: 0.00010731
Iteration 209/1000 | Loss: 0.00010729
Iteration 210/1000 | Loss: 0.00013580
Iteration 211/1000 | Loss: 0.00007583
Iteration 212/1000 | Loss: 0.00001954
Iteration 213/1000 | Loss: 0.00004322
Iteration 214/1000 | Loss: 0.00001940
Iteration 215/1000 | Loss: 0.00001923
Iteration 216/1000 | Loss: 0.00001918
Iteration 217/1000 | Loss: 0.00001918
Iteration 218/1000 | Loss: 0.00001918
Iteration 219/1000 | Loss: 0.00001917
Iteration 220/1000 | Loss: 0.00001917
Iteration 221/1000 | Loss: 0.00001917
Iteration 222/1000 | Loss: 0.00001917
Iteration 223/1000 | Loss: 0.00001917
Iteration 224/1000 | Loss: 0.00001917
Iteration 225/1000 | Loss: 0.00001917
Iteration 226/1000 | Loss: 0.00001917
Iteration 227/1000 | Loss: 0.00001917
Iteration 228/1000 | Loss: 0.00001917
Iteration 229/1000 | Loss: 0.00001915
Iteration 230/1000 | Loss: 0.00001915
Iteration 231/1000 | Loss: 0.00001915
Iteration 232/1000 | Loss: 0.00001914
Iteration 233/1000 | Loss: 0.00001908
Iteration 234/1000 | Loss: 0.00001903
Iteration 235/1000 | Loss: 0.00001903
Iteration 236/1000 | Loss: 0.00001902
Iteration 237/1000 | Loss: 0.00001902
Iteration 238/1000 | Loss: 0.00001902
Iteration 239/1000 | Loss: 0.00001900
Iteration 240/1000 | Loss: 0.00001899
Iteration 241/1000 | Loss: 0.00001899
Iteration 242/1000 | Loss: 0.00001899
Iteration 243/1000 | Loss: 0.00001899
Iteration 244/1000 | Loss: 0.00001899
Iteration 245/1000 | Loss: 0.00001899
Iteration 246/1000 | Loss: 0.00001899
Iteration 247/1000 | Loss: 0.00001899
Iteration 248/1000 | Loss: 0.00001899
Iteration 249/1000 | Loss: 0.00001899
Iteration 250/1000 | Loss: 0.00001898
Iteration 251/1000 | Loss: 0.00001898
Iteration 252/1000 | Loss: 0.00001897
Iteration 253/1000 | Loss: 0.00001896
Iteration 254/1000 | Loss: 0.00001895
Iteration 255/1000 | Loss: 0.00001894
Iteration 256/1000 | Loss: 0.00001894
Iteration 257/1000 | Loss: 0.00001894
Iteration 258/1000 | Loss: 0.00001894
Iteration 259/1000 | Loss: 0.00001894
Iteration 260/1000 | Loss: 0.00001894
Iteration 261/1000 | Loss: 0.00001893
Iteration 262/1000 | Loss: 0.00001893
Iteration 263/1000 | Loss: 0.00001893
Iteration 264/1000 | Loss: 0.00001891
Iteration 265/1000 | Loss: 0.00001891
Iteration 266/1000 | Loss: 0.00001891
Iteration 267/1000 | Loss: 0.00001891
Iteration 268/1000 | Loss: 0.00001891
Iteration 269/1000 | Loss: 0.00001891
Iteration 270/1000 | Loss: 0.00001891
Iteration 271/1000 | Loss: 0.00001891
Iteration 272/1000 | Loss: 0.00001891
Iteration 273/1000 | Loss: 0.00001891
Iteration 274/1000 | Loss: 0.00001891
Iteration 275/1000 | Loss: 0.00001891
Iteration 276/1000 | Loss: 0.00001891
Iteration 277/1000 | Loss: 0.00001891
Iteration 278/1000 | Loss: 0.00001891
Iteration 279/1000 | Loss: 0.00001891
Iteration 280/1000 | Loss: 0.00001891
Iteration 281/1000 | Loss: 0.00001891
Iteration 282/1000 | Loss: 0.00001891
Iteration 283/1000 | Loss: 0.00001891
Iteration 284/1000 | Loss: 0.00001891
Iteration 285/1000 | Loss: 0.00001891
Iteration 286/1000 | Loss: 0.00001891
Iteration 287/1000 | Loss: 0.00001891
Iteration 288/1000 | Loss: 0.00001891
Iteration 289/1000 | Loss: 0.00001891
Iteration 290/1000 | Loss: 0.00001891
Iteration 291/1000 | Loss: 0.00001891
Iteration 292/1000 | Loss: 0.00001891
Iteration 293/1000 | Loss: 0.00001891
Iteration 294/1000 | Loss: 0.00001891
Iteration 295/1000 | Loss: 0.00001891
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 295. Stopping optimization.
Last 5 losses: [1.8905473552877083e-05, 1.8905473552877083e-05, 1.8905473552877083e-05, 1.8905473552877083e-05, 1.8905473552877083e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8905473552877083e-05

Optimization complete. Final v2v error: 3.508805751800537 mm

Highest mean error: 13.121447563171387 mm for frame 118

Lowest mean error: 2.929018497467041 mm for frame 222

Saving results

Total time: 396.92577600479126
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00877646
Iteration 2/25 | Loss: 0.00115632
Iteration 3/25 | Loss: 0.00103913
Iteration 4/25 | Loss: 0.00101562
Iteration 5/25 | Loss: 0.00100858
Iteration 6/25 | Loss: 0.00100677
Iteration 7/25 | Loss: 0.00100631
Iteration 8/25 | Loss: 0.00100631
Iteration 9/25 | Loss: 0.00100631
Iteration 10/25 | Loss: 0.00100631
Iteration 11/25 | Loss: 0.00100631
Iteration 12/25 | Loss: 0.00100631
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010063108056783676, 0.0010063108056783676, 0.0010063108056783676, 0.0010063108056783676, 0.0010063108056783676]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010063108056783676

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67343819
Iteration 2/25 | Loss: 0.00176826
Iteration 3/25 | Loss: 0.00176826
Iteration 4/25 | Loss: 0.00176826
Iteration 5/25 | Loss: 0.00176826
Iteration 6/25 | Loss: 0.00176826
Iteration 7/25 | Loss: 0.00176826
Iteration 8/25 | Loss: 0.00176826
Iteration 9/25 | Loss: 0.00176826
Iteration 10/25 | Loss: 0.00176826
Iteration 11/25 | Loss: 0.00176826
Iteration 12/25 | Loss: 0.00176826
Iteration 13/25 | Loss: 0.00176826
Iteration 14/25 | Loss: 0.00176826
Iteration 15/25 | Loss: 0.00176826
Iteration 16/25 | Loss: 0.00176826
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0017682587495073676, 0.0017682587495073676, 0.0017682587495073676, 0.0017682587495073676, 0.0017682587495073676]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017682587495073676

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00176826
Iteration 2/1000 | Loss: 0.00003604
Iteration 3/1000 | Loss: 0.00002830
Iteration 4/1000 | Loss: 0.00002677
Iteration 5/1000 | Loss: 0.00002551
Iteration 6/1000 | Loss: 0.00002470
Iteration 7/1000 | Loss: 0.00002426
Iteration 8/1000 | Loss: 0.00002376
Iteration 9/1000 | Loss: 0.00002353
Iteration 10/1000 | Loss: 0.00002341
Iteration 11/1000 | Loss: 0.00002337
Iteration 12/1000 | Loss: 0.00002337
Iteration 13/1000 | Loss: 0.00002336
Iteration 14/1000 | Loss: 0.00002334
Iteration 15/1000 | Loss: 0.00002333
Iteration 16/1000 | Loss: 0.00002333
Iteration 17/1000 | Loss: 0.00002332
Iteration 18/1000 | Loss: 0.00002332
Iteration 19/1000 | Loss: 0.00002331
Iteration 20/1000 | Loss: 0.00002331
Iteration 21/1000 | Loss: 0.00002331
Iteration 22/1000 | Loss: 0.00002331
Iteration 23/1000 | Loss: 0.00002330
Iteration 24/1000 | Loss: 0.00002330
Iteration 25/1000 | Loss: 0.00002330
Iteration 26/1000 | Loss: 0.00002329
Iteration 27/1000 | Loss: 0.00002329
Iteration 28/1000 | Loss: 0.00002328
Iteration 29/1000 | Loss: 0.00002328
Iteration 30/1000 | Loss: 0.00002327
Iteration 31/1000 | Loss: 0.00002327
Iteration 32/1000 | Loss: 0.00002326
Iteration 33/1000 | Loss: 0.00002326
Iteration 34/1000 | Loss: 0.00002326
Iteration 35/1000 | Loss: 0.00002325
Iteration 36/1000 | Loss: 0.00002325
Iteration 37/1000 | Loss: 0.00002325
Iteration 38/1000 | Loss: 0.00002324
Iteration 39/1000 | Loss: 0.00002324
Iteration 40/1000 | Loss: 0.00002324
Iteration 41/1000 | Loss: 0.00002324
Iteration 42/1000 | Loss: 0.00002324
Iteration 43/1000 | Loss: 0.00002324
Iteration 44/1000 | Loss: 0.00002324
Iteration 45/1000 | Loss: 0.00002323
Iteration 46/1000 | Loss: 0.00002323
Iteration 47/1000 | Loss: 0.00002323
Iteration 48/1000 | Loss: 0.00002323
Iteration 49/1000 | Loss: 0.00002323
Iteration 50/1000 | Loss: 0.00002323
Iteration 51/1000 | Loss: 0.00002323
Iteration 52/1000 | Loss: 0.00002323
Iteration 53/1000 | Loss: 0.00002323
Iteration 54/1000 | Loss: 0.00002323
Iteration 55/1000 | Loss: 0.00002323
Iteration 56/1000 | Loss: 0.00002323
Iteration 57/1000 | Loss: 0.00002323
Iteration 58/1000 | Loss: 0.00002322
Iteration 59/1000 | Loss: 0.00002322
Iteration 60/1000 | Loss: 0.00002322
Iteration 61/1000 | Loss: 0.00002322
Iteration 62/1000 | Loss: 0.00002322
Iteration 63/1000 | Loss: 0.00002322
Iteration 64/1000 | Loss: 0.00002322
Iteration 65/1000 | Loss: 0.00002322
Iteration 66/1000 | Loss: 0.00002322
Iteration 67/1000 | Loss: 0.00002322
Iteration 68/1000 | Loss: 0.00002322
Iteration 69/1000 | Loss: 0.00002322
Iteration 70/1000 | Loss: 0.00002321
Iteration 71/1000 | Loss: 0.00002321
Iteration 72/1000 | Loss: 0.00002321
Iteration 73/1000 | Loss: 0.00002321
Iteration 74/1000 | Loss: 0.00002321
Iteration 75/1000 | Loss: 0.00002321
Iteration 76/1000 | Loss: 0.00002321
Iteration 77/1000 | Loss: 0.00002321
Iteration 78/1000 | Loss: 0.00002321
Iteration 79/1000 | Loss: 0.00002321
Iteration 80/1000 | Loss: 0.00002321
Iteration 81/1000 | Loss: 0.00002321
Iteration 82/1000 | Loss: 0.00002321
Iteration 83/1000 | Loss: 0.00002321
Iteration 84/1000 | Loss: 0.00002321
Iteration 85/1000 | Loss: 0.00002321
Iteration 86/1000 | Loss: 0.00002321
Iteration 87/1000 | Loss: 0.00002321
Iteration 88/1000 | Loss: 0.00002321
Iteration 89/1000 | Loss: 0.00002321
Iteration 90/1000 | Loss: 0.00002321
Iteration 91/1000 | Loss: 0.00002321
Iteration 92/1000 | Loss: 0.00002321
Iteration 93/1000 | Loss: 0.00002321
Iteration 94/1000 | Loss: 0.00002321
Iteration 95/1000 | Loss: 0.00002321
Iteration 96/1000 | Loss: 0.00002321
Iteration 97/1000 | Loss: 0.00002321
Iteration 98/1000 | Loss: 0.00002321
Iteration 99/1000 | Loss: 0.00002321
Iteration 100/1000 | Loss: 0.00002321
Iteration 101/1000 | Loss: 0.00002321
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [2.32086476898985e-05, 2.32086476898985e-05, 2.32086476898985e-05, 2.32086476898985e-05, 2.32086476898985e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.32086476898985e-05

Optimization complete. Final v2v error: 4.150722026824951 mm

Highest mean error: 4.951474189758301 mm for frame 90

Lowest mean error: 3.4408202171325684 mm for frame 137

Saving results

Total time: 28.56584858894348
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0164/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0164/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01092423
Iteration 2/25 | Loss: 0.00241829
Iteration 3/25 | Loss: 0.00179440
Iteration 4/25 | Loss: 0.00167865
Iteration 5/25 | Loss: 0.00153458
Iteration 6/25 | Loss: 0.00158799
Iteration 7/25 | Loss: 0.00151917
Iteration 8/25 | Loss: 0.00132036
Iteration 9/25 | Loss: 0.00128408
Iteration 10/25 | Loss: 0.00124422
Iteration 11/25 | Loss: 0.00123416
Iteration 12/25 | Loss: 0.00121451
Iteration 13/25 | Loss: 0.00118329
Iteration 14/25 | Loss: 0.00118058
Iteration 15/25 | Loss: 0.00116092
Iteration 16/25 | Loss: 0.00115445
Iteration 17/25 | Loss: 0.00116550
Iteration 18/25 | Loss: 0.00114949
Iteration 19/25 | Loss: 0.00114577
Iteration 20/25 | Loss: 0.00115501
Iteration 21/25 | Loss: 0.00114812
Iteration 22/25 | Loss: 0.00113815
Iteration 23/25 | Loss: 0.00112894
Iteration 24/25 | Loss: 0.00112272
Iteration 25/25 | Loss: 0.00112208

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62858975
Iteration 2/25 | Loss: 0.00250485
Iteration 3/25 | Loss: 0.00250485
Iteration 4/25 | Loss: 0.00250485
Iteration 5/25 | Loss: 0.00250485
Iteration 6/25 | Loss: 0.00250485
Iteration 7/25 | Loss: 0.00250485
Iteration 8/25 | Loss: 0.00250485
Iteration 9/25 | Loss: 0.00250485
Iteration 10/25 | Loss: 0.00250485
Iteration 11/25 | Loss: 0.00250485
Iteration 12/25 | Loss: 0.00250485
Iteration 13/25 | Loss: 0.00250485
Iteration 14/25 | Loss: 0.00250485
Iteration 15/25 | Loss: 0.00250485
Iteration 16/25 | Loss: 0.00250485
Iteration 17/25 | Loss: 0.00250485
Iteration 18/25 | Loss: 0.00250485
Iteration 19/25 | Loss: 0.00250485
Iteration 20/25 | Loss: 0.00250485
Iteration 21/25 | Loss: 0.00250485
Iteration 22/25 | Loss: 0.00250485
Iteration 23/25 | Loss: 0.00250485
Iteration 24/25 | Loss: 0.00250485
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0025048512034118176, 0.0025048512034118176, 0.0025048512034118176, 0.0025048512034118176, 0.0025048512034118176]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0025048512034118176

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00250485
Iteration 2/1000 | Loss: 0.00019067
Iteration 3/1000 | Loss: 0.00046978
Iteration 4/1000 | Loss: 0.00053019
Iteration 5/1000 | Loss: 0.00058081
Iteration 6/1000 | Loss: 0.00013290
Iteration 7/1000 | Loss: 0.00010052
Iteration 8/1000 | Loss: 0.00011937
Iteration 9/1000 | Loss: 0.00026590
Iteration 10/1000 | Loss: 0.00026130
Iteration 11/1000 | Loss: 0.00024738
Iteration 12/1000 | Loss: 0.00026936
Iteration 13/1000 | Loss: 0.00429358
Iteration 14/1000 | Loss: 0.00132235
Iteration 15/1000 | Loss: 0.00061981
Iteration 16/1000 | Loss: 0.00072112
Iteration 17/1000 | Loss: 0.00027838
Iteration 18/1000 | Loss: 0.00023319
Iteration 19/1000 | Loss: 0.00008151
Iteration 20/1000 | Loss: 0.00028243
Iteration 21/1000 | Loss: 0.00026235
Iteration 22/1000 | Loss: 0.00026246
Iteration 23/1000 | Loss: 0.00018776
Iteration 24/1000 | Loss: 0.00032689
Iteration 25/1000 | Loss: 0.00026987
Iteration 26/1000 | Loss: 0.00015137
Iteration 27/1000 | Loss: 0.00032675
Iteration 28/1000 | Loss: 0.00023867
Iteration 29/1000 | Loss: 0.00038492
Iteration 30/1000 | Loss: 0.00038579
Iteration 31/1000 | Loss: 0.00034011
Iteration 32/1000 | Loss: 0.00032404
Iteration 33/1000 | Loss: 0.00017271
Iteration 34/1000 | Loss: 0.00004007
Iteration 35/1000 | Loss: 0.00043033
Iteration 36/1000 | Loss: 0.00020056
Iteration 37/1000 | Loss: 0.00040361
Iteration 38/1000 | Loss: 0.00008982
Iteration 39/1000 | Loss: 0.00029135
Iteration 40/1000 | Loss: 0.00005999
Iteration 41/1000 | Loss: 0.00023354
Iteration 42/1000 | Loss: 0.00029239
Iteration 43/1000 | Loss: 0.00024486
Iteration 44/1000 | Loss: 0.00027062
Iteration 45/1000 | Loss: 0.00023248
Iteration 46/1000 | Loss: 0.00020280
Iteration 47/1000 | Loss: 0.00004025
Iteration 48/1000 | Loss: 0.00005104
Iteration 49/1000 | Loss: 0.00007256
Iteration 50/1000 | Loss: 0.00021481
Iteration 51/1000 | Loss: 0.00034957
Iteration 52/1000 | Loss: 0.00004449
Iteration 53/1000 | Loss: 0.00003447
Iteration 54/1000 | Loss: 0.00024681
Iteration 55/1000 | Loss: 0.00036775
Iteration 56/1000 | Loss: 0.00058435
Iteration 57/1000 | Loss: 0.00005290
Iteration 58/1000 | Loss: 0.00003033
Iteration 59/1000 | Loss: 0.00002722
Iteration 60/1000 | Loss: 0.00002554
Iteration 61/1000 | Loss: 0.00002457
Iteration 62/1000 | Loss: 0.00002292
Iteration 63/1000 | Loss: 0.00004125
Iteration 64/1000 | Loss: 0.00002997
Iteration 65/1000 | Loss: 0.00002392
Iteration 66/1000 | Loss: 0.00002220
Iteration 67/1000 | Loss: 0.00002116
Iteration 68/1000 | Loss: 0.00002060
Iteration 69/1000 | Loss: 0.00002048
Iteration 70/1000 | Loss: 0.00002026
Iteration 71/1000 | Loss: 0.00002008
Iteration 72/1000 | Loss: 0.00002007
Iteration 73/1000 | Loss: 0.00002006
Iteration 74/1000 | Loss: 0.00002002
Iteration 75/1000 | Loss: 0.00001990
Iteration 76/1000 | Loss: 0.00001989
Iteration 77/1000 | Loss: 0.00001989
Iteration 78/1000 | Loss: 0.00001987
Iteration 79/1000 | Loss: 0.00001987
Iteration 80/1000 | Loss: 0.00001987
Iteration 81/1000 | Loss: 0.00001986
Iteration 82/1000 | Loss: 0.00001986
Iteration 83/1000 | Loss: 0.00001986
Iteration 84/1000 | Loss: 0.00001986
Iteration 85/1000 | Loss: 0.00001984
Iteration 86/1000 | Loss: 0.00001984
Iteration 87/1000 | Loss: 0.00001984
Iteration 88/1000 | Loss: 0.00001983
Iteration 89/1000 | Loss: 0.00001983
Iteration 90/1000 | Loss: 0.00001983
Iteration 91/1000 | Loss: 0.00001983
Iteration 92/1000 | Loss: 0.00001982
Iteration 93/1000 | Loss: 0.00001981
Iteration 94/1000 | Loss: 0.00001981
Iteration 95/1000 | Loss: 0.00001980
Iteration 96/1000 | Loss: 0.00001980
Iteration 97/1000 | Loss: 0.00001979
Iteration 98/1000 | Loss: 0.00001979
Iteration 99/1000 | Loss: 0.00001979
Iteration 100/1000 | Loss: 0.00001978
Iteration 101/1000 | Loss: 0.00001978
Iteration 102/1000 | Loss: 0.00001978
Iteration 103/1000 | Loss: 0.00001977
Iteration 104/1000 | Loss: 0.00001977
Iteration 105/1000 | Loss: 0.00001976
Iteration 106/1000 | Loss: 0.00001976
Iteration 107/1000 | Loss: 0.00001976
Iteration 108/1000 | Loss: 0.00001976
Iteration 109/1000 | Loss: 0.00001976
Iteration 110/1000 | Loss: 0.00001976
Iteration 111/1000 | Loss: 0.00001976
Iteration 112/1000 | Loss: 0.00001976
Iteration 113/1000 | Loss: 0.00001976
Iteration 114/1000 | Loss: 0.00001976
Iteration 115/1000 | Loss: 0.00001976
Iteration 116/1000 | Loss: 0.00001976
Iteration 117/1000 | Loss: 0.00001976
Iteration 118/1000 | Loss: 0.00001976
Iteration 119/1000 | Loss: 0.00001976
Iteration 120/1000 | Loss: 0.00001976
Iteration 121/1000 | Loss: 0.00001976
Iteration 122/1000 | Loss: 0.00001976
Iteration 123/1000 | Loss: 0.00001976
Iteration 124/1000 | Loss: 0.00001976
Iteration 125/1000 | Loss: 0.00001976
Iteration 126/1000 | Loss: 0.00001976
Iteration 127/1000 | Loss: 0.00001976
Iteration 128/1000 | Loss: 0.00001976
Iteration 129/1000 | Loss: 0.00001976
Iteration 130/1000 | Loss: 0.00001976
Iteration 131/1000 | Loss: 0.00001976
Iteration 132/1000 | Loss: 0.00001976
Iteration 133/1000 | Loss: 0.00001976
Iteration 134/1000 | Loss: 0.00001976
Iteration 135/1000 | Loss: 0.00001976
Iteration 136/1000 | Loss: 0.00001976
Iteration 137/1000 | Loss: 0.00001976
Iteration 138/1000 | Loss: 0.00001976
Iteration 139/1000 | Loss: 0.00001976
Iteration 140/1000 | Loss: 0.00001976
Iteration 141/1000 | Loss: 0.00001976
Iteration 142/1000 | Loss: 0.00001976
Iteration 143/1000 | Loss: 0.00001976
Iteration 144/1000 | Loss: 0.00001976
Iteration 145/1000 | Loss: 0.00001976
Iteration 146/1000 | Loss: 0.00001976
Iteration 147/1000 | Loss: 0.00001976
Iteration 148/1000 | Loss: 0.00001976
Iteration 149/1000 | Loss: 0.00001976
Iteration 150/1000 | Loss: 0.00001976
Iteration 151/1000 | Loss: 0.00001976
Iteration 152/1000 | Loss: 0.00001976
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 152. Stopping optimization.
Last 5 losses: [1.975959094124846e-05, 1.975959094124846e-05, 1.975959094124846e-05, 1.975959094124846e-05, 1.975959094124846e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.975959094124846e-05

Optimization complete. Final v2v error: 3.7812557220458984 mm

Highest mean error: 4.816432952880859 mm for frame 76

Lowest mean error: 3.362072706222534 mm for frame 29

Saving results

Total time: 148.2687542438507

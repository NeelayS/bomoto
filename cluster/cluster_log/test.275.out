Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=275, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 15400-15455
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1032/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1032.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1032
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00773410
Iteration 2/25 | Loss: 0.00173198
Iteration 3/25 | Loss: 0.00103564
Iteration 4/25 | Loss: 0.00091323
Iteration 5/25 | Loss: 0.00087740
Iteration 6/25 | Loss: 0.00086804
Iteration 7/25 | Loss: 0.00086525
Iteration 8/25 | Loss: 0.00086454
Iteration 9/25 | Loss: 0.00086435
Iteration 10/25 | Loss: 0.00086435
Iteration 11/25 | Loss: 0.00086435
Iteration 12/25 | Loss: 0.00086435
Iteration 13/25 | Loss: 0.00086435
Iteration 14/25 | Loss: 0.00086435
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0008643546025268734, 0.0008643546025268734, 0.0008643546025268734, 0.0008643546025268734, 0.0008643546025268734]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008643546025268734

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.58861369
Iteration 2/25 | Loss: 0.00042885
Iteration 3/25 | Loss: 0.00042885
Iteration 4/25 | Loss: 0.00042884
Iteration 5/25 | Loss: 0.00042884
Iteration 6/25 | Loss: 0.00042884
Iteration 7/25 | Loss: 0.00042884
Iteration 8/25 | Loss: 0.00042884
Iteration 9/25 | Loss: 0.00042884
Iteration 10/25 | Loss: 0.00042884
Iteration 11/25 | Loss: 0.00042884
Iteration 12/25 | Loss: 0.00042884
Iteration 13/25 | Loss: 0.00042884
Iteration 14/25 | Loss: 0.00042884
Iteration 15/25 | Loss: 0.00042884
Iteration 16/25 | Loss: 0.00042884
Iteration 17/25 | Loss: 0.00042884
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00042884232243523, 0.00042884232243523, 0.00042884232243523, 0.00042884232243523, 0.00042884232243523]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00042884232243523

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042884
Iteration 2/1000 | Loss: 0.00004688
Iteration 3/1000 | Loss: 0.00003392
Iteration 4/1000 | Loss: 0.00002885
Iteration 5/1000 | Loss: 0.00002644
Iteration 6/1000 | Loss: 0.00002452
Iteration 7/1000 | Loss: 0.00002352
Iteration 8/1000 | Loss: 0.00002254
Iteration 9/1000 | Loss: 0.00002195
Iteration 10/1000 | Loss: 0.00002158
Iteration 11/1000 | Loss: 0.00002121
Iteration 12/1000 | Loss: 0.00002101
Iteration 13/1000 | Loss: 0.00002083
Iteration 14/1000 | Loss: 0.00002077
Iteration 15/1000 | Loss: 0.00002068
Iteration 16/1000 | Loss: 0.00002067
Iteration 17/1000 | Loss: 0.00002067
Iteration 18/1000 | Loss: 0.00002065
Iteration 19/1000 | Loss: 0.00002064
Iteration 20/1000 | Loss: 0.00002063
Iteration 21/1000 | Loss: 0.00002063
Iteration 22/1000 | Loss: 0.00002063
Iteration 23/1000 | Loss: 0.00002062
Iteration 24/1000 | Loss: 0.00002062
Iteration 25/1000 | Loss: 0.00002062
Iteration 26/1000 | Loss: 0.00002062
Iteration 27/1000 | Loss: 0.00002062
Iteration 28/1000 | Loss: 0.00002062
Iteration 29/1000 | Loss: 0.00002061
Iteration 30/1000 | Loss: 0.00002061
Iteration 31/1000 | Loss: 0.00002061
Iteration 32/1000 | Loss: 0.00002061
Iteration 33/1000 | Loss: 0.00002061
Iteration 34/1000 | Loss: 0.00002061
Iteration 35/1000 | Loss: 0.00002061
Iteration 36/1000 | Loss: 0.00002060
Iteration 37/1000 | Loss: 0.00002060
Iteration 38/1000 | Loss: 0.00002059
Iteration 39/1000 | Loss: 0.00002059
Iteration 40/1000 | Loss: 0.00002059
Iteration 41/1000 | Loss: 0.00002059
Iteration 42/1000 | Loss: 0.00002059
Iteration 43/1000 | Loss: 0.00002058
Iteration 44/1000 | Loss: 0.00002058
Iteration 45/1000 | Loss: 0.00002058
Iteration 46/1000 | Loss: 0.00002058
Iteration 47/1000 | Loss: 0.00002057
Iteration 48/1000 | Loss: 0.00002057
Iteration 49/1000 | Loss: 0.00002056
Iteration 50/1000 | Loss: 0.00002056
Iteration 51/1000 | Loss: 0.00002056
Iteration 52/1000 | Loss: 0.00002056
Iteration 53/1000 | Loss: 0.00002055
Iteration 54/1000 | Loss: 0.00002055
Iteration 55/1000 | Loss: 0.00002055
Iteration 56/1000 | Loss: 0.00002054
Iteration 57/1000 | Loss: 0.00002054
Iteration 58/1000 | Loss: 0.00002054
Iteration 59/1000 | Loss: 0.00002053
Iteration 60/1000 | Loss: 0.00002053
Iteration 61/1000 | Loss: 0.00002053
Iteration 62/1000 | Loss: 0.00002052
Iteration 63/1000 | Loss: 0.00002052
Iteration 64/1000 | Loss: 0.00002052
Iteration 65/1000 | Loss: 0.00002052
Iteration 66/1000 | Loss: 0.00002052
Iteration 67/1000 | Loss: 0.00002052
Iteration 68/1000 | Loss: 0.00002052
Iteration 69/1000 | Loss: 0.00002052
Iteration 70/1000 | Loss: 0.00002052
Iteration 71/1000 | Loss: 0.00002051
Iteration 72/1000 | Loss: 0.00002050
Iteration 73/1000 | Loss: 0.00002050
Iteration 74/1000 | Loss: 0.00002050
Iteration 75/1000 | Loss: 0.00002049
Iteration 76/1000 | Loss: 0.00002049
Iteration 77/1000 | Loss: 0.00002049
Iteration 78/1000 | Loss: 0.00002048
Iteration 79/1000 | Loss: 0.00002048
Iteration 80/1000 | Loss: 0.00002048
Iteration 81/1000 | Loss: 0.00002048
Iteration 82/1000 | Loss: 0.00002047
Iteration 83/1000 | Loss: 0.00002047
Iteration 84/1000 | Loss: 0.00002047
Iteration 85/1000 | Loss: 0.00002047
Iteration 86/1000 | Loss: 0.00002047
Iteration 87/1000 | Loss: 0.00002046
Iteration 88/1000 | Loss: 0.00002046
Iteration 89/1000 | Loss: 0.00002046
Iteration 90/1000 | Loss: 0.00002045
Iteration 91/1000 | Loss: 0.00002045
Iteration 92/1000 | Loss: 0.00002045
Iteration 93/1000 | Loss: 0.00002044
Iteration 94/1000 | Loss: 0.00002044
Iteration 95/1000 | Loss: 0.00002044
Iteration 96/1000 | Loss: 0.00002044
Iteration 97/1000 | Loss: 0.00002044
Iteration 98/1000 | Loss: 0.00002043
Iteration 99/1000 | Loss: 0.00002043
Iteration 100/1000 | Loss: 0.00002043
Iteration 101/1000 | Loss: 0.00002043
Iteration 102/1000 | Loss: 0.00002043
Iteration 103/1000 | Loss: 0.00002043
Iteration 104/1000 | Loss: 0.00002042
Iteration 105/1000 | Loss: 0.00002042
Iteration 106/1000 | Loss: 0.00002042
Iteration 107/1000 | Loss: 0.00002042
Iteration 108/1000 | Loss: 0.00002042
Iteration 109/1000 | Loss: 0.00002041
Iteration 110/1000 | Loss: 0.00002041
Iteration 111/1000 | Loss: 0.00002041
Iteration 112/1000 | Loss: 0.00002041
Iteration 113/1000 | Loss: 0.00002040
Iteration 114/1000 | Loss: 0.00002040
Iteration 115/1000 | Loss: 0.00002040
Iteration 116/1000 | Loss: 0.00002040
Iteration 117/1000 | Loss: 0.00002040
Iteration 118/1000 | Loss: 0.00002040
Iteration 119/1000 | Loss: 0.00002040
Iteration 120/1000 | Loss: 0.00002040
Iteration 121/1000 | Loss: 0.00002040
Iteration 122/1000 | Loss: 0.00002040
Iteration 123/1000 | Loss: 0.00002040
Iteration 124/1000 | Loss: 0.00002040
Iteration 125/1000 | Loss: 0.00002040
Iteration 126/1000 | Loss: 0.00002040
Iteration 127/1000 | Loss: 0.00002040
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [2.0402416339493357e-05, 2.0402416339493357e-05, 2.0402416339493357e-05, 2.0402416339493357e-05, 2.0402416339493357e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0402416339493357e-05

Optimization complete. Final v2v error: 3.7162814140319824 mm

Highest mean error: 5.655666828155518 mm for frame 33

Lowest mean error: 2.9350013732910156 mm for frame 1

Saving results

Total time: 42.626121044158936
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1058/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1058.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1058
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00391403
Iteration 2/25 | Loss: 0.00086442
Iteration 3/25 | Loss: 0.00073102
Iteration 4/25 | Loss: 0.00071244
Iteration 5/25 | Loss: 0.00070795
Iteration 6/25 | Loss: 0.00070638
Iteration 7/25 | Loss: 0.00070601
Iteration 8/25 | Loss: 0.00070601
Iteration 9/25 | Loss: 0.00070601
Iteration 10/25 | Loss: 0.00070601
Iteration 11/25 | Loss: 0.00070601
Iteration 12/25 | Loss: 0.00070601
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007060079369693995, 0.0007060079369693995, 0.0007060079369693995, 0.0007060079369693995, 0.0007060079369693995]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007060079369693995

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50682688
Iteration 2/25 | Loss: 0.00040772
Iteration 3/25 | Loss: 0.00040771
Iteration 4/25 | Loss: 0.00040771
Iteration 5/25 | Loss: 0.00040771
Iteration 6/25 | Loss: 0.00040771
Iteration 7/25 | Loss: 0.00040771
Iteration 8/25 | Loss: 0.00040771
Iteration 9/25 | Loss: 0.00040771
Iteration 10/25 | Loss: 0.00040771
Iteration 11/25 | Loss: 0.00040771
Iteration 12/25 | Loss: 0.00040771
Iteration 13/25 | Loss: 0.00040771
Iteration 14/25 | Loss: 0.00040771
Iteration 15/25 | Loss: 0.00040771
Iteration 16/25 | Loss: 0.00040771
Iteration 17/25 | Loss: 0.00040771
Iteration 18/25 | Loss: 0.00040771
Iteration 19/25 | Loss: 0.00040771
Iteration 20/25 | Loss: 0.00040771
Iteration 21/25 | Loss: 0.00040771
Iteration 22/25 | Loss: 0.00040771
Iteration 23/25 | Loss: 0.00040771
Iteration 24/25 | Loss: 0.00040771
Iteration 25/25 | Loss: 0.00040771

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040771
Iteration 2/1000 | Loss: 0.00002226
Iteration 3/1000 | Loss: 0.00001386
Iteration 4/1000 | Loss: 0.00001210
Iteration 5/1000 | Loss: 0.00001137
Iteration 6/1000 | Loss: 0.00001067
Iteration 7/1000 | Loss: 0.00001059
Iteration 8/1000 | Loss: 0.00001033
Iteration 9/1000 | Loss: 0.00001013
Iteration 10/1000 | Loss: 0.00001011
Iteration 11/1000 | Loss: 0.00001009
Iteration 12/1000 | Loss: 0.00001009
Iteration 13/1000 | Loss: 0.00001008
Iteration 14/1000 | Loss: 0.00001003
Iteration 15/1000 | Loss: 0.00001002
Iteration 16/1000 | Loss: 0.00001000
Iteration 17/1000 | Loss: 0.00000999
Iteration 18/1000 | Loss: 0.00000999
Iteration 19/1000 | Loss: 0.00000999
Iteration 20/1000 | Loss: 0.00000998
Iteration 21/1000 | Loss: 0.00000998
Iteration 22/1000 | Loss: 0.00000995
Iteration 23/1000 | Loss: 0.00000990
Iteration 24/1000 | Loss: 0.00000987
Iteration 25/1000 | Loss: 0.00000983
Iteration 26/1000 | Loss: 0.00000983
Iteration 27/1000 | Loss: 0.00000982
Iteration 28/1000 | Loss: 0.00000981
Iteration 29/1000 | Loss: 0.00000980
Iteration 30/1000 | Loss: 0.00000980
Iteration 31/1000 | Loss: 0.00000979
Iteration 32/1000 | Loss: 0.00000978
Iteration 33/1000 | Loss: 0.00000978
Iteration 34/1000 | Loss: 0.00000978
Iteration 35/1000 | Loss: 0.00000977
Iteration 36/1000 | Loss: 0.00000977
Iteration 37/1000 | Loss: 0.00000976
Iteration 38/1000 | Loss: 0.00000976
Iteration 39/1000 | Loss: 0.00000976
Iteration 40/1000 | Loss: 0.00000976
Iteration 41/1000 | Loss: 0.00000976
Iteration 42/1000 | Loss: 0.00000976
Iteration 43/1000 | Loss: 0.00000976
Iteration 44/1000 | Loss: 0.00000975
Iteration 45/1000 | Loss: 0.00000975
Iteration 46/1000 | Loss: 0.00000974
Iteration 47/1000 | Loss: 0.00000974
Iteration 48/1000 | Loss: 0.00000974
Iteration 49/1000 | Loss: 0.00000974
Iteration 50/1000 | Loss: 0.00000973
Iteration 51/1000 | Loss: 0.00000973
Iteration 52/1000 | Loss: 0.00000973
Iteration 53/1000 | Loss: 0.00000973
Iteration 54/1000 | Loss: 0.00000973
Iteration 55/1000 | Loss: 0.00000971
Iteration 56/1000 | Loss: 0.00000971
Iteration 57/1000 | Loss: 0.00000970
Iteration 58/1000 | Loss: 0.00000970
Iteration 59/1000 | Loss: 0.00000970
Iteration 60/1000 | Loss: 0.00000970
Iteration 61/1000 | Loss: 0.00000970
Iteration 62/1000 | Loss: 0.00000970
Iteration 63/1000 | Loss: 0.00000969
Iteration 64/1000 | Loss: 0.00000969
Iteration 65/1000 | Loss: 0.00000968
Iteration 66/1000 | Loss: 0.00000968
Iteration 67/1000 | Loss: 0.00000968
Iteration 68/1000 | Loss: 0.00000967
Iteration 69/1000 | Loss: 0.00000967
Iteration 70/1000 | Loss: 0.00000967
Iteration 71/1000 | Loss: 0.00000967
Iteration 72/1000 | Loss: 0.00000966
Iteration 73/1000 | Loss: 0.00000966
Iteration 74/1000 | Loss: 0.00000966
Iteration 75/1000 | Loss: 0.00000966
Iteration 76/1000 | Loss: 0.00000966
Iteration 77/1000 | Loss: 0.00000965
Iteration 78/1000 | Loss: 0.00000965
Iteration 79/1000 | Loss: 0.00000965
Iteration 80/1000 | Loss: 0.00000965
Iteration 81/1000 | Loss: 0.00000964
Iteration 82/1000 | Loss: 0.00000964
Iteration 83/1000 | Loss: 0.00000964
Iteration 84/1000 | Loss: 0.00000964
Iteration 85/1000 | Loss: 0.00000964
Iteration 86/1000 | Loss: 0.00000964
Iteration 87/1000 | Loss: 0.00000964
Iteration 88/1000 | Loss: 0.00000964
Iteration 89/1000 | Loss: 0.00000964
Iteration 90/1000 | Loss: 0.00000964
Iteration 91/1000 | Loss: 0.00000964
Iteration 92/1000 | Loss: 0.00000963
Iteration 93/1000 | Loss: 0.00000963
Iteration 94/1000 | Loss: 0.00000963
Iteration 95/1000 | Loss: 0.00000963
Iteration 96/1000 | Loss: 0.00000963
Iteration 97/1000 | Loss: 0.00000963
Iteration 98/1000 | Loss: 0.00000963
Iteration 99/1000 | Loss: 0.00000963
Iteration 100/1000 | Loss: 0.00000963
Iteration 101/1000 | Loss: 0.00000962
Iteration 102/1000 | Loss: 0.00000962
Iteration 103/1000 | Loss: 0.00000962
Iteration 104/1000 | Loss: 0.00000962
Iteration 105/1000 | Loss: 0.00000962
Iteration 106/1000 | Loss: 0.00000961
Iteration 107/1000 | Loss: 0.00000961
Iteration 108/1000 | Loss: 0.00000961
Iteration 109/1000 | Loss: 0.00000961
Iteration 110/1000 | Loss: 0.00000961
Iteration 111/1000 | Loss: 0.00000961
Iteration 112/1000 | Loss: 0.00000960
Iteration 113/1000 | Loss: 0.00000960
Iteration 114/1000 | Loss: 0.00000960
Iteration 115/1000 | Loss: 0.00000960
Iteration 116/1000 | Loss: 0.00000960
Iteration 117/1000 | Loss: 0.00000959
Iteration 118/1000 | Loss: 0.00000959
Iteration 119/1000 | Loss: 0.00000959
Iteration 120/1000 | Loss: 0.00000959
Iteration 121/1000 | Loss: 0.00000959
Iteration 122/1000 | Loss: 0.00000958
Iteration 123/1000 | Loss: 0.00000958
Iteration 124/1000 | Loss: 0.00000958
Iteration 125/1000 | Loss: 0.00000958
Iteration 126/1000 | Loss: 0.00000957
Iteration 127/1000 | Loss: 0.00000957
Iteration 128/1000 | Loss: 0.00000956
Iteration 129/1000 | Loss: 0.00000956
Iteration 130/1000 | Loss: 0.00000955
Iteration 131/1000 | Loss: 0.00000955
Iteration 132/1000 | Loss: 0.00000955
Iteration 133/1000 | Loss: 0.00000954
Iteration 134/1000 | Loss: 0.00000954
Iteration 135/1000 | Loss: 0.00000954
Iteration 136/1000 | Loss: 0.00000954
Iteration 137/1000 | Loss: 0.00000953
Iteration 138/1000 | Loss: 0.00000953
Iteration 139/1000 | Loss: 0.00000953
Iteration 140/1000 | Loss: 0.00000953
Iteration 141/1000 | Loss: 0.00000953
Iteration 142/1000 | Loss: 0.00000952
Iteration 143/1000 | Loss: 0.00000952
Iteration 144/1000 | Loss: 0.00000952
Iteration 145/1000 | Loss: 0.00000952
Iteration 146/1000 | Loss: 0.00000951
Iteration 147/1000 | Loss: 0.00000951
Iteration 148/1000 | Loss: 0.00000951
Iteration 149/1000 | Loss: 0.00000951
Iteration 150/1000 | Loss: 0.00000951
Iteration 151/1000 | Loss: 0.00000951
Iteration 152/1000 | Loss: 0.00000950
Iteration 153/1000 | Loss: 0.00000950
Iteration 154/1000 | Loss: 0.00000950
Iteration 155/1000 | Loss: 0.00000950
Iteration 156/1000 | Loss: 0.00000950
Iteration 157/1000 | Loss: 0.00000950
Iteration 158/1000 | Loss: 0.00000950
Iteration 159/1000 | Loss: 0.00000950
Iteration 160/1000 | Loss: 0.00000950
Iteration 161/1000 | Loss: 0.00000949
Iteration 162/1000 | Loss: 0.00000949
Iteration 163/1000 | Loss: 0.00000949
Iteration 164/1000 | Loss: 0.00000949
Iteration 165/1000 | Loss: 0.00000949
Iteration 166/1000 | Loss: 0.00000949
Iteration 167/1000 | Loss: 0.00000949
Iteration 168/1000 | Loss: 0.00000949
Iteration 169/1000 | Loss: 0.00000949
Iteration 170/1000 | Loss: 0.00000948
Iteration 171/1000 | Loss: 0.00000948
Iteration 172/1000 | Loss: 0.00000948
Iteration 173/1000 | Loss: 0.00000948
Iteration 174/1000 | Loss: 0.00000948
Iteration 175/1000 | Loss: 0.00000948
Iteration 176/1000 | Loss: 0.00000948
Iteration 177/1000 | Loss: 0.00000948
Iteration 178/1000 | Loss: 0.00000948
Iteration 179/1000 | Loss: 0.00000948
Iteration 180/1000 | Loss: 0.00000948
Iteration 181/1000 | Loss: 0.00000947
Iteration 182/1000 | Loss: 0.00000947
Iteration 183/1000 | Loss: 0.00000947
Iteration 184/1000 | Loss: 0.00000947
Iteration 185/1000 | Loss: 0.00000947
Iteration 186/1000 | Loss: 0.00000947
Iteration 187/1000 | Loss: 0.00000947
Iteration 188/1000 | Loss: 0.00000947
Iteration 189/1000 | Loss: 0.00000947
Iteration 190/1000 | Loss: 0.00000947
Iteration 191/1000 | Loss: 0.00000947
Iteration 192/1000 | Loss: 0.00000947
Iteration 193/1000 | Loss: 0.00000947
Iteration 194/1000 | Loss: 0.00000947
Iteration 195/1000 | Loss: 0.00000947
Iteration 196/1000 | Loss: 0.00000947
Iteration 197/1000 | Loss: 0.00000947
Iteration 198/1000 | Loss: 0.00000946
Iteration 199/1000 | Loss: 0.00000946
Iteration 200/1000 | Loss: 0.00000946
Iteration 201/1000 | Loss: 0.00000946
Iteration 202/1000 | Loss: 0.00000946
Iteration 203/1000 | Loss: 0.00000946
Iteration 204/1000 | Loss: 0.00000946
Iteration 205/1000 | Loss: 0.00000946
Iteration 206/1000 | Loss: 0.00000946
Iteration 207/1000 | Loss: 0.00000946
Iteration 208/1000 | Loss: 0.00000946
Iteration 209/1000 | Loss: 0.00000946
Iteration 210/1000 | Loss: 0.00000946
Iteration 211/1000 | Loss: 0.00000946
Iteration 212/1000 | Loss: 0.00000945
Iteration 213/1000 | Loss: 0.00000945
Iteration 214/1000 | Loss: 0.00000945
Iteration 215/1000 | Loss: 0.00000945
Iteration 216/1000 | Loss: 0.00000945
Iteration 217/1000 | Loss: 0.00000945
Iteration 218/1000 | Loss: 0.00000945
Iteration 219/1000 | Loss: 0.00000945
Iteration 220/1000 | Loss: 0.00000945
Iteration 221/1000 | Loss: 0.00000945
Iteration 222/1000 | Loss: 0.00000945
Iteration 223/1000 | Loss: 0.00000945
Iteration 224/1000 | Loss: 0.00000945
Iteration 225/1000 | Loss: 0.00000945
Iteration 226/1000 | Loss: 0.00000945
Iteration 227/1000 | Loss: 0.00000945
Iteration 228/1000 | Loss: 0.00000945
Iteration 229/1000 | Loss: 0.00000945
Iteration 230/1000 | Loss: 0.00000945
Iteration 231/1000 | Loss: 0.00000945
Iteration 232/1000 | Loss: 0.00000945
Iteration 233/1000 | Loss: 0.00000945
Iteration 234/1000 | Loss: 0.00000945
Iteration 235/1000 | Loss: 0.00000945
Iteration 236/1000 | Loss: 0.00000945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 236. Stopping optimization.
Last 5 losses: [9.4465085567208e-06, 9.4465085567208e-06, 9.4465085567208e-06, 9.4465085567208e-06, 9.4465085567208e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.4465085567208e-06

Optimization complete. Final v2v error: 2.6104624271392822 mm

Highest mean error: 3.460578680038452 mm for frame 72

Lowest mean error: 2.4598333835601807 mm for frame 113

Saving results

Total time: 40.99966740608215
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1044/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1044.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1044
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00923021
Iteration 2/25 | Loss: 0.00137801
Iteration 3/25 | Loss: 0.00098891
Iteration 4/25 | Loss: 0.00093615
Iteration 5/25 | Loss: 0.00092718
Iteration 6/25 | Loss: 0.00090652
Iteration 7/25 | Loss: 0.00089922
Iteration 8/25 | Loss: 0.00090277
Iteration 9/25 | Loss: 0.00090313
Iteration 10/25 | Loss: 0.00089142
Iteration 11/25 | Loss: 0.00088871
Iteration 12/25 | Loss: 0.00088766
Iteration 13/25 | Loss: 0.00088735
Iteration 14/25 | Loss: 0.00088722
Iteration 15/25 | Loss: 0.00088659
Iteration 16/25 | Loss: 0.00088565
Iteration 17/25 | Loss: 0.00088532
Iteration 18/25 | Loss: 0.00088517
Iteration 19/25 | Loss: 0.00088499
Iteration 20/25 | Loss: 0.00088913
Iteration 21/25 | Loss: 0.00088473
Iteration 22/25 | Loss: 0.00088388
Iteration 23/25 | Loss: 0.00088357
Iteration 24/25 | Loss: 0.00088356
Iteration 25/25 | Loss: 0.00088356

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.49090171
Iteration 2/25 | Loss: 0.00055768
Iteration 3/25 | Loss: 0.00055768
Iteration 4/25 | Loss: 0.00055768
Iteration 5/25 | Loss: 0.00055768
Iteration 6/25 | Loss: 0.00055768
Iteration 7/25 | Loss: 0.00055768
Iteration 8/25 | Loss: 0.00055768
Iteration 9/25 | Loss: 0.00055768
Iteration 10/25 | Loss: 0.00055768
Iteration 11/25 | Loss: 0.00055768
Iteration 12/25 | Loss: 0.00055768
Iteration 13/25 | Loss: 0.00055768
Iteration 14/25 | Loss: 0.00055768
Iteration 15/25 | Loss: 0.00055768
Iteration 16/25 | Loss: 0.00055768
Iteration 17/25 | Loss: 0.00055768
Iteration 18/25 | Loss: 0.00055768
Iteration 19/25 | Loss: 0.00055768
Iteration 20/25 | Loss: 0.00055768
Iteration 21/25 | Loss: 0.00055768
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0005576754338108003, 0.0005576754338108003, 0.0005576754338108003, 0.0005576754338108003, 0.0005576754338108003]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005576754338108003

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055768
Iteration 2/1000 | Loss: 0.00012543
Iteration 3/1000 | Loss: 0.00005142
Iteration 4/1000 | Loss: 0.00003917
Iteration 5/1000 | Loss: 0.00003482
Iteration 6/1000 | Loss: 0.00003035
Iteration 7/1000 | Loss: 0.00002881
Iteration 8/1000 | Loss: 0.00002743
Iteration 9/1000 | Loss: 0.00002684
Iteration 10/1000 | Loss: 0.00002631
Iteration 11/1000 | Loss: 0.00002599
Iteration 12/1000 | Loss: 0.00002577
Iteration 13/1000 | Loss: 0.00002557
Iteration 14/1000 | Loss: 0.00002544
Iteration 15/1000 | Loss: 0.00002541
Iteration 16/1000 | Loss: 0.00002535
Iteration 17/1000 | Loss: 0.00002531
Iteration 18/1000 | Loss: 0.00002528
Iteration 19/1000 | Loss: 0.00002527
Iteration 20/1000 | Loss: 0.00002526
Iteration 21/1000 | Loss: 0.00002525
Iteration 22/1000 | Loss: 0.00002525
Iteration 23/1000 | Loss: 0.00002525
Iteration 24/1000 | Loss: 0.00002525
Iteration 25/1000 | Loss: 0.00002524
Iteration 26/1000 | Loss: 0.00002524
Iteration 27/1000 | Loss: 0.00002524
Iteration 28/1000 | Loss: 0.00002524
Iteration 29/1000 | Loss: 0.00002524
Iteration 30/1000 | Loss: 0.00002524
Iteration 31/1000 | Loss: 0.00002524
Iteration 32/1000 | Loss: 0.00002524
Iteration 33/1000 | Loss: 0.00002524
Iteration 34/1000 | Loss: 0.00002524
Iteration 35/1000 | Loss: 0.00002524
Iteration 36/1000 | Loss: 0.00002523
Iteration 37/1000 | Loss: 0.00002523
Iteration 38/1000 | Loss: 0.00002523
Iteration 39/1000 | Loss: 0.00002523
Iteration 40/1000 | Loss: 0.00002522
Iteration 41/1000 | Loss: 0.00002521
Iteration 42/1000 | Loss: 0.00002521
Iteration 43/1000 | Loss: 0.00002520
Iteration 44/1000 | Loss: 0.00002520
Iteration 45/1000 | Loss: 0.00002520
Iteration 46/1000 | Loss: 0.00002519
Iteration 47/1000 | Loss: 0.00002519
Iteration 48/1000 | Loss: 0.00002519
Iteration 49/1000 | Loss: 0.00002519
Iteration 50/1000 | Loss: 0.00002518
Iteration 51/1000 | Loss: 0.00002518
Iteration 52/1000 | Loss: 0.00002518
Iteration 53/1000 | Loss: 0.00002518
Iteration 54/1000 | Loss: 0.00002518
Iteration 55/1000 | Loss: 0.00002518
Iteration 56/1000 | Loss: 0.00002517
Iteration 57/1000 | Loss: 0.00002517
Iteration 58/1000 | Loss: 0.00002517
Iteration 59/1000 | Loss: 0.00002517
Iteration 60/1000 | Loss: 0.00002517
Iteration 61/1000 | Loss: 0.00002517
Iteration 62/1000 | Loss: 0.00002517
Iteration 63/1000 | Loss: 0.00002516
Iteration 64/1000 | Loss: 0.00002516
Iteration 65/1000 | Loss: 0.00002516
Iteration 66/1000 | Loss: 0.00002516
Iteration 67/1000 | Loss: 0.00002516
Iteration 68/1000 | Loss: 0.00002516
Iteration 69/1000 | Loss: 0.00002516
Iteration 70/1000 | Loss: 0.00002516
Iteration 71/1000 | Loss: 0.00002516
Iteration 72/1000 | Loss: 0.00002515
Iteration 73/1000 | Loss: 0.00002515
Iteration 74/1000 | Loss: 0.00002515
Iteration 75/1000 | Loss: 0.00002515
Iteration 76/1000 | Loss: 0.00002515
Iteration 77/1000 | Loss: 0.00002515
Iteration 78/1000 | Loss: 0.00002515
Iteration 79/1000 | Loss: 0.00002515
Iteration 80/1000 | Loss: 0.00002514
Iteration 81/1000 | Loss: 0.00002514
Iteration 82/1000 | Loss: 0.00002514
Iteration 83/1000 | Loss: 0.00002514
Iteration 84/1000 | Loss: 0.00002513
Iteration 85/1000 | Loss: 0.00002513
Iteration 86/1000 | Loss: 0.00002513
Iteration 87/1000 | Loss: 0.00002513
Iteration 88/1000 | Loss: 0.00002513
Iteration 89/1000 | Loss: 0.00002513
Iteration 90/1000 | Loss: 0.00002512
Iteration 91/1000 | Loss: 0.00002512
Iteration 92/1000 | Loss: 0.00002512
Iteration 93/1000 | Loss: 0.00002512
Iteration 94/1000 | Loss: 0.00002512
Iteration 95/1000 | Loss: 0.00002512
Iteration 96/1000 | Loss: 0.00002512
Iteration 97/1000 | Loss: 0.00002512
Iteration 98/1000 | Loss: 0.00002511
Iteration 99/1000 | Loss: 0.00002511
Iteration 100/1000 | Loss: 0.00002511
Iteration 101/1000 | Loss: 0.00002511
Iteration 102/1000 | Loss: 0.00002511
Iteration 103/1000 | Loss: 0.00002510
Iteration 104/1000 | Loss: 0.00002510
Iteration 105/1000 | Loss: 0.00002510
Iteration 106/1000 | Loss: 0.00002510
Iteration 107/1000 | Loss: 0.00002510
Iteration 108/1000 | Loss: 0.00002510
Iteration 109/1000 | Loss: 0.00002509
Iteration 110/1000 | Loss: 0.00002509
Iteration 111/1000 | Loss: 0.00002509
Iteration 112/1000 | Loss: 0.00002509
Iteration 113/1000 | Loss: 0.00002509
Iteration 114/1000 | Loss: 0.00002509
Iteration 115/1000 | Loss: 0.00002509
Iteration 116/1000 | Loss: 0.00002509
Iteration 117/1000 | Loss: 0.00002509
Iteration 118/1000 | Loss: 0.00002509
Iteration 119/1000 | Loss: 0.00002509
Iteration 120/1000 | Loss: 0.00002509
Iteration 121/1000 | Loss: 0.00002509
Iteration 122/1000 | Loss: 0.00002509
Iteration 123/1000 | Loss: 0.00002509
Iteration 124/1000 | Loss: 0.00002509
Iteration 125/1000 | Loss: 0.00002508
Iteration 126/1000 | Loss: 0.00002508
Iteration 127/1000 | Loss: 0.00002508
Iteration 128/1000 | Loss: 0.00002507
Iteration 129/1000 | Loss: 0.00002507
Iteration 130/1000 | Loss: 0.00002507
Iteration 131/1000 | Loss: 0.00002507
Iteration 132/1000 | Loss: 0.00002506
Iteration 133/1000 | Loss: 0.00002506
Iteration 134/1000 | Loss: 0.00002506
Iteration 135/1000 | Loss: 0.00002506
Iteration 136/1000 | Loss: 0.00002506
Iteration 137/1000 | Loss: 0.00002506
Iteration 138/1000 | Loss: 0.00002506
Iteration 139/1000 | Loss: 0.00002506
Iteration 140/1000 | Loss: 0.00002506
Iteration 141/1000 | Loss: 0.00002505
Iteration 142/1000 | Loss: 0.00002505
Iteration 143/1000 | Loss: 0.00002505
Iteration 144/1000 | Loss: 0.00002505
Iteration 145/1000 | Loss: 0.00002505
Iteration 146/1000 | Loss: 0.00002505
Iteration 147/1000 | Loss: 0.00002505
Iteration 148/1000 | Loss: 0.00002505
Iteration 149/1000 | Loss: 0.00002505
Iteration 150/1000 | Loss: 0.00002505
Iteration 151/1000 | Loss: 0.00002505
Iteration 152/1000 | Loss: 0.00002505
Iteration 153/1000 | Loss: 0.00002505
Iteration 154/1000 | Loss: 0.00002505
Iteration 155/1000 | Loss: 0.00002505
Iteration 156/1000 | Loss: 0.00002505
Iteration 157/1000 | Loss: 0.00002505
Iteration 158/1000 | Loss: 0.00002505
Iteration 159/1000 | Loss: 0.00002505
Iteration 160/1000 | Loss: 0.00002505
Iteration 161/1000 | Loss: 0.00002505
Iteration 162/1000 | Loss: 0.00002505
Iteration 163/1000 | Loss: 0.00002505
Iteration 164/1000 | Loss: 0.00002505
Iteration 165/1000 | Loss: 0.00002505
Iteration 166/1000 | Loss: 0.00002505
Iteration 167/1000 | Loss: 0.00002505
Iteration 168/1000 | Loss: 0.00002505
Iteration 169/1000 | Loss: 0.00002505
Iteration 170/1000 | Loss: 0.00002505
Iteration 171/1000 | Loss: 0.00002505
Iteration 172/1000 | Loss: 0.00002505
Iteration 173/1000 | Loss: 0.00002505
Iteration 174/1000 | Loss: 0.00002505
Iteration 175/1000 | Loss: 0.00002505
Iteration 176/1000 | Loss: 0.00002505
Iteration 177/1000 | Loss: 0.00002505
Iteration 178/1000 | Loss: 0.00002505
Iteration 179/1000 | Loss: 0.00002505
Iteration 180/1000 | Loss: 0.00002505
Iteration 181/1000 | Loss: 0.00002505
Iteration 182/1000 | Loss: 0.00002505
Iteration 183/1000 | Loss: 0.00002505
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 183. Stopping optimization.
Last 5 losses: [2.504683652659878e-05, 2.504683652659878e-05, 2.504683652659878e-05, 2.504683652659878e-05, 2.504683652659878e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.504683652659878e-05

Optimization complete. Final v2v error: 4.140117168426514 mm

Highest mean error: 5.42343282699585 mm for frame 222

Lowest mean error: 3.7415242195129395 mm for frame 200

Saving results

Total time: 80.64597201347351
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1077
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00808226
Iteration 2/25 | Loss: 0.00156602
Iteration 3/25 | Loss: 0.00098134
Iteration 4/25 | Loss: 0.00109417
Iteration 5/25 | Loss: 0.00086455
Iteration 6/25 | Loss: 0.00082392
Iteration 7/25 | Loss: 0.00081983
Iteration 8/25 | Loss: 0.00081886
Iteration 9/25 | Loss: 0.00081869
Iteration 10/25 | Loss: 0.00081859
Iteration 11/25 | Loss: 0.00081859
Iteration 12/25 | Loss: 0.00081859
Iteration 13/25 | Loss: 0.00081858
Iteration 14/25 | Loss: 0.00081858
Iteration 15/25 | Loss: 0.00081858
Iteration 16/25 | Loss: 0.00081858
Iteration 17/25 | Loss: 0.00081858
Iteration 18/25 | Loss: 0.00081858
Iteration 19/25 | Loss: 0.00081858
Iteration 20/25 | Loss: 0.00081858
Iteration 21/25 | Loss: 0.00081858
Iteration 22/25 | Loss: 0.00081857
Iteration 23/25 | Loss: 0.00081857
Iteration 24/25 | Loss: 0.00081857
Iteration 25/25 | Loss: 0.00081857

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.62680030
Iteration 2/25 | Loss: 0.00054728
Iteration 3/25 | Loss: 0.00054727
Iteration 4/25 | Loss: 0.00054727
Iteration 5/25 | Loss: 0.00054727
Iteration 6/25 | Loss: 0.00054727
Iteration 7/25 | Loss: 0.00054727
Iteration 8/25 | Loss: 0.00054727
Iteration 9/25 | Loss: 0.00054727
Iteration 10/25 | Loss: 0.00054727
Iteration 11/25 | Loss: 0.00054727
Iteration 12/25 | Loss: 0.00054727
Iteration 13/25 | Loss: 0.00054727
Iteration 14/25 | Loss: 0.00054727
Iteration 15/25 | Loss: 0.00054727
Iteration 16/25 | Loss: 0.00054727
Iteration 17/25 | Loss: 0.00054727
Iteration 18/25 | Loss: 0.00054727
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005472723860293627, 0.0005472723860293627, 0.0005472723860293627, 0.0005472723860293627, 0.0005472723860293627]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005472723860293627

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054727
Iteration 2/1000 | Loss: 0.00004059
Iteration 3/1000 | Loss: 0.00002855
Iteration 4/1000 | Loss: 0.00002500
Iteration 5/1000 | Loss: 0.00002321
Iteration 6/1000 | Loss: 0.00002209
Iteration 7/1000 | Loss: 0.00002151
Iteration 8/1000 | Loss: 0.00002092
Iteration 9/1000 | Loss: 0.00002050
Iteration 10/1000 | Loss: 0.00002027
Iteration 11/1000 | Loss: 0.00002009
Iteration 12/1000 | Loss: 0.00002005
Iteration 13/1000 | Loss: 0.00001991
Iteration 14/1000 | Loss: 0.00001976
Iteration 15/1000 | Loss: 0.00001967
Iteration 16/1000 | Loss: 0.00001964
Iteration 17/1000 | Loss: 0.00001963
Iteration 18/1000 | Loss: 0.00001962
Iteration 19/1000 | Loss: 0.00001961
Iteration 20/1000 | Loss: 0.00001959
Iteration 21/1000 | Loss: 0.00001958
Iteration 22/1000 | Loss: 0.00001958
Iteration 23/1000 | Loss: 0.00001957
Iteration 24/1000 | Loss: 0.00001956
Iteration 25/1000 | Loss: 0.00001956
Iteration 26/1000 | Loss: 0.00001955
Iteration 27/1000 | Loss: 0.00001955
Iteration 28/1000 | Loss: 0.00001955
Iteration 29/1000 | Loss: 0.00001954
Iteration 30/1000 | Loss: 0.00001954
Iteration 31/1000 | Loss: 0.00001954
Iteration 32/1000 | Loss: 0.00001954
Iteration 33/1000 | Loss: 0.00001954
Iteration 34/1000 | Loss: 0.00001954
Iteration 35/1000 | Loss: 0.00001953
Iteration 36/1000 | Loss: 0.00001953
Iteration 37/1000 | Loss: 0.00001953
Iteration 38/1000 | Loss: 0.00001952
Iteration 39/1000 | Loss: 0.00001952
Iteration 40/1000 | Loss: 0.00001952
Iteration 41/1000 | Loss: 0.00001952
Iteration 42/1000 | Loss: 0.00001952
Iteration 43/1000 | Loss: 0.00001952
Iteration 44/1000 | Loss: 0.00001951
Iteration 45/1000 | Loss: 0.00001951
Iteration 46/1000 | Loss: 0.00001951
Iteration 47/1000 | Loss: 0.00001951
Iteration 48/1000 | Loss: 0.00001951
Iteration 49/1000 | Loss: 0.00001951
Iteration 50/1000 | Loss: 0.00001951
Iteration 51/1000 | Loss: 0.00001950
Iteration 52/1000 | Loss: 0.00001950
Iteration 53/1000 | Loss: 0.00001950
Iteration 54/1000 | Loss: 0.00001950
Iteration 55/1000 | Loss: 0.00001950
Iteration 56/1000 | Loss: 0.00001950
Iteration 57/1000 | Loss: 0.00001949
Iteration 58/1000 | Loss: 0.00001949
Iteration 59/1000 | Loss: 0.00001949
Iteration 60/1000 | Loss: 0.00001949
Iteration 61/1000 | Loss: 0.00001949
Iteration 62/1000 | Loss: 0.00001949
Iteration 63/1000 | Loss: 0.00001949
Iteration 64/1000 | Loss: 0.00001949
Iteration 65/1000 | Loss: 0.00001949
Iteration 66/1000 | Loss: 0.00001948
Iteration 67/1000 | Loss: 0.00001948
Iteration 68/1000 | Loss: 0.00001948
Iteration 69/1000 | Loss: 0.00001948
Iteration 70/1000 | Loss: 0.00001948
Iteration 71/1000 | Loss: 0.00001948
Iteration 72/1000 | Loss: 0.00001947
Iteration 73/1000 | Loss: 0.00001947
Iteration 74/1000 | Loss: 0.00001947
Iteration 75/1000 | Loss: 0.00001946
Iteration 76/1000 | Loss: 0.00001946
Iteration 77/1000 | Loss: 0.00001946
Iteration 78/1000 | Loss: 0.00001946
Iteration 79/1000 | Loss: 0.00001946
Iteration 80/1000 | Loss: 0.00001946
Iteration 81/1000 | Loss: 0.00001946
Iteration 82/1000 | Loss: 0.00001946
Iteration 83/1000 | Loss: 0.00001945
Iteration 84/1000 | Loss: 0.00001945
Iteration 85/1000 | Loss: 0.00001945
Iteration 86/1000 | Loss: 0.00001945
Iteration 87/1000 | Loss: 0.00001945
Iteration 88/1000 | Loss: 0.00001945
Iteration 89/1000 | Loss: 0.00001945
Iteration 90/1000 | Loss: 0.00001945
Iteration 91/1000 | Loss: 0.00001945
Iteration 92/1000 | Loss: 0.00001945
Iteration 93/1000 | Loss: 0.00001945
Iteration 94/1000 | Loss: 0.00001945
Iteration 95/1000 | Loss: 0.00001945
Iteration 96/1000 | Loss: 0.00001945
Iteration 97/1000 | Loss: 0.00001945
Iteration 98/1000 | Loss: 0.00001945
Iteration 99/1000 | Loss: 0.00001945
Iteration 100/1000 | Loss: 0.00001945
Iteration 101/1000 | Loss: 0.00001945
Iteration 102/1000 | Loss: 0.00001945
Iteration 103/1000 | Loss: 0.00001945
Iteration 104/1000 | Loss: 0.00001945
Iteration 105/1000 | Loss: 0.00001945
Iteration 106/1000 | Loss: 0.00001945
Iteration 107/1000 | Loss: 0.00001945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.945072472153697e-05, 1.945072472153697e-05, 1.945072472153697e-05, 1.945072472153697e-05, 1.945072472153697e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.945072472153697e-05

Optimization complete. Final v2v error: 3.5992817878723145 mm

Highest mean error: 4.70165491104126 mm for frame 53

Lowest mean error: 2.8636209964752197 mm for frame 73

Saving results

Total time: 48.35365653038025
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1047/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1047.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1047
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00530939
Iteration 2/25 | Loss: 0.00117152
Iteration 3/25 | Loss: 0.00085505
Iteration 4/25 | Loss: 0.00081506
Iteration 5/25 | Loss: 0.00080453
Iteration 6/25 | Loss: 0.00080223
Iteration 7/25 | Loss: 0.00080183
Iteration 8/25 | Loss: 0.00080183
Iteration 9/25 | Loss: 0.00080183
Iteration 10/25 | Loss: 0.00080183
Iteration 11/25 | Loss: 0.00080183
Iteration 12/25 | Loss: 0.00080183
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008018321823328733, 0.0008018321823328733, 0.0008018321823328733, 0.0008018321823328733, 0.0008018321823328733]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008018321823328733

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47297180
Iteration 2/25 | Loss: 0.00048613
Iteration 3/25 | Loss: 0.00048611
Iteration 4/25 | Loss: 0.00048611
Iteration 5/25 | Loss: 0.00048611
Iteration 6/25 | Loss: 0.00048611
Iteration 7/25 | Loss: 0.00048611
Iteration 8/25 | Loss: 0.00048611
Iteration 9/25 | Loss: 0.00048611
Iteration 10/25 | Loss: 0.00048611
Iteration 11/25 | Loss: 0.00048611
Iteration 12/25 | Loss: 0.00048611
Iteration 13/25 | Loss: 0.00048611
Iteration 14/25 | Loss: 0.00048611
Iteration 15/25 | Loss: 0.00048611
Iteration 16/25 | Loss: 0.00048611
Iteration 17/25 | Loss: 0.00048611
Iteration 18/25 | Loss: 0.00048611
Iteration 19/25 | Loss: 0.00048611
Iteration 20/25 | Loss: 0.00048611
Iteration 21/25 | Loss: 0.00048611
Iteration 22/25 | Loss: 0.00048611
Iteration 23/25 | Loss: 0.00048611
Iteration 24/25 | Loss: 0.00048611
Iteration 25/25 | Loss: 0.00048611

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048611
Iteration 2/1000 | Loss: 0.00003443
Iteration 3/1000 | Loss: 0.00002583
Iteration 4/1000 | Loss: 0.00002346
Iteration 5/1000 | Loss: 0.00002208
Iteration 6/1000 | Loss: 0.00002125
Iteration 7/1000 | Loss: 0.00002063
Iteration 8/1000 | Loss: 0.00002023
Iteration 9/1000 | Loss: 0.00001998
Iteration 10/1000 | Loss: 0.00001977
Iteration 11/1000 | Loss: 0.00001964
Iteration 12/1000 | Loss: 0.00001960
Iteration 13/1000 | Loss: 0.00001953
Iteration 14/1000 | Loss: 0.00001947
Iteration 15/1000 | Loss: 0.00001946
Iteration 16/1000 | Loss: 0.00001946
Iteration 17/1000 | Loss: 0.00001942
Iteration 18/1000 | Loss: 0.00001941
Iteration 19/1000 | Loss: 0.00001939
Iteration 20/1000 | Loss: 0.00001938
Iteration 21/1000 | Loss: 0.00001938
Iteration 22/1000 | Loss: 0.00001937
Iteration 23/1000 | Loss: 0.00001936
Iteration 24/1000 | Loss: 0.00001933
Iteration 25/1000 | Loss: 0.00001933
Iteration 26/1000 | Loss: 0.00001933
Iteration 27/1000 | Loss: 0.00001933
Iteration 28/1000 | Loss: 0.00001933
Iteration 29/1000 | Loss: 0.00001933
Iteration 30/1000 | Loss: 0.00001933
Iteration 31/1000 | Loss: 0.00001932
Iteration 32/1000 | Loss: 0.00001932
Iteration 33/1000 | Loss: 0.00001932
Iteration 34/1000 | Loss: 0.00001931
Iteration 35/1000 | Loss: 0.00001931
Iteration 36/1000 | Loss: 0.00001931
Iteration 37/1000 | Loss: 0.00001931
Iteration 38/1000 | Loss: 0.00001931
Iteration 39/1000 | Loss: 0.00001930
Iteration 40/1000 | Loss: 0.00001930
Iteration 41/1000 | Loss: 0.00001930
Iteration 42/1000 | Loss: 0.00001930
Iteration 43/1000 | Loss: 0.00001930
Iteration 44/1000 | Loss: 0.00001930
Iteration 45/1000 | Loss: 0.00001929
Iteration 46/1000 | Loss: 0.00001929
Iteration 47/1000 | Loss: 0.00001929
Iteration 48/1000 | Loss: 0.00001929
Iteration 49/1000 | Loss: 0.00001929
Iteration 50/1000 | Loss: 0.00001929
Iteration 51/1000 | Loss: 0.00001929
Iteration 52/1000 | Loss: 0.00001929
Iteration 53/1000 | Loss: 0.00001928
Iteration 54/1000 | Loss: 0.00001928
Iteration 55/1000 | Loss: 0.00001928
Iteration 56/1000 | Loss: 0.00001928
Iteration 57/1000 | Loss: 0.00001928
Iteration 58/1000 | Loss: 0.00001928
Iteration 59/1000 | Loss: 0.00001928
Iteration 60/1000 | Loss: 0.00001927
Iteration 61/1000 | Loss: 0.00001927
Iteration 62/1000 | Loss: 0.00001927
Iteration 63/1000 | Loss: 0.00001927
Iteration 64/1000 | Loss: 0.00001927
Iteration 65/1000 | Loss: 0.00001926
Iteration 66/1000 | Loss: 0.00001926
Iteration 67/1000 | Loss: 0.00001926
Iteration 68/1000 | Loss: 0.00001926
Iteration 69/1000 | Loss: 0.00001925
Iteration 70/1000 | Loss: 0.00001925
Iteration 71/1000 | Loss: 0.00001925
Iteration 72/1000 | Loss: 0.00001925
Iteration 73/1000 | Loss: 0.00001925
Iteration 74/1000 | Loss: 0.00001925
Iteration 75/1000 | Loss: 0.00001925
Iteration 76/1000 | Loss: 0.00001925
Iteration 77/1000 | Loss: 0.00001925
Iteration 78/1000 | Loss: 0.00001925
Iteration 79/1000 | Loss: 0.00001925
Iteration 80/1000 | Loss: 0.00001924
Iteration 81/1000 | Loss: 0.00001924
Iteration 82/1000 | Loss: 0.00001924
Iteration 83/1000 | Loss: 0.00001924
Iteration 84/1000 | Loss: 0.00001924
Iteration 85/1000 | Loss: 0.00001923
Iteration 86/1000 | Loss: 0.00001923
Iteration 87/1000 | Loss: 0.00001923
Iteration 88/1000 | Loss: 0.00001923
Iteration 89/1000 | Loss: 0.00001922
Iteration 90/1000 | Loss: 0.00001922
Iteration 91/1000 | Loss: 0.00001922
Iteration 92/1000 | Loss: 0.00001922
Iteration 93/1000 | Loss: 0.00001922
Iteration 94/1000 | Loss: 0.00001922
Iteration 95/1000 | Loss: 0.00001921
Iteration 96/1000 | Loss: 0.00001921
Iteration 97/1000 | Loss: 0.00001921
Iteration 98/1000 | Loss: 0.00001921
Iteration 99/1000 | Loss: 0.00001921
Iteration 100/1000 | Loss: 0.00001921
Iteration 101/1000 | Loss: 0.00001921
Iteration 102/1000 | Loss: 0.00001920
Iteration 103/1000 | Loss: 0.00001920
Iteration 104/1000 | Loss: 0.00001920
Iteration 105/1000 | Loss: 0.00001920
Iteration 106/1000 | Loss: 0.00001920
Iteration 107/1000 | Loss: 0.00001920
Iteration 108/1000 | Loss: 0.00001919
Iteration 109/1000 | Loss: 0.00001919
Iteration 110/1000 | Loss: 0.00001919
Iteration 111/1000 | Loss: 0.00001919
Iteration 112/1000 | Loss: 0.00001919
Iteration 113/1000 | Loss: 0.00001919
Iteration 114/1000 | Loss: 0.00001919
Iteration 115/1000 | Loss: 0.00001919
Iteration 116/1000 | Loss: 0.00001919
Iteration 117/1000 | Loss: 0.00001919
Iteration 118/1000 | Loss: 0.00001919
Iteration 119/1000 | Loss: 0.00001918
Iteration 120/1000 | Loss: 0.00001918
Iteration 121/1000 | Loss: 0.00001918
Iteration 122/1000 | Loss: 0.00001918
Iteration 123/1000 | Loss: 0.00001918
Iteration 124/1000 | Loss: 0.00001917
Iteration 125/1000 | Loss: 0.00001917
Iteration 126/1000 | Loss: 0.00001917
Iteration 127/1000 | Loss: 0.00001917
Iteration 128/1000 | Loss: 0.00001917
Iteration 129/1000 | Loss: 0.00001916
Iteration 130/1000 | Loss: 0.00001916
Iteration 131/1000 | Loss: 0.00001916
Iteration 132/1000 | Loss: 0.00001916
Iteration 133/1000 | Loss: 0.00001916
Iteration 134/1000 | Loss: 0.00001916
Iteration 135/1000 | Loss: 0.00001916
Iteration 136/1000 | Loss: 0.00001916
Iteration 137/1000 | Loss: 0.00001916
Iteration 138/1000 | Loss: 0.00001916
Iteration 139/1000 | Loss: 0.00001916
Iteration 140/1000 | Loss: 0.00001916
Iteration 141/1000 | Loss: 0.00001916
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [1.916421388159506e-05, 1.916421388159506e-05, 1.916421388159506e-05, 1.916421388159506e-05, 1.916421388159506e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.916421388159506e-05

Optimization complete. Final v2v error: 3.6463446617126465 mm

Highest mean error: 3.982971429824829 mm for frame 80

Lowest mean error: 3.1948468685150146 mm for frame 103

Saving results

Total time: 35.96962380409241
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1059/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1059.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1059
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00819748
Iteration 2/25 | Loss: 0.00092081
Iteration 3/25 | Loss: 0.00077115
Iteration 4/25 | Loss: 0.00074044
Iteration 5/25 | Loss: 0.00073288
Iteration 6/25 | Loss: 0.00073065
Iteration 7/25 | Loss: 0.00072996
Iteration 8/25 | Loss: 0.00072995
Iteration 9/25 | Loss: 0.00072995
Iteration 10/25 | Loss: 0.00072995
Iteration 11/25 | Loss: 0.00072995
Iteration 12/25 | Loss: 0.00072995
Iteration 13/25 | Loss: 0.00072993
Iteration 14/25 | Loss: 0.00072993
Iteration 15/25 | Loss: 0.00072993
Iteration 16/25 | Loss: 0.00072993
Iteration 17/25 | Loss: 0.00072993
Iteration 18/25 | Loss: 0.00072993
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007299311691895127, 0.0007299311691895127, 0.0007299311691895127, 0.0007299311691895127, 0.0007299311691895127]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007299311691895127

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51417363
Iteration 2/25 | Loss: 0.00059081
Iteration 3/25 | Loss: 0.00059081
Iteration 4/25 | Loss: 0.00059081
Iteration 5/25 | Loss: 0.00059081
Iteration 6/25 | Loss: 0.00059081
Iteration 7/25 | Loss: 0.00059081
Iteration 8/25 | Loss: 0.00059081
Iteration 9/25 | Loss: 0.00059081
Iteration 10/25 | Loss: 0.00059081
Iteration 11/25 | Loss: 0.00059081
Iteration 12/25 | Loss: 0.00059081
Iteration 13/25 | Loss: 0.00059081
Iteration 14/25 | Loss: 0.00059081
Iteration 15/25 | Loss: 0.00059081
Iteration 16/25 | Loss: 0.00059081
Iteration 17/25 | Loss: 0.00059081
Iteration 18/25 | Loss: 0.00059081
Iteration 19/25 | Loss: 0.00059081
Iteration 20/25 | Loss: 0.00059081
Iteration 21/25 | Loss: 0.00059081
Iteration 22/25 | Loss: 0.00059081
Iteration 23/25 | Loss: 0.00059081
Iteration 24/25 | Loss: 0.00059081
Iteration 25/25 | Loss: 0.00059081

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059081
Iteration 2/1000 | Loss: 0.00003645
Iteration 3/1000 | Loss: 0.00002515
Iteration 4/1000 | Loss: 0.00002016
Iteration 5/1000 | Loss: 0.00001831
Iteration 6/1000 | Loss: 0.00001722
Iteration 7/1000 | Loss: 0.00001662
Iteration 8/1000 | Loss: 0.00001618
Iteration 9/1000 | Loss: 0.00001579
Iteration 10/1000 | Loss: 0.00001548
Iteration 11/1000 | Loss: 0.00001544
Iteration 12/1000 | Loss: 0.00001537
Iteration 13/1000 | Loss: 0.00001525
Iteration 14/1000 | Loss: 0.00001523
Iteration 15/1000 | Loss: 0.00001520
Iteration 16/1000 | Loss: 0.00001519
Iteration 17/1000 | Loss: 0.00001502
Iteration 18/1000 | Loss: 0.00001498
Iteration 19/1000 | Loss: 0.00001489
Iteration 20/1000 | Loss: 0.00001485
Iteration 21/1000 | Loss: 0.00001481
Iteration 22/1000 | Loss: 0.00001480
Iteration 23/1000 | Loss: 0.00001480
Iteration 24/1000 | Loss: 0.00001479
Iteration 25/1000 | Loss: 0.00001479
Iteration 26/1000 | Loss: 0.00001478
Iteration 27/1000 | Loss: 0.00001477
Iteration 28/1000 | Loss: 0.00001477
Iteration 29/1000 | Loss: 0.00001476
Iteration 30/1000 | Loss: 0.00001476
Iteration 31/1000 | Loss: 0.00001475
Iteration 32/1000 | Loss: 0.00001475
Iteration 33/1000 | Loss: 0.00001474
Iteration 34/1000 | Loss: 0.00001474
Iteration 35/1000 | Loss: 0.00001474
Iteration 36/1000 | Loss: 0.00001473
Iteration 37/1000 | Loss: 0.00001473
Iteration 38/1000 | Loss: 0.00001472
Iteration 39/1000 | Loss: 0.00001472
Iteration 40/1000 | Loss: 0.00001471
Iteration 41/1000 | Loss: 0.00001470
Iteration 42/1000 | Loss: 0.00001470
Iteration 43/1000 | Loss: 0.00001470
Iteration 44/1000 | Loss: 0.00001470
Iteration 45/1000 | Loss: 0.00001470
Iteration 46/1000 | Loss: 0.00001470
Iteration 47/1000 | Loss: 0.00001470
Iteration 48/1000 | Loss: 0.00001469
Iteration 49/1000 | Loss: 0.00001469
Iteration 50/1000 | Loss: 0.00001469
Iteration 51/1000 | Loss: 0.00001469
Iteration 52/1000 | Loss: 0.00001469
Iteration 53/1000 | Loss: 0.00001468
Iteration 54/1000 | Loss: 0.00001468
Iteration 55/1000 | Loss: 0.00001468
Iteration 56/1000 | Loss: 0.00001468
Iteration 57/1000 | Loss: 0.00001467
Iteration 58/1000 | Loss: 0.00001467
Iteration 59/1000 | Loss: 0.00001467
Iteration 60/1000 | Loss: 0.00001467
Iteration 61/1000 | Loss: 0.00001466
Iteration 62/1000 | Loss: 0.00001466
Iteration 63/1000 | Loss: 0.00001466
Iteration 64/1000 | Loss: 0.00001466
Iteration 65/1000 | Loss: 0.00001465
Iteration 66/1000 | Loss: 0.00001465
Iteration 67/1000 | Loss: 0.00001465
Iteration 68/1000 | Loss: 0.00001465
Iteration 69/1000 | Loss: 0.00001465
Iteration 70/1000 | Loss: 0.00001464
Iteration 71/1000 | Loss: 0.00001464
Iteration 72/1000 | Loss: 0.00001464
Iteration 73/1000 | Loss: 0.00001464
Iteration 74/1000 | Loss: 0.00001464
Iteration 75/1000 | Loss: 0.00001463
Iteration 76/1000 | Loss: 0.00001463
Iteration 77/1000 | Loss: 0.00001463
Iteration 78/1000 | Loss: 0.00001462
Iteration 79/1000 | Loss: 0.00001462
Iteration 80/1000 | Loss: 0.00001462
Iteration 81/1000 | Loss: 0.00001462
Iteration 82/1000 | Loss: 0.00001461
Iteration 83/1000 | Loss: 0.00001461
Iteration 84/1000 | Loss: 0.00001461
Iteration 85/1000 | Loss: 0.00001461
Iteration 86/1000 | Loss: 0.00001460
Iteration 87/1000 | Loss: 0.00001460
Iteration 88/1000 | Loss: 0.00001460
Iteration 89/1000 | Loss: 0.00001460
Iteration 90/1000 | Loss: 0.00001460
Iteration 91/1000 | Loss: 0.00001459
Iteration 92/1000 | Loss: 0.00001459
Iteration 93/1000 | Loss: 0.00001459
Iteration 94/1000 | Loss: 0.00001459
Iteration 95/1000 | Loss: 0.00001459
Iteration 96/1000 | Loss: 0.00001459
Iteration 97/1000 | Loss: 0.00001458
Iteration 98/1000 | Loss: 0.00001458
Iteration 99/1000 | Loss: 0.00001458
Iteration 100/1000 | Loss: 0.00001458
Iteration 101/1000 | Loss: 0.00001458
Iteration 102/1000 | Loss: 0.00001458
Iteration 103/1000 | Loss: 0.00001457
Iteration 104/1000 | Loss: 0.00001457
Iteration 105/1000 | Loss: 0.00001457
Iteration 106/1000 | Loss: 0.00001457
Iteration 107/1000 | Loss: 0.00001457
Iteration 108/1000 | Loss: 0.00001457
Iteration 109/1000 | Loss: 0.00001457
Iteration 110/1000 | Loss: 0.00001457
Iteration 111/1000 | Loss: 0.00001457
Iteration 112/1000 | Loss: 0.00001457
Iteration 113/1000 | Loss: 0.00001457
Iteration 114/1000 | Loss: 0.00001457
Iteration 115/1000 | Loss: 0.00001457
Iteration 116/1000 | Loss: 0.00001457
Iteration 117/1000 | Loss: 0.00001457
Iteration 118/1000 | Loss: 0.00001457
Iteration 119/1000 | Loss: 0.00001457
Iteration 120/1000 | Loss: 0.00001457
Iteration 121/1000 | Loss: 0.00001457
Iteration 122/1000 | Loss: 0.00001457
Iteration 123/1000 | Loss: 0.00001457
Iteration 124/1000 | Loss: 0.00001457
Iteration 125/1000 | Loss: 0.00001457
Iteration 126/1000 | Loss: 0.00001457
Iteration 127/1000 | Loss: 0.00001457
Iteration 128/1000 | Loss: 0.00001457
Iteration 129/1000 | Loss: 0.00001457
Iteration 130/1000 | Loss: 0.00001457
Iteration 131/1000 | Loss: 0.00001457
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.457111011404777e-05, 1.457111011404777e-05, 1.457111011404777e-05, 1.457111011404777e-05, 1.457111011404777e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.457111011404777e-05

Optimization complete. Final v2v error: 3.1656389236450195 mm

Highest mean error: 4.588052272796631 mm for frame 33

Lowest mean error: 2.5799238681793213 mm for frame 155

Saving results

Total time: 43.91751575469971
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01037154
Iteration 2/25 | Loss: 0.01037154
Iteration 3/25 | Loss: 0.01037154
Iteration 4/25 | Loss: 0.01037154
Iteration 5/25 | Loss: 0.01037153
Iteration 6/25 | Loss: 0.01037153
Iteration 7/25 | Loss: 0.01037153
Iteration 8/25 | Loss: 0.00293120
Iteration 9/25 | Loss: 0.00180314
Iteration 10/25 | Loss: 0.00186690
Iteration 11/25 | Loss: 0.00174933
Iteration 12/25 | Loss: 0.00162199
Iteration 13/25 | Loss: 0.00162241
Iteration 14/25 | Loss: 0.00153346
Iteration 15/25 | Loss: 0.00148893
Iteration 16/25 | Loss: 0.00147912
Iteration 17/25 | Loss: 0.00146483
Iteration 18/25 | Loss: 0.00145419
Iteration 19/25 | Loss: 0.00152583
Iteration 20/25 | Loss: 0.00157458
Iteration 21/25 | Loss: 0.00138928
Iteration 22/25 | Loss: 0.00127981
Iteration 23/25 | Loss: 0.00119494
Iteration 24/25 | Loss: 0.00115963
Iteration 25/25 | Loss: 0.00114108

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50573885
Iteration 2/25 | Loss: 0.00598155
Iteration 3/25 | Loss: 0.00187157
Iteration 4/25 | Loss: 0.00187157
Iteration 5/25 | Loss: 0.00187157
Iteration 6/25 | Loss: 0.00187157
Iteration 7/25 | Loss: 0.00187157
Iteration 8/25 | Loss: 0.00187157
Iteration 9/25 | Loss: 0.00187157
Iteration 10/25 | Loss: 0.00187157
Iteration 11/25 | Loss: 0.00187157
Iteration 12/25 | Loss: 0.00187157
Iteration 13/25 | Loss: 0.00187157
Iteration 14/25 | Loss: 0.00187157
Iteration 15/25 | Loss: 0.00187157
Iteration 16/25 | Loss: 0.00187157
Iteration 17/25 | Loss: 0.00187157
Iteration 18/25 | Loss: 0.00187157
Iteration 19/25 | Loss: 0.00187157
Iteration 20/25 | Loss: 0.00187157
Iteration 21/25 | Loss: 0.00187157
Iteration 22/25 | Loss: 0.00187157
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0018715676851570606, 0.0018715676851570606, 0.0018715676851570606, 0.0018715676851570606, 0.0018715676851570606]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018715676851570606

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00187157
Iteration 2/1000 | Loss: 0.00554304
Iteration 3/1000 | Loss: 0.00127701
Iteration 4/1000 | Loss: 0.00133881
Iteration 5/1000 | Loss: 0.00264958
Iteration 6/1000 | Loss: 0.00281340
Iteration 7/1000 | Loss: 0.00192474
Iteration 8/1000 | Loss: 0.00658182
Iteration 9/1000 | Loss: 0.00435479
Iteration 10/1000 | Loss: 0.00184229
Iteration 11/1000 | Loss: 0.00197819
Iteration 12/1000 | Loss: 0.00143994
Iteration 13/1000 | Loss: 0.00107746
Iteration 14/1000 | Loss: 0.00137299
Iteration 15/1000 | Loss: 0.00063341
Iteration 16/1000 | Loss: 0.00052155
Iteration 17/1000 | Loss: 0.00085895
Iteration 18/1000 | Loss: 0.00118715
Iteration 19/1000 | Loss: 0.00025874
Iteration 20/1000 | Loss: 0.00024245
Iteration 21/1000 | Loss: 0.00177767
Iteration 22/1000 | Loss: 0.00050328
Iteration 23/1000 | Loss: 0.00108530
Iteration 24/1000 | Loss: 0.00117305
Iteration 25/1000 | Loss: 0.00132627
Iteration 26/1000 | Loss: 0.00118152
Iteration 27/1000 | Loss: 0.00117010
Iteration 28/1000 | Loss: 0.00022997
Iteration 29/1000 | Loss: 0.00120198
Iteration 30/1000 | Loss: 0.00055303
Iteration 31/1000 | Loss: 0.00098695
Iteration 32/1000 | Loss: 0.00009138
Iteration 33/1000 | Loss: 0.00067502
Iteration 34/1000 | Loss: 0.00037277
Iteration 35/1000 | Loss: 0.00072218
Iteration 36/1000 | Loss: 0.00130948
Iteration 37/1000 | Loss: 0.00075253
Iteration 38/1000 | Loss: 0.00008573
Iteration 39/1000 | Loss: 0.00004711
Iteration 40/1000 | Loss: 0.00060584
Iteration 41/1000 | Loss: 0.00005015
Iteration 42/1000 | Loss: 0.00005724
Iteration 43/1000 | Loss: 0.00009902
Iteration 44/1000 | Loss: 0.00004890
Iteration 45/1000 | Loss: 0.00016366
Iteration 46/1000 | Loss: 0.00003532
Iteration 47/1000 | Loss: 0.00015460
Iteration 48/1000 | Loss: 0.00016634
Iteration 49/1000 | Loss: 0.00004531
Iteration 50/1000 | Loss: 0.00021288
Iteration 51/1000 | Loss: 0.00031617
Iteration 52/1000 | Loss: 0.00053179
Iteration 53/1000 | Loss: 0.00073963
Iteration 54/1000 | Loss: 0.00065653
Iteration 55/1000 | Loss: 0.00020319
Iteration 56/1000 | Loss: 0.00242036
Iteration 57/1000 | Loss: 0.00012308
Iteration 58/1000 | Loss: 0.00005076
Iteration 59/1000 | Loss: 0.00004078
Iteration 60/1000 | Loss: 0.00003870
Iteration 61/1000 | Loss: 0.00002589
Iteration 62/1000 | Loss: 0.00002331
Iteration 63/1000 | Loss: 0.00007012
Iteration 64/1000 | Loss: 0.00002021
Iteration 65/1000 | Loss: 0.00001968
Iteration 66/1000 | Loss: 0.00001907
Iteration 67/1000 | Loss: 0.00017375
Iteration 68/1000 | Loss: 0.00001848
Iteration 69/1000 | Loss: 0.00001803
Iteration 70/1000 | Loss: 0.00001789
Iteration 71/1000 | Loss: 0.00015277
Iteration 72/1000 | Loss: 0.00002264
Iteration 73/1000 | Loss: 0.00001939
Iteration 74/1000 | Loss: 0.00001772
Iteration 75/1000 | Loss: 0.00001762
Iteration 76/1000 | Loss: 0.00001761
Iteration 77/1000 | Loss: 0.00001760
Iteration 78/1000 | Loss: 0.00001759
Iteration 79/1000 | Loss: 0.00001742
Iteration 80/1000 | Loss: 0.00001724
Iteration 81/1000 | Loss: 0.00001720
Iteration 82/1000 | Loss: 0.00001718
Iteration 83/1000 | Loss: 0.00001718
Iteration 84/1000 | Loss: 0.00001716
Iteration 85/1000 | Loss: 0.00001714
Iteration 86/1000 | Loss: 0.00017386
Iteration 87/1000 | Loss: 0.00027517
Iteration 88/1000 | Loss: 0.00015838
Iteration 89/1000 | Loss: 0.00008116
Iteration 90/1000 | Loss: 0.00008389
Iteration 91/1000 | Loss: 0.00009644
Iteration 92/1000 | Loss: 0.00012753
Iteration 93/1000 | Loss: 0.00003103
Iteration 94/1000 | Loss: 0.00001985
Iteration 95/1000 | Loss: 0.00012564
Iteration 96/1000 | Loss: 0.00001896
Iteration 97/1000 | Loss: 0.00013472
Iteration 98/1000 | Loss: 0.00001776
Iteration 99/1000 | Loss: 0.00022442
Iteration 100/1000 | Loss: 0.00003147
Iteration 101/1000 | Loss: 0.00003863
Iteration 102/1000 | Loss: 0.00001597
Iteration 103/1000 | Loss: 0.00004281
Iteration 104/1000 | Loss: 0.00001582
Iteration 105/1000 | Loss: 0.00001558
Iteration 106/1000 | Loss: 0.00001552
Iteration 107/1000 | Loss: 0.00001552
Iteration 108/1000 | Loss: 0.00001552
Iteration 109/1000 | Loss: 0.00001552
Iteration 110/1000 | Loss: 0.00001552
Iteration 111/1000 | Loss: 0.00001552
Iteration 112/1000 | Loss: 0.00001552
Iteration 113/1000 | Loss: 0.00001552
Iteration 114/1000 | Loss: 0.00001552
Iteration 115/1000 | Loss: 0.00001552
Iteration 116/1000 | Loss: 0.00001551
Iteration 117/1000 | Loss: 0.00001551
Iteration 118/1000 | Loss: 0.00001548
Iteration 119/1000 | Loss: 0.00001548
Iteration 120/1000 | Loss: 0.00001548
Iteration 121/1000 | Loss: 0.00001548
Iteration 122/1000 | Loss: 0.00001548
Iteration 123/1000 | Loss: 0.00001548
Iteration 124/1000 | Loss: 0.00001548
Iteration 125/1000 | Loss: 0.00001548
Iteration 126/1000 | Loss: 0.00001548
Iteration 127/1000 | Loss: 0.00001548
Iteration 128/1000 | Loss: 0.00001547
Iteration 129/1000 | Loss: 0.00001547
Iteration 130/1000 | Loss: 0.00001544
Iteration 131/1000 | Loss: 0.00001543
Iteration 132/1000 | Loss: 0.00001543
Iteration 133/1000 | Loss: 0.00001542
Iteration 134/1000 | Loss: 0.00001542
Iteration 135/1000 | Loss: 0.00001538
Iteration 136/1000 | Loss: 0.00001538
Iteration 137/1000 | Loss: 0.00001538
Iteration 138/1000 | Loss: 0.00001538
Iteration 139/1000 | Loss: 0.00001538
Iteration 140/1000 | Loss: 0.00001538
Iteration 141/1000 | Loss: 0.00001538
Iteration 142/1000 | Loss: 0.00001537
Iteration 143/1000 | Loss: 0.00001537
Iteration 144/1000 | Loss: 0.00001537
Iteration 145/1000 | Loss: 0.00001537
Iteration 146/1000 | Loss: 0.00001537
Iteration 147/1000 | Loss: 0.00001536
Iteration 148/1000 | Loss: 0.00001536
Iteration 149/1000 | Loss: 0.00001536
Iteration 150/1000 | Loss: 0.00001535
Iteration 151/1000 | Loss: 0.00001535
Iteration 152/1000 | Loss: 0.00001534
Iteration 153/1000 | Loss: 0.00001534
Iteration 154/1000 | Loss: 0.00001534
Iteration 155/1000 | Loss: 0.00001534
Iteration 156/1000 | Loss: 0.00001534
Iteration 157/1000 | Loss: 0.00001533
Iteration 158/1000 | Loss: 0.00001533
Iteration 159/1000 | Loss: 0.00001533
Iteration 160/1000 | Loss: 0.00001533
Iteration 161/1000 | Loss: 0.00001532
Iteration 162/1000 | Loss: 0.00001532
Iteration 163/1000 | Loss: 0.00001532
Iteration 164/1000 | Loss: 0.00001532
Iteration 165/1000 | Loss: 0.00001532
Iteration 166/1000 | Loss: 0.00001531
Iteration 167/1000 | Loss: 0.00001531
Iteration 168/1000 | Loss: 0.00001531
Iteration 169/1000 | Loss: 0.00001531
Iteration 170/1000 | Loss: 0.00001531
Iteration 171/1000 | Loss: 0.00001531
Iteration 172/1000 | Loss: 0.00001531
Iteration 173/1000 | Loss: 0.00001531
Iteration 174/1000 | Loss: 0.00001531
Iteration 175/1000 | Loss: 0.00001531
Iteration 176/1000 | Loss: 0.00001531
Iteration 177/1000 | Loss: 0.00001530
Iteration 178/1000 | Loss: 0.00001530
Iteration 179/1000 | Loss: 0.00001530
Iteration 180/1000 | Loss: 0.00001530
Iteration 181/1000 | Loss: 0.00001530
Iteration 182/1000 | Loss: 0.00001530
Iteration 183/1000 | Loss: 0.00001530
Iteration 184/1000 | Loss: 0.00001530
Iteration 185/1000 | Loss: 0.00001530
Iteration 186/1000 | Loss: 0.00001529
Iteration 187/1000 | Loss: 0.00001529
Iteration 188/1000 | Loss: 0.00001529
Iteration 189/1000 | Loss: 0.00001529
Iteration 190/1000 | Loss: 0.00001529
Iteration 191/1000 | Loss: 0.00001529
Iteration 192/1000 | Loss: 0.00001529
Iteration 193/1000 | Loss: 0.00001529
Iteration 194/1000 | Loss: 0.00001529
Iteration 195/1000 | Loss: 0.00001529
Iteration 196/1000 | Loss: 0.00001528
Iteration 197/1000 | Loss: 0.00001528
Iteration 198/1000 | Loss: 0.00001528
Iteration 199/1000 | Loss: 0.00001528
Iteration 200/1000 | Loss: 0.00001528
Iteration 201/1000 | Loss: 0.00001527
Iteration 202/1000 | Loss: 0.00001527
Iteration 203/1000 | Loss: 0.00001527
Iteration 204/1000 | Loss: 0.00001527
Iteration 205/1000 | Loss: 0.00001527
Iteration 206/1000 | Loss: 0.00001527
Iteration 207/1000 | Loss: 0.00001527
Iteration 208/1000 | Loss: 0.00001527
Iteration 209/1000 | Loss: 0.00001526
Iteration 210/1000 | Loss: 0.00001526
Iteration 211/1000 | Loss: 0.00001526
Iteration 212/1000 | Loss: 0.00001526
Iteration 213/1000 | Loss: 0.00001526
Iteration 214/1000 | Loss: 0.00001526
Iteration 215/1000 | Loss: 0.00001526
Iteration 216/1000 | Loss: 0.00001526
Iteration 217/1000 | Loss: 0.00001526
Iteration 218/1000 | Loss: 0.00001526
Iteration 219/1000 | Loss: 0.00001526
Iteration 220/1000 | Loss: 0.00001526
Iteration 221/1000 | Loss: 0.00001526
Iteration 222/1000 | Loss: 0.00001526
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 222. Stopping optimization.
Last 5 losses: [1.5264931789715774e-05, 1.5264931789715774e-05, 1.5264931789715774e-05, 1.5264931789715774e-05, 1.5264931789715774e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5264931789715774e-05

Optimization complete. Final v2v error: 3.312095880508423 mm

Highest mean error: 5.151732921600342 mm for frame 40

Lowest mean error: 2.940377950668335 mm for frame 229

Saving results

Total time: 206.7890944480896
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1064/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1064.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1064
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01068427
Iteration 2/25 | Loss: 0.00161576
Iteration 3/25 | Loss: 0.00108458
Iteration 4/25 | Loss: 0.00098400
Iteration 5/25 | Loss: 0.00099719
Iteration 6/25 | Loss: 0.00098573
Iteration 7/25 | Loss: 0.00097343
Iteration 8/25 | Loss: 0.00089232
Iteration 9/25 | Loss: 0.00083450
Iteration 10/25 | Loss: 0.00080630
Iteration 11/25 | Loss: 0.00080208
Iteration 12/25 | Loss: 0.00080238
Iteration 13/25 | Loss: 0.00079842
Iteration 14/25 | Loss: 0.00085058
Iteration 15/25 | Loss: 0.00079736
Iteration 16/25 | Loss: 0.00078933
Iteration 17/25 | Loss: 0.00079409
Iteration 18/25 | Loss: 0.00079435
Iteration 19/25 | Loss: 0.00078415
Iteration 20/25 | Loss: 0.00077971
Iteration 21/25 | Loss: 0.00077579
Iteration 22/25 | Loss: 0.00077179
Iteration 23/25 | Loss: 0.00077090
Iteration 24/25 | Loss: 0.00081269
Iteration 25/25 | Loss: 0.00082036

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64979351
Iteration 2/25 | Loss: 0.00068478
Iteration 3/25 | Loss: 0.00063994
Iteration 4/25 | Loss: 0.00063994
Iteration 5/25 | Loss: 0.00063994
Iteration 6/25 | Loss: 0.00063994
Iteration 7/25 | Loss: 0.00063993
Iteration 8/25 | Loss: 0.00063993
Iteration 9/25 | Loss: 0.00063993
Iteration 10/25 | Loss: 0.00063993
Iteration 11/25 | Loss: 0.00063993
Iteration 12/25 | Loss: 0.00063993
Iteration 13/25 | Loss: 0.00063993
Iteration 14/25 | Loss: 0.00063993
Iteration 15/25 | Loss: 0.00063993
Iteration 16/25 | Loss: 0.00063993
Iteration 17/25 | Loss: 0.00063993
Iteration 18/25 | Loss: 0.00063993
Iteration 19/25 | Loss: 0.00063993
Iteration 20/25 | Loss: 0.00063993
Iteration 21/25 | Loss: 0.00063993
Iteration 22/25 | Loss: 0.00063993
Iteration 23/25 | Loss: 0.00063993
Iteration 24/25 | Loss: 0.00063993
Iteration 25/25 | Loss: 0.00063993
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0006399336270987988, 0.0006399336270987988, 0.0006399336270987988, 0.0006399336270987988, 0.0006399336270987988]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006399336270987988

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00063993
Iteration 2/1000 | Loss: 0.00009417
Iteration 3/1000 | Loss: 0.00004254
Iteration 4/1000 | Loss: 0.00003770
Iteration 5/1000 | Loss: 0.00248332
Iteration 6/1000 | Loss: 0.00272868
Iteration 7/1000 | Loss: 0.00429747
Iteration 8/1000 | Loss: 0.00229379
Iteration 9/1000 | Loss: 0.00029702
Iteration 10/1000 | Loss: 0.00010296
Iteration 11/1000 | Loss: 0.00004480
Iteration 12/1000 | Loss: 0.00003195
Iteration 13/1000 | Loss: 0.00032812
Iteration 14/1000 | Loss: 0.00024887
Iteration 15/1000 | Loss: 0.00049398
Iteration 16/1000 | Loss: 0.00003608
Iteration 17/1000 | Loss: 0.00002266
Iteration 18/1000 | Loss: 0.00002009
Iteration 19/1000 | Loss: 0.00001855
Iteration 20/1000 | Loss: 0.00001748
Iteration 21/1000 | Loss: 0.00051619
Iteration 22/1000 | Loss: 0.00004215
Iteration 23/1000 | Loss: 0.00002089
Iteration 24/1000 | Loss: 0.00001807
Iteration 25/1000 | Loss: 0.00001657
Iteration 26/1000 | Loss: 0.00001511
Iteration 27/1000 | Loss: 0.00001419
Iteration 28/1000 | Loss: 0.00001381
Iteration 29/1000 | Loss: 0.00001361
Iteration 30/1000 | Loss: 0.00001356
Iteration 31/1000 | Loss: 0.00001340
Iteration 32/1000 | Loss: 0.00001339
Iteration 33/1000 | Loss: 0.00001331
Iteration 34/1000 | Loss: 0.00001331
Iteration 35/1000 | Loss: 0.00001324
Iteration 36/1000 | Loss: 0.00001323
Iteration 37/1000 | Loss: 0.00001322
Iteration 38/1000 | Loss: 0.00001321
Iteration 39/1000 | Loss: 0.00001320
Iteration 40/1000 | Loss: 0.00001320
Iteration 41/1000 | Loss: 0.00001320
Iteration 42/1000 | Loss: 0.00001320
Iteration 43/1000 | Loss: 0.00001319
Iteration 44/1000 | Loss: 0.00001319
Iteration 45/1000 | Loss: 0.00001319
Iteration 46/1000 | Loss: 0.00001318
Iteration 47/1000 | Loss: 0.00001318
Iteration 48/1000 | Loss: 0.00001318
Iteration 49/1000 | Loss: 0.00001317
Iteration 50/1000 | Loss: 0.00001315
Iteration 51/1000 | Loss: 0.00001315
Iteration 52/1000 | Loss: 0.00001315
Iteration 53/1000 | Loss: 0.00001314
Iteration 54/1000 | Loss: 0.00001314
Iteration 55/1000 | Loss: 0.00001314
Iteration 56/1000 | Loss: 0.00001314
Iteration 57/1000 | Loss: 0.00001313
Iteration 58/1000 | Loss: 0.00001313
Iteration 59/1000 | Loss: 0.00001313
Iteration 60/1000 | Loss: 0.00001313
Iteration 61/1000 | Loss: 0.00001313
Iteration 62/1000 | Loss: 0.00001313
Iteration 63/1000 | Loss: 0.00001312
Iteration 64/1000 | Loss: 0.00001312
Iteration 65/1000 | Loss: 0.00001312
Iteration 66/1000 | Loss: 0.00001312
Iteration 67/1000 | Loss: 0.00001312
Iteration 68/1000 | Loss: 0.00001312
Iteration 69/1000 | Loss: 0.00001312
Iteration 70/1000 | Loss: 0.00001312
Iteration 71/1000 | Loss: 0.00001312
Iteration 72/1000 | Loss: 0.00001312
Iteration 73/1000 | Loss: 0.00001312
Iteration 74/1000 | Loss: 0.00001312
Iteration 75/1000 | Loss: 0.00001312
Iteration 76/1000 | Loss: 0.00001312
Iteration 77/1000 | Loss: 0.00001312
Iteration 78/1000 | Loss: 0.00001312
Iteration 79/1000 | Loss: 0.00001312
Iteration 80/1000 | Loss: 0.00001312
Iteration 81/1000 | Loss: 0.00001312
Iteration 82/1000 | Loss: 0.00001312
Iteration 83/1000 | Loss: 0.00001312
Iteration 84/1000 | Loss: 0.00001312
Iteration 85/1000 | Loss: 0.00001312
Iteration 86/1000 | Loss: 0.00001312
Iteration 87/1000 | Loss: 0.00001312
Iteration 88/1000 | Loss: 0.00001312
Iteration 89/1000 | Loss: 0.00001312
Iteration 90/1000 | Loss: 0.00001312
Iteration 91/1000 | Loss: 0.00001312
Iteration 92/1000 | Loss: 0.00001312
Iteration 93/1000 | Loss: 0.00001312
Iteration 94/1000 | Loss: 0.00001312
Iteration 95/1000 | Loss: 0.00001312
Iteration 96/1000 | Loss: 0.00001312
Iteration 97/1000 | Loss: 0.00001312
Iteration 98/1000 | Loss: 0.00001312
Iteration 99/1000 | Loss: 0.00001312
Iteration 100/1000 | Loss: 0.00001312
Iteration 101/1000 | Loss: 0.00001312
Iteration 102/1000 | Loss: 0.00001312
Iteration 103/1000 | Loss: 0.00001312
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.3115221008774824e-05, 1.3115221008774824e-05, 1.3115221008774824e-05, 1.3115221008774824e-05, 1.3115221008774824e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3115221008774824e-05

Optimization complete. Final v2v error: 2.9638845920562744 mm

Highest mean error: 5.740429401397705 mm for frame 93

Lowest mean error: 2.7329440116882324 mm for frame 34

Saving results

Total time: 95.63110136985779
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00751853
Iteration 2/25 | Loss: 0.00170788
Iteration 3/25 | Loss: 0.00115821
Iteration 4/25 | Loss: 0.00100803
Iteration 5/25 | Loss: 0.00096867
Iteration 6/25 | Loss: 0.00095225
Iteration 7/25 | Loss: 0.00093891
Iteration 8/25 | Loss: 0.00089212
Iteration 9/25 | Loss: 0.00086161
Iteration 10/25 | Loss: 0.00084957
Iteration 11/25 | Loss: 0.00084144
Iteration 12/25 | Loss: 0.00083571
Iteration 13/25 | Loss: 0.00083288
Iteration 14/25 | Loss: 0.00083720
Iteration 15/25 | Loss: 0.00083624
Iteration 16/25 | Loss: 0.00083146
Iteration 17/25 | Loss: 0.00083067
Iteration 18/25 | Loss: 0.00082919
Iteration 19/25 | Loss: 0.00082807
Iteration 20/25 | Loss: 0.00082654
Iteration 21/25 | Loss: 0.00082621
Iteration 22/25 | Loss: 0.00082739
Iteration 23/25 | Loss: 0.00082692
Iteration 24/25 | Loss: 0.00082610
Iteration 25/25 | Loss: 0.00082526

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.24840879
Iteration 2/25 | Loss: 0.00071182
Iteration 3/25 | Loss: 0.00071177
Iteration 4/25 | Loss: 0.00071177
Iteration 5/25 | Loss: 0.00071177
Iteration 6/25 | Loss: 0.00071177
Iteration 7/25 | Loss: 0.00071176
Iteration 8/25 | Loss: 0.00071176
Iteration 9/25 | Loss: 0.00071176
Iteration 10/25 | Loss: 0.00071176
Iteration 11/25 | Loss: 0.00071176
Iteration 12/25 | Loss: 0.00071176
Iteration 13/25 | Loss: 0.00071176
Iteration 14/25 | Loss: 0.00071176
Iteration 15/25 | Loss: 0.00071176
Iteration 16/25 | Loss: 0.00071176
Iteration 17/25 | Loss: 0.00071176
Iteration 18/25 | Loss: 0.00071176
Iteration 19/25 | Loss: 0.00071176
Iteration 20/25 | Loss: 0.00071176
Iteration 21/25 | Loss: 0.00071176
Iteration 22/25 | Loss: 0.00071176
Iteration 23/25 | Loss: 0.00071176
Iteration 24/25 | Loss: 0.00071176
Iteration 25/25 | Loss: 0.00071176

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071176
Iteration 2/1000 | Loss: 0.00009986
Iteration 3/1000 | Loss: 0.00005539
Iteration 4/1000 | Loss: 0.00003691
Iteration 5/1000 | Loss: 0.00003275
Iteration 6/1000 | Loss: 0.00003036
Iteration 7/1000 | Loss: 0.00002828
Iteration 8/1000 | Loss: 0.00002660
Iteration 9/1000 | Loss: 0.00002509
Iteration 10/1000 | Loss: 0.00027684
Iteration 11/1000 | Loss: 0.00031662
Iteration 12/1000 | Loss: 0.00038985
Iteration 13/1000 | Loss: 0.00004335
Iteration 14/1000 | Loss: 0.00002938
Iteration 15/1000 | Loss: 0.00002460
Iteration 16/1000 | Loss: 0.00002244
Iteration 17/1000 | Loss: 0.00002108
Iteration 18/1000 | Loss: 0.00002017
Iteration 19/1000 | Loss: 0.00001939
Iteration 20/1000 | Loss: 0.00001892
Iteration 21/1000 | Loss: 0.00001870
Iteration 22/1000 | Loss: 0.00001867
Iteration 23/1000 | Loss: 0.00001847
Iteration 24/1000 | Loss: 0.00001829
Iteration 25/1000 | Loss: 0.00001814
Iteration 26/1000 | Loss: 0.00001811
Iteration 27/1000 | Loss: 0.00001809
Iteration 28/1000 | Loss: 0.00001808
Iteration 29/1000 | Loss: 0.00001807
Iteration 30/1000 | Loss: 0.00001806
Iteration 31/1000 | Loss: 0.00001805
Iteration 32/1000 | Loss: 0.00001805
Iteration 33/1000 | Loss: 0.00001804
Iteration 34/1000 | Loss: 0.00001803
Iteration 35/1000 | Loss: 0.00001803
Iteration 36/1000 | Loss: 0.00001799
Iteration 37/1000 | Loss: 0.00001798
Iteration 38/1000 | Loss: 0.00001797
Iteration 39/1000 | Loss: 0.00001797
Iteration 40/1000 | Loss: 0.00001796
Iteration 41/1000 | Loss: 0.00001796
Iteration 42/1000 | Loss: 0.00001796
Iteration 43/1000 | Loss: 0.00001795
Iteration 44/1000 | Loss: 0.00001794
Iteration 45/1000 | Loss: 0.00001792
Iteration 46/1000 | Loss: 0.00001792
Iteration 47/1000 | Loss: 0.00001791
Iteration 48/1000 | Loss: 0.00001791
Iteration 49/1000 | Loss: 0.00001790
Iteration 50/1000 | Loss: 0.00001790
Iteration 51/1000 | Loss: 0.00001789
Iteration 52/1000 | Loss: 0.00001789
Iteration 53/1000 | Loss: 0.00001788
Iteration 54/1000 | Loss: 0.00001787
Iteration 55/1000 | Loss: 0.00001787
Iteration 56/1000 | Loss: 0.00001787
Iteration 57/1000 | Loss: 0.00001786
Iteration 58/1000 | Loss: 0.00001786
Iteration 59/1000 | Loss: 0.00001786
Iteration 60/1000 | Loss: 0.00001785
Iteration 61/1000 | Loss: 0.00001785
Iteration 62/1000 | Loss: 0.00001785
Iteration 63/1000 | Loss: 0.00001785
Iteration 64/1000 | Loss: 0.00001783
Iteration 65/1000 | Loss: 0.00001783
Iteration 66/1000 | Loss: 0.00001782
Iteration 67/1000 | Loss: 0.00001782
Iteration 68/1000 | Loss: 0.00001781
Iteration 69/1000 | Loss: 0.00001781
Iteration 70/1000 | Loss: 0.00001780
Iteration 71/1000 | Loss: 0.00001780
Iteration 72/1000 | Loss: 0.00001780
Iteration 73/1000 | Loss: 0.00001779
Iteration 74/1000 | Loss: 0.00001779
Iteration 75/1000 | Loss: 0.00001779
Iteration 76/1000 | Loss: 0.00001779
Iteration 77/1000 | Loss: 0.00001779
Iteration 78/1000 | Loss: 0.00001778
Iteration 79/1000 | Loss: 0.00001778
Iteration 80/1000 | Loss: 0.00001778
Iteration 81/1000 | Loss: 0.00001778
Iteration 82/1000 | Loss: 0.00001777
Iteration 83/1000 | Loss: 0.00001776
Iteration 84/1000 | Loss: 0.00001776
Iteration 85/1000 | Loss: 0.00001775
Iteration 86/1000 | Loss: 0.00001775
Iteration 87/1000 | Loss: 0.00001774
Iteration 88/1000 | Loss: 0.00001774
Iteration 89/1000 | Loss: 0.00001773
Iteration 90/1000 | Loss: 0.00001773
Iteration 91/1000 | Loss: 0.00001773
Iteration 92/1000 | Loss: 0.00001773
Iteration 93/1000 | Loss: 0.00001773
Iteration 94/1000 | Loss: 0.00001772
Iteration 95/1000 | Loss: 0.00001772
Iteration 96/1000 | Loss: 0.00001772
Iteration 97/1000 | Loss: 0.00001772
Iteration 98/1000 | Loss: 0.00001771
Iteration 99/1000 | Loss: 0.00001771
Iteration 100/1000 | Loss: 0.00001771
Iteration 101/1000 | Loss: 0.00001771
Iteration 102/1000 | Loss: 0.00001770
Iteration 103/1000 | Loss: 0.00001770
Iteration 104/1000 | Loss: 0.00001770
Iteration 105/1000 | Loss: 0.00001770
Iteration 106/1000 | Loss: 0.00001770
Iteration 107/1000 | Loss: 0.00001770
Iteration 108/1000 | Loss: 0.00001769
Iteration 109/1000 | Loss: 0.00001769
Iteration 110/1000 | Loss: 0.00001769
Iteration 111/1000 | Loss: 0.00001769
Iteration 112/1000 | Loss: 0.00001769
Iteration 113/1000 | Loss: 0.00001769
Iteration 114/1000 | Loss: 0.00001769
Iteration 115/1000 | Loss: 0.00001769
Iteration 116/1000 | Loss: 0.00001769
Iteration 117/1000 | Loss: 0.00001769
Iteration 118/1000 | Loss: 0.00001769
Iteration 119/1000 | Loss: 0.00001769
Iteration 120/1000 | Loss: 0.00001769
Iteration 121/1000 | Loss: 0.00001769
Iteration 122/1000 | Loss: 0.00001768
Iteration 123/1000 | Loss: 0.00001768
Iteration 124/1000 | Loss: 0.00001768
Iteration 125/1000 | Loss: 0.00001768
Iteration 126/1000 | Loss: 0.00001768
Iteration 127/1000 | Loss: 0.00001768
Iteration 128/1000 | Loss: 0.00001768
Iteration 129/1000 | Loss: 0.00001768
Iteration 130/1000 | Loss: 0.00001768
Iteration 131/1000 | Loss: 0.00001768
Iteration 132/1000 | Loss: 0.00001768
Iteration 133/1000 | Loss: 0.00001768
Iteration 134/1000 | Loss: 0.00001768
Iteration 135/1000 | Loss: 0.00001768
Iteration 136/1000 | Loss: 0.00001767
Iteration 137/1000 | Loss: 0.00001767
Iteration 138/1000 | Loss: 0.00001767
Iteration 139/1000 | Loss: 0.00001767
Iteration 140/1000 | Loss: 0.00001767
Iteration 141/1000 | Loss: 0.00001767
Iteration 142/1000 | Loss: 0.00001767
Iteration 143/1000 | Loss: 0.00001766
Iteration 144/1000 | Loss: 0.00001766
Iteration 145/1000 | Loss: 0.00001766
Iteration 146/1000 | Loss: 0.00001766
Iteration 147/1000 | Loss: 0.00001766
Iteration 148/1000 | Loss: 0.00001766
Iteration 149/1000 | Loss: 0.00001766
Iteration 150/1000 | Loss: 0.00001765
Iteration 151/1000 | Loss: 0.00001765
Iteration 152/1000 | Loss: 0.00001765
Iteration 153/1000 | Loss: 0.00001765
Iteration 154/1000 | Loss: 0.00001765
Iteration 155/1000 | Loss: 0.00001765
Iteration 156/1000 | Loss: 0.00001764
Iteration 157/1000 | Loss: 0.00001764
Iteration 158/1000 | Loss: 0.00001764
Iteration 159/1000 | Loss: 0.00001764
Iteration 160/1000 | Loss: 0.00001764
Iteration 161/1000 | Loss: 0.00001764
Iteration 162/1000 | Loss: 0.00001763
Iteration 163/1000 | Loss: 0.00001763
Iteration 164/1000 | Loss: 0.00001763
Iteration 165/1000 | Loss: 0.00001763
Iteration 166/1000 | Loss: 0.00001763
Iteration 167/1000 | Loss: 0.00001763
Iteration 168/1000 | Loss: 0.00001763
Iteration 169/1000 | Loss: 0.00001763
Iteration 170/1000 | Loss: 0.00001763
Iteration 171/1000 | Loss: 0.00001763
Iteration 172/1000 | Loss: 0.00001763
Iteration 173/1000 | Loss: 0.00001763
Iteration 174/1000 | Loss: 0.00001763
Iteration 175/1000 | Loss: 0.00001763
Iteration 176/1000 | Loss: 0.00001763
Iteration 177/1000 | Loss: 0.00001763
Iteration 178/1000 | Loss: 0.00001763
Iteration 179/1000 | Loss: 0.00001763
Iteration 180/1000 | Loss: 0.00001763
Iteration 181/1000 | Loss: 0.00001763
Iteration 182/1000 | Loss: 0.00001763
Iteration 183/1000 | Loss: 0.00001763
Iteration 184/1000 | Loss: 0.00001762
Iteration 185/1000 | Loss: 0.00001762
Iteration 186/1000 | Loss: 0.00001762
Iteration 187/1000 | Loss: 0.00001762
Iteration 188/1000 | Loss: 0.00001762
Iteration 189/1000 | Loss: 0.00001762
Iteration 190/1000 | Loss: 0.00001762
Iteration 191/1000 | Loss: 0.00001762
Iteration 192/1000 | Loss: 0.00001762
Iteration 193/1000 | Loss: 0.00001762
Iteration 194/1000 | Loss: 0.00001762
Iteration 195/1000 | Loss: 0.00001762
Iteration 196/1000 | Loss: 0.00001762
Iteration 197/1000 | Loss: 0.00001762
Iteration 198/1000 | Loss: 0.00001762
Iteration 199/1000 | Loss: 0.00001762
Iteration 200/1000 | Loss: 0.00001762
Iteration 201/1000 | Loss: 0.00001762
Iteration 202/1000 | Loss: 0.00001762
Iteration 203/1000 | Loss: 0.00001762
Iteration 204/1000 | Loss: 0.00001762
Iteration 205/1000 | Loss: 0.00001762
Iteration 206/1000 | Loss: 0.00001761
Iteration 207/1000 | Loss: 0.00001761
Iteration 208/1000 | Loss: 0.00001761
Iteration 209/1000 | Loss: 0.00001761
Iteration 210/1000 | Loss: 0.00001761
Iteration 211/1000 | Loss: 0.00001761
Iteration 212/1000 | Loss: 0.00001761
Iteration 213/1000 | Loss: 0.00001761
Iteration 214/1000 | Loss: 0.00001761
Iteration 215/1000 | Loss: 0.00001761
Iteration 216/1000 | Loss: 0.00001761
Iteration 217/1000 | Loss: 0.00001761
Iteration 218/1000 | Loss: 0.00001761
Iteration 219/1000 | Loss: 0.00001761
Iteration 220/1000 | Loss: 0.00001761
Iteration 221/1000 | Loss: 0.00001761
Iteration 222/1000 | Loss: 0.00001761
Iteration 223/1000 | Loss: 0.00001761
Iteration 224/1000 | Loss: 0.00001761
Iteration 225/1000 | Loss: 0.00001761
Iteration 226/1000 | Loss: 0.00001761
Iteration 227/1000 | Loss: 0.00001761
Iteration 228/1000 | Loss: 0.00001761
Iteration 229/1000 | Loss: 0.00001761
Iteration 230/1000 | Loss: 0.00001760
Iteration 231/1000 | Loss: 0.00001760
Iteration 232/1000 | Loss: 0.00001760
Iteration 233/1000 | Loss: 0.00001760
Iteration 234/1000 | Loss: 0.00001760
Iteration 235/1000 | Loss: 0.00001760
Iteration 236/1000 | Loss: 0.00001760
Iteration 237/1000 | Loss: 0.00001760
Iteration 238/1000 | Loss: 0.00001760
Iteration 239/1000 | Loss: 0.00001760
Iteration 240/1000 | Loss: 0.00001760
Iteration 241/1000 | Loss: 0.00001760
Iteration 242/1000 | Loss: 0.00001760
Iteration 243/1000 | Loss: 0.00001760
Iteration 244/1000 | Loss: 0.00001760
Iteration 245/1000 | Loss: 0.00001760
Iteration 246/1000 | Loss: 0.00001760
Iteration 247/1000 | Loss: 0.00001760
Iteration 248/1000 | Loss: 0.00001760
Iteration 249/1000 | Loss: 0.00001760
Iteration 250/1000 | Loss: 0.00001760
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 250. Stopping optimization.
Last 5 losses: [1.7603360902285203e-05, 1.7603360902285203e-05, 1.7603360902285203e-05, 1.7603360902285203e-05, 1.7603360902285203e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7603360902285203e-05

Optimization complete. Final v2v error: 3.4843709468841553 mm

Highest mean error: 5.1295342445373535 mm for frame 104

Lowest mean error: 2.654315710067749 mm for frame 146

Saving results

Total time: 109.05854868888855
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00921476
Iteration 2/25 | Loss: 0.00147707
Iteration 3/25 | Loss: 0.00103355
Iteration 4/25 | Loss: 0.00095379
Iteration 5/25 | Loss: 0.00091904
Iteration 6/25 | Loss: 0.00091087
Iteration 7/25 | Loss: 0.00090843
Iteration 8/25 | Loss: 0.00090763
Iteration 9/25 | Loss: 0.00090762
Iteration 10/25 | Loss: 0.00090762
Iteration 11/25 | Loss: 0.00090762
Iteration 12/25 | Loss: 0.00090762
Iteration 13/25 | Loss: 0.00090762
Iteration 14/25 | Loss: 0.00090762
Iteration 15/25 | Loss: 0.00090762
Iteration 16/25 | Loss: 0.00090762
Iteration 17/25 | Loss: 0.00090762
Iteration 18/25 | Loss: 0.00090762
Iteration 19/25 | Loss: 0.00090762
Iteration 20/25 | Loss: 0.00090762
Iteration 21/25 | Loss: 0.00090762
Iteration 22/25 | Loss: 0.00090762
Iteration 23/25 | Loss: 0.00090762
Iteration 24/25 | Loss: 0.00090762
Iteration 25/25 | Loss: 0.00090762

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48702002
Iteration 2/25 | Loss: 0.00052337
Iteration 3/25 | Loss: 0.00052337
Iteration 4/25 | Loss: 0.00052337
Iteration 5/25 | Loss: 0.00052337
Iteration 6/25 | Loss: 0.00052337
Iteration 7/25 | Loss: 0.00052337
Iteration 8/25 | Loss: 0.00052337
Iteration 9/25 | Loss: 0.00052337
Iteration 10/25 | Loss: 0.00052337
Iteration 11/25 | Loss: 0.00052337
Iteration 12/25 | Loss: 0.00052337
Iteration 13/25 | Loss: 0.00052337
Iteration 14/25 | Loss: 0.00052337
Iteration 15/25 | Loss: 0.00052337
Iteration 16/25 | Loss: 0.00052337
Iteration 17/25 | Loss: 0.00052337
Iteration 18/25 | Loss: 0.00052337
Iteration 19/25 | Loss: 0.00052337
Iteration 20/25 | Loss: 0.00052337
Iteration 21/25 | Loss: 0.00052337
Iteration 22/25 | Loss: 0.00052337
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005233719130046666, 0.0005233719130046666, 0.0005233719130046666, 0.0005233719130046666, 0.0005233719130046666]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005233719130046666

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052337
Iteration 2/1000 | Loss: 0.00007807
Iteration 3/1000 | Loss: 0.00005305
Iteration 4/1000 | Loss: 0.00004394
Iteration 5/1000 | Loss: 0.00004054
Iteration 6/1000 | Loss: 0.00003881
Iteration 7/1000 | Loss: 0.00003735
Iteration 8/1000 | Loss: 0.00003647
Iteration 9/1000 | Loss: 0.00003580
Iteration 10/1000 | Loss: 0.00003517
Iteration 11/1000 | Loss: 0.00003480
Iteration 12/1000 | Loss: 0.00003462
Iteration 13/1000 | Loss: 0.00003438
Iteration 14/1000 | Loss: 0.00003415
Iteration 15/1000 | Loss: 0.00003397
Iteration 16/1000 | Loss: 0.00003384
Iteration 17/1000 | Loss: 0.00003371
Iteration 18/1000 | Loss: 0.00003362
Iteration 19/1000 | Loss: 0.00003354
Iteration 20/1000 | Loss: 0.00003347
Iteration 21/1000 | Loss: 0.00003341
Iteration 22/1000 | Loss: 0.00003341
Iteration 23/1000 | Loss: 0.00003340
Iteration 24/1000 | Loss: 0.00003340
Iteration 25/1000 | Loss: 0.00003339
Iteration 26/1000 | Loss: 0.00003339
Iteration 27/1000 | Loss: 0.00003338
Iteration 28/1000 | Loss: 0.00003338
Iteration 29/1000 | Loss: 0.00003338
Iteration 30/1000 | Loss: 0.00003338
Iteration 31/1000 | Loss: 0.00003337
Iteration 32/1000 | Loss: 0.00003337
Iteration 33/1000 | Loss: 0.00003337
Iteration 34/1000 | Loss: 0.00003337
Iteration 35/1000 | Loss: 0.00003337
Iteration 36/1000 | Loss: 0.00003337
Iteration 37/1000 | Loss: 0.00003337
Iteration 38/1000 | Loss: 0.00003336
Iteration 39/1000 | Loss: 0.00003336
Iteration 40/1000 | Loss: 0.00003336
Iteration 41/1000 | Loss: 0.00003336
Iteration 42/1000 | Loss: 0.00003336
Iteration 43/1000 | Loss: 0.00003336
Iteration 44/1000 | Loss: 0.00003335
Iteration 45/1000 | Loss: 0.00003335
Iteration 46/1000 | Loss: 0.00003335
Iteration 47/1000 | Loss: 0.00003335
Iteration 48/1000 | Loss: 0.00003335
Iteration 49/1000 | Loss: 0.00003335
Iteration 50/1000 | Loss: 0.00003334
Iteration 51/1000 | Loss: 0.00003334
Iteration 52/1000 | Loss: 0.00003334
Iteration 53/1000 | Loss: 0.00003333
Iteration 54/1000 | Loss: 0.00003333
Iteration 55/1000 | Loss: 0.00003333
Iteration 56/1000 | Loss: 0.00003333
Iteration 57/1000 | Loss: 0.00003332
Iteration 58/1000 | Loss: 0.00003332
Iteration 59/1000 | Loss: 0.00003332
Iteration 60/1000 | Loss: 0.00003332
Iteration 61/1000 | Loss: 0.00003332
Iteration 62/1000 | Loss: 0.00003331
Iteration 63/1000 | Loss: 0.00003331
Iteration 64/1000 | Loss: 0.00003331
Iteration 65/1000 | Loss: 0.00003331
Iteration 66/1000 | Loss: 0.00003330
Iteration 67/1000 | Loss: 0.00003330
Iteration 68/1000 | Loss: 0.00003330
Iteration 69/1000 | Loss: 0.00003329
Iteration 70/1000 | Loss: 0.00003329
Iteration 71/1000 | Loss: 0.00003329
Iteration 72/1000 | Loss: 0.00003328
Iteration 73/1000 | Loss: 0.00003328
Iteration 74/1000 | Loss: 0.00003328
Iteration 75/1000 | Loss: 0.00003328
Iteration 76/1000 | Loss: 0.00003327
Iteration 77/1000 | Loss: 0.00003327
Iteration 78/1000 | Loss: 0.00003327
Iteration 79/1000 | Loss: 0.00003326
Iteration 80/1000 | Loss: 0.00003326
Iteration 81/1000 | Loss: 0.00003326
Iteration 82/1000 | Loss: 0.00003326
Iteration 83/1000 | Loss: 0.00003326
Iteration 84/1000 | Loss: 0.00003326
Iteration 85/1000 | Loss: 0.00003326
Iteration 86/1000 | Loss: 0.00003325
Iteration 87/1000 | Loss: 0.00003325
Iteration 88/1000 | Loss: 0.00003325
Iteration 89/1000 | Loss: 0.00003325
Iteration 90/1000 | Loss: 0.00003324
Iteration 91/1000 | Loss: 0.00003324
Iteration 92/1000 | Loss: 0.00003324
Iteration 93/1000 | Loss: 0.00003324
Iteration 94/1000 | Loss: 0.00003324
Iteration 95/1000 | Loss: 0.00003324
Iteration 96/1000 | Loss: 0.00003324
Iteration 97/1000 | Loss: 0.00003324
Iteration 98/1000 | Loss: 0.00003323
Iteration 99/1000 | Loss: 0.00003323
Iteration 100/1000 | Loss: 0.00003323
Iteration 101/1000 | Loss: 0.00003323
Iteration 102/1000 | Loss: 0.00003323
Iteration 103/1000 | Loss: 0.00003323
Iteration 104/1000 | Loss: 0.00003323
Iteration 105/1000 | Loss: 0.00003323
Iteration 106/1000 | Loss: 0.00003323
Iteration 107/1000 | Loss: 0.00003323
Iteration 108/1000 | Loss: 0.00003323
Iteration 109/1000 | Loss: 0.00003323
Iteration 110/1000 | Loss: 0.00003322
Iteration 111/1000 | Loss: 0.00003322
Iteration 112/1000 | Loss: 0.00003322
Iteration 113/1000 | Loss: 0.00003322
Iteration 114/1000 | Loss: 0.00003322
Iteration 115/1000 | Loss: 0.00003322
Iteration 116/1000 | Loss: 0.00003322
Iteration 117/1000 | Loss: 0.00003322
Iteration 118/1000 | Loss: 0.00003321
Iteration 119/1000 | Loss: 0.00003321
Iteration 120/1000 | Loss: 0.00003321
Iteration 121/1000 | Loss: 0.00003321
Iteration 122/1000 | Loss: 0.00003321
Iteration 123/1000 | Loss: 0.00003321
Iteration 124/1000 | Loss: 0.00003320
Iteration 125/1000 | Loss: 0.00003320
Iteration 126/1000 | Loss: 0.00003320
Iteration 127/1000 | Loss: 0.00003320
Iteration 128/1000 | Loss: 0.00003320
Iteration 129/1000 | Loss: 0.00003320
Iteration 130/1000 | Loss: 0.00003320
Iteration 131/1000 | Loss: 0.00003320
Iteration 132/1000 | Loss: 0.00003320
Iteration 133/1000 | Loss: 0.00003320
Iteration 134/1000 | Loss: 0.00003320
Iteration 135/1000 | Loss: 0.00003319
Iteration 136/1000 | Loss: 0.00003319
Iteration 137/1000 | Loss: 0.00003319
Iteration 138/1000 | Loss: 0.00003319
Iteration 139/1000 | Loss: 0.00003319
Iteration 140/1000 | Loss: 0.00003319
Iteration 141/1000 | Loss: 0.00003318
Iteration 142/1000 | Loss: 0.00003318
Iteration 143/1000 | Loss: 0.00003318
Iteration 144/1000 | Loss: 0.00003318
Iteration 145/1000 | Loss: 0.00003318
Iteration 146/1000 | Loss: 0.00003318
Iteration 147/1000 | Loss: 0.00003318
Iteration 148/1000 | Loss: 0.00003318
Iteration 149/1000 | Loss: 0.00003318
Iteration 150/1000 | Loss: 0.00003318
Iteration 151/1000 | Loss: 0.00003318
Iteration 152/1000 | Loss: 0.00003318
Iteration 153/1000 | Loss: 0.00003318
Iteration 154/1000 | Loss: 0.00003318
Iteration 155/1000 | Loss: 0.00003318
Iteration 156/1000 | Loss: 0.00003318
Iteration 157/1000 | Loss: 0.00003317
Iteration 158/1000 | Loss: 0.00003317
Iteration 159/1000 | Loss: 0.00003317
Iteration 160/1000 | Loss: 0.00003317
Iteration 161/1000 | Loss: 0.00003317
Iteration 162/1000 | Loss: 0.00003317
Iteration 163/1000 | Loss: 0.00003317
Iteration 164/1000 | Loss: 0.00003317
Iteration 165/1000 | Loss: 0.00003317
Iteration 166/1000 | Loss: 0.00003317
Iteration 167/1000 | Loss: 0.00003317
Iteration 168/1000 | Loss: 0.00003317
Iteration 169/1000 | Loss: 0.00003317
Iteration 170/1000 | Loss: 0.00003317
Iteration 171/1000 | Loss: 0.00003316
Iteration 172/1000 | Loss: 0.00003316
Iteration 173/1000 | Loss: 0.00003316
Iteration 174/1000 | Loss: 0.00003316
Iteration 175/1000 | Loss: 0.00003316
Iteration 176/1000 | Loss: 0.00003316
Iteration 177/1000 | Loss: 0.00003316
Iteration 178/1000 | Loss: 0.00003316
Iteration 179/1000 | Loss: 0.00003316
Iteration 180/1000 | Loss: 0.00003315
Iteration 181/1000 | Loss: 0.00003315
Iteration 182/1000 | Loss: 0.00003315
Iteration 183/1000 | Loss: 0.00003315
Iteration 184/1000 | Loss: 0.00003315
Iteration 185/1000 | Loss: 0.00003315
Iteration 186/1000 | Loss: 0.00003314
Iteration 187/1000 | Loss: 0.00003314
Iteration 188/1000 | Loss: 0.00003314
Iteration 189/1000 | Loss: 0.00003314
Iteration 190/1000 | Loss: 0.00003314
Iteration 191/1000 | Loss: 0.00003314
Iteration 192/1000 | Loss: 0.00003314
Iteration 193/1000 | Loss: 0.00003314
Iteration 194/1000 | Loss: 0.00003314
Iteration 195/1000 | Loss: 0.00003314
Iteration 196/1000 | Loss: 0.00003314
Iteration 197/1000 | Loss: 0.00003314
Iteration 198/1000 | Loss: 0.00003313
Iteration 199/1000 | Loss: 0.00003313
Iteration 200/1000 | Loss: 0.00003313
Iteration 201/1000 | Loss: 0.00003313
Iteration 202/1000 | Loss: 0.00003313
Iteration 203/1000 | Loss: 0.00003313
Iteration 204/1000 | Loss: 0.00003313
Iteration 205/1000 | Loss: 0.00003313
Iteration 206/1000 | Loss: 0.00003313
Iteration 207/1000 | Loss: 0.00003313
Iteration 208/1000 | Loss: 0.00003313
Iteration 209/1000 | Loss: 0.00003313
Iteration 210/1000 | Loss: 0.00003312
Iteration 211/1000 | Loss: 0.00003312
Iteration 212/1000 | Loss: 0.00003312
Iteration 213/1000 | Loss: 0.00003312
Iteration 214/1000 | Loss: 0.00003312
Iteration 215/1000 | Loss: 0.00003312
Iteration 216/1000 | Loss: 0.00003312
Iteration 217/1000 | Loss: 0.00003312
Iteration 218/1000 | Loss: 0.00003312
Iteration 219/1000 | Loss: 0.00003311
Iteration 220/1000 | Loss: 0.00003311
Iteration 221/1000 | Loss: 0.00003311
Iteration 222/1000 | Loss: 0.00003311
Iteration 223/1000 | Loss: 0.00003311
Iteration 224/1000 | Loss: 0.00003311
Iteration 225/1000 | Loss: 0.00003311
Iteration 226/1000 | Loss: 0.00003311
Iteration 227/1000 | Loss: 0.00003311
Iteration 228/1000 | Loss: 0.00003311
Iteration 229/1000 | Loss: 0.00003311
Iteration 230/1000 | Loss: 0.00003311
Iteration 231/1000 | Loss: 0.00003311
Iteration 232/1000 | Loss: 0.00003311
Iteration 233/1000 | Loss: 0.00003311
Iteration 234/1000 | Loss: 0.00003311
Iteration 235/1000 | Loss: 0.00003311
Iteration 236/1000 | Loss: 0.00003311
Iteration 237/1000 | Loss: 0.00003311
Iteration 238/1000 | Loss: 0.00003311
Iteration 239/1000 | Loss: 0.00003311
Iteration 240/1000 | Loss: 0.00003311
Iteration 241/1000 | Loss: 0.00003311
Iteration 242/1000 | Loss: 0.00003311
Iteration 243/1000 | Loss: 0.00003311
Iteration 244/1000 | Loss: 0.00003311
Iteration 245/1000 | Loss: 0.00003311
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 245. Stopping optimization.
Last 5 losses: [3.3108437492046505e-05, 3.3108437492046505e-05, 3.3108437492046505e-05, 3.3108437492046505e-05, 3.3108437492046505e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.3108437492046505e-05

Optimization complete. Final v2v error: 4.6286115646362305 mm

Highest mean error: 7.510197162628174 mm for frame 117

Lowest mean error: 3.2093706130981445 mm for frame 3

Saving results

Total time: 55.62915515899658
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1065/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1065.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1065
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00413357
Iteration 2/25 | Loss: 0.00099228
Iteration 3/25 | Loss: 0.00084579
Iteration 4/25 | Loss: 0.00081982
Iteration 5/25 | Loss: 0.00081609
Iteration 6/25 | Loss: 0.00081541
Iteration 7/25 | Loss: 0.00081529
Iteration 8/25 | Loss: 0.00081529
Iteration 9/25 | Loss: 0.00081529
Iteration 10/25 | Loss: 0.00081529
Iteration 11/25 | Loss: 0.00081529
Iteration 12/25 | Loss: 0.00081529
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008152897353284061, 0.0008152897353284061, 0.0008152897353284061, 0.0008152897353284061, 0.0008152897353284061]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008152897353284061

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49807775
Iteration 2/25 | Loss: 0.00049395
Iteration 3/25 | Loss: 0.00049395
Iteration 4/25 | Loss: 0.00049395
Iteration 5/25 | Loss: 0.00049395
Iteration 6/25 | Loss: 0.00049395
Iteration 7/25 | Loss: 0.00049395
Iteration 8/25 | Loss: 0.00049395
Iteration 9/25 | Loss: 0.00049395
Iteration 10/25 | Loss: 0.00049395
Iteration 11/25 | Loss: 0.00049395
Iteration 12/25 | Loss: 0.00049395
Iteration 13/25 | Loss: 0.00049395
Iteration 14/25 | Loss: 0.00049395
Iteration 15/25 | Loss: 0.00049395
Iteration 16/25 | Loss: 0.00049395
Iteration 17/25 | Loss: 0.00049395
Iteration 18/25 | Loss: 0.00049395
Iteration 19/25 | Loss: 0.00049395
Iteration 20/25 | Loss: 0.00049395
Iteration 21/25 | Loss: 0.00049395
Iteration 22/25 | Loss: 0.00049395
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0004939480568282306, 0.0004939480568282306, 0.0004939480568282306, 0.0004939480568282306, 0.0004939480568282306]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004939480568282306

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049395
Iteration 2/1000 | Loss: 0.00004990
Iteration 3/1000 | Loss: 0.00003228
Iteration 4/1000 | Loss: 0.00002980
Iteration 5/1000 | Loss: 0.00002843
Iteration 6/1000 | Loss: 0.00002736
Iteration 7/1000 | Loss: 0.00002688
Iteration 8/1000 | Loss: 0.00002630
Iteration 9/1000 | Loss: 0.00002597
Iteration 10/1000 | Loss: 0.00002573
Iteration 11/1000 | Loss: 0.00002553
Iteration 12/1000 | Loss: 0.00002549
Iteration 13/1000 | Loss: 0.00002532
Iteration 14/1000 | Loss: 0.00002528
Iteration 15/1000 | Loss: 0.00002525
Iteration 16/1000 | Loss: 0.00002524
Iteration 17/1000 | Loss: 0.00002524
Iteration 18/1000 | Loss: 0.00002523
Iteration 19/1000 | Loss: 0.00002522
Iteration 20/1000 | Loss: 0.00002522
Iteration 21/1000 | Loss: 0.00002521
Iteration 22/1000 | Loss: 0.00002519
Iteration 23/1000 | Loss: 0.00002519
Iteration 24/1000 | Loss: 0.00002516
Iteration 25/1000 | Loss: 0.00002513
Iteration 26/1000 | Loss: 0.00002512
Iteration 27/1000 | Loss: 0.00002512
Iteration 28/1000 | Loss: 0.00002500
Iteration 29/1000 | Loss: 0.00002498
Iteration 30/1000 | Loss: 0.00002497
Iteration 31/1000 | Loss: 0.00002497
Iteration 32/1000 | Loss: 0.00002494
Iteration 33/1000 | Loss: 0.00002494
Iteration 34/1000 | Loss: 0.00002493
Iteration 35/1000 | Loss: 0.00002493
Iteration 36/1000 | Loss: 0.00002493
Iteration 37/1000 | Loss: 0.00002493
Iteration 38/1000 | Loss: 0.00002492
Iteration 39/1000 | Loss: 0.00002492
Iteration 40/1000 | Loss: 0.00002492
Iteration 41/1000 | Loss: 0.00002492
Iteration 42/1000 | Loss: 0.00002492
Iteration 43/1000 | Loss: 0.00002491
Iteration 44/1000 | Loss: 0.00002491
Iteration 45/1000 | Loss: 0.00002490
Iteration 46/1000 | Loss: 0.00002490
Iteration 47/1000 | Loss: 0.00002490
Iteration 48/1000 | Loss: 0.00002490
Iteration 49/1000 | Loss: 0.00002490
Iteration 50/1000 | Loss: 0.00002489
Iteration 51/1000 | Loss: 0.00002489
Iteration 52/1000 | Loss: 0.00002489
Iteration 53/1000 | Loss: 0.00002489
Iteration 54/1000 | Loss: 0.00002489
Iteration 55/1000 | Loss: 0.00002488
Iteration 56/1000 | Loss: 0.00002488
Iteration 57/1000 | Loss: 0.00002488
Iteration 58/1000 | Loss: 0.00002488
Iteration 59/1000 | Loss: 0.00002487
Iteration 60/1000 | Loss: 0.00002487
Iteration 61/1000 | Loss: 0.00002487
Iteration 62/1000 | Loss: 0.00002487
Iteration 63/1000 | Loss: 0.00002487
Iteration 64/1000 | Loss: 0.00002487
Iteration 65/1000 | Loss: 0.00002487
Iteration 66/1000 | Loss: 0.00002487
Iteration 67/1000 | Loss: 0.00002487
Iteration 68/1000 | Loss: 0.00002487
Iteration 69/1000 | Loss: 0.00002487
Iteration 70/1000 | Loss: 0.00002487
Iteration 71/1000 | Loss: 0.00002487
Iteration 72/1000 | Loss: 0.00002487
Iteration 73/1000 | Loss: 0.00002487
Iteration 74/1000 | Loss: 0.00002487
Iteration 75/1000 | Loss: 0.00002487
Iteration 76/1000 | Loss: 0.00002487
Iteration 77/1000 | Loss: 0.00002487
Iteration 78/1000 | Loss: 0.00002487
Iteration 79/1000 | Loss: 0.00002487
Iteration 80/1000 | Loss: 0.00002487
Iteration 81/1000 | Loss: 0.00002487
Iteration 82/1000 | Loss: 0.00002487
Iteration 83/1000 | Loss: 0.00002487
Iteration 84/1000 | Loss: 0.00002487
Iteration 85/1000 | Loss: 0.00002487
Iteration 86/1000 | Loss: 0.00002487
Iteration 87/1000 | Loss: 0.00002487
Iteration 88/1000 | Loss: 0.00002487
Iteration 89/1000 | Loss: 0.00002487
Iteration 90/1000 | Loss: 0.00002487
Iteration 91/1000 | Loss: 0.00002487
Iteration 92/1000 | Loss: 0.00002487
Iteration 93/1000 | Loss: 0.00002487
Iteration 94/1000 | Loss: 0.00002487
Iteration 95/1000 | Loss: 0.00002487
Iteration 96/1000 | Loss: 0.00002487
Iteration 97/1000 | Loss: 0.00002487
Iteration 98/1000 | Loss: 0.00002487
Iteration 99/1000 | Loss: 0.00002487
Iteration 100/1000 | Loss: 0.00002487
Iteration 101/1000 | Loss: 0.00002487
Iteration 102/1000 | Loss: 0.00002487
Iteration 103/1000 | Loss: 0.00002487
Iteration 104/1000 | Loss: 0.00002487
Iteration 105/1000 | Loss: 0.00002487
Iteration 106/1000 | Loss: 0.00002487
Iteration 107/1000 | Loss: 0.00002487
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [2.4868651962606236e-05, 2.4868651962606236e-05, 2.4868651962606236e-05, 2.4868651962606236e-05, 2.4868651962606236e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4868651962606236e-05

Optimization complete. Final v2v error: 4.13665246963501 mm

Highest mean error: 4.52852725982666 mm for frame 14

Lowest mean error: 3.7494726181030273 mm for frame 33

Saving results

Total time: 34.891470432281494
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1069/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1069.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1069
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00526965
Iteration 2/25 | Loss: 0.00085397
Iteration 3/25 | Loss: 0.00076124
Iteration 4/25 | Loss: 0.00074517
Iteration 5/25 | Loss: 0.00074019
Iteration 6/25 | Loss: 0.00073890
Iteration 7/25 | Loss: 0.00073886
Iteration 8/25 | Loss: 0.00073886
Iteration 9/25 | Loss: 0.00073886
Iteration 10/25 | Loss: 0.00073886
Iteration 11/25 | Loss: 0.00073886
Iteration 12/25 | Loss: 0.00073886
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007388560916297138, 0.0007388560916297138, 0.0007388560916297138, 0.0007388560916297138, 0.0007388560916297138]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007388560916297138

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 18.77604485
Iteration 2/25 | Loss: 0.00054465
Iteration 3/25 | Loss: 0.00054456
Iteration 4/25 | Loss: 0.00054456
Iteration 5/25 | Loss: 0.00054456
Iteration 6/25 | Loss: 0.00054456
Iteration 7/25 | Loss: 0.00054456
Iteration 8/25 | Loss: 0.00054456
Iteration 9/25 | Loss: 0.00054456
Iteration 10/25 | Loss: 0.00054456
Iteration 11/25 | Loss: 0.00054456
Iteration 12/25 | Loss: 0.00054456
Iteration 13/25 | Loss: 0.00054456
Iteration 14/25 | Loss: 0.00054456
Iteration 15/25 | Loss: 0.00054456
Iteration 16/25 | Loss: 0.00054456
Iteration 17/25 | Loss: 0.00054456
Iteration 18/25 | Loss: 0.00054456
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005445589777082205, 0.0005445589777082205, 0.0005445589777082205, 0.0005445589777082205, 0.0005445589777082205]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005445589777082205

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054456
Iteration 2/1000 | Loss: 0.00002089
Iteration 3/1000 | Loss: 0.00001565
Iteration 4/1000 | Loss: 0.00001435
Iteration 5/1000 | Loss: 0.00001355
Iteration 6/1000 | Loss: 0.00001316
Iteration 7/1000 | Loss: 0.00001295
Iteration 8/1000 | Loss: 0.00001288
Iteration 9/1000 | Loss: 0.00001276
Iteration 10/1000 | Loss: 0.00001264
Iteration 11/1000 | Loss: 0.00001248
Iteration 12/1000 | Loss: 0.00001248
Iteration 13/1000 | Loss: 0.00001241
Iteration 14/1000 | Loss: 0.00001238
Iteration 15/1000 | Loss: 0.00001237
Iteration 16/1000 | Loss: 0.00001232
Iteration 17/1000 | Loss: 0.00001230
Iteration 18/1000 | Loss: 0.00001229
Iteration 19/1000 | Loss: 0.00001228
Iteration 20/1000 | Loss: 0.00001228
Iteration 21/1000 | Loss: 0.00001227
Iteration 22/1000 | Loss: 0.00001227
Iteration 23/1000 | Loss: 0.00001227
Iteration 24/1000 | Loss: 0.00001227
Iteration 25/1000 | Loss: 0.00001226
Iteration 26/1000 | Loss: 0.00001226
Iteration 27/1000 | Loss: 0.00001226
Iteration 28/1000 | Loss: 0.00001225
Iteration 29/1000 | Loss: 0.00001224
Iteration 30/1000 | Loss: 0.00001224
Iteration 31/1000 | Loss: 0.00001224
Iteration 32/1000 | Loss: 0.00001224
Iteration 33/1000 | Loss: 0.00001224
Iteration 34/1000 | Loss: 0.00001224
Iteration 35/1000 | Loss: 0.00001224
Iteration 36/1000 | Loss: 0.00001224
Iteration 37/1000 | Loss: 0.00001224
Iteration 38/1000 | Loss: 0.00001223
Iteration 39/1000 | Loss: 0.00001223
Iteration 40/1000 | Loss: 0.00001223
Iteration 41/1000 | Loss: 0.00001222
Iteration 42/1000 | Loss: 0.00001222
Iteration 43/1000 | Loss: 0.00001221
Iteration 44/1000 | Loss: 0.00001221
Iteration 45/1000 | Loss: 0.00001221
Iteration 46/1000 | Loss: 0.00001220
Iteration 47/1000 | Loss: 0.00001220
Iteration 48/1000 | Loss: 0.00001220
Iteration 49/1000 | Loss: 0.00001220
Iteration 50/1000 | Loss: 0.00001219
Iteration 51/1000 | Loss: 0.00001219
Iteration 52/1000 | Loss: 0.00001219
Iteration 53/1000 | Loss: 0.00001219
Iteration 54/1000 | Loss: 0.00001219
Iteration 55/1000 | Loss: 0.00001219
Iteration 56/1000 | Loss: 0.00001219
Iteration 57/1000 | Loss: 0.00001219
Iteration 58/1000 | Loss: 0.00001219
Iteration 59/1000 | Loss: 0.00001219
Iteration 60/1000 | Loss: 0.00001219
Iteration 61/1000 | Loss: 0.00001219
Iteration 62/1000 | Loss: 0.00001218
Iteration 63/1000 | Loss: 0.00001218
Iteration 64/1000 | Loss: 0.00001217
Iteration 65/1000 | Loss: 0.00001216
Iteration 66/1000 | Loss: 0.00001216
Iteration 67/1000 | Loss: 0.00001215
Iteration 68/1000 | Loss: 0.00001215
Iteration 69/1000 | Loss: 0.00001214
Iteration 70/1000 | Loss: 0.00001212
Iteration 71/1000 | Loss: 0.00001212
Iteration 72/1000 | Loss: 0.00001212
Iteration 73/1000 | Loss: 0.00001211
Iteration 74/1000 | Loss: 0.00001211
Iteration 75/1000 | Loss: 0.00001211
Iteration 76/1000 | Loss: 0.00001211
Iteration 77/1000 | Loss: 0.00001211
Iteration 78/1000 | Loss: 0.00001210
Iteration 79/1000 | Loss: 0.00001209
Iteration 80/1000 | Loss: 0.00001209
Iteration 81/1000 | Loss: 0.00001209
Iteration 82/1000 | Loss: 0.00001208
Iteration 83/1000 | Loss: 0.00001208
Iteration 84/1000 | Loss: 0.00001208
Iteration 85/1000 | Loss: 0.00001208
Iteration 86/1000 | Loss: 0.00001207
Iteration 87/1000 | Loss: 0.00001207
Iteration 88/1000 | Loss: 0.00001207
Iteration 89/1000 | Loss: 0.00001207
Iteration 90/1000 | Loss: 0.00001207
Iteration 91/1000 | Loss: 0.00001207
Iteration 92/1000 | Loss: 0.00001206
Iteration 93/1000 | Loss: 0.00001206
Iteration 94/1000 | Loss: 0.00001206
Iteration 95/1000 | Loss: 0.00001206
Iteration 96/1000 | Loss: 0.00001206
Iteration 97/1000 | Loss: 0.00001206
Iteration 98/1000 | Loss: 0.00001206
Iteration 99/1000 | Loss: 0.00001206
Iteration 100/1000 | Loss: 0.00001205
Iteration 101/1000 | Loss: 0.00001205
Iteration 102/1000 | Loss: 0.00001205
Iteration 103/1000 | Loss: 0.00001205
Iteration 104/1000 | Loss: 0.00001205
Iteration 105/1000 | Loss: 0.00001205
Iteration 106/1000 | Loss: 0.00001205
Iteration 107/1000 | Loss: 0.00001205
Iteration 108/1000 | Loss: 0.00001204
Iteration 109/1000 | Loss: 0.00001204
Iteration 110/1000 | Loss: 0.00001204
Iteration 111/1000 | Loss: 0.00001204
Iteration 112/1000 | Loss: 0.00001204
Iteration 113/1000 | Loss: 0.00001204
Iteration 114/1000 | Loss: 0.00001204
Iteration 115/1000 | Loss: 0.00001204
Iteration 116/1000 | Loss: 0.00001203
Iteration 117/1000 | Loss: 0.00001203
Iteration 118/1000 | Loss: 0.00001203
Iteration 119/1000 | Loss: 0.00001203
Iteration 120/1000 | Loss: 0.00001203
Iteration 121/1000 | Loss: 0.00001203
Iteration 122/1000 | Loss: 0.00001203
Iteration 123/1000 | Loss: 0.00001203
Iteration 124/1000 | Loss: 0.00001203
Iteration 125/1000 | Loss: 0.00001203
Iteration 126/1000 | Loss: 0.00001203
Iteration 127/1000 | Loss: 0.00001202
Iteration 128/1000 | Loss: 0.00001202
Iteration 129/1000 | Loss: 0.00001202
Iteration 130/1000 | Loss: 0.00001202
Iteration 131/1000 | Loss: 0.00001202
Iteration 132/1000 | Loss: 0.00001202
Iteration 133/1000 | Loss: 0.00001202
Iteration 134/1000 | Loss: 0.00001202
Iteration 135/1000 | Loss: 0.00001202
Iteration 136/1000 | Loss: 0.00001202
Iteration 137/1000 | Loss: 0.00001202
Iteration 138/1000 | Loss: 0.00001202
Iteration 139/1000 | Loss: 0.00001202
Iteration 140/1000 | Loss: 0.00001202
Iteration 141/1000 | Loss: 0.00001202
Iteration 142/1000 | Loss: 0.00001202
Iteration 143/1000 | Loss: 0.00001202
Iteration 144/1000 | Loss: 0.00001202
Iteration 145/1000 | Loss: 0.00001202
Iteration 146/1000 | Loss: 0.00001202
Iteration 147/1000 | Loss: 0.00001202
Iteration 148/1000 | Loss: 0.00001201
Iteration 149/1000 | Loss: 0.00001201
Iteration 150/1000 | Loss: 0.00001201
Iteration 151/1000 | Loss: 0.00001201
Iteration 152/1000 | Loss: 0.00001201
Iteration 153/1000 | Loss: 0.00001201
Iteration 154/1000 | Loss: 0.00001201
Iteration 155/1000 | Loss: 0.00001201
Iteration 156/1000 | Loss: 0.00001201
Iteration 157/1000 | Loss: 0.00001201
Iteration 158/1000 | Loss: 0.00001201
Iteration 159/1000 | Loss: 0.00001201
Iteration 160/1000 | Loss: 0.00001200
Iteration 161/1000 | Loss: 0.00001200
Iteration 162/1000 | Loss: 0.00001200
Iteration 163/1000 | Loss: 0.00001200
Iteration 164/1000 | Loss: 0.00001200
Iteration 165/1000 | Loss: 0.00001200
Iteration 166/1000 | Loss: 0.00001200
Iteration 167/1000 | Loss: 0.00001200
Iteration 168/1000 | Loss: 0.00001200
Iteration 169/1000 | Loss: 0.00001200
Iteration 170/1000 | Loss: 0.00001200
Iteration 171/1000 | Loss: 0.00001199
Iteration 172/1000 | Loss: 0.00001199
Iteration 173/1000 | Loss: 0.00001199
Iteration 174/1000 | Loss: 0.00001199
Iteration 175/1000 | Loss: 0.00001199
Iteration 176/1000 | Loss: 0.00001199
Iteration 177/1000 | Loss: 0.00001199
Iteration 178/1000 | Loss: 0.00001199
Iteration 179/1000 | Loss: 0.00001199
Iteration 180/1000 | Loss: 0.00001199
Iteration 181/1000 | Loss: 0.00001199
Iteration 182/1000 | Loss: 0.00001199
Iteration 183/1000 | Loss: 0.00001199
Iteration 184/1000 | Loss: 0.00001199
Iteration 185/1000 | Loss: 0.00001199
Iteration 186/1000 | Loss: 0.00001199
Iteration 187/1000 | Loss: 0.00001199
Iteration 188/1000 | Loss: 0.00001199
Iteration 189/1000 | Loss: 0.00001199
Iteration 190/1000 | Loss: 0.00001199
Iteration 191/1000 | Loss: 0.00001199
Iteration 192/1000 | Loss: 0.00001199
Iteration 193/1000 | Loss: 0.00001199
Iteration 194/1000 | Loss: 0.00001199
Iteration 195/1000 | Loss: 0.00001199
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 195. Stopping optimization.
Last 5 losses: [1.1986056961177383e-05, 1.1986056961177383e-05, 1.1986056961177383e-05, 1.1986056961177383e-05, 1.1986056961177383e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1986056961177383e-05

Optimization complete. Final v2v error: 2.959134578704834 mm

Highest mean error: 3.1758413314819336 mm for frame 136

Lowest mean error: 2.7617785930633545 mm for frame 217

Saving results

Total time: 42.56497240066528
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00955636
Iteration 2/25 | Loss: 0.00123020
Iteration 3/25 | Loss: 0.00092621
Iteration 4/25 | Loss: 0.00089023
Iteration 5/25 | Loss: 0.00087696
Iteration 6/25 | Loss: 0.00087516
Iteration 7/25 | Loss: 0.00087451
Iteration 8/25 | Loss: 0.00087451
Iteration 9/25 | Loss: 0.00087451
Iteration 10/25 | Loss: 0.00087451
Iteration 11/25 | Loss: 0.00087451
Iteration 12/25 | Loss: 0.00087451
Iteration 13/25 | Loss: 0.00087451
Iteration 14/25 | Loss: 0.00087451
Iteration 15/25 | Loss: 0.00087451
Iteration 16/25 | Loss: 0.00087451
Iteration 17/25 | Loss: 0.00087451
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0008745107334107161, 0.0008745107334107161, 0.0008745107334107161, 0.0008745107334107161, 0.0008745107334107161]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008745107334107161

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.07199693
Iteration 2/25 | Loss: 0.00048956
Iteration 3/25 | Loss: 0.00048952
Iteration 4/25 | Loss: 0.00048951
Iteration 5/25 | Loss: 0.00048951
Iteration 6/25 | Loss: 0.00048951
Iteration 7/25 | Loss: 0.00048951
Iteration 8/25 | Loss: 0.00048951
Iteration 9/25 | Loss: 0.00048951
Iteration 10/25 | Loss: 0.00048951
Iteration 11/25 | Loss: 0.00048951
Iteration 12/25 | Loss: 0.00048951
Iteration 13/25 | Loss: 0.00048951
Iteration 14/25 | Loss: 0.00048951
Iteration 15/25 | Loss: 0.00048951
Iteration 16/25 | Loss: 0.00048951
Iteration 17/25 | Loss: 0.00048951
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004895128658972681, 0.0004895128658972681, 0.0004895128658972681, 0.0004895128658972681, 0.0004895128658972681]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004895128658972681

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048951
Iteration 2/1000 | Loss: 0.00003700
Iteration 3/1000 | Loss: 0.00002935
Iteration 4/1000 | Loss: 0.00002600
Iteration 5/1000 | Loss: 0.00002512
Iteration 6/1000 | Loss: 0.00002431
Iteration 7/1000 | Loss: 0.00002389
Iteration 8/1000 | Loss: 0.00002350
Iteration 9/1000 | Loss: 0.00002317
Iteration 10/1000 | Loss: 0.00002296
Iteration 11/1000 | Loss: 0.00002276
Iteration 12/1000 | Loss: 0.00002275
Iteration 13/1000 | Loss: 0.00002268
Iteration 14/1000 | Loss: 0.00002260
Iteration 15/1000 | Loss: 0.00002252
Iteration 16/1000 | Loss: 0.00002252
Iteration 17/1000 | Loss: 0.00002248
Iteration 18/1000 | Loss: 0.00002248
Iteration 19/1000 | Loss: 0.00002248
Iteration 20/1000 | Loss: 0.00002247
Iteration 21/1000 | Loss: 0.00002246
Iteration 22/1000 | Loss: 0.00002246
Iteration 23/1000 | Loss: 0.00002245
Iteration 24/1000 | Loss: 0.00002245
Iteration 25/1000 | Loss: 0.00002244
Iteration 26/1000 | Loss: 0.00002244
Iteration 27/1000 | Loss: 0.00002244
Iteration 28/1000 | Loss: 0.00002243
Iteration 29/1000 | Loss: 0.00002243
Iteration 30/1000 | Loss: 0.00002243
Iteration 31/1000 | Loss: 0.00002243
Iteration 32/1000 | Loss: 0.00002243
Iteration 33/1000 | Loss: 0.00002243
Iteration 34/1000 | Loss: 0.00002243
Iteration 35/1000 | Loss: 0.00002243
Iteration 36/1000 | Loss: 0.00002242
Iteration 37/1000 | Loss: 0.00002242
Iteration 38/1000 | Loss: 0.00002242
Iteration 39/1000 | Loss: 0.00002242
Iteration 40/1000 | Loss: 0.00002241
Iteration 41/1000 | Loss: 0.00002241
Iteration 42/1000 | Loss: 0.00002241
Iteration 43/1000 | Loss: 0.00002240
Iteration 44/1000 | Loss: 0.00002240
Iteration 45/1000 | Loss: 0.00002240
Iteration 46/1000 | Loss: 0.00002240
Iteration 47/1000 | Loss: 0.00002240
Iteration 48/1000 | Loss: 0.00002240
Iteration 49/1000 | Loss: 0.00002240
Iteration 50/1000 | Loss: 0.00002240
Iteration 51/1000 | Loss: 0.00002239
Iteration 52/1000 | Loss: 0.00002239
Iteration 53/1000 | Loss: 0.00002239
Iteration 54/1000 | Loss: 0.00002238
Iteration 55/1000 | Loss: 0.00002238
Iteration 56/1000 | Loss: 0.00002238
Iteration 57/1000 | Loss: 0.00002238
Iteration 58/1000 | Loss: 0.00002237
Iteration 59/1000 | Loss: 0.00002237
Iteration 60/1000 | Loss: 0.00002237
Iteration 61/1000 | Loss: 0.00002237
Iteration 62/1000 | Loss: 0.00002237
Iteration 63/1000 | Loss: 0.00002237
Iteration 64/1000 | Loss: 0.00002237
Iteration 65/1000 | Loss: 0.00002236
Iteration 66/1000 | Loss: 0.00002236
Iteration 67/1000 | Loss: 0.00002236
Iteration 68/1000 | Loss: 0.00002235
Iteration 69/1000 | Loss: 0.00002235
Iteration 70/1000 | Loss: 0.00002235
Iteration 71/1000 | Loss: 0.00002235
Iteration 72/1000 | Loss: 0.00002235
Iteration 73/1000 | Loss: 0.00002235
Iteration 74/1000 | Loss: 0.00002235
Iteration 75/1000 | Loss: 0.00002235
Iteration 76/1000 | Loss: 0.00002234
Iteration 77/1000 | Loss: 0.00002234
Iteration 78/1000 | Loss: 0.00002234
Iteration 79/1000 | Loss: 0.00002234
Iteration 80/1000 | Loss: 0.00002234
Iteration 81/1000 | Loss: 0.00002234
Iteration 82/1000 | Loss: 0.00002234
Iteration 83/1000 | Loss: 0.00002234
Iteration 84/1000 | Loss: 0.00002233
Iteration 85/1000 | Loss: 0.00002233
Iteration 86/1000 | Loss: 0.00002233
Iteration 87/1000 | Loss: 0.00002233
Iteration 88/1000 | Loss: 0.00002232
Iteration 89/1000 | Loss: 0.00002232
Iteration 90/1000 | Loss: 0.00002232
Iteration 91/1000 | Loss: 0.00002232
Iteration 92/1000 | Loss: 0.00002232
Iteration 93/1000 | Loss: 0.00002231
Iteration 94/1000 | Loss: 0.00002231
Iteration 95/1000 | Loss: 0.00002231
Iteration 96/1000 | Loss: 0.00002230
Iteration 97/1000 | Loss: 0.00002230
Iteration 98/1000 | Loss: 0.00002230
Iteration 99/1000 | Loss: 0.00002230
Iteration 100/1000 | Loss: 0.00002230
Iteration 101/1000 | Loss: 0.00002230
Iteration 102/1000 | Loss: 0.00002230
Iteration 103/1000 | Loss: 0.00002230
Iteration 104/1000 | Loss: 0.00002229
Iteration 105/1000 | Loss: 0.00002229
Iteration 106/1000 | Loss: 0.00002229
Iteration 107/1000 | Loss: 0.00002229
Iteration 108/1000 | Loss: 0.00002228
Iteration 109/1000 | Loss: 0.00002228
Iteration 110/1000 | Loss: 0.00002228
Iteration 111/1000 | Loss: 0.00002227
Iteration 112/1000 | Loss: 0.00002227
Iteration 113/1000 | Loss: 0.00002227
Iteration 114/1000 | Loss: 0.00002227
Iteration 115/1000 | Loss: 0.00002226
Iteration 116/1000 | Loss: 0.00002226
Iteration 117/1000 | Loss: 0.00002226
Iteration 118/1000 | Loss: 0.00002225
Iteration 119/1000 | Loss: 0.00002225
Iteration 120/1000 | Loss: 0.00002225
Iteration 121/1000 | Loss: 0.00002225
Iteration 122/1000 | Loss: 0.00002224
Iteration 123/1000 | Loss: 0.00002224
Iteration 124/1000 | Loss: 0.00002224
Iteration 125/1000 | Loss: 0.00002223
Iteration 126/1000 | Loss: 0.00002223
Iteration 127/1000 | Loss: 0.00002223
Iteration 128/1000 | Loss: 0.00002223
Iteration 129/1000 | Loss: 0.00002223
Iteration 130/1000 | Loss: 0.00002222
Iteration 131/1000 | Loss: 0.00002222
Iteration 132/1000 | Loss: 0.00002222
Iteration 133/1000 | Loss: 0.00002222
Iteration 134/1000 | Loss: 0.00002222
Iteration 135/1000 | Loss: 0.00002222
Iteration 136/1000 | Loss: 0.00002222
Iteration 137/1000 | Loss: 0.00002221
Iteration 138/1000 | Loss: 0.00002221
Iteration 139/1000 | Loss: 0.00002221
Iteration 140/1000 | Loss: 0.00002220
Iteration 141/1000 | Loss: 0.00002220
Iteration 142/1000 | Loss: 0.00002220
Iteration 143/1000 | Loss: 0.00002220
Iteration 144/1000 | Loss: 0.00002220
Iteration 145/1000 | Loss: 0.00002220
Iteration 146/1000 | Loss: 0.00002219
Iteration 147/1000 | Loss: 0.00002219
Iteration 148/1000 | Loss: 0.00002219
Iteration 149/1000 | Loss: 0.00002219
Iteration 150/1000 | Loss: 0.00002219
Iteration 151/1000 | Loss: 0.00002219
Iteration 152/1000 | Loss: 0.00002219
Iteration 153/1000 | Loss: 0.00002218
Iteration 154/1000 | Loss: 0.00002218
Iteration 155/1000 | Loss: 0.00002218
Iteration 156/1000 | Loss: 0.00002218
Iteration 157/1000 | Loss: 0.00002218
Iteration 158/1000 | Loss: 0.00002218
Iteration 159/1000 | Loss: 0.00002218
Iteration 160/1000 | Loss: 0.00002218
Iteration 161/1000 | Loss: 0.00002218
Iteration 162/1000 | Loss: 0.00002218
Iteration 163/1000 | Loss: 0.00002218
Iteration 164/1000 | Loss: 0.00002218
Iteration 165/1000 | Loss: 0.00002217
Iteration 166/1000 | Loss: 0.00002217
Iteration 167/1000 | Loss: 0.00002217
Iteration 168/1000 | Loss: 0.00002217
Iteration 169/1000 | Loss: 0.00002217
Iteration 170/1000 | Loss: 0.00002217
Iteration 171/1000 | Loss: 0.00002216
Iteration 172/1000 | Loss: 0.00002216
Iteration 173/1000 | Loss: 0.00002216
Iteration 174/1000 | Loss: 0.00002216
Iteration 175/1000 | Loss: 0.00002216
Iteration 176/1000 | Loss: 0.00002216
Iteration 177/1000 | Loss: 0.00002216
Iteration 178/1000 | Loss: 0.00002215
Iteration 179/1000 | Loss: 0.00002215
Iteration 180/1000 | Loss: 0.00002215
Iteration 181/1000 | Loss: 0.00002215
Iteration 182/1000 | Loss: 0.00002215
Iteration 183/1000 | Loss: 0.00002215
Iteration 184/1000 | Loss: 0.00002215
Iteration 185/1000 | Loss: 0.00002215
Iteration 186/1000 | Loss: 0.00002215
Iteration 187/1000 | Loss: 0.00002215
Iteration 188/1000 | Loss: 0.00002215
Iteration 189/1000 | Loss: 0.00002214
Iteration 190/1000 | Loss: 0.00002214
Iteration 191/1000 | Loss: 0.00002214
Iteration 192/1000 | Loss: 0.00002214
Iteration 193/1000 | Loss: 0.00002214
Iteration 194/1000 | Loss: 0.00002213
Iteration 195/1000 | Loss: 0.00002213
Iteration 196/1000 | Loss: 0.00002213
Iteration 197/1000 | Loss: 0.00002213
Iteration 198/1000 | Loss: 0.00002213
Iteration 199/1000 | Loss: 0.00002213
Iteration 200/1000 | Loss: 0.00002213
Iteration 201/1000 | Loss: 0.00002213
Iteration 202/1000 | Loss: 0.00002213
Iteration 203/1000 | Loss: 0.00002213
Iteration 204/1000 | Loss: 0.00002213
Iteration 205/1000 | Loss: 0.00002213
Iteration 206/1000 | Loss: 0.00002213
Iteration 207/1000 | Loss: 0.00002213
Iteration 208/1000 | Loss: 0.00002213
Iteration 209/1000 | Loss: 0.00002213
Iteration 210/1000 | Loss: 0.00002213
Iteration 211/1000 | Loss: 0.00002213
Iteration 212/1000 | Loss: 0.00002213
Iteration 213/1000 | Loss: 0.00002213
Iteration 214/1000 | Loss: 0.00002213
Iteration 215/1000 | Loss: 0.00002213
Iteration 216/1000 | Loss: 0.00002213
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 216. Stopping optimization.
Last 5 losses: [2.2131642253953032e-05, 2.2131642253953032e-05, 2.2131642253953032e-05, 2.2131642253953032e-05, 2.2131642253953032e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2131642253953032e-05

Optimization complete. Final v2v error: 3.8524062633514404 mm

Highest mean error: 4.518641471862793 mm for frame 81

Lowest mean error: 3.385037660598755 mm for frame 88

Saving results

Total time: 44.118229150772095
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1027/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1027.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1027
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01028452
Iteration 2/25 | Loss: 0.00339139
Iteration 3/25 | Loss: 0.00204417
Iteration 4/25 | Loss: 0.00171826
Iteration 5/25 | Loss: 0.00152748
Iteration 6/25 | Loss: 0.00154368
Iteration 7/25 | Loss: 0.00153699
Iteration 8/25 | Loss: 0.00145805
Iteration 9/25 | Loss: 0.00137102
Iteration 10/25 | Loss: 0.00129876
Iteration 11/25 | Loss: 0.00127500
Iteration 12/25 | Loss: 0.00125111
Iteration 13/25 | Loss: 0.00123262
Iteration 14/25 | Loss: 0.00120016
Iteration 15/25 | Loss: 0.00117460
Iteration 16/25 | Loss: 0.00113971
Iteration 17/25 | Loss: 0.00114228
Iteration 18/25 | Loss: 0.00112747
Iteration 19/25 | Loss: 0.00111441
Iteration 20/25 | Loss: 0.00110627
Iteration 21/25 | Loss: 0.00110121
Iteration 22/25 | Loss: 0.00110082
Iteration 23/25 | Loss: 0.00109588
Iteration 24/25 | Loss: 0.00109274
Iteration 25/25 | Loss: 0.00109190

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51444650
Iteration 2/25 | Loss: 0.00744469
Iteration 3/25 | Loss: 0.00441591
Iteration 4/25 | Loss: 0.00457395
Iteration 5/25 | Loss: 0.00441587
Iteration 6/25 | Loss: 0.00441587
Iteration 7/25 | Loss: 0.00441587
Iteration 8/25 | Loss: 0.00441587
Iteration 9/25 | Loss: 0.00441587
Iteration 10/25 | Loss: 0.00441587
Iteration 11/25 | Loss: 0.00441587
Iteration 12/25 | Loss: 0.00441587
Iteration 13/25 | Loss: 0.00441587
Iteration 14/25 | Loss: 0.00441587
Iteration 15/25 | Loss: 0.00441587
Iteration 16/25 | Loss: 0.00441587
Iteration 17/25 | Loss: 0.00441587
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.004415868781507015, 0.004415868781507015, 0.004415868781507015, 0.004415868781507015, 0.004415868781507015]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004415868781507015

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00441587
Iteration 2/1000 | Loss: 0.00533950
Iteration 3/1000 | Loss: 0.00109847
Iteration 4/1000 | Loss: 0.00144141
Iteration 5/1000 | Loss: 0.00067530
Iteration 6/1000 | Loss: 0.00213813
Iteration 7/1000 | Loss: 0.00117693
Iteration 8/1000 | Loss: 0.00057144
Iteration 9/1000 | Loss: 0.00039032
Iteration 10/1000 | Loss: 0.00092130
Iteration 11/1000 | Loss: 0.00090871
Iteration 12/1000 | Loss: 0.00237094
Iteration 13/1000 | Loss: 0.00215786
Iteration 14/1000 | Loss: 0.00100470
Iteration 15/1000 | Loss: 0.00124761
Iteration 16/1000 | Loss: 0.00034389
Iteration 17/1000 | Loss: 0.00084186
Iteration 18/1000 | Loss: 0.00110688
Iteration 19/1000 | Loss: 0.00085571
Iteration 20/1000 | Loss: 0.00066216
Iteration 21/1000 | Loss: 0.00030492
Iteration 22/1000 | Loss: 0.00098768
Iteration 23/1000 | Loss: 0.00024581
Iteration 24/1000 | Loss: 0.00059084
Iteration 25/1000 | Loss: 0.00030626
Iteration 26/1000 | Loss: 0.00015804
Iteration 27/1000 | Loss: 0.00047004
Iteration 28/1000 | Loss: 0.00013235
Iteration 29/1000 | Loss: 0.00105223
Iteration 30/1000 | Loss: 0.00080521
Iteration 31/1000 | Loss: 0.00073465
Iteration 32/1000 | Loss: 0.00059214
Iteration 33/1000 | Loss: 0.00083151
Iteration 34/1000 | Loss: 0.00015057
Iteration 35/1000 | Loss: 0.00107635
Iteration 36/1000 | Loss: 0.00082627
Iteration 37/1000 | Loss: 0.00065542
Iteration 38/1000 | Loss: 0.00016156
Iteration 39/1000 | Loss: 0.00112269
Iteration 40/1000 | Loss: 0.00134130
Iteration 41/1000 | Loss: 0.00108851
Iteration 42/1000 | Loss: 0.00013258
Iteration 43/1000 | Loss: 0.00077064
Iteration 44/1000 | Loss: 0.00055446
Iteration 45/1000 | Loss: 0.00070994
Iteration 46/1000 | Loss: 0.00012105
Iteration 47/1000 | Loss: 0.00052657
Iteration 48/1000 | Loss: 0.00059957
Iteration 49/1000 | Loss: 0.00049697
Iteration 50/1000 | Loss: 0.00050815
Iteration 51/1000 | Loss: 0.00044224
Iteration 52/1000 | Loss: 0.00090672
Iteration 53/1000 | Loss: 0.00014630
Iteration 54/1000 | Loss: 0.00010596
Iteration 55/1000 | Loss: 0.00051816
Iteration 56/1000 | Loss: 0.00010297
Iteration 57/1000 | Loss: 0.00060546
Iteration 58/1000 | Loss: 0.00031632
Iteration 59/1000 | Loss: 0.00110856
Iteration 60/1000 | Loss: 0.00255016
Iteration 61/1000 | Loss: 0.00024695
Iteration 62/1000 | Loss: 0.00020801
Iteration 63/1000 | Loss: 0.00044429
Iteration 64/1000 | Loss: 0.00026202
Iteration 65/1000 | Loss: 0.00010818
Iteration 66/1000 | Loss: 0.00011477
Iteration 67/1000 | Loss: 0.00007871
Iteration 68/1000 | Loss: 0.00040881
Iteration 69/1000 | Loss: 0.00023575
Iteration 70/1000 | Loss: 0.00007150
Iteration 71/1000 | Loss: 0.00021091
Iteration 72/1000 | Loss: 0.00031017
Iteration 73/1000 | Loss: 0.00007070
Iteration 74/1000 | Loss: 0.00008117
Iteration 75/1000 | Loss: 0.00008598
Iteration 76/1000 | Loss: 0.00104032
Iteration 77/1000 | Loss: 0.00051785
Iteration 78/1000 | Loss: 0.00035347
Iteration 79/1000 | Loss: 0.00028803
Iteration 80/1000 | Loss: 0.00033109
Iteration 81/1000 | Loss: 0.00100768
Iteration 82/1000 | Loss: 0.00031153
Iteration 83/1000 | Loss: 0.00008571
Iteration 84/1000 | Loss: 0.00010652
Iteration 85/1000 | Loss: 0.00006569
Iteration 86/1000 | Loss: 0.00006718
Iteration 87/1000 | Loss: 0.00035876
Iteration 88/1000 | Loss: 0.00023464
Iteration 89/1000 | Loss: 0.00007823
Iteration 90/1000 | Loss: 0.00006466
Iteration 91/1000 | Loss: 0.00007107
Iteration 92/1000 | Loss: 0.00006091
Iteration 93/1000 | Loss: 0.00057937
Iteration 94/1000 | Loss: 0.00006715
Iteration 95/1000 | Loss: 0.00047375
Iteration 96/1000 | Loss: 0.00022741
Iteration 97/1000 | Loss: 0.00059793
Iteration 98/1000 | Loss: 0.00023923
Iteration 99/1000 | Loss: 0.00031397
Iteration 100/1000 | Loss: 0.00022238
Iteration 101/1000 | Loss: 0.00015630
Iteration 102/1000 | Loss: 0.00046392
Iteration 103/1000 | Loss: 0.00018158
Iteration 104/1000 | Loss: 0.00026454
Iteration 105/1000 | Loss: 0.00020009
Iteration 106/1000 | Loss: 0.00045725
Iteration 107/1000 | Loss: 0.00064634
Iteration 108/1000 | Loss: 0.00073996
Iteration 109/1000 | Loss: 0.00024168
Iteration 110/1000 | Loss: 0.00007630
Iteration 111/1000 | Loss: 0.00006488
Iteration 112/1000 | Loss: 0.00017583
Iteration 113/1000 | Loss: 0.00033566
Iteration 114/1000 | Loss: 0.00038376
Iteration 115/1000 | Loss: 0.00037219
Iteration 116/1000 | Loss: 0.00034922
Iteration 117/1000 | Loss: 0.00035629
Iteration 118/1000 | Loss: 0.00030443
Iteration 119/1000 | Loss: 0.00053573
Iteration 120/1000 | Loss: 0.00090765
Iteration 121/1000 | Loss: 0.00026638
Iteration 122/1000 | Loss: 0.00018146
Iteration 123/1000 | Loss: 0.00028186
Iteration 124/1000 | Loss: 0.00006087
Iteration 125/1000 | Loss: 0.00005912
Iteration 126/1000 | Loss: 0.00004948
Iteration 127/1000 | Loss: 0.00005427
Iteration 128/1000 | Loss: 0.00010402
Iteration 129/1000 | Loss: 0.00036805
Iteration 130/1000 | Loss: 0.00008044
Iteration 131/1000 | Loss: 0.00014142
Iteration 132/1000 | Loss: 0.00007180
Iteration 133/1000 | Loss: 0.00027914
Iteration 134/1000 | Loss: 0.00030269
Iteration 135/1000 | Loss: 0.00013807
Iteration 136/1000 | Loss: 0.00026440
Iteration 137/1000 | Loss: 0.00012646
Iteration 138/1000 | Loss: 0.00025006
Iteration 139/1000 | Loss: 0.00039421
Iteration 140/1000 | Loss: 0.00037377
Iteration 141/1000 | Loss: 0.00011902
Iteration 142/1000 | Loss: 0.00022733
Iteration 143/1000 | Loss: 0.00024702
Iteration 144/1000 | Loss: 0.00026886
Iteration 145/1000 | Loss: 0.00010463
Iteration 146/1000 | Loss: 0.00011559
Iteration 147/1000 | Loss: 0.00006064
Iteration 148/1000 | Loss: 0.00004784
Iteration 149/1000 | Loss: 0.00005309
Iteration 150/1000 | Loss: 0.00005157
Iteration 151/1000 | Loss: 0.00003454
Iteration 152/1000 | Loss: 0.00004961
Iteration 153/1000 | Loss: 0.00004176
Iteration 154/1000 | Loss: 0.00004204
Iteration 155/1000 | Loss: 0.00004045
Iteration 156/1000 | Loss: 0.00004002
Iteration 157/1000 | Loss: 0.00004133
Iteration 158/1000 | Loss: 0.00004957
Iteration 159/1000 | Loss: 0.00004677
Iteration 160/1000 | Loss: 0.00003751
Iteration 161/1000 | Loss: 0.00004556
Iteration 162/1000 | Loss: 0.00004412
Iteration 163/1000 | Loss: 0.00004553
Iteration 164/1000 | Loss: 0.00004237
Iteration 165/1000 | Loss: 0.00004433
Iteration 166/1000 | Loss: 0.00004087
Iteration 167/1000 | Loss: 0.00004545
Iteration 168/1000 | Loss: 0.00006060
Iteration 169/1000 | Loss: 0.00008898
Iteration 170/1000 | Loss: 0.00005665
Iteration 171/1000 | Loss: 0.00003776
Iteration 172/1000 | Loss: 0.00004082
Iteration 173/1000 | Loss: 0.00004570
Iteration 174/1000 | Loss: 0.00005587
Iteration 175/1000 | Loss: 0.00006181
Iteration 176/1000 | Loss: 0.00005987
Iteration 177/1000 | Loss: 0.00004262
Iteration 178/1000 | Loss: 0.00003871
Iteration 179/1000 | Loss: 0.00004332
Iteration 180/1000 | Loss: 0.00003822
Iteration 181/1000 | Loss: 0.00004147
Iteration 182/1000 | Loss: 0.00004825
Iteration 183/1000 | Loss: 0.00003509
Iteration 184/1000 | Loss: 0.00003404
Iteration 185/1000 | Loss: 0.00007083
Iteration 186/1000 | Loss: 0.00003923
Iteration 187/1000 | Loss: 0.00004767
Iteration 188/1000 | Loss: 0.00003894
Iteration 189/1000 | Loss: 0.00004497
Iteration 190/1000 | Loss: 0.00003940
Iteration 191/1000 | Loss: 0.00004578
Iteration 192/1000 | Loss: 0.00003935
Iteration 193/1000 | Loss: 0.00004549
Iteration 194/1000 | Loss: 0.00003918
Iteration 195/1000 | Loss: 0.00004479
Iteration 196/1000 | Loss: 0.00003873
Iteration 197/1000 | Loss: 0.00004463
Iteration 198/1000 | Loss: 0.00003871
Iteration 199/1000 | Loss: 0.00004408
Iteration 200/1000 | Loss: 0.00033139
Iteration 201/1000 | Loss: 0.00004897
Iteration 202/1000 | Loss: 0.00006077
Iteration 203/1000 | Loss: 0.00013341
Iteration 204/1000 | Loss: 0.00014886
Iteration 205/1000 | Loss: 0.00004907
Iteration 206/1000 | Loss: 0.00003752
Iteration 207/1000 | Loss: 0.00005791
Iteration 208/1000 | Loss: 0.00004529
Iteration 209/1000 | Loss: 0.00004007
Iteration 210/1000 | Loss: 0.00009419
Iteration 211/1000 | Loss: 0.00005048
Iteration 212/1000 | Loss: 0.00004332
Iteration 213/1000 | Loss: 0.00004429
Iteration 214/1000 | Loss: 0.00004264
Iteration 215/1000 | Loss: 0.00004612
Iteration 216/1000 | Loss: 0.00004199
Iteration 217/1000 | Loss: 0.00004550
Iteration 218/1000 | Loss: 0.00004139
Iteration 219/1000 | Loss: 0.00004596
Iteration 220/1000 | Loss: 0.00004374
Iteration 221/1000 | Loss: 0.00004557
Iteration 222/1000 | Loss: 0.00004314
Iteration 223/1000 | Loss: 0.00004471
Iteration 224/1000 | Loss: 0.00005477
Iteration 225/1000 | Loss: 0.00002865
Iteration 226/1000 | Loss: 0.00008391
Iteration 227/1000 | Loss: 0.00002434
Iteration 228/1000 | Loss: 0.00008067
Iteration 229/1000 | Loss: 0.00002386
Iteration 230/1000 | Loss: 0.00002374
Iteration 231/1000 | Loss: 0.00002354
Iteration 232/1000 | Loss: 0.00002353
Iteration 233/1000 | Loss: 0.00002351
Iteration 234/1000 | Loss: 0.00002350
Iteration 235/1000 | Loss: 0.00002349
Iteration 236/1000 | Loss: 0.00002349
Iteration 237/1000 | Loss: 0.00002349
Iteration 238/1000 | Loss: 0.00002348
Iteration 239/1000 | Loss: 0.00002348
Iteration 240/1000 | Loss: 0.00002347
Iteration 241/1000 | Loss: 0.00002347
Iteration 242/1000 | Loss: 0.00002347
Iteration 243/1000 | Loss: 0.00002346
Iteration 244/1000 | Loss: 0.00002346
Iteration 245/1000 | Loss: 0.00002345
Iteration 246/1000 | Loss: 0.00002345
Iteration 247/1000 | Loss: 0.00002345
Iteration 248/1000 | Loss: 0.00002344
Iteration 249/1000 | Loss: 0.00002344
Iteration 250/1000 | Loss: 0.00002344
Iteration 251/1000 | Loss: 0.00002344
Iteration 252/1000 | Loss: 0.00002344
Iteration 253/1000 | Loss: 0.00002344
Iteration 254/1000 | Loss: 0.00002344
Iteration 255/1000 | Loss: 0.00002343
Iteration 256/1000 | Loss: 0.00002343
Iteration 257/1000 | Loss: 0.00002343
Iteration 258/1000 | Loss: 0.00002343
Iteration 259/1000 | Loss: 0.00002343
Iteration 260/1000 | Loss: 0.00002343
Iteration 261/1000 | Loss: 0.00002343
Iteration 262/1000 | Loss: 0.00002343
Iteration 263/1000 | Loss: 0.00002343
Iteration 264/1000 | Loss: 0.00002343
Iteration 265/1000 | Loss: 0.00002343
Iteration 266/1000 | Loss: 0.00002343
Iteration 267/1000 | Loss: 0.00002342
Iteration 268/1000 | Loss: 0.00002342
Iteration 269/1000 | Loss: 0.00002342
Iteration 270/1000 | Loss: 0.00002342
Iteration 271/1000 | Loss: 0.00002342
Iteration 272/1000 | Loss: 0.00002341
Iteration 273/1000 | Loss: 0.00002341
Iteration 274/1000 | Loss: 0.00002341
Iteration 275/1000 | Loss: 0.00002341
Iteration 276/1000 | Loss: 0.00002341
Iteration 277/1000 | Loss: 0.00002341
Iteration 278/1000 | Loss: 0.00002341
Iteration 279/1000 | Loss: 0.00002341
Iteration 280/1000 | Loss: 0.00002340
Iteration 281/1000 | Loss: 0.00002340
Iteration 282/1000 | Loss: 0.00002340
Iteration 283/1000 | Loss: 0.00002340
Iteration 284/1000 | Loss: 0.00002340
Iteration 285/1000 | Loss: 0.00002340
Iteration 286/1000 | Loss: 0.00002340
Iteration 287/1000 | Loss: 0.00002340
Iteration 288/1000 | Loss: 0.00002340
Iteration 289/1000 | Loss: 0.00002340
Iteration 290/1000 | Loss: 0.00002340
Iteration 291/1000 | Loss: 0.00002340
Iteration 292/1000 | Loss: 0.00002339
Iteration 293/1000 | Loss: 0.00002339
Iteration 294/1000 | Loss: 0.00002339
Iteration 295/1000 | Loss: 0.00002339
Iteration 296/1000 | Loss: 0.00002339
Iteration 297/1000 | Loss: 0.00002339
Iteration 298/1000 | Loss: 0.00002339
Iteration 299/1000 | Loss: 0.00002339
Iteration 300/1000 | Loss: 0.00002339
Iteration 301/1000 | Loss: 0.00002339
Iteration 302/1000 | Loss: 0.00002339
Iteration 303/1000 | Loss: 0.00002339
Iteration 304/1000 | Loss: 0.00002339
Iteration 305/1000 | Loss: 0.00002339
Iteration 306/1000 | Loss: 0.00002339
Iteration 307/1000 | Loss: 0.00002339
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 307. Stopping optimization.
Last 5 losses: [2.3392536604660563e-05, 2.3392536604660563e-05, 2.3392536604660563e-05, 2.3392536604660563e-05, 2.3392536604660563e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3392536604660563e-05

Optimization complete. Final v2v error: 3.2871553897857666 mm

Highest mean error: 11.3474760055542 mm for frame 199

Lowest mean error: 2.708747386932373 mm for frame 181

Saving results

Total time: 421.5788583755493
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00995854
Iteration 2/25 | Loss: 0.00097306
Iteration 3/25 | Loss: 0.00078140
Iteration 4/25 | Loss: 0.00074957
Iteration 5/25 | Loss: 0.00074007
Iteration 6/25 | Loss: 0.00073843
Iteration 7/25 | Loss: 0.00073843
Iteration 8/25 | Loss: 0.00073843
Iteration 9/25 | Loss: 0.00073843
Iteration 10/25 | Loss: 0.00073843
Iteration 11/25 | Loss: 0.00073843
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007384262862615287, 0.0007384262862615287, 0.0007384262862615287, 0.0007384262862615287, 0.0007384262862615287]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007384262862615287

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49150133
Iteration 2/25 | Loss: 0.00043302
Iteration 3/25 | Loss: 0.00043302
Iteration 4/25 | Loss: 0.00043302
Iteration 5/25 | Loss: 0.00043302
Iteration 6/25 | Loss: 0.00043302
Iteration 7/25 | Loss: 0.00043302
Iteration 8/25 | Loss: 0.00043302
Iteration 9/25 | Loss: 0.00043302
Iteration 10/25 | Loss: 0.00043302
Iteration 11/25 | Loss: 0.00043302
Iteration 12/25 | Loss: 0.00043302
Iteration 13/25 | Loss: 0.00043302
Iteration 14/25 | Loss: 0.00043302
Iteration 15/25 | Loss: 0.00043302
Iteration 16/25 | Loss: 0.00043302
Iteration 17/25 | Loss: 0.00043302
Iteration 18/25 | Loss: 0.00043302
Iteration 19/25 | Loss: 0.00043302
Iteration 20/25 | Loss: 0.00043302
Iteration 21/25 | Loss: 0.00043302
Iteration 22/25 | Loss: 0.00043302
Iteration 23/25 | Loss: 0.00043302
Iteration 24/25 | Loss: 0.00043302
Iteration 25/25 | Loss: 0.00043302

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043302
Iteration 2/1000 | Loss: 0.00002631
Iteration 3/1000 | Loss: 0.00002008
Iteration 4/1000 | Loss: 0.00001846
Iteration 5/1000 | Loss: 0.00001750
Iteration 6/1000 | Loss: 0.00001698
Iteration 7/1000 | Loss: 0.00001639
Iteration 8/1000 | Loss: 0.00001606
Iteration 9/1000 | Loss: 0.00001575
Iteration 10/1000 | Loss: 0.00001569
Iteration 11/1000 | Loss: 0.00001564
Iteration 12/1000 | Loss: 0.00001556
Iteration 13/1000 | Loss: 0.00001556
Iteration 14/1000 | Loss: 0.00001556
Iteration 15/1000 | Loss: 0.00001555
Iteration 16/1000 | Loss: 0.00001554
Iteration 17/1000 | Loss: 0.00001550
Iteration 18/1000 | Loss: 0.00001549
Iteration 19/1000 | Loss: 0.00001549
Iteration 20/1000 | Loss: 0.00001549
Iteration 21/1000 | Loss: 0.00001548
Iteration 22/1000 | Loss: 0.00001548
Iteration 23/1000 | Loss: 0.00001547
Iteration 24/1000 | Loss: 0.00001541
Iteration 25/1000 | Loss: 0.00001534
Iteration 26/1000 | Loss: 0.00001533
Iteration 27/1000 | Loss: 0.00001533
Iteration 28/1000 | Loss: 0.00001532
Iteration 29/1000 | Loss: 0.00001532
Iteration 30/1000 | Loss: 0.00001531
Iteration 31/1000 | Loss: 0.00001530
Iteration 32/1000 | Loss: 0.00001529
Iteration 33/1000 | Loss: 0.00001528
Iteration 34/1000 | Loss: 0.00001528
Iteration 35/1000 | Loss: 0.00001528
Iteration 36/1000 | Loss: 0.00001525
Iteration 37/1000 | Loss: 0.00001525
Iteration 38/1000 | Loss: 0.00001524
Iteration 39/1000 | Loss: 0.00001524
Iteration 40/1000 | Loss: 0.00001524
Iteration 41/1000 | Loss: 0.00001524
Iteration 42/1000 | Loss: 0.00001523
Iteration 43/1000 | Loss: 0.00001523
Iteration 44/1000 | Loss: 0.00001523
Iteration 45/1000 | Loss: 0.00001522
Iteration 46/1000 | Loss: 0.00001522
Iteration 47/1000 | Loss: 0.00001521
Iteration 48/1000 | Loss: 0.00001521
Iteration 49/1000 | Loss: 0.00001521
Iteration 50/1000 | Loss: 0.00001520
Iteration 51/1000 | Loss: 0.00001519
Iteration 52/1000 | Loss: 0.00001519
Iteration 53/1000 | Loss: 0.00001517
Iteration 54/1000 | Loss: 0.00001516
Iteration 55/1000 | Loss: 0.00001516
Iteration 56/1000 | Loss: 0.00001516
Iteration 57/1000 | Loss: 0.00001515
Iteration 58/1000 | Loss: 0.00001515
Iteration 59/1000 | Loss: 0.00001514
Iteration 60/1000 | Loss: 0.00001514
Iteration 61/1000 | Loss: 0.00001513
Iteration 62/1000 | Loss: 0.00001512
Iteration 63/1000 | Loss: 0.00001512
Iteration 64/1000 | Loss: 0.00001512
Iteration 65/1000 | Loss: 0.00001512
Iteration 66/1000 | Loss: 0.00001511
Iteration 67/1000 | Loss: 0.00001511
Iteration 68/1000 | Loss: 0.00001510
Iteration 69/1000 | Loss: 0.00001510
Iteration 70/1000 | Loss: 0.00001510
Iteration 71/1000 | Loss: 0.00001506
Iteration 72/1000 | Loss: 0.00001506
Iteration 73/1000 | Loss: 0.00001505
Iteration 74/1000 | Loss: 0.00001504
Iteration 75/1000 | Loss: 0.00001504
Iteration 76/1000 | Loss: 0.00001504
Iteration 77/1000 | Loss: 0.00001504
Iteration 78/1000 | Loss: 0.00001503
Iteration 79/1000 | Loss: 0.00001503
Iteration 80/1000 | Loss: 0.00001503
Iteration 81/1000 | Loss: 0.00001503
Iteration 82/1000 | Loss: 0.00001503
Iteration 83/1000 | Loss: 0.00001502
Iteration 84/1000 | Loss: 0.00001502
Iteration 85/1000 | Loss: 0.00001502
Iteration 86/1000 | Loss: 0.00001502
Iteration 87/1000 | Loss: 0.00001502
Iteration 88/1000 | Loss: 0.00001502
Iteration 89/1000 | Loss: 0.00001502
Iteration 90/1000 | Loss: 0.00001502
Iteration 91/1000 | Loss: 0.00001502
Iteration 92/1000 | Loss: 0.00001502
Iteration 93/1000 | Loss: 0.00001502
Iteration 94/1000 | Loss: 0.00001502
Iteration 95/1000 | Loss: 0.00001502
Iteration 96/1000 | Loss: 0.00001502
Iteration 97/1000 | Loss: 0.00001501
Iteration 98/1000 | Loss: 0.00001501
Iteration 99/1000 | Loss: 0.00001501
Iteration 100/1000 | Loss: 0.00001501
Iteration 101/1000 | Loss: 0.00001501
Iteration 102/1000 | Loss: 0.00001500
Iteration 103/1000 | Loss: 0.00001500
Iteration 104/1000 | Loss: 0.00001500
Iteration 105/1000 | Loss: 0.00001500
Iteration 106/1000 | Loss: 0.00001500
Iteration 107/1000 | Loss: 0.00001500
Iteration 108/1000 | Loss: 0.00001500
Iteration 109/1000 | Loss: 0.00001500
Iteration 110/1000 | Loss: 0.00001500
Iteration 111/1000 | Loss: 0.00001500
Iteration 112/1000 | Loss: 0.00001500
Iteration 113/1000 | Loss: 0.00001499
Iteration 114/1000 | Loss: 0.00001499
Iteration 115/1000 | Loss: 0.00001499
Iteration 116/1000 | Loss: 0.00001499
Iteration 117/1000 | Loss: 0.00001499
Iteration 118/1000 | Loss: 0.00001499
Iteration 119/1000 | Loss: 0.00001498
Iteration 120/1000 | Loss: 0.00001498
Iteration 121/1000 | Loss: 0.00001498
Iteration 122/1000 | Loss: 0.00001498
Iteration 123/1000 | Loss: 0.00001498
Iteration 124/1000 | Loss: 0.00001498
Iteration 125/1000 | Loss: 0.00001498
Iteration 126/1000 | Loss: 0.00001498
Iteration 127/1000 | Loss: 0.00001497
Iteration 128/1000 | Loss: 0.00001497
Iteration 129/1000 | Loss: 0.00001497
Iteration 130/1000 | Loss: 0.00001497
Iteration 131/1000 | Loss: 0.00001497
Iteration 132/1000 | Loss: 0.00001497
Iteration 133/1000 | Loss: 0.00001497
Iteration 134/1000 | Loss: 0.00001497
Iteration 135/1000 | Loss: 0.00001497
Iteration 136/1000 | Loss: 0.00001497
Iteration 137/1000 | Loss: 0.00001497
Iteration 138/1000 | Loss: 0.00001497
Iteration 139/1000 | Loss: 0.00001497
Iteration 140/1000 | Loss: 0.00001497
Iteration 141/1000 | Loss: 0.00001497
Iteration 142/1000 | Loss: 0.00001497
Iteration 143/1000 | Loss: 0.00001496
Iteration 144/1000 | Loss: 0.00001496
Iteration 145/1000 | Loss: 0.00001496
Iteration 146/1000 | Loss: 0.00001496
Iteration 147/1000 | Loss: 0.00001496
Iteration 148/1000 | Loss: 0.00001495
Iteration 149/1000 | Loss: 0.00001495
Iteration 150/1000 | Loss: 0.00001495
Iteration 151/1000 | Loss: 0.00001495
Iteration 152/1000 | Loss: 0.00001495
Iteration 153/1000 | Loss: 0.00001495
Iteration 154/1000 | Loss: 0.00001495
Iteration 155/1000 | Loss: 0.00001495
Iteration 156/1000 | Loss: 0.00001495
Iteration 157/1000 | Loss: 0.00001495
Iteration 158/1000 | Loss: 0.00001495
Iteration 159/1000 | Loss: 0.00001495
Iteration 160/1000 | Loss: 0.00001495
Iteration 161/1000 | Loss: 0.00001495
Iteration 162/1000 | Loss: 0.00001495
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [1.4951057892176323e-05, 1.4951057892176323e-05, 1.4951057892176323e-05, 1.4951057892176323e-05, 1.4951057892176323e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4951057892176323e-05

Optimization complete. Final v2v error: 3.2789645195007324 mm

Highest mean error: 3.6683244705200195 mm for frame 108

Lowest mean error: 3.0384674072265625 mm for frame 159

Saving results

Total time: 43.87301540374756
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1086
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840237
Iteration 2/25 | Loss: 0.00112597
Iteration 3/25 | Loss: 0.00085395
Iteration 4/25 | Loss: 0.00082449
Iteration 5/25 | Loss: 0.00081893
Iteration 6/25 | Loss: 0.00081748
Iteration 7/25 | Loss: 0.00081734
Iteration 8/25 | Loss: 0.00081734
Iteration 9/25 | Loss: 0.00081734
Iteration 10/25 | Loss: 0.00081734
Iteration 11/25 | Loss: 0.00081734
Iteration 12/25 | Loss: 0.00081734
Iteration 13/25 | Loss: 0.00081734
Iteration 14/25 | Loss: 0.00081734
Iteration 15/25 | Loss: 0.00081734
Iteration 16/25 | Loss: 0.00081734
Iteration 17/25 | Loss: 0.00081734
Iteration 18/25 | Loss: 0.00081734
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.000817338062915951, 0.000817338062915951, 0.000817338062915951, 0.000817338062915951, 0.000817338062915951]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000817338062915951

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.00857306
Iteration 2/25 | Loss: 0.00044744
Iteration 3/25 | Loss: 0.00044744
Iteration 4/25 | Loss: 0.00044744
Iteration 5/25 | Loss: 0.00044744
Iteration 6/25 | Loss: 0.00044744
Iteration 7/25 | Loss: 0.00044744
Iteration 8/25 | Loss: 0.00044744
Iteration 9/25 | Loss: 0.00044744
Iteration 10/25 | Loss: 0.00044744
Iteration 11/25 | Loss: 0.00044744
Iteration 12/25 | Loss: 0.00044743
Iteration 13/25 | Loss: 0.00044743
Iteration 14/25 | Loss: 0.00044743
Iteration 15/25 | Loss: 0.00044743
Iteration 16/25 | Loss: 0.00044743
Iteration 17/25 | Loss: 0.00044743
Iteration 18/25 | Loss: 0.00044743
Iteration 19/25 | Loss: 0.00044743
Iteration 20/25 | Loss: 0.00044743
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0004474349261727184, 0.0004474349261727184, 0.0004474349261727184, 0.0004474349261727184, 0.0004474349261727184]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004474349261727184

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044743
Iteration 2/1000 | Loss: 0.00002710
Iteration 3/1000 | Loss: 0.00002259
Iteration 4/1000 | Loss: 0.00002164
Iteration 5/1000 | Loss: 0.00002043
Iteration 6/1000 | Loss: 0.00001987
Iteration 7/1000 | Loss: 0.00001946
Iteration 8/1000 | Loss: 0.00001922
Iteration 9/1000 | Loss: 0.00001919
Iteration 10/1000 | Loss: 0.00001917
Iteration 11/1000 | Loss: 0.00001917
Iteration 12/1000 | Loss: 0.00001916
Iteration 13/1000 | Loss: 0.00001904
Iteration 14/1000 | Loss: 0.00001903
Iteration 15/1000 | Loss: 0.00001902
Iteration 16/1000 | Loss: 0.00001901
Iteration 17/1000 | Loss: 0.00001901
Iteration 18/1000 | Loss: 0.00001901
Iteration 19/1000 | Loss: 0.00001901
Iteration 20/1000 | Loss: 0.00001899
Iteration 21/1000 | Loss: 0.00001897
Iteration 22/1000 | Loss: 0.00001896
Iteration 23/1000 | Loss: 0.00001893
Iteration 24/1000 | Loss: 0.00001893
Iteration 25/1000 | Loss: 0.00001892
Iteration 26/1000 | Loss: 0.00001892
Iteration 27/1000 | Loss: 0.00001891
Iteration 28/1000 | Loss: 0.00001891
Iteration 29/1000 | Loss: 0.00001891
Iteration 30/1000 | Loss: 0.00001890
Iteration 31/1000 | Loss: 0.00001890
Iteration 32/1000 | Loss: 0.00001890
Iteration 33/1000 | Loss: 0.00001890
Iteration 34/1000 | Loss: 0.00001890
Iteration 35/1000 | Loss: 0.00001890
Iteration 36/1000 | Loss: 0.00001890
Iteration 37/1000 | Loss: 0.00001890
Iteration 38/1000 | Loss: 0.00001890
Iteration 39/1000 | Loss: 0.00001889
Iteration 40/1000 | Loss: 0.00001889
Iteration 41/1000 | Loss: 0.00001889
Iteration 42/1000 | Loss: 0.00001888
Iteration 43/1000 | Loss: 0.00001888
Iteration 44/1000 | Loss: 0.00001886
Iteration 45/1000 | Loss: 0.00001886
Iteration 46/1000 | Loss: 0.00001886
Iteration 47/1000 | Loss: 0.00001886
Iteration 48/1000 | Loss: 0.00001886
Iteration 49/1000 | Loss: 0.00001885
Iteration 50/1000 | Loss: 0.00001885
Iteration 51/1000 | Loss: 0.00001885
Iteration 52/1000 | Loss: 0.00001885
Iteration 53/1000 | Loss: 0.00001884
Iteration 54/1000 | Loss: 0.00001884
Iteration 55/1000 | Loss: 0.00001884
Iteration 56/1000 | Loss: 0.00001884
Iteration 57/1000 | Loss: 0.00001883
Iteration 58/1000 | Loss: 0.00001883
Iteration 59/1000 | Loss: 0.00001883
Iteration 60/1000 | Loss: 0.00001883
Iteration 61/1000 | Loss: 0.00001883
Iteration 62/1000 | Loss: 0.00001882
Iteration 63/1000 | Loss: 0.00001882
Iteration 64/1000 | Loss: 0.00001882
Iteration 65/1000 | Loss: 0.00001882
Iteration 66/1000 | Loss: 0.00001882
Iteration 67/1000 | Loss: 0.00001881
Iteration 68/1000 | Loss: 0.00001881
Iteration 69/1000 | Loss: 0.00001881
Iteration 70/1000 | Loss: 0.00001881
Iteration 71/1000 | Loss: 0.00001881
Iteration 72/1000 | Loss: 0.00001881
Iteration 73/1000 | Loss: 0.00001881
Iteration 74/1000 | Loss: 0.00001881
Iteration 75/1000 | Loss: 0.00001881
Iteration 76/1000 | Loss: 0.00001881
Iteration 77/1000 | Loss: 0.00001881
Iteration 78/1000 | Loss: 0.00001881
Iteration 79/1000 | Loss: 0.00001881
Iteration 80/1000 | Loss: 0.00001881
Iteration 81/1000 | Loss: 0.00001881
Iteration 82/1000 | Loss: 0.00001881
Iteration 83/1000 | Loss: 0.00001881
Iteration 84/1000 | Loss: 0.00001881
Iteration 85/1000 | Loss: 0.00001881
Iteration 86/1000 | Loss: 0.00001881
Iteration 87/1000 | Loss: 0.00001881
Iteration 88/1000 | Loss: 0.00001881
Iteration 89/1000 | Loss: 0.00001881
Iteration 90/1000 | Loss: 0.00001881
Iteration 91/1000 | Loss: 0.00001881
Iteration 92/1000 | Loss: 0.00001881
Iteration 93/1000 | Loss: 0.00001881
Iteration 94/1000 | Loss: 0.00001881
Iteration 95/1000 | Loss: 0.00001881
Iteration 96/1000 | Loss: 0.00001881
Iteration 97/1000 | Loss: 0.00001881
Iteration 98/1000 | Loss: 0.00001881
Iteration 99/1000 | Loss: 0.00001881
Iteration 100/1000 | Loss: 0.00001881
Iteration 101/1000 | Loss: 0.00001881
Iteration 102/1000 | Loss: 0.00001881
Iteration 103/1000 | Loss: 0.00001881
Iteration 104/1000 | Loss: 0.00001881
Iteration 105/1000 | Loss: 0.00001881
Iteration 106/1000 | Loss: 0.00001881
Iteration 107/1000 | Loss: 0.00001881
Iteration 108/1000 | Loss: 0.00001881
Iteration 109/1000 | Loss: 0.00001881
Iteration 110/1000 | Loss: 0.00001881
Iteration 111/1000 | Loss: 0.00001881
Iteration 112/1000 | Loss: 0.00001881
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 112. Stopping optimization.
Last 5 losses: [1.8812490452546626e-05, 1.8812490452546626e-05, 1.8812490452546626e-05, 1.8812490452546626e-05, 1.8812490452546626e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8812490452546626e-05

Optimization complete. Final v2v error: 3.7084178924560547 mm

Highest mean error: 3.925344944000244 mm for frame 120

Lowest mean error: 3.5485010147094727 mm for frame 136

Saving results

Total time: 28.72805118560791
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468279
Iteration 2/25 | Loss: 0.00098984
Iteration 3/25 | Loss: 0.00080181
Iteration 4/25 | Loss: 0.00077428
Iteration 5/25 | Loss: 0.00076655
Iteration 6/25 | Loss: 0.00076460
Iteration 7/25 | Loss: 0.00076405
Iteration 8/25 | Loss: 0.00076405
Iteration 9/25 | Loss: 0.00076405
Iteration 10/25 | Loss: 0.00076405
Iteration 11/25 | Loss: 0.00076405
Iteration 12/25 | Loss: 0.00076405
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007640515104867518, 0.0007640515104867518, 0.0007640515104867518, 0.0007640515104867518, 0.0007640515104867518]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007640515104867518

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.26382065
Iteration 2/25 | Loss: 0.00051329
Iteration 3/25 | Loss: 0.00051328
Iteration 4/25 | Loss: 0.00051328
Iteration 5/25 | Loss: 0.00051328
Iteration 6/25 | Loss: 0.00051328
Iteration 7/25 | Loss: 0.00051328
Iteration 8/25 | Loss: 0.00051328
Iteration 9/25 | Loss: 0.00051328
Iteration 10/25 | Loss: 0.00051328
Iteration 11/25 | Loss: 0.00051328
Iteration 12/25 | Loss: 0.00051328
Iteration 13/25 | Loss: 0.00051328
Iteration 14/25 | Loss: 0.00051328
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.000513282313477248, 0.000513282313477248, 0.000513282313477248, 0.000513282313477248, 0.000513282313477248]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000513282313477248

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00051328
Iteration 2/1000 | Loss: 0.00002995
Iteration 3/1000 | Loss: 0.00002011
Iteration 4/1000 | Loss: 0.00001738
Iteration 5/1000 | Loss: 0.00001642
Iteration 6/1000 | Loss: 0.00001559
Iteration 7/1000 | Loss: 0.00001511
Iteration 8/1000 | Loss: 0.00001481
Iteration 9/1000 | Loss: 0.00001456
Iteration 10/1000 | Loss: 0.00001451
Iteration 11/1000 | Loss: 0.00001450
Iteration 12/1000 | Loss: 0.00001441
Iteration 13/1000 | Loss: 0.00001441
Iteration 14/1000 | Loss: 0.00001439
Iteration 15/1000 | Loss: 0.00001439
Iteration 16/1000 | Loss: 0.00001437
Iteration 17/1000 | Loss: 0.00001437
Iteration 18/1000 | Loss: 0.00001433
Iteration 19/1000 | Loss: 0.00001430
Iteration 20/1000 | Loss: 0.00001429
Iteration 21/1000 | Loss: 0.00001427
Iteration 22/1000 | Loss: 0.00001426
Iteration 23/1000 | Loss: 0.00001426
Iteration 24/1000 | Loss: 0.00001423
Iteration 25/1000 | Loss: 0.00001423
Iteration 26/1000 | Loss: 0.00001422
Iteration 27/1000 | Loss: 0.00001422
Iteration 28/1000 | Loss: 0.00001422
Iteration 29/1000 | Loss: 0.00001422
Iteration 30/1000 | Loss: 0.00001421
Iteration 31/1000 | Loss: 0.00001420
Iteration 32/1000 | Loss: 0.00001420
Iteration 33/1000 | Loss: 0.00001417
Iteration 34/1000 | Loss: 0.00001417
Iteration 35/1000 | Loss: 0.00001417
Iteration 36/1000 | Loss: 0.00001416
Iteration 37/1000 | Loss: 0.00001416
Iteration 38/1000 | Loss: 0.00001413
Iteration 39/1000 | Loss: 0.00001413
Iteration 40/1000 | Loss: 0.00001413
Iteration 41/1000 | Loss: 0.00001413
Iteration 42/1000 | Loss: 0.00001413
Iteration 43/1000 | Loss: 0.00001413
Iteration 44/1000 | Loss: 0.00001413
Iteration 45/1000 | Loss: 0.00001413
Iteration 46/1000 | Loss: 0.00001412
Iteration 47/1000 | Loss: 0.00001412
Iteration 48/1000 | Loss: 0.00001411
Iteration 49/1000 | Loss: 0.00001411
Iteration 50/1000 | Loss: 0.00001411
Iteration 51/1000 | Loss: 0.00001410
Iteration 52/1000 | Loss: 0.00001410
Iteration 53/1000 | Loss: 0.00001409
Iteration 54/1000 | Loss: 0.00001409
Iteration 55/1000 | Loss: 0.00001409
Iteration 56/1000 | Loss: 0.00001409
Iteration 57/1000 | Loss: 0.00001409
Iteration 58/1000 | Loss: 0.00001408
Iteration 59/1000 | Loss: 0.00001408
Iteration 60/1000 | Loss: 0.00001408
Iteration 61/1000 | Loss: 0.00001407
Iteration 62/1000 | Loss: 0.00001407
Iteration 63/1000 | Loss: 0.00001407
Iteration 64/1000 | Loss: 0.00001407
Iteration 65/1000 | Loss: 0.00001407
Iteration 66/1000 | Loss: 0.00001407
Iteration 67/1000 | Loss: 0.00001407
Iteration 68/1000 | Loss: 0.00001407
Iteration 69/1000 | Loss: 0.00001407
Iteration 70/1000 | Loss: 0.00001406
Iteration 71/1000 | Loss: 0.00001406
Iteration 72/1000 | Loss: 0.00001406
Iteration 73/1000 | Loss: 0.00001406
Iteration 74/1000 | Loss: 0.00001406
Iteration 75/1000 | Loss: 0.00001406
Iteration 76/1000 | Loss: 0.00001406
Iteration 77/1000 | Loss: 0.00001406
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [1.4064145034353714e-05, 1.4064145034353714e-05, 1.4064145034353714e-05, 1.4064145034353714e-05, 1.4064145034353714e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4064145034353714e-05

Optimization complete. Final v2v error: 3.216301918029785 mm

Highest mean error: 3.533616781234741 mm for frame 108

Lowest mean error: 2.9262099266052246 mm for frame 136

Saving results

Total time: 29.778873205184937
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00456705
Iteration 2/25 | Loss: 0.00097164
Iteration 3/25 | Loss: 0.00085761
Iteration 4/25 | Loss: 0.00082263
Iteration 5/25 | Loss: 0.00081655
Iteration 6/25 | Loss: 0.00081562
Iteration 7/25 | Loss: 0.00081562
Iteration 8/25 | Loss: 0.00081562
Iteration 9/25 | Loss: 0.00081562
Iteration 10/25 | Loss: 0.00081562
Iteration 11/25 | Loss: 0.00081562
Iteration 12/25 | Loss: 0.00081562
Iteration 13/25 | Loss: 0.00081562
Iteration 14/25 | Loss: 0.00081562
Iteration 15/25 | Loss: 0.00081562
Iteration 16/25 | Loss: 0.00081562
Iteration 17/25 | Loss: 0.00081562
Iteration 18/25 | Loss: 0.00081562
Iteration 19/25 | Loss: 0.00081562
Iteration 20/25 | Loss: 0.00081562
Iteration 21/25 | Loss: 0.00081562
Iteration 22/25 | Loss: 0.00081562
Iteration 23/25 | Loss: 0.00081562
Iteration 24/25 | Loss: 0.00081562
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0008156222174875438, 0.0008156222174875438, 0.0008156222174875438, 0.0008156222174875438, 0.0008156222174875438]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008156222174875438

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47094178
Iteration 2/25 | Loss: 0.00047530
Iteration 3/25 | Loss: 0.00047530
Iteration 4/25 | Loss: 0.00047530
Iteration 5/25 | Loss: 0.00047530
Iteration 6/25 | Loss: 0.00047530
Iteration 7/25 | Loss: 0.00047530
Iteration 8/25 | Loss: 0.00047530
Iteration 9/25 | Loss: 0.00047530
Iteration 10/25 | Loss: 0.00047530
Iteration 11/25 | Loss: 0.00047530
Iteration 12/25 | Loss: 0.00047529
Iteration 13/25 | Loss: 0.00047529
Iteration 14/25 | Loss: 0.00047529
Iteration 15/25 | Loss: 0.00047529
Iteration 16/25 | Loss: 0.00047529
Iteration 17/25 | Loss: 0.00047529
Iteration 18/25 | Loss: 0.00047529
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00047529477160423994, 0.00047529477160423994, 0.00047529477160423994, 0.00047529477160423994, 0.00047529477160423994]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00047529477160423994

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047529
Iteration 2/1000 | Loss: 0.00005491
Iteration 3/1000 | Loss: 0.00003493
Iteration 4/1000 | Loss: 0.00003185
Iteration 5/1000 | Loss: 0.00002999
Iteration 6/1000 | Loss: 0.00002892
Iteration 7/1000 | Loss: 0.00002828
Iteration 8/1000 | Loss: 0.00002750
Iteration 9/1000 | Loss: 0.00002714
Iteration 10/1000 | Loss: 0.00002684
Iteration 11/1000 | Loss: 0.00002662
Iteration 12/1000 | Loss: 0.00002661
Iteration 13/1000 | Loss: 0.00002660
Iteration 14/1000 | Loss: 0.00002640
Iteration 15/1000 | Loss: 0.00002632
Iteration 16/1000 | Loss: 0.00002632
Iteration 17/1000 | Loss: 0.00002632
Iteration 18/1000 | Loss: 0.00002628
Iteration 19/1000 | Loss: 0.00002628
Iteration 20/1000 | Loss: 0.00002627
Iteration 21/1000 | Loss: 0.00002626
Iteration 22/1000 | Loss: 0.00002625
Iteration 23/1000 | Loss: 0.00002624
Iteration 24/1000 | Loss: 0.00002623
Iteration 25/1000 | Loss: 0.00002623
Iteration 26/1000 | Loss: 0.00002622
Iteration 27/1000 | Loss: 0.00002622
Iteration 28/1000 | Loss: 0.00002621
Iteration 29/1000 | Loss: 0.00002614
Iteration 30/1000 | Loss: 0.00002604
Iteration 31/1000 | Loss: 0.00002602
Iteration 32/1000 | Loss: 0.00002601
Iteration 33/1000 | Loss: 0.00002599
Iteration 34/1000 | Loss: 0.00002596
Iteration 35/1000 | Loss: 0.00002596
Iteration 36/1000 | Loss: 0.00002596
Iteration 37/1000 | Loss: 0.00002596
Iteration 38/1000 | Loss: 0.00002596
Iteration 39/1000 | Loss: 0.00002596
Iteration 40/1000 | Loss: 0.00002596
Iteration 41/1000 | Loss: 0.00002596
Iteration 42/1000 | Loss: 0.00002596
Iteration 43/1000 | Loss: 0.00002596
Iteration 44/1000 | Loss: 0.00002596
Iteration 45/1000 | Loss: 0.00002596
Iteration 46/1000 | Loss: 0.00002595
Iteration 47/1000 | Loss: 0.00002595
Iteration 48/1000 | Loss: 0.00002594
Iteration 49/1000 | Loss: 0.00002593
Iteration 50/1000 | Loss: 0.00002593
Iteration 51/1000 | Loss: 0.00002592
Iteration 52/1000 | Loss: 0.00002592
Iteration 53/1000 | Loss: 0.00002592
Iteration 54/1000 | Loss: 0.00002592
Iteration 55/1000 | Loss: 0.00002592
Iteration 56/1000 | Loss: 0.00002592
Iteration 57/1000 | Loss: 0.00002592
Iteration 58/1000 | Loss: 0.00002591
Iteration 59/1000 | Loss: 0.00002591
Iteration 60/1000 | Loss: 0.00002590
Iteration 61/1000 | Loss: 0.00002589
Iteration 62/1000 | Loss: 0.00002589
Iteration 63/1000 | Loss: 0.00002589
Iteration 64/1000 | Loss: 0.00002588
Iteration 65/1000 | Loss: 0.00002588
Iteration 66/1000 | Loss: 0.00002588
Iteration 67/1000 | Loss: 0.00002588
Iteration 68/1000 | Loss: 0.00002586
Iteration 69/1000 | Loss: 0.00002586
Iteration 70/1000 | Loss: 0.00002586
Iteration 71/1000 | Loss: 0.00002586
Iteration 72/1000 | Loss: 0.00002586
Iteration 73/1000 | Loss: 0.00002586
Iteration 74/1000 | Loss: 0.00002586
Iteration 75/1000 | Loss: 0.00002586
Iteration 76/1000 | Loss: 0.00002586
Iteration 77/1000 | Loss: 0.00002585
Iteration 78/1000 | Loss: 0.00002585
Iteration 79/1000 | Loss: 0.00002585
Iteration 80/1000 | Loss: 0.00002585
Iteration 81/1000 | Loss: 0.00002585
Iteration 82/1000 | Loss: 0.00002585
Iteration 83/1000 | Loss: 0.00002585
Iteration 84/1000 | Loss: 0.00002585
Iteration 85/1000 | Loss: 0.00002585
Iteration 86/1000 | Loss: 0.00002585
Iteration 87/1000 | Loss: 0.00002585
Iteration 88/1000 | Loss: 0.00002585
Iteration 89/1000 | Loss: 0.00002585
Iteration 90/1000 | Loss: 0.00002585
Iteration 91/1000 | Loss: 0.00002585
Iteration 92/1000 | Loss: 0.00002585
Iteration 93/1000 | Loss: 0.00002585
Iteration 94/1000 | Loss: 0.00002585
Iteration 95/1000 | Loss: 0.00002585
Iteration 96/1000 | Loss: 0.00002585
Iteration 97/1000 | Loss: 0.00002585
Iteration 98/1000 | Loss: 0.00002585
Iteration 99/1000 | Loss: 0.00002585
Iteration 100/1000 | Loss: 0.00002585
Iteration 101/1000 | Loss: 0.00002585
Iteration 102/1000 | Loss: 0.00002585
Iteration 103/1000 | Loss: 0.00002585
Iteration 104/1000 | Loss: 0.00002585
Iteration 105/1000 | Loss: 0.00002585
Iteration 106/1000 | Loss: 0.00002585
Iteration 107/1000 | Loss: 0.00002585
Iteration 108/1000 | Loss: 0.00002585
Iteration 109/1000 | Loss: 0.00002585
Iteration 110/1000 | Loss: 0.00002585
Iteration 111/1000 | Loss: 0.00002585
Iteration 112/1000 | Loss: 0.00002585
Iteration 113/1000 | Loss: 0.00002585
Iteration 114/1000 | Loss: 0.00002585
Iteration 115/1000 | Loss: 0.00002585
Iteration 116/1000 | Loss: 0.00002585
Iteration 117/1000 | Loss: 0.00002585
Iteration 118/1000 | Loss: 0.00002585
Iteration 119/1000 | Loss: 0.00002585
Iteration 120/1000 | Loss: 0.00002585
Iteration 121/1000 | Loss: 0.00002585
Iteration 122/1000 | Loss: 0.00002585
Iteration 123/1000 | Loss: 0.00002585
Iteration 124/1000 | Loss: 0.00002585
Iteration 125/1000 | Loss: 0.00002585
Iteration 126/1000 | Loss: 0.00002585
Iteration 127/1000 | Loss: 0.00002585
Iteration 128/1000 | Loss: 0.00002585
Iteration 129/1000 | Loss: 0.00002585
Iteration 130/1000 | Loss: 0.00002585
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 130. Stopping optimization.
Last 5 losses: [2.585149195510894e-05, 2.585149195510894e-05, 2.585149195510894e-05, 2.585149195510894e-05, 2.585149195510894e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.585149195510894e-05

Optimization complete. Final v2v error: 4.242527961730957 mm

Highest mean error: 4.442812919616699 mm for frame 124

Lowest mean error: 3.949819564819336 mm for frame 45

Saving results

Total time: 36.3368501663208
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1089/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1089.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1089
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00805987
Iteration 2/25 | Loss: 0.00117213
Iteration 3/25 | Loss: 0.00088686
Iteration 4/25 | Loss: 0.00081809
Iteration 5/25 | Loss: 0.00080190
Iteration 6/25 | Loss: 0.00079716
Iteration 7/25 | Loss: 0.00079671
Iteration 8/25 | Loss: 0.00079671
Iteration 9/25 | Loss: 0.00079668
Iteration 10/25 | Loss: 0.00079668
Iteration 11/25 | Loss: 0.00079668
Iteration 12/25 | Loss: 0.00079668
Iteration 13/25 | Loss: 0.00079668
Iteration 14/25 | Loss: 0.00079668
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0007966752164065838, 0.0007966752164065838, 0.0007966752164065838, 0.0007966752164065838, 0.0007966752164065838]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007966752164065838

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49796987
Iteration 2/25 | Loss: 0.00054451
Iteration 3/25 | Loss: 0.00054450
Iteration 4/25 | Loss: 0.00054450
Iteration 5/25 | Loss: 0.00054450
Iteration 6/25 | Loss: 0.00054450
Iteration 7/25 | Loss: 0.00054450
Iteration 8/25 | Loss: 0.00054450
Iteration 9/25 | Loss: 0.00054450
Iteration 10/25 | Loss: 0.00054450
Iteration 11/25 | Loss: 0.00054450
Iteration 12/25 | Loss: 0.00054450
Iteration 13/25 | Loss: 0.00054450
Iteration 14/25 | Loss: 0.00054450
Iteration 15/25 | Loss: 0.00054450
Iteration 16/25 | Loss: 0.00054450
Iteration 17/25 | Loss: 0.00054450
Iteration 18/25 | Loss: 0.00054450
Iteration 19/25 | Loss: 0.00054450
Iteration 20/25 | Loss: 0.00054450
Iteration 21/25 | Loss: 0.00054450
Iteration 22/25 | Loss: 0.00054450
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005445004208013415, 0.0005445004208013415, 0.0005445004208013415, 0.0005445004208013415, 0.0005445004208013415]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005445004208013415

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054450
Iteration 2/1000 | Loss: 0.00003524
Iteration 3/1000 | Loss: 0.00002748
Iteration 4/1000 | Loss: 0.00002457
Iteration 5/1000 | Loss: 0.00002314
Iteration 6/1000 | Loss: 0.00002225
Iteration 7/1000 | Loss: 0.00002143
Iteration 8/1000 | Loss: 0.00002095
Iteration 9/1000 | Loss: 0.00002063
Iteration 10/1000 | Loss: 0.00002040
Iteration 11/1000 | Loss: 0.00002029
Iteration 12/1000 | Loss: 0.00002027
Iteration 13/1000 | Loss: 0.00002010
Iteration 14/1000 | Loss: 0.00002006
Iteration 15/1000 | Loss: 0.00002005
Iteration 16/1000 | Loss: 0.00002004
Iteration 17/1000 | Loss: 0.00002003
Iteration 18/1000 | Loss: 0.00002002
Iteration 19/1000 | Loss: 0.00001999
Iteration 20/1000 | Loss: 0.00001997
Iteration 21/1000 | Loss: 0.00001996
Iteration 22/1000 | Loss: 0.00001995
Iteration 23/1000 | Loss: 0.00001995
Iteration 24/1000 | Loss: 0.00001995
Iteration 25/1000 | Loss: 0.00001995
Iteration 26/1000 | Loss: 0.00001994
Iteration 27/1000 | Loss: 0.00001994
Iteration 28/1000 | Loss: 0.00001994
Iteration 29/1000 | Loss: 0.00001994
Iteration 30/1000 | Loss: 0.00001994
Iteration 31/1000 | Loss: 0.00001994
Iteration 32/1000 | Loss: 0.00001993
Iteration 33/1000 | Loss: 0.00001993
Iteration 34/1000 | Loss: 0.00001993
Iteration 35/1000 | Loss: 0.00001993
Iteration 36/1000 | Loss: 0.00001991
Iteration 37/1000 | Loss: 0.00001991
Iteration 38/1000 | Loss: 0.00001991
Iteration 39/1000 | Loss: 0.00001991
Iteration 40/1000 | Loss: 0.00001990
Iteration 41/1000 | Loss: 0.00001990
Iteration 42/1000 | Loss: 0.00001990
Iteration 43/1000 | Loss: 0.00001990
Iteration 44/1000 | Loss: 0.00001990
Iteration 45/1000 | Loss: 0.00001989
Iteration 46/1000 | Loss: 0.00001989
Iteration 47/1000 | Loss: 0.00001989
Iteration 48/1000 | Loss: 0.00001989
Iteration 49/1000 | Loss: 0.00001988
Iteration 50/1000 | Loss: 0.00001988
Iteration 51/1000 | Loss: 0.00001988
Iteration 52/1000 | Loss: 0.00001987
Iteration 53/1000 | Loss: 0.00001987
Iteration 54/1000 | Loss: 0.00001987
Iteration 55/1000 | Loss: 0.00001987
Iteration 56/1000 | Loss: 0.00001987
Iteration 57/1000 | Loss: 0.00001987
Iteration 58/1000 | Loss: 0.00001986
Iteration 59/1000 | Loss: 0.00001986
Iteration 60/1000 | Loss: 0.00001985
Iteration 61/1000 | Loss: 0.00001985
Iteration 62/1000 | Loss: 0.00001984
Iteration 63/1000 | Loss: 0.00001984
Iteration 64/1000 | Loss: 0.00001983
Iteration 65/1000 | Loss: 0.00001983
Iteration 66/1000 | Loss: 0.00001983
Iteration 67/1000 | Loss: 0.00001981
Iteration 68/1000 | Loss: 0.00001981
Iteration 69/1000 | Loss: 0.00001981
Iteration 70/1000 | Loss: 0.00001979
Iteration 71/1000 | Loss: 0.00001979
Iteration 72/1000 | Loss: 0.00001979
Iteration 73/1000 | Loss: 0.00001979
Iteration 74/1000 | Loss: 0.00001979
Iteration 75/1000 | Loss: 0.00001979
Iteration 76/1000 | Loss: 0.00001979
Iteration 77/1000 | Loss: 0.00001978
Iteration 78/1000 | Loss: 0.00001978
Iteration 79/1000 | Loss: 0.00001978
Iteration 80/1000 | Loss: 0.00001978
Iteration 81/1000 | Loss: 0.00001977
Iteration 82/1000 | Loss: 0.00001976
Iteration 83/1000 | Loss: 0.00001976
Iteration 84/1000 | Loss: 0.00001975
Iteration 85/1000 | Loss: 0.00001975
Iteration 86/1000 | Loss: 0.00001975
Iteration 87/1000 | Loss: 0.00001975
Iteration 88/1000 | Loss: 0.00001975
Iteration 89/1000 | Loss: 0.00001975
Iteration 90/1000 | Loss: 0.00001975
Iteration 91/1000 | Loss: 0.00001975
Iteration 92/1000 | Loss: 0.00001975
Iteration 93/1000 | Loss: 0.00001975
Iteration 94/1000 | Loss: 0.00001975
Iteration 95/1000 | Loss: 0.00001975
Iteration 96/1000 | Loss: 0.00001975
Iteration 97/1000 | Loss: 0.00001975
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 97. Stopping optimization.
Last 5 losses: [1.9747149053728208e-05, 1.9747149053728208e-05, 1.9747149053728208e-05, 1.9747149053728208e-05, 1.9747149053728208e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9747149053728208e-05

Optimization complete. Final v2v error: 3.7485883235931396 mm

Highest mean error: 4.487919330596924 mm for frame 184

Lowest mean error: 3.5104503631591797 mm for frame 21

Saving results

Total time: 38.4259569644928
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1036/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1036.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1036
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00502534
Iteration 2/25 | Loss: 0.00103621
Iteration 3/25 | Loss: 0.00084872
Iteration 4/25 | Loss: 0.00075459
Iteration 5/25 | Loss: 0.00073709
Iteration 6/25 | Loss: 0.00073406
Iteration 7/25 | Loss: 0.00073346
Iteration 8/25 | Loss: 0.00073327
Iteration 9/25 | Loss: 0.00073326
Iteration 10/25 | Loss: 0.00073326
Iteration 11/25 | Loss: 0.00073326
Iteration 12/25 | Loss: 0.00073326
Iteration 13/25 | Loss: 0.00073326
Iteration 14/25 | Loss: 0.00073326
Iteration 15/25 | Loss: 0.00073326
Iteration 16/25 | Loss: 0.00073326
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007332565146498382, 0.0007332565146498382, 0.0007332565146498382, 0.0007332565146498382, 0.0007332565146498382]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007332565146498382

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.05043602
Iteration 2/25 | Loss: 0.00051997
Iteration 3/25 | Loss: 0.00051994
Iteration 4/25 | Loss: 0.00051994
Iteration 5/25 | Loss: 0.00051994
Iteration 6/25 | Loss: 0.00051994
Iteration 7/25 | Loss: 0.00051994
Iteration 8/25 | Loss: 0.00051994
Iteration 9/25 | Loss: 0.00051994
Iteration 10/25 | Loss: 0.00051994
Iteration 11/25 | Loss: 0.00051994
Iteration 12/25 | Loss: 0.00051994
Iteration 13/25 | Loss: 0.00051994
Iteration 14/25 | Loss: 0.00051994
Iteration 15/25 | Loss: 0.00051994
Iteration 16/25 | Loss: 0.00051994
Iteration 17/25 | Loss: 0.00051994
Iteration 18/25 | Loss: 0.00051994
Iteration 19/25 | Loss: 0.00051994
Iteration 20/25 | Loss: 0.00051994
Iteration 21/25 | Loss: 0.00051994
Iteration 22/25 | Loss: 0.00051994
Iteration 23/25 | Loss: 0.00051994
Iteration 24/25 | Loss: 0.00051994
Iteration 25/25 | Loss: 0.00051994

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00051994
Iteration 2/1000 | Loss: 0.00002568
Iteration 3/1000 | Loss: 0.00001640
Iteration 4/1000 | Loss: 0.00001523
Iteration 5/1000 | Loss: 0.00001455
Iteration 6/1000 | Loss: 0.00001391
Iteration 7/1000 | Loss: 0.00001351
Iteration 8/1000 | Loss: 0.00001326
Iteration 9/1000 | Loss: 0.00001306
Iteration 10/1000 | Loss: 0.00001296
Iteration 11/1000 | Loss: 0.00001292
Iteration 12/1000 | Loss: 0.00001286
Iteration 13/1000 | Loss: 0.00001282
Iteration 14/1000 | Loss: 0.00001280
Iteration 15/1000 | Loss: 0.00001279
Iteration 16/1000 | Loss: 0.00001279
Iteration 17/1000 | Loss: 0.00001278
Iteration 18/1000 | Loss: 0.00001278
Iteration 19/1000 | Loss: 0.00001276
Iteration 20/1000 | Loss: 0.00001275
Iteration 21/1000 | Loss: 0.00001274
Iteration 22/1000 | Loss: 0.00001272
Iteration 23/1000 | Loss: 0.00001271
Iteration 24/1000 | Loss: 0.00001271
Iteration 25/1000 | Loss: 0.00001270
Iteration 26/1000 | Loss: 0.00001268
Iteration 27/1000 | Loss: 0.00001260
Iteration 28/1000 | Loss: 0.00001257
Iteration 29/1000 | Loss: 0.00001257
Iteration 30/1000 | Loss: 0.00001257
Iteration 31/1000 | Loss: 0.00001257
Iteration 32/1000 | Loss: 0.00001256
Iteration 33/1000 | Loss: 0.00001256
Iteration 34/1000 | Loss: 0.00001256
Iteration 35/1000 | Loss: 0.00001256
Iteration 36/1000 | Loss: 0.00001255
Iteration 37/1000 | Loss: 0.00001255
Iteration 38/1000 | Loss: 0.00001255
Iteration 39/1000 | Loss: 0.00001255
Iteration 40/1000 | Loss: 0.00001255
Iteration 41/1000 | Loss: 0.00001255
Iteration 42/1000 | Loss: 0.00001254
Iteration 43/1000 | Loss: 0.00001254
Iteration 44/1000 | Loss: 0.00001254
Iteration 45/1000 | Loss: 0.00001254
Iteration 46/1000 | Loss: 0.00001254
Iteration 47/1000 | Loss: 0.00001254
Iteration 48/1000 | Loss: 0.00001254
Iteration 49/1000 | Loss: 0.00001254
Iteration 50/1000 | Loss: 0.00001253
Iteration 51/1000 | Loss: 0.00001253
Iteration 52/1000 | Loss: 0.00001252
Iteration 53/1000 | Loss: 0.00001252
Iteration 54/1000 | Loss: 0.00001252
Iteration 55/1000 | Loss: 0.00001252
Iteration 56/1000 | Loss: 0.00001251
Iteration 57/1000 | Loss: 0.00001251
Iteration 58/1000 | Loss: 0.00001251
Iteration 59/1000 | Loss: 0.00001251
Iteration 60/1000 | Loss: 0.00001251
Iteration 61/1000 | Loss: 0.00001251
Iteration 62/1000 | Loss: 0.00001251
Iteration 63/1000 | Loss: 0.00001251
Iteration 64/1000 | Loss: 0.00001251
Iteration 65/1000 | Loss: 0.00001250
Iteration 66/1000 | Loss: 0.00001250
Iteration 67/1000 | Loss: 0.00001250
Iteration 68/1000 | Loss: 0.00001249
Iteration 69/1000 | Loss: 0.00001249
Iteration 70/1000 | Loss: 0.00001248
Iteration 71/1000 | Loss: 0.00001248
Iteration 72/1000 | Loss: 0.00001248
Iteration 73/1000 | Loss: 0.00001247
Iteration 74/1000 | Loss: 0.00001247
Iteration 75/1000 | Loss: 0.00001246
Iteration 76/1000 | Loss: 0.00001246
Iteration 77/1000 | Loss: 0.00001246
Iteration 78/1000 | Loss: 0.00001246
Iteration 79/1000 | Loss: 0.00001245
Iteration 80/1000 | Loss: 0.00001244
Iteration 81/1000 | Loss: 0.00001244
Iteration 82/1000 | Loss: 0.00001244
Iteration 83/1000 | Loss: 0.00001244
Iteration 84/1000 | Loss: 0.00001243
Iteration 85/1000 | Loss: 0.00001243
Iteration 86/1000 | Loss: 0.00001243
Iteration 87/1000 | Loss: 0.00001243
Iteration 88/1000 | Loss: 0.00001243
Iteration 89/1000 | Loss: 0.00001243
Iteration 90/1000 | Loss: 0.00001243
Iteration 91/1000 | Loss: 0.00001243
Iteration 92/1000 | Loss: 0.00001243
Iteration 93/1000 | Loss: 0.00001243
Iteration 94/1000 | Loss: 0.00001242
Iteration 95/1000 | Loss: 0.00001242
Iteration 96/1000 | Loss: 0.00001242
Iteration 97/1000 | Loss: 0.00001241
Iteration 98/1000 | Loss: 0.00001241
Iteration 99/1000 | Loss: 0.00001240
Iteration 100/1000 | Loss: 0.00001240
Iteration 101/1000 | Loss: 0.00001240
Iteration 102/1000 | Loss: 0.00001240
Iteration 103/1000 | Loss: 0.00001239
Iteration 104/1000 | Loss: 0.00001239
Iteration 105/1000 | Loss: 0.00001238
Iteration 106/1000 | Loss: 0.00001238
Iteration 107/1000 | Loss: 0.00001238
Iteration 108/1000 | Loss: 0.00001237
Iteration 109/1000 | Loss: 0.00001237
Iteration 110/1000 | Loss: 0.00001237
Iteration 111/1000 | Loss: 0.00001237
Iteration 112/1000 | Loss: 0.00001237
Iteration 113/1000 | Loss: 0.00001236
Iteration 114/1000 | Loss: 0.00001236
Iteration 115/1000 | Loss: 0.00001236
Iteration 116/1000 | Loss: 0.00001236
Iteration 117/1000 | Loss: 0.00001236
Iteration 118/1000 | Loss: 0.00001236
Iteration 119/1000 | Loss: 0.00001236
Iteration 120/1000 | Loss: 0.00001235
Iteration 121/1000 | Loss: 0.00001235
Iteration 122/1000 | Loss: 0.00001235
Iteration 123/1000 | Loss: 0.00001235
Iteration 124/1000 | Loss: 0.00001235
Iteration 125/1000 | Loss: 0.00001235
Iteration 126/1000 | Loss: 0.00001235
Iteration 127/1000 | Loss: 0.00001235
Iteration 128/1000 | Loss: 0.00001235
Iteration 129/1000 | Loss: 0.00001235
Iteration 130/1000 | Loss: 0.00001235
Iteration 131/1000 | Loss: 0.00001235
Iteration 132/1000 | Loss: 0.00001235
Iteration 133/1000 | Loss: 0.00001235
Iteration 134/1000 | Loss: 0.00001235
Iteration 135/1000 | Loss: 0.00001235
Iteration 136/1000 | Loss: 0.00001235
Iteration 137/1000 | Loss: 0.00001234
Iteration 138/1000 | Loss: 0.00001234
Iteration 139/1000 | Loss: 0.00001234
Iteration 140/1000 | Loss: 0.00001234
Iteration 141/1000 | Loss: 0.00001234
Iteration 142/1000 | Loss: 0.00001234
Iteration 143/1000 | Loss: 0.00001234
Iteration 144/1000 | Loss: 0.00001234
Iteration 145/1000 | Loss: 0.00001234
Iteration 146/1000 | Loss: 0.00001234
Iteration 147/1000 | Loss: 0.00001234
Iteration 148/1000 | Loss: 0.00001234
Iteration 149/1000 | Loss: 0.00001234
Iteration 150/1000 | Loss: 0.00001234
Iteration 151/1000 | Loss: 0.00001234
Iteration 152/1000 | Loss: 0.00001234
Iteration 153/1000 | Loss: 0.00001234
Iteration 154/1000 | Loss: 0.00001234
Iteration 155/1000 | Loss: 0.00001234
Iteration 156/1000 | Loss: 0.00001234
Iteration 157/1000 | Loss: 0.00001233
Iteration 158/1000 | Loss: 0.00001233
Iteration 159/1000 | Loss: 0.00001233
Iteration 160/1000 | Loss: 0.00001233
Iteration 161/1000 | Loss: 0.00001233
Iteration 162/1000 | Loss: 0.00001233
Iteration 163/1000 | Loss: 0.00001233
Iteration 164/1000 | Loss: 0.00001233
Iteration 165/1000 | Loss: 0.00001233
Iteration 166/1000 | Loss: 0.00001233
Iteration 167/1000 | Loss: 0.00001233
Iteration 168/1000 | Loss: 0.00001233
Iteration 169/1000 | Loss: 0.00001233
Iteration 170/1000 | Loss: 0.00001233
Iteration 171/1000 | Loss: 0.00001233
Iteration 172/1000 | Loss: 0.00001233
Iteration 173/1000 | Loss: 0.00001233
Iteration 174/1000 | Loss: 0.00001233
Iteration 175/1000 | Loss: 0.00001233
Iteration 176/1000 | Loss: 0.00001233
Iteration 177/1000 | Loss: 0.00001232
Iteration 178/1000 | Loss: 0.00001232
Iteration 179/1000 | Loss: 0.00001232
Iteration 180/1000 | Loss: 0.00001232
Iteration 181/1000 | Loss: 0.00001232
Iteration 182/1000 | Loss: 0.00001232
Iteration 183/1000 | Loss: 0.00001232
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 183. Stopping optimization.
Last 5 losses: [1.2324740964686498e-05, 1.2324740964686498e-05, 1.2324740964686498e-05, 1.2324740964686498e-05, 1.2324740964686498e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2324740964686498e-05

Optimization complete. Final v2v error: 2.9626553058624268 mm

Highest mean error: 3.343536853790283 mm for frame 199

Lowest mean error: 2.625699996948242 mm for frame 32

Saving results

Total time: 46.95609998703003
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1054/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1054.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1054
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00334303
Iteration 2/25 | Loss: 0.00116978
Iteration 3/25 | Loss: 0.00087425
Iteration 4/25 | Loss: 0.00077056
Iteration 5/25 | Loss: 0.00075029
Iteration 6/25 | Loss: 0.00074562
Iteration 7/25 | Loss: 0.00074421
Iteration 8/25 | Loss: 0.00074375
Iteration 9/25 | Loss: 0.00074355
Iteration 10/25 | Loss: 0.00074351
Iteration 11/25 | Loss: 0.00074351
Iteration 12/25 | Loss: 0.00074351
Iteration 13/25 | Loss: 0.00074351
Iteration 14/25 | Loss: 0.00074351
Iteration 15/25 | Loss: 0.00074351
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0007435135776177049, 0.0007435135776177049, 0.0007435135776177049, 0.0007435135776177049, 0.0007435135776177049]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007435135776177049

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52041662
Iteration 2/25 | Loss: 0.00055151
Iteration 3/25 | Loss: 0.00055151
Iteration 4/25 | Loss: 0.00055151
Iteration 5/25 | Loss: 0.00055150
Iteration 6/25 | Loss: 0.00055150
Iteration 7/25 | Loss: 0.00055150
Iteration 8/25 | Loss: 0.00055150
Iteration 9/25 | Loss: 0.00055150
Iteration 10/25 | Loss: 0.00055150
Iteration 11/25 | Loss: 0.00055150
Iteration 12/25 | Loss: 0.00055150
Iteration 13/25 | Loss: 0.00055150
Iteration 14/25 | Loss: 0.00055150
Iteration 15/25 | Loss: 0.00055150
Iteration 16/25 | Loss: 0.00055150
Iteration 17/25 | Loss: 0.00055150
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0005515036755241454, 0.0005515036755241454, 0.0005515036755241454, 0.0005515036755241454, 0.0005515036755241454]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005515036755241454

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055150
Iteration 2/1000 | Loss: 0.00002980
Iteration 3/1000 | Loss: 0.00002247
Iteration 4/1000 | Loss: 0.00001950
Iteration 5/1000 | Loss: 0.00001826
Iteration 6/1000 | Loss: 0.00001736
Iteration 7/1000 | Loss: 0.00001692
Iteration 8/1000 | Loss: 0.00001659
Iteration 9/1000 | Loss: 0.00001628
Iteration 10/1000 | Loss: 0.00001602
Iteration 11/1000 | Loss: 0.00001584
Iteration 12/1000 | Loss: 0.00001577
Iteration 13/1000 | Loss: 0.00001563
Iteration 14/1000 | Loss: 0.00001552
Iteration 15/1000 | Loss: 0.00001545
Iteration 16/1000 | Loss: 0.00001541
Iteration 17/1000 | Loss: 0.00001541
Iteration 18/1000 | Loss: 0.00001538
Iteration 19/1000 | Loss: 0.00001538
Iteration 20/1000 | Loss: 0.00001538
Iteration 21/1000 | Loss: 0.00001537
Iteration 22/1000 | Loss: 0.00001536
Iteration 23/1000 | Loss: 0.00001535
Iteration 24/1000 | Loss: 0.00001535
Iteration 25/1000 | Loss: 0.00001535
Iteration 26/1000 | Loss: 0.00001535
Iteration 27/1000 | Loss: 0.00001534
Iteration 28/1000 | Loss: 0.00001534
Iteration 29/1000 | Loss: 0.00001534
Iteration 30/1000 | Loss: 0.00001534
Iteration 31/1000 | Loss: 0.00001534
Iteration 32/1000 | Loss: 0.00001533
Iteration 33/1000 | Loss: 0.00001533
Iteration 34/1000 | Loss: 0.00001533
Iteration 35/1000 | Loss: 0.00001533
Iteration 36/1000 | Loss: 0.00001533
Iteration 37/1000 | Loss: 0.00001533
Iteration 38/1000 | Loss: 0.00001532
Iteration 39/1000 | Loss: 0.00001532
Iteration 40/1000 | Loss: 0.00001532
Iteration 41/1000 | Loss: 0.00001531
Iteration 42/1000 | Loss: 0.00001531
Iteration 43/1000 | Loss: 0.00001531
Iteration 44/1000 | Loss: 0.00001531
Iteration 45/1000 | Loss: 0.00001531
Iteration 46/1000 | Loss: 0.00001531
Iteration 47/1000 | Loss: 0.00001531
Iteration 48/1000 | Loss: 0.00001531
Iteration 49/1000 | Loss: 0.00001530
Iteration 50/1000 | Loss: 0.00001530
Iteration 51/1000 | Loss: 0.00001530
Iteration 52/1000 | Loss: 0.00001530
Iteration 53/1000 | Loss: 0.00001529
Iteration 54/1000 | Loss: 0.00001529
Iteration 55/1000 | Loss: 0.00001529
Iteration 56/1000 | Loss: 0.00001529
Iteration 57/1000 | Loss: 0.00001529
Iteration 58/1000 | Loss: 0.00001529
Iteration 59/1000 | Loss: 0.00001529
Iteration 60/1000 | Loss: 0.00001529
Iteration 61/1000 | Loss: 0.00001529
Iteration 62/1000 | Loss: 0.00001528
Iteration 63/1000 | Loss: 0.00001528
Iteration 64/1000 | Loss: 0.00001528
Iteration 65/1000 | Loss: 0.00001528
Iteration 66/1000 | Loss: 0.00001528
Iteration 67/1000 | Loss: 0.00001528
Iteration 68/1000 | Loss: 0.00001528
Iteration 69/1000 | Loss: 0.00001528
Iteration 70/1000 | Loss: 0.00001528
Iteration 71/1000 | Loss: 0.00001528
Iteration 72/1000 | Loss: 0.00001528
Iteration 73/1000 | Loss: 0.00001527
Iteration 74/1000 | Loss: 0.00001527
Iteration 75/1000 | Loss: 0.00001527
Iteration 76/1000 | Loss: 0.00001527
Iteration 77/1000 | Loss: 0.00001527
Iteration 78/1000 | Loss: 0.00001527
Iteration 79/1000 | Loss: 0.00001527
Iteration 80/1000 | Loss: 0.00001527
Iteration 81/1000 | Loss: 0.00001527
Iteration 82/1000 | Loss: 0.00001527
Iteration 83/1000 | Loss: 0.00001527
Iteration 84/1000 | Loss: 0.00001527
Iteration 85/1000 | Loss: 0.00001526
Iteration 86/1000 | Loss: 0.00001526
Iteration 87/1000 | Loss: 0.00001526
Iteration 88/1000 | Loss: 0.00001526
Iteration 89/1000 | Loss: 0.00001526
Iteration 90/1000 | Loss: 0.00001526
Iteration 91/1000 | Loss: 0.00001526
Iteration 92/1000 | Loss: 0.00001525
Iteration 93/1000 | Loss: 0.00001525
Iteration 94/1000 | Loss: 0.00001525
Iteration 95/1000 | Loss: 0.00001525
Iteration 96/1000 | Loss: 0.00001525
Iteration 97/1000 | Loss: 0.00001525
Iteration 98/1000 | Loss: 0.00001525
Iteration 99/1000 | Loss: 0.00001525
Iteration 100/1000 | Loss: 0.00001525
Iteration 101/1000 | Loss: 0.00001525
Iteration 102/1000 | Loss: 0.00001525
Iteration 103/1000 | Loss: 0.00001525
Iteration 104/1000 | Loss: 0.00001524
Iteration 105/1000 | Loss: 0.00001524
Iteration 106/1000 | Loss: 0.00001524
Iteration 107/1000 | Loss: 0.00001524
Iteration 108/1000 | Loss: 0.00001524
Iteration 109/1000 | Loss: 0.00001524
Iteration 110/1000 | Loss: 0.00001524
Iteration 111/1000 | Loss: 0.00001524
Iteration 112/1000 | Loss: 0.00001524
Iteration 113/1000 | Loss: 0.00001524
Iteration 114/1000 | Loss: 0.00001523
Iteration 115/1000 | Loss: 0.00001523
Iteration 116/1000 | Loss: 0.00001523
Iteration 117/1000 | Loss: 0.00001523
Iteration 118/1000 | Loss: 0.00001523
Iteration 119/1000 | Loss: 0.00001523
Iteration 120/1000 | Loss: 0.00001523
Iteration 121/1000 | Loss: 0.00001523
Iteration 122/1000 | Loss: 0.00001523
Iteration 123/1000 | Loss: 0.00001523
Iteration 124/1000 | Loss: 0.00001522
Iteration 125/1000 | Loss: 0.00001522
Iteration 126/1000 | Loss: 0.00001522
Iteration 127/1000 | Loss: 0.00001522
Iteration 128/1000 | Loss: 0.00001521
Iteration 129/1000 | Loss: 0.00001521
Iteration 130/1000 | Loss: 0.00001521
Iteration 131/1000 | Loss: 0.00001521
Iteration 132/1000 | Loss: 0.00001521
Iteration 133/1000 | Loss: 0.00001520
Iteration 134/1000 | Loss: 0.00001520
Iteration 135/1000 | Loss: 0.00001520
Iteration 136/1000 | Loss: 0.00001520
Iteration 137/1000 | Loss: 0.00001520
Iteration 138/1000 | Loss: 0.00001520
Iteration 139/1000 | Loss: 0.00001520
Iteration 140/1000 | Loss: 0.00001520
Iteration 141/1000 | Loss: 0.00001520
Iteration 142/1000 | Loss: 0.00001520
Iteration 143/1000 | Loss: 0.00001519
Iteration 144/1000 | Loss: 0.00001519
Iteration 145/1000 | Loss: 0.00001519
Iteration 146/1000 | Loss: 0.00001519
Iteration 147/1000 | Loss: 0.00001519
Iteration 148/1000 | Loss: 0.00001519
Iteration 149/1000 | Loss: 0.00001519
Iteration 150/1000 | Loss: 0.00001519
Iteration 151/1000 | Loss: 0.00001518
Iteration 152/1000 | Loss: 0.00001518
Iteration 153/1000 | Loss: 0.00001518
Iteration 154/1000 | Loss: 0.00001518
Iteration 155/1000 | Loss: 0.00001518
Iteration 156/1000 | Loss: 0.00001518
Iteration 157/1000 | Loss: 0.00001518
Iteration 158/1000 | Loss: 0.00001518
Iteration 159/1000 | Loss: 0.00001518
Iteration 160/1000 | Loss: 0.00001518
Iteration 161/1000 | Loss: 0.00001518
Iteration 162/1000 | Loss: 0.00001518
Iteration 163/1000 | Loss: 0.00001518
Iteration 164/1000 | Loss: 0.00001518
Iteration 165/1000 | Loss: 0.00001518
Iteration 166/1000 | Loss: 0.00001518
Iteration 167/1000 | Loss: 0.00001518
Iteration 168/1000 | Loss: 0.00001518
Iteration 169/1000 | Loss: 0.00001518
Iteration 170/1000 | Loss: 0.00001518
Iteration 171/1000 | Loss: 0.00001518
Iteration 172/1000 | Loss: 0.00001518
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 172. Stopping optimization.
Last 5 losses: [1.5175887710938696e-05, 1.5175887710938696e-05, 1.5175887710938696e-05, 1.5175887710938696e-05, 1.5175887710938696e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5175887710938696e-05

Optimization complete. Final v2v error: 3.2910304069519043 mm

Highest mean error: 3.921750545501709 mm for frame 70

Lowest mean error: 2.853586196899414 mm for frame 81

Saving results

Total time: 45.526901721954346
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00849074
Iteration 2/25 | Loss: 0.00111586
Iteration 3/25 | Loss: 0.00082499
Iteration 4/25 | Loss: 0.00078401
Iteration 5/25 | Loss: 0.00077154
Iteration 6/25 | Loss: 0.00076994
Iteration 7/25 | Loss: 0.00076994
Iteration 8/25 | Loss: 0.00076994
Iteration 9/25 | Loss: 0.00076994
Iteration 10/25 | Loss: 0.00076994
Iteration 11/25 | Loss: 0.00076994
Iteration 12/25 | Loss: 0.00076994
Iteration 13/25 | Loss: 0.00076994
Iteration 14/25 | Loss: 0.00076994
Iteration 15/25 | Loss: 0.00076994
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0007699414272792637, 0.0007699414272792637, 0.0007699414272792637, 0.0007699414272792637, 0.0007699414272792637]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007699414272792637

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48234451
Iteration 2/25 | Loss: 0.00043525
Iteration 3/25 | Loss: 0.00043521
Iteration 4/25 | Loss: 0.00043521
Iteration 5/25 | Loss: 0.00043521
Iteration 6/25 | Loss: 0.00043521
Iteration 7/25 | Loss: 0.00043521
Iteration 8/25 | Loss: 0.00043521
Iteration 9/25 | Loss: 0.00043521
Iteration 10/25 | Loss: 0.00043521
Iteration 11/25 | Loss: 0.00043521
Iteration 12/25 | Loss: 0.00043521
Iteration 13/25 | Loss: 0.00043521
Iteration 14/25 | Loss: 0.00043521
Iteration 15/25 | Loss: 0.00043521
Iteration 16/25 | Loss: 0.00043521
Iteration 17/25 | Loss: 0.00043521
Iteration 18/25 | Loss: 0.00043521
Iteration 19/25 | Loss: 0.00043521
Iteration 20/25 | Loss: 0.00043521
Iteration 21/25 | Loss: 0.00043521
Iteration 22/25 | Loss: 0.00043521
Iteration 23/25 | Loss: 0.00043521
Iteration 24/25 | Loss: 0.00043521
Iteration 25/25 | Loss: 0.00043521

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043521
Iteration 2/1000 | Loss: 0.00003578
Iteration 3/1000 | Loss: 0.00002588
Iteration 4/1000 | Loss: 0.00002291
Iteration 5/1000 | Loss: 0.00002176
Iteration 6/1000 | Loss: 0.00002061
Iteration 7/1000 | Loss: 0.00001983
Iteration 8/1000 | Loss: 0.00001933
Iteration 9/1000 | Loss: 0.00001892
Iteration 10/1000 | Loss: 0.00001870
Iteration 11/1000 | Loss: 0.00001860
Iteration 12/1000 | Loss: 0.00001844
Iteration 13/1000 | Loss: 0.00001833
Iteration 14/1000 | Loss: 0.00001832
Iteration 15/1000 | Loss: 0.00001832
Iteration 16/1000 | Loss: 0.00001831
Iteration 17/1000 | Loss: 0.00001827
Iteration 18/1000 | Loss: 0.00001822
Iteration 19/1000 | Loss: 0.00001817
Iteration 20/1000 | Loss: 0.00001814
Iteration 21/1000 | Loss: 0.00001814
Iteration 22/1000 | Loss: 0.00001813
Iteration 23/1000 | Loss: 0.00001813
Iteration 24/1000 | Loss: 0.00001811
Iteration 25/1000 | Loss: 0.00001809
Iteration 26/1000 | Loss: 0.00001808
Iteration 27/1000 | Loss: 0.00001808
Iteration 28/1000 | Loss: 0.00001808
Iteration 29/1000 | Loss: 0.00001808
Iteration 30/1000 | Loss: 0.00001808
Iteration 31/1000 | Loss: 0.00001806
Iteration 32/1000 | Loss: 0.00001806
Iteration 33/1000 | Loss: 0.00001806
Iteration 34/1000 | Loss: 0.00001806
Iteration 35/1000 | Loss: 0.00001806
Iteration 36/1000 | Loss: 0.00001806
Iteration 37/1000 | Loss: 0.00001806
Iteration 38/1000 | Loss: 0.00001806
Iteration 39/1000 | Loss: 0.00001806
Iteration 40/1000 | Loss: 0.00001806
Iteration 41/1000 | Loss: 0.00001805
Iteration 42/1000 | Loss: 0.00001805
Iteration 43/1000 | Loss: 0.00001805
Iteration 44/1000 | Loss: 0.00001805
Iteration 45/1000 | Loss: 0.00001803
Iteration 46/1000 | Loss: 0.00001803
Iteration 47/1000 | Loss: 0.00001803
Iteration 48/1000 | Loss: 0.00001802
Iteration 49/1000 | Loss: 0.00001801
Iteration 50/1000 | Loss: 0.00001801
Iteration 51/1000 | Loss: 0.00001801
Iteration 52/1000 | Loss: 0.00001800
Iteration 53/1000 | Loss: 0.00001800
Iteration 54/1000 | Loss: 0.00001800
Iteration 55/1000 | Loss: 0.00001799
Iteration 56/1000 | Loss: 0.00001799
Iteration 57/1000 | Loss: 0.00001799
Iteration 58/1000 | Loss: 0.00001799
Iteration 59/1000 | Loss: 0.00001799
Iteration 60/1000 | Loss: 0.00001799
Iteration 61/1000 | Loss: 0.00001799
Iteration 62/1000 | Loss: 0.00001799
Iteration 63/1000 | Loss: 0.00001799
Iteration 64/1000 | Loss: 0.00001799
Iteration 65/1000 | Loss: 0.00001799
Iteration 66/1000 | Loss: 0.00001798
Iteration 67/1000 | Loss: 0.00001798
Iteration 68/1000 | Loss: 0.00001798
Iteration 69/1000 | Loss: 0.00001797
Iteration 70/1000 | Loss: 0.00001797
Iteration 71/1000 | Loss: 0.00001797
Iteration 72/1000 | Loss: 0.00001797
Iteration 73/1000 | Loss: 0.00001797
Iteration 74/1000 | Loss: 0.00001796
Iteration 75/1000 | Loss: 0.00001796
Iteration 76/1000 | Loss: 0.00001796
Iteration 77/1000 | Loss: 0.00001796
Iteration 78/1000 | Loss: 0.00001796
Iteration 79/1000 | Loss: 0.00001796
Iteration 80/1000 | Loss: 0.00001796
Iteration 81/1000 | Loss: 0.00001795
Iteration 82/1000 | Loss: 0.00001795
Iteration 83/1000 | Loss: 0.00001795
Iteration 84/1000 | Loss: 0.00001795
Iteration 85/1000 | Loss: 0.00001795
Iteration 86/1000 | Loss: 0.00001795
Iteration 87/1000 | Loss: 0.00001795
Iteration 88/1000 | Loss: 0.00001795
Iteration 89/1000 | Loss: 0.00001794
Iteration 90/1000 | Loss: 0.00001794
Iteration 91/1000 | Loss: 0.00001794
Iteration 92/1000 | Loss: 0.00001794
Iteration 93/1000 | Loss: 0.00001794
Iteration 94/1000 | Loss: 0.00001794
Iteration 95/1000 | Loss: 0.00001793
Iteration 96/1000 | Loss: 0.00001793
Iteration 97/1000 | Loss: 0.00001793
Iteration 98/1000 | Loss: 0.00001793
Iteration 99/1000 | Loss: 0.00001793
Iteration 100/1000 | Loss: 0.00001793
Iteration 101/1000 | Loss: 0.00001793
Iteration 102/1000 | Loss: 0.00001792
Iteration 103/1000 | Loss: 0.00001792
Iteration 104/1000 | Loss: 0.00001792
Iteration 105/1000 | Loss: 0.00001792
Iteration 106/1000 | Loss: 0.00001791
Iteration 107/1000 | Loss: 0.00001791
Iteration 108/1000 | Loss: 0.00001791
Iteration 109/1000 | Loss: 0.00001791
Iteration 110/1000 | Loss: 0.00001790
Iteration 111/1000 | Loss: 0.00001790
Iteration 112/1000 | Loss: 0.00001790
Iteration 113/1000 | Loss: 0.00001790
Iteration 114/1000 | Loss: 0.00001790
Iteration 115/1000 | Loss: 0.00001790
Iteration 116/1000 | Loss: 0.00001790
Iteration 117/1000 | Loss: 0.00001790
Iteration 118/1000 | Loss: 0.00001790
Iteration 119/1000 | Loss: 0.00001789
Iteration 120/1000 | Loss: 0.00001789
Iteration 121/1000 | Loss: 0.00001789
Iteration 122/1000 | Loss: 0.00001788
Iteration 123/1000 | Loss: 0.00001788
Iteration 124/1000 | Loss: 0.00001788
Iteration 125/1000 | Loss: 0.00001788
Iteration 126/1000 | Loss: 0.00001788
Iteration 127/1000 | Loss: 0.00001788
Iteration 128/1000 | Loss: 0.00001787
Iteration 129/1000 | Loss: 0.00001787
Iteration 130/1000 | Loss: 0.00001787
Iteration 131/1000 | Loss: 0.00001787
Iteration 132/1000 | Loss: 0.00001787
Iteration 133/1000 | Loss: 0.00001787
Iteration 134/1000 | Loss: 0.00001787
Iteration 135/1000 | Loss: 0.00001787
Iteration 136/1000 | Loss: 0.00001786
Iteration 137/1000 | Loss: 0.00001786
Iteration 138/1000 | Loss: 0.00001786
Iteration 139/1000 | Loss: 0.00001786
Iteration 140/1000 | Loss: 0.00001786
Iteration 141/1000 | Loss: 0.00001786
Iteration 142/1000 | Loss: 0.00001786
Iteration 143/1000 | Loss: 0.00001786
Iteration 144/1000 | Loss: 0.00001786
Iteration 145/1000 | Loss: 0.00001786
Iteration 146/1000 | Loss: 0.00001786
Iteration 147/1000 | Loss: 0.00001786
Iteration 148/1000 | Loss: 0.00001786
Iteration 149/1000 | Loss: 0.00001785
Iteration 150/1000 | Loss: 0.00001785
Iteration 151/1000 | Loss: 0.00001785
Iteration 152/1000 | Loss: 0.00001785
Iteration 153/1000 | Loss: 0.00001785
Iteration 154/1000 | Loss: 0.00001785
Iteration 155/1000 | Loss: 0.00001785
Iteration 156/1000 | Loss: 0.00001785
Iteration 157/1000 | Loss: 0.00001785
Iteration 158/1000 | Loss: 0.00001784
Iteration 159/1000 | Loss: 0.00001784
Iteration 160/1000 | Loss: 0.00001784
Iteration 161/1000 | Loss: 0.00001784
Iteration 162/1000 | Loss: 0.00001784
Iteration 163/1000 | Loss: 0.00001784
Iteration 164/1000 | Loss: 0.00001784
Iteration 165/1000 | Loss: 0.00001784
Iteration 166/1000 | Loss: 0.00001784
Iteration 167/1000 | Loss: 0.00001784
Iteration 168/1000 | Loss: 0.00001784
Iteration 169/1000 | Loss: 0.00001784
Iteration 170/1000 | Loss: 0.00001784
Iteration 171/1000 | Loss: 0.00001784
Iteration 172/1000 | Loss: 0.00001784
Iteration 173/1000 | Loss: 0.00001784
Iteration 174/1000 | Loss: 0.00001784
Iteration 175/1000 | Loss: 0.00001783
Iteration 176/1000 | Loss: 0.00001783
Iteration 177/1000 | Loss: 0.00001783
Iteration 178/1000 | Loss: 0.00001783
Iteration 179/1000 | Loss: 0.00001783
Iteration 180/1000 | Loss: 0.00001783
Iteration 181/1000 | Loss: 0.00001783
Iteration 182/1000 | Loss: 0.00001783
Iteration 183/1000 | Loss: 0.00001783
Iteration 184/1000 | Loss: 0.00001783
Iteration 185/1000 | Loss: 0.00001783
Iteration 186/1000 | Loss: 0.00001783
Iteration 187/1000 | Loss: 0.00001783
Iteration 188/1000 | Loss: 0.00001783
Iteration 189/1000 | Loss: 0.00001783
Iteration 190/1000 | Loss: 0.00001783
Iteration 191/1000 | Loss: 0.00001782
Iteration 192/1000 | Loss: 0.00001782
Iteration 193/1000 | Loss: 0.00001782
Iteration 194/1000 | Loss: 0.00001782
Iteration 195/1000 | Loss: 0.00001782
Iteration 196/1000 | Loss: 0.00001782
Iteration 197/1000 | Loss: 0.00001782
Iteration 198/1000 | Loss: 0.00001782
Iteration 199/1000 | Loss: 0.00001782
Iteration 200/1000 | Loss: 0.00001782
Iteration 201/1000 | Loss: 0.00001782
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 201. Stopping optimization.
Last 5 losses: [1.782227263902314e-05, 1.782227263902314e-05, 1.782227263902314e-05, 1.782227263902314e-05, 1.782227263902314e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.782227263902314e-05

Optimization complete. Final v2v error: 3.6150143146514893 mm

Highest mean error: 4.427746295928955 mm for frame 36

Lowest mean error: 3.310257911682129 mm for frame 94

Saving results

Total time: 41.73735022544861
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1053/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1053.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1053
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00446957
Iteration 2/25 | Loss: 0.00114903
Iteration 3/25 | Loss: 0.00082789
Iteration 4/25 | Loss: 0.00075848
Iteration 5/25 | Loss: 0.00074096
Iteration 6/25 | Loss: 0.00073663
Iteration 7/25 | Loss: 0.00073562
Iteration 8/25 | Loss: 0.00073562
Iteration 9/25 | Loss: 0.00073562
Iteration 10/25 | Loss: 0.00073562
Iteration 11/25 | Loss: 0.00073562
Iteration 12/25 | Loss: 0.00073562
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007356242858804762, 0.0007356242858804762, 0.0007356242858804762, 0.0007356242858804762, 0.0007356242858804762]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007356242858804762

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61128223
Iteration 2/25 | Loss: 0.00047472
Iteration 3/25 | Loss: 0.00047472
Iteration 4/25 | Loss: 0.00047472
Iteration 5/25 | Loss: 0.00047472
Iteration 6/25 | Loss: 0.00047472
Iteration 7/25 | Loss: 0.00047472
Iteration 8/25 | Loss: 0.00047472
Iteration 9/25 | Loss: 0.00047472
Iteration 10/25 | Loss: 0.00047472
Iteration 11/25 | Loss: 0.00047472
Iteration 12/25 | Loss: 0.00047472
Iteration 13/25 | Loss: 0.00047472
Iteration 14/25 | Loss: 0.00047472
Iteration 15/25 | Loss: 0.00047472
Iteration 16/25 | Loss: 0.00047472
Iteration 17/25 | Loss: 0.00047472
Iteration 18/25 | Loss: 0.00047472
Iteration 19/25 | Loss: 0.00047472
Iteration 20/25 | Loss: 0.00047472
Iteration 21/25 | Loss: 0.00047472
Iteration 22/25 | Loss: 0.00047472
Iteration 23/25 | Loss: 0.00047472
Iteration 24/25 | Loss: 0.00047472
Iteration 25/25 | Loss: 0.00047472

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047472
Iteration 2/1000 | Loss: 0.00002400
Iteration 3/1000 | Loss: 0.00001718
Iteration 4/1000 | Loss: 0.00001585
Iteration 5/1000 | Loss: 0.00001498
Iteration 6/1000 | Loss: 0.00001427
Iteration 7/1000 | Loss: 0.00001398
Iteration 8/1000 | Loss: 0.00001362
Iteration 9/1000 | Loss: 0.00001357
Iteration 10/1000 | Loss: 0.00001338
Iteration 11/1000 | Loss: 0.00001325
Iteration 12/1000 | Loss: 0.00001323
Iteration 13/1000 | Loss: 0.00001322
Iteration 14/1000 | Loss: 0.00001315
Iteration 15/1000 | Loss: 0.00001314
Iteration 16/1000 | Loss: 0.00001306
Iteration 17/1000 | Loss: 0.00001304
Iteration 18/1000 | Loss: 0.00001303
Iteration 19/1000 | Loss: 0.00001302
Iteration 20/1000 | Loss: 0.00001300
Iteration 21/1000 | Loss: 0.00001298
Iteration 22/1000 | Loss: 0.00001296
Iteration 23/1000 | Loss: 0.00001296
Iteration 24/1000 | Loss: 0.00001295
Iteration 25/1000 | Loss: 0.00001295
Iteration 26/1000 | Loss: 0.00001295
Iteration 27/1000 | Loss: 0.00001295
Iteration 28/1000 | Loss: 0.00001295
Iteration 29/1000 | Loss: 0.00001295
Iteration 30/1000 | Loss: 0.00001294
Iteration 31/1000 | Loss: 0.00001294
Iteration 32/1000 | Loss: 0.00001294
Iteration 33/1000 | Loss: 0.00001294
Iteration 34/1000 | Loss: 0.00001294
Iteration 35/1000 | Loss: 0.00001294
Iteration 36/1000 | Loss: 0.00001294
Iteration 37/1000 | Loss: 0.00001294
Iteration 38/1000 | Loss: 0.00001294
Iteration 39/1000 | Loss: 0.00001294
Iteration 40/1000 | Loss: 0.00001294
Iteration 41/1000 | Loss: 0.00001293
Iteration 42/1000 | Loss: 0.00001293
Iteration 43/1000 | Loss: 0.00001292
Iteration 44/1000 | Loss: 0.00001292
Iteration 45/1000 | Loss: 0.00001292
Iteration 46/1000 | Loss: 0.00001292
Iteration 47/1000 | Loss: 0.00001292
Iteration 48/1000 | Loss: 0.00001292
Iteration 49/1000 | Loss: 0.00001291
Iteration 50/1000 | Loss: 0.00001291
Iteration 51/1000 | Loss: 0.00001291
Iteration 52/1000 | Loss: 0.00001291
Iteration 53/1000 | Loss: 0.00001291
Iteration 54/1000 | Loss: 0.00001291
Iteration 55/1000 | Loss: 0.00001290
Iteration 56/1000 | Loss: 0.00001290
Iteration 57/1000 | Loss: 0.00001290
Iteration 58/1000 | Loss: 0.00001290
Iteration 59/1000 | Loss: 0.00001290
Iteration 60/1000 | Loss: 0.00001290
Iteration 61/1000 | Loss: 0.00001290
Iteration 62/1000 | Loss: 0.00001289
Iteration 63/1000 | Loss: 0.00001289
Iteration 64/1000 | Loss: 0.00001289
Iteration 65/1000 | Loss: 0.00001288
Iteration 66/1000 | Loss: 0.00001288
Iteration 67/1000 | Loss: 0.00001288
Iteration 68/1000 | Loss: 0.00001288
Iteration 69/1000 | Loss: 0.00001288
Iteration 70/1000 | Loss: 0.00001288
Iteration 71/1000 | Loss: 0.00001287
Iteration 72/1000 | Loss: 0.00001287
Iteration 73/1000 | Loss: 0.00001287
Iteration 74/1000 | Loss: 0.00001287
Iteration 75/1000 | Loss: 0.00001286
Iteration 76/1000 | Loss: 0.00001286
Iteration 77/1000 | Loss: 0.00001286
Iteration 78/1000 | Loss: 0.00001286
Iteration 79/1000 | Loss: 0.00001286
Iteration 80/1000 | Loss: 0.00001286
Iteration 81/1000 | Loss: 0.00001285
Iteration 82/1000 | Loss: 0.00001285
Iteration 83/1000 | Loss: 0.00001285
Iteration 84/1000 | Loss: 0.00001285
Iteration 85/1000 | Loss: 0.00001285
Iteration 86/1000 | Loss: 0.00001284
Iteration 87/1000 | Loss: 0.00001284
Iteration 88/1000 | Loss: 0.00001284
Iteration 89/1000 | Loss: 0.00001283
Iteration 90/1000 | Loss: 0.00001283
Iteration 91/1000 | Loss: 0.00001283
Iteration 92/1000 | Loss: 0.00001283
Iteration 93/1000 | Loss: 0.00001282
Iteration 94/1000 | Loss: 0.00001282
Iteration 95/1000 | Loss: 0.00001282
Iteration 96/1000 | Loss: 0.00001282
Iteration 97/1000 | Loss: 0.00001281
Iteration 98/1000 | Loss: 0.00001281
Iteration 99/1000 | Loss: 0.00001281
Iteration 100/1000 | Loss: 0.00001281
Iteration 101/1000 | Loss: 0.00001281
Iteration 102/1000 | Loss: 0.00001281
Iteration 103/1000 | Loss: 0.00001281
Iteration 104/1000 | Loss: 0.00001281
Iteration 105/1000 | Loss: 0.00001281
Iteration 106/1000 | Loss: 0.00001281
Iteration 107/1000 | Loss: 0.00001280
Iteration 108/1000 | Loss: 0.00001280
Iteration 109/1000 | Loss: 0.00001280
Iteration 110/1000 | Loss: 0.00001280
Iteration 111/1000 | Loss: 0.00001280
Iteration 112/1000 | Loss: 0.00001280
Iteration 113/1000 | Loss: 0.00001280
Iteration 114/1000 | Loss: 0.00001279
Iteration 115/1000 | Loss: 0.00001279
Iteration 116/1000 | Loss: 0.00001279
Iteration 117/1000 | Loss: 0.00001278
Iteration 118/1000 | Loss: 0.00001278
Iteration 119/1000 | Loss: 0.00001278
Iteration 120/1000 | Loss: 0.00001278
Iteration 121/1000 | Loss: 0.00001278
Iteration 122/1000 | Loss: 0.00001278
Iteration 123/1000 | Loss: 0.00001278
Iteration 124/1000 | Loss: 0.00001277
Iteration 125/1000 | Loss: 0.00001277
Iteration 126/1000 | Loss: 0.00001277
Iteration 127/1000 | Loss: 0.00001276
Iteration 128/1000 | Loss: 0.00001276
Iteration 129/1000 | Loss: 0.00001275
Iteration 130/1000 | Loss: 0.00001275
Iteration 131/1000 | Loss: 0.00001275
Iteration 132/1000 | Loss: 0.00001275
Iteration 133/1000 | Loss: 0.00001275
Iteration 134/1000 | Loss: 0.00001275
Iteration 135/1000 | Loss: 0.00001275
Iteration 136/1000 | Loss: 0.00001274
Iteration 137/1000 | Loss: 0.00001274
Iteration 138/1000 | Loss: 0.00001274
Iteration 139/1000 | Loss: 0.00001274
Iteration 140/1000 | Loss: 0.00001274
Iteration 141/1000 | Loss: 0.00001274
Iteration 142/1000 | Loss: 0.00001274
Iteration 143/1000 | Loss: 0.00001273
Iteration 144/1000 | Loss: 0.00001273
Iteration 145/1000 | Loss: 0.00001273
Iteration 146/1000 | Loss: 0.00001273
Iteration 147/1000 | Loss: 0.00001273
Iteration 148/1000 | Loss: 0.00001273
Iteration 149/1000 | Loss: 0.00001273
Iteration 150/1000 | Loss: 0.00001273
Iteration 151/1000 | Loss: 0.00001272
Iteration 152/1000 | Loss: 0.00001272
Iteration 153/1000 | Loss: 0.00001272
Iteration 154/1000 | Loss: 0.00001272
Iteration 155/1000 | Loss: 0.00001272
Iteration 156/1000 | Loss: 0.00001272
Iteration 157/1000 | Loss: 0.00001272
Iteration 158/1000 | Loss: 0.00001272
Iteration 159/1000 | Loss: 0.00001271
Iteration 160/1000 | Loss: 0.00001271
Iteration 161/1000 | Loss: 0.00001271
Iteration 162/1000 | Loss: 0.00001270
Iteration 163/1000 | Loss: 0.00001270
Iteration 164/1000 | Loss: 0.00001270
Iteration 165/1000 | Loss: 0.00001270
Iteration 166/1000 | Loss: 0.00001270
Iteration 167/1000 | Loss: 0.00001270
Iteration 168/1000 | Loss: 0.00001270
Iteration 169/1000 | Loss: 0.00001270
Iteration 170/1000 | Loss: 0.00001270
Iteration 171/1000 | Loss: 0.00001270
Iteration 172/1000 | Loss: 0.00001269
Iteration 173/1000 | Loss: 0.00001269
Iteration 174/1000 | Loss: 0.00001269
Iteration 175/1000 | Loss: 0.00001269
Iteration 176/1000 | Loss: 0.00001269
Iteration 177/1000 | Loss: 0.00001269
Iteration 178/1000 | Loss: 0.00001269
Iteration 179/1000 | Loss: 0.00001269
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.2694212273345329e-05, 1.2694212273345329e-05, 1.2694212273345329e-05, 1.2694212273345329e-05, 1.2694212273345329e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2694212273345329e-05

Optimization complete. Final v2v error: 2.994920492172241 mm

Highest mean error: 4.00007963180542 mm for frame 104

Lowest mean error: 2.780933141708374 mm for frame 180

Saving results

Total time: 44.458940744400024
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1037/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1037.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1037
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00412173
Iteration 2/25 | Loss: 0.00084408
Iteration 3/25 | Loss: 0.00075277
Iteration 4/25 | Loss: 0.00073998
Iteration 5/25 | Loss: 0.00073425
Iteration 6/25 | Loss: 0.00073320
Iteration 7/25 | Loss: 0.00073320
Iteration 8/25 | Loss: 0.00073320
Iteration 9/25 | Loss: 0.00073318
Iteration 10/25 | Loss: 0.00073318
Iteration 11/25 | Loss: 0.00073318
Iteration 12/25 | Loss: 0.00073318
Iteration 13/25 | Loss: 0.00073318
Iteration 14/25 | Loss: 0.00073318
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0007331830565817654, 0.0007331830565817654, 0.0007331830565817654, 0.0007331830565817654, 0.0007331830565817654]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007331830565817654

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50866544
Iteration 2/25 | Loss: 0.00045400
Iteration 3/25 | Loss: 0.00045400
Iteration 4/25 | Loss: 0.00045400
Iteration 5/25 | Loss: 0.00045400
Iteration 6/25 | Loss: 0.00045400
Iteration 7/25 | Loss: 0.00045400
Iteration 8/25 | Loss: 0.00045400
Iteration 9/25 | Loss: 0.00045400
Iteration 10/25 | Loss: 0.00045400
Iteration 11/25 | Loss: 0.00045400
Iteration 12/25 | Loss: 0.00045399
Iteration 13/25 | Loss: 0.00045399
Iteration 14/25 | Loss: 0.00045399
Iteration 15/25 | Loss: 0.00045399
Iteration 16/25 | Loss: 0.00045399
Iteration 17/25 | Loss: 0.00045399
Iteration 18/25 | Loss: 0.00045399
Iteration 19/25 | Loss: 0.00045399
Iteration 20/25 | Loss: 0.00045399
Iteration 21/25 | Loss: 0.00045399
Iteration 22/25 | Loss: 0.00045399
Iteration 23/25 | Loss: 0.00045399
Iteration 24/25 | Loss: 0.00045399
Iteration 25/25 | Loss: 0.00045399

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045399
Iteration 2/1000 | Loss: 0.00002044
Iteration 3/1000 | Loss: 0.00001482
Iteration 4/1000 | Loss: 0.00001373
Iteration 5/1000 | Loss: 0.00001290
Iteration 6/1000 | Loss: 0.00001242
Iteration 7/1000 | Loss: 0.00001218
Iteration 8/1000 | Loss: 0.00001198
Iteration 9/1000 | Loss: 0.00001181
Iteration 10/1000 | Loss: 0.00001176
Iteration 11/1000 | Loss: 0.00001175
Iteration 12/1000 | Loss: 0.00001170
Iteration 13/1000 | Loss: 0.00001168
Iteration 14/1000 | Loss: 0.00001168
Iteration 15/1000 | Loss: 0.00001167
Iteration 16/1000 | Loss: 0.00001167
Iteration 17/1000 | Loss: 0.00001154
Iteration 18/1000 | Loss: 0.00001152
Iteration 19/1000 | Loss: 0.00001152
Iteration 20/1000 | Loss: 0.00001152
Iteration 21/1000 | Loss: 0.00001152
Iteration 22/1000 | Loss: 0.00001152
Iteration 23/1000 | Loss: 0.00001152
Iteration 24/1000 | Loss: 0.00001152
Iteration 25/1000 | Loss: 0.00001151
Iteration 26/1000 | Loss: 0.00001151
Iteration 27/1000 | Loss: 0.00001150
Iteration 28/1000 | Loss: 0.00001150
Iteration 29/1000 | Loss: 0.00001148
Iteration 30/1000 | Loss: 0.00001148
Iteration 31/1000 | Loss: 0.00001148
Iteration 32/1000 | Loss: 0.00001147
Iteration 33/1000 | Loss: 0.00001147
Iteration 34/1000 | Loss: 0.00001147
Iteration 35/1000 | Loss: 0.00001144
Iteration 36/1000 | Loss: 0.00001144
Iteration 37/1000 | Loss: 0.00001144
Iteration 38/1000 | Loss: 0.00001143
Iteration 39/1000 | Loss: 0.00001143
Iteration 40/1000 | Loss: 0.00001143
Iteration 41/1000 | Loss: 0.00001142
Iteration 42/1000 | Loss: 0.00001142
Iteration 43/1000 | Loss: 0.00001140
Iteration 44/1000 | Loss: 0.00001138
Iteration 45/1000 | Loss: 0.00001137
Iteration 46/1000 | Loss: 0.00001137
Iteration 47/1000 | Loss: 0.00001137
Iteration 48/1000 | Loss: 0.00001136
Iteration 49/1000 | Loss: 0.00001136
Iteration 50/1000 | Loss: 0.00001136
Iteration 51/1000 | Loss: 0.00001136
Iteration 52/1000 | Loss: 0.00001135
Iteration 53/1000 | Loss: 0.00001135
Iteration 54/1000 | Loss: 0.00001135
Iteration 55/1000 | Loss: 0.00001134
Iteration 56/1000 | Loss: 0.00001133
Iteration 57/1000 | Loss: 0.00001133
Iteration 58/1000 | Loss: 0.00001132
Iteration 59/1000 | Loss: 0.00001132
Iteration 60/1000 | Loss: 0.00001131
Iteration 61/1000 | Loss: 0.00001130
Iteration 62/1000 | Loss: 0.00001130
Iteration 63/1000 | Loss: 0.00001130
Iteration 64/1000 | Loss: 0.00001130
Iteration 65/1000 | Loss: 0.00001130
Iteration 66/1000 | Loss: 0.00001130
Iteration 67/1000 | Loss: 0.00001130
Iteration 68/1000 | Loss: 0.00001130
Iteration 69/1000 | Loss: 0.00001130
Iteration 70/1000 | Loss: 0.00001129
Iteration 71/1000 | Loss: 0.00001129
Iteration 72/1000 | Loss: 0.00001129
Iteration 73/1000 | Loss: 0.00001128
Iteration 74/1000 | Loss: 0.00001128
Iteration 75/1000 | Loss: 0.00001128
Iteration 76/1000 | Loss: 0.00001128
Iteration 77/1000 | Loss: 0.00001128
Iteration 78/1000 | Loss: 0.00001128
Iteration 79/1000 | Loss: 0.00001128
Iteration 80/1000 | Loss: 0.00001128
Iteration 81/1000 | Loss: 0.00001128
Iteration 82/1000 | Loss: 0.00001127
Iteration 83/1000 | Loss: 0.00001127
Iteration 84/1000 | Loss: 0.00001127
Iteration 85/1000 | Loss: 0.00001126
Iteration 86/1000 | Loss: 0.00001126
Iteration 87/1000 | Loss: 0.00001126
Iteration 88/1000 | Loss: 0.00001126
Iteration 89/1000 | Loss: 0.00001126
Iteration 90/1000 | Loss: 0.00001126
Iteration 91/1000 | Loss: 0.00001126
Iteration 92/1000 | Loss: 0.00001126
Iteration 93/1000 | Loss: 0.00001125
Iteration 94/1000 | Loss: 0.00001125
Iteration 95/1000 | Loss: 0.00001125
Iteration 96/1000 | Loss: 0.00001125
Iteration 97/1000 | Loss: 0.00001125
Iteration 98/1000 | Loss: 0.00001125
Iteration 99/1000 | Loss: 0.00001125
Iteration 100/1000 | Loss: 0.00001125
Iteration 101/1000 | Loss: 0.00001125
Iteration 102/1000 | Loss: 0.00001125
Iteration 103/1000 | Loss: 0.00001125
Iteration 104/1000 | Loss: 0.00001125
Iteration 105/1000 | Loss: 0.00001125
Iteration 106/1000 | Loss: 0.00001125
Iteration 107/1000 | Loss: 0.00001124
Iteration 108/1000 | Loss: 0.00001124
Iteration 109/1000 | Loss: 0.00001124
Iteration 110/1000 | Loss: 0.00001124
Iteration 111/1000 | Loss: 0.00001124
Iteration 112/1000 | Loss: 0.00001124
Iteration 113/1000 | Loss: 0.00001124
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [1.1244701454415917e-05, 1.1244701454415917e-05, 1.1244701454415917e-05, 1.1244701454415917e-05, 1.1244701454415917e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1244701454415917e-05

Optimization complete. Final v2v error: 2.8859033584594727 mm

Highest mean error: 3.0265674591064453 mm for frame 174

Lowest mean error: 2.81413197517395 mm for frame 9

Saving results

Total time: 36.32103109359741
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_033/1051/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1051.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_033/1051
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00854560
Iteration 2/25 | Loss: 0.00096489
Iteration 3/25 | Loss: 0.00076416
Iteration 4/25 | Loss: 0.00073303
Iteration 5/25 | Loss: 0.00072584
Iteration 6/25 | Loss: 0.00072331
Iteration 7/25 | Loss: 0.00072288
Iteration 8/25 | Loss: 0.00072288
Iteration 9/25 | Loss: 0.00072288
Iteration 10/25 | Loss: 0.00072288
Iteration 11/25 | Loss: 0.00072288
Iteration 12/25 | Loss: 0.00072288
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007228772155940533, 0.0007228772155940533, 0.0007228772155940533, 0.0007228772155940533, 0.0007228772155940533]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007228772155940533

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49632740
Iteration 2/25 | Loss: 0.00044600
Iteration 3/25 | Loss: 0.00044598
Iteration 4/25 | Loss: 0.00044597
Iteration 5/25 | Loss: 0.00044597
Iteration 6/25 | Loss: 0.00044597
Iteration 7/25 | Loss: 0.00044597
Iteration 8/25 | Loss: 0.00044597
Iteration 9/25 | Loss: 0.00044597
Iteration 10/25 | Loss: 0.00044597
Iteration 11/25 | Loss: 0.00044597
Iteration 12/25 | Loss: 0.00044597
Iteration 13/25 | Loss: 0.00044597
Iteration 14/25 | Loss: 0.00044597
Iteration 15/25 | Loss: 0.00044597
Iteration 16/25 | Loss: 0.00044597
Iteration 17/25 | Loss: 0.00044597
Iteration 18/25 | Loss: 0.00044597
Iteration 19/25 | Loss: 0.00044597
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0004459724295884371, 0.0004459724295884371, 0.0004459724295884371, 0.0004459724295884371, 0.0004459724295884371]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004459724295884371

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044597
Iteration 2/1000 | Loss: 0.00002137
Iteration 3/1000 | Loss: 0.00001609
Iteration 4/1000 | Loss: 0.00001484
Iteration 5/1000 | Loss: 0.00001359
Iteration 6/1000 | Loss: 0.00001297
Iteration 7/1000 | Loss: 0.00001251
Iteration 8/1000 | Loss: 0.00001240
Iteration 9/1000 | Loss: 0.00001237
Iteration 10/1000 | Loss: 0.00001237
Iteration 11/1000 | Loss: 0.00001236
Iteration 12/1000 | Loss: 0.00001236
Iteration 13/1000 | Loss: 0.00001230
Iteration 14/1000 | Loss: 0.00001229
Iteration 15/1000 | Loss: 0.00001228
Iteration 16/1000 | Loss: 0.00001227
Iteration 17/1000 | Loss: 0.00001221
Iteration 18/1000 | Loss: 0.00001220
Iteration 19/1000 | Loss: 0.00001216
Iteration 20/1000 | Loss: 0.00001215
Iteration 21/1000 | Loss: 0.00001214
Iteration 22/1000 | Loss: 0.00001214
Iteration 23/1000 | Loss: 0.00001213
Iteration 24/1000 | Loss: 0.00001212
Iteration 25/1000 | Loss: 0.00001212
Iteration 26/1000 | Loss: 0.00001212
Iteration 27/1000 | Loss: 0.00001208
Iteration 28/1000 | Loss: 0.00001207
Iteration 29/1000 | Loss: 0.00001207
Iteration 30/1000 | Loss: 0.00001207
Iteration 31/1000 | Loss: 0.00001202
Iteration 32/1000 | Loss: 0.00001200
Iteration 33/1000 | Loss: 0.00001200
Iteration 34/1000 | Loss: 0.00001200
Iteration 35/1000 | Loss: 0.00001198
Iteration 36/1000 | Loss: 0.00001198
Iteration 37/1000 | Loss: 0.00001198
Iteration 38/1000 | Loss: 0.00001197
Iteration 39/1000 | Loss: 0.00001197
Iteration 40/1000 | Loss: 0.00001196
Iteration 41/1000 | Loss: 0.00001196
Iteration 42/1000 | Loss: 0.00001195
Iteration 43/1000 | Loss: 0.00001195
Iteration 44/1000 | Loss: 0.00001195
Iteration 45/1000 | Loss: 0.00001195
Iteration 46/1000 | Loss: 0.00001195
Iteration 47/1000 | Loss: 0.00001195
Iteration 48/1000 | Loss: 0.00001195
Iteration 49/1000 | Loss: 0.00001194
Iteration 50/1000 | Loss: 0.00001194
Iteration 51/1000 | Loss: 0.00001194
Iteration 52/1000 | Loss: 0.00001193
Iteration 53/1000 | Loss: 0.00001193
Iteration 54/1000 | Loss: 0.00001193
Iteration 55/1000 | Loss: 0.00001192
Iteration 56/1000 | Loss: 0.00001192
Iteration 57/1000 | Loss: 0.00001192
Iteration 58/1000 | Loss: 0.00001192
Iteration 59/1000 | Loss: 0.00001192
Iteration 60/1000 | Loss: 0.00001192
Iteration 61/1000 | Loss: 0.00001192
Iteration 62/1000 | Loss: 0.00001192
Iteration 63/1000 | Loss: 0.00001191
Iteration 64/1000 | Loss: 0.00001191
Iteration 65/1000 | Loss: 0.00001191
Iteration 66/1000 | Loss: 0.00001191
Iteration 67/1000 | Loss: 0.00001191
Iteration 68/1000 | Loss: 0.00001191
Iteration 69/1000 | Loss: 0.00001191
Iteration 70/1000 | Loss: 0.00001190
Iteration 71/1000 | Loss: 0.00001190
Iteration 72/1000 | Loss: 0.00001190
Iteration 73/1000 | Loss: 0.00001190
Iteration 74/1000 | Loss: 0.00001190
Iteration 75/1000 | Loss: 0.00001190
Iteration 76/1000 | Loss: 0.00001190
Iteration 77/1000 | Loss: 0.00001190
Iteration 78/1000 | Loss: 0.00001190
Iteration 79/1000 | Loss: 0.00001190
Iteration 80/1000 | Loss: 0.00001189
Iteration 81/1000 | Loss: 0.00001189
Iteration 82/1000 | Loss: 0.00001189
Iteration 83/1000 | Loss: 0.00001189
Iteration 84/1000 | Loss: 0.00001189
Iteration 85/1000 | Loss: 0.00001189
Iteration 86/1000 | Loss: 0.00001189
Iteration 87/1000 | Loss: 0.00001189
Iteration 88/1000 | Loss: 0.00001189
Iteration 89/1000 | Loss: 0.00001189
Iteration 90/1000 | Loss: 0.00001189
Iteration 91/1000 | Loss: 0.00001189
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 91. Stopping optimization.
Last 5 losses: [1.1893206647073384e-05, 1.1893206647073384e-05, 1.1893206647073384e-05, 1.1893206647073384e-05, 1.1893206647073384e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1893206647073384e-05

Optimization complete. Final v2v error: 2.929237127304077 mm

Highest mean error: 3.0308055877685547 mm for frame 74

Lowest mean error: 2.8128559589385986 mm for frame 120

Saving results

Total time: 29.669279098510742
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1042/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1042.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1042
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01065848
Iteration 2/25 | Loss: 0.00275755
Iteration 3/25 | Loss: 0.00203705
Iteration 4/25 | Loss: 0.00163062
Iteration 5/25 | Loss: 0.00151650
Iteration 6/25 | Loss: 0.00139051
Iteration 7/25 | Loss: 0.00127619
Iteration 8/25 | Loss: 0.00129215
Iteration 9/25 | Loss: 0.00123405
Iteration 10/25 | Loss: 0.00120366
Iteration 11/25 | Loss: 0.00117565
Iteration 12/25 | Loss: 0.00117125
Iteration 13/25 | Loss: 0.00115295
Iteration 14/25 | Loss: 0.00111832
Iteration 15/25 | Loss: 0.00111171
Iteration 16/25 | Loss: 0.00112142
Iteration 17/25 | Loss: 0.00113404
Iteration 18/25 | Loss: 0.00114618
Iteration 19/25 | Loss: 0.00110066
Iteration 20/25 | Loss: 0.00110280
Iteration 21/25 | Loss: 0.00108693
Iteration 22/25 | Loss: 0.00108347
Iteration 23/25 | Loss: 0.00108280
Iteration 24/25 | Loss: 0.00107619
Iteration 25/25 | Loss: 0.00107174

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47765708
Iteration 2/25 | Loss: 0.00728297
Iteration 3/25 | Loss: 0.00371540
Iteration 4/25 | Loss: 0.00371540
Iteration 5/25 | Loss: 0.00371540
Iteration 6/25 | Loss: 0.00371540
Iteration 7/25 | Loss: 0.00371540
Iteration 8/25 | Loss: 0.00371540
Iteration 9/25 | Loss: 0.00371540
Iteration 10/25 | Loss: 0.00371539
Iteration 11/25 | Loss: 0.00371539
Iteration 12/25 | Loss: 0.00371539
Iteration 13/25 | Loss: 0.00371539
Iteration 14/25 | Loss: 0.00371539
Iteration 15/25 | Loss: 0.00371539
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0037153949961066246, 0.0037153949961066246, 0.0037153949961066246, 0.0037153949961066246, 0.0037153949961066246]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0037153949961066246

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00371539
Iteration 2/1000 | Loss: 0.00495674
Iteration 3/1000 | Loss: 0.00275527
Iteration 4/1000 | Loss: 0.00189706
Iteration 5/1000 | Loss: 0.00608988
Iteration 6/1000 | Loss: 0.00119373
Iteration 7/1000 | Loss: 0.00105995
Iteration 8/1000 | Loss: 0.00098192
Iteration 9/1000 | Loss: 0.00113723
Iteration 10/1000 | Loss: 0.00105099
Iteration 11/1000 | Loss: 0.00130499
Iteration 12/1000 | Loss: 0.00223728
Iteration 13/1000 | Loss: 0.00160189
Iteration 14/1000 | Loss: 0.00199144
Iteration 15/1000 | Loss: 0.00150698
Iteration 16/1000 | Loss: 0.00030293
Iteration 17/1000 | Loss: 0.00021835
Iteration 18/1000 | Loss: 0.00217507
Iteration 19/1000 | Loss: 0.00013565
Iteration 20/1000 | Loss: 0.00039094
Iteration 21/1000 | Loss: 0.00011994
Iteration 22/1000 | Loss: 0.00047132
Iteration 23/1000 | Loss: 0.00105157
Iteration 24/1000 | Loss: 0.00553457
Iteration 25/1000 | Loss: 0.00391502
Iteration 26/1000 | Loss: 0.00510021
Iteration 27/1000 | Loss: 0.00166368
Iteration 28/1000 | Loss: 0.00121906
Iteration 29/1000 | Loss: 0.00106714
Iteration 30/1000 | Loss: 0.00153531
Iteration 31/1000 | Loss: 0.00256343
Iteration 32/1000 | Loss: 0.00385619
Iteration 33/1000 | Loss: 0.00094753
Iteration 34/1000 | Loss: 0.00069528
Iteration 35/1000 | Loss: 0.00184882
Iteration 36/1000 | Loss: 0.00102805
Iteration 37/1000 | Loss: 0.00159527
Iteration 38/1000 | Loss: 0.00094916
Iteration 39/1000 | Loss: 0.00105188
Iteration 40/1000 | Loss: 0.00055497
Iteration 41/1000 | Loss: 0.00082354
Iteration 42/1000 | Loss: 0.00053620
Iteration 43/1000 | Loss: 0.00173030
Iteration 44/1000 | Loss: 0.00115535
Iteration 45/1000 | Loss: 0.00164359
Iteration 46/1000 | Loss: 0.00087135
Iteration 47/1000 | Loss: 0.00192079
Iteration 48/1000 | Loss: 0.00112380
Iteration 49/1000 | Loss: 0.00040324
Iteration 50/1000 | Loss: 0.00693682
Iteration 51/1000 | Loss: 0.00188643
Iteration 52/1000 | Loss: 0.00274987
Iteration 53/1000 | Loss: 0.00059920
Iteration 54/1000 | Loss: 0.00179432
Iteration 55/1000 | Loss: 0.00064926
Iteration 56/1000 | Loss: 0.00265059
Iteration 57/1000 | Loss: 0.00093959
Iteration 58/1000 | Loss: 0.00050395
Iteration 59/1000 | Loss: 0.00035923
Iteration 60/1000 | Loss: 0.00104817
Iteration 61/1000 | Loss: 0.00066163
Iteration 62/1000 | Loss: 0.00201568
Iteration 63/1000 | Loss: 0.00063446
Iteration 64/1000 | Loss: 0.00051415
Iteration 65/1000 | Loss: 0.00145837
Iteration 66/1000 | Loss: 0.00099949
Iteration 67/1000 | Loss: 0.00073032
Iteration 68/1000 | Loss: 0.00066997
Iteration 69/1000 | Loss: 0.00029192
Iteration 70/1000 | Loss: 0.00041019
Iteration 71/1000 | Loss: 0.00013444
Iteration 72/1000 | Loss: 0.00060951
Iteration 73/1000 | Loss: 0.00046000
Iteration 74/1000 | Loss: 0.00060474
Iteration 75/1000 | Loss: 0.00035301
Iteration 76/1000 | Loss: 0.00074523
Iteration 77/1000 | Loss: 0.00052853
Iteration 78/1000 | Loss: 0.00080934
Iteration 79/1000 | Loss: 0.00089307
Iteration 80/1000 | Loss: 0.00039096
Iteration 81/1000 | Loss: 0.00093891
Iteration 82/1000 | Loss: 0.00079808
Iteration 83/1000 | Loss: 0.00018902
Iteration 84/1000 | Loss: 0.00044698
Iteration 85/1000 | Loss: 0.00057338
Iteration 86/1000 | Loss: 0.00021362
Iteration 87/1000 | Loss: 0.00008648
Iteration 88/1000 | Loss: 0.00065735
Iteration 89/1000 | Loss: 0.00138029
Iteration 90/1000 | Loss: 0.00113222
Iteration 91/1000 | Loss: 0.00140701
Iteration 92/1000 | Loss: 0.00097869
Iteration 93/1000 | Loss: 0.00007942
Iteration 94/1000 | Loss: 0.00006828
Iteration 95/1000 | Loss: 0.00010512
Iteration 96/1000 | Loss: 0.00010727
Iteration 97/1000 | Loss: 0.00078667
Iteration 98/1000 | Loss: 0.00095482
Iteration 99/1000 | Loss: 0.00073944
Iteration 100/1000 | Loss: 0.00039937
Iteration 101/1000 | Loss: 0.00025622
Iteration 102/1000 | Loss: 0.00025028
Iteration 103/1000 | Loss: 0.00067329
Iteration 104/1000 | Loss: 0.00026915
Iteration 105/1000 | Loss: 0.00053896
Iteration 106/1000 | Loss: 0.00070566
Iteration 107/1000 | Loss: 0.00057195
Iteration 108/1000 | Loss: 0.00174843
Iteration 109/1000 | Loss: 0.00044771
Iteration 110/1000 | Loss: 0.00055148
Iteration 111/1000 | Loss: 0.00257908
Iteration 112/1000 | Loss: 0.00075602
Iteration 113/1000 | Loss: 0.00046722
Iteration 114/1000 | Loss: 0.00154044
Iteration 115/1000 | Loss: 0.00106419
Iteration 116/1000 | Loss: 0.00043622
Iteration 117/1000 | Loss: 0.00078804
Iteration 118/1000 | Loss: 0.00023562
Iteration 119/1000 | Loss: 0.00014823
Iteration 120/1000 | Loss: 0.00004721
Iteration 121/1000 | Loss: 0.00004263
Iteration 122/1000 | Loss: 0.00003921
Iteration 123/1000 | Loss: 0.00003675
Iteration 124/1000 | Loss: 0.00003458
Iteration 125/1000 | Loss: 0.00003338
Iteration 126/1000 | Loss: 0.00032161
Iteration 127/1000 | Loss: 0.00003136
Iteration 128/1000 | Loss: 0.00003029
Iteration 129/1000 | Loss: 0.00002938
Iteration 130/1000 | Loss: 0.00002871
Iteration 131/1000 | Loss: 0.00002813
Iteration 132/1000 | Loss: 0.00002777
Iteration 133/1000 | Loss: 0.00002750
Iteration 134/1000 | Loss: 0.00002738
Iteration 135/1000 | Loss: 0.00002716
Iteration 136/1000 | Loss: 0.00002713
Iteration 137/1000 | Loss: 0.00002710
Iteration 138/1000 | Loss: 0.00002709
Iteration 139/1000 | Loss: 0.00002705
Iteration 140/1000 | Loss: 0.00002704
Iteration 141/1000 | Loss: 0.00002703
Iteration 142/1000 | Loss: 0.00002700
Iteration 143/1000 | Loss: 0.00002695
Iteration 144/1000 | Loss: 0.00002695
Iteration 145/1000 | Loss: 0.00002694
Iteration 146/1000 | Loss: 0.00002694
Iteration 147/1000 | Loss: 0.00002693
Iteration 148/1000 | Loss: 0.00002692
Iteration 149/1000 | Loss: 0.00002691
Iteration 150/1000 | Loss: 0.00002690
Iteration 151/1000 | Loss: 0.00002690
Iteration 152/1000 | Loss: 0.00002688
Iteration 153/1000 | Loss: 0.00002688
Iteration 154/1000 | Loss: 0.00002687
Iteration 155/1000 | Loss: 0.00002686
Iteration 156/1000 | Loss: 0.00002684
Iteration 157/1000 | Loss: 0.00002683
Iteration 158/1000 | Loss: 0.00002683
Iteration 159/1000 | Loss: 0.00002682
Iteration 160/1000 | Loss: 0.00002682
Iteration 161/1000 | Loss: 0.00002682
Iteration 162/1000 | Loss: 0.00002682
Iteration 163/1000 | Loss: 0.00002679
Iteration 164/1000 | Loss: 0.00002678
Iteration 165/1000 | Loss: 0.00002678
Iteration 166/1000 | Loss: 0.00002678
Iteration 167/1000 | Loss: 0.00002677
Iteration 168/1000 | Loss: 0.00002677
Iteration 169/1000 | Loss: 0.00002677
Iteration 170/1000 | Loss: 0.00002676
Iteration 171/1000 | Loss: 0.00002676
Iteration 172/1000 | Loss: 0.00002676
Iteration 173/1000 | Loss: 0.00002676
Iteration 174/1000 | Loss: 0.00002675
Iteration 175/1000 | Loss: 0.00002675
Iteration 176/1000 | Loss: 0.00002675
Iteration 177/1000 | Loss: 0.00002675
Iteration 178/1000 | Loss: 0.00002674
Iteration 179/1000 | Loss: 0.00002674
Iteration 180/1000 | Loss: 0.00002674
Iteration 181/1000 | Loss: 0.00002673
Iteration 182/1000 | Loss: 0.00002673
Iteration 183/1000 | Loss: 0.00002672
Iteration 184/1000 | Loss: 0.00002671
Iteration 185/1000 | Loss: 0.00002671
Iteration 186/1000 | Loss: 0.00002671
Iteration 187/1000 | Loss: 0.00002671
Iteration 188/1000 | Loss: 0.00002671
Iteration 189/1000 | Loss: 0.00002671
Iteration 190/1000 | Loss: 0.00002671
Iteration 191/1000 | Loss: 0.00002671
Iteration 192/1000 | Loss: 0.00002671
Iteration 193/1000 | Loss: 0.00002670
Iteration 194/1000 | Loss: 0.00002670
Iteration 195/1000 | Loss: 0.00002670
Iteration 196/1000 | Loss: 0.00002670
Iteration 197/1000 | Loss: 0.00002670
Iteration 198/1000 | Loss: 0.00002669
Iteration 199/1000 | Loss: 0.00002669
Iteration 200/1000 | Loss: 0.00002668
Iteration 201/1000 | Loss: 0.00002668
Iteration 202/1000 | Loss: 0.00002668
Iteration 203/1000 | Loss: 0.00002667
Iteration 204/1000 | Loss: 0.00002667
Iteration 205/1000 | Loss: 0.00002667
Iteration 206/1000 | Loss: 0.00002667
Iteration 207/1000 | Loss: 0.00002666
Iteration 208/1000 | Loss: 0.00002666
Iteration 209/1000 | Loss: 0.00002666
Iteration 210/1000 | Loss: 0.00002666
Iteration 211/1000 | Loss: 0.00002666
Iteration 212/1000 | Loss: 0.00002666
Iteration 213/1000 | Loss: 0.00002666
Iteration 214/1000 | Loss: 0.00002666
Iteration 215/1000 | Loss: 0.00002666
Iteration 216/1000 | Loss: 0.00002666
Iteration 217/1000 | Loss: 0.00002666
Iteration 218/1000 | Loss: 0.00002666
Iteration 219/1000 | Loss: 0.00002666
Iteration 220/1000 | Loss: 0.00002666
Iteration 221/1000 | Loss: 0.00002666
Iteration 222/1000 | Loss: 0.00002666
Iteration 223/1000 | Loss: 0.00002666
Iteration 224/1000 | Loss: 0.00002665
Iteration 225/1000 | Loss: 0.00002665
Iteration 226/1000 | Loss: 0.00002665
Iteration 227/1000 | Loss: 0.00002665
Iteration 228/1000 | Loss: 0.00002665
Iteration 229/1000 | Loss: 0.00002665
Iteration 230/1000 | Loss: 0.00002665
Iteration 231/1000 | Loss: 0.00002664
Iteration 232/1000 | Loss: 0.00002664
Iteration 233/1000 | Loss: 0.00002664
Iteration 234/1000 | Loss: 0.00002664
Iteration 235/1000 | Loss: 0.00002664
Iteration 236/1000 | Loss: 0.00002664
Iteration 237/1000 | Loss: 0.00002664
Iteration 238/1000 | Loss: 0.00002663
Iteration 239/1000 | Loss: 0.00002663
Iteration 240/1000 | Loss: 0.00002663
Iteration 241/1000 | Loss: 0.00002663
Iteration 242/1000 | Loss: 0.00002663
Iteration 243/1000 | Loss: 0.00002663
Iteration 244/1000 | Loss: 0.00002663
Iteration 245/1000 | Loss: 0.00002663
Iteration 246/1000 | Loss: 0.00002663
Iteration 247/1000 | Loss: 0.00002663
Iteration 248/1000 | Loss: 0.00002663
Iteration 249/1000 | Loss: 0.00002663
Iteration 250/1000 | Loss: 0.00002663
Iteration 251/1000 | Loss: 0.00002663
Iteration 252/1000 | Loss: 0.00002663
Iteration 253/1000 | Loss: 0.00002663
Iteration 254/1000 | Loss: 0.00002663
Iteration 255/1000 | Loss: 0.00002662
Iteration 256/1000 | Loss: 0.00002662
Iteration 257/1000 | Loss: 0.00002662
Iteration 258/1000 | Loss: 0.00002662
Iteration 259/1000 | Loss: 0.00002662
Iteration 260/1000 | Loss: 0.00002662
Iteration 261/1000 | Loss: 0.00002662
Iteration 262/1000 | Loss: 0.00002662
Iteration 263/1000 | Loss: 0.00002661
Iteration 264/1000 | Loss: 0.00002661
Iteration 265/1000 | Loss: 0.00002661
Iteration 266/1000 | Loss: 0.00002661
Iteration 267/1000 | Loss: 0.00002661
Iteration 268/1000 | Loss: 0.00002661
Iteration 269/1000 | Loss: 0.00002661
Iteration 270/1000 | Loss: 0.00002660
Iteration 271/1000 | Loss: 0.00002660
Iteration 272/1000 | Loss: 0.00002660
Iteration 273/1000 | Loss: 0.00002660
Iteration 274/1000 | Loss: 0.00002660
Iteration 275/1000 | Loss: 0.00002660
Iteration 276/1000 | Loss: 0.00002660
Iteration 277/1000 | Loss: 0.00002660
Iteration 278/1000 | Loss: 0.00002660
Iteration 279/1000 | Loss: 0.00002660
Iteration 280/1000 | Loss: 0.00002660
Iteration 281/1000 | Loss: 0.00002660
Iteration 282/1000 | Loss: 0.00002660
Iteration 283/1000 | Loss: 0.00002660
Iteration 284/1000 | Loss: 0.00002660
Iteration 285/1000 | Loss: 0.00002660
Iteration 286/1000 | Loss: 0.00002660
Iteration 287/1000 | Loss: 0.00002659
Iteration 288/1000 | Loss: 0.00002659
Iteration 289/1000 | Loss: 0.00002659
Iteration 290/1000 | Loss: 0.00002659
Iteration 291/1000 | Loss: 0.00002659
Iteration 292/1000 | Loss: 0.00002659
Iteration 293/1000 | Loss: 0.00002659
Iteration 294/1000 | Loss: 0.00002659
Iteration 295/1000 | Loss: 0.00002659
Iteration 296/1000 | Loss: 0.00002659
Iteration 297/1000 | Loss: 0.00002659
Iteration 298/1000 | Loss: 0.00002659
Iteration 299/1000 | Loss: 0.00002659
Iteration 300/1000 | Loss: 0.00002659
Iteration 301/1000 | Loss: 0.00002658
Iteration 302/1000 | Loss: 0.00002658
Iteration 303/1000 | Loss: 0.00002658
Iteration 304/1000 | Loss: 0.00002658
Iteration 305/1000 | Loss: 0.00002658
Iteration 306/1000 | Loss: 0.00002658
Iteration 307/1000 | Loss: 0.00002658
Iteration 308/1000 | Loss: 0.00002658
Iteration 309/1000 | Loss: 0.00002658
Iteration 310/1000 | Loss: 0.00002657
Iteration 311/1000 | Loss: 0.00002657
Iteration 312/1000 | Loss: 0.00002657
Iteration 313/1000 | Loss: 0.00002657
Iteration 314/1000 | Loss: 0.00002657
Iteration 315/1000 | Loss: 0.00002657
Iteration 316/1000 | Loss: 0.00002657
Iteration 317/1000 | Loss: 0.00002657
Iteration 318/1000 | Loss: 0.00002656
Iteration 319/1000 | Loss: 0.00002656
Iteration 320/1000 | Loss: 0.00002656
Iteration 321/1000 | Loss: 0.00002656
Iteration 322/1000 | Loss: 0.00002656
Iteration 323/1000 | Loss: 0.00002656
Iteration 324/1000 | Loss: 0.00002656
Iteration 325/1000 | Loss: 0.00002656
Iteration 326/1000 | Loss: 0.00002656
Iteration 327/1000 | Loss: 0.00002656
Iteration 328/1000 | Loss: 0.00002656
Iteration 329/1000 | Loss: 0.00002655
Iteration 330/1000 | Loss: 0.00002655
Iteration 331/1000 | Loss: 0.00002655
Iteration 332/1000 | Loss: 0.00002655
Iteration 333/1000 | Loss: 0.00002655
Iteration 334/1000 | Loss: 0.00002655
Iteration 335/1000 | Loss: 0.00002655
Iteration 336/1000 | Loss: 0.00002655
Iteration 337/1000 | Loss: 0.00002655
Iteration 338/1000 | Loss: 0.00002655
Iteration 339/1000 | Loss: 0.00002655
Iteration 340/1000 | Loss: 0.00002655
Iteration 341/1000 | Loss: 0.00002655
Iteration 342/1000 | Loss: 0.00002655
Iteration 343/1000 | Loss: 0.00002655
Iteration 344/1000 | Loss: 0.00002655
Iteration 345/1000 | Loss: 0.00002655
Iteration 346/1000 | Loss: 0.00002655
Iteration 347/1000 | Loss: 0.00002654
Iteration 348/1000 | Loss: 0.00002654
Iteration 349/1000 | Loss: 0.00002654
Iteration 350/1000 | Loss: 0.00002654
Iteration 351/1000 | Loss: 0.00002654
Iteration 352/1000 | Loss: 0.00002654
Iteration 353/1000 | Loss: 0.00002654
Iteration 354/1000 | Loss: 0.00002654
Iteration 355/1000 | Loss: 0.00002654
Iteration 356/1000 | Loss: 0.00002654
Iteration 357/1000 | Loss: 0.00002654
Iteration 358/1000 | Loss: 0.00002654
Iteration 359/1000 | Loss: 0.00002654
Iteration 360/1000 | Loss: 0.00002654
Iteration 361/1000 | Loss: 0.00002654
Iteration 362/1000 | Loss: 0.00002654
Iteration 363/1000 | Loss: 0.00002654
Iteration 364/1000 | Loss: 0.00002654
Iteration 365/1000 | Loss: 0.00002653
Iteration 366/1000 | Loss: 0.00002653
Iteration 367/1000 | Loss: 0.00002653
Iteration 368/1000 | Loss: 0.00002653
Iteration 369/1000 | Loss: 0.00002653
Iteration 370/1000 | Loss: 0.00002653
Iteration 371/1000 | Loss: 0.00002653
Iteration 372/1000 | Loss: 0.00002653
Iteration 373/1000 | Loss: 0.00002653
Iteration 374/1000 | Loss: 0.00002653
Iteration 375/1000 | Loss: 0.00002653
Iteration 376/1000 | Loss: 0.00002653
Iteration 377/1000 | Loss: 0.00002653
Iteration 378/1000 | Loss: 0.00002653
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 378. Stopping optimization.
Last 5 losses: [2.6532366973697208e-05, 2.6532366973697208e-05, 2.6532366973697208e-05, 2.6532366973697208e-05, 2.6532366973697208e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6532366973697208e-05

Optimization complete. Final v2v error: 3.880228281021118 mm

Highest mean error: 14.709583282470703 mm for frame 203

Lowest mean error: 3.2611331939697266 mm for frame 215

Saving results

Total time: 292.26555609703064
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01017292
Iteration 2/25 | Loss: 0.00180325
Iteration 3/25 | Loss: 0.00130792
Iteration 4/25 | Loss: 0.00119818
Iteration 5/25 | Loss: 0.00113493
Iteration 6/25 | Loss: 0.00109413
Iteration 7/25 | Loss: 0.00109754
Iteration 8/25 | Loss: 0.00106711
Iteration 9/25 | Loss: 0.00105846
Iteration 10/25 | Loss: 0.00103763
Iteration 11/25 | Loss: 0.00101079
Iteration 12/25 | Loss: 0.00099854
Iteration 13/25 | Loss: 0.00099406
Iteration 14/25 | Loss: 0.00099267
Iteration 15/25 | Loss: 0.00098640
Iteration 16/25 | Loss: 0.00098515
Iteration 17/25 | Loss: 0.00098490
Iteration 18/25 | Loss: 0.00098474
Iteration 19/25 | Loss: 0.00098472
Iteration 20/25 | Loss: 0.00098472
Iteration 21/25 | Loss: 0.00098472
Iteration 22/25 | Loss: 0.00098472
Iteration 23/25 | Loss: 0.00098472
Iteration 24/25 | Loss: 0.00098471
Iteration 25/25 | Loss: 0.00098471

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49426675
Iteration 2/25 | Loss: 0.00078713
Iteration 3/25 | Loss: 0.00078712
Iteration 4/25 | Loss: 0.00078712
Iteration 5/25 | Loss: 0.00078712
Iteration 6/25 | Loss: 0.00078712
Iteration 7/25 | Loss: 0.00078712
Iteration 8/25 | Loss: 0.00078712
Iteration 9/25 | Loss: 0.00078712
Iteration 10/25 | Loss: 0.00078712
Iteration 11/25 | Loss: 0.00078712
Iteration 12/25 | Loss: 0.00078712
Iteration 13/25 | Loss: 0.00078712
Iteration 14/25 | Loss: 0.00078712
Iteration 15/25 | Loss: 0.00078712
Iteration 16/25 | Loss: 0.00078712
Iteration 17/25 | Loss: 0.00078712
Iteration 18/25 | Loss: 0.00078712
Iteration 19/25 | Loss: 0.00078712
Iteration 20/25 | Loss: 0.00078712
Iteration 21/25 | Loss: 0.00078712
Iteration 22/25 | Loss: 0.00078712
Iteration 23/25 | Loss: 0.00078712
Iteration 24/25 | Loss: 0.00078712
Iteration 25/25 | Loss: 0.00078712

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078712
Iteration 2/1000 | Loss: 0.00039297
Iteration 3/1000 | Loss: 0.00006504
Iteration 4/1000 | Loss: 0.00005498
Iteration 5/1000 | Loss: 0.00005022
Iteration 6/1000 | Loss: 0.00004584
Iteration 7/1000 | Loss: 0.00007269
Iteration 8/1000 | Loss: 0.00005042
Iteration 9/1000 | Loss: 0.00010012
Iteration 10/1000 | Loss: 0.00004076
Iteration 11/1000 | Loss: 0.00004020
Iteration 12/1000 | Loss: 0.00007306
Iteration 13/1000 | Loss: 0.00003961
Iteration 14/1000 | Loss: 0.00037932
Iteration 15/1000 | Loss: 0.00009294
Iteration 16/1000 | Loss: 0.00003916
Iteration 17/1000 | Loss: 0.00007758
Iteration 18/1000 | Loss: 0.00003837
Iteration 19/1000 | Loss: 0.00005535
Iteration 20/1000 | Loss: 0.00003767
Iteration 21/1000 | Loss: 0.00003719
Iteration 22/1000 | Loss: 0.00003696
Iteration 23/1000 | Loss: 0.00003691
Iteration 24/1000 | Loss: 0.00003689
Iteration 25/1000 | Loss: 0.00003687
Iteration 26/1000 | Loss: 0.00003686
Iteration 27/1000 | Loss: 0.00003685
Iteration 28/1000 | Loss: 0.00003682
Iteration 29/1000 | Loss: 0.00003678
Iteration 30/1000 | Loss: 0.00003671
Iteration 31/1000 | Loss: 0.00003671
Iteration 32/1000 | Loss: 0.00003670
Iteration 33/1000 | Loss: 0.00003667
Iteration 34/1000 | Loss: 0.00003665
Iteration 35/1000 | Loss: 0.00003665
Iteration 36/1000 | Loss: 0.00003665
Iteration 37/1000 | Loss: 0.00003664
Iteration 38/1000 | Loss: 0.00003663
Iteration 39/1000 | Loss: 0.00003662
Iteration 40/1000 | Loss: 0.00003662
Iteration 41/1000 | Loss: 0.00003662
Iteration 42/1000 | Loss: 0.00003662
Iteration 43/1000 | Loss: 0.00003662
Iteration 44/1000 | Loss: 0.00003662
Iteration 45/1000 | Loss: 0.00003662
Iteration 46/1000 | Loss: 0.00003662
Iteration 47/1000 | Loss: 0.00003662
Iteration 48/1000 | Loss: 0.00003662
Iteration 49/1000 | Loss: 0.00003661
Iteration 50/1000 | Loss: 0.00003661
Iteration 51/1000 | Loss: 0.00003661
Iteration 52/1000 | Loss: 0.00003661
Iteration 53/1000 | Loss: 0.00003661
Iteration 54/1000 | Loss: 0.00003658
Iteration 55/1000 | Loss: 0.00003657
Iteration 56/1000 | Loss: 0.00003657
Iteration 57/1000 | Loss: 0.00003655
Iteration 58/1000 | Loss: 0.00003655
Iteration 59/1000 | Loss: 0.00003654
Iteration 60/1000 | Loss: 0.00003654
Iteration 61/1000 | Loss: 0.00003652
Iteration 62/1000 | Loss: 0.00003652
Iteration 63/1000 | Loss: 0.00003652
Iteration 64/1000 | Loss: 0.00003652
Iteration 65/1000 | Loss: 0.00003652
Iteration 66/1000 | Loss: 0.00003652
Iteration 67/1000 | Loss: 0.00003652
Iteration 68/1000 | Loss: 0.00003652
Iteration 69/1000 | Loss: 0.00003652
Iteration 70/1000 | Loss: 0.00003651
Iteration 71/1000 | Loss: 0.00003651
Iteration 72/1000 | Loss: 0.00003651
Iteration 73/1000 | Loss: 0.00003651
Iteration 74/1000 | Loss: 0.00003651
Iteration 75/1000 | Loss: 0.00003651
Iteration 76/1000 | Loss: 0.00003651
Iteration 77/1000 | Loss: 0.00003650
Iteration 78/1000 | Loss: 0.00003650
Iteration 79/1000 | Loss: 0.00003649
Iteration 80/1000 | Loss: 0.00003649
Iteration 81/1000 | Loss: 0.00003648
Iteration 82/1000 | Loss: 0.00003647
Iteration 83/1000 | Loss: 0.00003646
Iteration 84/1000 | Loss: 0.00003646
Iteration 85/1000 | Loss: 0.00003646
Iteration 86/1000 | Loss: 0.00003645
Iteration 87/1000 | Loss: 0.00003644
Iteration 88/1000 | Loss: 0.00003644
Iteration 89/1000 | Loss: 0.00003643
Iteration 90/1000 | Loss: 0.00003642
Iteration 91/1000 | Loss: 0.00003642
Iteration 92/1000 | Loss: 0.00003641
Iteration 93/1000 | Loss: 0.00003641
Iteration 94/1000 | Loss: 0.00003641
Iteration 95/1000 | Loss: 0.00003640
Iteration 96/1000 | Loss: 0.00003640
Iteration 97/1000 | Loss: 0.00003640
Iteration 98/1000 | Loss: 0.00003640
Iteration 99/1000 | Loss: 0.00003640
Iteration 100/1000 | Loss: 0.00003640
Iteration 101/1000 | Loss: 0.00003639
Iteration 102/1000 | Loss: 0.00003639
Iteration 103/1000 | Loss: 0.00003638
Iteration 104/1000 | Loss: 0.00003638
Iteration 105/1000 | Loss: 0.00003638
Iteration 106/1000 | Loss: 0.00003638
Iteration 107/1000 | Loss: 0.00003638
Iteration 108/1000 | Loss: 0.00003638
Iteration 109/1000 | Loss: 0.00003638
Iteration 110/1000 | Loss: 0.00003638
Iteration 111/1000 | Loss: 0.00003638
Iteration 112/1000 | Loss: 0.00003638
Iteration 113/1000 | Loss: 0.00003637
Iteration 114/1000 | Loss: 0.00003637
Iteration 115/1000 | Loss: 0.00003637
Iteration 116/1000 | Loss: 0.00003637
Iteration 117/1000 | Loss: 0.00003636
Iteration 118/1000 | Loss: 0.00003636
Iteration 119/1000 | Loss: 0.00003636
Iteration 120/1000 | Loss: 0.00003635
Iteration 121/1000 | Loss: 0.00003635
Iteration 122/1000 | Loss: 0.00003635
Iteration 123/1000 | Loss: 0.00003635
Iteration 124/1000 | Loss: 0.00003634
Iteration 125/1000 | Loss: 0.00003634
Iteration 126/1000 | Loss: 0.00003634
Iteration 127/1000 | Loss: 0.00003633
Iteration 128/1000 | Loss: 0.00003633
Iteration 129/1000 | Loss: 0.00003633
Iteration 130/1000 | Loss: 0.00003633
Iteration 131/1000 | Loss: 0.00003633
Iteration 132/1000 | Loss: 0.00003633
Iteration 133/1000 | Loss: 0.00003633
Iteration 134/1000 | Loss: 0.00003633
Iteration 135/1000 | Loss: 0.00003633
Iteration 136/1000 | Loss: 0.00003632
Iteration 137/1000 | Loss: 0.00003632
Iteration 138/1000 | Loss: 0.00003632
Iteration 139/1000 | Loss: 0.00003632
Iteration 140/1000 | Loss: 0.00003632
Iteration 141/1000 | Loss: 0.00003632
Iteration 142/1000 | Loss: 0.00003632
Iteration 143/1000 | Loss: 0.00003632
Iteration 144/1000 | Loss: 0.00003632
Iteration 145/1000 | Loss: 0.00003632
Iteration 146/1000 | Loss: 0.00003632
Iteration 147/1000 | Loss: 0.00003632
Iteration 148/1000 | Loss: 0.00003632
Iteration 149/1000 | Loss: 0.00003632
Iteration 150/1000 | Loss: 0.00003631
Iteration 151/1000 | Loss: 0.00003631
Iteration 152/1000 | Loss: 0.00003631
Iteration 153/1000 | Loss: 0.00003631
Iteration 154/1000 | Loss: 0.00003631
Iteration 155/1000 | Loss: 0.00003631
Iteration 156/1000 | Loss: 0.00003631
Iteration 157/1000 | Loss: 0.00003631
Iteration 158/1000 | Loss: 0.00003631
Iteration 159/1000 | Loss: 0.00003630
Iteration 160/1000 | Loss: 0.00003630
Iteration 161/1000 | Loss: 0.00003630
Iteration 162/1000 | Loss: 0.00003630
Iteration 163/1000 | Loss: 0.00003630
Iteration 164/1000 | Loss: 0.00003630
Iteration 165/1000 | Loss: 0.00003630
Iteration 166/1000 | Loss: 0.00003630
Iteration 167/1000 | Loss: 0.00003630
Iteration 168/1000 | Loss: 0.00003630
Iteration 169/1000 | Loss: 0.00003629
Iteration 170/1000 | Loss: 0.00003629
Iteration 171/1000 | Loss: 0.00003629
Iteration 172/1000 | Loss: 0.00003629
Iteration 173/1000 | Loss: 0.00003629
Iteration 174/1000 | Loss: 0.00003629
Iteration 175/1000 | Loss: 0.00003629
Iteration 176/1000 | Loss: 0.00003629
Iteration 177/1000 | Loss: 0.00003629
Iteration 178/1000 | Loss: 0.00003629
Iteration 179/1000 | Loss: 0.00003629
Iteration 180/1000 | Loss: 0.00003629
Iteration 181/1000 | Loss: 0.00003629
Iteration 182/1000 | Loss: 0.00003629
Iteration 183/1000 | Loss: 0.00003629
Iteration 184/1000 | Loss: 0.00003629
Iteration 185/1000 | Loss: 0.00003629
Iteration 186/1000 | Loss: 0.00003629
Iteration 187/1000 | Loss: 0.00003628
Iteration 188/1000 | Loss: 0.00003628
Iteration 189/1000 | Loss: 0.00003628
Iteration 190/1000 | Loss: 0.00003628
Iteration 191/1000 | Loss: 0.00003628
Iteration 192/1000 | Loss: 0.00003627
Iteration 193/1000 | Loss: 0.00003627
Iteration 194/1000 | Loss: 0.00003627
Iteration 195/1000 | Loss: 0.00003627
Iteration 196/1000 | Loss: 0.00003627
Iteration 197/1000 | Loss: 0.00003627
Iteration 198/1000 | Loss: 0.00003627
Iteration 199/1000 | Loss: 0.00003627
Iteration 200/1000 | Loss: 0.00003626
Iteration 201/1000 | Loss: 0.00003626
Iteration 202/1000 | Loss: 0.00003626
Iteration 203/1000 | Loss: 0.00003626
Iteration 204/1000 | Loss: 0.00003626
Iteration 205/1000 | Loss: 0.00003626
Iteration 206/1000 | Loss: 0.00003626
Iteration 207/1000 | Loss: 0.00003626
Iteration 208/1000 | Loss: 0.00003626
Iteration 209/1000 | Loss: 0.00003626
Iteration 210/1000 | Loss: 0.00003625
Iteration 211/1000 | Loss: 0.00003625
Iteration 212/1000 | Loss: 0.00003625
Iteration 213/1000 | Loss: 0.00003625
Iteration 214/1000 | Loss: 0.00003625
Iteration 215/1000 | Loss: 0.00003625
Iteration 216/1000 | Loss: 0.00003625
Iteration 217/1000 | Loss: 0.00003625
Iteration 218/1000 | Loss: 0.00003625
Iteration 219/1000 | Loss: 0.00003625
Iteration 220/1000 | Loss: 0.00003625
Iteration 221/1000 | Loss: 0.00003625
Iteration 222/1000 | Loss: 0.00003625
Iteration 223/1000 | Loss: 0.00003625
Iteration 224/1000 | Loss: 0.00003625
Iteration 225/1000 | Loss: 0.00003625
Iteration 226/1000 | Loss: 0.00003625
Iteration 227/1000 | Loss: 0.00003625
Iteration 228/1000 | Loss: 0.00003625
Iteration 229/1000 | Loss: 0.00003625
Iteration 230/1000 | Loss: 0.00003625
Iteration 231/1000 | Loss: 0.00003625
Iteration 232/1000 | Loss: 0.00003625
Iteration 233/1000 | Loss: 0.00003625
Iteration 234/1000 | Loss: 0.00003625
Iteration 235/1000 | Loss: 0.00003625
Iteration 236/1000 | Loss: 0.00003625
Iteration 237/1000 | Loss: 0.00003625
Iteration 238/1000 | Loss: 0.00003625
Iteration 239/1000 | Loss: 0.00003625
Iteration 240/1000 | Loss: 0.00003625
Iteration 241/1000 | Loss: 0.00003625
Iteration 242/1000 | Loss: 0.00003625
Iteration 243/1000 | Loss: 0.00003625
Iteration 244/1000 | Loss: 0.00003625
Iteration 245/1000 | Loss: 0.00003625
Iteration 246/1000 | Loss: 0.00003625
Iteration 247/1000 | Loss: 0.00003625
Iteration 248/1000 | Loss: 0.00003625
Iteration 249/1000 | Loss: 0.00003625
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 249. Stopping optimization.
Last 5 losses: [3.624836972448975e-05, 3.624836972448975e-05, 3.624836972448975e-05, 3.624836972448975e-05, 3.624836972448975e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.624836972448975e-05

Optimization complete. Final v2v error: 4.76550817489624 mm

Highest mean error: 14.545395851135254 mm for frame 178

Lowest mean error: 4.130635738372803 mm for frame 23

Saving results

Total time: 95.10726237297058
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00444751
Iteration 2/25 | Loss: 0.00095808
Iteration 3/25 | Loss: 0.00084734
Iteration 4/25 | Loss: 0.00083166
Iteration 5/25 | Loss: 0.00082522
Iteration 6/25 | Loss: 0.00082356
Iteration 7/25 | Loss: 0.00082295
Iteration 8/25 | Loss: 0.00082289
Iteration 9/25 | Loss: 0.00082289
Iteration 10/25 | Loss: 0.00082289
Iteration 11/25 | Loss: 0.00082289
Iteration 12/25 | Loss: 0.00082289
Iteration 13/25 | Loss: 0.00082289
Iteration 14/25 | Loss: 0.00082289
Iteration 15/25 | Loss: 0.00082289
Iteration 16/25 | Loss: 0.00082289
Iteration 17/25 | Loss: 0.00082289
Iteration 18/25 | Loss: 0.00082289
Iteration 19/25 | Loss: 0.00082289
Iteration 20/25 | Loss: 0.00082289
Iteration 21/25 | Loss: 0.00082289
Iteration 22/25 | Loss: 0.00082289
Iteration 23/25 | Loss: 0.00082289
Iteration 24/25 | Loss: 0.00082289
Iteration 25/25 | Loss: 0.00082289

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51604986
Iteration 2/25 | Loss: 0.00054848
Iteration 3/25 | Loss: 0.00054846
Iteration 4/25 | Loss: 0.00054846
Iteration 5/25 | Loss: 0.00054846
Iteration 6/25 | Loss: 0.00054846
Iteration 7/25 | Loss: 0.00054846
Iteration 8/25 | Loss: 0.00054846
Iteration 9/25 | Loss: 0.00054846
Iteration 10/25 | Loss: 0.00054846
Iteration 11/25 | Loss: 0.00054846
Iteration 12/25 | Loss: 0.00054846
Iteration 13/25 | Loss: 0.00054846
Iteration 14/25 | Loss: 0.00054846
Iteration 15/25 | Loss: 0.00054846
Iteration 16/25 | Loss: 0.00054846
Iteration 17/25 | Loss: 0.00054846
Iteration 18/25 | Loss: 0.00054846
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005484585999511182, 0.0005484585999511182, 0.0005484585999511182, 0.0005484585999511182, 0.0005484585999511182]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005484585999511182

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054846
Iteration 2/1000 | Loss: 0.00002487
Iteration 3/1000 | Loss: 0.00001546
Iteration 4/1000 | Loss: 0.00001384
Iteration 5/1000 | Loss: 0.00001277
Iteration 6/1000 | Loss: 0.00001235
Iteration 7/1000 | Loss: 0.00001208
Iteration 8/1000 | Loss: 0.00001206
Iteration 9/1000 | Loss: 0.00001196
Iteration 10/1000 | Loss: 0.00001187
Iteration 11/1000 | Loss: 0.00001181
Iteration 12/1000 | Loss: 0.00001174
Iteration 13/1000 | Loss: 0.00001173
Iteration 14/1000 | Loss: 0.00001172
Iteration 15/1000 | Loss: 0.00001172
Iteration 16/1000 | Loss: 0.00001170
Iteration 17/1000 | Loss: 0.00001168
Iteration 18/1000 | Loss: 0.00001168
Iteration 19/1000 | Loss: 0.00001167
Iteration 20/1000 | Loss: 0.00001167
Iteration 21/1000 | Loss: 0.00001166
Iteration 22/1000 | Loss: 0.00001166
Iteration 23/1000 | Loss: 0.00001165
Iteration 24/1000 | Loss: 0.00001164
Iteration 25/1000 | Loss: 0.00001164
Iteration 26/1000 | Loss: 0.00001163
Iteration 27/1000 | Loss: 0.00001163
Iteration 28/1000 | Loss: 0.00001163
Iteration 29/1000 | Loss: 0.00001162
Iteration 30/1000 | Loss: 0.00001162
Iteration 31/1000 | Loss: 0.00001161
Iteration 32/1000 | Loss: 0.00001161
Iteration 33/1000 | Loss: 0.00001160
Iteration 34/1000 | Loss: 0.00001160
Iteration 35/1000 | Loss: 0.00001159
Iteration 36/1000 | Loss: 0.00001159
Iteration 37/1000 | Loss: 0.00001159
Iteration 38/1000 | Loss: 0.00001159
Iteration 39/1000 | Loss: 0.00001158
Iteration 40/1000 | Loss: 0.00001157
Iteration 41/1000 | Loss: 0.00001157
Iteration 42/1000 | Loss: 0.00001157
Iteration 43/1000 | Loss: 0.00001157
Iteration 44/1000 | Loss: 0.00001156
Iteration 45/1000 | Loss: 0.00001156
Iteration 46/1000 | Loss: 0.00001156
Iteration 47/1000 | Loss: 0.00001155
Iteration 48/1000 | Loss: 0.00001155
Iteration 49/1000 | Loss: 0.00001155
Iteration 50/1000 | Loss: 0.00001154
Iteration 51/1000 | Loss: 0.00001154
Iteration 52/1000 | Loss: 0.00001154
Iteration 53/1000 | Loss: 0.00001154
Iteration 54/1000 | Loss: 0.00001154
Iteration 55/1000 | Loss: 0.00001154
Iteration 56/1000 | Loss: 0.00001153
Iteration 57/1000 | Loss: 0.00001152
Iteration 58/1000 | Loss: 0.00001152
Iteration 59/1000 | Loss: 0.00001152
Iteration 60/1000 | Loss: 0.00001152
Iteration 61/1000 | Loss: 0.00001151
Iteration 62/1000 | Loss: 0.00001151
Iteration 63/1000 | Loss: 0.00001151
Iteration 64/1000 | Loss: 0.00001150
Iteration 65/1000 | Loss: 0.00001150
Iteration 66/1000 | Loss: 0.00001150
Iteration 67/1000 | Loss: 0.00001149
Iteration 68/1000 | Loss: 0.00001149
Iteration 69/1000 | Loss: 0.00001149
Iteration 70/1000 | Loss: 0.00001149
Iteration 71/1000 | Loss: 0.00001149
Iteration 72/1000 | Loss: 0.00001148
Iteration 73/1000 | Loss: 0.00001148
Iteration 74/1000 | Loss: 0.00001148
Iteration 75/1000 | Loss: 0.00001148
Iteration 76/1000 | Loss: 0.00001148
Iteration 77/1000 | Loss: 0.00001147
Iteration 78/1000 | Loss: 0.00001147
Iteration 79/1000 | Loss: 0.00001147
Iteration 80/1000 | Loss: 0.00001147
Iteration 81/1000 | Loss: 0.00001147
Iteration 82/1000 | Loss: 0.00001147
Iteration 83/1000 | Loss: 0.00001147
Iteration 84/1000 | Loss: 0.00001147
Iteration 85/1000 | Loss: 0.00001147
Iteration 86/1000 | Loss: 0.00001146
Iteration 87/1000 | Loss: 0.00001146
Iteration 88/1000 | Loss: 0.00001146
Iteration 89/1000 | Loss: 0.00001146
Iteration 90/1000 | Loss: 0.00001146
Iteration 91/1000 | Loss: 0.00001146
Iteration 92/1000 | Loss: 0.00001146
Iteration 93/1000 | Loss: 0.00001146
Iteration 94/1000 | Loss: 0.00001146
Iteration 95/1000 | Loss: 0.00001146
Iteration 96/1000 | Loss: 0.00001146
Iteration 97/1000 | Loss: 0.00001146
Iteration 98/1000 | Loss: 0.00001146
Iteration 99/1000 | Loss: 0.00001146
Iteration 100/1000 | Loss: 0.00001146
Iteration 101/1000 | Loss: 0.00001146
Iteration 102/1000 | Loss: 0.00001145
Iteration 103/1000 | Loss: 0.00001145
Iteration 104/1000 | Loss: 0.00001145
Iteration 105/1000 | Loss: 0.00001145
Iteration 106/1000 | Loss: 0.00001145
Iteration 107/1000 | Loss: 0.00001145
Iteration 108/1000 | Loss: 0.00001145
Iteration 109/1000 | Loss: 0.00001145
Iteration 110/1000 | Loss: 0.00001145
Iteration 111/1000 | Loss: 0.00001145
Iteration 112/1000 | Loss: 0.00001145
Iteration 113/1000 | Loss: 0.00001145
Iteration 114/1000 | Loss: 0.00001145
Iteration 115/1000 | Loss: 0.00001145
Iteration 116/1000 | Loss: 0.00001145
Iteration 117/1000 | Loss: 0.00001145
Iteration 118/1000 | Loss: 0.00001145
Iteration 119/1000 | Loss: 0.00001145
Iteration 120/1000 | Loss: 0.00001145
Iteration 121/1000 | Loss: 0.00001145
Iteration 122/1000 | Loss: 0.00001145
Iteration 123/1000 | Loss: 0.00001145
Iteration 124/1000 | Loss: 0.00001145
Iteration 125/1000 | Loss: 0.00001145
Iteration 126/1000 | Loss: 0.00001145
Iteration 127/1000 | Loss: 0.00001145
Iteration 128/1000 | Loss: 0.00001145
Iteration 129/1000 | Loss: 0.00001145
Iteration 130/1000 | Loss: 0.00001145
Iteration 131/1000 | Loss: 0.00001145
Iteration 132/1000 | Loss: 0.00001145
Iteration 133/1000 | Loss: 0.00001145
Iteration 134/1000 | Loss: 0.00001145
Iteration 135/1000 | Loss: 0.00001145
Iteration 136/1000 | Loss: 0.00001145
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 136. Stopping optimization.
Last 5 losses: [1.1450856618466787e-05, 1.1450856618466787e-05, 1.1450856618466787e-05, 1.1450856618466787e-05, 1.1450856618466787e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1450856618466787e-05

Optimization complete. Final v2v error: 2.894559621810913 mm

Highest mean error: 3.176260232925415 mm for frame 112

Lowest mean error: 2.637706995010376 mm for frame 19

Saving results

Total time: 31.978349447250366
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00803733
Iteration 2/25 | Loss: 0.00136642
Iteration 3/25 | Loss: 0.00107104
Iteration 4/25 | Loss: 0.00102730
Iteration 5/25 | Loss: 0.00102046
Iteration 6/25 | Loss: 0.00101902
Iteration 7/25 | Loss: 0.00101900
Iteration 8/25 | Loss: 0.00101900
Iteration 9/25 | Loss: 0.00101900
Iteration 10/25 | Loss: 0.00101900
Iteration 11/25 | Loss: 0.00101900
Iteration 12/25 | Loss: 0.00101900
Iteration 13/25 | Loss: 0.00101900
Iteration 14/25 | Loss: 0.00101900
Iteration 15/25 | Loss: 0.00101900
Iteration 16/25 | Loss: 0.00101900
Iteration 17/25 | Loss: 0.00101900
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0010189992608502507, 0.0010189992608502507, 0.0010189992608502507, 0.0010189992608502507, 0.0010189992608502507]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010189992608502507

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49457932
Iteration 2/25 | Loss: 0.00052508
Iteration 3/25 | Loss: 0.00052504
Iteration 4/25 | Loss: 0.00052504
Iteration 5/25 | Loss: 0.00052504
Iteration 6/25 | Loss: 0.00052504
Iteration 7/25 | Loss: 0.00052504
Iteration 8/25 | Loss: 0.00052504
Iteration 9/25 | Loss: 0.00052504
Iteration 10/25 | Loss: 0.00052504
Iteration 11/25 | Loss: 0.00052504
Iteration 12/25 | Loss: 0.00052504
Iteration 13/25 | Loss: 0.00052504
Iteration 14/25 | Loss: 0.00052504
Iteration 15/25 | Loss: 0.00052504
Iteration 16/25 | Loss: 0.00052504
Iteration 17/25 | Loss: 0.00052504
Iteration 18/25 | Loss: 0.00052504
Iteration 19/25 | Loss: 0.00052504
Iteration 20/25 | Loss: 0.00052504
Iteration 21/25 | Loss: 0.00052504
Iteration 22/25 | Loss: 0.00052504
Iteration 23/25 | Loss: 0.00052504
Iteration 24/25 | Loss: 0.00052504
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0005250400281511247, 0.0005250400281511247, 0.0005250400281511247, 0.0005250400281511247, 0.0005250400281511247]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005250400281511247

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052504
Iteration 2/1000 | Loss: 0.00004846
Iteration 3/1000 | Loss: 0.00003503
Iteration 4/1000 | Loss: 0.00003188
Iteration 5/1000 | Loss: 0.00003056
Iteration 6/1000 | Loss: 0.00002989
Iteration 7/1000 | Loss: 0.00002941
Iteration 8/1000 | Loss: 0.00002912
Iteration 9/1000 | Loss: 0.00002888
Iteration 10/1000 | Loss: 0.00002869
Iteration 11/1000 | Loss: 0.00002865
Iteration 12/1000 | Loss: 0.00002861
Iteration 13/1000 | Loss: 0.00002850
Iteration 14/1000 | Loss: 0.00002848
Iteration 15/1000 | Loss: 0.00002846
Iteration 16/1000 | Loss: 0.00002845
Iteration 17/1000 | Loss: 0.00002845
Iteration 18/1000 | Loss: 0.00002844
Iteration 19/1000 | Loss: 0.00002844
Iteration 20/1000 | Loss: 0.00002843
Iteration 21/1000 | Loss: 0.00002843
Iteration 22/1000 | Loss: 0.00002842
Iteration 23/1000 | Loss: 0.00002842
Iteration 24/1000 | Loss: 0.00002842
Iteration 25/1000 | Loss: 0.00002841
Iteration 26/1000 | Loss: 0.00002841
Iteration 27/1000 | Loss: 0.00002841
Iteration 28/1000 | Loss: 0.00002841
Iteration 29/1000 | Loss: 0.00002841
Iteration 30/1000 | Loss: 0.00002841
Iteration 31/1000 | Loss: 0.00002840
Iteration 32/1000 | Loss: 0.00002840
Iteration 33/1000 | Loss: 0.00002840
Iteration 34/1000 | Loss: 0.00002840
Iteration 35/1000 | Loss: 0.00002840
Iteration 36/1000 | Loss: 0.00002840
Iteration 37/1000 | Loss: 0.00002840
Iteration 38/1000 | Loss: 0.00002840
Iteration 39/1000 | Loss: 0.00002840
Iteration 40/1000 | Loss: 0.00002840
Iteration 41/1000 | Loss: 0.00002839
Iteration 42/1000 | Loss: 0.00002839
Iteration 43/1000 | Loss: 0.00002839
Iteration 44/1000 | Loss: 0.00002839
Iteration 45/1000 | Loss: 0.00002839
Iteration 46/1000 | Loss: 0.00002839
Iteration 47/1000 | Loss: 0.00002839
Iteration 48/1000 | Loss: 0.00002839
Iteration 49/1000 | Loss: 0.00002839
Iteration 50/1000 | Loss: 0.00002839
Iteration 51/1000 | Loss: 0.00002839
Iteration 52/1000 | Loss: 0.00002839
Iteration 53/1000 | Loss: 0.00002839
Iteration 54/1000 | Loss: 0.00002839
Iteration 55/1000 | Loss: 0.00002839
Iteration 56/1000 | Loss: 0.00002838
Iteration 57/1000 | Loss: 0.00002838
Iteration 58/1000 | Loss: 0.00002838
Iteration 59/1000 | Loss: 0.00002838
Iteration 60/1000 | Loss: 0.00002838
Iteration 61/1000 | Loss: 0.00002838
Iteration 62/1000 | Loss: 0.00002838
Iteration 63/1000 | Loss: 0.00002838
Iteration 64/1000 | Loss: 0.00002838
Iteration 65/1000 | Loss: 0.00002838
Iteration 66/1000 | Loss: 0.00002838
Iteration 67/1000 | Loss: 0.00002838
Iteration 68/1000 | Loss: 0.00002838
Iteration 69/1000 | Loss: 0.00002838
Iteration 70/1000 | Loss: 0.00002838
Iteration 71/1000 | Loss: 0.00002838
Iteration 72/1000 | Loss: 0.00002838
Iteration 73/1000 | Loss: 0.00002838
Iteration 74/1000 | Loss: 0.00002838
Iteration 75/1000 | Loss: 0.00002838
Iteration 76/1000 | Loss: 0.00002838
Iteration 77/1000 | Loss: 0.00002838
Iteration 78/1000 | Loss: 0.00002838
Iteration 79/1000 | Loss: 0.00002838
Iteration 80/1000 | Loss: 0.00002838
Iteration 81/1000 | Loss: 0.00002838
Iteration 82/1000 | Loss: 0.00002838
Iteration 83/1000 | Loss: 0.00002838
Iteration 84/1000 | Loss: 0.00002838
Iteration 85/1000 | Loss: 0.00002838
Iteration 86/1000 | Loss: 0.00002838
Iteration 87/1000 | Loss: 0.00002838
Iteration 88/1000 | Loss: 0.00002838
Iteration 89/1000 | Loss: 0.00002838
Iteration 90/1000 | Loss: 0.00002838
Iteration 91/1000 | Loss: 0.00002838
Iteration 92/1000 | Loss: 0.00002838
Iteration 93/1000 | Loss: 0.00002838
Iteration 94/1000 | Loss: 0.00002838
Iteration 95/1000 | Loss: 0.00002838
Iteration 96/1000 | Loss: 0.00002838
Iteration 97/1000 | Loss: 0.00002838
Iteration 98/1000 | Loss: 0.00002838
Iteration 99/1000 | Loss: 0.00002838
Iteration 100/1000 | Loss: 0.00002838
Iteration 101/1000 | Loss: 0.00002838
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [2.8384398319758475e-05, 2.8384398319758475e-05, 2.8384398319758475e-05, 2.8384398319758475e-05, 2.8384398319758475e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8384398319758475e-05

Optimization complete. Final v2v error: 4.249200344085693 mm

Highest mean error: 4.597556114196777 mm for frame 87

Lowest mean error: 3.3094069957733154 mm for frame 4

Saving results

Total time: 29.85394859313965
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1084/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1084.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1084
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00875280
Iteration 2/25 | Loss: 0.00148921
Iteration 3/25 | Loss: 0.00102014
Iteration 4/25 | Loss: 0.00090636
Iteration 5/25 | Loss: 0.00088820
Iteration 6/25 | Loss: 0.00088615
Iteration 7/25 | Loss: 0.00088558
Iteration 8/25 | Loss: 0.00088558
Iteration 9/25 | Loss: 0.00088558
Iteration 10/25 | Loss: 0.00088558
Iteration 11/25 | Loss: 0.00088558
Iteration 12/25 | Loss: 0.00088558
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008855774067342281, 0.0008855774067342281, 0.0008855774067342281, 0.0008855774067342281, 0.0008855774067342281]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008855774067342281

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39348078
Iteration 2/25 | Loss: 0.00060951
Iteration 3/25 | Loss: 0.00060950
Iteration 4/25 | Loss: 0.00060950
Iteration 5/25 | Loss: 0.00060949
Iteration 6/25 | Loss: 0.00060949
Iteration 7/25 | Loss: 0.00060949
Iteration 8/25 | Loss: 0.00060949
Iteration 9/25 | Loss: 0.00060949
Iteration 10/25 | Loss: 0.00060949
Iteration 11/25 | Loss: 0.00060949
Iteration 12/25 | Loss: 0.00060949
Iteration 13/25 | Loss: 0.00060949
Iteration 14/25 | Loss: 0.00060949
Iteration 15/25 | Loss: 0.00060949
Iteration 16/25 | Loss: 0.00060949
Iteration 17/25 | Loss: 0.00060949
Iteration 18/25 | Loss: 0.00060949
Iteration 19/25 | Loss: 0.00060949
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0006094929995015264, 0.0006094929995015264, 0.0006094929995015264, 0.0006094929995015264, 0.0006094929995015264]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006094929995015264

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060949
Iteration 2/1000 | Loss: 0.00003760
Iteration 3/1000 | Loss: 0.00002551
Iteration 4/1000 | Loss: 0.00002143
Iteration 5/1000 | Loss: 0.00001980
Iteration 6/1000 | Loss: 0.00001856
Iteration 7/1000 | Loss: 0.00001794
Iteration 8/1000 | Loss: 0.00001755
Iteration 9/1000 | Loss: 0.00001731
Iteration 10/1000 | Loss: 0.00001725
Iteration 11/1000 | Loss: 0.00001714
Iteration 12/1000 | Loss: 0.00001704
Iteration 13/1000 | Loss: 0.00001703
Iteration 14/1000 | Loss: 0.00001702
Iteration 15/1000 | Loss: 0.00001701
Iteration 16/1000 | Loss: 0.00001701
Iteration 17/1000 | Loss: 0.00001701
Iteration 18/1000 | Loss: 0.00001700
Iteration 19/1000 | Loss: 0.00001700
Iteration 20/1000 | Loss: 0.00001700
Iteration 21/1000 | Loss: 0.00001699
Iteration 22/1000 | Loss: 0.00001699
Iteration 23/1000 | Loss: 0.00001698
Iteration 24/1000 | Loss: 0.00001698
Iteration 25/1000 | Loss: 0.00001698
Iteration 26/1000 | Loss: 0.00001697
Iteration 27/1000 | Loss: 0.00001697
Iteration 28/1000 | Loss: 0.00001697
Iteration 29/1000 | Loss: 0.00001696
Iteration 30/1000 | Loss: 0.00001696
Iteration 31/1000 | Loss: 0.00001696
Iteration 32/1000 | Loss: 0.00001696
Iteration 33/1000 | Loss: 0.00001695
Iteration 34/1000 | Loss: 0.00001695
Iteration 35/1000 | Loss: 0.00001694
Iteration 36/1000 | Loss: 0.00001694
Iteration 37/1000 | Loss: 0.00001694
Iteration 38/1000 | Loss: 0.00001694
Iteration 39/1000 | Loss: 0.00001693
Iteration 40/1000 | Loss: 0.00001693
Iteration 41/1000 | Loss: 0.00001692
Iteration 42/1000 | Loss: 0.00001692
Iteration 43/1000 | Loss: 0.00001692
Iteration 44/1000 | Loss: 0.00001692
Iteration 45/1000 | Loss: 0.00001692
Iteration 46/1000 | Loss: 0.00001692
Iteration 47/1000 | Loss: 0.00001692
Iteration 48/1000 | Loss: 0.00001692
Iteration 49/1000 | Loss: 0.00001692
Iteration 50/1000 | Loss: 0.00001692
Iteration 51/1000 | Loss: 0.00001692
Iteration 52/1000 | Loss: 0.00001692
Iteration 53/1000 | Loss: 0.00001692
Iteration 54/1000 | Loss: 0.00001692
Iteration 55/1000 | Loss: 0.00001691
Iteration 56/1000 | Loss: 0.00001691
Iteration 57/1000 | Loss: 0.00001691
Iteration 58/1000 | Loss: 0.00001691
Iteration 59/1000 | Loss: 0.00001691
Iteration 60/1000 | Loss: 0.00001691
Iteration 61/1000 | Loss: 0.00001690
Iteration 62/1000 | Loss: 0.00001690
Iteration 63/1000 | Loss: 0.00001690
Iteration 64/1000 | Loss: 0.00001690
Iteration 65/1000 | Loss: 0.00001689
Iteration 66/1000 | Loss: 0.00001689
Iteration 67/1000 | Loss: 0.00001689
Iteration 68/1000 | Loss: 0.00001689
Iteration 69/1000 | Loss: 0.00001689
Iteration 70/1000 | Loss: 0.00001689
Iteration 71/1000 | Loss: 0.00001688
Iteration 72/1000 | Loss: 0.00001688
Iteration 73/1000 | Loss: 0.00001688
Iteration 74/1000 | Loss: 0.00001688
Iteration 75/1000 | Loss: 0.00001688
Iteration 76/1000 | Loss: 0.00001688
Iteration 77/1000 | Loss: 0.00001688
Iteration 78/1000 | Loss: 0.00001688
Iteration 79/1000 | Loss: 0.00001688
Iteration 80/1000 | Loss: 0.00001688
Iteration 81/1000 | Loss: 0.00001687
Iteration 82/1000 | Loss: 0.00001687
Iteration 83/1000 | Loss: 0.00001687
Iteration 84/1000 | Loss: 0.00001687
Iteration 85/1000 | Loss: 0.00001687
Iteration 86/1000 | Loss: 0.00001687
Iteration 87/1000 | Loss: 0.00001687
Iteration 88/1000 | Loss: 0.00001687
Iteration 89/1000 | Loss: 0.00001687
Iteration 90/1000 | Loss: 0.00001686
Iteration 91/1000 | Loss: 0.00001686
Iteration 92/1000 | Loss: 0.00001686
Iteration 93/1000 | Loss: 0.00001686
Iteration 94/1000 | Loss: 0.00001686
Iteration 95/1000 | Loss: 0.00001686
Iteration 96/1000 | Loss: 0.00001686
Iteration 97/1000 | Loss: 0.00001686
Iteration 98/1000 | Loss: 0.00001686
Iteration 99/1000 | Loss: 0.00001686
Iteration 100/1000 | Loss: 0.00001686
Iteration 101/1000 | Loss: 0.00001686
Iteration 102/1000 | Loss: 0.00001686
Iteration 103/1000 | Loss: 0.00001686
Iteration 104/1000 | Loss: 0.00001686
Iteration 105/1000 | Loss: 0.00001686
Iteration 106/1000 | Loss: 0.00001686
Iteration 107/1000 | Loss: 0.00001686
Iteration 108/1000 | Loss: 0.00001686
Iteration 109/1000 | Loss: 0.00001686
Iteration 110/1000 | Loss: 0.00001686
Iteration 111/1000 | Loss: 0.00001686
Iteration 112/1000 | Loss: 0.00001686
Iteration 113/1000 | Loss: 0.00001686
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [1.6857136870385148e-05, 1.6857136870385148e-05, 1.6857136870385148e-05, 1.6857136870385148e-05, 1.6857136870385148e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6857136870385148e-05

Optimization complete. Final v2v error: 3.3889663219451904 mm

Highest mean error: 3.62935209274292 mm for frame 115

Lowest mean error: 2.7949798107147217 mm for frame 37

Saving results

Total time: 32.97656011581421
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1048/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1048.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1048
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00493800
Iteration 2/25 | Loss: 0.00135695
Iteration 3/25 | Loss: 0.00097068
Iteration 4/25 | Loss: 0.00089987
Iteration 5/25 | Loss: 0.00088795
Iteration 6/25 | Loss: 0.00088551
Iteration 7/25 | Loss: 0.00088545
Iteration 8/25 | Loss: 0.00088545
Iteration 9/25 | Loss: 0.00088545
Iteration 10/25 | Loss: 0.00088545
Iteration 11/25 | Loss: 0.00088545
Iteration 12/25 | Loss: 0.00088545
Iteration 13/25 | Loss: 0.00088545
Iteration 14/25 | Loss: 0.00088545
Iteration 15/25 | Loss: 0.00088545
Iteration 16/25 | Loss: 0.00088545
Iteration 17/25 | Loss: 0.00088545
Iteration 18/25 | Loss: 0.00088545
Iteration 19/25 | Loss: 0.00088545
Iteration 20/25 | Loss: 0.00088545
Iteration 21/25 | Loss: 0.00088545
Iteration 22/25 | Loss: 0.00088545
Iteration 23/25 | Loss: 0.00088545
Iteration 24/25 | Loss: 0.00088545
Iteration 25/25 | Loss: 0.00088545

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62619734
Iteration 2/25 | Loss: 0.00059684
Iteration 3/25 | Loss: 0.00059684
Iteration 4/25 | Loss: 0.00059684
Iteration 5/25 | Loss: 0.00059684
Iteration 6/25 | Loss: 0.00059684
Iteration 7/25 | Loss: 0.00059684
Iteration 8/25 | Loss: 0.00059684
Iteration 9/25 | Loss: 0.00059684
Iteration 10/25 | Loss: 0.00059684
Iteration 11/25 | Loss: 0.00059684
Iteration 12/25 | Loss: 0.00059684
Iteration 13/25 | Loss: 0.00059684
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0005968381883576512, 0.0005968381883576512, 0.0005968381883576512, 0.0005968381883576512, 0.0005968381883576512]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005968381883576512

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059684
Iteration 2/1000 | Loss: 0.00003384
Iteration 3/1000 | Loss: 0.00002531
Iteration 4/1000 | Loss: 0.00002257
Iteration 5/1000 | Loss: 0.00002127
Iteration 6/1000 | Loss: 0.00002051
Iteration 7/1000 | Loss: 0.00001987
Iteration 8/1000 | Loss: 0.00001933
Iteration 9/1000 | Loss: 0.00001905
Iteration 10/1000 | Loss: 0.00001875
Iteration 11/1000 | Loss: 0.00001850
Iteration 12/1000 | Loss: 0.00001847
Iteration 13/1000 | Loss: 0.00001827
Iteration 14/1000 | Loss: 0.00001812
Iteration 15/1000 | Loss: 0.00001808
Iteration 16/1000 | Loss: 0.00001807
Iteration 17/1000 | Loss: 0.00001806
Iteration 18/1000 | Loss: 0.00001805
Iteration 19/1000 | Loss: 0.00001803
Iteration 20/1000 | Loss: 0.00001802
Iteration 21/1000 | Loss: 0.00001801
Iteration 22/1000 | Loss: 0.00001801
Iteration 23/1000 | Loss: 0.00001800
Iteration 24/1000 | Loss: 0.00001796
Iteration 25/1000 | Loss: 0.00001794
Iteration 26/1000 | Loss: 0.00001794
Iteration 27/1000 | Loss: 0.00001794
Iteration 28/1000 | Loss: 0.00001793
Iteration 29/1000 | Loss: 0.00001793
Iteration 30/1000 | Loss: 0.00001793
Iteration 31/1000 | Loss: 0.00001793
Iteration 32/1000 | Loss: 0.00001793
Iteration 33/1000 | Loss: 0.00001793
Iteration 34/1000 | Loss: 0.00001793
Iteration 35/1000 | Loss: 0.00001793
Iteration 36/1000 | Loss: 0.00001792
Iteration 37/1000 | Loss: 0.00001792
Iteration 38/1000 | Loss: 0.00001792
Iteration 39/1000 | Loss: 0.00001792
Iteration 40/1000 | Loss: 0.00001791
Iteration 41/1000 | Loss: 0.00001791
Iteration 42/1000 | Loss: 0.00001790
Iteration 43/1000 | Loss: 0.00001790
Iteration 44/1000 | Loss: 0.00001790
Iteration 45/1000 | Loss: 0.00001790
Iteration 46/1000 | Loss: 0.00001789
Iteration 47/1000 | Loss: 0.00001789
Iteration 48/1000 | Loss: 0.00001789
Iteration 49/1000 | Loss: 0.00001789
Iteration 50/1000 | Loss: 0.00001789
Iteration 51/1000 | Loss: 0.00001789
Iteration 52/1000 | Loss: 0.00001789
Iteration 53/1000 | Loss: 0.00001789
Iteration 54/1000 | Loss: 0.00001789
Iteration 55/1000 | Loss: 0.00001789
Iteration 56/1000 | Loss: 0.00001788
Iteration 57/1000 | Loss: 0.00001788
Iteration 58/1000 | Loss: 0.00001788
Iteration 59/1000 | Loss: 0.00001788
Iteration 60/1000 | Loss: 0.00001788
Iteration 61/1000 | Loss: 0.00001788
Iteration 62/1000 | Loss: 0.00001787
Iteration 63/1000 | Loss: 0.00001787
Iteration 64/1000 | Loss: 0.00001787
Iteration 65/1000 | Loss: 0.00001787
Iteration 66/1000 | Loss: 0.00001787
Iteration 67/1000 | Loss: 0.00001787
Iteration 68/1000 | Loss: 0.00001787
Iteration 69/1000 | Loss: 0.00001787
Iteration 70/1000 | Loss: 0.00001787
Iteration 71/1000 | Loss: 0.00001787
Iteration 72/1000 | Loss: 0.00001787
Iteration 73/1000 | Loss: 0.00001787
Iteration 74/1000 | Loss: 0.00001787
Iteration 75/1000 | Loss: 0.00001787
Iteration 76/1000 | Loss: 0.00001787
Iteration 77/1000 | Loss: 0.00001787
Iteration 78/1000 | Loss: 0.00001787
Iteration 79/1000 | Loss: 0.00001787
Iteration 80/1000 | Loss: 0.00001787
Iteration 81/1000 | Loss: 0.00001787
Iteration 82/1000 | Loss: 0.00001787
Iteration 83/1000 | Loss: 0.00001787
Iteration 84/1000 | Loss: 0.00001787
Iteration 85/1000 | Loss: 0.00001787
Iteration 86/1000 | Loss: 0.00001787
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 86. Stopping optimization.
Last 5 losses: [1.7867752831079997e-05, 1.7867752831079997e-05, 1.7867752831079997e-05, 1.7867752831079997e-05, 1.7867752831079997e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7867752831079997e-05

Optimization complete. Final v2v error: 3.6053314208984375 mm

Highest mean error: 4.083382606506348 mm for frame 225

Lowest mean error: 3.3149654865264893 mm for frame 0

Saving results

Total time: 38.22988963127136
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00381543
Iteration 2/25 | Loss: 0.00094662
Iteration 3/25 | Loss: 0.00086756
Iteration 4/25 | Loss: 0.00085774
Iteration 5/25 | Loss: 0.00085169
Iteration 6/25 | Loss: 0.00085045
Iteration 7/25 | Loss: 0.00085045
Iteration 8/25 | Loss: 0.00085045
Iteration 9/25 | Loss: 0.00085045
Iteration 10/25 | Loss: 0.00085045
Iteration 11/25 | Loss: 0.00085045
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008504527504555881, 0.0008504527504555881, 0.0008504527504555881, 0.0008504527504555881, 0.0008504527504555881]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008504527504555881

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66997850
Iteration 2/25 | Loss: 0.00067555
Iteration 3/25 | Loss: 0.00067550
Iteration 4/25 | Loss: 0.00067550
Iteration 5/25 | Loss: 0.00067550
Iteration 6/25 | Loss: 0.00067550
Iteration 7/25 | Loss: 0.00067550
Iteration 8/25 | Loss: 0.00067550
Iteration 9/25 | Loss: 0.00067550
Iteration 10/25 | Loss: 0.00067550
Iteration 11/25 | Loss: 0.00067550
Iteration 12/25 | Loss: 0.00067550
Iteration 13/25 | Loss: 0.00067550
Iteration 14/25 | Loss: 0.00067550
Iteration 15/25 | Loss: 0.00067550
Iteration 16/25 | Loss: 0.00067550
Iteration 17/25 | Loss: 0.00067550
Iteration 18/25 | Loss: 0.00067550
Iteration 19/25 | Loss: 0.00067550
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0006754957139492035, 0.0006754957139492035, 0.0006754957139492035, 0.0006754957139492035, 0.0006754957139492035]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006754957139492035

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00067550
Iteration 2/1000 | Loss: 0.00002683
Iteration 3/1000 | Loss: 0.00001795
Iteration 4/1000 | Loss: 0.00001627
Iteration 5/1000 | Loss: 0.00001526
Iteration 6/1000 | Loss: 0.00001467
Iteration 7/1000 | Loss: 0.00001438
Iteration 8/1000 | Loss: 0.00001406
Iteration 9/1000 | Loss: 0.00001385
Iteration 10/1000 | Loss: 0.00001383
Iteration 11/1000 | Loss: 0.00001378
Iteration 12/1000 | Loss: 0.00001365
Iteration 13/1000 | Loss: 0.00001351
Iteration 14/1000 | Loss: 0.00001346
Iteration 15/1000 | Loss: 0.00001345
Iteration 16/1000 | Loss: 0.00001338
Iteration 17/1000 | Loss: 0.00001337
Iteration 18/1000 | Loss: 0.00001334
Iteration 19/1000 | Loss: 0.00001332
Iteration 20/1000 | Loss: 0.00001327
Iteration 21/1000 | Loss: 0.00001324
Iteration 22/1000 | Loss: 0.00001324
Iteration 23/1000 | Loss: 0.00001324
Iteration 24/1000 | Loss: 0.00001323
Iteration 25/1000 | Loss: 0.00001323
Iteration 26/1000 | Loss: 0.00001323
Iteration 27/1000 | Loss: 0.00001323
Iteration 28/1000 | Loss: 0.00001323
Iteration 29/1000 | Loss: 0.00001323
Iteration 30/1000 | Loss: 0.00001323
Iteration 31/1000 | Loss: 0.00001322
Iteration 32/1000 | Loss: 0.00001322
Iteration 33/1000 | Loss: 0.00001320
Iteration 34/1000 | Loss: 0.00001320
Iteration 35/1000 | Loss: 0.00001319
Iteration 36/1000 | Loss: 0.00001319
Iteration 37/1000 | Loss: 0.00001319
Iteration 38/1000 | Loss: 0.00001319
Iteration 39/1000 | Loss: 0.00001319
Iteration 40/1000 | Loss: 0.00001319
Iteration 41/1000 | Loss: 0.00001319
Iteration 42/1000 | Loss: 0.00001319
Iteration 43/1000 | Loss: 0.00001319
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 43. Stopping optimization.
Last 5 losses: [1.3194320672482718e-05, 1.3194320672482718e-05, 1.3194320672482718e-05, 1.3194320672482718e-05, 1.3194320672482718e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3194320672482718e-05

Optimization complete. Final v2v error: 3.1041765213012695 mm

Highest mean error: 3.450920581817627 mm for frame 129

Lowest mean error: 2.86722993850708 mm for frame 156

Saving results

Total time: 34.00135278701782
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1073/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1073.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1073
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00598234
Iteration 2/25 | Loss: 0.00111970
Iteration 3/25 | Loss: 0.00097255
Iteration 4/25 | Loss: 0.00092085
Iteration 5/25 | Loss: 0.00091224
Iteration 6/25 | Loss: 0.00090921
Iteration 7/25 | Loss: 0.00090834
Iteration 8/25 | Loss: 0.00090834
Iteration 9/25 | Loss: 0.00090834
Iteration 10/25 | Loss: 0.00090834
Iteration 11/25 | Loss: 0.00090834
Iteration 12/25 | Loss: 0.00090834
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009083403856493533, 0.0009083403856493533, 0.0009083403856493533, 0.0009083403856493533, 0.0009083403856493533]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009083403856493533

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.79563999
Iteration 2/25 | Loss: 0.00060682
Iteration 3/25 | Loss: 0.00060681
Iteration 4/25 | Loss: 0.00060681
Iteration 5/25 | Loss: 0.00060681
Iteration 6/25 | Loss: 0.00060681
Iteration 7/25 | Loss: 0.00060681
Iteration 8/25 | Loss: 0.00060681
Iteration 9/25 | Loss: 0.00060681
Iteration 10/25 | Loss: 0.00060681
Iteration 11/25 | Loss: 0.00060681
Iteration 12/25 | Loss: 0.00060681
Iteration 13/25 | Loss: 0.00060681
Iteration 14/25 | Loss: 0.00060681
Iteration 15/25 | Loss: 0.00060681
Iteration 16/25 | Loss: 0.00060681
Iteration 17/25 | Loss: 0.00060681
Iteration 18/25 | Loss: 0.00060681
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006068098009563982, 0.0006068098009563982, 0.0006068098009563982, 0.0006068098009563982, 0.0006068098009563982]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006068098009563982

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060681
Iteration 2/1000 | Loss: 0.00003772
Iteration 3/1000 | Loss: 0.00003124
Iteration 4/1000 | Loss: 0.00002946
Iteration 5/1000 | Loss: 0.00002838
Iteration 6/1000 | Loss: 0.00002756
Iteration 7/1000 | Loss: 0.00002696
Iteration 8/1000 | Loss: 0.00002651
Iteration 9/1000 | Loss: 0.00002623
Iteration 10/1000 | Loss: 0.00002588
Iteration 11/1000 | Loss: 0.00002567
Iteration 12/1000 | Loss: 0.00002563
Iteration 13/1000 | Loss: 0.00002551
Iteration 14/1000 | Loss: 0.00002543
Iteration 15/1000 | Loss: 0.00002542
Iteration 16/1000 | Loss: 0.00002541
Iteration 17/1000 | Loss: 0.00002540
Iteration 18/1000 | Loss: 0.00002540
Iteration 19/1000 | Loss: 0.00002540
Iteration 20/1000 | Loss: 0.00002539
Iteration 21/1000 | Loss: 0.00002539
Iteration 22/1000 | Loss: 0.00002535
Iteration 23/1000 | Loss: 0.00002534
Iteration 24/1000 | Loss: 0.00002533
Iteration 25/1000 | Loss: 0.00002533
Iteration 26/1000 | Loss: 0.00002531
Iteration 27/1000 | Loss: 0.00002531
Iteration 28/1000 | Loss: 0.00002530
Iteration 29/1000 | Loss: 0.00002529
Iteration 30/1000 | Loss: 0.00002529
Iteration 31/1000 | Loss: 0.00002528
Iteration 32/1000 | Loss: 0.00002528
Iteration 33/1000 | Loss: 0.00002528
Iteration 34/1000 | Loss: 0.00002528
Iteration 35/1000 | Loss: 0.00002528
Iteration 36/1000 | Loss: 0.00002527
Iteration 37/1000 | Loss: 0.00002527
Iteration 38/1000 | Loss: 0.00002527
Iteration 39/1000 | Loss: 0.00002527
Iteration 40/1000 | Loss: 0.00002527
Iteration 41/1000 | Loss: 0.00002527
Iteration 42/1000 | Loss: 0.00002527
Iteration 43/1000 | Loss: 0.00002526
Iteration 44/1000 | Loss: 0.00002524
Iteration 45/1000 | Loss: 0.00002524
Iteration 46/1000 | Loss: 0.00002524
Iteration 47/1000 | Loss: 0.00002523
Iteration 48/1000 | Loss: 0.00002523
Iteration 49/1000 | Loss: 0.00002523
Iteration 50/1000 | Loss: 0.00002523
Iteration 51/1000 | Loss: 0.00002522
Iteration 52/1000 | Loss: 0.00002522
Iteration 53/1000 | Loss: 0.00002521
Iteration 54/1000 | Loss: 0.00002521
Iteration 55/1000 | Loss: 0.00002521
Iteration 56/1000 | Loss: 0.00002521
Iteration 57/1000 | Loss: 0.00002521
Iteration 58/1000 | Loss: 0.00002521
Iteration 59/1000 | Loss: 0.00002521
Iteration 60/1000 | Loss: 0.00002521
Iteration 61/1000 | Loss: 0.00002521
Iteration 62/1000 | Loss: 0.00002521
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 62. Stopping optimization.
Last 5 losses: [2.520677116990555e-05, 2.520677116990555e-05, 2.520677116990555e-05, 2.520677116990555e-05, 2.520677116990555e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.520677116990555e-05

Optimization complete. Final v2v error: 4.219709396362305 mm

Highest mean error: 4.700679302215576 mm for frame 162

Lowest mean error: 3.943406105041504 mm for frame 32

Saving results

Total time: 38.02573895454407
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1081/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1081.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1081
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00381378
Iteration 2/25 | Loss: 0.00089601
Iteration 3/25 | Loss: 0.00081618
Iteration 4/25 | Loss: 0.00080267
Iteration 5/25 | Loss: 0.00079765
Iteration 6/25 | Loss: 0.00079630
Iteration 7/25 | Loss: 0.00079614
Iteration 8/25 | Loss: 0.00079614
Iteration 9/25 | Loss: 0.00079614
Iteration 10/25 | Loss: 0.00079614
Iteration 11/25 | Loss: 0.00079614
Iteration 12/25 | Loss: 0.00079614
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007961404626257718, 0.0007961404626257718, 0.0007961404626257718, 0.0007961404626257718, 0.0007961404626257718]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007961404626257718

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.19860744
Iteration 2/25 | Loss: 0.00058440
Iteration 3/25 | Loss: 0.00058440
Iteration 4/25 | Loss: 0.00058440
Iteration 5/25 | Loss: 0.00058440
Iteration 6/25 | Loss: 0.00058440
Iteration 7/25 | Loss: 0.00058440
Iteration 8/25 | Loss: 0.00058440
Iteration 9/25 | Loss: 0.00058440
Iteration 10/25 | Loss: 0.00058440
Iteration 11/25 | Loss: 0.00058440
Iteration 12/25 | Loss: 0.00058440
Iteration 13/25 | Loss: 0.00058440
Iteration 14/25 | Loss: 0.00058440
Iteration 15/25 | Loss: 0.00058440
Iteration 16/25 | Loss: 0.00058440
Iteration 17/25 | Loss: 0.00058440
Iteration 18/25 | Loss: 0.00058440
Iteration 19/25 | Loss: 0.00058440
Iteration 20/25 | Loss: 0.00058440
Iteration 21/25 | Loss: 0.00058440
Iteration 22/25 | Loss: 0.00058440
Iteration 23/25 | Loss: 0.00058440
Iteration 24/25 | Loss: 0.00058440
Iteration 25/25 | Loss: 0.00058440

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00058440
Iteration 2/1000 | Loss: 0.00002263
Iteration 3/1000 | Loss: 0.00001410
Iteration 4/1000 | Loss: 0.00001313
Iteration 5/1000 | Loss: 0.00001226
Iteration 6/1000 | Loss: 0.00001201
Iteration 7/1000 | Loss: 0.00001182
Iteration 8/1000 | Loss: 0.00001180
Iteration 9/1000 | Loss: 0.00001179
Iteration 10/1000 | Loss: 0.00001163
Iteration 11/1000 | Loss: 0.00001149
Iteration 12/1000 | Loss: 0.00001148
Iteration 13/1000 | Loss: 0.00001145
Iteration 14/1000 | Loss: 0.00001144
Iteration 15/1000 | Loss: 0.00001139
Iteration 16/1000 | Loss: 0.00001139
Iteration 17/1000 | Loss: 0.00001139
Iteration 18/1000 | Loss: 0.00001131
Iteration 19/1000 | Loss: 0.00001128
Iteration 20/1000 | Loss: 0.00001126
Iteration 21/1000 | Loss: 0.00001126
Iteration 22/1000 | Loss: 0.00001126
Iteration 23/1000 | Loss: 0.00001125
Iteration 24/1000 | Loss: 0.00001122
Iteration 25/1000 | Loss: 0.00001120
Iteration 26/1000 | Loss: 0.00001120
Iteration 27/1000 | Loss: 0.00001120
Iteration 28/1000 | Loss: 0.00001120
Iteration 29/1000 | Loss: 0.00001120
Iteration 30/1000 | Loss: 0.00001120
Iteration 31/1000 | Loss: 0.00001120
Iteration 32/1000 | Loss: 0.00001120
Iteration 33/1000 | Loss: 0.00001120
Iteration 34/1000 | Loss: 0.00001120
Iteration 35/1000 | Loss: 0.00001120
Iteration 36/1000 | Loss: 0.00001119
Iteration 37/1000 | Loss: 0.00001119
Iteration 38/1000 | Loss: 0.00001119
Iteration 39/1000 | Loss: 0.00001119
Iteration 40/1000 | Loss: 0.00001119
Iteration 41/1000 | Loss: 0.00001119
Iteration 42/1000 | Loss: 0.00001119
Iteration 43/1000 | Loss: 0.00001119
Iteration 44/1000 | Loss: 0.00001119
Iteration 45/1000 | Loss: 0.00001119
Iteration 46/1000 | Loss: 0.00001119
Iteration 47/1000 | Loss: 0.00001119
Iteration 48/1000 | Loss: 0.00001119
Iteration 49/1000 | Loss: 0.00001119
Iteration 50/1000 | Loss: 0.00001119
Iteration 51/1000 | Loss: 0.00001118
Iteration 52/1000 | Loss: 0.00001118
Iteration 53/1000 | Loss: 0.00001117
Iteration 54/1000 | Loss: 0.00001116
Iteration 55/1000 | Loss: 0.00001116
Iteration 56/1000 | Loss: 0.00001116
Iteration 57/1000 | Loss: 0.00001115
Iteration 58/1000 | Loss: 0.00001115
Iteration 59/1000 | Loss: 0.00001114
Iteration 60/1000 | Loss: 0.00001114
Iteration 61/1000 | Loss: 0.00001114
Iteration 62/1000 | Loss: 0.00001114
Iteration 63/1000 | Loss: 0.00001114
Iteration 64/1000 | Loss: 0.00001114
Iteration 65/1000 | Loss: 0.00001113
Iteration 66/1000 | Loss: 0.00001113
Iteration 67/1000 | Loss: 0.00001113
Iteration 68/1000 | Loss: 0.00001113
Iteration 69/1000 | Loss: 0.00001112
Iteration 70/1000 | Loss: 0.00001112
Iteration 71/1000 | Loss: 0.00001111
Iteration 72/1000 | Loss: 0.00001111
Iteration 73/1000 | Loss: 0.00001110
Iteration 74/1000 | Loss: 0.00001107
Iteration 75/1000 | Loss: 0.00001107
Iteration 76/1000 | Loss: 0.00001106
Iteration 77/1000 | Loss: 0.00001105
Iteration 78/1000 | Loss: 0.00001105
Iteration 79/1000 | Loss: 0.00001104
Iteration 80/1000 | Loss: 0.00001104
Iteration 81/1000 | Loss: 0.00001102
Iteration 82/1000 | Loss: 0.00001100
Iteration 83/1000 | Loss: 0.00001100
Iteration 84/1000 | Loss: 0.00001100
Iteration 85/1000 | Loss: 0.00001099
Iteration 86/1000 | Loss: 0.00001099
Iteration 87/1000 | Loss: 0.00001099
Iteration 88/1000 | Loss: 0.00001099
Iteration 89/1000 | Loss: 0.00001099
Iteration 90/1000 | Loss: 0.00001099
Iteration 91/1000 | Loss: 0.00001099
Iteration 92/1000 | Loss: 0.00001099
Iteration 93/1000 | Loss: 0.00001099
Iteration 94/1000 | Loss: 0.00001099
Iteration 95/1000 | Loss: 0.00001099
Iteration 96/1000 | Loss: 0.00001098
Iteration 97/1000 | Loss: 0.00001098
Iteration 98/1000 | Loss: 0.00001098
Iteration 99/1000 | Loss: 0.00001098
Iteration 100/1000 | Loss: 0.00001098
Iteration 101/1000 | Loss: 0.00001098
Iteration 102/1000 | Loss: 0.00001098
Iteration 103/1000 | Loss: 0.00001097
Iteration 104/1000 | Loss: 0.00001097
Iteration 105/1000 | Loss: 0.00001097
Iteration 106/1000 | Loss: 0.00001097
Iteration 107/1000 | Loss: 0.00001097
Iteration 108/1000 | Loss: 0.00001097
Iteration 109/1000 | Loss: 0.00001097
Iteration 110/1000 | Loss: 0.00001097
Iteration 111/1000 | Loss: 0.00001097
Iteration 112/1000 | Loss: 0.00001097
Iteration 113/1000 | Loss: 0.00001097
Iteration 114/1000 | Loss: 0.00001097
Iteration 115/1000 | Loss: 0.00001097
Iteration 116/1000 | Loss: 0.00001097
Iteration 117/1000 | Loss: 0.00001097
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [1.0965209185087588e-05, 1.0965209185087588e-05, 1.0965209185087588e-05, 1.0965209185087588e-05, 1.0965209185087588e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0965209185087588e-05

Optimization complete. Final v2v error: 2.8438973426818848 mm

Highest mean error: 3.0178170204162598 mm for frame 117

Lowest mean error: 2.7459397315979004 mm for frame 89

Saving results

Total time: 33.69544744491577
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1038/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1038.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1038
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00986139
Iteration 2/25 | Loss: 0.00986139
Iteration 3/25 | Loss: 0.00447856
Iteration 4/25 | Loss: 0.00290354
Iteration 5/25 | Loss: 0.00229827
Iteration 6/25 | Loss: 0.00212454
Iteration 7/25 | Loss: 0.00191486
Iteration 8/25 | Loss: 0.00194069
Iteration 9/25 | Loss: 0.00173559
Iteration 10/25 | Loss: 0.00168266
Iteration 11/25 | Loss: 0.00158261
Iteration 12/25 | Loss: 0.00155011
Iteration 13/25 | Loss: 0.00154099
Iteration 14/25 | Loss: 0.00143777
Iteration 15/25 | Loss: 0.00140741
Iteration 16/25 | Loss: 0.00137390
Iteration 17/25 | Loss: 0.00136393
Iteration 18/25 | Loss: 0.00134108
Iteration 19/25 | Loss: 0.00132724
Iteration 20/25 | Loss: 0.00131492
Iteration 21/25 | Loss: 0.00130893
Iteration 22/25 | Loss: 0.00131688
Iteration 23/25 | Loss: 0.00130236
Iteration 24/25 | Loss: 0.00129743
Iteration 25/25 | Loss: 0.00129551

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51300824
Iteration 2/25 | Loss: 0.00299834
Iteration 3/25 | Loss: 0.00298309
Iteration 4/25 | Loss: 0.00298309
Iteration 5/25 | Loss: 0.00298308
Iteration 6/25 | Loss: 0.00298308
Iteration 7/25 | Loss: 0.00298308
Iteration 8/25 | Loss: 0.00298308
Iteration 9/25 | Loss: 0.00298308
Iteration 10/25 | Loss: 0.00298308
Iteration 11/25 | Loss: 0.00298308
Iteration 12/25 | Loss: 0.00298308
Iteration 13/25 | Loss: 0.00298308
Iteration 14/25 | Loss: 0.00298308
Iteration 15/25 | Loss: 0.00298308
Iteration 16/25 | Loss: 0.00298308
Iteration 17/25 | Loss: 0.00298308
Iteration 18/25 | Loss: 0.00298308
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.002983081853017211, 0.002983081853017211, 0.002983081853017211, 0.002983081853017211, 0.002983081853017211]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002983081853017211

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00298308
Iteration 2/1000 | Loss: 0.00509122
Iteration 3/1000 | Loss: 0.00273297
Iteration 4/1000 | Loss: 0.00109967
Iteration 5/1000 | Loss: 0.00155322
Iteration 6/1000 | Loss: 0.00132101
Iteration 7/1000 | Loss: 0.00100560
Iteration 8/1000 | Loss: 0.00092815
Iteration 9/1000 | Loss: 0.00055915
Iteration 10/1000 | Loss: 0.00036410
Iteration 11/1000 | Loss: 0.00057873
Iteration 12/1000 | Loss: 0.00146691
Iteration 13/1000 | Loss: 0.00190127
Iteration 14/1000 | Loss: 0.00261625
Iteration 15/1000 | Loss: 0.00259619
Iteration 16/1000 | Loss: 0.00324969
Iteration 17/1000 | Loss: 0.00172594
Iteration 18/1000 | Loss: 0.00145932
Iteration 19/1000 | Loss: 0.00031278
Iteration 20/1000 | Loss: 0.00069150
Iteration 21/1000 | Loss: 0.00038070
Iteration 22/1000 | Loss: 0.00074008
Iteration 23/1000 | Loss: 0.00128548
Iteration 24/1000 | Loss: 0.00172357
Iteration 25/1000 | Loss: 0.00072515
Iteration 26/1000 | Loss: 0.00043170
Iteration 27/1000 | Loss: 0.00074739
Iteration 28/1000 | Loss: 0.00067405
Iteration 29/1000 | Loss: 0.00039786
Iteration 30/1000 | Loss: 0.00069077
Iteration 31/1000 | Loss: 0.00027516
Iteration 32/1000 | Loss: 0.00021004
Iteration 33/1000 | Loss: 0.00033876
Iteration 34/1000 | Loss: 0.00034945
Iteration 35/1000 | Loss: 0.00023472
Iteration 36/1000 | Loss: 0.00008515
Iteration 37/1000 | Loss: 0.00013646
Iteration 38/1000 | Loss: 0.00010350
Iteration 39/1000 | Loss: 0.00008535
Iteration 40/1000 | Loss: 0.00044007
Iteration 41/1000 | Loss: 0.00037285
Iteration 42/1000 | Loss: 0.00012368
Iteration 43/1000 | Loss: 0.00008213
Iteration 44/1000 | Loss: 0.00092837
Iteration 45/1000 | Loss: 0.00026760
Iteration 46/1000 | Loss: 0.00004922
Iteration 47/1000 | Loss: 0.00024612
Iteration 48/1000 | Loss: 0.00047020
Iteration 49/1000 | Loss: 0.00014013
Iteration 50/1000 | Loss: 0.00026250
Iteration 51/1000 | Loss: 0.00008878
Iteration 52/1000 | Loss: 0.00024132
Iteration 53/1000 | Loss: 0.00024564
Iteration 54/1000 | Loss: 0.00036943
Iteration 55/1000 | Loss: 0.00022165
Iteration 56/1000 | Loss: 0.00028240
Iteration 57/1000 | Loss: 0.00019722
Iteration 58/1000 | Loss: 0.00038279
Iteration 59/1000 | Loss: 0.00019084
Iteration 60/1000 | Loss: 0.00020130
Iteration 61/1000 | Loss: 0.00017562
Iteration 62/1000 | Loss: 0.00014461
Iteration 63/1000 | Loss: 0.00024005
Iteration 64/1000 | Loss: 0.00014168
Iteration 65/1000 | Loss: 0.00016540
Iteration 66/1000 | Loss: 0.00011886
Iteration 67/1000 | Loss: 0.00013146
Iteration 68/1000 | Loss: 0.00014347
Iteration 69/1000 | Loss: 0.00012948
Iteration 70/1000 | Loss: 0.00015997
Iteration 71/1000 | Loss: 0.00045662
Iteration 72/1000 | Loss: 0.00039217
Iteration 73/1000 | Loss: 0.00030803
Iteration 74/1000 | Loss: 0.00039390
Iteration 75/1000 | Loss: 0.00021639
Iteration 76/1000 | Loss: 0.00048439
Iteration 77/1000 | Loss: 0.00042839
Iteration 78/1000 | Loss: 0.00026871
Iteration 79/1000 | Loss: 0.00011629
Iteration 80/1000 | Loss: 0.00031565
Iteration 81/1000 | Loss: 0.00011026
Iteration 82/1000 | Loss: 0.00017039
Iteration 83/1000 | Loss: 0.00016655
Iteration 84/1000 | Loss: 0.00020509
Iteration 85/1000 | Loss: 0.00045010
Iteration 86/1000 | Loss: 0.00009985
Iteration 87/1000 | Loss: 0.00012899
Iteration 88/1000 | Loss: 0.00009184
Iteration 89/1000 | Loss: 0.00034605
Iteration 90/1000 | Loss: 0.00016726
Iteration 91/1000 | Loss: 0.00003670
Iteration 92/1000 | Loss: 0.00018623
Iteration 93/1000 | Loss: 0.00023468
Iteration 94/1000 | Loss: 0.00004007
Iteration 95/1000 | Loss: 0.00003280
Iteration 96/1000 | Loss: 0.00002880
Iteration 97/1000 | Loss: 0.00002583
Iteration 98/1000 | Loss: 0.00002419
Iteration 99/1000 | Loss: 0.00002321
Iteration 100/1000 | Loss: 0.00002211
Iteration 101/1000 | Loss: 0.00021881
Iteration 102/1000 | Loss: 0.00003079
Iteration 103/1000 | Loss: 0.00002051
Iteration 104/1000 | Loss: 0.00001969
Iteration 105/1000 | Loss: 0.00001928
Iteration 106/1000 | Loss: 0.00001913
Iteration 107/1000 | Loss: 0.00001895
Iteration 108/1000 | Loss: 0.00001891
Iteration 109/1000 | Loss: 0.00001868
Iteration 110/1000 | Loss: 0.00029095
Iteration 111/1000 | Loss: 0.00003422
Iteration 112/1000 | Loss: 0.00002862
Iteration 113/1000 | Loss: 0.00001923
Iteration 114/1000 | Loss: 0.00001867
Iteration 115/1000 | Loss: 0.00028949
Iteration 116/1000 | Loss: 0.00002433
Iteration 117/1000 | Loss: 0.00002086
Iteration 118/1000 | Loss: 0.00001921
Iteration 119/1000 | Loss: 0.00001789
Iteration 120/1000 | Loss: 0.00001716
Iteration 121/1000 | Loss: 0.00001694
Iteration 122/1000 | Loss: 0.00001684
Iteration 123/1000 | Loss: 0.00001678
Iteration 124/1000 | Loss: 0.00001662
Iteration 125/1000 | Loss: 0.00001661
Iteration 126/1000 | Loss: 0.00001659
Iteration 127/1000 | Loss: 0.00001653
Iteration 128/1000 | Loss: 0.00001653
Iteration 129/1000 | Loss: 0.00001652
Iteration 130/1000 | Loss: 0.00001650
Iteration 131/1000 | Loss: 0.00001649
Iteration 132/1000 | Loss: 0.00001649
Iteration 133/1000 | Loss: 0.00001648
Iteration 134/1000 | Loss: 0.00001648
Iteration 135/1000 | Loss: 0.00001648
Iteration 136/1000 | Loss: 0.00001648
Iteration 137/1000 | Loss: 0.00001647
Iteration 138/1000 | Loss: 0.00001647
Iteration 139/1000 | Loss: 0.00001646
Iteration 140/1000 | Loss: 0.00001646
Iteration 141/1000 | Loss: 0.00001645
Iteration 142/1000 | Loss: 0.00001645
Iteration 143/1000 | Loss: 0.00001645
Iteration 144/1000 | Loss: 0.00001645
Iteration 145/1000 | Loss: 0.00001644
Iteration 146/1000 | Loss: 0.00001644
Iteration 147/1000 | Loss: 0.00001643
Iteration 148/1000 | Loss: 0.00001643
Iteration 149/1000 | Loss: 0.00001643
Iteration 150/1000 | Loss: 0.00001642
Iteration 151/1000 | Loss: 0.00001642
Iteration 152/1000 | Loss: 0.00001642
Iteration 153/1000 | Loss: 0.00001642
Iteration 154/1000 | Loss: 0.00001642
Iteration 155/1000 | Loss: 0.00001642
Iteration 156/1000 | Loss: 0.00001642
Iteration 157/1000 | Loss: 0.00001642
Iteration 158/1000 | Loss: 0.00001642
Iteration 159/1000 | Loss: 0.00001642
Iteration 160/1000 | Loss: 0.00001642
Iteration 161/1000 | Loss: 0.00001642
Iteration 162/1000 | Loss: 0.00001641
Iteration 163/1000 | Loss: 0.00001641
Iteration 164/1000 | Loss: 0.00001641
Iteration 165/1000 | Loss: 0.00001641
Iteration 166/1000 | Loss: 0.00001641
Iteration 167/1000 | Loss: 0.00001641
Iteration 168/1000 | Loss: 0.00001641
Iteration 169/1000 | Loss: 0.00001641
Iteration 170/1000 | Loss: 0.00001641
Iteration 171/1000 | Loss: 0.00001641
Iteration 172/1000 | Loss: 0.00001641
Iteration 173/1000 | Loss: 0.00001641
Iteration 174/1000 | Loss: 0.00001641
Iteration 175/1000 | Loss: 0.00001641
Iteration 176/1000 | Loss: 0.00001640
Iteration 177/1000 | Loss: 0.00001640
Iteration 178/1000 | Loss: 0.00001640
Iteration 179/1000 | Loss: 0.00001640
Iteration 180/1000 | Loss: 0.00001640
Iteration 181/1000 | Loss: 0.00001640
Iteration 182/1000 | Loss: 0.00001640
Iteration 183/1000 | Loss: 0.00001640
Iteration 184/1000 | Loss: 0.00001640
Iteration 185/1000 | Loss: 0.00001640
Iteration 186/1000 | Loss: 0.00001640
Iteration 187/1000 | Loss: 0.00001640
Iteration 188/1000 | Loss: 0.00001640
Iteration 189/1000 | Loss: 0.00001640
Iteration 190/1000 | Loss: 0.00001639
Iteration 191/1000 | Loss: 0.00001639
Iteration 192/1000 | Loss: 0.00001639
Iteration 193/1000 | Loss: 0.00001639
Iteration 194/1000 | Loss: 0.00001639
Iteration 195/1000 | Loss: 0.00001639
Iteration 196/1000 | Loss: 0.00001639
Iteration 197/1000 | Loss: 0.00001639
Iteration 198/1000 | Loss: 0.00001639
Iteration 199/1000 | Loss: 0.00001639
Iteration 200/1000 | Loss: 0.00001639
Iteration 201/1000 | Loss: 0.00001639
Iteration 202/1000 | Loss: 0.00001639
Iteration 203/1000 | Loss: 0.00001639
Iteration 204/1000 | Loss: 0.00001639
Iteration 205/1000 | Loss: 0.00001639
Iteration 206/1000 | Loss: 0.00001639
Iteration 207/1000 | Loss: 0.00001639
Iteration 208/1000 | Loss: 0.00001639
Iteration 209/1000 | Loss: 0.00001639
Iteration 210/1000 | Loss: 0.00001639
Iteration 211/1000 | Loss: 0.00001639
Iteration 212/1000 | Loss: 0.00001639
Iteration 213/1000 | Loss: 0.00001639
Iteration 214/1000 | Loss: 0.00001639
Iteration 215/1000 | Loss: 0.00001639
Iteration 216/1000 | Loss: 0.00001639
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 216. Stopping optimization.
Last 5 losses: [1.6386113202315755e-05, 1.6386113202315755e-05, 1.6386113202315755e-05, 1.6386113202315755e-05, 1.6386113202315755e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6386113202315755e-05

Optimization complete. Final v2v error: 3.3804807662963867 mm

Highest mean error: 5.279006004333496 mm for frame 215

Lowest mean error: 3.107104778289795 mm for frame 80

Saving results

Total time: 254.4737253189087
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00424078
Iteration 2/25 | Loss: 0.00101130
Iteration 3/25 | Loss: 0.00085824
Iteration 4/25 | Loss: 0.00083223
Iteration 5/25 | Loss: 0.00082316
Iteration 6/25 | Loss: 0.00082031
Iteration 7/25 | Loss: 0.00081952
Iteration 8/25 | Loss: 0.00081952
Iteration 9/25 | Loss: 0.00081952
Iteration 10/25 | Loss: 0.00081952
Iteration 11/25 | Loss: 0.00081952
Iteration 12/25 | Loss: 0.00081952
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008195226546376944, 0.0008195226546376944, 0.0008195226546376944, 0.0008195226546376944, 0.0008195226546376944]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008195226546376944

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51061702
Iteration 2/25 | Loss: 0.00060850
Iteration 3/25 | Loss: 0.00060850
Iteration 4/25 | Loss: 0.00060850
Iteration 5/25 | Loss: 0.00060850
Iteration 6/25 | Loss: 0.00060850
Iteration 7/25 | Loss: 0.00060850
Iteration 8/25 | Loss: 0.00060850
Iteration 9/25 | Loss: 0.00060850
Iteration 10/25 | Loss: 0.00060850
Iteration 11/25 | Loss: 0.00060850
Iteration 12/25 | Loss: 0.00060850
Iteration 13/25 | Loss: 0.00060850
Iteration 14/25 | Loss: 0.00060850
Iteration 15/25 | Loss: 0.00060850
Iteration 16/25 | Loss: 0.00060850
Iteration 17/25 | Loss: 0.00060850
Iteration 18/25 | Loss: 0.00060850
Iteration 19/25 | Loss: 0.00060850
Iteration 20/25 | Loss: 0.00060850
Iteration 21/25 | Loss: 0.00060850
Iteration 22/25 | Loss: 0.00060850
Iteration 23/25 | Loss: 0.00060850
Iteration 24/25 | Loss: 0.00060850
Iteration 25/25 | Loss: 0.00060850

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060850
Iteration 2/1000 | Loss: 0.00002748
Iteration 3/1000 | Loss: 0.00001858
Iteration 4/1000 | Loss: 0.00001605
Iteration 5/1000 | Loss: 0.00001500
Iteration 6/1000 | Loss: 0.00001408
Iteration 7/1000 | Loss: 0.00001375
Iteration 8/1000 | Loss: 0.00001341
Iteration 9/1000 | Loss: 0.00001322
Iteration 10/1000 | Loss: 0.00001314
Iteration 11/1000 | Loss: 0.00001303
Iteration 12/1000 | Loss: 0.00001299
Iteration 13/1000 | Loss: 0.00001291
Iteration 14/1000 | Loss: 0.00001291
Iteration 15/1000 | Loss: 0.00001289
Iteration 16/1000 | Loss: 0.00001288
Iteration 17/1000 | Loss: 0.00001286
Iteration 18/1000 | Loss: 0.00001282
Iteration 19/1000 | Loss: 0.00001281
Iteration 20/1000 | Loss: 0.00001281
Iteration 21/1000 | Loss: 0.00001272
Iteration 22/1000 | Loss: 0.00001272
Iteration 23/1000 | Loss: 0.00001269
Iteration 24/1000 | Loss: 0.00001268
Iteration 25/1000 | Loss: 0.00001268
Iteration 26/1000 | Loss: 0.00001268
Iteration 27/1000 | Loss: 0.00001267
Iteration 28/1000 | Loss: 0.00001267
Iteration 29/1000 | Loss: 0.00001266
Iteration 30/1000 | Loss: 0.00001266
Iteration 31/1000 | Loss: 0.00001266
Iteration 32/1000 | Loss: 0.00001265
Iteration 33/1000 | Loss: 0.00001265
Iteration 34/1000 | Loss: 0.00001264
Iteration 35/1000 | Loss: 0.00001263
Iteration 36/1000 | Loss: 0.00001263
Iteration 37/1000 | Loss: 0.00001261
Iteration 38/1000 | Loss: 0.00001261
Iteration 39/1000 | Loss: 0.00001260
Iteration 40/1000 | Loss: 0.00001260
Iteration 41/1000 | Loss: 0.00001259
Iteration 42/1000 | Loss: 0.00001259
Iteration 43/1000 | Loss: 0.00001258
Iteration 44/1000 | Loss: 0.00001258
Iteration 45/1000 | Loss: 0.00001258
Iteration 46/1000 | Loss: 0.00001257
Iteration 47/1000 | Loss: 0.00001257
Iteration 48/1000 | Loss: 0.00001257
Iteration 49/1000 | Loss: 0.00001257
Iteration 50/1000 | Loss: 0.00001257
Iteration 51/1000 | Loss: 0.00001257
Iteration 52/1000 | Loss: 0.00001256
Iteration 53/1000 | Loss: 0.00001256
Iteration 54/1000 | Loss: 0.00001256
Iteration 55/1000 | Loss: 0.00001255
Iteration 56/1000 | Loss: 0.00001255
Iteration 57/1000 | Loss: 0.00001255
Iteration 58/1000 | Loss: 0.00001255
Iteration 59/1000 | Loss: 0.00001254
Iteration 60/1000 | Loss: 0.00001254
Iteration 61/1000 | Loss: 0.00001254
Iteration 62/1000 | Loss: 0.00001254
Iteration 63/1000 | Loss: 0.00001254
Iteration 64/1000 | Loss: 0.00001254
Iteration 65/1000 | Loss: 0.00001253
Iteration 66/1000 | Loss: 0.00001253
Iteration 67/1000 | Loss: 0.00001253
Iteration 68/1000 | Loss: 0.00001253
Iteration 69/1000 | Loss: 0.00001253
Iteration 70/1000 | Loss: 0.00001253
Iteration 71/1000 | Loss: 0.00001253
Iteration 72/1000 | Loss: 0.00001253
Iteration 73/1000 | Loss: 0.00001253
Iteration 74/1000 | Loss: 0.00001253
Iteration 75/1000 | Loss: 0.00001252
Iteration 76/1000 | Loss: 0.00001252
Iteration 77/1000 | Loss: 0.00001252
Iteration 78/1000 | Loss: 0.00001252
Iteration 79/1000 | Loss: 0.00001252
Iteration 80/1000 | Loss: 0.00001252
Iteration 81/1000 | Loss: 0.00001252
Iteration 82/1000 | Loss: 0.00001252
Iteration 83/1000 | Loss: 0.00001252
Iteration 84/1000 | Loss: 0.00001252
Iteration 85/1000 | Loss: 0.00001252
Iteration 86/1000 | Loss: 0.00001251
Iteration 87/1000 | Loss: 0.00001251
Iteration 88/1000 | Loss: 0.00001251
Iteration 89/1000 | Loss: 0.00001251
Iteration 90/1000 | Loss: 0.00001251
Iteration 91/1000 | Loss: 0.00001251
Iteration 92/1000 | Loss: 0.00001251
Iteration 93/1000 | Loss: 0.00001251
Iteration 94/1000 | Loss: 0.00001251
Iteration 95/1000 | Loss: 0.00001251
Iteration 96/1000 | Loss: 0.00001251
Iteration 97/1000 | Loss: 0.00001251
Iteration 98/1000 | Loss: 0.00001250
Iteration 99/1000 | Loss: 0.00001250
Iteration 100/1000 | Loss: 0.00001250
Iteration 101/1000 | Loss: 0.00001250
Iteration 102/1000 | Loss: 0.00001250
Iteration 103/1000 | Loss: 0.00001250
Iteration 104/1000 | Loss: 0.00001250
Iteration 105/1000 | Loss: 0.00001249
Iteration 106/1000 | Loss: 0.00001249
Iteration 107/1000 | Loss: 0.00001249
Iteration 108/1000 | Loss: 0.00001249
Iteration 109/1000 | Loss: 0.00001249
Iteration 110/1000 | Loss: 0.00001249
Iteration 111/1000 | Loss: 0.00001248
Iteration 112/1000 | Loss: 0.00001248
Iteration 113/1000 | Loss: 0.00001248
Iteration 114/1000 | Loss: 0.00001248
Iteration 115/1000 | Loss: 0.00001248
Iteration 116/1000 | Loss: 0.00001247
Iteration 117/1000 | Loss: 0.00001247
Iteration 118/1000 | Loss: 0.00001247
Iteration 119/1000 | Loss: 0.00001247
Iteration 120/1000 | Loss: 0.00001247
Iteration 121/1000 | Loss: 0.00001247
Iteration 122/1000 | Loss: 0.00001247
Iteration 123/1000 | Loss: 0.00001247
Iteration 124/1000 | Loss: 0.00001246
Iteration 125/1000 | Loss: 0.00001246
Iteration 126/1000 | Loss: 0.00001246
Iteration 127/1000 | Loss: 0.00001246
Iteration 128/1000 | Loss: 0.00001245
Iteration 129/1000 | Loss: 0.00001245
Iteration 130/1000 | Loss: 0.00001245
Iteration 131/1000 | Loss: 0.00001245
Iteration 132/1000 | Loss: 0.00001244
Iteration 133/1000 | Loss: 0.00001244
Iteration 134/1000 | Loss: 0.00001244
Iteration 135/1000 | Loss: 0.00001244
Iteration 136/1000 | Loss: 0.00001244
Iteration 137/1000 | Loss: 0.00001244
Iteration 138/1000 | Loss: 0.00001243
Iteration 139/1000 | Loss: 0.00001243
Iteration 140/1000 | Loss: 0.00001243
Iteration 141/1000 | Loss: 0.00001243
Iteration 142/1000 | Loss: 0.00001243
Iteration 143/1000 | Loss: 0.00001243
Iteration 144/1000 | Loss: 0.00001242
Iteration 145/1000 | Loss: 0.00001242
Iteration 146/1000 | Loss: 0.00001242
Iteration 147/1000 | Loss: 0.00001242
Iteration 148/1000 | Loss: 0.00001242
Iteration 149/1000 | Loss: 0.00001242
Iteration 150/1000 | Loss: 0.00001241
Iteration 151/1000 | Loss: 0.00001241
Iteration 152/1000 | Loss: 0.00001241
Iteration 153/1000 | Loss: 0.00001241
Iteration 154/1000 | Loss: 0.00001240
Iteration 155/1000 | Loss: 0.00001240
Iteration 156/1000 | Loss: 0.00001240
Iteration 157/1000 | Loss: 0.00001240
Iteration 158/1000 | Loss: 0.00001240
Iteration 159/1000 | Loss: 0.00001239
Iteration 160/1000 | Loss: 0.00001239
Iteration 161/1000 | Loss: 0.00001239
Iteration 162/1000 | Loss: 0.00001238
Iteration 163/1000 | Loss: 0.00001238
Iteration 164/1000 | Loss: 0.00001238
Iteration 165/1000 | Loss: 0.00001238
Iteration 166/1000 | Loss: 0.00001238
Iteration 167/1000 | Loss: 0.00001237
Iteration 168/1000 | Loss: 0.00001237
Iteration 169/1000 | Loss: 0.00001237
Iteration 170/1000 | Loss: 0.00001237
Iteration 171/1000 | Loss: 0.00001237
Iteration 172/1000 | Loss: 0.00001237
Iteration 173/1000 | Loss: 0.00001237
Iteration 174/1000 | Loss: 0.00001237
Iteration 175/1000 | Loss: 0.00001237
Iteration 176/1000 | Loss: 0.00001236
Iteration 177/1000 | Loss: 0.00001236
Iteration 178/1000 | Loss: 0.00001236
Iteration 179/1000 | Loss: 0.00001236
Iteration 180/1000 | Loss: 0.00001236
Iteration 181/1000 | Loss: 0.00001236
Iteration 182/1000 | Loss: 0.00001236
Iteration 183/1000 | Loss: 0.00001235
Iteration 184/1000 | Loss: 0.00001235
Iteration 185/1000 | Loss: 0.00001235
Iteration 186/1000 | Loss: 0.00001234
Iteration 187/1000 | Loss: 0.00001234
Iteration 188/1000 | Loss: 0.00001234
Iteration 189/1000 | Loss: 0.00001234
Iteration 190/1000 | Loss: 0.00001234
Iteration 191/1000 | Loss: 0.00001234
Iteration 192/1000 | Loss: 0.00001234
Iteration 193/1000 | Loss: 0.00001234
Iteration 194/1000 | Loss: 0.00001233
Iteration 195/1000 | Loss: 0.00001233
Iteration 196/1000 | Loss: 0.00001233
Iteration 197/1000 | Loss: 0.00001233
Iteration 198/1000 | Loss: 0.00001233
Iteration 199/1000 | Loss: 0.00001233
Iteration 200/1000 | Loss: 0.00001233
Iteration 201/1000 | Loss: 0.00001233
Iteration 202/1000 | Loss: 0.00001233
Iteration 203/1000 | Loss: 0.00001233
Iteration 204/1000 | Loss: 0.00001233
Iteration 205/1000 | Loss: 0.00001233
Iteration 206/1000 | Loss: 0.00001233
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 206. Stopping optimization.
Last 5 losses: [1.23298204925959e-05, 1.23298204925959e-05, 1.23298204925959e-05, 1.23298204925959e-05, 1.23298204925959e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.23298204925959e-05

Optimization complete. Final v2v error: 3.002004623413086 mm

Highest mean error: 3.876552104949951 mm for frame 64

Lowest mean error: 2.7335400581359863 mm for frame 45

Saving results

Total time: 48.50049614906311
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00597431
Iteration 2/25 | Loss: 0.00100723
Iteration 3/25 | Loss: 0.00089010
Iteration 4/25 | Loss: 0.00087846
Iteration 5/25 | Loss: 0.00087551
Iteration 6/25 | Loss: 0.00087506
Iteration 7/25 | Loss: 0.00087506
Iteration 8/25 | Loss: 0.00087506
Iteration 9/25 | Loss: 0.00087506
Iteration 10/25 | Loss: 0.00087506
Iteration 11/25 | Loss: 0.00087506
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008750581764616072, 0.0008750581764616072, 0.0008750581764616072, 0.0008750581764616072, 0.0008750581764616072]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008750581764616072

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.86656427
Iteration 2/25 | Loss: 0.00063107
Iteration 3/25 | Loss: 0.00063103
Iteration 4/25 | Loss: 0.00063103
Iteration 5/25 | Loss: 0.00063103
Iteration 6/25 | Loss: 0.00063103
Iteration 7/25 | Loss: 0.00063103
Iteration 8/25 | Loss: 0.00063103
Iteration 9/25 | Loss: 0.00063103
Iteration 10/25 | Loss: 0.00063103
Iteration 11/25 | Loss: 0.00063103
Iteration 12/25 | Loss: 0.00063103
Iteration 13/25 | Loss: 0.00063103
Iteration 14/25 | Loss: 0.00063103
Iteration 15/25 | Loss: 0.00063103
Iteration 16/25 | Loss: 0.00063103
Iteration 17/25 | Loss: 0.00063103
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006310254102572799, 0.0006310254102572799, 0.0006310254102572799, 0.0006310254102572799, 0.0006310254102572799]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006310254102572799

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00063103
Iteration 2/1000 | Loss: 0.00002334
Iteration 3/1000 | Loss: 0.00001744
Iteration 4/1000 | Loss: 0.00001615
Iteration 5/1000 | Loss: 0.00001530
Iteration 6/1000 | Loss: 0.00001501
Iteration 7/1000 | Loss: 0.00001480
Iteration 8/1000 | Loss: 0.00001469
Iteration 9/1000 | Loss: 0.00001469
Iteration 10/1000 | Loss: 0.00001468
Iteration 11/1000 | Loss: 0.00001452
Iteration 12/1000 | Loss: 0.00001444
Iteration 13/1000 | Loss: 0.00001433
Iteration 14/1000 | Loss: 0.00001424
Iteration 15/1000 | Loss: 0.00001419
Iteration 16/1000 | Loss: 0.00001419
Iteration 17/1000 | Loss: 0.00001418
Iteration 18/1000 | Loss: 0.00001417
Iteration 19/1000 | Loss: 0.00001417
Iteration 20/1000 | Loss: 0.00001417
Iteration 21/1000 | Loss: 0.00001416
Iteration 22/1000 | Loss: 0.00001415
Iteration 23/1000 | Loss: 0.00001415
Iteration 24/1000 | Loss: 0.00001415
Iteration 25/1000 | Loss: 0.00001414
Iteration 26/1000 | Loss: 0.00001413
Iteration 27/1000 | Loss: 0.00001412
Iteration 28/1000 | Loss: 0.00001412
Iteration 29/1000 | Loss: 0.00001412
Iteration 30/1000 | Loss: 0.00001412
Iteration 31/1000 | Loss: 0.00001412
Iteration 32/1000 | Loss: 0.00001411
Iteration 33/1000 | Loss: 0.00001411
Iteration 34/1000 | Loss: 0.00001411
Iteration 35/1000 | Loss: 0.00001410
Iteration 36/1000 | Loss: 0.00001410
Iteration 37/1000 | Loss: 0.00001410
Iteration 38/1000 | Loss: 0.00001410
Iteration 39/1000 | Loss: 0.00001410
Iteration 40/1000 | Loss: 0.00001410
Iteration 41/1000 | Loss: 0.00001410
Iteration 42/1000 | Loss: 0.00001410
Iteration 43/1000 | Loss: 0.00001410
Iteration 44/1000 | Loss: 0.00001409
Iteration 45/1000 | Loss: 0.00001409
Iteration 46/1000 | Loss: 0.00001408
Iteration 47/1000 | Loss: 0.00001408
Iteration 48/1000 | Loss: 0.00001408
Iteration 49/1000 | Loss: 0.00001408
Iteration 50/1000 | Loss: 0.00001407
Iteration 51/1000 | Loss: 0.00001407
Iteration 52/1000 | Loss: 0.00001406
Iteration 53/1000 | Loss: 0.00001405
Iteration 54/1000 | Loss: 0.00001405
Iteration 55/1000 | Loss: 0.00001404
Iteration 56/1000 | Loss: 0.00001404
Iteration 57/1000 | Loss: 0.00001403
Iteration 58/1000 | Loss: 0.00001403
Iteration 59/1000 | Loss: 0.00001402
Iteration 60/1000 | Loss: 0.00001402
Iteration 61/1000 | Loss: 0.00001402
Iteration 62/1000 | Loss: 0.00001402
Iteration 63/1000 | Loss: 0.00001401
Iteration 64/1000 | Loss: 0.00001400
Iteration 65/1000 | Loss: 0.00001399
Iteration 66/1000 | Loss: 0.00001399
Iteration 67/1000 | Loss: 0.00001399
Iteration 68/1000 | Loss: 0.00001398
Iteration 69/1000 | Loss: 0.00001398
Iteration 70/1000 | Loss: 0.00001397
Iteration 71/1000 | Loss: 0.00001396
Iteration 72/1000 | Loss: 0.00001395
Iteration 73/1000 | Loss: 0.00001395
Iteration 74/1000 | Loss: 0.00001395
Iteration 75/1000 | Loss: 0.00001394
Iteration 76/1000 | Loss: 0.00001394
Iteration 77/1000 | Loss: 0.00001394
Iteration 78/1000 | Loss: 0.00001393
Iteration 79/1000 | Loss: 0.00001393
Iteration 80/1000 | Loss: 0.00001393
Iteration 81/1000 | Loss: 0.00001391
Iteration 82/1000 | Loss: 0.00001391
Iteration 83/1000 | Loss: 0.00001391
Iteration 84/1000 | Loss: 0.00001391
Iteration 85/1000 | Loss: 0.00001391
Iteration 86/1000 | Loss: 0.00001391
Iteration 87/1000 | Loss: 0.00001391
Iteration 88/1000 | Loss: 0.00001391
Iteration 89/1000 | Loss: 0.00001391
Iteration 90/1000 | Loss: 0.00001390
Iteration 91/1000 | Loss: 0.00001390
Iteration 92/1000 | Loss: 0.00001390
Iteration 93/1000 | Loss: 0.00001389
Iteration 94/1000 | Loss: 0.00001389
Iteration 95/1000 | Loss: 0.00001389
Iteration 96/1000 | Loss: 0.00001389
Iteration 97/1000 | Loss: 0.00001389
Iteration 98/1000 | Loss: 0.00001389
Iteration 99/1000 | Loss: 0.00001388
Iteration 100/1000 | Loss: 0.00001388
Iteration 101/1000 | Loss: 0.00001388
Iteration 102/1000 | Loss: 0.00001388
Iteration 103/1000 | Loss: 0.00001388
Iteration 104/1000 | Loss: 0.00001388
Iteration 105/1000 | Loss: 0.00001388
Iteration 106/1000 | Loss: 0.00001388
Iteration 107/1000 | Loss: 0.00001388
Iteration 108/1000 | Loss: 0.00001388
Iteration 109/1000 | Loss: 0.00001388
Iteration 110/1000 | Loss: 0.00001388
Iteration 111/1000 | Loss: 0.00001388
Iteration 112/1000 | Loss: 0.00001387
Iteration 113/1000 | Loss: 0.00001387
Iteration 114/1000 | Loss: 0.00001387
Iteration 115/1000 | Loss: 0.00001387
Iteration 116/1000 | Loss: 0.00001387
Iteration 117/1000 | Loss: 0.00001387
Iteration 118/1000 | Loss: 0.00001387
Iteration 119/1000 | Loss: 0.00001387
Iteration 120/1000 | Loss: 0.00001387
Iteration 121/1000 | Loss: 0.00001387
Iteration 122/1000 | Loss: 0.00001387
Iteration 123/1000 | Loss: 0.00001387
Iteration 124/1000 | Loss: 0.00001387
Iteration 125/1000 | Loss: 0.00001387
Iteration 126/1000 | Loss: 0.00001387
Iteration 127/1000 | Loss: 0.00001387
Iteration 128/1000 | Loss: 0.00001386
Iteration 129/1000 | Loss: 0.00001386
Iteration 130/1000 | Loss: 0.00001386
Iteration 131/1000 | Loss: 0.00001386
Iteration 132/1000 | Loss: 0.00001386
Iteration 133/1000 | Loss: 0.00001386
Iteration 134/1000 | Loss: 0.00001386
Iteration 135/1000 | Loss: 0.00001386
Iteration 136/1000 | Loss: 0.00001386
Iteration 137/1000 | Loss: 0.00001386
Iteration 138/1000 | Loss: 0.00001386
Iteration 139/1000 | Loss: 0.00001386
Iteration 140/1000 | Loss: 0.00001386
Iteration 141/1000 | Loss: 0.00001386
Iteration 142/1000 | Loss: 0.00001386
Iteration 143/1000 | Loss: 0.00001386
Iteration 144/1000 | Loss: 0.00001386
Iteration 145/1000 | Loss: 0.00001385
Iteration 146/1000 | Loss: 0.00001385
Iteration 147/1000 | Loss: 0.00001385
Iteration 148/1000 | Loss: 0.00001385
Iteration 149/1000 | Loss: 0.00001385
Iteration 150/1000 | Loss: 0.00001385
Iteration 151/1000 | Loss: 0.00001385
Iteration 152/1000 | Loss: 0.00001385
Iteration 153/1000 | Loss: 0.00001385
Iteration 154/1000 | Loss: 0.00001385
Iteration 155/1000 | Loss: 0.00001385
Iteration 156/1000 | Loss: 0.00001385
Iteration 157/1000 | Loss: 0.00001385
Iteration 158/1000 | Loss: 0.00001385
Iteration 159/1000 | Loss: 0.00001385
Iteration 160/1000 | Loss: 0.00001385
Iteration 161/1000 | Loss: 0.00001385
Iteration 162/1000 | Loss: 0.00001385
Iteration 163/1000 | Loss: 0.00001385
Iteration 164/1000 | Loss: 0.00001385
Iteration 165/1000 | Loss: 0.00001385
Iteration 166/1000 | Loss: 0.00001385
Iteration 167/1000 | Loss: 0.00001385
Iteration 168/1000 | Loss: 0.00001385
Iteration 169/1000 | Loss: 0.00001385
Iteration 170/1000 | Loss: 0.00001385
Iteration 171/1000 | Loss: 0.00001385
Iteration 172/1000 | Loss: 0.00001385
Iteration 173/1000 | Loss: 0.00001385
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 173. Stopping optimization.
Last 5 losses: [1.3846919500792865e-05, 1.3846919500792865e-05, 1.3846919500792865e-05, 1.3846919500792865e-05, 1.3846919500792865e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3846919500792865e-05

Optimization complete. Final v2v error: 3.154264211654663 mm

Highest mean error: 3.5390357971191406 mm for frame 119

Lowest mean error: 2.8833494186401367 mm for frame 220

Saving results

Total time: 39.36241054534912
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1031/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1031.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1031
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00838126
Iteration 2/25 | Loss: 0.00154185
Iteration 3/25 | Loss: 0.00101511
Iteration 4/25 | Loss: 0.00091781
Iteration 5/25 | Loss: 0.00091169
Iteration 6/25 | Loss: 0.00091146
Iteration 7/25 | Loss: 0.00091146
Iteration 8/25 | Loss: 0.00091146
Iteration 9/25 | Loss: 0.00091146
Iteration 10/25 | Loss: 0.00091146
Iteration 11/25 | Loss: 0.00091146
Iteration 12/25 | Loss: 0.00091146
Iteration 13/25 | Loss: 0.00091146
Iteration 14/25 | Loss: 0.00091146
Iteration 15/25 | Loss: 0.00091146
Iteration 16/25 | Loss: 0.00091146
Iteration 17/25 | Loss: 0.00091146
Iteration 18/25 | Loss: 0.00091146
Iteration 19/25 | Loss: 0.00091146
Iteration 20/25 | Loss: 0.00091146
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0009114611893892288, 0.0009114611893892288, 0.0009114611893892288, 0.0009114611893892288, 0.0009114611893892288]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009114611893892288

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50816846
Iteration 2/25 | Loss: 0.00054146
Iteration 3/25 | Loss: 0.00054146
Iteration 4/25 | Loss: 0.00054146
Iteration 5/25 | Loss: 0.00054146
Iteration 6/25 | Loss: 0.00054146
Iteration 7/25 | Loss: 0.00054146
Iteration 8/25 | Loss: 0.00054146
Iteration 9/25 | Loss: 0.00054146
Iteration 10/25 | Loss: 0.00054146
Iteration 11/25 | Loss: 0.00054146
Iteration 12/25 | Loss: 0.00054146
Iteration 13/25 | Loss: 0.00054146
Iteration 14/25 | Loss: 0.00054146
Iteration 15/25 | Loss: 0.00054146
Iteration 16/25 | Loss: 0.00054146
Iteration 17/25 | Loss: 0.00054146
Iteration 18/25 | Loss: 0.00054146
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005414608167484403, 0.0005414608167484403, 0.0005414608167484403, 0.0005414608167484403, 0.0005414608167484403]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005414608167484403

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054146
Iteration 2/1000 | Loss: 0.00003348
Iteration 3/1000 | Loss: 0.00002524
Iteration 4/1000 | Loss: 0.00002329
Iteration 5/1000 | Loss: 0.00002217
Iteration 6/1000 | Loss: 0.00002135
Iteration 7/1000 | Loss: 0.00002073
Iteration 8/1000 | Loss: 0.00002044
Iteration 9/1000 | Loss: 0.00002018
Iteration 10/1000 | Loss: 0.00001997
Iteration 11/1000 | Loss: 0.00001985
Iteration 12/1000 | Loss: 0.00001980
Iteration 13/1000 | Loss: 0.00001977
Iteration 14/1000 | Loss: 0.00001970
Iteration 15/1000 | Loss: 0.00001970
Iteration 16/1000 | Loss: 0.00001970
Iteration 17/1000 | Loss: 0.00001970
Iteration 18/1000 | Loss: 0.00001969
Iteration 19/1000 | Loss: 0.00001969
Iteration 20/1000 | Loss: 0.00001969
Iteration 21/1000 | Loss: 0.00001968
Iteration 22/1000 | Loss: 0.00001968
Iteration 23/1000 | Loss: 0.00001964
Iteration 24/1000 | Loss: 0.00001963
Iteration 25/1000 | Loss: 0.00001963
Iteration 26/1000 | Loss: 0.00001962
Iteration 27/1000 | Loss: 0.00001962
Iteration 28/1000 | Loss: 0.00001961
Iteration 29/1000 | Loss: 0.00001961
Iteration 30/1000 | Loss: 0.00001961
Iteration 31/1000 | Loss: 0.00001961
Iteration 32/1000 | Loss: 0.00001961
Iteration 33/1000 | Loss: 0.00001961
Iteration 34/1000 | Loss: 0.00001961
Iteration 35/1000 | Loss: 0.00001961
Iteration 36/1000 | Loss: 0.00001961
Iteration 37/1000 | Loss: 0.00001961
Iteration 38/1000 | Loss: 0.00001960
Iteration 39/1000 | Loss: 0.00001960
Iteration 40/1000 | Loss: 0.00001959
Iteration 41/1000 | Loss: 0.00001957
Iteration 42/1000 | Loss: 0.00001957
Iteration 43/1000 | Loss: 0.00001957
Iteration 44/1000 | Loss: 0.00001957
Iteration 45/1000 | Loss: 0.00001957
Iteration 46/1000 | Loss: 0.00001957
Iteration 47/1000 | Loss: 0.00001957
Iteration 48/1000 | Loss: 0.00001957
Iteration 49/1000 | Loss: 0.00001957
Iteration 50/1000 | Loss: 0.00001957
Iteration 51/1000 | Loss: 0.00001957
Iteration 52/1000 | Loss: 0.00001957
Iteration 53/1000 | Loss: 0.00001957
Iteration 54/1000 | Loss: 0.00001957
Iteration 55/1000 | Loss: 0.00001957
Iteration 56/1000 | Loss: 0.00001957
Iteration 57/1000 | Loss: 0.00001957
Iteration 58/1000 | Loss: 0.00001955
Iteration 59/1000 | Loss: 0.00001955
Iteration 60/1000 | Loss: 0.00001955
Iteration 61/1000 | Loss: 0.00001954
Iteration 62/1000 | Loss: 0.00001954
Iteration 63/1000 | Loss: 0.00001954
Iteration 64/1000 | Loss: 0.00001954
Iteration 65/1000 | Loss: 0.00001954
Iteration 66/1000 | Loss: 0.00001954
Iteration 67/1000 | Loss: 0.00001954
Iteration 68/1000 | Loss: 0.00001954
Iteration 69/1000 | Loss: 0.00001954
Iteration 70/1000 | Loss: 0.00001953
Iteration 71/1000 | Loss: 0.00001953
Iteration 72/1000 | Loss: 0.00001953
Iteration 73/1000 | Loss: 0.00001953
Iteration 74/1000 | Loss: 0.00001953
Iteration 75/1000 | Loss: 0.00001953
Iteration 76/1000 | Loss: 0.00001953
Iteration 77/1000 | Loss: 0.00001953
Iteration 78/1000 | Loss: 0.00001953
Iteration 79/1000 | Loss: 0.00001953
Iteration 80/1000 | Loss: 0.00001953
Iteration 81/1000 | Loss: 0.00001953
Iteration 82/1000 | Loss: 0.00001953
Iteration 83/1000 | Loss: 0.00001953
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 83. Stopping optimization.
Last 5 losses: [1.9532144506229088e-05, 1.9532144506229088e-05, 1.9532144506229088e-05, 1.9532144506229088e-05, 1.9532144506229088e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9532144506229088e-05

Optimization complete. Final v2v error: 3.639970541000366 mm

Highest mean error: 3.7025845050811768 mm for frame 170

Lowest mean error: 3.3575327396392822 mm for frame 2

Saving results

Total time: 34.604411602020264
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1039
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01031923
Iteration 2/25 | Loss: 0.00360177
Iteration 3/25 | Loss: 0.00205125
Iteration 4/25 | Loss: 0.00182460
Iteration 5/25 | Loss: 0.00166346
Iteration 6/25 | Loss: 0.00168842
Iteration 7/25 | Loss: 0.00145425
Iteration 8/25 | Loss: 0.00120598
Iteration 9/25 | Loss: 0.00100219
Iteration 10/25 | Loss: 0.00091050
Iteration 11/25 | Loss: 0.00086784
Iteration 12/25 | Loss: 0.00085356
Iteration 13/25 | Loss: 0.00083663
Iteration 14/25 | Loss: 0.00083644
Iteration 15/25 | Loss: 0.00082932
Iteration 16/25 | Loss: 0.00083058
Iteration 17/25 | Loss: 0.00083047
Iteration 18/25 | Loss: 0.00082877
Iteration 19/25 | Loss: 0.00082836
Iteration 20/25 | Loss: 0.00082402
Iteration 21/25 | Loss: 0.00082955
Iteration 22/25 | Loss: 0.00082896
Iteration 23/25 | Loss: 0.00082880
Iteration 24/25 | Loss: 0.00082799
Iteration 25/25 | Loss: 0.00083110

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49430192
Iteration 2/25 | Loss: 0.00073722
Iteration 3/25 | Loss: 0.00073127
Iteration 4/25 | Loss: 0.00073127
Iteration 5/25 | Loss: 0.00073127
Iteration 6/25 | Loss: 0.00073127
Iteration 7/25 | Loss: 0.00073127
Iteration 8/25 | Loss: 0.00073127
Iteration 9/25 | Loss: 0.00073127
Iteration 10/25 | Loss: 0.00073127
Iteration 11/25 | Loss: 0.00073127
Iteration 12/25 | Loss: 0.00073127
Iteration 13/25 | Loss: 0.00073127
Iteration 14/25 | Loss: 0.00073127
Iteration 15/25 | Loss: 0.00073127
Iteration 16/25 | Loss: 0.00073127
Iteration 17/25 | Loss: 0.00073127
Iteration 18/25 | Loss: 0.00073127
Iteration 19/25 | Loss: 0.00073127
Iteration 20/25 | Loss: 0.00073127
Iteration 21/25 | Loss: 0.00073127
Iteration 22/25 | Loss: 0.00073127
Iteration 23/25 | Loss: 0.00073127
Iteration 24/25 | Loss: 0.00073127
Iteration 25/25 | Loss: 0.00073127

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073127
Iteration 2/1000 | Loss: 0.00028589
Iteration 3/1000 | Loss: 0.00022448
Iteration 4/1000 | Loss: 0.00024062
Iteration 5/1000 | Loss: 0.00024849
Iteration 6/1000 | Loss: 0.00020393
Iteration 7/1000 | Loss: 0.00013244
Iteration 8/1000 | Loss: 0.00014428
Iteration 9/1000 | Loss: 0.00017780
Iteration 10/1000 | Loss: 0.00021898
Iteration 11/1000 | Loss: 0.00003956
Iteration 12/1000 | Loss: 0.00002950
Iteration 13/1000 | Loss: 0.00002400
Iteration 14/1000 | Loss: 0.00005915
Iteration 15/1000 | Loss: 0.00002194
Iteration 16/1000 | Loss: 0.00015621
Iteration 17/1000 | Loss: 0.00001898
Iteration 18/1000 | Loss: 0.00001761
Iteration 19/1000 | Loss: 0.00001621
Iteration 20/1000 | Loss: 0.00001493
Iteration 21/1000 | Loss: 0.00001432
Iteration 22/1000 | Loss: 0.00001378
Iteration 23/1000 | Loss: 0.00001337
Iteration 24/1000 | Loss: 0.00001323
Iteration 25/1000 | Loss: 0.00001302
Iteration 26/1000 | Loss: 0.00001301
Iteration 27/1000 | Loss: 0.00001300
Iteration 28/1000 | Loss: 0.00001298
Iteration 29/1000 | Loss: 0.00001297
Iteration 30/1000 | Loss: 0.00001296
Iteration 31/1000 | Loss: 0.00001292
Iteration 32/1000 | Loss: 0.00001291
Iteration 33/1000 | Loss: 0.00001289
Iteration 34/1000 | Loss: 0.00001288
Iteration 35/1000 | Loss: 0.00001288
Iteration 36/1000 | Loss: 0.00001288
Iteration 37/1000 | Loss: 0.00001287
Iteration 38/1000 | Loss: 0.00001286
Iteration 39/1000 | Loss: 0.00001286
Iteration 40/1000 | Loss: 0.00001286
Iteration 41/1000 | Loss: 0.00001285
Iteration 42/1000 | Loss: 0.00001285
Iteration 43/1000 | Loss: 0.00001284
Iteration 44/1000 | Loss: 0.00001284
Iteration 45/1000 | Loss: 0.00001282
Iteration 46/1000 | Loss: 0.00001282
Iteration 47/1000 | Loss: 0.00001282
Iteration 48/1000 | Loss: 0.00001282
Iteration 49/1000 | Loss: 0.00001282
Iteration 50/1000 | Loss: 0.00001282
Iteration 51/1000 | Loss: 0.00001282
Iteration 52/1000 | Loss: 0.00001282
Iteration 53/1000 | Loss: 0.00001282
Iteration 54/1000 | Loss: 0.00001282
Iteration 55/1000 | Loss: 0.00001282
Iteration 56/1000 | Loss: 0.00001282
Iteration 57/1000 | Loss: 0.00001282
Iteration 58/1000 | Loss: 0.00001282
Iteration 59/1000 | Loss: 0.00001282
Iteration 60/1000 | Loss: 0.00001282
Iteration 61/1000 | Loss: 0.00001282
Iteration 62/1000 | Loss: 0.00001282
Iteration 63/1000 | Loss: 0.00001282
Iteration 64/1000 | Loss: 0.00001282
Iteration 65/1000 | Loss: 0.00001282
Iteration 66/1000 | Loss: 0.00001282
Iteration 67/1000 | Loss: 0.00001282
Iteration 68/1000 | Loss: 0.00001282
Iteration 69/1000 | Loss: 0.00001282
Iteration 70/1000 | Loss: 0.00001282
Iteration 71/1000 | Loss: 0.00001282
Iteration 72/1000 | Loss: 0.00001282
Iteration 73/1000 | Loss: 0.00001282
Iteration 74/1000 | Loss: 0.00001282
Iteration 75/1000 | Loss: 0.00001281
Iteration 76/1000 | Loss: 0.00001281
Iteration 77/1000 | Loss: 0.00001281
Iteration 78/1000 | Loss: 0.00001281
Iteration 79/1000 | Loss: 0.00001281
Iteration 80/1000 | Loss: 0.00001281
Iteration 81/1000 | Loss: 0.00001281
Iteration 82/1000 | Loss: 0.00001281
Iteration 83/1000 | Loss: 0.00001281
Iteration 84/1000 | Loss: 0.00001281
Iteration 85/1000 | Loss: 0.00001281
Iteration 86/1000 | Loss: 0.00001281
Iteration 87/1000 | Loss: 0.00001281
Iteration 88/1000 | Loss: 0.00001281
Iteration 89/1000 | Loss: 0.00001281
Iteration 90/1000 | Loss: 0.00001281
Iteration 91/1000 | Loss: 0.00001281
Iteration 92/1000 | Loss: 0.00001281
Iteration 93/1000 | Loss: 0.00001281
Iteration 94/1000 | Loss: 0.00001281
Iteration 95/1000 | Loss: 0.00001281
Iteration 96/1000 | Loss: 0.00001281
Iteration 97/1000 | Loss: 0.00001281
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 97. Stopping optimization.
Last 5 losses: [1.2814871297450736e-05, 1.2814871297450736e-05, 1.2814871297450736e-05, 1.2814871297450736e-05, 1.2814871297450736e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2814871297450736e-05

Optimization complete. Final v2v error: 3.025696277618408 mm

Highest mean error: 4.313969612121582 mm for frame 83

Lowest mean error: 2.7010531425476074 mm for frame 98

Saving results

Total time: 84.19992685317993
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1092/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1092.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1092
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00605925
Iteration 2/25 | Loss: 0.00125006
Iteration 3/25 | Loss: 0.00094929
Iteration 4/25 | Loss: 0.00087934
Iteration 5/25 | Loss: 0.00086341
Iteration 6/25 | Loss: 0.00085805
Iteration 7/25 | Loss: 0.00086116
Iteration 8/25 | Loss: 0.00085938
Iteration 9/25 | Loss: 0.00085513
Iteration 10/25 | Loss: 0.00085350
Iteration 11/25 | Loss: 0.00085110
Iteration 12/25 | Loss: 0.00084994
Iteration 13/25 | Loss: 0.00084920
Iteration 14/25 | Loss: 0.00084887
Iteration 15/25 | Loss: 0.00084875
Iteration 16/25 | Loss: 0.00084875
Iteration 17/25 | Loss: 0.00084875
Iteration 18/25 | Loss: 0.00084875
Iteration 19/25 | Loss: 0.00084875
Iteration 20/25 | Loss: 0.00084875
Iteration 21/25 | Loss: 0.00084875
Iteration 22/25 | Loss: 0.00084875
Iteration 23/25 | Loss: 0.00084875
Iteration 24/25 | Loss: 0.00084875
Iteration 25/25 | Loss: 0.00084875

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 7.75283051
Iteration 2/25 | Loss: 0.00061746
Iteration 3/25 | Loss: 0.00061746
Iteration 4/25 | Loss: 0.00061746
Iteration 5/25 | Loss: 0.00061746
Iteration 6/25 | Loss: 0.00061746
Iteration 7/25 | Loss: 0.00061746
Iteration 8/25 | Loss: 0.00061746
Iteration 9/25 | Loss: 0.00061746
Iteration 10/25 | Loss: 0.00061746
Iteration 11/25 | Loss: 0.00061746
Iteration 12/25 | Loss: 0.00061746
Iteration 13/25 | Loss: 0.00061746
Iteration 14/25 | Loss: 0.00061746
Iteration 15/25 | Loss: 0.00061746
Iteration 16/25 | Loss: 0.00061746
Iteration 17/25 | Loss: 0.00061746
Iteration 18/25 | Loss: 0.00061746
Iteration 19/25 | Loss: 0.00061746
Iteration 20/25 | Loss: 0.00061746
Iteration 21/25 | Loss: 0.00061746
Iteration 22/25 | Loss: 0.00061746
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0006174591253511608, 0.0006174591253511608, 0.0006174591253511608, 0.0006174591253511608, 0.0006174591253511608]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006174591253511608

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061746
Iteration 2/1000 | Loss: 0.00002967
Iteration 3/1000 | Loss: 0.00001922
Iteration 4/1000 | Loss: 0.00001794
Iteration 5/1000 | Loss: 0.00001690
Iteration 6/1000 | Loss: 0.00001612
Iteration 7/1000 | Loss: 0.00001568
Iteration 8/1000 | Loss: 0.00001542
Iteration 9/1000 | Loss: 0.00001521
Iteration 10/1000 | Loss: 0.00001504
Iteration 11/1000 | Loss: 0.00001503
Iteration 12/1000 | Loss: 0.00001494
Iteration 13/1000 | Loss: 0.00001492
Iteration 14/1000 | Loss: 0.00001490
Iteration 15/1000 | Loss: 0.00001489
Iteration 16/1000 | Loss: 0.00001487
Iteration 17/1000 | Loss: 0.00001481
Iteration 18/1000 | Loss: 0.00001480
Iteration 19/1000 | Loss: 0.00001479
Iteration 20/1000 | Loss: 0.00001479
Iteration 21/1000 | Loss: 0.00001477
Iteration 22/1000 | Loss: 0.00001477
Iteration 23/1000 | Loss: 0.00001476
Iteration 24/1000 | Loss: 0.00001476
Iteration 25/1000 | Loss: 0.00001475
Iteration 26/1000 | Loss: 0.00001474
Iteration 27/1000 | Loss: 0.00001473
Iteration 28/1000 | Loss: 0.00001472
Iteration 29/1000 | Loss: 0.00001471
Iteration 30/1000 | Loss: 0.00001468
Iteration 31/1000 | Loss: 0.00001468
Iteration 32/1000 | Loss: 0.00001468
Iteration 33/1000 | Loss: 0.00001467
Iteration 34/1000 | Loss: 0.00001467
Iteration 35/1000 | Loss: 0.00001467
Iteration 36/1000 | Loss: 0.00001466
Iteration 37/1000 | Loss: 0.00001465
Iteration 38/1000 | Loss: 0.00001465
Iteration 39/1000 | Loss: 0.00001465
Iteration 40/1000 | Loss: 0.00001465
Iteration 41/1000 | Loss: 0.00001465
Iteration 42/1000 | Loss: 0.00001465
Iteration 43/1000 | Loss: 0.00001464
Iteration 44/1000 | Loss: 0.00001464
Iteration 45/1000 | Loss: 0.00001464
Iteration 46/1000 | Loss: 0.00001464
Iteration 47/1000 | Loss: 0.00001464
Iteration 48/1000 | Loss: 0.00001464
Iteration 49/1000 | Loss: 0.00001464
Iteration 50/1000 | Loss: 0.00001463
Iteration 51/1000 | Loss: 0.00001463
Iteration 52/1000 | Loss: 0.00001463
Iteration 53/1000 | Loss: 0.00001462
Iteration 54/1000 | Loss: 0.00001461
Iteration 55/1000 | Loss: 0.00001461
Iteration 56/1000 | Loss: 0.00001461
Iteration 57/1000 | Loss: 0.00001461
Iteration 58/1000 | Loss: 0.00001461
Iteration 59/1000 | Loss: 0.00001461
Iteration 60/1000 | Loss: 0.00001461
Iteration 61/1000 | Loss: 0.00001461
Iteration 62/1000 | Loss: 0.00001461
Iteration 63/1000 | Loss: 0.00001461
Iteration 64/1000 | Loss: 0.00001460
Iteration 65/1000 | Loss: 0.00001460
Iteration 66/1000 | Loss: 0.00001460
Iteration 67/1000 | Loss: 0.00001459
Iteration 68/1000 | Loss: 0.00001459
Iteration 69/1000 | Loss: 0.00001458
Iteration 70/1000 | Loss: 0.00001457
Iteration 71/1000 | Loss: 0.00001457
Iteration 72/1000 | Loss: 0.00001457
Iteration 73/1000 | Loss: 0.00001456
Iteration 74/1000 | Loss: 0.00001456
Iteration 75/1000 | Loss: 0.00001456
Iteration 76/1000 | Loss: 0.00001455
Iteration 77/1000 | Loss: 0.00001454
Iteration 78/1000 | Loss: 0.00001454
Iteration 79/1000 | Loss: 0.00001454
Iteration 80/1000 | Loss: 0.00001453
Iteration 81/1000 | Loss: 0.00001453
Iteration 82/1000 | Loss: 0.00001453
Iteration 83/1000 | Loss: 0.00001453
Iteration 84/1000 | Loss: 0.00001451
Iteration 85/1000 | Loss: 0.00001450
Iteration 86/1000 | Loss: 0.00001450
Iteration 87/1000 | Loss: 0.00001450
Iteration 88/1000 | Loss: 0.00001449
Iteration 89/1000 | Loss: 0.00001449
Iteration 90/1000 | Loss: 0.00001449
Iteration 91/1000 | Loss: 0.00001448
Iteration 92/1000 | Loss: 0.00001448
Iteration 93/1000 | Loss: 0.00001448
Iteration 94/1000 | Loss: 0.00001447
Iteration 95/1000 | Loss: 0.00001447
Iteration 96/1000 | Loss: 0.00001446
Iteration 97/1000 | Loss: 0.00001446
Iteration 98/1000 | Loss: 0.00001446
Iteration 99/1000 | Loss: 0.00001446
Iteration 100/1000 | Loss: 0.00001445
Iteration 101/1000 | Loss: 0.00001445
Iteration 102/1000 | Loss: 0.00001445
Iteration 103/1000 | Loss: 0.00001445
Iteration 104/1000 | Loss: 0.00001445
Iteration 105/1000 | Loss: 0.00001445
Iteration 106/1000 | Loss: 0.00001445
Iteration 107/1000 | Loss: 0.00001445
Iteration 108/1000 | Loss: 0.00001444
Iteration 109/1000 | Loss: 0.00001444
Iteration 110/1000 | Loss: 0.00001444
Iteration 111/1000 | Loss: 0.00001444
Iteration 112/1000 | Loss: 0.00001444
Iteration 113/1000 | Loss: 0.00001444
Iteration 114/1000 | Loss: 0.00001444
Iteration 115/1000 | Loss: 0.00001443
Iteration 116/1000 | Loss: 0.00001443
Iteration 117/1000 | Loss: 0.00001443
Iteration 118/1000 | Loss: 0.00001443
Iteration 119/1000 | Loss: 0.00001443
Iteration 120/1000 | Loss: 0.00001443
Iteration 121/1000 | Loss: 0.00001443
Iteration 122/1000 | Loss: 0.00001443
Iteration 123/1000 | Loss: 0.00001443
Iteration 124/1000 | Loss: 0.00001443
Iteration 125/1000 | Loss: 0.00001443
Iteration 126/1000 | Loss: 0.00001443
Iteration 127/1000 | Loss: 0.00001443
Iteration 128/1000 | Loss: 0.00001443
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [1.4427402675210033e-05, 1.4427402675210033e-05, 1.4427402675210033e-05, 1.4427402675210033e-05, 1.4427402675210033e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4427402675210033e-05

Optimization complete. Final v2v error: 3.247960090637207 mm

Highest mean error: 3.7490670680999756 mm for frame 173

Lowest mean error: 2.8871748447418213 mm for frame 14

Saving results

Total time: 57.999154806137085
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1091/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1091.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1091
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00516131
Iteration 2/25 | Loss: 0.00100272
Iteration 3/25 | Loss: 0.00090398
Iteration 4/25 | Loss: 0.00088315
Iteration 5/25 | Loss: 0.00087810
Iteration 6/25 | Loss: 0.00087749
Iteration 7/25 | Loss: 0.00087749
Iteration 8/25 | Loss: 0.00087749
Iteration 9/25 | Loss: 0.00087749
Iteration 10/25 | Loss: 0.00087749
Iteration 11/25 | Loss: 0.00087749
Iteration 12/25 | Loss: 0.00087749
Iteration 13/25 | Loss: 0.00087749
Iteration 14/25 | Loss: 0.00087749
Iteration 15/25 | Loss: 0.00087749
Iteration 16/25 | Loss: 0.00087749
Iteration 17/25 | Loss: 0.00087749
Iteration 18/25 | Loss: 0.00087749
Iteration 19/25 | Loss: 0.00087749
Iteration 20/25 | Loss: 0.00087749
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0008774870657362044, 0.0008774870657362044, 0.0008774870657362044, 0.0008774870657362044, 0.0008774870657362044]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008774870657362044

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51610696
Iteration 2/25 | Loss: 0.00052834
Iteration 3/25 | Loss: 0.00052830
Iteration 4/25 | Loss: 0.00052830
Iteration 5/25 | Loss: 0.00052830
Iteration 6/25 | Loss: 0.00052830
Iteration 7/25 | Loss: 0.00052830
Iteration 8/25 | Loss: 0.00052830
Iteration 9/25 | Loss: 0.00052830
Iteration 10/25 | Loss: 0.00052830
Iteration 11/25 | Loss: 0.00052830
Iteration 12/25 | Loss: 0.00052830
Iteration 13/25 | Loss: 0.00052830
Iteration 14/25 | Loss: 0.00052830
Iteration 15/25 | Loss: 0.00052830
Iteration 16/25 | Loss: 0.00052830
Iteration 17/25 | Loss: 0.00052830
Iteration 18/25 | Loss: 0.00052830
Iteration 19/25 | Loss: 0.00052830
Iteration 20/25 | Loss: 0.00052830
Iteration 21/25 | Loss: 0.00052830
Iteration 22/25 | Loss: 0.00052830
Iteration 23/25 | Loss: 0.00052830
Iteration 24/25 | Loss: 0.00052830
Iteration 25/25 | Loss: 0.00052830

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052830
Iteration 2/1000 | Loss: 0.00003753
Iteration 3/1000 | Loss: 0.00002457
Iteration 4/1000 | Loss: 0.00002218
Iteration 5/1000 | Loss: 0.00002071
Iteration 6/1000 | Loss: 0.00001978
Iteration 7/1000 | Loss: 0.00001925
Iteration 8/1000 | Loss: 0.00001899
Iteration 9/1000 | Loss: 0.00001867
Iteration 10/1000 | Loss: 0.00001841
Iteration 11/1000 | Loss: 0.00001831
Iteration 12/1000 | Loss: 0.00001815
Iteration 13/1000 | Loss: 0.00001810
Iteration 14/1000 | Loss: 0.00001808
Iteration 15/1000 | Loss: 0.00001806
Iteration 16/1000 | Loss: 0.00001806
Iteration 17/1000 | Loss: 0.00001805
Iteration 18/1000 | Loss: 0.00001805
Iteration 19/1000 | Loss: 0.00001804
Iteration 20/1000 | Loss: 0.00001802
Iteration 21/1000 | Loss: 0.00001801
Iteration 22/1000 | Loss: 0.00001796
Iteration 23/1000 | Loss: 0.00001795
Iteration 24/1000 | Loss: 0.00001794
Iteration 25/1000 | Loss: 0.00001794
Iteration 26/1000 | Loss: 0.00001794
Iteration 27/1000 | Loss: 0.00001793
Iteration 28/1000 | Loss: 0.00001793
Iteration 29/1000 | Loss: 0.00001793
Iteration 30/1000 | Loss: 0.00001793
Iteration 31/1000 | Loss: 0.00001792
Iteration 32/1000 | Loss: 0.00001792
Iteration 33/1000 | Loss: 0.00001791
Iteration 34/1000 | Loss: 0.00001791
Iteration 35/1000 | Loss: 0.00001790
Iteration 36/1000 | Loss: 0.00001790
Iteration 37/1000 | Loss: 0.00001790
Iteration 38/1000 | Loss: 0.00001789
Iteration 39/1000 | Loss: 0.00001789
Iteration 40/1000 | Loss: 0.00001789
Iteration 41/1000 | Loss: 0.00001789
Iteration 42/1000 | Loss: 0.00001788
Iteration 43/1000 | Loss: 0.00001788
Iteration 44/1000 | Loss: 0.00001787
Iteration 45/1000 | Loss: 0.00001787
Iteration 46/1000 | Loss: 0.00001787
Iteration 47/1000 | Loss: 0.00001786
Iteration 48/1000 | Loss: 0.00001786
Iteration 49/1000 | Loss: 0.00001786
Iteration 50/1000 | Loss: 0.00001785
Iteration 51/1000 | Loss: 0.00001785
Iteration 52/1000 | Loss: 0.00001785
Iteration 53/1000 | Loss: 0.00001785
Iteration 54/1000 | Loss: 0.00001785
Iteration 55/1000 | Loss: 0.00001784
Iteration 56/1000 | Loss: 0.00001784
Iteration 57/1000 | Loss: 0.00001784
Iteration 58/1000 | Loss: 0.00001784
Iteration 59/1000 | Loss: 0.00001784
Iteration 60/1000 | Loss: 0.00001784
Iteration 61/1000 | Loss: 0.00001783
Iteration 62/1000 | Loss: 0.00001783
Iteration 63/1000 | Loss: 0.00001783
Iteration 64/1000 | Loss: 0.00001783
Iteration 65/1000 | Loss: 0.00001783
Iteration 66/1000 | Loss: 0.00001782
Iteration 67/1000 | Loss: 0.00001782
Iteration 68/1000 | Loss: 0.00001782
Iteration 69/1000 | Loss: 0.00001782
Iteration 70/1000 | Loss: 0.00001782
Iteration 71/1000 | Loss: 0.00001782
Iteration 72/1000 | Loss: 0.00001782
Iteration 73/1000 | Loss: 0.00001782
Iteration 74/1000 | Loss: 0.00001782
Iteration 75/1000 | Loss: 0.00001782
Iteration 76/1000 | Loss: 0.00001782
Iteration 77/1000 | Loss: 0.00001781
Iteration 78/1000 | Loss: 0.00001781
Iteration 79/1000 | Loss: 0.00001781
Iteration 80/1000 | Loss: 0.00001781
Iteration 81/1000 | Loss: 0.00001781
Iteration 82/1000 | Loss: 0.00001781
Iteration 83/1000 | Loss: 0.00001781
Iteration 84/1000 | Loss: 0.00001780
Iteration 85/1000 | Loss: 0.00001780
Iteration 86/1000 | Loss: 0.00001780
Iteration 87/1000 | Loss: 0.00001780
Iteration 88/1000 | Loss: 0.00001780
Iteration 89/1000 | Loss: 0.00001780
Iteration 90/1000 | Loss: 0.00001780
Iteration 91/1000 | Loss: 0.00001779
Iteration 92/1000 | Loss: 0.00001779
Iteration 93/1000 | Loss: 0.00001779
Iteration 94/1000 | Loss: 0.00001779
Iteration 95/1000 | Loss: 0.00001779
Iteration 96/1000 | Loss: 0.00001779
Iteration 97/1000 | Loss: 0.00001778
Iteration 98/1000 | Loss: 0.00001778
Iteration 99/1000 | Loss: 0.00001778
Iteration 100/1000 | Loss: 0.00001777
Iteration 101/1000 | Loss: 0.00001777
Iteration 102/1000 | Loss: 0.00001777
Iteration 103/1000 | Loss: 0.00001777
Iteration 104/1000 | Loss: 0.00001776
Iteration 105/1000 | Loss: 0.00001776
Iteration 106/1000 | Loss: 0.00001776
Iteration 107/1000 | Loss: 0.00001775
Iteration 108/1000 | Loss: 0.00001775
Iteration 109/1000 | Loss: 0.00001775
Iteration 110/1000 | Loss: 0.00001775
Iteration 111/1000 | Loss: 0.00001775
Iteration 112/1000 | Loss: 0.00001775
Iteration 113/1000 | Loss: 0.00001774
Iteration 114/1000 | Loss: 0.00001774
Iteration 115/1000 | Loss: 0.00001774
Iteration 116/1000 | Loss: 0.00001774
Iteration 117/1000 | Loss: 0.00001774
Iteration 118/1000 | Loss: 0.00001774
Iteration 119/1000 | Loss: 0.00001773
Iteration 120/1000 | Loss: 0.00001773
Iteration 121/1000 | Loss: 0.00001773
Iteration 122/1000 | Loss: 0.00001773
Iteration 123/1000 | Loss: 0.00001773
Iteration 124/1000 | Loss: 0.00001773
Iteration 125/1000 | Loss: 0.00001773
Iteration 126/1000 | Loss: 0.00001773
Iteration 127/1000 | Loss: 0.00001773
Iteration 128/1000 | Loss: 0.00001773
Iteration 129/1000 | Loss: 0.00001773
Iteration 130/1000 | Loss: 0.00001773
Iteration 131/1000 | Loss: 0.00001773
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.773495569068473e-05, 1.773495569068473e-05, 1.773495569068473e-05, 1.773495569068473e-05, 1.773495569068473e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.773495569068473e-05

Optimization complete. Final v2v error: 3.5104503631591797 mm

Highest mean error: 4.4115519523620605 mm for frame 156

Lowest mean error: 2.9970269203186035 mm for frame 8

Saving results

Total time: 40.56134271621704
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1040/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1040.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1040
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00547569
Iteration 2/25 | Loss: 0.00126526
Iteration 3/25 | Loss: 0.00097850
Iteration 4/25 | Loss: 0.00094483
Iteration 5/25 | Loss: 0.00093790
Iteration 6/25 | Loss: 0.00093672
Iteration 7/25 | Loss: 0.00093651
Iteration 8/25 | Loss: 0.00093651
Iteration 9/25 | Loss: 0.00093651
Iteration 10/25 | Loss: 0.00093651
Iteration 11/25 | Loss: 0.00093651
Iteration 12/25 | Loss: 0.00093651
Iteration 13/25 | Loss: 0.00093651
Iteration 14/25 | Loss: 0.00093651
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.000936505850404501, 0.000936505850404501, 0.000936505850404501, 0.000936505850404501, 0.000936505850404501]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000936505850404501

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51772857
Iteration 2/25 | Loss: 0.00059160
Iteration 3/25 | Loss: 0.00059160
Iteration 4/25 | Loss: 0.00059160
Iteration 5/25 | Loss: 0.00059160
Iteration 6/25 | Loss: 0.00059160
Iteration 7/25 | Loss: 0.00059160
Iteration 8/25 | Loss: 0.00059160
Iteration 9/25 | Loss: 0.00059160
Iteration 10/25 | Loss: 0.00059160
Iteration 11/25 | Loss: 0.00059160
Iteration 12/25 | Loss: 0.00059160
Iteration 13/25 | Loss: 0.00059160
Iteration 14/25 | Loss: 0.00059160
Iteration 15/25 | Loss: 0.00059160
Iteration 16/25 | Loss: 0.00059160
Iteration 17/25 | Loss: 0.00059160
Iteration 18/25 | Loss: 0.00059160
Iteration 19/25 | Loss: 0.00059160
Iteration 20/25 | Loss: 0.00059160
Iteration 21/25 | Loss: 0.00059160
Iteration 22/25 | Loss: 0.00059160
Iteration 23/25 | Loss: 0.00059160
Iteration 24/25 | Loss: 0.00059160
Iteration 25/25 | Loss: 0.00059160
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0005915967049077153, 0.0005915967049077153, 0.0005915967049077153, 0.0005915967049077153, 0.0005915967049077153]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005915967049077153

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059160
Iteration 2/1000 | Loss: 0.00003351
Iteration 3/1000 | Loss: 0.00002628
Iteration 4/1000 | Loss: 0.00002452
Iteration 5/1000 | Loss: 0.00002332
Iteration 6/1000 | Loss: 0.00002234
Iteration 7/1000 | Loss: 0.00002175
Iteration 8/1000 | Loss: 0.00002130
Iteration 9/1000 | Loss: 0.00002103
Iteration 10/1000 | Loss: 0.00002079
Iteration 11/1000 | Loss: 0.00002066
Iteration 12/1000 | Loss: 0.00002042
Iteration 13/1000 | Loss: 0.00002031
Iteration 14/1000 | Loss: 0.00002029
Iteration 15/1000 | Loss: 0.00002019
Iteration 16/1000 | Loss: 0.00002015
Iteration 17/1000 | Loss: 0.00002014
Iteration 18/1000 | Loss: 0.00002014
Iteration 19/1000 | Loss: 0.00002013
Iteration 20/1000 | Loss: 0.00002013
Iteration 21/1000 | Loss: 0.00002012
Iteration 22/1000 | Loss: 0.00002012
Iteration 23/1000 | Loss: 0.00002012
Iteration 24/1000 | Loss: 0.00002011
Iteration 25/1000 | Loss: 0.00002010
Iteration 26/1000 | Loss: 0.00002010
Iteration 27/1000 | Loss: 0.00002008
Iteration 28/1000 | Loss: 0.00002008
Iteration 29/1000 | Loss: 0.00002007
Iteration 30/1000 | Loss: 0.00002007
Iteration 31/1000 | Loss: 0.00002007
Iteration 32/1000 | Loss: 0.00002007
Iteration 33/1000 | Loss: 0.00002006
Iteration 34/1000 | Loss: 0.00002004
Iteration 35/1000 | Loss: 0.00002004
Iteration 36/1000 | Loss: 0.00002003
Iteration 37/1000 | Loss: 0.00002003
Iteration 38/1000 | Loss: 0.00002003
Iteration 39/1000 | Loss: 0.00002003
Iteration 40/1000 | Loss: 0.00002000
Iteration 41/1000 | Loss: 0.00002000
Iteration 42/1000 | Loss: 0.00001999
Iteration 43/1000 | Loss: 0.00001999
Iteration 44/1000 | Loss: 0.00001998
Iteration 45/1000 | Loss: 0.00001998
Iteration 46/1000 | Loss: 0.00001998
Iteration 47/1000 | Loss: 0.00001998
Iteration 48/1000 | Loss: 0.00001997
Iteration 49/1000 | Loss: 0.00001997
Iteration 50/1000 | Loss: 0.00001997
Iteration 51/1000 | Loss: 0.00001997
Iteration 52/1000 | Loss: 0.00001997
Iteration 53/1000 | Loss: 0.00001997
Iteration 54/1000 | Loss: 0.00001997
Iteration 55/1000 | Loss: 0.00001997
Iteration 56/1000 | Loss: 0.00001997
Iteration 57/1000 | Loss: 0.00001997
Iteration 58/1000 | Loss: 0.00001997
Iteration 59/1000 | Loss: 0.00001997
Iteration 60/1000 | Loss: 0.00001996
Iteration 61/1000 | Loss: 0.00001996
Iteration 62/1000 | Loss: 0.00001996
Iteration 63/1000 | Loss: 0.00001996
Iteration 64/1000 | Loss: 0.00001996
Iteration 65/1000 | Loss: 0.00001995
Iteration 66/1000 | Loss: 0.00001995
Iteration 67/1000 | Loss: 0.00001995
Iteration 68/1000 | Loss: 0.00001995
Iteration 69/1000 | Loss: 0.00001994
Iteration 70/1000 | Loss: 0.00001994
Iteration 71/1000 | Loss: 0.00001993
Iteration 72/1000 | Loss: 0.00001993
Iteration 73/1000 | Loss: 0.00001993
Iteration 74/1000 | Loss: 0.00001992
Iteration 75/1000 | Loss: 0.00001992
Iteration 76/1000 | Loss: 0.00001992
Iteration 77/1000 | Loss: 0.00001992
Iteration 78/1000 | Loss: 0.00001992
Iteration 79/1000 | Loss: 0.00001992
Iteration 80/1000 | Loss: 0.00001992
Iteration 81/1000 | Loss: 0.00001992
Iteration 82/1000 | Loss: 0.00001992
Iteration 83/1000 | Loss: 0.00001992
Iteration 84/1000 | Loss: 0.00001992
Iteration 85/1000 | Loss: 0.00001992
Iteration 86/1000 | Loss: 0.00001991
Iteration 87/1000 | Loss: 0.00001991
Iteration 88/1000 | Loss: 0.00001991
Iteration 89/1000 | Loss: 0.00001991
Iteration 90/1000 | Loss: 0.00001990
Iteration 91/1000 | Loss: 0.00001990
Iteration 92/1000 | Loss: 0.00001990
Iteration 93/1000 | Loss: 0.00001990
Iteration 94/1000 | Loss: 0.00001990
Iteration 95/1000 | Loss: 0.00001990
Iteration 96/1000 | Loss: 0.00001990
Iteration 97/1000 | Loss: 0.00001990
Iteration 98/1000 | Loss: 0.00001990
Iteration 99/1000 | Loss: 0.00001990
Iteration 100/1000 | Loss: 0.00001990
Iteration 101/1000 | Loss: 0.00001990
Iteration 102/1000 | Loss: 0.00001990
Iteration 103/1000 | Loss: 0.00001990
Iteration 104/1000 | Loss: 0.00001990
Iteration 105/1000 | Loss: 0.00001990
Iteration 106/1000 | Loss: 0.00001990
Iteration 107/1000 | Loss: 0.00001989
Iteration 108/1000 | Loss: 0.00001989
Iteration 109/1000 | Loss: 0.00001989
Iteration 110/1000 | Loss: 0.00001989
Iteration 111/1000 | Loss: 0.00001989
Iteration 112/1000 | Loss: 0.00001989
Iteration 113/1000 | Loss: 0.00001989
Iteration 114/1000 | Loss: 0.00001988
Iteration 115/1000 | Loss: 0.00001988
Iteration 116/1000 | Loss: 0.00001988
Iteration 117/1000 | Loss: 0.00001988
Iteration 118/1000 | Loss: 0.00001988
Iteration 119/1000 | Loss: 0.00001988
Iteration 120/1000 | Loss: 0.00001988
Iteration 121/1000 | Loss: 0.00001988
Iteration 122/1000 | Loss: 0.00001988
Iteration 123/1000 | Loss: 0.00001987
Iteration 124/1000 | Loss: 0.00001987
Iteration 125/1000 | Loss: 0.00001987
Iteration 126/1000 | Loss: 0.00001987
Iteration 127/1000 | Loss: 0.00001987
Iteration 128/1000 | Loss: 0.00001987
Iteration 129/1000 | Loss: 0.00001987
Iteration 130/1000 | Loss: 0.00001987
Iteration 131/1000 | Loss: 0.00001987
Iteration 132/1000 | Loss: 0.00001987
Iteration 133/1000 | Loss: 0.00001987
Iteration 134/1000 | Loss: 0.00001987
Iteration 135/1000 | Loss: 0.00001987
Iteration 136/1000 | Loss: 0.00001986
Iteration 137/1000 | Loss: 0.00001986
Iteration 138/1000 | Loss: 0.00001986
Iteration 139/1000 | Loss: 0.00001986
Iteration 140/1000 | Loss: 0.00001986
Iteration 141/1000 | Loss: 0.00001986
Iteration 142/1000 | Loss: 0.00001986
Iteration 143/1000 | Loss: 0.00001986
Iteration 144/1000 | Loss: 0.00001986
Iteration 145/1000 | Loss: 0.00001986
Iteration 146/1000 | Loss: 0.00001986
Iteration 147/1000 | Loss: 0.00001986
Iteration 148/1000 | Loss: 0.00001986
Iteration 149/1000 | Loss: 0.00001986
Iteration 150/1000 | Loss: 0.00001985
Iteration 151/1000 | Loss: 0.00001985
Iteration 152/1000 | Loss: 0.00001985
Iteration 153/1000 | Loss: 0.00001985
Iteration 154/1000 | Loss: 0.00001985
Iteration 155/1000 | Loss: 0.00001985
Iteration 156/1000 | Loss: 0.00001985
Iteration 157/1000 | Loss: 0.00001985
Iteration 158/1000 | Loss: 0.00001985
Iteration 159/1000 | Loss: 0.00001985
Iteration 160/1000 | Loss: 0.00001985
Iteration 161/1000 | Loss: 0.00001985
Iteration 162/1000 | Loss: 0.00001984
Iteration 163/1000 | Loss: 0.00001984
Iteration 164/1000 | Loss: 0.00001984
Iteration 165/1000 | Loss: 0.00001984
Iteration 166/1000 | Loss: 0.00001984
Iteration 167/1000 | Loss: 0.00001984
Iteration 168/1000 | Loss: 0.00001984
Iteration 169/1000 | Loss: 0.00001984
Iteration 170/1000 | Loss: 0.00001984
Iteration 171/1000 | Loss: 0.00001984
Iteration 172/1000 | Loss: 0.00001984
Iteration 173/1000 | Loss: 0.00001984
Iteration 174/1000 | Loss: 0.00001984
Iteration 175/1000 | Loss: 0.00001984
Iteration 176/1000 | Loss: 0.00001984
Iteration 177/1000 | Loss: 0.00001984
Iteration 178/1000 | Loss: 0.00001984
Iteration 179/1000 | Loss: 0.00001984
Iteration 180/1000 | Loss: 0.00001984
Iteration 181/1000 | Loss: 0.00001984
Iteration 182/1000 | Loss: 0.00001983
Iteration 183/1000 | Loss: 0.00001983
Iteration 184/1000 | Loss: 0.00001983
Iteration 185/1000 | Loss: 0.00001983
Iteration 186/1000 | Loss: 0.00001983
Iteration 187/1000 | Loss: 0.00001983
Iteration 188/1000 | Loss: 0.00001983
Iteration 189/1000 | Loss: 0.00001983
Iteration 190/1000 | Loss: 0.00001983
Iteration 191/1000 | Loss: 0.00001983
Iteration 192/1000 | Loss: 0.00001983
Iteration 193/1000 | Loss: 0.00001983
Iteration 194/1000 | Loss: 0.00001983
Iteration 195/1000 | Loss: 0.00001983
Iteration 196/1000 | Loss: 0.00001983
Iteration 197/1000 | Loss: 0.00001983
Iteration 198/1000 | Loss: 0.00001983
Iteration 199/1000 | Loss: 0.00001983
Iteration 200/1000 | Loss: 0.00001983
Iteration 201/1000 | Loss: 0.00001983
Iteration 202/1000 | Loss: 0.00001983
Iteration 203/1000 | Loss: 0.00001983
Iteration 204/1000 | Loss: 0.00001983
Iteration 205/1000 | Loss: 0.00001983
Iteration 206/1000 | Loss: 0.00001983
Iteration 207/1000 | Loss: 0.00001983
Iteration 208/1000 | Loss: 0.00001983
Iteration 209/1000 | Loss: 0.00001983
Iteration 210/1000 | Loss: 0.00001983
Iteration 211/1000 | Loss: 0.00001983
Iteration 212/1000 | Loss: 0.00001983
Iteration 213/1000 | Loss: 0.00001983
Iteration 214/1000 | Loss: 0.00001983
Iteration 215/1000 | Loss: 0.00001983
Iteration 216/1000 | Loss: 0.00001983
Iteration 217/1000 | Loss: 0.00001983
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 217. Stopping optimization.
Last 5 losses: [1.9827670257654972e-05, 1.9827670257654972e-05, 1.9827670257654972e-05, 1.9827670257654972e-05, 1.9827670257654972e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9827670257654972e-05

Optimization complete. Final v2v error: 3.762698173522949 mm

Highest mean error: 3.979656934738159 mm for frame 56

Lowest mean error: 3.2470853328704834 mm for frame 12

Saving results

Total time: 41.237648725509644
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1060/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1060.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1060
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00993856
Iteration 2/25 | Loss: 0.00993856
Iteration 3/25 | Loss: 0.00993855
Iteration 4/25 | Loss: 0.00439776
Iteration 5/25 | Loss: 0.00267101
Iteration 6/25 | Loss: 0.00231235
Iteration 7/25 | Loss: 0.00203900
Iteration 8/25 | Loss: 0.00208429
Iteration 9/25 | Loss: 0.00188348
Iteration 10/25 | Loss: 0.00168229
Iteration 11/25 | Loss: 0.00163377
Iteration 12/25 | Loss: 0.00162011
Iteration 13/25 | Loss: 0.00158583
Iteration 14/25 | Loss: 0.00157763
Iteration 15/25 | Loss: 0.00157013
Iteration 16/25 | Loss: 0.00158488
Iteration 17/25 | Loss: 0.00157451
Iteration 18/25 | Loss: 0.00156693
Iteration 19/25 | Loss: 0.00156175
Iteration 20/25 | Loss: 0.00156108
Iteration 21/25 | Loss: 0.00156306
Iteration 22/25 | Loss: 0.00156228
Iteration 23/25 | Loss: 0.00156363
Iteration 24/25 | Loss: 0.00156603
Iteration 25/25 | Loss: 0.00155857

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50610638
Iteration 2/25 | Loss: 0.01376197
Iteration 3/25 | Loss: 0.00872139
Iteration 4/25 | Loss: 0.00872133
Iteration 5/25 | Loss: 0.00872133
Iteration 6/25 | Loss: 0.00872133
Iteration 7/25 | Loss: 0.00872132
Iteration 8/25 | Loss: 0.00872132
Iteration 9/25 | Loss: 0.00872132
Iteration 10/25 | Loss: 0.00872132
Iteration 11/25 | Loss: 0.00872132
Iteration 12/25 | Loss: 0.00872132
Iteration 13/25 | Loss: 0.00872132
Iteration 14/25 | Loss: 0.00872132
Iteration 15/25 | Loss: 0.00872132
Iteration 16/25 | Loss: 0.00872132
Iteration 17/25 | Loss: 0.00872132
Iteration 18/25 | Loss: 0.00872132
Iteration 19/25 | Loss: 0.00872132
Iteration 20/25 | Loss: 0.00872132
Iteration 21/25 | Loss: 0.00872132
Iteration 22/25 | Loss: 0.00872132
Iteration 23/25 | Loss: 0.00872132
Iteration 24/25 | Loss: 0.00872132
Iteration 25/25 | Loss: 0.00872132

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00872132
Iteration 2/1000 | Loss: 0.00623270
Iteration 3/1000 | Loss: 0.00664003
Iteration 4/1000 | Loss: 0.00074101
Iteration 5/1000 | Loss: 0.00166173
Iteration 6/1000 | Loss: 0.01151623
Iteration 7/1000 | Loss: 0.00070674
Iteration 8/1000 | Loss: 0.00198067
Iteration 9/1000 | Loss: 0.00061851
Iteration 10/1000 | Loss: 0.00044227
Iteration 11/1000 | Loss: 0.00127959
Iteration 12/1000 | Loss: 0.00040163
Iteration 13/1000 | Loss: 0.00050670
Iteration 14/1000 | Loss: 0.00066951
Iteration 15/1000 | Loss: 0.00068174
Iteration 16/1000 | Loss: 0.00037409
Iteration 17/1000 | Loss: 0.00045805
Iteration 18/1000 | Loss: 0.00110616
Iteration 19/1000 | Loss: 0.00051167
Iteration 20/1000 | Loss: 0.00041726
Iteration 21/1000 | Loss: 0.00051388
Iteration 22/1000 | Loss: 0.00060444
Iteration 23/1000 | Loss: 0.00033560
Iteration 24/1000 | Loss: 0.00055232
Iteration 25/1000 | Loss: 0.00049415
Iteration 26/1000 | Loss: 0.00389114
Iteration 27/1000 | Loss: 0.00776966
Iteration 28/1000 | Loss: 0.01089694
Iteration 29/1000 | Loss: 0.01309377
Iteration 30/1000 | Loss: 0.00231065
Iteration 31/1000 | Loss: 0.00374969
Iteration 32/1000 | Loss: 0.00203859
Iteration 33/1000 | Loss: 0.00129318
Iteration 34/1000 | Loss: 0.00136595
Iteration 35/1000 | Loss: 0.00068361
Iteration 36/1000 | Loss: 0.00036583
Iteration 37/1000 | Loss: 0.00165115
Iteration 38/1000 | Loss: 0.00141175
Iteration 39/1000 | Loss: 0.01802326
Iteration 40/1000 | Loss: 0.00769532
Iteration 41/1000 | Loss: 0.00727812
Iteration 42/1000 | Loss: 0.00331623
Iteration 43/1000 | Loss: 0.00199874
Iteration 44/1000 | Loss: 0.00042034
Iteration 45/1000 | Loss: 0.00277553
Iteration 46/1000 | Loss: 0.00168584
Iteration 47/1000 | Loss: 0.00374538
Iteration 48/1000 | Loss: 0.00082571
Iteration 49/1000 | Loss: 0.00115904
Iteration 50/1000 | Loss: 0.00025578
Iteration 51/1000 | Loss: 0.00149593
Iteration 52/1000 | Loss: 0.00239090
Iteration 53/1000 | Loss: 0.00138718
Iteration 54/1000 | Loss: 0.00064271
Iteration 55/1000 | Loss: 0.00158291
Iteration 56/1000 | Loss: 0.00101827
Iteration 57/1000 | Loss: 0.00010410
Iteration 58/1000 | Loss: 0.00007575
Iteration 59/1000 | Loss: 0.00008467
Iteration 60/1000 | Loss: 0.00006140
Iteration 61/1000 | Loss: 0.00060346
Iteration 62/1000 | Loss: 0.00014339
Iteration 63/1000 | Loss: 0.00008327
Iteration 64/1000 | Loss: 0.00008140
Iteration 65/1000 | Loss: 0.00022849
Iteration 66/1000 | Loss: 0.00006931
Iteration 67/1000 | Loss: 0.00004283
Iteration 68/1000 | Loss: 0.00080154
Iteration 69/1000 | Loss: 0.00032214
Iteration 70/1000 | Loss: 0.00035777
Iteration 71/1000 | Loss: 0.00027739
Iteration 72/1000 | Loss: 0.00154528
Iteration 73/1000 | Loss: 0.00196710
Iteration 74/1000 | Loss: 0.00154803
Iteration 75/1000 | Loss: 0.00098388
Iteration 76/1000 | Loss: 0.00005200
Iteration 77/1000 | Loss: 0.00020696
Iteration 78/1000 | Loss: 0.00168185
Iteration 79/1000 | Loss: 0.00098133
Iteration 80/1000 | Loss: 0.00129193
Iteration 81/1000 | Loss: 0.00034066
Iteration 82/1000 | Loss: 0.00004491
Iteration 83/1000 | Loss: 0.00020863
Iteration 84/1000 | Loss: 0.00028553
Iteration 85/1000 | Loss: 0.00094801
Iteration 86/1000 | Loss: 0.00005339
Iteration 87/1000 | Loss: 0.00008998
Iteration 88/1000 | Loss: 0.00003607
Iteration 89/1000 | Loss: 0.00035263
Iteration 90/1000 | Loss: 0.00008334
Iteration 91/1000 | Loss: 0.00003645
Iteration 92/1000 | Loss: 0.00003281
Iteration 93/1000 | Loss: 0.00010220
Iteration 94/1000 | Loss: 0.00023722
Iteration 95/1000 | Loss: 0.00376625
Iteration 96/1000 | Loss: 0.00150048
Iteration 97/1000 | Loss: 0.00301373
Iteration 98/1000 | Loss: 0.00016768
Iteration 99/1000 | Loss: 0.00016967
Iteration 100/1000 | Loss: 0.00002791
Iteration 101/1000 | Loss: 0.00014395
Iteration 102/1000 | Loss: 0.00006817
Iteration 103/1000 | Loss: 0.00002511
Iteration 104/1000 | Loss: 0.00002484
Iteration 105/1000 | Loss: 0.00017268
Iteration 106/1000 | Loss: 0.00002480
Iteration 107/1000 | Loss: 0.00002459
Iteration 108/1000 | Loss: 0.00002458
Iteration 109/1000 | Loss: 0.00010609
Iteration 110/1000 | Loss: 0.00002441
Iteration 111/1000 | Loss: 0.00002421
Iteration 112/1000 | Loss: 0.00002406
Iteration 113/1000 | Loss: 0.00018118
Iteration 114/1000 | Loss: 0.00057128
Iteration 115/1000 | Loss: 0.00005446
Iteration 116/1000 | Loss: 0.00011242
Iteration 117/1000 | Loss: 0.00005738
Iteration 118/1000 | Loss: 0.00003991
Iteration 119/1000 | Loss: 0.00002424
Iteration 120/1000 | Loss: 0.00010608
Iteration 121/1000 | Loss: 0.00003008
Iteration 122/1000 | Loss: 0.00004090
Iteration 123/1000 | Loss: 0.00004398
Iteration 124/1000 | Loss: 0.00002991
Iteration 125/1000 | Loss: 0.00003087
Iteration 126/1000 | Loss: 0.00002638
Iteration 127/1000 | Loss: 0.00002389
Iteration 128/1000 | Loss: 0.00002388
Iteration 129/1000 | Loss: 0.00002384
Iteration 130/1000 | Loss: 0.00002384
Iteration 131/1000 | Loss: 0.00002384
Iteration 132/1000 | Loss: 0.00002384
Iteration 133/1000 | Loss: 0.00002384
Iteration 134/1000 | Loss: 0.00002383
Iteration 135/1000 | Loss: 0.00002383
Iteration 136/1000 | Loss: 0.00002383
Iteration 137/1000 | Loss: 0.00013027
Iteration 138/1000 | Loss: 0.00003486
Iteration 139/1000 | Loss: 0.00002382
Iteration 140/1000 | Loss: 0.00002378
Iteration 141/1000 | Loss: 0.00002378
Iteration 142/1000 | Loss: 0.00002376
Iteration 143/1000 | Loss: 0.00002372
Iteration 144/1000 | Loss: 0.00002368
Iteration 145/1000 | Loss: 0.00002367
Iteration 146/1000 | Loss: 0.00002367
Iteration 147/1000 | Loss: 0.00002364
Iteration 148/1000 | Loss: 0.00002363
Iteration 149/1000 | Loss: 0.00002363
Iteration 150/1000 | Loss: 0.00002362
Iteration 151/1000 | Loss: 0.00002362
Iteration 152/1000 | Loss: 0.00002361
Iteration 153/1000 | Loss: 0.00002361
Iteration 154/1000 | Loss: 0.00002361
Iteration 155/1000 | Loss: 0.00002361
Iteration 156/1000 | Loss: 0.00002360
Iteration 157/1000 | Loss: 0.00002360
Iteration 158/1000 | Loss: 0.00002360
Iteration 159/1000 | Loss: 0.00002360
Iteration 160/1000 | Loss: 0.00002360
Iteration 161/1000 | Loss: 0.00002360
Iteration 162/1000 | Loss: 0.00002360
Iteration 163/1000 | Loss: 0.00002360
Iteration 164/1000 | Loss: 0.00002360
Iteration 165/1000 | Loss: 0.00002360
Iteration 166/1000 | Loss: 0.00002360
Iteration 167/1000 | Loss: 0.00002359
Iteration 168/1000 | Loss: 0.00002359
Iteration 169/1000 | Loss: 0.00002359
Iteration 170/1000 | Loss: 0.00002359
Iteration 171/1000 | Loss: 0.00002359
Iteration 172/1000 | Loss: 0.00002359
Iteration 173/1000 | Loss: 0.00002359
Iteration 174/1000 | Loss: 0.00002359
Iteration 175/1000 | Loss: 0.00002359
Iteration 176/1000 | Loss: 0.00002358
Iteration 177/1000 | Loss: 0.00002358
Iteration 178/1000 | Loss: 0.00002358
Iteration 179/1000 | Loss: 0.00002358
Iteration 180/1000 | Loss: 0.00002358
Iteration 181/1000 | Loss: 0.00002358
Iteration 182/1000 | Loss: 0.00002358
Iteration 183/1000 | Loss: 0.00002358
Iteration 184/1000 | Loss: 0.00002358
Iteration 185/1000 | Loss: 0.00002358
Iteration 186/1000 | Loss: 0.00002358
Iteration 187/1000 | Loss: 0.00002358
Iteration 188/1000 | Loss: 0.00002358
Iteration 189/1000 | Loss: 0.00002358
Iteration 190/1000 | Loss: 0.00011961
Iteration 191/1000 | Loss: 0.00136014
Iteration 192/1000 | Loss: 0.00069583
Iteration 193/1000 | Loss: 0.00009892
Iteration 194/1000 | Loss: 0.00019418
Iteration 195/1000 | Loss: 0.00002790
Iteration 196/1000 | Loss: 0.00011865
Iteration 197/1000 | Loss: 0.00037251
Iteration 198/1000 | Loss: 0.00004723
Iteration 199/1000 | Loss: 0.00003996
Iteration 200/1000 | Loss: 0.00028061
Iteration 201/1000 | Loss: 0.00014724
Iteration 202/1000 | Loss: 0.00002793
Iteration 203/1000 | Loss: 0.00005317
Iteration 204/1000 | Loss: 0.00002462
Iteration 205/1000 | Loss: 0.00002416
Iteration 206/1000 | Loss: 0.00013842
Iteration 207/1000 | Loss: 0.00002630
Iteration 208/1000 | Loss: 0.00002474
Iteration 209/1000 | Loss: 0.00003097
Iteration 210/1000 | Loss: 0.00002335
Iteration 211/1000 | Loss: 0.00002335
Iteration 212/1000 | Loss: 0.00002312
Iteration 213/1000 | Loss: 0.00002308
Iteration 214/1000 | Loss: 0.00002298
Iteration 215/1000 | Loss: 0.00002297
Iteration 216/1000 | Loss: 0.00002297
Iteration 217/1000 | Loss: 0.00002296
Iteration 218/1000 | Loss: 0.00002295
Iteration 219/1000 | Loss: 0.00002295
Iteration 220/1000 | Loss: 0.00002294
Iteration 221/1000 | Loss: 0.00002294
Iteration 222/1000 | Loss: 0.00002294
Iteration 223/1000 | Loss: 0.00002292
Iteration 224/1000 | Loss: 0.00002292
Iteration 225/1000 | Loss: 0.00002292
Iteration 226/1000 | Loss: 0.00002291
Iteration 227/1000 | Loss: 0.00002291
Iteration 228/1000 | Loss: 0.00002289
Iteration 229/1000 | Loss: 0.00002289
Iteration 230/1000 | Loss: 0.00002289
Iteration 231/1000 | Loss: 0.00002289
Iteration 232/1000 | Loss: 0.00002289
Iteration 233/1000 | Loss: 0.00002288
Iteration 234/1000 | Loss: 0.00002288
Iteration 235/1000 | Loss: 0.00002288
Iteration 236/1000 | Loss: 0.00002287
Iteration 237/1000 | Loss: 0.00002283
Iteration 238/1000 | Loss: 0.00002283
Iteration 239/1000 | Loss: 0.00002282
Iteration 240/1000 | Loss: 0.00002282
Iteration 241/1000 | Loss: 0.00002281
Iteration 242/1000 | Loss: 0.00002279
Iteration 243/1000 | Loss: 0.00002277
Iteration 244/1000 | Loss: 0.00002277
Iteration 245/1000 | Loss: 0.00002273
Iteration 246/1000 | Loss: 0.00002268
Iteration 247/1000 | Loss: 0.00002263
Iteration 248/1000 | Loss: 0.00002263
Iteration 249/1000 | Loss: 0.00002262
Iteration 250/1000 | Loss: 0.00002261
Iteration 251/1000 | Loss: 0.00002261
Iteration 252/1000 | Loss: 0.00002261
Iteration 253/1000 | Loss: 0.00002261
Iteration 254/1000 | Loss: 0.00002261
Iteration 255/1000 | Loss: 0.00002260
Iteration 256/1000 | Loss: 0.00002260
Iteration 257/1000 | Loss: 0.00002259
Iteration 258/1000 | Loss: 0.00002259
Iteration 259/1000 | Loss: 0.00002258
Iteration 260/1000 | Loss: 0.00013558
Iteration 261/1000 | Loss: 0.00002530
Iteration 262/1000 | Loss: 0.00002515
Iteration 263/1000 | Loss: 0.00002261
Iteration 264/1000 | Loss: 0.00002251
Iteration 265/1000 | Loss: 0.00002250
Iteration 266/1000 | Loss: 0.00004654
Iteration 267/1000 | Loss: 0.00035672
Iteration 268/1000 | Loss: 0.00002380
Iteration 269/1000 | Loss: 0.00005614
Iteration 270/1000 | Loss: 0.00003863
Iteration 271/1000 | Loss: 0.00004588
Iteration 272/1000 | Loss: 0.00003539
Iteration 273/1000 | Loss: 0.00002252
Iteration 274/1000 | Loss: 0.00002251
Iteration 275/1000 | Loss: 0.00002251
Iteration 276/1000 | Loss: 0.00002251
Iteration 277/1000 | Loss: 0.00004384
Iteration 278/1000 | Loss: 0.00003057
Iteration 279/1000 | Loss: 0.00002264
Iteration 280/1000 | Loss: 0.00004184
Iteration 281/1000 | Loss: 0.00003153
Iteration 282/1000 | Loss: 0.00002250
Iteration 283/1000 | Loss: 0.00002250
Iteration 284/1000 | Loss: 0.00002250
Iteration 285/1000 | Loss: 0.00002250
Iteration 286/1000 | Loss: 0.00002250
Iteration 287/1000 | Loss: 0.00004264
Iteration 288/1000 | Loss: 0.00003377
Iteration 289/1000 | Loss: 0.00002249
Iteration 290/1000 | Loss: 0.00002249
Iteration 291/1000 | Loss: 0.00002249
Iteration 292/1000 | Loss: 0.00002248
Iteration 293/1000 | Loss: 0.00002248
Iteration 294/1000 | Loss: 0.00002248
Iteration 295/1000 | Loss: 0.00002248
Iteration 296/1000 | Loss: 0.00002248
Iteration 297/1000 | Loss: 0.00002247
Iteration 298/1000 | Loss: 0.00002247
Iteration 299/1000 | Loss: 0.00002247
Iteration 300/1000 | Loss: 0.00002247
Iteration 301/1000 | Loss: 0.00002247
Iteration 302/1000 | Loss: 0.00002247
Iteration 303/1000 | Loss: 0.00002247
Iteration 304/1000 | Loss: 0.00002247
Iteration 305/1000 | Loss: 0.00002247
Iteration 306/1000 | Loss: 0.00002247
Iteration 307/1000 | Loss: 0.00002247
Iteration 308/1000 | Loss: 0.00002247
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 308. Stopping optimization.
Last 5 losses: [2.2468704628408886e-05, 2.2468704628408886e-05, 2.2468704628408886e-05, 2.2468704628408886e-05, 2.2468704628408886e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2468704628408886e-05

Optimization complete. Final v2v error: 4.0309529304504395 mm

Highest mean error: 6.239535808563232 mm for frame 0

Lowest mean error: 3.626966953277588 mm for frame 15

Saving results

Total time: 333.6434655189514
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00575672
Iteration 2/25 | Loss: 0.00112236
Iteration 3/25 | Loss: 0.00093018
Iteration 4/25 | Loss: 0.00089561
Iteration 5/25 | Loss: 0.00089044
Iteration 6/25 | Loss: 0.00088960
Iteration 7/25 | Loss: 0.00088960
Iteration 8/25 | Loss: 0.00088960
Iteration 9/25 | Loss: 0.00088960
Iteration 10/25 | Loss: 0.00088960
Iteration 11/25 | Loss: 0.00088960
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008896003710106015, 0.0008896003710106015, 0.0008896003710106015, 0.0008896003710106015, 0.0008896003710106015]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008896003710106015

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.67687529
Iteration 2/25 | Loss: 0.00046464
Iteration 3/25 | Loss: 0.00046464
Iteration 4/25 | Loss: 0.00046464
Iteration 5/25 | Loss: 0.00046464
Iteration 6/25 | Loss: 0.00046463
Iteration 7/25 | Loss: 0.00046463
Iteration 8/25 | Loss: 0.00046463
Iteration 9/25 | Loss: 0.00046463
Iteration 10/25 | Loss: 0.00046463
Iteration 11/25 | Loss: 0.00046463
Iteration 12/25 | Loss: 0.00046463
Iteration 13/25 | Loss: 0.00046463
Iteration 14/25 | Loss: 0.00046463
Iteration 15/25 | Loss: 0.00046463
Iteration 16/25 | Loss: 0.00046463
Iteration 17/25 | Loss: 0.00046463
Iteration 18/25 | Loss: 0.00046463
Iteration 19/25 | Loss: 0.00046463
Iteration 20/25 | Loss: 0.00046463
Iteration 21/25 | Loss: 0.00046463
Iteration 22/25 | Loss: 0.00046463
Iteration 23/25 | Loss: 0.00046463
Iteration 24/25 | Loss: 0.00046463
Iteration 25/25 | Loss: 0.00046463

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046463
Iteration 2/1000 | Loss: 0.00003295
Iteration 3/1000 | Loss: 0.00002597
Iteration 4/1000 | Loss: 0.00002435
Iteration 5/1000 | Loss: 0.00002303
Iteration 6/1000 | Loss: 0.00002214
Iteration 7/1000 | Loss: 0.00002172
Iteration 8/1000 | Loss: 0.00002138
Iteration 9/1000 | Loss: 0.00002117
Iteration 10/1000 | Loss: 0.00002101
Iteration 11/1000 | Loss: 0.00002082
Iteration 12/1000 | Loss: 0.00002060
Iteration 13/1000 | Loss: 0.00002043
Iteration 14/1000 | Loss: 0.00002031
Iteration 15/1000 | Loss: 0.00002022
Iteration 16/1000 | Loss: 0.00002021
Iteration 17/1000 | Loss: 0.00002021
Iteration 18/1000 | Loss: 0.00002020
Iteration 19/1000 | Loss: 0.00002019
Iteration 20/1000 | Loss: 0.00002018
Iteration 21/1000 | Loss: 0.00002018
Iteration 22/1000 | Loss: 0.00002018
Iteration 23/1000 | Loss: 0.00002014
Iteration 24/1000 | Loss: 0.00002012
Iteration 25/1000 | Loss: 0.00002012
Iteration 26/1000 | Loss: 0.00002011
Iteration 27/1000 | Loss: 0.00002010
Iteration 28/1000 | Loss: 0.00002010
Iteration 29/1000 | Loss: 0.00002008
Iteration 30/1000 | Loss: 0.00002008
Iteration 31/1000 | Loss: 0.00002008
Iteration 32/1000 | Loss: 0.00002008
Iteration 33/1000 | Loss: 0.00002008
Iteration 34/1000 | Loss: 0.00002008
Iteration 35/1000 | Loss: 0.00002007
Iteration 36/1000 | Loss: 0.00002006
Iteration 37/1000 | Loss: 0.00002005
Iteration 38/1000 | Loss: 0.00002005
Iteration 39/1000 | Loss: 0.00002004
Iteration 40/1000 | Loss: 0.00002004
Iteration 41/1000 | Loss: 0.00002004
Iteration 42/1000 | Loss: 0.00002004
Iteration 43/1000 | Loss: 0.00002004
Iteration 44/1000 | Loss: 0.00002004
Iteration 45/1000 | Loss: 0.00002002
Iteration 46/1000 | Loss: 0.00002001
Iteration 47/1000 | Loss: 0.00002000
Iteration 48/1000 | Loss: 0.00002000
Iteration 49/1000 | Loss: 0.00001999
Iteration 50/1000 | Loss: 0.00001999
Iteration 51/1000 | Loss: 0.00001998
Iteration 52/1000 | Loss: 0.00001996
Iteration 53/1000 | Loss: 0.00001996
Iteration 54/1000 | Loss: 0.00001996
Iteration 55/1000 | Loss: 0.00001996
Iteration 56/1000 | Loss: 0.00001996
Iteration 57/1000 | Loss: 0.00001996
Iteration 58/1000 | Loss: 0.00001996
Iteration 59/1000 | Loss: 0.00001996
Iteration 60/1000 | Loss: 0.00001996
Iteration 61/1000 | Loss: 0.00001996
Iteration 62/1000 | Loss: 0.00001995
Iteration 63/1000 | Loss: 0.00001995
Iteration 64/1000 | Loss: 0.00001995
Iteration 65/1000 | Loss: 0.00001994
Iteration 66/1000 | Loss: 0.00001994
Iteration 67/1000 | Loss: 0.00001994
Iteration 68/1000 | Loss: 0.00001993
Iteration 69/1000 | Loss: 0.00001993
Iteration 70/1000 | Loss: 0.00001992
Iteration 71/1000 | Loss: 0.00001992
Iteration 72/1000 | Loss: 0.00001992
Iteration 73/1000 | Loss: 0.00001992
Iteration 74/1000 | Loss: 0.00001992
Iteration 75/1000 | Loss: 0.00001992
Iteration 76/1000 | Loss: 0.00001992
Iteration 77/1000 | Loss: 0.00001992
Iteration 78/1000 | Loss: 0.00001992
Iteration 79/1000 | Loss: 0.00001991
Iteration 80/1000 | Loss: 0.00001991
Iteration 81/1000 | Loss: 0.00001991
Iteration 82/1000 | Loss: 0.00001991
Iteration 83/1000 | Loss: 0.00001991
Iteration 84/1000 | Loss: 0.00001991
Iteration 85/1000 | Loss: 0.00001991
Iteration 86/1000 | Loss: 0.00001991
Iteration 87/1000 | Loss: 0.00001991
Iteration 88/1000 | Loss: 0.00001991
Iteration 89/1000 | Loss: 0.00001991
Iteration 90/1000 | Loss: 0.00001991
Iteration 91/1000 | Loss: 0.00001991
Iteration 92/1000 | Loss: 0.00001991
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [1.9913515643565916e-05, 1.9913515643565916e-05, 1.9913515643565916e-05, 1.9913515643565916e-05, 1.9913515643565916e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9913515643565916e-05

Optimization complete. Final v2v error: 3.699955940246582 mm

Highest mean error: 3.783149242401123 mm for frame 26

Lowest mean error: 3.6289734840393066 mm for frame 183

Saving results

Total time: 43.76144218444824
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1072/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1072.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1072
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00409337
Iteration 2/25 | Loss: 0.00120070
Iteration 3/25 | Loss: 0.00090431
Iteration 4/25 | Loss: 0.00084366
Iteration 5/25 | Loss: 0.00082837
Iteration 6/25 | Loss: 0.00082433
Iteration 7/25 | Loss: 0.00082296
Iteration 8/25 | Loss: 0.00082291
Iteration 9/25 | Loss: 0.00082291
Iteration 10/25 | Loss: 0.00082291
Iteration 11/25 | Loss: 0.00082291
Iteration 12/25 | Loss: 0.00082291
Iteration 13/25 | Loss: 0.00082291
Iteration 14/25 | Loss: 0.00082291
Iteration 15/25 | Loss: 0.00082291
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008229068480432034, 0.0008229068480432034, 0.0008229068480432034, 0.0008229068480432034, 0.0008229068480432034]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008229068480432034

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52034950
Iteration 2/25 | Loss: 0.00057031
Iteration 3/25 | Loss: 0.00057031
Iteration 4/25 | Loss: 0.00057031
Iteration 5/25 | Loss: 0.00057031
Iteration 6/25 | Loss: 0.00057031
Iteration 7/25 | Loss: 0.00057031
Iteration 8/25 | Loss: 0.00057031
Iteration 9/25 | Loss: 0.00057031
Iteration 10/25 | Loss: 0.00057031
Iteration 11/25 | Loss: 0.00057031
Iteration 12/25 | Loss: 0.00057031
Iteration 13/25 | Loss: 0.00057031
Iteration 14/25 | Loss: 0.00057031
Iteration 15/25 | Loss: 0.00057031
Iteration 16/25 | Loss: 0.00057031
Iteration 17/25 | Loss: 0.00057031
Iteration 18/25 | Loss: 0.00057031
Iteration 19/25 | Loss: 0.00057031
Iteration 20/25 | Loss: 0.00057031
Iteration 21/25 | Loss: 0.00057031
Iteration 22/25 | Loss: 0.00057031
Iteration 23/25 | Loss: 0.00057031
Iteration 24/25 | Loss: 0.00057031
Iteration 25/25 | Loss: 0.00057031

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00057031
Iteration 2/1000 | Loss: 0.00002098
Iteration 3/1000 | Loss: 0.00001454
Iteration 4/1000 | Loss: 0.00001336
Iteration 5/1000 | Loss: 0.00001244
Iteration 6/1000 | Loss: 0.00001192
Iteration 7/1000 | Loss: 0.00001156
Iteration 8/1000 | Loss: 0.00001133
Iteration 9/1000 | Loss: 0.00001130
Iteration 10/1000 | Loss: 0.00001120
Iteration 11/1000 | Loss: 0.00001108
Iteration 12/1000 | Loss: 0.00001102
Iteration 13/1000 | Loss: 0.00001101
Iteration 14/1000 | Loss: 0.00001094
Iteration 15/1000 | Loss: 0.00001088
Iteration 16/1000 | Loss: 0.00001088
Iteration 17/1000 | Loss: 0.00001086
Iteration 18/1000 | Loss: 0.00001082
Iteration 19/1000 | Loss: 0.00001081
Iteration 20/1000 | Loss: 0.00001080
Iteration 21/1000 | Loss: 0.00001080
Iteration 22/1000 | Loss: 0.00001078
Iteration 23/1000 | Loss: 0.00001077
Iteration 24/1000 | Loss: 0.00001077
Iteration 25/1000 | Loss: 0.00001076
Iteration 26/1000 | Loss: 0.00001076
Iteration 27/1000 | Loss: 0.00001075
Iteration 28/1000 | Loss: 0.00001074
Iteration 29/1000 | Loss: 0.00001074
Iteration 30/1000 | Loss: 0.00001073
Iteration 31/1000 | Loss: 0.00001072
Iteration 32/1000 | Loss: 0.00001072
Iteration 33/1000 | Loss: 0.00001072
Iteration 34/1000 | Loss: 0.00001072
Iteration 35/1000 | Loss: 0.00001072
Iteration 36/1000 | Loss: 0.00001071
Iteration 37/1000 | Loss: 0.00001071
Iteration 38/1000 | Loss: 0.00001071
Iteration 39/1000 | Loss: 0.00001071
Iteration 40/1000 | Loss: 0.00001071
Iteration 41/1000 | Loss: 0.00001071
Iteration 42/1000 | Loss: 0.00001070
Iteration 43/1000 | Loss: 0.00001069
Iteration 44/1000 | Loss: 0.00001068
Iteration 45/1000 | Loss: 0.00001068
Iteration 46/1000 | Loss: 0.00001068
Iteration 47/1000 | Loss: 0.00001068
Iteration 48/1000 | Loss: 0.00001068
Iteration 49/1000 | Loss: 0.00001068
Iteration 50/1000 | Loss: 0.00001068
Iteration 51/1000 | Loss: 0.00001068
Iteration 52/1000 | Loss: 0.00001068
Iteration 53/1000 | Loss: 0.00001068
Iteration 54/1000 | Loss: 0.00001068
Iteration 55/1000 | Loss: 0.00001068
Iteration 56/1000 | Loss: 0.00001067
Iteration 57/1000 | Loss: 0.00001066
Iteration 58/1000 | Loss: 0.00001066
Iteration 59/1000 | Loss: 0.00001066
Iteration 60/1000 | Loss: 0.00001066
Iteration 61/1000 | Loss: 0.00001065
Iteration 62/1000 | Loss: 0.00001065
Iteration 63/1000 | Loss: 0.00001065
Iteration 64/1000 | Loss: 0.00001065
Iteration 65/1000 | Loss: 0.00001065
Iteration 66/1000 | Loss: 0.00001065
Iteration 67/1000 | Loss: 0.00001065
Iteration 68/1000 | Loss: 0.00001065
Iteration 69/1000 | Loss: 0.00001065
Iteration 70/1000 | Loss: 0.00001065
Iteration 71/1000 | Loss: 0.00001065
Iteration 72/1000 | Loss: 0.00001064
Iteration 73/1000 | Loss: 0.00001064
Iteration 74/1000 | Loss: 0.00001064
Iteration 75/1000 | Loss: 0.00001064
Iteration 76/1000 | Loss: 0.00001064
Iteration 77/1000 | Loss: 0.00001064
Iteration 78/1000 | Loss: 0.00001064
Iteration 79/1000 | Loss: 0.00001064
Iteration 80/1000 | Loss: 0.00001064
Iteration 81/1000 | Loss: 0.00001064
Iteration 82/1000 | Loss: 0.00001063
Iteration 83/1000 | Loss: 0.00001063
Iteration 84/1000 | Loss: 0.00001063
Iteration 85/1000 | Loss: 0.00001063
Iteration 86/1000 | Loss: 0.00001063
Iteration 87/1000 | Loss: 0.00001063
Iteration 88/1000 | Loss: 0.00001062
Iteration 89/1000 | Loss: 0.00001062
Iteration 90/1000 | Loss: 0.00001062
Iteration 91/1000 | Loss: 0.00001062
Iteration 92/1000 | Loss: 0.00001062
Iteration 93/1000 | Loss: 0.00001062
Iteration 94/1000 | Loss: 0.00001062
Iteration 95/1000 | Loss: 0.00001062
Iteration 96/1000 | Loss: 0.00001062
Iteration 97/1000 | Loss: 0.00001062
Iteration 98/1000 | Loss: 0.00001062
Iteration 99/1000 | Loss: 0.00001062
Iteration 100/1000 | Loss: 0.00001062
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 100. Stopping optimization.
Last 5 losses: [1.0624612514220644e-05, 1.0624612514220644e-05, 1.0624612514220644e-05, 1.0624612514220644e-05, 1.0624612514220644e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0624612514220644e-05

Optimization complete. Final v2v error: 2.7942488193511963 mm

Highest mean error: 3.6201465129852295 mm for frame 76

Lowest mean error: 2.5839688777923584 mm for frame 165

Saving results

Total time: 34.331358432769775
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1030
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00839961
Iteration 2/25 | Loss: 0.00181606
Iteration 3/25 | Loss: 0.00103475
Iteration 4/25 | Loss: 0.00093032
Iteration 5/25 | Loss: 0.00091795
Iteration 6/25 | Loss: 0.00091470
Iteration 7/25 | Loss: 0.00091417
Iteration 8/25 | Loss: 0.00091417
Iteration 9/25 | Loss: 0.00091417
Iteration 10/25 | Loss: 0.00091417
Iteration 11/25 | Loss: 0.00091417
Iteration 12/25 | Loss: 0.00091417
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009141729678958654, 0.0009141729678958654, 0.0009141729678958654, 0.0009141729678958654, 0.0009141729678958654]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009141729678958654

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.88646734
Iteration 2/25 | Loss: 0.00076129
Iteration 3/25 | Loss: 0.00076129
Iteration 4/25 | Loss: 0.00076129
Iteration 5/25 | Loss: 0.00076129
Iteration 6/25 | Loss: 0.00076129
Iteration 7/25 | Loss: 0.00076128
Iteration 8/25 | Loss: 0.00076128
Iteration 9/25 | Loss: 0.00076128
Iteration 10/25 | Loss: 0.00076128
Iteration 11/25 | Loss: 0.00076128
Iteration 12/25 | Loss: 0.00076128
Iteration 13/25 | Loss: 0.00076128
Iteration 14/25 | Loss: 0.00076128
Iteration 15/25 | Loss: 0.00076128
Iteration 16/25 | Loss: 0.00076128
Iteration 17/25 | Loss: 0.00076128
Iteration 18/25 | Loss: 0.00076128
Iteration 19/25 | Loss: 0.00076128
Iteration 20/25 | Loss: 0.00076128
Iteration 21/25 | Loss: 0.00076128
Iteration 22/25 | Loss: 0.00076128
Iteration 23/25 | Loss: 0.00076128
Iteration 24/25 | Loss: 0.00076128
Iteration 25/25 | Loss: 0.00076128

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00076128
Iteration 2/1000 | Loss: 0.00002655
Iteration 3/1000 | Loss: 0.00001891
Iteration 4/1000 | Loss: 0.00001757
Iteration 5/1000 | Loss: 0.00001666
Iteration 6/1000 | Loss: 0.00001607
Iteration 7/1000 | Loss: 0.00001589
Iteration 8/1000 | Loss: 0.00001575
Iteration 9/1000 | Loss: 0.00001558
Iteration 10/1000 | Loss: 0.00001554
Iteration 11/1000 | Loss: 0.00001551
Iteration 12/1000 | Loss: 0.00001551
Iteration 13/1000 | Loss: 0.00001550
Iteration 14/1000 | Loss: 0.00001550
Iteration 15/1000 | Loss: 0.00001550
Iteration 16/1000 | Loss: 0.00001550
Iteration 17/1000 | Loss: 0.00001550
Iteration 18/1000 | Loss: 0.00001550
Iteration 19/1000 | Loss: 0.00001550
Iteration 20/1000 | Loss: 0.00001550
Iteration 21/1000 | Loss: 0.00001550
Iteration 22/1000 | Loss: 0.00001550
Iteration 23/1000 | Loss: 0.00001550
Iteration 24/1000 | Loss: 0.00001548
Iteration 25/1000 | Loss: 0.00001546
Iteration 26/1000 | Loss: 0.00001545
Iteration 27/1000 | Loss: 0.00001545
Iteration 28/1000 | Loss: 0.00001544
Iteration 29/1000 | Loss: 0.00001541
Iteration 30/1000 | Loss: 0.00001541
Iteration 31/1000 | Loss: 0.00001540
Iteration 32/1000 | Loss: 0.00001539
Iteration 33/1000 | Loss: 0.00001537
Iteration 34/1000 | Loss: 0.00001536
Iteration 35/1000 | Loss: 0.00001536
Iteration 36/1000 | Loss: 0.00001535
Iteration 37/1000 | Loss: 0.00001533
Iteration 38/1000 | Loss: 0.00001527
Iteration 39/1000 | Loss: 0.00001526
Iteration 40/1000 | Loss: 0.00001525
Iteration 41/1000 | Loss: 0.00001524
Iteration 42/1000 | Loss: 0.00001524
Iteration 43/1000 | Loss: 0.00001524
Iteration 44/1000 | Loss: 0.00001524
Iteration 45/1000 | Loss: 0.00001523
Iteration 46/1000 | Loss: 0.00001522
Iteration 47/1000 | Loss: 0.00001522
Iteration 48/1000 | Loss: 0.00001522
Iteration 49/1000 | Loss: 0.00001522
Iteration 50/1000 | Loss: 0.00001522
Iteration 51/1000 | Loss: 0.00001522
Iteration 52/1000 | Loss: 0.00001522
Iteration 53/1000 | Loss: 0.00001522
Iteration 54/1000 | Loss: 0.00001521
Iteration 55/1000 | Loss: 0.00001521
Iteration 56/1000 | Loss: 0.00001521
Iteration 57/1000 | Loss: 0.00001521
Iteration 58/1000 | Loss: 0.00001521
Iteration 59/1000 | Loss: 0.00001521
Iteration 60/1000 | Loss: 0.00001521
Iteration 61/1000 | Loss: 0.00001521
Iteration 62/1000 | Loss: 0.00001521
Iteration 63/1000 | Loss: 0.00001520
Iteration 64/1000 | Loss: 0.00001520
Iteration 65/1000 | Loss: 0.00001519
Iteration 66/1000 | Loss: 0.00001519
Iteration 67/1000 | Loss: 0.00001518
Iteration 68/1000 | Loss: 0.00001518
Iteration 69/1000 | Loss: 0.00001518
Iteration 70/1000 | Loss: 0.00001518
Iteration 71/1000 | Loss: 0.00001518
Iteration 72/1000 | Loss: 0.00001518
Iteration 73/1000 | Loss: 0.00001518
Iteration 74/1000 | Loss: 0.00001518
Iteration 75/1000 | Loss: 0.00001518
Iteration 76/1000 | Loss: 0.00001518
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [1.5180277841864154e-05, 1.5180277841864154e-05, 1.5180277841864154e-05, 1.5180277841864154e-05, 1.5180277841864154e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5180277841864154e-05

Optimization complete. Final v2v error: 3.2711591720581055 mm

Highest mean error: 3.5848968029022217 mm for frame 3

Lowest mean error: 3.028310537338257 mm for frame 124

Saving results

Total time: 32.97608137130737
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1061/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1061.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1061
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00559969
Iteration 2/25 | Loss: 0.00119631
Iteration 3/25 | Loss: 0.00093775
Iteration 4/25 | Loss: 0.00090627
Iteration 5/25 | Loss: 0.00089505
Iteration 6/25 | Loss: 0.00089299
Iteration 7/25 | Loss: 0.00089262
Iteration 8/25 | Loss: 0.00089262
Iteration 9/25 | Loss: 0.00089262
Iteration 10/25 | Loss: 0.00089262
Iteration 11/25 | Loss: 0.00089262
Iteration 12/25 | Loss: 0.00089262
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008926164009608328, 0.0008926164009608328, 0.0008926164009608328, 0.0008926164009608328, 0.0008926164009608328]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008926164009608328

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.24131703
Iteration 2/25 | Loss: 0.00052963
Iteration 3/25 | Loss: 0.00052960
Iteration 4/25 | Loss: 0.00052960
Iteration 5/25 | Loss: 0.00052960
Iteration 6/25 | Loss: 0.00052960
Iteration 7/25 | Loss: 0.00052960
Iteration 8/25 | Loss: 0.00052960
Iteration 9/25 | Loss: 0.00052960
Iteration 10/25 | Loss: 0.00052960
Iteration 11/25 | Loss: 0.00052960
Iteration 12/25 | Loss: 0.00052960
Iteration 13/25 | Loss: 0.00052960
Iteration 14/25 | Loss: 0.00052960
Iteration 15/25 | Loss: 0.00052960
Iteration 16/25 | Loss: 0.00052960
Iteration 17/25 | Loss: 0.00052960
Iteration 18/25 | Loss: 0.00052960
Iteration 19/25 | Loss: 0.00052960
Iteration 20/25 | Loss: 0.00052960
Iteration 21/25 | Loss: 0.00052960
Iteration 22/25 | Loss: 0.00052960
Iteration 23/25 | Loss: 0.00052960
Iteration 24/25 | Loss: 0.00052960
Iteration 25/25 | Loss: 0.00052960

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052960
Iteration 2/1000 | Loss: 0.00003322
Iteration 3/1000 | Loss: 0.00002431
Iteration 4/1000 | Loss: 0.00002195
Iteration 5/1000 | Loss: 0.00002086
Iteration 6/1000 | Loss: 0.00002016
Iteration 7/1000 | Loss: 0.00001960
Iteration 8/1000 | Loss: 0.00001923
Iteration 9/1000 | Loss: 0.00001894
Iteration 10/1000 | Loss: 0.00001877
Iteration 11/1000 | Loss: 0.00001855
Iteration 12/1000 | Loss: 0.00001843
Iteration 13/1000 | Loss: 0.00001839
Iteration 14/1000 | Loss: 0.00001837
Iteration 15/1000 | Loss: 0.00001835
Iteration 16/1000 | Loss: 0.00001835
Iteration 17/1000 | Loss: 0.00001834
Iteration 18/1000 | Loss: 0.00001832
Iteration 19/1000 | Loss: 0.00001832
Iteration 20/1000 | Loss: 0.00001832
Iteration 21/1000 | Loss: 0.00001832
Iteration 22/1000 | Loss: 0.00001832
Iteration 23/1000 | Loss: 0.00001832
Iteration 24/1000 | Loss: 0.00001831
Iteration 25/1000 | Loss: 0.00001830
Iteration 26/1000 | Loss: 0.00001828
Iteration 27/1000 | Loss: 0.00001828
Iteration 28/1000 | Loss: 0.00001828
Iteration 29/1000 | Loss: 0.00001827
Iteration 30/1000 | Loss: 0.00001827
Iteration 31/1000 | Loss: 0.00001826
Iteration 32/1000 | Loss: 0.00001826
Iteration 33/1000 | Loss: 0.00001826
Iteration 34/1000 | Loss: 0.00001825
Iteration 35/1000 | Loss: 0.00001825
Iteration 36/1000 | Loss: 0.00001825
Iteration 37/1000 | Loss: 0.00001825
Iteration 38/1000 | Loss: 0.00001825
Iteration 39/1000 | Loss: 0.00001825
Iteration 40/1000 | Loss: 0.00001825
Iteration 41/1000 | Loss: 0.00001825
Iteration 42/1000 | Loss: 0.00001825
Iteration 43/1000 | Loss: 0.00001825
Iteration 44/1000 | Loss: 0.00001824
Iteration 45/1000 | Loss: 0.00001824
Iteration 46/1000 | Loss: 0.00001824
Iteration 47/1000 | Loss: 0.00001823
Iteration 48/1000 | Loss: 0.00001823
Iteration 49/1000 | Loss: 0.00001823
Iteration 50/1000 | Loss: 0.00001823
Iteration 51/1000 | Loss: 0.00001823
Iteration 52/1000 | Loss: 0.00001823
Iteration 53/1000 | Loss: 0.00001823
Iteration 54/1000 | Loss: 0.00001823
Iteration 55/1000 | Loss: 0.00001823
Iteration 56/1000 | Loss: 0.00001823
Iteration 57/1000 | Loss: 0.00001823
Iteration 58/1000 | Loss: 0.00001822
Iteration 59/1000 | Loss: 0.00001822
Iteration 60/1000 | Loss: 0.00001821
Iteration 61/1000 | Loss: 0.00001821
Iteration 62/1000 | Loss: 0.00001821
Iteration 63/1000 | Loss: 0.00001821
Iteration 64/1000 | Loss: 0.00001821
Iteration 65/1000 | Loss: 0.00001821
Iteration 66/1000 | Loss: 0.00001820
Iteration 67/1000 | Loss: 0.00001820
Iteration 68/1000 | Loss: 0.00001820
Iteration 69/1000 | Loss: 0.00001820
Iteration 70/1000 | Loss: 0.00001820
Iteration 71/1000 | Loss: 0.00001820
Iteration 72/1000 | Loss: 0.00001820
Iteration 73/1000 | Loss: 0.00001819
Iteration 74/1000 | Loss: 0.00001819
Iteration 75/1000 | Loss: 0.00001819
Iteration 76/1000 | Loss: 0.00001819
Iteration 77/1000 | Loss: 0.00001819
Iteration 78/1000 | Loss: 0.00001819
Iteration 79/1000 | Loss: 0.00001819
Iteration 80/1000 | Loss: 0.00001819
Iteration 81/1000 | Loss: 0.00001819
Iteration 82/1000 | Loss: 0.00001819
Iteration 83/1000 | Loss: 0.00001819
Iteration 84/1000 | Loss: 0.00001818
Iteration 85/1000 | Loss: 0.00001818
Iteration 86/1000 | Loss: 0.00001818
Iteration 87/1000 | Loss: 0.00001818
Iteration 88/1000 | Loss: 0.00001818
Iteration 89/1000 | Loss: 0.00001818
Iteration 90/1000 | Loss: 0.00001817
Iteration 91/1000 | Loss: 0.00001817
Iteration 92/1000 | Loss: 0.00001817
Iteration 93/1000 | Loss: 0.00001817
Iteration 94/1000 | Loss: 0.00001817
Iteration 95/1000 | Loss: 0.00001817
Iteration 96/1000 | Loss: 0.00001816
Iteration 97/1000 | Loss: 0.00001816
Iteration 98/1000 | Loss: 0.00001816
Iteration 99/1000 | Loss: 0.00001815
Iteration 100/1000 | Loss: 0.00001815
Iteration 101/1000 | Loss: 0.00001815
Iteration 102/1000 | Loss: 0.00001814
Iteration 103/1000 | Loss: 0.00001814
Iteration 104/1000 | Loss: 0.00001814
Iteration 105/1000 | Loss: 0.00001814
Iteration 106/1000 | Loss: 0.00001814
Iteration 107/1000 | Loss: 0.00001813
Iteration 108/1000 | Loss: 0.00001813
Iteration 109/1000 | Loss: 0.00001813
Iteration 110/1000 | Loss: 0.00001813
Iteration 111/1000 | Loss: 0.00001813
Iteration 112/1000 | Loss: 0.00001813
Iteration 113/1000 | Loss: 0.00001813
Iteration 114/1000 | Loss: 0.00001813
Iteration 115/1000 | Loss: 0.00001813
Iteration 116/1000 | Loss: 0.00001813
Iteration 117/1000 | Loss: 0.00001813
Iteration 118/1000 | Loss: 0.00001812
Iteration 119/1000 | Loss: 0.00001812
Iteration 120/1000 | Loss: 0.00001812
Iteration 121/1000 | Loss: 0.00001812
Iteration 122/1000 | Loss: 0.00001812
Iteration 123/1000 | Loss: 0.00001812
Iteration 124/1000 | Loss: 0.00001812
Iteration 125/1000 | Loss: 0.00001812
Iteration 126/1000 | Loss: 0.00001812
Iteration 127/1000 | Loss: 0.00001812
Iteration 128/1000 | Loss: 0.00001812
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [1.8124330381397158e-05, 1.8124330381397158e-05, 1.8124330381397158e-05, 1.8124330381397158e-05, 1.8124330381397158e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8124330381397158e-05

Optimization complete. Final v2v error: 3.6574618816375732 mm

Highest mean error: 4.028656959533691 mm for frame 50

Lowest mean error: 3.313236713409424 mm for frame 75

Saving results

Total time: 40.874131202697754
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1082/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1082.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1082
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00519873
Iteration 2/25 | Loss: 0.00105816
Iteration 3/25 | Loss: 0.00089654
Iteration 4/25 | Loss: 0.00087195
Iteration 5/25 | Loss: 0.00086779
Iteration 6/25 | Loss: 0.00086729
Iteration 7/25 | Loss: 0.00086729
Iteration 8/25 | Loss: 0.00086729
Iteration 9/25 | Loss: 0.00086729
Iteration 10/25 | Loss: 0.00086729
Iteration 11/25 | Loss: 0.00086729
Iteration 12/25 | Loss: 0.00086729
Iteration 13/25 | Loss: 0.00086729
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008672903059050441, 0.0008672903059050441, 0.0008672903059050441, 0.0008672903059050441, 0.0008672903059050441]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008672903059050441

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.89032078
Iteration 2/25 | Loss: 0.00050768
Iteration 3/25 | Loss: 0.00050767
Iteration 4/25 | Loss: 0.00050767
Iteration 5/25 | Loss: 0.00050767
Iteration 6/25 | Loss: 0.00050767
Iteration 7/25 | Loss: 0.00050767
Iteration 8/25 | Loss: 0.00050767
Iteration 9/25 | Loss: 0.00050767
Iteration 10/25 | Loss: 0.00050767
Iteration 11/25 | Loss: 0.00050767
Iteration 12/25 | Loss: 0.00050767
Iteration 13/25 | Loss: 0.00050767
Iteration 14/25 | Loss: 0.00050767
Iteration 15/25 | Loss: 0.00050767
Iteration 16/25 | Loss: 0.00050767
Iteration 17/25 | Loss: 0.00050767
Iteration 18/25 | Loss: 0.00050767
Iteration 19/25 | Loss: 0.00050767
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0005076650995761156, 0.0005076650995761156, 0.0005076650995761156, 0.0005076650995761156, 0.0005076650995761156]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005076650995761156

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050767
Iteration 2/1000 | Loss: 0.00002484
Iteration 3/1000 | Loss: 0.00001830
Iteration 4/1000 | Loss: 0.00001694
Iteration 5/1000 | Loss: 0.00001630
Iteration 6/1000 | Loss: 0.00001592
Iteration 7/1000 | Loss: 0.00001553
Iteration 8/1000 | Loss: 0.00001552
Iteration 9/1000 | Loss: 0.00001544
Iteration 10/1000 | Loss: 0.00001519
Iteration 11/1000 | Loss: 0.00001503
Iteration 12/1000 | Loss: 0.00001499
Iteration 13/1000 | Loss: 0.00001498
Iteration 14/1000 | Loss: 0.00001480
Iteration 15/1000 | Loss: 0.00001480
Iteration 16/1000 | Loss: 0.00001467
Iteration 17/1000 | Loss: 0.00001466
Iteration 18/1000 | Loss: 0.00001466
Iteration 19/1000 | Loss: 0.00001466
Iteration 20/1000 | Loss: 0.00001465
Iteration 21/1000 | Loss: 0.00001465
Iteration 22/1000 | Loss: 0.00001465
Iteration 23/1000 | Loss: 0.00001465
Iteration 24/1000 | Loss: 0.00001462
Iteration 25/1000 | Loss: 0.00001462
Iteration 26/1000 | Loss: 0.00001462
Iteration 27/1000 | Loss: 0.00001462
Iteration 28/1000 | Loss: 0.00001462
Iteration 29/1000 | Loss: 0.00001462
Iteration 30/1000 | Loss: 0.00001462
Iteration 31/1000 | Loss: 0.00001462
Iteration 32/1000 | Loss: 0.00001462
Iteration 33/1000 | Loss: 0.00001461
Iteration 34/1000 | Loss: 0.00001461
Iteration 35/1000 | Loss: 0.00001461
Iteration 36/1000 | Loss: 0.00001459
Iteration 37/1000 | Loss: 0.00001459
Iteration 38/1000 | Loss: 0.00001456
Iteration 39/1000 | Loss: 0.00001456
Iteration 40/1000 | Loss: 0.00001455
Iteration 41/1000 | Loss: 0.00001455
Iteration 42/1000 | Loss: 0.00001454
Iteration 43/1000 | Loss: 0.00001454
Iteration 44/1000 | Loss: 0.00001454
Iteration 45/1000 | Loss: 0.00001454
Iteration 46/1000 | Loss: 0.00001454
Iteration 47/1000 | Loss: 0.00001454
Iteration 48/1000 | Loss: 0.00001453
Iteration 49/1000 | Loss: 0.00001453
Iteration 50/1000 | Loss: 0.00001453
Iteration 51/1000 | Loss: 0.00001453
Iteration 52/1000 | Loss: 0.00001453
Iteration 53/1000 | Loss: 0.00001453
Iteration 54/1000 | Loss: 0.00001453
Iteration 55/1000 | Loss: 0.00001453
Iteration 56/1000 | Loss: 0.00001453
Iteration 57/1000 | Loss: 0.00001453
Iteration 58/1000 | Loss: 0.00001453
Iteration 59/1000 | Loss: 0.00001453
Iteration 60/1000 | Loss: 0.00001453
Iteration 61/1000 | Loss: 0.00001452
Iteration 62/1000 | Loss: 0.00001452
Iteration 63/1000 | Loss: 0.00001452
Iteration 64/1000 | Loss: 0.00001452
Iteration 65/1000 | Loss: 0.00001452
Iteration 66/1000 | Loss: 0.00001452
Iteration 67/1000 | Loss: 0.00001452
Iteration 68/1000 | Loss: 0.00001452
Iteration 69/1000 | Loss: 0.00001451
Iteration 70/1000 | Loss: 0.00001451
Iteration 71/1000 | Loss: 0.00001451
Iteration 72/1000 | Loss: 0.00001450
Iteration 73/1000 | Loss: 0.00001450
Iteration 74/1000 | Loss: 0.00001450
Iteration 75/1000 | Loss: 0.00001449
Iteration 76/1000 | Loss: 0.00001449
Iteration 77/1000 | Loss: 0.00001449
Iteration 78/1000 | Loss: 0.00001449
Iteration 79/1000 | Loss: 0.00001449
Iteration 80/1000 | Loss: 0.00001449
Iteration 81/1000 | Loss: 0.00001449
Iteration 82/1000 | Loss: 0.00001449
Iteration 83/1000 | Loss: 0.00001448
Iteration 84/1000 | Loss: 0.00001448
Iteration 85/1000 | Loss: 0.00001448
Iteration 86/1000 | Loss: 0.00001448
Iteration 87/1000 | Loss: 0.00001448
Iteration 88/1000 | Loss: 0.00001447
Iteration 89/1000 | Loss: 0.00001447
Iteration 90/1000 | Loss: 0.00001447
Iteration 91/1000 | Loss: 0.00001447
Iteration 92/1000 | Loss: 0.00001447
Iteration 93/1000 | Loss: 0.00001446
Iteration 94/1000 | Loss: 0.00001446
Iteration 95/1000 | Loss: 0.00001446
Iteration 96/1000 | Loss: 0.00001446
Iteration 97/1000 | Loss: 0.00001446
Iteration 98/1000 | Loss: 0.00001446
Iteration 99/1000 | Loss: 0.00001446
Iteration 100/1000 | Loss: 0.00001446
Iteration 101/1000 | Loss: 0.00001445
Iteration 102/1000 | Loss: 0.00001445
Iteration 103/1000 | Loss: 0.00001445
Iteration 104/1000 | Loss: 0.00001445
Iteration 105/1000 | Loss: 0.00001445
Iteration 106/1000 | Loss: 0.00001445
Iteration 107/1000 | Loss: 0.00001445
Iteration 108/1000 | Loss: 0.00001445
Iteration 109/1000 | Loss: 0.00001445
Iteration 110/1000 | Loss: 0.00001445
Iteration 111/1000 | Loss: 0.00001445
Iteration 112/1000 | Loss: 0.00001445
Iteration 113/1000 | Loss: 0.00001445
Iteration 114/1000 | Loss: 0.00001445
Iteration 115/1000 | Loss: 0.00001445
Iteration 116/1000 | Loss: 0.00001445
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 116. Stopping optimization.
Last 5 losses: [1.4453239600697998e-05, 1.4453239600697998e-05, 1.4453239600697998e-05, 1.4453239600697998e-05, 1.4453239600697998e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4453239600697998e-05

Optimization complete. Final v2v error: 3.2678024768829346 mm

Highest mean error: 3.3166403770446777 mm for frame 3

Lowest mean error: 3.204110860824585 mm for frame 264

Saving results

Total time: 36.98712778091431
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1067/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1067.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1067
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00871169
Iteration 2/25 | Loss: 0.00148870
Iteration 3/25 | Loss: 0.00112872
Iteration 4/25 | Loss: 0.00106355
Iteration 5/25 | Loss: 0.00104454
Iteration 6/25 | Loss: 0.00102738
Iteration 7/25 | Loss: 0.00105351
Iteration 8/25 | Loss: 0.00099310
Iteration 9/25 | Loss: 0.00097722
Iteration 10/25 | Loss: 0.00095155
Iteration 11/25 | Loss: 0.00095896
Iteration 12/25 | Loss: 0.00093316
Iteration 13/25 | Loss: 0.00091967
Iteration 14/25 | Loss: 0.00091759
Iteration 15/25 | Loss: 0.00091745
Iteration 16/25 | Loss: 0.00091744
Iteration 17/25 | Loss: 0.00091742
Iteration 18/25 | Loss: 0.00091742
Iteration 19/25 | Loss: 0.00091742
Iteration 20/25 | Loss: 0.00091742
Iteration 21/25 | Loss: 0.00091742
Iteration 22/25 | Loss: 0.00091742
Iteration 23/25 | Loss: 0.00091742
Iteration 24/25 | Loss: 0.00091742
Iteration 25/25 | Loss: 0.00091742

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.03842890
Iteration 2/25 | Loss: 0.00057480
Iteration 3/25 | Loss: 0.00057479
Iteration 4/25 | Loss: 0.00057479
Iteration 5/25 | Loss: 0.00057479
Iteration 6/25 | Loss: 0.00057479
Iteration 7/25 | Loss: 0.00057478
Iteration 8/25 | Loss: 0.00057478
Iteration 9/25 | Loss: 0.00057478
Iteration 10/25 | Loss: 0.00057478
Iteration 11/25 | Loss: 0.00057478
Iteration 12/25 | Loss: 0.00057478
Iteration 13/25 | Loss: 0.00057478
Iteration 14/25 | Loss: 0.00057478
Iteration 15/25 | Loss: 0.00057478
Iteration 16/25 | Loss: 0.00057478
Iteration 17/25 | Loss: 0.00057478
Iteration 18/25 | Loss: 0.00057478
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005747839459218085, 0.0005747839459218085, 0.0005747839459218085, 0.0005747839459218085, 0.0005747839459218085]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005747839459218085

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00057478
Iteration 2/1000 | Loss: 0.00003711
Iteration 3/1000 | Loss: 0.00003081
Iteration 4/1000 | Loss: 0.00002727
Iteration 5/1000 | Loss: 0.00002567
Iteration 6/1000 | Loss: 0.00002475
Iteration 7/1000 | Loss: 0.00002391
Iteration 8/1000 | Loss: 0.00002343
Iteration 9/1000 | Loss: 0.00002313
Iteration 10/1000 | Loss: 0.00002294
Iteration 11/1000 | Loss: 0.00002279
Iteration 12/1000 | Loss: 0.00002266
Iteration 13/1000 | Loss: 0.00002265
Iteration 14/1000 | Loss: 0.00002265
Iteration 15/1000 | Loss: 0.00002265
Iteration 16/1000 | Loss: 0.00002265
Iteration 17/1000 | Loss: 0.00002265
Iteration 18/1000 | Loss: 0.00002265
Iteration 19/1000 | Loss: 0.00002265
Iteration 20/1000 | Loss: 0.00002265
Iteration 21/1000 | Loss: 0.00002265
Iteration 22/1000 | Loss: 0.00002265
Iteration 23/1000 | Loss: 0.00002265
Iteration 24/1000 | Loss: 0.00002264
Iteration 25/1000 | Loss: 0.00002264
Iteration 26/1000 | Loss: 0.00002264
Iteration 27/1000 | Loss: 0.00002264
Iteration 28/1000 | Loss: 0.00002264
Iteration 29/1000 | Loss: 0.00002263
Iteration 30/1000 | Loss: 0.00002263
Iteration 31/1000 | Loss: 0.00002263
Iteration 32/1000 | Loss: 0.00002262
Iteration 33/1000 | Loss: 0.00002262
Iteration 34/1000 | Loss: 0.00002262
Iteration 35/1000 | Loss: 0.00002261
Iteration 36/1000 | Loss: 0.00002261
Iteration 37/1000 | Loss: 0.00002260
Iteration 38/1000 | Loss: 0.00002257
Iteration 39/1000 | Loss: 0.00002257
Iteration 40/1000 | Loss: 0.00002257
Iteration 41/1000 | Loss: 0.00002257
Iteration 42/1000 | Loss: 0.00002254
Iteration 43/1000 | Loss: 0.00002253
Iteration 44/1000 | Loss: 0.00002253
Iteration 45/1000 | Loss: 0.00002253
Iteration 46/1000 | Loss: 0.00002253
Iteration 47/1000 | Loss: 0.00002253
Iteration 48/1000 | Loss: 0.00002253
Iteration 49/1000 | Loss: 0.00002253
Iteration 50/1000 | Loss: 0.00002252
Iteration 51/1000 | Loss: 0.00002252
Iteration 52/1000 | Loss: 0.00002252
Iteration 53/1000 | Loss: 0.00002252
Iteration 54/1000 | Loss: 0.00002252
Iteration 55/1000 | Loss: 0.00002252
Iteration 56/1000 | Loss: 0.00002252
Iteration 57/1000 | Loss: 0.00002251
Iteration 58/1000 | Loss: 0.00002251
Iteration 59/1000 | Loss: 0.00002251
Iteration 60/1000 | Loss: 0.00002251
Iteration 61/1000 | Loss: 0.00002251
Iteration 62/1000 | Loss: 0.00002251
Iteration 63/1000 | Loss: 0.00002251
Iteration 64/1000 | Loss: 0.00002251
Iteration 65/1000 | Loss: 0.00002251
Iteration 66/1000 | Loss: 0.00002250
Iteration 67/1000 | Loss: 0.00002250
Iteration 68/1000 | Loss: 0.00002250
Iteration 69/1000 | Loss: 0.00002250
Iteration 70/1000 | Loss: 0.00002250
Iteration 71/1000 | Loss: 0.00002249
Iteration 72/1000 | Loss: 0.00002249
Iteration 73/1000 | Loss: 0.00002249
Iteration 74/1000 | Loss: 0.00002249
Iteration 75/1000 | Loss: 0.00002249
Iteration 76/1000 | Loss: 0.00002249
Iteration 77/1000 | Loss: 0.00002249
Iteration 78/1000 | Loss: 0.00002249
Iteration 79/1000 | Loss: 0.00002249
Iteration 80/1000 | Loss: 0.00002249
Iteration 81/1000 | Loss: 0.00002249
Iteration 82/1000 | Loss: 0.00002249
Iteration 83/1000 | Loss: 0.00002248
Iteration 84/1000 | Loss: 0.00002248
Iteration 85/1000 | Loss: 0.00002248
Iteration 86/1000 | Loss: 0.00002248
Iteration 87/1000 | Loss: 0.00002248
Iteration 88/1000 | Loss: 0.00002248
Iteration 89/1000 | Loss: 0.00002248
Iteration 90/1000 | Loss: 0.00002248
Iteration 91/1000 | Loss: 0.00002248
Iteration 92/1000 | Loss: 0.00002248
Iteration 93/1000 | Loss: 0.00002248
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 93. Stopping optimization.
Last 5 losses: [2.2482348867924884e-05, 2.2482348867924884e-05, 2.2482348867924884e-05, 2.2482348867924884e-05, 2.2482348867924884e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2482348867924884e-05

Optimization complete. Final v2v error: 4.032050609588623 mm

Highest mean error: 4.455282688140869 mm for frame 73

Lowest mean error: 3.6583027839660645 mm for frame 38

Saving results

Total time: 49.10716438293457
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1057
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00748999
Iteration 2/25 | Loss: 0.00094935
Iteration 3/25 | Loss: 0.00085931
Iteration 4/25 | Loss: 0.00083975
Iteration 5/25 | Loss: 0.00083551
Iteration 6/25 | Loss: 0.00083420
Iteration 7/25 | Loss: 0.00083389
Iteration 8/25 | Loss: 0.00083387
Iteration 9/25 | Loss: 0.00083387
Iteration 10/25 | Loss: 0.00083387
Iteration 11/25 | Loss: 0.00083387
Iteration 12/25 | Loss: 0.00083387
Iteration 13/25 | Loss: 0.00083387
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008338676998391747, 0.0008338676998391747, 0.0008338676998391747, 0.0008338676998391747, 0.0008338676998391747]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008338676998391747

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 7.59561300
Iteration 2/25 | Loss: 0.00049276
Iteration 3/25 | Loss: 0.00049274
Iteration 4/25 | Loss: 0.00049274
Iteration 5/25 | Loss: 0.00049274
Iteration 6/25 | Loss: 0.00049274
Iteration 7/25 | Loss: 0.00049274
Iteration 8/25 | Loss: 0.00049274
Iteration 9/25 | Loss: 0.00049274
Iteration 10/25 | Loss: 0.00049274
Iteration 11/25 | Loss: 0.00049274
Iteration 12/25 | Loss: 0.00049274
Iteration 13/25 | Loss: 0.00049274
Iteration 14/25 | Loss: 0.00049274
Iteration 15/25 | Loss: 0.00049274
Iteration 16/25 | Loss: 0.00049274
Iteration 17/25 | Loss: 0.00049274
Iteration 18/25 | Loss: 0.00049274
Iteration 19/25 | Loss: 0.00049274
Iteration 20/25 | Loss: 0.00049274
Iteration 21/25 | Loss: 0.00049274
Iteration 22/25 | Loss: 0.00049274
Iteration 23/25 | Loss: 0.00049274
Iteration 24/25 | Loss: 0.00049274
Iteration 25/25 | Loss: 0.00049274

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049274
Iteration 2/1000 | Loss: 0.00002703
Iteration 3/1000 | Loss: 0.00001920
Iteration 4/1000 | Loss: 0.00001791
Iteration 5/1000 | Loss: 0.00001715
Iteration 6/1000 | Loss: 0.00001668
Iteration 7/1000 | Loss: 0.00001621
Iteration 8/1000 | Loss: 0.00001596
Iteration 9/1000 | Loss: 0.00001575
Iteration 10/1000 | Loss: 0.00001570
Iteration 11/1000 | Loss: 0.00001568
Iteration 12/1000 | Loss: 0.00001549
Iteration 13/1000 | Loss: 0.00001543
Iteration 14/1000 | Loss: 0.00001528
Iteration 15/1000 | Loss: 0.00001526
Iteration 16/1000 | Loss: 0.00001525
Iteration 17/1000 | Loss: 0.00001522
Iteration 18/1000 | Loss: 0.00001521
Iteration 19/1000 | Loss: 0.00001521
Iteration 20/1000 | Loss: 0.00001520
Iteration 21/1000 | Loss: 0.00001520
Iteration 22/1000 | Loss: 0.00001519
Iteration 23/1000 | Loss: 0.00001518
Iteration 24/1000 | Loss: 0.00001516
Iteration 25/1000 | Loss: 0.00001512
Iteration 26/1000 | Loss: 0.00001509
Iteration 27/1000 | Loss: 0.00001509
Iteration 28/1000 | Loss: 0.00001509
Iteration 29/1000 | Loss: 0.00001507
Iteration 30/1000 | Loss: 0.00001506
Iteration 31/1000 | Loss: 0.00001505
Iteration 32/1000 | Loss: 0.00001505
Iteration 33/1000 | Loss: 0.00001504
Iteration 34/1000 | Loss: 0.00001504
Iteration 35/1000 | Loss: 0.00001503
Iteration 36/1000 | Loss: 0.00001503
Iteration 37/1000 | Loss: 0.00001502
Iteration 38/1000 | Loss: 0.00001502
Iteration 39/1000 | Loss: 0.00001502
Iteration 40/1000 | Loss: 0.00001501
Iteration 41/1000 | Loss: 0.00001501
Iteration 42/1000 | Loss: 0.00001501
Iteration 43/1000 | Loss: 0.00001500
Iteration 44/1000 | Loss: 0.00001500
Iteration 45/1000 | Loss: 0.00001499
Iteration 46/1000 | Loss: 0.00001499
Iteration 47/1000 | Loss: 0.00001498
Iteration 48/1000 | Loss: 0.00001497
Iteration 49/1000 | Loss: 0.00001497
Iteration 50/1000 | Loss: 0.00001496
Iteration 51/1000 | Loss: 0.00001496
Iteration 52/1000 | Loss: 0.00001495
Iteration 53/1000 | Loss: 0.00001494
Iteration 54/1000 | Loss: 0.00001494
Iteration 55/1000 | Loss: 0.00001494
Iteration 56/1000 | Loss: 0.00001493
Iteration 57/1000 | Loss: 0.00001493
Iteration 58/1000 | Loss: 0.00001493
Iteration 59/1000 | Loss: 0.00001492
Iteration 60/1000 | Loss: 0.00001492
Iteration 61/1000 | Loss: 0.00001492
Iteration 62/1000 | Loss: 0.00001492
Iteration 63/1000 | Loss: 0.00001492
Iteration 64/1000 | Loss: 0.00001492
Iteration 65/1000 | Loss: 0.00001492
Iteration 66/1000 | Loss: 0.00001492
Iteration 67/1000 | Loss: 0.00001491
Iteration 68/1000 | Loss: 0.00001491
Iteration 69/1000 | Loss: 0.00001491
Iteration 70/1000 | Loss: 0.00001491
Iteration 71/1000 | Loss: 0.00001491
Iteration 72/1000 | Loss: 0.00001491
Iteration 73/1000 | Loss: 0.00001491
Iteration 74/1000 | Loss: 0.00001491
Iteration 75/1000 | Loss: 0.00001491
Iteration 76/1000 | Loss: 0.00001490
Iteration 77/1000 | Loss: 0.00001490
Iteration 78/1000 | Loss: 0.00001490
Iteration 79/1000 | Loss: 0.00001490
Iteration 80/1000 | Loss: 0.00001490
Iteration 81/1000 | Loss: 0.00001489
Iteration 82/1000 | Loss: 0.00001489
Iteration 83/1000 | Loss: 0.00001489
Iteration 84/1000 | Loss: 0.00001489
Iteration 85/1000 | Loss: 0.00001489
Iteration 86/1000 | Loss: 0.00001489
Iteration 87/1000 | Loss: 0.00001489
Iteration 88/1000 | Loss: 0.00001489
Iteration 89/1000 | Loss: 0.00001489
Iteration 90/1000 | Loss: 0.00001489
Iteration 91/1000 | Loss: 0.00001489
Iteration 92/1000 | Loss: 0.00001489
Iteration 93/1000 | Loss: 0.00001489
Iteration 94/1000 | Loss: 0.00001489
Iteration 95/1000 | Loss: 0.00001489
Iteration 96/1000 | Loss: 0.00001489
Iteration 97/1000 | Loss: 0.00001489
Iteration 98/1000 | Loss: 0.00001488
Iteration 99/1000 | Loss: 0.00001488
Iteration 100/1000 | Loss: 0.00001488
Iteration 101/1000 | Loss: 0.00001488
Iteration 102/1000 | Loss: 0.00001488
Iteration 103/1000 | Loss: 0.00001488
Iteration 104/1000 | Loss: 0.00001488
Iteration 105/1000 | Loss: 0.00001488
Iteration 106/1000 | Loss: 0.00001488
Iteration 107/1000 | Loss: 0.00001488
Iteration 108/1000 | Loss: 0.00001487
Iteration 109/1000 | Loss: 0.00001487
Iteration 110/1000 | Loss: 0.00001487
Iteration 111/1000 | Loss: 0.00001487
Iteration 112/1000 | Loss: 0.00001487
Iteration 113/1000 | Loss: 0.00001487
Iteration 114/1000 | Loss: 0.00001487
Iteration 115/1000 | Loss: 0.00001487
Iteration 116/1000 | Loss: 0.00001487
Iteration 117/1000 | Loss: 0.00001487
Iteration 118/1000 | Loss: 0.00001487
Iteration 119/1000 | Loss: 0.00001487
Iteration 120/1000 | Loss: 0.00001487
Iteration 121/1000 | Loss: 0.00001487
Iteration 122/1000 | Loss: 0.00001487
Iteration 123/1000 | Loss: 0.00001487
Iteration 124/1000 | Loss: 0.00001487
Iteration 125/1000 | Loss: 0.00001487
Iteration 126/1000 | Loss: 0.00001487
Iteration 127/1000 | Loss: 0.00001487
Iteration 128/1000 | Loss: 0.00001487
Iteration 129/1000 | Loss: 0.00001487
Iteration 130/1000 | Loss: 0.00001487
Iteration 131/1000 | Loss: 0.00001487
Iteration 132/1000 | Loss: 0.00001487
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 132. Stopping optimization.
Last 5 losses: [1.4869644473947119e-05, 1.4869644473947119e-05, 1.4869644473947119e-05, 1.4869644473947119e-05, 1.4869644473947119e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4869644473947119e-05

Optimization complete. Final v2v error: 3.2848968505859375 mm

Highest mean error: 3.664353609085083 mm for frame 38

Lowest mean error: 3.0133326053619385 mm for frame 12

Saving results

Total time: 37.56713819503784
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1025
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00770942
Iteration 2/25 | Loss: 0.00133299
Iteration 3/25 | Loss: 0.00107314
Iteration 4/25 | Loss: 0.00104455
Iteration 5/25 | Loss: 0.00103673
Iteration 6/25 | Loss: 0.00103464
Iteration 7/25 | Loss: 0.00103450
Iteration 8/25 | Loss: 0.00103450
Iteration 9/25 | Loss: 0.00103449
Iteration 10/25 | Loss: 0.00103449
Iteration 11/25 | Loss: 0.00103450
Iteration 12/25 | Loss: 0.00103450
Iteration 13/25 | Loss: 0.00103450
Iteration 14/25 | Loss: 0.00103450
Iteration 15/25 | Loss: 0.00103449
Iteration 16/25 | Loss: 0.00103450
Iteration 17/25 | Loss: 0.00103450
Iteration 18/25 | Loss: 0.00103450
Iteration 19/25 | Loss: 0.00103450
Iteration 20/25 | Loss: 0.00103450
Iteration 21/25 | Loss: 0.00103450
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0010344950715079904, 0.0010344950715079904, 0.0010344950715079904, 0.0010344950715079904, 0.0010344950715079904]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010344950715079904

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.42672634
Iteration 2/25 | Loss: 0.00062048
Iteration 3/25 | Loss: 0.00062043
Iteration 4/25 | Loss: 0.00062043
Iteration 5/25 | Loss: 0.00062043
Iteration 6/25 | Loss: 0.00062043
Iteration 7/25 | Loss: 0.00062043
Iteration 8/25 | Loss: 0.00062043
Iteration 9/25 | Loss: 0.00062043
Iteration 10/25 | Loss: 0.00062043
Iteration 11/25 | Loss: 0.00062043
Iteration 12/25 | Loss: 0.00062043
Iteration 13/25 | Loss: 0.00062043
Iteration 14/25 | Loss: 0.00062043
Iteration 15/25 | Loss: 0.00062043
Iteration 16/25 | Loss: 0.00062043
Iteration 17/25 | Loss: 0.00062043
Iteration 18/25 | Loss: 0.00062043
Iteration 19/25 | Loss: 0.00062043
Iteration 20/25 | Loss: 0.00062043
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0006204257952049375, 0.0006204257952049375, 0.0006204257952049375, 0.0006204257952049375, 0.0006204257952049375]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006204257952049375

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062043
Iteration 2/1000 | Loss: 0.00004352
Iteration 3/1000 | Loss: 0.00003257
Iteration 4/1000 | Loss: 0.00002997
Iteration 5/1000 | Loss: 0.00002888
Iteration 6/1000 | Loss: 0.00002809
Iteration 7/1000 | Loss: 0.00002761
Iteration 8/1000 | Loss: 0.00002735
Iteration 9/1000 | Loss: 0.00002711
Iteration 10/1000 | Loss: 0.00002693
Iteration 11/1000 | Loss: 0.00002683
Iteration 12/1000 | Loss: 0.00002675
Iteration 13/1000 | Loss: 0.00002674
Iteration 14/1000 | Loss: 0.00002669
Iteration 15/1000 | Loss: 0.00002664
Iteration 16/1000 | Loss: 0.00002660
Iteration 17/1000 | Loss: 0.00002658
Iteration 18/1000 | Loss: 0.00002655
Iteration 19/1000 | Loss: 0.00002654
Iteration 20/1000 | Loss: 0.00002653
Iteration 21/1000 | Loss: 0.00002652
Iteration 22/1000 | Loss: 0.00002651
Iteration 23/1000 | Loss: 0.00002649
Iteration 24/1000 | Loss: 0.00002648
Iteration 25/1000 | Loss: 0.00002642
Iteration 26/1000 | Loss: 0.00002640
Iteration 27/1000 | Loss: 0.00002639
Iteration 28/1000 | Loss: 0.00002639
Iteration 29/1000 | Loss: 0.00002638
Iteration 30/1000 | Loss: 0.00002638
Iteration 31/1000 | Loss: 0.00002638
Iteration 32/1000 | Loss: 0.00002637
Iteration 33/1000 | Loss: 0.00002636
Iteration 34/1000 | Loss: 0.00002636
Iteration 35/1000 | Loss: 0.00002636
Iteration 36/1000 | Loss: 0.00002636
Iteration 37/1000 | Loss: 0.00002635
Iteration 38/1000 | Loss: 0.00002635
Iteration 39/1000 | Loss: 0.00002635
Iteration 40/1000 | Loss: 0.00002635
Iteration 41/1000 | Loss: 0.00002635
Iteration 42/1000 | Loss: 0.00002635
Iteration 43/1000 | Loss: 0.00002635
Iteration 44/1000 | Loss: 0.00002635
Iteration 45/1000 | Loss: 0.00002635
Iteration 46/1000 | Loss: 0.00002635
Iteration 47/1000 | Loss: 0.00002635
Iteration 48/1000 | Loss: 0.00002635
Iteration 49/1000 | Loss: 0.00002635
Iteration 50/1000 | Loss: 0.00002635
Iteration 51/1000 | Loss: 0.00002635
Iteration 52/1000 | Loss: 0.00002635
Iteration 53/1000 | Loss: 0.00002635
Iteration 54/1000 | Loss: 0.00002635
Iteration 55/1000 | Loss: 0.00002635
Iteration 56/1000 | Loss: 0.00002635
Iteration 57/1000 | Loss: 0.00002635
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 57. Stopping optimization.
Last 5 losses: [2.634898373798933e-05, 2.634898373798933e-05, 2.634898373798933e-05, 2.634898373798933e-05, 2.634898373798933e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.634898373798933e-05

Optimization complete. Final v2v error: 4.13247537612915 mm

Highest mean error: 4.798943042755127 mm for frame 16

Lowest mean error: 3.400313138961792 mm for frame 82

Saving results

Total time: 32.46404051780701
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00778682
Iteration 2/25 | Loss: 0.00132874
Iteration 3/25 | Loss: 0.00093102
Iteration 4/25 | Loss: 0.00087755
Iteration 5/25 | Loss: 0.00086583
Iteration 6/25 | Loss: 0.00086453
Iteration 7/25 | Loss: 0.00086453
Iteration 8/25 | Loss: 0.00086453
Iteration 9/25 | Loss: 0.00086453
Iteration 10/25 | Loss: 0.00086453
Iteration 11/25 | Loss: 0.00086453
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008645300986245275, 0.0008645300986245275, 0.0008645300986245275, 0.0008645300986245275, 0.0008645300986245275]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008645300986245275

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50431359
Iteration 2/25 | Loss: 0.00059620
Iteration 3/25 | Loss: 0.00059618
Iteration 4/25 | Loss: 0.00059618
Iteration 5/25 | Loss: 0.00059618
Iteration 6/25 | Loss: 0.00059618
Iteration 7/25 | Loss: 0.00059618
Iteration 8/25 | Loss: 0.00059618
Iteration 9/25 | Loss: 0.00059618
Iteration 10/25 | Loss: 0.00059618
Iteration 11/25 | Loss: 0.00059618
Iteration 12/25 | Loss: 0.00059618
Iteration 13/25 | Loss: 0.00059618
Iteration 14/25 | Loss: 0.00059618
Iteration 15/25 | Loss: 0.00059618
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0005961774731986225, 0.0005961774731986225, 0.0005961774731986225, 0.0005961774731986225, 0.0005961774731986225]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005961774731986225

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059618
Iteration 2/1000 | Loss: 0.00002308
Iteration 3/1000 | Loss: 0.00001855
Iteration 4/1000 | Loss: 0.00001673
Iteration 5/1000 | Loss: 0.00001582
Iteration 6/1000 | Loss: 0.00001517
Iteration 7/1000 | Loss: 0.00001474
Iteration 8/1000 | Loss: 0.00001435
Iteration 9/1000 | Loss: 0.00001413
Iteration 10/1000 | Loss: 0.00001406
Iteration 11/1000 | Loss: 0.00001405
Iteration 12/1000 | Loss: 0.00001398
Iteration 13/1000 | Loss: 0.00001396
Iteration 14/1000 | Loss: 0.00001392
Iteration 15/1000 | Loss: 0.00001390
Iteration 16/1000 | Loss: 0.00001389
Iteration 17/1000 | Loss: 0.00001387
Iteration 18/1000 | Loss: 0.00001387
Iteration 19/1000 | Loss: 0.00001386
Iteration 20/1000 | Loss: 0.00001386
Iteration 21/1000 | Loss: 0.00001385
Iteration 22/1000 | Loss: 0.00001385
Iteration 23/1000 | Loss: 0.00001379
Iteration 24/1000 | Loss: 0.00001378
Iteration 25/1000 | Loss: 0.00001377
Iteration 26/1000 | Loss: 0.00001377
Iteration 27/1000 | Loss: 0.00001376
Iteration 28/1000 | Loss: 0.00001376
Iteration 29/1000 | Loss: 0.00001375
Iteration 30/1000 | Loss: 0.00001375
Iteration 31/1000 | Loss: 0.00001375
Iteration 32/1000 | Loss: 0.00001375
Iteration 33/1000 | Loss: 0.00001374
Iteration 34/1000 | Loss: 0.00001374
Iteration 35/1000 | Loss: 0.00001374
Iteration 36/1000 | Loss: 0.00001373
Iteration 37/1000 | Loss: 0.00001373
Iteration 38/1000 | Loss: 0.00001373
Iteration 39/1000 | Loss: 0.00001372
Iteration 40/1000 | Loss: 0.00001372
Iteration 41/1000 | Loss: 0.00001372
Iteration 42/1000 | Loss: 0.00001371
Iteration 43/1000 | Loss: 0.00001371
Iteration 44/1000 | Loss: 0.00001370
Iteration 45/1000 | Loss: 0.00001370
Iteration 46/1000 | Loss: 0.00001370
Iteration 47/1000 | Loss: 0.00001370
Iteration 48/1000 | Loss: 0.00001370
Iteration 49/1000 | Loss: 0.00001369
Iteration 50/1000 | Loss: 0.00001369
Iteration 51/1000 | Loss: 0.00001369
Iteration 52/1000 | Loss: 0.00001369
Iteration 53/1000 | Loss: 0.00001369
Iteration 54/1000 | Loss: 0.00001369
Iteration 55/1000 | Loss: 0.00001369
Iteration 56/1000 | Loss: 0.00001369
Iteration 57/1000 | Loss: 0.00001369
Iteration 58/1000 | Loss: 0.00001369
Iteration 59/1000 | Loss: 0.00001369
Iteration 60/1000 | Loss: 0.00001369
Iteration 61/1000 | Loss: 0.00001369
Iteration 62/1000 | Loss: 0.00001368
Iteration 63/1000 | Loss: 0.00001368
Iteration 64/1000 | Loss: 0.00001368
Iteration 65/1000 | Loss: 0.00001367
Iteration 66/1000 | Loss: 0.00001367
Iteration 67/1000 | Loss: 0.00001367
Iteration 68/1000 | Loss: 0.00001367
Iteration 69/1000 | Loss: 0.00001367
Iteration 70/1000 | Loss: 0.00001367
Iteration 71/1000 | Loss: 0.00001367
Iteration 72/1000 | Loss: 0.00001367
Iteration 73/1000 | Loss: 0.00001367
Iteration 74/1000 | Loss: 0.00001366
Iteration 75/1000 | Loss: 0.00001365
Iteration 76/1000 | Loss: 0.00001365
Iteration 77/1000 | Loss: 0.00001364
Iteration 78/1000 | Loss: 0.00001364
Iteration 79/1000 | Loss: 0.00001364
Iteration 80/1000 | Loss: 0.00001364
Iteration 81/1000 | Loss: 0.00001363
Iteration 82/1000 | Loss: 0.00001363
Iteration 83/1000 | Loss: 0.00001363
Iteration 84/1000 | Loss: 0.00001363
Iteration 85/1000 | Loss: 0.00001363
Iteration 86/1000 | Loss: 0.00001363
Iteration 87/1000 | Loss: 0.00001363
Iteration 88/1000 | Loss: 0.00001363
Iteration 89/1000 | Loss: 0.00001363
Iteration 90/1000 | Loss: 0.00001363
Iteration 91/1000 | Loss: 0.00001363
Iteration 92/1000 | Loss: 0.00001363
Iteration 93/1000 | Loss: 0.00001363
Iteration 94/1000 | Loss: 0.00001363
Iteration 95/1000 | Loss: 0.00001363
Iteration 96/1000 | Loss: 0.00001362
Iteration 97/1000 | Loss: 0.00001362
Iteration 98/1000 | Loss: 0.00001362
Iteration 99/1000 | Loss: 0.00001362
Iteration 100/1000 | Loss: 0.00001362
Iteration 101/1000 | Loss: 0.00001362
Iteration 102/1000 | Loss: 0.00001362
Iteration 103/1000 | Loss: 0.00001362
Iteration 104/1000 | Loss: 0.00001362
Iteration 105/1000 | Loss: 0.00001362
Iteration 106/1000 | Loss: 0.00001362
Iteration 107/1000 | Loss: 0.00001362
Iteration 108/1000 | Loss: 0.00001362
Iteration 109/1000 | Loss: 0.00001361
Iteration 110/1000 | Loss: 0.00001361
Iteration 111/1000 | Loss: 0.00001361
Iteration 112/1000 | Loss: 0.00001361
Iteration 113/1000 | Loss: 0.00001361
Iteration 114/1000 | Loss: 0.00001361
Iteration 115/1000 | Loss: 0.00001361
Iteration 116/1000 | Loss: 0.00001361
Iteration 117/1000 | Loss: 0.00001360
Iteration 118/1000 | Loss: 0.00001360
Iteration 119/1000 | Loss: 0.00001360
Iteration 120/1000 | Loss: 0.00001360
Iteration 121/1000 | Loss: 0.00001360
Iteration 122/1000 | Loss: 0.00001360
Iteration 123/1000 | Loss: 0.00001360
Iteration 124/1000 | Loss: 0.00001360
Iteration 125/1000 | Loss: 0.00001360
Iteration 126/1000 | Loss: 0.00001360
Iteration 127/1000 | Loss: 0.00001359
Iteration 128/1000 | Loss: 0.00001359
Iteration 129/1000 | Loss: 0.00001359
Iteration 130/1000 | Loss: 0.00001359
Iteration 131/1000 | Loss: 0.00001359
Iteration 132/1000 | Loss: 0.00001359
Iteration 133/1000 | Loss: 0.00001359
Iteration 134/1000 | Loss: 0.00001359
Iteration 135/1000 | Loss: 0.00001359
Iteration 136/1000 | Loss: 0.00001359
Iteration 137/1000 | Loss: 0.00001359
Iteration 138/1000 | Loss: 0.00001359
Iteration 139/1000 | Loss: 0.00001359
Iteration 140/1000 | Loss: 0.00001359
Iteration 141/1000 | Loss: 0.00001359
Iteration 142/1000 | Loss: 0.00001359
Iteration 143/1000 | Loss: 0.00001359
Iteration 144/1000 | Loss: 0.00001359
Iteration 145/1000 | Loss: 0.00001359
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [1.3587136891146656e-05, 1.3587136891146656e-05, 1.3587136891146656e-05, 1.3587136891146656e-05, 1.3587136891146656e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3587136891146656e-05

Optimization complete. Final v2v error: 3.1558055877685547 mm

Highest mean error: 3.39516282081604 mm for frame 0

Lowest mean error: 3.041635274887085 mm for frame 172

Saving results

Total time: 36.933837890625
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00757341
Iteration 2/25 | Loss: 0.00117373
Iteration 3/25 | Loss: 0.00095236
Iteration 4/25 | Loss: 0.00093182
Iteration 5/25 | Loss: 0.00092572
Iteration 6/25 | Loss: 0.00092410
Iteration 7/25 | Loss: 0.00092410
Iteration 8/25 | Loss: 0.00092410
Iteration 9/25 | Loss: 0.00092410
Iteration 10/25 | Loss: 0.00092410
Iteration 11/25 | Loss: 0.00092410
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009241036605089903, 0.0009241036605089903, 0.0009241036605089903, 0.0009241036605089903, 0.0009241036605089903]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009241036605089903

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.71678138
Iteration 2/25 | Loss: 0.00062965
Iteration 3/25 | Loss: 0.00062963
Iteration 4/25 | Loss: 0.00062963
Iteration 5/25 | Loss: 0.00062963
Iteration 6/25 | Loss: 0.00062963
Iteration 7/25 | Loss: 0.00062963
Iteration 8/25 | Loss: 0.00062963
Iteration 9/25 | Loss: 0.00062963
Iteration 10/25 | Loss: 0.00062963
Iteration 11/25 | Loss: 0.00062963
Iteration 12/25 | Loss: 0.00062963
Iteration 13/25 | Loss: 0.00062963
Iteration 14/25 | Loss: 0.00062963
Iteration 15/25 | Loss: 0.00062963
Iteration 16/25 | Loss: 0.00062963
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006296252249740064, 0.0006296252249740064, 0.0006296252249740064, 0.0006296252249740064, 0.0006296252249740064]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006296252249740064

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062963
Iteration 2/1000 | Loss: 0.00003323
Iteration 3/1000 | Loss: 0.00002473
Iteration 4/1000 | Loss: 0.00002301
Iteration 5/1000 | Loss: 0.00002169
Iteration 6/1000 | Loss: 0.00002105
Iteration 7/1000 | Loss: 0.00002064
Iteration 8/1000 | Loss: 0.00002029
Iteration 9/1000 | Loss: 0.00001997
Iteration 10/1000 | Loss: 0.00001975
Iteration 11/1000 | Loss: 0.00001960
Iteration 12/1000 | Loss: 0.00001945
Iteration 13/1000 | Loss: 0.00001941
Iteration 14/1000 | Loss: 0.00001940
Iteration 15/1000 | Loss: 0.00001939
Iteration 16/1000 | Loss: 0.00001938
Iteration 17/1000 | Loss: 0.00001937
Iteration 18/1000 | Loss: 0.00001936
Iteration 19/1000 | Loss: 0.00001935
Iteration 20/1000 | Loss: 0.00001930
Iteration 21/1000 | Loss: 0.00001929
Iteration 22/1000 | Loss: 0.00001929
Iteration 23/1000 | Loss: 0.00001928
Iteration 24/1000 | Loss: 0.00001926
Iteration 25/1000 | Loss: 0.00001925
Iteration 26/1000 | Loss: 0.00001925
Iteration 27/1000 | Loss: 0.00001924
Iteration 28/1000 | Loss: 0.00001924
Iteration 29/1000 | Loss: 0.00001923
Iteration 30/1000 | Loss: 0.00001923
Iteration 31/1000 | Loss: 0.00001922
Iteration 32/1000 | Loss: 0.00001922
Iteration 33/1000 | Loss: 0.00001918
Iteration 34/1000 | Loss: 0.00001918
Iteration 35/1000 | Loss: 0.00001918
Iteration 36/1000 | Loss: 0.00001918
Iteration 37/1000 | Loss: 0.00001918
Iteration 38/1000 | Loss: 0.00001918
Iteration 39/1000 | Loss: 0.00001916
Iteration 40/1000 | Loss: 0.00001916
Iteration 41/1000 | Loss: 0.00001915
Iteration 42/1000 | Loss: 0.00001915
Iteration 43/1000 | Loss: 0.00001914
Iteration 44/1000 | Loss: 0.00001914
Iteration 45/1000 | Loss: 0.00001913
Iteration 46/1000 | Loss: 0.00001913
Iteration 47/1000 | Loss: 0.00001912
Iteration 48/1000 | Loss: 0.00001912
Iteration 49/1000 | Loss: 0.00001912
Iteration 50/1000 | Loss: 0.00001912
Iteration 51/1000 | Loss: 0.00001912
Iteration 52/1000 | Loss: 0.00001912
Iteration 53/1000 | Loss: 0.00001912
Iteration 54/1000 | Loss: 0.00001911
Iteration 55/1000 | Loss: 0.00001911
Iteration 56/1000 | Loss: 0.00001911
Iteration 57/1000 | Loss: 0.00001911
Iteration 58/1000 | Loss: 0.00001911
Iteration 59/1000 | Loss: 0.00001911
Iteration 60/1000 | Loss: 0.00001911
Iteration 61/1000 | Loss: 0.00001911
Iteration 62/1000 | Loss: 0.00001911
Iteration 63/1000 | Loss: 0.00001910
Iteration 64/1000 | Loss: 0.00001910
Iteration 65/1000 | Loss: 0.00001910
Iteration 66/1000 | Loss: 0.00001909
Iteration 67/1000 | Loss: 0.00001909
Iteration 68/1000 | Loss: 0.00001909
Iteration 69/1000 | Loss: 0.00001909
Iteration 70/1000 | Loss: 0.00001908
Iteration 71/1000 | Loss: 0.00001908
Iteration 72/1000 | Loss: 0.00001908
Iteration 73/1000 | Loss: 0.00001908
Iteration 74/1000 | Loss: 0.00001908
Iteration 75/1000 | Loss: 0.00001908
Iteration 76/1000 | Loss: 0.00001908
Iteration 77/1000 | Loss: 0.00001907
Iteration 78/1000 | Loss: 0.00001907
Iteration 79/1000 | Loss: 0.00001907
Iteration 80/1000 | Loss: 0.00001907
Iteration 81/1000 | Loss: 0.00001907
Iteration 82/1000 | Loss: 0.00001907
Iteration 83/1000 | Loss: 0.00001906
Iteration 84/1000 | Loss: 0.00001906
Iteration 85/1000 | Loss: 0.00001906
Iteration 86/1000 | Loss: 0.00001906
Iteration 87/1000 | Loss: 0.00001906
Iteration 88/1000 | Loss: 0.00001905
Iteration 89/1000 | Loss: 0.00001905
Iteration 90/1000 | Loss: 0.00001905
Iteration 91/1000 | Loss: 0.00001904
Iteration 92/1000 | Loss: 0.00001904
Iteration 93/1000 | Loss: 0.00001904
Iteration 94/1000 | Loss: 0.00001904
Iteration 95/1000 | Loss: 0.00001904
Iteration 96/1000 | Loss: 0.00001903
Iteration 97/1000 | Loss: 0.00001903
Iteration 98/1000 | Loss: 0.00001903
Iteration 99/1000 | Loss: 0.00001903
Iteration 100/1000 | Loss: 0.00001903
Iteration 101/1000 | Loss: 0.00001903
Iteration 102/1000 | Loss: 0.00001903
Iteration 103/1000 | Loss: 0.00001902
Iteration 104/1000 | Loss: 0.00001902
Iteration 105/1000 | Loss: 0.00001902
Iteration 106/1000 | Loss: 0.00001902
Iteration 107/1000 | Loss: 0.00001902
Iteration 108/1000 | Loss: 0.00001902
Iteration 109/1000 | Loss: 0.00001902
Iteration 110/1000 | Loss: 0.00001902
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [1.9022558262804523e-05, 1.9022558262804523e-05, 1.9022558262804523e-05, 1.9022558262804523e-05, 1.9022558262804523e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9022558262804523e-05

Optimization complete. Final v2v error: 3.638251781463623 mm

Highest mean error: 4.489514350891113 mm for frame 187

Lowest mean error: 3.0195183753967285 mm for frame 7

Saving results

Total time: 38.67076110839844
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840869
Iteration 2/25 | Loss: 0.00140325
Iteration 3/25 | Loss: 0.00094795
Iteration 4/25 | Loss: 0.00090241
Iteration 5/25 | Loss: 0.00089219
Iteration 6/25 | Loss: 0.00089073
Iteration 7/25 | Loss: 0.00089073
Iteration 8/25 | Loss: 0.00089073
Iteration 9/25 | Loss: 0.00089073
Iteration 10/25 | Loss: 0.00089073
Iteration 11/25 | Loss: 0.00089073
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008907302981242537, 0.0008907302981242537, 0.0008907302981242537, 0.0008907302981242537, 0.0008907302981242537]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008907302981242537

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51497757
Iteration 2/25 | Loss: 0.00065438
Iteration 3/25 | Loss: 0.00065437
Iteration 4/25 | Loss: 0.00065437
Iteration 5/25 | Loss: 0.00065437
Iteration 6/25 | Loss: 0.00065437
Iteration 7/25 | Loss: 0.00065437
Iteration 8/25 | Loss: 0.00065437
Iteration 9/25 | Loss: 0.00065437
Iteration 10/25 | Loss: 0.00065437
Iteration 11/25 | Loss: 0.00065437
Iteration 12/25 | Loss: 0.00065437
Iteration 13/25 | Loss: 0.00065437
Iteration 14/25 | Loss: 0.00065437
Iteration 15/25 | Loss: 0.00065437
Iteration 16/25 | Loss: 0.00065437
Iteration 17/25 | Loss: 0.00065437
Iteration 18/25 | Loss: 0.00065437
Iteration 19/25 | Loss: 0.00065437
Iteration 20/25 | Loss: 0.00065437
Iteration 21/25 | Loss: 0.00065437
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.000654367555398494, 0.000654367555398494, 0.000654367555398494, 0.000654367555398494, 0.000654367555398494]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000654367555398494

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065437
Iteration 2/1000 | Loss: 0.00002994
Iteration 3/1000 | Loss: 0.00002366
Iteration 4/1000 | Loss: 0.00002131
Iteration 5/1000 | Loss: 0.00002030
Iteration 6/1000 | Loss: 0.00001970
Iteration 7/1000 | Loss: 0.00001931
Iteration 8/1000 | Loss: 0.00001926
Iteration 9/1000 | Loss: 0.00001905
Iteration 10/1000 | Loss: 0.00001877
Iteration 11/1000 | Loss: 0.00001858
Iteration 12/1000 | Loss: 0.00001858
Iteration 13/1000 | Loss: 0.00001857
Iteration 14/1000 | Loss: 0.00001850
Iteration 15/1000 | Loss: 0.00001848
Iteration 16/1000 | Loss: 0.00001845
Iteration 17/1000 | Loss: 0.00001845
Iteration 18/1000 | Loss: 0.00001844
Iteration 19/1000 | Loss: 0.00001844
Iteration 20/1000 | Loss: 0.00001844
Iteration 21/1000 | Loss: 0.00001844
Iteration 22/1000 | Loss: 0.00001843
Iteration 23/1000 | Loss: 0.00001843
Iteration 24/1000 | Loss: 0.00001843
Iteration 25/1000 | Loss: 0.00001842
Iteration 26/1000 | Loss: 0.00001842
Iteration 27/1000 | Loss: 0.00001841
Iteration 28/1000 | Loss: 0.00001840
Iteration 29/1000 | Loss: 0.00001838
Iteration 30/1000 | Loss: 0.00001838
Iteration 31/1000 | Loss: 0.00001838
Iteration 32/1000 | Loss: 0.00001838
Iteration 33/1000 | Loss: 0.00001837
Iteration 34/1000 | Loss: 0.00001837
Iteration 35/1000 | Loss: 0.00001837
Iteration 36/1000 | Loss: 0.00001837
Iteration 37/1000 | Loss: 0.00001836
Iteration 38/1000 | Loss: 0.00001835
Iteration 39/1000 | Loss: 0.00001834
Iteration 40/1000 | Loss: 0.00001834
Iteration 41/1000 | Loss: 0.00001833
Iteration 42/1000 | Loss: 0.00001831
Iteration 43/1000 | Loss: 0.00001831
Iteration 44/1000 | Loss: 0.00001831
Iteration 45/1000 | Loss: 0.00001831
Iteration 46/1000 | Loss: 0.00001831
Iteration 47/1000 | Loss: 0.00001831
Iteration 48/1000 | Loss: 0.00001831
Iteration 49/1000 | Loss: 0.00001830
Iteration 50/1000 | Loss: 0.00001830
Iteration 51/1000 | Loss: 0.00001830
Iteration 52/1000 | Loss: 0.00001830
Iteration 53/1000 | Loss: 0.00001830
Iteration 54/1000 | Loss: 0.00001829
Iteration 55/1000 | Loss: 0.00001829
Iteration 56/1000 | Loss: 0.00001829
Iteration 57/1000 | Loss: 0.00001828
Iteration 58/1000 | Loss: 0.00001828
Iteration 59/1000 | Loss: 0.00001828
Iteration 60/1000 | Loss: 0.00001827
Iteration 61/1000 | Loss: 0.00001827
Iteration 62/1000 | Loss: 0.00001826
Iteration 63/1000 | Loss: 0.00001826
Iteration 64/1000 | Loss: 0.00001826
Iteration 65/1000 | Loss: 0.00001826
Iteration 66/1000 | Loss: 0.00001826
Iteration 67/1000 | Loss: 0.00001825
Iteration 68/1000 | Loss: 0.00001825
Iteration 69/1000 | Loss: 0.00001824
Iteration 70/1000 | Loss: 0.00001824
Iteration 71/1000 | Loss: 0.00001824
Iteration 72/1000 | Loss: 0.00001824
Iteration 73/1000 | Loss: 0.00001823
Iteration 74/1000 | Loss: 0.00001823
Iteration 75/1000 | Loss: 0.00001822
Iteration 76/1000 | Loss: 0.00001822
Iteration 77/1000 | Loss: 0.00001822
Iteration 78/1000 | Loss: 0.00001821
Iteration 79/1000 | Loss: 0.00001821
Iteration 80/1000 | Loss: 0.00001821
Iteration 81/1000 | Loss: 0.00001821
Iteration 82/1000 | Loss: 0.00001821
Iteration 83/1000 | Loss: 0.00001821
Iteration 84/1000 | Loss: 0.00001821
Iteration 85/1000 | Loss: 0.00001821
Iteration 86/1000 | Loss: 0.00001821
Iteration 87/1000 | Loss: 0.00001820
Iteration 88/1000 | Loss: 0.00001820
Iteration 89/1000 | Loss: 0.00001820
Iteration 90/1000 | Loss: 0.00001820
Iteration 91/1000 | Loss: 0.00001820
Iteration 92/1000 | Loss: 0.00001820
Iteration 93/1000 | Loss: 0.00001820
Iteration 94/1000 | Loss: 0.00001820
Iteration 95/1000 | Loss: 0.00001820
Iteration 96/1000 | Loss: 0.00001820
Iteration 97/1000 | Loss: 0.00001820
Iteration 98/1000 | Loss: 0.00001820
Iteration 99/1000 | Loss: 0.00001820
Iteration 100/1000 | Loss: 0.00001820
Iteration 101/1000 | Loss: 0.00001820
Iteration 102/1000 | Loss: 0.00001820
Iteration 103/1000 | Loss: 0.00001820
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.8203238141722977e-05, 1.8203238141722977e-05, 1.8203238141722977e-05, 1.8203238141722977e-05, 1.8203238141722977e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8203238141722977e-05

Optimization complete. Final v2v error: 3.578549861907959 mm

Highest mean error: 3.853715419769287 mm for frame 177

Lowest mean error: 3.3999156951904297 mm for frame 140

Saving results

Total time: 36.61024498939514
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00454281
Iteration 2/25 | Loss: 0.00102667
Iteration 3/25 | Loss: 0.00088877
Iteration 4/25 | Loss: 0.00085134
Iteration 5/25 | Loss: 0.00084572
Iteration 6/25 | Loss: 0.00084455
Iteration 7/25 | Loss: 0.00084455
Iteration 8/25 | Loss: 0.00084455
Iteration 9/25 | Loss: 0.00084455
Iteration 10/25 | Loss: 0.00084455
Iteration 11/25 | Loss: 0.00084455
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.000844550842884928, 0.000844550842884928, 0.000844550842884928, 0.000844550842884928, 0.000844550842884928]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000844550842884928

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.33773279
Iteration 2/25 | Loss: 0.00058452
Iteration 3/25 | Loss: 0.00058449
Iteration 4/25 | Loss: 0.00058449
Iteration 5/25 | Loss: 0.00058449
Iteration 6/25 | Loss: 0.00058448
Iteration 7/25 | Loss: 0.00058448
Iteration 8/25 | Loss: 0.00058448
Iteration 9/25 | Loss: 0.00058448
Iteration 10/25 | Loss: 0.00058448
Iteration 11/25 | Loss: 0.00058448
Iteration 12/25 | Loss: 0.00058448
Iteration 13/25 | Loss: 0.00058448
Iteration 14/25 | Loss: 0.00058448
Iteration 15/25 | Loss: 0.00058448
Iteration 16/25 | Loss: 0.00058448
Iteration 17/25 | Loss: 0.00058448
Iteration 18/25 | Loss: 0.00058448
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005844830302521586, 0.0005844830302521586, 0.0005844830302521586, 0.0005844830302521586, 0.0005844830302521586]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005844830302521586

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00058448
Iteration 2/1000 | Loss: 0.00003151
Iteration 3/1000 | Loss: 0.00001986
Iteration 4/1000 | Loss: 0.00001823
Iteration 5/1000 | Loss: 0.00001705
Iteration 6/1000 | Loss: 0.00001645
Iteration 7/1000 | Loss: 0.00001612
Iteration 8/1000 | Loss: 0.00001580
Iteration 9/1000 | Loss: 0.00001558
Iteration 10/1000 | Loss: 0.00001548
Iteration 11/1000 | Loss: 0.00001545
Iteration 12/1000 | Loss: 0.00001532
Iteration 13/1000 | Loss: 0.00001523
Iteration 14/1000 | Loss: 0.00001520
Iteration 15/1000 | Loss: 0.00001519
Iteration 16/1000 | Loss: 0.00001519
Iteration 17/1000 | Loss: 0.00001518
Iteration 18/1000 | Loss: 0.00001518
Iteration 19/1000 | Loss: 0.00001518
Iteration 20/1000 | Loss: 0.00001518
Iteration 21/1000 | Loss: 0.00001517
Iteration 22/1000 | Loss: 0.00001517
Iteration 23/1000 | Loss: 0.00001516
Iteration 24/1000 | Loss: 0.00001516
Iteration 25/1000 | Loss: 0.00001516
Iteration 26/1000 | Loss: 0.00001515
Iteration 27/1000 | Loss: 0.00001515
Iteration 28/1000 | Loss: 0.00001515
Iteration 29/1000 | Loss: 0.00001515
Iteration 30/1000 | Loss: 0.00001515
Iteration 31/1000 | Loss: 0.00001514
Iteration 32/1000 | Loss: 0.00001514
Iteration 33/1000 | Loss: 0.00001514
Iteration 34/1000 | Loss: 0.00001514
Iteration 35/1000 | Loss: 0.00001514
Iteration 36/1000 | Loss: 0.00001514
Iteration 37/1000 | Loss: 0.00001514
Iteration 38/1000 | Loss: 0.00001514
Iteration 39/1000 | Loss: 0.00001513
Iteration 40/1000 | Loss: 0.00001513
Iteration 41/1000 | Loss: 0.00001512
Iteration 42/1000 | Loss: 0.00001512
Iteration 43/1000 | Loss: 0.00001512
Iteration 44/1000 | Loss: 0.00001511
Iteration 45/1000 | Loss: 0.00001511
Iteration 46/1000 | Loss: 0.00001511
Iteration 47/1000 | Loss: 0.00001511
Iteration 48/1000 | Loss: 0.00001510
Iteration 49/1000 | Loss: 0.00001510
Iteration 50/1000 | Loss: 0.00001509
Iteration 51/1000 | Loss: 0.00001509
Iteration 52/1000 | Loss: 0.00001509
Iteration 53/1000 | Loss: 0.00001508
Iteration 54/1000 | Loss: 0.00001508
Iteration 55/1000 | Loss: 0.00001508
Iteration 56/1000 | Loss: 0.00001508
Iteration 57/1000 | Loss: 0.00001508
Iteration 58/1000 | Loss: 0.00001507
Iteration 59/1000 | Loss: 0.00001507
Iteration 60/1000 | Loss: 0.00001507
Iteration 61/1000 | Loss: 0.00001506
Iteration 62/1000 | Loss: 0.00001506
Iteration 63/1000 | Loss: 0.00001506
Iteration 64/1000 | Loss: 0.00001506
Iteration 65/1000 | Loss: 0.00001505
Iteration 66/1000 | Loss: 0.00001505
Iteration 67/1000 | Loss: 0.00001505
Iteration 68/1000 | Loss: 0.00001505
Iteration 69/1000 | Loss: 0.00001504
Iteration 70/1000 | Loss: 0.00001504
Iteration 71/1000 | Loss: 0.00001504
Iteration 72/1000 | Loss: 0.00001504
Iteration 73/1000 | Loss: 0.00001504
Iteration 74/1000 | Loss: 0.00001503
Iteration 75/1000 | Loss: 0.00001503
Iteration 76/1000 | Loss: 0.00001503
Iteration 77/1000 | Loss: 0.00001503
Iteration 78/1000 | Loss: 0.00001502
Iteration 79/1000 | Loss: 0.00001502
Iteration 80/1000 | Loss: 0.00001502
Iteration 81/1000 | Loss: 0.00001502
Iteration 82/1000 | Loss: 0.00001501
Iteration 83/1000 | Loss: 0.00001501
Iteration 84/1000 | Loss: 0.00001501
Iteration 85/1000 | Loss: 0.00001501
Iteration 86/1000 | Loss: 0.00001501
Iteration 87/1000 | Loss: 0.00001501
Iteration 88/1000 | Loss: 0.00001501
Iteration 89/1000 | Loss: 0.00001501
Iteration 90/1000 | Loss: 0.00001501
Iteration 91/1000 | Loss: 0.00001501
Iteration 92/1000 | Loss: 0.00001501
Iteration 93/1000 | Loss: 0.00001501
Iteration 94/1000 | Loss: 0.00001501
Iteration 95/1000 | Loss: 0.00001501
Iteration 96/1000 | Loss: 0.00001501
Iteration 97/1000 | Loss: 0.00001501
Iteration 98/1000 | Loss: 0.00001501
Iteration 99/1000 | Loss: 0.00001501
Iteration 100/1000 | Loss: 0.00001501
Iteration 101/1000 | Loss: 0.00001501
Iteration 102/1000 | Loss: 0.00001501
Iteration 103/1000 | Loss: 0.00001501
Iteration 104/1000 | Loss: 0.00001501
Iteration 105/1000 | Loss: 0.00001501
Iteration 106/1000 | Loss: 0.00001501
Iteration 107/1000 | Loss: 0.00001501
Iteration 108/1000 | Loss: 0.00001501
Iteration 109/1000 | Loss: 0.00001501
Iteration 110/1000 | Loss: 0.00001501
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [1.5009135495347437e-05, 1.5009135495347437e-05, 1.5009135495347437e-05, 1.5009135495347437e-05, 1.5009135495347437e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5009135495347437e-05

Optimization complete. Final v2v error: 3.292531967163086 mm

Highest mean error: 3.6607043743133545 mm for frame 85

Lowest mean error: 2.8886845111846924 mm for frame 12

Saving results

Total time: 37.177841663360596
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_henry_posed_001/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_henry_posed_001/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435488
Iteration 2/25 | Loss: 0.00098985
Iteration 3/25 | Loss: 0.00087952
Iteration 4/25 | Loss: 0.00085842
Iteration 5/25 | Loss: 0.00085374
Iteration 6/25 | Loss: 0.00085328
Iteration 7/25 | Loss: 0.00085328
Iteration 8/25 | Loss: 0.00085328
Iteration 9/25 | Loss: 0.00085328
Iteration 10/25 | Loss: 0.00085328
Iteration 11/25 | Loss: 0.00085328
Iteration 12/25 | Loss: 0.00085328
Iteration 13/25 | Loss: 0.00085328
Iteration 14/25 | Loss: 0.00085328
Iteration 15/25 | Loss: 0.00085328
Iteration 16/25 | Loss: 0.00085328
Iteration 17/25 | Loss: 0.00085328
Iteration 18/25 | Loss: 0.00085328
Iteration 19/25 | Loss: 0.00085328
Iteration 20/25 | Loss: 0.00085328
Iteration 21/25 | Loss: 0.00085328
Iteration 22/25 | Loss: 0.00085328
Iteration 23/25 | Loss: 0.00085328
Iteration 24/25 | Loss: 0.00085328
Iteration 25/25 | Loss: 0.00085328
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0008532807696610689, 0.0008532807696610689, 0.0008532807696610689, 0.0008532807696610689, 0.0008532807696610689]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008532807696610689

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53848171
Iteration 2/25 | Loss: 0.00056976
Iteration 3/25 | Loss: 0.00056975
Iteration 4/25 | Loss: 0.00056975
Iteration 5/25 | Loss: 0.00056975
Iteration 6/25 | Loss: 0.00056975
Iteration 7/25 | Loss: 0.00056975
Iteration 8/25 | Loss: 0.00056975
Iteration 9/25 | Loss: 0.00056975
Iteration 10/25 | Loss: 0.00056975
Iteration 11/25 | Loss: 0.00056975
Iteration 12/25 | Loss: 0.00056975
Iteration 13/25 | Loss: 0.00056975
Iteration 14/25 | Loss: 0.00056975
Iteration 15/25 | Loss: 0.00056975
Iteration 16/25 | Loss: 0.00056975
Iteration 17/25 | Loss: 0.00056975
Iteration 18/25 | Loss: 0.00056975
Iteration 19/25 | Loss: 0.00056975
Iteration 20/25 | Loss: 0.00056975
Iteration 21/25 | Loss: 0.00056975
Iteration 22/25 | Loss: 0.00056975
Iteration 23/25 | Loss: 0.00056975
Iteration 24/25 | Loss: 0.00056975
Iteration 25/25 | Loss: 0.00056975

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056975
Iteration 2/1000 | Loss: 0.00004459
Iteration 3/1000 | Loss: 0.00003042
Iteration 4/1000 | Loss: 0.00002735
Iteration 5/1000 | Loss: 0.00002556
Iteration 6/1000 | Loss: 0.00002418
Iteration 7/1000 | Loss: 0.00002341
Iteration 8/1000 | Loss: 0.00002271
Iteration 9/1000 | Loss: 0.00002241
Iteration 10/1000 | Loss: 0.00002217
Iteration 11/1000 | Loss: 0.00002205
Iteration 12/1000 | Loss: 0.00002203
Iteration 13/1000 | Loss: 0.00002194
Iteration 14/1000 | Loss: 0.00002176
Iteration 15/1000 | Loss: 0.00002174
Iteration 16/1000 | Loss: 0.00002173
Iteration 17/1000 | Loss: 0.00002166
Iteration 18/1000 | Loss: 0.00002166
Iteration 19/1000 | Loss: 0.00002165
Iteration 20/1000 | Loss: 0.00002163
Iteration 21/1000 | Loss: 0.00002163
Iteration 22/1000 | Loss: 0.00002162
Iteration 23/1000 | Loss: 0.00002162
Iteration 24/1000 | Loss: 0.00002161
Iteration 25/1000 | Loss: 0.00002161
Iteration 26/1000 | Loss: 0.00002160
Iteration 27/1000 | Loss: 0.00002160
Iteration 28/1000 | Loss: 0.00002159
Iteration 29/1000 | Loss: 0.00002159
Iteration 30/1000 | Loss: 0.00002158
Iteration 31/1000 | Loss: 0.00002158
Iteration 32/1000 | Loss: 0.00002158
Iteration 33/1000 | Loss: 0.00002157
Iteration 34/1000 | Loss: 0.00002157
Iteration 35/1000 | Loss: 0.00002157
Iteration 36/1000 | Loss: 0.00002157
Iteration 37/1000 | Loss: 0.00002157
Iteration 38/1000 | Loss: 0.00002157
Iteration 39/1000 | Loss: 0.00002157
Iteration 40/1000 | Loss: 0.00002157
Iteration 41/1000 | Loss: 0.00002157
Iteration 42/1000 | Loss: 0.00002157
Iteration 43/1000 | Loss: 0.00002157
Iteration 44/1000 | Loss: 0.00002156
Iteration 45/1000 | Loss: 0.00002156
Iteration 46/1000 | Loss: 0.00002156
Iteration 47/1000 | Loss: 0.00002156
Iteration 48/1000 | Loss: 0.00002156
Iteration 49/1000 | Loss: 0.00002156
Iteration 50/1000 | Loss: 0.00002156
Iteration 51/1000 | Loss: 0.00002156
Iteration 52/1000 | Loss: 0.00002156
Iteration 53/1000 | Loss: 0.00002156
Iteration 54/1000 | Loss: 0.00002156
Iteration 55/1000 | Loss: 0.00002156
Iteration 56/1000 | Loss: 0.00002156
Iteration 57/1000 | Loss: 0.00002156
Iteration 58/1000 | Loss: 0.00002156
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 58. Stopping optimization.
Last 5 losses: [2.156288428523112e-05, 2.156288428523112e-05, 2.156288428523112e-05, 2.156288428523112e-05, 2.156288428523112e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.156288428523112e-05

Optimization complete. Final v2v error: 3.922136068344116 mm

Highest mean error: 4.21910285949707 mm for frame 232

Lowest mean error: 3.6428353786468506 mm for frame 93

Saving results

Total time: 33.443217515945435

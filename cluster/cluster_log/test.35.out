Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=35, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 1960-2015
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00771231
Iteration 2/25 | Loss: 0.00149455
Iteration 3/25 | Loss: 0.00090186
Iteration 4/25 | Loss: 0.00079244
Iteration 5/25 | Loss: 0.00076006
Iteration 6/25 | Loss: 0.00075148
Iteration 7/25 | Loss: 0.00074901
Iteration 8/25 | Loss: 0.00074834
Iteration 9/25 | Loss: 0.00074814
Iteration 10/25 | Loss: 0.00074814
Iteration 11/25 | Loss: 0.00074814
Iteration 12/25 | Loss: 0.00074814
Iteration 13/25 | Loss: 0.00074814
Iteration 14/25 | Loss: 0.00074814
Iteration 15/25 | Loss: 0.00074814
Iteration 16/25 | Loss: 0.00074814
Iteration 17/25 | Loss: 0.00074814
Iteration 18/25 | Loss: 0.00074814
Iteration 19/25 | Loss: 0.00074814
Iteration 20/25 | Loss: 0.00074814
Iteration 21/25 | Loss: 0.00074814
Iteration 22/25 | Loss: 0.00074814
Iteration 23/25 | Loss: 0.00074814
Iteration 24/25 | Loss: 0.00074814
Iteration 25/25 | Loss: 0.00074814

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.57647276
Iteration 2/25 | Loss: 0.00028008
Iteration 3/25 | Loss: 0.00028007
Iteration 4/25 | Loss: 0.00028007
Iteration 5/25 | Loss: 0.00028007
Iteration 6/25 | Loss: 0.00028007
Iteration 7/25 | Loss: 0.00028007
Iteration 8/25 | Loss: 0.00028007
Iteration 9/25 | Loss: 0.00028007
Iteration 10/25 | Loss: 0.00028007
Iteration 11/25 | Loss: 0.00028007
Iteration 12/25 | Loss: 0.00028007
Iteration 13/25 | Loss: 0.00028007
Iteration 14/25 | Loss: 0.00028007
Iteration 15/25 | Loss: 0.00028007
Iteration 16/25 | Loss: 0.00028007
Iteration 17/25 | Loss: 0.00028007
Iteration 18/25 | Loss: 0.00028007
Iteration 19/25 | Loss: 0.00028007
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0002800665097311139, 0.0002800665097311139, 0.0002800665097311139, 0.0002800665097311139, 0.0002800665097311139]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002800665097311139

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028007
Iteration 2/1000 | Loss: 0.00004958
Iteration 3/1000 | Loss: 0.00003480
Iteration 4/1000 | Loss: 0.00002872
Iteration 5/1000 | Loss: 0.00002652
Iteration 6/1000 | Loss: 0.00002476
Iteration 7/1000 | Loss: 0.00002352
Iteration 8/1000 | Loss: 0.00002262
Iteration 9/1000 | Loss: 0.00002197
Iteration 10/1000 | Loss: 0.00002156
Iteration 11/1000 | Loss: 0.00002121
Iteration 12/1000 | Loss: 0.00002094
Iteration 13/1000 | Loss: 0.00002092
Iteration 14/1000 | Loss: 0.00002074
Iteration 15/1000 | Loss: 0.00002060
Iteration 16/1000 | Loss: 0.00002057
Iteration 17/1000 | Loss: 0.00002055
Iteration 18/1000 | Loss: 0.00002054
Iteration 19/1000 | Loss: 0.00002052
Iteration 20/1000 | Loss: 0.00002052
Iteration 21/1000 | Loss: 0.00002052
Iteration 22/1000 | Loss: 0.00002052
Iteration 23/1000 | Loss: 0.00002052
Iteration 24/1000 | Loss: 0.00002051
Iteration 25/1000 | Loss: 0.00002050
Iteration 26/1000 | Loss: 0.00002049
Iteration 27/1000 | Loss: 0.00002048
Iteration 28/1000 | Loss: 0.00002048
Iteration 29/1000 | Loss: 0.00002048
Iteration 30/1000 | Loss: 0.00002047
Iteration 31/1000 | Loss: 0.00002047
Iteration 32/1000 | Loss: 0.00002047
Iteration 33/1000 | Loss: 0.00002047
Iteration 34/1000 | Loss: 0.00002046
Iteration 35/1000 | Loss: 0.00002046
Iteration 36/1000 | Loss: 0.00002046
Iteration 37/1000 | Loss: 0.00002045
Iteration 38/1000 | Loss: 0.00002045
Iteration 39/1000 | Loss: 0.00002045
Iteration 40/1000 | Loss: 0.00002044
Iteration 41/1000 | Loss: 0.00002044
Iteration 42/1000 | Loss: 0.00002044
Iteration 43/1000 | Loss: 0.00002043
Iteration 44/1000 | Loss: 0.00002043
Iteration 45/1000 | Loss: 0.00002043
Iteration 46/1000 | Loss: 0.00002042
Iteration 47/1000 | Loss: 0.00002042
Iteration 48/1000 | Loss: 0.00002042
Iteration 49/1000 | Loss: 0.00002042
Iteration 50/1000 | Loss: 0.00002041
Iteration 51/1000 | Loss: 0.00002041
Iteration 52/1000 | Loss: 0.00002041
Iteration 53/1000 | Loss: 0.00002041
Iteration 54/1000 | Loss: 0.00002040
Iteration 55/1000 | Loss: 0.00002040
Iteration 56/1000 | Loss: 0.00002040
Iteration 57/1000 | Loss: 0.00002040
Iteration 58/1000 | Loss: 0.00002039
Iteration 59/1000 | Loss: 0.00002039
Iteration 60/1000 | Loss: 0.00002039
Iteration 61/1000 | Loss: 0.00002039
Iteration 62/1000 | Loss: 0.00002038
Iteration 63/1000 | Loss: 0.00002038
Iteration 64/1000 | Loss: 0.00002038
Iteration 65/1000 | Loss: 0.00002038
Iteration 66/1000 | Loss: 0.00002038
Iteration 67/1000 | Loss: 0.00002038
Iteration 68/1000 | Loss: 0.00002038
Iteration 69/1000 | Loss: 0.00002038
Iteration 70/1000 | Loss: 0.00002037
Iteration 71/1000 | Loss: 0.00002037
Iteration 72/1000 | Loss: 0.00002037
Iteration 73/1000 | Loss: 0.00002037
Iteration 74/1000 | Loss: 0.00002037
Iteration 75/1000 | Loss: 0.00002037
Iteration 76/1000 | Loss: 0.00002037
Iteration 77/1000 | Loss: 0.00002037
Iteration 78/1000 | Loss: 0.00002037
Iteration 79/1000 | Loss: 0.00002037
Iteration 80/1000 | Loss: 0.00002037
Iteration 81/1000 | Loss: 0.00002037
Iteration 82/1000 | Loss: 0.00002037
Iteration 83/1000 | Loss: 0.00002036
Iteration 84/1000 | Loss: 0.00002036
Iteration 85/1000 | Loss: 0.00002036
Iteration 86/1000 | Loss: 0.00002036
Iteration 87/1000 | Loss: 0.00002036
Iteration 88/1000 | Loss: 0.00002036
Iteration 89/1000 | Loss: 0.00002036
Iteration 90/1000 | Loss: 0.00002036
Iteration 91/1000 | Loss: 0.00002036
Iteration 92/1000 | Loss: 0.00002036
Iteration 93/1000 | Loss: 0.00002036
Iteration 94/1000 | Loss: 0.00002036
Iteration 95/1000 | Loss: 0.00002036
Iteration 96/1000 | Loss: 0.00002036
Iteration 97/1000 | Loss: 0.00002036
Iteration 98/1000 | Loss: 0.00002036
Iteration 99/1000 | Loss: 0.00002036
Iteration 100/1000 | Loss: 0.00002036
Iteration 101/1000 | Loss: 0.00002036
Iteration 102/1000 | Loss: 0.00002036
Iteration 103/1000 | Loss: 0.00002036
Iteration 104/1000 | Loss: 0.00002036
Iteration 105/1000 | Loss: 0.00002036
Iteration 106/1000 | Loss: 0.00002036
Iteration 107/1000 | Loss: 0.00002036
Iteration 108/1000 | Loss: 0.00002036
Iteration 109/1000 | Loss: 0.00002036
Iteration 110/1000 | Loss: 0.00002036
Iteration 111/1000 | Loss: 0.00002036
Iteration 112/1000 | Loss: 0.00002036
Iteration 113/1000 | Loss: 0.00002036
Iteration 114/1000 | Loss: 0.00002036
Iteration 115/1000 | Loss: 0.00002036
Iteration 116/1000 | Loss: 0.00002036
Iteration 117/1000 | Loss: 0.00002036
Iteration 118/1000 | Loss: 0.00002036
Iteration 119/1000 | Loss: 0.00002036
Iteration 120/1000 | Loss: 0.00002036
Iteration 121/1000 | Loss: 0.00002036
Iteration 122/1000 | Loss: 0.00002036
Iteration 123/1000 | Loss: 0.00002036
Iteration 124/1000 | Loss: 0.00002036
Iteration 125/1000 | Loss: 0.00002036
Iteration 126/1000 | Loss: 0.00002036
Iteration 127/1000 | Loss: 0.00002036
Iteration 128/1000 | Loss: 0.00002036
Iteration 129/1000 | Loss: 0.00002036
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [2.0362633222248405e-05, 2.0362633222248405e-05, 2.0362633222248405e-05, 2.0362633222248405e-05, 2.0362633222248405e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0362633222248405e-05

Optimization complete. Final v2v error: 3.722285032272339 mm

Highest mean error: 5.667809009552002 mm for frame 33

Lowest mean error: 2.931058883666992 mm for frame 0

Saving results

Total time: 42.83058547973633
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00409320
Iteration 2/25 | Loss: 0.00114038
Iteration 3/25 | Loss: 0.00075773
Iteration 4/25 | Loss: 0.00065631
Iteration 5/25 | Loss: 0.00063889
Iteration 6/25 | Loss: 0.00063600
Iteration 7/25 | Loss: 0.00063535
Iteration 8/25 | Loss: 0.00063519
Iteration 9/25 | Loss: 0.00063519
Iteration 10/25 | Loss: 0.00063519
Iteration 11/25 | Loss: 0.00063519
Iteration 12/25 | Loss: 0.00063519
Iteration 13/25 | Loss: 0.00063519
Iteration 14/25 | Loss: 0.00063519
Iteration 15/25 | Loss: 0.00063519
Iteration 16/25 | Loss: 0.00063519
Iteration 17/25 | Loss: 0.00063519
Iteration 18/25 | Loss: 0.00063519
Iteration 19/25 | Loss: 0.00063519
Iteration 20/25 | Loss: 0.00063519
Iteration 21/25 | Loss: 0.00063519
Iteration 22/25 | Loss: 0.00063519
Iteration 23/25 | Loss: 0.00063519
Iteration 24/25 | Loss: 0.00063519
Iteration 25/25 | Loss: 0.00063519

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44593847
Iteration 2/25 | Loss: 0.00029923
Iteration 3/25 | Loss: 0.00029923
Iteration 4/25 | Loss: 0.00029923
Iteration 5/25 | Loss: 0.00029923
Iteration 6/25 | Loss: 0.00029923
Iteration 7/25 | Loss: 0.00029923
Iteration 8/25 | Loss: 0.00029923
Iteration 9/25 | Loss: 0.00029923
Iteration 10/25 | Loss: 0.00029923
Iteration 11/25 | Loss: 0.00029923
Iteration 12/25 | Loss: 0.00029923
Iteration 13/25 | Loss: 0.00029923
Iteration 14/25 | Loss: 0.00029923
Iteration 15/25 | Loss: 0.00029923
Iteration 16/25 | Loss: 0.00029923
Iteration 17/25 | Loss: 0.00029923
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0002992278023157269, 0.0002992278023157269, 0.0002992278023157269, 0.0002992278023157269, 0.0002992278023157269]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002992278023157269

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029923
Iteration 2/1000 | Loss: 0.00003327
Iteration 3/1000 | Loss: 0.00002233
Iteration 4/1000 | Loss: 0.00001812
Iteration 5/1000 | Loss: 0.00001685
Iteration 6/1000 | Loss: 0.00001599
Iteration 7/1000 | Loss: 0.00001545
Iteration 8/1000 | Loss: 0.00001505
Iteration 9/1000 | Loss: 0.00001481
Iteration 10/1000 | Loss: 0.00001458
Iteration 11/1000 | Loss: 0.00001438
Iteration 12/1000 | Loss: 0.00001419
Iteration 13/1000 | Loss: 0.00001415
Iteration 14/1000 | Loss: 0.00001412
Iteration 15/1000 | Loss: 0.00001412
Iteration 16/1000 | Loss: 0.00001409
Iteration 17/1000 | Loss: 0.00001408
Iteration 18/1000 | Loss: 0.00001408
Iteration 19/1000 | Loss: 0.00001404
Iteration 20/1000 | Loss: 0.00001404
Iteration 21/1000 | Loss: 0.00001402
Iteration 22/1000 | Loss: 0.00001402
Iteration 23/1000 | Loss: 0.00001401
Iteration 24/1000 | Loss: 0.00001401
Iteration 25/1000 | Loss: 0.00001401
Iteration 26/1000 | Loss: 0.00001400
Iteration 27/1000 | Loss: 0.00001400
Iteration 28/1000 | Loss: 0.00001399
Iteration 29/1000 | Loss: 0.00001399
Iteration 30/1000 | Loss: 0.00001398
Iteration 31/1000 | Loss: 0.00001398
Iteration 32/1000 | Loss: 0.00001398
Iteration 33/1000 | Loss: 0.00001397
Iteration 34/1000 | Loss: 0.00001397
Iteration 35/1000 | Loss: 0.00001397
Iteration 36/1000 | Loss: 0.00001396
Iteration 37/1000 | Loss: 0.00001395
Iteration 38/1000 | Loss: 0.00001395
Iteration 39/1000 | Loss: 0.00001394
Iteration 40/1000 | Loss: 0.00001394
Iteration 41/1000 | Loss: 0.00001394
Iteration 42/1000 | Loss: 0.00001393
Iteration 43/1000 | Loss: 0.00001393
Iteration 44/1000 | Loss: 0.00001392
Iteration 45/1000 | Loss: 0.00001392
Iteration 46/1000 | Loss: 0.00001392
Iteration 47/1000 | Loss: 0.00001391
Iteration 48/1000 | Loss: 0.00001391
Iteration 49/1000 | Loss: 0.00001391
Iteration 50/1000 | Loss: 0.00001391
Iteration 51/1000 | Loss: 0.00001390
Iteration 52/1000 | Loss: 0.00001390
Iteration 53/1000 | Loss: 0.00001390
Iteration 54/1000 | Loss: 0.00001390
Iteration 55/1000 | Loss: 0.00001390
Iteration 56/1000 | Loss: 0.00001390
Iteration 57/1000 | Loss: 0.00001390
Iteration 58/1000 | Loss: 0.00001390
Iteration 59/1000 | Loss: 0.00001390
Iteration 60/1000 | Loss: 0.00001389
Iteration 61/1000 | Loss: 0.00001389
Iteration 62/1000 | Loss: 0.00001389
Iteration 63/1000 | Loss: 0.00001389
Iteration 64/1000 | Loss: 0.00001389
Iteration 65/1000 | Loss: 0.00001389
Iteration 66/1000 | Loss: 0.00001389
Iteration 67/1000 | Loss: 0.00001389
Iteration 68/1000 | Loss: 0.00001389
Iteration 69/1000 | Loss: 0.00001389
Iteration 70/1000 | Loss: 0.00001388
Iteration 71/1000 | Loss: 0.00001388
Iteration 72/1000 | Loss: 0.00001388
Iteration 73/1000 | Loss: 0.00001388
Iteration 74/1000 | Loss: 0.00001388
Iteration 75/1000 | Loss: 0.00001388
Iteration 76/1000 | Loss: 0.00001388
Iteration 77/1000 | Loss: 0.00001388
Iteration 78/1000 | Loss: 0.00001388
Iteration 79/1000 | Loss: 0.00001387
Iteration 80/1000 | Loss: 0.00001387
Iteration 81/1000 | Loss: 0.00001387
Iteration 82/1000 | Loss: 0.00001387
Iteration 83/1000 | Loss: 0.00001387
Iteration 84/1000 | Loss: 0.00001387
Iteration 85/1000 | Loss: 0.00001387
Iteration 86/1000 | Loss: 0.00001386
Iteration 87/1000 | Loss: 0.00001386
Iteration 88/1000 | Loss: 0.00001386
Iteration 89/1000 | Loss: 0.00001386
Iteration 90/1000 | Loss: 0.00001386
Iteration 91/1000 | Loss: 0.00001386
Iteration 92/1000 | Loss: 0.00001386
Iteration 93/1000 | Loss: 0.00001385
Iteration 94/1000 | Loss: 0.00001385
Iteration 95/1000 | Loss: 0.00001385
Iteration 96/1000 | Loss: 0.00001385
Iteration 97/1000 | Loss: 0.00001385
Iteration 98/1000 | Loss: 0.00001385
Iteration 99/1000 | Loss: 0.00001384
Iteration 100/1000 | Loss: 0.00001384
Iteration 101/1000 | Loss: 0.00001384
Iteration 102/1000 | Loss: 0.00001384
Iteration 103/1000 | Loss: 0.00001384
Iteration 104/1000 | Loss: 0.00001383
Iteration 105/1000 | Loss: 0.00001383
Iteration 106/1000 | Loss: 0.00001383
Iteration 107/1000 | Loss: 0.00001383
Iteration 108/1000 | Loss: 0.00001383
Iteration 109/1000 | Loss: 0.00001382
Iteration 110/1000 | Loss: 0.00001382
Iteration 111/1000 | Loss: 0.00001382
Iteration 112/1000 | Loss: 0.00001382
Iteration 113/1000 | Loss: 0.00001382
Iteration 114/1000 | Loss: 0.00001382
Iteration 115/1000 | Loss: 0.00001382
Iteration 116/1000 | Loss: 0.00001382
Iteration 117/1000 | Loss: 0.00001382
Iteration 118/1000 | Loss: 0.00001382
Iteration 119/1000 | Loss: 0.00001381
Iteration 120/1000 | Loss: 0.00001381
Iteration 121/1000 | Loss: 0.00001381
Iteration 122/1000 | Loss: 0.00001381
Iteration 123/1000 | Loss: 0.00001381
Iteration 124/1000 | Loss: 0.00001381
Iteration 125/1000 | Loss: 0.00001381
Iteration 126/1000 | Loss: 0.00001381
Iteration 127/1000 | Loss: 0.00001381
Iteration 128/1000 | Loss: 0.00001380
Iteration 129/1000 | Loss: 0.00001380
Iteration 130/1000 | Loss: 0.00001380
Iteration 131/1000 | Loss: 0.00001380
Iteration 132/1000 | Loss: 0.00001380
Iteration 133/1000 | Loss: 0.00001380
Iteration 134/1000 | Loss: 0.00001380
Iteration 135/1000 | Loss: 0.00001380
Iteration 136/1000 | Loss: 0.00001380
Iteration 137/1000 | Loss: 0.00001380
Iteration 138/1000 | Loss: 0.00001380
Iteration 139/1000 | Loss: 0.00001380
Iteration 140/1000 | Loss: 0.00001380
Iteration 141/1000 | Loss: 0.00001380
Iteration 142/1000 | Loss: 0.00001380
Iteration 143/1000 | Loss: 0.00001380
Iteration 144/1000 | Loss: 0.00001380
Iteration 145/1000 | Loss: 0.00001380
Iteration 146/1000 | Loss: 0.00001380
Iteration 147/1000 | Loss: 0.00001380
Iteration 148/1000 | Loss: 0.00001380
Iteration 149/1000 | Loss: 0.00001380
Iteration 150/1000 | Loss: 0.00001380
Iteration 151/1000 | Loss: 0.00001380
Iteration 152/1000 | Loss: 0.00001380
Iteration 153/1000 | Loss: 0.00001380
Iteration 154/1000 | Loss: 0.00001380
Iteration 155/1000 | Loss: 0.00001380
Iteration 156/1000 | Loss: 0.00001380
Iteration 157/1000 | Loss: 0.00001380
Iteration 158/1000 | Loss: 0.00001380
Iteration 159/1000 | Loss: 0.00001380
Iteration 160/1000 | Loss: 0.00001380
Iteration 161/1000 | Loss: 0.00001380
Iteration 162/1000 | Loss: 0.00001380
Iteration 163/1000 | Loss: 0.00001380
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [1.3803618458041456e-05, 1.3803618458041456e-05, 1.3803618458041456e-05, 1.3803618458041456e-05, 1.3803618458041456e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3803618458041456e-05

Optimization complete. Final v2v error: 3.172497034072876 mm

Highest mean error: 3.9305925369262695 mm for frame 72

Lowest mean error: 2.7993977069854736 mm for frame 94

Saving results

Total time: 38.76948070526123
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1042/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1042.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1042
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00820058
Iteration 2/25 | Loss: 0.00078868
Iteration 3/25 | Loss: 0.00061942
Iteration 4/25 | Loss: 0.00059999
Iteration 5/25 | Loss: 0.00059408
Iteration 6/25 | Loss: 0.00059273
Iteration 7/25 | Loss: 0.00059258
Iteration 8/25 | Loss: 0.00059258
Iteration 9/25 | Loss: 0.00059258
Iteration 10/25 | Loss: 0.00059258
Iteration 11/25 | Loss: 0.00059258
Iteration 12/25 | Loss: 0.00059258
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0005925754085183144, 0.0005925754085183144, 0.0005925754085183144, 0.0005925754085183144, 0.0005925754085183144]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005925754085183144

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46548772
Iteration 2/25 | Loss: 0.00026063
Iteration 3/25 | Loss: 0.00026062
Iteration 4/25 | Loss: 0.00026062
Iteration 5/25 | Loss: 0.00026062
Iteration 6/25 | Loss: 0.00026062
Iteration 7/25 | Loss: 0.00026062
Iteration 8/25 | Loss: 0.00026062
Iteration 9/25 | Loss: 0.00026062
Iteration 10/25 | Loss: 0.00026062
Iteration 11/25 | Loss: 0.00026062
Iteration 12/25 | Loss: 0.00026062
Iteration 13/25 | Loss: 0.00026062
Iteration 14/25 | Loss: 0.00026062
Iteration 15/25 | Loss: 0.00026062
Iteration 16/25 | Loss: 0.00026062
Iteration 17/25 | Loss: 0.00026062
Iteration 18/25 | Loss: 0.00026062
Iteration 19/25 | Loss: 0.00026062
Iteration 20/25 | Loss: 0.00026062
Iteration 21/25 | Loss: 0.00026062
Iteration 22/25 | Loss: 0.00026062
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0002606214547995478, 0.0002606214547995478, 0.0002606214547995478, 0.0002606214547995478, 0.0002606214547995478]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002606214547995478

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026062
Iteration 2/1000 | Loss: 0.00002096
Iteration 3/1000 | Loss: 0.00001450
Iteration 4/1000 | Loss: 0.00001220
Iteration 5/1000 | Loss: 0.00001135
Iteration 6/1000 | Loss: 0.00001099
Iteration 7/1000 | Loss: 0.00001068
Iteration 8/1000 | Loss: 0.00001056
Iteration 9/1000 | Loss: 0.00001055
Iteration 10/1000 | Loss: 0.00001051
Iteration 11/1000 | Loss: 0.00001042
Iteration 12/1000 | Loss: 0.00001042
Iteration 13/1000 | Loss: 0.00001040
Iteration 14/1000 | Loss: 0.00001037
Iteration 15/1000 | Loss: 0.00001036
Iteration 16/1000 | Loss: 0.00001036
Iteration 17/1000 | Loss: 0.00001035
Iteration 18/1000 | Loss: 0.00001035
Iteration 19/1000 | Loss: 0.00001034
Iteration 20/1000 | Loss: 0.00001034
Iteration 21/1000 | Loss: 0.00001034
Iteration 22/1000 | Loss: 0.00001034
Iteration 23/1000 | Loss: 0.00001033
Iteration 24/1000 | Loss: 0.00001032
Iteration 25/1000 | Loss: 0.00001028
Iteration 26/1000 | Loss: 0.00001026
Iteration 27/1000 | Loss: 0.00001025
Iteration 28/1000 | Loss: 0.00001025
Iteration 29/1000 | Loss: 0.00001025
Iteration 30/1000 | Loss: 0.00001025
Iteration 31/1000 | Loss: 0.00001024
Iteration 32/1000 | Loss: 0.00001024
Iteration 33/1000 | Loss: 0.00001024
Iteration 34/1000 | Loss: 0.00001024
Iteration 35/1000 | Loss: 0.00001023
Iteration 36/1000 | Loss: 0.00001023
Iteration 37/1000 | Loss: 0.00001023
Iteration 38/1000 | Loss: 0.00001022
Iteration 39/1000 | Loss: 0.00001022
Iteration 40/1000 | Loss: 0.00001022
Iteration 41/1000 | Loss: 0.00001022
Iteration 42/1000 | Loss: 0.00001021
Iteration 43/1000 | Loss: 0.00001021
Iteration 44/1000 | Loss: 0.00001021
Iteration 45/1000 | Loss: 0.00001021
Iteration 46/1000 | Loss: 0.00001020
Iteration 47/1000 | Loss: 0.00001019
Iteration 48/1000 | Loss: 0.00001019
Iteration 49/1000 | Loss: 0.00001019
Iteration 50/1000 | Loss: 0.00001018
Iteration 51/1000 | Loss: 0.00001018
Iteration 52/1000 | Loss: 0.00001018
Iteration 53/1000 | Loss: 0.00001018
Iteration 54/1000 | Loss: 0.00001018
Iteration 55/1000 | Loss: 0.00001017
Iteration 56/1000 | Loss: 0.00001017
Iteration 57/1000 | Loss: 0.00001016
Iteration 58/1000 | Loss: 0.00001016
Iteration 59/1000 | Loss: 0.00001016
Iteration 60/1000 | Loss: 0.00001016
Iteration 61/1000 | Loss: 0.00001015
Iteration 62/1000 | Loss: 0.00001015
Iteration 63/1000 | Loss: 0.00001012
Iteration 64/1000 | Loss: 0.00001012
Iteration 65/1000 | Loss: 0.00001012
Iteration 66/1000 | Loss: 0.00001012
Iteration 67/1000 | Loss: 0.00001011
Iteration 68/1000 | Loss: 0.00001011
Iteration 69/1000 | Loss: 0.00001011
Iteration 70/1000 | Loss: 0.00001011
Iteration 71/1000 | Loss: 0.00001011
Iteration 72/1000 | Loss: 0.00001011
Iteration 73/1000 | Loss: 0.00001010
Iteration 74/1000 | Loss: 0.00001010
Iteration 75/1000 | Loss: 0.00001010
Iteration 76/1000 | Loss: 0.00001010
Iteration 77/1000 | Loss: 0.00001010
Iteration 78/1000 | Loss: 0.00001010
Iteration 79/1000 | Loss: 0.00001010
Iteration 80/1000 | Loss: 0.00001010
Iteration 81/1000 | Loss: 0.00001010
Iteration 82/1000 | Loss: 0.00001010
Iteration 83/1000 | Loss: 0.00001010
Iteration 84/1000 | Loss: 0.00001010
Iteration 85/1000 | Loss: 0.00001010
Iteration 86/1000 | Loss: 0.00001010
Iteration 87/1000 | Loss: 0.00001009
Iteration 88/1000 | Loss: 0.00001009
Iteration 89/1000 | Loss: 0.00001009
Iteration 90/1000 | Loss: 0.00001009
Iteration 91/1000 | Loss: 0.00001009
Iteration 92/1000 | Loss: 0.00001009
Iteration 93/1000 | Loss: 0.00001009
Iteration 94/1000 | Loss: 0.00001009
Iteration 95/1000 | Loss: 0.00001009
Iteration 96/1000 | Loss: 0.00001009
Iteration 97/1000 | Loss: 0.00001009
Iteration 98/1000 | Loss: 0.00001009
Iteration 99/1000 | Loss: 0.00001009
Iteration 100/1000 | Loss: 0.00001009
Iteration 101/1000 | Loss: 0.00001009
Iteration 102/1000 | Loss: 0.00001008
Iteration 103/1000 | Loss: 0.00001008
Iteration 104/1000 | Loss: 0.00001008
Iteration 105/1000 | Loss: 0.00001008
Iteration 106/1000 | Loss: 0.00001008
Iteration 107/1000 | Loss: 0.00001008
Iteration 108/1000 | Loss: 0.00001008
Iteration 109/1000 | Loss: 0.00001008
Iteration 110/1000 | Loss: 0.00001008
Iteration 111/1000 | Loss: 0.00001008
Iteration 112/1000 | Loss: 0.00001008
Iteration 113/1000 | Loss: 0.00001007
Iteration 114/1000 | Loss: 0.00001007
Iteration 115/1000 | Loss: 0.00001007
Iteration 116/1000 | Loss: 0.00001007
Iteration 117/1000 | Loss: 0.00001007
Iteration 118/1000 | Loss: 0.00001007
Iteration 119/1000 | Loss: 0.00001007
Iteration 120/1000 | Loss: 0.00001007
Iteration 121/1000 | Loss: 0.00001007
Iteration 122/1000 | Loss: 0.00001007
Iteration 123/1000 | Loss: 0.00001007
Iteration 124/1000 | Loss: 0.00001007
Iteration 125/1000 | Loss: 0.00001007
Iteration 126/1000 | Loss: 0.00001007
Iteration 127/1000 | Loss: 0.00001007
Iteration 128/1000 | Loss: 0.00001007
Iteration 129/1000 | Loss: 0.00001006
Iteration 130/1000 | Loss: 0.00001006
Iteration 131/1000 | Loss: 0.00001006
Iteration 132/1000 | Loss: 0.00001006
Iteration 133/1000 | Loss: 0.00001006
Iteration 134/1000 | Loss: 0.00001006
Iteration 135/1000 | Loss: 0.00001006
Iteration 136/1000 | Loss: 0.00001006
Iteration 137/1000 | Loss: 0.00001006
Iteration 138/1000 | Loss: 0.00001006
Iteration 139/1000 | Loss: 0.00001005
Iteration 140/1000 | Loss: 0.00001005
Iteration 141/1000 | Loss: 0.00001005
Iteration 142/1000 | Loss: 0.00001005
Iteration 143/1000 | Loss: 0.00001005
Iteration 144/1000 | Loss: 0.00001005
Iteration 145/1000 | Loss: 0.00001005
Iteration 146/1000 | Loss: 0.00001005
Iteration 147/1000 | Loss: 0.00001005
Iteration 148/1000 | Loss: 0.00001005
Iteration 149/1000 | Loss: 0.00001005
Iteration 150/1000 | Loss: 0.00001005
Iteration 151/1000 | Loss: 0.00001004
Iteration 152/1000 | Loss: 0.00001004
Iteration 153/1000 | Loss: 0.00001004
Iteration 154/1000 | Loss: 0.00001004
Iteration 155/1000 | Loss: 0.00001004
Iteration 156/1000 | Loss: 0.00001004
Iteration 157/1000 | Loss: 0.00001004
Iteration 158/1000 | Loss: 0.00001004
Iteration 159/1000 | Loss: 0.00001003
Iteration 160/1000 | Loss: 0.00001003
Iteration 161/1000 | Loss: 0.00001003
Iteration 162/1000 | Loss: 0.00001003
Iteration 163/1000 | Loss: 0.00001002
Iteration 164/1000 | Loss: 0.00001002
Iteration 165/1000 | Loss: 0.00001002
Iteration 166/1000 | Loss: 0.00001002
Iteration 167/1000 | Loss: 0.00001002
Iteration 168/1000 | Loss: 0.00001002
Iteration 169/1000 | Loss: 0.00001002
Iteration 170/1000 | Loss: 0.00001002
Iteration 171/1000 | Loss: 0.00001002
Iteration 172/1000 | Loss: 0.00001001
Iteration 173/1000 | Loss: 0.00001001
Iteration 174/1000 | Loss: 0.00001001
Iteration 175/1000 | Loss: 0.00001001
Iteration 176/1000 | Loss: 0.00001001
Iteration 177/1000 | Loss: 0.00001001
Iteration 178/1000 | Loss: 0.00001001
Iteration 179/1000 | Loss: 0.00001001
Iteration 180/1000 | Loss: 0.00001001
Iteration 181/1000 | Loss: 0.00001001
Iteration 182/1000 | Loss: 0.00001001
Iteration 183/1000 | Loss: 0.00001001
Iteration 184/1000 | Loss: 0.00001001
Iteration 185/1000 | Loss: 0.00001001
Iteration 186/1000 | Loss: 0.00001000
Iteration 187/1000 | Loss: 0.00001000
Iteration 188/1000 | Loss: 0.00001000
Iteration 189/1000 | Loss: 0.00001000
Iteration 190/1000 | Loss: 0.00001000
Iteration 191/1000 | Loss: 0.00001000
Iteration 192/1000 | Loss: 0.00001000
Iteration 193/1000 | Loss: 0.00001000
Iteration 194/1000 | Loss: 0.00001000
Iteration 195/1000 | Loss: 0.00001000
Iteration 196/1000 | Loss: 0.00001000
Iteration 197/1000 | Loss: 0.00001000
Iteration 198/1000 | Loss: 0.00001000
Iteration 199/1000 | Loss: 0.00001000
Iteration 200/1000 | Loss: 0.00001000
Iteration 201/1000 | Loss: 0.00001000
Iteration 202/1000 | Loss: 0.00001000
Iteration 203/1000 | Loss: 0.00001000
Iteration 204/1000 | Loss: 0.00001000
Iteration 205/1000 | Loss: 0.00001000
Iteration 206/1000 | Loss: 0.00001000
Iteration 207/1000 | Loss: 0.00001000
Iteration 208/1000 | Loss: 0.00001000
Iteration 209/1000 | Loss: 0.00001000
Iteration 210/1000 | Loss: 0.00001000
Iteration 211/1000 | Loss: 0.00001000
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 211. Stopping optimization.
Last 5 losses: [9.997209417633712e-06, 9.997209417633712e-06, 9.997209417633712e-06, 9.997209417633712e-06, 9.997209417633712e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.997209417633712e-06

Optimization complete. Final v2v error: 2.663036823272705 mm

Highest mean error: 2.8150079250335693 mm for frame 58

Lowest mean error: 2.5585057735443115 mm for frame 16

Saving results

Total time: 36.94171738624573
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1044/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1044.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1044
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00478950
Iteration 2/25 | Loss: 0.00111225
Iteration 3/25 | Loss: 0.00071447
Iteration 4/25 | Loss: 0.00064585
Iteration 5/25 | Loss: 0.00062907
Iteration 6/25 | Loss: 0.00062536
Iteration 7/25 | Loss: 0.00062370
Iteration 8/25 | Loss: 0.00062336
Iteration 9/25 | Loss: 0.00062336
Iteration 10/25 | Loss: 0.00062336
Iteration 11/25 | Loss: 0.00062336
Iteration 12/25 | Loss: 0.00062336
Iteration 13/25 | Loss: 0.00062336
Iteration 14/25 | Loss: 0.00062336
Iteration 15/25 | Loss: 0.00062336
Iteration 16/25 | Loss: 0.00062336
Iteration 17/25 | Loss: 0.00062336
Iteration 18/25 | Loss: 0.00062336
Iteration 19/25 | Loss: 0.00062336
Iteration 20/25 | Loss: 0.00062336
Iteration 21/25 | Loss: 0.00062336
Iteration 22/25 | Loss: 0.00062336
Iteration 23/25 | Loss: 0.00062336
Iteration 24/25 | Loss: 0.00062336
Iteration 25/25 | Loss: 0.00062336

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47353518
Iteration 2/25 | Loss: 0.00027354
Iteration 3/25 | Loss: 0.00027354
Iteration 4/25 | Loss: 0.00027354
Iteration 5/25 | Loss: 0.00027354
Iteration 6/25 | Loss: 0.00027354
Iteration 7/25 | Loss: 0.00027354
Iteration 8/25 | Loss: 0.00027354
Iteration 9/25 | Loss: 0.00027354
Iteration 10/25 | Loss: 0.00027354
Iteration 11/25 | Loss: 0.00027354
Iteration 12/25 | Loss: 0.00027354
Iteration 13/25 | Loss: 0.00027354
Iteration 14/25 | Loss: 0.00027354
Iteration 15/25 | Loss: 0.00027354
Iteration 16/25 | Loss: 0.00027354
Iteration 17/25 | Loss: 0.00027354
Iteration 18/25 | Loss: 0.00027354
Iteration 19/25 | Loss: 0.00027354
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00027353918994776905, 0.00027353918994776905, 0.00027353918994776905, 0.00027353918994776905, 0.00027353918994776905]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00027353918994776905

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027354
Iteration 2/1000 | Loss: 0.00002715
Iteration 3/1000 | Loss: 0.00001696
Iteration 4/1000 | Loss: 0.00001573
Iteration 5/1000 | Loss: 0.00001508
Iteration 6/1000 | Loss: 0.00001449
Iteration 7/1000 | Loss: 0.00001414
Iteration 8/1000 | Loss: 0.00001387
Iteration 9/1000 | Loss: 0.00001372
Iteration 10/1000 | Loss: 0.00001370
Iteration 11/1000 | Loss: 0.00001364
Iteration 12/1000 | Loss: 0.00001360
Iteration 13/1000 | Loss: 0.00001355
Iteration 14/1000 | Loss: 0.00001355
Iteration 15/1000 | Loss: 0.00001354
Iteration 16/1000 | Loss: 0.00001354
Iteration 17/1000 | Loss: 0.00001353
Iteration 18/1000 | Loss: 0.00001353
Iteration 19/1000 | Loss: 0.00001352
Iteration 20/1000 | Loss: 0.00001352
Iteration 21/1000 | Loss: 0.00001348
Iteration 22/1000 | Loss: 0.00001347
Iteration 23/1000 | Loss: 0.00001347
Iteration 24/1000 | Loss: 0.00001345
Iteration 25/1000 | Loss: 0.00001345
Iteration 26/1000 | Loss: 0.00001344
Iteration 27/1000 | Loss: 0.00001344
Iteration 28/1000 | Loss: 0.00001344
Iteration 29/1000 | Loss: 0.00001342
Iteration 30/1000 | Loss: 0.00001342
Iteration 31/1000 | Loss: 0.00001341
Iteration 32/1000 | Loss: 0.00001341
Iteration 33/1000 | Loss: 0.00001340
Iteration 34/1000 | Loss: 0.00001340
Iteration 35/1000 | Loss: 0.00001338
Iteration 36/1000 | Loss: 0.00001337
Iteration 37/1000 | Loss: 0.00001337
Iteration 38/1000 | Loss: 0.00001336
Iteration 39/1000 | Loss: 0.00001335
Iteration 40/1000 | Loss: 0.00001335
Iteration 41/1000 | Loss: 0.00001334
Iteration 42/1000 | Loss: 0.00001334
Iteration 43/1000 | Loss: 0.00001333
Iteration 44/1000 | Loss: 0.00001333
Iteration 45/1000 | Loss: 0.00001333
Iteration 46/1000 | Loss: 0.00001332
Iteration 47/1000 | Loss: 0.00001332
Iteration 48/1000 | Loss: 0.00001332
Iteration 49/1000 | Loss: 0.00001332
Iteration 50/1000 | Loss: 0.00001332
Iteration 51/1000 | Loss: 0.00001331
Iteration 52/1000 | Loss: 0.00001331
Iteration 53/1000 | Loss: 0.00001331
Iteration 54/1000 | Loss: 0.00001331
Iteration 55/1000 | Loss: 0.00001331
Iteration 56/1000 | Loss: 0.00001331
Iteration 57/1000 | Loss: 0.00001331
Iteration 58/1000 | Loss: 0.00001330
Iteration 59/1000 | Loss: 0.00001330
Iteration 60/1000 | Loss: 0.00001330
Iteration 61/1000 | Loss: 0.00001330
Iteration 62/1000 | Loss: 0.00001330
Iteration 63/1000 | Loss: 0.00001330
Iteration 64/1000 | Loss: 0.00001330
Iteration 65/1000 | Loss: 0.00001330
Iteration 66/1000 | Loss: 0.00001330
Iteration 67/1000 | Loss: 0.00001330
Iteration 68/1000 | Loss: 0.00001329
Iteration 69/1000 | Loss: 0.00001329
Iteration 70/1000 | Loss: 0.00001329
Iteration 71/1000 | Loss: 0.00001329
Iteration 72/1000 | Loss: 0.00001329
Iteration 73/1000 | Loss: 0.00001329
Iteration 74/1000 | Loss: 0.00001329
Iteration 75/1000 | Loss: 0.00001329
Iteration 76/1000 | Loss: 0.00001329
Iteration 77/1000 | Loss: 0.00001328
Iteration 78/1000 | Loss: 0.00001328
Iteration 79/1000 | Loss: 0.00001328
Iteration 80/1000 | Loss: 0.00001328
Iteration 81/1000 | Loss: 0.00001328
Iteration 82/1000 | Loss: 0.00001328
Iteration 83/1000 | Loss: 0.00001328
Iteration 84/1000 | Loss: 0.00001328
Iteration 85/1000 | Loss: 0.00001328
Iteration 86/1000 | Loss: 0.00001328
Iteration 87/1000 | Loss: 0.00001328
Iteration 88/1000 | Loss: 0.00001328
Iteration 89/1000 | Loss: 0.00001328
Iteration 90/1000 | Loss: 0.00001328
Iteration 91/1000 | Loss: 0.00001328
Iteration 92/1000 | Loss: 0.00001328
Iteration 93/1000 | Loss: 0.00001328
Iteration 94/1000 | Loss: 0.00001328
Iteration 95/1000 | Loss: 0.00001328
Iteration 96/1000 | Loss: 0.00001328
Iteration 97/1000 | Loss: 0.00001328
Iteration 98/1000 | Loss: 0.00001328
Iteration 99/1000 | Loss: 0.00001328
Iteration 100/1000 | Loss: 0.00001328
Iteration 101/1000 | Loss: 0.00001328
Iteration 102/1000 | Loss: 0.00001328
Iteration 103/1000 | Loss: 0.00001328
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.3281547580845654e-05, 1.3281547580845654e-05, 1.3281547580845654e-05, 1.3281547580845654e-05, 1.3281547580845654e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3281547580845654e-05

Optimization complete. Final v2v error: 2.8894095420837402 mm

Highest mean error: 4.473654270172119 mm for frame 83

Lowest mean error: 2.407364845275879 mm for frame 150

Saving results

Total time: 34.83767819404602
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00828410
Iteration 2/25 | Loss: 0.00085119
Iteration 3/25 | Loss: 0.00067429
Iteration 4/25 | Loss: 0.00064209
Iteration 5/25 | Loss: 0.00063236
Iteration 6/25 | Loss: 0.00062976
Iteration 7/25 | Loss: 0.00062925
Iteration 8/25 | Loss: 0.00062922
Iteration 9/25 | Loss: 0.00062922
Iteration 10/25 | Loss: 0.00062922
Iteration 11/25 | Loss: 0.00062922
Iteration 12/25 | Loss: 0.00062922
Iteration 13/25 | Loss: 0.00062922
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006292174221016467, 0.0006292174221016467, 0.0006292174221016467, 0.0006292174221016467, 0.0006292174221016467]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006292174221016467

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50326395
Iteration 2/25 | Loss: 0.00035434
Iteration 3/25 | Loss: 0.00035434
Iteration 4/25 | Loss: 0.00035434
Iteration 5/25 | Loss: 0.00035434
Iteration 6/25 | Loss: 0.00035434
Iteration 7/25 | Loss: 0.00035434
Iteration 8/25 | Loss: 0.00035434
Iteration 9/25 | Loss: 0.00035434
Iteration 10/25 | Loss: 0.00035433
Iteration 11/25 | Loss: 0.00035433
Iteration 12/25 | Loss: 0.00035433
Iteration 13/25 | Loss: 0.00035433
Iteration 14/25 | Loss: 0.00035433
Iteration 15/25 | Loss: 0.00035433
Iteration 16/25 | Loss: 0.00035433
Iteration 17/25 | Loss: 0.00035433
Iteration 18/25 | Loss: 0.00035433
Iteration 19/25 | Loss: 0.00035433
Iteration 20/25 | Loss: 0.00035433
Iteration 21/25 | Loss: 0.00035433
Iteration 22/25 | Loss: 0.00035433
Iteration 23/25 | Loss: 0.00035433
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00035433477023616433, 0.00035433477023616433, 0.00035433477023616433, 0.00035433477023616433, 0.00035433477023616433]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00035433477023616433

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035433
Iteration 2/1000 | Loss: 0.00003228
Iteration 3/1000 | Loss: 0.00002018
Iteration 4/1000 | Loss: 0.00001815
Iteration 5/1000 | Loss: 0.00001709
Iteration 6/1000 | Loss: 0.00001646
Iteration 7/1000 | Loss: 0.00001607
Iteration 8/1000 | Loss: 0.00001570
Iteration 9/1000 | Loss: 0.00001549
Iteration 10/1000 | Loss: 0.00001527
Iteration 11/1000 | Loss: 0.00001516
Iteration 12/1000 | Loss: 0.00001507
Iteration 13/1000 | Loss: 0.00001503
Iteration 14/1000 | Loss: 0.00001496
Iteration 15/1000 | Loss: 0.00001496
Iteration 16/1000 | Loss: 0.00001494
Iteration 17/1000 | Loss: 0.00001494
Iteration 18/1000 | Loss: 0.00001493
Iteration 19/1000 | Loss: 0.00001491
Iteration 20/1000 | Loss: 0.00001489
Iteration 21/1000 | Loss: 0.00001488
Iteration 22/1000 | Loss: 0.00001488
Iteration 23/1000 | Loss: 0.00001487
Iteration 24/1000 | Loss: 0.00001487
Iteration 25/1000 | Loss: 0.00001486
Iteration 26/1000 | Loss: 0.00001486
Iteration 27/1000 | Loss: 0.00001486
Iteration 28/1000 | Loss: 0.00001485
Iteration 29/1000 | Loss: 0.00001485
Iteration 30/1000 | Loss: 0.00001485
Iteration 31/1000 | Loss: 0.00001484
Iteration 32/1000 | Loss: 0.00001484
Iteration 33/1000 | Loss: 0.00001484
Iteration 34/1000 | Loss: 0.00001483
Iteration 35/1000 | Loss: 0.00001483
Iteration 36/1000 | Loss: 0.00001483
Iteration 37/1000 | Loss: 0.00001483
Iteration 38/1000 | Loss: 0.00001482
Iteration 39/1000 | Loss: 0.00001482
Iteration 40/1000 | Loss: 0.00001482
Iteration 41/1000 | Loss: 0.00001481
Iteration 42/1000 | Loss: 0.00001481
Iteration 43/1000 | Loss: 0.00001481
Iteration 44/1000 | Loss: 0.00001481
Iteration 45/1000 | Loss: 0.00001480
Iteration 46/1000 | Loss: 0.00001480
Iteration 47/1000 | Loss: 0.00001480
Iteration 48/1000 | Loss: 0.00001480
Iteration 49/1000 | Loss: 0.00001480
Iteration 50/1000 | Loss: 0.00001479
Iteration 51/1000 | Loss: 0.00001479
Iteration 52/1000 | Loss: 0.00001479
Iteration 53/1000 | Loss: 0.00001478
Iteration 54/1000 | Loss: 0.00001478
Iteration 55/1000 | Loss: 0.00001478
Iteration 56/1000 | Loss: 0.00001477
Iteration 57/1000 | Loss: 0.00001477
Iteration 58/1000 | Loss: 0.00001477
Iteration 59/1000 | Loss: 0.00001477
Iteration 60/1000 | Loss: 0.00001476
Iteration 61/1000 | Loss: 0.00001476
Iteration 62/1000 | Loss: 0.00001476
Iteration 63/1000 | Loss: 0.00001476
Iteration 64/1000 | Loss: 0.00001476
Iteration 65/1000 | Loss: 0.00001475
Iteration 66/1000 | Loss: 0.00001475
Iteration 67/1000 | Loss: 0.00001475
Iteration 68/1000 | Loss: 0.00001474
Iteration 69/1000 | Loss: 0.00001474
Iteration 70/1000 | Loss: 0.00001474
Iteration 71/1000 | Loss: 0.00001474
Iteration 72/1000 | Loss: 0.00001474
Iteration 73/1000 | Loss: 0.00001473
Iteration 74/1000 | Loss: 0.00001473
Iteration 75/1000 | Loss: 0.00001473
Iteration 76/1000 | Loss: 0.00001473
Iteration 77/1000 | Loss: 0.00001473
Iteration 78/1000 | Loss: 0.00001473
Iteration 79/1000 | Loss: 0.00001473
Iteration 80/1000 | Loss: 0.00001473
Iteration 81/1000 | Loss: 0.00001472
Iteration 82/1000 | Loss: 0.00001472
Iteration 83/1000 | Loss: 0.00001471
Iteration 84/1000 | Loss: 0.00001471
Iteration 85/1000 | Loss: 0.00001471
Iteration 86/1000 | Loss: 0.00001471
Iteration 87/1000 | Loss: 0.00001471
Iteration 88/1000 | Loss: 0.00001471
Iteration 89/1000 | Loss: 0.00001471
Iteration 90/1000 | Loss: 0.00001471
Iteration 91/1000 | Loss: 0.00001471
Iteration 92/1000 | Loss: 0.00001470
Iteration 93/1000 | Loss: 0.00001470
Iteration 94/1000 | Loss: 0.00001470
Iteration 95/1000 | Loss: 0.00001470
Iteration 96/1000 | Loss: 0.00001469
Iteration 97/1000 | Loss: 0.00001469
Iteration 98/1000 | Loss: 0.00001469
Iteration 99/1000 | Loss: 0.00001469
Iteration 100/1000 | Loss: 0.00001469
Iteration 101/1000 | Loss: 0.00001469
Iteration 102/1000 | Loss: 0.00001469
Iteration 103/1000 | Loss: 0.00001469
Iteration 104/1000 | Loss: 0.00001469
Iteration 105/1000 | Loss: 0.00001469
Iteration 106/1000 | Loss: 0.00001469
Iteration 107/1000 | Loss: 0.00001468
Iteration 108/1000 | Loss: 0.00001468
Iteration 109/1000 | Loss: 0.00001468
Iteration 110/1000 | Loss: 0.00001468
Iteration 111/1000 | Loss: 0.00001468
Iteration 112/1000 | Loss: 0.00001468
Iteration 113/1000 | Loss: 0.00001468
Iteration 114/1000 | Loss: 0.00001468
Iteration 115/1000 | Loss: 0.00001468
Iteration 116/1000 | Loss: 0.00001468
Iteration 117/1000 | Loss: 0.00001468
Iteration 118/1000 | Loss: 0.00001468
Iteration 119/1000 | Loss: 0.00001468
Iteration 120/1000 | Loss: 0.00001468
Iteration 121/1000 | Loss: 0.00001468
Iteration 122/1000 | Loss: 0.00001468
Iteration 123/1000 | Loss: 0.00001468
Iteration 124/1000 | Loss: 0.00001468
Iteration 125/1000 | Loss: 0.00001468
Iteration 126/1000 | Loss: 0.00001468
Iteration 127/1000 | Loss: 0.00001468
Iteration 128/1000 | Loss: 0.00001468
Iteration 129/1000 | Loss: 0.00001468
Iteration 130/1000 | Loss: 0.00001468
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 130. Stopping optimization.
Last 5 losses: [1.4683869267173577e-05, 1.4683869267173577e-05, 1.4683869267173577e-05, 1.4683869267173577e-05, 1.4683869267173577e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4683869267173577e-05

Optimization complete. Final v2v error: 3.243999719619751 mm

Highest mean error: 4.125901222229004 mm for frame 153

Lowest mean error: 2.8462681770324707 mm for frame 204

Saving results

Total time: 41.56609845161438
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1028
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00872370
Iteration 2/25 | Loss: 0.00128556
Iteration 3/25 | Loss: 0.00083333
Iteration 4/25 | Loss: 0.00076553
Iteration 5/25 | Loss: 0.00074938
Iteration 6/25 | Loss: 0.00074470
Iteration 7/25 | Loss: 0.00074353
Iteration 8/25 | Loss: 0.00074332
Iteration 9/25 | Loss: 0.00074332
Iteration 10/25 | Loss: 0.00074332
Iteration 11/25 | Loss: 0.00074332
Iteration 12/25 | Loss: 0.00074332
Iteration 13/25 | Loss: 0.00074332
Iteration 14/25 | Loss: 0.00074332
Iteration 15/25 | Loss: 0.00074332
Iteration 16/25 | Loss: 0.00074332
Iteration 17/25 | Loss: 0.00074332
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.000743316428270191, 0.000743316428270191, 0.000743316428270191, 0.000743316428270191, 0.000743316428270191]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000743316428270191

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48144853
Iteration 2/25 | Loss: 0.00033571
Iteration 3/25 | Loss: 0.00033571
Iteration 4/25 | Loss: 0.00033570
Iteration 5/25 | Loss: 0.00033570
Iteration 6/25 | Loss: 0.00033570
Iteration 7/25 | Loss: 0.00033570
Iteration 8/25 | Loss: 0.00033570
Iteration 9/25 | Loss: 0.00033570
Iteration 10/25 | Loss: 0.00033570
Iteration 11/25 | Loss: 0.00033570
Iteration 12/25 | Loss: 0.00033570
Iteration 13/25 | Loss: 0.00033570
Iteration 14/25 | Loss: 0.00033570
Iteration 15/25 | Loss: 0.00033570
Iteration 16/25 | Loss: 0.00033570
Iteration 17/25 | Loss: 0.00033570
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.000335702789016068, 0.000335702789016068, 0.000335702789016068, 0.000335702789016068, 0.000335702789016068]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000335702789016068

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033570
Iteration 2/1000 | Loss: 0.00004559
Iteration 3/1000 | Loss: 0.00002951
Iteration 4/1000 | Loss: 0.00002664
Iteration 5/1000 | Loss: 0.00002536
Iteration 6/1000 | Loss: 0.00002452
Iteration 7/1000 | Loss: 0.00002393
Iteration 8/1000 | Loss: 0.00002340
Iteration 9/1000 | Loss: 0.00002304
Iteration 10/1000 | Loss: 0.00002277
Iteration 11/1000 | Loss: 0.00002252
Iteration 12/1000 | Loss: 0.00002241
Iteration 13/1000 | Loss: 0.00002227
Iteration 14/1000 | Loss: 0.00002223
Iteration 15/1000 | Loss: 0.00002219
Iteration 16/1000 | Loss: 0.00002218
Iteration 17/1000 | Loss: 0.00002218
Iteration 18/1000 | Loss: 0.00002217
Iteration 19/1000 | Loss: 0.00002217
Iteration 20/1000 | Loss: 0.00002216
Iteration 21/1000 | Loss: 0.00002216
Iteration 22/1000 | Loss: 0.00002216
Iteration 23/1000 | Loss: 0.00002215
Iteration 24/1000 | Loss: 0.00002215
Iteration 25/1000 | Loss: 0.00002215
Iteration 26/1000 | Loss: 0.00002214
Iteration 27/1000 | Loss: 0.00002214
Iteration 28/1000 | Loss: 0.00002213
Iteration 29/1000 | Loss: 0.00002212
Iteration 30/1000 | Loss: 0.00002211
Iteration 31/1000 | Loss: 0.00002211
Iteration 32/1000 | Loss: 0.00002211
Iteration 33/1000 | Loss: 0.00002211
Iteration 34/1000 | Loss: 0.00002210
Iteration 35/1000 | Loss: 0.00002209
Iteration 36/1000 | Loss: 0.00002208
Iteration 37/1000 | Loss: 0.00002208
Iteration 38/1000 | Loss: 0.00002207
Iteration 39/1000 | Loss: 0.00002207
Iteration 40/1000 | Loss: 0.00002206
Iteration 41/1000 | Loss: 0.00002206
Iteration 42/1000 | Loss: 0.00002205
Iteration 43/1000 | Loss: 0.00002205
Iteration 44/1000 | Loss: 0.00002205
Iteration 45/1000 | Loss: 0.00002204
Iteration 46/1000 | Loss: 0.00002204
Iteration 47/1000 | Loss: 0.00002204
Iteration 48/1000 | Loss: 0.00002204
Iteration 49/1000 | Loss: 0.00002204
Iteration 50/1000 | Loss: 0.00002204
Iteration 51/1000 | Loss: 0.00002204
Iteration 52/1000 | Loss: 0.00002203
Iteration 53/1000 | Loss: 0.00002203
Iteration 54/1000 | Loss: 0.00002203
Iteration 55/1000 | Loss: 0.00002202
Iteration 56/1000 | Loss: 0.00002201
Iteration 57/1000 | Loss: 0.00002200
Iteration 58/1000 | Loss: 0.00002200
Iteration 59/1000 | Loss: 0.00002200
Iteration 60/1000 | Loss: 0.00002200
Iteration 61/1000 | Loss: 0.00002200
Iteration 62/1000 | Loss: 0.00002198
Iteration 63/1000 | Loss: 0.00002198
Iteration 64/1000 | Loss: 0.00002198
Iteration 65/1000 | Loss: 0.00002198
Iteration 66/1000 | Loss: 0.00002198
Iteration 67/1000 | Loss: 0.00002198
Iteration 68/1000 | Loss: 0.00002198
Iteration 69/1000 | Loss: 0.00002198
Iteration 70/1000 | Loss: 0.00002198
Iteration 71/1000 | Loss: 0.00002197
Iteration 72/1000 | Loss: 0.00002197
Iteration 73/1000 | Loss: 0.00002197
Iteration 74/1000 | Loss: 0.00002197
Iteration 75/1000 | Loss: 0.00002197
Iteration 76/1000 | Loss: 0.00002197
Iteration 77/1000 | Loss: 0.00002197
Iteration 78/1000 | Loss: 0.00002197
Iteration 79/1000 | Loss: 0.00002197
Iteration 80/1000 | Loss: 0.00002197
Iteration 81/1000 | Loss: 0.00002197
Iteration 82/1000 | Loss: 0.00002197
Iteration 83/1000 | Loss: 0.00002197
Iteration 84/1000 | Loss: 0.00002197
Iteration 85/1000 | Loss: 0.00002197
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [2.196928471676074e-05, 2.196928471676074e-05, 2.196928471676074e-05, 2.196928471676074e-05, 2.196928471676074e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.196928471676074e-05

Optimization complete. Final v2v error: 3.8310747146606445 mm

Highest mean error: 5.084161281585693 mm for frame 149

Lowest mean error: 2.982414960861206 mm for frame 11

Saving results

Total time: 36.573939085006714
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1059/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1059.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1059
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00528345
Iteration 2/25 | Loss: 0.00112547
Iteration 3/25 | Loss: 0.00078641
Iteration 4/25 | Loss: 0.00070815
Iteration 5/25 | Loss: 0.00068634
Iteration 6/25 | Loss: 0.00066882
Iteration 7/25 | Loss: 0.00065047
Iteration 8/25 | Loss: 0.00065803
Iteration 9/25 | Loss: 0.00066114
Iteration 10/25 | Loss: 0.00064482
Iteration 11/25 | Loss: 0.00063401
Iteration 12/25 | Loss: 0.00063156
Iteration 13/25 | Loss: 0.00063047
Iteration 14/25 | Loss: 0.00063401
Iteration 15/25 | Loss: 0.00063541
Iteration 16/25 | Loss: 0.00063179
Iteration 17/25 | Loss: 0.00063474
Iteration 18/25 | Loss: 0.00062634
Iteration 19/25 | Loss: 0.00062394
Iteration 20/25 | Loss: 0.00062327
Iteration 21/25 | Loss: 0.00062284
Iteration 22/25 | Loss: 0.00062260
Iteration 23/25 | Loss: 0.00062255
Iteration 24/25 | Loss: 0.00062255
Iteration 25/25 | Loss: 0.00062254

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50823379
Iteration 2/25 | Loss: 0.00026862
Iteration 3/25 | Loss: 0.00026861
Iteration 4/25 | Loss: 0.00026861
Iteration 5/25 | Loss: 0.00026861
Iteration 6/25 | Loss: 0.00026861
Iteration 7/25 | Loss: 0.00026861
Iteration 8/25 | Loss: 0.00026861
Iteration 9/25 | Loss: 0.00026861
Iteration 10/25 | Loss: 0.00026861
Iteration 11/25 | Loss: 0.00026861
Iteration 12/25 | Loss: 0.00026861
Iteration 13/25 | Loss: 0.00026861
Iteration 14/25 | Loss: 0.00026861
Iteration 15/25 | Loss: 0.00026861
Iteration 16/25 | Loss: 0.00026861
Iteration 17/25 | Loss: 0.00026861
Iteration 18/25 | Loss: 0.00026861
Iteration 19/25 | Loss: 0.00026861
Iteration 20/25 | Loss: 0.00026861
Iteration 21/25 | Loss: 0.00026861
Iteration 22/25 | Loss: 0.00026861
Iteration 23/25 | Loss: 0.00026861
Iteration 24/25 | Loss: 0.00026861
Iteration 25/25 | Loss: 0.00026861

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026861
Iteration 2/1000 | Loss: 0.00002715
Iteration 3/1000 | Loss: 0.00001791
Iteration 4/1000 | Loss: 0.00001536
Iteration 5/1000 | Loss: 0.00001449
Iteration 6/1000 | Loss: 0.00001381
Iteration 7/1000 | Loss: 0.00001357
Iteration 8/1000 | Loss: 0.00001325
Iteration 9/1000 | Loss: 0.00001318
Iteration 10/1000 | Loss: 0.00001313
Iteration 11/1000 | Loss: 0.00001301
Iteration 12/1000 | Loss: 0.00001298
Iteration 13/1000 | Loss: 0.00001297
Iteration 14/1000 | Loss: 0.00001296
Iteration 15/1000 | Loss: 0.00001295
Iteration 16/1000 | Loss: 0.00001290
Iteration 17/1000 | Loss: 0.00001285
Iteration 18/1000 | Loss: 0.00001284
Iteration 19/1000 | Loss: 0.00001276
Iteration 20/1000 | Loss: 0.00001273
Iteration 21/1000 | Loss: 0.00001273
Iteration 22/1000 | Loss: 0.00001270
Iteration 23/1000 | Loss: 0.00001270
Iteration 24/1000 | Loss: 0.00001270
Iteration 25/1000 | Loss: 0.00001269
Iteration 26/1000 | Loss: 0.00001268
Iteration 27/1000 | Loss: 0.00001268
Iteration 28/1000 | Loss: 0.00001267
Iteration 29/1000 | Loss: 0.00001267
Iteration 30/1000 | Loss: 0.00001266
Iteration 31/1000 | Loss: 0.00001264
Iteration 32/1000 | Loss: 0.00001264
Iteration 33/1000 | Loss: 0.00001263
Iteration 34/1000 | Loss: 0.00001263
Iteration 35/1000 | Loss: 0.00001262
Iteration 36/1000 | Loss: 0.00001262
Iteration 37/1000 | Loss: 0.00001261
Iteration 38/1000 | Loss: 0.00001260
Iteration 39/1000 | Loss: 0.00001260
Iteration 40/1000 | Loss: 0.00001259
Iteration 41/1000 | Loss: 0.00001256
Iteration 42/1000 | Loss: 0.00001256
Iteration 43/1000 | Loss: 0.00001254
Iteration 44/1000 | Loss: 0.00001254
Iteration 45/1000 | Loss: 0.00001254
Iteration 46/1000 | Loss: 0.00001254
Iteration 47/1000 | Loss: 0.00001254
Iteration 48/1000 | Loss: 0.00001254
Iteration 49/1000 | Loss: 0.00001254
Iteration 50/1000 | Loss: 0.00001254
Iteration 51/1000 | Loss: 0.00001253
Iteration 52/1000 | Loss: 0.00001253
Iteration 53/1000 | Loss: 0.00001253
Iteration 54/1000 | Loss: 0.00001252
Iteration 55/1000 | Loss: 0.00001252
Iteration 56/1000 | Loss: 0.00001251
Iteration 57/1000 | Loss: 0.00001250
Iteration 58/1000 | Loss: 0.00001250
Iteration 59/1000 | Loss: 0.00001250
Iteration 60/1000 | Loss: 0.00001249
Iteration 61/1000 | Loss: 0.00001249
Iteration 62/1000 | Loss: 0.00001249
Iteration 63/1000 | Loss: 0.00001249
Iteration 64/1000 | Loss: 0.00001248
Iteration 65/1000 | Loss: 0.00001248
Iteration 66/1000 | Loss: 0.00001248
Iteration 67/1000 | Loss: 0.00001247
Iteration 68/1000 | Loss: 0.00001247
Iteration 69/1000 | Loss: 0.00001247
Iteration 70/1000 | Loss: 0.00001247
Iteration 71/1000 | Loss: 0.00001247
Iteration 72/1000 | Loss: 0.00001247
Iteration 73/1000 | Loss: 0.00001246
Iteration 74/1000 | Loss: 0.00001246
Iteration 75/1000 | Loss: 0.00001246
Iteration 76/1000 | Loss: 0.00001246
Iteration 77/1000 | Loss: 0.00001246
Iteration 78/1000 | Loss: 0.00001245
Iteration 79/1000 | Loss: 0.00001245
Iteration 80/1000 | Loss: 0.00001245
Iteration 81/1000 | Loss: 0.00001245
Iteration 82/1000 | Loss: 0.00001245
Iteration 83/1000 | Loss: 0.00001244
Iteration 84/1000 | Loss: 0.00001244
Iteration 85/1000 | Loss: 0.00001244
Iteration 86/1000 | Loss: 0.00001244
Iteration 87/1000 | Loss: 0.00001244
Iteration 88/1000 | Loss: 0.00001244
Iteration 89/1000 | Loss: 0.00001244
Iteration 90/1000 | Loss: 0.00001244
Iteration 91/1000 | Loss: 0.00001244
Iteration 92/1000 | Loss: 0.00001244
Iteration 93/1000 | Loss: 0.00001243
Iteration 94/1000 | Loss: 0.00001243
Iteration 95/1000 | Loss: 0.00001243
Iteration 96/1000 | Loss: 0.00001243
Iteration 97/1000 | Loss: 0.00001243
Iteration 98/1000 | Loss: 0.00001243
Iteration 99/1000 | Loss: 0.00001243
Iteration 100/1000 | Loss: 0.00001242
Iteration 101/1000 | Loss: 0.00001242
Iteration 102/1000 | Loss: 0.00001242
Iteration 103/1000 | Loss: 0.00001242
Iteration 104/1000 | Loss: 0.00001242
Iteration 105/1000 | Loss: 0.00001242
Iteration 106/1000 | Loss: 0.00001242
Iteration 107/1000 | Loss: 0.00001241
Iteration 108/1000 | Loss: 0.00001241
Iteration 109/1000 | Loss: 0.00001241
Iteration 110/1000 | Loss: 0.00001241
Iteration 111/1000 | Loss: 0.00001240
Iteration 112/1000 | Loss: 0.00001240
Iteration 113/1000 | Loss: 0.00001240
Iteration 114/1000 | Loss: 0.00001240
Iteration 115/1000 | Loss: 0.00001240
Iteration 116/1000 | Loss: 0.00001240
Iteration 117/1000 | Loss: 0.00001240
Iteration 118/1000 | Loss: 0.00001240
Iteration 119/1000 | Loss: 0.00001240
Iteration 120/1000 | Loss: 0.00001240
Iteration 121/1000 | Loss: 0.00001240
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 121. Stopping optimization.
Last 5 losses: [1.2395397789077833e-05, 1.2395397789077833e-05, 1.2395397789077833e-05, 1.2395397789077833e-05, 1.2395397789077833e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2395397789077833e-05

Optimization complete. Final v2v error: 3.007329225540161 mm

Highest mean error: 3.90144419670105 mm for frame 39

Lowest mean error: 2.7140607833862305 mm for frame 123

Saving results

Total time: 66.35743856430054
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1079
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00488924
Iteration 2/25 | Loss: 0.00078474
Iteration 3/25 | Loss: 0.00063492
Iteration 4/25 | Loss: 0.00060332
Iteration 5/25 | Loss: 0.00059290
Iteration 6/25 | Loss: 0.00059067
Iteration 7/25 | Loss: 0.00059025
Iteration 8/25 | Loss: 0.00059025
Iteration 9/25 | Loss: 0.00059025
Iteration 10/25 | Loss: 0.00059025
Iteration 11/25 | Loss: 0.00059025
Iteration 12/25 | Loss: 0.00059025
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000590254261624068, 0.000590254261624068, 0.000590254261624068, 0.000590254261624068, 0.000590254261624068]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000590254261624068

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46091402
Iteration 2/25 | Loss: 0.00022210
Iteration 3/25 | Loss: 0.00022206
Iteration 4/25 | Loss: 0.00022206
Iteration 5/25 | Loss: 0.00022206
Iteration 6/25 | Loss: 0.00022206
Iteration 7/25 | Loss: 0.00022206
Iteration 8/25 | Loss: 0.00022206
Iteration 9/25 | Loss: 0.00022206
Iteration 10/25 | Loss: 0.00022206
Iteration 11/25 | Loss: 0.00022206
Iteration 12/25 | Loss: 0.00022206
Iteration 13/25 | Loss: 0.00022206
Iteration 14/25 | Loss: 0.00022206
Iteration 15/25 | Loss: 0.00022206
Iteration 16/25 | Loss: 0.00022206
Iteration 17/25 | Loss: 0.00022206
Iteration 18/25 | Loss: 0.00022206
Iteration 19/25 | Loss: 0.00022206
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00022205560526344925, 0.00022205560526344925, 0.00022205560526344925, 0.00022205560526344925, 0.00022205560526344925]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00022205560526344925

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00022206
Iteration 2/1000 | Loss: 0.00002285
Iteration 3/1000 | Loss: 0.00001544
Iteration 4/1000 | Loss: 0.00001376
Iteration 5/1000 | Loss: 0.00001310
Iteration 6/1000 | Loss: 0.00001261
Iteration 7/1000 | Loss: 0.00001225
Iteration 8/1000 | Loss: 0.00001220
Iteration 9/1000 | Loss: 0.00001198
Iteration 10/1000 | Loss: 0.00001196
Iteration 11/1000 | Loss: 0.00001196
Iteration 12/1000 | Loss: 0.00001195
Iteration 13/1000 | Loss: 0.00001195
Iteration 14/1000 | Loss: 0.00001195
Iteration 15/1000 | Loss: 0.00001186
Iteration 16/1000 | Loss: 0.00001183
Iteration 17/1000 | Loss: 0.00001183
Iteration 18/1000 | Loss: 0.00001183
Iteration 19/1000 | Loss: 0.00001182
Iteration 20/1000 | Loss: 0.00001182
Iteration 21/1000 | Loss: 0.00001181
Iteration 22/1000 | Loss: 0.00001181
Iteration 23/1000 | Loss: 0.00001179
Iteration 24/1000 | Loss: 0.00001178
Iteration 25/1000 | Loss: 0.00001178
Iteration 26/1000 | Loss: 0.00001176
Iteration 27/1000 | Loss: 0.00001176
Iteration 28/1000 | Loss: 0.00001176
Iteration 29/1000 | Loss: 0.00001176
Iteration 30/1000 | Loss: 0.00001176
Iteration 31/1000 | Loss: 0.00001176
Iteration 32/1000 | Loss: 0.00001176
Iteration 33/1000 | Loss: 0.00001176
Iteration 34/1000 | Loss: 0.00001176
Iteration 35/1000 | Loss: 0.00001176
Iteration 36/1000 | Loss: 0.00001173
Iteration 37/1000 | Loss: 0.00001172
Iteration 38/1000 | Loss: 0.00001172
Iteration 39/1000 | Loss: 0.00001172
Iteration 40/1000 | Loss: 0.00001172
Iteration 41/1000 | Loss: 0.00001171
Iteration 42/1000 | Loss: 0.00001170
Iteration 43/1000 | Loss: 0.00001169
Iteration 44/1000 | Loss: 0.00001169
Iteration 45/1000 | Loss: 0.00001169
Iteration 46/1000 | Loss: 0.00001168
Iteration 47/1000 | Loss: 0.00001168
Iteration 48/1000 | Loss: 0.00001168
Iteration 49/1000 | Loss: 0.00001168
Iteration 50/1000 | Loss: 0.00001168
Iteration 51/1000 | Loss: 0.00001167
Iteration 52/1000 | Loss: 0.00001167
Iteration 53/1000 | Loss: 0.00001167
Iteration 54/1000 | Loss: 0.00001167
Iteration 55/1000 | Loss: 0.00001166
Iteration 56/1000 | Loss: 0.00001166
Iteration 57/1000 | Loss: 0.00001166
Iteration 58/1000 | Loss: 0.00001165
Iteration 59/1000 | Loss: 0.00001165
Iteration 60/1000 | Loss: 0.00001165
Iteration 61/1000 | Loss: 0.00001164
Iteration 62/1000 | Loss: 0.00001164
Iteration 63/1000 | Loss: 0.00001164
Iteration 64/1000 | Loss: 0.00001163
Iteration 65/1000 | Loss: 0.00001162
Iteration 66/1000 | Loss: 0.00001162
Iteration 67/1000 | Loss: 0.00001161
Iteration 68/1000 | Loss: 0.00001161
Iteration 69/1000 | Loss: 0.00001161
Iteration 70/1000 | Loss: 0.00001161
Iteration 71/1000 | Loss: 0.00001160
Iteration 72/1000 | Loss: 0.00001159
Iteration 73/1000 | Loss: 0.00001159
Iteration 74/1000 | Loss: 0.00001158
Iteration 75/1000 | Loss: 0.00001158
Iteration 76/1000 | Loss: 0.00001158
Iteration 77/1000 | Loss: 0.00001158
Iteration 78/1000 | Loss: 0.00001158
Iteration 79/1000 | Loss: 0.00001158
Iteration 80/1000 | Loss: 0.00001158
Iteration 81/1000 | Loss: 0.00001158
Iteration 82/1000 | Loss: 0.00001158
Iteration 83/1000 | Loss: 0.00001157
Iteration 84/1000 | Loss: 0.00001157
Iteration 85/1000 | Loss: 0.00001157
Iteration 86/1000 | Loss: 0.00001157
Iteration 87/1000 | Loss: 0.00001157
Iteration 88/1000 | Loss: 0.00001156
Iteration 89/1000 | Loss: 0.00001156
Iteration 90/1000 | Loss: 0.00001156
Iteration 91/1000 | Loss: 0.00001155
Iteration 92/1000 | Loss: 0.00001155
Iteration 93/1000 | Loss: 0.00001155
Iteration 94/1000 | Loss: 0.00001155
Iteration 95/1000 | Loss: 0.00001155
Iteration 96/1000 | Loss: 0.00001155
Iteration 97/1000 | Loss: 0.00001155
Iteration 98/1000 | Loss: 0.00001154
Iteration 99/1000 | Loss: 0.00001154
Iteration 100/1000 | Loss: 0.00001154
Iteration 101/1000 | Loss: 0.00001154
Iteration 102/1000 | Loss: 0.00001154
Iteration 103/1000 | Loss: 0.00001154
Iteration 104/1000 | Loss: 0.00001154
Iteration 105/1000 | Loss: 0.00001154
Iteration 106/1000 | Loss: 0.00001154
Iteration 107/1000 | Loss: 0.00001154
Iteration 108/1000 | Loss: 0.00001153
Iteration 109/1000 | Loss: 0.00001153
Iteration 110/1000 | Loss: 0.00001153
Iteration 111/1000 | Loss: 0.00001153
Iteration 112/1000 | Loss: 0.00001153
Iteration 113/1000 | Loss: 0.00001153
Iteration 114/1000 | Loss: 0.00001153
Iteration 115/1000 | Loss: 0.00001153
Iteration 116/1000 | Loss: 0.00001153
Iteration 117/1000 | Loss: 0.00001153
Iteration 118/1000 | Loss: 0.00001153
Iteration 119/1000 | Loss: 0.00001153
Iteration 120/1000 | Loss: 0.00001153
Iteration 121/1000 | Loss: 0.00001153
Iteration 122/1000 | Loss: 0.00001152
Iteration 123/1000 | Loss: 0.00001152
Iteration 124/1000 | Loss: 0.00001152
Iteration 125/1000 | Loss: 0.00001152
Iteration 126/1000 | Loss: 0.00001152
Iteration 127/1000 | Loss: 0.00001152
Iteration 128/1000 | Loss: 0.00001152
Iteration 129/1000 | Loss: 0.00001152
Iteration 130/1000 | Loss: 0.00001152
Iteration 131/1000 | Loss: 0.00001152
Iteration 132/1000 | Loss: 0.00001152
Iteration 133/1000 | Loss: 0.00001152
Iteration 134/1000 | Loss: 0.00001152
Iteration 135/1000 | Loss: 0.00001152
Iteration 136/1000 | Loss: 0.00001152
Iteration 137/1000 | Loss: 0.00001152
Iteration 138/1000 | Loss: 0.00001151
Iteration 139/1000 | Loss: 0.00001151
Iteration 140/1000 | Loss: 0.00001151
Iteration 141/1000 | Loss: 0.00001151
Iteration 142/1000 | Loss: 0.00001151
Iteration 143/1000 | Loss: 0.00001151
Iteration 144/1000 | Loss: 0.00001151
Iteration 145/1000 | Loss: 0.00001151
Iteration 146/1000 | Loss: 0.00001151
Iteration 147/1000 | Loss: 0.00001151
Iteration 148/1000 | Loss: 0.00001151
Iteration 149/1000 | Loss: 0.00001150
Iteration 150/1000 | Loss: 0.00001150
Iteration 151/1000 | Loss: 0.00001150
Iteration 152/1000 | Loss: 0.00001150
Iteration 153/1000 | Loss: 0.00001150
Iteration 154/1000 | Loss: 0.00001150
Iteration 155/1000 | Loss: 0.00001150
Iteration 156/1000 | Loss: 0.00001150
Iteration 157/1000 | Loss: 0.00001150
Iteration 158/1000 | Loss: 0.00001149
Iteration 159/1000 | Loss: 0.00001149
Iteration 160/1000 | Loss: 0.00001149
Iteration 161/1000 | Loss: 0.00001149
Iteration 162/1000 | Loss: 0.00001149
Iteration 163/1000 | Loss: 0.00001149
Iteration 164/1000 | Loss: 0.00001149
Iteration 165/1000 | Loss: 0.00001149
Iteration 166/1000 | Loss: 0.00001149
Iteration 167/1000 | Loss: 0.00001149
Iteration 168/1000 | Loss: 0.00001149
Iteration 169/1000 | Loss: 0.00001148
Iteration 170/1000 | Loss: 0.00001148
Iteration 171/1000 | Loss: 0.00001148
Iteration 172/1000 | Loss: 0.00001148
Iteration 173/1000 | Loss: 0.00001147
Iteration 174/1000 | Loss: 0.00001147
Iteration 175/1000 | Loss: 0.00001147
Iteration 176/1000 | Loss: 0.00001147
Iteration 177/1000 | Loss: 0.00001147
Iteration 178/1000 | Loss: 0.00001147
Iteration 179/1000 | Loss: 0.00001147
Iteration 180/1000 | Loss: 0.00001147
Iteration 181/1000 | Loss: 0.00001147
Iteration 182/1000 | Loss: 0.00001146
Iteration 183/1000 | Loss: 0.00001146
Iteration 184/1000 | Loss: 0.00001146
Iteration 185/1000 | Loss: 0.00001146
Iteration 186/1000 | Loss: 0.00001146
Iteration 187/1000 | Loss: 0.00001146
Iteration 188/1000 | Loss: 0.00001146
Iteration 189/1000 | Loss: 0.00001146
Iteration 190/1000 | Loss: 0.00001146
Iteration 191/1000 | Loss: 0.00001146
Iteration 192/1000 | Loss: 0.00001145
Iteration 193/1000 | Loss: 0.00001145
Iteration 194/1000 | Loss: 0.00001145
Iteration 195/1000 | Loss: 0.00001145
Iteration 196/1000 | Loss: 0.00001145
Iteration 197/1000 | Loss: 0.00001145
Iteration 198/1000 | Loss: 0.00001145
Iteration 199/1000 | Loss: 0.00001145
Iteration 200/1000 | Loss: 0.00001145
Iteration 201/1000 | Loss: 0.00001145
Iteration 202/1000 | Loss: 0.00001145
Iteration 203/1000 | Loss: 0.00001145
Iteration 204/1000 | Loss: 0.00001145
Iteration 205/1000 | Loss: 0.00001145
Iteration 206/1000 | Loss: 0.00001145
Iteration 207/1000 | Loss: 0.00001144
Iteration 208/1000 | Loss: 0.00001144
Iteration 209/1000 | Loss: 0.00001144
Iteration 210/1000 | Loss: 0.00001144
Iteration 211/1000 | Loss: 0.00001144
Iteration 212/1000 | Loss: 0.00001144
Iteration 213/1000 | Loss: 0.00001144
Iteration 214/1000 | Loss: 0.00001144
Iteration 215/1000 | Loss: 0.00001144
Iteration 216/1000 | Loss: 0.00001144
Iteration 217/1000 | Loss: 0.00001144
Iteration 218/1000 | Loss: 0.00001144
Iteration 219/1000 | Loss: 0.00001144
Iteration 220/1000 | Loss: 0.00001144
Iteration 221/1000 | Loss: 0.00001144
Iteration 222/1000 | Loss: 0.00001143
Iteration 223/1000 | Loss: 0.00001143
Iteration 224/1000 | Loss: 0.00001143
Iteration 225/1000 | Loss: 0.00001143
Iteration 226/1000 | Loss: 0.00001143
Iteration 227/1000 | Loss: 0.00001143
Iteration 228/1000 | Loss: 0.00001143
Iteration 229/1000 | Loss: 0.00001143
Iteration 230/1000 | Loss: 0.00001143
Iteration 231/1000 | Loss: 0.00001143
Iteration 232/1000 | Loss: 0.00001143
Iteration 233/1000 | Loss: 0.00001143
Iteration 234/1000 | Loss: 0.00001143
Iteration 235/1000 | Loss: 0.00001143
Iteration 236/1000 | Loss: 0.00001143
Iteration 237/1000 | Loss: 0.00001143
Iteration 238/1000 | Loss: 0.00001143
Iteration 239/1000 | Loss: 0.00001143
Iteration 240/1000 | Loss: 0.00001142
Iteration 241/1000 | Loss: 0.00001142
Iteration 242/1000 | Loss: 0.00001142
Iteration 243/1000 | Loss: 0.00001142
Iteration 244/1000 | Loss: 0.00001142
Iteration 245/1000 | Loss: 0.00001142
Iteration 246/1000 | Loss: 0.00001142
Iteration 247/1000 | Loss: 0.00001142
Iteration 248/1000 | Loss: 0.00001142
Iteration 249/1000 | Loss: 0.00001142
Iteration 250/1000 | Loss: 0.00001142
Iteration 251/1000 | Loss: 0.00001142
Iteration 252/1000 | Loss: 0.00001142
Iteration 253/1000 | Loss: 0.00001142
Iteration 254/1000 | Loss: 0.00001142
Iteration 255/1000 | Loss: 0.00001142
Iteration 256/1000 | Loss: 0.00001142
Iteration 257/1000 | Loss: 0.00001142
Iteration 258/1000 | Loss: 0.00001142
Iteration 259/1000 | Loss: 0.00001142
Iteration 260/1000 | Loss: 0.00001142
Iteration 261/1000 | Loss: 0.00001142
Iteration 262/1000 | Loss: 0.00001142
Iteration 263/1000 | Loss: 0.00001142
Iteration 264/1000 | Loss: 0.00001142
Iteration 265/1000 | Loss: 0.00001142
Iteration 266/1000 | Loss: 0.00001142
Iteration 267/1000 | Loss: 0.00001142
Iteration 268/1000 | Loss: 0.00001142
Iteration 269/1000 | Loss: 0.00001142
Iteration 270/1000 | Loss: 0.00001142
Iteration 271/1000 | Loss: 0.00001142
Iteration 272/1000 | Loss: 0.00001142
Iteration 273/1000 | Loss: 0.00001142
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 273. Stopping optimization.
Last 5 losses: [1.1416322195145767e-05, 1.1416322195145767e-05, 1.1416322195145767e-05, 1.1416322195145767e-05, 1.1416322195145767e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1416322195145767e-05

Optimization complete. Final v2v error: 2.891873598098755 mm

Highest mean error: 3.282655954360962 mm for frame 27

Lowest mean error: 2.5660715103149414 mm for frame 16

Saving results

Total time: 39.802231550216675
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00449260
Iteration 2/25 | Loss: 0.00087297
Iteration 3/25 | Loss: 0.00074588
Iteration 4/25 | Loss: 0.00071236
Iteration 5/25 | Loss: 0.00069836
Iteration 6/25 | Loss: 0.00069643
Iteration 7/25 | Loss: 0.00069607
Iteration 8/25 | Loss: 0.00069607
Iteration 9/25 | Loss: 0.00069607
Iteration 10/25 | Loss: 0.00069607
Iteration 11/25 | Loss: 0.00069607
Iteration 12/25 | Loss: 0.00069607
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006960694445297122, 0.0006960694445297122, 0.0006960694445297122, 0.0006960694445297122, 0.0006960694445297122]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006960694445297122

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42583621
Iteration 2/25 | Loss: 0.00026600
Iteration 3/25 | Loss: 0.00026599
Iteration 4/25 | Loss: 0.00026599
Iteration 5/25 | Loss: 0.00026599
Iteration 6/25 | Loss: 0.00026599
Iteration 7/25 | Loss: 0.00026599
Iteration 8/25 | Loss: 0.00026599
Iteration 9/25 | Loss: 0.00026599
Iteration 10/25 | Loss: 0.00026599
Iteration 11/25 | Loss: 0.00026599
Iteration 12/25 | Loss: 0.00026599
Iteration 13/25 | Loss: 0.00026599
Iteration 14/25 | Loss: 0.00026599
Iteration 15/25 | Loss: 0.00026599
Iteration 16/25 | Loss: 0.00026599
Iteration 17/25 | Loss: 0.00026599
Iteration 18/25 | Loss: 0.00026599
Iteration 19/25 | Loss: 0.00026599
Iteration 20/25 | Loss: 0.00026599
Iteration 21/25 | Loss: 0.00026599
Iteration 22/25 | Loss: 0.00026599
Iteration 23/25 | Loss: 0.00026599
Iteration 24/25 | Loss: 0.00026599
Iteration 25/25 | Loss: 0.00026599

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026599
Iteration 2/1000 | Loss: 0.00004539
Iteration 3/1000 | Loss: 0.00003323
Iteration 4/1000 | Loss: 0.00003094
Iteration 5/1000 | Loss: 0.00002897
Iteration 6/1000 | Loss: 0.00002800
Iteration 7/1000 | Loss: 0.00002709
Iteration 8/1000 | Loss: 0.00002649
Iteration 9/1000 | Loss: 0.00002621
Iteration 10/1000 | Loss: 0.00002593
Iteration 11/1000 | Loss: 0.00002588
Iteration 12/1000 | Loss: 0.00002578
Iteration 13/1000 | Loss: 0.00002558
Iteration 14/1000 | Loss: 0.00002558
Iteration 15/1000 | Loss: 0.00002558
Iteration 16/1000 | Loss: 0.00002557
Iteration 17/1000 | Loss: 0.00002557
Iteration 18/1000 | Loss: 0.00002556
Iteration 19/1000 | Loss: 0.00002555
Iteration 20/1000 | Loss: 0.00002554
Iteration 21/1000 | Loss: 0.00002554
Iteration 22/1000 | Loss: 0.00002553
Iteration 23/1000 | Loss: 0.00002553
Iteration 24/1000 | Loss: 0.00002553
Iteration 25/1000 | Loss: 0.00002552
Iteration 26/1000 | Loss: 0.00002552
Iteration 27/1000 | Loss: 0.00002551
Iteration 28/1000 | Loss: 0.00002549
Iteration 29/1000 | Loss: 0.00002549
Iteration 30/1000 | Loss: 0.00002548
Iteration 31/1000 | Loss: 0.00002548
Iteration 32/1000 | Loss: 0.00002546
Iteration 33/1000 | Loss: 0.00002545
Iteration 34/1000 | Loss: 0.00002543
Iteration 35/1000 | Loss: 0.00002542
Iteration 36/1000 | Loss: 0.00002542
Iteration 37/1000 | Loss: 0.00002541
Iteration 38/1000 | Loss: 0.00002538
Iteration 39/1000 | Loss: 0.00002534
Iteration 40/1000 | Loss: 0.00002530
Iteration 41/1000 | Loss: 0.00002530
Iteration 42/1000 | Loss: 0.00002530
Iteration 43/1000 | Loss: 0.00002530
Iteration 44/1000 | Loss: 0.00002530
Iteration 45/1000 | Loss: 0.00002530
Iteration 46/1000 | Loss: 0.00002530
Iteration 47/1000 | Loss: 0.00002530
Iteration 48/1000 | Loss: 0.00002530
Iteration 49/1000 | Loss: 0.00002530
Iteration 50/1000 | Loss: 0.00002529
Iteration 51/1000 | Loss: 0.00002529
Iteration 52/1000 | Loss: 0.00002529
Iteration 53/1000 | Loss: 0.00002529
Iteration 54/1000 | Loss: 0.00002528
Iteration 55/1000 | Loss: 0.00002528
Iteration 56/1000 | Loss: 0.00002528
Iteration 57/1000 | Loss: 0.00002527
Iteration 58/1000 | Loss: 0.00002527
Iteration 59/1000 | Loss: 0.00002527
Iteration 60/1000 | Loss: 0.00002527
Iteration 61/1000 | Loss: 0.00002526
Iteration 62/1000 | Loss: 0.00002526
Iteration 63/1000 | Loss: 0.00002526
Iteration 64/1000 | Loss: 0.00002526
Iteration 65/1000 | Loss: 0.00002525
Iteration 66/1000 | Loss: 0.00002525
Iteration 67/1000 | Loss: 0.00002525
Iteration 68/1000 | Loss: 0.00002525
Iteration 69/1000 | Loss: 0.00002525
Iteration 70/1000 | Loss: 0.00002524
Iteration 71/1000 | Loss: 0.00002524
Iteration 72/1000 | Loss: 0.00002524
Iteration 73/1000 | Loss: 0.00002524
Iteration 74/1000 | Loss: 0.00002524
Iteration 75/1000 | Loss: 0.00002524
Iteration 76/1000 | Loss: 0.00002524
Iteration 77/1000 | Loss: 0.00002524
Iteration 78/1000 | Loss: 0.00002523
Iteration 79/1000 | Loss: 0.00002523
Iteration 80/1000 | Loss: 0.00002523
Iteration 81/1000 | Loss: 0.00002523
Iteration 82/1000 | Loss: 0.00002523
Iteration 83/1000 | Loss: 0.00002523
Iteration 84/1000 | Loss: 0.00002523
Iteration 85/1000 | Loss: 0.00002523
Iteration 86/1000 | Loss: 0.00002523
Iteration 87/1000 | Loss: 0.00002523
Iteration 88/1000 | Loss: 0.00002522
Iteration 89/1000 | Loss: 0.00002522
Iteration 90/1000 | Loss: 0.00002522
Iteration 91/1000 | Loss: 0.00002522
Iteration 92/1000 | Loss: 0.00002522
Iteration 93/1000 | Loss: 0.00002522
Iteration 94/1000 | Loss: 0.00002522
Iteration 95/1000 | Loss: 0.00002522
Iteration 96/1000 | Loss: 0.00002522
Iteration 97/1000 | Loss: 0.00002522
Iteration 98/1000 | Loss: 0.00002522
Iteration 99/1000 | Loss: 0.00002522
Iteration 100/1000 | Loss: 0.00002522
Iteration 101/1000 | Loss: 0.00002522
Iteration 102/1000 | Loss: 0.00002522
Iteration 103/1000 | Loss: 0.00002522
Iteration 104/1000 | Loss: 0.00002522
Iteration 105/1000 | Loss: 0.00002522
Iteration 106/1000 | Loss: 0.00002522
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [2.521940041333437e-05, 2.521940041333437e-05, 2.521940041333437e-05, 2.521940041333437e-05, 2.521940041333437e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.521940041333437e-05

Optimization complete. Final v2v error: 4.182452201843262 mm

Highest mean error: 4.386178016662598 mm for frame 115

Lowest mean error: 3.8980202674865723 mm for frame 64

Saving results

Total time: 34.62888836860657
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00793135
Iteration 2/25 | Loss: 0.00158632
Iteration 3/25 | Loss: 0.00083013
Iteration 4/25 | Loss: 0.00070433
Iteration 5/25 | Loss: 0.00067539
Iteration 6/25 | Loss: 0.00066969
Iteration 7/25 | Loss: 0.00067064
Iteration 8/25 | Loss: 0.00066452
Iteration 9/25 | Loss: 0.00066037
Iteration 10/25 | Loss: 0.00065801
Iteration 11/25 | Loss: 0.00065652
Iteration 12/25 | Loss: 0.00065582
Iteration 13/25 | Loss: 0.00065547
Iteration 14/25 | Loss: 0.00065532
Iteration 15/25 | Loss: 0.00065531
Iteration 16/25 | Loss: 0.00065530
Iteration 17/25 | Loss: 0.00065530
Iteration 18/25 | Loss: 0.00065530
Iteration 19/25 | Loss: 0.00065530
Iteration 20/25 | Loss: 0.00065530
Iteration 21/25 | Loss: 0.00065530
Iteration 22/25 | Loss: 0.00065530
Iteration 23/25 | Loss: 0.00065530
Iteration 24/25 | Loss: 0.00065530
Iteration 25/25 | Loss: 0.00065530

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.98094821
Iteration 2/25 | Loss: 0.00031245
Iteration 3/25 | Loss: 0.00031245
Iteration 4/25 | Loss: 0.00031245
Iteration 5/25 | Loss: 0.00031245
Iteration 6/25 | Loss: 0.00031245
Iteration 7/25 | Loss: 0.00031245
Iteration 8/25 | Loss: 0.00031245
Iteration 9/25 | Loss: 0.00031245
Iteration 10/25 | Loss: 0.00031245
Iteration 11/25 | Loss: 0.00031245
Iteration 12/25 | Loss: 0.00031245
Iteration 13/25 | Loss: 0.00031245
Iteration 14/25 | Loss: 0.00031245
Iteration 15/25 | Loss: 0.00031245
Iteration 16/25 | Loss: 0.00031245
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00031245138961821795, 0.00031245138961821795, 0.00031245138961821795, 0.00031245138961821795, 0.00031245138961821795]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031245138961821795

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031245
Iteration 2/1000 | Loss: 0.00003304
Iteration 3/1000 | Loss: 0.00002399
Iteration 4/1000 | Loss: 0.00002233
Iteration 5/1000 | Loss: 0.00002123
Iteration 6/1000 | Loss: 0.00002065
Iteration 7/1000 | Loss: 0.00002006
Iteration 8/1000 | Loss: 0.00001984
Iteration 9/1000 | Loss: 0.00001970
Iteration 10/1000 | Loss: 0.00001960
Iteration 11/1000 | Loss: 0.00001956
Iteration 12/1000 | Loss: 0.00001954
Iteration 13/1000 | Loss: 0.00001952
Iteration 14/1000 | Loss: 0.00001951
Iteration 15/1000 | Loss: 0.00001950
Iteration 16/1000 | Loss: 0.00001950
Iteration 17/1000 | Loss: 0.00001931
Iteration 18/1000 | Loss: 0.00001928
Iteration 19/1000 | Loss: 0.00001920
Iteration 20/1000 | Loss: 0.00001919
Iteration 21/1000 | Loss: 0.00001918
Iteration 22/1000 | Loss: 0.00001917
Iteration 23/1000 | Loss: 0.00001912
Iteration 24/1000 | Loss: 0.00001911
Iteration 25/1000 | Loss: 0.00001911
Iteration 26/1000 | Loss: 0.00001910
Iteration 27/1000 | Loss: 0.00001907
Iteration 28/1000 | Loss: 0.00001904
Iteration 29/1000 | Loss: 0.00001900
Iteration 30/1000 | Loss: 0.00001898
Iteration 31/1000 | Loss: 0.00001896
Iteration 32/1000 | Loss: 0.00001893
Iteration 33/1000 | Loss: 0.00001892
Iteration 34/1000 | Loss: 0.00001890
Iteration 35/1000 | Loss: 0.00001889
Iteration 36/1000 | Loss: 0.00001888
Iteration 37/1000 | Loss: 0.00001886
Iteration 38/1000 | Loss: 0.00001886
Iteration 39/1000 | Loss: 0.00001884
Iteration 40/1000 | Loss: 0.00001883
Iteration 41/1000 | Loss: 0.00001883
Iteration 42/1000 | Loss: 0.00001882
Iteration 43/1000 | Loss: 0.00001882
Iteration 44/1000 | Loss: 0.00001882
Iteration 45/1000 | Loss: 0.00001882
Iteration 46/1000 | Loss: 0.00001882
Iteration 47/1000 | Loss: 0.00001881
Iteration 48/1000 | Loss: 0.00001881
Iteration 49/1000 | Loss: 0.00001881
Iteration 50/1000 | Loss: 0.00001881
Iteration 51/1000 | Loss: 0.00001880
Iteration 52/1000 | Loss: 0.00001880
Iteration 53/1000 | Loss: 0.00001880
Iteration 54/1000 | Loss: 0.00001880
Iteration 55/1000 | Loss: 0.00001880
Iteration 56/1000 | Loss: 0.00001880
Iteration 57/1000 | Loss: 0.00001880
Iteration 58/1000 | Loss: 0.00001880
Iteration 59/1000 | Loss: 0.00001879
Iteration 60/1000 | Loss: 0.00001879
Iteration 61/1000 | Loss: 0.00001879
Iteration 62/1000 | Loss: 0.00001879
Iteration 63/1000 | Loss: 0.00001879
Iteration 64/1000 | Loss: 0.00001878
Iteration 65/1000 | Loss: 0.00001878
Iteration 66/1000 | Loss: 0.00001878
Iteration 67/1000 | Loss: 0.00001878
Iteration 68/1000 | Loss: 0.00001878
Iteration 69/1000 | Loss: 0.00001877
Iteration 70/1000 | Loss: 0.00001877
Iteration 71/1000 | Loss: 0.00001877
Iteration 72/1000 | Loss: 0.00001877
Iteration 73/1000 | Loss: 0.00001877
Iteration 74/1000 | Loss: 0.00001877
Iteration 75/1000 | Loss: 0.00001877
Iteration 76/1000 | Loss: 0.00001877
Iteration 77/1000 | Loss: 0.00001877
Iteration 78/1000 | Loss: 0.00001877
Iteration 79/1000 | Loss: 0.00001876
Iteration 80/1000 | Loss: 0.00001876
Iteration 81/1000 | Loss: 0.00001876
Iteration 82/1000 | Loss: 0.00001876
Iteration 83/1000 | Loss: 0.00001875
Iteration 84/1000 | Loss: 0.00001875
Iteration 85/1000 | Loss: 0.00001875
Iteration 86/1000 | Loss: 0.00001875
Iteration 87/1000 | Loss: 0.00001875
Iteration 88/1000 | Loss: 0.00001874
Iteration 89/1000 | Loss: 0.00001874
Iteration 90/1000 | Loss: 0.00001874
Iteration 91/1000 | Loss: 0.00001874
Iteration 92/1000 | Loss: 0.00001874
Iteration 93/1000 | Loss: 0.00001874
Iteration 94/1000 | Loss: 0.00001874
Iteration 95/1000 | Loss: 0.00001874
Iteration 96/1000 | Loss: 0.00001874
Iteration 97/1000 | Loss: 0.00001874
Iteration 98/1000 | Loss: 0.00001873
Iteration 99/1000 | Loss: 0.00001873
Iteration 100/1000 | Loss: 0.00001873
Iteration 101/1000 | Loss: 0.00001873
Iteration 102/1000 | Loss: 0.00001873
Iteration 103/1000 | Loss: 0.00001873
Iteration 104/1000 | Loss: 0.00001873
Iteration 105/1000 | Loss: 0.00001872
Iteration 106/1000 | Loss: 0.00001872
Iteration 107/1000 | Loss: 0.00001872
Iteration 108/1000 | Loss: 0.00001872
Iteration 109/1000 | Loss: 0.00001871
Iteration 110/1000 | Loss: 0.00001871
Iteration 111/1000 | Loss: 0.00001871
Iteration 112/1000 | Loss: 0.00001871
Iteration 113/1000 | Loss: 0.00001871
Iteration 114/1000 | Loss: 0.00001871
Iteration 115/1000 | Loss: 0.00001871
Iteration 116/1000 | Loss: 0.00001871
Iteration 117/1000 | Loss: 0.00001871
Iteration 118/1000 | Loss: 0.00001871
Iteration 119/1000 | Loss: 0.00001871
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [1.8711447410169058e-05, 1.8711447410169058e-05, 1.8711447410169058e-05, 1.8711447410169058e-05, 1.8711447410169058e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8711447410169058e-05

Optimization complete. Final v2v error: 3.6342873573303223 mm

Highest mean error: 4.124208450317383 mm for frame 81

Lowest mean error: 3.2382256984710693 mm for frame 178

Saving results

Total time: 53.71853160858154
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1064/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1064.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1064
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00770930
Iteration 2/25 | Loss: 0.00156035
Iteration 3/25 | Loss: 0.00092416
Iteration 4/25 | Loss: 0.00079828
Iteration 5/25 | Loss: 0.00077842
Iteration 6/25 | Loss: 0.00076632
Iteration 7/25 | Loss: 0.00075434
Iteration 8/25 | Loss: 0.00074427
Iteration 9/25 | Loss: 0.00073994
Iteration 10/25 | Loss: 0.00073810
Iteration 11/25 | Loss: 0.00072914
Iteration 12/25 | Loss: 0.00072781
Iteration 13/25 | Loss: 0.00072762
Iteration 14/25 | Loss: 0.00072761
Iteration 15/25 | Loss: 0.00072761
Iteration 16/25 | Loss: 0.00072761
Iteration 17/25 | Loss: 0.00072761
Iteration 18/25 | Loss: 0.00072761
Iteration 19/25 | Loss: 0.00072761
Iteration 20/25 | Loss: 0.00072761
Iteration 21/25 | Loss: 0.00072761
Iteration 22/25 | Loss: 0.00072761
Iteration 23/25 | Loss: 0.00072760
Iteration 24/25 | Loss: 0.00072760
Iteration 25/25 | Loss: 0.00072760

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47364533
Iteration 2/25 | Loss: 0.00029677
Iteration 3/25 | Loss: 0.00029674
Iteration 4/25 | Loss: 0.00029674
Iteration 5/25 | Loss: 0.00029674
Iteration 6/25 | Loss: 0.00029674
Iteration 7/25 | Loss: 0.00029674
Iteration 8/25 | Loss: 0.00029674
Iteration 9/25 | Loss: 0.00029674
Iteration 10/25 | Loss: 0.00029674
Iteration 11/25 | Loss: 0.00029674
Iteration 12/25 | Loss: 0.00029674
Iteration 13/25 | Loss: 0.00029674
Iteration 14/25 | Loss: 0.00029674
Iteration 15/25 | Loss: 0.00029674
Iteration 16/25 | Loss: 0.00029674
Iteration 17/25 | Loss: 0.00029674
Iteration 18/25 | Loss: 0.00029674
Iteration 19/25 | Loss: 0.00029674
Iteration 20/25 | Loss: 0.00029674
Iteration 21/25 | Loss: 0.00029674
Iteration 22/25 | Loss: 0.00029674
Iteration 23/25 | Loss: 0.00029674
Iteration 24/25 | Loss: 0.00029674
Iteration 25/25 | Loss: 0.00029674

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029674
Iteration 2/1000 | Loss: 0.00003575
Iteration 3/1000 | Loss: 0.00002520
Iteration 4/1000 | Loss: 0.00002321
Iteration 5/1000 | Loss: 0.00002205
Iteration 6/1000 | Loss: 0.00002118
Iteration 7/1000 | Loss: 0.00002070
Iteration 8/1000 | Loss: 0.00002017
Iteration 9/1000 | Loss: 0.00001981
Iteration 10/1000 | Loss: 0.00001954
Iteration 11/1000 | Loss: 0.00001949
Iteration 12/1000 | Loss: 0.00001930
Iteration 13/1000 | Loss: 0.00001930
Iteration 14/1000 | Loss: 0.00001929
Iteration 15/1000 | Loss: 0.00001921
Iteration 16/1000 | Loss: 0.00001909
Iteration 17/1000 | Loss: 0.00001906
Iteration 18/1000 | Loss: 0.00001905
Iteration 19/1000 | Loss: 0.00001901
Iteration 20/1000 | Loss: 0.00001901
Iteration 21/1000 | Loss: 0.00001900
Iteration 22/1000 | Loss: 0.00001900
Iteration 23/1000 | Loss: 0.00001899
Iteration 24/1000 | Loss: 0.00001898
Iteration 25/1000 | Loss: 0.00001898
Iteration 26/1000 | Loss: 0.00001897
Iteration 27/1000 | Loss: 0.00001897
Iteration 28/1000 | Loss: 0.00001896
Iteration 29/1000 | Loss: 0.00001896
Iteration 30/1000 | Loss: 0.00001895
Iteration 31/1000 | Loss: 0.00001895
Iteration 32/1000 | Loss: 0.00001894
Iteration 33/1000 | Loss: 0.00001894
Iteration 34/1000 | Loss: 0.00001894
Iteration 35/1000 | Loss: 0.00001893
Iteration 36/1000 | Loss: 0.00001893
Iteration 37/1000 | Loss: 0.00001892
Iteration 38/1000 | Loss: 0.00001892
Iteration 39/1000 | Loss: 0.00001892
Iteration 40/1000 | Loss: 0.00001891
Iteration 41/1000 | Loss: 0.00001891
Iteration 42/1000 | Loss: 0.00001891
Iteration 43/1000 | Loss: 0.00001890
Iteration 44/1000 | Loss: 0.00001890
Iteration 45/1000 | Loss: 0.00001890
Iteration 46/1000 | Loss: 0.00001889
Iteration 47/1000 | Loss: 0.00001889
Iteration 48/1000 | Loss: 0.00001889
Iteration 49/1000 | Loss: 0.00001889
Iteration 50/1000 | Loss: 0.00001889
Iteration 51/1000 | Loss: 0.00001889
Iteration 52/1000 | Loss: 0.00001888
Iteration 53/1000 | Loss: 0.00001888
Iteration 54/1000 | Loss: 0.00001888
Iteration 55/1000 | Loss: 0.00001888
Iteration 56/1000 | Loss: 0.00001888
Iteration 57/1000 | Loss: 0.00001888
Iteration 58/1000 | Loss: 0.00001888
Iteration 59/1000 | Loss: 0.00001888
Iteration 60/1000 | Loss: 0.00001888
Iteration 61/1000 | Loss: 0.00001888
Iteration 62/1000 | Loss: 0.00001888
Iteration 63/1000 | Loss: 0.00001887
Iteration 64/1000 | Loss: 0.00001887
Iteration 65/1000 | Loss: 0.00001887
Iteration 66/1000 | Loss: 0.00001887
Iteration 67/1000 | Loss: 0.00001887
Iteration 68/1000 | Loss: 0.00001887
Iteration 69/1000 | Loss: 0.00001887
Iteration 70/1000 | Loss: 0.00001887
Iteration 71/1000 | Loss: 0.00001887
Iteration 72/1000 | Loss: 0.00001887
Iteration 73/1000 | Loss: 0.00001887
Iteration 74/1000 | Loss: 0.00001887
Iteration 75/1000 | Loss: 0.00001887
Iteration 76/1000 | Loss: 0.00001887
Iteration 77/1000 | Loss: 0.00001887
Iteration 78/1000 | Loss: 0.00001887
Iteration 79/1000 | Loss: 0.00001887
Iteration 80/1000 | Loss: 0.00001887
Iteration 81/1000 | Loss: 0.00001887
Iteration 82/1000 | Loss: 0.00001887
Iteration 83/1000 | Loss: 0.00001887
Iteration 84/1000 | Loss: 0.00001887
Iteration 85/1000 | Loss: 0.00001887
Iteration 86/1000 | Loss: 0.00001887
Iteration 87/1000 | Loss: 0.00001887
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 87. Stopping optimization.
Last 5 losses: [1.8872797227231786e-05, 1.8872797227231786e-05, 1.8872797227231786e-05, 1.8872797227231786e-05, 1.8872797227231786e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8872797227231786e-05

Optimization complete. Final v2v error: 3.717268466949463 mm

Highest mean error: 4.3912577629089355 mm for frame 104

Lowest mean error: 3.3110475540161133 mm for frame 170

Saving results

Total time: 53.501869201660156
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1027/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1027.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1027
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01057862
Iteration 2/25 | Loss: 0.00176623
Iteration 3/25 | Loss: 0.00116047
Iteration 4/25 | Loss: 0.00112269
Iteration 5/25 | Loss: 0.00088606
Iteration 6/25 | Loss: 0.00088434
Iteration 7/25 | Loss: 0.00082017
Iteration 8/25 | Loss: 0.00078515
Iteration 9/25 | Loss: 0.00075163
Iteration 10/25 | Loss: 0.00070896
Iteration 11/25 | Loss: 0.00070601
Iteration 12/25 | Loss: 0.00069108
Iteration 13/25 | Loss: 0.00069635
Iteration 14/25 | Loss: 0.00068899
Iteration 15/25 | Loss: 0.00068641
Iteration 16/25 | Loss: 0.00066927
Iteration 17/25 | Loss: 0.00066135
Iteration 18/25 | Loss: 0.00065794
Iteration 19/25 | Loss: 0.00065705
Iteration 20/25 | Loss: 0.00065659
Iteration 21/25 | Loss: 0.00065637
Iteration 22/25 | Loss: 0.00065632
Iteration 23/25 | Loss: 0.00065632
Iteration 24/25 | Loss: 0.00065632
Iteration 25/25 | Loss: 0.00065632

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56823325
Iteration 2/25 | Loss: 0.00042485
Iteration 3/25 | Loss: 0.00042485
Iteration 4/25 | Loss: 0.00042485
Iteration 5/25 | Loss: 0.00042485
Iteration 6/25 | Loss: 0.00042485
Iteration 7/25 | Loss: 0.00042485
Iteration 8/25 | Loss: 0.00042485
Iteration 9/25 | Loss: 0.00042485
Iteration 10/25 | Loss: 0.00042485
Iteration 11/25 | Loss: 0.00042485
Iteration 12/25 | Loss: 0.00042485
Iteration 13/25 | Loss: 0.00042485
Iteration 14/25 | Loss: 0.00042485
Iteration 15/25 | Loss: 0.00042485
Iteration 16/25 | Loss: 0.00042485
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0004248482873663306, 0.0004248482873663306, 0.0004248482873663306, 0.0004248482873663306, 0.0004248482873663306]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004248482873663306

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042485
Iteration 2/1000 | Loss: 0.00004777
Iteration 3/1000 | Loss: 0.00003149
Iteration 4/1000 | Loss: 0.00002722
Iteration 5/1000 | Loss: 0.00076301
Iteration 6/1000 | Loss: 0.00023537
Iteration 7/1000 | Loss: 0.00030653
Iteration 8/1000 | Loss: 0.00016087
Iteration 9/1000 | Loss: 0.00002569
Iteration 10/1000 | Loss: 0.00002044
Iteration 11/1000 | Loss: 0.00031924
Iteration 12/1000 | Loss: 0.00027534
Iteration 13/1000 | Loss: 0.00033601
Iteration 14/1000 | Loss: 0.00034188
Iteration 15/1000 | Loss: 0.00031492
Iteration 16/1000 | Loss: 0.00048964
Iteration 17/1000 | Loss: 0.00026666
Iteration 18/1000 | Loss: 0.00002139
Iteration 19/1000 | Loss: 0.00001642
Iteration 20/1000 | Loss: 0.00001461
Iteration 21/1000 | Loss: 0.00001381
Iteration 22/1000 | Loss: 0.00001294
Iteration 23/1000 | Loss: 0.00001257
Iteration 24/1000 | Loss: 0.00001236
Iteration 25/1000 | Loss: 0.00001232
Iteration 26/1000 | Loss: 0.00001232
Iteration 27/1000 | Loss: 0.00001215
Iteration 28/1000 | Loss: 0.00001199
Iteration 29/1000 | Loss: 0.00001194
Iteration 30/1000 | Loss: 0.00001186
Iteration 31/1000 | Loss: 0.00001174
Iteration 32/1000 | Loss: 0.00001172
Iteration 33/1000 | Loss: 0.00001171
Iteration 34/1000 | Loss: 0.00001171
Iteration 35/1000 | Loss: 0.00001170
Iteration 36/1000 | Loss: 0.00001170
Iteration 37/1000 | Loss: 0.00001169
Iteration 38/1000 | Loss: 0.00001169
Iteration 39/1000 | Loss: 0.00001169
Iteration 40/1000 | Loss: 0.00001168
Iteration 41/1000 | Loss: 0.00001168
Iteration 42/1000 | Loss: 0.00001167
Iteration 43/1000 | Loss: 0.00001167
Iteration 44/1000 | Loss: 0.00001166
Iteration 45/1000 | Loss: 0.00001166
Iteration 46/1000 | Loss: 0.00001166
Iteration 47/1000 | Loss: 0.00001166
Iteration 48/1000 | Loss: 0.00001166
Iteration 49/1000 | Loss: 0.00001165
Iteration 50/1000 | Loss: 0.00001165
Iteration 51/1000 | Loss: 0.00001165
Iteration 52/1000 | Loss: 0.00001164
Iteration 53/1000 | Loss: 0.00001164
Iteration 54/1000 | Loss: 0.00001164
Iteration 55/1000 | Loss: 0.00001164
Iteration 56/1000 | Loss: 0.00001163
Iteration 57/1000 | Loss: 0.00001163
Iteration 58/1000 | Loss: 0.00001162
Iteration 59/1000 | Loss: 0.00001162
Iteration 60/1000 | Loss: 0.00001162
Iteration 61/1000 | Loss: 0.00001162
Iteration 62/1000 | Loss: 0.00001162
Iteration 63/1000 | Loss: 0.00001162
Iteration 64/1000 | Loss: 0.00001162
Iteration 65/1000 | Loss: 0.00001162
Iteration 66/1000 | Loss: 0.00001162
Iteration 67/1000 | Loss: 0.00001162
Iteration 68/1000 | Loss: 0.00001161
Iteration 69/1000 | Loss: 0.00001161
Iteration 70/1000 | Loss: 0.00001160
Iteration 71/1000 | Loss: 0.00001160
Iteration 72/1000 | Loss: 0.00001160
Iteration 73/1000 | Loss: 0.00001160
Iteration 74/1000 | Loss: 0.00001160
Iteration 75/1000 | Loss: 0.00001159
Iteration 76/1000 | Loss: 0.00001159
Iteration 77/1000 | Loss: 0.00001159
Iteration 78/1000 | Loss: 0.00001159
Iteration 79/1000 | Loss: 0.00001159
Iteration 80/1000 | Loss: 0.00001159
Iteration 81/1000 | Loss: 0.00001159
Iteration 82/1000 | Loss: 0.00001159
Iteration 83/1000 | Loss: 0.00001159
Iteration 84/1000 | Loss: 0.00001159
Iteration 85/1000 | Loss: 0.00001159
Iteration 86/1000 | Loss: 0.00001159
Iteration 87/1000 | Loss: 0.00001159
Iteration 88/1000 | Loss: 0.00001159
Iteration 89/1000 | Loss: 0.00001159
Iteration 90/1000 | Loss: 0.00001158
Iteration 91/1000 | Loss: 0.00001158
Iteration 92/1000 | Loss: 0.00001158
Iteration 93/1000 | Loss: 0.00001158
Iteration 94/1000 | Loss: 0.00001158
Iteration 95/1000 | Loss: 0.00001158
Iteration 96/1000 | Loss: 0.00001158
Iteration 97/1000 | Loss: 0.00001158
Iteration 98/1000 | Loss: 0.00001158
Iteration 99/1000 | Loss: 0.00001158
Iteration 100/1000 | Loss: 0.00001158
Iteration 101/1000 | Loss: 0.00001158
Iteration 102/1000 | Loss: 0.00001158
Iteration 103/1000 | Loss: 0.00001158
Iteration 104/1000 | Loss: 0.00001158
Iteration 105/1000 | Loss: 0.00001158
Iteration 106/1000 | Loss: 0.00001158
Iteration 107/1000 | Loss: 0.00001158
Iteration 108/1000 | Loss: 0.00001158
Iteration 109/1000 | Loss: 0.00001158
Iteration 110/1000 | Loss: 0.00001158
Iteration 111/1000 | Loss: 0.00001158
Iteration 112/1000 | Loss: 0.00001158
Iteration 113/1000 | Loss: 0.00001158
Iteration 114/1000 | Loss: 0.00001158
Iteration 115/1000 | Loss: 0.00001158
Iteration 116/1000 | Loss: 0.00001158
Iteration 117/1000 | Loss: 0.00001158
Iteration 118/1000 | Loss: 0.00001158
Iteration 119/1000 | Loss: 0.00001158
Iteration 120/1000 | Loss: 0.00001158
Iteration 121/1000 | Loss: 0.00001158
Iteration 122/1000 | Loss: 0.00001158
Iteration 123/1000 | Loss: 0.00001158
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.1583723789954092e-05, 1.1583723789954092e-05, 1.1583723789954092e-05, 1.1583723789954092e-05, 1.1583723789954092e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1583723789954092e-05

Optimization complete. Final v2v error: 2.917907953262329 mm

Highest mean error: 3.8641154766082764 mm for frame 134

Lowest mean error: 2.6108033657073975 mm for frame 96

Saving results

Total time: 87.13621473312378
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1070
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00675430
Iteration 2/25 | Loss: 0.00090894
Iteration 3/25 | Loss: 0.00076667
Iteration 4/25 | Loss: 0.00072100
Iteration 5/25 | Loss: 0.00071323
Iteration 6/25 | Loss: 0.00071163
Iteration 7/25 | Loss: 0.00071133
Iteration 8/25 | Loss: 0.00071133
Iteration 9/25 | Loss: 0.00071133
Iteration 10/25 | Loss: 0.00071133
Iteration 11/25 | Loss: 0.00071133
Iteration 12/25 | Loss: 0.00071133
Iteration 13/25 | Loss: 0.00071133
Iteration 14/25 | Loss: 0.00071133
Iteration 15/25 | Loss: 0.00071133
Iteration 16/25 | Loss: 0.00071133
Iteration 17/25 | Loss: 0.00071133
Iteration 18/25 | Loss: 0.00071133
Iteration 19/25 | Loss: 0.00071133
Iteration 20/25 | Loss: 0.00071133
Iteration 21/25 | Loss: 0.00071133
Iteration 22/25 | Loss: 0.00071133
Iteration 23/25 | Loss: 0.00071133
Iteration 24/25 | Loss: 0.00071133
Iteration 25/25 | Loss: 0.00071133

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45138729
Iteration 2/25 | Loss: 0.00036111
Iteration 3/25 | Loss: 0.00036110
Iteration 4/25 | Loss: 0.00036110
Iteration 5/25 | Loss: 0.00036110
Iteration 6/25 | Loss: 0.00036110
Iteration 7/25 | Loss: 0.00036110
Iteration 8/25 | Loss: 0.00036110
Iteration 9/25 | Loss: 0.00036110
Iteration 10/25 | Loss: 0.00036110
Iteration 11/25 | Loss: 0.00036109
Iteration 12/25 | Loss: 0.00036109
Iteration 13/25 | Loss: 0.00036109
Iteration 14/25 | Loss: 0.00036109
Iteration 15/25 | Loss: 0.00036109
Iteration 16/25 | Loss: 0.00036109
Iteration 17/25 | Loss: 0.00036109
Iteration 18/25 | Loss: 0.00036109
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003610947751440108, 0.0003610947751440108, 0.0003610947751440108, 0.0003610947751440108, 0.0003610947751440108]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003610947751440108

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00036109
Iteration 2/1000 | Loss: 0.00005312
Iteration 3/1000 | Loss: 0.00003652
Iteration 4/1000 | Loss: 0.00003363
Iteration 5/1000 | Loss: 0.00003210
Iteration 6/1000 | Loss: 0.00003119
Iteration 7/1000 | Loss: 0.00003069
Iteration 8/1000 | Loss: 0.00002993
Iteration 9/1000 | Loss: 0.00002951
Iteration 10/1000 | Loss: 0.00002918
Iteration 11/1000 | Loss: 0.00002896
Iteration 12/1000 | Loss: 0.00002873
Iteration 13/1000 | Loss: 0.00002865
Iteration 14/1000 | Loss: 0.00002861
Iteration 15/1000 | Loss: 0.00002854
Iteration 16/1000 | Loss: 0.00002852
Iteration 17/1000 | Loss: 0.00002849
Iteration 18/1000 | Loss: 0.00002846
Iteration 19/1000 | Loss: 0.00002845
Iteration 20/1000 | Loss: 0.00002845
Iteration 21/1000 | Loss: 0.00002844
Iteration 22/1000 | Loss: 0.00002844
Iteration 23/1000 | Loss: 0.00002844
Iteration 24/1000 | Loss: 0.00002844
Iteration 25/1000 | Loss: 0.00002844
Iteration 26/1000 | Loss: 0.00002843
Iteration 27/1000 | Loss: 0.00002843
Iteration 28/1000 | Loss: 0.00002843
Iteration 29/1000 | Loss: 0.00002842
Iteration 30/1000 | Loss: 0.00002842
Iteration 31/1000 | Loss: 0.00002842
Iteration 32/1000 | Loss: 0.00002841
Iteration 33/1000 | Loss: 0.00002841
Iteration 34/1000 | Loss: 0.00002841
Iteration 35/1000 | Loss: 0.00002841
Iteration 36/1000 | Loss: 0.00002840
Iteration 37/1000 | Loss: 0.00002840
Iteration 38/1000 | Loss: 0.00002840
Iteration 39/1000 | Loss: 0.00002840
Iteration 40/1000 | Loss: 0.00002840
Iteration 41/1000 | Loss: 0.00002839
Iteration 42/1000 | Loss: 0.00002838
Iteration 43/1000 | Loss: 0.00002838
Iteration 44/1000 | Loss: 0.00002838
Iteration 45/1000 | Loss: 0.00002838
Iteration 46/1000 | Loss: 0.00002838
Iteration 47/1000 | Loss: 0.00002838
Iteration 48/1000 | Loss: 0.00002838
Iteration 49/1000 | Loss: 0.00002838
Iteration 50/1000 | Loss: 0.00002837
Iteration 51/1000 | Loss: 0.00002837
Iteration 52/1000 | Loss: 0.00002837
Iteration 53/1000 | Loss: 0.00002836
Iteration 54/1000 | Loss: 0.00002836
Iteration 55/1000 | Loss: 0.00002836
Iteration 56/1000 | Loss: 0.00002836
Iteration 57/1000 | Loss: 0.00002836
Iteration 58/1000 | Loss: 0.00002836
Iteration 59/1000 | Loss: 0.00002836
Iteration 60/1000 | Loss: 0.00002836
Iteration 61/1000 | Loss: 0.00002836
Iteration 62/1000 | Loss: 0.00002836
Iteration 63/1000 | Loss: 0.00002836
Iteration 64/1000 | Loss: 0.00002835
Iteration 65/1000 | Loss: 0.00002835
Iteration 66/1000 | Loss: 0.00002835
Iteration 67/1000 | Loss: 0.00002835
Iteration 68/1000 | Loss: 0.00002835
Iteration 69/1000 | Loss: 0.00002835
Iteration 70/1000 | Loss: 0.00002835
Iteration 71/1000 | Loss: 0.00002835
Iteration 72/1000 | Loss: 0.00002835
Iteration 73/1000 | Loss: 0.00002835
Iteration 74/1000 | Loss: 0.00002835
Iteration 75/1000 | Loss: 0.00002835
Iteration 76/1000 | Loss: 0.00002835
Iteration 77/1000 | Loss: 0.00002835
Iteration 78/1000 | Loss: 0.00002835
Iteration 79/1000 | Loss: 0.00002835
Iteration 80/1000 | Loss: 0.00002835
Iteration 81/1000 | Loss: 0.00002835
Iteration 82/1000 | Loss: 0.00002835
Iteration 83/1000 | Loss: 0.00002835
Iteration 84/1000 | Loss: 0.00002835
Iteration 85/1000 | Loss: 0.00002835
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [2.8346525141387247e-05, 2.8346525141387247e-05, 2.8346525141387247e-05, 2.8346525141387247e-05, 2.8346525141387247e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8346525141387247e-05

Optimization complete. Final v2v error: 4.360284328460693 mm

Highest mean error: 4.722845077514648 mm for frame 27

Lowest mean error: 3.862821340560913 mm for frame 205

Saving results

Total time: 38.60633945465088
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00916754
Iteration 2/25 | Loss: 0.00127471
Iteration 3/25 | Loss: 0.00093494
Iteration 4/25 | Loss: 0.00084486
Iteration 5/25 | Loss: 0.00081151
Iteration 6/25 | Loss: 0.00081282
Iteration 7/25 | Loss: 0.00082200
Iteration 8/25 | Loss: 0.00081566
Iteration 9/25 | Loss: 0.00079705
Iteration 10/25 | Loss: 0.00078739
Iteration 11/25 | Loss: 0.00077669
Iteration 12/25 | Loss: 0.00076941
Iteration 13/25 | Loss: 0.00076439
Iteration 14/25 | Loss: 0.00075924
Iteration 15/25 | Loss: 0.00075594
Iteration 16/25 | Loss: 0.00075490
Iteration 17/25 | Loss: 0.00075518
Iteration 18/25 | Loss: 0.00075017
Iteration 19/25 | Loss: 0.00074885
Iteration 20/25 | Loss: 0.00074867
Iteration 21/25 | Loss: 0.00074866
Iteration 22/25 | Loss: 0.00074866
Iteration 23/25 | Loss: 0.00074865
Iteration 24/25 | Loss: 0.00074865
Iteration 25/25 | Loss: 0.00074865

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.33196735
Iteration 2/25 | Loss: 0.00067266
Iteration 3/25 | Loss: 0.00067266
Iteration 4/25 | Loss: 0.00067266
Iteration 5/25 | Loss: 0.00067266
Iteration 6/25 | Loss: 0.00067266
Iteration 7/25 | Loss: 0.00067266
Iteration 8/25 | Loss: 0.00067266
Iteration 9/25 | Loss: 0.00067266
Iteration 10/25 | Loss: 0.00067266
Iteration 11/25 | Loss: 0.00067266
Iteration 12/25 | Loss: 0.00067266
Iteration 13/25 | Loss: 0.00067266
Iteration 14/25 | Loss: 0.00067266
Iteration 15/25 | Loss: 0.00067266
Iteration 16/25 | Loss: 0.00067266
Iteration 17/25 | Loss: 0.00067266
Iteration 18/25 | Loss: 0.00067266
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006726594874635339, 0.0006726594874635339, 0.0006726594874635339, 0.0006726594874635339, 0.0006726594874635339]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006726594874635339

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00067266
Iteration 2/1000 | Loss: 0.00063424
Iteration 3/1000 | Loss: 0.00027143
Iteration 4/1000 | Loss: 0.00007137
Iteration 5/1000 | Loss: 0.00004901
Iteration 6/1000 | Loss: 0.00004189
Iteration 7/1000 | Loss: 0.00003910
Iteration 8/1000 | Loss: 0.00032295
Iteration 9/1000 | Loss: 0.00006581
Iteration 10/1000 | Loss: 0.00005390
Iteration 11/1000 | Loss: 0.00004886
Iteration 12/1000 | Loss: 0.00004685
Iteration 13/1000 | Loss: 0.00024015
Iteration 14/1000 | Loss: 0.00016098
Iteration 15/1000 | Loss: 0.00005353
Iteration 16/1000 | Loss: 0.00028372
Iteration 17/1000 | Loss: 0.00005690
Iteration 18/1000 | Loss: 0.00008427
Iteration 19/1000 | Loss: 0.00005028
Iteration 20/1000 | Loss: 0.00004173
Iteration 21/1000 | Loss: 0.00003892
Iteration 22/1000 | Loss: 0.00003677
Iteration 23/1000 | Loss: 0.00003519
Iteration 24/1000 | Loss: 0.00003437
Iteration 25/1000 | Loss: 0.00003393
Iteration 26/1000 | Loss: 0.00003359
Iteration 27/1000 | Loss: 0.00003322
Iteration 28/1000 | Loss: 0.00003285
Iteration 29/1000 | Loss: 0.00003221
Iteration 30/1000 | Loss: 0.00023037
Iteration 31/1000 | Loss: 0.00021143
Iteration 32/1000 | Loss: 0.00004857
Iteration 33/1000 | Loss: 0.00004058
Iteration 34/1000 | Loss: 0.00008731
Iteration 35/1000 | Loss: 0.00004331
Iteration 36/1000 | Loss: 0.00006442
Iteration 37/1000 | Loss: 0.00007048
Iteration 38/1000 | Loss: 0.00003436
Iteration 39/1000 | Loss: 0.00003209
Iteration 40/1000 | Loss: 0.00003091
Iteration 41/1000 | Loss: 0.00003026
Iteration 42/1000 | Loss: 0.00002967
Iteration 43/1000 | Loss: 0.00026025
Iteration 44/1000 | Loss: 0.00007331
Iteration 45/1000 | Loss: 0.00004373
Iteration 46/1000 | Loss: 0.00003784
Iteration 47/1000 | Loss: 0.00003526
Iteration 48/1000 | Loss: 0.00003328
Iteration 49/1000 | Loss: 0.00005063
Iteration 50/1000 | Loss: 0.00003611
Iteration 51/1000 | Loss: 0.00005480
Iteration 52/1000 | Loss: 0.00003113
Iteration 53/1000 | Loss: 0.00003051
Iteration 54/1000 | Loss: 0.00002904
Iteration 55/1000 | Loss: 0.00002828
Iteration 56/1000 | Loss: 0.00002782
Iteration 57/1000 | Loss: 0.00002751
Iteration 58/1000 | Loss: 0.00002723
Iteration 59/1000 | Loss: 0.00002695
Iteration 60/1000 | Loss: 0.00002692
Iteration 61/1000 | Loss: 0.00002668
Iteration 62/1000 | Loss: 0.00002643
Iteration 63/1000 | Loss: 0.00002627
Iteration 64/1000 | Loss: 0.00002627
Iteration 65/1000 | Loss: 0.00002623
Iteration 66/1000 | Loss: 0.00002623
Iteration 67/1000 | Loss: 0.00002620
Iteration 68/1000 | Loss: 0.00002615
Iteration 69/1000 | Loss: 0.00002614
Iteration 70/1000 | Loss: 0.00002612
Iteration 71/1000 | Loss: 0.00002611
Iteration 72/1000 | Loss: 0.00002610
Iteration 73/1000 | Loss: 0.00002607
Iteration 74/1000 | Loss: 0.00002606
Iteration 75/1000 | Loss: 0.00002606
Iteration 76/1000 | Loss: 0.00002605
Iteration 77/1000 | Loss: 0.00002605
Iteration 78/1000 | Loss: 0.00002604
Iteration 79/1000 | Loss: 0.00002604
Iteration 80/1000 | Loss: 0.00002604
Iteration 81/1000 | Loss: 0.00002603
Iteration 82/1000 | Loss: 0.00002603
Iteration 83/1000 | Loss: 0.00002603
Iteration 84/1000 | Loss: 0.00002602
Iteration 85/1000 | Loss: 0.00002602
Iteration 86/1000 | Loss: 0.00002602
Iteration 87/1000 | Loss: 0.00002601
Iteration 88/1000 | Loss: 0.00002601
Iteration 89/1000 | Loss: 0.00002601
Iteration 90/1000 | Loss: 0.00002600
Iteration 91/1000 | Loss: 0.00002600
Iteration 92/1000 | Loss: 0.00002600
Iteration 93/1000 | Loss: 0.00002600
Iteration 94/1000 | Loss: 0.00002599
Iteration 95/1000 | Loss: 0.00002599
Iteration 96/1000 | Loss: 0.00002599
Iteration 97/1000 | Loss: 0.00002599
Iteration 98/1000 | Loss: 0.00002599
Iteration 99/1000 | Loss: 0.00002598
Iteration 100/1000 | Loss: 0.00002598
Iteration 101/1000 | Loss: 0.00002598
Iteration 102/1000 | Loss: 0.00002598
Iteration 103/1000 | Loss: 0.00002598
Iteration 104/1000 | Loss: 0.00002598
Iteration 105/1000 | Loss: 0.00002598
Iteration 106/1000 | Loss: 0.00002597
Iteration 107/1000 | Loss: 0.00002597
Iteration 108/1000 | Loss: 0.00002597
Iteration 109/1000 | Loss: 0.00002597
Iteration 110/1000 | Loss: 0.00002597
Iteration 111/1000 | Loss: 0.00002596
Iteration 112/1000 | Loss: 0.00002596
Iteration 113/1000 | Loss: 0.00002596
Iteration 114/1000 | Loss: 0.00002595
Iteration 115/1000 | Loss: 0.00002595
Iteration 116/1000 | Loss: 0.00002595
Iteration 117/1000 | Loss: 0.00002595
Iteration 118/1000 | Loss: 0.00002594
Iteration 119/1000 | Loss: 0.00002594
Iteration 120/1000 | Loss: 0.00002594
Iteration 121/1000 | Loss: 0.00002594
Iteration 122/1000 | Loss: 0.00002594
Iteration 123/1000 | Loss: 0.00002594
Iteration 124/1000 | Loss: 0.00002594
Iteration 125/1000 | Loss: 0.00002594
Iteration 126/1000 | Loss: 0.00002594
Iteration 127/1000 | Loss: 0.00002594
Iteration 128/1000 | Loss: 0.00002594
Iteration 129/1000 | Loss: 0.00002594
Iteration 130/1000 | Loss: 0.00002594
Iteration 131/1000 | Loss: 0.00002594
Iteration 132/1000 | Loss: 0.00002594
Iteration 133/1000 | Loss: 0.00002594
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [2.593660246930085e-05, 2.593660246930085e-05, 2.593660246930085e-05, 2.593660246930085e-05, 2.593660246930085e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.593660246930085e-05

Optimization complete. Final v2v error: 4.199246406555176 mm

Highest mean error: 6.4460225105285645 mm for frame 98

Lowest mean error: 3.476691246032715 mm for frame 133

Saving results

Total time: 138.01574540138245
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_corey_posed_026/1048/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1048.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_corey_posed_026/1048
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01095673
Iteration 2/25 | Loss: 0.01095673
Iteration 3/25 | Loss: 0.01095673
Iteration 4/25 | Loss: 0.01095673
Iteration 5/25 | Loss: 0.01095673
Iteration 6/25 | Loss: 0.01095673
Iteration 7/25 | Loss: 0.01095673
Iteration 8/25 | Loss: 0.01095673
Iteration 9/25 | Loss: 0.01095673
Iteration 10/25 | Loss: 0.01095673
Iteration 11/25 | Loss: 0.01095672
Iteration 12/25 | Loss: 0.01095672
Iteration 13/25 | Loss: 0.01095672
Iteration 14/25 | Loss: 0.01095672
Iteration 15/25 | Loss: 0.01095672
Iteration 16/25 | Loss: 0.01095672
Iteration 17/25 | Loss: 0.01095672
Iteration 18/25 | Loss: 0.01095672
Iteration 19/25 | Loss: 0.01095672
Iteration 20/25 | Loss: 0.01095672
Iteration 21/25 | Loss: 0.01095672
Iteration 22/25 | Loss: 0.01095672
Iteration 23/25 | Loss: 0.01095671
Iteration 24/25 | Loss: 0.01095671
Iteration 25/25 | Loss: 0.01095671

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.90214860
Iteration 2/25 | Loss: 0.06306599
Iteration 3/25 | Loss: 0.06306116
Iteration 4/25 | Loss: 0.06306113
Iteration 5/25 | Loss: 0.06306113
Iteration 6/25 | Loss: 0.06306113
Iteration 7/25 | Loss: 0.06306113
Iteration 8/25 | Loss: 0.06306111
Iteration 9/25 | Loss: 0.06306113
Iteration 10/25 | Loss: 0.06306111
Iteration 11/25 | Loss: 0.06306111
Iteration 12/25 | Loss: 0.06306111
Iteration 13/25 | Loss: 0.06306111
Iteration 14/25 | Loss: 0.06306111
Iteration 15/25 | Loss: 0.06306111
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.06306111067533493, 0.06306111067533493, 0.06306111067533493, 0.06306111067533493, 0.06306111067533493]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.06306111067533493

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.06306111
Iteration 2/1000 | Loss: 0.00741831
Iteration 3/1000 | Loss: 0.00168002
Iteration 4/1000 | Loss: 0.00082661
Iteration 5/1000 | Loss: 0.00124668
Iteration 6/1000 | Loss: 0.01111356
Iteration 7/1000 | Loss: 0.00493882
Iteration 8/1000 | Loss: 0.00300316
Iteration 9/1000 | Loss: 0.00691568
Iteration 10/1000 | Loss: 0.00325648
Iteration 11/1000 | Loss: 0.00176691
Iteration 12/1000 | Loss: 0.00057725
Iteration 13/1000 | Loss: 0.00049004
Iteration 14/1000 | Loss: 0.00013675
Iteration 15/1000 | Loss: 0.00016838
Iteration 16/1000 | Loss: 0.00036779
Iteration 17/1000 | Loss: 0.00024651
Iteration 18/1000 | Loss: 0.00029667
Iteration 19/1000 | Loss: 0.00011472
Iteration 20/1000 | Loss: 0.00046706
Iteration 21/1000 | Loss: 0.00110215
Iteration 22/1000 | Loss: 0.00241199
Iteration 23/1000 | Loss: 0.00017470
Iteration 24/1000 | Loss: 0.00004802
Iteration 25/1000 | Loss: 0.00016834
Iteration 26/1000 | Loss: 0.00003814
Iteration 27/1000 | Loss: 0.00016301
Iteration 28/1000 | Loss: 0.00025207
Iteration 29/1000 | Loss: 0.00003300
Iteration 30/1000 | Loss: 0.00009955
Iteration 31/1000 | Loss: 0.00181017
Iteration 32/1000 | Loss: 0.00085589
Iteration 33/1000 | Loss: 0.00022164
Iteration 34/1000 | Loss: 0.00004016
Iteration 35/1000 | Loss: 0.00010080
Iteration 36/1000 | Loss: 0.00004531
Iteration 37/1000 | Loss: 0.00011317
Iteration 38/1000 | Loss: 0.00145947
Iteration 39/1000 | Loss: 0.00017762
Iteration 40/1000 | Loss: 0.00098682
Iteration 41/1000 | Loss: 0.00044429
Iteration 42/1000 | Loss: 0.00029371
Iteration 43/1000 | Loss: 0.00008314
Iteration 44/1000 | Loss: 0.00065684
Iteration 45/1000 | Loss: 0.00002674
Iteration 46/1000 | Loss: 0.00004398
Iteration 47/1000 | Loss: 0.00002474
Iteration 48/1000 | Loss: 0.00002409
Iteration 49/1000 | Loss: 0.00077723
Iteration 50/1000 | Loss: 0.00010951
Iteration 51/1000 | Loss: 0.00003591
Iteration 52/1000 | Loss: 0.00003895
Iteration 53/1000 | Loss: 0.00007543
Iteration 54/1000 | Loss: 0.00002275
Iteration 55/1000 | Loss: 0.00005740
Iteration 56/1000 | Loss: 0.00087039
Iteration 57/1000 | Loss: 0.00007834
Iteration 58/1000 | Loss: 0.00002761
Iteration 59/1000 | Loss: 0.00002191
Iteration 60/1000 | Loss: 0.00005010
Iteration 61/1000 | Loss: 0.00058207
Iteration 62/1000 | Loss: 0.00006121
Iteration 63/1000 | Loss: 0.00002169
Iteration 64/1000 | Loss: 0.00002448
Iteration 65/1000 | Loss: 0.00013668
Iteration 66/1000 | Loss: 0.00003063
Iteration 67/1000 | Loss: 0.00005705
Iteration 68/1000 | Loss: 0.00015848
Iteration 69/1000 | Loss: 0.00002329
Iteration 70/1000 | Loss: 0.00006897
Iteration 71/1000 | Loss: 0.00003312
Iteration 72/1000 | Loss: 0.00002680
Iteration 73/1000 | Loss: 0.00002054
Iteration 74/1000 | Loss: 0.00002046
Iteration 75/1000 | Loss: 0.00002537
Iteration 76/1000 | Loss: 0.00002034
Iteration 77/1000 | Loss: 0.00002032
Iteration 78/1000 | Loss: 0.00002032
Iteration 79/1000 | Loss: 0.00004464
Iteration 80/1000 | Loss: 0.00005362
Iteration 81/1000 | Loss: 0.00003837
Iteration 82/1000 | Loss: 0.00002027
Iteration 83/1000 | Loss: 0.00002015
Iteration 84/1000 | Loss: 0.00002014
Iteration 85/1000 | Loss: 0.00002014
Iteration 86/1000 | Loss: 0.00002014
Iteration 87/1000 | Loss: 0.00002014
Iteration 88/1000 | Loss: 0.00002014
Iteration 89/1000 | Loss: 0.00002014
Iteration 90/1000 | Loss: 0.00002014
Iteration 91/1000 | Loss: 0.00002014
Iteration 92/1000 | Loss: 0.00002014
Iteration 93/1000 | Loss: 0.00002014
Iteration 94/1000 | Loss: 0.00002014
Iteration 95/1000 | Loss: 0.00002013
Iteration 96/1000 | Loss: 0.00002011
Iteration 97/1000 | Loss: 0.00002011
Iteration 98/1000 | Loss: 0.00002011
Iteration 99/1000 | Loss: 0.00002011
Iteration 100/1000 | Loss: 0.00002011
Iteration 101/1000 | Loss: 0.00002011
Iteration 102/1000 | Loss: 0.00002011
Iteration 103/1000 | Loss: 0.00002010
Iteration 104/1000 | Loss: 0.00002010
Iteration 105/1000 | Loss: 0.00002010
Iteration 106/1000 | Loss: 0.00003727
Iteration 107/1000 | Loss: 0.00002170
Iteration 108/1000 | Loss: 0.00002170
Iteration 109/1000 | Loss: 0.00002007
Iteration 110/1000 | Loss: 0.00002007
Iteration 111/1000 | Loss: 0.00002007
Iteration 112/1000 | Loss: 0.00002007
Iteration 113/1000 | Loss: 0.00002006
Iteration 114/1000 | Loss: 0.00002006
Iteration 115/1000 | Loss: 0.00002006
Iteration 116/1000 | Loss: 0.00002006
Iteration 117/1000 | Loss: 0.00002006
Iteration 118/1000 | Loss: 0.00002006
Iteration 119/1000 | Loss: 0.00002006
Iteration 120/1000 | Loss: 0.00002006
Iteration 121/1000 | Loss: 0.00002006
Iteration 122/1000 | Loss: 0.00002005
Iteration 123/1000 | Loss: 0.00002005
Iteration 124/1000 | Loss: 0.00002005
Iteration 125/1000 | Loss: 0.00002005
Iteration 126/1000 | Loss: 0.00002005
Iteration 127/1000 | Loss: 0.00002005
Iteration 128/1000 | Loss: 0.00002005
Iteration 129/1000 | Loss: 0.00002004
Iteration 130/1000 | Loss: 0.00002004
Iteration 131/1000 | Loss: 0.00002004
Iteration 132/1000 | Loss: 0.00002004
Iteration 133/1000 | Loss: 0.00002004
Iteration 134/1000 | Loss: 0.00002004
Iteration 135/1000 | Loss: 0.00002004
Iteration 136/1000 | Loss: 0.00002004
Iteration 137/1000 | Loss: 0.00002004
Iteration 138/1000 | Loss: 0.00002004
Iteration 139/1000 | Loss: 0.00002004
Iteration 140/1000 | Loss: 0.00002004
Iteration 141/1000 | Loss: 0.00002004
Iteration 142/1000 | Loss: 0.00002004
Iteration 143/1000 | Loss: 0.00002004
Iteration 144/1000 | Loss: 0.00002003
Iteration 145/1000 | Loss: 0.00002003
Iteration 146/1000 | Loss: 0.00002003
Iteration 147/1000 | Loss: 0.00002003
Iteration 148/1000 | Loss: 0.00002003
Iteration 149/1000 | Loss: 0.00002002
Iteration 150/1000 | Loss: 0.00002002
Iteration 151/1000 | Loss: 0.00002002
Iteration 152/1000 | Loss: 0.00002002
Iteration 153/1000 | Loss: 0.00002002
Iteration 154/1000 | Loss: 0.00002002
Iteration 155/1000 | Loss: 0.00002001
Iteration 156/1000 | Loss: 0.00002001
Iteration 157/1000 | Loss: 0.00002001
Iteration 158/1000 | Loss: 0.00002001
Iteration 159/1000 | Loss: 0.00002560
Iteration 160/1000 | Loss: 0.00002001
Iteration 161/1000 | Loss: 0.00002001
Iteration 162/1000 | Loss: 0.00002001
Iteration 163/1000 | Loss: 0.00002000
Iteration 164/1000 | Loss: 0.00002000
Iteration 165/1000 | Loss: 0.00002000
Iteration 166/1000 | Loss: 0.00002000
Iteration 167/1000 | Loss: 0.00002000
Iteration 168/1000 | Loss: 0.00002000
Iteration 169/1000 | Loss: 0.00002000
Iteration 170/1000 | Loss: 0.00002000
Iteration 171/1000 | Loss: 0.00002000
Iteration 172/1000 | Loss: 0.00001999
Iteration 173/1000 | Loss: 0.00001999
Iteration 174/1000 | Loss: 0.00002558
Iteration 175/1000 | Loss: 0.00002558
Iteration 176/1000 | Loss: 0.00002557
Iteration 177/1000 | Loss: 0.00002557
Iteration 178/1000 | Loss: 0.00002557
Iteration 179/1000 | Loss: 0.00002556
Iteration 180/1000 | Loss: 0.00025098
Iteration 181/1000 | Loss: 0.00007147
Iteration 182/1000 | Loss: 0.00002288
Iteration 183/1000 | Loss: 0.00002678
Iteration 184/1000 | Loss: 0.00004346
Iteration 185/1000 | Loss: 0.00001998
Iteration 186/1000 | Loss: 0.00001997
Iteration 187/1000 | Loss: 0.00001997
Iteration 188/1000 | Loss: 0.00001997
Iteration 189/1000 | Loss: 0.00001997
Iteration 190/1000 | Loss: 0.00001996
Iteration 191/1000 | Loss: 0.00001996
Iteration 192/1000 | Loss: 0.00001996
Iteration 193/1000 | Loss: 0.00001996
Iteration 194/1000 | Loss: 0.00001996
Iteration 195/1000 | Loss: 0.00001996
Iteration 196/1000 | Loss: 0.00001995
Iteration 197/1000 | Loss: 0.00001994
Iteration 198/1000 | Loss: 0.00001994
Iteration 199/1000 | Loss: 0.00001994
Iteration 200/1000 | Loss: 0.00001994
Iteration 201/1000 | Loss: 0.00001994
Iteration 202/1000 | Loss: 0.00001994
Iteration 203/1000 | Loss: 0.00001994
Iteration 204/1000 | Loss: 0.00001993
Iteration 205/1000 | Loss: 0.00001993
Iteration 206/1000 | Loss: 0.00001993
Iteration 207/1000 | Loss: 0.00001992
Iteration 208/1000 | Loss: 0.00001992
Iteration 209/1000 | Loss: 0.00002569
Iteration 210/1000 | Loss: 0.00001992
Iteration 211/1000 | Loss: 0.00001992
Iteration 212/1000 | Loss: 0.00001992
Iteration 213/1000 | Loss: 0.00001991
Iteration 214/1000 | Loss: 0.00001991
Iteration 215/1000 | Loss: 0.00001991
Iteration 216/1000 | Loss: 0.00001991
Iteration 217/1000 | Loss: 0.00001991
Iteration 218/1000 | Loss: 0.00001991
Iteration 219/1000 | Loss: 0.00001990
Iteration 220/1000 | Loss: 0.00001990
Iteration 221/1000 | Loss: 0.00001990
Iteration 222/1000 | Loss: 0.00001990
Iteration 223/1000 | Loss: 0.00001990
Iteration 224/1000 | Loss: 0.00001990
Iteration 225/1000 | Loss: 0.00001989
Iteration 226/1000 | Loss: 0.00001989
Iteration 227/1000 | Loss: 0.00001989
Iteration 228/1000 | Loss: 0.00001989
Iteration 229/1000 | Loss: 0.00001989
Iteration 230/1000 | Loss: 0.00001989
Iteration 231/1000 | Loss: 0.00001989
Iteration 232/1000 | Loss: 0.00001989
Iteration 233/1000 | Loss: 0.00001989
Iteration 234/1000 | Loss: 0.00001989
Iteration 235/1000 | Loss: 0.00001989
Iteration 236/1000 | Loss: 0.00001989
Iteration 237/1000 | Loss: 0.00001989
Iteration 238/1000 | Loss: 0.00001989
Iteration 239/1000 | Loss: 0.00001989
Iteration 240/1000 | Loss: 0.00001989
Iteration 241/1000 | Loss: 0.00001989
Iteration 242/1000 | Loss: 0.00001989
Iteration 243/1000 | Loss: 0.00001989
Iteration 244/1000 | Loss: 0.00001989
Iteration 245/1000 | Loss: 0.00001989
Iteration 246/1000 | Loss: 0.00001989
Iteration 247/1000 | Loss: 0.00001989
Iteration 248/1000 | Loss: 0.00001989
Iteration 249/1000 | Loss: 0.00001989
Iteration 250/1000 | Loss: 0.00001989
Iteration 251/1000 | Loss: 0.00001989
Iteration 252/1000 | Loss: 0.00001989
Iteration 253/1000 | Loss: 0.00001989
Iteration 254/1000 | Loss: 0.00001989
Iteration 255/1000 | Loss: 0.00001989
Iteration 256/1000 | Loss: 0.00001989
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 256. Stopping optimization.
Last 5 losses: [1.988508302019909e-05, 1.988508302019909e-05, 1.988508302019909e-05, 1.988508302019909e-05, 1.988508302019909e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.988508302019909e-05

Optimization complete. Final v2v error: 3.542578935623169 mm

Highest mean error: 4.791568279266357 mm for frame 225

Lowest mean error: 2.741861343383789 mm for frame 123

Saving results

Total time: 158.4250454902649
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00441683
Iteration 2/25 | Loss: 0.00088523
Iteration 3/25 | Loss: 0.00077326
Iteration 4/25 | Loss: 0.00075510
Iteration 5/25 | Loss: 0.00074991
Iteration 6/25 | Loss: 0.00074843
Iteration 7/25 | Loss: 0.00074823
Iteration 8/25 | Loss: 0.00074823
Iteration 9/25 | Loss: 0.00074823
Iteration 10/25 | Loss: 0.00074823
Iteration 11/25 | Loss: 0.00074823
Iteration 12/25 | Loss: 0.00074823
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007482297369278967, 0.0007482297369278967, 0.0007482297369278967, 0.0007482297369278967, 0.0007482297369278967]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007482297369278967

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.37593150
Iteration 2/25 | Loss: 0.00030181
Iteration 3/25 | Loss: 0.00030181
Iteration 4/25 | Loss: 0.00030181
Iteration 5/25 | Loss: 0.00030181
Iteration 6/25 | Loss: 0.00030180
Iteration 7/25 | Loss: 0.00030180
Iteration 8/25 | Loss: 0.00030180
Iteration 9/25 | Loss: 0.00030180
Iteration 10/25 | Loss: 0.00030180
Iteration 11/25 | Loss: 0.00030180
Iteration 12/25 | Loss: 0.00030180
Iteration 13/25 | Loss: 0.00030180
Iteration 14/25 | Loss: 0.00030180
Iteration 15/25 | Loss: 0.00030180
Iteration 16/25 | Loss: 0.00030180
Iteration 17/25 | Loss: 0.00030180
Iteration 18/25 | Loss: 0.00030180
Iteration 19/25 | Loss: 0.00030180
Iteration 20/25 | Loss: 0.00030180
Iteration 21/25 | Loss: 0.00030180
Iteration 22/25 | Loss: 0.00030180
Iteration 23/25 | Loss: 0.00030180
Iteration 24/25 | Loss: 0.00030180
Iteration 25/25 | Loss: 0.00030180

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030180
Iteration 2/1000 | Loss: 0.00002228
Iteration 3/1000 | Loss: 0.00001698
Iteration 4/1000 | Loss: 0.00001546
Iteration 5/1000 | Loss: 0.00001465
Iteration 6/1000 | Loss: 0.00001404
Iteration 7/1000 | Loss: 0.00001353
Iteration 8/1000 | Loss: 0.00001333
Iteration 9/1000 | Loss: 0.00001330
Iteration 10/1000 | Loss: 0.00001329
Iteration 11/1000 | Loss: 0.00001327
Iteration 12/1000 | Loss: 0.00001326
Iteration 13/1000 | Loss: 0.00001325
Iteration 14/1000 | Loss: 0.00001325
Iteration 15/1000 | Loss: 0.00001324
Iteration 16/1000 | Loss: 0.00001323
Iteration 17/1000 | Loss: 0.00001323
Iteration 18/1000 | Loss: 0.00001322
Iteration 19/1000 | Loss: 0.00001322
Iteration 20/1000 | Loss: 0.00001321
Iteration 21/1000 | Loss: 0.00001318
Iteration 22/1000 | Loss: 0.00001317
Iteration 23/1000 | Loss: 0.00001317
Iteration 24/1000 | Loss: 0.00001316
Iteration 25/1000 | Loss: 0.00001316
Iteration 26/1000 | Loss: 0.00001315
Iteration 27/1000 | Loss: 0.00001315
Iteration 28/1000 | Loss: 0.00001315
Iteration 29/1000 | Loss: 0.00001315
Iteration 30/1000 | Loss: 0.00001314
Iteration 31/1000 | Loss: 0.00001314
Iteration 32/1000 | Loss: 0.00001314
Iteration 33/1000 | Loss: 0.00001313
Iteration 34/1000 | Loss: 0.00001313
Iteration 35/1000 | Loss: 0.00001312
Iteration 36/1000 | Loss: 0.00001312
Iteration 37/1000 | Loss: 0.00001312
Iteration 38/1000 | Loss: 0.00001311
Iteration 39/1000 | Loss: 0.00001311
Iteration 40/1000 | Loss: 0.00001311
Iteration 41/1000 | Loss: 0.00001311
Iteration 42/1000 | Loss: 0.00001311
Iteration 43/1000 | Loss: 0.00001310
Iteration 44/1000 | Loss: 0.00001310
Iteration 45/1000 | Loss: 0.00001310
Iteration 46/1000 | Loss: 0.00001310
Iteration 47/1000 | Loss: 0.00001310
Iteration 48/1000 | Loss: 0.00001310
Iteration 49/1000 | Loss: 0.00001310
Iteration 50/1000 | Loss: 0.00001310
Iteration 51/1000 | Loss: 0.00001310
Iteration 52/1000 | Loss: 0.00001309
Iteration 53/1000 | Loss: 0.00001309
Iteration 54/1000 | Loss: 0.00001309
Iteration 55/1000 | Loss: 0.00001309
Iteration 56/1000 | Loss: 0.00001308
Iteration 57/1000 | Loss: 0.00001308
Iteration 58/1000 | Loss: 0.00001308
Iteration 59/1000 | Loss: 0.00001308
Iteration 60/1000 | Loss: 0.00001308
Iteration 61/1000 | Loss: 0.00001308
Iteration 62/1000 | Loss: 0.00001308
Iteration 63/1000 | Loss: 0.00001308
Iteration 64/1000 | Loss: 0.00001308
Iteration 65/1000 | Loss: 0.00001307
Iteration 66/1000 | Loss: 0.00001307
Iteration 67/1000 | Loss: 0.00001307
Iteration 68/1000 | Loss: 0.00001307
Iteration 69/1000 | Loss: 0.00001307
Iteration 70/1000 | Loss: 0.00001307
Iteration 71/1000 | Loss: 0.00001307
Iteration 72/1000 | Loss: 0.00001307
Iteration 73/1000 | Loss: 0.00001306
Iteration 74/1000 | Loss: 0.00001306
Iteration 75/1000 | Loss: 0.00001306
Iteration 76/1000 | Loss: 0.00001306
Iteration 77/1000 | Loss: 0.00001306
Iteration 78/1000 | Loss: 0.00001306
Iteration 79/1000 | Loss: 0.00001306
Iteration 80/1000 | Loss: 0.00001306
Iteration 81/1000 | Loss: 0.00001306
Iteration 82/1000 | Loss: 0.00001306
Iteration 83/1000 | Loss: 0.00001305
Iteration 84/1000 | Loss: 0.00001305
Iteration 85/1000 | Loss: 0.00001305
Iteration 86/1000 | Loss: 0.00001305
Iteration 87/1000 | Loss: 0.00001305
Iteration 88/1000 | Loss: 0.00001305
Iteration 89/1000 | Loss: 0.00001305
Iteration 90/1000 | Loss: 0.00001305
Iteration 91/1000 | Loss: 0.00001305
Iteration 92/1000 | Loss: 0.00001305
Iteration 93/1000 | Loss: 0.00001305
Iteration 94/1000 | Loss: 0.00001304
Iteration 95/1000 | Loss: 0.00001304
Iteration 96/1000 | Loss: 0.00001304
Iteration 97/1000 | Loss: 0.00001304
Iteration 98/1000 | Loss: 0.00001304
Iteration 99/1000 | Loss: 0.00001304
Iteration 100/1000 | Loss: 0.00001304
Iteration 101/1000 | Loss: 0.00001304
Iteration 102/1000 | Loss: 0.00001304
Iteration 103/1000 | Loss: 0.00001304
Iteration 104/1000 | Loss: 0.00001304
Iteration 105/1000 | Loss: 0.00001304
Iteration 106/1000 | Loss: 0.00001304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.3041898455412593e-05, 1.3041898455412593e-05, 1.3041898455412593e-05, 1.3041898455412593e-05, 1.3041898455412593e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3041898455412593e-05

Optimization complete. Final v2v error: 3.0318238735198975 mm

Highest mean error: 3.756119728088379 mm for frame 71

Lowest mean error: 2.667705774307251 mm for frame 102

Saving results

Total time: 30.63490080833435
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00834904
Iteration 2/25 | Loss: 0.00147985
Iteration 3/25 | Loss: 0.00109131
Iteration 4/25 | Loss: 0.00100506
Iteration 5/25 | Loss: 0.00099712
Iteration 6/25 | Loss: 0.00097664
Iteration 7/25 | Loss: 0.00096538
Iteration 8/25 | Loss: 0.00096641
Iteration 9/25 | Loss: 0.00096938
Iteration 10/25 | Loss: 0.00095901
Iteration 11/25 | Loss: 0.00096115
Iteration 12/25 | Loss: 0.00096174
Iteration 13/25 | Loss: 0.00096766
Iteration 14/25 | Loss: 0.00097122
Iteration 15/25 | Loss: 0.00096350
Iteration 16/25 | Loss: 0.00097537
Iteration 17/25 | Loss: 0.00097280
Iteration 18/25 | Loss: 0.00096318
Iteration 19/25 | Loss: 0.00094944
Iteration 20/25 | Loss: 0.00095480
Iteration 21/25 | Loss: 0.00094956
Iteration 22/25 | Loss: 0.00095889
Iteration 23/25 | Loss: 0.00094233
Iteration 24/25 | Loss: 0.00094843
Iteration 25/25 | Loss: 0.00092839

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 8.00735378
Iteration 2/25 | Loss: 0.00117043
Iteration 3/25 | Loss: 0.00117021
Iteration 4/25 | Loss: 0.00117020
Iteration 5/25 | Loss: 0.00117020
Iteration 6/25 | Loss: 0.00117020
Iteration 7/25 | Loss: 0.00117020
Iteration 8/25 | Loss: 0.00117020
Iteration 9/25 | Loss: 0.00117020
Iteration 10/25 | Loss: 0.00117020
Iteration 11/25 | Loss: 0.00117020
Iteration 12/25 | Loss: 0.00117020
Iteration 13/25 | Loss: 0.00117020
Iteration 14/25 | Loss: 0.00117020
Iteration 15/25 | Loss: 0.00117020
Iteration 16/25 | Loss: 0.00117020
Iteration 17/25 | Loss: 0.00117020
Iteration 18/25 | Loss: 0.00117020
Iteration 19/25 | Loss: 0.00117020
Iteration 20/25 | Loss: 0.00117020
Iteration 21/25 | Loss: 0.00117020
Iteration 22/25 | Loss: 0.00117020
Iteration 23/25 | Loss: 0.00117020
Iteration 24/25 | Loss: 0.00117020
Iteration 25/25 | Loss: 0.00117020

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00117020
Iteration 2/1000 | Loss: 0.00690662
Iteration 3/1000 | Loss: 0.01089516
Iteration 4/1000 | Loss: 0.01023866
Iteration 5/1000 | Loss: 0.01018830
Iteration 6/1000 | Loss: 0.00525759
Iteration 7/1000 | Loss: 0.00084434
Iteration 8/1000 | Loss: 0.00066259
Iteration 9/1000 | Loss: 0.00013437
Iteration 10/1000 | Loss: 0.00050210
Iteration 11/1000 | Loss: 0.00014463
Iteration 12/1000 | Loss: 0.00006430
Iteration 13/1000 | Loss: 0.00005553
Iteration 14/1000 | Loss: 0.00004586
Iteration 15/1000 | Loss: 0.00004293
Iteration 16/1000 | Loss: 0.00098257
Iteration 17/1000 | Loss: 0.00011117
Iteration 18/1000 | Loss: 0.00005320
Iteration 19/1000 | Loss: 0.00099591
Iteration 20/1000 | Loss: 0.00059282
Iteration 21/1000 | Loss: 0.00027984
Iteration 22/1000 | Loss: 0.00053834
Iteration 23/1000 | Loss: 0.00005782
Iteration 24/1000 | Loss: 0.00020866
Iteration 25/1000 | Loss: 0.00055364
Iteration 26/1000 | Loss: 0.00035074
Iteration 27/1000 | Loss: 0.00030491
Iteration 28/1000 | Loss: 0.00151324
Iteration 29/1000 | Loss: 0.00069846
Iteration 30/1000 | Loss: 0.00084219
Iteration 31/1000 | Loss: 0.00050734
Iteration 32/1000 | Loss: 0.00076353
Iteration 33/1000 | Loss: 0.00101477
Iteration 34/1000 | Loss: 0.00054182
Iteration 35/1000 | Loss: 0.00081910
Iteration 36/1000 | Loss: 0.00027589
Iteration 37/1000 | Loss: 0.00004042
Iteration 38/1000 | Loss: 0.00003600
Iteration 39/1000 | Loss: 0.00003352
Iteration 40/1000 | Loss: 0.00003161
Iteration 41/1000 | Loss: 0.00003034
Iteration 42/1000 | Loss: 0.00026227
Iteration 43/1000 | Loss: 0.00003860
Iteration 44/1000 | Loss: 0.00002891
Iteration 45/1000 | Loss: 0.00002757
Iteration 46/1000 | Loss: 0.00002707
Iteration 47/1000 | Loss: 0.00002680
Iteration 48/1000 | Loss: 0.00002653
Iteration 49/1000 | Loss: 0.00002635
Iteration 50/1000 | Loss: 0.00002627
Iteration 51/1000 | Loss: 0.00002616
Iteration 52/1000 | Loss: 0.00002601
Iteration 53/1000 | Loss: 0.00002601
Iteration 54/1000 | Loss: 0.00002591
Iteration 55/1000 | Loss: 0.00002587
Iteration 56/1000 | Loss: 0.00002587
Iteration 57/1000 | Loss: 0.00002586
Iteration 58/1000 | Loss: 0.00002586
Iteration 59/1000 | Loss: 0.00002585
Iteration 60/1000 | Loss: 0.00002584
Iteration 61/1000 | Loss: 0.00002582
Iteration 62/1000 | Loss: 0.00002581
Iteration 63/1000 | Loss: 0.00002581
Iteration 64/1000 | Loss: 0.00002580
Iteration 65/1000 | Loss: 0.00002580
Iteration 66/1000 | Loss: 0.00002580
Iteration 67/1000 | Loss: 0.00002580
Iteration 68/1000 | Loss: 0.00002579
Iteration 69/1000 | Loss: 0.00002579
Iteration 70/1000 | Loss: 0.00002577
Iteration 71/1000 | Loss: 0.00002574
Iteration 72/1000 | Loss: 0.00002574
Iteration 73/1000 | Loss: 0.00002574
Iteration 74/1000 | Loss: 0.00002573
Iteration 75/1000 | Loss: 0.00002573
Iteration 76/1000 | Loss: 0.00002573
Iteration 77/1000 | Loss: 0.00002572
Iteration 78/1000 | Loss: 0.00002572
Iteration 79/1000 | Loss: 0.00002571
Iteration 80/1000 | Loss: 0.00002571
Iteration 81/1000 | Loss: 0.00002571
Iteration 82/1000 | Loss: 0.00002571
Iteration 83/1000 | Loss: 0.00002570
Iteration 84/1000 | Loss: 0.00002570
Iteration 85/1000 | Loss: 0.00002570
Iteration 86/1000 | Loss: 0.00002569
Iteration 87/1000 | Loss: 0.00002569
Iteration 88/1000 | Loss: 0.00002569
Iteration 89/1000 | Loss: 0.00002569
Iteration 90/1000 | Loss: 0.00002568
Iteration 91/1000 | Loss: 0.00002568
Iteration 92/1000 | Loss: 0.00002568
Iteration 93/1000 | Loss: 0.00002567
Iteration 94/1000 | Loss: 0.00002567
Iteration 95/1000 | Loss: 0.00002567
Iteration 96/1000 | Loss: 0.00002566
Iteration 97/1000 | Loss: 0.00002565
Iteration 98/1000 | Loss: 0.00002565
Iteration 99/1000 | Loss: 0.00002565
Iteration 100/1000 | Loss: 0.00002564
Iteration 101/1000 | Loss: 0.00002564
Iteration 102/1000 | Loss: 0.00002563
Iteration 103/1000 | Loss: 0.00002563
Iteration 104/1000 | Loss: 0.00002563
Iteration 105/1000 | Loss: 0.00002563
Iteration 106/1000 | Loss: 0.00002562
Iteration 107/1000 | Loss: 0.00002562
Iteration 108/1000 | Loss: 0.00002562
Iteration 109/1000 | Loss: 0.00002561
Iteration 110/1000 | Loss: 0.00002561
Iteration 111/1000 | Loss: 0.00002561
Iteration 112/1000 | Loss: 0.00002560
Iteration 113/1000 | Loss: 0.00002560
Iteration 114/1000 | Loss: 0.00002560
Iteration 115/1000 | Loss: 0.00002560
Iteration 116/1000 | Loss: 0.00002560
Iteration 117/1000 | Loss: 0.00002560
Iteration 118/1000 | Loss: 0.00002560
Iteration 119/1000 | Loss: 0.00002560
Iteration 120/1000 | Loss: 0.00002559
Iteration 121/1000 | Loss: 0.00002559
Iteration 122/1000 | Loss: 0.00002559
Iteration 123/1000 | Loss: 0.00002559
Iteration 124/1000 | Loss: 0.00002559
Iteration 125/1000 | Loss: 0.00002559
Iteration 126/1000 | Loss: 0.00002559
Iteration 127/1000 | Loss: 0.00002559
Iteration 128/1000 | Loss: 0.00002559
Iteration 129/1000 | Loss: 0.00002559
Iteration 130/1000 | Loss: 0.00002559
Iteration 131/1000 | Loss: 0.00002559
Iteration 132/1000 | Loss: 0.00002559
Iteration 133/1000 | Loss: 0.00002559
Iteration 134/1000 | Loss: 0.00002559
Iteration 135/1000 | Loss: 0.00002559
Iteration 136/1000 | Loss: 0.00002559
Iteration 137/1000 | Loss: 0.00002559
Iteration 138/1000 | Loss: 0.00002559
Iteration 139/1000 | Loss: 0.00002559
Iteration 140/1000 | Loss: 0.00002559
Iteration 141/1000 | Loss: 0.00002559
Iteration 142/1000 | Loss: 0.00002559
Iteration 143/1000 | Loss: 0.00002559
Iteration 144/1000 | Loss: 0.00002559
Iteration 145/1000 | Loss: 0.00002559
Iteration 146/1000 | Loss: 0.00002559
Iteration 147/1000 | Loss: 0.00002559
Iteration 148/1000 | Loss: 0.00002559
Iteration 149/1000 | Loss: 0.00002559
Iteration 150/1000 | Loss: 0.00002559
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [2.5590556106180884e-05, 2.5590556106180884e-05, 2.5590556106180884e-05, 2.5590556106180884e-05, 2.5590556106180884e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5590556106180884e-05

Optimization complete. Final v2v error: 4.100471496582031 mm

Highest mean error: 6.453719615936279 mm for frame 50

Lowest mean error: 3.0171945095062256 mm for frame 73

Saving results

Total time: 130.56436920166016
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00509843
Iteration 2/25 | Loss: 0.00092151
Iteration 3/25 | Loss: 0.00078926
Iteration 4/25 | Loss: 0.00076905
Iteration 5/25 | Loss: 0.00076336
Iteration 6/25 | Loss: 0.00076172
Iteration 7/25 | Loss: 0.00076116
Iteration 8/25 | Loss: 0.00076116
Iteration 9/25 | Loss: 0.00076116
Iteration 10/25 | Loss: 0.00076116
Iteration 11/25 | Loss: 0.00076116
Iteration 12/25 | Loss: 0.00076116
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007611637702211738, 0.0007611637702211738, 0.0007611637702211738, 0.0007611637702211738, 0.0007611637702211738]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007611637702211738

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.01991701
Iteration 2/25 | Loss: 0.00030532
Iteration 3/25 | Loss: 0.00030531
Iteration 4/25 | Loss: 0.00030531
Iteration 5/25 | Loss: 0.00030531
Iteration 6/25 | Loss: 0.00030531
Iteration 7/25 | Loss: 0.00030531
Iteration 8/25 | Loss: 0.00030531
Iteration 9/25 | Loss: 0.00030531
Iteration 10/25 | Loss: 0.00030531
Iteration 11/25 | Loss: 0.00030531
Iteration 12/25 | Loss: 0.00030531
Iteration 13/25 | Loss: 0.00030531
Iteration 14/25 | Loss: 0.00030531
Iteration 15/25 | Loss: 0.00030531
Iteration 16/25 | Loss: 0.00030531
Iteration 17/25 | Loss: 0.00030531
Iteration 18/25 | Loss: 0.00030531
Iteration 19/25 | Loss: 0.00030531
Iteration 20/25 | Loss: 0.00030531
Iteration 21/25 | Loss: 0.00030531
Iteration 22/25 | Loss: 0.00030531
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00030530846561305225, 0.00030530846561305225, 0.00030530846561305225, 0.00030530846561305225, 0.00030530846561305225]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00030530846561305225

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030531
Iteration 2/1000 | Loss: 0.00003310
Iteration 3/1000 | Loss: 0.00002051
Iteration 4/1000 | Loss: 0.00001831
Iteration 5/1000 | Loss: 0.00001715
Iteration 6/1000 | Loss: 0.00001648
Iteration 7/1000 | Loss: 0.00001595
Iteration 8/1000 | Loss: 0.00001566
Iteration 9/1000 | Loss: 0.00001551
Iteration 10/1000 | Loss: 0.00001548
Iteration 11/1000 | Loss: 0.00001547
Iteration 12/1000 | Loss: 0.00001545
Iteration 13/1000 | Loss: 0.00001545
Iteration 14/1000 | Loss: 0.00001544
Iteration 15/1000 | Loss: 0.00001544
Iteration 16/1000 | Loss: 0.00001544
Iteration 17/1000 | Loss: 0.00001544
Iteration 18/1000 | Loss: 0.00001544
Iteration 19/1000 | Loss: 0.00001544
Iteration 20/1000 | Loss: 0.00001543
Iteration 21/1000 | Loss: 0.00001543
Iteration 22/1000 | Loss: 0.00001543
Iteration 23/1000 | Loss: 0.00001543
Iteration 24/1000 | Loss: 0.00001542
Iteration 25/1000 | Loss: 0.00001541
Iteration 26/1000 | Loss: 0.00001541
Iteration 27/1000 | Loss: 0.00001541
Iteration 28/1000 | Loss: 0.00001540
Iteration 29/1000 | Loss: 0.00001540
Iteration 30/1000 | Loss: 0.00001540
Iteration 31/1000 | Loss: 0.00001540
Iteration 32/1000 | Loss: 0.00001539
Iteration 33/1000 | Loss: 0.00001539
Iteration 34/1000 | Loss: 0.00001539
Iteration 35/1000 | Loss: 0.00001539
Iteration 36/1000 | Loss: 0.00001539
Iteration 37/1000 | Loss: 0.00001538
Iteration 38/1000 | Loss: 0.00001538
Iteration 39/1000 | Loss: 0.00001538
Iteration 40/1000 | Loss: 0.00001537
Iteration 41/1000 | Loss: 0.00001537
Iteration 42/1000 | Loss: 0.00001537
Iteration 43/1000 | Loss: 0.00001537
Iteration 44/1000 | Loss: 0.00001537
Iteration 45/1000 | Loss: 0.00001536
Iteration 46/1000 | Loss: 0.00001535
Iteration 47/1000 | Loss: 0.00001535
Iteration 48/1000 | Loss: 0.00001534
Iteration 49/1000 | Loss: 0.00001534
Iteration 50/1000 | Loss: 0.00001534
Iteration 51/1000 | Loss: 0.00001534
Iteration 52/1000 | Loss: 0.00001533
Iteration 53/1000 | Loss: 0.00001533
Iteration 54/1000 | Loss: 0.00001533
Iteration 55/1000 | Loss: 0.00001533
Iteration 56/1000 | Loss: 0.00001533
Iteration 57/1000 | Loss: 0.00001533
Iteration 58/1000 | Loss: 0.00001532
Iteration 59/1000 | Loss: 0.00001532
Iteration 60/1000 | Loss: 0.00001532
Iteration 61/1000 | Loss: 0.00001532
Iteration 62/1000 | Loss: 0.00001531
Iteration 63/1000 | Loss: 0.00001531
Iteration 64/1000 | Loss: 0.00001531
Iteration 65/1000 | Loss: 0.00001531
Iteration 66/1000 | Loss: 0.00001530
Iteration 67/1000 | Loss: 0.00001530
Iteration 68/1000 | Loss: 0.00001529
Iteration 69/1000 | Loss: 0.00001529
Iteration 70/1000 | Loss: 0.00001529
Iteration 71/1000 | Loss: 0.00001528
Iteration 72/1000 | Loss: 0.00001528
Iteration 73/1000 | Loss: 0.00001527
Iteration 74/1000 | Loss: 0.00001527
Iteration 75/1000 | Loss: 0.00001527
Iteration 76/1000 | Loss: 0.00001526
Iteration 77/1000 | Loss: 0.00001526
Iteration 78/1000 | Loss: 0.00001526
Iteration 79/1000 | Loss: 0.00001525
Iteration 80/1000 | Loss: 0.00001525
Iteration 81/1000 | Loss: 0.00001525
Iteration 82/1000 | Loss: 0.00001525
Iteration 83/1000 | Loss: 0.00001525
Iteration 84/1000 | Loss: 0.00001525
Iteration 85/1000 | Loss: 0.00001525
Iteration 86/1000 | Loss: 0.00001525
Iteration 87/1000 | Loss: 0.00001525
Iteration 88/1000 | Loss: 0.00001525
Iteration 89/1000 | Loss: 0.00001525
Iteration 90/1000 | Loss: 0.00001524
Iteration 91/1000 | Loss: 0.00001524
Iteration 92/1000 | Loss: 0.00001524
Iteration 93/1000 | Loss: 0.00001523
Iteration 94/1000 | Loss: 0.00001523
Iteration 95/1000 | Loss: 0.00001523
Iteration 96/1000 | Loss: 0.00001523
Iteration 97/1000 | Loss: 0.00001523
Iteration 98/1000 | Loss: 0.00001523
Iteration 99/1000 | Loss: 0.00001522
Iteration 100/1000 | Loss: 0.00001522
Iteration 101/1000 | Loss: 0.00001522
Iteration 102/1000 | Loss: 0.00001522
Iteration 103/1000 | Loss: 0.00001522
Iteration 104/1000 | Loss: 0.00001522
Iteration 105/1000 | Loss: 0.00001522
Iteration 106/1000 | Loss: 0.00001522
Iteration 107/1000 | Loss: 0.00001522
Iteration 108/1000 | Loss: 0.00001522
Iteration 109/1000 | Loss: 0.00001522
Iteration 110/1000 | Loss: 0.00001522
Iteration 111/1000 | Loss: 0.00001522
Iteration 112/1000 | Loss: 0.00001522
Iteration 113/1000 | Loss: 0.00001522
Iteration 114/1000 | Loss: 0.00001522
Iteration 115/1000 | Loss: 0.00001522
Iteration 116/1000 | Loss: 0.00001522
Iteration 117/1000 | Loss: 0.00001522
Iteration 118/1000 | Loss: 0.00001522
Iteration 119/1000 | Loss: 0.00001522
Iteration 120/1000 | Loss: 0.00001522
Iteration 121/1000 | Loss: 0.00001522
Iteration 122/1000 | Loss: 0.00001522
Iteration 123/1000 | Loss: 0.00001521
Iteration 124/1000 | Loss: 0.00001521
Iteration 125/1000 | Loss: 0.00001521
Iteration 126/1000 | Loss: 0.00001521
Iteration 127/1000 | Loss: 0.00001521
Iteration 128/1000 | Loss: 0.00001521
Iteration 129/1000 | Loss: 0.00001521
Iteration 130/1000 | Loss: 0.00001521
Iteration 131/1000 | Loss: 0.00001521
Iteration 132/1000 | Loss: 0.00001521
Iteration 133/1000 | Loss: 0.00001521
Iteration 134/1000 | Loss: 0.00001521
Iteration 135/1000 | Loss: 0.00001521
Iteration 136/1000 | Loss: 0.00001521
Iteration 137/1000 | Loss: 0.00001521
Iteration 138/1000 | Loss: 0.00001521
Iteration 139/1000 | Loss: 0.00001521
Iteration 140/1000 | Loss: 0.00001521
Iteration 141/1000 | Loss: 0.00001521
Iteration 142/1000 | Loss: 0.00001521
Iteration 143/1000 | Loss: 0.00001521
Iteration 144/1000 | Loss: 0.00001521
Iteration 145/1000 | Loss: 0.00001521
Iteration 146/1000 | Loss: 0.00001521
Iteration 147/1000 | Loss: 0.00001521
Iteration 148/1000 | Loss: 0.00001521
Iteration 149/1000 | Loss: 0.00001521
Iteration 150/1000 | Loss: 0.00001521
Iteration 151/1000 | Loss: 0.00001521
Iteration 152/1000 | Loss: 0.00001521
Iteration 153/1000 | Loss: 0.00001521
Iteration 154/1000 | Loss: 0.00001521
Iteration 155/1000 | Loss: 0.00001521
Iteration 156/1000 | Loss: 0.00001521
Iteration 157/1000 | Loss: 0.00001521
Iteration 158/1000 | Loss: 0.00001521
Iteration 159/1000 | Loss: 0.00001521
Iteration 160/1000 | Loss: 0.00001521
Iteration 161/1000 | Loss: 0.00001521
Iteration 162/1000 | Loss: 0.00001521
Iteration 163/1000 | Loss: 0.00001521
Iteration 164/1000 | Loss: 0.00001521
Iteration 165/1000 | Loss: 0.00001521
Iteration 166/1000 | Loss: 0.00001521
Iteration 167/1000 | Loss: 0.00001521
Iteration 168/1000 | Loss: 0.00001521
Iteration 169/1000 | Loss: 0.00001521
Iteration 170/1000 | Loss: 0.00001521
Iteration 171/1000 | Loss: 0.00001521
Iteration 172/1000 | Loss: 0.00001521
Iteration 173/1000 | Loss: 0.00001521
Iteration 174/1000 | Loss: 0.00001521
Iteration 175/1000 | Loss: 0.00001521
Iteration 176/1000 | Loss: 0.00001521
Iteration 177/1000 | Loss: 0.00001521
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.5213701772154309e-05, 1.5213701772154309e-05, 1.5213701772154309e-05, 1.5213701772154309e-05, 1.5213701772154309e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5213701772154309e-05

Optimization complete. Final v2v error: 3.3522350788116455 mm

Highest mean error: 3.8098456859588623 mm for frame 47

Lowest mean error: 3.038139581680298 mm for frame 116

Saving results

Total time: 35.2451376914978
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01054482
Iteration 2/25 | Loss: 0.00140682
Iteration 3/25 | Loss: 0.00096638
Iteration 4/25 | Loss: 0.00085485
Iteration 5/25 | Loss: 0.00082128
Iteration 6/25 | Loss: 0.00081192
Iteration 7/25 | Loss: 0.00080957
Iteration 8/25 | Loss: 0.00081307
Iteration 9/25 | Loss: 0.00080865
Iteration 10/25 | Loss: 0.00080715
Iteration 11/25 | Loss: 0.00080622
Iteration 12/25 | Loss: 0.00080991
Iteration 13/25 | Loss: 0.00080650
Iteration 14/25 | Loss: 0.00080882
Iteration 15/25 | Loss: 0.00080708
Iteration 16/25 | Loss: 0.00080544
Iteration 17/25 | Loss: 0.00080421
Iteration 18/25 | Loss: 0.00080341
Iteration 19/25 | Loss: 0.00080276
Iteration 20/25 | Loss: 0.00080255
Iteration 21/25 | Loss: 0.00080254
Iteration 22/25 | Loss: 0.00080254
Iteration 23/25 | Loss: 0.00080254
Iteration 24/25 | Loss: 0.00080254
Iteration 25/25 | Loss: 0.00080254

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56547320
Iteration 2/25 | Loss: 0.00029116
Iteration 3/25 | Loss: 0.00029115
Iteration 4/25 | Loss: 0.00029115
Iteration 5/25 | Loss: 0.00029115
Iteration 6/25 | Loss: 0.00029115
Iteration 7/25 | Loss: 0.00029115
Iteration 8/25 | Loss: 0.00029115
Iteration 9/25 | Loss: 0.00029115
Iteration 10/25 | Loss: 0.00029115
Iteration 11/25 | Loss: 0.00029115
Iteration 12/25 | Loss: 0.00029115
Iteration 13/25 | Loss: 0.00029115
Iteration 14/25 | Loss: 0.00029115
Iteration 15/25 | Loss: 0.00029115
Iteration 16/25 | Loss: 0.00029115
Iteration 17/25 | Loss: 0.00029115
Iteration 18/25 | Loss: 0.00029115
Iteration 19/25 | Loss: 0.00029115
Iteration 20/25 | Loss: 0.00029115
Iteration 21/25 | Loss: 0.00029115
Iteration 22/25 | Loss: 0.00029115
Iteration 23/25 | Loss: 0.00029115
Iteration 24/25 | Loss: 0.00029115
Iteration 25/25 | Loss: 0.00029115
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0002911483170464635, 0.0002911483170464635, 0.0002911483170464635, 0.0002911483170464635, 0.0002911483170464635]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002911483170464635

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029115
Iteration 2/1000 | Loss: 0.00002903
Iteration 3/1000 | Loss: 0.00001987
Iteration 4/1000 | Loss: 0.00001780
Iteration 5/1000 | Loss: 0.00001723
Iteration 6/1000 | Loss: 0.00001667
Iteration 7/1000 | Loss: 0.00001641
Iteration 8/1000 | Loss: 0.00001610
Iteration 9/1000 | Loss: 0.00001603
Iteration 10/1000 | Loss: 0.00001583
Iteration 11/1000 | Loss: 0.00001578
Iteration 12/1000 | Loss: 0.00001571
Iteration 13/1000 | Loss: 0.00001560
Iteration 14/1000 | Loss: 0.00001558
Iteration 15/1000 | Loss: 0.00001555
Iteration 16/1000 | Loss: 0.00001553
Iteration 17/1000 | Loss: 0.00001549
Iteration 18/1000 | Loss: 0.00001548
Iteration 19/1000 | Loss: 0.00001542
Iteration 20/1000 | Loss: 0.00001542
Iteration 21/1000 | Loss: 0.00001540
Iteration 22/1000 | Loss: 0.00001539
Iteration 23/1000 | Loss: 0.00001539
Iteration 24/1000 | Loss: 0.00001539
Iteration 25/1000 | Loss: 0.00001539
Iteration 26/1000 | Loss: 0.00001538
Iteration 27/1000 | Loss: 0.00001537
Iteration 28/1000 | Loss: 0.00001537
Iteration 29/1000 | Loss: 0.00001537
Iteration 30/1000 | Loss: 0.00001536
Iteration 31/1000 | Loss: 0.00001536
Iteration 32/1000 | Loss: 0.00001536
Iteration 33/1000 | Loss: 0.00001536
Iteration 34/1000 | Loss: 0.00001535
Iteration 35/1000 | Loss: 0.00001535
Iteration 36/1000 | Loss: 0.00001535
Iteration 37/1000 | Loss: 0.00001534
Iteration 38/1000 | Loss: 0.00001534
Iteration 39/1000 | Loss: 0.00001533
Iteration 40/1000 | Loss: 0.00001533
Iteration 41/1000 | Loss: 0.00001532
Iteration 42/1000 | Loss: 0.00001532
Iteration 43/1000 | Loss: 0.00001532
Iteration 44/1000 | Loss: 0.00001530
Iteration 45/1000 | Loss: 0.00001530
Iteration 46/1000 | Loss: 0.00001530
Iteration 47/1000 | Loss: 0.00001529
Iteration 48/1000 | Loss: 0.00001529
Iteration 49/1000 | Loss: 0.00001528
Iteration 50/1000 | Loss: 0.00001528
Iteration 51/1000 | Loss: 0.00001528
Iteration 52/1000 | Loss: 0.00001528
Iteration 53/1000 | Loss: 0.00001528
Iteration 54/1000 | Loss: 0.00001528
Iteration 55/1000 | Loss: 0.00001528
Iteration 56/1000 | Loss: 0.00001528
Iteration 57/1000 | Loss: 0.00001528
Iteration 58/1000 | Loss: 0.00001528
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 58. Stopping optimization.
Last 5 losses: [1.527989297755994e-05, 1.527989297755994e-05, 1.527989297755994e-05, 1.527989297755994e-05, 1.527989297755994e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.527989297755994e-05

Optimization complete. Final v2v error: 3.387824773788452 mm

Highest mean error: 3.8762152194976807 mm for frame 175

Lowest mean error: 3.1278865337371826 mm for frame 95

Saving results

Total time: 63.40498232841492
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00865341
Iteration 2/25 | Loss: 0.00182030
Iteration 3/25 | Loss: 0.00097782
Iteration 4/25 | Loss: 0.00085849
Iteration 5/25 | Loss: 0.00084128
Iteration 6/25 | Loss: 0.00083869
Iteration 7/25 | Loss: 0.00083810
Iteration 8/25 | Loss: 0.00083810
Iteration 9/25 | Loss: 0.00083810
Iteration 10/25 | Loss: 0.00083810
Iteration 11/25 | Loss: 0.00083810
Iteration 12/25 | Loss: 0.00083810
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008380982908420265, 0.0008380982908420265, 0.0008380982908420265, 0.0008380982908420265, 0.0008380982908420265]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008380982908420265

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39999509
Iteration 2/25 | Loss: 0.00051881
Iteration 3/25 | Loss: 0.00051881
Iteration 4/25 | Loss: 0.00051881
Iteration 5/25 | Loss: 0.00051881
Iteration 6/25 | Loss: 0.00051881
Iteration 7/25 | Loss: 0.00051881
Iteration 8/25 | Loss: 0.00051881
Iteration 9/25 | Loss: 0.00051881
Iteration 10/25 | Loss: 0.00051881
Iteration 11/25 | Loss: 0.00051881
Iteration 12/25 | Loss: 0.00051881
Iteration 13/25 | Loss: 0.00051881
Iteration 14/25 | Loss: 0.00051881
Iteration 15/25 | Loss: 0.00051881
Iteration 16/25 | Loss: 0.00051881
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0005188097711652517, 0.0005188097711652517, 0.0005188097711652517, 0.0005188097711652517, 0.0005188097711652517]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005188097711652517

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00051881
Iteration 2/1000 | Loss: 0.00003638
Iteration 3/1000 | Loss: 0.00002649
Iteration 4/1000 | Loss: 0.00002359
Iteration 5/1000 | Loss: 0.00002255
Iteration 6/1000 | Loss: 0.00002199
Iteration 7/1000 | Loss: 0.00002156
Iteration 8/1000 | Loss: 0.00002126
Iteration 9/1000 | Loss: 0.00002104
Iteration 10/1000 | Loss: 0.00002083
Iteration 11/1000 | Loss: 0.00002064
Iteration 12/1000 | Loss: 0.00002050
Iteration 13/1000 | Loss: 0.00002050
Iteration 14/1000 | Loss: 0.00002045
Iteration 15/1000 | Loss: 0.00002045
Iteration 16/1000 | Loss: 0.00002045
Iteration 17/1000 | Loss: 0.00002045
Iteration 18/1000 | Loss: 0.00002045
Iteration 19/1000 | Loss: 0.00002044
Iteration 20/1000 | Loss: 0.00002044
Iteration 21/1000 | Loss: 0.00002044
Iteration 22/1000 | Loss: 0.00002044
Iteration 23/1000 | Loss: 0.00002044
Iteration 24/1000 | Loss: 0.00002044
Iteration 25/1000 | Loss: 0.00002044
Iteration 26/1000 | Loss: 0.00002044
Iteration 27/1000 | Loss: 0.00002044
Iteration 28/1000 | Loss: 0.00002044
Iteration 29/1000 | Loss: 0.00002044
Iteration 30/1000 | Loss: 0.00002043
Iteration 31/1000 | Loss: 0.00002043
Iteration 32/1000 | Loss: 0.00002043
Iteration 33/1000 | Loss: 0.00002043
Iteration 34/1000 | Loss: 0.00002043
Iteration 35/1000 | Loss: 0.00002043
Iteration 36/1000 | Loss: 0.00002043
Iteration 37/1000 | Loss: 0.00002043
Iteration 38/1000 | Loss: 0.00002043
Iteration 39/1000 | Loss: 0.00002042
Iteration 40/1000 | Loss: 0.00002039
Iteration 41/1000 | Loss: 0.00002039
Iteration 42/1000 | Loss: 0.00002038
Iteration 43/1000 | Loss: 0.00002038
Iteration 44/1000 | Loss: 0.00002036
Iteration 45/1000 | Loss: 0.00002036
Iteration 46/1000 | Loss: 0.00002035
Iteration 47/1000 | Loss: 0.00002035
Iteration 48/1000 | Loss: 0.00002035
Iteration 49/1000 | Loss: 0.00002035
Iteration 50/1000 | Loss: 0.00002035
Iteration 51/1000 | Loss: 0.00002035
Iteration 52/1000 | Loss: 0.00002035
Iteration 53/1000 | Loss: 0.00002035
Iteration 54/1000 | Loss: 0.00002035
Iteration 55/1000 | Loss: 0.00002035
Iteration 56/1000 | Loss: 0.00002035
Iteration 57/1000 | Loss: 0.00002035
Iteration 58/1000 | Loss: 0.00002034
Iteration 59/1000 | Loss: 0.00002034
Iteration 60/1000 | Loss: 0.00002034
Iteration 61/1000 | Loss: 0.00002034
Iteration 62/1000 | Loss: 0.00002034
Iteration 63/1000 | Loss: 0.00002034
Iteration 64/1000 | Loss: 0.00002034
Iteration 65/1000 | Loss: 0.00002034
Iteration 66/1000 | Loss: 0.00002034
Iteration 67/1000 | Loss: 0.00002034
Iteration 68/1000 | Loss: 0.00002034
Iteration 69/1000 | Loss: 0.00002033
Iteration 70/1000 | Loss: 0.00002033
Iteration 71/1000 | Loss: 0.00002033
Iteration 72/1000 | Loss: 0.00002032
Iteration 73/1000 | Loss: 0.00002028
Iteration 74/1000 | Loss: 0.00002028
Iteration 75/1000 | Loss: 0.00002027
Iteration 76/1000 | Loss: 0.00002026
Iteration 77/1000 | Loss: 0.00002026
Iteration 78/1000 | Loss: 0.00002025
Iteration 79/1000 | Loss: 0.00002025
Iteration 80/1000 | Loss: 0.00002024
Iteration 81/1000 | Loss: 0.00002024
Iteration 82/1000 | Loss: 0.00002024
Iteration 83/1000 | Loss: 0.00002024
Iteration 84/1000 | Loss: 0.00002023
Iteration 85/1000 | Loss: 0.00002023
Iteration 86/1000 | Loss: 0.00002022
Iteration 87/1000 | Loss: 0.00002022
Iteration 88/1000 | Loss: 0.00002022
Iteration 89/1000 | Loss: 0.00002021
Iteration 90/1000 | Loss: 0.00002021
Iteration 91/1000 | Loss: 0.00002021
Iteration 92/1000 | Loss: 0.00002021
Iteration 93/1000 | Loss: 0.00002021
Iteration 94/1000 | Loss: 0.00002021
Iteration 95/1000 | Loss: 0.00002021
Iteration 96/1000 | Loss: 0.00002021
Iteration 97/1000 | Loss: 0.00002021
Iteration 98/1000 | Loss: 0.00002021
Iteration 99/1000 | Loss: 0.00002020
Iteration 100/1000 | Loss: 0.00002020
Iteration 101/1000 | Loss: 0.00002020
Iteration 102/1000 | Loss: 0.00002020
Iteration 103/1000 | Loss: 0.00002019
Iteration 104/1000 | Loss: 0.00002019
Iteration 105/1000 | Loss: 0.00002019
Iteration 106/1000 | Loss: 0.00002019
Iteration 107/1000 | Loss: 0.00002019
Iteration 108/1000 | Loss: 0.00002019
Iteration 109/1000 | Loss: 0.00002019
Iteration 110/1000 | Loss: 0.00002018
Iteration 111/1000 | Loss: 0.00002018
Iteration 112/1000 | Loss: 0.00002018
Iteration 113/1000 | Loss: 0.00002018
Iteration 114/1000 | Loss: 0.00002018
Iteration 115/1000 | Loss: 0.00002018
Iteration 116/1000 | Loss: 0.00002018
Iteration 117/1000 | Loss: 0.00002017
Iteration 118/1000 | Loss: 0.00002017
Iteration 119/1000 | Loss: 0.00002017
Iteration 120/1000 | Loss: 0.00002017
Iteration 121/1000 | Loss: 0.00002017
Iteration 122/1000 | Loss: 0.00002017
Iteration 123/1000 | Loss: 0.00002016
Iteration 124/1000 | Loss: 0.00002016
Iteration 125/1000 | Loss: 0.00002016
Iteration 126/1000 | Loss: 0.00002016
Iteration 127/1000 | Loss: 0.00002016
Iteration 128/1000 | Loss: 0.00002015
Iteration 129/1000 | Loss: 0.00002015
Iteration 130/1000 | Loss: 0.00002015
Iteration 131/1000 | Loss: 0.00002015
Iteration 132/1000 | Loss: 0.00002015
Iteration 133/1000 | Loss: 0.00002015
Iteration 134/1000 | Loss: 0.00002015
Iteration 135/1000 | Loss: 0.00002014
Iteration 136/1000 | Loss: 0.00002014
Iteration 137/1000 | Loss: 0.00002014
Iteration 138/1000 | Loss: 0.00002014
Iteration 139/1000 | Loss: 0.00002014
Iteration 140/1000 | Loss: 0.00002014
Iteration 141/1000 | Loss: 0.00002014
Iteration 142/1000 | Loss: 0.00002014
Iteration 143/1000 | Loss: 0.00002014
Iteration 144/1000 | Loss: 0.00002014
Iteration 145/1000 | Loss: 0.00002013
Iteration 146/1000 | Loss: 0.00002013
Iteration 147/1000 | Loss: 0.00002013
Iteration 148/1000 | Loss: 0.00002013
Iteration 149/1000 | Loss: 0.00002013
Iteration 150/1000 | Loss: 0.00002013
Iteration 151/1000 | Loss: 0.00002013
Iteration 152/1000 | Loss: 0.00002013
Iteration 153/1000 | Loss: 0.00002013
Iteration 154/1000 | Loss: 0.00002013
Iteration 155/1000 | Loss: 0.00002013
Iteration 156/1000 | Loss: 0.00002013
Iteration 157/1000 | Loss: 0.00002013
Iteration 158/1000 | Loss: 0.00002012
Iteration 159/1000 | Loss: 0.00002012
Iteration 160/1000 | Loss: 0.00002012
Iteration 161/1000 | Loss: 0.00002012
Iteration 162/1000 | Loss: 0.00002012
Iteration 163/1000 | Loss: 0.00002012
Iteration 164/1000 | Loss: 0.00002012
Iteration 165/1000 | Loss: 0.00002012
Iteration 166/1000 | Loss: 0.00002012
Iteration 167/1000 | Loss: 0.00002012
Iteration 168/1000 | Loss: 0.00002012
Iteration 169/1000 | Loss: 0.00002012
Iteration 170/1000 | Loss: 0.00002012
Iteration 171/1000 | Loss: 0.00002012
Iteration 172/1000 | Loss: 0.00002012
Iteration 173/1000 | Loss: 0.00002012
Iteration 174/1000 | Loss: 0.00002012
Iteration 175/1000 | Loss: 0.00002011
Iteration 176/1000 | Loss: 0.00002011
Iteration 177/1000 | Loss: 0.00002011
Iteration 178/1000 | Loss: 0.00002011
Iteration 179/1000 | Loss: 0.00002011
Iteration 180/1000 | Loss: 0.00002011
Iteration 181/1000 | Loss: 0.00002011
Iteration 182/1000 | Loss: 0.00002011
Iteration 183/1000 | Loss: 0.00002011
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 183. Stopping optimization.
Last 5 losses: [2.0110908735659905e-05, 2.0110908735659905e-05, 2.0110908735659905e-05, 2.0110908735659905e-05, 2.0110908735659905e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0110908735659905e-05

Optimization complete. Final v2v error: 3.7844371795654297 mm

Highest mean error: 4.958113670349121 mm for frame 51

Lowest mean error: 3.172905683517456 mm for frame 161

Saving results

Total time: 44.50937557220459
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01120399
Iteration 2/25 | Loss: 0.01120399
Iteration 3/25 | Loss: 0.01120398
Iteration 4/25 | Loss: 0.01120398
Iteration 5/25 | Loss: 0.01120397
Iteration 6/25 | Loss: 0.00241737
Iteration 7/25 | Loss: 0.00194232
Iteration 8/25 | Loss: 0.00172876
Iteration 9/25 | Loss: 0.00193975
Iteration 10/25 | Loss: 0.00149399
Iteration 11/25 | Loss: 0.00124244
Iteration 12/25 | Loss: 0.00111650
Iteration 13/25 | Loss: 0.00102010
Iteration 14/25 | Loss: 0.00095825
Iteration 15/25 | Loss: 0.00095591
Iteration 16/25 | Loss: 0.00092516
Iteration 17/25 | Loss: 0.00090890
Iteration 18/25 | Loss: 0.00088529
Iteration 19/25 | Loss: 0.00086921
Iteration 20/25 | Loss: 0.00085860
Iteration 21/25 | Loss: 0.00085569
Iteration 22/25 | Loss: 0.00085452
Iteration 23/25 | Loss: 0.00085416
Iteration 24/25 | Loss: 0.00085395
Iteration 25/25 | Loss: 0.00085386

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39870799
Iteration 2/25 | Loss: 0.00038192
Iteration 3/25 | Loss: 0.00038191
Iteration 4/25 | Loss: 0.00038191
Iteration 5/25 | Loss: 0.00038191
Iteration 6/25 | Loss: 0.00038191
Iteration 7/25 | Loss: 0.00038190
Iteration 8/25 | Loss: 0.00038190
Iteration 9/25 | Loss: 0.00038190
Iteration 10/25 | Loss: 0.00038190
Iteration 11/25 | Loss: 0.00038190
Iteration 12/25 | Loss: 0.00038190
Iteration 13/25 | Loss: 0.00038190
Iteration 14/25 | Loss: 0.00038190
Iteration 15/25 | Loss: 0.00038190
Iteration 16/25 | Loss: 0.00038190
Iteration 17/25 | Loss: 0.00038190
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003819042176473886, 0.0003819042176473886, 0.0003819042176473886, 0.0003819042176473886, 0.0003819042176473886]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003819042176473886

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038190
Iteration 2/1000 | Loss: 0.00002953
Iteration 3/1000 | Loss: 0.00002027
Iteration 4/1000 | Loss: 0.00001780
Iteration 5/1000 | Loss: 0.00001671
Iteration 6/1000 | Loss: 0.00001615
Iteration 7/1000 | Loss: 0.00001561
Iteration 8/1000 | Loss: 0.00001530
Iteration 9/1000 | Loss: 0.00001514
Iteration 10/1000 | Loss: 0.00001505
Iteration 11/1000 | Loss: 0.00001505
Iteration 12/1000 | Loss: 0.00001503
Iteration 13/1000 | Loss: 0.00001500
Iteration 14/1000 | Loss: 0.00001496
Iteration 15/1000 | Loss: 0.00001495
Iteration 16/1000 | Loss: 0.00001494
Iteration 17/1000 | Loss: 0.00001492
Iteration 18/1000 | Loss: 0.00001492
Iteration 19/1000 | Loss: 0.00001490
Iteration 20/1000 | Loss: 0.00001490
Iteration 21/1000 | Loss: 0.00001489
Iteration 22/1000 | Loss: 0.00001487
Iteration 23/1000 | Loss: 0.00001487
Iteration 24/1000 | Loss: 0.00001487
Iteration 25/1000 | Loss: 0.00001487
Iteration 26/1000 | Loss: 0.00001487
Iteration 27/1000 | Loss: 0.00001487
Iteration 28/1000 | Loss: 0.00001487
Iteration 29/1000 | Loss: 0.00001484
Iteration 30/1000 | Loss: 0.00001484
Iteration 31/1000 | Loss: 0.00001480
Iteration 32/1000 | Loss: 0.00001480
Iteration 33/1000 | Loss: 0.00001479
Iteration 34/1000 | Loss: 0.00001479
Iteration 35/1000 | Loss: 0.00001479
Iteration 36/1000 | Loss: 0.00001479
Iteration 37/1000 | Loss: 0.00001479
Iteration 38/1000 | Loss: 0.00001478
Iteration 39/1000 | Loss: 0.00001478
Iteration 40/1000 | Loss: 0.00001478
Iteration 41/1000 | Loss: 0.00001478
Iteration 42/1000 | Loss: 0.00001478
Iteration 43/1000 | Loss: 0.00001478
Iteration 44/1000 | Loss: 0.00001478
Iteration 45/1000 | Loss: 0.00001478
Iteration 46/1000 | Loss: 0.00001478
Iteration 47/1000 | Loss: 0.00001478
Iteration 48/1000 | Loss: 0.00001478
Iteration 49/1000 | Loss: 0.00001478
Iteration 50/1000 | Loss: 0.00001478
Iteration 51/1000 | Loss: 0.00001478
Iteration 52/1000 | Loss: 0.00001477
Iteration 53/1000 | Loss: 0.00001477
Iteration 54/1000 | Loss: 0.00001477
Iteration 55/1000 | Loss: 0.00001477
Iteration 56/1000 | Loss: 0.00001477
Iteration 57/1000 | Loss: 0.00001477
Iteration 58/1000 | Loss: 0.00001477
Iteration 59/1000 | Loss: 0.00001476
Iteration 60/1000 | Loss: 0.00001476
Iteration 61/1000 | Loss: 0.00001476
Iteration 62/1000 | Loss: 0.00001476
Iteration 63/1000 | Loss: 0.00001476
Iteration 64/1000 | Loss: 0.00001476
Iteration 65/1000 | Loss: 0.00001476
Iteration 66/1000 | Loss: 0.00001476
Iteration 67/1000 | Loss: 0.00001476
Iteration 68/1000 | Loss: 0.00001476
Iteration 69/1000 | Loss: 0.00001476
Iteration 70/1000 | Loss: 0.00001475
Iteration 71/1000 | Loss: 0.00001475
Iteration 72/1000 | Loss: 0.00001475
Iteration 73/1000 | Loss: 0.00001475
Iteration 74/1000 | Loss: 0.00001475
Iteration 75/1000 | Loss: 0.00001474
Iteration 76/1000 | Loss: 0.00001474
Iteration 77/1000 | Loss: 0.00001473
Iteration 78/1000 | Loss: 0.00001473
Iteration 79/1000 | Loss: 0.00001473
Iteration 80/1000 | Loss: 0.00001473
Iteration 81/1000 | Loss: 0.00001473
Iteration 82/1000 | Loss: 0.00001473
Iteration 83/1000 | Loss: 0.00001473
Iteration 84/1000 | Loss: 0.00001473
Iteration 85/1000 | Loss: 0.00001473
Iteration 86/1000 | Loss: 0.00001472
Iteration 87/1000 | Loss: 0.00001472
Iteration 88/1000 | Loss: 0.00001472
Iteration 89/1000 | Loss: 0.00001472
Iteration 90/1000 | Loss: 0.00001472
Iteration 91/1000 | Loss: 0.00001472
Iteration 92/1000 | Loss: 0.00001472
Iteration 93/1000 | Loss: 0.00001472
Iteration 94/1000 | Loss: 0.00001471
Iteration 95/1000 | Loss: 0.00001471
Iteration 96/1000 | Loss: 0.00001471
Iteration 97/1000 | Loss: 0.00001471
Iteration 98/1000 | Loss: 0.00001471
Iteration 99/1000 | Loss: 0.00001471
Iteration 100/1000 | Loss: 0.00001471
Iteration 101/1000 | Loss: 0.00001471
Iteration 102/1000 | Loss: 0.00001471
Iteration 103/1000 | Loss: 0.00001471
Iteration 104/1000 | Loss: 0.00001470
Iteration 105/1000 | Loss: 0.00001470
Iteration 106/1000 | Loss: 0.00001470
Iteration 107/1000 | Loss: 0.00001469
Iteration 108/1000 | Loss: 0.00001469
Iteration 109/1000 | Loss: 0.00001469
Iteration 110/1000 | Loss: 0.00001469
Iteration 111/1000 | Loss: 0.00001469
Iteration 112/1000 | Loss: 0.00001469
Iteration 113/1000 | Loss: 0.00001469
Iteration 114/1000 | Loss: 0.00001469
Iteration 115/1000 | Loss: 0.00001468
Iteration 116/1000 | Loss: 0.00001468
Iteration 117/1000 | Loss: 0.00001468
Iteration 118/1000 | Loss: 0.00001468
Iteration 119/1000 | Loss: 0.00001468
Iteration 120/1000 | Loss: 0.00001468
Iteration 121/1000 | Loss: 0.00001468
Iteration 122/1000 | Loss: 0.00001468
Iteration 123/1000 | Loss: 0.00001468
Iteration 124/1000 | Loss: 0.00001468
Iteration 125/1000 | Loss: 0.00001468
Iteration 126/1000 | Loss: 0.00001468
Iteration 127/1000 | Loss: 0.00001468
Iteration 128/1000 | Loss: 0.00001468
Iteration 129/1000 | Loss: 0.00001468
Iteration 130/1000 | Loss: 0.00001467
Iteration 131/1000 | Loss: 0.00001467
Iteration 132/1000 | Loss: 0.00001467
Iteration 133/1000 | Loss: 0.00001467
Iteration 134/1000 | Loss: 0.00001467
Iteration 135/1000 | Loss: 0.00001467
Iteration 136/1000 | Loss: 0.00001467
Iteration 137/1000 | Loss: 0.00001467
Iteration 138/1000 | Loss: 0.00001467
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [1.4673933037556708e-05, 1.4673933037556708e-05, 1.4673933037556708e-05, 1.4673933037556708e-05, 1.4673933037556708e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4673933037556708e-05

Optimization complete. Final v2v error: 3.2161765098571777 mm

Highest mean error: 4.042128086090088 mm for frame 74

Lowest mean error: 2.939117431640625 mm for frame 145

Saving results

Total time: 68.14835572242737
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00594121
Iteration 2/25 | Loss: 0.00103675
Iteration 3/25 | Loss: 0.00087687
Iteration 4/25 | Loss: 0.00085354
Iteration 5/25 | Loss: 0.00084849
Iteration 6/25 | Loss: 0.00084731
Iteration 7/25 | Loss: 0.00084731
Iteration 8/25 | Loss: 0.00084731
Iteration 9/25 | Loss: 0.00084731
Iteration 10/25 | Loss: 0.00084731
Iteration 11/25 | Loss: 0.00084731
Iteration 12/25 | Loss: 0.00084731
Iteration 13/25 | Loss: 0.00084731
Iteration 14/25 | Loss: 0.00084731
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0008473102934658527, 0.0008473102934658527, 0.0008473102934658527, 0.0008473102934658527, 0.0008473102934658527]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008473102934658527

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43556118
Iteration 2/25 | Loss: 0.00038903
Iteration 3/25 | Loss: 0.00038898
Iteration 4/25 | Loss: 0.00038898
Iteration 5/25 | Loss: 0.00038898
Iteration 6/25 | Loss: 0.00038898
Iteration 7/25 | Loss: 0.00038898
Iteration 8/25 | Loss: 0.00038898
Iteration 9/25 | Loss: 0.00038898
Iteration 10/25 | Loss: 0.00038898
Iteration 11/25 | Loss: 0.00038898
Iteration 12/25 | Loss: 0.00038898
Iteration 13/25 | Loss: 0.00038898
Iteration 14/25 | Loss: 0.00038898
Iteration 15/25 | Loss: 0.00038898
Iteration 16/25 | Loss: 0.00038898
Iteration 17/25 | Loss: 0.00038898
Iteration 18/25 | Loss: 0.00038898
Iteration 19/25 | Loss: 0.00038898
Iteration 20/25 | Loss: 0.00038898
Iteration 21/25 | Loss: 0.00038898
Iteration 22/25 | Loss: 0.00038898
Iteration 23/25 | Loss: 0.00038898
Iteration 24/25 | Loss: 0.00038898
Iteration 25/25 | Loss: 0.00038898

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038898
Iteration 2/1000 | Loss: 0.00002872
Iteration 3/1000 | Loss: 0.00002010
Iteration 4/1000 | Loss: 0.00001809
Iteration 5/1000 | Loss: 0.00001698
Iteration 6/1000 | Loss: 0.00001622
Iteration 7/1000 | Loss: 0.00001568
Iteration 8/1000 | Loss: 0.00001538
Iteration 9/1000 | Loss: 0.00001529
Iteration 10/1000 | Loss: 0.00001520
Iteration 11/1000 | Loss: 0.00001518
Iteration 12/1000 | Loss: 0.00001517
Iteration 13/1000 | Loss: 0.00001517
Iteration 14/1000 | Loss: 0.00001516
Iteration 15/1000 | Loss: 0.00001515
Iteration 16/1000 | Loss: 0.00001515
Iteration 17/1000 | Loss: 0.00001514
Iteration 18/1000 | Loss: 0.00001514
Iteration 19/1000 | Loss: 0.00001513
Iteration 20/1000 | Loss: 0.00001513
Iteration 21/1000 | Loss: 0.00001512
Iteration 22/1000 | Loss: 0.00001512
Iteration 23/1000 | Loss: 0.00001512
Iteration 24/1000 | Loss: 0.00001511
Iteration 25/1000 | Loss: 0.00001510
Iteration 26/1000 | Loss: 0.00001510
Iteration 27/1000 | Loss: 0.00001510
Iteration 28/1000 | Loss: 0.00001509
Iteration 29/1000 | Loss: 0.00001508
Iteration 30/1000 | Loss: 0.00001508
Iteration 31/1000 | Loss: 0.00001507
Iteration 32/1000 | Loss: 0.00001507
Iteration 33/1000 | Loss: 0.00001507
Iteration 34/1000 | Loss: 0.00001507
Iteration 35/1000 | Loss: 0.00001507
Iteration 36/1000 | Loss: 0.00001507
Iteration 37/1000 | Loss: 0.00001507
Iteration 38/1000 | Loss: 0.00001507
Iteration 39/1000 | Loss: 0.00001507
Iteration 40/1000 | Loss: 0.00001507
Iteration 41/1000 | Loss: 0.00001507
Iteration 42/1000 | Loss: 0.00001506
Iteration 43/1000 | Loss: 0.00001506
Iteration 44/1000 | Loss: 0.00001506
Iteration 45/1000 | Loss: 0.00001506
Iteration 46/1000 | Loss: 0.00001506
Iteration 47/1000 | Loss: 0.00001506
Iteration 48/1000 | Loss: 0.00001506
Iteration 49/1000 | Loss: 0.00001506
Iteration 50/1000 | Loss: 0.00001506
Iteration 51/1000 | Loss: 0.00001505
Iteration 52/1000 | Loss: 0.00001505
Iteration 53/1000 | Loss: 0.00001505
Iteration 54/1000 | Loss: 0.00001505
Iteration 55/1000 | Loss: 0.00001505
Iteration 56/1000 | Loss: 0.00001504
Iteration 57/1000 | Loss: 0.00001504
Iteration 58/1000 | Loss: 0.00001504
Iteration 59/1000 | Loss: 0.00001504
Iteration 60/1000 | Loss: 0.00001504
Iteration 61/1000 | Loss: 0.00001504
Iteration 62/1000 | Loss: 0.00001504
Iteration 63/1000 | Loss: 0.00001504
Iteration 64/1000 | Loss: 0.00001504
Iteration 65/1000 | Loss: 0.00001503
Iteration 66/1000 | Loss: 0.00001503
Iteration 67/1000 | Loss: 0.00001503
Iteration 68/1000 | Loss: 0.00001502
Iteration 69/1000 | Loss: 0.00001502
Iteration 70/1000 | Loss: 0.00001501
Iteration 71/1000 | Loss: 0.00001501
Iteration 72/1000 | Loss: 0.00001500
Iteration 73/1000 | Loss: 0.00001500
Iteration 74/1000 | Loss: 0.00001500
Iteration 75/1000 | Loss: 0.00001500
Iteration 76/1000 | Loss: 0.00001500
Iteration 77/1000 | Loss: 0.00001499
Iteration 78/1000 | Loss: 0.00001499
Iteration 79/1000 | Loss: 0.00001499
Iteration 80/1000 | Loss: 0.00001499
Iteration 81/1000 | Loss: 0.00001499
Iteration 82/1000 | Loss: 0.00001499
Iteration 83/1000 | Loss: 0.00001499
Iteration 84/1000 | Loss: 0.00001499
Iteration 85/1000 | Loss: 0.00001499
Iteration 86/1000 | Loss: 0.00001499
Iteration 87/1000 | Loss: 0.00001499
Iteration 88/1000 | Loss: 0.00001499
Iteration 89/1000 | Loss: 0.00001499
Iteration 90/1000 | Loss: 0.00001499
Iteration 91/1000 | Loss: 0.00001499
Iteration 92/1000 | Loss: 0.00001499
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [1.4988742805144284e-05, 1.4988742805144284e-05, 1.4988742805144284e-05, 1.4988742805144284e-05, 1.4988742805144284e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4988742805144284e-05

Optimization complete. Final v2v error: 3.3457393646240234 mm

Highest mean error: 3.561210870742798 mm for frame 183

Lowest mean error: 3.1730597019195557 mm for frame 175

Saving results

Total time: 28.867375135421753
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00874325
Iteration 2/25 | Loss: 0.00105777
Iteration 3/25 | Loss: 0.00091295
Iteration 4/25 | Loss: 0.00087130
Iteration 5/25 | Loss: 0.00085002
Iteration 6/25 | Loss: 0.00084376
Iteration 7/25 | Loss: 0.00084093
Iteration 8/25 | Loss: 0.00083952
Iteration 9/25 | Loss: 0.00083940
Iteration 10/25 | Loss: 0.00083940
Iteration 11/25 | Loss: 0.00083940
Iteration 12/25 | Loss: 0.00083940
Iteration 13/25 | Loss: 0.00083940
Iteration 14/25 | Loss: 0.00083940
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0008393987664021552, 0.0008393987664021552, 0.0008393987664021552, 0.0008393987664021552, 0.0008393987664021552]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008393987664021552

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67215526
Iteration 2/25 | Loss: 0.00059464
Iteration 3/25 | Loss: 0.00059464
Iteration 4/25 | Loss: 0.00059464
Iteration 5/25 | Loss: 0.00059464
Iteration 6/25 | Loss: 0.00059464
Iteration 7/25 | Loss: 0.00059464
Iteration 8/25 | Loss: 0.00059464
Iteration 9/25 | Loss: 0.00059464
Iteration 10/25 | Loss: 0.00059464
Iteration 11/25 | Loss: 0.00059464
Iteration 12/25 | Loss: 0.00059464
Iteration 13/25 | Loss: 0.00059464
Iteration 14/25 | Loss: 0.00059464
Iteration 15/25 | Loss: 0.00059464
Iteration 16/25 | Loss: 0.00059464
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0005946413148194551, 0.0005946413148194551, 0.0005946413148194551, 0.0005946413148194551, 0.0005946413148194551]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005946413148194551

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059464
Iteration 2/1000 | Loss: 0.00005260
Iteration 3/1000 | Loss: 0.00003367
Iteration 4/1000 | Loss: 0.00002750
Iteration 5/1000 | Loss: 0.00002488
Iteration 6/1000 | Loss: 0.00002380
Iteration 7/1000 | Loss: 0.00002308
Iteration 8/1000 | Loss: 0.00002247
Iteration 9/1000 | Loss: 0.00002190
Iteration 10/1000 | Loss: 0.00002147
Iteration 11/1000 | Loss: 0.00002117
Iteration 12/1000 | Loss: 0.00002102
Iteration 13/1000 | Loss: 0.00002096
Iteration 14/1000 | Loss: 0.00002087
Iteration 15/1000 | Loss: 0.00002085
Iteration 16/1000 | Loss: 0.00002084
Iteration 17/1000 | Loss: 0.00002084
Iteration 18/1000 | Loss: 0.00002084
Iteration 19/1000 | Loss: 0.00002081
Iteration 20/1000 | Loss: 0.00002081
Iteration 21/1000 | Loss: 0.00002079
Iteration 22/1000 | Loss: 0.00002079
Iteration 23/1000 | Loss: 0.00002076
Iteration 24/1000 | Loss: 0.00002076
Iteration 25/1000 | Loss: 0.00002073
Iteration 26/1000 | Loss: 0.00002072
Iteration 27/1000 | Loss: 0.00002071
Iteration 28/1000 | Loss: 0.00002071
Iteration 29/1000 | Loss: 0.00002070
Iteration 30/1000 | Loss: 0.00002070
Iteration 31/1000 | Loss: 0.00002069
Iteration 32/1000 | Loss: 0.00002069
Iteration 33/1000 | Loss: 0.00002069
Iteration 34/1000 | Loss: 0.00002069
Iteration 35/1000 | Loss: 0.00002069
Iteration 36/1000 | Loss: 0.00002068
Iteration 37/1000 | Loss: 0.00002068
Iteration 38/1000 | Loss: 0.00002068
Iteration 39/1000 | Loss: 0.00002067
Iteration 40/1000 | Loss: 0.00002067
Iteration 41/1000 | Loss: 0.00002066
Iteration 42/1000 | Loss: 0.00002066
Iteration 43/1000 | Loss: 0.00002066
Iteration 44/1000 | Loss: 0.00002065
Iteration 45/1000 | Loss: 0.00002065
Iteration 46/1000 | Loss: 0.00002065
Iteration 47/1000 | Loss: 0.00002065
Iteration 48/1000 | Loss: 0.00002065
Iteration 49/1000 | Loss: 0.00002065
Iteration 50/1000 | Loss: 0.00002065
Iteration 51/1000 | Loss: 0.00002064
Iteration 52/1000 | Loss: 0.00002064
Iteration 53/1000 | Loss: 0.00002064
Iteration 54/1000 | Loss: 0.00002063
Iteration 55/1000 | Loss: 0.00002063
Iteration 56/1000 | Loss: 0.00002063
Iteration 57/1000 | Loss: 0.00002063
Iteration 58/1000 | Loss: 0.00002063
Iteration 59/1000 | Loss: 0.00002063
Iteration 60/1000 | Loss: 0.00002062
Iteration 61/1000 | Loss: 0.00002062
Iteration 62/1000 | Loss: 0.00002062
Iteration 63/1000 | Loss: 0.00002062
Iteration 64/1000 | Loss: 0.00002061
Iteration 65/1000 | Loss: 0.00002061
Iteration 66/1000 | Loss: 0.00002060
Iteration 67/1000 | Loss: 0.00002060
Iteration 68/1000 | Loss: 0.00002060
Iteration 69/1000 | Loss: 0.00002060
Iteration 70/1000 | Loss: 0.00002059
Iteration 71/1000 | Loss: 0.00002059
Iteration 72/1000 | Loss: 0.00002059
Iteration 73/1000 | Loss: 0.00002059
Iteration 74/1000 | Loss: 0.00002059
Iteration 75/1000 | Loss: 0.00002059
Iteration 76/1000 | Loss: 0.00002058
Iteration 77/1000 | Loss: 0.00002058
Iteration 78/1000 | Loss: 0.00002058
Iteration 79/1000 | Loss: 0.00002058
Iteration 80/1000 | Loss: 0.00002058
Iteration 81/1000 | Loss: 0.00002058
Iteration 82/1000 | Loss: 0.00002058
Iteration 83/1000 | Loss: 0.00002058
Iteration 84/1000 | Loss: 0.00002057
Iteration 85/1000 | Loss: 0.00002057
Iteration 86/1000 | Loss: 0.00002057
Iteration 87/1000 | Loss: 0.00002057
Iteration 88/1000 | Loss: 0.00002057
Iteration 89/1000 | Loss: 0.00002057
Iteration 90/1000 | Loss: 0.00002057
Iteration 91/1000 | Loss: 0.00002056
Iteration 92/1000 | Loss: 0.00002056
Iteration 93/1000 | Loss: 0.00002056
Iteration 94/1000 | Loss: 0.00002056
Iteration 95/1000 | Loss: 0.00002056
Iteration 96/1000 | Loss: 0.00002056
Iteration 97/1000 | Loss: 0.00002055
Iteration 98/1000 | Loss: 0.00002055
Iteration 99/1000 | Loss: 0.00002055
Iteration 100/1000 | Loss: 0.00002055
Iteration 101/1000 | Loss: 0.00002055
Iteration 102/1000 | Loss: 0.00002054
Iteration 103/1000 | Loss: 0.00002054
Iteration 104/1000 | Loss: 0.00002054
Iteration 105/1000 | Loss: 0.00002054
Iteration 106/1000 | Loss: 0.00002054
Iteration 107/1000 | Loss: 0.00002054
Iteration 108/1000 | Loss: 0.00002054
Iteration 109/1000 | Loss: 0.00002054
Iteration 110/1000 | Loss: 0.00002053
Iteration 111/1000 | Loss: 0.00002053
Iteration 112/1000 | Loss: 0.00002053
Iteration 113/1000 | Loss: 0.00002053
Iteration 114/1000 | Loss: 0.00002053
Iteration 115/1000 | Loss: 0.00002053
Iteration 116/1000 | Loss: 0.00002053
Iteration 117/1000 | Loss: 0.00002053
Iteration 118/1000 | Loss: 0.00002053
Iteration 119/1000 | Loss: 0.00002053
Iteration 120/1000 | Loss: 0.00002053
Iteration 121/1000 | Loss: 0.00002053
Iteration 122/1000 | Loss: 0.00002052
Iteration 123/1000 | Loss: 0.00002052
Iteration 124/1000 | Loss: 0.00002052
Iteration 125/1000 | Loss: 0.00002052
Iteration 126/1000 | Loss: 0.00002052
Iteration 127/1000 | Loss: 0.00002052
Iteration 128/1000 | Loss: 0.00002052
Iteration 129/1000 | Loss: 0.00002051
Iteration 130/1000 | Loss: 0.00002051
Iteration 131/1000 | Loss: 0.00002051
Iteration 132/1000 | Loss: 0.00002051
Iteration 133/1000 | Loss: 0.00002051
Iteration 134/1000 | Loss: 0.00002051
Iteration 135/1000 | Loss: 0.00002051
Iteration 136/1000 | Loss: 0.00002051
Iteration 137/1000 | Loss: 0.00002051
Iteration 138/1000 | Loss: 0.00002050
Iteration 139/1000 | Loss: 0.00002050
Iteration 140/1000 | Loss: 0.00002050
Iteration 141/1000 | Loss: 0.00002050
Iteration 142/1000 | Loss: 0.00002050
Iteration 143/1000 | Loss: 0.00002050
Iteration 144/1000 | Loss: 0.00002050
Iteration 145/1000 | Loss: 0.00002049
Iteration 146/1000 | Loss: 0.00002049
Iteration 147/1000 | Loss: 0.00002049
Iteration 148/1000 | Loss: 0.00002049
Iteration 149/1000 | Loss: 0.00002049
Iteration 150/1000 | Loss: 0.00002049
Iteration 151/1000 | Loss: 0.00002049
Iteration 152/1000 | Loss: 0.00002049
Iteration 153/1000 | Loss: 0.00002049
Iteration 154/1000 | Loss: 0.00002049
Iteration 155/1000 | Loss: 0.00002048
Iteration 156/1000 | Loss: 0.00002048
Iteration 157/1000 | Loss: 0.00002048
Iteration 158/1000 | Loss: 0.00002048
Iteration 159/1000 | Loss: 0.00002048
Iteration 160/1000 | Loss: 0.00002048
Iteration 161/1000 | Loss: 0.00002048
Iteration 162/1000 | Loss: 0.00002048
Iteration 163/1000 | Loss: 0.00002048
Iteration 164/1000 | Loss: 0.00002048
Iteration 165/1000 | Loss: 0.00002048
Iteration 166/1000 | Loss: 0.00002048
Iteration 167/1000 | Loss: 0.00002048
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 167. Stopping optimization.
Last 5 losses: [2.0482430045376532e-05, 2.0482430045376532e-05, 2.0482430045376532e-05, 2.0482430045376532e-05, 2.0482430045376532e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0482430045376532e-05

Optimization complete. Final v2v error: 3.694943904876709 mm

Highest mean error: 5.77812385559082 mm for frame 136

Lowest mean error: 2.813291549682617 mm for frame 43

Saving results

Total time: 41.90807890892029
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01196512
Iteration 2/25 | Loss: 0.00134610
Iteration 3/25 | Loss: 0.00099679
Iteration 4/25 | Loss: 0.00096987
Iteration 5/25 | Loss: 0.00095360
Iteration 6/25 | Loss: 0.00094372
Iteration 7/25 | Loss: 0.00094358
Iteration 8/25 | Loss: 0.00094356
Iteration 9/25 | Loss: 0.00094356
Iteration 10/25 | Loss: 0.00094356
Iteration 11/25 | Loss: 0.00094356
Iteration 12/25 | Loss: 0.00094355
Iteration 13/25 | Loss: 0.00094355
Iteration 14/25 | Loss: 0.00094355
Iteration 15/25 | Loss: 0.00094355
Iteration 16/25 | Loss: 0.00094355
Iteration 17/25 | Loss: 0.00094355
Iteration 18/25 | Loss: 0.00094355
Iteration 19/25 | Loss: 0.00094355
Iteration 20/25 | Loss: 0.00094355
Iteration 21/25 | Loss: 0.00094355
Iteration 22/25 | Loss: 0.00094355
Iteration 23/25 | Loss: 0.00094355
Iteration 24/25 | Loss: 0.00094355
Iteration 25/25 | Loss: 0.00094355

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.84715652
Iteration 2/25 | Loss: 0.00054026
Iteration 3/25 | Loss: 0.00047392
Iteration 4/25 | Loss: 0.00047392
Iteration 5/25 | Loss: 0.00047392
Iteration 6/25 | Loss: 0.00047391
Iteration 7/25 | Loss: 0.00047391
Iteration 8/25 | Loss: 0.00047391
Iteration 9/25 | Loss: 0.00047391
Iteration 10/25 | Loss: 0.00047391
Iteration 11/25 | Loss: 0.00047391
Iteration 12/25 | Loss: 0.00047391
Iteration 13/25 | Loss: 0.00047391
Iteration 14/25 | Loss: 0.00047391
Iteration 15/25 | Loss: 0.00047391
Iteration 16/25 | Loss: 0.00047391
Iteration 17/25 | Loss: 0.00047391
Iteration 18/25 | Loss: 0.00047391
Iteration 19/25 | Loss: 0.00047391
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0004739142314065248, 0.0004739142314065248, 0.0004739142314065248, 0.0004739142314065248, 0.0004739142314065248]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004739142314065248

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047391
Iteration 2/1000 | Loss: 0.00004594
Iteration 3/1000 | Loss: 0.00003562
Iteration 4/1000 | Loss: 0.00011989
Iteration 5/1000 | Loss: 0.00003203
Iteration 6/1000 | Loss: 0.00003116
Iteration 7/1000 | Loss: 0.00003059
Iteration 8/1000 | Loss: 0.00003009
Iteration 9/1000 | Loss: 0.00002970
Iteration 10/1000 | Loss: 0.00002948
Iteration 11/1000 | Loss: 0.00002940
Iteration 12/1000 | Loss: 0.00002940
Iteration 13/1000 | Loss: 0.00002936
Iteration 14/1000 | Loss: 0.00002935
Iteration 15/1000 | Loss: 0.00002931
Iteration 16/1000 | Loss: 0.00002931
Iteration 17/1000 | Loss: 0.00002927
Iteration 18/1000 | Loss: 0.00002926
Iteration 19/1000 | Loss: 0.00002924
Iteration 20/1000 | Loss: 0.00002920
Iteration 21/1000 | Loss: 0.00002917
Iteration 22/1000 | Loss: 0.00002917
Iteration 23/1000 | Loss: 0.00002917
Iteration 24/1000 | Loss: 0.00002917
Iteration 25/1000 | Loss: 0.00002917
Iteration 26/1000 | Loss: 0.00002917
Iteration 27/1000 | Loss: 0.00002917
Iteration 28/1000 | Loss: 0.00002917
Iteration 29/1000 | Loss: 0.00002916
Iteration 30/1000 | Loss: 0.00002916
Iteration 31/1000 | Loss: 0.00002916
Iteration 32/1000 | Loss: 0.00002916
Iteration 33/1000 | Loss: 0.00002914
Iteration 34/1000 | Loss: 0.00002914
Iteration 35/1000 | Loss: 0.00002914
Iteration 36/1000 | Loss: 0.00002914
Iteration 37/1000 | Loss: 0.00002913
Iteration 38/1000 | Loss: 0.00002913
Iteration 39/1000 | Loss: 0.00002913
Iteration 40/1000 | Loss: 0.00002913
Iteration 41/1000 | Loss: 0.00002913
Iteration 42/1000 | Loss: 0.00002912
Iteration 43/1000 | Loss: 0.00002912
Iteration 44/1000 | Loss: 0.00002912
Iteration 45/1000 | Loss: 0.00002912
Iteration 46/1000 | Loss: 0.00002912
Iteration 47/1000 | Loss: 0.00002912
Iteration 48/1000 | Loss: 0.00002912
Iteration 49/1000 | Loss: 0.00002912
Iteration 50/1000 | Loss: 0.00002912
Iteration 51/1000 | Loss: 0.00002912
Iteration 52/1000 | Loss: 0.00002912
Iteration 53/1000 | Loss: 0.00002912
Iteration 54/1000 | Loss: 0.00002912
Iteration 55/1000 | Loss: 0.00002912
Iteration 56/1000 | Loss: 0.00002912
Iteration 57/1000 | Loss: 0.00002912
Iteration 58/1000 | Loss: 0.00002912
Iteration 59/1000 | Loss: 0.00002912
Iteration 60/1000 | Loss: 0.00002912
Iteration 61/1000 | Loss: 0.00002912
Iteration 62/1000 | Loss: 0.00002912
Iteration 63/1000 | Loss: 0.00002912
Iteration 64/1000 | Loss: 0.00002912
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 64. Stopping optimization.
Last 5 losses: [2.911527917603962e-05, 2.911527917603962e-05, 2.911527917603962e-05, 2.911527917603962e-05, 2.911527917603962e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.911527917603962e-05

Optimization complete. Final v2v error: 4.582864761352539 mm

Highest mean error: 5.209886074066162 mm for frame 104

Lowest mean error: 3.955968141555786 mm for frame 1

Saving results

Total time: 32.877882957458496
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00555150
Iteration 2/25 | Loss: 0.00091654
Iteration 3/25 | Loss: 0.00079803
Iteration 4/25 | Loss: 0.00077885
Iteration 5/25 | Loss: 0.00077259
Iteration 6/25 | Loss: 0.00077094
Iteration 7/25 | Loss: 0.00077036
Iteration 8/25 | Loss: 0.00077033
Iteration 9/25 | Loss: 0.00077033
Iteration 10/25 | Loss: 0.00077033
Iteration 11/25 | Loss: 0.00077033
Iteration 12/25 | Loss: 0.00077033
Iteration 13/25 | Loss: 0.00077033
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007703310693614185, 0.0007703310693614185, 0.0007703310693614185, 0.0007703310693614185, 0.0007703310693614185]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007703310693614185

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.76086426
Iteration 2/25 | Loss: 0.00030898
Iteration 3/25 | Loss: 0.00030897
Iteration 4/25 | Loss: 0.00030896
Iteration 5/25 | Loss: 0.00030896
Iteration 6/25 | Loss: 0.00030896
Iteration 7/25 | Loss: 0.00030896
Iteration 8/25 | Loss: 0.00030896
Iteration 9/25 | Loss: 0.00030896
Iteration 10/25 | Loss: 0.00030896
Iteration 11/25 | Loss: 0.00030896
Iteration 12/25 | Loss: 0.00030896
Iteration 13/25 | Loss: 0.00030896
Iteration 14/25 | Loss: 0.00030896
Iteration 15/25 | Loss: 0.00030896
Iteration 16/25 | Loss: 0.00030896
Iteration 17/25 | Loss: 0.00030896
Iteration 18/25 | Loss: 0.00030896
Iteration 19/25 | Loss: 0.00030896
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003089625097345561, 0.0003089625097345561, 0.0003089625097345561, 0.0003089625097345561, 0.0003089625097345561]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003089625097345561

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030896
Iteration 2/1000 | Loss: 0.00002464
Iteration 3/1000 | Loss: 0.00001955
Iteration 4/1000 | Loss: 0.00001799
Iteration 5/1000 | Loss: 0.00001726
Iteration 6/1000 | Loss: 0.00001672
Iteration 7/1000 | Loss: 0.00001623
Iteration 8/1000 | Loss: 0.00001608
Iteration 9/1000 | Loss: 0.00001602
Iteration 10/1000 | Loss: 0.00001596
Iteration 11/1000 | Loss: 0.00001593
Iteration 12/1000 | Loss: 0.00001592
Iteration 13/1000 | Loss: 0.00001592
Iteration 14/1000 | Loss: 0.00001591
Iteration 15/1000 | Loss: 0.00001591
Iteration 16/1000 | Loss: 0.00001591
Iteration 17/1000 | Loss: 0.00001590
Iteration 18/1000 | Loss: 0.00001590
Iteration 19/1000 | Loss: 0.00001589
Iteration 20/1000 | Loss: 0.00001589
Iteration 21/1000 | Loss: 0.00001588
Iteration 22/1000 | Loss: 0.00001588
Iteration 23/1000 | Loss: 0.00001588
Iteration 24/1000 | Loss: 0.00001588
Iteration 25/1000 | Loss: 0.00001587
Iteration 26/1000 | Loss: 0.00001587
Iteration 27/1000 | Loss: 0.00001587
Iteration 28/1000 | Loss: 0.00001587
Iteration 29/1000 | Loss: 0.00001586
Iteration 30/1000 | Loss: 0.00001586
Iteration 31/1000 | Loss: 0.00001586
Iteration 32/1000 | Loss: 0.00001585
Iteration 33/1000 | Loss: 0.00001585
Iteration 34/1000 | Loss: 0.00001585
Iteration 35/1000 | Loss: 0.00001584
Iteration 36/1000 | Loss: 0.00001584
Iteration 37/1000 | Loss: 0.00001584
Iteration 38/1000 | Loss: 0.00001584
Iteration 39/1000 | Loss: 0.00001584
Iteration 40/1000 | Loss: 0.00001584
Iteration 41/1000 | Loss: 0.00001584
Iteration 42/1000 | Loss: 0.00001583
Iteration 43/1000 | Loss: 0.00001583
Iteration 44/1000 | Loss: 0.00001583
Iteration 45/1000 | Loss: 0.00001583
Iteration 46/1000 | Loss: 0.00001582
Iteration 47/1000 | Loss: 0.00001582
Iteration 48/1000 | Loss: 0.00001582
Iteration 49/1000 | Loss: 0.00001582
Iteration 50/1000 | Loss: 0.00001582
Iteration 51/1000 | Loss: 0.00001582
Iteration 52/1000 | Loss: 0.00001582
Iteration 53/1000 | Loss: 0.00001582
Iteration 54/1000 | Loss: 0.00001581
Iteration 55/1000 | Loss: 0.00001581
Iteration 56/1000 | Loss: 0.00001581
Iteration 57/1000 | Loss: 0.00001580
Iteration 58/1000 | Loss: 0.00001580
Iteration 59/1000 | Loss: 0.00001580
Iteration 60/1000 | Loss: 0.00001580
Iteration 61/1000 | Loss: 0.00001579
Iteration 62/1000 | Loss: 0.00001579
Iteration 63/1000 | Loss: 0.00001579
Iteration 64/1000 | Loss: 0.00001579
Iteration 65/1000 | Loss: 0.00001579
Iteration 66/1000 | Loss: 0.00001579
Iteration 67/1000 | Loss: 0.00001578
Iteration 68/1000 | Loss: 0.00001578
Iteration 69/1000 | Loss: 0.00001578
Iteration 70/1000 | Loss: 0.00001578
Iteration 71/1000 | Loss: 0.00001577
Iteration 72/1000 | Loss: 0.00001577
Iteration 73/1000 | Loss: 0.00001577
Iteration 74/1000 | Loss: 0.00001577
Iteration 75/1000 | Loss: 0.00001577
Iteration 76/1000 | Loss: 0.00001577
Iteration 77/1000 | Loss: 0.00001577
Iteration 78/1000 | Loss: 0.00001577
Iteration 79/1000 | Loss: 0.00001577
Iteration 80/1000 | Loss: 0.00001577
Iteration 81/1000 | Loss: 0.00001577
Iteration 82/1000 | Loss: 0.00001577
Iteration 83/1000 | Loss: 0.00001577
Iteration 84/1000 | Loss: 0.00001577
Iteration 85/1000 | Loss: 0.00001576
Iteration 86/1000 | Loss: 0.00001576
Iteration 87/1000 | Loss: 0.00001576
Iteration 88/1000 | Loss: 0.00001576
Iteration 89/1000 | Loss: 0.00001576
Iteration 90/1000 | Loss: 0.00001576
Iteration 91/1000 | Loss: 0.00001576
Iteration 92/1000 | Loss: 0.00001576
Iteration 93/1000 | Loss: 0.00001576
Iteration 94/1000 | Loss: 0.00001576
Iteration 95/1000 | Loss: 0.00001576
Iteration 96/1000 | Loss: 0.00001575
Iteration 97/1000 | Loss: 0.00001575
Iteration 98/1000 | Loss: 0.00001575
Iteration 99/1000 | Loss: 0.00001575
Iteration 100/1000 | Loss: 0.00001575
Iteration 101/1000 | Loss: 0.00001575
Iteration 102/1000 | Loss: 0.00001575
Iteration 103/1000 | Loss: 0.00001575
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.5754174455651082e-05, 1.5754174455651082e-05, 1.5754174455651082e-05, 1.5754174455651082e-05, 1.5754174455651082e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5754174455651082e-05

Optimization complete. Final v2v error: 3.362957000732422 mm

Highest mean error: 3.7999088764190674 mm for frame 71

Lowest mean error: 3.074263095855713 mm for frame 43

Saving results

Total time: 29.663891077041626
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00965995
Iteration 2/25 | Loss: 0.00164893
Iteration 3/25 | Loss: 0.00110763
Iteration 4/25 | Loss: 0.00101112
Iteration 5/25 | Loss: 0.00097915
Iteration 6/25 | Loss: 0.00097226
Iteration 7/25 | Loss: 0.00096949
Iteration 8/25 | Loss: 0.00100732
Iteration 9/25 | Loss: 0.00099917
Iteration 10/25 | Loss: 0.00101561
Iteration 11/25 | Loss: 0.00100443
Iteration 12/25 | Loss: 0.00095411
Iteration 13/25 | Loss: 0.00094309
Iteration 14/25 | Loss: 0.00094486
Iteration 15/25 | Loss: 0.00094172
Iteration 16/25 | Loss: 0.00095037
Iteration 17/25 | Loss: 0.00092992
Iteration 18/25 | Loss: 0.00092384
Iteration 19/25 | Loss: 0.00093058
Iteration 20/25 | Loss: 0.00092488
Iteration 21/25 | Loss: 0.00092225
Iteration 22/25 | Loss: 0.00101372
Iteration 23/25 | Loss: 0.00101706
Iteration 24/25 | Loss: 0.00101025
Iteration 25/25 | Loss: 0.00102297

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.46879530
Iteration 2/25 | Loss: 0.00188098
Iteration 3/25 | Loss: 0.00177862
Iteration 4/25 | Loss: 0.00177861
Iteration 5/25 | Loss: 0.00177861
Iteration 6/25 | Loss: 0.00177861
Iteration 7/25 | Loss: 0.00177861
Iteration 8/25 | Loss: 0.00177861
Iteration 9/25 | Loss: 0.00177861
Iteration 10/25 | Loss: 0.00177861
Iteration 11/25 | Loss: 0.00177861
Iteration 12/25 | Loss: 0.00177861
Iteration 13/25 | Loss: 0.00177861
Iteration 14/25 | Loss: 0.00177861
Iteration 15/25 | Loss: 0.00177861
Iteration 16/25 | Loss: 0.00177861
Iteration 17/25 | Loss: 0.00177861
Iteration 18/25 | Loss: 0.00177861
Iteration 19/25 | Loss: 0.00177861
Iteration 20/25 | Loss: 0.00177861
Iteration 21/25 | Loss: 0.00177861
Iteration 22/25 | Loss: 0.00177861
Iteration 23/25 | Loss: 0.00177861
Iteration 24/25 | Loss: 0.00177861
Iteration 25/25 | Loss: 0.00177861

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00177861
Iteration 2/1000 | Loss: 0.00450478
Iteration 3/1000 | Loss: 0.00566583
Iteration 4/1000 | Loss: 0.00449196
Iteration 5/1000 | Loss: 0.00761021
Iteration 6/1000 | Loss: 0.00776732
Iteration 7/1000 | Loss: 0.00878546
Iteration 8/1000 | Loss: 0.00583033
Iteration 9/1000 | Loss: 0.00283705
Iteration 10/1000 | Loss: 0.00244349
Iteration 11/1000 | Loss: 0.00160492
Iteration 12/1000 | Loss: 0.00255215
Iteration 13/1000 | Loss: 0.00301531
Iteration 14/1000 | Loss: 0.00425841
Iteration 15/1000 | Loss: 0.00348952
Iteration 16/1000 | Loss: 0.00308616
Iteration 17/1000 | Loss: 0.00220183
Iteration 18/1000 | Loss: 0.00318698
Iteration 19/1000 | Loss: 0.00319122
Iteration 20/1000 | Loss: 0.00129912
Iteration 21/1000 | Loss: 0.00223516
Iteration 22/1000 | Loss: 0.00253080
Iteration 23/1000 | Loss: 0.00295443
Iteration 24/1000 | Loss: 0.00239754
Iteration 25/1000 | Loss: 0.00336976
Iteration 26/1000 | Loss: 0.00301872
Iteration 27/1000 | Loss: 0.00065652
Iteration 28/1000 | Loss: 0.00167863
Iteration 29/1000 | Loss: 0.00233137
Iteration 30/1000 | Loss: 0.00057755
Iteration 31/1000 | Loss: 0.00056834
Iteration 32/1000 | Loss: 0.00026116
Iteration 33/1000 | Loss: 0.00039798
Iteration 34/1000 | Loss: 0.00117899
Iteration 35/1000 | Loss: 0.00035611
Iteration 36/1000 | Loss: 0.00070835
Iteration 37/1000 | Loss: 0.00186189
Iteration 38/1000 | Loss: 0.00083804
Iteration 39/1000 | Loss: 0.00214958
Iteration 40/1000 | Loss: 0.00072604
Iteration 41/1000 | Loss: 0.00186523
Iteration 42/1000 | Loss: 0.00213103
Iteration 43/1000 | Loss: 0.00237294
Iteration 44/1000 | Loss: 0.00497508
Iteration 45/1000 | Loss: 0.00433933
Iteration 46/1000 | Loss: 0.00105458
Iteration 47/1000 | Loss: 0.00552361
Iteration 48/1000 | Loss: 0.00060902
Iteration 49/1000 | Loss: 0.00050442
Iteration 50/1000 | Loss: 0.00251251
Iteration 51/1000 | Loss: 0.00146078
Iteration 52/1000 | Loss: 0.00298002
Iteration 53/1000 | Loss: 0.00078453
Iteration 54/1000 | Loss: 0.00257704
Iteration 55/1000 | Loss: 0.00282848
Iteration 56/1000 | Loss: 0.00275928
Iteration 57/1000 | Loss: 0.00086122
Iteration 58/1000 | Loss: 0.00237001
Iteration 59/1000 | Loss: 0.00015502
Iteration 60/1000 | Loss: 0.00026781
Iteration 61/1000 | Loss: 0.00040511
Iteration 62/1000 | Loss: 0.00058906
Iteration 63/1000 | Loss: 0.00556985
Iteration 64/1000 | Loss: 0.00284655
Iteration 65/1000 | Loss: 0.00131929
Iteration 66/1000 | Loss: 0.00042514
Iteration 67/1000 | Loss: 0.00190495
Iteration 68/1000 | Loss: 0.00254015
Iteration 69/1000 | Loss: 0.00051636
Iteration 70/1000 | Loss: 0.00583402
Iteration 71/1000 | Loss: 0.00178848
Iteration 72/1000 | Loss: 0.00187698
Iteration 73/1000 | Loss: 0.00413440
Iteration 74/1000 | Loss: 0.00013421
Iteration 75/1000 | Loss: 0.00028142
Iteration 76/1000 | Loss: 0.00352490
Iteration 77/1000 | Loss: 0.00212660
Iteration 78/1000 | Loss: 0.00280011
Iteration 79/1000 | Loss: 0.00123831
Iteration 80/1000 | Loss: 0.00175255
Iteration 81/1000 | Loss: 0.00279629
Iteration 82/1000 | Loss: 0.00408633
Iteration 83/1000 | Loss: 0.00187412
Iteration 84/1000 | Loss: 0.00326090
Iteration 85/1000 | Loss: 0.00074645
Iteration 86/1000 | Loss: 0.00130067
Iteration 87/1000 | Loss: 0.00186894
Iteration 88/1000 | Loss: 0.00221888
Iteration 89/1000 | Loss: 0.00072318
Iteration 90/1000 | Loss: 0.00163642
Iteration 91/1000 | Loss: 0.00202878
Iteration 92/1000 | Loss: 0.00244844
Iteration 93/1000 | Loss: 0.00179539
Iteration 94/1000 | Loss: 0.00244920
Iteration 95/1000 | Loss: 0.00330957
Iteration 96/1000 | Loss: 0.00215636
Iteration 97/1000 | Loss: 0.00215594
Iteration 98/1000 | Loss: 0.00368591
Iteration 99/1000 | Loss: 0.00389358
Iteration 100/1000 | Loss: 0.00393391
Iteration 101/1000 | Loss: 0.00158590
Iteration 102/1000 | Loss: 0.00323562
Iteration 103/1000 | Loss: 0.00346150
Iteration 104/1000 | Loss: 0.00236847
Iteration 105/1000 | Loss: 0.00283608
Iteration 106/1000 | Loss: 0.00033076
Iteration 107/1000 | Loss: 0.00010288
Iteration 108/1000 | Loss: 0.00016847
Iteration 109/1000 | Loss: 0.00018032
Iteration 110/1000 | Loss: 0.00066637
Iteration 111/1000 | Loss: 0.00052636
Iteration 112/1000 | Loss: 0.00019703
Iteration 113/1000 | Loss: 0.00023495
Iteration 114/1000 | Loss: 0.00068323
Iteration 115/1000 | Loss: 0.00028052
Iteration 116/1000 | Loss: 0.00016684
Iteration 117/1000 | Loss: 0.00016272
Iteration 118/1000 | Loss: 0.00037230
Iteration 119/1000 | Loss: 0.00006300
Iteration 120/1000 | Loss: 0.00026339
Iteration 121/1000 | Loss: 0.00004191
Iteration 122/1000 | Loss: 0.00004443
Iteration 123/1000 | Loss: 0.00006113
Iteration 124/1000 | Loss: 0.00014349
Iteration 125/1000 | Loss: 0.00009135
Iteration 126/1000 | Loss: 0.00020940
Iteration 127/1000 | Loss: 0.00022780
Iteration 128/1000 | Loss: 0.00021294
Iteration 129/1000 | Loss: 0.00019167
Iteration 130/1000 | Loss: 0.00005926
Iteration 131/1000 | Loss: 0.00009262
Iteration 132/1000 | Loss: 0.00003779
Iteration 133/1000 | Loss: 0.00004762
Iteration 134/1000 | Loss: 0.00003699
Iteration 135/1000 | Loss: 0.00005084
Iteration 136/1000 | Loss: 0.00004627
Iteration 137/1000 | Loss: 0.00005739
Iteration 138/1000 | Loss: 0.00004357
Iteration 139/1000 | Loss: 0.00003318
Iteration 140/1000 | Loss: 0.00003246
Iteration 141/1000 | Loss: 0.00013408
Iteration 142/1000 | Loss: 0.00009487
Iteration 143/1000 | Loss: 0.00026217
Iteration 144/1000 | Loss: 0.00032554
Iteration 145/1000 | Loss: 0.00049702
Iteration 146/1000 | Loss: 0.00071291
Iteration 147/1000 | Loss: 0.00011943
Iteration 148/1000 | Loss: 0.00030821
Iteration 149/1000 | Loss: 0.00010714
Iteration 150/1000 | Loss: 0.00024925
Iteration 151/1000 | Loss: 0.00005006
Iteration 152/1000 | Loss: 0.00003455
Iteration 153/1000 | Loss: 0.00007199
Iteration 154/1000 | Loss: 0.00016586
Iteration 155/1000 | Loss: 0.00018746
Iteration 156/1000 | Loss: 0.00020216
Iteration 157/1000 | Loss: 0.00009081
Iteration 158/1000 | Loss: 0.00003294
Iteration 159/1000 | Loss: 0.00003207
Iteration 160/1000 | Loss: 0.00004032
Iteration 161/1000 | Loss: 0.00008223
Iteration 162/1000 | Loss: 0.00015761
Iteration 163/1000 | Loss: 0.00007035
Iteration 164/1000 | Loss: 0.00012376
Iteration 165/1000 | Loss: 0.00017361
Iteration 166/1000 | Loss: 0.00008040
Iteration 167/1000 | Loss: 0.00014091
Iteration 168/1000 | Loss: 0.00019433
Iteration 169/1000 | Loss: 0.00019572
Iteration 170/1000 | Loss: 0.00007149
Iteration 171/1000 | Loss: 0.00016094
Iteration 172/1000 | Loss: 0.00015257
Iteration 173/1000 | Loss: 0.00015699
Iteration 174/1000 | Loss: 0.00018415
Iteration 175/1000 | Loss: 0.00017312
Iteration 176/1000 | Loss: 0.00011340
Iteration 177/1000 | Loss: 0.00021946
Iteration 178/1000 | Loss: 0.00025466
Iteration 179/1000 | Loss: 0.00009638
Iteration 180/1000 | Loss: 0.00019614
Iteration 181/1000 | Loss: 0.00015645
Iteration 182/1000 | Loss: 0.00012501
Iteration 183/1000 | Loss: 0.00013611
Iteration 184/1000 | Loss: 0.00015682
Iteration 185/1000 | Loss: 0.00009083
Iteration 186/1000 | Loss: 0.00014096
Iteration 187/1000 | Loss: 0.00017362
Iteration 188/1000 | Loss: 0.00014551
Iteration 189/1000 | Loss: 0.00010363
Iteration 190/1000 | Loss: 0.00019334
Iteration 191/1000 | Loss: 0.00017169
Iteration 192/1000 | Loss: 0.00006786
Iteration 193/1000 | Loss: 0.00015787
Iteration 194/1000 | Loss: 0.00023131
Iteration 195/1000 | Loss: 0.00005183
Iteration 196/1000 | Loss: 0.00015652
Iteration 197/1000 | Loss: 0.00021876
Iteration 198/1000 | Loss: 0.00004319
Iteration 199/1000 | Loss: 0.00017415
Iteration 200/1000 | Loss: 0.00023545
Iteration 201/1000 | Loss: 0.00003382
Iteration 202/1000 | Loss: 0.00003078
Iteration 203/1000 | Loss: 0.00002930
Iteration 204/1000 | Loss: 0.00002865
Iteration 205/1000 | Loss: 0.00002844
Iteration 206/1000 | Loss: 0.00007436
Iteration 207/1000 | Loss: 0.00083376
Iteration 208/1000 | Loss: 0.00027456
Iteration 209/1000 | Loss: 0.00009598
Iteration 210/1000 | Loss: 0.00008909
Iteration 211/1000 | Loss: 0.00018096
Iteration 212/1000 | Loss: 0.00008012
Iteration 213/1000 | Loss: 0.00027052
Iteration 214/1000 | Loss: 0.00007769
Iteration 215/1000 | Loss: 0.00011349
Iteration 216/1000 | Loss: 0.00007781
Iteration 217/1000 | Loss: 0.00013542
Iteration 218/1000 | Loss: 0.00007156
Iteration 219/1000 | Loss: 0.00003384
Iteration 220/1000 | Loss: 0.00007615
Iteration 221/1000 | Loss: 0.00005671
Iteration 222/1000 | Loss: 0.00004441
Iteration 223/1000 | Loss: 0.00003598
Iteration 224/1000 | Loss: 0.00003150
Iteration 225/1000 | Loss: 0.00011604
Iteration 226/1000 | Loss: 0.00026152
Iteration 227/1000 | Loss: 0.00010339
Iteration 228/1000 | Loss: 0.00013902
Iteration 229/1000 | Loss: 0.00019713
Iteration 230/1000 | Loss: 0.00007861
Iteration 231/1000 | Loss: 0.00005638
Iteration 232/1000 | Loss: 0.00019951
Iteration 233/1000 | Loss: 0.00027196
Iteration 234/1000 | Loss: 0.00019267
Iteration 235/1000 | Loss: 0.00030336
Iteration 236/1000 | Loss: 0.00019652
Iteration 237/1000 | Loss: 0.00018474
Iteration 238/1000 | Loss: 0.00016873
Iteration 239/1000 | Loss: 0.00025210
Iteration 240/1000 | Loss: 0.00004240
Iteration 241/1000 | Loss: 0.00016830
Iteration 242/1000 | Loss: 0.00017848
Iteration 243/1000 | Loss: 0.00016606
Iteration 244/1000 | Loss: 0.00027152
Iteration 245/1000 | Loss: 0.00022529
Iteration 246/1000 | Loss: 0.00018105
Iteration 247/1000 | Loss: 0.00023519
Iteration 248/1000 | Loss: 0.00026870
Iteration 249/1000 | Loss: 0.00006613
Iteration 250/1000 | Loss: 0.00003566
Iteration 251/1000 | Loss: 0.00003284
Iteration 252/1000 | Loss: 0.00081654
Iteration 253/1000 | Loss: 0.00003362
Iteration 254/1000 | Loss: 0.00002922
Iteration 255/1000 | Loss: 0.00002837
Iteration 256/1000 | Loss: 0.00002779
Iteration 257/1000 | Loss: 0.00002721
Iteration 258/1000 | Loss: 0.00002694
Iteration 259/1000 | Loss: 0.00002665
Iteration 260/1000 | Loss: 0.00035063
Iteration 261/1000 | Loss: 0.00020306
Iteration 262/1000 | Loss: 0.00024155
Iteration 263/1000 | Loss: 0.00010449
Iteration 264/1000 | Loss: 0.00021860
Iteration 265/1000 | Loss: 0.00015629
Iteration 266/1000 | Loss: 0.00031785
Iteration 267/1000 | Loss: 0.00019062
Iteration 268/1000 | Loss: 0.00038204
Iteration 269/1000 | Loss: 0.00024930
Iteration 270/1000 | Loss: 0.00016567
Iteration 271/1000 | Loss: 0.00013040
Iteration 272/1000 | Loss: 0.00025043
Iteration 273/1000 | Loss: 0.00024559
Iteration 274/1000 | Loss: 0.00023488
Iteration 275/1000 | Loss: 0.00014921
Iteration 276/1000 | Loss: 0.00002909
Iteration 277/1000 | Loss: 0.00002818
Iteration 278/1000 | Loss: 0.00002728
Iteration 279/1000 | Loss: 0.00027491
Iteration 280/1000 | Loss: 0.00004305
Iteration 281/1000 | Loss: 0.00032553
Iteration 282/1000 | Loss: 0.00003261
Iteration 283/1000 | Loss: 0.00002900
Iteration 284/1000 | Loss: 0.00002664
Iteration 285/1000 | Loss: 0.00002582
Iteration 286/1000 | Loss: 0.00002535
Iteration 287/1000 | Loss: 0.00002492
Iteration 288/1000 | Loss: 0.00002457
Iteration 289/1000 | Loss: 0.00002435
Iteration 290/1000 | Loss: 0.00002429
Iteration 291/1000 | Loss: 0.00002412
Iteration 292/1000 | Loss: 0.00002389
Iteration 293/1000 | Loss: 0.00002362
Iteration 294/1000 | Loss: 0.00002340
Iteration 295/1000 | Loss: 0.00002336
Iteration 296/1000 | Loss: 0.00002331
Iteration 297/1000 | Loss: 0.00002331
Iteration 298/1000 | Loss: 0.00002319
Iteration 299/1000 | Loss: 0.00002319
Iteration 300/1000 | Loss: 0.00002318
Iteration 301/1000 | Loss: 0.00002318
Iteration 302/1000 | Loss: 0.00002315
Iteration 303/1000 | Loss: 0.00002315
Iteration 304/1000 | Loss: 0.00002314
Iteration 305/1000 | Loss: 0.00002314
Iteration 306/1000 | Loss: 0.00002313
Iteration 307/1000 | Loss: 0.00002313
Iteration 308/1000 | Loss: 0.00002313
Iteration 309/1000 | Loss: 0.00002313
Iteration 310/1000 | Loss: 0.00002313
Iteration 311/1000 | Loss: 0.00002313
Iteration 312/1000 | Loss: 0.00002313
Iteration 313/1000 | Loss: 0.00002313
Iteration 314/1000 | Loss: 0.00002313
Iteration 315/1000 | Loss: 0.00002313
Iteration 316/1000 | Loss: 0.00002313
Iteration 317/1000 | Loss: 0.00002312
Iteration 318/1000 | Loss: 0.00002312
Iteration 319/1000 | Loss: 0.00002312
Iteration 320/1000 | Loss: 0.00002312
Iteration 321/1000 | Loss: 0.00002312
Iteration 322/1000 | Loss: 0.00002312
Iteration 323/1000 | Loss: 0.00002312
Iteration 324/1000 | Loss: 0.00002312
Iteration 325/1000 | Loss: 0.00002312
Iteration 326/1000 | Loss: 0.00002312
Iteration 327/1000 | Loss: 0.00002312
Iteration 328/1000 | Loss: 0.00002311
Iteration 329/1000 | Loss: 0.00002311
Iteration 330/1000 | Loss: 0.00002311
Iteration 331/1000 | Loss: 0.00002311
Iteration 332/1000 | Loss: 0.00002311
Iteration 333/1000 | Loss: 0.00002311
Iteration 334/1000 | Loss: 0.00002311
Iteration 335/1000 | Loss: 0.00002311
Iteration 336/1000 | Loss: 0.00002311
Iteration 337/1000 | Loss: 0.00002311
Iteration 338/1000 | Loss: 0.00002311
Iteration 339/1000 | Loss: 0.00002311
Iteration 340/1000 | Loss: 0.00002311
Iteration 341/1000 | Loss: 0.00002310
Iteration 342/1000 | Loss: 0.00002310
Iteration 343/1000 | Loss: 0.00002310
Iteration 344/1000 | Loss: 0.00002310
Iteration 345/1000 | Loss: 0.00002310
Iteration 346/1000 | Loss: 0.00002310
Iteration 347/1000 | Loss: 0.00002310
Iteration 348/1000 | Loss: 0.00002310
Iteration 349/1000 | Loss: 0.00002310
Iteration 350/1000 | Loss: 0.00002310
Iteration 351/1000 | Loss: 0.00002310
Iteration 352/1000 | Loss: 0.00002310
Iteration 353/1000 | Loss: 0.00002310
Iteration 354/1000 | Loss: 0.00002310
Iteration 355/1000 | Loss: 0.00002310
Iteration 356/1000 | Loss: 0.00002310
Iteration 357/1000 | Loss: 0.00002310
Iteration 358/1000 | Loss: 0.00002310
Iteration 359/1000 | Loss: 0.00002309
Iteration 360/1000 | Loss: 0.00002309
Iteration 361/1000 | Loss: 0.00002309
Iteration 362/1000 | Loss: 0.00002309
Iteration 363/1000 | Loss: 0.00002309
Iteration 364/1000 | Loss: 0.00002309
Iteration 365/1000 | Loss: 0.00002309
Iteration 366/1000 | Loss: 0.00002309
Iteration 367/1000 | Loss: 0.00002309
Iteration 368/1000 | Loss: 0.00002309
Iteration 369/1000 | Loss: 0.00002309
Iteration 370/1000 | Loss: 0.00002309
Iteration 371/1000 | Loss: 0.00002309
Iteration 372/1000 | Loss: 0.00002309
Iteration 373/1000 | Loss: 0.00002309
Iteration 374/1000 | Loss: 0.00002309
Iteration 375/1000 | Loss: 0.00002309
Iteration 376/1000 | Loss: 0.00002309
Iteration 377/1000 | Loss: 0.00002309
Iteration 378/1000 | Loss: 0.00002309
Iteration 379/1000 | Loss: 0.00002308
Iteration 380/1000 | Loss: 0.00002308
Iteration 381/1000 | Loss: 0.00002308
Iteration 382/1000 | Loss: 0.00002308
Iteration 383/1000 | Loss: 0.00002308
Iteration 384/1000 | Loss: 0.00002308
Iteration 385/1000 | Loss: 0.00002308
Iteration 386/1000 | Loss: 0.00002308
Iteration 387/1000 | Loss: 0.00002308
Iteration 388/1000 | Loss: 0.00002308
Iteration 389/1000 | Loss: 0.00002308
Iteration 390/1000 | Loss: 0.00002308
Iteration 391/1000 | Loss: 0.00002308
Iteration 392/1000 | Loss: 0.00002308
Iteration 393/1000 | Loss: 0.00002308
Iteration 394/1000 | Loss: 0.00002308
Iteration 395/1000 | Loss: 0.00002308
Iteration 396/1000 | Loss: 0.00002308
Iteration 397/1000 | Loss: 0.00002308
Iteration 398/1000 | Loss: 0.00002308
Iteration 399/1000 | Loss: 0.00002307
Iteration 400/1000 | Loss: 0.00002307
Iteration 401/1000 | Loss: 0.00002307
Iteration 402/1000 | Loss: 0.00002307
Iteration 403/1000 | Loss: 0.00002307
Iteration 404/1000 | Loss: 0.00002307
Iteration 405/1000 | Loss: 0.00002307
Iteration 406/1000 | Loss: 0.00002307
Iteration 407/1000 | Loss: 0.00002307
Iteration 408/1000 | Loss: 0.00002307
Iteration 409/1000 | Loss: 0.00002307
Iteration 410/1000 | Loss: 0.00002307
Iteration 411/1000 | Loss: 0.00002307
Iteration 412/1000 | Loss: 0.00002307
Iteration 413/1000 | Loss: 0.00002307
Iteration 414/1000 | Loss: 0.00002307
Iteration 415/1000 | Loss: 0.00002307
Iteration 416/1000 | Loss: 0.00002306
Iteration 417/1000 | Loss: 0.00002306
Iteration 418/1000 | Loss: 0.00002306
Iteration 419/1000 | Loss: 0.00002306
Iteration 420/1000 | Loss: 0.00002306
Iteration 421/1000 | Loss: 0.00002306
Iteration 422/1000 | Loss: 0.00002306
Iteration 423/1000 | Loss: 0.00002306
Iteration 424/1000 | Loss: 0.00002306
Iteration 425/1000 | Loss: 0.00002306
Iteration 426/1000 | Loss: 0.00002306
Iteration 427/1000 | Loss: 0.00002306
Iteration 428/1000 | Loss: 0.00002306
Iteration 429/1000 | Loss: 0.00002306
Iteration 430/1000 | Loss: 0.00002306
Iteration 431/1000 | Loss: 0.00002306
Iteration 432/1000 | Loss: 0.00002306
Iteration 433/1000 | Loss: 0.00002306
Iteration 434/1000 | Loss: 0.00002306
Iteration 435/1000 | Loss: 0.00002306
Iteration 436/1000 | Loss: 0.00002306
Iteration 437/1000 | Loss: 0.00002306
Iteration 438/1000 | Loss: 0.00002306
Iteration 439/1000 | Loss: 0.00002306
Iteration 440/1000 | Loss: 0.00002306
Iteration 441/1000 | Loss: 0.00002306
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 441. Stopping optimization.
Last 5 losses: [2.306343594682403e-05, 2.306343594682403e-05, 2.306343594682403e-05, 2.306343594682403e-05, 2.306343594682403e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.306343594682403e-05

Optimization complete. Final v2v error: 4.031239032745361 mm

Highest mean error: 5.739035129547119 mm for frame 75

Lowest mean error: 3.1447322368621826 mm for frame 144

Saving results

Total time: 469.12263321876526
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00877626
Iteration 2/25 | Loss: 0.00101513
Iteration 3/25 | Loss: 0.00076003
Iteration 4/25 | Loss: 0.00072989
Iteration 5/25 | Loss: 0.00072094
Iteration 6/25 | Loss: 0.00071853
Iteration 7/25 | Loss: 0.00071780
Iteration 8/25 | Loss: 0.00071780
Iteration 9/25 | Loss: 0.00071780
Iteration 10/25 | Loss: 0.00071780
Iteration 11/25 | Loss: 0.00071780
Iteration 12/25 | Loss: 0.00071780
Iteration 13/25 | Loss: 0.00071780
Iteration 14/25 | Loss: 0.00071780
Iteration 15/25 | Loss: 0.00071780
Iteration 16/25 | Loss: 0.00071780
Iteration 17/25 | Loss: 0.00071780
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.000717798771802336, 0.000717798771802336, 0.000717798771802336, 0.000717798771802336, 0.000717798771802336]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000717798771802336

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44894111
Iteration 2/25 | Loss: 0.00030027
Iteration 3/25 | Loss: 0.00030027
Iteration 4/25 | Loss: 0.00030027
Iteration 5/25 | Loss: 0.00030027
Iteration 6/25 | Loss: 0.00030027
Iteration 7/25 | Loss: 0.00030027
Iteration 8/25 | Loss: 0.00030027
Iteration 9/25 | Loss: 0.00030027
Iteration 10/25 | Loss: 0.00030027
Iteration 11/25 | Loss: 0.00030027
Iteration 12/25 | Loss: 0.00030027
Iteration 13/25 | Loss: 0.00030027
Iteration 14/25 | Loss: 0.00030027
Iteration 15/25 | Loss: 0.00030027
Iteration 16/25 | Loss: 0.00030027
Iteration 17/25 | Loss: 0.00030027
Iteration 18/25 | Loss: 0.00030027
Iteration 19/25 | Loss: 0.00030027
Iteration 20/25 | Loss: 0.00030027
Iteration 21/25 | Loss: 0.00030027
Iteration 22/25 | Loss: 0.00030027
Iteration 23/25 | Loss: 0.00030027
Iteration 24/25 | Loss: 0.00030027
Iteration 25/25 | Loss: 0.00030027

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030027
Iteration 2/1000 | Loss: 0.00002166
Iteration 3/1000 | Loss: 0.00001592
Iteration 4/1000 | Loss: 0.00001462
Iteration 5/1000 | Loss: 0.00001405
Iteration 6/1000 | Loss: 0.00001366
Iteration 7/1000 | Loss: 0.00001326
Iteration 8/1000 | Loss: 0.00001319
Iteration 9/1000 | Loss: 0.00001301
Iteration 10/1000 | Loss: 0.00001293
Iteration 11/1000 | Loss: 0.00001289
Iteration 12/1000 | Loss: 0.00001288
Iteration 13/1000 | Loss: 0.00001281
Iteration 14/1000 | Loss: 0.00001280
Iteration 15/1000 | Loss: 0.00001279
Iteration 16/1000 | Loss: 0.00001278
Iteration 17/1000 | Loss: 0.00001277
Iteration 18/1000 | Loss: 0.00001274
Iteration 19/1000 | Loss: 0.00001274
Iteration 20/1000 | Loss: 0.00001274
Iteration 21/1000 | Loss: 0.00001273
Iteration 22/1000 | Loss: 0.00001273
Iteration 23/1000 | Loss: 0.00001273
Iteration 24/1000 | Loss: 0.00001272
Iteration 25/1000 | Loss: 0.00001272
Iteration 26/1000 | Loss: 0.00001272
Iteration 27/1000 | Loss: 0.00001272
Iteration 28/1000 | Loss: 0.00001271
Iteration 29/1000 | Loss: 0.00001271
Iteration 30/1000 | Loss: 0.00001271
Iteration 31/1000 | Loss: 0.00001271
Iteration 32/1000 | Loss: 0.00001271
Iteration 33/1000 | Loss: 0.00001271
Iteration 34/1000 | Loss: 0.00001271
Iteration 35/1000 | Loss: 0.00001271
Iteration 36/1000 | Loss: 0.00001271
Iteration 37/1000 | Loss: 0.00001271
Iteration 38/1000 | Loss: 0.00001270
Iteration 39/1000 | Loss: 0.00001270
Iteration 40/1000 | Loss: 0.00001270
Iteration 41/1000 | Loss: 0.00001270
Iteration 42/1000 | Loss: 0.00001269
Iteration 43/1000 | Loss: 0.00001269
Iteration 44/1000 | Loss: 0.00001269
Iteration 45/1000 | Loss: 0.00001268
Iteration 46/1000 | Loss: 0.00001268
Iteration 47/1000 | Loss: 0.00001267
Iteration 48/1000 | Loss: 0.00001267
Iteration 49/1000 | Loss: 0.00001266
Iteration 50/1000 | Loss: 0.00001266
Iteration 51/1000 | Loss: 0.00001265
Iteration 52/1000 | Loss: 0.00001265
Iteration 53/1000 | Loss: 0.00001265
Iteration 54/1000 | Loss: 0.00001264
Iteration 55/1000 | Loss: 0.00001264
Iteration 56/1000 | Loss: 0.00001264
Iteration 57/1000 | Loss: 0.00001264
Iteration 58/1000 | Loss: 0.00001263
Iteration 59/1000 | Loss: 0.00001263
Iteration 60/1000 | Loss: 0.00001263
Iteration 61/1000 | Loss: 0.00001263
Iteration 62/1000 | Loss: 0.00001263
Iteration 63/1000 | Loss: 0.00001263
Iteration 64/1000 | Loss: 0.00001262
Iteration 65/1000 | Loss: 0.00001262
Iteration 66/1000 | Loss: 0.00001262
Iteration 67/1000 | Loss: 0.00001262
Iteration 68/1000 | Loss: 0.00001262
Iteration 69/1000 | Loss: 0.00001262
Iteration 70/1000 | Loss: 0.00001262
Iteration 71/1000 | Loss: 0.00001262
Iteration 72/1000 | Loss: 0.00001262
Iteration 73/1000 | Loss: 0.00001261
Iteration 74/1000 | Loss: 0.00001261
Iteration 75/1000 | Loss: 0.00001261
Iteration 76/1000 | Loss: 0.00001261
Iteration 77/1000 | Loss: 0.00001261
Iteration 78/1000 | Loss: 0.00001261
Iteration 79/1000 | Loss: 0.00001261
Iteration 80/1000 | Loss: 0.00001260
Iteration 81/1000 | Loss: 0.00001260
Iteration 82/1000 | Loss: 0.00001260
Iteration 83/1000 | Loss: 0.00001260
Iteration 84/1000 | Loss: 0.00001260
Iteration 85/1000 | Loss: 0.00001260
Iteration 86/1000 | Loss: 0.00001260
Iteration 87/1000 | Loss: 0.00001260
Iteration 88/1000 | Loss: 0.00001260
Iteration 89/1000 | Loss: 0.00001260
Iteration 90/1000 | Loss: 0.00001259
Iteration 91/1000 | Loss: 0.00001259
Iteration 92/1000 | Loss: 0.00001259
Iteration 93/1000 | Loss: 0.00001259
Iteration 94/1000 | Loss: 0.00001259
Iteration 95/1000 | Loss: 0.00001259
Iteration 96/1000 | Loss: 0.00001259
Iteration 97/1000 | Loss: 0.00001259
Iteration 98/1000 | Loss: 0.00001259
Iteration 99/1000 | Loss: 0.00001259
Iteration 100/1000 | Loss: 0.00001259
Iteration 101/1000 | Loss: 0.00001259
Iteration 102/1000 | Loss: 0.00001259
Iteration 103/1000 | Loss: 0.00001258
Iteration 104/1000 | Loss: 0.00001258
Iteration 105/1000 | Loss: 0.00001258
Iteration 106/1000 | Loss: 0.00001258
Iteration 107/1000 | Loss: 0.00001258
Iteration 108/1000 | Loss: 0.00001258
Iteration 109/1000 | Loss: 0.00001258
Iteration 110/1000 | Loss: 0.00001258
Iteration 111/1000 | Loss: 0.00001258
Iteration 112/1000 | Loss: 0.00001258
Iteration 113/1000 | Loss: 0.00001258
Iteration 114/1000 | Loss: 0.00001258
Iteration 115/1000 | Loss: 0.00001258
Iteration 116/1000 | Loss: 0.00001257
Iteration 117/1000 | Loss: 0.00001257
Iteration 118/1000 | Loss: 0.00001257
Iteration 119/1000 | Loss: 0.00001257
Iteration 120/1000 | Loss: 0.00001257
Iteration 121/1000 | Loss: 0.00001257
Iteration 122/1000 | Loss: 0.00001257
Iteration 123/1000 | Loss: 0.00001257
Iteration 124/1000 | Loss: 0.00001257
Iteration 125/1000 | Loss: 0.00001257
Iteration 126/1000 | Loss: 0.00001256
Iteration 127/1000 | Loss: 0.00001256
Iteration 128/1000 | Loss: 0.00001256
Iteration 129/1000 | Loss: 0.00001256
Iteration 130/1000 | Loss: 0.00001256
Iteration 131/1000 | Loss: 0.00001256
Iteration 132/1000 | Loss: 0.00001256
Iteration 133/1000 | Loss: 0.00001256
Iteration 134/1000 | Loss: 0.00001256
Iteration 135/1000 | Loss: 0.00001256
Iteration 136/1000 | Loss: 0.00001256
Iteration 137/1000 | Loss: 0.00001256
Iteration 138/1000 | Loss: 0.00001255
Iteration 139/1000 | Loss: 0.00001255
Iteration 140/1000 | Loss: 0.00001255
Iteration 141/1000 | Loss: 0.00001255
Iteration 142/1000 | Loss: 0.00001255
Iteration 143/1000 | Loss: 0.00001255
Iteration 144/1000 | Loss: 0.00001255
Iteration 145/1000 | Loss: 0.00001255
Iteration 146/1000 | Loss: 0.00001255
Iteration 147/1000 | Loss: 0.00001255
Iteration 148/1000 | Loss: 0.00001255
Iteration 149/1000 | Loss: 0.00001255
Iteration 150/1000 | Loss: 0.00001255
Iteration 151/1000 | Loss: 0.00001255
Iteration 152/1000 | Loss: 0.00001255
Iteration 153/1000 | Loss: 0.00001255
Iteration 154/1000 | Loss: 0.00001255
Iteration 155/1000 | Loss: 0.00001255
Iteration 156/1000 | Loss: 0.00001255
Iteration 157/1000 | Loss: 0.00001255
Iteration 158/1000 | Loss: 0.00001255
Iteration 159/1000 | Loss: 0.00001255
Iteration 160/1000 | Loss: 0.00001255
Iteration 161/1000 | Loss: 0.00001255
Iteration 162/1000 | Loss: 0.00001255
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [1.2553805390780326e-05, 1.2553805390780326e-05, 1.2553805390780326e-05, 1.2553805390780326e-05, 1.2553805390780326e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2553805390780326e-05

Optimization complete. Final v2v error: 3.033001184463501 mm

Highest mean error: 3.544480323791504 mm for frame 191

Lowest mean error: 2.4467720985412598 mm for frame 17

Saving results

Total time: 40.574042320251465
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01097553
Iteration 2/25 | Loss: 0.00305252
Iteration 3/25 | Loss: 0.00237829
Iteration 4/25 | Loss: 0.00196798
Iteration 5/25 | Loss: 0.00185789
Iteration 6/25 | Loss: 0.00182254
Iteration 7/25 | Loss: 0.00161732
Iteration 8/25 | Loss: 0.00157923
Iteration 9/25 | Loss: 0.00136966
Iteration 10/25 | Loss: 0.00126127
Iteration 11/25 | Loss: 0.00120060
Iteration 12/25 | Loss: 0.00120300
Iteration 13/25 | Loss: 0.00118038
Iteration 14/25 | Loss: 0.00121914
Iteration 15/25 | Loss: 0.00120387
Iteration 16/25 | Loss: 0.00115659
Iteration 17/25 | Loss: 0.00114696
Iteration 18/25 | Loss: 0.00114284
Iteration 19/25 | Loss: 0.00114301
Iteration 20/25 | Loss: 0.00113466
Iteration 21/25 | Loss: 0.00113261
Iteration 22/25 | Loss: 0.00113198
Iteration 23/25 | Loss: 0.00113177
Iteration 24/25 | Loss: 0.00113163
Iteration 25/25 | Loss: 0.00113161

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45736742
Iteration 2/25 | Loss: 0.00275396
Iteration 3/25 | Loss: 0.00208162
Iteration 4/25 | Loss: 0.00208162
Iteration 5/25 | Loss: 0.00208162
Iteration 6/25 | Loss: 0.00208162
Iteration 7/25 | Loss: 0.00208162
Iteration 8/25 | Loss: 0.00208162
Iteration 9/25 | Loss: 0.00208162
Iteration 10/25 | Loss: 0.00208162
Iteration 11/25 | Loss: 0.00208162
Iteration 12/25 | Loss: 0.00208162
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0020816160831600428, 0.0020816160831600428, 0.0020816160831600428, 0.0020816160831600428, 0.0020816160831600428]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020816160831600428

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00208162
Iteration 2/1000 | Loss: 0.00068918
Iteration 3/1000 | Loss: 0.00040296
Iteration 4/1000 | Loss: 0.00100811
Iteration 5/1000 | Loss: 0.00030377
Iteration 6/1000 | Loss: 0.00970578
Iteration 7/1000 | Loss: 0.00028442
Iteration 8/1000 | Loss: 0.00156981
Iteration 9/1000 | Loss: 0.00056827
Iteration 10/1000 | Loss: 0.00203991
Iteration 11/1000 | Loss: 0.00314440
Iteration 12/1000 | Loss: 0.00026786
Iteration 13/1000 | Loss: 0.00030331
Iteration 14/1000 | Loss: 0.00017598
Iteration 15/1000 | Loss: 0.00016967
Iteration 16/1000 | Loss: 0.00115246
Iteration 17/1000 | Loss: 0.01072836
Iteration 18/1000 | Loss: 0.00611220
Iteration 19/1000 | Loss: 0.00222281
Iteration 20/1000 | Loss: 0.00161999
Iteration 21/1000 | Loss: 0.00512529
Iteration 22/1000 | Loss: 0.00487055
Iteration 23/1000 | Loss: 0.00217471
Iteration 24/1000 | Loss: 0.01238981
Iteration 25/1000 | Loss: 0.00690838
Iteration 26/1000 | Loss: 0.00505102
Iteration 27/1000 | Loss: 0.00357511
Iteration 28/1000 | Loss: 0.00184850
Iteration 29/1000 | Loss: 0.00240985
Iteration 30/1000 | Loss: 0.00314243
Iteration 31/1000 | Loss: 0.00345870
Iteration 32/1000 | Loss: 0.00122524
Iteration 33/1000 | Loss: 0.00074999
Iteration 34/1000 | Loss: 0.00129850
Iteration 35/1000 | Loss: 0.00124939
Iteration 36/1000 | Loss: 0.00308636
Iteration 37/1000 | Loss: 0.00548124
Iteration 38/1000 | Loss: 0.00311400
Iteration 39/1000 | Loss: 0.00444104
Iteration 40/1000 | Loss: 0.00134355
Iteration 41/1000 | Loss: 0.00134360
Iteration 42/1000 | Loss: 0.00052274
Iteration 43/1000 | Loss: 0.00054278
Iteration 44/1000 | Loss: 0.00048849
Iteration 45/1000 | Loss: 0.00026450
Iteration 46/1000 | Loss: 0.00031494
Iteration 47/1000 | Loss: 0.00022143
Iteration 48/1000 | Loss: 0.00016486
Iteration 49/1000 | Loss: 0.00048422
Iteration 50/1000 | Loss: 0.00017602
Iteration 51/1000 | Loss: 0.00018118
Iteration 52/1000 | Loss: 0.00053816
Iteration 53/1000 | Loss: 0.00025226
Iteration 54/1000 | Loss: 0.00060243
Iteration 55/1000 | Loss: 0.00028312
Iteration 56/1000 | Loss: 0.00032029
Iteration 57/1000 | Loss: 0.00057080
Iteration 58/1000 | Loss: 0.00064544
Iteration 59/1000 | Loss: 0.00025649
Iteration 60/1000 | Loss: 0.00037809
Iteration 61/1000 | Loss: 0.00017286
Iteration 62/1000 | Loss: 0.00117246
Iteration 63/1000 | Loss: 0.00028912
Iteration 64/1000 | Loss: 0.00030183
Iteration 65/1000 | Loss: 0.00031572
Iteration 66/1000 | Loss: 0.00032253
Iteration 67/1000 | Loss: 0.00029992
Iteration 68/1000 | Loss: 0.00061187
Iteration 69/1000 | Loss: 0.00018122
Iteration 70/1000 | Loss: 0.00019408
Iteration 71/1000 | Loss: 0.00046588
Iteration 72/1000 | Loss: 0.00031167
Iteration 73/1000 | Loss: 0.00033938
Iteration 74/1000 | Loss: 0.00073304
Iteration 75/1000 | Loss: 0.00040688
Iteration 76/1000 | Loss: 0.00053081
Iteration 77/1000 | Loss: 0.00043476
Iteration 78/1000 | Loss: 0.00040590
Iteration 79/1000 | Loss: 0.00143953
Iteration 80/1000 | Loss: 0.00222439
Iteration 81/1000 | Loss: 0.00264661
Iteration 82/1000 | Loss: 0.00254146
Iteration 83/1000 | Loss: 0.00185311
Iteration 84/1000 | Loss: 0.00042065
Iteration 85/1000 | Loss: 0.00034990
Iteration 86/1000 | Loss: 0.00039924
Iteration 87/1000 | Loss: 0.00032752
Iteration 88/1000 | Loss: 0.00149820
Iteration 89/1000 | Loss: 0.00044687
Iteration 90/1000 | Loss: 0.00041927
Iteration 91/1000 | Loss: 0.00028994
Iteration 92/1000 | Loss: 0.00031856
Iteration 93/1000 | Loss: 0.00026167
Iteration 94/1000 | Loss: 0.00023654
Iteration 95/1000 | Loss: 0.00019052
Iteration 96/1000 | Loss: 0.00019981
Iteration 97/1000 | Loss: 0.00026266
Iteration 98/1000 | Loss: 0.00139863
Iteration 99/1000 | Loss: 0.00114249
Iteration 100/1000 | Loss: 0.00104724
Iteration 101/1000 | Loss: 0.00069267
Iteration 102/1000 | Loss: 0.00182834
Iteration 103/1000 | Loss: 0.00026766
Iteration 104/1000 | Loss: 0.00014279
Iteration 105/1000 | Loss: 0.00009539
Iteration 106/1000 | Loss: 0.00014332
Iteration 107/1000 | Loss: 0.00027419
Iteration 108/1000 | Loss: 0.00006924
Iteration 109/1000 | Loss: 0.00044771
Iteration 110/1000 | Loss: 0.00005918
Iteration 111/1000 | Loss: 0.00040149
Iteration 112/1000 | Loss: 0.00005283
Iteration 113/1000 | Loss: 0.00029105
Iteration 114/1000 | Loss: 0.00005081
Iteration 115/1000 | Loss: 0.00004954
Iteration 116/1000 | Loss: 0.00022113
Iteration 117/1000 | Loss: 0.00005040
Iteration 118/1000 | Loss: 0.00004666
Iteration 119/1000 | Loss: 0.00046804
Iteration 120/1000 | Loss: 0.00035161
Iteration 121/1000 | Loss: 0.00007587
Iteration 122/1000 | Loss: 0.00004696
Iteration 123/1000 | Loss: 0.00010412
Iteration 124/1000 | Loss: 0.00004689
Iteration 125/1000 | Loss: 0.00004584
Iteration 126/1000 | Loss: 0.00004552
Iteration 127/1000 | Loss: 0.00046392
Iteration 128/1000 | Loss: 0.00026778
Iteration 129/1000 | Loss: 0.00004716
Iteration 130/1000 | Loss: 0.00033236
Iteration 131/1000 | Loss: 0.00012634
Iteration 132/1000 | Loss: 0.00004605
Iteration 133/1000 | Loss: 0.00035617
Iteration 134/1000 | Loss: 0.00036365
Iteration 135/1000 | Loss: 0.00004746
Iteration 136/1000 | Loss: 0.00031993
Iteration 137/1000 | Loss: 0.00004822
Iteration 138/1000 | Loss: 0.00004581
Iteration 139/1000 | Loss: 0.00004548
Iteration 140/1000 | Loss: 0.00004524
Iteration 141/1000 | Loss: 0.00004521
Iteration 142/1000 | Loss: 0.00004519
Iteration 143/1000 | Loss: 0.00004518
Iteration 144/1000 | Loss: 0.00004514
Iteration 145/1000 | Loss: 0.00004512
Iteration 146/1000 | Loss: 0.00004512
Iteration 147/1000 | Loss: 0.00004512
Iteration 148/1000 | Loss: 0.00004512
Iteration 149/1000 | Loss: 0.00004512
Iteration 150/1000 | Loss: 0.00004512
Iteration 151/1000 | Loss: 0.00004512
Iteration 152/1000 | Loss: 0.00004512
Iteration 153/1000 | Loss: 0.00004512
Iteration 154/1000 | Loss: 0.00004512
Iteration 155/1000 | Loss: 0.00004512
Iteration 156/1000 | Loss: 0.00004511
Iteration 157/1000 | Loss: 0.00004511
Iteration 158/1000 | Loss: 0.00004511
Iteration 159/1000 | Loss: 0.00004510
Iteration 160/1000 | Loss: 0.00004510
Iteration 161/1000 | Loss: 0.00004510
Iteration 162/1000 | Loss: 0.00004510
Iteration 163/1000 | Loss: 0.00004509
Iteration 164/1000 | Loss: 0.00004509
Iteration 165/1000 | Loss: 0.00004509
Iteration 166/1000 | Loss: 0.00004509
Iteration 167/1000 | Loss: 0.00004508
Iteration 168/1000 | Loss: 0.00004508
Iteration 169/1000 | Loss: 0.00004508
Iteration 170/1000 | Loss: 0.00004508
Iteration 171/1000 | Loss: 0.00004508
Iteration 172/1000 | Loss: 0.00004508
Iteration 173/1000 | Loss: 0.00004508
Iteration 174/1000 | Loss: 0.00004508
Iteration 175/1000 | Loss: 0.00004508
Iteration 176/1000 | Loss: 0.00004508
Iteration 177/1000 | Loss: 0.00004508
Iteration 178/1000 | Loss: 0.00004507
Iteration 179/1000 | Loss: 0.00004507
Iteration 180/1000 | Loss: 0.00004507
Iteration 181/1000 | Loss: 0.00004506
Iteration 182/1000 | Loss: 0.00004506
Iteration 183/1000 | Loss: 0.00004506
Iteration 184/1000 | Loss: 0.00004506
Iteration 185/1000 | Loss: 0.00004505
Iteration 186/1000 | Loss: 0.00004504
Iteration 187/1000 | Loss: 0.00004503
Iteration 188/1000 | Loss: 0.00004503
Iteration 189/1000 | Loss: 0.00004503
Iteration 190/1000 | Loss: 0.00004503
Iteration 191/1000 | Loss: 0.00004503
Iteration 192/1000 | Loss: 0.00004503
Iteration 193/1000 | Loss: 0.00004503
Iteration 194/1000 | Loss: 0.00004503
Iteration 195/1000 | Loss: 0.00004503
Iteration 196/1000 | Loss: 0.00004503
Iteration 197/1000 | Loss: 0.00004503
Iteration 198/1000 | Loss: 0.00004503
Iteration 199/1000 | Loss: 0.00004502
Iteration 200/1000 | Loss: 0.00004502
Iteration 201/1000 | Loss: 0.00004502
Iteration 202/1000 | Loss: 0.00004502
Iteration 203/1000 | Loss: 0.00004502
Iteration 204/1000 | Loss: 0.00004502
Iteration 205/1000 | Loss: 0.00004502
Iteration 206/1000 | Loss: 0.00004500
Iteration 207/1000 | Loss: 0.00004500
Iteration 208/1000 | Loss: 0.00004500
Iteration 209/1000 | Loss: 0.00004500
Iteration 210/1000 | Loss: 0.00004500
Iteration 211/1000 | Loss: 0.00004500
Iteration 212/1000 | Loss: 0.00004500
Iteration 213/1000 | Loss: 0.00004500
Iteration 214/1000 | Loss: 0.00004500
Iteration 215/1000 | Loss: 0.00004500
Iteration 216/1000 | Loss: 0.00004500
Iteration 217/1000 | Loss: 0.00004500
Iteration 218/1000 | Loss: 0.00004500
Iteration 219/1000 | Loss: 0.00004499
Iteration 220/1000 | Loss: 0.00004499
Iteration 221/1000 | Loss: 0.00004499
Iteration 222/1000 | Loss: 0.00004498
Iteration 223/1000 | Loss: 0.00004498
Iteration 224/1000 | Loss: 0.00004498
Iteration 225/1000 | Loss: 0.00004498
Iteration 226/1000 | Loss: 0.00004498
Iteration 227/1000 | Loss: 0.00004498
Iteration 228/1000 | Loss: 0.00004497
Iteration 229/1000 | Loss: 0.00004497
Iteration 230/1000 | Loss: 0.00004497
Iteration 231/1000 | Loss: 0.00004497
Iteration 232/1000 | Loss: 0.00004497
Iteration 233/1000 | Loss: 0.00004497
Iteration 234/1000 | Loss: 0.00004496
Iteration 235/1000 | Loss: 0.00004496
Iteration 236/1000 | Loss: 0.00004496
Iteration 237/1000 | Loss: 0.00004496
Iteration 238/1000 | Loss: 0.00004496
Iteration 239/1000 | Loss: 0.00004495
Iteration 240/1000 | Loss: 0.00004495
Iteration 241/1000 | Loss: 0.00004495
Iteration 242/1000 | Loss: 0.00004495
Iteration 243/1000 | Loss: 0.00004495
Iteration 244/1000 | Loss: 0.00004495
Iteration 245/1000 | Loss: 0.00004495
Iteration 246/1000 | Loss: 0.00004495
Iteration 247/1000 | Loss: 0.00004495
Iteration 248/1000 | Loss: 0.00004495
Iteration 249/1000 | Loss: 0.00004495
Iteration 250/1000 | Loss: 0.00004495
Iteration 251/1000 | Loss: 0.00004495
Iteration 252/1000 | Loss: 0.00004495
Iteration 253/1000 | Loss: 0.00004495
Iteration 254/1000 | Loss: 0.00004495
Iteration 255/1000 | Loss: 0.00004495
Iteration 256/1000 | Loss: 0.00004495
Iteration 257/1000 | Loss: 0.00004495
Iteration 258/1000 | Loss: 0.00004495
Iteration 259/1000 | Loss: 0.00004495
Iteration 260/1000 | Loss: 0.00004495
Iteration 261/1000 | Loss: 0.00004495
Iteration 262/1000 | Loss: 0.00004495
Iteration 263/1000 | Loss: 0.00004495
Iteration 264/1000 | Loss: 0.00004495
Iteration 265/1000 | Loss: 0.00004495
Iteration 266/1000 | Loss: 0.00004495
Iteration 267/1000 | Loss: 0.00004495
Iteration 268/1000 | Loss: 0.00004495
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 268. Stopping optimization.
Last 5 losses: [4.49519393441733e-05, 4.49519393441733e-05, 4.49519393441733e-05, 4.49519393441733e-05, 4.49519393441733e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.49519393441733e-05

Optimization complete. Final v2v error: 4.618996620178223 mm

Highest mean error: 24.006967544555664 mm for frame 29

Lowest mean error: 3.721743583679199 mm for frame 6

Saving results

Total time: 264.33776450157166
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00867098
Iteration 2/25 | Loss: 0.00169829
Iteration 3/25 | Loss: 0.00102798
Iteration 4/25 | Loss: 0.00090700
Iteration 5/25 | Loss: 0.00089058
Iteration 6/25 | Loss: 0.00088702
Iteration 7/25 | Loss: 0.00088627
Iteration 8/25 | Loss: 0.00088627
Iteration 9/25 | Loss: 0.00088627
Iteration 10/25 | Loss: 0.00088627
Iteration 11/25 | Loss: 0.00088627
Iteration 12/25 | Loss: 0.00088627
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008862674003466964, 0.0008862674003466964, 0.0008862674003466964, 0.0008862674003466964, 0.0008862674003466964]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008862674003466964

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35586178
Iteration 2/25 | Loss: 0.00044767
Iteration 3/25 | Loss: 0.00044767
Iteration 4/25 | Loss: 0.00044767
Iteration 5/25 | Loss: 0.00044766
Iteration 6/25 | Loss: 0.00044766
Iteration 7/25 | Loss: 0.00044766
Iteration 8/25 | Loss: 0.00044766
Iteration 9/25 | Loss: 0.00044766
Iteration 10/25 | Loss: 0.00044766
Iteration 11/25 | Loss: 0.00044766
Iteration 12/25 | Loss: 0.00044766
Iteration 13/25 | Loss: 0.00044766
Iteration 14/25 | Loss: 0.00044766
Iteration 15/25 | Loss: 0.00044766
Iteration 16/25 | Loss: 0.00044766
Iteration 17/25 | Loss: 0.00044766
Iteration 18/25 | Loss: 0.00044766
Iteration 19/25 | Loss: 0.00044766
Iteration 20/25 | Loss: 0.00044766
Iteration 21/25 | Loss: 0.00044766
Iteration 22/25 | Loss: 0.00044766
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00044766374048776925, 0.00044766374048776925, 0.00044766374048776925, 0.00044766374048776925, 0.00044766374048776925]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00044766374048776925

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044766
Iteration 2/1000 | Loss: 0.00003141
Iteration 3/1000 | Loss: 0.00002438
Iteration 4/1000 | Loss: 0.00002170
Iteration 5/1000 | Loss: 0.00002066
Iteration 6/1000 | Loss: 0.00002016
Iteration 7/1000 | Loss: 0.00001981
Iteration 8/1000 | Loss: 0.00001948
Iteration 9/1000 | Loss: 0.00001926
Iteration 10/1000 | Loss: 0.00001922
Iteration 11/1000 | Loss: 0.00001904
Iteration 12/1000 | Loss: 0.00001898
Iteration 13/1000 | Loss: 0.00001898
Iteration 14/1000 | Loss: 0.00001895
Iteration 15/1000 | Loss: 0.00001893
Iteration 16/1000 | Loss: 0.00001890
Iteration 17/1000 | Loss: 0.00001889
Iteration 18/1000 | Loss: 0.00001887
Iteration 19/1000 | Loss: 0.00001886
Iteration 20/1000 | Loss: 0.00001886
Iteration 21/1000 | Loss: 0.00001886
Iteration 22/1000 | Loss: 0.00001886
Iteration 23/1000 | Loss: 0.00001886
Iteration 24/1000 | Loss: 0.00001886
Iteration 25/1000 | Loss: 0.00001886
Iteration 26/1000 | Loss: 0.00001886
Iteration 27/1000 | Loss: 0.00001886
Iteration 28/1000 | Loss: 0.00001885
Iteration 29/1000 | Loss: 0.00001885
Iteration 30/1000 | Loss: 0.00001885
Iteration 31/1000 | Loss: 0.00001885
Iteration 32/1000 | Loss: 0.00001885
Iteration 33/1000 | Loss: 0.00001885
Iteration 34/1000 | Loss: 0.00001885
Iteration 35/1000 | Loss: 0.00001885
Iteration 36/1000 | Loss: 0.00001885
Iteration 37/1000 | Loss: 0.00001885
Iteration 38/1000 | Loss: 0.00001885
Iteration 39/1000 | Loss: 0.00001885
Iteration 40/1000 | Loss: 0.00001885
Iteration 41/1000 | Loss: 0.00001885
Iteration 42/1000 | Loss: 0.00001885
Iteration 43/1000 | Loss: 0.00001885
Iteration 44/1000 | Loss: 0.00001885
Iteration 45/1000 | Loss: 0.00001885
Iteration 46/1000 | Loss: 0.00001885
Iteration 47/1000 | Loss: 0.00001885
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 47. Stopping optimization.
Last 5 losses: [1.8853432266041636e-05, 1.8853432266041636e-05, 1.8853432266041636e-05, 1.8853432266041636e-05, 1.8853432266041636e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8853432266041636e-05

Optimization complete. Final v2v error: 3.715587615966797 mm

Highest mean error: 4.080674648284912 mm for frame 124

Lowest mean error: 3.4741783142089844 mm for frame 90

Saving results

Total time: 30.694956064224243
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00875162
Iteration 2/25 | Loss: 0.00111866
Iteration 3/25 | Loss: 0.00095219
Iteration 4/25 | Loss: 0.00089518
Iteration 5/25 | Loss: 0.00088526
Iteration 6/25 | Loss: 0.00088309
Iteration 7/25 | Loss: 0.00088284
Iteration 8/25 | Loss: 0.00088284
Iteration 9/25 | Loss: 0.00088284
Iteration 10/25 | Loss: 0.00088284
Iteration 11/25 | Loss: 0.00088284
Iteration 12/25 | Loss: 0.00088284
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008828373393043876, 0.0008828373393043876, 0.0008828373393043876, 0.0008828373393043876, 0.0008828373393043876]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008828373393043876

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26550007
Iteration 2/25 | Loss: 0.00048343
Iteration 3/25 | Loss: 0.00048343
Iteration 4/25 | Loss: 0.00048343
Iteration 5/25 | Loss: 0.00048343
Iteration 6/25 | Loss: 0.00048342
Iteration 7/25 | Loss: 0.00048342
Iteration 8/25 | Loss: 0.00048342
Iteration 9/25 | Loss: 0.00048342
Iteration 10/25 | Loss: 0.00048342
Iteration 11/25 | Loss: 0.00048342
Iteration 12/25 | Loss: 0.00048342
Iteration 13/25 | Loss: 0.00048342
Iteration 14/25 | Loss: 0.00048342
Iteration 15/25 | Loss: 0.00048342
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00048342408263124526, 0.00048342408263124526, 0.00048342408263124526, 0.00048342408263124526, 0.00048342408263124526]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00048342408263124526

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048342
Iteration 2/1000 | Loss: 0.00004395
Iteration 3/1000 | Loss: 0.00002937
Iteration 4/1000 | Loss: 0.00002620
Iteration 5/1000 | Loss: 0.00002547
Iteration 6/1000 | Loss: 0.00002463
Iteration 7/1000 | Loss: 0.00002412
Iteration 8/1000 | Loss: 0.00002364
Iteration 9/1000 | Loss: 0.00002335
Iteration 10/1000 | Loss: 0.00002312
Iteration 11/1000 | Loss: 0.00002300
Iteration 12/1000 | Loss: 0.00002296
Iteration 13/1000 | Loss: 0.00002291
Iteration 14/1000 | Loss: 0.00002288
Iteration 15/1000 | Loss: 0.00002288
Iteration 16/1000 | Loss: 0.00002287
Iteration 17/1000 | Loss: 0.00002287
Iteration 18/1000 | Loss: 0.00002287
Iteration 19/1000 | Loss: 0.00002286
Iteration 20/1000 | Loss: 0.00002286
Iteration 21/1000 | Loss: 0.00002285
Iteration 22/1000 | Loss: 0.00002284
Iteration 23/1000 | Loss: 0.00002284
Iteration 24/1000 | Loss: 0.00002284
Iteration 25/1000 | Loss: 0.00002283
Iteration 26/1000 | Loss: 0.00002283
Iteration 27/1000 | Loss: 0.00002283
Iteration 28/1000 | Loss: 0.00002283
Iteration 29/1000 | Loss: 0.00002283
Iteration 30/1000 | Loss: 0.00002283
Iteration 31/1000 | Loss: 0.00002283
Iteration 32/1000 | Loss: 0.00002283
Iteration 33/1000 | Loss: 0.00002282
Iteration 34/1000 | Loss: 0.00002282
Iteration 35/1000 | Loss: 0.00002282
Iteration 36/1000 | Loss: 0.00002282
Iteration 37/1000 | Loss: 0.00002282
Iteration 38/1000 | Loss: 0.00002282
Iteration 39/1000 | Loss: 0.00002282
Iteration 40/1000 | Loss: 0.00002282
Iteration 41/1000 | Loss: 0.00002282
Iteration 42/1000 | Loss: 0.00002282
Iteration 43/1000 | Loss: 0.00002282
Iteration 44/1000 | Loss: 0.00002282
Iteration 45/1000 | Loss: 0.00002282
Iteration 46/1000 | Loss: 0.00002282
Iteration 47/1000 | Loss: 0.00002282
Iteration 48/1000 | Loss: 0.00002282
Iteration 49/1000 | Loss: 0.00002282
Iteration 50/1000 | Loss: 0.00002282
Iteration 51/1000 | Loss: 0.00002282
Iteration 52/1000 | Loss: 0.00002282
Iteration 53/1000 | Loss: 0.00002282
Iteration 54/1000 | Loss: 0.00002282
Iteration 55/1000 | Loss: 0.00002282
Iteration 56/1000 | Loss: 0.00002282
Iteration 57/1000 | Loss: 0.00002282
Iteration 58/1000 | Loss: 0.00002282
Iteration 59/1000 | Loss: 0.00002282
Iteration 60/1000 | Loss: 0.00002282
Iteration 61/1000 | Loss: 0.00002282
Iteration 62/1000 | Loss: 0.00002282
Iteration 63/1000 | Loss: 0.00002282
Iteration 64/1000 | Loss: 0.00002282
Iteration 65/1000 | Loss: 0.00002282
Iteration 66/1000 | Loss: 0.00002282
Iteration 67/1000 | Loss: 0.00002282
Iteration 68/1000 | Loss: 0.00002282
Iteration 69/1000 | Loss: 0.00002282
Iteration 70/1000 | Loss: 0.00002282
Iteration 71/1000 | Loss: 0.00002282
Iteration 72/1000 | Loss: 0.00002282
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [2.2820564481662586e-05, 2.2820564481662586e-05, 2.2820564481662586e-05, 2.2820564481662586e-05, 2.2820564481662586e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2820564481662586e-05

Optimization complete. Final v2v error: 3.9490163326263428 mm

Highest mean error: 4.349222183227539 mm for frame 20

Lowest mean error: 3.7077274322509766 mm for frame 190

Saving results

Total time: 30.440908908843994
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00437655
Iteration 2/25 | Loss: 0.00100175
Iteration 3/25 | Loss: 0.00078853
Iteration 4/25 | Loss: 0.00075874
Iteration 5/25 | Loss: 0.00075350
Iteration 6/25 | Loss: 0.00075147
Iteration 7/25 | Loss: 0.00075104
Iteration 8/25 | Loss: 0.00075104
Iteration 9/25 | Loss: 0.00075104
Iteration 10/25 | Loss: 0.00075104
Iteration 11/25 | Loss: 0.00075104
Iteration 12/25 | Loss: 0.00075104
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007510359864681959, 0.0007510359864681959, 0.0007510359864681959, 0.0007510359864681959, 0.0007510359864681959]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007510359864681959

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43940353
Iteration 2/25 | Loss: 0.00034220
Iteration 3/25 | Loss: 0.00034219
Iteration 4/25 | Loss: 0.00034219
Iteration 5/25 | Loss: 0.00034219
Iteration 6/25 | Loss: 0.00034219
Iteration 7/25 | Loss: 0.00034219
Iteration 8/25 | Loss: 0.00034219
Iteration 9/25 | Loss: 0.00034219
Iteration 10/25 | Loss: 0.00034219
Iteration 11/25 | Loss: 0.00034219
Iteration 12/25 | Loss: 0.00034219
Iteration 13/25 | Loss: 0.00034219
Iteration 14/25 | Loss: 0.00034219
Iteration 15/25 | Loss: 0.00034219
Iteration 16/25 | Loss: 0.00034219
Iteration 17/25 | Loss: 0.00034219
Iteration 18/25 | Loss: 0.00034219
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003421924193389714, 0.0003421924193389714, 0.0003421924193389714, 0.0003421924193389714, 0.0003421924193389714]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003421924193389714

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034219
Iteration 2/1000 | Loss: 0.00002716
Iteration 3/1000 | Loss: 0.00001966
Iteration 4/1000 | Loss: 0.00001787
Iteration 5/1000 | Loss: 0.00001711
Iteration 6/1000 | Loss: 0.00001654
Iteration 7/1000 | Loss: 0.00001616
Iteration 8/1000 | Loss: 0.00001594
Iteration 9/1000 | Loss: 0.00001582
Iteration 10/1000 | Loss: 0.00001578
Iteration 11/1000 | Loss: 0.00001577
Iteration 12/1000 | Loss: 0.00001576
Iteration 13/1000 | Loss: 0.00001575
Iteration 14/1000 | Loss: 0.00001575
Iteration 15/1000 | Loss: 0.00001574
Iteration 16/1000 | Loss: 0.00001574
Iteration 17/1000 | Loss: 0.00001573
Iteration 18/1000 | Loss: 0.00001572
Iteration 19/1000 | Loss: 0.00001572
Iteration 20/1000 | Loss: 0.00001571
Iteration 21/1000 | Loss: 0.00001570
Iteration 22/1000 | Loss: 0.00001570
Iteration 23/1000 | Loss: 0.00001570
Iteration 24/1000 | Loss: 0.00001570
Iteration 25/1000 | Loss: 0.00001570
Iteration 26/1000 | Loss: 0.00001569
Iteration 27/1000 | Loss: 0.00001569
Iteration 28/1000 | Loss: 0.00001563
Iteration 29/1000 | Loss: 0.00001563
Iteration 30/1000 | Loss: 0.00001562
Iteration 31/1000 | Loss: 0.00001562
Iteration 32/1000 | Loss: 0.00001562
Iteration 33/1000 | Loss: 0.00001561
Iteration 34/1000 | Loss: 0.00001561
Iteration 35/1000 | Loss: 0.00001561
Iteration 36/1000 | Loss: 0.00001560
Iteration 37/1000 | Loss: 0.00001560
Iteration 38/1000 | Loss: 0.00001560
Iteration 39/1000 | Loss: 0.00001559
Iteration 40/1000 | Loss: 0.00001559
Iteration 41/1000 | Loss: 0.00001559
Iteration 42/1000 | Loss: 0.00001558
Iteration 43/1000 | Loss: 0.00001558
Iteration 44/1000 | Loss: 0.00001558
Iteration 45/1000 | Loss: 0.00001557
Iteration 46/1000 | Loss: 0.00001557
Iteration 47/1000 | Loss: 0.00001557
Iteration 48/1000 | Loss: 0.00001557
Iteration 49/1000 | Loss: 0.00001557
Iteration 50/1000 | Loss: 0.00001556
Iteration 51/1000 | Loss: 0.00001555
Iteration 52/1000 | Loss: 0.00001555
Iteration 53/1000 | Loss: 0.00001555
Iteration 54/1000 | Loss: 0.00001555
Iteration 55/1000 | Loss: 0.00001555
Iteration 56/1000 | Loss: 0.00001555
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 56. Stopping optimization.
Last 5 losses: [1.5546787835774012e-05, 1.5546787835774012e-05, 1.5546787835774012e-05, 1.5546787835774012e-05, 1.5546787835774012e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5546787835774012e-05

Optimization complete. Final v2v error: 3.3401265144348145 mm

Highest mean error: 3.5339016914367676 mm for frame 116

Lowest mean error: 3.0341434478759766 mm for frame 10

Saving results

Total time: 28.26206374168396
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01162784
Iteration 2/25 | Loss: 0.00374788
Iteration 3/25 | Loss: 0.00243229
Iteration 4/25 | Loss: 0.00197252
Iteration 5/25 | Loss: 0.00189283
Iteration 6/25 | Loss: 0.00221754
Iteration 7/25 | Loss: 0.00227780
Iteration 8/25 | Loss: 0.00150286
Iteration 9/25 | Loss: 0.00137222
Iteration 10/25 | Loss: 0.00130533
Iteration 11/25 | Loss: 0.00127332
Iteration 12/25 | Loss: 0.00125081
Iteration 13/25 | Loss: 0.00123271
Iteration 14/25 | Loss: 0.00122956
Iteration 15/25 | Loss: 0.00122580
Iteration 16/25 | Loss: 0.00122885
Iteration 17/25 | Loss: 0.00122822
Iteration 18/25 | Loss: 0.00123509
Iteration 19/25 | Loss: 0.00124191
Iteration 20/25 | Loss: 0.00121338
Iteration 21/25 | Loss: 0.00120223
Iteration 22/25 | Loss: 0.00118700
Iteration 23/25 | Loss: 0.00117974
Iteration 24/25 | Loss: 0.00117708
Iteration 25/25 | Loss: 0.00117657

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.64799148
Iteration 2/25 | Loss: 0.00050817
Iteration 3/25 | Loss: 0.00050817
Iteration 4/25 | Loss: 0.00050817
Iteration 5/25 | Loss: 0.00050817
Iteration 6/25 | Loss: 0.00050817
Iteration 7/25 | Loss: 0.00050817
Iteration 8/25 | Loss: 0.00050817
Iteration 9/25 | Loss: 0.00050817
Iteration 10/25 | Loss: 0.00050817
Iteration 11/25 | Loss: 0.00050817
Iteration 12/25 | Loss: 0.00050817
Iteration 13/25 | Loss: 0.00050817
Iteration 14/25 | Loss: 0.00050817
Iteration 15/25 | Loss: 0.00050817
Iteration 16/25 | Loss: 0.00050817
Iteration 17/25 | Loss: 0.00050817
Iteration 18/25 | Loss: 0.00050817
Iteration 19/25 | Loss: 0.00050817
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0005081719136796892, 0.0005081719136796892, 0.0005081719136796892, 0.0005081719136796892, 0.0005081719136796892]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005081719136796892

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050817
Iteration 2/1000 | Loss: 0.00012494
Iteration 3/1000 | Loss: 0.00009190
Iteration 4/1000 | Loss: 0.00008158
Iteration 5/1000 | Loss: 0.00007889
Iteration 6/1000 | Loss: 0.00007666
Iteration 7/1000 | Loss: 0.00007510
Iteration 8/1000 | Loss: 0.00007390
Iteration 9/1000 | Loss: 0.00007301
Iteration 10/1000 | Loss: 0.00007232
Iteration 11/1000 | Loss: 0.00007193
Iteration 12/1000 | Loss: 0.00007160
Iteration 13/1000 | Loss: 0.00007136
Iteration 14/1000 | Loss: 0.00007119
Iteration 15/1000 | Loss: 0.00007112
Iteration 16/1000 | Loss: 0.00007106
Iteration 17/1000 | Loss: 0.00007098
Iteration 18/1000 | Loss: 0.00007084
Iteration 19/1000 | Loss: 0.00007070
Iteration 20/1000 | Loss: 0.00007060
Iteration 21/1000 | Loss: 0.00007054
Iteration 22/1000 | Loss: 0.00007043
Iteration 23/1000 | Loss: 0.00007042
Iteration 24/1000 | Loss: 0.00007042
Iteration 25/1000 | Loss: 0.00007041
Iteration 26/1000 | Loss: 0.00007041
Iteration 27/1000 | Loss: 0.00007040
Iteration 28/1000 | Loss: 0.00007038
Iteration 29/1000 | Loss: 0.00007037
Iteration 30/1000 | Loss: 0.00007036
Iteration 31/1000 | Loss: 0.00007036
Iteration 32/1000 | Loss: 0.00007036
Iteration 33/1000 | Loss: 0.00007036
Iteration 34/1000 | Loss: 0.00007036
Iteration 35/1000 | Loss: 0.00007036
Iteration 36/1000 | Loss: 0.00007036
Iteration 37/1000 | Loss: 0.00007036
Iteration 38/1000 | Loss: 0.00007036
Iteration 39/1000 | Loss: 0.00007036
Iteration 40/1000 | Loss: 0.00007036
Iteration 41/1000 | Loss: 0.00007034
Iteration 42/1000 | Loss: 0.00007034
Iteration 43/1000 | Loss: 0.00007033
Iteration 44/1000 | Loss: 0.00007033
Iteration 45/1000 | Loss: 0.00007033
Iteration 46/1000 | Loss: 0.00007033
Iteration 47/1000 | Loss: 0.00007032
Iteration 48/1000 | Loss: 0.00007031
Iteration 49/1000 | Loss: 0.00007030
Iteration 50/1000 | Loss: 0.00007030
Iteration 51/1000 | Loss: 0.00007030
Iteration 52/1000 | Loss: 0.00007030
Iteration 53/1000 | Loss: 0.00007029
Iteration 54/1000 | Loss: 0.00007029
Iteration 55/1000 | Loss: 0.00007029
Iteration 56/1000 | Loss: 0.00007028
Iteration 57/1000 | Loss: 0.00007028
Iteration 58/1000 | Loss: 0.00007027
Iteration 59/1000 | Loss: 0.00007027
Iteration 60/1000 | Loss: 0.00007027
Iteration 61/1000 | Loss: 0.00007027
Iteration 62/1000 | Loss: 0.00007027
Iteration 63/1000 | Loss: 0.00007027
Iteration 64/1000 | Loss: 0.00007027
Iteration 65/1000 | Loss: 0.00007027
Iteration 66/1000 | Loss: 0.00007027
Iteration 67/1000 | Loss: 0.00007027
Iteration 68/1000 | Loss: 0.00007026
Iteration 69/1000 | Loss: 0.00007026
Iteration 70/1000 | Loss: 0.00007026
Iteration 71/1000 | Loss: 0.00007025
Iteration 72/1000 | Loss: 0.00007025
Iteration 73/1000 | Loss: 0.00007025
Iteration 74/1000 | Loss: 0.00007025
Iteration 75/1000 | Loss: 0.00007025
Iteration 76/1000 | Loss: 0.00007025
Iteration 77/1000 | Loss: 0.00007025
Iteration 78/1000 | Loss: 0.00007025
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 78. Stopping optimization.
Last 5 losses: [7.025381637504324e-05, 7.025381637504324e-05, 7.025381637504324e-05, 7.025381637504324e-05, 7.025381637504324e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 7.025381637504324e-05

Optimization complete. Final v2v error: 6.065244197845459 mm

Highest mean error: 7.198235034942627 mm for frame 233

Lowest mean error: 3.9265403747558594 mm for frame 57

Saving results

Total time: 90.94286060333252
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01052221
Iteration 2/25 | Loss: 0.00331857
Iteration 3/25 | Loss: 0.00221336
Iteration 4/25 | Loss: 0.00214710
Iteration 5/25 | Loss: 0.00177538
Iteration 6/25 | Loss: 0.00169692
Iteration 7/25 | Loss: 0.00168123
Iteration 8/25 | Loss: 0.00172209
Iteration 9/25 | Loss: 0.00167531
Iteration 10/25 | Loss: 0.00166127
Iteration 11/25 | Loss: 0.00167041
Iteration 12/25 | Loss: 0.00164386
Iteration 13/25 | Loss: 0.00164038
Iteration 14/25 | Loss: 0.00163443
Iteration 15/25 | Loss: 0.00163799
Iteration 16/25 | Loss: 0.00163397
Iteration 17/25 | Loss: 0.00163394
Iteration 18/25 | Loss: 0.00163394
Iteration 19/25 | Loss: 0.00163394
Iteration 20/25 | Loss: 0.00163394
Iteration 21/25 | Loss: 0.00163394
Iteration 22/25 | Loss: 0.00163394
Iteration 23/25 | Loss: 0.00163394
Iteration 24/25 | Loss: 0.00163394
Iteration 25/25 | Loss: 0.00163394

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39504242
Iteration 2/25 | Loss: 0.01084062
Iteration 3/25 | Loss: 0.00649088
Iteration 4/25 | Loss: 0.00649037
Iteration 5/25 | Loss: 0.00649037
Iteration 6/25 | Loss: 0.00649036
Iteration 7/25 | Loss: 0.00649036
Iteration 8/25 | Loss: 0.00649036
Iteration 9/25 | Loss: 0.00649036
Iteration 10/25 | Loss: 0.00649036
Iteration 11/25 | Loss: 0.00649036
Iteration 12/25 | Loss: 0.00649036
Iteration 13/25 | Loss: 0.00649036
Iteration 14/25 | Loss: 0.00649036
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.006490363273769617, 0.006490363273769617, 0.006490363273769617, 0.006490363273769617, 0.006490363273769617]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006490363273769617

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00649036
Iteration 2/1000 | Loss: 0.01100944
Iteration 3/1000 | Loss: 0.00106508
Iteration 4/1000 | Loss: 0.00411426
Iteration 5/1000 | Loss: 0.00791088
Iteration 6/1000 | Loss: 0.00064153
Iteration 7/1000 | Loss: 0.00053555
Iteration 8/1000 | Loss: 0.00047877
Iteration 9/1000 | Loss: 0.00335250
Iteration 10/1000 | Loss: 0.00189213
Iteration 11/1000 | Loss: 0.01392854
Iteration 12/1000 | Loss: 0.01251523
Iteration 13/1000 | Loss: 0.02092653
Iteration 14/1000 | Loss: 0.01238089
Iteration 15/1000 | Loss: 0.00160880
Iteration 16/1000 | Loss: 0.00129339
Iteration 17/1000 | Loss: 0.00030688
Iteration 18/1000 | Loss: 0.00068531
Iteration 19/1000 | Loss: 0.00031591
Iteration 20/1000 | Loss: 0.00038024
Iteration 21/1000 | Loss: 0.00010756
Iteration 22/1000 | Loss: 0.00011554
Iteration 23/1000 | Loss: 0.00031556
Iteration 24/1000 | Loss: 0.00017936
Iteration 25/1000 | Loss: 0.00024656
Iteration 26/1000 | Loss: 0.00049495
Iteration 27/1000 | Loss: 0.00018296
Iteration 28/1000 | Loss: 0.00479995
Iteration 29/1000 | Loss: 0.00075548
Iteration 30/1000 | Loss: 0.00041168
Iteration 31/1000 | Loss: 0.00007028
Iteration 32/1000 | Loss: 0.00046028
Iteration 33/1000 | Loss: 0.00330829
Iteration 34/1000 | Loss: 0.00082993
Iteration 35/1000 | Loss: 0.00245842
Iteration 36/1000 | Loss: 0.00161649
Iteration 37/1000 | Loss: 0.00057519
Iteration 38/1000 | Loss: 0.00016656
Iteration 39/1000 | Loss: 0.00021008
Iteration 40/1000 | Loss: 0.00007947
Iteration 41/1000 | Loss: 0.00004245
Iteration 42/1000 | Loss: 0.00005680
Iteration 43/1000 | Loss: 0.00008387
Iteration 44/1000 | Loss: 0.00006817
Iteration 45/1000 | Loss: 0.00021577
Iteration 46/1000 | Loss: 0.00020354
Iteration 47/1000 | Loss: 0.00007418
Iteration 48/1000 | Loss: 0.00007634
Iteration 49/1000 | Loss: 0.00070194
Iteration 50/1000 | Loss: 0.00019907
Iteration 51/1000 | Loss: 0.00007313
Iteration 52/1000 | Loss: 0.00015721
Iteration 53/1000 | Loss: 0.00002383
Iteration 54/1000 | Loss: 0.00002294
Iteration 55/1000 | Loss: 0.00013882
Iteration 56/1000 | Loss: 0.00134041
Iteration 57/1000 | Loss: 0.00009383
Iteration 58/1000 | Loss: 0.00014109
Iteration 59/1000 | Loss: 0.00026460
Iteration 60/1000 | Loss: 0.00007539
Iteration 61/1000 | Loss: 0.00003200
Iteration 62/1000 | Loss: 0.00008343
Iteration 63/1000 | Loss: 0.00030164
Iteration 64/1000 | Loss: 0.00005994
Iteration 65/1000 | Loss: 0.00005835
Iteration 66/1000 | Loss: 0.00002253
Iteration 67/1000 | Loss: 0.00002219
Iteration 68/1000 | Loss: 0.00002204
Iteration 69/1000 | Loss: 0.00007747
Iteration 70/1000 | Loss: 0.00007747
Iteration 71/1000 | Loss: 0.00024961
Iteration 72/1000 | Loss: 0.00003769
Iteration 73/1000 | Loss: 0.00003719
Iteration 74/1000 | Loss: 0.00005932
Iteration 75/1000 | Loss: 0.00002199
Iteration 76/1000 | Loss: 0.00002196
Iteration 77/1000 | Loss: 0.00002195
Iteration 78/1000 | Loss: 0.00002195
Iteration 79/1000 | Loss: 0.00002195
Iteration 80/1000 | Loss: 0.00002195
Iteration 81/1000 | Loss: 0.00002195
Iteration 82/1000 | Loss: 0.00002195
Iteration 83/1000 | Loss: 0.00002195
Iteration 84/1000 | Loss: 0.00002195
Iteration 85/1000 | Loss: 0.00002195
Iteration 86/1000 | Loss: 0.00002195
Iteration 87/1000 | Loss: 0.00002195
Iteration 88/1000 | Loss: 0.00002195
Iteration 89/1000 | Loss: 0.00002195
Iteration 90/1000 | Loss: 0.00002195
Iteration 91/1000 | Loss: 0.00002195
Iteration 92/1000 | Loss: 0.00002195
Iteration 93/1000 | Loss: 0.00004046
Iteration 94/1000 | Loss: 0.00002199
Iteration 95/1000 | Loss: 0.00002194
Iteration 96/1000 | Loss: 0.00002194
Iteration 97/1000 | Loss: 0.00002194
Iteration 98/1000 | Loss: 0.00002194
Iteration 99/1000 | Loss: 0.00002194
Iteration 100/1000 | Loss: 0.00002194
Iteration 101/1000 | Loss: 0.00002194
Iteration 102/1000 | Loss: 0.00002194
Iteration 103/1000 | Loss: 0.00002194
Iteration 104/1000 | Loss: 0.00002194
Iteration 105/1000 | Loss: 0.00002193
Iteration 106/1000 | Loss: 0.00002193
Iteration 107/1000 | Loss: 0.00002193
Iteration 108/1000 | Loss: 0.00002192
Iteration 109/1000 | Loss: 0.00002192
Iteration 110/1000 | Loss: 0.00002192
Iteration 111/1000 | Loss: 0.00002192
Iteration 112/1000 | Loss: 0.00002191
Iteration 113/1000 | Loss: 0.00002191
Iteration 114/1000 | Loss: 0.00002191
Iteration 115/1000 | Loss: 0.00002191
Iteration 116/1000 | Loss: 0.00002191
Iteration 117/1000 | Loss: 0.00002191
Iteration 118/1000 | Loss: 0.00002191
Iteration 119/1000 | Loss: 0.00002190
Iteration 120/1000 | Loss: 0.00002190
Iteration 121/1000 | Loss: 0.00002190
Iteration 122/1000 | Loss: 0.00002190
Iteration 123/1000 | Loss: 0.00002190
Iteration 124/1000 | Loss: 0.00002190
Iteration 125/1000 | Loss: 0.00002190
Iteration 126/1000 | Loss: 0.00002190
Iteration 127/1000 | Loss: 0.00002190
Iteration 128/1000 | Loss: 0.00002190
Iteration 129/1000 | Loss: 0.00002190
Iteration 130/1000 | Loss: 0.00002190
Iteration 131/1000 | Loss: 0.00002190
Iteration 132/1000 | Loss: 0.00002189
Iteration 133/1000 | Loss: 0.00002189
Iteration 134/1000 | Loss: 0.00002189
Iteration 135/1000 | Loss: 0.00002189
Iteration 136/1000 | Loss: 0.00002189
Iteration 137/1000 | Loss: 0.00002189
Iteration 138/1000 | Loss: 0.00002189
Iteration 139/1000 | Loss: 0.00002189
Iteration 140/1000 | Loss: 0.00002189
Iteration 141/1000 | Loss: 0.00002189
Iteration 142/1000 | Loss: 0.00002189
Iteration 143/1000 | Loss: 0.00002189
Iteration 144/1000 | Loss: 0.00002189
Iteration 145/1000 | Loss: 0.00002189
Iteration 146/1000 | Loss: 0.00002189
Iteration 147/1000 | Loss: 0.00002189
Iteration 148/1000 | Loss: 0.00002189
Iteration 149/1000 | Loss: 0.00002189
Iteration 150/1000 | Loss: 0.00002189
Iteration 151/1000 | Loss: 0.00002189
Iteration 152/1000 | Loss: 0.00002189
Iteration 153/1000 | Loss: 0.00002189
Iteration 154/1000 | Loss: 0.00002189
Iteration 155/1000 | Loss: 0.00002189
Iteration 156/1000 | Loss: 0.00002189
Iteration 157/1000 | Loss: 0.00002189
Iteration 158/1000 | Loss: 0.00002189
Iteration 159/1000 | Loss: 0.00002189
Iteration 160/1000 | Loss: 0.00002189
Iteration 161/1000 | Loss: 0.00002189
Iteration 162/1000 | Loss: 0.00002189
Iteration 163/1000 | Loss: 0.00002189
Iteration 164/1000 | Loss: 0.00002189
Iteration 165/1000 | Loss: 0.00002189
Iteration 166/1000 | Loss: 0.00002189
Iteration 167/1000 | Loss: 0.00002189
Iteration 168/1000 | Loss: 0.00002189
Iteration 169/1000 | Loss: 0.00002189
Iteration 170/1000 | Loss: 0.00002189
Iteration 171/1000 | Loss: 0.00002189
Iteration 172/1000 | Loss: 0.00002189
Iteration 173/1000 | Loss: 0.00002189
Iteration 174/1000 | Loss: 0.00002189
Iteration 175/1000 | Loss: 0.00002189
Iteration 176/1000 | Loss: 0.00002189
Iteration 177/1000 | Loss: 0.00002189
Iteration 178/1000 | Loss: 0.00002189
Iteration 179/1000 | Loss: 0.00002189
Iteration 180/1000 | Loss: 0.00002189
Iteration 181/1000 | Loss: 0.00002189
Iteration 182/1000 | Loss: 0.00002189
Iteration 183/1000 | Loss: 0.00002189
Iteration 184/1000 | Loss: 0.00002189
Iteration 185/1000 | Loss: 0.00002189
Iteration 186/1000 | Loss: 0.00002189
Iteration 187/1000 | Loss: 0.00002189
Iteration 188/1000 | Loss: 0.00002189
Iteration 189/1000 | Loss: 0.00002189
Iteration 190/1000 | Loss: 0.00002189
Iteration 191/1000 | Loss: 0.00002189
Iteration 192/1000 | Loss: 0.00002189
Iteration 193/1000 | Loss: 0.00002189
Iteration 194/1000 | Loss: 0.00002189
Iteration 195/1000 | Loss: 0.00002189
Iteration 196/1000 | Loss: 0.00002189
Iteration 197/1000 | Loss: 0.00002189
Iteration 198/1000 | Loss: 0.00002189
Iteration 199/1000 | Loss: 0.00002189
Iteration 200/1000 | Loss: 0.00002189
Iteration 201/1000 | Loss: 0.00002189
Iteration 202/1000 | Loss: 0.00002189
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 202. Stopping optimization.
Last 5 losses: [2.1890660718781874e-05, 2.1890660718781874e-05, 2.1890660718781874e-05, 2.1890660718781874e-05, 2.1890660718781874e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1890660718781874e-05

Optimization complete. Final v2v error: 4.0039896965026855 mm

Highest mean error: 4.1535162925720215 mm for frame 54

Lowest mean error: 3.839890718460083 mm for frame 39

Saving results

Total time: 160.90481662750244
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00906201
Iteration 2/25 | Loss: 0.00275023
Iteration 3/25 | Loss: 0.00177100
Iteration 4/25 | Loss: 0.00133654
Iteration 5/25 | Loss: 0.00125307
Iteration 6/25 | Loss: 0.00113158
Iteration 7/25 | Loss: 0.00111947
Iteration 8/25 | Loss: 0.00108264
Iteration 9/25 | Loss: 0.00106521
Iteration 10/25 | Loss: 0.00105497
Iteration 11/25 | Loss: 0.00104303
Iteration 12/25 | Loss: 0.00104567
Iteration 13/25 | Loss: 0.00104506
Iteration 14/25 | Loss: 0.00103618
Iteration 15/25 | Loss: 0.00103943
Iteration 16/25 | Loss: 0.00103319
Iteration 17/25 | Loss: 0.00103270
Iteration 18/25 | Loss: 0.00103210
Iteration 19/25 | Loss: 0.00103189
Iteration 20/25 | Loss: 0.00103168
Iteration 21/25 | Loss: 0.00103127
Iteration 22/25 | Loss: 0.00103057
Iteration 23/25 | Loss: 0.00102975
Iteration 24/25 | Loss: 0.00102929
Iteration 25/25 | Loss: 0.00102885

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.50706196
Iteration 2/25 | Loss: 0.00314971
Iteration 3/25 | Loss: 0.00296244
Iteration 4/25 | Loss: 0.00296244
Iteration 5/25 | Loss: 0.00296244
Iteration 6/25 | Loss: 0.00296244
Iteration 7/25 | Loss: 0.00296244
Iteration 8/25 | Loss: 0.00296244
Iteration 9/25 | Loss: 0.00296244
Iteration 10/25 | Loss: 0.00296244
Iteration 11/25 | Loss: 0.00296244
Iteration 12/25 | Loss: 0.00296244
Iteration 13/25 | Loss: 0.00296244
Iteration 14/25 | Loss: 0.00296244
Iteration 15/25 | Loss: 0.00296244
Iteration 16/25 | Loss: 0.00296244
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.002962439088150859, 0.002962439088150859, 0.002962439088150859, 0.002962439088150859, 0.002962439088150859]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002962439088150859

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00296244
Iteration 2/1000 | Loss: 0.00210478
Iteration 3/1000 | Loss: 0.00103257
Iteration 4/1000 | Loss: 0.00650604
Iteration 5/1000 | Loss: 0.00492123
Iteration 6/1000 | Loss: 0.00286022
Iteration 7/1000 | Loss: 0.00090762
Iteration 8/1000 | Loss: 0.00226674
Iteration 9/1000 | Loss: 0.00029812
Iteration 10/1000 | Loss: 0.00027302
Iteration 11/1000 | Loss: 0.00011093
Iteration 12/1000 | Loss: 0.00085462
Iteration 13/1000 | Loss: 0.00386258
Iteration 14/1000 | Loss: 0.00243151
Iteration 15/1000 | Loss: 0.00214526
Iteration 16/1000 | Loss: 0.00028989
Iteration 17/1000 | Loss: 0.00020204
Iteration 18/1000 | Loss: 0.00114529
Iteration 19/1000 | Loss: 0.00063295
Iteration 20/1000 | Loss: 0.00094656
Iteration 21/1000 | Loss: 0.00058488
Iteration 22/1000 | Loss: 0.00091125
Iteration 23/1000 | Loss: 0.00084259
Iteration 24/1000 | Loss: 0.00080441
Iteration 25/1000 | Loss: 0.00121339
Iteration 26/1000 | Loss: 0.00093666
Iteration 27/1000 | Loss: 0.00012317
Iteration 28/1000 | Loss: 0.00008079
Iteration 29/1000 | Loss: 0.00062140
Iteration 30/1000 | Loss: 0.00035010
Iteration 31/1000 | Loss: 0.00007090
Iteration 32/1000 | Loss: 0.00039547
Iteration 33/1000 | Loss: 0.00070569
Iteration 34/1000 | Loss: 0.00065261
Iteration 35/1000 | Loss: 0.00018015
Iteration 36/1000 | Loss: 0.00031884
Iteration 37/1000 | Loss: 0.00032113
Iteration 38/1000 | Loss: 0.00005149
Iteration 39/1000 | Loss: 0.00037122
Iteration 40/1000 | Loss: 0.00016302
Iteration 41/1000 | Loss: 0.00044769
Iteration 42/1000 | Loss: 0.00031328
Iteration 43/1000 | Loss: 0.00023624
Iteration 44/1000 | Loss: 0.00056046
Iteration 45/1000 | Loss: 0.00010114
Iteration 46/1000 | Loss: 0.00056842
Iteration 47/1000 | Loss: 0.00114734
Iteration 48/1000 | Loss: 0.00064278
Iteration 49/1000 | Loss: 0.00031503
Iteration 50/1000 | Loss: 0.00041261
Iteration 51/1000 | Loss: 0.00041145
Iteration 52/1000 | Loss: 0.00058864
Iteration 53/1000 | Loss: 0.00068954
Iteration 54/1000 | Loss: 0.00033450
Iteration 55/1000 | Loss: 0.00053128
Iteration 56/1000 | Loss: 0.00050128
Iteration 57/1000 | Loss: 0.00064164
Iteration 58/1000 | Loss: 0.00056472
Iteration 59/1000 | Loss: 0.00045108
Iteration 60/1000 | Loss: 0.00063076
Iteration 61/1000 | Loss: 0.00015073
Iteration 62/1000 | Loss: 0.00011078
Iteration 63/1000 | Loss: 0.00004689
Iteration 64/1000 | Loss: 0.00004127
Iteration 65/1000 | Loss: 0.00051806
Iteration 66/1000 | Loss: 0.00037998
Iteration 67/1000 | Loss: 0.00016456
Iteration 68/1000 | Loss: 0.00003529
Iteration 69/1000 | Loss: 0.00003348
Iteration 70/1000 | Loss: 0.00025163
Iteration 71/1000 | Loss: 0.00003244
Iteration 72/1000 | Loss: 0.00092490
Iteration 73/1000 | Loss: 0.00033406
Iteration 74/1000 | Loss: 0.00004357
Iteration 75/1000 | Loss: 0.00003224
Iteration 76/1000 | Loss: 0.00002911
Iteration 77/1000 | Loss: 0.00002711
Iteration 78/1000 | Loss: 0.00021212
Iteration 79/1000 | Loss: 0.00003586
Iteration 80/1000 | Loss: 0.00019596
Iteration 81/1000 | Loss: 0.00010861
Iteration 82/1000 | Loss: 0.00002664
Iteration 83/1000 | Loss: 0.00023409
Iteration 84/1000 | Loss: 0.00003271
Iteration 85/1000 | Loss: 0.00002796
Iteration 86/1000 | Loss: 0.00002547
Iteration 87/1000 | Loss: 0.00002468
Iteration 88/1000 | Loss: 0.00002445
Iteration 89/1000 | Loss: 0.00002443
Iteration 90/1000 | Loss: 0.00002418
Iteration 91/1000 | Loss: 0.00016651
Iteration 92/1000 | Loss: 0.00003281
Iteration 93/1000 | Loss: 0.00017754
Iteration 94/1000 | Loss: 0.00011832
Iteration 95/1000 | Loss: 0.00002398
Iteration 96/1000 | Loss: 0.00064146
Iteration 97/1000 | Loss: 0.00028785
Iteration 98/1000 | Loss: 0.00020454
Iteration 99/1000 | Loss: 0.00002488
Iteration 100/1000 | Loss: 0.00002386
Iteration 101/1000 | Loss: 0.00002357
Iteration 102/1000 | Loss: 0.00002355
Iteration 103/1000 | Loss: 0.00002349
Iteration 104/1000 | Loss: 0.00002345
Iteration 105/1000 | Loss: 0.00002345
Iteration 106/1000 | Loss: 0.00002344
Iteration 107/1000 | Loss: 0.00002343
Iteration 108/1000 | Loss: 0.00002343
Iteration 109/1000 | Loss: 0.00002343
Iteration 110/1000 | Loss: 0.00002342
Iteration 111/1000 | Loss: 0.00002341
Iteration 112/1000 | Loss: 0.00002341
Iteration 113/1000 | Loss: 0.00002340
Iteration 114/1000 | Loss: 0.00002340
Iteration 115/1000 | Loss: 0.00002339
Iteration 116/1000 | Loss: 0.00002338
Iteration 117/1000 | Loss: 0.00016625
Iteration 118/1000 | Loss: 0.00038388
Iteration 119/1000 | Loss: 0.00003034
Iteration 120/1000 | Loss: 0.00031819
Iteration 121/1000 | Loss: 0.00009346
Iteration 122/1000 | Loss: 0.00022871
Iteration 123/1000 | Loss: 0.00025162
Iteration 124/1000 | Loss: 0.00016543
Iteration 125/1000 | Loss: 0.00010485
Iteration 126/1000 | Loss: 0.00010946
Iteration 127/1000 | Loss: 0.00003029
Iteration 128/1000 | Loss: 0.00002821
Iteration 129/1000 | Loss: 0.00019714
Iteration 130/1000 | Loss: 0.00046590
Iteration 131/1000 | Loss: 0.00054757
Iteration 132/1000 | Loss: 0.00009747
Iteration 133/1000 | Loss: 0.00004430
Iteration 134/1000 | Loss: 0.00002967
Iteration 135/1000 | Loss: 0.00059820
Iteration 136/1000 | Loss: 0.00085527
Iteration 137/1000 | Loss: 0.00061854
Iteration 138/1000 | Loss: 0.00008263
Iteration 139/1000 | Loss: 0.00049420
Iteration 140/1000 | Loss: 0.00048774
Iteration 141/1000 | Loss: 0.00057747
Iteration 142/1000 | Loss: 0.00011320
Iteration 143/1000 | Loss: 0.00063562
Iteration 144/1000 | Loss: 0.00049128
Iteration 145/1000 | Loss: 0.00088186
Iteration 146/1000 | Loss: 0.00006292
Iteration 147/1000 | Loss: 0.00007174
Iteration 148/1000 | Loss: 0.00004057
Iteration 149/1000 | Loss: 0.00088565
Iteration 150/1000 | Loss: 0.00076353
Iteration 151/1000 | Loss: 0.00068741
Iteration 152/1000 | Loss: 0.00077659
Iteration 153/1000 | Loss: 0.00085580
Iteration 154/1000 | Loss: 0.00006504
Iteration 155/1000 | Loss: 0.00003977
Iteration 156/1000 | Loss: 0.00033244
Iteration 157/1000 | Loss: 0.00066201
Iteration 158/1000 | Loss: 0.00034319
Iteration 159/1000 | Loss: 0.00108038
Iteration 160/1000 | Loss: 0.00065951
Iteration 161/1000 | Loss: 0.00004126
Iteration 162/1000 | Loss: 0.00022505
Iteration 163/1000 | Loss: 0.00036725
Iteration 164/1000 | Loss: 0.00048498
Iteration 165/1000 | Loss: 0.00009168
Iteration 166/1000 | Loss: 0.00009660
Iteration 167/1000 | Loss: 0.00002547
Iteration 168/1000 | Loss: 0.00002443
Iteration 169/1000 | Loss: 0.00024471
Iteration 170/1000 | Loss: 0.00002339
Iteration 171/1000 | Loss: 0.00002254
Iteration 172/1000 | Loss: 0.00003641
Iteration 173/1000 | Loss: 0.00002824
Iteration 174/1000 | Loss: 0.00003534
Iteration 175/1000 | Loss: 0.00020715
Iteration 176/1000 | Loss: 0.00006198
Iteration 177/1000 | Loss: 0.00008327
Iteration 178/1000 | Loss: 0.00002310
Iteration 179/1000 | Loss: 0.00012045
Iteration 180/1000 | Loss: 0.00002175
Iteration 181/1000 | Loss: 0.00002099
Iteration 182/1000 | Loss: 0.00002077
Iteration 183/1000 | Loss: 0.00002056
Iteration 184/1000 | Loss: 0.00002051
Iteration 185/1000 | Loss: 0.00002045
Iteration 186/1000 | Loss: 0.00002027
Iteration 187/1000 | Loss: 0.00002026
Iteration 188/1000 | Loss: 0.00002024
Iteration 189/1000 | Loss: 0.00002018
Iteration 190/1000 | Loss: 0.00002010
Iteration 191/1000 | Loss: 0.00002002
Iteration 192/1000 | Loss: 0.00001998
Iteration 193/1000 | Loss: 0.00001997
Iteration 194/1000 | Loss: 0.00001997
Iteration 195/1000 | Loss: 0.00001996
Iteration 196/1000 | Loss: 0.00001995
Iteration 197/1000 | Loss: 0.00001995
Iteration 198/1000 | Loss: 0.00001994
Iteration 199/1000 | Loss: 0.00001993
Iteration 200/1000 | Loss: 0.00001993
Iteration 201/1000 | Loss: 0.00001992
Iteration 202/1000 | Loss: 0.00001992
Iteration 203/1000 | Loss: 0.00001992
Iteration 204/1000 | Loss: 0.00001991
Iteration 205/1000 | Loss: 0.00001991
Iteration 206/1000 | Loss: 0.00001991
Iteration 207/1000 | Loss: 0.00001990
Iteration 208/1000 | Loss: 0.00001990
Iteration 209/1000 | Loss: 0.00001990
Iteration 210/1000 | Loss: 0.00001989
Iteration 211/1000 | Loss: 0.00001989
Iteration 212/1000 | Loss: 0.00001989
Iteration 213/1000 | Loss: 0.00001988
Iteration 214/1000 | Loss: 0.00001988
Iteration 215/1000 | Loss: 0.00001988
Iteration 216/1000 | Loss: 0.00001988
Iteration 217/1000 | Loss: 0.00001988
Iteration 218/1000 | Loss: 0.00001988
Iteration 219/1000 | Loss: 0.00001987
Iteration 220/1000 | Loss: 0.00001987
Iteration 221/1000 | Loss: 0.00001987
Iteration 222/1000 | Loss: 0.00001987
Iteration 223/1000 | Loss: 0.00001987
Iteration 224/1000 | Loss: 0.00001987
Iteration 225/1000 | Loss: 0.00001987
Iteration 226/1000 | Loss: 0.00001986
Iteration 227/1000 | Loss: 0.00001986
Iteration 228/1000 | Loss: 0.00001986
Iteration 229/1000 | Loss: 0.00001986
Iteration 230/1000 | Loss: 0.00001986
Iteration 231/1000 | Loss: 0.00001986
Iteration 232/1000 | Loss: 0.00001986
Iteration 233/1000 | Loss: 0.00001986
Iteration 234/1000 | Loss: 0.00001985
Iteration 235/1000 | Loss: 0.00001985
Iteration 236/1000 | Loss: 0.00001985
Iteration 237/1000 | Loss: 0.00001985
Iteration 238/1000 | Loss: 0.00001985
Iteration 239/1000 | Loss: 0.00001985
Iteration 240/1000 | Loss: 0.00001985
Iteration 241/1000 | Loss: 0.00001985
Iteration 242/1000 | Loss: 0.00001985
Iteration 243/1000 | Loss: 0.00001985
Iteration 244/1000 | Loss: 0.00001985
Iteration 245/1000 | Loss: 0.00001985
Iteration 246/1000 | Loss: 0.00001985
Iteration 247/1000 | Loss: 0.00001985
Iteration 248/1000 | Loss: 0.00001985
Iteration 249/1000 | Loss: 0.00001985
Iteration 250/1000 | Loss: 0.00001985
Iteration 251/1000 | Loss: 0.00001984
Iteration 252/1000 | Loss: 0.00001984
Iteration 253/1000 | Loss: 0.00001984
Iteration 254/1000 | Loss: 0.00001984
Iteration 255/1000 | Loss: 0.00001984
Iteration 256/1000 | Loss: 0.00001984
Iteration 257/1000 | Loss: 0.00001984
Iteration 258/1000 | Loss: 0.00001984
Iteration 259/1000 | Loss: 0.00001984
Iteration 260/1000 | Loss: 0.00001984
Iteration 261/1000 | Loss: 0.00001984
Iteration 262/1000 | Loss: 0.00001984
Iteration 263/1000 | Loss: 0.00001984
Iteration 264/1000 | Loss: 0.00001984
Iteration 265/1000 | Loss: 0.00001984
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 265. Stopping optimization.
Last 5 losses: [1.984011942113284e-05, 1.984011942113284e-05, 1.984011942113284e-05, 1.984011942113284e-05, 1.984011942113284e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.984011942113284e-05

Optimization complete. Final v2v error: 3.7258739471435547 mm

Highest mean error: 6.547374248504639 mm for frame 68

Lowest mean error: 2.996717691421509 mm for frame 153

Saving results

Total time: 311.1941010951996
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00829218
Iteration 2/25 | Loss: 0.00135664
Iteration 3/25 | Loss: 0.00088995
Iteration 4/25 | Loss: 0.00078428
Iteration 5/25 | Loss: 0.00076425
Iteration 6/25 | Loss: 0.00075899
Iteration 7/25 | Loss: 0.00075779
Iteration 8/25 | Loss: 0.00075776
Iteration 9/25 | Loss: 0.00075761
Iteration 10/25 | Loss: 0.00075761
Iteration 11/25 | Loss: 0.00075761
Iteration 12/25 | Loss: 0.00075761
Iteration 13/25 | Loss: 0.00075761
Iteration 14/25 | Loss: 0.00075761
Iteration 15/25 | Loss: 0.00075761
Iteration 16/25 | Loss: 0.00075761
Iteration 17/25 | Loss: 0.00075761
Iteration 18/25 | Loss: 0.00075761
Iteration 19/25 | Loss: 0.00075761
Iteration 20/25 | Loss: 0.00075761
Iteration 21/25 | Loss: 0.00075761
Iteration 22/25 | Loss: 0.00075761
Iteration 23/25 | Loss: 0.00075761
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0007576128700748086, 0.0007576128700748086, 0.0007576128700748086, 0.0007576128700748086, 0.0007576128700748086]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007576128700748086

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51150727
Iteration 2/25 | Loss: 0.00035728
Iteration 3/25 | Loss: 0.00035728
Iteration 4/25 | Loss: 0.00035728
Iteration 5/25 | Loss: 0.00035728
Iteration 6/25 | Loss: 0.00035728
Iteration 7/25 | Loss: 0.00035728
Iteration 8/25 | Loss: 0.00035728
Iteration 9/25 | Loss: 0.00035728
Iteration 10/25 | Loss: 0.00035728
Iteration 11/25 | Loss: 0.00035728
Iteration 12/25 | Loss: 0.00035728
Iteration 13/25 | Loss: 0.00035728
Iteration 14/25 | Loss: 0.00035728
Iteration 15/25 | Loss: 0.00035728
Iteration 16/25 | Loss: 0.00035728
Iteration 17/25 | Loss: 0.00035728
Iteration 18/25 | Loss: 0.00035728
Iteration 19/25 | Loss: 0.00035728
Iteration 20/25 | Loss: 0.00035728
Iteration 21/25 | Loss: 0.00035728
Iteration 22/25 | Loss: 0.00035728
Iteration 23/25 | Loss: 0.00035728
Iteration 24/25 | Loss: 0.00035728
Iteration 25/25 | Loss: 0.00035728

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035728
Iteration 2/1000 | Loss: 0.00002774
Iteration 3/1000 | Loss: 0.00001872
Iteration 4/1000 | Loss: 0.00001656
Iteration 5/1000 | Loss: 0.00001578
Iteration 6/1000 | Loss: 0.00001522
Iteration 7/1000 | Loss: 0.00001485
Iteration 8/1000 | Loss: 0.00001460
Iteration 9/1000 | Loss: 0.00001433
Iteration 10/1000 | Loss: 0.00001431
Iteration 11/1000 | Loss: 0.00001423
Iteration 12/1000 | Loss: 0.00001423
Iteration 13/1000 | Loss: 0.00001423
Iteration 14/1000 | Loss: 0.00001422
Iteration 15/1000 | Loss: 0.00001421
Iteration 16/1000 | Loss: 0.00001417
Iteration 17/1000 | Loss: 0.00001416
Iteration 18/1000 | Loss: 0.00001415
Iteration 19/1000 | Loss: 0.00001415
Iteration 20/1000 | Loss: 0.00001414
Iteration 21/1000 | Loss: 0.00001413
Iteration 22/1000 | Loss: 0.00001413
Iteration 23/1000 | Loss: 0.00001412
Iteration 24/1000 | Loss: 0.00001412
Iteration 25/1000 | Loss: 0.00001412
Iteration 26/1000 | Loss: 0.00001411
Iteration 27/1000 | Loss: 0.00001411
Iteration 28/1000 | Loss: 0.00001410
Iteration 29/1000 | Loss: 0.00001409
Iteration 30/1000 | Loss: 0.00001409
Iteration 31/1000 | Loss: 0.00001408
Iteration 32/1000 | Loss: 0.00001408
Iteration 33/1000 | Loss: 0.00001407
Iteration 34/1000 | Loss: 0.00001405
Iteration 35/1000 | Loss: 0.00001405
Iteration 36/1000 | Loss: 0.00001403
Iteration 37/1000 | Loss: 0.00001403
Iteration 38/1000 | Loss: 0.00001402
Iteration 39/1000 | Loss: 0.00001402
Iteration 40/1000 | Loss: 0.00001402
Iteration 41/1000 | Loss: 0.00001402
Iteration 42/1000 | Loss: 0.00001401
Iteration 43/1000 | Loss: 0.00001401
Iteration 44/1000 | Loss: 0.00001401
Iteration 45/1000 | Loss: 0.00001400
Iteration 46/1000 | Loss: 0.00001399
Iteration 47/1000 | Loss: 0.00001399
Iteration 48/1000 | Loss: 0.00001398
Iteration 49/1000 | Loss: 0.00001398
Iteration 50/1000 | Loss: 0.00001398
Iteration 51/1000 | Loss: 0.00001398
Iteration 52/1000 | Loss: 0.00001398
Iteration 53/1000 | Loss: 0.00001397
Iteration 54/1000 | Loss: 0.00001397
Iteration 55/1000 | Loss: 0.00001397
Iteration 56/1000 | Loss: 0.00001397
Iteration 57/1000 | Loss: 0.00001397
Iteration 58/1000 | Loss: 0.00001397
Iteration 59/1000 | Loss: 0.00001397
Iteration 60/1000 | Loss: 0.00001397
Iteration 61/1000 | Loss: 0.00001397
Iteration 62/1000 | Loss: 0.00001396
Iteration 63/1000 | Loss: 0.00001396
Iteration 64/1000 | Loss: 0.00001396
Iteration 65/1000 | Loss: 0.00001395
Iteration 66/1000 | Loss: 0.00001395
Iteration 67/1000 | Loss: 0.00001395
Iteration 68/1000 | Loss: 0.00001395
Iteration 69/1000 | Loss: 0.00001394
Iteration 70/1000 | Loss: 0.00001393
Iteration 71/1000 | Loss: 0.00001393
Iteration 72/1000 | Loss: 0.00001392
Iteration 73/1000 | Loss: 0.00001392
Iteration 74/1000 | Loss: 0.00001391
Iteration 75/1000 | Loss: 0.00001391
Iteration 76/1000 | Loss: 0.00001391
Iteration 77/1000 | Loss: 0.00001390
Iteration 78/1000 | Loss: 0.00001390
Iteration 79/1000 | Loss: 0.00001390
Iteration 80/1000 | Loss: 0.00001389
Iteration 81/1000 | Loss: 0.00001389
Iteration 82/1000 | Loss: 0.00001389
Iteration 83/1000 | Loss: 0.00001389
Iteration 84/1000 | Loss: 0.00001389
Iteration 85/1000 | Loss: 0.00001389
Iteration 86/1000 | Loss: 0.00001388
Iteration 87/1000 | Loss: 0.00001388
Iteration 88/1000 | Loss: 0.00001388
Iteration 89/1000 | Loss: 0.00001387
Iteration 90/1000 | Loss: 0.00001387
Iteration 91/1000 | Loss: 0.00001387
Iteration 92/1000 | Loss: 0.00001387
Iteration 93/1000 | Loss: 0.00001387
Iteration 94/1000 | Loss: 0.00001386
Iteration 95/1000 | Loss: 0.00001386
Iteration 96/1000 | Loss: 0.00001386
Iteration 97/1000 | Loss: 0.00001386
Iteration 98/1000 | Loss: 0.00001386
Iteration 99/1000 | Loss: 0.00001386
Iteration 100/1000 | Loss: 0.00001386
Iteration 101/1000 | Loss: 0.00001386
Iteration 102/1000 | Loss: 0.00001386
Iteration 103/1000 | Loss: 0.00001386
Iteration 104/1000 | Loss: 0.00001386
Iteration 105/1000 | Loss: 0.00001386
Iteration 106/1000 | Loss: 0.00001386
Iteration 107/1000 | Loss: 0.00001386
Iteration 108/1000 | Loss: 0.00001386
Iteration 109/1000 | Loss: 0.00001385
Iteration 110/1000 | Loss: 0.00001385
Iteration 111/1000 | Loss: 0.00001385
Iteration 112/1000 | Loss: 0.00001385
Iteration 113/1000 | Loss: 0.00001385
Iteration 114/1000 | Loss: 0.00001385
Iteration 115/1000 | Loss: 0.00001385
Iteration 116/1000 | Loss: 0.00001385
Iteration 117/1000 | Loss: 0.00001385
Iteration 118/1000 | Loss: 0.00001384
Iteration 119/1000 | Loss: 0.00001384
Iteration 120/1000 | Loss: 0.00001384
Iteration 121/1000 | Loss: 0.00001384
Iteration 122/1000 | Loss: 0.00001384
Iteration 123/1000 | Loss: 0.00001384
Iteration 124/1000 | Loss: 0.00001384
Iteration 125/1000 | Loss: 0.00001384
Iteration 126/1000 | Loss: 0.00001384
Iteration 127/1000 | Loss: 0.00001383
Iteration 128/1000 | Loss: 0.00001383
Iteration 129/1000 | Loss: 0.00001383
Iteration 130/1000 | Loss: 0.00001383
Iteration 131/1000 | Loss: 0.00001383
Iteration 132/1000 | Loss: 0.00001383
Iteration 133/1000 | Loss: 0.00001383
Iteration 134/1000 | Loss: 0.00001383
Iteration 135/1000 | Loss: 0.00001383
Iteration 136/1000 | Loss: 0.00001383
Iteration 137/1000 | Loss: 0.00001383
Iteration 138/1000 | Loss: 0.00001383
Iteration 139/1000 | Loss: 0.00001383
Iteration 140/1000 | Loss: 0.00001382
Iteration 141/1000 | Loss: 0.00001382
Iteration 142/1000 | Loss: 0.00001382
Iteration 143/1000 | Loss: 0.00001382
Iteration 144/1000 | Loss: 0.00001382
Iteration 145/1000 | Loss: 0.00001382
Iteration 146/1000 | Loss: 0.00001382
Iteration 147/1000 | Loss: 0.00001382
Iteration 148/1000 | Loss: 0.00001381
Iteration 149/1000 | Loss: 0.00001381
Iteration 150/1000 | Loss: 0.00001381
Iteration 151/1000 | Loss: 0.00001381
Iteration 152/1000 | Loss: 0.00001381
Iteration 153/1000 | Loss: 0.00001381
Iteration 154/1000 | Loss: 0.00001381
Iteration 155/1000 | Loss: 0.00001381
Iteration 156/1000 | Loss: 0.00001381
Iteration 157/1000 | Loss: 0.00001380
Iteration 158/1000 | Loss: 0.00001380
Iteration 159/1000 | Loss: 0.00001380
Iteration 160/1000 | Loss: 0.00001380
Iteration 161/1000 | Loss: 0.00001380
Iteration 162/1000 | Loss: 0.00001380
Iteration 163/1000 | Loss: 0.00001380
Iteration 164/1000 | Loss: 0.00001380
Iteration 165/1000 | Loss: 0.00001380
Iteration 166/1000 | Loss: 0.00001380
Iteration 167/1000 | Loss: 0.00001380
Iteration 168/1000 | Loss: 0.00001380
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 168. Stopping optimization.
Last 5 losses: [1.380027606501244e-05, 1.380027606501244e-05, 1.380027606501244e-05, 1.380027606501244e-05, 1.380027606501244e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.380027606501244e-05

Optimization complete. Final v2v error: 3.1906614303588867 mm

Highest mean error: 3.9368979930877686 mm for frame 56

Lowest mean error: 2.7057712078094482 mm for frame 31

Saving results

Total time: 38.35551118850708
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00394074
Iteration 2/25 | Loss: 0.00095977
Iteration 3/25 | Loss: 0.00087026
Iteration 4/25 | Loss: 0.00084208
Iteration 5/25 | Loss: 0.00083341
Iteration 6/25 | Loss: 0.00083132
Iteration 7/25 | Loss: 0.00083087
Iteration 8/25 | Loss: 0.00083084
Iteration 9/25 | Loss: 0.00083084
Iteration 10/25 | Loss: 0.00083084
Iteration 11/25 | Loss: 0.00083084
Iteration 12/25 | Loss: 0.00083084
Iteration 13/25 | Loss: 0.00083084
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0008308435790240765, 0.0008308435790240765, 0.0008308435790240765, 0.0008308435790240765, 0.0008308435790240765]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008308435790240765

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.30293369
Iteration 2/25 | Loss: 0.00031122
Iteration 3/25 | Loss: 0.00031121
Iteration 4/25 | Loss: 0.00031121
Iteration 5/25 | Loss: 0.00031121
Iteration 6/25 | Loss: 0.00031121
Iteration 7/25 | Loss: 0.00031121
Iteration 8/25 | Loss: 0.00031121
Iteration 9/25 | Loss: 0.00031121
Iteration 10/25 | Loss: 0.00031121
Iteration 11/25 | Loss: 0.00031121
Iteration 12/25 | Loss: 0.00031121
Iteration 13/25 | Loss: 0.00031121
Iteration 14/25 | Loss: 0.00031121
Iteration 15/25 | Loss: 0.00031121
Iteration 16/25 | Loss: 0.00031121
Iteration 17/25 | Loss: 0.00031121
Iteration 18/25 | Loss: 0.00031121
Iteration 19/25 | Loss: 0.00031121
Iteration 20/25 | Loss: 0.00031121
Iteration 21/25 | Loss: 0.00031121
Iteration 22/25 | Loss: 0.00031121
Iteration 23/25 | Loss: 0.00031121
Iteration 24/25 | Loss: 0.00031121
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00031120775383897126, 0.00031120775383897126, 0.00031120775383897126, 0.00031120775383897126, 0.00031120775383897126]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031120775383897126

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031121
Iteration 2/1000 | Loss: 0.00004446
Iteration 3/1000 | Loss: 0.00003610
Iteration 4/1000 | Loss: 0.00003277
Iteration 5/1000 | Loss: 0.00003033
Iteration 6/1000 | Loss: 0.00002930
Iteration 7/1000 | Loss: 0.00002839
Iteration 8/1000 | Loss: 0.00002802
Iteration 9/1000 | Loss: 0.00002781
Iteration 10/1000 | Loss: 0.00002771
Iteration 11/1000 | Loss: 0.00002771
Iteration 12/1000 | Loss: 0.00002770
Iteration 13/1000 | Loss: 0.00002768
Iteration 14/1000 | Loss: 0.00002765
Iteration 15/1000 | Loss: 0.00002765
Iteration 16/1000 | Loss: 0.00002764
Iteration 17/1000 | Loss: 0.00002764
Iteration 18/1000 | Loss: 0.00002764
Iteration 19/1000 | Loss: 0.00002763
Iteration 20/1000 | Loss: 0.00002763
Iteration 21/1000 | Loss: 0.00002763
Iteration 22/1000 | Loss: 0.00002762
Iteration 23/1000 | Loss: 0.00002762
Iteration 24/1000 | Loss: 0.00002761
Iteration 25/1000 | Loss: 0.00002761
Iteration 26/1000 | Loss: 0.00002761
Iteration 27/1000 | Loss: 0.00002761
Iteration 28/1000 | Loss: 0.00002761
Iteration 29/1000 | Loss: 0.00002761
Iteration 30/1000 | Loss: 0.00002761
Iteration 31/1000 | Loss: 0.00002761
Iteration 32/1000 | Loss: 0.00002761
Iteration 33/1000 | Loss: 0.00002760
Iteration 34/1000 | Loss: 0.00002760
Iteration 35/1000 | Loss: 0.00002760
Iteration 36/1000 | Loss: 0.00002760
Iteration 37/1000 | Loss: 0.00002759
Iteration 38/1000 | Loss: 0.00002759
Iteration 39/1000 | Loss: 0.00002758
Iteration 40/1000 | Loss: 0.00002758
Iteration 41/1000 | Loss: 0.00002758
Iteration 42/1000 | Loss: 0.00002757
Iteration 43/1000 | Loss: 0.00002757
Iteration 44/1000 | Loss: 0.00002757
Iteration 45/1000 | Loss: 0.00002757
Iteration 46/1000 | Loss: 0.00002757
Iteration 47/1000 | Loss: 0.00002757
Iteration 48/1000 | Loss: 0.00002757
Iteration 49/1000 | Loss: 0.00002757
Iteration 50/1000 | Loss: 0.00002757
Iteration 51/1000 | Loss: 0.00002757
Iteration 52/1000 | Loss: 0.00002756
Iteration 53/1000 | Loss: 0.00002756
Iteration 54/1000 | Loss: 0.00002756
Iteration 55/1000 | Loss: 0.00002756
Iteration 56/1000 | Loss: 0.00002755
Iteration 57/1000 | Loss: 0.00002755
Iteration 58/1000 | Loss: 0.00002755
Iteration 59/1000 | Loss: 0.00002755
Iteration 60/1000 | Loss: 0.00002755
Iteration 61/1000 | Loss: 0.00002755
Iteration 62/1000 | Loss: 0.00002755
Iteration 63/1000 | Loss: 0.00002755
Iteration 64/1000 | Loss: 0.00002755
Iteration 65/1000 | Loss: 0.00002755
Iteration 66/1000 | Loss: 0.00002755
Iteration 67/1000 | Loss: 0.00002755
Iteration 68/1000 | Loss: 0.00002754
Iteration 69/1000 | Loss: 0.00002754
Iteration 70/1000 | Loss: 0.00002754
Iteration 71/1000 | Loss: 0.00002754
Iteration 72/1000 | Loss: 0.00002754
Iteration 73/1000 | Loss: 0.00002754
Iteration 74/1000 | Loss: 0.00002754
Iteration 75/1000 | Loss: 0.00002754
Iteration 76/1000 | Loss: 0.00002754
Iteration 77/1000 | Loss: 0.00002754
Iteration 78/1000 | Loss: 0.00002754
Iteration 79/1000 | Loss: 0.00002754
Iteration 80/1000 | Loss: 0.00002754
Iteration 81/1000 | Loss: 0.00002754
Iteration 82/1000 | Loss: 0.00002754
Iteration 83/1000 | Loss: 0.00002754
Iteration 84/1000 | Loss: 0.00002754
Iteration 85/1000 | Loss: 0.00002754
Iteration 86/1000 | Loss: 0.00002754
Iteration 87/1000 | Loss: 0.00002754
Iteration 88/1000 | Loss: 0.00002754
Iteration 89/1000 | Loss: 0.00002754
Iteration 90/1000 | Loss: 0.00002754
Iteration 91/1000 | Loss: 0.00002754
Iteration 92/1000 | Loss: 0.00002754
Iteration 93/1000 | Loss: 0.00002754
Iteration 94/1000 | Loss: 0.00002754
Iteration 95/1000 | Loss: 0.00002754
Iteration 96/1000 | Loss: 0.00002754
Iteration 97/1000 | Loss: 0.00002754
Iteration 98/1000 | Loss: 0.00002754
Iteration 99/1000 | Loss: 0.00002754
Iteration 100/1000 | Loss: 0.00002754
Iteration 101/1000 | Loss: 0.00002754
Iteration 102/1000 | Loss: 0.00002754
Iteration 103/1000 | Loss: 0.00002754
Iteration 104/1000 | Loss: 0.00002754
Iteration 105/1000 | Loss: 0.00002754
Iteration 106/1000 | Loss: 0.00002754
Iteration 107/1000 | Loss: 0.00002754
Iteration 108/1000 | Loss: 0.00002754
Iteration 109/1000 | Loss: 0.00002754
Iteration 110/1000 | Loss: 0.00002754
Iteration 111/1000 | Loss: 0.00002754
Iteration 112/1000 | Loss: 0.00002754
Iteration 113/1000 | Loss: 0.00002754
Iteration 114/1000 | Loss: 0.00002754
Iteration 115/1000 | Loss: 0.00002754
Iteration 116/1000 | Loss: 0.00002754
Iteration 117/1000 | Loss: 0.00002754
Iteration 118/1000 | Loss: 0.00002754
Iteration 119/1000 | Loss: 0.00002754
Iteration 120/1000 | Loss: 0.00002754
Iteration 121/1000 | Loss: 0.00002754
Iteration 122/1000 | Loss: 0.00002754
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [2.754494380496908e-05, 2.754494380496908e-05, 2.754494380496908e-05, 2.754494380496908e-05, 2.754494380496908e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.754494380496908e-05

Optimization complete. Final v2v error: 4.354577541351318 mm

Highest mean error: 4.664748191833496 mm for frame 109

Lowest mean error: 4.1751275062561035 mm for frame 90

Saving results

Total time: 32.42329001426697
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01041628
Iteration 2/25 | Loss: 0.00167587
Iteration 3/25 | Loss: 0.00109270
Iteration 4/25 | Loss: 0.00104517
Iteration 5/25 | Loss: 0.00102486
Iteration 6/25 | Loss: 0.00101997
Iteration 7/25 | Loss: 0.00101906
Iteration 8/25 | Loss: 0.00101906
Iteration 9/25 | Loss: 0.00101906
Iteration 10/25 | Loss: 0.00101906
Iteration 11/25 | Loss: 0.00101906
Iteration 12/25 | Loss: 0.00101906
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001019058283418417, 0.001019058283418417, 0.001019058283418417, 0.001019058283418417, 0.001019058283418417]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001019058283418417

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.94842881
Iteration 2/25 | Loss: 0.00054712
Iteration 3/25 | Loss: 0.00054711
Iteration 4/25 | Loss: 0.00054711
Iteration 5/25 | Loss: 0.00054711
Iteration 6/25 | Loss: 0.00054711
Iteration 7/25 | Loss: 0.00054711
Iteration 8/25 | Loss: 0.00054711
Iteration 9/25 | Loss: 0.00054711
Iteration 10/25 | Loss: 0.00054711
Iteration 11/25 | Loss: 0.00054711
Iteration 12/25 | Loss: 0.00054711
Iteration 13/25 | Loss: 0.00054711
Iteration 14/25 | Loss: 0.00054711
Iteration 15/25 | Loss: 0.00054711
Iteration 16/25 | Loss: 0.00054711
Iteration 17/25 | Loss: 0.00054711
Iteration 18/25 | Loss: 0.00054711
Iteration 19/25 | Loss: 0.00054711
Iteration 20/25 | Loss: 0.00054711
Iteration 21/25 | Loss: 0.00054711
Iteration 22/25 | Loss: 0.00054711
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005471099866554141, 0.0005471099866554141, 0.0005471099866554141, 0.0005471099866554141, 0.0005471099866554141]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005471099866554141

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054711
Iteration 2/1000 | Loss: 0.00007613
Iteration 3/1000 | Loss: 0.00005973
Iteration 4/1000 | Loss: 0.00005434
Iteration 5/1000 | Loss: 0.00005114
Iteration 6/1000 | Loss: 0.00004946
Iteration 7/1000 | Loss: 0.00004817
Iteration 8/1000 | Loss: 0.00004733
Iteration 9/1000 | Loss: 0.00004671
Iteration 10/1000 | Loss: 0.00004638
Iteration 11/1000 | Loss: 0.00004612
Iteration 12/1000 | Loss: 0.00004593
Iteration 13/1000 | Loss: 0.00004579
Iteration 14/1000 | Loss: 0.00004578
Iteration 15/1000 | Loss: 0.00004571
Iteration 16/1000 | Loss: 0.00004564
Iteration 17/1000 | Loss: 0.00004552
Iteration 18/1000 | Loss: 0.00004550
Iteration 19/1000 | Loss: 0.00004550
Iteration 20/1000 | Loss: 0.00004549
Iteration 21/1000 | Loss: 0.00004549
Iteration 22/1000 | Loss: 0.00004549
Iteration 23/1000 | Loss: 0.00004549
Iteration 24/1000 | Loss: 0.00004548
Iteration 25/1000 | Loss: 0.00004546
Iteration 26/1000 | Loss: 0.00004546
Iteration 27/1000 | Loss: 0.00004546
Iteration 28/1000 | Loss: 0.00004546
Iteration 29/1000 | Loss: 0.00004546
Iteration 30/1000 | Loss: 0.00004546
Iteration 31/1000 | Loss: 0.00004546
Iteration 32/1000 | Loss: 0.00004546
Iteration 33/1000 | Loss: 0.00004546
Iteration 34/1000 | Loss: 0.00004545
Iteration 35/1000 | Loss: 0.00004545
Iteration 36/1000 | Loss: 0.00004545
Iteration 37/1000 | Loss: 0.00004541
Iteration 38/1000 | Loss: 0.00004538
Iteration 39/1000 | Loss: 0.00004538
Iteration 40/1000 | Loss: 0.00004536
Iteration 41/1000 | Loss: 0.00004536
Iteration 42/1000 | Loss: 0.00004535
Iteration 43/1000 | Loss: 0.00004535
Iteration 44/1000 | Loss: 0.00004534
Iteration 45/1000 | Loss: 0.00004533
Iteration 46/1000 | Loss: 0.00004532
Iteration 47/1000 | Loss: 0.00004532
Iteration 48/1000 | Loss: 0.00004531
Iteration 49/1000 | Loss: 0.00004530
Iteration 50/1000 | Loss: 0.00004530
Iteration 51/1000 | Loss: 0.00004530
Iteration 52/1000 | Loss: 0.00004529
Iteration 53/1000 | Loss: 0.00004529
Iteration 54/1000 | Loss: 0.00004529
Iteration 55/1000 | Loss: 0.00004529
Iteration 56/1000 | Loss: 0.00004529
Iteration 57/1000 | Loss: 0.00004528
Iteration 58/1000 | Loss: 0.00004528
Iteration 59/1000 | Loss: 0.00004528
Iteration 60/1000 | Loss: 0.00004526
Iteration 61/1000 | Loss: 0.00004526
Iteration 62/1000 | Loss: 0.00004526
Iteration 63/1000 | Loss: 0.00004526
Iteration 64/1000 | Loss: 0.00004526
Iteration 65/1000 | Loss: 0.00004526
Iteration 66/1000 | Loss: 0.00004526
Iteration 67/1000 | Loss: 0.00004526
Iteration 68/1000 | Loss: 0.00004525
Iteration 69/1000 | Loss: 0.00004525
Iteration 70/1000 | Loss: 0.00004525
Iteration 71/1000 | Loss: 0.00004525
Iteration 72/1000 | Loss: 0.00004525
Iteration 73/1000 | Loss: 0.00004525
Iteration 74/1000 | Loss: 0.00004525
Iteration 75/1000 | Loss: 0.00004525
Iteration 76/1000 | Loss: 0.00004525
Iteration 77/1000 | Loss: 0.00004525
Iteration 78/1000 | Loss: 0.00004525
Iteration 79/1000 | Loss: 0.00004525
Iteration 80/1000 | Loss: 0.00004524
Iteration 81/1000 | Loss: 0.00004524
Iteration 82/1000 | Loss: 0.00004524
Iteration 83/1000 | Loss: 0.00004524
Iteration 84/1000 | Loss: 0.00004524
Iteration 85/1000 | Loss: 0.00004524
Iteration 86/1000 | Loss: 0.00004523
Iteration 87/1000 | Loss: 0.00004522
Iteration 88/1000 | Loss: 0.00004522
Iteration 89/1000 | Loss: 0.00004522
Iteration 90/1000 | Loss: 0.00004521
Iteration 91/1000 | Loss: 0.00004521
Iteration 92/1000 | Loss: 0.00004521
Iteration 93/1000 | Loss: 0.00004520
Iteration 94/1000 | Loss: 0.00004520
Iteration 95/1000 | Loss: 0.00004520
Iteration 96/1000 | Loss: 0.00004519
Iteration 97/1000 | Loss: 0.00004519
Iteration 98/1000 | Loss: 0.00004519
Iteration 99/1000 | Loss: 0.00004518
Iteration 100/1000 | Loss: 0.00004518
Iteration 101/1000 | Loss: 0.00004518
Iteration 102/1000 | Loss: 0.00004517
Iteration 103/1000 | Loss: 0.00004517
Iteration 104/1000 | Loss: 0.00004517
Iteration 105/1000 | Loss: 0.00004517
Iteration 106/1000 | Loss: 0.00004517
Iteration 107/1000 | Loss: 0.00004516
Iteration 108/1000 | Loss: 0.00004516
Iteration 109/1000 | Loss: 0.00004516
Iteration 110/1000 | Loss: 0.00004516
Iteration 111/1000 | Loss: 0.00004516
Iteration 112/1000 | Loss: 0.00004516
Iteration 113/1000 | Loss: 0.00004516
Iteration 114/1000 | Loss: 0.00004515
Iteration 115/1000 | Loss: 0.00004515
Iteration 116/1000 | Loss: 0.00004515
Iteration 117/1000 | Loss: 0.00004515
Iteration 118/1000 | Loss: 0.00004514
Iteration 119/1000 | Loss: 0.00004514
Iteration 120/1000 | Loss: 0.00004514
Iteration 121/1000 | Loss: 0.00004514
Iteration 122/1000 | Loss: 0.00004514
Iteration 123/1000 | Loss: 0.00004514
Iteration 124/1000 | Loss: 0.00004513
Iteration 125/1000 | Loss: 0.00004513
Iteration 126/1000 | Loss: 0.00004513
Iteration 127/1000 | Loss: 0.00004513
Iteration 128/1000 | Loss: 0.00004513
Iteration 129/1000 | Loss: 0.00004513
Iteration 130/1000 | Loss: 0.00004513
Iteration 131/1000 | Loss: 0.00004512
Iteration 132/1000 | Loss: 0.00004512
Iteration 133/1000 | Loss: 0.00004512
Iteration 134/1000 | Loss: 0.00004512
Iteration 135/1000 | Loss: 0.00004512
Iteration 136/1000 | Loss: 0.00004512
Iteration 137/1000 | Loss: 0.00004512
Iteration 138/1000 | Loss: 0.00004512
Iteration 139/1000 | Loss: 0.00004512
Iteration 140/1000 | Loss: 0.00004512
Iteration 141/1000 | Loss: 0.00004512
Iteration 142/1000 | Loss: 0.00004511
Iteration 143/1000 | Loss: 0.00004511
Iteration 144/1000 | Loss: 0.00004511
Iteration 145/1000 | Loss: 0.00004511
Iteration 146/1000 | Loss: 0.00004511
Iteration 147/1000 | Loss: 0.00004511
Iteration 148/1000 | Loss: 0.00004511
Iteration 149/1000 | Loss: 0.00004511
Iteration 150/1000 | Loss: 0.00004511
Iteration 151/1000 | Loss: 0.00004511
Iteration 152/1000 | Loss: 0.00004511
Iteration 153/1000 | Loss: 0.00004511
Iteration 154/1000 | Loss: 0.00004511
Iteration 155/1000 | Loss: 0.00004511
Iteration 156/1000 | Loss: 0.00004511
Iteration 157/1000 | Loss: 0.00004511
Iteration 158/1000 | Loss: 0.00004511
Iteration 159/1000 | Loss: 0.00004511
Iteration 160/1000 | Loss: 0.00004511
Iteration 161/1000 | Loss: 0.00004511
Iteration 162/1000 | Loss: 0.00004511
Iteration 163/1000 | Loss: 0.00004511
Iteration 164/1000 | Loss: 0.00004511
Iteration 165/1000 | Loss: 0.00004511
Iteration 166/1000 | Loss: 0.00004511
Iteration 167/1000 | Loss: 0.00004511
Iteration 168/1000 | Loss: 0.00004511
Iteration 169/1000 | Loss: 0.00004511
Iteration 170/1000 | Loss: 0.00004511
Iteration 171/1000 | Loss: 0.00004511
Iteration 172/1000 | Loss: 0.00004511
Iteration 173/1000 | Loss: 0.00004511
Iteration 174/1000 | Loss: 0.00004511
Iteration 175/1000 | Loss: 0.00004511
Iteration 176/1000 | Loss: 0.00004511
Iteration 177/1000 | Loss: 0.00004511
Iteration 178/1000 | Loss: 0.00004511
Iteration 179/1000 | Loss: 0.00004511
Iteration 180/1000 | Loss: 0.00004511
Iteration 181/1000 | Loss: 0.00004511
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [4.510713552008383e-05, 4.510713552008383e-05, 4.510713552008383e-05, 4.510713552008383e-05, 4.510713552008383e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.510713552008383e-05

Optimization complete. Final v2v error: 5.515594959259033 mm

Highest mean error: 6.407686233520508 mm for frame 94

Lowest mean error: 5.025941371917725 mm for frame 124

Saving results

Total time: 50.83525586128235
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01110280
Iteration 2/25 | Loss: 0.00200990
Iteration 3/25 | Loss: 0.00132875
Iteration 4/25 | Loss: 0.00130515
Iteration 5/25 | Loss: 0.00125401
Iteration 6/25 | Loss: 0.00123062
Iteration 7/25 | Loss: 0.00111927
Iteration 8/25 | Loss: 0.00106000
Iteration 9/25 | Loss: 0.00106430
Iteration 10/25 | Loss: 0.00094598
Iteration 11/25 | Loss: 0.00090498
Iteration 12/25 | Loss: 0.00092739
Iteration 13/25 | Loss: 0.00087977
Iteration 14/25 | Loss: 0.00087357
Iteration 15/25 | Loss: 0.00092229
Iteration 16/25 | Loss: 0.00086259
Iteration 17/25 | Loss: 0.00086473
Iteration 18/25 | Loss: 0.00084544
Iteration 19/25 | Loss: 0.00083848
Iteration 20/25 | Loss: 0.00083587
Iteration 21/25 | Loss: 0.00083522
Iteration 22/25 | Loss: 0.00083511
Iteration 23/25 | Loss: 0.00083511
Iteration 24/25 | Loss: 0.00083511
Iteration 25/25 | Loss: 0.00083511

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53226101
Iteration 2/25 | Loss: 0.00129619
Iteration 3/25 | Loss: 0.00127839
Iteration 4/25 | Loss: 0.00127839
Iteration 5/25 | Loss: 0.00127839
Iteration 6/25 | Loss: 0.00127839
Iteration 7/25 | Loss: 0.00127839
Iteration 8/25 | Loss: 0.00127839
Iteration 9/25 | Loss: 0.00127839
Iteration 10/25 | Loss: 0.00127839
Iteration 11/25 | Loss: 0.00127839
Iteration 12/25 | Loss: 0.00127839
Iteration 13/25 | Loss: 0.00127839
Iteration 14/25 | Loss: 0.00127839
Iteration 15/25 | Loss: 0.00127839
Iteration 16/25 | Loss: 0.00127839
Iteration 17/25 | Loss: 0.00127839
Iteration 18/25 | Loss: 0.00127839
Iteration 19/25 | Loss: 0.00127839
Iteration 20/25 | Loss: 0.00127839
Iteration 21/25 | Loss: 0.00127839
Iteration 22/25 | Loss: 0.00127839
Iteration 23/25 | Loss: 0.00127839
Iteration 24/25 | Loss: 0.00127839
Iteration 25/25 | Loss: 0.00127839

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00127839
Iteration 2/1000 | Loss: 0.00025227
Iteration 3/1000 | Loss: 0.00023766
Iteration 4/1000 | Loss: 0.00019315
Iteration 5/1000 | Loss: 0.00128420
Iteration 6/1000 | Loss: 0.00007716
Iteration 7/1000 | Loss: 0.00164494
Iteration 8/1000 | Loss: 0.00011930
Iteration 9/1000 | Loss: 0.00008792
Iteration 10/1000 | Loss: 0.00006396
Iteration 11/1000 | Loss: 0.00008446
Iteration 12/1000 | Loss: 0.00003709
Iteration 13/1000 | Loss: 0.00005230
Iteration 14/1000 | Loss: 0.00006316
Iteration 15/1000 | Loss: 0.00004875
Iteration 16/1000 | Loss: 0.00091458
Iteration 17/1000 | Loss: 0.00024711
Iteration 18/1000 | Loss: 0.00057600
Iteration 19/1000 | Loss: 0.00003905
Iteration 20/1000 | Loss: 0.00006424
Iteration 21/1000 | Loss: 0.00002720
Iteration 22/1000 | Loss: 0.00002470
Iteration 23/1000 | Loss: 0.00003575
Iteration 24/1000 | Loss: 0.00002226
Iteration 25/1000 | Loss: 0.00003525
Iteration 26/1000 | Loss: 0.00002141
Iteration 27/1000 | Loss: 0.00002115
Iteration 28/1000 | Loss: 0.00003631
Iteration 29/1000 | Loss: 0.00002087
Iteration 30/1000 | Loss: 0.00002737
Iteration 31/1000 | Loss: 0.00002076
Iteration 32/1000 | Loss: 0.00002063
Iteration 33/1000 | Loss: 0.00002062
Iteration 34/1000 | Loss: 0.00002052
Iteration 35/1000 | Loss: 0.00003181
Iteration 36/1000 | Loss: 0.00002264
Iteration 37/1000 | Loss: 0.00002041
Iteration 38/1000 | Loss: 0.00002039
Iteration 39/1000 | Loss: 0.00002038
Iteration 40/1000 | Loss: 0.00002037
Iteration 41/1000 | Loss: 0.00002037
Iteration 42/1000 | Loss: 0.00002035
Iteration 43/1000 | Loss: 0.00002035
Iteration 44/1000 | Loss: 0.00002034
Iteration 45/1000 | Loss: 0.00002034
Iteration 46/1000 | Loss: 0.00002951
Iteration 47/1000 | Loss: 0.00002034
Iteration 48/1000 | Loss: 0.00002034
Iteration 49/1000 | Loss: 0.00002300
Iteration 50/1000 | Loss: 0.00002030
Iteration 51/1000 | Loss: 0.00002030
Iteration 52/1000 | Loss: 0.00002029
Iteration 53/1000 | Loss: 0.00002029
Iteration 54/1000 | Loss: 0.00002029
Iteration 55/1000 | Loss: 0.00002029
Iteration 56/1000 | Loss: 0.00002029
Iteration 57/1000 | Loss: 0.00002029
Iteration 58/1000 | Loss: 0.00002029
Iteration 59/1000 | Loss: 0.00002029
Iteration 60/1000 | Loss: 0.00002029
Iteration 61/1000 | Loss: 0.00002029
Iteration 62/1000 | Loss: 0.00002029
Iteration 63/1000 | Loss: 0.00002029
Iteration 64/1000 | Loss: 0.00002029
Iteration 65/1000 | Loss: 0.00002028
Iteration 66/1000 | Loss: 0.00002028
Iteration 67/1000 | Loss: 0.00002028
Iteration 68/1000 | Loss: 0.00002028
Iteration 69/1000 | Loss: 0.00002028
Iteration 70/1000 | Loss: 0.00002028
Iteration 71/1000 | Loss: 0.00002028
Iteration 72/1000 | Loss: 0.00002028
Iteration 73/1000 | Loss: 0.00002028
Iteration 74/1000 | Loss: 0.00002027
Iteration 75/1000 | Loss: 0.00002027
Iteration 76/1000 | Loss: 0.00002027
Iteration 77/1000 | Loss: 0.00002027
Iteration 78/1000 | Loss: 0.00002027
Iteration 79/1000 | Loss: 0.00002027
Iteration 80/1000 | Loss: 0.00002027
Iteration 81/1000 | Loss: 0.00002027
Iteration 82/1000 | Loss: 0.00002027
Iteration 83/1000 | Loss: 0.00002027
Iteration 84/1000 | Loss: 0.00002027
Iteration 85/1000 | Loss: 0.00002027
Iteration 86/1000 | Loss: 0.00002027
Iteration 87/1000 | Loss: 0.00002027
Iteration 88/1000 | Loss: 0.00002027
Iteration 89/1000 | Loss: 0.00002027
Iteration 90/1000 | Loss: 0.00002027
Iteration 91/1000 | Loss: 0.00002027
Iteration 92/1000 | Loss: 0.00002027
Iteration 93/1000 | Loss: 0.00002027
Iteration 94/1000 | Loss: 0.00002027
Iteration 95/1000 | Loss: 0.00002027
Iteration 96/1000 | Loss: 0.00002027
Iteration 97/1000 | Loss: 0.00002027
Iteration 98/1000 | Loss: 0.00002027
Iteration 99/1000 | Loss: 0.00002027
Iteration 100/1000 | Loss: 0.00002027
Iteration 101/1000 | Loss: 0.00002027
Iteration 102/1000 | Loss: 0.00002027
Iteration 103/1000 | Loss: 0.00002027
Iteration 104/1000 | Loss: 0.00002027
Iteration 105/1000 | Loss: 0.00002027
Iteration 106/1000 | Loss: 0.00002027
Iteration 107/1000 | Loss: 0.00002027
Iteration 108/1000 | Loss: 0.00002027
Iteration 109/1000 | Loss: 0.00002027
Iteration 110/1000 | Loss: 0.00002027
Iteration 111/1000 | Loss: 0.00002027
Iteration 112/1000 | Loss: 0.00002027
Iteration 113/1000 | Loss: 0.00002027
Iteration 114/1000 | Loss: 0.00002027
Iteration 115/1000 | Loss: 0.00002027
Iteration 116/1000 | Loss: 0.00002027
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 116. Stopping optimization.
Last 5 losses: [2.027320078923367e-05, 2.027320078923367e-05, 2.027320078923367e-05, 2.027320078923367e-05, 2.027320078923367e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.027320078923367e-05

Optimization complete. Final v2v error: 3.6245830059051514 mm

Highest mean error: 11.755056381225586 mm for frame 95

Lowest mean error: 3.1598832607269287 mm for frame 45

Saving results

Total time: 95.8208703994751
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00814301
Iteration 2/25 | Loss: 0.00150414
Iteration 3/25 | Loss: 0.00120382
Iteration 4/25 | Loss: 0.00115616
Iteration 5/25 | Loss: 0.00114317
Iteration 6/25 | Loss: 0.00114029
Iteration 7/25 | Loss: 0.00114029
Iteration 8/25 | Loss: 0.00114029
Iteration 9/25 | Loss: 0.00114029
Iteration 10/25 | Loss: 0.00114029
Iteration 11/25 | Loss: 0.00114029
Iteration 12/25 | Loss: 0.00114029
Iteration 13/25 | Loss: 0.00114029
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0011402874952182174, 0.0011402874952182174, 0.0011402874952182174, 0.0011402874952182174, 0.0011402874952182174]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011402874952182174

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.95429069
Iteration 2/25 | Loss: 0.00065116
Iteration 3/25 | Loss: 0.00065116
Iteration 4/25 | Loss: 0.00065116
Iteration 5/25 | Loss: 0.00065116
Iteration 6/25 | Loss: 0.00065116
Iteration 7/25 | Loss: 0.00065116
Iteration 8/25 | Loss: 0.00065116
Iteration 9/25 | Loss: 0.00065116
Iteration 10/25 | Loss: 0.00065116
Iteration 11/25 | Loss: 0.00065116
Iteration 12/25 | Loss: 0.00065116
Iteration 13/25 | Loss: 0.00065116
Iteration 14/25 | Loss: 0.00065116
Iteration 15/25 | Loss: 0.00065116
Iteration 16/25 | Loss: 0.00065116
Iteration 17/25 | Loss: 0.00065116
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006511551910080016, 0.0006511551910080016, 0.0006511551910080016, 0.0006511551910080016, 0.0006511551910080016]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006511551910080016

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065116
Iteration 2/1000 | Loss: 0.00008700
Iteration 3/1000 | Loss: 0.00007214
Iteration 4/1000 | Loss: 0.00006680
Iteration 5/1000 | Loss: 0.00006337
Iteration 6/1000 | Loss: 0.00006073
Iteration 7/1000 | Loss: 0.00005947
Iteration 8/1000 | Loss: 0.00005835
Iteration 9/1000 | Loss: 0.00005792
Iteration 10/1000 | Loss: 0.00005746
Iteration 11/1000 | Loss: 0.00005714
Iteration 12/1000 | Loss: 0.00005678
Iteration 13/1000 | Loss: 0.00005647
Iteration 14/1000 | Loss: 0.00005625
Iteration 15/1000 | Loss: 0.00005604
Iteration 16/1000 | Loss: 0.00005584
Iteration 17/1000 | Loss: 0.00005578
Iteration 18/1000 | Loss: 0.00005565
Iteration 19/1000 | Loss: 0.00005560
Iteration 20/1000 | Loss: 0.00005552
Iteration 21/1000 | Loss: 0.00005539
Iteration 22/1000 | Loss: 0.00005538
Iteration 23/1000 | Loss: 0.00005537
Iteration 24/1000 | Loss: 0.00005536
Iteration 25/1000 | Loss: 0.00005535
Iteration 26/1000 | Loss: 0.00005534
Iteration 27/1000 | Loss: 0.00005532
Iteration 28/1000 | Loss: 0.00005531
Iteration 29/1000 | Loss: 0.00005531
Iteration 30/1000 | Loss: 0.00005529
Iteration 31/1000 | Loss: 0.00005527
Iteration 32/1000 | Loss: 0.00005525
Iteration 33/1000 | Loss: 0.00005525
Iteration 34/1000 | Loss: 0.00005525
Iteration 35/1000 | Loss: 0.00005525
Iteration 36/1000 | Loss: 0.00005525
Iteration 37/1000 | Loss: 0.00005525
Iteration 38/1000 | Loss: 0.00005525
Iteration 39/1000 | Loss: 0.00005525
Iteration 40/1000 | Loss: 0.00005525
Iteration 41/1000 | Loss: 0.00005525
Iteration 42/1000 | Loss: 0.00005525
Iteration 43/1000 | Loss: 0.00005525
Iteration 44/1000 | Loss: 0.00005525
Iteration 45/1000 | Loss: 0.00005525
Iteration 46/1000 | Loss: 0.00005525
Iteration 47/1000 | Loss: 0.00005525
Iteration 48/1000 | Loss: 0.00005525
Iteration 49/1000 | Loss: 0.00005525
Iteration 50/1000 | Loss: 0.00005525
Iteration 51/1000 | Loss: 0.00005525
Iteration 52/1000 | Loss: 0.00005525
Iteration 53/1000 | Loss: 0.00005525
Iteration 54/1000 | Loss: 0.00005525
Iteration 55/1000 | Loss: 0.00005525
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 55. Stopping optimization.
Last 5 losses: [5.524598600459285e-05, 5.524598600459285e-05, 5.524598600459285e-05, 5.524598600459285e-05, 5.524598600459285e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.524598600459285e-05

Optimization complete. Final v2v error: 5.995698928833008 mm

Highest mean error: 7.833462238311768 mm for frame 92

Lowest mean error: 5.092251777648926 mm for frame 154

Saving results

Total time: 45.481245279312134
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_0535/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_0535/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00457172
Iteration 2/25 | Loss: 0.00091970
Iteration 3/25 | Loss: 0.00076034
Iteration 4/25 | Loss: 0.00074622
Iteration 5/25 | Loss: 0.00074367
Iteration 6/25 | Loss: 0.00074304
Iteration 7/25 | Loss: 0.00074304
Iteration 8/25 | Loss: 0.00074304
Iteration 9/25 | Loss: 0.00074304
Iteration 10/25 | Loss: 0.00074304
Iteration 11/25 | Loss: 0.00074304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007430423283949494, 0.0007430423283949494, 0.0007430423283949494, 0.0007430423283949494, 0.0007430423283949494]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007430423283949494

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45587802
Iteration 2/25 | Loss: 0.00030055
Iteration 3/25 | Loss: 0.00030055
Iteration 4/25 | Loss: 0.00030055
Iteration 5/25 | Loss: 0.00030055
Iteration 6/25 | Loss: 0.00030054
Iteration 7/25 | Loss: 0.00030054
Iteration 8/25 | Loss: 0.00030054
Iteration 9/25 | Loss: 0.00030054
Iteration 10/25 | Loss: 0.00030054
Iteration 11/25 | Loss: 0.00030054
Iteration 12/25 | Loss: 0.00030054
Iteration 13/25 | Loss: 0.00030054
Iteration 14/25 | Loss: 0.00030054
Iteration 15/25 | Loss: 0.00030054
Iteration 16/25 | Loss: 0.00030054
Iteration 17/25 | Loss: 0.00030054
Iteration 18/25 | Loss: 0.00030054
Iteration 19/25 | Loss: 0.00030054
Iteration 20/25 | Loss: 0.00030054
Iteration 21/25 | Loss: 0.00030054
Iteration 22/25 | Loss: 0.00030054
Iteration 23/25 | Loss: 0.00030054
Iteration 24/25 | Loss: 0.00030054
Iteration 25/25 | Loss: 0.00030054

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030054
Iteration 2/1000 | Loss: 0.00002573
Iteration 3/1000 | Loss: 0.00002006
Iteration 4/1000 | Loss: 0.00001800
Iteration 5/1000 | Loss: 0.00001725
Iteration 6/1000 | Loss: 0.00001711
Iteration 7/1000 | Loss: 0.00001671
Iteration 8/1000 | Loss: 0.00001642
Iteration 9/1000 | Loss: 0.00001631
Iteration 10/1000 | Loss: 0.00001624
Iteration 11/1000 | Loss: 0.00001619
Iteration 12/1000 | Loss: 0.00001618
Iteration 13/1000 | Loss: 0.00001617
Iteration 14/1000 | Loss: 0.00001617
Iteration 15/1000 | Loss: 0.00001617
Iteration 16/1000 | Loss: 0.00001617
Iteration 17/1000 | Loss: 0.00001617
Iteration 18/1000 | Loss: 0.00001614
Iteration 19/1000 | Loss: 0.00001614
Iteration 20/1000 | Loss: 0.00001614
Iteration 21/1000 | Loss: 0.00001614
Iteration 22/1000 | Loss: 0.00001614
Iteration 23/1000 | Loss: 0.00001613
Iteration 24/1000 | Loss: 0.00001613
Iteration 25/1000 | Loss: 0.00001613
Iteration 26/1000 | Loss: 0.00001613
Iteration 27/1000 | Loss: 0.00001613
Iteration 28/1000 | Loss: 0.00001613
Iteration 29/1000 | Loss: 0.00001612
Iteration 30/1000 | Loss: 0.00001611
Iteration 31/1000 | Loss: 0.00001611
Iteration 32/1000 | Loss: 0.00001610
Iteration 33/1000 | Loss: 0.00001610
Iteration 34/1000 | Loss: 0.00001609
Iteration 35/1000 | Loss: 0.00001609
Iteration 36/1000 | Loss: 0.00001609
Iteration 37/1000 | Loss: 0.00001608
Iteration 38/1000 | Loss: 0.00001608
Iteration 39/1000 | Loss: 0.00001607
Iteration 40/1000 | Loss: 0.00001607
Iteration 41/1000 | Loss: 0.00001607
Iteration 42/1000 | Loss: 0.00001606
Iteration 43/1000 | Loss: 0.00001605
Iteration 44/1000 | Loss: 0.00001605
Iteration 45/1000 | Loss: 0.00001605
Iteration 46/1000 | Loss: 0.00001605
Iteration 47/1000 | Loss: 0.00001605
Iteration 48/1000 | Loss: 0.00001605
Iteration 49/1000 | Loss: 0.00001605
Iteration 50/1000 | Loss: 0.00001604
Iteration 51/1000 | Loss: 0.00001604
Iteration 52/1000 | Loss: 0.00001602
Iteration 53/1000 | Loss: 0.00001602
Iteration 54/1000 | Loss: 0.00001602
Iteration 55/1000 | Loss: 0.00001602
Iteration 56/1000 | Loss: 0.00001602
Iteration 57/1000 | Loss: 0.00001601
Iteration 58/1000 | Loss: 0.00001601
Iteration 59/1000 | Loss: 0.00001601
Iteration 60/1000 | Loss: 0.00001601
Iteration 61/1000 | Loss: 0.00001601
Iteration 62/1000 | Loss: 0.00001601
Iteration 63/1000 | Loss: 0.00001601
Iteration 64/1000 | Loss: 0.00001601
Iteration 65/1000 | Loss: 0.00001601
Iteration 66/1000 | Loss: 0.00001599
Iteration 67/1000 | Loss: 0.00001599
Iteration 68/1000 | Loss: 0.00001599
Iteration 69/1000 | Loss: 0.00001598
Iteration 70/1000 | Loss: 0.00001598
Iteration 71/1000 | Loss: 0.00001598
Iteration 72/1000 | Loss: 0.00001598
Iteration 73/1000 | Loss: 0.00001598
Iteration 74/1000 | Loss: 0.00001597
Iteration 75/1000 | Loss: 0.00001597
Iteration 76/1000 | Loss: 0.00001596
Iteration 77/1000 | Loss: 0.00001596
Iteration 78/1000 | Loss: 0.00001595
Iteration 79/1000 | Loss: 0.00001595
Iteration 80/1000 | Loss: 0.00001595
Iteration 81/1000 | Loss: 0.00001595
Iteration 82/1000 | Loss: 0.00001595
Iteration 83/1000 | Loss: 0.00001595
Iteration 84/1000 | Loss: 0.00001595
Iteration 85/1000 | Loss: 0.00001594
Iteration 86/1000 | Loss: 0.00001594
Iteration 87/1000 | Loss: 0.00001594
Iteration 88/1000 | Loss: 0.00001594
Iteration 89/1000 | Loss: 0.00001594
Iteration 90/1000 | Loss: 0.00001594
Iteration 91/1000 | Loss: 0.00001594
Iteration 92/1000 | Loss: 0.00001594
Iteration 93/1000 | Loss: 0.00001594
Iteration 94/1000 | Loss: 0.00001594
Iteration 95/1000 | Loss: 0.00001594
Iteration 96/1000 | Loss: 0.00001594
Iteration 97/1000 | Loss: 0.00001593
Iteration 98/1000 | Loss: 0.00001593
Iteration 99/1000 | Loss: 0.00001593
Iteration 100/1000 | Loss: 0.00001592
Iteration 101/1000 | Loss: 0.00001592
Iteration 102/1000 | Loss: 0.00001592
Iteration 103/1000 | Loss: 0.00001591
Iteration 104/1000 | Loss: 0.00001591
Iteration 105/1000 | Loss: 0.00001591
Iteration 106/1000 | Loss: 0.00001591
Iteration 107/1000 | Loss: 0.00001590
Iteration 108/1000 | Loss: 0.00001590
Iteration 109/1000 | Loss: 0.00001590
Iteration 110/1000 | Loss: 0.00001590
Iteration 111/1000 | Loss: 0.00001590
Iteration 112/1000 | Loss: 0.00001590
Iteration 113/1000 | Loss: 0.00001589
Iteration 114/1000 | Loss: 0.00001589
Iteration 115/1000 | Loss: 0.00001589
Iteration 116/1000 | Loss: 0.00001589
Iteration 117/1000 | Loss: 0.00001589
Iteration 118/1000 | Loss: 0.00001589
Iteration 119/1000 | Loss: 0.00001589
Iteration 120/1000 | Loss: 0.00001589
Iteration 121/1000 | Loss: 0.00001589
Iteration 122/1000 | Loss: 0.00001589
Iteration 123/1000 | Loss: 0.00001589
Iteration 124/1000 | Loss: 0.00001589
Iteration 125/1000 | Loss: 0.00001589
Iteration 126/1000 | Loss: 0.00001589
Iteration 127/1000 | Loss: 0.00001588
Iteration 128/1000 | Loss: 0.00001588
Iteration 129/1000 | Loss: 0.00001588
Iteration 130/1000 | Loss: 0.00001588
Iteration 131/1000 | Loss: 0.00001588
Iteration 132/1000 | Loss: 0.00001588
Iteration 133/1000 | Loss: 0.00001588
Iteration 134/1000 | Loss: 0.00001588
Iteration 135/1000 | Loss: 0.00001588
Iteration 136/1000 | Loss: 0.00001588
Iteration 137/1000 | Loss: 0.00001588
Iteration 138/1000 | Loss: 0.00001588
Iteration 139/1000 | Loss: 0.00001588
Iteration 140/1000 | Loss: 0.00001588
Iteration 141/1000 | Loss: 0.00001588
Iteration 142/1000 | Loss: 0.00001588
Iteration 143/1000 | Loss: 0.00001588
Iteration 144/1000 | Loss: 0.00001588
Iteration 145/1000 | Loss: 0.00001588
Iteration 146/1000 | Loss: 0.00001588
Iteration 147/1000 | Loss: 0.00001588
Iteration 148/1000 | Loss: 0.00001588
Iteration 149/1000 | Loss: 0.00001588
Iteration 150/1000 | Loss: 0.00001588
Iteration 151/1000 | Loss: 0.00001588
Iteration 152/1000 | Loss: 0.00001588
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 152. Stopping optimization.
Last 5 losses: [1.587601400387939e-05, 1.587601400387939e-05, 1.587601400387939e-05, 1.587601400387939e-05, 1.587601400387939e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.587601400387939e-05

Optimization complete. Final v2v error: 3.3634471893310547 mm

Highest mean error: 3.98537278175354 mm for frame 35

Lowest mean error: 2.8921091556549072 mm for frame 96

Saving results

Total time: 35.139705419540405
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01042531
Iteration 2/25 | Loss: 0.00169861
Iteration 3/25 | Loss: 0.00116913
Iteration 4/25 | Loss: 0.00103427
Iteration 5/25 | Loss: 0.00097270
Iteration 6/25 | Loss: 0.00094892
Iteration 7/25 | Loss: 0.00093620
Iteration 8/25 | Loss: 0.00092783
Iteration 9/25 | Loss: 0.00091406
Iteration 10/25 | Loss: 0.00089734
Iteration 11/25 | Loss: 0.00087643
Iteration 12/25 | Loss: 0.00085980
Iteration 13/25 | Loss: 0.00085271
Iteration 14/25 | Loss: 0.00084467
Iteration 15/25 | Loss: 0.00083902
Iteration 16/25 | Loss: 0.00083062
Iteration 17/25 | Loss: 0.00082308
Iteration 18/25 | Loss: 0.00082034
Iteration 19/25 | Loss: 0.00081995
Iteration 20/25 | Loss: 0.00081829
Iteration 21/25 | Loss: 0.00081759
Iteration 22/25 | Loss: 0.00081626
Iteration 23/25 | Loss: 0.00081370
Iteration 24/25 | Loss: 0.00081371
Iteration 25/25 | Loss: 0.00081358

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45290911
Iteration 2/25 | Loss: 0.00056985
Iteration 3/25 | Loss: 0.00056985
Iteration 4/25 | Loss: 0.00056984
Iteration 5/25 | Loss: 0.00056984
Iteration 6/25 | Loss: 0.00056984
Iteration 7/25 | Loss: 0.00056984
Iteration 8/25 | Loss: 0.00056984
Iteration 9/25 | Loss: 0.00056984
Iteration 10/25 | Loss: 0.00056984
Iteration 11/25 | Loss: 0.00056984
Iteration 12/25 | Loss: 0.00056984
Iteration 13/25 | Loss: 0.00056984
Iteration 14/25 | Loss: 0.00056984
Iteration 15/25 | Loss: 0.00056984
Iteration 16/25 | Loss: 0.00056984
Iteration 17/25 | Loss: 0.00056984
Iteration 18/25 | Loss: 0.00056984
Iteration 19/25 | Loss: 0.00056984
Iteration 20/25 | Loss: 0.00056984
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0005698433378711343, 0.0005698433378711343, 0.0005698433378711343, 0.0005698433378711343, 0.0005698433378711343]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005698433378711343

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056984
Iteration 2/1000 | Loss: 0.00016612
Iteration 3/1000 | Loss: 0.00041442
Iteration 4/1000 | Loss: 0.00008013
Iteration 5/1000 | Loss: 0.00018081
Iteration 6/1000 | Loss: 0.00018066
Iteration 7/1000 | Loss: 0.00007881
Iteration 8/1000 | Loss: 0.00017245
Iteration 9/1000 | Loss: 0.00011855
Iteration 10/1000 | Loss: 0.00008629
Iteration 11/1000 | Loss: 0.00008300
Iteration 12/1000 | Loss: 0.00012428
Iteration 13/1000 | Loss: 0.00008225
Iteration 14/1000 | Loss: 0.00012554
Iteration 15/1000 | Loss: 0.00014006
Iteration 16/1000 | Loss: 0.00019919
Iteration 17/1000 | Loss: 0.00009503
Iteration 18/1000 | Loss: 0.00014094
Iteration 19/1000 | Loss: 0.00016752
Iteration 20/1000 | Loss: 0.00014514
Iteration 21/1000 | Loss: 0.00021868
Iteration 22/1000 | Loss: 0.00018821
Iteration 23/1000 | Loss: 0.00028366
Iteration 24/1000 | Loss: 0.00018549
Iteration 25/1000 | Loss: 0.00023496
Iteration 26/1000 | Loss: 0.00028595
Iteration 27/1000 | Loss: 0.00006270
Iteration 28/1000 | Loss: 0.00006002
Iteration 29/1000 | Loss: 0.00007180
Iteration 30/1000 | Loss: 0.00006543
Iteration 31/1000 | Loss: 0.00006916
Iteration 32/1000 | Loss: 0.00007000
Iteration 33/1000 | Loss: 0.00006737
Iteration 34/1000 | Loss: 0.00005962
Iteration 35/1000 | Loss: 0.00006083
Iteration 36/1000 | Loss: 0.00005258
Iteration 37/1000 | Loss: 0.00005835
Iteration 38/1000 | Loss: 0.00006829
Iteration 39/1000 | Loss: 0.00006825
Iteration 40/1000 | Loss: 0.00007097
Iteration 41/1000 | Loss: 0.00006713
Iteration 42/1000 | Loss: 0.00007128
Iteration 43/1000 | Loss: 0.00006754
Iteration 44/1000 | Loss: 0.00006060
Iteration 45/1000 | Loss: 0.00007178
Iteration 46/1000 | Loss: 0.00006032
Iteration 47/1000 | Loss: 0.00005570
Iteration 48/1000 | Loss: 0.00007516
Iteration 49/1000 | Loss: 0.00006686
Iteration 50/1000 | Loss: 0.00006843
Iteration 51/1000 | Loss: 0.00006404
Iteration 52/1000 | Loss: 0.00006774
Iteration 53/1000 | Loss: 0.00006493
Iteration 54/1000 | Loss: 0.00006287
Iteration 55/1000 | Loss: 0.00006882
Iteration 56/1000 | Loss: 0.00043292
Iteration 57/1000 | Loss: 0.00040601
Iteration 58/1000 | Loss: 0.00014059
Iteration 59/1000 | Loss: 0.00023917
Iteration 60/1000 | Loss: 0.00004465
Iteration 61/1000 | Loss: 0.00006406
Iteration 62/1000 | Loss: 0.00018865
Iteration 63/1000 | Loss: 0.00014676
Iteration 64/1000 | Loss: 0.00005099
Iteration 65/1000 | Loss: 0.00014032
Iteration 66/1000 | Loss: 0.00005777
Iteration 67/1000 | Loss: 0.00005534
Iteration 68/1000 | Loss: 0.00004954
Iteration 69/1000 | Loss: 0.00005615
Iteration 70/1000 | Loss: 0.00004380
Iteration 71/1000 | Loss: 0.00006398
Iteration 72/1000 | Loss: 0.00005070
Iteration 73/1000 | Loss: 0.00004704
Iteration 74/1000 | Loss: 0.00006510
Iteration 75/1000 | Loss: 0.00004340
Iteration 76/1000 | Loss: 0.00004200
Iteration 77/1000 | Loss: 0.00004836
Iteration 78/1000 | Loss: 0.00004952
Iteration 79/1000 | Loss: 0.00005246
Iteration 80/1000 | Loss: 0.00004637
Iteration 81/1000 | Loss: 0.00005331
Iteration 82/1000 | Loss: 0.00004533
Iteration 83/1000 | Loss: 0.00004986
Iteration 84/1000 | Loss: 0.00004279
Iteration 85/1000 | Loss: 0.00004468
Iteration 86/1000 | Loss: 0.00004542
Iteration 87/1000 | Loss: 0.00004737
Iteration 88/1000 | Loss: 0.00004576
Iteration 89/1000 | Loss: 0.00004723
Iteration 90/1000 | Loss: 0.00004546
Iteration 91/1000 | Loss: 0.00004630
Iteration 92/1000 | Loss: 0.00006627
Iteration 93/1000 | Loss: 0.00004235
Iteration 94/1000 | Loss: 0.00005824
Iteration 95/1000 | Loss: 0.00004497
Iteration 96/1000 | Loss: 0.00004048
Iteration 97/1000 | Loss: 0.00003633
Iteration 98/1000 | Loss: 0.00006310
Iteration 99/1000 | Loss: 0.00003519
Iteration 100/1000 | Loss: 0.00003306
Iteration 101/1000 | Loss: 0.00003218
Iteration 102/1000 | Loss: 0.00003187
Iteration 103/1000 | Loss: 0.00003176
Iteration 104/1000 | Loss: 0.00003174
Iteration 105/1000 | Loss: 0.00003174
Iteration 106/1000 | Loss: 0.00003173
Iteration 107/1000 | Loss: 0.00003170
Iteration 108/1000 | Loss: 0.00003170
Iteration 109/1000 | Loss: 0.00003170
Iteration 110/1000 | Loss: 0.00003169
Iteration 111/1000 | Loss: 0.00003169
Iteration 112/1000 | Loss: 0.00003168
Iteration 113/1000 | Loss: 0.00003168
Iteration 114/1000 | Loss: 0.00003167
Iteration 115/1000 | Loss: 0.00003167
Iteration 116/1000 | Loss: 0.00003166
Iteration 117/1000 | Loss: 0.00003165
Iteration 118/1000 | Loss: 0.00003165
Iteration 119/1000 | Loss: 0.00003164
Iteration 120/1000 | Loss: 0.00003164
Iteration 121/1000 | Loss: 0.00003164
Iteration 122/1000 | Loss: 0.00003160
Iteration 123/1000 | Loss: 0.00003160
Iteration 124/1000 | Loss: 0.00003157
Iteration 125/1000 | Loss: 0.00003151
Iteration 126/1000 | Loss: 0.00003149
Iteration 127/1000 | Loss: 0.00003148
Iteration 128/1000 | Loss: 0.00003146
Iteration 129/1000 | Loss: 0.00003146
Iteration 130/1000 | Loss: 0.00003145
Iteration 131/1000 | Loss: 0.00003145
Iteration 132/1000 | Loss: 0.00003144
Iteration 133/1000 | Loss: 0.00003143
Iteration 134/1000 | Loss: 0.00003143
Iteration 135/1000 | Loss: 0.00003143
Iteration 136/1000 | Loss: 0.00003142
Iteration 137/1000 | Loss: 0.00003141
Iteration 138/1000 | Loss: 0.00003140
Iteration 139/1000 | Loss: 0.00003139
Iteration 140/1000 | Loss: 0.00003139
Iteration 141/1000 | Loss: 0.00003138
Iteration 142/1000 | Loss: 0.00003138
Iteration 143/1000 | Loss: 0.00003138
Iteration 144/1000 | Loss: 0.00003138
Iteration 145/1000 | Loss: 0.00003138
Iteration 146/1000 | Loss: 0.00003138
Iteration 147/1000 | Loss: 0.00003138
Iteration 148/1000 | Loss: 0.00003137
Iteration 149/1000 | Loss: 0.00003137
Iteration 150/1000 | Loss: 0.00003137
Iteration 151/1000 | Loss: 0.00003137
Iteration 152/1000 | Loss: 0.00003137
Iteration 153/1000 | Loss: 0.00003137
Iteration 154/1000 | Loss: 0.00003137
Iteration 155/1000 | Loss: 0.00003137
Iteration 156/1000 | Loss: 0.00003136
Iteration 157/1000 | Loss: 0.00003136
Iteration 158/1000 | Loss: 0.00003136
Iteration 159/1000 | Loss: 0.00003136
Iteration 160/1000 | Loss: 0.00003135
Iteration 161/1000 | Loss: 0.00003135
Iteration 162/1000 | Loss: 0.00003135
Iteration 163/1000 | Loss: 0.00003135
Iteration 164/1000 | Loss: 0.00003135
Iteration 165/1000 | Loss: 0.00003135
Iteration 166/1000 | Loss: 0.00003135
Iteration 167/1000 | Loss: 0.00003135
Iteration 168/1000 | Loss: 0.00003135
Iteration 169/1000 | Loss: 0.00003135
Iteration 170/1000 | Loss: 0.00003135
Iteration 171/1000 | Loss: 0.00003134
Iteration 172/1000 | Loss: 0.00003134
Iteration 173/1000 | Loss: 0.00003133
Iteration 174/1000 | Loss: 0.00003133
Iteration 175/1000 | Loss: 0.00003132
Iteration 176/1000 | Loss: 0.00003132
Iteration 177/1000 | Loss: 0.00003131
Iteration 178/1000 | Loss: 0.00003130
Iteration 179/1000 | Loss: 0.00003130
Iteration 180/1000 | Loss: 0.00003130
Iteration 181/1000 | Loss: 0.00003129
Iteration 182/1000 | Loss: 0.00003129
Iteration 183/1000 | Loss: 0.00003129
Iteration 184/1000 | Loss: 0.00003129
Iteration 185/1000 | Loss: 0.00003129
Iteration 186/1000 | Loss: 0.00003129
Iteration 187/1000 | Loss: 0.00003129
Iteration 188/1000 | Loss: 0.00003129
Iteration 189/1000 | Loss: 0.00003129
Iteration 190/1000 | Loss: 0.00003129
Iteration 191/1000 | Loss: 0.00003129
Iteration 192/1000 | Loss: 0.00003128
Iteration 193/1000 | Loss: 0.00003128
Iteration 194/1000 | Loss: 0.00003128
Iteration 195/1000 | Loss: 0.00003128
Iteration 196/1000 | Loss: 0.00003128
Iteration 197/1000 | Loss: 0.00003128
Iteration 198/1000 | Loss: 0.00003128
Iteration 199/1000 | Loss: 0.00003128
Iteration 200/1000 | Loss: 0.00003128
Iteration 201/1000 | Loss: 0.00003128
Iteration 202/1000 | Loss: 0.00003127
Iteration 203/1000 | Loss: 0.00003127
Iteration 204/1000 | Loss: 0.00003127
Iteration 205/1000 | Loss: 0.00003127
Iteration 206/1000 | Loss: 0.00003127
Iteration 207/1000 | Loss: 0.00003127
Iteration 208/1000 | Loss: 0.00003127
Iteration 209/1000 | Loss: 0.00003127
Iteration 210/1000 | Loss: 0.00003127
Iteration 211/1000 | Loss: 0.00003126
Iteration 212/1000 | Loss: 0.00003126
Iteration 213/1000 | Loss: 0.00003126
Iteration 214/1000 | Loss: 0.00003126
Iteration 215/1000 | Loss: 0.00003125
Iteration 216/1000 | Loss: 0.00003125
Iteration 217/1000 | Loss: 0.00003125
Iteration 218/1000 | Loss: 0.00003125
Iteration 219/1000 | Loss: 0.00003125
Iteration 220/1000 | Loss: 0.00003125
Iteration 221/1000 | Loss: 0.00003125
Iteration 222/1000 | Loss: 0.00003124
Iteration 223/1000 | Loss: 0.00003124
Iteration 224/1000 | Loss: 0.00003124
Iteration 225/1000 | Loss: 0.00003124
Iteration 226/1000 | Loss: 0.00003124
Iteration 227/1000 | Loss: 0.00003124
Iteration 228/1000 | Loss: 0.00003124
Iteration 229/1000 | Loss: 0.00003124
Iteration 230/1000 | Loss: 0.00003124
Iteration 231/1000 | Loss: 0.00003124
Iteration 232/1000 | Loss: 0.00003124
Iteration 233/1000 | Loss: 0.00003124
Iteration 234/1000 | Loss: 0.00003124
Iteration 235/1000 | Loss: 0.00003124
Iteration 236/1000 | Loss: 0.00003124
Iteration 237/1000 | Loss: 0.00003124
Iteration 238/1000 | Loss: 0.00003124
Iteration 239/1000 | Loss: 0.00003124
Iteration 240/1000 | Loss: 0.00003124
Iteration 241/1000 | Loss: 0.00003124
Iteration 242/1000 | Loss: 0.00003124
Iteration 243/1000 | Loss: 0.00003124
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 243. Stopping optimization.
Last 5 losses: [3.1243780540535226e-05, 3.1243780540535226e-05, 3.1243780540535226e-05, 3.1243780540535226e-05, 3.1243780540535226e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.1243780540535226e-05

Optimization complete. Final v2v error: 4.7533860206604 mm

Highest mean error: 9.609527587890625 mm for frame 72

Lowest mean error: 3.8734424114227295 mm for frame 1

Saving results

Total time: 230.92894315719604
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00632253
Iteration 2/25 | Loss: 0.00115095
Iteration 3/25 | Loss: 0.00086289
Iteration 4/25 | Loss: 0.00082496
Iteration 5/25 | Loss: 0.00082019
Iteration 6/25 | Loss: 0.00081950
Iteration 7/25 | Loss: 0.00081950
Iteration 8/25 | Loss: 0.00081950
Iteration 9/25 | Loss: 0.00081950
Iteration 10/25 | Loss: 0.00081950
Iteration 11/25 | Loss: 0.00081950
Iteration 12/25 | Loss: 0.00081950
Iteration 13/25 | Loss: 0.00081950
Iteration 14/25 | Loss: 0.00081950
Iteration 15/25 | Loss: 0.00081950
Iteration 16/25 | Loss: 0.00081950
Iteration 17/25 | Loss: 0.00081950
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0008195008849725127, 0.0008195008849725127, 0.0008195008849725127, 0.0008195008849725127, 0.0008195008849725127]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008195008849725127

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.67151922
Iteration 2/25 | Loss: 0.00045527
Iteration 3/25 | Loss: 0.00045527
Iteration 4/25 | Loss: 0.00045527
Iteration 5/25 | Loss: 0.00045527
Iteration 6/25 | Loss: 0.00045527
Iteration 7/25 | Loss: 0.00045527
Iteration 8/25 | Loss: 0.00045527
Iteration 9/25 | Loss: 0.00045527
Iteration 10/25 | Loss: 0.00045527
Iteration 11/25 | Loss: 0.00045527
Iteration 12/25 | Loss: 0.00045527
Iteration 13/25 | Loss: 0.00045527
Iteration 14/25 | Loss: 0.00045527
Iteration 15/25 | Loss: 0.00045527
Iteration 16/25 | Loss: 0.00045527
Iteration 17/25 | Loss: 0.00045527
Iteration 18/25 | Loss: 0.00045527
Iteration 19/25 | Loss: 0.00045527
Iteration 20/25 | Loss: 0.00045527
Iteration 21/25 | Loss: 0.00045527
Iteration 22/25 | Loss: 0.00045527
Iteration 23/25 | Loss: 0.00045527
Iteration 24/25 | Loss: 0.00045527
Iteration 25/25 | Loss: 0.00045527

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045527
Iteration 2/1000 | Loss: 0.00005683
Iteration 3/1000 | Loss: 0.00004099
Iteration 4/1000 | Loss: 0.00003731
Iteration 5/1000 | Loss: 0.00003587
Iteration 6/1000 | Loss: 0.00003449
Iteration 7/1000 | Loss: 0.00003388
Iteration 8/1000 | Loss: 0.00003353
Iteration 9/1000 | Loss: 0.00003333
Iteration 10/1000 | Loss: 0.00003322
Iteration 11/1000 | Loss: 0.00003318
Iteration 12/1000 | Loss: 0.00003313
Iteration 13/1000 | Loss: 0.00003310
Iteration 14/1000 | Loss: 0.00003307
Iteration 15/1000 | Loss: 0.00003306
Iteration 16/1000 | Loss: 0.00003305
Iteration 17/1000 | Loss: 0.00003303
Iteration 18/1000 | Loss: 0.00003303
Iteration 19/1000 | Loss: 0.00003302
Iteration 20/1000 | Loss: 0.00003302
Iteration 21/1000 | Loss: 0.00003301
Iteration 22/1000 | Loss: 0.00003301
Iteration 23/1000 | Loss: 0.00003301
Iteration 24/1000 | Loss: 0.00003300
Iteration 25/1000 | Loss: 0.00003300
Iteration 26/1000 | Loss: 0.00003300
Iteration 27/1000 | Loss: 0.00003300
Iteration 28/1000 | Loss: 0.00003300
Iteration 29/1000 | Loss: 0.00003299
Iteration 30/1000 | Loss: 0.00003299
Iteration 31/1000 | Loss: 0.00003299
Iteration 32/1000 | Loss: 0.00003299
Iteration 33/1000 | Loss: 0.00003299
Iteration 34/1000 | Loss: 0.00003299
Iteration 35/1000 | Loss: 0.00003299
Iteration 36/1000 | Loss: 0.00003299
Iteration 37/1000 | Loss: 0.00003299
Iteration 38/1000 | Loss: 0.00003298
Iteration 39/1000 | Loss: 0.00003298
Iteration 40/1000 | Loss: 0.00003298
Iteration 41/1000 | Loss: 0.00003298
Iteration 42/1000 | Loss: 0.00003297
Iteration 43/1000 | Loss: 0.00003297
Iteration 44/1000 | Loss: 0.00003297
Iteration 45/1000 | Loss: 0.00003297
Iteration 46/1000 | Loss: 0.00003297
Iteration 47/1000 | Loss: 0.00003297
Iteration 48/1000 | Loss: 0.00003297
Iteration 49/1000 | Loss: 0.00003297
Iteration 50/1000 | Loss: 0.00003297
Iteration 51/1000 | Loss: 0.00003297
Iteration 52/1000 | Loss: 0.00003297
Iteration 53/1000 | Loss: 0.00003296
Iteration 54/1000 | Loss: 0.00003296
Iteration 55/1000 | Loss: 0.00003296
Iteration 56/1000 | Loss: 0.00003296
Iteration 57/1000 | Loss: 0.00003296
Iteration 58/1000 | Loss: 0.00003296
Iteration 59/1000 | Loss: 0.00003295
Iteration 60/1000 | Loss: 0.00003295
Iteration 61/1000 | Loss: 0.00003295
Iteration 62/1000 | Loss: 0.00003295
Iteration 63/1000 | Loss: 0.00003295
Iteration 64/1000 | Loss: 0.00003294
Iteration 65/1000 | Loss: 0.00003294
Iteration 66/1000 | Loss: 0.00003294
Iteration 67/1000 | Loss: 0.00003294
Iteration 68/1000 | Loss: 0.00003294
Iteration 69/1000 | Loss: 0.00003293
Iteration 70/1000 | Loss: 0.00003293
Iteration 71/1000 | Loss: 0.00003293
Iteration 72/1000 | Loss: 0.00003293
Iteration 73/1000 | Loss: 0.00003293
Iteration 74/1000 | Loss: 0.00003292
Iteration 75/1000 | Loss: 0.00003291
Iteration 76/1000 | Loss: 0.00003291
Iteration 77/1000 | Loss: 0.00003290
Iteration 78/1000 | Loss: 0.00003290
Iteration 79/1000 | Loss: 0.00003290
Iteration 80/1000 | Loss: 0.00003290
Iteration 81/1000 | Loss: 0.00003290
Iteration 82/1000 | Loss: 0.00003290
Iteration 83/1000 | Loss: 0.00003289
Iteration 84/1000 | Loss: 0.00003289
Iteration 85/1000 | Loss: 0.00003289
Iteration 86/1000 | Loss: 0.00003289
Iteration 87/1000 | Loss: 0.00003289
Iteration 88/1000 | Loss: 0.00003289
Iteration 89/1000 | Loss: 0.00003289
Iteration 90/1000 | Loss: 0.00003289
Iteration 91/1000 | Loss: 0.00003289
Iteration 92/1000 | Loss: 0.00003288
Iteration 93/1000 | Loss: 0.00003288
Iteration 94/1000 | Loss: 0.00003288
Iteration 95/1000 | Loss: 0.00003288
Iteration 96/1000 | Loss: 0.00003288
Iteration 97/1000 | Loss: 0.00003288
Iteration 98/1000 | Loss: 0.00003288
Iteration 99/1000 | Loss: 0.00003288
Iteration 100/1000 | Loss: 0.00003288
Iteration 101/1000 | Loss: 0.00003288
Iteration 102/1000 | Loss: 0.00003288
Iteration 103/1000 | Loss: 0.00003287
Iteration 104/1000 | Loss: 0.00003287
Iteration 105/1000 | Loss: 0.00003287
Iteration 106/1000 | Loss: 0.00003287
Iteration 107/1000 | Loss: 0.00003287
Iteration 108/1000 | Loss: 0.00003287
Iteration 109/1000 | Loss: 0.00003287
Iteration 110/1000 | Loss: 0.00003287
Iteration 111/1000 | Loss: 0.00003287
Iteration 112/1000 | Loss: 0.00003287
Iteration 113/1000 | Loss: 0.00003287
Iteration 114/1000 | Loss: 0.00003287
Iteration 115/1000 | Loss: 0.00003286
Iteration 116/1000 | Loss: 0.00003286
Iteration 117/1000 | Loss: 0.00003286
Iteration 118/1000 | Loss: 0.00003286
Iteration 119/1000 | Loss: 0.00003286
Iteration 120/1000 | Loss: 0.00003286
Iteration 121/1000 | Loss: 0.00003286
Iteration 122/1000 | Loss: 0.00003286
Iteration 123/1000 | Loss: 0.00003286
Iteration 124/1000 | Loss: 0.00003286
Iteration 125/1000 | Loss: 0.00003286
Iteration 126/1000 | Loss: 0.00003286
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 126. Stopping optimization.
Last 5 losses: [3.286134960944764e-05, 3.286134960944764e-05, 3.286134960944764e-05, 3.286134960944764e-05, 3.286134960944764e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.286134960944764e-05

Optimization complete. Final v2v error: 4.825662612915039 mm

Highest mean error: 5.059143543243408 mm for frame 34

Lowest mean error: 4.523402690887451 mm for frame 128

Saving results

Total time: 37.13807463645935
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00811689
Iteration 2/25 | Loss: 0.00122024
Iteration 3/25 | Loss: 0.00080229
Iteration 4/25 | Loss: 0.00067215
Iteration 5/25 | Loss: 0.00063239
Iteration 6/25 | Loss: 0.00060499
Iteration 7/25 | Loss: 0.00061900
Iteration 8/25 | Loss: 0.00060695
Iteration 9/25 | Loss: 0.00058894
Iteration 10/25 | Loss: 0.00058042
Iteration 11/25 | Loss: 0.00057167
Iteration 12/25 | Loss: 0.00056854
Iteration 13/25 | Loss: 0.00057139
Iteration 14/25 | Loss: 0.00056522
Iteration 15/25 | Loss: 0.00056498
Iteration 16/25 | Loss: 0.00056489
Iteration 17/25 | Loss: 0.00056489
Iteration 18/25 | Loss: 0.00056488
Iteration 19/25 | Loss: 0.00056488
Iteration 20/25 | Loss: 0.00056488
Iteration 21/25 | Loss: 0.00056488
Iteration 22/25 | Loss: 0.00056488
Iteration 23/25 | Loss: 0.00056488
Iteration 24/25 | Loss: 0.00056488
Iteration 25/25 | Loss: 0.00056488

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.91350985
Iteration 2/25 | Loss: 0.00036229
Iteration 3/25 | Loss: 0.00036226
Iteration 4/25 | Loss: 0.00036226
Iteration 5/25 | Loss: 0.00036226
Iteration 6/25 | Loss: 0.00036226
Iteration 7/25 | Loss: 0.00036226
Iteration 8/25 | Loss: 0.00036226
Iteration 9/25 | Loss: 0.00036226
Iteration 10/25 | Loss: 0.00036226
Iteration 11/25 | Loss: 0.00036226
Iteration 12/25 | Loss: 0.00036226
Iteration 13/25 | Loss: 0.00036226
Iteration 14/25 | Loss: 0.00036226
Iteration 15/25 | Loss: 0.00036226
Iteration 16/25 | Loss: 0.00036226
Iteration 17/25 | Loss: 0.00036226
Iteration 18/25 | Loss: 0.00036226
Iteration 19/25 | Loss: 0.00036226
Iteration 20/25 | Loss: 0.00036226
Iteration 21/25 | Loss: 0.00036226
Iteration 22/25 | Loss: 0.00036226
Iteration 23/25 | Loss: 0.00036226
Iteration 24/25 | Loss: 0.00036226
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00036225951043888927, 0.00036225951043888927, 0.00036225951043888927, 0.00036225951043888927, 0.00036225951043888927]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00036225951043888927

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00036226
Iteration 2/1000 | Loss: 0.00002562
Iteration 3/1000 | Loss: 0.00001685
Iteration 4/1000 | Loss: 0.00001550
Iteration 5/1000 | Loss: 0.00001476
Iteration 6/1000 | Loss: 0.00001444
Iteration 7/1000 | Loss: 0.00001429
Iteration 8/1000 | Loss: 0.00001408
Iteration 9/1000 | Loss: 0.00001398
Iteration 10/1000 | Loss: 0.00001394
Iteration 11/1000 | Loss: 0.00001394
Iteration 12/1000 | Loss: 0.00001382
Iteration 13/1000 | Loss: 0.00001378
Iteration 14/1000 | Loss: 0.00001378
Iteration 15/1000 | Loss: 0.00001377
Iteration 16/1000 | Loss: 0.00001377
Iteration 17/1000 | Loss: 0.00001376
Iteration 18/1000 | Loss: 0.00001376
Iteration 19/1000 | Loss: 0.00001376
Iteration 20/1000 | Loss: 0.00001374
Iteration 21/1000 | Loss: 0.00001372
Iteration 22/1000 | Loss: 0.00001372
Iteration 23/1000 | Loss: 0.00001371
Iteration 24/1000 | Loss: 0.00001370
Iteration 25/1000 | Loss: 0.00001370
Iteration 26/1000 | Loss: 0.00001370
Iteration 27/1000 | Loss: 0.00001370
Iteration 28/1000 | Loss: 0.00001369
Iteration 29/1000 | Loss: 0.00001368
Iteration 30/1000 | Loss: 0.00001367
Iteration 31/1000 | Loss: 0.00001367
Iteration 32/1000 | Loss: 0.00001367
Iteration 33/1000 | Loss: 0.00001366
Iteration 34/1000 | Loss: 0.00001366
Iteration 35/1000 | Loss: 0.00001366
Iteration 36/1000 | Loss: 0.00001366
Iteration 37/1000 | Loss: 0.00001366
Iteration 38/1000 | Loss: 0.00001365
Iteration 39/1000 | Loss: 0.00001365
Iteration 40/1000 | Loss: 0.00001365
Iteration 41/1000 | Loss: 0.00001365
Iteration 42/1000 | Loss: 0.00001365
Iteration 43/1000 | Loss: 0.00001365
Iteration 44/1000 | Loss: 0.00001364
Iteration 45/1000 | Loss: 0.00001364
Iteration 46/1000 | Loss: 0.00001364
Iteration 47/1000 | Loss: 0.00001363
Iteration 48/1000 | Loss: 0.00001363
Iteration 49/1000 | Loss: 0.00001362
Iteration 50/1000 | Loss: 0.00001362
Iteration 51/1000 | Loss: 0.00001361
Iteration 52/1000 | Loss: 0.00001361
Iteration 53/1000 | Loss: 0.00001361
Iteration 54/1000 | Loss: 0.00001361
Iteration 55/1000 | Loss: 0.00001360
Iteration 56/1000 | Loss: 0.00001360
Iteration 57/1000 | Loss: 0.00001360
Iteration 58/1000 | Loss: 0.00001360
Iteration 59/1000 | Loss: 0.00001360
Iteration 60/1000 | Loss: 0.00001359
Iteration 61/1000 | Loss: 0.00001359
Iteration 62/1000 | Loss: 0.00001359
Iteration 63/1000 | Loss: 0.00001359
Iteration 64/1000 | Loss: 0.00001358
Iteration 65/1000 | Loss: 0.00001358
Iteration 66/1000 | Loss: 0.00001358
Iteration 67/1000 | Loss: 0.00001358
Iteration 68/1000 | Loss: 0.00001358
Iteration 69/1000 | Loss: 0.00001358
Iteration 70/1000 | Loss: 0.00001358
Iteration 71/1000 | Loss: 0.00001357
Iteration 72/1000 | Loss: 0.00001357
Iteration 73/1000 | Loss: 0.00001357
Iteration 74/1000 | Loss: 0.00001357
Iteration 75/1000 | Loss: 0.00001357
Iteration 76/1000 | Loss: 0.00001357
Iteration 77/1000 | Loss: 0.00001357
Iteration 78/1000 | Loss: 0.00001357
Iteration 79/1000 | Loss: 0.00001357
Iteration 80/1000 | Loss: 0.00001357
Iteration 81/1000 | Loss: 0.00001357
Iteration 82/1000 | Loss: 0.00001357
Iteration 83/1000 | Loss: 0.00001357
Iteration 84/1000 | Loss: 0.00001357
Iteration 85/1000 | Loss: 0.00001356
Iteration 86/1000 | Loss: 0.00001356
Iteration 87/1000 | Loss: 0.00001356
Iteration 88/1000 | Loss: 0.00001356
Iteration 89/1000 | Loss: 0.00001356
Iteration 90/1000 | Loss: 0.00001356
Iteration 91/1000 | Loss: 0.00001356
Iteration 92/1000 | Loss: 0.00001355
Iteration 93/1000 | Loss: 0.00001355
Iteration 94/1000 | Loss: 0.00001355
Iteration 95/1000 | Loss: 0.00001355
Iteration 96/1000 | Loss: 0.00001355
Iteration 97/1000 | Loss: 0.00001355
Iteration 98/1000 | Loss: 0.00001355
Iteration 99/1000 | Loss: 0.00001355
Iteration 100/1000 | Loss: 0.00001355
Iteration 101/1000 | Loss: 0.00001355
Iteration 102/1000 | Loss: 0.00001355
Iteration 103/1000 | Loss: 0.00001355
Iteration 104/1000 | Loss: 0.00001355
Iteration 105/1000 | Loss: 0.00001355
Iteration 106/1000 | Loss: 0.00001355
Iteration 107/1000 | Loss: 0.00001355
Iteration 108/1000 | Loss: 0.00001355
Iteration 109/1000 | Loss: 0.00001355
Iteration 110/1000 | Loss: 0.00001354
Iteration 111/1000 | Loss: 0.00001354
Iteration 112/1000 | Loss: 0.00001354
Iteration 113/1000 | Loss: 0.00001354
Iteration 114/1000 | Loss: 0.00001354
Iteration 115/1000 | Loss: 0.00001353
Iteration 116/1000 | Loss: 0.00001353
Iteration 117/1000 | Loss: 0.00001353
Iteration 118/1000 | Loss: 0.00001353
Iteration 119/1000 | Loss: 0.00001353
Iteration 120/1000 | Loss: 0.00001353
Iteration 121/1000 | Loss: 0.00001353
Iteration 122/1000 | Loss: 0.00001353
Iteration 123/1000 | Loss: 0.00001353
Iteration 124/1000 | Loss: 0.00001352
Iteration 125/1000 | Loss: 0.00001352
Iteration 126/1000 | Loss: 0.00001352
Iteration 127/1000 | Loss: 0.00001352
Iteration 128/1000 | Loss: 0.00001352
Iteration 129/1000 | Loss: 0.00001352
Iteration 130/1000 | Loss: 0.00001352
Iteration 131/1000 | Loss: 0.00001352
Iteration 132/1000 | Loss: 0.00001352
Iteration 133/1000 | Loss: 0.00001352
Iteration 134/1000 | Loss: 0.00001352
Iteration 135/1000 | Loss: 0.00001352
Iteration 136/1000 | Loss: 0.00001352
Iteration 137/1000 | Loss: 0.00001352
Iteration 138/1000 | Loss: 0.00001352
Iteration 139/1000 | Loss: 0.00001352
Iteration 140/1000 | Loss: 0.00001352
Iteration 141/1000 | Loss: 0.00001352
Iteration 142/1000 | Loss: 0.00001352
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [1.352375875285361e-05, 1.352375875285361e-05, 1.352375875285361e-05, 1.352375875285361e-05, 1.352375875285361e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.352375875285361e-05

Optimization complete. Final v2v error: 3.2086024284362793 mm

Highest mean error: 3.6166625022888184 mm for frame 199

Lowest mean error: 2.8590707778930664 mm for frame 71

Saving results

Total time: 57.524646043777466
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00765953
Iteration 2/25 | Loss: 0.00083928
Iteration 3/25 | Loss: 0.00065195
Iteration 4/25 | Loss: 0.00061507
Iteration 5/25 | Loss: 0.00060747
Iteration 6/25 | Loss: 0.00060637
Iteration 7/25 | Loss: 0.00060637
Iteration 8/25 | Loss: 0.00060637
Iteration 9/25 | Loss: 0.00060637
Iteration 10/25 | Loss: 0.00060637
Iteration 11/25 | Loss: 0.00060637
Iteration 12/25 | Loss: 0.00060637
Iteration 13/25 | Loss: 0.00060637
Iteration 14/25 | Loss: 0.00060637
Iteration 15/25 | Loss: 0.00060637
Iteration 16/25 | Loss: 0.00060637
Iteration 17/25 | Loss: 0.00060637
Iteration 18/25 | Loss: 0.00060637
Iteration 19/25 | Loss: 0.00060637
Iteration 20/25 | Loss: 0.00060637
Iteration 21/25 | Loss: 0.00060637
Iteration 22/25 | Loss: 0.00060637
Iteration 23/25 | Loss: 0.00060637
Iteration 24/25 | Loss: 0.00060637
Iteration 25/25 | Loss: 0.00060637

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50015175
Iteration 2/25 | Loss: 0.00023092
Iteration 3/25 | Loss: 0.00023086
Iteration 4/25 | Loss: 0.00023086
Iteration 5/25 | Loss: 0.00023086
Iteration 6/25 | Loss: 0.00023086
Iteration 7/25 | Loss: 0.00023086
Iteration 8/25 | Loss: 0.00023086
Iteration 9/25 | Loss: 0.00023086
Iteration 10/25 | Loss: 0.00023086
Iteration 11/25 | Loss: 0.00023086
Iteration 12/25 | Loss: 0.00023086
Iteration 13/25 | Loss: 0.00023086
Iteration 14/25 | Loss: 0.00023086
Iteration 15/25 | Loss: 0.00023086
Iteration 16/25 | Loss: 0.00023086
Iteration 17/25 | Loss: 0.00023086
Iteration 18/25 | Loss: 0.00023086
Iteration 19/25 | Loss: 0.00023086
Iteration 20/25 | Loss: 0.00023086
Iteration 21/25 | Loss: 0.00023086
Iteration 22/25 | Loss: 0.00023086
Iteration 23/25 | Loss: 0.00023086
Iteration 24/25 | Loss: 0.00023086
Iteration 25/25 | Loss: 0.00023086

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00023086
Iteration 2/1000 | Loss: 0.00002273
Iteration 3/1000 | Loss: 0.00001732
Iteration 4/1000 | Loss: 0.00001554
Iteration 5/1000 | Loss: 0.00001441
Iteration 6/1000 | Loss: 0.00001392
Iteration 7/1000 | Loss: 0.00001365
Iteration 8/1000 | Loss: 0.00001335
Iteration 9/1000 | Loss: 0.00001332
Iteration 10/1000 | Loss: 0.00001321
Iteration 11/1000 | Loss: 0.00001317
Iteration 12/1000 | Loss: 0.00001314
Iteration 13/1000 | Loss: 0.00001309
Iteration 14/1000 | Loss: 0.00001309
Iteration 15/1000 | Loss: 0.00001308
Iteration 16/1000 | Loss: 0.00001305
Iteration 17/1000 | Loss: 0.00001304
Iteration 18/1000 | Loss: 0.00001303
Iteration 19/1000 | Loss: 0.00001301
Iteration 20/1000 | Loss: 0.00001297
Iteration 21/1000 | Loss: 0.00001296
Iteration 22/1000 | Loss: 0.00001295
Iteration 23/1000 | Loss: 0.00001295
Iteration 24/1000 | Loss: 0.00001294
Iteration 25/1000 | Loss: 0.00001293
Iteration 26/1000 | Loss: 0.00001293
Iteration 27/1000 | Loss: 0.00001292
Iteration 28/1000 | Loss: 0.00001291
Iteration 29/1000 | Loss: 0.00001291
Iteration 30/1000 | Loss: 0.00001291
Iteration 31/1000 | Loss: 0.00001291
Iteration 32/1000 | Loss: 0.00001291
Iteration 33/1000 | Loss: 0.00001291
Iteration 34/1000 | Loss: 0.00001290
Iteration 35/1000 | Loss: 0.00001289
Iteration 36/1000 | Loss: 0.00001289
Iteration 37/1000 | Loss: 0.00001289
Iteration 38/1000 | Loss: 0.00001288
Iteration 39/1000 | Loss: 0.00001288
Iteration 40/1000 | Loss: 0.00001288
Iteration 41/1000 | Loss: 0.00001288
Iteration 42/1000 | Loss: 0.00001288
Iteration 43/1000 | Loss: 0.00001288
Iteration 44/1000 | Loss: 0.00001288
Iteration 45/1000 | Loss: 0.00001288
Iteration 46/1000 | Loss: 0.00001288
Iteration 47/1000 | Loss: 0.00001288
Iteration 48/1000 | Loss: 0.00001287
Iteration 49/1000 | Loss: 0.00001287
Iteration 50/1000 | Loss: 0.00001287
Iteration 51/1000 | Loss: 0.00001286
Iteration 52/1000 | Loss: 0.00001286
Iteration 53/1000 | Loss: 0.00001286
Iteration 54/1000 | Loss: 0.00001286
Iteration 55/1000 | Loss: 0.00001286
Iteration 56/1000 | Loss: 0.00001286
Iteration 57/1000 | Loss: 0.00001286
Iteration 58/1000 | Loss: 0.00001286
Iteration 59/1000 | Loss: 0.00001286
Iteration 60/1000 | Loss: 0.00001286
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 60. Stopping optimization.
Last 5 losses: [1.2864144082413986e-05, 1.2864144082413986e-05, 1.2864144082413986e-05, 1.2864144082413986e-05, 1.2864144082413986e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2864144082413986e-05

Optimization complete. Final v2v error: 3.0556955337524414 mm

Highest mean error: 3.3022420406341553 mm for frame 174

Lowest mean error: 2.6584980487823486 mm for frame 139

Saving results

Total time: 31.36221742630005
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00848018
Iteration 2/25 | Loss: 0.00137055
Iteration 3/25 | Loss: 0.00098358
Iteration 4/25 | Loss: 0.00087231
Iteration 5/25 | Loss: 0.00083106
Iteration 6/25 | Loss: 0.00082260
Iteration 7/25 | Loss: 0.00081981
Iteration 8/25 | Loss: 0.00081928
Iteration 9/25 | Loss: 0.00084623
Iteration 10/25 | Loss: 0.00079686
Iteration 11/25 | Loss: 0.00079794
Iteration 12/25 | Loss: 0.00079026
Iteration 13/25 | Loss: 0.00077333
Iteration 14/25 | Loss: 0.00076364
Iteration 15/25 | Loss: 0.00076132
Iteration 16/25 | Loss: 0.00076024
Iteration 17/25 | Loss: 0.00076318
Iteration 18/25 | Loss: 0.00076139
Iteration 19/25 | Loss: 0.00075912
Iteration 20/25 | Loss: 0.00075724
Iteration 21/25 | Loss: 0.00075619
Iteration 22/25 | Loss: 0.00075573
Iteration 23/25 | Loss: 0.00075562
Iteration 24/25 | Loss: 0.00075544
Iteration 25/25 | Loss: 0.00075462

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.56790781
Iteration 2/25 | Loss: 0.00243232
Iteration 3/25 | Loss: 0.00243160
Iteration 4/25 | Loss: 0.00243160
Iteration 5/25 | Loss: 0.00243160
Iteration 6/25 | Loss: 0.00243160
Iteration 7/25 | Loss: 0.00243160
Iteration 8/25 | Loss: 0.00243160
Iteration 9/25 | Loss: 0.00243160
Iteration 10/25 | Loss: 0.00243160
Iteration 11/25 | Loss: 0.00243160
Iteration 12/25 | Loss: 0.00243160
Iteration 13/25 | Loss: 0.00243160
Iteration 14/25 | Loss: 0.00243160
Iteration 15/25 | Loss: 0.00243160
Iteration 16/25 | Loss: 0.00243160
Iteration 17/25 | Loss: 0.00243160
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0024315998889505863, 0.0024315998889505863, 0.0024315998889505863, 0.0024315998889505863, 0.0024315998889505863]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0024315998889505863

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00243160
Iteration 2/1000 | Loss: 0.00022371
Iteration 3/1000 | Loss: 0.00147889
Iteration 4/1000 | Loss: 0.00012557
Iteration 5/1000 | Loss: 0.00008046
Iteration 6/1000 | Loss: 0.00006001
Iteration 7/1000 | Loss: 0.00005003
Iteration 8/1000 | Loss: 0.00586605
Iteration 9/1000 | Loss: 0.00006122
Iteration 10/1000 | Loss: 0.00004363
Iteration 11/1000 | Loss: 0.00027824
Iteration 12/1000 | Loss: 0.00005869
Iteration 13/1000 | Loss: 0.00004581
Iteration 14/1000 | Loss: 0.00004067
Iteration 15/1000 | Loss: 0.00003820
Iteration 16/1000 | Loss: 0.00003620
Iteration 17/1000 | Loss: 0.00003522
Iteration 18/1000 | Loss: 0.00003431
Iteration 19/1000 | Loss: 0.00003361
Iteration 20/1000 | Loss: 0.00003328
Iteration 21/1000 | Loss: 0.00003304
Iteration 22/1000 | Loss: 0.00003272
Iteration 23/1000 | Loss: 0.00003242
Iteration 24/1000 | Loss: 0.00003220
Iteration 25/1000 | Loss: 0.00003202
Iteration 26/1000 | Loss: 0.00003198
Iteration 27/1000 | Loss: 0.00003192
Iteration 28/1000 | Loss: 0.00003190
Iteration 29/1000 | Loss: 0.00003185
Iteration 30/1000 | Loss: 0.00003181
Iteration 31/1000 | Loss: 0.00003178
Iteration 32/1000 | Loss: 0.00003177
Iteration 33/1000 | Loss: 0.00003176
Iteration 34/1000 | Loss: 0.00003174
Iteration 35/1000 | Loss: 0.00003174
Iteration 36/1000 | Loss: 0.00003170
Iteration 37/1000 | Loss: 0.00003170
Iteration 38/1000 | Loss: 0.00003170
Iteration 39/1000 | Loss: 0.00003170
Iteration 40/1000 | Loss: 0.00003170
Iteration 41/1000 | Loss: 0.00003170
Iteration 42/1000 | Loss: 0.00003170
Iteration 43/1000 | Loss: 0.00003170
Iteration 44/1000 | Loss: 0.00003170
Iteration 45/1000 | Loss: 0.00003170
Iteration 46/1000 | Loss: 0.00003169
Iteration 47/1000 | Loss: 0.00003169
Iteration 48/1000 | Loss: 0.00003167
Iteration 49/1000 | Loss: 0.00003166
Iteration 50/1000 | Loss: 0.00003166
Iteration 51/1000 | Loss: 0.00003164
Iteration 52/1000 | Loss: 0.00003164
Iteration 53/1000 | Loss: 0.00003164
Iteration 54/1000 | Loss: 0.00003164
Iteration 55/1000 | Loss: 0.00003163
Iteration 56/1000 | Loss: 0.00003163
Iteration 57/1000 | Loss: 0.00003163
Iteration 58/1000 | Loss: 0.00003163
Iteration 59/1000 | Loss: 0.00003163
Iteration 60/1000 | Loss: 0.00003162
Iteration 61/1000 | Loss: 0.00003162
Iteration 62/1000 | Loss: 0.00003162
Iteration 63/1000 | Loss: 0.00003162
Iteration 64/1000 | Loss: 0.00003162
Iteration 65/1000 | Loss: 0.00003162
Iteration 66/1000 | Loss: 0.00003162
Iteration 67/1000 | Loss: 0.00003161
Iteration 68/1000 | Loss: 0.00003161
Iteration 69/1000 | Loss: 0.00003161
Iteration 70/1000 | Loss: 0.00003161
Iteration 71/1000 | Loss: 0.00003161
Iteration 72/1000 | Loss: 0.00003161
Iteration 73/1000 | Loss: 0.00003160
Iteration 74/1000 | Loss: 0.00003160
Iteration 75/1000 | Loss: 0.00003160
Iteration 76/1000 | Loss: 0.00003160
Iteration 77/1000 | Loss: 0.00003160
Iteration 78/1000 | Loss: 0.00003160
Iteration 79/1000 | Loss: 0.00003159
Iteration 80/1000 | Loss: 0.00003158
Iteration 81/1000 | Loss: 0.00003158
Iteration 82/1000 | Loss: 0.00003158
Iteration 83/1000 | Loss: 0.00003157
Iteration 84/1000 | Loss: 0.00003157
Iteration 85/1000 | Loss: 0.00003157
Iteration 86/1000 | Loss: 0.00003156
Iteration 87/1000 | Loss: 0.00003155
Iteration 88/1000 | Loss: 0.00003155
Iteration 89/1000 | Loss: 0.00003153
Iteration 90/1000 | Loss: 0.00003153
Iteration 91/1000 | Loss: 0.00003152
Iteration 92/1000 | Loss: 0.00003152
Iteration 93/1000 | Loss: 0.00003152
Iteration 94/1000 | Loss: 0.00003152
Iteration 95/1000 | Loss: 0.00003152
Iteration 96/1000 | Loss: 0.00003152
Iteration 97/1000 | Loss: 0.00003151
Iteration 98/1000 | Loss: 0.00003150
Iteration 99/1000 | Loss: 0.00003150
Iteration 100/1000 | Loss: 0.00003150
Iteration 101/1000 | Loss: 0.00003150
Iteration 102/1000 | Loss: 0.00003149
Iteration 103/1000 | Loss: 0.00003149
Iteration 104/1000 | Loss: 0.00003149
Iteration 105/1000 | Loss: 0.00003149
Iteration 106/1000 | Loss: 0.00003148
Iteration 107/1000 | Loss: 0.00003148
Iteration 108/1000 | Loss: 0.00003148
Iteration 109/1000 | Loss: 0.00003148
Iteration 110/1000 | Loss: 0.00003147
Iteration 111/1000 | Loss: 0.00003147
Iteration 112/1000 | Loss: 0.00003147
Iteration 113/1000 | Loss: 0.00003146
Iteration 114/1000 | Loss: 0.00003146
Iteration 115/1000 | Loss: 0.00003143
Iteration 116/1000 | Loss: 0.00003143
Iteration 117/1000 | Loss: 0.00003142
Iteration 118/1000 | Loss: 0.00003141
Iteration 119/1000 | Loss: 0.00003141
Iteration 120/1000 | Loss: 0.00003141
Iteration 121/1000 | Loss: 0.00003140
Iteration 122/1000 | Loss: 0.00003140
Iteration 123/1000 | Loss: 0.00003140
Iteration 124/1000 | Loss: 0.00003140
Iteration 125/1000 | Loss: 0.00003140
Iteration 126/1000 | Loss: 0.00003139
Iteration 127/1000 | Loss: 0.00003139
Iteration 128/1000 | Loss: 0.00003139
Iteration 129/1000 | Loss: 0.00003139
Iteration 130/1000 | Loss: 0.00003138
Iteration 131/1000 | Loss: 0.00003138
Iteration 132/1000 | Loss: 0.00003138
Iteration 133/1000 | Loss: 0.00003138
Iteration 134/1000 | Loss: 0.00003138
Iteration 135/1000 | Loss: 0.00003138
Iteration 136/1000 | Loss: 0.00003137
Iteration 137/1000 | Loss: 0.00003137
Iteration 138/1000 | Loss: 0.00003137
Iteration 139/1000 | Loss: 0.00003137
Iteration 140/1000 | Loss: 0.00003137
Iteration 141/1000 | Loss: 0.00003137
Iteration 142/1000 | Loss: 0.00003137
Iteration 143/1000 | Loss: 0.00003137
Iteration 144/1000 | Loss: 0.00003137
Iteration 145/1000 | Loss: 0.00003137
Iteration 146/1000 | Loss: 0.00003137
Iteration 147/1000 | Loss: 0.00003137
Iteration 148/1000 | Loss: 0.00003137
Iteration 149/1000 | Loss: 0.00003137
Iteration 150/1000 | Loss: 0.00003137
Iteration 151/1000 | Loss: 0.00003137
Iteration 152/1000 | Loss: 0.00003137
Iteration 153/1000 | Loss: 0.00003137
Iteration 154/1000 | Loss: 0.00003137
Iteration 155/1000 | Loss: 0.00003137
Iteration 156/1000 | Loss: 0.00003137
Iteration 157/1000 | Loss: 0.00003137
Iteration 158/1000 | Loss: 0.00003137
Iteration 159/1000 | Loss: 0.00003137
Iteration 160/1000 | Loss: 0.00003137
Iteration 161/1000 | Loss: 0.00003137
Iteration 162/1000 | Loss: 0.00003137
Iteration 163/1000 | Loss: 0.00003137
Iteration 164/1000 | Loss: 0.00003137
Iteration 165/1000 | Loss: 0.00003137
Iteration 166/1000 | Loss: 0.00003137
Iteration 167/1000 | Loss: 0.00003137
Iteration 168/1000 | Loss: 0.00003137
Iteration 169/1000 | Loss: 0.00003137
Iteration 170/1000 | Loss: 0.00003137
Iteration 171/1000 | Loss: 0.00003137
Iteration 172/1000 | Loss: 0.00003137
Iteration 173/1000 | Loss: 0.00003137
Iteration 174/1000 | Loss: 0.00003137
Iteration 175/1000 | Loss: 0.00003137
Iteration 176/1000 | Loss: 0.00003137
Iteration 177/1000 | Loss: 0.00003137
Iteration 178/1000 | Loss: 0.00003137
Iteration 179/1000 | Loss: 0.00003137
Iteration 180/1000 | Loss: 0.00003137
Iteration 181/1000 | Loss: 0.00003137
Iteration 182/1000 | Loss: 0.00003137
Iteration 183/1000 | Loss: 0.00003137
Iteration 184/1000 | Loss: 0.00003137
Iteration 185/1000 | Loss: 0.00003137
Iteration 186/1000 | Loss: 0.00003137
Iteration 187/1000 | Loss: 0.00003137
Iteration 188/1000 | Loss: 0.00003137
Iteration 189/1000 | Loss: 0.00003137
Iteration 190/1000 | Loss: 0.00003137
Iteration 191/1000 | Loss: 0.00003137
Iteration 192/1000 | Loss: 0.00003137
Iteration 193/1000 | Loss: 0.00003137
Iteration 194/1000 | Loss: 0.00003137
Iteration 195/1000 | Loss: 0.00003137
Iteration 196/1000 | Loss: 0.00003137
Iteration 197/1000 | Loss: 0.00003137
Iteration 198/1000 | Loss: 0.00003137
Iteration 199/1000 | Loss: 0.00003137
Iteration 200/1000 | Loss: 0.00003137
Iteration 201/1000 | Loss: 0.00003137
Iteration 202/1000 | Loss: 0.00003137
Iteration 203/1000 | Loss: 0.00003137
Iteration 204/1000 | Loss: 0.00003137
Iteration 205/1000 | Loss: 0.00003137
Iteration 206/1000 | Loss: 0.00003137
Iteration 207/1000 | Loss: 0.00003137
Iteration 208/1000 | Loss: 0.00003137
Iteration 209/1000 | Loss: 0.00003137
Iteration 210/1000 | Loss: 0.00003137
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 210. Stopping optimization.
Last 5 losses: [3.136538725811988e-05, 3.136538725811988e-05, 3.136538725811988e-05, 3.136538725811988e-05, 3.136538725811988e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.136538725811988e-05

Optimization complete. Final v2v error: 4.41844367980957 mm

Highest mean error: 7.075593948364258 mm for frame 56

Lowest mean error: 2.7542576789855957 mm for frame 105

Saving results

Total time: 94.6430504322052
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00959159
Iteration 2/25 | Loss: 0.00314616
Iteration 3/25 | Loss: 0.00216523
Iteration 4/25 | Loss: 0.00178257
Iteration 5/25 | Loss: 0.00153818
Iteration 6/25 | Loss: 0.00143246
Iteration 7/25 | Loss: 0.00132143
Iteration 8/25 | Loss: 0.00147283
Iteration 9/25 | Loss: 0.00131541
Iteration 10/25 | Loss: 0.00131823
Iteration 11/25 | Loss: 0.00130351
Iteration 12/25 | Loss: 0.00137465
Iteration 13/25 | Loss: 0.00125082
Iteration 14/25 | Loss: 0.00125840
Iteration 15/25 | Loss: 0.00124708
Iteration 16/25 | Loss: 0.00127350
Iteration 17/25 | Loss: 0.00125835
Iteration 18/25 | Loss: 0.00120465
Iteration 19/25 | Loss: 0.00122699
Iteration 20/25 | Loss: 0.00120079
Iteration 21/25 | Loss: 0.00120190
Iteration 22/25 | Loss: 0.00117568
Iteration 23/25 | Loss: 0.00117423
Iteration 24/25 | Loss: 0.00119119
Iteration 25/25 | Loss: 0.00118084

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.45220709
Iteration 2/25 | Loss: 0.00866955
Iteration 3/25 | Loss: 0.00800391
Iteration 4/25 | Loss: 0.00800391
Iteration 5/25 | Loss: 0.00800391
Iteration 6/25 | Loss: 0.00800390
Iteration 7/25 | Loss: 0.00800390
Iteration 8/25 | Loss: 0.00800390
Iteration 9/25 | Loss: 0.00800390
Iteration 10/25 | Loss: 0.00800390
Iteration 11/25 | Loss: 0.00800390
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.008003904484212399, 0.008003904484212399, 0.008003904484212399, 0.008003904484212399, 0.008003904484212399]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.008003904484212399

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00800390
Iteration 2/1000 | Loss: 0.00638056
Iteration 3/1000 | Loss: 0.00458052
Iteration 4/1000 | Loss: 0.00418685
Iteration 5/1000 | Loss: 0.00917125
Iteration 6/1000 | Loss: 0.00953640
Iteration 7/1000 | Loss: 0.00566233
Iteration 8/1000 | Loss: 0.01093460
Iteration 9/1000 | Loss: 0.00837425
Iteration 10/1000 | Loss: 0.00468929
Iteration 11/1000 | Loss: 0.00347356
Iteration 12/1000 | Loss: 0.00466266
Iteration 13/1000 | Loss: 0.00367905
Iteration 14/1000 | Loss: 0.00284052
Iteration 15/1000 | Loss: 0.00156694
Iteration 16/1000 | Loss: 0.00144650
Iteration 17/1000 | Loss: 0.00560197
Iteration 18/1000 | Loss: 0.00248959
Iteration 19/1000 | Loss: 0.00272726
Iteration 20/1000 | Loss: 0.00100851
Iteration 21/1000 | Loss: 0.00517796
Iteration 22/1000 | Loss: 0.00097766
Iteration 23/1000 | Loss: 0.00197422
Iteration 24/1000 | Loss: 0.00074993
Iteration 25/1000 | Loss: 0.00239173
Iteration 26/1000 | Loss: 0.00144614
Iteration 27/1000 | Loss: 0.00188516
Iteration 28/1000 | Loss: 0.00088407
Iteration 29/1000 | Loss: 0.00129841
Iteration 30/1000 | Loss: 0.00114054
Iteration 31/1000 | Loss: 0.00436320
Iteration 32/1000 | Loss: 0.00279261
Iteration 33/1000 | Loss: 0.00115800
Iteration 34/1000 | Loss: 0.00082755
Iteration 35/1000 | Loss: 0.00100131
Iteration 36/1000 | Loss: 0.00160939
Iteration 37/1000 | Loss: 0.00480330
Iteration 38/1000 | Loss: 0.00088467
Iteration 39/1000 | Loss: 0.00102502
Iteration 40/1000 | Loss: 0.00154632
Iteration 41/1000 | Loss: 0.00087869
Iteration 42/1000 | Loss: 0.00176610
Iteration 43/1000 | Loss: 0.00296809
Iteration 44/1000 | Loss: 0.00388516
Iteration 45/1000 | Loss: 0.00225902
Iteration 46/1000 | Loss: 0.00285397
Iteration 47/1000 | Loss: 0.00404600
Iteration 48/1000 | Loss: 0.00291823
Iteration 49/1000 | Loss: 0.00271712
Iteration 50/1000 | Loss: 0.00149153
Iteration 51/1000 | Loss: 0.00187266
Iteration 52/1000 | Loss: 0.00156558
Iteration 53/1000 | Loss: 0.00112419
Iteration 54/1000 | Loss: 0.00112355
Iteration 55/1000 | Loss: 0.00131594
Iteration 56/1000 | Loss: 0.00294390
Iteration 57/1000 | Loss: 0.00217916
Iteration 58/1000 | Loss: 0.00259171
Iteration 59/1000 | Loss: 0.00166121
Iteration 60/1000 | Loss: 0.00151310
Iteration 61/1000 | Loss: 0.00296027
Iteration 62/1000 | Loss: 0.00163253
Iteration 63/1000 | Loss: 0.00323480
Iteration 64/1000 | Loss: 0.00199992
Iteration 65/1000 | Loss: 0.00189140
Iteration 66/1000 | Loss: 0.00136800
Iteration 67/1000 | Loss: 0.00084238
Iteration 68/1000 | Loss: 0.00126326
Iteration 69/1000 | Loss: 0.00215583
Iteration 70/1000 | Loss: 0.00170240
Iteration 71/1000 | Loss: 0.00171930
Iteration 72/1000 | Loss: 0.00085994
Iteration 73/1000 | Loss: 0.00149188
Iteration 74/1000 | Loss: 0.00100536
Iteration 75/1000 | Loss: 0.00094061
Iteration 76/1000 | Loss: 0.00103844
Iteration 77/1000 | Loss: 0.00075294
Iteration 78/1000 | Loss: 0.00401864
Iteration 79/1000 | Loss: 0.00401569
Iteration 80/1000 | Loss: 0.00559557
Iteration 81/1000 | Loss: 0.00456762
Iteration 82/1000 | Loss: 0.00367121
Iteration 83/1000 | Loss: 0.00133848
Iteration 84/1000 | Loss: 0.00249699
Iteration 85/1000 | Loss: 0.00634569
Iteration 86/1000 | Loss: 0.00290191
Iteration 87/1000 | Loss: 0.00529852
Iteration 88/1000 | Loss: 0.00650484
Iteration 89/1000 | Loss: 0.00414082
Iteration 90/1000 | Loss: 0.00329137
Iteration 91/1000 | Loss: 0.00095835
Iteration 92/1000 | Loss: 0.00128057
Iteration 93/1000 | Loss: 0.00314598
Iteration 94/1000 | Loss: 0.00077187
Iteration 95/1000 | Loss: 0.00088126
Iteration 96/1000 | Loss: 0.00259038
Iteration 97/1000 | Loss: 0.00029121
Iteration 98/1000 | Loss: 0.00180210
Iteration 99/1000 | Loss: 0.00020420
Iteration 100/1000 | Loss: 0.00223228
Iteration 101/1000 | Loss: 0.00017982
Iteration 102/1000 | Loss: 0.00013388
Iteration 103/1000 | Loss: 0.00256740
Iteration 104/1000 | Loss: 0.00051377
Iteration 105/1000 | Loss: 0.00182515
Iteration 106/1000 | Loss: 0.00020555
Iteration 107/1000 | Loss: 0.00083195
Iteration 108/1000 | Loss: 0.00061622
Iteration 109/1000 | Loss: 0.00009055
Iteration 110/1000 | Loss: 0.00007590
Iteration 111/1000 | Loss: 0.00006345
Iteration 112/1000 | Loss: 0.00097843
Iteration 113/1000 | Loss: 0.00095490
Iteration 114/1000 | Loss: 0.00156435
Iteration 115/1000 | Loss: 0.00062144
Iteration 116/1000 | Loss: 0.00267165
Iteration 117/1000 | Loss: 0.00130246
Iteration 118/1000 | Loss: 0.00035635
Iteration 119/1000 | Loss: 0.00010427
Iteration 120/1000 | Loss: 0.00013330
Iteration 121/1000 | Loss: 0.00037303
Iteration 122/1000 | Loss: 0.00026421
Iteration 123/1000 | Loss: 0.00056202
Iteration 124/1000 | Loss: 0.00006319
Iteration 125/1000 | Loss: 0.00005212
Iteration 126/1000 | Loss: 0.00008179
Iteration 127/1000 | Loss: 0.00011791
Iteration 128/1000 | Loss: 0.00005043
Iteration 129/1000 | Loss: 0.00024128
Iteration 130/1000 | Loss: 0.00004258
Iteration 131/1000 | Loss: 0.00011117
Iteration 132/1000 | Loss: 0.00013267
Iteration 133/1000 | Loss: 0.00079840
Iteration 134/1000 | Loss: 0.00090962
Iteration 135/1000 | Loss: 0.00005667
Iteration 136/1000 | Loss: 0.00004591
Iteration 137/1000 | Loss: 0.00054126
Iteration 138/1000 | Loss: 0.00004224
Iteration 139/1000 | Loss: 0.00005534
Iteration 140/1000 | Loss: 0.00004251
Iteration 141/1000 | Loss: 0.00112284
Iteration 142/1000 | Loss: 0.00069041
Iteration 143/1000 | Loss: 0.00008129
Iteration 144/1000 | Loss: 0.00021741
Iteration 145/1000 | Loss: 0.00022248
Iteration 146/1000 | Loss: 0.00004304
Iteration 147/1000 | Loss: 0.00003720
Iteration 148/1000 | Loss: 0.00003552
Iteration 149/1000 | Loss: 0.00003466
Iteration 150/1000 | Loss: 0.00003368
Iteration 151/1000 | Loss: 0.00004819
Iteration 152/1000 | Loss: 0.00003273
Iteration 153/1000 | Loss: 0.00082446
Iteration 154/1000 | Loss: 0.00049014
Iteration 155/1000 | Loss: 0.00007094
Iteration 156/1000 | Loss: 0.00007131
Iteration 157/1000 | Loss: 0.00010076
Iteration 158/1000 | Loss: 0.00042463
Iteration 159/1000 | Loss: 0.00003550
Iteration 160/1000 | Loss: 0.00003161
Iteration 161/1000 | Loss: 0.00002934
Iteration 162/1000 | Loss: 0.00002824
Iteration 163/1000 | Loss: 0.00002733
Iteration 164/1000 | Loss: 0.00017703
Iteration 165/1000 | Loss: 0.00002561
Iteration 166/1000 | Loss: 0.00002504
Iteration 167/1000 | Loss: 0.00002459
Iteration 168/1000 | Loss: 0.00002401
Iteration 169/1000 | Loss: 0.00002351
Iteration 170/1000 | Loss: 0.00002310
Iteration 171/1000 | Loss: 0.00002299
Iteration 172/1000 | Loss: 0.00002299
Iteration 173/1000 | Loss: 0.00002298
Iteration 174/1000 | Loss: 0.00002295
Iteration 175/1000 | Loss: 0.00002295
Iteration 176/1000 | Loss: 0.00002295
Iteration 177/1000 | Loss: 0.00002294
Iteration 178/1000 | Loss: 0.00002294
Iteration 179/1000 | Loss: 0.00002293
Iteration 180/1000 | Loss: 0.00002293
Iteration 181/1000 | Loss: 0.00002292
Iteration 182/1000 | Loss: 0.00002292
Iteration 183/1000 | Loss: 0.00002291
Iteration 184/1000 | Loss: 0.00002291
Iteration 185/1000 | Loss: 0.00002289
Iteration 186/1000 | Loss: 0.00002287
Iteration 187/1000 | Loss: 0.00002287
Iteration 188/1000 | Loss: 0.00002286
Iteration 189/1000 | Loss: 0.00002286
Iteration 190/1000 | Loss: 0.00002283
Iteration 191/1000 | Loss: 0.00002280
Iteration 192/1000 | Loss: 0.00002279
Iteration 193/1000 | Loss: 0.00002279
Iteration 194/1000 | Loss: 0.00002279
Iteration 195/1000 | Loss: 0.00004367
Iteration 196/1000 | Loss: 0.00002669
Iteration 197/1000 | Loss: 0.00002273
Iteration 198/1000 | Loss: 0.00002690
Iteration 199/1000 | Loss: 0.00002267
Iteration 200/1000 | Loss: 0.00002266
Iteration 201/1000 | Loss: 0.00003287
Iteration 202/1000 | Loss: 0.00002269
Iteration 203/1000 | Loss: 0.00002269
Iteration 204/1000 | Loss: 0.00002269
Iteration 205/1000 | Loss: 0.00002269
Iteration 206/1000 | Loss: 0.00002269
Iteration 207/1000 | Loss: 0.00002269
Iteration 208/1000 | Loss: 0.00002269
Iteration 209/1000 | Loss: 0.00002269
Iteration 210/1000 | Loss: 0.00002269
Iteration 211/1000 | Loss: 0.00002269
Iteration 212/1000 | Loss: 0.00002267
Iteration 213/1000 | Loss: 0.00002267
Iteration 214/1000 | Loss: 0.00002266
Iteration 215/1000 | Loss: 0.00002265
Iteration 216/1000 | Loss: 0.00002265
Iteration 217/1000 | Loss: 0.00002265
Iteration 218/1000 | Loss: 0.00002264
Iteration 219/1000 | Loss: 0.00002264
Iteration 220/1000 | Loss: 0.00002263
Iteration 221/1000 | Loss: 0.00002263
Iteration 222/1000 | Loss: 0.00002262
Iteration 223/1000 | Loss: 0.00002262
Iteration 224/1000 | Loss: 0.00002262
Iteration 225/1000 | Loss: 0.00002261
Iteration 226/1000 | Loss: 0.00002261
Iteration 227/1000 | Loss: 0.00002261
Iteration 228/1000 | Loss: 0.00002261
Iteration 229/1000 | Loss: 0.00002261
Iteration 230/1000 | Loss: 0.00002260
Iteration 231/1000 | Loss: 0.00002260
Iteration 232/1000 | Loss: 0.00002260
Iteration 233/1000 | Loss: 0.00002260
Iteration 234/1000 | Loss: 0.00002260
Iteration 235/1000 | Loss: 0.00002260
Iteration 236/1000 | Loss: 0.00002260
Iteration 237/1000 | Loss: 0.00002260
Iteration 238/1000 | Loss: 0.00002260
Iteration 239/1000 | Loss: 0.00002260
Iteration 240/1000 | Loss: 0.00002260
Iteration 241/1000 | Loss: 0.00002259
Iteration 242/1000 | Loss: 0.00002259
Iteration 243/1000 | Loss: 0.00002259
Iteration 244/1000 | Loss: 0.00002259
Iteration 245/1000 | Loss: 0.00002259
Iteration 246/1000 | Loss: 0.00002259
Iteration 247/1000 | Loss: 0.00002259
Iteration 248/1000 | Loss: 0.00002259
Iteration 249/1000 | Loss: 0.00002259
Iteration 250/1000 | Loss: 0.00002259
Iteration 251/1000 | Loss: 0.00002259
Iteration 252/1000 | Loss: 0.00002259
Iteration 253/1000 | Loss: 0.00002259
Iteration 254/1000 | Loss: 0.00002259
Iteration 255/1000 | Loss: 0.00002259
Iteration 256/1000 | Loss: 0.00002259
Iteration 257/1000 | Loss: 0.00002259
Iteration 258/1000 | Loss: 0.00002259
Iteration 259/1000 | Loss: 0.00002259
Iteration 260/1000 | Loss: 0.00002259
Iteration 261/1000 | Loss: 0.00002259
Iteration 262/1000 | Loss: 0.00002259
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 262. Stopping optimization.
Last 5 losses: [2.2591304514207877e-05, 2.2591304514207877e-05, 2.2591304514207877e-05, 2.2591304514207877e-05, 2.2591304514207877e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2591304514207877e-05

Optimization complete. Final v2v error: 3.587540864944458 mm

Highest mean error: 14.66305160522461 mm for frame 71

Lowest mean error: 2.616283893585205 mm for frame 199

Saving results

Total time: 319.63770294189453
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00463306
Iteration 2/25 | Loss: 0.00103474
Iteration 3/25 | Loss: 0.00071326
Iteration 4/25 | Loss: 0.00067546
Iteration 5/25 | Loss: 0.00066761
Iteration 6/25 | Loss: 0.00066664
Iteration 7/25 | Loss: 0.00066664
Iteration 8/25 | Loss: 0.00066664
Iteration 9/25 | Loss: 0.00066664
Iteration 10/25 | Loss: 0.00066664
Iteration 11/25 | Loss: 0.00066664
Iteration 12/25 | Loss: 0.00066664
Iteration 13/25 | Loss: 0.00066664
Iteration 14/25 | Loss: 0.00066664
Iteration 15/25 | Loss: 0.00066664
Iteration 16/25 | Loss: 0.00066664
Iteration 17/25 | Loss: 0.00066664
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006666380795650184, 0.0006666380795650184, 0.0006666380795650184, 0.0006666380795650184, 0.0006666380795650184]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006666380795650184

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48994136
Iteration 2/25 | Loss: 0.00038589
Iteration 3/25 | Loss: 0.00038589
Iteration 4/25 | Loss: 0.00038588
Iteration 5/25 | Loss: 0.00038588
Iteration 6/25 | Loss: 0.00038588
Iteration 7/25 | Loss: 0.00038588
Iteration 8/25 | Loss: 0.00038588
Iteration 9/25 | Loss: 0.00038588
Iteration 10/25 | Loss: 0.00038588
Iteration 11/25 | Loss: 0.00038588
Iteration 12/25 | Loss: 0.00038588
Iteration 13/25 | Loss: 0.00038588
Iteration 14/25 | Loss: 0.00038588
Iteration 15/25 | Loss: 0.00038588
Iteration 16/25 | Loss: 0.00038588
Iteration 17/25 | Loss: 0.00038588
Iteration 18/25 | Loss: 0.00038588
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00038588177994824946, 0.00038588177994824946, 0.00038588177994824946, 0.00038588177994824946, 0.00038588177994824946]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00038588177994824946

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038588
Iteration 2/1000 | Loss: 0.00004652
Iteration 3/1000 | Loss: 0.00003174
Iteration 4/1000 | Loss: 0.00002849
Iteration 5/1000 | Loss: 0.00002727
Iteration 6/1000 | Loss: 0.00002660
Iteration 7/1000 | Loss: 0.00002610
Iteration 8/1000 | Loss: 0.00002586
Iteration 9/1000 | Loss: 0.00002560
Iteration 10/1000 | Loss: 0.00002541
Iteration 11/1000 | Loss: 0.00002537
Iteration 12/1000 | Loss: 0.00002536
Iteration 13/1000 | Loss: 0.00002535
Iteration 14/1000 | Loss: 0.00002535
Iteration 15/1000 | Loss: 0.00002534
Iteration 16/1000 | Loss: 0.00002532
Iteration 17/1000 | Loss: 0.00002532
Iteration 18/1000 | Loss: 0.00002532
Iteration 19/1000 | Loss: 0.00002532
Iteration 20/1000 | Loss: 0.00002532
Iteration 21/1000 | Loss: 0.00002532
Iteration 22/1000 | Loss: 0.00002532
Iteration 23/1000 | Loss: 0.00002532
Iteration 24/1000 | Loss: 0.00002532
Iteration 25/1000 | Loss: 0.00002531
Iteration 26/1000 | Loss: 0.00002531
Iteration 27/1000 | Loss: 0.00002531
Iteration 28/1000 | Loss: 0.00002531
Iteration 29/1000 | Loss: 0.00002531
Iteration 30/1000 | Loss: 0.00002531
Iteration 31/1000 | Loss: 0.00002531
Iteration 32/1000 | Loss: 0.00002530
Iteration 33/1000 | Loss: 0.00002530
Iteration 34/1000 | Loss: 0.00002529
Iteration 35/1000 | Loss: 0.00002529
Iteration 36/1000 | Loss: 0.00002529
Iteration 37/1000 | Loss: 0.00002529
Iteration 38/1000 | Loss: 0.00002529
Iteration 39/1000 | Loss: 0.00002529
Iteration 40/1000 | Loss: 0.00002529
Iteration 41/1000 | Loss: 0.00002528
Iteration 42/1000 | Loss: 0.00002528
Iteration 43/1000 | Loss: 0.00002527
Iteration 44/1000 | Loss: 0.00002527
Iteration 45/1000 | Loss: 0.00002527
Iteration 46/1000 | Loss: 0.00002526
Iteration 47/1000 | Loss: 0.00002517
Iteration 48/1000 | Loss: 0.00002515
Iteration 49/1000 | Loss: 0.00002515
Iteration 50/1000 | Loss: 0.00002510
Iteration 51/1000 | Loss: 0.00002510
Iteration 52/1000 | Loss: 0.00002509
Iteration 53/1000 | Loss: 0.00002508
Iteration 54/1000 | Loss: 0.00002507
Iteration 55/1000 | Loss: 0.00002507
Iteration 56/1000 | Loss: 0.00002506
Iteration 57/1000 | Loss: 0.00002506
Iteration 58/1000 | Loss: 0.00002506
Iteration 59/1000 | Loss: 0.00002504
Iteration 60/1000 | Loss: 0.00002503
Iteration 61/1000 | Loss: 0.00002503
Iteration 62/1000 | Loss: 0.00002503
Iteration 63/1000 | Loss: 0.00002503
Iteration 64/1000 | Loss: 0.00002503
Iteration 65/1000 | Loss: 0.00002503
Iteration 66/1000 | Loss: 0.00002503
Iteration 67/1000 | Loss: 0.00002501
Iteration 68/1000 | Loss: 0.00002501
Iteration 69/1000 | Loss: 0.00002500
Iteration 70/1000 | Loss: 0.00002500
Iteration 71/1000 | Loss: 0.00002500
Iteration 72/1000 | Loss: 0.00002500
Iteration 73/1000 | Loss: 0.00002500
Iteration 74/1000 | Loss: 0.00002500
Iteration 75/1000 | Loss: 0.00002500
Iteration 76/1000 | Loss: 0.00002499
Iteration 77/1000 | Loss: 0.00002499
Iteration 78/1000 | Loss: 0.00002499
Iteration 79/1000 | Loss: 0.00002499
Iteration 80/1000 | Loss: 0.00002499
Iteration 81/1000 | Loss: 0.00002499
Iteration 82/1000 | Loss: 0.00002499
Iteration 83/1000 | Loss: 0.00002499
Iteration 84/1000 | Loss: 0.00002498
Iteration 85/1000 | Loss: 0.00002498
Iteration 86/1000 | Loss: 0.00002498
Iteration 87/1000 | Loss: 0.00002497
Iteration 88/1000 | Loss: 0.00002497
Iteration 89/1000 | Loss: 0.00002497
Iteration 90/1000 | Loss: 0.00002497
Iteration 91/1000 | Loss: 0.00002497
Iteration 92/1000 | Loss: 0.00002497
Iteration 93/1000 | Loss: 0.00002497
Iteration 94/1000 | Loss: 0.00002496
Iteration 95/1000 | Loss: 0.00002496
Iteration 96/1000 | Loss: 0.00002496
Iteration 97/1000 | Loss: 0.00002495
Iteration 98/1000 | Loss: 0.00002495
Iteration 99/1000 | Loss: 0.00002495
Iteration 100/1000 | Loss: 0.00002495
Iteration 101/1000 | Loss: 0.00002495
Iteration 102/1000 | Loss: 0.00002495
Iteration 103/1000 | Loss: 0.00002495
Iteration 104/1000 | Loss: 0.00002495
Iteration 105/1000 | Loss: 0.00002494
Iteration 106/1000 | Loss: 0.00002494
Iteration 107/1000 | Loss: 0.00002494
Iteration 108/1000 | Loss: 0.00002494
Iteration 109/1000 | Loss: 0.00002493
Iteration 110/1000 | Loss: 0.00002493
Iteration 111/1000 | Loss: 0.00002493
Iteration 112/1000 | Loss: 0.00002493
Iteration 113/1000 | Loss: 0.00002493
Iteration 114/1000 | Loss: 0.00002493
Iteration 115/1000 | Loss: 0.00002493
Iteration 116/1000 | Loss: 0.00002493
Iteration 117/1000 | Loss: 0.00002493
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [2.4930379368015565e-05, 2.4930379368015565e-05, 2.4930379368015565e-05, 2.4930379368015565e-05, 2.4930379368015565e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4930379368015565e-05

Optimization complete. Final v2v error: 4.043146133422852 mm

Highest mean error: 4.539308071136475 mm for frame 161

Lowest mean error: 3.5537919998168945 mm for frame 120

Saving results

Total time: 38.559070110321045
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00412167
Iteration 2/25 | Loss: 0.00072480
Iteration 3/25 | Loss: 0.00059966
Iteration 4/25 | Loss: 0.00057941
Iteration 5/25 | Loss: 0.00057204
Iteration 6/25 | Loss: 0.00057064
Iteration 7/25 | Loss: 0.00057026
Iteration 8/25 | Loss: 0.00057024
Iteration 9/25 | Loss: 0.00057024
Iteration 10/25 | Loss: 0.00057024
Iteration 11/25 | Loss: 0.00057024
Iteration 12/25 | Loss: 0.00057024
Iteration 13/25 | Loss: 0.00057024
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0005702421767637134, 0.0005702421767637134, 0.0005702421767637134, 0.0005702421767637134, 0.0005702421767637134]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005702421767637134

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.83118999
Iteration 2/25 | Loss: 0.00034994
Iteration 3/25 | Loss: 0.00034994
Iteration 4/25 | Loss: 0.00034994
Iteration 5/25 | Loss: 0.00034994
Iteration 6/25 | Loss: 0.00034993
Iteration 7/25 | Loss: 0.00034993
Iteration 8/25 | Loss: 0.00034993
Iteration 9/25 | Loss: 0.00034993
Iteration 10/25 | Loss: 0.00034993
Iteration 11/25 | Loss: 0.00034993
Iteration 12/25 | Loss: 0.00034993
Iteration 13/25 | Loss: 0.00034993
Iteration 14/25 | Loss: 0.00034993
Iteration 15/25 | Loss: 0.00034993
Iteration 16/25 | Loss: 0.00034993
Iteration 17/25 | Loss: 0.00034993
Iteration 18/25 | Loss: 0.00034993
Iteration 19/25 | Loss: 0.00034993
Iteration 20/25 | Loss: 0.00034993
Iteration 21/25 | Loss: 0.00034993
Iteration 22/25 | Loss: 0.00034993
Iteration 23/25 | Loss: 0.00034993
Iteration 24/25 | Loss: 0.00034993
Iteration 25/25 | Loss: 0.00034993
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0003499338054098189, 0.0003499338054098189, 0.0003499338054098189, 0.0003499338054098189, 0.0003499338054098189]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003499338054098189

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034993
Iteration 2/1000 | Loss: 0.00004039
Iteration 3/1000 | Loss: 0.00002471
Iteration 4/1000 | Loss: 0.00002021
Iteration 5/1000 | Loss: 0.00001877
Iteration 6/1000 | Loss: 0.00001740
Iteration 7/1000 | Loss: 0.00001696
Iteration 8/1000 | Loss: 0.00001662
Iteration 9/1000 | Loss: 0.00001637
Iteration 10/1000 | Loss: 0.00001613
Iteration 11/1000 | Loss: 0.00001602
Iteration 12/1000 | Loss: 0.00001599
Iteration 13/1000 | Loss: 0.00001591
Iteration 14/1000 | Loss: 0.00001581
Iteration 15/1000 | Loss: 0.00001579
Iteration 16/1000 | Loss: 0.00001579
Iteration 17/1000 | Loss: 0.00001577
Iteration 18/1000 | Loss: 0.00001576
Iteration 19/1000 | Loss: 0.00001576
Iteration 20/1000 | Loss: 0.00001576
Iteration 21/1000 | Loss: 0.00001575
Iteration 22/1000 | Loss: 0.00001575
Iteration 23/1000 | Loss: 0.00001574
Iteration 24/1000 | Loss: 0.00001574
Iteration 25/1000 | Loss: 0.00001574
Iteration 26/1000 | Loss: 0.00001574
Iteration 27/1000 | Loss: 0.00001574
Iteration 28/1000 | Loss: 0.00001574
Iteration 29/1000 | Loss: 0.00001573
Iteration 30/1000 | Loss: 0.00001573
Iteration 31/1000 | Loss: 0.00001573
Iteration 32/1000 | Loss: 0.00001573
Iteration 33/1000 | Loss: 0.00001573
Iteration 34/1000 | Loss: 0.00001573
Iteration 35/1000 | Loss: 0.00001572
Iteration 36/1000 | Loss: 0.00001572
Iteration 37/1000 | Loss: 0.00001571
Iteration 38/1000 | Loss: 0.00001571
Iteration 39/1000 | Loss: 0.00001571
Iteration 40/1000 | Loss: 0.00001571
Iteration 41/1000 | Loss: 0.00001571
Iteration 42/1000 | Loss: 0.00001571
Iteration 43/1000 | Loss: 0.00001570
Iteration 44/1000 | Loss: 0.00001570
Iteration 45/1000 | Loss: 0.00001570
Iteration 46/1000 | Loss: 0.00001570
Iteration 47/1000 | Loss: 0.00001570
Iteration 48/1000 | Loss: 0.00001570
Iteration 49/1000 | Loss: 0.00001570
Iteration 50/1000 | Loss: 0.00001570
Iteration 51/1000 | Loss: 0.00001569
Iteration 52/1000 | Loss: 0.00001569
Iteration 53/1000 | Loss: 0.00001569
Iteration 54/1000 | Loss: 0.00001568
Iteration 55/1000 | Loss: 0.00001568
Iteration 56/1000 | Loss: 0.00001568
Iteration 57/1000 | Loss: 0.00001567
Iteration 58/1000 | Loss: 0.00001567
Iteration 59/1000 | Loss: 0.00001567
Iteration 60/1000 | Loss: 0.00001567
Iteration 61/1000 | Loss: 0.00001566
Iteration 62/1000 | Loss: 0.00001566
Iteration 63/1000 | Loss: 0.00001566
Iteration 64/1000 | Loss: 0.00001566
Iteration 65/1000 | Loss: 0.00001566
Iteration 66/1000 | Loss: 0.00001566
Iteration 67/1000 | Loss: 0.00001565
Iteration 68/1000 | Loss: 0.00001565
Iteration 69/1000 | Loss: 0.00001565
Iteration 70/1000 | Loss: 0.00001565
Iteration 71/1000 | Loss: 0.00001564
Iteration 72/1000 | Loss: 0.00001564
Iteration 73/1000 | Loss: 0.00001564
Iteration 74/1000 | Loss: 0.00001563
Iteration 75/1000 | Loss: 0.00001563
Iteration 76/1000 | Loss: 0.00001563
Iteration 77/1000 | Loss: 0.00001563
Iteration 78/1000 | Loss: 0.00001562
Iteration 79/1000 | Loss: 0.00001562
Iteration 80/1000 | Loss: 0.00001562
Iteration 81/1000 | Loss: 0.00001562
Iteration 82/1000 | Loss: 0.00001562
Iteration 83/1000 | Loss: 0.00001562
Iteration 84/1000 | Loss: 0.00001562
Iteration 85/1000 | Loss: 0.00001562
Iteration 86/1000 | Loss: 0.00001562
Iteration 87/1000 | Loss: 0.00001561
Iteration 88/1000 | Loss: 0.00001561
Iteration 89/1000 | Loss: 0.00001561
Iteration 90/1000 | Loss: 0.00001561
Iteration 91/1000 | Loss: 0.00001561
Iteration 92/1000 | Loss: 0.00001561
Iteration 93/1000 | Loss: 0.00001560
Iteration 94/1000 | Loss: 0.00001560
Iteration 95/1000 | Loss: 0.00001560
Iteration 96/1000 | Loss: 0.00001560
Iteration 97/1000 | Loss: 0.00001560
Iteration 98/1000 | Loss: 0.00001560
Iteration 99/1000 | Loss: 0.00001560
Iteration 100/1000 | Loss: 0.00001560
Iteration 101/1000 | Loss: 0.00001560
Iteration 102/1000 | Loss: 0.00001560
Iteration 103/1000 | Loss: 0.00001560
Iteration 104/1000 | Loss: 0.00001560
Iteration 105/1000 | Loss: 0.00001560
Iteration 106/1000 | Loss: 0.00001560
Iteration 107/1000 | Loss: 0.00001560
Iteration 108/1000 | Loss: 0.00001560
Iteration 109/1000 | Loss: 0.00001559
Iteration 110/1000 | Loss: 0.00001559
Iteration 111/1000 | Loss: 0.00001559
Iteration 112/1000 | Loss: 0.00001559
Iteration 113/1000 | Loss: 0.00001559
Iteration 114/1000 | Loss: 0.00001559
Iteration 115/1000 | Loss: 0.00001559
Iteration 116/1000 | Loss: 0.00001559
Iteration 117/1000 | Loss: 0.00001559
Iteration 118/1000 | Loss: 0.00001559
Iteration 119/1000 | Loss: 0.00001559
Iteration 120/1000 | Loss: 0.00001559
Iteration 121/1000 | Loss: 0.00001559
Iteration 122/1000 | Loss: 0.00001559
Iteration 123/1000 | Loss: 0.00001559
Iteration 124/1000 | Loss: 0.00001559
Iteration 125/1000 | Loss: 0.00001559
Iteration 126/1000 | Loss: 0.00001559
Iteration 127/1000 | Loss: 0.00001558
Iteration 128/1000 | Loss: 0.00001558
Iteration 129/1000 | Loss: 0.00001558
Iteration 130/1000 | Loss: 0.00001558
Iteration 131/1000 | Loss: 0.00001558
Iteration 132/1000 | Loss: 0.00001558
Iteration 133/1000 | Loss: 0.00001558
Iteration 134/1000 | Loss: 0.00001558
Iteration 135/1000 | Loss: 0.00001558
Iteration 136/1000 | Loss: 0.00001558
Iteration 137/1000 | Loss: 0.00001558
Iteration 138/1000 | Loss: 0.00001558
Iteration 139/1000 | Loss: 0.00001558
Iteration 140/1000 | Loss: 0.00001558
Iteration 141/1000 | Loss: 0.00001558
Iteration 142/1000 | Loss: 0.00001558
Iteration 143/1000 | Loss: 0.00001558
Iteration 144/1000 | Loss: 0.00001557
Iteration 145/1000 | Loss: 0.00001557
Iteration 146/1000 | Loss: 0.00001557
Iteration 147/1000 | Loss: 0.00001557
Iteration 148/1000 | Loss: 0.00001557
Iteration 149/1000 | Loss: 0.00001557
Iteration 150/1000 | Loss: 0.00001557
Iteration 151/1000 | Loss: 0.00001557
Iteration 152/1000 | Loss: 0.00001557
Iteration 153/1000 | Loss: 0.00001557
Iteration 154/1000 | Loss: 0.00001557
Iteration 155/1000 | Loss: 0.00001557
Iteration 156/1000 | Loss: 0.00001557
Iteration 157/1000 | Loss: 0.00001556
Iteration 158/1000 | Loss: 0.00001556
Iteration 159/1000 | Loss: 0.00001556
Iteration 160/1000 | Loss: 0.00001556
Iteration 161/1000 | Loss: 0.00001556
Iteration 162/1000 | Loss: 0.00001556
Iteration 163/1000 | Loss: 0.00001556
Iteration 164/1000 | Loss: 0.00001556
Iteration 165/1000 | Loss: 0.00001556
Iteration 166/1000 | Loss: 0.00001556
Iteration 167/1000 | Loss: 0.00001556
Iteration 168/1000 | Loss: 0.00001556
Iteration 169/1000 | Loss: 0.00001556
Iteration 170/1000 | Loss: 0.00001556
Iteration 171/1000 | Loss: 0.00001556
Iteration 172/1000 | Loss: 0.00001556
Iteration 173/1000 | Loss: 0.00001556
Iteration 174/1000 | Loss: 0.00001556
Iteration 175/1000 | Loss: 0.00001556
Iteration 176/1000 | Loss: 0.00001556
Iteration 177/1000 | Loss: 0.00001556
Iteration 178/1000 | Loss: 0.00001556
Iteration 179/1000 | Loss: 0.00001556
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.5559666280751117e-05, 1.5559666280751117e-05, 1.5559666280751117e-05, 1.5559666280751117e-05, 1.5559666280751117e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5559666280751117e-05

Optimization complete. Final v2v error: 3.379424810409546 mm

Highest mean error: 4.080590724945068 mm for frame 72

Lowest mean error: 2.981024742126465 mm for frame 59

Saving results

Total time: 38.77044224739075
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00513616
Iteration 2/25 | Loss: 0.00087088
Iteration 3/25 | Loss: 0.00075014
Iteration 4/25 | Loss: 0.00070074
Iteration 5/25 | Loss: 0.00068223
Iteration 6/25 | Loss: 0.00067875
Iteration 7/25 | Loss: 0.00067807
Iteration 8/25 | Loss: 0.00067799
Iteration 9/25 | Loss: 0.00067799
Iteration 10/25 | Loss: 0.00067799
Iteration 11/25 | Loss: 0.00067799
Iteration 12/25 | Loss: 0.00067799
Iteration 13/25 | Loss: 0.00067799
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006779937539249659, 0.0006779937539249659, 0.0006779937539249659, 0.0006779937539249659, 0.0006779937539249659]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006779937539249659

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.79488516
Iteration 2/25 | Loss: 0.00035562
Iteration 3/25 | Loss: 0.00035562
Iteration 4/25 | Loss: 0.00035561
Iteration 5/25 | Loss: 0.00035561
Iteration 6/25 | Loss: 0.00035561
Iteration 7/25 | Loss: 0.00035561
Iteration 8/25 | Loss: 0.00035561
Iteration 9/25 | Loss: 0.00035561
Iteration 10/25 | Loss: 0.00035561
Iteration 11/25 | Loss: 0.00035561
Iteration 12/25 | Loss: 0.00035561
Iteration 13/25 | Loss: 0.00035561
Iteration 14/25 | Loss: 0.00035561
Iteration 15/25 | Loss: 0.00035561
Iteration 16/25 | Loss: 0.00035561
Iteration 17/25 | Loss: 0.00035561
Iteration 18/25 | Loss: 0.00035561
Iteration 19/25 | Loss: 0.00035561
Iteration 20/25 | Loss: 0.00035561
Iteration 21/25 | Loss: 0.00035561
Iteration 22/25 | Loss: 0.00035561
Iteration 23/25 | Loss: 0.00035561
Iteration 24/25 | Loss: 0.00035561
Iteration 25/25 | Loss: 0.00035561

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035561
Iteration 2/1000 | Loss: 0.00006001
Iteration 3/1000 | Loss: 0.00003663
Iteration 4/1000 | Loss: 0.00003026
Iteration 5/1000 | Loss: 0.00002802
Iteration 6/1000 | Loss: 0.00002670
Iteration 7/1000 | Loss: 0.00002597
Iteration 8/1000 | Loss: 0.00002534
Iteration 9/1000 | Loss: 0.00002489
Iteration 10/1000 | Loss: 0.00002466
Iteration 11/1000 | Loss: 0.00002445
Iteration 12/1000 | Loss: 0.00002443
Iteration 13/1000 | Loss: 0.00002436
Iteration 14/1000 | Loss: 0.00002427
Iteration 15/1000 | Loss: 0.00002423
Iteration 16/1000 | Loss: 0.00002419
Iteration 17/1000 | Loss: 0.00002417
Iteration 18/1000 | Loss: 0.00002415
Iteration 19/1000 | Loss: 0.00002413
Iteration 20/1000 | Loss: 0.00002413
Iteration 21/1000 | Loss: 0.00002413
Iteration 22/1000 | Loss: 0.00002413
Iteration 23/1000 | Loss: 0.00002412
Iteration 24/1000 | Loss: 0.00002412
Iteration 25/1000 | Loss: 0.00002412
Iteration 26/1000 | Loss: 0.00002412
Iteration 27/1000 | Loss: 0.00002412
Iteration 28/1000 | Loss: 0.00002411
Iteration 29/1000 | Loss: 0.00002410
Iteration 30/1000 | Loss: 0.00002409
Iteration 31/1000 | Loss: 0.00002409
Iteration 32/1000 | Loss: 0.00002409
Iteration 33/1000 | Loss: 0.00002408
Iteration 34/1000 | Loss: 0.00002408
Iteration 35/1000 | Loss: 0.00002407
Iteration 36/1000 | Loss: 0.00002407
Iteration 37/1000 | Loss: 0.00002407
Iteration 38/1000 | Loss: 0.00002407
Iteration 39/1000 | Loss: 0.00002406
Iteration 40/1000 | Loss: 0.00002406
Iteration 41/1000 | Loss: 0.00002406
Iteration 42/1000 | Loss: 0.00002406
Iteration 43/1000 | Loss: 0.00002406
Iteration 44/1000 | Loss: 0.00002406
Iteration 45/1000 | Loss: 0.00002406
Iteration 46/1000 | Loss: 0.00002406
Iteration 47/1000 | Loss: 0.00002406
Iteration 48/1000 | Loss: 0.00002405
Iteration 49/1000 | Loss: 0.00002405
Iteration 50/1000 | Loss: 0.00002405
Iteration 51/1000 | Loss: 0.00002405
Iteration 52/1000 | Loss: 0.00002405
Iteration 53/1000 | Loss: 0.00002405
Iteration 54/1000 | Loss: 0.00002405
Iteration 55/1000 | Loss: 0.00002405
Iteration 56/1000 | Loss: 0.00002404
Iteration 57/1000 | Loss: 0.00002404
Iteration 58/1000 | Loss: 0.00002404
Iteration 59/1000 | Loss: 0.00002403
Iteration 60/1000 | Loss: 0.00002403
Iteration 61/1000 | Loss: 0.00002403
Iteration 62/1000 | Loss: 0.00002402
Iteration 63/1000 | Loss: 0.00002401
Iteration 64/1000 | Loss: 0.00002401
Iteration 65/1000 | Loss: 0.00002401
Iteration 66/1000 | Loss: 0.00002401
Iteration 67/1000 | Loss: 0.00002400
Iteration 68/1000 | Loss: 0.00002400
Iteration 69/1000 | Loss: 0.00002399
Iteration 70/1000 | Loss: 0.00002399
Iteration 71/1000 | Loss: 0.00002398
Iteration 72/1000 | Loss: 0.00002398
Iteration 73/1000 | Loss: 0.00002398
Iteration 74/1000 | Loss: 0.00002397
Iteration 75/1000 | Loss: 0.00002397
Iteration 76/1000 | Loss: 0.00002397
Iteration 77/1000 | Loss: 0.00002397
Iteration 78/1000 | Loss: 0.00002396
Iteration 79/1000 | Loss: 0.00002396
Iteration 80/1000 | Loss: 0.00002395
Iteration 81/1000 | Loss: 0.00002395
Iteration 82/1000 | Loss: 0.00002395
Iteration 83/1000 | Loss: 0.00002395
Iteration 84/1000 | Loss: 0.00002395
Iteration 85/1000 | Loss: 0.00002395
Iteration 86/1000 | Loss: 0.00002395
Iteration 87/1000 | Loss: 0.00002395
Iteration 88/1000 | Loss: 0.00002395
Iteration 89/1000 | Loss: 0.00002395
Iteration 90/1000 | Loss: 0.00002395
Iteration 91/1000 | Loss: 0.00002395
Iteration 92/1000 | Loss: 0.00002395
Iteration 93/1000 | Loss: 0.00002394
Iteration 94/1000 | Loss: 0.00002394
Iteration 95/1000 | Loss: 0.00002394
Iteration 96/1000 | Loss: 0.00002394
Iteration 97/1000 | Loss: 0.00002394
Iteration 98/1000 | Loss: 0.00002393
Iteration 99/1000 | Loss: 0.00002393
Iteration 100/1000 | Loss: 0.00002393
Iteration 101/1000 | Loss: 0.00002393
Iteration 102/1000 | Loss: 0.00002393
Iteration 103/1000 | Loss: 0.00002393
Iteration 104/1000 | Loss: 0.00002393
Iteration 105/1000 | Loss: 0.00002393
Iteration 106/1000 | Loss: 0.00002393
Iteration 107/1000 | Loss: 0.00002392
Iteration 108/1000 | Loss: 0.00002392
Iteration 109/1000 | Loss: 0.00002392
Iteration 110/1000 | Loss: 0.00002392
Iteration 111/1000 | Loss: 0.00002392
Iteration 112/1000 | Loss: 0.00002392
Iteration 113/1000 | Loss: 0.00002392
Iteration 114/1000 | Loss: 0.00002391
Iteration 115/1000 | Loss: 0.00002391
Iteration 116/1000 | Loss: 0.00002391
Iteration 117/1000 | Loss: 0.00002391
Iteration 118/1000 | Loss: 0.00002390
Iteration 119/1000 | Loss: 0.00002390
Iteration 120/1000 | Loss: 0.00002390
Iteration 121/1000 | Loss: 0.00002390
Iteration 122/1000 | Loss: 0.00002390
Iteration 123/1000 | Loss: 0.00002389
Iteration 124/1000 | Loss: 0.00002389
Iteration 125/1000 | Loss: 0.00002388
Iteration 126/1000 | Loss: 0.00002388
Iteration 127/1000 | Loss: 0.00002388
Iteration 128/1000 | Loss: 0.00002388
Iteration 129/1000 | Loss: 0.00002388
Iteration 130/1000 | Loss: 0.00002387
Iteration 131/1000 | Loss: 0.00002387
Iteration 132/1000 | Loss: 0.00002387
Iteration 133/1000 | Loss: 0.00002387
Iteration 134/1000 | Loss: 0.00002387
Iteration 135/1000 | Loss: 0.00002386
Iteration 136/1000 | Loss: 0.00002386
Iteration 137/1000 | Loss: 0.00002386
Iteration 138/1000 | Loss: 0.00002386
Iteration 139/1000 | Loss: 0.00002386
Iteration 140/1000 | Loss: 0.00002386
Iteration 141/1000 | Loss: 0.00002386
Iteration 142/1000 | Loss: 0.00002386
Iteration 143/1000 | Loss: 0.00002385
Iteration 144/1000 | Loss: 0.00002385
Iteration 145/1000 | Loss: 0.00002385
Iteration 146/1000 | Loss: 0.00002385
Iteration 147/1000 | Loss: 0.00002385
Iteration 148/1000 | Loss: 0.00002385
Iteration 149/1000 | Loss: 0.00002385
Iteration 150/1000 | Loss: 0.00002385
Iteration 151/1000 | Loss: 0.00002385
Iteration 152/1000 | Loss: 0.00002385
Iteration 153/1000 | Loss: 0.00002385
Iteration 154/1000 | Loss: 0.00002385
Iteration 155/1000 | Loss: 0.00002385
Iteration 156/1000 | Loss: 0.00002385
Iteration 157/1000 | Loss: 0.00002385
Iteration 158/1000 | Loss: 0.00002385
Iteration 159/1000 | Loss: 0.00002385
Iteration 160/1000 | Loss: 0.00002385
Iteration 161/1000 | Loss: 0.00002384
Iteration 162/1000 | Loss: 0.00002384
Iteration 163/1000 | Loss: 0.00002384
Iteration 164/1000 | Loss: 0.00002384
Iteration 165/1000 | Loss: 0.00002384
Iteration 166/1000 | Loss: 0.00002384
Iteration 167/1000 | Loss: 0.00002384
Iteration 168/1000 | Loss: 0.00002384
Iteration 169/1000 | Loss: 0.00002384
Iteration 170/1000 | Loss: 0.00002384
Iteration 171/1000 | Loss: 0.00002384
Iteration 172/1000 | Loss: 0.00002384
Iteration 173/1000 | Loss: 0.00002383
Iteration 174/1000 | Loss: 0.00002383
Iteration 175/1000 | Loss: 0.00002383
Iteration 176/1000 | Loss: 0.00002383
Iteration 177/1000 | Loss: 0.00002383
Iteration 178/1000 | Loss: 0.00002383
Iteration 179/1000 | Loss: 0.00002383
Iteration 180/1000 | Loss: 0.00002383
Iteration 181/1000 | Loss: 0.00002383
Iteration 182/1000 | Loss: 0.00002383
Iteration 183/1000 | Loss: 0.00002383
Iteration 184/1000 | Loss: 0.00002383
Iteration 185/1000 | Loss: 0.00002383
Iteration 186/1000 | Loss: 0.00002383
Iteration 187/1000 | Loss: 0.00002383
Iteration 188/1000 | Loss: 0.00002383
Iteration 189/1000 | Loss: 0.00002383
Iteration 190/1000 | Loss: 0.00002383
Iteration 191/1000 | Loss: 0.00002383
Iteration 192/1000 | Loss: 0.00002383
Iteration 193/1000 | Loss: 0.00002383
Iteration 194/1000 | Loss: 0.00002383
Iteration 195/1000 | Loss: 0.00002383
Iteration 196/1000 | Loss: 0.00002383
Iteration 197/1000 | Loss: 0.00002383
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [2.3834540115785785e-05, 2.3834540115785785e-05, 2.3834540115785785e-05, 2.3834540115785785e-05, 2.3834540115785785e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3834540115785785e-05

Optimization complete. Final v2v error: 4.11862325668335 mm

Highest mean error: 4.828959941864014 mm for frame 96

Lowest mean error: 3.594956159591675 mm for frame 131

Saving results

Total time: 41.39276719093323
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01123965
Iteration 2/25 | Loss: 0.00162499
Iteration 3/25 | Loss: 0.00094750
Iteration 4/25 | Loss: 0.00080487
Iteration 5/25 | Loss: 0.00077030
Iteration 6/25 | Loss: 0.00076369
Iteration 7/25 | Loss: 0.00075796
Iteration 8/25 | Loss: 0.00075451
Iteration 9/25 | Loss: 0.00075155
Iteration 10/25 | Loss: 0.00075031
Iteration 11/25 | Loss: 0.00074997
Iteration 12/25 | Loss: 0.00074988
Iteration 13/25 | Loss: 0.00074988
Iteration 14/25 | Loss: 0.00074988
Iteration 15/25 | Loss: 0.00074988
Iteration 16/25 | Loss: 0.00074988
Iteration 17/25 | Loss: 0.00074987
Iteration 18/25 | Loss: 0.00074987
Iteration 19/25 | Loss: 0.00074987
Iteration 20/25 | Loss: 0.00074987
Iteration 21/25 | Loss: 0.00074987
Iteration 22/25 | Loss: 0.00074987
Iteration 23/25 | Loss: 0.00074987
Iteration 24/25 | Loss: 0.00074987
Iteration 25/25 | Loss: 0.00074987

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.85486031
Iteration 2/25 | Loss: 0.00062314
Iteration 3/25 | Loss: 0.00062306
Iteration 4/25 | Loss: 0.00062306
Iteration 5/25 | Loss: 0.00062306
Iteration 6/25 | Loss: 0.00062306
Iteration 7/25 | Loss: 0.00062306
Iteration 8/25 | Loss: 0.00062306
Iteration 9/25 | Loss: 0.00062305
Iteration 10/25 | Loss: 0.00062305
Iteration 11/25 | Loss: 0.00062305
Iteration 12/25 | Loss: 0.00062305
Iteration 13/25 | Loss: 0.00062305
Iteration 14/25 | Loss: 0.00062305
Iteration 15/25 | Loss: 0.00062305
Iteration 16/25 | Loss: 0.00062305
Iteration 17/25 | Loss: 0.00062305
Iteration 18/25 | Loss: 0.00062305
Iteration 19/25 | Loss: 0.00062305
Iteration 20/25 | Loss: 0.00062305
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0006230543367564678, 0.0006230543367564678, 0.0006230543367564678, 0.0006230543367564678, 0.0006230543367564678]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006230543367564678

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062305
Iteration 2/1000 | Loss: 0.00006260
Iteration 3/1000 | Loss: 0.00003847
Iteration 4/1000 | Loss: 0.00003342
Iteration 5/1000 | Loss: 0.00003110
Iteration 6/1000 | Loss: 0.00002915
Iteration 7/1000 | Loss: 0.00002828
Iteration 8/1000 | Loss: 0.00002775
Iteration 9/1000 | Loss: 0.00002732
Iteration 10/1000 | Loss: 0.00002693
Iteration 11/1000 | Loss: 0.00002669
Iteration 12/1000 | Loss: 0.00002650
Iteration 13/1000 | Loss: 0.00002644
Iteration 14/1000 | Loss: 0.00002642
Iteration 15/1000 | Loss: 0.00002625
Iteration 16/1000 | Loss: 0.00002613
Iteration 17/1000 | Loss: 0.00002612
Iteration 18/1000 | Loss: 0.00002599
Iteration 19/1000 | Loss: 0.00002598
Iteration 20/1000 | Loss: 0.00002592
Iteration 21/1000 | Loss: 0.00002589
Iteration 22/1000 | Loss: 0.00002589
Iteration 23/1000 | Loss: 0.00002588
Iteration 24/1000 | Loss: 0.00002587
Iteration 25/1000 | Loss: 0.00002585
Iteration 26/1000 | Loss: 0.00002585
Iteration 27/1000 | Loss: 0.00002585
Iteration 28/1000 | Loss: 0.00002585
Iteration 29/1000 | Loss: 0.00002585
Iteration 30/1000 | Loss: 0.00002585
Iteration 31/1000 | Loss: 0.00002584
Iteration 32/1000 | Loss: 0.00002583
Iteration 33/1000 | Loss: 0.00002583
Iteration 34/1000 | Loss: 0.00002582
Iteration 35/1000 | Loss: 0.00002582
Iteration 36/1000 | Loss: 0.00002582
Iteration 37/1000 | Loss: 0.00002581
Iteration 38/1000 | Loss: 0.00002581
Iteration 39/1000 | Loss: 0.00002580
Iteration 40/1000 | Loss: 0.00002580
Iteration 41/1000 | Loss: 0.00002580
Iteration 42/1000 | Loss: 0.00002579
Iteration 43/1000 | Loss: 0.00002579
Iteration 44/1000 | Loss: 0.00002579
Iteration 45/1000 | Loss: 0.00002579
Iteration 46/1000 | Loss: 0.00002578
Iteration 47/1000 | Loss: 0.00002578
Iteration 48/1000 | Loss: 0.00002577
Iteration 49/1000 | Loss: 0.00002577
Iteration 50/1000 | Loss: 0.00002577
Iteration 51/1000 | Loss: 0.00002577
Iteration 52/1000 | Loss: 0.00002576
Iteration 53/1000 | Loss: 0.00002576
Iteration 54/1000 | Loss: 0.00002576
Iteration 55/1000 | Loss: 0.00002576
Iteration 56/1000 | Loss: 0.00002576
Iteration 57/1000 | Loss: 0.00002575
Iteration 58/1000 | Loss: 0.00002575
Iteration 59/1000 | Loss: 0.00002575
Iteration 60/1000 | Loss: 0.00002575
Iteration 61/1000 | Loss: 0.00002574
Iteration 62/1000 | Loss: 0.00002574
Iteration 63/1000 | Loss: 0.00002574
Iteration 64/1000 | Loss: 0.00002574
Iteration 65/1000 | Loss: 0.00002574
Iteration 66/1000 | Loss: 0.00002574
Iteration 67/1000 | Loss: 0.00002574
Iteration 68/1000 | Loss: 0.00002574
Iteration 69/1000 | Loss: 0.00002574
Iteration 70/1000 | Loss: 0.00002574
Iteration 71/1000 | Loss: 0.00002574
Iteration 72/1000 | Loss: 0.00002574
Iteration 73/1000 | Loss: 0.00002574
Iteration 74/1000 | Loss: 0.00002574
Iteration 75/1000 | Loss: 0.00002574
Iteration 76/1000 | Loss: 0.00002574
Iteration 77/1000 | Loss: 0.00002574
Iteration 78/1000 | Loss: 0.00002574
Iteration 79/1000 | Loss: 0.00002574
Iteration 80/1000 | Loss: 0.00002574
Iteration 81/1000 | Loss: 0.00002574
Iteration 82/1000 | Loss: 0.00002574
Iteration 83/1000 | Loss: 0.00002574
Iteration 84/1000 | Loss: 0.00002574
Iteration 85/1000 | Loss: 0.00002574
Iteration 86/1000 | Loss: 0.00002574
Iteration 87/1000 | Loss: 0.00002574
Iteration 88/1000 | Loss: 0.00002574
Iteration 89/1000 | Loss: 0.00002574
Iteration 90/1000 | Loss: 0.00002574
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 90. Stopping optimization.
Last 5 losses: [2.574412246758584e-05, 2.574412246758584e-05, 2.574412246758584e-05, 2.574412246758584e-05, 2.574412246758584e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.574412246758584e-05

Optimization complete. Final v2v error: 4.081491947174072 mm

Highest mean error: 5.00990104675293 mm for frame 57

Lowest mean error: 3.134732484817505 mm for frame 161

Saving results

Total time: 54.7333550453186
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00706688
Iteration 2/25 | Loss: 0.00074259
Iteration 3/25 | Loss: 0.00057271
Iteration 4/25 | Loss: 0.00054253
Iteration 5/25 | Loss: 0.00053084
Iteration 6/25 | Loss: 0.00052848
Iteration 7/25 | Loss: 0.00052812
Iteration 8/25 | Loss: 0.00052812
Iteration 9/25 | Loss: 0.00052812
Iteration 10/25 | Loss: 0.00052812
Iteration 11/25 | Loss: 0.00052812
Iteration 12/25 | Loss: 0.00052812
Iteration 13/25 | Loss: 0.00052812
Iteration 14/25 | Loss: 0.00052812
Iteration 15/25 | Loss: 0.00052812
Iteration 16/25 | Loss: 0.00052812
Iteration 17/25 | Loss: 0.00052812
Iteration 18/25 | Loss: 0.00052812
Iteration 19/25 | Loss: 0.00052812
Iteration 20/25 | Loss: 0.00052812
Iteration 21/25 | Loss: 0.00052812
Iteration 22/25 | Loss: 0.00052812
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005281156627461314, 0.0005281156627461314, 0.0005281156627461314, 0.0005281156627461314, 0.0005281156627461314]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005281156627461314

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56377494
Iteration 2/25 | Loss: 0.00031951
Iteration 3/25 | Loss: 0.00031950
Iteration 4/25 | Loss: 0.00031950
Iteration 5/25 | Loss: 0.00031950
Iteration 6/25 | Loss: 0.00031950
Iteration 7/25 | Loss: 0.00031950
Iteration 8/25 | Loss: 0.00031950
Iteration 9/25 | Loss: 0.00031950
Iteration 10/25 | Loss: 0.00031950
Iteration 11/25 | Loss: 0.00031950
Iteration 12/25 | Loss: 0.00031950
Iteration 13/25 | Loss: 0.00031950
Iteration 14/25 | Loss: 0.00031950
Iteration 15/25 | Loss: 0.00031950
Iteration 16/25 | Loss: 0.00031950
Iteration 17/25 | Loss: 0.00031950
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003195023746229708, 0.0003195023746229708, 0.0003195023746229708, 0.0003195023746229708, 0.0003195023746229708]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003195023746229708

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031950
Iteration 2/1000 | Loss: 0.00002920
Iteration 3/1000 | Loss: 0.00001453
Iteration 4/1000 | Loss: 0.00001215
Iteration 5/1000 | Loss: 0.00001088
Iteration 6/1000 | Loss: 0.00001044
Iteration 7/1000 | Loss: 0.00001027
Iteration 8/1000 | Loss: 0.00001015
Iteration 9/1000 | Loss: 0.00001012
Iteration 10/1000 | Loss: 0.00001011
Iteration 11/1000 | Loss: 0.00001010
Iteration 12/1000 | Loss: 0.00001010
Iteration 13/1000 | Loss: 0.00001009
Iteration 14/1000 | Loss: 0.00001009
Iteration 15/1000 | Loss: 0.00001009
Iteration 16/1000 | Loss: 0.00001009
Iteration 17/1000 | Loss: 0.00001008
Iteration 18/1000 | Loss: 0.00001008
Iteration 19/1000 | Loss: 0.00001007
Iteration 20/1000 | Loss: 0.00001007
Iteration 21/1000 | Loss: 0.00001006
Iteration 22/1000 | Loss: 0.00001005
Iteration 23/1000 | Loss: 0.00001005
Iteration 24/1000 | Loss: 0.00001002
Iteration 25/1000 | Loss: 0.00001002
Iteration 26/1000 | Loss: 0.00001002
Iteration 27/1000 | Loss: 0.00001002
Iteration 28/1000 | Loss: 0.00001002
Iteration 29/1000 | Loss: 0.00001002
Iteration 30/1000 | Loss: 0.00001002
Iteration 31/1000 | Loss: 0.00001002
Iteration 32/1000 | Loss: 0.00001001
Iteration 33/1000 | Loss: 0.00001001
Iteration 34/1000 | Loss: 0.00001001
Iteration 35/1000 | Loss: 0.00000998
Iteration 36/1000 | Loss: 0.00000998
Iteration 37/1000 | Loss: 0.00000998
Iteration 38/1000 | Loss: 0.00000997
Iteration 39/1000 | Loss: 0.00000996
Iteration 40/1000 | Loss: 0.00000994
Iteration 41/1000 | Loss: 0.00000994
Iteration 42/1000 | Loss: 0.00000994
Iteration 43/1000 | Loss: 0.00000994
Iteration 44/1000 | Loss: 0.00000994
Iteration 45/1000 | Loss: 0.00000994
Iteration 46/1000 | Loss: 0.00000994
Iteration 47/1000 | Loss: 0.00000994
Iteration 48/1000 | Loss: 0.00000994
Iteration 49/1000 | Loss: 0.00000994
Iteration 50/1000 | Loss: 0.00000993
Iteration 51/1000 | Loss: 0.00000993
Iteration 52/1000 | Loss: 0.00000993
Iteration 53/1000 | Loss: 0.00000993
Iteration 54/1000 | Loss: 0.00000993
Iteration 55/1000 | Loss: 0.00000993
Iteration 56/1000 | Loss: 0.00000993
Iteration 57/1000 | Loss: 0.00000993
Iteration 58/1000 | Loss: 0.00000991
Iteration 59/1000 | Loss: 0.00000990
Iteration 60/1000 | Loss: 0.00000990
Iteration 61/1000 | Loss: 0.00000990
Iteration 62/1000 | Loss: 0.00000990
Iteration 63/1000 | Loss: 0.00000990
Iteration 64/1000 | Loss: 0.00000989
Iteration 65/1000 | Loss: 0.00000989
Iteration 66/1000 | Loss: 0.00000989
Iteration 67/1000 | Loss: 0.00000989
Iteration 68/1000 | Loss: 0.00000989
Iteration 69/1000 | Loss: 0.00000989
Iteration 70/1000 | Loss: 0.00000989
Iteration 71/1000 | Loss: 0.00000989
Iteration 72/1000 | Loss: 0.00000989
Iteration 73/1000 | Loss: 0.00000989
Iteration 74/1000 | Loss: 0.00000988
Iteration 75/1000 | Loss: 0.00000988
Iteration 76/1000 | Loss: 0.00000988
Iteration 77/1000 | Loss: 0.00000988
Iteration 78/1000 | Loss: 0.00000988
Iteration 79/1000 | Loss: 0.00000988
Iteration 80/1000 | Loss: 0.00000988
Iteration 81/1000 | Loss: 0.00000988
Iteration 82/1000 | Loss: 0.00000988
Iteration 83/1000 | Loss: 0.00000988
Iteration 84/1000 | Loss: 0.00000988
Iteration 85/1000 | Loss: 0.00000988
Iteration 86/1000 | Loss: 0.00000988
Iteration 87/1000 | Loss: 0.00000988
Iteration 88/1000 | Loss: 0.00000988
Iteration 89/1000 | Loss: 0.00000988
Iteration 90/1000 | Loss: 0.00000988
Iteration 91/1000 | Loss: 0.00000988
Iteration 92/1000 | Loss: 0.00000988
Iteration 93/1000 | Loss: 0.00000987
Iteration 94/1000 | Loss: 0.00000987
Iteration 95/1000 | Loss: 0.00000987
Iteration 96/1000 | Loss: 0.00000987
Iteration 97/1000 | Loss: 0.00000987
Iteration 98/1000 | Loss: 0.00000987
Iteration 99/1000 | Loss: 0.00000987
Iteration 100/1000 | Loss: 0.00000986
Iteration 101/1000 | Loss: 0.00000986
Iteration 102/1000 | Loss: 0.00000986
Iteration 103/1000 | Loss: 0.00000986
Iteration 104/1000 | Loss: 0.00000986
Iteration 105/1000 | Loss: 0.00000986
Iteration 106/1000 | Loss: 0.00000986
Iteration 107/1000 | Loss: 0.00000986
Iteration 108/1000 | Loss: 0.00000986
Iteration 109/1000 | Loss: 0.00000986
Iteration 110/1000 | Loss: 0.00000986
Iteration 111/1000 | Loss: 0.00000986
Iteration 112/1000 | Loss: 0.00000986
Iteration 113/1000 | Loss: 0.00000986
Iteration 114/1000 | Loss: 0.00000986
Iteration 115/1000 | Loss: 0.00000986
Iteration 116/1000 | Loss: 0.00000985
Iteration 117/1000 | Loss: 0.00000985
Iteration 118/1000 | Loss: 0.00000985
Iteration 119/1000 | Loss: 0.00000985
Iteration 120/1000 | Loss: 0.00000985
Iteration 121/1000 | Loss: 0.00000985
Iteration 122/1000 | Loss: 0.00000985
Iteration 123/1000 | Loss: 0.00000985
Iteration 124/1000 | Loss: 0.00000985
Iteration 125/1000 | Loss: 0.00000985
Iteration 126/1000 | Loss: 0.00000985
Iteration 127/1000 | Loss: 0.00000985
Iteration 128/1000 | Loss: 0.00000985
Iteration 129/1000 | Loss: 0.00000985
Iteration 130/1000 | Loss: 0.00000984
Iteration 131/1000 | Loss: 0.00000984
Iteration 132/1000 | Loss: 0.00000984
Iteration 133/1000 | Loss: 0.00000984
Iteration 134/1000 | Loss: 0.00000984
Iteration 135/1000 | Loss: 0.00000984
Iteration 136/1000 | Loss: 0.00000984
Iteration 137/1000 | Loss: 0.00000984
Iteration 138/1000 | Loss: 0.00000984
Iteration 139/1000 | Loss: 0.00000984
Iteration 140/1000 | Loss: 0.00000984
Iteration 141/1000 | Loss: 0.00000984
Iteration 142/1000 | Loss: 0.00000984
Iteration 143/1000 | Loss: 0.00000984
Iteration 144/1000 | Loss: 0.00000984
Iteration 145/1000 | Loss: 0.00000984
Iteration 146/1000 | Loss: 0.00000984
Iteration 147/1000 | Loss: 0.00000983
Iteration 148/1000 | Loss: 0.00000983
Iteration 149/1000 | Loss: 0.00000983
Iteration 150/1000 | Loss: 0.00000983
Iteration 151/1000 | Loss: 0.00000983
Iteration 152/1000 | Loss: 0.00000983
Iteration 153/1000 | Loss: 0.00000983
Iteration 154/1000 | Loss: 0.00000983
Iteration 155/1000 | Loss: 0.00000983
Iteration 156/1000 | Loss: 0.00000983
Iteration 157/1000 | Loss: 0.00000983
Iteration 158/1000 | Loss: 0.00000983
Iteration 159/1000 | Loss: 0.00000982
Iteration 160/1000 | Loss: 0.00000982
Iteration 161/1000 | Loss: 0.00000982
Iteration 162/1000 | Loss: 0.00000982
Iteration 163/1000 | Loss: 0.00000982
Iteration 164/1000 | Loss: 0.00000982
Iteration 165/1000 | Loss: 0.00000982
Iteration 166/1000 | Loss: 0.00000982
Iteration 167/1000 | Loss: 0.00000982
Iteration 168/1000 | Loss: 0.00000982
Iteration 169/1000 | Loss: 0.00000982
Iteration 170/1000 | Loss: 0.00000982
Iteration 171/1000 | Loss: 0.00000982
Iteration 172/1000 | Loss: 0.00000982
Iteration 173/1000 | Loss: 0.00000982
Iteration 174/1000 | Loss: 0.00000982
Iteration 175/1000 | Loss: 0.00000982
Iteration 176/1000 | Loss: 0.00000982
Iteration 177/1000 | Loss: 0.00000981
Iteration 178/1000 | Loss: 0.00000981
Iteration 179/1000 | Loss: 0.00000981
Iteration 180/1000 | Loss: 0.00000981
Iteration 181/1000 | Loss: 0.00000981
Iteration 182/1000 | Loss: 0.00000981
Iteration 183/1000 | Loss: 0.00000981
Iteration 184/1000 | Loss: 0.00000981
Iteration 185/1000 | Loss: 0.00000981
Iteration 186/1000 | Loss: 0.00000981
Iteration 187/1000 | Loss: 0.00000981
Iteration 188/1000 | Loss: 0.00000981
Iteration 189/1000 | Loss: 0.00000981
Iteration 190/1000 | Loss: 0.00000981
Iteration 191/1000 | Loss: 0.00000981
Iteration 192/1000 | Loss: 0.00000981
Iteration 193/1000 | Loss: 0.00000981
Iteration 194/1000 | Loss: 0.00000981
Iteration 195/1000 | Loss: 0.00000981
Iteration 196/1000 | Loss: 0.00000981
Iteration 197/1000 | Loss: 0.00000981
Iteration 198/1000 | Loss: 0.00000981
Iteration 199/1000 | Loss: 0.00000981
Iteration 200/1000 | Loss: 0.00000981
Iteration 201/1000 | Loss: 0.00000981
Iteration 202/1000 | Loss: 0.00000981
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 202. Stopping optimization.
Last 5 losses: [9.806954039959237e-06, 9.806954039959237e-06, 9.806954039959237e-06, 9.806954039959237e-06, 9.806954039959237e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.806954039959237e-06

Optimization complete. Final v2v error: 2.668637275695801 mm

Highest mean error: 3.0292797088623047 mm for frame 72

Lowest mean error: 2.4986765384674072 mm for frame 64

Saving results

Total time: 33.1566264629364
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00699733
Iteration 2/25 | Loss: 0.00079781
Iteration 3/25 | Loss: 0.00066202
Iteration 4/25 | Loss: 0.00063387
Iteration 5/25 | Loss: 0.00062250
Iteration 6/25 | Loss: 0.00062039
Iteration 7/25 | Loss: 0.00061973
Iteration 8/25 | Loss: 0.00061969
Iteration 9/25 | Loss: 0.00061969
Iteration 10/25 | Loss: 0.00061969
Iteration 11/25 | Loss: 0.00061969
Iteration 12/25 | Loss: 0.00061969
Iteration 13/25 | Loss: 0.00061969
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006196877220645547, 0.0006196877220645547, 0.0006196877220645547, 0.0006196877220645547, 0.0006196877220645547]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006196877220645547

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.05256486
Iteration 2/25 | Loss: 0.00042962
Iteration 3/25 | Loss: 0.00042962
Iteration 4/25 | Loss: 0.00042961
Iteration 5/25 | Loss: 0.00042961
Iteration 6/25 | Loss: 0.00042961
Iteration 7/25 | Loss: 0.00042961
Iteration 8/25 | Loss: 0.00042961
Iteration 9/25 | Loss: 0.00042961
Iteration 10/25 | Loss: 0.00042961
Iteration 11/25 | Loss: 0.00042961
Iteration 12/25 | Loss: 0.00042961
Iteration 13/25 | Loss: 0.00042961
Iteration 14/25 | Loss: 0.00042961
Iteration 15/25 | Loss: 0.00042961
Iteration 16/25 | Loss: 0.00042961
Iteration 17/25 | Loss: 0.00042961
Iteration 18/25 | Loss: 0.00042961
Iteration 19/25 | Loss: 0.00042961
Iteration 20/25 | Loss: 0.00042961
Iteration 21/25 | Loss: 0.00042961
Iteration 22/25 | Loss: 0.00042961
Iteration 23/25 | Loss: 0.00042961
Iteration 24/25 | Loss: 0.00042961
Iteration 25/25 | Loss: 0.00042961

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042961
Iteration 2/1000 | Loss: 0.00003600
Iteration 3/1000 | Loss: 0.00002159
Iteration 4/1000 | Loss: 0.00001906
Iteration 5/1000 | Loss: 0.00001766
Iteration 6/1000 | Loss: 0.00001717
Iteration 7/1000 | Loss: 0.00001680
Iteration 8/1000 | Loss: 0.00001663
Iteration 9/1000 | Loss: 0.00001662
Iteration 10/1000 | Loss: 0.00001652
Iteration 11/1000 | Loss: 0.00001649
Iteration 12/1000 | Loss: 0.00001646
Iteration 13/1000 | Loss: 0.00001645
Iteration 14/1000 | Loss: 0.00001638
Iteration 15/1000 | Loss: 0.00001638
Iteration 16/1000 | Loss: 0.00001637
Iteration 17/1000 | Loss: 0.00001636
Iteration 18/1000 | Loss: 0.00001636
Iteration 19/1000 | Loss: 0.00001635
Iteration 20/1000 | Loss: 0.00001633
Iteration 21/1000 | Loss: 0.00001632
Iteration 22/1000 | Loss: 0.00001631
Iteration 23/1000 | Loss: 0.00001630
Iteration 24/1000 | Loss: 0.00001630
Iteration 25/1000 | Loss: 0.00001629
Iteration 26/1000 | Loss: 0.00001629
Iteration 27/1000 | Loss: 0.00001629
Iteration 28/1000 | Loss: 0.00001629
Iteration 29/1000 | Loss: 0.00001629
Iteration 30/1000 | Loss: 0.00001629
Iteration 31/1000 | Loss: 0.00001629
Iteration 32/1000 | Loss: 0.00001629
Iteration 33/1000 | Loss: 0.00001628
Iteration 34/1000 | Loss: 0.00001628
Iteration 35/1000 | Loss: 0.00001628
Iteration 36/1000 | Loss: 0.00001628
Iteration 37/1000 | Loss: 0.00001628
Iteration 38/1000 | Loss: 0.00001628
Iteration 39/1000 | Loss: 0.00001628
Iteration 40/1000 | Loss: 0.00001627
Iteration 41/1000 | Loss: 0.00001627
Iteration 42/1000 | Loss: 0.00001627
Iteration 43/1000 | Loss: 0.00001626
Iteration 44/1000 | Loss: 0.00001626
Iteration 45/1000 | Loss: 0.00001626
Iteration 46/1000 | Loss: 0.00001626
Iteration 47/1000 | Loss: 0.00001625
Iteration 48/1000 | Loss: 0.00001625
Iteration 49/1000 | Loss: 0.00001625
Iteration 50/1000 | Loss: 0.00001624
Iteration 51/1000 | Loss: 0.00001623
Iteration 52/1000 | Loss: 0.00001623
Iteration 53/1000 | Loss: 0.00001623
Iteration 54/1000 | Loss: 0.00001623
Iteration 55/1000 | Loss: 0.00001622
Iteration 56/1000 | Loss: 0.00001622
Iteration 57/1000 | Loss: 0.00001622
Iteration 58/1000 | Loss: 0.00001622
Iteration 59/1000 | Loss: 0.00001621
Iteration 60/1000 | Loss: 0.00001621
Iteration 61/1000 | Loss: 0.00001621
Iteration 62/1000 | Loss: 0.00001621
Iteration 63/1000 | Loss: 0.00001621
Iteration 64/1000 | Loss: 0.00001621
Iteration 65/1000 | Loss: 0.00001621
Iteration 66/1000 | Loss: 0.00001621
Iteration 67/1000 | Loss: 0.00001620
Iteration 68/1000 | Loss: 0.00001620
Iteration 69/1000 | Loss: 0.00001620
Iteration 70/1000 | Loss: 0.00001620
Iteration 71/1000 | Loss: 0.00001619
Iteration 72/1000 | Loss: 0.00001618
Iteration 73/1000 | Loss: 0.00001618
Iteration 74/1000 | Loss: 0.00001618
Iteration 75/1000 | Loss: 0.00001618
Iteration 76/1000 | Loss: 0.00001618
Iteration 77/1000 | Loss: 0.00001617
Iteration 78/1000 | Loss: 0.00001617
Iteration 79/1000 | Loss: 0.00001617
Iteration 80/1000 | Loss: 0.00001617
Iteration 81/1000 | Loss: 0.00001617
Iteration 82/1000 | Loss: 0.00001617
Iteration 83/1000 | Loss: 0.00001617
Iteration 84/1000 | Loss: 0.00001616
Iteration 85/1000 | Loss: 0.00001616
Iteration 86/1000 | Loss: 0.00001615
Iteration 87/1000 | Loss: 0.00001615
Iteration 88/1000 | Loss: 0.00001615
Iteration 89/1000 | Loss: 0.00001615
Iteration 90/1000 | Loss: 0.00001615
Iteration 91/1000 | Loss: 0.00001615
Iteration 92/1000 | Loss: 0.00001614
Iteration 93/1000 | Loss: 0.00001614
Iteration 94/1000 | Loss: 0.00001614
Iteration 95/1000 | Loss: 0.00001613
Iteration 96/1000 | Loss: 0.00001613
Iteration 97/1000 | Loss: 0.00001613
Iteration 98/1000 | Loss: 0.00001613
Iteration 99/1000 | Loss: 0.00001613
Iteration 100/1000 | Loss: 0.00001613
Iteration 101/1000 | Loss: 0.00001612
Iteration 102/1000 | Loss: 0.00001612
Iteration 103/1000 | Loss: 0.00001612
Iteration 104/1000 | Loss: 0.00001612
Iteration 105/1000 | Loss: 0.00001612
Iteration 106/1000 | Loss: 0.00001612
Iteration 107/1000 | Loss: 0.00001612
Iteration 108/1000 | Loss: 0.00001612
Iteration 109/1000 | Loss: 0.00001612
Iteration 110/1000 | Loss: 0.00001612
Iteration 111/1000 | Loss: 0.00001612
Iteration 112/1000 | Loss: 0.00001612
Iteration 113/1000 | Loss: 0.00001612
Iteration 114/1000 | Loss: 0.00001612
Iteration 115/1000 | Loss: 0.00001612
Iteration 116/1000 | Loss: 0.00001612
Iteration 117/1000 | Loss: 0.00001612
Iteration 118/1000 | Loss: 0.00001612
Iteration 119/1000 | Loss: 0.00001612
Iteration 120/1000 | Loss: 0.00001612
Iteration 121/1000 | Loss: 0.00001612
Iteration 122/1000 | Loss: 0.00001612
Iteration 123/1000 | Loss: 0.00001612
Iteration 124/1000 | Loss: 0.00001612
Iteration 125/1000 | Loss: 0.00001612
Iteration 126/1000 | Loss: 0.00001612
Iteration 127/1000 | Loss: 0.00001612
Iteration 128/1000 | Loss: 0.00001612
Iteration 129/1000 | Loss: 0.00001612
Iteration 130/1000 | Loss: 0.00001612
Iteration 131/1000 | Loss: 0.00001612
Iteration 132/1000 | Loss: 0.00001612
Iteration 133/1000 | Loss: 0.00001612
Iteration 134/1000 | Loss: 0.00001612
Iteration 135/1000 | Loss: 0.00001612
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [1.6120970030897297e-05, 1.6120970030897297e-05, 1.6120970030897297e-05, 1.6120970030897297e-05, 1.6120970030897297e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6120970030897297e-05

Optimization complete. Final v2v error: 3.5031991004943848 mm

Highest mean error: 3.847095489501953 mm for frame 46

Lowest mean error: 3.0815505981445312 mm for frame 149

Saving results

Total time: 32.906310081481934
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00791789
Iteration 2/25 | Loss: 0.00082290
Iteration 3/25 | Loss: 0.00066863
Iteration 4/25 | Loss: 0.00063759
Iteration 5/25 | Loss: 0.00062302
Iteration 6/25 | Loss: 0.00062040
Iteration 7/25 | Loss: 0.00062022
Iteration 8/25 | Loss: 0.00062022
Iteration 9/25 | Loss: 0.00062022
Iteration 10/25 | Loss: 0.00062022
Iteration 11/25 | Loss: 0.00062022
Iteration 12/25 | Loss: 0.00062022
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006202151998877525, 0.0006202151998877525, 0.0006202151998877525, 0.0006202151998877525, 0.0006202151998877525]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006202151998877525

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59043384
Iteration 2/25 | Loss: 0.00040379
Iteration 3/25 | Loss: 0.00040379
Iteration 4/25 | Loss: 0.00040379
Iteration 5/25 | Loss: 0.00040379
Iteration 6/25 | Loss: 0.00040379
Iteration 7/25 | Loss: 0.00040379
Iteration 8/25 | Loss: 0.00040379
Iteration 9/25 | Loss: 0.00040379
Iteration 10/25 | Loss: 0.00040379
Iteration 11/25 | Loss: 0.00040379
Iteration 12/25 | Loss: 0.00040379
Iteration 13/25 | Loss: 0.00040379
Iteration 14/25 | Loss: 0.00040379
Iteration 15/25 | Loss: 0.00040379
Iteration 16/25 | Loss: 0.00040379
Iteration 17/25 | Loss: 0.00040379
Iteration 18/25 | Loss: 0.00040379
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00040378631092607975, 0.00040378631092607975, 0.00040378631092607975, 0.00040378631092607975, 0.00040378631092607975]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00040378631092607975

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040379
Iteration 2/1000 | Loss: 0.00002928
Iteration 3/1000 | Loss: 0.00002059
Iteration 4/1000 | Loss: 0.00001867
Iteration 5/1000 | Loss: 0.00001807
Iteration 6/1000 | Loss: 0.00001778
Iteration 7/1000 | Loss: 0.00001767
Iteration 8/1000 | Loss: 0.00001760
Iteration 9/1000 | Loss: 0.00001748
Iteration 10/1000 | Loss: 0.00001733
Iteration 11/1000 | Loss: 0.00001728
Iteration 12/1000 | Loss: 0.00001724
Iteration 13/1000 | Loss: 0.00001711
Iteration 14/1000 | Loss: 0.00001709
Iteration 15/1000 | Loss: 0.00001708
Iteration 16/1000 | Loss: 0.00001707
Iteration 17/1000 | Loss: 0.00001706
Iteration 18/1000 | Loss: 0.00001703
Iteration 19/1000 | Loss: 0.00001701
Iteration 20/1000 | Loss: 0.00001700
Iteration 21/1000 | Loss: 0.00001700
Iteration 22/1000 | Loss: 0.00001699
Iteration 23/1000 | Loss: 0.00001699
Iteration 24/1000 | Loss: 0.00001699
Iteration 25/1000 | Loss: 0.00001698
Iteration 26/1000 | Loss: 0.00001698
Iteration 27/1000 | Loss: 0.00001697
Iteration 28/1000 | Loss: 0.00001696
Iteration 29/1000 | Loss: 0.00001696
Iteration 30/1000 | Loss: 0.00001696
Iteration 31/1000 | Loss: 0.00001694
Iteration 32/1000 | Loss: 0.00001694
Iteration 33/1000 | Loss: 0.00001694
Iteration 34/1000 | Loss: 0.00001693
Iteration 35/1000 | Loss: 0.00001693
Iteration 36/1000 | Loss: 0.00001692
Iteration 37/1000 | Loss: 0.00001692
Iteration 38/1000 | Loss: 0.00001692
Iteration 39/1000 | Loss: 0.00001691
Iteration 40/1000 | Loss: 0.00001691
Iteration 41/1000 | Loss: 0.00001690
Iteration 42/1000 | Loss: 0.00001690
Iteration 43/1000 | Loss: 0.00001690
Iteration 44/1000 | Loss: 0.00001690
Iteration 45/1000 | Loss: 0.00001689
Iteration 46/1000 | Loss: 0.00001689
Iteration 47/1000 | Loss: 0.00001688
Iteration 48/1000 | Loss: 0.00001688
Iteration 49/1000 | Loss: 0.00001688
Iteration 50/1000 | Loss: 0.00001687
Iteration 51/1000 | Loss: 0.00001687
Iteration 52/1000 | Loss: 0.00001686
Iteration 53/1000 | Loss: 0.00001686
Iteration 54/1000 | Loss: 0.00001686
Iteration 55/1000 | Loss: 0.00001686
Iteration 56/1000 | Loss: 0.00001685
Iteration 57/1000 | Loss: 0.00001685
Iteration 58/1000 | Loss: 0.00001683
Iteration 59/1000 | Loss: 0.00001683
Iteration 60/1000 | Loss: 0.00001683
Iteration 61/1000 | Loss: 0.00001683
Iteration 62/1000 | Loss: 0.00001683
Iteration 63/1000 | Loss: 0.00001683
Iteration 64/1000 | Loss: 0.00001683
Iteration 65/1000 | Loss: 0.00001683
Iteration 66/1000 | Loss: 0.00001683
Iteration 67/1000 | Loss: 0.00001683
Iteration 68/1000 | Loss: 0.00001683
Iteration 69/1000 | Loss: 0.00001682
Iteration 70/1000 | Loss: 0.00001682
Iteration 71/1000 | Loss: 0.00001682
Iteration 72/1000 | Loss: 0.00001681
Iteration 73/1000 | Loss: 0.00001681
Iteration 74/1000 | Loss: 0.00001681
Iteration 75/1000 | Loss: 0.00001681
Iteration 76/1000 | Loss: 0.00001681
Iteration 77/1000 | Loss: 0.00001680
Iteration 78/1000 | Loss: 0.00001680
Iteration 79/1000 | Loss: 0.00001680
Iteration 80/1000 | Loss: 0.00001680
Iteration 81/1000 | Loss: 0.00001680
Iteration 82/1000 | Loss: 0.00001680
Iteration 83/1000 | Loss: 0.00001680
Iteration 84/1000 | Loss: 0.00001680
Iteration 85/1000 | Loss: 0.00001680
Iteration 86/1000 | Loss: 0.00001680
Iteration 87/1000 | Loss: 0.00001680
Iteration 88/1000 | Loss: 0.00001680
Iteration 89/1000 | Loss: 0.00001680
Iteration 90/1000 | Loss: 0.00001680
Iteration 91/1000 | Loss: 0.00001680
Iteration 92/1000 | Loss: 0.00001680
Iteration 93/1000 | Loss: 0.00001680
Iteration 94/1000 | Loss: 0.00001680
Iteration 95/1000 | Loss: 0.00001680
Iteration 96/1000 | Loss: 0.00001680
Iteration 97/1000 | Loss: 0.00001680
Iteration 98/1000 | Loss: 0.00001680
Iteration 99/1000 | Loss: 0.00001680
Iteration 100/1000 | Loss: 0.00001680
Iteration 101/1000 | Loss: 0.00001680
Iteration 102/1000 | Loss: 0.00001680
Iteration 103/1000 | Loss: 0.00001680
Iteration 104/1000 | Loss: 0.00001680
Iteration 105/1000 | Loss: 0.00001680
Iteration 106/1000 | Loss: 0.00001680
Iteration 107/1000 | Loss: 0.00001680
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.6800584489828907e-05, 1.6800584489828907e-05, 1.6800584489828907e-05, 1.6800584489828907e-05, 1.6800584489828907e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6800584489828907e-05

Optimization complete. Final v2v error: 3.511791467666626 mm

Highest mean error: 4.148443698883057 mm for frame 54

Lowest mean error: 2.9552574157714844 mm for frame 109

Saving results

Total time: 34.03833341598511
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00453072
Iteration 2/25 | Loss: 0.00083336
Iteration 3/25 | Loss: 0.00061795
Iteration 4/25 | Loss: 0.00059534
Iteration 5/25 | Loss: 0.00058681
Iteration 6/25 | Loss: 0.00058444
Iteration 7/25 | Loss: 0.00058416
Iteration 8/25 | Loss: 0.00058416
Iteration 9/25 | Loss: 0.00058416
Iteration 10/25 | Loss: 0.00058416
Iteration 11/25 | Loss: 0.00058416
Iteration 12/25 | Loss: 0.00058416
Iteration 13/25 | Loss: 0.00058416
Iteration 14/25 | Loss: 0.00058416
Iteration 15/25 | Loss: 0.00058416
Iteration 16/25 | Loss: 0.00058416
Iteration 17/25 | Loss: 0.00058416
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0005841609672643244, 0.0005841609672643244, 0.0005841609672643244, 0.0005841609672643244, 0.0005841609672643244]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005841609672643244

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50390220
Iteration 2/25 | Loss: 0.00042729
Iteration 3/25 | Loss: 0.00042729
Iteration 4/25 | Loss: 0.00042729
Iteration 5/25 | Loss: 0.00042729
Iteration 6/25 | Loss: 0.00042729
Iteration 7/25 | Loss: 0.00042729
Iteration 8/25 | Loss: 0.00042729
Iteration 9/25 | Loss: 0.00042729
Iteration 10/25 | Loss: 0.00042729
Iteration 11/25 | Loss: 0.00042729
Iteration 12/25 | Loss: 0.00042729
Iteration 13/25 | Loss: 0.00042729
Iteration 14/25 | Loss: 0.00042729
Iteration 15/25 | Loss: 0.00042729
Iteration 16/25 | Loss: 0.00042729
Iteration 17/25 | Loss: 0.00042729
Iteration 18/25 | Loss: 0.00042729
Iteration 19/25 | Loss: 0.00042729
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00042728669359348714, 0.00042728669359348714, 0.00042728669359348714, 0.00042728669359348714, 0.00042728669359348714]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00042728669359348714

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042729
Iteration 2/1000 | Loss: 0.00004066
Iteration 3/1000 | Loss: 0.00002152
Iteration 4/1000 | Loss: 0.00001862
Iteration 5/1000 | Loss: 0.00001738
Iteration 6/1000 | Loss: 0.00001689
Iteration 7/1000 | Loss: 0.00001645
Iteration 8/1000 | Loss: 0.00001619
Iteration 9/1000 | Loss: 0.00001603
Iteration 10/1000 | Loss: 0.00001598
Iteration 11/1000 | Loss: 0.00001596
Iteration 12/1000 | Loss: 0.00001593
Iteration 13/1000 | Loss: 0.00001592
Iteration 14/1000 | Loss: 0.00001592
Iteration 15/1000 | Loss: 0.00001590
Iteration 16/1000 | Loss: 0.00001590
Iteration 17/1000 | Loss: 0.00001589
Iteration 18/1000 | Loss: 0.00001589
Iteration 19/1000 | Loss: 0.00001587
Iteration 20/1000 | Loss: 0.00001587
Iteration 21/1000 | Loss: 0.00001587
Iteration 22/1000 | Loss: 0.00001587
Iteration 23/1000 | Loss: 0.00001585
Iteration 24/1000 | Loss: 0.00001585
Iteration 25/1000 | Loss: 0.00001584
Iteration 26/1000 | Loss: 0.00001583
Iteration 27/1000 | Loss: 0.00001583
Iteration 28/1000 | Loss: 0.00001583
Iteration 29/1000 | Loss: 0.00001583
Iteration 30/1000 | Loss: 0.00001583
Iteration 31/1000 | Loss: 0.00001583
Iteration 32/1000 | Loss: 0.00001583
Iteration 33/1000 | Loss: 0.00001583
Iteration 34/1000 | Loss: 0.00001582
Iteration 35/1000 | Loss: 0.00001582
Iteration 36/1000 | Loss: 0.00001582
Iteration 37/1000 | Loss: 0.00001582
Iteration 38/1000 | Loss: 0.00001582
Iteration 39/1000 | Loss: 0.00001581
Iteration 40/1000 | Loss: 0.00001580
Iteration 41/1000 | Loss: 0.00001580
Iteration 42/1000 | Loss: 0.00001580
Iteration 43/1000 | Loss: 0.00001579
Iteration 44/1000 | Loss: 0.00001579
Iteration 45/1000 | Loss: 0.00001579
Iteration 46/1000 | Loss: 0.00001578
Iteration 47/1000 | Loss: 0.00001578
Iteration 48/1000 | Loss: 0.00001577
Iteration 49/1000 | Loss: 0.00001577
Iteration 50/1000 | Loss: 0.00001577
Iteration 51/1000 | Loss: 0.00001577
Iteration 52/1000 | Loss: 0.00001576
Iteration 53/1000 | Loss: 0.00001576
Iteration 54/1000 | Loss: 0.00001576
Iteration 55/1000 | Loss: 0.00001576
Iteration 56/1000 | Loss: 0.00001575
Iteration 57/1000 | Loss: 0.00001575
Iteration 58/1000 | Loss: 0.00001575
Iteration 59/1000 | Loss: 0.00001575
Iteration 60/1000 | Loss: 0.00001575
Iteration 61/1000 | Loss: 0.00001574
Iteration 62/1000 | Loss: 0.00001574
Iteration 63/1000 | Loss: 0.00001574
Iteration 64/1000 | Loss: 0.00001574
Iteration 65/1000 | Loss: 0.00001574
Iteration 66/1000 | Loss: 0.00001574
Iteration 67/1000 | Loss: 0.00001574
Iteration 68/1000 | Loss: 0.00001574
Iteration 69/1000 | Loss: 0.00001574
Iteration 70/1000 | Loss: 0.00001574
Iteration 71/1000 | Loss: 0.00001573
Iteration 72/1000 | Loss: 0.00001573
Iteration 73/1000 | Loss: 0.00001573
Iteration 74/1000 | Loss: 0.00001573
Iteration 75/1000 | Loss: 0.00001573
Iteration 76/1000 | Loss: 0.00001573
Iteration 77/1000 | Loss: 0.00001572
Iteration 78/1000 | Loss: 0.00001572
Iteration 79/1000 | Loss: 0.00001572
Iteration 80/1000 | Loss: 0.00001572
Iteration 81/1000 | Loss: 0.00001572
Iteration 82/1000 | Loss: 0.00001572
Iteration 83/1000 | Loss: 0.00001572
Iteration 84/1000 | Loss: 0.00001572
Iteration 85/1000 | Loss: 0.00001572
Iteration 86/1000 | Loss: 0.00001571
Iteration 87/1000 | Loss: 0.00001571
Iteration 88/1000 | Loss: 0.00001571
Iteration 89/1000 | Loss: 0.00001571
Iteration 90/1000 | Loss: 0.00001571
Iteration 91/1000 | Loss: 0.00001571
Iteration 92/1000 | Loss: 0.00001571
Iteration 93/1000 | Loss: 0.00001571
Iteration 94/1000 | Loss: 0.00001571
Iteration 95/1000 | Loss: 0.00001571
Iteration 96/1000 | Loss: 0.00001571
Iteration 97/1000 | Loss: 0.00001571
Iteration 98/1000 | Loss: 0.00001570
Iteration 99/1000 | Loss: 0.00001570
Iteration 100/1000 | Loss: 0.00001570
Iteration 101/1000 | Loss: 0.00001570
Iteration 102/1000 | Loss: 0.00001570
Iteration 103/1000 | Loss: 0.00001570
Iteration 104/1000 | Loss: 0.00001570
Iteration 105/1000 | Loss: 0.00001570
Iteration 106/1000 | Loss: 0.00001570
Iteration 107/1000 | Loss: 0.00001570
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.5701105439802632e-05, 1.5701105439802632e-05, 1.5701105439802632e-05, 1.5701105439802632e-05, 1.5701105439802632e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5701105439802632e-05

Optimization complete. Final v2v error: 3.321385145187378 mm

Highest mean error: 3.9624698162078857 mm for frame 16

Lowest mean error: 2.7694060802459717 mm for frame 210

Saving results

Total time: 35.071632862091064
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01072038
Iteration 2/25 | Loss: 0.01072038
Iteration 3/25 | Loss: 0.01072038
Iteration 4/25 | Loss: 0.01072038
Iteration 5/25 | Loss: 0.01072038
Iteration 6/25 | Loss: 0.01072038
Iteration 7/25 | Loss: 0.01072038
Iteration 8/25 | Loss: 0.01072038
Iteration 9/25 | Loss: 0.01072038
Iteration 10/25 | Loss: 0.01072038
Iteration 11/25 | Loss: 0.01072037
Iteration 12/25 | Loss: 0.01072037
Iteration 13/25 | Loss: 0.01072037
Iteration 14/25 | Loss: 0.01072037
Iteration 15/25 | Loss: 0.01072037
Iteration 16/25 | Loss: 0.01072037
Iteration 17/25 | Loss: 0.01072037
Iteration 18/25 | Loss: 0.01072037
Iteration 19/25 | Loss: 0.01072037
Iteration 20/25 | Loss: 0.01072037
Iteration 21/25 | Loss: 0.01072037
Iteration 22/25 | Loss: 0.01072037
Iteration 23/25 | Loss: 0.01072037
Iteration 24/25 | Loss: 0.01072037
Iteration 25/25 | Loss: 0.01072037

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.76970518
Iteration 2/25 | Loss: 0.13072197
Iteration 3/25 | Loss: 0.11115394
Iteration 4/25 | Loss: 0.10504292
Iteration 5/25 | Loss: 0.10483538
Iteration 6/25 | Loss: 0.10483538
Iteration 7/25 | Loss: 0.10483538
Iteration 8/25 | Loss: 0.10483538
Iteration 9/25 | Loss: 0.10483538
Iteration 10/25 | Loss: 0.10483538
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.1048353835940361, 0.1048353835940361, 0.1048353835940361, 0.1048353835940361, 0.1048353835940361]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.1048353835940361

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.10483538
Iteration 2/1000 | Loss: 0.00342524
Iteration 3/1000 | Loss: 0.00735390
Iteration 4/1000 | Loss: 0.00274118
Iteration 5/1000 | Loss: 0.00090215
Iteration 6/1000 | Loss: 0.00055662
Iteration 7/1000 | Loss: 0.00013245
Iteration 8/1000 | Loss: 0.00010515
Iteration 9/1000 | Loss: 0.00013947
Iteration 10/1000 | Loss: 0.00023819
Iteration 11/1000 | Loss: 0.00106153
Iteration 12/1000 | Loss: 0.00012852
Iteration 13/1000 | Loss: 0.00027991
Iteration 14/1000 | Loss: 0.00015570
Iteration 15/1000 | Loss: 0.00024154
Iteration 16/1000 | Loss: 0.00004660
Iteration 17/1000 | Loss: 0.00008715
Iteration 18/1000 | Loss: 0.00015928
Iteration 19/1000 | Loss: 0.00016592
Iteration 20/1000 | Loss: 0.00011312
Iteration 21/1000 | Loss: 0.00004554
Iteration 22/1000 | Loss: 0.00047268
Iteration 23/1000 | Loss: 0.00007548
Iteration 24/1000 | Loss: 0.00004257
Iteration 25/1000 | Loss: 0.00006969
Iteration 26/1000 | Loss: 0.00010252
Iteration 27/1000 | Loss: 0.00005221
Iteration 28/1000 | Loss: 0.00004258
Iteration 29/1000 | Loss: 0.00004003
Iteration 30/1000 | Loss: 0.00004524
Iteration 31/1000 | Loss: 0.00002567
Iteration 32/1000 | Loss: 0.00003005
Iteration 33/1000 | Loss: 0.00003478
Iteration 34/1000 | Loss: 0.00012982
Iteration 35/1000 | Loss: 0.00012144
Iteration 36/1000 | Loss: 0.00004382
Iteration 37/1000 | Loss: 0.00006326
Iteration 38/1000 | Loss: 0.00021888
Iteration 39/1000 | Loss: 0.00003799
Iteration 40/1000 | Loss: 0.00002900
Iteration 41/1000 | Loss: 0.00002432
Iteration 42/1000 | Loss: 0.00002083
Iteration 43/1000 | Loss: 0.00002756
Iteration 44/1000 | Loss: 0.00004378
Iteration 45/1000 | Loss: 0.00002261
Iteration 46/1000 | Loss: 0.00002228
Iteration 47/1000 | Loss: 0.00002092
Iteration 48/1000 | Loss: 0.00002013
Iteration 49/1000 | Loss: 0.00002013
Iteration 50/1000 | Loss: 0.00002012
Iteration 51/1000 | Loss: 0.00002012
Iteration 52/1000 | Loss: 0.00002012
Iteration 53/1000 | Loss: 0.00002011
Iteration 54/1000 | Loss: 0.00002162
Iteration 55/1000 | Loss: 0.00002889
Iteration 56/1000 | Loss: 0.00003605
Iteration 57/1000 | Loss: 0.00002258
Iteration 58/1000 | Loss: 0.00002752
Iteration 59/1000 | Loss: 0.00007921
Iteration 60/1000 | Loss: 0.00203844
Iteration 61/1000 | Loss: 0.00005124
Iteration 62/1000 | Loss: 0.00002677
Iteration 63/1000 | Loss: 0.00006045
Iteration 64/1000 | Loss: 0.00012452
Iteration 65/1000 | Loss: 0.00003929
Iteration 66/1000 | Loss: 0.00003086
Iteration 67/1000 | Loss: 0.00009606
Iteration 68/1000 | Loss: 0.00003147
Iteration 69/1000 | Loss: 0.00002104
Iteration 70/1000 | Loss: 0.00002485
Iteration 71/1000 | Loss: 0.00002378
Iteration 72/1000 | Loss: 0.00001978
Iteration 73/1000 | Loss: 0.00001983
Iteration 74/1000 | Loss: 0.00002123
Iteration 75/1000 | Loss: 0.00001998
Iteration 76/1000 | Loss: 0.00002673
Iteration 77/1000 | Loss: 0.00002029
Iteration 78/1000 | Loss: 0.00001986
Iteration 79/1000 | Loss: 0.00001992
Iteration 80/1000 | Loss: 0.00001978
Iteration 81/1000 | Loss: 0.00001977
Iteration 82/1000 | Loss: 0.00001977
Iteration 83/1000 | Loss: 0.00001978
Iteration 84/1000 | Loss: 0.00001976
Iteration 85/1000 | Loss: 0.00001976
Iteration 86/1000 | Loss: 0.00001976
Iteration 87/1000 | Loss: 0.00001976
Iteration 88/1000 | Loss: 0.00001976
Iteration 89/1000 | Loss: 0.00001976
Iteration 90/1000 | Loss: 0.00001976
Iteration 91/1000 | Loss: 0.00001976
Iteration 92/1000 | Loss: 0.00001976
Iteration 93/1000 | Loss: 0.00001976
Iteration 94/1000 | Loss: 0.00001976
Iteration 95/1000 | Loss: 0.00001976
Iteration 96/1000 | Loss: 0.00001976
Iteration 97/1000 | Loss: 0.00001976
Iteration 98/1000 | Loss: 0.00001976
Iteration 99/1000 | Loss: 0.00001976
Iteration 100/1000 | Loss: 0.00001976
Iteration 101/1000 | Loss: 0.00001976
Iteration 102/1000 | Loss: 0.00001976
Iteration 103/1000 | Loss: 0.00001976
Iteration 104/1000 | Loss: 0.00001976
Iteration 105/1000 | Loss: 0.00001976
Iteration 106/1000 | Loss: 0.00001976
Iteration 107/1000 | Loss: 0.00001976
Iteration 108/1000 | Loss: 0.00001976
Iteration 109/1000 | Loss: 0.00001976
Iteration 110/1000 | Loss: 0.00001976
Iteration 111/1000 | Loss: 0.00001976
Iteration 112/1000 | Loss: 0.00001976
Iteration 113/1000 | Loss: 0.00001976
Iteration 114/1000 | Loss: 0.00001976
Iteration 115/1000 | Loss: 0.00001976
Iteration 116/1000 | Loss: 0.00001976
Iteration 117/1000 | Loss: 0.00001976
Iteration 118/1000 | Loss: 0.00001976
Iteration 119/1000 | Loss: 0.00001976
Iteration 120/1000 | Loss: 0.00001976
Iteration 121/1000 | Loss: 0.00001976
Iteration 122/1000 | Loss: 0.00001976
Iteration 123/1000 | Loss: 0.00001976
Iteration 124/1000 | Loss: 0.00001976
Iteration 125/1000 | Loss: 0.00001976
Iteration 126/1000 | Loss: 0.00001976
Iteration 127/1000 | Loss: 0.00001976
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [1.975965096789878e-05, 1.975965096789878e-05, 1.975965096789878e-05, 1.975965096789878e-05, 1.975965096789878e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.975965096789878e-05

Optimization complete. Final v2v error: 3.7456138134002686 mm

Highest mean error: 3.9440276622772217 mm for frame 34

Lowest mean error: 3.5025382041931152 mm for frame 234

Saving results

Total time: 117.12866044044495
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_27_us_1570/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_27_us_1570/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00980776
Iteration 2/25 | Loss: 0.00135146
Iteration 3/25 | Loss: 0.00102960
Iteration 4/25 | Loss: 0.00094152
Iteration 5/25 | Loss: 0.00091384
Iteration 6/25 | Loss: 0.00090615
Iteration 7/25 | Loss: 0.00090182
Iteration 8/25 | Loss: 0.00089599
Iteration 9/25 | Loss: 0.00088891
Iteration 10/25 | Loss: 0.00090323
Iteration 11/25 | Loss: 0.00088616
Iteration 12/25 | Loss: 0.00087945
Iteration 13/25 | Loss: 0.00087363
Iteration 14/25 | Loss: 0.00087217
Iteration 15/25 | Loss: 0.00087468
Iteration 16/25 | Loss: 0.00087512
Iteration 17/25 | Loss: 0.00087644
Iteration 18/25 | Loss: 0.00086850
Iteration 19/25 | Loss: 0.00086415
Iteration 20/25 | Loss: 0.00086492
Iteration 21/25 | Loss: 0.00086298
Iteration 22/25 | Loss: 0.00086500
Iteration 23/25 | Loss: 0.00086447
Iteration 24/25 | Loss: 0.00086381
Iteration 25/25 | Loss: 0.00086153

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46946120
Iteration 2/25 | Loss: 0.00141739
Iteration 3/25 | Loss: 0.00141739
Iteration 4/25 | Loss: 0.00141739
Iteration 5/25 | Loss: 0.00141739
Iteration 6/25 | Loss: 0.00141739
Iteration 7/25 | Loss: 0.00141739
Iteration 8/25 | Loss: 0.00141739
Iteration 9/25 | Loss: 0.00141738
Iteration 10/25 | Loss: 0.00141738
Iteration 11/25 | Loss: 0.00141738
Iteration 12/25 | Loss: 0.00141738
Iteration 13/25 | Loss: 0.00141738
Iteration 14/25 | Loss: 0.00141738
Iteration 15/25 | Loss: 0.00141738
Iteration 16/25 | Loss: 0.00141738
Iteration 17/25 | Loss: 0.00141738
Iteration 18/25 | Loss: 0.00141738
Iteration 19/25 | Loss: 0.00141738
Iteration 20/25 | Loss: 0.00141738
Iteration 21/25 | Loss: 0.00141738
Iteration 22/25 | Loss: 0.00141738
Iteration 23/25 | Loss: 0.00141738
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0014173847157508135, 0.0014173847157508135, 0.0014173847157508135, 0.0014173847157508135, 0.0014173847157508135]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014173847157508135

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00141738
Iteration 2/1000 | Loss: 0.00022460
Iteration 3/1000 | Loss: 0.00020896
Iteration 4/1000 | Loss: 0.00020235
Iteration 5/1000 | Loss: 0.00011136
Iteration 6/1000 | Loss: 0.00100959
Iteration 7/1000 | Loss: 0.00020185
Iteration 8/1000 | Loss: 0.00058943
Iteration 9/1000 | Loss: 0.00040913
Iteration 10/1000 | Loss: 0.00048738
Iteration 11/1000 | Loss: 0.00044935
Iteration 12/1000 | Loss: 0.00061812
Iteration 13/1000 | Loss: 0.00053252
Iteration 14/1000 | Loss: 0.00075427
Iteration 15/1000 | Loss: 0.00063154
Iteration 16/1000 | Loss: 0.00079024
Iteration 17/1000 | Loss: 0.00071076
Iteration 18/1000 | Loss: 0.00036930
Iteration 19/1000 | Loss: 0.00088301
Iteration 20/1000 | Loss: 0.00057399
Iteration 21/1000 | Loss: 0.00049997
Iteration 22/1000 | Loss: 0.00064311
Iteration 23/1000 | Loss: 0.00073878
Iteration 24/1000 | Loss: 0.00030471
Iteration 25/1000 | Loss: 0.00082707
Iteration 26/1000 | Loss: 0.00107805
Iteration 27/1000 | Loss: 0.00058688
Iteration 28/1000 | Loss: 0.00020144
Iteration 29/1000 | Loss: 0.00011679
Iteration 30/1000 | Loss: 0.00036423
Iteration 31/1000 | Loss: 0.00020257
Iteration 32/1000 | Loss: 0.00013521
Iteration 33/1000 | Loss: 0.00084050
Iteration 34/1000 | Loss: 0.00050969
Iteration 35/1000 | Loss: 0.00015441
Iteration 36/1000 | Loss: 0.00008868
Iteration 37/1000 | Loss: 0.00007627
Iteration 38/1000 | Loss: 0.00007124
Iteration 39/1000 | Loss: 0.00101718
Iteration 40/1000 | Loss: 0.00048381
Iteration 41/1000 | Loss: 0.00037047
Iteration 42/1000 | Loss: 0.00076770
Iteration 43/1000 | Loss: 0.00025024
Iteration 44/1000 | Loss: 0.00032226
Iteration 45/1000 | Loss: 0.00017964
Iteration 46/1000 | Loss: 0.00023220
Iteration 47/1000 | Loss: 0.00025563
Iteration 48/1000 | Loss: 0.00039298
Iteration 49/1000 | Loss: 0.00060303
Iteration 50/1000 | Loss: 0.00020437
Iteration 51/1000 | Loss: 0.00071946
Iteration 52/1000 | Loss: 0.00053837
Iteration 53/1000 | Loss: 0.00006899
Iteration 54/1000 | Loss: 0.00101099
Iteration 55/1000 | Loss: 0.00049647
Iteration 56/1000 | Loss: 0.00008345
Iteration 57/1000 | Loss: 0.00053682
Iteration 58/1000 | Loss: 0.00042913
Iteration 59/1000 | Loss: 0.00059133
Iteration 60/1000 | Loss: 0.00338993
Iteration 61/1000 | Loss: 0.00017407
Iteration 62/1000 | Loss: 0.00009728
Iteration 63/1000 | Loss: 0.00020969
Iteration 64/1000 | Loss: 0.00034490
Iteration 65/1000 | Loss: 0.00046408
Iteration 66/1000 | Loss: 0.00010761
Iteration 67/1000 | Loss: 0.00022954
Iteration 68/1000 | Loss: 0.00013373
Iteration 69/1000 | Loss: 0.00013117
Iteration 70/1000 | Loss: 0.00017244
Iteration 71/1000 | Loss: 0.00045327
Iteration 72/1000 | Loss: 0.00011873
Iteration 73/1000 | Loss: 0.00028487
Iteration 74/1000 | Loss: 0.00013244
Iteration 75/1000 | Loss: 0.00011885
Iteration 76/1000 | Loss: 0.00021334
Iteration 77/1000 | Loss: 0.00022381
Iteration 78/1000 | Loss: 0.00006293
Iteration 79/1000 | Loss: 0.00009407
Iteration 80/1000 | Loss: 0.00005626
Iteration 81/1000 | Loss: 0.00014286
Iteration 82/1000 | Loss: 0.00028880
Iteration 83/1000 | Loss: 0.00018120
Iteration 84/1000 | Loss: 0.00013858
Iteration 85/1000 | Loss: 0.00020440
Iteration 86/1000 | Loss: 0.00023143
Iteration 87/1000 | Loss: 0.00024535
Iteration 88/1000 | Loss: 0.00033583
Iteration 89/1000 | Loss: 0.00020350
Iteration 90/1000 | Loss: 0.00015944
Iteration 91/1000 | Loss: 0.00011862
Iteration 92/1000 | Loss: 0.00026211
Iteration 93/1000 | Loss: 0.00008698
Iteration 94/1000 | Loss: 0.00027441
Iteration 95/1000 | Loss: 0.00009492
Iteration 96/1000 | Loss: 0.00008533
Iteration 97/1000 | Loss: 0.00013082
Iteration 98/1000 | Loss: 0.00019788
Iteration 99/1000 | Loss: 0.00034324
Iteration 100/1000 | Loss: 0.00012892
Iteration 101/1000 | Loss: 0.00043698
Iteration 102/1000 | Loss: 0.00004698
Iteration 103/1000 | Loss: 0.00004095
Iteration 104/1000 | Loss: 0.00003914
Iteration 105/1000 | Loss: 0.00003643
Iteration 106/1000 | Loss: 0.00003434
Iteration 107/1000 | Loss: 0.00003342
Iteration 108/1000 | Loss: 0.00003245
Iteration 109/1000 | Loss: 0.00003161
Iteration 110/1000 | Loss: 0.00003112
Iteration 111/1000 | Loss: 0.00003081
Iteration 112/1000 | Loss: 0.00003060
Iteration 113/1000 | Loss: 0.00003035
Iteration 114/1000 | Loss: 0.00003029
Iteration 115/1000 | Loss: 0.00003028
Iteration 116/1000 | Loss: 0.00003028
Iteration 117/1000 | Loss: 0.00003022
Iteration 118/1000 | Loss: 0.00003020
Iteration 119/1000 | Loss: 0.00003018
Iteration 120/1000 | Loss: 0.00003006
Iteration 121/1000 | Loss: 0.00003006
Iteration 122/1000 | Loss: 0.00003001
Iteration 123/1000 | Loss: 0.00003000
Iteration 124/1000 | Loss: 0.00003000
Iteration 125/1000 | Loss: 0.00002999
Iteration 126/1000 | Loss: 0.00002997
Iteration 127/1000 | Loss: 0.00002992
Iteration 128/1000 | Loss: 0.00002992
Iteration 129/1000 | Loss: 0.00002991
Iteration 130/1000 | Loss: 0.00002991
Iteration 131/1000 | Loss: 0.00002990
Iteration 132/1000 | Loss: 0.00002990
Iteration 133/1000 | Loss: 0.00002989
Iteration 134/1000 | Loss: 0.00002989
Iteration 135/1000 | Loss: 0.00002989
Iteration 136/1000 | Loss: 0.00002989
Iteration 137/1000 | Loss: 0.00002988
Iteration 138/1000 | Loss: 0.00002988
Iteration 139/1000 | Loss: 0.00002988
Iteration 140/1000 | Loss: 0.00002988
Iteration 141/1000 | Loss: 0.00002987
Iteration 142/1000 | Loss: 0.00002986
Iteration 143/1000 | Loss: 0.00002986
Iteration 144/1000 | Loss: 0.00002986
Iteration 145/1000 | Loss: 0.00002986
Iteration 146/1000 | Loss: 0.00002985
Iteration 147/1000 | Loss: 0.00002985
Iteration 148/1000 | Loss: 0.00002985
Iteration 149/1000 | Loss: 0.00002985
Iteration 150/1000 | Loss: 0.00002984
Iteration 151/1000 | Loss: 0.00002984
Iteration 152/1000 | Loss: 0.00002984
Iteration 153/1000 | Loss: 0.00002984
Iteration 154/1000 | Loss: 0.00002984
Iteration 155/1000 | Loss: 0.00002984
Iteration 156/1000 | Loss: 0.00002984
Iteration 157/1000 | Loss: 0.00002983
Iteration 158/1000 | Loss: 0.00002983
Iteration 159/1000 | Loss: 0.00002983
Iteration 160/1000 | Loss: 0.00002983
Iteration 161/1000 | Loss: 0.00002983
Iteration 162/1000 | Loss: 0.00002983
Iteration 163/1000 | Loss: 0.00002983
Iteration 164/1000 | Loss: 0.00002983
Iteration 165/1000 | Loss: 0.00002983
Iteration 166/1000 | Loss: 0.00002983
Iteration 167/1000 | Loss: 0.00002983
Iteration 168/1000 | Loss: 0.00002983
Iteration 169/1000 | Loss: 0.00002983
Iteration 170/1000 | Loss: 0.00002982
Iteration 171/1000 | Loss: 0.00002982
Iteration 172/1000 | Loss: 0.00002982
Iteration 173/1000 | Loss: 0.00002982
Iteration 174/1000 | Loss: 0.00002982
Iteration 175/1000 | Loss: 0.00002982
Iteration 176/1000 | Loss: 0.00002982
Iteration 177/1000 | Loss: 0.00002982
Iteration 178/1000 | Loss: 0.00002982
Iteration 179/1000 | Loss: 0.00002982
Iteration 180/1000 | Loss: 0.00002982
Iteration 181/1000 | Loss: 0.00002982
Iteration 182/1000 | Loss: 0.00002982
Iteration 183/1000 | Loss: 0.00002981
Iteration 184/1000 | Loss: 0.00002981
Iteration 185/1000 | Loss: 0.00002981
Iteration 186/1000 | Loss: 0.00002981
Iteration 187/1000 | Loss: 0.00002981
Iteration 188/1000 | Loss: 0.00002981
Iteration 189/1000 | Loss: 0.00002981
Iteration 190/1000 | Loss: 0.00002981
Iteration 191/1000 | Loss: 0.00002981
Iteration 192/1000 | Loss: 0.00002981
Iteration 193/1000 | Loss: 0.00002981
Iteration 194/1000 | Loss: 0.00002981
Iteration 195/1000 | Loss: 0.00002981
Iteration 196/1000 | Loss: 0.00002980
Iteration 197/1000 | Loss: 0.00002980
Iteration 198/1000 | Loss: 0.00002980
Iteration 199/1000 | Loss: 0.00002980
Iteration 200/1000 | Loss: 0.00002980
Iteration 201/1000 | Loss: 0.00002980
Iteration 202/1000 | Loss: 0.00002979
Iteration 203/1000 | Loss: 0.00002979
Iteration 204/1000 | Loss: 0.00002979
Iteration 205/1000 | Loss: 0.00002979
Iteration 206/1000 | Loss: 0.00002979
Iteration 207/1000 | Loss: 0.00002978
Iteration 208/1000 | Loss: 0.00002978
Iteration 209/1000 | Loss: 0.00002978
Iteration 210/1000 | Loss: 0.00002978
Iteration 211/1000 | Loss: 0.00002978
Iteration 212/1000 | Loss: 0.00002978
Iteration 213/1000 | Loss: 0.00002978
Iteration 214/1000 | Loss: 0.00002978
Iteration 215/1000 | Loss: 0.00002978
Iteration 216/1000 | Loss: 0.00002978
Iteration 217/1000 | Loss: 0.00002977
Iteration 218/1000 | Loss: 0.00002977
Iteration 219/1000 | Loss: 0.00002977
Iteration 220/1000 | Loss: 0.00002977
Iteration 221/1000 | Loss: 0.00002977
Iteration 222/1000 | Loss: 0.00002977
Iteration 223/1000 | Loss: 0.00002977
Iteration 224/1000 | Loss: 0.00002977
Iteration 225/1000 | Loss: 0.00002977
Iteration 226/1000 | Loss: 0.00002977
Iteration 227/1000 | Loss: 0.00002977
Iteration 228/1000 | Loss: 0.00002977
Iteration 229/1000 | Loss: 0.00002977
Iteration 230/1000 | Loss: 0.00002977
Iteration 231/1000 | Loss: 0.00002977
Iteration 232/1000 | Loss: 0.00002977
Iteration 233/1000 | Loss: 0.00002977
Iteration 234/1000 | Loss: 0.00002977
Iteration 235/1000 | Loss: 0.00002977
Iteration 236/1000 | Loss: 0.00002977
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 236. Stopping optimization.
Last 5 losses: [2.9765697036054917e-05, 2.9765697036054917e-05, 2.9765697036054917e-05, 2.9765697036054917e-05, 2.9765697036054917e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9765697036054917e-05

Optimization complete. Final v2v error: 4.491494655609131 mm

Highest mean error: 8.500020027160645 mm for frame 122

Lowest mean error: 3.5168087482452393 mm for frame 217

Saving results

Total time: 248.37682032585144

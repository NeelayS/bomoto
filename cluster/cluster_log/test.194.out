Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=194, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 10864-10919
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01058899
Iteration 2/25 | Loss: 0.00207737
Iteration 3/25 | Loss: 0.00162529
Iteration 4/25 | Loss: 0.00152171
Iteration 5/25 | Loss: 0.00160306
Iteration 6/25 | Loss: 0.00162218
Iteration 7/25 | Loss: 0.00144690
Iteration 8/25 | Loss: 0.00136559
Iteration 9/25 | Loss: 0.00127058
Iteration 10/25 | Loss: 0.00124261
Iteration 11/25 | Loss: 0.00120939
Iteration 12/25 | Loss: 0.00115376
Iteration 13/25 | Loss: 0.00112416
Iteration 14/25 | Loss: 0.00111810
Iteration 15/25 | Loss: 0.00108752
Iteration 16/25 | Loss: 0.00104930
Iteration 17/25 | Loss: 0.00104158
Iteration 18/25 | Loss: 0.00104780
Iteration 19/25 | Loss: 0.00103680
Iteration 20/25 | Loss: 0.00104312
Iteration 21/25 | Loss: 0.00104390
Iteration 22/25 | Loss: 0.00104036
Iteration 23/25 | Loss: 0.00103977
Iteration 24/25 | Loss: 0.00103826
Iteration 25/25 | Loss: 0.00103386

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80703652
Iteration 2/25 | Loss: 0.00259643
Iteration 3/25 | Loss: 0.00189511
Iteration 4/25 | Loss: 0.00189511
Iteration 5/25 | Loss: 0.00189511
Iteration 6/25 | Loss: 0.00189511
Iteration 7/25 | Loss: 0.00189511
Iteration 8/25 | Loss: 0.00189511
Iteration 9/25 | Loss: 0.00189511
Iteration 10/25 | Loss: 0.00189511
Iteration 11/25 | Loss: 0.00189511
Iteration 12/25 | Loss: 0.00189511
Iteration 13/25 | Loss: 0.00189511
Iteration 14/25 | Loss: 0.00189511
Iteration 15/25 | Loss: 0.00189511
Iteration 16/25 | Loss: 0.00189511
Iteration 17/25 | Loss: 0.00189511
Iteration 18/25 | Loss: 0.00189511
Iteration 19/25 | Loss: 0.00189511
Iteration 20/25 | Loss: 0.00189511
Iteration 21/25 | Loss: 0.00189511
Iteration 22/25 | Loss: 0.00189511
Iteration 23/25 | Loss: 0.00189511
Iteration 24/25 | Loss: 0.00189511
Iteration 25/25 | Loss: 0.00189511

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00189511
Iteration 2/1000 | Loss: 0.00167458
Iteration 3/1000 | Loss: 0.00150176
Iteration 4/1000 | Loss: 0.00211395
Iteration 5/1000 | Loss: 0.00035866
Iteration 6/1000 | Loss: 0.00046560
Iteration 7/1000 | Loss: 0.00190410
Iteration 8/1000 | Loss: 0.00078795
Iteration 9/1000 | Loss: 0.00095392
Iteration 10/1000 | Loss: 0.00261077
Iteration 11/1000 | Loss: 0.00185453
Iteration 12/1000 | Loss: 0.00164508
Iteration 13/1000 | Loss: 0.00187864
Iteration 14/1000 | Loss: 0.00244121
Iteration 15/1000 | Loss: 0.00088618
Iteration 16/1000 | Loss: 0.00165010
Iteration 17/1000 | Loss: 0.00259645
Iteration 18/1000 | Loss: 0.00125866
Iteration 19/1000 | Loss: 0.00052499
Iteration 20/1000 | Loss: 0.00010508
Iteration 21/1000 | Loss: 0.00045344
Iteration 22/1000 | Loss: 0.00053690
Iteration 23/1000 | Loss: 0.00029564
Iteration 24/1000 | Loss: 0.00020370
Iteration 25/1000 | Loss: 0.00214194
Iteration 26/1000 | Loss: 0.00143390
Iteration 27/1000 | Loss: 0.00143843
Iteration 28/1000 | Loss: 0.00172671
Iteration 29/1000 | Loss: 0.00041184
Iteration 30/1000 | Loss: 0.00046527
Iteration 31/1000 | Loss: 0.00026046
Iteration 32/1000 | Loss: 0.00076428
Iteration 33/1000 | Loss: 0.00031859
Iteration 34/1000 | Loss: 0.00028410
Iteration 35/1000 | Loss: 0.00020800
Iteration 36/1000 | Loss: 0.00036659
Iteration 37/1000 | Loss: 0.00102101
Iteration 38/1000 | Loss: 0.00047202
Iteration 39/1000 | Loss: 0.00032563
Iteration 40/1000 | Loss: 0.00197222
Iteration 41/1000 | Loss: 0.00087147
Iteration 42/1000 | Loss: 0.00120470
Iteration 43/1000 | Loss: 0.00089965
Iteration 44/1000 | Loss: 0.00131393
Iteration 45/1000 | Loss: 0.00029246
Iteration 46/1000 | Loss: 0.00062683
Iteration 47/1000 | Loss: 0.00115187
Iteration 48/1000 | Loss: 0.00153403
Iteration 49/1000 | Loss: 0.00055892
Iteration 50/1000 | Loss: 0.00039170
Iteration 51/1000 | Loss: 0.00110804
Iteration 52/1000 | Loss: 0.00162961
Iteration 53/1000 | Loss: 0.00130560
Iteration 54/1000 | Loss: 0.00196494
Iteration 55/1000 | Loss: 0.00049675
Iteration 56/1000 | Loss: 0.00090405
Iteration 57/1000 | Loss: 0.00100310
Iteration 58/1000 | Loss: 0.00035277
Iteration 59/1000 | Loss: 0.00075275
Iteration 60/1000 | Loss: 0.00057169
Iteration 61/1000 | Loss: 0.00060598
Iteration 62/1000 | Loss: 0.00048153
Iteration 63/1000 | Loss: 0.00026709
Iteration 64/1000 | Loss: 0.00037212
Iteration 65/1000 | Loss: 0.00031783
Iteration 66/1000 | Loss: 0.00162559
Iteration 67/1000 | Loss: 0.00131656
Iteration 68/1000 | Loss: 0.00033866
Iteration 69/1000 | Loss: 0.00017715
Iteration 70/1000 | Loss: 0.00009992
Iteration 71/1000 | Loss: 0.00023286
Iteration 72/1000 | Loss: 0.00034187
Iteration 73/1000 | Loss: 0.00029829
Iteration 74/1000 | Loss: 0.00028242
Iteration 75/1000 | Loss: 0.00034564
Iteration 76/1000 | Loss: 0.00027160
Iteration 77/1000 | Loss: 0.00050857
Iteration 78/1000 | Loss: 0.00040870
Iteration 79/1000 | Loss: 0.00029940
Iteration 80/1000 | Loss: 0.00025825
Iteration 81/1000 | Loss: 0.00020366
Iteration 82/1000 | Loss: 0.00009721
Iteration 83/1000 | Loss: 0.00039125
Iteration 84/1000 | Loss: 0.00026021
Iteration 85/1000 | Loss: 0.00072669
Iteration 86/1000 | Loss: 0.00032789
Iteration 87/1000 | Loss: 0.00031657
Iteration 88/1000 | Loss: 0.00034511
Iteration 89/1000 | Loss: 0.00025142
Iteration 90/1000 | Loss: 0.00018602
Iteration 91/1000 | Loss: 0.00021920
Iteration 92/1000 | Loss: 0.00024122
Iteration 93/1000 | Loss: 0.00013496
Iteration 94/1000 | Loss: 0.00021676
Iteration 95/1000 | Loss: 0.00028197
Iteration 96/1000 | Loss: 0.00017363
Iteration 97/1000 | Loss: 0.00026403
Iteration 98/1000 | Loss: 0.00026635
Iteration 99/1000 | Loss: 0.00030066
Iteration 100/1000 | Loss: 0.00041047
Iteration 101/1000 | Loss: 0.00035995
Iteration 102/1000 | Loss: 0.00025682
Iteration 103/1000 | Loss: 0.00027363
Iteration 104/1000 | Loss: 0.00010285
Iteration 105/1000 | Loss: 0.00116688
Iteration 106/1000 | Loss: 0.00072977
Iteration 107/1000 | Loss: 0.00007369
Iteration 108/1000 | Loss: 0.00097233
Iteration 109/1000 | Loss: 0.00053475
Iteration 110/1000 | Loss: 0.00004541
Iteration 111/1000 | Loss: 0.00017067
Iteration 112/1000 | Loss: 0.00015958
Iteration 113/1000 | Loss: 0.00013499
Iteration 114/1000 | Loss: 0.00014473
Iteration 115/1000 | Loss: 0.00011513
Iteration 116/1000 | Loss: 0.00078663
Iteration 117/1000 | Loss: 0.00015830
Iteration 118/1000 | Loss: 0.00016566
Iteration 119/1000 | Loss: 0.00027313
Iteration 120/1000 | Loss: 0.00021127
Iteration 121/1000 | Loss: 0.00054559
Iteration 122/1000 | Loss: 0.00006729
Iteration 123/1000 | Loss: 0.00040206
Iteration 124/1000 | Loss: 0.00013333
Iteration 125/1000 | Loss: 0.00014923
Iteration 126/1000 | Loss: 0.00021164
Iteration 127/1000 | Loss: 0.00016180
Iteration 128/1000 | Loss: 0.00019221
Iteration 129/1000 | Loss: 0.00018128
Iteration 130/1000 | Loss: 0.00011680
Iteration 131/1000 | Loss: 0.00006716
Iteration 132/1000 | Loss: 0.00023362
Iteration 133/1000 | Loss: 0.00010753
Iteration 134/1000 | Loss: 0.00012782
Iteration 135/1000 | Loss: 0.00037225
Iteration 136/1000 | Loss: 0.00013027
Iteration 137/1000 | Loss: 0.00016503
Iteration 138/1000 | Loss: 0.00015650
Iteration 139/1000 | Loss: 0.00014123
Iteration 140/1000 | Loss: 0.00012896
Iteration 141/1000 | Loss: 0.00012757
Iteration 142/1000 | Loss: 0.00011918
Iteration 143/1000 | Loss: 0.00012047
Iteration 144/1000 | Loss: 0.00013629
Iteration 145/1000 | Loss: 0.00012284
Iteration 146/1000 | Loss: 0.00023105
Iteration 147/1000 | Loss: 0.00018971
Iteration 148/1000 | Loss: 0.00024499
Iteration 149/1000 | Loss: 0.00017904
Iteration 150/1000 | Loss: 0.00013468
Iteration 151/1000 | Loss: 0.00011843
Iteration 152/1000 | Loss: 0.00147080
Iteration 153/1000 | Loss: 0.00012501
Iteration 154/1000 | Loss: 0.00021756
Iteration 155/1000 | Loss: 0.00020359
Iteration 156/1000 | Loss: 0.00033127
Iteration 157/1000 | Loss: 0.00018412
Iteration 158/1000 | Loss: 0.00003055
Iteration 159/1000 | Loss: 0.00002236
Iteration 160/1000 | Loss: 0.00011572
Iteration 161/1000 | Loss: 0.00004989
Iteration 162/1000 | Loss: 0.00004719
Iteration 163/1000 | Loss: 0.00008723
Iteration 164/1000 | Loss: 0.00001841
Iteration 165/1000 | Loss: 0.00015069
Iteration 166/1000 | Loss: 0.00001604
Iteration 167/1000 | Loss: 0.00001399
Iteration 168/1000 | Loss: 0.00001288
Iteration 169/1000 | Loss: 0.00001225
Iteration 170/1000 | Loss: 0.00001200
Iteration 171/1000 | Loss: 0.00001168
Iteration 172/1000 | Loss: 0.00001143
Iteration 173/1000 | Loss: 0.00001133
Iteration 174/1000 | Loss: 0.00001129
Iteration 175/1000 | Loss: 0.00001128
Iteration 176/1000 | Loss: 0.00001120
Iteration 177/1000 | Loss: 0.00001120
Iteration 178/1000 | Loss: 0.00001119
Iteration 179/1000 | Loss: 0.00001118
Iteration 180/1000 | Loss: 0.00001117
Iteration 181/1000 | Loss: 0.00001116
Iteration 182/1000 | Loss: 0.00001113
Iteration 183/1000 | Loss: 0.00001111
Iteration 184/1000 | Loss: 0.00001110
Iteration 185/1000 | Loss: 0.00001108
Iteration 186/1000 | Loss: 0.00001107
Iteration 187/1000 | Loss: 0.00001107
Iteration 188/1000 | Loss: 0.00001104
Iteration 189/1000 | Loss: 0.00001104
Iteration 190/1000 | Loss: 0.00001103
Iteration 191/1000 | Loss: 0.00001103
Iteration 192/1000 | Loss: 0.00001103
Iteration 193/1000 | Loss: 0.00001103
Iteration 194/1000 | Loss: 0.00001102
Iteration 195/1000 | Loss: 0.00001102
Iteration 196/1000 | Loss: 0.00001101
Iteration 197/1000 | Loss: 0.00001101
Iteration 198/1000 | Loss: 0.00001100
Iteration 199/1000 | Loss: 0.00001100
Iteration 200/1000 | Loss: 0.00001100
Iteration 201/1000 | Loss: 0.00001100
Iteration 202/1000 | Loss: 0.00001100
Iteration 203/1000 | Loss: 0.00001099
Iteration 204/1000 | Loss: 0.00001099
Iteration 205/1000 | Loss: 0.00001099
Iteration 206/1000 | Loss: 0.00001099
Iteration 207/1000 | Loss: 0.00001099
Iteration 208/1000 | Loss: 0.00001099
Iteration 209/1000 | Loss: 0.00001099
Iteration 210/1000 | Loss: 0.00001099
Iteration 211/1000 | Loss: 0.00001099
Iteration 212/1000 | Loss: 0.00001099
Iteration 213/1000 | Loss: 0.00001099
Iteration 214/1000 | Loss: 0.00001099
Iteration 215/1000 | Loss: 0.00001098
Iteration 216/1000 | Loss: 0.00001098
Iteration 217/1000 | Loss: 0.00001098
Iteration 218/1000 | Loss: 0.00001098
Iteration 219/1000 | Loss: 0.00001098
Iteration 220/1000 | Loss: 0.00001098
Iteration 221/1000 | Loss: 0.00001098
Iteration 222/1000 | Loss: 0.00001098
Iteration 223/1000 | Loss: 0.00001098
Iteration 224/1000 | Loss: 0.00001097
Iteration 225/1000 | Loss: 0.00001096
Iteration 226/1000 | Loss: 0.00001095
Iteration 227/1000 | Loss: 0.00001095
Iteration 228/1000 | Loss: 0.00001095
Iteration 229/1000 | Loss: 0.00001095
Iteration 230/1000 | Loss: 0.00001095
Iteration 231/1000 | Loss: 0.00001095
Iteration 232/1000 | Loss: 0.00001095
Iteration 233/1000 | Loss: 0.00001095
Iteration 234/1000 | Loss: 0.00001095
Iteration 235/1000 | Loss: 0.00001095
Iteration 236/1000 | Loss: 0.00001095
Iteration 237/1000 | Loss: 0.00001094
Iteration 238/1000 | Loss: 0.00001094
Iteration 239/1000 | Loss: 0.00001094
Iteration 240/1000 | Loss: 0.00001094
Iteration 241/1000 | Loss: 0.00001094
Iteration 242/1000 | Loss: 0.00001093
Iteration 243/1000 | Loss: 0.00001092
Iteration 244/1000 | Loss: 0.00001092
Iteration 245/1000 | Loss: 0.00001092
Iteration 246/1000 | Loss: 0.00001091
Iteration 247/1000 | Loss: 0.00001091
Iteration 248/1000 | Loss: 0.00001091
Iteration 249/1000 | Loss: 0.00001091
Iteration 250/1000 | Loss: 0.00001091
Iteration 251/1000 | Loss: 0.00001091
Iteration 252/1000 | Loss: 0.00001091
Iteration 253/1000 | Loss: 0.00001090
Iteration 254/1000 | Loss: 0.00001090
Iteration 255/1000 | Loss: 0.00001090
Iteration 256/1000 | Loss: 0.00001089
Iteration 257/1000 | Loss: 0.00001089
Iteration 258/1000 | Loss: 0.00001089
Iteration 259/1000 | Loss: 0.00001089
Iteration 260/1000 | Loss: 0.00001088
Iteration 261/1000 | Loss: 0.00001088
Iteration 262/1000 | Loss: 0.00001088
Iteration 263/1000 | Loss: 0.00001088
Iteration 264/1000 | Loss: 0.00001088
Iteration 265/1000 | Loss: 0.00001088
Iteration 266/1000 | Loss: 0.00001087
Iteration 267/1000 | Loss: 0.00001087
Iteration 268/1000 | Loss: 0.00001087
Iteration 269/1000 | Loss: 0.00001087
Iteration 270/1000 | Loss: 0.00001087
Iteration 271/1000 | Loss: 0.00001087
Iteration 272/1000 | Loss: 0.00001087
Iteration 273/1000 | Loss: 0.00001087
Iteration 274/1000 | Loss: 0.00001087
Iteration 275/1000 | Loss: 0.00001087
Iteration 276/1000 | Loss: 0.00001087
Iteration 277/1000 | Loss: 0.00001087
Iteration 278/1000 | Loss: 0.00001086
Iteration 279/1000 | Loss: 0.00001086
Iteration 280/1000 | Loss: 0.00001086
Iteration 281/1000 | Loss: 0.00001086
Iteration 282/1000 | Loss: 0.00001086
Iteration 283/1000 | Loss: 0.00001086
Iteration 284/1000 | Loss: 0.00001086
Iteration 285/1000 | Loss: 0.00001086
Iteration 286/1000 | Loss: 0.00001086
Iteration 287/1000 | Loss: 0.00001086
Iteration 288/1000 | Loss: 0.00001086
Iteration 289/1000 | Loss: 0.00001086
Iteration 290/1000 | Loss: 0.00001085
Iteration 291/1000 | Loss: 0.00001085
Iteration 292/1000 | Loss: 0.00001085
Iteration 293/1000 | Loss: 0.00001085
Iteration 294/1000 | Loss: 0.00001085
Iteration 295/1000 | Loss: 0.00001085
Iteration 296/1000 | Loss: 0.00001085
Iteration 297/1000 | Loss: 0.00001085
Iteration 298/1000 | Loss: 0.00001085
Iteration 299/1000 | Loss: 0.00001085
Iteration 300/1000 | Loss: 0.00001085
Iteration 301/1000 | Loss: 0.00001085
Iteration 302/1000 | Loss: 0.00001085
Iteration 303/1000 | Loss: 0.00001084
Iteration 304/1000 | Loss: 0.00001084
Iteration 305/1000 | Loss: 0.00001084
Iteration 306/1000 | Loss: 0.00001084
Iteration 307/1000 | Loss: 0.00001084
Iteration 308/1000 | Loss: 0.00001084
Iteration 309/1000 | Loss: 0.00001084
Iteration 310/1000 | Loss: 0.00001084
Iteration 311/1000 | Loss: 0.00001084
Iteration 312/1000 | Loss: 0.00001084
Iteration 313/1000 | Loss: 0.00001083
Iteration 314/1000 | Loss: 0.00001083
Iteration 315/1000 | Loss: 0.00001083
Iteration 316/1000 | Loss: 0.00001083
Iteration 317/1000 | Loss: 0.00001083
Iteration 318/1000 | Loss: 0.00001083
Iteration 319/1000 | Loss: 0.00001083
Iteration 320/1000 | Loss: 0.00001083
Iteration 321/1000 | Loss: 0.00001083
Iteration 322/1000 | Loss: 0.00001083
Iteration 323/1000 | Loss: 0.00001083
Iteration 324/1000 | Loss: 0.00001083
Iteration 325/1000 | Loss: 0.00001083
Iteration 326/1000 | Loss: 0.00001083
Iteration 327/1000 | Loss: 0.00001083
Iteration 328/1000 | Loss: 0.00001082
Iteration 329/1000 | Loss: 0.00001082
Iteration 330/1000 | Loss: 0.00001082
Iteration 331/1000 | Loss: 0.00001082
Iteration 332/1000 | Loss: 0.00001082
Iteration 333/1000 | Loss: 0.00001082
Iteration 334/1000 | Loss: 0.00001082
Iteration 335/1000 | Loss: 0.00001082
Iteration 336/1000 | Loss: 0.00001082
Iteration 337/1000 | Loss: 0.00001082
Iteration 338/1000 | Loss: 0.00001082
Iteration 339/1000 | Loss: 0.00001082
Iteration 340/1000 | Loss: 0.00001082
Iteration 341/1000 | Loss: 0.00001082
Iteration 342/1000 | Loss: 0.00001082
Iteration 343/1000 | Loss: 0.00001081
Iteration 344/1000 | Loss: 0.00001081
Iteration 345/1000 | Loss: 0.00001081
Iteration 346/1000 | Loss: 0.00001081
Iteration 347/1000 | Loss: 0.00001081
Iteration 348/1000 | Loss: 0.00001081
Iteration 349/1000 | Loss: 0.00001081
Iteration 350/1000 | Loss: 0.00001081
Iteration 351/1000 | Loss: 0.00001081
Iteration 352/1000 | Loss: 0.00001081
Iteration 353/1000 | Loss: 0.00001081
Iteration 354/1000 | Loss: 0.00001081
Iteration 355/1000 | Loss: 0.00001080
Iteration 356/1000 | Loss: 0.00001080
Iteration 357/1000 | Loss: 0.00001080
Iteration 358/1000 | Loss: 0.00001080
Iteration 359/1000 | Loss: 0.00001080
Iteration 360/1000 | Loss: 0.00001080
Iteration 361/1000 | Loss: 0.00001080
Iteration 362/1000 | Loss: 0.00001080
Iteration 363/1000 | Loss: 0.00001080
Iteration 364/1000 | Loss: 0.00001080
Iteration 365/1000 | Loss: 0.00001080
Iteration 366/1000 | Loss: 0.00001080
Iteration 367/1000 | Loss: 0.00001079
Iteration 368/1000 | Loss: 0.00001079
Iteration 369/1000 | Loss: 0.00001079
Iteration 370/1000 | Loss: 0.00001079
Iteration 371/1000 | Loss: 0.00001079
Iteration 372/1000 | Loss: 0.00001079
Iteration 373/1000 | Loss: 0.00001078
Iteration 374/1000 | Loss: 0.00001078
Iteration 375/1000 | Loss: 0.00001078
Iteration 376/1000 | Loss: 0.00001078
Iteration 377/1000 | Loss: 0.00001077
Iteration 378/1000 | Loss: 0.00001077
Iteration 379/1000 | Loss: 0.00001077
Iteration 380/1000 | Loss: 0.00001077
Iteration 381/1000 | Loss: 0.00001077
Iteration 382/1000 | Loss: 0.00001076
Iteration 383/1000 | Loss: 0.00001076
Iteration 384/1000 | Loss: 0.00001076
Iteration 385/1000 | Loss: 0.00001076
Iteration 386/1000 | Loss: 0.00001075
Iteration 387/1000 | Loss: 0.00001075
Iteration 388/1000 | Loss: 0.00001075
Iteration 389/1000 | Loss: 0.00001074
Iteration 390/1000 | Loss: 0.00001074
Iteration 391/1000 | Loss: 0.00001074
Iteration 392/1000 | Loss: 0.00001074
Iteration 393/1000 | Loss: 0.00001074
Iteration 394/1000 | Loss: 0.00001074
Iteration 395/1000 | Loss: 0.00001074
Iteration 396/1000 | Loss: 0.00001074
Iteration 397/1000 | Loss: 0.00001074
Iteration 398/1000 | Loss: 0.00001074
Iteration 399/1000 | Loss: 0.00001074
Iteration 400/1000 | Loss: 0.00001074
Iteration 401/1000 | Loss: 0.00001074
Iteration 402/1000 | Loss: 0.00001074
Iteration 403/1000 | Loss: 0.00001074
Iteration 404/1000 | Loss: 0.00001074
Iteration 405/1000 | Loss: 0.00001073
Iteration 406/1000 | Loss: 0.00001073
Iteration 407/1000 | Loss: 0.00001073
Iteration 408/1000 | Loss: 0.00001073
Iteration 409/1000 | Loss: 0.00001073
Iteration 410/1000 | Loss: 0.00001073
Iteration 411/1000 | Loss: 0.00001073
Iteration 412/1000 | Loss: 0.00001073
Iteration 413/1000 | Loss: 0.00001073
Iteration 414/1000 | Loss: 0.00001073
Iteration 415/1000 | Loss: 0.00001073
Iteration 416/1000 | Loss: 0.00001073
Iteration 417/1000 | Loss: 0.00001073
Iteration 418/1000 | Loss: 0.00001073
Iteration 419/1000 | Loss: 0.00001073
Iteration 420/1000 | Loss: 0.00001073
Iteration 421/1000 | Loss: 0.00001073
Iteration 422/1000 | Loss: 0.00001073
Iteration 423/1000 | Loss: 0.00001073
Iteration 424/1000 | Loss: 0.00001073
Iteration 425/1000 | Loss: 0.00001073
Iteration 426/1000 | Loss: 0.00001073
Iteration 427/1000 | Loss: 0.00001073
Iteration 428/1000 | Loss: 0.00001073
Iteration 429/1000 | Loss: 0.00001073
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 429. Stopping optimization.
Last 5 losses: [1.0726776963565499e-05, 1.0726776963565499e-05, 1.0726776963565499e-05, 1.0726776963565499e-05, 1.0726776963565499e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0726776963565499e-05

Optimization complete. Final v2v error: 2.8248021602630615 mm

Highest mean error: 3.753693103790283 mm for frame 60

Lowest mean error: 2.402831792831421 mm for frame 105

Saving results

Total time: 296.76290917396545
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00848657
Iteration 2/25 | Loss: 0.00113945
Iteration 3/25 | Loss: 0.00101921
Iteration 4/25 | Loss: 0.00100235
Iteration 5/25 | Loss: 0.00099900
Iteration 6/25 | Loss: 0.00099848
Iteration 7/25 | Loss: 0.00099848
Iteration 8/25 | Loss: 0.00099848
Iteration 9/25 | Loss: 0.00099848
Iteration 10/25 | Loss: 0.00099848
Iteration 11/25 | Loss: 0.00099848
Iteration 12/25 | Loss: 0.00099848
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009984768694266677, 0.0009984768694266677, 0.0009984768694266677, 0.0009984768694266677, 0.0009984768694266677]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009984768694266677

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46327353
Iteration 2/25 | Loss: 0.00048806
Iteration 3/25 | Loss: 0.00048806
Iteration 4/25 | Loss: 0.00048806
Iteration 5/25 | Loss: 0.00048806
Iteration 6/25 | Loss: 0.00048806
Iteration 7/25 | Loss: 0.00048806
Iteration 8/25 | Loss: 0.00048806
Iteration 9/25 | Loss: 0.00048806
Iteration 10/25 | Loss: 0.00048806
Iteration 11/25 | Loss: 0.00048806
Iteration 12/25 | Loss: 0.00048806
Iteration 13/25 | Loss: 0.00048806
Iteration 14/25 | Loss: 0.00048806
Iteration 15/25 | Loss: 0.00048806
Iteration 16/25 | Loss: 0.00048806
Iteration 17/25 | Loss: 0.00048806
Iteration 18/25 | Loss: 0.00048806
Iteration 19/25 | Loss: 0.00048806
Iteration 20/25 | Loss: 0.00048806
Iteration 21/25 | Loss: 0.00048806
Iteration 22/25 | Loss: 0.00048806
Iteration 23/25 | Loss: 0.00048806
Iteration 24/25 | Loss: 0.00048806
Iteration 25/25 | Loss: 0.00048806

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048806
Iteration 2/1000 | Loss: 0.00004077
Iteration 3/1000 | Loss: 0.00001791
Iteration 4/1000 | Loss: 0.00001503
Iteration 5/1000 | Loss: 0.00001390
Iteration 6/1000 | Loss: 0.00001323
Iteration 7/1000 | Loss: 0.00001277
Iteration 8/1000 | Loss: 0.00001243
Iteration 9/1000 | Loss: 0.00001229
Iteration 10/1000 | Loss: 0.00001223
Iteration 11/1000 | Loss: 0.00001222
Iteration 12/1000 | Loss: 0.00001222
Iteration 13/1000 | Loss: 0.00001221
Iteration 14/1000 | Loss: 0.00001221
Iteration 15/1000 | Loss: 0.00001213
Iteration 16/1000 | Loss: 0.00001212
Iteration 17/1000 | Loss: 0.00001206
Iteration 18/1000 | Loss: 0.00001197
Iteration 19/1000 | Loss: 0.00001196
Iteration 20/1000 | Loss: 0.00001190
Iteration 21/1000 | Loss: 0.00001189
Iteration 22/1000 | Loss: 0.00001189
Iteration 23/1000 | Loss: 0.00001188
Iteration 24/1000 | Loss: 0.00001188
Iteration 25/1000 | Loss: 0.00001187
Iteration 26/1000 | Loss: 0.00001185
Iteration 27/1000 | Loss: 0.00001185
Iteration 28/1000 | Loss: 0.00001185
Iteration 29/1000 | Loss: 0.00001185
Iteration 30/1000 | Loss: 0.00001184
Iteration 31/1000 | Loss: 0.00001184
Iteration 32/1000 | Loss: 0.00001184
Iteration 33/1000 | Loss: 0.00001183
Iteration 34/1000 | Loss: 0.00001183
Iteration 35/1000 | Loss: 0.00001183
Iteration 36/1000 | Loss: 0.00001182
Iteration 37/1000 | Loss: 0.00001182
Iteration 38/1000 | Loss: 0.00001182
Iteration 39/1000 | Loss: 0.00001181
Iteration 40/1000 | Loss: 0.00001181
Iteration 41/1000 | Loss: 0.00001181
Iteration 42/1000 | Loss: 0.00001181
Iteration 43/1000 | Loss: 0.00001181
Iteration 44/1000 | Loss: 0.00001180
Iteration 45/1000 | Loss: 0.00001180
Iteration 46/1000 | Loss: 0.00001180
Iteration 47/1000 | Loss: 0.00001179
Iteration 48/1000 | Loss: 0.00001179
Iteration 49/1000 | Loss: 0.00001178
Iteration 50/1000 | Loss: 0.00001177
Iteration 51/1000 | Loss: 0.00001177
Iteration 52/1000 | Loss: 0.00001176
Iteration 53/1000 | Loss: 0.00001176
Iteration 54/1000 | Loss: 0.00001176
Iteration 55/1000 | Loss: 0.00001176
Iteration 56/1000 | Loss: 0.00001176
Iteration 57/1000 | Loss: 0.00001176
Iteration 58/1000 | Loss: 0.00001176
Iteration 59/1000 | Loss: 0.00001175
Iteration 60/1000 | Loss: 0.00001175
Iteration 61/1000 | Loss: 0.00001175
Iteration 62/1000 | Loss: 0.00001175
Iteration 63/1000 | Loss: 0.00001175
Iteration 64/1000 | Loss: 0.00001175
Iteration 65/1000 | Loss: 0.00001174
Iteration 66/1000 | Loss: 0.00001174
Iteration 67/1000 | Loss: 0.00001174
Iteration 68/1000 | Loss: 0.00001174
Iteration 69/1000 | Loss: 0.00001173
Iteration 70/1000 | Loss: 0.00001173
Iteration 71/1000 | Loss: 0.00001172
Iteration 72/1000 | Loss: 0.00001172
Iteration 73/1000 | Loss: 0.00001172
Iteration 74/1000 | Loss: 0.00001172
Iteration 75/1000 | Loss: 0.00001171
Iteration 76/1000 | Loss: 0.00001171
Iteration 77/1000 | Loss: 0.00001171
Iteration 78/1000 | Loss: 0.00001171
Iteration 79/1000 | Loss: 0.00001170
Iteration 80/1000 | Loss: 0.00001170
Iteration 81/1000 | Loss: 0.00001170
Iteration 82/1000 | Loss: 0.00001170
Iteration 83/1000 | Loss: 0.00001170
Iteration 84/1000 | Loss: 0.00001170
Iteration 85/1000 | Loss: 0.00001169
Iteration 86/1000 | Loss: 0.00001169
Iteration 87/1000 | Loss: 0.00001169
Iteration 88/1000 | Loss: 0.00001169
Iteration 89/1000 | Loss: 0.00001169
Iteration 90/1000 | Loss: 0.00001169
Iteration 91/1000 | Loss: 0.00001169
Iteration 92/1000 | Loss: 0.00001169
Iteration 93/1000 | Loss: 0.00001169
Iteration 94/1000 | Loss: 0.00001169
Iteration 95/1000 | Loss: 0.00001169
Iteration 96/1000 | Loss: 0.00001169
Iteration 97/1000 | Loss: 0.00001169
Iteration 98/1000 | Loss: 0.00001169
Iteration 99/1000 | Loss: 0.00001169
Iteration 100/1000 | Loss: 0.00001169
Iteration 101/1000 | Loss: 0.00001169
Iteration 102/1000 | Loss: 0.00001169
Iteration 103/1000 | Loss: 0.00001169
Iteration 104/1000 | Loss: 0.00001169
Iteration 105/1000 | Loss: 0.00001169
Iteration 106/1000 | Loss: 0.00001169
Iteration 107/1000 | Loss: 0.00001169
Iteration 108/1000 | Loss: 0.00001169
Iteration 109/1000 | Loss: 0.00001169
Iteration 110/1000 | Loss: 0.00001169
Iteration 111/1000 | Loss: 0.00001169
Iteration 112/1000 | Loss: 0.00001169
Iteration 113/1000 | Loss: 0.00001169
Iteration 114/1000 | Loss: 0.00001169
Iteration 115/1000 | Loss: 0.00001169
Iteration 116/1000 | Loss: 0.00001169
Iteration 117/1000 | Loss: 0.00001169
Iteration 118/1000 | Loss: 0.00001169
Iteration 119/1000 | Loss: 0.00001169
Iteration 120/1000 | Loss: 0.00001169
Iteration 121/1000 | Loss: 0.00001169
Iteration 122/1000 | Loss: 0.00001169
Iteration 123/1000 | Loss: 0.00001169
Iteration 124/1000 | Loss: 0.00001169
Iteration 125/1000 | Loss: 0.00001169
Iteration 126/1000 | Loss: 0.00001169
Iteration 127/1000 | Loss: 0.00001169
Iteration 128/1000 | Loss: 0.00001169
Iteration 129/1000 | Loss: 0.00001169
Iteration 130/1000 | Loss: 0.00001169
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 130. Stopping optimization.
Last 5 losses: [1.1685119716275949e-05, 1.1685119716275949e-05, 1.1685119716275949e-05, 1.1685119716275949e-05, 1.1685119716275949e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1685119716275949e-05

Optimization complete. Final v2v error: 2.9788317680358887 mm

Highest mean error: 3.4139206409454346 mm for frame 89

Lowest mean error: 2.7427139282226562 mm for frame 70

Saving results

Total time: 30.718912601470947
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01079261
Iteration 2/25 | Loss: 0.01079261
Iteration 3/25 | Loss: 0.01079261
Iteration 4/25 | Loss: 0.01079261
Iteration 5/25 | Loss: 0.01079261
Iteration 6/25 | Loss: 0.01079261
Iteration 7/25 | Loss: 0.01079261
Iteration 8/25 | Loss: 0.01079261
Iteration 9/25 | Loss: 0.01079261
Iteration 10/25 | Loss: 0.01079261
Iteration 11/25 | Loss: 0.01079261
Iteration 12/25 | Loss: 0.01079260
Iteration 13/25 | Loss: 0.01079260
Iteration 14/25 | Loss: 0.01079260
Iteration 15/25 | Loss: 0.01079260
Iteration 16/25 | Loss: 0.01079260
Iteration 17/25 | Loss: 0.01079260
Iteration 18/25 | Loss: 0.01079260
Iteration 19/25 | Loss: 0.01079260
Iteration 20/25 | Loss: 0.01079260
Iteration 21/25 | Loss: 0.01079260
Iteration 22/25 | Loss: 0.01079260
Iteration 23/25 | Loss: 0.01079260
Iteration 24/25 | Loss: 0.01079260
Iteration 25/25 | Loss: 0.01079259

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67908716
Iteration 2/25 | Loss: 0.11052505
Iteration 3/25 | Loss: 0.11051593
Iteration 4/25 | Loss: 0.11051590
Iteration 5/25 | Loss: 0.11051588
Iteration 6/25 | Loss: 0.11051587
Iteration 7/25 | Loss: 0.11051586
Iteration 8/25 | Loss: 0.11051586
Iteration 9/25 | Loss: 0.11051586
Iteration 10/25 | Loss: 0.11051586
Iteration 11/25 | Loss: 0.11051586
Iteration 12/25 | Loss: 0.11051586
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.11051586270332336, 0.11051586270332336, 0.11051586270332336, 0.11051586270332336, 0.11051586270332336]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.11051586270332336

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.11051586
Iteration 2/1000 | Loss: 0.00343545
Iteration 3/1000 | Loss: 0.00674902
Iteration 4/1000 | Loss: 0.03097055
Iteration 5/1000 | Loss: 0.00096461
Iteration 6/1000 | Loss: 0.00043296
Iteration 7/1000 | Loss: 0.00077858
Iteration 8/1000 | Loss: 0.00064267
Iteration 9/1000 | Loss: 0.00012403
Iteration 10/1000 | Loss: 0.00014811
Iteration 11/1000 | Loss: 0.00006977
Iteration 12/1000 | Loss: 0.00042553
Iteration 13/1000 | Loss: 0.00008385
Iteration 14/1000 | Loss: 0.00049635
Iteration 15/1000 | Loss: 0.00006478
Iteration 16/1000 | Loss: 0.00010865
Iteration 17/1000 | Loss: 0.00024900
Iteration 18/1000 | Loss: 0.00009934
Iteration 19/1000 | Loss: 0.00004441
Iteration 20/1000 | Loss: 0.00007593
Iteration 21/1000 | Loss: 0.00015688
Iteration 22/1000 | Loss: 0.00073841
Iteration 23/1000 | Loss: 0.00010614
Iteration 24/1000 | Loss: 0.00008641
Iteration 25/1000 | Loss: 0.00002119
Iteration 26/1000 | Loss: 0.00004616
Iteration 27/1000 | Loss: 0.00015720
Iteration 28/1000 | Loss: 0.00004200
Iteration 29/1000 | Loss: 0.00003465
Iteration 30/1000 | Loss: 0.00003671
Iteration 31/1000 | Loss: 0.00003053
Iteration 32/1000 | Loss: 0.00003701
Iteration 33/1000 | Loss: 0.00002387
Iteration 34/1000 | Loss: 0.00003591
Iteration 35/1000 | Loss: 0.00005790
Iteration 36/1000 | Loss: 0.00001795
Iteration 37/1000 | Loss: 0.00001612
Iteration 38/1000 | Loss: 0.00003951
Iteration 39/1000 | Loss: 0.00002614
Iteration 40/1000 | Loss: 0.00020641
Iteration 41/1000 | Loss: 0.00011147
Iteration 42/1000 | Loss: 0.00010890
Iteration 43/1000 | Loss: 0.00001708
Iteration 44/1000 | Loss: 0.00005675
Iteration 45/1000 | Loss: 0.00001883
Iteration 46/1000 | Loss: 0.00001576
Iteration 47/1000 | Loss: 0.00001645
Iteration 48/1000 | Loss: 0.00003361
Iteration 49/1000 | Loss: 0.00001563
Iteration 50/1000 | Loss: 0.00001747
Iteration 51/1000 | Loss: 0.00001509
Iteration 52/1000 | Loss: 0.00002887
Iteration 53/1000 | Loss: 0.00002763
Iteration 54/1000 | Loss: 0.00006620
Iteration 55/1000 | Loss: 0.00001616
Iteration 56/1000 | Loss: 0.00001578
Iteration 57/1000 | Loss: 0.00001701
Iteration 58/1000 | Loss: 0.00001904
Iteration 59/1000 | Loss: 0.00002033
Iteration 60/1000 | Loss: 0.00001495
Iteration 61/1000 | Loss: 0.00001479
Iteration 62/1000 | Loss: 0.00001479
Iteration 63/1000 | Loss: 0.00001478
Iteration 64/1000 | Loss: 0.00001478
Iteration 65/1000 | Loss: 0.00001478
Iteration 66/1000 | Loss: 0.00001478
Iteration 67/1000 | Loss: 0.00001478
Iteration 68/1000 | Loss: 0.00001478
Iteration 69/1000 | Loss: 0.00001478
Iteration 70/1000 | Loss: 0.00001478
Iteration 71/1000 | Loss: 0.00001478
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 71. Stopping optimization.
Last 5 losses: [1.4782609468966257e-05, 1.4782609468966257e-05, 1.4782609468966257e-05, 1.4782609468966257e-05, 1.4782609468966257e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4782609468966257e-05

Optimization complete. Final v2v error: 3.279470920562744 mm

Highest mean error: 3.7175142765045166 mm for frame 136

Lowest mean error: 3.0477664470672607 mm for frame 237

Saving results

Total time: 97.38089418411255
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00897058
Iteration 2/25 | Loss: 0.00107155
Iteration 3/25 | Loss: 0.00095225
Iteration 4/25 | Loss: 0.00094334
Iteration 5/25 | Loss: 0.00094072
Iteration 6/25 | Loss: 0.00094038
Iteration 7/25 | Loss: 0.00094038
Iteration 8/25 | Loss: 0.00094038
Iteration 9/25 | Loss: 0.00094038
Iteration 10/25 | Loss: 0.00094038
Iteration 11/25 | Loss: 0.00094038
Iteration 12/25 | Loss: 0.00094038
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009403752628713846, 0.0009403752628713846, 0.0009403752628713846, 0.0009403752628713846, 0.0009403752628713846]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009403752628713846

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 7.06190157
Iteration 2/25 | Loss: 0.00048459
Iteration 3/25 | Loss: 0.00048459
Iteration 4/25 | Loss: 0.00048459
Iteration 5/25 | Loss: 0.00048459
Iteration 6/25 | Loss: 0.00048458
Iteration 7/25 | Loss: 0.00048458
Iteration 8/25 | Loss: 0.00048458
Iteration 9/25 | Loss: 0.00048458
Iteration 10/25 | Loss: 0.00048458
Iteration 11/25 | Loss: 0.00048458
Iteration 12/25 | Loss: 0.00048458
Iteration 13/25 | Loss: 0.00048458
Iteration 14/25 | Loss: 0.00048458
Iteration 15/25 | Loss: 0.00048458
Iteration 16/25 | Loss: 0.00048458
Iteration 17/25 | Loss: 0.00048458
Iteration 18/25 | Loss: 0.00048458
Iteration 19/25 | Loss: 0.00048458
Iteration 20/25 | Loss: 0.00048458
Iteration 21/25 | Loss: 0.00048458
Iteration 22/25 | Loss: 0.00048458
Iteration 23/25 | Loss: 0.00048458
Iteration 24/25 | Loss: 0.00048458
Iteration 25/25 | Loss: 0.00048458

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048458
Iteration 2/1000 | Loss: 0.00002536
Iteration 3/1000 | Loss: 0.00001585
Iteration 4/1000 | Loss: 0.00001301
Iteration 5/1000 | Loss: 0.00001180
Iteration 6/1000 | Loss: 0.00001127
Iteration 7/1000 | Loss: 0.00001124
Iteration 8/1000 | Loss: 0.00001083
Iteration 9/1000 | Loss: 0.00001073
Iteration 10/1000 | Loss: 0.00001069
Iteration 11/1000 | Loss: 0.00001049
Iteration 12/1000 | Loss: 0.00001044
Iteration 13/1000 | Loss: 0.00001039
Iteration 14/1000 | Loss: 0.00001038
Iteration 15/1000 | Loss: 0.00001036
Iteration 16/1000 | Loss: 0.00001028
Iteration 17/1000 | Loss: 0.00001025
Iteration 18/1000 | Loss: 0.00001025
Iteration 19/1000 | Loss: 0.00001024
Iteration 20/1000 | Loss: 0.00001024
Iteration 21/1000 | Loss: 0.00001023
Iteration 22/1000 | Loss: 0.00001021
Iteration 23/1000 | Loss: 0.00001020
Iteration 24/1000 | Loss: 0.00001020
Iteration 25/1000 | Loss: 0.00001020
Iteration 26/1000 | Loss: 0.00001020
Iteration 27/1000 | Loss: 0.00001020
Iteration 28/1000 | Loss: 0.00001020
Iteration 29/1000 | Loss: 0.00001020
Iteration 30/1000 | Loss: 0.00001020
Iteration 31/1000 | Loss: 0.00001019
Iteration 32/1000 | Loss: 0.00001019
Iteration 33/1000 | Loss: 0.00001019
Iteration 34/1000 | Loss: 0.00001019
Iteration 35/1000 | Loss: 0.00001018
Iteration 36/1000 | Loss: 0.00001018
Iteration 37/1000 | Loss: 0.00001018
Iteration 38/1000 | Loss: 0.00001017
Iteration 39/1000 | Loss: 0.00001017
Iteration 40/1000 | Loss: 0.00001017
Iteration 41/1000 | Loss: 0.00001017
Iteration 42/1000 | Loss: 0.00001016
Iteration 43/1000 | Loss: 0.00001016
Iteration 44/1000 | Loss: 0.00001016
Iteration 45/1000 | Loss: 0.00001016
Iteration 46/1000 | Loss: 0.00001016
Iteration 47/1000 | Loss: 0.00001016
Iteration 48/1000 | Loss: 0.00001016
Iteration 49/1000 | Loss: 0.00001016
Iteration 50/1000 | Loss: 0.00001015
Iteration 51/1000 | Loss: 0.00001015
Iteration 52/1000 | Loss: 0.00001015
Iteration 53/1000 | Loss: 0.00001015
Iteration 54/1000 | Loss: 0.00001015
Iteration 55/1000 | Loss: 0.00001014
Iteration 56/1000 | Loss: 0.00001014
Iteration 57/1000 | Loss: 0.00001014
Iteration 58/1000 | Loss: 0.00001013
Iteration 59/1000 | Loss: 0.00001013
Iteration 60/1000 | Loss: 0.00001012
Iteration 61/1000 | Loss: 0.00001012
Iteration 62/1000 | Loss: 0.00001012
Iteration 63/1000 | Loss: 0.00001012
Iteration 64/1000 | Loss: 0.00001012
Iteration 65/1000 | Loss: 0.00001012
Iteration 66/1000 | Loss: 0.00001012
Iteration 67/1000 | Loss: 0.00001012
Iteration 68/1000 | Loss: 0.00001011
Iteration 69/1000 | Loss: 0.00001011
Iteration 70/1000 | Loss: 0.00001011
Iteration 71/1000 | Loss: 0.00001011
Iteration 72/1000 | Loss: 0.00001010
Iteration 73/1000 | Loss: 0.00001010
Iteration 74/1000 | Loss: 0.00001010
Iteration 75/1000 | Loss: 0.00001010
Iteration 76/1000 | Loss: 0.00001009
Iteration 77/1000 | Loss: 0.00001009
Iteration 78/1000 | Loss: 0.00001009
Iteration 79/1000 | Loss: 0.00001009
Iteration 80/1000 | Loss: 0.00001009
Iteration 81/1000 | Loss: 0.00001009
Iteration 82/1000 | Loss: 0.00001009
Iteration 83/1000 | Loss: 0.00001009
Iteration 84/1000 | Loss: 0.00001009
Iteration 85/1000 | Loss: 0.00001009
Iteration 86/1000 | Loss: 0.00001009
Iteration 87/1000 | Loss: 0.00001009
Iteration 88/1000 | Loss: 0.00001009
Iteration 89/1000 | Loss: 0.00001009
Iteration 90/1000 | Loss: 0.00001009
Iteration 91/1000 | Loss: 0.00001009
Iteration 92/1000 | Loss: 0.00001009
Iteration 93/1000 | Loss: 0.00001008
Iteration 94/1000 | Loss: 0.00001008
Iteration 95/1000 | Loss: 0.00001008
Iteration 96/1000 | Loss: 0.00001008
Iteration 97/1000 | Loss: 0.00001008
Iteration 98/1000 | Loss: 0.00001008
Iteration 99/1000 | Loss: 0.00001008
Iteration 100/1000 | Loss: 0.00001008
Iteration 101/1000 | Loss: 0.00001008
Iteration 102/1000 | Loss: 0.00001008
Iteration 103/1000 | Loss: 0.00001008
Iteration 104/1000 | Loss: 0.00001008
Iteration 105/1000 | Loss: 0.00001008
Iteration 106/1000 | Loss: 0.00001007
Iteration 107/1000 | Loss: 0.00001007
Iteration 108/1000 | Loss: 0.00001007
Iteration 109/1000 | Loss: 0.00001007
Iteration 110/1000 | Loss: 0.00001007
Iteration 111/1000 | Loss: 0.00001006
Iteration 112/1000 | Loss: 0.00001006
Iteration 113/1000 | Loss: 0.00001006
Iteration 114/1000 | Loss: 0.00001006
Iteration 115/1000 | Loss: 0.00001006
Iteration 116/1000 | Loss: 0.00001006
Iteration 117/1000 | Loss: 0.00001006
Iteration 118/1000 | Loss: 0.00001006
Iteration 119/1000 | Loss: 0.00001006
Iteration 120/1000 | Loss: 0.00001006
Iteration 121/1000 | Loss: 0.00001006
Iteration 122/1000 | Loss: 0.00001005
Iteration 123/1000 | Loss: 0.00001005
Iteration 124/1000 | Loss: 0.00001005
Iteration 125/1000 | Loss: 0.00001005
Iteration 126/1000 | Loss: 0.00001005
Iteration 127/1000 | Loss: 0.00001005
Iteration 128/1000 | Loss: 0.00001005
Iteration 129/1000 | Loss: 0.00001005
Iteration 130/1000 | Loss: 0.00001005
Iteration 131/1000 | Loss: 0.00001005
Iteration 132/1000 | Loss: 0.00001005
Iteration 133/1000 | Loss: 0.00001005
Iteration 134/1000 | Loss: 0.00001005
Iteration 135/1000 | Loss: 0.00001005
Iteration 136/1000 | Loss: 0.00001004
Iteration 137/1000 | Loss: 0.00001004
Iteration 138/1000 | Loss: 0.00001004
Iteration 139/1000 | Loss: 0.00001004
Iteration 140/1000 | Loss: 0.00001004
Iteration 141/1000 | Loss: 0.00001004
Iteration 142/1000 | Loss: 0.00001004
Iteration 143/1000 | Loss: 0.00001004
Iteration 144/1000 | Loss: 0.00001004
Iteration 145/1000 | Loss: 0.00001004
Iteration 146/1000 | Loss: 0.00001004
Iteration 147/1000 | Loss: 0.00001004
Iteration 148/1000 | Loss: 0.00001004
Iteration 149/1000 | Loss: 0.00001004
Iteration 150/1000 | Loss: 0.00001004
Iteration 151/1000 | Loss: 0.00001003
Iteration 152/1000 | Loss: 0.00001003
Iteration 153/1000 | Loss: 0.00001003
Iteration 154/1000 | Loss: 0.00001003
Iteration 155/1000 | Loss: 0.00001003
Iteration 156/1000 | Loss: 0.00001003
Iteration 157/1000 | Loss: 0.00001003
Iteration 158/1000 | Loss: 0.00001003
Iteration 159/1000 | Loss: 0.00001003
Iteration 160/1000 | Loss: 0.00001003
Iteration 161/1000 | Loss: 0.00001003
Iteration 162/1000 | Loss: 0.00001002
Iteration 163/1000 | Loss: 0.00001002
Iteration 164/1000 | Loss: 0.00001002
Iteration 165/1000 | Loss: 0.00001002
Iteration 166/1000 | Loss: 0.00001002
Iteration 167/1000 | Loss: 0.00001001
Iteration 168/1000 | Loss: 0.00001001
Iteration 169/1000 | Loss: 0.00001001
Iteration 170/1000 | Loss: 0.00001001
Iteration 171/1000 | Loss: 0.00001001
Iteration 172/1000 | Loss: 0.00001001
Iteration 173/1000 | Loss: 0.00001001
Iteration 174/1000 | Loss: 0.00001001
Iteration 175/1000 | Loss: 0.00001001
Iteration 176/1000 | Loss: 0.00001001
Iteration 177/1000 | Loss: 0.00001001
Iteration 178/1000 | Loss: 0.00001001
Iteration 179/1000 | Loss: 0.00001001
Iteration 180/1000 | Loss: 0.00001001
Iteration 181/1000 | Loss: 0.00001001
Iteration 182/1000 | Loss: 0.00001001
Iteration 183/1000 | Loss: 0.00001001
Iteration 184/1000 | Loss: 0.00001001
Iteration 185/1000 | Loss: 0.00001001
Iteration 186/1000 | Loss: 0.00001001
Iteration 187/1000 | Loss: 0.00001001
Iteration 188/1000 | Loss: 0.00001001
Iteration 189/1000 | Loss: 0.00001001
Iteration 190/1000 | Loss: 0.00001001
Iteration 191/1000 | Loss: 0.00001001
Iteration 192/1000 | Loss: 0.00001001
Iteration 193/1000 | Loss: 0.00001001
Iteration 194/1000 | Loss: 0.00001001
Iteration 195/1000 | Loss: 0.00001001
Iteration 196/1000 | Loss: 0.00001001
Iteration 197/1000 | Loss: 0.00001001
Iteration 198/1000 | Loss: 0.00001001
Iteration 199/1000 | Loss: 0.00001001
Iteration 200/1000 | Loss: 0.00001001
Iteration 201/1000 | Loss: 0.00001001
Iteration 202/1000 | Loss: 0.00001001
Iteration 203/1000 | Loss: 0.00001001
Iteration 204/1000 | Loss: 0.00001001
Iteration 205/1000 | Loss: 0.00001001
Iteration 206/1000 | Loss: 0.00001001
Iteration 207/1000 | Loss: 0.00001001
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [1.000939209916396e-05, 1.000939209916396e-05, 1.000939209916396e-05, 1.000939209916396e-05, 1.000939209916396e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.000939209916396e-05

Optimization complete. Final v2v error: 2.703672409057617 mm

Highest mean error: 2.9130547046661377 mm for frame 183

Lowest mean error: 2.5150105953216553 mm for frame 94

Saving results

Total time: 38.86326003074646
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00888219
Iteration 2/25 | Loss: 0.00128316
Iteration 3/25 | Loss: 0.00102143
Iteration 4/25 | Loss: 0.00099442
Iteration 5/25 | Loss: 0.00098648
Iteration 6/25 | Loss: 0.00098425
Iteration 7/25 | Loss: 0.00098416
Iteration 8/25 | Loss: 0.00098415
Iteration 9/25 | Loss: 0.00098416
Iteration 10/25 | Loss: 0.00098416
Iteration 11/25 | Loss: 0.00098416
Iteration 12/25 | Loss: 0.00098416
Iteration 13/25 | Loss: 0.00098416
Iteration 14/25 | Loss: 0.00098416
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0009841551072895527, 0.0009841551072895527, 0.0009841551072895527, 0.0009841551072895527, 0.0009841551072895527]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009841551072895527

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.89748669
Iteration 2/25 | Loss: 0.00054712
Iteration 3/25 | Loss: 0.00054712
Iteration 4/25 | Loss: 0.00054712
Iteration 5/25 | Loss: 0.00054712
Iteration 6/25 | Loss: 0.00054712
Iteration 7/25 | Loss: 0.00054712
Iteration 8/25 | Loss: 0.00054712
Iteration 9/25 | Loss: 0.00054712
Iteration 10/25 | Loss: 0.00054712
Iteration 11/25 | Loss: 0.00054712
Iteration 12/25 | Loss: 0.00054712
Iteration 13/25 | Loss: 0.00054712
Iteration 14/25 | Loss: 0.00054712
Iteration 15/25 | Loss: 0.00054712
Iteration 16/25 | Loss: 0.00054712
Iteration 17/25 | Loss: 0.00054712
Iteration 18/25 | Loss: 0.00054712
Iteration 19/25 | Loss: 0.00054712
Iteration 20/25 | Loss: 0.00054712
Iteration 21/25 | Loss: 0.00054712
Iteration 22/25 | Loss: 0.00054712
Iteration 23/25 | Loss: 0.00054712
Iteration 24/25 | Loss: 0.00054712
Iteration 25/25 | Loss: 0.00054712

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054712
Iteration 2/1000 | Loss: 0.00003574
Iteration 3/1000 | Loss: 0.00001618
Iteration 4/1000 | Loss: 0.00001392
Iteration 5/1000 | Loss: 0.00001283
Iteration 6/1000 | Loss: 0.00001239
Iteration 7/1000 | Loss: 0.00001200
Iteration 8/1000 | Loss: 0.00001192
Iteration 9/1000 | Loss: 0.00001190
Iteration 10/1000 | Loss: 0.00001189
Iteration 11/1000 | Loss: 0.00001178
Iteration 12/1000 | Loss: 0.00001168
Iteration 13/1000 | Loss: 0.00001155
Iteration 14/1000 | Loss: 0.00001154
Iteration 15/1000 | Loss: 0.00001154
Iteration 16/1000 | Loss: 0.00001149
Iteration 17/1000 | Loss: 0.00001148
Iteration 18/1000 | Loss: 0.00001147
Iteration 19/1000 | Loss: 0.00001147
Iteration 20/1000 | Loss: 0.00001146
Iteration 21/1000 | Loss: 0.00001146
Iteration 22/1000 | Loss: 0.00001146
Iteration 23/1000 | Loss: 0.00001146
Iteration 24/1000 | Loss: 0.00001145
Iteration 25/1000 | Loss: 0.00001145
Iteration 26/1000 | Loss: 0.00001145
Iteration 27/1000 | Loss: 0.00001145
Iteration 28/1000 | Loss: 0.00001144
Iteration 29/1000 | Loss: 0.00001144
Iteration 30/1000 | Loss: 0.00001143
Iteration 31/1000 | Loss: 0.00001143
Iteration 32/1000 | Loss: 0.00001142
Iteration 33/1000 | Loss: 0.00001142
Iteration 34/1000 | Loss: 0.00001142
Iteration 35/1000 | Loss: 0.00001141
Iteration 36/1000 | Loss: 0.00001141
Iteration 37/1000 | Loss: 0.00001140
Iteration 38/1000 | Loss: 0.00001140
Iteration 39/1000 | Loss: 0.00001139
Iteration 40/1000 | Loss: 0.00001138
Iteration 41/1000 | Loss: 0.00001138
Iteration 42/1000 | Loss: 0.00001138
Iteration 43/1000 | Loss: 0.00001138
Iteration 44/1000 | Loss: 0.00001137
Iteration 45/1000 | Loss: 0.00001137
Iteration 46/1000 | Loss: 0.00001137
Iteration 47/1000 | Loss: 0.00001137
Iteration 48/1000 | Loss: 0.00001136
Iteration 49/1000 | Loss: 0.00001136
Iteration 50/1000 | Loss: 0.00001136
Iteration 51/1000 | Loss: 0.00001136
Iteration 52/1000 | Loss: 0.00001135
Iteration 53/1000 | Loss: 0.00001135
Iteration 54/1000 | Loss: 0.00001135
Iteration 55/1000 | Loss: 0.00001134
Iteration 56/1000 | Loss: 0.00001134
Iteration 57/1000 | Loss: 0.00001133
Iteration 58/1000 | Loss: 0.00001133
Iteration 59/1000 | Loss: 0.00001133
Iteration 60/1000 | Loss: 0.00001133
Iteration 61/1000 | Loss: 0.00001133
Iteration 62/1000 | Loss: 0.00001133
Iteration 63/1000 | Loss: 0.00001132
Iteration 64/1000 | Loss: 0.00001132
Iteration 65/1000 | Loss: 0.00001132
Iteration 66/1000 | Loss: 0.00001132
Iteration 67/1000 | Loss: 0.00001132
Iteration 68/1000 | Loss: 0.00001132
Iteration 69/1000 | Loss: 0.00001132
Iteration 70/1000 | Loss: 0.00001132
Iteration 71/1000 | Loss: 0.00001132
Iteration 72/1000 | Loss: 0.00001132
Iteration 73/1000 | Loss: 0.00001131
Iteration 74/1000 | Loss: 0.00001131
Iteration 75/1000 | Loss: 0.00001131
Iteration 76/1000 | Loss: 0.00001130
Iteration 77/1000 | Loss: 0.00001130
Iteration 78/1000 | Loss: 0.00001130
Iteration 79/1000 | Loss: 0.00001129
Iteration 80/1000 | Loss: 0.00001129
Iteration 81/1000 | Loss: 0.00001129
Iteration 82/1000 | Loss: 0.00001129
Iteration 83/1000 | Loss: 0.00001128
Iteration 84/1000 | Loss: 0.00001128
Iteration 85/1000 | Loss: 0.00001128
Iteration 86/1000 | Loss: 0.00001128
Iteration 87/1000 | Loss: 0.00001128
Iteration 88/1000 | Loss: 0.00001128
Iteration 89/1000 | Loss: 0.00001127
Iteration 90/1000 | Loss: 0.00001126
Iteration 91/1000 | Loss: 0.00001126
Iteration 92/1000 | Loss: 0.00001126
Iteration 93/1000 | Loss: 0.00001126
Iteration 94/1000 | Loss: 0.00001126
Iteration 95/1000 | Loss: 0.00001125
Iteration 96/1000 | Loss: 0.00001125
Iteration 97/1000 | Loss: 0.00001125
Iteration 98/1000 | Loss: 0.00001125
Iteration 99/1000 | Loss: 0.00001125
Iteration 100/1000 | Loss: 0.00001125
Iteration 101/1000 | Loss: 0.00001125
Iteration 102/1000 | Loss: 0.00001124
Iteration 103/1000 | Loss: 0.00001124
Iteration 104/1000 | Loss: 0.00001124
Iteration 105/1000 | Loss: 0.00001123
Iteration 106/1000 | Loss: 0.00001123
Iteration 107/1000 | Loss: 0.00001122
Iteration 108/1000 | Loss: 0.00001122
Iteration 109/1000 | Loss: 0.00001122
Iteration 110/1000 | Loss: 0.00001122
Iteration 111/1000 | Loss: 0.00001122
Iteration 112/1000 | Loss: 0.00001121
Iteration 113/1000 | Loss: 0.00001121
Iteration 114/1000 | Loss: 0.00001120
Iteration 115/1000 | Loss: 0.00001120
Iteration 116/1000 | Loss: 0.00001120
Iteration 117/1000 | Loss: 0.00001119
Iteration 118/1000 | Loss: 0.00001119
Iteration 119/1000 | Loss: 0.00001119
Iteration 120/1000 | Loss: 0.00001119
Iteration 121/1000 | Loss: 0.00001119
Iteration 122/1000 | Loss: 0.00001118
Iteration 123/1000 | Loss: 0.00001117
Iteration 124/1000 | Loss: 0.00001117
Iteration 125/1000 | Loss: 0.00001117
Iteration 126/1000 | Loss: 0.00001117
Iteration 127/1000 | Loss: 0.00001117
Iteration 128/1000 | Loss: 0.00001117
Iteration 129/1000 | Loss: 0.00001117
Iteration 130/1000 | Loss: 0.00001117
Iteration 131/1000 | Loss: 0.00001117
Iteration 132/1000 | Loss: 0.00001117
Iteration 133/1000 | Loss: 0.00001117
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [1.1168042874487583e-05, 1.1168042874487583e-05, 1.1168042874487583e-05, 1.1168042874487583e-05, 1.1168042874487583e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1168042874487583e-05

Optimization complete. Final v2v error: 2.8748891353607178 mm

Highest mean error: 3.444190263748169 mm for frame 171

Lowest mean error: 2.5305471420288086 mm for frame 211

Saving results

Total time: 36.55655002593994
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01052238
Iteration 2/25 | Loss: 0.00268236
Iteration 3/25 | Loss: 0.00175774
Iteration 4/25 | Loss: 0.00147772
Iteration 5/25 | Loss: 0.00134409
Iteration 6/25 | Loss: 0.00132336
Iteration 7/25 | Loss: 0.00131658
Iteration 8/25 | Loss: 0.00128791
Iteration 9/25 | Loss: 0.00125487
Iteration 10/25 | Loss: 0.00124444
Iteration 11/25 | Loss: 0.00120815
Iteration 12/25 | Loss: 0.00121577
Iteration 13/25 | Loss: 0.00118507
Iteration 14/25 | Loss: 0.00118320
Iteration 15/25 | Loss: 0.00118294
Iteration 16/25 | Loss: 0.00117531
Iteration 17/25 | Loss: 0.00117111
Iteration 18/25 | Loss: 0.00116646
Iteration 19/25 | Loss: 0.00116324
Iteration 20/25 | Loss: 0.00116228
Iteration 21/25 | Loss: 0.00116107
Iteration 22/25 | Loss: 0.00116049
Iteration 23/25 | Loss: 0.00116048
Iteration 24/25 | Loss: 0.00116048
Iteration 25/25 | Loss: 0.00116048

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.40148222
Iteration 2/25 | Loss: 0.00175816
Iteration 3/25 | Loss: 0.00142256
Iteration 4/25 | Loss: 0.00141354
Iteration 5/25 | Loss: 0.00141354
Iteration 6/25 | Loss: 0.00141354
Iteration 7/25 | Loss: 0.00141354
Iteration 8/25 | Loss: 0.00141354
Iteration 9/25 | Loss: 0.00141354
Iteration 10/25 | Loss: 0.00141354
Iteration 11/25 | Loss: 0.00141354
Iteration 12/25 | Loss: 0.00141354
Iteration 13/25 | Loss: 0.00141354
Iteration 14/25 | Loss: 0.00141354
Iteration 15/25 | Loss: 0.00141354
Iteration 16/25 | Loss: 0.00141354
Iteration 17/25 | Loss: 0.00141354
Iteration 18/25 | Loss: 0.00141354
Iteration 19/25 | Loss: 0.00141354
Iteration 20/25 | Loss: 0.00141354
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0014135425444692373, 0.0014135425444692373, 0.0014135425444692373, 0.0014135425444692373, 0.0014135425444692373]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014135425444692373

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00141354
Iteration 2/1000 | Loss: 0.00082235
Iteration 3/1000 | Loss: 0.00048906
Iteration 4/1000 | Loss: 0.00038638
Iteration 5/1000 | Loss: 0.00022564
Iteration 6/1000 | Loss: 0.00013885
Iteration 7/1000 | Loss: 0.00021515
Iteration 8/1000 | Loss: 0.00021652
Iteration 9/1000 | Loss: 0.00023248
Iteration 10/1000 | Loss: 0.00012539
Iteration 11/1000 | Loss: 0.00019980
Iteration 12/1000 | Loss: 0.00017274
Iteration 13/1000 | Loss: 0.00016791
Iteration 14/1000 | Loss: 0.00031522
Iteration 15/1000 | Loss: 0.00009833
Iteration 16/1000 | Loss: 0.00031529
Iteration 17/1000 | Loss: 0.00034113
Iteration 18/1000 | Loss: 0.00028882
Iteration 19/1000 | Loss: 0.00008512
Iteration 20/1000 | Loss: 0.00007827
Iteration 21/1000 | Loss: 0.00010507
Iteration 22/1000 | Loss: 0.00009773
Iteration 23/1000 | Loss: 0.00128802
Iteration 24/1000 | Loss: 0.00196476
Iteration 25/1000 | Loss: 0.00049618
Iteration 26/1000 | Loss: 0.00037704
Iteration 27/1000 | Loss: 0.00012085
Iteration 28/1000 | Loss: 0.00012978
Iteration 29/1000 | Loss: 0.00017278
Iteration 30/1000 | Loss: 0.00044226
Iteration 31/1000 | Loss: 0.00004379
Iteration 32/1000 | Loss: 0.00027920
Iteration 33/1000 | Loss: 0.00003915
Iteration 34/1000 | Loss: 0.00005672
Iteration 35/1000 | Loss: 0.00003685
Iteration 36/1000 | Loss: 0.00004014
Iteration 37/1000 | Loss: 0.00004121
Iteration 38/1000 | Loss: 0.00003906
Iteration 39/1000 | Loss: 0.00003809
Iteration 40/1000 | Loss: 0.00003088
Iteration 41/1000 | Loss: 0.00003787
Iteration 42/1000 | Loss: 0.00011152
Iteration 43/1000 | Loss: 0.00002367
Iteration 44/1000 | Loss: 0.00004407
Iteration 45/1000 | Loss: 0.00005387
Iteration 46/1000 | Loss: 0.00005203
Iteration 47/1000 | Loss: 0.00005421
Iteration 48/1000 | Loss: 0.00014307
Iteration 49/1000 | Loss: 0.00003489
Iteration 50/1000 | Loss: 0.00003560
Iteration 51/1000 | Loss: 0.00001785
Iteration 52/1000 | Loss: 0.00001935
Iteration 53/1000 | Loss: 0.00001831
Iteration 54/1000 | Loss: 0.00001772
Iteration 55/1000 | Loss: 0.00001772
Iteration 56/1000 | Loss: 0.00001772
Iteration 57/1000 | Loss: 0.00001772
Iteration 58/1000 | Loss: 0.00001772
Iteration 59/1000 | Loss: 0.00001772
Iteration 60/1000 | Loss: 0.00001771
Iteration 61/1000 | Loss: 0.00001771
Iteration 62/1000 | Loss: 0.00001771
Iteration 63/1000 | Loss: 0.00002251
Iteration 64/1000 | Loss: 0.00013389
Iteration 65/1000 | Loss: 0.00003530
Iteration 66/1000 | Loss: 0.00001938
Iteration 67/1000 | Loss: 0.00001755
Iteration 68/1000 | Loss: 0.00001749
Iteration 69/1000 | Loss: 0.00001749
Iteration 70/1000 | Loss: 0.00001749
Iteration 71/1000 | Loss: 0.00001749
Iteration 72/1000 | Loss: 0.00001749
Iteration 73/1000 | Loss: 0.00001748
Iteration 74/1000 | Loss: 0.00001748
Iteration 75/1000 | Loss: 0.00001748
Iteration 76/1000 | Loss: 0.00001750
Iteration 77/1000 | Loss: 0.00001750
Iteration 78/1000 | Loss: 0.00001750
Iteration 79/1000 | Loss: 0.00002719
Iteration 80/1000 | Loss: 0.00001877
Iteration 81/1000 | Loss: 0.00001772
Iteration 82/1000 | Loss: 0.00001772
Iteration 83/1000 | Loss: 0.00002623
Iteration 84/1000 | Loss: 0.00002034
Iteration 85/1000 | Loss: 0.00001751
Iteration 86/1000 | Loss: 0.00002090
Iteration 87/1000 | Loss: 0.00001801
Iteration 88/1000 | Loss: 0.00001735
Iteration 89/1000 | Loss: 0.00001735
Iteration 90/1000 | Loss: 0.00001739
Iteration 91/1000 | Loss: 0.00001739
Iteration 92/1000 | Loss: 0.00001734
Iteration 93/1000 | Loss: 0.00001734
Iteration 94/1000 | Loss: 0.00001734
Iteration 95/1000 | Loss: 0.00001733
Iteration 96/1000 | Loss: 0.00001751
Iteration 97/1000 | Loss: 0.00001732
Iteration 98/1000 | Loss: 0.00001732
Iteration 99/1000 | Loss: 0.00001732
Iteration 100/1000 | Loss: 0.00001732
Iteration 101/1000 | Loss: 0.00001732
Iteration 102/1000 | Loss: 0.00001732
Iteration 103/1000 | Loss: 0.00001732
Iteration 104/1000 | Loss: 0.00001732
Iteration 105/1000 | Loss: 0.00001732
Iteration 106/1000 | Loss: 0.00001732
Iteration 107/1000 | Loss: 0.00001731
Iteration 108/1000 | Loss: 0.00001731
Iteration 109/1000 | Loss: 0.00001731
Iteration 110/1000 | Loss: 0.00001730
Iteration 111/1000 | Loss: 0.00001730
Iteration 112/1000 | Loss: 0.00001975
Iteration 113/1000 | Loss: 0.00001819
Iteration 114/1000 | Loss: 0.00001731
Iteration 115/1000 | Loss: 0.00001725
Iteration 116/1000 | Loss: 0.00001725
Iteration 117/1000 | Loss: 0.00001725
Iteration 118/1000 | Loss: 0.00001725
Iteration 119/1000 | Loss: 0.00001725
Iteration 120/1000 | Loss: 0.00001725
Iteration 121/1000 | Loss: 0.00001724
Iteration 122/1000 | Loss: 0.00001724
Iteration 123/1000 | Loss: 0.00001724
Iteration 124/1000 | Loss: 0.00001724
Iteration 125/1000 | Loss: 0.00001724
Iteration 126/1000 | Loss: 0.00001724
Iteration 127/1000 | Loss: 0.00001724
Iteration 128/1000 | Loss: 0.00001724
Iteration 129/1000 | Loss: 0.00001724
Iteration 130/1000 | Loss: 0.00001724
Iteration 131/1000 | Loss: 0.00001724
Iteration 132/1000 | Loss: 0.00001724
Iteration 133/1000 | Loss: 0.00001724
Iteration 134/1000 | Loss: 0.00001724
Iteration 135/1000 | Loss: 0.00001724
Iteration 136/1000 | Loss: 0.00001724
Iteration 137/1000 | Loss: 0.00001724
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 137. Stopping optimization.
Last 5 losses: [1.724051071505528e-05, 1.724051071505528e-05, 1.724051071505528e-05, 1.724051071505528e-05, 1.724051071505528e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.724051071505528e-05

Optimization complete. Final v2v error: 3.131204843521118 mm

Highest mean error: 14.81908130645752 mm for frame 119

Lowest mean error: 2.4697439670562744 mm for frame 57

Saving results

Total time: 151.43744349479675
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00768757
Iteration 2/25 | Loss: 0.00169625
Iteration 3/25 | Loss: 0.00122879
Iteration 4/25 | Loss: 0.00117800
Iteration 5/25 | Loss: 0.00119992
Iteration 6/25 | Loss: 0.00116452
Iteration 7/25 | Loss: 0.00116623
Iteration 8/25 | Loss: 0.00118661
Iteration 9/25 | Loss: 0.00115306
Iteration 10/25 | Loss: 0.00114942
Iteration 11/25 | Loss: 0.00115021
Iteration 12/25 | Loss: 0.00115212
Iteration 13/25 | Loss: 0.00115325
Iteration 14/25 | Loss: 0.00115251
Iteration 15/25 | Loss: 0.00115029
Iteration 16/25 | Loss: 0.00114732
Iteration 17/25 | Loss: 0.00114438
Iteration 18/25 | Loss: 0.00114402
Iteration 19/25 | Loss: 0.00114401
Iteration 20/25 | Loss: 0.00114400
Iteration 21/25 | Loss: 0.00114400
Iteration 22/25 | Loss: 0.00114400
Iteration 23/25 | Loss: 0.00114400
Iteration 24/25 | Loss: 0.00114400
Iteration 25/25 | Loss: 0.00114400

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.71383083
Iteration 2/25 | Loss: 0.00071549
Iteration 3/25 | Loss: 0.00071545
Iteration 4/25 | Loss: 0.00071545
Iteration 5/25 | Loss: 0.00071545
Iteration 6/25 | Loss: 0.00071545
Iteration 7/25 | Loss: 0.00071545
Iteration 8/25 | Loss: 0.00071545
Iteration 9/25 | Loss: 0.00071545
Iteration 10/25 | Loss: 0.00071545
Iteration 11/25 | Loss: 0.00071545
Iteration 12/25 | Loss: 0.00071545
Iteration 13/25 | Loss: 0.00071545
Iteration 14/25 | Loss: 0.00071545
Iteration 15/25 | Loss: 0.00071545
Iteration 16/25 | Loss: 0.00071545
Iteration 17/25 | Loss: 0.00071545
Iteration 18/25 | Loss: 0.00071545
Iteration 19/25 | Loss: 0.00071545
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0007154497434385121, 0.0007154497434385121, 0.0007154497434385121, 0.0007154497434385121, 0.0007154497434385121]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007154497434385121

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071545
Iteration 2/1000 | Loss: 0.00006635
Iteration 3/1000 | Loss: 0.00003837
Iteration 4/1000 | Loss: 0.00003360
Iteration 5/1000 | Loss: 0.00003185
Iteration 6/1000 | Loss: 0.00003066
Iteration 7/1000 | Loss: 0.00002996
Iteration 8/1000 | Loss: 0.00002940
Iteration 9/1000 | Loss: 0.00002893
Iteration 10/1000 | Loss: 0.00002866
Iteration 11/1000 | Loss: 0.00002840
Iteration 12/1000 | Loss: 0.00002819
Iteration 13/1000 | Loss: 0.00002801
Iteration 14/1000 | Loss: 0.00002791
Iteration 15/1000 | Loss: 0.00002787
Iteration 16/1000 | Loss: 0.00002786
Iteration 17/1000 | Loss: 0.00002783
Iteration 18/1000 | Loss: 0.00002782
Iteration 19/1000 | Loss: 0.00002776
Iteration 20/1000 | Loss: 0.00002776
Iteration 21/1000 | Loss: 0.00002774
Iteration 22/1000 | Loss: 0.00002773
Iteration 23/1000 | Loss: 0.00002773
Iteration 24/1000 | Loss: 0.00002772
Iteration 25/1000 | Loss: 0.00002769
Iteration 26/1000 | Loss: 0.00002765
Iteration 27/1000 | Loss: 0.00002764
Iteration 28/1000 | Loss: 0.00002764
Iteration 29/1000 | Loss: 0.00002763
Iteration 30/1000 | Loss: 0.00002762
Iteration 31/1000 | Loss: 0.00002759
Iteration 32/1000 | Loss: 0.00002755
Iteration 33/1000 | Loss: 0.00002753
Iteration 34/1000 | Loss: 0.00002752
Iteration 35/1000 | Loss: 0.00002752
Iteration 36/1000 | Loss: 0.00002751
Iteration 37/1000 | Loss: 0.00002751
Iteration 38/1000 | Loss: 0.00002751
Iteration 39/1000 | Loss: 0.00002750
Iteration 40/1000 | Loss: 0.00002750
Iteration 41/1000 | Loss: 0.00002749
Iteration 42/1000 | Loss: 0.00002749
Iteration 43/1000 | Loss: 0.00002748
Iteration 44/1000 | Loss: 0.00002748
Iteration 45/1000 | Loss: 0.00002747
Iteration 46/1000 | Loss: 0.00002747
Iteration 47/1000 | Loss: 0.00002745
Iteration 48/1000 | Loss: 0.00002745
Iteration 49/1000 | Loss: 0.00002745
Iteration 50/1000 | Loss: 0.00002744
Iteration 51/1000 | Loss: 0.00002744
Iteration 52/1000 | Loss: 0.00002744
Iteration 53/1000 | Loss: 0.00002743
Iteration 54/1000 | Loss: 0.00002743
Iteration 55/1000 | Loss: 0.00002743
Iteration 56/1000 | Loss: 0.00002742
Iteration 57/1000 | Loss: 0.00002742
Iteration 58/1000 | Loss: 0.00002742
Iteration 59/1000 | Loss: 0.00002741
Iteration 60/1000 | Loss: 0.00002741
Iteration 61/1000 | Loss: 0.00002741
Iteration 62/1000 | Loss: 0.00002741
Iteration 63/1000 | Loss: 0.00002741
Iteration 64/1000 | Loss: 0.00002740
Iteration 65/1000 | Loss: 0.00002740
Iteration 66/1000 | Loss: 0.00002740
Iteration 67/1000 | Loss: 0.00002740
Iteration 68/1000 | Loss: 0.00002740
Iteration 69/1000 | Loss: 0.00002740
Iteration 70/1000 | Loss: 0.00002739
Iteration 71/1000 | Loss: 0.00002739
Iteration 72/1000 | Loss: 0.00002739
Iteration 73/1000 | Loss: 0.00002738
Iteration 74/1000 | Loss: 0.00002738
Iteration 75/1000 | Loss: 0.00002738
Iteration 76/1000 | Loss: 0.00002737
Iteration 77/1000 | Loss: 0.00002737
Iteration 78/1000 | Loss: 0.00002737
Iteration 79/1000 | Loss: 0.00002737
Iteration 80/1000 | Loss: 0.00002736
Iteration 81/1000 | Loss: 0.00002736
Iteration 82/1000 | Loss: 0.00002736
Iteration 83/1000 | Loss: 0.00002736
Iteration 84/1000 | Loss: 0.00002736
Iteration 85/1000 | Loss: 0.00002736
Iteration 86/1000 | Loss: 0.00002736
Iteration 87/1000 | Loss: 0.00002735
Iteration 88/1000 | Loss: 0.00002735
Iteration 89/1000 | Loss: 0.00002735
Iteration 90/1000 | Loss: 0.00002735
Iteration 91/1000 | Loss: 0.00002735
Iteration 92/1000 | Loss: 0.00002735
Iteration 93/1000 | Loss: 0.00002734
Iteration 94/1000 | Loss: 0.00002734
Iteration 95/1000 | Loss: 0.00002734
Iteration 96/1000 | Loss: 0.00002733
Iteration 97/1000 | Loss: 0.00002733
Iteration 98/1000 | Loss: 0.00002733
Iteration 99/1000 | Loss: 0.00002733
Iteration 100/1000 | Loss: 0.00002733
Iteration 101/1000 | Loss: 0.00002733
Iteration 102/1000 | Loss: 0.00002733
Iteration 103/1000 | Loss: 0.00002732
Iteration 104/1000 | Loss: 0.00002732
Iteration 105/1000 | Loss: 0.00002732
Iteration 106/1000 | Loss: 0.00002731
Iteration 107/1000 | Loss: 0.00002731
Iteration 108/1000 | Loss: 0.00002731
Iteration 109/1000 | Loss: 0.00002731
Iteration 110/1000 | Loss: 0.00002730
Iteration 111/1000 | Loss: 0.00002730
Iteration 112/1000 | Loss: 0.00002730
Iteration 113/1000 | Loss: 0.00002730
Iteration 114/1000 | Loss: 0.00002730
Iteration 115/1000 | Loss: 0.00002730
Iteration 116/1000 | Loss: 0.00002729
Iteration 117/1000 | Loss: 0.00002729
Iteration 118/1000 | Loss: 0.00002729
Iteration 119/1000 | Loss: 0.00002729
Iteration 120/1000 | Loss: 0.00002729
Iteration 121/1000 | Loss: 0.00002729
Iteration 122/1000 | Loss: 0.00002729
Iteration 123/1000 | Loss: 0.00002728
Iteration 124/1000 | Loss: 0.00002728
Iteration 125/1000 | Loss: 0.00002728
Iteration 126/1000 | Loss: 0.00002727
Iteration 127/1000 | Loss: 0.00002727
Iteration 128/1000 | Loss: 0.00002727
Iteration 129/1000 | Loss: 0.00002727
Iteration 130/1000 | Loss: 0.00002727
Iteration 131/1000 | Loss: 0.00002726
Iteration 132/1000 | Loss: 0.00002726
Iteration 133/1000 | Loss: 0.00002726
Iteration 134/1000 | Loss: 0.00002726
Iteration 135/1000 | Loss: 0.00002726
Iteration 136/1000 | Loss: 0.00002726
Iteration 137/1000 | Loss: 0.00002725
Iteration 138/1000 | Loss: 0.00002725
Iteration 139/1000 | Loss: 0.00002725
Iteration 140/1000 | Loss: 0.00002725
Iteration 141/1000 | Loss: 0.00002725
Iteration 142/1000 | Loss: 0.00002725
Iteration 143/1000 | Loss: 0.00002725
Iteration 144/1000 | Loss: 0.00002724
Iteration 145/1000 | Loss: 0.00002724
Iteration 146/1000 | Loss: 0.00002724
Iteration 147/1000 | Loss: 0.00002724
Iteration 148/1000 | Loss: 0.00002723
Iteration 149/1000 | Loss: 0.00002723
Iteration 150/1000 | Loss: 0.00002723
Iteration 151/1000 | Loss: 0.00002723
Iteration 152/1000 | Loss: 0.00002723
Iteration 153/1000 | Loss: 0.00002723
Iteration 154/1000 | Loss: 0.00002723
Iteration 155/1000 | Loss: 0.00002723
Iteration 156/1000 | Loss: 0.00002723
Iteration 157/1000 | Loss: 0.00002723
Iteration 158/1000 | Loss: 0.00002723
Iteration 159/1000 | Loss: 0.00002723
Iteration 160/1000 | Loss: 0.00002723
Iteration 161/1000 | Loss: 0.00002723
Iteration 162/1000 | Loss: 0.00002723
Iteration 163/1000 | Loss: 0.00002723
Iteration 164/1000 | Loss: 0.00002723
Iteration 165/1000 | Loss: 0.00002723
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [2.7225019948673435e-05, 2.7225019948673435e-05, 2.7225019948673435e-05, 2.7225019948673435e-05, 2.7225019948673435e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7225019948673435e-05

Optimization complete. Final v2v error: 4.2118120193481445 mm

Highest mean error: 9.898845672607422 mm for frame 20

Lowest mean error: 3.2732512950897217 mm for frame 90

Saving results

Total time: 76.39764761924744
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00812911
Iteration 2/25 | Loss: 0.00137983
Iteration 3/25 | Loss: 0.00111313
Iteration 4/25 | Loss: 0.00108376
Iteration 5/25 | Loss: 0.00107737
Iteration 6/25 | Loss: 0.00107514
Iteration 7/25 | Loss: 0.00107499
Iteration 8/25 | Loss: 0.00107499
Iteration 9/25 | Loss: 0.00107499
Iteration 10/25 | Loss: 0.00107499
Iteration 11/25 | Loss: 0.00107499
Iteration 12/25 | Loss: 0.00107499
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001074989209882915, 0.001074989209882915, 0.001074989209882915, 0.001074989209882915, 0.001074989209882915]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001074989209882915

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.44166827
Iteration 2/25 | Loss: 0.00071455
Iteration 3/25 | Loss: 0.00071455
Iteration 4/25 | Loss: 0.00071454
Iteration 5/25 | Loss: 0.00071454
Iteration 6/25 | Loss: 0.00071454
Iteration 7/25 | Loss: 0.00071454
Iteration 8/25 | Loss: 0.00071454
Iteration 9/25 | Loss: 0.00071454
Iteration 10/25 | Loss: 0.00071454
Iteration 11/25 | Loss: 0.00071454
Iteration 12/25 | Loss: 0.00071454
Iteration 13/25 | Loss: 0.00071454
Iteration 14/25 | Loss: 0.00071454
Iteration 15/25 | Loss: 0.00071454
Iteration 16/25 | Loss: 0.00071454
Iteration 17/25 | Loss: 0.00071454
Iteration 18/25 | Loss: 0.00071454
Iteration 19/25 | Loss: 0.00071454
Iteration 20/25 | Loss: 0.00071454
Iteration 21/25 | Loss: 0.00071454
Iteration 22/25 | Loss: 0.00071454
Iteration 23/25 | Loss: 0.00071454
Iteration 24/25 | Loss: 0.00071454
Iteration 25/25 | Loss: 0.00071454

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071454
Iteration 2/1000 | Loss: 0.00005898
Iteration 3/1000 | Loss: 0.00002650
Iteration 4/1000 | Loss: 0.00002208
Iteration 5/1000 | Loss: 0.00002032
Iteration 6/1000 | Loss: 0.00001953
Iteration 7/1000 | Loss: 0.00001889
Iteration 8/1000 | Loss: 0.00001849
Iteration 9/1000 | Loss: 0.00001817
Iteration 10/1000 | Loss: 0.00001799
Iteration 11/1000 | Loss: 0.00001777
Iteration 12/1000 | Loss: 0.00001768
Iteration 13/1000 | Loss: 0.00001758
Iteration 14/1000 | Loss: 0.00001756
Iteration 15/1000 | Loss: 0.00001756
Iteration 16/1000 | Loss: 0.00001755
Iteration 17/1000 | Loss: 0.00001748
Iteration 18/1000 | Loss: 0.00001745
Iteration 19/1000 | Loss: 0.00001744
Iteration 20/1000 | Loss: 0.00001744
Iteration 21/1000 | Loss: 0.00001743
Iteration 22/1000 | Loss: 0.00001742
Iteration 23/1000 | Loss: 0.00001742
Iteration 24/1000 | Loss: 0.00001741
Iteration 25/1000 | Loss: 0.00001740
Iteration 26/1000 | Loss: 0.00001740
Iteration 27/1000 | Loss: 0.00001740
Iteration 28/1000 | Loss: 0.00001739
Iteration 29/1000 | Loss: 0.00001739
Iteration 30/1000 | Loss: 0.00001738
Iteration 31/1000 | Loss: 0.00001738
Iteration 32/1000 | Loss: 0.00001738
Iteration 33/1000 | Loss: 0.00001737
Iteration 34/1000 | Loss: 0.00001737
Iteration 35/1000 | Loss: 0.00001737
Iteration 36/1000 | Loss: 0.00001736
Iteration 37/1000 | Loss: 0.00001736
Iteration 38/1000 | Loss: 0.00001736
Iteration 39/1000 | Loss: 0.00001736
Iteration 40/1000 | Loss: 0.00001736
Iteration 41/1000 | Loss: 0.00001736
Iteration 42/1000 | Loss: 0.00001736
Iteration 43/1000 | Loss: 0.00001735
Iteration 44/1000 | Loss: 0.00001735
Iteration 45/1000 | Loss: 0.00001735
Iteration 46/1000 | Loss: 0.00001735
Iteration 47/1000 | Loss: 0.00001735
Iteration 48/1000 | Loss: 0.00001735
Iteration 49/1000 | Loss: 0.00001735
Iteration 50/1000 | Loss: 0.00001734
Iteration 51/1000 | Loss: 0.00001734
Iteration 52/1000 | Loss: 0.00001734
Iteration 53/1000 | Loss: 0.00001734
Iteration 54/1000 | Loss: 0.00001733
Iteration 55/1000 | Loss: 0.00001733
Iteration 56/1000 | Loss: 0.00001732
Iteration 57/1000 | Loss: 0.00001732
Iteration 58/1000 | Loss: 0.00001731
Iteration 59/1000 | Loss: 0.00001731
Iteration 60/1000 | Loss: 0.00001730
Iteration 61/1000 | Loss: 0.00001730
Iteration 62/1000 | Loss: 0.00001730
Iteration 63/1000 | Loss: 0.00001729
Iteration 64/1000 | Loss: 0.00001728
Iteration 65/1000 | Loss: 0.00001727
Iteration 66/1000 | Loss: 0.00001727
Iteration 67/1000 | Loss: 0.00001727
Iteration 68/1000 | Loss: 0.00001727
Iteration 69/1000 | Loss: 0.00001726
Iteration 70/1000 | Loss: 0.00001726
Iteration 71/1000 | Loss: 0.00001726
Iteration 72/1000 | Loss: 0.00001726
Iteration 73/1000 | Loss: 0.00001726
Iteration 74/1000 | Loss: 0.00001725
Iteration 75/1000 | Loss: 0.00001725
Iteration 76/1000 | Loss: 0.00001725
Iteration 77/1000 | Loss: 0.00001725
Iteration 78/1000 | Loss: 0.00001724
Iteration 79/1000 | Loss: 0.00001724
Iteration 80/1000 | Loss: 0.00001724
Iteration 81/1000 | Loss: 0.00001724
Iteration 82/1000 | Loss: 0.00001724
Iteration 83/1000 | Loss: 0.00001724
Iteration 84/1000 | Loss: 0.00001724
Iteration 85/1000 | Loss: 0.00001723
Iteration 86/1000 | Loss: 0.00001723
Iteration 87/1000 | Loss: 0.00001723
Iteration 88/1000 | Loss: 0.00001723
Iteration 89/1000 | Loss: 0.00001722
Iteration 90/1000 | Loss: 0.00001722
Iteration 91/1000 | Loss: 0.00001722
Iteration 92/1000 | Loss: 0.00001722
Iteration 93/1000 | Loss: 0.00001722
Iteration 94/1000 | Loss: 0.00001721
Iteration 95/1000 | Loss: 0.00001721
Iteration 96/1000 | Loss: 0.00001721
Iteration 97/1000 | Loss: 0.00001721
Iteration 98/1000 | Loss: 0.00001721
Iteration 99/1000 | Loss: 0.00001721
Iteration 100/1000 | Loss: 0.00001721
Iteration 101/1000 | Loss: 0.00001721
Iteration 102/1000 | Loss: 0.00001721
Iteration 103/1000 | Loss: 0.00001721
Iteration 104/1000 | Loss: 0.00001721
Iteration 105/1000 | Loss: 0.00001721
Iteration 106/1000 | Loss: 0.00001721
Iteration 107/1000 | Loss: 0.00001721
Iteration 108/1000 | Loss: 0.00001721
Iteration 109/1000 | Loss: 0.00001721
Iteration 110/1000 | Loss: 0.00001721
Iteration 111/1000 | Loss: 0.00001721
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 111. Stopping optimization.
Last 5 losses: [1.721029548207298e-05, 1.721029548207298e-05, 1.721029548207298e-05, 1.721029548207298e-05, 1.721029548207298e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.721029548207298e-05

Optimization complete. Final v2v error: 3.57791805267334 mm

Highest mean error: 4.345902442932129 mm for frame 76

Lowest mean error: 3.0500552654266357 mm for frame 111

Saving results

Total time: 39.81388854980469
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00837224
Iteration 2/25 | Loss: 0.00123198
Iteration 3/25 | Loss: 0.00110110
Iteration 4/25 | Loss: 0.00107423
Iteration 5/25 | Loss: 0.00107044
Iteration 6/25 | Loss: 0.00107044
Iteration 7/25 | Loss: 0.00107044
Iteration 8/25 | Loss: 0.00107044
Iteration 9/25 | Loss: 0.00107044
Iteration 10/25 | Loss: 0.00107044
Iteration 11/25 | Loss: 0.00107044
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001070435275323689, 0.001070435275323689, 0.001070435275323689, 0.001070435275323689, 0.001070435275323689]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001070435275323689

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.61553717
Iteration 2/25 | Loss: 0.00052142
Iteration 3/25 | Loss: 0.00052142
Iteration 4/25 | Loss: 0.00052142
Iteration 5/25 | Loss: 0.00052142
Iteration 6/25 | Loss: 0.00052141
Iteration 7/25 | Loss: 0.00052141
Iteration 8/25 | Loss: 0.00052141
Iteration 9/25 | Loss: 0.00052141
Iteration 10/25 | Loss: 0.00052141
Iteration 11/25 | Loss: 0.00052141
Iteration 12/25 | Loss: 0.00052141
Iteration 13/25 | Loss: 0.00052141
Iteration 14/25 | Loss: 0.00052141
Iteration 15/25 | Loss: 0.00052141
Iteration 16/25 | Loss: 0.00052141
Iteration 17/25 | Loss: 0.00052141
Iteration 18/25 | Loss: 0.00052141
Iteration 19/25 | Loss: 0.00052141
Iteration 20/25 | Loss: 0.00052141
Iteration 21/25 | Loss: 0.00052141
Iteration 22/25 | Loss: 0.00052141
Iteration 23/25 | Loss: 0.00052141
Iteration 24/25 | Loss: 0.00052141
Iteration 25/25 | Loss: 0.00052141

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052141
Iteration 2/1000 | Loss: 0.00004249
Iteration 3/1000 | Loss: 0.00002942
Iteration 4/1000 | Loss: 0.00002614
Iteration 5/1000 | Loss: 0.00002489
Iteration 6/1000 | Loss: 0.00002418
Iteration 7/1000 | Loss: 0.00002365
Iteration 8/1000 | Loss: 0.00002309
Iteration 9/1000 | Loss: 0.00002282
Iteration 10/1000 | Loss: 0.00002258
Iteration 11/1000 | Loss: 0.00002252
Iteration 12/1000 | Loss: 0.00002252
Iteration 13/1000 | Loss: 0.00002246
Iteration 14/1000 | Loss: 0.00002240
Iteration 15/1000 | Loss: 0.00002239
Iteration 16/1000 | Loss: 0.00002227
Iteration 17/1000 | Loss: 0.00002224
Iteration 18/1000 | Loss: 0.00002223
Iteration 19/1000 | Loss: 0.00002223
Iteration 20/1000 | Loss: 0.00002222
Iteration 21/1000 | Loss: 0.00002222
Iteration 22/1000 | Loss: 0.00002221
Iteration 23/1000 | Loss: 0.00002221
Iteration 24/1000 | Loss: 0.00002221
Iteration 25/1000 | Loss: 0.00002220
Iteration 26/1000 | Loss: 0.00002220
Iteration 27/1000 | Loss: 0.00002220
Iteration 28/1000 | Loss: 0.00002220
Iteration 29/1000 | Loss: 0.00002220
Iteration 30/1000 | Loss: 0.00002220
Iteration 31/1000 | Loss: 0.00002220
Iteration 32/1000 | Loss: 0.00002219
Iteration 33/1000 | Loss: 0.00002218
Iteration 34/1000 | Loss: 0.00002217
Iteration 35/1000 | Loss: 0.00002217
Iteration 36/1000 | Loss: 0.00002217
Iteration 37/1000 | Loss: 0.00002217
Iteration 38/1000 | Loss: 0.00002217
Iteration 39/1000 | Loss: 0.00002217
Iteration 40/1000 | Loss: 0.00002217
Iteration 41/1000 | Loss: 0.00002217
Iteration 42/1000 | Loss: 0.00002217
Iteration 43/1000 | Loss: 0.00002217
Iteration 44/1000 | Loss: 0.00002217
Iteration 45/1000 | Loss: 0.00002216
Iteration 46/1000 | Loss: 0.00002216
Iteration 47/1000 | Loss: 0.00002216
Iteration 48/1000 | Loss: 0.00002214
Iteration 49/1000 | Loss: 0.00002214
Iteration 50/1000 | Loss: 0.00002214
Iteration 51/1000 | Loss: 0.00002214
Iteration 52/1000 | Loss: 0.00002214
Iteration 53/1000 | Loss: 0.00002214
Iteration 54/1000 | Loss: 0.00002214
Iteration 55/1000 | Loss: 0.00002213
Iteration 56/1000 | Loss: 0.00002213
Iteration 57/1000 | Loss: 0.00002213
Iteration 58/1000 | Loss: 0.00002213
Iteration 59/1000 | Loss: 0.00002213
Iteration 60/1000 | Loss: 0.00002213
Iteration 61/1000 | Loss: 0.00002213
Iteration 62/1000 | Loss: 0.00002212
Iteration 63/1000 | Loss: 0.00002212
Iteration 64/1000 | Loss: 0.00002212
Iteration 65/1000 | Loss: 0.00002211
Iteration 66/1000 | Loss: 0.00002211
Iteration 67/1000 | Loss: 0.00002211
Iteration 68/1000 | Loss: 0.00002211
Iteration 69/1000 | Loss: 0.00002211
Iteration 70/1000 | Loss: 0.00002211
Iteration 71/1000 | Loss: 0.00002210
Iteration 72/1000 | Loss: 0.00002210
Iteration 73/1000 | Loss: 0.00002210
Iteration 74/1000 | Loss: 0.00002210
Iteration 75/1000 | Loss: 0.00002210
Iteration 76/1000 | Loss: 0.00002209
Iteration 77/1000 | Loss: 0.00002209
Iteration 78/1000 | Loss: 0.00002209
Iteration 79/1000 | Loss: 0.00002209
Iteration 80/1000 | Loss: 0.00002208
Iteration 81/1000 | Loss: 0.00002208
Iteration 82/1000 | Loss: 0.00002208
Iteration 83/1000 | Loss: 0.00002208
Iteration 84/1000 | Loss: 0.00002208
Iteration 85/1000 | Loss: 0.00002208
Iteration 86/1000 | Loss: 0.00002208
Iteration 87/1000 | Loss: 0.00002208
Iteration 88/1000 | Loss: 0.00002207
Iteration 89/1000 | Loss: 0.00002207
Iteration 90/1000 | Loss: 0.00002206
Iteration 91/1000 | Loss: 0.00002206
Iteration 92/1000 | Loss: 0.00002206
Iteration 93/1000 | Loss: 0.00002206
Iteration 94/1000 | Loss: 0.00002206
Iteration 95/1000 | Loss: 0.00002206
Iteration 96/1000 | Loss: 0.00002205
Iteration 97/1000 | Loss: 0.00002205
Iteration 98/1000 | Loss: 0.00002204
Iteration 99/1000 | Loss: 0.00002204
Iteration 100/1000 | Loss: 0.00002204
Iteration 101/1000 | Loss: 0.00002204
Iteration 102/1000 | Loss: 0.00002204
Iteration 103/1000 | Loss: 0.00002204
Iteration 104/1000 | Loss: 0.00002203
Iteration 105/1000 | Loss: 0.00002203
Iteration 106/1000 | Loss: 0.00002203
Iteration 107/1000 | Loss: 0.00002202
Iteration 108/1000 | Loss: 0.00002202
Iteration 109/1000 | Loss: 0.00002202
Iteration 110/1000 | Loss: 0.00002202
Iteration 111/1000 | Loss: 0.00002202
Iteration 112/1000 | Loss: 0.00002202
Iteration 113/1000 | Loss: 0.00002202
Iteration 114/1000 | Loss: 0.00002202
Iteration 115/1000 | Loss: 0.00002201
Iteration 116/1000 | Loss: 0.00002201
Iteration 117/1000 | Loss: 0.00002201
Iteration 118/1000 | Loss: 0.00002201
Iteration 119/1000 | Loss: 0.00002201
Iteration 120/1000 | Loss: 0.00002201
Iteration 121/1000 | Loss: 0.00002201
Iteration 122/1000 | Loss: 0.00002201
Iteration 123/1000 | Loss: 0.00002201
Iteration 124/1000 | Loss: 0.00002201
Iteration 125/1000 | Loss: 0.00002200
Iteration 126/1000 | Loss: 0.00002200
Iteration 127/1000 | Loss: 0.00002200
Iteration 128/1000 | Loss: 0.00002200
Iteration 129/1000 | Loss: 0.00002200
Iteration 130/1000 | Loss: 0.00002200
Iteration 131/1000 | Loss: 0.00002200
Iteration 132/1000 | Loss: 0.00002200
Iteration 133/1000 | Loss: 0.00002200
Iteration 134/1000 | Loss: 0.00002200
Iteration 135/1000 | Loss: 0.00002200
Iteration 136/1000 | Loss: 0.00002200
Iteration 137/1000 | Loss: 0.00002200
Iteration 138/1000 | Loss: 0.00002200
Iteration 139/1000 | Loss: 0.00002200
Iteration 140/1000 | Loss: 0.00002200
Iteration 141/1000 | Loss: 0.00002200
Iteration 142/1000 | Loss: 0.00002200
Iteration 143/1000 | Loss: 0.00002200
Iteration 144/1000 | Loss: 0.00002200
Iteration 145/1000 | Loss: 0.00002200
Iteration 146/1000 | Loss: 0.00002200
Iteration 147/1000 | Loss: 0.00002200
Iteration 148/1000 | Loss: 0.00002200
Iteration 149/1000 | Loss: 0.00002200
Iteration 150/1000 | Loss: 0.00002200
Iteration 151/1000 | Loss: 0.00002200
Iteration 152/1000 | Loss: 0.00002200
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 152. Stopping optimization.
Last 5 losses: [2.2001919205649756e-05, 2.2001919205649756e-05, 2.2001919205649756e-05, 2.2001919205649756e-05, 2.2001919205649756e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2001919205649756e-05

Optimization complete. Final v2v error: 3.9269630908966064 mm

Highest mean error: 4.262556552886963 mm for frame 64

Lowest mean error: 3.527439832687378 mm for frame 197

Saving results

Total time: 35.30977463722229
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00880965
Iteration 2/25 | Loss: 0.00114959
Iteration 3/25 | Loss: 0.00097804
Iteration 4/25 | Loss: 0.00095863
Iteration 5/25 | Loss: 0.00095409
Iteration 6/25 | Loss: 0.00095306
Iteration 7/25 | Loss: 0.00095305
Iteration 8/25 | Loss: 0.00095305
Iteration 9/25 | Loss: 0.00095305
Iteration 10/25 | Loss: 0.00095305
Iteration 11/25 | Loss: 0.00095305
Iteration 12/25 | Loss: 0.00095305
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009530539973638952, 0.0009530539973638952, 0.0009530539973638952, 0.0009530539973638952, 0.0009530539973638952]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009530539973638952

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42469108
Iteration 2/25 | Loss: 0.00042757
Iteration 3/25 | Loss: 0.00042755
Iteration 4/25 | Loss: 0.00042755
Iteration 5/25 | Loss: 0.00042754
Iteration 6/25 | Loss: 0.00042754
Iteration 7/25 | Loss: 0.00042754
Iteration 8/25 | Loss: 0.00042754
Iteration 9/25 | Loss: 0.00042754
Iteration 10/25 | Loss: 0.00042754
Iteration 11/25 | Loss: 0.00042754
Iteration 12/25 | Loss: 0.00042754
Iteration 13/25 | Loss: 0.00042754
Iteration 14/25 | Loss: 0.00042754
Iteration 15/25 | Loss: 0.00042754
Iteration 16/25 | Loss: 0.00042754
Iteration 17/25 | Loss: 0.00042754
Iteration 18/25 | Loss: 0.00042754
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0004275434766896069, 0.0004275434766896069, 0.0004275434766896069, 0.0004275434766896069, 0.0004275434766896069]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004275434766896069

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042754
Iteration 2/1000 | Loss: 0.00003053
Iteration 3/1000 | Loss: 0.00001602
Iteration 4/1000 | Loss: 0.00001292
Iteration 5/1000 | Loss: 0.00001166
Iteration 6/1000 | Loss: 0.00001097
Iteration 7/1000 | Loss: 0.00001038
Iteration 8/1000 | Loss: 0.00001009
Iteration 9/1000 | Loss: 0.00000999
Iteration 10/1000 | Loss: 0.00000983
Iteration 11/1000 | Loss: 0.00000978
Iteration 12/1000 | Loss: 0.00000975
Iteration 13/1000 | Loss: 0.00000973
Iteration 14/1000 | Loss: 0.00000960
Iteration 15/1000 | Loss: 0.00000952
Iteration 16/1000 | Loss: 0.00000949
Iteration 17/1000 | Loss: 0.00000945
Iteration 18/1000 | Loss: 0.00000943
Iteration 19/1000 | Loss: 0.00000943
Iteration 20/1000 | Loss: 0.00000943
Iteration 21/1000 | Loss: 0.00000943
Iteration 22/1000 | Loss: 0.00000942
Iteration 23/1000 | Loss: 0.00000941
Iteration 24/1000 | Loss: 0.00000936
Iteration 25/1000 | Loss: 0.00000936
Iteration 26/1000 | Loss: 0.00000936
Iteration 27/1000 | Loss: 0.00000933
Iteration 28/1000 | Loss: 0.00000932
Iteration 29/1000 | Loss: 0.00000932
Iteration 30/1000 | Loss: 0.00000931
Iteration 31/1000 | Loss: 0.00000931
Iteration 32/1000 | Loss: 0.00000931
Iteration 33/1000 | Loss: 0.00000930
Iteration 34/1000 | Loss: 0.00000930
Iteration 35/1000 | Loss: 0.00000930
Iteration 36/1000 | Loss: 0.00000930
Iteration 37/1000 | Loss: 0.00000930
Iteration 38/1000 | Loss: 0.00000930
Iteration 39/1000 | Loss: 0.00000929
Iteration 40/1000 | Loss: 0.00000929
Iteration 41/1000 | Loss: 0.00000928
Iteration 42/1000 | Loss: 0.00000928
Iteration 43/1000 | Loss: 0.00000928
Iteration 44/1000 | Loss: 0.00000927
Iteration 45/1000 | Loss: 0.00000927
Iteration 46/1000 | Loss: 0.00000927
Iteration 47/1000 | Loss: 0.00000927
Iteration 48/1000 | Loss: 0.00000927
Iteration 49/1000 | Loss: 0.00000926
Iteration 50/1000 | Loss: 0.00000926
Iteration 51/1000 | Loss: 0.00000925
Iteration 52/1000 | Loss: 0.00000925
Iteration 53/1000 | Loss: 0.00000925
Iteration 54/1000 | Loss: 0.00000925
Iteration 55/1000 | Loss: 0.00000924
Iteration 56/1000 | Loss: 0.00000924
Iteration 57/1000 | Loss: 0.00000924
Iteration 58/1000 | Loss: 0.00000924
Iteration 59/1000 | Loss: 0.00000924
Iteration 60/1000 | Loss: 0.00000924
Iteration 61/1000 | Loss: 0.00000924
Iteration 62/1000 | Loss: 0.00000924
Iteration 63/1000 | Loss: 0.00000924
Iteration 64/1000 | Loss: 0.00000924
Iteration 65/1000 | Loss: 0.00000924
Iteration 66/1000 | Loss: 0.00000924
Iteration 67/1000 | Loss: 0.00000923
Iteration 68/1000 | Loss: 0.00000923
Iteration 69/1000 | Loss: 0.00000923
Iteration 70/1000 | Loss: 0.00000923
Iteration 71/1000 | Loss: 0.00000922
Iteration 72/1000 | Loss: 0.00000922
Iteration 73/1000 | Loss: 0.00000922
Iteration 74/1000 | Loss: 0.00000922
Iteration 75/1000 | Loss: 0.00000921
Iteration 76/1000 | Loss: 0.00000921
Iteration 77/1000 | Loss: 0.00000921
Iteration 78/1000 | Loss: 0.00000921
Iteration 79/1000 | Loss: 0.00000921
Iteration 80/1000 | Loss: 0.00000921
Iteration 81/1000 | Loss: 0.00000921
Iteration 82/1000 | Loss: 0.00000921
Iteration 83/1000 | Loss: 0.00000921
Iteration 84/1000 | Loss: 0.00000921
Iteration 85/1000 | Loss: 0.00000920
Iteration 86/1000 | Loss: 0.00000920
Iteration 87/1000 | Loss: 0.00000920
Iteration 88/1000 | Loss: 0.00000920
Iteration 89/1000 | Loss: 0.00000920
Iteration 90/1000 | Loss: 0.00000920
Iteration 91/1000 | Loss: 0.00000920
Iteration 92/1000 | Loss: 0.00000920
Iteration 93/1000 | Loss: 0.00000920
Iteration 94/1000 | Loss: 0.00000919
Iteration 95/1000 | Loss: 0.00000919
Iteration 96/1000 | Loss: 0.00000919
Iteration 97/1000 | Loss: 0.00000919
Iteration 98/1000 | Loss: 0.00000919
Iteration 99/1000 | Loss: 0.00000919
Iteration 100/1000 | Loss: 0.00000919
Iteration 101/1000 | Loss: 0.00000919
Iteration 102/1000 | Loss: 0.00000919
Iteration 103/1000 | Loss: 0.00000919
Iteration 104/1000 | Loss: 0.00000919
Iteration 105/1000 | Loss: 0.00000919
Iteration 106/1000 | Loss: 0.00000919
Iteration 107/1000 | Loss: 0.00000919
Iteration 108/1000 | Loss: 0.00000919
Iteration 109/1000 | Loss: 0.00000919
Iteration 110/1000 | Loss: 0.00000919
Iteration 111/1000 | Loss: 0.00000919
Iteration 112/1000 | Loss: 0.00000919
Iteration 113/1000 | Loss: 0.00000919
Iteration 114/1000 | Loss: 0.00000919
Iteration 115/1000 | Loss: 0.00000919
Iteration 116/1000 | Loss: 0.00000919
Iteration 117/1000 | Loss: 0.00000919
Iteration 118/1000 | Loss: 0.00000919
Iteration 119/1000 | Loss: 0.00000919
Iteration 120/1000 | Loss: 0.00000919
Iteration 121/1000 | Loss: 0.00000919
Iteration 122/1000 | Loss: 0.00000919
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [9.190118362312205e-06, 9.190118362312205e-06, 9.190118362312205e-06, 9.190118362312205e-06, 9.190118362312205e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.190118362312205e-06

Optimization complete. Final v2v error: 2.624023675918579 mm

Highest mean error: 2.8338334560394287 mm for frame 68

Lowest mean error: 2.3662357330322266 mm for frame 140

Saving results

Total time: 33.51209115982056
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_32_nl_5553/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_32_nl_5553/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468132
Iteration 2/25 | Loss: 0.00113470
Iteration 3/25 | Loss: 0.00101358
Iteration 4/25 | Loss: 0.00098687
Iteration 5/25 | Loss: 0.00098078
Iteration 6/25 | Loss: 0.00097961
Iteration 7/25 | Loss: 0.00097961
Iteration 8/25 | Loss: 0.00097961
Iteration 9/25 | Loss: 0.00097961
Iteration 10/25 | Loss: 0.00097961
Iteration 11/25 | Loss: 0.00097961
Iteration 12/25 | Loss: 0.00097961
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009796135127544403, 0.0009796135127544403, 0.0009796135127544403, 0.0009796135127544403, 0.0009796135127544403]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009796135127544403

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.25266218
Iteration 2/25 | Loss: 0.00047508
Iteration 3/25 | Loss: 0.00047506
Iteration 4/25 | Loss: 0.00047506
Iteration 5/25 | Loss: 0.00047505
Iteration 6/25 | Loss: 0.00047505
Iteration 7/25 | Loss: 0.00047505
Iteration 8/25 | Loss: 0.00047505
Iteration 9/25 | Loss: 0.00047505
Iteration 10/25 | Loss: 0.00047505
Iteration 11/25 | Loss: 0.00047505
Iteration 12/25 | Loss: 0.00047505
Iteration 13/25 | Loss: 0.00047505
Iteration 14/25 | Loss: 0.00047505
Iteration 15/25 | Loss: 0.00047505
Iteration 16/25 | Loss: 0.00047505
Iteration 17/25 | Loss: 0.00047505
Iteration 18/25 | Loss: 0.00047505
Iteration 19/25 | Loss: 0.00047505
Iteration 20/25 | Loss: 0.00047505
Iteration 21/25 | Loss: 0.00047505
Iteration 22/25 | Loss: 0.00047505
Iteration 23/25 | Loss: 0.00047505
Iteration 24/25 | Loss: 0.00047505
Iteration 25/25 | Loss: 0.00047505

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047505
Iteration 2/1000 | Loss: 0.00003037
Iteration 3/1000 | Loss: 0.00001940
Iteration 4/1000 | Loss: 0.00001670
Iteration 5/1000 | Loss: 0.00001586
Iteration 6/1000 | Loss: 0.00001529
Iteration 7/1000 | Loss: 0.00001477
Iteration 8/1000 | Loss: 0.00001443
Iteration 9/1000 | Loss: 0.00001413
Iteration 10/1000 | Loss: 0.00001398
Iteration 11/1000 | Loss: 0.00001394
Iteration 12/1000 | Loss: 0.00001392
Iteration 13/1000 | Loss: 0.00001391
Iteration 14/1000 | Loss: 0.00001391
Iteration 15/1000 | Loss: 0.00001390
Iteration 16/1000 | Loss: 0.00001389
Iteration 17/1000 | Loss: 0.00001387
Iteration 18/1000 | Loss: 0.00001387
Iteration 19/1000 | Loss: 0.00001386
Iteration 20/1000 | Loss: 0.00001386
Iteration 21/1000 | Loss: 0.00001385
Iteration 22/1000 | Loss: 0.00001385
Iteration 23/1000 | Loss: 0.00001384
Iteration 24/1000 | Loss: 0.00001384
Iteration 25/1000 | Loss: 0.00001383
Iteration 26/1000 | Loss: 0.00001383
Iteration 27/1000 | Loss: 0.00001382
Iteration 28/1000 | Loss: 0.00001382
Iteration 29/1000 | Loss: 0.00001381
Iteration 30/1000 | Loss: 0.00001380
Iteration 31/1000 | Loss: 0.00001380
Iteration 32/1000 | Loss: 0.00001375
Iteration 33/1000 | Loss: 0.00001375
Iteration 34/1000 | Loss: 0.00001375
Iteration 35/1000 | Loss: 0.00001375
Iteration 36/1000 | Loss: 0.00001375
Iteration 37/1000 | Loss: 0.00001374
Iteration 38/1000 | Loss: 0.00001373
Iteration 39/1000 | Loss: 0.00001373
Iteration 40/1000 | Loss: 0.00001373
Iteration 41/1000 | Loss: 0.00001371
Iteration 42/1000 | Loss: 0.00001371
Iteration 43/1000 | Loss: 0.00001371
Iteration 44/1000 | Loss: 0.00001371
Iteration 45/1000 | Loss: 0.00001371
Iteration 46/1000 | Loss: 0.00001371
Iteration 47/1000 | Loss: 0.00001371
Iteration 48/1000 | Loss: 0.00001371
Iteration 49/1000 | Loss: 0.00001371
Iteration 50/1000 | Loss: 0.00001371
Iteration 51/1000 | Loss: 0.00001371
Iteration 52/1000 | Loss: 0.00001371
Iteration 53/1000 | Loss: 0.00001371
Iteration 54/1000 | Loss: 0.00001370
Iteration 55/1000 | Loss: 0.00001370
Iteration 56/1000 | Loss: 0.00001369
Iteration 57/1000 | Loss: 0.00001369
Iteration 58/1000 | Loss: 0.00001368
Iteration 59/1000 | Loss: 0.00001366
Iteration 60/1000 | Loss: 0.00001366
Iteration 61/1000 | Loss: 0.00001365
Iteration 62/1000 | Loss: 0.00001365
Iteration 63/1000 | Loss: 0.00001365
Iteration 64/1000 | Loss: 0.00001364
Iteration 65/1000 | Loss: 0.00001364
Iteration 66/1000 | Loss: 0.00001363
Iteration 67/1000 | Loss: 0.00001362
Iteration 68/1000 | Loss: 0.00001361
Iteration 69/1000 | Loss: 0.00001361
Iteration 70/1000 | Loss: 0.00001360
Iteration 71/1000 | Loss: 0.00001360
Iteration 72/1000 | Loss: 0.00001359
Iteration 73/1000 | Loss: 0.00001359
Iteration 74/1000 | Loss: 0.00001359
Iteration 75/1000 | Loss: 0.00001358
Iteration 76/1000 | Loss: 0.00001357
Iteration 77/1000 | Loss: 0.00001356
Iteration 78/1000 | Loss: 0.00001356
Iteration 79/1000 | Loss: 0.00001355
Iteration 80/1000 | Loss: 0.00001354
Iteration 81/1000 | Loss: 0.00001354
Iteration 82/1000 | Loss: 0.00001354
Iteration 83/1000 | Loss: 0.00001353
Iteration 84/1000 | Loss: 0.00001353
Iteration 85/1000 | Loss: 0.00001352
Iteration 86/1000 | Loss: 0.00001352
Iteration 87/1000 | Loss: 0.00001352
Iteration 88/1000 | Loss: 0.00001351
Iteration 89/1000 | Loss: 0.00001351
Iteration 90/1000 | Loss: 0.00001350
Iteration 91/1000 | Loss: 0.00001348
Iteration 92/1000 | Loss: 0.00001347
Iteration 93/1000 | Loss: 0.00001346
Iteration 94/1000 | Loss: 0.00001346
Iteration 95/1000 | Loss: 0.00001346
Iteration 96/1000 | Loss: 0.00001346
Iteration 97/1000 | Loss: 0.00001346
Iteration 98/1000 | Loss: 0.00001346
Iteration 99/1000 | Loss: 0.00001346
Iteration 100/1000 | Loss: 0.00001346
Iteration 101/1000 | Loss: 0.00001346
Iteration 102/1000 | Loss: 0.00001346
Iteration 103/1000 | Loss: 0.00001346
Iteration 104/1000 | Loss: 0.00001346
Iteration 105/1000 | Loss: 0.00001345
Iteration 106/1000 | Loss: 0.00001345
Iteration 107/1000 | Loss: 0.00001345
Iteration 108/1000 | Loss: 0.00001345
Iteration 109/1000 | Loss: 0.00001345
Iteration 110/1000 | Loss: 0.00001345
Iteration 111/1000 | Loss: 0.00001344
Iteration 112/1000 | Loss: 0.00001344
Iteration 113/1000 | Loss: 0.00001343
Iteration 114/1000 | Loss: 0.00001343
Iteration 115/1000 | Loss: 0.00001343
Iteration 116/1000 | Loss: 0.00001343
Iteration 117/1000 | Loss: 0.00001343
Iteration 118/1000 | Loss: 0.00001343
Iteration 119/1000 | Loss: 0.00001343
Iteration 120/1000 | Loss: 0.00001342
Iteration 121/1000 | Loss: 0.00001342
Iteration 122/1000 | Loss: 0.00001342
Iteration 123/1000 | Loss: 0.00001342
Iteration 124/1000 | Loss: 0.00001341
Iteration 125/1000 | Loss: 0.00001341
Iteration 126/1000 | Loss: 0.00001340
Iteration 127/1000 | Loss: 0.00001340
Iteration 128/1000 | Loss: 0.00001340
Iteration 129/1000 | Loss: 0.00001340
Iteration 130/1000 | Loss: 0.00001340
Iteration 131/1000 | Loss: 0.00001340
Iteration 132/1000 | Loss: 0.00001340
Iteration 133/1000 | Loss: 0.00001340
Iteration 134/1000 | Loss: 0.00001340
Iteration 135/1000 | Loss: 0.00001339
Iteration 136/1000 | Loss: 0.00001338
Iteration 137/1000 | Loss: 0.00001338
Iteration 138/1000 | Loss: 0.00001338
Iteration 139/1000 | Loss: 0.00001338
Iteration 140/1000 | Loss: 0.00001338
Iteration 141/1000 | Loss: 0.00001338
Iteration 142/1000 | Loss: 0.00001338
Iteration 143/1000 | Loss: 0.00001337
Iteration 144/1000 | Loss: 0.00001337
Iteration 145/1000 | Loss: 0.00001337
Iteration 146/1000 | Loss: 0.00001336
Iteration 147/1000 | Loss: 0.00001336
Iteration 148/1000 | Loss: 0.00001336
Iteration 149/1000 | Loss: 0.00001336
Iteration 150/1000 | Loss: 0.00001335
Iteration 151/1000 | Loss: 0.00001335
Iteration 152/1000 | Loss: 0.00001335
Iteration 153/1000 | Loss: 0.00001335
Iteration 154/1000 | Loss: 0.00001335
Iteration 155/1000 | Loss: 0.00001335
Iteration 156/1000 | Loss: 0.00001334
Iteration 157/1000 | Loss: 0.00001334
Iteration 158/1000 | Loss: 0.00001334
Iteration 159/1000 | Loss: 0.00001334
Iteration 160/1000 | Loss: 0.00001334
Iteration 161/1000 | Loss: 0.00001334
Iteration 162/1000 | Loss: 0.00001334
Iteration 163/1000 | Loss: 0.00001334
Iteration 164/1000 | Loss: 0.00001334
Iteration 165/1000 | Loss: 0.00001334
Iteration 166/1000 | Loss: 0.00001334
Iteration 167/1000 | Loss: 0.00001334
Iteration 168/1000 | Loss: 0.00001334
Iteration 169/1000 | Loss: 0.00001334
Iteration 170/1000 | Loss: 0.00001334
Iteration 171/1000 | Loss: 0.00001334
Iteration 172/1000 | Loss: 0.00001334
Iteration 173/1000 | Loss: 0.00001334
Iteration 174/1000 | Loss: 0.00001334
Iteration 175/1000 | Loss: 0.00001334
Iteration 176/1000 | Loss: 0.00001334
Iteration 177/1000 | Loss: 0.00001333
Iteration 178/1000 | Loss: 0.00001333
Iteration 179/1000 | Loss: 0.00001333
Iteration 180/1000 | Loss: 0.00001333
Iteration 181/1000 | Loss: 0.00001333
Iteration 182/1000 | Loss: 0.00001333
Iteration 183/1000 | Loss: 0.00001333
Iteration 184/1000 | Loss: 0.00001333
Iteration 185/1000 | Loss: 0.00001333
Iteration 186/1000 | Loss: 0.00001333
Iteration 187/1000 | Loss: 0.00001333
Iteration 188/1000 | Loss: 0.00001333
Iteration 189/1000 | Loss: 0.00001333
Iteration 190/1000 | Loss: 0.00001333
Iteration 191/1000 | Loss: 0.00001333
Iteration 192/1000 | Loss: 0.00001333
Iteration 193/1000 | Loss: 0.00001333
Iteration 194/1000 | Loss: 0.00001333
Iteration 195/1000 | Loss: 0.00001333
Iteration 196/1000 | Loss: 0.00001333
Iteration 197/1000 | Loss: 0.00001333
Iteration 198/1000 | Loss: 0.00001333
Iteration 199/1000 | Loss: 0.00001333
Iteration 200/1000 | Loss: 0.00001333
Iteration 201/1000 | Loss: 0.00001333
Iteration 202/1000 | Loss: 0.00001332
Iteration 203/1000 | Loss: 0.00001332
Iteration 204/1000 | Loss: 0.00001332
Iteration 205/1000 | Loss: 0.00001332
Iteration 206/1000 | Loss: 0.00001332
Iteration 207/1000 | Loss: 0.00001332
Iteration 208/1000 | Loss: 0.00001332
Iteration 209/1000 | Loss: 0.00001332
Iteration 210/1000 | Loss: 0.00001332
Iteration 211/1000 | Loss: 0.00001332
Iteration 212/1000 | Loss: 0.00001332
Iteration 213/1000 | Loss: 0.00001332
Iteration 214/1000 | Loss: 0.00001332
Iteration 215/1000 | Loss: 0.00001332
Iteration 216/1000 | Loss: 0.00001332
Iteration 217/1000 | Loss: 0.00001332
Iteration 218/1000 | Loss: 0.00001332
Iteration 219/1000 | Loss: 0.00001332
Iteration 220/1000 | Loss: 0.00001332
Iteration 221/1000 | Loss: 0.00001332
Iteration 222/1000 | Loss: 0.00001332
Iteration 223/1000 | Loss: 0.00001332
Iteration 224/1000 | Loss: 0.00001332
Iteration 225/1000 | Loss: 0.00001332
Iteration 226/1000 | Loss: 0.00001332
Iteration 227/1000 | Loss: 0.00001332
Iteration 228/1000 | Loss: 0.00001332
Iteration 229/1000 | Loss: 0.00001332
Iteration 230/1000 | Loss: 0.00001332
Iteration 231/1000 | Loss: 0.00001332
Iteration 232/1000 | Loss: 0.00001332
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 232. Stopping optimization.
Last 5 losses: [1.3320191101229284e-05, 1.3320191101229284e-05, 1.3320191101229284e-05, 1.3320191101229284e-05, 1.3320191101229284e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3320191101229284e-05

Optimization complete. Final v2v error: 3.120570659637451 mm

Highest mean error: 3.665771961212158 mm for frame 67

Lowest mean error: 2.6766958236694336 mm for frame 12

Saving results

Total time: 45.829856395721436
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00725654
Iteration 2/25 | Loss: 0.00106676
Iteration 3/25 | Loss: 0.00080803
Iteration 4/25 | Loss: 0.00075322
Iteration 5/25 | Loss: 0.00073533
Iteration 6/25 | Loss: 0.00072677
Iteration 7/25 | Loss: 0.00072417
Iteration 8/25 | Loss: 0.00072288
Iteration 9/25 | Loss: 0.00073698
Iteration 10/25 | Loss: 0.00072707
Iteration 11/25 | Loss: 0.00071950
Iteration 12/25 | Loss: 0.00070835
Iteration 13/25 | Loss: 0.00070709
Iteration 14/25 | Loss: 0.00070680
Iteration 15/25 | Loss: 0.00070675
Iteration 16/25 | Loss: 0.00070675
Iteration 17/25 | Loss: 0.00070675
Iteration 18/25 | Loss: 0.00070675
Iteration 19/25 | Loss: 0.00070675
Iteration 20/25 | Loss: 0.00070675
Iteration 21/25 | Loss: 0.00070675
Iteration 22/25 | Loss: 0.00070675
Iteration 23/25 | Loss: 0.00070675
Iteration 24/25 | Loss: 0.00070675
Iteration 25/25 | Loss: 0.00070675

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48801541
Iteration 2/25 | Loss: 0.00023856
Iteration 3/25 | Loss: 0.00023856
Iteration 4/25 | Loss: 0.00023855
Iteration 5/25 | Loss: 0.00023855
Iteration 6/25 | Loss: 0.00023855
Iteration 7/25 | Loss: 0.00023855
Iteration 8/25 | Loss: 0.00023855
Iteration 9/25 | Loss: 0.00023855
Iteration 10/25 | Loss: 0.00023855
Iteration 11/25 | Loss: 0.00023855
Iteration 12/25 | Loss: 0.00023855
Iteration 13/25 | Loss: 0.00023855
Iteration 14/25 | Loss: 0.00023855
Iteration 15/25 | Loss: 0.00023855
Iteration 16/25 | Loss: 0.00023855
Iteration 17/25 | Loss: 0.00023855
Iteration 18/25 | Loss: 0.00023855
Iteration 19/25 | Loss: 0.00023855
Iteration 20/25 | Loss: 0.00023855
Iteration 21/25 | Loss: 0.00023855
Iteration 22/25 | Loss: 0.00023855
Iteration 23/25 | Loss: 0.00023855
Iteration 24/25 | Loss: 0.00023855
Iteration 25/25 | Loss: 0.00023855

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00023855
Iteration 2/1000 | Loss: 0.00005935
Iteration 3/1000 | Loss: 0.00004191
Iteration 4/1000 | Loss: 0.00003457
Iteration 5/1000 | Loss: 0.00003176
Iteration 6/1000 | Loss: 0.00002980
Iteration 7/1000 | Loss: 0.00002830
Iteration 8/1000 | Loss: 0.00002751
Iteration 9/1000 | Loss: 0.00002695
Iteration 10/1000 | Loss: 0.00002663
Iteration 11/1000 | Loss: 0.00002634
Iteration 12/1000 | Loss: 0.00002611
Iteration 13/1000 | Loss: 0.00002586
Iteration 14/1000 | Loss: 0.00002576
Iteration 15/1000 | Loss: 0.00002571
Iteration 16/1000 | Loss: 0.00002566
Iteration 17/1000 | Loss: 0.00002566
Iteration 18/1000 | Loss: 0.00002562
Iteration 19/1000 | Loss: 0.00002560
Iteration 20/1000 | Loss: 0.00002559
Iteration 21/1000 | Loss: 0.00002556
Iteration 22/1000 | Loss: 0.00002553
Iteration 23/1000 | Loss: 0.00002552
Iteration 24/1000 | Loss: 0.00002552
Iteration 25/1000 | Loss: 0.00002552
Iteration 26/1000 | Loss: 0.00002551
Iteration 27/1000 | Loss: 0.00002551
Iteration 28/1000 | Loss: 0.00002551
Iteration 29/1000 | Loss: 0.00002550
Iteration 30/1000 | Loss: 0.00002550
Iteration 31/1000 | Loss: 0.00002550
Iteration 32/1000 | Loss: 0.00002549
Iteration 33/1000 | Loss: 0.00002549
Iteration 34/1000 | Loss: 0.00002549
Iteration 35/1000 | Loss: 0.00002548
Iteration 36/1000 | Loss: 0.00002548
Iteration 37/1000 | Loss: 0.00002548
Iteration 38/1000 | Loss: 0.00002548
Iteration 39/1000 | Loss: 0.00002548
Iteration 40/1000 | Loss: 0.00002547
Iteration 41/1000 | Loss: 0.00002547
Iteration 42/1000 | Loss: 0.00002547
Iteration 43/1000 | Loss: 0.00002547
Iteration 44/1000 | Loss: 0.00002546
Iteration 45/1000 | Loss: 0.00002546
Iteration 46/1000 | Loss: 0.00002546
Iteration 47/1000 | Loss: 0.00002545
Iteration 48/1000 | Loss: 0.00002545
Iteration 49/1000 | Loss: 0.00002545
Iteration 50/1000 | Loss: 0.00002545
Iteration 51/1000 | Loss: 0.00002545
Iteration 52/1000 | Loss: 0.00002544
Iteration 53/1000 | Loss: 0.00002544
Iteration 54/1000 | Loss: 0.00002544
Iteration 55/1000 | Loss: 0.00002544
Iteration 56/1000 | Loss: 0.00002544
Iteration 57/1000 | Loss: 0.00002544
Iteration 58/1000 | Loss: 0.00002544
Iteration 59/1000 | Loss: 0.00002544
Iteration 60/1000 | Loss: 0.00002543
Iteration 61/1000 | Loss: 0.00002543
Iteration 62/1000 | Loss: 0.00002543
Iteration 63/1000 | Loss: 0.00002543
Iteration 64/1000 | Loss: 0.00002543
Iteration 65/1000 | Loss: 0.00002543
Iteration 66/1000 | Loss: 0.00002542
Iteration 67/1000 | Loss: 0.00002542
Iteration 68/1000 | Loss: 0.00002542
Iteration 69/1000 | Loss: 0.00002542
Iteration 70/1000 | Loss: 0.00002542
Iteration 71/1000 | Loss: 0.00002542
Iteration 72/1000 | Loss: 0.00002542
Iteration 73/1000 | Loss: 0.00002542
Iteration 74/1000 | Loss: 0.00002542
Iteration 75/1000 | Loss: 0.00002542
Iteration 76/1000 | Loss: 0.00002542
Iteration 77/1000 | Loss: 0.00002542
Iteration 78/1000 | Loss: 0.00002541
Iteration 79/1000 | Loss: 0.00002541
Iteration 80/1000 | Loss: 0.00002541
Iteration 81/1000 | Loss: 0.00002541
Iteration 82/1000 | Loss: 0.00002541
Iteration 83/1000 | Loss: 0.00002541
Iteration 84/1000 | Loss: 0.00002541
Iteration 85/1000 | Loss: 0.00002541
Iteration 86/1000 | Loss: 0.00002541
Iteration 87/1000 | Loss: 0.00002541
Iteration 88/1000 | Loss: 0.00002541
Iteration 89/1000 | Loss: 0.00002541
Iteration 90/1000 | Loss: 0.00002541
Iteration 91/1000 | Loss: 0.00002541
Iteration 92/1000 | Loss: 0.00002540
Iteration 93/1000 | Loss: 0.00002540
Iteration 94/1000 | Loss: 0.00002540
Iteration 95/1000 | Loss: 0.00002540
Iteration 96/1000 | Loss: 0.00002539
Iteration 97/1000 | Loss: 0.00002539
Iteration 98/1000 | Loss: 0.00002539
Iteration 99/1000 | Loss: 0.00002539
Iteration 100/1000 | Loss: 0.00002539
Iteration 101/1000 | Loss: 0.00002539
Iteration 102/1000 | Loss: 0.00002539
Iteration 103/1000 | Loss: 0.00002539
Iteration 104/1000 | Loss: 0.00002539
Iteration 105/1000 | Loss: 0.00002538
Iteration 106/1000 | Loss: 0.00002538
Iteration 107/1000 | Loss: 0.00002538
Iteration 108/1000 | Loss: 0.00002538
Iteration 109/1000 | Loss: 0.00002538
Iteration 110/1000 | Loss: 0.00002538
Iteration 111/1000 | Loss: 0.00002538
Iteration 112/1000 | Loss: 0.00002538
Iteration 113/1000 | Loss: 0.00002537
Iteration 114/1000 | Loss: 0.00002537
Iteration 115/1000 | Loss: 0.00002537
Iteration 116/1000 | Loss: 0.00002537
Iteration 117/1000 | Loss: 0.00002537
Iteration 118/1000 | Loss: 0.00002537
Iteration 119/1000 | Loss: 0.00002536
Iteration 120/1000 | Loss: 0.00002536
Iteration 121/1000 | Loss: 0.00002536
Iteration 122/1000 | Loss: 0.00002536
Iteration 123/1000 | Loss: 0.00002536
Iteration 124/1000 | Loss: 0.00002535
Iteration 125/1000 | Loss: 0.00002535
Iteration 126/1000 | Loss: 0.00002535
Iteration 127/1000 | Loss: 0.00002535
Iteration 128/1000 | Loss: 0.00002535
Iteration 129/1000 | Loss: 0.00002535
Iteration 130/1000 | Loss: 0.00002535
Iteration 131/1000 | Loss: 0.00002534
Iteration 132/1000 | Loss: 0.00002534
Iteration 133/1000 | Loss: 0.00002534
Iteration 134/1000 | Loss: 0.00002534
Iteration 135/1000 | Loss: 0.00002534
Iteration 136/1000 | Loss: 0.00002534
Iteration 137/1000 | Loss: 0.00002534
Iteration 138/1000 | Loss: 0.00002534
Iteration 139/1000 | Loss: 0.00002534
Iteration 140/1000 | Loss: 0.00002533
Iteration 141/1000 | Loss: 0.00002533
Iteration 142/1000 | Loss: 0.00002533
Iteration 143/1000 | Loss: 0.00002533
Iteration 144/1000 | Loss: 0.00002533
Iteration 145/1000 | Loss: 0.00002533
Iteration 146/1000 | Loss: 0.00002533
Iteration 147/1000 | Loss: 0.00002533
Iteration 148/1000 | Loss: 0.00002533
Iteration 149/1000 | Loss: 0.00002533
Iteration 150/1000 | Loss: 0.00002533
Iteration 151/1000 | Loss: 0.00002533
Iteration 152/1000 | Loss: 0.00002533
Iteration 153/1000 | Loss: 0.00002533
Iteration 154/1000 | Loss: 0.00002533
Iteration 155/1000 | Loss: 0.00002533
Iteration 156/1000 | Loss: 0.00002533
Iteration 157/1000 | Loss: 0.00002533
Iteration 158/1000 | Loss: 0.00002533
Iteration 159/1000 | Loss: 0.00002533
Iteration 160/1000 | Loss: 0.00002533
Iteration 161/1000 | Loss: 0.00002533
Iteration 162/1000 | Loss: 0.00002533
Iteration 163/1000 | Loss: 0.00002533
Iteration 164/1000 | Loss: 0.00002533
Iteration 165/1000 | Loss: 0.00002533
Iteration 166/1000 | Loss: 0.00002532
Iteration 167/1000 | Loss: 0.00002532
Iteration 168/1000 | Loss: 0.00002532
Iteration 169/1000 | Loss: 0.00002532
Iteration 170/1000 | Loss: 0.00002532
Iteration 171/1000 | Loss: 0.00002532
Iteration 172/1000 | Loss: 0.00002532
Iteration 173/1000 | Loss: 0.00002532
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 173. Stopping optimization.
Last 5 losses: [2.5324980015284382e-05, 2.5324980015284382e-05, 2.5324980015284382e-05, 2.5324980015284382e-05, 2.5324980015284382e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5324980015284382e-05

Optimization complete. Final v2v error: 4.204901218414307 mm

Highest mean error: 5.278493881225586 mm for frame 96

Lowest mean error: 3.2982964515686035 mm for frame 2

Saving results

Total time: 55.88484501838684
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01076786
Iteration 2/25 | Loss: 0.00192512
Iteration 3/25 | Loss: 0.00108012
Iteration 4/25 | Loss: 0.00107016
Iteration 5/25 | Loss: 0.00111724
Iteration 6/25 | Loss: 0.00106944
Iteration 7/25 | Loss: 0.00082263
Iteration 8/25 | Loss: 0.00082028
Iteration 9/25 | Loss: 0.00087029
Iteration 10/25 | Loss: 0.00079681
Iteration 11/25 | Loss: 0.00076530
Iteration 12/25 | Loss: 0.00074203
Iteration 13/25 | Loss: 0.00071712
Iteration 14/25 | Loss: 0.00072541
Iteration 15/25 | Loss: 0.00073083
Iteration 16/25 | Loss: 0.00071507
Iteration 17/25 | Loss: 0.00070699
Iteration 18/25 | Loss: 0.00069180
Iteration 19/25 | Loss: 0.00068404
Iteration 20/25 | Loss: 0.00068135
Iteration 21/25 | Loss: 0.00067329
Iteration 22/25 | Loss: 0.00067299
Iteration 23/25 | Loss: 0.00067265
Iteration 24/25 | Loss: 0.00067350
Iteration 25/25 | Loss: 0.00067269

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.37807178
Iteration 2/25 | Loss: 0.00412510
Iteration 3/25 | Loss: 0.00119674
Iteration 4/25 | Loss: 0.00119674
Iteration 5/25 | Loss: 0.00119674
Iteration 6/25 | Loss: 0.00119674
Iteration 7/25 | Loss: 0.00119674
Iteration 8/25 | Loss: 0.00119674
Iteration 9/25 | Loss: 0.00119674
Iteration 10/25 | Loss: 0.00119674
Iteration 11/25 | Loss: 0.00119674
Iteration 12/25 | Loss: 0.00119674
Iteration 13/25 | Loss: 0.00119674
Iteration 14/25 | Loss: 0.00119674
Iteration 15/25 | Loss: 0.00119674
Iteration 16/25 | Loss: 0.00119674
Iteration 17/25 | Loss: 0.00119674
Iteration 18/25 | Loss: 0.00119674
Iteration 19/25 | Loss: 0.00119674
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0011967376340180635, 0.0011967376340180635, 0.0011967376340180635, 0.0011967376340180635, 0.0011967376340180635]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011967376340180635

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00119674
Iteration 2/1000 | Loss: 0.00034641
Iteration 3/1000 | Loss: 0.00025502
Iteration 4/1000 | Loss: 0.00150478
Iteration 5/1000 | Loss: 0.00045978
Iteration 6/1000 | Loss: 0.00198960
Iteration 7/1000 | Loss: 0.00107837
Iteration 8/1000 | Loss: 0.00147976
Iteration 9/1000 | Loss: 0.00026051
Iteration 10/1000 | Loss: 0.00010395
Iteration 11/1000 | Loss: 0.00004863
Iteration 12/1000 | Loss: 0.00007571
Iteration 13/1000 | Loss: 0.00004960
Iteration 14/1000 | Loss: 0.00005960
Iteration 15/1000 | Loss: 0.00004685
Iteration 16/1000 | Loss: 0.00004274
Iteration 17/1000 | Loss: 0.00006275
Iteration 18/1000 | Loss: 0.00006896
Iteration 19/1000 | Loss: 0.00006268
Iteration 20/1000 | Loss: 0.00007398
Iteration 21/1000 | Loss: 0.00006305
Iteration 22/1000 | Loss: 0.00006935
Iteration 23/1000 | Loss: 0.00006051
Iteration 24/1000 | Loss: 0.00007086
Iteration 25/1000 | Loss: 0.00007062
Iteration 26/1000 | Loss: 0.00006481
Iteration 27/1000 | Loss: 0.00004759
Iteration 28/1000 | Loss: 0.00006573
Iteration 29/1000 | Loss: 0.00005353
Iteration 30/1000 | Loss: 0.00006989
Iteration 31/1000 | Loss: 0.00005241
Iteration 32/1000 | Loss: 0.00006938
Iteration 33/1000 | Loss: 0.00005194
Iteration 34/1000 | Loss: 0.00003636
Iteration 35/1000 | Loss: 0.00005904
Iteration 36/1000 | Loss: 0.00007197
Iteration 37/1000 | Loss: 0.00005653
Iteration 38/1000 | Loss: 0.00005966
Iteration 39/1000 | Loss: 0.00010843
Iteration 40/1000 | Loss: 0.00007182
Iteration 41/1000 | Loss: 0.00007033
Iteration 42/1000 | Loss: 0.00005825
Iteration 43/1000 | Loss: 0.00006928
Iteration 44/1000 | Loss: 0.00006552
Iteration 45/1000 | Loss: 0.00006816
Iteration 46/1000 | Loss: 0.00006522
Iteration 47/1000 | Loss: 0.00006451
Iteration 48/1000 | Loss: 0.00006447
Iteration 49/1000 | Loss: 0.00005468
Iteration 50/1000 | Loss: 0.00007918
Iteration 51/1000 | Loss: 0.00005187
Iteration 52/1000 | Loss: 0.00006915
Iteration 53/1000 | Loss: 0.00006011
Iteration 54/1000 | Loss: 0.00007807
Iteration 55/1000 | Loss: 0.00006984
Iteration 56/1000 | Loss: 0.00003375
Iteration 57/1000 | Loss: 0.00004081
Iteration 58/1000 | Loss: 0.00003078
Iteration 59/1000 | Loss: 0.00006825
Iteration 60/1000 | Loss: 0.00003242
Iteration 61/1000 | Loss: 0.00005433
Iteration 62/1000 | Loss: 0.00006615
Iteration 63/1000 | Loss: 0.00006707
Iteration 64/1000 | Loss: 0.00006476
Iteration 65/1000 | Loss: 0.00002843
Iteration 66/1000 | Loss: 0.00002400
Iteration 67/1000 | Loss: 0.00002225
Iteration 68/1000 | Loss: 0.00002119
Iteration 69/1000 | Loss: 0.00002068
Iteration 70/1000 | Loss: 0.00002039
Iteration 71/1000 | Loss: 0.00002014
Iteration 72/1000 | Loss: 0.00002011
Iteration 73/1000 | Loss: 0.00001999
Iteration 74/1000 | Loss: 0.00001981
Iteration 75/1000 | Loss: 0.00001973
Iteration 76/1000 | Loss: 0.00001971
Iteration 77/1000 | Loss: 0.00001967
Iteration 78/1000 | Loss: 0.00001963
Iteration 79/1000 | Loss: 0.00001959
Iteration 80/1000 | Loss: 0.00001959
Iteration 81/1000 | Loss: 0.00001958
Iteration 82/1000 | Loss: 0.00001957
Iteration 83/1000 | Loss: 0.00001956
Iteration 84/1000 | Loss: 0.00001955
Iteration 85/1000 | Loss: 0.00001954
Iteration 86/1000 | Loss: 0.00001951
Iteration 87/1000 | Loss: 0.00001950
Iteration 88/1000 | Loss: 0.00001948
Iteration 89/1000 | Loss: 0.00001947
Iteration 90/1000 | Loss: 0.00001947
Iteration 91/1000 | Loss: 0.00001946
Iteration 92/1000 | Loss: 0.00001945
Iteration 93/1000 | Loss: 0.00001944
Iteration 94/1000 | Loss: 0.00001944
Iteration 95/1000 | Loss: 0.00001943
Iteration 96/1000 | Loss: 0.00001941
Iteration 97/1000 | Loss: 0.00001939
Iteration 98/1000 | Loss: 0.00001939
Iteration 99/1000 | Loss: 0.00001938
Iteration 100/1000 | Loss: 0.00001938
Iteration 101/1000 | Loss: 0.00001937
Iteration 102/1000 | Loss: 0.00001936
Iteration 103/1000 | Loss: 0.00001936
Iteration 104/1000 | Loss: 0.00001935
Iteration 105/1000 | Loss: 0.00001935
Iteration 106/1000 | Loss: 0.00001935
Iteration 107/1000 | Loss: 0.00001934
Iteration 108/1000 | Loss: 0.00001934
Iteration 109/1000 | Loss: 0.00001934
Iteration 110/1000 | Loss: 0.00001934
Iteration 111/1000 | Loss: 0.00001934
Iteration 112/1000 | Loss: 0.00001934
Iteration 113/1000 | Loss: 0.00001934
Iteration 114/1000 | Loss: 0.00001933
Iteration 115/1000 | Loss: 0.00001933
Iteration 116/1000 | Loss: 0.00001933
Iteration 117/1000 | Loss: 0.00001932
Iteration 118/1000 | Loss: 0.00001932
Iteration 119/1000 | Loss: 0.00001932
Iteration 120/1000 | Loss: 0.00001931
Iteration 121/1000 | Loss: 0.00001931
Iteration 122/1000 | Loss: 0.00001931
Iteration 123/1000 | Loss: 0.00001931
Iteration 124/1000 | Loss: 0.00001931
Iteration 125/1000 | Loss: 0.00001931
Iteration 126/1000 | Loss: 0.00001930
Iteration 127/1000 | Loss: 0.00001930
Iteration 128/1000 | Loss: 0.00001930
Iteration 129/1000 | Loss: 0.00001930
Iteration 130/1000 | Loss: 0.00001930
Iteration 131/1000 | Loss: 0.00001930
Iteration 132/1000 | Loss: 0.00001929
Iteration 133/1000 | Loss: 0.00001929
Iteration 134/1000 | Loss: 0.00001929
Iteration 135/1000 | Loss: 0.00001929
Iteration 136/1000 | Loss: 0.00001929
Iteration 137/1000 | Loss: 0.00001929
Iteration 138/1000 | Loss: 0.00001929
Iteration 139/1000 | Loss: 0.00001929
Iteration 140/1000 | Loss: 0.00001929
Iteration 141/1000 | Loss: 0.00001928
Iteration 142/1000 | Loss: 0.00001928
Iteration 143/1000 | Loss: 0.00001928
Iteration 144/1000 | Loss: 0.00001928
Iteration 145/1000 | Loss: 0.00001928
Iteration 146/1000 | Loss: 0.00001928
Iteration 147/1000 | Loss: 0.00001927
Iteration 148/1000 | Loss: 0.00001927
Iteration 149/1000 | Loss: 0.00001926
Iteration 150/1000 | Loss: 0.00001926
Iteration 151/1000 | Loss: 0.00001926
Iteration 152/1000 | Loss: 0.00001926
Iteration 153/1000 | Loss: 0.00001926
Iteration 154/1000 | Loss: 0.00001926
Iteration 155/1000 | Loss: 0.00001925
Iteration 156/1000 | Loss: 0.00001925
Iteration 157/1000 | Loss: 0.00001925
Iteration 158/1000 | Loss: 0.00001925
Iteration 159/1000 | Loss: 0.00001925
Iteration 160/1000 | Loss: 0.00001925
Iteration 161/1000 | Loss: 0.00001925
Iteration 162/1000 | Loss: 0.00001925
Iteration 163/1000 | Loss: 0.00001925
Iteration 164/1000 | Loss: 0.00001925
Iteration 165/1000 | Loss: 0.00001925
Iteration 166/1000 | Loss: 0.00001925
Iteration 167/1000 | Loss: 0.00001925
Iteration 168/1000 | Loss: 0.00001925
Iteration 169/1000 | Loss: 0.00001925
Iteration 170/1000 | Loss: 0.00001925
Iteration 171/1000 | Loss: 0.00001925
Iteration 172/1000 | Loss: 0.00001925
Iteration 173/1000 | Loss: 0.00001925
Iteration 174/1000 | Loss: 0.00001925
Iteration 175/1000 | Loss: 0.00001925
Iteration 176/1000 | Loss: 0.00001925
Iteration 177/1000 | Loss: 0.00001925
Iteration 178/1000 | Loss: 0.00001925
Iteration 179/1000 | Loss: 0.00001925
Iteration 180/1000 | Loss: 0.00001925
Iteration 181/1000 | Loss: 0.00001925
Iteration 182/1000 | Loss: 0.00001925
Iteration 183/1000 | Loss: 0.00001925
Iteration 184/1000 | Loss: 0.00001925
Iteration 185/1000 | Loss: 0.00001925
Iteration 186/1000 | Loss: 0.00001925
Iteration 187/1000 | Loss: 0.00001925
Iteration 188/1000 | Loss: 0.00001925
Iteration 189/1000 | Loss: 0.00001925
Iteration 190/1000 | Loss: 0.00001925
Iteration 191/1000 | Loss: 0.00001925
Iteration 192/1000 | Loss: 0.00001925
Iteration 193/1000 | Loss: 0.00001925
Iteration 194/1000 | Loss: 0.00001925
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 194. Stopping optimization.
Last 5 losses: [1.9248753233114257e-05, 1.9248753233114257e-05, 1.9248753233114257e-05, 1.9248753233114257e-05, 1.9248753233114257e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9248753233114257e-05

Optimization complete. Final v2v error: 3.385359525680542 mm

Highest mean error: 11.149393081665039 mm for frame 90

Lowest mean error: 2.926715850830078 mm for frame 40

Saving results

Total time: 157.33852696418762
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00896413
Iteration 2/25 | Loss: 0.00226592
Iteration 3/25 | Loss: 0.00129011
Iteration 4/25 | Loss: 0.00098585
Iteration 5/25 | Loss: 0.00092906
Iteration 6/25 | Loss: 0.00086991
Iteration 7/25 | Loss: 0.00082695
Iteration 8/25 | Loss: 0.00075779
Iteration 9/25 | Loss: 0.00071278
Iteration 10/25 | Loss: 0.00069341
Iteration 11/25 | Loss: 0.00068784
Iteration 12/25 | Loss: 0.00068407
Iteration 13/25 | Loss: 0.00068156
Iteration 14/25 | Loss: 0.00067906
Iteration 15/25 | Loss: 0.00067755
Iteration 16/25 | Loss: 0.00067350
Iteration 17/25 | Loss: 0.00067248
Iteration 18/25 | Loss: 0.00067217
Iteration 19/25 | Loss: 0.00067196
Iteration 20/25 | Loss: 0.00067292
Iteration 21/25 | Loss: 0.00067170
Iteration 22/25 | Loss: 0.00067019
Iteration 23/25 | Loss: 0.00066898
Iteration 24/25 | Loss: 0.00066835
Iteration 25/25 | Loss: 0.00066820

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.92756891
Iteration 2/25 | Loss: 0.00012825
Iteration 3/25 | Loss: 0.00012824
Iteration 4/25 | Loss: 0.00012824
Iteration 5/25 | Loss: 0.00012824
Iteration 6/25 | Loss: 0.00012824
Iteration 7/25 | Loss: 0.00012824
Iteration 8/25 | Loss: 0.00012824
Iteration 9/25 | Loss: 0.00012824
Iteration 10/25 | Loss: 0.00012824
Iteration 11/25 | Loss: 0.00012824
Iteration 12/25 | Loss: 0.00012824
Iteration 13/25 | Loss: 0.00012824
Iteration 14/25 | Loss: 0.00012824
Iteration 15/25 | Loss: 0.00012824
Iteration 16/25 | Loss: 0.00012824
Iteration 17/25 | Loss: 0.00012824
Iteration 18/25 | Loss: 0.00012824
Iteration 19/25 | Loss: 0.00012824
Iteration 20/25 | Loss: 0.00012824
Iteration 21/25 | Loss: 0.00012824
Iteration 22/25 | Loss: 0.00012824
Iteration 23/25 | Loss: 0.00012824
Iteration 24/25 | Loss: 0.00012824
Iteration 25/25 | Loss: 0.00012824

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00012824
Iteration 2/1000 | Loss: 0.00003320
Iteration 3/1000 | Loss: 0.00002378
Iteration 4/1000 | Loss: 0.00002217
Iteration 5/1000 | Loss: 0.00002123
Iteration 6/1000 | Loss: 0.00002074
Iteration 7/1000 | Loss: 0.00002026
Iteration 8/1000 | Loss: 0.00002000
Iteration 9/1000 | Loss: 0.00001969
Iteration 10/1000 | Loss: 0.00001946
Iteration 11/1000 | Loss: 0.00001929
Iteration 12/1000 | Loss: 0.00001917
Iteration 13/1000 | Loss: 0.00001905
Iteration 14/1000 | Loss: 0.00001902
Iteration 15/1000 | Loss: 0.00001901
Iteration 16/1000 | Loss: 0.00001901
Iteration 17/1000 | Loss: 0.00001900
Iteration 18/1000 | Loss: 0.00001900
Iteration 19/1000 | Loss: 0.00001896
Iteration 20/1000 | Loss: 0.00001896
Iteration 21/1000 | Loss: 0.00001893
Iteration 22/1000 | Loss: 0.00001888
Iteration 23/1000 | Loss: 0.00001888
Iteration 24/1000 | Loss: 0.00001887
Iteration 25/1000 | Loss: 0.00001885
Iteration 26/1000 | Loss: 0.00001885
Iteration 27/1000 | Loss: 0.00001884
Iteration 28/1000 | Loss: 0.00001884
Iteration 29/1000 | Loss: 0.00001884
Iteration 30/1000 | Loss: 0.00001883
Iteration 31/1000 | Loss: 0.00001882
Iteration 32/1000 | Loss: 0.00001881
Iteration 33/1000 | Loss: 0.00001880
Iteration 34/1000 | Loss: 0.00001879
Iteration 35/1000 | Loss: 0.00001879
Iteration 36/1000 | Loss: 0.00001879
Iteration 37/1000 | Loss: 0.00001879
Iteration 38/1000 | Loss: 0.00001879
Iteration 39/1000 | Loss: 0.00001878
Iteration 40/1000 | Loss: 0.00001878
Iteration 41/1000 | Loss: 0.00001878
Iteration 42/1000 | Loss: 0.00001877
Iteration 43/1000 | Loss: 0.00001876
Iteration 44/1000 | Loss: 0.00001875
Iteration 45/1000 | Loss: 0.00001875
Iteration 46/1000 | Loss: 0.00001875
Iteration 47/1000 | Loss: 0.00001875
Iteration 48/1000 | Loss: 0.00001875
Iteration 49/1000 | Loss: 0.00001875
Iteration 50/1000 | Loss: 0.00001874
Iteration 51/1000 | Loss: 0.00001874
Iteration 52/1000 | Loss: 0.00001874
Iteration 53/1000 | Loss: 0.00001874
Iteration 54/1000 | Loss: 0.00001874
Iteration 55/1000 | Loss: 0.00001874
Iteration 56/1000 | Loss: 0.00001874
Iteration 57/1000 | Loss: 0.00001874
Iteration 58/1000 | Loss: 0.00001873
Iteration 59/1000 | Loss: 0.00001873
Iteration 60/1000 | Loss: 0.00001873
Iteration 61/1000 | Loss: 0.00001873
Iteration 62/1000 | Loss: 0.00001872
Iteration 63/1000 | Loss: 0.00001872
Iteration 64/1000 | Loss: 0.00001872
Iteration 65/1000 | Loss: 0.00001872
Iteration 66/1000 | Loss: 0.00001872
Iteration 67/1000 | Loss: 0.00001872
Iteration 68/1000 | Loss: 0.00001872
Iteration 69/1000 | Loss: 0.00001871
Iteration 70/1000 | Loss: 0.00001871
Iteration 71/1000 | Loss: 0.00001871
Iteration 72/1000 | Loss: 0.00001871
Iteration 73/1000 | Loss: 0.00001871
Iteration 74/1000 | Loss: 0.00001871
Iteration 75/1000 | Loss: 0.00001870
Iteration 76/1000 | Loss: 0.00001870
Iteration 77/1000 | Loss: 0.00001870
Iteration 78/1000 | Loss: 0.00001870
Iteration 79/1000 | Loss: 0.00001870
Iteration 80/1000 | Loss: 0.00001869
Iteration 81/1000 | Loss: 0.00001869
Iteration 82/1000 | Loss: 0.00001869
Iteration 83/1000 | Loss: 0.00001868
Iteration 84/1000 | Loss: 0.00001868
Iteration 85/1000 | Loss: 0.00001868
Iteration 86/1000 | Loss: 0.00001868
Iteration 87/1000 | Loss: 0.00001867
Iteration 88/1000 | Loss: 0.00001867
Iteration 89/1000 | Loss: 0.00001867
Iteration 90/1000 | Loss: 0.00001867
Iteration 91/1000 | Loss: 0.00001867
Iteration 92/1000 | Loss: 0.00001867
Iteration 93/1000 | Loss: 0.00001867
Iteration 94/1000 | Loss: 0.00001867
Iteration 95/1000 | Loss: 0.00001867
Iteration 96/1000 | Loss: 0.00001867
Iteration 97/1000 | Loss: 0.00001867
Iteration 98/1000 | Loss: 0.00001867
Iteration 99/1000 | Loss: 0.00001866
Iteration 100/1000 | Loss: 0.00001866
Iteration 101/1000 | Loss: 0.00001866
Iteration 102/1000 | Loss: 0.00001866
Iteration 103/1000 | Loss: 0.00001866
Iteration 104/1000 | Loss: 0.00001866
Iteration 105/1000 | Loss: 0.00001865
Iteration 106/1000 | Loss: 0.00001865
Iteration 107/1000 | Loss: 0.00001865
Iteration 108/1000 | Loss: 0.00001865
Iteration 109/1000 | Loss: 0.00001865
Iteration 110/1000 | Loss: 0.00001865
Iteration 111/1000 | Loss: 0.00001865
Iteration 112/1000 | Loss: 0.00001865
Iteration 113/1000 | Loss: 0.00001865
Iteration 114/1000 | Loss: 0.00001865
Iteration 115/1000 | Loss: 0.00001865
Iteration 116/1000 | Loss: 0.00001865
Iteration 117/1000 | Loss: 0.00001865
Iteration 118/1000 | Loss: 0.00001865
Iteration 119/1000 | Loss: 0.00001865
Iteration 120/1000 | Loss: 0.00001865
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 120. Stopping optimization.
Last 5 losses: [1.8649114281288348e-05, 1.8649114281288348e-05, 1.8649114281288348e-05, 1.8649114281288348e-05, 1.8649114281288348e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8649114281288348e-05

Optimization complete. Final v2v error: 3.6733901500701904 mm

Highest mean error: 4.472081661224365 mm for frame 141

Lowest mean error: 3.1142148971557617 mm for frame 11

Saving results

Total time: 81.77267861366272
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01076750
Iteration 2/25 | Loss: 0.00186863
Iteration 3/25 | Loss: 0.00117766
Iteration 4/25 | Loss: 0.00093559
Iteration 5/25 | Loss: 0.00083842
Iteration 6/25 | Loss: 0.00080702
Iteration 7/25 | Loss: 0.00080522
Iteration 8/25 | Loss: 0.00080058
Iteration 9/25 | Loss: 0.00079760
Iteration 10/25 | Loss: 0.00079706
Iteration 11/25 | Loss: 0.00079682
Iteration 12/25 | Loss: 0.00079668
Iteration 13/25 | Loss: 0.00079666
Iteration 14/25 | Loss: 0.00079666
Iteration 15/25 | Loss: 0.00079666
Iteration 16/25 | Loss: 0.00079666
Iteration 17/25 | Loss: 0.00079665
Iteration 18/25 | Loss: 0.00079665
Iteration 19/25 | Loss: 0.00079665
Iteration 20/25 | Loss: 0.00079665
Iteration 21/25 | Loss: 0.00079665
Iteration 22/25 | Loss: 0.00079665
Iteration 23/25 | Loss: 0.00079665
Iteration 24/25 | Loss: 0.00079665
Iteration 25/25 | Loss: 0.00079665

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.18523932
Iteration 2/25 | Loss: 0.00031332
Iteration 3/25 | Loss: 0.00031332
Iteration 4/25 | Loss: 0.00031332
Iteration 5/25 | Loss: 0.00031332
Iteration 6/25 | Loss: 0.00031332
Iteration 7/25 | Loss: 0.00031332
Iteration 8/25 | Loss: 0.00031332
Iteration 9/25 | Loss: 0.00031332
Iteration 10/25 | Loss: 0.00031331
Iteration 11/25 | Loss: 0.00031331
Iteration 12/25 | Loss: 0.00031331
Iteration 13/25 | Loss: 0.00031331
Iteration 14/25 | Loss: 0.00031331
Iteration 15/25 | Loss: 0.00031331
Iteration 16/25 | Loss: 0.00031331
Iteration 17/25 | Loss: 0.00031331
Iteration 18/25 | Loss: 0.00031331
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00031331475474871695, 0.00031331475474871695, 0.00031331475474871695, 0.00031331475474871695, 0.00031331475474871695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031331475474871695

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031331
Iteration 2/1000 | Loss: 0.00004661
Iteration 3/1000 | Loss: 0.00003540
Iteration 4/1000 | Loss: 0.00003228
Iteration 5/1000 | Loss: 0.00002995
Iteration 6/1000 | Loss: 0.00002861
Iteration 7/1000 | Loss: 0.00002775
Iteration 8/1000 | Loss: 0.00002723
Iteration 9/1000 | Loss: 0.00002692
Iteration 10/1000 | Loss: 0.00002659
Iteration 11/1000 | Loss: 0.00002635
Iteration 12/1000 | Loss: 0.00002619
Iteration 13/1000 | Loss: 0.00002612
Iteration 14/1000 | Loss: 0.00002611
Iteration 15/1000 | Loss: 0.00002610
Iteration 16/1000 | Loss: 0.00002607
Iteration 17/1000 | Loss: 0.00002600
Iteration 18/1000 | Loss: 0.00002598
Iteration 19/1000 | Loss: 0.00002593
Iteration 20/1000 | Loss: 0.00002588
Iteration 21/1000 | Loss: 0.00002588
Iteration 22/1000 | Loss: 0.00002586
Iteration 23/1000 | Loss: 0.00002586
Iteration 24/1000 | Loss: 0.00002586
Iteration 25/1000 | Loss: 0.00002585
Iteration 26/1000 | Loss: 0.00002584
Iteration 27/1000 | Loss: 0.00002584
Iteration 28/1000 | Loss: 0.00002583
Iteration 29/1000 | Loss: 0.00002582
Iteration 30/1000 | Loss: 0.00002582
Iteration 31/1000 | Loss: 0.00002582
Iteration 32/1000 | Loss: 0.00002582
Iteration 33/1000 | Loss: 0.00002582
Iteration 34/1000 | Loss: 0.00002582
Iteration 35/1000 | Loss: 0.00002580
Iteration 36/1000 | Loss: 0.00002579
Iteration 37/1000 | Loss: 0.00002579
Iteration 38/1000 | Loss: 0.00002577
Iteration 39/1000 | Loss: 0.00002577
Iteration 40/1000 | Loss: 0.00002577
Iteration 41/1000 | Loss: 0.00002577
Iteration 42/1000 | Loss: 0.00002576
Iteration 43/1000 | Loss: 0.00002574
Iteration 44/1000 | Loss: 0.00002574
Iteration 45/1000 | Loss: 0.00002574
Iteration 46/1000 | Loss: 0.00002573
Iteration 47/1000 | Loss: 0.00002573
Iteration 48/1000 | Loss: 0.00002573
Iteration 49/1000 | Loss: 0.00002573
Iteration 50/1000 | Loss: 0.00002573
Iteration 51/1000 | Loss: 0.00002573
Iteration 52/1000 | Loss: 0.00002573
Iteration 53/1000 | Loss: 0.00002573
Iteration 54/1000 | Loss: 0.00002573
Iteration 55/1000 | Loss: 0.00002572
Iteration 56/1000 | Loss: 0.00002572
Iteration 57/1000 | Loss: 0.00002572
Iteration 58/1000 | Loss: 0.00002572
Iteration 59/1000 | Loss: 0.00002572
Iteration 60/1000 | Loss: 0.00002572
Iteration 61/1000 | Loss: 0.00002572
Iteration 62/1000 | Loss: 0.00002572
Iteration 63/1000 | Loss: 0.00002572
Iteration 64/1000 | Loss: 0.00002572
Iteration 65/1000 | Loss: 0.00002572
Iteration 66/1000 | Loss: 0.00002572
Iteration 67/1000 | Loss: 0.00002572
Iteration 68/1000 | Loss: 0.00002572
Iteration 69/1000 | Loss: 0.00002572
Iteration 70/1000 | Loss: 0.00002572
Iteration 71/1000 | Loss: 0.00002572
Iteration 72/1000 | Loss: 0.00002572
Iteration 73/1000 | Loss: 0.00002572
Iteration 74/1000 | Loss: 0.00002572
Iteration 75/1000 | Loss: 0.00002572
Iteration 76/1000 | Loss: 0.00002572
Iteration 77/1000 | Loss: 0.00002572
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [2.5722451027831994e-05, 2.5722451027831994e-05, 2.5722451027831994e-05, 2.5722451027831994e-05, 2.5722451027831994e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5722451027831994e-05

Optimization complete. Final v2v error: 4.317648887634277 mm

Highest mean error: 5.862425327301025 mm for frame 233

Lowest mean error: 3.749065637588501 mm for frame 2

Saving results

Total time: 51.45615482330322
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00604703
Iteration 2/25 | Loss: 0.00088456
Iteration 3/25 | Loss: 0.00072224
Iteration 4/25 | Loss: 0.00070227
Iteration 5/25 | Loss: 0.00069494
Iteration 6/25 | Loss: 0.00069344
Iteration 7/25 | Loss: 0.00069339
Iteration 8/25 | Loss: 0.00069339
Iteration 9/25 | Loss: 0.00069339
Iteration 10/25 | Loss: 0.00069339
Iteration 11/25 | Loss: 0.00069339
Iteration 12/25 | Loss: 0.00069339
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006933920085430145, 0.0006933920085430145, 0.0006933920085430145, 0.0006933920085430145, 0.0006933920085430145]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006933920085430145

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.33764029
Iteration 2/25 | Loss: 0.00016978
Iteration 3/25 | Loss: 0.00016975
Iteration 4/25 | Loss: 0.00016975
Iteration 5/25 | Loss: 0.00016975
Iteration 6/25 | Loss: 0.00016975
Iteration 7/25 | Loss: 0.00016975
Iteration 8/25 | Loss: 0.00016975
Iteration 9/25 | Loss: 0.00016975
Iteration 10/25 | Loss: 0.00016975
Iteration 11/25 | Loss: 0.00016975
Iteration 12/25 | Loss: 0.00016975
Iteration 13/25 | Loss: 0.00016975
Iteration 14/25 | Loss: 0.00016975
Iteration 15/25 | Loss: 0.00016975
Iteration 16/25 | Loss: 0.00016975
Iteration 17/25 | Loss: 0.00016975
Iteration 18/25 | Loss: 0.00016975
Iteration 19/25 | Loss: 0.00016975
Iteration 20/25 | Loss: 0.00016975
Iteration 21/25 | Loss: 0.00016975
Iteration 22/25 | Loss: 0.00016975
Iteration 23/25 | Loss: 0.00016975
Iteration 24/25 | Loss: 0.00016975
Iteration 25/25 | Loss: 0.00016975

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00016975
Iteration 2/1000 | Loss: 0.00003384
Iteration 3/1000 | Loss: 0.00002851
Iteration 4/1000 | Loss: 0.00002634
Iteration 5/1000 | Loss: 0.00002479
Iteration 6/1000 | Loss: 0.00002412
Iteration 7/1000 | Loss: 0.00002361
Iteration 8/1000 | Loss: 0.00002312
Iteration 9/1000 | Loss: 0.00002281
Iteration 10/1000 | Loss: 0.00002263
Iteration 11/1000 | Loss: 0.00002259
Iteration 12/1000 | Loss: 0.00002249
Iteration 13/1000 | Loss: 0.00002233
Iteration 14/1000 | Loss: 0.00002232
Iteration 15/1000 | Loss: 0.00002231
Iteration 16/1000 | Loss: 0.00002231
Iteration 17/1000 | Loss: 0.00002229
Iteration 18/1000 | Loss: 0.00002228
Iteration 19/1000 | Loss: 0.00002227
Iteration 20/1000 | Loss: 0.00002227
Iteration 21/1000 | Loss: 0.00002225
Iteration 22/1000 | Loss: 0.00002225
Iteration 23/1000 | Loss: 0.00002224
Iteration 24/1000 | Loss: 0.00002223
Iteration 25/1000 | Loss: 0.00002221
Iteration 26/1000 | Loss: 0.00002220
Iteration 27/1000 | Loss: 0.00002220
Iteration 28/1000 | Loss: 0.00002219
Iteration 29/1000 | Loss: 0.00002214
Iteration 30/1000 | Loss: 0.00002212
Iteration 31/1000 | Loss: 0.00002212
Iteration 32/1000 | Loss: 0.00002211
Iteration 33/1000 | Loss: 0.00002211
Iteration 34/1000 | Loss: 0.00002210
Iteration 35/1000 | Loss: 0.00002208
Iteration 36/1000 | Loss: 0.00002207
Iteration 37/1000 | Loss: 0.00002207
Iteration 38/1000 | Loss: 0.00002206
Iteration 39/1000 | Loss: 0.00002206
Iteration 40/1000 | Loss: 0.00002205
Iteration 41/1000 | Loss: 0.00002205
Iteration 42/1000 | Loss: 0.00002204
Iteration 43/1000 | Loss: 0.00002203
Iteration 44/1000 | Loss: 0.00002203
Iteration 45/1000 | Loss: 0.00002203
Iteration 46/1000 | Loss: 0.00002202
Iteration 47/1000 | Loss: 0.00002202
Iteration 48/1000 | Loss: 0.00002201
Iteration 49/1000 | Loss: 0.00002201
Iteration 50/1000 | Loss: 0.00002201
Iteration 51/1000 | Loss: 0.00002200
Iteration 52/1000 | Loss: 0.00002200
Iteration 53/1000 | Loss: 0.00002200
Iteration 54/1000 | Loss: 0.00002200
Iteration 55/1000 | Loss: 0.00002199
Iteration 56/1000 | Loss: 0.00002199
Iteration 57/1000 | Loss: 0.00002199
Iteration 58/1000 | Loss: 0.00002199
Iteration 59/1000 | Loss: 0.00002198
Iteration 60/1000 | Loss: 0.00002198
Iteration 61/1000 | Loss: 0.00002198
Iteration 62/1000 | Loss: 0.00002198
Iteration 63/1000 | Loss: 0.00002198
Iteration 64/1000 | Loss: 0.00002198
Iteration 65/1000 | Loss: 0.00002198
Iteration 66/1000 | Loss: 0.00002197
Iteration 67/1000 | Loss: 0.00002197
Iteration 68/1000 | Loss: 0.00002197
Iteration 69/1000 | Loss: 0.00002197
Iteration 70/1000 | Loss: 0.00002196
Iteration 71/1000 | Loss: 0.00002196
Iteration 72/1000 | Loss: 0.00002196
Iteration 73/1000 | Loss: 0.00002196
Iteration 74/1000 | Loss: 0.00002196
Iteration 75/1000 | Loss: 0.00002196
Iteration 76/1000 | Loss: 0.00002196
Iteration 77/1000 | Loss: 0.00002196
Iteration 78/1000 | Loss: 0.00002196
Iteration 79/1000 | Loss: 0.00002196
Iteration 80/1000 | Loss: 0.00002196
Iteration 81/1000 | Loss: 0.00002196
Iteration 82/1000 | Loss: 0.00002196
Iteration 83/1000 | Loss: 0.00002196
Iteration 84/1000 | Loss: 0.00002196
Iteration 85/1000 | Loss: 0.00002195
Iteration 86/1000 | Loss: 0.00002195
Iteration 87/1000 | Loss: 0.00002195
Iteration 88/1000 | Loss: 0.00002195
Iteration 89/1000 | Loss: 0.00002195
Iteration 90/1000 | Loss: 0.00002195
Iteration 91/1000 | Loss: 0.00002195
Iteration 92/1000 | Loss: 0.00002194
Iteration 93/1000 | Loss: 0.00002194
Iteration 94/1000 | Loss: 0.00002194
Iteration 95/1000 | Loss: 0.00002194
Iteration 96/1000 | Loss: 0.00002194
Iteration 97/1000 | Loss: 0.00002194
Iteration 98/1000 | Loss: 0.00002194
Iteration 99/1000 | Loss: 0.00002194
Iteration 100/1000 | Loss: 0.00002193
Iteration 101/1000 | Loss: 0.00002193
Iteration 102/1000 | Loss: 0.00002193
Iteration 103/1000 | Loss: 0.00002193
Iteration 104/1000 | Loss: 0.00002193
Iteration 105/1000 | Loss: 0.00002192
Iteration 106/1000 | Loss: 0.00002192
Iteration 107/1000 | Loss: 0.00002192
Iteration 108/1000 | Loss: 0.00002192
Iteration 109/1000 | Loss: 0.00002191
Iteration 110/1000 | Loss: 0.00002191
Iteration 111/1000 | Loss: 0.00002191
Iteration 112/1000 | Loss: 0.00002191
Iteration 113/1000 | Loss: 0.00002191
Iteration 114/1000 | Loss: 0.00002191
Iteration 115/1000 | Loss: 0.00002191
Iteration 116/1000 | Loss: 0.00002191
Iteration 117/1000 | Loss: 0.00002191
Iteration 118/1000 | Loss: 0.00002191
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [2.1910876967012882e-05, 2.1910876967012882e-05, 2.1910876967012882e-05, 2.1910876967012882e-05, 2.1910876967012882e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1910876967012882e-05

Optimization complete. Final v2v error: 3.9941375255584717 mm

Highest mean error: 4.50944185256958 mm for frame 213

Lowest mean error: 3.576979398727417 mm for frame 239

Saving results

Total time: 39.49113130569458
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00466924
Iteration 2/25 | Loss: 0.00082609
Iteration 3/25 | Loss: 0.00070064
Iteration 4/25 | Loss: 0.00066600
Iteration 5/25 | Loss: 0.00065814
Iteration 6/25 | Loss: 0.00065645
Iteration 7/25 | Loss: 0.00065645
Iteration 8/25 | Loss: 0.00065645
Iteration 9/25 | Loss: 0.00065645
Iteration 10/25 | Loss: 0.00065645
Iteration 11/25 | Loss: 0.00065645
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0006564500508829951, 0.0006564500508829951, 0.0006564500508829951, 0.0006564500508829951, 0.0006564500508829951]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006564500508829951

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32235885
Iteration 2/25 | Loss: 0.00027447
Iteration 3/25 | Loss: 0.00027446
Iteration 4/25 | Loss: 0.00027446
Iteration 5/25 | Loss: 0.00027446
Iteration 6/25 | Loss: 0.00027446
Iteration 7/25 | Loss: 0.00027445
Iteration 8/25 | Loss: 0.00027445
Iteration 9/25 | Loss: 0.00027445
Iteration 10/25 | Loss: 0.00027445
Iteration 11/25 | Loss: 0.00027445
Iteration 12/25 | Loss: 0.00027445
Iteration 13/25 | Loss: 0.00027445
Iteration 14/25 | Loss: 0.00027445
Iteration 15/25 | Loss: 0.00027445
Iteration 16/25 | Loss: 0.00027445
Iteration 17/25 | Loss: 0.00027445
Iteration 18/25 | Loss: 0.00027445
Iteration 19/25 | Loss: 0.00027445
Iteration 20/25 | Loss: 0.00027445
Iteration 21/25 | Loss: 0.00027445
Iteration 22/25 | Loss: 0.00027445
Iteration 23/25 | Loss: 0.00027445
Iteration 24/25 | Loss: 0.00027445
Iteration 25/25 | Loss: 0.00027445

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027445
Iteration 2/1000 | Loss: 0.00003464
Iteration 3/1000 | Loss: 0.00002662
Iteration 4/1000 | Loss: 0.00002403
Iteration 5/1000 | Loss: 0.00002231
Iteration 6/1000 | Loss: 0.00002128
Iteration 7/1000 | Loss: 0.00002076
Iteration 8/1000 | Loss: 0.00002042
Iteration 9/1000 | Loss: 0.00002027
Iteration 10/1000 | Loss: 0.00002005
Iteration 11/1000 | Loss: 0.00001992
Iteration 12/1000 | Loss: 0.00001981
Iteration 13/1000 | Loss: 0.00001973
Iteration 14/1000 | Loss: 0.00001973
Iteration 15/1000 | Loss: 0.00001971
Iteration 16/1000 | Loss: 0.00001970
Iteration 17/1000 | Loss: 0.00001970
Iteration 18/1000 | Loss: 0.00001970
Iteration 19/1000 | Loss: 0.00001967
Iteration 20/1000 | Loss: 0.00001967
Iteration 21/1000 | Loss: 0.00001967
Iteration 22/1000 | Loss: 0.00001967
Iteration 23/1000 | Loss: 0.00001967
Iteration 24/1000 | Loss: 0.00001966
Iteration 25/1000 | Loss: 0.00001966
Iteration 26/1000 | Loss: 0.00001965
Iteration 27/1000 | Loss: 0.00001963
Iteration 28/1000 | Loss: 0.00001962
Iteration 29/1000 | Loss: 0.00001961
Iteration 30/1000 | Loss: 0.00001961
Iteration 31/1000 | Loss: 0.00001961
Iteration 32/1000 | Loss: 0.00001960
Iteration 33/1000 | Loss: 0.00001960
Iteration 34/1000 | Loss: 0.00001956
Iteration 35/1000 | Loss: 0.00001955
Iteration 36/1000 | Loss: 0.00001954
Iteration 37/1000 | Loss: 0.00001953
Iteration 38/1000 | Loss: 0.00001950
Iteration 39/1000 | Loss: 0.00001949
Iteration 40/1000 | Loss: 0.00001949
Iteration 41/1000 | Loss: 0.00001948
Iteration 42/1000 | Loss: 0.00001948
Iteration 43/1000 | Loss: 0.00001948
Iteration 44/1000 | Loss: 0.00001947
Iteration 45/1000 | Loss: 0.00001947
Iteration 46/1000 | Loss: 0.00001947
Iteration 47/1000 | Loss: 0.00001946
Iteration 48/1000 | Loss: 0.00001946
Iteration 49/1000 | Loss: 0.00001946
Iteration 50/1000 | Loss: 0.00001945
Iteration 51/1000 | Loss: 0.00001945
Iteration 52/1000 | Loss: 0.00001945
Iteration 53/1000 | Loss: 0.00001945
Iteration 54/1000 | Loss: 0.00001945
Iteration 55/1000 | Loss: 0.00001945
Iteration 56/1000 | Loss: 0.00001945
Iteration 57/1000 | Loss: 0.00001945
Iteration 58/1000 | Loss: 0.00001944
Iteration 59/1000 | Loss: 0.00001944
Iteration 60/1000 | Loss: 0.00001944
Iteration 61/1000 | Loss: 0.00001943
Iteration 62/1000 | Loss: 0.00001943
Iteration 63/1000 | Loss: 0.00001943
Iteration 64/1000 | Loss: 0.00001943
Iteration 65/1000 | Loss: 0.00001943
Iteration 66/1000 | Loss: 0.00001943
Iteration 67/1000 | Loss: 0.00001943
Iteration 68/1000 | Loss: 0.00001942
Iteration 69/1000 | Loss: 0.00001942
Iteration 70/1000 | Loss: 0.00001942
Iteration 71/1000 | Loss: 0.00001942
Iteration 72/1000 | Loss: 0.00001941
Iteration 73/1000 | Loss: 0.00001941
Iteration 74/1000 | Loss: 0.00001941
Iteration 75/1000 | Loss: 0.00001941
Iteration 76/1000 | Loss: 0.00001941
Iteration 77/1000 | Loss: 0.00001940
Iteration 78/1000 | Loss: 0.00001940
Iteration 79/1000 | Loss: 0.00001940
Iteration 80/1000 | Loss: 0.00001939
Iteration 81/1000 | Loss: 0.00001939
Iteration 82/1000 | Loss: 0.00001939
Iteration 83/1000 | Loss: 0.00001938
Iteration 84/1000 | Loss: 0.00001938
Iteration 85/1000 | Loss: 0.00001938
Iteration 86/1000 | Loss: 0.00001938
Iteration 87/1000 | Loss: 0.00001938
Iteration 88/1000 | Loss: 0.00001938
Iteration 89/1000 | Loss: 0.00001937
Iteration 90/1000 | Loss: 0.00001937
Iteration 91/1000 | Loss: 0.00001937
Iteration 92/1000 | Loss: 0.00001936
Iteration 93/1000 | Loss: 0.00001936
Iteration 94/1000 | Loss: 0.00001935
Iteration 95/1000 | Loss: 0.00001935
Iteration 96/1000 | Loss: 0.00001935
Iteration 97/1000 | Loss: 0.00001935
Iteration 98/1000 | Loss: 0.00001935
Iteration 99/1000 | Loss: 0.00001935
Iteration 100/1000 | Loss: 0.00001935
Iteration 101/1000 | Loss: 0.00001935
Iteration 102/1000 | Loss: 0.00001935
Iteration 103/1000 | Loss: 0.00001935
Iteration 104/1000 | Loss: 0.00001935
Iteration 105/1000 | Loss: 0.00001935
Iteration 106/1000 | Loss: 0.00001935
Iteration 107/1000 | Loss: 0.00001935
Iteration 108/1000 | Loss: 0.00001935
Iteration 109/1000 | Loss: 0.00001934
Iteration 110/1000 | Loss: 0.00001934
Iteration 111/1000 | Loss: 0.00001934
Iteration 112/1000 | Loss: 0.00001933
Iteration 113/1000 | Loss: 0.00001933
Iteration 114/1000 | Loss: 0.00001933
Iteration 115/1000 | Loss: 0.00001932
Iteration 116/1000 | Loss: 0.00001932
Iteration 117/1000 | Loss: 0.00001932
Iteration 118/1000 | Loss: 0.00001932
Iteration 119/1000 | Loss: 0.00001932
Iteration 120/1000 | Loss: 0.00001932
Iteration 121/1000 | Loss: 0.00001931
Iteration 122/1000 | Loss: 0.00001931
Iteration 123/1000 | Loss: 0.00001931
Iteration 124/1000 | Loss: 0.00001931
Iteration 125/1000 | Loss: 0.00001931
Iteration 126/1000 | Loss: 0.00001931
Iteration 127/1000 | Loss: 0.00001931
Iteration 128/1000 | Loss: 0.00001931
Iteration 129/1000 | Loss: 0.00001931
Iteration 130/1000 | Loss: 0.00001931
Iteration 131/1000 | Loss: 0.00001931
Iteration 132/1000 | Loss: 0.00001930
Iteration 133/1000 | Loss: 0.00001930
Iteration 134/1000 | Loss: 0.00001930
Iteration 135/1000 | Loss: 0.00001930
Iteration 136/1000 | Loss: 0.00001930
Iteration 137/1000 | Loss: 0.00001930
Iteration 138/1000 | Loss: 0.00001930
Iteration 139/1000 | Loss: 0.00001930
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 139. Stopping optimization.
Last 5 losses: [1.9301083739264868e-05, 1.9301083739264868e-05, 1.9301083739264868e-05, 1.9301083739264868e-05, 1.9301083739264868e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9301083739264868e-05

Optimization complete. Final v2v error: 3.7605550289154053 mm

Highest mean error: 4.269838809967041 mm for frame 142

Lowest mean error: 3.1394433975219727 mm for frame 13

Saving results

Total time: 40.62605357170105
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00416830
Iteration 2/25 | Loss: 0.00077909
Iteration 3/25 | Loss: 0.00057736
Iteration 4/25 | Loss: 0.00055822
Iteration 5/25 | Loss: 0.00055496
Iteration 6/25 | Loss: 0.00055410
Iteration 7/25 | Loss: 0.00055406
Iteration 8/25 | Loss: 0.00055406
Iteration 9/25 | Loss: 0.00055406
Iteration 10/25 | Loss: 0.00055406
Iteration 11/25 | Loss: 0.00055406
Iteration 12/25 | Loss: 0.00055406
Iteration 13/25 | Loss: 0.00055406
Iteration 14/25 | Loss: 0.00055406
Iteration 15/25 | Loss: 0.00055406
Iteration 16/25 | Loss: 0.00055406
Iteration 17/25 | Loss: 0.00055406
Iteration 18/25 | Loss: 0.00055406
Iteration 19/25 | Loss: 0.00055406
Iteration 20/25 | Loss: 0.00055406
Iteration 21/25 | Loss: 0.00055406
Iteration 22/25 | Loss: 0.00055406
Iteration 23/25 | Loss: 0.00055406
Iteration 24/25 | Loss: 0.00055406
Iteration 25/25 | Loss: 0.00055406

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30263960
Iteration 2/25 | Loss: 0.00016875
Iteration 3/25 | Loss: 0.00016875
Iteration 4/25 | Loss: 0.00016875
Iteration 5/25 | Loss: 0.00016875
Iteration 6/25 | Loss: 0.00016875
Iteration 7/25 | Loss: 0.00016875
Iteration 8/25 | Loss: 0.00016875
Iteration 9/25 | Loss: 0.00016874
Iteration 10/25 | Loss: 0.00016874
Iteration 11/25 | Loss: 0.00016874
Iteration 12/25 | Loss: 0.00016874
Iteration 13/25 | Loss: 0.00016874
Iteration 14/25 | Loss: 0.00016874
Iteration 15/25 | Loss: 0.00016874
Iteration 16/25 | Loss: 0.00016874
Iteration 17/25 | Loss: 0.00016874
Iteration 18/25 | Loss: 0.00016874
Iteration 19/25 | Loss: 0.00016874
Iteration 20/25 | Loss: 0.00016874
Iteration 21/25 | Loss: 0.00016874
Iteration 22/25 | Loss: 0.00016874
Iteration 23/25 | Loss: 0.00016874
Iteration 24/25 | Loss: 0.00016874
Iteration 25/25 | Loss: 0.00016874

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00016874
Iteration 2/1000 | Loss: 0.00001892
Iteration 3/1000 | Loss: 0.00001598
Iteration 4/1000 | Loss: 0.00001477
Iteration 5/1000 | Loss: 0.00001395
Iteration 6/1000 | Loss: 0.00001367
Iteration 7/1000 | Loss: 0.00001350
Iteration 8/1000 | Loss: 0.00001344
Iteration 9/1000 | Loss: 0.00001344
Iteration 10/1000 | Loss: 0.00001339
Iteration 11/1000 | Loss: 0.00001337
Iteration 12/1000 | Loss: 0.00001336
Iteration 13/1000 | Loss: 0.00001333
Iteration 14/1000 | Loss: 0.00001331
Iteration 15/1000 | Loss: 0.00001329
Iteration 16/1000 | Loss: 0.00001329
Iteration 17/1000 | Loss: 0.00001329
Iteration 18/1000 | Loss: 0.00001328
Iteration 19/1000 | Loss: 0.00001328
Iteration 20/1000 | Loss: 0.00001327
Iteration 21/1000 | Loss: 0.00001325
Iteration 22/1000 | Loss: 0.00001325
Iteration 23/1000 | Loss: 0.00001324
Iteration 24/1000 | Loss: 0.00001324
Iteration 25/1000 | Loss: 0.00001318
Iteration 26/1000 | Loss: 0.00001318
Iteration 27/1000 | Loss: 0.00001318
Iteration 28/1000 | Loss: 0.00001318
Iteration 29/1000 | Loss: 0.00001317
Iteration 30/1000 | Loss: 0.00001317
Iteration 31/1000 | Loss: 0.00001317
Iteration 32/1000 | Loss: 0.00001317
Iteration 33/1000 | Loss: 0.00001317
Iteration 34/1000 | Loss: 0.00001317
Iteration 35/1000 | Loss: 0.00001317
Iteration 36/1000 | Loss: 0.00001317
Iteration 37/1000 | Loss: 0.00001316
Iteration 38/1000 | Loss: 0.00001316
Iteration 39/1000 | Loss: 0.00001316
Iteration 40/1000 | Loss: 0.00001315
Iteration 41/1000 | Loss: 0.00001315
Iteration 42/1000 | Loss: 0.00001315
Iteration 43/1000 | Loss: 0.00001315
Iteration 44/1000 | Loss: 0.00001315
Iteration 45/1000 | Loss: 0.00001314
Iteration 46/1000 | Loss: 0.00001314
Iteration 47/1000 | Loss: 0.00001314
Iteration 48/1000 | Loss: 0.00001313
Iteration 49/1000 | Loss: 0.00001313
Iteration 50/1000 | Loss: 0.00001313
Iteration 51/1000 | Loss: 0.00001313
Iteration 52/1000 | Loss: 0.00001312
Iteration 53/1000 | Loss: 0.00001312
Iteration 54/1000 | Loss: 0.00001312
Iteration 55/1000 | Loss: 0.00001312
Iteration 56/1000 | Loss: 0.00001310
Iteration 57/1000 | Loss: 0.00001310
Iteration 58/1000 | Loss: 0.00001310
Iteration 59/1000 | Loss: 0.00001310
Iteration 60/1000 | Loss: 0.00001309
Iteration 61/1000 | Loss: 0.00001309
Iteration 62/1000 | Loss: 0.00001309
Iteration 63/1000 | Loss: 0.00001309
Iteration 64/1000 | Loss: 0.00001308
Iteration 65/1000 | Loss: 0.00001308
Iteration 66/1000 | Loss: 0.00001308
Iteration 67/1000 | Loss: 0.00001308
Iteration 68/1000 | Loss: 0.00001308
Iteration 69/1000 | Loss: 0.00001308
Iteration 70/1000 | Loss: 0.00001308
Iteration 71/1000 | Loss: 0.00001308
Iteration 72/1000 | Loss: 0.00001308
Iteration 73/1000 | Loss: 0.00001308
Iteration 74/1000 | Loss: 0.00001308
Iteration 75/1000 | Loss: 0.00001307
Iteration 76/1000 | Loss: 0.00001307
Iteration 77/1000 | Loss: 0.00001307
Iteration 78/1000 | Loss: 0.00001307
Iteration 79/1000 | Loss: 0.00001307
Iteration 80/1000 | Loss: 0.00001307
Iteration 81/1000 | Loss: 0.00001305
Iteration 82/1000 | Loss: 0.00001305
Iteration 83/1000 | Loss: 0.00001305
Iteration 84/1000 | Loss: 0.00001305
Iteration 85/1000 | Loss: 0.00001305
Iteration 86/1000 | Loss: 0.00001305
Iteration 87/1000 | Loss: 0.00001305
Iteration 88/1000 | Loss: 0.00001305
Iteration 89/1000 | Loss: 0.00001305
Iteration 90/1000 | Loss: 0.00001305
Iteration 91/1000 | Loss: 0.00001305
Iteration 92/1000 | Loss: 0.00001305
Iteration 93/1000 | Loss: 0.00001304
Iteration 94/1000 | Loss: 0.00001304
Iteration 95/1000 | Loss: 0.00001304
Iteration 96/1000 | Loss: 0.00001304
Iteration 97/1000 | Loss: 0.00001304
Iteration 98/1000 | Loss: 0.00001304
Iteration 99/1000 | Loss: 0.00001303
Iteration 100/1000 | Loss: 0.00001303
Iteration 101/1000 | Loss: 0.00001303
Iteration 102/1000 | Loss: 0.00001303
Iteration 103/1000 | Loss: 0.00001303
Iteration 104/1000 | Loss: 0.00001302
Iteration 105/1000 | Loss: 0.00001302
Iteration 106/1000 | Loss: 0.00001302
Iteration 107/1000 | Loss: 0.00001302
Iteration 108/1000 | Loss: 0.00001301
Iteration 109/1000 | Loss: 0.00001301
Iteration 110/1000 | Loss: 0.00001301
Iteration 111/1000 | Loss: 0.00001301
Iteration 112/1000 | Loss: 0.00001301
Iteration 113/1000 | Loss: 0.00001300
Iteration 114/1000 | Loss: 0.00001300
Iteration 115/1000 | Loss: 0.00001300
Iteration 116/1000 | Loss: 0.00001300
Iteration 117/1000 | Loss: 0.00001299
Iteration 118/1000 | Loss: 0.00001299
Iteration 119/1000 | Loss: 0.00001299
Iteration 120/1000 | Loss: 0.00001299
Iteration 121/1000 | Loss: 0.00001299
Iteration 122/1000 | Loss: 0.00001299
Iteration 123/1000 | Loss: 0.00001299
Iteration 124/1000 | Loss: 0.00001299
Iteration 125/1000 | Loss: 0.00001299
Iteration 126/1000 | Loss: 0.00001299
Iteration 127/1000 | Loss: 0.00001299
Iteration 128/1000 | Loss: 0.00001299
Iteration 129/1000 | Loss: 0.00001299
Iteration 130/1000 | Loss: 0.00001299
Iteration 131/1000 | Loss: 0.00001299
Iteration 132/1000 | Loss: 0.00001299
Iteration 133/1000 | Loss: 0.00001299
Iteration 134/1000 | Loss: 0.00001298
Iteration 135/1000 | Loss: 0.00001298
Iteration 136/1000 | Loss: 0.00001298
Iteration 137/1000 | Loss: 0.00001298
Iteration 138/1000 | Loss: 0.00001298
Iteration 139/1000 | Loss: 0.00001298
Iteration 140/1000 | Loss: 0.00001298
Iteration 141/1000 | Loss: 0.00001298
Iteration 142/1000 | Loss: 0.00001298
Iteration 143/1000 | Loss: 0.00001298
Iteration 144/1000 | Loss: 0.00001298
Iteration 145/1000 | Loss: 0.00001297
Iteration 146/1000 | Loss: 0.00001297
Iteration 147/1000 | Loss: 0.00001297
Iteration 148/1000 | Loss: 0.00001297
Iteration 149/1000 | Loss: 0.00001297
Iteration 150/1000 | Loss: 0.00001297
Iteration 151/1000 | Loss: 0.00001297
Iteration 152/1000 | Loss: 0.00001297
Iteration 153/1000 | Loss: 0.00001297
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 153. Stopping optimization.
Last 5 losses: [1.2971582691534422e-05, 1.2971582691534422e-05, 1.2971582691534422e-05, 1.2971582691534422e-05, 1.2971582691534422e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2971582691534422e-05

Optimization complete. Final v2v error: 3.071382522583008 mm

Highest mean error: 3.453085422515869 mm for frame 48

Lowest mean error: 2.795185089111328 mm for frame 181

Saving results

Total time: 32.05885362625122
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01083128
Iteration 2/25 | Loss: 0.00279856
Iteration 3/25 | Loss: 0.00233516
Iteration 4/25 | Loss: 0.00205062
Iteration 5/25 | Loss: 0.00194133
Iteration 6/25 | Loss: 0.00188715
Iteration 7/25 | Loss: 0.00175995
Iteration 8/25 | Loss: 0.00157130
Iteration 9/25 | Loss: 0.00142988
Iteration 10/25 | Loss: 0.00135648
Iteration 11/25 | Loss: 0.00133860
Iteration 12/25 | Loss: 0.00129105
Iteration 13/25 | Loss: 0.00127228
Iteration 14/25 | Loss: 0.00125528
Iteration 15/25 | Loss: 0.00122636
Iteration 16/25 | Loss: 0.00119699
Iteration 17/25 | Loss: 0.00117631
Iteration 18/25 | Loss: 0.00116850
Iteration 19/25 | Loss: 0.00115663
Iteration 20/25 | Loss: 0.00114748
Iteration 21/25 | Loss: 0.00114527
Iteration 22/25 | Loss: 0.00114339
Iteration 23/25 | Loss: 0.00114104
Iteration 24/25 | Loss: 0.00114053
Iteration 25/25 | Loss: 0.00113963

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31420505
Iteration 2/25 | Loss: 0.00509483
Iteration 3/25 | Loss: 0.00509482
Iteration 4/25 | Loss: 0.00509482
Iteration 5/25 | Loss: 0.00509481
Iteration 6/25 | Loss: 0.00509481
Iteration 7/25 | Loss: 0.00509481
Iteration 8/25 | Loss: 0.00509481
Iteration 9/25 | Loss: 0.00509481
Iteration 10/25 | Loss: 0.00509481
Iteration 11/25 | Loss: 0.00509481
Iteration 12/25 | Loss: 0.00509481
Iteration 13/25 | Loss: 0.00509481
Iteration 14/25 | Loss: 0.00509481
Iteration 15/25 | Loss: 0.00509481
Iteration 16/25 | Loss: 0.00509481
Iteration 17/25 | Loss: 0.00509481
Iteration 18/25 | Loss: 0.00509481
Iteration 19/25 | Loss: 0.00509481
Iteration 20/25 | Loss: 0.00509481
Iteration 21/25 | Loss: 0.00509481
Iteration 22/25 | Loss: 0.00509481
Iteration 23/25 | Loss: 0.00509481
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.005094810854643583, 0.005094810854643583, 0.005094810854643583, 0.005094810854643583, 0.005094810854643583]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005094810854643583

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00509481
Iteration 2/1000 | Loss: 0.00085171
Iteration 3/1000 | Loss: 0.01262851
Iteration 4/1000 | Loss: 0.00459699
Iteration 5/1000 | Loss: 0.00197258
Iteration 6/1000 | Loss: 0.00096893
Iteration 7/1000 | Loss: 0.00154338
Iteration 8/1000 | Loss: 0.00186288
Iteration 9/1000 | Loss: 0.00154481
Iteration 10/1000 | Loss: 0.00089202
Iteration 11/1000 | Loss: 0.00180791
Iteration 12/1000 | Loss: 0.00183939
Iteration 13/1000 | Loss: 0.00162410
Iteration 14/1000 | Loss: 0.00131122
Iteration 15/1000 | Loss: 0.00102650
Iteration 16/1000 | Loss: 0.00118095
Iteration 17/1000 | Loss: 0.00126865
Iteration 18/1000 | Loss: 0.00209437
Iteration 19/1000 | Loss: 0.00091927
Iteration 20/1000 | Loss: 0.00199064
Iteration 21/1000 | Loss: 0.00288133
Iteration 22/1000 | Loss: 0.00232493
Iteration 23/1000 | Loss: 0.00281885
Iteration 24/1000 | Loss: 0.00277889
Iteration 25/1000 | Loss: 0.00245547
Iteration 26/1000 | Loss: 0.00147076
Iteration 27/1000 | Loss: 0.00123881
Iteration 28/1000 | Loss: 0.00064107
Iteration 29/1000 | Loss: 0.00059044
Iteration 30/1000 | Loss: 0.00093873
Iteration 31/1000 | Loss: 0.00042961
Iteration 32/1000 | Loss: 0.00077210
Iteration 33/1000 | Loss: 0.00057581
Iteration 34/1000 | Loss: 0.00081908
Iteration 35/1000 | Loss: 0.00072494
Iteration 36/1000 | Loss: 0.00097566
Iteration 37/1000 | Loss: 0.00072560
Iteration 38/1000 | Loss: 0.00071026
Iteration 39/1000 | Loss: 0.00087548
Iteration 40/1000 | Loss: 0.00085590
Iteration 41/1000 | Loss: 0.00097121
Iteration 42/1000 | Loss: 0.00133980
Iteration 43/1000 | Loss: 0.00093354
Iteration 44/1000 | Loss: 0.00169552
Iteration 45/1000 | Loss: 0.00167233
Iteration 46/1000 | Loss: 0.00046171
Iteration 47/1000 | Loss: 0.00049444
Iteration 48/1000 | Loss: 0.00036822
Iteration 49/1000 | Loss: 0.00169208
Iteration 50/1000 | Loss: 0.00075552
Iteration 51/1000 | Loss: 0.00043531
Iteration 52/1000 | Loss: 0.00105699
Iteration 53/1000 | Loss: 0.00087019
Iteration 54/1000 | Loss: 0.00059536
Iteration 55/1000 | Loss: 0.00102270
Iteration 56/1000 | Loss: 0.00064178
Iteration 57/1000 | Loss: 0.00048279
Iteration 58/1000 | Loss: 0.00105322
Iteration 59/1000 | Loss: 0.00031510
Iteration 60/1000 | Loss: 0.00030883
Iteration 61/1000 | Loss: 0.00077498
Iteration 62/1000 | Loss: 0.00151621
Iteration 63/1000 | Loss: 0.00039810
Iteration 64/1000 | Loss: 0.00029209
Iteration 65/1000 | Loss: 0.00027631
Iteration 66/1000 | Loss: 0.00079140
Iteration 67/1000 | Loss: 0.00063596
Iteration 68/1000 | Loss: 0.00024900
Iteration 69/1000 | Loss: 0.00027815
Iteration 70/1000 | Loss: 0.00098726
Iteration 71/1000 | Loss: 0.00031723
Iteration 72/1000 | Loss: 0.00025603
Iteration 73/1000 | Loss: 0.00025233
Iteration 74/1000 | Loss: 0.00023497
Iteration 75/1000 | Loss: 0.00090799
Iteration 76/1000 | Loss: 0.00105386
Iteration 77/1000 | Loss: 0.00054367
Iteration 78/1000 | Loss: 0.00092661
Iteration 79/1000 | Loss: 0.00027904
Iteration 80/1000 | Loss: 0.00023268
Iteration 81/1000 | Loss: 0.00111841
Iteration 82/1000 | Loss: 0.00024867
Iteration 83/1000 | Loss: 0.00090129
Iteration 84/1000 | Loss: 0.00696175
Iteration 85/1000 | Loss: 0.00562614
Iteration 86/1000 | Loss: 0.00102680
Iteration 87/1000 | Loss: 0.00053893
Iteration 88/1000 | Loss: 0.00068186
Iteration 89/1000 | Loss: 0.00230642
Iteration 90/1000 | Loss: 0.00205217
Iteration 91/1000 | Loss: 0.00079955
Iteration 92/1000 | Loss: 0.00076921
Iteration 93/1000 | Loss: 0.00044980
Iteration 94/1000 | Loss: 0.00057093
Iteration 95/1000 | Loss: 0.00029592
Iteration 96/1000 | Loss: 0.00039773
Iteration 97/1000 | Loss: 0.00046653
Iteration 98/1000 | Loss: 0.00016663
Iteration 99/1000 | Loss: 0.00015281
Iteration 100/1000 | Loss: 0.00135307
Iteration 101/1000 | Loss: 0.00028881
Iteration 102/1000 | Loss: 0.00088299
Iteration 103/1000 | Loss: 0.00018071
Iteration 104/1000 | Loss: 0.00015583
Iteration 105/1000 | Loss: 0.00013779
Iteration 106/1000 | Loss: 0.00012599
Iteration 107/1000 | Loss: 0.00065064
Iteration 108/1000 | Loss: 0.00069648
Iteration 109/1000 | Loss: 0.00075879
Iteration 110/1000 | Loss: 0.00051214
Iteration 111/1000 | Loss: 0.00018966
Iteration 112/1000 | Loss: 0.00011354
Iteration 113/1000 | Loss: 0.00010208
Iteration 114/1000 | Loss: 0.00080360
Iteration 115/1000 | Loss: 0.00124630
Iteration 116/1000 | Loss: 0.00077554
Iteration 117/1000 | Loss: 0.00023740
Iteration 118/1000 | Loss: 0.00090737
Iteration 119/1000 | Loss: 0.00032190
Iteration 120/1000 | Loss: 0.00026025
Iteration 121/1000 | Loss: 0.00073223
Iteration 122/1000 | Loss: 0.00074359
Iteration 123/1000 | Loss: 0.00017655
Iteration 124/1000 | Loss: 0.00021369
Iteration 125/1000 | Loss: 0.00025576
Iteration 126/1000 | Loss: 0.00014652
Iteration 127/1000 | Loss: 0.00011970
Iteration 128/1000 | Loss: 0.00012756
Iteration 129/1000 | Loss: 0.00139874
Iteration 130/1000 | Loss: 0.00385389
Iteration 131/1000 | Loss: 0.00531807
Iteration 132/1000 | Loss: 0.00423193
Iteration 133/1000 | Loss: 0.00112233
Iteration 134/1000 | Loss: 0.00052613
Iteration 135/1000 | Loss: 0.00077731
Iteration 136/1000 | Loss: 0.00053098
Iteration 137/1000 | Loss: 0.00016095
Iteration 138/1000 | Loss: 0.00010448
Iteration 139/1000 | Loss: 0.00071718
Iteration 140/1000 | Loss: 0.00088703
Iteration 141/1000 | Loss: 0.00017369
Iteration 142/1000 | Loss: 0.00068442
Iteration 143/1000 | Loss: 0.00082458
Iteration 144/1000 | Loss: 0.00052188
Iteration 145/1000 | Loss: 0.00059463
Iteration 146/1000 | Loss: 0.00123282
Iteration 147/1000 | Loss: 0.00094713
Iteration 148/1000 | Loss: 0.00009333
Iteration 149/1000 | Loss: 0.00006733
Iteration 150/1000 | Loss: 0.00005491
Iteration 151/1000 | Loss: 0.00004926
Iteration 152/1000 | Loss: 0.00004456
Iteration 153/1000 | Loss: 0.00004138
Iteration 154/1000 | Loss: 0.00003817
Iteration 155/1000 | Loss: 0.00003630
Iteration 156/1000 | Loss: 0.00003534
Iteration 157/1000 | Loss: 0.00003430
Iteration 158/1000 | Loss: 0.00003346
Iteration 159/1000 | Loss: 0.00003271
Iteration 160/1000 | Loss: 0.00003218
Iteration 161/1000 | Loss: 0.00003178
Iteration 162/1000 | Loss: 0.00003131
Iteration 163/1000 | Loss: 0.00003090
Iteration 164/1000 | Loss: 0.00003068
Iteration 165/1000 | Loss: 0.00003052
Iteration 166/1000 | Loss: 0.00003047
Iteration 167/1000 | Loss: 0.00003039
Iteration 168/1000 | Loss: 0.00003039
Iteration 169/1000 | Loss: 0.00050060
Iteration 170/1000 | Loss: 0.00006708
Iteration 171/1000 | Loss: 0.00003241
Iteration 172/1000 | Loss: 0.00002934
Iteration 173/1000 | Loss: 0.00002743
Iteration 174/1000 | Loss: 0.00002664
Iteration 175/1000 | Loss: 0.00002634
Iteration 176/1000 | Loss: 0.00002615
Iteration 177/1000 | Loss: 0.00002601
Iteration 178/1000 | Loss: 0.00002601
Iteration 179/1000 | Loss: 0.00002600
Iteration 180/1000 | Loss: 0.00002597
Iteration 181/1000 | Loss: 0.00002597
Iteration 182/1000 | Loss: 0.00002596
Iteration 183/1000 | Loss: 0.00002596
Iteration 184/1000 | Loss: 0.00002595
Iteration 185/1000 | Loss: 0.00002595
Iteration 186/1000 | Loss: 0.00002594
Iteration 187/1000 | Loss: 0.00002594
Iteration 188/1000 | Loss: 0.00002593
Iteration 189/1000 | Loss: 0.00002590
Iteration 190/1000 | Loss: 0.00002589
Iteration 191/1000 | Loss: 0.00002580
Iteration 192/1000 | Loss: 0.00002577
Iteration 193/1000 | Loss: 0.00002576
Iteration 194/1000 | Loss: 0.00002574
Iteration 195/1000 | Loss: 0.00002573
Iteration 196/1000 | Loss: 0.00002573
Iteration 197/1000 | Loss: 0.00002572
Iteration 198/1000 | Loss: 0.00002572
Iteration 199/1000 | Loss: 0.00002572
Iteration 200/1000 | Loss: 0.00002572
Iteration 201/1000 | Loss: 0.00002571
Iteration 202/1000 | Loss: 0.00002571
Iteration 203/1000 | Loss: 0.00002571
Iteration 204/1000 | Loss: 0.00002571
Iteration 205/1000 | Loss: 0.00002571
Iteration 206/1000 | Loss: 0.00002571
Iteration 207/1000 | Loss: 0.00002571
Iteration 208/1000 | Loss: 0.00002571
Iteration 209/1000 | Loss: 0.00002571
Iteration 210/1000 | Loss: 0.00002570
Iteration 211/1000 | Loss: 0.00002570
Iteration 212/1000 | Loss: 0.00002570
Iteration 213/1000 | Loss: 0.00002570
Iteration 214/1000 | Loss: 0.00002570
Iteration 215/1000 | Loss: 0.00002570
Iteration 216/1000 | Loss: 0.00002570
Iteration 217/1000 | Loss: 0.00002570
Iteration 218/1000 | Loss: 0.00002569
Iteration 219/1000 | Loss: 0.00002569
Iteration 220/1000 | Loss: 0.00002569
Iteration 221/1000 | Loss: 0.00002569
Iteration 222/1000 | Loss: 0.00002569
Iteration 223/1000 | Loss: 0.00002569
Iteration 224/1000 | Loss: 0.00002568
Iteration 225/1000 | Loss: 0.00002568
Iteration 226/1000 | Loss: 0.00002568
Iteration 227/1000 | Loss: 0.00002568
Iteration 228/1000 | Loss: 0.00002568
Iteration 229/1000 | Loss: 0.00002568
Iteration 230/1000 | Loss: 0.00002568
Iteration 231/1000 | Loss: 0.00002568
Iteration 232/1000 | Loss: 0.00002568
Iteration 233/1000 | Loss: 0.00002568
Iteration 234/1000 | Loss: 0.00002568
Iteration 235/1000 | Loss: 0.00002568
Iteration 236/1000 | Loss: 0.00002568
Iteration 237/1000 | Loss: 0.00002567
Iteration 238/1000 | Loss: 0.00002567
Iteration 239/1000 | Loss: 0.00002567
Iteration 240/1000 | Loss: 0.00002567
Iteration 241/1000 | Loss: 0.00002567
Iteration 242/1000 | Loss: 0.00002567
Iteration 243/1000 | Loss: 0.00002567
Iteration 244/1000 | Loss: 0.00002567
Iteration 245/1000 | Loss: 0.00002567
Iteration 246/1000 | Loss: 0.00002567
Iteration 247/1000 | Loss: 0.00002567
Iteration 248/1000 | Loss: 0.00002567
Iteration 249/1000 | Loss: 0.00002567
Iteration 250/1000 | Loss: 0.00002567
Iteration 251/1000 | Loss: 0.00002567
Iteration 252/1000 | Loss: 0.00002567
Iteration 253/1000 | Loss: 0.00002567
Iteration 254/1000 | Loss: 0.00002567
Iteration 255/1000 | Loss: 0.00002567
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 255. Stopping optimization.
Last 5 losses: [2.567283809185028e-05, 2.567283809185028e-05, 2.567283809185028e-05, 2.567283809185028e-05, 2.567283809185028e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.567283809185028e-05

Optimization complete. Final v2v error: 3.7740797996520996 mm

Highest mean error: 12.531030654907227 mm for frame 92

Lowest mean error: 3.4470560550689697 mm for frame 52

Saving results

Total time: 289.9837610721588
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00806670
Iteration 2/25 | Loss: 0.00104956
Iteration 3/25 | Loss: 0.00081459
Iteration 4/25 | Loss: 0.00076986
Iteration 5/25 | Loss: 0.00076244
Iteration 6/25 | Loss: 0.00076151
Iteration 7/25 | Loss: 0.00076151
Iteration 8/25 | Loss: 0.00076151
Iteration 9/25 | Loss: 0.00076151
Iteration 10/25 | Loss: 0.00076151
Iteration 11/25 | Loss: 0.00076151
Iteration 12/25 | Loss: 0.00076151
Iteration 13/25 | Loss: 0.00076151
Iteration 14/25 | Loss: 0.00076151
Iteration 15/25 | Loss: 0.00076151
Iteration 16/25 | Loss: 0.00076151
Iteration 17/25 | Loss: 0.00076151
Iteration 18/25 | Loss: 0.00076151
Iteration 19/25 | Loss: 0.00076151
Iteration 20/25 | Loss: 0.00076151
Iteration 21/25 | Loss: 0.00076151
Iteration 22/25 | Loss: 0.00076151
Iteration 23/25 | Loss: 0.00076151
Iteration 24/25 | Loss: 0.00076151
Iteration 25/25 | Loss: 0.00076151

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29425323
Iteration 2/25 | Loss: 0.00039109
Iteration 3/25 | Loss: 0.00039106
Iteration 4/25 | Loss: 0.00039106
Iteration 5/25 | Loss: 0.00039106
Iteration 6/25 | Loss: 0.00039106
Iteration 7/25 | Loss: 0.00039106
Iteration 8/25 | Loss: 0.00039106
Iteration 9/25 | Loss: 0.00039106
Iteration 10/25 | Loss: 0.00039106
Iteration 11/25 | Loss: 0.00039106
Iteration 12/25 | Loss: 0.00039106
Iteration 13/25 | Loss: 0.00039106
Iteration 14/25 | Loss: 0.00039106
Iteration 15/25 | Loss: 0.00039106
Iteration 16/25 | Loss: 0.00039106
Iteration 17/25 | Loss: 0.00039106
Iteration 18/25 | Loss: 0.00039106
Iteration 19/25 | Loss: 0.00039106
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003910596133209765, 0.0003910596133209765, 0.0003910596133209765, 0.0003910596133209765, 0.0003910596133209765]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003910596133209765

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039106
Iteration 2/1000 | Loss: 0.00008196
Iteration 3/1000 | Loss: 0.00004108
Iteration 4/1000 | Loss: 0.00003720
Iteration 5/1000 | Loss: 0.00003370
Iteration 6/1000 | Loss: 0.00003248
Iteration 7/1000 | Loss: 0.00003113
Iteration 8/1000 | Loss: 0.00003035
Iteration 9/1000 | Loss: 0.00002984
Iteration 10/1000 | Loss: 0.00002944
Iteration 11/1000 | Loss: 0.00002911
Iteration 12/1000 | Loss: 0.00002887
Iteration 13/1000 | Loss: 0.00002873
Iteration 14/1000 | Loss: 0.00002868
Iteration 15/1000 | Loss: 0.00002861
Iteration 16/1000 | Loss: 0.00002860
Iteration 17/1000 | Loss: 0.00002860
Iteration 18/1000 | Loss: 0.00002856
Iteration 19/1000 | Loss: 0.00002856
Iteration 20/1000 | Loss: 0.00002856
Iteration 21/1000 | Loss: 0.00002855
Iteration 22/1000 | Loss: 0.00002855
Iteration 23/1000 | Loss: 0.00002854
Iteration 24/1000 | Loss: 0.00002853
Iteration 25/1000 | Loss: 0.00002853
Iteration 26/1000 | Loss: 0.00002852
Iteration 27/1000 | Loss: 0.00002852
Iteration 28/1000 | Loss: 0.00002851
Iteration 29/1000 | Loss: 0.00002851
Iteration 30/1000 | Loss: 0.00002851
Iteration 31/1000 | Loss: 0.00002851
Iteration 32/1000 | Loss: 0.00002850
Iteration 33/1000 | Loss: 0.00002850
Iteration 34/1000 | Loss: 0.00002850
Iteration 35/1000 | Loss: 0.00002850
Iteration 36/1000 | Loss: 0.00002849
Iteration 37/1000 | Loss: 0.00002849
Iteration 38/1000 | Loss: 0.00002849
Iteration 39/1000 | Loss: 0.00002849
Iteration 40/1000 | Loss: 0.00002849
Iteration 41/1000 | Loss: 0.00002849
Iteration 42/1000 | Loss: 0.00002849
Iteration 43/1000 | Loss: 0.00002849
Iteration 44/1000 | Loss: 0.00002849
Iteration 45/1000 | Loss: 0.00002848
Iteration 46/1000 | Loss: 0.00002848
Iteration 47/1000 | Loss: 0.00002848
Iteration 48/1000 | Loss: 0.00002848
Iteration 49/1000 | Loss: 0.00002848
Iteration 50/1000 | Loss: 0.00002848
Iteration 51/1000 | Loss: 0.00002847
Iteration 52/1000 | Loss: 0.00002847
Iteration 53/1000 | Loss: 0.00002846
Iteration 54/1000 | Loss: 0.00002846
Iteration 55/1000 | Loss: 0.00002846
Iteration 56/1000 | Loss: 0.00002845
Iteration 57/1000 | Loss: 0.00002845
Iteration 58/1000 | Loss: 0.00002845
Iteration 59/1000 | Loss: 0.00002845
Iteration 60/1000 | Loss: 0.00002845
Iteration 61/1000 | Loss: 0.00002845
Iteration 62/1000 | Loss: 0.00002845
Iteration 63/1000 | Loss: 0.00002844
Iteration 64/1000 | Loss: 0.00002844
Iteration 65/1000 | Loss: 0.00002844
Iteration 66/1000 | Loss: 0.00002844
Iteration 67/1000 | Loss: 0.00002844
Iteration 68/1000 | Loss: 0.00002844
Iteration 69/1000 | Loss: 0.00002843
Iteration 70/1000 | Loss: 0.00002843
Iteration 71/1000 | Loss: 0.00002843
Iteration 72/1000 | Loss: 0.00002843
Iteration 73/1000 | Loss: 0.00002843
Iteration 74/1000 | Loss: 0.00002843
Iteration 75/1000 | Loss: 0.00002843
Iteration 76/1000 | Loss: 0.00002842
Iteration 77/1000 | Loss: 0.00002842
Iteration 78/1000 | Loss: 0.00002842
Iteration 79/1000 | Loss: 0.00002842
Iteration 80/1000 | Loss: 0.00002842
Iteration 81/1000 | Loss: 0.00002842
Iteration 82/1000 | Loss: 0.00002842
Iteration 83/1000 | Loss: 0.00002842
Iteration 84/1000 | Loss: 0.00002842
Iteration 85/1000 | Loss: 0.00002842
Iteration 86/1000 | Loss: 0.00002842
Iteration 87/1000 | Loss: 0.00002842
Iteration 88/1000 | Loss: 0.00002842
Iteration 89/1000 | Loss: 0.00002842
Iteration 90/1000 | Loss: 0.00002842
Iteration 91/1000 | Loss: 0.00002842
Iteration 92/1000 | Loss: 0.00002842
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [2.8423384719644673e-05, 2.8423384719644673e-05, 2.8423384719644673e-05, 2.8423384719644673e-05, 2.8423384719644673e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8423384719644673e-05

Optimization complete. Final v2v error: 4.610079288482666 mm

Highest mean error: 4.9745941162109375 mm for frame 55

Lowest mean error: 4.201512813568115 mm for frame 23

Saving results

Total time: 37.614189863204956
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00874626
Iteration 2/25 | Loss: 0.00078206
Iteration 3/25 | Loss: 0.00066751
Iteration 4/25 | Loss: 0.00064947
Iteration 5/25 | Loss: 0.00064170
Iteration 6/25 | Loss: 0.00064035
Iteration 7/25 | Loss: 0.00064035
Iteration 8/25 | Loss: 0.00064035
Iteration 9/25 | Loss: 0.00064035
Iteration 10/25 | Loss: 0.00064035
Iteration 11/25 | Loss: 0.00064035
Iteration 12/25 | Loss: 0.00064035
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000640345155261457, 0.000640345155261457, 0.000640345155261457, 0.000640345155261457, 0.000640345155261457]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000640345155261457

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32726002
Iteration 2/25 | Loss: 0.00027369
Iteration 3/25 | Loss: 0.00027368
Iteration 4/25 | Loss: 0.00027368
Iteration 5/25 | Loss: 0.00027368
Iteration 6/25 | Loss: 0.00027368
Iteration 7/25 | Loss: 0.00027368
Iteration 8/25 | Loss: 0.00027368
Iteration 9/25 | Loss: 0.00027368
Iteration 10/25 | Loss: 0.00027368
Iteration 11/25 | Loss: 0.00027368
Iteration 12/25 | Loss: 0.00027368
Iteration 13/25 | Loss: 0.00027368
Iteration 14/25 | Loss: 0.00027368
Iteration 15/25 | Loss: 0.00027368
Iteration 16/25 | Loss: 0.00027368
Iteration 17/25 | Loss: 0.00027368
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00027368191513232887, 0.00027368191513232887, 0.00027368191513232887, 0.00027368191513232887, 0.00027368191513232887]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00027368191513232887

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027368
Iteration 2/1000 | Loss: 0.00004117
Iteration 3/1000 | Loss: 0.00003195
Iteration 4/1000 | Loss: 0.00002945
Iteration 5/1000 | Loss: 0.00002660
Iteration 6/1000 | Loss: 0.00002528
Iteration 7/1000 | Loss: 0.00002435
Iteration 8/1000 | Loss: 0.00002383
Iteration 9/1000 | Loss: 0.00002354
Iteration 10/1000 | Loss: 0.00002329
Iteration 11/1000 | Loss: 0.00002311
Iteration 12/1000 | Loss: 0.00002310
Iteration 13/1000 | Loss: 0.00002308
Iteration 14/1000 | Loss: 0.00002307
Iteration 15/1000 | Loss: 0.00002307
Iteration 16/1000 | Loss: 0.00002306
Iteration 17/1000 | Loss: 0.00002305
Iteration 18/1000 | Loss: 0.00002303
Iteration 19/1000 | Loss: 0.00002298
Iteration 20/1000 | Loss: 0.00002295
Iteration 21/1000 | Loss: 0.00002295
Iteration 22/1000 | Loss: 0.00002294
Iteration 23/1000 | Loss: 0.00002294
Iteration 24/1000 | Loss: 0.00002293
Iteration 25/1000 | Loss: 0.00002292
Iteration 26/1000 | Loss: 0.00002292
Iteration 27/1000 | Loss: 0.00002291
Iteration 28/1000 | Loss: 0.00002291
Iteration 29/1000 | Loss: 0.00002290
Iteration 30/1000 | Loss: 0.00002290
Iteration 31/1000 | Loss: 0.00002290
Iteration 32/1000 | Loss: 0.00002290
Iteration 33/1000 | Loss: 0.00002289
Iteration 34/1000 | Loss: 0.00002289
Iteration 35/1000 | Loss: 0.00002289
Iteration 36/1000 | Loss: 0.00002289
Iteration 37/1000 | Loss: 0.00002289
Iteration 38/1000 | Loss: 0.00002288
Iteration 39/1000 | Loss: 0.00002288
Iteration 40/1000 | Loss: 0.00002288
Iteration 41/1000 | Loss: 0.00002287
Iteration 42/1000 | Loss: 0.00002287
Iteration 43/1000 | Loss: 0.00002286
Iteration 44/1000 | Loss: 0.00002286
Iteration 45/1000 | Loss: 0.00002285
Iteration 46/1000 | Loss: 0.00002285
Iteration 47/1000 | Loss: 0.00002285
Iteration 48/1000 | Loss: 0.00002283
Iteration 49/1000 | Loss: 0.00002282
Iteration 50/1000 | Loss: 0.00002282
Iteration 51/1000 | Loss: 0.00002281
Iteration 52/1000 | Loss: 0.00002281
Iteration 53/1000 | Loss: 0.00002280
Iteration 54/1000 | Loss: 0.00002278
Iteration 55/1000 | Loss: 0.00002277
Iteration 56/1000 | Loss: 0.00002277
Iteration 57/1000 | Loss: 0.00002277
Iteration 58/1000 | Loss: 0.00002277
Iteration 59/1000 | Loss: 0.00002277
Iteration 60/1000 | Loss: 0.00002277
Iteration 61/1000 | Loss: 0.00002277
Iteration 62/1000 | Loss: 0.00002277
Iteration 63/1000 | Loss: 0.00002277
Iteration 64/1000 | Loss: 0.00002277
Iteration 65/1000 | Loss: 0.00002277
Iteration 66/1000 | Loss: 0.00002276
Iteration 67/1000 | Loss: 0.00002276
Iteration 68/1000 | Loss: 0.00002276
Iteration 69/1000 | Loss: 0.00002276
Iteration 70/1000 | Loss: 0.00002276
Iteration 71/1000 | Loss: 0.00002276
Iteration 72/1000 | Loss: 0.00002276
Iteration 73/1000 | Loss: 0.00002276
Iteration 74/1000 | Loss: 0.00002276
Iteration 75/1000 | Loss: 0.00002276
Iteration 76/1000 | Loss: 0.00002276
Iteration 77/1000 | Loss: 0.00002276
Iteration 78/1000 | Loss: 0.00002275
Iteration 79/1000 | Loss: 0.00002274
Iteration 80/1000 | Loss: 0.00002274
Iteration 81/1000 | Loss: 0.00002274
Iteration 82/1000 | Loss: 0.00002274
Iteration 83/1000 | Loss: 0.00002274
Iteration 84/1000 | Loss: 0.00002274
Iteration 85/1000 | Loss: 0.00002273
Iteration 86/1000 | Loss: 0.00002273
Iteration 87/1000 | Loss: 0.00002273
Iteration 88/1000 | Loss: 0.00002273
Iteration 89/1000 | Loss: 0.00002273
Iteration 90/1000 | Loss: 0.00002272
Iteration 91/1000 | Loss: 0.00002272
Iteration 92/1000 | Loss: 0.00002272
Iteration 93/1000 | Loss: 0.00002272
Iteration 94/1000 | Loss: 0.00002272
Iteration 95/1000 | Loss: 0.00002272
Iteration 96/1000 | Loss: 0.00002271
Iteration 97/1000 | Loss: 0.00002271
Iteration 98/1000 | Loss: 0.00002271
Iteration 99/1000 | Loss: 0.00002271
Iteration 100/1000 | Loss: 0.00002271
Iteration 101/1000 | Loss: 0.00002271
Iteration 102/1000 | Loss: 0.00002271
Iteration 103/1000 | Loss: 0.00002271
Iteration 104/1000 | Loss: 0.00002271
Iteration 105/1000 | Loss: 0.00002270
Iteration 106/1000 | Loss: 0.00002270
Iteration 107/1000 | Loss: 0.00002270
Iteration 108/1000 | Loss: 0.00002270
Iteration 109/1000 | Loss: 0.00002270
Iteration 110/1000 | Loss: 0.00002270
Iteration 111/1000 | Loss: 0.00002270
Iteration 112/1000 | Loss: 0.00002270
Iteration 113/1000 | Loss: 0.00002269
Iteration 114/1000 | Loss: 0.00002269
Iteration 115/1000 | Loss: 0.00002269
Iteration 116/1000 | Loss: 0.00002269
Iteration 117/1000 | Loss: 0.00002269
Iteration 118/1000 | Loss: 0.00002269
Iteration 119/1000 | Loss: 0.00002269
Iteration 120/1000 | Loss: 0.00002269
Iteration 121/1000 | Loss: 0.00002268
Iteration 122/1000 | Loss: 0.00002268
Iteration 123/1000 | Loss: 0.00002268
Iteration 124/1000 | Loss: 0.00002268
Iteration 125/1000 | Loss: 0.00002268
Iteration 126/1000 | Loss: 0.00002268
Iteration 127/1000 | Loss: 0.00002268
Iteration 128/1000 | Loss: 0.00002268
Iteration 129/1000 | Loss: 0.00002268
Iteration 130/1000 | Loss: 0.00002268
Iteration 131/1000 | Loss: 0.00002267
Iteration 132/1000 | Loss: 0.00002267
Iteration 133/1000 | Loss: 0.00002267
Iteration 134/1000 | Loss: 0.00002267
Iteration 135/1000 | Loss: 0.00002267
Iteration 136/1000 | Loss: 0.00002267
Iteration 137/1000 | Loss: 0.00002266
Iteration 138/1000 | Loss: 0.00002266
Iteration 139/1000 | Loss: 0.00002266
Iteration 140/1000 | Loss: 0.00002266
Iteration 141/1000 | Loss: 0.00002266
Iteration 142/1000 | Loss: 0.00002266
Iteration 143/1000 | Loss: 0.00002266
Iteration 144/1000 | Loss: 0.00002266
Iteration 145/1000 | Loss: 0.00002266
Iteration 146/1000 | Loss: 0.00002266
Iteration 147/1000 | Loss: 0.00002266
Iteration 148/1000 | Loss: 0.00002265
Iteration 149/1000 | Loss: 0.00002265
Iteration 150/1000 | Loss: 0.00002265
Iteration 151/1000 | Loss: 0.00002265
Iteration 152/1000 | Loss: 0.00002265
Iteration 153/1000 | Loss: 0.00002265
Iteration 154/1000 | Loss: 0.00002265
Iteration 155/1000 | Loss: 0.00002265
Iteration 156/1000 | Loss: 0.00002265
Iteration 157/1000 | Loss: 0.00002265
Iteration 158/1000 | Loss: 0.00002265
Iteration 159/1000 | Loss: 0.00002265
Iteration 160/1000 | Loss: 0.00002265
Iteration 161/1000 | Loss: 0.00002265
Iteration 162/1000 | Loss: 0.00002265
Iteration 163/1000 | Loss: 0.00002265
Iteration 164/1000 | Loss: 0.00002265
Iteration 165/1000 | Loss: 0.00002264
Iteration 166/1000 | Loss: 0.00002264
Iteration 167/1000 | Loss: 0.00002264
Iteration 168/1000 | Loss: 0.00002264
Iteration 169/1000 | Loss: 0.00002264
Iteration 170/1000 | Loss: 0.00002264
Iteration 171/1000 | Loss: 0.00002264
Iteration 172/1000 | Loss: 0.00002264
Iteration 173/1000 | Loss: 0.00002264
Iteration 174/1000 | Loss: 0.00002264
Iteration 175/1000 | Loss: 0.00002264
Iteration 176/1000 | Loss: 0.00002264
Iteration 177/1000 | Loss: 0.00002264
Iteration 178/1000 | Loss: 0.00002264
Iteration 179/1000 | Loss: 0.00002263
Iteration 180/1000 | Loss: 0.00002263
Iteration 181/1000 | Loss: 0.00002263
Iteration 182/1000 | Loss: 0.00002263
Iteration 183/1000 | Loss: 0.00002263
Iteration 184/1000 | Loss: 0.00002263
Iteration 185/1000 | Loss: 0.00002263
Iteration 186/1000 | Loss: 0.00002263
Iteration 187/1000 | Loss: 0.00002263
Iteration 188/1000 | Loss: 0.00002263
Iteration 189/1000 | Loss: 0.00002263
Iteration 190/1000 | Loss: 0.00002263
Iteration 191/1000 | Loss: 0.00002262
Iteration 192/1000 | Loss: 0.00002262
Iteration 193/1000 | Loss: 0.00002262
Iteration 194/1000 | Loss: 0.00002262
Iteration 195/1000 | Loss: 0.00002262
Iteration 196/1000 | Loss: 0.00002262
Iteration 197/1000 | Loss: 0.00002262
Iteration 198/1000 | Loss: 0.00002261
Iteration 199/1000 | Loss: 0.00002261
Iteration 200/1000 | Loss: 0.00002261
Iteration 201/1000 | Loss: 0.00002261
Iteration 202/1000 | Loss: 0.00002261
Iteration 203/1000 | Loss: 0.00002261
Iteration 204/1000 | Loss: 0.00002261
Iteration 205/1000 | Loss: 0.00002261
Iteration 206/1000 | Loss: 0.00002261
Iteration 207/1000 | Loss: 0.00002261
Iteration 208/1000 | Loss: 0.00002261
Iteration 209/1000 | Loss: 0.00002261
Iteration 210/1000 | Loss: 0.00002261
Iteration 211/1000 | Loss: 0.00002261
Iteration 212/1000 | Loss: 0.00002261
Iteration 213/1000 | Loss: 0.00002261
Iteration 214/1000 | Loss: 0.00002261
Iteration 215/1000 | Loss: 0.00002261
Iteration 216/1000 | Loss: 0.00002261
Iteration 217/1000 | Loss: 0.00002261
Iteration 218/1000 | Loss: 0.00002261
Iteration 219/1000 | Loss: 0.00002261
Iteration 220/1000 | Loss: 0.00002261
Iteration 221/1000 | Loss: 0.00002261
Iteration 222/1000 | Loss: 0.00002261
Iteration 223/1000 | Loss: 0.00002261
Iteration 224/1000 | Loss: 0.00002261
Iteration 225/1000 | Loss: 0.00002261
Iteration 226/1000 | Loss: 0.00002261
Iteration 227/1000 | Loss: 0.00002261
Iteration 228/1000 | Loss: 0.00002261
Iteration 229/1000 | Loss: 0.00002261
Iteration 230/1000 | Loss: 0.00002261
Iteration 231/1000 | Loss: 0.00002261
Iteration 232/1000 | Loss: 0.00002261
Iteration 233/1000 | Loss: 0.00002261
Iteration 234/1000 | Loss: 0.00002261
Iteration 235/1000 | Loss: 0.00002261
Iteration 236/1000 | Loss: 0.00002261
Iteration 237/1000 | Loss: 0.00002261
Iteration 238/1000 | Loss: 0.00002261
Iteration 239/1000 | Loss: 0.00002261
Iteration 240/1000 | Loss: 0.00002261
Iteration 241/1000 | Loss: 0.00002261
Iteration 242/1000 | Loss: 0.00002261
Iteration 243/1000 | Loss: 0.00002261
Iteration 244/1000 | Loss: 0.00002261
Iteration 245/1000 | Loss: 0.00002261
Iteration 246/1000 | Loss: 0.00002261
Iteration 247/1000 | Loss: 0.00002261
Iteration 248/1000 | Loss: 0.00002261
Iteration 249/1000 | Loss: 0.00002261
Iteration 250/1000 | Loss: 0.00002261
Iteration 251/1000 | Loss: 0.00002261
Iteration 252/1000 | Loss: 0.00002261
Iteration 253/1000 | Loss: 0.00002261
Iteration 254/1000 | Loss: 0.00002261
Iteration 255/1000 | Loss: 0.00002261
Iteration 256/1000 | Loss: 0.00002261
Iteration 257/1000 | Loss: 0.00002261
Iteration 258/1000 | Loss: 0.00002261
Iteration 259/1000 | Loss: 0.00002261
Iteration 260/1000 | Loss: 0.00002261
Iteration 261/1000 | Loss: 0.00002261
Iteration 262/1000 | Loss: 0.00002261
Iteration 263/1000 | Loss: 0.00002261
Iteration 264/1000 | Loss: 0.00002261
Iteration 265/1000 | Loss: 0.00002261
Iteration 266/1000 | Loss: 0.00002261
Iteration 267/1000 | Loss: 0.00002261
Iteration 268/1000 | Loss: 0.00002261
Iteration 269/1000 | Loss: 0.00002261
Iteration 270/1000 | Loss: 0.00002261
Iteration 271/1000 | Loss: 0.00002261
Iteration 272/1000 | Loss: 0.00002261
Iteration 273/1000 | Loss: 0.00002261
Iteration 274/1000 | Loss: 0.00002261
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 274. Stopping optimization.
Last 5 losses: [2.2607468054047786e-05, 2.2607468054047786e-05, 2.2607468054047786e-05, 2.2607468054047786e-05, 2.2607468054047786e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2607468054047786e-05

Optimization complete. Final v2v error: 3.9663920402526855 mm

Highest mean error: 4.57852840423584 mm for frame 100

Lowest mean error: 3.174241065979004 mm for frame 16

Saving results

Total time: 42.22024583816528
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00394342
Iteration 2/25 | Loss: 0.00075878
Iteration 3/25 | Loss: 0.00060760
Iteration 4/25 | Loss: 0.00058983
Iteration 5/25 | Loss: 0.00058539
Iteration 6/25 | Loss: 0.00058394
Iteration 7/25 | Loss: 0.00058359
Iteration 8/25 | Loss: 0.00058359
Iteration 9/25 | Loss: 0.00058359
Iteration 10/25 | Loss: 0.00058359
Iteration 11/25 | Loss: 0.00058359
Iteration 12/25 | Loss: 0.00058359
Iteration 13/25 | Loss: 0.00058359
Iteration 14/25 | Loss: 0.00058359
Iteration 15/25 | Loss: 0.00058359
Iteration 16/25 | Loss: 0.00058359
Iteration 17/25 | Loss: 0.00058359
Iteration 18/25 | Loss: 0.00058359
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005835904739797115, 0.0005835904739797115, 0.0005835904739797115, 0.0005835904739797115, 0.0005835904739797115]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005835904739797115

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32409000
Iteration 2/25 | Loss: 0.00026048
Iteration 3/25 | Loss: 0.00026048
Iteration 4/25 | Loss: 0.00026048
Iteration 5/25 | Loss: 0.00026048
Iteration 6/25 | Loss: 0.00026048
Iteration 7/25 | Loss: 0.00026048
Iteration 8/25 | Loss: 0.00026048
Iteration 9/25 | Loss: 0.00026048
Iteration 10/25 | Loss: 0.00026048
Iteration 11/25 | Loss: 0.00026048
Iteration 12/25 | Loss: 0.00026048
Iteration 13/25 | Loss: 0.00026048
Iteration 14/25 | Loss: 0.00026048
Iteration 15/25 | Loss: 0.00026048
Iteration 16/25 | Loss: 0.00026048
Iteration 17/25 | Loss: 0.00026048
Iteration 18/25 | Loss: 0.00026048
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00026047660503536463, 0.00026047660503536463, 0.00026047660503536463, 0.00026047660503536463, 0.00026047660503536463]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00026047660503536463

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026048
Iteration 2/1000 | Loss: 0.00002762
Iteration 3/1000 | Loss: 0.00001761
Iteration 4/1000 | Loss: 0.00001576
Iteration 5/1000 | Loss: 0.00001468
Iteration 6/1000 | Loss: 0.00001396
Iteration 7/1000 | Loss: 0.00001355
Iteration 8/1000 | Loss: 0.00001332
Iteration 9/1000 | Loss: 0.00001325
Iteration 10/1000 | Loss: 0.00001319
Iteration 11/1000 | Loss: 0.00001317
Iteration 12/1000 | Loss: 0.00001316
Iteration 13/1000 | Loss: 0.00001315
Iteration 14/1000 | Loss: 0.00001315
Iteration 15/1000 | Loss: 0.00001313
Iteration 16/1000 | Loss: 0.00001313
Iteration 17/1000 | Loss: 0.00001312
Iteration 18/1000 | Loss: 0.00001312
Iteration 19/1000 | Loss: 0.00001311
Iteration 20/1000 | Loss: 0.00001311
Iteration 21/1000 | Loss: 0.00001308
Iteration 22/1000 | Loss: 0.00001302
Iteration 23/1000 | Loss: 0.00001302
Iteration 24/1000 | Loss: 0.00001301
Iteration 25/1000 | Loss: 0.00001300
Iteration 26/1000 | Loss: 0.00001299
Iteration 27/1000 | Loss: 0.00001298
Iteration 28/1000 | Loss: 0.00001294
Iteration 29/1000 | Loss: 0.00001292
Iteration 30/1000 | Loss: 0.00001291
Iteration 31/1000 | Loss: 0.00001290
Iteration 32/1000 | Loss: 0.00001290
Iteration 33/1000 | Loss: 0.00001289
Iteration 34/1000 | Loss: 0.00001289
Iteration 35/1000 | Loss: 0.00001289
Iteration 36/1000 | Loss: 0.00001288
Iteration 37/1000 | Loss: 0.00001287
Iteration 38/1000 | Loss: 0.00001287
Iteration 39/1000 | Loss: 0.00001287
Iteration 40/1000 | Loss: 0.00001286
Iteration 41/1000 | Loss: 0.00001286
Iteration 42/1000 | Loss: 0.00001286
Iteration 43/1000 | Loss: 0.00001286
Iteration 44/1000 | Loss: 0.00001285
Iteration 45/1000 | Loss: 0.00001285
Iteration 46/1000 | Loss: 0.00001284
Iteration 47/1000 | Loss: 0.00001284
Iteration 48/1000 | Loss: 0.00001284
Iteration 49/1000 | Loss: 0.00001284
Iteration 50/1000 | Loss: 0.00001284
Iteration 51/1000 | Loss: 0.00001284
Iteration 52/1000 | Loss: 0.00001284
Iteration 53/1000 | Loss: 0.00001284
Iteration 54/1000 | Loss: 0.00001283
Iteration 55/1000 | Loss: 0.00001283
Iteration 56/1000 | Loss: 0.00001282
Iteration 57/1000 | Loss: 0.00001281
Iteration 58/1000 | Loss: 0.00001280
Iteration 59/1000 | Loss: 0.00001280
Iteration 60/1000 | Loss: 0.00001280
Iteration 61/1000 | Loss: 0.00001279
Iteration 62/1000 | Loss: 0.00001277
Iteration 63/1000 | Loss: 0.00001277
Iteration 64/1000 | Loss: 0.00001277
Iteration 65/1000 | Loss: 0.00001276
Iteration 66/1000 | Loss: 0.00001276
Iteration 67/1000 | Loss: 0.00001274
Iteration 68/1000 | Loss: 0.00001273
Iteration 69/1000 | Loss: 0.00001273
Iteration 70/1000 | Loss: 0.00001272
Iteration 71/1000 | Loss: 0.00001272
Iteration 72/1000 | Loss: 0.00001271
Iteration 73/1000 | Loss: 0.00001271
Iteration 74/1000 | Loss: 0.00001271
Iteration 75/1000 | Loss: 0.00001271
Iteration 76/1000 | Loss: 0.00001270
Iteration 77/1000 | Loss: 0.00001270
Iteration 78/1000 | Loss: 0.00001270
Iteration 79/1000 | Loss: 0.00001268
Iteration 80/1000 | Loss: 0.00001268
Iteration 81/1000 | Loss: 0.00001268
Iteration 82/1000 | Loss: 0.00001268
Iteration 83/1000 | Loss: 0.00001267
Iteration 84/1000 | Loss: 0.00001267
Iteration 85/1000 | Loss: 0.00001266
Iteration 86/1000 | Loss: 0.00001266
Iteration 87/1000 | Loss: 0.00001265
Iteration 88/1000 | Loss: 0.00001265
Iteration 89/1000 | Loss: 0.00001265
Iteration 90/1000 | Loss: 0.00001264
Iteration 91/1000 | Loss: 0.00001264
Iteration 92/1000 | Loss: 0.00001264
Iteration 93/1000 | Loss: 0.00001264
Iteration 94/1000 | Loss: 0.00001263
Iteration 95/1000 | Loss: 0.00001263
Iteration 96/1000 | Loss: 0.00001262
Iteration 97/1000 | Loss: 0.00001262
Iteration 98/1000 | Loss: 0.00001262
Iteration 99/1000 | Loss: 0.00001262
Iteration 100/1000 | Loss: 0.00001262
Iteration 101/1000 | Loss: 0.00001261
Iteration 102/1000 | Loss: 0.00001261
Iteration 103/1000 | Loss: 0.00001261
Iteration 104/1000 | Loss: 0.00001261
Iteration 105/1000 | Loss: 0.00001261
Iteration 106/1000 | Loss: 0.00001261
Iteration 107/1000 | Loss: 0.00001261
Iteration 108/1000 | Loss: 0.00001261
Iteration 109/1000 | Loss: 0.00001261
Iteration 110/1000 | Loss: 0.00001261
Iteration 111/1000 | Loss: 0.00001261
Iteration 112/1000 | Loss: 0.00001261
Iteration 113/1000 | Loss: 0.00001261
Iteration 114/1000 | Loss: 0.00001261
Iteration 115/1000 | Loss: 0.00001261
Iteration 116/1000 | Loss: 0.00001260
Iteration 117/1000 | Loss: 0.00001260
Iteration 118/1000 | Loss: 0.00001260
Iteration 119/1000 | Loss: 0.00001260
Iteration 120/1000 | Loss: 0.00001260
Iteration 121/1000 | Loss: 0.00001260
Iteration 122/1000 | Loss: 0.00001260
Iteration 123/1000 | Loss: 0.00001260
Iteration 124/1000 | Loss: 0.00001260
Iteration 125/1000 | Loss: 0.00001259
Iteration 126/1000 | Loss: 0.00001259
Iteration 127/1000 | Loss: 0.00001259
Iteration 128/1000 | Loss: 0.00001259
Iteration 129/1000 | Loss: 0.00001259
Iteration 130/1000 | Loss: 0.00001259
Iteration 131/1000 | Loss: 0.00001259
Iteration 132/1000 | Loss: 0.00001259
Iteration 133/1000 | Loss: 0.00001259
Iteration 134/1000 | Loss: 0.00001259
Iteration 135/1000 | Loss: 0.00001259
Iteration 136/1000 | Loss: 0.00001259
Iteration 137/1000 | Loss: 0.00001259
Iteration 138/1000 | Loss: 0.00001259
Iteration 139/1000 | Loss: 0.00001259
Iteration 140/1000 | Loss: 0.00001259
Iteration 141/1000 | Loss: 0.00001259
Iteration 142/1000 | Loss: 0.00001259
Iteration 143/1000 | Loss: 0.00001259
Iteration 144/1000 | Loss: 0.00001259
Iteration 145/1000 | Loss: 0.00001259
Iteration 146/1000 | Loss: 0.00001259
Iteration 147/1000 | Loss: 0.00001259
Iteration 148/1000 | Loss: 0.00001259
Iteration 149/1000 | Loss: 0.00001259
Iteration 150/1000 | Loss: 0.00001259
Iteration 151/1000 | Loss: 0.00001259
Iteration 152/1000 | Loss: 0.00001259
Iteration 153/1000 | Loss: 0.00001259
Iteration 154/1000 | Loss: 0.00001259
Iteration 155/1000 | Loss: 0.00001259
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 155. Stopping optimization.
Last 5 losses: [1.2587601304403506e-05, 1.2587601304403506e-05, 1.2587601304403506e-05, 1.2587601304403506e-05, 1.2587601304403506e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2587601304403506e-05

Optimization complete. Final v2v error: 3.043369770050049 mm

Highest mean error: 3.6879472732543945 mm for frame 53

Lowest mean error: 2.7312183380126953 mm for frame 150

Saving results

Total time: 35.067676305770874
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00598275
Iteration 2/25 | Loss: 0.00135061
Iteration 3/25 | Loss: 0.00082727
Iteration 4/25 | Loss: 0.00073437
Iteration 5/25 | Loss: 0.00071740
Iteration 6/25 | Loss: 0.00071268
Iteration 7/25 | Loss: 0.00071112
Iteration 8/25 | Loss: 0.00071057
Iteration 9/25 | Loss: 0.00071057
Iteration 10/25 | Loss: 0.00071057
Iteration 11/25 | Loss: 0.00071057
Iteration 12/25 | Loss: 0.00071057
Iteration 13/25 | Loss: 0.00071057
Iteration 14/25 | Loss: 0.00071057
Iteration 15/25 | Loss: 0.00071057
Iteration 16/25 | Loss: 0.00071057
Iteration 17/25 | Loss: 0.00071057
Iteration 18/25 | Loss: 0.00071057
Iteration 19/25 | Loss: 0.00071057
Iteration 20/25 | Loss: 0.00071057
Iteration 21/25 | Loss: 0.00071057
Iteration 22/25 | Loss: 0.00071057
Iteration 23/25 | Loss: 0.00071057
Iteration 24/25 | Loss: 0.00071057
Iteration 25/25 | Loss: 0.00071057

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29230237
Iteration 2/25 | Loss: 0.00034589
Iteration 3/25 | Loss: 0.00034585
Iteration 4/25 | Loss: 0.00034585
Iteration 5/25 | Loss: 0.00034585
Iteration 6/25 | Loss: 0.00034585
Iteration 7/25 | Loss: 0.00034585
Iteration 8/25 | Loss: 0.00034585
Iteration 9/25 | Loss: 0.00034585
Iteration 10/25 | Loss: 0.00034585
Iteration 11/25 | Loss: 0.00034585
Iteration 12/25 | Loss: 0.00034585
Iteration 13/25 | Loss: 0.00034585
Iteration 14/25 | Loss: 0.00034585
Iteration 15/25 | Loss: 0.00034585
Iteration 16/25 | Loss: 0.00034585
Iteration 17/25 | Loss: 0.00034585
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00034585202229209244, 0.00034585202229209244, 0.00034585202229209244, 0.00034585202229209244, 0.00034585202229209244]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00034585202229209244

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034585
Iteration 2/1000 | Loss: 0.00005946
Iteration 3/1000 | Loss: 0.00004019
Iteration 4/1000 | Loss: 0.00003240
Iteration 5/1000 | Loss: 0.00002938
Iteration 6/1000 | Loss: 0.00002741
Iteration 7/1000 | Loss: 0.00002628
Iteration 8/1000 | Loss: 0.00002555
Iteration 9/1000 | Loss: 0.00002517
Iteration 10/1000 | Loss: 0.00002489
Iteration 11/1000 | Loss: 0.00002459
Iteration 12/1000 | Loss: 0.00002455
Iteration 13/1000 | Loss: 0.00002447
Iteration 14/1000 | Loss: 0.00002429
Iteration 15/1000 | Loss: 0.00002424
Iteration 16/1000 | Loss: 0.00002424
Iteration 17/1000 | Loss: 0.00002423
Iteration 18/1000 | Loss: 0.00002422
Iteration 19/1000 | Loss: 0.00002422
Iteration 20/1000 | Loss: 0.00002421
Iteration 21/1000 | Loss: 0.00002421
Iteration 22/1000 | Loss: 0.00002420
Iteration 23/1000 | Loss: 0.00002420
Iteration 24/1000 | Loss: 0.00002419
Iteration 25/1000 | Loss: 0.00002419
Iteration 26/1000 | Loss: 0.00002419
Iteration 27/1000 | Loss: 0.00002419
Iteration 28/1000 | Loss: 0.00002419
Iteration 29/1000 | Loss: 0.00002418
Iteration 30/1000 | Loss: 0.00002418
Iteration 31/1000 | Loss: 0.00002417
Iteration 32/1000 | Loss: 0.00002415
Iteration 33/1000 | Loss: 0.00002414
Iteration 34/1000 | Loss: 0.00002413
Iteration 35/1000 | Loss: 0.00002412
Iteration 36/1000 | Loss: 0.00002412
Iteration 37/1000 | Loss: 0.00002411
Iteration 38/1000 | Loss: 0.00002411
Iteration 39/1000 | Loss: 0.00002410
Iteration 40/1000 | Loss: 0.00002409
Iteration 41/1000 | Loss: 0.00002409
Iteration 42/1000 | Loss: 0.00002409
Iteration 43/1000 | Loss: 0.00002408
Iteration 44/1000 | Loss: 0.00002408
Iteration 45/1000 | Loss: 0.00002407
Iteration 46/1000 | Loss: 0.00002406
Iteration 47/1000 | Loss: 0.00002406
Iteration 48/1000 | Loss: 0.00002405
Iteration 49/1000 | Loss: 0.00002405
Iteration 50/1000 | Loss: 0.00002404
Iteration 51/1000 | Loss: 0.00002404
Iteration 52/1000 | Loss: 0.00002404
Iteration 53/1000 | Loss: 0.00002403
Iteration 54/1000 | Loss: 0.00002403
Iteration 55/1000 | Loss: 0.00002403
Iteration 56/1000 | Loss: 0.00002402
Iteration 57/1000 | Loss: 0.00002402
Iteration 58/1000 | Loss: 0.00002401
Iteration 59/1000 | Loss: 0.00002401
Iteration 60/1000 | Loss: 0.00002401
Iteration 61/1000 | Loss: 0.00002401
Iteration 62/1000 | Loss: 0.00002400
Iteration 63/1000 | Loss: 0.00002400
Iteration 64/1000 | Loss: 0.00002400
Iteration 65/1000 | Loss: 0.00002400
Iteration 66/1000 | Loss: 0.00002400
Iteration 67/1000 | Loss: 0.00002400
Iteration 68/1000 | Loss: 0.00002400
Iteration 69/1000 | Loss: 0.00002400
Iteration 70/1000 | Loss: 0.00002400
Iteration 71/1000 | Loss: 0.00002400
Iteration 72/1000 | Loss: 0.00002400
Iteration 73/1000 | Loss: 0.00002400
Iteration 74/1000 | Loss: 0.00002400
Iteration 75/1000 | Loss: 0.00002400
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 75. Stopping optimization.
Last 5 losses: [2.4003489670576528e-05, 2.4003489670576528e-05, 2.4003489670576528e-05, 2.4003489670576528e-05, 2.4003489670576528e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4003489670576528e-05

Optimization complete. Final v2v error: 4.217189788818359 mm

Highest mean error: 4.491119384765625 mm for frame 121

Lowest mean error: 3.8102517127990723 mm for frame 0

Saving results

Total time: 34.17806124687195
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00384714
Iteration 2/25 | Loss: 0.00072604
Iteration 3/25 | Loss: 0.00064152
Iteration 4/25 | Loss: 0.00062409
Iteration 5/25 | Loss: 0.00061853
Iteration 6/25 | Loss: 0.00061732
Iteration 7/25 | Loss: 0.00061732
Iteration 8/25 | Loss: 0.00061732
Iteration 9/25 | Loss: 0.00061732
Iteration 10/25 | Loss: 0.00061732
Iteration 11/25 | Loss: 0.00061732
Iteration 12/25 | Loss: 0.00061732
Iteration 13/25 | Loss: 0.00061732
Iteration 14/25 | Loss: 0.00061732
Iteration 15/25 | Loss: 0.00061732
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0006173248984850943, 0.0006173248984850943, 0.0006173248984850943, 0.0006173248984850943, 0.0006173248984850943]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006173248984850943

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.47316337
Iteration 2/25 | Loss: 0.00025242
Iteration 3/25 | Loss: 0.00025241
Iteration 4/25 | Loss: 0.00025241
Iteration 5/25 | Loss: 0.00025241
Iteration 6/25 | Loss: 0.00025241
Iteration 7/25 | Loss: 0.00025241
Iteration 8/25 | Loss: 0.00025241
Iteration 9/25 | Loss: 0.00025241
Iteration 10/25 | Loss: 0.00025241
Iteration 11/25 | Loss: 0.00025241
Iteration 12/25 | Loss: 0.00025241
Iteration 13/25 | Loss: 0.00025241
Iteration 14/25 | Loss: 0.00025241
Iteration 15/25 | Loss: 0.00025241
Iteration 16/25 | Loss: 0.00025241
Iteration 17/25 | Loss: 0.00025241
Iteration 18/25 | Loss: 0.00025241
Iteration 19/25 | Loss: 0.00025241
Iteration 20/25 | Loss: 0.00025241
Iteration 21/25 | Loss: 0.00025241
Iteration 22/25 | Loss: 0.00025241
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0002524106530472636, 0.0002524106530472636, 0.0002524106530472636, 0.0002524106530472636, 0.0002524106530472636]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002524106530472636

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00025241
Iteration 2/1000 | Loss: 0.00003502
Iteration 3/1000 | Loss: 0.00002748
Iteration 4/1000 | Loss: 0.00002486
Iteration 5/1000 | Loss: 0.00002268
Iteration 6/1000 | Loss: 0.00002117
Iteration 7/1000 | Loss: 0.00002041
Iteration 8/1000 | Loss: 0.00002002
Iteration 9/1000 | Loss: 0.00001978
Iteration 10/1000 | Loss: 0.00001954
Iteration 11/1000 | Loss: 0.00001936
Iteration 12/1000 | Loss: 0.00001935
Iteration 13/1000 | Loss: 0.00001931
Iteration 14/1000 | Loss: 0.00001929
Iteration 15/1000 | Loss: 0.00001923
Iteration 16/1000 | Loss: 0.00001923
Iteration 17/1000 | Loss: 0.00001917
Iteration 18/1000 | Loss: 0.00001916
Iteration 19/1000 | Loss: 0.00001909
Iteration 20/1000 | Loss: 0.00001908
Iteration 21/1000 | Loss: 0.00001904
Iteration 22/1000 | Loss: 0.00001903
Iteration 23/1000 | Loss: 0.00001903
Iteration 24/1000 | Loss: 0.00001902
Iteration 25/1000 | Loss: 0.00001897
Iteration 26/1000 | Loss: 0.00001896
Iteration 27/1000 | Loss: 0.00001896
Iteration 28/1000 | Loss: 0.00001893
Iteration 29/1000 | Loss: 0.00001892
Iteration 30/1000 | Loss: 0.00001892
Iteration 31/1000 | Loss: 0.00001892
Iteration 32/1000 | Loss: 0.00001892
Iteration 33/1000 | Loss: 0.00001891
Iteration 34/1000 | Loss: 0.00001891
Iteration 35/1000 | Loss: 0.00001891
Iteration 36/1000 | Loss: 0.00001890
Iteration 37/1000 | Loss: 0.00001890
Iteration 38/1000 | Loss: 0.00001890
Iteration 39/1000 | Loss: 0.00001890
Iteration 40/1000 | Loss: 0.00001889
Iteration 41/1000 | Loss: 0.00001889
Iteration 42/1000 | Loss: 0.00001889
Iteration 43/1000 | Loss: 0.00001889
Iteration 44/1000 | Loss: 0.00001889
Iteration 45/1000 | Loss: 0.00001889
Iteration 46/1000 | Loss: 0.00001889
Iteration 47/1000 | Loss: 0.00001888
Iteration 48/1000 | Loss: 0.00001888
Iteration 49/1000 | Loss: 0.00001888
Iteration 50/1000 | Loss: 0.00001888
Iteration 51/1000 | Loss: 0.00001888
Iteration 52/1000 | Loss: 0.00001888
Iteration 53/1000 | Loss: 0.00001887
Iteration 54/1000 | Loss: 0.00001887
Iteration 55/1000 | Loss: 0.00001887
Iteration 56/1000 | Loss: 0.00001887
Iteration 57/1000 | Loss: 0.00001886
Iteration 58/1000 | Loss: 0.00001886
Iteration 59/1000 | Loss: 0.00001886
Iteration 60/1000 | Loss: 0.00001886
Iteration 61/1000 | Loss: 0.00001886
Iteration 62/1000 | Loss: 0.00001885
Iteration 63/1000 | Loss: 0.00001885
Iteration 64/1000 | Loss: 0.00001885
Iteration 65/1000 | Loss: 0.00001885
Iteration 66/1000 | Loss: 0.00001885
Iteration 67/1000 | Loss: 0.00001885
Iteration 68/1000 | Loss: 0.00001885
Iteration 69/1000 | Loss: 0.00001885
Iteration 70/1000 | Loss: 0.00001885
Iteration 71/1000 | Loss: 0.00001884
Iteration 72/1000 | Loss: 0.00001884
Iteration 73/1000 | Loss: 0.00001884
Iteration 74/1000 | Loss: 0.00001884
Iteration 75/1000 | Loss: 0.00001883
Iteration 76/1000 | Loss: 0.00001883
Iteration 77/1000 | Loss: 0.00001883
Iteration 78/1000 | Loss: 0.00001883
Iteration 79/1000 | Loss: 0.00001883
Iteration 80/1000 | Loss: 0.00001883
Iteration 81/1000 | Loss: 0.00001883
Iteration 82/1000 | Loss: 0.00001882
Iteration 83/1000 | Loss: 0.00001882
Iteration 84/1000 | Loss: 0.00001882
Iteration 85/1000 | Loss: 0.00001882
Iteration 86/1000 | Loss: 0.00001881
Iteration 87/1000 | Loss: 0.00001881
Iteration 88/1000 | Loss: 0.00001881
Iteration 89/1000 | Loss: 0.00001881
Iteration 90/1000 | Loss: 0.00001880
Iteration 91/1000 | Loss: 0.00001880
Iteration 92/1000 | Loss: 0.00001880
Iteration 93/1000 | Loss: 0.00001880
Iteration 94/1000 | Loss: 0.00001880
Iteration 95/1000 | Loss: 0.00001880
Iteration 96/1000 | Loss: 0.00001880
Iteration 97/1000 | Loss: 0.00001880
Iteration 98/1000 | Loss: 0.00001880
Iteration 99/1000 | Loss: 0.00001880
Iteration 100/1000 | Loss: 0.00001879
Iteration 101/1000 | Loss: 0.00001879
Iteration 102/1000 | Loss: 0.00001879
Iteration 103/1000 | Loss: 0.00001879
Iteration 104/1000 | Loss: 0.00001879
Iteration 105/1000 | Loss: 0.00001879
Iteration 106/1000 | Loss: 0.00001879
Iteration 107/1000 | Loss: 0.00001879
Iteration 108/1000 | Loss: 0.00001879
Iteration 109/1000 | Loss: 0.00001879
Iteration 110/1000 | Loss: 0.00001879
Iteration 111/1000 | Loss: 0.00001879
Iteration 112/1000 | Loss: 0.00001879
Iteration 113/1000 | Loss: 0.00001879
Iteration 114/1000 | Loss: 0.00001879
Iteration 115/1000 | Loss: 0.00001879
Iteration 116/1000 | Loss: 0.00001879
Iteration 117/1000 | Loss: 0.00001879
Iteration 118/1000 | Loss: 0.00001879
Iteration 119/1000 | Loss: 0.00001879
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [1.878575494629331e-05, 1.878575494629331e-05, 1.878575494629331e-05, 1.878575494629331e-05, 1.878575494629331e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.878575494629331e-05

Optimization complete. Final v2v error: 3.719604969024658 mm

Highest mean error: 3.893751621246338 mm for frame 78

Lowest mean error: 3.561235189437866 mm for frame 136

Saving results

Total time: 36.00677251815796
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00374257
Iteration 2/25 | Loss: 0.00091387
Iteration 3/25 | Loss: 0.00075325
Iteration 4/25 | Loss: 0.00071841
Iteration 5/25 | Loss: 0.00070909
Iteration 6/25 | Loss: 0.00070782
Iteration 7/25 | Loss: 0.00070736
Iteration 8/25 | Loss: 0.00070736
Iteration 9/25 | Loss: 0.00070736
Iteration 10/25 | Loss: 0.00070736
Iteration 11/25 | Loss: 0.00070736
Iteration 12/25 | Loss: 0.00070736
Iteration 13/25 | Loss: 0.00070736
Iteration 14/25 | Loss: 0.00070736
Iteration 15/25 | Loss: 0.00070736
Iteration 16/25 | Loss: 0.00070736
Iteration 17/25 | Loss: 0.00070736
Iteration 18/25 | Loss: 0.00070736
Iteration 19/25 | Loss: 0.00070736
Iteration 20/25 | Loss: 0.00070736
Iteration 21/25 | Loss: 0.00070736
Iteration 22/25 | Loss: 0.00070736
Iteration 23/25 | Loss: 0.00070736
Iteration 24/25 | Loss: 0.00070736
Iteration 25/25 | Loss: 0.00070736

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27515399
Iteration 2/25 | Loss: 0.00034219
Iteration 3/25 | Loss: 0.00034219
Iteration 4/25 | Loss: 0.00034219
Iteration 5/25 | Loss: 0.00034219
Iteration 6/25 | Loss: 0.00034219
Iteration 7/25 | Loss: 0.00034219
Iteration 8/25 | Loss: 0.00034219
Iteration 9/25 | Loss: 0.00034219
Iteration 10/25 | Loss: 0.00034219
Iteration 11/25 | Loss: 0.00034219
Iteration 12/25 | Loss: 0.00034219
Iteration 13/25 | Loss: 0.00034219
Iteration 14/25 | Loss: 0.00034219
Iteration 15/25 | Loss: 0.00034219
Iteration 16/25 | Loss: 0.00034219
Iteration 17/25 | Loss: 0.00034219
Iteration 18/25 | Loss: 0.00034219
Iteration 19/25 | Loss: 0.00034219
Iteration 20/25 | Loss: 0.00034219
Iteration 21/25 | Loss: 0.00034219
Iteration 22/25 | Loss: 0.00034219
Iteration 23/25 | Loss: 0.00034219
Iteration 24/25 | Loss: 0.00034219
Iteration 25/25 | Loss: 0.00034219
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00034218523069284856, 0.00034218523069284856, 0.00034218523069284856, 0.00034218523069284856, 0.00034218523069284856]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00034218523069284856

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034219
Iteration 2/1000 | Loss: 0.00007988
Iteration 3/1000 | Loss: 0.00005502
Iteration 4/1000 | Loss: 0.00004441
Iteration 5/1000 | Loss: 0.00003927
Iteration 6/1000 | Loss: 0.00003653
Iteration 7/1000 | Loss: 0.00003465
Iteration 8/1000 | Loss: 0.00003357
Iteration 9/1000 | Loss: 0.00003242
Iteration 10/1000 | Loss: 0.00003186
Iteration 11/1000 | Loss: 0.00003134
Iteration 12/1000 | Loss: 0.00003102
Iteration 13/1000 | Loss: 0.00003075
Iteration 14/1000 | Loss: 0.00003045
Iteration 15/1000 | Loss: 0.00003027
Iteration 16/1000 | Loss: 0.00003018
Iteration 17/1000 | Loss: 0.00003010
Iteration 18/1000 | Loss: 0.00002997
Iteration 19/1000 | Loss: 0.00002995
Iteration 20/1000 | Loss: 0.00002992
Iteration 21/1000 | Loss: 0.00002992
Iteration 22/1000 | Loss: 0.00002992
Iteration 23/1000 | Loss: 0.00002991
Iteration 24/1000 | Loss: 0.00002990
Iteration 25/1000 | Loss: 0.00002986
Iteration 26/1000 | Loss: 0.00002984
Iteration 27/1000 | Loss: 0.00002983
Iteration 28/1000 | Loss: 0.00002983
Iteration 29/1000 | Loss: 0.00002983
Iteration 30/1000 | Loss: 0.00002982
Iteration 31/1000 | Loss: 0.00002981
Iteration 32/1000 | Loss: 0.00002981
Iteration 33/1000 | Loss: 0.00002981
Iteration 34/1000 | Loss: 0.00002980
Iteration 35/1000 | Loss: 0.00002980
Iteration 36/1000 | Loss: 0.00002979
Iteration 37/1000 | Loss: 0.00002979
Iteration 38/1000 | Loss: 0.00002979
Iteration 39/1000 | Loss: 0.00002978
Iteration 40/1000 | Loss: 0.00002978
Iteration 41/1000 | Loss: 0.00002977
Iteration 42/1000 | Loss: 0.00002977
Iteration 43/1000 | Loss: 0.00002976
Iteration 44/1000 | Loss: 0.00002976
Iteration 45/1000 | Loss: 0.00002975
Iteration 46/1000 | Loss: 0.00002973
Iteration 47/1000 | Loss: 0.00002972
Iteration 48/1000 | Loss: 0.00002971
Iteration 49/1000 | Loss: 0.00002971
Iteration 50/1000 | Loss: 0.00002971
Iteration 51/1000 | Loss: 0.00002970
Iteration 52/1000 | Loss: 0.00002967
Iteration 53/1000 | Loss: 0.00002965
Iteration 54/1000 | Loss: 0.00002964
Iteration 55/1000 | Loss: 0.00002964
Iteration 56/1000 | Loss: 0.00002964
Iteration 57/1000 | Loss: 0.00002963
Iteration 58/1000 | Loss: 0.00002963
Iteration 59/1000 | Loss: 0.00002963
Iteration 60/1000 | Loss: 0.00002962
Iteration 61/1000 | Loss: 0.00002961
Iteration 62/1000 | Loss: 0.00002960
Iteration 63/1000 | Loss: 0.00002960
Iteration 64/1000 | Loss: 0.00002959
Iteration 65/1000 | Loss: 0.00002959
Iteration 66/1000 | Loss: 0.00002958
Iteration 67/1000 | Loss: 0.00002958
Iteration 68/1000 | Loss: 0.00002958
Iteration 69/1000 | Loss: 0.00002957
Iteration 70/1000 | Loss: 0.00002957
Iteration 71/1000 | Loss: 0.00002956
Iteration 72/1000 | Loss: 0.00002956
Iteration 73/1000 | Loss: 0.00002955
Iteration 74/1000 | Loss: 0.00002955
Iteration 75/1000 | Loss: 0.00002955
Iteration 76/1000 | Loss: 0.00002955
Iteration 77/1000 | Loss: 0.00002954
Iteration 78/1000 | Loss: 0.00002954
Iteration 79/1000 | Loss: 0.00002954
Iteration 80/1000 | Loss: 0.00002954
Iteration 81/1000 | Loss: 0.00002954
Iteration 82/1000 | Loss: 0.00002954
Iteration 83/1000 | Loss: 0.00002954
Iteration 84/1000 | Loss: 0.00002953
Iteration 85/1000 | Loss: 0.00002953
Iteration 86/1000 | Loss: 0.00002953
Iteration 87/1000 | Loss: 0.00002952
Iteration 88/1000 | Loss: 0.00002952
Iteration 89/1000 | Loss: 0.00002952
Iteration 90/1000 | Loss: 0.00002952
Iteration 91/1000 | Loss: 0.00002951
Iteration 92/1000 | Loss: 0.00002951
Iteration 93/1000 | Loss: 0.00002951
Iteration 94/1000 | Loss: 0.00002951
Iteration 95/1000 | Loss: 0.00002951
Iteration 96/1000 | Loss: 0.00002950
Iteration 97/1000 | Loss: 0.00002950
Iteration 98/1000 | Loss: 0.00002950
Iteration 99/1000 | Loss: 0.00002950
Iteration 100/1000 | Loss: 0.00002949
Iteration 101/1000 | Loss: 0.00002949
Iteration 102/1000 | Loss: 0.00002949
Iteration 103/1000 | Loss: 0.00002949
Iteration 104/1000 | Loss: 0.00002949
Iteration 105/1000 | Loss: 0.00002949
Iteration 106/1000 | Loss: 0.00002949
Iteration 107/1000 | Loss: 0.00002949
Iteration 108/1000 | Loss: 0.00002949
Iteration 109/1000 | Loss: 0.00002949
Iteration 110/1000 | Loss: 0.00002948
Iteration 111/1000 | Loss: 0.00002948
Iteration 112/1000 | Loss: 0.00002948
Iteration 113/1000 | Loss: 0.00002948
Iteration 114/1000 | Loss: 0.00002948
Iteration 115/1000 | Loss: 0.00002948
Iteration 116/1000 | Loss: 0.00002947
Iteration 117/1000 | Loss: 0.00002947
Iteration 118/1000 | Loss: 0.00002947
Iteration 119/1000 | Loss: 0.00002947
Iteration 120/1000 | Loss: 0.00002947
Iteration 121/1000 | Loss: 0.00002946
Iteration 122/1000 | Loss: 0.00002946
Iteration 123/1000 | Loss: 0.00002946
Iteration 124/1000 | Loss: 0.00002945
Iteration 125/1000 | Loss: 0.00002945
Iteration 126/1000 | Loss: 0.00002945
Iteration 127/1000 | Loss: 0.00002945
Iteration 128/1000 | Loss: 0.00002944
Iteration 129/1000 | Loss: 0.00002944
Iteration 130/1000 | Loss: 0.00002944
Iteration 131/1000 | Loss: 0.00002944
Iteration 132/1000 | Loss: 0.00002944
Iteration 133/1000 | Loss: 0.00002943
Iteration 134/1000 | Loss: 0.00002943
Iteration 135/1000 | Loss: 0.00002943
Iteration 136/1000 | Loss: 0.00002943
Iteration 137/1000 | Loss: 0.00002943
Iteration 138/1000 | Loss: 0.00002943
Iteration 139/1000 | Loss: 0.00002943
Iteration 140/1000 | Loss: 0.00002942
Iteration 141/1000 | Loss: 0.00002942
Iteration 142/1000 | Loss: 0.00002942
Iteration 143/1000 | Loss: 0.00002942
Iteration 144/1000 | Loss: 0.00002942
Iteration 145/1000 | Loss: 0.00002942
Iteration 146/1000 | Loss: 0.00002942
Iteration 147/1000 | Loss: 0.00002942
Iteration 148/1000 | Loss: 0.00002942
Iteration 149/1000 | Loss: 0.00002942
Iteration 150/1000 | Loss: 0.00002942
Iteration 151/1000 | Loss: 0.00002942
Iteration 152/1000 | Loss: 0.00002941
Iteration 153/1000 | Loss: 0.00002941
Iteration 154/1000 | Loss: 0.00002941
Iteration 155/1000 | Loss: 0.00002941
Iteration 156/1000 | Loss: 0.00002941
Iteration 157/1000 | Loss: 0.00002941
Iteration 158/1000 | Loss: 0.00002940
Iteration 159/1000 | Loss: 0.00002940
Iteration 160/1000 | Loss: 0.00002940
Iteration 161/1000 | Loss: 0.00002940
Iteration 162/1000 | Loss: 0.00002940
Iteration 163/1000 | Loss: 0.00002940
Iteration 164/1000 | Loss: 0.00002940
Iteration 165/1000 | Loss: 0.00002939
Iteration 166/1000 | Loss: 0.00002939
Iteration 167/1000 | Loss: 0.00002939
Iteration 168/1000 | Loss: 0.00002939
Iteration 169/1000 | Loss: 0.00002939
Iteration 170/1000 | Loss: 0.00002939
Iteration 171/1000 | Loss: 0.00002939
Iteration 172/1000 | Loss: 0.00002939
Iteration 173/1000 | Loss: 0.00002939
Iteration 174/1000 | Loss: 0.00002939
Iteration 175/1000 | Loss: 0.00002939
Iteration 176/1000 | Loss: 0.00002939
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 176. Stopping optimization.
Last 5 losses: [2.9390039344434626e-05, 2.9390039344434626e-05, 2.9390039344434626e-05, 2.9390039344434626e-05, 2.9390039344434626e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9390039344434626e-05

Optimization complete. Final v2v error: 4.523303508758545 mm

Highest mean error: 5.409082889556885 mm for frame 112

Lowest mean error: 3.762305498123169 mm for frame 100

Saving results

Total time: 48.13061285018921
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00914633
Iteration 2/25 | Loss: 0.00261382
Iteration 3/25 | Loss: 0.00137536
Iteration 4/25 | Loss: 0.00108430
Iteration 5/25 | Loss: 0.00102337
Iteration 6/25 | Loss: 0.00101182
Iteration 7/25 | Loss: 0.00102231
Iteration 8/25 | Loss: 0.00101363
Iteration 9/25 | Loss: 0.00100051
Iteration 10/25 | Loss: 0.00098898
Iteration 11/25 | Loss: 0.00096628
Iteration 12/25 | Loss: 0.00095339
Iteration 13/25 | Loss: 0.00094695
Iteration 14/25 | Loss: 0.00094454
Iteration 15/25 | Loss: 0.00094137
Iteration 16/25 | Loss: 0.00093572
Iteration 17/25 | Loss: 0.00093741
Iteration 18/25 | Loss: 0.00093846
Iteration 19/25 | Loss: 0.00093571
Iteration 20/25 | Loss: 0.00093017
Iteration 21/25 | Loss: 0.00093117
Iteration 22/25 | Loss: 0.00093263
Iteration 23/25 | Loss: 0.00092794
Iteration 24/25 | Loss: 0.00092667
Iteration 25/25 | Loss: 0.00092607

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.98893213
Iteration 2/25 | Loss: 0.00429405
Iteration 3/25 | Loss: 0.00402930
Iteration 4/25 | Loss: 0.00402930
Iteration 5/25 | Loss: 0.00402930
Iteration 6/25 | Loss: 0.00402930
Iteration 7/25 | Loss: 0.00402930
Iteration 8/25 | Loss: 0.00402930
Iteration 9/25 | Loss: 0.00402930
Iteration 10/25 | Loss: 0.00402930
Iteration 11/25 | Loss: 0.00402930
Iteration 12/25 | Loss: 0.00402930
Iteration 13/25 | Loss: 0.00402930
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.004029299132525921, 0.004029299132525921, 0.004029299132525921, 0.004029299132525921, 0.004029299132525921]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004029299132525921

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00402930
Iteration 2/1000 | Loss: 0.00191146
Iteration 3/1000 | Loss: 0.00238937
Iteration 4/1000 | Loss: 0.00502804
Iteration 5/1000 | Loss: 0.00172502
Iteration 6/1000 | Loss: 0.00626621
Iteration 7/1000 | Loss: 0.00268042
Iteration 8/1000 | Loss: 0.00272901
Iteration 9/1000 | Loss: 0.00172943
Iteration 10/1000 | Loss: 0.00175432
Iteration 11/1000 | Loss: 0.00331062
Iteration 12/1000 | Loss: 0.00129251
Iteration 13/1000 | Loss: 0.00015267
Iteration 14/1000 | Loss: 0.00013504
Iteration 15/1000 | Loss: 0.00116374
Iteration 16/1000 | Loss: 0.00107907
Iteration 17/1000 | Loss: 0.00021600
Iteration 18/1000 | Loss: 0.00047377
Iteration 19/1000 | Loss: 0.00030148
Iteration 20/1000 | Loss: 0.00010572
Iteration 21/1000 | Loss: 0.00009418
Iteration 22/1000 | Loss: 0.00006674
Iteration 23/1000 | Loss: 0.00010661
Iteration 24/1000 | Loss: 0.00008945
Iteration 25/1000 | Loss: 0.00005780
Iteration 26/1000 | Loss: 0.00019273
Iteration 27/1000 | Loss: 0.00023378
Iteration 28/1000 | Loss: 0.00008100
Iteration 29/1000 | Loss: 0.00022883
Iteration 30/1000 | Loss: 0.00060350
Iteration 31/1000 | Loss: 0.00007296
Iteration 32/1000 | Loss: 0.00005041
Iteration 33/1000 | Loss: 0.00062543
Iteration 34/1000 | Loss: 0.00005512
Iteration 35/1000 | Loss: 0.00004177
Iteration 36/1000 | Loss: 0.00005145
Iteration 37/1000 | Loss: 0.00005383
Iteration 38/1000 | Loss: 0.00004909
Iteration 39/1000 | Loss: 0.00064339
Iteration 40/1000 | Loss: 0.00004114
Iteration 41/1000 | Loss: 0.00004188
Iteration 42/1000 | Loss: 0.00079391
Iteration 43/1000 | Loss: 0.00055486
Iteration 44/1000 | Loss: 0.00004508
Iteration 45/1000 | Loss: 0.00002946
Iteration 46/1000 | Loss: 0.00042288
Iteration 47/1000 | Loss: 0.00018896
Iteration 48/1000 | Loss: 0.00006631
Iteration 49/1000 | Loss: 0.00004521
Iteration 50/1000 | Loss: 0.00004567
Iteration 51/1000 | Loss: 0.00004296
Iteration 52/1000 | Loss: 0.00004217
Iteration 53/1000 | Loss: 0.00003115
Iteration 54/1000 | Loss: 0.00005668
Iteration 55/1000 | Loss: 0.00002597
Iteration 56/1000 | Loss: 0.00004160
Iteration 57/1000 | Loss: 0.00004134
Iteration 58/1000 | Loss: 0.00004059
Iteration 59/1000 | Loss: 0.00004449
Iteration 60/1000 | Loss: 0.00004010
Iteration 61/1000 | Loss: 0.00018609
Iteration 62/1000 | Loss: 0.00004073
Iteration 63/1000 | Loss: 0.00004058
Iteration 64/1000 | Loss: 0.00008480
Iteration 65/1000 | Loss: 0.00003854
Iteration 66/1000 | Loss: 0.00004043
Iteration 67/1000 | Loss: 0.00004851
Iteration 68/1000 | Loss: 0.00006482
Iteration 69/1000 | Loss: 0.00004254
Iteration 70/1000 | Loss: 0.00004236
Iteration 71/1000 | Loss: 0.00006768
Iteration 72/1000 | Loss: 0.00008639
Iteration 73/1000 | Loss: 0.00003564
Iteration 74/1000 | Loss: 0.00003940
Iteration 75/1000 | Loss: 0.00004002
Iteration 76/1000 | Loss: 0.00004198
Iteration 77/1000 | Loss: 0.00006607
Iteration 78/1000 | Loss: 0.00006092
Iteration 79/1000 | Loss: 0.00002976
Iteration 80/1000 | Loss: 0.00002415
Iteration 81/1000 | Loss: 0.00002256
Iteration 82/1000 | Loss: 0.00012537
Iteration 83/1000 | Loss: 0.00002797
Iteration 84/1000 | Loss: 0.00002402
Iteration 85/1000 | Loss: 0.00002165
Iteration 86/1000 | Loss: 0.00002100
Iteration 87/1000 | Loss: 0.00002043
Iteration 88/1000 | Loss: 0.00010276
Iteration 89/1000 | Loss: 0.00005458
Iteration 90/1000 | Loss: 0.00002048
Iteration 91/1000 | Loss: 0.00001987
Iteration 92/1000 | Loss: 0.00010771
Iteration 93/1000 | Loss: 0.00004274
Iteration 94/1000 | Loss: 0.00001971
Iteration 95/1000 | Loss: 0.00011521
Iteration 96/1000 | Loss: 0.00006471
Iteration 97/1000 | Loss: 0.00002020
Iteration 98/1000 | Loss: 0.00001942
Iteration 99/1000 | Loss: 0.00015022
Iteration 100/1000 | Loss: 0.00008532
Iteration 101/1000 | Loss: 0.00002006
Iteration 102/1000 | Loss: 0.00016034
Iteration 103/1000 | Loss: 0.00003353
Iteration 104/1000 | Loss: 0.00002414
Iteration 105/1000 | Loss: 0.00001958
Iteration 106/1000 | Loss: 0.00001894
Iteration 107/1000 | Loss: 0.00001884
Iteration 108/1000 | Loss: 0.00001882
Iteration 109/1000 | Loss: 0.00001882
Iteration 110/1000 | Loss: 0.00001881
Iteration 111/1000 | Loss: 0.00001881
Iteration 112/1000 | Loss: 0.00001881
Iteration 113/1000 | Loss: 0.00001881
Iteration 114/1000 | Loss: 0.00001880
Iteration 115/1000 | Loss: 0.00001880
Iteration 116/1000 | Loss: 0.00001879
Iteration 117/1000 | Loss: 0.00001879
Iteration 118/1000 | Loss: 0.00011903
Iteration 119/1000 | Loss: 0.00005163
Iteration 120/1000 | Loss: 0.00005914
Iteration 121/1000 | Loss: 0.00072018
Iteration 122/1000 | Loss: 0.00039246
Iteration 123/1000 | Loss: 0.00003410
Iteration 124/1000 | Loss: 0.00002009
Iteration 125/1000 | Loss: 0.00001891
Iteration 126/1000 | Loss: 0.00001872
Iteration 127/1000 | Loss: 0.00001871
Iteration 128/1000 | Loss: 0.00001869
Iteration 129/1000 | Loss: 0.00001869
Iteration 130/1000 | Loss: 0.00001869
Iteration 131/1000 | Loss: 0.00001869
Iteration 132/1000 | Loss: 0.00001869
Iteration 133/1000 | Loss: 0.00001869
Iteration 134/1000 | Loss: 0.00001869
Iteration 135/1000 | Loss: 0.00001869
Iteration 136/1000 | Loss: 0.00001868
Iteration 137/1000 | Loss: 0.00001868
Iteration 138/1000 | Loss: 0.00001868
Iteration 139/1000 | Loss: 0.00001868
Iteration 140/1000 | Loss: 0.00001868
Iteration 141/1000 | Loss: 0.00001868
Iteration 142/1000 | Loss: 0.00001866
Iteration 143/1000 | Loss: 0.00001865
Iteration 144/1000 | Loss: 0.00001865
Iteration 145/1000 | Loss: 0.00001864
Iteration 146/1000 | Loss: 0.00001864
Iteration 147/1000 | Loss: 0.00001864
Iteration 148/1000 | Loss: 0.00001864
Iteration 149/1000 | Loss: 0.00001863
Iteration 150/1000 | Loss: 0.00001863
Iteration 151/1000 | Loss: 0.00001863
Iteration 152/1000 | Loss: 0.00001862
Iteration 153/1000 | Loss: 0.00001862
Iteration 154/1000 | Loss: 0.00001862
Iteration 155/1000 | Loss: 0.00001862
Iteration 156/1000 | Loss: 0.00001862
Iteration 157/1000 | Loss: 0.00001862
Iteration 158/1000 | Loss: 0.00001862
Iteration 159/1000 | Loss: 0.00001862
Iteration 160/1000 | Loss: 0.00001862
Iteration 161/1000 | Loss: 0.00001861
Iteration 162/1000 | Loss: 0.00001861
Iteration 163/1000 | Loss: 0.00001861
Iteration 164/1000 | Loss: 0.00001861
Iteration 165/1000 | Loss: 0.00001861
Iteration 166/1000 | Loss: 0.00001861
Iteration 167/1000 | Loss: 0.00001861
Iteration 168/1000 | Loss: 0.00001860
Iteration 169/1000 | Loss: 0.00001860
Iteration 170/1000 | Loss: 0.00001860
Iteration 171/1000 | Loss: 0.00001860
Iteration 172/1000 | Loss: 0.00001860
Iteration 173/1000 | Loss: 0.00001860
Iteration 174/1000 | Loss: 0.00001860
Iteration 175/1000 | Loss: 0.00001860
Iteration 176/1000 | Loss: 0.00003395
Iteration 177/1000 | Loss: 0.00001871
Iteration 178/1000 | Loss: 0.00001856
Iteration 179/1000 | Loss: 0.00001856
Iteration 180/1000 | Loss: 0.00001856
Iteration 181/1000 | Loss: 0.00001855
Iteration 182/1000 | Loss: 0.00001855
Iteration 183/1000 | Loss: 0.00001855
Iteration 184/1000 | Loss: 0.00001854
Iteration 185/1000 | Loss: 0.00001854
Iteration 186/1000 | Loss: 0.00001854
Iteration 187/1000 | Loss: 0.00001854
Iteration 188/1000 | Loss: 0.00001854
Iteration 189/1000 | Loss: 0.00001854
Iteration 190/1000 | Loss: 0.00001854
Iteration 191/1000 | Loss: 0.00001854
Iteration 192/1000 | Loss: 0.00001854
Iteration 193/1000 | Loss: 0.00001854
Iteration 194/1000 | Loss: 0.00001854
Iteration 195/1000 | Loss: 0.00001853
Iteration 196/1000 | Loss: 0.00001853
Iteration 197/1000 | Loss: 0.00001853
Iteration 198/1000 | Loss: 0.00001853
Iteration 199/1000 | Loss: 0.00001853
Iteration 200/1000 | Loss: 0.00001853
Iteration 201/1000 | Loss: 0.00001853
Iteration 202/1000 | Loss: 0.00001853
Iteration 203/1000 | Loss: 0.00001853
Iteration 204/1000 | Loss: 0.00001853
Iteration 205/1000 | Loss: 0.00001853
Iteration 206/1000 | Loss: 0.00001853
Iteration 207/1000 | Loss: 0.00001853
Iteration 208/1000 | Loss: 0.00001852
Iteration 209/1000 | Loss: 0.00001852
Iteration 210/1000 | Loss: 0.00001852
Iteration 211/1000 | Loss: 0.00001852
Iteration 212/1000 | Loss: 0.00001852
Iteration 213/1000 | Loss: 0.00001852
Iteration 214/1000 | Loss: 0.00001852
Iteration 215/1000 | Loss: 0.00001852
Iteration 216/1000 | Loss: 0.00001852
Iteration 217/1000 | Loss: 0.00001851
Iteration 218/1000 | Loss: 0.00001851
Iteration 219/1000 | Loss: 0.00001851
Iteration 220/1000 | Loss: 0.00001851
Iteration 221/1000 | Loss: 0.00001850
Iteration 222/1000 | Loss: 0.00001850
Iteration 223/1000 | Loss: 0.00001850
Iteration 224/1000 | Loss: 0.00001850
Iteration 225/1000 | Loss: 0.00001850
Iteration 226/1000 | Loss: 0.00001849
Iteration 227/1000 | Loss: 0.00001849
Iteration 228/1000 | Loss: 0.00001849
Iteration 229/1000 | Loss: 0.00001849
Iteration 230/1000 | Loss: 0.00001849
Iteration 231/1000 | Loss: 0.00001848
Iteration 232/1000 | Loss: 0.00001848
Iteration 233/1000 | Loss: 0.00001848
Iteration 234/1000 | Loss: 0.00001847
Iteration 235/1000 | Loss: 0.00001847
Iteration 236/1000 | Loss: 0.00001847
Iteration 237/1000 | Loss: 0.00001846
Iteration 238/1000 | Loss: 0.00001846
Iteration 239/1000 | Loss: 0.00001845
Iteration 240/1000 | Loss: 0.00001845
Iteration 241/1000 | Loss: 0.00001845
Iteration 242/1000 | Loss: 0.00001845
Iteration 243/1000 | Loss: 0.00001845
Iteration 244/1000 | Loss: 0.00001844
Iteration 245/1000 | Loss: 0.00001844
Iteration 246/1000 | Loss: 0.00001843
Iteration 247/1000 | Loss: 0.00001843
Iteration 248/1000 | Loss: 0.00002554
Iteration 249/1000 | Loss: 0.00011586
Iteration 250/1000 | Loss: 0.00005325
Iteration 251/1000 | Loss: 0.00001856
Iteration 252/1000 | Loss: 0.00002572
Iteration 253/1000 | Loss: 0.00008022
Iteration 254/1000 | Loss: 0.00004544
Iteration 255/1000 | Loss: 0.00002081
Iteration 256/1000 | Loss: 0.00002699
Iteration 257/1000 | Loss: 0.00001841
Iteration 258/1000 | Loss: 0.00001837
Iteration 259/1000 | Loss: 0.00001837
Iteration 260/1000 | Loss: 0.00001837
Iteration 261/1000 | Loss: 0.00001836
Iteration 262/1000 | Loss: 0.00001836
Iteration 263/1000 | Loss: 0.00001836
Iteration 264/1000 | Loss: 0.00001836
Iteration 265/1000 | Loss: 0.00001836
Iteration 266/1000 | Loss: 0.00001836
Iteration 267/1000 | Loss: 0.00001836
Iteration 268/1000 | Loss: 0.00001836
Iteration 269/1000 | Loss: 0.00001835
Iteration 270/1000 | Loss: 0.00001835
Iteration 271/1000 | Loss: 0.00001835
Iteration 272/1000 | Loss: 0.00001835
Iteration 273/1000 | Loss: 0.00001835
Iteration 274/1000 | Loss: 0.00001835
Iteration 275/1000 | Loss: 0.00001835
Iteration 276/1000 | Loss: 0.00001835
Iteration 277/1000 | Loss: 0.00001835
Iteration 278/1000 | Loss: 0.00001834
Iteration 279/1000 | Loss: 0.00001834
Iteration 280/1000 | Loss: 0.00001834
Iteration 281/1000 | Loss: 0.00001834
Iteration 282/1000 | Loss: 0.00001834
Iteration 283/1000 | Loss: 0.00001834
Iteration 284/1000 | Loss: 0.00001834
Iteration 285/1000 | Loss: 0.00001834
Iteration 286/1000 | Loss: 0.00001834
Iteration 287/1000 | Loss: 0.00001834
Iteration 288/1000 | Loss: 0.00001834
Iteration 289/1000 | Loss: 0.00001834
Iteration 290/1000 | Loss: 0.00001834
Iteration 291/1000 | Loss: 0.00001834
Iteration 292/1000 | Loss: 0.00001834
Iteration 293/1000 | Loss: 0.00001834
Iteration 294/1000 | Loss: 0.00001834
Iteration 295/1000 | Loss: 0.00001833
Iteration 296/1000 | Loss: 0.00001833
Iteration 297/1000 | Loss: 0.00001833
Iteration 298/1000 | Loss: 0.00001833
Iteration 299/1000 | Loss: 0.00001833
Iteration 300/1000 | Loss: 0.00001833
Iteration 301/1000 | Loss: 0.00001833
Iteration 302/1000 | Loss: 0.00001833
Iteration 303/1000 | Loss: 0.00001833
Iteration 304/1000 | Loss: 0.00001833
Iteration 305/1000 | Loss: 0.00001833
Iteration 306/1000 | Loss: 0.00001833
Iteration 307/1000 | Loss: 0.00001833
Iteration 308/1000 | Loss: 0.00001833
Iteration 309/1000 | Loss: 0.00001833
Iteration 310/1000 | Loss: 0.00001833
Iteration 311/1000 | Loss: 0.00001833
Iteration 312/1000 | Loss: 0.00001832
Iteration 313/1000 | Loss: 0.00001832
Iteration 314/1000 | Loss: 0.00001832
Iteration 315/1000 | Loss: 0.00001832
Iteration 316/1000 | Loss: 0.00001832
Iteration 317/1000 | Loss: 0.00001832
Iteration 318/1000 | Loss: 0.00001832
Iteration 319/1000 | Loss: 0.00001832
Iteration 320/1000 | Loss: 0.00001832
Iteration 321/1000 | Loss: 0.00001832
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 321. Stopping optimization.
Last 5 losses: [1.8324242773815058e-05, 1.8324242773815058e-05, 1.8324242773815058e-05, 1.8324242773815058e-05, 1.8324242773815058e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8324242773815058e-05

Optimization complete. Final v2v error: 3.5919952392578125 mm

Highest mean error: 5.9955058097839355 mm for frame 68

Lowest mean error: 2.895092725753784 mm for frame 114

Saving results

Total time: 240.64027571678162
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00438782
Iteration 2/25 | Loss: 0.00095749
Iteration 3/25 | Loss: 0.00073244
Iteration 4/25 | Loss: 0.00070801
Iteration 5/25 | Loss: 0.00070045
Iteration 6/25 | Loss: 0.00069795
Iteration 7/25 | Loss: 0.00069743
Iteration 8/25 | Loss: 0.00069743
Iteration 9/25 | Loss: 0.00069743
Iteration 10/25 | Loss: 0.00069743
Iteration 11/25 | Loss: 0.00069743
Iteration 12/25 | Loss: 0.00069743
Iteration 13/25 | Loss: 0.00069743
Iteration 14/25 | Loss: 0.00069743
Iteration 15/25 | Loss: 0.00069743
Iteration 16/25 | Loss: 0.00069743
Iteration 17/25 | Loss: 0.00069743
Iteration 18/25 | Loss: 0.00069743
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006974308053031564, 0.0006974308053031564, 0.0006974308053031564, 0.0006974308053031564, 0.0006974308053031564]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006974308053031564

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.93581480
Iteration 2/25 | Loss: 0.00029112
Iteration 3/25 | Loss: 0.00029112
Iteration 4/25 | Loss: 0.00029112
Iteration 5/25 | Loss: 0.00029112
Iteration 6/25 | Loss: 0.00029111
Iteration 7/25 | Loss: 0.00029111
Iteration 8/25 | Loss: 0.00029111
Iteration 9/25 | Loss: 0.00029111
Iteration 10/25 | Loss: 0.00029111
Iteration 11/25 | Loss: 0.00029111
Iteration 12/25 | Loss: 0.00029111
Iteration 13/25 | Loss: 0.00029111
Iteration 14/25 | Loss: 0.00029111
Iteration 15/25 | Loss: 0.00029111
Iteration 16/25 | Loss: 0.00029111
Iteration 17/25 | Loss: 0.00029111
Iteration 18/25 | Loss: 0.00029111
Iteration 19/25 | Loss: 0.00029111
Iteration 20/25 | Loss: 0.00029111
Iteration 21/25 | Loss: 0.00029111
Iteration 22/25 | Loss: 0.00029111
Iteration 23/25 | Loss: 0.00029111
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0002911138872150332, 0.0002911138872150332, 0.0002911138872150332, 0.0002911138872150332, 0.0002911138872150332]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002911138872150332

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029111
Iteration 2/1000 | Loss: 0.00005330
Iteration 3/1000 | Loss: 0.00003337
Iteration 4/1000 | Loss: 0.00002912
Iteration 5/1000 | Loss: 0.00002679
Iteration 6/1000 | Loss: 0.00002572
Iteration 7/1000 | Loss: 0.00002466
Iteration 8/1000 | Loss: 0.00002418
Iteration 9/1000 | Loss: 0.00002387
Iteration 10/1000 | Loss: 0.00002371
Iteration 11/1000 | Loss: 0.00002370
Iteration 12/1000 | Loss: 0.00002337
Iteration 13/1000 | Loss: 0.00002327
Iteration 14/1000 | Loss: 0.00002320
Iteration 15/1000 | Loss: 0.00002320
Iteration 16/1000 | Loss: 0.00002319
Iteration 17/1000 | Loss: 0.00002318
Iteration 18/1000 | Loss: 0.00002318
Iteration 19/1000 | Loss: 0.00002318
Iteration 20/1000 | Loss: 0.00002318
Iteration 21/1000 | Loss: 0.00002316
Iteration 22/1000 | Loss: 0.00002316
Iteration 23/1000 | Loss: 0.00002316
Iteration 24/1000 | Loss: 0.00002316
Iteration 25/1000 | Loss: 0.00002316
Iteration 26/1000 | Loss: 0.00002316
Iteration 27/1000 | Loss: 0.00002316
Iteration 28/1000 | Loss: 0.00002315
Iteration 29/1000 | Loss: 0.00002315
Iteration 30/1000 | Loss: 0.00002315
Iteration 31/1000 | Loss: 0.00002315
Iteration 32/1000 | Loss: 0.00002314
Iteration 33/1000 | Loss: 0.00002314
Iteration 34/1000 | Loss: 0.00002314
Iteration 35/1000 | Loss: 0.00002313
Iteration 36/1000 | Loss: 0.00002313
Iteration 37/1000 | Loss: 0.00002313
Iteration 38/1000 | Loss: 0.00002313
Iteration 39/1000 | Loss: 0.00002313
Iteration 40/1000 | Loss: 0.00002313
Iteration 41/1000 | Loss: 0.00002312
Iteration 42/1000 | Loss: 0.00002312
Iteration 43/1000 | Loss: 0.00002312
Iteration 44/1000 | Loss: 0.00002312
Iteration 45/1000 | Loss: 0.00002312
Iteration 46/1000 | Loss: 0.00002312
Iteration 47/1000 | Loss: 0.00002312
Iteration 48/1000 | Loss: 0.00002312
Iteration 49/1000 | Loss: 0.00002312
Iteration 50/1000 | Loss: 0.00002312
Iteration 51/1000 | Loss: 0.00002312
Iteration 52/1000 | Loss: 0.00002312
Iteration 53/1000 | Loss: 0.00002312
Iteration 54/1000 | Loss: 0.00002312
Iteration 55/1000 | Loss: 0.00002312
Iteration 56/1000 | Loss: 0.00002312
Iteration 57/1000 | Loss: 0.00002312
Iteration 58/1000 | Loss: 0.00002312
Iteration 59/1000 | Loss: 0.00002312
Iteration 60/1000 | Loss: 0.00002312
Iteration 61/1000 | Loss: 0.00002312
Iteration 62/1000 | Loss: 0.00002312
Iteration 63/1000 | Loss: 0.00002312
Iteration 64/1000 | Loss: 0.00002312
Iteration 65/1000 | Loss: 0.00002312
Iteration 66/1000 | Loss: 0.00002312
Iteration 67/1000 | Loss: 0.00002312
Iteration 68/1000 | Loss: 0.00002312
Iteration 69/1000 | Loss: 0.00002312
Iteration 70/1000 | Loss: 0.00002312
Iteration 71/1000 | Loss: 0.00002312
Iteration 72/1000 | Loss: 0.00002312
Iteration 73/1000 | Loss: 0.00002312
Iteration 74/1000 | Loss: 0.00002312
Iteration 75/1000 | Loss: 0.00002312
Iteration 76/1000 | Loss: 0.00002312
Iteration 77/1000 | Loss: 0.00002312
Iteration 78/1000 | Loss: 0.00002312
Iteration 79/1000 | Loss: 0.00002312
Iteration 80/1000 | Loss: 0.00002312
Iteration 81/1000 | Loss: 0.00002312
Iteration 82/1000 | Loss: 0.00002312
Iteration 83/1000 | Loss: 0.00002312
Iteration 84/1000 | Loss: 0.00002312
Iteration 85/1000 | Loss: 0.00002312
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [2.311937714694068e-05, 2.311937714694068e-05, 2.311937714694068e-05, 2.311937714694068e-05, 2.311937714694068e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.311937714694068e-05

Optimization complete. Final v2v error: 4.053598880767822 mm

Highest mean error: 4.186185836791992 mm for frame 98

Lowest mean error: 3.970393419265747 mm for frame 1

Saving results

Total time: 29.355082035064697
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00340424
Iteration 2/25 | Loss: 0.00085217
Iteration 3/25 | Loss: 0.00068465
Iteration 4/25 | Loss: 0.00064839
Iteration 5/25 | Loss: 0.00063832
Iteration 6/25 | Loss: 0.00063535
Iteration 7/25 | Loss: 0.00063443
Iteration 8/25 | Loss: 0.00063428
Iteration 9/25 | Loss: 0.00063428
Iteration 10/25 | Loss: 0.00063428
Iteration 11/25 | Loss: 0.00063428
Iteration 12/25 | Loss: 0.00063428
Iteration 13/25 | Loss: 0.00063428
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006342768901959062, 0.0006342768901959062, 0.0006342768901959062, 0.0006342768901959062, 0.0006342768901959062]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006342768901959062

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29993391
Iteration 2/25 | Loss: 0.00034490
Iteration 3/25 | Loss: 0.00034490
Iteration 4/25 | Loss: 0.00034489
Iteration 5/25 | Loss: 0.00034489
Iteration 6/25 | Loss: 0.00034489
Iteration 7/25 | Loss: 0.00034489
Iteration 8/25 | Loss: 0.00034489
Iteration 9/25 | Loss: 0.00034489
Iteration 10/25 | Loss: 0.00034489
Iteration 11/25 | Loss: 0.00034489
Iteration 12/25 | Loss: 0.00034489
Iteration 13/25 | Loss: 0.00034489
Iteration 14/25 | Loss: 0.00034489
Iteration 15/25 | Loss: 0.00034489
Iteration 16/25 | Loss: 0.00034489
Iteration 17/25 | Loss: 0.00034489
Iteration 18/25 | Loss: 0.00034489
Iteration 19/25 | Loss: 0.00034489
Iteration 20/25 | Loss: 0.00034489
Iteration 21/25 | Loss: 0.00034489
Iteration 22/25 | Loss: 0.00034489
Iteration 23/25 | Loss: 0.00034489
Iteration 24/25 | Loss: 0.00034489
Iteration 25/25 | Loss: 0.00034489

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034489
Iteration 2/1000 | Loss: 0.00005115
Iteration 3/1000 | Loss: 0.00003096
Iteration 4/1000 | Loss: 0.00002381
Iteration 5/1000 | Loss: 0.00002202
Iteration 6/1000 | Loss: 0.00002024
Iteration 7/1000 | Loss: 0.00001930
Iteration 8/1000 | Loss: 0.00001874
Iteration 9/1000 | Loss: 0.00001842
Iteration 10/1000 | Loss: 0.00001821
Iteration 11/1000 | Loss: 0.00001801
Iteration 12/1000 | Loss: 0.00001793
Iteration 13/1000 | Loss: 0.00001788
Iteration 14/1000 | Loss: 0.00001788
Iteration 15/1000 | Loss: 0.00001784
Iteration 16/1000 | Loss: 0.00001773
Iteration 17/1000 | Loss: 0.00001771
Iteration 18/1000 | Loss: 0.00001770
Iteration 19/1000 | Loss: 0.00001766
Iteration 20/1000 | Loss: 0.00001763
Iteration 21/1000 | Loss: 0.00001762
Iteration 22/1000 | Loss: 0.00001761
Iteration 23/1000 | Loss: 0.00001758
Iteration 24/1000 | Loss: 0.00001757
Iteration 25/1000 | Loss: 0.00001755
Iteration 26/1000 | Loss: 0.00001754
Iteration 27/1000 | Loss: 0.00001753
Iteration 28/1000 | Loss: 0.00001752
Iteration 29/1000 | Loss: 0.00001752
Iteration 30/1000 | Loss: 0.00001752
Iteration 31/1000 | Loss: 0.00001750
Iteration 32/1000 | Loss: 0.00001749
Iteration 33/1000 | Loss: 0.00001749
Iteration 34/1000 | Loss: 0.00001749
Iteration 35/1000 | Loss: 0.00001748
Iteration 36/1000 | Loss: 0.00001748
Iteration 37/1000 | Loss: 0.00001747
Iteration 38/1000 | Loss: 0.00001747
Iteration 39/1000 | Loss: 0.00001746
Iteration 40/1000 | Loss: 0.00001745
Iteration 41/1000 | Loss: 0.00001745
Iteration 42/1000 | Loss: 0.00001744
Iteration 43/1000 | Loss: 0.00001744
Iteration 44/1000 | Loss: 0.00001743
Iteration 45/1000 | Loss: 0.00001743
Iteration 46/1000 | Loss: 0.00001742
Iteration 47/1000 | Loss: 0.00001742
Iteration 48/1000 | Loss: 0.00001742
Iteration 49/1000 | Loss: 0.00001741
Iteration 50/1000 | Loss: 0.00001741
Iteration 51/1000 | Loss: 0.00001741
Iteration 52/1000 | Loss: 0.00001741
Iteration 53/1000 | Loss: 0.00001741
Iteration 54/1000 | Loss: 0.00001741
Iteration 55/1000 | Loss: 0.00001741
Iteration 56/1000 | Loss: 0.00001740
Iteration 57/1000 | Loss: 0.00001740
Iteration 58/1000 | Loss: 0.00001740
Iteration 59/1000 | Loss: 0.00001740
Iteration 60/1000 | Loss: 0.00001740
Iteration 61/1000 | Loss: 0.00001740
Iteration 62/1000 | Loss: 0.00001740
Iteration 63/1000 | Loss: 0.00001740
Iteration 64/1000 | Loss: 0.00001740
Iteration 65/1000 | Loss: 0.00001739
Iteration 66/1000 | Loss: 0.00001739
Iteration 67/1000 | Loss: 0.00001739
Iteration 68/1000 | Loss: 0.00001738
Iteration 69/1000 | Loss: 0.00001738
Iteration 70/1000 | Loss: 0.00001738
Iteration 71/1000 | Loss: 0.00001738
Iteration 72/1000 | Loss: 0.00001738
Iteration 73/1000 | Loss: 0.00001737
Iteration 74/1000 | Loss: 0.00001737
Iteration 75/1000 | Loss: 0.00001737
Iteration 76/1000 | Loss: 0.00001737
Iteration 77/1000 | Loss: 0.00001737
Iteration 78/1000 | Loss: 0.00001737
Iteration 79/1000 | Loss: 0.00001737
Iteration 80/1000 | Loss: 0.00001737
Iteration 81/1000 | Loss: 0.00001737
Iteration 82/1000 | Loss: 0.00001736
Iteration 83/1000 | Loss: 0.00001736
Iteration 84/1000 | Loss: 0.00001735
Iteration 85/1000 | Loss: 0.00001735
Iteration 86/1000 | Loss: 0.00001734
Iteration 87/1000 | Loss: 0.00001733
Iteration 88/1000 | Loss: 0.00001733
Iteration 89/1000 | Loss: 0.00001733
Iteration 90/1000 | Loss: 0.00001733
Iteration 91/1000 | Loss: 0.00001732
Iteration 92/1000 | Loss: 0.00001732
Iteration 93/1000 | Loss: 0.00001732
Iteration 94/1000 | Loss: 0.00001732
Iteration 95/1000 | Loss: 0.00001732
Iteration 96/1000 | Loss: 0.00001731
Iteration 97/1000 | Loss: 0.00001731
Iteration 98/1000 | Loss: 0.00001731
Iteration 99/1000 | Loss: 0.00001731
Iteration 100/1000 | Loss: 0.00001731
Iteration 101/1000 | Loss: 0.00001731
Iteration 102/1000 | Loss: 0.00001730
Iteration 103/1000 | Loss: 0.00001730
Iteration 104/1000 | Loss: 0.00001730
Iteration 105/1000 | Loss: 0.00001730
Iteration 106/1000 | Loss: 0.00001730
Iteration 107/1000 | Loss: 0.00001729
Iteration 108/1000 | Loss: 0.00001729
Iteration 109/1000 | Loss: 0.00001729
Iteration 110/1000 | Loss: 0.00001729
Iteration 111/1000 | Loss: 0.00001729
Iteration 112/1000 | Loss: 0.00001729
Iteration 113/1000 | Loss: 0.00001729
Iteration 114/1000 | Loss: 0.00001729
Iteration 115/1000 | Loss: 0.00001729
Iteration 116/1000 | Loss: 0.00001729
Iteration 117/1000 | Loss: 0.00001729
Iteration 118/1000 | Loss: 0.00001728
Iteration 119/1000 | Loss: 0.00001728
Iteration 120/1000 | Loss: 0.00001728
Iteration 121/1000 | Loss: 0.00001728
Iteration 122/1000 | Loss: 0.00001728
Iteration 123/1000 | Loss: 0.00001728
Iteration 124/1000 | Loss: 0.00001728
Iteration 125/1000 | Loss: 0.00001728
Iteration 126/1000 | Loss: 0.00001727
Iteration 127/1000 | Loss: 0.00001727
Iteration 128/1000 | Loss: 0.00001727
Iteration 129/1000 | Loss: 0.00001727
Iteration 130/1000 | Loss: 0.00001727
Iteration 131/1000 | Loss: 0.00001727
Iteration 132/1000 | Loss: 0.00001726
Iteration 133/1000 | Loss: 0.00001726
Iteration 134/1000 | Loss: 0.00001726
Iteration 135/1000 | Loss: 0.00001725
Iteration 136/1000 | Loss: 0.00001725
Iteration 137/1000 | Loss: 0.00001725
Iteration 138/1000 | Loss: 0.00001725
Iteration 139/1000 | Loss: 0.00001725
Iteration 140/1000 | Loss: 0.00001724
Iteration 141/1000 | Loss: 0.00001724
Iteration 142/1000 | Loss: 0.00001724
Iteration 143/1000 | Loss: 0.00001724
Iteration 144/1000 | Loss: 0.00001724
Iteration 145/1000 | Loss: 0.00001724
Iteration 146/1000 | Loss: 0.00001723
Iteration 147/1000 | Loss: 0.00001723
Iteration 148/1000 | Loss: 0.00001723
Iteration 149/1000 | Loss: 0.00001723
Iteration 150/1000 | Loss: 0.00001723
Iteration 151/1000 | Loss: 0.00001723
Iteration 152/1000 | Loss: 0.00001723
Iteration 153/1000 | Loss: 0.00001723
Iteration 154/1000 | Loss: 0.00001723
Iteration 155/1000 | Loss: 0.00001723
Iteration 156/1000 | Loss: 0.00001723
Iteration 157/1000 | Loss: 0.00001723
Iteration 158/1000 | Loss: 0.00001723
Iteration 159/1000 | Loss: 0.00001723
Iteration 160/1000 | Loss: 0.00001723
Iteration 161/1000 | Loss: 0.00001723
Iteration 162/1000 | Loss: 0.00001723
Iteration 163/1000 | Loss: 0.00001723
Iteration 164/1000 | Loss: 0.00001723
Iteration 165/1000 | Loss: 0.00001723
Iteration 166/1000 | Loss: 0.00001723
Iteration 167/1000 | Loss: 0.00001723
Iteration 168/1000 | Loss: 0.00001723
Iteration 169/1000 | Loss: 0.00001723
Iteration 170/1000 | Loss: 0.00001723
Iteration 171/1000 | Loss: 0.00001723
Iteration 172/1000 | Loss: 0.00001723
Iteration 173/1000 | Loss: 0.00001723
Iteration 174/1000 | Loss: 0.00001723
Iteration 175/1000 | Loss: 0.00001723
Iteration 176/1000 | Loss: 0.00001723
Iteration 177/1000 | Loss: 0.00001723
Iteration 178/1000 | Loss: 0.00001723
Iteration 179/1000 | Loss: 0.00001723
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.722873275866732e-05, 1.722873275866732e-05, 1.722873275866732e-05, 1.722873275866732e-05, 1.722873275866732e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.722873275866732e-05

Optimization complete. Final v2v error: 3.5245909690856934 mm

Highest mean error: 3.757857322692871 mm for frame 78

Lowest mean error: 3.2560808658599854 mm for frame 2

Saving results

Total time: 41.655783891677856
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00728952
Iteration 2/25 | Loss: 0.00093536
Iteration 3/25 | Loss: 0.00070096
Iteration 4/25 | Loss: 0.00066918
Iteration 5/25 | Loss: 0.00064189
Iteration 6/25 | Loss: 0.00062877
Iteration 7/25 | Loss: 0.00062514
Iteration 8/25 | Loss: 0.00062713
Iteration 9/25 | Loss: 0.00062420
Iteration 10/25 | Loss: 0.00062769
Iteration 11/25 | Loss: 0.00062377
Iteration 12/25 | Loss: 0.00062837
Iteration 13/25 | Loss: 0.00062329
Iteration 14/25 | Loss: 0.00062703
Iteration 15/25 | Loss: 0.00062293
Iteration 16/25 | Loss: 0.00062590
Iteration 17/25 | Loss: 0.00062284
Iteration 18/25 | Loss: 0.00062280
Iteration 19/25 | Loss: 0.00062280
Iteration 20/25 | Loss: 0.00062280
Iteration 21/25 | Loss: 0.00062280
Iteration 22/25 | Loss: 0.00062280
Iteration 23/25 | Loss: 0.00062280
Iteration 24/25 | Loss: 0.00062280
Iteration 25/25 | Loss: 0.00062280

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.51639938
Iteration 2/25 | Loss: 0.00024824
Iteration 3/25 | Loss: 0.00024824
Iteration 4/25 | Loss: 0.00024824
Iteration 5/25 | Loss: 0.00024824
Iteration 6/25 | Loss: 0.00024824
Iteration 7/25 | Loss: 0.00024823
Iteration 8/25 | Loss: 0.00024823
Iteration 9/25 | Loss: 0.00024823
Iteration 10/25 | Loss: 0.00024823
Iteration 11/25 | Loss: 0.00024823
Iteration 12/25 | Loss: 0.00024823
Iteration 13/25 | Loss: 0.00024823
Iteration 14/25 | Loss: 0.00024823
Iteration 15/25 | Loss: 0.00024823
Iteration 16/25 | Loss: 0.00024823
Iteration 17/25 | Loss: 0.00024823
Iteration 18/25 | Loss: 0.00024823
Iteration 19/25 | Loss: 0.00024823
Iteration 20/25 | Loss: 0.00024823
Iteration 21/25 | Loss: 0.00024823
Iteration 22/25 | Loss: 0.00024823
Iteration 23/25 | Loss: 0.00024823
Iteration 24/25 | Loss: 0.00024823
Iteration 25/25 | Loss: 0.00024823

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00024823
Iteration 2/1000 | Loss: 0.00003891
Iteration 3/1000 | Loss: 0.00002765
Iteration 4/1000 | Loss: 0.00002450
Iteration 5/1000 | Loss: 0.00038752
Iteration 6/1000 | Loss: 0.00002446
Iteration 7/1000 | Loss: 0.00002129
Iteration 8/1000 | Loss: 0.00001998
Iteration 9/1000 | Loss: 0.00001910
Iteration 10/1000 | Loss: 0.00001873
Iteration 11/1000 | Loss: 0.00001860
Iteration 12/1000 | Loss: 0.00001859
Iteration 13/1000 | Loss: 0.00001855
Iteration 14/1000 | Loss: 0.00001854
Iteration 15/1000 | Loss: 0.00001853
Iteration 16/1000 | Loss: 0.00001852
Iteration 17/1000 | Loss: 0.00001851
Iteration 18/1000 | Loss: 0.00004508
Iteration 19/1000 | Loss: 0.00001842
Iteration 20/1000 | Loss: 0.00001839
Iteration 21/1000 | Loss: 0.00001839
Iteration 22/1000 | Loss: 0.00001839
Iteration 23/1000 | Loss: 0.00001839
Iteration 24/1000 | Loss: 0.00001838
Iteration 25/1000 | Loss: 0.00001838
Iteration 26/1000 | Loss: 0.00001828
Iteration 27/1000 | Loss: 0.00001824
Iteration 28/1000 | Loss: 0.00001821
Iteration 29/1000 | Loss: 0.00001819
Iteration 30/1000 | Loss: 0.00001819
Iteration 31/1000 | Loss: 0.00001819
Iteration 32/1000 | Loss: 0.00001819
Iteration 33/1000 | Loss: 0.00001818
Iteration 34/1000 | Loss: 0.00001818
Iteration 35/1000 | Loss: 0.00001817
Iteration 36/1000 | Loss: 0.00001817
Iteration 37/1000 | Loss: 0.00001817
Iteration 38/1000 | Loss: 0.00001815
Iteration 39/1000 | Loss: 0.00001814
Iteration 40/1000 | Loss: 0.00001813
Iteration 41/1000 | Loss: 0.00001810
Iteration 42/1000 | Loss: 0.00005224
Iteration 43/1000 | Loss: 0.00001810
Iteration 44/1000 | Loss: 0.00001809
Iteration 45/1000 | Loss: 0.00001808
Iteration 46/1000 | Loss: 0.00001808
Iteration 47/1000 | Loss: 0.00001808
Iteration 48/1000 | Loss: 0.00001808
Iteration 49/1000 | Loss: 0.00001808
Iteration 50/1000 | Loss: 0.00001807
Iteration 51/1000 | Loss: 0.00001807
Iteration 52/1000 | Loss: 0.00001807
Iteration 53/1000 | Loss: 0.00001806
Iteration 54/1000 | Loss: 0.00001806
Iteration 55/1000 | Loss: 0.00001806
Iteration 56/1000 | Loss: 0.00001805
Iteration 57/1000 | Loss: 0.00001805
Iteration 58/1000 | Loss: 0.00001804
Iteration 59/1000 | Loss: 0.00001804
Iteration 60/1000 | Loss: 0.00001804
Iteration 61/1000 | Loss: 0.00001804
Iteration 62/1000 | Loss: 0.00001804
Iteration 63/1000 | Loss: 0.00001804
Iteration 64/1000 | Loss: 0.00001804
Iteration 65/1000 | Loss: 0.00001803
Iteration 66/1000 | Loss: 0.00001803
Iteration 67/1000 | Loss: 0.00001803
Iteration 68/1000 | Loss: 0.00001803
Iteration 69/1000 | Loss: 0.00001803
Iteration 70/1000 | Loss: 0.00001803
Iteration 71/1000 | Loss: 0.00001803
Iteration 72/1000 | Loss: 0.00001801
Iteration 73/1000 | Loss: 0.00001801
Iteration 74/1000 | Loss: 0.00001801
Iteration 75/1000 | Loss: 0.00001801
Iteration 76/1000 | Loss: 0.00004156
Iteration 77/1000 | Loss: 0.00001818
Iteration 78/1000 | Loss: 0.00001797
Iteration 79/1000 | Loss: 0.00001796
Iteration 80/1000 | Loss: 0.00001796
Iteration 81/1000 | Loss: 0.00001796
Iteration 82/1000 | Loss: 0.00001796
Iteration 83/1000 | Loss: 0.00001796
Iteration 84/1000 | Loss: 0.00001796
Iteration 85/1000 | Loss: 0.00001796
Iteration 86/1000 | Loss: 0.00001796
Iteration 87/1000 | Loss: 0.00001796
Iteration 88/1000 | Loss: 0.00001796
Iteration 89/1000 | Loss: 0.00001796
Iteration 90/1000 | Loss: 0.00001796
Iteration 91/1000 | Loss: 0.00001796
Iteration 92/1000 | Loss: 0.00001796
Iteration 93/1000 | Loss: 0.00001796
Iteration 94/1000 | Loss: 0.00001796
Iteration 95/1000 | Loss: 0.00001796
Iteration 96/1000 | Loss: 0.00001796
Iteration 97/1000 | Loss: 0.00001796
Iteration 98/1000 | Loss: 0.00001796
Iteration 99/1000 | Loss: 0.00001796
Iteration 100/1000 | Loss: 0.00001796
Iteration 101/1000 | Loss: 0.00001796
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [1.796048309188336e-05, 1.796048309188336e-05, 1.796048309188336e-05, 1.796048309188336e-05, 1.796048309188336e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.796048309188336e-05

Optimization complete. Final v2v error: 3.566985845565796 mm

Highest mean error: 4.523691654205322 mm for frame 140

Lowest mean error: 2.9442553520202637 mm for frame 235

Saving results

Total time: 66.4631118774414
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01009538
Iteration 2/25 | Loss: 0.00364057
Iteration 3/25 | Loss: 0.00200232
Iteration 4/25 | Loss: 0.00165260
Iteration 5/25 | Loss: 0.00140548
Iteration 6/25 | Loss: 0.00131208
Iteration 7/25 | Loss: 0.00129124
Iteration 8/25 | Loss: 0.00124371
Iteration 9/25 | Loss: 0.00118683
Iteration 10/25 | Loss: 0.00110315
Iteration 11/25 | Loss: 0.00104235
Iteration 12/25 | Loss: 0.00102417
Iteration 13/25 | Loss: 0.00099823
Iteration 14/25 | Loss: 0.00103126
Iteration 15/25 | Loss: 0.00106013
Iteration 16/25 | Loss: 0.00106008
Iteration 17/25 | Loss: 0.00099873
Iteration 18/25 | Loss: 0.00094901
Iteration 19/25 | Loss: 0.00090481
Iteration 20/25 | Loss: 0.00089362
Iteration 21/25 | Loss: 0.00088895
Iteration 22/25 | Loss: 0.00088442
Iteration 23/25 | Loss: 0.00088343
Iteration 24/25 | Loss: 0.00088324
Iteration 25/25 | Loss: 0.00088294

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.33812571
Iteration 2/25 | Loss: 0.00426033
Iteration 3/25 | Loss: 0.00291215
Iteration 4/25 | Loss: 0.00290994
Iteration 5/25 | Loss: 0.00252618
Iteration 6/25 | Loss: 0.00245262
Iteration 7/25 | Loss: 0.00231952
Iteration 8/25 | Loss: 0.00231952
Iteration 9/25 | Loss: 0.00231952
Iteration 10/25 | Loss: 0.00231952
Iteration 11/25 | Loss: 0.00231952
Iteration 12/25 | Loss: 0.00231952
Iteration 13/25 | Loss: 0.00231952
Iteration 14/25 | Loss: 0.00231952
Iteration 15/25 | Loss: 0.00231952
Iteration 16/25 | Loss: 0.00231952
Iteration 17/25 | Loss: 0.00231952
Iteration 18/25 | Loss: 0.00231952
Iteration 19/25 | Loss: 0.00231952
Iteration 20/25 | Loss: 0.00231952
Iteration 21/25 | Loss: 0.00231952
Iteration 22/25 | Loss: 0.00231952
Iteration 23/25 | Loss: 0.00231952
Iteration 24/25 | Loss: 0.00231952
Iteration 25/25 | Loss: 0.00231952

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00231952
Iteration 2/1000 | Loss: 0.00123334
Iteration 3/1000 | Loss: 0.00071835
Iteration 4/1000 | Loss: 0.00046721
Iteration 5/1000 | Loss: 0.00373972
Iteration 6/1000 | Loss: 0.00053326
Iteration 7/1000 | Loss: 0.00028325
Iteration 8/1000 | Loss: 0.00052275
Iteration 9/1000 | Loss: 0.00070920
Iteration 10/1000 | Loss: 0.00044310
Iteration 11/1000 | Loss: 0.00041921
Iteration 12/1000 | Loss: 0.00017591
Iteration 13/1000 | Loss: 0.00011293
Iteration 14/1000 | Loss: 0.00070830
Iteration 15/1000 | Loss: 0.00121639
Iteration 16/1000 | Loss: 0.00031725
Iteration 17/1000 | Loss: 0.00041650
Iteration 18/1000 | Loss: 0.00021056
Iteration 19/1000 | Loss: 0.00039926
Iteration 20/1000 | Loss: 0.00071384
Iteration 21/1000 | Loss: 0.00052648
Iteration 22/1000 | Loss: 0.00053474
Iteration 23/1000 | Loss: 0.00037277
Iteration 24/1000 | Loss: 0.00042820
Iteration 25/1000 | Loss: 0.00023993
Iteration 26/1000 | Loss: 0.00010410
Iteration 27/1000 | Loss: 0.00009683
Iteration 28/1000 | Loss: 0.00009434
Iteration 29/1000 | Loss: 0.00015351
Iteration 30/1000 | Loss: 0.00039996
Iteration 31/1000 | Loss: 0.00011527
Iteration 32/1000 | Loss: 0.00009703
Iteration 33/1000 | Loss: 0.00009230
Iteration 34/1000 | Loss: 0.00008826
Iteration 35/1000 | Loss: 0.00008580
Iteration 36/1000 | Loss: 0.00025633
Iteration 37/1000 | Loss: 0.00060580
Iteration 38/1000 | Loss: 0.00033340
Iteration 39/1000 | Loss: 0.00021462
Iteration 40/1000 | Loss: 0.00048665
Iteration 41/1000 | Loss: 0.00012522
Iteration 42/1000 | Loss: 0.00016758
Iteration 43/1000 | Loss: 0.00022495
Iteration 44/1000 | Loss: 0.00089709
Iteration 45/1000 | Loss: 0.00018535
Iteration 46/1000 | Loss: 0.00130159
Iteration 47/1000 | Loss: 0.00022286
Iteration 48/1000 | Loss: 0.00013157
Iteration 49/1000 | Loss: 0.00014202
Iteration 50/1000 | Loss: 0.00035483
Iteration 51/1000 | Loss: 0.00015856
Iteration 52/1000 | Loss: 0.00059673
Iteration 53/1000 | Loss: 0.00052857
Iteration 54/1000 | Loss: 0.00073164
Iteration 55/1000 | Loss: 0.00042694
Iteration 56/1000 | Loss: 0.00041210
Iteration 57/1000 | Loss: 0.00036371
Iteration 58/1000 | Loss: 0.00043748
Iteration 59/1000 | Loss: 0.00051864
Iteration 60/1000 | Loss: 0.00030571
Iteration 61/1000 | Loss: 0.00023945
Iteration 62/1000 | Loss: 0.00040945
Iteration 63/1000 | Loss: 0.00029976
Iteration 64/1000 | Loss: 0.00213734
Iteration 65/1000 | Loss: 0.00074350
Iteration 66/1000 | Loss: 0.00110751
Iteration 67/1000 | Loss: 0.00076072
Iteration 68/1000 | Loss: 0.00035041
Iteration 69/1000 | Loss: 0.00148331
Iteration 70/1000 | Loss: 0.00036911
Iteration 71/1000 | Loss: 0.00030436
Iteration 72/1000 | Loss: 0.00036254
Iteration 73/1000 | Loss: 0.00033624
Iteration 74/1000 | Loss: 0.00096436
Iteration 75/1000 | Loss: 0.00160204
Iteration 76/1000 | Loss: 0.00090897
Iteration 77/1000 | Loss: 0.00046552
Iteration 78/1000 | Loss: 0.00018285
Iteration 79/1000 | Loss: 0.00010494
Iteration 80/1000 | Loss: 0.00029204
Iteration 81/1000 | Loss: 0.00007594
Iteration 82/1000 | Loss: 0.00066275
Iteration 83/1000 | Loss: 0.00051187
Iteration 84/1000 | Loss: 0.00033278
Iteration 85/1000 | Loss: 0.00021367
Iteration 86/1000 | Loss: 0.00020997
Iteration 87/1000 | Loss: 0.00057265
Iteration 88/1000 | Loss: 0.00028496
Iteration 89/1000 | Loss: 0.00013405
Iteration 90/1000 | Loss: 0.00018713
Iteration 91/1000 | Loss: 0.00016775
Iteration 92/1000 | Loss: 0.00019372
Iteration 93/1000 | Loss: 0.00018642
Iteration 94/1000 | Loss: 0.00056730
Iteration 95/1000 | Loss: 0.00069696
Iteration 96/1000 | Loss: 0.00009392
Iteration 97/1000 | Loss: 0.00013608
Iteration 98/1000 | Loss: 0.00192162
Iteration 99/1000 | Loss: 0.00010192
Iteration 100/1000 | Loss: 0.00007451
Iteration 101/1000 | Loss: 0.00058850
Iteration 102/1000 | Loss: 0.00006095
Iteration 103/1000 | Loss: 0.00023350
Iteration 104/1000 | Loss: 0.00016652
Iteration 105/1000 | Loss: 0.00004596
Iteration 106/1000 | Loss: 0.00012478
Iteration 107/1000 | Loss: 0.00004160
Iteration 108/1000 | Loss: 0.00010038
Iteration 109/1000 | Loss: 0.00015260
Iteration 110/1000 | Loss: 0.00003905
Iteration 111/1000 | Loss: 0.00003840
Iteration 112/1000 | Loss: 0.00009233
Iteration 113/1000 | Loss: 0.00004132
Iteration 114/1000 | Loss: 0.00003764
Iteration 115/1000 | Loss: 0.00007710
Iteration 116/1000 | Loss: 0.00007878
Iteration 117/1000 | Loss: 0.00003723
Iteration 118/1000 | Loss: 0.00007606
Iteration 119/1000 | Loss: 0.00005338
Iteration 120/1000 | Loss: 0.00004405
Iteration 121/1000 | Loss: 0.00006344
Iteration 122/1000 | Loss: 0.00004080
Iteration 123/1000 | Loss: 0.00003700
Iteration 124/1000 | Loss: 0.00003683
Iteration 125/1000 | Loss: 0.00003680
Iteration 126/1000 | Loss: 0.00003679
Iteration 127/1000 | Loss: 0.00003676
Iteration 128/1000 | Loss: 0.00003676
Iteration 129/1000 | Loss: 0.00003676
Iteration 130/1000 | Loss: 0.00003676
Iteration 131/1000 | Loss: 0.00003676
Iteration 132/1000 | Loss: 0.00003676
Iteration 133/1000 | Loss: 0.00003676
Iteration 134/1000 | Loss: 0.00003676
Iteration 135/1000 | Loss: 0.00003676
Iteration 136/1000 | Loss: 0.00003676
Iteration 137/1000 | Loss: 0.00003676
Iteration 138/1000 | Loss: 0.00003676
Iteration 139/1000 | Loss: 0.00003675
Iteration 140/1000 | Loss: 0.00003673
Iteration 141/1000 | Loss: 0.00003673
Iteration 142/1000 | Loss: 0.00003673
Iteration 143/1000 | Loss: 0.00003672
Iteration 144/1000 | Loss: 0.00003672
Iteration 145/1000 | Loss: 0.00003672
Iteration 146/1000 | Loss: 0.00003671
Iteration 147/1000 | Loss: 0.00003670
Iteration 148/1000 | Loss: 0.00003670
Iteration 149/1000 | Loss: 0.00003669
Iteration 150/1000 | Loss: 0.00003669
Iteration 151/1000 | Loss: 0.00003669
Iteration 152/1000 | Loss: 0.00003668
Iteration 153/1000 | Loss: 0.00003668
Iteration 154/1000 | Loss: 0.00003668
Iteration 155/1000 | Loss: 0.00003668
Iteration 156/1000 | Loss: 0.00003668
Iteration 157/1000 | Loss: 0.00003668
Iteration 158/1000 | Loss: 0.00003668
Iteration 159/1000 | Loss: 0.00003668
Iteration 160/1000 | Loss: 0.00003668
Iteration 161/1000 | Loss: 0.00003667
Iteration 162/1000 | Loss: 0.00003667
Iteration 163/1000 | Loss: 0.00003667
Iteration 164/1000 | Loss: 0.00003667
Iteration 165/1000 | Loss: 0.00003667
Iteration 166/1000 | Loss: 0.00003667
Iteration 167/1000 | Loss: 0.00003666
Iteration 168/1000 | Loss: 0.00003666
Iteration 169/1000 | Loss: 0.00003666
Iteration 170/1000 | Loss: 0.00003665
Iteration 171/1000 | Loss: 0.00003665
Iteration 172/1000 | Loss: 0.00003665
Iteration 173/1000 | Loss: 0.00003665
Iteration 174/1000 | Loss: 0.00003665
Iteration 175/1000 | Loss: 0.00003665
Iteration 176/1000 | Loss: 0.00003665
Iteration 177/1000 | Loss: 0.00003665
Iteration 178/1000 | Loss: 0.00003665
Iteration 179/1000 | Loss: 0.00003665
Iteration 180/1000 | Loss: 0.00003665
Iteration 181/1000 | Loss: 0.00003665
Iteration 182/1000 | Loss: 0.00003665
Iteration 183/1000 | Loss: 0.00003665
Iteration 184/1000 | Loss: 0.00003665
Iteration 185/1000 | Loss: 0.00003664
Iteration 186/1000 | Loss: 0.00003664
Iteration 187/1000 | Loss: 0.00003664
Iteration 188/1000 | Loss: 0.00003664
Iteration 189/1000 | Loss: 0.00003664
Iteration 190/1000 | Loss: 0.00003664
Iteration 191/1000 | Loss: 0.00003664
Iteration 192/1000 | Loss: 0.00003664
Iteration 193/1000 | Loss: 0.00003664
Iteration 194/1000 | Loss: 0.00003663
Iteration 195/1000 | Loss: 0.00003663
Iteration 196/1000 | Loss: 0.00003663
Iteration 197/1000 | Loss: 0.00003663
Iteration 198/1000 | Loss: 0.00003663
Iteration 199/1000 | Loss: 0.00003663
Iteration 200/1000 | Loss: 0.00003662
Iteration 201/1000 | Loss: 0.00003662
Iteration 202/1000 | Loss: 0.00003662
Iteration 203/1000 | Loss: 0.00003661
Iteration 204/1000 | Loss: 0.00003661
Iteration 205/1000 | Loss: 0.00003661
Iteration 206/1000 | Loss: 0.00003661
Iteration 207/1000 | Loss: 0.00003661
Iteration 208/1000 | Loss: 0.00003661
Iteration 209/1000 | Loss: 0.00003661
Iteration 210/1000 | Loss: 0.00003661
Iteration 211/1000 | Loss: 0.00003661
Iteration 212/1000 | Loss: 0.00003661
Iteration 213/1000 | Loss: 0.00003661
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 213. Stopping optimization.
Last 5 losses: [3.6610887036658823e-05, 3.6610887036658823e-05, 3.6610887036658823e-05, 3.6610887036658823e-05, 3.6610887036658823e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.6610887036658823e-05

Optimization complete. Final v2v error: 4.373554229736328 mm

Highest mean error: 6.4460625648498535 mm for frame 91

Lowest mean error: 3.272418975830078 mm for frame 6

Saving results

Total time: 229.59298944473267
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01063230
Iteration 2/25 | Loss: 0.00205704
Iteration 3/25 | Loss: 0.00124301
Iteration 4/25 | Loss: 0.00114309
Iteration 5/25 | Loss: 0.00104877
Iteration 6/25 | Loss: 0.00102157
Iteration 7/25 | Loss: 0.00095550
Iteration 8/25 | Loss: 0.00089645
Iteration 9/25 | Loss: 0.00085505
Iteration 10/25 | Loss: 0.00087313
Iteration 11/25 | Loss: 0.00085646
Iteration 12/25 | Loss: 0.00085420
Iteration 13/25 | Loss: 0.00083470
Iteration 14/25 | Loss: 0.00082340
Iteration 15/25 | Loss: 0.00082042
Iteration 16/25 | Loss: 0.00082653
Iteration 17/25 | Loss: 0.00082562
Iteration 18/25 | Loss: 0.00081252
Iteration 19/25 | Loss: 0.00079674
Iteration 20/25 | Loss: 0.00079601
Iteration 21/25 | Loss: 0.00079913
Iteration 22/25 | Loss: 0.00079542
Iteration 23/25 | Loss: 0.00079468
Iteration 24/25 | Loss: 0.00079150
Iteration 25/25 | Loss: 0.00079447

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30898762
Iteration 2/25 | Loss: 0.00266844
Iteration 3/25 | Loss: 0.00176358
Iteration 4/25 | Loss: 0.00176357
Iteration 5/25 | Loss: 0.00176357
Iteration 6/25 | Loss: 0.00176356
Iteration 7/25 | Loss: 0.00176356
Iteration 8/25 | Loss: 0.00176356
Iteration 9/25 | Loss: 0.00176356
Iteration 10/25 | Loss: 0.00176356
Iteration 11/25 | Loss: 0.00176356
Iteration 12/25 | Loss: 0.00176356
Iteration 13/25 | Loss: 0.00176356
Iteration 14/25 | Loss: 0.00176356
Iteration 15/25 | Loss: 0.00176356
Iteration 16/25 | Loss: 0.00176356
Iteration 17/25 | Loss: 0.00176356
Iteration 18/25 | Loss: 0.00176356
Iteration 19/25 | Loss: 0.00176356
Iteration 20/25 | Loss: 0.00176356
Iteration 21/25 | Loss: 0.00176356
Iteration 22/25 | Loss: 0.00176356
Iteration 23/25 | Loss: 0.00176356
Iteration 24/25 | Loss: 0.00176356
Iteration 25/25 | Loss: 0.00176356

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00176356
Iteration 2/1000 | Loss: 0.00065790
Iteration 3/1000 | Loss: 0.00113094
Iteration 4/1000 | Loss: 0.00041400
Iteration 5/1000 | Loss: 0.00031092
Iteration 6/1000 | Loss: 0.00036610
Iteration 7/1000 | Loss: 0.00031644
Iteration 8/1000 | Loss: 0.00032902
Iteration 9/1000 | Loss: 0.00040410
Iteration 10/1000 | Loss: 0.00040676
Iteration 11/1000 | Loss: 0.00038303
Iteration 12/1000 | Loss: 0.00026886
Iteration 13/1000 | Loss: 0.00029237
Iteration 14/1000 | Loss: 0.00037967
Iteration 15/1000 | Loss: 0.00056193
Iteration 16/1000 | Loss: 0.00156923
Iteration 17/1000 | Loss: 0.00168258
Iteration 18/1000 | Loss: 0.00031448
Iteration 19/1000 | Loss: 0.00051873
Iteration 20/1000 | Loss: 0.00068631
Iteration 21/1000 | Loss: 0.00013097
Iteration 22/1000 | Loss: 0.00026160
Iteration 23/1000 | Loss: 0.00016133
Iteration 24/1000 | Loss: 0.00228372
Iteration 25/1000 | Loss: 0.00100423
Iteration 26/1000 | Loss: 0.00214868
Iteration 27/1000 | Loss: 0.00646510
Iteration 28/1000 | Loss: 0.00994246
Iteration 29/1000 | Loss: 0.00639290
Iteration 30/1000 | Loss: 0.00587565
Iteration 31/1000 | Loss: 0.00066669
Iteration 32/1000 | Loss: 0.00137553
Iteration 33/1000 | Loss: 0.00055629
Iteration 34/1000 | Loss: 0.00200224
Iteration 35/1000 | Loss: 0.00028123
Iteration 36/1000 | Loss: 0.00058130
Iteration 37/1000 | Loss: 0.00016192
Iteration 38/1000 | Loss: 0.00026431
Iteration 39/1000 | Loss: 0.00006069
Iteration 40/1000 | Loss: 0.00004970
Iteration 41/1000 | Loss: 0.00015182
Iteration 42/1000 | Loss: 0.00043022
Iteration 43/1000 | Loss: 0.00004093
Iteration 44/1000 | Loss: 0.00025252
Iteration 45/1000 | Loss: 0.00052919
Iteration 46/1000 | Loss: 0.00065666
Iteration 47/1000 | Loss: 0.00049779
Iteration 48/1000 | Loss: 0.00053589
Iteration 49/1000 | Loss: 0.00029823
Iteration 50/1000 | Loss: 0.00027713
Iteration 51/1000 | Loss: 0.00033531
Iteration 52/1000 | Loss: 0.00021044
Iteration 53/1000 | Loss: 0.00003201
Iteration 54/1000 | Loss: 0.00002692
Iteration 55/1000 | Loss: 0.00017025
Iteration 56/1000 | Loss: 0.00002399
Iteration 57/1000 | Loss: 0.00002171
Iteration 58/1000 | Loss: 0.00028826
Iteration 59/1000 | Loss: 0.00015281
Iteration 60/1000 | Loss: 0.00027866
Iteration 61/1000 | Loss: 0.00003263
Iteration 62/1000 | Loss: 0.00002694
Iteration 63/1000 | Loss: 0.00002429
Iteration 64/1000 | Loss: 0.00050294
Iteration 65/1000 | Loss: 0.00006775
Iteration 66/1000 | Loss: 0.00053230
Iteration 67/1000 | Loss: 0.00030339
Iteration 68/1000 | Loss: 0.00048656
Iteration 69/1000 | Loss: 0.00132152
Iteration 70/1000 | Loss: 0.00065738
Iteration 71/1000 | Loss: 0.00060054
Iteration 72/1000 | Loss: 0.00046329
Iteration 73/1000 | Loss: 0.00036711
Iteration 74/1000 | Loss: 0.00025029
Iteration 75/1000 | Loss: 0.00039848
Iteration 76/1000 | Loss: 0.00012126
Iteration 77/1000 | Loss: 0.00005962
Iteration 78/1000 | Loss: 0.00002793
Iteration 79/1000 | Loss: 0.00003003
Iteration 80/1000 | Loss: 0.00012408
Iteration 81/1000 | Loss: 0.00055254
Iteration 82/1000 | Loss: 0.00015971
Iteration 83/1000 | Loss: 0.00108976
Iteration 84/1000 | Loss: 0.00021955
Iteration 85/1000 | Loss: 0.00038823
Iteration 86/1000 | Loss: 0.00037030
Iteration 87/1000 | Loss: 0.00038942
Iteration 88/1000 | Loss: 0.00027537
Iteration 89/1000 | Loss: 0.00105621
Iteration 90/1000 | Loss: 0.00051737
Iteration 91/1000 | Loss: 0.00002670
Iteration 92/1000 | Loss: 0.00002376
Iteration 93/1000 | Loss: 0.00002212
Iteration 94/1000 | Loss: 0.00002160
Iteration 95/1000 | Loss: 0.00009211
Iteration 96/1000 | Loss: 0.00002155
Iteration 97/1000 | Loss: 0.00007150
Iteration 98/1000 | Loss: 0.00002750
Iteration 99/1000 | Loss: 0.00002848
Iteration 100/1000 | Loss: 0.00002113
Iteration 101/1000 | Loss: 0.00002108
Iteration 102/1000 | Loss: 0.00002067
Iteration 103/1000 | Loss: 0.00078119
Iteration 104/1000 | Loss: 0.00038993
Iteration 105/1000 | Loss: 0.00003075
Iteration 106/1000 | Loss: 0.00017357
Iteration 107/1000 | Loss: 0.00019860
Iteration 108/1000 | Loss: 0.00002057
Iteration 109/1000 | Loss: 0.00001933
Iteration 110/1000 | Loss: 0.00001863
Iteration 111/1000 | Loss: 0.00010421
Iteration 112/1000 | Loss: 0.00067647
Iteration 113/1000 | Loss: 0.00027482
Iteration 114/1000 | Loss: 0.00003319
Iteration 115/1000 | Loss: 0.00002028
Iteration 116/1000 | Loss: 0.00001830
Iteration 117/1000 | Loss: 0.00001786
Iteration 118/1000 | Loss: 0.00001765
Iteration 119/1000 | Loss: 0.00010977
Iteration 120/1000 | Loss: 0.00020222
Iteration 121/1000 | Loss: 0.00003489
Iteration 122/1000 | Loss: 0.00045661
Iteration 123/1000 | Loss: 0.00017863
Iteration 124/1000 | Loss: 0.00005090
Iteration 125/1000 | Loss: 0.00011599
Iteration 126/1000 | Loss: 0.00002339
Iteration 127/1000 | Loss: 0.00004769
Iteration 128/1000 | Loss: 0.00032693
Iteration 129/1000 | Loss: 0.00003979
Iteration 130/1000 | Loss: 0.00028429
Iteration 131/1000 | Loss: 0.00031373
Iteration 132/1000 | Loss: 0.00026747
Iteration 133/1000 | Loss: 0.00009687
Iteration 134/1000 | Loss: 0.00063572
Iteration 135/1000 | Loss: 0.00040059
Iteration 136/1000 | Loss: 0.00019755
Iteration 137/1000 | Loss: 0.00022537
Iteration 138/1000 | Loss: 0.00002502
Iteration 139/1000 | Loss: 0.00030546
Iteration 140/1000 | Loss: 0.00016673
Iteration 141/1000 | Loss: 0.00005157
Iteration 142/1000 | Loss: 0.00002516
Iteration 143/1000 | Loss: 0.00002014
Iteration 144/1000 | Loss: 0.00005018
Iteration 145/1000 | Loss: 0.00011295
Iteration 146/1000 | Loss: 0.00004436
Iteration 147/1000 | Loss: 0.00005003
Iteration 148/1000 | Loss: 0.00011239
Iteration 149/1000 | Loss: 0.00005796
Iteration 150/1000 | Loss: 0.00002527
Iteration 151/1000 | Loss: 0.00003638
Iteration 152/1000 | Loss: 0.00001842
Iteration 153/1000 | Loss: 0.00005091
Iteration 154/1000 | Loss: 0.00001697
Iteration 155/1000 | Loss: 0.00015159
Iteration 156/1000 | Loss: 0.00001682
Iteration 157/1000 | Loss: 0.00001620
Iteration 158/1000 | Loss: 0.00001606
Iteration 159/1000 | Loss: 0.00001594
Iteration 160/1000 | Loss: 0.00001593
Iteration 161/1000 | Loss: 0.00001593
Iteration 162/1000 | Loss: 0.00001591
Iteration 163/1000 | Loss: 0.00001590
Iteration 164/1000 | Loss: 0.00001590
Iteration 165/1000 | Loss: 0.00001590
Iteration 166/1000 | Loss: 0.00001590
Iteration 167/1000 | Loss: 0.00001589
Iteration 168/1000 | Loss: 0.00001589
Iteration 169/1000 | Loss: 0.00001589
Iteration 170/1000 | Loss: 0.00001589
Iteration 171/1000 | Loss: 0.00001589
Iteration 172/1000 | Loss: 0.00001589
Iteration 173/1000 | Loss: 0.00001589
Iteration 174/1000 | Loss: 0.00001589
Iteration 175/1000 | Loss: 0.00001589
Iteration 176/1000 | Loss: 0.00001589
Iteration 177/1000 | Loss: 0.00001589
Iteration 178/1000 | Loss: 0.00001589
Iteration 179/1000 | Loss: 0.00001589
Iteration 180/1000 | Loss: 0.00001589
Iteration 181/1000 | Loss: 0.00001589
Iteration 182/1000 | Loss: 0.00001589
Iteration 183/1000 | Loss: 0.00001588
Iteration 184/1000 | Loss: 0.00001587
Iteration 185/1000 | Loss: 0.00001586
Iteration 186/1000 | Loss: 0.00001586
Iteration 187/1000 | Loss: 0.00001586
Iteration 188/1000 | Loss: 0.00001586
Iteration 189/1000 | Loss: 0.00001585
Iteration 190/1000 | Loss: 0.00001585
Iteration 191/1000 | Loss: 0.00001585
Iteration 192/1000 | Loss: 0.00001585
Iteration 193/1000 | Loss: 0.00001585
Iteration 194/1000 | Loss: 0.00001584
Iteration 195/1000 | Loss: 0.00001584
Iteration 196/1000 | Loss: 0.00001583
Iteration 197/1000 | Loss: 0.00001583
Iteration 198/1000 | Loss: 0.00001583
Iteration 199/1000 | Loss: 0.00001582
Iteration 200/1000 | Loss: 0.00001582
Iteration 201/1000 | Loss: 0.00001582
Iteration 202/1000 | Loss: 0.00001582
Iteration 203/1000 | Loss: 0.00001582
Iteration 204/1000 | Loss: 0.00001581
Iteration 205/1000 | Loss: 0.00001581
Iteration 206/1000 | Loss: 0.00001581
Iteration 207/1000 | Loss: 0.00001581
Iteration 208/1000 | Loss: 0.00001581
Iteration 209/1000 | Loss: 0.00001581
Iteration 210/1000 | Loss: 0.00001581
Iteration 211/1000 | Loss: 0.00001581
Iteration 212/1000 | Loss: 0.00001581
Iteration 213/1000 | Loss: 0.00001581
Iteration 214/1000 | Loss: 0.00001581
Iteration 215/1000 | Loss: 0.00001581
Iteration 216/1000 | Loss: 0.00001581
Iteration 217/1000 | Loss: 0.00001581
Iteration 218/1000 | Loss: 0.00001581
Iteration 219/1000 | Loss: 0.00001581
Iteration 220/1000 | Loss: 0.00001581
Iteration 221/1000 | Loss: 0.00001581
Iteration 222/1000 | Loss: 0.00001581
Iteration 223/1000 | Loss: 0.00001581
Iteration 224/1000 | Loss: 0.00001581
Iteration 225/1000 | Loss: 0.00001581
Iteration 226/1000 | Loss: 0.00001581
Iteration 227/1000 | Loss: 0.00001581
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 227. Stopping optimization.
Last 5 losses: [1.5806854207767174e-05, 1.5806854207767174e-05, 1.5806854207767174e-05, 1.5806854207767174e-05, 1.5806854207767174e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5806854207767174e-05

Optimization complete. Final v2v error: 3.3726978302001953 mm

Highest mean error: 4.521268367767334 mm for frame 75

Lowest mean error: 2.8503198623657227 mm for frame 4

Saving results

Total time: 264.5805399417877
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00906322
Iteration 2/25 | Loss: 0.00097976
Iteration 3/25 | Loss: 0.00069807
Iteration 4/25 | Loss: 0.00066428
Iteration 5/25 | Loss: 0.00065694
Iteration 6/25 | Loss: 0.00065534
Iteration 7/25 | Loss: 0.00065523
Iteration 8/25 | Loss: 0.00065523
Iteration 9/25 | Loss: 0.00065523
Iteration 10/25 | Loss: 0.00065523
Iteration 11/25 | Loss: 0.00065523
Iteration 12/25 | Loss: 0.00065523
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006552332197315991, 0.0006552332197315991, 0.0006552332197315991, 0.0006552332197315991, 0.0006552332197315991]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006552332197315991

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80735540
Iteration 2/25 | Loss: 0.00026299
Iteration 3/25 | Loss: 0.00026299
Iteration 4/25 | Loss: 0.00026299
Iteration 5/25 | Loss: 0.00026299
Iteration 6/25 | Loss: 0.00026299
Iteration 7/25 | Loss: 0.00026299
Iteration 8/25 | Loss: 0.00026299
Iteration 9/25 | Loss: 0.00026299
Iteration 10/25 | Loss: 0.00026299
Iteration 11/25 | Loss: 0.00026299
Iteration 12/25 | Loss: 0.00026299
Iteration 13/25 | Loss: 0.00026299
Iteration 14/25 | Loss: 0.00026299
Iteration 15/25 | Loss: 0.00026299
Iteration 16/25 | Loss: 0.00026299
Iteration 17/25 | Loss: 0.00026299
Iteration 18/25 | Loss: 0.00026299
Iteration 19/25 | Loss: 0.00026299
Iteration 20/25 | Loss: 0.00026299
Iteration 21/25 | Loss: 0.00026299
Iteration 22/25 | Loss: 0.00026299
Iteration 23/25 | Loss: 0.00026299
Iteration 24/25 | Loss: 0.00026299
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00026298617012798786, 0.00026298617012798786, 0.00026298617012798786, 0.00026298617012798786, 0.00026298617012798786]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00026298617012798786

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026299
Iteration 2/1000 | Loss: 0.00003484
Iteration 3/1000 | Loss: 0.00002682
Iteration 4/1000 | Loss: 0.00002377
Iteration 5/1000 | Loss: 0.00002155
Iteration 6/1000 | Loss: 0.00002050
Iteration 7/1000 | Loss: 0.00001979
Iteration 8/1000 | Loss: 0.00001923
Iteration 9/1000 | Loss: 0.00001896
Iteration 10/1000 | Loss: 0.00001884
Iteration 11/1000 | Loss: 0.00001883
Iteration 12/1000 | Loss: 0.00001877
Iteration 13/1000 | Loss: 0.00001876
Iteration 14/1000 | Loss: 0.00001864
Iteration 15/1000 | Loss: 0.00001860
Iteration 16/1000 | Loss: 0.00001859
Iteration 17/1000 | Loss: 0.00001859
Iteration 18/1000 | Loss: 0.00001859
Iteration 19/1000 | Loss: 0.00001859
Iteration 20/1000 | Loss: 0.00001858
Iteration 21/1000 | Loss: 0.00001858
Iteration 22/1000 | Loss: 0.00001857
Iteration 23/1000 | Loss: 0.00001857
Iteration 24/1000 | Loss: 0.00001857
Iteration 25/1000 | Loss: 0.00001856
Iteration 26/1000 | Loss: 0.00001856
Iteration 27/1000 | Loss: 0.00001856
Iteration 28/1000 | Loss: 0.00001855
Iteration 29/1000 | Loss: 0.00001855
Iteration 30/1000 | Loss: 0.00001855
Iteration 31/1000 | Loss: 0.00001855
Iteration 32/1000 | Loss: 0.00001855
Iteration 33/1000 | Loss: 0.00001855
Iteration 34/1000 | Loss: 0.00001855
Iteration 35/1000 | Loss: 0.00001855
Iteration 36/1000 | Loss: 0.00001854
Iteration 37/1000 | Loss: 0.00001854
Iteration 38/1000 | Loss: 0.00001854
Iteration 39/1000 | Loss: 0.00001854
Iteration 40/1000 | Loss: 0.00001854
Iteration 41/1000 | Loss: 0.00001853
Iteration 42/1000 | Loss: 0.00001853
Iteration 43/1000 | Loss: 0.00001853
Iteration 44/1000 | Loss: 0.00001853
Iteration 45/1000 | Loss: 0.00001853
Iteration 46/1000 | Loss: 0.00001852
Iteration 47/1000 | Loss: 0.00001852
Iteration 48/1000 | Loss: 0.00001852
Iteration 49/1000 | Loss: 0.00001852
Iteration 50/1000 | Loss: 0.00001852
Iteration 51/1000 | Loss: 0.00001851
Iteration 52/1000 | Loss: 0.00001851
Iteration 53/1000 | Loss: 0.00001851
Iteration 54/1000 | Loss: 0.00001851
Iteration 55/1000 | Loss: 0.00001850
Iteration 56/1000 | Loss: 0.00001850
Iteration 57/1000 | Loss: 0.00001849
Iteration 58/1000 | Loss: 0.00001849
Iteration 59/1000 | Loss: 0.00001849
Iteration 60/1000 | Loss: 0.00001849
Iteration 61/1000 | Loss: 0.00001849
Iteration 62/1000 | Loss: 0.00001849
Iteration 63/1000 | Loss: 0.00001849
Iteration 64/1000 | Loss: 0.00001848
Iteration 65/1000 | Loss: 0.00001848
Iteration 66/1000 | Loss: 0.00001848
Iteration 67/1000 | Loss: 0.00001848
Iteration 68/1000 | Loss: 0.00001848
Iteration 69/1000 | Loss: 0.00001848
Iteration 70/1000 | Loss: 0.00001848
Iteration 71/1000 | Loss: 0.00001848
Iteration 72/1000 | Loss: 0.00001848
Iteration 73/1000 | Loss: 0.00001847
Iteration 74/1000 | Loss: 0.00001847
Iteration 75/1000 | Loss: 0.00001847
Iteration 76/1000 | Loss: 0.00001846
Iteration 77/1000 | Loss: 0.00001846
Iteration 78/1000 | Loss: 0.00001845
Iteration 79/1000 | Loss: 0.00001845
Iteration 80/1000 | Loss: 0.00001845
Iteration 81/1000 | Loss: 0.00001845
Iteration 82/1000 | Loss: 0.00001845
Iteration 83/1000 | Loss: 0.00001845
Iteration 84/1000 | Loss: 0.00001845
Iteration 85/1000 | Loss: 0.00001844
Iteration 86/1000 | Loss: 0.00001844
Iteration 87/1000 | Loss: 0.00001844
Iteration 88/1000 | Loss: 0.00001844
Iteration 89/1000 | Loss: 0.00001844
Iteration 90/1000 | Loss: 0.00001844
Iteration 91/1000 | Loss: 0.00001844
Iteration 92/1000 | Loss: 0.00001843
Iteration 93/1000 | Loss: 0.00001843
Iteration 94/1000 | Loss: 0.00001843
Iteration 95/1000 | Loss: 0.00001841
Iteration 96/1000 | Loss: 0.00001841
Iteration 97/1000 | Loss: 0.00001841
Iteration 98/1000 | Loss: 0.00001841
Iteration 99/1000 | Loss: 0.00001841
Iteration 100/1000 | Loss: 0.00001840
Iteration 101/1000 | Loss: 0.00001840
Iteration 102/1000 | Loss: 0.00001840
Iteration 103/1000 | Loss: 0.00001839
Iteration 104/1000 | Loss: 0.00001839
Iteration 105/1000 | Loss: 0.00001839
Iteration 106/1000 | Loss: 0.00001838
Iteration 107/1000 | Loss: 0.00001838
Iteration 108/1000 | Loss: 0.00001838
Iteration 109/1000 | Loss: 0.00001837
Iteration 110/1000 | Loss: 0.00001836
Iteration 111/1000 | Loss: 0.00001836
Iteration 112/1000 | Loss: 0.00001836
Iteration 113/1000 | Loss: 0.00001835
Iteration 114/1000 | Loss: 0.00001835
Iteration 115/1000 | Loss: 0.00001835
Iteration 116/1000 | Loss: 0.00001835
Iteration 117/1000 | Loss: 0.00001835
Iteration 118/1000 | Loss: 0.00001834
Iteration 119/1000 | Loss: 0.00001834
Iteration 120/1000 | Loss: 0.00001834
Iteration 121/1000 | Loss: 0.00001834
Iteration 122/1000 | Loss: 0.00001833
Iteration 123/1000 | Loss: 0.00001833
Iteration 124/1000 | Loss: 0.00001833
Iteration 125/1000 | Loss: 0.00001833
Iteration 126/1000 | Loss: 0.00001833
Iteration 127/1000 | Loss: 0.00001833
Iteration 128/1000 | Loss: 0.00001833
Iteration 129/1000 | Loss: 0.00001833
Iteration 130/1000 | Loss: 0.00001832
Iteration 131/1000 | Loss: 0.00001832
Iteration 132/1000 | Loss: 0.00001832
Iteration 133/1000 | Loss: 0.00001832
Iteration 134/1000 | Loss: 0.00001832
Iteration 135/1000 | Loss: 0.00001831
Iteration 136/1000 | Loss: 0.00001831
Iteration 137/1000 | Loss: 0.00001831
Iteration 138/1000 | Loss: 0.00001831
Iteration 139/1000 | Loss: 0.00001830
Iteration 140/1000 | Loss: 0.00001830
Iteration 141/1000 | Loss: 0.00001830
Iteration 142/1000 | Loss: 0.00001830
Iteration 143/1000 | Loss: 0.00001829
Iteration 144/1000 | Loss: 0.00001829
Iteration 145/1000 | Loss: 0.00001829
Iteration 146/1000 | Loss: 0.00001829
Iteration 147/1000 | Loss: 0.00001829
Iteration 148/1000 | Loss: 0.00001829
Iteration 149/1000 | Loss: 0.00001829
Iteration 150/1000 | Loss: 0.00001829
Iteration 151/1000 | Loss: 0.00001827
Iteration 152/1000 | Loss: 0.00001827
Iteration 153/1000 | Loss: 0.00001827
Iteration 154/1000 | Loss: 0.00001827
Iteration 155/1000 | Loss: 0.00001827
Iteration 156/1000 | Loss: 0.00001827
Iteration 157/1000 | Loss: 0.00001827
Iteration 158/1000 | Loss: 0.00001827
Iteration 159/1000 | Loss: 0.00001827
Iteration 160/1000 | Loss: 0.00001827
Iteration 161/1000 | Loss: 0.00001826
Iteration 162/1000 | Loss: 0.00001826
Iteration 163/1000 | Loss: 0.00001826
Iteration 164/1000 | Loss: 0.00001826
Iteration 165/1000 | Loss: 0.00001826
Iteration 166/1000 | Loss: 0.00001825
Iteration 167/1000 | Loss: 0.00001825
Iteration 168/1000 | Loss: 0.00001824
Iteration 169/1000 | Loss: 0.00001823
Iteration 170/1000 | Loss: 0.00001823
Iteration 171/1000 | Loss: 0.00001823
Iteration 172/1000 | Loss: 0.00001822
Iteration 173/1000 | Loss: 0.00001822
Iteration 174/1000 | Loss: 0.00001822
Iteration 175/1000 | Loss: 0.00001822
Iteration 176/1000 | Loss: 0.00001822
Iteration 177/1000 | Loss: 0.00001822
Iteration 178/1000 | Loss: 0.00001822
Iteration 179/1000 | Loss: 0.00001821
Iteration 180/1000 | Loss: 0.00001821
Iteration 181/1000 | Loss: 0.00001821
Iteration 182/1000 | Loss: 0.00001821
Iteration 183/1000 | Loss: 0.00001821
Iteration 184/1000 | Loss: 0.00001821
Iteration 185/1000 | Loss: 0.00001821
Iteration 186/1000 | Loss: 0.00001821
Iteration 187/1000 | Loss: 0.00001820
Iteration 188/1000 | Loss: 0.00001820
Iteration 189/1000 | Loss: 0.00001820
Iteration 190/1000 | Loss: 0.00001820
Iteration 191/1000 | Loss: 0.00001820
Iteration 192/1000 | Loss: 0.00001820
Iteration 193/1000 | Loss: 0.00001820
Iteration 194/1000 | Loss: 0.00001820
Iteration 195/1000 | Loss: 0.00001820
Iteration 196/1000 | Loss: 0.00001819
Iteration 197/1000 | Loss: 0.00001819
Iteration 198/1000 | Loss: 0.00001819
Iteration 199/1000 | Loss: 0.00001819
Iteration 200/1000 | Loss: 0.00001819
Iteration 201/1000 | Loss: 0.00001819
Iteration 202/1000 | Loss: 0.00001819
Iteration 203/1000 | Loss: 0.00001819
Iteration 204/1000 | Loss: 0.00001818
Iteration 205/1000 | Loss: 0.00001818
Iteration 206/1000 | Loss: 0.00001818
Iteration 207/1000 | Loss: 0.00001818
Iteration 208/1000 | Loss: 0.00001818
Iteration 209/1000 | Loss: 0.00001818
Iteration 210/1000 | Loss: 0.00001818
Iteration 211/1000 | Loss: 0.00001818
Iteration 212/1000 | Loss: 0.00001818
Iteration 213/1000 | Loss: 0.00001818
Iteration 214/1000 | Loss: 0.00001818
Iteration 215/1000 | Loss: 0.00001818
Iteration 216/1000 | Loss: 0.00001818
Iteration 217/1000 | Loss: 0.00001818
Iteration 218/1000 | Loss: 0.00001818
Iteration 219/1000 | Loss: 0.00001818
Iteration 220/1000 | Loss: 0.00001818
Iteration 221/1000 | Loss: 0.00001818
Iteration 222/1000 | Loss: 0.00001818
Iteration 223/1000 | Loss: 0.00001818
Iteration 224/1000 | Loss: 0.00001818
Iteration 225/1000 | Loss: 0.00001818
Iteration 226/1000 | Loss: 0.00001818
Iteration 227/1000 | Loss: 0.00001818
Iteration 228/1000 | Loss: 0.00001818
Iteration 229/1000 | Loss: 0.00001818
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 229. Stopping optimization.
Last 5 losses: [1.8180779079557396e-05, 1.8180779079557396e-05, 1.8180779079557396e-05, 1.8180779079557396e-05, 1.8180779079557396e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8180779079557396e-05

Optimization complete. Final v2v error: 3.6660306453704834 mm

Highest mean error: 4.216753005981445 mm for frame 114

Lowest mean error: 3.1528618335723877 mm for frame 237

Saving results

Total time: 45.540953397750854
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00580696
Iteration 2/25 | Loss: 0.00114525
Iteration 3/25 | Loss: 0.00079141
Iteration 4/25 | Loss: 0.00071104
Iteration 5/25 | Loss: 0.00068366
Iteration 6/25 | Loss: 0.00066173
Iteration 7/25 | Loss: 0.00065409
Iteration 8/25 | Loss: 0.00065079
Iteration 9/25 | Loss: 0.00064956
Iteration 10/25 | Loss: 0.00064878
Iteration 11/25 | Loss: 0.00064821
Iteration 12/25 | Loss: 0.00064770
Iteration 13/25 | Loss: 0.00064752
Iteration 14/25 | Loss: 0.00064739
Iteration 15/25 | Loss: 0.00064734
Iteration 16/25 | Loss: 0.00064734
Iteration 17/25 | Loss: 0.00064734
Iteration 18/25 | Loss: 0.00064734
Iteration 19/25 | Loss: 0.00064734
Iteration 20/25 | Loss: 0.00064734
Iteration 21/25 | Loss: 0.00064734
Iteration 22/25 | Loss: 0.00064734
Iteration 23/25 | Loss: 0.00064734
Iteration 24/25 | Loss: 0.00064734
Iteration 25/25 | Loss: 0.00064733

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.12373734
Iteration 2/25 | Loss: 0.00024918
Iteration 3/25 | Loss: 0.00024917
Iteration 4/25 | Loss: 0.00024917
Iteration 5/25 | Loss: 0.00024917
Iteration 6/25 | Loss: 0.00024917
Iteration 7/25 | Loss: 0.00024917
Iteration 8/25 | Loss: 0.00024917
Iteration 9/25 | Loss: 0.00024917
Iteration 10/25 | Loss: 0.00024917
Iteration 11/25 | Loss: 0.00024917
Iteration 12/25 | Loss: 0.00024917
Iteration 13/25 | Loss: 0.00024917
Iteration 14/25 | Loss: 0.00024917
Iteration 15/25 | Loss: 0.00024917
Iteration 16/25 | Loss: 0.00024917
Iteration 17/25 | Loss: 0.00024917
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00024916965048760176, 0.00024916965048760176, 0.00024916965048760176, 0.00024916965048760176, 0.00024916965048760176]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00024916965048760176

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00024917
Iteration 2/1000 | Loss: 0.00003605
Iteration 3/1000 | Loss: 0.00002928
Iteration 4/1000 | Loss: 0.00002714
Iteration 5/1000 | Loss: 0.00002474
Iteration 6/1000 | Loss: 0.00002343
Iteration 7/1000 | Loss: 0.00002266
Iteration 8/1000 | Loss: 0.00002227
Iteration 9/1000 | Loss: 0.00002206
Iteration 10/1000 | Loss: 0.00002184
Iteration 11/1000 | Loss: 0.00002176
Iteration 12/1000 | Loss: 0.00002172
Iteration 13/1000 | Loss: 0.00002170
Iteration 14/1000 | Loss: 0.00002167
Iteration 15/1000 | Loss: 0.00002165
Iteration 16/1000 | Loss: 0.00002162
Iteration 17/1000 | Loss: 0.00002161
Iteration 18/1000 | Loss: 0.00002161
Iteration 19/1000 | Loss: 0.00002156
Iteration 20/1000 | Loss: 0.00002152
Iteration 21/1000 | Loss: 0.00002150
Iteration 22/1000 | Loss: 0.00002150
Iteration 23/1000 | Loss: 0.00002149
Iteration 24/1000 | Loss: 0.00002148
Iteration 25/1000 | Loss: 0.00002148
Iteration 26/1000 | Loss: 0.00002147
Iteration 27/1000 | Loss: 0.00002145
Iteration 28/1000 | Loss: 0.00002145
Iteration 29/1000 | Loss: 0.00002144
Iteration 30/1000 | Loss: 0.00002144
Iteration 31/1000 | Loss: 0.00002143
Iteration 32/1000 | Loss: 0.00002142
Iteration 33/1000 | Loss: 0.00002142
Iteration 34/1000 | Loss: 0.00002142
Iteration 35/1000 | Loss: 0.00002142
Iteration 36/1000 | Loss: 0.00002141
Iteration 37/1000 | Loss: 0.00002141
Iteration 38/1000 | Loss: 0.00002140
Iteration 39/1000 | Loss: 0.00002138
Iteration 40/1000 | Loss: 0.00002138
Iteration 41/1000 | Loss: 0.00002138
Iteration 42/1000 | Loss: 0.00002137
Iteration 43/1000 | Loss: 0.00002137
Iteration 44/1000 | Loss: 0.00002137
Iteration 45/1000 | Loss: 0.00002136
Iteration 46/1000 | Loss: 0.00002136
Iteration 47/1000 | Loss: 0.00002136
Iteration 48/1000 | Loss: 0.00002135
Iteration 49/1000 | Loss: 0.00002135
Iteration 50/1000 | Loss: 0.00002134
Iteration 51/1000 | Loss: 0.00002134
Iteration 52/1000 | Loss: 0.00002133
Iteration 53/1000 | Loss: 0.00002133
Iteration 54/1000 | Loss: 0.00002133
Iteration 55/1000 | Loss: 0.00002132
Iteration 56/1000 | Loss: 0.00002131
Iteration 57/1000 | Loss: 0.00002131
Iteration 58/1000 | Loss: 0.00002131
Iteration 59/1000 | Loss: 0.00002130
Iteration 60/1000 | Loss: 0.00002130
Iteration 61/1000 | Loss: 0.00002130
Iteration 62/1000 | Loss: 0.00002130
Iteration 63/1000 | Loss: 0.00002129
Iteration 64/1000 | Loss: 0.00002129
Iteration 65/1000 | Loss: 0.00002129
Iteration 66/1000 | Loss: 0.00002129
Iteration 67/1000 | Loss: 0.00002129
Iteration 68/1000 | Loss: 0.00002129
Iteration 69/1000 | Loss: 0.00002129
Iteration 70/1000 | Loss: 0.00002128
Iteration 71/1000 | Loss: 0.00002128
Iteration 72/1000 | Loss: 0.00002128
Iteration 73/1000 | Loss: 0.00002128
Iteration 74/1000 | Loss: 0.00002128
Iteration 75/1000 | Loss: 0.00002128
Iteration 76/1000 | Loss: 0.00002128
Iteration 77/1000 | Loss: 0.00002128
Iteration 78/1000 | Loss: 0.00002127
Iteration 79/1000 | Loss: 0.00002127
Iteration 80/1000 | Loss: 0.00002127
Iteration 81/1000 | Loss: 0.00002127
Iteration 82/1000 | Loss: 0.00002127
Iteration 83/1000 | Loss: 0.00002127
Iteration 84/1000 | Loss: 0.00002127
Iteration 85/1000 | Loss: 0.00002127
Iteration 86/1000 | Loss: 0.00002127
Iteration 87/1000 | Loss: 0.00002127
Iteration 88/1000 | Loss: 0.00002127
Iteration 89/1000 | Loss: 0.00002127
Iteration 90/1000 | Loss: 0.00002127
Iteration 91/1000 | Loss: 0.00002127
Iteration 92/1000 | Loss: 0.00002127
Iteration 93/1000 | Loss: 0.00002127
Iteration 94/1000 | Loss: 0.00002127
Iteration 95/1000 | Loss: 0.00002127
Iteration 96/1000 | Loss: 0.00002127
Iteration 97/1000 | Loss: 0.00002127
Iteration 98/1000 | Loss: 0.00002127
Iteration 99/1000 | Loss: 0.00002127
Iteration 100/1000 | Loss: 0.00002127
Iteration 101/1000 | Loss: 0.00002127
Iteration 102/1000 | Loss: 0.00002127
Iteration 103/1000 | Loss: 0.00002127
Iteration 104/1000 | Loss: 0.00002127
Iteration 105/1000 | Loss: 0.00002127
Iteration 106/1000 | Loss: 0.00002127
Iteration 107/1000 | Loss: 0.00002127
Iteration 108/1000 | Loss: 0.00002127
Iteration 109/1000 | Loss: 0.00002127
Iteration 110/1000 | Loss: 0.00002127
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [2.1273575839586556e-05, 2.1273575839586556e-05, 2.1273575839586556e-05, 2.1273575839586556e-05, 2.1273575839586556e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1273575839586556e-05

Optimization complete. Final v2v error: 3.931905508041382 mm

Highest mean error: 4.443329811096191 mm for frame 167

Lowest mean error: 3.2444372177124023 mm for frame 219

Saving results

Total time: 53.44089341163635
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00863586
Iteration 2/25 | Loss: 0.00077983
Iteration 3/25 | Loss: 0.00067548
Iteration 4/25 | Loss: 0.00064234
Iteration 5/25 | Loss: 0.00062974
Iteration 6/25 | Loss: 0.00062740
Iteration 7/25 | Loss: 0.00062697
Iteration 8/25 | Loss: 0.00062697
Iteration 9/25 | Loss: 0.00062697
Iteration 10/25 | Loss: 0.00062697
Iteration 11/25 | Loss: 0.00062697
Iteration 12/25 | Loss: 0.00062697
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006269694422371686, 0.0006269694422371686, 0.0006269694422371686, 0.0006269694422371686, 0.0006269694422371686]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006269694422371686

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.21056485
Iteration 2/25 | Loss: 0.00024685
Iteration 3/25 | Loss: 0.00024685
Iteration 4/25 | Loss: 0.00024684
Iteration 5/25 | Loss: 0.00024684
Iteration 6/25 | Loss: 0.00024684
Iteration 7/25 | Loss: 0.00024684
Iteration 8/25 | Loss: 0.00024684
Iteration 9/25 | Loss: 0.00024684
Iteration 10/25 | Loss: 0.00024684
Iteration 11/25 | Loss: 0.00024684
Iteration 12/25 | Loss: 0.00024684
Iteration 13/25 | Loss: 0.00024684
Iteration 14/25 | Loss: 0.00024684
Iteration 15/25 | Loss: 0.00024684
Iteration 16/25 | Loss: 0.00024684
Iteration 17/25 | Loss: 0.00024684
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00024684271193109453, 0.00024684271193109453, 0.00024684271193109453, 0.00024684271193109453, 0.00024684271193109453]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00024684271193109453

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00024684
Iteration 2/1000 | Loss: 0.00003577
Iteration 3/1000 | Loss: 0.00002475
Iteration 4/1000 | Loss: 0.00002231
Iteration 5/1000 | Loss: 0.00002110
Iteration 6/1000 | Loss: 0.00002037
Iteration 7/1000 | Loss: 0.00001965
Iteration 8/1000 | Loss: 0.00001919
Iteration 9/1000 | Loss: 0.00001878
Iteration 10/1000 | Loss: 0.00001855
Iteration 11/1000 | Loss: 0.00001843
Iteration 12/1000 | Loss: 0.00001827
Iteration 13/1000 | Loss: 0.00001826
Iteration 14/1000 | Loss: 0.00001825
Iteration 15/1000 | Loss: 0.00001825
Iteration 16/1000 | Loss: 0.00001822
Iteration 17/1000 | Loss: 0.00001820
Iteration 18/1000 | Loss: 0.00001819
Iteration 19/1000 | Loss: 0.00001818
Iteration 20/1000 | Loss: 0.00001817
Iteration 21/1000 | Loss: 0.00001815
Iteration 22/1000 | Loss: 0.00001814
Iteration 23/1000 | Loss: 0.00001813
Iteration 24/1000 | Loss: 0.00001811
Iteration 25/1000 | Loss: 0.00001811
Iteration 26/1000 | Loss: 0.00001811
Iteration 27/1000 | Loss: 0.00001811
Iteration 28/1000 | Loss: 0.00001811
Iteration 29/1000 | Loss: 0.00001811
Iteration 30/1000 | Loss: 0.00001811
Iteration 31/1000 | Loss: 0.00001811
Iteration 32/1000 | Loss: 0.00001811
Iteration 33/1000 | Loss: 0.00001811
Iteration 34/1000 | Loss: 0.00001810
Iteration 35/1000 | Loss: 0.00001810
Iteration 36/1000 | Loss: 0.00001810
Iteration 37/1000 | Loss: 0.00001809
Iteration 38/1000 | Loss: 0.00001809
Iteration 39/1000 | Loss: 0.00001808
Iteration 40/1000 | Loss: 0.00001808
Iteration 41/1000 | Loss: 0.00001808
Iteration 42/1000 | Loss: 0.00001807
Iteration 43/1000 | Loss: 0.00001807
Iteration 44/1000 | Loss: 0.00001807
Iteration 45/1000 | Loss: 0.00001806
Iteration 46/1000 | Loss: 0.00001806
Iteration 47/1000 | Loss: 0.00001805
Iteration 48/1000 | Loss: 0.00001805
Iteration 49/1000 | Loss: 0.00001805
Iteration 50/1000 | Loss: 0.00001805
Iteration 51/1000 | Loss: 0.00001805
Iteration 52/1000 | Loss: 0.00001804
Iteration 53/1000 | Loss: 0.00001804
Iteration 54/1000 | Loss: 0.00001803
Iteration 55/1000 | Loss: 0.00001803
Iteration 56/1000 | Loss: 0.00001803
Iteration 57/1000 | Loss: 0.00001803
Iteration 58/1000 | Loss: 0.00001803
Iteration 59/1000 | Loss: 0.00001803
Iteration 60/1000 | Loss: 0.00001802
Iteration 61/1000 | Loss: 0.00001802
Iteration 62/1000 | Loss: 0.00001802
Iteration 63/1000 | Loss: 0.00001802
Iteration 64/1000 | Loss: 0.00001802
Iteration 65/1000 | Loss: 0.00001802
Iteration 66/1000 | Loss: 0.00001801
Iteration 67/1000 | Loss: 0.00001801
Iteration 68/1000 | Loss: 0.00001801
Iteration 69/1000 | Loss: 0.00001801
Iteration 70/1000 | Loss: 0.00001801
Iteration 71/1000 | Loss: 0.00001800
Iteration 72/1000 | Loss: 0.00001800
Iteration 73/1000 | Loss: 0.00001800
Iteration 74/1000 | Loss: 0.00001799
Iteration 75/1000 | Loss: 0.00001799
Iteration 76/1000 | Loss: 0.00001799
Iteration 77/1000 | Loss: 0.00001798
Iteration 78/1000 | Loss: 0.00001798
Iteration 79/1000 | Loss: 0.00001797
Iteration 80/1000 | Loss: 0.00001797
Iteration 81/1000 | Loss: 0.00001796
Iteration 82/1000 | Loss: 0.00001795
Iteration 83/1000 | Loss: 0.00001795
Iteration 84/1000 | Loss: 0.00001795
Iteration 85/1000 | Loss: 0.00001795
Iteration 86/1000 | Loss: 0.00001794
Iteration 87/1000 | Loss: 0.00001794
Iteration 88/1000 | Loss: 0.00001794
Iteration 89/1000 | Loss: 0.00001794
Iteration 90/1000 | Loss: 0.00001794
Iteration 91/1000 | Loss: 0.00001794
Iteration 92/1000 | Loss: 0.00001794
Iteration 93/1000 | Loss: 0.00001794
Iteration 94/1000 | Loss: 0.00001794
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.7943737475434318e-05, 1.7943737475434318e-05, 1.7943737475434318e-05, 1.7943737475434318e-05, 1.7943737475434318e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7943737475434318e-05

Optimization complete. Final v2v error: 3.60606050491333 mm

Highest mean error: 4.259822845458984 mm for frame 131

Lowest mean error: 3.0832576751708984 mm for frame 44

Saving results

Total time: 37.35213041305542
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00384262
Iteration 2/25 | Loss: 0.00079777
Iteration 3/25 | Loss: 0.00064979
Iteration 4/25 | Loss: 0.00062610
Iteration 5/25 | Loss: 0.00061942
Iteration 6/25 | Loss: 0.00061674
Iteration 7/25 | Loss: 0.00061605
Iteration 8/25 | Loss: 0.00061602
Iteration 9/25 | Loss: 0.00061602
Iteration 10/25 | Loss: 0.00061602
Iteration 11/25 | Loss: 0.00061602
Iteration 12/25 | Loss: 0.00061602
Iteration 13/25 | Loss: 0.00061602
Iteration 14/25 | Loss: 0.00061602
Iteration 15/25 | Loss: 0.00061602
Iteration 16/25 | Loss: 0.00061602
Iteration 17/25 | Loss: 0.00061602
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006160184275358915, 0.0006160184275358915, 0.0006160184275358915, 0.0006160184275358915, 0.0006160184275358915]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006160184275358915

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31251788
Iteration 2/25 | Loss: 0.00028449
Iteration 3/25 | Loss: 0.00028448
Iteration 4/25 | Loss: 0.00028448
Iteration 5/25 | Loss: 0.00028448
Iteration 6/25 | Loss: 0.00028448
Iteration 7/25 | Loss: 0.00028448
Iteration 8/25 | Loss: 0.00028448
Iteration 9/25 | Loss: 0.00028448
Iteration 10/25 | Loss: 0.00028448
Iteration 11/25 | Loss: 0.00028448
Iteration 12/25 | Loss: 0.00028448
Iteration 13/25 | Loss: 0.00028448
Iteration 14/25 | Loss: 0.00028448
Iteration 15/25 | Loss: 0.00028448
Iteration 16/25 | Loss: 0.00028448
Iteration 17/25 | Loss: 0.00028448
Iteration 18/25 | Loss: 0.00028448
Iteration 19/25 | Loss: 0.00028448
Iteration 20/25 | Loss: 0.00028448
Iteration 21/25 | Loss: 0.00028448
Iteration 22/25 | Loss: 0.00028448
Iteration 23/25 | Loss: 0.00028448
Iteration 24/25 | Loss: 0.00028448
Iteration 25/25 | Loss: 0.00028448

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028448
Iteration 2/1000 | Loss: 0.00004380
Iteration 3/1000 | Loss: 0.00002863
Iteration 4/1000 | Loss: 0.00002474
Iteration 5/1000 | Loss: 0.00002302
Iteration 6/1000 | Loss: 0.00002144
Iteration 7/1000 | Loss: 0.00002041
Iteration 8/1000 | Loss: 0.00001983
Iteration 9/1000 | Loss: 0.00001948
Iteration 10/1000 | Loss: 0.00001918
Iteration 11/1000 | Loss: 0.00001894
Iteration 12/1000 | Loss: 0.00001878
Iteration 13/1000 | Loss: 0.00001876
Iteration 14/1000 | Loss: 0.00001867
Iteration 15/1000 | Loss: 0.00001866
Iteration 16/1000 | Loss: 0.00001858
Iteration 17/1000 | Loss: 0.00001855
Iteration 18/1000 | Loss: 0.00001854
Iteration 19/1000 | Loss: 0.00001853
Iteration 20/1000 | Loss: 0.00001851
Iteration 21/1000 | Loss: 0.00001851
Iteration 22/1000 | Loss: 0.00001849
Iteration 23/1000 | Loss: 0.00001848
Iteration 24/1000 | Loss: 0.00001843
Iteration 25/1000 | Loss: 0.00001833
Iteration 26/1000 | Loss: 0.00001832
Iteration 27/1000 | Loss: 0.00001831
Iteration 28/1000 | Loss: 0.00001831
Iteration 29/1000 | Loss: 0.00001831
Iteration 30/1000 | Loss: 0.00001830
Iteration 31/1000 | Loss: 0.00001829
Iteration 32/1000 | Loss: 0.00001828
Iteration 33/1000 | Loss: 0.00001828
Iteration 34/1000 | Loss: 0.00001828
Iteration 35/1000 | Loss: 0.00001828
Iteration 36/1000 | Loss: 0.00001827
Iteration 37/1000 | Loss: 0.00001827
Iteration 38/1000 | Loss: 0.00001825
Iteration 39/1000 | Loss: 0.00001825
Iteration 40/1000 | Loss: 0.00001825
Iteration 41/1000 | Loss: 0.00001825
Iteration 42/1000 | Loss: 0.00001825
Iteration 43/1000 | Loss: 0.00001824
Iteration 44/1000 | Loss: 0.00001824
Iteration 45/1000 | Loss: 0.00001824
Iteration 46/1000 | Loss: 0.00001824
Iteration 47/1000 | Loss: 0.00001823
Iteration 48/1000 | Loss: 0.00001823
Iteration 49/1000 | Loss: 0.00001822
Iteration 50/1000 | Loss: 0.00001822
Iteration 51/1000 | Loss: 0.00001822
Iteration 52/1000 | Loss: 0.00001822
Iteration 53/1000 | Loss: 0.00001821
Iteration 54/1000 | Loss: 0.00001821
Iteration 55/1000 | Loss: 0.00001821
Iteration 56/1000 | Loss: 0.00001821
Iteration 57/1000 | Loss: 0.00001821
Iteration 58/1000 | Loss: 0.00001821
Iteration 59/1000 | Loss: 0.00001821
Iteration 60/1000 | Loss: 0.00001821
Iteration 61/1000 | Loss: 0.00001821
Iteration 62/1000 | Loss: 0.00001821
Iteration 63/1000 | Loss: 0.00001821
Iteration 64/1000 | Loss: 0.00001821
Iteration 65/1000 | Loss: 0.00001821
Iteration 66/1000 | Loss: 0.00001821
Iteration 67/1000 | Loss: 0.00001821
Iteration 68/1000 | Loss: 0.00001820
Iteration 69/1000 | Loss: 0.00001820
Iteration 70/1000 | Loss: 0.00001820
Iteration 71/1000 | Loss: 0.00001820
Iteration 72/1000 | Loss: 0.00001820
Iteration 73/1000 | Loss: 0.00001820
Iteration 74/1000 | Loss: 0.00001820
Iteration 75/1000 | Loss: 0.00001820
Iteration 76/1000 | Loss: 0.00001820
Iteration 77/1000 | Loss: 0.00001820
Iteration 78/1000 | Loss: 0.00001820
Iteration 79/1000 | Loss: 0.00001820
Iteration 80/1000 | Loss: 0.00001820
Iteration 81/1000 | Loss: 0.00001820
Iteration 82/1000 | Loss: 0.00001820
Iteration 83/1000 | Loss: 0.00001819
Iteration 84/1000 | Loss: 0.00001819
Iteration 85/1000 | Loss: 0.00001819
Iteration 86/1000 | Loss: 0.00001819
Iteration 87/1000 | Loss: 0.00001819
Iteration 88/1000 | Loss: 0.00001819
Iteration 89/1000 | Loss: 0.00001819
Iteration 90/1000 | Loss: 0.00001819
Iteration 91/1000 | Loss: 0.00001819
Iteration 92/1000 | Loss: 0.00001819
Iteration 93/1000 | Loss: 0.00001818
Iteration 94/1000 | Loss: 0.00001818
Iteration 95/1000 | Loss: 0.00001818
Iteration 96/1000 | Loss: 0.00001818
Iteration 97/1000 | Loss: 0.00001818
Iteration 98/1000 | Loss: 0.00001818
Iteration 99/1000 | Loss: 0.00001818
Iteration 100/1000 | Loss: 0.00001818
Iteration 101/1000 | Loss: 0.00001818
Iteration 102/1000 | Loss: 0.00001818
Iteration 103/1000 | Loss: 0.00001817
Iteration 104/1000 | Loss: 0.00001817
Iteration 105/1000 | Loss: 0.00001817
Iteration 106/1000 | Loss: 0.00001817
Iteration 107/1000 | Loss: 0.00001817
Iteration 108/1000 | Loss: 0.00001817
Iteration 109/1000 | Loss: 0.00001817
Iteration 110/1000 | Loss: 0.00001817
Iteration 111/1000 | Loss: 0.00001817
Iteration 112/1000 | Loss: 0.00001817
Iteration 113/1000 | Loss: 0.00001816
Iteration 114/1000 | Loss: 0.00001816
Iteration 115/1000 | Loss: 0.00001816
Iteration 116/1000 | Loss: 0.00001816
Iteration 117/1000 | Loss: 0.00001816
Iteration 118/1000 | Loss: 0.00001816
Iteration 119/1000 | Loss: 0.00001816
Iteration 120/1000 | Loss: 0.00001816
Iteration 121/1000 | Loss: 0.00001815
Iteration 122/1000 | Loss: 0.00001815
Iteration 123/1000 | Loss: 0.00001815
Iteration 124/1000 | Loss: 0.00001815
Iteration 125/1000 | Loss: 0.00001815
Iteration 126/1000 | Loss: 0.00001815
Iteration 127/1000 | Loss: 0.00001815
Iteration 128/1000 | Loss: 0.00001815
Iteration 129/1000 | Loss: 0.00001815
Iteration 130/1000 | Loss: 0.00001815
Iteration 131/1000 | Loss: 0.00001815
Iteration 132/1000 | Loss: 0.00001815
Iteration 133/1000 | Loss: 0.00001815
Iteration 134/1000 | Loss: 0.00001815
Iteration 135/1000 | Loss: 0.00001815
Iteration 136/1000 | Loss: 0.00001815
Iteration 137/1000 | Loss: 0.00001815
Iteration 138/1000 | Loss: 0.00001815
Iteration 139/1000 | Loss: 0.00001815
Iteration 140/1000 | Loss: 0.00001815
Iteration 141/1000 | Loss: 0.00001815
Iteration 142/1000 | Loss: 0.00001815
Iteration 143/1000 | Loss: 0.00001815
Iteration 144/1000 | Loss: 0.00001815
Iteration 145/1000 | Loss: 0.00001815
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [1.8152770280721597e-05, 1.8152770280721597e-05, 1.8152770280721597e-05, 1.8152770280721597e-05, 1.8152770280721597e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8152770280721597e-05

Optimization complete. Final v2v error: 3.564986228942871 mm

Highest mean error: 4.139155864715576 mm for frame 111

Lowest mean error: 3.04762864112854 mm for frame 0

Saving results

Total time: 41.9233603477478
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_28_us_1478/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_28_us_1478/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01032452
Iteration 2/25 | Loss: 0.00247595
Iteration 3/25 | Loss: 0.00196457
Iteration 4/25 | Loss: 0.00171660
Iteration 5/25 | Loss: 0.00160084
Iteration 6/25 | Loss: 0.00142761
Iteration 7/25 | Loss: 0.00118386
Iteration 8/25 | Loss: 0.00098796
Iteration 9/25 | Loss: 0.00087276
Iteration 10/25 | Loss: 0.00082190
Iteration 11/25 | Loss: 0.00081269
Iteration 12/25 | Loss: 0.00080743
Iteration 13/25 | Loss: 0.00080579
Iteration 14/25 | Loss: 0.00080339
Iteration 15/25 | Loss: 0.00079465
Iteration 16/25 | Loss: 0.00077008
Iteration 17/25 | Loss: 0.00076001
Iteration 18/25 | Loss: 0.00075352
Iteration 19/25 | Loss: 0.00074750
Iteration 20/25 | Loss: 0.00074432
Iteration 21/25 | Loss: 0.00074670
Iteration 22/25 | Loss: 0.00074180
Iteration 23/25 | Loss: 0.00073944
Iteration 24/25 | Loss: 0.00073855
Iteration 25/25 | Loss: 0.00073846

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32155418
Iteration 2/25 | Loss: 0.00121920
Iteration 3/25 | Loss: 0.00121918
Iteration 4/25 | Loss: 0.00121918
Iteration 5/25 | Loss: 0.00121918
Iteration 6/25 | Loss: 0.00121918
Iteration 7/25 | Loss: 0.00121918
Iteration 8/25 | Loss: 0.00121918
Iteration 9/25 | Loss: 0.00121918
Iteration 10/25 | Loss: 0.00121918
Iteration 11/25 | Loss: 0.00121918
Iteration 12/25 | Loss: 0.00121918
Iteration 13/25 | Loss: 0.00121918
Iteration 14/25 | Loss: 0.00121918
Iteration 15/25 | Loss: 0.00121918
Iteration 16/25 | Loss: 0.00121918
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012191813439130783, 0.0012191813439130783, 0.0012191813439130783, 0.0012191813439130783, 0.0012191813439130783]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012191813439130783

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00121918
Iteration 2/1000 | Loss: 0.00100171
Iteration 3/1000 | Loss: 0.00054861
Iteration 4/1000 | Loss: 0.00014930
Iteration 5/1000 | Loss: 0.00011351
Iteration 6/1000 | Loss: 0.00007966
Iteration 7/1000 | Loss: 0.00006119
Iteration 8/1000 | Loss: 0.00004722
Iteration 9/1000 | Loss: 0.00005718
Iteration 10/1000 | Loss: 0.00004542
Iteration 11/1000 | Loss: 0.00003684
Iteration 12/1000 | Loss: 0.00014222
Iteration 13/1000 | Loss: 0.00003967
Iteration 14/1000 | Loss: 0.00003817
Iteration 15/1000 | Loss: 0.00016328
Iteration 16/1000 | Loss: 0.00003799
Iteration 17/1000 | Loss: 0.00004848
Iteration 18/1000 | Loss: 0.00004019
Iteration 19/1000 | Loss: 0.00004911
Iteration 20/1000 | Loss: 0.00003216
Iteration 21/1000 | Loss: 0.00004407
Iteration 22/1000 | Loss: 0.00004347
Iteration 23/1000 | Loss: 0.00003956
Iteration 24/1000 | Loss: 0.00003882
Iteration 25/1000 | Loss: 0.00003576
Iteration 26/1000 | Loss: 0.00003562
Iteration 27/1000 | Loss: 0.00003448
Iteration 28/1000 | Loss: 0.00003483
Iteration 29/1000 | Loss: 0.00003979
Iteration 30/1000 | Loss: 0.00004332
Iteration 31/1000 | Loss: 0.00004393
Iteration 32/1000 | Loss: 0.00003928
Iteration 33/1000 | Loss: 0.00003129
Iteration 34/1000 | Loss: 0.00003882
Iteration 35/1000 | Loss: 0.00002945
Iteration 36/1000 | Loss: 0.00004796
Iteration 37/1000 | Loss: 0.00003819
Iteration 38/1000 | Loss: 0.00004562
Iteration 39/1000 | Loss: 0.00003491
Iteration 40/1000 | Loss: 0.00004832
Iteration 41/1000 | Loss: 0.00003799
Iteration 42/1000 | Loss: 0.00003919
Iteration 43/1000 | Loss: 0.00003523
Iteration 44/1000 | Loss: 0.00004083
Iteration 45/1000 | Loss: 0.00003116
Iteration 46/1000 | Loss: 0.00003573
Iteration 47/1000 | Loss: 0.00003800
Iteration 48/1000 | Loss: 0.00003870
Iteration 49/1000 | Loss: 0.00003688
Iteration 50/1000 | Loss: 0.00004160
Iteration 51/1000 | Loss: 0.00004114
Iteration 52/1000 | Loss: 0.00003941
Iteration 53/1000 | Loss: 0.00003942
Iteration 54/1000 | Loss: 0.00003416
Iteration 55/1000 | Loss: 0.00003833
Iteration 56/1000 | Loss: 0.00003900
Iteration 57/1000 | Loss: 0.00003825
Iteration 58/1000 | Loss: 0.00003875
Iteration 59/1000 | Loss: 0.00005494
Iteration 60/1000 | Loss: 0.00003332
Iteration 61/1000 | Loss: 0.00004437
Iteration 62/1000 | Loss: 0.00003278
Iteration 63/1000 | Loss: 0.00003970
Iteration 64/1000 | Loss: 0.00004608
Iteration 65/1000 | Loss: 0.00004144
Iteration 66/1000 | Loss: 0.00002971
Iteration 67/1000 | Loss: 0.00002797
Iteration 68/1000 | Loss: 0.00002634
Iteration 69/1000 | Loss: 0.00002565
Iteration 70/1000 | Loss: 0.00002526
Iteration 71/1000 | Loss: 0.00002506
Iteration 72/1000 | Loss: 0.00002492
Iteration 73/1000 | Loss: 0.00002481
Iteration 74/1000 | Loss: 0.00002480
Iteration 75/1000 | Loss: 0.00002479
Iteration 76/1000 | Loss: 0.00002479
Iteration 77/1000 | Loss: 0.00002478
Iteration 78/1000 | Loss: 0.00002478
Iteration 79/1000 | Loss: 0.00002478
Iteration 80/1000 | Loss: 0.00002478
Iteration 81/1000 | Loss: 0.00002478
Iteration 82/1000 | Loss: 0.00002477
Iteration 83/1000 | Loss: 0.00002477
Iteration 84/1000 | Loss: 0.00002477
Iteration 85/1000 | Loss: 0.00002476
Iteration 86/1000 | Loss: 0.00002475
Iteration 87/1000 | Loss: 0.00002475
Iteration 88/1000 | Loss: 0.00002475
Iteration 89/1000 | Loss: 0.00002474
Iteration 90/1000 | Loss: 0.00002474
Iteration 91/1000 | Loss: 0.00002473
Iteration 92/1000 | Loss: 0.00002472
Iteration 93/1000 | Loss: 0.00002472
Iteration 94/1000 | Loss: 0.00002472
Iteration 95/1000 | Loss: 0.00002472
Iteration 96/1000 | Loss: 0.00002472
Iteration 97/1000 | Loss: 0.00002471
Iteration 98/1000 | Loss: 0.00002471
Iteration 99/1000 | Loss: 0.00002471
Iteration 100/1000 | Loss: 0.00002471
Iteration 101/1000 | Loss: 0.00002471
Iteration 102/1000 | Loss: 0.00002471
Iteration 103/1000 | Loss: 0.00002471
Iteration 104/1000 | Loss: 0.00002471
Iteration 105/1000 | Loss: 0.00002471
Iteration 106/1000 | Loss: 0.00002471
Iteration 107/1000 | Loss: 0.00002471
Iteration 108/1000 | Loss: 0.00002471
Iteration 109/1000 | Loss: 0.00002471
Iteration 110/1000 | Loss: 0.00002471
Iteration 111/1000 | Loss: 0.00002471
Iteration 112/1000 | Loss: 0.00002470
Iteration 113/1000 | Loss: 0.00002470
Iteration 114/1000 | Loss: 0.00002470
Iteration 115/1000 | Loss: 0.00002470
Iteration 116/1000 | Loss: 0.00002469
Iteration 117/1000 | Loss: 0.00002469
Iteration 118/1000 | Loss: 0.00002469
Iteration 119/1000 | Loss: 0.00002469
Iteration 120/1000 | Loss: 0.00002469
Iteration 121/1000 | Loss: 0.00002469
Iteration 122/1000 | Loss: 0.00002469
Iteration 123/1000 | Loss: 0.00002468
Iteration 124/1000 | Loss: 0.00002468
Iteration 125/1000 | Loss: 0.00002468
Iteration 126/1000 | Loss: 0.00002468
Iteration 127/1000 | Loss: 0.00002467
Iteration 128/1000 | Loss: 0.00002467
Iteration 129/1000 | Loss: 0.00002467
Iteration 130/1000 | Loss: 0.00002467
Iteration 131/1000 | Loss: 0.00002467
Iteration 132/1000 | Loss: 0.00002466
Iteration 133/1000 | Loss: 0.00002466
Iteration 134/1000 | Loss: 0.00002466
Iteration 135/1000 | Loss: 0.00002466
Iteration 136/1000 | Loss: 0.00002466
Iteration 137/1000 | Loss: 0.00002465
Iteration 138/1000 | Loss: 0.00002465
Iteration 139/1000 | Loss: 0.00002465
Iteration 140/1000 | Loss: 0.00002465
Iteration 141/1000 | Loss: 0.00002465
Iteration 142/1000 | Loss: 0.00002465
Iteration 143/1000 | Loss: 0.00002465
Iteration 144/1000 | Loss: 0.00002465
Iteration 145/1000 | Loss: 0.00002465
Iteration 146/1000 | Loss: 0.00002465
Iteration 147/1000 | Loss: 0.00002465
Iteration 148/1000 | Loss: 0.00002465
Iteration 149/1000 | Loss: 0.00002465
Iteration 150/1000 | Loss: 0.00002464
Iteration 151/1000 | Loss: 0.00002464
Iteration 152/1000 | Loss: 0.00002464
Iteration 153/1000 | Loss: 0.00002464
Iteration 154/1000 | Loss: 0.00002464
Iteration 155/1000 | Loss: 0.00002464
Iteration 156/1000 | Loss: 0.00002464
Iteration 157/1000 | Loss: 0.00002464
Iteration 158/1000 | Loss: 0.00002464
Iteration 159/1000 | Loss: 0.00002464
Iteration 160/1000 | Loss: 0.00002464
Iteration 161/1000 | Loss: 0.00002464
Iteration 162/1000 | Loss: 0.00002464
Iteration 163/1000 | Loss: 0.00002463
Iteration 164/1000 | Loss: 0.00002463
Iteration 165/1000 | Loss: 0.00002463
Iteration 166/1000 | Loss: 0.00002463
Iteration 167/1000 | Loss: 0.00002462
Iteration 168/1000 | Loss: 0.00002462
Iteration 169/1000 | Loss: 0.00002462
Iteration 170/1000 | Loss: 0.00002461
Iteration 171/1000 | Loss: 0.00002461
Iteration 172/1000 | Loss: 0.00002461
Iteration 173/1000 | Loss: 0.00002460
Iteration 174/1000 | Loss: 0.00002460
Iteration 175/1000 | Loss: 0.00002460
Iteration 176/1000 | Loss: 0.00002460
Iteration 177/1000 | Loss: 0.00002460
Iteration 178/1000 | Loss: 0.00002460
Iteration 179/1000 | Loss: 0.00002460
Iteration 180/1000 | Loss: 0.00002460
Iteration 181/1000 | Loss: 0.00002460
Iteration 182/1000 | Loss: 0.00002460
Iteration 183/1000 | Loss: 0.00002460
Iteration 184/1000 | Loss: 0.00002460
Iteration 185/1000 | Loss: 0.00002460
Iteration 186/1000 | Loss: 0.00002460
Iteration 187/1000 | Loss: 0.00002460
Iteration 188/1000 | Loss: 0.00002460
Iteration 189/1000 | Loss: 0.00002460
Iteration 190/1000 | Loss: 0.00002460
Iteration 191/1000 | Loss: 0.00002460
Iteration 192/1000 | Loss: 0.00002460
Iteration 193/1000 | Loss: 0.00002460
Iteration 194/1000 | Loss: 0.00002460
Iteration 195/1000 | Loss: 0.00002460
Iteration 196/1000 | Loss: 0.00002460
Iteration 197/1000 | Loss: 0.00002460
Iteration 198/1000 | Loss: 0.00002459
Iteration 199/1000 | Loss: 0.00002459
Iteration 200/1000 | Loss: 0.00002459
Iteration 201/1000 | Loss: 0.00002459
Iteration 202/1000 | Loss: 0.00002459
Iteration 203/1000 | Loss: 0.00002459
Iteration 204/1000 | Loss: 0.00002459
Iteration 205/1000 | Loss: 0.00002459
Iteration 206/1000 | Loss: 0.00002459
Iteration 207/1000 | Loss: 0.00002459
Iteration 208/1000 | Loss: 0.00002459
Iteration 209/1000 | Loss: 0.00002459
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 209. Stopping optimization.
Last 5 losses: [2.459429560985882e-05, 2.459429560985882e-05, 2.459429560985882e-05, 2.459429560985882e-05, 2.459429560985882e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.459429560985882e-05

Optimization complete. Final v2v error: 4.012277126312256 mm

Highest mean error: 12.061161041259766 mm for frame 172

Lowest mean error: 3.437849521636963 mm for frame 59

Saving results

Total time: 177.1710684299469
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00980140
Iteration 2/25 | Loss: 0.00403524
Iteration 3/25 | Loss: 0.00228590
Iteration 4/25 | Loss: 0.00213149
Iteration 5/25 | Loss: 0.00220390
Iteration 6/25 | Loss: 0.00195731
Iteration 7/25 | Loss: 0.00147224
Iteration 8/25 | Loss: 0.00144396
Iteration 9/25 | Loss: 0.00122054
Iteration 10/25 | Loss: 0.00117472
Iteration 11/25 | Loss: 0.00117930
Iteration 12/25 | Loss: 0.00116389
Iteration 13/25 | Loss: 0.00115713
Iteration 14/25 | Loss: 0.00115290
Iteration 15/25 | Loss: 0.00115504
Iteration 16/25 | Loss: 0.00117097
Iteration 17/25 | Loss: 0.00116642
Iteration 18/25 | Loss: 0.00115756
Iteration 19/25 | Loss: 0.00115243
Iteration 20/25 | Loss: 0.00114765
Iteration 21/25 | Loss: 0.00114498
Iteration 22/25 | Loss: 0.00114426
Iteration 23/25 | Loss: 0.00114397
Iteration 24/25 | Loss: 0.00114393
Iteration 25/25 | Loss: 0.00114382

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29270506
Iteration 2/25 | Loss: 0.00128837
Iteration 3/25 | Loss: 0.00128837
Iteration 4/25 | Loss: 0.00128837
Iteration 5/25 | Loss: 0.00128837
Iteration 6/25 | Loss: 0.00128837
Iteration 7/25 | Loss: 0.00128837
Iteration 8/25 | Loss: 0.00128837
Iteration 9/25 | Loss: 0.00128837
Iteration 10/25 | Loss: 0.00128837
Iteration 11/25 | Loss: 0.00128837
Iteration 12/25 | Loss: 0.00128837
Iteration 13/25 | Loss: 0.00128837
Iteration 14/25 | Loss: 0.00128837
Iteration 15/25 | Loss: 0.00128837
Iteration 16/25 | Loss: 0.00128837
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012883684830740094, 0.0012883684830740094, 0.0012883684830740094, 0.0012883684830740094, 0.0012883684830740094]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012883684830740094

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00128837
Iteration 2/1000 | Loss: 0.00019675
Iteration 3/1000 | Loss: 0.00026432
Iteration 4/1000 | Loss: 0.00036605
Iteration 5/1000 | Loss: 0.00022911
Iteration 6/1000 | Loss: 0.00074551
Iteration 7/1000 | Loss: 0.00044664
Iteration 8/1000 | Loss: 0.00071379
Iteration 9/1000 | Loss: 0.00114035
Iteration 10/1000 | Loss: 0.00070866
Iteration 11/1000 | Loss: 0.00014727
Iteration 12/1000 | Loss: 0.00011154
Iteration 13/1000 | Loss: 0.00009432
Iteration 14/1000 | Loss: 0.00008200
Iteration 15/1000 | Loss: 0.00007494
Iteration 16/1000 | Loss: 0.00007112
Iteration 17/1000 | Loss: 0.00006781
Iteration 18/1000 | Loss: 0.00006590
Iteration 19/1000 | Loss: 0.00006489
Iteration 20/1000 | Loss: 0.00006413
Iteration 21/1000 | Loss: 0.00006341
Iteration 22/1000 | Loss: 0.00029424
Iteration 23/1000 | Loss: 0.00006842
Iteration 24/1000 | Loss: 0.00006411
Iteration 25/1000 | Loss: 0.00030387
Iteration 26/1000 | Loss: 0.00008338
Iteration 27/1000 | Loss: 0.00006823
Iteration 28/1000 | Loss: 0.00006444
Iteration 29/1000 | Loss: 0.00006195
Iteration 30/1000 | Loss: 0.00006094
Iteration 31/1000 | Loss: 0.00006014
Iteration 32/1000 | Loss: 0.00005959
Iteration 33/1000 | Loss: 0.00005929
Iteration 34/1000 | Loss: 0.00005927
Iteration 35/1000 | Loss: 0.00005910
Iteration 36/1000 | Loss: 0.00005900
Iteration 37/1000 | Loss: 0.00005898
Iteration 38/1000 | Loss: 0.00005897
Iteration 39/1000 | Loss: 0.00005893
Iteration 40/1000 | Loss: 0.00005893
Iteration 41/1000 | Loss: 0.00005893
Iteration 42/1000 | Loss: 0.00005890
Iteration 43/1000 | Loss: 0.00005888
Iteration 44/1000 | Loss: 0.00005884
Iteration 45/1000 | Loss: 0.00005884
Iteration 46/1000 | Loss: 0.00005883
Iteration 47/1000 | Loss: 0.00005876
Iteration 48/1000 | Loss: 0.00005876
Iteration 49/1000 | Loss: 0.00005874
Iteration 50/1000 | Loss: 0.00005874
Iteration 51/1000 | Loss: 0.00005873
Iteration 52/1000 | Loss: 0.00005873
Iteration 53/1000 | Loss: 0.00005871
Iteration 54/1000 | Loss: 0.00005868
Iteration 55/1000 | Loss: 0.00005865
Iteration 56/1000 | Loss: 0.00005864
Iteration 57/1000 | Loss: 0.00005863
Iteration 58/1000 | Loss: 0.00005859
Iteration 59/1000 | Loss: 0.00005858
Iteration 60/1000 | Loss: 0.00005858
Iteration 61/1000 | Loss: 0.00005858
Iteration 62/1000 | Loss: 0.00005858
Iteration 63/1000 | Loss: 0.00005858
Iteration 64/1000 | Loss: 0.00005858
Iteration 65/1000 | Loss: 0.00005858
Iteration 66/1000 | Loss: 0.00005858
Iteration 67/1000 | Loss: 0.00005858
Iteration 68/1000 | Loss: 0.00005857
Iteration 69/1000 | Loss: 0.00005856
Iteration 70/1000 | Loss: 0.00005856
Iteration 71/1000 | Loss: 0.00005856
Iteration 72/1000 | Loss: 0.00005856
Iteration 73/1000 | Loss: 0.00005855
Iteration 74/1000 | Loss: 0.00005855
Iteration 75/1000 | Loss: 0.00005855
Iteration 76/1000 | Loss: 0.00005854
Iteration 77/1000 | Loss: 0.00005853
Iteration 78/1000 | Loss: 0.00005852
Iteration 79/1000 | Loss: 0.00005852
Iteration 80/1000 | Loss: 0.00005851
Iteration 81/1000 | Loss: 0.00005851
Iteration 82/1000 | Loss: 0.00005851
Iteration 83/1000 | Loss: 0.00005850
Iteration 84/1000 | Loss: 0.00005850
Iteration 85/1000 | Loss: 0.00005850
Iteration 86/1000 | Loss: 0.00005850
Iteration 87/1000 | Loss: 0.00005850
Iteration 88/1000 | Loss: 0.00005850
Iteration 89/1000 | Loss: 0.00005849
Iteration 90/1000 | Loss: 0.00005849
Iteration 91/1000 | Loss: 0.00005849
Iteration 92/1000 | Loss: 0.00005848
Iteration 93/1000 | Loss: 0.00005848
Iteration 94/1000 | Loss: 0.00005848
Iteration 95/1000 | Loss: 0.00005848
Iteration 96/1000 | Loss: 0.00005848
Iteration 97/1000 | Loss: 0.00005848
Iteration 98/1000 | Loss: 0.00005847
Iteration 99/1000 | Loss: 0.00005847
Iteration 100/1000 | Loss: 0.00005847
Iteration 101/1000 | Loss: 0.00005846
Iteration 102/1000 | Loss: 0.00005846
Iteration 103/1000 | Loss: 0.00005846
Iteration 104/1000 | Loss: 0.00005845
Iteration 105/1000 | Loss: 0.00005845
Iteration 106/1000 | Loss: 0.00005845
Iteration 107/1000 | Loss: 0.00005845
Iteration 108/1000 | Loss: 0.00005845
Iteration 109/1000 | Loss: 0.00005845
Iteration 110/1000 | Loss: 0.00005845
Iteration 111/1000 | Loss: 0.00005845
Iteration 112/1000 | Loss: 0.00005845
Iteration 113/1000 | Loss: 0.00005845
Iteration 114/1000 | Loss: 0.00005845
Iteration 115/1000 | Loss: 0.00005845
Iteration 116/1000 | Loss: 0.00005845
Iteration 117/1000 | Loss: 0.00005845
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [5.844837141921744e-05, 5.844837141921744e-05, 5.844837141921744e-05, 5.844837141921744e-05, 5.844837141921744e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.844837141921744e-05

Optimization complete. Final v2v error: 5.982056140899658 mm

Highest mean error: 15.774972915649414 mm for frame 129

Lowest mean error: 5.1727614402771 mm for frame 101

Saving results

Total time: 99.63554954528809
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00466565
Iteration 2/25 | Loss: 0.00175374
Iteration 3/25 | Loss: 0.00164276
Iteration 4/25 | Loss: 0.00162465
Iteration 5/25 | Loss: 0.00161486
Iteration 6/25 | Loss: 0.00161216
Iteration 7/25 | Loss: 0.00161151
Iteration 8/25 | Loss: 0.00161151
Iteration 9/25 | Loss: 0.00161151
Iteration 10/25 | Loss: 0.00161151
Iteration 11/25 | Loss: 0.00161151
Iteration 12/25 | Loss: 0.00161151
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0016115145990625024, 0.0016115145990625024, 0.0016115145990625024, 0.0016115145990625024, 0.0016115145990625024]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016115145990625024

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.92231035
Iteration 2/25 | Loss: 0.00143365
Iteration 3/25 | Loss: 0.00143364
Iteration 4/25 | Loss: 0.00143364
Iteration 5/25 | Loss: 0.00143364
Iteration 6/25 | Loss: 0.00143364
Iteration 7/25 | Loss: 0.00143364
Iteration 8/25 | Loss: 0.00143364
Iteration 9/25 | Loss: 0.00143364
Iteration 10/25 | Loss: 0.00143364
Iteration 11/25 | Loss: 0.00143364
Iteration 12/25 | Loss: 0.00143364
Iteration 13/25 | Loss: 0.00143364
Iteration 14/25 | Loss: 0.00143364
Iteration 15/25 | Loss: 0.00143364
Iteration 16/25 | Loss: 0.00143364
Iteration 17/25 | Loss: 0.00143364
Iteration 18/25 | Loss: 0.00143364
Iteration 19/25 | Loss: 0.00143364
Iteration 20/25 | Loss: 0.00143364
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0014336406020447612, 0.0014336406020447612, 0.0014336406020447612, 0.0014336406020447612, 0.0014336406020447612]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014336406020447612

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00143364
Iteration 2/1000 | Loss: 0.00008869
Iteration 3/1000 | Loss: 0.00006514
Iteration 4/1000 | Loss: 0.00005518
Iteration 5/1000 | Loss: 0.00005139
Iteration 6/1000 | Loss: 0.00004924
Iteration 7/1000 | Loss: 0.00004807
Iteration 8/1000 | Loss: 0.00004750
Iteration 9/1000 | Loss: 0.00004693
Iteration 10/1000 | Loss: 0.00004653
Iteration 11/1000 | Loss: 0.00004630
Iteration 12/1000 | Loss: 0.00004610
Iteration 13/1000 | Loss: 0.00004599
Iteration 14/1000 | Loss: 0.00004598
Iteration 15/1000 | Loss: 0.00004596
Iteration 16/1000 | Loss: 0.00004596
Iteration 17/1000 | Loss: 0.00004596
Iteration 18/1000 | Loss: 0.00004596
Iteration 19/1000 | Loss: 0.00004596
Iteration 20/1000 | Loss: 0.00004596
Iteration 21/1000 | Loss: 0.00004596
Iteration 22/1000 | Loss: 0.00004592
Iteration 23/1000 | Loss: 0.00004592
Iteration 24/1000 | Loss: 0.00004592
Iteration 25/1000 | Loss: 0.00004592
Iteration 26/1000 | Loss: 0.00004592
Iteration 27/1000 | Loss: 0.00004592
Iteration 28/1000 | Loss: 0.00004592
Iteration 29/1000 | Loss: 0.00004589
Iteration 30/1000 | Loss: 0.00004589
Iteration 31/1000 | Loss: 0.00004589
Iteration 32/1000 | Loss: 0.00004588
Iteration 33/1000 | Loss: 0.00004587
Iteration 34/1000 | Loss: 0.00004587
Iteration 35/1000 | Loss: 0.00004587
Iteration 36/1000 | Loss: 0.00004585
Iteration 37/1000 | Loss: 0.00004585
Iteration 38/1000 | Loss: 0.00004584
Iteration 39/1000 | Loss: 0.00004584
Iteration 40/1000 | Loss: 0.00004583
Iteration 41/1000 | Loss: 0.00004583
Iteration 42/1000 | Loss: 0.00004581
Iteration 43/1000 | Loss: 0.00004580
Iteration 44/1000 | Loss: 0.00004580
Iteration 45/1000 | Loss: 0.00004579
Iteration 46/1000 | Loss: 0.00004579
Iteration 47/1000 | Loss: 0.00004577
Iteration 48/1000 | Loss: 0.00004577
Iteration 49/1000 | Loss: 0.00004576
Iteration 50/1000 | Loss: 0.00004576
Iteration 51/1000 | Loss: 0.00004575
Iteration 52/1000 | Loss: 0.00004575
Iteration 53/1000 | Loss: 0.00004574
Iteration 54/1000 | Loss: 0.00004574
Iteration 55/1000 | Loss: 0.00004574
Iteration 56/1000 | Loss: 0.00004574
Iteration 57/1000 | Loss: 0.00004574
Iteration 58/1000 | Loss: 0.00004573
Iteration 59/1000 | Loss: 0.00004573
Iteration 60/1000 | Loss: 0.00004573
Iteration 61/1000 | Loss: 0.00004573
Iteration 62/1000 | Loss: 0.00004573
Iteration 63/1000 | Loss: 0.00004573
Iteration 64/1000 | Loss: 0.00004573
Iteration 65/1000 | Loss: 0.00004572
Iteration 66/1000 | Loss: 0.00004572
Iteration 67/1000 | Loss: 0.00004572
Iteration 68/1000 | Loss: 0.00004571
Iteration 69/1000 | Loss: 0.00004571
Iteration 70/1000 | Loss: 0.00004571
Iteration 71/1000 | Loss: 0.00004570
Iteration 72/1000 | Loss: 0.00004570
Iteration 73/1000 | Loss: 0.00004570
Iteration 74/1000 | Loss: 0.00004570
Iteration 75/1000 | Loss: 0.00004570
Iteration 76/1000 | Loss: 0.00004570
Iteration 77/1000 | Loss: 0.00004570
Iteration 78/1000 | Loss: 0.00004570
Iteration 79/1000 | Loss: 0.00004569
Iteration 80/1000 | Loss: 0.00004569
Iteration 81/1000 | Loss: 0.00004569
Iteration 82/1000 | Loss: 0.00004569
Iteration 83/1000 | Loss: 0.00004568
Iteration 84/1000 | Loss: 0.00004568
Iteration 85/1000 | Loss: 0.00004568
Iteration 86/1000 | Loss: 0.00004568
Iteration 87/1000 | Loss: 0.00004568
Iteration 88/1000 | Loss: 0.00004568
Iteration 89/1000 | Loss: 0.00004568
Iteration 90/1000 | Loss: 0.00004568
Iteration 91/1000 | Loss: 0.00004568
Iteration 92/1000 | Loss: 0.00004568
Iteration 93/1000 | Loss: 0.00004568
Iteration 94/1000 | Loss: 0.00004568
Iteration 95/1000 | Loss: 0.00004568
Iteration 96/1000 | Loss: 0.00004568
Iteration 97/1000 | Loss: 0.00004568
Iteration 98/1000 | Loss: 0.00004568
Iteration 99/1000 | Loss: 0.00004568
Iteration 100/1000 | Loss: 0.00004568
Iteration 101/1000 | Loss: 0.00004568
Iteration 102/1000 | Loss: 0.00004568
Iteration 103/1000 | Loss: 0.00004568
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [4.567873838823289e-05, 4.567873838823289e-05, 4.567873838823289e-05, 4.567873838823289e-05, 4.567873838823289e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.567873838823289e-05

Optimization complete. Final v2v error: 5.791366100311279 mm

Highest mean error: 6.2712578773498535 mm for frame 118

Lowest mean error: 5.1301188468933105 mm for frame 10

Saving results

Total time: 35.909414768218994
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00862959
Iteration 2/25 | Loss: 0.00209075
Iteration 3/25 | Loss: 0.00170939
Iteration 4/25 | Loss: 0.00167312
Iteration 5/25 | Loss: 0.00166185
Iteration 6/25 | Loss: 0.00165888
Iteration 7/25 | Loss: 0.00165857
Iteration 8/25 | Loss: 0.00165857
Iteration 9/25 | Loss: 0.00165857
Iteration 10/25 | Loss: 0.00165857
Iteration 11/25 | Loss: 0.00165857
Iteration 12/25 | Loss: 0.00165857
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0016585710691288114, 0.0016585710691288114, 0.0016585710691288114, 0.0016585710691288114, 0.0016585710691288114]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016585710691288114

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.24984919
Iteration 2/25 | Loss: 0.00107025
Iteration 3/25 | Loss: 0.00107025
Iteration 4/25 | Loss: 0.00107025
Iteration 5/25 | Loss: 0.00107025
Iteration 6/25 | Loss: 0.00107025
Iteration 7/25 | Loss: 0.00107025
Iteration 8/25 | Loss: 0.00107025
Iteration 9/25 | Loss: 0.00107025
Iteration 10/25 | Loss: 0.00107025
Iteration 11/25 | Loss: 0.00107025
Iteration 12/25 | Loss: 0.00107025
Iteration 13/25 | Loss: 0.00107025
Iteration 14/25 | Loss: 0.00107025
Iteration 15/25 | Loss: 0.00107025
Iteration 16/25 | Loss: 0.00107025
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001070246915332973, 0.001070246915332973, 0.001070246915332973, 0.001070246915332973, 0.001070246915332973]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001070246915332973

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00107025
Iteration 2/1000 | Loss: 0.00010613
Iteration 3/1000 | Loss: 0.00008512
Iteration 4/1000 | Loss: 0.00007551
Iteration 5/1000 | Loss: 0.00006831
Iteration 6/1000 | Loss: 0.00006522
Iteration 7/1000 | Loss: 0.00006307
Iteration 8/1000 | Loss: 0.00006225
Iteration 9/1000 | Loss: 0.00006140
Iteration 10/1000 | Loss: 0.00006076
Iteration 11/1000 | Loss: 0.00006011
Iteration 12/1000 | Loss: 0.00005970
Iteration 13/1000 | Loss: 0.00005943
Iteration 14/1000 | Loss: 0.00005924
Iteration 15/1000 | Loss: 0.00005904
Iteration 16/1000 | Loss: 0.00005887
Iteration 17/1000 | Loss: 0.00005868
Iteration 18/1000 | Loss: 0.00005846
Iteration 19/1000 | Loss: 0.00005833
Iteration 20/1000 | Loss: 0.00005820
Iteration 21/1000 | Loss: 0.00005820
Iteration 22/1000 | Loss: 0.00005806
Iteration 23/1000 | Loss: 0.00005797
Iteration 24/1000 | Loss: 0.00005792
Iteration 25/1000 | Loss: 0.00005791
Iteration 26/1000 | Loss: 0.00005789
Iteration 27/1000 | Loss: 0.00005786
Iteration 28/1000 | Loss: 0.00005786
Iteration 29/1000 | Loss: 0.00005784
Iteration 30/1000 | Loss: 0.00005784
Iteration 31/1000 | Loss: 0.00005781
Iteration 32/1000 | Loss: 0.00005780
Iteration 33/1000 | Loss: 0.00005780
Iteration 34/1000 | Loss: 0.00005780
Iteration 35/1000 | Loss: 0.00005777
Iteration 36/1000 | Loss: 0.00005777
Iteration 37/1000 | Loss: 0.00005777
Iteration 38/1000 | Loss: 0.00005776
Iteration 39/1000 | Loss: 0.00005775
Iteration 40/1000 | Loss: 0.00005775
Iteration 41/1000 | Loss: 0.00005775
Iteration 42/1000 | Loss: 0.00005775
Iteration 43/1000 | Loss: 0.00005775
Iteration 44/1000 | Loss: 0.00005775
Iteration 45/1000 | Loss: 0.00005775
Iteration 46/1000 | Loss: 0.00005775
Iteration 47/1000 | Loss: 0.00005775
Iteration 48/1000 | Loss: 0.00005775
Iteration 49/1000 | Loss: 0.00005775
Iteration 50/1000 | Loss: 0.00005775
Iteration 51/1000 | Loss: 0.00005774
Iteration 52/1000 | Loss: 0.00005774
Iteration 53/1000 | Loss: 0.00005774
Iteration 54/1000 | Loss: 0.00005774
Iteration 55/1000 | Loss: 0.00005774
Iteration 56/1000 | Loss: 0.00005774
Iteration 57/1000 | Loss: 0.00005774
Iteration 58/1000 | Loss: 0.00005773
Iteration 59/1000 | Loss: 0.00005773
Iteration 60/1000 | Loss: 0.00005773
Iteration 61/1000 | Loss: 0.00005772
Iteration 62/1000 | Loss: 0.00005772
Iteration 63/1000 | Loss: 0.00005772
Iteration 64/1000 | Loss: 0.00005772
Iteration 65/1000 | Loss: 0.00005772
Iteration 66/1000 | Loss: 0.00005772
Iteration 67/1000 | Loss: 0.00005772
Iteration 68/1000 | Loss: 0.00005772
Iteration 69/1000 | Loss: 0.00005772
Iteration 70/1000 | Loss: 0.00005771
Iteration 71/1000 | Loss: 0.00005771
Iteration 72/1000 | Loss: 0.00005771
Iteration 73/1000 | Loss: 0.00005771
Iteration 74/1000 | Loss: 0.00005771
Iteration 75/1000 | Loss: 0.00005771
Iteration 76/1000 | Loss: 0.00005771
Iteration 77/1000 | Loss: 0.00005770
Iteration 78/1000 | Loss: 0.00005770
Iteration 79/1000 | Loss: 0.00005770
Iteration 80/1000 | Loss: 0.00005770
Iteration 81/1000 | Loss: 0.00005769
Iteration 82/1000 | Loss: 0.00005769
Iteration 83/1000 | Loss: 0.00005769
Iteration 84/1000 | Loss: 0.00005769
Iteration 85/1000 | Loss: 0.00005769
Iteration 86/1000 | Loss: 0.00005768
Iteration 87/1000 | Loss: 0.00005768
Iteration 88/1000 | Loss: 0.00005768
Iteration 89/1000 | Loss: 0.00005768
Iteration 90/1000 | Loss: 0.00005767
Iteration 91/1000 | Loss: 0.00005767
Iteration 92/1000 | Loss: 0.00005767
Iteration 93/1000 | Loss: 0.00005767
Iteration 94/1000 | Loss: 0.00005766
Iteration 95/1000 | Loss: 0.00005766
Iteration 96/1000 | Loss: 0.00005766
Iteration 97/1000 | Loss: 0.00005766
Iteration 98/1000 | Loss: 0.00005766
Iteration 99/1000 | Loss: 0.00005765
Iteration 100/1000 | Loss: 0.00005765
Iteration 101/1000 | Loss: 0.00005765
Iteration 102/1000 | Loss: 0.00005765
Iteration 103/1000 | Loss: 0.00005765
Iteration 104/1000 | Loss: 0.00005765
Iteration 105/1000 | Loss: 0.00005765
Iteration 106/1000 | Loss: 0.00005765
Iteration 107/1000 | Loss: 0.00005765
Iteration 108/1000 | Loss: 0.00005765
Iteration 109/1000 | Loss: 0.00005765
Iteration 110/1000 | Loss: 0.00005765
Iteration 111/1000 | Loss: 0.00005765
Iteration 112/1000 | Loss: 0.00005765
Iteration 113/1000 | Loss: 0.00005765
Iteration 114/1000 | Loss: 0.00005765
Iteration 115/1000 | Loss: 0.00005765
Iteration 116/1000 | Loss: 0.00005765
Iteration 117/1000 | Loss: 0.00005765
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [5.76509592065122e-05, 5.76509592065122e-05, 5.76509592065122e-05, 5.76509592065122e-05, 5.76509592065122e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.76509592065122e-05

Optimization complete. Final v2v error: 6.222761154174805 mm

Highest mean error: 8.810723304748535 mm for frame 152

Lowest mean error: 4.7693095207214355 mm for frame 20

Saving results

Total time: 49.02256751060486
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01017455
Iteration 2/25 | Loss: 0.00235854
Iteration 3/25 | Loss: 0.00203059
Iteration 4/25 | Loss: 0.00187935
Iteration 5/25 | Loss: 0.00182654
Iteration 6/25 | Loss: 0.00176977
Iteration 7/25 | Loss: 0.00174011
Iteration 8/25 | Loss: 0.00172977
Iteration 9/25 | Loss: 0.00172489
Iteration 10/25 | Loss: 0.00173084
Iteration 11/25 | Loss: 0.00173268
Iteration 12/25 | Loss: 0.00171867
Iteration 13/25 | Loss: 0.00171734
Iteration 14/25 | Loss: 0.00171492
Iteration 15/25 | Loss: 0.00171556
Iteration 16/25 | Loss: 0.00171531
Iteration 17/25 | Loss: 0.00170976
Iteration 18/25 | Loss: 0.00170366
Iteration 19/25 | Loss: 0.00170383
Iteration 20/25 | Loss: 0.00170059
Iteration 21/25 | Loss: 0.00170102
Iteration 22/25 | Loss: 0.00169852
Iteration 23/25 | Loss: 0.00169730
Iteration 24/25 | Loss: 0.00170038
Iteration 25/25 | Loss: 0.00170825

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46078646
Iteration 2/25 | Loss: 0.00202216
Iteration 3/25 | Loss: 0.00202215
Iteration 4/25 | Loss: 0.00202215
Iteration 5/25 | Loss: 0.00202215
Iteration 6/25 | Loss: 0.00202215
Iteration 7/25 | Loss: 0.00202215
Iteration 8/25 | Loss: 0.00202215
Iteration 9/25 | Loss: 0.00202215
Iteration 10/25 | Loss: 0.00202215
Iteration 11/25 | Loss: 0.00202215
Iteration 12/25 | Loss: 0.00202215
Iteration 13/25 | Loss: 0.00202215
Iteration 14/25 | Loss: 0.00202215
Iteration 15/25 | Loss: 0.00202215
Iteration 16/25 | Loss: 0.00202215
Iteration 17/25 | Loss: 0.00202215
Iteration 18/25 | Loss: 0.00202215
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0020221455488353968, 0.0020221455488353968, 0.0020221455488353968, 0.0020221455488353968, 0.0020221455488353968]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020221455488353968

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00202215
Iteration 2/1000 | Loss: 0.00018993
Iteration 3/1000 | Loss: 0.00013542
Iteration 4/1000 | Loss: 0.00009854
Iteration 5/1000 | Loss: 0.00058945
Iteration 6/1000 | Loss: 0.00062424
Iteration 7/1000 | Loss: 0.00078088
Iteration 8/1000 | Loss: 0.00174346
Iteration 9/1000 | Loss: 0.00020524
Iteration 10/1000 | Loss: 0.00021022
Iteration 11/1000 | Loss: 0.00009818
Iteration 12/1000 | Loss: 0.00018578
Iteration 13/1000 | Loss: 0.00022866
Iteration 14/1000 | Loss: 0.00025417
Iteration 15/1000 | Loss: 0.00037941
Iteration 16/1000 | Loss: 0.00009225
Iteration 17/1000 | Loss: 0.00023582
Iteration 18/1000 | Loss: 0.00008117
Iteration 19/1000 | Loss: 0.00013050
Iteration 20/1000 | Loss: 0.00025379
Iteration 21/1000 | Loss: 0.00007877
Iteration 22/1000 | Loss: 0.00007129
Iteration 23/1000 | Loss: 0.00006855
Iteration 24/1000 | Loss: 0.00006713
Iteration 25/1000 | Loss: 0.00006632
Iteration 26/1000 | Loss: 0.00035081
Iteration 27/1000 | Loss: 0.00007118
Iteration 28/1000 | Loss: 0.00006524
Iteration 29/1000 | Loss: 0.00006303
Iteration 30/1000 | Loss: 0.00006223
Iteration 31/1000 | Loss: 0.00006158
Iteration 32/1000 | Loss: 0.00006114
Iteration 33/1000 | Loss: 0.00006082
Iteration 34/1000 | Loss: 0.00006054
Iteration 35/1000 | Loss: 0.00006028
Iteration 36/1000 | Loss: 0.00005994
Iteration 37/1000 | Loss: 0.00005978
Iteration 38/1000 | Loss: 0.00005964
Iteration 39/1000 | Loss: 0.00005959
Iteration 40/1000 | Loss: 0.00005957
Iteration 41/1000 | Loss: 0.00005939
Iteration 42/1000 | Loss: 0.00005936
Iteration 43/1000 | Loss: 0.00005936
Iteration 44/1000 | Loss: 0.00005935
Iteration 45/1000 | Loss: 0.00005934
Iteration 46/1000 | Loss: 0.00005933
Iteration 47/1000 | Loss: 0.00005932
Iteration 48/1000 | Loss: 0.00005931
Iteration 49/1000 | Loss: 0.00005930
Iteration 50/1000 | Loss: 0.00005930
Iteration 51/1000 | Loss: 0.00005929
Iteration 52/1000 | Loss: 0.00005928
Iteration 53/1000 | Loss: 0.00005928
Iteration 54/1000 | Loss: 0.00005924
Iteration 55/1000 | Loss: 0.00005922
Iteration 56/1000 | Loss: 0.00005922
Iteration 57/1000 | Loss: 0.00005921
Iteration 58/1000 | Loss: 0.00005919
Iteration 59/1000 | Loss: 0.00005919
Iteration 60/1000 | Loss: 0.00005915
Iteration 61/1000 | Loss: 0.00005913
Iteration 62/1000 | Loss: 0.00005910
Iteration 63/1000 | Loss: 0.00005910
Iteration 64/1000 | Loss: 0.00005909
Iteration 65/1000 | Loss: 0.00005908
Iteration 66/1000 | Loss: 0.00005908
Iteration 67/1000 | Loss: 0.00005908
Iteration 68/1000 | Loss: 0.00005908
Iteration 69/1000 | Loss: 0.00005907
Iteration 70/1000 | Loss: 0.00005907
Iteration 71/1000 | Loss: 0.00005907
Iteration 72/1000 | Loss: 0.00005906
Iteration 73/1000 | Loss: 0.00005906
Iteration 74/1000 | Loss: 0.00005906
Iteration 75/1000 | Loss: 0.00005905
Iteration 76/1000 | Loss: 0.00005905
Iteration 77/1000 | Loss: 0.00005905
Iteration 78/1000 | Loss: 0.00005905
Iteration 79/1000 | Loss: 0.00005905
Iteration 80/1000 | Loss: 0.00005904
Iteration 81/1000 | Loss: 0.00005904
Iteration 82/1000 | Loss: 0.00005904
Iteration 83/1000 | Loss: 0.00005904
Iteration 84/1000 | Loss: 0.00005904
Iteration 85/1000 | Loss: 0.00005904
Iteration 86/1000 | Loss: 0.00005904
Iteration 87/1000 | Loss: 0.00005903
Iteration 88/1000 | Loss: 0.00005903
Iteration 89/1000 | Loss: 0.00005903
Iteration 90/1000 | Loss: 0.00005903
Iteration 91/1000 | Loss: 0.00005903
Iteration 92/1000 | Loss: 0.00005903
Iteration 93/1000 | Loss: 0.00005903
Iteration 94/1000 | Loss: 0.00005902
Iteration 95/1000 | Loss: 0.00005902
Iteration 96/1000 | Loss: 0.00005902
Iteration 97/1000 | Loss: 0.00005902
Iteration 98/1000 | Loss: 0.00005902
Iteration 99/1000 | Loss: 0.00005901
Iteration 100/1000 | Loss: 0.00005901
Iteration 101/1000 | Loss: 0.00005901
Iteration 102/1000 | Loss: 0.00005901
Iteration 103/1000 | Loss: 0.00005901
Iteration 104/1000 | Loss: 0.00005901
Iteration 105/1000 | Loss: 0.00005900
Iteration 106/1000 | Loss: 0.00005900
Iteration 107/1000 | Loss: 0.00005900
Iteration 108/1000 | Loss: 0.00005900
Iteration 109/1000 | Loss: 0.00005900
Iteration 110/1000 | Loss: 0.00005900
Iteration 111/1000 | Loss: 0.00005900
Iteration 112/1000 | Loss: 0.00005900
Iteration 113/1000 | Loss: 0.00005900
Iteration 114/1000 | Loss: 0.00005900
Iteration 115/1000 | Loss: 0.00005900
Iteration 116/1000 | Loss: 0.00005900
Iteration 117/1000 | Loss: 0.00005900
Iteration 118/1000 | Loss: 0.00005900
Iteration 119/1000 | Loss: 0.00005900
Iteration 120/1000 | Loss: 0.00005900
Iteration 121/1000 | Loss: 0.00005900
Iteration 122/1000 | Loss: 0.00005900
Iteration 123/1000 | Loss: 0.00005899
Iteration 124/1000 | Loss: 0.00005899
Iteration 125/1000 | Loss: 0.00005899
Iteration 126/1000 | Loss: 0.00005899
Iteration 127/1000 | Loss: 0.00005899
Iteration 128/1000 | Loss: 0.00005899
Iteration 129/1000 | Loss: 0.00005899
Iteration 130/1000 | Loss: 0.00005899
Iteration 131/1000 | Loss: 0.00005899
Iteration 132/1000 | Loss: 0.00005899
Iteration 133/1000 | Loss: 0.00005899
Iteration 134/1000 | Loss: 0.00005899
Iteration 135/1000 | Loss: 0.00005899
Iteration 136/1000 | Loss: 0.00005899
Iteration 137/1000 | Loss: 0.00005899
Iteration 138/1000 | Loss: 0.00005899
Iteration 139/1000 | Loss: 0.00005899
Iteration 140/1000 | Loss: 0.00005899
Iteration 141/1000 | Loss: 0.00005899
Iteration 142/1000 | Loss: 0.00005899
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [5.8994741266360506e-05, 5.8994741266360506e-05, 5.8994741266360506e-05, 5.8994741266360506e-05, 5.8994741266360506e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.8994741266360506e-05

Optimization complete. Final v2v error: 5.406063079833984 mm

Highest mean error: 13.751002311706543 mm for frame 70

Lowest mean error: 4.473117828369141 mm for frame 133

Saving results

Total time: 108.41273140907288
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00437450
Iteration 2/25 | Loss: 0.00162596
Iteration 3/25 | Loss: 0.00154603
Iteration 4/25 | Loss: 0.00153734
Iteration 5/25 | Loss: 0.00153362
Iteration 6/25 | Loss: 0.00153221
Iteration 7/25 | Loss: 0.00153221
Iteration 8/25 | Loss: 0.00153221
Iteration 9/25 | Loss: 0.00153221
Iteration 10/25 | Loss: 0.00153221
Iteration 11/25 | Loss: 0.00153221
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001532212016172707, 0.001532212016172707, 0.001532212016172707, 0.001532212016172707, 0.001532212016172707]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001532212016172707

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60295415
Iteration 2/25 | Loss: 0.00144641
Iteration 3/25 | Loss: 0.00144641
Iteration 4/25 | Loss: 0.00144641
Iteration 5/25 | Loss: 0.00144641
Iteration 6/25 | Loss: 0.00144641
Iteration 7/25 | Loss: 0.00144641
Iteration 8/25 | Loss: 0.00144641
Iteration 9/25 | Loss: 0.00144641
Iteration 10/25 | Loss: 0.00144641
Iteration 11/25 | Loss: 0.00144641
Iteration 12/25 | Loss: 0.00144641
Iteration 13/25 | Loss: 0.00144641
Iteration 14/25 | Loss: 0.00144641
Iteration 15/25 | Loss: 0.00144641
Iteration 16/25 | Loss: 0.00144641
Iteration 17/25 | Loss: 0.00144641
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001446408685296774, 0.001446408685296774, 0.001446408685296774, 0.001446408685296774, 0.001446408685296774]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001446408685296774

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00144641
Iteration 2/1000 | Loss: 0.00006991
Iteration 3/1000 | Loss: 0.00005058
Iteration 4/1000 | Loss: 0.00004057
Iteration 5/1000 | Loss: 0.00003395
Iteration 6/1000 | Loss: 0.00003136
Iteration 7/1000 | Loss: 0.00003007
Iteration 8/1000 | Loss: 0.00002941
Iteration 9/1000 | Loss: 0.00002914
Iteration 10/1000 | Loss: 0.00002885
Iteration 11/1000 | Loss: 0.00002853
Iteration 12/1000 | Loss: 0.00002834
Iteration 13/1000 | Loss: 0.00002833
Iteration 14/1000 | Loss: 0.00002816
Iteration 15/1000 | Loss: 0.00002811
Iteration 16/1000 | Loss: 0.00002808
Iteration 17/1000 | Loss: 0.00002808
Iteration 18/1000 | Loss: 0.00002807
Iteration 19/1000 | Loss: 0.00002804
Iteration 20/1000 | Loss: 0.00002804
Iteration 21/1000 | Loss: 0.00002803
Iteration 22/1000 | Loss: 0.00002801
Iteration 23/1000 | Loss: 0.00002801
Iteration 24/1000 | Loss: 0.00002799
Iteration 25/1000 | Loss: 0.00002798
Iteration 26/1000 | Loss: 0.00002798
Iteration 27/1000 | Loss: 0.00002797
Iteration 28/1000 | Loss: 0.00002796
Iteration 29/1000 | Loss: 0.00002795
Iteration 30/1000 | Loss: 0.00002794
Iteration 31/1000 | Loss: 0.00002794
Iteration 32/1000 | Loss: 0.00002793
Iteration 33/1000 | Loss: 0.00002792
Iteration 34/1000 | Loss: 0.00002792
Iteration 35/1000 | Loss: 0.00002792
Iteration 36/1000 | Loss: 0.00002791
Iteration 37/1000 | Loss: 0.00002791
Iteration 38/1000 | Loss: 0.00002791
Iteration 39/1000 | Loss: 0.00002790
Iteration 40/1000 | Loss: 0.00002789
Iteration 41/1000 | Loss: 0.00002783
Iteration 42/1000 | Loss: 0.00002781
Iteration 43/1000 | Loss: 0.00002780
Iteration 44/1000 | Loss: 0.00002780
Iteration 45/1000 | Loss: 0.00002780
Iteration 46/1000 | Loss: 0.00002779
Iteration 47/1000 | Loss: 0.00002779
Iteration 48/1000 | Loss: 0.00002778
Iteration 49/1000 | Loss: 0.00002778
Iteration 50/1000 | Loss: 0.00002777
Iteration 51/1000 | Loss: 0.00002777
Iteration 52/1000 | Loss: 0.00002777
Iteration 53/1000 | Loss: 0.00002776
Iteration 54/1000 | Loss: 0.00002776
Iteration 55/1000 | Loss: 0.00002776
Iteration 56/1000 | Loss: 0.00002776
Iteration 57/1000 | Loss: 0.00002776
Iteration 58/1000 | Loss: 0.00002775
Iteration 59/1000 | Loss: 0.00002775
Iteration 60/1000 | Loss: 0.00002775
Iteration 61/1000 | Loss: 0.00002775
Iteration 62/1000 | Loss: 0.00002774
Iteration 63/1000 | Loss: 0.00002774
Iteration 64/1000 | Loss: 0.00002774
Iteration 65/1000 | Loss: 0.00002774
Iteration 66/1000 | Loss: 0.00002773
Iteration 67/1000 | Loss: 0.00002773
Iteration 68/1000 | Loss: 0.00002773
Iteration 69/1000 | Loss: 0.00002773
Iteration 70/1000 | Loss: 0.00002773
Iteration 71/1000 | Loss: 0.00002773
Iteration 72/1000 | Loss: 0.00002773
Iteration 73/1000 | Loss: 0.00002773
Iteration 74/1000 | Loss: 0.00002772
Iteration 75/1000 | Loss: 0.00002772
Iteration 76/1000 | Loss: 0.00002772
Iteration 77/1000 | Loss: 0.00002772
Iteration 78/1000 | Loss: 0.00002772
Iteration 79/1000 | Loss: 0.00002772
Iteration 80/1000 | Loss: 0.00002772
Iteration 81/1000 | Loss: 0.00002772
Iteration 82/1000 | Loss: 0.00002772
Iteration 83/1000 | Loss: 0.00002772
Iteration 84/1000 | Loss: 0.00002772
Iteration 85/1000 | Loss: 0.00002771
Iteration 86/1000 | Loss: 0.00002771
Iteration 87/1000 | Loss: 0.00002771
Iteration 88/1000 | Loss: 0.00002771
Iteration 89/1000 | Loss: 0.00002771
Iteration 90/1000 | Loss: 0.00002771
Iteration 91/1000 | Loss: 0.00002771
Iteration 92/1000 | Loss: 0.00002771
Iteration 93/1000 | Loss: 0.00002771
Iteration 94/1000 | Loss: 0.00002771
Iteration 95/1000 | Loss: 0.00002771
Iteration 96/1000 | Loss: 0.00002771
Iteration 97/1000 | Loss: 0.00002771
Iteration 98/1000 | Loss: 0.00002771
Iteration 99/1000 | Loss: 0.00002771
Iteration 100/1000 | Loss: 0.00002771
Iteration 101/1000 | Loss: 0.00002771
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 101. Stopping optimization.
Last 5 losses: [2.7709045752999373e-05, 2.7709045752999373e-05, 2.7709045752999373e-05, 2.7709045752999373e-05, 2.7709045752999373e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7709045752999373e-05

Optimization complete. Final v2v error: 4.6055498123168945 mm

Highest mean error: 4.736984729766846 mm for frame 20

Lowest mean error: 4.502987384796143 mm for frame 48

Saving results

Total time: 35.35037136077881
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00617392
Iteration 2/25 | Loss: 0.00169807
Iteration 3/25 | Loss: 0.00161846
Iteration 4/25 | Loss: 0.00160686
Iteration 5/25 | Loss: 0.00160146
Iteration 6/25 | Loss: 0.00160065
Iteration 7/25 | Loss: 0.00160065
Iteration 8/25 | Loss: 0.00160065
Iteration 9/25 | Loss: 0.00160065
Iteration 10/25 | Loss: 0.00160065
Iteration 11/25 | Loss: 0.00160065
Iteration 12/25 | Loss: 0.00160065
Iteration 13/25 | Loss: 0.00160065
Iteration 14/25 | Loss: 0.00160065
Iteration 15/25 | Loss: 0.00160065
Iteration 16/25 | Loss: 0.00160065
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00160064862575382, 0.00160064862575382, 0.00160064862575382, 0.00160064862575382, 0.00160064862575382]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00160064862575382

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.74484491
Iteration 2/25 | Loss: 0.00154735
Iteration 3/25 | Loss: 0.00154735
Iteration 4/25 | Loss: 0.00154735
Iteration 5/25 | Loss: 0.00154735
Iteration 6/25 | Loss: 0.00154735
Iteration 7/25 | Loss: 0.00154735
Iteration 8/25 | Loss: 0.00154734
Iteration 9/25 | Loss: 0.00154734
Iteration 10/25 | Loss: 0.00154734
Iteration 11/25 | Loss: 0.00154734
Iteration 12/25 | Loss: 0.00154734
Iteration 13/25 | Loss: 0.00154734
Iteration 14/25 | Loss: 0.00154734
Iteration 15/25 | Loss: 0.00154734
Iteration 16/25 | Loss: 0.00154734
Iteration 17/25 | Loss: 0.00154734
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0015473439125344157, 0.0015473439125344157, 0.0015473439125344157, 0.0015473439125344157, 0.0015473439125344157]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015473439125344157

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00154734
Iteration 2/1000 | Loss: 0.00007095
Iteration 3/1000 | Loss: 0.00005334
Iteration 4/1000 | Loss: 0.00004178
Iteration 5/1000 | Loss: 0.00003831
Iteration 6/1000 | Loss: 0.00003654
Iteration 7/1000 | Loss: 0.00003548
Iteration 8/1000 | Loss: 0.00003505
Iteration 9/1000 | Loss: 0.00003460
Iteration 10/1000 | Loss: 0.00003438
Iteration 11/1000 | Loss: 0.00003425
Iteration 12/1000 | Loss: 0.00003419
Iteration 13/1000 | Loss: 0.00003404
Iteration 14/1000 | Loss: 0.00003397
Iteration 15/1000 | Loss: 0.00003395
Iteration 16/1000 | Loss: 0.00003394
Iteration 17/1000 | Loss: 0.00003394
Iteration 18/1000 | Loss: 0.00003393
Iteration 19/1000 | Loss: 0.00003390
Iteration 20/1000 | Loss: 0.00003390
Iteration 21/1000 | Loss: 0.00003390
Iteration 22/1000 | Loss: 0.00003390
Iteration 23/1000 | Loss: 0.00003390
Iteration 24/1000 | Loss: 0.00003390
Iteration 25/1000 | Loss: 0.00003390
Iteration 26/1000 | Loss: 0.00003390
Iteration 27/1000 | Loss: 0.00003390
Iteration 28/1000 | Loss: 0.00003390
Iteration 29/1000 | Loss: 0.00003390
Iteration 30/1000 | Loss: 0.00003389
Iteration 31/1000 | Loss: 0.00003389
Iteration 32/1000 | Loss: 0.00003388
Iteration 33/1000 | Loss: 0.00003388
Iteration 34/1000 | Loss: 0.00003387
Iteration 35/1000 | Loss: 0.00003386
Iteration 36/1000 | Loss: 0.00003386
Iteration 37/1000 | Loss: 0.00003384
Iteration 38/1000 | Loss: 0.00003381
Iteration 39/1000 | Loss: 0.00003376
Iteration 40/1000 | Loss: 0.00003369
Iteration 41/1000 | Loss: 0.00003369
Iteration 42/1000 | Loss: 0.00003369
Iteration 43/1000 | Loss: 0.00003369
Iteration 44/1000 | Loss: 0.00003369
Iteration 45/1000 | Loss: 0.00003365
Iteration 46/1000 | Loss: 0.00003364
Iteration 47/1000 | Loss: 0.00003363
Iteration 48/1000 | Loss: 0.00003363
Iteration 49/1000 | Loss: 0.00003363
Iteration 50/1000 | Loss: 0.00003362
Iteration 51/1000 | Loss: 0.00003362
Iteration 52/1000 | Loss: 0.00003360
Iteration 53/1000 | Loss: 0.00003360
Iteration 54/1000 | Loss: 0.00003360
Iteration 55/1000 | Loss: 0.00003360
Iteration 56/1000 | Loss: 0.00003360
Iteration 57/1000 | Loss: 0.00003360
Iteration 58/1000 | Loss: 0.00003360
Iteration 59/1000 | Loss: 0.00003360
Iteration 60/1000 | Loss: 0.00003360
Iteration 61/1000 | Loss: 0.00003360
Iteration 62/1000 | Loss: 0.00003360
Iteration 63/1000 | Loss: 0.00003360
Iteration 64/1000 | Loss: 0.00003360
Iteration 65/1000 | Loss: 0.00003359
Iteration 66/1000 | Loss: 0.00003359
Iteration 67/1000 | Loss: 0.00003359
Iteration 68/1000 | Loss: 0.00003359
Iteration 69/1000 | Loss: 0.00003359
Iteration 70/1000 | Loss: 0.00003359
Iteration 71/1000 | Loss: 0.00003359
Iteration 72/1000 | Loss: 0.00003359
Iteration 73/1000 | Loss: 0.00003358
Iteration 74/1000 | Loss: 0.00003358
Iteration 75/1000 | Loss: 0.00003358
Iteration 76/1000 | Loss: 0.00003358
Iteration 77/1000 | Loss: 0.00003358
Iteration 78/1000 | Loss: 0.00003357
Iteration 79/1000 | Loss: 0.00003357
Iteration 80/1000 | Loss: 0.00003357
Iteration 81/1000 | Loss: 0.00003357
Iteration 82/1000 | Loss: 0.00003357
Iteration 83/1000 | Loss: 0.00003357
Iteration 84/1000 | Loss: 0.00003356
Iteration 85/1000 | Loss: 0.00003356
Iteration 86/1000 | Loss: 0.00003356
Iteration 87/1000 | Loss: 0.00003356
Iteration 88/1000 | Loss: 0.00003356
Iteration 89/1000 | Loss: 0.00003356
Iteration 90/1000 | Loss: 0.00003356
Iteration 91/1000 | Loss: 0.00003356
Iteration 92/1000 | Loss: 0.00003356
Iteration 93/1000 | Loss: 0.00003356
Iteration 94/1000 | Loss: 0.00003356
Iteration 95/1000 | Loss: 0.00003356
Iteration 96/1000 | Loss: 0.00003356
Iteration 97/1000 | Loss: 0.00003356
Iteration 98/1000 | Loss: 0.00003356
Iteration 99/1000 | Loss: 0.00003355
Iteration 100/1000 | Loss: 0.00003355
Iteration 101/1000 | Loss: 0.00003355
Iteration 102/1000 | Loss: 0.00003355
Iteration 103/1000 | Loss: 0.00003355
Iteration 104/1000 | Loss: 0.00003355
Iteration 105/1000 | Loss: 0.00003355
Iteration 106/1000 | Loss: 0.00003355
Iteration 107/1000 | Loss: 0.00003355
Iteration 108/1000 | Loss: 0.00003355
Iteration 109/1000 | Loss: 0.00003355
Iteration 110/1000 | Loss: 0.00003355
Iteration 111/1000 | Loss: 0.00003355
Iteration 112/1000 | Loss: 0.00003355
Iteration 113/1000 | Loss: 0.00003355
Iteration 114/1000 | Loss: 0.00003355
Iteration 115/1000 | Loss: 0.00003355
Iteration 116/1000 | Loss: 0.00003355
Iteration 117/1000 | Loss: 0.00003355
Iteration 118/1000 | Loss: 0.00003355
Iteration 119/1000 | Loss: 0.00003355
Iteration 120/1000 | Loss: 0.00003355
Iteration 121/1000 | Loss: 0.00003355
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 121. Stopping optimization.
Last 5 losses: [3.35538134095259e-05, 3.35538134095259e-05, 3.35538134095259e-05, 3.35538134095259e-05, 3.35538134095259e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.35538134095259e-05

Optimization complete. Final v2v error: 5.072648048400879 mm

Highest mean error: 5.302858352661133 mm for frame 103

Lowest mean error: 4.835093975067139 mm for frame 118

Saving results

Total time: 35.12143087387085
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01302763
Iteration 2/25 | Loss: 0.00316066
Iteration 3/25 | Loss: 0.00192079
Iteration 4/25 | Loss: 0.00178521
Iteration 5/25 | Loss: 0.00179978
Iteration 6/25 | Loss: 0.00173436
Iteration 7/25 | Loss: 0.00170175
Iteration 8/25 | Loss: 0.00168702
Iteration 9/25 | Loss: 0.00168390
Iteration 10/25 | Loss: 0.00166119
Iteration 11/25 | Loss: 0.00165542
Iteration 12/25 | Loss: 0.00165380
Iteration 13/25 | Loss: 0.00165324
Iteration 14/25 | Loss: 0.00166375
Iteration 15/25 | Loss: 0.00164873
Iteration 16/25 | Loss: 0.00164563
Iteration 17/25 | Loss: 0.00164514
Iteration 18/25 | Loss: 0.00164507
Iteration 19/25 | Loss: 0.00164507
Iteration 20/25 | Loss: 0.00164506
Iteration 21/25 | Loss: 0.00164506
Iteration 22/25 | Loss: 0.00164506
Iteration 23/25 | Loss: 0.00164506
Iteration 24/25 | Loss: 0.00164505
Iteration 25/25 | Loss: 0.00164505

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.72673023
Iteration 2/25 | Loss: 0.00204504
Iteration 3/25 | Loss: 0.00204502
Iteration 4/25 | Loss: 0.00204502
Iteration 5/25 | Loss: 0.00204502
Iteration 6/25 | Loss: 0.00204502
Iteration 7/25 | Loss: 0.00204502
Iteration 8/25 | Loss: 0.00204502
Iteration 9/25 | Loss: 0.00204502
Iteration 10/25 | Loss: 0.00204502
Iteration 11/25 | Loss: 0.00204502
Iteration 12/25 | Loss: 0.00204502
Iteration 13/25 | Loss: 0.00204502
Iteration 14/25 | Loss: 0.00204502
Iteration 15/25 | Loss: 0.00204502
Iteration 16/25 | Loss: 0.00204502
Iteration 17/25 | Loss: 0.00204502
Iteration 18/25 | Loss: 0.00204502
Iteration 19/25 | Loss: 0.00204502
Iteration 20/25 | Loss: 0.00204502
Iteration 21/25 | Loss: 0.00204502
Iteration 22/25 | Loss: 0.00204502
Iteration 23/25 | Loss: 0.00204502
Iteration 24/25 | Loss: 0.00204502
Iteration 25/25 | Loss: 0.00204502

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00204502
Iteration 2/1000 | Loss: 0.00039693
Iteration 3/1000 | Loss: 0.00030751
Iteration 4/1000 | Loss: 0.00024087
Iteration 5/1000 | Loss: 0.00018123
Iteration 6/1000 | Loss: 0.00016306
Iteration 7/1000 | Loss: 0.00331023
Iteration 8/1000 | Loss: 0.00030616
Iteration 9/1000 | Loss: 0.00497739
Iteration 10/1000 | Loss: 0.00062073
Iteration 11/1000 | Loss: 0.00795183
Iteration 12/1000 | Loss: 0.00068521
Iteration 13/1000 | Loss: 0.00081772
Iteration 14/1000 | Loss: 0.00033020
Iteration 15/1000 | Loss: 0.00050247
Iteration 16/1000 | Loss: 0.00256290
Iteration 17/1000 | Loss: 0.00128492
Iteration 18/1000 | Loss: 0.00249903
Iteration 19/1000 | Loss: 0.00041242
Iteration 20/1000 | Loss: 0.00060892
Iteration 21/1000 | Loss: 0.00040044
Iteration 22/1000 | Loss: 0.00076313
Iteration 23/1000 | Loss: 0.00034058
Iteration 24/1000 | Loss: 0.00054705
Iteration 25/1000 | Loss: 0.00027458
Iteration 26/1000 | Loss: 0.00020448
Iteration 27/1000 | Loss: 0.00014782
Iteration 28/1000 | Loss: 0.00010172
Iteration 29/1000 | Loss: 0.00009189
Iteration 30/1000 | Loss: 0.00066629
Iteration 31/1000 | Loss: 0.00042221
Iteration 32/1000 | Loss: 0.00008371
Iteration 33/1000 | Loss: 0.00007892
Iteration 34/1000 | Loss: 0.00014327
Iteration 35/1000 | Loss: 0.00007309
Iteration 36/1000 | Loss: 0.00006982
Iteration 37/1000 | Loss: 0.00006830
Iteration 38/1000 | Loss: 0.00006714
Iteration 39/1000 | Loss: 0.00006641
Iteration 40/1000 | Loss: 0.00006604
Iteration 41/1000 | Loss: 0.00006574
Iteration 42/1000 | Loss: 0.00006552
Iteration 43/1000 | Loss: 0.00006534
Iteration 44/1000 | Loss: 0.00006524
Iteration 45/1000 | Loss: 0.00006514
Iteration 46/1000 | Loss: 0.00006511
Iteration 47/1000 | Loss: 0.00006511
Iteration 48/1000 | Loss: 0.00006505
Iteration 49/1000 | Loss: 0.00006505
Iteration 50/1000 | Loss: 0.00006502
Iteration 51/1000 | Loss: 0.00006501
Iteration 52/1000 | Loss: 0.00006501
Iteration 53/1000 | Loss: 0.00006501
Iteration 54/1000 | Loss: 0.00006500
Iteration 55/1000 | Loss: 0.00006500
Iteration 56/1000 | Loss: 0.00006496
Iteration 57/1000 | Loss: 0.00006492
Iteration 58/1000 | Loss: 0.00006492
Iteration 59/1000 | Loss: 0.00006492
Iteration 60/1000 | Loss: 0.00006492
Iteration 61/1000 | Loss: 0.00006492
Iteration 62/1000 | Loss: 0.00006491
Iteration 63/1000 | Loss: 0.00006491
Iteration 64/1000 | Loss: 0.00006491
Iteration 65/1000 | Loss: 0.00006491
Iteration 66/1000 | Loss: 0.00006491
Iteration 67/1000 | Loss: 0.00006491
Iteration 68/1000 | Loss: 0.00006490
Iteration 69/1000 | Loss: 0.00006490
Iteration 70/1000 | Loss: 0.00006488
Iteration 71/1000 | Loss: 0.00006488
Iteration 72/1000 | Loss: 0.00006488
Iteration 73/1000 | Loss: 0.00006488
Iteration 74/1000 | Loss: 0.00006488
Iteration 75/1000 | Loss: 0.00006488
Iteration 76/1000 | Loss: 0.00006488
Iteration 77/1000 | Loss: 0.00006487
Iteration 78/1000 | Loss: 0.00006487
Iteration 79/1000 | Loss: 0.00006487
Iteration 80/1000 | Loss: 0.00006487
Iteration 81/1000 | Loss: 0.00006487
Iteration 82/1000 | Loss: 0.00006487
Iteration 83/1000 | Loss: 0.00006486
Iteration 84/1000 | Loss: 0.00006486
Iteration 85/1000 | Loss: 0.00006485
Iteration 86/1000 | Loss: 0.00006485
Iteration 87/1000 | Loss: 0.00006485
Iteration 88/1000 | Loss: 0.00006485
Iteration 89/1000 | Loss: 0.00006485
Iteration 90/1000 | Loss: 0.00006483
Iteration 91/1000 | Loss: 0.00006483
Iteration 92/1000 | Loss: 0.00006483
Iteration 93/1000 | Loss: 0.00006483
Iteration 94/1000 | Loss: 0.00006483
Iteration 95/1000 | Loss: 0.00006482
Iteration 96/1000 | Loss: 0.00006482
Iteration 97/1000 | Loss: 0.00006482
Iteration 98/1000 | Loss: 0.00006482
Iteration 99/1000 | Loss: 0.00006482
Iteration 100/1000 | Loss: 0.00006482
Iteration 101/1000 | Loss: 0.00006482
Iteration 102/1000 | Loss: 0.00006482
Iteration 103/1000 | Loss: 0.00006482
Iteration 104/1000 | Loss: 0.00006481
Iteration 105/1000 | Loss: 0.00006481
Iteration 106/1000 | Loss: 0.00006481
Iteration 107/1000 | Loss: 0.00006481
Iteration 108/1000 | Loss: 0.00006481
Iteration 109/1000 | Loss: 0.00006480
Iteration 110/1000 | Loss: 0.00006480
Iteration 111/1000 | Loss: 0.00006480
Iteration 112/1000 | Loss: 0.00006479
Iteration 113/1000 | Loss: 0.00006479
Iteration 114/1000 | Loss: 0.00006479
Iteration 115/1000 | Loss: 0.00006479
Iteration 116/1000 | Loss: 0.00006479
Iteration 117/1000 | Loss: 0.00006479
Iteration 118/1000 | Loss: 0.00006479
Iteration 119/1000 | Loss: 0.00006479
Iteration 120/1000 | Loss: 0.00006478
Iteration 121/1000 | Loss: 0.00006478
Iteration 122/1000 | Loss: 0.00006478
Iteration 123/1000 | Loss: 0.00006478
Iteration 124/1000 | Loss: 0.00006477
Iteration 125/1000 | Loss: 0.00006477
Iteration 126/1000 | Loss: 0.00006477
Iteration 127/1000 | Loss: 0.00006477
Iteration 128/1000 | Loss: 0.00006477
Iteration 129/1000 | Loss: 0.00006477
Iteration 130/1000 | Loss: 0.00006477
Iteration 131/1000 | Loss: 0.00006477
Iteration 132/1000 | Loss: 0.00006477
Iteration 133/1000 | Loss: 0.00006477
Iteration 134/1000 | Loss: 0.00006476
Iteration 135/1000 | Loss: 0.00006476
Iteration 136/1000 | Loss: 0.00006476
Iteration 137/1000 | Loss: 0.00006476
Iteration 138/1000 | Loss: 0.00006476
Iteration 139/1000 | Loss: 0.00006476
Iteration 140/1000 | Loss: 0.00006476
Iteration 141/1000 | Loss: 0.00006476
Iteration 142/1000 | Loss: 0.00006476
Iteration 143/1000 | Loss: 0.00006475
Iteration 144/1000 | Loss: 0.00006475
Iteration 145/1000 | Loss: 0.00006475
Iteration 146/1000 | Loss: 0.00006475
Iteration 147/1000 | Loss: 0.00006474
Iteration 148/1000 | Loss: 0.00006474
Iteration 149/1000 | Loss: 0.00006474
Iteration 150/1000 | Loss: 0.00006474
Iteration 151/1000 | Loss: 0.00006474
Iteration 152/1000 | Loss: 0.00006474
Iteration 153/1000 | Loss: 0.00006474
Iteration 154/1000 | Loss: 0.00006473
Iteration 155/1000 | Loss: 0.00006473
Iteration 156/1000 | Loss: 0.00006473
Iteration 157/1000 | Loss: 0.00006473
Iteration 158/1000 | Loss: 0.00006473
Iteration 159/1000 | Loss: 0.00006473
Iteration 160/1000 | Loss: 0.00006473
Iteration 161/1000 | Loss: 0.00006473
Iteration 162/1000 | Loss: 0.00006473
Iteration 163/1000 | Loss: 0.00006473
Iteration 164/1000 | Loss: 0.00006473
Iteration 165/1000 | Loss: 0.00006473
Iteration 166/1000 | Loss: 0.00006473
Iteration 167/1000 | Loss: 0.00006473
Iteration 168/1000 | Loss: 0.00006472
Iteration 169/1000 | Loss: 0.00006472
Iteration 170/1000 | Loss: 0.00006472
Iteration 171/1000 | Loss: 0.00006472
Iteration 172/1000 | Loss: 0.00006472
Iteration 173/1000 | Loss: 0.00006472
Iteration 174/1000 | Loss: 0.00006472
Iteration 175/1000 | Loss: 0.00006472
Iteration 176/1000 | Loss: 0.00006471
Iteration 177/1000 | Loss: 0.00006471
Iteration 178/1000 | Loss: 0.00006471
Iteration 179/1000 | Loss: 0.00006471
Iteration 180/1000 | Loss: 0.00006471
Iteration 181/1000 | Loss: 0.00006471
Iteration 182/1000 | Loss: 0.00006471
Iteration 183/1000 | Loss: 0.00006471
Iteration 184/1000 | Loss: 0.00006471
Iteration 185/1000 | Loss: 0.00006471
Iteration 186/1000 | Loss: 0.00006470
Iteration 187/1000 | Loss: 0.00006470
Iteration 188/1000 | Loss: 0.00006470
Iteration 189/1000 | Loss: 0.00006470
Iteration 190/1000 | Loss: 0.00006470
Iteration 191/1000 | Loss: 0.00006470
Iteration 192/1000 | Loss: 0.00006470
Iteration 193/1000 | Loss: 0.00006469
Iteration 194/1000 | Loss: 0.00006469
Iteration 195/1000 | Loss: 0.00006469
Iteration 196/1000 | Loss: 0.00006469
Iteration 197/1000 | Loss: 0.00006469
Iteration 198/1000 | Loss: 0.00006469
Iteration 199/1000 | Loss: 0.00006468
Iteration 200/1000 | Loss: 0.00006468
Iteration 201/1000 | Loss: 0.00006468
Iteration 202/1000 | Loss: 0.00006468
Iteration 203/1000 | Loss: 0.00006468
Iteration 204/1000 | Loss: 0.00006468
Iteration 205/1000 | Loss: 0.00006468
Iteration 206/1000 | Loss: 0.00006468
Iteration 207/1000 | Loss: 0.00006468
Iteration 208/1000 | Loss: 0.00006468
Iteration 209/1000 | Loss: 0.00006468
Iteration 210/1000 | Loss: 0.00006468
Iteration 211/1000 | Loss: 0.00006468
Iteration 212/1000 | Loss: 0.00006468
Iteration 213/1000 | Loss: 0.00006468
Iteration 214/1000 | Loss: 0.00006468
Iteration 215/1000 | Loss: 0.00006468
Iteration 216/1000 | Loss: 0.00006468
Iteration 217/1000 | Loss: 0.00006468
Iteration 218/1000 | Loss: 0.00006468
Iteration 219/1000 | Loss: 0.00006468
Iteration 220/1000 | Loss: 0.00006468
Iteration 221/1000 | Loss: 0.00006468
Iteration 222/1000 | Loss: 0.00006468
Iteration 223/1000 | Loss: 0.00006468
Iteration 224/1000 | Loss: 0.00006468
Iteration 225/1000 | Loss: 0.00006468
Iteration 226/1000 | Loss: 0.00006468
Iteration 227/1000 | Loss: 0.00006468
Iteration 228/1000 | Loss: 0.00006468
Iteration 229/1000 | Loss: 0.00006468
Iteration 230/1000 | Loss: 0.00006468
Iteration 231/1000 | Loss: 0.00006468
Iteration 232/1000 | Loss: 0.00006468
Iteration 233/1000 | Loss: 0.00006468
Iteration 234/1000 | Loss: 0.00006468
Iteration 235/1000 | Loss: 0.00006468
Iteration 236/1000 | Loss: 0.00006468
Iteration 237/1000 | Loss: 0.00006468
Iteration 238/1000 | Loss: 0.00006468
Iteration 239/1000 | Loss: 0.00006468
Iteration 240/1000 | Loss: 0.00006468
Iteration 241/1000 | Loss: 0.00006468
Iteration 242/1000 | Loss: 0.00006468
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 242. Stopping optimization.
Last 5 losses: [6.468111678259447e-05, 6.468111678259447e-05, 6.468111678259447e-05, 6.468111678259447e-05, 6.468111678259447e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 6.468111678259447e-05

Optimization complete. Final v2v error: 6.715658664703369 mm

Highest mean error: 12.281408309936523 mm for frame 16

Lowest mean error: 6.046199321746826 mm for frame 25

Saving results

Total time: 106.04455351829529
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01117936
Iteration 2/25 | Loss: 0.00211579
Iteration 3/25 | Loss: 0.00175606
Iteration 4/25 | Loss: 0.00172236
Iteration 5/25 | Loss: 0.00170912
Iteration 6/25 | Loss: 0.00170570
Iteration 7/25 | Loss: 0.00170446
Iteration 8/25 | Loss: 0.00170446
Iteration 9/25 | Loss: 0.00170446
Iteration 10/25 | Loss: 0.00170446
Iteration 11/25 | Loss: 0.00170446
Iteration 12/25 | Loss: 0.00170446
Iteration 13/25 | Loss: 0.00170446
Iteration 14/25 | Loss: 0.00170446
Iteration 15/25 | Loss: 0.00170446
Iteration 16/25 | Loss: 0.00170446
Iteration 17/25 | Loss: 0.00170446
Iteration 18/25 | Loss: 0.00170446
Iteration 19/25 | Loss: 0.00170446
Iteration 20/25 | Loss: 0.00170446
Iteration 21/25 | Loss: 0.00170446
Iteration 22/25 | Loss: 0.00170446
Iteration 23/25 | Loss: 0.00170446
Iteration 24/25 | Loss: 0.00170446
Iteration 25/25 | Loss: 0.00170446

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.07501161
Iteration 2/25 | Loss: 0.00112579
Iteration 3/25 | Loss: 0.00112578
Iteration 4/25 | Loss: 0.00112578
Iteration 5/25 | Loss: 0.00112578
Iteration 6/25 | Loss: 0.00112578
Iteration 7/25 | Loss: 0.00112578
Iteration 8/25 | Loss: 0.00112578
Iteration 9/25 | Loss: 0.00112578
Iteration 10/25 | Loss: 0.00112578
Iteration 11/25 | Loss: 0.00112578
Iteration 12/25 | Loss: 0.00112578
Iteration 13/25 | Loss: 0.00112578
Iteration 14/25 | Loss: 0.00112578
Iteration 15/25 | Loss: 0.00112578
Iteration 16/25 | Loss: 0.00112578
Iteration 17/25 | Loss: 0.00112578
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001125775626860559, 0.001125775626860559, 0.001125775626860559, 0.001125775626860559, 0.001125775626860559]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001125775626860559

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112578
Iteration 2/1000 | Loss: 0.00011134
Iteration 3/1000 | Loss: 0.00008180
Iteration 4/1000 | Loss: 0.00006935
Iteration 5/1000 | Loss: 0.00006199
Iteration 6/1000 | Loss: 0.00005871
Iteration 7/1000 | Loss: 0.00005592
Iteration 8/1000 | Loss: 0.00005467
Iteration 9/1000 | Loss: 0.00005376
Iteration 10/1000 | Loss: 0.00005304
Iteration 11/1000 | Loss: 0.00005240
Iteration 12/1000 | Loss: 0.00005200
Iteration 13/1000 | Loss: 0.00005175
Iteration 14/1000 | Loss: 0.00005158
Iteration 15/1000 | Loss: 0.00005156
Iteration 16/1000 | Loss: 0.00005156
Iteration 17/1000 | Loss: 0.00005153
Iteration 18/1000 | Loss: 0.00005151
Iteration 19/1000 | Loss: 0.00005145
Iteration 20/1000 | Loss: 0.00005142
Iteration 21/1000 | Loss: 0.00005141
Iteration 22/1000 | Loss: 0.00005141
Iteration 23/1000 | Loss: 0.00005141
Iteration 24/1000 | Loss: 0.00005138
Iteration 25/1000 | Loss: 0.00005138
Iteration 26/1000 | Loss: 0.00005136
Iteration 27/1000 | Loss: 0.00005132
Iteration 28/1000 | Loss: 0.00005129
Iteration 29/1000 | Loss: 0.00005128
Iteration 30/1000 | Loss: 0.00005128
Iteration 31/1000 | Loss: 0.00005127
Iteration 32/1000 | Loss: 0.00005127
Iteration 33/1000 | Loss: 0.00005125
Iteration 34/1000 | Loss: 0.00005125
Iteration 35/1000 | Loss: 0.00005124
Iteration 36/1000 | Loss: 0.00005123
Iteration 37/1000 | Loss: 0.00005122
Iteration 38/1000 | Loss: 0.00005122
Iteration 39/1000 | Loss: 0.00005121
Iteration 40/1000 | Loss: 0.00005121
Iteration 41/1000 | Loss: 0.00005118
Iteration 42/1000 | Loss: 0.00005118
Iteration 43/1000 | Loss: 0.00005118
Iteration 44/1000 | Loss: 0.00005118
Iteration 45/1000 | Loss: 0.00005118
Iteration 46/1000 | Loss: 0.00005117
Iteration 47/1000 | Loss: 0.00005117
Iteration 48/1000 | Loss: 0.00005117
Iteration 49/1000 | Loss: 0.00005117
Iteration 50/1000 | Loss: 0.00005117
Iteration 51/1000 | Loss: 0.00005116
Iteration 52/1000 | Loss: 0.00005116
Iteration 53/1000 | Loss: 0.00005115
Iteration 54/1000 | Loss: 0.00005115
Iteration 55/1000 | Loss: 0.00005115
Iteration 56/1000 | Loss: 0.00005114
Iteration 57/1000 | Loss: 0.00005114
Iteration 58/1000 | Loss: 0.00005114
Iteration 59/1000 | Loss: 0.00005114
Iteration 60/1000 | Loss: 0.00005114
Iteration 61/1000 | Loss: 0.00005113
Iteration 62/1000 | Loss: 0.00005113
Iteration 63/1000 | Loss: 0.00005113
Iteration 64/1000 | Loss: 0.00005112
Iteration 65/1000 | Loss: 0.00005112
Iteration 66/1000 | Loss: 0.00005112
Iteration 67/1000 | Loss: 0.00005112
Iteration 68/1000 | Loss: 0.00005111
Iteration 69/1000 | Loss: 0.00005111
Iteration 70/1000 | Loss: 0.00005111
Iteration 71/1000 | Loss: 0.00005111
Iteration 72/1000 | Loss: 0.00005111
Iteration 73/1000 | Loss: 0.00005111
Iteration 74/1000 | Loss: 0.00005111
Iteration 75/1000 | Loss: 0.00005110
Iteration 76/1000 | Loss: 0.00005110
Iteration 77/1000 | Loss: 0.00005110
Iteration 78/1000 | Loss: 0.00005110
Iteration 79/1000 | Loss: 0.00005109
Iteration 80/1000 | Loss: 0.00005109
Iteration 81/1000 | Loss: 0.00005109
Iteration 82/1000 | Loss: 0.00005109
Iteration 83/1000 | Loss: 0.00005109
Iteration 84/1000 | Loss: 0.00005109
Iteration 85/1000 | Loss: 0.00005109
Iteration 86/1000 | Loss: 0.00005108
Iteration 87/1000 | Loss: 0.00005108
Iteration 88/1000 | Loss: 0.00005108
Iteration 89/1000 | Loss: 0.00005107
Iteration 90/1000 | Loss: 0.00005107
Iteration 91/1000 | Loss: 0.00005107
Iteration 92/1000 | Loss: 0.00005107
Iteration 93/1000 | Loss: 0.00005107
Iteration 94/1000 | Loss: 0.00005107
Iteration 95/1000 | Loss: 0.00005107
Iteration 96/1000 | Loss: 0.00005107
Iteration 97/1000 | Loss: 0.00005106
Iteration 98/1000 | Loss: 0.00005106
Iteration 99/1000 | Loss: 0.00005106
Iteration 100/1000 | Loss: 0.00005106
Iteration 101/1000 | Loss: 0.00005106
Iteration 102/1000 | Loss: 0.00005106
Iteration 103/1000 | Loss: 0.00005106
Iteration 104/1000 | Loss: 0.00005105
Iteration 105/1000 | Loss: 0.00005105
Iteration 106/1000 | Loss: 0.00005105
Iteration 107/1000 | Loss: 0.00005105
Iteration 108/1000 | Loss: 0.00005105
Iteration 109/1000 | Loss: 0.00005105
Iteration 110/1000 | Loss: 0.00005105
Iteration 111/1000 | Loss: 0.00005105
Iteration 112/1000 | Loss: 0.00005105
Iteration 113/1000 | Loss: 0.00005104
Iteration 114/1000 | Loss: 0.00005104
Iteration 115/1000 | Loss: 0.00005104
Iteration 116/1000 | Loss: 0.00005104
Iteration 117/1000 | Loss: 0.00005104
Iteration 118/1000 | Loss: 0.00005104
Iteration 119/1000 | Loss: 0.00005104
Iteration 120/1000 | Loss: 0.00005104
Iteration 121/1000 | Loss: 0.00005104
Iteration 122/1000 | Loss: 0.00005103
Iteration 123/1000 | Loss: 0.00005103
Iteration 124/1000 | Loss: 0.00005103
Iteration 125/1000 | Loss: 0.00005103
Iteration 126/1000 | Loss: 0.00005103
Iteration 127/1000 | Loss: 0.00005103
Iteration 128/1000 | Loss: 0.00005103
Iteration 129/1000 | Loss: 0.00005103
Iteration 130/1000 | Loss: 0.00005103
Iteration 131/1000 | Loss: 0.00005103
Iteration 132/1000 | Loss: 0.00005103
Iteration 133/1000 | Loss: 0.00005103
Iteration 134/1000 | Loss: 0.00005103
Iteration 135/1000 | Loss: 0.00005103
Iteration 136/1000 | Loss: 0.00005102
Iteration 137/1000 | Loss: 0.00005102
Iteration 138/1000 | Loss: 0.00005102
Iteration 139/1000 | Loss: 0.00005102
Iteration 140/1000 | Loss: 0.00005102
Iteration 141/1000 | Loss: 0.00005102
Iteration 142/1000 | Loss: 0.00005102
Iteration 143/1000 | Loss: 0.00005101
Iteration 144/1000 | Loss: 0.00005101
Iteration 145/1000 | Loss: 0.00005101
Iteration 146/1000 | Loss: 0.00005101
Iteration 147/1000 | Loss: 0.00005101
Iteration 148/1000 | Loss: 0.00005101
Iteration 149/1000 | Loss: 0.00005101
Iteration 150/1000 | Loss: 0.00005101
Iteration 151/1000 | Loss: 0.00005100
Iteration 152/1000 | Loss: 0.00005100
Iteration 153/1000 | Loss: 0.00005100
Iteration 154/1000 | Loss: 0.00005100
Iteration 155/1000 | Loss: 0.00005100
Iteration 156/1000 | Loss: 0.00005100
Iteration 157/1000 | Loss: 0.00005100
Iteration 158/1000 | Loss: 0.00005100
Iteration 159/1000 | Loss: 0.00005100
Iteration 160/1000 | Loss: 0.00005100
Iteration 161/1000 | Loss: 0.00005100
Iteration 162/1000 | Loss: 0.00005100
Iteration 163/1000 | Loss: 0.00005100
Iteration 164/1000 | Loss: 0.00005099
Iteration 165/1000 | Loss: 0.00005099
Iteration 166/1000 | Loss: 0.00005099
Iteration 167/1000 | Loss: 0.00005099
Iteration 168/1000 | Loss: 0.00005099
Iteration 169/1000 | Loss: 0.00005098
Iteration 170/1000 | Loss: 0.00005098
Iteration 171/1000 | Loss: 0.00005098
Iteration 172/1000 | Loss: 0.00005098
Iteration 173/1000 | Loss: 0.00005098
Iteration 174/1000 | Loss: 0.00005098
Iteration 175/1000 | Loss: 0.00005098
Iteration 176/1000 | Loss: 0.00005098
Iteration 177/1000 | Loss: 0.00005098
Iteration 178/1000 | Loss: 0.00005098
Iteration 179/1000 | Loss: 0.00005098
Iteration 180/1000 | Loss: 0.00005097
Iteration 181/1000 | Loss: 0.00005097
Iteration 182/1000 | Loss: 0.00005097
Iteration 183/1000 | Loss: 0.00005097
Iteration 184/1000 | Loss: 0.00005097
Iteration 185/1000 | Loss: 0.00005097
Iteration 186/1000 | Loss: 0.00005097
Iteration 187/1000 | Loss: 0.00005097
Iteration 188/1000 | Loss: 0.00005097
Iteration 189/1000 | Loss: 0.00005097
Iteration 190/1000 | Loss: 0.00005096
Iteration 191/1000 | Loss: 0.00005096
Iteration 192/1000 | Loss: 0.00005096
Iteration 193/1000 | Loss: 0.00005096
Iteration 194/1000 | Loss: 0.00005096
Iteration 195/1000 | Loss: 0.00005096
Iteration 196/1000 | Loss: 0.00005096
Iteration 197/1000 | Loss: 0.00005096
Iteration 198/1000 | Loss: 0.00005095
Iteration 199/1000 | Loss: 0.00005095
Iteration 200/1000 | Loss: 0.00005095
Iteration 201/1000 | Loss: 0.00005095
Iteration 202/1000 | Loss: 0.00005095
Iteration 203/1000 | Loss: 0.00005095
Iteration 204/1000 | Loss: 0.00005095
Iteration 205/1000 | Loss: 0.00005095
Iteration 206/1000 | Loss: 0.00005095
Iteration 207/1000 | Loss: 0.00005095
Iteration 208/1000 | Loss: 0.00005095
Iteration 209/1000 | Loss: 0.00005095
Iteration 210/1000 | Loss: 0.00005095
Iteration 211/1000 | Loss: 0.00005095
Iteration 212/1000 | Loss: 0.00005095
Iteration 213/1000 | Loss: 0.00005095
Iteration 214/1000 | Loss: 0.00005095
Iteration 215/1000 | Loss: 0.00005095
Iteration 216/1000 | Loss: 0.00005095
Iteration 217/1000 | Loss: 0.00005095
Iteration 218/1000 | Loss: 0.00005095
Iteration 219/1000 | Loss: 0.00005095
Iteration 220/1000 | Loss: 0.00005095
Iteration 221/1000 | Loss: 0.00005095
Iteration 222/1000 | Loss: 0.00005095
Iteration 223/1000 | Loss: 0.00005095
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 223. Stopping optimization.
Last 5 losses: [5.0953676691278815e-05, 5.0953676691278815e-05, 5.0953676691278815e-05, 5.0953676691278815e-05, 5.0953676691278815e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.0953676691278815e-05

Optimization complete. Final v2v error: 5.869400501251221 mm

Highest mean error: 6.709831714630127 mm for frame 76

Lowest mean error: 5.4169793128967285 mm for frame 0

Saving results

Total time: 49.3456244468689
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00527174
Iteration 2/25 | Loss: 0.00193521
Iteration 3/25 | Loss: 0.00165375
Iteration 4/25 | Loss: 0.00162418
Iteration 5/25 | Loss: 0.00161497
Iteration 6/25 | Loss: 0.00161243
Iteration 7/25 | Loss: 0.00161180
Iteration 8/25 | Loss: 0.00161180
Iteration 9/25 | Loss: 0.00161180
Iteration 10/25 | Loss: 0.00161180
Iteration 11/25 | Loss: 0.00161180
Iteration 12/25 | Loss: 0.00161180
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0016118019120767713, 0.0016118019120767713, 0.0016118019120767713, 0.0016118019120767713, 0.0016118019120767713]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016118019120767713

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.33865857
Iteration 2/25 | Loss: 0.00145082
Iteration 3/25 | Loss: 0.00145082
Iteration 4/25 | Loss: 0.00145082
Iteration 5/25 | Loss: 0.00145082
Iteration 6/25 | Loss: 0.00145082
Iteration 7/25 | Loss: 0.00145082
Iteration 8/25 | Loss: 0.00145082
Iteration 9/25 | Loss: 0.00145082
Iteration 10/25 | Loss: 0.00145082
Iteration 11/25 | Loss: 0.00145082
Iteration 12/25 | Loss: 0.00145082
Iteration 13/25 | Loss: 0.00145082
Iteration 14/25 | Loss: 0.00145082
Iteration 15/25 | Loss: 0.00145082
Iteration 16/25 | Loss: 0.00145082
Iteration 17/25 | Loss: 0.00145082
Iteration 18/25 | Loss: 0.00145082
Iteration 19/25 | Loss: 0.00145082
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0014508228050544858, 0.0014508228050544858, 0.0014508228050544858, 0.0014508228050544858, 0.0014508228050544858]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014508228050544858

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00145082
Iteration 2/1000 | Loss: 0.00008395
Iteration 3/1000 | Loss: 0.00006008
Iteration 4/1000 | Loss: 0.00004981
Iteration 5/1000 | Loss: 0.00004507
Iteration 6/1000 | Loss: 0.00004300
Iteration 7/1000 | Loss: 0.00004157
Iteration 8/1000 | Loss: 0.00004078
Iteration 9/1000 | Loss: 0.00004028
Iteration 10/1000 | Loss: 0.00003979
Iteration 11/1000 | Loss: 0.00003945
Iteration 12/1000 | Loss: 0.00003918
Iteration 13/1000 | Loss: 0.00003901
Iteration 14/1000 | Loss: 0.00003897
Iteration 15/1000 | Loss: 0.00003893
Iteration 16/1000 | Loss: 0.00003889
Iteration 17/1000 | Loss: 0.00003889
Iteration 18/1000 | Loss: 0.00003886
Iteration 19/1000 | Loss: 0.00003885
Iteration 20/1000 | Loss: 0.00003885
Iteration 21/1000 | Loss: 0.00003884
Iteration 22/1000 | Loss: 0.00003884
Iteration 23/1000 | Loss: 0.00003883
Iteration 24/1000 | Loss: 0.00003882
Iteration 25/1000 | Loss: 0.00003882
Iteration 26/1000 | Loss: 0.00003882
Iteration 27/1000 | Loss: 0.00003881
Iteration 28/1000 | Loss: 0.00003881
Iteration 29/1000 | Loss: 0.00003880
Iteration 30/1000 | Loss: 0.00003880
Iteration 31/1000 | Loss: 0.00003880
Iteration 32/1000 | Loss: 0.00003879
Iteration 33/1000 | Loss: 0.00003879
Iteration 34/1000 | Loss: 0.00003879
Iteration 35/1000 | Loss: 0.00003878
Iteration 36/1000 | Loss: 0.00003878
Iteration 37/1000 | Loss: 0.00003878
Iteration 38/1000 | Loss: 0.00003877
Iteration 39/1000 | Loss: 0.00003876
Iteration 40/1000 | Loss: 0.00003875
Iteration 41/1000 | Loss: 0.00003875
Iteration 42/1000 | Loss: 0.00003875
Iteration 43/1000 | Loss: 0.00003875
Iteration 44/1000 | Loss: 0.00003875
Iteration 45/1000 | Loss: 0.00003875
Iteration 46/1000 | Loss: 0.00003875
Iteration 47/1000 | Loss: 0.00003875
Iteration 48/1000 | Loss: 0.00003875
Iteration 49/1000 | Loss: 0.00003875
Iteration 50/1000 | Loss: 0.00003875
Iteration 51/1000 | Loss: 0.00003875
Iteration 52/1000 | Loss: 0.00003873
Iteration 53/1000 | Loss: 0.00003872
Iteration 54/1000 | Loss: 0.00003872
Iteration 55/1000 | Loss: 0.00003871
Iteration 56/1000 | Loss: 0.00003871
Iteration 57/1000 | Loss: 0.00003871
Iteration 58/1000 | Loss: 0.00003870
Iteration 59/1000 | Loss: 0.00003870
Iteration 60/1000 | Loss: 0.00003870
Iteration 61/1000 | Loss: 0.00003869
Iteration 62/1000 | Loss: 0.00003869
Iteration 63/1000 | Loss: 0.00003869
Iteration 64/1000 | Loss: 0.00003868
Iteration 65/1000 | Loss: 0.00003868
Iteration 66/1000 | Loss: 0.00003868
Iteration 67/1000 | Loss: 0.00003868
Iteration 68/1000 | Loss: 0.00003868
Iteration 69/1000 | Loss: 0.00003867
Iteration 70/1000 | Loss: 0.00003867
Iteration 71/1000 | Loss: 0.00003867
Iteration 72/1000 | Loss: 0.00003866
Iteration 73/1000 | Loss: 0.00003866
Iteration 74/1000 | Loss: 0.00003866
Iteration 75/1000 | Loss: 0.00003866
Iteration 76/1000 | Loss: 0.00003866
Iteration 77/1000 | Loss: 0.00003866
Iteration 78/1000 | Loss: 0.00003866
Iteration 79/1000 | Loss: 0.00003866
Iteration 80/1000 | Loss: 0.00003865
Iteration 81/1000 | Loss: 0.00003865
Iteration 82/1000 | Loss: 0.00003865
Iteration 83/1000 | Loss: 0.00003864
Iteration 84/1000 | Loss: 0.00003864
Iteration 85/1000 | Loss: 0.00003864
Iteration 86/1000 | Loss: 0.00003864
Iteration 87/1000 | Loss: 0.00003864
Iteration 88/1000 | Loss: 0.00003864
Iteration 89/1000 | Loss: 0.00003864
Iteration 90/1000 | Loss: 0.00003863
Iteration 91/1000 | Loss: 0.00003863
Iteration 92/1000 | Loss: 0.00003863
Iteration 93/1000 | Loss: 0.00003863
Iteration 94/1000 | Loss: 0.00003863
Iteration 95/1000 | Loss: 0.00003863
Iteration 96/1000 | Loss: 0.00003863
Iteration 97/1000 | Loss: 0.00003863
Iteration 98/1000 | Loss: 0.00003863
Iteration 99/1000 | Loss: 0.00003863
Iteration 100/1000 | Loss: 0.00003863
Iteration 101/1000 | Loss: 0.00003862
Iteration 102/1000 | Loss: 0.00003862
Iteration 103/1000 | Loss: 0.00003862
Iteration 104/1000 | Loss: 0.00003862
Iteration 105/1000 | Loss: 0.00003862
Iteration 106/1000 | Loss: 0.00003862
Iteration 107/1000 | Loss: 0.00003862
Iteration 108/1000 | Loss: 0.00003862
Iteration 109/1000 | Loss: 0.00003862
Iteration 110/1000 | Loss: 0.00003862
Iteration 111/1000 | Loss: 0.00003862
Iteration 112/1000 | Loss: 0.00003862
Iteration 113/1000 | Loss: 0.00003862
Iteration 114/1000 | Loss: 0.00003862
Iteration 115/1000 | Loss: 0.00003862
Iteration 116/1000 | Loss: 0.00003862
Iteration 117/1000 | Loss: 0.00003862
Iteration 118/1000 | Loss: 0.00003862
Iteration 119/1000 | Loss: 0.00003862
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [3.86211286240723e-05, 3.86211286240723e-05, 3.86211286240723e-05, 3.86211286240723e-05, 3.86211286240723e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.86211286240723e-05

Optimization complete. Final v2v error: 5.479280948638916 mm

Highest mean error: 5.693184852600098 mm for frame 122

Lowest mean error: 5.306851863861084 mm for frame 0

Saving results

Total time: 36.71581530570984
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01127002
Iteration 2/25 | Loss: 0.01127002
Iteration 3/25 | Loss: 0.00310556
Iteration 4/25 | Loss: 0.00252529
Iteration 5/25 | Loss: 0.00227158
Iteration 6/25 | Loss: 0.00229728
Iteration 7/25 | Loss: 0.00232824
Iteration 8/25 | Loss: 0.00222860
Iteration 9/25 | Loss: 0.00212940
Iteration 10/25 | Loss: 0.00205264
Iteration 11/25 | Loss: 0.00201839
Iteration 12/25 | Loss: 0.00198662
Iteration 13/25 | Loss: 0.00196864
Iteration 14/25 | Loss: 0.00194289
Iteration 15/25 | Loss: 0.00192829
Iteration 16/25 | Loss: 0.00190575
Iteration 17/25 | Loss: 0.00188683
Iteration 18/25 | Loss: 0.00188751
Iteration 19/25 | Loss: 0.00187916
Iteration 20/25 | Loss: 0.00187452
Iteration 21/25 | Loss: 0.00187714
Iteration 22/25 | Loss: 0.00187006
Iteration 23/25 | Loss: 0.00187401
Iteration 24/25 | Loss: 0.00188068
Iteration 25/25 | Loss: 0.00187120

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45162463
Iteration 2/25 | Loss: 0.00488646
Iteration 3/25 | Loss: 0.00488646
Iteration 4/25 | Loss: 0.00583231
Iteration 5/25 | Loss: 0.00612151
Iteration 6/25 | Loss: 0.00639564
Iteration 7/25 | Loss: 0.00446144
Iteration 8/25 | Loss: 0.00394180
Iteration 9/25 | Loss: 0.00394176
Iteration 10/25 | Loss: 0.00394176
Iteration 11/25 | Loss: 0.00394176
Iteration 12/25 | Loss: 0.00394176
Iteration 13/25 | Loss: 0.00394176
Iteration 14/25 | Loss: 0.00394176
Iteration 15/25 | Loss: 0.00394176
Iteration 16/25 | Loss: 0.00394176
Iteration 17/25 | Loss: 0.00394176
Iteration 18/25 | Loss: 0.00394176
Iteration 19/25 | Loss: 0.00394176
Iteration 20/25 | Loss: 0.00394176
Iteration 21/25 | Loss: 0.00394176
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.003941756673157215, 0.003941756673157215, 0.003941756673157215, 0.003941756673157215, 0.003941756673157215]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003941756673157215

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00394176
Iteration 2/1000 | Loss: 0.00080980
Iteration 3/1000 | Loss: 0.00216284
Iteration 4/1000 | Loss: 0.00148387
Iteration 5/1000 | Loss: 0.00148371
Iteration 6/1000 | Loss: 0.00134706
Iteration 7/1000 | Loss: 0.00129441
Iteration 8/1000 | Loss: 0.00062659
Iteration 9/1000 | Loss: 0.00035310
Iteration 10/1000 | Loss: 0.00083510
Iteration 11/1000 | Loss: 0.00023123
Iteration 12/1000 | Loss: 0.00022243
Iteration 13/1000 | Loss: 0.00020100
Iteration 14/1000 | Loss: 0.00083078
Iteration 15/1000 | Loss: 0.00113759
Iteration 16/1000 | Loss: 0.00152899
Iteration 17/1000 | Loss: 0.00126511
Iteration 18/1000 | Loss: 0.00044722
Iteration 19/1000 | Loss: 0.00023753
Iteration 20/1000 | Loss: 0.00033392
Iteration 21/1000 | Loss: 0.00028888
Iteration 22/1000 | Loss: 0.00018607
Iteration 23/1000 | Loss: 0.00018486
Iteration 24/1000 | Loss: 0.00016283
Iteration 25/1000 | Loss: 0.00039995
Iteration 26/1000 | Loss: 0.00033253
Iteration 27/1000 | Loss: 0.00080341
Iteration 28/1000 | Loss: 0.00018041
Iteration 29/1000 | Loss: 0.00047825
Iteration 30/1000 | Loss: 0.00015881
Iteration 31/1000 | Loss: 0.00016624
Iteration 32/1000 | Loss: 0.00055791
Iteration 33/1000 | Loss: 0.00022149
Iteration 34/1000 | Loss: 0.00038868
Iteration 35/1000 | Loss: 0.00024127
Iteration 36/1000 | Loss: 0.00025037
Iteration 37/1000 | Loss: 0.00015150
Iteration 38/1000 | Loss: 0.00028242
Iteration 39/1000 | Loss: 0.00021903
Iteration 40/1000 | Loss: 0.00022217
Iteration 41/1000 | Loss: 0.00025611
Iteration 42/1000 | Loss: 0.00027982
Iteration 43/1000 | Loss: 0.00017856
Iteration 44/1000 | Loss: 0.00023801
Iteration 45/1000 | Loss: 0.00018970
Iteration 46/1000 | Loss: 0.00022886
Iteration 47/1000 | Loss: 0.00042580
Iteration 48/1000 | Loss: 0.00034511
Iteration 49/1000 | Loss: 0.00022372
Iteration 50/1000 | Loss: 0.00051592
Iteration 51/1000 | Loss: 0.00044884
Iteration 52/1000 | Loss: 0.00049267
Iteration 53/1000 | Loss: 0.00037395
Iteration 54/1000 | Loss: 0.00037796
Iteration 55/1000 | Loss: 0.00018490
Iteration 56/1000 | Loss: 0.00016292
Iteration 57/1000 | Loss: 0.00017391
Iteration 58/1000 | Loss: 0.00018912
Iteration 59/1000 | Loss: 0.00016625
Iteration 60/1000 | Loss: 0.00016194
Iteration 61/1000 | Loss: 0.00017606
Iteration 62/1000 | Loss: 0.00018998
Iteration 63/1000 | Loss: 0.00017023
Iteration 64/1000 | Loss: 0.00017236
Iteration 65/1000 | Loss: 0.00016322
Iteration 66/1000 | Loss: 0.00015812
Iteration 67/1000 | Loss: 0.00017389
Iteration 68/1000 | Loss: 0.00014944
Iteration 69/1000 | Loss: 0.00016214
Iteration 70/1000 | Loss: 0.00016472
Iteration 71/1000 | Loss: 0.00016645
Iteration 72/1000 | Loss: 0.00017952
Iteration 73/1000 | Loss: 0.00017555
Iteration 74/1000 | Loss: 0.00016849
Iteration 75/1000 | Loss: 0.00017396
Iteration 76/1000 | Loss: 0.00015224
Iteration 77/1000 | Loss: 0.00015344
Iteration 78/1000 | Loss: 0.00017088
Iteration 79/1000 | Loss: 0.00017309
Iteration 80/1000 | Loss: 0.00017459
Iteration 81/1000 | Loss: 0.00016230
Iteration 82/1000 | Loss: 0.00015152
Iteration 83/1000 | Loss: 0.00017733
Iteration 84/1000 | Loss: 0.00017720
Iteration 85/1000 | Loss: 0.00017110
Iteration 86/1000 | Loss: 0.00016524
Iteration 87/1000 | Loss: 0.00015564
Iteration 88/1000 | Loss: 0.00018858
Iteration 89/1000 | Loss: 0.00015224
Iteration 90/1000 | Loss: 0.00015818
Iteration 91/1000 | Loss: 0.00015799
Iteration 92/1000 | Loss: 0.00017059
Iteration 93/1000 | Loss: 0.00016359
Iteration 94/1000 | Loss: 0.00016866
Iteration 95/1000 | Loss: 0.00016648
Iteration 96/1000 | Loss: 0.00016844
Iteration 97/1000 | Loss: 0.00016846
Iteration 98/1000 | Loss: 0.00016876
Iteration 99/1000 | Loss: 0.00016053
Iteration 100/1000 | Loss: 0.00015471
Iteration 101/1000 | Loss: 0.00014455
Iteration 102/1000 | Loss: 0.00014259
Iteration 103/1000 | Loss: 0.00014095
Iteration 104/1000 | Loss: 0.00013950
Iteration 105/1000 | Loss: 0.00013858
Iteration 106/1000 | Loss: 0.00013803
Iteration 107/1000 | Loss: 0.00013761
Iteration 108/1000 | Loss: 0.00013727
Iteration 109/1000 | Loss: 0.00013706
Iteration 110/1000 | Loss: 0.00013692
Iteration 111/1000 | Loss: 0.00013684
Iteration 112/1000 | Loss: 0.00013683
Iteration 113/1000 | Loss: 0.00013678
Iteration 114/1000 | Loss: 0.00013670
Iteration 115/1000 | Loss: 0.00013669
Iteration 116/1000 | Loss: 0.00013669
Iteration 117/1000 | Loss: 0.00013667
Iteration 118/1000 | Loss: 0.00013667
Iteration 119/1000 | Loss: 0.00013666
Iteration 120/1000 | Loss: 0.00013666
Iteration 121/1000 | Loss: 0.00013666
Iteration 122/1000 | Loss: 0.00013666
Iteration 123/1000 | Loss: 0.00013665
Iteration 124/1000 | Loss: 0.00013665
Iteration 125/1000 | Loss: 0.00013665
Iteration 126/1000 | Loss: 0.00013665
Iteration 127/1000 | Loss: 0.00013664
Iteration 128/1000 | Loss: 0.00013664
Iteration 129/1000 | Loss: 0.00013664
Iteration 130/1000 | Loss: 0.00013664
Iteration 131/1000 | Loss: 0.00013664
Iteration 132/1000 | Loss: 0.00013664
Iteration 133/1000 | Loss: 0.00013663
Iteration 134/1000 | Loss: 0.00013663
Iteration 135/1000 | Loss: 0.00013663
Iteration 136/1000 | Loss: 0.00013662
Iteration 137/1000 | Loss: 0.00013662
Iteration 138/1000 | Loss: 0.00013662
Iteration 139/1000 | Loss: 0.00013662
Iteration 140/1000 | Loss: 0.00013662
Iteration 141/1000 | Loss: 0.00013661
Iteration 142/1000 | Loss: 0.00013661
Iteration 143/1000 | Loss: 0.00013661
Iteration 144/1000 | Loss: 0.00013661
Iteration 145/1000 | Loss: 0.00013661
Iteration 146/1000 | Loss: 0.00013661
Iteration 147/1000 | Loss: 0.00013660
Iteration 148/1000 | Loss: 0.00013660
Iteration 149/1000 | Loss: 0.00013659
Iteration 150/1000 | Loss: 0.00013659
Iteration 151/1000 | Loss: 0.00013658
Iteration 152/1000 | Loss: 0.00013658
Iteration 153/1000 | Loss: 0.00013657
Iteration 154/1000 | Loss: 0.00013657
Iteration 155/1000 | Loss: 0.00013657
Iteration 156/1000 | Loss: 0.00013657
Iteration 157/1000 | Loss: 0.00013656
Iteration 158/1000 | Loss: 0.00013656
Iteration 159/1000 | Loss: 0.00013655
Iteration 160/1000 | Loss: 0.00013655
Iteration 161/1000 | Loss: 0.00013655
Iteration 162/1000 | Loss: 0.00013654
Iteration 163/1000 | Loss: 0.00013654
Iteration 164/1000 | Loss: 0.00013654
Iteration 165/1000 | Loss: 0.00013654
Iteration 166/1000 | Loss: 0.00013654
Iteration 167/1000 | Loss: 0.00013654
Iteration 168/1000 | Loss: 0.00013653
Iteration 169/1000 | Loss: 0.00013653
Iteration 170/1000 | Loss: 0.00013653
Iteration 171/1000 | Loss: 0.00013653
Iteration 172/1000 | Loss: 0.00013653
Iteration 173/1000 | Loss: 0.00013653
Iteration 174/1000 | Loss: 0.00013653
Iteration 175/1000 | Loss: 0.00013653
Iteration 176/1000 | Loss: 0.00013652
Iteration 177/1000 | Loss: 0.00013652
Iteration 178/1000 | Loss: 0.00013652
Iteration 179/1000 | Loss: 0.00013652
Iteration 180/1000 | Loss: 0.00013652
Iteration 181/1000 | Loss: 0.00013652
Iteration 182/1000 | Loss: 0.00013652
Iteration 183/1000 | Loss: 0.00013651
Iteration 184/1000 | Loss: 0.00013651
Iteration 185/1000 | Loss: 0.00013651
Iteration 186/1000 | Loss: 0.00013651
Iteration 187/1000 | Loss: 0.00013651
Iteration 188/1000 | Loss: 0.00013651
Iteration 189/1000 | Loss: 0.00013651
Iteration 190/1000 | Loss: 0.00013651
Iteration 191/1000 | Loss: 0.00013651
Iteration 192/1000 | Loss: 0.00013651
Iteration 193/1000 | Loss: 0.00013651
Iteration 194/1000 | Loss: 0.00013651
Iteration 195/1000 | Loss: 0.00013651
Iteration 196/1000 | Loss: 0.00013651
Iteration 197/1000 | Loss: 0.00013651
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [0.00013650978507939726, 0.00013650978507939726, 0.00013650978507939726, 0.00013650978507939726, 0.00013650978507939726]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00013650978507939726

Optimization complete. Final v2v error: 7.050802230834961 mm

Highest mean error: 15.103519439697266 mm for frame 172

Lowest mean error: 5.09591817855835 mm for frame 71

Saving results

Total time: 241.92652034759521
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01005805
Iteration 2/25 | Loss: 0.01005805
Iteration 3/25 | Loss: 0.01005805
Iteration 4/25 | Loss: 0.01005805
Iteration 5/25 | Loss: 0.01005804
Iteration 6/25 | Loss: 0.00551116
Iteration 7/25 | Loss: 0.00370936
Iteration 8/25 | Loss: 0.00310942
Iteration 9/25 | Loss: 0.00274401
Iteration 10/25 | Loss: 0.00233839
Iteration 11/25 | Loss: 0.00210641
Iteration 12/25 | Loss: 0.00187398
Iteration 13/25 | Loss: 0.00181091
Iteration 14/25 | Loss: 0.00174906
Iteration 15/25 | Loss: 0.00171993
Iteration 16/25 | Loss: 0.00170315
Iteration 17/25 | Loss: 0.00169439
Iteration 18/25 | Loss: 0.00168522
Iteration 19/25 | Loss: 0.00168292
Iteration 20/25 | Loss: 0.00168273
Iteration 21/25 | Loss: 0.00168134
Iteration 22/25 | Loss: 0.00168129
Iteration 23/25 | Loss: 0.00168129
Iteration 24/25 | Loss: 0.00168128
Iteration 25/25 | Loss: 0.00168128

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.53543395
Iteration 2/25 | Loss: 0.00245063
Iteration 3/25 | Loss: 0.00245063
Iteration 4/25 | Loss: 0.00245063
Iteration 5/25 | Loss: 0.00245063
Iteration 6/25 | Loss: 0.00245063
Iteration 7/25 | Loss: 0.00245063
Iteration 8/25 | Loss: 0.00245063
Iteration 9/25 | Loss: 0.00245063
Iteration 10/25 | Loss: 0.00245063
Iteration 11/25 | Loss: 0.00245063
Iteration 12/25 | Loss: 0.00245062
Iteration 13/25 | Loss: 0.00245062
Iteration 14/25 | Loss: 0.00245062
Iteration 15/25 | Loss: 0.00245062
Iteration 16/25 | Loss: 0.00245062
Iteration 17/25 | Loss: 0.00245062
Iteration 18/25 | Loss: 0.00245062
Iteration 19/25 | Loss: 0.00245062
Iteration 20/25 | Loss: 0.00245062
Iteration 21/25 | Loss: 0.00245062
Iteration 22/25 | Loss: 0.00245062
Iteration 23/25 | Loss: 0.00245062
Iteration 24/25 | Loss: 0.00245062
Iteration 25/25 | Loss: 0.00245062

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00245062
Iteration 2/1000 | Loss: 0.00018568
Iteration 3/1000 | Loss: 0.00010527
Iteration 4/1000 | Loss: 0.00008323
Iteration 5/1000 | Loss: 0.00007715
Iteration 6/1000 | Loss: 0.00007474
Iteration 7/1000 | Loss: 0.00007321
Iteration 8/1000 | Loss: 0.00007217
Iteration 9/1000 | Loss: 0.00007152
Iteration 10/1000 | Loss: 0.00007109
Iteration 11/1000 | Loss: 0.00007088
Iteration 12/1000 | Loss: 0.00007063
Iteration 13/1000 | Loss: 0.00008040
Iteration 14/1000 | Loss: 0.00007452
Iteration 15/1000 | Loss: 0.00007104
Iteration 16/1000 | Loss: 0.00007042
Iteration 17/1000 | Loss: 0.00007026
Iteration 18/1000 | Loss: 0.00007026
Iteration 19/1000 | Loss: 0.00007025
Iteration 20/1000 | Loss: 0.00007025
Iteration 21/1000 | Loss: 0.00007025
Iteration 22/1000 | Loss: 0.00007025
Iteration 23/1000 | Loss: 0.00007024
Iteration 24/1000 | Loss: 0.00007024
Iteration 25/1000 | Loss: 0.00007023
Iteration 26/1000 | Loss: 0.00007022
Iteration 27/1000 | Loss: 0.00007021
Iteration 28/1000 | Loss: 0.00007018
Iteration 29/1000 | Loss: 0.00007018
Iteration 30/1000 | Loss: 0.00007018
Iteration 31/1000 | Loss: 0.00007018
Iteration 32/1000 | Loss: 0.00007018
Iteration 33/1000 | Loss: 0.00007018
Iteration 34/1000 | Loss: 0.00007018
Iteration 35/1000 | Loss: 0.00007018
Iteration 36/1000 | Loss: 0.00007018
Iteration 37/1000 | Loss: 0.00007018
Iteration 38/1000 | Loss: 0.00007017
Iteration 39/1000 | Loss: 0.00007017
Iteration 40/1000 | Loss: 0.00007016
Iteration 41/1000 | Loss: 0.00007015
Iteration 42/1000 | Loss: 0.00007015
Iteration 43/1000 | Loss: 0.00007015
Iteration 44/1000 | Loss: 0.00007015
Iteration 45/1000 | Loss: 0.00007015
Iteration 46/1000 | Loss: 0.00007015
Iteration 47/1000 | Loss: 0.00007015
Iteration 48/1000 | Loss: 0.00007015
Iteration 49/1000 | Loss: 0.00007015
Iteration 50/1000 | Loss: 0.00007015
Iteration 51/1000 | Loss: 0.00007014
Iteration 52/1000 | Loss: 0.00007014
Iteration 53/1000 | Loss: 0.00007014
Iteration 54/1000 | Loss: 0.00007011
Iteration 55/1000 | Loss: 0.00007011
Iteration 56/1000 | Loss: 0.00007009
Iteration 57/1000 | Loss: 0.00007008
Iteration 58/1000 | Loss: 0.00007007
Iteration 59/1000 | Loss: 0.00007006
Iteration 60/1000 | Loss: 0.00007006
Iteration 61/1000 | Loss: 0.00007006
Iteration 62/1000 | Loss: 0.00007006
Iteration 63/1000 | Loss: 0.00007006
Iteration 64/1000 | Loss: 0.00007005
Iteration 65/1000 | Loss: 0.00007005
Iteration 66/1000 | Loss: 0.00007005
Iteration 67/1000 | Loss: 0.00007004
Iteration 68/1000 | Loss: 0.00007004
Iteration 69/1000 | Loss: 0.00007004
Iteration 70/1000 | Loss: 0.00007004
Iteration 71/1000 | Loss: 0.00007003
Iteration 72/1000 | Loss: 0.00007003
Iteration 73/1000 | Loss: 0.00007003
Iteration 74/1000 | Loss: 0.00007003
Iteration 75/1000 | Loss: 0.00007003
Iteration 76/1000 | Loss: 0.00007003
Iteration 77/1000 | Loss: 0.00007003
Iteration 78/1000 | Loss: 0.00007003
Iteration 79/1000 | Loss: 0.00007003
Iteration 80/1000 | Loss: 0.00007003
Iteration 81/1000 | Loss: 0.00007003
Iteration 82/1000 | Loss: 0.00007003
Iteration 83/1000 | Loss: 0.00007003
Iteration 84/1000 | Loss: 0.00007002
Iteration 85/1000 | Loss: 0.00007002
Iteration 86/1000 | Loss: 0.00007002
Iteration 87/1000 | Loss: 0.00007002
Iteration 88/1000 | Loss: 0.00007002
Iteration 89/1000 | Loss: 0.00007002
Iteration 90/1000 | Loss: 0.00007002
Iteration 91/1000 | Loss: 0.00007002
Iteration 92/1000 | Loss: 0.00007002
Iteration 93/1000 | Loss: 0.00007002
Iteration 94/1000 | Loss: 0.00007002
Iteration 95/1000 | Loss: 0.00007002
Iteration 96/1000 | Loss: 0.00007002
Iteration 97/1000 | Loss: 0.00007001
Iteration 98/1000 | Loss: 0.00007001
Iteration 99/1000 | Loss: 0.00007001
Iteration 100/1000 | Loss: 0.00007001
Iteration 101/1000 | Loss: 0.00007001
Iteration 102/1000 | Loss: 0.00007001
Iteration 103/1000 | Loss: 0.00007001
Iteration 104/1000 | Loss: 0.00007001
Iteration 105/1000 | Loss: 0.00007001
Iteration 106/1000 | Loss: 0.00007001
Iteration 107/1000 | Loss: 0.00007001
Iteration 108/1000 | Loss: 0.00007001
Iteration 109/1000 | Loss: 0.00007001
Iteration 110/1000 | Loss: 0.00007001
Iteration 111/1000 | Loss: 0.00007001
Iteration 112/1000 | Loss: 0.00007001
Iteration 113/1000 | Loss: 0.00007001
Iteration 114/1000 | Loss: 0.00007001
Iteration 115/1000 | Loss: 0.00007001
Iteration 116/1000 | Loss: 0.00007001
Iteration 117/1000 | Loss: 0.00007001
Iteration 118/1000 | Loss: 0.00007001
Iteration 119/1000 | Loss: 0.00007000
Iteration 120/1000 | Loss: 0.00007000
Iteration 121/1000 | Loss: 0.00007000
Iteration 122/1000 | Loss: 0.00007000
Iteration 123/1000 | Loss: 0.00007000
Iteration 124/1000 | Loss: 0.00007000
Iteration 125/1000 | Loss: 0.00007000
Iteration 126/1000 | Loss: 0.00007000
Iteration 127/1000 | Loss: 0.00007000
Iteration 128/1000 | Loss: 0.00007000
Iteration 129/1000 | Loss: 0.00007000
Iteration 130/1000 | Loss: 0.00007000
Iteration 131/1000 | Loss: 0.00007000
Iteration 132/1000 | Loss: 0.00007000
Iteration 133/1000 | Loss: 0.00007000
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [7.000436016824096e-05, 7.000436016824096e-05, 7.000436016824096e-05, 7.000436016824096e-05, 7.000436016824096e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 7.000436016824096e-05

Optimization complete. Final v2v error: 6.769284248352051 mm

Highest mean error: 10.163427352905273 mm for frame 230

Lowest mean error: 5.734856128692627 mm for frame 234

Saving results

Total time: 72.18349123001099
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00514934
Iteration 2/25 | Loss: 0.00172281
Iteration 3/25 | Loss: 0.00164236
Iteration 4/25 | Loss: 0.00162123
Iteration 5/25 | Loss: 0.00161506
Iteration 6/25 | Loss: 0.00161377
Iteration 7/25 | Loss: 0.00161348
Iteration 8/25 | Loss: 0.00161348
Iteration 9/25 | Loss: 0.00161348
Iteration 10/25 | Loss: 0.00161348
Iteration 11/25 | Loss: 0.00161348
Iteration 12/25 | Loss: 0.00161348
Iteration 13/25 | Loss: 0.00161348
Iteration 14/25 | Loss: 0.00161348
Iteration 15/25 | Loss: 0.00161348
Iteration 16/25 | Loss: 0.00161348
Iteration 17/25 | Loss: 0.00161348
Iteration 18/25 | Loss: 0.00161348
Iteration 19/25 | Loss: 0.00161348
Iteration 20/25 | Loss: 0.00161348
Iteration 21/25 | Loss: 0.00161348
Iteration 22/25 | Loss: 0.00161348
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0016134835314005613, 0.0016134835314005613, 0.0016134835314005613, 0.0016134835314005613, 0.0016134835314005613]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016134835314005613

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.28022444
Iteration 2/25 | Loss: 0.00143679
Iteration 3/25 | Loss: 0.00143679
Iteration 4/25 | Loss: 0.00143679
Iteration 5/25 | Loss: 0.00143679
Iteration 6/25 | Loss: 0.00143679
Iteration 7/25 | Loss: 0.00143679
Iteration 8/25 | Loss: 0.00143679
Iteration 9/25 | Loss: 0.00143679
Iteration 10/25 | Loss: 0.00143679
Iteration 11/25 | Loss: 0.00143679
Iteration 12/25 | Loss: 0.00143679
Iteration 13/25 | Loss: 0.00143679
Iteration 14/25 | Loss: 0.00143679
Iteration 15/25 | Loss: 0.00143679
Iteration 16/25 | Loss: 0.00143679
Iteration 17/25 | Loss: 0.00143679
Iteration 18/25 | Loss: 0.00143679
Iteration 19/25 | Loss: 0.00143679
Iteration 20/25 | Loss: 0.00143679
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0014367860276252031, 0.0014367860276252031, 0.0014367860276252031, 0.0014367860276252031, 0.0014367860276252031]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014367860276252031

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00143679
Iteration 2/1000 | Loss: 0.00008947
Iteration 3/1000 | Loss: 0.00006381
Iteration 4/1000 | Loss: 0.00005299
Iteration 5/1000 | Loss: 0.00004994
Iteration 6/1000 | Loss: 0.00004759
Iteration 7/1000 | Loss: 0.00004627
Iteration 8/1000 | Loss: 0.00004563
Iteration 9/1000 | Loss: 0.00004501
Iteration 10/1000 | Loss: 0.00004465
Iteration 11/1000 | Loss: 0.00004447
Iteration 12/1000 | Loss: 0.00004433
Iteration 13/1000 | Loss: 0.00004432
Iteration 14/1000 | Loss: 0.00004429
Iteration 15/1000 | Loss: 0.00004429
Iteration 16/1000 | Loss: 0.00004429
Iteration 17/1000 | Loss: 0.00004429
Iteration 18/1000 | Loss: 0.00004428
Iteration 19/1000 | Loss: 0.00004427
Iteration 20/1000 | Loss: 0.00004427
Iteration 21/1000 | Loss: 0.00004426
Iteration 22/1000 | Loss: 0.00004426
Iteration 23/1000 | Loss: 0.00004426
Iteration 24/1000 | Loss: 0.00004426
Iteration 25/1000 | Loss: 0.00004426
Iteration 26/1000 | Loss: 0.00004425
Iteration 27/1000 | Loss: 0.00004425
Iteration 28/1000 | Loss: 0.00004425
Iteration 29/1000 | Loss: 0.00004424
Iteration 30/1000 | Loss: 0.00004424
Iteration 31/1000 | Loss: 0.00004423
Iteration 32/1000 | Loss: 0.00004423
Iteration 33/1000 | Loss: 0.00004422
Iteration 34/1000 | Loss: 0.00004422
Iteration 35/1000 | Loss: 0.00004421
Iteration 36/1000 | Loss: 0.00004421
Iteration 37/1000 | Loss: 0.00004421
Iteration 38/1000 | Loss: 0.00004420
Iteration 39/1000 | Loss: 0.00004420
Iteration 40/1000 | Loss: 0.00004420
Iteration 41/1000 | Loss: 0.00004420
Iteration 42/1000 | Loss: 0.00004420
Iteration 43/1000 | Loss: 0.00004420
Iteration 44/1000 | Loss: 0.00004420
Iteration 45/1000 | Loss: 0.00004420
Iteration 46/1000 | Loss: 0.00004420
Iteration 47/1000 | Loss: 0.00004419
Iteration 48/1000 | Loss: 0.00004419
Iteration 49/1000 | Loss: 0.00004417
Iteration 50/1000 | Loss: 0.00004417
Iteration 51/1000 | Loss: 0.00004417
Iteration 52/1000 | Loss: 0.00004417
Iteration 53/1000 | Loss: 0.00004417
Iteration 54/1000 | Loss: 0.00004417
Iteration 55/1000 | Loss: 0.00004417
Iteration 56/1000 | Loss: 0.00004416
Iteration 57/1000 | Loss: 0.00004416
Iteration 58/1000 | Loss: 0.00004416
Iteration 59/1000 | Loss: 0.00004415
Iteration 60/1000 | Loss: 0.00004415
Iteration 61/1000 | Loss: 0.00004414
Iteration 62/1000 | Loss: 0.00004414
Iteration 63/1000 | Loss: 0.00004413
Iteration 64/1000 | Loss: 0.00004413
Iteration 65/1000 | Loss: 0.00004413
Iteration 66/1000 | Loss: 0.00004413
Iteration 67/1000 | Loss: 0.00004413
Iteration 68/1000 | Loss: 0.00004412
Iteration 69/1000 | Loss: 0.00004412
Iteration 70/1000 | Loss: 0.00004412
Iteration 71/1000 | Loss: 0.00004411
Iteration 72/1000 | Loss: 0.00004411
Iteration 73/1000 | Loss: 0.00004411
Iteration 74/1000 | Loss: 0.00004410
Iteration 75/1000 | Loss: 0.00004410
Iteration 76/1000 | Loss: 0.00004410
Iteration 77/1000 | Loss: 0.00004410
Iteration 78/1000 | Loss: 0.00004410
Iteration 79/1000 | Loss: 0.00004409
Iteration 80/1000 | Loss: 0.00004409
Iteration 81/1000 | Loss: 0.00004409
Iteration 82/1000 | Loss: 0.00004408
Iteration 83/1000 | Loss: 0.00004408
Iteration 84/1000 | Loss: 0.00004408
Iteration 85/1000 | Loss: 0.00004407
Iteration 86/1000 | Loss: 0.00004407
Iteration 87/1000 | Loss: 0.00004406
Iteration 88/1000 | Loss: 0.00004406
Iteration 89/1000 | Loss: 0.00004406
Iteration 90/1000 | Loss: 0.00004405
Iteration 91/1000 | Loss: 0.00004405
Iteration 92/1000 | Loss: 0.00004405
Iteration 93/1000 | Loss: 0.00004405
Iteration 94/1000 | Loss: 0.00004404
Iteration 95/1000 | Loss: 0.00004404
Iteration 96/1000 | Loss: 0.00004404
Iteration 97/1000 | Loss: 0.00004403
Iteration 98/1000 | Loss: 0.00004403
Iteration 99/1000 | Loss: 0.00004403
Iteration 100/1000 | Loss: 0.00004403
Iteration 101/1000 | Loss: 0.00004402
Iteration 102/1000 | Loss: 0.00004402
Iteration 103/1000 | Loss: 0.00004402
Iteration 104/1000 | Loss: 0.00004402
Iteration 105/1000 | Loss: 0.00004402
Iteration 106/1000 | Loss: 0.00004402
Iteration 107/1000 | Loss: 0.00004402
Iteration 108/1000 | Loss: 0.00004402
Iteration 109/1000 | Loss: 0.00004402
Iteration 110/1000 | Loss: 0.00004401
Iteration 111/1000 | Loss: 0.00004401
Iteration 112/1000 | Loss: 0.00004401
Iteration 113/1000 | Loss: 0.00004401
Iteration 114/1000 | Loss: 0.00004401
Iteration 115/1000 | Loss: 0.00004401
Iteration 116/1000 | Loss: 0.00004401
Iteration 117/1000 | Loss: 0.00004401
Iteration 118/1000 | Loss: 0.00004401
Iteration 119/1000 | Loss: 0.00004401
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [4.4013366277795285e-05, 4.4013366277795285e-05, 4.4013366277795285e-05, 4.4013366277795285e-05, 4.4013366277795285e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.4013366277795285e-05

Optimization complete. Final v2v error: 5.625064849853516 mm

Highest mean error: 6.224903106689453 mm for frame 29

Lowest mean error: 5.296324729919434 mm for frame 15

Saving results

Total time: 34.907209157943726
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01101100
Iteration 2/25 | Loss: 0.00266916
Iteration 3/25 | Loss: 0.00190541
Iteration 4/25 | Loss: 0.00176507
Iteration 5/25 | Loss: 0.00178199
Iteration 6/25 | Loss: 0.00178051
Iteration 7/25 | Loss: 0.00158184
Iteration 8/25 | Loss: 0.00149678
Iteration 9/25 | Loss: 0.00148171
Iteration 10/25 | Loss: 0.00146494
Iteration 11/25 | Loss: 0.00145743
Iteration 12/25 | Loss: 0.00145378
Iteration 13/25 | Loss: 0.00144653
Iteration 14/25 | Loss: 0.00144385
Iteration 15/25 | Loss: 0.00144136
Iteration 16/25 | Loss: 0.00144198
Iteration 17/25 | Loss: 0.00144067
Iteration 18/25 | Loss: 0.00143944
Iteration 19/25 | Loss: 0.00143851
Iteration 20/25 | Loss: 0.00143950
Iteration 21/25 | Loss: 0.00144090
Iteration 22/25 | Loss: 0.00143948
Iteration 23/25 | Loss: 0.00144110
Iteration 24/25 | Loss: 0.00143932
Iteration 25/25 | Loss: 0.00144159

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.34800863
Iteration 2/25 | Loss: 0.00116511
Iteration 3/25 | Loss: 0.00115247
Iteration 4/25 | Loss: 0.00115247
Iteration 5/25 | Loss: 0.00115247
Iteration 6/25 | Loss: 0.00115247
Iteration 7/25 | Loss: 0.00115247
Iteration 8/25 | Loss: 0.00115247
Iteration 9/25 | Loss: 0.00115247
Iteration 10/25 | Loss: 0.00115247
Iteration 11/25 | Loss: 0.00115247
Iteration 12/25 | Loss: 0.00115247
Iteration 13/25 | Loss: 0.00115247
Iteration 14/25 | Loss: 0.00115247
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0011524742003530264, 0.0011524742003530264, 0.0011524742003530264, 0.0011524742003530264, 0.0011524742003530264]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011524742003530264

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00115247
Iteration 2/1000 | Loss: 0.00010110
Iteration 3/1000 | Loss: 0.00010299
Iteration 4/1000 | Loss: 0.00007074
Iteration 5/1000 | Loss: 0.00011407
Iteration 6/1000 | Loss: 0.00007345
Iteration 7/1000 | Loss: 0.00010056
Iteration 8/1000 | Loss: 0.00006221
Iteration 9/1000 | Loss: 0.00008879
Iteration 10/1000 | Loss: 0.00007664
Iteration 11/1000 | Loss: 0.00007692
Iteration 12/1000 | Loss: 0.00007141
Iteration 13/1000 | Loss: 0.00008948
Iteration 14/1000 | Loss: 0.00006787
Iteration 15/1000 | Loss: 0.00005362
Iteration 16/1000 | Loss: 0.00006966
Iteration 17/1000 | Loss: 0.00004720
Iteration 18/1000 | Loss: 0.00005668
Iteration 19/1000 | Loss: 0.00007169
Iteration 20/1000 | Loss: 0.00005329
Iteration 21/1000 | Loss: 0.00006827
Iteration 22/1000 | Loss: 0.00009378
Iteration 23/1000 | Loss: 0.00014542
Iteration 24/1000 | Loss: 0.00005283
Iteration 25/1000 | Loss: 0.00005278
Iteration 26/1000 | Loss: 0.00004702
Iteration 27/1000 | Loss: 0.00006585
Iteration 28/1000 | Loss: 0.00005708
Iteration 29/1000 | Loss: 0.00006270
Iteration 30/1000 | Loss: 0.00006364
Iteration 31/1000 | Loss: 0.00008245
Iteration 32/1000 | Loss: 0.00004646
Iteration 33/1000 | Loss: 0.00005656
Iteration 34/1000 | Loss: 0.00005496
Iteration 35/1000 | Loss: 0.00005728
Iteration 36/1000 | Loss: 0.00006991
Iteration 37/1000 | Loss: 0.00004589
Iteration 38/1000 | Loss: 0.00004733
Iteration 39/1000 | Loss: 0.00007466
Iteration 40/1000 | Loss: 0.00003763
Iteration 41/1000 | Loss: 0.00004388
Iteration 42/1000 | Loss: 0.00003796
Iteration 43/1000 | Loss: 0.00003527
Iteration 44/1000 | Loss: 0.00003481
Iteration 45/1000 | Loss: 0.00003455
Iteration 46/1000 | Loss: 0.00003440
Iteration 47/1000 | Loss: 0.00003416
Iteration 48/1000 | Loss: 0.00003415
Iteration 49/1000 | Loss: 0.00003395
Iteration 50/1000 | Loss: 0.00004351
Iteration 51/1000 | Loss: 0.00003685
Iteration 52/1000 | Loss: 0.00003422
Iteration 53/1000 | Loss: 0.00003397
Iteration 54/1000 | Loss: 0.00003397
Iteration 55/1000 | Loss: 0.00003368
Iteration 56/1000 | Loss: 0.00003367
Iteration 57/1000 | Loss: 0.00003367
Iteration 58/1000 | Loss: 0.00003367
Iteration 59/1000 | Loss: 0.00003366
Iteration 60/1000 | Loss: 0.00003366
Iteration 61/1000 | Loss: 0.00003365
Iteration 62/1000 | Loss: 0.00003365
Iteration 63/1000 | Loss: 0.00003365
Iteration 64/1000 | Loss: 0.00003365
Iteration 65/1000 | Loss: 0.00003364
Iteration 66/1000 | Loss: 0.00003364
Iteration 67/1000 | Loss: 0.00003364
Iteration 68/1000 | Loss: 0.00003364
Iteration 69/1000 | Loss: 0.00003364
Iteration 70/1000 | Loss: 0.00003363
Iteration 71/1000 | Loss: 0.00003363
Iteration 72/1000 | Loss: 0.00003441
Iteration 73/1000 | Loss: 0.00003440
Iteration 74/1000 | Loss: 0.00003418
Iteration 75/1000 | Loss: 0.00003382
Iteration 76/1000 | Loss: 0.00003355
Iteration 77/1000 | Loss: 0.00003354
Iteration 78/1000 | Loss: 0.00003354
Iteration 79/1000 | Loss: 0.00003354
Iteration 80/1000 | Loss: 0.00003353
Iteration 81/1000 | Loss: 0.00003353
Iteration 82/1000 | Loss: 0.00003353
Iteration 83/1000 | Loss: 0.00003353
Iteration 84/1000 | Loss: 0.00003352
Iteration 85/1000 | Loss: 0.00003352
Iteration 86/1000 | Loss: 0.00003352
Iteration 87/1000 | Loss: 0.00003352
Iteration 88/1000 | Loss: 0.00003352
Iteration 89/1000 | Loss: 0.00003352
Iteration 90/1000 | Loss: 0.00003352
Iteration 91/1000 | Loss: 0.00003351
Iteration 92/1000 | Loss: 0.00003351
Iteration 93/1000 | Loss: 0.00003351
Iteration 94/1000 | Loss: 0.00003351
Iteration 95/1000 | Loss: 0.00003351
Iteration 96/1000 | Loss: 0.00003351
Iteration 97/1000 | Loss: 0.00003351
Iteration 98/1000 | Loss: 0.00003350
Iteration 99/1000 | Loss: 0.00003350
Iteration 100/1000 | Loss: 0.00003350
Iteration 101/1000 | Loss: 0.00003350
Iteration 102/1000 | Loss: 0.00003350
Iteration 103/1000 | Loss: 0.00003350
Iteration 104/1000 | Loss: 0.00003350
Iteration 105/1000 | Loss: 0.00003350
Iteration 106/1000 | Loss: 0.00003350
Iteration 107/1000 | Loss: 0.00003350
Iteration 108/1000 | Loss: 0.00003349
Iteration 109/1000 | Loss: 0.00003349
Iteration 110/1000 | Loss: 0.00003349
Iteration 111/1000 | Loss: 0.00003349
Iteration 112/1000 | Loss: 0.00003349
Iteration 113/1000 | Loss: 0.00003349
Iteration 114/1000 | Loss: 0.00003349
Iteration 115/1000 | Loss: 0.00003349
Iteration 116/1000 | Loss: 0.00003349
Iteration 117/1000 | Loss: 0.00003349
Iteration 118/1000 | Loss: 0.00003349
Iteration 119/1000 | Loss: 0.00003349
Iteration 120/1000 | Loss: 0.00003349
Iteration 121/1000 | Loss: 0.00003349
Iteration 122/1000 | Loss: 0.00003349
Iteration 123/1000 | Loss: 0.00003349
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [3.349406324559823e-05, 3.349406324559823e-05, 3.349406324559823e-05, 3.349406324559823e-05, 3.349406324559823e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.349406324559823e-05

Optimization complete. Final v2v error: 4.926155090332031 mm

Highest mean error: 13.079253196716309 mm for frame 35

Lowest mean error: 4.343416690826416 mm for frame 6

Saving results

Total time: 127.39328694343567
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01000964
Iteration 2/25 | Loss: 0.00392976
Iteration 3/25 | Loss: 0.00320249
Iteration 4/25 | Loss: 0.00253880
Iteration 5/25 | Loss: 0.00255419
Iteration 6/25 | Loss: 0.00245886
Iteration 7/25 | Loss: 0.00242014
Iteration 8/25 | Loss: 0.00240871
Iteration 9/25 | Loss: 0.00239705
Iteration 10/25 | Loss: 0.00240435
Iteration 11/25 | Loss: 0.00240487
Iteration 12/25 | Loss: 0.00239275
Iteration 13/25 | Loss: 0.00238069
Iteration 14/25 | Loss: 0.00238064
Iteration 15/25 | Loss: 0.00238071
Iteration 16/25 | Loss: 0.00238005
Iteration 17/25 | Loss: 0.00238058
Iteration 18/25 | Loss: 0.00237975
Iteration 19/25 | Loss: 0.00237888
Iteration 20/25 | Loss: 0.00237983
Iteration 21/25 | Loss: 0.00237942
Iteration 22/25 | Loss: 0.00237995
Iteration 23/25 | Loss: 0.00237961
Iteration 24/25 | Loss: 0.00237959
Iteration 25/25 | Loss: 0.00237915

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.63105875
Iteration 2/25 | Loss: 0.00872041
Iteration 3/25 | Loss: 0.00481246
Iteration 4/25 | Loss: 0.00481245
Iteration 5/25 | Loss: 0.00481245
Iteration 6/25 | Loss: 0.00481245
Iteration 7/25 | Loss: 0.00481245
Iteration 8/25 | Loss: 0.00481245
Iteration 9/25 | Loss: 0.00481245
Iteration 10/25 | Loss: 0.00481245
Iteration 11/25 | Loss: 0.00481245
Iteration 12/25 | Loss: 0.00481245
Iteration 13/25 | Loss: 0.00481245
Iteration 14/25 | Loss: 0.00481245
Iteration 15/25 | Loss: 0.00481245
Iteration 16/25 | Loss: 0.00481245
Iteration 17/25 | Loss: 0.00481245
Iteration 18/25 | Loss: 0.00481245
Iteration 19/25 | Loss: 0.00481245
Iteration 20/25 | Loss: 0.00481245
Iteration 21/25 | Loss: 0.00481245
Iteration 22/25 | Loss: 0.00481245
Iteration 23/25 | Loss: 0.00481245
Iteration 24/25 | Loss: 0.00481245
Iteration 25/25 | Loss: 0.00481245

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00481245
Iteration 2/1000 | Loss: 0.00138257
Iteration 3/1000 | Loss: 0.00029458
Iteration 4/1000 | Loss: 0.00021838
Iteration 5/1000 | Loss: 0.00019607
Iteration 6/1000 | Loss: 0.00018309
Iteration 7/1000 | Loss: 0.00139654
Iteration 8/1000 | Loss: 0.00016350
Iteration 9/1000 | Loss: 0.00015966
Iteration 10/1000 | Loss: 0.00018954
Iteration 11/1000 | Loss: 0.00015511
Iteration 12/1000 | Loss: 0.00015338
Iteration 13/1000 | Loss: 0.00015692
Iteration 14/1000 | Loss: 0.00015008
Iteration 15/1000 | Loss: 0.00015445
Iteration 16/1000 | Loss: 0.00015314
Iteration 17/1000 | Loss: 0.00043036
Iteration 18/1000 | Loss: 0.00019451
Iteration 19/1000 | Loss: 0.00015175
Iteration 20/1000 | Loss: 0.00015433
Iteration 21/1000 | Loss: 0.00015018
Iteration 22/1000 | Loss: 0.00015358
Iteration 23/1000 | Loss: 0.00019926
Iteration 24/1000 | Loss: 0.00015197
Iteration 25/1000 | Loss: 0.00043751
Iteration 26/1000 | Loss: 0.00124097
Iteration 27/1000 | Loss: 0.00019407
Iteration 28/1000 | Loss: 0.00033980
Iteration 29/1000 | Loss: 0.00076801
Iteration 30/1000 | Loss: 0.00032845
Iteration 31/1000 | Loss: 0.00015319
Iteration 32/1000 | Loss: 0.00014759
Iteration 33/1000 | Loss: 0.00014292
Iteration 34/1000 | Loss: 0.00014221
Iteration 35/1000 | Loss: 0.00019882
Iteration 36/1000 | Loss: 0.00068621
Iteration 37/1000 | Loss: 0.00018504
Iteration 38/1000 | Loss: 0.00014205
Iteration 39/1000 | Loss: 0.00014148
Iteration 40/1000 | Loss: 0.00014130
Iteration 41/1000 | Loss: 0.00014108
Iteration 42/1000 | Loss: 0.00049899
Iteration 43/1000 | Loss: 0.00130376
Iteration 44/1000 | Loss: 0.00016348
Iteration 45/1000 | Loss: 0.00016444
Iteration 46/1000 | Loss: 0.00022416
Iteration 47/1000 | Loss: 0.00032607
Iteration 48/1000 | Loss: 0.00014122
Iteration 49/1000 | Loss: 0.00014075
Iteration 50/1000 | Loss: 0.00014041
Iteration 51/1000 | Loss: 0.00014021
Iteration 52/1000 | Loss: 0.00014002
Iteration 53/1000 | Loss: 0.00013979
Iteration 54/1000 | Loss: 0.00027463
Iteration 55/1000 | Loss: 0.00014000
Iteration 56/1000 | Loss: 0.00013951
Iteration 57/1000 | Loss: 0.00033597
Iteration 58/1000 | Loss: 0.00032938
Iteration 59/1000 | Loss: 0.00014162
Iteration 60/1000 | Loss: 0.00017686
Iteration 61/1000 | Loss: 0.00014617
Iteration 62/1000 | Loss: 0.00013962
Iteration 63/1000 | Loss: 0.00033904
Iteration 64/1000 | Loss: 0.00016142
Iteration 65/1000 | Loss: 0.00013965
Iteration 66/1000 | Loss: 0.00013930
Iteration 67/1000 | Loss: 0.00013916
Iteration 68/1000 | Loss: 0.00013916
Iteration 69/1000 | Loss: 0.00013916
Iteration 70/1000 | Loss: 0.00013915
Iteration 71/1000 | Loss: 0.00013915
Iteration 72/1000 | Loss: 0.00013915
Iteration 73/1000 | Loss: 0.00013915
Iteration 74/1000 | Loss: 0.00013915
Iteration 75/1000 | Loss: 0.00013915
Iteration 76/1000 | Loss: 0.00013915
Iteration 77/1000 | Loss: 0.00013914
Iteration 78/1000 | Loss: 0.00013913
Iteration 79/1000 | Loss: 0.00013913
Iteration 80/1000 | Loss: 0.00013912
Iteration 81/1000 | Loss: 0.00013912
Iteration 82/1000 | Loss: 0.00013912
Iteration 83/1000 | Loss: 0.00013912
Iteration 84/1000 | Loss: 0.00013912
Iteration 85/1000 | Loss: 0.00013912
Iteration 86/1000 | Loss: 0.00013912
Iteration 87/1000 | Loss: 0.00013911
Iteration 88/1000 | Loss: 0.00013911
Iteration 89/1000 | Loss: 0.00013911
Iteration 90/1000 | Loss: 0.00013911
Iteration 91/1000 | Loss: 0.00013911
Iteration 92/1000 | Loss: 0.00013911
Iteration 93/1000 | Loss: 0.00013911
Iteration 94/1000 | Loss: 0.00013911
Iteration 95/1000 | Loss: 0.00013911
Iteration 96/1000 | Loss: 0.00013911
Iteration 97/1000 | Loss: 0.00013911
Iteration 98/1000 | Loss: 0.00013911
Iteration 99/1000 | Loss: 0.00013911
Iteration 100/1000 | Loss: 0.00013911
Iteration 101/1000 | Loss: 0.00013910
Iteration 102/1000 | Loss: 0.00013910
Iteration 103/1000 | Loss: 0.00013910
Iteration 104/1000 | Loss: 0.00013910
Iteration 105/1000 | Loss: 0.00013910
Iteration 106/1000 | Loss: 0.00013910
Iteration 107/1000 | Loss: 0.00013910
Iteration 108/1000 | Loss: 0.00013909
Iteration 109/1000 | Loss: 0.00013909
Iteration 110/1000 | Loss: 0.00013909
Iteration 111/1000 | Loss: 0.00013908
Iteration 112/1000 | Loss: 0.00013908
Iteration 113/1000 | Loss: 0.00013908
Iteration 114/1000 | Loss: 0.00013908
Iteration 115/1000 | Loss: 0.00013908
Iteration 116/1000 | Loss: 0.00013908
Iteration 117/1000 | Loss: 0.00013907
Iteration 118/1000 | Loss: 0.00013907
Iteration 119/1000 | Loss: 0.00013907
Iteration 120/1000 | Loss: 0.00013906
Iteration 121/1000 | Loss: 0.00013904
Iteration 122/1000 | Loss: 0.00013904
Iteration 123/1000 | Loss: 0.00013904
Iteration 124/1000 | Loss: 0.00013904
Iteration 125/1000 | Loss: 0.00013904
Iteration 126/1000 | Loss: 0.00013904
Iteration 127/1000 | Loss: 0.00013904
Iteration 128/1000 | Loss: 0.00013903
Iteration 129/1000 | Loss: 0.00013903
Iteration 130/1000 | Loss: 0.00013903
Iteration 131/1000 | Loss: 0.00013903
Iteration 132/1000 | Loss: 0.00013903
Iteration 133/1000 | Loss: 0.00013903
Iteration 134/1000 | Loss: 0.00013903
Iteration 135/1000 | Loss: 0.00013902
Iteration 136/1000 | Loss: 0.00013900
Iteration 137/1000 | Loss: 0.00013899
Iteration 138/1000 | Loss: 0.00013899
Iteration 139/1000 | Loss: 0.00013899
Iteration 140/1000 | Loss: 0.00013899
Iteration 141/1000 | Loss: 0.00013899
Iteration 142/1000 | Loss: 0.00013899
Iteration 143/1000 | Loss: 0.00013899
Iteration 144/1000 | Loss: 0.00013899
Iteration 145/1000 | Loss: 0.00013898
Iteration 146/1000 | Loss: 0.00013896
Iteration 147/1000 | Loss: 0.00013895
Iteration 148/1000 | Loss: 0.00013895
Iteration 149/1000 | Loss: 0.00013895
Iteration 150/1000 | Loss: 0.00013895
Iteration 151/1000 | Loss: 0.00013895
Iteration 152/1000 | Loss: 0.00013895
Iteration 153/1000 | Loss: 0.00013895
Iteration 154/1000 | Loss: 0.00013895
Iteration 155/1000 | Loss: 0.00013894
Iteration 156/1000 | Loss: 0.00013894
Iteration 157/1000 | Loss: 0.00013894
Iteration 158/1000 | Loss: 0.00013894
Iteration 159/1000 | Loss: 0.00013894
Iteration 160/1000 | Loss: 0.00013894
Iteration 161/1000 | Loss: 0.00013893
Iteration 162/1000 | Loss: 0.00013893
Iteration 163/1000 | Loss: 0.00013893
Iteration 164/1000 | Loss: 0.00013893
Iteration 165/1000 | Loss: 0.00013893
Iteration 166/1000 | Loss: 0.00013893
Iteration 167/1000 | Loss: 0.00013893
Iteration 168/1000 | Loss: 0.00013893
Iteration 169/1000 | Loss: 0.00013893
Iteration 170/1000 | Loss: 0.00013893
Iteration 171/1000 | Loss: 0.00013893
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 171. Stopping optimization.
Last 5 losses: [0.00013893135474063456, 0.00013893135474063456, 0.00013893135474063456, 0.00013893135474063456, 0.00013893135474063456]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00013893135474063456

Optimization complete. Final v2v error: 9.408102035522461 mm

Highest mean error: 13.018549919128418 mm for frame 73

Lowest mean error: 7.872458457946777 mm for frame 39

Saving results

Total time: 146.28139901161194
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00949863
Iteration 2/25 | Loss: 0.00180075
Iteration 3/25 | Loss: 0.00166439
Iteration 4/25 | Loss: 0.00164110
Iteration 5/25 | Loss: 0.00163448
Iteration 6/25 | Loss: 0.00163521
Iteration 7/25 | Loss: 0.00163234
Iteration 8/25 | Loss: 0.00163106
Iteration 9/25 | Loss: 0.00162889
Iteration 10/25 | Loss: 0.00162731
Iteration 11/25 | Loss: 0.00162681
Iteration 12/25 | Loss: 0.00162672
Iteration 13/25 | Loss: 0.00162662
Iteration 14/25 | Loss: 0.00162661
Iteration 15/25 | Loss: 0.00162661
Iteration 16/25 | Loss: 0.00162661
Iteration 17/25 | Loss: 0.00162661
Iteration 18/25 | Loss: 0.00162661
Iteration 19/25 | Loss: 0.00162661
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0016266054008156061, 0.0016266054008156061, 0.0016266054008156061, 0.0016266054008156061, 0.0016266054008156061]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016266054008156061

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.33560216
Iteration 2/25 | Loss: 0.00240562
Iteration 3/25 | Loss: 0.00240562
Iteration 4/25 | Loss: 0.00240562
Iteration 5/25 | Loss: 0.00240562
Iteration 6/25 | Loss: 0.00240562
Iteration 7/25 | Loss: 0.00240562
Iteration 8/25 | Loss: 0.00240562
Iteration 9/25 | Loss: 0.00240562
Iteration 10/25 | Loss: 0.00240562
Iteration 11/25 | Loss: 0.00240562
Iteration 12/25 | Loss: 0.00240562
Iteration 13/25 | Loss: 0.00240562
Iteration 14/25 | Loss: 0.00240562
Iteration 15/25 | Loss: 0.00240562
Iteration 16/25 | Loss: 0.00240562
Iteration 17/25 | Loss: 0.00240562
Iteration 18/25 | Loss: 0.00240562
Iteration 19/25 | Loss: 0.00240562
Iteration 20/25 | Loss: 0.00240562
Iteration 21/25 | Loss: 0.00240562
Iteration 22/25 | Loss: 0.00240562
Iteration 23/25 | Loss: 0.00240562
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.002405618317425251, 0.002405618317425251, 0.002405618317425251, 0.002405618317425251, 0.002405618317425251]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002405618317425251

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00240562
Iteration 2/1000 | Loss: 0.00017307
Iteration 3/1000 | Loss: 0.00013615
Iteration 4/1000 | Loss: 0.00011337
Iteration 5/1000 | Loss: 0.00045373
Iteration 6/1000 | Loss: 0.00100273
Iteration 7/1000 | Loss: 0.00010271
Iteration 8/1000 | Loss: 0.00176317
Iteration 9/1000 | Loss: 0.00043491
Iteration 10/1000 | Loss: 0.00008740
Iteration 11/1000 | Loss: 0.00082455
Iteration 12/1000 | Loss: 0.00031364
Iteration 13/1000 | Loss: 0.00006239
Iteration 14/1000 | Loss: 0.00047607
Iteration 15/1000 | Loss: 0.00006344
Iteration 16/1000 | Loss: 0.00005328
Iteration 17/1000 | Loss: 0.00004950
Iteration 18/1000 | Loss: 0.00004685
Iteration 19/1000 | Loss: 0.00031796
Iteration 20/1000 | Loss: 0.00016466
Iteration 21/1000 | Loss: 0.00004564
Iteration 22/1000 | Loss: 0.00093521
Iteration 23/1000 | Loss: 0.00035622
Iteration 24/1000 | Loss: 0.00004787
Iteration 25/1000 | Loss: 0.00028532
Iteration 26/1000 | Loss: 0.00026886
Iteration 27/1000 | Loss: 0.00020904
Iteration 28/1000 | Loss: 0.00004853
Iteration 29/1000 | Loss: 0.00004358
Iteration 30/1000 | Loss: 0.00063128
Iteration 31/1000 | Loss: 0.00014701
Iteration 32/1000 | Loss: 0.00004143
Iteration 33/1000 | Loss: 0.00062607
Iteration 34/1000 | Loss: 0.00007058
Iteration 35/1000 | Loss: 0.00004255
Iteration 36/1000 | Loss: 0.00003864
Iteration 37/1000 | Loss: 0.00003755
Iteration 38/1000 | Loss: 0.00003694
Iteration 39/1000 | Loss: 0.00061233
Iteration 40/1000 | Loss: 0.00006689
Iteration 41/1000 | Loss: 0.00003983
Iteration 42/1000 | Loss: 0.00003553
Iteration 43/1000 | Loss: 0.00003474
Iteration 44/1000 | Loss: 0.00003415
Iteration 45/1000 | Loss: 0.00003359
Iteration 46/1000 | Loss: 0.00003317
Iteration 47/1000 | Loss: 0.00003291
Iteration 48/1000 | Loss: 0.00003281
Iteration 49/1000 | Loss: 0.00003280
Iteration 50/1000 | Loss: 0.00003279
Iteration 51/1000 | Loss: 0.00003266
Iteration 52/1000 | Loss: 0.00003265
Iteration 53/1000 | Loss: 0.00003263
Iteration 54/1000 | Loss: 0.00003259
Iteration 55/1000 | Loss: 0.00003254
Iteration 56/1000 | Loss: 0.00003246
Iteration 57/1000 | Loss: 0.00003246
Iteration 58/1000 | Loss: 0.00003245
Iteration 59/1000 | Loss: 0.00003245
Iteration 60/1000 | Loss: 0.00003243
Iteration 61/1000 | Loss: 0.00003243
Iteration 62/1000 | Loss: 0.00003242
Iteration 63/1000 | Loss: 0.00003242
Iteration 64/1000 | Loss: 0.00003242
Iteration 65/1000 | Loss: 0.00003241
Iteration 66/1000 | Loss: 0.00003241
Iteration 67/1000 | Loss: 0.00003239
Iteration 68/1000 | Loss: 0.00003239
Iteration 69/1000 | Loss: 0.00003238
Iteration 70/1000 | Loss: 0.00003238
Iteration 71/1000 | Loss: 0.00003237
Iteration 72/1000 | Loss: 0.00003236
Iteration 73/1000 | Loss: 0.00003236
Iteration 74/1000 | Loss: 0.00003236
Iteration 75/1000 | Loss: 0.00003235
Iteration 76/1000 | Loss: 0.00003235
Iteration 77/1000 | Loss: 0.00003234
Iteration 78/1000 | Loss: 0.00003233
Iteration 79/1000 | Loss: 0.00003233
Iteration 80/1000 | Loss: 0.00003232
Iteration 81/1000 | Loss: 0.00003232
Iteration 82/1000 | Loss: 0.00003232
Iteration 83/1000 | Loss: 0.00003232
Iteration 84/1000 | Loss: 0.00003232
Iteration 85/1000 | Loss: 0.00003232
Iteration 86/1000 | Loss: 0.00003231
Iteration 87/1000 | Loss: 0.00003231
Iteration 88/1000 | Loss: 0.00003231
Iteration 89/1000 | Loss: 0.00003230
Iteration 90/1000 | Loss: 0.00003230
Iteration 91/1000 | Loss: 0.00003230
Iteration 92/1000 | Loss: 0.00003230
Iteration 93/1000 | Loss: 0.00003230
Iteration 94/1000 | Loss: 0.00003230
Iteration 95/1000 | Loss: 0.00003229
Iteration 96/1000 | Loss: 0.00003228
Iteration 97/1000 | Loss: 0.00003228
Iteration 98/1000 | Loss: 0.00003227
Iteration 99/1000 | Loss: 0.00003227
Iteration 100/1000 | Loss: 0.00003226
Iteration 101/1000 | Loss: 0.00003226
Iteration 102/1000 | Loss: 0.00003225
Iteration 103/1000 | Loss: 0.00003225
Iteration 104/1000 | Loss: 0.00003224
Iteration 105/1000 | Loss: 0.00003224
Iteration 106/1000 | Loss: 0.00003224
Iteration 107/1000 | Loss: 0.00003224
Iteration 108/1000 | Loss: 0.00003223
Iteration 109/1000 | Loss: 0.00003223
Iteration 110/1000 | Loss: 0.00003223
Iteration 111/1000 | Loss: 0.00003223
Iteration 112/1000 | Loss: 0.00003223
Iteration 113/1000 | Loss: 0.00003223
Iteration 114/1000 | Loss: 0.00003222
Iteration 115/1000 | Loss: 0.00003222
Iteration 116/1000 | Loss: 0.00003222
Iteration 117/1000 | Loss: 0.00003222
Iteration 118/1000 | Loss: 0.00003221
Iteration 119/1000 | Loss: 0.00003221
Iteration 120/1000 | Loss: 0.00003221
Iteration 121/1000 | Loss: 0.00003221
Iteration 122/1000 | Loss: 0.00003221
Iteration 123/1000 | Loss: 0.00003221
Iteration 124/1000 | Loss: 0.00003221
Iteration 125/1000 | Loss: 0.00003221
Iteration 126/1000 | Loss: 0.00003221
Iteration 127/1000 | Loss: 0.00003221
Iteration 128/1000 | Loss: 0.00003220
Iteration 129/1000 | Loss: 0.00003220
Iteration 130/1000 | Loss: 0.00003220
Iteration 131/1000 | Loss: 0.00003220
Iteration 132/1000 | Loss: 0.00003220
Iteration 133/1000 | Loss: 0.00003220
Iteration 134/1000 | Loss: 0.00003220
Iteration 135/1000 | Loss: 0.00003220
Iteration 136/1000 | Loss: 0.00003220
Iteration 137/1000 | Loss: 0.00003220
Iteration 138/1000 | Loss: 0.00003220
Iteration 139/1000 | Loss: 0.00003220
Iteration 140/1000 | Loss: 0.00003219
Iteration 141/1000 | Loss: 0.00003219
Iteration 142/1000 | Loss: 0.00003219
Iteration 143/1000 | Loss: 0.00003219
Iteration 144/1000 | Loss: 0.00003219
Iteration 145/1000 | Loss: 0.00003219
Iteration 146/1000 | Loss: 0.00003219
Iteration 147/1000 | Loss: 0.00003219
Iteration 148/1000 | Loss: 0.00003219
Iteration 149/1000 | Loss: 0.00003219
Iteration 150/1000 | Loss: 0.00003219
Iteration 151/1000 | Loss: 0.00003219
Iteration 152/1000 | Loss: 0.00003219
Iteration 153/1000 | Loss: 0.00003219
Iteration 154/1000 | Loss: 0.00003219
Iteration 155/1000 | Loss: 0.00003219
Iteration 156/1000 | Loss: 0.00003219
Iteration 157/1000 | Loss: 0.00003219
Iteration 158/1000 | Loss: 0.00003219
Iteration 159/1000 | Loss: 0.00003219
Iteration 160/1000 | Loss: 0.00003218
Iteration 161/1000 | Loss: 0.00003218
Iteration 162/1000 | Loss: 0.00003218
Iteration 163/1000 | Loss: 0.00003218
Iteration 164/1000 | Loss: 0.00003218
Iteration 165/1000 | Loss: 0.00003218
Iteration 166/1000 | Loss: 0.00003218
Iteration 167/1000 | Loss: 0.00003218
Iteration 168/1000 | Loss: 0.00003218
Iteration 169/1000 | Loss: 0.00003218
Iteration 170/1000 | Loss: 0.00003218
Iteration 171/1000 | Loss: 0.00003218
Iteration 172/1000 | Loss: 0.00003218
Iteration 173/1000 | Loss: 0.00003218
Iteration 174/1000 | Loss: 0.00003218
Iteration 175/1000 | Loss: 0.00003218
Iteration 176/1000 | Loss: 0.00003218
Iteration 177/1000 | Loss: 0.00003218
Iteration 178/1000 | Loss: 0.00003218
Iteration 179/1000 | Loss: 0.00003218
Iteration 180/1000 | Loss: 0.00003217
Iteration 181/1000 | Loss: 0.00003217
Iteration 182/1000 | Loss: 0.00003217
Iteration 183/1000 | Loss: 0.00003217
Iteration 184/1000 | Loss: 0.00003217
Iteration 185/1000 | Loss: 0.00003217
Iteration 186/1000 | Loss: 0.00003217
Iteration 187/1000 | Loss: 0.00003217
Iteration 188/1000 | Loss: 0.00003217
Iteration 189/1000 | Loss: 0.00003217
Iteration 190/1000 | Loss: 0.00003217
Iteration 191/1000 | Loss: 0.00003217
Iteration 192/1000 | Loss: 0.00003217
Iteration 193/1000 | Loss: 0.00003217
Iteration 194/1000 | Loss: 0.00003217
Iteration 195/1000 | Loss: 0.00003217
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 195. Stopping optimization.
Last 5 losses: [3.217334960936569e-05, 3.217334960936569e-05, 3.217334960936569e-05, 3.217334960936569e-05, 3.217334960936569e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.217334960936569e-05

Optimization complete. Final v2v error: 4.782205104827881 mm

Highest mean error: 13.898345947265625 mm for frame 115

Lowest mean error: 4.328703880310059 mm for frame 230

Saving results

Total time: 118.74019837379456
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00489523
Iteration 2/25 | Loss: 0.00173231
Iteration 3/25 | Loss: 0.00158872
Iteration 4/25 | Loss: 0.00156438
Iteration 5/25 | Loss: 0.00155813
Iteration 6/25 | Loss: 0.00155638
Iteration 7/25 | Loss: 0.00155608
Iteration 8/25 | Loss: 0.00155608
Iteration 9/25 | Loss: 0.00155608
Iteration 10/25 | Loss: 0.00155608
Iteration 11/25 | Loss: 0.00155608
Iteration 12/25 | Loss: 0.00155608
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0015560832107439637, 0.0015560832107439637, 0.0015560832107439637, 0.0015560832107439637, 0.0015560832107439637]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015560832107439637

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35816181
Iteration 2/25 | Loss: 0.00144416
Iteration 3/25 | Loss: 0.00144416
Iteration 4/25 | Loss: 0.00144415
Iteration 5/25 | Loss: 0.00144415
Iteration 6/25 | Loss: 0.00144415
Iteration 7/25 | Loss: 0.00144415
Iteration 8/25 | Loss: 0.00144415
Iteration 9/25 | Loss: 0.00144415
Iteration 10/25 | Loss: 0.00144415
Iteration 11/25 | Loss: 0.00144415
Iteration 12/25 | Loss: 0.00144415
Iteration 13/25 | Loss: 0.00144415
Iteration 14/25 | Loss: 0.00144415
Iteration 15/25 | Loss: 0.00144415
Iteration 16/25 | Loss: 0.00144415
Iteration 17/25 | Loss: 0.00144415
Iteration 18/25 | Loss: 0.00144415
Iteration 19/25 | Loss: 0.00144415
Iteration 20/25 | Loss: 0.00144415
Iteration 21/25 | Loss: 0.00144415
Iteration 22/25 | Loss: 0.00144415
Iteration 23/25 | Loss: 0.00144415
Iteration 24/25 | Loss: 0.00144415
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0014441523235291243, 0.0014441523235291243, 0.0014441523235291243, 0.0014441523235291243, 0.0014441523235291243]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014441523235291243

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00144415
Iteration 2/1000 | Loss: 0.00007148
Iteration 3/1000 | Loss: 0.00004760
Iteration 4/1000 | Loss: 0.00003805
Iteration 5/1000 | Loss: 0.00003274
Iteration 6/1000 | Loss: 0.00003010
Iteration 7/1000 | Loss: 0.00002919
Iteration 8/1000 | Loss: 0.00002842
Iteration 9/1000 | Loss: 0.00002796
Iteration 10/1000 | Loss: 0.00002767
Iteration 11/1000 | Loss: 0.00002739
Iteration 12/1000 | Loss: 0.00002711
Iteration 13/1000 | Loss: 0.00002704
Iteration 14/1000 | Loss: 0.00002703
Iteration 15/1000 | Loss: 0.00002700
Iteration 16/1000 | Loss: 0.00002691
Iteration 17/1000 | Loss: 0.00002691
Iteration 18/1000 | Loss: 0.00002690
Iteration 19/1000 | Loss: 0.00002689
Iteration 20/1000 | Loss: 0.00002689
Iteration 21/1000 | Loss: 0.00002686
Iteration 22/1000 | Loss: 0.00002685
Iteration 23/1000 | Loss: 0.00002685
Iteration 24/1000 | Loss: 0.00002685
Iteration 25/1000 | Loss: 0.00002682
Iteration 26/1000 | Loss: 0.00002681
Iteration 27/1000 | Loss: 0.00002681
Iteration 28/1000 | Loss: 0.00002681
Iteration 29/1000 | Loss: 0.00002680
Iteration 30/1000 | Loss: 0.00002680
Iteration 31/1000 | Loss: 0.00002680
Iteration 32/1000 | Loss: 0.00002680
Iteration 33/1000 | Loss: 0.00002680
Iteration 34/1000 | Loss: 0.00002680
Iteration 35/1000 | Loss: 0.00002679
Iteration 36/1000 | Loss: 0.00002679
Iteration 37/1000 | Loss: 0.00002679
Iteration 38/1000 | Loss: 0.00002679
Iteration 39/1000 | Loss: 0.00002679
Iteration 40/1000 | Loss: 0.00002679
Iteration 41/1000 | Loss: 0.00002678
Iteration 42/1000 | Loss: 0.00002678
Iteration 43/1000 | Loss: 0.00002678
Iteration 44/1000 | Loss: 0.00002677
Iteration 45/1000 | Loss: 0.00002677
Iteration 46/1000 | Loss: 0.00002677
Iteration 47/1000 | Loss: 0.00002677
Iteration 48/1000 | Loss: 0.00002677
Iteration 49/1000 | Loss: 0.00002677
Iteration 50/1000 | Loss: 0.00002677
Iteration 51/1000 | Loss: 0.00002677
Iteration 52/1000 | Loss: 0.00002677
Iteration 53/1000 | Loss: 0.00002676
Iteration 54/1000 | Loss: 0.00002676
Iteration 55/1000 | Loss: 0.00002676
Iteration 56/1000 | Loss: 0.00002676
Iteration 57/1000 | Loss: 0.00002676
Iteration 58/1000 | Loss: 0.00002675
Iteration 59/1000 | Loss: 0.00002675
Iteration 60/1000 | Loss: 0.00002675
Iteration 61/1000 | Loss: 0.00002675
Iteration 62/1000 | Loss: 0.00002675
Iteration 63/1000 | Loss: 0.00002675
Iteration 64/1000 | Loss: 0.00002675
Iteration 65/1000 | Loss: 0.00002675
Iteration 66/1000 | Loss: 0.00002675
Iteration 67/1000 | Loss: 0.00002675
Iteration 68/1000 | Loss: 0.00002675
Iteration 69/1000 | Loss: 0.00002674
Iteration 70/1000 | Loss: 0.00002674
Iteration 71/1000 | Loss: 0.00002674
Iteration 72/1000 | Loss: 0.00002674
Iteration 73/1000 | Loss: 0.00002674
Iteration 74/1000 | Loss: 0.00002674
Iteration 75/1000 | Loss: 0.00002674
Iteration 76/1000 | Loss: 0.00002674
Iteration 77/1000 | Loss: 0.00002674
Iteration 78/1000 | Loss: 0.00002674
Iteration 79/1000 | Loss: 0.00002674
Iteration 80/1000 | Loss: 0.00002674
Iteration 81/1000 | Loss: 0.00002673
Iteration 82/1000 | Loss: 0.00002673
Iteration 83/1000 | Loss: 0.00002673
Iteration 84/1000 | Loss: 0.00002673
Iteration 85/1000 | Loss: 0.00002673
Iteration 86/1000 | Loss: 0.00002672
Iteration 87/1000 | Loss: 0.00002672
Iteration 88/1000 | Loss: 0.00002672
Iteration 89/1000 | Loss: 0.00002672
Iteration 90/1000 | Loss: 0.00002672
Iteration 91/1000 | Loss: 0.00002671
Iteration 92/1000 | Loss: 0.00002671
Iteration 93/1000 | Loss: 0.00002671
Iteration 94/1000 | Loss: 0.00002671
Iteration 95/1000 | Loss: 0.00002670
Iteration 96/1000 | Loss: 0.00002670
Iteration 97/1000 | Loss: 0.00002670
Iteration 98/1000 | Loss: 0.00002670
Iteration 99/1000 | Loss: 0.00002670
Iteration 100/1000 | Loss: 0.00002670
Iteration 101/1000 | Loss: 0.00002670
Iteration 102/1000 | Loss: 0.00002670
Iteration 103/1000 | Loss: 0.00002670
Iteration 104/1000 | Loss: 0.00002670
Iteration 105/1000 | Loss: 0.00002670
Iteration 106/1000 | Loss: 0.00002670
Iteration 107/1000 | Loss: 0.00002670
Iteration 108/1000 | Loss: 0.00002670
Iteration 109/1000 | Loss: 0.00002670
Iteration 110/1000 | Loss: 0.00002670
Iteration 111/1000 | Loss: 0.00002670
Iteration 112/1000 | Loss: 0.00002670
Iteration 113/1000 | Loss: 0.00002670
Iteration 114/1000 | Loss: 0.00002670
Iteration 115/1000 | Loss: 0.00002670
Iteration 116/1000 | Loss: 0.00002670
Iteration 117/1000 | Loss: 0.00002670
Iteration 118/1000 | Loss: 0.00002670
Iteration 119/1000 | Loss: 0.00002670
Iteration 120/1000 | Loss: 0.00002670
Iteration 121/1000 | Loss: 0.00002670
Iteration 122/1000 | Loss: 0.00002670
Iteration 123/1000 | Loss: 0.00002670
Iteration 124/1000 | Loss: 0.00002670
Iteration 125/1000 | Loss: 0.00002670
Iteration 126/1000 | Loss: 0.00002670
Iteration 127/1000 | Loss: 0.00002670
Iteration 128/1000 | Loss: 0.00002670
Iteration 129/1000 | Loss: 0.00002670
Iteration 130/1000 | Loss: 0.00002670
Iteration 131/1000 | Loss: 0.00002670
Iteration 132/1000 | Loss: 0.00002670
Iteration 133/1000 | Loss: 0.00002670
Iteration 134/1000 | Loss: 0.00002670
Iteration 135/1000 | Loss: 0.00002670
Iteration 136/1000 | Loss: 0.00002670
Iteration 137/1000 | Loss: 0.00002670
Iteration 138/1000 | Loss: 0.00002670
Iteration 139/1000 | Loss: 0.00002670
Iteration 140/1000 | Loss: 0.00002670
Iteration 141/1000 | Loss: 0.00002670
Iteration 142/1000 | Loss: 0.00002670
Iteration 143/1000 | Loss: 0.00002670
Iteration 144/1000 | Loss: 0.00002670
Iteration 145/1000 | Loss: 0.00002670
Iteration 146/1000 | Loss: 0.00002670
Iteration 147/1000 | Loss: 0.00002670
Iteration 148/1000 | Loss: 0.00002670
Iteration 149/1000 | Loss: 0.00002670
Iteration 150/1000 | Loss: 0.00002670
Iteration 151/1000 | Loss: 0.00002670
Iteration 152/1000 | Loss: 0.00002670
Iteration 153/1000 | Loss: 0.00002670
Iteration 154/1000 | Loss: 0.00002670
Iteration 155/1000 | Loss: 0.00002670
Iteration 156/1000 | Loss: 0.00002670
Iteration 157/1000 | Loss: 0.00002670
Iteration 158/1000 | Loss: 0.00002670
Iteration 159/1000 | Loss: 0.00002670
Iteration 160/1000 | Loss: 0.00002670
Iteration 161/1000 | Loss: 0.00002670
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 161. Stopping optimization.
Last 5 losses: [2.669798777787946e-05, 2.669798777787946e-05, 2.669798777787946e-05, 2.669798777787946e-05, 2.669798777787946e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.669798777787946e-05

Optimization complete. Final v2v error: 4.4752678871154785 mm

Highest mean error: 5.007846832275391 mm for frame 43

Lowest mean error: 4.061023712158203 mm for frame 4

Saving results

Total time: 36.34044432640076
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00523369
Iteration 2/25 | Loss: 0.00178092
Iteration 3/25 | Loss: 0.00163226
Iteration 4/25 | Loss: 0.00161235
Iteration 5/25 | Loss: 0.00160729
Iteration 6/25 | Loss: 0.00160676
Iteration 7/25 | Loss: 0.00160676
Iteration 8/25 | Loss: 0.00160676
Iteration 9/25 | Loss: 0.00160676
Iteration 10/25 | Loss: 0.00160676
Iteration 11/25 | Loss: 0.00160676
Iteration 12/25 | Loss: 0.00160676
Iteration 13/25 | Loss: 0.00160676
Iteration 14/25 | Loss: 0.00160676
Iteration 15/25 | Loss: 0.00160676
Iteration 16/25 | Loss: 0.00160676
Iteration 17/25 | Loss: 0.00160676
Iteration 18/25 | Loss: 0.00160676
Iteration 19/25 | Loss: 0.00160676
Iteration 20/25 | Loss: 0.00160676
Iteration 21/25 | Loss: 0.00160676
Iteration 22/25 | Loss: 0.00160676
Iteration 23/25 | Loss: 0.00160676
Iteration 24/25 | Loss: 0.00160676
Iteration 25/25 | Loss: 0.00160676

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26048124
Iteration 2/25 | Loss: 0.00122338
Iteration 3/25 | Loss: 0.00122338
Iteration 4/25 | Loss: 0.00122338
Iteration 5/25 | Loss: 0.00122338
Iteration 6/25 | Loss: 0.00122338
Iteration 7/25 | Loss: 0.00122338
Iteration 8/25 | Loss: 0.00122338
Iteration 9/25 | Loss: 0.00122337
Iteration 10/25 | Loss: 0.00122337
Iteration 11/25 | Loss: 0.00122337
Iteration 12/25 | Loss: 0.00122337
Iteration 13/25 | Loss: 0.00122337
Iteration 14/25 | Loss: 0.00122337
Iteration 15/25 | Loss: 0.00122337
Iteration 16/25 | Loss: 0.00122337
Iteration 17/25 | Loss: 0.00122337
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012233745073899627, 0.0012233745073899627, 0.0012233745073899627, 0.0012233745073899627, 0.0012233745073899627]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012233745073899627

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00122337
Iteration 2/1000 | Loss: 0.00009603
Iteration 3/1000 | Loss: 0.00006395
Iteration 4/1000 | Loss: 0.00005198
Iteration 5/1000 | Loss: 0.00004333
Iteration 6/1000 | Loss: 0.00004013
Iteration 7/1000 | Loss: 0.00003855
Iteration 8/1000 | Loss: 0.00003745
Iteration 9/1000 | Loss: 0.00003634
Iteration 10/1000 | Loss: 0.00003568
Iteration 11/1000 | Loss: 0.00003513
Iteration 12/1000 | Loss: 0.00003469
Iteration 13/1000 | Loss: 0.00003436
Iteration 14/1000 | Loss: 0.00003404
Iteration 15/1000 | Loss: 0.00003375
Iteration 16/1000 | Loss: 0.00003352
Iteration 17/1000 | Loss: 0.00003334
Iteration 18/1000 | Loss: 0.00003332
Iteration 19/1000 | Loss: 0.00003329
Iteration 20/1000 | Loss: 0.00003322
Iteration 21/1000 | Loss: 0.00003320
Iteration 22/1000 | Loss: 0.00003318
Iteration 23/1000 | Loss: 0.00003318
Iteration 24/1000 | Loss: 0.00003317
Iteration 25/1000 | Loss: 0.00003317
Iteration 26/1000 | Loss: 0.00003309
Iteration 27/1000 | Loss: 0.00003305
Iteration 28/1000 | Loss: 0.00003304
Iteration 29/1000 | Loss: 0.00003304
Iteration 30/1000 | Loss: 0.00003303
Iteration 31/1000 | Loss: 0.00003300
Iteration 32/1000 | Loss: 0.00003297
Iteration 33/1000 | Loss: 0.00003291
Iteration 34/1000 | Loss: 0.00003287
Iteration 35/1000 | Loss: 0.00003280
Iteration 36/1000 | Loss: 0.00003277
Iteration 37/1000 | Loss: 0.00003277
Iteration 38/1000 | Loss: 0.00003277
Iteration 39/1000 | Loss: 0.00003277
Iteration 40/1000 | Loss: 0.00003277
Iteration 41/1000 | Loss: 0.00003277
Iteration 42/1000 | Loss: 0.00003276
Iteration 43/1000 | Loss: 0.00003276
Iteration 44/1000 | Loss: 0.00003275
Iteration 45/1000 | Loss: 0.00003275
Iteration 46/1000 | Loss: 0.00003275
Iteration 47/1000 | Loss: 0.00003275
Iteration 48/1000 | Loss: 0.00003275
Iteration 49/1000 | Loss: 0.00003274
Iteration 50/1000 | Loss: 0.00003274
Iteration 51/1000 | Loss: 0.00003274
Iteration 52/1000 | Loss: 0.00003273
Iteration 53/1000 | Loss: 0.00003273
Iteration 54/1000 | Loss: 0.00003273
Iteration 55/1000 | Loss: 0.00003273
Iteration 56/1000 | Loss: 0.00003273
Iteration 57/1000 | Loss: 0.00003272
Iteration 58/1000 | Loss: 0.00003272
Iteration 59/1000 | Loss: 0.00003272
Iteration 60/1000 | Loss: 0.00003272
Iteration 61/1000 | Loss: 0.00003272
Iteration 62/1000 | Loss: 0.00003272
Iteration 63/1000 | Loss: 0.00003272
Iteration 64/1000 | Loss: 0.00003271
Iteration 65/1000 | Loss: 0.00003271
Iteration 66/1000 | Loss: 0.00003271
Iteration 67/1000 | Loss: 0.00003271
Iteration 68/1000 | Loss: 0.00003271
Iteration 69/1000 | Loss: 0.00003271
Iteration 70/1000 | Loss: 0.00003271
Iteration 71/1000 | Loss: 0.00003271
Iteration 72/1000 | Loss: 0.00003271
Iteration 73/1000 | Loss: 0.00003270
Iteration 74/1000 | Loss: 0.00003270
Iteration 75/1000 | Loss: 0.00003270
Iteration 76/1000 | Loss: 0.00003270
Iteration 77/1000 | Loss: 0.00003270
Iteration 78/1000 | Loss: 0.00003270
Iteration 79/1000 | Loss: 0.00003270
Iteration 80/1000 | Loss: 0.00003270
Iteration 81/1000 | Loss: 0.00003270
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 81. Stopping optimization.
Last 5 losses: [3.2704821933293715e-05, 3.2704821933293715e-05, 3.2704821933293715e-05, 3.2704821933293715e-05, 3.2704821933293715e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.2704821933293715e-05

Optimization complete. Final v2v error: 5.080336093902588 mm

Highest mean error: 5.798460483551025 mm for frame 205

Lowest mean error: 4.634500503540039 mm for frame 266

Saving results

Total time: 50.53057074546814
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00973893
Iteration 2/25 | Loss: 0.00174176
Iteration 3/25 | Loss: 0.00163420
Iteration 4/25 | Loss: 0.00161490
Iteration 5/25 | Loss: 0.00160569
Iteration 6/25 | Loss: 0.00160428
Iteration 7/25 | Loss: 0.00160428
Iteration 8/25 | Loss: 0.00160428
Iteration 9/25 | Loss: 0.00160428
Iteration 10/25 | Loss: 0.00160428
Iteration 11/25 | Loss: 0.00160428
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0016042785719037056, 0.0016042785719037056, 0.0016042785719037056, 0.0016042785719037056, 0.0016042785719037056]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016042785719037056

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.32246351
Iteration 2/25 | Loss: 0.00151034
Iteration 3/25 | Loss: 0.00151034
Iteration 4/25 | Loss: 0.00151034
Iteration 5/25 | Loss: 0.00151034
Iteration 6/25 | Loss: 0.00151034
Iteration 7/25 | Loss: 0.00151034
Iteration 8/25 | Loss: 0.00151034
Iteration 9/25 | Loss: 0.00151034
Iteration 10/25 | Loss: 0.00151034
Iteration 11/25 | Loss: 0.00151034
Iteration 12/25 | Loss: 0.00151034
Iteration 13/25 | Loss: 0.00151034
Iteration 14/25 | Loss: 0.00151034
Iteration 15/25 | Loss: 0.00151034
Iteration 16/25 | Loss: 0.00151034
Iteration 17/25 | Loss: 0.00151034
Iteration 18/25 | Loss: 0.00151034
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0015103372279554605, 0.0015103372279554605, 0.0015103372279554605, 0.0015103372279554605, 0.0015103372279554605]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015103372279554605

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00151034
Iteration 2/1000 | Loss: 0.00006495
Iteration 3/1000 | Loss: 0.00004941
Iteration 4/1000 | Loss: 0.00004219
Iteration 5/1000 | Loss: 0.00004017
Iteration 6/1000 | Loss: 0.00003890
Iteration 7/1000 | Loss: 0.00003818
Iteration 8/1000 | Loss: 0.00003773
Iteration 9/1000 | Loss: 0.00003725
Iteration 10/1000 | Loss: 0.00003684
Iteration 11/1000 | Loss: 0.00003654
Iteration 12/1000 | Loss: 0.00003634
Iteration 13/1000 | Loss: 0.00003629
Iteration 14/1000 | Loss: 0.00003627
Iteration 15/1000 | Loss: 0.00003627
Iteration 16/1000 | Loss: 0.00003626
Iteration 17/1000 | Loss: 0.00003625
Iteration 18/1000 | Loss: 0.00003625
Iteration 19/1000 | Loss: 0.00003624
Iteration 20/1000 | Loss: 0.00003615
Iteration 21/1000 | Loss: 0.00003601
Iteration 22/1000 | Loss: 0.00003601
Iteration 23/1000 | Loss: 0.00003600
Iteration 24/1000 | Loss: 0.00003600
Iteration 25/1000 | Loss: 0.00003599
Iteration 26/1000 | Loss: 0.00003599
Iteration 27/1000 | Loss: 0.00003596
Iteration 28/1000 | Loss: 0.00003596
Iteration 29/1000 | Loss: 0.00003595
Iteration 30/1000 | Loss: 0.00003595
Iteration 31/1000 | Loss: 0.00003594
Iteration 32/1000 | Loss: 0.00003594
Iteration 33/1000 | Loss: 0.00003594
Iteration 34/1000 | Loss: 0.00003594
Iteration 35/1000 | Loss: 0.00003592
Iteration 36/1000 | Loss: 0.00003592
Iteration 37/1000 | Loss: 0.00003592
Iteration 38/1000 | Loss: 0.00003592
Iteration 39/1000 | Loss: 0.00003591
Iteration 40/1000 | Loss: 0.00003590
Iteration 41/1000 | Loss: 0.00003590
Iteration 42/1000 | Loss: 0.00003590
Iteration 43/1000 | Loss: 0.00003590
Iteration 44/1000 | Loss: 0.00003590
Iteration 45/1000 | Loss: 0.00003590
Iteration 46/1000 | Loss: 0.00003590
Iteration 47/1000 | Loss: 0.00003590
Iteration 48/1000 | Loss: 0.00003590
Iteration 49/1000 | Loss: 0.00003590
Iteration 50/1000 | Loss: 0.00003589
Iteration 51/1000 | Loss: 0.00003589
Iteration 52/1000 | Loss: 0.00003589
Iteration 53/1000 | Loss: 0.00003589
Iteration 54/1000 | Loss: 0.00003589
Iteration 55/1000 | Loss: 0.00003589
Iteration 56/1000 | Loss: 0.00003588
Iteration 57/1000 | Loss: 0.00003588
Iteration 58/1000 | Loss: 0.00003588
Iteration 59/1000 | Loss: 0.00003588
Iteration 60/1000 | Loss: 0.00003587
Iteration 61/1000 | Loss: 0.00003587
Iteration 62/1000 | Loss: 0.00003587
Iteration 63/1000 | Loss: 0.00003587
Iteration 64/1000 | Loss: 0.00003587
Iteration 65/1000 | Loss: 0.00003587
Iteration 66/1000 | Loss: 0.00003587
Iteration 67/1000 | Loss: 0.00003587
Iteration 68/1000 | Loss: 0.00003587
Iteration 69/1000 | Loss: 0.00003586
Iteration 70/1000 | Loss: 0.00003586
Iteration 71/1000 | Loss: 0.00003586
Iteration 72/1000 | Loss: 0.00003586
Iteration 73/1000 | Loss: 0.00003586
Iteration 74/1000 | Loss: 0.00003586
Iteration 75/1000 | Loss: 0.00003586
Iteration 76/1000 | Loss: 0.00003586
Iteration 77/1000 | Loss: 0.00003585
Iteration 78/1000 | Loss: 0.00003585
Iteration 79/1000 | Loss: 0.00003585
Iteration 80/1000 | Loss: 0.00003585
Iteration 81/1000 | Loss: 0.00003585
Iteration 82/1000 | Loss: 0.00003584
Iteration 83/1000 | Loss: 0.00003584
Iteration 84/1000 | Loss: 0.00003584
Iteration 85/1000 | Loss: 0.00003584
Iteration 86/1000 | Loss: 0.00003584
Iteration 87/1000 | Loss: 0.00003584
Iteration 88/1000 | Loss: 0.00003584
Iteration 89/1000 | Loss: 0.00003584
Iteration 90/1000 | Loss: 0.00003584
Iteration 91/1000 | Loss: 0.00003584
Iteration 92/1000 | Loss: 0.00003583
Iteration 93/1000 | Loss: 0.00003583
Iteration 94/1000 | Loss: 0.00003583
Iteration 95/1000 | Loss: 0.00003583
Iteration 96/1000 | Loss: 0.00003583
Iteration 97/1000 | Loss: 0.00003583
Iteration 98/1000 | Loss: 0.00003583
Iteration 99/1000 | Loss: 0.00003582
Iteration 100/1000 | Loss: 0.00003582
Iteration 101/1000 | Loss: 0.00003582
Iteration 102/1000 | Loss: 0.00003582
Iteration 103/1000 | Loss: 0.00003582
Iteration 104/1000 | Loss: 0.00003582
Iteration 105/1000 | Loss: 0.00003582
Iteration 106/1000 | Loss: 0.00003581
Iteration 107/1000 | Loss: 0.00003581
Iteration 108/1000 | Loss: 0.00003581
Iteration 109/1000 | Loss: 0.00003581
Iteration 110/1000 | Loss: 0.00003581
Iteration 111/1000 | Loss: 0.00003581
Iteration 112/1000 | Loss: 0.00003581
Iteration 113/1000 | Loss: 0.00003581
Iteration 114/1000 | Loss: 0.00003581
Iteration 115/1000 | Loss: 0.00003581
Iteration 116/1000 | Loss: 0.00003581
Iteration 117/1000 | Loss: 0.00003581
Iteration 118/1000 | Loss: 0.00003581
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [3.581157579901628e-05, 3.581157579901628e-05, 3.581157579901628e-05, 3.581157579901628e-05, 3.581157579901628e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.581157579901628e-05

Optimization complete. Final v2v error: 5.286593914031982 mm

Highest mean error: 5.57258939743042 mm for frame 133

Lowest mean error: 5.0811662673950195 mm for frame 22

Saving results

Total time: 37.28333234786987
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01158382
Iteration 2/25 | Loss: 0.00226830
Iteration 3/25 | Loss: 0.00176501
Iteration 4/25 | Loss: 0.00167969
Iteration 5/25 | Loss: 0.00166881
Iteration 6/25 | Loss: 0.00166077
Iteration 7/25 | Loss: 0.00165822
Iteration 8/25 | Loss: 0.00165721
Iteration 9/25 | Loss: 0.00165716
Iteration 10/25 | Loss: 0.00165716
Iteration 11/25 | Loss: 0.00165716
Iteration 12/25 | Loss: 0.00165716
Iteration 13/25 | Loss: 0.00165716
Iteration 14/25 | Loss: 0.00165716
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0016571579035371542, 0.0016571579035371542, 0.0016571579035371542, 0.0016571579035371542, 0.0016571579035371542]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016571579035371542

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29315698
Iteration 2/25 | Loss: 0.00139667
Iteration 3/25 | Loss: 0.00139667
Iteration 4/25 | Loss: 0.00139667
Iteration 5/25 | Loss: 0.00139667
Iteration 6/25 | Loss: 0.00139667
Iteration 7/25 | Loss: 0.00139667
Iteration 8/25 | Loss: 0.00139667
Iteration 9/25 | Loss: 0.00139667
Iteration 10/25 | Loss: 0.00139667
Iteration 11/25 | Loss: 0.00139667
Iteration 12/25 | Loss: 0.00139667
Iteration 13/25 | Loss: 0.00139667
Iteration 14/25 | Loss: 0.00139667
Iteration 15/25 | Loss: 0.00139667
Iteration 16/25 | Loss: 0.00139667
Iteration 17/25 | Loss: 0.00139667
Iteration 18/25 | Loss: 0.00139667
Iteration 19/25 | Loss: 0.00139667
Iteration 20/25 | Loss: 0.00139667
Iteration 21/25 | Loss: 0.00139667
Iteration 22/25 | Loss: 0.00139667
Iteration 23/25 | Loss: 0.00139667
Iteration 24/25 | Loss: 0.00139667
Iteration 25/25 | Loss: 0.00139667

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00139667
Iteration 2/1000 | Loss: 0.00007065
Iteration 3/1000 | Loss: 0.00005158
Iteration 4/1000 | Loss: 0.00004278
Iteration 5/1000 | Loss: 0.00004040
Iteration 6/1000 | Loss: 0.00003968
Iteration 7/1000 | Loss: 0.00003880
Iteration 8/1000 | Loss: 0.00003826
Iteration 9/1000 | Loss: 0.00003792
Iteration 10/1000 | Loss: 0.00003762
Iteration 11/1000 | Loss: 0.00003745
Iteration 12/1000 | Loss: 0.00003745
Iteration 13/1000 | Loss: 0.00003740
Iteration 14/1000 | Loss: 0.00003735
Iteration 15/1000 | Loss: 0.00003729
Iteration 16/1000 | Loss: 0.00003725
Iteration 17/1000 | Loss: 0.00003723
Iteration 18/1000 | Loss: 0.00003722
Iteration 19/1000 | Loss: 0.00003721
Iteration 20/1000 | Loss: 0.00003721
Iteration 21/1000 | Loss: 0.00003720
Iteration 22/1000 | Loss: 0.00003720
Iteration 23/1000 | Loss: 0.00003720
Iteration 24/1000 | Loss: 0.00003719
Iteration 25/1000 | Loss: 0.00003719
Iteration 26/1000 | Loss: 0.00003719
Iteration 27/1000 | Loss: 0.00003719
Iteration 28/1000 | Loss: 0.00003719
Iteration 29/1000 | Loss: 0.00003718
Iteration 30/1000 | Loss: 0.00003718
Iteration 31/1000 | Loss: 0.00003718
Iteration 32/1000 | Loss: 0.00003718
Iteration 33/1000 | Loss: 0.00003718
Iteration 34/1000 | Loss: 0.00003717
Iteration 35/1000 | Loss: 0.00003717
Iteration 36/1000 | Loss: 0.00003717
Iteration 37/1000 | Loss: 0.00003717
Iteration 38/1000 | Loss: 0.00003717
Iteration 39/1000 | Loss: 0.00003717
Iteration 40/1000 | Loss: 0.00003716
Iteration 41/1000 | Loss: 0.00003716
Iteration 42/1000 | Loss: 0.00003716
Iteration 43/1000 | Loss: 0.00003716
Iteration 44/1000 | Loss: 0.00003715
Iteration 45/1000 | Loss: 0.00003715
Iteration 46/1000 | Loss: 0.00003715
Iteration 47/1000 | Loss: 0.00003715
Iteration 48/1000 | Loss: 0.00003715
Iteration 49/1000 | Loss: 0.00003714
Iteration 50/1000 | Loss: 0.00003714
Iteration 51/1000 | Loss: 0.00003714
Iteration 52/1000 | Loss: 0.00003714
Iteration 53/1000 | Loss: 0.00003714
Iteration 54/1000 | Loss: 0.00003714
Iteration 55/1000 | Loss: 0.00003714
Iteration 56/1000 | Loss: 0.00003714
Iteration 57/1000 | Loss: 0.00003714
Iteration 58/1000 | Loss: 0.00003714
Iteration 59/1000 | Loss: 0.00003714
Iteration 60/1000 | Loss: 0.00003714
Iteration 61/1000 | Loss: 0.00003714
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 61. Stopping optimization.
Last 5 losses: [3.713573460117914e-05, 3.713573460117914e-05, 3.713573460117914e-05, 3.713573460117914e-05, 3.713573460117914e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.713573460117914e-05

Optimization complete. Final v2v error: 5.226901531219482 mm

Highest mean error: 5.480853080749512 mm for frame 6

Lowest mean error: 4.999114036560059 mm for frame 165

Saving results

Total time: 37.74241662025452
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_47_us_1850/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_47_us_1850/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00621866
Iteration 2/25 | Loss: 0.00220946
Iteration 3/25 | Loss: 0.00166517
Iteration 4/25 | Loss: 0.00161974
Iteration 5/25 | Loss: 0.00161101
Iteration 6/25 | Loss: 0.00160740
Iteration 7/25 | Loss: 0.00160670
Iteration 8/25 | Loss: 0.00160670
Iteration 9/25 | Loss: 0.00160670
Iteration 10/25 | Loss: 0.00160670
Iteration 11/25 | Loss: 0.00160670
Iteration 12/25 | Loss: 0.00160670
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0016066980315372348, 0.0016066980315372348, 0.0016066980315372348, 0.0016066980315372348, 0.0016066980315372348]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016066980315372348

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.00716627
Iteration 2/25 | Loss: 0.00110818
Iteration 3/25 | Loss: 0.00110817
Iteration 4/25 | Loss: 0.00110817
Iteration 5/25 | Loss: 0.00110817
Iteration 6/25 | Loss: 0.00110817
Iteration 7/25 | Loss: 0.00110817
Iteration 8/25 | Loss: 0.00110817
Iteration 9/25 | Loss: 0.00110817
Iteration 10/25 | Loss: 0.00110817
Iteration 11/25 | Loss: 0.00110817
Iteration 12/25 | Loss: 0.00110817
Iteration 13/25 | Loss: 0.00110817
Iteration 14/25 | Loss: 0.00110817
Iteration 15/25 | Loss: 0.00110817
Iteration 16/25 | Loss: 0.00110817
Iteration 17/25 | Loss: 0.00110817
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0011081688571721315, 0.0011081688571721315, 0.0011081688571721315, 0.0011081688571721315, 0.0011081688571721315]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011081688571721315

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00110817
Iteration 2/1000 | Loss: 0.00010001
Iteration 3/1000 | Loss: 0.00007473
Iteration 4/1000 | Loss: 0.00006438
Iteration 5/1000 | Loss: 0.00005796
Iteration 6/1000 | Loss: 0.00005520
Iteration 7/1000 | Loss: 0.00005348
Iteration 8/1000 | Loss: 0.00005235
Iteration 9/1000 | Loss: 0.00005155
Iteration 10/1000 | Loss: 0.00005091
Iteration 11/1000 | Loss: 0.00005034
Iteration 12/1000 | Loss: 0.00004995
Iteration 13/1000 | Loss: 0.00004965
Iteration 14/1000 | Loss: 0.00004949
Iteration 15/1000 | Loss: 0.00004942
Iteration 16/1000 | Loss: 0.00004940
Iteration 17/1000 | Loss: 0.00004932
Iteration 18/1000 | Loss: 0.00004924
Iteration 19/1000 | Loss: 0.00004918
Iteration 20/1000 | Loss: 0.00004914
Iteration 21/1000 | Loss: 0.00004914
Iteration 22/1000 | Loss: 0.00004912
Iteration 23/1000 | Loss: 0.00004910
Iteration 24/1000 | Loss: 0.00004910
Iteration 25/1000 | Loss: 0.00004908
Iteration 26/1000 | Loss: 0.00004905
Iteration 27/1000 | Loss: 0.00004905
Iteration 28/1000 | Loss: 0.00004905
Iteration 29/1000 | Loss: 0.00004905
Iteration 30/1000 | Loss: 0.00004903
Iteration 31/1000 | Loss: 0.00004903
Iteration 32/1000 | Loss: 0.00004903
Iteration 33/1000 | Loss: 0.00004903
Iteration 34/1000 | Loss: 0.00004903
Iteration 35/1000 | Loss: 0.00004902
Iteration 36/1000 | Loss: 0.00004902
Iteration 37/1000 | Loss: 0.00004902
Iteration 38/1000 | Loss: 0.00004901
Iteration 39/1000 | Loss: 0.00004901
Iteration 40/1000 | Loss: 0.00004900
Iteration 41/1000 | Loss: 0.00004900
Iteration 42/1000 | Loss: 0.00004900
Iteration 43/1000 | Loss: 0.00004899
Iteration 44/1000 | Loss: 0.00004899
Iteration 45/1000 | Loss: 0.00004899
Iteration 46/1000 | Loss: 0.00004898
Iteration 47/1000 | Loss: 0.00004898
Iteration 48/1000 | Loss: 0.00004898
Iteration 49/1000 | Loss: 0.00004898
Iteration 50/1000 | Loss: 0.00004898
Iteration 51/1000 | Loss: 0.00004897
Iteration 52/1000 | Loss: 0.00004896
Iteration 53/1000 | Loss: 0.00004895
Iteration 54/1000 | Loss: 0.00004895
Iteration 55/1000 | Loss: 0.00004894
Iteration 56/1000 | Loss: 0.00004894
Iteration 57/1000 | Loss: 0.00004893
Iteration 58/1000 | Loss: 0.00004893
Iteration 59/1000 | Loss: 0.00004892
Iteration 60/1000 | Loss: 0.00004892
Iteration 61/1000 | Loss: 0.00004891
Iteration 62/1000 | Loss: 0.00004891
Iteration 63/1000 | Loss: 0.00004891
Iteration 64/1000 | Loss: 0.00004890
Iteration 65/1000 | Loss: 0.00004890
Iteration 66/1000 | Loss: 0.00004890
Iteration 67/1000 | Loss: 0.00004890
Iteration 68/1000 | Loss: 0.00004889
Iteration 69/1000 | Loss: 0.00004889
Iteration 70/1000 | Loss: 0.00004889
Iteration 71/1000 | Loss: 0.00004889
Iteration 72/1000 | Loss: 0.00004889
Iteration 73/1000 | Loss: 0.00004889
Iteration 74/1000 | Loss: 0.00004888
Iteration 75/1000 | Loss: 0.00004888
Iteration 76/1000 | Loss: 0.00004888
Iteration 77/1000 | Loss: 0.00004888
Iteration 78/1000 | Loss: 0.00004888
Iteration 79/1000 | Loss: 0.00004888
Iteration 80/1000 | Loss: 0.00004888
Iteration 81/1000 | Loss: 0.00004887
Iteration 82/1000 | Loss: 0.00004887
Iteration 83/1000 | Loss: 0.00004887
Iteration 84/1000 | Loss: 0.00004887
Iteration 85/1000 | Loss: 0.00004887
Iteration 86/1000 | Loss: 0.00004886
Iteration 87/1000 | Loss: 0.00004886
Iteration 88/1000 | Loss: 0.00004885
Iteration 89/1000 | Loss: 0.00004885
Iteration 90/1000 | Loss: 0.00004885
Iteration 91/1000 | Loss: 0.00004885
Iteration 92/1000 | Loss: 0.00004885
Iteration 93/1000 | Loss: 0.00004885
Iteration 94/1000 | Loss: 0.00004885
Iteration 95/1000 | Loss: 0.00004885
Iteration 96/1000 | Loss: 0.00004885
Iteration 97/1000 | Loss: 0.00004885
Iteration 98/1000 | Loss: 0.00004885
Iteration 99/1000 | Loss: 0.00004885
Iteration 100/1000 | Loss: 0.00004884
Iteration 101/1000 | Loss: 0.00004884
Iteration 102/1000 | Loss: 0.00004884
Iteration 103/1000 | Loss: 0.00004884
Iteration 104/1000 | Loss: 0.00004884
Iteration 105/1000 | Loss: 0.00004884
Iteration 106/1000 | Loss: 0.00004883
Iteration 107/1000 | Loss: 0.00004883
Iteration 108/1000 | Loss: 0.00004883
Iteration 109/1000 | Loss: 0.00004883
Iteration 110/1000 | Loss: 0.00004883
Iteration 111/1000 | Loss: 0.00004883
Iteration 112/1000 | Loss: 0.00004882
Iteration 113/1000 | Loss: 0.00004882
Iteration 114/1000 | Loss: 0.00004882
Iteration 115/1000 | Loss: 0.00004882
Iteration 116/1000 | Loss: 0.00004882
Iteration 117/1000 | Loss: 0.00004882
Iteration 118/1000 | Loss: 0.00004881
Iteration 119/1000 | Loss: 0.00004881
Iteration 120/1000 | Loss: 0.00004881
Iteration 121/1000 | Loss: 0.00004881
Iteration 122/1000 | Loss: 0.00004881
Iteration 123/1000 | Loss: 0.00004881
Iteration 124/1000 | Loss: 0.00004881
Iteration 125/1000 | Loss: 0.00004881
Iteration 126/1000 | Loss: 0.00004881
Iteration 127/1000 | Loss: 0.00004881
Iteration 128/1000 | Loss: 0.00004881
Iteration 129/1000 | Loss: 0.00004881
Iteration 130/1000 | Loss: 0.00004881
Iteration 131/1000 | Loss: 0.00004881
Iteration 132/1000 | Loss: 0.00004881
Iteration 133/1000 | Loss: 0.00004881
Iteration 134/1000 | Loss: 0.00004881
Iteration 135/1000 | Loss: 0.00004881
Iteration 136/1000 | Loss: 0.00004881
Iteration 137/1000 | Loss: 0.00004881
Iteration 138/1000 | Loss: 0.00004881
Iteration 139/1000 | Loss: 0.00004881
Iteration 140/1000 | Loss: 0.00004881
Iteration 141/1000 | Loss: 0.00004881
Iteration 142/1000 | Loss: 0.00004881
Iteration 143/1000 | Loss: 0.00004881
Iteration 144/1000 | Loss: 0.00004881
Iteration 145/1000 | Loss: 0.00004881
Iteration 146/1000 | Loss: 0.00004881
Iteration 147/1000 | Loss: 0.00004881
Iteration 148/1000 | Loss: 0.00004881
Iteration 149/1000 | Loss: 0.00004881
Iteration 150/1000 | Loss: 0.00004880
Iteration 151/1000 | Loss: 0.00004880
Iteration 152/1000 | Loss: 0.00004880
Iteration 153/1000 | Loss: 0.00004880
Iteration 154/1000 | Loss: 0.00004880
Iteration 155/1000 | Loss: 0.00004880
Iteration 156/1000 | Loss: 0.00004880
Iteration 157/1000 | Loss: 0.00004880
Iteration 158/1000 | Loss: 0.00004880
Iteration 159/1000 | Loss: 0.00004880
Iteration 160/1000 | Loss: 0.00004880
Iteration 161/1000 | Loss: 0.00004880
Iteration 162/1000 | Loss: 0.00004880
Iteration 163/1000 | Loss: 0.00004880
Iteration 164/1000 | Loss: 0.00004880
Iteration 165/1000 | Loss: 0.00004880
Iteration 166/1000 | Loss: 0.00004880
Iteration 167/1000 | Loss: 0.00004880
Iteration 168/1000 | Loss: 0.00004880
Iteration 169/1000 | Loss: 0.00004880
Iteration 170/1000 | Loss: 0.00004880
Iteration 171/1000 | Loss: 0.00004880
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 171. Stopping optimization.
Last 5 losses: [4.880496999248862e-05, 4.880496999248862e-05, 4.880496999248862e-05, 4.880496999248862e-05, 4.880496999248862e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.880496999248862e-05

Optimization complete. Final v2v error: 5.767557144165039 mm

Highest mean error: 7.002590656280518 mm for frame 75

Lowest mean error: 4.839820384979248 mm for frame 167

Saving results

Total time: 46.170852184295654

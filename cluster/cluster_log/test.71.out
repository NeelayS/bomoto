Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=71, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 3976-4031
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00460233
Iteration 2/25 | Loss: 0.00088028
Iteration 3/25 | Loss: 0.00074692
Iteration 4/25 | Loss: 0.00072388
Iteration 5/25 | Loss: 0.00071877
Iteration 6/25 | Loss: 0.00071695
Iteration 7/25 | Loss: 0.00071622
Iteration 8/25 | Loss: 0.00071622
Iteration 9/25 | Loss: 0.00071622
Iteration 10/25 | Loss: 0.00071622
Iteration 11/25 | Loss: 0.00071622
Iteration 12/25 | Loss: 0.00071622
Iteration 13/25 | Loss: 0.00071622
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007162170368246734, 0.0007162170368246734, 0.0007162170368246734, 0.0007162170368246734, 0.0007162170368246734]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007162170368246734

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47688472
Iteration 2/25 | Loss: 0.00027363
Iteration 3/25 | Loss: 0.00027362
Iteration 4/25 | Loss: 0.00027362
Iteration 5/25 | Loss: 0.00027362
Iteration 6/25 | Loss: 0.00027362
Iteration 7/25 | Loss: 0.00027362
Iteration 8/25 | Loss: 0.00027362
Iteration 9/25 | Loss: 0.00027362
Iteration 10/25 | Loss: 0.00027362
Iteration 11/25 | Loss: 0.00027362
Iteration 12/25 | Loss: 0.00027362
Iteration 13/25 | Loss: 0.00027362
Iteration 14/25 | Loss: 0.00027362
Iteration 15/25 | Loss: 0.00027362
Iteration 16/25 | Loss: 0.00027362
Iteration 17/25 | Loss: 0.00027362
Iteration 18/25 | Loss: 0.00027362
Iteration 19/25 | Loss: 0.00027362
Iteration 20/25 | Loss: 0.00027362
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0002736167807597667, 0.0002736167807597667, 0.0002736167807597667, 0.0002736167807597667, 0.0002736167807597667]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002736167807597667

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00027362
Iteration 2/1000 | Loss: 0.00002650
Iteration 3/1000 | Loss: 0.00001530
Iteration 4/1000 | Loss: 0.00001293
Iteration 5/1000 | Loss: 0.00001203
Iteration 6/1000 | Loss: 0.00001157
Iteration 7/1000 | Loss: 0.00001130
Iteration 8/1000 | Loss: 0.00001122
Iteration 9/1000 | Loss: 0.00001115
Iteration 10/1000 | Loss: 0.00001110
Iteration 11/1000 | Loss: 0.00001107
Iteration 12/1000 | Loss: 0.00001107
Iteration 13/1000 | Loss: 0.00001107
Iteration 14/1000 | Loss: 0.00001106
Iteration 15/1000 | Loss: 0.00001105
Iteration 16/1000 | Loss: 0.00001104
Iteration 17/1000 | Loss: 0.00001103
Iteration 18/1000 | Loss: 0.00001102
Iteration 19/1000 | Loss: 0.00001102
Iteration 20/1000 | Loss: 0.00001102
Iteration 21/1000 | Loss: 0.00001101
Iteration 22/1000 | Loss: 0.00001101
Iteration 23/1000 | Loss: 0.00001100
Iteration 24/1000 | Loss: 0.00001100
Iteration 25/1000 | Loss: 0.00001099
Iteration 26/1000 | Loss: 0.00001098
Iteration 27/1000 | Loss: 0.00001098
Iteration 28/1000 | Loss: 0.00001098
Iteration 29/1000 | Loss: 0.00001098
Iteration 30/1000 | Loss: 0.00001097
Iteration 31/1000 | Loss: 0.00001096
Iteration 32/1000 | Loss: 0.00001096
Iteration 33/1000 | Loss: 0.00001095
Iteration 34/1000 | Loss: 0.00001094
Iteration 35/1000 | Loss: 0.00001094
Iteration 36/1000 | Loss: 0.00001093
Iteration 37/1000 | Loss: 0.00001093
Iteration 38/1000 | Loss: 0.00001093
Iteration 39/1000 | Loss: 0.00001091
Iteration 40/1000 | Loss: 0.00001091
Iteration 41/1000 | Loss: 0.00001091
Iteration 42/1000 | Loss: 0.00001090
Iteration 43/1000 | Loss: 0.00001090
Iteration 44/1000 | Loss: 0.00001089
Iteration 45/1000 | Loss: 0.00001088
Iteration 46/1000 | Loss: 0.00001088
Iteration 47/1000 | Loss: 0.00001087
Iteration 48/1000 | Loss: 0.00001087
Iteration 49/1000 | Loss: 0.00001087
Iteration 50/1000 | Loss: 0.00001087
Iteration 51/1000 | Loss: 0.00001087
Iteration 52/1000 | Loss: 0.00001087
Iteration 53/1000 | Loss: 0.00001086
Iteration 54/1000 | Loss: 0.00001086
Iteration 55/1000 | Loss: 0.00001086
Iteration 56/1000 | Loss: 0.00001086
Iteration 57/1000 | Loss: 0.00001086
Iteration 58/1000 | Loss: 0.00001085
Iteration 59/1000 | Loss: 0.00001085
Iteration 60/1000 | Loss: 0.00001084
Iteration 61/1000 | Loss: 0.00001084
Iteration 62/1000 | Loss: 0.00001083
Iteration 63/1000 | Loss: 0.00001083
Iteration 64/1000 | Loss: 0.00001083
Iteration 65/1000 | Loss: 0.00001083
Iteration 66/1000 | Loss: 0.00001083
Iteration 67/1000 | Loss: 0.00001083
Iteration 68/1000 | Loss: 0.00001082
Iteration 69/1000 | Loss: 0.00001082
Iteration 70/1000 | Loss: 0.00001082
Iteration 71/1000 | Loss: 0.00001081
Iteration 72/1000 | Loss: 0.00001081
Iteration 73/1000 | Loss: 0.00001081
Iteration 74/1000 | Loss: 0.00001081
Iteration 75/1000 | Loss: 0.00001080
Iteration 76/1000 | Loss: 0.00001080
Iteration 77/1000 | Loss: 0.00001080
Iteration 78/1000 | Loss: 0.00001079
Iteration 79/1000 | Loss: 0.00001079
Iteration 80/1000 | Loss: 0.00001079
Iteration 81/1000 | Loss: 0.00001079
Iteration 82/1000 | Loss: 0.00001079
Iteration 83/1000 | Loss: 0.00001079
Iteration 84/1000 | Loss: 0.00001079
Iteration 85/1000 | Loss: 0.00001079
Iteration 86/1000 | Loss: 0.00001078
Iteration 87/1000 | Loss: 0.00001078
Iteration 88/1000 | Loss: 0.00001078
Iteration 89/1000 | Loss: 0.00001078
Iteration 90/1000 | Loss: 0.00001077
Iteration 91/1000 | Loss: 0.00001077
Iteration 92/1000 | Loss: 0.00001077
Iteration 93/1000 | Loss: 0.00001077
Iteration 94/1000 | Loss: 0.00001077
Iteration 95/1000 | Loss: 0.00001077
Iteration 96/1000 | Loss: 0.00001077
Iteration 97/1000 | Loss: 0.00001077
Iteration 98/1000 | Loss: 0.00001076
Iteration 99/1000 | Loss: 0.00001076
Iteration 100/1000 | Loss: 0.00001076
Iteration 101/1000 | Loss: 0.00001076
Iteration 102/1000 | Loss: 0.00001076
Iteration 103/1000 | Loss: 0.00001076
Iteration 104/1000 | Loss: 0.00001076
Iteration 105/1000 | Loss: 0.00001076
Iteration 106/1000 | Loss: 0.00001075
Iteration 107/1000 | Loss: 0.00001075
Iteration 108/1000 | Loss: 0.00001075
Iteration 109/1000 | Loss: 0.00001075
Iteration 110/1000 | Loss: 0.00001075
Iteration 111/1000 | Loss: 0.00001075
Iteration 112/1000 | Loss: 0.00001074
Iteration 113/1000 | Loss: 0.00001074
Iteration 114/1000 | Loss: 0.00001074
Iteration 115/1000 | Loss: 0.00001074
Iteration 116/1000 | Loss: 0.00001074
Iteration 117/1000 | Loss: 0.00001074
Iteration 118/1000 | Loss: 0.00001074
Iteration 119/1000 | Loss: 0.00001074
Iteration 120/1000 | Loss: 0.00001074
Iteration 121/1000 | Loss: 0.00001074
Iteration 122/1000 | Loss: 0.00001074
Iteration 123/1000 | Loss: 0.00001074
Iteration 124/1000 | Loss: 0.00001073
Iteration 125/1000 | Loss: 0.00001073
Iteration 126/1000 | Loss: 0.00001073
Iteration 127/1000 | Loss: 0.00001073
Iteration 128/1000 | Loss: 0.00001073
Iteration 129/1000 | Loss: 0.00001073
Iteration 130/1000 | Loss: 0.00001073
Iteration 131/1000 | Loss: 0.00001073
Iteration 132/1000 | Loss: 0.00001073
Iteration 133/1000 | Loss: 0.00001073
Iteration 134/1000 | Loss: 0.00001073
Iteration 135/1000 | Loss: 0.00001073
Iteration 136/1000 | Loss: 0.00001073
Iteration 137/1000 | Loss: 0.00001073
Iteration 138/1000 | Loss: 0.00001073
Iteration 139/1000 | Loss: 0.00001073
Iteration 140/1000 | Loss: 0.00001073
Iteration 141/1000 | Loss: 0.00001073
Iteration 142/1000 | Loss: 0.00001073
Iteration 143/1000 | Loss: 0.00001073
Iteration 144/1000 | Loss: 0.00001073
Iteration 145/1000 | Loss: 0.00001073
Iteration 146/1000 | Loss: 0.00001073
Iteration 147/1000 | Loss: 0.00001073
Iteration 148/1000 | Loss: 0.00001073
Iteration 149/1000 | Loss: 0.00001073
Iteration 150/1000 | Loss: 0.00001073
Iteration 151/1000 | Loss: 0.00001073
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [1.0726097571023274e-05, 1.0726097571023274e-05, 1.0726097571023274e-05, 1.0726097571023274e-05, 1.0726097571023274e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0726097571023274e-05

Optimization complete. Final v2v error: 2.6781833171844482 mm

Highest mean error: 3.217679023742676 mm for frame 59

Lowest mean error: 2.4293482303619385 mm for frame 101

Saving results

Total time: 33.83572602272034
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00884829
Iteration 2/25 | Loss: 0.00243557
Iteration 3/25 | Loss: 0.00149700
Iteration 4/25 | Loss: 0.00118900
Iteration 5/25 | Loss: 0.00113452
Iteration 6/25 | Loss: 0.00106697
Iteration 7/25 | Loss: 0.00102179
Iteration 8/25 | Loss: 0.00093943
Iteration 9/25 | Loss: 0.00089285
Iteration 10/25 | Loss: 0.00087064
Iteration 11/25 | Loss: 0.00085602
Iteration 12/25 | Loss: 0.00084499
Iteration 13/25 | Loss: 0.00083933
Iteration 14/25 | Loss: 0.00083770
Iteration 15/25 | Loss: 0.00083679
Iteration 16/25 | Loss: 0.00083490
Iteration 17/25 | Loss: 0.00083405
Iteration 18/25 | Loss: 0.00083482
Iteration 19/25 | Loss: 0.00083254
Iteration 20/25 | Loss: 0.00083286
Iteration 21/25 | Loss: 0.00083074
Iteration 22/25 | Loss: 0.00083032
Iteration 23/25 | Loss: 0.00083018
Iteration 24/25 | Loss: 0.00083013
Iteration 25/25 | Loss: 0.00083013

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.04628444
Iteration 2/25 | Loss: 0.00040201
Iteration 3/25 | Loss: 0.00040201
Iteration 4/25 | Loss: 0.00040201
Iteration 5/25 | Loss: 0.00040201
Iteration 6/25 | Loss: 0.00040201
Iteration 7/25 | Loss: 0.00040201
Iteration 8/25 | Loss: 0.00040200
Iteration 9/25 | Loss: 0.00040200
Iteration 10/25 | Loss: 0.00040200
Iteration 11/25 | Loss: 0.00040200
Iteration 12/25 | Loss: 0.00040200
Iteration 13/25 | Loss: 0.00040200
Iteration 14/25 | Loss: 0.00040200
Iteration 15/25 | Loss: 0.00040200
Iteration 16/25 | Loss: 0.00040200
Iteration 17/25 | Loss: 0.00040200
Iteration 18/25 | Loss: 0.00040200
Iteration 19/25 | Loss: 0.00040200
Iteration 20/25 | Loss: 0.00040200
Iteration 21/25 | Loss: 0.00040200
Iteration 22/25 | Loss: 0.00040200
Iteration 23/25 | Loss: 0.00040200
Iteration 24/25 | Loss: 0.00040200
Iteration 25/25 | Loss: 0.00040200

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040200
Iteration 2/1000 | Loss: 0.00003210
Iteration 3/1000 | Loss: 0.00002332
Iteration 4/1000 | Loss: 0.00002136
Iteration 5/1000 | Loss: 0.00002058
Iteration 6/1000 | Loss: 0.00002009
Iteration 7/1000 | Loss: 0.00001976
Iteration 8/1000 | Loss: 0.00001947
Iteration 9/1000 | Loss: 0.00001934
Iteration 10/1000 | Loss: 0.00001921
Iteration 11/1000 | Loss: 0.00001919
Iteration 12/1000 | Loss: 0.00001918
Iteration 13/1000 | Loss: 0.00001915
Iteration 14/1000 | Loss: 0.00001911
Iteration 15/1000 | Loss: 0.00001907
Iteration 16/1000 | Loss: 0.00001907
Iteration 17/1000 | Loss: 0.00001906
Iteration 18/1000 | Loss: 0.00001899
Iteration 19/1000 | Loss: 0.00001896
Iteration 20/1000 | Loss: 0.00001895
Iteration 21/1000 | Loss: 0.00001894
Iteration 22/1000 | Loss: 0.00001894
Iteration 23/1000 | Loss: 0.00001890
Iteration 24/1000 | Loss: 0.00001889
Iteration 25/1000 | Loss: 0.00001886
Iteration 26/1000 | Loss: 0.00001885
Iteration 27/1000 | Loss: 0.00001885
Iteration 28/1000 | Loss: 0.00001884
Iteration 29/1000 | Loss: 0.00001884
Iteration 30/1000 | Loss: 0.00001884
Iteration 31/1000 | Loss: 0.00001883
Iteration 32/1000 | Loss: 0.00001883
Iteration 33/1000 | Loss: 0.00001883
Iteration 34/1000 | Loss: 0.00001883
Iteration 35/1000 | Loss: 0.00001883
Iteration 36/1000 | Loss: 0.00001883
Iteration 37/1000 | Loss: 0.00001882
Iteration 38/1000 | Loss: 0.00001882
Iteration 39/1000 | Loss: 0.00001881
Iteration 40/1000 | Loss: 0.00001881
Iteration 41/1000 | Loss: 0.00001881
Iteration 42/1000 | Loss: 0.00001881
Iteration 43/1000 | Loss: 0.00001881
Iteration 44/1000 | Loss: 0.00001881
Iteration 45/1000 | Loss: 0.00001881
Iteration 46/1000 | Loss: 0.00001881
Iteration 47/1000 | Loss: 0.00001881
Iteration 48/1000 | Loss: 0.00001881
Iteration 49/1000 | Loss: 0.00001881
Iteration 50/1000 | Loss: 0.00001881
Iteration 51/1000 | Loss: 0.00001881
Iteration 52/1000 | Loss: 0.00001881
Iteration 53/1000 | Loss: 0.00001881
Iteration 54/1000 | Loss: 0.00001881
Iteration 55/1000 | Loss: 0.00001881
Iteration 56/1000 | Loss: 0.00001881
Iteration 57/1000 | Loss: 0.00001881
Iteration 58/1000 | Loss: 0.00001881
Iteration 59/1000 | Loss: 0.00001881
Iteration 60/1000 | Loss: 0.00001881
Iteration 61/1000 | Loss: 0.00001881
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 61. Stopping optimization.
Last 5 losses: [1.8806815205607563e-05, 1.8806815205607563e-05, 1.8806815205607563e-05, 1.8806815205607563e-05, 1.8806815205607563e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8806815205607563e-05

Optimization complete. Final v2v error: 3.576012372970581 mm

Highest mean error: 4.637939453125 mm for frame 141

Lowest mean error: 3.046020746231079 mm for frame 63

Saving results

Total time: 69.49180030822754
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00457105
Iteration 2/25 | Loss: 0.00114718
Iteration 3/25 | Loss: 0.00084636
Iteration 4/25 | Loss: 0.00079993
Iteration 5/25 | Loss: 0.00079519
Iteration 6/25 | Loss: 0.00079387
Iteration 7/25 | Loss: 0.00079387
Iteration 8/25 | Loss: 0.00079387
Iteration 9/25 | Loss: 0.00079387
Iteration 10/25 | Loss: 0.00079387
Iteration 11/25 | Loss: 0.00079387
Iteration 12/25 | Loss: 0.00079387
Iteration 13/25 | Loss: 0.00079387
Iteration 14/25 | Loss: 0.00079387
Iteration 15/25 | Loss: 0.00079387
Iteration 16/25 | Loss: 0.00079387
Iteration 17/25 | Loss: 0.00079387
Iteration 18/25 | Loss: 0.00079387
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007938650087453425, 0.0007938650087453425, 0.0007938650087453425, 0.0007938650087453425, 0.0007938650087453425]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007938650087453425

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49079978
Iteration 2/25 | Loss: 0.00041210
Iteration 3/25 | Loss: 0.00041210
Iteration 4/25 | Loss: 0.00041210
Iteration 5/25 | Loss: 0.00041210
Iteration 6/25 | Loss: 0.00041210
Iteration 7/25 | Loss: 0.00041210
Iteration 8/25 | Loss: 0.00041209
Iteration 9/25 | Loss: 0.00041209
Iteration 10/25 | Loss: 0.00041209
Iteration 11/25 | Loss: 0.00041209
Iteration 12/25 | Loss: 0.00041209
Iteration 13/25 | Loss: 0.00041209
Iteration 14/25 | Loss: 0.00041209
Iteration 15/25 | Loss: 0.00041209
Iteration 16/25 | Loss: 0.00041209
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0004120945814065635, 0.0004120945814065635, 0.0004120945814065635, 0.0004120945814065635, 0.0004120945814065635]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004120945814065635

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041209
Iteration 2/1000 | Loss: 0.00002471
Iteration 3/1000 | Loss: 0.00002002
Iteration 4/1000 | Loss: 0.00001843
Iteration 5/1000 | Loss: 0.00001776
Iteration 6/1000 | Loss: 0.00001726
Iteration 7/1000 | Loss: 0.00001688
Iteration 8/1000 | Loss: 0.00001654
Iteration 9/1000 | Loss: 0.00001649
Iteration 10/1000 | Loss: 0.00001629
Iteration 11/1000 | Loss: 0.00001626
Iteration 12/1000 | Loss: 0.00001626
Iteration 13/1000 | Loss: 0.00001625
Iteration 14/1000 | Loss: 0.00001622
Iteration 15/1000 | Loss: 0.00001617
Iteration 16/1000 | Loss: 0.00001616
Iteration 17/1000 | Loss: 0.00001616
Iteration 18/1000 | Loss: 0.00001615
Iteration 19/1000 | Loss: 0.00001615
Iteration 20/1000 | Loss: 0.00001615
Iteration 21/1000 | Loss: 0.00001614
Iteration 22/1000 | Loss: 0.00001614
Iteration 23/1000 | Loss: 0.00001614
Iteration 24/1000 | Loss: 0.00001614
Iteration 25/1000 | Loss: 0.00001613
Iteration 26/1000 | Loss: 0.00001613
Iteration 27/1000 | Loss: 0.00001613
Iteration 28/1000 | Loss: 0.00001613
Iteration 29/1000 | Loss: 0.00001613
Iteration 30/1000 | Loss: 0.00001613
Iteration 31/1000 | Loss: 0.00001613
Iteration 32/1000 | Loss: 0.00001613
Iteration 33/1000 | Loss: 0.00001613
Iteration 34/1000 | Loss: 0.00001613
Iteration 35/1000 | Loss: 0.00001612
Iteration 36/1000 | Loss: 0.00001612
Iteration 37/1000 | Loss: 0.00001612
Iteration 38/1000 | Loss: 0.00001611
Iteration 39/1000 | Loss: 0.00001611
Iteration 40/1000 | Loss: 0.00001611
Iteration 41/1000 | Loss: 0.00001611
Iteration 42/1000 | Loss: 0.00001610
Iteration 43/1000 | Loss: 0.00001610
Iteration 44/1000 | Loss: 0.00001610
Iteration 45/1000 | Loss: 0.00001610
Iteration 46/1000 | Loss: 0.00001609
Iteration 47/1000 | Loss: 0.00001609
Iteration 48/1000 | Loss: 0.00001609
Iteration 49/1000 | Loss: 0.00001609
Iteration 50/1000 | Loss: 0.00001609
Iteration 51/1000 | Loss: 0.00001609
Iteration 52/1000 | Loss: 0.00001609
Iteration 53/1000 | Loss: 0.00001609
Iteration 54/1000 | Loss: 0.00001609
Iteration 55/1000 | Loss: 0.00001609
Iteration 56/1000 | Loss: 0.00001609
Iteration 57/1000 | Loss: 0.00001608
Iteration 58/1000 | Loss: 0.00001608
Iteration 59/1000 | Loss: 0.00001608
Iteration 60/1000 | Loss: 0.00001608
Iteration 61/1000 | Loss: 0.00001608
Iteration 62/1000 | Loss: 0.00001608
Iteration 63/1000 | Loss: 0.00001608
Iteration 64/1000 | Loss: 0.00001608
Iteration 65/1000 | Loss: 0.00001608
Iteration 66/1000 | Loss: 0.00001607
Iteration 67/1000 | Loss: 0.00001607
Iteration 68/1000 | Loss: 0.00001607
Iteration 69/1000 | Loss: 0.00001607
Iteration 70/1000 | Loss: 0.00001607
Iteration 71/1000 | Loss: 0.00001607
Iteration 72/1000 | Loss: 0.00001606
Iteration 73/1000 | Loss: 0.00001606
Iteration 74/1000 | Loss: 0.00001606
Iteration 75/1000 | Loss: 0.00001606
Iteration 76/1000 | Loss: 0.00001606
Iteration 77/1000 | Loss: 0.00001606
Iteration 78/1000 | Loss: 0.00001606
Iteration 79/1000 | Loss: 0.00001606
Iteration 80/1000 | Loss: 0.00001606
Iteration 81/1000 | Loss: 0.00001605
Iteration 82/1000 | Loss: 0.00001605
Iteration 83/1000 | Loss: 0.00001605
Iteration 84/1000 | Loss: 0.00001605
Iteration 85/1000 | Loss: 0.00001605
Iteration 86/1000 | Loss: 0.00001604
Iteration 87/1000 | Loss: 0.00001604
Iteration 88/1000 | Loss: 0.00001604
Iteration 89/1000 | Loss: 0.00001604
Iteration 90/1000 | Loss: 0.00001604
Iteration 91/1000 | Loss: 0.00001604
Iteration 92/1000 | Loss: 0.00001603
Iteration 93/1000 | Loss: 0.00001603
Iteration 94/1000 | Loss: 0.00001603
Iteration 95/1000 | Loss: 0.00001603
Iteration 96/1000 | Loss: 0.00001603
Iteration 97/1000 | Loss: 0.00001603
Iteration 98/1000 | Loss: 0.00001603
Iteration 99/1000 | Loss: 0.00001603
Iteration 100/1000 | Loss: 0.00001603
Iteration 101/1000 | Loss: 0.00001602
Iteration 102/1000 | Loss: 0.00001602
Iteration 103/1000 | Loss: 0.00001602
Iteration 104/1000 | Loss: 0.00001602
Iteration 105/1000 | Loss: 0.00001602
Iteration 106/1000 | Loss: 0.00001602
Iteration 107/1000 | Loss: 0.00001602
Iteration 108/1000 | Loss: 0.00001602
Iteration 109/1000 | Loss: 0.00001602
Iteration 110/1000 | Loss: 0.00001602
Iteration 111/1000 | Loss: 0.00001602
Iteration 112/1000 | Loss: 0.00001602
Iteration 113/1000 | Loss: 0.00001602
Iteration 114/1000 | Loss: 0.00001601
Iteration 115/1000 | Loss: 0.00001601
Iteration 116/1000 | Loss: 0.00001601
Iteration 117/1000 | Loss: 0.00001601
Iteration 118/1000 | Loss: 0.00001601
Iteration 119/1000 | Loss: 0.00001601
Iteration 120/1000 | Loss: 0.00001601
Iteration 121/1000 | Loss: 0.00001601
Iteration 122/1000 | Loss: 0.00001601
Iteration 123/1000 | Loss: 0.00001601
Iteration 124/1000 | Loss: 0.00001601
Iteration 125/1000 | Loss: 0.00001601
Iteration 126/1000 | Loss: 0.00001601
Iteration 127/1000 | Loss: 0.00001600
Iteration 128/1000 | Loss: 0.00001600
Iteration 129/1000 | Loss: 0.00001600
Iteration 130/1000 | Loss: 0.00001600
Iteration 131/1000 | Loss: 0.00001600
Iteration 132/1000 | Loss: 0.00001600
Iteration 133/1000 | Loss: 0.00001600
Iteration 134/1000 | Loss: 0.00001600
Iteration 135/1000 | Loss: 0.00001600
Iteration 136/1000 | Loss: 0.00001600
Iteration 137/1000 | Loss: 0.00001600
Iteration 138/1000 | Loss: 0.00001600
Iteration 139/1000 | Loss: 0.00001600
Iteration 140/1000 | Loss: 0.00001600
Iteration 141/1000 | Loss: 0.00001600
Iteration 142/1000 | Loss: 0.00001600
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [1.5999901734176092e-05, 1.5999901734176092e-05, 1.5999901734176092e-05, 1.5999901734176092e-05, 1.5999901734176092e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5999901734176092e-05

Optimization complete. Final v2v error: 3.315119981765747 mm

Highest mean error: 3.529280424118042 mm for frame 48

Lowest mean error: 3.1976945400238037 mm for frame 231

Saving results

Total time: 35.66393208503723
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01116193
Iteration 2/25 | Loss: 0.00203035
Iteration 3/25 | Loss: 0.00115028
Iteration 4/25 | Loss: 0.00104369
Iteration 5/25 | Loss: 0.00099679
Iteration 6/25 | Loss: 0.00100399
Iteration 7/25 | Loss: 0.00099528
Iteration 8/25 | Loss: 0.00095457
Iteration 9/25 | Loss: 0.00092916
Iteration 10/25 | Loss: 0.00091673
Iteration 11/25 | Loss: 0.00090555
Iteration 12/25 | Loss: 0.00089980
Iteration 13/25 | Loss: 0.00089835
Iteration 14/25 | Loss: 0.00090036
Iteration 15/25 | Loss: 0.00089737
Iteration 16/25 | Loss: 0.00089355
Iteration 17/25 | Loss: 0.00089263
Iteration 18/25 | Loss: 0.00089232
Iteration 19/25 | Loss: 0.00089210
Iteration 20/25 | Loss: 0.00089195
Iteration 21/25 | Loss: 0.00089188
Iteration 22/25 | Loss: 0.00089185
Iteration 23/25 | Loss: 0.00089175
Iteration 24/25 | Loss: 0.00089267
Iteration 25/25 | Loss: 0.00089230

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.74049211
Iteration 2/25 | Loss: 0.00041156
Iteration 3/25 | Loss: 0.00035495
Iteration 4/25 | Loss: 0.00035482
Iteration 5/25 | Loss: 0.00035482
Iteration 6/25 | Loss: 0.00035482
Iteration 7/25 | Loss: 0.00035482
Iteration 8/25 | Loss: 0.00035482
Iteration 9/25 | Loss: 0.00035482
Iteration 10/25 | Loss: 0.00035482
Iteration 11/25 | Loss: 0.00035482
Iteration 12/25 | Loss: 0.00035482
Iteration 13/25 | Loss: 0.00035482
Iteration 14/25 | Loss: 0.00035482
Iteration 15/25 | Loss: 0.00035482
Iteration 16/25 | Loss: 0.00035482
Iteration 17/25 | Loss: 0.00035482
Iteration 18/25 | Loss: 0.00035482
Iteration 19/25 | Loss: 0.00035482
Iteration 20/25 | Loss: 0.00035482
Iteration 21/25 | Loss: 0.00035482
Iteration 22/25 | Loss: 0.00035482
Iteration 23/25 | Loss: 0.00035482
Iteration 24/25 | Loss: 0.00035482
Iteration 25/25 | Loss: 0.00035482
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0003548198437783867, 0.0003548198437783867, 0.0003548198437783867, 0.0003548198437783867, 0.0003548198437783867]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003548198437783867

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035482
Iteration 2/1000 | Loss: 0.00005367
Iteration 3/1000 | Loss: 0.00010641
Iteration 4/1000 | Loss: 0.00004083
Iteration 5/1000 | Loss: 0.00003861
Iteration 6/1000 | Loss: 0.00010699
Iteration 7/1000 | Loss: 0.00003630
Iteration 8/1000 | Loss: 0.00003521
Iteration 9/1000 | Loss: 0.00003450
Iteration 10/1000 | Loss: 0.00003406
Iteration 11/1000 | Loss: 0.00003372
Iteration 12/1000 | Loss: 0.00008339
Iteration 13/1000 | Loss: 0.00003344
Iteration 14/1000 | Loss: 0.00003323
Iteration 15/1000 | Loss: 0.00003304
Iteration 16/1000 | Loss: 0.00003286
Iteration 17/1000 | Loss: 0.00003277
Iteration 18/1000 | Loss: 0.00003272
Iteration 19/1000 | Loss: 0.00003269
Iteration 20/1000 | Loss: 0.00003269
Iteration 21/1000 | Loss: 0.00003268
Iteration 22/1000 | Loss: 0.00003268
Iteration 23/1000 | Loss: 0.00003268
Iteration 24/1000 | Loss: 0.00003268
Iteration 25/1000 | Loss: 0.00003268
Iteration 26/1000 | Loss: 0.00003268
Iteration 27/1000 | Loss: 0.00003268
Iteration 28/1000 | Loss: 0.00003267
Iteration 29/1000 | Loss: 0.00003261
Iteration 30/1000 | Loss: 0.00003261
Iteration 31/1000 | Loss: 0.00003260
Iteration 32/1000 | Loss: 0.00003259
Iteration 33/1000 | Loss: 0.00003254
Iteration 34/1000 | Loss: 0.00003253
Iteration 35/1000 | Loss: 0.00003251
Iteration 36/1000 | Loss: 0.00003251
Iteration 37/1000 | Loss: 0.00003251
Iteration 38/1000 | Loss: 0.00003251
Iteration 39/1000 | Loss: 0.00003251
Iteration 40/1000 | Loss: 0.00003251
Iteration 41/1000 | Loss: 0.00003250
Iteration 42/1000 | Loss: 0.00003250
Iteration 43/1000 | Loss: 0.00003250
Iteration 44/1000 | Loss: 0.00003250
Iteration 45/1000 | Loss: 0.00003250
Iteration 46/1000 | Loss: 0.00003250
Iteration 47/1000 | Loss: 0.00003250
Iteration 48/1000 | Loss: 0.00003250
Iteration 49/1000 | Loss: 0.00003249
Iteration 50/1000 | Loss: 0.00003249
Iteration 51/1000 | Loss: 0.00003249
Iteration 52/1000 | Loss: 0.00003249
Iteration 53/1000 | Loss: 0.00003248
Iteration 54/1000 | Loss: 0.00003248
Iteration 55/1000 | Loss: 0.00003248
Iteration 56/1000 | Loss: 0.00003248
Iteration 57/1000 | Loss: 0.00003248
Iteration 58/1000 | Loss: 0.00003248
Iteration 59/1000 | Loss: 0.00003248
Iteration 60/1000 | Loss: 0.00003248
Iteration 61/1000 | Loss: 0.00003248
Iteration 62/1000 | Loss: 0.00003248
Iteration 63/1000 | Loss: 0.00003248
Iteration 64/1000 | Loss: 0.00003248
Iteration 65/1000 | Loss: 0.00003248
Iteration 66/1000 | Loss: 0.00003247
Iteration 67/1000 | Loss: 0.00003247
Iteration 68/1000 | Loss: 0.00003247
Iteration 69/1000 | Loss: 0.00003247
Iteration 70/1000 | Loss: 0.00003245
Iteration 71/1000 | Loss: 0.00003245
Iteration 72/1000 | Loss: 0.00003245
Iteration 73/1000 | Loss: 0.00003245
Iteration 74/1000 | Loss: 0.00003245
Iteration 75/1000 | Loss: 0.00003245
Iteration 76/1000 | Loss: 0.00003245
Iteration 77/1000 | Loss: 0.00003244
Iteration 78/1000 | Loss: 0.00003244
Iteration 79/1000 | Loss: 0.00003244
Iteration 80/1000 | Loss: 0.00003244
Iteration 81/1000 | Loss: 0.00003244
Iteration 82/1000 | Loss: 0.00003244
Iteration 83/1000 | Loss: 0.00003244
Iteration 84/1000 | Loss: 0.00003244
Iteration 85/1000 | Loss: 0.00003244
Iteration 86/1000 | Loss: 0.00003244
Iteration 87/1000 | Loss: 0.00003244
Iteration 88/1000 | Loss: 0.00003243
Iteration 89/1000 | Loss: 0.00003243
Iteration 90/1000 | Loss: 0.00003242
Iteration 91/1000 | Loss: 0.00003242
Iteration 92/1000 | Loss: 0.00003242
Iteration 93/1000 | Loss: 0.00003241
Iteration 94/1000 | Loss: 0.00003241
Iteration 95/1000 | Loss: 0.00003241
Iteration 96/1000 | Loss: 0.00003240
Iteration 97/1000 | Loss: 0.00003240
Iteration 98/1000 | Loss: 0.00003240
Iteration 99/1000 | Loss: 0.00003240
Iteration 100/1000 | Loss: 0.00003239
Iteration 101/1000 | Loss: 0.00003239
Iteration 102/1000 | Loss: 0.00003239
Iteration 103/1000 | Loss: 0.00003239
Iteration 104/1000 | Loss: 0.00003239
Iteration 105/1000 | Loss: 0.00003239
Iteration 106/1000 | Loss: 0.00003239
Iteration 107/1000 | Loss: 0.00003238
Iteration 108/1000 | Loss: 0.00003238
Iteration 109/1000 | Loss: 0.00003238
Iteration 110/1000 | Loss: 0.00003238
Iteration 111/1000 | Loss: 0.00003238
Iteration 112/1000 | Loss: 0.00003238
Iteration 113/1000 | Loss: 0.00003238
Iteration 114/1000 | Loss: 0.00003238
Iteration 115/1000 | Loss: 0.00003238
Iteration 116/1000 | Loss: 0.00003237
Iteration 117/1000 | Loss: 0.00003237
Iteration 118/1000 | Loss: 0.00003237
Iteration 119/1000 | Loss: 0.00003237
Iteration 120/1000 | Loss: 0.00003236
Iteration 121/1000 | Loss: 0.00003236
Iteration 122/1000 | Loss: 0.00003236
Iteration 123/1000 | Loss: 0.00003235
Iteration 124/1000 | Loss: 0.00003235
Iteration 125/1000 | Loss: 0.00003235
Iteration 126/1000 | Loss: 0.00003235
Iteration 127/1000 | Loss: 0.00003235
Iteration 128/1000 | Loss: 0.00003235
Iteration 129/1000 | Loss: 0.00003234
Iteration 130/1000 | Loss: 0.00003234
Iteration 131/1000 | Loss: 0.00003234
Iteration 132/1000 | Loss: 0.00003234
Iteration 133/1000 | Loss: 0.00003234
Iteration 134/1000 | Loss: 0.00003234
Iteration 135/1000 | Loss: 0.00003234
Iteration 136/1000 | Loss: 0.00003233
Iteration 137/1000 | Loss: 0.00003233
Iteration 138/1000 | Loss: 0.00003233
Iteration 139/1000 | Loss: 0.00003233
Iteration 140/1000 | Loss: 0.00003233
Iteration 141/1000 | Loss: 0.00003233
Iteration 142/1000 | Loss: 0.00003233
Iteration 143/1000 | Loss: 0.00003233
Iteration 144/1000 | Loss: 0.00003233
Iteration 145/1000 | Loss: 0.00003233
Iteration 146/1000 | Loss: 0.00003233
Iteration 147/1000 | Loss: 0.00003233
Iteration 148/1000 | Loss: 0.00003233
Iteration 149/1000 | Loss: 0.00003233
Iteration 150/1000 | Loss: 0.00003233
Iteration 151/1000 | Loss: 0.00003233
Iteration 152/1000 | Loss: 0.00003232
Iteration 153/1000 | Loss: 0.00003232
Iteration 154/1000 | Loss: 0.00003232
Iteration 155/1000 | Loss: 0.00003232
Iteration 156/1000 | Loss: 0.00003231
Iteration 157/1000 | Loss: 0.00003231
Iteration 158/1000 | Loss: 0.00003231
Iteration 159/1000 | Loss: 0.00003231
Iteration 160/1000 | Loss: 0.00003230
Iteration 161/1000 | Loss: 0.00003230
Iteration 162/1000 | Loss: 0.00003230
Iteration 163/1000 | Loss: 0.00003229
Iteration 164/1000 | Loss: 0.00003229
Iteration 165/1000 | Loss: 0.00003229
Iteration 166/1000 | Loss: 0.00003229
Iteration 167/1000 | Loss: 0.00003229
Iteration 168/1000 | Loss: 0.00003229
Iteration 169/1000 | Loss: 0.00003228
Iteration 170/1000 | Loss: 0.00003228
Iteration 171/1000 | Loss: 0.00003228
Iteration 172/1000 | Loss: 0.00003228
Iteration 173/1000 | Loss: 0.00003228
Iteration 174/1000 | Loss: 0.00003228
Iteration 175/1000 | Loss: 0.00003228
Iteration 176/1000 | Loss: 0.00003228
Iteration 177/1000 | Loss: 0.00003228
Iteration 178/1000 | Loss: 0.00003228
Iteration 179/1000 | Loss: 0.00003227
Iteration 180/1000 | Loss: 0.00003227
Iteration 181/1000 | Loss: 0.00003227
Iteration 182/1000 | Loss: 0.00003227
Iteration 183/1000 | Loss: 0.00003227
Iteration 184/1000 | Loss: 0.00003227
Iteration 185/1000 | Loss: 0.00003227
Iteration 186/1000 | Loss: 0.00003227
Iteration 187/1000 | Loss: 0.00003226
Iteration 188/1000 | Loss: 0.00003226
Iteration 189/1000 | Loss: 0.00003226
Iteration 190/1000 | Loss: 0.00003226
Iteration 191/1000 | Loss: 0.00003226
Iteration 192/1000 | Loss: 0.00003226
Iteration 193/1000 | Loss: 0.00003226
Iteration 194/1000 | Loss: 0.00003225
Iteration 195/1000 | Loss: 0.00003225
Iteration 196/1000 | Loss: 0.00003225
Iteration 197/1000 | Loss: 0.00003225
Iteration 198/1000 | Loss: 0.00003225
Iteration 199/1000 | Loss: 0.00003225
Iteration 200/1000 | Loss: 0.00003225
Iteration 201/1000 | Loss: 0.00003225
Iteration 202/1000 | Loss: 0.00003225
Iteration 203/1000 | Loss: 0.00003225
Iteration 204/1000 | Loss: 0.00003225
Iteration 205/1000 | Loss: 0.00003225
Iteration 206/1000 | Loss: 0.00003225
Iteration 207/1000 | Loss: 0.00003225
Iteration 208/1000 | Loss: 0.00003225
Iteration 209/1000 | Loss: 0.00003225
Iteration 210/1000 | Loss: 0.00003224
Iteration 211/1000 | Loss: 0.00003224
Iteration 212/1000 | Loss: 0.00003224
Iteration 213/1000 | Loss: 0.00003224
Iteration 214/1000 | Loss: 0.00003224
Iteration 215/1000 | Loss: 0.00003224
Iteration 216/1000 | Loss: 0.00003224
Iteration 217/1000 | Loss: 0.00003224
Iteration 218/1000 | Loss: 0.00003224
Iteration 219/1000 | Loss: 0.00003224
Iteration 220/1000 | Loss: 0.00003224
Iteration 221/1000 | Loss: 0.00003224
Iteration 222/1000 | Loss: 0.00003223
Iteration 223/1000 | Loss: 0.00003223
Iteration 224/1000 | Loss: 0.00003223
Iteration 225/1000 | Loss: 0.00003223
Iteration 226/1000 | Loss: 0.00003223
Iteration 227/1000 | Loss: 0.00003222
Iteration 228/1000 | Loss: 0.00003222
Iteration 229/1000 | Loss: 0.00003222
Iteration 230/1000 | Loss: 0.00003222
Iteration 231/1000 | Loss: 0.00003222
Iteration 232/1000 | Loss: 0.00003222
Iteration 233/1000 | Loss: 0.00003222
Iteration 234/1000 | Loss: 0.00003222
Iteration 235/1000 | Loss: 0.00003222
Iteration 236/1000 | Loss: 0.00003222
Iteration 237/1000 | Loss: 0.00003222
Iteration 238/1000 | Loss: 0.00003222
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 238. Stopping optimization.
Last 5 losses: [3.222189116058871e-05, 3.222189116058871e-05, 3.222189116058871e-05, 3.222189116058871e-05, 3.222189116058871e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.222189116058871e-05

Optimization complete. Final v2v error: 4.730246067047119 mm

Highest mean error: 5.941190242767334 mm for frame 171

Lowest mean error: 3.9376304149627686 mm for frame 205

Saving results

Total time: 97.23427987098694
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00598520
Iteration 2/25 | Loss: 0.00083263
Iteration 3/25 | Loss: 0.00071788
Iteration 4/25 | Loss: 0.00070294
Iteration 5/25 | Loss: 0.00069799
Iteration 6/25 | Loss: 0.00069695
Iteration 7/25 | Loss: 0.00069695
Iteration 8/25 | Loss: 0.00069695
Iteration 9/25 | Loss: 0.00069695
Iteration 10/25 | Loss: 0.00069695
Iteration 11/25 | Loss: 0.00069695
Iteration 12/25 | Loss: 0.00069695
Iteration 13/25 | Loss: 0.00069695
Iteration 14/25 | Loss: 0.00069695
Iteration 15/25 | Loss: 0.00069695
Iteration 16/25 | Loss: 0.00069695
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006969455862417817, 0.0006969455862417817, 0.0006969455862417817, 0.0006969455862417817, 0.0006969455862417817]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006969455862417817

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.17078543
Iteration 2/25 | Loss: 0.00029940
Iteration 3/25 | Loss: 0.00029940
Iteration 4/25 | Loss: 0.00029940
Iteration 5/25 | Loss: 0.00029940
Iteration 6/25 | Loss: 0.00029940
Iteration 7/25 | Loss: 0.00029940
Iteration 8/25 | Loss: 0.00029940
Iteration 9/25 | Loss: 0.00029940
Iteration 10/25 | Loss: 0.00029940
Iteration 11/25 | Loss: 0.00029940
Iteration 12/25 | Loss: 0.00029940
Iteration 13/25 | Loss: 0.00029940
Iteration 14/25 | Loss: 0.00029940
Iteration 15/25 | Loss: 0.00029940
Iteration 16/25 | Loss: 0.00029940
Iteration 17/25 | Loss: 0.00029940
Iteration 18/25 | Loss: 0.00029940
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00029939712840132415, 0.00029939712840132415, 0.00029939712840132415, 0.00029939712840132415, 0.00029939712840132415]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00029939712840132415

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029940
Iteration 2/1000 | Loss: 0.00002497
Iteration 3/1000 | Loss: 0.00001612
Iteration 4/1000 | Loss: 0.00001486
Iteration 5/1000 | Loss: 0.00001382
Iteration 6/1000 | Loss: 0.00001340
Iteration 7/1000 | Loss: 0.00001308
Iteration 8/1000 | Loss: 0.00001291
Iteration 9/1000 | Loss: 0.00001288
Iteration 10/1000 | Loss: 0.00001273
Iteration 11/1000 | Loss: 0.00001256
Iteration 12/1000 | Loss: 0.00001253
Iteration 13/1000 | Loss: 0.00001239
Iteration 14/1000 | Loss: 0.00001238
Iteration 15/1000 | Loss: 0.00001238
Iteration 16/1000 | Loss: 0.00001230
Iteration 17/1000 | Loss: 0.00001230
Iteration 18/1000 | Loss: 0.00001228
Iteration 19/1000 | Loss: 0.00001228
Iteration 20/1000 | Loss: 0.00001227
Iteration 21/1000 | Loss: 0.00001224
Iteration 22/1000 | Loss: 0.00001224
Iteration 23/1000 | Loss: 0.00001224
Iteration 24/1000 | Loss: 0.00001224
Iteration 25/1000 | Loss: 0.00001224
Iteration 26/1000 | Loss: 0.00001221
Iteration 27/1000 | Loss: 0.00001220
Iteration 28/1000 | Loss: 0.00001220
Iteration 29/1000 | Loss: 0.00001219
Iteration 30/1000 | Loss: 0.00001219
Iteration 31/1000 | Loss: 0.00001219
Iteration 32/1000 | Loss: 0.00001213
Iteration 33/1000 | Loss: 0.00001213
Iteration 34/1000 | Loss: 0.00001209
Iteration 35/1000 | Loss: 0.00001205
Iteration 36/1000 | Loss: 0.00001203
Iteration 37/1000 | Loss: 0.00001202
Iteration 38/1000 | Loss: 0.00001202
Iteration 39/1000 | Loss: 0.00001201
Iteration 40/1000 | Loss: 0.00001201
Iteration 41/1000 | Loss: 0.00001200
Iteration 42/1000 | Loss: 0.00001200
Iteration 43/1000 | Loss: 0.00001199
Iteration 44/1000 | Loss: 0.00001199
Iteration 45/1000 | Loss: 0.00001199
Iteration 46/1000 | Loss: 0.00001199
Iteration 47/1000 | Loss: 0.00001199
Iteration 48/1000 | Loss: 0.00001199
Iteration 49/1000 | Loss: 0.00001198
Iteration 50/1000 | Loss: 0.00001198
Iteration 51/1000 | Loss: 0.00001198
Iteration 52/1000 | Loss: 0.00001198
Iteration 53/1000 | Loss: 0.00001198
Iteration 54/1000 | Loss: 0.00001198
Iteration 55/1000 | Loss: 0.00001197
Iteration 56/1000 | Loss: 0.00001197
Iteration 57/1000 | Loss: 0.00001197
Iteration 58/1000 | Loss: 0.00001197
Iteration 59/1000 | Loss: 0.00001196
Iteration 60/1000 | Loss: 0.00001196
Iteration 61/1000 | Loss: 0.00001195
Iteration 62/1000 | Loss: 0.00001195
Iteration 63/1000 | Loss: 0.00001195
Iteration 64/1000 | Loss: 0.00001195
Iteration 65/1000 | Loss: 0.00001195
Iteration 66/1000 | Loss: 0.00001195
Iteration 67/1000 | Loss: 0.00001195
Iteration 68/1000 | Loss: 0.00001195
Iteration 69/1000 | Loss: 0.00001195
Iteration 70/1000 | Loss: 0.00001195
Iteration 71/1000 | Loss: 0.00001194
Iteration 72/1000 | Loss: 0.00001194
Iteration 73/1000 | Loss: 0.00001194
Iteration 74/1000 | Loss: 0.00001194
Iteration 75/1000 | Loss: 0.00001194
Iteration 76/1000 | Loss: 0.00001194
Iteration 77/1000 | Loss: 0.00001194
Iteration 78/1000 | Loss: 0.00001194
Iteration 79/1000 | Loss: 0.00001194
Iteration 80/1000 | Loss: 0.00001193
Iteration 81/1000 | Loss: 0.00001193
Iteration 82/1000 | Loss: 0.00001193
Iteration 83/1000 | Loss: 0.00001193
Iteration 84/1000 | Loss: 0.00001193
Iteration 85/1000 | Loss: 0.00001193
Iteration 86/1000 | Loss: 0.00001192
Iteration 87/1000 | Loss: 0.00001192
Iteration 88/1000 | Loss: 0.00001192
Iteration 89/1000 | Loss: 0.00001192
Iteration 90/1000 | Loss: 0.00001192
Iteration 91/1000 | Loss: 0.00001192
Iteration 92/1000 | Loss: 0.00001192
Iteration 93/1000 | Loss: 0.00001191
Iteration 94/1000 | Loss: 0.00001191
Iteration 95/1000 | Loss: 0.00001191
Iteration 96/1000 | Loss: 0.00001191
Iteration 97/1000 | Loss: 0.00001191
Iteration 98/1000 | Loss: 0.00001191
Iteration 99/1000 | Loss: 0.00001190
Iteration 100/1000 | Loss: 0.00001190
Iteration 101/1000 | Loss: 0.00001190
Iteration 102/1000 | Loss: 0.00001190
Iteration 103/1000 | Loss: 0.00001190
Iteration 104/1000 | Loss: 0.00001190
Iteration 105/1000 | Loss: 0.00001190
Iteration 106/1000 | Loss: 0.00001190
Iteration 107/1000 | Loss: 0.00001190
Iteration 108/1000 | Loss: 0.00001190
Iteration 109/1000 | Loss: 0.00001189
Iteration 110/1000 | Loss: 0.00001189
Iteration 111/1000 | Loss: 0.00001189
Iteration 112/1000 | Loss: 0.00001189
Iteration 113/1000 | Loss: 0.00001189
Iteration 114/1000 | Loss: 0.00001189
Iteration 115/1000 | Loss: 0.00001189
Iteration 116/1000 | Loss: 0.00001189
Iteration 117/1000 | Loss: 0.00001189
Iteration 118/1000 | Loss: 0.00001189
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [1.1892801012436394e-05, 1.1892801012436394e-05, 1.1892801012436394e-05, 1.1892801012436394e-05, 1.1892801012436394e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1892801012436394e-05

Optimization complete. Final v2v error: 2.96370530128479 mm

Highest mean error: 3.177107572555542 mm for frame 110

Lowest mean error: 2.834395170211792 mm for frame 78

Saving results

Total time: 35.984734296798706
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01005834
Iteration 2/25 | Loss: 0.01005833
Iteration 3/25 | Loss: 0.01005833
Iteration 4/25 | Loss: 0.01005832
Iteration 5/25 | Loss: 0.01005832
Iteration 6/25 | Loss: 0.00288152
Iteration 7/25 | Loss: 0.00158543
Iteration 8/25 | Loss: 0.00145388
Iteration 9/25 | Loss: 0.00142304
Iteration 10/25 | Loss: 0.00141315
Iteration 11/25 | Loss: 0.00141222
Iteration 12/25 | Loss: 0.00140945
Iteration 13/25 | Loss: 0.00140746
Iteration 14/25 | Loss: 0.00140700
Iteration 15/25 | Loss: 0.00140900
Iteration 16/25 | Loss: 0.00140937
Iteration 17/25 | Loss: 0.00140793
Iteration 18/25 | Loss: 0.00140672
Iteration 19/25 | Loss: 0.00140370
Iteration 20/25 | Loss: 0.00140164
Iteration 21/25 | Loss: 0.00140143
Iteration 22/25 | Loss: 0.00140136
Iteration 23/25 | Loss: 0.00140136
Iteration 24/25 | Loss: 0.00140136
Iteration 25/25 | Loss: 0.00140135

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44711924
Iteration 2/25 | Loss: 0.00461794
Iteration 3/25 | Loss: 0.00461794
Iteration 4/25 | Loss: 0.00461794
Iteration 5/25 | Loss: 0.00461794
Iteration 6/25 | Loss: 0.00461794
Iteration 7/25 | Loss: 0.00461794
Iteration 8/25 | Loss: 0.00461793
Iteration 9/25 | Loss: 0.00461793
Iteration 10/25 | Loss: 0.00461793
Iteration 11/25 | Loss: 0.00461793
Iteration 12/25 | Loss: 0.00461793
Iteration 13/25 | Loss: 0.00461793
Iteration 14/25 | Loss: 0.00461793
Iteration 15/25 | Loss: 0.00461793
Iteration 16/25 | Loss: 0.00461793
Iteration 17/25 | Loss: 0.00461793
Iteration 18/25 | Loss: 0.00461793
Iteration 19/25 | Loss: 0.00461793
Iteration 20/25 | Loss: 0.00461793
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.004617932718247175, 0.004617932718247175, 0.004617932718247175, 0.004617932718247175, 0.004617932718247175]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004617932718247175

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00461793
Iteration 2/1000 | Loss: 0.00081280
Iteration 3/1000 | Loss: 0.00059449
Iteration 4/1000 | Loss: 0.00048296
Iteration 5/1000 | Loss: 0.00043169
Iteration 6/1000 | Loss: 0.00037489
Iteration 7/1000 | Loss: 0.00034223
Iteration 8/1000 | Loss: 0.00031748
Iteration 9/1000 | Loss: 0.00030170
Iteration 10/1000 | Loss: 0.00172424
Iteration 11/1000 | Loss: 0.01744324
Iteration 12/1000 | Loss: 0.00248358
Iteration 13/1000 | Loss: 0.00079347
Iteration 14/1000 | Loss: 0.00030660
Iteration 15/1000 | Loss: 0.00020001
Iteration 16/1000 | Loss: 0.00014003
Iteration 17/1000 | Loss: 0.00010607
Iteration 18/1000 | Loss: 0.00007179
Iteration 19/1000 | Loss: 0.00005128
Iteration 20/1000 | Loss: 0.00004153
Iteration 21/1000 | Loss: 0.00003599
Iteration 22/1000 | Loss: 0.00003054
Iteration 23/1000 | Loss: 0.00002615
Iteration 24/1000 | Loss: 0.00002364
Iteration 25/1000 | Loss: 0.00002174
Iteration 26/1000 | Loss: 0.00002019
Iteration 27/1000 | Loss: 0.00001889
Iteration 28/1000 | Loss: 0.00001829
Iteration 29/1000 | Loss: 0.00001770
Iteration 30/1000 | Loss: 0.00001726
Iteration 31/1000 | Loss: 0.00001686
Iteration 32/1000 | Loss: 0.00001658
Iteration 33/1000 | Loss: 0.00001635
Iteration 34/1000 | Loss: 0.00001632
Iteration 35/1000 | Loss: 0.00001626
Iteration 36/1000 | Loss: 0.00001622
Iteration 37/1000 | Loss: 0.00001618
Iteration 38/1000 | Loss: 0.00001618
Iteration 39/1000 | Loss: 0.00001618
Iteration 40/1000 | Loss: 0.00001617
Iteration 41/1000 | Loss: 0.00001617
Iteration 42/1000 | Loss: 0.00001617
Iteration 43/1000 | Loss: 0.00001617
Iteration 44/1000 | Loss: 0.00001617
Iteration 45/1000 | Loss: 0.00001617
Iteration 46/1000 | Loss: 0.00001617
Iteration 47/1000 | Loss: 0.00001617
Iteration 48/1000 | Loss: 0.00001616
Iteration 49/1000 | Loss: 0.00001616
Iteration 50/1000 | Loss: 0.00001615
Iteration 51/1000 | Loss: 0.00001615
Iteration 52/1000 | Loss: 0.00001614
Iteration 53/1000 | Loss: 0.00001614
Iteration 54/1000 | Loss: 0.00001613
Iteration 55/1000 | Loss: 0.00001612
Iteration 56/1000 | Loss: 0.00001611
Iteration 57/1000 | Loss: 0.00001609
Iteration 58/1000 | Loss: 0.00001608
Iteration 59/1000 | Loss: 0.00001607
Iteration 60/1000 | Loss: 0.00001606
Iteration 61/1000 | Loss: 0.00001605
Iteration 62/1000 | Loss: 0.00001605
Iteration 63/1000 | Loss: 0.00001605
Iteration 64/1000 | Loss: 0.00001605
Iteration 65/1000 | Loss: 0.00001605
Iteration 66/1000 | Loss: 0.00001604
Iteration 67/1000 | Loss: 0.00001603
Iteration 68/1000 | Loss: 0.00001603
Iteration 69/1000 | Loss: 0.00001603
Iteration 70/1000 | Loss: 0.00001603
Iteration 71/1000 | Loss: 0.00001603
Iteration 72/1000 | Loss: 0.00001602
Iteration 73/1000 | Loss: 0.00001602
Iteration 74/1000 | Loss: 0.00001602
Iteration 75/1000 | Loss: 0.00001602
Iteration 76/1000 | Loss: 0.00001602
Iteration 77/1000 | Loss: 0.00001602
Iteration 78/1000 | Loss: 0.00001602
Iteration 79/1000 | Loss: 0.00001602
Iteration 80/1000 | Loss: 0.00001602
Iteration 81/1000 | Loss: 0.00001601
Iteration 82/1000 | Loss: 0.00001601
Iteration 83/1000 | Loss: 0.00001601
Iteration 84/1000 | Loss: 0.00001601
Iteration 85/1000 | Loss: 0.00001601
Iteration 86/1000 | Loss: 0.00001601
Iteration 87/1000 | Loss: 0.00001601
Iteration 88/1000 | Loss: 0.00001601
Iteration 89/1000 | Loss: 0.00001601
Iteration 90/1000 | Loss: 0.00001601
Iteration 91/1000 | Loss: 0.00001601
Iteration 92/1000 | Loss: 0.00001601
Iteration 93/1000 | Loss: 0.00001601
Iteration 94/1000 | Loss: 0.00001601
Iteration 95/1000 | Loss: 0.00001600
Iteration 96/1000 | Loss: 0.00001600
Iteration 97/1000 | Loss: 0.00001600
Iteration 98/1000 | Loss: 0.00001600
Iteration 99/1000 | Loss: 0.00001600
Iteration 100/1000 | Loss: 0.00001600
Iteration 101/1000 | Loss: 0.00001600
Iteration 102/1000 | Loss: 0.00001600
Iteration 103/1000 | Loss: 0.00001600
Iteration 104/1000 | Loss: 0.00001600
Iteration 105/1000 | Loss: 0.00001600
Iteration 106/1000 | Loss: 0.00001600
Iteration 107/1000 | Loss: 0.00001600
Iteration 108/1000 | Loss: 0.00001600
Iteration 109/1000 | Loss: 0.00001599
Iteration 110/1000 | Loss: 0.00001599
Iteration 111/1000 | Loss: 0.00001599
Iteration 112/1000 | Loss: 0.00001599
Iteration 113/1000 | Loss: 0.00001598
Iteration 114/1000 | Loss: 0.00001598
Iteration 115/1000 | Loss: 0.00001598
Iteration 116/1000 | Loss: 0.00001597
Iteration 117/1000 | Loss: 0.00001597
Iteration 118/1000 | Loss: 0.00001597
Iteration 119/1000 | Loss: 0.00001597
Iteration 120/1000 | Loss: 0.00001597
Iteration 121/1000 | Loss: 0.00001597
Iteration 122/1000 | Loss: 0.00001597
Iteration 123/1000 | Loss: 0.00001597
Iteration 124/1000 | Loss: 0.00001596
Iteration 125/1000 | Loss: 0.00001596
Iteration 126/1000 | Loss: 0.00001596
Iteration 127/1000 | Loss: 0.00001596
Iteration 128/1000 | Loss: 0.00001596
Iteration 129/1000 | Loss: 0.00001596
Iteration 130/1000 | Loss: 0.00001596
Iteration 131/1000 | Loss: 0.00001596
Iteration 132/1000 | Loss: 0.00001595
Iteration 133/1000 | Loss: 0.00001595
Iteration 134/1000 | Loss: 0.00001595
Iteration 135/1000 | Loss: 0.00001595
Iteration 136/1000 | Loss: 0.00001595
Iteration 137/1000 | Loss: 0.00001595
Iteration 138/1000 | Loss: 0.00001595
Iteration 139/1000 | Loss: 0.00001595
Iteration 140/1000 | Loss: 0.00001595
Iteration 141/1000 | Loss: 0.00001595
Iteration 142/1000 | Loss: 0.00001595
Iteration 143/1000 | Loss: 0.00001595
Iteration 144/1000 | Loss: 0.00001595
Iteration 145/1000 | Loss: 0.00001595
Iteration 146/1000 | Loss: 0.00001595
Iteration 147/1000 | Loss: 0.00001595
Iteration 148/1000 | Loss: 0.00001595
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.5951898603816517e-05, 1.5951898603816517e-05, 1.5951898603816517e-05, 1.5951898603816517e-05, 1.5951898603816517e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5951898603816517e-05

Optimization complete. Final v2v error: 3.3751635551452637 mm

Highest mean error: 3.5448532104492188 mm for frame 170

Lowest mean error: 3.182896614074707 mm for frame 102

Saving results

Total time: 98.19296264648438
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1028
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01043810
Iteration 2/25 | Loss: 0.00249583
Iteration 3/25 | Loss: 0.00195580
Iteration 4/25 | Loss: 0.00171003
Iteration 5/25 | Loss: 0.00184366
Iteration 6/25 | Loss: 0.00164603
Iteration 7/25 | Loss: 0.00137842
Iteration 8/25 | Loss: 0.00120928
Iteration 9/25 | Loss: 0.00106508
Iteration 10/25 | Loss: 0.00094708
Iteration 11/25 | Loss: 0.00087076
Iteration 12/25 | Loss: 0.00083543
Iteration 13/25 | Loss: 0.00081949
Iteration 14/25 | Loss: 0.00081625
Iteration 15/25 | Loss: 0.00081924
Iteration 16/25 | Loss: 0.00081374
Iteration 17/25 | Loss: 0.00079935
Iteration 18/25 | Loss: 0.00079143
Iteration 19/25 | Loss: 0.00078942
Iteration 20/25 | Loss: 0.00078872
Iteration 21/25 | Loss: 0.00078844
Iteration 22/25 | Loss: 0.00078823
Iteration 23/25 | Loss: 0.00078805
Iteration 24/25 | Loss: 0.00078791
Iteration 25/25 | Loss: 0.00078844

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43035209
Iteration 2/25 | Loss: 0.00033519
Iteration 3/25 | Loss: 0.00033517
Iteration 4/25 | Loss: 0.00033517
Iteration 5/25 | Loss: 0.00033517
Iteration 6/25 | Loss: 0.00033517
Iteration 7/25 | Loss: 0.00033517
Iteration 8/25 | Loss: 0.00033517
Iteration 9/25 | Loss: 0.00033517
Iteration 10/25 | Loss: 0.00033517
Iteration 11/25 | Loss: 0.00033517
Iteration 12/25 | Loss: 0.00033517
Iteration 13/25 | Loss: 0.00033517
Iteration 14/25 | Loss: 0.00033517
Iteration 15/25 | Loss: 0.00033517
Iteration 16/25 | Loss: 0.00033517
Iteration 17/25 | Loss: 0.00033517
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003351684135850519, 0.0003351684135850519, 0.0003351684135850519, 0.0003351684135850519, 0.0003351684135850519]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003351684135850519

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033517
Iteration 2/1000 | Loss: 0.00003472
Iteration 3/1000 | Loss: 0.00002810
Iteration 4/1000 | Loss: 0.00002551
Iteration 5/1000 | Loss: 0.00002394
Iteration 6/1000 | Loss: 0.00002282
Iteration 7/1000 | Loss: 0.00002183
Iteration 8/1000 | Loss: 0.00002143
Iteration 9/1000 | Loss: 0.00002093
Iteration 10/1000 | Loss: 0.00002057
Iteration 11/1000 | Loss: 0.00002032
Iteration 12/1000 | Loss: 0.00002021
Iteration 13/1000 | Loss: 0.00002009
Iteration 14/1000 | Loss: 0.00002004
Iteration 15/1000 | Loss: 0.00001992
Iteration 16/1000 | Loss: 0.00001992
Iteration 17/1000 | Loss: 0.00001992
Iteration 18/1000 | Loss: 0.00001991
Iteration 19/1000 | Loss: 0.00054481
Iteration 20/1000 | Loss: 0.00002086
Iteration 21/1000 | Loss: 0.00002014
Iteration 22/1000 | Loss: 0.00001912
Iteration 23/1000 | Loss: 0.00001844
Iteration 24/1000 | Loss: 0.00001823
Iteration 25/1000 | Loss: 0.00001815
Iteration 26/1000 | Loss: 0.00001813
Iteration 27/1000 | Loss: 0.00001812
Iteration 28/1000 | Loss: 0.00001810
Iteration 29/1000 | Loss: 0.00001810
Iteration 30/1000 | Loss: 0.00001809
Iteration 31/1000 | Loss: 0.00001809
Iteration 32/1000 | Loss: 0.00001808
Iteration 33/1000 | Loss: 0.00001806
Iteration 34/1000 | Loss: 0.00001805
Iteration 35/1000 | Loss: 0.00001805
Iteration 36/1000 | Loss: 0.00001804
Iteration 37/1000 | Loss: 0.00001804
Iteration 38/1000 | Loss: 0.00001804
Iteration 39/1000 | Loss: 0.00001804
Iteration 40/1000 | Loss: 0.00001804
Iteration 41/1000 | Loss: 0.00001804
Iteration 42/1000 | Loss: 0.00001803
Iteration 43/1000 | Loss: 0.00001803
Iteration 44/1000 | Loss: 0.00001800
Iteration 45/1000 | Loss: 0.00001799
Iteration 46/1000 | Loss: 0.00001799
Iteration 47/1000 | Loss: 0.00001799
Iteration 48/1000 | Loss: 0.00001799
Iteration 49/1000 | Loss: 0.00001798
Iteration 50/1000 | Loss: 0.00001798
Iteration 51/1000 | Loss: 0.00001798
Iteration 52/1000 | Loss: 0.00001797
Iteration 53/1000 | Loss: 0.00001797
Iteration 54/1000 | Loss: 0.00001797
Iteration 55/1000 | Loss: 0.00001797
Iteration 56/1000 | Loss: 0.00001797
Iteration 57/1000 | Loss: 0.00001797
Iteration 58/1000 | Loss: 0.00001796
Iteration 59/1000 | Loss: 0.00001796
Iteration 60/1000 | Loss: 0.00001796
Iteration 61/1000 | Loss: 0.00001796
Iteration 62/1000 | Loss: 0.00001796
Iteration 63/1000 | Loss: 0.00001796
Iteration 64/1000 | Loss: 0.00001796
Iteration 65/1000 | Loss: 0.00001796
Iteration 66/1000 | Loss: 0.00001796
Iteration 67/1000 | Loss: 0.00001796
Iteration 68/1000 | Loss: 0.00001796
Iteration 69/1000 | Loss: 0.00001796
Iteration 70/1000 | Loss: 0.00001796
Iteration 71/1000 | Loss: 0.00001796
Iteration 72/1000 | Loss: 0.00001796
Iteration 73/1000 | Loss: 0.00001796
Iteration 74/1000 | Loss: 0.00001796
Iteration 75/1000 | Loss: 0.00001796
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 75. Stopping optimization.
Last 5 losses: [1.79567068698816e-05, 1.79567068698816e-05, 1.79567068698816e-05, 1.79567068698816e-05, 1.79567068698816e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.79567068698816e-05

Optimization complete. Final v2v error: 3.5651447772979736 mm

Highest mean error: 4.420249938964844 mm for frame 166

Lowest mean error: 3.3833250999450684 mm for frame 11

Saving results

Total time: 86.79410529136658
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1071/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1071.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1071
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00397036
Iteration 2/25 | Loss: 0.00095503
Iteration 3/25 | Loss: 0.00082041
Iteration 4/25 | Loss: 0.00079511
Iteration 5/25 | Loss: 0.00078941
Iteration 6/25 | Loss: 0.00078818
Iteration 7/25 | Loss: 0.00078797
Iteration 8/25 | Loss: 0.00078797
Iteration 9/25 | Loss: 0.00078797
Iteration 10/25 | Loss: 0.00078797
Iteration 11/25 | Loss: 0.00078797
Iteration 12/25 | Loss: 0.00078797
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007879700278863311, 0.0007879700278863311, 0.0007879700278863311, 0.0007879700278863311, 0.0007879700278863311]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007879700278863311

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42903984
Iteration 2/25 | Loss: 0.00033647
Iteration 3/25 | Loss: 0.00033647
Iteration 4/25 | Loss: 0.00033647
Iteration 5/25 | Loss: 0.00033647
Iteration 6/25 | Loss: 0.00033647
Iteration 7/25 | Loss: 0.00033647
Iteration 8/25 | Loss: 0.00033647
Iteration 9/25 | Loss: 0.00033647
Iteration 10/25 | Loss: 0.00033647
Iteration 11/25 | Loss: 0.00033647
Iteration 12/25 | Loss: 0.00033647
Iteration 13/25 | Loss: 0.00033647
Iteration 14/25 | Loss: 0.00033647
Iteration 15/25 | Loss: 0.00033647
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.00033647031523287296, 0.00033647031523287296, 0.00033647031523287296, 0.00033647031523287296, 0.00033647031523287296]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00033647031523287296

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033647
Iteration 2/1000 | Loss: 0.00005825
Iteration 3/1000 | Loss: 0.00003713
Iteration 4/1000 | Loss: 0.00003286
Iteration 5/1000 | Loss: 0.00003091
Iteration 6/1000 | Loss: 0.00002924
Iteration 7/1000 | Loss: 0.00002827
Iteration 8/1000 | Loss: 0.00002739
Iteration 9/1000 | Loss: 0.00002682
Iteration 10/1000 | Loss: 0.00002650
Iteration 11/1000 | Loss: 0.00002623
Iteration 12/1000 | Loss: 0.00002595
Iteration 13/1000 | Loss: 0.00002568
Iteration 14/1000 | Loss: 0.00002548
Iteration 15/1000 | Loss: 0.00002545
Iteration 16/1000 | Loss: 0.00002541
Iteration 17/1000 | Loss: 0.00002541
Iteration 18/1000 | Loss: 0.00002540
Iteration 19/1000 | Loss: 0.00002534
Iteration 20/1000 | Loss: 0.00002534
Iteration 21/1000 | Loss: 0.00002533
Iteration 22/1000 | Loss: 0.00002532
Iteration 23/1000 | Loss: 0.00002532
Iteration 24/1000 | Loss: 0.00002531
Iteration 25/1000 | Loss: 0.00002524
Iteration 26/1000 | Loss: 0.00002516
Iteration 27/1000 | Loss: 0.00002516
Iteration 28/1000 | Loss: 0.00002515
Iteration 29/1000 | Loss: 0.00002514
Iteration 30/1000 | Loss: 0.00002514
Iteration 31/1000 | Loss: 0.00002513
Iteration 32/1000 | Loss: 0.00002513
Iteration 33/1000 | Loss: 0.00002513
Iteration 34/1000 | Loss: 0.00002513
Iteration 35/1000 | Loss: 0.00002513
Iteration 36/1000 | Loss: 0.00002513
Iteration 37/1000 | Loss: 0.00002513
Iteration 38/1000 | Loss: 0.00002512
Iteration 39/1000 | Loss: 0.00002512
Iteration 40/1000 | Loss: 0.00002512
Iteration 41/1000 | Loss: 0.00002512
Iteration 42/1000 | Loss: 0.00002512
Iteration 43/1000 | Loss: 0.00002511
Iteration 44/1000 | Loss: 0.00002511
Iteration 45/1000 | Loss: 0.00002511
Iteration 46/1000 | Loss: 0.00002510
Iteration 47/1000 | Loss: 0.00002510
Iteration 48/1000 | Loss: 0.00002510
Iteration 49/1000 | Loss: 0.00002510
Iteration 50/1000 | Loss: 0.00002510
Iteration 51/1000 | Loss: 0.00002510
Iteration 52/1000 | Loss: 0.00002509
Iteration 53/1000 | Loss: 0.00002509
Iteration 54/1000 | Loss: 0.00002509
Iteration 55/1000 | Loss: 0.00002509
Iteration 56/1000 | Loss: 0.00002509
Iteration 57/1000 | Loss: 0.00002509
Iteration 58/1000 | Loss: 0.00002509
Iteration 59/1000 | Loss: 0.00002508
Iteration 60/1000 | Loss: 0.00002508
Iteration 61/1000 | Loss: 0.00002508
Iteration 62/1000 | Loss: 0.00002508
Iteration 63/1000 | Loss: 0.00002508
Iteration 64/1000 | Loss: 0.00002508
Iteration 65/1000 | Loss: 0.00002508
Iteration 66/1000 | Loss: 0.00002508
Iteration 67/1000 | Loss: 0.00002508
Iteration 68/1000 | Loss: 0.00002508
Iteration 69/1000 | Loss: 0.00002507
Iteration 70/1000 | Loss: 0.00002507
Iteration 71/1000 | Loss: 0.00002507
Iteration 72/1000 | Loss: 0.00002507
Iteration 73/1000 | Loss: 0.00002506
Iteration 74/1000 | Loss: 0.00002506
Iteration 75/1000 | Loss: 0.00002506
Iteration 76/1000 | Loss: 0.00002506
Iteration 77/1000 | Loss: 0.00002506
Iteration 78/1000 | Loss: 0.00002505
Iteration 79/1000 | Loss: 0.00002505
Iteration 80/1000 | Loss: 0.00002505
Iteration 81/1000 | Loss: 0.00002505
Iteration 82/1000 | Loss: 0.00002504
Iteration 83/1000 | Loss: 0.00002504
Iteration 84/1000 | Loss: 0.00002504
Iteration 85/1000 | Loss: 0.00002504
Iteration 86/1000 | Loss: 0.00002504
Iteration 87/1000 | Loss: 0.00002504
Iteration 88/1000 | Loss: 0.00002504
Iteration 89/1000 | Loss: 0.00002504
Iteration 90/1000 | Loss: 0.00002503
Iteration 91/1000 | Loss: 0.00002503
Iteration 92/1000 | Loss: 0.00002503
Iteration 93/1000 | Loss: 0.00002503
Iteration 94/1000 | Loss: 0.00002502
Iteration 95/1000 | Loss: 0.00002502
Iteration 96/1000 | Loss: 0.00002502
Iteration 97/1000 | Loss: 0.00002502
Iteration 98/1000 | Loss: 0.00002502
Iteration 99/1000 | Loss: 0.00002502
Iteration 100/1000 | Loss: 0.00002502
Iteration 101/1000 | Loss: 0.00002501
Iteration 102/1000 | Loss: 0.00002501
Iteration 103/1000 | Loss: 0.00002501
Iteration 104/1000 | Loss: 0.00002501
Iteration 105/1000 | Loss: 0.00002501
Iteration 106/1000 | Loss: 0.00002500
Iteration 107/1000 | Loss: 0.00002500
Iteration 108/1000 | Loss: 0.00002500
Iteration 109/1000 | Loss: 0.00002500
Iteration 110/1000 | Loss: 0.00002500
Iteration 111/1000 | Loss: 0.00002500
Iteration 112/1000 | Loss: 0.00002499
Iteration 113/1000 | Loss: 0.00002499
Iteration 114/1000 | Loss: 0.00002499
Iteration 115/1000 | Loss: 0.00002499
Iteration 116/1000 | Loss: 0.00002499
Iteration 117/1000 | Loss: 0.00002498
Iteration 118/1000 | Loss: 0.00002498
Iteration 119/1000 | Loss: 0.00002498
Iteration 120/1000 | Loss: 0.00002498
Iteration 121/1000 | Loss: 0.00002498
Iteration 122/1000 | Loss: 0.00002497
Iteration 123/1000 | Loss: 0.00002497
Iteration 124/1000 | Loss: 0.00002497
Iteration 125/1000 | Loss: 0.00002497
Iteration 126/1000 | Loss: 0.00002497
Iteration 127/1000 | Loss: 0.00002497
Iteration 128/1000 | Loss: 0.00002496
Iteration 129/1000 | Loss: 0.00002496
Iteration 130/1000 | Loss: 0.00002496
Iteration 131/1000 | Loss: 0.00002496
Iteration 132/1000 | Loss: 0.00002496
Iteration 133/1000 | Loss: 0.00002496
Iteration 134/1000 | Loss: 0.00002496
Iteration 135/1000 | Loss: 0.00002495
Iteration 136/1000 | Loss: 0.00002495
Iteration 137/1000 | Loss: 0.00002495
Iteration 138/1000 | Loss: 0.00002495
Iteration 139/1000 | Loss: 0.00002495
Iteration 140/1000 | Loss: 0.00002494
Iteration 141/1000 | Loss: 0.00002494
Iteration 142/1000 | Loss: 0.00002494
Iteration 143/1000 | Loss: 0.00002494
Iteration 144/1000 | Loss: 0.00002494
Iteration 145/1000 | Loss: 0.00002494
Iteration 146/1000 | Loss: 0.00002493
Iteration 147/1000 | Loss: 0.00002493
Iteration 148/1000 | Loss: 0.00002493
Iteration 149/1000 | Loss: 0.00002493
Iteration 150/1000 | Loss: 0.00002493
Iteration 151/1000 | Loss: 0.00002493
Iteration 152/1000 | Loss: 0.00002493
Iteration 153/1000 | Loss: 0.00002493
Iteration 154/1000 | Loss: 0.00002493
Iteration 155/1000 | Loss: 0.00002493
Iteration 156/1000 | Loss: 0.00002493
Iteration 157/1000 | Loss: 0.00002493
Iteration 158/1000 | Loss: 0.00002493
Iteration 159/1000 | Loss: 0.00002493
Iteration 160/1000 | Loss: 0.00002493
Iteration 161/1000 | Loss: 0.00002493
Iteration 162/1000 | Loss: 0.00002493
Iteration 163/1000 | Loss: 0.00002493
Iteration 164/1000 | Loss: 0.00002493
Iteration 165/1000 | Loss: 0.00002493
Iteration 166/1000 | Loss: 0.00002493
Iteration 167/1000 | Loss: 0.00002493
Iteration 168/1000 | Loss: 0.00002493
Iteration 169/1000 | Loss: 0.00002493
Iteration 170/1000 | Loss: 0.00002493
Iteration 171/1000 | Loss: 0.00002493
Iteration 172/1000 | Loss: 0.00002493
Iteration 173/1000 | Loss: 0.00002493
Iteration 174/1000 | Loss: 0.00002493
Iteration 175/1000 | Loss: 0.00002493
Iteration 176/1000 | Loss: 0.00002493
Iteration 177/1000 | Loss: 0.00002493
Iteration 178/1000 | Loss: 0.00002493
Iteration 179/1000 | Loss: 0.00002493
Iteration 180/1000 | Loss: 0.00002493
Iteration 181/1000 | Loss: 0.00002493
Iteration 182/1000 | Loss: 0.00002493
Iteration 183/1000 | Loss: 0.00002493
Iteration 184/1000 | Loss: 0.00002493
Iteration 185/1000 | Loss: 0.00002493
Iteration 186/1000 | Loss: 0.00002493
Iteration 187/1000 | Loss: 0.00002493
Iteration 188/1000 | Loss: 0.00002493
Iteration 189/1000 | Loss: 0.00002493
Iteration 190/1000 | Loss: 0.00002493
Iteration 191/1000 | Loss: 0.00002493
Iteration 192/1000 | Loss: 0.00002493
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 192. Stopping optimization.
Last 5 losses: [2.492584280844312e-05, 2.492584280844312e-05, 2.492584280844312e-05, 2.492584280844312e-05, 2.492584280844312e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.492584280844312e-05

Optimization complete. Final v2v error: 4.0611772537231445 mm

Highest mean error: 4.2649078369140625 mm for frame 106

Lowest mean error: 3.871843099594116 mm for frame 43

Saving results

Total time: 43.24116110801697
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1085
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00896471
Iteration 2/25 | Loss: 0.00171135
Iteration 3/25 | Loss: 0.00108375
Iteration 4/25 | Loss: 0.00096187
Iteration 5/25 | Loss: 0.00094284
Iteration 6/25 | Loss: 0.00090353
Iteration 7/25 | Loss: 0.00085755
Iteration 8/25 | Loss: 0.00084245
Iteration 9/25 | Loss: 0.00083793
Iteration 10/25 | Loss: 0.00083743
Iteration 11/25 | Loss: 0.00083834
Iteration 12/25 | Loss: 0.00083480
Iteration 13/25 | Loss: 0.00083506
Iteration 14/25 | Loss: 0.00083462
Iteration 15/25 | Loss: 0.00083322
Iteration 16/25 | Loss: 0.00083051
Iteration 17/25 | Loss: 0.00082922
Iteration 18/25 | Loss: 0.00082892
Iteration 19/25 | Loss: 0.00082881
Iteration 20/25 | Loss: 0.00082880
Iteration 21/25 | Loss: 0.00082880
Iteration 22/25 | Loss: 0.00082880
Iteration 23/25 | Loss: 0.00082880
Iteration 24/25 | Loss: 0.00082879
Iteration 25/25 | Loss: 0.00082879

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.66578341
Iteration 2/25 | Loss: 0.00046481
Iteration 3/25 | Loss: 0.00037312
Iteration 4/25 | Loss: 0.00037312
Iteration 5/25 | Loss: 0.00037312
Iteration 6/25 | Loss: 0.00037312
Iteration 7/25 | Loss: 0.00037312
Iteration 8/25 | Loss: 0.00037312
Iteration 9/25 | Loss: 0.00037312
Iteration 10/25 | Loss: 0.00037312
Iteration 11/25 | Loss: 0.00037312
Iteration 12/25 | Loss: 0.00037312
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.00037312257336452603, 0.00037312257336452603, 0.00037312257336452603, 0.00037312257336452603, 0.00037312257336452603]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00037312257336452603

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00037312
Iteration 2/1000 | Loss: 0.00003974
Iteration 3/1000 | Loss: 0.00003069
Iteration 4/1000 | Loss: 0.00002750
Iteration 5/1000 | Loss: 0.00002629
Iteration 6/1000 | Loss: 0.00005482
Iteration 7/1000 | Loss: 0.00002487
Iteration 8/1000 | Loss: 0.00004833
Iteration 9/1000 | Loss: 0.00002426
Iteration 10/1000 | Loss: 0.00002421
Iteration 11/1000 | Loss: 0.00002390
Iteration 12/1000 | Loss: 0.00008639
Iteration 13/1000 | Loss: 0.00002358
Iteration 14/1000 | Loss: 0.00002354
Iteration 15/1000 | Loss: 0.00002339
Iteration 16/1000 | Loss: 0.00002327
Iteration 17/1000 | Loss: 0.00002324
Iteration 18/1000 | Loss: 0.00002323
Iteration 19/1000 | Loss: 0.00002314
Iteration 20/1000 | Loss: 0.00002313
Iteration 21/1000 | Loss: 0.00002313
Iteration 22/1000 | Loss: 0.00002311
Iteration 23/1000 | Loss: 0.00002311
Iteration 24/1000 | Loss: 0.00002310
Iteration 25/1000 | Loss: 0.00002310
Iteration 26/1000 | Loss: 0.00002310
Iteration 27/1000 | Loss: 0.00002306
Iteration 28/1000 | Loss: 0.00002305
Iteration 29/1000 | Loss: 0.00002305
Iteration 30/1000 | Loss: 0.00002305
Iteration 31/1000 | Loss: 0.00002304
Iteration 32/1000 | Loss: 0.00002303
Iteration 33/1000 | Loss: 0.00002303
Iteration 34/1000 | Loss: 0.00002303
Iteration 35/1000 | Loss: 0.00002302
Iteration 36/1000 | Loss: 0.00002302
Iteration 37/1000 | Loss: 0.00002302
Iteration 38/1000 | Loss: 0.00002301
Iteration 39/1000 | Loss: 0.00002301
Iteration 40/1000 | Loss: 0.00002301
Iteration 41/1000 | Loss: 0.00002301
Iteration 42/1000 | Loss: 0.00002301
Iteration 43/1000 | Loss: 0.00002301
Iteration 44/1000 | Loss: 0.00002300
Iteration 45/1000 | Loss: 0.00002300
Iteration 46/1000 | Loss: 0.00002300
Iteration 47/1000 | Loss: 0.00002300
Iteration 48/1000 | Loss: 0.00002300
Iteration 49/1000 | Loss: 0.00002300
Iteration 50/1000 | Loss: 0.00002300
Iteration 51/1000 | Loss: 0.00002300
Iteration 52/1000 | Loss: 0.00002300
Iteration 53/1000 | Loss: 0.00002300
Iteration 54/1000 | Loss: 0.00002300
Iteration 55/1000 | Loss: 0.00002300
Iteration 56/1000 | Loss: 0.00002300
Iteration 57/1000 | Loss: 0.00002300
Iteration 58/1000 | Loss: 0.00002299
Iteration 59/1000 | Loss: 0.00002299
Iteration 60/1000 | Loss: 0.00002299
Iteration 61/1000 | Loss: 0.00002299
Iteration 62/1000 | Loss: 0.00002299
Iteration 63/1000 | Loss: 0.00002299
Iteration 64/1000 | Loss: 0.00002299
Iteration 65/1000 | Loss: 0.00002299
Iteration 66/1000 | Loss: 0.00002298
Iteration 67/1000 | Loss: 0.00002298
Iteration 68/1000 | Loss: 0.00002298
Iteration 69/1000 | Loss: 0.00002298
Iteration 70/1000 | Loss: 0.00002298
Iteration 71/1000 | Loss: 0.00002298
Iteration 72/1000 | Loss: 0.00002297
Iteration 73/1000 | Loss: 0.00002297
Iteration 74/1000 | Loss: 0.00002297
Iteration 75/1000 | Loss: 0.00002297
Iteration 76/1000 | Loss: 0.00002297
Iteration 77/1000 | Loss: 0.00002297
Iteration 78/1000 | Loss: 0.00002297
Iteration 79/1000 | Loss: 0.00002297
Iteration 80/1000 | Loss: 0.00002297
Iteration 81/1000 | Loss: 0.00002297
Iteration 82/1000 | Loss: 0.00002296
Iteration 83/1000 | Loss: 0.00002296
Iteration 84/1000 | Loss: 0.00002296
Iteration 85/1000 | Loss: 0.00002295
Iteration 86/1000 | Loss: 0.00002295
Iteration 87/1000 | Loss: 0.00002295
Iteration 88/1000 | Loss: 0.00002295
Iteration 89/1000 | Loss: 0.00002295
Iteration 90/1000 | Loss: 0.00002295
Iteration 91/1000 | Loss: 0.00002294
Iteration 92/1000 | Loss: 0.00002294
Iteration 93/1000 | Loss: 0.00002294
Iteration 94/1000 | Loss: 0.00002294
Iteration 95/1000 | Loss: 0.00002294
Iteration 96/1000 | Loss: 0.00002293
Iteration 97/1000 | Loss: 0.00002293
Iteration 98/1000 | Loss: 0.00002293
Iteration 99/1000 | Loss: 0.00002293
Iteration 100/1000 | Loss: 0.00002293
Iteration 101/1000 | Loss: 0.00002293
Iteration 102/1000 | Loss: 0.00002293
Iteration 103/1000 | Loss: 0.00002293
Iteration 104/1000 | Loss: 0.00002293
Iteration 105/1000 | Loss: 0.00002293
Iteration 106/1000 | Loss: 0.00002293
Iteration 107/1000 | Loss: 0.00002293
Iteration 108/1000 | Loss: 0.00002293
Iteration 109/1000 | Loss: 0.00002292
Iteration 110/1000 | Loss: 0.00002292
Iteration 111/1000 | Loss: 0.00002292
Iteration 112/1000 | Loss: 0.00002292
Iteration 113/1000 | Loss: 0.00002292
Iteration 114/1000 | Loss: 0.00002292
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 114. Stopping optimization.
Last 5 losses: [2.2924656150280498e-05, 2.2924656150280498e-05, 2.2924656150280498e-05, 2.2924656150280498e-05, 2.2924656150280498e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2924656150280498e-05

Optimization complete. Final v2v error: 3.9871339797973633 mm

Highest mean error: 4.528464317321777 mm for frame 189

Lowest mean error: 3.30871844291687 mm for frame 130

Saving results

Total time: 72.63464331626892
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00935385
Iteration 2/25 | Loss: 0.00153220
Iteration 3/25 | Loss: 0.00094983
Iteration 4/25 | Loss: 0.00088764
Iteration 5/25 | Loss: 0.00086577
Iteration 6/25 | Loss: 0.00085865
Iteration 7/25 | Loss: 0.00085769
Iteration 8/25 | Loss: 0.00085769
Iteration 9/25 | Loss: 0.00085769
Iteration 10/25 | Loss: 0.00085769
Iteration 11/25 | Loss: 0.00085769
Iteration 12/25 | Loss: 0.00085769
Iteration 13/25 | Loss: 0.00085769
Iteration 14/25 | Loss: 0.00085769
Iteration 15/25 | Loss: 0.00085769
Iteration 16/25 | Loss: 0.00085769
Iteration 17/25 | Loss: 0.00085769
Iteration 18/25 | Loss: 0.00085769
Iteration 19/25 | Loss: 0.00085769
Iteration 20/25 | Loss: 0.00085769
Iteration 21/25 | Loss: 0.00085769
Iteration 22/25 | Loss: 0.00085769
Iteration 23/25 | Loss: 0.00085769
Iteration 24/25 | Loss: 0.00085769
Iteration 25/25 | Loss: 0.00085769

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.11570287
Iteration 2/25 | Loss: 0.00032675
Iteration 3/25 | Loss: 0.00032675
Iteration 4/25 | Loss: 0.00032675
Iteration 5/25 | Loss: 0.00032675
Iteration 6/25 | Loss: 0.00032675
Iteration 7/25 | Loss: 0.00032675
Iteration 8/25 | Loss: 0.00032675
Iteration 9/25 | Loss: 0.00032675
Iteration 10/25 | Loss: 0.00032675
Iteration 11/25 | Loss: 0.00032675
Iteration 12/25 | Loss: 0.00032675
Iteration 13/25 | Loss: 0.00032675
Iteration 14/25 | Loss: 0.00032675
Iteration 15/25 | Loss: 0.00032675
Iteration 16/25 | Loss: 0.00032675
Iteration 17/25 | Loss: 0.00032675
Iteration 18/25 | Loss: 0.00032675
Iteration 19/25 | Loss: 0.00032675
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003267454740125686, 0.0003267454740125686, 0.0003267454740125686, 0.0003267454740125686, 0.0003267454740125686]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003267454740125686

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032675
Iteration 2/1000 | Loss: 0.00005106
Iteration 3/1000 | Loss: 0.00003820
Iteration 4/1000 | Loss: 0.00003376
Iteration 5/1000 | Loss: 0.00003219
Iteration 6/1000 | Loss: 0.00003062
Iteration 7/1000 | Loss: 0.00002960
Iteration 8/1000 | Loss: 0.00002869
Iteration 9/1000 | Loss: 0.00002823
Iteration 10/1000 | Loss: 0.00002790
Iteration 11/1000 | Loss: 0.00002766
Iteration 12/1000 | Loss: 0.00002747
Iteration 13/1000 | Loss: 0.00002733
Iteration 14/1000 | Loss: 0.00002724
Iteration 15/1000 | Loss: 0.00002720
Iteration 16/1000 | Loss: 0.00002719
Iteration 17/1000 | Loss: 0.00002715
Iteration 18/1000 | Loss: 0.00002712
Iteration 19/1000 | Loss: 0.00002711
Iteration 20/1000 | Loss: 0.00002711
Iteration 21/1000 | Loss: 0.00002710
Iteration 22/1000 | Loss: 0.00002710
Iteration 23/1000 | Loss: 0.00002709
Iteration 24/1000 | Loss: 0.00002709
Iteration 25/1000 | Loss: 0.00002708
Iteration 26/1000 | Loss: 0.00002706
Iteration 27/1000 | Loss: 0.00002705
Iteration 28/1000 | Loss: 0.00002705
Iteration 29/1000 | Loss: 0.00002703
Iteration 30/1000 | Loss: 0.00002703
Iteration 31/1000 | Loss: 0.00002699
Iteration 32/1000 | Loss: 0.00002696
Iteration 33/1000 | Loss: 0.00002690
Iteration 34/1000 | Loss: 0.00002689
Iteration 35/1000 | Loss: 0.00002689
Iteration 36/1000 | Loss: 0.00002688
Iteration 37/1000 | Loss: 0.00002687
Iteration 38/1000 | Loss: 0.00002685
Iteration 39/1000 | Loss: 0.00002684
Iteration 40/1000 | Loss: 0.00002684
Iteration 41/1000 | Loss: 0.00002683
Iteration 42/1000 | Loss: 0.00002682
Iteration 43/1000 | Loss: 0.00002681
Iteration 44/1000 | Loss: 0.00002680
Iteration 45/1000 | Loss: 0.00002677
Iteration 46/1000 | Loss: 0.00002671
Iteration 47/1000 | Loss: 0.00002670
Iteration 48/1000 | Loss: 0.00002669
Iteration 49/1000 | Loss: 0.00002666
Iteration 50/1000 | Loss: 0.00002665
Iteration 51/1000 | Loss: 0.00002665
Iteration 52/1000 | Loss: 0.00002665
Iteration 53/1000 | Loss: 0.00002664
Iteration 54/1000 | Loss: 0.00002664
Iteration 55/1000 | Loss: 0.00002663
Iteration 56/1000 | Loss: 0.00002663
Iteration 57/1000 | Loss: 0.00002662
Iteration 58/1000 | Loss: 0.00002661
Iteration 59/1000 | Loss: 0.00002661
Iteration 60/1000 | Loss: 0.00002661
Iteration 61/1000 | Loss: 0.00002660
Iteration 62/1000 | Loss: 0.00002660
Iteration 63/1000 | Loss: 0.00002659
Iteration 64/1000 | Loss: 0.00002659
Iteration 65/1000 | Loss: 0.00002659
Iteration 66/1000 | Loss: 0.00002659
Iteration 67/1000 | Loss: 0.00002658
Iteration 68/1000 | Loss: 0.00002658
Iteration 69/1000 | Loss: 0.00002658
Iteration 70/1000 | Loss: 0.00002658
Iteration 71/1000 | Loss: 0.00002657
Iteration 72/1000 | Loss: 0.00002657
Iteration 73/1000 | Loss: 0.00002657
Iteration 74/1000 | Loss: 0.00002657
Iteration 75/1000 | Loss: 0.00002657
Iteration 76/1000 | Loss: 0.00002656
Iteration 77/1000 | Loss: 0.00002656
Iteration 78/1000 | Loss: 0.00002656
Iteration 79/1000 | Loss: 0.00002656
Iteration 80/1000 | Loss: 0.00002656
Iteration 81/1000 | Loss: 0.00002656
Iteration 82/1000 | Loss: 0.00002656
Iteration 83/1000 | Loss: 0.00002656
Iteration 84/1000 | Loss: 0.00002655
Iteration 85/1000 | Loss: 0.00002655
Iteration 86/1000 | Loss: 0.00002655
Iteration 87/1000 | Loss: 0.00002655
Iteration 88/1000 | Loss: 0.00002655
Iteration 89/1000 | Loss: 0.00002655
Iteration 90/1000 | Loss: 0.00002655
Iteration 91/1000 | Loss: 0.00002655
Iteration 92/1000 | Loss: 0.00002655
Iteration 93/1000 | Loss: 0.00002655
Iteration 94/1000 | Loss: 0.00002655
Iteration 95/1000 | Loss: 0.00002654
Iteration 96/1000 | Loss: 0.00002654
Iteration 97/1000 | Loss: 0.00002654
Iteration 98/1000 | Loss: 0.00002654
Iteration 99/1000 | Loss: 0.00002654
Iteration 100/1000 | Loss: 0.00002654
Iteration 101/1000 | Loss: 0.00002654
Iteration 102/1000 | Loss: 0.00002653
Iteration 103/1000 | Loss: 0.00002653
Iteration 104/1000 | Loss: 0.00002653
Iteration 105/1000 | Loss: 0.00002653
Iteration 106/1000 | Loss: 0.00002653
Iteration 107/1000 | Loss: 0.00002653
Iteration 108/1000 | Loss: 0.00002653
Iteration 109/1000 | Loss: 0.00002653
Iteration 110/1000 | Loss: 0.00002653
Iteration 111/1000 | Loss: 0.00002653
Iteration 112/1000 | Loss: 0.00002653
Iteration 113/1000 | Loss: 0.00002653
Iteration 114/1000 | Loss: 0.00002653
Iteration 115/1000 | Loss: 0.00002653
Iteration 116/1000 | Loss: 0.00002652
Iteration 117/1000 | Loss: 0.00002652
Iteration 118/1000 | Loss: 0.00002652
Iteration 119/1000 | Loss: 0.00002652
Iteration 120/1000 | Loss: 0.00002652
Iteration 121/1000 | Loss: 0.00002652
Iteration 122/1000 | Loss: 0.00002652
Iteration 123/1000 | Loss: 0.00002651
Iteration 124/1000 | Loss: 0.00002651
Iteration 125/1000 | Loss: 0.00002651
Iteration 126/1000 | Loss: 0.00002651
Iteration 127/1000 | Loss: 0.00002651
Iteration 128/1000 | Loss: 0.00002651
Iteration 129/1000 | Loss: 0.00002651
Iteration 130/1000 | Loss: 0.00002651
Iteration 131/1000 | Loss: 0.00002651
Iteration 132/1000 | Loss: 0.00002651
Iteration 133/1000 | Loss: 0.00002651
Iteration 134/1000 | Loss: 0.00002651
Iteration 135/1000 | Loss: 0.00002650
Iteration 136/1000 | Loss: 0.00002650
Iteration 137/1000 | Loss: 0.00002650
Iteration 138/1000 | Loss: 0.00002650
Iteration 139/1000 | Loss: 0.00002650
Iteration 140/1000 | Loss: 0.00002650
Iteration 141/1000 | Loss: 0.00002650
Iteration 142/1000 | Loss: 0.00002650
Iteration 143/1000 | Loss: 0.00002650
Iteration 144/1000 | Loss: 0.00002650
Iteration 145/1000 | Loss: 0.00002650
Iteration 146/1000 | Loss: 0.00002650
Iteration 147/1000 | Loss: 0.00002650
Iteration 148/1000 | Loss: 0.00002650
Iteration 149/1000 | Loss: 0.00002650
Iteration 150/1000 | Loss: 0.00002650
Iteration 151/1000 | Loss: 0.00002650
Iteration 152/1000 | Loss: 0.00002650
Iteration 153/1000 | Loss: 0.00002650
Iteration 154/1000 | Loss: 0.00002650
Iteration 155/1000 | Loss: 0.00002650
Iteration 156/1000 | Loss: 0.00002650
Iteration 157/1000 | Loss: 0.00002650
Iteration 158/1000 | Loss: 0.00002650
Iteration 159/1000 | Loss: 0.00002650
Iteration 160/1000 | Loss: 0.00002650
Iteration 161/1000 | Loss: 0.00002650
Iteration 162/1000 | Loss: 0.00002650
Iteration 163/1000 | Loss: 0.00002650
Iteration 164/1000 | Loss: 0.00002650
Iteration 165/1000 | Loss: 0.00002650
Iteration 166/1000 | Loss: 0.00002650
Iteration 167/1000 | Loss: 0.00002650
Iteration 168/1000 | Loss: 0.00002650
Iteration 169/1000 | Loss: 0.00002650
Iteration 170/1000 | Loss: 0.00002650
Iteration 171/1000 | Loss: 0.00002650
Iteration 172/1000 | Loss: 0.00002650
Iteration 173/1000 | Loss: 0.00002650
Iteration 174/1000 | Loss: 0.00002650
Iteration 175/1000 | Loss: 0.00002650
Iteration 176/1000 | Loss: 0.00002650
Iteration 177/1000 | Loss: 0.00002650
Iteration 178/1000 | Loss: 0.00002650
Iteration 179/1000 | Loss: 0.00002650
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [2.649617636052426e-05, 2.649617636052426e-05, 2.649617636052426e-05, 2.649617636052426e-05, 2.649617636052426e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.649617636052426e-05

Optimization complete. Final v2v error: 4.185295581817627 mm

Highest mean error: 5.408029079437256 mm for frame 103

Lowest mean error: 3.3961315155029297 mm for frame 41

Saving results

Total time: 47.16547918319702
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1070
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00393082
Iteration 2/25 | Loss: 0.00083231
Iteration 3/25 | Loss: 0.00073537
Iteration 4/25 | Loss: 0.00071503
Iteration 5/25 | Loss: 0.00070710
Iteration 6/25 | Loss: 0.00070543
Iteration 7/25 | Loss: 0.00070487
Iteration 8/25 | Loss: 0.00070487
Iteration 9/25 | Loss: 0.00070487
Iteration 10/25 | Loss: 0.00070487
Iteration 11/25 | Loss: 0.00070487
Iteration 12/25 | Loss: 0.00070487
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007048726547509432, 0.0007048726547509432, 0.0007048726547509432, 0.0007048726547509432, 0.0007048726547509432]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007048726547509432

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.00558662
Iteration 2/25 | Loss: 0.00029693
Iteration 3/25 | Loss: 0.00029693
Iteration 4/25 | Loss: 0.00029692
Iteration 5/25 | Loss: 0.00029692
Iteration 6/25 | Loss: 0.00029692
Iteration 7/25 | Loss: 0.00029692
Iteration 8/25 | Loss: 0.00029692
Iteration 9/25 | Loss: 0.00029692
Iteration 10/25 | Loss: 0.00029692
Iteration 11/25 | Loss: 0.00029692
Iteration 12/25 | Loss: 0.00029692
Iteration 13/25 | Loss: 0.00029692
Iteration 14/25 | Loss: 0.00029692
Iteration 15/25 | Loss: 0.00029692
Iteration 16/25 | Loss: 0.00029692
Iteration 17/25 | Loss: 0.00029692
Iteration 18/25 | Loss: 0.00029692
Iteration 19/25 | Loss: 0.00029692
Iteration 20/25 | Loss: 0.00029692
Iteration 21/25 | Loss: 0.00029692
Iteration 22/25 | Loss: 0.00029692
Iteration 23/25 | Loss: 0.00029692
Iteration 24/25 | Loss: 0.00029692
Iteration 25/25 | Loss: 0.00029692

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029692
Iteration 2/1000 | Loss: 0.00002381
Iteration 3/1000 | Loss: 0.00001660
Iteration 4/1000 | Loss: 0.00001538
Iteration 5/1000 | Loss: 0.00001448
Iteration 6/1000 | Loss: 0.00001388
Iteration 7/1000 | Loss: 0.00001350
Iteration 8/1000 | Loss: 0.00001319
Iteration 9/1000 | Loss: 0.00001301
Iteration 10/1000 | Loss: 0.00001287
Iteration 11/1000 | Loss: 0.00001275
Iteration 12/1000 | Loss: 0.00001265
Iteration 13/1000 | Loss: 0.00001261
Iteration 14/1000 | Loss: 0.00001261
Iteration 15/1000 | Loss: 0.00001260
Iteration 16/1000 | Loss: 0.00001260
Iteration 17/1000 | Loss: 0.00001259
Iteration 18/1000 | Loss: 0.00001258
Iteration 19/1000 | Loss: 0.00001258
Iteration 20/1000 | Loss: 0.00001253
Iteration 21/1000 | Loss: 0.00001252
Iteration 22/1000 | Loss: 0.00001251
Iteration 23/1000 | Loss: 0.00001248
Iteration 24/1000 | Loss: 0.00001248
Iteration 25/1000 | Loss: 0.00001248
Iteration 26/1000 | Loss: 0.00001248
Iteration 27/1000 | Loss: 0.00001248
Iteration 28/1000 | Loss: 0.00001248
Iteration 29/1000 | Loss: 0.00001248
Iteration 30/1000 | Loss: 0.00001248
Iteration 31/1000 | Loss: 0.00001248
Iteration 32/1000 | Loss: 0.00001248
Iteration 33/1000 | Loss: 0.00001248
Iteration 34/1000 | Loss: 0.00001247
Iteration 35/1000 | Loss: 0.00001245
Iteration 36/1000 | Loss: 0.00001244
Iteration 37/1000 | Loss: 0.00001244
Iteration 38/1000 | Loss: 0.00001244
Iteration 39/1000 | Loss: 0.00001244
Iteration 40/1000 | Loss: 0.00001244
Iteration 41/1000 | Loss: 0.00001243
Iteration 42/1000 | Loss: 0.00001243
Iteration 43/1000 | Loss: 0.00001243
Iteration 44/1000 | Loss: 0.00001243
Iteration 45/1000 | Loss: 0.00001243
Iteration 46/1000 | Loss: 0.00001243
Iteration 47/1000 | Loss: 0.00001243
Iteration 48/1000 | Loss: 0.00001243
Iteration 49/1000 | Loss: 0.00001243
Iteration 50/1000 | Loss: 0.00001243
Iteration 51/1000 | Loss: 0.00001242
Iteration 52/1000 | Loss: 0.00001242
Iteration 53/1000 | Loss: 0.00001242
Iteration 54/1000 | Loss: 0.00001241
Iteration 55/1000 | Loss: 0.00001240
Iteration 56/1000 | Loss: 0.00001240
Iteration 57/1000 | Loss: 0.00001240
Iteration 58/1000 | Loss: 0.00001239
Iteration 59/1000 | Loss: 0.00001239
Iteration 60/1000 | Loss: 0.00001239
Iteration 61/1000 | Loss: 0.00001239
Iteration 62/1000 | Loss: 0.00001239
Iteration 63/1000 | Loss: 0.00001239
Iteration 64/1000 | Loss: 0.00001239
Iteration 65/1000 | Loss: 0.00001239
Iteration 66/1000 | Loss: 0.00001238
Iteration 67/1000 | Loss: 0.00001238
Iteration 68/1000 | Loss: 0.00001237
Iteration 69/1000 | Loss: 0.00001237
Iteration 70/1000 | Loss: 0.00001237
Iteration 71/1000 | Loss: 0.00001236
Iteration 72/1000 | Loss: 0.00001236
Iteration 73/1000 | Loss: 0.00001236
Iteration 74/1000 | Loss: 0.00001235
Iteration 75/1000 | Loss: 0.00001235
Iteration 76/1000 | Loss: 0.00001235
Iteration 77/1000 | Loss: 0.00001234
Iteration 78/1000 | Loss: 0.00001234
Iteration 79/1000 | Loss: 0.00001234
Iteration 80/1000 | Loss: 0.00001233
Iteration 81/1000 | Loss: 0.00001233
Iteration 82/1000 | Loss: 0.00001233
Iteration 83/1000 | Loss: 0.00001232
Iteration 84/1000 | Loss: 0.00001232
Iteration 85/1000 | Loss: 0.00001232
Iteration 86/1000 | Loss: 0.00001231
Iteration 87/1000 | Loss: 0.00001231
Iteration 88/1000 | Loss: 0.00001231
Iteration 89/1000 | Loss: 0.00001230
Iteration 90/1000 | Loss: 0.00001230
Iteration 91/1000 | Loss: 0.00001229
Iteration 92/1000 | Loss: 0.00001229
Iteration 93/1000 | Loss: 0.00001228
Iteration 94/1000 | Loss: 0.00001227
Iteration 95/1000 | Loss: 0.00001227
Iteration 96/1000 | Loss: 0.00001227
Iteration 97/1000 | Loss: 0.00001227
Iteration 98/1000 | Loss: 0.00001226
Iteration 99/1000 | Loss: 0.00001226
Iteration 100/1000 | Loss: 0.00001226
Iteration 101/1000 | Loss: 0.00001226
Iteration 102/1000 | Loss: 0.00001226
Iteration 103/1000 | Loss: 0.00001225
Iteration 104/1000 | Loss: 0.00001225
Iteration 105/1000 | Loss: 0.00001225
Iteration 106/1000 | Loss: 0.00001225
Iteration 107/1000 | Loss: 0.00001224
Iteration 108/1000 | Loss: 0.00001224
Iteration 109/1000 | Loss: 0.00001224
Iteration 110/1000 | Loss: 0.00001223
Iteration 111/1000 | Loss: 0.00001223
Iteration 112/1000 | Loss: 0.00001223
Iteration 113/1000 | Loss: 0.00001223
Iteration 114/1000 | Loss: 0.00001223
Iteration 115/1000 | Loss: 0.00001222
Iteration 116/1000 | Loss: 0.00001222
Iteration 117/1000 | Loss: 0.00001222
Iteration 118/1000 | Loss: 0.00001222
Iteration 119/1000 | Loss: 0.00001222
Iteration 120/1000 | Loss: 0.00001222
Iteration 121/1000 | Loss: 0.00001222
Iteration 122/1000 | Loss: 0.00001222
Iteration 123/1000 | Loss: 0.00001222
Iteration 124/1000 | Loss: 0.00001222
Iteration 125/1000 | Loss: 0.00001222
Iteration 126/1000 | Loss: 0.00001222
Iteration 127/1000 | Loss: 0.00001221
Iteration 128/1000 | Loss: 0.00001221
Iteration 129/1000 | Loss: 0.00001221
Iteration 130/1000 | Loss: 0.00001221
Iteration 131/1000 | Loss: 0.00001220
Iteration 132/1000 | Loss: 0.00001220
Iteration 133/1000 | Loss: 0.00001220
Iteration 134/1000 | Loss: 0.00001220
Iteration 135/1000 | Loss: 0.00001220
Iteration 136/1000 | Loss: 0.00001220
Iteration 137/1000 | Loss: 0.00001220
Iteration 138/1000 | Loss: 0.00001220
Iteration 139/1000 | Loss: 0.00001219
Iteration 140/1000 | Loss: 0.00001219
Iteration 141/1000 | Loss: 0.00001219
Iteration 142/1000 | Loss: 0.00001219
Iteration 143/1000 | Loss: 0.00001219
Iteration 144/1000 | Loss: 0.00001219
Iteration 145/1000 | Loss: 0.00001218
Iteration 146/1000 | Loss: 0.00001218
Iteration 147/1000 | Loss: 0.00001218
Iteration 148/1000 | Loss: 0.00001218
Iteration 149/1000 | Loss: 0.00001218
Iteration 150/1000 | Loss: 0.00001218
Iteration 151/1000 | Loss: 0.00001218
Iteration 152/1000 | Loss: 0.00001218
Iteration 153/1000 | Loss: 0.00001218
Iteration 154/1000 | Loss: 0.00001218
Iteration 155/1000 | Loss: 0.00001217
Iteration 156/1000 | Loss: 0.00001217
Iteration 157/1000 | Loss: 0.00001217
Iteration 158/1000 | Loss: 0.00001217
Iteration 159/1000 | Loss: 0.00001217
Iteration 160/1000 | Loss: 0.00001217
Iteration 161/1000 | Loss: 0.00001217
Iteration 162/1000 | Loss: 0.00001217
Iteration 163/1000 | Loss: 0.00001217
Iteration 164/1000 | Loss: 0.00001217
Iteration 165/1000 | Loss: 0.00001217
Iteration 166/1000 | Loss: 0.00001217
Iteration 167/1000 | Loss: 0.00001217
Iteration 168/1000 | Loss: 0.00001217
Iteration 169/1000 | Loss: 0.00001217
Iteration 170/1000 | Loss: 0.00001216
Iteration 171/1000 | Loss: 0.00001216
Iteration 172/1000 | Loss: 0.00001216
Iteration 173/1000 | Loss: 0.00001216
Iteration 174/1000 | Loss: 0.00001216
Iteration 175/1000 | Loss: 0.00001216
Iteration 176/1000 | Loss: 0.00001216
Iteration 177/1000 | Loss: 0.00001216
Iteration 178/1000 | Loss: 0.00001216
Iteration 179/1000 | Loss: 0.00001215
Iteration 180/1000 | Loss: 0.00001215
Iteration 181/1000 | Loss: 0.00001215
Iteration 182/1000 | Loss: 0.00001215
Iteration 183/1000 | Loss: 0.00001215
Iteration 184/1000 | Loss: 0.00001215
Iteration 185/1000 | Loss: 0.00001215
Iteration 186/1000 | Loss: 0.00001215
Iteration 187/1000 | Loss: 0.00001215
Iteration 188/1000 | Loss: 0.00001215
Iteration 189/1000 | Loss: 0.00001215
Iteration 190/1000 | Loss: 0.00001215
Iteration 191/1000 | Loss: 0.00001215
Iteration 192/1000 | Loss: 0.00001215
Iteration 193/1000 | Loss: 0.00001215
Iteration 194/1000 | Loss: 0.00001215
Iteration 195/1000 | Loss: 0.00001214
Iteration 196/1000 | Loss: 0.00001214
Iteration 197/1000 | Loss: 0.00001214
Iteration 198/1000 | Loss: 0.00001214
Iteration 199/1000 | Loss: 0.00001214
Iteration 200/1000 | Loss: 0.00001214
Iteration 201/1000 | Loss: 0.00001214
Iteration 202/1000 | Loss: 0.00001214
Iteration 203/1000 | Loss: 0.00001214
Iteration 204/1000 | Loss: 0.00001214
Iteration 205/1000 | Loss: 0.00001214
Iteration 206/1000 | Loss: 0.00001214
Iteration 207/1000 | Loss: 0.00001214
Iteration 208/1000 | Loss: 0.00001214
Iteration 209/1000 | Loss: 0.00001214
Iteration 210/1000 | Loss: 0.00001214
Iteration 211/1000 | Loss: 0.00001214
Iteration 212/1000 | Loss: 0.00001213
Iteration 213/1000 | Loss: 0.00001213
Iteration 214/1000 | Loss: 0.00001213
Iteration 215/1000 | Loss: 0.00001213
Iteration 216/1000 | Loss: 0.00001213
Iteration 217/1000 | Loss: 0.00001213
Iteration 218/1000 | Loss: 0.00001213
Iteration 219/1000 | Loss: 0.00001213
Iteration 220/1000 | Loss: 0.00001213
Iteration 221/1000 | Loss: 0.00001213
Iteration 222/1000 | Loss: 0.00001213
Iteration 223/1000 | Loss: 0.00001213
Iteration 224/1000 | Loss: 0.00001213
Iteration 225/1000 | Loss: 0.00001213
Iteration 226/1000 | Loss: 0.00001213
Iteration 227/1000 | Loss: 0.00001213
Iteration 228/1000 | Loss: 0.00001213
Iteration 229/1000 | Loss: 0.00001213
Iteration 230/1000 | Loss: 0.00001213
Iteration 231/1000 | Loss: 0.00001213
Iteration 232/1000 | Loss: 0.00001213
Iteration 233/1000 | Loss: 0.00001213
Iteration 234/1000 | Loss: 0.00001213
Iteration 235/1000 | Loss: 0.00001213
Iteration 236/1000 | Loss: 0.00001213
Iteration 237/1000 | Loss: 0.00001213
Iteration 238/1000 | Loss: 0.00001213
Iteration 239/1000 | Loss: 0.00001213
Iteration 240/1000 | Loss: 0.00001213
Iteration 241/1000 | Loss: 0.00001213
Iteration 242/1000 | Loss: 0.00001213
Iteration 243/1000 | Loss: 0.00001213
Iteration 244/1000 | Loss: 0.00001213
Iteration 245/1000 | Loss: 0.00001213
Iteration 246/1000 | Loss: 0.00001213
Iteration 247/1000 | Loss: 0.00001213
Iteration 248/1000 | Loss: 0.00001213
Iteration 249/1000 | Loss: 0.00001213
Iteration 250/1000 | Loss: 0.00001213
Iteration 251/1000 | Loss: 0.00001213
Iteration 252/1000 | Loss: 0.00001213
Iteration 253/1000 | Loss: 0.00001213
Iteration 254/1000 | Loss: 0.00001213
Iteration 255/1000 | Loss: 0.00001213
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 255. Stopping optimization.
Last 5 losses: [1.2134067219449207e-05, 1.2134067219449207e-05, 1.2134067219449207e-05, 1.2134067219449207e-05, 1.2134067219449207e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2134067219449207e-05

Optimization complete. Final v2v error: 2.962435245513916 mm

Highest mean error: 3.7214386463165283 mm for frame 77

Lowest mean error: 2.685532331466675 mm for frame 99

Saving results

Total time: 44.62829661369324
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402034
Iteration 2/25 | Loss: 0.00097494
Iteration 3/25 | Loss: 0.00075595
Iteration 4/25 | Loss: 0.00072827
Iteration 5/25 | Loss: 0.00072180
Iteration 6/25 | Loss: 0.00071983
Iteration 7/25 | Loss: 0.00071944
Iteration 8/25 | Loss: 0.00071944
Iteration 9/25 | Loss: 0.00071944
Iteration 10/25 | Loss: 0.00071944
Iteration 11/25 | Loss: 0.00071944
Iteration 12/25 | Loss: 0.00071944
Iteration 13/25 | Loss: 0.00071944
Iteration 14/25 | Loss: 0.00071944
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.000719444768037647, 0.000719444768037647, 0.000719444768037647, 0.000719444768037647, 0.000719444768037647]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000719444768037647

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52480686
Iteration 2/25 | Loss: 0.00030219
Iteration 3/25 | Loss: 0.00030219
Iteration 4/25 | Loss: 0.00030219
Iteration 5/25 | Loss: 0.00030219
Iteration 6/25 | Loss: 0.00030219
Iteration 7/25 | Loss: 0.00030219
Iteration 8/25 | Loss: 0.00030219
Iteration 9/25 | Loss: 0.00030219
Iteration 10/25 | Loss: 0.00030219
Iteration 11/25 | Loss: 0.00030219
Iteration 12/25 | Loss: 0.00030219
Iteration 13/25 | Loss: 0.00030219
Iteration 14/25 | Loss: 0.00030219
Iteration 15/25 | Loss: 0.00030219
Iteration 16/25 | Loss: 0.00030219
Iteration 17/25 | Loss: 0.00030219
Iteration 18/25 | Loss: 0.00030219
Iteration 19/25 | Loss: 0.00030219
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00030218769097700715, 0.00030218769097700715, 0.00030218769097700715, 0.00030218769097700715, 0.00030218769097700715]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00030218769097700715

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030219
Iteration 2/1000 | Loss: 0.00002755
Iteration 3/1000 | Loss: 0.00001969
Iteration 4/1000 | Loss: 0.00001868
Iteration 5/1000 | Loss: 0.00001791
Iteration 6/1000 | Loss: 0.00001748
Iteration 7/1000 | Loss: 0.00001707
Iteration 8/1000 | Loss: 0.00001681
Iteration 9/1000 | Loss: 0.00001661
Iteration 10/1000 | Loss: 0.00001653
Iteration 11/1000 | Loss: 0.00001644
Iteration 12/1000 | Loss: 0.00001641
Iteration 13/1000 | Loss: 0.00001629
Iteration 14/1000 | Loss: 0.00001618
Iteration 15/1000 | Loss: 0.00001607
Iteration 16/1000 | Loss: 0.00001602
Iteration 17/1000 | Loss: 0.00001601
Iteration 18/1000 | Loss: 0.00001600
Iteration 19/1000 | Loss: 0.00001596
Iteration 20/1000 | Loss: 0.00001596
Iteration 21/1000 | Loss: 0.00001593
Iteration 22/1000 | Loss: 0.00001591
Iteration 23/1000 | Loss: 0.00001591
Iteration 24/1000 | Loss: 0.00001591
Iteration 25/1000 | Loss: 0.00001590
Iteration 26/1000 | Loss: 0.00001590
Iteration 27/1000 | Loss: 0.00001589
Iteration 28/1000 | Loss: 0.00001589
Iteration 29/1000 | Loss: 0.00001588
Iteration 30/1000 | Loss: 0.00001588
Iteration 31/1000 | Loss: 0.00001588
Iteration 32/1000 | Loss: 0.00001588
Iteration 33/1000 | Loss: 0.00001587
Iteration 34/1000 | Loss: 0.00001587
Iteration 35/1000 | Loss: 0.00001587
Iteration 36/1000 | Loss: 0.00001587
Iteration 37/1000 | Loss: 0.00001586
Iteration 38/1000 | Loss: 0.00001586
Iteration 39/1000 | Loss: 0.00001586
Iteration 40/1000 | Loss: 0.00001586
Iteration 41/1000 | Loss: 0.00001586
Iteration 42/1000 | Loss: 0.00001585
Iteration 43/1000 | Loss: 0.00001585
Iteration 44/1000 | Loss: 0.00001584
Iteration 45/1000 | Loss: 0.00001584
Iteration 46/1000 | Loss: 0.00001584
Iteration 47/1000 | Loss: 0.00001584
Iteration 48/1000 | Loss: 0.00001584
Iteration 49/1000 | Loss: 0.00001583
Iteration 50/1000 | Loss: 0.00001583
Iteration 51/1000 | Loss: 0.00001583
Iteration 52/1000 | Loss: 0.00001583
Iteration 53/1000 | Loss: 0.00001583
Iteration 54/1000 | Loss: 0.00001583
Iteration 55/1000 | Loss: 0.00001583
Iteration 56/1000 | Loss: 0.00001582
Iteration 57/1000 | Loss: 0.00001582
Iteration 58/1000 | Loss: 0.00001582
Iteration 59/1000 | Loss: 0.00001582
Iteration 60/1000 | Loss: 0.00001581
Iteration 61/1000 | Loss: 0.00001581
Iteration 62/1000 | Loss: 0.00001581
Iteration 63/1000 | Loss: 0.00001580
Iteration 64/1000 | Loss: 0.00001580
Iteration 65/1000 | Loss: 0.00001580
Iteration 66/1000 | Loss: 0.00001580
Iteration 67/1000 | Loss: 0.00001580
Iteration 68/1000 | Loss: 0.00001579
Iteration 69/1000 | Loss: 0.00001579
Iteration 70/1000 | Loss: 0.00001579
Iteration 71/1000 | Loss: 0.00001578
Iteration 72/1000 | Loss: 0.00001578
Iteration 73/1000 | Loss: 0.00001578
Iteration 74/1000 | Loss: 0.00001578
Iteration 75/1000 | Loss: 0.00001578
Iteration 76/1000 | Loss: 0.00001578
Iteration 77/1000 | Loss: 0.00001578
Iteration 78/1000 | Loss: 0.00001578
Iteration 79/1000 | Loss: 0.00001577
Iteration 80/1000 | Loss: 0.00001577
Iteration 81/1000 | Loss: 0.00001577
Iteration 82/1000 | Loss: 0.00001577
Iteration 83/1000 | Loss: 0.00001577
Iteration 84/1000 | Loss: 0.00001577
Iteration 85/1000 | Loss: 0.00001577
Iteration 86/1000 | Loss: 0.00001577
Iteration 87/1000 | Loss: 0.00001577
Iteration 88/1000 | Loss: 0.00001576
Iteration 89/1000 | Loss: 0.00001576
Iteration 90/1000 | Loss: 0.00001576
Iteration 91/1000 | Loss: 0.00001576
Iteration 92/1000 | Loss: 0.00001576
Iteration 93/1000 | Loss: 0.00001576
Iteration 94/1000 | Loss: 0.00001576
Iteration 95/1000 | Loss: 0.00001576
Iteration 96/1000 | Loss: 0.00001576
Iteration 97/1000 | Loss: 0.00001576
Iteration 98/1000 | Loss: 0.00001576
Iteration 99/1000 | Loss: 0.00001575
Iteration 100/1000 | Loss: 0.00001575
Iteration 101/1000 | Loss: 0.00001575
Iteration 102/1000 | Loss: 0.00001575
Iteration 103/1000 | Loss: 0.00001575
Iteration 104/1000 | Loss: 0.00001575
Iteration 105/1000 | Loss: 0.00001575
Iteration 106/1000 | Loss: 0.00001575
Iteration 107/1000 | Loss: 0.00001575
Iteration 108/1000 | Loss: 0.00001575
Iteration 109/1000 | Loss: 0.00001575
Iteration 110/1000 | Loss: 0.00001575
Iteration 111/1000 | Loss: 0.00001575
Iteration 112/1000 | Loss: 0.00001575
Iteration 113/1000 | Loss: 0.00001575
Iteration 114/1000 | Loss: 0.00001575
Iteration 115/1000 | Loss: 0.00001575
Iteration 116/1000 | Loss: 0.00001575
Iteration 117/1000 | Loss: 0.00001575
Iteration 118/1000 | Loss: 0.00001575
Iteration 119/1000 | Loss: 0.00001575
Iteration 120/1000 | Loss: 0.00001575
Iteration 121/1000 | Loss: 0.00001575
Iteration 122/1000 | Loss: 0.00001575
Iteration 123/1000 | Loss: 0.00001575
Iteration 124/1000 | Loss: 0.00001575
Iteration 125/1000 | Loss: 0.00001575
Iteration 126/1000 | Loss: 0.00001575
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 126. Stopping optimization.
Last 5 losses: [1.574560701556038e-05, 1.574560701556038e-05, 1.574560701556038e-05, 1.574560701556038e-05, 1.574560701556038e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.574560701556038e-05

Optimization complete. Final v2v error: 3.3178069591522217 mm

Highest mean error: 3.8246989250183105 mm for frame 135

Lowest mean error: 2.798093795776367 mm for frame 117

Saving results

Total time: 40.22320199012756
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1068/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1068.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1068
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00482353
Iteration 2/25 | Loss: 0.00085732
Iteration 3/25 | Loss: 0.00076347
Iteration 4/25 | Loss: 0.00073872
Iteration 5/25 | Loss: 0.00072831
Iteration 6/25 | Loss: 0.00072641
Iteration 7/25 | Loss: 0.00072600
Iteration 8/25 | Loss: 0.00072600
Iteration 9/25 | Loss: 0.00072600
Iteration 10/25 | Loss: 0.00072600
Iteration 11/25 | Loss: 0.00072600
Iteration 12/25 | Loss: 0.00072600
Iteration 13/25 | Loss: 0.00072600
Iteration 14/25 | Loss: 0.00072600
Iteration 15/25 | Loss: 0.00072600
Iteration 16/25 | Loss: 0.00072600
Iteration 17/25 | Loss: 0.00072600
Iteration 18/25 | Loss: 0.00072600
Iteration 19/25 | Loss: 0.00072600
Iteration 20/25 | Loss: 0.00072600
Iteration 21/25 | Loss: 0.00072600
Iteration 22/25 | Loss: 0.00072600
Iteration 23/25 | Loss: 0.00072600
Iteration 24/25 | Loss: 0.00072600
Iteration 25/25 | Loss: 0.00072600

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.80899072
Iteration 2/25 | Loss: 0.00031875
Iteration 3/25 | Loss: 0.00031874
Iteration 4/25 | Loss: 0.00031874
Iteration 5/25 | Loss: 0.00031874
Iteration 6/25 | Loss: 0.00031874
Iteration 7/25 | Loss: 0.00031874
Iteration 8/25 | Loss: 0.00031874
Iteration 9/25 | Loss: 0.00031874
Iteration 10/25 | Loss: 0.00031874
Iteration 11/25 | Loss: 0.00031874
Iteration 12/25 | Loss: 0.00031874
Iteration 13/25 | Loss: 0.00031874
Iteration 14/25 | Loss: 0.00031874
Iteration 15/25 | Loss: 0.00031874
Iteration 16/25 | Loss: 0.00031874
Iteration 17/25 | Loss: 0.00031874
Iteration 18/25 | Loss: 0.00031874
Iteration 19/25 | Loss: 0.00031874
Iteration 20/25 | Loss: 0.00031874
Iteration 21/25 | Loss: 0.00031874
Iteration 22/25 | Loss: 0.00031874
Iteration 23/25 | Loss: 0.00031874
Iteration 24/25 | Loss: 0.00031874
Iteration 25/25 | Loss: 0.00031874

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031874
Iteration 2/1000 | Loss: 0.00003015
Iteration 3/1000 | Loss: 0.00001871
Iteration 4/1000 | Loss: 0.00001678
Iteration 5/1000 | Loss: 0.00001553
Iteration 6/1000 | Loss: 0.00001526
Iteration 7/1000 | Loss: 0.00001480
Iteration 8/1000 | Loss: 0.00001456
Iteration 9/1000 | Loss: 0.00001440
Iteration 10/1000 | Loss: 0.00001436
Iteration 11/1000 | Loss: 0.00001425
Iteration 12/1000 | Loss: 0.00001425
Iteration 13/1000 | Loss: 0.00001421
Iteration 14/1000 | Loss: 0.00001420
Iteration 15/1000 | Loss: 0.00001420
Iteration 16/1000 | Loss: 0.00001409
Iteration 17/1000 | Loss: 0.00001407
Iteration 18/1000 | Loss: 0.00001406
Iteration 19/1000 | Loss: 0.00001406
Iteration 20/1000 | Loss: 0.00001405
Iteration 21/1000 | Loss: 0.00001403
Iteration 22/1000 | Loss: 0.00001403
Iteration 23/1000 | Loss: 0.00001402
Iteration 24/1000 | Loss: 0.00001402
Iteration 25/1000 | Loss: 0.00001399
Iteration 26/1000 | Loss: 0.00001399
Iteration 27/1000 | Loss: 0.00001397
Iteration 28/1000 | Loss: 0.00001395
Iteration 29/1000 | Loss: 0.00001394
Iteration 30/1000 | Loss: 0.00001394
Iteration 31/1000 | Loss: 0.00001394
Iteration 32/1000 | Loss: 0.00001394
Iteration 33/1000 | Loss: 0.00001394
Iteration 34/1000 | Loss: 0.00001394
Iteration 35/1000 | Loss: 0.00001394
Iteration 36/1000 | Loss: 0.00001393
Iteration 37/1000 | Loss: 0.00001393
Iteration 38/1000 | Loss: 0.00001391
Iteration 39/1000 | Loss: 0.00001391
Iteration 40/1000 | Loss: 0.00001390
Iteration 41/1000 | Loss: 0.00001390
Iteration 42/1000 | Loss: 0.00001389
Iteration 43/1000 | Loss: 0.00001389
Iteration 44/1000 | Loss: 0.00001389
Iteration 45/1000 | Loss: 0.00001389
Iteration 46/1000 | Loss: 0.00001389
Iteration 47/1000 | Loss: 0.00001389
Iteration 48/1000 | Loss: 0.00001388
Iteration 49/1000 | Loss: 0.00001388
Iteration 50/1000 | Loss: 0.00001388
Iteration 51/1000 | Loss: 0.00001388
Iteration 52/1000 | Loss: 0.00001388
Iteration 53/1000 | Loss: 0.00001388
Iteration 54/1000 | Loss: 0.00001388
Iteration 55/1000 | Loss: 0.00001388
Iteration 56/1000 | Loss: 0.00001388
Iteration 57/1000 | Loss: 0.00001387
Iteration 58/1000 | Loss: 0.00001387
Iteration 59/1000 | Loss: 0.00001386
Iteration 60/1000 | Loss: 0.00001386
Iteration 61/1000 | Loss: 0.00001386
Iteration 62/1000 | Loss: 0.00001386
Iteration 63/1000 | Loss: 0.00001386
Iteration 64/1000 | Loss: 0.00001386
Iteration 65/1000 | Loss: 0.00001386
Iteration 66/1000 | Loss: 0.00001386
Iteration 67/1000 | Loss: 0.00001385
Iteration 68/1000 | Loss: 0.00001385
Iteration 69/1000 | Loss: 0.00001385
Iteration 70/1000 | Loss: 0.00001384
Iteration 71/1000 | Loss: 0.00001384
Iteration 72/1000 | Loss: 0.00001384
Iteration 73/1000 | Loss: 0.00001384
Iteration 74/1000 | Loss: 0.00001384
Iteration 75/1000 | Loss: 0.00001383
Iteration 76/1000 | Loss: 0.00001382
Iteration 77/1000 | Loss: 0.00001380
Iteration 78/1000 | Loss: 0.00001380
Iteration 79/1000 | Loss: 0.00001380
Iteration 80/1000 | Loss: 0.00001380
Iteration 81/1000 | Loss: 0.00001380
Iteration 82/1000 | Loss: 0.00001380
Iteration 83/1000 | Loss: 0.00001380
Iteration 84/1000 | Loss: 0.00001380
Iteration 85/1000 | Loss: 0.00001380
Iteration 86/1000 | Loss: 0.00001380
Iteration 87/1000 | Loss: 0.00001380
Iteration 88/1000 | Loss: 0.00001379
Iteration 89/1000 | Loss: 0.00001378
Iteration 90/1000 | Loss: 0.00001376
Iteration 91/1000 | Loss: 0.00001376
Iteration 92/1000 | Loss: 0.00001376
Iteration 93/1000 | Loss: 0.00001376
Iteration 94/1000 | Loss: 0.00001376
Iteration 95/1000 | Loss: 0.00001375
Iteration 96/1000 | Loss: 0.00001375
Iteration 97/1000 | Loss: 0.00001375
Iteration 98/1000 | Loss: 0.00001375
Iteration 99/1000 | Loss: 0.00001375
Iteration 100/1000 | Loss: 0.00001375
Iteration 101/1000 | Loss: 0.00001375
Iteration 102/1000 | Loss: 0.00001375
Iteration 103/1000 | Loss: 0.00001375
Iteration 104/1000 | Loss: 0.00001374
Iteration 105/1000 | Loss: 0.00001373
Iteration 106/1000 | Loss: 0.00001372
Iteration 107/1000 | Loss: 0.00001372
Iteration 108/1000 | Loss: 0.00001372
Iteration 109/1000 | Loss: 0.00001371
Iteration 110/1000 | Loss: 0.00001371
Iteration 111/1000 | Loss: 0.00001370
Iteration 112/1000 | Loss: 0.00001370
Iteration 113/1000 | Loss: 0.00001370
Iteration 114/1000 | Loss: 0.00001370
Iteration 115/1000 | Loss: 0.00001370
Iteration 116/1000 | Loss: 0.00001369
Iteration 117/1000 | Loss: 0.00001369
Iteration 118/1000 | Loss: 0.00001369
Iteration 119/1000 | Loss: 0.00001369
Iteration 120/1000 | Loss: 0.00001369
Iteration 121/1000 | Loss: 0.00001369
Iteration 122/1000 | Loss: 0.00001369
Iteration 123/1000 | Loss: 0.00001368
Iteration 124/1000 | Loss: 0.00001368
Iteration 125/1000 | Loss: 0.00001368
Iteration 126/1000 | Loss: 0.00001367
Iteration 127/1000 | Loss: 0.00001367
Iteration 128/1000 | Loss: 0.00001367
Iteration 129/1000 | Loss: 0.00001367
Iteration 130/1000 | Loss: 0.00001367
Iteration 131/1000 | Loss: 0.00001367
Iteration 132/1000 | Loss: 0.00001367
Iteration 133/1000 | Loss: 0.00001366
Iteration 134/1000 | Loss: 0.00001366
Iteration 135/1000 | Loss: 0.00001366
Iteration 136/1000 | Loss: 0.00001366
Iteration 137/1000 | Loss: 0.00001366
Iteration 138/1000 | Loss: 0.00001366
Iteration 139/1000 | Loss: 0.00001366
Iteration 140/1000 | Loss: 0.00001365
Iteration 141/1000 | Loss: 0.00001365
Iteration 142/1000 | Loss: 0.00001365
Iteration 143/1000 | Loss: 0.00001365
Iteration 144/1000 | Loss: 0.00001365
Iteration 145/1000 | Loss: 0.00001365
Iteration 146/1000 | Loss: 0.00001365
Iteration 147/1000 | Loss: 0.00001365
Iteration 148/1000 | Loss: 0.00001365
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.3654424037667923e-05, 1.3654424037667923e-05, 1.3654424037667923e-05, 1.3654424037667923e-05, 1.3654424037667923e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3654424037667923e-05

Optimization complete. Final v2v error: 3.142216682434082 mm

Highest mean error: 3.565865993499756 mm for frame 126

Lowest mean error: 2.9275436401367188 mm for frame 66

Saving results

Total time: 37.20381999015808
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1079
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00583861
Iteration 2/25 | Loss: 0.00109178
Iteration 3/25 | Loss: 0.00088373
Iteration 4/25 | Loss: 0.00084002
Iteration 5/25 | Loss: 0.00082390
Iteration 6/25 | Loss: 0.00082110
Iteration 7/25 | Loss: 0.00082029
Iteration 8/25 | Loss: 0.00082029
Iteration 9/25 | Loss: 0.00082029
Iteration 10/25 | Loss: 0.00082029
Iteration 11/25 | Loss: 0.00082029
Iteration 12/25 | Loss: 0.00082029
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008202903554774821, 0.0008202903554774821, 0.0008202903554774821, 0.0008202903554774821, 0.0008202903554774821]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008202903554774821

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44816673
Iteration 2/25 | Loss: 0.00035952
Iteration 3/25 | Loss: 0.00035947
Iteration 4/25 | Loss: 0.00035947
Iteration 5/25 | Loss: 0.00035946
Iteration 6/25 | Loss: 0.00035946
Iteration 7/25 | Loss: 0.00035946
Iteration 8/25 | Loss: 0.00035946
Iteration 9/25 | Loss: 0.00035946
Iteration 10/25 | Loss: 0.00035946
Iteration 11/25 | Loss: 0.00035946
Iteration 12/25 | Loss: 0.00035946
Iteration 13/25 | Loss: 0.00035946
Iteration 14/25 | Loss: 0.00035946
Iteration 15/25 | Loss: 0.00035946
Iteration 16/25 | Loss: 0.00035946
Iteration 17/25 | Loss: 0.00035946
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00035946283605881035, 0.00035946283605881035, 0.00035946283605881035, 0.00035946283605881035, 0.00035946283605881035]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00035946283605881035

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035946
Iteration 2/1000 | Loss: 0.00003468
Iteration 3/1000 | Loss: 0.00002673
Iteration 4/1000 | Loss: 0.00002433
Iteration 5/1000 | Loss: 0.00002343
Iteration 6/1000 | Loss: 0.00002266
Iteration 7/1000 | Loss: 0.00002228
Iteration 8/1000 | Loss: 0.00002191
Iteration 9/1000 | Loss: 0.00002163
Iteration 10/1000 | Loss: 0.00002141
Iteration 11/1000 | Loss: 0.00002123
Iteration 12/1000 | Loss: 0.00002123
Iteration 13/1000 | Loss: 0.00002121
Iteration 14/1000 | Loss: 0.00002116
Iteration 15/1000 | Loss: 0.00002115
Iteration 16/1000 | Loss: 0.00002112
Iteration 17/1000 | Loss: 0.00002103
Iteration 18/1000 | Loss: 0.00002102
Iteration 19/1000 | Loss: 0.00002093
Iteration 20/1000 | Loss: 0.00002092
Iteration 21/1000 | Loss: 0.00002091
Iteration 22/1000 | Loss: 0.00002091
Iteration 23/1000 | Loss: 0.00002089
Iteration 24/1000 | Loss: 0.00002085
Iteration 25/1000 | Loss: 0.00002085
Iteration 26/1000 | Loss: 0.00002082
Iteration 27/1000 | Loss: 0.00002082
Iteration 28/1000 | Loss: 0.00002081
Iteration 29/1000 | Loss: 0.00002080
Iteration 30/1000 | Loss: 0.00002077
Iteration 31/1000 | Loss: 0.00002077
Iteration 32/1000 | Loss: 0.00002076
Iteration 33/1000 | Loss: 0.00002076
Iteration 34/1000 | Loss: 0.00002075
Iteration 35/1000 | Loss: 0.00002075
Iteration 36/1000 | Loss: 0.00002074
Iteration 37/1000 | Loss: 0.00002074
Iteration 38/1000 | Loss: 0.00002074
Iteration 39/1000 | Loss: 0.00002073
Iteration 40/1000 | Loss: 0.00002073
Iteration 41/1000 | Loss: 0.00002073
Iteration 42/1000 | Loss: 0.00002073
Iteration 43/1000 | Loss: 0.00002072
Iteration 44/1000 | Loss: 0.00002072
Iteration 45/1000 | Loss: 0.00002071
Iteration 46/1000 | Loss: 0.00002071
Iteration 47/1000 | Loss: 0.00002071
Iteration 48/1000 | Loss: 0.00002071
Iteration 49/1000 | Loss: 0.00002071
Iteration 50/1000 | Loss: 0.00002070
Iteration 51/1000 | Loss: 0.00002070
Iteration 52/1000 | Loss: 0.00002070
Iteration 53/1000 | Loss: 0.00002070
Iteration 54/1000 | Loss: 0.00002070
Iteration 55/1000 | Loss: 0.00002069
Iteration 56/1000 | Loss: 0.00002069
Iteration 57/1000 | Loss: 0.00002069
Iteration 58/1000 | Loss: 0.00002069
Iteration 59/1000 | Loss: 0.00002068
Iteration 60/1000 | Loss: 0.00002068
Iteration 61/1000 | Loss: 0.00002068
Iteration 62/1000 | Loss: 0.00002068
Iteration 63/1000 | Loss: 0.00002067
Iteration 64/1000 | Loss: 0.00002067
Iteration 65/1000 | Loss: 0.00002067
Iteration 66/1000 | Loss: 0.00002066
Iteration 67/1000 | Loss: 0.00002066
Iteration 68/1000 | Loss: 0.00002066
Iteration 69/1000 | Loss: 0.00002066
Iteration 70/1000 | Loss: 0.00002066
Iteration 71/1000 | Loss: 0.00002066
Iteration 72/1000 | Loss: 0.00002066
Iteration 73/1000 | Loss: 0.00002066
Iteration 74/1000 | Loss: 0.00002066
Iteration 75/1000 | Loss: 0.00002066
Iteration 76/1000 | Loss: 0.00002066
Iteration 77/1000 | Loss: 0.00002065
Iteration 78/1000 | Loss: 0.00002065
Iteration 79/1000 | Loss: 0.00002065
Iteration 80/1000 | Loss: 0.00002065
Iteration 81/1000 | Loss: 0.00002065
Iteration 82/1000 | Loss: 0.00002064
Iteration 83/1000 | Loss: 0.00002064
Iteration 84/1000 | Loss: 0.00002064
Iteration 85/1000 | Loss: 0.00002064
Iteration 86/1000 | Loss: 0.00002064
Iteration 87/1000 | Loss: 0.00002064
Iteration 88/1000 | Loss: 0.00002063
Iteration 89/1000 | Loss: 0.00002063
Iteration 90/1000 | Loss: 0.00002063
Iteration 91/1000 | Loss: 0.00002063
Iteration 92/1000 | Loss: 0.00002063
Iteration 93/1000 | Loss: 0.00002063
Iteration 94/1000 | Loss: 0.00002063
Iteration 95/1000 | Loss: 0.00002063
Iteration 96/1000 | Loss: 0.00002063
Iteration 97/1000 | Loss: 0.00002063
Iteration 98/1000 | Loss: 0.00002063
Iteration 99/1000 | Loss: 0.00002063
Iteration 100/1000 | Loss: 0.00002063
Iteration 101/1000 | Loss: 0.00002062
Iteration 102/1000 | Loss: 0.00002062
Iteration 103/1000 | Loss: 0.00002062
Iteration 104/1000 | Loss: 0.00002062
Iteration 105/1000 | Loss: 0.00002061
Iteration 106/1000 | Loss: 0.00002061
Iteration 107/1000 | Loss: 0.00002061
Iteration 108/1000 | Loss: 0.00002061
Iteration 109/1000 | Loss: 0.00002061
Iteration 110/1000 | Loss: 0.00002061
Iteration 111/1000 | Loss: 0.00002061
Iteration 112/1000 | Loss: 0.00002060
Iteration 113/1000 | Loss: 0.00002060
Iteration 114/1000 | Loss: 0.00002060
Iteration 115/1000 | Loss: 0.00002060
Iteration 116/1000 | Loss: 0.00002060
Iteration 117/1000 | Loss: 0.00002060
Iteration 118/1000 | Loss: 0.00002060
Iteration 119/1000 | Loss: 0.00002060
Iteration 120/1000 | Loss: 0.00002060
Iteration 121/1000 | Loss: 0.00002060
Iteration 122/1000 | Loss: 0.00002060
Iteration 123/1000 | Loss: 0.00002060
Iteration 124/1000 | Loss: 0.00002060
Iteration 125/1000 | Loss: 0.00002060
Iteration 126/1000 | Loss: 0.00002060
Iteration 127/1000 | Loss: 0.00002060
Iteration 128/1000 | Loss: 0.00002060
Iteration 129/1000 | Loss: 0.00002060
Iteration 130/1000 | Loss: 0.00002060
Iteration 131/1000 | Loss: 0.00002060
Iteration 132/1000 | Loss: 0.00002060
Iteration 133/1000 | Loss: 0.00002060
Iteration 134/1000 | Loss: 0.00002060
Iteration 135/1000 | Loss: 0.00002060
Iteration 136/1000 | Loss: 0.00002060
Iteration 137/1000 | Loss: 0.00002060
Iteration 138/1000 | Loss: 0.00002060
Iteration 139/1000 | Loss: 0.00002060
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 139. Stopping optimization.
Last 5 losses: [2.059675352938939e-05, 2.059675352938939e-05, 2.059675352938939e-05, 2.059675352938939e-05, 2.059675352938939e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.059675352938939e-05

Optimization complete. Final v2v error: 3.8430874347686768 mm

Highest mean error: 4.524676322937012 mm for frame 14

Lowest mean error: 3.402888059616089 mm for frame 122

Saving results

Total time: 43.58750510215759
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00834316
Iteration 2/25 | Loss: 0.00164796
Iteration 3/25 | Loss: 0.00098557
Iteration 4/25 | Loss: 0.00090328
Iteration 5/25 | Loss: 0.00084672
Iteration 6/25 | Loss: 0.00088582
Iteration 7/25 | Loss: 0.00087193
Iteration 8/25 | Loss: 0.00082965
Iteration 9/25 | Loss: 0.00079760
Iteration 10/25 | Loss: 0.00078867
Iteration 11/25 | Loss: 0.00079500
Iteration 12/25 | Loss: 0.00078403
Iteration 13/25 | Loss: 0.00078589
Iteration 14/25 | Loss: 0.00078815
Iteration 15/25 | Loss: 0.00078225
Iteration 16/25 | Loss: 0.00077908
Iteration 17/25 | Loss: 0.00077855
Iteration 18/25 | Loss: 0.00077842
Iteration 19/25 | Loss: 0.00077842
Iteration 20/25 | Loss: 0.00077842
Iteration 21/25 | Loss: 0.00077842
Iteration 22/25 | Loss: 0.00077842
Iteration 23/25 | Loss: 0.00077841
Iteration 24/25 | Loss: 0.00077841
Iteration 25/25 | Loss: 0.00077841

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.73754358
Iteration 2/25 | Loss: 0.00040569
Iteration 3/25 | Loss: 0.00040566
Iteration 4/25 | Loss: 0.00040566
Iteration 5/25 | Loss: 0.00040565
Iteration 6/25 | Loss: 0.00040565
Iteration 7/25 | Loss: 0.00040565
Iteration 8/25 | Loss: 0.00040565
Iteration 9/25 | Loss: 0.00040565
Iteration 10/25 | Loss: 0.00040565
Iteration 11/25 | Loss: 0.00040565
Iteration 12/25 | Loss: 0.00040565
Iteration 13/25 | Loss: 0.00040565
Iteration 14/25 | Loss: 0.00040565
Iteration 15/25 | Loss: 0.00040565
Iteration 16/25 | Loss: 0.00040565
Iteration 17/25 | Loss: 0.00040565
Iteration 18/25 | Loss: 0.00040565
Iteration 19/25 | Loss: 0.00040565
Iteration 20/25 | Loss: 0.00040565
Iteration 21/25 | Loss: 0.00040565
Iteration 22/25 | Loss: 0.00040565
Iteration 23/25 | Loss: 0.00040565
Iteration 24/25 | Loss: 0.00040565
Iteration 25/25 | Loss: 0.00040565

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040565
Iteration 2/1000 | Loss: 0.00002144
Iteration 3/1000 | Loss: 0.00001807
Iteration 4/1000 | Loss: 0.00001698
Iteration 5/1000 | Loss: 0.00001638
Iteration 6/1000 | Loss: 0.00001600
Iteration 7/1000 | Loss: 0.00001574
Iteration 8/1000 | Loss: 0.00001553
Iteration 9/1000 | Loss: 0.00001550
Iteration 10/1000 | Loss: 0.00001549
Iteration 11/1000 | Loss: 0.00001545
Iteration 12/1000 | Loss: 0.00001544
Iteration 13/1000 | Loss: 0.00001543
Iteration 14/1000 | Loss: 0.00001539
Iteration 15/1000 | Loss: 0.00001539
Iteration 16/1000 | Loss: 0.00001533
Iteration 17/1000 | Loss: 0.00001533
Iteration 18/1000 | Loss: 0.00001532
Iteration 19/1000 | Loss: 0.00001531
Iteration 20/1000 | Loss: 0.00001530
Iteration 21/1000 | Loss: 0.00001530
Iteration 22/1000 | Loss: 0.00001530
Iteration 23/1000 | Loss: 0.00001530
Iteration 24/1000 | Loss: 0.00001530
Iteration 25/1000 | Loss: 0.00001529
Iteration 26/1000 | Loss: 0.00001529
Iteration 27/1000 | Loss: 0.00001529
Iteration 28/1000 | Loss: 0.00001529
Iteration 29/1000 | Loss: 0.00001529
Iteration 30/1000 | Loss: 0.00001529
Iteration 31/1000 | Loss: 0.00001528
Iteration 32/1000 | Loss: 0.00001528
Iteration 33/1000 | Loss: 0.00001527
Iteration 34/1000 | Loss: 0.00001527
Iteration 35/1000 | Loss: 0.00001527
Iteration 36/1000 | Loss: 0.00001526
Iteration 37/1000 | Loss: 0.00001526
Iteration 38/1000 | Loss: 0.00001526
Iteration 39/1000 | Loss: 0.00001526
Iteration 40/1000 | Loss: 0.00001526
Iteration 41/1000 | Loss: 0.00001526
Iteration 42/1000 | Loss: 0.00001526
Iteration 43/1000 | Loss: 0.00001525
Iteration 44/1000 | Loss: 0.00001525
Iteration 45/1000 | Loss: 0.00001525
Iteration 46/1000 | Loss: 0.00001525
Iteration 47/1000 | Loss: 0.00001525
Iteration 48/1000 | Loss: 0.00001525
Iteration 49/1000 | Loss: 0.00001525
Iteration 50/1000 | Loss: 0.00001524
Iteration 51/1000 | Loss: 0.00001524
Iteration 52/1000 | Loss: 0.00001524
Iteration 53/1000 | Loss: 0.00001524
Iteration 54/1000 | Loss: 0.00001524
Iteration 55/1000 | Loss: 0.00001524
Iteration 56/1000 | Loss: 0.00001524
Iteration 57/1000 | Loss: 0.00001524
Iteration 58/1000 | Loss: 0.00001523
Iteration 59/1000 | Loss: 0.00001523
Iteration 60/1000 | Loss: 0.00001523
Iteration 61/1000 | Loss: 0.00001523
Iteration 62/1000 | Loss: 0.00001523
Iteration 63/1000 | Loss: 0.00001523
Iteration 64/1000 | Loss: 0.00001523
Iteration 65/1000 | Loss: 0.00001523
Iteration 66/1000 | Loss: 0.00001523
Iteration 67/1000 | Loss: 0.00001522
Iteration 68/1000 | Loss: 0.00001522
Iteration 69/1000 | Loss: 0.00001522
Iteration 70/1000 | Loss: 0.00001522
Iteration 71/1000 | Loss: 0.00001522
Iteration 72/1000 | Loss: 0.00001522
Iteration 73/1000 | Loss: 0.00001522
Iteration 74/1000 | Loss: 0.00001522
Iteration 75/1000 | Loss: 0.00001522
Iteration 76/1000 | Loss: 0.00001522
Iteration 77/1000 | Loss: 0.00001522
Iteration 78/1000 | Loss: 0.00001522
Iteration 79/1000 | Loss: 0.00001522
Iteration 80/1000 | Loss: 0.00001522
Iteration 81/1000 | Loss: 0.00001522
Iteration 82/1000 | Loss: 0.00001522
Iteration 83/1000 | Loss: 0.00001522
Iteration 84/1000 | Loss: 0.00001522
Iteration 85/1000 | Loss: 0.00001522
Iteration 86/1000 | Loss: 0.00001522
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 86. Stopping optimization.
Last 5 losses: [1.5222060937958304e-05, 1.5222060937958304e-05, 1.5222060937958304e-05, 1.5222060937958304e-05, 1.5222060937958304e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5222060937958304e-05

Optimization complete. Final v2v error: 3.278090476989746 mm

Highest mean error: 3.829371929168701 mm for frame 7

Lowest mean error: 2.949773073196411 mm for frame 69

Saving results

Total time: 57.747185707092285
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01030355
Iteration 2/25 | Loss: 0.00205046
Iteration 3/25 | Loss: 0.00130161
Iteration 4/25 | Loss: 0.00124977
Iteration 5/25 | Loss: 0.00118588
Iteration 6/25 | Loss: 0.00093882
Iteration 7/25 | Loss: 0.00094741
Iteration 8/25 | Loss: 0.00093431
Iteration 9/25 | Loss: 0.00089450
Iteration 10/25 | Loss: 0.00089992
Iteration 11/25 | Loss: 0.00089665
Iteration 12/25 | Loss: 0.00089937
Iteration 13/25 | Loss: 0.00089720
Iteration 14/25 | Loss: 0.00088480
Iteration 15/25 | Loss: 0.00088263
Iteration 16/25 | Loss: 0.00087782
Iteration 17/25 | Loss: 0.00087011
Iteration 18/25 | Loss: 0.00086011
Iteration 19/25 | Loss: 0.00086853
Iteration 20/25 | Loss: 0.00086002
Iteration 21/25 | Loss: 0.00085287
Iteration 22/25 | Loss: 0.00084402
Iteration 23/25 | Loss: 0.00083898
Iteration 24/25 | Loss: 0.00084126
Iteration 25/25 | Loss: 0.00084337

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47615921
Iteration 2/25 | Loss: 0.00042968
Iteration 3/25 | Loss: 0.00040378
Iteration 4/25 | Loss: 0.00040378
Iteration 5/25 | Loss: 0.00040378
Iteration 6/25 | Loss: 0.00040378
Iteration 7/25 | Loss: 0.00040378
Iteration 8/25 | Loss: 0.00040378
Iteration 9/25 | Loss: 0.00040378
Iteration 10/25 | Loss: 0.00040378
Iteration 11/25 | Loss: 0.00040378
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.00040377830737270415, 0.00040377830737270415, 0.00040377830737270415, 0.00040377830737270415, 0.00040377830737270415]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00040377830737270415

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00040378
Iteration 2/1000 | Loss: 0.00005505
Iteration 3/1000 | Loss: 0.00005630
Iteration 4/1000 | Loss: 0.00004857
Iteration 5/1000 | Loss: 0.00006189
Iteration 6/1000 | Loss: 0.00002887
Iteration 7/1000 | Loss: 0.00002693
Iteration 8/1000 | Loss: 0.00003879
Iteration 9/1000 | Loss: 0.00005722
Iteration 10/1000 | Loss: 0.00005231
Iteration 11/1000 | Loss: 0.00002466
Iteration 12/1000 | Loss: 0.00002287
Iteration 13/1000 | Loss: 0.00003016
Iteration 14/1000 | Loss: 0.00002180
Iteration 15/1000 | Loss: 0.00002143
Iteration 16/1000 | Loss: 0.00002105
Iteration 17/1000 | Loss: 0.00005030
Iteration 18/1000 | Loss: 0.00014896
Iteration 19/1000 | Loss: 0.00002110
Iteration 20/1000 | Loss: 0.00002060
Iteration 21/1000 | Loss: 0.00003529
Iteration 22/1000 | Loss: 0.00002046
Iteration 23/1000 | Loss: 0.00002045
Iteration 24/1000 | Loss: 0.00002042
Iteration 25/1000 | Loss: 0.00002038
Iteration 26/1000 | Loss: 0.00002038
Iteration 27/1000 | Loss: 0.00002036
Iteration 28/1000 | Loss: 0.00002035
Iteration 29/1000 | Loss: 0.00002034
Iteration 30/1000 | Loss: 0.00002034
Iteration 31/1000 | Loss: 0.00004064
Iteration 32/1000 | Loss: 0.00004449
Iteration 33/1000 | Loss: 0.00002672
Iteration 34/1000 | Loss: 0.00002020
Iteration 35/1000 | Loss: 0.00002020
Iteration 36/1000 | Loss: 0.00002020
Iteration 37/1000 | Loss: 0.00002020
Iteration 38/1000 | Loss: 0.00002020
Iteration 39/1000 | Loss: 0.00002019
Iteration 40/1000 | Loss: 0.00002019
Iteration 41/1000 | Loss: 0.00002019
Iteration 42/1000 | Loss: 0.00002019
Iteration 43/1000 | Loss: 0.00002019
Iteration 44/1000 | Loss: 0.00002018
Iteration 45/1000 | Loss: 0.00002018
Iteration 46/1000 | Loss: 0.00002018
Iteration 47/1000 | Loss: 0.00002018
Iteration 48/1000 | Loss: 0.00002018
Iteration 49/1000 | Loss: 0.00002017
Iteration 50/1000 | Loss: 0.00002017
Iteration 51/1000 | Loss: 0.00002017
Iteration 52/1000 | Loss: 0.00003047
Iteration 53/1000 | Loss: 0.00002078
Iteration 54/1000 | Loss: 0.00002027
Iteration 55/1000 | Loss: 0.00002043
Iteration 56/1000 | Loss: 0.00002016
Iteration 57/1000 | Loss: 0.00002016
Iteration 58/1000 | Loss: 0.00002016
Iteration 59/1000 | Loss: 0.00002016
Iteration 60/1000 | Loss: 0.00002016
Iteration 61/1000 | Loss: 0.00002016
Iteration 62/1000 | Loss: 0.00002015
Iteration 63/1000 | Loss: 0.00002015
Iteration 64/1000 | Loss: 0.00002015
Iteration 65/1000 | Loss: 0.00002015
Iteration 66/1000 | Loss: 0.00002015
Iteration 67/1000 | Loss: 0.00002015
Iteration 68/1000 | Loss: 0.00002015
Iteration 69/1000 | Loss: 0.00002015
Iteration 70/1000 | Loss: 0.00002015
Iteration 71/1000 | Loss: 0.00002015
Iteration 72/1000 | Loss: 0.00002015
Iteration 73/1000 | Loss: 0.00002015
Iteration 74/1000 | Loss: 0.00002015
Iteration 75/1000 | Loss: 0.00002015
Iteration 76/1000 | Loss: 0.00002015
Iteration 77/1000 | Loss: 0.00002015
Iteration 78/1000 | Loss: 0.00002015
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 78. Stopping optimization.
Last 5 losses: [2.015009340539109e-05, 2.015009340539109e-05, 2.015009340539109e-05, 2.015009340539109e-05, 2.015009340539109e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.015009340539109e-05

Optimization complete. Final v2v error: 3.5576703548431396 mm

Highest mean error: 13.594040870666504 mm for frame 131

Lowest mean error: 2.9892239570617676 mm for frame 173

Saving results

Total time: 99.9697847366333
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00416086
Iteration 2/25 | Loss: 0.00109947
Iteration 3/25 | Loss: 0.00086051
Iteration 4/25 | Loss: 0.00082673
Iteration 5/25 | Loss: 0.00081373
Iteration 6/25 | Loss: 0.00081159
Iteration 7/25 | Loss: 0.00081088
Iteration 8/25 | Loss: 0.00081087
Iteration 9/25 | Loss: 0.00081087
Iteration 10/25 | Loss: 0.00081087
Iteration 11/25 | Loss: 0.00081087
Iteration 12/25 | Loss: 0.00081087
Iteration 13/25 | Loss: 0.00081087
Iteration 14/25 | Loss: 0.00081087
Iteration 15/25 | Loss: 0.00081087
Iteration 16/25 | Loss: 0.00081087
Iteration 17/25 | Loss: 0.00081087
Iteration 18/25 | Loss: 0.00081087
Iteration 19/25 | Loss: 0.00081087
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000810871075373143, 0.000810871075373143, 0.000810871075373143, 0.000810871075373143, 0.000810871075373143]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000810871075373143

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.96110201
Iteration 2/25 | Loss: 0.00038121
Iteration 3/25 | Loss: 0.00038119
Iteration 4/25 | Loss: 0.00038119
Iteration 5/25 | Loss: 0.00038119
Iteration 6/25 | Loss: 0.00038118
Iteration 7/25 | Loss: 0.00038118
Iteration 8/25 | Loss: 0.00038118
Iteration 9/25 | Loss: 0.00038118
Iteration 10/25 | Loss: 0.00038118
Iteration 11/25 | Loss: 0.00038118
Iteration 12/25 | Loss: 0.00038118
Iteration 13/25 | Loss: 0.00038118
Iteration 14/25 | Loss: 0.00038118
Iteration 15/25 | Loss: 0.00038118
Iteration 16/25 | Loss: 0.00038118
Iteration 17/25 | Loss: 0.00038118
Iteration 18/25 | Loss: 0.00038118
Iteration 19/25 | Loss: 0.00038118
Iteration 20/25 | Loss: 0.00038118
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0003811837232206017, 0.0003811837232206017, 0.0003811837232206017, 0.0003811837232206017, 0.0003811837232206017]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003811837232206017

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038118
Iteration 2/1000 | Loss: 0.00003649
Iteration 3/1000 | Loss: 0.00002760
Iteration 4/1000 | Loss: 0.00002618
Iteration 5/1000 | Loss: 0.00002494
Iteration 6/1000 | Loss: 0.00002419
Iteration 7/1000 | Loss: 0.00002358
Iteration 8/1000 | Loss: 0.00002321
Iteration 9/1000 | Loss: 0.00002287
Iteration 10/1000 | Loss: 0.00002267
Iteration 11/1000 | Loss: 0.00002244
Iteration 12/1000 | Loss: 0.00002232
Iteration 13/1000 | Loss: 0.00002225
Iteration 14/1000 | Loss: 0.00002224
Iteration 15/1000 | Loss: 0.00002223
Iteration 16/1000 | Loss: 0.00002221
Iteration 17/1000 | Loss: 0.00002221
Iteration 18/1000 | Loss: 0.00002221
Iteration 19/1000 | Loss: 0.00002220
Iteration 20/1000 | Loss: 0.00002220
Iteration 21/1000 | Loss: 0.00002217
Iteration 22/1000 | Loss: 0.00002217
Iteration 23/1000 | Loss: 0.00002217
Iteration 24/1000 | Loss: 0.00002216
Iteration 25/1000 | Loss: 0.00002216
Iteration 26/1000 | Loss: 0.00002216
Iteration 27/1000 | Loss: 0.00002215
Iteration 28/1000 | Loss: 0.00002214
Iteration 29/1000 | Loss: 0.00002213
Iteration 30/1000 | Loss: 0.00002213
Iteration 31/1000 | Loss: 0.00002213
Iteration 32/1000 | Loss: 0.00002213
Iteration 33/1000 | Loss: 0.00002213
Iteration 34/1000 | Loss: 0.00002213
Iteration 35/1000 | Loss: 0.00002213
Iteration 36/1000 | Loss: 0.00002213
Iteration 37/1000 | Loss: 0.00002213
Iteration 38/1000 | Loss: 0.00002213
Iteration 39/1000 | Loss: 0.00002212
Iteration 40/1000 | Loss: 0.00002212
Iteration 41/1000 | Loss: 0.00002212
Iteration 42/1000 | Loss: 0.00002212
Iteration 43/1000 | Loss: 0.00002212
Iteration 44/1000 | Loss: 0.00002212
Iteration 45/1000 | Loss: 0.00002211
Iteration 46/1000 | Loss: 0.00002211
Iteration 47/1000 | Loss: 0.00002210
Iteration 48/1000 | Loss: 0.00002210
Iteration 49/1000 | Loss: 0.00002210
Iteration 50/1000 | Loss: 0.00002210
Iteration 51/1000 | Loss: 0.00002210
Iteration 52/1000 | Loss: 0.00002210
Iteration 53/1000 | Loss: 0.00002210
Iteration 54/1000 | Loss: 0.00002210
Iteration 55/1000 | Loss: 0.00002210
Iteration 56/1000 | Loss: 0.00002210
Iteration 57/1000 | Loss: 0.00002209
Iteration 58/1000 | Loss: 0.00002209
Iteration 59/1000 | Loss: 0.00002209
Iteration 60/1000 | Loss: 0.00002207
Iteration 61/1000 | Loss: 0.00002207
Iteration 62/1000 | Loss: 0.00002206
Iteration 63/1000 | Loss: 0.00002206
Iteration 64/1000 | Loss: 0.00002205
Iteration 65/1000 | Loss: 0.00002205
Iteration 66/1000 | Loss: 0.00002204
Iteration 67/1000 | Loss: 0.00002204
Iteration 68/1000 | Loss: 0.00002203
Iteration 69/1000 | Loss: 0.00002203
Iteration 70/1000 | Loss: 0.00002203
Iteration 71/1000 | Loss: 0.00002202
Iteration 72/1000 | Loss: 0.00002202
Iteration 73/1000 | Loss: 0.00002201
Iteration 74/1000 | Loss: 0.00002201
Iteration 75/1000 | Loss: 0.00002201
Iteration 76/1000 | Loss: 0.00002201
Iteration 77/1000 | Loss: 0.00002201
Iteration 78/1000 | Loss: 0.00002200
Iteration 79/1000 | Loss: 0.00002200
Iteration 80/1000 | Loss: 0.00002200
Iteration 81/1000 | Loss: 0.00002200
Iteration 82/1000 | Loss: 0.00002200
Iteration 83/1000 | Loss: 0.00002200
Iteration 84/1000 | Loss: 0.00002200
Iteration 85/1000 | Loss: 0.00002199
Iteration 86/1000 | Loss: 0.00002199
Iteration 87/1000 | Loss: 0.00002199
Iteration 88/1000 | Loss: 0.00002199
Iteration 89/1000 | Loss: 0.00002199
Iteration 90/1000 | Loss: 0.00002199
Iteration 91/1000 | Loss: 0.00002199
Iteration 92/1000 | Loss: 0.00002199
Iteration 93/1000 | Loss: 0.00002199
Iteration 94/1000 | Loss: 0.00002199
Iteration 95/1000 | Loss: 0.00002199
Iteration 96/1000 | Loss: 0.00002198
Iteration 97/1000 | Loss: 0.00002198
Iteration 98/1000 | Loss: 0.00002198
Iteration 99/1000 | Loss: 0.00002198
Iteration 100/1000 | Loss: 0.00002198
Iteration 101/1000 | Loss: 0.00002198
Iteration 102/1000 | Loss: 0.00002198
Iteration 103/1000 | Loss: 0.00002198
Iteration 104/1000 | Loss: 0.00002198
Iteration 105/1000 | Loss: 0.00002197
Iteration 106/1000 | Loss: 0.00002197
Iteration 107/1000 | Loss: 0.00002197
Iteration 108/1000 | Loss: 0.00002197
Iteration 109/1000 | Loss: 0.00002197
Iteration 110/1000 | Loss: 0.00002197
Iteration 111/1000 | Loss: 0.00002197
Iteration 112/1000 | Loss: 0.00002197
Iteration 113/1000 | Loss: 0.00002197
Iteration 114/1000 | Loss: 0.00002197
Iteration 115/1000 | Loss: 0.00002197
Iteration 116/1000 | Loss: 0.00002197
Iteration 117/1000 | Loss: 0.00002197
Iteration 118/1000 | Loss: 0.00002197
Iteration 119/1000 | Loss: 0.00002197
Iteration 120/1000 | Loss: 0.00002197
Iteration 121/1000 | Loss: 0.00002196
Iteration 122/1000 | Loss: 0.00002196
Iteration 123/1000 | Loss: 0.00002196
Iteration 124/1000 | Loss: 0.00002196
Iteration 125/1000 | Loss: 0.00002196
Iteration 126/1000 | Loss: 0.00002196
Iteration 127/1000 | Loss: 0.00002196
Iteration 128/1000 | Loss: 0.00002196
Iteration 129/1000 | Loss: 0.00002196
Iteration 130/1000 | Loss: 0.00002196
Iteration 131/1000 | Loss: 0.00002196
Iteration 132/1000 | Loss: 0.00002196
Iteration 133/1000 | Loss: 0.00002196
Iteration 134/1000 | Loss: 0.00002196
Iteration 135/1000 | Loss: 0.00002196
Iteration 136/1000 | Loss: 0.00002196
Iteration 137/1000 | Loss: 0.00002196
Iteration 138/1000 | Loss: 0.00002196
Iteration 139/1000 | Loss: 0.00002196
Iteration 140/1000 | Loss: 0.00002196
Iteration 141/1000 | Loss: 0.00002196
Iteration 142/1000 | Loss: 0.00002196
Iteration 143/1000 | Loss: 0.00002196
Iteration 144/1000 | Loss: 0.00002196
Iteration 145/1000 | Loss: 0.00002196
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [2.195743945776485e-05, 2.195743945776485e-05, 2.195743945776485e-05, 2.195743945776485e-05, 2.195743945776485e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.195743945776485e-05

Optimization complete. Final v2v error: 3.919405937194824 mm

Highest mean error: 4.437427520751953 mm for frame 49

Lowest mean error: 3.52229642868042 mm for frame 56

Saving results

Total time: 37.2441291809082
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1034/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1034.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1034
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00449060
Iteration 2/25 | Loss: 0.00091720
Iteration 3/25 | Loss: 0.00077222
Iteration 4/25 | Loss: 0.00075165
Iteration 5/25 | Loss: 0.00074675
Iteration 6/25 | Loss: 0.00074604
Iteration 7/25 | Loss: 0.00074604
Iteration 8/25 | Loss: 0.00074604
Iteration 9/25 | Loss: 0.00074604
Iteration 10/25 | Loss: 0.00074604
Iteration 11/25 | Loss: 0.00074604
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007460360648110509, 0.0007460360648110509, 0.0007460360648110509, 0.0007460360648110509, 0.0007460360648110509]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007460360648110509

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.76571894
Iteration 2/25 | Loss: 0.00031188
Iteration 3/25 | Loss: 0.00031188
Iteration 4/25 | Loss: 0.00031188
Iteration 5/25 | Loss: 0.00031188
Iteration 6/25 | Loss: 0.00031188
Iteration 7/25 | Loss: 0.00031188
Iteration 8/25 | Loss: 0.00031188
Iteration 9/25 | Loss: 0.00031188
Iteration 10/25 | Loss: 0.00031188
Iteration 11/25 | Loss: 0.00031188
Iteration 12/25 | Loss: 0.00031188
Iteration 13/25 | Loss: 0.00031188
Iteration 14/25 | Loss: 0.00031188
Iteration 15/25 | Loss: 0.00031188
Iteration 16/25 | Loss: 0.00031188
Iteration 17/25 | Loss: 0.00031188
Iteration 18/25 | Loss: 0.00031188
Iteration 19/25 | Loss: 0.00031188
Iteration 20/25 | Loss: 0.00031188
Iteration 21/25 | Loss: 0.00031188
Iteration 22/25 | Loss: 0.00031188
Iteration 23/25 | Loss: 0.00031188
Iteration 24/25 | Loss: 0.00031188
Iteration 25/25 | Loss: 0.00031188
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0003118756867479533, 0.0003118756867479533, 0.0003118756867479533, 0.0003118756867479533, 0.0003118756867479533]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003118756867479533

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031188
Iteration 2/1000 | Loss: 0.00002225
Iteration 3/1000 | Loss: 0.00001827
Iteration 4/1000 | Loss: 0.00001699
Iteration 5/1000 | Loss: 0.00001604
Iteration 6/1000 | Loss: 0.00001567
Iteration 7/1000 | Loss: 0.00001535
Iteration 8/1000 | Loss: 0.00001523
Iteration 9/1000 | Loss: 0.00001503
Iteration 10/1000 | Loss: 0.00001483
Iteration 11/1000 | Loss: 0.00001478
Iteration 12/1000 | Loss: 0.00001477
Iteration 13/1000 | Loss: 0.00001476
Iteration 14/1000 | Loss: 0.00001476
Iteration 15/1000 | Loss: 0.00001475
Iteration 16/1000 | Loss: 0.00001472
Iteration 17/1000 | Loss: 0.00001471
Iteration 18/1000 | Loss: 0.00001469
Iteration 19/1000 | Loss: 0.00001462
Iteration 20/1000 | Loss: 0.00001461
Iteration 21/1000 | Loss: 0.00001458
Iteration 22/1000 | Loss: 0.00001455
Iteration 23/1000 | Loss: 0.00001452
Iteration 24/1000 | Loss: 0.00001451
Iteration 25/1000 | Loss: 0.00001451
Iteration 26/1000 | Loss: 0.00001448
Iteration 27/1000 | Loss: 0.00001447
Iteration 28/1000 | Loss: 0.00001447
Iteration 29/1000 | Loss: 0.00001447
Iteration 30/1000 | Loss: 0.00001446
Iteration 31/1000 | Loss: 0.00001446
Iteration 32/1000 | Loss: 0.00001443
Iteration 33/1000 | Loss: 0.00001442
Iteration 34/1000 | Loss: 0.00001434
Iteration 35/1000 | Loss: 0.00001431
Iteration 36/1000 | Loss: 0.00001431
Iteration 37/1000 | Loss: 0.00001426
Iteration 38/1000 | Loss: 0.00001426
Iteration 39/1000 | Loss: 0.00001425
Iteration 40/1000 | Loss: 0.00001425
Iteration 41/1000 | Loss: 0.00001424
Iteration 42/1000 | Loss: 0.00001424
Iteration 43/1000 | Loss: 0.00001422
Iteration 44/1000 | Loss: 0.00001421
Iteration 45/1000 | Loss: 0.00001421
Iteration 46/1000 | Loss: 0.00001421
Iteration 47/1000 | Loss: 0.00001420
Iteration 48/1000 | Loss: 0.00001420
Iteration 49/1000 | Loss: 0.00001420
Iteration 50/1000 | Loss: 0.00001418
Iteration 51/1000 | Loss: 0.00001418
Iteration 52/1000 | Loss: 0.00001418
Iteration 53/1000 | Loss: 0.00001418
Iteration 54/1000 | Loss: 0.00001418
Iteration 55/1000 | Loss: 0.00001418
Iteration 56/1000 | Loss: 0.00001418
Iteration 57/1000 | Loss: 0.00001418
Iteration 58/1000 | Loss: 0.00001418
Iteration 59/1000 | Loss: 0.00001418
Iteration 60/1000 | Loss: 0.00001418
Iteration 61/1000 | Loss: 0.00001418
Iteration 62/1000 | Loss: 0.00001418
Iteration 63/1000 | Loss: 0.00001417
Iteration 64/1000 | Loss: 0.00001417
Iteration 65/1000 | Loss: 0.00001417
Iteration 66/1000 | Loss: 0.00001417
Iteration 67/1000 | Loss: 0.00001417
Iteration 68/1000 | Loss: 0.00001417
Iteration 69/1000 | Loss: 0.00001417
Iteration 70/1000 | Loss: 0.00001417
Iteration 71/1000 | Loss: 0.00001417
Iteration 72/1000 | Loss: 0.00001417
Iteration 73/1000 | Loss: 0.00001417
Iteration 74/1000 | Loss: 0.00001417
Iteration 75/1000 | Loss: 0.00001417
Iteration 76/1000 | Loss: 0.00001417
Iteration 77/1000 | Loss: 0.00001417
Iteration 78/1000 | Loss: 0.00001417
Iteration 79/1000 | Loss: 0.00001417
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 79. Stopping optimization.
Last 5 losses: [1.417310704709962e-05, 1.417310704709962e-05, 1.417310704709962e-05, 1.417310704709962e-05, 1.417310704709962e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.417310704709962e-05

Optimization complete. Final v2v error: 3.1764516830444336 mm

Highest mean error: 3.6590843200683594 mm for frame 94

Lowest mean error: 2.952542781829834 mm for frame 48

Saving results

Total time: 33.70015025138855
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01124183
Iteration 2/25 | Loss: 0.01124182
Iteration 3/25 | Loss: 0.00376263
Iteration 4/25 | Loss: 0.00283551
Iteration 5/25 | Loss: 0.00251053
Iteration 6/25 | Loss: 0.00217364
Iteration 7/25 | Loss: 0.00195373
Iteration 8/25 | Loss: 0.00176295
Iteration 9/25 | Loss: 0.00161782
Iteration 10/25 | Loss: 0.00151000
Iteration 11/25 | Loss: 0.00148180
Iteration 12/25 | Loss: 0.00143706
Iteration 13/25 | Loss: 0.00138760
Iteration 14/25 | Loss: 0.00135605
Iteration 15/25 | Loss: 0.00130437
Iteration 16/25 | Loss: 0.00126074
Iteration 17/25 | Loss: 0.00122280
Iteration 18/25 | Loss: 0.00118930
Iteration 19/25 | Loss: 0.00119103
Iteration 20/25 | Loss: 0.00116941
Iteration 21/25 | Loss: 0.00116241
Iteration 22/25 | Loss: 0.00115817
Iteration 23/25 | Loss: 0.00115060
Iteration 24/25 | Loss: 0.00112710
Iteration 25/25 | Loss: 0.00111955

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26630092
Iteration 2/25 | Loss: 0.00322512
Iteration 3/25 | Loss: 0.00284048
Iteration 4/25 | Loss: 0.00284048
Iteration 5/25 | Loss: 0.00284048
Iteration 6/25 | Loss: 0.00284048
Iteration 7/25 | Loss: 0.00284048
Iteration 8/25 | Loss: 0.00284048
Iteration 9/25 | Loss: 0.00284048
Iteration 10/25 | Loss: 0.00284048
Iteration 11/25 | Loss: 0.00284048
Iteration 12/25 | Loss: 0.00284048
Iteration 13/25 | Loss: 0.00284048
Iteration 14/25 | Loss: 0.00284048
Iteration 15/25 | Loss: 0.00284048
Iteration 16/25 | Loss: 0.00284048
Iteration 17/25 | Loss: 0.00284048
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0028404807671904564, 0.0028404807671904564, 0.0028404807671904564, 0.0028404807671904564, 0.0028404807671904564]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0028404807671904564

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00284048
Iteration 2/1000 | Loss: 0.00172974
Iteration 3/1000 | Loss: 0.00138391
Iteration 4/1000 | Loss: 0.00173367
Iteration 5/1000 | Loss: 0.00191944
Iteration 6/1000 | Loss: 0.00154264
Iteration 7/1000 | Loss: 0.00245037
Iteration 8/1000 | Loss: 0.00178360
Iteration 9/1000 | Loss: 0.00107807
Iteration 10/1000 | Loss: 0.00147795
Iteration 11/1000 | Loss: 0.00118688
Iteration 12/1000 | Loss: 0.00155703
Iteration 13/1000 | Loss: 0.00096396
Iteration 14/1000 | Loss: 0.00103722
Iteration 15/1000 | Loss: 0.00111073
Iteration 16/1000 | Loss: 0.00120196
Iteration 17/1000 | Loss: 0.00140227
Iteration 18/1000 | Loss: 0.00105534
Iteration 19/1000 | Loss: 0.00061521
Iteration 20/1000 | Loss: 0.00051959
Iteration 21/1000 | Loss: 0.00077534
Iteration 22/1000 | Loss: 0.00040639
Iteration 23/1000 | Loss: 0.00084181
Iteration 24/1000 | Loss: 0.00080942
Iteration 25/1000 | Loss: 0.00046655
Iteration 26/1000 | Loss: 0.00045039
Iteration 27/1000 | Loss: 0.00091382
Iteration 28/1000 | Loss: 0.00051809
Iteration 29/1000 | Loss: 0.00089750
Iteration 30/1000 | Loss: 0.00018318
Iteration 31/1000 | Loss: 0.00028522
Iteration 32/1000 | Loss: 0.00031568
Iteration 33/1000 | Loss: 0.00032210
Iteration 34/1000 | Loss: 0.00024973
Iteration 35/1000 | Loss: 0.00060963
Iteration 36/1000 | Loss: 0.00024556
Iteration 37/1000 | Loss: 0.00042436
Iteration 38/1000 | Loss: 0.00021517
Iteration 39/1000 | Loss: 0.00015444
Iteration 40/1000 | Loss: 0.00043048
Iteration 41/1000 | Loss: 0.00346973
Iteration 42/1000 | Loss: 0.00164655
Iteration 43/1000 | Loss: 0.00153410
Iteration 44/1000 | Loss: 0.00093613
Iteration 45/1000 | Loss: 0.00042957
Iteration 46/1000 | Loss: 0.00063500
Iteration 47/1000 | Loss: 0.00024557
Iteration 48/1000 | Loss: 0.00096796
Iteration 49/1000 | Loss: 0.00220065
Iteration 50/1000 | Loss: 0.00099736
Iteration 51/1000 | Loss: 0.00028619
Iteration 52/1000 | Loss: 0.00063772
Iteration 53/1000 | Loss: 0.00129768
Iteration 54/1000 | Loss: 0.00206921
Iteration 55/1000 | Loss: 0.00069930
Iteration 56/1000 | Loss: 0.00098575
Iteration 57/1000 | Loss: 0.00032807
Iteration 58/1000 | Loss: 0.00020973
Iteration 59/1000 | Loss: 0.00054245
Iteration 60/1000 | Loss: 0.00022425
Iteration 61/1000 | Loss: 0.00050021
Iteration 62/1000 | Loss: 0.00045628
Iteration 63/1000 | Loss: 0.00027174
Iteration 64/1000 | Loss: 0.00130452
Iteration 65/1000 | Loss: 0.00204042
Iteration 66/1000 | Loss: 0.00161229
Iteration 67/1000 | Loss: 0.00139331
Iteration 68/1000 | Loss: 0.00013525
Iteration 69/1000 | Loss: 0.00014301
Iteration 70/1000 | Loss: 0.00038877
Iteration 71/1000 | Loss: 0.00024726
Iteration 72/1000 | Loss: 0.00099641
Iteration 73/1000 | Loss: 0.00075266
Iteration 74/1000 | Loss: 0.00016477
Iteration 75/1000 | Loss: 0.00018043
Iteration 76/1000 | Loss: 0.00008265
Iteration 77/1000 | Loss: 0.00013269
Iteration 78/1000 | Loss: 0.00009944
Iteration 79/1000 | Loss: 0.00007965
Iteration 80/1000 | Loss: 0.00013091
Iteration 81/1000 | Loss: 0.00010663
Iteration 82/1000 | Loss: 0.00010119
Iteration 83/1000 | Loss: 0.00010837
Iteration 84/1000 | Loss: 0.00010297
Iteration 85/1000 | Loss: 0.00008225
Iteration 86/1000 | Loss: 0.00011769
Iteration 87/1000 | Loss: 0.00007305
Iteration 88/1000 | Loss: 0.00010466
Iteration 89/1000 | Loss: 0.00011979
Iteration 90/1000 | Loss: 0.00010304
Iteration 91/1000 | Loss: 0.00015067
Iteration 92/1000 | Loss: 0.00009257
Iteration 93/1000 | Loss: 0.00028609
Iteration 94/1000 | Loss: 0.00017217
Iteration 95/1000 | Loss: 0.00015078
Iteration 96/1000 | Loss: 0.00026850
Iteration 97/1000 | Loss: 0.00008174
Iteration 98/1000 | Loss: 0.00034235
Iteration 99/1000 | Loss: 0.00027288
Iteration 100/1000 | Loss: 0.00029189
Iteration 101/1000 | Loss: 0.00012269
Iteration 102/1000 | Loss: 0.00009503
Iteration 103/1000 | Loss: 0.00009171
Iteration 104/1000 | Loss: 0.00006963
Iteration 105/1000 | Loss: 0.00007494
Iteration 106/1000 | Loss: 0.00006877
Iteration 107/1000 | Loss: 0.00008967
Iteration 108/1000 | Loss: 0.00008753
Iteration 109/1000 | Loss: 0.00009148
Iteration 110/1000 | Loss: 0.00007911
Iteration 111/1000 | Loss: 0.00007896
Iteration 112/1000 | Loss: 0.00007122
Iteration 113/1000 | Loss: 0.00009078
Iteration 114/1000 | Loss: 0.00011161
Iteration 115/1000 | Loss: 0.00012065
Iteration 116/1000 | Loss: 0.00010607
Iteration 117/1000 | Loss: 0.00009921
Iteration 118/1000 | Loss: 0.00008239
Iteration 119/1000 | Loss: 0.00008457
Iteration 120/1000 | Loss: 0.00009122
Iteration 121/1000 | Loss: 0.00009144
Iteration 122/1000 | Loss: 0.00008816
Iteration 123/1000 | Loss: 0.00008826
Iteration 124/1000 | Loss: 0.00009255
Iteration 125/1000 | Loss: 0.00008566
Iteration 126/1000 | Loss: 0.00008808
Iteration 127/1000 | Loss: 0.00009433
Iteration 128/1000 | Loss: 0.00006884
Iteration 129/1000 | Loss: 0.00005924
Iteration 130/1000 | Loss: 0.00008709
Iteration 131/1000 | Loss: 0.00010605
Iteration 132/1000 | Loss: 0.00009724
Iteration 133/1000 | Loss: 0.00006746
Iteration 134/1000 | Loss: 0.00008156
Iteration 135/1000 | Loss: 0.00008340
Iteration 136/1000 | Loss: 0.00009455
Iteration 137/1000 | Loss: 0.00008903
Iteration 138/1000 | Loss: 0.00006305
Iteration 139/1000 | Loss: 0.00007593
Iteration 140/1000 | Loss: 0.00008783
Iteration 141/1000 | Loss: 0.00008522
Iteration 142/1000 | Loss: 0.00008217
Iteration 143/1000 | Loss: 0.00008863
Iteration 144/1000 | Loss: 0.00009351
Iteration 145/1000 | Loss: 0.00007868
Iteration 146/1000 | Loss: 0.00008961
Iteration 147/1000 | Loss: 0.00008177
Iteration 148/1000 | Loss: 0.00007479
Iteration 149/1000 | Loss: 0.00005402
Iteration 150/1000 | Loss: 0.00006145
Iteration 151/1000 | Loss: 0.00005022
Iteration 152/1000 | Loss: 0.00007193
Iteration 153/1000 | Loss: 0.00008018
Iteration 154/1000 | Loss: 0.00006019
Iteration 155/1000 | Loss: 0.00007066
Iteration 156/1000 | Loss: 0.00005703
Iteration 157/1000 | Loss: 0.00006167
Iteration 158/1000 | Loss: 0.00005996
Iteration 159/1000 | Loss: 0.00004370
Iteration 160/1000 | Loss: 0.00005934
Iteration 161/1000 | Loss: 0.00005465
Iteration 162/1000 | Loss: 0.00005454
Iteration 163/1000 | Loss: 0.00006226
Iteration 164/1000 | Loss: 0.00007144
Iteration 165/1000 | Loss: 0.00006022
Iteration 166/1000 | Loss: 0.00005535
Iteration 167/1000 | Loss: 0.00005049
Iteration 168/1000 | Loss: 0.00005815
Iteration 169/1000 | Loss: 0.00006149
Iteration 170/1000 | Loss: 0.00006130
Iteration 171/1000 | Loss: 0.00006218
Iteration 172/1000 | Loss: 0.00006162
Iteration 173/1000 | Loss: 0.00005640
Iteration 174/1000 | Loss: 0.00006056
Iteration 175/1000 | Loss: 0.00005450
Iteration 176/1000 | Loss: 0.00006036
Iteration 177/1000 | Loss: 0.00005367
Iteration 178/1000 | Loss: 0.00006263
Iteration 179/1000 | Loss: 0.00004911
Iteration 180/1000 | Loss: 0.00005583
Iteration 181/1000 | Loss: 0.00007199
Iteration 182/1000 | Loss: 0.00006485
Iteration 183/1000 | Loss: 0.00007360
Iteration 184/1000 | Loss: 0.00007166
Iteration 185/1000 | Loss: 0.00007477
Iteration 186/1000 | Loss: 0.00006906
Iteration 187/1000 | Loss: 0.00008541
Iteration 188/1000 | Loss: 0.00005079
Iteration 189/1000 | Loss: 0.00006741
Iteration 190/1000 | Loss: 0.00004495
Iteration 191/1000 | Loss: 0.00004655
Iteration 192/1000 | Loss: 0.00005316
Iteration 193/1000 | Loss: 0.00004330
Iteration 194/1000 | Loss: 0.00005200
Iteration 195/1000 | Loss: 0.00005077
Iteration 196/1000 | Loss: 0.00020122
Iteration 197/1000 | Loss: 0.00006205
Iteration 198/1000 | Loss: 0.00005927
Iteration 199/1000 | Loss: 0.00003841
Iteration 200/1000 | Loss: 0.00003808
Iteration 201/1000 | Loss: 0.00004206
Iteration 202/1000 | Loss: 0.00004386
Iteration 203/1000 | Loss: 0.00005989
Iteration 204/1000 | Loss: 0.00005092
Iteration 205/1000 | Loss: 0.00005472
Iteration 206/1000 | Loss: 0.00004926
Iteration 207/1000 | Loss: 0.00003951
Iteration 208/1000 | Loss: 0.00004264
Iteration 209/1000 | Loss: 0.00008051
Iteration 210/1000 | Loss: 0.00005602
Iteration 211/1000 | Loss: 0.00004493
Iteration 212/1000 | Loss: 0.00005180
Iteration 213/1000 | Loss: 0.00004197
Iteration 214/1000 | Loss: 0.00003644
Iteration 215/1000 | Loss: 0.00003138
Iteration 216/1000 | Loss: 0.00003897
Iteration 217/1000 | Loss: 0.00004888
Iteration 218/1000 | Loss: 0.00003715
Iteration 219/1000 | Loss: 0.00003986
Iteration 220/1000 | Loss: 0.00004662
Iteration 221/1000 | Loss: 0.00005936
Iteration 222/1000 | Loss: 0.00004912
Iteration 223/1000 | Loss: 0.00003343
Iteration 224/1000 | Loss: 0.00003771
Iteration 225/1000 | Loss: 0.00003298
Iteration 226/1000 | Loss: 0.00004078
Iteration 227/1000 | Loss: 0.00004485
Iteration 228/1000 | Loss: 0.00004425
Iteration 229/1000 | Loss: 0.00003942
Iteration 230/1000 | Loss: 0.00004928
Iteration 231/1000 | Loss: 0.00004386
Iteration 232/1000 | Loss: 0.00004120
Iteration 233/1000 | Loss: 0.00003292
Iteration 234/1000 | Loss: 0.00003378
Iteration 235/1000 | Loss: 0.00004140
Iteration 236/1000 | Loss: 0.00004236
Iteration 237/1000 | Loss: 0.00004048
Iteration 238/1000 | Loss: 0.00006212
Iteration 239/1000 | Loss: 0.00003245
Iteration 240/1000 | Loss: 0.00002992
Iteration 241/1000 | Loss: 0.00002910
Iteration 242/1000 | Loss: 0.00002856
Iteration 243/1000 | Loss: 0.00004484
Iteration 244/1000 | Loss: 0.00003213
Iteration 245/1000 | Loss: 0.00003550
Iteration 246/1000 | Loss: 0.00012328
Iteration 247/1000 | Loss: 0.00006948
Iteration 248/1000 | Loss: 0.00003384
Iteration 249/1000 | Loss: 0.00003575
Iteration 250/1000 | Loss: 0.00002986
Iteration 251/1000 | Loss: 0.00003583
Iteration 252/1000 | Loss: 0.00003295
Iteration 253/1000 | Loss: 0.00003369
Iteration 254/1000 | Loss: 0.00003130
Iteration 255/1000 | Loss: 0.00003593
Iteration 256/1000 | Loss: 0.00003820
Iteration 257/1000 | Loss: 0.00003567
Iteration 258/1000 | Loss: 0.00004216
Iteration 259/1000 | Loss: 0.00004399
Iteration 260/1000 | Loss: 0.00003153
Iteration 261/1000 | Loss: 0.00004175
Iteration 262/1000 | Loss: 0.00004459
Iteration 263/1000 | Loss: 0.00003887
Iteration 264/1000 | Loss: 0.00004099
Iteration 265/1000 | Loss: 0.00005558
Iteration 266/1000 | Loss: 0.00005311
Iteration 267/1000 | Loss: 0.00005010
Iteration 268/1000 | Loss: 0.00004230
Iteration 269/1000 | Loss: 0.00004456
Iteration 270/1000 | Loss: 0.00003334
Iteration 271/1000 | Loss: 0.00006381
Iteration 272/1000 | Loss: 0.00003980
Iteration 273/1000 | Loss: 0.00004658
Iteration 274/1000 | Loss: 0.00005227
Iteration 275/1000 | Loss: 0.00003855
Iteration 276/1000 | Loss: 0.00003207
Iteration 277/1000 | Loss: 0.00003030
Iteration 278/1000 | Loss: 0.00004780
Iteration 279/1000 | Loss: 0.00005428
Iteration 280/1000 | Loss: 0.00005048
Iteration 281/1000 | Loss: 0.00003223
Iteration 282/1000 | Loss: 0.00004589
Iteration 283/1000 | Loss: 0.00005289
Iteration 284/1000 | Loss: 0.00004669
Iteration 285/1000 | Loss: 0.00003115
Iteration 286/1000 | Loss: 0.00005394
Iteration 287/1000 | Loss: 0.00002998
Iteration 288/1000 | Loss: 0.00003582
Iteration 289/1000 | Loss: 0.00002874
Iteration 290/1000 | Loss: 0.00004049
Iteration 291/1000 | Loss: 0.00002779
Iteration 292/1000 | Loss: 0.00002693
Iteration 293/1000 | Loss: 0.00002655
Iteration 294/1000 | Loss: 0.00002619
Iteration 295/1000 | Loss: 0.00003375
Iteration 296/1000 | Loss: 0.00003375
Iteration 297/1000 | Loss: 0.00007923
Iteration 298/1000 | Loss: 0.00002632
Iteration 299/1000 | Loss: 0.00002598
Iteration 300/1000 | Loss: 0.00002595
Iteration 301/1000 | Loss: 0.00002595
Iteration 302/1000 | Loss: 0.00002594
Iteration 303/1000 | Loss: 0.00002593
Iteration 304/1000 | Loss: 0.00002592
Iteration 305/1000 | Loss: 0.00002592
Iteration 306/1000 | Loss: 0.00002592
Iteration 307/1000 | Loss: 0.00002592
Iteration 308/1000 | Loss: 0.00002592
Iteration 309/1000 | Loss: 0.00002592
Iteration 310/1000 | Loss: 0.00002592
Iteration 311/1000 | Loss: 0.00002592
Iteration 312/1000 | Loss: 0.00002592
Iteration 313/1000 | Loss: 0.00002592
Iteration 314/1000 | Loss: 0.00002592
Iteration 315/1000 | Loss: 0.00002591
Iteration 316/1000 | Loss: 0.00002591
Iteration 317/1000 | Loss: 0.00002591
Iteration 318/1000 | Loss: 0.00002591
Iteration 319/1000 | Loss: 0.00002589
Iteration 320/1000 | Loss: 0.00002589
Iteration 321/1000 | Loss: 0.00002588
Iteration 322/1000 | Loss: 0.00002588
Iteration 323/1000 | Loss: 0.00002587
Iteration 324/1000 | Loss: 0.00002587
Iteration 325/1000 | Loss: 0.00002586
Iteration 326/1000 | Loss: 0.00002586
Iteration 327/1000 | Loss: 0.00002586
Iteration 328/1000 | Loss: 0.00002586
Iteration 329/1000 | Loss: 0.00002585
Iteration 330/1000 | Loss: 0.00002585
Iteration 331/1000 | Loss: 0.00004255
Iteration 332/1000 | Loss: 0.00002655
Iteration 333/1000 | Loss: 0.00002593
Iteration 334/1000 | Loss: 0.00002577
Iteration 335/1000 | Loss: 0.00002577
Iteration 336/1000 | Loss: 0.00002577
Iteration 337/1000 | Loss: 0.00002577
Iteration 338/1000 | Loss: 0.00002576
Iteration 339/1000 | Loss: 0.00002576
Iteration 340/1000 | Loss: 0.00002576
Iteration 341/1000 | Loss: 0.00002576
Iteration 342/1000 | Loss: 0.00002576
Iteration 343/1000 | Loss: 0.00002576
Iteration 344/1000 | Loss: 0.00002576
Iteration 345/1000 | Loss: 0.00002576
Iteration 346/1000 | Loss: 0.00002575
Iteration 347/1000 | Loss: 0.00002575
Iteration 348/1000 | Loss: 0.00002575
Iteration 349/1000 | Loss: 0.00002574
Iteration 350/1000 | Loss: 0.00002574
Iteration 351/1000 | Loss: 0.00002574
Iteration 352/1000 | Loss: 0.00002574
Iteration 353/1000 | Loss: 0.00002574
Iteration 354/1000 | Loss: 0.00002574
Iteration 355/1000 | Loss: 0.00002574
Iteration 356/1000 | Loss: 0.00002573
Iteration 357/1000 | Loss: 0.00002573
Iteration 358/1000 | Loss: 0.00002573
Iteration 359/1000 | Loss: 0.00002573
Iteration 360/1000 | Loss: 0.00002572
Iteration 361/1000 | Loss: 0.00002572
Iteration 362/1000 | Loss: 0.00002572
Iteration 363/1000 | Loss: 0.00002572
Iteration 364/1000 | Loss: 0.00002572
Iteration 365/1000 | Loss: 0.00002572
Iteration 366/1000 | Loss: 0.00002572
Iteration 367/1000 | Loss: 0.00002571
Iteration 368/1000 | Loss: 0.00002571
Iteration 369/1000 | Loss: 0.00002571
Iteration 370/1000 | Loss: 0.00002571
Iteration 371/1000 | Loss: 0.00002569
Iteration 372/1000 | Loss: 0.00002569
Iteration 373/1000 | Loss: 0.00002569
Iteration 374/1000 | Loss: 0.00002569
Iteration 375/1000 | Loss: 0.00002569
Iteration 376/1000 | Loss: 0.00002568
Iteration 377/1000 | Loss: 0.00002568
Iteration 378/1000 | Loss: 0.00002568
Iteration 379/1000 | Loss: 0.00002568
Iteration 380/1000 | Loss: 0.00002568
Iteration 381/1000 | Loss: 0.00002568
Iteration 382/1000 | Loss: 0.00002567
Iteration 383/1000 | Loss: 0.00002567
Iteration 384/1000 | Loss: 0.00002566
Iteration 385/1000 | Loss: 0.00002566
Iteration 386/1000 | Loss: 0.00002565
Iteration 387/1000 | Loss: 0.00002565
Iteration 388/1000 | Loss: 0.00002565
Iteration 389/1000 | Loss: 0.00002565
Iteration 390/1000 | Loss: 0.00002565
Iteration 391/1000 | Loss: 0.00002565
Iteration 392/1000 | Loss: 0.00002564
Iteration 393/1000 | Loss: 0.00002564
Iteration 394/1000 | Loss: 0.00002562
Iteration 395/1000 | Loss: 0.00002562
Iteration 396/1000 | Loss: 0.00002562
Iteration 397/1000 | Loss: 0.00002562
Iteration 398/1000 | Loss: 0.00002561
Iteration 399/1000 | Loss: 0.00002561
Iteration 400/1000 | Loss: 0.00002561
Iteration 401/1000 | Loss: 0.00002561
Iteration 402/1000 | Loss: 0.00002560
Iteration 403/1000 | Loss: 0.00002560
Iteration 404/1000 | Loss: 0.00002560
Iteration 405/1000 | Loss: 0.00002560
Iteration 406/1000 | Loss: 0.00002559
Iteration 407/1000 | Loss: 0.00002559
Iteration 408/1000 | Loss: 0.00002559
Iteration 409/1000 | Loss: 0.00002559
Iteration 410/1000 | Loss: 0.00002559
Iteration 411/1000 | Loss: 0.00002559
Iteration 412/1000 | Loss: 0.00002559
Iteration 413/1000 | Loss: 0.00002559
Iteration 414/1000 | Loss: 0.00002559
Iteration 415/1000 | Loss: 0.00002558
Iteration 416/1000 | Loss: 0.00002558
Iteration 417/1000 | Loss: 0.00002557
Iteration 418/1000 | Loss: 0.00002557
Iteration 419/1000 | Loss: 0.00002556
Iteration 420/1000 | Loss: 0.00002555
Iteration 421/1000 | Loss: 0.00002555
Iteration 422/1000 | Loss: 0.00002550
Iteration 423/1000 | Loss: 0.00002549
Iteration 424/1000 | Loss: 0.00005670
Iteration 425/1000 | Loss: 0.00003040
Iteration 426/1000 | Loss: 0.00002812
Iteration 427/1000 | Loss: 0.00005631
Iteration 428/1000 | Loss: 0.00002623
Iteration 429/1000 | Loss: 0.00002569
Iteration 430/1000 | Loss: 0.00003324
Iteration 431/1000 | Loss: 0.00002535
Iteration 432/1000 | Loss: 0.00002529
Iteration 433/1000 | Loss: 0.00002529
Iteration 434/1000 | Loss: 0.00002528
Iteration 435/1000 | Loss: 0.00002528
Iteration 436/1000 | Loss: 0.00002527
Iteration 437/1000 | Loss: 0.00002527
Iteration 438/1000 | Loss: 0.00002525
Iteration 439/1000 | Loss: 0.00002520
Iteration 440/1000 | Loss: 0.00002519
Iteration 441/1000 | Loss: 0.00002519
Iteration 442/1000 | Loss: 0.00002519
Iteration 443/1000 | Loss: 0.00002518
Iteration 444/1000 | Loss: 0.00002518
Iteration 445/1000 | Loss: 0.00002518
Iteration 446/1000 | Loss: 0.00002518
Iteration 447/1000 | Loss: 0.00002518
Iteration 448/1000 | Loss: 0.00002517
Iteration 449/1000 | Loss: 0.00002517
Iteration 450/1000 | Loss: 0.00002514
Iteration 451/1000 | Loss: 0.00002512
Iteration 452/1000 | Loss: 0.00002512
Iteration 453/1000 | Loss: 0.00002512
Iteration 454/1000 | Loss: 0.00002512
Iteration 455/1000 | Loss: 0.00002512
Iteration 456/1000 | Loss: 0.00002512
Iteration 457/1000 | Loss: 0.00002512
Iteration 458/1000 | Loss: 0.00002512
Iteration 459/1000 | Loss: 0.00002508
Iteration 460/1000 | Loss: 0.00002508
Iteration 461/1000 | Loss: 0.00002508
Iteration 462/1000 | Loss: 0.00002508
Iteration 463/1000 | Loss: 0.00002508
Iteration 464/1000 | Loss: 0.00002508
Iteration 465/1000 | Loss: 0.00002508
Iteration 466/1000 | Loss: 0.00002508
Iteration 467/1000 | Loss: 0.00002508
Iteration 468/1000 | Loss: 0.00002508
Iteration 469/1000 | Loss: 0.00002507
Iteration 470/1000 | Loss: 0.00002507
Iteration 471/1000 | Loss: 0.00002507
Iteration 472/1000 | Loss: 0.00002506
Iteration 473/1000 | Loss: 0.00002505
Iteration 474/1000 | Loss: 0.00002505
Iteration 475/1000 | Loss: 0.00002505
Iteration 476/1000 | Loss: 0.00002504
Iteration 477/1000 | Loss: 0.00002504
Iteration 478/1000 | Loss: 0.00002504
Iteration 479/1000 | Loss: 0.00002504
Iteration 480/1000 | Loss: 0.00002504
Iteration 481/1000 | Loss: 0.00002504
Iteration 482/1000 | Loss: 0.00002504
Iteration 483/1000 | Loss: 0.00005040
Iteration 484/1000 | Loss: 0.00002916
Iteration 485/1000 | Loss: 0.00003377
Iteration 486/1000 | Loss: 0.00002502
Iteration 487/1000 | Loss: 0.00002502
Iteration 488/1000 | Loss: 0.00002501
Iteration 489/1000 | Loss: 0.00002501
Iteration 490/1000 | Loss: 0.00002501
Iteration 491/1000 | Loss: 0.00002501
Iteration 492/1000 | Loss: 0.00002501
Iteration 493/1000 | Loss: 0.00002501
Iteration 494/1000 | Loss: 0.00002501
Iteration 495/1000 | Loss: 0.00002501
Iteration 496/1000 | Loss: 0.00002501
Iteration 497/1000 | Loss: 0.00002501
Iteration 498/1000 | Loss: 0.00002501
Iteration 499/1000 | Loss: 0.00002501
Iteration 500/1000 | Loss: 0.00002501
Iteration 501/1000 | Loss: 0.00002501
Iteration 502/1000 | Loss: 0.00002501
Iteration 503/1000 | Loss: 0.00002501
Iteration 504/1000 | Loss: 0.00002500
Iteration 505/1000 | Loss: 0.00002500
Iteration 506/1000 | Loss: 0.00003422
Iteration 507/1000 | Loss: 0.00004122
Iteration 508/1000 | Loss: 0.00002501
Iteration 509/1000 | Loss: 0.00002501
Iteration 510/1000 | Loss: 0.00002501
Iteration 511/1000 | Loss: 0.00002501
Iteration 512/1000 | Loss: 0.00002500
Iteration 513/1000 | Loss: 0.00002500
Iteration 514/1000 | Loss: 0.00002500
Iteration 515/1000 | Loss: 0.00002500
Iteration 516/1000 | Loss: 0.00002500
Iteration 517/1000 | Loss: 0.00002500
Iteration 518/1000 | Loss: 0.00002500
Iteration 519/1000 | Loss: 0.00002500
Iteration 520/1000 | Loss: 0.00002500
Iteration 521/1000 | Loss: 0.00002500
Iteration 522/1000 | Loss: 0.00002500
Iteration 523/1000 | Loss: 0.00002500
Iteration 524/1000 | Loss: 0.00002500
Iteration 525/1000 | Loss: 0.00002500
Iteration 526/1000 | Loss: 0.00002500
Iteration 527/1000 | Loss: 0.00002500
Iteration 528/1000 | Loss: 0.00002500
Iteration 529/1000 | Loss: 0.00002500
Iteration 530/1000 | Loss: 0.00002500
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 530. Stopping optimization.
Last 5 losses: [2.4998391381814145e-05, 2.4998391381814145e-05, 2.4998391381814145e-05, 2.4998391381814145e-05, 2.4998391381814145e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4998391381814145e-05

Optimization complete. Final v2v error: 3.8699920177459717 mm

Highest mean error: 12.568535804748535 mm for frame 238

Lowest mean error: 3.4193005561828613 mm for frame 19

Saving results

Total time: 575.9779114723206
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1052/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1052.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1052
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00821074
Iteration 2/25 | Loss: 0.00091985
Iteration 3/25 | Loss: 0.00078718
Iteration 4/25 | Loss: 0.00075919
Iteration 5/25 | Loss: 0.00075217
Iteration 6/25 | Loss: 0.00075097
Iteration 7/25 | Loss: 0.00075061
Iteration 8/25 | Loss: 0.00075061
Iteration 9/25 | Loss: 0.00075061
Iteration 10/25 | Loss: 0.00075061
Iteration 11/25 | Loss: 0.00075061
Iteration 12/25 | Loss: 0.00075061
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007506099063903093, 0.0007506099063903093, 0.0007506099063903093, 0.0007506099063903093, 0.0007506099063903093]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007506099063903093

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52891767
Iteration 2/25 | Loss: 0.00033293
Iteration 3/25 | Loss: 0.00033293
Iteration 4/25 | Loss: 0.00033293
Iteration 5/25 | Loss: 0.00033293
Iteration 6/25 | Loss: 0.00033293
Iteration 7/25 | Loss: 0.00033293
Iteration 8/25 | Loss: 0.00033293
Iteration 9/25 | Loss: 0.00033293
Iteration 10/25 | Loss: 0.00033293
Iteration 11/25 | Loss: 0.00033293
Iteration 12/25 | Loss: 0.00033293
Iteration 13/25 | Loss: 0.00033293
Iteration 14/25 | Loss: 0.00033293
Iteration 15/25 | Loss: 0.00033293
Iteration 16/25 | Loss: 0.00033293
Iteration 17/25 | Loss: 0.00033293
Iteration 18/25 | Loss: 0.00033293
Iteration 19/25 | Loss: 0.00033293
Iteration 20/25 | Loss: 0.00033293
Iteration 21/25 | Loss: 0.00033293
Iteration 22/25 | Loss: 0.00033293
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00033293102751486003, 0.00033293102751486003, 0.00033293102751486003, 0.00033293102751486003, 0.00033293102751486003]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00033293102751486003

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033293
Iteration 2/1000 | Loss: 0.00002653
Iteration 3/1000 | Loss: 0.00001933
Iteration 4/1000 | Loss: 0.00001827
Iteration 5/1000 | Loss: 0.00001736
Iteration 6/1000 | Loss: 0.00001697
Iteration 7/1000 | Loss: 0.00001650
Iteration 8/1000 | Loss: 0.00001624
Iteration 9/1000 | Loss: 0.00001600
Iteration 10/1000 | Loss: 0.00001585
Iteration 11/1000 | Loss: 0.00001571
Iteration 12/1000 | Loss: 0.00001567
Iteration 13/1000 | Loss: 0.00001566
Iteration 14/1000 | Loss: 0.00001560
Iteration 15/1000 | Loss: 0.00001558
Iteration 16/1000 | Loss: 0.00001558
Iteration 17/1000 | Loss: 0.00001557
Iteration 18/1000 | Loss: 0.00001556
Iteration 19/1000 | Loss: 0.00001556
Iteration 20/1000 | Loss: 0.00001556
Iteration 21/1000 | Loss: 0.00001555
Iteration 22/1000 | Loss: 0.00001555
Iteration 23/1000 | Loss: 0.00001554
Iteration 24/1000 | Loss: 0.00001552
Iteration 25/1000 | Loss: 0.00001552
Iteration 26/1000 | Loss: 0.00001552
Iteration 27/1000 | Loss: 0.00001551
Iteration 28/1000 | Loss: 0.00001550
Iteration 29/1000 | Loss: 0.00001550
Iteration 30/1000 | Loss: 0.00001547
Iteration 31/1000 | Loss: 0.00001547
Iteration 32/1000 | Loss: 0.00001547
Iteration 33/1000 | Loss: 0.00001546
Iteration 34/1000 | Loss: 0.00001545
Iteration 35/1000 | Loss: 0.00001545
Iteration 36/1000 | Loss: 0.00001545
Iteration 37/1000 | Loss: 0.00001544
Iteration 38/1000 | Loss: 0.00001544
Iteration 39/1000 | Loss: 0.00001543
Iteration 40/1000 | Loss: 0.00001542
Iteration 41/1000 | Loss: 0.00001542
Iteration 42/1000 | Loss: 0.00001542
Iteration 43/1000 | Loss: 0.00001541
Iteration 44/1000 | Loss: 0.00001541
Iteration 45/1000 | Loss: 0.00001540
Iteration 46/1000 | Loss: 0.00001540
Iteration 47/1000 | Loss: 0.00001540
Iteration 48/1000 | Loss: 0.00001538
Iteration 49/1000 | Loss: 0.00001538
Iteration 50/1000 | Loss: 0.00001538
Iteration 51/1000 | Loss: 0.00001538
Iteration 52/1000 | Loss: 0.00001538
Iteration 53/1000 | Loss: 0.00001538
Iteration 54/1000 | Loss: 0.00001538
Iteration 55/1000 | Loss: 0.00001538
Iteration 56/1000 | Loss: 0.00001538
Iteration 57/1000 | Loss: 0.00001538
Iteration 58/1000 | Loss: 0.00001537
Iteration 59/1000 | Loss: 0.00001537
Iteration 60/1000 | Loss: 0.00001536
Iteration 61/1000 | Loss: 0.00001534
Iteration 62/1000 | Loss: 0.00001534
Iteration 63/1000 | Loss: 0.00001534
Iteration 64/1000 | Loss: 0.00001534
Iteration 65/1000 | Loss: 0.00001534
Iteration 66/1000 | Loss: 0.00001534
Iteration 67/1000 | Loss: 0.00001534
Iteration 68/1000 | Loss: 0.00001534
Iteration 69/1000 | Loss: 0.00001533
Iteration 70/1000 | Loss: 0.00001533
Iteration 71/1000 | Loss: 0.00001533
Iteration 72/1000 | Loss: 0.00001533
Iteration 73/1000 | Loss: 0.00001533
Iteration 74/1000 | Loss: 0.00001533
Iteration 75/1000 | Loss: 0.00001533
Iteration 76/1000 | Loss: 0.00001533
Iteration 77/1000 | Loss: 0.00001531
Iteration 78/1000 | Loss: 0.00001531
Iteration 79/1000 | Loss: 0.00001530
Iteration 80/1000 | Loss: 0.00001530
Iteration 81/1000 | Loss: 0.00001530
Iteration 82/1000 | Loss: 0.00001529
Iteration 83/1000 | Loss: 0.00001529
Iteration 84/1000 | Loss: 0.00001529
Iteration 85/1000 | Loss: 0.00001529
Iteration 86/1000 | Loss: 0.00001529
Iteration 87/1000 | Loss: 0.00001528
Iteration 88/1000 | Loss: 0.00001528
Iteration 89/1000 | Loss: 0.00001528
Iteration 90/1000 | Loss: 0.00001528
Iteration 91/1000 | Loss: 0.00001528
Iteration 92/1000 | Loss: 0.00001527
Iteration 93/1000 | Loss: 0.00001527
Iteration 94/1000 | Loss: 0.00001527
Iteration 95/1000 | Loss: 0.00001527
Iteration 96/1000 | Loss: 0.00001527
Iteration 97/1000 | Loss: 0.00001527
Iteration 98/1000 | Loss: 0.00001527
Iteration 99/1000 | Loss: 0.00001527
Iteration 100/1000 | Loss: 0.00001527
Iteration 101/1000 | Loss: 0.00001527
Iteration 102/1000 | Loss: 0.00001527
Iteration 103/1000 | Loss: 0.00001526
Iteration 104/1000 | Loss: 0.00001526
Iteration 105/1000 | Loss: 0.00001526
Iteration 106/1000 | Loss: 0.00001526
Iteration 107/1000 | Loss: 0.00001526
Iteration 108/1000 | Loss: 0.00001526
Iteration 109/1000 | Loss: 0.00001526
Iteration 110/1000 | Loss: 0.00001526
Iteration 111/1000 | Loss: 0.00001526
Iteration 112/1000 | Loss: 0.00001526
Iteration 113/1000 | Loss: 0.00001526
Iteration 114/1000 | Loss: 0.00001526
Iteration 115/1000 | Loss: 0.00001525
Iteration 116/1000 | Loss: 0.00001525
Iteration 117/1000 | Loss: 0.00001525
Iteration 118/1000 | Loss: 0.00001525
Iteration 119/1000 | Loss: 0.00001525
Iteration 120/1000 | Loss: 0.00001525
Iteration 121/1000 | Loss: 0.00001525
Iteration 122/1000 | Loss: 0.00001525
Iteration 123/1000 | Loss: 0.00001524
Iteration 124/1000 | Loss: 0.00001524
Iteration 125/1000 | Loss: 0.00001524
Iteration 126/1000 | Loss: 0.00001524
Iteration 127/1000 | Loss: 0.00001524
Iteration 128/1000 | Loss: 0.00001524
Iteration 129/1000 | Loss: 0.00001524
Iteration 130/1000 | Loss: 0.00001524
Iteration 131/1000 | Loss: 0.00001524
Iteration 132/1000 | Loss: 0.00001524
Iteration 133/1000 | Loss: 0.00001524
Iteration 134/1000 | Loss: 0.00001524
Iteration 135/1000 | Loss: 0.00001524
Iteration 136/1000 | Loss: 0.00001524
Iteration 137/1000 | Loss: 0.00001524
Iteration 138/1000 | Loss: 0.00001524
Iteration 139/1000 | Loss: 0.00001524
Iteration 140/1000 | Loss: 0.00001524
Iteration 141/1000 | Loss: 0.00001524
Iteration 142/1000 | Loss: 0.00001524
Iteration 143/1000 | Loss: 0.00001524
Iteration 144/1000 | Loss: 0.00001524
Iteration 145/1000 | Loss: 0.00001524
Iteration 146/1000 | Loss: 0.00001524
Iteration 147/1000 | Loss: 0.00001524
Iteration 148/1000 | Loss: 0.00001524
Iteration 149/1000 | Loss: 0.00001524
Iteration 150/1000 | Loss: 0.00001524
Iteration 151/1000 | Loss: 0.00001524
Iteration 152/1000 | Loss: 0.00001524
Iteration 153/1000 | Loss: 0.00001524
Iteration 154/1000 | Loss: 0.00001524
Iteration 155/1000 | Loss: 0.00001524
Iteration 156/1000 | Loss: 0.00001524
Iteration 157/1000 | Loss: 0.00001524
Iteration 158/1000 | Loss: 0.00001524
Iteration 159/1000 | Loss: 0.00001524
Iteration 160/1000 | Loss: 0.00001524
Iteration 161/1000 | Loss: 0.00001524
Iteration 162/1000 | Loss: 0.00001524
Iteration 163/1000 | Loss: 0.00001524
Iteration 164/1000 | Loss: 0.00001524
Iteration 165/1000 | Loss: 0.00001524
Iteration 166/1000 | Loss: 0.00001524
Iteration 167/1000 | Loss: 0.00001524
Iteration 168/1000 | Loss: 0.00001524
Iteration 169/1000 | Loss: 0.00001524
Iteration 170/1000 | Loss: 0.00001524
Iteration 171/1000 | Loss: 0.00001524
Iteration 172/1000 | Loss: 0.00001524
Iteration 173/1000 | Loss: 0.00001524
Iteration 174/1000 | Loss: 0.00001524
Iteration 175/1000 | Loss: 0.00001524
Iteration 176/1000 | Loss: 0.00001524
Iteration 177/1000 | Loss: 0.00001524
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.523893115518149e-05, 1.523893115518149e-05, 1.523893115518149e-05, 1.523893115518149e-05, 1.523893115518149e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.523893115518149e-05

Optimization complete. Final v2v error: 3.336651086807251 mm

Highest mean error: 3.941352367401123 mm for frame 99

Lowest mean error: 3.115530014038086 mm for frame 40

Saving results

Total time: 36.809370279312134
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1029/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1029.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1029
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01095723
Iteration 2/25 | Loss: 0.00114463
Iteration 3/25 | Loss: 0.00078803
Iteration 4/25 | Loss: 0.00073939
Iteration 5/25 | Loss: 0.00073285
Iteration 6/25 | Loss: 0.00073171
Iteration 7/25 | Loss: 0.00073171
Iteration 8/25 | Loss: 0.00073171
Iteration 9/25 | Loss: 0.00073171
Iteration 10/25 | Loss: 0.00073171
Iteration 11/25 | Loss: 0.00073171
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007317059789784253, 0.0007317059789784253, 0.0007317059789784253, 0.0007317059789784253, 0.0007317059789784253]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007317059789784253

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.30334258
Iteration 2/25 | Loss: 0.00025540
Iteration 3/25 | Loss: 0.00025540
Iteration 4/25 | Loss: 0.00025540
Iteration 5/25 | Loss: 0.00025540
Iteration 6/25 | Loss: 0.00025540
Iteration 7/25 | Loss: 0.00025540
Iteration 8/25 | Loss: 0.00025540
Iteration 9/25 | Loss: 0.00025540
Iteration 10/25 | Loss: 0.00025540
Iteration 11/25 | Loss: 0.00025540
Iteration 12/25 | Loss: 0.00025540
Iteration 13/25 | Loss: 0.00025540
Iteration 14/25 | Loss: 0.00025540
Iteration 15/25 | Loss: 0.00025540
Iteration 16/25 | Loss: 0.00025540
Iteration 17/25 | Loss: 0.00025540
Iteration 18/25 | Loss: 0.00025540
Iteration 19/25 | Loss: 0.00025540
Iteration 20/25 | Loss: 0.00025540
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.00025539705529809, 0.00025539705529809, 0.00025539705529809, 0.00025539705529809, 0.00025539705529809]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00025539705529809

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00025540
Iteration 2/1000 | Loss: 0.00002089
Iteration 3/1000 | Loss: 0.00001590
Iteration 4/1000 | Loss: 0.00001422
Iteration 5/1000 | Loss: 0.00001286
Iteration 6/1000 | Loss: 0.00001246
Iteration 7/1000 | Loss: 0.00001207
Iteration 8/1000 | Loss: 0.00001185
Iteration 9/1000 | Loss: 0.00001168
Iteration 10/1000 | Loss: 0.00001165
Iteration 11/1000 | Loss: 0.00001157
Iteration 12/1000 | Loss: 0.00001150
Iteration 13/1000 | Loss: 0.00001149
Iteration 14/1000 | Loss: 0.00001146
Iteration 15/1000 | Loss: 0.00001145
Iteration 16/1000 | Loss: 0.00001143
Iteration 17/1000 | Loss: 0.00001142
Iteration 18/1000 | Loss: 0.00001141
Iteration 19/1000 | Loss: 0.00001141
Iteration 20/1000 | Loss: 0.00001141
Iteration 21/1000 | Loss: 0.00001140
Iteration 22/1000 | Loss: 0.00001140
Iteration 23/1000 | Loss: 0.00001139
Iteration 24/1000 | Loss: 0.00001138
Iteration 25/1000 | Loss: 0.00001138
Iteration 26/1000 | Loss: 0.00001138
Iteration 27/1000 | Loss: 0.00001137
Iteration 28/1000 | Loss: 0.00001137
Iteration 29/1000 | Loss: 0.00001137
Iteration 30/1000 | Loss: 0.00001136
Iteration 31/1000 | Loss: 0.00001136
Iteration 32/1000 | Loss: 0.00001136
Iteration 33/1000 | Loss: 0.00001135
Iteration 34/1000 | Loss: 0.00001135
Iteration 35/1000 | Loss: 0.00001135
Iteration 36/1000 | Loss: 0.00001135
Iteration 37/1000 | Loss: 0.00001134
Iteration 38/1000 | Loss: 0.00001134
Iteration 39/1000 | Loss: 0.00001133
Iteration 40/1000 | Loss: 0.00001133
Iteration 41/1000 | Loss: 0.00001133
Iteration 42/1000 | Loss: 0.00001133
Iteration 43/1000 | Loss: 0.00001133
Iteration 44/1000 | Loss: 0.00001133
Iteration 45/1000 | Loss: 0.00001132
Iteration 46/1000 | Loss: 0.00001132
Iteration 47/1000 | Loss: 0.00001132
Iteration 48/1000 | Loss: 0.00001132
Iteration 49/1000 | Loss: 0.00001132
Iteration 50/1000 | Loss: 0.00001132
Iteration 51/1000 | Loss: 0.00001132
Iteration 52/1000 | Loss: 0.00001132
Iteration 53/1000 | Loss: 0.00001131
Iteration 54/1000 | Loss: 0.00001131
Iteration 55/1000 | Loss: 0.00001131
Iteration 56/1000 | Loss: 0.00001131
Iteration 57/1000 | Loss: 0.00001131
Iteration 58/1000 | Loss: 0.00001131
Iteration 59/1000 | Loss: 0.00001131
Iteration 60/1000 | Loss: 0.00001131
Iteration 61/1000 | Loss: 0.00001131
Iteration 62/1000 | Loss: 0.00001131
Iteration 63/1000 | Loss: 0.00001130
Iteration 64/1000 | Loss: 0.00001130
Iteration 65/1000 | Loss: 0.00001130
Iteration 66/1000 | Loss: 0.00001129
Iteration 67/1000 | Loss: 0.00001129
Iteration 68/1000 | Loss: 0.00001129
Iteration 69/1000 | Loss: 0.00001129
Iteration 70/1000 | Loss: 0.00001129
Iteration 71/1000 | Loss: 0.00001129
Iteration 72/1000 | Loss: 0.00001129
Iteration 73/1000 | Loss: 0.00001129
Iteration 74/1000 | Loss: 0.00001129
Iteration 75/1000 | Loss: 0.00001129
Iteration 76/1000 | Loss: 0.00001129
Iteration 77/1000 | Loss: 0.00001129
Iteration 78/1000 | Loss: 0.00001129
Iteration 79/1000 | Loss: 0.00001129
Iteration 80/1000 | Loss: 0.00001128
Iteration 81/1000 | Loss: 0.00001128
Iteration 82/1000 | Loss: 0.00001128
Iteration 83/1000 | Loss: 0.00001128
Iteration 84/1000 | Loss: 0.00001128
Iteration 85/1000 | Loss: 0.00001128
Iteration 86/1000 | Loss: 0.00001128
Iteration 87/1000 | Loss: 0.00001128
Iteration 88/1000 | Loss: 0.00001128
Iteration 89/1000 | Loss: 0.00001128
Iteration 90/1000 | Loss: 0.00001128
Iteration 91/1000 | Loss: 0.00001128
Iteration 92/1000 | Loss: 0.00001128
Iteration 93/1000 | Loss: 0.00001128
Iteration 94/1000 | Loss: 0.00001128
Iteration 95/1000 | Loss: 0.00001127
Iteration 96/1000 | Loss: 0.00001127
Iteration 97/1000 | Loss: 0.00001127
Iteration 98/1000 | Loss: 0.00001127
Iteration 99/1000 | Loss: 0.00001127
Iteration 100/1000 | Loss: 0.00001127
Iteration 101/1000 | Loss: 0.00001127
Iteration 102/1000 | Loss: 0.00001127
Iteration 103/1000 | Loss: 0.00001127
Iteration 104/1000 | Loss: 0.00001127
Iteration 105/1000 | Loss: 0.00001127
Iteration 106/1000 | Loss: 0.00001127
Iteration 107/1000 | Loss: 0.00001127
Iteration 108/1000 | Loss: 0.00001127
Iteration 109/1000 | Loss: 0.00001127
Iteration 110/1000 | Loss: 0.00001127
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 110. Stopping optimization.
Last 5 losses: [1.1270964023424312e-05, 1.1270964023424312e-05, 1.1270964023424312e-05, 1.1270964023424312e-05, 1.1270964023424312e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1270964023424312e-05

Optimization complete. Final v2v error: 2.8584110736846924 mm

Highest mean error: 3.014448642730713 mm for frame 68

Lowest mean error: 2.7384705543518066 mm for frame 172

Saving results

Total time: 34.01808786392212
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00410479
Iteration 2/25 | Loss: 0.00083814
Iteration 3/25 | Loss: 0.00075442
Iteration 4/25 | Loss: 0.00073967
Iteration 5/25 | Loss: 0.00073754
Iteration 6/25 | Loss: 0.00073736
Iteration 7/25 | Loss: 0.00073736
Iteration 8/25 | Loss: 0.00073736
Iteration 9/25 | Loss: 0.00073736
Iteration 10/25 | Loss: 0.00073736
Iteration 11/25 | Loss: 0.00073736
Iteration 12/25 | Loss: 0.00073736
Iteration 13/25 | Loss: 0.00073736
Iteration 14/25 | Loss: 0.00073736
Iteration 15/25 | Loss: 0.00073736
Iteration 16/25 | Loss: 0.00073736
Iteration 17/25 | Loss: 0.00073736
Iteration 18/25 | Loss: 0.00073736
Iteration 19/25 | Loss: 0.00073736
Iteration 20/25 | Loss: 0.00073736
Iteration 21/25 | Loss: 0.00073736
Iteration 22/25 | Loss: 0.00073736
Iteration 23/25 | Loss: 0.00073736
Iteration 24/25 | Loss: 0.00073736
Iteration 25/25 | Loss: 0.00073736

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.26104164
Iteration 2/25 | Loss: 0.00031722
Iteration 3/25 | Loss: 0.00031721
Iteration 4/25 | Loss: 0.00031721
Iteration 5/25 | Loss: 0.00031721
Iteration 6/25 | Loss: 0.00031721
Iteration 7/25 | Loss: 0.00031721
Iteration 8/25 | Loss: 0.00031721
Iteration 9/25 | Loss: 0.00031721
Iteration 10/25 | Loss: 0.00031721
Iteration 11/25 | Loss: 0.00031721
Iteration 12/25 | Loss: 0.00031721
Iteration 13/25 | Loss: 0.00031721
Iteration 14/25 | Loss: 0.00031721
Iteration 15/25 | Loss: 0.00031721
Iteration 16/25 | Loss: 0.00031721
Iteration 17/25 | Loss: 0.00031721
Iteration 18/25 | Loss: 0.00031721
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003172075084876269, 0.0003172075084876269, 0.0003172075084876269, 0.0003172075084876269, 0.0003172075084876269]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003172075084876269

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031721
Iteration 2/1000 | Loss: 0.00002765
Iteration 3/1000 | Loss: 0.00002250
Iteration 4/1000 | Loss: 0.00002118
Iteration 5/1000 | Loss: 0.00001971
Iteration 6/1000 | Loss: 0.00001896
Iteration 7/1000 | Loss: 0.00001854
Iteration 8/1000 | Loss: 0.00001824
Iteration 9/1000 | Loss: 0.00001801
Iteration 10/1000 | Loss: 0.00001795
Iteration 11/1000 | Loss: 0.00001792
Iteration 12/1000 | Loss: 0.00001790
Iteration 13/1000 | Loss: 0.00001786
Iteration 14/1000 | Loss: 0.00001776
Iteration 15/1000 | Loss: 0.00001775
Iteration 16/1000 | Loss: 0.00001756
Iteration 17/1000 | Loss: 0.00001755
Iteration 18/1000 | Loss: 0.00001753
Iteration 19/1000 | Loss: 0.00001753
Iteration 20/1000 | Loss: 0.00001752
Iteration 21/1000 | Loss: 0.00001752
Iteration 22/1000 | Loss: 0.00001751
Iteration 23/1000 | Loss: 0.00001751
Iteration 24/1000 | Loss: 0.00001750
Iteration 25/1000 | Loss: 0.00001749
Iteration 26/1000 | Loss: 0.00001749
Iteration 27/1000 | Loss: 0.00001748
Iteration 28/1000 | Loss: 0.00001748
Iteration 29/1000 | Loss: 0.00001741
Iteration 30/1000 | Loss: 0.00001741
Iteration 31/1000 | Loss: 0.00001731
Iteration 32/1000 | Loss: 0.00001730
Iteration 33/1000 | Loss: 0.00001722
Iteration 34/1000 | Loss: 0.00001722
Iteration 35/1000 | Loss: 0.00001721
Iteration 36/1000 | Loss: 0.00001719
Iteration 37/1000 | Loss: 0.00001718
Iteration 38/1000 | Loss: 0.00001718
Iteration 39/1000 | Loss: 0.00001717
Iteration 40/1000 | Loss: 0.00001716
Iteration 41/1000 | Loss: 0.00001716
Iteration 42/1000 | Loss: 0.00001716
Iteration 43/1000 | Loss: 0.00001715
Iteration 44/1000 | Loss: 0.00001715
Iteration 45/1000 | Loss: 0.00001715
Iteration 46/1000 | Loss: 0.00001715
Iteration 47/1000 | Loss: 0.00001715
Iteration 48/1000 | Loss: 0.00001715
Iteration 49/1000 | Loss: 0.00001714
Iteration 50/1000 | Loss: 0.00001714
Iteration 51/1000 | Loss: 0.00001714
Iteration 52/1000 | Loss: 0.00001714
Iteration 53/1000 | Loss: 0.00001714
Iteration 54/1000 | Loss: 0.00001714
Iteration 55/1000 | Loss: 0.00001714
Iteration 56/1000 | Loss: 0.00001714
Iteration 57/1000 | Loss: 0.00001713
Iteration 58/1000 | Loss: 0.00001713
Iteration 59/1000 | Loss: 0.00001713
Iteration 60/1000 | Loss: 0.00001713
Iteration 61/1000 | Loss: 0.00001713
Iteration 62/1000 | Loss: 0.00001712
Iteration 63/1000 | Loss: 0.00001712
Iteration 64/1000 | Loss: 0.00001712
Iteration 65/1000 | Loss: 0.00001712
Iteration 66/1000 | Loss: 0.00001712
Iteration 67/1000 | Loss: 0.00001712
Iteration 68/1000 | Loss: 0.00001712
Iteration 69/1000 | Loss: 0.00001712
Iteration 70/1000 | Loss: 0.00001712
Iteration 71/1000 | Loss: 0.00001711
Iteration 72/1000 | Loss: 0.00001711
Iteration 73/1000 | Loss: 0.00001711
Iteration 74/1000 | Loss: 0.00001710
Iteration 75/1000 | Loss: 0.00001710
Iteration 76/1000 | Loss: 0.00001710
Iteration 77/1000 | Loss: 0.00001710
Iteration 78/1000 | Loss: 0.00001710
Iteration 79/1000 | Loss: 0.00001709
Iteration 80/1000 | Loss: 0.00001709
Iteration 81/1000 | Loss: 0.00001709
Iteration 82/1000 | Loss: 0.00001709
Iteration 83/1000 | Loss: 0.00001709
Iteration 84/1000 | Loss: 0.00001709
Iteration 85/1000 | Loss: 0.00001708
Iteration 86/1000 | Loss: 0.00001708
Iteration 87/1000 | Loss: 0.00001708
Iteration 88/1000 | Loss: 0.00001708
Iteration 89/1000 | Loss: 0.00001708
Iteration 90/1000 | Loss: 0.00001708
Iteration 91/1000 | Loss: 0.00001708
Iteration 92/1000 | Loss: 0.00001708
Iteration 93/1000 | Loss: 0.00001708
Iteration 94/1000 | Loss: 0.00001708
Iteration 95/1000 | Loss: 0.00001707
Iteration 96/1000 | Loss: 0.00001707
Iteration 97/1000 | Loss: 0.00001707
Iteration 98/1000 | Loss: 0.00001707
Iteration 99/1000 | Loss: 0.00001707
Iteration 100/1000 | Loss: 0.00001707
Iteration 101/1000 | Loss: 0.00001707
Iteration 102/1000 | Loss: 0.00001707
Iteration 103/1000 | Loss: 0.00001707
Iteration 104/1000 | Loss: 0.00001706
Iteration 105/1000 | Loss: 0.00001706
Iteration 106/1000 | Loss: 0.00001706
Iteration 107/1000 | Loss: 0.00001706
Iteration 108/1000 | Loss: 0.00001706
Iteration 109/1000 | Loss: 0.00001706
Iteration 110/1000 | Loss: 0.00001705
Iteration 111/1000 | Loss: 0.00001705
Iteration 112/1000 | Loss: 0.00001705
Iteration 113/1000 | Loss: 0.00001705
Iteration 114/1000 | Loss: 0.00001705
Iteration 115/1000 | Loss: 0.00001705
Iteration 116/1000 | Loss: 0.00001705
Iteration 117/1000 | Loss: 0.00001704
Iteration 118/1000 | Loss: 0.00001704
Iteration 119/1000 | Loss: 0.00001703
Iteration 120/1000 | Loss: 0.00001703
Iteration 121/1000 | Loss: 0.00001703
Iteration 122/1000 | Loss: 0.00001703
Iteration 123/1000 | Loss: 0.00001703
Iteration 124/1000 | Loss: 0.00001703
Iteration 125/1000 | Loss: 0.00001703
Iteration 126/1000 | Loss: 0.00001703
Iteration 127/1000 | Loss: 0.00001703
Iteration 128/1000 | Loss: 0.00001703
Iteration 129/1000 | Loss: 0.00001703
Iteration 130/1000 | Loss: 0.00001703
Iteration 131/1000 | Loss: 0.00001703
Iteration 132/1000 | Loss: 0.00001703
Iteration 133/1000 | Loss: 0.00001702
Iteration 134/1000 | Loss: 0.00001702
Iteration 135/1000 | Loss: 0.00001702
Iteration 136/1000 | Loss: 0.00001702
Iteration 137/1000 | Loss: 0.00001702
Iteration 138/1000 | Loss: 0.00001702
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [1.7024802218656987e-05, 1.7024802218656987e-05, 1.7024802218656987e-05, 1.7024802218656987e-05, 1.7024802218656987e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7024802218656987e-05

Optimization complete. Final v2v error: 3.5018064975738525 mm

Highest mean error: 3.751011610031128 mm for frame 169

Lowest mean error: 3.308539628982544 mm for frame 7

Saving results

Total time: 40.38191819190979
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1033/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1033.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1033
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00864158
Iteration 2/25 | Loss: 0.00116808
Iteration 3/25 | Loss: 0.00090143
Iteration 4/25 | Loss: 0.00085304
Iteration 5/25 | Loss: 0.00085612
Iteration 6/25 | Loss: 0.00083107
Iteration 7/25 | Loss: 0.00081970
Iteration 8/25 | Loss: 0.00081537
Iteration 9/25 | Loss: 0.00082270
Iteration 10/25 | Loss: 0.00082181
Iteration 11/25 | Loss: 0.00081794
Iteration 12/25 | Loss: 0.00081496
Iteration 13/25 | Loss: 0.00081340
Iteration 14/25 | Loss: 0.00081101
Iteration 15/25 | Loss: 0.00081043
Iteration 16/25 | Loss: 0.00081041
Iteration 17/25 | Loss: 0.00081041
Iteration 18/25 | Loss: 0.00081041
Iteration 19/25 | Loss: 0.00081041
Iteration 20/25 | Loss: 0.00081041
Iteration 21/25 | Loss: 0.00081041
Iteration 22/25 | Loss: 0.00081041
Iteration 23/25 | Loss: 0.00081040
Iteration 24/25 | Loss: 0.00081040
Iteration 25/25 | Loss: 0.00081040

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32320547
Iteration 2/25 | Loss: 0.00034012
Iteration 3/25 | Loss: 0.00034008
Iteration 4/25 | Loss: 0.00034008
Iteration 5/25 | Loss: 0.00034008
Iteration 6/25 | Loss: 0.00034008
Iteration 7/25 | Loss: 0.00034008
Iteration 8/25 | Loss: 0.00034008
Iteration 9/25 | Loss: 0.00034008
Iteration 10/25 | Loss: 0.00034008
Iteration 11/25 | Loss: 0.00034008
Iteration 12/25 | Loss: 0.00034008
Iteration 13/25 | Loss: 0.00034008
Iteration 14/25 | Loss: 0.00034008
Iteration 15/25 | Loss: 0.00034008
Iteration 16/25 | Loss: 0.00034008
Iteration 17/25 | Loss: 0.00034008
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00034007534850388765, 0.00034007534850388765, 0.00034007534850388765, 0.00034007534850388765, 0.00034007534850388765]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00034007534850388765

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034008
Iteration 2/1000 | Loss: 0.00003412
Iteration 3/1000 | Loss: 0.00002745
Iteration 4/1000 | Loss: 0.00002401
Iteration 5/1000 | Loss: 0.00002279
Iteration 6/1000 | Loss: 0.00002184
Iteration 7/1000 | Loss: 0.00002130
Iteration 8/1000 | Loss: 0.00002084
Iteration 9/1000 | Loss: 0.00002056
Iteration 10/1000 | Loss: 0.00002034
Iteration 11/1000 | Loss: 0.00002027
Iteration 12/1000 | Loss: 0.00002024
Iteration 13/1000 | Loss: 0.00002017
Iteration 14/1000 | Loss: 0.00002015
Iteration 15/1000 | Loss: 0.00002012
Iteration 16/1000 | Loss: 0.00002012
Iteration 17/1000 | Loss: 0.00002010
Iteration 18/1000 | Loss: 0.00002009
Iteration 19/1000 | Loss: 0.00002008
Iteration 20/1000 | Loss: 0.00002007
Iteration 21/1000 | Loss: 0.00002002
Iteration 22/1000 | Loss: 0.00001998
Iteration 23/1000 | Loss: 0.00001997
Iteration 24/1000 | Loss: 0.00001997
Iteration 25/1000 | Loss: 0.00001996
Iteration 26/1000 | Loss: 0.00001994
Iteration 27/1000 | Loss: 0.00001994
Iteration 28/1000 | Loss: 0.00001993
Iteration 29/1000 | Loss: 0.00001992
Iteration 30/1000 | Loss: 0.00001992
Iteration 31/1000 | Loss: 0.00001991
Iteration 32/1000 | Loss: 0.00001991
Iteration 33/1000 | Loss: 0.00001991
Iteration 34/1000 | Loss: 0.00001989
Iteration 35/1000 | Loss: 0.00001987
Iteration 36/1000 | Loss: 0.00001985
Iteration 37/1000 | Loss: 0.00001985
Iteration 38/1000 | Loss: 0.00001985
Iteration 39/1000 | Loss: 0.00001985
Iteration 40/1000 | Loss: 0.00001984
Iteration 41/1000 | Loss: 0.00001984
Iteration 42/1000 | Loss: 0.00001983
Iteration 43/1000 | Loss: 0.00001981
Iteration 44/1000 | Loss: 0.00001980
Iteration 45/1000 | Loss: 0.00001980
Iteration 46/1000 | Loss: 0.00001980
Iteration 47/1000 | Loss: 0.00001978
Iteration 48/1000 | Loss: 0.00001978
Iteration 49/1000 | Loss: 0.00001978
Iteration 50/1000 | Loss: 0.00001978
Iteration 51/1000 | Loss: 0.00001978
Iteration 52/1000 | Loss: 0.00001978
Iteration 53/1000 | Loss: 0.00001978
Iteration 54/1000 | Loss: 0.00001977
Iteration 55/1000 | Loss: 0.00001977
Iteration 56/1000 | Loss: 0.00001977
Iteration 57/1000 | Loss: 0.00001976
Iteration 58/1000 | Loss: 0.00001976
Iteration 59/1000 | Loss: 0.00001976
Iteration 60/1000 | Loss: 0.00001976
Iteration 61/1000 | Loss: 0.00001975
Iteration 62/1000 | Loss: 0.00001975
Iteration 63/1000 | Loss: 0.00001975
Iteration 64/1000 | Loss: 0.00001974
Iteration 65/1000 | Loss: 0.00001974
Iteration 66/1000 | Loss: 0.00001974
Iteration 67/1000 | Loss: 0.00001974
Iteration 68/1000 | Loss: 0.00001974
Iteration 69/1000 | Loss: 0.00001974
Iteration 70/1000 | Loss: 0.00001974
Iteration 71/1000 | Loss: 0.00001974
Iteration 72/1000 | Loss: 0.00001974
Iteration 73/1000 | Loss: 0.00001974
Iteration 74/1000 | Loss: 0.00001973
Iteration 75/1000 | Loss: 0.00001973
Iteration 76/1000 | Loss: 0.00001973
Iteration 77/1000 | Loss: 0.00001973
Iteration 78/1000 | Loss: 0.00001973
Iteration 79/1000 | Loss: 0.00001972
Iteration 80/1000 | Loss: 0.00001972
Iteration 81/1000 | Loss: 0.00001972
Iteration 82/1000 | Loss: 0.00001972
Iteration 83/1000 | Loss: 0.00001971
Iteration 84/1000 | Loss: 0.00001971
Iteration 85/1000 | Loss: 0.00001971
Iteration 86/1000 | Loss: 0.00001971
Iteration 87/1000 | Loss: 0.00001971
Iteration 88/1000 | Loss: 0.00001971
Iteration 89/1000 | Loss: 0.00001971
Iteration 90/1000 | Loss: 0.00001971
Iteration 91/1000 | Loss: 0.00001971
Iteration 92/1000 | Loss: 0.00001971
Iteration 93/1000 | Loss: 0.00001971
Iteration 94/1000 | Loss: 0.00001971
Iteration 95/1000 | Loss: 0.00001971
Iteration 96/1000 | Loss: 0.00001971
Iteration 97/1000 | Loss: 0.00001971
Iteration 98/1000 | Loss: 0.00001971
Iteration 99/1000 | Loss: 0.00001971
Iteration 100/1000 | Loss: 0.00001971
Iteration 101/1000 | Loss: 0.00001971
Iteration 102/1000 | Loss: 0.00001971
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.971036908798851e-05, 1.971036908798851e-05, 1.971036908798851e-05, 1.971036908798851e-05, 1.971036908798851e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.971036908798851e-05

Optimization complete. Final v2v error: 3.70772647857666 mm

Highest mean error: 4.097249984741211 mm for frame 72

Lowest mean error: 3.4210383892059326 mm for frame 109

Saving results

Total time: 50.586806535720825
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00464841
Iteration 2/25 | Loss: 0.00091268
Iteration 3/25 | Loss: 0.00079985
Iteration 4/25 | Loss: 0.00077866
Iteration 5/25 | Loss: 0.00077335
Iteration 6/25 | Loss: 0.00077126
Iteration 7/25 | Loss: 0.00077098
Iteration 8/25 | Loss: 0.00077098
Iteration 9/25 | Loss: 0.00077098
Iteration 10/25 | Loss: 0.00077098
Iteration 11/25 | Loss: 0.00077098
Iteration 12/25 | Loss: 0.00077098
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007709829369559884, 0.0007709829369559884, 0.0007709829369559884, 0.0007709829369559884, 0.0007709829369559884]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007709829369559884

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48900700
Iteration 2/25 | Loss: 0.00038201
Iteration 3/25 | Loss: 0.00038201
Iteration 4/25 | Loss: 0.00038201
Iteration 5/25 | Loss: 0.00038201
Iteration 6/25 | Loss: 0.00038201
Iteration 7/25 | Loss: 0.00038201
Iteration 8/25 | Loss: 0.00038201
Iteration 9/25 | Loss: 0.00038201
Iteration 10/25 | Loss: 0.00038201
Iteration 11/25 | Loss: 0.00038201
Iteration 12/25 | Loss: 0.00038201
Iteration 13/25 | Loss: 0.00038201
Iteration 14/25 | Loss: 0.00038201
Iteration 15/25 | Loss: 0.00038201
Iteration 16/25 | Loss: 0.00038201
Iteration 17/25 | Loss: 0.00038201
Iteration 18/25 | Loss: 0.00038201
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003820096899289638, 0.0003820096899289638, 0.0003820096899289638, 0.0003820096899289638, 0.0003820096899289638]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003820096899289638

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00038201
Iteration 2/1000 | Loss: 0.00003182
Iteration 3/1000 | Loss: 0.00002428
Iteration 4/1000 | Loss: 0.00002287
Iteration 5/1000 | Loss: 0.00002192
Iteration 6/1000 | Loss: 0.00002130
Iteration 7/1000 | Loss: 0.00002072
Iteration 8/1000 | Loss: 0.00002035
Iteration 9/1000 | Loss: 0.00002016
Iteration 10/1000 | Loss: 0.00002006
Iteration 11/1000 | Loss: 0.00001995
Iteration 12/1000 | Loss: 0.00001987
Iteration 13/1000 | Loss: 0.00001985
Iteration 14/1000 | Loss: 0.00001984
Iteration 15/1000 | Loss: 0.00001976
Iteration 16/1000 | Loss: 0.00001966
Iteration 17/1000 | Loss: 0.00001962
Iteration 18/1000 | Loss: 0.00001962
Iteration 19/1000 | Loss: 0.00001959
Iteration 20/1000 | Loss: 0.00001957
Iteration 21/1000 | Loss: 0.00001956
Iteration 22/1000 | Loss: 0.00001955
Iteration 23/1000 | Loss: 0.00001955
Iteration 24/1000 | Loss: 0.00001952
Iteration 25/1000 | Loss: 0.00001949
Iteration 26/1000 | Loss: 0.00001946
Iteration 27/1000 | Loss: 0.00001945
Iteration 28/1000 | Loss: 0.00001944
Iteration 29/1000 | Loss: 0.00001944
Iteration 30/1000 | Loss: 0.00001943
Iteration 31/1000 | Loss: 0.00001942
Iteration 32/1000 | Loss: 0.00001941
Iteration 33/1000 | Loss: 0.00001940
Iteration 34/1000 | Loss: 0.00001939
Iteration 35/1000 | Loss: 0.00001938
Iteration 36/1000 | Loss: 0.00001938
Iteration 37/1000 | Loss: 0.00001936
Iteration 38/1000 | Loss: 0.00001935
Iteration 39/1000 | Loss: 0.00001935
Iteration 40/1000 | Loss: 0.00001935
Iteration 41/1000 | Loss: 0.00001934
Iteration 42/1000 | Loss: 0.00001934
Iteration 43/1000 | Loss: 0.00001933
Iteration 44/1000 | Loss: 0.00001933
Iteration 45/1000 | Loss: 0.00001932
Iteration 46/1000 | Loss: 0.00001932
Iteration 47/1000 | Loss: 0.00001932
Iteration 48/1000 | Loss: 0.00001932
Iteration 49/1000 | Loss: 0.00001932
Iteration 50/1000 | Loss: 0.00001932
Iteration 51/1000 | Loss: 0.00001932
Iteration 52/1000 | Loss: 0.00001931
Iteration 53/1000 | Loss: 0.00001931
Iteration 54/1000 | Loss: 0.00001931
Iteration 55/1000 | Loss: 0.00001931
Iteration 56/1000 | Loss: 0.00001930
Iteration 57/1000 | Loss: 0.00001930
Iteration 58/1000 | Loss: 0.00001930
Iteration 59/1000 | Loss: 0.00001930
Iteration 60/1000 | Loss: 0.00001930
Iteration 61/1000 | Loss: 0.00001930
Iteration 62/1000 | Loss: 0.00001930
Iteration 63/1000 | Loss: 0.00001930
Iteration 64/1000 | Loss: 0.00001929
Iteration 65/1000 | Loss: 0.00001929
Iteration 66/1000 | Loss: 0.00001929
Iteration 67/1000 | Loss: 0.00001929
Iteration 68/1000 | Loss: 0.00001929
Iteration 69/1000 | Loss: 0.00001928
Iteration 70/1000 | Loss: 0.00001928
Iteration 71/1000 | Loss: 0.00001928
Iteration 72/1000 | Loss: 0.00001928
Iteration 73/1000 | Loss: 0.00001928
Iteration 74/1000 | Loss: 0.00001928
Iteration 75/1000 | Loss: 0.00001928
Iteration 76/1000 | Loss: 0.00001928
Iteration 77/1000 | Loss: 0.00001928
Iteration 78/1000 | Loss: 0.00001928
Iteration 79/1000 | Loss: 0.00001927
Iteration 80/1000 | Loss: 0.00001927
Iteration 81/1000 | Loss: 0.00001927
Iteration 82/1000 | Loss: 0.00001927
Iteration 83/1000 | Loss: 0.00001927
Iteration 84/1000 | Loss: 0.00001927
Iteration 85/1000 | Loss: 0.00001927
Iteration 86/1000 | Loss: 0.00001927
Iteration 87/1000 | Loss: 0.00001927
Iteration 88/1000 | Loss: 0.00001926
Iteration 89/1000 | Loss: 0.00001926
Iteration 90/1000 | Loss: 0.00001926
Iteration 91/1000 | Loss: 0.00001926
Iteration 92/1000 | Loss: 0.00001926
Iteration 93/1000 | Loss: 0.00001926
Iteration 94/1000 | Loss: 0.00001926
Iteration 95/1000 | Loss: 0.00001926
Iteration 96/1000 | Loss: 0.00001926
Iteration 97/1000 | Loss: 0.00001926
Iteration 98/1000 | Loss: 0.00001926
Iteration 99/1000 | Loss: 0.00001925
Iteration 100/1000 | Loss: 0.00001925
Iteration 101/1000 | Loss: 0.00001925
Iteration 102/1000 | Loss: 0.00001925
Iteration 103/1000 | Loss: 0.00001925
Iteration 104/1000 | Loss: 0.00001925
Iteration 105/1000 | Loss: 0.00001925
Iteration 106/1000 | Loss: 0.00001925
Iteration 107/1000 | Loss: 0.00001925
Iteration 108/1000 | Loss: 0.00001925
Iteration 109/1000 | Loss: 0.00001925
Iteration 110/1000 | Loss: 0.00001925
Iteration 111/1000 | Loss: 0.00001925
Iteration 112/1000 | Loss: 0.00001925
Iteration 113/1000 | Loss: 0.00001925
Iteration 114/1000 | Loss: 0.00001925
Iteration 115/1000 | Loss: 0.00001925
Iteration 116/1000 | Loss: 0.00001925
Iteration 117/1000 | Loss: 0.00001924
Iteration 118/1000 | Loss: 0.00001924
Iteration 119/1000 | Loss: 0.00001924
Iteration 120/1000 | Loss: 0.00001924
Iteration 121/1000 | Loss: 0.00001924
Iteration 122/1000 | Loss: 0.00001924
Iteration 123/1000 | Loss: 0.00001924
Iteration 124/1000 | Loss: 0.00001924
Iteration 125/1000 | Loss: 0.00001924
Iteration 126/1000 | Loss: 0.00001923
Iteration 127/1000 | Loss: 0.00001923
Iteration 128/1000 | Loss: 0.00001923
Iteration 129/1000 | Loss: 0.00001923
Iteration 130/1000 | Loss: 0.00001923
Iteration 131/1000 | Loss: 0.00001923
Iteration 132/1000 | Loss: 0.00001923
Iteration 133/1000 | Loss: 0.00001923
Iteration 134/1000 | Loss: 0.00001923
Iteration 135/1000 | Loss: 0.00001923
Iteration 136/1000 | Loss: 0.00001923
Iteration 137/1000 | Loss: 0.00001923
Iteration 138/1000 | Loss: 0.00001923
Iteration 139/1000 | Loss: 0.00001923
Iteration 140/1000 | Loss: 0.00001923
Iteration 141/1000 | Loss: 0.00001923
Iteration 142/1000 | Loss: 0.00001923
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [1.9229893950978294e-05, 1.9229893950978294e-05, 1.9229893950978294e-05, 1.9229893950978294e-05, 1.9229893950978294e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9229893950978294e-05

Optimization complete. Final v2v error: 3.6753597259521484 mm

Highest mean error: 4.067206859588623 mm for frame 30

Lowest mean error: 3.189305543899536 mm for frame 65

Saving results

Total time: 42.90040588378906
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1043/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1043.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1043
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00889947
Iteration 2/25 | Loss: 0.00090556
Iteration 3/25 | Loss: 0.00079295
Iteration 4/25 | Loss: 0.00076064
Iteration 5/25 | Loss: 0.00075228
Iteration 6/25 | Loss: 0.00075065
Iteration 7/25 | Loss: 0.00075054
Iteration 8/25 | Loss: 0.00075054
Iteration 9/25 | Loss: 0.00075054
Iteration 10/25 | Loss: 0.00075054
Iteration 11/25 | Loss: 0.00075054
Iteration 12/25 | Loss: 0.00075054
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007505352259613574, 0.0007505352259613574, 0.0007505352259613574, 0.0007505352259613574, 0.0007505352259613574]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007505352259613574

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55221510
Iteration 2/25 | Loss: 0.00028918
Iteration 3/25 | Loss: 0.00028917
Iteration 4/25 | Loss: 0.00028917
Iteration 5/25 | Loss: 0.00028917
Iteration 6/25 | Loss: 0.00028917
Iteration 7/25 | Loss: 0.00028917
Iteration 8/25 | Loss: 0.00028917
Iteration 9/25 | Loss: 0.00028917
Iteration 10/25 | Loss: 0.00028917
Iteration 11/25 | Loss: 0.00028917
Iteration 12/25 | Loss: 0.00028917
Iteration 13/25 | Loss: 0.00028917
Iteration 14/25 | Loss: 0.00028917
Iteration 15/25 | Loss: 0.00028917
Iteration 16/25 | Loss: 0.00028917
Iteration 17/25 | Loss: 0.00028917
Iteration 18/25 | Loss: 0.00028917
Iteration 19/25 | Loss: 0.00028917
Iteration 20/25 | Loss: 0.00028917
Iteration 21/25 | Loss: 0.00028917
Iteration 22/25 | Loss: 0.00028917
Iteration 23/25 | Loss: 0.00028917
Iteration 24/25 | Loss: 0.00028917
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0002891651529353112, 0.0002891651529353112, 0.0002891651529353112, 0.0002891651529353112, 0.0002891651529353112]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002891651529353112

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028917
Iteration 2/1000 | Loss: 0.00002874
Iteration 3/1000 | Loss: 0.00002306
Iteration 4/1000 | Loss: 0.00002187
Iteration 5/1000 | Loss: 0.00002061
Iteration 6/1000 | Loss: 0.00001988
Iteration 7/1000 | Loss: 0.00001930
Iteration 8/1000 | Loss: 0.00001896
Iteration 9/1000 | Loss: 0.00001869
Iteration 10/1000 | Loss: 0.00001850
Iteration 11/1000 | Loss: 0.00001844
Iteration 12/1000 | Loss: 0.00001842
Iteration 13/1000 | Loss: 0.00001832
Iteration 14/1000 | Loss: 0.00001829
Iteration 15/1000 | Loss: 0.00001829
Iteration 16/1000 | Loss: 0.00001828
Iteration 17/1000 | Loss: 0.00001827
Iteration 18/1000 | Loss: 0.00001826
Iteration 19/1000 | Loss: 0.00001824
Iteration 20/1000 | Loss: 0.00001824
Iteration 21/1000 | Loss: 0.00001823
Iteration 22/1000 | Loss: 0.00001823
Iteration 23/1000 | Loss: 0.00001822
Iteration 24/1000 | Loss: 0.00001821
Iteration 25/1000 | Loss: 0.00001821
Iteration 26/1000 | Loss: 0.00001821
Iteration 27/1000 | Loss: 0.00001820
Iteration 28/1000 | Loss: 0.00001820
Iteration 29/1000 | Loss: 0.00001820
Iteration 30/1000 | Loss: 0.00001820
Iteration 31/1000 | Loss: 0.00001819
Iteration 32/1000 | Loss: 0.00001819
Iteration 33/1000 | Loss: 0.00001819
Iteration 34/1000 | Loss: 0.00001819
Iteration 35/1000 | Loss: 0.00001819
Iteration 36/1000 | Loss: 0.00001819
Iteration 37/1000 | Loss: 0.00001818
Iteration 38/1000 | Loss: 0.00001818
Iteration 39/1000 | Loss: 0.00001818
Iteration 40/1000 | Loss: 0.00001818
Iteration 41/1000 | Loss: 0.00001818
Iteration 42/1000 | Loss: 0.00001817
Iteration 43/1000 | Loss: 0.00001817
Iteration 44/1000 | Loss: 0.00001817
Iteration 45/1000 | Loss: 0.00001817
Iteration 46/1000 | Loss: 0.00001816
Iteration 47/1000 | Loss: 0.00001816
Iteration 48/1000 | Loss: 0.00001816
Iteration 49/1000 | Loss: 0.00001816
Iteration 50/1000 | Loss: 0.00001815
Iteration 51/1000 | Loss: 0.00001815
Iteration 52/1000 | Loss: 0.00001815
Iteration 53/1000 | Loss: 0.00001815
Iteration 54/1000 | Loss: 0.00001814
Iteration 55/1000 | Loss: 0.00001814
Iteration 56/1000 | Loss: 0.00001814
Iteration 57/1000 | Loss: 0.00001814
Iteration 58/1000 | Loss: 0.00001814
Iteration 59/1000 | Loss: 0.00001814
Iteration 60/1000 | Loss: 0.00001814
Iteration 61/1000 | Loss: 0.00001814
Iteration 62/1000 | Loss: 0.00001814
Iteration 63/1000 | Loss: 0.00001814
Iteration 64/1000 | Loss: 0.00001814
Iteration 65/1000 | Loss: 0.00001813
Iteration 66/1000 | Loss: 0.00001813
Iteration 67/1000 | Loss: 0.00001812
Iteration 68/1000 | Loss: 0.00001812
Iteration 69/1000 | Loss: 0.00001812
Iteration 70/1000 | Loss: 0.00001812
Iteration 71/1000 | Loss: 0.00001812
Iteration 72/1000 | Loss: 0.00001812
Iteration 73/1000 | Loss: 0.00001811
Iteration 74/1000 | Loss: 0.00001811
Iteration 75/1000 | Loss: 0.00001811
Iteration 76/1000 | Loss: 0.00001811
Iteration 77/1000 | Loss: 0.00001811
Iteration 78/1000 | Loss: 0.00001810
Iteration 79/1000 | Loss: 0.00001810
Iteration 80/1000 | Loss: 0.00001809
Iteration 81/1000 | Loss: 0.00001809
Iteration 82/1000 | Loss: 0.00001809
Iteration 83/1000 | Loss: 0.00001808
Iteration 84/1000 | Loss: 0.00001808
Iteration 85/1000 | Loss: 0.00001808
Iteration 86/1000 | Loss: 0.00001808
Iteration 87/1000 | Loss: 0.00001808
Iteration 88/1000 | Loss: 0.00001808
Iteration 89/1000 | Loss: 0.00001807
Iteration 90/1000 | Loss: 0.00001807
Iteration 91/1000 | Loss: 0.00001807
Iteration 92/1000 | Loss: 0.00001807
Iteration 93/1000 | Loss: 0.00001807
Iteration 94/1000 | Loss: 0.00001806
Iteration 95/1000 | Loss: 0.00001806
Iteration 96/1000 | Loss: 0.00001806
Iteration 97/1000 | Loss: 0.00001805
Iteration 98/1000 | Loss: 0.00001805
Iteration 99/1000 | Loss: 0.00001805
Iteration 100/1000 | Loss: 0.00001805
Iteration 101/1000 | Loss: 0.00001805
Iteration 102/1000 | Loss: 0.00001805
Iteration 103/1000 | Loss: 0.00001805
Iteration 104/1000 | Loss: 0.00001805
Iteration 105/1000 | Loss: 0.00001805
Iteration 106/1000 | Loss: 0.00001804
Iteration 107/1000 | Loss: 0.00001804
Iteration 108/1000 | Loss: 0.00001804
Iteration 109/1000 | Loss: 0.00001804
Iteration 110/1000 | Loss: 0.00001804
Iteration 111/1000 | Loss: 0.00001802
Iteration 112/1000 | Loss: 0.00001801
Iteration 113/1000 | Loss: 0.00001801
Iteration 114/1000 | Loss: 0.00001801
Iteration 115/1000 | Loss: 0.00001801
Iteration 116/1000 | Loss: 0.00001801
Iteration 117/1000 | Loss: 0.00001801
Iteration 118/1000 | Loss: 0.00001800
Iteration 119/1000 | Loss: 0.00001800
Iteration 120/1000 | Loss: 0.00001800
Iteration 121/1000 | Loss: 0.00001800
Iteration 122/1000 | Loss: 0.00001800
Iteration 123/1000 | Loss: 0.00001800
Iteration 124/1000 | Loss: 0.00001799
Iteration 125/1000 | Loss: 0.00001799
Iteration 126/1000 | Loss: 0.00001799
Iteration 127/1000 | Loss: 0.00001799
Iteration 128/1000 | Loss: 0.00001799
Iteration 129/1000 | Loss: 0.00001799
Iteration 130/1000 | Loss: 0.00001799
Iteration 131/1000 | Loss: 0.00001798
Iteration 132/1000 | Loss: 0.00001798
Iteration 133/1000 | Loss: 0.00001798
Iteration 134/1000 | Loss: 0.00001798
Iteration 135/1000 | Loss: 0.00001798
Iteration 136/1000 | Loss: 0.00001798
Iteration 137/1000 | Loss: 0.00001798
Iteration 138/1000 | Loss: 0.00001798
Iteration 139/1000 | Loss: 0.00001798
Iteration 140/1000 | Loss: 0.00001798
Iteration 141/1000 | Loss: 0.00001797
Iteration 142/1000 | Loss: 0.00001797
Iteration 143/1000 | Loss: 0.00001797
Iteration 144/1000 | Loss: 0.00001797
Iteration 145/1000 | Loss: 0.00001797
Iteration 146/1000 | Loss: 0.00001797
Iteration 147/1000 | Loss: 0.00001797
Iteration 148/1000 | Loss: 0.00001797
Iteration 149/1000 | Loss: 0.00001797
Iteration 150/1000 | Loss: 0.00001797
Iteration 151/1000 | Loss: 0.00001797
Iteration 152/1000 | Loss: 0.00001797
Iteration 153/1000 | Loss: 0.00001797
Iteration 154/1000 | Loss: 0.00001796
Iteration 155/1000 | Loss: 0.00001796
Iteration 156/1000 | Loss: 0.00001796
Iteration 157/1000 | Loss: 0.00001796
Iteration 158/1000 | Loss: 0.00001796
Iteration 159/1000 | Loss: 0.00001796
Iteration 160/1000 | Loss: 0.00001796
Iteration 161/1000 | Loss: 0.00001796
Iteration 162/1000 | Loss: 0.00001796
Iteration 163/1000 | Loss: 0.00001796
Iteration 164/1000 | Loss: 0.00001795
Iteration 165/1000 | Loss: 0.00001795
Iteration 166/1000 | Loss: 0.00001795
Iteration 167/1000 | Loss: 0.00001795
Iteration 168/1000 | Loss: 0.00001795
Iteration 169/1000 | Loss: 0.00001795
Iteration 170/1000 | Loss: 0.00001795
Iteration 171/1000 | Loss: 0.00001795
Iteration 172/1000 | Loss: 0.00001795
Iteration 173/1000 | Loss: 0.00001795
Iteration 174/1000 | Loss: 0.00001795
Iteration 175/1000 | Loss: 0.00001795
Iteration 176/1000 | Loss: 0.00001795
Iteration 177/1000 | Loss: 0.00001795
Iteration 178/1000 | Loss: 0.00001795
Iteration 179/1000 | Loss: 0.00001795
Iteration 180/1000 | Loss: 0.00001795
Iteration 181/1000 | Loss: 0.00001795
Iteration 182/1000 | Loss: 0.00001795
Iteration 183/1000 | Loss: 0.00001795
Iteration 184/1000 | Loss: 0.00001795
Iteration 185/1000 | Loss: 0.00001795
Iteration 186/1000 | Loss: 0.00001795
Iteration 187/1000 | Loss: 0.00001795
Iteration 188/1000 | Loss: 0.00001795
Iteration 189/1000 | Loss: 0.00001795
Iteration 190/1000 | Loss: 0.00001795
Iteration 191/1000 | Loss: 0.00001795
Iteration 192/1000 | Loss: 0.00001795
Iteration 193/1000 | Loss: 0.00001795
Iteration 194/1000 | Loss: 0.00001795
Iteration 195/1000 | Loss: 0.00001795
Iteration 196/1000 | Loss: 0.00001795
Iteration 197/1000 | Loss: 0.00001795
Iteration 198/1000 | Loss: 0.00001795
Iteration 199/1000 | Loss: 0.00001795
Iteration 200/1000 | Loss: 0.00001795
Iteration 201/1000 | Loss: 0.00001795
Iteration 202/1000 | Loss: 0.00001795
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 202. Stopping optimization.
Last 5 losses: [1.794789386622142e-05, 1.794789386622142e-05, 1.794789386622142e-05, 1.794789386622142e-05, 1.794789386622142e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.794789386622142e-05

Optimization complete. Final v2v error: 3.5611252784729004 mm

Highest mean error: 4.586276531219482 mm for frame 92

Lowest mean error: 3.2322795391082764 mm for frame 67

Saving results

Total time: 41.47968864440918
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1026/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1026.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1026
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00783404
Iteration 2/25 | Loss: 0.00123206
Iteration 3/25 | Loss: 0.00083049
Iteration 4/25 | Loss: 0.00078479
Iteration 5/25 | Loss: 0.00078947
Iteration 6/25 | Loss: 0.00078389
Iteration 7/25 | Loss: 0.00076982
Iteration 8/25 | Loss: 0.00076233
Iteration 9/25 | Loss: 0.00076386
Iteration 10/25 | Loss: 0.00076195
Iteration 11/25 | Loss: 0.00075992
Iteration 12/25 | Loss: 0.00076197
Iteration 13/25 | Loss: 0.00076042
Iteration 14/25 | Loss: 0.00075962
Iteration 15/25 | Loss: 0.00075817
Iteration 16/25 | Loss: 0.00075614
Iteration 17/25 | Loss: 0.00075589
Iteration 18/25 | Loss: 0.00075585
Iteration 19/25 | Loss: 0.00075585
Iteration 20/25 | Loss: 0.00075585
Iteration 21/25 | Loss: 0.00075585
Iteration 22/25 | Loss: 0.00075585
Iteration 23/25 | Loss: 0.00075585
Iteration 24/25 | Loss: 0.00075584
Iteration 25/25 | Loss: 0.00075584

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 15.57328796
Iteration 2/25 | Loss: 0.00033236
Iteration 3/25 | Loss: 0.00033204
Iteration 4/25 | Loss: 0.00033204
Iteration 5/25 | Loss: 0.00033204
Iteration 6/25 | Loss: 0.00033204
Iteration 7/25 | Loss: 0.00033204
Iteration 8/25 | Loss: 0.00033204
Iteration 9/25 | Loss: 0.00033204
Iteration 10/25 | Loss: 0.00033204
Iteration 11/25 | Loss: 0.00033204
Iteration 12/25 | Loss: 0.00033204
Iteration 13/25 | Loss: 0.00033204
Iteration 14/25 | Loss: 0.00033204
Iteration 15/25 | Loss: 0.00033204
Iteration 16/25 | Loss: 0.00033204
Iteration 17/25 | Loss: 0.00033204
Iteration 18/25 | Loss: 0.00033204
Iteration 19/25 | Loss: 0.00033204
Iteration 20/25 | Loss: 0.00033204
Iteration 21/25 | Loss: 0.00033204
Iteration 22/25 | Loss: 0.00033204
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0003320415853522718, 0.0003320415853522718, 0.0003320415853522718, 0.0003320415853522718, 0.0003320415853522718]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003320415853522718

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033204
Iteration 2/1000 | Loss: 0.00002108
Iteration 3/1000 | Loss: 0.00001829
Iteration 4/1000 | Loss: 0.00001674
Iteration 5/1000 | Loss: 0.00001597
Iteration 6/1000 | Loss: 0.00001554
Iteration 7/1000 | Loss: 0.00001518
Iteration 8/1000 | Loss: 0.00001494
Iteration 9/1000 | Loss: 0.00001476
Iteration 10/1000 | Loss: 0.00001469
Iteration 11/1000 | Loss: 0.00001462
Iteration 12/1000 | Loss: 0.00001459
Iteration 13/1000 | Loss: 0.00001458
Iteration 14/1000 | Loss: 0.00001458
Iteration 15/1000 | Loss: 0.00001455
Iteration 16/1000 | Loss: 0.00001455
Iteration 17/1000 | Loss: 0.00001455
Iteration 18/1000 | Loss: 0.00001454
Iteration 19/1000 | Loss: 0.00001453
Iteration 20/1000 | Loss: 0.00001453
Iteration 21/1000 | Loss: 0.00001452
Iteration 22/1000 | Loss: 0.00001452
Iteration 23/1000 | Loss: 0.00001452
Iteration 24/1000 | Loss: 0.00001452
Iteration 25/1000 | Loss: 0.00001452
Iteration 26/1000 | Loss: 0.00001452
Iteration 27/1000 | Loss: 0.00001452
Iteration 28/1000 | Loss: 0.00001452
Iteration 29/1000 | Loss: 0.00001452
Iteration 30/1000 | Loss: 0.00001451
Iteration 31/1000 | Loss: 0.00001451
Iteration 32/1000 | Loss: 0.00001451
Iteration 33/1000 | Loss: 0.00001451
Iteration 34/1000 | Loss: 0.00001451
Iteration 35/1000 | Loss: 0.00001450
Iteration 36/1000 | Loss: 0.00001450
Iteration 37/1000 | Loss: 0.00001450
Iteration 38/1000 | Loss: 0.00001450
Iteration 39/1000 | Loss: 0.00001450
Iteration 40/1000 | Loss: 0.00001450
Iteration 41/1000 | Loss: 0.00001449
Iteration 42/1000 | Loss: 0.00001449
Iteration 43/1000 | Loss: 0.00001449
Iteration 44/1000 | Loss: 0.00001449
Iteration 45/1000 | Loss: 0.00001448
Iteration 46/1000 | Loss: 0.00001448
Iteration 47/1000 | Loss: 0.00001448
Iteration 48/1000 | Loss: 0.00001448
Iteration 49/1000 | Loss: 0.00001448
Iteration 50/1000 | Loss: 0.00001448
Iteration 51/1000 | Loss: 0.00001448
Iteration 52/1000 | Loss: 0.00001448
Iteration 53/1000 | Loss: 0.00001447
Iteration 54/1000 | Loss: 0.00001447
Iteration 55/1000 | Loss: 0.00001447
Iteration 56/1000 | Loss: 0.00001447
Iteration 57/1000 | Loss: 0.00001447
Iteration 58/1000 | Loss: 0.00001446
Iteration 59/1000 | Loss: 0.00001446
Iteration 60/1000 | Loss: 0.00001446
Iteration 61/1000 | Loss: 0.00001446
Iteration 62/1000 | Loss: 0.00001446
Iteration 63/1000 | Loss: 0.00001446
Iteration 64/1000 | Loss: 0.00001446
Iteration 65/1000 | Loss: 0.00001446
Iteration 66/1000 | Loss: 0.00001446
Iteration 67/1000 | Loss: 0.00001446
Iteration 68/1000 | Loss: 0.00001446
Iteration 69/1000 | Loss: 0.00001445
Iteration 70/1000 | Loss: 0.00001445
Iteration 71/1000 | Loss: 0.00001445
Iteration 72/1000 | Loss: 0.00001445
Iteration 73/1000 | Loss: 0.00001445
Iteration 74/1000 | Loss: 0.00001445
Iteration 75/1000 | Loss: 0.00001445
Iteration 76/1000 | Loss: 0.00001444
Iteration 77/1000 | Loss: 0.00001444
Iteration 78/1000 | Loss: 0.00001444
Iteration 79/1000 | Loss: 0.00001444
Iteration 80/1000 | Loss: 0.00001444
Iteration 81/1000 | Loss: 0.00001443
Iteration 82/1000 | Loss: 0.00001443
Iteration 83/1000 | Loss: 0.00001443
Iteration 84/1000 | Loss: 0.00001443
Iteration 85/1000 | Loss: 0.00001442
Iteration 86/1000 | Loss: 0.00001442
Iteration 87/1000 | Loss: 0.00001442
Iteration 88/1000 | Loss: 0.00001442
Iteration 89/1000 | Loss: 0.00001441
Iteration 90/1000 | Loss: 0.00001441
Iteration 91/1000 | Loss: 0.00001441
Iteration 92/1000 | Loss: 0.00001441
Iteration 93/1000 | Loss: 0.00001440
Iteration 94/1000 | Loss: 0.00001440
Iteration 95/1000 | Loss: 0.00001440
Iteration 96/1000 | Loss: 0.00001439
Iteration 97/1000 | Loss: 0.00001439
Iteration 98/1000 | Loss: 0.00001439
Iteration 99/1000 | Loss: 0.00001439
Iteration 100/1000 | Loss: 0.00001439
Iteration 101/1000 | Loss: 0.00001439
Iteration 102/1000 | Loss: 0.00001439
Iteration 103/1000 | Loss: 0.00001439
Iteration 104/1000 | Loss: 0.00001439
Iteration 105/1000 | Loss: 0.00001439
Iteration 106/1000 | Loss: 0.00001439
Iteration 107/1000 | Loss: 0.00001439
Iteration 108/1000 | Loss: 0.00001439
Iteration 109/1000 | Loss: 0.00001439
Iteration 110/1000 | Loss: 0.00001439
Iteration 111/1000 | Loss: 0.00001439
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 111. Stopping optimization.
Last 5 losses: [1.4385734175448306e-05, 1.4385734175448306e-05, 1.4385734175448306e-05, 1.4385734175448306e-05, 1.4385734175448306e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4385734175448306e-05

Optimization complete. Final v2v error: 3.26747727394104 mm

Highest mean error: 3.778920888900757 mm for frame 4

Lowest mean error: 2.979870557785034 mm for frame 113

Saving results

Total time: 59.959232330322266
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1063/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1063.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1063
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01072256
Iteration 2/25 | Loss: 0.00378015
Iteration 3/25 | Loss: 0.00187510
Iteration 4/25 | Loss: 0.00154307
Iteration 5/25 | Loss: 0.00138614
Iteration 6/25 | Loss: 0.00135637
Iteration 7/25 | Loss: 0.00118769
Iteration 8/25 | Loss: 0.00120207
Iteration 9/25 | Loss: 0.00098261
Iteration 10/25 | Loss: 0.00093746
Iteration 11/25 | Loss: 0.00089065
Iteration 12/25 | Loss: 0.00085209
Iteration 13/25 | Loss: 0.00084071
Iteration 14/25 | Loss: 0.00084040
Iteration 15/25 | Loss: 0.00084372
Iteration 16/25 | Loss: 0.00082895
Iteration 17/25 | Loss: 0.00081163
Iteration 18/25 | Loss: 0.00080022
Iteration 19/25 | Loss: 0.00079582
Iteration 20/25 | Loss: 0.00079352
Iteration 21/25 | Loss: 0.00079285
Iteration 22/25 | Loss: 0.00079263
Iteration 23/25 | Loss: 0.00079261
Iteration 24/25 | Loss: 0.00079261
Iteration 25/25 | Loss: 0.00079260

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79266155
Iteration 2/25 | Loss: 0.00061888
Iteration 3/25 | Loss: 0.00055092
Iteration 4/25 | Loss: 0.00055091
Iteration 5/25 | Loss: 0.00055091
Iteration 6/25 | Loss: 0.00055091
Iteration 7/25 | Loss: 0.00055091
Iteration 8/25 | Loss: 0.00055091
Iteration 9/25 | Loss: 0.00055091
Iteration 10/25 | Loss: 0.00055091
Iteration 11/25 | Loss: 0.00055091
Iteration 12/25 | Loss: 0.00055091
Iteration 13/25 | Loss: 0.00055091
Iteration 14/25 | Loss: 0.00055091
Iteration 15/25 | Loss: 0.00055091
Iteration 16/25 | Loss: 0.00055091
Iteration 17/25 | Loss: 0.00055091
Iteration 18/25 | Loss: 0.00055091
Iteration 19/25 | Loss: 0.00055091
Iteration 20/25 | Loss: 0.00055091
Iteration 21/25 | Loss: 0.00055091
Iteration 22/25 | Loss: 0.00055091
Iteration 23/25 | Loss: 0.00055091
Iteration 24/25 | Loss: 0.00055091
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0005509122274816036, 0.0005509122274816036, 0.0005509122274816036, 0.0005509122274816036, 0.0005509122274816036]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005509122274816036

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055091
Iteration 2/1000 | Loss: 0.00009512
Iteration 3/1000 | Loss: 0.00008007
Iteration 4/1000 | Loss: 0.00004655
Iteration 5/1000 | Loss: 0.00005822
Iteration 6/1000 | Loss: 0.00007398
Iteration 7/1000 | Loss: 0.00003918
Iteration 8/1000 | Loss: 0.00003656
Iteration 9/1000 | Loss: 0.00047145
Iteration 10/1000 | Loss: 0.00191096
Iteration 11/1000 | Loss: 0.00032758
Iteration 12/1000 | Loss: 0.00012929
Iteration 13/1000 | Loss: 0.00014788
Iteration 14/1000 | Loss: 0.00003974
Iteration 15/1000 | Loss: 0.00009625
Iteration 16/1000 | Loss: 0.00002268
Iteration 17/1000 | Loss: 0.00007331
Iteration 18/1000 | Loss: 0.00009837
Iteration 19/1000 | Loss: 0.00001779
Iteration 20/1000 | Loss: 0.00001671
Iteration 21/1000 | Loss: 0.00001593
Iteration 22/1000 | Loss: 0.00001547
Iteration 23/1000 | Loss: 0.00002076
Iteration 24/1000 | Loss: 0.00004502
Iteration 25/1000 | Loss: 0.00001512
Iteration 26/1000 | Loss: 0.00001579
Iteration 27/1000 | Loss: 0.00001463
Iteration 28/1000 | Loss: 0.00001463
Iteration 29/1000 | Loss: 0.00001463
Iteration 30/1000 | Loss: 0.00001462
Iteration 31/1000 | Loss: 0.00001461
Iteration 32/1000 | Loss: 0.00001458
Iteration 33/1000 | Loss: 0.00001893
Iteration 34/1000 | Loss: 0.00001451
Iteration 35/1000 | Loss: 0.00001451
Iteration 36/1000 | Loss: 0.00001451
Iteration 37/1000 | Loss: 0.00001451
Iteration 38/1000 | Loss: 0.00001451
Iteration 39/1000 | Loss: 0.00001451
Iteration 40/1000 | Loss: 0.00001451
Iteration 41/1000 | Loss: 0.00001451
Iteration 42/1000 | Loss: 0.00001451
Iteration 43/1000 | Loss: 0.00001450
Iteration 44/1000 | Loss: 0.00001450
Iteration 45/1000 | Loss: 0.00001615
Iteration 46/1000 | Loss: 0.00001446
Iteration 47/1000 | Loss: 0.00001446
Iteration 48/1000 | Loss: 0.00001445
Iteration 49/1000 | Loss: 0.00001444
Iteration 50/1000 | Loss: 0.00001444
Iteration 51/1000 | Loss: 0.00001443
Iteration 52/1000 | Loss: 0.00001443
Iteration 53/1000 | Loss: 0.00001443
Iteration 54/1000 | Loss: 0.00001443
Iteration 55/1000 | Loss: 0.00001443
Iteration 56/1000 | Loss: 0.00001442
Iteration 57/1000 | Loss: 0.00001442
Iteration 58/1000 | Loss: 0.00001442
Iteration 59/1000 | Loss: 0.00001442
Iteration 60/1000 | Loss: 0.00001442
Iteration 61/1000 | Loss: 0.00001441
Iteration 62/1000 | Loss: 0.00001441
Iteration 63/1000 | Loss: 0.00001441
Iteration 64/1000 | Loss: 0.00001441
Iteration 65/1000 | Loss: 0.00001441
Iteration 66/1000 | Loss: 0.00001441
Iteration 67/1000 | Loss: 0.00001440
Iteration 68/1000 | Loss: 0.00001440
Iteration 69/1000 | Loss: 0.00001440
Iteration 70/1000 | Loss: 0.00001439
Iteration 71/1000 | Loss: 0.00001439
Iteration 72/1000 | Loss: 0.00001439
Iteration 73/1000 | Loss: 0.00001439
Iteration 74/1000 | Loss: 0.00001439
Iteration 75/1000 | Loss: 0.00001438
Iteration 76/1000 | Loss: 0.00001438
Iteration 77/1000 | Loss: 0.00001438
Iteration 78/1000 | Loss: 0.00001438
Iteration 79/1000 | Loss: 0.00001438
Iteration 80/1000 | Loss: 0.00001438
Iteration 81/1000 | Loss: 0.00001438
Iteration 82/1000 | Loss: 0.00001438
Iteration 83/1000 | Loss: 0.00001437
Iteration 84/1000 | Loss: 0.00001437
Iteration 85/1000 | Loss: 0.00001436
Iteration 86/1000 | Loss: 0.00001436
Iteration 87/1000 | Loss: 0.00001436
Iteration 88/1000 | Loss: 0.00001436
Iteration 89/1000 | Loss: 0.00001436
Iteration 90/1000 | Loss: 0.00001435
Iteration 91/1000 | Loss: 0.00001435
Iteration 92/1000 | Loss: 0.00001435
Iteration 93/1000 | Loss: 0.00001435
Iteration 94/1000 | Loss: 0.00001435
Iteration 95/1000 | Loss: 0.00001435
Iteration 96/1000 | Loss: 0.00001435
Iteration 97/1000 | Loss: 0.00001434
Iteration 98/1000 | Loss: 0.00001434
Iteration 99/1000 | Loss: 0.00001434
Iteration 100/1000 | Loss: 0.00001434
Iteration 101/1000 | Loss: 0.00001434
Iteration 102/1000 | Loss: 0.00001434
Iteration 103/1000 | Loss: 0.00001434
Iteration 104/1000 | Loss: 0.00001434
Iteration 105/1000 | Loss: 0.00001434
Iteration 106/1000 | Loss: 0.00001434
Iteration 107/1000 | Loss: 0.00001434
Iteration 108/1000 | Loss: 0.00001434
Iteration 109/1000 | Loss: 0.00001433
Iteration 110/1000 | Loss: 0.00001433
Iteration 111/1000 | Loss: 0.00001433
Iteration 112/1000 | Loss: 0.00001433
Iteration 113/1000 | Loss: 0.00001433
Iteration 114/1000 | Loss: 0.00001433
Iteration 115/1000 | Loss: 0.00001433
Iteration 116/1000 | Loss: 0.00001433
Iteration 117/1000 | Loss: 0.00001433
Iteration 118/1000 | Loss: 0.00001433
Iteration 119/1000 | Loss: 0.00001433
Iteration 120/1000 | Loss: 0.00001433
Iteration 121/1000 | Loss: 0.00001433
Iteration 122/1000 | Loss: 0.00001433
Iteration 123/1000 | Loss: 0.00001433
Iteration 124/1000 | Loss: 0.00001433
Iteration 125/1000 | Loss: 0.00001433
Iteration 126/1000 | Loss: 0.00001432
Iteration 127/1000 | Loss: 0.00001432
Iteration 128/1000 | Loss: 0.00001432
Iteration 129/1000 | Loss: 0.00001432
Iteration 130/1000 | Loss: 0.00001432
Iteration 131/1000 | Loss: 0.00001431
Iteration 132/1000 | Loss: 0.00001431
Iteration 133/1000 | Loss: 0.00001431
Iteration 134/1000 | Loss: 0.00001431
Iteration 135/1000 | Loss: 0.00001431
Iteration 136/1000 | Loss: 0.00001431
Iteration 137/1000 | Loss: 0.00001431
Iteration 138/1000 | Loss: 0.00001431
Iteration 139/1000 | Loss: 0.00001431
Iteration 140/1000 | Loss: 0.00001431
Iteration 141/1000 | Loss: 0.00001431
Iteration 142/1000 | Loss: 0.00001431
Iteration 143/1000 | Loss: 0.00001431
Iteration 144/1000 | Loss: 0.00001431
Iteration 145/1000 | Loss: 0.00001431
Iteration 146/1000 | Loss: 0.00001430
Iteration 147/1000 | Loss: 0.00001430
Iteration 148/1000 | Loss: 0.00001430
Iteration 149/1000 | Loss: 0.00001430
Iteration 150/1000 | Loss: 0.00001430
Iteration 151/1000 | Loss: 0.00001430
Iteration 152/1000 | Loss: 0.00001430
Iteration 153/1000 | Loss: 0.00001430
Iteration 154/1000 | Loss: 0.00001430
Iteration 155/1000 | Loss: 0.00001430
Iteration 156/1000 | Loss: 0.00001430
Iteration 157/1000 | Loss: 0.00001430
Iteration 158/1000 | Loss: 0.00001430
Iteration 159/1000 | Loss: 0.00001430
Iteration 160/1000 | Loss: 0.00001430
Iteration 161/1000 | Loss: 0.00001429
Iteration 162/1000 | Loss: 0.00001429
Iteration 163/1000 | Loss: 0.00001429
Iteration 164/1000 | Loss: 0.00001429
Iteration 165/1000 | Loss: 0.00001429
Iteration 166/1000 | Loss: 0.00001429
Iteration 167/1000 | Loss: 0.00001429
Iteration 168/1000 | Loss: 0.00001429
Iteration 169/1000 | Loss: 0.00001429
Iteration 170/1000 | Loss: 0.00001429
Iteration 171/1000 | Loss: 0.00001429
Iteration 172/1000 | Loss: 0.00001429
Iteration 173/1000 | Loss: 0.00001429
Iteration 174/1000 | Loss: 0.00001429
Iteration 175/1000 | Loss: 0.00001429
Iteration 176/1000 | Loss: 0.00001429
Iteration 177/1000 | Loss: 0.00001429
Iteration 178/1000 | Loss: 0.00001428
Iteration 179/1000 | Loss: 0.00001428
Iteration 180/1000 | Loss: 0.00001428
Iteration 181/1000 | Loss: 0.00001428
Iteration 182/1000 | Loss: 0.00001428
Iteration 183/1000 | Loss: 0.00001428
Iteration 184/1000 | Loss: 0.00001428
Iteration 185/1000 | Loss: 0.00001428
Iteration 186/1000 | Loss: 0.00001428
Iteration 187/1000 | Loss: 0.00001428
Iteration 188/1000 | Loss: 0.00001428
Iteration 189/1000 | Loss: 0.00001428
Iteration 190/1000 | Loss: 0.00001428
Iteration 191/1000 | Loss: 0.00001428
Iteration 192/1000 | Loss: 0.00001428
Iteration 193/1000 | Loss: 0.00001428
Iteration 194/1000 | Loss: 0.00001428
Iteration 195/1000 | Loss: 0.00001428
Iteration 196/1000 | Loss: 0.00001428
Iteration 197/1000 | Loss: 0.00001428
Iteration 198/1000 | Loss: 0.00001428
Iteration 199/1000 | Loss: 0.00001428
Iteration 200/1000 | Loss: 0.00001428
Iteration 201/1000 | Loss: 0.00001428
Iteration 202/1000 | Loss: 0.00001428
Iteration 203/1000 | Loss: 0.00001428
Iteration 204/1000 | Loss: 0.00001428
Iteration 205/1000 | Loss: 0.00001428
Iteration 206/1000 | Loss: 0.00001428
Iteration 207/1000 | Loss: 0.00001427
Iteration 208/1000 | Loss: 0.00001427
Iteration 209/1000 | Loss: 0.00001427
Iteration 210/1000 | Loss: 0.00001427
Iteration 211/1000 | Loss: 0.00001427
Iteration 212/1000 | Loss: 0.00001427
Iteration 213/1000 | Loss: 0.00001427
Iteration 214/1000 | Loss: 0.00001427
Iteration 215/1000 | Loss: 0.00001427
Iteration 216/1000 | Loss: 0.00001427
Iteration 217/1000 | Loss: 0.00001427
Iteration 218/1000 | Loss: 0.00001427
Iteration 219/1000 | Loss: 0.00001427
Iteration 220/1000 | Loss: 0.00001427
Iteration 221/1000 | Loss: 0.00001427
Iteration 222/1000 | Loss: 0.00001427
Iteration 223/1000 | Loss: 0.00001427
Iteration 224/1000 | Loss: 0.00001427
Iteration 225/1000 | Loss: 0.00001427
Iteration 226/1000 | Loss: 0.00001427
Iteration 227/1000 | Loss: 0.00001427
Iteration 228/1000 | Loss: 0.00001427
Iteration 229/1000 | Loss: 0.00001427
Iteration 230/1000 | Loss: 0.00001427
Iteration 231/1000 | Loss: 0.00001427
Iteration 232/1000 | Loss: 0.00001427
Iteration 233/1000 | Loss: 0.00001427
Iteration 234/1000 | Loss: 0.00001427
Iteration 235/1000 | Loss: 0.00001427
Iteration 236/1000 | Loss: 0.00001427
Iteration 237/1000 | Loss: 0.00001427
Iteration 238/1000 | Loss: 0.00001427
Iteration 239/1000 | Loss: 0.00001427
Iteration 240/1000 | Loss: 0.00001427
Iteration 241/1000 | Loss: 0.00001427
Iteration 242/1000 | Loss: 0.00001427
Iteration 243/1000 | Loss: 0.00001427
Iteration 244/1000 | Loss: 0.00001427
Iteration 245/1000 | Loss: 0.00001427
Iteration 246/1000 | Loss: 0.00001427
Iteration 247/1000 | Loss: 0.00001427
Iteration 248/1000 | Loss: 0.00001427
Iteration 249/1000 | Loss: 0.00001427
Iteration 250/1000 | Loss: 0.00001427
Iteration 251/1000 | Loss: 0.00001427
Iteration 252/1000 | Loss: 0.00001427
Iteration 253/1000 | Loss: 0.00001427
Iteration 254/1000 | Loss: 0.00001427
Iteration 255/1000 | Loss: 0.00001427
Iteration 256/1000 | Loss: 0.00001427
Iteration 257/1000 | Loss: 0.00001427
Iteration 258/1000 | Loss: 0.00001427
Iteration 259/1000 | Loss: 0.00001427
Iteration 260/1000 | Loss: 0.00001427
Iteration 261/1000 | Loss: 0.00001427
Iteration 262/1000 | Loss: 0.00001427
Iteration 263/1000 | Loss: 0.00001427
Iteration 264/1000 | Loss: 0.00001427
Iteration 265/1000 | Loss: 0.00001427
Iteration 266/1000 | Loss: 0.00001427
Iteration 267/1000 | Loss: 0.00001427
Iteration 268/1000 | Loss: 0.00001427
Iteration 269/1000 | Loss: 0.00001427
Iteration 270/1000 | Loss: 0.00001427
Iteration 271/1000 | Loss: 0.00001427
Iteration 272/1000 | Loss: 0.00001427
Iteration 273/1000 | Loss: 0.00001427
Iteration 274/1000 | Loss: 0.00001427
Iteration 275/1000 | Loss: 0.00001427
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 275. Stopping optimization.
Last 5 losses: [1.4269175153458491e-05, 1.4269175153458491e-05, 1.4269175153458491e-05, 1.4269175153458491e-05, 1.4269175153458491e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4269175153458491e-05

Optimization complete. Final v2v error: 3.1679117679595947 mm

Highest mean error: 4.374687194824219 mm for frame 78

Lowest mean error: 2.7263612747192383 mm for frame 22

Saving results

Total time: 92.3586483001709
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1095/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1095.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1095
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00745083
Iteration 2/25 | Loss: 0.00116768
Iteration 3/25 | Loss: 0.00087337
Iteration 4/25 | Loss: 0.00081930
Iteration 5/25 | Loss: 0.00080745
Iteration 6/25 | Loss: 0.00080491
Iteration 7/25 | Loss: 0.00080485
Iteration 8/25 | Loss: 0.00080485
Iteration 9/25 | Loss: 0.00080485
Iteration 10/25 | Loss: 0.00080485
Iteration 11/25 | Loss: 0.00080485
Iteration 12/25 | Loss: 0.00080485
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008048457675613463, 0.0008048457675613463, 0.0008048457675613463, 0.0008048457675613463, 0.0008048457675613463]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008048457675613463

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.69986689
Iteration 2/25 | Loss: 0.00039522
Iteration 3/25 | Loss: 0.00039522
Iteration 4/25 | Loss: 0.00039522
Iteration 5/25 | Loss: 0.00039522
Iteration 6/25 | Loss: 0.00039522
Iteration 7/25 | Loss: 0.00039522
Iteration 8/25 | Loss: 0.00039522
Iteration 9/25 | Loss: 0.00039522
Iteration 10/25 | Loss: 0.00039522
Iteration 11/25 | Loss: 0.00039522
Iteration 12/25 | Loss: 0.00039522
Iteration 13/25 | Loss: 0.00039522
Iteration 14/25 | Loss: 0.00039522
Iteration 15/25 | Loss: 0.00039522
Iteration 16/25 | Loss: 0.00039522
Iteration 17/25 | Loss: 0.00039522
Iteration 18/25 | Loss: 0.00039522
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003952200640924275, 0.0003952200640924275, 0.0003952200640924275, 0.0003952200640924275, 0.0003952200640924275]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003952200640924275

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039522
Iteration 2/1000 | Loss: 0.00004652
Iteration 3/1000 | Loss: 0.00002898
Iteration 4/1000 | Loss: 0.00002551
Iteration 5/1000 | Loss: 0.00002385
Iteration 6/1000 | Loss: 0.00002256
Iteration 7/1000 | Loss: 0.00002188
Iteration 8/1000 | Loss: 0.00002138
Iteration 9/1000 | Loss: 0.00002094
Iteration 10/1000 | Loss: 0.00002061
Iteration 11/1000 | Loss: 0.00002041
Iteration 12/1000 | Loss: 0.00002024
Iteration 13/1000 | Loss: 0.00002019
Iteration 14/1000 | Loss: 0.00002008
Iteration 15/1000 | Loss: 0.00001998
Iteration 16/1000 | Loss: 0.00001990
Iteration 17/1000 | Loss: 0.00001983
Iteration 18/1000 | Loss: 0.00001981
Iteration 19/1000 | Loss: 0.00001981
Iteration 20/1000 | Loss: 0.00001980
Iteration 21/1000 | Loss: 0.00001980
Iteration 22/1000 | Loss: 0.00001979
Iteration 23/1000 | Loss: 0.00001978
Iteration 24/1000 | Loss: 0.00001978
Iteration 25/1000 | Loss: 0.00001977
Iteration 26/1000 | Loss: 0.00001977
Iteration 27/1000 | Loss: 0.00001977
Iteration 28/1000 | Loss: 0.00001976
Iteration 29/1000 | Loss: 0.00001976
Iteration 30/1000 | Loss: 0.00001976
Iteration 31/1000 | Loss: 0.00001976
Iteration 32/1000 | Loss: 0.00001976
Iteration 33/1000 | Loss: 0.00001976
Iteration 34/1000 | Loss: 0.00001976
Iteration 35/1000 | Loss: 0.00001976
Iteration 36/1000 | Loss: 0.00001975
Iteration 37/1000 | Loss: 0.00001975
Iteration 38/1000 | Loss: 0.00001975
Iteration 39/1000 | Loss: 0.00001975
Iteration 40/1000 | Loss: 0.00001975
Iteration 41/1000 | Loss: 0.00001974
Iteration 42/1000 | Loss: 0.00001974
Iteration 43/1000 | Loss: 0.00001974
Iteration 44/1000 | Loss: 0.00001974
Iteration 45/1000 | Loss: 0.00001973
Iteration 46/1000 | Loss: 0.00001973
Iteration 47/1000 | Loss: 0.00001973
Iteration 48/1000 | Loss: 0.00001973
Iteration 49/1000 | Loss: 0.00001972
Iteration 50/1000 | Loss: 0.00001972
Iteration 51/1000 | Loss: 0.00001972
Iteration 52/1000 | Loss: 0.00001972
Iteration 53/1000 | Loss: 0.00001972
Iteration 54/1000 | Loss: 0.00001972
Iteration 55/1000 | Loss: 0.00001971
Iteration 56/1000 | Loss: 0.00001971
Iteration 57/1000 | Loss: 0.00001971
Iteration 58/1000 | Loss: 0.00001971
Iteration 59/1000 | Loss: 0.00001971
Iteration 60/1000 | Loss: 0.00001970
Iteration 61/1000 | Loss: 0.00001970
Iteration 62/1000 | Loss: 0.00001969
Iteration 63/1000 | Loss: 0.00001969
Iteration 64/1000 | Loss: 0.00001969
Iteration 65/1000 | Loss: 0.00001969
Iteration 66/1000 | Loss: 0.00001969
Iteration 67/1000 | Loss: 0.00001969
Iteration 68/1000 | Loss: 0.00001969
Iteration 69/1000 | Loss: 0.00001969
Iteration 70/1000 | Loss: 0.00001969
Iteration 71/1000 | Loss: 0.00001968
Iteration 72/1000 | Loss: 0.00001968
Iteration 73/1000 | Loss: 0.00001968
Iteration 74/1000 | Loss: 0.00001968
Iteration 75/1000 | Loss: 0.00001968
Iteration 76/1000 | Loss: 0.00001968
Iteration 77/1000 | Loss: 0.00001968
Iteration 78/1000 | Loss: 0.00001968
Iteration 79/1000 | Loss: 0.00001967
Iteration 80/1000 | Loss: 0.00001967
Iteration 81/1000 | Loss: 0.00001967
Iteration 82/1000 | Loss: 0.00001967
Iteration 83/1000 | Loss: 0.00001967
Iteration 84/1000 | Loss: 0.00001967
Iteration 85/1000 | Loss: 0.00001967
Iteration 86/1000 | Loss: 0.00001967
Iteration 87/1000 | Loss: 0.00001967
Iteration 88/1000 | Loss: 0.00001966
Iteration 89/1000 | Loss: 0.00001966
Iteration 90/1000 | Loss: 0.00001966
Iteration 91/1000 | Loss: 0.00001966
Iteration 92/1000 | Loss: 0.00001966
Iteration 93/1000 | Loss: 0.00001966
Iteration 94/1000 | Loss: 0.00001966
Iteration 95/1000 | Loss: 0.00001966
Iteration 96/1000 | Loss: 0.00001966
Iteration 97/1000 | Loss: 0.00001966
Iteration 98/1000 | Loss: 0.00001965
Iteration 99/1000 | Loss: 0.00001965
Iteration 100/1000 | Loss: 0.00001965
Iteration 101/1000 | Loss: 0.00001965
Iteration 102/1000 | Loss: 0.00001965
Iteration 103/1000 | Loss: 0.00001965
Iteration 104/1000 | Loss: 0.00001965
Iteration 105/1000 | Loss: 0.00001965
Iteration 106/1000 | Loss: 0.00001965
Iteration 107/1000 | Loss: 0.00001965
Iteration 108/1000 | Loss: 0.00001965
Iteration 109/1000 | Loss: 0.00001965
Iteration 110/1000 | Loss: 0.00001965
Iteration 111/1000 | Loss: 0.00001965
Iteration 112/1000 | Loss: 0.00001964
Iteration 113/1000 | Loss: 0.00001964
Iteration 114/1000 | Loss: 0.00001964
Iteration 115/1000 | Loss: 0.00001964
Iteration 116/1000 | Loss: 0.00001964
Iteration 117/1000 | Loss: 0.00001964
Iteration 118/1000 | Loss: 0.00001964
Iteration 119/1000 | Loss: 0.00001964
Iteration 120/1000 | Loss: 0.00001964
Iteration 121/1000 | Loss: 0.00001964
Iteration 122/1000 | Loss: 0.00001964
Iteration 123/1000 | Loss: 0.00001964
Iteration 124/1000 | Loss: 0.00001964
Iteration 125/1000 | Loss: 0.00001964
Iteration 126/1000 | Loss: 0.00001963
Iteration 127/1000 | Loss: 0.00001963
Iteration 128/1000 | Loss: 0.00001963
Iteration 129/1000 | Loss: 0.00001963
Iteration 130/1000 | Loss: 0.00001963
Iteration 131/1000 | Loss: 0.00001963
Iteration 132/1000 | Loss: 0.00001963
Iteration 133/1000 | Loss: 0.00001963
Iteration 134/1000 | Loss: 0.00001962
Iteration 135/1000 | Loss: 0.00001962
Iteration 136/1000 | Loss: 0.00001962
Iteration 137/1000 | Loss: 0.00001962
Iteration 138/1000 | Loss: 0.00001962
Iteration 139/1000 | Loss: 0.00001962
Iteration 140/1000 | Loss: 0.00001962
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [1.9624092601588927e-05, 1.9624092601588927e-05, 1.9624092601588927e-05, 1.9624092601588927e-05, 1.9624092601588927e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9624092601588927e-05

Optimization complete. Final v2v error: 3.73775315284729 mm

Highest mean error: 5.273433208465576 mm for frame 64

Lowest mean error: 2.962858200073242 mm for frame 47

Saving results

Total time: 46.315213203430176
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1088/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1088.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1088
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00576701
Iteration 2/25 | Loss: 0.00083659
Iteration 3/25 | Loss: 0.00072284
Iteration 4/25 | Loss: 0.00070772
Iteration 5/25 | Loss: 0.00070166
Iteration 6/25 | Loss: 0.00070026
Iteration 7/25 | Loss: 0.00070022
Iteration 8/25 | Loss: 0.00070022
Iteration 9/25 | Loss: 0.00070022
Iteration 10/25 | Loss: 0.00070022
Iteration 11/25 | Loss: 0.00070022
Iteration 12/25 | Loss: 0.00070022
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007002197089605033, 0.0007002197089605033, 0.0007002197089605033, 0.0007002197089605033, 0.0007002197089605033]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007002197089605033

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.95314956
Iteration 2/25 | Loss: 0.00032395
Iteration 3/25 | Loss: 0.00032395
Iteration 4/25 | Loss: 0.00032394
Iteration 5/25 | Loss: 0.00032394
Iteration 6/25 | Loss: 0.00032394
Iteration 7/25 | Loss: 0.00032394
Iteration 8/25 | Loss: 0.00032394
Iteration 9/25 | Loss: 0.00032394
Iteration 10/25 | Loss: 0.00032394
Iteration 11/25 | Loss: 0.00032394
Iteration 12/25 | Loss: 0.00032394
Iteration 13/25 | Loss: 0.00032394
Iteration 14/25 | Loss: 0.00032394
Iteration 15/25 | Loss: 0.00032394
Iteration 16/25 | Loss: 0.00032394
Iteration 17/25 | Loss: 0.00032394
Iteration 18/25 | Loss: 0.00032394
Iteration 19/25 | Loss: 0.00032394
Iteration 20/25 | Loss: 0.00032394
Iteration 21/25 | Loss: 0.00032394
Iteration 22/25 | Loss: 0.00032394
Iteration 23/25 | Loss: 0.00032394
Iteration 24/25 | Loss: 0.00032394
Iteration 25/25 | Loss: 0.00032394

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032394
Iteration 2/1000 | Loss: 0.00001858
Iteration 3/1000 | Loss: 0.00001397
Iteration 4/1000 | Loss: 0.00001313
Iteration 5/1000 | Loss: 0.00001267
Iteration 6/1000 | Loss: 0.00001228
Iteration 7/1000 | Loss: 0.00001223
Iteration 8/1000 | Loss: 0.00001194
Iteration 9/1000 | Loss: 0.00001178
Iteration 10/1000 | Loss: 0.00001170
Iteration 11/1000 | Loss: 0.00001169
Iteration 12/1000 | Loss: 0.00001159
Iteration 13/1000 | Loss: 0.00001158
Iteration 14/1000 | Loss: 0.00001150
Iteration 15/1000 | Loss: 0.00001146
Iteration 16/1000 | Loss: 0.00001142
Iteration 17/1000 | Loss: 0.00001140
Iteration 18/1000 | Loss: 0.00001135
Iteration 19/1000 | Loss: 0.00001135
Iteration 20/1000 | Loss: 0.00001132
Iteration 21/1000 | Loss: 0.00001132
Iteration 22/1000 | Loss: 0.00001130
Iteration 23/1000 | Loss: 0.00001124
Iteration 24/1000 | Loss: 0.00001122
Iteration 25/1000 | Loss: 0.00001122
Iteration 26/1000 | Loss: 0.00001122
Iteration 27/1000 | Loss: 0.00001121
Iteration 28/1000 | Loss: 0.00001121
Iteration 29/1000 | Loss: 0.00001120
Iteration 30/1000 | Loss: 0.00001118
Iteration 31/1000 | Loss: 0.00001118
Iteration 32/1000 | Loss: 0.00001118
Iteration 33/1000 | Loss: 0.00001117
Iteration 34/1000 | Loss: 0.00001117
Iteration 35/1000 | Loss: 0.00001117
Iteration 36/1000 | Loss: 0.00001117
Iteration 37/1000 | Loss: 0.00001117
Iteration 38/1000 | Loss: 0.00001117
Iteration 39/1000 | Loss: 0.00001117
Iteration 40/1000 | Loss: 0.00001116
Iteration 41/1000 | Loss: 0.00001116
Iteration 42/1000 | Loss: 0.00001116
Iteration 43/1000 | Loss: 0.00001116
Iteration 44/1000 | Loss: 0.00001116
Iteration 45/1000 | Loss: 0.00001116
Iteration 46/1000 | Loss: 0.00001116
Iteration 47/1000 | Loss: 0.00001116
Iteration 48/1000 | Loss: 0.00001115
Iteration 49/1000 | Loss: 0.00001114
Iteration 50/1000 | Loss: 0.00001113
Iteration 51/1000 | Loss: 0.00001113
Iteration 52/1000 | Loss: 0.00001113
Iteration 53/1000 | Loss: 0.00001111
Iteration 54/1000 | Loss: 0.00001111
Iteration 55/1000 | Loss: 0.00001110
Iteration 56/1000 | Loss: 0.00001110
Iteration 57/1000 | Loss: 0.00001110
Iteration 58/1000 | Loss: 0.00001109
Iteration 59/1000 | Loss: 0.00001108
Iteration 60/1000 | Loss: 0.00001108
Iteration 61/1000 | Loss: 0.00001107
Iteration 62/1000 | Loss: 0.00001106
Iteration 63/1000 | Loss: 0.00001105
Iteration 64/1000 | Loss: 0.00001105
Iteration 65/1000 | Loss: 0.00001104
Iteration 66/1000 | Loss: 0.00001104
Iteration 67/1000 | Loss: 0.00001104
Iteration 68/1000 | Loss: 0.00001103
Iteration 69/1000 | Loss: 0.00001103
Iteration 70/1000 | Loss: 0.00001101
Iteration 71/1000 | Loss: 0.00001101
Iteration 72/1000 | Loss: 0.00001101
Iteration 73/1000 | Loss: 0.00001101
Iteration 74/1000 | Loss: 0.00001101
Iteration 75/1000 | Loss: 0.00001100
Iteration 76/1000 | Loss: 0.00001100
Iteration 77/1000 | Loss: 0.00001100
Iteration 78/1000 | Loss: 0.00001100
Iteration 79/1000 | Loss: 0.00001100
Iteration 80/1000 | Loss: 0.00001099
Iteration 81/1000 | Loss: 0.00001099
Iteration 82/1000 | Loss: 0.00001099
Iteration 83/1000 | Loss: 0.00001099
Iteration 84/1000 | Loss: 0.00001099
Iteration 85/1000 | Loss: 0.00001099
Iteration 86/1000 | Loss: 0.00001099
Iteration 87/1000 | Loss: 0.00001099
Iteration 88/1000 | Loss: 0.00001099
Iteration 89/1000 | Loss: 0.00001098
Iteration 90/1000 | Loss: 0.00001098
Iteration 91/1000 | Loss: 0.00001098
Iteration 92/1000 | Loss: 0.00001098
Iteration 93/1000 | Loss: 0.00001098
Iteration 94/1000 | Loss: 0.00001098
Iteration 95/1000 | Loss: 0.00001098
Iteration 96/1000 | Loss: 0.00001098
Iteration 97/1000 | Loss: 0.00001098
Iteration 98/1000 | Loss: 0.00001097
Iteration 99/1000 | Loss: 0.00001097
Iteration 100/1000 | Loss: 0.00001097
Iteration 101/1000 | Loss: 0.00001097
Iteration 102/1000 | Loss: 0.00001097
Iteration 103/1000 | Loss: 0.00001097
Iteration 104/1000 | Loss: 0.00001097
Iteration 105/1000 | Loss: 0.00001097
Iteration 106/1000 | Loss: 0.00001097
Iteration 107/1000 | Loss: 0.00001097
Iteration 108/1000 | Loss: 0.00001097
Iteration 109/1000 | Loss: 0.00001097
Iteration 110/1000 | Loss: 0.00001097
Iteration 111/1000 | Loss: 0.00001097
Iteration 112/1000 | Loss: 0.00001096
Iteration 113/1000 | Loss: 0.00001096
Iteration 114/1000 | Loss: 0.00001096
Iteration 115/1000 | Loss: 0.00001096
Iteration 116/1000 | Loss: 0.00001096
Iteration 117/1000 | Loss: 0.00001096
Iteration 118/1000 | Loss: 0.00001096
Iteration 119/1000 | Loss: 0.00001096
Iteration 120/1000 | Loss: 0.00001096
Iteration 121/1000 | Loss: 0.00001096
Iteration 122/1000 | Loss: 0.00001096
Iteration 123/1000 | Loss: 0.00001096
Iteration 124/1000 | Loss: 0.00001096
Iteration 125/1000 | Loss: 0.00001095
Iteration 126/1000 | Loss: 0.00001095
Iteration 127/1000 | Loss: 0.00001095
Iteration 128/1000 | Loss: 0.00001095
Iteration 129/1000 | Loss: 0.00001095
Iteration 130/1000 | Loss: 0.00001095
Iteration 131/1000 | Loss: 0.00001095
Iteration 132/1000 | Loss: 0.00001095
Iteration 133/1000 | Loss: 0.00001095
Iteration 134/1000 | Loss: 0.00001095
Iteration 135/1000 | Loss: 0.00001095
Iteration 136/1000 | Loss: 0.00001095
Iteration 137/1000 | Loss: 0.00001095
Iteration 138/1000 | Loss: 0.00001095
Iteration 139/1000 | Loss: 0.00001095
Iteration 140/1000 | Loss: 0.00001095
Iteration 141/1000 | Loss: 0.00001095
Iteration 142/1000 | Loss: 0.00001095
Iteration 143/1000 | Loss: 0.00001095
Iteration 144/1000 | Loss: 0.00001095
Iteration 145/1000 | Loss: 0.00001095
Iteration 146/1000 | Loss: 0.00001095
Iteration 147/1000 | Loss: 0.00001095
Iteration 148/1000 | Loss: 0.00001095
Iteration 149/1000 | Loss: 0.00001095
Iteration 150/1000 | Loss: 0.00001095
Iteration 151/1000 | Loss: 0.00001095
Iteration 152/1000 | Loss: 0.00001095
Iteration 153/1000 | Loss: 0.00001095
Iteration 154/1000 | Loss: 0.00001095
Iteration 155/1000 | Loss: 0.00001095
Iteration 156/1000 | Loss: 0.00001095
Iteration 157/1000 | Loss: 0.00001095
Iteration 158/1000 | Loss: 0.00001095
Iteration 159/1000 | Loss: 0.00001095
Iteration 160/1000 | Loss: 0.00001095
Iteration 161/1000 | Loss: 0.00001095
Iteration 162/1000 | Loss: 0.00001095
Iteration 163/1000 | Loss: 0.00001095
Iteration 164/1000 | Loss: 0.00001095
Iteration 165/1000 | Loss: 0.00001095
Iteration 166/1000 | Loss: 0.00001095
Iteration 167/1000 | Loss: 0.00001095
Iteration 168/1000 | Loss: 0.00001095
Iteration 169/1000 | Loss: 0.00001095
Iteration 170/1000 | Loss: 0.00001095
Iteration 171/1000 | Loss: 0.00001095
Iteration 172/1000 | Loss: 0.00001095
Iteration 173/1000 | Loss: 0.00001095
Iteration 174/1000 | Loss: 0.00001095
Iteration 175/1000 | Loss: 0.00001095
Iteration 176/1000 | Loss: 0.00001095
Iteration 177/1000 | Loss: 0.00001095
Iteration 178/1000 | Loss: 0.00001095
Iteration 179/1000 | Loss: 0.00001095
Iteration 180/1000 | Loss: 0.00001095
Iteration 181/1000 | Loss: 0.00001095
Iteration 182/1000 | Loss: 0.00001095
Iteration 183/1000 | Loss: 0.00001095
Iteration 184/1000 | Loss: 0.00001095
Iteration 185/1000 | Loss: 0.00001095
Iteration 186/1000 | Loss: 0.00001095
Iteration 187/1000 | Loss: 0.00001095
Iteration 188/1000 | Loss: 0.00001095
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 188. Stopping optimization.
Last 5 losses: [1.095333482226124e-05, 1.095333482226124e-05, 1.095333482226124e-05, 1.095333482226124e-05, 1.095333482226124e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.095333482226124e-05

Optimization complete. Final v2v error: 2.8367412090301514 mm

Highest mean error: 3.1066534519195557 mm for frame 137

Lowest mean error: 2.7031335830688477 mm for frame 62

Saving results

Total time: 36.21950936317444
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1096
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01037136
Iteration 2/25 | Loss: 0.00263016
Iteration 3/25 | Loss: 0.00133437
Iteration 4/25 | Loss: 0.00112127
Iteration 5/25 | Loss: 0.00100820
Iteration 6/25 | Loss: 0.00099642
Iteration 7/25 | Loss: 0.00096426
Iteration 8/25 | Loss: 0.00093385
Iteration 9/25 | Loss: 0.00092557
Iteration 10/25 | Loss: 0.00092085
Iteration 11/25 | Loss: 0.00090619
Iteration 12/25 | Loss: 0.00089416
Iteration 13/25 | Loss: 0.00087762
Iteration 14/25 | Loss: 0.00087078
Iteration 15/25 | Loss: 0.00086024
Iteration 16/25 | Loss: 0.00085687
Iteration 17/25 | Loss: 0.00085650
Iteration 18/25 | Loss: 0.00085239
Iteration 19/25 | Loss: 0.00085284
Iteration 20/25 | Loss: 0.00084787
Iteration 21/25 | Loss: 0.00084464
Iteration 22/25 | Loss: 0.00084088
Iteration 23/25 | Loss: 0.00084002
Iteration 24/25 | Loss: 0.00084628
Iteration 25/25 | Loss: 0.00084227

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46202409
Iteration 2/25 | Loss: 0.00045638
Iteration 3/25 | Loss: 0.00038559
Iteration 4/25 | Loss: 0.00035356
Iteration 5/25 | Loss: 0.00035356
Iteration 6/25 | Loss: 0.00035356
Iteration 7/25 | Loss: 0.00035356
Iteration 8/25 | Loss: 0.00035356
Iteration 9/25 | Loss: 0.00035356
Iteration 10/25 | Loss: 0.00035356
Iteration 11/25 | Loss: 0.00035356
Iteration 12/25 | Loss: 0.00035356
Iteration 13/25 | Loss: 0.00035356
Iteration 14/25 | Loss: 0.00035356
Iteration 15/25 | Loss: 0.00035356
Iteration 16/25 | Loss: 0.00035356
Iteration 17/25 | Loss: 0.00035356
Iteration 18/25 | Loss: 0.00035356
Iteration 19/25 | Loss: 0.00035356
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00035355970612727106, 0.00035355970612727106, 0.00035355970612727106, 0.00035355970612727106, 0.00035355970612727106]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00035355970612727106

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035356
Iteration 2/1000 | Loss: 0.00018490
Iteration 3/1000 | Loss: 0.00007819
Iteration 4/1000 | Loss: 0.00007055
Iteration 5/1000 | Loss: 0.00006399
Iteration 6/1000 | Loss: 0.00003336
Iteration 7/1000 | Loss: 0.00004007
Iteration 8/1000 | Loss: 0.00009549
Iteration 9/1000 | Loss: 0.00008680
Iteration 10/1000 | Loss: 0.00002998
Iteration 11/1000 | Loss: 0.00003453
Iteration 12/1000 | Loss: 0.00014313
Iteration 13/1000 | Loss: 0.00012831
Iteration 14/1000 | Loss: 0.00013429
Iteration 15/1000 | Loss: 0.00006541
Iteration 16/1000 | Loss: 0.00008015
Iteration 17/1000 | Loss: 0.00013131
Iteration 18/1000 | Loss: 0.00012881
Iteration 19/1000 | Loss: 0.00004622
Iteration 20/1000 | Loss: 0.00003609
Iteration 21/1000 | Loss: 0.00015408
Iteration 22/1000 | Loss: 0.00011610
Iteration 23/1000 | Loss: 0.00010601
Iteration 24/1000 | Loss: 0.00008988
Iteration 25/1000 | Loss: 0.00017251
Iteration 26/1000 | Loss: 0.00003932
Iteration 27/1000 | Loss: 0.00011930
Iteration 28/1000 | Loss: 0.00002955
Iteration 29/1000 | Loss: 0.00005530
Iteration 30/1000 | Loss: 0.00013865
Iteration 31/1000 | Loss: 0.00015148
Iteration 32/1000 | Loss: 0.00009178
Iteration 33/1000 | Loss: 0.00011421
Iteration 34/1000 | Loss: 0.00009617
Iteration 35/1000 | Loss: 0.00013367
Iteration 36/1000 | Loss: 0.00008038
Iteration 37/1000 | Loss: 0.00003514
Iteration 38/1000 | Loss: 0.00011654
Iteration 39/1000 | Loss: 0.00006031
Iteration 40/1000 | Loss: 0.00018190
Iteration 41/1000 | Loss: 0.00006802
Iteration 42/1000 | Loss: 0.00006990
Iteration 43/1000 | Loss: 0.00016304
Iteration 44/1000 | Loss: 0.00023556
Iteration 45/1000 | Loss: 0.00016512
Iteration 46/1000 | Loss: 0.00003683
Iteration 47/1000 | Loss: 0.00014939
Iteration 48/1000 | Loss: 0.00003102
Iteration 49/1000 | Loss: 0.00002664
Iteration 50/1000 | Loss: 0.00013848
Iteration 51/1000 | Loss: 0.00002480
Iteration 52/1000 | Loss: 0.00003547
Iteration 53/1000 | Loss: 0.00002568
Iteration 54/1000 | Loss: 0.00004079
Iteration 55/1000 | Loss: 0.00003428
Iteration 56/1000 | Loss: 0.00012777
Iteration 57/1000 | Loss: 0.00018999
Iteration 58/1000 | Loss: 0.00024162
Iteration 59/1000 | Loss: 0.00010424
Iteration 60/1000 | Loss: 0.00002616
Iteration 61/1000 | Loss: 0.00021251
Iteration 62/1000 | Loss: 0.00014679
Iteration 63/1000 | Loss: 0.00016771
Iteration 64/1000 | Loss: 0.00002973
Iteration 65/1000 | Loss: 0.00002471
Iteration 66/1000 | Loss: 0.00002252
Iteration 67/1000 | Loss: 0.00002222
Iteration 68/1000 | Loss: 0.00005739
Iteration 69/1000 | Loss: 0.00002205
Iteration 70/1000 | Loss: 0.00002190
Iteration 71/1000 | Loss: 0.00002189
Iteration 72/1000 | Loss: 0.00002189
Iteration 73/1000 | Loss: 0.00002186
Iteration 74/1000 | Loss: 0.00002185
Iteration 75/1000 | Loss: 0.00002184
Iteration 76/1000 | Loss: 0.00002183
Iteration 77/1000 | Loss: 0.00002177
Iteration 78/1000 | Loss: 0.00002167
Iteration 79/1000 | Loss: 0.00002166
Iteration 80/1000 | Loss: 0.00002166
Iteration 81/1000 | Loss: 0.00002166
Iteration 82/1000 | Loss: 0.00002165
Iteration 83/1000 | Loss: 0.00002164
Iteration 84/1000 | Loss: 0.00002159
Iteration 85/1000 | Loss: 0.00002153
Iteration 86/1000 | Loss: 0.00002153
Iteration 87/1000 | Loss: 0.00002142
Iteration 88/1000 | Loss: 0.00002139
Iteration 89/1000 | Loss: 0.00002136
Iteration 90/1000 | Loss: 0.00002134
Iteration 91/1000 | Loss: 0.00002133
Iteration 92/1000 | Loss: 0.00004552
Iteration 93/1000 | Loss: 0.00005611
Iteration 94/1000 | Loss: 0.00002918
Iteration 95/1000 | Loss: 0.00002587
Iteration 96/1000 | Loss: 0.00002332
Iteration 97/1000 | Loss: 0.00007693
Iteration 98/1000 | Loss: 0.00002987
Iteration 99/1000 | Loss: 0.00003228
Iteration 100/1000 | Loss: 0.00002478
Iteration 101/1000 | Loss: 0.00002583
Iteration 102/1000 | Loss: 0.00002172
Iteration 103/1000 | Loss: 0.00003023
Iteration 104/1000 | Loss: 0.00002833
Iteration 105/1000 | Loss: 0.00002455
Iteration 106/1000 | Loss: 0.00003680
Iteration 107/1000 | Loss: 0.00003972
Iteration 108/1000 | Loss: 0.00005972
Iteration 109/1000 | Loss: 0.00002371
Iteration 110/1000 | Loss: 0.00002258
Iteration 111/1000 | Loss: 0.00002203
Iteration 112/1000 | Loss: 0.00002170
Iteration 113/1000 | Loss: 0.00002126
Iteration 114/1000 | Loss: 0.00002115
Iteration 115/1000 | Loss: 0.00002105
Iteration 116/1000 | Loss: 0.00002104
Iteration 117/1000 | Loss: 0.00002104
Iteration 118/1000 | Loss: 0.00002103
Iteration 119/1000 | Loss: 0.00002101
Iteration 120/1000 | Loss: 0.00002101
Iteration 121/1000 | Loss: 0.00002101
Iteration 122/1000 | Loss: 0.00002101
Iteration 123/1000 | Loss: 0.00002101
Iteration 124/1000 | Loss: 0.00002101
Iteration 125/1000 | Loss: 0.00002100
Iteration 126/1000 | Loss: 0.00002100
Iteration 127/1000 | Loss: 0.00002100
Iteration 128/1000 | Loss: 0.00002100
Iteration 129/1000 | Loss: 0.00002100
Iteration 130/1000 | Loss: 0.00002099
Iteration 131/1000 | Loss: 0.00002099
Iteration 132/1000 | Loss: 0.00002099
Iteration 133/1000 | Loss: 0.00002099
Iteration 134/1000 | Loss: 0.00002099
Iteration 135/1000 | Loss: 0.00002099
Iteration 136/1000 | Loss: 0.00002099
Iteration 137/1000 | Loss: 0.00002099
Iteration 138/1000 | Loss: 0.00002099
Iteration 139/1000 | Loss: 0.00002098
Iteration 140/1000 | Loss: 0.00002098
Iteration 141/1000 | Loss: 0.00002098
Iteration 142/1000 | Loss: 0.00002098
Iteration 143/1000 | Loss: 0.00002098
Iteration 144/1000 | Loss: 0.00002098
Iteration 145/1000 | Loss: 0.00002098
Iteration 146/1000 | Loss: 0.00002098
Iteration 147/1000 | Loss: 0.00002098
Iteration 148/1000 | Loss: 0.00002098
Iteration 149/1000 | Loss: 0.00002098
Iteration 150/1000 | Loss: 0.00002098
Iteration 151/1000 | Loss: 0.00002098
Iteration 152/1000 | Loss: 0.00002098
Iteration 153/1000 | Loss: 0.00002098
Iteration 154/1000 | Loss: 0.00002098
Iteration 155/1000 | Loss: 0.00002098
Iteration 156/1000 | Loss: 0.00002098
Iteration 157/1000 | Loss: 0.00002098
Iteration 158/1000 | Loss: 0.00002098
Iteration 159/1000 | Loss: 0.00002098
Iteration 160/1000 | Loss: 0.00002098
Iteration 161/1000 | Loss: 0.00002098
Iteration 162/1000 | Loss: 0.00002098
Iteration 163/1000 | Loss: 0.00002098
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [2.097532524203416e-05, 2.097532524203416e-05, 2.097532524203416e-05, 2.097532524203416e-05, 2.097532524203416e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.097532524203416e-05

Optimization complete. Final v2v error: 3.8958539962768555 mm

Highest mean error: 5.213828086853027 mm for frame 180

Lowest mean error: 3.5463123321533203 mm for frame 138

Saving results

Total time: 212.46716785430908
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1076/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1076.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1076
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00271469
Iteration 2/25 | Loss: 0.00107687
Iteration 3/25 | Loss: 0.00083325
Iteration 4/25 | Loss: 0.00076849
Iteration 5/25 | Loss: 0.00074663
Iteration 6/25 | Loss: 0.00074069
Iteration 7/25 | Loss: 0.00073901
Iteration 8/25 | Loss: 0.00073845
Iteration 9/25 | Loss: 0.00073845
Iteration 10/25 | Loss: 0.00073845
Iteration 11/25 | Loss: 0.00073845
Iteration 12/25 | Loss: 0.00073845
Iteration 13/25 | Loss: 0.00073845
Iteration 14/25 | Loss: 0.00073845
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0007384475902654231, 0.0007384475902654231, 0.0007384475902654231, 0.0007384475902654231, 0.0007384475902654231]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007384475902654231

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48629558
Iteration 2/25 | Loss: 0.00033593
Iteration 3/25 | Loss: 0.00033593
Iteration 4/25 | Loss: 0.00033593
Iteration 5/25 | Loss: 0.00033593
Iteration 6/25 | Loss: 0.00033593
Iteration 7/25 | Loss: 0.00033593
Iteration 8/25 | Loss: 0.00033593
Iteration 9/25 | Loss: 0.00033593
Iteration 10/25 | Loss: 0.00033593
Iteration 11/25 | Loss: 0.00033593
Iteration 12/25 | Loss: 0.00033593
Iteration 13/25 | Loss: 0.00033593
Iteration 14/25 | Loss: 0.00033593
Iteration 15/25 | Loss: 0.00033593
Iteration 16/25 | Loss: 0.00033593
Iteration 17/25 | Loss: 0.00033593
Iteration 18/25 | Loss: 0.00033593
Iteration 19/25 | Loss: 0.00033593
Iteration 20/25 | Loss: 0.00033593
Iteration 21/25 | Loss: 0.00033593
Iteration 22/25 | Loss: 0.00033593
Iteration 23/25 | Loss: 0.00033593
Iteration 24/25 | Loss: 0.00033593
Iteration 25/25 | Loss: 0.00033593

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033593
Iteration 2/1000 | Loss: 0.00002982
Iteration 3/1000 | Loss: 0.00001941
Iteration 4/1000 | Loss: 0.00001787
Iteration 5/1000 | Loss: 0.00001696
Iteration 6/1000 | Loss: 0.00001632
Iteration 7/1000 | Loss: 0.00001591
Iteration 8/1000 | Loss: 0.00001556
Iteration 9/1000 | Loss: 0.00001526
Iteration 10/1000 | Loss: 0.00001503
Iteration 11/1000 | Loss: 0.00001494
Iteration 12/1000 | Loss: 0.00001488
Iteration 13/1000 | Loss: 0.00001484
Iteration 14/1000 | Loss: 0.00001483
Iteration 15/1000 | Loss: 0.00001481
Iteration 16/1000 | Loss: 0.00001475
Iteration 17/1000 | Loss: 0.00001474
Iteration 18/1000 | Loss: 0.00001473
Iteration 19/1000 | Loss: 0.00001465
Iteration 20/1000 | Loss: 0.00001462
Iteration 21/1000 | Loss: 0.00001461
Iteration 22/1000 | Loss: 0.00001460
Iteration 23/1000 | Loss: 0.00001459
Iteration 24/1000 | Loss: 0.00001459
Iteration 25/1000 | Loss: 0.00001458
Iteration 26/1000 | Loss: 0.00001457
Iteration 27/1000 | Loss: 0.00001456
Iteration 28/1000 | Loss: 0.00001454
Iteration 29/1000 | Loss: 0.00001454
Iteration 30/1000 | Loss: 0.00001453
Iteration 31/1000 | Loss: 0.00001453
Iteration 32/1000 | Loss: 0.00001452
Iteration 33/1000 | Loss: 0.00001452
Iteration 34/1000 | Loss: 0.00001451
Iteration 35/1000 | Loss: 0.00001451
Iteration 36/1000 | Loss: 0.00001450
Iteration 37/1000 | Loss: 0.00001450
Iteration 38/1000 | Loss: 0.00001450
Iteration 39/1000 | Loss: 0.00001449
Iteration 40/1000 | Loss: 0.00001449
Iteration 41/1000 | Loss: 0.00001449
Iteration 42/1000 | Loss: 0.00001448
Iteration 43/1000 | Loss: 0.00001448
Iteration 44/1000 | Loss: 0.00001448
Iteration 45/1000 | Loss: 0.00001447
Iteration 46/1000 | Loss: 0.00001447
Iteration 47/1000 | Loss: 0.00001446
Iteration 48/1000 | Loss: 0.00001446
Iteration 49/1000 | Loss: 0.00001446
Iteration 50/1000 | Loss: 0.00001445
Iteration 51/1000 | Loss: 0.00001445
Iteration 52/1000 | Loss: 0.00001444
Iteration 53/1000 | Loss: 0.00001444
Iteration 54/1000 | Loss: 0.00001444
Iteration 55/1000 | Loss: 0.00001443
Iteration 56/1000 | Loss: 0.00001443
Iteration 57/1000 | Loss: 0.00001443
Iteration 58/1000 | Loss: 0.00001442
Iteration 59/1000 | Loss: 0.00001442
Iteration 60/1000 | Loss: 0.00001441
Iteration 61/1000 | Loss: 0.00001441
Iteration 62/1000 | Loss: 0.00001441
Iteration 63/1000 | Loss: 0.00001440
Iteration 64/1000 | Loss: 0.00001440
Iteration 65/1000 | Loss: 0.00001440
Iteration 66/1000 | Loss: 0.00001440
Iteration 67/1000 | Loss: 0.00001440
Iteration 68/1000 | Loss: 0.00001440
Iteration 69/1000 | Loss: 0.00001440
Iteration 70/1000 | Loss: 0.00001440
Iteration 71/1000 | Loss: 0.00001439
Iteration 72/1000 | Loss: 0.00001439
Iteration 73/1000 | Loss: 0.00001439
Iteration 74/1000 | Loss: 0.00001438
Iteration 75/1000 | Loss: 0.00001438
Iteration 76/1000 | Loss: 0.00001438
Iteration 77/1000 | Loss: 0.00001437
Iteration 78/1000 | Loss: 0.00001437
Iteration 79/1000 | Loss: 0.00001437
Iteration 80/1000 | Loss: 0.00001437
Iteration 81/1000 | Loss: 0.00001436
Iteration 82/1000 | Loss: 0.00001436
Iteration 83/1000 | Loss: 0.00001436
Iteration 84/1000 | Loss: 0.00001435
Iteration 85/1000 | Loss: 0.00001435
Iteration 86/1000 | Loss: 0.00001435
Iteration 87/1000 | Loss: 0.00001435
Iteration 88/1000 | Loss: 0.00001435
Iteration 89/1000 | Loss: 0.00001434
Iteration 90/1000 | Loss: 0.00001434
Iteration 91/1000 | Loss: 0.00001434
Iteration 92/1000 | Loss: 0.00001433
Iteration 93/1000 | Loss: 0.00001433
Iteration 94/1000 | Loss: 0.00001433
Iteration 95/1000 | Loss: 0.00001433
Iteration 96/1000 | Loss: 0.00001433
Iteration 97/1000 | Loss: 0.00001433
Iteration 98/1000 | Loss: 0.00001433
Iteration 99/1000 | Loss: 0.00001433
Iteration 100/1000 | Loss: 0.00001433
Iteration 101/1000 | Loss: 0.00001433
Iteration 102/1000 | Loss: 0.00001433
Iteration 103/1000 | Loss: 0.00001433
Iteration 104/1000 | Loss: 0.00001433
Iteration 105/1000 | Loss: 0.00001432
Iteration 106/1000 | Loss: 0.00001432
Iteration 107/1000 | Loss: 0.00001432
Iteration 108/1000 | Loss: 0.00001432
Iteration 109/1000 | Loss: 0.00001432
Iteration 110/1000 | Loss: 0.00001432
Iteration 111/1000 | Loss: 0.00001432
Iteration 112/1000 | Loss: 0.00001432
Iteration 113/1000 | Loss: 0.00001432
Iteration 114/1000 | Loss: 0.00001432
Iteration 115/1000 | Loss: 0.00001432
Iteration 116/1000 | Loss: 0.00001432
Iteration 117/1000 | Loss: 0.00001432
Iteration 118/1000 | Loss: 0.00001432
Iteration 119/1000 | Loss: 0.00001432
Iteration 120/1000 | Loss: 0.00001432
Iteration 121/1000 | Loss: 0.00001432
Iteration 122/1000 | Loss: 0.00001432
Iteration 123/1000 | Loss: 0.00001432
Iteration 124/1000 | Loss: 0.00001432
Iteration 125/1000 | Loss: 0.00001432
Iteration 126/1000 | Loss: 0.00001432
Iteration 127/1000 | Loss: 0.00001432
Iteration 128/1000 | Loss: 0.00001432
Iteration 129/1000 | Loss: 0.00001432
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [1.4324519725050777e-05, 1.4324519725050777e-05, 1.4324519725050777e-05, 1.4324519725050777e-05, 1.4324519725050777e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4324519725050777e-05

Optimization complete. Final v2v error: 3.163405656814575 mm

Highest mean error: 3.519470453262329 mm for frame 57

Lowest mean error: 2.8428306579589844 mm for frame 0

Saving results

Total time: 44.222105979919434
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1075/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1075.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1075
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00587621
Iteration 2/25 | Loss: 0.00116642
Iteration 3/25 | Loss: 0.00093354
Iteration 4/25 | Loss: 0.00088935
Iteration 5/25 | Loss: 0.00086474
Iteration 6/25 | Loss: 0.00085733
Iteration 7/25 | Loss: 0.00085464
Iteration 8/25 | Loss: 0.00085381
Iteration 9/25 | Loss: 0.00085367
Iteration 10/25 | Loss: 0.00085937
Iteration 11/25 | Loss: 0.00085671
Iteration 12/25 | Loss: 0.00085408
Iteration 13/25 | Loss: 0.00085650
Iteration 14/25 | Loss: 0.00085403
Iteration 15/25 | Loss: 0.00085897
Iteration 16/25 | Loss: 0.00085370
Iteration 17/25 | Loss: 0.00085321
Iteration 18/25 | Loss: 0.00085224
Iteration 19/25 | Loss: 0.00085179
Iteration 20/25 | Loss: 0.00085163
Iteration 21/25 | Loss: 0.00085153
Iteration 22/25 | Loss: 0.00085145
Iteration 23/25 | Loss: 0.00085145
Iteration 24/25 | Loss: 0.00085145
Iteration 25/25 | Loss: 0.00085145

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.20771670
Iteration 2/25 | Loss: 0.00044634
Iteration 3/25 | Loss: 0.00044633
Iteration 4/25 | Loss: 0.00044633
Iteration 5/25 | Loss: 0.00044633
Iteration 6/25 | Loss: 0.00044633
Iteration 7/25 | Loss: 0.00044632
Iteration 8/25 | Loss: 0.00044632
Iteration 9/25 | Loss: 0.00044632
Iteration 10/25 | Loss: 0.00044632
Iteration 11/25 | Loss: 0.00044632
Iteration 12/25 | Loss: 0.00044632
Iteration 13/25 | Loss: 0.00044632
Iteration 14/25 | Loss: 0.00044632
Iteration 15/25 | Loss: 0.00044632
Iteration 16/25 | Loss: 0.00044632
Iteration 17/25 | Loss: 0.00044632
Iteration 18/25 | Loss: 0.00044632
Iteration 19/25 | Loss: 0.00044632
Iteration 20/25 | Loss: 0.00044632
Iteration 21/25 | Loss: 0.00044632
Iteration 22/25 | Loss: 0.00044632
Iteration 23/25 | Loss: 0.00044632
Iteration 24/25 | Loss: 0.00044632
Iteration 25/25 | Loss: 0.00044632

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044632
Iteration 2/1000 | Loss: 0.00005884
Iteration 3/1000 | Loss: 0.00004140
Iteration 4/1000 | Loss: 0.00003771
Iteration 5/1000 | Loss: 0.00003647
Iteration 6/1000 | Loss: 0.00003530
Iteration 7/1000 | Loss: 0.00003461
Iteration 8/1000 | Loss: 0.00006157
Iteration 9/1000 | Loss: 0.00003387
Iteration 10/1000 | Loss: 0.00003269
Iteration 11/1000 | Loss: 0.00003183
Iteration 12/1000 | Loss: 0.00003125
Iteration 13/1000 | Loss: 0.00003081
Iteration 14/1000 | Loss: 0.00003055
Iteration 15/1000 | Loss: 0.00003036
Iteration 16/1000 | Loss: 0.00003034
Iteration 17/1000 | Loss: 0.00003032
Iteration 18/1000 | Loss: 0.00003031
Iteration 19/1000 | Loss: 0.00003030
Iteration 20/1000 | Loss: 0.00003029
Iteration 21/1000 | Loss: 0.00003029
Iteration 22/1000 | Loss: 0.00003020
Iteration 23/1000 | Loss: 0.00003019
Iteration 24/1000 | Loss: 0.00003017
Iteration 25/1000 | Loss: 0.00003016
Iteration 26/1000 | Loss: 0.00003016
Iteration 27/1000 | Loss: 0.00003012
Iteration 28/1000 | Loss: 0.00003008
Iteration 29/1000 | Loss: 0.00003006
Iteration 30/1000 | Loss: 0.00003002
Iteration 31/1000 | Loss: 0.00003001
Iteration 32/1000 | Loss: 0.00003001
Iteration 33/1000 | Loss: 0.00003001
Iteration 34/1000 | Loss: 0.00003001
Iteration 35/1000 | Loss: 0.00003001
Iteration 36/1000 | Loss: 0.00003001
Iteration 37/1000 | Loss: 0.00003000
Iteration 38/1000 | Loss: 0.00002998
Iteration 39/1000 | Loss: 0.00002997
Iteration 40/1000 | Loss: 0.00002997
Iteration 41/1000 | Loss: 0.00002997
Iteration 42/1000 | Loss: 0.00002997
Iteration 43/1000 | Loss: 0.00002997
Iteration 44/1000 | Loss: 0.00002996
Iteration 45/1000 | Loss: 0.00002996
Iteration 46/1000 | Loss: 0.00002996
Iteration 47/1000 | Loss: 0.00002995
Iteration 48/1000 | Loss: 0.00002995
Iteration 49/1000 | Loss: 0.00002994
Iteration 50/1000 | Loss: 0.00002994
Iteration 51/1000 | Loss: 0.00002994
Iteration 52/1000 | Loss: 0.00002993
Iteration 53/1000 | Loss: 0.00002993
Iteration 54/1000 | Loss: 0.00002993
Iteration 55/1000 | Loss: 0.00002993
Iteration 56/1000 | Loss: 0.00002992
Iteration 57/1000 | Loss: 0.00002992
Iteration 58/1000 | Loss: 0.00002992
Iteration 59/1000 | Loss: 0.00002992
Iteration 60/1000 | Loss: 0.00002991
Iteration 61/1000 | Loss: 0.00002991
Iteration 62/1000 | Loss: 0.00002991
Iteration 63/1000 | Loss: 0.00002991
Iteration 64/1000 | Loss: 0.00002989
Iteration 65/1000 | Loss: 0.00002989
Iteration 66/1000 | Loss: 0.00002989
Iteration 67/1000 | Loss: 0.00002989
Iteration 68/1000 | Loss: 0.00002989
Iteration 69/1000 | Loss: 0.00002989
Iteration 70/1000 | Loss: 0.00002989
Iteration 71/1000 | Loss: 0.00002989
Iteration 72/1000 | Loss: 0.00002989
Iteration 73/1000 | Loss: 0.00002989
Iteration 74/1000 | Loss: 0.00002989
Iteration 75/1000 | Loss: 0.00002989
Iteration 76/1000 | Loss: 0.00002988
Iteration 77/1000 | Loss: 0.00002988
Iteration 78/1000 | Loss: 0.00002988
Iteration 79/1000 | Loss: 0.00002988
Iteration 80/1000 | Loss: 0.00002988
Iteration 81/1000 | Loss: 0.00002987
Iteration 82/1000 | Loss: 0.00002987
Iteration 83/1000 | Loss: 0.00002986
Iteration 84/1000 | Loss: 0.00002986
Iteration 85/1000 | Loss: 0.00002986
Iteration 86/1000 | Loss: 0.00002986
Iteration 87/1000 | Loss: 0.00002985
Iteration 88/1000 | Loss: 0.00002985
Iteration 89/1000 | Loss: 0.00002985
Iteration 90/1000 | Loss: 0.00002985
Iteration 91/1000 | Loss: 0.00002985
Iteration 92/1000 | Loss: 0.00002985
Iteration 93/1000 | Loss: 0.00002985
Iteration 94/1000 | Loss: 0.00002985
Iteration 95/1000 | Loss: 0.00002985
Iteration 96/1000 | Loss: 0.00002984
Iteration 97/1000 | Loss: 0.00002984
Iteration 98/1000 | Loss: 0.00002984
Iteration 99/1000 | Loss: 0.00002984
Iteration 100/1000 | Loss: 0.00002984
Iteration 101/1000 | Loss: 0.00002984
Iteration 102/1000 | Loss: 0.00002984
Iteration 103/1000 | Loss: 0.00002984
Iteration 104/1000 | Loss: 0.00002984
Iteration 105/1000 | Loss: 0.00002984
Iteration 106/1000 | Loss: 0.00002984
Iteration 107/1000 | Loss: 0.00002984
Iteration 108/1000 | Loss: 0.00002984
Iteration 109/1000 | Loss: 0.00002984
Iteration 110/1000 | Loss: 0.00002984
Iteration 111/1000 | Loss: 0.00002984
Iteration 112/1000 | Loss: 0.00002984
Iteration 113/1000 | Loss: 0.00002984
Iteration 114/1000 | Loss: 0.00002984
Iteration 115/1000 | Loss: 0.00002984
Iteration 116/1000 | Loss: 0.00002984
Iteration 117/1000 | Loss: 0.00002983
Iteration 118/1000 | Loss: 0.00002983
Iteration 119/1000 | Loss: 0.00002983
Iteration 120/1000 | Loss: 0.00002983
Iteration 121/1000 | Loss: 0.00002983
Iteration 122/1000 | Loss: 0.00002983
Iteration 123/1000 | Loss: 0.00002983
Iteration 124/1000 | Loss: 0.00002983
Iteration 125/1000 | Loss: 0.00002983
Iteration 126/1000 | Loss: 0.00002982
Iteration 127/1000 | Loss: 0.00002982
Iteration 128/1000 | Loss: 0.00002982
Iteration 129/1000 | Loss: 0.00002982
Iteration 130/1000 | Loss: 0.00002982
Iteration 131/1000 | Loss: 0.00002982
Iteration 132/1000 | Loss: 0.00002982
Iteration 133/1000 | Loss: 0.00002982
Iteration 134/1000 | Loss: 0.00002982
Iteration 135/1000 | Loss: 0.00002982
Iteration 136/1000 | Loss: 0.00002982
Iteration 137/1000 | Loss: 0.00002982
Iteration 138/1000 | Loss: 0.00002982
Iteration 139/1000 | Loss: 0.00002982
Iteration 140/1000 | Loss: 0.00002982
Iteration 141/1000 | Loss: 0.00002982
Iteration 142/1000 | Loss: 0.00002982
Iteration 143/1000 | Loss: 0.00002982
Iteration 144/1000 | Loss: 0.00002982
Iteration 145/1000 | Loss: 0.00002982
Iteration 146/1000 | Loss: 0.00002982
Iteration 147/1000 | Loss: 0.00002982
Iteration 148/1000 | Loss: 0.00002982
Iteration 149/1000 | Loss: 0.00002982
Iteration 150/1000 | Loss: 0.00002982
Iteration 151/1000 | Loss: 0.00002982
Iteration 152/1000 | Loss: 0.00002982
Iteration 153/1000 | Loss: 0.00002981
Iteration 154/1000 | Loss: 0.00002981
Iteration 155/1000 | Loss: 0.00002981
Iteration 156/1000 | Loss: 0.00002981
Iteration 157/1000 | Loss: 0.00002981
Iteration 158/1000 | Loss: 0.00002981
Iteration 159/1000 | Loss: 0.00002981
Iteration 160/1000 | Loss: 0.00002981
Iteration 161/1000 | Loss: 0.00002981
Iteration 162/1000 | Loss: 0.00002981
Iteration 163/1000 | Loss: 0.00002981
Iteration 164/1000 | Loss: 0.00002981
Iteration 165/1000 | Loss: 0.00002981
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [2.9812073989887722e-05, 2.9812073989887722e-05, 2.9812073989887722e-05, 2.9812073989887722e-05, 2.9812073989887722e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9812073989887722e-05

Optimization complete. Final v2v error: 4.405592441558838 mm

Highest mean error: 6.471461296081543 mm for frame 114

Lowest mean error: 3.6531832218170166 mm for frame 134

Saving results

Total time: 73.67915177345276
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1041/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1041.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1041
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00884411
Iteration 2/25 | Loss: 0.00088934
Iteration 3/25 | Loss: 0.00073997
Iteration 4/25 | Loss: 0.00072404
Iteration 5/25 | Loss: 0.00072105
Iteration 6/25 | Loss: 0.00072025
Iteration 7/25 | Loss: 0.00072017
Iteration 8/25 | Loss: 0.00072017
Iteration 9/25 | Loss: 0.00072017
Iteration 10/25 | Loss: 0.00072017
Iteration 11/25 | Loss: 0.00072017
Iteration 12/25 | Loss: 0.00072017
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007201684056781232, 0.0007201684056781232, 0.0007201684056781232, 0.0007201684056781232, 0.0007201684056781232]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007201684056781232

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.90530419
Iteration 2/25 | Loss: 0.00031726
Iteration 3/25 | Loss: 0.00031726
Iteration 4/25 | Loss: 0.00031726
Iteration 5/25 | Loss: 0.00031726
Iteration 6/25 | Loss: 0.00031726
Iteration 7/25 | Loss: 0.00031726
Iteration 8/25 | Loss: 0.00031726
Iteration 9/25 | Loss: 0.00031726
Iteration 10/25 | Loss: 0.00031726
Iteration 11/25 | Loss: 0.00031726
Iteration 12/25 | Loss: 0.00031726
Iteration 13/25 | Loss: 0.00031726
Iteration 14/25 | Loss: 0.00031726
Iteration 15/25 | Loss: 0.00031726
Iteration 16/25 | Loss: 0.00031726
Iteration 17/25 | Loss: 0.00031726
Iteration 18/25 | Loss: 0.00031726
Iteration 19/25 | Loss: 0.00031726
Iteration 20/25 | Loss: 0.00031726
Iteration 21/25 | Loss: 0.00031726
Iteration 22/25 | Loss: 0.00031726
Iteration 23/25 | Loss: 0.00031726
Iteration 24/25 | Loss: 0.00031726
Iteration 25/25 | Loss: 0.00031726
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00031725599546916783, 0.00031725599546916783, 0.00031725599546916783, 0.00031725599546916783, 0.00031725599546916783]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031725599546916783

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031726
Iteration 2/1000 | Loss: 0.00002338
Iteration 3/1000 | Loss: 0.00001497
Iteration 4/1000 | Loss: 0.00001380
Iteration 5/1000 | Loss: 0.00001321
Iteration 6/1000 | Loss: 0.00001284
Iteration 7/1000 | Loss: 0.00001258
Iteration 8/1000 | Loss: 0.00001245
Iteration 9/1000 | Loss: 0.00001244
Iteration 10/1000 | Loss: 0.00001242
Iteration 11/1000 | Loss: 0.00001236
Iteration 12/1000 | Loss: 0.00001234
Iteration 13/1000 | Loss: 0.00001233
Iteration 14/1000 | Loss: 0.00001233
Iteration 15/1000 | Loss: 0.00001228
Iteration 16/1000 | Loss: 0.00001227
Iteration 17/1000 | Loss: 0.00001226
Iteration 18/1000 | Loss: 0.00001226
Iteration 19/1000 | Loss: 0.00001210
Iteration 20/1000 | Loss: 0.00001207
Iteration 21/1000 | Loss: 0.00001205
Iteration 22/1000 | Loss: 0.00001204
Iteration 23/1000 | Loss: 0.00001203
Iteration 24/1000 | Loss: 0.00001203
Iteration 25/1000 | Loss: 0.00001203
Iteration 26/1000 | Loss: 0.00001202
Iteration 27/1000 | Loss: 0.00001202
Iteration 28/1000 | Loss: 0.00001199
Iteration 29/1000 | Loss: 0.00001198
Iteration 30/1000 | Loss: 0.00001194
Iteration 31/1000 | Loss: 0.00001189
Iteration 32/1000 | Loss: 0.00001186
Iteration 33/1000 | Loss: 0.00001186
Iteration 34/1000 | Loss: 0.00001185
Iteration 35/1000 | Loss: 0.00001181
Iteration 36/1000 | Loss: 0.00001181
Iteration 37/1000 | Loss: 0.00001181
Iteration 38/1000 | Loss: 0.00001180
Iteration 39/1000 | Loss: 0.00001180
Iteration 40/1000 | Loss: 0.00001177
Iteration 41/1000 | Loss: 0.00001177
Iteration 42/1000 | Loss: 0.00001177
Iteration 43/1000 | Loss: 0.00001176
Iteration 44/1000 | Loss: 0.00001176
Iteration 45/1000 | Loss: 0.00001176
Iteration 46/1000 | Loss: 0.00001174
Iteration 47/1000 | Loss: 0.00001174
Iteration 48/1000 | Loss: 0.00001173
Iteration 49/1000 | Loss: 0.00001173
Iteration 50/1000 | Loss: 0.00001173
Iteration 51/1000 | Loss: 0.00001173
Iteration 52/1000 | Loss: 0.00001172
Iteration 53/1000 | Loss: 0.00001172
Iteration 54/1000 | Loss: 0.00001172
Iteration 55/1000 | Loss: 0.00001170
Iteration 56/1000 | Loss: 0.00001170
Iteration 57/1000 | Loss: 0.00001169
Iteration 58/1000 | Loss: 0.00001169
Iteration 59/1000 | Loss: 0.00001168
Iteration 60/1000 | Loss: 0.00001168
Iteration 61/1000 | Loss: 0.00001168
Iteration 62/1000 | Loss: 0.00001168
Iteration 63/1000 | Loss: 0.00001167
Iteration 64/1000 | Loss: 0.00001167
Iteration 65/1000 | Loss: 0.00001165
Iteration 66/1000 | Loss: 0.00001165
Iteration 67/1000 | Loss: 0.00001164
Iteration 68/1000 | Loss: 0.00001164
Iteration 69/1000 | Loss: 0.00001164
Iteration 70/1000 | Loss: 0.00001163
Iteration 71/1000 | Loss: 0.00001163
Iteration 72/1000 | Loss: 0.00001163
Iteration 73/1000 | Loss: 0.00001163
Iteration 74/1000 | Loss: 0.00001163
Iteration 75/1000 | Loss: 0.00001162
Iteration 76/1000 | Loss: 0.00001162
Iteration 77/1000 | Loss: 0.00001162
Iteration 78/1000 | Loss: 0.00001162
Iteration 79/1000 | Loss: 0.00001162
Iteration 80/1000 | Loss: 0.00001161
Iteration 81/1000 | Loss: 0.00001161
Iteration 82/1000 | Loss: 0.00001161
Iteration 83/1000 | Loss: 0.00001161
Iteration 84/1000 | Loss: 0.00001160
Iteration 85/1000 | Loss: 0.00001160
Iteration 86/1000 | Loss: 0.00001160
Iteration 87/1000 | Loss: 0.00001160
Iteration 88/1000 | Loss: 0.00001160
Iteration 89/1000 | Loss: 0.00001159
Iteration 90/1000 | Loss: 0.00001159
Iteration 91/1000 | Loss: 0.00001159
Iteration 92/1000 | Loss: 0.00001159
Iteration 93/1000 | Loss: 0.00001159
Iteration 94/1000 | Loss: 0.00001159
Iteration 95/1000 | Loss: 0.00001159
Iteration 96/1000 | Loss: 0.00001159
Iteration 97/1000 | Loss: 0.00001159
Iteration 98/1000 | Loss: 0.00001159
Iteration 99/1000 | Loss: 0.00001159
Iteration 100/1000 | Loss: 0.00001159
Iteration 101/1000 | Loss: 0.00001159
Iteration 102/1000 | Loss: 0.00001159
Iteration 103/1000 | Loss: 0.00001158
Iteration 104/1000 | Loss: 0.00001158
Iteration 105/1000 | Loss: 0.00001158
Iteration 106/1000 | Loss: 0.00001158
Iteration 107/1000 | Loss: 0.00001158
Iteration 108/1000 | Loss: 0.00001158
Iteration 109/1000 | Loss: 0.00001158
Iteration 110/1000 | Loss: 0.00001158
Iteration 111/1000 | Loss: 0.00001158
Iteration 112/1000 | Loss: 0.00001158
Iteration 113/1000 | Loss: 0.00001158
Iteration 114/1000 | Loss: 0.00001157
Iteration 115/1000 | Loss: 0.00001157
Iteration 116/1000 | Loss: 0.00001157
Iteration 117/1000 | Loss: 0.00001157
Iteration 118/1000 | Loss: 0.00001157
Iteration 119/1000 | Loss: 0.00001157
Iteration 120/1000 | Loss: 0.00001157
Iteration 121/1000 | Loss: 0.00001157
Iteration 122/1000 | Loss: 0.00001157
Iteration 123/1000 | Loss: 0.00001157
Iteration 124/1000 | Loss: 0.00001157
Iteration 125/1000 | Loss: 0.00001157
Iteration 126/1000 | Loss: 0.00001156
Iteration 127/1000 | Loss: 0.00001156
Iteration 128/1000 | Loss: 0.00001156
Iteration 129/1000 | Loss: 0.00001156
Iteration 130/1000 | Loss: 0.00001156
Iteration 131/1000 | Loss: 0.00001156
Iteration 132/1000 | Loss: 0.00001156
Iteration 133/1000 | Loss: 0.00001156
Iteration 134/1000 | Loss: 0.00001155
Iteration 135/1000 | Loss: 0.00001155
Iteration 136/1000 | Loss: 0.00001155
Iteration 137/1000 | Loss: 0.00001155
Iteration 138/1000 | Loss: 0.00001155
Iteration 139/1000 | Loss: 0.00001155
Iteration 140/1000 | Loss: 0.00001155
Iteration 141/1000 | Loss: 0.00001155
Iteration 142/1000 | Loss: 0.00001155
Iteration 143/1000 | Loss: 0.00001155
Iteration 144/1000 | Loss: 0.00001155
Iteration 145/1000 | Loss: 0.00001155
Iteration 146/1000 | Loss: 0.00001155
Iteration 147/1000 | Loss: 0.00001155
Iteration 148/1000 | Loss: 0.00001155
Iteration 149/1000 | Loss: 0.00001155
Iteration 150/1000 | Loss: 0.00001155
Iteration 151/1000 | Loss: 0.00001155
Iteration 152/1000 | Loss: 0.00001155
Iteration 153/1000 | Loss: 0.00001155
Iteration 154/1000 | Loss: 0.00001155
Iteration 155/1000 | Loss: 0.00001154
Iteration 156/1000 | Loss: 0.00001154
Iteration 157/1000 | Loss: 0.00001154
Iteration 158/1000 | Loss: 0.00001154
Iteration 159/1000 | Loss: 0.00001154
Iteration 160/1000 | Loss: 0.00001154
Iteration 161/1000 | Loss: 0.00001154
Iteration 162/1000 | Loss: 0.00001154
Iteration 163/1000 | Loss: 0.00001154
Iteration 164/1000 | Loss: 0.00001154
Iteration 165/1000 | Loss: 0.00001154
Iteration 166/1000 | Loss: 0.00001154
Iteration 167/1000 | Loss: 0.00001154
Iteration 168/1000 | Loss: 0.00001154
Iteration 169/1000 | Loss: 0.00001154
Iteration 170/1000 | Loss: 0.00001154
Iteration 171/1000 | Loss: 0.00001154
Iteration 172/1000 | Loss: 0.00001154
Iteration 173/1000 | Loss: 0.00001154
Iteration 174/1000 | Loss: 0.00001154
Iteration 175/1000 | Loss: 0.00001154
Iteration 176/1000 | Loss: 0.00001154
Iteration 177/1000 | Loss: 0.00001154
Iteration 178/1000 | Loss: 0.00001154
Iteration 179/1000 | Loss: 0.00001154
Iteration 180/1000 | Loss: 0.00001154
Iteration 181/1000 | Loss: 0.00001154
Iteration 182/1000 | Loss: 0.00001154
Iteration 183/1000 | Loss: 0.00001154
Iteration 184/1000 | Loss: 0.00001154
Iteration 185/1000 | Loss: 0.00001154
Iteration 186/1000 | Loss: 0.00001154
Iteration 187/1000 | Loss: 0.00001154
Iteration 188/1000 | Loss: 0.00001154
Iteration 189/1000 | Loss: 0.00001154
Iteration 190/1000 | Loss: 0.00001154
Iteration 191/1000 | Loss: 0.00001154
Iteration 192/1000 | Loss: 0.00001154
Iteration 193/1000 | Loss: 0.00001154
Iteration 194/1000 | Loss: 0.00001154
Iteration 195/1000 | Loss: 0.00001154
Iteration 196/1000 | Loss: 0.00001154
Iteration 197/1000 | Loss: 0.00001154
Iteration 198/1000 | Loss: 0.00001154
Iteration 199/1000 | Loss: 0.00001154
Iteration 200/1000 | Loss: 0.00001154
Iteration 201/1000 | Loss: 0.00001154
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 201. Stopping optimization.
Last 5 losses: [1.153574794443557e-05, 1.153574794443557e-05, 1.153574794443557e-05, 1.153574794443557e-05, 1.153574794443557e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.153574794443557e-05

Optimization complete. Final v2v error: 2.8655295372009277 mm

Highest mean error: 3.3530972003936768 mm for frame 51

Lowest mean error: 2.719923734664917 mm for frame 21

Saving results

Total time: 37.55437612533569
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1074/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1074.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1074
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00427769
Iteration 2/25 | Loss: 0.00090371
Iteration 3/25 | Loss: 0.00078936
Iteration 4/25 | Loss: 0.00076304
Iteration 5/25 | Loss: 0.00075377
Iteration 6/25 | Loss: 0.00075265
Iteration 7/25 | Loss: 0.00075230
Iteration 8/25 | Loss: 0.00075230
Iteration 9/25 | Loss: 0.00075230
Iteration 10/25 | Loss: 0.00075230
Iteration 11/25 | Loss: 0.00075230
Iteration 12/25 | Loss: 0.00075230
Iteration 13/25 | Loss: 0.00075230
Iteration 14/25 | Loss: 0.00075230
Iteration 15/25 | Loss: 0.00075230
Iteration 16/25 | Loss: 0.00075230
Iteration 17/25 | Loss: 0.00075230
Iteration 18/25 | Loss: 0.00075230
Iteration 19/25 | Loss: 0.00075230
Iteration 20/25 | Loss: 0.00075230
Iteration 21/25 | Loss: 0.00075230
Iteration 22/25 | Loss: 0.00075230
Iteration 23/25 | Loss: 0.00075230
Iteration 24/25 | Loss: 0.00075230
Iteration 25/25 | Loss: 0.00075230

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46739006
Iteration 2/25 | Loss: 0.00033347
Iteration 3/25 | Loss: 0.00033347
Iteration 4/25 | Loss: 0.00033347
Iteration 5/25 | Loss: 0.00033347
Iteration 6/25 | Loss: 0.00033347
Iteration 7/25 | Loss: 0.00033347
Iteration 8/25 | Loss: 0.00033347
Iteration 9/25 | Loss: 0.00033347
Iteration 10/25 | Loss: 0.00033347
Iteration 11/25 | Loss: 0.00033347
Iteration 12/25 | Loss: 0.00033347
Iteration 13/25 | Loss: 0.00033347
Iteration 14/25 | Loss: 0.00033347
Iteration 15/25 | Loss: 0.00033347
Iteration 16/25 | Loss: 0.00033347
Iteration 17/25 | Loss: 0.00033347
Iteration 18/25 | Loss: 0.00033347
Iteration 19/25 | Loss: 0.00033347
Iteration 20/25 | Loss: 0.00033347
Iteration 21/25 | Loss: 0.00033347
Iteration 22/25 | Loss: 0.00033347
Iteration 23/25 | Loss: 0.00033347
Iteration 24/25 | Loss: 0.00033347
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.000333469855831936, 0.000333469855831936, 0.000333469855831936, 0.000333469855831936, 0.000333469855831936]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000333469855831936

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033347
Iteration 2/1000 | Loss: 0.00002808
Iteration 3/1000 | Loss: 0.00002081
Iteration 4/1000 | Loss: 0.00001978
Iteration 5/1000 | Loss: 0.00001893
Iteration 6/1000 | Loss: 0.00001849
Iteration 7/1000 | Loss: 0.00001816
Iteration 8/1000 | Loss: 0.00001788
Iteration 9/1000 | Loss: 0.00001769
Iteration 10/1000 | Loss: 0.00001765
Iteration 11/1000 | Loss: 0.00001761
Iteration 12/1000 | Loss: 0.00001760
Iteration 13/1000 | Loss: 0.00001754
Iteration 14/1000 | Loss: 0.00001754
Iteration 15/1000 | Loss: 0.00001748
Iteration 16/1000 | Loss: 0.00001748
Iteration 17/1000 | Loss: 0.00001743
Iteration 18/1000 | Loss: 0.00001742
Iteration 19/1000 | Loss: 0.00001742
Iteration 20/1000 | Loss: 0.00001742
Iteration 21/1000 | Loss: 0.00001741
Iteration 22/1000 | Loss: 0.00001741
Iteration 23/1000 | Loss: 0.00001741
Iteration 24/1000 | Loss: 0.00001740
Iteration 25/1000 | Loss: 0.00001740
Iteration 26/1000 | Loss: 0.00001739
Iteration 27/1000 | Loss: 0.00001739
Iteration 28/1000 | Loss: 0.00001739
Iteration 29/1000 | Loss: 0.00001739
Iteration 30/1000 | Loss: 0.00001738
Iteration 31/1000 | Loss: 0.00001738
Iteration 32/1000 | Loss: 0.00001738
Iteration 33/1000 | Loss: 0.00001738
Iteration 34/1000 | Loss: 0.00001738
Iteration 35/1000 | Loss: 0.00001738
Iteration 36/1000 | Loss: 0.00001738
Iteration 37/1000 | Loss: 0.00001737
Iteration 38/1000 | Loss: 0.00001737
Iteration 39/1000 | Loss: 0.00001737
Iteration 40/1000 | Loss: 0.00001737
Iteration 41/1000 | Loss: 0.00001737
Iteration 42/1000 | Loss: 0.00001736
Iteration 43/1000 | Loss: 0.00001736
Iteration 44/1000 | Loss: 0.00001736
Iteration 45/1000 | Loss: 0.00001736
Iteration 46/1000 | Loss: 0.00001735
Iteration 47/1000 | Loss: 0.00001735
Iteration 48/1000 | Loss: 0.00001735
Iteration 49/1000 | Loss: 0.00001734
Iteration 50/1000 | Loss: 0.00001734
Iteration 51/1000 | Loss: 0.00001734
Iteration 52/1000 | Loss: 0.00001734
Iteration 53/1000 | Loss: 0.00001733
Iteration 54/1000 | Loss: 0.00001733
Iteration 55/1000 | Loss: 0.00001733
Iteration 56/1000 | Loss: 0.00001732
Iteration 57/1000 | Loss: 0.00001732
Iteration 58/1000 | Loss: 0.00001731
Iteration 59/1000 | Loss: 0.00001730
Iteration 60/1000 | Loss: 0.00001730
Iteration 61/1000 | Loss: 0.00001730
Iteration 62/1000 | Loss: 0.00001730
Iteration 63/1000 | Loss: 0.00001730
Iteration 64/1000 | Loss: 0.00001729
Iteration 65/1000 | Loss: 0.00001729
Iteration 66/1000 | Loss: 0.00001729
Iteration 67/1000 | Loss: 0.00001728
Iteration 68/1000 | Loss: 0.00001727
Iteration 69/1000 | Loss: 0.00001727
Iteration 70/1000 | Loss: 0.00001726
Iteration 71/1000 | Loss: 0.00001725
Iteration 72/1000 | Loss: 0.00001725
Iteration 73/1000 | Loss: 0.00001724
Iteration 74/1000 | Loss: 0.00001724
Iteration 75/1000 | Loss: 0.00001724
Iteration 76/1000 | Loss: 0.00001724
Iteration 77/1000 | Loss: 0.00001724
Iteration 78/1000 | Loss: 0.00001723
Iteration 79/1000 | Loss: 0.00001723
Iteration 80/1000 | Loss: 0.00001723
Iteration 81/1000 | Loss: 0.00001723
Iteration 82/1000 | Loss: 0.00001723
Iteration 83/1000 | Loss: 0.00001723
Iteration 84/1000 | Loss: 0.00001722
Iteration 85/1000 | Loss: 0.00001722
Iteration 86/1000 | Loss: 0.00001722
Iteration 87/1000 | Loss: 0.00001722
Iteration 88/1000 | Loss: 0.00001722
Iteration 89/1000 | Loss: 0.00001722
Iteration 90/1000 | Loss: 0.00001722
Iteration 91/1000 | Loss: 0.00001721
Iteration 92/1000 | Loss: 0.00001721
Iteration 93/1000 | Loss: 0.00001721
Iteration 94/1000 | Loss: 0.00001720
Iteration 95/1000 | Loss: 0.00001720
Iteration 96/1000 | Loss: 0.00001720
Iteration 97/1000 | Loss: 0.00001720
Iteration 98/1000 | Loss: 0.00001720
Iteration 99/1000 | Loss: 0.00001720
Iteration 100/1000 | Loss: 0.00001720
Iteration 101/1000 | Loss: 0.00001720
Iteration 102/1000 | Loss: 0.00001720
Iteration 103/1000 | Loss: 0.00001720
Iteration 104/1000 | Loss: 0.00001720
Iteration 105/1000 | Loss: 0.00001720
Iteration 106/1000 | Loss: 0.00001720
Iteration 107/1000 | Loss: 0.00001720
Iteration 108/1000 | Loss: 0.00001720
Iteration 109/1000 | Loss: 0.00001720
Iteration 110/1000 | Loss: 0.00001720
Iteration 111/1000 | Loss: 0.00001720
Iteration 112/1000 | Loss: 0.00001720
Iteration 113/1000 | Loss: 0.00001720
Iteration 114/1000 | Loss: 0.00001720
Iteration 115/1000 | Loss: 0.00001720
Iteration 116/1000 | Loss: 0.00001720
Iteration 117/1000 | Loss: 0.00001720
Iteration 118/1000 | Loss: 0.00001720
Iteration 119/1000 | Loss: 0.00001720
Iteration 120/1000 | Loss: 0.00001720
Iteration 121/1000 | Loss: 0.00001720
Iteration 122/1000 | Loss: 0.00001720
Iteration 123/1000 | Loss: 0.00001720
Iteration 124/1000 | Loss: 0.00001720
Iteration 125/1000 | Loss: 0.00001720
Iteration 126/1000 | Loss: 0.00001720
Iteration 127/1000 | Loss: 0.00001720
Iteration 128/1000 | Loss: 0.00001720
Iteration 129/1000 | Loss: 0.00001720
Iteration 130/1000 | Loss: 0.00001720
Iteration 131/1000 | Loss: 0.00001720
Iteration 132/1000 | Loss: 0.00001720
Iteration 133/1000 | Loss: 0.00001720
Iteration 134/1000 | Loss: 0.00001720
Iteration 135/1000 | Loss: 0.00001720
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [1.7201407899847254e-05, 1.7201407899847254e-05, 1.7201407899847254e-05, 1.7201407899847254e-05, 1.7201407899847254e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7201407899847254e-05

Optimization complete. Final v2v error: 3.4966790676116943 mm

Highest mean error: 3.792874336242676 mm for frame 97

Lowest mean error: 3.138669490814209 mm for frame 4

Saving results

Total time: 33.73944020271301
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1094
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00892172
Iteration 2/25 | Loss: 0.00133824
Iteration 3/25 | Loss: 0.00089805
Iteration 4/25 | Loss: 0.00081359
Iteration 5/25 | Loss: 0.00079785
Iteration 6/25 | Loss: 0.00079451
Iteration 7/25 | Loss: 0.00079395
Iteration 8/25 | Loss: 0.00079395
Iteration 9/25 | Loss: 0.00079395
Iteration 10/25 | Loss: 0.00079395
Iteration 11/25 | Loss: 0.00079395
Iteration 12/25 | Loss: 0.00079395
Iteration 13/25 | Loss: 0.00079395
Iteration 14/25 | Loss: 0.00079395
Iteration 15/25 | Loss: 0.00079395
Iteration 16/25 | Loss: 0.00079395
Iteration 17/25 | Loss: 0.00079395
Iteration 18/25 | Loss: 0.00079395
Iteration 19/25 | Loss: 0.00079395
Iteration 20/25 | Loss: 0.00079395
Iteration 21/25 | Loss: 0.00079395
Iteration 22/25 | Loss: 0.00079395
Iteration 23/25 | Loss: 0.00079395
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.000793950748629868, 0.000793950748629868, 0.000793950748629868, 0.000793950748629868, 0.000793950748629868]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000793950748629868

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.46828461
Iteration 2/25 | Loss: 0.00032202
Iteration 3/25 | Loss: 0.00032201
Iteration 4/25 | Loss: 0.00032201
Iteration 5/25 | Loss: 0.00032201
Iteration 6/25 | Loss: 0.00032201
Iteration 7/25 | Loss: 0.00032201
Iteration 8/25 | Loss: 0.00032201
Iteration 9/25 | Loss: 0.00032201
Iteration 10/25 | Loss: 0.00032201
Iteration 11/25 | Loss: 0.00032201
Iteration 12/25 | Loss: 0.00032201
Iteration 13/25 | Loss: 0.00032201
Iteration 14/25 | Loss: 0.00032201
Iteration 15/25 | Loss: 0.00032201
Iteration 16/25 | Loss: 0.00032201
Iteration 17/25 | Loss: 0.00032201
Iteration 18/25 | Loss: 0.00032201
Iteration 19/25 | Loss: 0.00032201
Iteration 20/25 | Loss: 0.00032201
Iteration 21/25 | Loss: 0.00032201
Iteration 22/25 | Loss: 0.00032201
Iteration 23/25 | Loss: 0.00032201
Iteration 24/25 | Loss: 0.00032201
Iteration 25/25 | Loss: 0.00032201

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032201
Iteration 2/1000 | Loss: 0.00002308
Iteration 3/1000 | Loss: 0.00001607
Iteration 4/1000 | Loss: 0.00001457
Iteration 5/1000 | Loss: 0.00001396
Iteration 6/1000 | Loss: 0.00001347
Iteration 7/1000 | Loss: 0.00001331
Iteration 8/1000 | Loss: 0.00001322
Iteration 9/1000 | Loss: 0.00001311
Iteration 10/1000 | Loss: 0.00001290
Iteration 11/1000 | Loss: 0.00001282
Iteration 12/1000 | Loss: 0.00001281
Iteration 13/1000 | Loss: 0.00001279
Iteration 14/1000 | Loss: 0.00001274
Iteration 15/1000 | Loss: 0.00001272
Iteration 16/1000 | Loss: 0.00001271
Iteration 17/1000 | Loss: 0.00001270
Iteration 18/1000 | Loss: 0.00001269
Iteration 19/1000 | Loss: 0.00001269
Iteration 20/1000 | Loss: 0.00001269
Iteration 21/1000 | Loss: 0.00001269
Iteration 22/1000 | Loss: 0.00001269
Iteration 23/1000 | Loss: 0.00001269
Iteration 24/1000 | Loss: 0.00001269
Iteration 25/1000 | Loss: 0.00001269
Iteration 26/1000 | Loss: 0.00001268
Iteration 27/1000 | Loss: 0.00001268
Iteration 28/1000 | Loss: 0.00001267
Iteration 29/1000 | Loss: 0.00001266
Iteration 30/1000 | Loss: 0.00001263
Iteration 31/1000 | Loss: 0.00001263
Iteration 32/1000 | Loss: 0.00001263
Iteration 33/1000 | Loss: 0.00001262
Iteration 34/1000 | Loss: 0.00001262
Iteration 35/1000 | Loss: 0.00001262
Iteration 36/1000 | Loss: 0.00001262
Iteration 37/1000 | Loss: 0.00001261
Iteration 38/1000 | Loss: 0.00001259
Iteration 39/1000 | Loss: 0.00001259
Iteration 40/1000 | Loss: 0.00001259
Iteration 41/1000 | Loss: 0.00001259
Iteration 42/1000 | Loss: 0.00001259
Iteration 43/1000 | Loss: 0.00001258
Iteration 44/1000 | Loss: 0.00001258
Iteration 45/1000 | Loss: 0.00001258
Iteration 46/1000 | Loss: 0.00001258
Iteration 47/1000 | Loss: 0.00001257
Iteration 48/1000 | Loss: 0.00001257
Iteration 49/1000 | Loss: 0.00001257
Iteration 50/1000 | Loss: 0.00001256
Iteration 51/1000 | Loss: 0.00001256
Iteration 52/1000 | Loss: 0.00001256
Iteration 53/1000 | Loss: 0.00001256
Iteration 54/1000 | Loss: 0.00001255
Iteration 55/1000 | Loss: 0.00001255
Iteration 56/1000 | Loss: 0.00001254
Iteration 57/1000 | Loss: 0.00001254
Iteration 58/1000 | Loss: 0.00001253
Iteration 59/1000 | Loss: 0.00001252
Iteration 60/1000 | Loss: 0.00001249
Iteration 61/1000 | Loss: 0.00001249
Iteration 62/1000 | Loss: 0.00001246
Iteration 63/1000 | Loss: 0.00001245
Iteration 64/1000 | Loss: 0.00001244
Iteration 65/1000 | Loss: 0.00001244
Iteration 66/1000 | Loss: 0.00001244
Iteration 67/1000 | Loss: 0.00001244
Iteration 68/1000 | Loss: 0.00001244
Iteration 69/1000 | Loss: 0.00001244
Iteration 70/1000 | Loss: 0.00001243
Iteration 71/1000 | Loss: 0.00001243
Iteration 72/1000 | Loss: 0.00001243
Iteration 73/1000 | Loss: 0.00001243
Iteration 74/1000 | Loss: 0.00001243
Iteration 75/1000 | Loss: 0.00001243
Iteration 76/1000 | Loss: 0.00001242
Iteration 77/1000 | Loss: 0.00001241
Iteration 78/1000 | Loss: 0.00001241
Iteration 79/1000 | Loss: 0.00001241
Iteration 80/1000 | Loss: 0.00001240
Iteration 81/1000 | Loss: 0.00001240
Iteration 82/1000 | Loss: 0.00001240
Iteration 83/1000 | Loss: 0.00001240
Iteration 84/1000 | Loss: 0.00001240
Iteration 85/1000 | Loss: 0.00001239
Iteration 86/1000 | Loss: 0.00001239
Iteration 87/1000 | Loss: 0.00001238
Iteration 88/1000 | Loss: 0.00001238
Iteration 89/1000 | Loss: 0.00001238
Iteration 90/1000 | Loss: 0.00001238
Iteration 91/1000 | Loss: 0.00001238
Iteration 92/1000 | Loss: 0.00001238
Iteration 93/1000 | Loss: 0.00001238
Iteration 94/1000 | Loss: 0.00001238
Iteration 95/1000 | Loss: 0.00001238
Iteration 96/1000 | Loss: 0.00001238
Iteration 97/1000 | Loss: 0.00001237
Iteration 98/1000 | Loss: 0.00001237
Iteration 99/1000 | Loss: 0.00001237
Iteration 100/1000 | Loss: 0.00001237
Iteration 101/1000 | Loss: 0.00001237
Iteration 102/1000 | Loss: 0.00001237
Iteration 103/1000 | Loss: 0.00001237
Iteration 104/1000 | Loss: 0.00001237
Iteration 105/1000 | Loss: 0.00001237
Iteration 106/1000 | Loss: 0.00001236
Iteration 107/1000 | Loss: 0.00001236
Iteration 108/1000 | Loss: 0.00001236
Iteration 109/1000 | Loss: 0.00001236
Iteration 110/1000 | Loss: 0.00001236
Iteration 111/1000 | Loss: 0.00001236
Iteration 112/1000 | Loss: 0.00001236
Iteration 113/1000 | Loss: 0.00001236
Iteration 114/1000 | Loss: 0.00001236
Iteration 115/1000 | Loss: 0.00001236
Iteration 116/1000 | Loss: 0.00001236
Iteration 117/1000 | Loss: 0.00001236
Iteration 118/1000 | Loss: 0.00001236
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [1.2359002539596986e-05, 1.2359002539596986e-05, 1.2359002539596986e-05, 1.2359002539596986e-05, 1.2359002539596986e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2359002539596986e-05

Optimization complete. Final v2v error: 2.945981025695801 mm

Highest mean error: 3.1066768169403076 mm for frame 181

Lowest mean error: 2.7864327430725098 mm for frame 204

Saving results

Total time: 39.17079567909241
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1066
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468464
Iteration 2/25 | Loss: 0.00087410
Iteration 3/25 | Loss: 0.00076203
Iteration 4/25 | Loss: 0.00074353
Iteration 5/25 | Loss: 0.00073812
Iteration 6/25 | Loss: 0.00073745
Iteration 7/25 | Loss: 0.00073745
Iteration 8/25 | Loss: 0.00073745
Iteration 9/25 | Loss: 0.00073745
Iteration 10/25 | Loss: 0.00073745
Iteration 11/25 | Loss: 0.00073745
Iteration 12/25 | Loss: 0.00073745
Iteration 13/25 | Loss: 0.00073745
Iteration 14/25 | Loss: 0.00073745
Iteration 15/25 | Loss: 0.00073745
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0007374518900178373, 0.0007374518900178373, 0.0007374518900178373, 0.0007374518900178373, 0.0007374518900178373]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007374518900178373

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.95726013
Iteration 2/25 | Loss: 0.00030462
Iteration 3/25 | Loss: 0.00030462
Iteration 4/25 | Loss: 0.00030462
Iteration 5/25 | Loss: 0.00030462
Iteration 6/25 | Loss: 0.00030462
Iteration 7/25 | Loss: 0.00030462
Iteration 8/25 | Loss: 0.00030462
Iteration 9/25 | Loss: 0.00030462
Iteration 10/25 | Loss: 0.00030461
Iteration 11/25 | Loss: 0.00030461
Iteration 12/25 | Loss: 0.00030461
Iteration 13/25 | Loss: 0.00030461
Iteration 14/25 | Loss: 0.00030461
Iteration 15/25 | Loss: 0.00030461
Iteration 16/25 | Loss: 0.00030461
Iteration 17/25 | Loss: 0.00030461
Iteration 18/25 | Loss: 0.00030461
Iteration 19/25 | Loss: 0.00030461
Iteration 20/25 | Loss: 0.00030461
Iteration 21/25 | Loss: 0.00030461
Iteration 22/25 | Loss: 0.00030461
Iteration 23/25 | Loss: 0.00030461
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00030461454298347235, 0.00030461454298347235, 0.00030461454298347235, 0.00030461454298347235, 0.00030461454298347235]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00030461454298347235

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030461
Iteration 2/1000 | Loss: 0.00002062
Iteration 3/1000 | Loss: 0.00001718
Iteration 4/1000 | Loss: 0.00001598
Iteration 5/1000 | Loss: 0.00001527
Iteration 6/1000 | Loss: 0.00001488
Iteration 7/1000 | Loss: 0.00001467
Iteration 8/1000 | Loss: 0.00001441
Iteration 9/1000 | Loss: 0.00001439
Iteration 10/1000 | Loss: 0.00001439
Iteration 11/1000 | Loss: 0.00001418
Iteration 12/1000 | Loss: 0.00001417
Iteration 13/1000 | Loss: 0.00001402
Iteration 14/1000 | Loss: 0.00001399
Iteration 15/1000 | Loss: 0.00001399
Iteration 16/1000 | Loss: 0.00001395
Iteration 17/1000 | Loss: 0.00001394
Iteration 18/1000 | Loss: 0.00001389
Iteration 19/1000 | Loss: 0.00001385
Iteration 20/1000 | Loss: 0.00001384
Iteration 21/1000 | Loss: 0.00001384
Iteration 22/1000 | Loss: 0.00001383
Iteration 23/1000 | Loss: 0.00001380
Iteration 24/1000 | Loss: 0.00001379
Iteration 25/1000 | Loss: 0.00001379
Iteration 26/1000 | Loss: 0.00001379
Iteration 27/1000 | Loss: 0.00001378
Iteration 28/1000 | Loss: 0.00001375
Iteration 29/1000 | Loss: 0.00001374
Iteration 30/1000 | Loss: 0.00001374
Iteration 31/1000 | Loss: 0.00001374
Iteration 32/1000 | Loss: 0.00001374
Iteration 33/1000 | Loss: 0.00001373
Iteration 34/1000 | Loss: 0.00001373
Iteration 35/1000 | Loss: 0.00001372
Iteration 36/1000 | Loss: 0.00001371
Iteration 37/1000 | Loss: 0.00001371
Iteration 38/1000 | Loss: 0.00001369
Iteration 39/1000 | Loss: 0.00001367
Iteration 40/1000 | Loss: 0.00001366
Iteration 41/1000 | Loss: 0.00001366
Iteration 42/1000 | Loss: 0.00001366
Iteration 43/1000 | Loss: 0.00001359
Iteration 44/1000 | Loss: 0.00001358
Iteration 45/1000 | Loss: 0.00001358
Iteration 46/1000 | Loss: 0.00001358
Iteration 47/1000 | Loss: 0.00001357
Iteration 48/1000 | Loss: 0.00001352
Iteration 49/1000 | Loss: 0.00001351
Iteration 50/1000 | Loss: 0.00001351
Iteration 51/1000 | Loss: 0.00001351
Iteration 52/1000 | Loss: 0.00001347
Iteration 53/1000 | Loss: 0.00001347
Iteration 54/1000 | Loss: 0.00001346
Iteration 55/1000 | Loss: 0.00001346
Iteration 56/1000 | Loss: 0.00001346
Iteration 57/1000 | Loss: 0.00001346
Iteration 58/1000 | Loss: 0.00001346
Iteration 59/1000 | Loss: 0.00001346
Iteration 60/1000 | Loss: 0.00001346
Iteration 61/1000 | Loss: 0.00001346
Iteration 62/1000 | Loss: 0.00001346
Iteration 63/1000 | Loss: 0.00001346
Iteration 64/1000 | Loss: 0.00001346
Iteration 65/1000 | Loss: 0.00001346
Iteration 66/1000 | Loss: 0.00001346
Iteration 67/1000 | Loss: 0.00001346
Iteration 68/1000 | Loss: 0.00001346
Iteration 69/1000 | Loss: 0.00001345
Iteration 70/1000 | Loss: 0.00001345
Iteration 71/1000 | Loss: 0.00001345
Iteration 72/1000 | Loss: 0.00001345
Iteration 73/1000 | Loss: 0.00001344
Iteration 74/1000 | Loss: 0.00001344
Iteration 75/1000 | Loss: 0.00001344
Iteration 76/1000 | Loss: 0.00001344
Iteration 77/1000 | Loss: 0.00001344
Iteration 78/1000 | Loss: 0.00001344
Iteration 79/1000 | Loss: 0.00001344
Iteration 80/1000 | Loss: 0.00001343
Iteration 81/1000 | Loss: 0.00001343
Iteration 82/1000 | Loss: 0.00001343
Iteration 83/1000 | Loss: 0.00001343
Iteration 84/1000 | Loss: 0.00001343
Iteration 85/1000 | Loss: 0.00001343
Iteration 86/1000 | Loss: 0.00001343
Iteration 87/1000 | Loss: 0.00001343
Iteration 88/1000 | Loss: 0.00001343
Iteration 89/1000 | Loss: 0.00001343
Iteration 90/1000 | Loss: 0.00001343
Iteration 91/1000 | Loss: 0.00001343
Iteration 92/1000 | Loss: 0.00001342
Iteration 93/1000 | Loss: 0.00001342
Iteration 94/1000 | Loss: 0.00001342
Iteration 95/1000 | Loss: 0.00001341
Iteration 96/1000 | Loss: 0.00001341
Iteration 97/1000 | Loss: 0.00001341
Iteration 98/1000 | Loss: 0.00001341
Iteration 99/1000 | Loss: 0.00001341
Iteration 100/1000 | Loss: 0.00001341
Iteration 101/1000 | Loss: 0.00001341
Iteration 102/1000 | Loss: 0.00001341
Iteration 103/1000 | Loss: 0.00001341
Iteration 104/1000 | Loss: 0.00001341
Iteration 105/1000 | Loss: 0.00001341
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 105. Stopping optimization.
Last 5 losses: [1.3406050129560754e-05, 1.3406050129560754e-05, 1.3406050129560754e-05, 1.3406050129560754e-05, 1.3406050129560754e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3406050129560754e-05

Optimization complete. Final v2v error: 3.119230031967163 mm

Highest mean error: 3.3615031242370605 mm for frame 90

Lowest mean error: 2.96557879447937 mm for frame 32

Saving results

Total time: 37.79111838340759
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1046
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01029643
Iteration 2/25 | Loss: 0.01029643
Iteration 3/25 | Loss: 0.00281594
Iteration 4/25 | Loss: 0.00179667
Iteration 5/25 | Loss: 0.00149902
Iteration 6/25 | Loss: 0.00165019
Iteration 7/25 | Loss: 0.00132969
Iteration 8/25 | Loss: 0.00108469
Iteration 9/25 | Loss: 0.00099649
Iteration 10/25 | Loss: 0.00095359
Iteration 11/25 | Loss: 0.00096069
Iteration 12/25 | Loss: 0.00092928
Iteration 13/25 | Loss: 0.00089239
Iteration 14/25 | Loss: 0.00087887
Iteration 15/25 | Loss: 0.00088130
Iteration 16/25 | Loss: 0.00087112
Iteration 17/25 | Loss: 0.00086116
Iteration 18/25 | Loss: 0.00086176
Iteration 19/25 | Loss: 0.00085673
Iteration 20/25 | Loss: 0.00085602
Iteration 21/25 | Loss: 0.00085420
Iteration 22/25 | Loss: 0.00085574
Iteration 23/25 | Loss: 0.00085413
Iteration 24/25 | Loss: 0.00085516
Iteration 25/25 | Loss: 0.00085437

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50581717
Iteration 2/25 | Loss: 0.00097227
Iteration 3/25 | Loss: 0.00068700
Iteration 4/25 | Loss: 0.00068700
Iteration 5/25 | Loss: 0.00068700
Iteration 6/25 | Loss: 0.00068700
Iteration 7/25 | Loss: 0.00068700
Iteration 8/25 | Loss: 0.00068700
Iteration 9/25 | Loss: 0.00068700
Iteration 10/25 | Loss: 0.00068700
Iteration 11/25 | Loss: 0.00068700
Iteration 12/25 | Loss: 0.00068700
Iteration 13/25 | Loss: 0.00068700
Iteration 14/25 | Loss: 0.00068700
Iteration 15/25 | Loss: 0.00068700
Iteration 16/25 | Loss: 0.00068700
Iteration 17/25 | Loss: 0.00068700
Iteration 18/25 | Loss: 0.00068700
Iteration 19/25 | Loss: 0.00068700
Iteration 20/25 | Loss: 0.00068700
Iteration 21/25 | Loss: 0.00068700
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0006869978969916701, 0.0006869978969916701, 0.0006869978969916701, 0.0006869978969916701, 0.0006869978969916701]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006869978969916701

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00068700
Iteration 2/1000 | Loss: 0.00049583
Iteration 3/1000 | Loss: 0.00042964
Iteration 4/1000 | Loss: 0.00032023
Iteration 5/1000 | Loss: 0.00015891
Iteration 6/1000 | Loss: 0.00022935
Iteration 7/1000 | Loss: 0.00019258
Iteration 8/1000 | Loss: 0.00021172
Iteration 9/1000 | Loss: 0.00018871
Iteration 10/1000 | Loss: 0.00017312
Iteration 11/1000 | Loss: 0.00033941
Iteration 12/1000 | Loss: 0.00032642
Iteration 13/1000 | Loss: 0.00023314
Iteration 14/1000 | Loss: 0.00029396
Iteration 15/1000 | Loss: 0.00023014
Iteration 16/1000 | Loss: 0.00020694
Iteration 17/1000 | Loss: 0.00013257
Iteration 18/1000 | Loss: 0.00034592
Iteration 19/1000 | Loss: 0.00030313
Iteration 20/1000 | Loss: 0.00029804
Iteration 21/1000 | Loss: 0.00017941
Iteration 22/1000 | Loss: 0.00020851
Iteration 23/1000 | Loss: 0.00033534
Iteration 24/1000 | Loss: 0.00024669
Iteration 25/1000 | Loss: 0.00031586
Iteration 26/1000 | Loss: 0.00022984
Iteration 27/1000 | Loss: 0.00029171
Iteration 28/1000 | Loss: 0.00009178
Iteration 29/1000 | Loss: 0.00026688
Iteration 30/1000 | Loss: 0.00022951
Iteration 31/1000 | Loss: 0.00031015
Iteration 32/1000 | Loss: 0.00006408
Iteration 33/1000 | Loss: 0.00010649
Iteration 34/1000 | Loss: 0.00015484
Iteration 35/1000 | Loss: 0.00014085
Iteration 36/1000 | Loss: 0.00016244
Iteration 37/1000 | Loss: 0.00025306
Iteration 38/1000 | Loss: 0.00014763
Iteration 39/1000 | Loss: 0.00017796
Iteration 40/1000 | Loss: 0.00013682
Iteration 41/1000 | Loss: 0.00019576
Iteration 42/1000 | Loss: 0.00027270
Iteration 43/1000 | Loss: 0.00038874
Iteration 44/1000 | Loss: 0.00042014
Iteration 45/1000 | Loss: 0.00048693
Iteration 46/1000 | Loss: 0.00086571
Iteration 47/1000 | Loss: 0.00017223
Iteration 48/1000 | Loss: 0.00013134
Iteration 49/1000 | Loss: 0.00018779
Iteration 50/1000 | Loss: 0.00030686
Iteration 51/1000 | Loss: 0.00018765
Iteration 52/1000 | Loss: 0.00019050
Iteration 53/1000 | Loss: 0.00009739
Iteration 54/1000 | Loss: 0.00047448
Iteration 55/1000 | Loss: 0.00045155
Iteration 56/1000 | Loss: 0.00052388
Iteration 57/1000 | Loss: 0.00017659
Iteration 58/1000 | Loss: 0.00057265
Iteration 59/1000 | Loss: 0.00039386
Iteration 60/1000 | Loss: 0.00044713
Iteration 61/1000 | Loss: 0.00046192
Iteration 62/1000 | Loss: 0.00047035
Iteration 63/1000 | Loss: 0.00040884
Iteration 64/1000 | Loss: 0.00045727
Iteration 65/1000 | Loss: 0.00042173
Iteration 66/1000 | Loss: 0.00050418
Iteration 67/1000 | Loss: 0.00066441
Iteration 68/1000 | Loss: 0.00023635
Iteration 69/1000 | Loss: 0.00054029
Iteration 70/1000 | Loss: 0.00054335
Iteration 71/1000 | Loss: 0.00039547
Iteration 72/1000 | Loss: 0.00040104
Iteration 73/1000 | Loss: 0.00042278
Iteration 74/1000 | Loss: 0.00009280
Iteration 75/1000 | Loss: 0.00083625
Iteration 76/1000 | Loss: 0.00096572
Iteration 77/1000 | Loss: 0.00020033
Iteration 78/1000 | Loss: 0.00017651
Iteration 79/1000 | Loss: 0.00024392
Iteration 80/1000 | Loss: 0.00039769
Iteration 81/1000 | Loss: 0.00050147
Iteration 82/1000 | Loss: 0.00045764
Iteration 83/1000 | Loss: 0.00048309
Iteration 84/1000 | Loss: 0.00057006
Iteration 85/1000 | Loss: 0.00018885
Iteration 86/1000 | Loss: 0.00044637
Iteration 87/1000 | Loss: 0.00054723
Iteration 88/1000 | Loss: 0.00046741
Iteration 89/1000 | Loss: 0.00042975
Iteration 90/1000 | Loss: 0.00052244
Iteration 91/1000 | Loss: 0.00051626
Iteration 92/1000 | Loss: 0.00032656
Iteration 93/1000 | Loss: 0.00033020
Iteration 94/1000 | Loss: 0.00034179
Iteration 95/1000 | Loss: 0.00059580
Iteration 96/1000 | Loss: 0.00030838
Iteration 97/1000 | Loss: 0.00008621
Iteration 98/1000 | Loss: 0.00031087
Iteration 99/1000 | Loss: 0.00023293
Iteration 100/1000 | Loss: 0.00037863
Iteration 101/1000 | Loss: 0.00045751
Iteration 102/1000 | Loss: 0.00045237
Iteration 103/1000 | Loss: 0.00041397
Iteration 104/1000 | Loss: 0.00019720
Iteration 105/1000 | Loss: 0.00062209
Iteration 106/1000 | Loss: 0.00040825
Iteration 107/1000 | Loss: 0.00018342
Iteration 108/1000 | Loss: 0.00031199
Iteration 109/1000 | Loss: 0.00044735
Iteration 110/1000 | Loss: 0.00036074
Iteration 111/1000 | Loss: 0.00021458
Iteration 112/1000 | Loss: 0.00046733
Iteration 113/1000 | Loss: 0.00043409
Iteration 114/1000 | Loss: 0.00079271
Iteration 115/1000 | Loss: 0.00043561
Iteration 116/1000 | Loss: 0.00024733
Iteration 117/1000 | Loss: 0.00017980
Iteration 118/1000 | Loss: 0.00042293
Iteration 119/1000 | Loss: 0.00046573
Iteration 120/1000 | Loss: 0.00072750
Iteration 121/1000 | Loss: 0.00052484
Iteration 122/1000 | Loss: 0.00039263
Iteration 123/1000 | Loss: 0.00053481
Iteration 124/1000 | Loss: 0.00070850
Iteration 125/1000 | Loss: 0.00047709
Iteration 126/1000 | Loss: 0.00035909
Iteration 127/1000 | Loss: 0.00023262
Iteration 128/1000 | Loss: 0.00033315
Iteration 129/1000 | Loss: 0.00042205
Iteration 130/1000 | Loss: 0.00058616
Iteration 131/1000 | Loss: 0.00042654
Iteration 132/1000 | Loss: 0.00062440
Iteration 133/1000 | Loss: 0.00017430
Iteration 134/1000 | Loss: 0.00015087
Iteration 135/1000 | Loss: 0.00047914
Iteration 136/1000 | Loss: 0.00091738
Iteration 137/1000 | Loss: 0.00103579
Iteration 138/1000 | Loss: 0.00073215
Iteration 139/1000 | Loss: 0.00016542
Iteration 140/1000 | Loss: 0.00032310
Iteration 141/1000 | Loss: 0.00015676
Iteration 142/1000 | Loss: 0.00062084
Iteration 143/1000 | Loss: 0.00044251
Iteration 144/1000 | Loss: 0.00045260
Iteration 145/1000 | Loss: 0.00007216
Iteration 146/1000 | Loss: 0.00018824
Iteration 147/1000 | Loss: 0.00009019
Iteration 148/1000 | Loss: 0.00026371
Iteration 149/1000 | Loss: 0.00025385
Iteration 150/1000 | Loss: 0.00027438
Iteration 151/1000 | Loss: 0.00026263
Iteration 152/1000 | Loss: 0.00028554
Iteration 153/1000 | Loss: 0.00025164
Iteration 154/1000 | Loss: 0.00026788
Iteration 155/1000 | Loss: 0.00023655
Iteration 156/1000 | Loss: 0.00020266
Iteration 157/1000 | Loss: 0.00012907
Iteration 158/1000 | Loss: 0.00014516
Iteration 159/1000 | Loss: 0.00020753
Iteration 160/1000 | Loss: 0.00014099
Iteration 161/1000 | Loss: 0.00023620
Iteration 162/1000 | Loss: 0.00015696
Iteration 163/1000 | Loss: 0.00005701
Iteration 164/1000 | Loss: 0.00004162
Iteration 165/1000 | Loss: 0.00032323
Iteration 166/1000 | Loss: 0.00045650
Iteration 167/1000 | Loss: 0.00043649
Iteration 168/1000 | Loss: 0.00018229
Iteration 169/1000 | Loss: 0.00013440
Iteration 170/1000 | Loss: 0.00008635
Iteration 171/1000 | Loss: 0.00010819
Iteration 172/1000 | Loss: 0.00005467
Iteration 173/1000 | Loss: 0.00007061
Iteration 174/1000 | Loss: 0.00010082
Iteration 175/1000 | Loss: 0.00010996
Iteration 176/1000 | Loss: 0.00013693
Iteration 177/1000 | Loss: 0.00007584
Iteration 178/1000 | Loss: 0.00010186
Iteration 179/1000 | Loss: 0.00010222
Iteration 180/1000 | Loss: 0.00010487
Iteration 181/1000 | Loss: 0.00010382
Iteration 182/1000 | Loss: 0.00013781
Iteration 183/1000 | Loss: 0.00010381
Iteration 184/1000 | Loss: 0.00010167
Iteration 185/1000 | Loss: 0.00010536
Iteration 186/1000 | Loss: 0.00011095
Iteration 187/1000 | Loss: 0.00119280
Iteration 188/1000 | Loss: 0.00082171
Iteration 189/1000 | Loss: 0.00067063
Iteration 190/1000 | Loss: 0.00070203
Iteration 191/1000 | Loss: 0.00003633
Iteration 192/1000 | Loss: 0.00021832
Iteration 193/1000 | Loss: 0.00005592
Iteration 194/1000 | Loss: 0.00007332
Iteration 195/1000 | Loss: 0.00010145
Iteration 196/1000 | Loss: 0.00004231
Iteration 197/1000 | Loss: 0.00015558
Iteration 198/1000 | Loss: 0.00009176
Iteration 199/1000 | Loss: 0.00014900
Iteration 200/1000 | Loss: 0.00010753
Iteration 201/1000 | Loss: 0.00013625
Iteration 202/1000 | Loss: 0.00013486
Iteration 203/1000 | Loss: 0.00019334
Iteration 204/1000 | Loss: 0.00012380
Iteration 205/1000 | Loss: 0.00012452
Iteration 206/1000 | Loss: 0.00018130
Iteration 207/1000 | Loss: 0.00011708
Iteration 208/1000 | Loss: 0.00006309
Iteration 209/1000 | Loss: 0.00011805
Iteration 210/1000 | Loss: 0.00013591
Iteration 211/1000 | Loss: 0.00008240
Iteration 212/1000 | Loss: 0.00007341
Iteration 213/1000 | Loss: 0.00010050
Iteration 214/1000 | Loss: 0.00006983
Iteration 215/1000 | Loss: 0.00009370
Iteration 216/1000 | Loss: 0.00025561
Iteration 217/1000 | Loss: 0.00022574
Iteration 218/1000 | Loss: 0.00033221
Iteration 219/1000 | Loss: 0.00012923
Iteration 220/1000 | Loss: 0.00016807
Iteration 221/1000 | Loss: 0.00008386
Iteration 222/1000 | Loss: 0.00012909
Iteration 223/1000 | Loss: 0.00009390
Iteration 224/1000 | Loss: 0.00005874
Iteration 225/1000 | Loss: 0.00005334
Iteration 226/1000 | Loss: 0.00011846
Iteration 227/1000 | Loss: 0.00008295
Iteration 228/1000 | Loss: 0.00036132
Iteration 229/1000 | Loss: 0.00072653
Iteration 230/1000 | Loss: 0.00053267
Iteration 231/1000 | Loss: 0.00053177
Iteration 232/1000 | Loss: 0.00060939
Iteration 233/1000 | Loss: 0.00070181
Iteration 234/1000 | Loss: 0.00027908
Iteration 235/1000 | Loss: 0.00008196
Iteration 236/1000 | Loss: 0.00003378
Iteration 237/1000 | Loss: 0.00008254
Iteration 238/1000 | Loss: 0.00002821
Iteration 239/1000 | Loss: 0.00006840
Iteration 240/1000 | Loss: 0.00003588
Iteration 241/1000 | Loss: 0.00003402
Iteration 242/1000 | Loss: 0.00003999
Iteration 243/1000 | Loss: 0.00003794
Iteration 244/1000 | Loss: 0.00002837
Iteration 245/1000 | Loss: 0.00002566
Iteration 246/1000 | Loss: 0.00006191
Iteration 247/1000 | Loss: 0.00002441
Iteration 248/1000 | Loss: 0.00002401
Iteration 249/1000 | Loss: 0.00002368
Iteration 250/1000 | Loss: 0.00002366
Iteration 251/1000 | Loss: 0.00002363
Iteration 252/1000 | Loss: 0.00002342
Iteration 253/1000 | Loss: 0.00002337
Iteration 254/1000 | Loss: 0.00002331
Iteration 255/1000 | Loss: 0.00002325
Iteration 256/1000 | Loss: 0.00002325
Iteration 257/1000 | Loss: 0.00002322
Iteration 258/1000 | Loss: 0.00002317
Iteration 259/1000 | Loss: 0.00002302
Iteration 260/1000 | Loss: 0.00002300
Iteration 261/1000 | Loss: 0.00002293
Iteration 262/1000 | Loss: 0.00002291
Iteration 263/1000 | Loss: 0.00002291
Iteration 264/1000 | Loss: 0.00002290
Iteration 265/1000 | Loss: 0.00002290
Iteration 266/1000 | Loss: 0.00002289
Iteration 267/1000 | Loss: 0.00002289
Iteration 268/1000 | Loss: 0.00002285
Iteration 269/1000 | Loss: 0.00002284
Iteration 270/1000 | Loss: 0.00002284
Iteration 271/1000 | Loss: 0.00002279
Iteration 272/1000 | Loss: 0.00002278
Iteration 273/1000 | Loss: 0.00002276
Iteration 274/1000 | Loss: 0.00002271
Iteration 275/1000 | Loss: 0.00002268
Iteration 276/1000 | Loss: 0.00002267
Iteration 277/1000 | Loss: 0.00002263
Iteration 278/1000 | Loss: 0.00002252
Iteration 279/1000 | Loss: 0.00002252
Iteration 280/1000 | Loss: 0.00002251
Iteration 281/1000 | Loss: 0.00002251
Iteration 282/1000 | Loss: 0.00002251
Iteration 283/1000 | Loss: 0.00002251
Iteration 284/1000 | Loss: 0.00002251
Iteration 285/1000 | Loss: 0.00002251
Iteration 286/1000 | Loss: 0.00002250
Iteration 287/1000 | Loss: 0.00002250
Iteration 288/1000 | Loss: 0.00002250
Iteration 289/1000 | Loss: 0.00002249
Iteration 290/1000 | Loss: 0.00002249
Iteration 291/1000 | Loss: 0.00002248
Iteration 292/1000 | Loss: 0.00002248
Iteration 293/1000 | Loss: 0.00002248
Iteration 294/1000 | Loss: 0.00002247
Iteration 295/1000 | Loss: 0.00002247
Iteration 296/1000 | Loss: 0.00002246
Iteration 297/1000 | Loss: 0.00002246
Iteration 298/1000 | Loss: 0.00002246
Iteration 299/1000 | Loss: 0.00002246
Iteration 300/1000 | Loss: 0.00002246
Iteration 301/1000 | Loss: 0.00002246
Iteration 302/1000 | Loss: 0.00002246
Iteration 303/1000 | Loss: 0.00002246
Iteration 304/1000 | Loss: 0.00002246
Iteration 305/1000 | Loss: 0.00002246
Iteration 306/1000 | Loss: 0.00002245
Iteration 307/1000 | Loss: 0.00002245
Iteration 308/1000 | Loss: 0.00018496
Iteration 309/1000 | Loss: 0.00005243
Iteration 310/1000 | Loss: 0.00037512
Iteration 311/1000 | Loss: 0.00016117
Iteration 312/1000 | Loss: 0.00003974
Iteration 313/1000 | Loss: 0.00002646
Iteration 314/1000 | Loss: 0.00002497
Iteration 315/1000 | Loss: 0.00002401
Iteration 316/1000 | Loss: 0.00002315
Iteration 317/1000 | Loss: 0.00002270
Iteration 318/1000 | Loss: 0.00002238
Iteration 319/1000 | Loss: 0.00021774
Iteration 320/1000 | Loss: 0.00008304
Iteration 321/1000 | Loss: 0.00002241
Iteration 322/1000 | Loss: 0.00020981
Iteration 323/1000 | Loss: 0.00002442
Iteration 324/1000 | Loss: 0.00002201
Iteration 325/1000 | Loss: 0.00002165
Iteration 326/1000 | Loss: 0.00002144
Iteration 327/1000 | Loss: 0.00002143
Iteration 328/1000 | Loss: 0.00002141
Iteration 329/1000 | Loss: 0.00002138
Iteration 330/1000 | Loss: 0.00002121
Iteration 331/1000 | Loss: 0.00002106
Iteration 332/1000 | Loss: 0.00002100
Iteration 333/1000 | Loss: 0.00002097
Iteration 334/1000 | Loss: 0.00002097
Iteration 335/1000 | Loss: 0.00002093
Iteration 336/1000 | Loss: 0.00002092
Iteration 337/1000 | Loss: 0.00002092
Iteration 338/1000 | Loss: 0.00002091
Iteration 339/1000 | Loss: 0.00002085
Iteration 340/1000 | Loss: 0.00002084
Iteration 341/1000 | Loss: 0.00002083
Iteration 342/1000 | Loss: 0.00002083
Iteration 343/1000 | Loss: 0.00002080
Iteration 344/1000 | Loss: 0.00002079
Iteration 345/1000 | Loss: 0.00002078
Iteration 346/1000 | Loss: 0.00002078
Iteration 347/1000 | Loss: 0.00002077
Iteration 348/1000 | Loss: 0.00002076
Iteration 349/1000 | Loss: 0.00002076
Iteration 350/1000 | Loss: 0.00002073
Iteration 351/1000 | Loss: 0.00002073
Iteration 352/1000 | Loss: 0.00002072
Iteration 353/1000 | Loss: 0.00002072
Iteration 354/1000 | Loss: 0.00002072
Iteration 355/1000 | Loss: 0.00002072
Iteration 356/1000 | Loss: 0.00002072
Iteration 357/1000 | Loss: 0.00002072
Iteration 358/1000 | Loss: 0.00002071
Iteration 359/1000 | Loss: 0.00002071
Iteration 360/1000 | Loss: 0.00002071
Iteration 361/1000 | Loss: 0.00002071
Iteration 362/1000 | Loss: 0.00002071
Iteration 363/1000 | Loss: 0.00002070
Iteration 364/1000 | Loss: 0.00002070
Iteration 365/1000 | Loss: 0.00002070
Iteration 366/1000 | Loss: 0.00002070
Iteration 367/1000 | Loss: 0.00002069
Iteration 368/1000 | Loss: 0.00002069
Iteration 369/1000 | Loss: 0.00002069
Iteration 370/1000 | Loss: 0.00002068
Iteration 371/1000 | Loss: 0.00002068
Iteration 372/1000 | Loss: 0.00002068
Iteration 373/1000 | Loss: 0.00002067
Iteration 374/1000 | Loss: 0.00002067
Iteration 375/1000 | Loss: 0.00002067
Iteration 376/1000 | Loss: 0.00002066
Iteration 377/1000 | Loss: 0.00002066
Iteration 378/1000 | Loss: 0.00002066
Iteration 379/1000 | Loss: 0.00002066
Iteration 380/1000 | Loss: 0.00002066
Iteration 381/1000 | Loss: 0.00002065
Iteration 382/1000 | Loss: 0.00002065
Iteration 383/1000 | Loss: 0.00002065
Iteration 384/1000 | Loss: 0.00002065
Iteration 385/1000 | Loss: 0.00002064
Iteration 386/1000 | Loss: 0.00002064
Iteration 387/1000 | Loss: 0.00002064
Iteration 388/1000 | Loss: 0.00002064
Iteration 389/1000 | Loss: 0.00002063
Iteration 390/1000 | Loss: 0.00002063
Iteration 391/1000 | Loss: 0.00002063
Iteration 392/1000 | Loss: 0.00002063
Iteration 393/1000 | Loss: 0.00002063
Iteration 394/1000 | Loss: 0.00002063
Iteration 395/1000 | Loss: 0.00002063
Iteration 396/1000 | Loss: 0.00002063
Iteration 397/1000 | Loss: 0.00002062
Iteration 398/1000 | Loss: 0.00002062
Iteration 399/1000 | Loss: 0.00002062
Iteration 400/1000 | Loss: 0.00002062
Iteration 401/1000 | Loss: 0.00002061
Iteration 402/1000 | Loss: 0.00002061
Iteration 403/1000 | Loss: 0.00002061
Iteration 404/1000 | Loss: 0.00002061
Iteration 405/1000 | Loss: 0.00002060
Iteration 406/1000 | Loss: 0.00002060
Iteration 407/1000 | Loss: 0.00002060
Iteration 408/1000 | Loss: 0.00002060
Iteration 409/1000 | Loss: 0.00002060
Iteration 410/1000 | Loss: 0.00002060
Iteration 411/1000 | Loss: 0.00002060
Iteration 412/1000 | Loss: 0.00002060
Iteration 413/1000 | Loss: 0.00002059
Iteration 414/1000 | Loss: 0.00002059
Iteration 415/1000 | Loss: 0.00002059
Iteration 416/1000 | Loss: 0.00002059
Iteration 417/1000 | Loss: 0.00002059
Iteration 418/1000 | Loss: 0.00002059
Iteration 419/1000 | Loss: 0.00002059
Iteration 420/1000 | Loss: 0.00002059
Iteration 421/1000 | Loss: 0.00002059
Iteration 422/1000 | Loss: 0.00002059
Iteration 423/1000 | Loss: 0.00002059
Iteration 424/1000 | Loss: 0.00002059
Iteration 425/1000 | Loss: 0.00002059
Iteration 426/1000 | Loss: 0.00002059
Iteration 427/1000 | Loss: 0.00002059
Iteration 428/1000 | Loss: 0.00002058
Iteration 429/1000 | Loss: 0.00002058
Iteration 430/1000 | Loss: 0.00002058
Iteration 431/1000 | Loss: 0.00002058
Iteration 432/1000 | Loss: 0.00002058
Iteration 433/1000 | Loss: 0.00002058
Iteration 434/1000 | Loss: 0.00002058
Iteration 435/1000 | Loss: 0.00002058
Iteration 436/1000 | Loss: 0.00002058
Iteration 437/1000 | Loss: 0.00002058
Iteration 438/1000 | Loss: 0.00002058
Iteration 439/1000 | Loss: 0.00002058
Iteration 440/1000 | Loss: 0.00002058
Iteration 441/1000 | Loss: 0.00002058
Iteration 442/1000 | Loss: 0.00002058
Iteration 443/1000 | Loss: 0.00002057
Iteration 444/1000 | Loss: 0.00002057
Iteration 445/1000 | Loss: 0.00002057
Iteration 446/1000 | Loss: 0.00002057
Iteration 447/1000 | Loss: 0.00002057
Iteration 448/1000 | Loss: 0.00002057
Iteration 449/1000 | Loss: 0.00002057
Iteration 450/1000 | Loss: 0.00002057
Iteration 451/1000 | Loss: 0.00002057
Iteration 452/1000 | Loss: 0.00002057
Iteration 453/1000 | Loss: 0.00002057
Iteration 454/1000 | Loss: 0.00002056
Iteration 455/1000 | Loss: 0.00002056
Iteration 456/1000 | Loss: 0.00002056
Iteration 457/1000 | Loss: 0.00002056
Iteration 458/1000 | Loss: 0.00002056
Iteration 459/1000 | Loss: 0.00002056
Iteration 460/1000 | Loss: 0.00002056
Iteration 461/1000 | Loss: 0.00002056
Iteration 462/1000 | Loss: 0.00002056
Iteration 463/1000 | Loss: 0.00002056
Iteration 464/1000 | Loss: 0.00002056
Iteration 465/1000 | Loss: 0.00002056
Iteration 466/1000 | Loss: 0.00002056
Iteration 467/1000 | Loss: 0.00002056
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 467. Stopping optimization.
Last 5 losses: [2.0561266865115613e-05, 2.0561266865115613e-05, 2.0561266865115613e-05, 2.0561266865115613e-05, 2.0561266865115613e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0561266865115613e-05

Optimization complete. Final v2v error: 3.608563184738159 mm

Highest mean error: 5.837769508361816 mm for frame 145

Lowest mean error: 3.086247682571411 mm for frame 65

Saving results

Total time: 514.7974016666412
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1087/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1087.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1087
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00842885
Iteration 2/25 | Loss: 0.00122905
Iteration 3/25 | Loss: 0.00092776
Iteration 4/25 | Loss: 0.00088897
Iteration 5/25 | Loss: 0.00088309
Iteration 6/25 | Loss: 0.00088200
Iteration 7/25 | Loss: 0.00088172
Iteration 8/25 | Loss: 0.00088172
Iteration 9/25 | Loss: 0.00088172
Iteration 10/25 | Loss: 0.00088172
Iteration 11/25 | Loss: 0.00088172
Iteration 12/25 | Loss: 0.00088172
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008817198104225099, 0.0008817198104225099, 0.0008817198104225099, 0.0008817198104225099, 0.0008817198104225099]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008817198104225099

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.68825221
Iteration 2/25 | Loss: 0.00043383
Iteration 3/25 | Loss: 0.00043378
Iteration 4/25 | Loss: 0.00043378
Iteration 5/25 | Loss: 0.00043378
Iteration 6/25 | Loss: 0.00043378
Iteration 7/25 | Loss: 0.00043378
Iteration 8/25 | Loss: 0.00043378
Iteration 9/25 | Loss: 0.00043378
Iteration 10/25 | Loss: 0.00043378
Iteration 11/25 | Loss: 0.00043378
Iteration 12/25 | Loss: 0.00043378
Iteration 13/25 | Loss: 0.00043378
Iteration 14/25 | Loss: 0.00043378
Iteration 15/25 | Loss: 0.00043378
Iteration 16/25 | Loss: 0.00043378
Iteration 17/25 | Loss: 0.00043378
Iteration 18/25 | Loss: 0.00043378
Iteration 19/25 | Loss: 0.00043378
Iteration 20/25 | Loss: 0.00043378
Iteration 21/25 | Loss: 0.00043378
Iteration 22/25 | Loss: 0.00043378
Iteration 23/25 | Loss: 0.00043378
Iteration 24/25 | Loss: 0.00043378
Iteration 25/25 | Loss: 0.00043378

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043378
Iteration 2/1000 | Loss: 0.00008236
Iteration 3/1000 | Loss: 0.00005234
Iteration 4/1000 | Loss: 0.00004100
Iteration 5/1000 | Loss: 0.00003656
Iteration 6/1000 | Loss: 0.00003470
Iteration 7/1000 | Loss: 0.00003327
Iteration 8/1000 | Loss: 0.00003219
Iteration 9/1000 | Loss: 0.00003159
Iteration 10/1000 | Loss: 0.00003095
Iteration 11/1000 | Loss: 0.00003049
Iteration 12/1000 | Loss: 0.00003008
Iteration 13/1000 | Loss: 0.00002966
Iteration 14/1000 | Loss: 0.00002930
Iteration 15/1000 | Loss: 0.00002902
Iteration 16/1000 | Loss: 0.00002882
Iteration 17/1000 | Loss: 0.00002860
Iteration 18/1000 | Loss: 0.00002848
Iteration 19/1000 | Loss: 0.00002844
Iteration 20/1000 | Loss: 0.00002828
Iteration 21/1000 | Loss: 0.00002826
Iteration 22/1000 | Loss: 0.00002818
Iteration 23/1000 | Loss: 0.00002818
Iteration 24/1000 | Loss: 0.00002816
Iteration 25/1000 | Loss: 0.00002815
Iteration 26/1000 | Loss: 0.00002814
Iteration 27/1000 | Loss: 0.00002814
Iteration 28/1000 | Loss: 0.00002814
Iteration 29/1000 | Loss: 0.00002813
Iteration 30/1000 | Loss: 0.00002813
Iteration 31/1000 | Loss: 0.00002813
Iteration 32/1000 | Loss: 0.00002812
Iteration 33/1000 | Loss: 0.00002812
Iteration 34/1000 | Loss: 0.00002812
Iteration 35/1000 | Loss: 0.00002811
Iteration 36/1000 | Loss: 0.00002810
Iteration 37/1000 | Loss: 0.00002810
Iteration 38/1000 | Loss: 0.00002810
Iteration 39/1000 | Loss: 0.00002809
Iteration 40/1000 | Loss: 0.00002809
Iteration 41/1000 | Loss: 0.00002809
Iteration 42/1000 | Loss: 0.00002808
Iteration 43/1000 | Loss: 0.00002808
Iteration 44/1000 | Loss: 0.00002808
Iteration 45/1000 | Loss: 0.00002808
Iteration 46/1000 | Loss: 0.00002807
Iteration 47/1000 | Loss: 0.00002807
Iteration 48/1000 | Loss: 0.00002807
Iteration 49/1000 | Loss: 0.00002806
Iteration 50/1000 | Loss: 0.00002805
Iteration 51/1000 | Loss: 0.00002805
Iteration 52/1000 | Loss: 0.00002805
Iteration 53/1000 | Loss: 0.00002805
Iteration 54/1000 | Loss: 0.00002804
Iteration 55/1000 | Loss: 0.00002804
Iteration 56/1000 | Loss: 0.00002804
Iteration 57/1000 | Loss: 0.00002804
Iteration 58/1000 | Loss: 0.00002804
Iteration 59/1000 | Loss: 0.00002804
Iteration 60/1000 | Loss: 0.00002803
Iteration 61/1000 | Loss: 0.00002803
Iteration 62/1000 | Loss: 0.00002803
Iteration 63/1000 | Loss: 0.00002802
Iteration 64/1000 | Loss: 0.00002802
Iteration 65/1000 | Loss: 0.00002802
Iteration 66/1000 | Loss: 0.00002802
Iteration 67/1000 | Loss: 0.00002802
Iteration 68/1000 | Loss: 0.00002802
Iteration 69/1000 | Loss: 0.00002802
Iteration 70/1000 | Loss: 0.00002802
Iteration 71/1000 | Loss: 0.00002802
Iteration 72/1000 | Loss: 0.00002802
Iteration 73/1000 | Loss: 0.00002801
Iteration 74/1000 | Loss: 0.00002801
Iteration 75/1000 | Loss: 0.00002801
Iteration 76/1000 | Loss: 0.00002801
Iteration 77/1000 | Loss: 0.00002800
Iteration 78/1000 | Loss: 0.00002800
Iteration 79/1000 | Loss: 0.00002800
Iteration 80/1000 | Loss: 0.00002800
Iteration 81/1000 | Loss: 0.00002800
Iteration 82/1000 | Loss: 0.00002800
Iteration 83/1000 | Loss: 0.00002800
Iteration 84/1000 | Loss: 0.00002799
Iteration 85/1000 | Loss: 0.00002799
Iteration 86/1000 | Loss: 0.00002799
Iteration 87/1000 | Loss: 0.00002799
Iteration 88/1000 | Loss: 0.00002799
Iteration 89/1000 | Loss: 0.00002798
Iteration 90/1000 | Loss: 0.00002798
Iteration 91/1000 | Loss: 0.00002798
Iteration 92/1000 | Loss: 0.00002798
Iteration 93/1000 | Loss: 0.00002797
Iteration 94/1000 | Loss: 0.00002797
Iteration 95/1000 | Loss: 0.00002797
Iteration 96/1000 | Loss: 0.00002797
Iteration 97/1000 | Loss: 0.00002797
Iteration 98/1000 | Loss: 0.00002797
Iteration 99/1000 | Loss: 0.00002797
Iteration 100/1000 | Loss: 0.00002797
Iteration 101/1000 | Loss: 0.00002797
Iteration 102/1000 | Loss: 0.00002797
Iteration 103/1000 | Loss: 0.00002797
Iteration 104/1000 | Loss: 0.00002797
Iteration 105/1000 | Loss: 0.00002796
Iteration 106/1000 | Loss: 0.00002796
Iteration 107/1000 | Loss: 0.00002796
Iteration 108/1000 | Loss: 0.00002796
Iteration 109/1000 | Loss: 0.00002796
Iteration 110/1000 | Loss: 0.00002796
Iteration 111/1000 | Loss: 0.00002796
Iteration 112/1000 | Loss: 0.00002796
Iteration 113/1000 | Loss: 0.00002795
Iteration 114/1000 | Loss: 0.00002795
Iteration 115/1000 | Loss: 0.00002795
Iteration 116/1000 | Loss: 0.00002795
Iteration 117/1000 | Loss: 0.00002795
Iteration 118/1000 | Loss: 0.00002795
Iteration 119/1000 | Loss: 0.00002795
Iteration 120/1000 | Loss: 0.00002795
Iteration 121/1000 | Loss: 0.00002795
Iteration 122/1000 | Loss: 0.00002795
Iteration 123/1000 | Loss: 0.00002795
Iteration 124/1000 | Loss: 0.00002795
Iteration 125/1000 | Loss: 0.00002795
Iteration 126/1000 | Loss: 0.00002795
Iteration 127/1000 | Loss: 0.00002795
Iteration 128/1000 | Loss: 0.00002795
Iteration 129/1000 | Loss: 0.00002795
Iteration 130/1000 | Loss: 0.00002795
Iteration 131/1000 | Loss: 0.00002795
Iteration 132/1000 | Loss: 0.00002795
Iteration 133/1000 | Loss: 0.00002795
Iteration 134/1000 | Loss: 0.00002795
Iteration 135/1000 | Loss: 0.00002795
Iteration 136/1000 | Loss: 0.00002795
Iteration 137/1000 | Loss: 0.00002795
Iteration 138/1000 | Loss: 0.00002795
Iteration 139/1000 | Loss: 0.00002795
Iteration 140/1000 | Loss: 0.00002795
Iteration 141/1000 | Loss: 0.00002795
Iteration 142/1000 | Loss: 0.00002795
Iteration 143/1000 | Loss: 0.00002795
Iteration 144/1000 | Loss: 0.00002795
Iteration 145/1000 | Loss: 0.00002795
Iteration 146/1000 | Loss: 0.00002795
Iteration 147/1000 | Loss: 0.00002795
Iteration 148/1000 | Loss: 0.00002795
Iteration 149/1000 | Loss: 0.00002795
Iteration 150/1000 | Loss: 0.00002795
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [2.794684587570373e-05, 2.794684587570373e-05, 2.794684587570373e-05, 2.794684587570373e-05, 2.794684587570373e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.794684587570373e-05

Optimization complete. Final v2v error: 4.179281234741211 mm

Highest mean error: 6.021933078765869 mm for frame 163

Lowest mean error: 2.9018938541412354 mm for frame 56

Saving results

Total time: 48.06148386001587
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1035/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1035.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1035
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00388207
Iteration 2/25 | Loss: 0.00091795
Iteration 3/25 | Loss: 0.00073409
Iteration 4/25 | Loss: 0.00070971
Iteration 5/25 | Loss: 0.00070204
Iteration 6/25 | Loss: 0.00069947
Iteration 7/25 | Loss: 0.00069862
Iteration 8/25 | Loss: 0.00069855
Iteration 9/25 | Loss: 0.00069855
Iteration 10/25 | Loss: 0.00069855
Iteration 11/25 | Loss: 0.00069855
Iteration 12/25 | Loss: 0.00069855
Iteration 13/25 | Loss: 0.00069855
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006985535728745162, 0.0006985535728745162, 0.0006985535728745162, 0.0006985535728745162, 0.0006985535728745162]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006985535728745162

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46351683
Iteration 2/25 | Loss: 0.00026996
Iteration 3/25 | Loss: 0.00026995
Iteration 4/25 | Loss: 0.00026995
Iteration 5/25 | Loss: 0.00026995
Iteration 6/25 | Loss: 0.00026995
Iteration 7/25 | Loss: 0.00026995
Iteration 8/25 | Loss: 0.00026995
Iteration 9/25 | Loss: 0.00026995
Iteration 10/25 | Loss: 0.00026995
Iteration 11/25 | Loss: 0.00026995
Iteration 12/25 | Loss: 0.00026995
Iteration 13/25 | Loss: 0.00026995
Iteration 14/25 | Loss: 0.00026995
Iteration 15/25 | Loss: 0.00026995
Iteration 16/25 | Loss: 0.00026995
Iteration 17/25 | Loss: 0.00026995
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00026994996005669236, 0.00026994996005669236, 0.00026994996005669236, 0.00026994996005669236, 0.00026994996005669236]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00026994996005669236

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026995
Iteration 2/1000 | Loss: 0.00002323
Iteration 3/1000 | Loss: 0.00001822
Iteration 4/1000 | Loss: 0.00001654
Iteration 5/1000 | Loss: 0.00001541
Iteration 6/1000 | Loss: 0.00001466
Iteration 7/1000 | Loss: 0.00001416
Iteration 8/1000 | Loss: 0.00001394
Iteration 9/1000 | Loss: 0.00001380
Iteration 10/1000 | Loss: 0.00001361
Iteration 11/1000 | Loss: 0.00001352
Iteration 12/1000 | Loss: 0.00001350
Iteration 13/1000 | Loss: 0.00001345
Iteration 14/1000 | Loss: 0.00001344
Iteration 15/1000 | Loss: 0.00001344
Iteration 16/1000 | Loss: 0.00001342
Iteration 17/1000 | Loss: 0.00001342
Iteration 18/1000 | Loss: 0.00001337
Iteration 19/1000 | Loss: 0.00001337
Iteration 20/1000 | Loss: 0.00001336
Iteration 21/1000 | Loss: 0.00001335
Iteration 22/1000 | Loss: 0.00001334
Iteration 23/1000 | Loss: 0.00001330
Iteration 24/1000 | Loss: 0.00001330
Iteration 25/1000 | Loss: 0.00001329
Iteration 26/1000 | Loss: 0.00001328
Iteration 27/1000 | Loss: 0.00001328
Iteration 28/1000 | Loss: 0.00001328
Iteration 29/1000 | Loss: 0.00001327
Iteration 30/1000 | Loss: 0.00001327
Iteration 31/1000 | Loss: 0.00001326
Iteration 32/1000 | Loss: 0.00001326
Iteration 33/1000 | Loss: 0.00001325
Iteration 34/1000 | Loss: 0.00001325
Iteration 35/1000 | Loss: 0.00001325
Iteration 36/1000 | Loss: 0.00001325
Iteration 37/1000 | Loss: 0.00001325
Iteration 38/1000 | Loss: 0.00001324
Iteration 39/1000 | Loss: 0.00001324
Iteration 40/1000 | Loss: 0.00001324
Iteration 41/1000 | Loss: 0.00001324
Iteration 42/1000 | Loss: 0.00001324
Iteration 43/1000 | Loss: 0.00001324
Iteration 44/1000 | Loss: 0.00001323
Iteration 45/1000 | Loss: 0.00001323
Iteration 46/1000 | Loss: 0.00001323
Iteration 47/1000 | Loss: 0.00001323
Iteration 48/1000 | Loss: 0.00001322
Iteration 49/1000 | Loss: 0.00001322
Iteration 50/1000 | Loss: 0.00001322
Iteration 51/1000 | Loss: 0.00001321
Iteration 52/1000 | Loss: 0.00001321
Iteration 53/1000 | Loss: 0.00001321
Iteration 54/1000 | Loss: 0.00001320
Iteration 55/1000 | Loss: 0.00001320
Iteration 56/1000 | Loss: 0.00001320
Iteration 57/1000 | Loss: 0.00001319
Iteration 58/1000 | Loss: 0.00001319
Iteration 59/1000 | Loss: 0.00001319
Iteration 60/1000 | Loss: 0.00001318
Iteration 61/1000 | Loss: 0.00001317
Iteration 62/1000 | Loss: 0.00001317
Iteration 63/1000 | Loss: 0.00001317
Iteration 64/1000 | Loss: 0.00001317
Iteration 65/1000 | Loss: 0.00001317
Iteration 66/1000 | Loss: 0.00001316
Iteration 67/1000 | Loss: 0.00001316
Iteration 68/1000 | Loss: 0.00001316
Iteration 69/1000 | Loss: 0.00001316
Iteration 70/1000 | Loss: 0.00001316
Iteration 71/1000 | Loss: 0.00001316
Iteration 72/1000 | Loss: 0.00001316
Iteration 73/1000 | Loss: 0.00001315
Iteration 74/1000 | Loss: 0.00001312
Iteration 75/1000 | Loss: 0.00001312
Iteration 76/1000 | Loss: 0.00001311
Iteration 77/1000 | Loss: 0.00001311
Iteration 78/1000 | Loss: 0.00001311
Iteration 79/1000 | Loss: 0.00001310
Iteration 80/1000 | Loss: 0.00001310
Iteration 81/1000 | Loss: 0.00001310
Iteration 82/1000 | Loss: 0.00001310
Iteration 83/1000 | Loss: 0.00001310
Iteration 84/1000 | Loss: 0.00001309
Iteration 85/1000 | Loss: 0.00001309
Iteration 86/1000 | Loss: 0.00001309
Iteration 87/1000 | Loss: 0.00001309
Iteration 88/1000 | Loss: 0.00001308
Iteration 89/1000 | Loss: 0.00001307
Iteration 90/1000 | Loss: 0.00001307
Iteration 91/1000 | Loss: 0.00001307
Iteration 92/1000 | Loss: 0.00001307
Iteration 93/1000 | Loss: 0.00001307
Iteration 94/1000 | Loss: 0.00001307
Iteration 95/1000 | Loss: 0.00001307
Iteration 96/1000 | Loss: 0.00001306
Iteration 97/1000 | Loss: 0.00001306
Iteration 98/1000 | Loss: 0.00001306
Iteration 99/1000 | Loss: 0.00001306
Iteration 100/1000 | Loss: 0.00001306
Iteration 101/1000 | Loss: 0.00001306
Iteration 102/1000 | Loss: 0.00001306
Iteration 103/1000 | Loss: 0.00001305
Iteration 104/1000 | Loss: 0.00001305
Iteration 105/1000 | Loss: 0.00001305
Iteration 106/1000 | Loss: 0.00001305
Iteration 107/1000 | Loss: 0.00001304
Iteration 108/1000 | Loss: 0.00001304
Iteration 109/1000 | Loss: 0.00001304
Iteration 110/1000 | Loss: 0.00001304
Iteration 111/1000 | Loss: 0.00001304
Iteration 112/1000 | Loss: 0.00001304
Iteration 113/1000 | Loss: 0.00001304
Iteration 114/1000 | Loss: 0.00001304
Iteration 115/1000 | Loss: 0.00001304
Iteration 116/1000 | Loss: 0.00001304
Iteration 117/1000 | Loss: 0.00001304
Iteration 118/1000 | Loss: 0.00001304
Iteration 119/1000 | Loss: 0.00001304
Iteration 120/1000 | Loss: 0.00001304
Iteration 121/1000 | Loss: 0.00001304
Iteration 122/1000 | Loss: 0.00001304
Iteration 123/1000 | Loss: 0.00001304
Iteration 124/1000 | Loss: 0.00001304
Iteration 125/1000 | Loss: 0.00001304
Iteration 126/1000 | Loss: 0.00001304
Iteration 127/1000 | Loss: 0.00001304
Iteration 128/1000 | Loss: 0.00001304
Iteration 129/1000 | Loss: 0.00001304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [1.3044776096649002e-05, 1.3044776096649002e-05, 1.3044776096649002e-05, 1.3044776096649002e-05, 1.3044776096649002e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3044776096649002e-05

Optimization complete. Final v2v error: 3.0565853118896484 mm

Highest mean error: 3.4436190128326416 mm for frame 77

Lowest mean error: 2.8344643115997314 mm for frame 24

Saving results

Total time: 37.397703886032104
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1093/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1093.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1093
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00431450
Iteration 2/25 | Loss: 0.00090862
Iteration 3/25 | Loss: 0.00076491
Iteration 4/25 | Loss: 0.00074396
Iteration 5/25 | Loss: 0.00073630
Iteration 6/25 | Loss: 0.00073430
Iteration 7/25 | Loss: 0.00073367
Iteration 8/25 | Loss: 0.00073362
Iteration 9/25 | Loss: 0.00073362
Iteration 10/25 | Loss: 0.00073362
Iteration 11/25 | Loss: 0.00073362
Iteration 12/25 | Loss: 0.00073362
Iteration 13/25 | Loss: 0.00073362
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007336192647926509, 0.0007336192647926509, 0.0007336192647926509, 0.0007336192647926509, 0.0007336192647926509]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007336192647926509

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.47090340
Iteration 2/25 | Loss: 0.00029993
Iteration 3/25 | Loss: 0.00029991
Iteration 4/25 | Loss: 0.00029991
Iteration 5/25 | Loss: 0.00029991
Iteration 6/25 | Loss: 0.00029991
Iteration 7/25 | Loss: 0.00029991
Iteration 8/25 | Loss: 0.00029991
Iteration 9/25 | Loss: 0.00029991
Iteration 10/25 | Loss: 0.00029990
Iteration 11/25 | Loss: 0.00029990
Iteration 12/25 | Loss: 0.00029990
Iteration 13/25 | Loss: 0.00029990
Iteration 14/25 | Loss: 0.00029990
Iteration 15/25 | Loss: 0.00029990
Iteration 16/25 | Loss: 0.00029990
Iteration 17/25 | Loss: 0.00029990
Iteration 18/25 | Loss: 0.00029990
Iteration 19/25 | Loss: 0.00029990
Iteration 20/25 | Loss: 0.00029990
Iteration 21/25 | Loss: 0.00029990
Iteration 22/25 | Loss: 0.00029990
Iteration 23/25 | Loss: 0.00029990
Iteration 24/25 | Loss: 0.00029990
Iteration 25/25 | Loss: 0.00029990

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029990
Iteration 2/1000 | Loss: 0.00002440
Iteration 3/1000 | Loss: 0.00001919
Iteration 4/1000 | Loss: 0.00001800
Iteration 5/1000 | Loss: 0.00001714
Iteration 6/1000 | Loss: 0.00001663
Iteration 7/1000 | Loss: 0.00001630
Iteration 8/1000 | Loss: 0.00001628
Iteration 9/1000 | Loss: 0.00001627
Iteration 10/1000 | Loss: 0.00001606
Iteration 11/1000 | Loss: 0.00001601
Iteration 12/1000 | Loss: 0.00001596
Iteration 13/1000 | Loss: 0.00001587
Iteration 14/1000 | Loss: 0.00001584
Iteration 15/1000 | Loss: 0.00001583
Iteration 16/1000 | Loss: 0.00001571
Iteration 17/1000 | Loss: 0.00001567
Iteration 18/1000 | Loss: 0.00001564
Iteration 19/1000 | Loss: 0.00001563
Iteration 20/1000 | Loss: 0.00001563
Iteration 21/1000 | Loss: 0.00001562
Iteration 22/1000 | Loss: 0.00001562
Iteration 23/1000 | Loss: 0.00001561
Iteration 24/1000 | Loss: 0.00001560
Iteration 25/1000 | Loss: 0.00001559
Iteration 26/1000 | Loss: 0.00001559
Iteration 27/1000 | Loss: 0.00001559
Iteration 28/1000 | Loss: 0.00001556
Iteration 29/1000 | Loss: 0.00001556
Iteration 30/1000 | Loss: 0.00001555
Iteration 31/1000 | Loss: 0.00001555
Iteration 32/1000 | Loss: 0.00001555
Iteration 33/1000 | Loss: 0.00001554
Iteration 34/1000 | Loss: 0.00001554
Iteration 35/1000 | Loss: 0.00001554
Iteration 36/1000 | Loss: 0.00001554
Iteration 37/1000 | Loss: 0.00001554
Iteration 38/1000 | Loss: 0.00001553
Iteration 39/1000 | Loss: 0.00001553
Iteration 40/1000 | Loss: 0.00001553
Iteration 41/1000 | Loss: 0.00001552
Iteration 42/1000 | Loss: 0.00001552
Iteration 43/1000 | Loss: 0.00001552
Iteration 44/1000 | Loss: 0.00001552
Iteration 45/1000 | Loss: 0.00001551
Iteration 46/1000 | Loss: 0.00001551
Iteration 47/1000 | Loss: 0.00001549
Iteration 48/1000 | Loss: 0.00001549
Iteration 49/1000 | Loss: 0.00001549
Iteration 50/1000 | Loss: 0.00001549
Iteration 51/1000 | Loss: 0.00001549
Iteration 52/1000 | Loss: 0.00001548
Iteration 53/1000 | Loss: 0.00001548
Iteration 54/1000 | Loss: 0.00001547
Iteration 55/1000 | Loss: 0.00001547
Iteration 56/1000 | Loss: 0.00001545
Iteration 57/1000 | Loss: 0.00001545
Iteration 58/1000 | Loss: 0.00001545
Iteration 59/1000 | Loss: 0.00001544
Iteration 60/1000 | Loss: 0.00001544
Iteration 61/1000 | Loss: 0.00001544
Iteration 62/1000 | Loss: 0.00001543
Iteration 63/1000 | Loss: 0.00001543
Iteration 64/1000 | Loss: 0.00001542
Iteration 65/1000 | Loss: 0.00001541
Iteration 66/1000 | Loss: 0.00001541
Iteration 67/1000 | Loss: 0.00001540
Iteration 68/1000 | Loss: 0.00001537
Iteration 69/1000 | Loss: 0.00001536
Iteration 70/1000 | Loss: 0.00001536
Iteration 71/1000 | Loss: 0.00001534
Iteration 72/1000 | Loss: 0.00001534
Iteration 73/1000 | Loss: 0.00001533
Iteration 74/1000 | Loss: 0.00001533
Iteration 75/1000 | Loss: 0.00001533
Iteration 76/1000 | Loss: 0.00001532
Iteration 77/1000 | Loss: 0.00001532
Iteration 78/1000 | Loss: 0.00001531
Iteration 79/1000 | Loss: 0.00001531
Iteration 80/1000 | Loss: 0.00001531
Iteration 81/1000 | Loss: 0.00001530
Iteration 82/1000 | Loss: 0.00001530
Iteration 83/1000 | Loss: 0.00001530
Iteration 84/1000 | Loss: 0.00001530
Iteration 85/1000 | Loss: 0.00001529
Iteration 86/1000 | Loss: 0.00001529
Iteration 87/1000 | Loss: 0.00001529
Iteration 88/1000 | Loss: 0.00001529
Iteration 89/1000 | Loss: 0.00001529
Iteration 90/1000 | Loss: 0.00001529
Iteration 91/1000 | Loss: 0.00001528
Iteration 92/1000 | Loss: 0.00001528
Iteration 93/1000 | Loss: 0.00001528
Iteration 94/1000 | Loss: 0.00001528
Iteration 95/1000 | Loss: 0.00001528
Iteration 96/1000 | Loss: 0.00001528
Iteration 97/1000 | Loss: 0.00001528
Iteration 98/1000 | Loss: 0.00001527
Iteration 99/1000 | Loss: 0.00001527
Iteration 100/1000 | Loss: 0.00001527
Iteration 101/1000 | Loss: 0.00001527
Iteration 102/1000 | Loss: 0.00001527
Iteration 103/1000 | Loss: 0.00001527
Iteration 104/1000 | Loss: 0.00001527
Iteration 105/1000 | Loss: 0.00001527
Iteration 106/1000 | Loss: 0.00001527
Iteration 107/1000 | Loss: 0.00001526
Iteration 108/1000 | Loss: 0.00001526
Iteration 109/1000 | Loss: 0.00001526
Iteration 110/1000 | Loss: 0.00001526
Iteration 111/1000 | Loss: 0.00001526
Iteration 112/1000 | Loss: 0.00001526
Iteration 113/1000 | Loss: 0.00001526
Iteration 114/1000 | Loss: 0.00001526
Iteration 115/1000 | Loss: 0.00001526
Iteration 116/1000 | Loss: 0.00001526
Iteration 117/1000 | Loss: 0.00001525
Iteration 118/1000 | Loss: 0.00001525
Iteration 119/1000 | Loss: 0.00001525
Iteration 120/1000 | Loss: 0.00001525
Iteration 121/1000 | Loss: 0.00001525
Iteration 122/1000 | Loss: 0.00001525
Iteration 123/1000 | Loss: 0.00001525
Iteration 124/1000 | Loss: 0.00001525
Iteration 125/1000 | Loss: 0.00001524
Iteration 126/1000 | Loss: 0.00001524
Iteration 127/1000 | Loss: 0.00001524
Iteration 128/1000 | Loss: 0.00001524
Iteration 129/1000 | Loss: 0.00001524
Iteration 130/1000 | Loss: 0.00001524
Iteration 131/1000 | Loss: 0.00001524
Iteration 132/1000 | Loss: 0.00001524
Iteration 133/1000 | Loss: 0.00001524
Iteration 134/1000 | Loss: 0.00001524
Iteration 135/1000 | Loss: 0.00001524
Iteration 136/1000 | Loss: 0.00001524
Iteration 137/1000 | Loss: 0.00001524
Iteration 138/1000 | Loss: 0.00001524
Iteration 139/1000 | Loss: 0.00001523
Iteration 140/1000 | Loss: 0.00001523
Iteration 141/1000 | Loss: 0.00001523
Iteration 142/1000 | Loss: 0.00001523
Iteration 143/1000 | Loss: 0.00001523
Iteration 144/1000 | Loss: 0.00001523
Iteration 145/1000 | Loss: 0.00001523
Iteration 146/1000 | Loss: 0.00001523
Iteration 147/1000 | Loss: 0.00001523
Iteration 148/1000 | Loss: 0.00001523
Iteration 149/1000 | Loss: 0.00001523
Iteration 150/1000 | Loss: 0.00001523
Iteration 151/1000 | Loss: 0.00001523
Iteration 152/1000 | Loss: 0.00001523
Iteration 153/1000 | Loss: 0.00001523
Iteration 154/1000 | Loss: 0.00001523
Iteration 155/1000 | Loss: 0.00001523
Iteration 156/1000 | Loss: 0.00001523
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.523297032690607e-05, 1.523297032690607e-05, 1.523297032690607e-05, 1.523297032690607e-05, 1.523297032690607e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.523297032690607e-05

Optimization complete. Final v2v error: 3.2834367752075195 mm

Highest mean error: 3.760481595993042 mm for frame 107

Lowest mean error: 3.0787229537963867 mm for frame 61

Saving results

Total time: 39.92000126838684
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1098/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1098.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1098
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00492656
Iteration 2/25 | Loss: 0.00115902
Iteration 3/25 | Loss: 0.00086943
Iteration 4/25 | Loss: 0.00081132
Iteration 5/25 | Loss: 0.00079946
Iteration 6/25 | Loss: 0.00079742
Iteration 7/25 | Loss: 0.00079684
Iteration 8/25 | Loss: 0.00079684
Iteration 9/25 | Loss: 0.00079684
Iteration 10/25 | Loss: 0.00079684
Iteration 11/25 | Loss: 0.00079684
Iteration 12/25 | Loss: 0.00079684
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007968406425788999, 0.0007968406425788999, 0.0007968406425788999, 0.0007968406425788999, 0.0007968406425788999]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007968406425788999

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48288178
Iteration 2/25 | Loss: 0.00034049
Iteration 3/25 | Loss: 0.00034047
Iteration 4/25 | Loss: 0.00034047
Iteration 5/25 | Loss: 0.00034047
Iteration 6/25 | Loss: 0.00034047
Iteration 7/25 | Loss: 0.00034047
Iteration 8/25 | Loss: 0.00034047
Iteration 9/25 | Loss: 0.00034047
Iteration 10/25 | Loss: 0.00034047
Iteration 11/25 | Loss: 0.00034047
Iteration 12/25 | Loss: 0.00034047
Iteration 13/25 | Loss: 0.00034047
Iteration 14/25 | Loss: 0.00034047
Iteration 15/25 | Loss: 0.00034047
Iteration 16/25 | Loss: 0.00034047
Iteration 17/25 | Loss: 0.00034047
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003404698509257287, 0.0003404698509257287, 0.0003404698509257287, 0.0003404698509257287, 0.0003404698509257287]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003404698509257287

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034047
Iteration 2/1000 | Loss: 0.00003757
Iteration 3/1000 | Loss: 0.00002646
Iteration 4/1000 | Loss: 0.00002344
Iteration 5/1000 | Loss: 0.00002181
Iteration 6/1000 | Loss: 0.00001998
Iteration 7/1000 | Loss: 0.00001903
Iteration 8/1000 | Loss: 0.00001829
Iteration 9/1000 | Loss: 0.00001787
Iteration 10/1000 | Loss: 0.00001759
Iteration 11/1000 | Loss: 0.00001745
Iteration 12/1000 | Loss: 0.00001728
Iteration 13/1000 | Loss: 0.00001711
Iteration 14/1000 | Loss: 0.00001703
Iteration 15/1000 | Loss: 0.00001699
Iteration 16/1000 | Loss: 0.00001697
Iteration 17/1000 | Loss: 0.00001697
Iteration 18/1000 | Loss: 0.00001691
Iteration 19/1000 | Loss: 0.00001689
Iteration 20/1000 | Loss: 0.00001688
Iteration 21/1000 | Loss: 0.00001687
Iteration 22/1000 | Loss: 0.00001687
Iteration 23/1000 | Loss: 0.00001686
Iteration 24/1000 | Loss: 0.00001686
Iteration 25/1000 | Loss: 0.00001686
Iteration 26/1000 | Loss: 0.00001685
Iteration 27/1000 | Loss: 0.00001685
Iteration 28/1000 | Loss: 0.00001685
Iteration 29/1000 | Loss: 0.00001684
Iteration 30/1000 | Loss: 0.00001684
Iteration 31/1000 | Loss: 0.00001683
Iteration 32/1000 | Loss: 0.00001683
Iteration 33/1000 | Loss: 0.00001682
Iteration 34/1000 | Loss: 0.00001682
Iteration 35/1000 | Loss: 0.00001682
Iteration 36/1000 | Loss: 0.00001682
Iteration 37/1000 | Loss: 0.00001682
Iteration 38/1000 | Loss: 0.00001682
Iteration 39/1000 | Loss: 0.00001682
Iteration 40/1000 | Loss: 0.00001682
Iteration 41/1000 | Loss: 0.00001682
Iteration 42/1000 | Loss: 0.00001681
Iteration 43/1000 | Loss: 0.00001681
Iteration 44/1000 | Loss: 0.00001681
Iteration 45/1000 | Loss: 0.00001681
Iteration 46/1000 | Loss: 0.00001681
Iteration 47/1000 | Loss: 0.00001681
Iteration 48/1000 | Loss: 0.00001680
Iteration 49/1000 | Loss: 0.00001679
Iteration 50/1000 | Loss: 0.00001679
Iteration 51/1000 | Loss: 0.00001679
Iteration 52/1000 | Loss: 0.00001678
Iteration 53/1000 | Loss: 0.00001678
Iteration 54/1000 | Loss: 0.00001678
Iteration 55/1000 | Loss: 0.00001678
Iteration 56/1000 | Loss: 0.00001678
Iteration 57/1000 | Loss: 0.00001678
Iteration 58/1000 | Loss: 0.00001678
Iteration 59/1000 | Loss: 0.00001677
Iteration 60/1000 | Loss: 0.00001677
Iteration 61/1000 | Loss: 0.00001677
Iteration 62/1000 | Loss: 0.00001677
Iteration 63/1000 | Loss: 0.00001676
Iteration 64/1000 | Loss: 0.00001676
Iteration 65/1000 | Loss: 0.00001676
Iteration 66/1000 | Loss: 0.00001676
Iteration 67/1000 | Loss: 0.00001675
Iteration 68/1000 | Loss: 0.00001675
Iteration 69/1000 | Loss: 0.00001675
Iteration 70/1000 | Loss: 0.00001674
Iteration 71/1000 | Loss: 0.00001674
Iteration 72/1000 | Loss: 0.00001674
Iteration 73/1000 | Loss: 0.00001673
Iteration 74/1000 | Loss: 0.00001673
Iteration 75/1000 | Loss: 0.00001673
Iteration 76/1000 | Loss: 0.00001673
Iteration 77/1000 | Loss: 0.00001672
Iteration 78/1000 | Loss: 0.00001672
Iteration 79/1000 | Loss: 0.00001671
Iteration 80/1000 | Loss: 0.00001671
Iteration 81/1000 | Loss: 0.00001671
Iteration 82/1000 | Loss: 0.00001671
Iteration 83/1000 | Loss: 0.00001671
Iteration 84/1000 | Loss: 0.00001670
Iteration 85/1000 | Loss: 0.00001670
Iteration 86/1000 | Loss: 0.00001670
Iteration 87/1000 | Loss: 0.00001670
Iteration 88/1000 | Loss: 0.00001670
Iteration 89/1000 | Loss: 0.00001669
Iteration 90/1000 | Loss: 0.00001669
Iteration 91/1000 | Loss: 0.00001669
Iteration 92/1000 | Loss: 0.00001669
Iteration 93/1000 | Loss: 0.00001669
Iteration 94/1000 | Loss: 0.00001669
Iteration 95/1000 | Loss: 0.00001669
Iteration 96/1000 | Loss: 0.00001668
Iteration 97/1000 | Loss: 0.00001668
Iteration 98/1000 | Loss: 0.00001668
Iteration 99/1000 | Loss: 0.00001668
Iteration 100/1000 | Loss: 0.00001667
Iteration 101/1000 | Loss: 0.00001667
Iteration 102/1000 | Loss: 0.00001667
Iteration 103/1000 | Loss: 0.00001667
Iteration 104/1000 | Loss: 0.00001667
Iteration 105/1000 | Loss: 0.00001667
Iteration 106/1000 | Loss: 0.00001667
Iteration 107/1000 | Loss: 0.00001667
Iteration 108/1000 | Loss: 0.00001667
Iteration 109/1000 | Loss: 0.00001667
Iteration 110/1000 | Loss: 0.00001666
Iteration 111/1000 | Loss: 0.00001666
Iteration 112/1000 | Loss: 0.00001666
Iteration 113/1000 | Loss: 0.00001666
Iteration 114/1000 | Loss: 0.00001665
Iteration 115/1000 | Loss: 0.00001665
Iteration 116/1000 | Loss: 0.00001665
Iteration 117/1000 | Loss: 0.00001664
Iteration 118/1000 | Loss: 0.00001664
Iteration 119/1000 | Loss: 0.00001664
Iteration 120/1000 | Loss: 0.00001664
Iteration 121/1000 | Loss: 0.00001664
Iteration 122/1000 | Loss: 0.00001664
Iteration 123/1000 | Loss: 0.00001663
Iteration 124/1000 | Loss: 0.00001663
Iteration 125/1000 | Loss: 0.00001663
Iteration 126/1000 | Loss: 0.00001663
Iteration 127/1000 | Loss: 0.00001663
Iteration 128/1000 | Loss: 0.00001663
Iteration 129/1000 | Loss: 0.00001663
Iteration 130/1000 | Loss: 0.00001663
Iteration 131/1000 | Loss: 0.00001663
Iteration 132/1000 | Loss: 0.00001662
Iteration 133/1000 | Loss: 0.00001662
Iteration 134/1000 | Loss: 0.00001662
Iteration 135/1000 | Loss: 0.00001662
Iteration 136/1000 | Loss: 0.00001662
Iteration 137/1000 | Loss: 0.00001662
Iteration 138/1000 | Loss: 0.00001662
Iteration 139/1000 | Loss: 0.00001662
Iteration 140/1000 | Loss: 0.00001662
Iteration 141/1000 | Loss: 0.00001661
Iteration 142/1000 | Loss: 0.00001661
Iteration 143/1000 | Loss: 0.00001661
Iteration 144/1000 | Loss: 0.00001661
Iteration 145/1000 | Loss: 0.00001661
Iteration 146/1000 | Loss: 0.00001661
Iteration 147/1000 | Loss: 0.00001661
Iteration 148/1000 | Loss: 0.00001661
Iteration 149/1000 | Loss: 0.00001661
Iteration 150/1000 | Loss: 0.00001660
Iteration 151/1000 | Loss: 0.00001660
Iteration 152/1000 | Loss: 0.00001660
Iteration 153/1000 | Loss: 0.00001660
Iteration 154/1000 | Loss: 0.00001660
Iteration 155/1000 | Loss: 0.00001660
Iteration 156/1000 | Loss: 0.00001660
Iteration 157/1000 | Loss: 0.00001660
Iteration 158/1000 | Loss: 0.00001660
Iteration 159/1000 | Loss: 0.00001659
Iteration 160/1000 | Loss: 0.00001659
Iteration 161/1000 | Loss: 0.00001659
Iteration 162/1000 | Loss: 0.00001659
Iteration 163/1000 | Loss: 0.00001659
Iteration 164/1000 | Loss: 0.00001659
Iteration 165/1000 | Loss: 0.00001659
Iteration 166/1000 | Loss: 0.00001659
Iteration 167/1000 | Loss: 0.00001659
Iteration 168/1000 | Loss: 0.00001659
Iteration 169/1000 | Loss: 0.00001658
Iteration 170/1000 | Loss: 0.00001658
Iteration 171/1000 | Loss: 0.00001658
Iteration 172/1000 | Loss: 0.00001658
Iteration 173/1000 | Loss: 0.00001658
Iteration 174/1000 | Loss: 0.00001658
Iteration 175/1000 | Loss: 0.00001658
Iteration 176/1000 | Loss: 0.00001658
Iteration 177/1000 | Loss: 0.00001658
Iteration 178/1000 | Loss: 0.00001658
Iteration 179/1000 | Loss: 0.00001658
Iteration 180/1000 | Loss: 0.00001658
Iteration 181/1000 | Loss: 0.00001658
Iteration 182/1000 | Loss: 0.00001658
Iteration 183/1000 | Loss: 0.00001657
Iteration 184/1000 | Loss: 0.00001657
Iteration 185/1000 | Loss: 0.00001657
Iteration 186/1000 | Loss: 0.00001657
Iteration 187/1000 | Loss: 0.00001657
Iteration 188/1000 | Loss: 0.00001657
Iteration 189/1000 | Loss: 0.00001657
Iteration 190/1000 | Loss: 0.00001657
Iteration 191/1000 | Loss: 0.00001657
Iteration 192/1000 | Loss: 0.00001657
Iteration 193/1000 | Loss: 0.00001657
Iteration 194/1000 | Loss: 0.00001657
Iteration 195/1000 | Loss: 0.00001657
Iteration 196/1000 | Loss: 0.00001657
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [1.657011489442084e-05, 1.657011489442084e-05, 1.657011489442084e-05, 1.657011489442084e-05, 1.657011489442084e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.657011489442084e-05

Optimization complete. Final v2v error: 3.4141430854797363 mm

Highest mean error: 4.177238464355469 mm for frame 135

Lowest mean error: 3.09663987159729 mm for frame 72

Saving results

Total time: 43.58914804458618
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00845852
Iteration 2/25 | Loss: 0.00089421
Iteration 3/25 | Loss: 0.00076610
Iteration 4/25 | Loss: 0.00074033
Iteration 5/25 | Loss: 0.00073369
Iteration 6/25 | Loss: 0.00073215
Iteration 7/25 | Loss: 0.00073203
Iteration 8/25 | Loss: 0.00073203
Iteration 9/25 | Loss: 0.00073203
Iteration 10/25 | Loss: 0.00073203
Iteration 11/25 | Loss: 0.00073203
Iteration 12/25 | Loss: 0.00073203
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007320323493331671, 0.0007320323493331671, 0.0007320323493331671, 0.0007320323493331671, 0.0007320323493331671]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007320323493331671

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54107559
Iteration 2/25 | Loss: 0.00028801
Iteration 3/25 | Loss: 0.00028801
Iteration 4/25 | Loss: 0.00028801
Iteration 5/25 | Loss: 0.00028801
Iteration 6/25 | Loss: 0.00028801
Iteration 7/25 | Loss: 0.00028801
Iteration 8/25 | Loss: 0.00028801
Iteration 9/25 | Loss: 0.00028801
Iteration 10/25 | Loss: 0.00028801
Iteration 11/25 | Loss: 0.00028801
Iteration 12/25 | Loss: 0.00028801
Iteration 13/25 | Loss: 0.00028801
Iteration 14/25 | Loss: 0.00028801
Iteration 15/25 | Loss: 0.00028801
Iteration 16/25 | Loss: 0.00028801
Iteration 17/25 | Loss: 0.00028801
Iteration 18/25 | Loss: 0.00028801
Iteration 19/25 | Loss: 0.00028801
Iteration 20/25 | Loss: 0.00028801
Iteration 21/25 | Loss: 0.00028801
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0002880063548218459, 0.0002880063548218459, 0.0002880063548218459, 0.0002880063548218459, 0.0002880063548218459]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002880063548218459

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028801
Iteration 2/1000 | Loss: 0.00002558
Iteration 3/1000 | Loss: 0.00001974
Iteration 4/1000 | Loss: 0.00001835
Iteration 5/1000 | Loss: 0.00001728
Iteration 6/1000 | Loss: 0.00001685
Iteration 7/1000 | Loss: 0.00001640
Iteration 8/1000 | Loss: 0.00001633
Iteration 9/1000 | Loss: 0.00001611
Iteration 10/1000 | Loss: 0.00001610
Iteration 11/1000 | Loss: 0.00001591
Iteration 12/1000 | Loss: 0.00001588
Iteration 13/1000 | Loss: 0.00001580
Iteration 14/1000 | Loss: 0.00001574
Iteration 15/1000 | Loss: 0.00001570
Iteration 16/1000 | Loss: 0.00001568
Iteration 17/1000 | Loss: 0.00001566
Iteration 18/1000 | Loss: 0.00001565
Iteration 19/1000 | Loss: 0.00001564
Iteration 20/1000 | Loss: 0.00001564
Iteration 21/1000 | Loss: 0.00001563
Iteration 22/1000 | Loss: 0.00001563
Iteration 23/1000 | Loss: 0.00001563
Iteration 24/1000 | Loss: 0.00001560
Iteration 25/1000 | Loss: 0.00001559
Iteration 26/1000 | Loss: 0.00001558
Iteration 27/1000 | Loss: 0.00001557
Iteration 28/1000 | Loss: 0.00001557
Iteration 29/1000 | Loss: 0.00001557
Iteration 30/1000 | Loss: 0.00001556
Iteration 31/1000 | Loss: 0.00001556
Iteration 32/1000 | Loss: 0.00001556
Iteration 33/1000 | Loss: 0.00001555
Iteration 34/1000 | Loss: 0.00001555
Iteration 35/1000 | Loss: 0.00001555
Iteration 36/1000 | Loss: 0.00001554
Iteration 37/1000 | Loss: 0.00001554
Iteration 38/1000 | Loss: 0.00001554
Iteration 39/1000 | Loss: 0.00001553
Iteration 40/1000 | Loss: 0.00001553
Iteration 41/1000 | Loss: 0.00001553
Iteration 42/1000 | Loss: 0.00001553
Iteration 43/1000 | Loss: 0.00001553
Iteration 44/1000 | Loss: 0.00001552
Iteration 45/1000 | Loss: 0.00001552
Iteration 46/1000 | Loss: 0.00001552
Iteration 47/1000 | Loss: 0.00001552
Iteration 48/1000 | Loss: 0.00001551
Iteration 49/1000 | Loss: 0.00001551
Iteration 50/1000 | Loss: 0.00001551
Iteration 51/1000 | Loss: 0.00001551
Iteration 52/1000 | Loss: 0.00001550
Iteration 53/1000 | Loss: 0.00001549
Iteration 54/1000 | Loss: 0.00001549
Iteration 55/1000 | Loss: 0.00001548
Iteration 56/1000 | Loss: 0.00001547
Iteration 57/1000 | Loss: 0.00001546
Iteration 58/1000 | Loss: 0.00001544
Iteration 59/1000 | Loss: 0.00001543
Iteration 60/1000 | Loss: 0.00001543
Iteration 61/1000 | Loss: 0.00001542
Iteration 62/1000 | Loss: 0.00001542
Iteration 63/1000 | Loss: 0.00001542
Iteration 64/1000 | Loss: 0.00001542
Iteration 65/1000 | Loss: 0.00001541
Iteration 66/1000 | Loss: 0.00001541
Iteration 67/1000 | Loss: 0.00001540
Iteration 68/1000 | Loss: 0.00001540
Iteration 69/1000 | Loss: 0.00001540
Iteration 70/1000 | Loss: 0.00001540
Iteration 71/1000 | Loss: 0.00001539
Iteration 72/1000 | Loss: 0.00001539
Iteration 73/1000 | Loss: 0.00001539
Iteration 74/1000 | Loss: 0.00001539
Iteration 75/1000 | Loss: 0.00001539
Iteration 76/1000 | Loss: 0.00001539
Iteration 77/1000 | Loss: 0.00001539
Iteration 78/1000 | Loss: 0.00001538
Iteration 79/1000 | Loss: 0.00001538
Iteration 80/1000 | Loss: 0.00001538
Iteration 81/1000 | Loss: 0.00001537
Iteration 82/1000 | Loss: 0.00001537
Iteration 83/1000 | Loss: 0.00001536
Iteration 84/1000 | Loss: 0.00001536
Iteration 85/1000 | Loss: 0.00001536
Iteration 86/1000 | Loss: 0.00001536
Iteration 87/1000 | Loss: 0.00001536
Iteration 88/1000 | Loss: 0.00001536
Iteration 89/1000 | Loss: 0.00001535
Iteration 90/1000 | Loss: 0.00001535
Iteration 91/1000 | Loss: 0.00001535
Iteration 92/1000 | Loss: 0.00001535
Iteration 93/1000 | Loss: 0.00001535
Iteration 94/1000 | Loss: 0.00001535
Iteration 95/1000 | Loss: 0.00001535
Iteration 96/1000 | Loss: 0.00001535
Iteration 97/1000 | Loss: 0.00001534
Iteration 98/1000 | Loss: 0.00001534
Iteration 99/1000 | Loss: 0.00001534
Iteration 100/1000 | Loss: 0.00001534
Iteration 101/1000 | Loss: 0.00001534
Iteration 102/1000 | Loss: 0.00001534
Iteration 103/1000 | Loss: 0.00001534
Iteration 104/1000 | Loss: 0.00001534
Iteration 105/1000 | Loss: 0.00001534
Iteration 106/1000 | Loss: 0.00001534
Iteration 107/1000 | Loss: 0.00001534
Iteration 108/1000 | Loss: 0.00001534
Iteration 109/1000 | Loss: 0.00001534
Iteration 110/1000 | Loss: 0.00001534
Iteration 111/1000 | Loss: 0.00001534
Iteration 112/1000 | Loss: 0.00001534
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 112. Stopping optimization.
Last 5 losses: [1.5339073797804303e-05, 1.5339073797804303e-05, 1.5339073797804303e-05, 1.5339073797804303e-05, 1.5339073797804303e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5339073797804303e-05

Optimization complete. Final v2v error: 3.343782663345337 mm

Highest mean error: 3.7961220741271973 mm for frame 176

Lowest mean error: 3.0240564346313477 mm for frame 68

Saving results

Total time: 35.37712502479553
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00429246
Iteration 2/25 | Loss: 0.00089526
Iteration 3/25 | Loss: 0.00075701
Iteration 4/25 | Loss: 0.00072832
Iteration 5/25 | Loss: 0.00072196
Iteration 6/25 | Loss: 0.00071963
Iteration 7/25 | Loss: 0.00071924
Iteration 8/25 | Loss: 0.00071924
Iteration 9/25 | Loss: 0.00071924
Iteration 10/25 | Loss: 0.00071924
Iteration 11/25 | Loss: 0.00071924
Iteration 12/25 | Loss: 0.00071924
Iteration 13/25 | Loss: 0.00071924
Iteration 14/25 | Loss: 0.00071924
Iteration 15/25 | Loss: 0.00071924
Iteration 16/25 | Loss: 0.00071924
Iteration 17/25 | Loss: 0.00071924
Iteration 18/25 | Loss: 0.00071924
Iteration 19/25 | Loss: 0.00071924
Iteration 20/25 | Loss: 0.00071924
Iteration 21/25 | Loss: 0.00071924
Iteration 22/25 | Loss: 0.00071924
Iteration 23/25 | Loss: 0.00071924
Iteration 24/25 | Loss: 0.00071924
Iteration 25/25 | Loss: 0.00071924

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47845173
Iteration 2/25 | Loss: 0.00037331
Iteration 3/25 | Loss: 0.00037331
Iteration 4/25 | Loss: 0.00037331
Iteration 5/25 | Loss: 0.00037331
Iteration 6/25 | Loss: 0.00037331
Iteration 7/25 | Loss: 0.00037331
Iteration 8/25 | Loss: 0.00037331
Iteration 9/25 | Loss: 0.00037331
Iteration 10/25 | Loss: 0.00037331
Iteration 11/25 | Loss: 0.00037330
Iteration 12/25 | Loss: 0.00037330
Iteration 13/25 | Loss: 0.00037330
Iteration 14/25 | Loss: 0.00037330
Iteration 15/25 | Loss: 0.00037330
Iteration 16/25 | Loss: 0.00037330
Iteration 17/25 | Loss: 0.00037330
Iteration 18/25 | Loss: 0.00037330
Iteration 19/25 | Loss: 0.00037330
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000373304559616372, 0.000373304559616372, 0.000373304559616372, 0.000373304559616372, 0.000373304559616372]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000373304559616372

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00037330
Iteration 2/1000 | Loss: 0.00002246
Iteration 3/1000 | Loss: 0.00001388
Iteration 4/1000 | Loss: 0.00001240
Iteration 5/1000 | Loss: 0.00001176
Iteration 6/1000 | Loss: 0.00001133
Iteration 7/1000 | Loss: 0.00001119
Iteration 8/1000 | Loss: 0.00001112
Iteration 9/1000 | Loss: 0.00001111
Iteration 10/1000 | Loss: 0.00001110
Iteration 11/1000 | Loss: 0.00001103
Iteration 12/1000 | Loss: 0.00001096
Iteration 13/1000 | Loss: 0.00001096
Iteration 14/1000 | Loss: 0.00001096
Iteration 15/1000 | Loss: 0.00001095
Iteration 16/1000 | Loss: 0.00001094
Iteration 17/1000 | Loss: 0.00001089
Iteration 18/1000 | Loss: 0.00001088
Iteration 19/1000 | Loss: 0.00001087
Iteration 20/1000 | Loss: 0.00001084
Iteration 21/1000 | Loss: 0.00001083
Iteration 22/1000 | Loss: 0.00001082
Iteration 23/1000 | Loss: 0.00001082
Iteration 24/1000 | Loss: 0.00001081
Iteration 25/1000 | Loss: 0.00001077
Iteration 26/1000 | Loss: 0.00001077
Iteration 27/1000 | Loss: 0.00001076
Iteration 28/1000 | Loss: 0.00001076
Iteration 29/1000 | Loss: 0.00001076
Iteration 30/1000 | Loss: 0.00001076
Iteration 31/1000 | Loss: 0.00001075
Iteration 32/1000 | Loss: 0.00001075
Iteration 33/1000 | Loss: 0.00001075
Iteration 34/1000 | Loss: 0.00001075
Iteration 35/1000 | Loss: 0.00001075
Iteration 36/1000 | Loss: 0.00001074
Iteration 37/1000 | Loss: 0.00001073
Iteration 38/1000 | Loss: 0.00001073
Iteration 39/1000 | Loss: 0.00001073
Iteration 40/1000 | Loss: 0.00001073
Iteration 41/1000 | Loss: 0.00001072
Iteration 42/1000 | Loss: 0.00001072
Iteration 43/1000 | Loss: 0.00001072
Iteration 44/1000 | Loss: 0.00001072
Iteration 45/1000 | Loss: 0.00001072
Iteration 46/1000 | Loss: 0.00001072
Iteration 47/1000 | Loss: 0.00001072
Iteration 48/1000 | Loss: 0.00001072
Iteration 49/1000 | Loss: 0.00001071
Iteration 50/1000 | Loss: 0.00001071
Iteration 51/1000 | Loss: 0.00001071
Iteration 52/1000 | Loss: 0.00001071
Iteration 53/1000 | Loss: 0.00001071
Iteration 54/1000 | Loss: 0.00001070
Iteration 55/1000 | Loss: 0.00001070
Iteration 56/1000 | Loss: 0.00001070
Iteration 57/1000 | Loss: 0.00001069
Iteration 58/1000 | Loss: 0.00001069
Iteration 59/1000 | Loss: 0.00001069
Iteration 60/1000 | Loss: 0.00001069
Iteration 61/1000 | Loss: 0.00001069
Iteration 62/1000 | Loss: 0.00001069
Iteration 63/1000 | Loss: 0.00001069
Iteration 64/1000 | Loss: 0.00001069
Iteration 65/1000 | Loss: 0.00001069
Iteration 66/1000 | Loss: 0.00001069
Iteration 67/1000 | Loss: 0.00001069
Iteration 68/1000 | Loss: 0.00001069
Iteration 69/1000 | Loss: 0.00001069
Iteration 70/1000 | Loss: 0.00001069
Iteration 71/1000 | Loss: 0.00001068
Iteration 72/1000 | Loss: 0.00001068
Iteration 73/1000 | Loss: 0.00001068
Iteration 74/1000 | Loss: 0.00001068
Iteration 75/1000 | Loss: 0.00001068
Iteration 76/1000 | Loss: 0.00001067
Iteration 77/1000 | Loss: 0.00001067
Iteration 78/1000 | Loss: 0.00001067
Iteration 79/1000 | Loss: 0.00001067
Iteration 80/1000 | Loss: 0.00001067
Iteration 81/1000 | Loss: 0.00001067
Iteration 82/1000 | Loss: 0.00001067
Iteration 83/1000 | Loss: 0.00001067
Iteration 84/1000 | Loss: 0.00001066
Iteration 85/1000 | Loss: 0.00001066
Iteration 86/1000 | Loss: 0.00001066
Iteration 87/1000 | Loss: 0.00001066
Iteration 88/1000 | Loss: 0.00001066
Iteration 89/1000 | Loss: 0.00001066
Iteration 90/1000 | Loss: 0.00001066
Iteration 91/1000 | Loss: 0.00001066
Iteration 92/1000 | Loss: 0.00001066
Iteration 93/1000 | Loss: 0.00001066
Iteration 94/1000 | Loss: 0.00001066
Iteration 95/1000 | Loss: 0.00001065
Iteration 96/1000 | Loss: 0.00001065
Iteration 97/1000 | Loss: 0.00001065
Iteration 98/1000 | Loss: 0.00001065
Iteration 99/1000 | Loss: 0.00001065
Iteration 100/1000 | Loss: 0.00001065
Iteration 101/1000 | Loss: 0.00001065
Iteration 102/1000 | Loss: 0.00001065
Iteration 103/1000 | Loss: 0.00001065
Iteration 104/1000 | Loss: 0.00001065
Iteration 105/1000 | Loss: 0.00001065
Iteration 106/1000 | Loss: 0.00001065
Iteration 107/1000 | Loss: 0.00001065
Iteration 108/1000 | Loss: 0.00001064
Iteration 109/1000 | Loss: 0.00001064
Iteration 110/1000 | Loss: 0.00001064
Iteration 111/1000 | Loss: 0.00001064
Iteration 112/1000 | Loss: 0.00001064
Iteration 113/1000 | Loss: 0.00001063
Iteration 114/1000 | Loss: 0.00001063
Iteration 115/1000 | Loss: 0.00001063
Iteration 116/1000 | Loss: 0.00001063
Iteration 117/1000 | Loss: 0.00001063
Iteration 118/1000 | Loss: 0.00001063
Iteration 119/1000 | Loss: 0.00001063
Iteration 120/1000 | Loss: 0.00001063
Iteration 121/1000 | Loss: 0.00001063
Iteration 122/1000 | Loss: 0.00001063
Iteration 123/1000 | Loss: 0.00001063
Iteration 124/1000 | Loss: 0.00001063
Iteration 125/1000 | Loss: 0.00001063
Iteration 126/1000 | Loss: 0.00001063
Iteration 127/1000 | Loss: 0.00001063
Iteration 128/1000 | Loss: 0.00001062
Iteration 129/1000 | Loss: 0.00001062
Iteration 130/1000 | Loss: 0.00001062
Iteration 131/1000 | Loss: 0.00001062
Iteration 132/1000 | Loss: 0.00001062
Iteration 133/1000 | Loss: 0.00001062
Iteration 134/1000 | Loss: 0.00001062
Iteration 135/1000 | Loss: 0.00001062
Iteration 136/1000 | Loss: 0.00001062
Iteration 137/1000 | Loss: 0.00001062
Iteration 138/1000 | Loss: 0.00001062
Iteration 139/1000 | Loss: 0.00001062
Iteration 140/1000 | Loss: 0.00001062
Iteration 141/1000 | Loss: 0.00001062
Iteration 142/1000 | Loss: 0.00001062
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 142. Stopping optimization.
Last 5 losses: [1.0622420631989371e-05, 1.0622420631989371e-05, 1.0622420631989371e-05, 1.0622420631989371e-05, 1.0622420631989371e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0622420631989371e-05

Optimization complete. Final v2v error: 2.751206874847412 mm

Highest mean error: 2.9349870681762695 mm for frame 123

Lowest mean error: 2.5239202976226807 mm for frame 142

Saving results

Total time: 35.53504681587219
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1097/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1097.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1097
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01093385
Iteration 2/25 | Loss: 0.00302320
Iteration 3/25 | Loss: 0.00173868
Iteration 4/25 | Loss: 0.00144552
Iteration 5/25 | Loss: 0.00141285
Iteration 6/25 | Loss: 0.00137186
Iteration 7/25 | Loss: 0.00132350
Iteration 8/25 | Loss: 0.00128365
Iteration 9/25 | Loss: 0.00126739
Iteration 10/25 | Loss: 0.00125698
Iteration 11/25 | Loss: 0.00124565
Iteration 12/25 | Loss: 0.00122656
Iteration 13/25 | Loss: 0.00120998
Iteration 14/25 | Loss: 0.00120231
Iteration 15/25 | Loss: 0.00119599
Iteration 16/25 | Loss: 0.00119160
Iteration 17/25 | Loss: 0.00118783
Iteration 18/25 | Loss: 0.00118786
Iteration 19/25 | Loss: 0.00118591
Iteration 20/25 | Loss: 0.00118470
Iteration 21/25 | Loss: 0.00118388
Iteration 22/25 | Loss: 0.00118486
Iteration 23/25 | Loss: 0.00118398
Iteration 24/25 | Loss: 0.00118046
Iteration 25/25 | Loss: 0.00117941

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.26082873
Iteration 2/25 | Loss: 0.00442508
Iteration 3/25 | Loss: 0.00395858
Iteration 4/25 | Loss: 0.00395858
Iteration 5/25 | Loss: 0.00395858
Iteration 6/25 | Loss: 0.00395858
Iteration 7/25 | Loss: 0.00395858
Iteration 8/25 | Loss: 0.00395858
Iteration 9/25 | Loss: 0.00395858
Iteration 10/25 | Loss: 0.00395858
Iteration 11/25 | Loss: 0.00395858
Iteration 12/25 | Loss: 0.00395858
Iteration 13/25 | Loss: 0.00395858
Iteration 14/25 | Loss: 0.00395858
Iteration 15/25 | Loss: 0.00395858
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.003958575427532196, 0.003958575427532196, 0.003958575427532196, 0.003958575427532196, 0.003958575427532196]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003958575427532196

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00395858
Iteration 2/1000 | Loss: 0.00178127
Iteration 3/1000 | Loss: 0.00501401
Iteration 4/1000 | Loss: 0.00193328
Iteration 5/1000 | Loss: 0.00117149
Iteration 6/1000 | Loss: 0.00187490
Iteration 7/1000 | Loss: 0.00156449
Iteration 8/1000 | Loss: 0.00149512
Iteration 9/1000 | Loss: 0.00168191
Iteration 10/1000 | Loss: 0.00301450
Iteration 11/1000 | Loss: 0.00635216
Iteration 12/1000 | Loss: 0.01925434
Iteration 13/1000 | Loss: 0.01171850
Iteration 14/1000 | Loss: 0.00217879
Iteration 15/1000 | Loss: 0.00569970
Iteration 16/1000 | Loss: 0.01055725
Iteration 17/1000 | Loss: 0.00941143
Iteration 18/1000 | Loss: 0.00801917
Iteration 19/1000 | Loss: 0.00686962
Iteration 20/1000 | Loss: 0.00985838
Iteration 21/1000 | Loss: 0.00857194
Iteration 22/1000 | Loss: 0.00594071
Iteration 23/1000 | Loss: 0.00700854
Iteration 24/1000 | Loss: 0.00829759
Iteration 25/1000 | Loss: 0.00530039
Iteration 26/1000 | Loss: 0.00451834
Iteration 27/1000 | Loss: 0.00586011
Iteration 28/1000 | Loss: 0.00278843
Iteration 29/1000 | Loss: 0.00347995
Iteration 30/1000 | Loss: 0.00531873
Iteration 31/1000 | Loss: 0.00808779
Iteration 32/1000 | Loss: 0.00354617
Iteration 33/1000 | Loss: 0.00272539
Iteration 34/1000 | Loss: 0.00230166
Iteration 35/1000 | Loss: 0.00246647
Iteration 36/1000 | Loss: 0.00264028
Iteration 37/1000 | Loss: 0.00431414
Iteration 38/1000 | Loss: 0.00249121
Iteration 39/1000 | Loss: 0.00186203
Iteration 40/1000 | Loss: 0.00201632
Iteration 41/1000 | Loss: 0.00158376
Iteration 42/1000 | Loss: 0.00278662
Iteration 43/1000 | Loss: 0.00269733
Iteration 44/1000 | Loss: 0.00389430
Iteration 45/1000 | Loss: 0.00348681
Iteration 46/1000 | Loss: 0.00304607
Iteration 47/1000 | Loss: 0.00483039
Iteration 48/1000 | Loss: 0.00460588
Iteration 49/1000 | Loss: 0.00121858
Iteration 50/1000 | Loss: 0.00228831
Iteration 51/1000 | Loss: 0.00201113
Iteration 52/1000 | Loss: 0.00176243
Iteration 53/1000 | Loss: 0.00332946
Iteration 54/1000 | Loss: 0.00250564
Iteration 55/1000 | Loss: 0.00278055
Iteration 56/1000 | Loss: 0.00131766
Iteration 57/1000 | Loss: 0.00186563
Iteration 58/1000 | Loss: 0.00141947
Iteration 59/1000 | Loss: 0.00232655
Iteration 60/1000 | Loss: 0.00109500
Iteration 61/1000 | Loss: 0.00185341
Iteration 62/1000 | Loss: 0.00208357
Iteration 63/1000 | Loss: 0.00105243
Iteration 64/1000 | Loss: 0.00092101
Iteration 65/1000 | Loss: 0.00127503
Iteration 66/1000 | Loss: 0.00151012
Iteration 67/1000 | Loss: 0.00048222
Iteration 68/1000 | Loss: 0.00153492
Iteration 69/1000 | Loss: 0.00071328
Iteration 70/1000 | Loss: 0.00032643
Iteration 71/1000 | Loss: 0.00051845
Iteration 72/1000 | Loss: 0.00152031
Iteration 73/1000 | Loss: 0.00104911
Iteration 74/1000 | Loss: 0.00241073
Iteration 75/1000 | Loss: 0.00082497
Iteration 76/1000 | Loss: 0.00080497
Iteration 77/1000 | Loss: 0.00041513
Iteration 78/1000 | Loss: 0.00047171
Iteration 79/1000 | Loss: 0.00009383
Iteration 80/1000 | Loss: 0.00104223
Iteration 81/1000 | Loss: 0.00126959
Iteration 82/1000 | Loss: 0.00171010
Iteration 83/1000 | Loss: 0.00132570
Iteration 84/1000 | Loss: 0.00070964
Iteration 85/1000 | Loss: 0.00024103
Iteration 86/1000 | Loss: 0.00045502
Iteration 87/1000 | Loss: 0.00065058
Iteration 88/1000 | Loss: 0.00106700
Iteration 89/1000 | Loss: 0.00007427
Iteration 90/1000 | Loss: 0.00045893
Iteration 91/1000 | Loss: 0.00080260
Iteration 92/1000 | Loss: 0.00008246
Iteration 93/1000 | Loss: 0.00007047
Iteration 94/1000 | Loss: 0.00112257
Iteration 95/1000 | Loss: 0.00053344
Iteration 96/1000 | Loss: 0.00038253
Iteration 97/1000 | Loss: 0.00088243
Iteration 98/1000 | Loss: 0.00009279
Iteration 99/1000 | Loss: 0.00016333
Iteration 100/1000 | Loss: 0.00008040
Iteration 101/1000 | Loss: 0.00071190
Iteration 102/1000 | Loss: 0.00073666
Iteration 103/1000 | Loss: 0.00054539
Iteration 104/1000 | Loss: 0.00006907
Iteration 105/1000 | Loss: 0.00005943
Iteration 106/1000 | Loss: 0.00005523
Iteration 107/1000 | Loss: 0.00005112
Iteration 108/1000 | Loss: 0.00004791
Iteration 109/1000 | Loss: 0.00004620
Iteration 110/1000 | Loss: 0.00004459
Iteration 111/1000 | Loss: 0.00100231
Iteration 112/1000 | Loss: 0.00047911
Iteration 113/1000 | Loss: 0.00053993
Iteration 114/1000 | Loss: 0.00037609
Iteration 115/1000 | Loss: 0.00006599
Iteration 116/1000 | Loss: 0.00005063
Iteration 117/1000 | Loss: 0.00004360
Iteration 118/1000 | Loss: 0.00004022
Iteration 119/1000 | Loss: 0.00003797
Iteration 120/1000 | Loss: 0.00038039
Iteration 121/1000 | Loss: 0.00030662
Iteration 122/1000 | Loss: 0.00004543
Iteration 123/1000 | Loss: 0.00003931
Iteration 124/1000 | Loss: 0.00003640
Iteration 125/1000 | Loss: 0.00003502
Iteration 126/1000 | Loss: 0.00004309
Iteration 127/1000 | Loss: 0.00003412
Iteration 128/1000 | Loss: 0.00107747
Iteration 129/1000 | Loss: 0.00043948
Iteration 130/1000 | Loss: 0.00005154
Iteration 131/1000 | Loss: 0.00003176
Iteration 132/1000 | Loss: 0.00003102
Iteration 133/1000 | Loss: 0.00003071
Iteration 134/1000 | Loss: 0.00003043
Iteration 135/1000 | Loss: 0.00003041
Iteration 136/1000 | Loss: 0.00103570
Iteration 137/1000 | Loss: 0.00004704
Iteration 138/1000 | Loss: 0.00003619
Iteration 139/1000 | Loss: 0.00003138
Iteration 140/1000 | Loss: 0.00002893
Iteration 141/1000 | Loss: 0.00002754
Iteration 142/1000 | Loss: 0.00002685
Iteration 143/1000 | Loss: 0.00002654
Iteration 144/1000 | Loss: 0.00002635
Iteration 145/1000 | Loss: 0.00002615
Iteration 146/1000 | Loss: 0.00002606
Iteration 147/1000 | Loss: 0.00044185
Iteration 148/1000 | Loss: 0.00002713
Iteration 149/1000 | Loss: 0.00002605
Iteration 150/1000 | Loss: 0.00002593
Iteration 151/1000 | Loss: 0.00002586
Iteration 152/1000 | Loss: 0.00002585
Iteration 153/1000 | Loss: 0.00002585
Iteration 154/1000 | Loss: 0.00002585
Iteration 155/1000 | Loss: 0.00002585
Iteration 156/1000 | Loss: 0.00002585
Iteration 157/1000 | Loss: 0.00002585
Iteration 158/1000 | Loss: 0.00002585
Iteration 159/1000 | Loss: 0.00002584
Iteration 160/1000 | Loss: 0.00002584
Iteration 161/1000 | Loss: 0.00002584
Iteration 162/1000 | Loss: 0.00002584
Iteration 163/1000 | Loss: 0.00002584
Iteration 164/1000 | Loss: 0.00002584
Iteration 165/1000 | Loss: 0.00002583
Iteration 166/1000 | Loss: 0.00002583
Iteration 167/1000 | Loss: 0.00002583
Iteration 168/1000 | Loss: 0.00002582
Iteration 169/1000 | Loss: 0.00002582
Iteration 170/1000 | Loss: 0.00002582
Iteration 171/1000 | Loss: 0.00002582
Iteration 172/1000 | Loss: 0.00002582
Iteration 173/1000 | Loss: 0.00002581
Iteration 174/1000 | Loss: 0.00002581
Iteration 175/1000 | Loss: 0.00002581
Iteration 176/1000 | Loss: 0.00002581
Iteration 177/1000 | Loss: 0.00002581
Iteration 178/1000 | Loss: 0.00002581
Iteration 179/1000 | Loss: 0.00002581
Iteration 180/1000 | Loss: 0.00002581
Iteration 181/1000 | Loss: 0.00002581
Iteration 182/1000 | Loss: 0.00002580
Iteration 183/1000 | Loss: 0.00002580
Iteration 184/1000 | Loss: 0.00002580
Iteration 185/1000 | Loss: 0.00002580
Iteration 186/1000 | Loss: 0.00002580
Iteration 187/1000 | Loss: 0.00002580
Iteration 188/1000 | Loss: 0.00002579
Iteration 189/1000 | Loss: 0.00002579
Iteration 190/1000 | Loss: 0.00002578
Iteration 191/1000 | Loss: 0.00002578
Iteration 192/1000 | Loss: 0.00002578
Iteration 193/1000 | Loss: 0.00002577
Iteration 194/1000 | Loss: 0.00002577
Iteration 195/1000 | Loss: 0.00002577
Iteration 196/1000 | Loss: 0.00002577
Iteration 197/1000 | Loss: 0.00002576
Iteration 198/1000 | Loss: 0.00002576
Iteration 199/1000 | Loss: 0.00002576
Iteration 200/1000 | Loss: 0.00002576
Iteration 201/1000 | Loss: 0.00002576
Iteration 202/1000 | Loss: 0.00002576
Iteration 203/1000 | Loss: 0.00002575
Iteration 204/1000 | Loss: 0.00002575
Iteration 205/1000 | Loss: 0.00002575
Iteration 206/1000 | Loss: 0.00002574
Iteration 207/1000 | Loss: 0.00002574
Iteration 208/1000 | Loss: 0.00002574
Iteration 209/1000 | Loss: 0.00002573
Iteration 210/1000 | Loss: 0.00002573
Iteration 211/1000 | Loss: 0.00002573
Iteration 212/1000 | Loss: 0.00002573
Iteration 213/1000 | Loss: 0.00002573
Iteration 214/1000 | Loss: 0.00002572
Iteration 215/1000 | Loss: 0.00002572
Iteration 216/1000 | Loss: 0.00002572
Iteration 217/1000 | Loss: 0.00002572
Iteration 218/1000 | Loss: 0.00002572
Iteration 219/1000 | Loss: 0.00002572
Iteration 220/1000 | Loss: 0.00002572
Iteration 221/1000 | Loss: 0.00002572
Iteration 222/1000 | Loss: 0.00002572
Iteration 223/1000 | Loss: 0.00002572
Iteration 224/1000 | Loss: 0.00002571
Iteration 225/1000 | Loss: 0.00002571
Iteration 226/1000 | Loss: 0.00002571
Iteration 227/1000 | Loss: 0.00002571
Iteration 228/1000 | Loss: 0.00002571
Iteration 229/1000 | Loss: 0.00002571
Iteration 230/1000 | Loss: 0.00002571
Iteration 231/1000 | Loss: 0.00002571
Iteration 232/1000 | Loss: 0.00002571
Iteration 233/1000 | Loss: 0.00002571
Iteration 234/1000 | Loss: 0.00002571
Iteration 235/1000 | Loss: 0.00002571
Iteration 236/1000 | Loss: 0.00002571
Iteration 237/1000 | Loss: 0.00002571
Iteration 238/1000 | Loss: 0.00002571
Iteration 239/1000 | Loss: 0.00002571
Iteration 240/1000 | Loss: 0.00002571
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 240. Stopping optimization.
Last 5 losses: [2.570821925473865e-05, 2.570821925473865e-05, 2.570821925473865e-05, 2.570821925473865e-05, 2.570821925473865e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.570821925473865e-05

Optimization complete. Final v2v error: 4.0758209228515625 mm

Highest mean error: 6.130867004394531 mm for frame 32

Lowest mean error: 3.193448066711426 mm for frame 133

Saving results

Total time: 260.27153062820435
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1062/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1062.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1062
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00598707
Iteration 2/25 | Loss: 0.00111376
Iteration 3/25 | Loss: 0.00088601
Iteration 4/25 | Loss: 0.00078764
Iteration 5/25 | Loss: 0.00074730
Iteration 6/25 | Loss: 0.00073554
Iteration 7/25 | Loss: 0.00072817
Iteration 8/25 | Loss: 0.00072425
Iteration 9/25 | Loss: 0.00071472
Iteration 10/25 | Loss: 0.00071318
Iteration 11/25 | Loss: 0.00071182
Iteration 12/25 | Loss: 0.00071084
Iteration 13/25 | Loss: 0.00071012
Iteration 14/25 | Loss: 0.00070968
Iteration 15/25 | Loss: 0.00070934
Iteration 16/25 | Loss: 0.00071154
Iteration 17/25 | Loss: 0.00070788
Iteration 18/25 | Loss: 0.00070653
Iteration 19/25 | Loss: 0.00070594
Iteration 20/25 | Loss: 0.00070576
Iteration 21/25 | Loss: 0.00070575
Iteration 22/25 | Loss: 0.00070575
Iteration 23/25 | Loss: 0.00070575
Iteration 24/25 | Loss: 0.00070574
Iteration 25/25 | Loss: 0.00070574

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.30203319
Iteration 2/25 | Loss: 0.00029864
Iteration 3/25 | Loss: 0.00029864
Iteration 4/25 | Loss: 0.00029864
Iteration 5/25 | Loss: 0.00029864
Iteration 6/25 | Loss: 0.00029864
Iteration 7/25 | Loss: 0.00029864
Iteration 8/25 | Loss: 0.00029864
Iteration 9/25 | Loss: 0.00029864
Iteration 10/25 | Loss: 0.00029864
Iteration 11/25 | Loss: 0.00029864
Iteration 12/25 | Loss: 0.00029864
Iteration 13/25 | Loss: 0.00029864
Iteration 14/25 | Loss: 0.00029864
Iteration 15/25 | Loss: 0.00029864
Iteration 16/25 | Loss: 0.00029864
Iteration 17/25 | Loss: 0.00029864
Iteration 18/25 | Loss: 0.00029864
Iteration 19/25 | Loss: 0.00029864
Iteration 20/25 | Loss: 0.00029864
Iteration 21/25 | Loss: 0.00029864
Iteration 22/25 | Loss: 0.00029864
Iteration 23/25 | Loss: 0.00029864
Iteration 24/25 | Loss: 0.00029864
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00029863533563911915, 0.00029863533563911915, 0.00029863533563911915, 0.00029863533563911915, 0.00029863533563911915]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00029863533563911915

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029864
Iteration 2/1000 | Loss: 0.00002179
Iteration 3/1000 | Loss: 0.00001502
Iteration 4/1000 | Loss: 0.00001351
Iteration 5/1000 | Loss: 0.00001278
Iteration 6/1000 | Loss: 0.00001218
Iteration 7/1000 | Loss: 0.00001191
Iteration 8/1000 | Loss: 0.00001166
Iteration 9/1000 | Loss: 0.00001162
Iteration 10/1000 | Loss: 0.00001156
Iteration 11/1000 | Loss: 0.00001155
Iteration 12/1000 | Loss: 0.00001154
Iteration 13/1000 | Loss: 0.00001146
Iteration 14/1000 | Loss: 0.00001133
Iteration 15/1000 | Loss: 0.00001125
Iteration 16/1000 | Loss: 0.00001124
Iteration 17/1000 | Loss: 0.00001123
Iteration 18/1000 | Loss: 0.00001123
Iteration 19/1000 | Loss: 0.00001118
Iteration 20/1000 | Loss: 0.00001118
Iteration 21/1000 | Loss: 0.00001118
Iteration 22/1000 | Loss: 0.00001114
Iteration 23/1000 | Loss: 0.00001114
Iteration 24/1000 | Loss: 0.00001114
Iteration 25/1000 | Loss: 0.00001113
Iteration 26/1000 | Loss: 0.00001113
Iteration 27/1000 | Loss: 0.00001113
Iteration 28/1000 | Loss: 0.00001112
Iteration 29/1000 | Loss: 0.00001111
Iteration 30/1000 | Loss: 0.00001111
Iteration 31/1000 | Loss: 0.00001110
Iteration 32/1000 | Loss: 0.00001110
Iteration 33/1000 | Loss: 0.00001110
Iteration 34/1000 | Loss: 0.00001109
Iteration 35/1000 | Loss: 0.00001109
Iteration 36/1000 | Loss: 0.00001109
Iteration 37/1000 | Loss: 0.00001109
Iteration 38/1000 | Loss: 0.00001109
Iteration 39/1000 | Loss: 0.00001108
Iteration 40/1000 | Loss: 0.00001108
Iteration 41/1000 | Loss: 0.00001108
Iteration 42/1000 | Loss: 0.00001108
Iteration 43/1000 | Loss: 0.00001108
Iteration 44/1000 | Loss: 0.00001108
Iteration 45/1000 | Loss: 0.00001108
Iteration 46/1000 | Loss: 0.00001108
Iteration 47/1000 | Loss: 0.00001107
Iteration 48/1000 | Loss: 0.00001107
Iteration 49/1000 | Loss: 0.00001107
Iteration 50/1000 | Loss: 0.00001107
Iteration 51/1000 | Loss: 0.00001107
Iteration 52/1000 | Loss: 0.00001107
Iteration 53/1000 | Loss: 0.00001106
Iteration 54/1000 | Loss: 0.00001106
Iteration 55/1000 | Loss: 0.00001106
Iteration 56/1000 | Loss: 0.00001106
Iteration 57/1000 | Loss: 0.00001106
Iteration 58/1000 | Loss: 0.00001106
Iteration 59/1000 | Loss: 0.00001106
Iteration 60/1000 | Loss: 0.00001106
Iteration 61/1000 | Loss: 0.00001106
Iteration 62/1000 | Loss: 0.00001105
Iteration 63/1000 | Loss: 0.00001105
Iteration 64/1000 | Loss: 0.00001105
Iteration 65/1000 | Loss: 0.00001105
Iteration 66/1000 | Loss: 0.00001105
Iteration 67/1000 | Loss: 0.00001105
Iteration 68/1000 | Loss: 0.00001105
Iteration 69/1000 | Loss: 0.00001105
Iteration 70/1000 | Loss: 0.00001105
Iteration 71/1000 | Loss: 0.00001105
Iteration 72/1000 | Loss: 0.00001105
Iteration 73/1000 | Loss: 0.00001105
Iteration 74/1000 | Loss: 0.00001105
Iteration 75/1000 | Loss: 0.00001105
Iteration 76/1000 | Loss: 0.00001105
Iteration 77/1000 | Loss: 0.00001105
Iteration 78/1000 | Loss: 0.00001105
Iteration 79/1000 | Loss: 0.00001105
Iteration 80/1000 | Loss: 0.00001105
Iteration 81/1000 | Loss: 0.00001105
Iteration 82/1000 | Loss: 0.00001105
Iteration 83/1000 | Loss: 0.00001105
Iteration 84/1000 | Loss: 0.00001105
Iteration 85/1000 | Loss: 0.00001105
Iteration 86/1000 | Loss: 0.00001105
Iteration 87/1000 | Loss: 0.00001105
Iteration 88/1000 | Loss: 0.00001105
Iteration 89/1000 | Loss: 0.00001105
Iteration 90/1000 | Loss: 0.00001105
Iteration 91/1000 | Loss: 0.00001105
Iteration 92/1000 | Loss: 0.00001105
Iteration 93/1000 | Loss: 0.00001105
Iteration 94/1000 | Loss: 0.00001105
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.1052369700337294e-05, 1.1052369700337294e-05, 1.1052369700337294e-05, 1.1052369700337294e-05, 1.1052369700337294e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1052369700337294e-05

Optimization complete. Final v2v error: 2.8265023231506348 mm

Highest mean error: 3.1821444034576416 mm for frame 72

Lowest mean error: 2.57108736038208 mm for frame 178

Saving results

Total time: 63.06137561798096
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1050/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1050.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1050
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00793073
Iteration 2/25 | Loss: 0.00131170
Iteration 3/25 | Loss: 0.00096068
Iteration 4/25 | Loss: 0.00091648
Iteration 5/25 | Loss: 0.00090547
Iteration 6/25 | Loss: 0.00089230
Iteration 7/25 | Loss: 0.00088779
Iteration 8/25 | Loss: 0.00089043
Iteration 9/25 | Loss: 0.00089377
Iteration 10/25 | Loss: 0.00089093
Iteration 11/25 | Loss: 0.00088700
Iteration 12/25 | Loss: 0.00088644
Iteration 13/25 | Loss: 0.00088585
Iteration 14/25 | Loss: 0.00088494
Iteration 15/25 | Loss: 0.00088463
Iteration 16/25 | Loss: 0.00088419
Iteration 17/25 | Loss: 0.00088595
Iteration 18/25 | Loss: 0.00088510
Iteration 19/25 | Loss: 0.00088299
Iteration 20/25 | Loss: 0.00088259
Iteration 21/25 | Loss: 0.00088246
Iteration 22/25 | Loss: 0.00088246
Iteration 23/25 | Loss: 0.00088246
Iteration 24/25 | Loss: 0.00088246
Iteration 25/25 | Loss: 0.00088246

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46047437
Iteration 2/25 | Loss: 0.00031472
Iteration 3/25 | Loss: 0.00031470
Iteration 4/25 | Loss: 0.00031469
Iteration 5/25 | Loss: 0.00031469
Iteration 6/25 | Loss: 0.00031469
Iteration 7/25 | Loss: 0.00031469
Iteration 8/25 | Loss: 0.00031469
Iteration 9/25 | Loss: 0.00031469
Iteration 10/25 | Loss: 0.00031469
Iteration 11/25 | Loss: 0.00031469
Iteration 12/25 | Loss: 0.00031469
Iteration 13/25 | Loss: 0.00031469
Iteration 14/25 | Loss: 0.00031469
Iteration 15/25 | Loss: 0.00031469
Iteration 16/25 | Loss: 0.00031469
Iteration 17/25 | Loss: 0.00031469
Iteration 18/25 | Loss: 0.00031469
Iteration 19/25 | Loss: 0.00031469
Iteration 20/25 | Loss: 0.00031469
Iteration 21/25 | Loss: 0.00031469
Iteration 22/25 | Loss: 0.00031469
Iteration 23/25 | Loss: 0.00031469
Iteration 24/25 | Loss: 0.00031469
Iteration 25/25 | Loss: 0.00031469

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031469
Iteration 2/1000 | Loss: 0.00003531
Iteration 3/1000 | Loss: 0.00003003
Iteration 4/1000 | Loss: 0.00002794
Iteration 5/1000 | Loss: 0.00002592
Iteration 6/1000 | Loss: 0.00002523
Iteration 7/1000 | Loss: 0.00002454
Iteration 8/1000 | Loss: 0.00002406
Iteration 9/1000 | Loss: 0.00002379
Iteration 10/1000 | Loss: 0.00002361
Iteration 11/1000 | Loss: 0.00002356
Iteration 12/1000 | Loss: 0.00002349
Iteration 13/1000 | Loss: 0.00002346
Iteration 14/1000 | Loss: 0.00002346
Iteration 15/1000 | Loss: 0.00002340
Iteration 16/1000 | Loss: 0.00002336
Iteration 17/1000 | Loss: 0.00002336
Iteration 18/1000 | Loss: 0.00002333
Iteration 19/1000 | Loss: 0.00002333
Iteration 20/1000 | Loss: 0.00002332
Iteration 21/1000 | Loss: 0.00002332
Iteration 22/1000 | Loss: 0.00002330
Iteration 23/1000 | Loss: 0.00002330
Iteration 24/1000 | Loss: 0.00002329
Iteration 25/1000 | Loss: 0.00002329
Iteration 26/1000 | Loss: 0.00002329
Iteration 27/1000 | Loss: 0.00002328
Iteration 28/1000 | Loss: 0.00002328
Iteration 29/1000 | Loss: 0.00002328
Iteration 30/1000 | Loss: 0.00002328
Iteration 31/1000 | Loss: 0.00002328
Iteration 32/1000 | Loss: 0.00002328
Iteration 33/1000 | Loss: 0.00002328
Iteration 34/1000 | Loss: 0.00002328
Iteration 35/1000 | Loss: 0.00002328
Iteration 36/1000 | Loss: 0.00002328
Iteration 37/1000 | Loss: 0.00002328
Iteration 38/1000 | Loss: 0.00002327
Iteration 39/1000 | Loss: 0.00002326
Iteration 40/1000 | Loss: 0.00002326
Iteration 41/1000 | Loss: 0.00002325
Iteration 42/1000 | Loss: 0.00002325
Iteration 43/1000 | Loss: 0.00002325
Iteration 44/1000 | Loss: 0.00002325
Iteration 45/1000 | Loss: 0.00002325
Iteration 46/1000 | Loss: 0.00002324
Iteration 47/1000 | Loss: 0.00002324
Iteration 48/1000 | Loss: 0.00002324
Iteration 49/1000 | Loss: 0.00002323
Iteration 50/1000 | Loss: 0.00002323
Iteration 51/1000 | Loss: 0.00002323
Iteration 52/1000 | Loss: 0.00002322
Iteration 53/1000 | Loss: 0.00002322
Iteration 54/1000 | Loss: 0.00002322
Iteration 55/1000 | Loss: 0.00002322
Iteration 56/1000 | Loss: 0.00002322
Iteration 57/1000 | Loss: 0.00002322
Iteration 58/1000 | Loss: 0.00002322
Iteration 59/1000 | Loss: 0.00002322
Iteration 60/1000 | Loss: 0.00002322
Iteration 61/1000 | Loss: 0.00002322
Iteration 62/1000 | Loss: 0.00002322
Iteration 63/1000 | Loss: 0.00002322
Iteration 64/1000 | Loss: 0.00002322
Iteration 65/1000 | Loss: 0.00002322
Iteration 66/1000 | Loss: 0.00002322
Iteration 67/1000 | Loss: 0.00002322
Iteration 68/1000 | Loss: 0.00002322
Iteration 69/1000 | Loss: 0.00002322
Iteration 70/1000 | Loss: 0.00002322
Iteration 71/1000 | Loss: 0.00002322
Iteration 72/1000 | Loss: 0.00002322
Iteration 73/1000 | Loss: 0.00002322
Iteration 74/1000 | Loss: 0.00002322
Iteration 75/1000 | Loss: 0.00002322
Iteration 76/1000 | Loss: 0.00002322
Iteration 77/1000 | Loss: 0.00002322
Iteration 78/1000 | Loss: 0.00002322
Iteration 79/1000 | Loss: 0.00002322
Iteration 80/1000 | Loss: 0.00002322
Iteration 81/1000 | Loss: 0.00002322
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 81. Stopping optimization.
Last 5 losses: [2.3216751287691295e-05, 2.3216751287691295e-05, 2.3216751287691295e-05, 2.3216751287691295e-05, 2.3216751287691295e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3216751287691295e-05

Optimization complete. Final v2v error: 3.999785900115967 mm

Highest mean error: 5.986221790313721 mm for frame 65

Lowest mean error: 3.517864942550659 mm for frame 194

Saving results

Total time: 65.79884457588196
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1080/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1080.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1080
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00367888
Iteration 2/25 | Loss: 0.00081476
Iteration 3/25 | Loss: 0.00072738
Iteration 4/25 | Loss: 0.00070931
Iteration 5/25 | Loss: 0.00070271
Iteration 6/25 | Loss: 0.00070140
Iteration 7/25 | Loss: 0.00070102
Iteration 8/25 | Loss: 0.00070102
Iteration 9/25 | Loss: 0.00070102
Iteration 10/25 | Loss: 0.00070102
Iteration 11/25 | Loss: 0.00070102
Iteration 12/25 | Loss: 0.00070102
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007010205881670117, 0.0007010205881670117, 0.0007010205881670117, 0.0007010205881670117, 0.0007010205881670117]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007010205881670117

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.03651094
Iteration 2/25 | Loss: 0.00030345
Iteration 3/25 | Loss: 0.00030345
Iteration 4/25 | Loss: 0.00030345
Iteration 5/25 | Loss: 0.00030345
Iteration 6/25 | Loss: 0.00030345
Iteration 7/25 | Loss: 0.00030345
Iteration 8/25 | Loss: 0.00030345
Iteration 9/25 | Loss: 0.00030345
Iteration 10/25 | Loss: 0.00030345
Iteration 11/25 | Loss: 0.00030345
Iteration 12/25 | Loss: 0.00030345
Iteration 13/25 | Loss: 0.00030345
Iteration 14/25 | Loss: 0.00030345
Iteration 15/25 | Loss: 0.00030345
Iteration 16/25 | Loss: 0.00030345
Iteration 17/25 | Loss: 0.00030345
Iteration 18/25 | Loss: 0.00030345
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0003034455294255167, 0.0003034455294255167, 0.0003034455294255167, 0.0003034455294255167, 0.0003034455294255167]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003034455294255167

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030345
Iteration 2/1000 | Loss: 0.00002483
Iteration 3/1000 | Loss: 0.00001614
Iteration 4/1000 | Loss: 0.00001485
Iteration 5/1000 | Loss: 0.00001404
Iteration 6/1000 | Loss: 0.00001369
Iteration 7/1000 | Loss: 0.00001333
Iteration 8/1000 | Loss: 0.00001330
Iteration 9/1000 | Loss: 0.00001313
Iteration 10/1000 | Loss: 0.00001294
Iteration 11/1000 | Loss: 0.00001292
Iteration 12/1000 | Loss: 0.00001291
Iteration 13/1000 | Loss: 0.00001276
Iteration 14/1000 | Loss: 0.00001273
Iteration 15/1000 | Loss: 0.00001272
Iteration 16/1000 | Loss: 0.00001265
Iteration 17/1000 | Loss: 0.00001259
Iteration 18/1000 | Loss: 0.00001258
Iteration 19/1000 | Loss: 0.00001257
Iteration 20/1000 | Loss: 0.00001256
Iteration 21/1000 | Loss: 0.00001256
Iteration 22/1000 | Loss: 0.00001255
Iteration 23/1000 | Loss: 0.00001255
Iteration 24/1000 | Loss: 0.00001255
Iteration 25/1000 | Loss: 0.00001254
Iteration 26/1000 | Loss: 0.00001254
Iteration 27/1000 | Loss: 0.00001253
Iteration 28/1000 | Loss: 0.00001252
Iteration 29/1000 | Loss: 0.00001251
Iteration 30/1000 | Loss: 0.00001250
Iteration 31/1000 | Loss: 0.00001250
Iteration 32/1000 | Loss: 0.00001250
Iteration 33/1000 | Loss: 0.00001249
Iteration 34/1000 | Loss: 0.00001249
Iteration 35/1000 | Loss: 0.00001249
Iteration 36/1000 | Loss: 0.00001249
Iteration 37/1000 | Loss: 0.00001248
Iteration 38/1000 | Loss: 0.00001248
Iteration 39/1000 | Loss: 0.00001247
Iteration 40/1000 | Loss: 0.00001246
Iteration 41/1000 | Loss: 0.00001246
Iteration 42/1000 | Loss: 0.00001245
Iteration 43/1000 | Loss: 0.00001245
Iteration 44/1000 | Loss: 0.00001244
Iteration 45/1000 | Loss: 0.00001244
Iteration 46/1000 | Loss: 0.00001243
Iteration 47/1000 | Loss: 0.00001243
Iteration 48/1000 | Loss: 0.00001242
Iteration 49/1000 | Loss: 0.00001241
Iteration 50/1000 | Loss: 0.00001238
Iteration 51/1000 | Loss: 0.00001238
Iteration 52/1000 | Loss: 0.00001238
Iteration 53/1000 | Loss: 0.00001233
Iteration 54/1000 | Loss: 0.00001231
Iteration 55/1000 | Loss: 0.00001231
Iteration 56/1000 | Loss: 0.00001231
Iteration 57/1000 | Loss: 0.00001231
Iteration 58/1000 | Loss: 0.00001230
Iteration 59/1000 | Loss: 0.00001230
Iteration 60/1000 | Loss: 0.00001228
Iteration 61/1000 | Loss: 0.00001228
Iteration 62/1000 | Loss: 0.00001227
Iteration 63/1000 | Loss: 0.00001227
Iteration 64/1000 | Loss: 0.00001227
Iteration 65/1000 | Loss: 0.00001227
Iteration 66/1000 | Loss: 0.00001227
Iteration 67/1000 | Loss: 0.00001227
Iteration 68/1000 | Loss: 0.00001226
Iteration 69/1000 | Loss: 0.00001226
Iteration 70/1000 | Loss: 0.00001226
Iteration 71/1000 | Loss: 0.00001225
Iteration 72/1000 | Loss: 0.00001225
Iteration 73/1000 | Loss: 0.00001225
Iteration 74/1000 | Loss: 0.00001225
Iteration 75/1000 | Loss: 0.00001225
Iteration 76/1000 | Loss: 0.00001225
Iteration 77/1000 | Loss: 0.00001224
Iteration 78/1000 | Loss: 0.00001224
Iteration 79/1000 | Loss: 0.00001224
Iteration 80/1000 | Loss: 0.00001224
Iteration 81/1000 | Loss: 0.00001224
Iteration 82/1000 | Loss: 0.00001224
Iteration 83/1000 | Loss: 0.00001224
Iteration 84/1000 | Loss: 0.00001224
Iteration 85/1000 | Loss: 0.00001224
Iteration 86/1000 | Loss: 0.00001224
Iteration 87/1000 | Loss: 0.00001224
Iteration 88/1000 | Loss: 0.00001223
Iteration 89/1000 | Loss: 0.00001223
Iteration 90/1000 | Loss: 0.00001223
Iteration 91/1000 | Loss: 0.00001223
Iteration 92/1000 | Loss: 0.00001223
Iteration 93/1000 | Loss: 0.00001223
Iteration 94/1000 | Loss: 0.00001223
Iteration 95/1000 | Loss: 0.00001222
Iteration 96/1000 | Loss: 0.00001222
Iteration 97/1000 | Loss: 0.00001222
Iteration 98/1000 | Loss: 0.00001222
Iteration 99/1000 | Loss: 0.00001222
Iteration 100/1000 | Loss: 0.00001222
Iteration 101/1000 | Loss: 0.00001222
Iteration 102/1000 | Loss: 0.00001221
Iteration 103/1000 | Loss: 0.00001221
Iteration 104/1000 | Loss: 0.00001221
Iteration 105/1000 | Loss: 0.00001221
Iteration 106/1000 | Loss: 0.00001221
Iteration 107/1000 | Loss: 0.00001221
Iteration 108/1000 | Loss: 0.00001220
Iteration 109/1000 | Loss: 0.00001220
Iteration 110/1000 | Loss: 0.00001220
Iteration 111/1000 | Loss: 0.00001220
Iteration 112/1000 | Loss: 0.00001220
Iteration 113/1000 | Loss: 0.00001220
Iteration 114/1000 | Loss: 0.00001220
Iteration 115/1000 | Loss: 0.00001220
Iteration 116/1000 | Loss: 0.00001220
Iteration 117/1000 | Loss: 0.00001219
Iteration 118/1000 | Loss: 0.00001219
Iteration 119/1000 | Loss: 0.00001219
Iteration 120/1000 | Loss: 0.00001219
Iteration 121/1000 | Loss: 0.00001219
Iteration 122/1000 | Loss: 0.00001219
Iteration 123/1000 | Loss: 0.00001219
Iteration 124/1000 | Loss: 0.00001219
Iteration 125/1000 | Loss: 0.00001219
Iteration 126/1000 | Loss: 0.00001219
Iteration 127/1000 | Loss: 0.00001219
Iteration 128/1000 | Loss: 0.00001219
Iteration 129/1000 | Loss: 0.00001219
Iteration 130/1000 | Loss: 0.00001219
Iteration 131/1000 | Loss: 0.00001219
Iteration 132/1000 | Loss: 0.00001219
Iteration 133/1000 | Loss: 0.00001219
Iteration 134/1000 | Loss: 0.00001219
Iteration 135/1000 | Loss: 0.00001219
Iteration 136/1000 | Loss: 0.00001219
Iteration 137/1000 | Loss: 0.00001218
Iteration 138/1000 | Loss: 0.00001218
Iteration 139/1000 | Loss: 0.00001218
Iteration 140/1000 | Loss: 0.00001218
Iteration 141/1000 | Loss: 0.00001218
Iteration 142/1000 | Loss: 0.00001218
Iteration 143/1000 | Loss: 0.00001218
Iteration 144/1000 | Loss: 0.00001218
Iteration 145/1000 | Loss: 0.00001218
Iteration 146/1000 | Loss: 0.00001218
Iteration 147/1000 | Loss: 0.00001218
Iteration 148/1000 | Loss: 0.00001218
Iteration 149/1000 | Loss: 0.00001218
Iteration 150/1000 | Loss: 0.00001218
Iteration 151/1000 | Loss: 0.00001218
Iteration 152/1000 | Loss: 0.00001218
Iteration 153/1000 | Loss: 0.00001218
Iteration 154/1000 | Loss: 0.00001218
Iteration 155/1000 | Loss: 0.00001218
Iteration 156/1000 | Loss: 0.00001218
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.2176137715869118e-05, 1.2176137715869118e-05, 1.2176137715869118e-05, 1.2176137715869118e-05, 1.2176137715869118e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2176137715869118e-05

Optimization complete. Final v2v error: 2.974766731262207 mm

Highest mean error: 3.236132860183716 mm for frame 94

Lowest mean error: 2.772984743118286 mm for frame 123

Saving results

Total time: 38.892905950546265
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01037307
Iteration 2/25 | Loss: 0.00197810
Iteration 3/25 | Loss: 0.00135735
Iteration 4/25 | Loss: 0.00118074
Iteration 5/25 | Loss: 0.00121117
Iteration 6/25 | Loss: 0.00118384
Iteration 7/25 | Loss: 0.00116588
Iteration 8/25 | Loss: 0.00114307
Iteration 9/25 | Loss: 0.00111806
Iteration 10/25 | Loss: 0.00109107
Iteration 11/25 | Loss: 0.00105321
Iteration 12/25 | Loss: 0.00101072
Iteration 13/25 | Loss: 0.00097898
Iteration 14/25 | Loss: 0.00095933
Iteration 15/25 | Loss: 0.00094679
Iteration 16/25 | Loss: 0.00092899
Iteration 17/25 | Loss: 0.00092675
Iteration 18/25 | Loss: 0.00092071
Iteration 19/25 | Loss: 0.00091068
Iteration 20/25 | Loss: 0.00090077
Iteration 21/25 | Loss: 0.00090143
Iteration 22/25 | Loss: 0.00090395
Iteration 23/25 | Loss: 0.00089797
Iteration 24/25 | Loss: 0.00089986
Iteration 25/25 | Loss: 0.00090352

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.36708653
Iteration 2/25 | Loss: 0.00198837
Iteration 3/25 | Loss: 0.00169011
Iteration 4/25 | Loss: 0.00169008
Iteration 5/25 | Loss: 0.00169008
Iteration 6/25 | Loss: 0.00169008
Iteration 7/25 | Loss: 0.00169008
Iteration 8/25 | Loss: 0.00169008
Iteration 9/25 | Loss: 0.00169008
Iteration 10/25 | Loss: 0.00169008
Iteration 11/25 | Loss: 0.00169008
Iteration 12/25 | Loss: 0.00169008
Iteration 13/25 | Loss: 0.00169008
Iteration 14/25 | Loss: 0.00169008
Iteration 15/25 | Loss: 0.00169008
Iteration 16/25 | Loss: 0.00169008
Iteration 17/25 | Loss: 0.00169008
Iteration 18/25 | Loss: 0.00169008
Iteration 19/25 | Loss: 0.00169008
Iteration 20/25 | Loss: 0.00169008
Iteration 21/25 | Loss: 0.00169008
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0016900758491829038, 0.0016900758491829038, 0.0016900758491829038, 0.0016900758491829038, 0.0016900758491829038]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016900758491829038

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00169008
Iteration 2/1000 | Loss: 0.00093025
Iteration 3/1000 | Loss: 0.00034673
Iteration 4/1000 | Loss: 0.00075193
Iteration 5/1000 | Loss: 0.00054615
Iteration 6/1000 | Loss: 0.00069456
Iteration 7/1000 | Loss: 0.00051844
Iteration 8/1000 | Loss: 0.00076053
Iteration 9/1000 | Loss: 0.00074074
Iteration 10/1000 | Loss: 0.00075722
Iteration 11/1000 | Loss: 0.00066739
Iteration 12/1000 | Loss: 0.00062362
Iteration 13/1000 | Loss: 0.00055038
Iteration 14/1000 | Loss: 0.00069180
Iteration 15/1000 | Loss: 0.00050513
Iteration 16/1000 | Loss: 0.00057244
Iteration 17/1000 | Loss: 0.00048269
Iteration 18/1000 | Loss: 0.00049281
Iteration 19/1000 | Loss: 0.00074933
Iteration 20/1000 | Loss: 0.00081086
Iteration 21/1000 | Loss: 0.00055658
Iteration 22/1000 | Loss: 0.00078734
Iteration 23/1000 | Loss: 0.00089533
Iteration 24/1000 | Loss: 0.00070170
Iteration 25/1000 | Loss: 0.00072986
Iteration 26/1000 | Loss: 0.00062173
Iteration 27/1000 | Loss: 0.00066210
Iteration 28/1000 | Loss: 0.00041352
Iteration 29/1000 | Loss: 0.00054603
Iteration 30/1000 | Loss: 0.00063298
Iteration 31/1000 | Loss: 0.00064704
Iteration 32/1000 | Loss: 0.00038519
Iteration 33/1000 | Loss: 0.00031674
Iteration 34/1000 | Loss: 0.00014344
Iteration 35/1000 | Loss: 0.00018343
Iteration 36/1000 | Loss: 0.00029646
Iteration 37/1000 | Loss: 0.00027244
Iteration 38/1000 | Loss: 0.00019550
Iteration 39/1000 | Loss: 0.00012136
Iteration 40/1000 | Loss: 0.00015665
Iteration 41/1000 | Loss: 0.00012548
Iteration 42/1000 | Loss: 0.00039285
Iteration 43/1000 | Loss: 0.00038213
Iteration 44/1000 | Loss: 0.00039016
Iteration 45/1000 | Loss: 0.00031398
Iteration 46/1000 | Loss: 0.00037522
Iteration 47/1000 | Loss: 0.00043828
Iteration 48/1000 | Loss: 0.00051614
Iteration 49/1000 | Loss: 0.00054830
Iteration 50/1000 | Loss: 0.00056099
Iteration 51/1000 | Loss: 0.00050333
Iteration 52/1000 | Loss: 0.00093465
Iteration 53/1000 | Loss: 0.00091558
Iteration 54/1000 | Loss: 0.00028197
Iteration 55/1000 | Loss: 0.00022151
Iteration 56/1000 | Loss: 0.00040816
Iteration 57/1000 | Loss: 0.00017822
Iteration 58/1000 | Loss: 0.00029575
Iteration 59/1000 | Loss: 0.00016244
Iteration 60/1000 | Loss: 0.00017943
Iteration 61/1000 | Loss: 0.00015433
Iteration 62/1000 | Loss: 0.00018131
Iteration 63/1000 | Loss: 0.00016459
Iteration 64/1000 | Loss: 0.00028295
Iteration 65/1000 | Loss: 0.00021281
Iteration 66/1000 | Loss: 0.00023874
Iteration 67/1000 | Loss: 0.00022425
Iteration 68/1000 | Loss: 0.00016360
Iteration 69/1000 | Loss: 0.00014230
Iteration 70/1000 | Loss: 0.00020885
Iteration 71/1000 | Loss: 0.00016220
Iteration 72/1000 | Loss: 0.00017957
Iteration 73/1000 | Loss: 0.00041609
Iteration 74/1000 | Loss: 0.00130568
Iteration 75/1000 | Loss: 0.00095073
Iteration 76/1000 | Loss: 0.00483012
Iteration 77/1000 | Loss: 0.00248909
Iteration 78/1000 | Loss: 0.00117460
Iteration 79/1000 | Loss: 0.00135162
Iteration 80/1000 | Loss: 0.00094166
Iteration 81/1000 | Loss: 0.00060404
Iteration 82/1000 | Loss: 0.00073326
Iteration 83/1000 | Loss: 0.00060638
Iteration 84/1000 | Loss: 0.00017434
Iteration 85/1000 | Loss: 0.00037909
Iteration 86/1000 | Loss: 0.00017132
Iteration 87/1000 | Loss: 0.00016321
Iteration 88/1000 | Loss: 0.00019872
Iteration 89/1000 | Loss: 0.00070477
Iteration 90/1000 | Loss: 0.00060646
Iteration 91/1000 | Loss: 0.00065278
Iteration 92/1000 | Loss: 0.00041030
Iteration 93/1000 | Loss: 0.00070296
Iteration 94/1000 | Loss: 0.00118961
Iteration 95/1000 | Loss: 0.00118192
Iteration 96/1000 | Loss: 0.00050462
Iteration 97/1000 | Loss: 0.00018306
Iteration 98/1000 | Loss: 0.00049545
Iteration 99/1000 | Loss: 0.00006807
Iteration 100/1000 | Loss: 0.00005468
Iteration 101/1000 | Loss: 0.00013545
Iteration 102/1000 | Loss: 0.00024923
Iteration 103/1000 | Loss: 0.00022858
Iteration 104/1000 | Loss: 0.00004223
Iteration 105/1000 | Loss: 0.00018003
Iteration 106/1000 | Loss: 0.00020600
Iteration 107/1000 | Loss: 0.00009441
Iteration 108/1000 | Loss: 0.00023918
Iteration 109/1000 | Loss: 0.00004371
Iteration 110/1000 | Loss: 0.00008558
Iteration 111/1000 | Loss: 0.00007988
Iteration 112/1000 | Loss: 0.00022191
Iteration 113/1000 | Loss: 0.00005499
Iteration 114/1000 | Loss: 0.00012991
Iteration 115/1000 | Loss: 0.00005127
Iteration 116/1000 | Loss: 0.00003909
Iteration 117/1000 | Loss: 0.00009733
Iteration 118/1000 | Loss: 0.00004000
Iteration 119/1000 | Loss: 0.00041764
Iteration 120/1000 | Loss: 0.00011415
Iteration 121/1000 | Loss: 0.00012267
Iteration 122/1000 | Loss: 0.00009609
Iteration 123/1000 | Loss: 0.00012212
Iteration 124/1000 | Loss: 0.00003095
Iteration 125/1000 | Loss: 0.00014602
Iteration 126/1000 | Loss: 0.00009587
Iteration 127/1000 | Loss: 0.00014248
Iteration 128/1000 | Loss: 0.00007519
Iteration 129/1000 | Loss: 0.00013325
Iteration 130/1000 | Loss: 0.00015917
Iteration 131/1000 | Loss: 0.00006127
Iteration 132/1000 | Loss: 0.00025288
Iteration 133/1000 | Loss: 0.00033571
Iteration 134/1000 | Loss: 0.00038725
Iteration 135/1000 | Loss: 0.00022612
Iteration 136/1000 | Loss: 0.00015582
Iteration 137/1000 | Loss: 0.00016795
Iteration 138/1000 | Loss: 0.00021058
Iteration 139/1000 | Loss: 0.00016664
Iteration 140/1000 | Loss: 0.00011166
Iteration 141/1000 | Loss: 0.00009858
Iteration 142/1000 | Loss: 0.00003551
Iteration 143/1000 | Loss: 0.00006973
Iteration 144/1000 | Loss: 0.00004620
Iteration 145/1000 | Loss: 0.00002363
Iteration 146/1000 | Loss: 0.00011674
Iteration 147/1000 | Loss: 0.00015638
Iteration 148/1000 | Loss: 0.00002131
Iteration 149/1000 | Loss: 0.00002039
Iteration 150/1000 | Loss: 0.00009523
Iteration 151/1000 | Loss: 0.00002189
Iteration 152/1000 | Loss: 0.00011237
Iteration 153/1000 | Loss: 0.00009076
Iteration 154/1000 | Loss: 0.00008470
Iteration 155/1000 | Loss: 0.00005776
Iteration 156/1000 | Loss: 0.00002808
Iteration 157/1000 | Loss: 0.00002517
Iteration 158/1000 | Loss: 0.00012812
Iteration 159/1000 | Loss: 0.00013850
Iteration 160/1000 | Loss: 0.00004632
Iteration 161/1000 | Loss: 0.00015304
Iteration 162/1000 | Loss: 0.00010650
Iteration 163/1000 | Loss: 0.00012315
Iteration 164/1000 | Loss: 0.00011248
Iteration 165/1000 | Loss: 0.00012392
Iteration 166/1000 | Loss: 0.00011162
Iteration 167/1000 | Loss: 0.00002441
Iteration 168/1000 | Loss: 0.00010696
Iteration 169/1000 | Loss: 0.00006740
Iteration 170/1000 | Loss: 0.00006756
Iteration 171/1000 | Loss: 0.00010925
Iteration 172/1000 | Loss: 0.00011239
Iteration 173/1000 | Loss: 0.00012237
Iteration 174/1000 | Loss: 0.00012690
Iteration 175/1000 | Loss: 0.00007446
Iteration 176/1000 | Loss: 0.00011272
Iteration 177/1000 | Loss: 0.00011493
Iteration 178/1000 | Loss: 0.00007482
Iteration 179/1000 | Loss: 0.00009585
Iteration 180/1000 | Loss: 0.00011646
Iteration 181/1000 | Loss: 0.00022875
Iteration 182/1000 | Loss: 0.00010465
Iteration 183/1000 | Loss: 0.00009020
Iteration 184/1000 | Loss: 0.00003851
Iteration 185/1000 | Loss: 0.00011544
Iteration 186/1000 | Loss: 0.00003662
Iteration 187/1000 | Loss: 0.00016293
Iteration 188/1000 | Loss: 0.00002482
Iteration 189/1000 | Loss: 0.00006796
Iteration 190/1000 | Loss: 0.00002461
Iteration 191/1000 | Loss: 0.00005192
Iteration 192/1000 | Loss: 0.00006913
Iteration 193/1000 | Loss: 0.00007414
Iteration 194/1000 | Loss: 0.00005969
Iteration 195/1000 | Loss: 0.00004339
Iteration 196/1000 | Loss: 0.00002425
Iteration 197/1000 | Loss: 0.00002052
Iteration 198/1000 | Loss: 0.00002276
Iteration 199/1000 | Loss: 0.00002255
Iteration 200/1000 | Loss: 0.00002016
Iteration 201/1000 | Loss: 0.00007061
Iteration 202/1000 | Loss: 0.00011021
Iteration 203/1000 | Loss: 0.00011988
Iteration 204/1000 | Loss: 0.00013333
Iteration 205/1000 | Loss: 0.00013112
Iteration 206/1000 | Loss: 0.00020037
Iteration 207/1000 | Loss: 0.00012975
Iteration 208/1000 | Loss: 0.00012303
Iteration 209/1000 | Loss: 0.00004619
Iteration 210/1000 | Loss: 0.00004426
Iteration 211/1000 | Loss: 0.00003651
Iteration 212/1000 | Loss: 0.00002220
Iteration 213/1000 | Loss: 0.00002471
Iteration 214/1000 | Loss: 0.00002130
Iteration 215/1000 | Loss: 0.00002074
Iteration 216/1000 | Loss: 0.00002027
Iteration 217/1000 | Loss: 0.00011971
Iteration 218/1000 | Loss: 0.00008349
Iteration 219/1000 | Loss: 0.00002033
Iteration 220/1000 | Loss: 0.00035031
Iteration 221/1000 | Loss: 0.00007279
Iteration 222/1000 | Loss: 0.00009761
Iteration 223/1000 | Loss: 0.00011140
Iteration 224/1000 | Loss: 0.00009290
Iteration 225/1000 | Loss: 0.00007195
Iteration 226/1000 | Loss: 0.00007531
Iteration 227/1000 | Loss: 0.00007256
Iteration 228/1000 | Loss: 0.00002942
Iteration 229/1000 | Loss: 0.00010039
Iteration 230/1000 | Loss: 0.00007110
Iteration 231/1000 | Loss: 0.00004832
Iteration 232/1000 | Loss: 0.00002164
Iteration 233/1000 | Loss: 0.00009138
Iteration 234/1000 | Loss: 0.00004018
Iteration 235/1000 | Loss: 0.00002149
Iteration 236/1000 | Loss: 0.00002087
Iteration 237/1000 | Loss: 0.00002058
Iteration 238/1000 | Loss: 0.00020498
Iteration 239/1000 | Loss: 0.00007563
Iteration 240/1000 | Loss: 0.00002618
Iteration 241/1000 | Loss: 0.00002154
Iteration 242/1000 | Loss: 0.00001938
Iteration 243/1000 | Loss: 0.00001892
Iteration 244/1000 | Loss: 0.00001856
Iteration 245/1000 | Loss: 0.00001823
Iteration 246/1000 | Loss: 0.00001795
Iteration 247/1000 | Loss: 0.00001770
Iteration 248/1000 | Loss: 0.00001763
Iteration 249/1000 | Loss: 0.00001762
Iteration 250/1000 | Loss: 0.00001762
Iteration 251/1000 | Loss: 0.00001759
Iteration 252/1000 | Loss: 0.00001758
Iteration 253/1000 | Loss: 0.00001757
Iteration 254/1000 | Loss: 0.00001757
Iteration 255/1000 | Loss: 0.00001756
Iteration 256/1000 | Loss: 0.00001756
Iteration 257/1000 | Loss: 0.00001756
Iteration 258/1000 | Loss: 0.00001754
Iteration 259/1000 | Loss: 0.00001754
Iteration 260/1000 | Loss: 0.00001754
Iteration 261/1000 | Loss: 0.00001754
Iteration 262/1000 | Loss: 0.00001754
Iteration 263/1000 | Loss: 0.00001754
Iteration 264/1000 | Loss: 0.00001754
Iteration 265/1000 | Loss: 0.00001754
Iteration 266/1000 | Loss: 0.00001753
Iteration 267/1000 | Loss: 0.00001753
Iteration 268/1000 | Loss: 0.00001753
Iteration 269/1000 | Loss: 0.00001753
Iteration 270/1000 | Loss: 0.00001753
Iteration 271/1000 | Loss: 0.00001753
Iteration 272/1000 | Loss: 0.00001753
Iteration 273/1000 | Loss: 0.00001753
Iteration 274/1000 | Loss: 0.00001748
Iteration 275/1000 | Loss: 0.00001747
Iteration 276/1000 | Loss: 0.00001747
Iteration 277/1000 | Loss: 0.00001746
Iteration 278/1000 | Loss: 0.00001746
Iteration 279/1000 | Loss: 0.00001745
Iteration 280/1000 | Loss: 0.00001745
Iteration 281/1000 | Loss: 0.00001745
Iteration 282/1000 | Loss: 0.00001744
Iteration 283/1000 | Loss: 0.00001743
Iteration 284/1000 | Loss: 0.00001742
Iteration 285/1000 | Loss: 0.00001741
Iteration 286/1000 | Loss: 0.00001741
Iteration 287/1000 | Loss: 0.00001741
Iteration 288/1000 | Loss: 0.00001741
Iteration 289/1000 | Loss: 0.00001739
Iteration 290/1000 | Loss: 0.00001739
Iteration 291/1000 | Loss: 0.00001739
Iteration 292/1000 | Loss: 0.00001739
Iteration 293/1000 | Loss: 0.00001739
Iteration 294/1000 | Loss: 0.00001738
Iteration 295/1000 | Loss: 0.00001738
Iteration 296/1000 | Loss: 0.00001737
Iteration 297/1000 | Loss: 0.00001737
Iteration 298/1000 | Loss: 0.00001737
Iteration 299/1000 | Loss: 0.00001737
Iteration 300/1000 | Loss: 0.00001736
Iteration 301/1000 | Loss: 0.00001736
Iteration 302/1000 | Loss: 0.00001736
Iteration 303/1000 | Loss: 0.00001736
Iteration 304/1000 | Loss: 0.00001735
Iteration 305/1000 | Loss: 0.00001735
Iteration 306/1000 | Loss: 0.00001735
Iteration 307/1000 | Loss: 0.00001735
Iteration 308/1000 | Loss: 0.00001735
Iteration 309/1000 | Loss: 0.00001734
Iteration 310/1000 | Loss: 0.00001734
Iteration 311/1000 | Loss: 0.00001734
Iteration 312/1000 | Loss: 0.00001734
Iteration 313/1000 | Loss: 0.00001734
Iteration 314/1000 | Loss: 0.00001734
Iteration 315/1000 | Loss: 0.00001734
Iteration 316/1000 | Loss: 0.00001733
Iteration 317/1000 | Loss: 0.00001733
Iteration 318/1000 | Loss: 0.00001733
Iteration 319/1000 | Loss: 0.00001733
Iteration 320/1000 | Loss: 0.00001733
Iteration 321/1000 | Loss: 0.00001733
Iteration 322/1000 | Loss: 0.00001733
Iteration 323/1000 | Loss: 0.00001733
Iteration 324/1000 | Loss: 0.00001733
Iteration 325/1000 | Loss: 0.00001733
Iteration 326/1000 | Loss: 0.00001732
Iteration 327/1000 | Loss: 0.00001732
Iteration 328/1000 | Loss: 0.00001732
Iteration 329/1000 | Loss: 0.00001732
Iteration 330/1000 | Loss: 0.00001732
Iteration 331/1000 | Loss: 0.00001731
Iteration 332/1000 | Loss: 0.00001731
Iteration 333/1000 | Loss: 0.00001731
Iteration 334/1000 | Loss: 0.00001731
Iteration 335/1000 | Loss: 0.00001730
Iteration 336/1000 | Loss: 0.00001730
Iteration 337/1000 | Loss: 0.00001730
Iteration 338/1000 | Loss: 0.00001730
Iteration 339/1000 | Loss: 0.00001730
Iteration 340/1000 | Loss: 0.00001729
Iteration 341/1000 | Loss: 0.00001729
Iteration 342/1000 | Loss: 0.00005490
Iteration 343/1000 | Loss: 0.00004391
Iteration 344/1000 | Loss: 0.00001726
Iteration 345/1000 | Loss: 0.00001725
Iteration 346/1000 | Loss: 0.00001725
Iteration 347/1000 | Loss: 0.00001725
Iteration 348/1000 | Loss: 0.00001725
Iteration 349/1000 | Loss: 0.00001724
Iteration 350/1000 | Loss: 0.00001724
Iteration 351/1000 | Loss: 0.00001724
Iteration 352/1000 | Loss: 0.00001724
Iteration 353/1000 | Loss: 0.00001723
Iteration 354/1000 | Loss: 0.00001723
Iteration 355/1000 | Loss: 0.00001723
Iteration 356/1000 | Loss: 0.00001722
Iteration 357/1000 | Loss: 0.00001722
Iteration 358/1000 | Loss: 0.00001722
Iteration 359/1000 | Loss: 0.00001722
Iteration 360/1000 | Loss: 0.00001722
Iteration 361/1000 | Loss: 0.00001722
Iteration 362/1000 | Loss: 0.00001722
Iteration 363/1000 | Loss: 0.00001722
Iteration 364/1000 | Loss: 0.00001722
Iteration 365/1000 | Loss: 0.00001722
Iteration 366/1000 | Loss: 0.00001722
Iteration 367/1000 | Loss: 0.00001722
Iteration 368/1000 | Loss: 0.00001722
Iteration 369/1000 | Loss: 0.00001721
Iteration 370/1000 | Loss: 0.00001721
Iteration 371/1000 | Loss: 0.00001721
Iteration 372/1000 | Loss: 0.00001721
Iteration 373/1000 | Loss: 0.00001721
Iteration 374/1000 | Loss: 0.00001721
Iteration 375/1000 | Loss: 0.00001721
Iteration 376/1000 | Loss: 0.00001721
Iteration 377/1000 | Loss: 0.00001721
Iteration 378/1000 | Loss: 0.00001721
Iteration 379/1000 | Loss: 0.00001721
Iteration 380/1000 | Loss: 0.00001721
Iteration 381/1000 | Loss: 0.00001721
Iteration 382/1000 | Loss: 0.00001721
Iteration 383/1000 | Loss: 0.00001721
Iteration 384/1000 | Loss: 0.00001721
Iteration 385/1000 | Loss: 0.00001721
Iteration 386/1000 | Loss: 0.00001721
Iteration 387/1000 | Loss: 0.00001721
Iteration 388/1000 | Loss: 0.00001721
Iteration 389/1000 | Loss: 0.00001721
Iteration 390/1000 | Loss: 0.00001721
Iteration 391/1000 | Loss: 0.00001721
Iteration 392/1000 | Loss: 0.00001721
Iteration 393/1000 | Loss: 0.00001721
Iteration 394/1000 | Loss: 0.00001721
Iteration 395/1000 | Loss: 0.00001721
Iteration 396/1000 | Loss: 0.00001721
Iteration 397/1000 | Loss: 0.00001721
Iteration 398/1000 | Loss: 0.00001721
Iteration 399/1000 | Loss: 0.00001721
Iteration 400/1000 | Loss: 0.00001721
Iteration 401/1000 | Loss: 0.00001721
Iteration 402/1000 | Loss: 0.00001721
Iteration 403/1000 | Loss: 0.00001721
Iteration 404/1000 | Loss: 0.00001721
Iteration 405/1000 | Loss: 0.00001721
Iteration 406/1000 | Loss: 0.00001721
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 406. Stopping optimization.
Last 5 losses: [1.7205476979142986e-05, 1.7205476979142986e-05, 1.7205476979142986e-05, 1.7205476979142986e-05, 1.7205476979142986e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7205476979142986e-05

Optimization complete. Final v2v error: 3.3938205242156982 mm

Highest mean error: 6.8930559158325195 mm for frame 220

Lowest mean error: 3.130652666091919 mm for frame 200

Saving results

Total time: 468.5221345424652
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00569899
Iteration 2/25 | Loss: 0.00093919
Iteration 3/25 | Loss: 0.00081663
Iteration 4/25 | Loss: 0.00079393
Iteration 5/25 | Loss: 0.00078970
Iteration 6/25 | Loss: 0.00078913
Iteration 7/25 | Loss: 0.00078904
Iteration 8/25 | Loss: 0.00078904
Iteration 9/25 | Loss: 0.00078904
Iteration 10/25 | Loss: 0.00078904
Iteration 11/25 | Loss: 0.00078904
Iteration 12/25 | Loss: 0.00078904
Iteration 13/25 | Loss: 0.00078904
Iteration 14/25 | Loss: 0.00078904
Iteration 15/25 | Loss: 0.00078904
Iteration 16/25 | Loss: 0.00078904
Iteration 17/25 | Loss: 0.00078904
Iteration 18/25 | Loss: 0.00078904
Iteration 19/25 | Loss: 0.00078904
Iteration 20/25 | Loss: 0.00078904
Iteration 21/25 | Loss: 0.00078904
Iteration 22/25 | Loss: 0.00078904
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0007890426204539835, 0.0007890426204539835, 0.0007890426204539835, 0.0007890426204539835, 0.0007890426204539835]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007890426204539835

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43197155
Iteration 2/25 | Loss: 0.00033917
Iteration 3/25 | Loss: 0.00033913
Iteration 4/25 | Loss: 0.00033913
Iteration 5/25 | Loss: 0.00033913
Iteration 6/25 | Loss: 0.00033913
Iteration 7/25 | Loss: 0.00033913
Iteration 8/25 | Loss: 0.00033913
Iteration 9/25 | Loss: 0.00033913
Iteration 10/25 | Loss: 0.00033913
Iteration 11/25 | Loss: 0.00033913
Iteration 12/25 | Loss: 0.00033913
Iteration 13/25 | Loss: 0.00033913
Iteration 14/25 | Loss: 0.00033913
Iteration 15/25 | Loss: 0.00033913
Iteration 16/25 | Loss: 0.00033913
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.00033913200604729354, 0.00033913200604729354, 0.00033913200604729354, 0.00033913200604729354, 0.00033913200604729354]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00033913200604729354

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00033913
Iteration 2/1000 | Loss: 0.00003521
Iteration 3/1000 | Loss: 0.00002562
Iteration 4/1000 | Loss: 0.00002344
Iteration 5/1000 | Loss: 0.00002224
Iteration 6/1000 | Loss: 0.00002162
Iteration 7/1000 | Loss: 0.00002116
Iteration 8/1000 | Loss: 0.00002084
Iteration 9/1000 | Loss: 0.00002056
Iteration 10/1000 | Loss: 0.00002037
Iteration 11/1000 | Loss: 0.00002035
Iteration 12/1000 | Loss: 0.00002027
Iteration 13/1000 | Loss: 0.00002024
Iteration 14/1000 | Loss: 0.00002018
Iteration 15/1000 | Loss: 0.00002009
Iteration 16/1000 | Loss: 0.00002001
Iteration 17/1000 | Loss: 0.00001997
Iteration 18/1000 | Loss: 0.00001996
Iteration 19/1000 | Loss: 0.00001996
Iteration 20/1000 | Loss: 0.00001995
Iteration 21/1000 | Loss: 0.00001995
Iteration 22/1000 | Loss: 0.00001994
Iteration 23/1000 | Loss: 0.00001994
Iteration 24/1000 | Loss: 0.00001994
Iteration 25/1000 | Loss: 0.00001994
Iteration 26/1000 | Loss: 0.00001994
Iteration 27/1000 | Loss: 0.00001993
Iteration 28/1000 | Loss: 0.00001993
Iteration 29/1000 | Loss: 0.00001993
Iteration 30/1000 | Loss: 0.00001993
Iteration 31/1000 | Loss: 0.00001993
Iteration 32/1000 | Loss: 0.00001992
Iteration 33/1000 | Loss: 0.00001992
Iteration 34/1000 | Loss: 0.00001992
Iteration 35/1000 | Loss: 0.00001992
Iteration 36/1000 | Loss: 0.00001991
Iteration 37/1000 | Loss: 0.00001991
Iteration 38/1000 | Loss: 0.00001990
Iteration 39/1000 | Loss: 0.00001990
Iteration 40/1000 | Loss: 0.00001990
Iteration 41/1000 | Loss: 0.00001989
Iteration 42/1000 | Loss: 0.00001989
Iteration 43/1000 | Loss: 0.00001989
Iteration 44/1000 | Loss: 0.00001989
Iteration 45/1000 | Loss: 0.00001989
Iteration 46/1000 | Loss: 0.00001989
Iteration 47/1000 | Loss: 0.00001988
Iteration 48/1000 | Loss: 0.00001988
Iteration 49/1000 | Loss: 0.00001988
Iteration 50/1000 | Loss: 0.00001987
Iteration 51/1000 | Loss: 0.00001987
Iteration 52/1000 | Loss: 0.00001986
Iteration 53/1000 | Loss: 0.00001986
Iteration 54/1000 | Loss: 0.00001986
Iteration 55/1000 | Loss: 0.00001986
Iteration 56/1000 | Loss: 0.00001985
Iteration 57/1000 | Loss: 0.00001985
Iteration 58/1000 | Loss: 0.00001985
Iteration 59/1000 | Loss: 0.00001984
Iteration 60/1000 | Loss: 0.00001984
Iteration 61/1000 | Loss: 0.00001984
Iteration 62/1000 | Loss: 0.00001983
Iteration 63/1000 | Loss: 0.00001983
Iteration 64/1000 | Loss: 0.00001979
Iteration 65/1000 | Loss: 0.00001978
Iteration 66/1000 | Loss: 0.00001977
Iteration 67/1000 | Loss: 0.00001977
Iteration 68/1000 | Loss: 0.00001977
Iteration 69/1000 | Loss: 0.00001976
Iteration 70/1000 | Loss: 0.00001976
Iteration 71/1000 | Loss: 0.00001975
Iteration 72/1000 | Loss: 0.00001975
Iteration 73/1000 | Loss: 0.00001973
Iteration 74/1000 | Loss: 0.00001973
Iteration 75/1000 | Loss: 0.00001973
Iteration 76/1000 | Loss: 0.00001973
Iteration 77/1000 | Loss: 0.00001973
Iteration 78/1000 | Loss: 0.00001973
Iteration 79/1000 | Loss: 0.00001972
Iteration 80/1000 | Loss: 0.00001972
Iteration 81/1000 | Loss: 0.00001972
Iteration 82/1000 | Loss: 0.00001972
Iteration 83/1000 | Loss: 0.00001971
Iteration 84/1000 | Loss: 0.00001971
Iteration 85/1000 | Loss: 0.00001970
Iteration 86/1000 | Loss: 0.00001970
Iteration 87/1000 | Loss: 0.00001970
Iteration 88/1000 | Loss: 0.00001970
Iteration 89/1000 | Loss: 0.00001970
Iteration 90/1000 | Loss: 0.00001970
Iteration 91/1000 | Loss: 0.00001970
Iteration 92/1000 | Loss: 0.00001969
Iteration 93/1000 | Loss: 0.00001969
Iteration 94/1000 | Loss: 0.00001969
Iteration 95/1000 | Loss: 0.00001969
Iteration 96/1000 | Loss: 0.00001969
Iteration 97/1000 | Loss: 0.00001969
Iteration 98/1000 | Loss: 0.00001969
Iteration 99/1000 | Loss: 0.00001969
Iteration 100/1000 | Loss: 0.00001969
Iteration 101/1000 | Loss: 0.00001968
Iteration 102/1000 | Loss: 0.00001968
Iteration 103/1000 | Loss: 0.00001968
Iteration 104/1000 | Loss: 0.00001968
Iteration 105/1000 | Loss: 0.00001968
Iteration 106/1000 | Loss: 0.00001968
Iteration 107/1000 | Loss: 0.00001968
Iteration 108/1000 | Loss: 0.00001968
Iteration 109/1000 | Loss: 0.00001968
Iteration 110/1000 | Loss: 0.00001968
Iteration 111/1000 | Loss: 0.00001967
Iteration 112/1000 | Loss: 0.00001967
Iteration 113/1000 | Loss: 0.00001967
Iteration 114/1000 | Loss: 0.00001967
Iteration 115/1000 | Loss: 0.00001967
Iteration 116/1000 | Loss: 0.00001967
Iteration 117/1000 | Loss: 0.00001967
Iteration 118/1000 | Loss: 0.00001967
Iteration 119/1000 | Loss: 0.00001967
Iteration 120/1000 | Loss: 0.00001967
Iteration 121/1000 | Loss: 0.00001967
Iteration 122/1000 | Loss: 0.00001967
Iteration 123/1000 | Loss: 0.00001967
Iteration 124/1000 | Loss: 0.00001967
Iteration 125/1000 | Loss: 0.00001967
Iteration 126/1000 | Loss: 0.00001967
Iteration 127/1000 | Loss: 0.00001967
Iteration 128/1000 | Loss: 0.00001967
Iteration 129/1000 | Loss: 0.00001967
Iteration 130/1000 | Loss: 0.00001967
Iteration 131/1000 | Loss: 0.00001967
Iteration 132/1000 | Loss: 0.00001967
Iteration 133/1000 | Loss: 0.00001967
Iteration 134/1000 | Loss: 0.00001967
Iteration 135/1000 | Loss: 0.00001967
Iteration 136/1000 | Loss: 0.00001967
Iteration 137/1000 | Loss: 0.00001967
Iteration 138/1000 | Loss: 0.00001967
Iteration 139/1000 | Loss: 0.00001967
Iteration 140/1000 | Loss: 0.00001967
Iteration 141/1000 | Loss: 0.00001967
Iteration 142/1000 | Loss: 0.00001967
Iteration 143/1000 | Loss: 0.00001967
Iteration 144/1000 | Loss: 0.00001967
Iteration 145/1000 | Loss: 0.00001967
Iteration 146/1000 | Loss: 0.00001967
Iteration 147/1000 | Loss: 0.00001967
Iteration 148/1000 | Loss: 0.00001967
Iteration 149/1000 | Loss: 0.00001967
Iteration 150/1000 | Loss: 0.00001967
Iteration 151/1000 | Loss: 0.00001967
Iteration 152/1000 | Loss: 0.00001967
Iteration 153/1000 | Loss: 0.00001967
Iteration 154/1000 | Loss: 0.00001967
Iteration 155/1000 | Loss: 0.00001967
Iteration 156/1000 | Loss: 0.00001967
Iteration 157/1000 | Loss: 0.00001967
Iteration 158/1000 | Loss: 0.00001967
Iteration 159/1000 | Loss: 0.00001967
Iteration 160/1000 | Loss: 0.00001967
Iteration 161/1000 | Loss: 0.00001967
Iteration 162/1000 | Loss: 0.00001967
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [1.9669081666506827e-05, 1.9669081666506827e-05, 1.9669081666506827e-05, 1.9669081666506827e-05, 1.9669081666506827e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9669081666506827e-05

Optimization complete. Final v2v error: 3.7577574253082275 mm

Highest mean error: 4.136826992034912 mm for frame 122

Lowest mean error: 3.26499605178833 mm for frame 36

Saving results

Total time: 38.340455055236816
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1032/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1032.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1032
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00807636
Iteration 2/25 | Loss: 0.00103196
Iteration 3/25 | Loss: 0.00086908
Iteration 4/25 | Loss: 0.00083626
Iteration 5/25 | Loss: 0.00082473
Iteration 6/25 | Loss: 0.00082076
Iteration 7/25 | Loss: 0.00081938
Iteration 8/25 | Loss: 0.00081916
Iteration 9/25 | Loss: 0.00081916
Iteration 10/25 | Loss: 0.00081916
Iteration 11/25 | Loss: 0.00081916
Iteration 12/25 | Loss: 0.00081916
Iteration 13/25 | Loss: 0.00081916
Iteration 14/25 | Loss: 0.00081916
Iteration 15/25 | Loss: 0.00081916
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008191561209969223, 0.0008191561209969223, 0.0008191561209969223, 0.0008191561209969223, 0.0008191561209969223]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008191561209969223

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46998465
Iteration 2/25 | Loss: 0.00034820
Iteration 3/25 | Loss: 0.00034820
Iteration 4/25 | Loss: 0.00034820
Iteration 5/25 | Loss: 0.00034820
Iteration 6/25 | Loss: 0.00034820
Iteration 7/25 | Loss: 0.00034820
Iteration 8/25 | Loss: 0.00034820
Iteration 9/25 | Loss: 0.00034819
Iteration 10/25 | Loss: 0.00034819
Iteration 11/25 | Loss: 0.00034819
Iteration 12/25 | Loss: 0.00034819
Iteration 13/25 | Loss: 0.00034819
Iteration 14/25 | Loss: 0.00034819
Iteration 15/25 | Loss: 0.00034819
Iteration 16/25 | Loss: 0.00034819
Iteration 17/25 | Loss: 0.00034819
Iteration 18/25 | Loss: 0.00034819
Iteration 19/25 | Loss: 0.00034819
Iteration 20/25 | Loss: 0.00034819
Iteration 21/25 | Loss: 0.00034819
Iteration 22/25 | Loss: 0.00034819
Iteration 23/25 | Loss: 0.00034819
Iteration 24/25 | Loss: 0.00034819
Iteration 25/25 | Loss: 0.00034819
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00034819458960555494, 0.00034819458960555494, 0.00034819458960555494, 0.00034819458960555494, 0.00034819458960555494]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00034819458960555494

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034819
Iteration 2/1000 | Loss: 0.00004249
Iteration 3/1000 | Loss: 0.00003072
Iteration 4/1000 | Loss: 0.00002777
Iteration 5/1000 | Loss: 0.00002634
Iteration 6/1000 | Loss: 0.00002536
Iteration 7/1000 | Loss: 0.00002474
Iteration 8/1000 | Loss: 0.00002431
Iteration 9/1000 | Loss: 0.00002396
Iteration 10/1000 | Loss: 0.00002370
Iteration 11/1000 | Loss: 0.00002352
Iteration 12/1000 | Loss: 0.00002338
Iteration 13/1000 | Loss: 0.00002326
Iteration 14/1000 | Loss: 0.00002320
Iteration 15/1000 | Loss: 0.00002317
Iteration 16/1000 | Loss: 0.00002316
Iteration 17/1000 | Loss: 0.00002315
Iteration 18/1000 | Loss: 0.00002314
Iteration 19/1000 | Loss: 0.00002314
Iteration 20/1000 | Loss: 0.00002313
Iteration 21/1000 | Loss: 0.00002312
Iteration 22/1000 | Loss: 0.00002312
Iteration 23/1000 | Loss: 0.00002311
Iteration 24/1000 | Loss: 0.00002311
Iteration 25/1000 | Loss: 0.00002310
Iteration 26/1000 | Loss: 0.00002310
Iteration 27/1000 | Loss: 0.00002309
Iteration 28/1000 | Loss: 0.00002309
Iteration 29/1000 | Loss: 0.00002309
Iteration 30/1000 | Loss: 0.00002308
Iteration 31/1000 | Loss: 0.00002308
Iteration 32/1000 | Loss: 0.00002308
Iteration 33/1000 | Loss: 0.00002307
Iteration 34/1000 | Loss: 0.00002307
Iteration 35/1000 | Loss: 0.00002306
Iteration 36/1000 | Loss: 0.00002306
Iteration 37/1000 | Loss: 0.00002305
Iteration 38/1000 | Loss: 0.00002305
Iteration 39/1000 | Loss: 0.00002304
Iteration 40/1000 | Loss: 0.00002304
Iteration 41/1000 | Loss: 0.00002304
Iteration 42/1000 | Loss: 0.00002304
Iteration 43/1000 | Loss: 0.00002304
Iteration 44/1000 | Loss: 0.00002303
Iteration 45/1000 | Loss: 0.00002303
Iteration 46/1000 | Loss: 0.00002302
Iteration 47/1000 | Loss: 0.00002302
Iteration 48/1000 | Loss: 0.00002302
Iteration 49/1000 | Loss: 0.00002302
Iteration 50/1000 | Loss: 0.00002301
Iteration 51/1000 | Loss: 0.00002301
Iteration 52/1000 | Loss: 0.00002301
Iteration 53/1000 | Loss: 0.00002301
Iteration 54/1000 | Loss: 0.00002300
Iteration 55/1000 | Loss: 0.00002300
Iteration 56/1000 | Loss: 0.00002298
Iteration 57/1000 | Loss: 0.00002298
Iteration 58/1000 | Loss: 0.00002298
Iteration 59/1000 | Loss: 0.00002298
Iteration 60/1000 | Loss: 0.00002298
Iteration 61/1000 | Loss: 0.00002298
Iteration 62/1000 | Loss: 0.00002298
Iteration 63/1000 | Loss: 0.00002297
Iteration 64/1000 | Loss: 0.00002297
Iteration 65/1000 | Loss: 0.00002297
Iteration 66/1000 | Loss: 0.00002296
Iteration 67/1000 | Loss: 0.00002296
Iteration 68/1000 | Loss: 0.00002295
Iteration 69/1000 | Loss: 0.00002295
Iteration 70/1000 | Loss: 0.00002295
Iteration 71/1000 | Loss: 0.00002294
Iteration 72/1000 | Loss: 0.00002294
Iteration 73/1000 | Loss: 0.00002294
Iteration 74/1000 | Loss: 0.00002294
Iteration 75/1000 | Loss: 0.00002293
Iteration 76/1000 | Loss: 0.00002293
Iteration 77/1000 | Loss: 0.00002293
Iteration 78/1000 | Loss: 0.00002293
Iteration 79/1000 | Loss: 0.00002293
Iteration 80/1000 | Loss: 0.00002293
Iteration 81/1000 | Loss: 0.00002293
Iteration 82/1000 | Loss: 0.00002292
Iteration 83/1000 | Loss: 0.00002292
Iteration 84/1000 | Loss: 0.00002292
Iteration 85/1000 | Loss: 0.00002292
Iteration 86/1000 | Loss: 0.00002291
Iteration 87/1000 | Loss: 0.00002291
Iteration 88/1000 | Loss: 0.00002291
Iteration 89/1000 | Loss: 0.00002290
Iteration 90/1000 | Loss: 0.00002290
Iteration 91/1000 | Loss: 0.00002290
Iteration 92/1000 | Loss: 0.00002290
Iteration 93/1000 | Loss: 0.00002290
Iteration 94/1000 | Loss: 0.00002290
Iteration 95/1000 | Loss: 0.00002290
Iteration 96/1000 | Loss: 0.00002290
Iteration 97/1000 | Loss: 0.00002289
Iteration 98/1000 | Loss: 0.00002289
Iteration 99/1000 | Loss: 0.00002289
Iteration 100/1000 | Loss: 0.00002289
Iteration 101/1000 | Loss: 0.00002289
Iteration 102/1000 | Loss: 0.00002289
Iteration 103/1000 | Loss: 0.00002289
Iteration 104/1000 | Loss: 0.00002289
Iteration 105/1000 | Loss: 0.00002288
Iteration 106/1000 | Loss: 0.00002288
Iteration 107/1000 | Loss: 0.00002288
Iteration 108/1000 | Loss: 0.00002288
Iteration 109/1000 | Loss: 0.00002288
Iteration 110/1000 | Loss: 0.00002288
Iteration 111/1000 | Loss: 0.00002288
Iteration 112/1000 | Loss: 0.00002287
Iteration 113/1000 | Loss: 0.00002287
Iteration 114/1000 | Loss: 0.00002287
Iteration 115/1000 | Loss: 0.00002287
Iteration 116/1000 | Loss: 0.00002287
Iteration 117/1000 | Loss: 0.00002287
Iteration 118/1000 | Loss: 0.00002287
Iteration 119/1000 | Loss: 0.00002287
Iteration 120/1000 | Loss: 0.00002287
Iteration 121/1000 | Loss: 0.00002287
Iteration 122/1000 | Loss: 0.00002286
Iteration 123/1000 | Loss: 0.00002286
Iteration 124/1000 | Loss: 0.00002286
Iteration 125/1000 | Loss: 0.00002286
Iteration 126/1000 | Loss: 0.00002286
Iteration 127/1000 | Loss: 0.00002286
Iteration 128/1000 | Loss: 0.00002286
Iteration 129/1000 | Loss: 0.00002286
Iteration 130/1000 | Loss: 0.00002286
Iteration 131/1000 | Loss: 0.00002286
Iteration 132/1000 | Loss: 0.00002286
Iteration 133/1000 | Loss: 0.00002286
Iteration 134/1000 | Loss: 0.00002286
Iteration 135/1000 | Loss: 0.00002286
Iteration 136/1000 | Loss: 0.00002286
Iteration 137/1000 | Loss: 0.00002286
Iteration 138/1000 | Loss: 0.00002286
Iteration 139/1000 | Loss: 0.00002286
Iteration 140/1000 | Loss: 0.00002286
Iteration 141/1000 | Loss: 0.00002286
Iteration 142/1000 | Loss: 0.00002286
Iteration 143/1000 | Loss: 0.00002286
Iteration 144/1000 | Loss: 0.00002286
Iteration 145/1000 | Loss: 0.00002286
Iteration 146/1000 | Loss: 0.00002286
Iteration 147/1000 | Loss: 0.00002286
Iteration 148/1000 | Loss: 0.00002286
Iteration 149/1000 | Loss: 0.00002286
Iteration 150/1000 | Loss: 0.00002286
Iteration 151/1000 | Loss: 0.00002286
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [2.2855971110402606e-05, 2.2855971110402606e-05, 2.2855971110402606e-05, 2.2855971110402606e-05, 2.2855971110402606e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2855971110402606e-05

Optimization complete. Final v2v error: 3.848271608352661 mm

Highest mean error: 4.595108509063721 mm for frame 63

Lowest mean error: 3.175974130630493 mm for frame 1

Saving results

Total time: 41.074368476867676
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1058/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1058.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1058
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01045149
Iteration 2/25 | Loss: 0.00251728
Iteration 3/25 | Loss: 0.00160907
Iteration 4/25 | Loss: 0.00128776
Iteration 5/25 | Loss: 0.00115278
Iteration 6/25 | Loss: 0.00117997
Iteration 7/25 | Loss: 0.00114423
Iteration 8/25 | Loss: 0.00105276
Iteration 9/25 | Loss: 0.00100847
Iteration 10/25 | Loss: 0.00097795
Iteration 11/25 | Loss: 0.00092511
Iteration 12/25 | Loss: 0.00088355
Iteration 13/25 | Loss: 0.00086215
Iteration 14/25 | Loss: 0.00082792
Iteration 15/25 | Loss: 0.00080121
Iteration 16/25 | Loss: 0.00079164
Iteration 17/25 | Loss: 0.00079773
Iteration 18/25 | Loss: 0.00079059
Iteration 19/25 | Loss: 0.00078434
Iteration 20/25 | Loss: 0.00077446
Iteration 21/25 | Loss: 0.00076959
Iteration 22/25 | Loss: 0.00076308
Iteration 23/25 | Loss: 0.00075586
Iteration 24/25 | Loss: 0.00075650
Iteration 25/25 | Loss: 0.00075598

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48181796
Iteration 2/25 | Loss: 0.00144930
Iteration 3/25 | Loss: 0.00050926
Iteration 4/25 | Loss: 0.00050926
Iteration 5/25 | Loss: 0.00050926
Iteration 6/25 | Loss: 0.00050926
Iteration 7/25 | Loss: 0.00050926
Iteration 8/25 | Loss: 0.00050926
Iteration 9/25 | Loss: 0.00050926
Iteration 10/25 | Loss: 0.00050926
Iteration 11/25 | Loss: 0.00050926
Iteration 12/25 | Loss: 0.00050926
Iteration 13/25 | Loss: 0.00050926
Iteration 14/25 | Loss: 0.00050926
Iteration 15/25 | Loss: 0.00050926
Iteration 16/25 | Loss: 0.00050926
Iteration 17/25 | Loss: 0.00050926
Iteration 18/25 | Loss: 0.00050926
Iteration 19/25 | Loss: 0.00050926
Iteration 20/25 | Loss: 0.00050926
Iteration 21/25 | Loss: 0.00050926
Iteration 22/25 | Loss: 0.00050926
Iteration 23/25 | Loss: 0.00050926
Iteration 24/25 | Loss: 0.00050926
Iteration 25/25 | Loss: 0.00050926
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0005092572537250817, 0.0005092572537250817, 0.0005092572537250817, 0.0005092572537250817, 0.0005092572537250817]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005092572537250817

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050926
Iteration 2/1000 | Loss: 0.00025469
Iteration 3/1000 | Loss: 0.00033658
Iteration 4/1000 | Loss: 0.00038044
Iteration 5/1000 | Loss: 0.00025439
Iteration 6/1000 | Loss: 0.00035663
Iteration 7/1000 | Loss: 0.00007177
Iteration 8/1000 | Loss: 0.00008563
Iteration 9/1000 | Loss: 0.00040449
Iteration 10/1000 | Loss: 0.00006986
Iteration 11/1000 | Loss: 0.00030856
Iteration 12/1000 | Loss: 0.00026879
Iteration 13/1000 | Loss: 0.00023156
Iteration 14/1000 | Loss: 0.00020194
Iteration 15/1000 | Loss: 0.00005262
Iteration 16/1000 | Loss: 0.00020124
Iteration 17/1000 | Loss: 0.00029276
Iteration 18/1000 | Loss: 0.00034642
Iteration 19/1000 | Loss: 0.00020454
Iteration 20/1000 | Loss: 0.00021484
Iteration 21/1000 | Loss: 0.00026019
Iteration 22/1000 | Loss: 0.00034678
Iteration 23/1000 | Loss: 0.00048017
Iteration 24/1000 | Loss: 0.00051939
Iteration 25/1000 | Loss: 0.00030825
Iteration 26/1000 | Loss: 0.00037422
Iteration 27/1000 | Loss: 0.00045202
Iteration 28/1000 | Loss: 0.00026589
Iteration 29/1000 | Loss: 0.00026443
Iteration 30/1000 | Loss: 0.00038189
Iteration 31/1000 | Loss: 0.00023075
Iteration 32/1000 | Loss: 0.00014209
Iteration 33/1000 | Loss: 0.00053786
Iteration 34/1000 | Loss: 0.00038815
Iteration 35/1000 | Loss: 0.00028654
Iteration 36/1000 | Loss: 0.00058424
Iteration 37/1000 | Loss: 0.00034983
Iteration 38/1000 | Loss: 0.00017837
Iteration 39/1000 | Loss: 0.00008217
Iteration 40/1000 | Loss: 0.00011148
Iteration 41/1000 | Loss: 0.00020769
Iteration 42/1000 | Loss: 0.00010857
Iteration 43/1000 | Loss: 0.00032822
Iteration 44/1000 | Loss: 0.00021378
Iteration 45/1000 | Loss: 0.00015784
Iteration 46/1000 | Loss: 0.00021303
Iteration 47/1000 | Loss: 0.00020837
Iteration 48/1000 | Loss: 0.00017310
Iteration 49/1000 | Loss: 0.00012595
Iteration 50/1000 | Loss: 0.00005138
Iteration 51/1000 | Loss: 0.00040041
Iteration 52/1000 | Loss: 0.00040814
Iteration 53/1000 | Loss: 0.00049373
Iteration 54/1000 | Loss: 0.00025190
Iteration 55/1000 | Loss: 0.00004780
Iteration 56/1000 | Loss: 0.00002876
Iteration 57/1000 | Loss: 0.00029144
Iteration 58/1000 | Loss: 0.00029695
Iteration 59/1000 | Loss: 0.00035860
Iteration 60/1000 | Loss: 0.00038869
Iteration 61/1000 | Loss: 0.00028702
Iteration 62/1000 | Loss: 0.00007955
Iteration 63/1000 | Loss: 0.00024950
Iteration 64/1000 | Loss: 0.00027192
Iteration 65/1000 | Loss: 0.00026153
Iteration 66/1000 | Loss: 0.00023756
Iteration 67/1000 | Loss: 0.00041728
Iteration 68/1000 | Loss: 0.00060134
Iteration 69/1000 | Loss: 0.00036068
Iteration 70/1000 | Loss: 0.00041493
Iteration 71/1000 | Loss: 0.00043939
Iteration 72/1000 | Loss: 0.00045348
Iteration 73/1000 | Loss: 0.00059534
Iteration 74/1000 | Loss: 0.00042097
Iteration 75/1000 | Loss: 0.00047325
Iteration 76/1000 | Loss: 0.00017515
Iteration 77/1000 | Loss: 0.00046923
Iteration 78/1000 | Loss: 0.00049908
Iteration 79/1000 | Loss: 0.00039761
Iteration 80/1000 | Loss: 0.00041091
Iteration 81/1000 | Loss: 0.00055017
Iteration 82/1000 | Loss: 0.00040213
Iteration 83/1000 | Loss: 0.00054248
Iteration 84/1000 | Loss: 0.00044073
Iteration 85/1000 | Loss: 0.00054368
Iteration 86/1000 | Loss: 0.00047974
Iteration 87/1000 | Loss: 0.00048609
Iteration 88/1000 | Loss: 0.00041934
Iteration 89/1000 | Loss: 0.00060680
Iteration 90/1000 | Loss: 0.00030532
Iteration 91/1000 | Loss: 0.00052479
Iteration 92/1000 | Loss: 0.00060018
Iteration 93/1000 | Loss: 0.00055662
Iteration 94/1000 | Loss: 0.00019600
Iteration 95/1000 | Loss: 0.00010206
Iteration 96/1000 | Loss: 0.00003455
Iteration 97/1000 | Loss: 0.00010435
Iteration 98/1000 | Loss: 0.00028371
Iteration 99/1000 | Loss: 0.00013557
Iteration 100/1000 | Loss: 0.00017517
Iteration 101/1000 | Loss: 0.00034654
Iteration 102/1000 | Loss: 0.00105563
Iteration 103/1000 | Loss: 0.00030977
Iteration 104/1000 | Loss: 0.00076251
Iteration 105/1000 | Loss: 0.00070009
Iteration 106/1000 | Loss: 0.00011007
Iteration 107/1000 | Loss: 0.00004305
Iteration 108/1000 | Loss: 0.00003363
Iteration 109/1000 | Loss: 0.00002786
Iteration 110/1000 | Loss: 0.00044010
Iteration 111/1000 | Loss: 0.00005669
Iteration 112/1000 | Loss: 0.00005984
Iteration 113/1000 | Loss: 0.00012184
Iteration 114/1000 | Loss: 0.00002750
Iteration 115/1000 | Loss: 0.00012677
Iteration 116/1000 | Loss: 0.00002466
Iteration 117/1000 | Loss: 0.00002194
Iteration 118/1000 | Loss: 0.00047619
Iteration 119/1000 | Loss: 0.00008787
Iteration 120/1000 | Loss: 0.00037315
Iteration 121/1000 | Loss: 0.00038637
Iteration 122/1000 | Loss: 0.00072014
Iteration 123/1000 | Loss: 0.00002932
Iteration 124/1000 | Loss: 0.00007511
Iteration 125/1000 | Loss: 0.00002458
Iteration 126/1000 | Loss: 0.00002375
Iteration 127/1000 | Loss: 0.00091502
Iteration 128/1000 | Loss: 0.00031100
Iteration 129/1000 | Loss: 0.00006782
Iteration 130/1000 | Loss: 0.00002390
Iteration 131/1000 | Loss: 0.00002165
Iteration 132/1000 | Loss: 0.00032039
Iteration 133/1000 | Loss: 0.00042136
Iteration 134/1000 | Loss: 0.00013427
Iteration 135/1000 | Loss: 0.00024123
Iteration 136/1000 | Loss: 0.00034403
Iteration 137/1000 | Loss: 0.00023192
Iteration 138/1000 | Loss: 0.00033824
Iteration 139/1000 | Loss: 0.00035351
Iteration 140/1000 | Loss: 0.00029662
Iteration 141/1000 | Loss: 0.00024074
Iteration 142/1000 | Loss: 0.00003140
Iteration 143/1000 | Loss: 0.00040270
Iteration 144/1000 | Loss: 0.00034218
Iteration 145/1000 | Loss: 0.00003587
Iteration 146/1000 | Loss: 0.00002714
Iteration 147/1000 | Loss: 0.00002279
Iteration 148/1000 | Loss: 0.00005040
Iteration 149/1000 | Loss: 0.00002209
Iteration 150/1000 | Loss: 0.00001736
Iteration 151/1000 | Loss: 0.00010757
Iteration 152/1000 | Loss: 0.00002544
Iteration 153/1000 | Loss: 0.00001620
Iteration 154/1000 | Loss: 0.00001589
Iteration 155/1000 | Loss: 0.00001589
Iteration 156/1000 | Loss: 0.00001580
Iteration 157/1000 | Loss: 0.00001538
Iteration 158/1000 | Loss: 0.00001510
Iteration 159/1000 | Loss: 0.00001497
Iteration 160/1000 | Loss: 0.00001492
Iteration 161/1000 | Loss: 0.00001491
Iteration 162/1000 | Loss: 0.00001481
Iteration 163/1000 | Loss: 0.00001480
Iteration 164/1000 | Loss: 0.00001480
Iteration 165/1000 | Loss: 0.00001479
Iteration 166/1000 | Loss: 0.00001479
Iteration 167/1000 | Loss: 0.00001478
Iteration 168/1000 | Loss: 0.00001477
Iteration 169/1000 | Loss: 0.00001474
Iteration 170/1000 | Loss: 0.00001474
Iteration 171/1000 | Loss: 0.00001473
Iteration 172/1000 | Loss: 0.00001473
Iteration 173/1000 | Loss: 0.00001472
Iteration 174/1000 | Loss: 0.00001472
Iteration 175/1000 | Loss: 0.00001471
Iteration 176/1000 | Loss: 0.00001471
Iteration 177/1000 | Loss: 0.00001470
Iteration 178/1000 | Loss: 0.00001470
Iteration 179/1000 | Loss: 0.00001469
Iteration 180/1000 | Loss: 0.00001469
Iteration 181/1000 | Loss: 0.00001469
Iteration 182/1000 | Loss: 0.00001469
Iteration 183/1000 | Loss: 0.00001468
Iteration 184/1000 | Loss: 0.00001468
Iteration 185/1000 | Loss: 0.00001468
Iteration 186/1000 | Loss: 0.00001468
Iteration 187/1000 | Loss: 0.00001467
Iteration 188/1000 | Loss: 0.00001467
Iteration 189/1000 | Loss: 0.00001466
Iteration 190/1000 | Loss: 0.00001466
Iteration 191/1000 | Loss: 0.00001466
Iteration 192/1000 | Loss: 0.00001466
Iteration 193/1000 | Loss: 0.00001465
Iteration 194/1000 | Loss: 0.00001464
Iteration 195/1000 | Loss: 0.00001464
Iteration 196/1000 | Loss: 0.00001463
Iteration 197/1000 | Loss: 0.00001463
Iteration 198/1000 | Loss: 0.00001463
Iteration 199/1000 | Loss: 0.00001462
Iteration 200/1000 | Loss: 0.00001462
Iteration 201/1000 | Loss: 0.00001462
Iteration 202/1000 | Loss: 0.00001462
Iteration 203/1000 | Loss: 0.00001462
Iteration 204/1000 | Loss: 0.00001462
Iteration 205/1000 | Loss: 0.00001462
Iteration 206/1000 | Loss: 0.00001462
Iteration 207/1000 | Loss: 0.00001462
Iteration 208/1000 | Loss: 0.00001462
Iteration 209/1000 | Loss: 0.00001462
Iteration 210/1000 | Loss: 0.00001462
Iteration 211/1000 | Loss: 0.00001461
Iteration 212/1000 | Loss: 0.00001461
Iteration 213/1000 | Loss: 0.00001461
Iteration 214/1000 | Loss: 0.00001461
Iteration 215/1000 | Loss: 0.00001461
Iteration 216/1000 | Loss: 0.00001461
Iteration 217/1000 | Loss: 0.00001461
Iteration 218/1000 | Loss: 0.00001461
Iteration 219/1000 | Loss: 0.00001461
Iteration 220/1000 | Loss: 0.00001461
Iteration 221/1000 | Loss: 0.00001461
Iteration 222/1000 | Loss: 0.00001460
Iteration 223/1000 | Loss: 0.00001460
Iteration 224/1000 | Loss: 0.00001460
Iteration 225/1000 | Loss: 0.00001460
Iteration 226/1000 | Loss: 0.00001460
Iteration 227/1000 | Loss: 0.00001460
Iteration 228/1000 | Loss: 0.00001460
Iteration 229/1000 | Loss: 0.00001460
Iteration 230/1000 | Loss: 0.00001460
Iteration 231/1000 | Loss: 0.00001460
Iteration 232/1000 | Loss: 0.00001460
Iteration 233/1000 | Loss: 0.00001460
Iteration 234/1000 | Loss: 0.00001460
Iteration 235/1000 | Loss: 0.00001460
Iteration 236/1000 | Loss: 0.00001460
Iteration 237/1000 | Loss: 0.00001460
Iteration 238/1000 | Loss: 0.00001460
Iteration 239/1000 | Loss: 0.00001460
Iteration 240/1000 | Loss: 0.00001460
Iteration 241/1000 | Loss: 0.00001460
Iteration 242/1000 | Loss: 0.00001460
Iteration 243/1000 | Loss: 0.00001460
Iteration 244/1000 | Loss: 0.00001460
Iteration 245/1000 | Loss: 0.00001460
Iteration 246/1000 | Loss: 0.00001460
Iteration 247/1000 | Loss: 0.00001460
Iteration 248/1000 | Loss: 0.00001460
Iteration 249/1000 | Loss: 0.00001460
Iteration 250/1000 | Loss: 0.00001460
Iteration 251/1000 | Loss: 0.00001460
Iteration 252/1000 | Loss: 0.00001460
Iteration 253/1000 | Loss: 0.00001460
Iteration 254/1000 | Loss: 0.00001460
Iteration 255/1000 | Loss: 0.00001460
Iteration 256/1000 | Loss: 0.00001460
Iteration 257/1000 | Loss: 0.00001460
Iteration 258/1000 | Loss: 0.00001460
Iteration 259/1000 | Loss: 0.00001460
Iteration 260/1000 | Loss: 0.00001460
Iteration 261/1000 | Loss: 0.00001460
Iteration 262/1000 | Loss: 0.00001460
Iteration 263/1000 | Loss: 0.00001460
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 263. Stopping optimization.
Last 5 losses: [1.4600928807340097e-05, 1.4600928807340097e-05, 1.4600928807340097e-05, 1.4600928807340097e-05, 1.4600928807340097e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4600928807340097e-05

Optimization complete. Final v2v error: 3.183523416519165 mm

Highest mean error: 5.782153129577637 mm for frame 41

Lowest mean error: 2.7757041454315186 mm for frame 123

Saving results

Total time: 267.17510437965393
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1044/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1044.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1044
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00998706
Iteration 2/25 | Loss: 0.00440474
Iteration 3/25 | Loss: 0.00309396
Iteration 4/25 | Loss: 0.00279400
Iteration 5/25 | Loss: 0.00270586
Iteration 6/25 | Loss: 0.00232266
Iteration 7/25 | Loss: 0.00191608
Iteration 8/25 | Loss: 0.00182272
Iteration 9/25 | Loss: 0.00175746
Iteration 10/25 | Loss: 0.00170531
Iteration 11/25 | Loss: 0.00168757
Iteration 12/25 | Loss: 0.00168822
Iteration 13/25 | Loss: 0.00164328
Iteration 14/25 | Loss: 0.00159957
Iteration 15/25 | Loss: 0.00160709
Iteration 16/25 | Loss: 0.00158187
Iteration 17/25 | Loss: 0.00156465
Iteration 18/25 | Loss: 0.00153225
Iteration 19/25 | Loss: 0.00152526
Iteration 20/25 | Loss: 0.00151815
Iteration 21/25 | Loss: 0.00151993
Iteration 22/25 | Loss: 0.00151310
Iteration 23/25 | Loss: 0.00151236
Iteration 24/25 | Loss: 0.00151219
Iteration 25/25 | Loss: 0.00151201

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.40753114
Iteration 2/25 | Loss: 0.01895756
Iteration 3/25 | Loss: 0.00445241
Iteration 4/25 | Loss: 0.00493843
Iteration 5/25 | Loss: 0.00445070
Iteration 6/25 | Loss: 0.00445070
Iteration 7/25 | Loss: 0.00445070
Iteration 8/25 | Loss: 0.00445070
Iteration 9/25 | Loss: 0.00445070
Iteration 10/25 | Loss: 0.00445070
Iteration 11/25 | Loss: 0.00445069
Iteration 12/25 | Loss: 0.00445069
Iteration 13/25 | Loss: 0.00445069
Iteration 14/25 | Loss: 0.00445069
Iteration 15/25 | Loss: 0.00445069
Iteration 16/25 | Loss: 0.00445069
Iteration 17/25 | Loss: 0.00445069
Iteration 18/25 | Loss: 0.00445069
Iteration 19/25 | Loss: 0.00445069
Iteration 20/25 | Loss: 0.00445069
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.004450693726539612, 0.004450693726539612, 0.004450693726539612, 0.004450693726539612, 0.004450693726539612]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004450693726539612

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00445069
Iteration 2/1000 | Loss: 0.00949009
Iteration 3/1000 | Loss: 0.00100182
Iteration 4/1000 | Loss: 0.00403935
Iteration 5/1000 | Loss: 0.00094712
Iteration 6/1000 | Loss: 0.00213786
Iteration 7/1000 | Loss: 0.00503129
Iteration 8/1000 | Loss: 0.00697205
Iteration 9/1000 | Loss: 0.00247826
Iteration 10/1000 | Loss: 0.00215885
Iteration 11/1000 | Loss: 0.00353652
Iteration 12/1000 | Loss: 0.00132089
Iteration 13/1000 | Loss: 0.00152014
Iteration 14/1000 | Loss: 0.00062631
Iteration 15/1000 | Loss: 0.00060993
Iteration 16/1000 | Loss: 0.00090186
Iteration 17/1000 | Loss: 0.00095897
Iteration 18/1000 | Loss: 0.00154920
Iteration 19/1000 | Loss: 0.00343583
Iteration 20/1000 | Loss: 0.00273344
Iteration 21/1000 | Loss: 0.00238666
Iteration 22/1000 | Loss: 0.00961653
Iteration 23/1000 | Loss: 0.01481495
Iteration 24/1000 | Loss: 0.02142317
Iteration 25/1000 | Loss: 0.01188623
Iteration 26/1000 | Loss: 0.00529612
Iteration 27/1000 | Loss: 0.00356734
Iteration 28/1000 | Loss: 0.00260644
Iteration 29/1000 | Loss: 0.00138294
Iteration 30/1000 | Loss: 0.00199630
Iteration 31/1000 | Loss: 0.00416104
Iteration 32/1000 | Loss: 0.00114230
Iteration 33/1000 | Loss: 0.00080830
Iteration 34/1000 | Loss: 0.00131394
Iteration 35/1000 | Loss: 0.00137815
Iteration 36/1000 | Loss: 0.00400597
Iteration 37/1000 | Loss: 0.00277817
Iteration 38/1000 | Loss: 0.00164494
Iteration 39/1000 | Loss: 0.00090579
Iteration 40/1000 | Loss: 0.00122186
Iteration 41/1000 | Loss: 0.00076642
Iteration 42/1000 | Loss: 0.00278699
Iteration 43/1000 | Loss: 0.00011926
Iteration 44/1000 | Loss: 0.00048697
Iteration 45/1000 | Loss: 0.00202277
Iteration 46/1000 | Loss: 0.00021089
Iteration 47/1000 | Loss: 0.00028435
Iteration 48/1000 | Loss: 0.00018863
Iteration 49/1000 | Loss: 0.00039067
Iteration 50/1000 | Loss: 0.00058188
Iteration 51/1000 | Loss: 0.00003493
Iteration 52/1000 | Loss: 0.00055405
Iteration 53/1000 | Loss: 0.00003691
Iteration 54/1000 | Loss: 0.00059522
Iteration 55/1000 | Loss: 0.00036318
Iteration 56/1000 | Loss: 0.00006176
Iteration 57/1000 | Loss: 0.00067379
Iteration 58/1000 | Loss: 0.00005325
Iteration 59/1000 | Loss: 0.00003516
Iteration 60/1000 | Loss: 0.00068713
Iteration 61/1000 | Loss: 0.00002683
Iteration 62/1000 | Loss: 0.00002517
Iteration 63/1000 | Loss: 0.00002319
Iteration 64/1000 | Loss: 0.00002220
Iteration 65/1000 | Loss: 0.00043853
Iteration 66/1000 | Loss: 0.00002178
Iteration 67/1000 | Loss: 0.00039061
Iteration 68/1000 | Loss: 0.00057936
Iteration 69/1000 | Loss: 0.00006419
Iteration 70/1000 | Loss: 0.00002169
Iteration 71/1000 | Loss: 0.00002017
Iteration 72/1000 | Loss: 0.00001946
Iteration 73/1000 | Loss: 0.00001879
Iteration 74/1000 | Loss: 0.00001837
Iteration 75/1000 | Loss: 0.00001792
Iteration 76/1000 | Loss: 0.00001753
Iteration 77/1000 | Loss: 0.00001725
Iteration 78/1000 | Loss: 0.00001698
Iteration 79/1000 | Loss: 0.00001680
Iteration 80/1000 | Loss: 0.00001678
Iteration 81/1000 | Loss: 0.00001663
Iteration 82/1000 | Loss: 0.00035626
Iteration 83/1000 | Loss: 0.00001720
Iteration 84/1000 | Loss: 0.00001656
Iteration 85/1000 | Loss: 0.00001650
Iteration 86/1000 | Loss: 0.00001644
Iteration 87/1000 | Loss: 0.00001642
Iteration 88/1000 | Loss: 0.00001641
Iteration 89/1000 | Loss: 0.00001640
Iteration 90/1000 | Loss: 0.00001640
Iteration 91/1000 | Loss: 0.00001639
Iteration 92/1000 | Loss: 0.00001639
Iteration 93/1000 | Loss: 0.00001639
Iteration 94/1000 | Loss: 0.00001639
Iteration 95/1000 | Loss: 0.00001639
Iteration 96/1000 | Loss: 0.00001639
Iteration 97/1000 | Loss: 0.00001639
Iteration 98/1000 | Loss: 0.00001638
Iteration 99/1000 | Loss: 0.00001638
Iteration 100/1000 | Loss: 0.00001638
Iteration 101/1000 | Loss: 0.00001638
Iteration 102/1000 | Loss: 0.00001638
Iteration 103/1000 | Loss: 0.00001638
Iteration 104/1000 | Loss: 0.00001638
Iteration 105/1000 | Loss: 0.00001638
Iteration 106/1000 | Loss: 0.00001638
Iteration 107/1000 | Loss: 0.00001638
Iteration 108/1000 | Loss: 0.00001637
Iteration 109/1000 | Loss: 0.00001637
Iteration 110/1000 | Loss: 0.00001637
Iteration 111/1000 | Loss: 0.00001637
Iteration 112/1000 | Loss: 0.00001637
Iteration 113/1000 | Loss: 0.00001637
Iteration 114/1000 | Loss: 0.00001637
Iteration 115/1000 | Loss: 0.00001637
Iteration 116/1000 | Loss: 0.00001637
Iteration 117/1000 | Loss: 0.00001637
Iteration 118/1000 | Loss: 0.00001637
Iteration 119/1000 | Loss: 0.00001637
Iteration 120/1000 | Loss: 0.00001636
Iteration 121/1000 | Loss: 0.00001636
Iteration 122/1000 | Loss: 0.00001636
Iteration 123/1000 | Loss: 0.00001636
Iteration 124/1000 | Loss: 0.00001636
Iteration 125/1000 | Loss: 0.00001636
Iteration 126/1000 | Loss: 0.00001636
Iteration 127/1000 | Loss: 0.00001636
Iteration 128/1000 | Loss: 0.00001636
Iteration 129/1000 | Loss: 0.00001636
Iteration 130/1000 | Loss: 0.00001636
Iteration 131/1000 | Loss: 0.00001636
Iteration 132/1000 | Loss: 0.00001636
Iteration 133/1000 | Loss: 0.00001636
Iteration 134/1000 | Loss: 0.00001636
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 134. Stopping optimization.
Last 5 losses: [1.6361111192964017e-05, 1.6361111192964017e-05, 1.6361111192964017e-05, 1.6361111192964017e-05, 1.6361111192964017e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6361111192964017e-05

Optimization complete. Final v2v error: 3.509756088256836 mm

Highest mean error: 4.312509536743164 mm for frame 187

Lowest mean error: 3.2963883876800537 mm for frame 89

Saving results

Total time: 189.9271833896637
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1077
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01023304
Iteration 2/25 | Loss: 0.00274742
Iteration 3/25 | Loss: 0.00181215
Iteration 4/25 | Loss: 0.00156808
Iteration 5/25 | Loss: 0.00144874
Iteration 6/25 | Loss: 0.00133464
Iteration 7/25 | Loss: 0.00128230
Iteration 8/25 | Loss: 0.00122569
Iteration 9/25 | Loss: 0.00120075
Iteration 10/25 | Loss: 0.00116868
Iteration 11/25 | Loss: 0.00115257
Iteration 12/25 | Loss: 0.00107136
Iteration 13/25 | Loss: 0.00101889
Iteration 14/25 | Loss: 0.00098914
Iteration 15/25 | Loss: 0.00094939
Iteration 16/25 | Loss: 0.00093319
Iteration 17/25 | Loss: 0.00092306
Iteration 18/25 | Loss: 0.00091728
Iteration 19/25 | Loss: 0.00091594
Iteration 20/25 | Loss: 0.00091561
Iteration 21/25 | Loss: 0.00091554
Iteration 22/25 | Loss: 0.00091545
Iteration 23/25 | Loss: 0.00091544
Iteration 24/25 | Loss: 0.00091544
Iteration 25/25 | Loss: 0.00091544

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48325300
Iteration 2/25 | Loss: 0.00139775
Iteration 3/25 | Loss: 0.00105667
Iteration 4/25 | Loss: 0.00105667
Iteration 5/25 | Loss: 0.00105667
Iteration 6/25 | Loss: 0.00105667
Iteration 7/25 | Loss: 0.00105667
Iteration 8/25 | Loss: 0.00105667
Iteration 9/25 | Loss: 0.00105667
Iteration 10/25 | Loss: 0.00105667
Iteration 11/25 | Loss: 0.00105667
Iteration 12/25 | Loss: 0.00105667
Iteration 13/25 | Loss: 0.00105667
Iteration 14/25 | Loss: 0.00105667
Iteration 15/25 | Loss: 0.00105667
Iteration 16/25 | Loss: 0.00105667
Iteration 17/25 | Loss: 0.00105667
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0010566690471023321, 0.0010566690471023321, 0.0010566690471023321, 0.0010566690471023321, 0.0010566690471023321]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010566690471023321

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00105667
Iteration 2/1000 | Loss: 0.00041575
Iteration 3/1000 | Loss: 0.00048457
Iteration 4/1000 | Loss: 0.00026285
Iteration 5/1000 | Loss: 0.00028011
Iteration 6/1000 | Loss: 0.00029595
Iteration 7/1000 | Loss: 0.00006112
Iteration 8/1000 | Loss: 0.00005434
Iteration 9/1000 | Loss: 0.00005077
Iteration 10/1000 | Loss: 0.00004808
Iteration 11/1000 | Loss: 0.00004641
Iteration 12/1000 | Loss: 0.00011278
Iteration 13/1000 | Loss: 0.00004536
Iteration 14/1000 | Loss: 0.00007618
Iteration 15/1000 | Loss: 0.00004346
Iteration 16/1000 | Loss: 0.00004276
Iteration 17/1000 | Loss: 0.00004205
Iteration 18/1000 | Loss: 0.00004146
Iteration 19/1000 | Loss: 0.00004740
Iteration 20/1000 | Loss: 0.00022002
Iteration 21/1000 | Loss: 0.00026025
Iteration 22/1000 | Loss: 0.00005341
Iteration 23/1000 | Loss: 0.00004701
Iteration 24/1000 | Loss: 0.00004306
Iteration 25/1000 | Loss: 0.00003845
Iteration 26/1000 | Loss: 0.00003626
Iteration 27/1000 | Loss: 0.00003545
Iteration 28/1000 | Loss: 0.00003496
Iteration 29/1000 | Loss: 0.00003466
Iteration 30/1000 | Loss: 0.00003444
Iteration 31/1000 | Loss: 0.00003430
Iteration 32/1000 | Loss: 0.00003426
Iteration 33/1000 | Loss: 0.00003426
Iteration 34/1000 | Loss: 0.00003408
Iteration 35/1000 | Loss: 0.00003408
Iteration 36/1000 | Loss: 0.00003401
Iteration 37/1000 | Loss: 0.00003399
Iteration 38/1000 | Loss: 0.00003398
Iteration 39/1000 | Loss: 0.00003395
Iteration 40/1000 | Loss: 0.00003395
Iteration 41/1000 | Loss: 0.00003394
Iteration 42/1000 | Loss: 0.00003394
Iteration 43/1000 | Loss: 0.00003394
Iteration 44/1000 | Loss: 0.00003393
Iteration 45/1000 | Loss: 0.00003393
Iteration 46/1000 | Loss: 0.00003392
Iteration 47/1000 | Loss: 0.00003392
Iteration 48/1000 | Loss: 0.00003392
Iteration 49/1000 | Loss: 0.00003391
Iteration 50/1000 | Loss: 0.00003391
Iteration 51/1000 | Loss: 0.00003391
Iteration 52/1000 | Loss: 0.00003391
Iteration 53/1000 | Loss: 0.00003391
Iteration 54/1000 | Loss: 0.00003391
Iteration 55/1000 | Loss: 0.00003391
Iteration 56/1000 | Loss: 0.00003391
Iteration 57/1000 | Loss: 0.00003390
Iteration 58/1000 | Loss: 0.00003390
Iteration 59/1000 | Loss: 0.00003390
Iteration 60/1000 | Loss: 0.00003390
Iteration 61/1000 | Loss: 0.00003390
Iteration 62/1000 | Loss: 0.00003390
Iteration 63/1000 | Loss: 0.00003390
Iteration 64/1000 | Loss: 0.00003389
Iteration 65/1000 | Loss: 0.00003389
Iteration 66/1000 | Loss: 0.00003389
Iteration 67/1000 | Loss: 0.00003389
Iteration 68/1000 | Loss: 0.00003389
Iteration 69/1000 | Loss: 0.00003389
Iteration 70/1000 | Loss: 0.00003388
Iteration 71/1000 | Loss: 0.00003388
Iteration 72/1000 | Loss: 0.00003388
Iteration 73/1000 | Loss: 0.00003388
Iteration 74/1000 | Loss: 0.00003388
Iteration 75/1000 | Loss: 0.00003388
Iteration 76/1000 | Loss: 0.00003388
Iteration 77/1000 | Loss: 0.00003387
Iteration 78/1000 | Loss: 0.00003387
Iteration 79/1000 | Loss: 0.00003387
Iteration 80/1000 | Loss: 0.00003387
Iteration 81/1000 | Loss: 0.00003387
Iteration 82/1000 | Loss: 0.00003386
Iteration 83/1000 | Loss: 0.00003386
Iteration 84/1000 | Loss: 0.00003386
Iteration 85/1000 | Loss: 0.00003386
Iteration 86/1000 | Loss: 0.00003386
Iteration 87/1000 | Loss: 0.00003385
Iteration 88/1000 | Loss: 0.00003385
Iteration 89/1000 | Loss: 0.00003385
Iteration 90/1000 | Loss: 0.00003385
Iteration 91/1000 | Loss: 0.00003385
Iteration 92/1000 | Loss: 0.00003384
Iteration 93/1000 | Loss: 0.00003384
Iteration 94/1000 | Loss: 0.00003384
Iteration 95/1000 | Loss: 0.00003384
Iteration 96/1000 | Loss: 0.00003384
Iteration 97/1000 | Loss: 0.00003384
Iteration 98/1000 | Loss: 0.00003384
Iteration 99/1000 | Loss: 0.00003384
Iteration 100/1000 | Loss: 0.00003384
Iteration 101/1000 | Loss: 0.00003384
Iteration 102/1000 | Loss: 0.00003384
Iteration 103/1000 | Loss: 0.00003384
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [3.384285810170695e-05, 3.384285810170695e-05, 3.384285810170695e-05, 3.384285810170695e-05, 3.384285810170695e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.384285810170695e-05

Optimization complete. Final v2v error: 3.9344449043273926 mm

Highest mean error: 6.196529865264893 mm for frame 45

Lowest mean error: 2.9028265476226807 mm for frame 149

Saving results

Total time: 88.91014814376831
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1047/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1047.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1047
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00788981
Iteration 2/25 | Loss: 0.00132090
Iteration 3/25 | Loss: 0.00097246
Iteration 4/25 | Loss: 0.00094967
Iteration 5/25 | Loss: 0.00097246
Iteration 6/25 | Loss: 0.00094334
Iteration 7/25 | Loss: 0.00084968
Iteration 8/25 | Loss: 0.00085066
Iteration 9/25 | Loss: 0.00082985
Iteration 10/25 | Loss: 0.00082616
Iteration 11/25 | Loss: 0.00082305
Iteration 12/25 | Loss: 0.00082468
Iteration 13/25 | Loss: 0.00082114
Iteration 14/25 | Loss: 0.00081747
Iteration 15/25 | Loss: 0.00081524
Iteration 16/25 | Loss: 0.00081195
Iteration 17/25 | Loss: 0.00080540
Iteration 18/25 | Loss: 0.00081045
Iteration 19/25 | Loss: 0.00081556
Iteration 20/25 | Loss: 0.00081177
Iteration 21/25 | Loss: 0.00080899
Iteration 22/25 | Loss: 0.00081687
Iteration 23/25 | Loss: 0.00082270
Iteration 24/25 | Loss: 0.00080700
Iteration 25/25 | Loss: 0.00079771

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.72453129
Iteration 2/25 | Loss: 0.00065948
Iteration 3/25 | Loss: 0.00065948
Iteration 4/25 | Loss: 0.00065948
Iteration 5/25 | Loss: 0.00065948
Iteration 6/25 | Loss: 0.00065948
Iteration 7/25 | Loss: 0.00065948
Iteration 8/25 | Loss: 0.00065948
Iteration 9/25 | Loss: 0.00065948
Iteration 10/25 | Loss: 0.00065948
Iteration 11/25 | Loss: 0.00065948
Iteration 12/25 | Loss: 0.00065948
Iteration 13/25 | Loss: 0.00065948
Iteration 14/25 | Loss: 0.00065948
Iteration 15/25 | Loss: 0.00065948
Iteration 16/25 | Loss: 0.00065948
Iteration 17/25 | Loss: 0.00065948
Iteration 18/25 | Loss: 0.00065948
Iteration 19/25 | Loss: 0.00065948
Iteration 20/25 | Loss: 0.00065948
Iteration 21/25 | Loss: 0.00065948
Iteration 22/25 | Loss: 0.00065948
Iteration 23/25 | Loss: 0.00065948
Iteration 24/25 | Loss: 0.00065948
Iteration 25/25 | Loss: 0.00065948

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065948
Iteration 2/1000 | Loss: 0.00034791
Iteration 3/1000 | Loss: 0.00044966
Iteration 4/1000 | Loss: 0.00045380
Iteration 5/1000 | Loss: 0.00031814
Iteration 6/1000 | Loss: 0.00011029
Iteration 7/1000 | Loss: 0.00044828
Iteration 8/1000 | Loss: 0.00028832
Iteration 9/1000 | Loss: 0.00036948
Iteration 10/1000 | Loss: 0.00035800
Iteration 11/1000 | Loss: 0.00044839
Iteration 12/1000 | Loss: 0.00055156
Iteration 13/1000 | Loss: 0.00039789
Iteration 14/1000 | Loss: 0.00026541
Iteration 15/1000 | Loss: 0.00032243
Iteration 16/1000 | Loss: 0.00033385
Iteration 17/1000 | Loss: 0.00315995
Iteration 18/1000 | Loss: 0.00014708
Iteration 19/1000 | Loss: 0.00086373
Iteration 20/1000 | Loss: 0.00071510
Iteration 21/1000 | Loss: 0.00067209
Iteration 22/1000 | Loss: 0.00137929
Iteration 23/1000 | Loss: 0.00084310
Iteration 24/1000 | Loss: 0.00028997
Iteration 25/1000 | Loss: 0.00027558
Iteration 26/1000 | Loss: 0.00003232
Iteration 27/1000 | Loss: 0.00002322
Iteration 28/1000 | Loss: 0.00002044
Iteration 29/1000 | Loss: 0.00001937
Iteration 30/1000 | Loss: 0.00001873
Iteration 31/1000 | Loss: 0.00001842
Iteration 32/1000 | Loss: 0.00001810
Iteration 33/1000 | Loss: 0.00001780
Iteration 34/1000 | Loss: 0.00001770
Iteration 35/1000 | Loss: 0.00001769
Iteration 36/1000 | Loss: 0.00001746
Iteration 37/1000 | Loss: 0.00001959
Iteration 38/1000 | Loss: 0.00001770
Iteration 39/1000 | Loss: 0.00001722
Iteration 40/1000 | Loss: 0.00038857
Iteration 41/1000 | Loss: 0.00002134
Iteration 42/1000 | Loss: 0.00001833
Iteration 43/1000 | Loss: 0.00001718
Iteration 44/1000 | Loss: 0.00001629
Iteration 45/1000 | Loss: 0.00001570
Iteration 46/1000 | Loss: 0.00001522
Iteration 47/1000 | Loss: 0.00001505
Iteration 48/1000 | Loss: 0.00001494
Iteration 49/1000 | Loss: 0.00001493
Iteration 50/1000 | Loss: 0.00001490
Iteration 51/1000 | Loss: 0.00001488
Iteration 52/1000 | Loss: 0.00001484
Iteration 53/1000 | Loss: 0.00001484
Iteration 54/1000 | Loss: 0.00001483
Iteration 55/1000 | Loss: 0.00001482
Iteration 56/1000 | Loss: 0.00001482
Iteration 57/1000 | Loss: 0.00001481
Iteration 58/1000 | Loss: 0.00001480
Iteration 59/1000 | Loss: 0.00001479
Iteration 60/1000 | Loss: 0.00001479
Iteration 61/1000 | Loss: 0.00001478
Iteration 62/1000 | Loss: 0.00001478
Iteration 63/1000 | Loss: 0.00001478
Iteration 64/1000 | Loss: 0.00001478
Iteration 65/1000 | Loss: 0.00001477
Iteration 66/1000 | Loss: 0.00001477
Iteration 67/1000 | Loss: 0.00001477
Iteration 68/1000 | Loss: 0.00001477
Iteration 69/1000 | Loss: 0.00001477
Iteration 70/1000 | Loss: 0.00001476
Iteration 71/1000 | Loss: 0.00001476
Iteration 72/1000 | Loss: 0.00001476
Iteration 73/1000 | Loss: 0.00001476
Iteration 74/1000 | Loss: 0.00001476
Iteration 75/1000 | Loss: 0.00001476
Iteration 76/1000 | Loss: 0.00001475
Iteration 77/1000 | Loss: 0.00001475
Iteration 78/1000 | Loss: 0.00001475
Iteration 79/1000 | Loss: 0.00001475
Iteration 80/1000 | Loss: 0.00001475
Iteration 81/1000 | Loss: 0.00001474
Iteration 82/1000 | Loss: 0.00001474
Iteration 83/1000 | Loss: 0.00001474
Iteration 84/1000 | Loss: 0.00001474
Iteration 85/1000 | Loss: 0.00001474
Iteration 86/1000 | Loss: 0.00001473
Iteration 87/1000 | Loss: 0.00001473
Iteration 88/1000 | Loss: 0.00001473
Iteration 89/1000 | Loss: 0.00001472
Iteration 90/1000 | Loss: 0.00001472
Iteration 91/1000 | Loss: 0.00001472
Iteration 92/1000 | Loss: 0.00001471
Iteration 93/1000 | Loss: 0.00001471
Iteration 94/1000 | Loss: 0.00001471
Iteration 95/1000 | Loss: 0.00001470
Iteration 96/1000 | Loss: 0.00001470
Iteration 97/1000 | Loss: 0.00001470
Iteration 98/1000 | Loss: 0.00001470
Iteration 99/1000 | Loss: 0.00001470
Iteration 100/1000 | Loss: 0.00001470
Iteration 101/1000 | Loss: 0.00001470
Iteration 102/1000 | Loss: 0.00001470
Iteration 103/1000 | Loss: 0.00001470
Iteration 104/1000 | Loss: 0.00001469
Iteration 105/1000 | Loss: 0.00001469
Iteration 106/1000 | Loss: 0.00001469
Iteration 107/1000 | Loss: 0.00001469
Iteration 108/1000 | Loss: 0.00001469
Iteration 109/1000 | Loss: 0.00001469
Iteration 110/1000 | Loss: 0.00001468
Iteration 111/1000 | Loss: 0.00001468
Iteration 112/1000 | Loss: 0.00001468
Iteration 113/1000 | Loss: 0.00001468
Iteration 114/1000 | Loss: 0.00001468
Iteration 115/1000 | Loss: 0.00001468
Iteration 116/1000 | Loss: 0.00001468
Iteration 117/1000 | Loss: 0.00001467
Iteration 118/1000 | Loss: 0.00001467
Iteration 119/1000 | Loss: 0.00001467
Iteration 120/1000 | Loss: 0.00001467
Iteration 121/1000 | Loss: 0.00001467
Iteration 122/1000 | Loss: 0.00001467
Iteration 123/1000 | Loss: 0.00001467
Iteration 124/1000 | Loss: 0.00001466
Iteration 125/1000 | Loss: 0.00001466
Iteration 126/1000 | Loss: 0.00001466
Iteration 127/1000 | Loss: 0.00001466
Iteration 128/1000 | Loss: 0.00001466
Iteration 129/1000 | Loss: 0.00001466
Iteration 130/1000 | Loss: 0.00001466
Iteration 131/1000 | Loss: 0.00001466
Iteration 132/1000 | Loss: 0.00001466
Iteration 133/1000 | Loss: 0.00001465
Iteration 134/1000 | Loss: 0.00001465
Iteration 135/1000 | Loss: 0.00001465
Iteration 136/1000 | Loss: 0.00001464
Iteration 137/1000 | Loss: 0.00001464
Iteration 138/1000 | Loss: 0.00001463
Iteration 139/1000 | Loss: 0.00001463
Iteration 140/1000 | Loss: 0.00001463
Iteration 141/1000 | Loss: 0.00001463
Iteration 142/1000 | Loss: 0.00001463
Iteration 143/1000 | Loss: 0.00001463
Iteration 144/1000 | Loss: 0.00001462
Iteration 145/1000 | Loss: 0.00001462
Iteration 146/1000 | Loss: 0.00001462
Iteration 147/1000 | Loss: 0.00001462
Iteration 148/1000 | Loss: 0.00001461
Iteration 149/1000 | Loss: 0.00001461
Iteration 150/1000 | Loss: 0.00001461
Iteration 151/1000 | Loss: 0.00001461
Iteration 152/1000 | Loss: 0.00001461
Iteration 153/1000 | Loss: 0.00001461
Iteration 154/1000 | Loss: 0.00001460
Iteration 155/1000 | Loss: 0.00001460
Iteration 156/1000 | Loss: 0.00001460
Iteration 157/1000 | Loss: 0.00001459
Iteration 158/1000 | Loss: 0.00001459
Iteration 159/1000 | Loss: 0.00001459
Iteration 160/1000 | Loss: 0.00001459
Iteration 161/1000 | Loss: 0.00001458
Iteration 162/1000 | Loss: 0.00001458
Iteration 163/1000 | Loss: 0.00001458
Iteration 164/1000 | Loss: 0.00001458
Iteration 165/1000 | Loss: 0.00001457
Iteration 166/1000 | Loss: 0.00001457
Iteration 167/1000 | Loss: 0.00001457
Iteration 168/1000 | Loss: 0.00001457
Iteration 169/1000 | Loss: 0.00001457
Iteration 170/1000 | Loss: 0.00001457
Iteration 171/1000 | Loss: 0.00001457
Iteration 172/1000 | Loss: 0.00001456
Iteration 173/1000 | Loss: 0.00001456
Iteration 174/1000 | Loss: 0.00001456
Iteration 175/1000 | Loss: 0.00001456
Iteration 176/1000 | Loss: 0.00001456
Iteration 177/1000 | Loss: 0.00001456
Iteration 178/1000 | Loss: 0.00001456
Iteration 179/1000 | Loss: 0.00001456
Iteration 180/1000 | Loss: 0.00001456
Iteration 181/1000 | Loss: 0.00001456
Iteration 182/1000 | Loss: 0.00001456
Iteration 183/1000 | Loss: 0.00001456
Iteration 184/1000 | Loss: 0.00001456
Iteration 185/1000 | Loss: 0.00001456
Iteration 186/1000 | Loss: 0.00001456
Iteration 187/1000 | Loss: 0.00001455
Iteration 188/1000 | Loss: 0.00001455
Iteration 189/1000 | Loss: 0.00001455
Iteration 190/1000 | Loss: 0.00001455
Iteration 191/1000 | Loss: 0.00001455
Iteration 192/1000 | Loss: 0.00001455
Iteration 193/1000 | Loss: 0.00001455
Iteration 194/1000 | Loss: 0.00001455
Iteration 195/1000 | Loss: 0.00001455
Iteration 196/1000 | Loss: 0.00001455
Iteration 197/1000 | Loss: 0.00001455
Iteration 198/1000 | Loss: 0.00001455
Iteration 199/1000 | Loss: 0.00001455
Iteration 200/1000 | Loss: 0.00001455
Iteration 201/1000 | Loss: 0.00001455
Iteration 202/1000 | Loss: 0.00001455
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 202. Stopping optimization.
Last 5 losses: [1.4552815628121607e-05, 1.4552815628121607e-05, 1.4552815628121607e-05, 1.4552815628121607e-05, 1.4552815628121607e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4552815628121607e-05

Optimization complete. Final v2v error: 3.123958110809326 mm

Highest mean error: 9.069951057434082 mm for frame 87

Lowest mean error: 2.4607200622558594 mm for frame 236

Saving results

Total time: 139.52994298934937
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1059/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1059.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1059
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00427079
Iteration 2/25 | Loss: 0.00094974
Iteration 3/25 | Loss: 0.00077802
Iteration 4/25 | Loss: 0.00075851
Iteration 5/25 | Loss: 0.00075318
Iteration 6/25 | Loss: 0.00075126
Iteration 7/25 | Loss: 0.00075113
Iteration 8/25 | Loss: 0.00075113
Iteration 9/25 | Loss: 0.00075113
Iteration 10/25 | Loss: 0.00075111
Iteration 11/25 | Loss: 0.00075111
Iteration 12/25 | Loss: 0.00075111
Iteration 13/25 | Loss: 0.00075111
Iteration 14/25 | Loss: 0.00075111
Iteration 15/25 | Loss: 0.00075111
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0007511103176511824, 0.0007511103176511824, 0.0007511103176511824, 0.0007511103176511824, 0.0007511103176511824]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007511103176511824

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46466219
Iteration 2/25 | Loss: 0.00039502
Iteration 3/25 | Loss: 0.00039502
Iteration 4/25 | Loss: 0.00039502
Iteration 5/25 | Loss: 0.00039502
Iteration 6/25 | Loss: 0.00039502
Iteration 7/25 | Loss: 0.00039502
Iteration 8/25 | Loss: 0.00039502
Iteration 9/25 | Loss: 0.00039502
Iteration 10/25 | Loss: 0.00039502
Iteration 11/25 | Loss: 0.00039502
Iteration 12/25 | Loss: 0.00039502
Iteration 13/25 | Loss: 0.00039502
Iteration 14/25 | Loss: 0.00039502
Iteration 15/25 | Loss: 0.00039502
Iteration 16/25 | Loss: 0.00039502
Iteration 17/25 | Loss: 0.00039502
Iteration 18/25 | Loss: 0.00039502
Iteration 19/25 | Loss: 0.00039502
Iteration 20/25 | Loss: 0.00039502
Iteration 21/25 | Loss: 0.00039502
Iteration 22/25 | Loss: 0.00039502
Iteration 23/25 | Loss: 0.00039502
Iteration 24/25 | Loss: 0.00039502
Iteration 25/25 | Loss: 0.00039502

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039502
Iteration 2/1000 | Loss: 0.00002261
Iteration 3/1000 | Loss: 0.00001617
Iteration 4/1000 | Loss: 0.00001500
Iteration 5/1000 | Loss: 0.00001439
Iteration 6/1000 | Loss: 0.00001414
Iteration 7/1000 | Loss: 0.00001390
Iteration 8/1000 | Loss: 0.00001380
Iteration 9/1000 | Loss: 0.00001369
Iteration 10/1000 | Loss: 0.00001367
Iteration 11/1000 | Loss: 0.00001367
Iteration 12/1000 | Loss: 0.00001366
Iteration 13/1000 | Loss: 0.00001366
Iteration 14/1000 | Loss: 0.00001365
Iteration 15/1000 | Loss: 0.00001364
Iteration 16/1000 | Loss: 0.00001363
Iteration 17/1000 | Loss: 0.00001363
Iteration 18/1000 | Loss: 0.00001362
Iteration 19/1000 | Loss: 0.00001360
Iteration 20/1000 | Loss: 0.00001358
Iteration 21/1000 | Loss: 0.00001353
Iteration 22/1000 | Loss: 0.00001352
Iteration 23/1000 | Loss: 0.00001352
Iteration 24/1000 | Loss: 0.00001348
Iteration 25/1000 | Loss: 0.00001346
Iteration 26/1000 | Loss: 0.00001345
Iteration 27/1000 | Loss: 0.00001345
Iteration 28/1000 | Loss: 0.00001345
Iteration 29/1000 | Loss: 0.00001345
Iteration 30/1000 | Loss: 0.00001345
Iteration 31/1000 | Loss: 0.00001345
Iteration 32/1000 | Loss: 0.00001345
Iteration 33/1000 | Loss: 0.00001345
Iteration 34/1000 | Loss: 0.00001344
Iteration 35/1000 | Loss: 0.00001344
Iteration 36/1000 | Loss: 0.00001343
Iteration 37/1000 | Loss: 0.00001343
Iteration 38/1000 | Loss: 0.00001342
Iteration 39/1000 | Loss: 0.00001342
Iteration 40/1000 | Loss: 0.00001342
Iteration 41/1000 | Loss: 0.00001342
Iteration 42/1000 | Loss: 0.00001341
Iteration 43/1000 | Loss: 0.00001341
Iteration 44/1000 | Loss: 0.00001340
Iteration 45/1000 | Loss: 0.00001340
Iteration 46/1000 | Loss: 0.00001340
Iteration 47/1000 | Loss: 0.00001340
Iteration 48/1000 | Loss: 0.00001340
Iteration 49/1000 | Loss: 0.00001340
Iteration 50/1000 | Loss: 0.00001340
Iteration 51/1000 | Loss: 0.00001340
Iteration 52/1000 | Loss: 0.00001339
Iteration 53/1000 | Loss: 0.00001339
Iteration 54/1000 | Loss: 0.00001339
Iteration 55/1000 | Loss: 0.00001339
Iteration 56/1000 | Loss: 0.00001339
Iteration 57/1000 | Loss: 0.00001338
Iteration 58/1000 | Loss: 0.00001338
Iteration 59/1000 | Loss: 0.00001338
Iteration 60/1000 | Loss: 0.00001338
Iteration 61/1000 | Loss: 0.00001338
Iteration 62/1000 | Loss: 0.00001337
Iteration 63/1000 | Loss: 0.00001337
Iteration 64/1000 | Loss: 0.00001337
Iteration 65/1000 | Loss: 0.00001337
Iteration 66/1000 | Loss: 0.00001336
Iteration 67/1000 | Loss: 0.00001336
Iteration 68/1000 | Loss: 0.00001336
Iteration 69/1000 | Loss: 0.00001335
Iteration 70/1000 | Loss: 0.00001335
Iteration 71/1000 | Loss: 0.00001335
Iteration 72/1000 | Loss: 0.00001335
Iteration 73/1000 | Loss: 0.00001335
Iteration 74/1000 | Loss: 0.00001335
Iteration 75/1000 | Loss: 0.00001334
Iteration 76/1000 | Loss: 0.00001334
Iteration 77/1000 | Loss: 0.00001334
Iteration 78/1000 | Loss: 0.00001334
Iteration 79/1000 | Loss: 0.00001334
Iteration 80/1000 | Loss: 0.00001333
Iteration 81/1000 | Loss: 0.00001333
Iteration 82/1000 | Loss: 0.00001333
Iteration 83/1000 | Loss: 0.00001333
Iteration 84/1000 | Loss: 0.00001333
Iteration 85/1000 | Loss: 0.00001332
Iteration 86/1000 | Loss: 0.00001332
Iteration 87/1000 | Loss: 0.00001332
Iteration 88/1000 | Loss: 0.00001332
Iteration 89/1000 | Loss: 0.00001332
Iteration 90/1000 | Loss: 0.00001331
Iteration 91/1000 | Loss: 0.00001331
Iteration 92/1000 | Loss: 0.00001331
Iteration 93/1000 | Loss: 0.00001331
Iteration 94/1000 | Loss: 0.00001330
Iteration 95/1000 | Loss: 0.00001330
Iteration 96/1000 | Loss: 0.00001330
Iteration 97/1000 | Loss: 0.00001330
Iteration 98/1000 | Loss: 0.00001329
Iteration 99/1000 | Loss: 0.00001329
Iteration 100/1000 | Loss: 0.00001329
Iteration 101/1000 | Loss: 0.00001329
Iteration 102/1000 | Loss: 0.00001328
Iteration 103/1000 | Loss: 0.00001328
Iteration 104/1000 | Loss: 0.00001328
Iteration 105/1000 | Loss: 0.00001328
Iteration 106/1000 | Loss: 0.00001328
Iteration 107/1000 | Loss: 0.00001328
Iteration 108/1000 | Loss: 0.00001328
Iteration 109/1000 | Loss: 0.00001328
Iteration 110/1000 | Loss: 0.00001328
Iteration 111/1000 | Loss: 0.00001328
Iteration 112/1000 | Loss: 0.00001328
Iteration 113/1000 | Loss: 0.00001328
Iteration 114/1000 | Loss: 0.00001328
Iteration 115/1000 | Loss: 0.00001328
Iteration 116/1000 | Loss: 0.00001327
Iteration 117/1000 | Loss: 0.00001327
Iteration 118/1000 | Loss: 0.00001327
Iteration 119/1000 | Loss: 0.00001327
Iteration 120/1000 | Loss: 0.00001327
Iteration 121/1000 | Loss: 0.00001327
Iteration 122/1000 | Loss: 0.00001327
Iteration 123/1000 | Loss: 0.00001327
Iteration 124/1000 | Loss: 0.00001327
Iteration 125/1000 | Loss: 0.00001327
Iteration 126/1000 | Loss: 0.00001327
Iteration 127/1000 | Loss: 0.00001327
Iteration 128/1000 | Loss: 0.00001327
Iteration 129/1000 | Loss: 0.00001327
Iteration 130/1000 | Loss: 0.00001327
Iteration 131/1000 | Loss: 0.00001327
Iteration 132/1000 | Loss: 0.00001326
Iteration 133/1000 | Loss: 0.00001326
Iteration 134/1000 | Loss: 0.00001326
Iteration 135/1000 | Loss: 0.00001326
Iteration 136/1000 | Loss: 0.00001326
Iteration 137/1000 | Loss: 0.00001326
Iteration 138/1000 | Loss: 0.00001326
Iteration 139/1000 | Loss: 0.00001326
Iteration 140/1000 | Loss: 0.00001326
Iteration 141/1000 | Loss: 0.00001326
Iteration 142/1000 | Loss: 0.00001326
Iteration 143/1000 | Loss: 0.00001326
Iteration 144/1000 | Loss: 0.00001326
Iteration 145/1000 | Loss: 0.00001326
Iteration 146/1000 | Loss: 0.00001326
Iteration 147/1000 | Loss: 0.00001326
Iteration 148/1000 | Loss: 0.00001326
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.325939956586808e-05, 1.325939956586808e-05, 1.325939956586808e-05, 1.325939956586808e-05, 1.325939956586808e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.325939956586808e-05

Optimization complete. Final v2v error: 3.0681440830230713 mm

Highest mean error: 3.6528708934783936 mm for frame 9

Lowest mean error: 2.8484203815460205 mm for frame 20

Saving results

Total time: 33.27325749397278
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christopher_posed_002/1012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christopher_posed_002/1012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00376862
Iteration 2/25 | Loss: 0.00091603
Iteration 3/25 | Loss: 0.00077718
Iteration 4/25 | Loss: 0.00075739
Iteration 5/25 | Loss: 0.00075137
Iteration 6/25 | Loss: 0.00074989
Iteration 7/25 | Loss: 0.00074983
Iteration 8/25 | Loss: 0.00074983
Iteration 9/25 | Loss: 0.00074983
Iteration 10/25 | Loss: 0.00074983
Iteration 11/25 | Loss: 0.00074983
Iteration 12/25 | Loss: 0.00074983
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007498254999518394, 0.0007498254999518394, 0.0007498254999518394, 0.0007498254999518394, 0.0007498254999518394]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007498254999518394

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.92409837
Iteration 2/25 | Loss: 0.00028255
Iteration 3/25 | Loss: 0.00028254
Iteration 4/25 | Loss: 0.00028254
Iteration 5/25 | Loss: 0.00028254
Iteration 6/25 | Loss: 0.00028254
Iteration 7/25 | Loss: 0.00028254
Iteration 8/25 | Loss: 0.00028254
Iteration 9/25 | Loss: 0.00028254
Iteration 10/25 | Loss: 0.00028254
Iteration 11/25 | Loss: 0.00028254
Iteration 12/25 | Loss: 0.00028254
Iteration 13/25 | Loss: 0.00028254
Iteration 14/25 | Loss: 0.00028254
Iteration 15/25 | Loss: 0.00028254
Iteration 16/25 | Loss: 0.00028254
Iteration 17/25 | Loss: 0.00028254
Iteration 18/25 | Loss: 0.00028254
Iteration 19/25 | Loss: 0.00028254
Iteration 20/25 | Loss: 0.00028254
Iteration 21/25 | Loss: 0.00028254
Iteration 22/25 | Loss: 0.00028254
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00028253841446712613, 0.00028253841446712613, 0.00028253841446712613, 0.00028253841446712613, 0.00028253841446712613]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00028253841446712613

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00028254
Iteration 2/1000 | Loss: 0.00002916
Iteration 3/1000 | Loss: 0.00001932
Iteration 4/1000 | Loss: 0.00001752
Iteration 5/1000 | Loss: 0.00001653
Iteration 6/1000 | Loss: 0.00001599
Iteration 7/1000 | Loss: 0.00001578
Iteration 8/1000 | Loss: 0.00001552
Iteration 9/1000 | Loss: 0.00001546
Iteration 10/1000 | Loss: 0.00001536
Iteration 11/1000 | Loss: 0.00001535
Iteration 12/1000 | Loss: 0.00001528
Iteration 13/1000 | Loss: 0.00001527
Iteration 14/1000 | Loss: 0.00001527
Iteration 15/1000 | Loss: 0.00001526
Iteration 16/1000 | Loss: 0.00001526
Iteration 17/1000 | Loss: 0.00001523
Iteration 18/1000 | Loss: 0.00001523
Iteration 19/1000 | Loss: 0.00001522
Iteration 20/1000 | Loss: 0.00001504
Iteration 21/1000 | Loss: 0.00001500
Iteration 22/1000 | Loss: 0.00001486
Iteration 23/1000 | Loss: 0.00001485
Iteration 24/1000 | Loss: 0.00001485
Iteration 25/1000 | Loss: 0.00001485
Iteration 26/1000 | Loss: 0.00001484
Iteration 27/1000 | Loss: 0.00001484
Iteration 28/1000 | Loss: 0.00001483
Iteration 29/1000 | Loss: 0.00001483
Iteration 30/1000 | Loss: 0.00001481
Iteration 31/1000 | Loss: 0.00001477
Iteration 32/1000 | Loss: 0.00001470
Iteration 33/1000 | Loss: 0.00001466
Iteration 34/1000 | Loss: 0.00001463
Iteration 35/1000 | Loss: 0.00001463
Iteration 36/1000 | Loss: 0.00001462
Iteration 37/1000 | Loss: 0.00001462
Iteration 38/1000 | Loss: 0.00001462
Iteration 39/1000 | Loss: 0.00001462
Iteration 40/1000 | Loss: 0.00001461
Iteration 41/1000 | Loss: 0.00001460
Iteration 42/1000 | Loss: 0.00001459
Iteration 43/1000 | Loss: 0.00001459
Iteration 44/1000 | Loss: 0.00001459
Iteration 45/1000 | Loss: 0.00001459
Iteration 46/1000 | Loss: 0.00001459
Iteration 47/1000 | Loss: 0.00001459
Iteration 48/1000 | Loss: 0.00001458
Iteration 49/1000 | Loss: 0.00001458
Iteration 50/1000 | Loss: 0.00001458
Iteration 51/1000 | Loss: 0.00001458
Iteration 52/1000 | Loss: 0.00001457
Iteration 53/1000 | Loss: 0.00001457
Iteration 54/1000 | Loss: 0.00001456
Iteration 55/1000 | Loss: 0.00001456
Iteration 56/1000 | Loss: 0.00001455
Iteration 57/1000 | Loss: 0.00001455
Iteration 58/1000 | Loss: 0.00001454
Iteration 59/1000 | Loss: 0.00001454
Iteration 60/1000 | Loss: 0.00001454
Iteration 61/1000 | Loss: 0.00001453
Iteration 62/1000 | Loss: 0.00001453
Iteration 63/1000 | Loss: 0.00001453
Iteration 64/1000 | Loss: 0.00001453
Iteration 65/1000 | Loss: 0.00001452
Iteration 66/1000 | Loss: 0.00001452
Iteration 67/1000 | Loss: 0.00001452
Iteration 68/1000 | Loss: 0.00001451
Iteration 69/1000 | Loss: 0.00001450
Iteration 70/1000 | Loss: 0.00001450
Iteration 71/1000 | Loss: 0.00001450
Iteration 72/1000 | Loss: 0.00001450
Iteration 73/1000 | Loss: 0.00001450
Iteration 74/1000 | Loss: 0.00001450
Iteration 75/1000 | Loss: 0.00001450
Iteration 76/1000 | Loss: 0.00001449
Iteration 77/1000 | Loss: 0.00001449
Iteration 78/1000 | Loss: 0.00001449
Iteration 79/1000 | Loss: 0.00001449
Iteration 80/1000 | Loss: 0.00001449
Iteration 81/1000 | Loss: 0.00001449
Iteration 82/1000 | Loss: 0.00001449
Iteration 83/1000 | Loss: 0.00001449
Iteration 84/1000 | Loss: 0.00001449
Iteration 85/1000 | Loss: 0.00001449
Iteration 86/1000 | Loss: 0.00001449
Iteration 87/1000 | Loss: 0.00001449
Iteration 88/1000 | Loss: 0.00001449
Iteration 89/1000 | Loss: 0.00001449
Iteration 90/1000 | Loss: 0.00001449
Iteration 91/1000 | Loss: 0.00001449
Iteration 92/1000 | Loss: 0.00001449
Iteration 93/1000 | Loss: 0.00001449
Iteration 94/1000 | Loss: 0.00001449
Iteration 95/1000 | Loss: 0.00001449
Iteration 96/1000 | Loss: 0.00001449
Iteration 97/1000 | Loss: 0.00001449
Iteration 98/1000 | Loss: 0.00001449
Iteration 99/1000 | Loss: 0.00001449
Iteration 100/1000 | Loss: 0.00001449
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 100. Stopping optimization.
Last 5 losses: [1.448993498343043e-05, 1.448993498343043e-05, 1.448993498343043e-05, 1.448993498343043e-05, 1.448993498343043e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.448993498343043e-05

Optimization complete. Final v2v error: 3.215468645095825 mm

Highest mean error: 3.336397409439087 mm for frame 8

Lowest mean error: 3.1708343029022217 mm for frame 174

Saving results

Total time: 36.80071020126343

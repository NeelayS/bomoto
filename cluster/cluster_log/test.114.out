Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=114, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 6384-6439
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1038/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1038.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1038
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00407235
Iteration 2/25 | Loss: 0.00146690
Iteration 3/25 | Loss: 0.00137301
Iteration 4/25 | Loss: 0.00135799
Iteration 5/25 | Loss: 0.00135358
Iteration 6/25 | Loss: 0.00135266
Iteration 7/25 | Loss: 0.00135266
Iteration 8/25 | Loss: 0.00135266
Iteration 9/25 | Loss: 0.00135266
Iteration 10/25 | Loss: 0.00135266
Iteration 11/25 | Loss: 0.00135266
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013526583788916469, 0.0013526583788916469, 0.0013526583788916469, 0.0013526583788916469, 0.0013526583788916469]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013526583788916469

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26612008
Iteration 2/25 | Loss: 0.00210014
Iteration 3/25 | Loss: 0.00210012
Iteration 4/25 | Loss: 0.00210011
Iteration 5/25 | Loss: 0.00210011
Iteration 6/25 | Loss: 0.00210011
Iteration 7/25 | Loss: 0.00210011
Iteration 8/25 | Loss: 0.00210011
Iteration 9/25 | Loss: 0.00210011
Iteration 10/25 | Loss: 0.00210011
Iteration 11/25 | Loss: 0.00210011
Iteration 12/25 | Loss: 0.00210011
Iteration 13/25 | Loss: 0.00210011
Iteration 14/25 | Loss: 0.00210011
Iteration 15/25 | Loss: 0.00210011
Iteration 16/25 | Loss: 0.00210011
Iteration 17/25 | Loss: 0.00210011
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.002100111683830619, 0.002100111683830619, 0.002100111683830619, 0.002100111683830619, 0.002100111683830619]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002100111683830619

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00210011
Iteration 2/1000 | Loss: 0.00005310
Iteration 3/1000 | Loss: 0.00003561
Iteration 4/1000 | Loss: 0.00002858
Iteration 5/1000 | Loss: 0.00002408
Iteration 6/1000 | Loss: 0.00002198
Iteration 7/1000 | Loss: 0.00002054
Iteration 8/1000 | Loss: 0.00001951
Iteration 9/1000 | Loss: 0.00001882
Iteration 10/1000 | Loss: 0.00001836
Iteration 11/1000 | Loss: 0.00001799
Iteration 12/1000 | Loss: 0.00001763
Iteration 13/1000 | Loss: 0.00001731
Iteration 14/1000 | Loss: 0.00001731
Iteration 15/1000 | Loss: 0.00001730
Iteration 16/1000 | Loss: 0.00001727
Iteration 17/1000 | Loss: 0.00001720
Iteration 18/1000 | Loss: 0.00001717
Iteration 19/1000 | Loss: 0.00001716
Iteration 20/1000 | Loss: 0.00001710
Iteration 21/1000 | Loss: 0.00001709
Iteration 22/1000 | Loss: 0.00001703
Iteration 23/1000 | Loss: 0.00001699
Iteration 24/1000 | Loss: 0.00001699
Iteration 25/1000 | Loss: 0.00001685
Iteration 26/1000 | Loss: 0.00001684
Iteration 27/1000 | Loss: 0.00001684
Iteration 28/1000 | Loss: 0.00001683
Iteration 29/1000 | Loss: 0.00001683
Iteration 30/1000 | Loss: 0.00001674
Iteration 31/1000 | Loss: 0.00001670
Iteration 32/1000 | Loss: 0.00001666
Iteration 33/1000 | Loss: 0.00001666
Iteration 34/1000 | Loss: 0.00001664
Iteration 35/1000 | Loss: 0.00001663
Iteration 36/1000 | Loss: 0.00001662
Iteration 37/1000 | Loss: 0.00001658
Iteration 38/1000 | Loss: 0.00001657
Iteration 39/1000 | Loss: 0.00001656
Iteration 40/1000 | Loss: 0.00001655
Iteration 41/1000 | Loss: 0.00001655
Iteration 42/1000 | Loss: 0.00001654
Iteration 43/1000 | Loss: 0.00001654
Iteration 44/1000 | Loss: 0.00001653
Iteration 45/1000 | Loss: 0.00001653
Iteration 46/1000 | Loss: 0.00001652
Iteration 47/1000 | Loss: 0.00001649
Iteration 48/1000 | Loss: 0.00001647
Iteration 49/1000 | Loss: 0.00001646
Iteration 50/1000 | Loss: 0.00001646
Iteration 51/1000 | Loss: 0.00001646
Iteration 52/1000 | Loss: 0.00001646
Iteration 53/1000 | Loss: 0.00001646
Iteration 54/1000 | Loss: 0.00001646
Iteration 55/1000 | Loss: 0.00001646
Iteration 56/1000 | Loss: 0.00001646
Iteration 57/1000 | Loss: 0.00001645
Iteration 58/1000 | Loss: 0.00001645
Iteration 59/1000 | Loss: 0.00001644
Iteration 60/1000 | Loss: 0.00001643
Iteration 61/1000 | Loss: 0.00001642
Iteration 62/1000 | Loss: 0.00001642
Iteration 63/1000 | Loss: 0.00001642
Iteration 64/1000 | Loss: 0.00001642
Iteration 65/1000 | Loss: 0.00001641
Iteration 66/1000 | Loss: 0.00001641
Iteration 67/1000 | Loss: 0.00001641
Iteration 68/1000 | Loss: 0.00001641
Iteration 69/1000 | Loss: 0.00001641
Iteration 70/1000 | Loss: 0.00001641
Iteration 71/1000 | Loss: 0.00001641
Iteration 72/1000 | Loss: 0.00001640
Iteration 73/1000 | Loss: 0.00001640
Iteration 74/1000 | Loss: 0.00001640
Iteration 75/1000 | Loss: 0.00001640
Iteration 76/1000 | Loss: 0.00001639
Iteration 77/1000 | Loss: 0.00001639
Iteration 78/1000 | Loss: 0.00001639
Iteration 79/1000 | Loss: 0.00001639
Iteration 80/1000 | Loss: 0.00001639
Iteration 81/1000 | Loss: 0.00001639
Iteration 82/1000 | Loss: 0.00001638
Iteration 83/1000 | Loss: 0.00001638
Iteration 84/1000 | Loss: 0.00001638
Iteration 85/1000 | Loss: 0.00001637
Iteration 86/1000 | Loss: 0.00001637
Iteration 87/1000 | Loss: 0.00001636
Iteration 88/1000 | Loss: 0.00001636
Iteration 89/1000 | Loss: 0.00001636
Iteration 90/1000 | Loss: 0.00001636
Iteration 91/1000 | Loss: 0.00001635
Iteration 92/1000 | Loss: 0.00001635
Iteration 93/1000 | Loss: 0.00001635
Iteration 94/1000 | Loss: 0.00001634
Iteration 95/1000 | Loss: 0.00001634
Iteration 96/1000 | Loss: 0.00001634
Iteration 97/1000 | Loss: 0.00001633
Iteration 98/1000 | Loss: 0.00001632
Iteration 99/1000 | Loss: 0.00001631
Iteration 100/1000 | Loss: 0.00001630
Iteration 101/1000 | Loss: 0.00001630
Iteration 102/1000 | Loss: 0.00001629
Iteration 103/1000 | Loss: 0.00001629
Iteration 104/1000 | Loss: 0.00001629
Iteration 105/1000 | Loss: 0.00001628
Iteration 106/1000 | Loss: 0.00001628
Iteration 107/1000 | Loss: 0.00001628
Iteration 108/1000 | Loss: 0.00001627
Iteration 109/1000 | Loss: 0.00001626
Iteration 110/1000 | Loss: 0.00001625
Iteration 111/1000 | Loss: 0.00001624
Iteration 112/1000 | Loss: 0.00001623
Iteration 113/1000 | Loss: 0.00001623
Iteration 114/1000 | Loss: 0.00001623
Iteration 115/1000 | Loss: 0.00001622
Iteration 116/1000 | Loss: 0.00001622
Iteration 117/1000 | Loss: 0.00001622
Iteration 118/1000 | Loss: 0.00001622
Iteration 119/1000 | Loss: 0.00001622
Iteration 120/1000 | Loss: 0.00001621
Iteration 121/1000 | Loss: 0.00001621
Iteration 122/1000 | Loss: 0.00001621
Iteration 123/1000 | Loss: 0.00001621
Iteration 124/1000 | Loss: 0.00001621
Iteration 125/1000 | Loss: 0.00001621
Iteration 126/1000 | Loss: 0.00001621
Iteration 127/1000 | Loss: 0.00001621
Iteration 128/1000 | Loss: 0.00001621
Iteration 129/1000 | Loss: 0.00001621
Iteration 130/1000 | Loss: 0.00001621
Iteration 131/1000 | Loss: 0.00001621
Iteration 132/1000 | Loss: 0.00001620
Iteration 133/1000 | Loss: 0.00001620
Iteration 134/1000 | Loss: 0.00001620
Iteration 135/1000 | Loss: 0.00001619
Iteration 136/1000 | Loss: 0.00001619
Iteration 137/1000 | Loss: 0.00001619
Iteration 138/1000 | Loss: 0.00001618
Iteration 139/1000 | Loss: 0.00001618
Iteration 140/1000 | Loss: 0.00001618
Iteration 141/1000 | Loss: 0.00001617
Iteration 142/1000 | Loss: 0.00001617
Iteration 143/1000 | Loss: 0.00001617
Iteration 144/1000 | Loss: 0.00001617
Iteration 145/1000 | Loss: 0.00001616
Iteration 146/1000 | Loss: 0.00001616
Iteration 147/1000 | Loss: 0.00001616
Iteration 148/1000 | Loss: 0.00001615
Iteration 149/1000 | Loss: 0.00001615
Iteration 150/1000 | Loss: 0.00001615
Iteration 151/1000 | Loss: 0.00001614
Iteration 152/1000 | Loss: 0.00001614
Iteration 153/1000 | Loss: 0.00001614
Iteration 154/1000 | Loss: 0.00001614
Iteration 155/1000 | Loss: 0.00001614
Iteration 156/1000 | Loss: 0.00001614
Iteration 157/1000 | Loss: 0.00001614
Iteration 158/1000 | Loss: 0.00001614
Iteration 159/1000 | Loss: 0.00001614
Iteration 160/1000 | Loss: 0.00001614
Iteration 161/1000 | Loss: 0.00001614
Iteration 162/1000 | Loss: 0.00001613
Iteration 163/1000 | Loss: 0.00001613
Iteration 164/1000 | Loss: 0.00001613
Iteration 165/1000 | Loss: 0.00001613
Iteration 166/1000 | Loss: 0.00001613
Iteration 167/1000 | Loss: 0.00001613
Iteration 168/1000 | Loss: 0.00001613
Iteration 169/1000 | Loss: 0.00001613
Iteration 170/1000 | Loss: 0.00001612
Iteration 171/1000 | Loss: 0.00001612
Iteration 172/1000 | Loss: 0.00001612
Iteration 173/1000 | Loss: 0.00001612
Iteration 174/1000 | Loss: 0.00001612
Iteration 175/1000 | Loss: 0.00001612
Iteration 176/1000 | Loss: 0.00001611
Iteration 177/1000 | Loss: 0.00001611
Iteration 178/1000 | Loss: 0.00001611
Iteration 179/1000 | Loss: 0.00001611
Iteration 180/1000 | Loss: 0.00001610
Iteration 181/1000 | Loss: 0.00001610
Iteration 182/1000 | Loss: 0.00001610
Iteration 183/1000 | Loss: 0.00001610
Iteration 184/1000 | Loss: 0.00001610
Iteration 185/1000 | Loss: 0.00001610
Iteration 186/1000 | Loss: 0.00001610
Iteration 187/1000 | Loss: 0.00001610
Iteration 188/1000 | Loss: 0.00001610
Iteration 189/1000 | Loss: 0.00001610
Iteration 190/1000 | Loss: 0.00001610
Iteration 191/1000 | Loss: 0.00001610
Iteration 192/1000 | Loss: 0.00001610
Iteration 193/1000 | Loss: 0.00001609
Iteration 194/1000 | Loss: 0.00001609
Iteration 195/1000 | Loss: 0.00001609
Iteration 196/1000 | Loss: 0.00001609
Iteration 197/1000 | Loss: 0.00001609
Iteration 198/1000 | Loss: 0.00001609
Iteration 199/1000 | Loss: 0.00001609
Iteration 200/1000 | Loss: 0.00001609
Iteration 201/1000 | Loss: 0.00001609
Iteration 202/1000 | Loss: 0.00001609
Iteration 203/1000 | Loss: 0.00001608
Iteration 204/1000 | Loss: 0.00001608
Iteration 205/1000 | Loss: 0.00001608
Iteration 206/1000 | Loss: 0.00001608
Iteration 207/1000 | Loss: 0.00001608
Iteration 208/1000 | Loss: 0.00001607
Iteration 209/1000 | Loss: 0.00001607
Iteration 210/1000 | Loss: 0.00001607
Iteration 211/1000 | Loss: 0.00001607
Iteration 212/1000 | Loss: 0.00001606
Iteration 213/1000 | Loss: 0.00001606
Iteration 214/1000 | Loss: 0.00001606
Iteration 215/1000 | Loss: 0.00001606
Iteration 216/1000 | Loss: 0.00001606
Iteration 217/1000 | Loss: 0.00001605
Iteration 218/1000 | Loss: 0.00001605
Iteration 219/1000 | Loss: 0.00001605
Iteration 220/1000 | Loss: 0.00001605
Iteration 221/1000 | Loss: 0.00001605
Iteration 222/1000 | Loss: 0.00001604
Iteration 223/1000 | Loss: 0.00001604
Iteration 224/1000 | Loss: 0.00001604
Iteration 225/1000 | Loss: 0.00001604
Iteration 226/1000 | Loss: 0.00001604
Iteration 227/1000 | Loss: 0.00001604
Iteration 228/1000 | Loss: 0.00001604
Iteration 229/1000 | Loss: 0.00001604
Iteration 230/1000 | Loss: 0.00001604
Iteration 231/1000 | Loss: 0.00001604
Iteration 232/1000 | Loss: 0.00001604
Iteration 233/1000 | Loss: 0.00001603
Iteration 234/1000 | Loss: 0.00001603
Iteration 235/1000 | Loss: 0.00001603
Iteration 236/1000 | Loss: 0.00001603
Iteration 237/1000 | Loss: 0.00001603
Iteration 238/1000 | Loss: 0.00001603
Iteration 239/1000 | Loss: 0.00001603
Iteration 240/1000 | Loss: 0.00001603
Iteration 241/1000 | Loss: 0.00001603
Iteration 242/1000 | Loss: 0.00001603
Iteration 243/1000 | Loss: 0.00001603
Iteration 244/1000 | Loss: 0.00001603
Iteration 245/1000 | Loss: 0.00001603
Iteration 246/1000 | Loss: 0.00001603
Iteration 247/1000 | Loss: 0.00001603
Iteration 248/1000 | Loss: 0.00001603
Iteration 249/1000 | Loss: 0.00001603
Iteration 250/1000 | Loss: 0.00001603
Iteration 251/1000 | Loss: 0.00001603
Iteration 252/1000 | Loss: 0.00001603
Iteration 253/1000 | Loss: 0.00001603
Iteration 254/1000 | Loss: 0.00001603
Iteration 255/1000 | Loss: 0.00001603
Iteration 256/1000 | Loss: 0.00001603
Iteration 257/1000 | Loss: 0.00001603
Iteration 258/1000 | Loss: 0.00001603
Iteration 259/1000 | Loss: 0.00001603
Iteration 260/1000 | Loss: 0.00001603
Iteration 261/1000 | Loss: 0.00001603
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 261. Stopping optimization.
Last 5 losses: [1.6027619494707324e-05, 1.6027619494707324e-05, 1.6027619494707324e-05, 1.6027619494707324e-05, 1.6027619494707324e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6027619494707324e-05

Optimization complete. Final v2v error: 3.321293830871582 mm

Highest mean error: 5.291995525360107 mm for frame 89

Lowest mean error: 2.7574691772460938 mm for frame 32

Saving results

Total time: 54.10571813583374
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00541979
Iteration 2/25 | Loss: 0.00157338
Iteration 3/25 | Loss: 0.00142264
Iteration 4/25 | Loss: 0.00139606
Iteration 5/25 | Loss: 0.00139759
Iteration 6/25 | Loss: 0.00135891
Iteration 7/25 | Loss: 0.00135722
Iteration 8/25 | Loss: 0.00135689
Iteration 9/25 | Loss: 0.00135673
Iteration 10/25 | Loss: 0.00135660
Iteration 11/25 | Loss: 0.00135657
Iteration 12/25 | Loss: 0.00135656
Iteration 13/25 | Loss: 0.00135656
Iteration 14/25 | Loss: 0.00135656
Iteration 15/25 | Loss: 0.00135656
Iteration 16/25 | Loss: 0.00135656
Iteration 17/25 | Loss: 0.00135656
Iteration 18/25 | Loss: 0.00135656
Iteration 19/25 | Loss: 0.00135655
Iteration 20/25 | Loss: 0.00135655
Iteration 21/25 | Loss: 0.00135655
Iteration 22/25 | Loss: 0.00135655
Iteration 23/25 | Loss: 0.00135655
Iteration 24/25 | Loss: 0.00135655
Iteration 25/25 | Loss: 0.00135655

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.66120505
Iteration 2/25 | Loss: 0.00205618
Iteration 3/25 | Loss: 0.00205616
Iteration 4/25 | Loss: 0.00205616
Iteration 5/25 | Loss: 0.00205616
Iteration 6/25 | Loss: 0.00205615
Iteration 7/25 | Loss: 0.00205615
Iteration 8/25 | Loss: 0.00205615
Iteration 9/25 | Loss: 0.00205615
Iteration 10/25 | Loss: 0.00205615
Iteration 11/25 | Loss: 0.00205615
Iteration 12/25 | Loss: 0.00205615
Iteration 13/25 | Loss: 0.00205615
Iteration 14/25 | Loss: 0.00205615
Iteration 15/25 | Loss: 0.00205615
Iteration 16/25 | Loss: 0.00205615
Iteration 17/25 | Loss: 0.00205615
Iteration 18/25 | Loss: 0.00205615
Iteration 19/25 | Loss: 0.00205615
Iteration 20/25 | Loss: 0.00205615
Iteration 21/25 | Loss: 0.00205615
Iteration 22/25 | Loss: 0.00205615
Iteration 23/25 | Loss: 0.00205615
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0020561530254781246, 0.0020561530254781246, 0.0020561530254781246, 0.0020561530254781246, 0.0020561530254781246]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020561530254781246

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00205615
Iteration 2/1000 | Loss: 0.00003735
Iteration 3/1000 | Loss: 0.00002657
Iteration 4/1000 | Loss: 0.00002392
Iteration 5/1000 | Loss: 0.00002229
Iteration 6/1000 | Loss: 0.00002110
Iteration 7/1000 | Loss: 0.00002034
Iteration 8/1000 | Loss: 0.00001989
Iteration 9/1000 | Loss: 0.00001952
Iteration 10/1000 | Loss: 0.00001912
Iteration 11/1000 | Loss: 0.00001885
Iteration 12/1000 | Loss: 0.00001865
Iteration 13/1000 | Loss: 0.00001859
Iteration 14/1000 | Loss: 0.00001857
Iteration 15/1000 | Loss: 0.00001844
Iteration 16/1000 | Loss: 0.00001828
Iteration 17/1000 | Loss: 0.00001825
Iteration 18/1000 | Loss: 0.00001812
Iteration 19/1000 | Loss: 0.00001810
Iteration 20/1000 | Loss: 0.00001805
Iteration 21/1000 | Loss: 0.00001801
Iteration 22/1000 | Loss: 0.00001799
Iteration 23/1000 | Loss: 0.00001799
Iteration 24/1000 | Loss: 0.00001798
Iteration 25/1000 | Loss: 0.00001794
Iteration 26/1000 | Loss: 0.00001793
Iteration 27/1000 | Loss: 0.00001792
Iteration 28/1000 | Loss: 0.00001792
Iteration 29/1000 | Loss: 0.00001791
Iteration 30/1000 | Loss: 0.00001790
Iteration 31/1000 | Loss: 0.00001789
Iteration 32/1000 | Loss: 0.00001788
Iteration 33/1000 | Loss: 0.00001788
Iteration 34/1000 | Loss: 0.00001787
Iteration 35/1000 | Loss: 0.00001787
Iteration 36/1000 | Loss: 0.00001786
Iteration 37/1000 | Loss: 0.00001786
Iteration 38/1000 | Loss: 0.00001785
Iteration 39/1000 | Loss: 0.00001785
Iteration 40/1000 | Loss: 0.00001785
Iteration 41/1000 | Loss: 0.00001784
Iteration 42/1000 | Loss: 0.00001784
Iteration 43/1000 | Loss: 0.00001783
Iteration 44/1000 | Loss: 0.00001783
Iteration 45/1000 | Loss: 0.00001782
Iteration 46/1000 | Loss: 0.00001782
Iteration 47/1000 | Loss: 0.00001782
Iteration 48/1000 | Loss: 0.00001781
Iteration 49/1000 | Loss: 0.00001780
Iteration 50/1000 | Loss: 0.00001780
Iteration 51/1000 | Loss: 0.00001779
Iteration 52/1000 | Loss: 0.00001779
Iteration 53/1000 | Loss: 0.00001779
Iteration 54/1000 | Loss: 0.00001779
Iteration 55/1000 | Loss: 0.00001779
Iteration 56/1000 | Loss: 0.00001779
Iteration 57/1000 | Loss: 0.00001778
Iteration 58/1000 | Loss: 0.00001778
Iteration 59/1000 | Loss: 0.00001778
Iteration 60/1000 | Loss: 0.00001778
Iteration 61/1000 | Loss: 0.00001777
Iteration 62/1000 | Loss: 0.00001777
Iteration 63/1000 | Loss: 0.00001777
Iteration 64/1000 | Loss: 0.00001776
Iteration 65/1000 | Loss: 0.00001776
Iteration 66/1000 | Loss: 0.00001775
Iteration 67/1000 | Loss: 0.00001775
Iteration 68/1000 | Loss: 0.00001774
Iteration 69/1000 | Loss: 0.00001774
Iteration 70/1000 | Loss: 0.00001774
Iteration 71/1000 | Loss: 0.00001774
Iteration 72/1000 | Loss: 0.00001774
Iteration 73/1000 | Loss: 0.00001773
Iteration 74/1000 | Loss: 0.00001773
Iteration 75/1000 | Loss: 0.00001772
Iteration 76/1000 | Loss: 0.00001770
Iteration 77/1000 | Loss: 0.00001770
Iteration 78/1000 | Loss: 0.00001768
Iteration 79/1000 | Loss: 0.00001768
Iteration 80/1000 | Loss: 0.00001767
Iteration 81/1000 | Loss: 0.00001766
Iteration 82/1000 | Loss: 0.00001765
Iteration 83/1000 | Loss: 0.00001765
Iteration 84/1000 | Loss: 0.00001764
Iteration 85/1000 | Loss: 0.00001764
Iteration 86/1000 | Loss: 0.00001764
Iteration 87/1000 | Loss: 0.00001763
Iteration 88/1000 | Loss: 0.00001763
Iteration 89/1000 | Loss: 0.00001763
Iteration 90/1000 | Loss: 0.00001762
Iteration 91/1000 | Loss: 0.00001762
Iteration 92/1000 | Loss: 0.00001762
Iteration 93/1000 | Loss: 0.00001761
Iteration 94/1000 | Loss: 0.00001761
Iteration 95/1000 | Loss: 0.00001760
Iteration 96/1000 | Loss: 0.00001760
Iteration 97/1000 | Loss: 0.00001759
Iteration 98/1000 | Loss: 0.00001759
Iteration 99/1000 | Loss: 0.00001759
Iteration 100/1000 | Loss: 0.00001758
Iteration 101/1000 | Loss: 0.00001758
Iteration 102/1000 | Loss: 0.00001758
Iteration 103/1000 | Loss: 0.00001758
Iteration 104/1000 | Loss: 0.00001757
Iteration 105/1000 | Loss: 0.00001757
Iteration 106/1000 | Loss: 0.00001757
Iteration 107/1000 | Loss: 0.00001757
Iteration 108/1000 | Loss: 0.00001757
Iteration 109/1000 | Loss: 0.00001757
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.75738623511279e-05, 1.75738623511279e-05, 1.75738623511279e-05, 1.75738623511279e-05, 1.75738623511279e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.75738623511279e-05

Optimization complete. Final v2v error: 3.530238628387451 mm

Highest mean error: 4.591191291809082 mm for frame 107

Lowest mean error: 3.028813123703003 mm for frame 127

Saving results

Total time: 57.43344688415527
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00894275
Iteration 2/25 | Loss: 0.00150755
Iteration 3/25 | Loss: 0.00141097
Iteration 4/25 | Loss: 0.00139256
Iteration 5/25 | Loss: 0.00138679
Iteration 6/25 | Loss: 0.00138550
Iteration 7/25 | Loss: 0.00138550
Iteration 8/25 | Loss: 0.00138550
Iteration 9/25 | Loss: 0.00138550
Iteration 10/25 | Loss: 0.00138550
Iteration 11/25 | Loss: 0.00138550
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013854982098564506, 0.0013854982098564506, 0.0013854982098564506, 0.0013854982098564506, 0.0013854982098564506]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013854982098564506

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27446699
Iteration 2/25 | Loss: 0.00183969
Iteration 3/25 | Loss: 0.00183968
Iteration 4/25 | Loss: 0.00183968
Iteration 5/25 | Loss: 0.00183968
Iteration 6/25 | Loss: 0.00183968
Iteration 7/25 | Loss: 0.00183968
Iteration 8/25 | Loss: 0.00183968
Iteration 9/25 | Loss: 0.00183968
Iteration 10/25 | Loss: 0.00183968
Iteration 11/25 | Loss: 0.00183968
Iteration 12/25 | Loss: 0.00183968
Iteration 13/25 | Loss: 0.00183968
Iteration 14/25 | Loss: 0.00183968
Iteration 15/25 | Loss: 0.00183968
Iteration 16/25 | Loss: 0.00183968
Iteration 17/25 | Loss: 0.00183968
Iteration 18/25 | Loss: 0.00183968
Iteration 19/25 | Loss: 0.00183968
Iteration 20/25 | Loss: 0.00183968
Iteration 21/25 | Loss: 0.00183968
Iteration 22/25 | Loss: 0.00183968
Iteration 23/25 | Loss: 0.00183968
Iteration 24/25 | Loss: 0.00183968
Iteration 25/25 | Loss: 0.00183968

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00183968
Iteration 2/1000 | Loss: 0.00004867
Iteration 3/1000 | Loss: 0.00003461
Iteration 4/1000 | Loss: 0.00002854
Iteration 5/1000 | Loss: 0.00002651
Iteration 6/1000 | Loss: 0.00002539
Iteration 7/1000 | Loss: 0.00002439
Iteration 8/1000 | Loss: 0.00002371
Iteration 9/1000 | Loss: 0.00002303
Iteration 10/1000 | Loss: 0.00002273
Iteration 11/1000 | Loss: 0.00002245
Iteration 12/1000 | Loss: 0.00002217
Iteration 13/1000 | Loss: 0.00002202
Iteration 14/1000 | Loss: 0.00002190
Iteration 15/1000 | Loss: 0.00002170
Iteration 16/1000 | Loss: 0.00002162
Iteration 17/1000 | Loss: 0.00002154
Iteration 18/1000 | Loss: 0.00002147
Iteration 19/1000 | Loss: 0.00002146
Iteration 20/1000 | Loss: 0.00002146
Iteration 21/1000 | Loss: 0.00002145
Iteration 22/1000 | Loss: 0.00002138
Iteration 23/1000 | Loss: 0.00002136
Iteration 24/1000 | Loss: 0.00002135
Iteration 25/1000 | Loss: 0.00002133
Iteration 26/1000 | Loss: 0.00002131
Iteration 27/1000 | Loss: 0.00002130
Iteration 28/1000 | Loss: 0.00002130
Iteration 29/1000 | Loss: 0.00002129
Iteration 30/1000 | Loss: 0.00002129
Iteration 31/1000 | Loss: 0.00002128
Iteration 32/1000 | Loss: 0.00002124
Iteration 33/1000 | Loss: 0.00002121
Iteration 34/1000 | Loss: 0.00002120
Iteration 35/1000 | Loss: 0.00002120
Iteration 36/1000 | Loss: 0.00002119
Iteration 37/1000 | Loss: 0.00002119
Iteration 38/1000 | Loss: 0.00002118
Iteration 39/1000 | Loss: 0.00002118
Iteration 40/1000 | Loss: 0.00002117
Iteration 41/1000 | Loss: 0.00002117
Iteration 42/1000 | Loss: 0.00002115
Iteration 43/1000 | Loss: 0.00002114
Iteration 44/1000 | Loss: 0.00002114
Iteration 45/1000 | Loss: 0.00002113
Iteration 46/1000 | Loss: 0.00002113
Iteration 47/1000 | Loss: 0.00002112
Iteration 48/1000 | Loss: 0.00002112
Iteration 49/1000 | Loss: 0.00002112
Iteration 50/1000 | Loss: 0.00002112
Iteration 51/1000 | Loss: 0.00002111
Iteration 52/1000 | Loss: 0.00002111
Iteration 53/1000 | Loss: 0.00002110
Iteration 54/1000 | Loss: 0.00002110
Iteration 55/1000 | Loss: 0.00002109
Iteration 56/1000 | Loss: 0.00002109
Iteration 57/1000 | Loss: 0.00002108
Iteration 58/1000 | Loss: 0.00002108
Iteration 59/1000 | Loss: 0.00002108
Iteration 60/1000 | Loss: 0.00002107
Iteration 61/1000 | Loss: 0.00002107
Iteration 62/1000 | Loss: 0.00002107
Iteration 63/1000 | Loss: 0.00002106
Iteration 64/1000 | Loss: 0.00002106
Iteration 65/1000 | Loss: 0.00002106
Iteration 66/1000 | Loss: 0.00002106
Iteration 67/1000 | Loss: 0.00002106
Iteration 68/1000 | Loss: 0.00002106
Iteration 69/1000 | Loss: 0.00002105
Iteration 70/1000 | Loss: 0.00002105
Iteration 71/1000 | Loss: 0.00002105
Iteration 72/1000 | Loss: 0.00002105
Iteration 73/1000 | Loss: 0.00002105
Iteration 74/1000 | Loss: 0.00002105
Iteration 75/1000 | Loss: 0.00002105
Iteration 76/1000 | Loss: 0.00002105
Iteration 77/1000 | Loss: 0.00002105
Iteration 78/1000 | Loss: 0.00002105
Iteration 79/1000 | Loss: 0.00002105
Iteration 80/1000 | Loss: 0.00002104
Iteration 81/1000 | Loss: 0.00002104
Iteration 82/1000 | Loss: 0.00002103
Iteration 83/1000 | Loss: 0.00002103
Iteration 84/1000 | Loss: 0.00002103
Iteration 85/1000 | Loss: 0.00002103
Iteration 86/1000 | Loss: 0.00002102
Iteration 87/1000 | Loss: 0.00002102
Iteration 88/1000 | Loss: 0.00002101
Iteration 89/1000 | Loss: 0.00002101
Iteration 90/1000 | Loss: 0.00002101
Iteration 91/1000 | Loss: 0.00002101
Iteration 92/1000 | Loss: 0.00002100
Iteration 93/1000 | Loss: 0.00002100
Iteration 94/1000 | Loss: 0.00002099
Iteration 95/1000 | Loss: 0.00002099
Iteration 96/1000 | Loss: 0.00002099
Iteration 97/1000 | Loss: 0.00002099
Iteration 98/1000 | Loss: 0.00002099
Iteration 99/1000 | Loss: 0.00002099
Iteration 100/1000 | Loss: 0.00002099
Iteration 101/1000 | Loss: 0.00002099
Iteration 102/1000 | Loss: 0.00002099
Iteration 103/1000 | Loss: 0.00002099
Iteration 104/1000 | Loss: 0.00002098
Iteration 105/1000 | Loss: 0.00002098
Iteration 106/1000 | Loss: 0.00002098
Iteration 107/1000 | Loss: 0.00002097
Iteration 108/1000 | Loss: 0.00002097
Iteration 109/1000 | Loss: 0.00002097
Iteration 110/1000 | Loss: 0.00002096
Iteration 111/1000 | Loss: 0.00002096
Iteration 112/1000 | Loss: 0.00002096
Iteration 113/1000 | Loss: 0.00002096
Iteration 114/1000 | Loss: 0.00002096
Iteration 115/1000 | Loss: 0.00002096
Iteration 116/1000 | Loss: 0.00002096
Iteration 117/1000 | Loss: 0.00002096
Iteration 118/1000 | Loss: 0.00002096
Iteration 119/1000 | Loss: 0.00002096
Iteration 120/1000 | Loss: 0.00002095
Iteration 121/1000 | Loss: 0.00002095
Iteration 122/1000 | Loss: 0.00002095
Iteration 123/1000 | Loss: 0.00002094
Iteration 124/1000 | Loss: 0.00002094
Iteration 125/1000 | Loss: 0.00002094
Iteration 126/1000 | Loss: 0.00002094
Iteration 127/1000 | Loss: 0.00002093
Iteration 128/1000 | Loss: 0.00002093
Iteration 129/1000 | Loss: 0.00002093
Iteration 130/1000 | Loss: 0.00002093
Iteration 131/1000 | Loss: 0.00002093
Iteration 132/1000 | Loss: 0.00002093
Iteration 133/1000 | Loss: 0.00002092
Iteration 134/1000 | Loss: 0.00002092
Iteration 135/1000 | Loss: 0.00002092
Iteration 136/1000 | Loss: 0.00002092
Iteration 137/1000 | Loss: 0.00002092
Iteration 138/1000 | Loss: 0.00002092
Iteration 139/1000 | Loss: 0.00002092
Iteration 140/1000 | Loss: 0.00002092
Iteration 141/1000 | Loss: 0.00002091
Iteration 142/1000 | Loss: 0.00002091
Iteration 143/1000 | Loss: 0.00002091
Iteration 144/1000 | Loss: 0.00002091
Iteration 145/1000 | Loss: 0.00002091
Iteration 146/1000 | Loss: 0.00002091
Iteration 147/1000 | Loss: 0.00002091
Iteration 148/1000 | Loss: 0.00002091
Iteration 149/1000 | Loss: 0.00002091
Iteration 150/1000 | Loss: 0.00002091
Iteration 151/1000 | Loss: 0.00002091
Iteration 152/1000 | Loss: 0.00002091
Iteration 153/1000 | Loss: 0.00002090
Iteration 154/1000 | Loss: 0.00002090
Iteration 155/1000 | Loss: 0.00002090
Iteration 156/1000 | Loss: 0.00002090
Iteration 157/1000 | Loss: 0.00002090
Iteration 158/1000 | Loss: 0.00002090
Iteration 159/1000 | Loss: 0.00002090
Iteration 160/1000 | Loss: 0.00002089
Iteration 161/1000 | Loss: 0.00002089
Iteration 162/1000 | Loss: 0.00002089
Iteration 163/1000 | Loss: 0.00002089
Iteration 164/1000 | Loss: 0.00002089
Iteration 165/1000 | Loss: 0.00002089
Iteration 166/1000 | Loss: 0.00002089
Iteration 167/1000 | Loss: 0.00002089
Iteration 168/1000 | Loss: 0.00002089
Iteration 169/1000 | Loss: 0.00002089
Iteration 170/1000 | Loss: 0.00002089
Iteration 171/1000 | Loss: 0.00002089
Iteration 172/1000 | Loss: 0.00002089
Iteration 173/1000 | Loss: 0.00002089
Iteration 174/1000 | Loss: 0.00002089
Iteration 175/1000 | Loss: 0.00002089
Iteration 176/1000 | Loss: 0.00002088
Iteration 177/1000 | Loss: 0.00002088
Iteration 178/1000 | Loss: 0.00002088
Iteration 179/1000 | Loss: 0.00002088
Iteration 180/1000 | Loss: 0.00002088
Iteration 181/1000 | Loss: 0.00002088
Iteration 182/1000 | Loss: 0.00002088
Iteration 183/1000 | Loss: 0.00002088
Iteration 184/1000 | Loss: 0.00002088
Iteration 185/1000 | Loss: 0.00002088
Iteration 186/1000 | Loss: 0.00002088
Iteration 187/1000 | Loss: 0.00002088
Iteration 188/1000 | Loss: 0.00002088
Iteration 189/1000 | Loss: 0.00002088
Iteration 190/1000 | Loss: 0.00002087
Iteration 191/1000 | Loss: 0.00002087
Iteration 192/1000 | Loss: 0.00002087
Iteration 193/1000 | Loss: 0.00002087
Iteration 194/1000 | Loss: 0.00002087
Iteration 195/1000 | Loss: 0.00002087
Iteration 196/1000 | Loss: 0.00002087
Iteration 197/1000 | Loss: 0.00002087
Iteration 198/1000 | Loss: 0.00002087
Iteration 199/1000 | Loss: 0.00002087
Iteration 200/1000 | Loss: 0.00002087
Iteration 201/1000 | Loss: 0.00002087
Iteration 202/1000 | Loss: 0.00002086
Iteration 203/1000 | Loss: 0.00002086
Iteration 204/1000 | Loss: 0.00002086
Iteration 205/1000 | Loss: 0.00002086
Iteration 206/1000 | Loss: 0.00002086
Iteration 207/1000 | Loss: 0.00002086
Iteration 208/1000 | Loss: 0.00002086
Iteration 209/1000 | Loss: 0.00002086
Iteration 210/1000 | Loss: 0.00002086
Iteration 211/1000 | Loss: 0.00002086
Iteration 212/1000 | Loss: 0.00002086
Iteration 213/1000 | Loss: 0.00002086
Iteration 214/1000 | Loss: 0.00002086
Iteration 215/1000 | Loss: 0.00002086
Iteration 216/1000 | Loss: 0.00002086
Iteration 217/1000 | Loss: 0.00002086
Iteration 218/1000 | Loss: 0.00002086
Iteration 219/1000 | Loss: 0.00002085
Iteration 220/1000 | Loss: 0.00002085
Iteration 221/1000 | Loss: 0.00002085
Iteration 222/1000 | Loss: 0.00002085
Iteration 223/1000 | Loss: 0.00002085
Iteration 224/1000 | Loss: 0.00002085
Iteration 225/1000 | Loss: 0.00002085
Iteration 226/1000 | Loss: 0.00002085
Iteration 227/1000 | Loss: 0.00002085
Iteration 228/1000 | Loss: 0.00002085
Iteration 229/1000 | Loss: 0.00002085
Iteration 230/1000 | Loss: 0.00002085
Iteration 231/1000 | Loss: 0.00002085
Iteration 232/1000 | Loss: 0.00002085
Iteration 233/1000 | Loss: 0.00002085
Iteration 234/1000 | Loss: 0.00002085
Iteration 235/1000 | Loss: 0.00002085
Iteration 236/1000 | Loss: 0.00002084
Iteration 237/1000 | Loss: 0.00002084
Iteration 238/1000 | Loss: 0.00002084
Iteration 239/1000 | Loss: 0.00002084
Iteration 240/1000 | Loss: 0.00002084
Iteration 241/1000 | Loss: 0.00002084
Iteration 242/1000 | Loss: 0.00002084
Iteration 243/1000 | Loss: 0.00002084
Iteration 244/1000 | Loss: 0.00002084
Iteration 245/1000 | Loss: 0.00002084
Iteration 246/1000 | Loss: 0.00002084
Iteration 247/1000 | Loss: 0.00002084
Iteration 248/1000 | Loss: 0.00002084
Iteration 249/1000 | Loss: 0.00002084
Iteration 250/1000 | Loss: 0.00002084
Iteration 251/1000 | Loss: 0.00002084
Iteration 252/1000 | Loss: 0.00002084
Iteration 253/1000 | Loss: 0.00002084
Iteration 254/1000 | Loss: 0.00002084
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 254. Stopping optimization.
Last 5 losses: [2.083937761199195e-05, 2.083937761199195e-05, 2.083937761199195e-05, 2.083937761199195e-05, 2.083937761199195e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.083937761199195e-05

Optimization complete. Final v2v error: 3.838679313659668 mm

Highest mean error: 5.820621967315674 mm for frame 70

Lowest mean error: 3.3625898361206055 mm for frame 49

Saving results

Total time: 49.14756727218628
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1031/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1031.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1031
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00438496
Iteration 2/25 | Loss: 0.00143757
Iteration 3/25 | Loss: 0.00135841
Iteration 4/25 | Loss: 0.00134591
Iteration 5/25 | Loss: 0.00134183
Iteration 6/25 | Loss: 0.00134141
Iteration 7/25 | Loss: 0.00134141
Iteration 8/25 | Loss: 0.00134141
Iteration 9/25 | Loss: 0.00134141
Iteration 10/25 | Loss: 0.00134141
Iteration 11/25 | Loss: 0.00134141
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013414148706942797, 0.0013414148706942797, 0.0013414148706942797, 0.0013414148706942797, 0.0013414148706942797]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013414148706942797

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.49973345
Iteration 2/25 | Loss: 0.00186650
Iteration 3/25 | Loss: 0.00186648
Iteration 4/25 | Loss: 0.00186648
Iteration 5/25 | Loss: 0.00186648
Iteration 6/25 | Loss: 0.00186648
Iteration 7/25 | Loss: 0.00186648
Iteration 8/25 | Loss: 0.00186648
Iteration 9/25 | Loss: 0.00186648
Iteration 10/25 | Loss: 0.00186648
Iteration 11/25 | Loss: 0.00186648
Iteration 12/25 | Loss: 0.00186648
Iteration 13/25 | Loss: 0.00186648
Iteration 14/25 | Loss: 0.00186648
Iteration 15/25 | Loss: 0.00186648
Iteration 16/25 | Loss: 0.00186648
Iteration 17/25 | Loss: 0.00186648
Iteration 18/25 | Loss: 0.00186648
Iteration 19/25 | Loss: 0.00186648
Iteration 20/25 | Loss: 0.00186648
Iteration 21/25 | Loss: 0.00186648
Iteration 22/25 | Loss: 0.00186648
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0018664763774722815, 0.0018664763774722815, 0.0018664763774722815, 0.0018664763774722815, 0.0018664763774722815]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018664763774722815

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00186648
Iteration 2/1000 | Loss: 0.00002655
Iteration 3/1000 | Loss: 0.00002054
Iteration 4/1000 | Loss: 0.00001810
Iteration 5/1000 | Loss: 0.00001700
Iteration 6/1000 | Loss: 0.00001604
Iteration 7/1000 | Loss: 0.00001536
Iteration 8/1000 | Loss: 0.00001496
Iteration 9/1000 | Loss: 0.00001450
Iteration 10/1000 | Loss: 0.00001412
Iteration 11/1000 | Loss: 0.00001388
Iteration 12/1000 | Loss: 0.00001385
Iteration 13/1000 | Loss: 0.00001371
Iteration 14/1000 | Loss: 0.00001359
Iteration 15/1000 | Loss: 0.00001340
Iteration 16/1000 | Loss: 0.00001330
Iteration 17/1000 | Loss: 0.00001319
Iteration 18/1000 | Loss: 0.00001318
Iteration 19/1000 | Loss: 0.00001304
Iteration 20/1000 | Loss: 0.00001300
Iteration 21/1000 | Loss: 0.00001297
Iteration 22/1000 | Loss: 0.00001294
Iteration 23/1000 | Loss: 0.00001293
Iteration 24/1000 | Loss: 0.00001293
Iteration 25/1000 | Loss: 0.00001291
Iteration 26/1000 | Loss: 0.00001290
Iteration 27/1000 | Loss: 0.00001289
Iteration 28/1000 | Loss: 0.00001288
Iteration 29/1000 | Loss: 0.00001286
Iteration 30/1000 | Loss: 0.00001281
Iteration 31/1000 | Loss: 0.00001281
Iteration 32/1000 | Loss: 0.00001278
Iteration 33/1000 | Loss: 0.00001277
Iteration 34/1000 | Loss: 0.00001276
Iteration 35/1000 | Loss: 0.00001275
Iteration 36/1000 | Loss: 0.00001271
Iteration 37/1000 | Loss: 0.00001268
Iteration 38/1000 | Loss: 0.00001267
Iteration 39/1000 | Loss: 0.00001267
Iteration 40/1000 | Loss: 0.00001266
Iteration 41/1000 | Loss: 0.00001266
Iteration 42/1000 | Loss: 0.00001265
Iteration 43/1000 | Loss: 0.00001264
Iteration 44/1000 | Loss: 0.00001263
Iteration 45/1000 | Loss: 0.00001263
Iteration 46/1000 | Loss: 0.00001262
Iteration 47/1000 | Loss: 0.00001261
Iteration 48/1000 | Loss: 0.00001260
Iteration 49/1000 | Loss: 0.00001260
Iteration 50/1000 | Loss: 0.00001257
Iteration 51/1000 | Loss: 0.00001256
Iteration 52/1000 | Loss: 0.00001256
Iteration 53/1000 | Loss: 0.00001255
Iteration 54/1000 | Loss: 0.00001255
Iteration 55/1000 | Loss: 0.00001254
Iteration 56/1000 | Loss: 0.00001254
Iteration 57/1000 | Loss: 0.00001253
Iteration 58/1000 | Loss: 0.00001253
Iteration 59/1000 | Loss: 0.00001253
Iteration 60/1000 | Loss: 0.00001252
Iteration 61/1000 | Loss: 0.00001252
Iteration 62/1000 | Loss: 0.00001252
Iteration 63/1000 | Loss: 0.00001251
Iteration 64/1000 | Loss: 0.00001251
Iteration 65/1000 | Loss: 0.00001251
Iteration 66/1000 | Loss: 0.00001250
Iteration 67/1000 | Loss: 0.00001250
Iteration 68/1000 | Loss: 0.00001250
Iteration 69/1000 | Loss: 0.00001249
Iteration 70/1000 | Loss: 0.00001249
Iteration 71/1000 | Loss: 0.00001249
Iteration 72/1000 | Loss: 0.00001249
Iteration 73/1000 | Loss: 0.00001248
Iteration 74/1000 | Loss: 0.00001248
Iteration 75/1000 | Loss: 0.00001248
Iteration 76/1000 | Loss: 0.00001248
Iteration 77/1000 | Loss: 0.00001248
Iteration 78/1000 | Loss: 0.00001248
Iteration 79/1000 | Loss: 0.00001248
Iteration 80/1000 | Loss: 0.00001247
Iteration 81/1000 | Loss: 0.00001247
Iteration 82/1000 | Loss: 0.00001247
Iteration 83/1000 | Loss: 0.00001247
Iteration 84/1000 | Loss: 0.00001247
Iteration 85/1000 | Loss: 0.00001247
Iteration 86/1000 | Loss: 0.00001247
Iteration 87/1000 | Loss: 0.00001246
Iteration 88/1000 | Loss: 0.00001246
Iteration 89/1000 | Loss: 0.00001246
Iteration 90/1000 | Loss: 0.00001246
Iteration 91/1000 | Loss: 0.00001246
Iteration 92/1000 | Loss: 0.00001245
Iteration 93/1000 | Loss: 0.00001245
Iteration 94/1000 | Loss: 0.00001245
Iteration 95/1000 | Loss: 0.00001245
Iteration 96/1000 | Loss: 0.00001245
Iteration 97/1000 | Loss: 0.00001245
Iteration 98/1000 | Loss: 0.00001244
Iteration 99/1000 | Loss: 0.00001244
Iteration 100/1000 | Loss: 0.00001244
Iteration 101/1000 | Loss: 0.00001244
Iteration 102/1000 | Loss: 0.00001244
Iteration 103/1000 | Loss: 0.00001244
Iteration 104/1000 | Loss: 0.00001244
Iteration 105/1000 | Loss: 0.00001244
Iteration 106/1000 | Loss: 0.00001243
Iteration 107/1000 | Loss: 0.00001243
Iteration 108/1000 | Loss: 0.00001243
Iteration 109/1000 | Loss: 0.00001243
Iteration 110/1000 | Loss: 0.00001243
Iteration 111/1000 | Loss: 0.00001243
Iteration 112/1000 | Loss: 0.00001243
Iteration 113/1000 | Loss: 0.00001243
Iteration 114/1000 | Loss: 0.00001242
Iteration 115/1000 | Loss: 0.00001242
Iteration 116/1000 | Loss: 0.00001242
Iteration 117/1000 | Loss: 0.00001242
Iteration 118/1000 | Loss: 0.00001242
Iteration 119/1000 | Loss: 0.00001242
Iteration 120/1000 | Loss: 0.00001241
Iteration 121/1000 | Loss: 0.00001241
Iteration 122/1000 | Loss: 0.00001241
Iteration 123/1000 | Loss: 0.00001240
Iteration 124/1000 | Loss: 0.00001240
Iteration 125/1000 | Loss: 0.00001240
Iteration 126/1000 | Loss: 0.00001240
Iteration 127/1000 | Loss: 0.00001240
Iteration 128/1000 | Loss: 0.00001240
Iteration 129/1000 | Loss: 0.00001240
Iteration 130/1000 | Loss: 0.00001240
Iteration 131/1000 | Loss: 0.00001240
Iteration 132/1000 | Loss: 0.00001239
Iteration 133/1000 | Loss: 0.00001239
Iteration 134/1000 | Loss: 0.00001239
Iteration 135/1000 | Loss: 0.00001239
Iteration 136/1000 | Loss: 0.00001239
Iteration 137/1000 | Loss: 0.00001239
Iteration 138/1000 | Loss: 0.00001239
Iteration 139/1000 | Loss: 0.00001239
Iteration 140/1000 | Loss: 0.00001239
Iteration 141/1000 | Loss: 0.00001239
Iteration 142/1000 | Loss: 0.00001239
Iteration 143/1000 | Loss: 0.00001239
Iteration 144/1000 | Loss: 0.00001239
Iteration 145/1000 | Loss: 0.00001239
Iteration 146/1000 | Loss: 0.00001239
Iteration 147/1000 | Loss: 0.00001239
Iteration 148/1000 | Loss: 0.00001239
Iteration 149/1000 | Loss: 0.00001238
Iteration 150/1000 | Loss: 0.00001238
Iteration 151/1000 | Loss: 0.00001238
Iteration 152/1000 | Loss: 0.00001238
Iteration 153/1000 | Loss: 0.00001238
Iteration 154/1000 | Loss: 0.00001238
Iteration 155/1000 | Loss: 0.00001238
Iteration 156/1000 | Loss: 0.00001238
Iteration 157/1000 | Loss: 0.00001238
Iteration 158/1000 | Loss: 0.00001238
Iteration 159/1000 | Loss: 0.00001238
Iteration 160/1000 | Loss: 0.00001238
Iteration 161/1000 | Loss: 0.00001238
Iteration 162/1000 | Loss: 0.00001238
Iteration 163/1000 | Loss: 0.00001237
Iteration 164/1000 | Loss: 0.00001237
Iteration 165/1000 | Loss: 0.00001237
Iteration 166/1000 | Loss: 0.00001237
Iteration 167/1000 | Loss: 0.00001237
Iteration 168/1000 | Loss: 0.00001237
Iteration 169/1000 | Loss: 0.00001237
Iteration 170/1000 | Loss: 0.00001237
Iteration 171/1000 | Loss: 0.00001237
Iteration 172/1000 | Loss: 0.00001237
Iteration 173/1000 | Loss: 0.00001237
Iteration 174/1000 | Loss: 0.00001237
Iteration 175/1000 | Loss: 0.00001237
Iteration 176/1000 | Loss: 0.00001237
Iteration 177/1000 | Loss: 0.00001237
Iteration 178/1000 | Loss: 0.00001237
Iteration 179/1000 | Loss: 0.00001237
Iteration 180/1000 | Loss: 0.00001237
Iteration 181/1000 | Loss: 0.00001237
Iteration 182/1000 | Loss: 0.00001237
Iteration 183/1000 | Loss: 0.00001237
Iteration 184/1000 | Loss: 0.00001237
Iteration 185/1000 | Loss: 0.00001237
Iteration 186/1000 | Loss: 0.00001236
Iteration 187/1000 | Loss: 0.00001236
Iteration 188/1000 | Loss: 0.00001236
Iteration 189/1000 | Loss: 0.00001236
Iteration 190/1000 | Loss: 0.00001236
Iteration 191/1000 | Loss: 0.00001236
Iteration 192/1000 | Loss: 0.00001236
Iteration 193/1000 | Loss: 0.00001236
Iteration 194/1000 | Loss: 0.00001236
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 194. Stopping optimization.
Last 5 losses: [1.2364065696601756e-05, 1.2364065696601756e-05, 1.2364065696601756e-05, 1.2364065696601756e-05, 1.2364065696601756e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2364065696601756e-05

Optimization complete. Final v2v error: 3.0506837368011475 mm

Highest mean error: 3.6970770359039307 mm for frame 92

Lowest mean error: 2.7760095596313477 mm for frame 206

Saving results

Total time: 51.436497926712036
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1039
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00806036
Iteration 2/25 | Loss: 0.00142885
Iteration 3/25 | Loss: 0.00135756
Iteration 4/25 | Loss: 0.00134168
Iteration 5/25 | Loss: 0.00133664
Iteration 6/25 | Loss: 0.00133600
Iteration 7/25 | Loss: 0.00133600
Iteration 8/25 | Loss: 0.00133600
Iteration 9/25 | Loss: 0.00133600
Iteration 10/25 | Loss: 0.00133600
Iteration 11/25 | Loss: 0.00133600
Iteration 12/25 | Loss: 0.00133600
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001336000277660787, 0.001336000277660787, 0.001336000277660787, 0.001336000277660787, 0.001336000277660787]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001336000277660787

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29017711
Iteration 2/25 | Loss: 0.00173747
Iteration 3/25 | Loss: 0.00173747
Iteration 4/25 | Loss: 0.00173747
Iteration 5/25 | Loss: 0.00173747
Iteration 6/25 | Loss: 0.00173747
Iteration 7/25 | Loss: 0.00173747
Iteration 8/25 | Loss: 0.00173747
Iteration 9/25 | Loss: 0.00173747
Iteration 10/25 | Loss: 0.00173747
Iteration 11/25 | Loss: 0.00173747
Iteration 12/25 | Loss: 0.00173747
Iteration 13/25 | Loss: 0.00173746
Iteration 14/25 | Loss: 0.00173746
Iteration 15/25 | Loss: 0.00173746
Iteration 16/25 | Loss: 0.00173746
Iteration 17/25 | Loss: 0.00173746
Iteration 18/25 | Loss: 0.00173746
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0017374649178236723, 0.0017374649178236723, 0.0017374649178236723, 0.0017374649178236723, 0.0017374649178236723]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017374649178236723

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00173746
Iteration 2/1000 | Loss: 0.00002642
Iteration 3/1000 | Loss: 0.00001912
Iteration 4/1000 | Loss: 0.00001760
Iteration 5/1000 | Loss: 0.00001678
Iteration 6/1000 | Loss: 0.00001605
Iteration 7/1000 | Loss: 0.00001537
Iteration 8/1000 | Loss: 0.00001495
Iteration 9/1000 | Loss: 0.00001456
Iteration 10/1000 | Loss: 0.00001429
Iteration 11/1000 | Loss: 0.00001403
Iteration 12/1000 | Loss: 0.00001393
Iteration 13/1000 | Loss: 0.00001377
Iteration 14/1000 | Loss: 0.00001369
Iteration 15/1000 | Loss: 0.00001363
Iteration 16/1000 | Loss: 0.00001357
Iteration 17/1000 | Loss: 0.00001354
Iteration 18/1000 | Loss: 0.00001353
Iteration 19/1000 | Loss: 0.00001353
Iteration 20/1000 | Loss: 0.00001353
Iteration 21/1000 | Loss: 0.00001349
Iteration 22/1000 | Loss: 0.00001348
Iteration 23/1000 | Loss: 0.00001348
Iteration 24/1000 | Loss: 0.00001347
Iteration 25/1000 | Loss: 0.00001346
Iteration 26/1000 | Loss: 0.00001346
Iteration 27/1000 | Loss: 0.00001345
Iteration 28/1000 | Loss: 0.00001345
Iteration 29/1000 | Loss: 0.00001337
Iteration 30/1000 | Loss: 0.00001331
Iteration 31/1000 | Loss: 0.00001330
Iteration 32/1000 | Loss: 0.00001327
Iteration 33/1000 | Loss: 0.00001327
Iteration 34/1000 | Loss: 0.00001327
Iteration 35/1000 | Loss: 0.00001320
Iteration 36/1000 | Loss: 0.00001320
Iteration 37/1000 | Loss: 0.00001320
Iteration 38/1000 | Loss: 0.00001320
Iteration 39/1000 | Loss: 0.00001320
Iteration 40/1000 | Loss: 0.00001320
Iteration 41/1000 | Loss: 0.00001320
Iteration 42/1000 | Loss: 0.00001320
Iteration 43/1000 | Loss: 0.00001320
Iteration 44/1000 | Loss: 0.00001320
Iteration 45/1000 | Loss: 0.00001319
Iteration 46/1000 | Loss: 0.00001319
Iteration 47/1000 | Loss: 0.00001319
Iteration 48/1000 | Loss: 0.00001319
Iteration 49/1000 | Loss: 0.00001319
Iteration 50/1000 | Loss: 0.00001319
Iteration 51/1000 | Loss: 0.00001319
Iteration 52/1000 | Loss: 0.00001319
Iteration 53/1000 | Loss: 0.00001319
Iteration 54/1000 | Loss: 0.00001319
Iteration 55/1000 | Loss: 0.00001318
Iteration 56/1000 | Loss: 0.00001318
Iteration 57/1000 | Loss: 0.00001318
Iteration 58/1000 | Loss: 0.00001318
Iteration 59/1000 | Loss: 0.00001318
Iteration 60/1000 | Loss: 0.00001317
Iteration 61/1000 | Loss: 0.00001316
Iteration 62/1000 | Loss: 0.00001315
Iteration 63/1000 | Loss: 0.00001315
Iteration 64/1000 | Loss: 0.00001314
Iteration 65/1000 | Loss: 0.00001314
Iteration 66/1000 | Loss: 0.00001313
Iteration 67/1000 | Loss: 0.00001313
Iteration 68/1000 | Loss: 0.00001313
Iteration 69/1000 | Loss: 0.00001312
Iteration 70/1000 | Loss: 0.00001312
Iteration 71/1000 | Loss: 0.00001312
Iteration 72/1000 | Loss: 0.00001311
Iteration 73/1000 | Loss: 0.00001311
Iteration 74/1000 | Loss: 0.00001309
Iteration 75/1000 | Loss: 0.00001308
Iteration 76/1000 | Loss: 0.00001308
Iteration 77/1000 | Loss: 0.00001308
Iteration 78/1000 | Loss: 0.00001308
Iteration 79/1000 | Loss: 0.00001308
Iteration 80/1000 | Loss: 0.00001307
Iteration 81/1000 | Loss: 0.00001307
Iteration 82/1000 | Loss: 0.00001307
Iteration 83/1000 | Loss: 0.00001307
Iteration 84/1000 | Loss: 0.00001306
Iteration 85/1000 | Loss: 0.00001306
Iteration 86/1000 | Loss: 0.00001305
Iteration 87/1000 | Loss: 0.00001305
Iteration 88/1000 | Loss: 0.00001305
Iteration 89/1000 | Loss: 0.00001305
Iteration 90/1000 | Loss: 0.00001304
Iteration 91/1000 | Loss: 0.00001304
Iteration 92/1000 | Loss: 0.00001304
Iteration 93/1000 | Loss: 0.00001304
Iteration 94/1000 | Loss: 0.00001304
Iteration 95/1000 | Loss: 0.00001304
Iteration 96/1000 | Loss: 0.00001304
Iteration 97/1000 | Loss: 0.00001304
Iteration 98/1000 | Loss: 0.00001304
Iteration 99/1000 | Loss: 0.00001304
Iteration 100/1000 | Loss: 0.00001304
Iteration 101/1000 | Loss: 0.00001304
Iteration 102/1000 | Loss: 0.00001304
Iteration 103/1000 | Loss: 0.00001304
Iteration 104/1000 | Loss: 0.00001304
Iteration 105/1000 | Loss: 0.00001304
Iteration 106/1000 | Loss: 0.00001304
Iteration 107/1000 | Loss: 0.00001304
Iteration 108/1000 | Loss: 0.00001303
Iteration 109/1000 | Loss: 0.00001303
Iteration 110/1000 | Loss: 0.00001303
Iteration 111/1000 | Loss: 0.00001303
Iteration 112/1000 | Loss: 0.00001303
Iteration 113/1000 | Loss: 0.00001303
Iteration 114/1000 | Loss: 0.00001303
Iteration 115/1000 | Loss: 0.00001303
Iteration 116/1000 | Loss: 0.00001303
Iteration 117/1000 | Loss: 0.00001303
Iteration 118/1000 | Loss: 0.00001303
Iteration 119/1000 | Loss: 0.00001303
Iteration 120/1000 | Loss: 0.00001303
Iteration 121/1000 | Loss: 0.00001302
Iteration 122/1000 | Loss: 0.00001302
Iteration 123/1000 | Loss: 0.00001302
Iteration 124/1000 | Loss: 0.00001302
Iteration 125/1000 | Loss: 0.00001302
Iteration 126/1000 | Loss: 0.00001302
Iteration 127/1000 | Loss: 0.00001302
Iteration 128/1000 | Loss: 0.00001302
Iteration 129/1000 | Loss: 0.00001302
Iteration 130/1000 | Loss: 0.00001302
Iteration 131/1000 | Loss: 0.00001302
Iteration 132/1000 | Loss: 0.00001302
Iteration 133/1000 | Loss: 0.00001302
Iteration 134/1000 | Loss: 0.00001302
Iteration 135/1000 | Loss: 0.00001302
Iteration 136/1000 | Loss: 0.00001302
Iteration 137/1000 | Loss: 0.00001302
Iteration 138/1000 | Loss: 0.00001301
Iteration 139/1000 | Loss: 0.00001301
Iteration 140/1000 | Loss: 0.00001301
Iteration 141/1000 | Loss: 0.00001301
Iteration 142/1000 | Loss: 0.00001301
Iteration 143/1000 | Loss: 0.00001301
Iteration 144/1000 | Loss: 0.00001301
Iteration 145/1000 | Loss: 0.00001300
Iteration 146/1000 | Loss: 0.00001300
Iteration 147/1000 | Loss: 0.00001300
Iteration 148/1000 | Loss: 0.00001299
Iteration 149/1000 | Loss: 0.00001299
Iteration 150/1000 | Loss: 0.00001299
Iteration 151/1000 | Loss: 0.00001298
Iteration 152/1000 | Loss: 0.00001298
Iteration 153/1000 | Loss: 0.00001298
Iteration 154/1000 | Loss: 0.00001298
Iteration 155/1000 | Loss: 0.00001297
Iteration 156/1000 | Loss: 0.00001297
Iteration 157/1000 | Loss: 0.00001297
Iteration 158/1000 | Loss: 0.00001297
Iteration 159/1000 | Loss: 0.00001296
Iteration 160/1000 | Loss: 0.00001296
Iteration 161/1000 | Loss: 0.00001296
Iteration 162/1000 | Loss: 0.00001296
Iteration 163/1000 | Loss: 0.00001296
Iteration 164/1000 | Loss: 0.00001296
Iteration 165/1000 | Loss: 0.00001296
Iteration 166/1000 | Loss: 0.00001296
Iteration 167/1000 | Loss: 0.00001296
Iteration 168/1000 | Loss: 0.00001296
Iteration 169/1000 | Loss: 0.00001296
Iteration 170/1000 | Loss: 0.00001296
Iteration 171/1000 | Loss: 0.00001296
Iteration 172/1000 | Loss: 0.00001296
Iteration 173/1000 | Loss: 0.00001296
Iteration 174/1000 | Loss: 0.00001296
Iteration 175/1000 | Loss: 0.00001296
Iteration 176/1000 | Loss: 0.00001296
Iteration 177/1000 | Loss: 0.00001296
Iteration 178/1000 | Loss: 0.00001296
Iteration 179/1000 | Loss: 0.00001296
Iteration 180/1000 | Loss: 0.00001296
Iteration 181/1000 | Loss: 0.00001296
Iteration 182/1000 | Loss: 0.00001296
Iteration 183/1000 | Loss: 0.00001296
Iteration 184/1000 | Loss: 0.00001296
Iteration 185/1000 | Loss: 0.00001296
Iteration 186/1000 | Loss: 0.00001296
Iteration 187/1000 | Loss: 0.00001296
Iteration 188/1000 | Loss: 0.00001296
Iteration 189/1000 | Loss: 0.00001296
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 189. Stopping optimization.
Last 5 losses: [1.2960710591869429e-05, 1.2960710591869429e-05, 1.2960710591869429e-05, 1.2960710591869429e-05, 1.2960710591869429e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2960710591869429e-05

Optimization complete. Final v2v error: 3.1428444385528564 mm

Highest mean error: 3.193235397338867 mm for frame 67

Lowest mean error: 3.0906543731689453 mm for frame 53

Saving results

Total time: 41.75852131843567
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1092/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1092.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1092
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00764306
Iteration 2/25 | Loss: 0.00161061
Iteration 3/25 | Loss: 0.00139478
Iteration 4/25 | Loss: 0.00137860
Iteration 5/25 | Loss: 0.00139751
Iteration 6/25 | Loss: 0.00139017
Iteration 7/25 | Loss: 0.00136540
Iteration 8/25 | Loss: 0.00136268
Iteration 9/25 | Loss: 0.00136217
Iteration 10/25 | Loss: 0.00136211
Iteration 11/25 | Loss: 0.00136210
Iteration 12/25 | Loss: 0.00136210
Iteration 13/25 | Loss: 0.00136210
Iteration 14/25 | Loss: 0.00136210
Iteration 15/25 | Loss: 0.00136210
Iteration 16/25 | Loss: 0.00136210
Iteration 17/25 | Loss: 0.00136210
Iteration 18/25 | Loss: 0.00136210
Iteration 19/25 | Loss: 0.00136209
Iteration 20/25 | Loss: 0.00136209
Iteration 21/25 | Loss: 0.00136209
Iteration 22/25 | Loss: 0.00136209
Iteration 23/25 | Loss: 0.00136209
Iteration 24/25 | Loss: 0.00136209
Iteration 25/25 | Loss: 0.00136209

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25417805
Iteration 2/25 | Loss: 0.00148156
Iteration 3/25 | Loss: 0.00148156
Iteration 4/25 | Loss: 0.00148156
Iteration 5/25 | Loss: 0.00148155
Iteration 6/25 | Loss: 0.00148155
Iteration 7/25 | Loss: 0.00148155
Iteration 8/25 | Loss: 0.00148155
Iteration 9/25 | Loss: 0.00148155
Iteration 10/25 | Loss: 0.00148155
Iteration 11/25 | Loss: 0.00148155
Iteration 12/25 | Loss: 0.00148155
Iteration 13/25 | Loss: 0.00148155
Iteration 14/25 | Loss: 0.00148155
Iteration 15/25 | Loss: 0.00148155
Iteration 16/25 | Loss: 0.00148155
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001481553423218429, 0.001481553423218429, 0.001481553423218429, 0.001481553423218429, 0.001481553423218429]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001481553423218429

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00148155
Iteration 2/1000 | Loss: 0.00003113
Iteration 3/1000 | Loss: 0.00002438
Iteration 4/1000 | Loss: 0.00002129
Iteration 5/1000 | Loss: 0.00001993
Iteration 6/1000 | Loss: 0.00001907
Iteration 7/1000 | Loss: 0.00001846
Iteration 8/1000 | Loss: 0.00001797
Iteration 9/1000 | Loss: 0.00001762
Iteration 10/1000 | Loss: 0.00001736
Iteration 11/1000 | Loss: 0.00001707
Iteration 12/1000 | Loss: 0.00001682
Iteration 13/1000 | Loss: 0.00001661
Iteration 14/1000 | Loss: 0.00001638
Iteration 15/1000 | Loss: 0.00001622
Iteration 16/1000 | Loss: 0.00001619
Iteration 17/1000 | Loss: 0.00001612
Iteration 18/1000 | Loss: 0.00001611
Iteration 19/1000 | Loss: 0.00001609
Iteration 20/1000 | Loss: 0.00001609
Iteration 21/1000 | Loss: 0.00001609
Iteration 22/1000 | Loss: 0.00001609
Iteration 23/1000 | Loss: 0.00001608
Iteration 24/1000 | Loss: 0.00001607
Iteration 25/1000 | Loss: 0.00001602
Iteration 26/1000 | Loss: 0.00001601
Iteration 27/1000 | Loss: 0.00001599
Iteration 28/1000 | Loss: 0.00001594
Iteration 29/1000 | Loss: 0.00001594
Iteration 30/1000 | Loss: 0.00001592
Iteration 31/1000 | Loss: 0.00001592
Iteration 32/1000 | Loss: 0.00001591
Iteration 33/1000 | Loss: 0.00001591
Iteration 34/1000 | Loss: 0.00001590
Iteration 35/1000 | Loss: 0.00001589
Iteration 36/1000 | Loss: 0.00001588
Iteration 37/1000 | Loss: 0.00001588
Iteration 38/1000 | Loss: 0.00001588
Iteration 39/1000 | Loss: 0.00001587
Iteration 40/1000 | Loss: 0.00001587
Iteration 41/1000 | Loss: 0.00001587
Iteration 42/1000 | Loss: 0.00001587
Iteration 43/1000 | Loss: 0.00001586
Iteration 44/1000 | Loss: 0.00001586
Iteration 45/1000 | Loss: 0.00001585
Iteration 46/1000 | Loss: 0.00001585
Iteration 47/1000 | Loss: 0.00001585
Iteration 48/1000 | Loss: 0.00001585
Iteration 49/1000 | Loss: 0.00001585
Iteration 50/1000 | Loss: 0.00001585
Iteration 51/1000 | Loss: 0.00001584
Iteration 52/1000 | Loss: 0.00001584
Iteration 53/1000 | Loss: 0.00001584
Iteration 54/1000 | Loss: 0.00001584
Iteration 55/1000 | Loss: 0.00001583
Iteration 56/1000 | Loss: 0.00001583
Iteration 57/1000 | Loss: 0.00001582
Iteration 58/1000 | Loss: 0.00001581
Iteration 59/1000 | Loss: 0.00001580
Iteration 60/1000 | Loss: 0.00001580
Iteration 61/1000 | Loss: 0.00001580
Iteration 62/1000 | Loss: 0.00001580
Iteration 63/1000 | Loss: 0.00001580
Iteration 64/1000 | Loss: 0.00001580
Iteration 65/1000 | Loss: 0.00001579
Iteration 66/1000 | Loss: 0.00001579
Iteration 67/1000 | Loss: 0.00001579
Iteration 68/1000 | Loss: 0.00001578
Iteration 69/1000 | Loss: 0.00001577
Iteration 70/1000 | Loss: 0.00001577
Iteration 71/1000 | Loss: 0.00001577
Iteration 72/1000 | Loss: 0.00001576
Iteration 73/1000 | Loss: 0.00001576
Iteration 74/1000 | Loss: 0.00001576
Iteration 75/1000 | Loss: 0.00001576
Iteration 76/1000 | Loss: 0.00001576
Iteration 77/1000 | Loss: 0.00001576
Iteration 78/1000 | Loss: 0.00001575
Iteration 79/1000 | Loss: 0.00001575
Iteration 80/1000 | Loss: 0.00001575
Iteration 81/1000 | Loss: 0.00001575
Iteration 82/1000 | Loss: 0.00001574
Iteration 83/1000 | Loss: 0.00001574
Iteration 84/1000 | Loss: 0.00001574
Iteration 85/1000 | Loss: 0.00001574
Iteration 86/1000 | Loss: 0.00001574
Iteration 87/1000 | Loss: 0.00001574
Iteration 88/1000 | Loss: 0.00001574
Iteration 89/1000 | Loss: 0.00001574
Iteration 90/1000 | Loss: 0.00001574
Iteration 91/1000 | Loss: 0.00001574
Iteration 92/1000 | Loss: 0.00001574
Iteration 93/1000 | Loss: 0.00001574
Iteration 94/1000 | Loss: 0.00001573
Iteration 95/1000 | Loss: 0.00001573
Iteration 96/1000 | Loss: 0.00001573
Iteration 97/1000 | Loss: 0.00001573
Iteration 98/1000 | Loss: 0.00001573
Iteration 99/1000 | Loss: 0.00001573
Iteration 100/1000 | Loss: 0.00001573
Iteration 101/1000 | Loss: 0.00001573
Iteration 102/1000 | Loss: 0.00001573
Iteration 103/1000 | Loss: 0.00001573
Iteration 104/1000 | Loss: 0.00001573
Iteration 105/1000 | Loss: 0.00001573
Iteration 106/1000 | Loss: 0.00001573
Iteration 107/1000 | Loss: 0.00001572
Iteration 108/1000 | Loss: 0.00001572
Iteration 109/1000 | Loss: 0.00001572
Iteration 110/1000 | Loss: 0.00001572
Iteration 111/1000 | Loss: 0.00001572
Iteration 112/1000 | Loss: 0.00001572
Iteration 113/1000 | Loss: 0.00001572
Iteration 114/1000 | Loss: 0.00001572
Iteration 115/1000 | Loss: 0.00001572
Iteration 116/1000 | Loss: 0.00001572
Iteration 117/1000 | Loss: 0.00001572
Iteration 118/1000 | Loss: 0.00001572
Iteration 119/1000 | Loss: 0.00001572
Iteration 120/1000 | Loss: 0.00001572
Iteration 121/1000 | Loss: 0.00001572
Iteration 122/1000 | Loss: 0.00001572
Iteration 123/1000 | Loss: 0.00001572
Iteration 124/1000 | Loss: 0.00001572
Iteration 125/1000 | Loss: 0.00001571
Iteration 126/1000 | Loss: 0.00001571
Iteration 127/1000 | Loss: 0.00001571
Iteration 128/1000 | Loss: 0.00001571
Iteration 129/1000 | Loss: 0.00001571
Iteration 130/1000 | Loss: 0.00001571
Iteration 131/1000 | Loss: 0.00001571
Iteration 132/1000 | Loss: 0.00001571
Iteration 133/1000 | Loss: 0.00001571
Iteration 134/1000 | Loss: 0.00001571
Iteration 135/1000 | Loss: 0.00001571
Iteration 136/1000 | Loss: 0.00001571
Iteration 137/1000 | Loss: 0.00001571
Iteration 138/1000 | Loss: 0.00001571
Iteration 139/1000 | Loss: 0.00001571
Iteration 140/1000 | Loss: 0.00001571
Iteration 141/1000 | Loss: 0.00001571
Iteration 142/1000 | Loss: 0.00001571
Iteration 143/1000 | Loss: 0.00001571
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 143. Stopping optimization.
Last 5 losses: [1.5705540135968477e-05, 1.5705540135968477e-05, 1.5705540135968477e-05, 1.5705540135968477e-05, 1.5705540135968477e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5705540135968477e-05

Optimization complete. Final v2v error: 3.3650643825531006 mm

Highest mean error: 3.7470362186431885 mm for frame 80

Lowest mean error: 3.1246259212493896 mm for frame 104

Saving results

Total time: 49.342987298965454
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1091/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1091.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1091
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00552678
Iteration 2/25 | Loss: 0.00175516
Iteration 3/25 | Loss: 0.00150648
Iteration 4/25 | Loss: 0.00148932
Iteration 5/25 | Loss: 0.00148657
Iteration 6/25 | Loss: 0.00148592
Iteration 7/25 | Loss: 0.00148592
Iteration 8/25 | Loss: 0.00148592
Iteration 9/25 | Loss: 0.00148592
Iteration 10/25 | Loss: 0.00148592
Iteration 11/25 | Loss: 0.00148592
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0014859194634482265, 0.0014859194634482265, 0.0014859194634482265, 0.0014859194634482265, 0.0014859194634482265]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014859194634482265

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.97079605
Iteration 2/25 | Loss: 0.00162029
Iteration 3/25 | Loss: 0.00162027
Iteration 4/25 | Loss: 0.00162027
Iteration 5/25 | Loss: 0.00162027
Iteration 6/25 | Loss: 0.00162027
Iteration 7/25 | Loss: 0.00162027
Iteration 8/25 | Loss: 0.00162027
Iteration 9/25 | Loss: 0.00162027
Iteration 10/25 | Loss: 0.00162027
Iteration 11/25 | Loss: 0.00162027
Iteration 12/25 | Loss: 0.00162027
Iteration 13/25 | Loss: 0.00162027
Iteration 14/25 | Loss: 0.00162027
Iteration 15/25 | Loss: 0.00162027
Iteration 16/25 | Loss: 0.00162027
Iteration 17/25 | Loss: 0.00162027
Iteration 18/25 | Loss: 0.00162027
Iteration 19/25 | Loss: 0.00162027
Iteration 20/25 | Loss: 0.00162027
Iteration 21/25 | Loss: 0.00162027
Iteration 22/25 | Loss: 0.00162027
Iteration 23/25 | Loss: 0.00162027
Iteration 24/25 | Loss: 0.00162027
Iteration 25/25 | Loss: 0.00162027

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00162027
Iteration 2/1000 | Loss: 0.00004592
Iteration 3/1000 | Loss: 0.00003288
Iteration 4/1000 | Loss: 0.00002735
Iteration 5/1000 | Loss: 0.00002597
Iteration 6/1000 | Loss: 0.00002517
Iteration 7/1000 | Loss: 0.00002452
Iteration 8/1000 | Loss: 0.00002394
Iteration 9/1000 | Loss: 0.00002355
Iteration 10/1000 | Loss: 0.00002311
Iteration 11/1000 | Loss: 0.00002278
Iteration 12/1000 | Loss: 0.00002245
Iteration 13/1000 | Loss: 0.00002221
Iteration 14/1000 | Loss: 0.00002199
Iteration 15/1000 | Loss: 0.00002177
Iteration 16/1000 | Loss: 0.00002167
Iteration 17/1000 | Loss: 0.00002164
Iteration 18/1000 | Loss: 0.00002155
Iteration 19/1000 | Loss: 0.00002142
Iteration 20/1000 | Loss: 0.00002140
Iteration 21/1000 | Loss: 0.00002137
Iteration 22/1000 | Loss: 0.00002136
Iteration 23/1000 | Loss: 0.00002131
Iteration 24/1000 | Loss: 0.00002127
Iteration 25/1000 | Loss: 0.00002122
Iteration 26/1000 | Loss: 0.00002120
Iteration 27/1000 | Loss: 0.00002120
Iteration 28/1000 | Loss: 0.00002120
Iteration 29/1000 | Loss: 0.00002120
Iteration 30/1000 | Loss: 0.00002120
Iteration 31/1000 | Loss: 0.00002120
Iteration 32/1000 | Loss: 0.00002119
Iteration 33/1000 | Loss: 0.00002119
Iteration 34/1000 | Loss: 0.00002119
Iteration 35/1000 | Loss: 0.00002119
Iteration 36/1000 | Loss: 0.00002119
Iteration 37/1000 | Loss: 0.00002119
Iteration 38/1000 | Loss: 0.00002119
Iteration 39/1000 | Loss: 0.00002118
Iteration 40/1000 | Loss: 0.00002118
Iteration 41/1000 | Loss: 0.00002118
Iteration 42/1000 | Loss: 0.00002117
Iteration 43/1000 | Loss: 0.00002116
Iteration 44/1000 | Loss: 0.00002116
Iteration 45/1000 | Loss: 0.00002116
Iteration 46/1000 | Loss: 0.00002116
Iteration 47/1000 | Loss: 0.00002115
Iteration 48/1000 | Loss: 0.00002115
Iteration 49/1000 | Loss: 0.00002114
Iteration 50/1000 | Loss: 0.00002114
Iteration 51/1000 | Loss: 0.00002113
Iteration 52/1000 | Loss: 0.00002113
Iteration 53/1000 | Loss: 0.00002113
Iteration 54/1000 | Loss: 0.00002113
Iteration 55/1000 | Loss: 0.00002112
Iteration 56/1000 | Loss: 0.00002112
Iteration 57/1000 | Loss: 0.00002112
Iteration 58/1000 | Loss: 0.00002111
Iteration 59/1000 | Loss: 0.00002111
Iteration 60/1000 | Loss: 0.00002111
Iteration 61/1000 | Loss: 0.00002110
Iteration 62/1000 | Loss: 0.00002110
Iteration 63/1000 | Loss: 0.00002110
Iteration 64/1000 | Loss: 0.00002110
Iteration 65/1000 | Loss: 0.00002110
Iteration 66/1000 | Loss: 0.00002109
Iteration 67/1000 | Loss: 0.00002109
Iteration 68/1000 | Loss: 0.00002109
Iteration 69/1000 | Loss: 0.00002109
Iteration 70/1000 | Loss: 0.00002109
Iteration 71/1000 | Loss: 0.00002108
Iteration 72/1000 | Loss: 0.00002108
Iteration 73/1000 | Loss: 0.00002108
Iteration 74/1000 | Loss: 0.00002108
Iteration 75/1000 | Loss: 0.00002108
Iteration 76/1000 | Loss: 0.00002108
Iteration 77/1000 | Loss: 0.00002108
Iteration 78/1000 | Loss: 0.00002108
Iteration 79/1000 | Loss: 0.00002108
Iteration 80/1000 | Loss: 0.00002108
Iteration 81/1000 | Loss: 0.00002108
Iteration 82/1000 | Loss: 0.00002108
Iteration 83/1000 | Loss: 0.00002107
Iteration 84/1000 | Loss: 0.00002107
Iteration 85/1000 | Loss: 0.00002107
Iteration 86/1000 | Loss: 0.00002107
Iteration 87/1000 | Loss: 0.00002107
Iteration 88/1000 | Loss: 0.00002107
Iteration 89/1000 | Loss: 0.00002107
Iteration 90/1000 | Loss: 0.00002107
Iteration 91/1000 | Loss: 0.00002107
Iteration 92/1000 | Loss: 0.00002107
Iteration 93/1000 | Loss: 0.00002107
Iteration 94/1000 | Loss: 0.00002107
Iteration 95/1000 | Loss: 0.00002107
Iteration 96/1000 | Loss: 0.00002107
Iteration 97/1000 | Loss: 0.00002107
Iteration 98/1000 | Loss: 0.00002107
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 98. Stopping optimization.
Last 5 losses: [2.1066476620035246e-05, 2.1066476620035246e-05, 2.1066476620035246e-05, 2.1066476620035246e-05, 2.1066476620035246e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1066476620035246e-05

Optimization complete. Final v2v error: 3.7262985706329346 mm

Highest mean error: 4.709932804107666 mm for frame 59

Lowest mean error: 2.9623146057128906 mm for frame 137

Saving results

Total time: 43.04805254936218
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1040/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1040.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1040
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00387852
Iteration 2/25 | Loss: 0.00170884
Iteration 3/25 | Loss: 0.00141251
Iteration 4/25 | Loss: 0.00137549
Iteration 5/25 | Loss: 0.00136666
Iteration 6/25 | Loss: 0.00136460
Iteration 7/25 | Loss: 0.00136403
Iteration 8/25 | Loss: 0.00136403
Iteration 9/25 | Loss: 0.00136403
Iteration 10/25 | Loss: 0.00136403
Iteration 11/25 | Loss: 0.00136403
Iteration 12/25 | Loss: 0.00136403
Iteration 13/25 | Loss: 0.00136403
Iteration 14/25 | Loss: 0.00136403
Iteration 15/25 | Loss: 0.00136403
Iteration 16/25 | Loss: 0.00136403
Iteration 17/25 | Loss: 0.00136403
Iteration 18/25 | Loss: 0.00136403
Iteration 19/25 | Loss: 0.00136403
Iteration 20/25 | Loss: 0.00136403
Iteration 21/25 | Loss: 0.00136403
Iteration 22/25 | Loss: 0.00136403
Iteration 23/25 | Loss: 0.00136403
Iteration 24/25 | Loss: 0.00136403
Iteration 25/25 | Loss: 0.00136403

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.21721947
Iteration 2/25 | Loss: 0.00174493
Iteration 3/25 | Loss: 0.00174493
Iteration 4/25 | Loss: 0.00174493
Iteration 5/25 | Loss: 0.00174493
Iteration 6/25 | Loss: 0.00174493
Iteration 7/25 | Loss: 0.00174493
Iteration 8/25 | Loss: 0.00174493
Iteration 9/25 | Loss: 0.00174493
Iteration 10/25 | Loss: 0.00174493
Iteration 11/25 | Loss: 0.00174493
Iteration 12/25 | Loss: 0.00174493
Iteration 13/25 | Loss: 0.00174493
Iteration 14/25 | Loss: 0.00174493
Iteration 15/25 | Loss: 0.00174493
Iteration 16/25 | Loss: 0.00174493
Iteration 17/25 | Loss: 0.00174493
Iteration 18/25 | Loss: 0.00174493
Iteration 19/25 | Loss: 0.00174493
Iteration 20/25 | Loss: 0.00174493
Iteration 21/25 | Loss: 0.00174493
Iteration 22/25 | Loss: 0.00174493
Iteration 23/25 | Loss: 0.00174493
Iteration 24/25 | Loss: 0.00174493
Iteration 25/25 | Loss: 0.00174493
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0017449273727834225, 0.0017449273727834225, 0.0017449273727834225, 0.0017449273727834225, 0.0017449273727834225]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017449273727834225

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00174493
Iteration 2/1000 | Loss: 0.00004476
Iteration 3/1000 | Loss: 0.00002619
Iteration 4/1000 | Loss: 0.00002186
Iteration 5/1000 | Loss: 0.00001904
Iteration 6/1000 | Loss: 0.00001792
Iteration 7/1000 | Loss: 0.00001717
Iteration 8/1000 | Loss: 0.00001673
Iteration 9/1000 | Loss: 0.00001633
Iteration 10/1000 | Loss: 0.00001590
Iteration 11/1000 | Loss: 0.00001563
Iteration 12/1000 | Loss: 0.00001545
Iteration 13/1000 | Loss: 0.00001533
Iteration 14/1000 | Loss: 0.00001528
Iteration 15/1000 | Loss: 0.00001516
Iteration 16/1000 | Loss: 0.00001515
Iteration 17/1000 | Loss: 0.00001513
Iteration 18/1000 | Loss: 0.00001511
Iteration 19/1000 | Loss: 0.00001510
Iteration 20/1000 | Loss: 0.00001510
Iteration 21/1000 | Loss: 0.00001509
Iteration 22/1000 | Loss: 0.00001508
Iteration 23/1000 | Loss: 0.00001508
Iteration 24/1000 | Loss: 0.00001506
Iteration 25/1000 | Loss: 0.00001506
Iteration 26/1000 | Loss: 0.00001506
Iteration 27/1000 | Loss: 0.00001506
Iteration 28/1000 | Loss: 0.00001506
Iteration 29/1000 | Loss: 0.00001506
Iteration 30/1000 | Loss: 0.00001506
Iteration 31/1000 | Loss: 0.00001506
Iteration 32/1000 | Loss: 0.00001506
Iteration 33/1000 | Loss: 0.00001505
Iteration 34/1000 | Loss: 0.00001505
Iteration 35/1000 | Loss: 0.00001505
Iteration 36/1000 | Loss: 0.00001505
Iteration 37/1000 | Loss: 0.00001505
Iteration 38/1000 | Loss: 0.00001505
Iteration 39/1000 | Loss: 0.00001505
Iteration 40/1000 | Loss: 0.00001505
Iteration 41/1000 | Loss: 0.00001505
Iteration 42/1000 | Loss: 0.00001505
Iteration 43/1000 | Loss: 0.00001505
Iteration 44/1000 | Loss: 0.00001505
Iteration 45/1000 | Loss: 0.00001505
Iteration 46/1000 | Loss: 0.00001505
Iteration 47/1000 | Loss: 0.00001505
Iteration 48/1000 | Loss: 0.00001505
Iteration 49/1000 | Loss: 0.00001505
Iteration 50/1000 | Loss: 0.00001505
Iteration 51/1000 | Loss: 0.00001505
Iteration 52/1000 | Loss: 0.00001505
Iteration 53/1000 | Loss: 0.00001505
Iteration 54/1000 | Loss: 0.00001505
Iteration 55/1000 | Loss: 0.00001505
Iteration 56/1000 | Loss: 0.00001505
Iteration 57/1000 | Loss: 0.00001505
Iteration 58/1000 | Loss: 0.00001505
Iteration 59/1000 | Loss: 0.00001505
Iteration 60/1000 | Loss: 0.00001505
Iteration 61/1000 | Loss: 0.00001505
Iteration 62/1000 | Loss: 0.00001505
Iteration 63/1000 | Loss: 0.00001505
Iteration 64/1000 | Loss: 0.00001505
Iteration 65/1000 | Loss: 0.00001505
Iteration 66/1000 | Loss: 0.00001505
Iteration 67/1000 | Loss: 0.00001505
Iteration 68/1000 | Loss: 0.00001505
Iteration 69/1000 | Loss: 0.00001505
Iteration 70/1000 | Loss: 0.00001505
Iteration 71/1000 | Loss: 0.00001505
Iteration 72/1000 | Loss: 0.00001505
Iteration 73/1000 | Loss: 0.00001505
Iteration 74/1000 | Loss: 0.00001505
Iteration 75/1000 | Loss: 0.00001505
Iteration 76/1000 | Loss: 0.00001505
Iteration 77/1000 | Loss: 0.00001505
Iteration 78/1000 | Loss: 0.00001505
Iteration 79/1000 | Loss: 0.00001505
Iteration 80/1000 | Loss: 0.00001505
Iteration 81/1000 | Loss: 0.00001505
Iteration 82/1000 | Loss: 0.00001505
Iteration 83/1000 | Loss: 0.00001505
Iteration 84/1000 | Loss: 0.00001505
Iteration 85/1000 | Loss: 0.00001505
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [1.5048107343318406e-05, 1.5048107343318406e-05, 1.5048107343318406e-05, 1.5048107343318406e-05, 1.5048107343318406e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5048107343318406e-05

Optimization complete. Final v2v error: 3.3241629600524902 mm

Highest mean error: 3.527867317199707 mm for frame 103

Lowest mean error: 3.182431936264038 mm for frame 25

Saving results

Total time: 32.058011293411255
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1060/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1060.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1060
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00682643
Iteration 2/25 | Loss: 0.00166981
Iteration 3/25 | Loss: 0.00144720
Iteration 4/25 | Loss: 0.00142261
Iteration 5/25 | Loss: 0.00144729
Iteration 6/25 | Loss: 0.00142336
Iteration 7/25 | Loss: 0.00140530
Iteration 8/25 | Loss: 0.00139814
Iteration 9/25 | Loss: 0.00139848
Iteration 10/25 | Loss: 0.00140185
Iteration 11/25 | Loss: 0.00139787
Iteration 12/25 | Loss: 0.00139599
Iteration 13/25 | Loss: 0.00139577
Iteration 14/25 | Loss: 0.00139570
Iteration 15/25 | Loss: 0.00139569
Iteration 16/25 | Loss: 0.00139569
Iteration 17/25 | Loss: 0.00139569
Iteration 18/25 | Loss: 0.00139569
Iteration 19/25 | Loss: 0.00139569
Iteration 20/25 | Loss: 0.00139569
Iteration 21/25 | Loss: 0.00139569
Iteration 22/25 | Loss: 0.00139569
Iteration 23/25 | Loss: 0.00139569
Iteration 24/25 | Loss: 0.00139569
Iteration 25/25 | Loss: 0.00139569

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.19343281
Iteration 2/25 | Loss: 0.00256840
Iteration 3/25 | Loss: 0.00256838
Iteration 4/25 | Loss: 0.00256838
Iteration 5/25 | Loss: 0.00256838
Iteration 6/25 | Loss: 0.00256838
Iteration 7/25 | Loss: 0.00256838
Iteration 8/25 | Loss: 0.00256838
Iteration 9/25 | Loss: 0.00256838
Iteration 10/25 | Loss: 0.00256838
Iteration 11/25 | Loss: 0.00256838
Iteration 12/25 | Loss: 0.00256838
Iteration 13/25 | Loss: 0.00256838
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.002568379510194063, 0.002568379510194063, 0.002568379510194063, 0.002568379510194063, 0.002568379510194063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002568379510194063

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00256838
Iteration 2/1000 | Loss: 0.00010928
Iteration 3/1000 | Loss: 0.00008330
Iteration 4/1000 | Loss: 0.00005377
Iteration 5/1000 | Loss: 0.00004293
Iteration 6/1000 | Loss: 0.00004884
Iteration 7/1000 | Loss: 0.00003222
Iteration 8/1000 | Loss: 0.00002774
Iteration 9/1000 | Loss: 0.00002593
Iteration 10/1000 | Loss: 0.00003022
Iteration 11/1000 | Loss: 0.00002104
Iteration 12/1000 | Loss: 0.00002594
Iteration 13/1000 | Loss: 0.00002814
Iteration 14/1000 | Loss: 0.00002486
Iteration 15/1000 | Loss: 0.00002743
Iteration 16/1000 | Loss: 0.00001819
Iteration 17/1000 | Loss: 0.00002999
Iteration 18/1000 | Loss: 0.00002927
Iteration 19/1000 | Loss: 0.00002886
Iteration 20/1000 | Loss: 0.00002926
Iteration 21/1000 | Loss: 0.00002507
Iteration 22/1000 | Loss: 0.00016297
Iteration 23/1000 | Loss: 0.00002954
Iteration 24/1000 | Loss: 0.00002895
Iteration 25/1000 | Loss: 0.00002885
Iteration 26/1000 | Loss: 0.00002782
Iteration 27/1000 | Loss: 0.00002906
Iteration 28/1000 | Loss: 0.00003019
Iteration 29/1000 | Loss: 0.00001941
Iteration 30/1000 | Loss: 0.00002637
Iteration 31/1000 | Loss: 0.00016577
Iteration 32/1000 | Loss: 0.00003165
Iteration 33/1000 | Loss: 0.00003057
Iteration 34/1000 | Loss: 0.00003236
Iteration 35/1000 | Loss: 0.00002865
Iteration 36/1000 | Loss: 0.00003014
Iteration 37/1000 | Loss: 0.00002500
Iteration 38/1000 | Loss: 0.00002971
Iteration 39/1000 | Loss: 0.00002254
Iteration 40/1000 | Loss: 0.00002656
Iteration 41/1000 | Loss: 0.00002928
Iteration 42/1000 | Loss: 0.00003122
Iteration 43/1000 | Loss: 0.00002779
Iteration 44/1000 | Loss: 0.00002126
Iteration 45/1000 | Loss: 0.00002668
Iteration 46/1000 | Loss: 0.00002137
Iteration 47/1000 | Loss: 0.00001839
Iteration 48/1000 | Loss: 0.00001728
Iteration 49/1000 | Loss: 0.00001669
Iteration 50/1000 | Loss: 0.00001630
Iteration 51/1000 | Loss: 0.00001604
Iteration 52/1000 | Loss: 0.00001573
Iteration 53/1000 | Loss: 0.00014329
Iteration 54/1000 | Loss: 0.00001854
Iteration 55/1000 | Loss: 0.00001780
Iteration 56/1000 | Loss: 0.00001694
Iteration 57/1000 | Loss: 0.00001628
Iteration 58/1000 | Loss: 0.00001588
Iteration 59/1000 | Loss: 0.00001556
Iteration 60/1000 | Loss: 0.00001539
Iteration 61/1000 | Loss: 0.00001522
Iteration 62/1000 | Loss: 0.00002344
Iteration 63/1000 | Loss: 0.00002360
Iteration 64/1000 | Loss: 0.00002281
Iteration 65/1000 | Loss: 0.00001966
Iteration 66/1000 | Loss: 0.00002229
Iteration 67/1000 | Loss: 0.00002229
Iteration 68/1000 | Loss: 0.00002320
Iteration 69/1000 | Loss: 0.00001739
Iteration 70/1000 | Loss: 0.00001614
Iteration 71/1000 | Loss: 0.00002289
Iteration 72/1000 | Loss: 0.00001556
Iteration 73/1000 | Loss: 0.00001518
Iteration 74/1000 | Loss: 0.00001493
Iteration 75/1000 | Loss: 0.00001485
Iteration 76/1000 | Loss: 0.00001484
Iteration 77/1000 | Loss: 0.00001483
Iteration 78/1000 | Loss: 0.00001480
Iteration 79/1000 | Loss: 0.00001480
Iteration 80/1000 | Loss: 0.00001480
Iteration 81/1000 | Loss: 0.00001480
Iteration 82/1000 | Loss: 0.00001480
Iteration 83/1000 | Loss: 0.00001480
Iteration 84/1000 | Loss: 0.00001480
Iteration 85/1000 | Loss: 0.00001480
Iteration 86/1000 | Loss: 0.00001480
Iteration 87/1000 | Loss: 0.00001480
Iteration 88/1000 | Loss: 0.00001480
Iteration 89/1000 | Loss: 0.00001479
Iteration 90/1000 | Loss: 0.00001479
Iteration 91/1000 | Loss: 0.00001478
Iteration 92/1000 | Loss: 0.00001476
Iteration 93/1000 | Loss: 0.00001474
Iteration 94/1000 | Loss: 0.00001473
Iteration 95/1000 | Loss: 0.00001473
Iteration 96/1000 | Loss: 0.00001473
Iteration 97/1000 | Loss: 0.00001473
Iteration 98/1000 | Loss: 0.00001472
Iteration 99/1000 | Loss: 0.00001472
Iteration 100/1000 | Loss: 0.00001471
Iteration 101/1000 | Loss: 0.00001471
Iteration 102/1000 | Loss: 0.00001470
Iteration 103/1000 | Loss: 0.00001470
Iteration 104/1000 | Loss: 0.00001469
Iteration 105/1000 | Loss: 0.00001467
Iteration 106/1000 | Loss: 0.00001467
Iteration 107/1000 | Loss: 0.00001466
Iteration 108/1000 | Loss: 0.00001466
Iteration 109/1000 | Loss: 0.00001465
Iteration 110/1000 | Loss: 0.00001465
Iteration 111/1000 | Loss: 0.00001461
Iteration 112/1000 | Loss: 0.00001458
Iteration 113/1000 | Loss: 0.00001457
Iteration 114/1000 | Loss: 0.00001454
Iteration 115/1000 | Loss: 0.00001454
Iteration 116/1000 | Loss: 0.00001452
Iteration 117/1000 | Loss: 0.00001449
Iteration 118/1000 | Loss: 0.00001449
Iteration 119/1000 | Loss: 0.00001448
Iteration 120/1000 | Loss: 0.00001448
Iteration 121/1000 | Loss: 0.00001448
Iteration 122/1000 | Loss: 0.00001448
Iteration 123/1000 | Loss: 0.00001448
Iteration 124/1000 | Loss: 0.00001448
Iteration 125/1000 | Loss: 0.00001448
Iteration 126/1000 | Loss: 0.00001447
Iteration 127/1000 | Loss: 0.00001447
Iteration 128/1000 | Loss: 0.00001447
Iteration 129/1000 | Loss: 0.00001446
Iteration 130/1000 | Loss: 0.00001445
Iteration 131/1000 | Loss: 0.00001445
Iteration 132/1000 | Loss: 0.00001445
Iteration 133/1000 | Loss: 0.00001444
Iteration 134/1000 | Loss: 0.00001444
Iteration 135/1000 | Loss: 0.00001444
Iteration 136/1000 | Loss: 0.00001444
Iteration 137/1000 | Loss: 0.00001443
Iteration 138/1000 | Loss: 0.00001442
Iteration 139/1000 | Loss: 0.00001442
Iteration 140/1000 | Loss: 0.00001441
Iteration 141/1000 | Loss: 0.00001441
Iteration 142/1000 | Loss: 0.00001440
Iteration 143/1000 | Loss: 0.00001440
Iteration 144/1000 | Loss: 0.00001440
Iteration 145/1000 | Loss: 0.00001440
Iteration 146/1000 | Loss: 0.00001440
Iteration 147/1000 | Loss: 0.00001440
Iteration 148/1000 | Loss: 0.00001440
Iteration 149/1000 | Loss: 0.00001439
Iteration 150/1000 | Loss: 0.00001439
Iteration 151/1000 | Loss: 0.00001439
Iteration 152/1000 | Loss: 0.00001438
Iteration 153/1000 | Loss: 0.00001438
Iteration 154/1000 | Loss: 0.00001438
Iteration 155/1000 | Loss: 0.00001438
Iteration 156/1000 | Loss: 0.00001438
Iteration 157/1000 | Loss: 0.00001438
Iteration 158/1000 | Loss: 0.00001438
Iteration 159/1000 | Loss: 0.00001438
Iteration 160/1000 | Loss: 0.00001438
Iteration 161/1000 | Loss: 0.00001438
Iteration 162/1000 | Loss: 0.00001437
Iteration 163/1000 | Loss: 0.00001437
Iteration 164/1000 | Loss: 0.00001437
Iteration 165/1000 | Loss: 0.00001437
Iteration 166/1000 | Loss: 0.00001437
Iteration 167/1000 | Loss: 0.00001437
Iteration 168/1000 | Loss: 0.00001437
Iteration 169/1000 | Loss: 0.00001437
Iteration 170/1000 | Loss: 0.00001436
Iteration 171/1000 | Loss: 0.00001436
Iteration 172/1000 | Loss: 0.00001435
Iteration 173/1000 | Loss: 0.00001435
Iteration 174/1000 | Loss: 0.00001435
Iteration 175/1000 | Loss: 0.00001435
Iteration 176/1000 | Loss: 0.00001435
Iteration 177/1000 | Loss: 0.00001435
Iteration 178/1000 | Loss: 0.00001435
Iteration 179/1000 | Loss: 0.00001435
Iteration 180/1000 | Loss: 0.00001434
Iteration 181/1000 | Loss: 0.00001434
Iteration 182/1000 | Loss: 0.00001434
Iteration 183/1000 | Loss: 0.00001434
Iteration 184/1000 | Loss: 0.00001434
Iteration 185/1000 | Loss: 0.00001433
Iteration 186/1000 | Loss: 0.00001433
Iteration 187/1000 | Loss: 0.00001433
Iteration 188/1000 | Loss: 0.00001433
Iteration 189/1000 | Loss: 0.00001432
Iteration 190/1000 | Loss: 0.00001432
Iteration 191/1000 | Loss: 0.00001432
Iteration 192/1000 | Loss: 0.00001432
Iteration 193/1000 | Loss: 0.00001432
Iteration 194/1000 | Loss: 0.00001432
Iteration 195/1000 | Loss: 0.00001432
Iteration 196/1000 | Loss: 0.00001432
Iteration 197/1000 | Loss: 0.00001432
Iteration 198/1000 | Loss: 0.00001432
Iteration 199/1000 | Loss: 0.00001432
Iteration 200/1000 | Loss: 0.00001431
Iteration 201/1000 | Loss: 0.00001431
Iteration 202/1000 | Loss: 0.00001431
Iteration 203/1000 | Loss: 0.00001431
Iteration 204/1000 | Loss: 0.00001431
Iteration 205/1000 | Loss: 0.00001431
Iteration 206/1000 | Loss: 0.00001431
Iteration 207/1000 | Loss: 0.00001431
Iteration 208/1000 | Loss: 0.00001431
Iteration 209/1000 | Loss: 0.00001431
Iteration 210/1000 | Loss: 0.00001431
Iteration 211/1000 | Loss: 0.00001431
Iteration 212/1000 | Loss: 0.00001431
Iteration 213/1000 | Loss: 0.00001431
Iteration 214/1000 | Loss: 0.00001430
Iteration 215/1000 | Loss: 0.00001430
Iteration 216/1000 | Loss: 0.00001430
Iteration 217/1000 | Loss: 0.00001430
Iteration 218/1000 | Loss: 0.00001430
Iteration 219/1000 | Loss: 0.00001429
Iteration 220/1000 | Loss: 0.00001429
Iteration 221/1000 | Loss: 0.00001429
Iteration 222/1000 | Loss: 0.00001429
Iteration 223/1000 | Loss: 0.00001429
Iteration 224/1000 | Loss: 0.00001429
Iteration 225/1000 | Loss: 0.00001429
Iteration 226/1000 | Loss: 0.00001429
Iteration 227/1000 | Loss: 0.00001428
Iteration 228/1000 | Loss: 0.00001428
Iteration 229/1000 | Loss: 0.00001428
Iteration 230/1000 | Loss: 0.00001428
Iteration 231/1000 | Loss: 0.00001428
Iteration 232/1000 | Loss: 0.00001428
Iteration 233/1000 | Loss: 0.00001427
Iteration 234/1000 | Loss: 0.00001427
Iteration 235/1000 | Loss: 0.00001427
Iteration 236/1000 | Loss: 0.00001427
Iteration 237/1000 | Loss: 0.00001427
Iteration 238/1000 | Loss: 0.00001427
Iteration 239/1000 | Loss: 0.00001427
Iteration 240/1000 | Loss: 0.00001427
Iteration 241/1000 | Loss: 0.00001427
Iteration 242/1000 | Loss: 0.00001427
Iteration 243/1000 | Loss: 0.00001427
Iteration 244/1000 | Loss: 0.00001426
Iteration 245/1000 | Loss: 0.00001426
Iteration 246/1000 | Loss: 0.00001426
Iteration 247/1000 | Loss: 0.00001426
Iteration 248/1000 | Loss: 0.00001426
Iteration 249/1000 | Loss: 0.00001426
Iteration 250/1000 | Loss: 0.00001426
Iteration 251/1000 | Loss: 0.00001426
Iteration 252/1000 | Loss: 0.00001426
Iteration 253/1000 | Loss: 0.00001426
Iteration 254/1000 | Loss: 0.00001426
Iteration 255/1000 | Loss: 0.00001426
Iteration 256/1000 | Loss: 0.00001426
Iteration 257/1000 | Loss: 0.00001426
Iteration 258/1000 | Loss: 0.00001426
Iteration 259/1000 | Loss: 0.00001426
Iteration 260/1000 | Loss: 0.00001426
Iteration 261/1000 | Loss: 0.00001426
Iteration 262/1000 | Loss: 0.00001426
Iteration 263/1000 | Loss: 0.00001426
Iteration 264/1000 | Loss: 0.00001426
Iteration 265/1000 | Loss: 0.00001426
Iteration 266/1000 | Loss: 0.00001425
Iteration 267/1000 | Loss: 0.00001425
Iteration 268/1000 | Loss: 0.00001425
Iteration 269/1000 | Loss: 0.00001425
Iteration 270/1000 | Loss: 0.00001425
Iteration 271/1000 | Loss: 0.00001425
Iteration 272/1000 | Loss: 0.00001425
Iteration 273/1000 | Loss: 0.00001425
Iteration 274/1000 | Loss: 0.00001425
Iteration 275/1000 | Loss: 0.00001425
Iteration 276/1000 | Loss: 0.00001425
Iteration 277/1000 | Loss: 0.00001425
Iteration 278/1000 | Loss: 0.00001425
Iteration 279/1000 | Loss: 0.00001425
Iteration 280/1000 | Loss: 0.00001425
Iteration 281/1000 | Loss: 0.00001425
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 281. Stopping optimization.
Last 5 losses: [1.425154823664343e-05, 1.425154823664343e-05, 1.425154823664343e-05, 1.425154823664343e-05, 1.425154823664343e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.425154823664343e-05

Optimization complete. Final v2v error: 3.235619068145752 mm

Highest mean error: 4.373330116271973 mm for frame 118

Lowest mean error: 2.9821276664733887 mm for frame 12

Saving results

Total time: 161.24202871322632
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00415343
Iteration 2/25 | Loss: 0.00142094
Iteration 3/25 | Loss: 0.00136287
Iteration 4/25 | Loss: 0.00135146
Iteration 5/25 | Loss: 0.00134834
Iteration 6/25 | Loss: 0.00134805
Iteration 7/25 | Loss: 0.00134805
Iteration 8/25 | Loss: 0.00134805
Iteration 9/25 | Loss: 0.00134805
Iteration 10/25 | Loss: 0.00134805
Iteration 11/25 | Loss: 0.00134805
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.00134804577101022, 0.00134804577101022, 0.00134804577101022, 0.00134804577101022, 0.00134804577101022]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00134804577101022

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27845216
Iteration 2/25 | Loss: 0.00174743
Iteration 3/25 | Loss: 0.00174742
Iteration 4/25 | Loss: 0.00174742
Iteration 5/25 | Loss: 0.00174742
Iteration 6/25 | Loss: 0.00174742
Iteration 7/25 | Loss: 0.00174742
Iteration 8/25 | Loss: 0.00174742
Iteration 9/25 | Loss: 0.00174742
Iteration 10/25 | Loss: 0.00174742
Iteration 11/25 | Loss: 0.00174742
Iteration 12/25 | Loss: 0.00174742
Iteration 13/25 | Loss: 0.00174742
Iteration 14/25 | Loss: 0.00174742
Iteration 15/25 | Loss: 0.00174742
Iteration 16/25 | Loss: 0.00174742
Iteration 17/25 | Loss: 0.00174742
Iteration 18/25 | Loss: 0.00174742
Iteration 19/25 | Loss: 0.00174742
Iteration 20/25 | Loss: 0.00174742
Iteration 21/25 | Loss: 0.00174742
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0017474211053922772, 0.0017474211053922772, 0.0017474211053922772, 0.0017474211053922772, 0.0017474211053922772]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017474211053922772

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00174742
Iteration 2/1000 | Loss: 0.00003022
Iteration 3/1000 | Loss: 0.00002001
Iteration 4/1000 | Loss: 0.00001845
Iteration 5/1000 | Loss: 0.00001785
Iteration 6/1000 | Loss: 0.00001702
Iteration 7/1000 | Loss: 0.00001627
Iteration 8/1000 | Loss: 0.00001597
Iteration 9/1000 | Loss: 0.00001550
Iteration 10/1000 | Loss: 0.00001510
Iteration 11/1000 | Loss: 0.00001499
Iteration 12/1000 | Loss: 0.00001471
Iteration 13/1000 | Loss: 0.00001468
Iteration 14/1000 | Loss: 0.00001445
Iteration 15/1000 | Loss: 0.00001425
Iteration 16/1000 | Loss: 0.00001420
Iteration 17/1000 | Loss: 0.00001418
Iteration 18/1000 | Loss: 0.00001417
Iteration 19/1000 | Loss: 0.00001416
Iteration 20/1000 | Loss: 0.00001414
Iteration 21/1000 | Loss: 0.00001414
Iteration 22/1000 | Loss: 0.00001413
Iteration 23/1000 | Loss: 0.00001412
Iteration 24/1000 | Loss: 0.00001406
Iteration 25/1000 | Loss: 0.00001398
Iteration 26/1000 | Loss: 0.00001398
Iteration 27/1000 | Loss: 0.00001397
Iteration 28/1000 | Loss: 0.00001397
Iteration 29/1000 | Loss: 0.00001397
Iteration 30/1000 | Loss: 0.00001397
Iteration 31/1000 | Loss: 0.00001396
Iteration 32/1000 | Loss: 0.00001396
Iteration 33/1000 | Loss: 0.00001396
Iteration 34/1000 | Loss: 0.00001395
Iteration 35/1000 | Loss: 0.00001395
Iteration 36/1000 | Loss: 0.00001390
Iteration 37/1000 | Loss: 0.00001390
Iteration 38/1000 | Loss: 0.00001389
Iteration 39/1000 | Loss: 0.00001389
Iteration 40/1000 | Loss: 0.00001388
Iteration 41/1000 | Loss: 0.00001387
Iteration 42/1000 | Loss: 0.00001387
Iteration 43/1000 | Loss: 0.00001386
Iteration 44/1000 | Loss: 0.00001386
Iteration 45/1000 | Loss: 0.00001385
Iteration 46/1000 | Loss: 0.00001385
Iteration 47/1000 | Loss: 0.00001385
Iteration 48/1000 | Loss: 0.00001384
Iteration 49/1000 | Loss: 0.00001384
Iteration 50/1000 | Loss: 0.00001384
Iteration 51/1000 | Loss: 0.00001381
Iteration 52/1000 | Loss: 0.00001381
Iteration 53/1000 | Loss: 0.00001381
Iteration 54/1000 | Loss: 0.00001381
Iteration 55/1000 | Loss: 0.00001380
Iteration 56/1000 | Loss: 0.00001380
Iteration 57/1000 | Loss: 0.00001380
Iteration 58/1000 | Loss: 0.00001380
Iteration 59/1000 | Loss: 0.00001377
Iteration 60/1000 | Loss: 0.00001377
Iteration 61/1000 | Loss: 0.00001377
Iteration 62/1000 | Loss: 0.00001377
Iteration 63/1000 | Loss: 0.00001377
Iteration 64/1000 | Loss: 0.00001377
Iteration 65/1000 | Loss: 0.00001376
Iteration 66/1000 | Loss: 0.00001376
Iteration 67/1000 | Loss: 0.00001376
Iteration 68/1000 | Loss: 0.00001376
Iteration 69/1000 | Loss: 0.00001376
Iteration 70/1000 | Loss: 0.00001375
Iteration 71/1000 | Loss: 0.00001375
Iteration 72/1000 | Loss: 0.00001375
Iteration 73/1000 | Loss: 0.00001374
Iteration 74/1000 | Loss: 0.00001374
Iteration 75/1000 | Loss: 0.00001374
Iteration 76/1000 | Loss: 0.00001373
Iteration 77/1000 | Loss: 0.00001373
Iteration 78/1000 | Loss: 0.00001373
Iteration 79/1000 | Loss: 0.00001373
Iteration 80/1000 | Loss: 0.00001373
Iteration 81/1000 | Loss: 0.00001373
Iteration 82/1000 | Loss: 0.00001373
Iteration 83/1000 | Loss: 0.00001373
Iteration 84/1000 | Loss: 0.00001373
Iteration 85/1000 | Loss: 0.00001373
Iteration 86/1000 | Loss: 0.00001373
Iteration 87/1000 | Loss: 0.00001373
Iteration 88/1000 | Loss: 0.00001373
Iteration 89/1000 | Loss: 0.00001373
Iteration 90/1000 | Loss: 0.00001373
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 90. Stopping optimization.
Last 5 losses: [1.3726048564421944e-05, 1.3726048564421944e-05, 1.3726048564421944e-05, 1.3726048564421944e-05, 1.3726048564421944e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3726048564421944e-05

Optimization complete. Final v2v error: 3.244166374206543 mm

Highest mean error: 3.379164934158325 mm for frame 119

Lowest mean error: 3.2004761695861816 mm for frame 110

Saving results

Total time: 36.88774490356445
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1072/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1072.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1072
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00944932
Iteration 2/25 | Loss: 0.00248407
Iteration 3/25 | Loss: 0.00169958
Iteration 4/25 | Loss: 0.00164721
Iteration 5/25 | Loss: 0.00162584
Iteration 6/25 | Loss: 0.00155467
Iteration 7/25 | Loss: 0.00149240
Iteration 8/25 | Loss: 0.00144999
Iteration 9/25 | Loss: 0.00143753
Iteration 10/25 | Loss: 0.00143281
Iteration 11/25 | Loss: 0.00142624
Iteration 12/25 | Loss: 0.00142058
Iteration 13/25 | Loss: 0.00141820
Iteration 14/25 | Loss: 0.00141718
Iteration 15/25 | Loss: 0.00141697
Iteration 16/25 | Loss: 0.00141685
Iteration 17/25 | Loss: 0.00141684
Iteration 18/25 | Loss: 0.00141684
Iteration 19/25 | Loss: 0.00141684
Iteration 20/25 | Loss: 0.00141683
Iteration 21/25 | Loss: 0.00141683
Iteration 22/25 | Loss: 0.00141683
Iteration 23/25 | Loss: 0.00141683
Iteration 24/25 | Loss: 0.00141683
Iteration 25/25 | Loss: 0.00141678

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.24928463
Iteration 2/25 | Loss: 0.00147773
Iteration 3/25 | Loss: 0.00145060
Iteration 4/25 | Loss: 0.00145060
Iteration 5/25 | Loss: 0.00145060
Iteration 6/25 | Loss: 0.00145060
Iteration 7/25 | Loss: 0.00145060
Iteration 8/25 | Loss: 0.00145059
Iteration 9/25 | Loss: 0.00145059
Iteration 10/25 | Loss: 0.00145059
Iteration 11/25 | Loss: 0.00145059
Iteration 12/25 | Loss: 0.00145059
Iteration 13/25 | Loss: 0.00145059
Iteration 14/25 | Loss: 0.00145059
Iteration 15/25 | Loss: 0.00145059
Iteration 16/25 | Loss: 0.00145059
Iteration 17/25 | Loss: 0.00145059
Iteration 18/25 | Loss: 0.00145059
Iteration 19/25 | Loss: 0.00145059
Iteration 20/25 | Loss: 0.00145059
Iteration 21/25 | Loss: 0.00145059
Iteration 22/25 | Loss: 0.00145059
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0014505931176245213, 0.0014505931176245213, 0.0014505931176245213, 0.0014505931176245213, 0.0014505931176245213]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014505931176245213

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00145059
Iteration 2/1000 | Loss: 0.00004238
Iteration 3/1000 | Loss: 0.00014053
Iteration 4/1000 | Loss: 0.00002900
Iteration 5/1000 | Loss: 0.00002744
Iteration 6/1000 | Loss: 0.00002280
Iteration 7/1000 | Loss: 0.00002218
Iteration 8/1000 | Loss: 0.00002107
Iteration 9/1000 | Loss: 0.00002054
Iteration 10/1000 | Loss: 0.00002010
Iteration 11/1000 | Loss: 0.00001964
Iteration 12/1000 | Loss: 0.00001928
Iteration 13/1000 | Loss: 0.00006943
Iteration 14/1000 | Loss: 0.00002873
Iteration 15/1000 | Loss: 0.00010399
Iteration 16/1000 | Loss: 0.00002287
Iteration 17/1000 | Loss: 0.00001889
Iteration 18/1000 | Loss: 0.00002314
Iteration 19/1000 | Loss: 0.00001834
Iteration 20/1000 | Loss: 0.00004331
Iteration 21/1000 | Loss: 0.00001787
Iteration 22/1000 | Loss: 0.00001762
Iteration 23/1000 | Loss: 0.00001753
Iteration 24/1000 | Loss: 0.00001749
Iteration 25/1000 | Loss: 0.00001744
Iteration 26/1000 | Loss: 0.00001727
Iteration 27/1000 | Loss: 0.00010021
Iteration 28/1000 | Loss: 0.00009132
Iteration 29/1000 | Loss: 0.00016845
Iteration 30/1000 | Loss: 0.00005847
Iteration 31/1000 | Loss: 0.00009009
Iteration 32/1000 | Loss: 0.00001717
Iteration 33/1000 | Loss: 0.00001696
Iteration 34/1000 | Loss: 0.00001692
Iteration 35/1000 | Loss: 0.00001688
Iteration 36/1000 | Loss: 0.00001687
Iteration 37/1000 | Loss: 0.00001687
Iteration 38/1000 | Loss: 0.00001686
Iteration 39/1000 | Loss: 0.00001683
Iteration 40/1000 | Loss: 0.00001679
Iteration 41/1000 | Loss: 0.00001678
Iteration 42/1000 | Loss: 0.00001678
Iteration 43/1000 | Loss: 0.00001677
Iteration 44/1000 | Loss: 0.00001677
Iteration 45/1000 | Loss: 0.00001676
Iteration 46/1000 | Loss: 0.00001676
Iteration 47/1000 | Loss: 0.00001675
Iteration 48/1000 | Loss: 0.00001675
Iteration 49/1000 | Loss: 0.00001675
Iteration 50/1000 | Loss: 0.00001673
Iteration 51/1000 | Loss: 0.00001672
Iteration 52/1000 | Loss: 0.00001672
Iteration 53/1000 | Loss: 0.00001671
Iteration 54/1000 | Loss: 0.00001671
Iteration 55/1000 | Loss: 0.00001670
Iteration 56/1000 | Loss: 0.00001670
Iteration 57/1000 | Loss: 0.00001670
Iteration 58/1000 | Loss: 0.00001669
Iteration 59/1000 | Loss: 0.00001669
Iteration 60/1000 | Loss: 0.00001668
Iteration 61/1000 | Loss: 0.00001668
Iteration 62/1000 | Loss: 0.00001667
Iteration 63/1000 | Loss: 0.00001666
Iteration 64/1000 | Loss: 0.00001665
Iteration 65/1000 | Loss: 0.00001665
Iteration 66/1000 | Loss: 0.00001665
Iteration 67/1000 | Loss: 0.00001664
Iteration 68/1000 | Loss: 0.00001664
Iteration 69/1000 | Loss: 0.00001664
Iteration 70/1000 | Loss: 0.00001664
Iteration 71/1000 | Loss: 0.00001664
Iteration 72/1000 | Loss: 0.00001664
Iteration 73/1000 | Loss: 0.00001664
Iteration 74/1000 | Loss: 0.00001664
Iteration 75/1000 | Loss: 0.00001664
Iteration 76/1000 | Loss: 0.00001663
Iteration 77/1000 | Loss: 0.00001661
Iteration 78/1000 | Loss: 0.00001660
Iteration 79/1000 | Loss: 0.00001660
Iteration 80/1000 | Loss: 0.00001659
Iteration 81/1000 | Loss: 0.00001658
Iteration 82/1000 | Loss: 0.00001658
Iteration 83/1000 | Loss: 0.00001658
Iteration 84/1000 | Loss: 0.00001658
Iteration 85/1000 | Loss: 0.00001658
Iteration 86/1000 | Loss: 0.00001658
Iteration 87/1000 | Loss: 0.00001658
Iteration 88/1000 | Loss: 0.00001658
Iteration 89/1000 | Loss: 0.00001657
Iteration 90/1000 | Loss: 0.00001656
Iteration 91/1000 | Loss: 0.00001656
Iteration 92/1000 | Loss: 0.00001656
Iteration 93/1000 | Loss: 0.00001655
Iteration 94/1000 | Loss: 0.00001655
Iteration 95/1000 | Loss: 0.00001655
Iteration 96/1000 | Loss: 0.00001655
Iteration 97/1000 | Loss: 0.00001654
Iteration 98/1000 | Loss: 0.00001654
Iteration 99/1000 | Loss: 0.00001654
Iteration 100/1000 | Loss: 0.00001654
Iteration 101/1000 | Loss: 0.00001654
Iteration 102/1000 | Loss: 0.00001653
Iteration 103/1000 | Loss: 0.00001653
Iteration 104/1000 | Loss: 0.00001653
Iteration 105/1000 | Loss: 0.00001652
Iteration 106/1000 | Loss: 0.00001652
Iteration 107/1000 | Loss: 0.00001652
Iteration 108/1000 | Loss: 0.00001652
Iteration 109/1000 | Loss: 0.00001651
Iteration 110/1000 | Loss: 0.00001651
Iteration 111/1000 | Loss: 0.00001651
Iteration 112/1000 | Loss: 0.00001651
Iteration 113/1000 | Loss: 0.00001651
Iteration 114/1000 | Loss: 0.00001650
Iteration 115/1000 | Loss: 0.00001650
Iteration 116/1000 | Loss: 0.00001650
Iteration 117/1000 | Loss: 0.00001650
Iteration 118/1000 | Loss: 0.00001650
Iteration 119/1000 | Loss: 0.00001650
Iteration 120/1000 | Loss: 0.00001650
Iteration 121/1000 | Loss: 0.00001650
Iteration 122/1000 | Loss: 0.00001650
Iteration 123/1000 | Loss: 0.00001650
Iteration 124/1000 | Loss: 0.00001650
Iteration 125/1000 | Loss: 0.00001650
Iteration 126/1000 | Loss: 0.00001650
Iteration 127/1000 | Loss: 0.00001650
Iteration 128/1000 | Loss: 0.00001650
Iteration 129/1000 | Loss: 0.00001650
Iteration 130/1000 | Loss: 0.00001650
Iteration 131/1000 | Loss: 0.00001650
Iteration 132/1000 | Loss: 0.00001650
Iteration 133/1000 | Loss: 0.00001650
Iteration 134/1000 | Loss: 0.00001650
Iteration 135/1000 | Loss: 0.00001650
Iteration 136/1000 | Loss: 0.00001650
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 136. Stopping optimization.
Last 5 losses: [1.64977118402021e-05, 1.64977118402021e-05, 1.64977118402021e-05, 1.64977118402021e-05, 1.64977118402021e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.64977118402021e-05

Optimization complete. Final v2v error: 3.4242501258850098 mm

Highest mean error: 4.762017726898193 mm for frame 9

Lowest mean error: 2.9657793045043945 mm for frame 36

Saving results

Total time: 96.63788199424744
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1030
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00949273
Iteration 2/25 | Loss: 0.00949272
Iteration 3/25 | Loss: 0.00949272
Iteration 4/25 | Loss: 0.00949272
Iteration 5/25 | Loss: 0.00949272
Iteration 6/25 | Loss: 0.00949272
Iteration 7/25 | Loss: 0.00949272
Iteration 8/25 | Loss: 0.00949272
Iteration 9/25 | Loss: 0.00949272
Iteration 10/25 | Loss: 0.00949271
Iteration 11/25 | Loss: 0.00949271
Iteration 12/25 | Loss: 0.00949271
Iteration 13/25 | Loss: 0.00949271
Iteration 14/25 | Loss: 0.00949271
Iteration 15/25 | Loss: 0.00949271
Iteration 16/25 | Loss: 0.00949271
Iteration 17/25 | Loss: 0.00949270
Iteration 18/25 | Loss: 0.00949270
Iteration 19/25 | Loss: 0.00949270
Iteration 20/25 | Loss: 0.00949270
Iteration 21/25 | Loss: 0.00949270
Iteration 22/25 | Loss: 0.00949270
Iteration 23/25 | Loss: 0.00949270
Iteration 24/25 | Loss: 0.00949270
Iteration 25/25 | Loss: 0.00949269

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29143989
Iteration 2/25 | Loss: 0.18027073
Iteration 3/25 | Loss: 0.17954168
Iteration 4/25 | Loss: 0.17894565
Iteration 5/25 | Loss: 0.17889082
Iteration 6/25 | Loss: 0.17879783
Iteration 7/25 | Loss: 0.17879781
Iteration 8/25 | Loss: 0.17879777
Iteration 9/25 | Loss: 0.17879777
Iteration 10/25 | Loss: 0.17879777
Iteration 11/25 | Loss: 0.17879777
Iteration 12/25 | Loss: 0.17879777
Iteration 13/25 | Loss: 0.17879777
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.17879776656627655, 0.17879776656627655, 0.17879776656627655, 0.17879776656627655, 0.17879776656627655]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.17879776656627655

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.17879775
Iteration 2/1000 | Loss: 0.00197368
Iteration 3/1000 | Loss: 0.00042089
Iteration 4/1000 | Loss: 0.00018995
Iteration 5/1000 | Loss: 0.00005333
Iteration 6/1000 | Loss: 0.00007638
Iteration 7/1000 | Loss: 0.00003965
Iteration 8/1000 | Loss: 0.00010744
Iteration 9/1000 | Loss: 0.00030365
Iteration 10/1000 | Loss: 0.00171070
Iteration 11/1000 | Loss: 0.00004025
Iteration 12/1000 | Loss: 0.00033791
Iteration 13/1000 | Loss: 0.00075335
Iteration 14/1000 | Loss: 0.00003577
Iteration 15/1000 | Loss: 0.00046811
Iteration 16/1000 | Loss: 0.00034152
Iteration 17/1000 | Loss: 0.00002453
Iteration 18/1000 | Loss: 0.00016699
Iteration 19/1000 | Loss: 0.00001802
Iteration 20/1000 | Loss: 0.00017025
Iteration 21/1000 | Loss: 0.00004032
Iteration 22/1000 | Loss: 0.00003240
Iteration 23/1000 | Loss: 0.00001594
Iteration 24/1000 | Loss: 0.00025114
Iteration 25/1000 | Loss: 0.00006647
Iteration 26/1000 | Loss: 0.00003543
Iteration 27/1000 | Loss: 0.00128500
Iteration 28/1000 | Loss: 0.00083448
Iteration 29/1000 | Loss: 0.00005107
Iteration 30/1000 | Loss: 0.00003843
Iteration 31/1000 | Loss: 0.00005883
Iteration 32/1000 | Loss: 0.00113586
Iteration 33/1000 | Loss: 0.00017701
Iteration 34/1000 | Loss: 0.00002844
Iteration 35/1000 | Loss: 0.00003273
Iteration 36/1000 | Loss: 0.00001834
Iteration 37/1000 | Loss: 0.00001627
Iteration 38/1000 | Loss: 0.00001389
Iteration 39/1000 | Loss: 0.00001378
Iteration 40/1000 | Loss: 0.00004250
Iteration 41/1000 | Loss: 0.00004250
Iteration 42/1000 | Loss: 0.00029999
Iteration 43/1000 | Loss: 0.00001711
Iteration 44/1000 | Loss: 0.00001369
Iteration 45/1000 | Loss: 0.00001358
Iteration 46/1000 | Loss: 0.00001357
Iteration 47/1000 | Loss: 0.00001354
Iteration 48/1000 | Loss: 0.00001354
Iteration 49/1000 | Loss: 0.00001353
Iteration 50/1000 | Loss: 0.00001353
Iteration 51/1000 | Loss: 0.00001352
Iteration 52/1000 | Loss: 0.00001351
Iteration 53/1000 | Loss: 0.00002391
Iteration 54/1000 | Loss: 0.00004901
Iteration 55/1000 | Loss: 0.00010321
Iteration 56/1000 | Loss: 0.00006019
Iteration 57/1000 | Loss: 0.00004891
Iteration 58/1000 | Loss: 0.00001360
Iteration 59/1000 | Loss: 0.00001487
Iteration 60/1000 | Loss: 0.00001347
Iteration 61/1000 | Loss: 0.00001723
Iteration 62/1000 | Loss: 0.00002774
Iteration 63/1000 | Loss: 0.00006721
Iteration 64/1000 | Loss: 0.00001336
Iteration 65/1000 | Loss: 0.00001336
Iteration 66/1000 | Loss: 0.00001336
Iteration 67/1000 | Loss: 0.00001336
Iteration 68/1000 | Loss: 0.00001336
Iteration 69/1000 | Loss: 0.00001336
Iteration 70/1000 | Loss: 0.00001336
Iteration 71/1000 | Loss: 0.00001336
Iteration 72/1000 | Loss: 0.00001335
Iteration 73/1000 | Loss: 0.00001335
Iteration 74/1000 | Loss: 0.00001335
Iteration 75/1000 | Loss: 0.00001335
Iteration 76/1000 | Loss: 0.00001334
Iteration 77/1000 | Loss: 0.00001334
Iteration 78/1000 | Loss: 0.00001334
Iteration 79/1000 | Loss: 0.00001334
Iteration 80/1000 | Loss: 0.00001334
Iteration 81/1000 | Loss: 0.00001334
Iteration 82/1000 | Loss: 0.00001334
Iteration 83/1000 | Loss: 0.00001333
Iteration 84/1000 | Loss: 0.00001333
Iteration 85/1000 | Loss: 0.00001333
Iteration 86/1000 | Loss: 0.00001333
Iteration 87/1000 | Loss: 0.00001333
Iteration 88/1000 | Loss: 0.00001333
Iteration 89/1000 | Loss: 0.00001333
Iteration 90/1000 | Loss: 0.00001332
Iteration 91/1000 | Loss: 0.00001332
Iteration 92/1000 | Loss: 0.00001332
Iteration 93/1000 | Loss: 0.00001331
Iteration 94/1000 | Loss: 0.00001331
Iteration 95/1000 | Loss: 0.00001331
Iteration 96/1000 | Loss: 0.00001331
Iteration 97/1000 | Loss: 0.00001331
Iteration 98/1000 | Loss: 0.00001330
Iteration 99/1000 | Loss: 0.00001330
Iteration 100/1000 | Loss: 0.00001328
Iteration 101/1000 | Loss: 0.00001327
Iteration 102/1000 | Loss: 0.00001327
Iteration 103/1000 | Loss: 0.00001326
Iteration 104/1000 | Loss: 0.00001326
Iteration 105/1000 | Loss: 0.00001326
Iteration 106/1000 | Loss: 0.00001326
Iteration 107/1000 | Loss: 0.00001326
Iteration 108/1000 | Loss: 0.00001326
Iteration 109/1000 | Loss: 0.00001326
Iteration 110/1000 | Loss: 0.00001326
Iteration 111/1000 | Loss: 0.00001325
Iteration 112/1000 | Loss: 0.00001324
Iteration 113/1000 | Loss: 0.00001324
Iteration 114/1000 | Loss: 0.00001324
Iteration 115/1000 | Loss: 0.00001324
Iteration 116/1000 | Loss: 0.00001324
Iteration 117/1000 | Loss: 0.00001324
Iteration 118/1000 | Loss: 0.00001324
Iteration 119/1000 | Loss: 0.00001324
Iteration 120/1000 | Loss: 0.00001324
Iteration 121/1000 | Loss: 0.00001323
Iteration 122/1000 | Loss: 0.00001323
Iteration 123/1000 | Loss: 0.00001323
Iteration 124/1000 | Loss: 0.00001323
Iteration 125/1000 | Loss: 0.00001323
Iteration 126/1000 | Loss: 0.00001323
Iteration 127/1000 | Loss: 0.00001323
Iteration 128/1000 | Loss: 0.00001323
Iteration 129/1000 | Loss: 0.00001323
Iteration 130/1000 | Loss: 0.00001323
Iteration 131/1000 | Loss: 0.00001323
Iteration 132/1000 | Loss: 0.00001322
Iteration 133/1000 | Loss: 0.00001322
Iteration 134/1000 | Loss: 0.00001322
Iteration 135/1000 | Loss: 0.00001322
Iteration 136/1000 | Loss: 0.00001322
Iteration 137/1000 | Loss: 0.00001322
Iteration 138/1000 | Loss: 0.00001322
Iteration 139/1000 | Loss: 0.00001322
Iteration 140/1000 | Loss: 0.00001322
Iteration 141/1000 | Loss: 0.00001322
Iteration 142/1000 | Loss: 0.00001322
Iteration 143/1000 | Loss: 0.00001321
Iteration 144/1000 | Loss: 0.00001321
Iteration 145/1000 | Loss: 0.00001321
Iteration 146/1000 | Loss: 0.00001321
Iteration 147/1000 | Loss: 0.00001321
Iteration 148/1000 | Loss: 0.00001321
Iteration 149/1000 | Loss: 0.00001321
Iteration 150/1000 | Loss: 0.00001321
Iteration 151/1000 | Loss: 0.00001321
Iteration 152/1000 | Loss: 0.00001321
Iteration 153/1000 | Loss: 0.00001321
Iteration 154/1000 | Loss: 0.00001320
Iteration 155/1000 | Loss: 0.00001320
Iteration 156/1000 | Loss: 0.00001320
Iteration 157/1000 | Loss: 0.00001320
Iteration 158/1000 | Loss: 0.00001320
Iteration 159/1000 | Loss: 0.00001320
Iteration 160/1000 | Loss: 0.00001320
Iteration 161/1000 | Loss: 0.00001320
Iteration 162/1000 | Loss: 0.00001320
Iteration 163/1000 | Loss: 0.00001320
Iteration 164/1000 | Loss: 0.00001320
Iteration 165/1000 | Loss: 0.00001320
Iteration 166/1000 | Loss: 0.00001320
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 166. Stopping optimization.
Last 5 losses: [1.3201844012655783e-05, 1.3201844012655783e-05, 1.3201844012655783e-05, 1.3201844012655783e-05, 1.3201844012655783e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3201844012655783e-05

Optimization complete. Final v2v error: 3.121692657470703 mm

Highest mean error: 3.528449535369873 mm for frame 233

Lowest mean error: 2.977046489715576 mm for frame 124

Saving results

Total time: 100.51204991340637
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1061/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1061.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1061
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00816970
Iteration 2/25 | Loss: 0.00155841
Iteration 3/25 | Loss: 0.00139822
Iteration 4/25 | Loss: 0.00137732
Iteration 5/25 | Loss: 0.00137521
Iteration 6/25 | Loss: 0.00137769
Iteration 7/25 | Loss: 0.00137558
Iteration 8/25 | Loss: 0.00137696
Iteration 9/25 | Loss: 0.00137248
Iteration 10/25 | Loss: 0.00137227
Iteration 11/25 | Loss: 0.00136963
Iteration 12/25 | Loss: 0.00136854
Iteration 13/25 | Loss: 0.00136753
Iteration 14/25 | Loss: 0.00136671
Iteration 15/25 | Loss: 0.00136650
Iteration 16/25 | Loss: 0.00136642
Iteration 17/25 | Loss: 0.00136642
Iteration 18/25 | Loss: 0.00136642
Iteration 19/25 | Loss: 0.00136641
Iteration 20/25 | Loss: 0.00136641
Iteration 21/25 | Loss: 0.00136641
Iteration 22/25 | Loss: 0.00136641
Iteration 23/25 | Loss: 0.00136640
Iteration 24/25 | Loss: 0.00136639
Iteration 25/25 | Loss: 0.00136639

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.57473850
Iteration 2/25 | Loss: 0.00171390
Iteration 3/25 | Loss: 0.00171390
Iteration 4/25 | Loss: 0.00171390
Iteration 5/25 | Loss: 0.00171390
Iteration 6/25 | Loss: 0.00171390
Iteration 7/25 | Loss: 0.00171390
Iteration 8/25 | Loss: 0.00171390
Iteration 9/25 | Loss: 0.00171390
Iteration 10/25 | Loss: 0.00171390
Iteration 11/25 | Loss: 0.00171390
Iteration 12/25 | Loss: 0.00171390
Iteration 13/25 | Loss: 0.00171390
Iteration 14/25 | Loss: 0.00171390
Iteration 15/25 | Loss: 0.00171390
Iteration 16/25 | Loss: 0.00171390
Iteration 17/25 | Loss: 0.00171390
Iteration 18/25 | Loss: 0.00171390
Iteration 19/25 | Loss: 0.00171390
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0017138998955488205, 0.0017138998955488205, 0.0017138998955488205, 0.0017138998955488205, 0.0017138998955488205]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017138998955488205

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00171390
Iteration 2/1000 | Loss: 0.00003262
Iteration 3/1000 | Loss: 0.00002533
Iteration 4/1000 | Loss: 0.00002320
Iteration 5/1000 | Loss: 0.00002175
Iteration 6/1000 | Loss: 0.00002068
Iteration 7/1000 | Loss: 0.00001992
Iteration 8/1000 | Loss: 0.00001939
Iteration 9/1000 | Loss: 0.00001894
Iteration 10/1000 | Loss: 0.00001844
Iteration 11/1000 | Loss: 0.00001815
Iteration 12/1000 | Loss: 0.00001790
Iteration 13/1000 | Loss: 0.00029290
Iteration 14/1000 | Loss: 0.00002035
Iteration 15/1000 | Loss: 0.00001827
Iteration 16/1000 | Loss: 0.00001753
Iteration 17/1000 | Loss: 0.00001704
Iteration 18/1000 | Loss: 0.00001662
Iteration 19/1000 | Loss: 0.00001633
Iteration 20/1000 | Loss: 0.00001630
Iteration 21/1000 | Loss: 0.00001629
Iteration 22/1000 | Loss: 0.00001629
Iteration 23/1000 | Loss: 0.00001628
Iteration 24/1000 | Loss: 0.00001623
Iteration 25/1000 | Loss: 0.00001623
Iteration 26/1000 | Loss: 0.00001622
Iteration 27/1000 | Loss: 0.00001617
Iteration 28/1000 | Loss: 0.00001611
Iteration 29/1000 | Loss: 0.00001607
Iteration 30/1000 | Loss: 0.00001607
Iteration 31/1000 | Loss: 0.00001605
Iteration 32/1000 | Loss: 0.00001605
Iteration 33/1000 | Loss: 0.00001605
Iteration 34/1000 | Loss: 0.00001604
Iteration 35/1000 | Loss: 0.00001604
Iteration 36/1000 | Loss: 0.00001603
Iteration 37/1000 | Loss: 0.00001603
Iteration 38/1000 | Loss: 0.00001602
Iteration 39/1000 | Loss: 0.00001601
Iteration 40/1000 | Loss: 0.00001592
Iteration 41/1000 | Loss: 0.00001592
Iteration 42/1000 | Loss: 0.00001591
Iteration 43/1000 | Loss: 0.00001591
Iteration 44/1000 | Loss: 0.00001591
Iteration 45/1000 | Loss: 0.00001591
Iteration 46/1000 | Loss: 0.00001590
Iteration 47/1000 | Loss: 0.00001588
Iteration 48/1000 | Loss: 0.00001588
Iteration 49/1000 | Loss: 0.00001585
Iteration 50/1000 | Loss: 0.00001585
Iteration 51/1000 | Loss: 0.00001583
Iteration 52/1000 | Loss: 0.00001583
Iteration 53/1000 | Loss: 0.00001582
Iteration 54/1000 | Loss: 0.00001582
Iteration 55/1000 | Loss: 0.00001582
Iteration 56/1000 | Loss: 0.00001581
Iteration 57/1000 | Loss: 0.00001580
Iteration 58/1000 | Loss: 0.00001578
Iteration 59/1000 | Loss: 0.00001577
Iteration 60/1000 | Loss: 0.00001576
Iteration 61/1000 | Loss: 0.00001576
Iteration 62/1000 | Loss: 0.00001575
Iteration 63/1000 | Loss: 0.00001574
Iteration 64/1000 | Loss: 0.00001573
Iteration 65/1000 | Loss: 0.00001573
Iteration 66/1000 | Loss: 0.00001572
Iteration 67/1000 | Loss: 0.00001572
Iteration 68/1000 | Loss: 0.00001572
Iteration 69/1000 | Loss: 0.00001571
Iteration 70/1000 | Loss: 0.00001571
Iteration 71/1000 | Loss: 0.00001571
Iteration 72/1000 | Loss: 0.00001570
Iteration 73/1000 | Loss: 0.00001570
Iteration 74/1000 | Loss: 0.00001570
Iteration 75/1000 | Loss: 0.00001569
Iteration 76/1000 | Loss: 0.00001567
Iteration 77/1000 | Loss: 0.00001567
Iteration 78/1000 | Loss: 0.00001567
Iteration 79/1000 | Loss: 0.00001566
Iteration 80/1000 | Loss: 0.00001566
Iteration 81/1000 | Loss: 0.00001566
Iteration 82/1000 | Loss: 0.00001565
Iteration 83/1000 | Loss: 0.00001565
Iteration 84/1000 | Loss: 0.00001565
Iteration 85/1000 | Loss: 0.00001564
Iteration 86/1000 | Loss: 0.00001564
Iteration 87/1000 | Loss: 0.00001564
Iteration 88/1000 | Loss: 0.00001564
Iteration 89/1000 | Loss: 0.00001564
Iteration 90/1000 | Loss: 0.00001564
Iteration 91/1000 | Loss: 0.00001564
Iteration 92/1000 | Loss: 0.00001564
Iteration 93/1000 | Loss: 0.00001564
Iteration 94/1000 | Loss: 0.00001564
Iteration 95/1000 | Loss: 0.00001564
Iteration 96/1000 | Loss: 0.00001564
Iteration 97/1000 | Loss: 0.00001564
Iteration 98/1000 | Loss: 0.00001564
Iteration 99/1000 | Loss: 0.00001563
Iteration 100/1000 | Loss: 0.00001563
Iteration 101/1000 | Loss: 0.00001563
Iteration 102/1000 | Loss: 0.00001563
Iteration 103/1000 | Loss: 0.00001563
Iteration 104/1000 | Loss: 0.00001563
Iteration 105/1000 | Loss: 0.00001563
Iteration 106/1000 | Loss: 0.00001563
Iteration 107/1000 | Loss: 0.00001563
Iteration 108/1000 | Loss: 0.00001563
Iteration 109/1000 | Loss: 0.00001563
Iteration 110/1000 | Loss: 0.00001563
Iteration 111/1000 | Loss: 0.00001563
Iteration 112/1000 | Loss: 0.00001563
Iteration 113/1000 | Loss: 0.00001563
Iteration 114/1000 | Loss: 0.00001563
Iteration 115/1000 | Loss: 0.00001563
Iteration 116/1000 | Loss: 0.00001563
Iteration 117/1000 | Loss: 0.00001562
Iteration 118/1000 | Loss: 0.00001562
Iteration 119/1000 | Loss: 0.00001562
Iteration 120/1000 | Loss: 0.00001562
Iteration 121/1000 | Loss: 0.00001562
Iteration 122/1000 | Loss: 0.00001562
Iteration 123/1000 | Loss: 0.00001562
Iteration 124/1000 | Loss: 0.00001562
Iteration 125/1000 | Loss: 0.00001562
Iteration 126/1000 | Loss: 0.00001562
Iteration 127/1000 | Loss: 0.00001562
Iteration 128/1000 | Loss: 0.00001561
Iteration 129/1000 | Loss: 0.00001561
Iteration 130/1000 | Loss: 0.00001561
Iteration 131/1000 | Loss: 0.00001561
Iteration 132/1000 | Loss: 0.00001561
Iteration 133/1000 | Loss: 0.00001561
Iteration 134/1000 | Loss: 0.00001561
Iteration 135/1000 | Loss: 0.00001561
Iteration 136/1000 | Loss: 0.00001561
Iteration 137/1000 | Loss: 0.00001561
Iteration 138/1000 | Loss: 0.00001561
Iteration 139/1000 | Loss: 0.00001561
Iteration 140/1000 | Loss: 0.00001561
Iteration 141/1000 | Loss: 0.00001561
Iteration 142/1000 | Loss: 0.00001561
Iteration 143/1000 | Loss: 0.00001561
Iteration 144/1000 | Loss: 0.00001560
Iteration 145/1000 | Loss: 0.00001560
Iteration 146/1000 | Loss: 0.00001560
Iteration 147/1000 | Loss: 0.00001560
Iteration 148/1000 | Loss: 0.00001560
Iteration 149/1000 | Loss: 0.00001560
Iteration 150/1000 | Loss: 0.00001560
Iteration 151/1000 | Loss: 0.00001560
Iteration 152/1000 | Loss: 0.00001560
Iteration 153/1000 | Loss: 0.00001560
Iteration 154/1000 | Loss: 0.00001560
Iteration 155/1000 | Loss: 0.00001560
Iteration 156/1000 | Loss: 0.00001560
Iteration 157/1000 | Loss: 0.00001560
Iteration 158/1000 | Loss: 0.00001560
Iteration 159/1000 | Loss: 0.00001560
Iteration 160/1000 | Loss: 0.00001560
Iteration 161/1000 | Loss: 0.00001560
Iteration 162/1000 | Loss: 0.00001559
Iteration 163/1000 | Loss: 0.00001559
Iteration 164/1000 | Loss: 0.00001559
Iteration 165/1000 | Loss: 0.00001559
Iteration 166/1000 | Loss: 0.00001559
Iteration 167/1000 | Loss: 0.00001559
Iteration 168/1000 | Loss: 0.00001559
Iteration 169/1000 | Loss: 0.00001559
Iteration 170/1000 | Loss: 0.00001559
Iteration 171/1000 | Loss: 0.00001559
Iteration 172/1000 | Loss: 0.00001559
Iteration 173/1000 | Loss: 0.00001559
Iteration 174/1000 | Loss: 0.00001559
Iteration 175/1000 | Loss: 0.00001559
Iteration 176/1000 | Loss: 0.00001559
Iteration 177/1000 | Loss: 0.00001559
Iteration 178/1000 | Loss: 0.00001559
Iteration 179/1000 | Loss: 0.00001559
Iteration 180/1000 | Loss: 0.00001559
Iteration 181/1000 | Loss: 0.00001559
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.5588417227263562e-05, 1.5588417227263562e-05, 1.5588417227263562e-05, 1.5588417227263562e-05, 1.5588417227263562e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5588417227263562e-05

Optimization complete. Final v2v error: 3.3666694164276123 mm

Highest mean error: 4.5470757484436035 mm for frame 183

Lowest mean error: 2.9508869647979736 mm for frame 233

Saving results

Total time: 79.46245312690735
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1082/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1082.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1082
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01060442
Iteration 2/25 | Loss: 0.00287172
Iteration 3/25 | Loss: 0.00194005
Iteration 4/25 | Loss: 0.00179421
Iteration 5/25 | Loss: 0.00176254
Iteration 6/25 | Loss: 0.00171931
Iteration 7/25 | Loss: 0.00169928
Iteration 8/25 | Loss: 0.00167164
Iteration 9/25 | Loss: 0.00168406
Iteration 10/25 | Loss: 0.00163977
Iteration 11/25 | Loss: 0.00159822
Iteration 12/25 | Loss: 0.00153294
Iteration 13/25 | Loss: 0.00151735
Iteration 14/25 | Loss: 0.00149797
Iteration 15/25 | Loss: 0.00147400
Iteration 16/25 | Loss: 0.00146682
Iteration 17/25 | Loss: 0.00146184
Iteration 18/25 | Loss: 0.00145550
Iteration 19/25 | Loss: 0.00145140
Iteration 20/25 | Loss: 0.00144812
Iteration 21/25 | Loss: 0.00144748
Iteration 22/25 | Loss: 0.00144798
Iteration 23/25 | Loss: 0.00144647
Iteration 24/25 | Loss: 0.00144790
Iteration 25/25 | Loss: 0.00144770

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.01924193
Iteration 2/25 | Loss: 0.00178430
Iteration 3/25 | Loss: 0.00178430
Iteration 4/25 | Loss: 0.00178430
Iteration 5/25 | Loss: 0.00178430
Iteration 6/25 | Loss: 0.00178430
Iteration 7/25 | Loss: 0.00178430
Iteration 8/25 | Loss: 0.00178430
Iteration 9/25 | Loss: 0.00178430
Iteration 10/25 | Loss: 0.00178430
Iteration 11/25 | Loss: 0.00178430
Iteration 12/25 | Loss: 0.00178430
Iteration 13/25 | Loss: 0.00178430
Iteration 14/25 | Loss: 0.00178430
Iteration 15/25 | Loss: 0.00178430
Iteration 16/25 | Loss: 0.00178430
Iteration 17/25 | Loss: 0.00178430
Iteration 18/25 | Loss: 0.00178430
Iteration 19/25 | Loss: 0.00178430
Iteration 20/25 | Loss: 0.00178430
Iteration 21/25 | Loss: 0.00178430
Iteration 22/25 | Loss: 0.00178430
Iteration 23/25 | Loss: 0.00178430
Iteration 24/25 | Loss: 0.00178430
Iteration 25/25 | Loss: 0.00178430

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00178430
Iteration 2/1000 | Loss: 0.00014855
Iteration 3/1000 | Loss: 0.00008841
Iteration 4/1000 | Loss: 0.00006035
Iteration 5/1000 | Loss: 0.00006832
Iteration 6/1000 | Loss: 0.00005006
Iteration 7/1000 | Loss: 0.00009642
Iteration 8/1000 | Loss: 0.00019730
Iteration 9/1000 | Loss: 0.00005486
Iteration 10/1000 | Loss: 0.00007278
Iteration 11/1000 | Loss: 0.00006397
Iteration 12/1000 | Loss: 0.00006252
Iteration 13/1000 | Loss: 0.00004433
Iteration 14/1000 | Loss: 0.00005630
Iteration 15/1000 | Loss: 0.00007138
Iteration 16/1000 | Loss: 0.00005814
Iteration 17/1000 | Loss: 0.00005670
Iteration 18/1000 | Loss: 0.00006165
Iteration 19/1000 | Loss: 0.00005933
Iteration 20/1000 | Loss: 0.00005442
Iteration 21/1000 | Loss: 0.00005369
Iteration 22/1000 | Loss: 0.00006241
Iteration 23/1000 | Loss: 0.00005921
Iteration 24/1000 | Loss: 0.00005782
Iteration 25/1000 | Loss: 0.00004716
Iteration 26/1000 | Loss: 0.00015848
Iteration 27/1000 | Loss: 0.00005604
Iteration 28/1000 | Loss: 0.00006373
Iteration 29/1000 | Loss: 0.00005402
Iteration 30/1000 | Loss: 0.00006270
Iteration 31/1000 | Loss: 0.00005580
Iteration 32/1000 | Loss: 0.00005476
Iteration 33/1000 | Loss: 0.00006519
Iteration 34/1000 | Loss: 0.00026429
Iteration 35/1000 | Loss: 0.00008509
Iteration 36/1000 | Loss: 0.00007646
Iteration 37/1000 | Loss: 0.00005982
Iteration 38/1000 | Loss: 0.00012640
Iteration 39/1000 | Loss: 0.00006426
Iteration 40/1000 | Loss: 0.00005435
Iteration 41/1000 | Loss: 0.00006449
Iteration 42/1000 | Loss: 0.00006122
Iteration 43/1000 | Loss: 0.00005944
Iteration 44/1000 | Loss: 0.00006534
Iteration 45/1000 | Loss: 0.00019777
Iteration 46/1000 | Loss: 0.00013947
Iteration 47/1000 | Loss: 0.00011371
Iteration 48/1000 | Loss: 0.00019764
Iteration 49/1000 | Loss: 0.00017436
Iteration 50/1000 | Loss: 0.00016803
Iteration 51/1000 | Loss: 0.00080563
Iteration 52/1000 | Loss: 0.00056976
Iteration 53/1000 | Loss: 0.00025050
Iteration 54/1000 | Loss: 0.00005725
Iteration 55/1000 | Loss: 0.00005319
Iteration 56/1000 | Loss: 0.00056566
Iteration 57/1000 | Loss: 0.00016088
Iteration 58/1000 | Loss: 0.00005725
Iteration 59/1000 | Loss: 0.00006399
Iteration 60/1000 | Loss: 0.00003846
Iteration 61/1000 | Loss: 0.00005473
Iteration 62/1000 | Loss: 0.00003847
Iteration 63/1000 | Loss: 0.00002985
Iteration 64/1000 | Loss: 0.00005218
Iteration 65/1000 | Loss: 0.00004786
Iteration 66/1000 | Loss: 0.00004400
Iteration 67/1000 | Loss: 0.00004435
Iteration 68/1000 | Loss: 0.00004269
Iteration 69/1000 | Loss: 0.00014893
Iteration 70/1000 | Loss: 0.00007221
Iteration 71/1000 | Loss: 0.00002779
Iteration 72/1000 | Loss: 0.00004345
Iteration 73/1000 | Loss: 0.00005562
Iteration 74/1000 | Loss: 0.00004610
Iteration 75/1000 | Loss: 0.00005064
Iteration 76/1000 | Loss: 0.00014259
Iteration 77/1000 | Loss: 0.00005083
Iteration 78/1000 | Loss: 0.00010663
Iteration 79/1000 | Loss: 0.00004927
Iteration 80/1000 | Loss: 0.00003653
Iteration 81/1000 | Loss: 0.00005067
Iteration 82/1000 | Loss: 0.00003450
Iteration 83/1000 | Loss: 0.00004847
Iteration 84/1000 | Loss: 0.00007101
Iteration 85/1000 | Loss: 0.00007244
Iteration 86/1000 | Loss: 0.00005110
Iteration 87/1000 | Loss: 0.00004783
Iteration 88/1000 | Loss: 0.00004731
Iteration 89/1000 | Loss: 0.00004306
Iteration 90/1000 | Loss: 0.00002674
Iteration 91/1000 | Loss: 0.00002495
Iteration 92/1000 | Loss: 0.00002255
Iteration 93/1000 | Loss: 0.00007714
Iteration 94/1000 | Loss: 0.00004014
Iteration 95/1000 | Loss: 0.00002116
Iteration 96/1000 | Loss: 0.00007030
Iteration 97/1000 | Loss: 0.00002053
Iteration 98/1000 | Loss: 0.00002008
Iteration 99/1000 | Loss: 0.00001978
Iteration 100/1000 | Loss: 0.00001952
Iteration 101/1000 | Loss: 0.00001937
Iteration 102/1000 | Loss: 0.00001933
Iteration 103/1000 | Loss: 0.00001933
Iteration 104/1000 | Loss: 0.00001933
Iteration 105/1000 | Loss: 0.00001932
Iteration 106/1000 | Loss: 0.00001932
Iteration 107/1000 | Loss: 0.00001930
Iteration 108/1000 | Loss: 0.00001930
Iteration 109/1000 | Loss: 0.00001930
Iteration 110/1000 | Loss: 0.00001929
Iteration 111/1000 | Loss: 0.00001929
Iteration 112/1000 | Loss: 0.00001929
Iteration 113/1000 | Loss: 0.00001929
Iteration 114/1000 | Loss: 0.00001927
Iteration 115/1000 | Loss: 0.00001927
Iteration 116/1000 | Loss: 0.00001926
Iteration 117/1000 | Loss: 0.00001926
Iteration 118/1000 | Loss: 0.00001926
Iteration 119/1000 | Loss: 0.00001926
Iteration 120/1000 | Loss: 0.00001926
Iteration 121/1000 | Loss: 0.00001926
Iteration 122/1000 | Loss: 0.00001925
Iteration 123/1000 | Loss: 0.00001925
Iteration 124/1000 | Loss: 0.00001925
Iteration 125/1000 | Loss: 0.00001924
Iteration 126/1000 | Loss: 0.00001924
Iteration 127/1000 | Loss: 0.00001923
Iteration 128/1000 | Loss: 0.00001920
Iteration 129/1000 | Loss: 0.00001920
Iteration 130/1000 | Loss: 0.00001919
Iteration 131/1000 | Loss: 0.00001916
Iteration 132/1000 | Loss: 0.00001915
Iteration 133/1000 | Loss: 0.00001914
Iteration 134/1000 | Loss: 0.00001911
Iteration 135/1000 | Loss: 0.00001910
Iteration 136/1000 | Loss: 0.00001909
Iteration 137/1000 | Loss: 0.00001903
Iteration 138/1000 | Loss: 0.00001901
Iteration 139/1000 | Loss: 0.00001901
Iteration 140/1000 | Loss: 0.00001901
Iteration 141/1000 | Loss: 0.00001901
Iteration 142/1000 | Loss: 0.00001899
Iteration 143/1000 | Loss: 0.00001899
Iteration 144/1000 | Loss: 0.00001899
Iteration 145/1000 | Loss: 0.00001899
Iteration 146/1000 | Loss: 0.00001898
Iteration 147/1000 | Loss: 0.00001898
Iteration 148/1000 | Loss: 0.00001897
Iteration 149/1000 | Loss: 0.00001897
Iteration 150/1000 | Loss: 0.00001896
Iteration 151/1000 | Loss: 0.00001896
Iteration 152/1000 | Loss: 0.00001896
Iteration 153/1000 | Loss: 0.00001896
Iteration 154/1000 | Loss: 0.00001896
Iteration 155/1000 | Loss: 0.00001896
Iteration 156/1000 | Loss: 0.00001896
Iteration 157/1000 | Loss: 0.00001896
Iteration 158/1000 | Loss: 0.00001896
Iteration 159/1000 | Loss: 0.00001896
Iteration 160/1000 | Loss: 0.00001896
Iteration 161/1000 | Loss: 0.00001895
Iteration 162/1000 | Loss: 0.00001895
Iteration 163/1000 | Loss: 0.00001895
Iteration 164/1000 | Loss: 0.00001894
Iteration 165/1000 | Loss: 0.00001894
Iteration 166/1000 | Loss: 0.00001894
Iteration 167/1000 | Loss: 0.00001894
Iteration 168/1000 | Loss: 0.00001894
Iteration 169/1000 | Loss: 0.00001894
Iteration 170/1000 | Loss: 0.00001894
Iteration 171/1000 | Loss: 0.00001894
Iteration 172/1000 | Loss: 0.00001894
Iteration 173/1000 | Loss: 0.00001894
Iteration 174/1000 | Loss: 0.00001893
Iteration 175/1000 | Loss: 0.00001893
Iteration 176/1000 | Loss: 0.00001893
Iteration 177/1000 | Loss: 0.00001892
Iteration 178/1000 | Loss: 0.00001892
Iteration 179/1000 | Loss: 0.00001892
Iteration 180/1000 | Loss: 0.00001892
Iteration 181/1000 | Loss: 0.00001892
Iteration 182/1000 | Loss: 0.00001892
Iteration 183/1000 | Loss: 0.00001892
Iteration 184/1000 | Loss: 0.00001892
Iteration 185/1000 | Loss: 0.00001891
Iteration 186/1000 | Loss: 0.00001891
Iteration 187/1000 | Loss: 0.00001891
Iteration 188/1000 | Loss: 0.00001891
Iteration 189/1000 | Loss: 0.00001891
Iteration 190/1000 | Loss: 0.00001891
Iteration 191/1000 | Loss: 0.00001891
Iteration 192/1000 | Loss: 0.00001891
Iteration 193/1000 | Loss: 0.00001891
Iteration 194/1000 | Loss: 0.00001891
Iteration 195/1000 | Loss: 0.00001891
Iteration 196/1000 | Loss: 0.00001891
Iteration 197/1000 | Loss: 0.00001890
Iteration 198/1000 | Loss: 0.00001890
Iteration 199/1000 | Loss: 0.00001890
Iteration 200/1000 | Loss: 0.00001890
Iteration 201/1000 | Loss: 0.00001890
Iteration 202/1000 | Loss: 0.00001890
Iteration 203/1000 | Loss: 0.00001890
Iteration 204/1000 | Loss: 0.00001890
Iteration 205/1000 | Loss: 0.00001889
Iteration 206/1000 | Loss: 0.00001889
Iteration 207/1000 | Loss: 0.00001889
Iteration 208/1000 | Loss: 0.00001889
Iteration 209/1000 | Loss: 0.00001889
Iteration 210/1000 | Loss: 0.00001889
Iteration 211/1000 | Loss: 0.00001889
Iteration 212/1000 | Loss: 0.00001889
Iteration 213/1000 | Loss: 0.00001889
Iteration 214/1000 | Loss: 0.00001889
Iteration 215/1000 | Loss: 0.00001889
Iteration 216/1000 | Loss: 0.00001888
Iteration 217/1000 | Loss: 0.00001888
Iteration 218/1000 | Loss: 0.00001888
Iteration 219/1000 | Loss: 0.00001888
Iteration 220/1000 | Loss: 0.00001888
Iteration 221/1000 | Loss: 0.00001888
Iteration 222/1000 | Loss: 0.00001888
Iteration 223/1000 | Loss: 0.00001888
Iteration 224/1000 | Loss: 0.00001888
Iteration 225/1000 | Loss: 0.00001887
Iteration 226/1000 | Loss: 0.00001887
Iteration 227/1000 | Loss: 0.00001887
Iteration 228/1000 | Loss: 0.00001887
Iteration 229/1000 | Loss: 0.00001887
Iteration 230/1000 | Loss: 0.00001887
Iteration 231/1000 | Loss: 0.00001887
Iteration 232/1000 | Loss: 0.00001887
Iteration 233/1000 | Loss: 0.00001887
Iteration 234/1000 | Loss: 0.00001887
Iteration 235/1000 | Loss: 0.00001887
Iteration 236/1000 | Loss: 0.00001887
Iteration 237/1000 | Loss: 0.00001887
Iteration 238/1000 | Loss: 0.00001886
Iteration 239/1000 | Loss: 0.00001886
Iteration 240/1000 | Loss: 0.00001886
Iteration 241/1000 | Loss: 0.00001886
Iteration 242/1000 | Loss: 0.00001886
Iteration 243/1000 | Loss: 0.00001886
Iteration 244/1000 | Loss: 0.00001886
Iteration 245/1000 | Loss: 0.00001886
Iteration 246/1000 | Loss: 0.00001886
Iteration 247/1000 | Loss: 0.00001886
Iteration 248/1000 | Loss: 0.00001886
Iteration 249/1000 | Loss: 0.00001886
Iteration 250/1000 | Loss: 0.00001886
Iteration 251/1000 | Loss: 0.00001886
Iteration 252/1000 | Loss: 0.00001886
Iteration 253/1000 | Loss: 0.00001886
Iteration 254/1000 | Loss: 0.00001886
Iteration 255/1000 | Loss: 0.00001886
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 255. Stopping optimization.
Last 5 losses: [1.8864568119170144e-05, 1.8864568119170144e-05, 1.8864568119170144e-05, 1.8864568119170144e-05, 1.8864568119170144e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8864568119170144e-05

Optimization complete. Final v2v error: 3.7373998165130615 mm

Highest mean error: 4.8765869140625 mm for frame 108

Lowest mean error: 3.563511848449707 mm for frame 130

Saving results

Total time: 197.98410201072693
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1067/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1067.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1067
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00661221
Iteration 2/25 | Loss: 0.00162994
Iteration 3/25 | Loss: 0.00146520
Iteration 4/25 | Loss: 0.00145065
Iteration 5/25 | Loss: 0.00144872
Iteration 6/25 | Loss: 0.00144872
Iteration 7/25 | Loss: 0.00144872
Iteration 8/25 | Loss: 0.00144872
Iteration 9/25 | Loss: 0.00144872
Iteration 10/25 | Loss: 0.00144872
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.001448724651709199, 0.001448724651709199, 0.001448724651709199, 0.001448724651709199, 0.001448724651709199]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001448724651709199

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.59371376
Iteration 2/25 | Loss: 0.00182590
Iteration 3/25 | Loss: 0.00182587
Iteration 4/25 | Loss: 0.00182587
Iteration 5/25 | Loss: 0.00182587
Iteration 6/25 | Loss: 0.00182587
Iteration 7/25 | Loss: 0.00182587
Iteration 8/25 | Loss: 0.00182587
Iteration 9/25 | Loss: 0.00182587
Iteration 10/25 | Loss: 0.00182587
Iteration 11/25 | Loss: 0.00182587
Iteration 12/25 | Loss: 0.00182587
Iteration 13/25 | Loss: 0.00182587
Iteration 14/25 | Loss: 0.00182587
Iteration 15/25 | Loss: 0.00182587
Iteration 16/25 | Loss: 0.00182587
Iteration 17/25 | Loss: 0.00182587
Iteration 18/25 | Loss: 0.00182587
Iteration 19/25 | Loss: 0.00182587
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0018258655909448862, 0.0018258655909448862, 0.0018258655909448862, 0.0018258655909448862, 0.0018258655909448862]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018258655909448862

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00182587
Iteration 2/1000 | Loss: 0.00003286
Iteration 3/1000 | Loss: 0.00002478
Iteration 4/1000 | Loss: 0.00002256
Iteration 5/1000 | Loss: 0.00002165
Iteration 6/1000 | Loss: 0.00002094
Iteration 7/1000 | Loss: 0.00002054
Iteration 8/1000 | Loss: 0.00002014
Iteration 9/1000 | Loss: 0.00001965
Iteration 10/1000 | Loss: 0.00001927
Iteration 11/1000 | Loss: 0.00001901
Iteration 12/1000 | Loss: 0.00001897
Iteration 13/1000 | Loss: 0.00001880
Iteration 14/1000 | Loss: 0.00001873
Iteration 15/1000 | Loss: 0.00001871
Iteration 16/1000 | Loss: 0.00001863
Iteration 17/1000 | Loss: 0.00001863
Iteration 18/1000 | Loss: 0.00001855
Iteration 19/1000 | Loss: 0.00001850
Iteration 20/1000 | Loss: 0.00001839
Iteration 21/1000 | Loss: 0.00001838
Iteration 22/1000 | Loss: 0.00001837
Iteration 23/1000 | Loss: 0.00001836
Iteration 24/1000 | Loss: 0.00001836
Iteration 25/1000 | Loss: 0.00001835
Iteration 26/1000 | Loss: 0.00001835
Iteration 27/1000 | Loss: 0.00001828
Iteration 28/1000 | Loss: 0.00001825
Iteration 29/1000 | Loss: 0.00001824
Iteration 30/1000 | Loss: 0.00001823
Iteration 31/1000 | Loss: 0.00001823
Iteration 32/1000 | Loss: 0.00001823
Iteration 33/1000 | Loss: 0.00001823
Iteration 34/1000 | Loss: 0.00001822
Iteration 35/1000 | Loss: 0.00001822
Iteration 36/1000 | Loss: 0.00001818
Iteration 37/1000 | Loss: 0.00001818
Iteration 38/1000 | Loss: 0.00001816
Iteration 39/1000 | Loss: 0.00001815
Iteration 40/1000 | Loss: 0.00001815
Iteration 41/1000 | Loss: 0.00001814
Iteration 42/1000 | Loss: 0.00001814
Iteration 43/1000 | Loss: 0.00001813
Iteration 44/1000 | Loss: 0.00001813
Iteration 45/1000 | Loss: 0.00001812
Iteration 46/1000 | Loss: 0.00001812
Iteration 47/1000 | Loss: 0.00001812
Iteration 48/1000 | Loss: 0.00001812
Iteration 49/1000 | Loss: 0.00001812
Iteration 50/1000 | Loss: 0.00001806
Iteration 51/1000 | Loss: 0.00001805
Iteration 52/1000 | Loss: 0.00001803
Iteration 53/1000 | Loss: 0.00001803
Iteration 54/1000 | Loss: 0.00001803
Iteration 55/1000 | Loss: 0.00001802
Iteration 56/1000 | Loss: 0.00001801
Iteration 57/1000 | Loss: 0.00001801
Iteration 58/1000 | Loss: 0.00001801
Iteration 59/1000 | Loss: 0.00001798
Iteration 60/1000 | Loss: 0.00001798
Iteration 61/1000 | Loss: 0.00001798
Iteration 62/1000 | Loss: 0.00001798
Iteration 63/1000 | Loss: 0.00001797
Iteration 64/1000 | Loss: 0.00001797
Iteration 65/1000 | Loss: 0.00001797
Iteration 66/1000 | Loss: 0.00001795
Iteration 67/1000 | Loss: 0.00001795
Iteration 68/1000 | Loss: 0.00001794
Iteration 69/1000 | Loss: 0.00001794
Iteration 70/1000 | Loss: 0.00001793
Iteration 71/1000 | Loss: 0.00001793
Iteration 72/1000 | Loss: 0.00001793
Iteration 73/1000 | Loss: 0.00001793
Iteration 74/1000 | Loss: 0.00001793
Iteration 75/1000 | Loss: 0.00001793
Iteration 76/1000 | Loss: 0.00001792
Iteration 77/1000 | Loss: 0.00001792
Iteration 78/1000 | Loss: 0.00001792
Iteration 79/1000 | Loss: 0.00001791
Iteration 80/1000 | Loss: 0.00001791
Iteration 81/1000 | Loss: 0.00001791
Iteration 82/1000 | Loss: 0.00001790
Iteration 83/1000 | Loss: 0.00001790
Iteration 84/1000 | Loss: 0.00001790
Iteration 85/1000 | Loss: 0.00001790
Iteration 86/1000 | Loss: 0.00001789
Iteration 87/1000 | Loss: 0.00001789
Iteration 88/1000 | Loss: 0.00001789
Iteration 89/1000 | Loss: 0.00001789
Iteration 90/1000 | Loss: 0.00001788
Iteration 91/1000 | Loss: 0.00001787
Iteration 92/1000 | Loss: 0.00001787
Iteration 93/1000 | Loss: 0.00001787
Iteration 94/1000 | Loss: 0.00001787
Iteration 95/1000 | Loss: 0.00001787
Iteration 96/1000 | Loss: 0.00001787
Iteration 97/1000 | Loss: 0.00001786
Iteration 98/1000 | Loss: 0.00001786
Iteration 99/1000 | Loss: 0.00001786
Iteration 100/1000 | Loss: 0.00001786
Iteration 101/1000 | Loss: 0.00001786
Iteration 102/1000 | Loss: 0.00001786
Iteration 103/1000 | Loss: 0.00001786
Iteration 104/1000 | Loss: 0.00001786
Iteration 105/1000 | Loss: 0.00001785
Iteration 106/1000 | Loss: 0.00001785
Iteration 107/1000 | Loss: 0.00001785
Iteration 108/1000 | Loss: 0.00001784
Iteration 109/1000 | Loss: 0.00001784
Iteration 110/1000 | Loss: 0.00001784
Iteration 111/1000 | Loss: 0.00001784
Iteration 112/1000 | Loss: 0.00001784
Iteration 113/1000 | Loss: 0.00001783
Iteration 114/1000 | Loss: 0.00001783
Iteration 115/1000 | Loss: 0.00001783
Iteration 116/1000 | Loss: 0.00001783
Iteration 117/1000 | Loss: 0.00001783
Iteration 118/1000 | Loss: 0.00001783
Iteration 119/1000 | Loss: 0.00001783
Iteration 120/1000 | Loss: 0.00001783
Iteration 121/1000 | Loss: 0.00001783
Iteration 122/1000 | Loss: 0.00001783
Iteration 123/1000 | Loss: 0.00001783
Iteration 124/1000 | Loss: 0.00001783
Iteration 125/1000 | Loss: 0.00001783
Iteration 126/1000 | Loss: 0.00001783
Iteration 127/1000 | Loss: 0.00001783
Iteration 128/1000 | Loss: 0.00001783
Iteration 129/1000 | Loss: 0.00001783
Iteration 130/1000 | Loss: 0.00001783
Iteration 131/1000 | Loss: 0.00001783
Iteration 132/1000 | Loss: 0.00001783
Iteration 133/1000 | Loss: 0.00001783
Iteration 134/1000 | Loss: 0.00001783
Iteration 135/1000 | Loss: 0.00001783
Iteration 136/1000 | Loss: 0.00001783
Iteration 137/1000 | Loss: 0.00001783
Iteration 138/1000 | Loss: 0.00001783
Iteration 139/1000 | Loss: 0.00001783
Iteration 140/1000 | Loss: 0.00001783
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [1.7825757822720334e-05, 1.7825757822720334e-05, 1.7825757822720334e-05, 1.7825757822720334e-05, 1.7825757822720334e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7825757822720334e-05

Optimization complete. Final v2v error: 3.495669364929199 mm

Highest mean error: 4.43743371963501 mm for frame 177

Lowest mean error: 2.9572579860687256 mm for frame 62

Saving results

Total time: 42.46828365325928
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1057
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00464458
Iteration 2/25 | Loss: 0.00163372
Iteration 3/25 | Loss: 0.00143241
Iteration 4/25 | Loss: 0.00140520
Iteration 5/25 | Loss: 0.00139672
Iteration 6/25 | Loss: 0.00139486
Iteration 7/25 | Loss: 0.00139456
Iteration 8/25 | Loss: 0.00139456
Iteration 9/25 | Loss: 0.00139456
Iteration 10/25 | Loss: 0.00139456
Iteration 11/25 | Loss: 0.00139455
Iteration 12/25 | Loss: 0.00139456
Iteration 13/25 | Loss: 0.00139455
Iteration 14/25 | Loss: 0.00139455
Iteration 15/25 | Loss: 0.00139455
Iteration 16/25 | Loss: 0.00139456
Iteration 17/25 | Loss: 0.00139456
Iteration 18/25 | Loss: 0.00139455
Iteration 19/25 | Loss: 0.00139455
Iteration 20/25 | Loss: 0.00139455
Iteration 21/25 | Loss: 0.00139455
Iteration 22/25 | Loss: 0.00139455
Iteration 23/25 | Loss: 0.00139455
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0013945549726486206, 0.0013945549726486206, 0.0013945549726486206, 0.0013945549726486206, 0.0013945549726486206]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013945549726486206

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.13582599
Iteration 2/25 | Loss: 0.00210410
Iteration 3/25 | Loss: 0.00210408
Iteration 4/25 | Loss: 0.00210408
Iteration 5/25 | Loss: 0.00210408
Iteration 6/25 | Loss: 0.00210408
Iteration 7/25 | Loss: 0.00210408
Iteration 8/25 | Loss: 0.00210408
Iteration 9/25 | Loss: 0.00210408
Iteration 10/25 | Loss: 0.00210408
Iteration 11/25 | Loss: 0.00210408
Iteration 12/25 | Loss: 0.00210408
Iteration 13/25 | Loss: 0.00210408
Iteration 14/25 | Loss: 0.00210408
Iteration 15/25 | Loss: 0.00210408
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0021040758583694696, 0.0021040758583694696, 0.0021040758583694696, 0.0021040758583694696, 0.0021040758583694696]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0021040758583694696

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00210408
Iteration 2/1000 | Loss: 0.00006775
Iteration 3/1000 | Loss: 0.00004220
Iteration 4/1000 | Loss: 0.00003421
Iteration 5/1000 | Loss: 0.00003156
Iteration 6/1000 | Loss: 0.00003025
Iteration 7/1000 | Loss: 0.00002897
Iteration 8/1000 | Loss: 0.00002817
Iteration 9/1000 | Loss: 0.00002748
Iteration 10/1000 | Loss: 0.00002692
Iteration 11/1000 | Loss: 0.00002650
Iteration 12/1000 | Loss: 0.00002622
Iteration 13/1000 | Loss: 0.00002596
Iteration 14/1000 | Loss: 0.00002577
Iteration 15/1000 | Loss: 0.00002572
Iteration 16/1000 | Loss: 0.00002561
Iteration 17/1000 | Loss: 0.00002546
Iteration 18/1000 | Loss: 0.00002537
Iteration 19/1000 | Loss: 0.00002519
Iteration 20/1000 | Loss: 0.00002517
Iteration 21/1000 | Loss: 0.00002512
Iteration 22/1000 | Loss: 0.00002508
Iteration 23/1000 | Loss: 0.00002507
Iteration 24/1000 | Loss: 0.00002507
Iteration 25/1000 | Loss: 0.00002502
Iteration 26/1000 | Loss: 0.00002499
Iteration 27/1000 | Loss: 0.00002495
Iteration 28/1000 | Loss: 0.00002495
Iteration 29/1000 | Loss: 0.00002494
Iteration 30/1000 | Loss: 0.00002493
Iteration 31/1000 | Loss: 0.00002492
Iteration 32/1000 | Loss: 0.00002487
Iteration 33/1000 | Loss: 0.00002486
Iteration 34/1000 | Loss: 0.00002486
Iteration 35/1000 | Loss: 0.00002484
Iteration 36/1000 | Loss: 0.00002483
Iteration 37/1000 | Loss: 0.00002482
Iteration 38/1000 | Loss: 0.00002482
Iteration 39/1000 | Loss: 0.00002482
Iteration 40/1000 | Loss: 0.00002482
Iteration 41/1000 | Loss: 0.00002482
Iteration 42/1000 | Loss: 0.00002482
Iteration 43/1000 | Loss: 0.00002482
Iteration 44/1000 | Loss: 0.00002482
Iteration 45/1000 | Loss: 0.00002482
Iteration 46/1000 | Loss: 0.00002482
Iteration 47/1000 | Loss: 0.00002481
Iteration 48/1000 | Loss: 0.00002481
Iteration 49/1000 | Loss: 0.00002481
Iteration 50/1000 | Loss: 0.00002480
Iteration 51/1000 | Loss: 0.00002479
Iteration 52/1000 | Loss: 0.00002479
Iteration 53/1000 | Loss: 0.00002479
Iteration 54/1000 | Loss: 0.00002479
Iteration 55/1000 | Loss: 0.00002479
Iteration 56/1000 | Loss: 0.00002479
Iteration 57/1000 | Loss: 0.00002479
Iteration 58/1000 | Loss: 0.00002479
Iteration 59/1000 | Loss: 0.00002478
Iteration 60/1000 | Loss: 0.00002477
Iteration 61/1000 | Loss: 0.00002476
Iteration 62/1000 | Loss: 0.00002476
Iteration 63/1000 | Loss: 0.00002476
Iteration 64/1000 | Loss: 0.00002476
Iteration 65/1000 | Loss: 0.00002475
Iteration 66/1000 | Loss: 0.00002475
Iteration 67/1000 | Loss: 0.00002475
Iteration 68/1000 | Loss: 0.00002475
Iteration 69/1000 | Loss: 0.00002475
Iteration 70/1000 | Loss: 0.00002475
Iteration 71/1000 | Loss: 0.00002475
Iteration 72/1000 | Loss: 0.00002475
Iteration 73/1000 | Loss: 0.00002474
Iteration 74/1000 | Loss: 0.00002474
Iteration 75/1000 | Loss: 0.00002474
Iteration 76/1000 | Loss: 0.00002474
Iteration 77/1000 | Loss: 0.00002474
Iteration 78/1000 | Loss: 0.00002473
Iteration 79/1000 | Loss: 0.00002473
Iteration 80/1000 | Loss: 0.00002473
Iteration 81/1000 | Loss: 0.00002473
Iteration 82/1000 | Loss: 0.00002473
Iteration 83/1000 | Loss: 0.00002473
Iteration 84/1000 | Loss: 0.00002473
Iteration 85/1000 | Loss: 0.00002473
Iteration 86/1000 | Loss: 0.00002473
Iteration 87/1000 | Loss: 0.00002473
Iteration 88/1000 | Loss: 0.00002472
Iteration 89/1000 | Loss: 0.00002472
Iteration 90/1000 | Loss: 0.00002472
Iteration 91/1000 | Loss: 0.00002471
Iteration 92/1000 | Loss: 0.00002471
Iteration 93/1000 | Loss: 0.00002470
Iteration 94/1000 | Loss: 0.00002470
Iteration 95/1000 | Loss: 0.00002470
Iteration 96/1000 | Loss: 0.00002470
Iteration 97/1000 | Loss: 0.00002470
Iteration 98/1000 | Loss: 0.00002469
Iteration 99/1000 | Loss: 0.00002469
Iteration 100/1000 | Loss: 0.00002469
Iteration 101/1000 | Loss: 0.00002469
Iteration 102/1000 | Loss: 0.00002469
Iteration 103/1000 | Loss: 0.00002469
Iteration 104/1000 | Loss: 0.00002468
Iteration 105/1000 | Loss: 0.00002468
Iteration 106/1000 | Loss: 0.00002468
Iteration 107/1000 | Loss: 0.00002468
Iteration 108/1000 | Loss: 0.00002468
Iteration 109/1000 | Loss: 0.00002468
Iteration 110/1000 | Loss: 0.00002467
Iteration 111/1000 | Loss: 0.00002467
Iteration 112/1000 | Loss: 0.00002467
Iteration 113/1000 | Loss: 0.00002467
Iteration 114/1000 | Loss: 0.00002466
Iteration 115/1000 | Loss: 0.00002466
Iteration 116/1000 | Loss: 0.00002466
Iteration 117/1000 | Loss: 0.00002466
Iteration 118/1000 | Loss: 0.00002466
Iteration 119/1000 | Loss: 0.00002466
Iteration 120/1000 | Loss: 0.00002466
Iteration 121/1000 | Loss: 0.00002466
Iteration 122/1000 | Loss: 0.00002466
Iteration 123/1000 | Loss: 0.00002465
Iteration 124/1000 | Loss: 0.00002465
Iteration 125/1000 | Loss: 0.00002465
Iteration 126/1000 | Loss: 0.00002465
Iteration 127/1000 | Loss: 0.00002465
Iteration 128/1000 | Loss: 0.00002465
Iteration 129/1000 | Loss: 0.00002465
Iteration 130/1000 | Loss: 0.00002465
Iteration 131/1000 | Loss: 0.00002464
Iteration 132/1000 | Loss: 0.00002464
Iteration 133/1000 | Loss: 0.00002464
Iteration 134/1000 | Loss: 0.00002464
Iteration 135/1000 | Loss: 0.00002464
Iteration 136/1000 | Loss: 0.00002464
Iteration 137/1000 | Loss: 0.00002464
Iteration 138/1000 | Loss: 0.00002464
Iteration 139/1000 | Loss: 0.00002464
Iteration 140/1000 | Loss: 0.00002464
Iteration 141/1000 | Loss: 0.00002464
Iteration 142/1000 | Loss: 0.00002464
Iteration 143/1000 | Loss: 0.00002464
Iteration 144/1000 | Loss: 0.00002464
Iteration 145/1000 | Loss: 0.00002464
Iteration 146/1000 | Loss: 0.00002464
Iteration 147/1000 | Loss: 0.00002463
Iteration 148/1000 | Loss: 0.00002463
Iteration 149/1000 | Loss: 0.00002463
Iteration 150/1000 | Loss: 0.00002463
Iteration 151/1000 | Loss: 0.00002463
Iteration 152/1000 | Loss: 0.00002463
Iteration 153/1000 | Loss: 0.00002463
Iteration 154/1000 | Loss: 0.00002463
Iteration 155/1000 | Loss: 0.00002463
Iteration 156/1000 | Loss: 0.00002463
Iteration 157/1000 | Loss: 0.00002463
Iteration 158/1000 | Loss: 0.00002463
Iteration 159/1000 | Loss: 0.00002463
Iteration 160/1000 | Loss: 0.00002463
Iteration 161/1000 | Loss: 0.00002463
Iteration 162/1000 | Loss: 0.00002463
Iteration 163/1000 | Loss: 0.00002463
Iteration 164/1000 | Loss: 0.00002463
Iteration 165/1000 | Loss: 0.00002463
Iteration 166/1000 | Loss: 0.00002462
Iteration 167/1000 | Loss: 0.00002462
Iteration 168/1000 | Loss: 0.00002462
Iteration 169/1000 | Loss: 0.00002462
Iteration 170/1000 | Loss: 0.00002462
Iteration 171/1000 | Loss: 0.00002462
Iteration 172/1000 | Loss: 0.00002462
Iteration 173/1000 | Loss: 0.00002462
Iteration 174/1000 | Loss: 0.00002462
Iteration 175/1000 | Loss: 0.00002462
Iteration 176/1000 | Loss: 0.00002462
Iteration 177/1000 | Loss: 0.00002462
Iteration 178/1000 | Loss: 0.00002462
Iteration 179/1000 | Loss: 0.00002462
Iteration 180/1000 | Loss: 0.00002462
Iteration 181/1000 | Loss: 0.00002462
Iteration 182/1000 | Loss: 0.00002462
Iteration 183/1000 | Loss: 0.00002462
Iteration 184/1000 | Loss: 0.00002462
Iteration 185/1000 | Loss: 0.00002462
Iteration 186/1000 | Loss: 0.00002462
Iteration 187/1000 | Loss: 0.00002462
Iteration 188/1000 | Loss: 0.00002462
Iteration 189/1000 | Loss: 0.00002462
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 189. Stopping optimization.
Last 5 losses: [2.461571966705378e-05, 2.461571966705378e-05, 2.461571966705378e-05, 2.461571966705378e-05, 2.461571966705378e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.461571966705378e-05

Optimization complete. Final v2v error: 4.058204174041748 mm

Highest mean error: 5.701463222503662 mm for frame 74

Lowest mean error: 3.251591444015503 mm for frame 35

Saving results

Total time: 48.51584458351135
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1025
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00854724
Iteration 2/25 | Loss: 0.00150735
Iteration 3/25 | Loss: 0.00137782
Iteration 4/25 | Loss: 0.00136527
Iteration 5/25 | Loss: 0.00136222
Iteration 6/25 | Loss: 0.00136165
Iteration 7/25 | Loss: 0.00136165
Iteration 8/25 | Loss: 0.00136165
Iteration 9/25 | Loss: 0.00136165
Iteration 10/25 | Loss: 0.00136165
Iteration 11/25 | Loss: 0.00136165
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013616526266559958, 0.0013616526266559958, 0.0013616526266559958, 0.0013616526266559958, 0.0013616526266559958]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013616526266559958

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35235679
Iteration 2/25 | Loss: 0.00175495
Iteration 3/25 | Loss: 0.00175495
Iteration 4/25 | Loss: 0.00175495
Iteration 5/25 | Loss: 0.00175495
Iteration 6/25 | Loss: 0.00175495
Iteration 7/25 | Loss: 0.00175495
Iteration 8/25 | Loss: 0.00175495
Iteration 9/25 | Loss: 0.00175495
Iteration 10/25 | Loss: 0.00175495
Iteration 11/25 | Loss: 0.00175495
Iteration 12/25 | Loss: 0.00175495
Iteration 13/25 | Loss: 0.00175495
Iteration 14/25 | Loss: 0.00175495
Iteration 15/25 | Loss: 0.00175495
Iteration 16/25 | Loss: 0.00175495
Iteration 17/25 | Loss: 0.00175495
Iteration 18/25 | Loss: 0.00175495
Iteration 19/25 | Loss: 0.00175495
Iteration 20/25 | Loss: 0.00175495
Iteration 21/25 | Loss: 0.00175495
Iteration 22/25 | Loss: 0.00175495
Iteration 23/25 | Loss: 0.00175495
Iteration 24/25 | Loss: 0.00175495
Iteration 25/25 | Loss: 0.00175495

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00175495
Iteration 2/1000 | Loss: 0.00003393
Iteration 3/1000 | Loss: 0.00002471
Iteration 4/1000 | Loss: 0.00002137
Iteration 5/1000 | Loss: 0.00001998
Iteration 6/1000 | Loss: 0.00001924
Iteration 7/1000 | Loss: 0.00001862
Iteration 8/1000 | Loss: 0.00001804
Iteration 9/1000 | Loss: 0.00001762
Iteration 10/1000 | Loss: 0.00001713
Iteration 11/1000 | Loss: 0.00001679
Iteration 12/1000 | Loss: 0.00001653
Iteration 13/1000 | Loss: 0.00001632
Iteration 14/1000 | Loss: 0.00001612
Iteration 15/1000 | Loss: 0.00001595
Iteration 16/1000 | Loss: 0.00001586
Iteration 17/1000 | Loss: 0.00001583
Iteration 18/1000 | Loss: 0.00001580
Iteration 19/1000 | Loss: 0.00001578
Iteration 20/1000 | Loss: 0.00001575
Iteration 21/1000 | Loss: 0.00001567
Iteration 22/1000 | Loss: 0.00001567
Iteration 23/1000 | Loss: 0.00001564
Iteration 24/1000 | Loss: 0.00001563
Iteration 25/1000 | Loss: 0.00001563
Iteration 26/1000 | Loss: 0.00001562
Iteration 27/1000 | Loss: 0.00001558
Iteration 28/1000 | Loss: 0.00001558
Iteration 29/1000 | Loss: 0.00001558
Iteration 30/1000 | Loss: 0.00001557
Iteration 31/1000 | Loss: 0.00001557
Iteration 32/1000 | Loss: 0.00001556
Iteration 33/1000 | Loss: 0.00001556
Iteration 34/1000 | Loss: 0.00001556
Iteration 35/1000 | Loss: 0.00001554
Iteration 36/1000 | Loss: 0.00001554
Iteration 37/1000 | Loss: 0.00001554
Iteration 38/1000 | Loss: 0.00001554
Iteration 39/1000 | Loss: 0.00001554
Iteration 40/1000 | Loss: 0.00001554
Iteration 41/1000 | Loss: 0.00001554
Iteration 42/1000 | Loss: 0.00001554
Iteration 43/1000 | Loss: 0.00001554
Iteration 44/1000 | Loss: 0.00001554
Iteration 45/1000 | Loss: 0.00001554
Iteration 46/1000 | Loss: 0.00001553
Iteration 47/1000 | Loss: 0.00001553
Iteration 48/1000 | Loss: 0.00001553
Iteration 49/1000 | Loss: 0.00001553
Iteration 50/1000 | Loss: 0.00001553
Iteration 51/1000 | Loss: 0.00001553
Iteration 52/1000 | Loss: 0.00001553
Iteration 53/1000 | Loss: 0.00001553
Iteration 54/1000 | Loss: 0.00001553
Iteration 55/1000 | Loss: 0.00001553
Iteration 56/1000 | Loss: 0.00001553
Iteration 57/1000 | Loss: 0.00001552
Iteration 58/1000 | Loss: 0.00001552
Iteration 59/1000 | Loss: 0.00001552
Iteration 60/1000 | Loss: 0.00001552
Iteration 61/1000 | Loss: 0.00001552
Iteration 62/1000 | Loss: 0.00001552
Iteration 63/1000 | Loss: 0.00001552
Iteration 64/1000 | Loss: 0.00001551
Iteration 65/1000 | Loss: 0.00001551
Iteration 66/1000 | Loss: 0.00001550
Iteration 67/1000 | Loss: 0.00001550
Iteration 68/1000 | Loss: 0.00001550
Iteration 69/1000 | Loss: 0.00001550
Iteration 70/1000 | Loss: 0.00001550
Iteration 71/1000 | Loss: 0.00001550
Iteration 72/1000 | Loss: 0.00001550
Iteration 73/1000 | Loss: 0.00001549
Iteration 74/1000 | Loss: 0.00001549
Iteration 75/1000 | Loss: 0.00001549
Iteration 76/1000 | Loss: 0.00001549
Iteration 77/1000 | Loss: 0.00001549
Iteration 78/1000 | Loss: 0.00001549
Iteration 79/1000 | Loss: 0.00001548
Iteration 80/1000 | Loss: 0.00001548
Iteration 81/1000 | Loss: 0.00001548
Iteration 82/1000 | Loss: 0.00001548
Iteration 83/1000 | Loss: 0.00001548
Iteration 84/1000 | Loss: 0.00001548
Iteration 85/1000 | Loss: 0.00001548
Iteration 86/1000 | Loss: 0.00001548
Iteration 87/1000 | Loss: 0.00001548
Iteration 88/1000 | Loss: 0.00001548
Iteration 89/1000 | Loss: 0.00001548
Iteration 90/1000 | Loss: 0.00001548
Iteration 91/1000 | Loss: 0.00001547
Iteration 92/1000 | Loss: 0.00001547
Iteration 93/1000 | Loss: 0.00001546
Iteration 94/1000 | Loss: 0.00001546
Iteration 95/1000 | Loss: 0.00001546
Iteration 96/1000 | Loss: 0.00001546
Iteration 97/1000 | Loss: 0.00001546
Iteration 98/1000 | Loss: 0.00001546
Iteration 99/1000 | Loss: 0.00001546
Iteration 100/1000 | Loss: 0.00001546
Iteration 101/1000 | Loss: 0.00001546
Iteration 102/1000 | Loss: 0.00001545
Iteration 103/1000 | Loss: 0.00001545
Iteration 104/1000 | Loss: 0.00001545
Iteration 105/1000 | Loss: 0.00001545
Iteration 106/1000 | Loss: 0.00001545
Iteration 107/1000 | Loss: 0.00001544
Iteration 108/1000 | Loss: 0.00001544
Iteration 109/1000 | Loss: 0.00001544
Iteration 110/1000 | Loss: 0.00001544
Iteration 111/1000 | Loss: 0.00001544
Iteration 112/1000 | Loss: 0.00001543
Iteration 113/1000 | Loss: 0.00001543
Iteration 114/1000 | Loss: 0.00001543
Iteration 115/1000 | Loss: 0.00001543
Iteration 116/1000 | Loss: 0.00001543
Iteration 117/1000 | Loss: 0.00001543
Iteration 118/1000 | Loss: 0.00001543
Iteration 119/1000 | Loss: 0.00001543
Iteration 120/1000 | Loss: 0.00001542
Iteration 121/1000 | Loss: 0.00001542
Iteration 122/1000 | Loss: 0.00001542
Iteration 123/1000 | Loss: 0.00001542
Iteration 124/1000 | Loss: 0.00001542
Iteration 125/1000 | Loss: 0.00001542
Iteration 126/1000 | Loss: 0.00001542
Iteration 127/1000 | Loss: 0.00001542
Iteration 128/1000 | Loss: 0.00001541
Iteration 129/1000 | Loss: 0.00001541
Iteration 130/1000 | Loss: 0.00001541
Iteration 131/1000 | Loss: 0.00001541
Iteration 132/1000 | Loss: 0.00001541
Iteration 133/1000 | Loss: 0.00001541
Iteration 134/1000 | Loss: 0.00001541
Iteration 135/1000 | Loss: 0.00001541
Iteration 136/1000 | Loss: 0.00001541
Iteration 137/1000 | Loss: 0.00001541
Iteration 138/1000 | Loss: 0.00001541
Iteration 139/1000 | Loss: 0.00001541
Iteration 140/1000 | Loss: 0.00001540
Iteration 141/1000 | Loss: 0.00001540
Iteration 142/1000 | Loss: 0.00001540
Iteration 143/1000 | Loss: 0.00001540
Iteration 144/1000 | Loss: 0.00001540
Iteration 145/1000 | Loss: 0.00001540
Iteration 146/1000 | Loss: 0.00001540
Iteration 147/1000 | Loss: 0.00001540
Iteration 148/1000 | Loss: 0.00001540
Iteration 149/1000 | Loss: 0.00001540
Iteration 150/1000 | Loss: 0.00001539
Iteration 151/1000 | Loss: 0.00001539
Iteration 152/1000 | Loss: 0.00001539
Iteration 153/1000 | Loss: 0.00001539
Iteration 154/1000 | Loss: 0.00001539
Iteration 155/1000 | Loss: 0.00001539
Iteration 156/1000 | Loss: 0.00001539
Iteration 157/1000 | Loss: 0.00001539
Iteration 158/1000 | Loss: 0.00001538
Iteration 159/1000 | Loss: 0.00001538
Iteration 160/1000 | Loss: 0.00001538
Iteration 161/1000 | Loss: 0.00001538
Iteration 162/1000 | Loss: 0.00001538
Iteration 163/1000 | Loss: 0.00001538
Iteration 164/1000 | Loss: 0.00001538
Iteration 165/1000 | Loss: 0.00001538
Iteration 166/1000 | Loss: 0.00001538
Iteration 167/1000 | Loss: 0.00001538
Iteration 168/1000 | Loss: 0.00001538
Iteration 169/1000 | Loss: 0.00001538
Iteration 170/1000 | Loss: 0.00001538
Iteration 171/1000 | Loss: 0.00001538
Iteration 172/1000 | Loss: 0.00001538
Iteration 173/1000 | Loss: 0.00001538
Iteration 174/1000 | Loss: 0.00001538
Iteration 175/1000 | Loss: 0.00001538
Iteration 176/1000 | Loss: 0.00001537
Iteration 177/1000 | Loss: 0.00001537
Iteration 178/1000 | Loss: 0.00001537
Iteration 179/1000 | Loss: 0.00001537
Iteration 180/1000 | Loss: 0.00001537
Iteration 181/1000 | Loss: 0.00001537
Iteration 182/1000 | Loss: 0.00001537
Iteration 183/1000 | Loss: 0.00001537
Iteration 184/1000 | Loss: 0.00001537
Iteration 185/1000 | Loss: 0.00001537
Iteration 186/1000 | Loss: 0.00001537
Iteration 187/1000 | Loss: 0.00001537
Iteration 188/1000 | Loss: 0.00001537
Iteration 189/1000 | Loss: 0.00001537
Iteration 190/1000 | Loss: 0.00001537
Iteration 191/1000 | Loss: 0.00001537
Iteration 192/1000 | Loss: 0.00001537
Iteration 193/1000 | Loss: 0.00001536
Iteration 194/1000 | Loss: 0.00001536
Iteration 195/1000 | Loss: 0.00001536
Iteration 196/1000 | Loss: 0.00001536
Iteration 197/1000 | Loss: 0.00001536
Iteration 198/1000 | Loss: 0.00001536
Iteration 199/1000 | Loss: 0.00001536
Iteration 200/1000 | Loss: 0.00001536
Iteration 201/1000 | Loss: 0.00001536
Iteration 202/1000 | Loss: 0.00001536
Iteration 203/1000 | Loss: 0.00001536
Iteration 204/1000 | Loss: 0.00001536
Iteration 205/1000 | Loss: 0.00001535
Iteration 206/1000 | Loss: 0.00001535
Iteration 207/1000 | Loss: 0.00001535
Iteration 208/1000 | Loss: 0.00001535
Iteration 209/1000 | Loss: 0.00001535
Iteration 210/1000 | Loss: 0.00001535
Iteration 211/1000 | Loss: 0.00001535
Iteration 212/1000 | Loss: 0.00001535
Iteration 213/1000 | Loss: 0.00001535
Iteration 214/1000 | Loss: 0.00001535
Iteration 215/1000 | Loss: 0.00001535
Iteration 216/1000 | Loss: 0.00001535
Iteration 217/1000 | Loss: 0.00001535
Iteration 218/1000 | Loss: 0.00001535
Iteration 219/1000 | Loss: 0.00001535
Iteration 220/1000 | Loss: 0.00001535
Iteration 221/1000 | Loss: 0.00001535
Iteration 222/1000 | Loss: 0.00001535
Iteration 223/1000 | Loss: 0.00001535
Iteration 224/1000 | Loss: 0.00001535
Iteration 225/1000 | Loss: 0.00001535
Iteration 226/1000 | Loss: 0.00001535
Iteration 227/1000 | Loss: 0.00001535
Iteration 228/1000 | Loss: 0.00001534
Iteration 229/1000 | Loss: 0.00001534
Iteration 230/1000 | Loss: 0.00001534
Iteration 231/1000 | Loss: 0.00001534
Iteration 232/1000 | Loss: 0.00001534
Iteration 233/1000 | Loss: 0.00001534
Iteration 234/1000 | Loss: 0.00001534
Iteration 235/1000 | Loss: 0.00001534
Iteration 236/1000 | Loss: 0.00001534
Iteration 237/1000 | Loss: 0.00001534
Iteration 238/1000 | Loss: 0.00001534
Iteration 239/1000 | Loss: 0.00001534
Iteration 240/1000 | Loss: 0.00001534
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 240. Stopping optimization.
Last 5 losses: [1.5339093806687742e-05, 1.5339093806687742e-05, 1.5339093806687742e-05, 1.5339093806687742e-05, 1.5339093806687742e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5339093806687742e-05

Optimization complete. Final v2v error: 3.2810800075531006 mm

Highest mean error: 4.579174518585205 mm for frame 56

Lowest mean error: 2.9496591091156006 mm for frame 20

Saving results

Total time: 45.35152196884155
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00413835
Iteration 2/25 | Loss: 0.00140635
Iteration 3/25 | Loss: 0.00133729
Iteration 4/25 | Loss: 0.00132987
Iteration 5/25 | Loss: 0.00132799
Iteration 6/25 | Loss: 0.00132783
Iteration 7/25 | Loss: 0.00132783
Iteration 8/25 | Loss: 0.00132783
Iteration 9/25 | Loss: 0.00132783
Iteration 10/25 | Loss: 0.00132783
Iteration 11/25 | Loss: 0.00132783
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013278275728225708, 0.0013278275728225708, 0.0013278275728225708, 0.0013278275728225708, 0.0013278275728225708]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013278275728225708

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27600563
Iteration 2/25 | Loss: 0.00199791
Iteration 3/25 | Loss: 0.00199791
Iteration 4/25 | Loss: 0.00199791
Iteration 5/25 | Loss: 0.00199791
Iteration 6/25 | Loss: 0.00199791
Iteration 7/25 | Loss: 0.00199791
Iteration 8/25 | Loss: 0.00199791
Iteration 9/25 | Loss: 0.00199791
Iteration 10/25 | Loss: 0.00199791
Iteration 11/25 | Loss: 0.00199791
Iteration 12/25 | Loss: 0.00199791
Iteration 13/25 | Loss: 0.00199791
Iteration 14/25 | Loss: 0.00199791
Iteration 15/25 | Loss: 0.00199791
Iteration 16/25 | Loss: 0.00199791
Iteration 17/25 | Loss: 0.00199791
Iteration 18/25 | Loss: 0.00199791
Iteration 19/25 | Loss: 0.00199791
Iteration 20/25 | Loss: 0.00199791
Iteration 21/25 | Loss: 0.00199791
Iteration 22/25 | Loss: 0.00199791
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0019979053176939487, 0.0019979053176939487, 0.0019979053176939487, 0.0019979053176939487, 0.0019979053176939487]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019979053176939487

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00199791
Iteration 2/1000 | Loss: 0.00002660
Iteration 3/1000 | Loss: 0.00001722
Iteration 4/1000 | Loss: 0.00001471
Iteration 5/1000 | Loss: 0.00001387
Iteration 6/1000 | Loss: 0.00001319
Iteration 7/1000 | Loss: 0.00001258
Iteration 8/1000 | Loss: 0.00001218
Iteration 9/1000 | Loss: 0.00001193
Iteration 10/1000 | Loss: 0.00001162
Iteration 11/1000 | Loss: 0.00001141
Iteration 12/1000 | Loss: 0.00001136
Iteration 13/1000 | Loss: 0.00001121
Iteration 14/1000 | Loss: 0.00001111
Iteration 15/1000 | Loss: 0.00001102
Iteration 16/1000 | Loss: 0.00001101
Iteration 17/1000 | Loss: 0.00001091
Iteration 18/1000 | Loss: 0.00001084
Iteration 19/1000 | Loss: 0.00001080
Iteration 20/1000 | Loss: 0.00001080
Iteration 21/1000 | Loss: 0.00001078
Iteration 22/1000 | Loss: 0.00001073
Iteration 23/1000 | Loss: 0.00001073
Iteration 24/1000 | Loss: 0.00001072
Iteration 25/1000 | Loss: 0.00001071
Iteration 26/1000 | Loss: 0.00001071
Iteration 27/1000 | Loss: 0.00001071
Iteration 28/1000 | Loss: 0.00001071
Iteration 29/1000 | Loss: 0.00001071
Iteration 30/1000 | Loss: 0.00001070
Iteration 31/1000 | Loss: 0.00001069
Iteration 32/1000 | Loss: 0.00001068
Iteration 33/1000 | Loss: 0.00001068
Iteration 34/1000 | Loss: 0.00001067
Iteration 35/1000 | Loss: 0.00001066
Iteration 36/1000 | Loss: 0.00001066
Iteration 37/1000 | Loss: 0.00001065
Iteration 38/1000 | Loss: 0.00001064
Iteration 39/1000 | Loss: 0.00001064
Iteration 40/1000 | Loss: 0.00001063
Iteration 41/1000 | Loss: 0.00001063
Iteration 42/1000 | Loss: 0.00001062
Iteration 43/1000 | Loss: 0.00001062
Iteration 44/1000 | Loss: 0.00001061
Iteration 45/1000 | Loss: 0.00001061
Iteration 46/1000 | Loss: 0.00001060
Iteration 47/1000 | Loss: 0.00001060
Iteration 48/1000 | Loss: 0.00001059
Iteration 49/1000 | Loss: 0.00001059
Iteration 50/1000 | Loss: 0.00001058
Iteration 51/1000 | Loss: 0.00001058
Iteration 52/1000 | Loss: 0.00001057
Iteration 53/1000 | Loss: 0.00001057
Iteration 54/1000 | Loss: 0.00001056
Iteration 55/1000 | Loss: 0.00001056
Iteration 56/1000 | Loss: 0.00001056
Iteration 57/1000 | Loss: 0.00001055
Iteration 58/1000 | Loss: 0.00001055
Iteration 59/1000 | Loss: 0.00001055
Iteration 60/1000 | Loss: 0.00001054
Iteration 61/1000 | Loss: 0.00001054
Iteration 62/1000 | Loss: 0.00001054
Iteration 63/1000 | Loss: 0.00001053
Iteration 64/1000 | Loss: 0.00001053
Iteration 65/1000 | Loss: 0.00001053
Iteration 66/1000 | Loss: 0.00001053
Iteration 67/1000 | Loss: 0.00001053
Iteration 68/1000 | Loss: 0.00001053
Iteration 69/1000 | Loss: 0.00001053
Iteration 70/1000 | Loss: 0.00001053
Iteration 71/1000 | Loss: 0.00001052
Iteration 72/1000 | Loss: 0.00001052
Iteration 73/1000 | Loss: 0.00001051
Iteration 74/1000 | Loss: 0.00001051
Iteration 75/1000 | Loss: 0.00001051
Iteration 76/1000 | Loss: 0.00001050
Iteration 77/1000 | Loss: 0.00001050
Iteration 78/1000 | Loss: 0.00001050
Iteration 79/1000 | Loss: 0.00001050
Iteration 80/1000 | Loss: 0.00001049
Iteration 81/1000 | Loss: 0.00001049
Iteration 82/1000 | Loss: 0.00001049
Iteration 83/1000 | Loss: 0.00001048
Iteration 84/1000 | Loss: 0.00001048
Iteration 85/1000 | Loss: 0.00001048
Iteration 86/1000 | Loss: 0.00001047
Iteration 87/1000 | Loss: 0.00001047
Iteration 88/1000 | Loss: 0.00001047
Iteration 89/1000 | Loss: 0.00001047
Iteration 90/1000 | Loss: 0.00001047
Iteration 91/1000 | Loss: 0.00001047
Iteration 92/1000 | Loss: 0.00001047
Iteration 93/1000 | Loss: 0.00001047
Iteration 94/1000 | Loss: 0.00001047
Iteration 95/1000 | Loss: 0.00001047
Iteration 96/1000 | Loss: 0.00001047
Iteration 97/1000 | Loss: 0.00001046
Iteration 98/1000 | Loss: 0.00001046
Iteration 99/1000 | Loss: 0.00001046
Iteration 100/1000 | Loss: 0.00001046
Iteration 101/1000 | Loss: 0.00001046
Iteration 102/1000 | Loss: 0.00001046
Iteration 103/1000 | Loss: 0.00001046
Iteration 104/1000 | Loss: 0.00001046
Iteration 105/1000 | Loss: 0.00001045
Iteration 106/1000 | Loss: 0.00001045
Iteration 107/1000 | Loss: 0.00001045
Iteration 108/1000 | Loss: 0.00001045
Iteration 109/1000 | Loss: 0.00001044
Iteration 110/1000 | Loss: 0.00001044
Iteration 111/1000 | Loss: 0.00001044
Iteration 112/1000 | Loss: 0.00001044
Iteration 113/1000 | Loss: 0.00001043
Iteration 114/1000 | Loss: 0.00001043
Iteration 115/1000 | Loss: 0.00001043
Iteration 116/1000 | Loss: 0.00001042
Iteration 117/1000 | Loss: 0.00001042
Iteration 118/1000 | Loss: 0.00001041
Iteration 119/1000 | Loss: 0.00001041
Iteration 120/1000 | Loss: 0.00001041
Iteration 121/1000 | Loss: 0.00001040
Iteration 122/1000 | Loss: 0.00001040
Iteration 123/1000 | Loss: 0.00001040
Iteration 124/1000 | Loss: 0.00001039
Iteration 125/1000 | Loss: 0.00001039
Iteration 126/1000 | Loss: 0.00001038
Iteration 127/1000 | Loss: 0.00001038
Iteration 128/1000 | Loss: 0.00001038
Iteration 129/1000 | Loss: 0.00001038
Iteration 130/1000 | Loss: 0.00001036
Iteration 131/1000 | Loss: 0.00001036
Iteration 132/1000 | Loss: 0.00001036
Iteration 133/1000 | Loss: 0.00001036
Iteration 134/1000 | Loss: 0.00001036
Iteration 135/1000 | Loss: 0.00001035
Iteration 136/1000 | Loss: 0.00001035
Iteration 137/1000 | Loss: 0.00001035
Iteration 138/1000 | Loss: 0.00001035
Iteration 139/1000 | Loss: 0.00001035
Iteration 140/1000 | Loss: 0.00001035
Iteration 141/1000 | Loss: 0.00001035
Iteration 142/1000 | Loss: 0.00001035
Iteration 143/1000 | Loss: 0.00001034
Iteration 144/1000 | Loss: 0.00001034
Iteration 145/1000 | Loss: 0.00001034
Iteration 146/1000 | Loss: 0.00001034
Iteration 147/1000 | Loss: 0.00001034
Iteration 148/1000 | Loss: 0.00001034
Iteration 149/1000 | Loss: 0.00001034
Iteration 150/1000 | Loss: 0.00001034
Iteration 151/1000 | Loss: 0.00001033
Iteration 152/1000 | Loss: 0.00001033
Iteration 153/1000 | Loss: 0.00001033
Iteration 154/1000 | Loss: 0.00001033
Iteration 155/1000 | Loss: 0.00001033
Iteration 156/1000 | Loss: 0.00001033
Iteration 157/1000 | Loss: 0.00001032
Iteration 158/1000 | Loss: 0.00001032
Iteration 159/1000 | Loss: 0.00001032
Iteration 160/1000 | Loss: 0.00001032
Iteration 161/1000 | Loss: 0.00001032
Iteration 162/1000 | Loss: 0.00001032
Iteration 163/1000 | Loss: 0.00001031
Iteration 164/1000 | Loss: 0.00001031
Iteration 165/1000 | Loss: 0.00001031
Iteration 166/1000 | Loss: 0.00001031
Iteration 167/1000 | Loss: 0.00001031
Iteration 168/1000 | Loss: 0.00001031
Iteration 169/1000 | Loss: 0.00001031
Iteration 170/1000 | Loss: 0.00001031
Iteration 171/1000 | Loss: 0.00001030
Iteration 172/1000 | Loss: 0.00001030
Iteration 173/1000 | Loss: 0.00001030
Iteration 174/1000 | Loss: 0.00001030
Iteration 175/1000 | Loss: 0.00001030
Iteration 176/1000 | Loss: 0.00001030
Iteration 177/1000 | Loss: 0.00001030
Iteration 178/1000 | Loss: 0.00001030
Iteration 179/1000 | Loss: 0.00001030
Iteration 180/1000 | Loss: 0.00001030
Iteration 181/1000 | Loss: 0.00001029
Iteration 182/1000 | Loss: 0.00001029
Iteration 183/1000 | Loss: 0.00001029
Iteration 184/1000 | Loss: 0.00001029
Iteration 185/1000 | Loss: 0.00001029
Iteration 186/1000 | Loss: 0.00001029
Iteration 187/1000 | Loss: 0.00001029
Iteration 188/1000 | Loss: 0.00001029
Iteration 189/1000 | Loss: 0.00001028
Iteration 190/1000 | Loss: 0.00001028
Iteration 191/1000 | Loss: 0.00001028
Iteration 192/1000 | Loss: 0.00001028
Iteration 193/1000 | Loss: 0.00001027
Iteration 194/1000 | Loss: 0.00001027
Iteration 195/1000 | Loss: 0.00001027
Iteration 196/1000 | Loss: 0.00001027
Iteration 197/1000 | Loss: 0.00001027
Iteration 198/1000 | Loss: 0.00001027
Iteration 199/1000 | Loss: 0.00001027
Iteration 200/1000 | Loss: 0.00001027
Iteration 201/1000 | Loss: 0.00001027
Iteration 202/1000 | Loss: 0.00001027
Iteration 203/1000 | Loss: 0.00001027
Iteration 204/1000 | Loss: 0.00001027
Iteration 205/1000 | Loss: 0.00001027
Iteration 206/1000 | Loss: 0.00001026
Iteration 207/1000 | Loss: 0.00001026
Iteration 208/1000 | Loss: 0.00001026
Iteration 209/1000 | Loss: 0.00001026
Iteration 210/1000 | Loss: 0.00001026
Iteration 211/1000 | Loss: 0.00001026
Iteration 212/1000 | Loss: 0.00001026
Iteration 213/1000 | Loss: 0.00001026
Iteration 214/1000 | Loss: 0.00001025
Iteration 215/1000 | Loss: 0.00001025
Iteration 216/1000 | Loss: 0.00001025
Iteration 217/1000 | Loss: 0.00001025
Iteration 218/1000 | Loss: 0.00001025
Iteration 219/1000 | Loss: 0.00001024
Iteration 220/1000 | Loss: 0.00001024
Iteration 221/1000 | Loss: 0.00001024
Iteration 222/1000 | Loss: 0.00001024
Iteration 223/1000 | Loss: 0.00001024
Iteration 224/1000 | Loss: 0.00001024
Iteration 225/1000 | Loss: 0.00001024
Iteration 226/1000 | Loss: 0.00001024
Iteration 227/1000 | Loss: 0.00001024
Iteration 228/1000 | Loss: 0.00001024
Iteration 229/1000 | Loss: 0.00001024
Iteration 230/1000 | Loss: 0.00001024
Iteration 231/1000 | Loss: 0.00001024
Iteration 232/1000 | Loss: 0.00001024
Iteration 233/1000 | Loss: 0.00001024
Iteration 234/1000 | Loss: 0.00001024
Iteration 235/1000 | Loss: 0.00001023
Iteration 236/1000 | Loss: 0.00001023
Iteration 237/1000 | Loss: 0.00001023
Iteration 238/1000 | Loss: 0.00001023
Iteration 239/1000 | Loss: 0.00001023
Iteration 240/1000 | Loss: 0.00001023
Iteration 241/1000 | Loss: 0.00001023
Iteration 242/1000 | Loss: 0.00001023
Iteration 243/1000 | Loss: 0.00001023
Iteration 244/1000 | Loss: 0.00001023
Iteration 245/1000 | Loss: 0.00001023
Iteration 246/1000 | Loss: 0.00001023
Iteration 247/1000 | Loss: 0.00001022
Iteration 248/1000 | Loss: 0.00001022
Iteration 249/1000 | Loss: 0.00001022
Iteration 250/1000 | Loss: 0.00001022
Iteration 251/1000 | Loss: 0.00001022
Iteration 252/1000 | Loss: 0.00001022
Iteration 253/1000 | Loss: 0.00001022
Iteration 254/1000 | Loss: 0.00001022
Iteration 255/1000 | Loss: 0.00001022
Iteration 256/1000 | Loss: 0.00001022
Iteration 257/1000 | Loss: 0.00001022
Iteration 258/1000 | Loss: 0.00001022
Iteration 259/1000 | Loss: 0.00001022
Iteration 260/1000 | Loss: 0.00001022
Iteration 261/1000 | Loss: 0.00001022
Iteration 262/1000 | Loss: 0.00001022
Iteration 263/1000 | Loss: 0.00001022
Iteration 264/1000 | Loss: 0.00001022
Iteration 265/1000 | Loss: 0.00001021
Iteration 266/1000 | Loss: 0.00001021
Iteration 267/1000 | Loss: 0.00001021
Iteration 268/1000 | Loss: 0.00001021
Iteration 269/1000 | Loss: 0.00001021
Iteration 270/1000 | Loss: 0.00001021
Iteration 271/1000 | Loss: 0.00001021
Iteration 272/1000 | Loss: 0.00001021
Iteration 273/1000 | Loss: 0.00001021
Iteration 274/1000 | Loss: 0.00001021
Iteration 275/1000 | Loss: 0.00001021
Iteration 276/1000 | Loss: 0.00001021
Iteration 277/1000 | Loss: 0.00001021
Iteration 278/1000 | Loss: 0.00001021
Iteration 279/1000 | Loss: 0.00001021
Iteration 280/1000 | Loss: 0.00001021
Iteration 281/1000 | Loss: 0.00001021
Iteration 282/1000 | Loss: 0.00001021
Iteration 283/1000 | Loss: 0.00001021
Iteration 284/1000 | Loss: 0.00001021
Iteration 285/1000 | Loss: 0.00001021
Iteration 286/1000 | Loss: 0.00001021
Iteration 287/1000 | Loss: 0.00001021
Iteration 288/1000 | Loss: 0.00001021
Iteration 289/1000 | Loss: 0.00001021
Iteration 290/1000 | Loss: 0.00001021
Iteration 291/1000 | Loss: 0.00001021
Iteration 292/1000 | Loss: 0.00001021
Iteration 293/1000 | Loss: 0.00001021
Iteration 294/1000 | Loss: 0.00001021
Iteration 295/1000 | Loss: 0.00001021
Iteration 296/1000 | Loss: 0.00001021
Iteration 297/1000 | Loss: 0.00001021
Iteration 298/1000 | Loss: 0.00001021
Iteration 299/1000 | Loss: 0.00001021
Iteration 300/1000 | Loss: 0.00001021
Iteration 301/1000 | Loss: 0.00001021
Iteration 302/1000 | Loss: 0.00001021
Iteration 303/1000 | Loss: 0.00001021
Iteration 304/1000 | Loss: 0.00001021
Iteration 305/1000 | Loss: 0.00001021
Iteration 306/1000 | Loss: 0.00001021
Iteration 307/1000 | Loss: 0.00001021
Iteration 308/1000 | Loss: 0.00001021
Iteration 309/1000 | Loss: 0.00001021
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 309. Stopping optimization.
Last 5 losses: [1.0208013009105343e-05, 1.0208013009105343e-05, 1.0208013009105343e-05, 1.0208013009105343e-05, 1.0208013009105343e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0208013009105343e-05

Optimization complete. Final v2v error: 2.7405989170074463 mm

Highest mean error: 3.57271409034729 mm for frame 55

Lowest mean error: 2.587608814239502 mm for frame 154

Saving results

Total time: 49.89516067504883
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402088
Iteration 2/25 | Loss: 0.00140358
Iteration 3/25 | Loss: 0.00136221
Iteration 4/25 | Loss: 0.00135909
Iteration 5/25 | Loss: 0.00135909
Iteration 6/25 | Loss: 0.00135909
Iteration 7/25 | Loss: 0.00135909
Iteration 8/25 | Loss: 0.00135909
Iteration 9/25 | Loss: 0.00135909
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 9. Stopping optimization.
Last 5 losses: [0.0013590872986242175, 0.0013590872986242175, 0.0013590872986242175, 0.0013590872986242175, 0.0013590872986242175]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013590872986242175

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27644503
Iteration 2/25 | Loss: 0.00175957
Iteration 3/25 | Loss: 0.00175957
Iteration 4/25 | Loss: 0.00175957
Iteration 5/25 | Loss: 0.00175957
Iteration 6/25 | Loss: 0.00175957
Iteration 7/25 | Loss: 0.00175957
Iteration 8/25 | Loss: 0.00175957
Iteration 9/25 | Loss: 0.00175957
Iteration 10/25 | Loss: 0.00175957
Iteration 11/25 | Loss: 0.00175957
Iteration 12/25 | Loss: 0.00175957
Iteration 13/25 | Loss: 0.00175957
Iteration 14/25 | Loss: 0.00175957
Iteration 15/25 | Loss: 0.00175957
Iteration 16/25 | Loss: 0.00175957
Iteration 17/25 | Loss: 0.00175957
Iteration 18/25 | Loss: 0.00175957
Iteration 19/25 | Loss: 0.00175957
Iteration 20/25 | Loss: 0.00175957
Iteration 21/25 | Loss: 0.00175957
Iteration 22/25 | Loss: 0.00175957
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0017595670651644468, 0.0017595670651644468, 0.0017595670651644468, 0.0017595670651644468, 0.0017595670651644468]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017595670651644468

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00175957
Iteration 2/1000 | Loss: 0.00001997
Iteration 3/1000 | Loss: 0.00001713
Iteration 4/1000 | Loss: 0.00001564
Iteration 5/1000 | Loss: 0.00001474
Iteration 6/1000 | Loss: 0.00001418
Iteration 7/1000 | Loss: 0.00001372
Iteration 8/1000 | Loss: 0.00001330
Iteration 9/1000 | Loss: 0.00001309
Iteration 10/1000 | Loss: 0.00001283
Iteration 11/1000 | Loss: 0.00001272
Iteration 12/1000 | Loss: 0.00001245
Iteration 13/1000 | Loss: 0.00001229
Iteration 14/1000 | Loss: 0.00001214
Iteration 15/1000 | Loss: 0.00001211
Iteration 16/1000 | Loss: 0.00001198
Iteration 17/1000 | Loss: 0.00001195
Iteration 18/1000 | Loss: 0.00001191
Iteration 19/1000 | Loss: 0.00001190
Iteration 20/1000 | Loss: 0.00001185
Iteration 21/1000 | Loss: 0.00001183
Iteration 22/1000 | Loss: 0.00001182
Iteration 23/1000 | Loss: 0.00001180
Iteration 24/1000 | Loss: 0.00001179
Iteration 25/1000 | Loss: 0.00001175
Iteration 26/1000 | Loss: 0.00001172
Iteration 27/1000 | Loss: 0.00001168
Iteration 28/1000 | Loss: 0.00001166
Iteration 29/1000 | Loss: 0.00001165
Iteration 30/1000 | Loss: 0.00001165
Iteration 31/1000 | Loss: 0.00001165
Iteration 32/1000 | Loss: 0.00001164
Iteration 33/1000 | Loss: 0.00001163
Iteration 34/1000 | Loss: 0.00001161
Iteration 35/1000 | Loss: 0.00001156
Iteration 36/1000 | Loss: 0.00001156
Iteration 37/1000 | Loss: 0.00001155
Iteration 38/1000 | Loss: 0.00001155
Iteration 39/1000 | Loss: 0.00001154
Iteration 40/1000 | Loss: 0.00001153
Iteration 41/1000 | Loss: 0.00001152
Iteration 42/1000 | Loss: 0.00001152
Iteration 43/1000 | Loss: 0.00001151
Iteration 44/1000 | Loss: 0.00001149
Iteration 45/1000 | Loss: 0.00001149
Iteration 46/1000 | Loss: 0.00001149
Iteration 47/1000 | Loss: 0.00001147
Iteration 48/1000 | Loss: 0.00001146
Iteration 49/1000 | Loss: 0.00001145
Iteration 50/1000 | Loss: 0.00001144
Iteration 51/1000 | Loss: 0.00001143
Iteration 52/1000 | Loss: 0.00001142
Iteration 53/1000 | Loss: 0.00001142
Iteration 54/1000 | Loss: 0.00001141
Iteration 55/1000 | Loss: 0.00001141
Iteration 56/1000 | Loss: 0.00001141
Iteration 57/1000 | Loss: 0.00001140
Iteration 58/1000 | Loss: 0.00001140
Iteration 59/1000 | Loss: 0.00001140
Iteration 60/1000 | Loss: 0.00001139
Iteration 61/1000 | Loss: 0.00001139
Iteration 62/1000 | Loss: 0.00001138
Iteration 63/1000 | Loss: 0.00001137
Iteration 64/1000 | Loss: 0.00001137
Iteration 65/1000 | Loss: 0.00001137
Iteration 66/1000 | Loss: 0.00001136
Iteration 67/1000 | Loss: 0.00001136
Iteration 68/1000 | Loss: 0.00001136
Iteration 69/1000 | Loss: 0.00001136
Iteration 70/1000 | Loss: 0.00001135
Iteration 71/1000 | Loss: 0.00001135
Iteration 72/1000 | Loss: 0.00001135
Iteration 73/1000 | Loss: 0.00001135
Iteration 74/1000 | Loss: 0.00001135
Iteration 75/1000 | Loss: 0.00001135
Iteration 76/1000 | Loss: 0.00001135
Iteration 77/1000 | Loss: 0.00001135
Iteration 78/1000 | Loss: 0.00001135
Iteration 79/1000 | Loss: 0.00001134
Iteration 80/1000 | Loss: 0.00001134
Iteration 81/1000 | Loss: 0.00001134
Iteration 82/1000 | Loss: 0.00001134
Iteration 83/1000 | Loss: 0.00001133
Iteration 84/1000 | Loss: 0.00001133
Iteration 85/1000 | Loss: 0.00001133
Iteration 86/1000 | Loss: 0.00001133
Iteration 87/1000 | Loss: 0.00001132
Iteration 88/1000 | Loss: 0.00001132
Iteration 89/1000 | Loss: 0.00001132
Iteration 90/1000 | Loss: 0.00001132
Iteration 91/1000 | Loss: 0.00001132
Iteration 92/1000 | Loss: 0.00001132
Iteration 93/1000 | Loss: 0.00001132
Iteration 94/1000 | Loss: 0.00001132
Iteration 95/1000 | Loss: 0.00001131
Iteration 96/1000 | Loss: 0.00001131
Iteration 97/1000 | Loss: 0.00001131
Iteration 98/1000 | Loss: 0.00001131
Iteration 99/1000 | Loss: 0.00001131
Iteration 100/1000 | Loss: 0.00001131
Iteration 101/1000 | Loss: 0.00001130
Iteration 102/1000 | Loss: 0.00001130
Iteration 103/1000 | Loss: 0.00001130
Iteration 104/1000 | Loss: 0.00001130
Iteration 105/1000 | Loss: 0.00001129
Iteration 106/1000 | Loss: 0.00001129
Iteration 107/1000 | Loss: 0.00001129
Iteration 108/1000 | Loss: 0.00001129
Iteration 109/1000 | Loss: 0.00001129
Iteration 110/1000 | Loss: 0.00001129
Iteration 111/1000 | Loss: 0.00001128
Iteration 112/1000 | Loss: 0.00001128
Iteration 113/1000 | Loss: 0.00001128
Iteration 114/1000 | Loss: 0.00001128
Iteration 115/1000 | Loss: 0.00001127
Iteration 116/1000 | Loss: 0.00001127
Iteration 117/1000 | Loss: 0.00001127
Iteration 118/1000 | Loss: 0.00001127
Iteration 119/1000 | Loss: 0.00001127
Iteration 120/1000 | Loss: 0.00001127
Iteration 121/1000 | Loss: 0.00001127
Iteration 122/1000 | Loss: 0.00001127
Iteration 123/1000 | Loss: 0.00001126
Iteration 124/1000 | Loss: 0.00001126
Iteration 125/1000 | Loss: 0.00001126
Iteration 126/1000 | Loss: 0.00001126
Iteration 127/1000 | Loss: 0.00001126
Iteration 128/1000 | Loss: 0.00001126
Iteration 129/1000 | Loss: 0.00001126
Iteration 130/1000 | Loss: 0.00001126
Iteration 131/1000 | Loss: 0.00001126
Iteration 132/1000 | Loss: 0.00001126
Iteration 133/1000 | Loss: 0.00001126
Iteration 134/1000 | Loss: 0.00001126
Iteration 135/1000 | Loss: 0.00001126
Iteration 136/1000 | Loss: 0.00001126
Iteration 137/1000 | Loss: 0.00001126
Iteration 138/1000 | Loss: 0.00001126
Iteration 139/1000 | Loss: 0.00001126
Iteration 140/1000 | Loss: 0.00001126
Iteration 141/1000 | Loss: 0.00001126
Iteration 142/1000 | Loss: 0.00001126
Iteration 143/1000 | Loss: 0.00001126
Iteration 144/1000 | Loss: 0.00001126
Iteration 145/1000 | Loss: 0.00001126
Iteration 146/1000 | Loss: 0.00001126
Iteration 147/1000 | Loss: 0.00001126
Iteration 148/1000 | Loss: 0.00001126
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.1258115591772366e-05, 1.1258115591772366e-05, 1.1258115591772366e-05, 1.1258115591772366e-05, 1.1258115591772366e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1258115591772366e-05

Optimization complete. Final v2v error: 2.932696580886841 mm

Highest mean error: 3.110849618911743 mm for frame 128

Lowest mean error: 2.834656000137329 mm for frame 228

Saving results

Total time: 42.99354910850525
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00440173
Iteration 2/25 | Loss: 0.00147023
Iteration 3/25 | Loss: 0.00139151
Iteration 4/25 | Loss: 0.00138516
Iteration 5/25 | Loss: 0.00138303
Iteration 6/25 | Loss: 0.00138295
Iteration 7/25 | Loss: 0.00138295
Iteration 8/25 | Loss: 0.00138295
Iteration 9/25 | Loss: 0.00138295
Iteration 10/25 | Loss: 0.00138295
Iteration 11/25 | Loss: 0.00138295
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013829483650624752, 0.0013829483650624752, 0.0013829483650624752, 0.0013829483650624752, 0.0013829483650624752]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013829483650624752

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26185739
Iteration 2/25 | Loss: 0.00192748
Iteration 3/25 | Loss: 0.00192747
Iteration 4/25 | Loss: 0.00192747
Iteration 5/25 | Loss: 0.00192747
Iteration 6/25 | Loss: 0.00192747
Iteration 7/25 | Loss: 0.00192747
Iteration 8/25 | Loss: 0.00192747
Iteration 9/25 | Loss: 0.00192747
Iteration 10/25 | Loss: 0.00192747
Iteration 11/25 | Loss: 0.00192747
Iteration 12/25 | Loss: 0.00192747
Iteration 13/25 | Loss: 0.00192747
Iteration 14/25 | Loss: 0.00192747
Iteration 15/25 | Loss: 0.00192747
Iteration 16/25 | Loss: 0.00192747
Iteration 17/25 | Loss: 0.00192747
Iteration 18/25 | Loss: 0.00192747
Iteration 19/25 | Loss: 0.00192747
Iteration 20/25 | Loss: 0.00192747
Iteration 21/25 | Loss: 0.00192747
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0019274717196822166, 0.0019274717196822166, 0.0019274717196822166, 0.0019274717196822166, 0.0019274717196822166]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019274717196822166

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00192747
Iteration 2/1000 | Loss: 0.00002818
Iteration 3/1000 | Loss: 0.00002094
Iteration 4/1000 | Loss: 0.00001925
Iteration 5/1000 | Loss: 0.00001838
Iteration 6/1000 | Loss: 0.00001764
Iteration 7/1000 | Loss: 0.00001728
Iteration 8/1000 | Loss: 0.00001702
Iteration 9/1000 | Loss: 0.00001678
Iteration 10/1000 | Loss: 0.00001657
Iteration 11/1000 | Loss: 0.00001644
Iteration 12/1000 | Loss: 0.00001627
Iteration 13/1000 | Loss: 0.00001621
Iteration 14/1000 | Loss: 0.00001605
Iteration 15/1000 | Loss: 0.00001605
Iteration 16/1000 | Loss: 0.00001598
Iteration 17/1000 | Loss: 0.00001592
Iteration 18/1000 | Loss: 0.00001585
Iteration 19/1000 | Loss: 0.00001582
Iteration 20/1000 | Loss: 0.00001582
Iteration 21/1000 | Loss: 0.00001581
Iteration 22/1000 | Loss: 0.00001581
Iteration 23/1000 | Loss: 0.00001579
Iteration 24/1000 | Loss: 0.00001578
Iteration 25/1000 | Loss: 0.00001578
Iteration 26/1000 | Loss: 0.00001578
Iteration 27/1000 | Loss: 0.00001578
Iteration 28/1000 | Loss: 0.00001578
Iteration 29/1000 | Loss: 0.00001578
Iteration 30/1000 | Loss: 0.00001578
Iteration 31/1000 | Loss: 0.00001577
Iteration 32/1000 | Loss: 0.00001576
Iteration 33/1000 | Loss: 0.00001575
Iteration 34/1000 | Loss: 0.00001574
Iteration 35/1000 | Loss: 0.00001574
Iteration 36/1000 | Loss: 0.00001574
Iteration 37/1000 | Loss: 0.00001573
Iteration 38/1000 | Loss: 0.00001573
Iteration 39/1000 | Loss: 0.00001573
Iteration 40/1000 | Loss: 0.00001570
Iteration 41/1000 | Loss: 0.00001569
Iteration 42/1000 | Loss: 0.00001569
Iteration 43/1000 | Loss: 0.00001568
Iteration 44/1000 | Loss: 0.00001567
Iteration 45/1000 | Loss: 0.00001567
Iteration 46/1000 | Loss: 0.00001567
Iteration 47/1000 | Loss: 0.00001567
Iteration 48/1000 | Loss: 0.00001567
Iteration 49/1000 | Loss: 0.00001567
Iteration 50/1000 | Loss: 0.00001567
Iteration 51/1000 | Loss: 0.00001566
Iteration 52/1000 | Loss: 0.00001566
Iteration 53/1000 | Loss: 0.00001566
Iteration 54/1000 | Loss: 0.00001566
Iteration 55/1000 | Loss: 0.00001566
Iteration 56/1000 | Loss: 0.00001566
Iteration 57/1000 | Loss: 0.00001566
Iteration 58/1000 | Loss: 0.00001566
Iteration 59/1000 | Loss: 0.00001566
Iteration 60/1000 | Loss: 0.00001566
Iteration 61/1000 | Loss: 0.00001565
Iteration 62/1000 | Loss: 0.00001565
Iteration 63/1000 | Loss: 0.00001565
Iteration 64/1000 | Loss: 0.00001565
Iteration 65/1000 | Loss: 0.00001565
Iteration 66/1000 | Loss: 0.00001565
Iteration 67/1000 | Loss: 0.00001565
Iteration 68/1000 | Loss: 0.00001565
Iteration 69/1000 | Loss: 0.00001565
Iteration 70/1000 | Loss: 0.00001564
Iteration 71/1000 | Loss: 0.00001564
Iteration 72/1000 | Loss: 0.00001564
Iteration 73/1000 | Loss: 0.00001564
Iteration 74/1000 | Loss: 0.00001563
Iteration 75/1000 | Loss: 0.00001563
Iteration 76/1000 | Loss: 0.00001562
Iteration 77/1000 | Loss: 0.00001562
Iteration 78/1000 | Loss: 0.00001562
Iteration 79/1000 | Loss: 0.00001562
Iteration 80/1000 | Loss: 0.00001561
Iteration 81/1000 | Loss: 0.00001561
Iteration 82/1000 | Loss: 0.00001561
Iteration 83/1000 | Loss: 0.00001561
Iteration 84/1000 | Loss: 0.00001561
Iteration 85/1000 | Loss: 0.00001561
Iteration 86/1000 | Loss: 0.00001561
Iteration 87/1000 | Loss: 0.00001561
Iteration 88/1000 | Loss: 0.00001561
Iteration 89/1000 | Loss: 0.00001561
Iteration 90/1000 | Loss: 0.00001560
Iteration 91/1000 | Loss: 0.00001560
Iteration 92/1000 | Loss: 0.00001559
Iteration 93/1000 | Loss: 0.00001559
Iteration 94/1000 | Loss: 0.00001558
Iteration 95/1000 | Loss: 0.00001558
Iteration 96/1000 | Loss: 0.00001558
Iteration 97/1000 | Loss: 0.00001558
Iteration 98/1000 | Loss: 0.00001558
Iteration 99/1000 | Loss: 0.00001558
Iteration 100/1000 | Loss: 0.00001558
Iteration 101/1000 | Loss: 0.00001558
Iteration 102/1000 | Loss: 0.00001557
Iteration 103/1000 | Loss: 0.00001557
Iteration 104/1000 | Loss: 0.00001556
Iteration 105/1000 | Loss: 0.00001556
Iteration 106/1000 | Loss: 0.00001556
Iteration 107/1000 | Loss: 0.00001556
Iteration 108/1000 | Loss: 0.00001555
Iteration 109/1000 | Loss: 0.00001555
Iteration 110/1000 | Loss: 0.00001555
Iteration 111/1000 | Loss: 0.00001554
Iteration 112/1000 | Loss: 0.00001554
Iteration 113/1000 | Loss: 0.00001554
Iteration 114/1000 | Loss: 0.00001554
Iteration 115/1000 | Loss: 0.00001554
Iteration 116/1000 | Loss: 0.00001554
Iteration 117/1000 | Loss: 0.00001554
Iteration 118/1000 | Loss: 0.00001554
Iteration 119/1000 | Loss: 0.00001554
Iteration 120/1000 | Loss: 0.00001554
Iteration 121/1000 | Loss: 0.00001553
Iteration 122/1000 | Loss: 0.00001553
Iteration 123/1000 | Loss: 0.00001552
Iteration 124/1000 | Loss: 0.00001552
Iteration 125/1000 | Loss: 0.00001552
Iteration 126/1000 | Loss: 0.00001552
Iteration 127/1000 | Loss: 0.00001552
Iteration 128/1000 | Loss: 0.00001551
Iteration 129/1000 | Loss: 0.00001551
Iteration 130/1000 | Loss: 0.00001551
Iteration 131/1000 | Loss: 0.00001551
Iteration 132/1000 | Loss: 0.00001551
Iteration 133/1000 | Loss: 0.00001551
Iteration 134/1000 | Loss: 0.00001551
Iteration 135/1000 | Loss: 0.00001550
Iteration 136/1000 | Loss: 0.00001550
Iteration 137/1000 | Loss: 0.00001550
Iteration 138/1000 | Loss: 0.00001550
Iteration 139/1000 | Loss: 0.00001549
Iteration 140/1000 | Loss: 0.00001549
Iteration 141/1000 | Loss: 0.00001549
Iteration 142/1000 | Loss: 0.00001549
Iteration 143/1000 | Loss: 0.00001548
Iteration 144/1000 | Loss: 0.00001548
Iteration 145/1000 | Loss: 0.00001548
Iteration 146/1000 | Loss: 0.00001548
Iteration 147/1000 | Loss: 0.00001548
Iteration 148/1000 | Loss: 0.00001547
Iteration 149/1000 | Loss: 0.00001547
Iteration 150/1000 | Loss: 0.00001547
Iteration 151/1000 | Loss: 0.00001547
Iteration 152/1000 | Loss: 0.00001547
Iteration 153/1000 | Loss: 0.00001547
Iteration 154/1000 | Loss: 0.00001547
Iteration 155/1000 | Loss: 0.00001547
Iteration 156/1000 | Loss: 0.00001547
Iteration 157/1000 | Loss: 0.00001546
Iteration 158/1000 | Loss: 0.00001546
Iteration 159/1000 | Loss: 0.00001546
Iteration 160/1000 | Loss: 0.00001546
Iteration 161/1000 | Loss: 0.00001546
Iteration 162/1000 | Loss: 0.00001546
Iteration 163/1000 | Loss: 0.00001546
Iteration 164/1000 | Loss: 0.00001546
Iteration 165/1000 | Loss: 0.00001546
Iteration 166/1000 | Loss: 0.00001546
Iteration 167/1000 | Loss: 0.00001545
Iteration 168/1000 | Loss: 0.00001545
Iteration 169/1000 | Loss: 0.00001545
Iteration 170/1000 | Loss: 0.00001545
Iteration 171/1000 | Loss: 0.00001545
Iteration 172/1000 | Loss: 0.00001545
Iteration 173/1000 | Loss: 0.00001544
Iteration 174/1000 | Loss: 0.00001544
Iteration 175/1000 | Loss: 0.00001544
Iteration 176/1000 | Loss: 0.00001544
Iteration 177/1000 | Loss: 0.00001544
Iteration 178/1000 | Loss: 0.00001543
Iteration 179/1000 | Loss: 0.00001543
Iteration 180/1000 | Loss: 0.00001543
Iteration 181/1000 | Loss: 0.00001543
Iteration 182/1000 | Loss: 0.00001542
Iteration 183/1000 | Loss: 0.00001542
Iteration 184/1000 | Loss: 0.00001542
Iteration 185/1000 | Loss: 0.00001541
Iteration 186/1000 | Loss: 0.00001541
Iteration 187/1000 | Loss: 0.00001541
Iteration 188/1000 | Loss: 0.00001540
Iteration 189/1000 | Loss: 0.00001540
Iteration 190/1000 | Loss: 0.00001540
Iteration 191/1000 | Loss: 0.00001538
Iteration 192/1000 | Loss: 0.00001538
Iteration 193/1000 | Loss: 0.00001538
Iteration 194/1000 | Loss: 0.00001538
Iteration 195/1000 | Loss: 0.00001538
Iteration 196/1000 | Loss: 0.00001538
Iteration 197/1000 | Loss: 0.00001538
Iteration 198/1000 | Loss: 0.00001538
Iteration 199/1000 | Loss: 0.00001538
Iteration 200/1000 | Loss: 0.00001537
Iteration 201/1000 | Loss: 0.00001537
Iteration 202/1000 | Loss: 0.00001537
Iteration 203/1000 | Loss: 0.00001537
Iteration 204/1000 | Loss: 0.00001537
Iteration 205/1000 | Loss: 0.00001537
Iteration 206/1000 | Loss: 0.00001537
Iteration 207/1000 | Loss: 0.00001537
Iteration 208/1000 | Loss: 0.00001536
Iteration 209/1000 | Loss: 0.00001536
Iteration 210/1000 | Loss: 0.00001536
Iteration 211/1000 | Loss: 0.00001536
Iteration 212/1000 | Loss: 0.00001536
Iteration 213/1000 | Loss: 0.00001535
Iteration 214/1000 | Loss: 0.00001535
Iteration 215/1000 | Loss: 0.00001535
Iteration 216/1000 | Loss: 0.00001535
Iteration 217/1000 | Loss: 0.00001535
Iteration 218/1000 | Loss: 0.00001535
Iteration 219/1000 | Loss: 0.00001535
Iteration 220/1000 | Loss: 0.00001535
Iteration 221/1000 | Loss: 0.00001535
Iteration 222/1000 | Loss: 0.00001535
Iteration 223/1000 | Loss: 0.00001535
Iteration 224/1000 | Loss: 0.00001535
Iteration 225/1000 | Loss: 0.00001534
Iteration 226/1000 | Loss: 0.00001534
Iteration 227/1000 | Loss: 0.00001534
Iteration 228/1000 | Loss: 0.00001534
Iteration 229/1000 | Loss: 0.00001534
Iteration 230/1000 | Loss: 0.00001534
Iteration 231/1000 | Loss: 0.00001534
Iteration 232/1000 | Loss: 0.00001534
Iteration 233/1000 | Loss: 0.00001534
Iteration 234/1000 | Loss: 0.00001533
Iteration 235/1000 | Loss: 0.00001533
Iteration 236/1000 | Loss: 0.00001533
Iteration 237/1000 | Loss: 0.00001533
Iteration 238/1000 | Loss: 0.00001533
Iteration 239/1000 | Loss: 0.00001533
Iteration 240/1000 | Loss: 0.00001533
Iteration 241/1000 | Loss: 0.00001533
Iteration 242/1000 | Loss: 0.00001533
Iteration 243/1000 | Loss: 0.00001533
Iteration 244/1000 | Loss: 0.00001532
Iteration 245/1000 | Loss: 0.00001532
Iteration 246/1000 | Loss: 0.00001532
Iteration 247/1000 | Loss: 0.00001532
Iteration 248/1000 | Loss: 0.00001532
Iteration 249/1000 | Loss: 0.00001532
Iteration 250/1000 | Loss: 0.00001532
Iteration 251/1000 | Loss: 0.00001532
Iteration 252/1000 | Loss: 0.00001532
Iteration 253/1000 | Loss: 0.00001532
Iteration 254/1000 | Loss: 0.00001532
Iteration 255/1000 | Loss: 0.00001532
Iteration 256/1000 | Loss: 0.00001532
Iteration 257/1000 | Loss: 0.00001532
Iteration 258/1000 | Loss: 0.00001532
Iteration 259/1000 | Loss: 0.00001532
Iteration 260/1000 | Loss: 0.00001532
Iteration 261/1000 | Loss: 0.00001532
Iteration 262/1000 | Loss: 0.00001532
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 262. Stopping optimization.
Last 5 losses: [1.532437454443425e-05, 1.532437454443425e-05, 1.532437454443425e-05, 1.532437454443425e-05, 1.532437454443425e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.532437454443425e-05

Optimization complete. Final v2v error: 3.3267223834991455 mm

Highest mean error: 3.791133165359497 mm for frame 9

Lowest mean error: 3.094282865524292 mm for frame 21

Saving results

Total time: 47.434048652648926
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00640117
Iteration 2/25 | Loss: 0.00167997
Iteration 3/25 | Loss: 0.00155203
Iteration 4/25 | Loss: 0.00154802
Iteration 5/25 | Loss: 0.00154802
Iteration 6/25 | Loss: 0.00154802
Iteration 7/25 | Loss: 0.00154802
Iteration 8/25 | Loss: 0.00154802
Iteration 9/25 | Loss: 0.00154802
Iteration 10/25 | Loss: 0.00154802
Iteration 11/25 | Loss: 0.00154802
Iteration 12/25 | Loss: 0.00154802
Iteration 13/25 | Loss: 0.00154802
Iteration 14/25 | Loss: 0.00154802
Iteration 15/25 | Loss: 0.00154802
Iteration 16/25 | Loss: 0.00154802
Iteration 17/25 | Loss: 0.00154802
Iteration 18/25 | Loss: 0.00154802
Iteration 19/25 | Loss: 0.00154802
Iteration 20/25 | Loss: 0.00154802
Iteration 21/25 | Loss: 0.00154802
Iteration 22/25 | Loss: 0.00154802
Iteration 23/25 | Loss: 0.00154802
Iteration 24/25 | Loss: 0.00154802
Iteration 25/25 | Loss: 0.00154802

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.58432525
Iteration 2/25 | Loss: 0.00138867
Iteration 3/25 | Loss: 0.00138866
Iteration 4/25 | Loss: 0.00138866
Iteration 5/25 | Loss: 0.00138866
Iteration 6/25 | Loss: 0.00138866
Iteration 7/25 | Loss: 0.00138866
Iteration 8/25 | Loss: 0.00138866
Iteration 9/25 | Loss: 0.00138866
Iteration 10/25 | Loss: 0.00138866
Iteration 11/25 | Loss: 0.00138866
Iteration 12/25 | Loss: 0.00138866
Iteration 13/25 | Loss: 0.00138866
Iteration 14/25 | Loss: 0.00138866
Iteration 15/25 | Loss: 0.00138866
Iteration 16/25 | Loss: 0.00138866
Iteration 17/25 | Loss: 0.00138866
Iteration 18/25 | Loss: 0.00138866
Iteration 19/25 | Loss: 0.00138866
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0013886562082916498, 0.0013886562082916498, 0.0013886562082916498, 0.0013886562082916498, 0.0013886562082916498]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013886562082916498

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00138866
Iteration 2/1000 | Loss: 0.00004608
Iteration 3/1000 | Loss: 0.00003403
Iteration 4/1000 | Loss: 0.00003098
Iteration 5/1000 | Loss: 0.00002987
Iteration 6/1000 | Loss: 0.00002905
Iteration 7/1000 | Loss: 0.00002868
Iteration 8/1000 | Loss: 0.00002814
Iteration 9/1000 | Loss: 0.00002770
Iteration 10/1000 | Loss: 0.00002730
Iteration 11/1000 | Loss: 0.00002693
Iteration 12/1000 | Loss: 0.00002659
Iteration 13/1000 | Loss: 0.00002630
Iteration 14/1000 | Loss: 0.00002611
Iteration 15/1000 | Loss: 0.00002590
Iteration 16/1000 | Loss: 0.00002578
Iteration 17/1000 | Loss: 0.00002570
Iteration 18/1000 | Loss: 0.00002569
Iteration 19/1000 | Loss: 0.00002568
Iteration 20/1000 | Loss: 0.00002562
Iteration 21/1000 | Loss: 0.00002557
Iteration 22/1000 | Loss: 0.00002554
Iteration 23/1000 | Loss: 0.00002553
Iteration 24/1000 | Loss: 0.00002553
Iteration 25/1000 | Loss: 0.00002552
Iteration 26/1000 | Loss: 0.00002552
Iteration 27/1000 | Loss: 0.00002552
Iteration 28/1000 | Loss: 0.00002551
Iteration 29/1000 | Loss: 0.00002551
Iteration 30/1000 | Loss: 0.00002551
Iteration 31/1000 | Loss: 0.00002551
Iteration 32/1000 | Loss: 0.00002551
Iteration 33/1000 | Loss: 0.00002551
Iteration 34/1000 | Loss: 0.00002551
Iteration 35/1000 | Loss: 0.00002551
Iteration 36/1000 | Loss: 0.00002551
Iteration 37/1000 | Loss: 0.00002550
Iteration 38/1000 | Loss: 0.00002550
Iteration 39/1000 | Loss: 0.00002550
Iteration 40/1000 | Loss: 0.00002550
Iteration 41/1000 | Loss: 0.00002550
Iteration 42/1000 | Loss: 0.00002549
Iteration 43/1000 | Loss: 0.00002549
Iteration 44/1000 | Loss: 0.00002549
Iteration 45/1000 | Loss: 0.00002548
Iteration 46/1000 | Loss: 0.00002548
Iteration 47/1000 | Loss: 0.00002548
Iteration 48/1000 | Loss: 0.00002548
Iteration 49/1000 | Loss: 0.00002548
Iteration 50/1000 | Loss: 0.00002548
Iteration 51/1000 | Loss: 0.00002548
Iteration 52/1000 | Loss: 0.00002547
Iteration 53/1000 | Loss: 0.00002547
Iteration 54/1000 | Loss: 0.00002545
Iteration 55/1000 | Loss: 0.00002545
Iteration 56/1000 | Loss: 0.00002545
Iteration 57/1000 | Loss: 0.00002545
Iteration 58/1000 | Loss: 0.00002545
Iteration 59/1000 | Loss: 0.00002545
Iteration 60/1000 | Loss: 0.00002545
Iteration 61/1000 | Loss: 0.00002545
Iteration 62/1000 | Loss: 0.00002545
Iteration 63/1000 | Loss: 0.00002545
Iteration 64/1000 | Loss: 0.00002544
Iteration 65/1000 | Loss: 0.00002544
Iteration 66/1000 | Loss: 0.00002544
Iteration 67/1000 | Loss: 0.00002544
Iteration 68/1000 | Loss: 0.00002543
Iteration 69/1000 | Loss: 0.00002543
Iteration 70/1000 | Loss: 0.00002543
Iteration 71/1000 | Loss: 0.00002543
Iteration 72/1000 | Loss: 0.00002543
Iteration 73/1000 | Loss: 0.00002543
Iteration 74/1000 | Loss: 0.00002543
Iteration 75/1000 | Loss: 0.00002543
Iteration 76/1000 | Loss: 0.00002542
Iteration 77/1000 | Loss: 0.00002542
Iteration 78/1000 | Loss: 0.00002542
Iteration 79/1000 | Loss: 0.00002542
Iteration 80/1000 | Loss: 0.00002542
Iteration 81/1000 | Loss: 0.00002542
Iteration 82/1000 | Loss: 0.00002542
Iteration 83/1000 | Loss: 0.00002541
Iteration 84/1000 | Loss: 0.00002541
Iteration 85/1000 | Loss: 0.00002541
Iteration 86/1000 | Loss: 0.00002541
Iteration 87/1000 | Loss: 0.00002541
Iteration 88/1000 | Loss: 0.00002541
Iteration 89/1000 | Loss: 0.00002541
Iteration 90/1000 | Loss: 0.00002541
Iteration 91/1000 | Loss: 0.00002541
Iteration 92/1000 | Loss: 0.00002541
Iteration 93/1000 | Loss: 0.00002540
Iteration 94/1000 | Loss: 0.00002540
Iteration 95/1000 | Loss: 0.00002540
Iteration 96/1000 | Loss: 0.00002540
Iteration 97/1000 | Loss: 0.00002540
Iteration 98/1000 | Loss: 0.00002540
Iteration 99/1000 | Loss: 0.00002540
Iteration 100/1000 | Loss: 0.00002540
Iteration 101/1000 | Loss: 0.00002539
Iteration 102/1000 | Loss: 0.00002539
Iteration 103/1000 | Loss: 0.00002539
Iteration 104/1000 | Loss: 0.00002538
Iteration 105/1000 | Loss: 0.00002538
Iteration 106/1000 | Loss: 0.00002538
Iteration 107/1000 | Loss: 0.00002538
Iteration 108/1000 | Loss: 0.00002537
Iteration 109/1000 | Loss: 0.00002537
Iteration 110/1000 | Loss: 0.00002537
Iteration 111/1000 | Loss: 0.00002537
Iteration 112/1000 | Loss: 0.00002537
Iteration 113/1000 | Loss: 0.00002537
Iteration 114/1000 | Loss: 0.00002537
Iteration 115/1000 | Loss: 0.00002537
Iteration 116/1000 | Loss: 0.00002537
Iteration 117/1000 | Loss: 0.00002537
Iteration 118/1000 | Loss: 0.00002536
Iteration 119/1000 | Loss: 0.00002536
Iteration 120/1000 | Loss: 0.00002536
Iteration 121/1000 | Loss: 0.00002536
Iteration 122/1000 | Loss: 0.00002536
Iteration 123/1000 | Loss: 0.00002536
Iteration 124/1000 | Loss: 0.00002536
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [2.536357169447001e-05, 2.536357169447001e-05, 2.536357169447001e-05, 2.536357169447001e-05, 2.536357169447001e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.536357169447001e-05

Optimization complete. Final v2v error: 4.066722393035889 mm

Highest mean error: 4.776680946350098 mm for frame 174

Lowest mean error: 3.8589577674865723 mm for frame 106

Saving results

Total time: 42.60844898223877
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00428955
Iteration 2/25 | Loss: 0.00144003
Iteration 3/25 | Loss: 0.00136807
Iteration 4/25 | Loss: 0.00135465
Iteration 5/25 | Loss: 0.00135144
Iteration 6/25 | Loss: 0.00135144
Iteration 7/25 | Loss: 0.00135144
Iteration 8/25 | Loss: 0.00135144
Iteration 9/25 | Loss: 0.00135144
Iteration 10/25 | Loss: 0.00135144
Iteration 11/25 | Loss: 0.00135144
Iteration 12/25 | Loss: 0.00135144
Iteration 13/25 | Loss: 0.00135144
Iteration 14/25 | Loss: 0.00135144
Iteration 15/25 | Loss: 0.00135144
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013514356687664986, 0.0013514356687664986, 0.0013514356687664986, 0.0013514356687664986, 0.0013514356687664986]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013514356687664986

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.00858259
Iteration 2/25 | Loss: 0.00175506
Iteration 3/25 | Loss: 0.00175505
Iteration 4/25 | Loss: 0.00175505
Iteration 5/25 | Loss: 0.00175505
Iteration 6/25 | Loss: 0.00175505
Iteration 7/25 | Loss: 0.00175505
Iteration 8/25 | Loss: 0.00175505
Iteration 9/25 | Loss: 0.00175505
Iteration 10/25 | Loss: 0.00175505
Iteration 11/25 | Loss: 0.00175505
Iteration 12/25 | Loss: 0.00175505
Iteration 13/25 | Loss: 0.00175505
Iteration 14/25 | Loss: 0.00175505
Iteration 15/25 | Loss: 0.00175505
Iteration 16/25 | Loss: 0.00175505
Iteration 17/25 | Loss: 0.00175505
Iteration 18/25 | Loss: 0.00175505
Iteration 19/25 | Loss: 0.00175505
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0017550465418025851, 0.0017550465418025851, 0.0017550465418025851, 0.0017550465418025851, 0.0017550465418025851]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017550465418025851

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00175505
Iteration 2/1000 | Loss: 0.00002662
Iteration 3/1000 | Loss: 0.00002218
Iteration 4/1000 | Loss: 0.00002055
Iteration 5/1000 | Loss: 0.00001920
Iteration 6/1000 | Loss: 0.00001826
Iteration 7/1000 | Loss: 0.00001768
Iteration 8/1000 | Loss: 0.00001711
Iteration 9/1000 | Loss: 0.00001654
Iteration 10/1000 | Loss: 0.00001627
Iteration 11/1000 | Loss: 0.00001599
Iteration 12/1000 | Loss: 0.00001574
Iteration 13/1000 | Loss: 0.00001552
Iteration 14/1000 | Loss: 0.00001551
Iteration 15/1000 | Loss: 0.00001550
Iteration 16/1000 | Loss: 0.00001549
Iteration 17/1000 | Loss: 0.00001540
Iteration 18/1000 | Loss: 0.00001531
Iteration 19/1000 | Loss: 0.00001527
Iteration 20/1000 | Loss: 0.00001523
Iteration 21/1000 | Loss: 0.00001520
Iteration 22/1000 | Loss: 0.00001520
Iteration 23/1000 | Loss: 0.00001517
Iteration 24/1000 | Loss: 0.00001516
Iteration 25/1000 | Loss: 0.00001513
Iteration 26/1000 | Loss: 0.00001512
Iteration 27/1000 | Loss: 0.00001512
Iteration 28/1000 | Loss: 0.00001512
Iteration 29/1000 | Loss: 0.00001510
Iteration 30/1000 | Loss: 0.00001509
Iteration 31/1000 | Loss: 0.00001500
Iteration 32/1000 | Loss: 0.00001499
Iteration 33/1000 | Loss: 0.00001499
Iteration 34/1000 | Loss: 0.00001498
Iteration 35/1000 | Loss: 0.00001498
Iteration 36/1000 | Loss: 0.00001497
Iteration 37/1000 | Loss: 0.00001494
Iteration 38/1000 | Loss: 0.00001493
Iteration 39/1000 | Loss: 0.00001493
Iteration 40/1000 | Loss: 0.00001489
Iteration 41/1000 | Loss: 0.00001483
Iteration 42/1000 | Loss: 0.00001479
Iteration 43/1000 | Loss: 0.00001479
Iteration 44/1000 | Loss: 0.00001479
Iteration 45/1000 | Loss: 0.00001479
Iteration 46/1000 | Loss: 0.00001479
Iteration 47/1000 | Loss: 0.00001479
Iteration 48/1000 | Loss: 0.00001479
Iteration 49/1000 | Loss: 0.00001479
Iteration 50/1000 | Loss: 0.00001479
Iteration 51/1000 | Loss: 0.00001479
Iteration 52/1000 | Loss: 0.00001479
Iteration 53/1000 | Loss: 0.00001478
Iteration 54/1000 | Loss: 0.00001478
Iteration 55/1000 | Loss: 0.00001478
Iteration 56/1000 | Loss: 0.00001477
Iteration 57/1000 | Loss: 0.00001476
Iteration 58/1000 | Loss: 0.00001476
Iteration 59/1000 | Loss: 0.00001476
Iteration 60/1000 | Loss: 0.00001475
Iteration 61/1000 | Loss: 0.00001475
Iteration 62/1000 | Loss: 0.00001475
Iteration 63/1000 | Loss: 0.00001475
Iteration 64/1000 | Loss: 0.00001475
Iteration 65/1000 | Loss: 0.00001475
Iteration 66/1000 | Loss: 0.00001475
Iteration 67/1000 | Loss: 0.00001475
Iteration 68/1000 | Loss: 0.00001475
Iteration 69/1000 | Loss: 0.00001475
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 69. Stopping optimization.
Last 5 losses: [1.4752681636309717e-05, 1.4752681636309717e-05, 1.4752681636309717e-05, 1.4752681636309717e-05, 1.4752681636309717e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4752681636309717e-05

Optimization complete. Final v2v error: 3.3056607246398926 mm

Highest mean error: 4.097952365875244 mm for frame 235

Lowest mean error: 3.1206419467926025 mm for frame 10

Saving results

Total time: 39.53812599182129
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00944733
Iteration 2/25 | Loss: 0.00332926
Iteration 3/25 | Loss: 0.00179794
Iteration 4/25 | Loss: 0.00162731
Iteration 5/25 | Loss: 0.00167129
Iteration 6/25 | Loss: 0.00160415
Iteration 7/25 | Loss: 0.00151098
Iteration 8/25 | Loss: 0.00145411
Iteration 9/25 | Loss: 0.00145461
Iteration 10/25 | Loss: 0.00143683
Iteration 11/25 | Loss: 0.00142174
Iteration 12/25 | Loss: 0.00141733
Iteration 13/25 | Loss: 0.00141572
Iteration 14/25 | Loss: 0.00141843
Iteration 15/25 | Loss: 0.00141832
Iteration 16/25 | Loss: 0.00141794
Iteration 17/25 | Loss: 0.00141598
Iteration 18/25 | Loss: 0.00141434
Iteration 19/25 | Loss: 0.00141412
Iteration 20/25 | Loss: 0.00141403
Iteration 21/25 | Loss: 0.00141403
Iteration 22/25 | Loss: 0.00141402
Iteration 23/25 | Loss: 0.00141402
Iteration 24/25 | Loss: 0.00141402
Iteration 25/25 | Loss: 0.00141402

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26078236
Iteration 2/25 | Loss: 0.00151392
Iteration 3/25 | Loss: 0.00151392
Iteration 4/25 | Loss: 0.00151392
Iteration 5/25 | Loss: 0.00151392
Iteration 6/25 | Loss: 0.00151392
Iteration 7/25 | Loss: 0.00151392
Iteration 8/25 | Loss: 0.00151392
Iteration 9/25 | Loss: 0.00151392
Iteration 10/25 | Loss: 0.00151392
Iteration 11/25 | Loss: 0.00151392
Iteration 12/25 | Loss: 0.00151392
Iteration 13/25 | Loss: 0.00151392
Iteration 14/25 | Loss: 0.00151392
Iteration 15/25 | Loss: 0.00151392
Iteration 16/25 | Loss: 0.00151392
Iteration 17/25 | Loss: 0.00151392
Iteration 18/25 | Loss: 0.00151392
Iteration 19/25 | Loss: 0.00151392
Iteration 20/25 | Loss: 0.00151392
Iteration 21/25 | Loss: 0.00151392
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0015139190945774317, 0.0015139190945774317, 0.0015139190945774317, 0.0015139190945774317, 0.0015139190945774317]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015139190945774317

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00151392
Iteration 2/1000 | Loss: 0.00005199
Iteration 3/1000 | Loss: 0.00003076
Iteration 4/1000 | Loss: 0.00002506
Iteration 5/1000 | Loss: 0.00002288
Iteration 6/1000 | Loss: 0.00002161
Iteration 7/1000 | Loss: 0.00002081
Iteration 8/1000 | Loss: 0.00002018
Iteration 9/1000 | Loss: 0.00001954
Iteration 10/1000 | Loss: 0.00001909
Iteration 11/1000 | Loss: 0.00018735
Iteration 12/1000 | Loss: 0.00002171
Iteration 13/1000 | Loss: 0.00001960
Iteration 14/1000 | Loss: 0.00001838
Iteration 15/1000 | Loss: 0.00001780
Iteration 16/1000 | Loss: 0.00001759
Iteration 17/1000 | Loss: 0.00001743
Iteration 18/1000 | Loss: 0.00001741
Iteration 19/1000 | Loss: 0.00001740
Iteration 20/1000 | Loss: 0.00001735
Iteration 21/1000 | Loss: 0.00001734
Iteration 22/1000 | Loss: 0.00001734
Iteration 23/1000 | Loss: 0.00001733
Iteration 24/1000 | Loss: 0.00001733
Iteration 25/1000 | Loss: 0.00002142
Iteration 26/1000 | Loss: 0.00007229
Iteration 27/1000 | Loss: 0.00001981
Iteration 28/1000 | Loss: 0.00001760
Iteration 29/1000 | Loss: 0.00001720
Iteration 30/1000 | Loss: 0.00008343
Iteration 31/1000 | Loss: 0.00001707
Iteration 32/1000 | Loss: 0.00001688
Iteration 33/1000 | Loss: 0.00001685
Iteration 34/1000 | Loss: 0.00001678
Iteration 35/1000 | Loss: 0.00001675
Iteration 36/1000 | Loss: 0.00001675
Iteration 37/1000 | Loss: 0.00001675
Iteration 38/1000 | Loss: 0.00001675
Iteration 39/1000 | Loss: 0.00001675
Iteration 40/1000 | Loss: 0.00001675
Iteration 41/1000 | Loss: 0.00001675
Iteration 42/1000 | Loss: 0.00001675
Iteration 43/1000 | Loss: 0.00001675
Iteration 44/1000 | Loss: 0.00001675
Iteration 45/1000 | Loss: 0.00001675
Iteration 46/1000 | Loss: 0.00001674
Iteration 47/1000 | Loss: 0.00001674
Iteration 48/1000 | Loss: 0.00001672
Iteration 49/1000 | Loss: 0.00001672
Iteration 50/1000 | Loss: 0.00001671
Iteration 51/1000 | Loss: 0.00001670
Iteration 52/1000 | Loss: 0.00001669
Iteration 53/1000 | Loss: 0.00001669
Iteration 54/1000 | Loss: 0.00001668
Iteration 55/1000 | Loss: 0.00001667
Iteration 56/1000 | Loss: 0.00001667
Iteration 57/1000 | Loss: 0.00001662
Iteration 58/1000 | Loss: 0.00001661
Iteration 59/1000 | Loss: 0.00001661
Iteration 60/1000 | Loss: 0.00001660
Iteration 61/1000 | Loss: 0.00001659
Iteration 62/1000 | Loss: 0.00001659
Iteration 63/1000 | Loss: 0.00001655
Iteration 64/1000 | Loss: 0.00001655
Iteration 65/1000 | Loss: 0.00001655
Iteration 66/1000 | Loss: 0.00001654
Iteration 67/1000 | Loss: 0.00001654
Iteration 68/1000 | Loss: 0.00001654
Iteration 69/1000 | Loss: 0.00001654
Iteration 70/1000 | Loss: 0.00001653
Iteration 71/1000 | Loss: 0.00001653
Iteration 72/1000 | Loss: 0.00001653
Iteration 73/1000 | Loss: 0.00001652
Iteration 74/1000 | Loss: 0.00001651
Iteration 75/1000 | Loss: 0.00001651
Iteration 76/1000 | Loss: 0.00001651
Iteration 77/1000 | Loss: 0.00001651
Iteration 78/1000 | Loss: 0.00001651
Iteration 79/1000 | Loss: 0.00001651
Iteration 80/1000 | Loss: 0.00001651
Iteration 81/1000 | Loss: 0.00001651
Iteration 82/1000 | Loss: 0.00001650
Iteration 83/1000 | Loss: 0.00001650
Iteration 84/1000 | Loss: 0.00001650
Iteration 85/1000 | Loss: 0.00001650
Iteration 86/1000 | Loss: 0.00001649
Iteration 87/1000 | Loss: 0.00001649
Iteration 88/1000 | Loss: 0.00001649
Iteration 89/1000 | Loss: 0.00001649
Iteration 90/1000 | Loss: 0.00001648
Iteration 91/1000 | Loss: 0.00001648
Iteration 92/1000 | Loss: 0.00001648
Iteration 93/1000 | Loss: 0.00001648
Iteration 94/1000 | Loss: 0.00001648
Iteration 95/1000 | Loss: 0.00001648
Iteration 96/1000 | Loss: 0.00001648
Iteration 97/1000 | Loss: 0.00001648
Iteration 98/1000 | Loss: 0.00001648
Iteration 99/1000 | Loss: 0.00001648
Iteration 100/1000 | Loss: 0.00001647
Iteration 101/1000 | Loss: 0.00001647
Iteration 102/1000 | Loss: 0.00001647
Iteration 103/1000 | Loss: 0.00001647
Iteration 104/1000 | Loss: 0.00001647
Iteration 105/1000 | Loss: 0.00001647
Iteration 106/1000 | Loss: 0.00001647
Iteration 107/1000 | Loss: 0.00001647
Iteration 108/1000 | Loss: 0.00001647
Iteration 109/1000 | Loss: 0.00001647
Iteration 110/1000 | Loss: 0.00001646
Iteration 111/1000 | Loss: 0.00001646
Iteration 112/1000 | Loss: 0.00001646
Iteration 113/1000 | Loss: 0.00001646
Iteration 114/1000 | Loss: 0.00001646
Iteration 115/1000 | Loss: 0.00001646
Iteration 116/1000 | Loss: 0.00001646
Iteration 117/1000 | Loss: 0.00001646
Iteration 118/1000 | Loss: 0.00001646
Iteration 119/1000 | Loss: 0.00001646
Iteration 120/1000 | Loss: 0.00001646
Iteration 121/1000 | Loss: 0.00001646
Iteration 122/1000 | Loss: 0.00001646
Iteration 123/1000 | Loss: 0.00001646
Iteration 124/1000 | Loss: 0.00001646
Iteration 125/1000 | Loss: 0.00001646
Iteration 126/1000 | Loss: 0.00001646
Iteration 127/1000 | Loss: 0.00001646
Iteration 128/1000 | Loss: 0.00001646
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [1.6458676327602006e-05, 1.6458676327602006e-05, 1.6458676327602006e-05, 1.6458676327602006e-05, 1.6458676327602006e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6458676327602006e-05

Optimization complete. Final v2v error: 3.422766923904419 mm

Highest mean error: 4.7556891441345215 mm for frame 22

Lowest mean error: 2.9619500637054443 mm for frame 50

Saving results

Total time: 93.20416069030762
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1028
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00828237
Iteration 2/25 | Loss: 0.00141910
Iteration 3/25 | Loss: 0.00135973
Iteration 4/25 | Loss: 0.00134673
Iteration 5/25 | Loss: 0.00134287
Iteration 6/25 | Loss: 0.00134287
Iteration 7/25 | Loss: 0.00134287
Iteration 8/25 | Loss: 0.00134287
Iteration 9/25 | Loss: 0.00134287
Iteration 10/25 | Loss: 0.00134287
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0013428744859993458, 0.0013428744859993458, 0.0013428744859993458, 0.0013428744859993458, 0.0013428744859993458]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013428744859993458

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.28599274
Iteration 2/25 | Loss: 0.00177379
Iteration 3/25 | Loss: 0.00177378
Iteration 4/25 | Loss: 0.00177378
Iteration 5/25 | Loss: 0.00177378
Iteration 6/25 | Loss: 0.00177378
Iteration 7/25 | Loss: 0.00177378
Iteration 8/25 | Loss: 0.00177378
Iteration 9/25 | Loss: 0.00177378
Iteration 10/25 | Loss: 0.00177378
Iteration 11/25 | Loss: 0.00177378
Iteration 12/25 | Loss: 0.00177378
Iteration 13/25 | Loss: 0.00177378
Iteration 14/25 | Loss: 0.00177378
Iteration 15/25 | Loss: 0.00177378
Iteration 16/25 | Loss: 0.00177378
Iteration 17/25 | Loss: 0.00177378
Iteration 18/25 | Loss: 0.00177378
Iteration 19/25 | Loss: 0.00177378
Iteration 20/25 | Loss: 0.00177378
Iteration 21/25 | Loss: 0.00177378
Iteration 22/25 | Loss: 0.00177378
Iteration 23/25 | Loss: 0.00177378
Iteration 24/25 | Loss: 0.00177378
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0017737835878506303, 0.0017737835878506303, 0.0017737835878506303, 0.0017737835878506303, 0.0017737835878506303]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017737835878506303

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00177378
Iteration 2/1000 | Loss: 0.00002348
Iteration 3/1000 | Loss: 0.00001946
Iteration 4/1000 | Loss: 0.00001804
Iteration 5/1000 | Loss: 0.00001702
Iteration 6/1000 | Loss: 0.00001627
Iteration 7/1000 | Loss: 0.00001576
Iteration 8/1000 | Loss: 0.00001531
Iteration 9/1000 | Loss: 0.00001484
Iteration 10/1000 | Loss: 0.00001454
Iteration 11/1000 | Loss: 0.00001433
Iteration 12/1000 | Loss: 0.00001430
Iteration 13/1000 | Loss: 0.00001404
Iteration 14/1000 | Loss: 0.00001399
Iteration 15/1000 | Loss: 0.00001390
Iteration 16/1000 | Loss: 0.00001373
Iteration 17/1000 | Loss: 0.00001363
Iteration 18/1000 | Loss: 0.00001355
Iteration 19/1000 | Loss: 0.00001353
Iteration 20/1000 | Loss: 0.00001353
Iteration 21/1000 | Loss: 0.00001352
Iteration 22/1000 | Loss: 0.00001351
Iteration 23/1000 | Loss: 0.00001350
Iteration 24/1000 | Loss: 0.00001350
Iteration 25/1000 | Loss: 0.00001349
Iteration 26/1000 | Loss: 0.00001348
Iteration 27/1000 | Loss: 0.00001348
Iteration 28/1000 | Loss: 0.00001347
Iteration 29/1000 | Loss: 0.00001347
Iteration 30/1000 | Loss: 0.00001346
Iteration 31/1000 | Loss: 0.00001346
Iteration 32/1000 | Loss: 0.00001346
Iteration 33/1000 | Loss: 0.00001344
Iteration 34/1000 | Loss: 0.00001342
Iteration 35/1000 | Loss: 0.00001341
Iteration 36/1000 | Loss: 0.00001339
Iteration 37/1000 | Loss: 0.00001339
Iteration 38/1000 | Loss: 0.00001338
Iteration 39/1000 | Loss: 0.00001330
Iteration 40/1000 | Loss: 0.00001329
Iteration 41/1000 | Loss: 0.00001328
Iteration 42/1000 | Loss: 0.00001327
Iteration 43/1000 | Loss: 0.00001327
Iteration 44/1000 | Loss: 0.00001326
Iteration 45/1000 | Loss: 0.00001325
Iteration 46/1000 | Loss: 0.00001325
Iteration 47/1000 | Loss: 0.00001324
Iteration 48/1000 | Loss: 0.00001321
Iteration 49/1000 | Loss: 0.00001321
Iteration 50/1000 | Loss: 0.00001320
Iteration 51/1000 | Loss: 0.00001320
Iteration 52/1000 | Loss: 0.00001320
Iteration 53/1000 | Loss: 0.00001320
Iteration 54/1000 | Loss: 0.00001320
Iteration 55/1000 | Loss: 0.00001317
Iteration 56/1000 | Loss: 0.00001317
Iteration 57/1000 | Loss: 0.00001316
Iteration 58/1000 | Loss: 0.00001316
Iteration 59/1000 | Loss: 0.00001316
Iteration 60/1000 | Loss: 0.00001314
Iteration 61/1000 | Loss: 0.00001314
Iteration 62/1000 | Loss: 0.00001313
Iteration 63/1000 | Loss: 0.00001312
Iteration 64/1000 | Loss: 0.00001312
Iteration 65/1000 | Loss: 0.00001312
Iteration 66/1000 | Loss: 0.00001311
Iteration 67/1000 | Loss: 0.00001311
Iteration 68/1000 | Loss: 0.00001311
Iteration 69/1000 | Loss: 0.00001311
Iteration 70/1000 | Loss: 0.00001311
Iteration 71/1000 | Loss: 0.00001311
Iteration 72/1000 | Loss: 0.00001311
Iteration 73/1000 | Loss: 0.00001311
Iteration 74/1000 | Loss: 0.00001310
Iteration 75/1000 | Loss: 0.00001310
Iteration 76/1000 | Loss: 0.00001310
Iteration 77/1000 | Loss: 0.00001310
Iteration 78/1000 | Loss: 0.00001310
Iteration 79/1000 | Loss: 0.00001310
Iteration 80/1000 | Loss: 0.00001310
Iteration 81/1000 | Loss: 0.00001310
Iteration 82/1000 | Loss: 0.00001310
Iteration 83/1000 | Loss: 0.00001310
Iteration 84/1000 | Loss: 0.00001309
Iteration 85/1000 | Loss: 0.00001309
Iteration 86/1000 | Loss: 0.00001309
Iteration 87/1000 | Loss: 0.00001309
Iteration 88/1000 | Loss: 0.00001309
Iteration 89/1000 | Loss: 0.00001309
Iteration 90/1000 | Loss: 0.00001309
Iteration 91/1000 | Loss: 0.00001308
Iteration 92/1000 | Loss: 0.00001308
Iteration 93/1000 | Loss: 0.00001308
Iteration 94/1000 | Loss: 0.00001308
Iteration 95/1000 | Loss: 0.00001308
Iteration 96/1000 | Loss: 0.00001307
Iteration 97/1000 | Loss: 0.00001307
Iteration 98/1000 | Loss: 0.00001307
Iteration 99/1000 | Loss: 0.00001307
Iteration 100/1000 | Loss: 0.00001307
Iteration 101/1000 | Loss: 0.00001306
Iteration 102/1000 | Loss: 0.00001306
Iteration 103/1000 | Loss: 0.00001306
Iteration 104/1000 | Loss: 0.00001306
Iteration 105/1000 | Loss: 0.00001306
Iteration 106/1000 | Loss: 0.00001306
Iteration 107/1000 | Loss: 0.00001306
Iteration 108/1000 | Loss: 0.00001305
Iteration 109/1000 | Loss: 0.00001305
Iteration 110/1000 | Loss: 0.00001305
Iteration 111/1000 | Loss: 0.00001305
Iteration 112/1000 | Loss: 0.00001305
Iteration 113/1000 | Loss: 0.00001305
Iteration 114/1000 | Loss: 0.00001304
Iteration 115/1000 | Loss: 0.00001304
Iteration 116/1000 | Loss: 0.00001304
Iteration 117/1000 | Loss: 0.00001304
Iteration 118/1000 | Loss: 0.00001304
Iteration 119/1000 | Loss: 0.00001304
Iteration 120/1000 | Loss: 0.00001304
Iteration 121/1000 | Loss: 0.00001304
Iteration 122/1000 | Loss: 0.00001304
Iteration 123/1000 | Loss: 0.00001304
Iteration 124/1000 | Loss: 0.00001304
Iteration 125/1000 | Loss: 0.00001304
Iteration 126/1000 | Loss: 0.00001304
Iteration 127/1000 | Loss: 0.00001304
Iteration 128/1000 | Loss: 0.00001304
Iteration 129/1000 | Loss: 0.00001304
Iteration 130/1000 | Loss: 0.00001304
Iteration 131/1000 | Loss: 0.00001304
Iteration 132/1000 | Loss: 0.00001304
Iteration 133/1000 | Loss: 0.00001304
Iteration 134/1000 | Loss: 0.00001304
Iteration 135/1000 | Loss: 0.00001304
Iteration 136/1000 | Loss: 0.00001304
Iteration 137/1000 | Loss: 0.00001304
Iteration 138/1000 | Loss: 0.00001304
Iteration 139/1000 | Loss: 0.00001304
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 139. Stopping optimization.
Last 5 losses: [1.3040361409366596e-05, 1.3040361409366596e-05, 1.3040361409366596e-05, 1.3040361409366596e-05, 1.3040361409366596e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3040361409366596e-05

Optimization complete. Final v2v error: 3.1350860595703125 mm

Highest mean error: 3.416067361831665 mm for frame 115

Lowest mean error: 3.019700527191162 mm for frame 196

Saving results

Total time: 47.01957416534424
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1071/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1071.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1071
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00478065
Iteration 2/25 | Loss: 0.00143689
Iteration 3/25 | Loss: 0.00137785
Iteration 4/25 | Loss: 0.00136806
Iteration 5/25 | Loss: 0.00136583
Iteration 6/25 | Loss: 0.00136583
Iteration 7/25 | Loss: 0.00136583
Iteration 8/25 | Loss: 0.00136583
Iteration 9/25 | Loss: 0.00136583
Iteration 10/25 | Loss: 0.00136583
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0013658335665240884, 0.0013658335665240884, 0.0013658335665240884, 0.0013658335665240884, 0.0013658335665240884]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013658335665240884

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.29338288
Iteration 2/25 | Loss: 0.00183405
Iteration 3/25 | Loss: 0.00183405
Iteration 4/25 | Loss: 0.00183405
Iteration 5/25 | Loss: 0.00183405
Iteration 6/25 | Loss: 0.00183405
Iteration 7/25 | Loss: 0.00183405
Iteration 8/25 | Loss: 0.00183404
Iteration 9/25 | Loss: 0.00183404
Iteration 10/25 | Loss: 0.00183404
Iteration 11/25 | Loss: 0.00183404
Iteration 12/25 | Loss: 0.00183404
Iteration 13/25 | Loss: 0.00183404
Iteration 14/25 | Loss: 0.00183404
Iteration 15/25 | Loss: 0.00183404
Iteration 16/25 | Loss: 0.00183404
Iteration 17/25 | Loss: 0.00183404
Iteration 18/25 | Loss: 0.00183404
Iteration 19/25 | Loss: 0.00183404
Iteration 20/25 | Loss: 0.00183404
Iteration 21/25 | Loss: 0.00183404
Iteration 22/25 | Loss: 0.00183404
Iteration 23/25 | Loss: 0.00183404
Iteration 24/25 | Loss: 0.00183404
Iteration 25/25 | Loss: 0.00183404

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00183404
Iteration 2/1000 | Loss: 0.00002561
Iteration 3/1000 | Loss: 0.00002102
Iteration 4/1000 | Loss: 0.00001937
Iteration 5/1000 | Loss: 0.00001855
Iteration 6/1000 | Loss: 0.00001807
Iteration 7/1000 | Loss: 0.00001764
Iteration 8/1000 | Loss: 0.00001726
Iteration 9/1000 | Loss: 0.00001686
Iteration 10/1000 | Loss: 0.00001652
Iteration 11/1000 | Loss: 0.00001629
Iteration 12/1000 | Loss: 0.00001625
Iteration 13/1000 | Loss: 0.00001619
Iteration 14/1000 | Loss: 0.00001601
Iteration 15/1000 | Loss: 0.00001591
Iteration 16/1000 | Loss: 0.00001586
Iteration 17/1000 | Loss: 0.00001578
Iteration 18/1000 | Loss: 0.00001569
Iteration 19/1000 | Loss: 0.00001561
Iteration 20/1000 | Loss: 0.00001556
Iteration 21/1000 | Loss: 0.00001550
Iteration 22/1000 | Loss: 0.00001548
Iteration 23/1000 | Loss: 0.00001547
Iteration 24/1000 | Loss: 0.00001547
Iteration 25/1000 | Loss: 0.00001546
Iteration 26/1000 | Loss: 0.00001545
Iteration 27/1000 | Loss: 0.00001544
Iteration 28/1000 | Loss: 0.00001542
Iteration 29/1000 | Loss: 0.00001542
Iteration 30/1000 | Loss: 0.00001542
Iteration 31/1000 | Loss: 0.00001541
Iteration 32/1000 | Loss: 0.00001541
Iteration 33/1000 | Loss: 0.00001541
Iteration 34/1000 | Loss: 0.00001541
Iteration 35/1000 | Loss: 0.00001540
Iteration 36/1000 | Loss: 0.00001540
Iteration 37/1000 | Loss: 0.00001540
Iteration 38/1000 | Loss: 0.00001539
Iteration 39/1000 | Loss: 0.00001539
Iteration 40/1000 | Loss: 0.00001538
Iteration 41/1000 | Loss: 0.00001537
Iteration 42/1000 | Loss: 0.00001537
Iteration 43/1000 | Loss: 0.00001536
Iteration 44/1000 | Loss: 0.00001536
Iteration 45/1000 | Loss: 0.00001536
Iteration 46/1000 | Loss: 0.00001535
Iteration 47/1000 | Loss: 0.00001534
Iteration 48/1000 | Loss: 0.00001531
Iteration 49/1000 | Loss: 0.00001530
Iteration 50/1000 | Loss: 0.00001521
Iteration 51/1000 | Loss: 0.00001517
Iteration 52/1000 | Loss: 0.00001516
Iteration 53/1000 | Loss: 0.00001515
Iteration 54/1000 | Loss: 0.00001513
Iteration 55/1000 | Loss: 0.00001513
Iteration 56/1000 | Loss: 0.00001512
Iteration 57/1000 | Loss: 0.00001512
Iteration 58/1000 | Loss: 0.00001512
Iteration 59/1000 | Loss: 0.00001512
Iteration 60/1000 | Loss: 0.00001512
Iteration 61/1000 | Loss: 0.00001512
Iteration 62/1000 | Loss: 0.00001511
Iteration 63/1000 | Loss: 0.00001511
Iteration 64/1000 | Loss: 0.00001511
Iteration 65/1000 | Loss: 0.00001511
Iteration 66/1000 | Loss: 0.00001510
Iteration 67/1000 | Loss: 0.00001510
Iteration 68/1000 | Loss: 0.00001510
Iteration 69/1000 | Loss: 0.00001509
Iteration 70/1000 | Loss: 0.00001509
Iteration 71/1000 | Loss: 0.00001509
Iteration 72/1000 | Loss: 0.00001509
Iteration 73/1000 | Loss: 0.00001508
Iteration 74/1000 | Loss: 0.00001508
Iteration 75/1000 | Loss: 0.00001508
Iteration 76/1000 | Loss: 0.00001507
Iteration 77/1000 | Loss: 0.00001507
Iteration 78/1000 | Loss: 0.00001507
Iteration 79/1000 | Loss: 0.00001507
Iteration 80/1000 | Loss: 0.00001506
Iteration 81/1000 | Loss: 0.00001506
Iteration 82/1000 | Loss: 0.00001506
Iteration 83/1000 | Loss: 0.00001506
Iteration 84/1000 | Loss: 0.00001506
Iteration 85/1000 | Loss: 0.00001506
Iteration 86/1000 | Loss: 0.00001506
Iteration 87/1000 | Loss: 0.00001506
Iteration 88/1000 | Loss: 0.00001505
Iteration 89/1000 | Loss: 0.00001505
Iteration 90/1000 | Loss: 0.00001505
Iteration 91/1000 | Loss: 0.00001505
Iteration 92/1000 | Loss: 0.00001505
Iteration 93/1000 | Loss: 0.00001505
Iteration 94/1000 | Loss: 0.00001505
Iteration 95/1000 | Loss: 0.00001505
Iteration 96/1000 | Loss: 0.00001505
Iteration 97/1000 | Loss: 0.00001505
Iteration 98/1000 | Loss: 0.00001504
Iteration 99/1000 | Loss: 0.00001504
Iteration 100/1000 | Loss: 0.00001504
Iteration 101/1000 | Loss: 0.00001504
Iteration 102/1000 | Loss: 0.00001504
Iteration 103/1000 | Loss: 0.00001504
Iteration 104/1000 | Loss: 0.00001503
Iteration 105/1000 | Loss: 0.00001503
Iteration 106/1000 | Loss: 0.00001503
Iteration 107/1000 | Loss: 0.00001503
Iteration 108/1000 | Loss: 0.00001503
Iteration 109/1000 | Loss: 0.00001503
Iteration 110/1000 | Loss: 0.00001502
Iteration 111/1000 | Loss: 0.00001502
Iteration 112/1000 | Loss: 0.00001502
Iteration 113/1000 | Loss: 0.00001502
Iteration 114/1000 | Loss: 0.00001502
Iteration 115/1000 | Loss: 0.00001502
Iteration 116/1000 | Loss: 0.00001502
Iteration 117/1000 | Loss: 0.00001502
Iteration 118/1000 | Loss: 0.00001502
Iteration 119/1000 | Loss: 0.00001502
Iteration 120/1000 | Loss: 0.00001502
Iteration 121/1000 | Loss: 0.00001502
Iteration 122/1000 | Loss: 0.00001502
Iteration 123/1000 | Loss: 0.00001502
Iteration 124/1000 | Loss: 0.00001502
Iteration 125/1000 | Loss: 0.00001501
Iteration 126/1000 | Loss: 0.00001501
Iteration 127/1000 | Loss: 0.00001501
Iteration 128/1000 | Loss: 0.00001501
Iteration 129/1000 | Loss: 0.00001501
Iteration 130/1000 | Loss: 0.00001501
Iteration 131/1000 | Loss: 0.00001500
Iteration 132/1000 | Loss: 0.00001500
Iteration 133/1000 | Loss: 0.00001500
Iteration 134/1000 | Loss: 0.00001500
Iteration 135/1000 | Loss: 0.00001500
Iteration 136/1000 | Loss: 0.00001500
Iteration 137/1000 | Loss: 0.00001500
Iteration 138/1000 | Loss: 0.00001500
Iteration 139/1000 | Loss: 0.00001499
Iteration 140/1000 | Loss: 0.00001499
Iteration 141/1000 | Loss: 0.00001499
Iteration 142/1000 | Loss: 0.00001499
Iteration 143/1000 | Loss: 0.00001499
Iteration 144/1000 | Loss: 0.00001499
Iteration 145/1000 | Loss: 0.00001499
Iteration 146/1000 | Loss: 0.00001499
Iteration 147/1000 | Loss: 0.00001498
Iteration 148/1000 | Loss: 0.00001498
Iteration 149/1000 | Loss: 0.00001498
Iteration 150/1000 | Loss: 0.00001498
Iteration 151/1000 | Loss: 0.00001498
Iteration 152/1000 | Loss: 0.00001498
Iteration 153/1000 | Loss: 0.00001498
Iteration 154/1000 | Loss: 0.00001498
Iteration 155/1000 | Loss: 0.00001498
Iteration 156/1000 | Loss: 0.00001498
Iteration 157/1000 | Loss: 0.00001497
Iteration 158/1000 | Loss: 0.00001497
Iteration 159/1000 | Loss: 0.00001497
Iteration 160/1000 | Loss: 0.00001497
Iteration 161/1000 | Loss: 0.00001497
Iteration 162/1000 | Loss: 0.00001497
Iteration 163/1000 | Loss: 0.00001497
Iteration 164/1000 | Loss: 0.00001497
Iteration 165/1000 | Loss: 0.00001497
Iteration 166/1000 | Loss: 0.00001497
Iteration 167/1000 | Loss: 0.00001497
Iteration 168/1000 | Loss: 0.00001497
Iteration 169/1000 | Loss: 0.00001497
Iteration 170/1000 | Loss: 0.00001497
Iteration 171/1000 | Loss: 0.00001496
Iteration 172/1000 | Loss: 0.00001496
Iteration 173/1000 | Loss: 0.00001496
Iteration 174/1000 | Loss: 0.00001496
Iteration 175/1000 | Loss: 0.00001496
Iteration 176/1000 | Loss: 0.00001496
Iteration 177/1000 | Loss: 0.00001496
Iteration 178/1000 | Loss: 0.00001496
Iteration 179/1000 | Loss: 0.00001496
Iteration 180/1000 | Loss: 0.00001496
Iteration 181/1000 | Loss: 0.00001496
Iteration 182/1000 | Loss: 0.00001496
Iteration 183/1000 | Loss: 0.00001496
Iteration 184/1000 | Loss: 0.00001496
Iteration 185/1000 | Loss: 0.00001496
Iteration 186/1000 | Loss: 0.00001496
Iteration 187/1000 | Loss: 0.00001496
Iteration 188/1000 | Loss: 0.00001496
Iteration 189/1000 | Loss: 0.00001496
Iteration 190/1000 | Loss: 0.00001496
Iteration 191/1000 | Loss: 0.00001496
Iteration 192/1000 | Loss: 0.00001496
Iteration 193/1000 | Loss: 0.00001496
Iteration 194/1000 | Loss: 0.00001496
Iteration 195/1000 | Loss: 0.00001496
Iteration 196/1000 | Loss: 0.00001496
Iteration 197/1000 | Loss: 0.00001496
Iteration 198/1000 | Loss: 0.00001496
Iteration 199/1000 | Loss: 0.00001496
Iteration 200/1000 | Loss: 0.00001496
Iteration 201/1000 | Loss: 0.00001496
Iteration 202/1000 | Loss: 0.00001496
Iteration 203/1000 | Loss: 0.00001496
Iteration 204/1000 | Loss: 0.00001496
Iteration 205/1000 | Loss: 0.00001496
Iteration 206/1000 | Loss: 0.00001496
Iteration 207/1000 | Loss: 0.00001496
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [1.495965898357099e-05, 1.495965898357099e-05, 1.495965898357099e-05, 1.495965898357099e-05, 1.495965898357099e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.495965898357099e-05

Optimization complete. Final v2v error: 3.2453203201293945 mm

Highest mean error: 3.4469056129455566 mm for frame 211

Lowest mean error: 3.0334231853485107 mm for frame 17

Saving results

Total time: 50.25304961204529
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1085
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00704368
Iteration 2/25 | Loss: 0.00175247
Iteration 3/25 | Loss: 0.00155472
Iteration 4/25 | Loss: 0.00141087
Iteration 5/25 | Loss: 0.00141316
Iteration 6/25 | Loss: 0.00137434
Iteration 7/25 | Loss: 0.00136710
Iteration 8/25 | Loss: 0.00135624
Iteration 9/25 | Loss: 0.00135219
Iteration 10/25 | Loss: 0.00135083
Iteration 11/25 | Loss: 0.00135031
Iteration 12/25 | Loss: 0.00135010
Iteration 13/25 | Loss: 0.00135007
Iteration 14/25 | Loss: 0.00135007
Iteration 15/25 | Loss: 0.00135007
Iteration 16/25 | Loss: 0.00135006
Iteration 17/25 | Loss: 0.00135006
Iteration 18/25 | Loss: 0.00135006
Iteration 19/25 | Loss: 0.00135006
Iteration 20/25 | Loss: 0.00135006
Iteration 21/25 | Loss: 0.00135006
Iteration 22/25 | Loss: 0.00135006
Iteration 23/25 | Loss: 0.00135005
Iteration 24/25 | Loss: 0.00135005
Iteration 25/25 | Loss: 0.00135005

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.65987539
Iteration 2/25 | Loss: 0.00191590
Iteration 3/25 | Loss: 0.00191590
Iteration 4/25 | Loss: 0.00191590
Iteration 5/25 | Loss: 0.00191590
Iteration 6/25 | Loss: 0.00191589
Iteration 7/25 | Loss: 0.00191589
Iteration 8/25 | Loss: 0.00191589
Iteration 9/25 | Loss: 0.00191589
Iteration 10/25 | Loss: 0.00191589
Iteration 11/25 | Loss: 0.00191589
Iteration 12/25 | Loss: 0.00191589
Iteration 13/25 | Loss: 0.00191589
Iteration 14/25 | Loss: 0.00191589
Iteration 15/25 | Loss: 0.00191589
Iteration 16/25 | Loss: 0.00191589
Iteration 17/25 | Loss: 0.00191589
Iteration 18/25 | Loss: 0.00191589
Iteration 19/25 | Loss: 0.00191589
Iteration 20/25 | Loss: 0.00191589
Iteration 21/25 | Loss: 0.00191589
Iteration 22/25 | Loss: 0.00191589
Iteration 23/25 | Loss: 0.00191589
Iteration 24/25 | Loss: 0.00191589
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0019158911891281605, 0.0019158911891281605, 0.0019158911891281605, 0.0019158911891281605, 0.0019158911891281605]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019158911891281605

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00191589
Iteration 2/1000 | Loss: 0.00002936
Iteration 3/1000 | Loss: 0.00003944
Iteration 4/1000 | Loss: 0.00003246
Iteration 5/1000 | Loss: 0.00005971
Iteration 6/1000 | Loss: 0.00001663
Iteration 7/1000 | Loss: 0.00002228
Iteration 8/1000 | Loss: 0.00001575
Iteration 9/1000 | Loss: 0.00001537
Iteration 10/1000 | Loss: 0.00001486
Iteration 11/1000 | Loss: 0.00001456
Iteration 12/1000 | Loss: 0.00001431
Iteration 13/1000 | Loss: 0.00002199
Iteration 14/1000 | Loss: 0.00001403
Iteration 15/1000 | Loss: 0.00003233
Iteration 16/1000 | Loss: 0.00002673
Iteration 17/1000 | Loss: 0.00001377
Iteration 18/1000 | Loss: 0.00001467
Iteration 19/1000 | Loss: 0.00001373
Iteration 20/1000 | Loss: 0.00001372
Iteration 21/1000 | Loss: 0.00001372
Iteration 22/1000 | Loss: 0.00001372
Iteration 23/1000 | Loss: 0.00001372
Iteration 24/1000 | Loss: 0.00001372
Iteration 25/1000 | Loss: 0.00001372
Iteration 26/1000 | Loss: 0.00001372
Iteration 27/1000 | Loss: 0.00001371
Iteration 28/1000 | Loss: 0.00001370
Iteration 29/1000 | Loss: 0.00001369
Iteration 30/1000 | Loss: 0.00001622
Iteration 31/1000 | Loss: 0.00001968
Iteration 32/1000 | Loss: 0.00001416
Iteration 33/1000 | Loss: 0.00002549
Iteration 34/1000 | Loss: 0.00001769
Iteration 35/1000 | Loss: 0.00002209
Iteration 36/1000 | Loss: 0.00001390
Iteration 37/1000 | Loss: 0.00001377
Iteration 38/1000 | Loss: 0.00001347
Iteration 39/1000 | Loss: 0.00001347
Iteration 40/1000 | Loss: 0.00001347
Iteration 41/1000 | Loss: 0.00001347
Iteration 42/1000 | Loss: 0.00001346
Iteration 43/1000 | Loss: 0.00001346
Iteration 44/1000 | Loss: 0.00001346
Iteration 45/1000 | Loss: 0.00001346
Iteration 46/1000 | Loss: 0.00001346
Iteration 47/1000 | Loss: 0.00001346
Iteration 48/1000 | Loss: 0.00001345
Iteration 49/1000 | Loss: 0.00001345
Iteration 50/1000 | Loss: 0.00001345
Iteration 51/1000 | Loss: 0.00001344
Iteration 52/1000 | Loss: 0.00001390
Iteration 53/1000 | Loss: 0.00001343
Iteration 54/1000 | Loss: 0.00001343
Iteration 55/1000 | Loss: 0.00001343
Iteration 56/1000 | Loss: 0.00001343
Iteration 57/1000 | Loss: 0.00001343
Iteration 58/1000 | Loss: 0.00001343
Iteration 59/1000 | Loss: 0.00001343
Iteration 60/1000 | Loss: 0.00001343
Iteration 61/1000 | Loss: 0.00001343
Iteration 62/1000 | Loss: 0.00001344
Iteration 63/1000 | Loss: 0.00001344
Iteration 64/1000 | Loss: 0.00001341
Iteration 65/1000 | Loss: 0.00001341
Iteration 66/1000 | Loss: 0.00001341
Iteration 67/1000 | Loss: 0.00001341
Iteration 68/1000 | Loss: 0.00001341
Iteration 69/1000 | Loss: 0.00001341
Iteration 70/1000 | Loss: 0.00001341
Iteration 71/1000 | Loss: 0.00001341
Iteration 72/1000 | Loss: 0.00001341
Iteration 73/1000 | Loss: 0.00001341
Iteration 74/1000 | Loss: 0.00001341
Iteration 75/1000 | Loss: 0.00001341
Iteration 76/1000 | Loss: 0.00001340
Iteration 77/1000 | Loss: 0.00001338
Iteration 78/1000 | Loss: 0.00001338
Iteration 79/1000 | Loss: 0.00001338
Iteration 80/1000 | Loss: 0.00001337
Iteration 81/1000 | Loss: 0.00001337
Iteration 82/1000 | Loss: 0.00001337
Iteration 83/1000 | Loss: 0.00001337
Iteration 84/1000 | Loss: 0.00001336
Iteration 85/1000 | Loss: 0.00001336
Iteration 86/1000 | Loss: 0.00001336
Iteration 87/1000 | Loss: 0.00001336
Iteration 88/1000 | Loss: 0.00001335
Iteration 89/1000 | Loss: 0.00001335
Iteration 90/1000 | Loss: 0.00001334
Iteration 91/1000 | Loss: 0.00001425
Iteration 92/1000 | Loss: 0.00001331
Iteration 93/1000 | Loss: 0.00001331
Iteration 94/1000 | Loss: 0.00001331
Iteration 95/1000 | Loss: 0.00001331
Iteration 96/1000 | Loss: 0.00001331
Iteration 97/1000 | Loss: 0.00001331
Iteration 98/1000 | Loss: 0.00001331
Iteration 99/1000 | Loss: 0.00001331
Iteration 100/1000 | Loss: 0.00001331
Iteration 101/1000 | Loss: 0.00001331
Iteration 102/1000 | Loss: 0.00001331
Iteration 103/1000 | Loss: 0.00001331
Iteration 104/1000 | Loss: 0.00001331
Iteration 105/1000 | Loss: 0.00001331
Iteration 106/1000 | Loss: 0.00001330
Iteration 107/1000 | Loss: 0.00001330
Iteration 108/1000 | Loss: 0.00001330
Iteration 109/1000 | Loss: 0.00001329
Iteration 110/1000 | Loss: 0.00001329
Iteration 111/1000 | Loss: 0.00001960
Iteration 112/1000 | Loss: 0.00001327
Iteration 113/1000 | Loss: 0.00001326
Iteration 114/1000 | Loss: 0.00001326
Iteration 115/1000 | Loss: 0.00001326
Iteration 116/1000 | Loss: 0.00001326
Iteration 117/1000 | Loss: 0.00001326
Iteration 118/1000 | Loss: 0.00001326
Iteration 119/1000 | Loss: 0.00001326
Iteration 120/1000 | Loss: 0.00001325
Iteration 121/1000 | Loss: 0.00001325
Iteration 122/1000 | Loss: 0.00001325
Iteration 123/1000 | Loss: 0.00001325
Iteration 124/1000 | Loss: 0.00001522
Iteration 125/1000 | Loss: 0.00001326
Iteration 126/1000 | Loss: 0.00001325
Iteration 127/1000 | Loss: 0.00001325
Iteration 128/1000 | Loss: 0.00001325
Iteration 129/1000 | Loss: 0.00001325
Iteration 130/1000 | Loss: 0.00001325
Iteration 131/1000 | Loss: 0.00001325
Iteration 132/1000 | Loss: 0.00001325
Iteration 133/1000 | Loss: 0.00001325
Iteration 134/1000 | Loss: 0.00001325
Iteration 135/1000 | Loss: 0.00001324
Iteration 136/1000 | Loss: 0.00001324
Iteration 137/1000 | Loss: 0.00001324
Iteration 138/1000 | Loss: 0.00001324
Iteration 139/1000 | Loss: 0.00001324
Iteration 140/1000 | Loss: 0.00001324
Iteration 141/1000 | Loss: 0.00001324
Iteration 142/1000 | Loss: 0.00001324
Iteration 143/1000 | Loss: 0.00001324
Iteration 144/1000 | Loss: 0.00001324
Iteration 145/1000 | Loss: 0.00001323
Iteration 146/1000 | Loss: 0.00001323
Iteration 147/1000 | Loss: 0.00001323
Iteration 148/1000 | Loss: 0.00001323
Iteration 149/1000 | Loss: 0.00001323
Iteration 150/1000 | Loss: 0.00001323
Iteration 151/1000 | Loss: 0.00001323
Iteration 152/1000 | Loss: 0.00001323
Iteration 153/1000 | Loss: 0.00001323
Iteration 154/1000 | Loss: 0.00001323
Iteration 155/1000 | Loss: 0.00001323
Iteration 156/1000 | Loss: 0.00001323
Iteration 157/1000 | Loss: 0.00001323
Iteration 158/1000 | Loss: 0.00001323
Iteration 159/1000 | Loss: 0.00001323
Iteration 160/1000 | Loss: 0.00001323
Iteration 161/1000 | Loss: 0.00001323
Iteration 162/1000 | Loss: 0.00001323
Iteration 163/1000 | Loss: 0.00001323
Iteration 164/1000 | Loss: 0.00001323
Iteration 165/1000 | Loss: 0.00001323
Iteration 166/1000 | Loss: 0.00001323
Iteration 167/1000 | Loss: 0.00001322
Iteration 168/1000 | Loss: 0.00001322
Iteration 169/1000 | Loss: 0.00001322
Iteration 170/1000 | Loss: 0.00001322
Iteration 171/1000 | Loss: 0.00001322
Iteration 172/1000 | Loss: 0.00001322
Iteration 173/1000 | Loss: 0.00001322
Iteration 174/1000 | Loss: 0.00001322
Iteration 175/1000 | Loss: 0.00001322
Iteration 176/1000 | Loss: 0.00001322
Iteration 177/1000 | Loss: 0.00001322
Iteration 178/1000 | Loss: 0.00001322
Iteration 179/1000 | Loss: 0.00001322
Iteration 180/1000 | Loss: 0.00001322
Iteration 181/1000 | Loss: 0.00001322
Iteration 182/1000 | Loss: 0.00001322
Iteration 183/1000 | Loss: 0.00001322
Iteration 184/1000 | Loss: 0.00001322
Iteration 185/1000 | Loss: 0.00001322
Iteration 186/1000 | Loss: 0.00001322
Iteration 187/1000 | Loss: 0.00001322
Iteration 188/1000 | Loss: 0.00001322
Iteration 189/1000 | Loss: 0.00001322
Iteration 190/1000 | Loss: 0.00001322
Iteration 191/1000 | Loss: 0.00001322
Iteration 192/1000 | Loss: 0.00001322
Iteration 193/1000 | Loss: 0.00001322
Iteration 194/1000 | Loss: 0.00001322
Iteration 195/1000 | Loss: 0.00001322
Iteration 196/1000 | Loss: 0.00001322
Iteration 197/1000 | Loss: 0.00001322
Iteration 198/1000 | Loss: 0.00001322
Iteration 199/1000 | Loss: 0.00001322
Iteration 200/1000 | Loss: 0.00001322
Iteration 201/1000 | Loss: 0.00001322
Iteration 202/1000 | Loss: 0.00001322
Iteration 203/1000 | Loss: 0.00001322
Iteration 204/1000 | Loss: 0.00001322
Iteration 205/1000 | Loss: 0.00001322
Iteration 206/1000 | Loss: 0.00001322
Iteration 207/1000 | Loss: 0.00001322
Iteration 208/1000 | Loss: 0.00001322
Iteration 209/1000 | Loss: 0.00001322
Iteration 210/1000 | Loss: 0.00001322
Iteration 211/1000 | Loss: 0.00001322
Iteration 212/1000 | Loss: 0.00001322
Iteration 213/1000 | Loss: 0.00001322
Iteration 214/1000 | Loss: 0.00001322
Iteration 215/1000 | Loss: 0.00001322
Iteration 216/1000 | Loss: 0.00001322
Iteration 217/1000 | Loss: 0.00001322
Iteration 218/1000 | Loss: 0.00001322
Iteration 219/1000 | Loss: 0.00001322
Iteration 220/1000 | Loss: 0.00001322
Iteration 221/1000 | Loss: 0.00001322
Iteration 222/1000 | Loss: 0.00001322
Iteration 223/1000 | Loss: 0.00001322
Iteration 224/1000 | Loss: 0.00001322
Iteration 225/1000 | Loss: 0.00001322
Iteration 226/1000 | Loss: 0.00001322
Iteration 227/1000 | Loss: 0.00001322
Iteration 228/1000 | Loss: 0.00001322
Iteration 229/1000 | Loss: 0.00001322
Iteration 230/1000 | Loss: 0.00001322
Iteration 231/1000 | Loss: 0.00001322
Iteration 232/1000 | Loss: 0.00001322
Iteration 233/1000 | Loss: 0.00001322
Iteration 234/1000 | Loss: 0.00001322
Iteration 235/1000 | Loss: 0.00001322
Iteration 236/1000 | Loss: 0.00001322
Iteration 237/1000 | Loss: 0.00001322
Iteration 238/1000 | Loss: 0.00001322
Iteration 239/1000 | Loss: 0.00001322
Iteration 240/1000 | Loss: 0.00001322
Iteration 241/1000 | Loss: 0.00001322
Iteration 242/1000 | Loss: 0.00001322
Iteration 243/1000 | Loss: 0.00001322
Iteration 244/1000 | Loss: 0.00001322
Iteration 245/1000 | Loss: 0.00001322
Iteration 246/1000 | Loss: 0.00001322
Iteration 247/1000 | Loss: 0.00001322
Iteration 248/1000 | Loss: 0.00001322
Iteration 249/1000 | Loss: 0.00001322
Iteration 250/1000 | Loss: 0.00001322
Iteration 251/1000 | Loss: 0.00001322
Iteration 252/1000 | Loss: 0.00001322
Iteration 253/1000 | Loss: 0.00001322
Iteration 254/1000 | Loss: 0.00001322
Iteration 255/1000 | Loss: 0.00001322
Iteration 256/1000 | Loss: 0.00001322
Iteration 257/1000 | Loss: 0.00001322
Iteration 258/1000 | Loss: 0.00001322
Iteration 259/1000 | Loss: 0.00001322
Iteration 260/1000 | Loss: 0.00001322
Iteration 261/1000 | Loss: 0.00001322
Iteration 262/1000 | Loss: 0.00001322
Iteration 263/1000 | Loss: 0.00001322
Iteration 264/1000 | Loss: 0.00001322
Iteration 265/1000 | Loss: 0.00001322
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 265. Stopping optimization.
Last 5 losses: [1.3220422260928899e-05, 1.3220422260928899e-05, 1.3220422260928899e-05, 1.3220422260928899e-05, 1.3220422260928899e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3220422260928899e-05

Optimization complete. Final v2v error: 3.117227077484131 mm

Highest mean error: 3.686147451400757 mm for frame 43

Lowest mean error: 2.82267165184021 mm for frame 130

Saving results

Total time: 81.28058910369873
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00563447
Iteration 2/25 | Loss: 0.00145794
Iteration 3/25 | Loss: 0.00136132
Iteration 4/25 | Loss: 0.00134759
Iteration 5/25 | Loss: 0.00134341
Iteration 6/25 | Loss: 0.00134238
Iteration 7/25 | Loss: 0.00134238
Iteration 8/25 | Loss: 0.00134238
Iteration 9/25 | Loss: 0.00134238
Iteration 10/25 | Loss: 0.00134238
Iteration 11/25 | Loss: 0.00134238
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013423816999420524, 0.0013423816999420524, 0.0013423816999420524, 0.0013423816999420524, 0.0013423816999420524]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013423816999420524

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.92763239
Iteration 2/25 | Loss: 0.00130780
Iteration 3/25 | Loss: 0.00130780
Iteration 4/25 | Loss: 0.00130780
Iteration 5/25 | Loss: 0.00130780
Iteration 6/25 | Loss: 0.00130779
Iteration 7/25 | Loss: 0.00130779
Iteration 8/25 | Loss: 0.00130779
Iteration 9/25 | Loss: 0.00130779
Iteration 10/25 | Loss: 0.00130779
Iteration 11/25 | Loss: 0.00130779
Iteration 12/25 | Loss: 0.00130779
Iteration 13/25 | Loss: 0.00130779
Iteration 14/25 | Loss: 0.00130779
Iteration 15/25 | Loss: 0.00130779
Iteration 16/25 | Loss: 0.00130779
Iteration 17/25 | Loss: 0.00130779
Iteration 18/25 | Loss: 0.00130779
Iteration 19/25 | Loss: 0.00130779
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0013077936600893736, 0.0013077936600893736, 0.0013077936600893736, 0.0013077936600893736, 0.0013077936600893736]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013077936600893736

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00130779
Iteration 2/1000 | Loss: 0.00003921
Iteration 3/1000 | Loss: 0.00003408
Iteration 4/1000 | Loss: 0.00003144
Iteration 5/1000 | Loss: 0.00002961
Iteration 6/1000 | Loss: 0.00002861
Iteration 7/1000 | Loss: 0.00002785
Iteration 8/1000 | Loss: 0.00002736
Iteration 9/1000 | Loss: 0.00002685
Iteration 10/1000 | Loss: 0.00002653
Iteration 11/1000 | Loss: 0.00002643
Iteration 12/1000 | Loss: 0.00002616
Iteration 13/1000 | Loss: 0.00002593
Iteration 14/1000 | Loss: 0.00002573
Iteration 15/1000 | Loss: 0.00002562
Iteration 16/1000 | Loss: 0.00002562
Iteration 17/1000 | Loss: 0.00002562
Iteration 18/1000 | Loss: 0.00002562
Iteration 19/1000 | Loss: 0.00002562
Iteration 20/1000 | Loss: 0.00002561
Iteration 21/1000 | Loss: 0.00002561
Iteration 22/1000 | Loss: 0.00002560
Iteration 23/1000 | Loss: 0.00002560
Iteration 24/1000 | Loss: 0.00002560
Iteration 25/1000 | Loss: 0.00002560
Iteration 26/1000 | Loss: 0.00002560
Iteration 27/1000 | Loss: 0.00002560
Iteration 28/1000 | Loss: 0.00002560
Iteration 29/1000 | Loss: 0.00002560
Iteration 30/1000 | Loss: 0.00002560
Iteration 31/1000 | Loss: 0.00002559
Iteration 32/1000 | Loss: 0.00002552
Iteration 33/1000 | Loss: 0.00002552
Iteration 34/1000 | Loss: 0.00002551
Iteration 35/1000 | Loss: 0.00002551
Iteration 36/1000 | Loss: 0.00002551
Iteration 37/1000 | Loss: 0.00002551
Iteration 38/1000 | Loss: 0.00002551
Iteration 39/1000 | Loss: 0.00002551
Iteration 40/1000 | Loss: 0.00002551
Iteration 41/1000 | Loss: 0.00002551
Iteration 42/1000 | Loss: 0.00002551
Iteration 43/1000 | Loss: 0.00002547
Iteration 44/1000 | Loss: 0.00002547
Iteration 45/1000 | Loss: 0.00002547
Iteration 46/1000 | Loss: 0.00002547
Iteration 47/1000 | Loss: 0.00002547
Iteration 48/1000 | Loss: 0.00002547
Iteration 49/1000 | Loss: 0.00002547
Iteration 50/1000 | Loss: 0.00002547
Iteration 51/1000 | Loss: 0.00002547
Iteration 52/1000 | Loss: 0.00002546
Iteration 53/1000 | Loss: 0.00002546
Iteration 54/1000 | Loss: 0.00002546
Iteration 55/1000 | Loss: 0.00002544
Iteration 56/1000 | Loss: 0.00002544
Iteration 57/1000 | Loss: 0.00002544
Iteration 58/1000 | Loss: 0.00002544
Iteration 59/1000 | Loss: 0.00002544
Iteration 60/1000 | Loss: 0.00002544
Iteration 61/1000 | Loss: 0.00002544
Iteration 62/1000 | Loss: 0.00002544
Iteration 63/1000 | Loss: 0.00002544
Iteration 64/1000 | Loss: 0.00002544
Iteration 65/1000 | Loss: 0.00002544
Iteration 66/1000 | Loss: 0.00002543
Iteration 67/1000 | Loss: 0.00002543
Iteration 68/1000 | Loss: 0.00002541
Iteration 69/1000 | Loss: 0.00002541
Iteration 70/1000 | Loss: 0.00002541
Iteration 71/1000 | Loss: 0.00002540
Iteration 72/1000 | Loss: 0.00002540
Iteration 73/1000 | Loss: 0.00002540
Iteration 74/1000 | Loss: 0.00002529
Iteration 75/1000 | Loss: 0.00002528
Iteration 76/1000 | Loss: 0.00002528
Iteration 77/1000 | Loss: 0.00002528
Iteration 78/1000 | Loss: 0.00002528
Iteration 79/1000 | Loss: 0.00002528
Iteration 80/1000 | Loss: 0.00002528
Iteration 81/1000 | Loss: 0.00002527
Iteration 82/1000 | Loss: 0.00002527
Iteration 83/1000 | Loss: 0.00002527
Iteration 84/1000 | Loss: 0.00002527
Iteration 85/1000 | Loss: 0.00002526
Iteration 86/1000 | Loss: 0.00002526
Iteration 87/1000 | Loss: 0.00002525
Iteration 88/1000 | Loss: 0.00002524
Iteration 89/1000 | Loss: 0.00002524
Iteration 90/1000 | Loss: 0.00002523
Iteration 91/1000 | Loss: 0.00002523
Iteration 92/1000 | Loss: 0.00002523
Iteration 93/1000 | Loss: 0.00002523
Iteration 94/1000 | Loss: 0.00002523
Iteration 95/1000 | Loss: 0.00002522
Iteration 96/1000 | Loss: 0.00002522
Iteration 97/1000 | Loss: 0.00002522
Iteration 98/1000 | Loss: 0.00002522
Iteration 99/1000 | Loss: 0.00002522
Iteration 100/1000 | Loss: 0.00002521
Iteration 101/1000 | Loss: 0.00002521
Iteration 102/1000 | Loss: 0.00002521
Iteration 103/1000 | Loss: 0.00002521
Iteration 104/1000 | Loss: 0.00002521
Iteration 105/1000 | Loss: 0.00002521
Iteration 106/1000 | Loss: 0.00002521
Iteration 107/1000 | Loss: 0.00002521
Iteration 108/1000 | Loss: 0.00002521
Iteration 109/1000 | Loss: 0.00002521
Iteration 110/1000 | Loss: 0.00002521
Iteration 111/1000 | Loss: 0.00002521
Iteration 112/1000 | Loss: 0.00002521
Iteration 113/1000 | Loss: 0.00002521
Iteration 114/1000 | Loss: 0.00002521
Iteration 115/1000 | Loss: 0.00002521
Iteration 116/1000 | Loss: 0.00002521
Iteration 117/1000 | Loss: 0.00002521
Iteration 118/1000 | Loss: 0.00002521
Iteration 119/1000 | Loss: 0.00002521
Iteration 120/1000 | Loss: 0.00002521
Iteration 121/1000 | Loss: 0.00002521
Iteration 122/1000 | Loss: 0.00002521
Iteration 123/1000 | Loss: 0.00002521
Iteration 124/1000 | Loss: 0.00002521
Iteration 125/1000 | Loss: 0.00002521
Iteration 126/1000 | Loss: 0.00002521
Iteration 127/1000 | Loss: 0.00002521
Iteration 128/1000 | Loss: 0.00002521
Iteration 129/1000 | Loss: 0.00002521
Iteration 130/1000 | Loss: 0.00002521
Iteration 131/1000 | Loss: 0.00002521
Iteration 132/1000 | Loss: 0.00002521
Iteration 133/1000 | Loss: 0.00002521
Iteration 134/1000 | Loss: 0.00002521
Iteration 135/1000 | Loss: 0.00002521
Iteration 136/1000 | Loss: 0.00002521
Iteration 137/1000 | Loss: 0.00002521
Iteration 138/1000 | Loss: 0.00002521
Iteration 139/1000 | Loss: 0.00002521
Iteration 140/1000 | Loss: 0.00002521
Iteration 141/1000 | Loss: 0.00002521
Iteration 142/1000 | Loss: 0.00002521
Iteration 143/1000 | Loss: 0.00002521
Iteration 144/1000 | Loss: 0.00002521
Iteration 145/1000 | Loss: 0.00002521
Iteration 146/1000 | Loss: 0.00002521
Iteration 147/1000 | Loss: 0.00002521
Iteration 148/1000 | Loss: 0.00002521
Iteration 149/1000 | Loss: 0.00002521
Iteration 150/1000 | Loss: 0.00002521
Iteration 151/1000 | Loss: 0.00002521
Iteration 152/1000 | Loss: 0.00002521
Iteration 153/1000 | Loss: 0.00002521
Iteration 154/1000 | Loss: 0.00002521
Iteration 155/1000 | Loss: 0.00002521
Iteration 156/1000 | Loss: 0.00002521
Iteration 157/1000 | Loss: 0.00002521
Iteration 158/1000 | Loss: 0.00002521
Iteration 159/1000 | Loss: 0.00002521
Iteration 160/1000 | Loss: 0.00002521
Iteration 161/1000 | Loss: 0.00002521
Iteration 162/1000 | Loss: 0.00002521
Iteration 163/1000 | Loss: 0.00002521
Iteration 164/1000 | Loss: 0.00002521
Iteration 165/1000 | Loss: 0.00002521
Iteration 166/1000 | Loss: 0.00002521
Iteration 167/1000 | Loss: 0.00002521
Iteration 168/1000 | Loss: 0.00002521
Iteration 169/1000 | Loss: 0.00002521
Iteration 170/1000 | Loss: 0.00002521
Iteration 171/1000 | Loss: 0.00002521
Iteration 172/1000 | Loss: 0.00002521
Iteration 173/1000 | Loss: 0.00002521
Iteration 174/1000 | Loss: 0.00002521
Iteration 175/1000 | Loss: 0.00002521
Iteration 176/1000 | Loss: 0.00002521
Iteration 177/1000 | Loss: 0.00002521
Iteration 178/1000 | Loss: 0.00002521
Iteration 179/1000 | Loss: 0.00002521
Iteration 180/1000 | Loss: 0.00002521
Iteration 181/1000 | Loss: 0.00002521
Iteration 182/1000 | Loss: 0.00002521
Iteration 183/1000 | Loss: 0.00002521
Iteration 184/1000 | Loss: 0.00002521
Iteration 185/1000 | Loss: 0.00002521
Iteration 186/1000 | Loss: 0.00002521
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 186. Stopping optimization.
Last 5 losses: [2.5206043574144132e-05, 2.5206043574144132e-05, 2.5206043574144132e-05, 2.5206043574144132e-05, 2.5206043574144132e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5206043574144132e-05

Optimization complete. Final v2v error: 4.366413116455078 mm

Highest mean error: 4.474140167236328 mm for frame 12

Lowest mean error: 4.219499588012695 mm for frame 142

Saving results

Total time: 39.316014528274536
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1070
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01018883
Iteration 2/25 | Loss: 0.01018883
Iteration 3/25 | Loss: 0.01018883
Iteration 4/25 | Loss: 0.01018883
Iteration 5/25 | Loss: 0.01018883
Iteration 6/25 | Loss: 0.01018883
Iteration 7/25 | Loss: 0.01018883
Iteration 8/25 | Loss: 0.01018883
Iteration 9/25 | Loss: 0.01018882
Iteration 10/25 | Loss: 0.01018882
Iteration 11/25 | Loss: 0.01018881
Iteration 12/25 | Loss: 0.01018881
Iteration 13/25 | Loss: 0.01018881
Iteration 14/25 | Loss: 0.01018881
Iteration 15/25 | Loss: 0.01018880
Iteration 16/25 | Loss: 0.01018880
Iteration 17/25 | Loss: 0.01018880
Iteration 18/25 | Loss: 0.01018880
Iteration 19/25 | Loss: 0.01018880
Iteration 20/25 | Loss: 0.01018879
Iteration 21/25 | Loss: 0.01018879
Iteration 22/25 | Loss: 0.01018879
Iteration 23/25 | Loss: 0.01018878
Iteration 24/25 | Loss: 0.01018878
Iteration 25/25 | Loss: 0.01018878

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26479673
Iteration 2/25 | Loss: 0.19112647
Iteration 3/25 | Loss: 0.18671539
Iteration 4/25 | Loss: 0.18665777
Iteration 5/25 | Loss: 0.18665770
Iteration 6/25 | Loss: 0.18665770
Iteration 7/25 | Loss: 0.18653467
Iteration 8/25 | Loss: 0.18653467
Iteration 9/25 | Loss: 0.18653467
Iteration 10/25 | Loss: 0.18653466
Iteration 11/25 | Loss: 0.18653464
Iteration 12/25 | Loss: 0.18653466
Iteration 13/25 | Loss: 0.18653466
Iteration 14/25 | Loss: 0.18653464
Iteration 15/25 | Loss: 0.18653464
Iteration 16/25 | Loss: 0.18653464
Iteration 17/25 | Loss: 0.18653464
Iteration 18/25 | Loss: 0.18653464
Iteration 19/25 | Loss: 0.18653463
Iteration 20/25 | Loss: 0.18653463
Iteration 21/25 | Loss: 0.18653463
Iteration 22/25 | Loss: 0.18653463
Iteration 23/25 | Loss: 0.18653464
Iteration 24/25 | Loss: 0.18653464
Iteration 25/25 | Loss: 0.18653460

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.18653460
Iteration 2/1000 | Loss: 0.00173131
Iteration 3/1000 | Loss: 0.00372264
Iteration 4/1000 | Loss: 0.00304366
Iteration 5/1000 | Loss: 0.00869317
Iteration 6/1000 | Loss: 0.00185558
Iteration 7/1000 | Loss: 0.00014128
Iteration 8/1000 | Loss: 0.00007100
Iteration 9/1000 | Loss: 0.00004962
Iteration 10/1000 | Loss: 0.00003945
Iteration 11/1000 | Loss: 0.00003526
Iteration 12/1000 | Loss: 0.00003163
Iteration 13/1000 | Loss: 0.00002930
Iteration 14/1000 | Loss: 0.00002749
Iteration 15/1000 | Loss: 0.00002595
Iteration 16/1000 | Loss: 0.00002463
Iteration 17/1000 | Loss: 0.00002358
Iteration 18/1000 | Loss: 0.00002279
Iteration 19/1000 | Loss: 0.00002207
Iteration 20/1000 | Loss: 0.00002122
Iteration 21/1000 | Loss: 0.00002055
Iteration 22/1000 | Loss: 0.00001992
Iteration 23/1000 | Loss: 0.00001936
Iteration 24/1000 | Loss: 0.00001895
Iteration 25/1000 | Loss: 0.00001863
Iteration 26/1000 | Loss: 0.00001831
Iteration 27/1000 | Loss: 0.00001803
Iteration 28/1000 | Loss: 0.00001780
Iteration 29/1000 | Loss: 0.00001770
Iteration 30/1000 | Loss: 0.00001743
Iteration 31/1000 | Loss: 0.00001727
Iteration 32/1000 | Loss: 0.00001715
Iteration 33/1000 | Loss: 0.00001709
Iteration 34/1000 | Loss: 0.00001707
Iteration 35/1000 | Loss: 0.00001703
Iteration 36/1000 | Loss: 0.00001701
Iteration 37/1000 | Loss: 0.00001700
Iteration 38/1000 | Loss: 0.00001699
Iteration 39/1000 | Loss: 0.00001697
Iteration 40/1000 | Loss: 0.00001695
Iteration 41/1000 | Loss: 0.00001694
Iteration 42/1000 | Loss: 0.00001694
Iteration 43/1000 | Loss: 0.00001690
Iteration 44/1000 | Loss: 0.00001688
Iteration 45/1000 | Loss: 0.00001687
Iteration 46/1000 | Loss: 0.00001687
Iteration 47/1000 | Loss: 0.00001685
Iteration 48/1000 | Loss: 0.00001681
Iteration 49/1000 | Loss: 0.00001674
Iteration 50/1000 | Loss: 0.00001674
Iteration 51/1000 | Loss: 0.00001671
Iteration 52/1000 | Loss: 0.00001668
Iteration 53/1000 | Loss: 0.00001666
Iteration 54/1000 | Loss: 0.00001664
Iteration 55/1000 | Loss: 0.00001664
Iteration 56/1000 | Loss: 0.00001663
Iteration 57/1000 | Loss: 0.00001663
Iteration 58/1000 | Loss: 0.00001663
Iteration 59/1000 | Loss: 0.00001662
Iteration 60/1000 | Loss: 0.00001662
Iteration 61/1000 | Loss: 0.00001662
Iteration 62/1000 | Loss: 0.00001662
Iteration 63/1000 | Loss: 0.00001662
Iteration 64/1000 | Loss: 0.00001662
Iteration 65/1000 | Loss: 0.00001662
Iteration 66/1000 | Loss: 0.00001661
Iteration 67/1000 | Loss: 0.00001661
Iteration 68/1000 | Loss: 0.00001661
Iteration 69/1000 | Loss: 0.00001661
Iteration 70/1000 | Loss: 0.00001660
Iteration 71/1000 | Loss: 0.00001660
Iteration 72/1000 | Loss: 0.00001659
Iteration 73/1000 | Loss: 0.00001659
Iteration 74/1000 | Loss: 0.00001659
Iteration 75/1000 | Loss: 0.00001659
Iteration 76/1000 | Loss: 0.00001658
Iteration 77/1000 | Loss: 0.00001658
Iteration 78/1000 | Loss: 0.00001658
Iteration 79/1000 | Loss: 0.00001657
Iteration 80/1000 | Loss: 0.00001657
Iteration 81/1000 | Loss: 0.00001656
Iteration 82/1000 | Loss: 0.00001656
Iteration 83/1000 | Loss: 0.00001655
Iteration 84/1000 | Loss: 0.00001655
Iteration 85/1000 | Loss: 0.00001655
Iteration 86/1000 | Loss: 0.00001654
Iteration 87/1000 | Loss: 0.00001654
Iteration 88/1000 | Loss: 0.00001654
Iteration 89/1000 | Loss: 0.00001654
Iteration 90/1000 | Loss: 0.00001653
Iteration 91/1000 | Loss: 0.00001653
Iteration 92/1000 | Loss: 0.00001653
Iteration 93/1000 | Loss: 0.00001652
Iteration 94/1000 | Loss: 0.00001652
Iteration 95/1000 | Loss: 0.00001652
Iteration 96/1000 | Loss: 0.00001651
Iteration 97/1000 | Loss: 0.00001651
Iteration 98/1000 | Loss: 0.00001651
Iteration 99/1000 | Loss: 0.00001651
Iteration 100/1000 | Loss: 0.00001651
Iteration 101/1000 | Loss: 0.00001651
Iteration 102/1000 | Loss: 0.00001650
Iteration 103/1000 | Loss: 0.00001650
Iteration 104/1000 | Loss: 0.00001650
Iteration 105/1000 | Loss: 0.00001650
Iteration 106/1000 | Loss: 0.00001650
Iteration 107/1000 | Loss: 0.00001650
Iteration 108/1000 | Loss: 0.00001650
Iteration 109/1000 | Loss: 0.00001650
Iteration 110/1000 | Loss: 0.00001650
Iteration 111/1000 | Loss: 0.00001650
Iteration 112/1000 | Loss: 0.00001650
Iteration 113/1000 | Loss: 0.00001650
Iteration 114/1000 | Loss: 0.00001650
Iteration 115/1000 | Loss: 0.00001650
Iteration 116/1000 | Loss: 0.00001650
Iteration 117/1000 | Loss: 0.00001650
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [1.6501726349815726e-05, 1.6501726349815726e-05, 1.6501726349815726e-05, 1.6501726349815726e-05, 1.6501726349815726e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6501726349815726e-05

Optimization complete. Final v2v error: 3.4270102977752686 mm

Highest mean error: 5.252082824707031 mm for frame 67

Lowest mean error: 2.9057931900024414 mm for frame 138

Saving results

Total time: 76.01709985733032
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00749400
Iteration 2/25 | Loss: 0.00155786
Iteration 3/25 | Loss: 0.00141391
Iteration 4/25 | Loss: 0.00139208
Iteration 5/25 | Loss: 0.00138706
Iteration 6/25 | Loss: 0.00138671
Iteration 7/25 | Loss: 0.00138671
Iteration 8/25 | Loss: 0.00138671
Iteration 9/25 | Loss: 0.00138671
Iteration 10/25 | Loss: 0.00138671
Iteration 11/25 | Loss: 0.00138671
Iteration 12/25 | Loss: 0.00138671
Iteration 13/25 | Loss: 0.00138671
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0013867112575098872, 0.0013867112575098872, 0.0013867112575098872, 0.0013867112575098872, 0.0013867112575098872]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013867112575098872

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30786562
Iteration 2/25 | Loss: 0.00233107
Iteration 3/25 | Loss: 0.00233107
Iteration 4/25 | Loss: 0.00233107
Iteration 5/25 | Loss: 0.00233107
Iteration 6/25 | Loss: 0.00233106
Iteration 7/25 | Loss: 0.00233106
Iteration 8/25 | Loss: 0.00233106
Iteration 9/25 | Loss: 0.00233106
Iteration 10/25 | Loss: 0.00233106
Iteration 11/25 | Loss: 0.00233106
Iteration 12/25 | Loss: 0.00233106
Iteration 13/25 | Loss: 0.00233106
Iteration 14/25 | Loss: 0.00233106
Iteration 15/25 | Loss: 0.00233106
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0023310636170208454, 0.0023310636170208454, 0.0023310636170208454, 0.0023310636170208454, 0.0023310636170208454]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0023310636170208454

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00233106
Iteration 2/1000 | Loss: 0.00003685
Iteration 3/1000 | Loss: 0.00002713
Iteration 4/1000 | Loss: 0.00002185
Iteration 5/1000 | Loss: 0.00002048
Iteration 6/1000 | Loss: 0.00001955
Iteration 7/1000 | Loss: 0.00001881
Iteration 8/1000 | Loss: 0.00001834
Iteration 9/1000 | Loss: 0.00001790
Iteration 10/1000 | Loss: 0.00001758
Iteration 11/1000 | Loss: 0.00001711
Iteration 12/1000 | Loss: 0.00001673
Iteration 13/1000 | Loss: 0.00001649
Iteration 14/1000 | Loss: 0.00001626
Iteration 15/1000 | Loss: 0.00001604
Iteration 16/1000 | Loss: 0.00001582
Iteration 17/1000 | Loss: 0.00001582
Iteration 18/1000 | Loss: 0.00001578
Iteration 19/1000 | Loss: 0.00001575
Iteration 20/1000 | Loss: 0.00001568
Iteration 21/1000 | Loss: 0.00001564
Iteration 22/1000 | Loss: 0.00001563
Iteration 23/1000 | Loss: 0.00001561
Iteration 24/1000 | Loss: 0.00001561
Iteration 25/1000 | Loss: 0.00001560
Iteration 26/1000 | Loss: 0.00001560
Iteration 27/1000 | Loss: 0.00001558
Iteration 28/1000 | Loss: 0.00001557
Iteration 29/1000 | Loss: 0.00001556
Iteration 30/1000 | Loss: 0.00001555
Iteration 31/1000 | Loss: 0.00001554
Iteration 32/1000 | Loss: 0.00001554
Iteration 33/1000 | Loss: 0.00001553
Iteration 34/1000 | Loss: 0.00001552
Iteration 35/1000 | Loss: 0.00001549
Iteration 36/1000 | Loss: 0.00001548
Iteration 37/1000 | Loss: 0.00001547
Iteration 38/1000 | Loss: 0.00001547
Iteration 39/1000 | Loss: 0.00001546
Iteration 40/1000 | Loss: 0.00001546
Iteration 41/1000 | Loss: 0.00001545
Iteration 42/1000 | Loss: 0.00001545
Iteration 43/1000 | Loss: 0.00001544
Iteration 44/1000 | Loss: 0.00001544
Iteration 45/1000 | Loss: 0.00001544
Iteration 46/1000 | Loss: 0.00001543
Iteration 47/1000 | Loss: 0.00001542
Iteration 48/1000 | Loss: 0.00001542
Iteration 49/1000 | Loss: 0.00001542
Iteration 50/1000 | Loss: 0.00001541
Iteration 51/1000 | Loss: 0.00001540
Iteration 52/1000 | Loss: 0.00001540
Iteration 53/1000 | Loss: 0.00001538
Iteration 54/1000 | Loss: 0.00001538
Iteration 55/1000 | Loss: 0.00001538
Iteration 56/1000 | Loss: 0.00001538
Iteration 57/1000 | Loss: 0.00001538
Iteration 58/1000 | Loss: 0.00001538
Iteration 59/1000 | Loss: 0.00001537
Iteration 60/1000 | Loss: 0.00001536
Iteration 61/1000 | Loss: 0.00001536
Iteration 62/1000 | Loss: 0.00001535
Iteration 63/1000 | Loss: 0.00001535
Iteration 64/1000 | Loss: 0.00001534
Iteration 65/1000 | Loss: 0.00001534
Iteration 66/1000 | Loss: 0.00001533
Iteration 67/1000 | Loss: 0.00001533
Iteration 68/1000 | Loss: 0.00001532
Iteration 69/1000 | Loss: 0.00001532
Iteration 70/1000 | Loss: 0.00001532
Iteration 71/1000 | Loss: 0.00001532
Iteration 72/1000 | Loss: 0.00001532
Iteration 73/1000 | Loss: 0.00001531
Iteration 74/1000 | Loss: 0.00001531
Iteration 75/1000 | Loss: 0.00001531
Iteration 76/1000 | Loss: 0.00001530
Iteration 77/1000 | Loss: 0.00001530
Iteration 78/1000 | Loss: 0.00001530
Iteration 79/1000 | Loss: 0.00001529
Iteration 80/1000 | Loss: 0.00001529
Iteration 81/1000 | Loss: 0.00001529
Iteration 82/1000 | Loss: 0.00001528
Iteration 83/1000 | Loss: 0.00001528
Iteration 84/1000 | Loss: 0.00001528
Iteration 85/1000 | Loss: 0.00001528
Iteration 86/1000 | Loss: 0.00001527
Iteration 87/1000 | Loss: 0.00001527
Iteration 88/1000 | Loss: 0.00001526
Iteration 89/1000 | Loss: 0.00001526
Iteration 90/1000 | Loss: 0.00001525
Iteration 91/1000 | Loss: 0.00001525
Iteration 92/1000 | Loss: 0.00001524
Iteration 93/1000 | Loss: 0.00001524
Iteration 94/1000 | Loss: 0.00001524
Iteration 95/1000 | Loss: 0.00001523
Iteration 96/1000 | Loss: 0.00001523
Iteration 97/1000 | Loss: 0.00001523
Iteration 98/1000 | Loss: 0.00001523
Iteration 99/1000 | Loss: 0.00001523
Iteration 100/1000 | Loss: 0.00001523
Iteration 101/1000 | Loss: 0.00001523
Iteration 102/1000 | Loss: 0.00001522
Iteration 103/1000 | Loss: 0.00001522
Iteration 104/1000 | Loss: 0.00001522
Iteration 105/1000 | Loss: 0.00001522
Iteration 106/1000 | Loss: 0.00001522
Iteration 107/1000 | Loss: 0.00001521
Iteration 108/1000 | Loss: 0.00001521
Iteration 109/1000 | Loss: 0.00001521
Iteration 110/1000 | Loss: 0.00001521
Iteration 111/1000 | Loss: 0.00001520
Iteration 112/1000 | Loss: 0.00001520
Iteration 113/1000 | Loss: 0.00001520
Iteration 114/1000 | Loss: 0.00001520
Iteration 115/1000 | Loss: 0.00001519
Iteration 116/1000 | Loss: 0.00001519
Iteration 117/1000 | Loss: 0.00001519
Iteration 118/1000 | Loss: 0.00001519
Iteration 119/1000 | Loss: 0.00001518
Iteration 120/1000 | Loss: 0.00001518
Iteration 121/1000 | Loss: 0.00001518
Iteration 122/1000 | Loss: 0.00001518
Iteration 123/1000 | Loss: 0.00001518
Iteration 124/1000 | Loss: 0.00001518
Iteration 125/1000 | Loss: 0.00001517
Iteration 126/1000 | Loss: 0.00001517
Iteration 127/1000 | Loss: 0.00001517
Iteration 128/1000 | Loss: 0.00001517
Iteration 129/1000 | Loss: 0.00001517
Iteration 130/1000 | Loss: 0.00001517
Iteration 131/1000 | Loss: 0.00001517
Iteration 132/1000 | Loss: 0.00001517
Iteration 133/1000 | Loss: 0.00001517
Iteration 134/1000 | Loss: 0.00001517
Iteration 135/1000 | Loss: 0.00001517
Iteration 136/1000 | Loss: 0.00001517
Iteration 137/1000 | Loss: 0.00001517
Iteration 138/1000 | Loss: 0.00001517
Iteration 139/1000 | Loss: 0.00001516
Iteration 140/1000 | Loss: 0.00001516
Iteration 141/1000 | Loss: 0.00001515
Iteration 142/1000 | Loss: 0.00001515
Iteration 143/1000 | Loss: 0.00001515
Iteration 144/1000 | Loss: 0.00001515
Iteration 145/1000 | Loss: 0.00001515
Iteration 146/1000 | Loss: 0.00001515
Iteration 147/1000 | Loss: 0.00001515
Iteration 148/1000 | Loss: 0.00001515
Iteration 149/1000 | Loss: 0.00001515
Iteration 150/1000 | Loss: 0.00001515
Iteration 151/1000 | Loss: 0.00001515
Iteration 152/1000 | Loss: 0.00001515
Iteration 153/1000 | Loss: 0.00001514
Iteration 154/1000 | Loss: 0.00001514
Iteration 155/1000 | Loss: 0.00001514
Iteration 156/1000 | Loss: 0.00001514
Iteration 157/1000 | Loss: 0.00001514
Iteration 158/1000 | Loss: 0.00001514
Iteration 159/1000 | Loss: 0.00001514
Iteration 160/1000 | Loss: 0.00001514
Iteration 161/1000 | Loss: 0.00001514
Iteration 162/1000 | Loss: 0.00001513
Iteration 163/1000 | Loss: 0.00001513
Iteration 164/1000 | Loss: 0.00001513
Iteration 165/1000 | Loss: 0.00001513
Iteration 166/1000 | Loss: 0.00001513
Iteration 167/1000 | Loss: 0.00001513
Iteration 168/1000 | Loss: 0.00001513
Iteration 169/1000 | Loss: 0.00001513
Iteration 170/1000 | Loss: 0.00001513
Iteration 171/1000 | Loss: 0.00001512
Iteration 172/1000 | Loss: 0.00001512
Iteration 173/1000 | Loss: 0.00001512
Iteration 174/1000 | Loss: 0.00001512
Iteration 175/1000 | Loss: 0.00001512
Iteration 176/1000 | Loss: 0.00001512
Iteration 177/1000 | Loss: 0.00001512
Iteration 178/1000 | Loss: 0.00001512
Iteration 179/1000 | Loss: 0.00001512
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.5122050172067247e-05, 1.5122050172067247e-05, 1.5122050172067247e-05, 1.5122050172067247e-05, 1.5122050172067247e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5122050172067247e-05

Optimization complete. Final v2v error: 3.34519362449646 mm

Highest mean error: 3.682103395462036 mm for frame 25

Lowest mean error: 2.7229535579681396 mm for frame 167

Saving results

Total time: 51.39730167388916
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1068/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1068.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1068
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00959530
Iteration 2/25 | Loss: 0.00185338
Iteration 3/25 | Loss: 0.00157946
Iteration 4/25 | Loss: 0.00155898
Iteration 5/25 | Loss: 0.00155241
Iteration 6/25 | Loss: 0.00155227
Iteration 7/25 | Loss: 0.00155227
Iteration 8/25 | Loss: 0.00155227
Iteration 9/25 | Loss: 0.00155227
Iteration 10/25 | Loss: 0.00155227
Iteration 11/25 | Loss: 0.00155227
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0015522693283855915, 0.0015522693283855915, 0.0015522693283855915, 0.0015522693283855915, 0.0015522693283855915]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015522693283855915

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.48689732
Iteration 2/25 | Loss: 0.00192784
Iteration 3/25 | Loss: 0.00192783
Iteration 4/25 | Loss: 0.00192783
Iteration 5/25 | Loss: 0.00192783
Iteration 6/25 | Loss: 0.00192783
Iteration 7/25 | Loss: 0.00192783
Iteration 8/25 | Loss: 0.00192783
Iteration 9/25 | Loss: 0.00192783
Iteration 10/25 | Loss: 0.00192783
Iteration 11/25 | Loss: 0.00192783
Iteration 12/25 | Loss: 0.00192783
Iteration 13/25 | Loss: 0.00192783
Iteration 14/25 | Loss: 0.00192783
Iteration 15/25 | Loss: 0.00192783
Iteration 16/25 | Loss: 0.00192783
Iteration 17/25 | Loss: 0.00192783
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0019278321415185928, 0.0019278321415185928, 0.0019278321415185928, 0.0019278321415185928, 0.0019278321415185928]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019278321415185928

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00192783
Iteration 2/1000 | Loss: 0.00007273
Iteration 3/1000 | Loss: 0.00004978
Iteration 4/1000 | Loss: 0.00004302
Iteration 5/1000 | Loss: 0.00004079
Iteration 6/1000 | Loss: 0.00003924
Iteration 7/1000 | Loss: 0.00003814
Iteration 8/1000 | Loss: 0.00003756
Iteration 9/1000 | Loss: 0.00003699
Iteration 10/1000 | Loss: 0.00003653
Iteration 11/1000 | Loss: 0.00003610
Iteration 12/1000 | Loss: 0.00003571
Iteration 13/1000 | Loss: 0.00003539
Iteration 14/1000 | Loss: 0.00003505
Iteration 15/1000 | Loss: 0.00003477
Iteration 16/1000 | Loss: 0.00003445
Iteration 17/1000 | Loss: 0.00003413
Iteration 18/1000 | Loss: 0.00003382
Iteration 19/1000 | Loss: 0.00003362
Iteration 20/1000 | Loss: 0.00003347
Iteration 21/1000 | Loss: 0.00003337
Iteration 22/1000 | Loss: 0.00003327
Iteration 23/1000 | Loss: 0.00003322
Iteration 24/1000 | Loss: 0.00003321
Iteration 25/1000 | Loss: 0.00003320
Iteration 26/1000 | Loss: 0.00003318
Iteration 27/1000 | Loss: 0.00003318
Iteration 28/1000 | Loss: 0.00003317
Iteration 29/1000 | Loss: 0.00003317
Iteration 30/1000 | Loss: 0.00003317
Iteration 31/1000 | Loss: 0.00003316
Iteration 32/1000 | Loss: 0.00003312
Iteration 33/1000 | Loss: 0.00003309
Iteration 34/1000 | Loss: 0.00003308
Iteration 35/1000 | Loss: 0.00003307
Iteration 36/1000 | Loss: 0.00003306
Iteration 37/1000 | Loss: 0.00003306
Iteration 38/1000 | Loss: 0.00003306
Iteration 39/1000 | Loss: 0.00003306
Iteration 40/1000 | Loss: 0.00003304
Iteration 41/1000 | Loss: 0.00003304
Iteration 42/1000 | Loss: 0.00003303
Iteration 43/1000 | Loss: 0.00003303
Iteration 44/1000 | Loss: 0.00003303
Iteration 45/1000 | Loss: 0.00003303
Iteration 46/1000 | Loss: 0.00003303
Iteration 47/1000 | Loss: 0.00003302
Iteration 48/1000 | Loss: 0.00003302
Iteration 49/1000 | Loss: 0.00003302
Iteration 50/1000 | Loss: 0.00003302
Iteration 51/1000 | Loss: 0.00003302
Iteration 52/1000 | Loss: 0.00003302
Iteration 53/1000 | Loss: 0.00003301
Iteration 54/1000 | Loss: 0.00003301
Iteration 55/1000 | Loss: 0.00003301
Iteration 56/1000 | Loss: 0.00003301
Iteration 57/1000 | Loss: 0.00003300
Iteration 58/1000 | Loss: 0.00003300
Iteration 59/1000 | Loss: 0.00003300
Iteration 60/1000 | Loss: 0.00003300
Iteration 61/1000 | Loss: 0.00003299
Iteration 62/1000 | Loss: 0.00003299
Iteration 63/1000 | Loss: 0.00003299
Iteration 64/1000 | Loss: 0.00003299
Iteration 65/1000 | Loss: 0.00003299
Iteration 66/1000 | Loss: 0.00003298
Iteration 67/1000 | Loss: 0.00003298
Iteration 68/1000 | Loss: 0.00003298
Iteration 69/1000 | Loss: 0.00003298
Iteration 70/1000 | Loss: 0.00003298
Iteration 71/1000 | Loss: 0.00003298
Iteration 72/1000 | Loss: 0.00003297
Iteration 73/1000 | Loss: 0.00003297
Iteration 74/1000 | Loss: 0.00003297
Iteration 75/1000 | Loss: 0.00003297
Iteration 76/1000 | Loss: 0.00003297
Iteration 77/1000 | Loss: 0.00003297
Iteration 78/1000 | Loss: 0.00003297
Iteration 79/1000 | Loss: 0.00003297
Iteration 80/1000 | Loss: 0.00003297
Iteration 81/1000 | Loss: 0.00003297
Iteration 82/1000 | Loss: 0.00003297
Iteration 83/1000 | Loss: 0.00003297
Iteration 84/1000 | Loss: 0.00003297
Iteration 85/1000 | Loss: 0.00003296
Iteration 86/1000 | Loss: 0.00003296
Iteration 87/1000 | Loss: 0.00003296
Iteration 88/1000 | Loss: 0.00003296
Iteration 89/1000 | Loss: 0.00003296
Iteration 90/1000 | Loss: 0.00003296
Iteration 91/1000 | Loss: 0.00003296
Iteration 92/1000 | Loss: 0.00003295
Iteration 93/1000 | Loss: 0.00003295
Iteration 94/1000 | Loss: 0.00003295
Iteration 95/1000 | Loss: 0.00003295
Iteration 96/1000 | Loss: 0.00003295
Iteration 97/1000 | Loss: 0.00003295
Iteration 98/1000 | Loss: 0.00003295
Iteration 99/1000 | Loss: 0.00003295
Iteration 100/1000 | Loss: 0.00003295
Iteration 101/1000 | Loss: 0.00003295
Iteration 102/1000 | Loss: 0.00003295
Iteration 103/1000 | Loss: 0.00003295
Iteration 104/1000 | Loss: 0.00003295
Iteration 105/1000 | Loss: 0.00003295
Iteration 106/1000 | Loss: 0.00003295
Iteration 107/1000 | Loss: 0.00003294
Iteration 108/1000 | Loss: 0.00003294
Iteration 109/1000 | Loss: 0.00003294
Iteration 110/1000 | Loss: 0.00003294
Iteration 111/1000 | Loss: 0.00003294
Iteration 112/1000 | Loss: 0.00003294
Iteration 113/1000 | Loss: 0.00003294
Iteration 114/1000 | Loss: 0.00003294
Iteration 115/1000 | Loss: 0.00003294
Iteration 116/1000 | Loss: 0.00003294
Iteration 117/1000 | Loss: 0.00003294
Iteration 118/1000 | Loss: 0.00003294
Iteration 119/1000 | Loss: 0.00003293
Iteration 120/1000 | Loss: 0.00003293
Iteration 121/1000 | Loss: 0.00003293
Iteration 122/1000 | Loss: 0.00003293
Iteration 123/1000 | Loss: 0.00003293
Iteration 124/1000 | Loss: 0.00003293
Iteration 125/1000 | Loss: 0.00003293
Iteration 126/1000 | Loss: 0.00003293
Iteration 127/1000 | Loss: 0.00003293
Iteration 128/1000 | Loss: 0.00003293
Iteration 129/1000 | Loss: 0.00003293
Iteration 130/1000 | Loss: 0.00003293
Iteration 131/1000 | Loss: 0.00003293
Iteration 132/1000 | Loss: 0.00003292
Iteration 133/1000 | Loss: 0.00003292
Iteration 134/1000 | Loss: 0.00003292
Iteration 135/1000 | Loss: 0.00003292
Iteration 136/1000 | Loss: 0.00003292
Iteration 137/1000 | Loss: 0.00003292
Iteration 138/1000 | Loss: 0.00003292
Iteration 139/1000 | Loss: 0.00003292
Iteration 140/1000 | Loss: 0.00003292
Iteration 141/1000 | Loss: 0.00003292
Iteration 142/1000 | Loss: 0.00003292
Iteration 143/1000 | Loss: 0.00003292
Iteration 144/1000 | Loss: 0.00003291
Iteration 145/1000 | Loss: 0.00003291
Iteration 146/1000 | Loss: 0.00003291
Iteration 147/1000 | Loss: 0.00003291
Iteration 148/1000 | Loss: 0.00003291
Iteration 149/1000 | Loss: 0.00003291
Iteration 150/1000 | Loss: 0.00003291
Iteration 151/1000 | Loss: 0.00003291
Iteration 152/1000 | Loss: 0.00003291
Iteration 153/1000 | Loss: 0.00003291
Iteration 154/1000 | Loss: 0.00003291
Iteration 155/1000 | Loss: 0.00003291
Iteration 156/1000 | Loss: 0.00003291
Iteration 157/1000 | Loss: 0.00003291
Iteration 158/1000 | Loss: 0.00003291
Iteration 159/1000 | Loss: 0.00003290
Iteration 160/1000 | Loss: 0.00003290
Iteration 161/1000 | Loss: 0.00003290
Iteration 162/1000 | Loss: 0.00003290
Iteration 163/1000 | Loss: 0.00003290
Iteration 164/1000 | Loss: 0.00003290
Iteration 165/1000 | Loss: 0.00003290
Iteration 166/1000 | Loss: 0.00003290
Iteration 167/1000 | Loss: 0.00003290
Iteration 168/1000 | Loss: 0.00003290
Iteration 169/1000 | Loss: 0.00003290
Iteration 170/1000 | Loss: 0.00003290
Iteration 171/1000 | Loss: 0.00003290
Iteration 172/1000 | Loss: 0.00003290
Iteration 173/1000 | Loss: 0.00003289
Iteration 174/1000 | Loss: 0.00003289
Iteration 175/1000 | Loss: 0.00003289
Iteration 176/1000 | Loss: 0.00003289
Iteration 177/1000 | Loss: 0.00003289
Iteration 178/1000 | Loss: 0.00003289
Iteration 179/1000 | Loss: 0.00003289
Iteration 180/1000 | Loss: 0.00003288
Iteration 181/1000 | Loss: 0.00003288
Iteration 182/1000 | Loss: 0.00003288
Iteration 183/1000 | Loss: 0.00003288
Iteration 184/1000 | Loss: 0.00003288
Iteration 185/1000 | Loss: 0.00003288
Iteration 186/1000 | Loss: 0.00003288
Iteration 187/1000 | Loss: 0.00003288
Iteration 188/1000 | Loss: 0.00003288
Iteration 189/1000 | Loss: 0.00003288
Iteration 190/1000 | Loss: 0.00003288
Iteration 191/1000 | Loss: 0.00003288
Iteration 192/1000 | Loss: 0.00003288
Iteration 193/1000 | Loss: 0.00003288
Iteration 194/1000 | Loss: 0.00003287
Iteration 195/1000 | Loss: 0.00003287
Iteration 196/1000 | Loss: 0.00003287
Iteration 197/1000 | Loss: 0.00003287
Iteration 198/1000 | Loss: 0.00003287
Iteration 199/1000 | Loss: 0.00003287
Iteration 200/1000 | Loss: 0.00003287
Iteration 201/1000 | Loss: 0.00003287
Iteration 202/1000 | Loss: 0.00003287
Iteration 203/1000 | Loss: 0.00003287
Iteration 204/1000 | Loss: 0.00003287
Iteration 205/1000 | Loss: 0.00003286
Iteration 206/1000 | Loss: 0.00003286
Iteration 207/1000 | Loss: 0.00003286
Iteration 208/1000 | Loss: 0.00003286
Iteration 209/1000 | Loss: 0.00003286
Iteration 210/1000 | Loss: 0.00003286
Iteration 211/1000 | Loss: 0.00003286
Iteration 212/1000 | Loss: 0.00003286
Iteration 213/1000 | Loss: 0.00003286
Iteration 214/1000 | Loss: 0.00003286
Iteration 215/1000 | Loss: 0.00003286
Iteration 216/1000 | Loss: 0.00003286
Iteration 217/1000 | Loss: 0.00003286
Iteration 218/1000 | Loss: 0.00003286
Iteration 219/1000 | Loss: 0.00003286
Iteration 220/1000 | Loss: 0.00003285
Iteration 221/1000 | Loss: 0.00003285
Iteration 222/1000 | Loss: 0.00003285
Iteration 223/1000 | Loss: 0.00003285
Iteration 224/1000 | Loss: 0.00003285
Iteration 225/1000 | Loss: 0.00003285
Iteration 226/1000 | Loss: 0.00003285
Iteration 227/1000 | Loss: 0.00003285
Iteration 228/1000 | Loss: 0.00003285
Iteration 229/1000 | Loss: 0.00003285
Iteration 230/1000 | Loss: 0.00003285
Iteration 231/1000 | Loss: 0.00003285
Iteration 232/1000 | Loss: 0.00003285
Iteration 233/1000 | Loss: 0.00003285
Iteration 234/1000 | Loss: 0.00003285
Iteration 235/1000 | Loss: 0.00003285
Iteration 236/1000 | Loss: 0.00003285
Iteration 237/1000 | Loss: 0.00003284
Iteration 238/1000 | Loss: 0.00003284
Iteration 239/1000 | Loss: 0.00003284
Iteration 240/1000 | Loss: 0.00003284
Iteration 241/1000 | Loss: 0.00003284
Iteration 242/1000 | Loss: 0.00003284
Iteration 243/1000 | Loss: 0.00003284
Iteration 244/1000 | Loss: 0.00003284
Iteration 245/1000 | Loss: 0.00003284
Iteration 246/1000 | Loss: 0.00003284
Iteration 247/1000 | Loss: 0.00003284
Iteration 248/1000 | Loss: 0.00003284
Iteration 249/1000 | Loss: 0.00003284
Iteration 250/1000 | Loss: 0.00003284
Iteration 251/1000 | Loss: 0.00003284
Iteration 252/1000 | Loss: 0.00003284
Iteration 253/1000 | Loss: 0.00003284
Iteration 254/1000 | Loss: 0.00003284
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 254. Stopping optimization.
Last 5 losses: [3.2837891922099516e-05, 3.2837891922099516e-05, 3.2837891922099516e-05, 3.2837891922099516e-05, 3.2837891922099516e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.2837891922099516e-05

Optimization complete. Final v2v error: 4.833230495452881 mm

Highest mean error: 5.579765796661377 mm for frame 13

Lowest mean error: 4.497635364532471 mm for frame 46

Saving results

Total time: 55.957313537597656
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1079
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00810418
Iteration 2/25 | Loss: 0.00145196
Iteration 3/25 | Loss: 0.00136513
Iteration 4/25 | Loss: 0.00135221
Iteration 5/25 | Loss: 0.00134841
Iteration 6/25 | Loss: 0.00134805
Iteration 7/25 | Loss: 0.00134805
Iteration 8/25 | Loss: 0.00134805
Iteration 9/25 | Loss: 0.00134805
Iteration 10/25 | Loss: 0.00134805
Iteration 11/25 | Loss: 0.00134805
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013480467023327947, 0.0013480467023327947, 0.0013480467023327947, 0.0013480467023327947, 0.0013480467023327947]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013480467023327947

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.21052384
Iteration 2/25 | Loss: 0.00186592
Iteration 3/25 | Loss: 0.00186592
Iteration 4/25 | Loss: 0.00186591
Iteration 5/25 | Loss: 0.00186591
Iteration 6/25 | Loss: 0.00186591
Iteration 7/25 | Loss: 0.00186591
Iteration 8/25 | Loss: 0.00186591
Iteration 9/25 | Loss: 0.00186591
Iteration 10/25 | Loss: 0.00186591
Iteration 11/25 | Loss: 0.00186591
Iteration 12/25 | Loss: 0.00186591
Iteration 13/25 | Loss: 0.00186591
Iteration 14/25 | Loss: 0.00186591
Iteration 15/25 | Loss: 0.00186591
Iteration 16/25 | Loss: 0.00186591
Iteration 17/25 | Loss: 0.00186591
Iteration 18/25 | Loss: 0.00186591
Iteration 19/25 | Loss: 0.00186591
Iteration 20/25 | Loss: 0.00186591
Iteration 21/25 | Loss: 0.00186591
Iteration 22/25 | Loss: 0.00186591
Iteration 23/25 | Loss: 0.00186591
Iteration 24/25 | Loss: 0.00186591
Iteration 25/25 | Loss: 0.00186591

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00186591
Iteration 2/1000 | Loss: 0.00002856
Iteration 3/1000 | Loss: 0.00001944
Iteration 4/1000 | Loss: 0.00001709
Iteration 5/1000 | Loss: 0.00001595
Iteration 6/1000 | Loss: 0.00001521
Iteration 7/1000 | Loss: 0.00001467
Iteration 8/1000 | Loss: 0.00001440
Iteration 9/1000 | Loss: 0.00001402
Iteration 10/1000 | Loss: 0.00001381
Iteration 11/1000 | Loss: 0.00001367
Iteration 12/1000 | Loss: 0.00001361
Iteration 13/1000 | Loss: 0.00001356
Iteration 14/1000 | Loss: 0.00001339
Iteration 15/1000 | Loss: 0.00001320
Iteration 16/1000 | Loss: 0.00001310
Iteration 17/1000 | Loss: 0.00001308
Iteration 18/1000 | Loss: 0.00001307
Iteration 19/1000 | Loss: 0.00001301
Iteration 20/1000 | Loss: 0.00001292
Iteration 21/1000 | Loss: 0.00001286
Iteration 22/1000 | Loss: 0.00001284
Iteration 23/1000 | Loss: 0.00001284
Iteration 24/1000 | Loss: 0.00001277
Iteration 25/1000 | Loss: 0.00001274
Iteration 26/1000 | Loss: 0.00001273
Iteration 27/1000 | Loss: 0.00001273
Iteration 28/1000 | Loss: 0.00001272
Iteration 29/1000 | Loss: 0.00001271
Iteration 30/1000 | Loss: 0.00001270
Iteration 31/1000 | Loss: 0.00001266
Iteration 32/1000 | Loss: 0.00001266
Iteration 33/1000 | Loss: 0.00001266
Iteration 34/1000 | Loss: 0.00001266
Iteration 35/1000 | Loss: 0.00001266
Iteration 36/1000 | Loss: 0.00001266
Iteration 37/1000 | Loss: 0.00001266
Iteration 38/1000 | Loss: 0.00001264
Iteration 39/1000 | Loss: 0.00001262
Iteration 40/1000 | Loss: 0.00001260
Iteration 41/1000 | Loss: 0.00001260
Iteration 42/1000 | Loss: 0.00001260
Iteration 43/1000 | Loss: 0.00001260
Iteration 44/1000 | Loss: 0.00001259
Iteration 45/1000 | Loss: 0.00001259
Iteration 46/1000 | Loss: 0.00001258
Iteration 47/1000 | Loss: 0.00001258
Iteration 48/1000 | Loss: 0.00001258
Iteration 49/1000 | Loss: 0.00001257
Iteration 50/1000 | Loss: 0.00001256
Iteration 51/1000 | Loss: 0.00001255
Iteration 52/1000 | Loss: 0.00001255
Iteration 53/1000 | Loss: 0.00001255
Iteration 54/1000 | Loss: 0.00001255
Iteration 55/1000 | Loss: 0.00001255
Iteration 56/1000 | Loss: 0.00001255
Iteration 57/1000 | Loss: 0.00001255
Iteration 58/1000 | Loss: 0.00001255
Iteration 59/1000 | Loss: 0.00001254
Iteration 60/1000 | Loss: 0.00001254
Iteration 61/1000 | Loss: 0.00001254
Iteration 62/1000 | Loss: 0.00001254
Iteration 63/1000 | Loss: 0.00001254
Iteration 64/1000 | Loss: 0.00001254
Iteration 65/1000 | Loss: 0.00001253
Iteration 66/1000 | Loss: 0.00001253
Iteration 67/1000 | Loss: 0.00001253
Iteration 68/1000 | Loss: 0.00001253
Iteration 69/1000 | Loss: 0.00001253
Iteration 70/1000 | Loss: 0.00001252
Iteration 71/1000 | Loss: 0.00001252
Iteration 72/1000 | Loss: 0.00001252
Iteration 73/1000 | Loss: 0.00001252
Iteration 74/1000 | Loss: 0.00001252
Iteration 75/1000 | Loss: 0.00001252
Iteration 76/1000 | Loss: 0.00001252
Iteration 77/1000 | Loss: 0.00001252
Iteration 78/1000 | Loss: 0.00001252
Iteration 79/1000 | Loss: 0.00001252
Iteration 80/1000 | Loss: 0.00001252
Iteration 81/1000 | Loss: 0.00001252
Iteration 82/1000 | Loss: 0.00001251
Iteration 83/1000 | Loss: 0.00001251
Iteration 84/1000 | Loss: 0.00001251
Iteration 85/1000 | Loss: 0.00001251
Iteration 86/1000 | Loss: 0.00001251
Iteration 87/1000 | Loss: 0.00001251
Iteration 88/1000 | Loss: 0.00001250
Iteration 89/1000 | Loss: 0.00001250
Iteration 90/1000 | Loss: 0.00001250
Iteration 91/1000 | Loss: 0.00001250
Iteration 92/1000 | Loss: 0.00001250
Iteration 93/1000 | Loss: 0.00001250
Iteration 94/1000 | Loss: 0.00001250
Iteration 95/1000 | Loss: 0.00001250
Iteration 96/1000 | Loss: 0.00001250
Iteration 97/1000 | Loss: 0.00001250
Iteration 98/1000 | Loss: 0.00001249
Iteration 99/1000 | Loss: 0.00001249
Iteration 100/1000 | Loss: 0.00001249
Iteration 101/1000 | Loss: 0.00001249
Iteration 102/1000 | Loss: 0.00001249
Iteration 103/1000 | Loss: 0.00001249
Iteration 104/1000 | Loss: 0.00001249
Iteration 105/1000 | Loss: 0.00001248
Iteration 106/1000 | Loss: 0.00001248
Iteration 107/1000 | Loss: 0.00001248
Iteration 108/1000 | Loss: 0.00001247
Iteration 109/1000 | Loss: 0.00001247
Iteration 110/1000 | Loss: 0.00001247
Iteration 111/1000 | Loss: 0.00001247
Iteration 112/1000 | Loss: 0.00001247
Iteration 113/1000 | Loss: 0.00001247
Iteration 114/1000 | Loss: 0.00001247
Iteration 115/1000 | Loss: 0.00001247
Iteration 116/1000 | Loss: 0.00001247
Iteration 117/1000 | Loss: 0.00001247
Iteration 118/1000 | Loss: 0.00001247
Iteration 119/1000 | Loss: 0.00001247
Iteration 120/1000 | Loss: 0.00001247
Iteration 121/1000 | Loss: 0.00001247
Iteration 122/1000 | Loss: 0.00001247
Iteration 123/1000 | Loss: 0.00001247
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.2468870409065858e-05, 1.2468870409065858e-05, 1.2468870409065858e-05, 1.2468870409065858e-05, 1.2468870409065858e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2468870409065858e-05

Optimization complete. Final v2v error: 3.000002384185791 mm

Highest mean error: 4.127024173736572 mm for frame 56

Lowest mean error: 2.6785826683044434 mm for frame 108

Saving results

Total time: 39.376981258392334
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00957093
Iteration 2/25 | Loss: 0.00957092
Iteration 3/25 | Loss: 0.00957092
Iteration 4/25 | Loss: 0.00957092
Iteration 5/25 | Loss: 0.00957092
Iteration 6/25 | Loss: 0.00957092
Iteration 7/25 | Loss: 0.00957092
Iteration 8/25 | Loss: 0.00957092
Iteration 9/25 | Loss: 0.00957092
Iteration 10/25 | Loss: 0.00957092
Iteration 11/25 | Loss: 0.00957092
Iteration 12/25 | Loss: 0.00957092
Iteration 13/25 | Loss: 0.00957092
Iteration 14/25 | Loss: 0.00957091
Iteration 15/25 | Loss: 0.00957091
Iteration 16/25 | Loss: 0.00957091
Iteration 17/25 | Loss: 0.00957091
Iteration 18/25 | Loss: 0.00957091
Iteration 19/25 | Loss: 0.00957091
Iteration 20/25 | Loss: 0.00957091
Iteration 21/25 | Loss: 0.00957091
Iteration 22/25 | Loss: 0.00957091
Iteration 23/25 | Loss: 0.00957091
Iteration 24/25 | Loss: 0.00957091
Iteration 25/25 | Loss: 0.00957091

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41396940
Iteration 2/25 | Loss: 0.18809353
Iteration 3/25 | Loss: 0.18808523
Iteration 4/25 | Loss: 0.18808514
Iteration 5/25 | Loss: 0.18808512
Iteration 6/25 | Loss: 0.18808511
Iteration 7/25 | Loss: 0.18808511
Iteration 8/25 | Loss: 0.18808511
Iteration 9/25 | Loss: 0.18808508
Iteration 10/25 | Loss: 0.18808508
Iteration 11/25 | Loss: 0.18808508
Iteration 12/25 | Loss: 0.18808508
Iteration 13/25 | Loss: 0.18808508
Iteration 14/25 | Loss: 0.18808508
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.18808507919311523, 0.18808507919311523, 0.18808507919311523, 0.18808507919311523, 0.18808507919311523]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.18808507919311523

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.18808508
Iteration 2/1000 | Loss: 0.00972262
Iteration 3/1000 | Loss: 0.00388250
Iteration 4/1000 | Loss: 0.00649043
Iteration 5/1000 | Loss: 0.00290759
Iteration 6/1000 | Loss: 0.00162941
Iteration 7/1000 | Loss: 0.00203034
Iteration 8/1000 | Loss: 0.00238404
Iteration 9/1000 | Loss: 0.00049154
Iteration 10/1000 | Loss: 0.00062297
Iteration 11/1000 | Loss: 0.00123768
Iteration 12/1000 | Loss: 0.00022003
Iteration 13/1000 | Loss: 0.00089973
Iteration 14/1000 | Loss: 0.00060033
Iteration 15/1000 | Loss: 0.00022486
Iteration 16/1000 | Loss: 0.00072237
Iteration 17/1000 | Loss: 0.00126575
Iteration 18/1000 | Loss: 0.00060984
Iteration 19/1000 | Loss: 0.00011420
Iteration 20/1000 | Loss: 0.00025757
Iteration 21/1000 | Loss: 0.00005915
Iteration 22/1000 | Loss: 0.00017788
Iteration 23/1000 | Loss: 0.00004146
Iteration 24/1000 | Loss: 0.00012730
Iteration 25/1000 | Loss: 0.00015268
Iteration 26/1000 | Loss: 0.00004498
Iteration 27/1000 | Loss: 0.00003278
Iteration 28/1000 | Loss: 0.00030354
Iteration 29/1000 | Loss: 0.00152733
Iteration 30/1000 | Loss: 0.00018380
Iteration 31/1000 | Loss: 0.00002883
Iteration 32/1000 | Loss: 0.00002738
Iteration 33/1000 | Loss: 0.00002640
Iteration 34/1000 | Loss: 0.00011321
Iteration 35/1000 | Loss: 0.00029692
Iteration 36/1000 | Loss: 0.00006763
Iteration 37/1000 | Loss: 0.00005466
Iteration 38/1000 | Loss: 0.00006113
Iteration 39/1000 | Loss: 0.00002492
Iteration 40/1000 | Loss: 0.00002455
Iteration 41/1000 | Loss: 0.00002415
Iteration 42/1000 | Loss: 0.00012616
Iteration 43/1000 | Loss: 0.00022105
Iteration 44/1000 | Loss: 0.00016028
Iteration 45/1000 | Loss: 0.00002438
Iteration 46/1000 | Loss: 0.00023895
Iteration 47/1000 | Loss: 0.00004700
Iteration 48/1000 | Loss: 0.00006995
Iteration 49/1000 | Loss: 0.00013247
Iteration 50/1000 | Loss: 0.00002981
Iteration 51/1000 | Loss: 0.00003096
Iteration 52/1000 | Loss: 0.00002318
Iteration 53/1000 | Loss: 0.00005453
Iteration 54/1000 | Loss: 0.00002472
Iteration 55/1000 | Loss: 0.00003033
Iteration 56/1000 | Loss: 0.00002284
Iteration 57/1000 | Loss: 0.00008226
Iteration 58/1000 | Loss: 0.00006652
Iteration 59/1000 | Loss: 0.00002286
Iteration 60/1000 | Loss: 0.00002273
Iteration 61/1000 | Loss: 0.00002273
Iteration 62/1000 | Loss: 0.00002273
Iteration 63/1000 | Loss: 0.00002273
Iteration 64/1000 | Loss: 0.00002273
Iteration 65/1000 | Loss: 0.00002273
Iteration 66/1000 | Loss: 0.00002273
Iteration 67/1000 | Loss: 0.00002273
Iteration 68/1000 | Loss: 0.00002273
Iteration 69/1000 | Loss: 0.00002272
Iteration 70/1000 | Loss: 0.00002272
Iteration 71/1000 | Loss: 0.00002271
Iteration 72/1000 | Loss: 0.00002271
Iteration 73/1000 | Loss: 0.00002271
Iteration 74/1000 | Loss: 0.00002270
Iteration 75/1000 | Loss: 0.00002270
Iteration 76/1000 | Loss: 0.00002270
Iteration 77/1000 | Loss: 0.00002270
Iteration 78/1000 | Loss: 0.00002270
Iteration 79/1000 | Loss: 0.00002270
Iteration 80/1000 | Loss: 0.00002270
Iteration 81/1000 | Loss: 0.00002270
Iteration 82/1000 | Loss: 0.00002270
Iteration 83/1000 | Loss: 0.00002270
Iteration 84/1000 | Loss: 0.00002270
Iteration 85/1000 | Loss: 0.00002270
Iteration 86/1000 | Loss: 0.00002269
Iteration 87/1000 | Loss: 0.00002269
Iteration 88/1000 | Loss: 0.00002269
Iteration 89/1000 | Loss: 0.00002269
Iteration 90/1000 | Loss: 0.00002269
Iteration 91/1000 | Loss: 0.00002269
Iteration 92/1000 | Loss: 0.00002269
Iteration 93/1000 | Loss: 0.00002268
Iteration 94/1000 | Loss: 0.00002268
Iteration 95/1000 | Loss: 0.00002268
Iteration 96/1000 | Loss: 0.00002268
Iteration 97/1000 | Loss: 0.00002268
Iteration 98/1000 | Loss: 0.00002268
Iteration 99/1000 | Loss: 0.00002268
Iteration 100/1000 | Loss: 0.00002267
Iteration 101/1000 | Loss: 0.00002267
Iteration 102/1000 | Loss: 0.00002267
Iteration 103/1000 | Loss: 0.00002267
Iteration 104/1000 | Loss: 0.00002267
Iteration 105/1000 | Loss: 0.00002267
Iteration 106/1000 | Loss: 0.00002267
Iteration 107/1000 | Loss: 0.00002267
Iteration 108/1000 | Loss: 0.00002267
Iteration 109/1000 | Loss: 0.00002267
Iteration 110/1000 | Loss: 0.00002267
Iteration 111/1000 | Loss: 0.00002266
Iteration 112/1000 | Loss: 0.00002266
Iteration 113/1000 | Loss: 0.00002266
Iteration 114/1000 | Loss: 0.00002266
Iteration 115/1000 | Loss: 0.00002266
Iteration 116/1000 | Loss: 0.00002266
Iteration 117/1000 | Loss: 0.00002265
Iteration 118/1000 | Loss: 0.00002265
Iteration 119/1000 | Loss: 0.00002265
Iteration 120/1000 | Loss: 0.00002265
Iteration 121/1000 | Loss: 0.00002265
Iteration 122/1000 | Loss: 0.00002264
Iteration 123/1000 | Loss: 0.00002264
Iteration 124/1000 | Loss: 0.00002264
Iteration 125/1000 | Loss: 0.00002264
Iteration 126/1000 | Loss: 0.00002262
Iteration 127/1000 | Loss: 0.00002262
Iteration 128/1000 | Loss: 0.00002262
Iteration 129/1000 | Loss: 0.00002262
Iteration 130/1000 | Loss: 0.00002261
Iteration 131/1000 | Loss: 0.00002261
Iteration 132/1000 | Loss: 0.00002261
Iteration 133/1000 | Loss: 0.00002261
Iteration 134/1000 | Loss: 0.00002261
Iteration 135/1000 | Loss: 0.00002261
Iteration 136/1000 | Loss: 0.00002260
Iteration 137/1000 | Loss: 0.00002260
Iteration 138/1000 | Loss: 0.00002259
Iteration 139/1000 | Loss: 0.00002259
Iteration 140/1000 | Loss: 0.00002259
Iteration 141/1000 | Loss: 0.00002259
Iteration 142/1000 | Loss: 0.00002259
Iteration 143/1000 | Loss: 0.00002259
Iteration 144/1000 | Loss: 0.00002259
Iteration 145/1000 | Loss: 0.00002259
Iteration 146/1000 | Loss: 0.00002259
Iteration 147/1000 | Loss: 0.00002258
Iteration 148/1000 | Loss: 0.00002258
Iteration 149/1000 | Loss: 0.00002258
Iteration 150/1000 | Loss: 0.00002258
Iteration 151/1000 | Loss: 0.00002258
Iteration 152/1000 | Loss: 0.00002258
Iteration 153/1000 | Loss: 0.00002258
Iteration 154/1000 | Loss: 0.00002258
Iteration 155/1000 | Loss: 0.00002258
Iteration 156/1000 | Loss: 0.00002258
Iteration 157/1000 | Loss: 0.00002258
Iteration 158/1000 | Loss: 0.00002258
Iteration 159/1000 | Loss: 0.00002258
Iteration 160/1000 | Loss: 0.00002258
Iteration 161/1000 | Loss: 0.00002258
Iteration 162/1000 | Loss: 0.00002258
Iteration 163/1000 | Loss: 0.00002258
Iteration 164/1000 | Loss: 0.00002258
Iteration 165/1000 | Loss: 0.00002258
Iteration 166/1000 | Loss: 0.00002258
Iteration 167/1000 | Loss: 0.00002258
Iteration 168/1000 | Loss: 0.00002258
Iteration 169/1000 | Loss: 0.00002258
Iteration 170/1000 | Loss: 0.00002258
Iteration 171/1000 | Loss: 0.00002258
Iteration 172/1000 | Loss: 0.00002258
Iteration 173/1000 | Loss: 0.00002258
Iteration 174/1000 | Loss: 0.00002258
Iteration 175/1000 | Loss: 0.00002258
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 175. Stopping optimization.
Last 5 losses: [2.2580119548365474e-05, 2.2580119548365474e-05, 2.2580119548365474e-05, 2.2580119548365474e-05, 2.2580119548365474e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2580119548365474e-05

Optimization complete. Final v2v error: 4.126883029937744 mm

Highest mean error: 4.327282905578613 mm for frame 218

Lowest mean error: 3.8556034564971924 mm for frame 17

Saving results

Total time: 106.64478826522827
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00798795
Iteration 2/25 | Loss: 0.00151186
Iteration 3/25 | Loss: 0.00137361
Iteration 4/25 | Loss: 0.00136105
Iteration 5/25 | Loss: 0.00135874
Iteration 6/25 | Loss: 0.00135874
Iteration 7/25 | Loss: 0.00135874
Iteration 8/25 | Loss: 0.00135874
Iteration 9/25 | Loss: 0.00135874
Iteration 10/25 | Loss: 0.00135874
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0013587437570095062, 0.0013587437570095062, 0.0013587437570095062, 0.0013587437570095062, 0.0013587437570095062]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013587437570095062

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26673877
Iteration 2/25 | Loss: 0.00190238
Iteration 3/25 | Loss: 0.00190238
Iteration 4/25 | Loss: 0.00190238
Iteration 5/25 | Loss: 0.00190238
Iteration 6/25 | Loss: 0.00190238
Iteration 7/25 | Loss: 0.00190238
Iteration 8/25 | Loss: 0.00190238
Iteration 9/25 | Loss: 0.00190238
Iteration 10/25 | Loss: 0.00190238
Iteration 11/25 | Loss: 0.00190238
Iteration 12/25 | Loss: 0.00190238
Iteration 13/25 | Loss: 0.00190238
Iteration 14/25 | Loss: 0.00190238
Iteration 15/25 | Loss: 0.00190238
Iteration 16/25 | Loss: 0.00190238
Iteration 17/25 | Loss: 0.00190238
Iteration 18/25 | Loss: 0.00190238
Iteration 19/25 | Loss: 0.00190238
Iteration 20/25 | Loss: 0.00190238
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0019023766508325934, 0.0019023766508325934, 0.0019023766508325934, 0.0019023766508325934, 0.0019023766508325934]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019023766508325934

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00190238
Iteration 2/1000 | Loss: 0.00002452
Iteration 3/1000 | Loss: 0.00001704
Iteration 4/1000 | Loss: 0.00001570
Iteration 5/1000 | Loss: 0.00001451
Iteration 6/1000 | Loss: 0.00001365
Iteration 7/1000 | Loss: 0.00001316
Iteration 8/1000 | Loss: 0.00001286
Iteration 9/1000 | Loss: 0.00001237
Iteration 10/1000 | Loss: 0.00001204
Iteration 11/1000 | Loss: 0.00001195
Iteration 12/1000 | Loss: 0.00001176
Iteration 13/1000 | Loss: 0.00001165
Iteration 14/1000 | Loss: 0.00001165
Iteration 15/1000 | Loss: 0.00001165
Iteration 16/1000 | Loss: 0.00001161
Iteration 17/1000 | Loss: 0.00001159
Iteration 18/1000 | Loss: 0.00001146
Iteration 19/1000 | Loss: 0.00001145
Iteration 20/1000 | Loss: 0.00001142
Iteration 21/1000 | Loss: 0.00001138
Iteration 22/1000 | Loss: 0.00001136
Iteration 23/1000 | Loss: 0.00001136
Iteration 24/1000 | Loss: 0.00001135
Iteration 25/1000 | Loss: 0.00001132
Iteration 26/1000 | Loss: 0.00001131
Iteration 27/1000 | Loss: 0.00001130
Iteration 28/1000 | Loss: 0.00001129
Iteration 29/1000 | Loss: 0.00001129
Iteration 30/1000 | Loss: 0.00001127
Iteration 31/1000 | Loss: 0.00001127
Iteration 32/1000 | Loss: 0.00001126
Iteration 33/1000 | Loss: 0.00001125
Iteration 34/1000 | Loss: 0.00001125
Iteration 35/1000 | Loss: 0.00001124
Iteration 36/1000 | Loss: 0.00001124
Iteration 37/1000 | Loss: 0.00001124
Iteration 38/1000 | Loss: 0.00001123
Iteration 39/1000 | Loss: 0.00001121
Iteration 40/1000 | Loss: 0.00001121
Iteration 41/1000 | Loss: 0.00001119
Iteration 42/1000 | Loss: 0.00001118
Iteration 43/1000 | Loss: 0.00001118
Iteration 44/1000 | Loss: 0.00001118
Iteration 45/1000 | Loss: 0.00001117
Iteration 46/1000 | Loss: 0.00001117
Iteration 47/1000 | Loss: 0.00001116
Iteration 48/1000 | Loss: 0.00001116
Iteration 49/1000 | Loss: 0.00001115
Iteration 50/1000 | Loss: 0.00001114
Iteration 51/1000 | Loss: 0.00001114
Iteration 52/1000 | Loss: 0.00001113
Iteration 53/1000 | Loss: 0.00001112
Iteration 54/1000 | Loss: 0.00001111
Iteration 55/1000 | Loss: 0.00001111
Iteration 56/1000 | Loss: 0.00001111
Iteration 57/1000 | Loss: 0.00001110
Iteration 58/1000 | Loss: 0.00001109
Iteration 59/1000 | Loss: 0.00001109
Iteration 60/1000 | Loss: 0.00001109
Iteration 61/1000 | Loss: 0.00001108
Iteration 62/1000 | Loss: 0.00001108
Iteration 63/1000 | Loss: 0.00001107
Iteration 64/1000 | Loss: 0.00001107
Iteration 65/1000 | Loss: 0.00001106
Iteration 66/1000 | Loss: 0.00001106
Iteration 67/1000 | Loss: 0.00001106
Iteration 68/1000 | Loss: 0.00001105
Iteration 69/1000 | Loss: 0.00001105
Iteration 70/1000 | Loss: 0.00001104
Iteration 71/1000 | Loss: 0.00001104
Iteration 72/1000 | Loss: 0.00001104
Iteration 73/1000 | Loss: 0.00001104
Iteration 74/1000 | Loss: 0.00001104
Iteration 75/1000 | Loss: 0.00001103
Iteration 76/1000 | Loss: 0.00001103
Iteration 77/1000 | Loss: 0.00001103
Iteration 78/1000 | Loss: 0.00001103
Iteration 79/1000 | Loss: 0.00001103
Iteration 80/1000 | Loss: 0.00001102
Iteration 81/1000 | Loss: 0.00001102
Iteration 82/1000 | Loss: 0.00001102
Iteration 83/1000 | Loss: 0.00001101
Iteration 84/1000 | Loss: 0.00001101
Iteration 85/1000 | Loss: 0.00001101
Iteration 86/1000 | Loss: 0.00001100
Iteration 87/1000 | Loss: 0.00001100
Iteration 88/1000 | Loss: 0.00001100
Iteration 89/1000 | Loss: 0.00001099
Iteration 90/1000 | Loss: 0.00001099
Iteration 91/1000 | Loss: 0.00001099
Iteration 92/1000 | Loss: 0.00001099
Iteration 93/1000 | Loss: 0.00001099
Iteration 94/1000 | Loss: 0.00001099
Iteration 95/1000 | Loss: 0.00001099
Iteration 96/1000 | Loss: 0.00001099
Iteration 97/1000 | Loss: 0.00001099
Iteration 98/1000 | Loss: 0.00001099
Iteration 99/1000 | Loss: 0.00001098
Iteration 100/1000 | Loss: 0.00001098
Iteration 101/1000 | Loss: 0.00001097
Iteration 102/1000 | Loss: 0.00001097
Iteration 103/1000 | Loss: 0.00001096
Iteration 104/1000 | Loss: 0.00001096
Iteration 105/1000 | Loss: 0.00001096
Iteration 106/1000 | Loss: 0.00001095
Iteration 107/1000 | Loss: 0.00001095
Iteration 108/1000 | Loss: 0.00001095
Iteration 109/1000 | Loss: 0.00001095
Iteration 110/1000 | Loss: 0.00001095
Iteration 111/1000 | Loss: 0.00001094
Iteration 112/1000 | Loss: 0.00001094
Iteration 113/1000 | Loss: 0.00001093
Iteration 114/1000 | Loss: 0.00001093
Iteration 115/1000 | Loss: 0.00001093
Iteration 116/1000 | Loss: 0.00001093
Iteration 117/1000 | Loss: 0.00001093
Iteration 118/1000 | Loss: 0.00001092
Iteration 119/1000 | Loss: 0.00001092
Iteration 120/1000 | Loss: 0.00001092
Iteration 121/1000 | Loss: 0.00001092
Iteration 122/1000 | Loss: 0.00001091
Iteration 123/1000 | Loss: 0.00001091
Iteration 124/1000 | Loss: 0.00001091
Iteration 125/1000 | Loss: 0.00001091
Iteration 126/1000 | Loss: 0.00001091
Iteration 127/1000 | Loss: 0.00001091
Iteration 128/1000 | Loss: 0.00001091
Iteration 129/1000 | Loss: 0.00001091
Iteration 130/1000 | Loss: 0.00001091
Iteration 131/1000 | Loss: 0.00001090
Iteration 132/1000 | Loss: 0.00001090
Iteration 133/1000 | Loss: 0.00001090
Iteration 134/1000 | Loss: 0.00001090
Iteration 135/1000 | Loss: 0.00001089
Iteration 136/1000 | Loss: 0.00001089
Iteration 137/1000 | Loss: 0.00001089
Iteration 138/1000 | Loss: 0.00001089
Iteration 139/1000 | Loss: 0.00001088
Iteration 140/1000 | Loss: 0.00001088
Iteration 141/1000 | Loss: 0.00001088
Iteration 142/1000 | Loss: 0.00001088
Iteration 143/1000 | Loss: 0.00001088
Iteration 144/1000 | Loss: 0.00001088
Iteration 145/1000 | Loss: 0.00001088
Iteration 146/1000 | Loss: 0.00001088
Iteration 147/1000 | Loss: 0.00001088
Iteration 148/1000 | Loss: 0.00001088
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.088457884179661e-05, 1.088457884179661e-05, 1.088457884179661e-05, 1.088457884179661e-05, 1.088457884179661e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.088457884179661e-05

Optimization complete. Final v2v error: 2.846034288406372 mm

Highest mean error: 2.9980084896087646 mm for frame 150

Lowest mean error: 2.69500732421875 mm for frame 76

Saving results

Total time: 44.48934030532837
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00863089
Iteration 2/25 | Loss: 0.00142122
Iteration 3/25 | Loss: 0.00135883
Iteration 4/25 | Loss: 0.00135099
Iteration 5/25 | Loss: 0.00134903
Iteration 6/25 | Loss: 0.00134903
Iteration 7/25 | Loss: 0.00134903
Iteration 8/25 | Loss: 0.00134903
Iteration 9/25 | Loss: 0.00134903
Iteration 10/25 | Loss: 0.00134903
Iteration 11/25 | Loss: 0.00134903
Iteration 12/25 | Loss: 0.00134903
Iteration 13/25 | Loss: 0.00134903
Iteration 14/25 | Loss: 0.00134903
Iteration 15/25 | Loss: 0.00134903
Iteration 16/25 | Loss: 0.00134903
Iteration 17/25 | Loss: 0.00134903
Iteration 18/25 | Loss: 0.00134903
Iteration 19/25 | Loss: 0.00134903
Iteration 20/25 | Loss: 0.00134903
Iteration 21/25 | Loss: 0.00134903
Iteration 22/25 | Loss: 0.00134903
Iteration 23/25 | Loss: 0.00134903
Iteration 24/25 | Loss: 0.00134903
Iteration 25/25 | Loss: 0.00134903

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.84475636
Iteration 2/25 | Loss: 0.00193609
Iteration 3/25 | Loss: 0.00193608
Iteration 4/25 | Loss: 0.00193608
Iteration 5/25 | Loss: 0.00193608
Iteration 6/25 | Loss: 0.00193608
Iteration 7/25 | Loss: 0.00193608
Iteration 8/25 | Loss: 0.00193608
Iteration 9/25 | Loss: 0.00193608
Iteration 10/25 | Loss: 0.00193608
Iteration 11/25 | Loss: 0.00193608
Iteration 12/25 | Loss: 0.00193608
Iteration 13/25 | Loss: 0.00193608
Iteration 14/25 | Loss: 0.00193608
Iteration 15/25 | Loss: 0.00193608
Iteration 16/25 | Loss: 0.00193608
Iteration 17/25 | Loss: 0.00193608
Iteration 18/25 | Loss: 0.00193608
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0019360758597031236, 0.0019360758597031236, 0.0019360758597031236, 0.0019360758597031236, 0.0019360758597031236]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019360758597031236

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00193608
Iteration 2/1000 | Loss: 0.00003142
Iteration 3/1000 | Loss: 0.00002098
Iteration 4/1000 | Loss: 0.00001713
Iteration 5/1000 | Loss: 0.00001552
Iteration 6/1000 | Loss: 0.00001454
Iteration 7/1000 | Loss: 0.00001395
Iteration 8/1000 | Loss: 0.00001342
Iteration 9/1000 | Loss: 0.00001305
Iteration 10/1000 | Loss: 0.00001278
Iteration 11/1000 | Loss: 0.00001249
Iteration 12/1000 | Loss: 0.00001226
Iteration 13/1000 | Loss: 0.00001225
Iteration 14/1000 | Loss: 0.00001225
Iteration 15/1000 | Loss: 0.00001214
Iteration 16/1000 | Loss: 0.00001211
Iteration 17/1000 | Loss: 0.00001210
Iteration 18/1000 | Loss: 0.00001198
Iteration 19/1000 | Loss: 0.00001185
Iteration 20/1000 | Loss: 0.00001181
Iteration 21/1000 | Loss: 0.00001177
Iteration 22/1000 | Loss: 0.00001176
Iteration 23/1000 | Loss: 0.00001175
Iteration 24/1000 | Loss: 0.00001167
Iteration 25/1000 | Loss: 0.00001166
Iteration 26/1000 | Loss: 0.00001158
Iteration 27/1000 | Loss: 0.00001157
Iteration 28/1000 | Loss: 0.00001154
Iteration 29/1000 | Loss: 0.00001154
Iteration 30/1000 | Loss: 0.00001153
Iteration 31/1000 | Loss: 0.00001152
Iteration 32/1000 | Loss: 0.00001152
Iteration 33/1000 | Loss: 0.00001151
Iteration 34/1000 | Loss: 0.00001150
Iteration 35/1000 | Loss: 0.00001150
Iteration 36/1000 | Loss: 0.00001149
Iteration 37/1000 | Loss: 0.00001148
Iteration 38/1000 | Loss: 0.00001148
Iteration 39/1000 | Loss: 0.00001147
Iteration 40/1000 | Loss: 0.00001147
Iteration 41/1000 | Loss: 0.00001147
Iteration 42/1000 | Loss: 0.00001146
Iteration 43/1000 | Loss: 0.00001146
Iteration 44/1000 | Loss: 0.00001146
Iteration 45/1000 | Loss: 0.00001145
Iteration 46/1000 | Loss: 0.00001142
Iteration 47/1000 | Loss: 0.00001141
Iteration 48/1000 | Loss: 0.00001140
Iteration 49/1000 | Loss: 0.00001140
Iteration 50/1000 | Loss: 0.00001129
Iteration 51/1000 | Loss: 0.00001122
Iteration 52/1000 | Loss: 0.00001122
Iteration 53/1000 | Loss: 0.00001120
Iteration 54/1000 | Loss: 0.00001119
Iteration 55/1000 | Loss: 0.00001118
Iteration 56/1000 | Loss: 0.00001118
Iteration 57/1000 | Loss: 0.00001117
Iteration 58/1000 | Loss: 0.00001116
Iteration 59/1000 | Loss: 0.00001113
Iteration 60/1000 | Loss: 0.00001112
Iteration 61/1000 | Loss: 0.00001112
Iteration 62/1000 | Loss: 0.00001112
Iteration 63/1000 | Loss: 0.00001112
Iteration 64/1000 | Loss: 0.00001112
Iteration 65/1000 | Loss: 0.00001112
Iteration 66/1000 | Loss: 0.00001111
Iteration 67/1000 | Loss: 0.00001111
Iteration 68/1000 | Loss: 0.00001111
Iteration 69/1000 | Loss: 0.00001110
Iteration 70/1000 | Loss: 0.00001110
Iteration 71/1000 | Loss: 0.00001110
Iteration 72/1000 | Loss: 0.00001110
Iteration 73/1000 | Loss: 0.00001109
Iteration 74/1000 | Loss: 0.00001109
Iteration 75/1000 | Loss: 0.00001108
Iteration 76/1000 | Loss: 0.00001107
Iteration 77/1000 | Loss: 0.00001107
Iteration 78/1000 | Loss: 0.00001107
Iteration 79/1000 | Loss: 0.00001106
Iteration 80/1000 | Loss: 0.00001106
Iteration 81/1000 | Loss: 0.00001106
Iteration 82/1000 | Loss: 0.00001105
Iteration 83/1000 | Loss: 0.00001105
Iteration 84/1000 | Loss: 0.00001105
Iteration 85/1000 | Loss: 0.00001104
Iteration 86/1000 | Loss: 0.00001104
Iteration 87/1000 | Loss: 0.00001104
Iteration 88/1000 | Loss: 0.00001104
Iteration 89/1000 | Loss: 0.00001104
Iteration 90/1000 | Loss: 0.00001104
Iteration 91/1000 | Loss: 0.00001104
Iteration 92/1000 | Loss: 0.00001104
Iteration 93/1000 | Loss: 0.00001103
Iteration 94/1000 | Loss: 0.00001103
Iteration 95/1000 | Loss: 0.00001103
Iteration 96/1000 | Loss: 0.00001103
Iteration 97/1000 | Loss: 0.00001103
Iteration 98/1000 | Loss: 0.00001103
Iteration 99/1000 | Loss: 0.00001103
Iteration 100/1000 | Loss: 0.00001102
Iteration 101/1000 | Loss: 0.00001102
Iteration 102/1000 | Loss: 0.00001102
Iteration 103/1000 | Loss: 0.00001102
Iteration 104/1000 | Loss: 0.00001101
Iteration 105/1000 | Loss: 0.00001101
Iteration 106/1000 | Loss: 0.00001101
Iteration 107/1000 | Loss: 0.00001101
Iteration 108/1000 | Loss: 0.00001101
Iteration 109/1000 | Loss: 0.00001101
Iteration 110/1000 | Loss: 0.00001101
Iteration 111/1000 | Loss: 0.00001101
Iteration 112/1000 | Loss: 0.00001101
Iteration 113/1000 | Loss: 0.00001101
Iteration 114/1000 | Loss: 0.00001101
Iteration 115/1000 | Loss: 0.00001100
Iteration 116/1000 | Loss: 0.00001100
Iteration 117/1000 | Loss: 0.00001100
Iteration 118/1000 | Loss: 0.00001100
Iteration 119/1000 | Loss: 0.00001100
Iteration 120/1000 | Loss: 0.00001100
Iteration 121/1000 | Loss: 0.00001100
Iteration 122/1000 | Loss: 0.00001100
Iteration 123/1000 | Loss: 0.00001100
Iteration 124/1000 | Loss: 0.00001100
Iteration 125/1000 | Loss: 0.00001100
Iteration 126/1000 | Loss: 0.00001100
Iteration 127/1000 | Loss: 0.00001100
Iteration 128/1000 | Loss: 0.00001100
Iteration 129/1000 | Loss: 0.00001100
Iteration 130/1000 | Loss: 0.00001100
Iteration 131/1000 | Loss: 0.00001100
Iteration 132/1000 | Loss: 0.00001100
Iteration 133/1000 | Loss: 0.00001100
Iteration 134/1000 | Loss: 0.00001100
Iteration 135/1000 | Loss: 0.00001100
Iteration 136/1000 | Loss: 0.00001100
Iteration 137/1000 | Loss: 0.00001100
Iteration 138/1000 | Loss: 0.00001100
Iteration 139/1000 | Loss: 0.00001100
Iteration 140/1000 | Loss: 0.00001100
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [1.1002854989783373e-05, 1.1002854989783373e-05, 1.1002854989783373e-05, 1.1002854989783373e-05, 1.1002854989783373e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1002854989783373e-05

Optimization complete. Final v2v error: 2.8769021034240723 mm

Highest mean error: 3.4107518196105957 mm for frame 117

Lowest mean error: 2.6646745204925537 mm for frame 88

Saving results

Total time: 40.10834288597107
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1034/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1034.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1034
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00404219
Iteration 2/25 | Loss: 0.00143608
Iteration 3/25 | Loss: 0.00136086
Iteration 4/25 | Loss: 0.00135431
Iteration 5/25 | Loss: 0.00135431
Iteration 6/25 | Loss: 0.00135431
Iteration 7/25 | Loss: 0.00135431
Iteration 8/25 | Loss: 0.00135431
Iteration 9/25 | Loss: 0.00135431
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 9. Stopping optimization.
Last 5 losses: [0.0013543106615543365, 0.0013543106615543365, 0.0013543106615543365, 0.0013543106615543365, 0.0013543106615543365]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013543106615543365

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52305198
Iteration 2/25 | Loss: 0.00175626
Iteration 3/25 | Loss: 0.00175626
Iteration 4/25 | Loss: 0.00175626
Iteration 5/25 | Loss: 0.00175626
Iteration 6/25 | Loss: 0.00175626
Iteration 7/25 | Loss: 0.00175626
Iteration 8/25 | Loss: 0.00175626
Iteration 9/25 | Loss: 0.00175626
Iteration 10/25 | Loss: 0.00175626
Iteration 11/25 | Loss: 0.00175626
Iteration 12/25 | Loss: 0.00175626
Iteration 13/25 | Loss: 0.00175626
Iteration 14/25 | Loss: 0.00175626
Iteration 15/25 | Loss: 0.00175626
Iteration 16/25 | Loss: 0.00175626
Iteration 17/25 | Loss: 0.00175626
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0017562577268108726, 0.0017562577268108726, 0.0017562577268108726, 0.0017562577268108726, 0.0017562577268108726]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017562577268108726

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00175626
Iteration 2/1000 | Loss: 0.00002576
Iteration 3/1000 | Loss: 0.00001655
Iteration 4/1000 | Loss: 0.00001496
Iteration 5/1000 | Loss: 0.00001427
Iteration 6/1000 | Loss: 0.00001375
Iteration 7/1000 | Loss: 0.00001342
Iteration 8/1000 | Loss: 0.00001314
Iteration 9/1000 | Loss: 0.00001266
Iteration 10/1000 | Loss: 0.00001235
Iteration 11/1000 | Loss: 0.00001216
Iteration 12/1000 | Loss: 0.00001196
Iteration 13/1000 | Loss: 0.00001195
Iteration 14/1000 | Loss: 0.00001193
Iteration 15/1000 | Loss: 0.00001186
Iteration 16/1000 | Loss: 0.00001181
Iteration 17/1000 | Loss: 0.00001173
Iteration 18/1000 | Loss: 0.00001168
Iteration 19/1000 | Loss: 0.00001166
Iteration 20/1000 | Loss: 0.00001162
Iteration 21/1000 | Loss: 0.00001156
Iteration 22/1000 | Loss: 0.00001152
Iteration 23/1000 | Loss: 0.00001152
Iteration 24/1000 | Loss: 0.00001151
Iteration 25/1000 | Loss: 0.00001151
Iteration 26/1000 | Loss: 0.00001147
Iteration 27/1000 | Loss: 0.00001146
Iteration 28/1000 | Loss: 0.00001145
Iteration 29/1000 | Loss: 0.00001144
Iteration 30/1000 | Loss: 0.00001144
Iteration 31/1000 | Loss: 0.00001133
Iteration 32/1000 | Loss: 0.00001133
Iteration 33/1000 | Loss: 0.00001131
Iteration 34/1000 | Loss: 0.00001130
Iteration 35/1000 | Loss: 0.00001130
Iteration 36/1000 | Loss: 0.00001130
Iteration 37/1000 | Loss: 0.00001129
Iteration 38/1000 | Loss: 0.00001129
Iteration 39/1000 | Loss: 0.00001127
Iteration 40/1000 | Loss: 0.00001127
Iteration 41/1000 | Loss: 0.00001125
Iteration 42/1000 | Loss: 0.00001125
Iteration 43/1000 | Loss: 0.00001125
Iteration 44/1000 | Loss: 0.00001125
Iteration 45/1000 | Loss: 0.00001125
Iteration 46/1000 | Loss: 0.00001125
Iteration 47/1000 | Loss: 0.00001125
Iteration 48/1000 | Loss: 0.00001125
Iteration 49/1000 | Loss: 0.00001125
Iteration 50/1000 | Loss: 0.00001125
Iteration 51/1000 | Loss: 0.00001124
Iteration 52/1000 | Loss: 0.00001124
Iteration 53/1000 | Loss: 0.00001124
Iteration 54/1000 | Loss: 0.00001124
Iteration 55/1000 | Loss: 0.00001124
Iteration 56/1000 | Loss: 0.00001122
Iteration 57/1000 | Loss: 0.00001122
Iteration 58/1000 | Loss: 0.00001119
Iteration 59/1000 | Loss: 0.00001119
Iteration 60/1000 | Loss: 0.00001119
Iteration 61/1000 | Loss: 0.00001119
Iteration 62/1000 | Loss: 0.00001119
Iteration 63/1000 | Loss: 0.00001119
Iteration 64/1000 | Loss: 0.00001118
Iteration 65/1000 | Loss: 0.00001118
Iteration 66/1000 | Loss: 0.00001115
Iteration 67/1000 | Loss: 0.00001115
Iteration 68/1000 | Loss: 0.00001115
Iteration 69/1000 | Loss: 0.00001115
Iteration 70/1000 | Loss: 0.00001115
Iteration 71/1000 | Loss: 0.00001115
Iteration 72/1000 | Loss: 0.00001115
Iteration 73/1000 | Loss: 0.00001115
Iteration 74/1000 | Loss: 0.00001114
Iteration 75/1000 | Loss: 0.00001114
Iteration 76/1000 | Loss: 0.00001114
Iteration 77/1000 | Loss: 0.00001114
Iteration 78/1000 | Loss: 0.00001114
Iteration 79/1000 | Loss: 0.00001114
Iteration 80/1000 | Loss: 0.00001114
Iteration 81/1000 | Loss: 0.00001114
Iteration 82/1000 | Loss: 0.00001114
Iteration 83/1000 | Loss: 0.00001114
Iteration 84/1000 | Loss: 0.00001113
Iteration 85/1000 | Loss: 0.00001113
Iteration 86/1000 | Loss: 0.00001112
Iteration 87/1000 | Loss: 0.00001112
Iteration 88/1000 | Loss: 0.00001112
Iteration 89/1000 | Loss: 0.00001112
Iteration 90/1000 | Loss: 0.00001111
Iteration 91/1000 | Loss: 0.00001110
Iteration 92/1000 | Loss: 0.00001110
Iteration 93/1000 | Loss: 0.00001110
Iteration 94/1000 | Loss: 0.00001110
Iteration 95/1000 | Loss: 0.00001110
Iteration 96/1000 | Loss: 0.00001110
Iteration 97/1000 | Loss: 0.00001109
Iteration 98/1000 | Loss: 0.00001109
Iteration 99/1000 | Loss: 0.00001108
Iteration 100/1000 | Loss: 0.00001108
Iteration 101/1000 | Loss: 0.00001107
Iteration 102/1000 | Loss: 0.00001107
Iteration 103/1000 | Loss: 0.00001107
Iteration 104/1000 | Loss: 0.00001106
Iteration 105/1000 | Loss: 0.00001106
Iteration 106/1000 | Loss: 0.00001105
Iteration 107/1000 | Loss: 0.00001105
Iteration 108/1000 | Loss: 0.00001105
Iteration 109/1000 | Loss: 0.00001105
Iteration 110/1000 | Loss: 0.00001104
Iteration 111/1000 | Loss: 0.00001104
Iteration 112/1000 | Loss: 0.00001104
Iteration 113/1000 | Loss: 0.00001104
Iteration 114/1000 | Loss: 0.00001103
Iteration 115/1000 | Loss: 0.00001103
Iteration 116/1000 | Loss: 0.00001103
Iteration 117/1000 | Loss: 0.00001103
Iteration 118/1000 | Loss: 0.00001103
Iteration 119/1000 | Loss: 0.00001102
Iteration 120/1000 | Loss: 0.00001102
Iteration 121/1000 | Loss: 0.00001102
Iteration 122/1000 | Loss: 0.00001102
Iteration 123/1000 | Loss: 0.00001102
Iteration 124/1000 | Loss: 0.00001102
Iteration 125/1000 | Loss: 0.00001102
Iteration 126/1000 | Loss: 0.00001102
Iteration 127/1000 | Loss: 0.00001102
Iteration 128/1000 | Loss: 0.00001102
Iteration 129/1000 | Loss: 0.00001102
Iteration 130/1000 | Loss: 0.00001101
Iteration 131/1000 | Loss: 0.00001101
Iteration 132/1000 | Loss: 0.00001101
Iteration 133/1000 | Loss: 0.00001101
Iteration 134/1000 | Loss: 0.00001101
Iteration 135/1000 | Loss: 0.00001101
Iteration 136/1000 | Loss: 0.00001101
Iteration 137/1000 | Loss: 0.00001101
Iteration 138/1000 | Loss: 0.00001101
Iteration 139/1000 | Loss: 0.00001101
Iteration 140/1000 | Loss: 0.00001100
Iteration 141/1000 | Loss: 0.00001100
Iteration 142/1000 | Loss: 0.00001100
Iteration 143/1000 | Loss: 0.00001100
Iteration 144/1000 | Loss: 0.00001100
Iteration 145/1000 | Loss: 0.00001100
Iteration 146/1000 | Loss: 0.00001100
Iteration 147/1000 | Loss: 0.00001100
Iteration 148/1000 | Loss: 0.00001100
Iteration 149/1000 | Loss: 0.00001100
Iteration 150/1000 | Loss: 0.00001100
Iteration 151/1000 | Loss: 0.00001100
Iteration 152/1000 | Loss: 0.00001100
Iteration 153/1000 | Loss: 0.00001099
Iteration 154/1000 | Loss: 0.00001099
Iteration 155/1000 | Loss: 0.00001099
Iteration 156/1000 | Loss: 0.00001099
Iteration 157/1000 | Loss: 0.00001099
Iteration 158/1000 | Loss: 0.00001099
Iteration 159/1000 | Loss: 0.00001099
Iteration 160/1000 | Loss: 0.00001099
Iteration 161/1000 | Loss: 0.00001099
Iteration 162/1000 | Loss: 0.00001099
Iteration 163/1000 | Loss: 0.00001099
Iteration 164/1000 | Loss: 0.00001099
Iteration 165/1000 | Loss: 0.00001099
Iteration 166/1000 | Loss: 0.00001098
Iteration 167/1000 | Loss: 0.00001098
Iteration 168/1000 | Loss: 0.00001098
Iteration 169/1000 | Loss: 0.00001098
Iteration 170/1000 | Loss: 0.00001098
Iteration 171/1000 | Loss: 0.00001098
Iteration 172/1000 | Loss: 0.00001098
Iteration 173/1000 | Loss: 0.00001098
Iteration 174/1000 | Loss: 0.00001098
Iteration 175/1000 | Loss: 0.00001098
Iteration 176/1000 | Loss: 0.00001098
Iteration 177/1000 | Loss: 0.00001098
Iteration 178/1000 | Loss: 0.00001098
Iteration 179/1000 | Loss: 0.00001098
Iteration 180/1000 | Loss: 0.00001098
Iteration 181/1000 | Loss: 0.00001097
Iteration 182/1000 | Loss: 0.00001097
Iteration 183/1000 | Loss: 0.00001097
Iteration 184/1000 | Loss: 0.00001097
Iteration 185/1000 | Loss: 0.00001097
Iteration 186/1000 | Loss: 0.00001097
Iteration 187/1000 | Loss: 0.00001097
Iteration 188/1000 | Loss: 0.00001097
Iteration 189/1000 | Loss: 0.00001097
Iteration 190/1000 | Loss: 0.00001097
Iteration 191/1000 | Loss: 0.00001097
Iteration 192/1000 | Loss: 0.00001097
Iteration 193/1000 | Loss: 0.00001096
Iteration 194/1000 | Loss: 0.00001096
Iteration 195/1000 | Loss: 0.00001096
Iteration 196/1000 | Loss: 0.00001096
Iteration 197/1000 | Loss: 0.00001096
Iteration 198/1000 | Loss: 0.00001096
Iteration 199/1000 | Loss: 0.00001096
Iteration 200/1000 | Loss: 0.00001096
Iteration 201/1000 | Loss: 0.00001096
Iteration 202/1000 | Loss: 0.00001096
Iteration 203/1000 | Loss: 0.00001096
Iteration 204/1000 | Loss: 0.00001096
Iteration 205/1000 | Loss: 0.00001096
Iteration 206/1000 | Loss: 0.00001096
Iteration 207/1000 | Loss: 0.00001096
Iteration 208/1000 | Loss: 0.00001096
Iteration 209/1000 | Loss: 0.00001096
Iteration 210/1000 | Loss: 0.00001096
Iteration 211/1000 | Loss: 0.00001096
Iteration 212/1000 | Loss: 0.00001096
Iteration 213/1000 | Loss: 0.00001096
Iteration 214/1000 | Loss: 0.00001096
Iteration 215/1000 | Loss: 0.00001096
Iteration 216/1000 | Loss: 0.00001096
Iteration 217/1000 | Loss: 0.00001096
Iteration 218/1000 | Loss: 0.00001096
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 218. Stopping optimization.
Last 5 losses: [1.0958621714962646e-05, 1.0958621714962646e-05, 1.0958621714962646e-05, 1.0958621714962646e-05, 1.0958621714962646e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0958621714962646e-05

Optimization complete. Final v2v error: 2.8432695865631104 mm

Highest mean error: 2.979449510574341 mm for frame 133

Lowest mean error: 2.7154123783111572 mm for frame 43

Saving results

Total time: 48.743000745773315
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00773830
Iteration 2/25 | Loss: 0.00156853
Iteration 3/25 | Loss: 0.00146382
Iteration 4/25 | Loss: 0.00145549
Iteration 5/25 | Loss: 0.00145511
Iteration 6/25 | Loss: 0.00145511
Iteration 7/25 | Loss: 0.00145511
Iteration 8/25 | Loss: 0.00145511
Iteration 9/25 | Loss: 0.00145511
Iteration 10/25 | Loss: 0.00145511
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.001455114921554923, 0.001455114921554923, 0.001455114921554923, 0.001455114921554923, 0.001455114921554923]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001455114921554923

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.86683357
Iteration 2/25 | Loss: 0.00153747
Iteration 3/25 | Loss: 0.00153745
Iteration 4/25 | Loss: 0.00153745
Iteration 5/25 | Loss: 0.00153745
Iteration 6/25 | Loss: 0.00153745
Iteration 7/25 | Loss: 0.00153745
Iteration 8/25 | Loss: 0.00153745
Iteration 9/25 | Loss: 0.00153745
Iteration 10/25 | Loss: 0.00153745
Iteration 11/25 | Loss: 0.00153744
Iteration 12/25 | Loss: 0.00153744
Iteration 13/25 | Loss: 0.00153744
Iteration 14/25 | Loss: 0.00153744
Iteration 15/25 | Loss: 0.00153744
Iteration 16/25 | Loss: 0.00153744
Iteration 17/25 | Loss: 0.00153744
Iteration 18/25 | Loss: 0.00153744
Iteration 19/25 | Loss: 0.00153744
Iteration 20/25 | Loss: 0.00153744
Iteration 21/25 | Loss: 0.00153744
Iteration 22/25 | Loss: 0.00153744
Iteration 23/25 | Loss: 0.00153744
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0015374443028122187, 0.0015374443028122187, 0.0015374443028122187, 0.0015374443028122187, 0.0015374443028122187]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015374443028122187

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00153744
Iteration 2/1000 | Loss: 0.00003228
Iteration 3/1000 | Loss: 0.00002456
Iteration 4/1000 | Loss: 0.00002248
Iteration 5/1000 | Loss: 0.00002163
Iteration 6/1000 | Loss: 0.00002108
Iteration 7/1000 | Loss: 0.00002079
Iteration 8/1000 | Loss: 0.00002042
Iteration 9/1000 | Loss: 0.00002002
Iteration 10/1000 | Loss: 0.00001966
Iteration 11/1000 | Loss: 0.00001938
Iteration 12/1000 | Loss: 0.00001916
Iteration 13/1000 | Loss: 0.00001894
Iteration 14/1000 | Loss: 0.00001881
Iteration 15/1000 | Loss: 0.00001878
Iteration 16/1000 | Loss: 0.00001871
Iteration 17/1000 | Loss: 0.00001857
Iteration 18/1000 | Loss: 0.00001854
Iteration 19/1000 | Loss: 0.00001853
Iteration 20/1000 | Loss: 0.00001853
Iteration 21/1000 | Loss: 0.00001851
Iteration 22/1000 | Loss: 0.00001850
Iteration 23/1000 | Loss: 0.00001849
Iteration 24/1000 | Loss: 0.00001848
Iteration 25/1000 | Loss: 0.00001844
Iteration 26/1000 | Loss: 0.00001843
Iteration 27/1000 | Loss: 0.00001842
Iteration 28/1000 | Loss: 0.00001840
Iteration 29/1000 | Loss: 0.00001834
Iteration 30/1000 | Loss: 0.00001832
Iteration 31/1000 | Loss: 0.00001829
Iteration 32/1000 | Loss: 0.00001829
Iteration 33/1000 | Loss: 0.00001828
Iteration 34/1000 | Loss: 0.00001828
Iteration 35/1000 | Loss: 0.00001828
Iteration 36/1000 | Loss: 0.00001827
Iteration 37/1000 | Loss: 0.00001824
Iteration 38/1000 | Loss: 0.00001823
Iteration 39/1000 | Loss: 0.00001823
Iteration 40/1000 | Loss: 0.00001823
Iteration 41/1000 | Loss: 0.00001823
Iteration 42/1000 | Loss: 0.00001823
Iteration 43/1000 | Loss: 0.00001823
Iteration 44/1000 | Loss: 0.00001823
Iteration 45/1000 | Loss: 0.00001823
Iteration 46/1000 | Loss: 0.00001822
Iteration 47/1000 | Loss: 0.00001822
Iteration 48/1000 | Loss: 0.00001822
Iteration 49/1000 | Loss: 0.00001822
Iteration 50/1000 | Loss: 0.00001822
Iteration 51/1000 | Loss: 0.00001821
Iteration 52/1000 | Loss: 0.00001820
Iteration 53/1000 | Loss: 0.00001820
Iteration 54/1000 | Loss: 0.00001820
Iteration 55/1000 | Loss: 0.00001820
Iteration 56/1000 | Loss: 0.00001820
Iteration 57/1000 | Loss: 0.00001820
Iteration 58/1000 | Loss: 0.00001820
Iteration 59/1000 | Loss: 0.00001820
Iteration 60/1000 | Loss: 0.00001820
Iteration 61/1000 | Loss: 0.00001820
Iteration 62/1000 | Loss: 0.00001820
Iteration 63/1000 | Loss: 0.00001820
Iteration 64/1000 | Loss: 0.00001820
Iteration 65/1000 | Loss: 0.00001820
Iteration 66/1000 | Loss: 0.00001820
Iteration 67/1000 | Loss: 0.00001820
Iteration 68/1000 | Loss: 0.00001820
Iteration 69/1000 | Loss: 0.00001820
Iteration 70/1000 | Loss: 0.00001820
Iteration 71/1000 | Loss: 0.00001820
Iteration 72/1000 | Loss: 0.00001820
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [1.8201437342213467e-05, 1.8201437342213467e-05, 1.8201437342213467e-05, 1.8201437342213467e-05, 1.8201437342213467e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8201437342213467e-05

Optimization complete. Final v2v error: 3.5560154914855957 mm

Highest mean error: 3.943946123123169 mm for frame 172

Lowest mean error: 3.3042280673980713 mm for frame 51

Saving results

Total time: 39.457292556762695
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1052/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1052.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1052
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01026249
Iteration 2/25 | Loss: 0.00206280
Iteration 3/25 | Loss: 0.00168588
Iteration 4/25 | Loss: 0.00165760
Iteration 5/25 | Loss: 0.00162594
Iteration 6/25 | Loss: 0.00159890
Iteration 7/25 | Loss: 0.00160547
Iteration 8/25 | Loss: 0.00158305
Iteration 9/25 | Loss: 0.00157535
Iteration 10/25 | Loss: 0.00156901
Iteration 11/25 | Loss: 0.00158080
Iteration 12/25 | Loss: 0.00157987
Iteration 13/25 | Loss: 0.00158443
Iteration 14/25 | Loss: 0.00158106
Iteration 15/25 | Loss: 0.00156655
Iteration 16/25 | Loss: 0.00154943
Iteration 17/25 | Loss: 0.00154431
Iteration 18/25 | Loss: 0.00154346
Iteration 19/25 | Loss: 0.00154315
Iteration 20/25 | Loss: 0.00154289
Iteration 21/25 | Loss: 0.00154251
Iteration 22/25 | Loss: 0.00154189
Iteration 23/25 | Loss: 0.00154111
Iteration 24/25 | Loss: 0.00154038
Iteration 25/25 | Loss: 0.00154274

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.15017152
Iteration 2/25 | Loss: 0.00233492
Iteration 3/25 | Loss: 0.00233492
Iteration 4/25 | Loss: 0.00233492
Iteration 5/25 | Loss: 0.00233492
Iteration 6/25 | Loss: 0.00233492
Iteration 7/25 | Loss: 0.00233492
Iteration 8/25 | Loss: 0.00233492
Iteration 9/25 | Loss: 0.00233492
Iteration 10/25 | Loss: 0.00233492
Iteration 11/25 | Loss: 0.00233492
Iteration 12/25 | Loss: 0.00233492
Iteration 13/25 | Loss: 0.00233492
Iteration 14/25 | Loss: 0.00233492
Iteration 15/25 | Loss: 0.00233492
Iteration 16/25 | Loss: 0.00233492
Iteration 17/25 | Loss: 0.00233492
Iteration 18/25 | Loss: 0.00233492
Iteration 19/25 | Loss: 0.00233492
Iteration 20/25 | Loss: 0.00233492
Iteration 21/25 | Loss: 0.00233492
Iteration 22/25 | Loss: 0.00233492
Iteration 23/25 | Loss: 0.00233492
Iteration 24/25 | Loss: 0.00233492
Iteration 25/25 | Loss: 0.00233492

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00233492
Iteration 2/1000 | Loss: 0.00029289
Iteration 3/1000 | Loss: 0.00009951
Iteration 4/1000 | Loss: 0.00007954
Iteration 5/1000 | Loss: 0.00006529
Iteration 6/1000 | Loss: 0.00005834
Iteration 7/1000 | Loss: 0.00005388
Iteration 8/1000 | Loss: 0.00233808
Iteration 9/1000 | Loss: 0.00058778
Iteration 10/1000 | Loss: 0.00050115
Iteration 11/1000 | Loss: 0.00045025
Iteration 12/1000 | Loss: 0.00047694
Iteration 13/1000 | Loss: 0.00026892
Iteration 14/1000 | Loss: 0.00036525
Iteration 15/1000 | Loss: 0.00018824
Iteration 16/1000 | Loss: 0.00005393
Iteration 17/1000 | Loss: 0.00004881
Iteration 18/1000 | Loss: 0.00004267
Iteration 19/1000 | Loss: 0.00003940
Iteration 20/1000 | Loss: 0.00003655
Iteration 21/1000 | Loss: 0.00003479
Iteration 22/1000 | Loss: 0.00003322
Iteration 23/1000 | Loss: 0.00003180
Iteration 24/1000 | Loss: 0.00003079
Iteration 25/1000 | Loss: 0.00023264
Iteration 26/1000 | Loss: 0.00005433
Iteration 27/1000 | Loss: 0.00004342
Iteration 28/1000 | Loss: 0.00003472
Iteration 29/1000 | Loss: 0.00003246
Iteration 30/1000 | Loss: 0.00003165
Iteration 31/1000 | Loss: 0.00003088
Iteration 32/1000 | Loss: 0.00003012
Iteration 33/1000 | Loss: 0.00002936
Iteration 34/1000 | Loss: 0.00002892
Iteration 35/1000 | Loss: 0.00004371
Iteration 36/1000 | Loss: 0.00003072
Iteration 37/1000 | Loss: 0.00003489
Iteration 38/1000 | Loss: 0.00004160
Iteration 39/1000 | Loss: 0.00004271
Iteration 40/1000 | Loss: 0.00004515
Iteration 41/1000 | Loss: 0.00003375
Iteration 42/1000 | Loss: 0.00004324
Iteration 43/1000 | Loss: 0.00003861
Iteration 44/1000 | Loss: 0.00003370
Iteration 45/1000 | Loss: 0.00003051
Iteration 46/1000 | Loss: 0.00002830
Iteration 47/1000 | Loss: 0.00002796
Iteration 48/1000 | Loss: 0.00002770
Iteration 49/1000 | Loss: 0.00002751
Iteration 50/1000 | Loss: 0.00002732
Iteration 51/1000 | Loss: 0.00002717
Iteration 52/1000 | Loss: 0.00002712
Iteration 53/1000 | Loss: 0.00002708
Iteration 54/1000 | Loss: 0.00002708
Iteration 55/1000 | Loss: 0.00002706
Iteration 56/1000 | Loss: 0.00002704
Iteration 57/1000 | Loss: 0.00002704
Iteration 58/1000 | Loss: 0.00002704
Iteration 59/1000 | Loss: 0.00002704
Iteration 60/1000 | Loss: 0.00002704
Iteration 61/1000 | Loss: 0.00002704
Iteration 62/1000 | Loss: 0.00002704
Iteration 63/1000 | Loss: 0.00002703
Iteration 64/1000 | Loss: 0.00002703
Iteration 65/1000 | Loss: 0.00002703
Iteration 66/1000 | Loss: 0.00002701
Iteration 67/1000 | Loss: 0.00002701
Iteration 68/1000 | Loss: 0.00002701
Iteration 69/1000 | Loss: 0.00002701
Iteration 70/1000 | Loss: 0.00002701
Iteration 71/1000 | Loss: 0.00002700
Iteration 72/1000 | Loss: 0.00002700
Iteration 73/1000 | Loss: 0.00002700
Iteration 74/1000 | Loss: 0.00002700
Iteration 75/1000 | Loss: 0.00002700
Iteration 76/1000 | Loss: 0.00002700
Iteration 77/1000 | Loss: 0.00002699
Iteration 78/1000 | Loss: 0.00002698
Iteration 79/1000 | Loss: 0.00002698
Iteration 80/1000 | Loss: 0.00002698
Iteration 81/1000 | Loss: 0.00002697
Iteration 82/1000 | Loss: 0.00002697
Iteration 83/1000 | Loss: 0.00002696
Iteration 84/1000 | Loss: 0.00002696
Iteration 85/1000 | Loss: 0.00002696
Iteration 86/1000 | Loss: 0.00002696
Iteration 87/1000 | Loss: 0.00002696
Iteration 88/1000 | Loss: 0.00002695
Iteration 89/1000 | Loss: 0.00002695
Iteration 90/1000 | Loss: 0.00002695
Iteration 91/1000 | Loss: 0.00002694
Iteration 92/1000 | Loss: 0.00002694
Iteration 93/1000 | Loss: 0.00002694
Iteration 94/1000 | Loss: 0.00002693
Iteration 95/1000 | Loss: 0.00002693
Iteration 96/1000 | Loss: 0.00002693
Iteration 97/1000 | Loss: 0.00002692
Iteration 98/1000 | Loss: 0.00002691
Iteration 99/1000 | Loss: 0.00002691
Iteration 100/1000 | Loss: 0.00002691
Iteration 101/1000 | Loss: 0.00002691
Iteration 102/1000 | Loss: 0.00002690
Iteration 103/1000 | Loss: 0.00002690
Iteration 104/1000 | Loss: 0.00002690
Iteration 105/1000 | Loss: 0.00002690
Iteration 106/1000 | Loss: 0.00002690
Iteration 107/1000 | Loss: 0.00002690
Iteration 108/1000 | Loss: 0.00002690
Iteration 109/1000 | Loss: 0.00002690
Iteration 110/1000 | Loss: 0.00002690
Iteration 111/1000 | Loss: 0.00002690
Iteration 112/1000 | Loss: 0.00002689
Iteration 113/1000 | Loss: 0.00002689
Iteration 114/1000 | Loss: 0.00002689
Iteration 115/1000 | Loss: 0.00002689
Iteration 116/1000 | Loss: 0.00002689
Iteration 117/1000 | Loss: 0.00002689
Iteration 118/1000 | Loss: 0.00002689
Iteration 119/1000 | Loss: 0.00002689
Iteration 120/1000 | Loss: 0.00002689
Iteration 121/1000 | Loss: 0.00002689
Iteration 122/1000 | Loss: 0.00002689
Iteration 123/1000 | Loss: 0.00002688
Iteration 124/1000 | Loss: 0.00002688
Iteration 125/1000 | Loss: 0.00002688
Iteration 126/1000 | Loss: 0.00002688
Iteration 127/1000 | Loss: 0.00002688
Iteration 128/1000 | Loss: 0.00002688
Iteration 129/1000 | Loss: 0.00002688
Iteration 130/1000 | Loss: 0.00002688
Iteration 131/1000 | Loss: 0.00002688
Iteration 132/1000 | Loss: 0.00002687
Iteration 133/1000 | Loss: 0.00002687
Iteration 134/1000 | Loss: 0.00002687
Iteration 135/1000 | Loss: 0.00002687
Iteration 136/1000 | Loss: 0.00002686
Iteration 137/1000 | Loss: 0.00002686
Iteration 138/1000 | Loss: 0.00002685
Iteration 139/1000 | Loss: 0.00002685
Iteration 140/1000 | Loss: 0.00002684
Iteration 141/1000 | Loss: 0.00002684
Iteration 142/1000 | Loss: 0.00002684
Iteration 143/1000 | Loss: 0.00002683
Iteration 144/1000 | Loss: 0.00002683
Iteration 145/1000 | Loss: 0.00002683
Iteration 146/1000 | Loss: 0.00002682
Iteration 147/1000 | Loss: 0.00002682
Iteration 148/1000 | Loss: 0.00002682
Iteration 149/1000 | Loss: 0.00002681
Iteration 150/1000 | Loss: 0.00002681
Iteration 151/1000 | Loss: 0.00002681
Iteration 152/1000 | Loss: 0.00002681
Iteration 153/1000 | Loss: 0.00002681
Iteration 154/1000 | Loss: 0.00002681
Iteration 155/1000 | Loss: 0.00002681
Iteration 156/1000 | Loss: 0.00002681
Iteration 157/1000 | Loss: 0.00002681
Iteration 158/1000 | Loss: 0.00002680
Iteration 159/1000 | Loss: 0.00002680
Iteration 160/1000 | Loss: 0.00002680
Iteration 161/1000 | Loss: 0.00002680
Iteration 162/1000 | Loss: 0.00002680
Iteration 163/1000 | Loss: 0.00002680
Iteration 164/1000 | Loss: 0.00002680
Iteration 165/1000 | Loss: 0.00002680
Iteration 166/1000 | Loss: 0.00002680
Iteration 167/1000 | Loss: 0.00002680
Iteration 168/1000 | Loss: 0.00002680
Iteration 169/1000 | Loss: 0.00002680
Iteration 170/1000 | Loss: 0.00002679
Iteration 171/1000 | Loss: 0.00002679
Iteration 172/1000 | Loss: 0.00002679
Iteration 173/1000 | Loss: 0.00002679
Iteration 174/1000 | Loss: 0.00002679
Iteration 175/1000 | Loss: 0.00002678
Iteration 176/1000 | Loss: 0.00002678
Iteration 177/1000 | Loss: 0.00002678
Iteration 178/1000 | Loss: 0.00002678
Iteration 179/1000 | Loss: 0.00002678
Iteration 180/1000 | Loss: 0.00002677
Iteration 181/1000 | Loss: 0.00002677
Iteration 182/1000 | Loss: 0.00002677
Iteration 183/1000 | Loss: 0.00002677
Iteration 184/1000 | Loss: 0.00002676
Iteration 185/1000 | Loss: 0.00002676
Iteration 186/1000 | Loss: 0.00002676
Iteration 187/1000 | Loss: 0.00002676
Iteration 188/1000 | Loss: 0.00002676
Iteration 189/1000 | Loss: 0.00002675
Iteration 190/1000 | Loss: 0.00002675
Iteration 191/1000 | Loss: 0.00002675
Iteration 192/1000 | Loss: 0.00002675
Iteration 193/1000 | Loss: 0.00002675
Iteration 194/1000 | Loss: 0.00002675
Iteration 195/1000 | Loss: 0.00002675
Iteration 196/1000 | Loss: 0.00002675
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [2.675359974091407e-05, 2.675359974091407e-05, 2.675359974091407e-05, 2.675359974091407e-05, 2.675359974091407e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.675359974091407e-05

Optimization complete. Final v2v error: 4.171847820281982 mm

Highest mean error: 5.560546398162842 mm for frame 9

Lowest mean error: 3.627366065979004 mm for frame 56

Saving results

Total time: 144.0515649318695
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1029/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1029.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1029
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00972179
Iteration 2/25 | Loss: 0.00220188
Iteration 3/25 | Loss: 0.00187791
Iteration 4/25 | Loss: 0.00184051
Iteration 5/25 | Loss: 0.00184770
Iteration 6/25 | Loss: 0.00172404
Iteration 7/25 | Loss: 0.00155819
Iteration 8/25 | Loss: 0.00156254
Iteration 9/25 | Loss: 0.00155405
Iteration 10/25 | Loss: 0.00147419
Iteration 11/25 | Loss: 0.00145672
Iteration 12/25 | Loss: 0.00144680
Iteration 13/25 | Loss: 0.00142774
Iteration 14/25 | Loss: 0.00142131
Iteration 15/25 | Loss: 0.00140921
Iteration 16/25 | Loss: 0.00140370
Iteration 17/25 | Loss: 0.00140521
Iteration 18/25 | Loss: 0.00140313
Iteration 19/25 | Loss: 0.00139996
Iteration 20/25 | Loss: 0.00139822
Iteration 21/25 | Loss: 0.00139670
Iteration 22/25 | Loss: 0.00140046
Iteration 23/25 | Loss: 0.00139899
Iteration 24/25 | Loss: 0.00139867
Iteration 25/25 | Loss: 0.00140113

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65056801
Iteration 2/25 | Loss: 0.00222486
Iteration 3/25 | Loss: 0.00222486
Iteration 4/25 | Loss: 0.00222486
Iteration 5/25 | Loss: 0.00222486
Iteration 6/25 | Loss: 0.00222485
Iteration 7/25 | Loss: 0.00222485
Iteration 8/25 | Loss: 0.00222485
Iteration 9/25 | Loss: 0.00222485
Iteration 10/25 | Loss: 0.00222485
Iteration 11/25 | Loss: 0.00222485
Iteration 12/25 | Loss: 0.00222485
Iteration 13/25 | Loss: 0.00222485
Iteration 14/25 | Loss: 0.00222485
Iteration 15/25 | Loss: 0.00222485
Iteration 16/25 | Loss: 0.00222485
Iteration 17/25 | Loss: 0.00222485
Iteration 18/25 | Loss: 0.00222485
Iteration 19/25 | Loss: 0.00222485
Iteration 20/25 | Loss: 0.00222485
Iteration 21/25 | Loss: 0.00222485
Iteration 22/25 | Loss: 0.00222485
Iteration 23/25 | Loss: 0.00222485
Iteration 24/25 | Loss: 0.00222485
Iteration 25/25 | Loss: 0.00222485

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00222485
Iteration 2/1000 | Loss: 0.00041702
Iteration 3/1000 | Loss: 0.00023839
Iteration 4/1000 | Loss: 0.00012480
Iteration 5/1000 | Loss: 0.00121940
Iteration 6/1000 | Loss: 0.00027100
Iteration 7/1000 | Loss: 0.00024529
Iteration 8/1000 | Loss: 0.00036469
Iteration 9/1000 | Loss: 0.00011141
Iteration 10/1000 | Loss: 0.00120471
Iteration 11/1000 | Loss: 0.00056927
Iteration 12/1000 | Loss: 0.00021781
Iteration 13/1000 | Loss: 0.00072886
Iteration 14/1000 | Loss: 0.00013106
Iteration 15/1000 | Loss: 0.00080762
Iteration 16/1000 | Loss: 0.00031805
Iteration 17/1000 | Loss: 0.00020810
Iteration 18/1000 | Loss: 0.00023090
Iteration 19/1000 | Loss: 0.00013357
Iteration 20/1000 | Loss: 0.00021314
Iteration 21/1000 | Loss: 0.00025227
Iteration 22/1000 | Loss: 0.00021887
Iteration 23/1000 | Loss: 0.00018873
Iteration 24/1000 | Loss: 0.00018040
Iteration 25/1000 | Loss: 0.00022479
Iteration 26/1000 | Loss: 0.00017794
Iteration 27/1000 | Loss: 0.00021016
Iteration 28/1000 | Loss: 0.00017754
Iteration 29/1000 | Loss: 0.00037676
Iteration 30/1000 | Loss: 0.00106461
Iteration 31/1000 | Loss: 0.00038932
Iteration 32/1000 | Loss: 0.00011014
Iteration 33/1000 | Loss: 0.00024614
Iteration 34/1000 | Loss: 0.00031512
Iteration 35/1000 | Loss: 0.00076494
Iteration 36/1000 | Loss: 0.00046838
Iteration 37/1000 | Loss: 0.00006770
Iteration 38/1000 | Loss: 0.00047773
Iteration 39/1000 | Loss: 0.00005338
Iteration 40/1000 | Loss: 0.00057114
Iteration 41/1000 | Loss: 0.00003813
Iteration 42/1000 | Loss: 0.00003519
Iteration 43/1000 | Loss: 0.00003175
Iteration 44/1000 | Loss: 0.00002861
Iteration 45/1000 | Loss: 0.00004335
Iteration 46/1000 | Loss: 0.00002660
Iteration 47/1000 | Loss: 0.00002447
Iteration 48/1000 | Loss: 0.00002348
Iteration 49/1000 | Loss: 0.00003228
Iteration 50/1000 | Loss: 0.00002666
Iteration 51/1000 | Loss: 0.00002202
Iteration 52/1000 | Loss: 0.00002155
Iteration 53/1000 | Loss: 0.00032643
Iteration 54/1000 | Loss: 0.00003217
Iteration 55/1000 | Loss: 0.00029161
Iteration 56/1000 | Loss: 0.00002669
Iteration 57/1000 | Loss: 0.00002235
Iteration 58/1000 | Loss: 0.00002004
Iteration 59/1000 | Loss: 0.00001780
Iteration 60/1000 | Loss: 0.00001685
Iteration 61/1000 | Loss: 0.00001609
Iteration 62/1000 | Loss: 0.00001570
Iteration 63/1000 | Loss: 0.00001526
Iteration 64/1000 | Loss: 0.00001490
Iteration 65/1000 | Loss: 0.00001460
Iteration 66/1000 | Loss: 0.00001438
Iteration 67/1000 | Loss: 0.00001411
Iteration 68/1000 | Loss: 0.00001402
Iteration 69/1000 | Loss: 0.00001400
Iteration 70/1000 | Loss: 0.00001400
Iteration 71/1000 | Loss: 0.00001398
Iteration 72/1000 | Loss: 0.00001397
Iteration 73/1000 | Loss: 0.00001392
Iteration 74/1000 | Loss: 0.00001392
Iteration 75/1000 | Loss: 0.00001390
Iteration 76/1000 | Loss: 0.00001390
Iteration 77/1000 | Loss: 0.00001389
Iteration 78/1000 | Loss: 0.00001389
Iteration 79/1000 | Loss: 0.00001388
Iteration 80/1000 | Loss: 0.00001388
Iteration 81/1000 | Loss: 0.00001385
Iteration 82/1000 | Loss: 0.00001385
Iteration 83/1000 | Loss: 0.00001385
Iteration 84/1000 | Loss: 0.00001381
Iteration 85/1000 | Loss: 0.00001380
Iteration 86/1000 | Loss: 0.00001380
Iteration 87/1000 | Loss: 0.00001379
Iteration 88/1000 | Loss: 0.00001379
Iteration 89/1000 | Loss: 0.00001378
Iteration 90/1000 | Loss: 0.00001377
Iteration 91/1000 | Loss: 0.00001377
Iteration 92/1000 | Loss: 0.00001376
Iteration 93/1000 | Loss: 0.00001376
Iteration 94/1000 | Loss: 0.00001376
Iteration 95/1000 | Loss: 0.00001376
Iteration 96/1000 | Loss: 0.00001376
Iteration 97/1000 | Loss: 0.00001375
Iteration 98/1000 | Loss: 0.00001375
Iteration 99/1000 | Loss: 0.00001375
Iteration 100/1000 | Loss: 0.00001374
Iteration 101/1000 | Loss: 0.00001374
Iteration 102/1000 | Loss: 0.00001374
Iteration 103/1000 | Loss: 0.00001374
Iteration 104/1000 | Loss: 0.00001374
Iteration 105/1000 | Loss: 0.00001374
Iteration 106/1000 | Loss: 0.00001374
Iteration 107/1000 | Loss: 0.00001373
Iteration 108/1000 | Loss: 0.00001373
Iteration 109/1000 | Loss: 0.00001373
Iteration 110/1000 | Loss: 0.00001372
Iteration 111/1000 | Loss: 0.00001372
Iteration 112/1000 | Loss: 0.00001372
Iteration 113/1000 | Loss: 0.00001372
Iteration 114/1000 | Loss: 0.00001371
Iteration 115/1000 | Loss: 0.00001371
Iteration 116/1000 | Loss: 0.00001371
Iteration 117/1000 | Loss: 0.00001371
Iteration 118/1000 | Loss: 0.00001371
Iteration 119/1000 | Loss: 0.00001371
Iteration 120/1000 | Loss: 0.00001371
Iteration 121/1000 | Loss: 0.00001371
Iteration 122/1000 | Loss: 0.00001371
Iteration 123/1000 | Loss: 0.00001371
Iteration 124/1000 | Loss: 0.00001371
Iteration 125/1000 | Loss: 0.00001371
Iteration 126/1000 | Loss: 0.00001371
Iteration 127/1000 | Loss: 0.00001371
Iteration 128/1000 | Loss: 0.00001371
Iteration 129/1000 | Loss: 0.00001371
Iteration 130/1000 | Loss: 0.00001371
Iteration 131/1000 | Loss: 0.00001371
Iteration 132/1000 | Loss: 0.00001371
Iteration 133/1000 | Loss: 0.00001371
Iteration 134/1000 | Loss: 0.00001371
Iteration 135/1000 | Loss: 0.00001371
Iteration 136/1000 | Loss: 0.00001371
Iteration 137/1000 | Loss: 0.00001370
Iteration 138/1000 | Loss: 0.00001370
Iteration 139/1000 | Loss: 0.00001370
Iteration 140/1000 | Loss: 0.00001370
Iteration 141/1000 | Loss: 0.00001370
Iteration 142/1000 | Loss: 0.00001370
Iteration 143/1000 | Loss: 0.00001370
Iteration 144/1000 | Loss: 0.00001370
Iteration 145/1000 | Loss: 0.00001370
Iteration 146/1000 | Loss: 0.00001370
Iteration 147/1000 | Loss: 0.00001370
Iteration 148/1000 | Loss: 0.00001370
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.3704272532777395e-05, 1.3704272532777395e-05, 1.3704272532777395e-05, 1.3704272532777395e-05, 1.3704272532777395e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3704272532777395e-05

Optimization complete. Final v2v error: 3.190701723098755 mm

Highest mean error: 4.188787937164307 mm for frame 58

Lowest mean error: 2.7909176349639893 mm for frame 89

Saving results

Total time: 144.95602416992188
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00998350
Iteration 2/25 | Loss: 0.00193882
Iteration 3/25 | Loss: 0.00192788
Iteration 4/25 | Loss: 0.00151801
Iteration 5/25 | Loss: 0.00147058
Iteration 6/25 | Loss: 0.00151145
Iteration 7/25 | Loss: 0.00152366
Iteration 8/25 | Loss: 0.00148126
Iteration 9/25 | Loss: 0.00145417
Iteration 10/25 | Loss: 0.00142485
Iteration 11/25 | Loss: 0.00140496
Iteration 12/25 | Loss: 0.00139722
Iteration 13/25 | Loss: 0.00138861
Iteration 14/25 | Loss: 0.00138408
Iteration 15/25 | Loss: 0.00138456
Iteration 16/25 | Loss: 0.00138346
Iteration 17/25 | Loss: 0.00138341
Iteration 18/25 | Loss: 0.00137623
Iteration 19/25 | Loss: 0.00138410
Iteration 20/25 | Loss: 0.00138124
Iteration 21/25 | Loss: 0.00137437
Iteration 22/25 | Loss: 0.00137211
Iteration 23/25 | Loss: 0.00137052
Iteration 24/25 | Loss: 0.00136984
Iteration 25/25 | Loss: 0.00136319

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.34067225
Iteration 2/25 | Loss: 0.00222774
Iteration 3/25 | Loss: 0.00214413
Iteration 4/25 | Loss: 0.00214413
Iteration 5/25 | Loss: 0.00214413
Iteration 6/25 | Loss: 0.00214413
Iteration 7/25 | Loss: 0.00214412
Iteration 8/25 | Loss: 0.00214412
Iteration 9/25 | Loss: 0.00214412
Iteration 10/25 | Loss: 0.00214412
Iteration 11/25 | Loss: 0.00214412
Iteration 12/25 | Loss: 0.00214412
Iteration 13/25 | Loss: 0.00214412
Iteration 14/25 | Loss: 0.00214412
Iteration 15/25 | Loss: 0.00214412
Iteration 16/25 | Loss: 0.00214412
Iteration 17/25 | Loss: 0.00214412
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0021441238932311535, 0.0021441238932311535, 0.0021441238932311535, 0.0021441238932311535, 0.0021441238932311535]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0021441238932311535

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00214412
Iteration 2/1000 | Loss: 0.00011819
Iteration 3/1000 | Loss: 0.00047631
Iteration 4/1000 | Loss: 0.00002456
Iteration 5/1000 | Loss: 0.00002007
Iteration 6/1000 | Loss: 0.00001842
Iteration 7/1000 | Loss: 0.00001735
Iteration 8/1000 | Loss: 0.00011528
Iteration 9/1000 | Loss: 0.00009798
Iteration 10/1000 | Loss: 0.00032025
Iteration 11/1000 | Loss: 0.00023059
Iteration 12/1000 | Loss: 0.00015429
Iteration 13/1000 | Loss: 0.00141560
Iteration 14/1000 | Loss: 0.00061832
Iteration 15/1000 | Loss: 0.00015670
Iteration 16/1000 | Loss: 0.00029083
Iteration 17/1000 | Loss: 0.00018436
Iteration 18/1000 | Loss: 0.00003730
Iteration 19/1000 | Loss: 0.00002362
Iteration 20/1000 | Loss: 0.00027290
Iteration 21/1000 | Loss: 0.00058700
Iteration 22/1000 | Loss: 0.00034077
Iteration 23/1000 | Loss: 0.00045350
Iteration 24/1000 | Loss: 0.00041995
Iteration 25/1000 | Loss: 0.00004542
Iteration 26/1000 | Loss: 0.00002891
Iteration 27/1000 | Loss: 0.00014960
Iteration 28/1000 | Loss: 0.00006202
Iteration 29/1000 | Loss: 0.00008470
Iteration 30/1000 | Loss: 0.00003434
Iteration 31/1000 | Loss: 0.00002338
Iteration 32/1000 | Loss: 0.00002095
Iteration 33/1000 | Loss: 0.00009429
Iteration 34/1000 | Loss: 0.00002069
Iteration 35/1000 | Loss: 0.00021050
Iteration 36/1000 | Loss: 0.00018608
Iteration 37/1000 | Loss: 0.00019502
Iteration 38/1000 | Loss: 0.00030598
Iteration 39/1000 | Loss: 0.00002922
Iteration 40/1000 | Loss: 0.00002226
Iteration 41/1000 | Loss: 0.00013502
Iteration 42/1000 | Loss: 0.00001776
Iteration 43/1000 | Loss: 0.00001640
Iteration 44/1000 | Loss: 0.00018913
Iteration 45/1000 | Loss: 0.00006634
Iteration 46/1000 | Loss: 0.00001468
Iteration 47/1000 | Loss: 0.00006878
Iteration 48/1000 | Loss: 0.00005058
Iteration 49/1000 | Loss: 0.00001362
Iteration 50/1000 | Loss: 0.00005134
Iteration 51/1000 | Loss: 0.00002771
Iteration 52/1000 | Loss: 0.00002384
Iteration 53/1000 | Loss: 0.00001291
Iteration 54/1000 | Loss: 0.00001265
Iteration 55/1000 | Loss: 0.00001265
Iteration 56/1000 | Loss: 0.00001248
Iteration 57/1000 | Loss: 0.00001237
Iteration 58/1000 | Loss: 0.00001233
Iteration 59/1000 | Loss: 0.00001227
Iteration 60/1000 | Loss: 0.00001227
Iteration 61/1000 | Loss: 0.00001227
Iteration 62/1000 | Loss: 0.00001226
Iteration 63/1000 | Loss: 0.00001226
Iteration 64/1000 | Loss: 0.00001226
Iteration 65/1000 | Loss: 0.00001225
Iteration 66/1000 | Loss: 0.00001225
Iteration 67/1000 | Loss: 0.00001224
Iteration 68/1000 | Loss: 0.00001218
Iteration 69/1000 | Loss: 0.00001218
Iteration 70/1000 | Loss: 0.00001218
Iteration 71/1000 | Loss: 0.00001218
Iteration 72/1000 | Loss: 0.00001218
Iteration 73/1000 | Loss: 0.00001217
Iteration 74/1000 | Loss: 0.00001216
Iteration 75/1000 | Loss: 0.00001215
Iteration 76/1000 | Loss: 0.00001214
Iteration 77/1000 | Loss: 0.00001213
Iteration 78/1000 | Loss: 0.00001213
Iteration 79/1000 | Loss: 0.00001211
Iteration 80/1000 | Loss: 0.00001211
Iteration 81/1000 | Loss: 0.00001211
Iteration 82/1000 | Loss: 0.00001211
Iteration 83/1000 | Loss: 0.00001211
Iteration 84/1000 | Loss: 0.00001211
Iteration 85/1000 | Loss: 0.00001211
Iteration 86/1000 | Loss: 0.00001211
Iteration 87/1000 | Loss: 0.00001211
Iteration 88/1000 | Loss: 0.00001211
Iteration 89/1000 | Loss: 0.00001210
Iteration 90/1000 | Loss: 0.00001210
Iteration 91/1000 | Loss: 0.00001210
Iteration 92/1000 | Loss: 0.00001210
Iteration 93/1000 | Loss: 0.00001209
Iteration 94/1000 | Loss: 0.00001208
Iteration 95/1000 | Loss: 0.00001208
Iteration 96/1000 | Loss: 0.00001206
Iteration 97/1000 | Loss: 0.00001206
Iteration 98/1000 | Loss: 0.00001205
Iteration 99/1000 | Loss: 0.00001205
Iteration 100/1000 | Loss: 0.00001205
Iteration 101/1000 | Loss: 0.00001205
Iteration 102/1000 | Loss: 0.00001205
Iteration 103/1000 | Loss: 0.00001205
Iteration 104/1000 | Loss: 0.00001205
Iteration 105/1000 | Loss: 0.00001205
Iteration 106/1000 | Loss: 0.00001205
Iteration 107/1000 | Loss: 0.00001204
Iteration 108/1000 | Loss: 0.00001203
Iteration 109/1000 | Loss: 0.00001203
Iteration 110/1000 | Loss: 0.00001203
Iteration 111/1000 | Loss: 0.00001202
Iteration 112/1000 | Loss: 0.00001202
Iteration 113/1000 | Loss: 0.00001202
Iteration 114/1000 | Loss: 0.00001202
Iteration 115/1000 | Loss: 0.00001202
Iteration 116/1000 | Loss: 0.00001202
Iteration 117/1000 | Loss: 0.00001202
Iteration 118/1000 | Loss: 0.00001202
Iteration 119/1000 | Loss: 0.00001201
Iteration 120/1000 | Loss: 0.00001201
Iteration 121/1000 | Loss: 0.00001201
Iteration 122/1000 | Loss: 0.00001201
Iteration 123/1000 | Loss: 0.00001201
Iteration 124/1000 | Loss: 0.00001201
Iteration 125/1000 | Loss: 0.00001201
Iteration 126/1000 | Loss: 0.00001201
Iteration 127/1000 | Loss: 0.00001201
Iteration 128/1000 | Loss: 0.00001201
Iteration 129/1000 | Loss: 0.00001201
Iteration 130/1000 | Loss: 0.00001201
Iteration 131/1000 | Loss: 0.00001201
Iteration 132/1000 | Loss: 0.00001201
Iteration 133/1000 | Loss: 0.00001200
Iteration 134/1000 | Loss: 0.00001200
Iteration 135/1000 | Loss: 0.00001200
Iteration 136/1000 | Loss: 0.00001200
Iteration 137/1000 | Loss: 0.00001199
Iteration 138/1000 | Loss: 0.00001199
Iteration 139/1000 | Loss: 0.00001199
Iteration 140/1000 | Loss: 0.00001199
Iteration 141/1000 | Loss: 0.00001199
Iteration 142/1000 | Loss: 0.00001199
Iteration 143/1000 | Loss: 0.00001198
Iteration 144/1000 | Loss: 0.00001198
Iteration 145/1000 | Loss: 0.00001197
Iteration 146/1000 | Loss: 0.00001197
Iteration 147/1000 | Loss: 0.00001196
Iteration 148/1000 | Loss: 0.00001196
Iteration 149/1000 | Loss: 0.00001196
Iteration 150/1000 | Loss: 0.00001196
Iteration 151/1000 | Loss: 0.00001196
Iteration 152/1000 | Loss: 0.00001195
Iteration 153/1000 | Loss: 0.00001195
Iteration 154/1000 | Loss: 0.00001195
Iteration 155/1000 | Loss: 0.00001194
Iteration 156/1000 | Loss: 0.00001194
Iteration 157/1000 | Loss: 0.00001193
Iteration 158/1000 | Loss: 0.00001192
Iteration 159/1000 | Loss: 0.00001192
Iteration 160/1000 | Loss: 0.00001191
Iteration 161/1000 | Loss: 0.00001191
Iteration 162/1000 | Loss: 0.00001190
Iteration 163/1000 | Loss: 0.00001190
Iteration 164/1000 | Loss: 0.00001189
Iteration 165/1000 | Loss: 0.00001189
Iteration 166/1000 | Loss: 0.00001189
Iteration 167/1000 | Loss: 0.00001189
Iteration 168/1000 | Loss: 0.00001189
Iteration 169/1000 | Loss: 0.00001188
Iteration 170/1000 | Loss: 0.00001188
Iteration 171/1000 | Loss: 0.00001188
Iteration 172/1000 | Loss: 0.00001188
Iteration 173/1000 | Loss: 0.00001188
Iteration 174/1000 | Loss: 0.00001187
Iteration 175/1000 | Loss: 0.00001187
Iteration 176/1000 | Loss: 0.00001187
Iteration 177/1000 | Loss: 0.00001187
Iteration 178/1000 | Loss: 0.00001186
Iteration 179/1000 | Loss: 0.00001186
Iteration 180/1000 | Loss: 0.00001186
Iteration 181/1000 | Loss: 0.00001186
Iteration 182/1000 | Loss: 0.00001186
Iteration 183/1000 | Loss: 0.00001186
Iteration 184/1000 | Loss: 0.00001186
Iteration 185/1000 | Loss: 0.00001185
Iteration 186/1000 | Loss: 0.00001185
Iteration 187/1000 | Loss: 0.00001185
Iteration 188/1000 | Loss: 0.00001185
Iteration 189/1000 | Loss: 0.00001185
Iteration 190/1000 | Loss: 0.00001185
Iteration 191/1000 | Loss: 0.00001185
Iteration 192/1000 | Loss: 0.00001185
Iteration 193/1000 | Loss: 0.00001185
Iteration 194/1000 | Loss: 0.00001185
Iteration 195/1000 | Loss: 0.00001185
Iteration 196/1000 | Loss: 0.00001184
Iteration 197/1000 | Loss: 0.00001184
Iteration 198/1000 | Loss: 0.00001184
Iteration 199/1000 | Loss: 0.00001184
Iteration 200/1000 | Loss: 0.00001184
Iteration 201/1000 | Loss: 0.00001184
Iteration 202/1000 | Loss: 0.00001184
Iteration 203/1000 | Loss: 0.00001183
Iteration 204/1000 | Loss: 0.00001183
Iteration 205/1000 | Loss: 0.00001183
Iteration 206/1000 | Loss: 0.00001183
Iteration 207/1000 | Loss: 0.00001183
Iteration 208/1000 | Loss: 0.00001183
Iteration 209/1000 | Loss: 0.00001183
Iteration 210/1000 | Loss: 0.00001183
Iteration 211/1000 | Loss: 0.00001183
Iteration 212/1000 | Loss: 0.00001183
Iteration 213/1000 | Loss: 0.00001183
Iteration 214/1000 | Loss: 0.00001183
Iteration 215/1000 | Loss: 0.00001183
Iteration 216/1000 | Loss: 0.00001182
Iteration 217/1000 | Loss: 0.00001182
Iteration 218/1000 | Loss: 0.00001181
Iteration 219/1000 | Loss: 0.00001181
Iteration 220/1000 | Loss: 0.00001181
Iteration 221/1000 | Loss: 0.00001181
Iteration 222/1000 | Loss: 0.00001181
Iteration 223/1000 | Loss: 0.00001180
Iteration 224/1000 | Loss: 0.00001180
Iteration 225/1000 | Loss: 0.00001180
Iteration 226/1000 | Loss: 0.00001180
Iteration 227/1000 | Loss: 0.00001180
Iteration 228/1000 | Loss: 0.00001179
Iteration 229/1000 | Loss: 0.00001179
Iteration 230/1000 | Loss: 0.00001179
Iteration 231/1000 | Loss: 0.00001179
Iteration 232/1000 | Loss: 0.00001179
Iteration 233/1000 | Loss: 0.00001179
Iteration 234/1000 | Loss: 0.00001179
Iteration 235/1000 | Loss: 0.00001179
Iteration 236/1000 | Loss: 0.00001179
Iteration 237/1000 | Loss: 0.00001179
Iteration 238/1000 | Loss: 0.00001179
Iteration 239/1000 | Loss: 0.00001179
Iteration 240/1000 | Loss: 0.00001179
Iteration 241/1000 | Loss: 0.00001179
Iteration 242/1000 | Loss: 0.00001179
Iteration 243/1000 | Loss: 0.00001179
Iteration 244/1000 | Loss: 0.00001179
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 244. Stopping optimization.
Last 5 losses: [1.1789957170549314e-05, 1.1789957170549314e-05, 1.1789957170549314e-05, 1.1789957170549314e-05, 1.1789957170549314e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1789957170549314e-05

Optimization complete. Final v2v error: 2.9674935340881348 mm

Highest mean error: 3.691011905670166 mm for frame 89

Lowest mean error: 2.829040050506592 mm for frame 10

Saving results

Total time: 138.11110949516296
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1033/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1033.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1033
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00730421
Iteration 2/25 | Loss: 0.00146853
Iteration 3/25 | Loss: 0.00139951
Iteration 4/25 | Loss: 0.00139091
Iteration 5/25 | Loss: 0.00138895
Iteration 6/25 | Loss: 0.00138876
Iteration 7/25 | Loss: 0.00138876
Iteration 8/25 | Loss: 0.00138876
Iteration 9/25 | Loss: 0.00138876
Iteration 10/25 | Loss: 0.00138876
Iteration 11/25 | Loss: 0.00138876
Iteration 12/25 | Loss: 0.00138876
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0013887635432183743, 0.0013887635432183743, 0.0013887635432183743, 0.0013887635432183743, 0.0013887635432183743]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013887635432183743

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25360024
Iteration 2/25 | Loss: 0.00164261
Iteration 3/25 | Loss: 0.00164253
Iteration 4/25 | Loss: 0.00164253
Iteration 5/25 | Loss: 0.00164253
Iteration 6/25 | Loss: 0.00164253
Iteration 7/25 | Loss: 0.00164253
Iteration 8/25 | Loss: 0.00164253
Iteration 9/25 | Loss: 0.00164253
Iteration 10/25 | Loss: 0.00164253
Iteration 11/25 | Loss: 0.00164253
Iteration 12/25 | Loss: 0.00164253
Iteration 13/25 | Loss: 0.00164253
Iteration 14/25 | Loss: 0.00164253
Iteration 15/25 | Loss: 0.00164253
Iteration 16/25 | Loss: 0.00164253
Iteration 17/25 | Loss: 0.00164253
Iteration 18/25 | Loss: 0.00164253
Iteration 19/25 | Loss: 0.00164253
Iteration 20/25 | Loss: 0.00164253
Iteration 21/25 | Loss: 0.00164253
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0016425284557044506, 0.0016425284557044506, 0.0016425284557044506, 0.0016425284557044506, 0.0016425284557044506]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016425284557044506

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00164253
Iteration 2/1000 | Loss: 0.00004005
Iteration 3/1000 | Loss: 0.00002966
Iteration 4/1000 | Loss: 0.00002687
Iteration 5/1000 | Loss: 0.00002515
Iteration 6/1000 | Loss: 0.00002399
Iteration 7/1000 | Loss: 0.00002312
Iteration 8/1000 | Loss: 0.00002247
Iteration 9/1000 | Loss: 0.00002208
Iteration 10/1000 | Loss: 0.00002164
Iteration 11/1000 | Loss: 0.00002130
Iteration 12/1000 | Loss: 0.00002095
Iteration 13/1000 | Loss: 0.00002064
Iteration 14/1000 | Loss: 0.00002023
Iteration 15/1000 | Loss: 0.00002011
Iteration 16/1000 | Loss: 0.00001989
Iteration 17/1000 | Loss: 0.00001985
Iteration 18/1000 | Loss: 0.00001982
Iteration 19/1000 | Loss: 0.00001981
Iteration 20/1000 | Loss: 0.00001980
Iteration 21/1000 | Loss: 0.00001971
Iteration 22/1000 | Loss: 0.00001968
Iteration 23/1000 | Loss: 0.00001966
Iteration 24/1000 | Loss: 0.00001962
Iteration 25/1000 | Loss: 0.00001961
Iteration 26/1000 | Loss: 0.00001960
Iteration 27/1000 | Loss: 0.00001959
Iteration 28/1000 | Loss: 0.00001959
Iteration 29/1000 | Loss: 0.00001958
Iteration 30/1000 | Loss: 0.00001955
Iteration 31/1000 | Loss: 0.00001954
Iteration 32/1000 | Loss: 0.00001954
Iteration 33/1000 | Loss: 0.00001953
Iteration 34/1000 | Loss: 0.00001952
Iteration 35/1000 | Loss: 0.00001952
Iteration 36/1000 | Loss: 0.00001948
Iteration 37/1000 | Loss: 0.00001948
Iteration 38/1000 | Loss: 0.00001946
Iteration 39/1000 | Loss: 0.00001943
Iteration 40/1000 | Loss: 0.00001943
Iteration 41/1000 | Loss: 0.00001943
Iteration 42/1000 | Loss: 0.00001942
Iteration 43/1000 | Loss: 0.00001935
Iteration 44/1000 | Loss: 0.00001935
Iteration 45/1000 | Loss: 0.00001934
Iteration 46/1000 | Loss: 0.00001933
Iteration 47/1000 | Loss: 0.00001930
Iteration 48/1000 | Loss: 0.00001930
Iteration 49/1000 | Loss: 0.00001929
Iteration 50/1000 | Loss: 0.00001929
Iteration 51/1000 | Loss: 0.00001929
Iteration 52/1000 | Loss: 0.00001929
Iteration 53/1000 | Loss: 0.00001929
Iteration 54/1000 | Loss: 0.00001927
Iteration 55/1000 | Loss: 0.00001926
Iteration 56/1000 | Loss: 0.00001926
Iteration 57/1000 | Loss: 0.00001925
Iteration 58/1000 | Loss: 0.00001925
Iteration 59/1000 | Loss: 0.00001925
Iteration 60/1000 | Loss: 0.00001925
Iteration 61/1000 | Loss: 0.00001925
Iteration 62/1000 | Loss: 0.00001925
Iteration 63/1000 | Loss: 0.00001925
Iteration 64/1000 | Loss: 0.00001925
Iteration 65/1000 | Loss: 0.00001925
Iteration 66/1000 | Loss: 0.00001925
Iteration 67/1000 | Loss: 0.00001924
Iteration 68/1000 | Loss: 0.00001924
Iteration 69/1000 | Loss: 0.00001924
Iteration 70/1000 | Loss: 0.00001924
Iteration 71/1000 | Loss: 0.00001924
Iteration 72/1000 | Loss: 0.00001923
Iteration 73/1000 | Loss: 0.00001923
Iteration 74/1000 | Loss: 0.00001922
Iteration 75/1000 | Loss: 0.00001922
Iteration 76/1000 | Loss: 0.00001922
Iteration 77/1000 | Loss: 0.00001921
Iteration 78/1000 | Loss: 0.00001921
Iteration 79/1000 | Loss: 0.00001921
Iteration 80/1000 | Loss: 0.00001921
Iteration 81/1000 | Loss: 0.00001920
Iteration 82/1000 | Loss: 0.00001920
Iteration 83/1000 | Loss: 0.00001920
Iteration 84/1000 | Loss: 0.00001920
Iteration 85/1000 | Loss: 0.00001920
Iteration 86/1000 | Loss: 0.00001919
Iteration 87/1000 | Loss: 0.00001919
Iteration 88/1000 | Loss: 0.00001919
Iteration 89/1000 | Loss: 0.00001919
Iteration 90/1000 | Loss: 0.00001918
Iteration 91/1000 | Loss: 0.00001918
Iteration 92/1000 | Loss: 0.00001918
Iteration 93/1000 | Loss: 0.00001918
Iteration 94/1000 | Loss: 0.00001917
Iteration 95/1000 | Loss: 0.00001917
Iteration 96/1000 | Loss: 0.00001917
Iteration 97/1000 | Loss: 0.00001917
Iteration 98/1000 | Loss: 0.00001917
Iteration 99/1000 | Loss: 0.00001917
Iteration 100/1000 | Loss: 0.00001917
Iteration 101/1000 | Loss: 0.00001917
Iteration 102/1000 | Loss: 0.00001917
Iteration 103/1000 | Loss: 0.00001917
Iteration 104/1000 | Loss: 0.00001917
Iteration 105/1000 | Loss: 0.00001917
Iteration 106/1000 | Loss: 0.00001917
Iteration 107/1000 | Loss: 0.00001917
Iteration 108/1000 | Loss: 0.00001917
Iteration 109/1000 | Loss: 0.00001917
Iteration 110/1000 | Loss: 0.00001917
Iteration 111/1000 | Loss: 0.00001917
Iteration 112/1000 | Loss: 0.00001917
Iteration 113/1000 | Loss: 0.00001917
Iteration 114/1000 | Loss: 0.00001917
Iteration 115/1000 | Loss: 0.00001917
Iteration 116/1000 | Loss: 0.00001917
Iteration 117/1000 | Loss: 0.00001917
Iteration 118/1000 | Loss: 0.00001917
Iteration 119/1000 | Loss: 0.00001917
Iteration 120/1000 | Loss: 0.00001917
Iteration 121/1000 | Loss: 0.00001917
Iteration 122/1000 | Loss: 0.00001917
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [1.9169319784850813e-05, 1.9169319784850813e-05, 1.9169319784850813e-05, 1.9169319784850813e-05, 1.9169319784850813e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9169319784850813e-05

Optimization complete. Final v2v error: 3.7074506282806396 mm

Highest mean error: 3.9547555446624756 mm for frame 42

Lowest mean error: 3.5901007652282715 mm for frame 94

Saving results

Total time: 40.53228139877319
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00959147
Iteration 2/25 | Loss: 0.00223589
Iteration 3/25 | Loss: 0.00185866
Iteration 4/25 | Loss: 0.00168786
Iteration 5/25 | Loss: 0.00179030
Iteration 6/25 | Loss: 0.00174116
Iteration 7/25 | Loss: 0.00162026
Iteration 8/25 | Loss: 0.00149601
Iteration 9/25 | Loss: 0.00153130
Iteration 10/25 | Loss: 0.00145374
Iteration 11/25 | Loss: 0.00159041
Iteration 12/25 | Loss: 0.00145194
Iteration 13/25 | Loss: 0.00144721
Iteration 14/25 | Loss: 0.00145038
Iteration 15/25 | Loss: 0.00144797
Iteration 16/25 | Loss: 0.00144621
Iteration 17/25 | Loss: 0.00144391
Iteration 18/25 | Loss: 0.00144333
Iteration 19/25 | Loss: 0.00144429
Iteration 20/25 | Loss: 0.00144227
Iteration 21/25 | Loss: 0.00144082
Iteration 22/25 | Loss: 0.00144037
Iteration 23/25 | Loss: 0.00144036
Iteration 24/25 | Loss: 0.00144036
Iteration 25/25 | Loss: 0.00144035

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.70348907
Iteration 2/25 | Loss: 0.00251582
Iteration 3/25 | Loss: 0.00251582
Iteration 4/25 | Loss: 0.00251582
Iteration 5/25 | Loss: 0.00251581
Iteration 6/25 | Loss: 0.00251581
Iteration 7/25 | Loss: 0.00251581
Iteration 8/25 | Loss: 0.00251581
Iteration 9/25 | Loss: 0.00251581
Iteration 10/25 | Loss: 0.00251581
Iteration 11/25 | Loss: 0.00251581
Iteration 12/25 | Loss: 0.00251581
Iteration 13/25 | Loss: 0.00251581
Iteration 14/25 | Loss: 0.00251581
Iteration 15/25 | Loss: 0.00251581
Iteration 16/25 | Loss: 0.00251581
Iteration 17/25 | Loss: 0.00251581
Iteration 18/25 | Loss: 0.00251581
Iteration 19/25 | Loss: 0.00251581
Iteration 20/25 | Loss: 0.00251581
Iteration 21/25 | Loss: 0.00251581
Iteration 22/25 | Loss: 0.00251581
Iteration 23/25 | Loss: 0.00251581
Iteration 24/25 | Loss: 0.00251581
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0025158121716231108, 0.0025158121716231108, 0.0025158121716231108, 0.0025158121716231108, 0.0025158121716231108]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0025158121716231108

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00251581
Iteration 2/1000 | Loss: 0.00013964
Iteration 3/1000 | Loss: 0.00009925
Iteration 4/1000 | Loss: 0.00006796
Iteration 5/1000 | Loss: 0.00005779
Iteration 6/1000 | Loss: 0.00005246
Iteration 7/1000 | Loss: 0.00005030
Iteration 8/1000 | Loss: 0.00013252
Iteration 9/1000 | Loss: 0.00015722
Iteration 10/1000 | Loss: 0.00006998
Iteration 11/1000 | Loss: 0.00032205
Iteration 12/1000 | Loss: 0.00007164
Iteration 13/1000 | Loss: 0.00020015
Iteration 14/1000 | Loss: 0.00007198
Iteration 15/1000 | Loss: 0.00004780
Iteration 16/1000 | Loss: 0.00003930
Iteration 17/1000 | Loss: 0.00003571
Iteration 18/1000 | Loss: 0.00003223
Iteration 19/1000 | Loss: 0.00002999
Iteration 20/1000 | Loss: 0.00026439
Iteration 21/1000 | Loss: 0.00073376
Iteration 22/1000 | Loss: 0.00035163
Iteration 23/1000 | Loss: 0.00004347
Iteration 24/1000 | Loss: 0.00025779
Iteration 25/1000 | Loss: 0.00004240
Iteration 26/1000 | Loss: 0.00003399
Iteration 27/1000 | Loss: 0.00002989
Iteration 28/1000 | Loss: 0.00002720
Iteration 29/1000 | Loss: 0.00002572
Iteration 30/1000 | Loss: 0.00002494
Iteration 31/1000 | Loss: 0.00002413
Iteration 32/1000 | Loss: 0.00032697
Iteration 33/1000 | Loss: 0.00003646
Iteration 34/1000 | Loss: 0.00002966
Iteration 35/1000 | Loss: 0.00002544
Iteration 36/1000 | Loss: 0.00013356
Iteration 37/1000 | Loss: 0.00009817
Iteration 38/1000 | Loss: 0.00010542
Iteration 39/1000 | Loss: 0.00013184
Iteration 40/1000 | Loss: 0.00002716
Iteration 41/1000 | Loss: 0.00002519
Iteration 42/1000 | Loss: 0.00002392
Iteration 43/1000 | Loss: 0.00002327
Iteration 44/1000 | Loss: 0.00035902
Iteration 45/1000 | Loss: 0.00074955
Iteration 46/1000 | Loss: 0.00038745
Iteration 47/1000 | Loss: 0.00016657
Iteration 48/1000 | Loss: 0.00028283
Iteration 49/1000 | Loss: 0.00004445
Iteration 50/1000 | Loss: 0.00002851
Iteration 51/1000 | Loss: 0.00002886
Iteration 52/1000 | Loss: 0.00002512
Iteration 53/1000 | Loss: 0.00002348
Iteration 54/1000 | Loss: 0.00041937
Iteration 55/1000 | Loss: 0.00076762
Iteration 56/1000 | Loss: 0.00007309
Iteration 57/1000 | Loss: 0.00005314
Iteration 58/1000 | Loss: 0.00003410
Iteration 59/1000 | Loss: 0.00002974
Iteration 60/1000 | Loss: 0.00002463
Iteration 61/1000 | Loss: 0.00002164
Iteration 62/1000 | Loss: 0.00001959
Iteration 63/1000 | Loss: 0.00001856
Iteration 64/1000 | Loss: 0.00001757
Iteration 65/1000 | Loss: 0.00001708
Iteration 66/1000 | Loss: 0.00001672
Iteration 67/1000 | Loss: 0.00001644
Iteration 68/1000 | Loss: 0.00001630
Iteration 69/1000 | Loss: 0.00001623
Iteration 70/1000 | Loss: 0.00001621
Iteration 71/1000 | Loss: 0.00001620
Iteration 72/1000 | Loss: 0.00001616
Iteration 73/1000 | Loss: 0.00001612
Iteration 74/1000 | Loss: 0.00001611
Iteration 75/1000 | Loss: 0.00001603
Iteration 76/1000 | Loss: 0.00001603
Iteration 77/1000 | Loss: 0.00001601
Iteration 78/1000 | Loss: 0.00001601
Iteration 79/1000 | Loss: 0.00001601
Iteration 80/1000 | Loss: 0.00001600
Iteration 81/1000 | Loss: 0.00001600
Iteration 82/1000 | Loss: 0.00001600
Iteration 83/1000 | Loss: 0.00001600
Iteration 84/1000 | Loss: 0.00001599
Iteration 85/1000 | Loss: 0.00001599
Iteration 86/1000 | Loss: 0.00001599
Iteration 87/1000 | Loss: 0.00001599
Iteration 88/1000 | Loss: 0.00001598
Iteration 89/1000 | Loss: 0.00001598
Iteration 90/1000 | Loss: 0.00001598
Iteration 91/1000 | Loss: 0.00001598
Iteration 92/1000 | Loss: 0.00001597
Iteration 93/1000 | Loss: 0.00001597
Iteration 94/1000 | Loss: 0.00001597
Iteration 95/1000 | Loss: 0.00001597
Iteration 96/1000 | Loss: 0.00001596
Iteration 97/1000 | Loss: 0.00001596
Iteration 98/1000 | Loss: 0.00001596
Iteration 99/1000 | Loss: 0.00001596
Iteration 100/1000 | Loss: 0.00001596
Iteration 101/1000 | Loss: 0.00001596
Iteration 102/1000 | Loss: 0.00001596
Iteration 103/1000 | Loss: 0.00001596
Iteration 104/1000 | Loss: 0.00001596
Iteration 105/1000 | Loss: 0.00001596
Iteration 106/1000 | Loss: 0.00001596
Iteration 107/1000 | Loss: 0.00001596
Iteration 108/1000 | Loss: 0.00001595
Iteration 109/1000 | Loss: 0.00001595
Iteration 110/1000 | Loss: 0.00001594
Iteration 111/1000 | Loss: 0.00001594
Iteration 112/1000 | Loss: 0.00001594
Iteration 113/1000 | Loss: 0.00001594
Iteration 114/1000 | Loss: 0.00001594
Iteration 115/1000 | Loss: 0.00001593
Iteration 116/1000 | Loss: 0.00001593
Iteration 117/1000 | Loss: 0.00001593
Iteration 118/1000 | Loss: 0.00001593
Iteration 119/1000 | Loss: 0.00001593
Iteration 120/1000 | Loss: 0.00001593
Iteration 121/1000 | Loss: 0.00001593
Iteration 122/1000 | Loss: 0.00001593
Iteration 123/1000 | Loss: 0.00001593
Iteration 124/1000 | Loss: 0.00001593
Iteration 125/1000 | Loss: 0.00001592
Iteration 126/1000 | Loss: 0.00001592
Iteration 127/1000 | Loss: 0.00001592
Iteration 128/1000 | Loss: 0.00001592
Iteration 129/1000 | Loss: 0.00001592
Iteration 130/1000 | Loss: 0.00001592
Iteration 131/1000 | Loss: 0.00001592
Iteration 132/1000 | Loss: 0.00001592
Iteration 133/1000 | Loss: 0.00001591
Iteration 134/1000 | Loss: 0.00001591
Iteration 135/1000 | Loss: 0.00001591
Iteration 136/1000 | Loss: 0.00001591
Iteration 137/1000 | Loss: 0.00001591
Iteration 138/1000 | Loss: 0.00001591
Iteration 139/1000 | Loss: 0.00001591
Iteration 140/1000 | Loss: 0.00001591
Iteration 141/1000 | Loss: 0.00001591
Iteration 142/1000 | Loss: 0.00001591
Iteration 143/1000 | Loss: 0.00001591
Iteration 144/1000 | Loss: 0.00001591
Iteration 145/1000 | Loss: 0.00001591
Iteration 146/1000 | Loss: 0.00001591
Iteration 147/1000 | Loss: 0.00001591
Iteration 148/1000 | Loss: 0.00001591
Iteration 149/1000 | Loss: 0.00001591
Iteration 150/1000 | Loss: 0.00001590
Iteration 151/1000 | Loss: 0.00001590
Iteration 152/1000 | Loss: 0.00001590
Iteration 153/1000 | Loss: 0.00001590
Iteration 154/1000 | Loss: 0.00001590
Iteration 155/1000 | Loss: 0.00001589
Iteration 156/1000 | Loss: 0.00001589
Iteration 157/1000 | Loss: 0.00001589
Iteration 158/1000 | Loss: 0.00001589
Iteration 159/1000 | Loss: 0.00001589
Iteration 160/1000 | Loss: 0.00001589
Iteration 161/1000 | Loss: 0.00001589
Iteration 162/1000 | Loss: 0.00001589
Iteration 163/1000 | Loss: 0.00001589
Iteration 164/1000 | Loss: 0.00001589
Iteration 165/1000 | Loss: 0.00001589
Iteration 166/1000 | Loss: 0.00001589
Iteration 167/1000 | Loss: 0.00001589
Iteration 168/1000 | Loss: 0.00001589
Iteration 169/1000 | Loss: 0.00001588
Iteration 170/1000 | Loss: 0.00001588
Iteration 171/1000 | Loss: 0.00001588
Iteration 172/1000 | Loss: 0.00001588
Iteration 173/1000 | Loss: 0.00001588
Iteration 174/1000 | Loss: 0.00001588
Iteration 175/1000 | Loss: 0.00001588
Iteration 176/1000 | Loss: 0.00001588
Iteration 177/1000 | Loss: 0.00001588
Iteration 178/1000 | Loss: 0.00001587
Iteration 179/1000 | Loss: 0.00001587
Iteration 180/1000 | Loss: 0.00001587
Iteration 181/1000 | Loss: 0.00001587
Iteration 182/1000 | Loss: 0.00001587
Iteration 183/1000 | Loss: 0.00001587
Iteration 184/1000 | Loss: 0.00001587
Iteration 185/1000 | Loss: 0.00001587
Iteration 186/1000 | Loss: 0.00001587
Iteration 187/1000 | Loss: 0.00001587
Iteration 188/1000 | Loss: 0.00001587
Iteration 189/1000 | Loss: 0.00001587
Iteration 190/1000 | Loss: 0.00001586
Iteration 191/1000 | Loss: 0.00001586
Iteration 192/1000 | Loss: 0.00001586
Iteration 193/1000 | Loss: 0.00001586
Iteration 194/1000 | Loss: 0.00001586
Iteration 195/1000 | Loss: 0.00001586
Iteration 196/1000 | Loss: 0.00001586
Iteration 197/1000 | Loss: 0.00001586
Iteration 198/1000 | Loss: 0.00001586
Iteration 199/1000 | Loss: 0.00001586
Iteration 200/1000 | Loss: 0.00001585
Iteration 201/1000 | Loss: 0.00001585
Iteration 202/1000 | Loss: 0.00001585
Iteration 203/1000 | Loss: 0.00001585
Iteration 204/1000 | Loss: 0.00001585
Iteration 205/1000 | Loss: 0.00001585
Iteration 206/1000 | Loss: 0.00001585
Iteration 207/1000 | Loss: 0.00001585
Iteration 208/1000 | Loss: 0.00001585
Iteration 209/1000 | Loss: 0.00001584
Iteration 210/1000 | Loss: 0.00001584
Iteration 211/1000 | Loss: 0.00001584
Iteration 212/1000 | Loss: 0.00001584
Iteration 213/1000 | Loss: 0.00001584
Iteration 214/1000 | Loss: 0.00001584
Iteration 215/1000 | Loss: 0.00001584
Iteration 216/1000 | Loss: 0.00001584
Iteration 217/1000 | Loss: 0.00001584
Iteration 218/1000 | Loss: 0.00001584
Iteration 219/1000 | Loss: 0.00001584
Iteration 220/1000 | Loss: 0.00001584
Iteration 221/1000 | Loss: 0.00001583
Iteration 222/1000 | Loss: 0.00001583
Iteration 223/1000 | Loss: 0.00001583
Iteration 224/1000 | Loss: 0.00001583
Iteration 225/1000 | Loss: 0.00001583
Iteration 226/1000 | Loss: 0.00001583
Iteration 227/1000 | Loss: 0.00001583
Iteration 228/1000 | Loss: 0.00001583
Iteration 229/1000 | Loss: 0.00001583
Iteration 230/1000 | Loss: 0.00001583
Iteration 231/1000 | Loss: 0.00001583
Iteration 232/1000 | Loss: 0.00001583
Iteration 233/1000 | Loss: 0.00001583
Iteration 234/1000 | Loss: 0.00001583
Iteration 235/1000 | Loss: 0.00001583
Iteration 236/1000 | Loss: 0.00001583
Iteration 237/1000 | Loss: 0.00001582
Iteration 238/1000 | Loss: 0.00001582
Iteration 239/1000 | Loss: 0.00001582
Iteration 240/1000 | Loss: 0.00001582
Iteration 241/1000 | Loss: 0.00001582
Iteration 242/1000 | Loss: 0.00001582
Iteration 243/1000 | Loss: 0.00001582
Iteration 244/1000 | Loss: 0.00001582
Iteration 245/1000 | Loss: 0.00001582
Iteration 246/1000 | Loss: 0.00001582
Iteration 247/1000 | Loss: 0.00001582
Iteration 248/1000 | Loss: 0.00001582
Iteration 249/1000 | Loss: 0.00001582
Iteration 250/1000 | Loss: 0.00001582
Iteration 251/1000 | Loss: 0.00001581
Iteration 252/1000 | Loss: 0.00001581
Iteration 253/1000 | Loss: 0.00001581
Iteration 254/1000 | Loss: 0.00001581
Iteration 255/1000 | Loss: 0.00001581
Iteration 256/1000 | Loss: 0.00001581
Iteration 257/1000 | Loss: 0.00001581
Iteration 258/1000 | Loss: 0.00001581
Iteration 259/1000 | Loss: 0.00001581
Iteration 260/1000 | Loss: 0.00001580
Iteration 261/1000 | Loss: 0.00001580
Iteration 262/1000 | Loss: 0.00001580
Iteration 263/1000 | Loss: 0.00001580
Iteration 264/1000 | Loss: 0.00001580
Iteration 265/1000 | Loss: 0.00001580
Iteration 266/1000 | Loss: 0.00001580
Iteration 267/1000 | Loss: 0.00001580
Iteration 268/1000 | Loss: 0.00001580
Iteration 269/1000 | Loss: 0.00001580
Iteration 270/1000 | Loss: 0.00001580
Iteration 271/1000 | Loss: 0.00001580
Iteration 272/1000 | Loss: 0.00001580
Iteration 273/1000 | Loss: 0.00001580
Iteration 274/1000 | Loss: 0.00001580
Iteration 275/1000 | Loss: 0.00001580
Iteration 276/1000 | Loss: 0.00001580
Iteration 277/1000 | Loss: 0.00001580
Iteration 278/1000 | Loss: 0.00001580
Iteration 279/1000 | Loss: 0.00001580
Iteration 280/1000 | Loss: 0.00001580
Iteration 281/1000 | Loss: 0.00001580
Iteration 282/1000 | Loss: 0.00001580
Iteration 283/1000 | Loss: 0.00001580
Iteration 284/1000 | Loss: 0.00001580
Iteration 285/1000 | Loss: 0.00001580
Iteration 286/1000 | Loss: 0.00001580
Iteration 287/1000 | Loss: 0.00001580
Iteration 288/1000 | Loss: 0.00001580
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 288. Stopping optimization.
Last 5 losses: [1.5804429494892247e-05, 1.5804429494892247e-05, 1.5804429494892247e-05, 1.5804429494892247e-05, 1.5804429494892247e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5804429494892247e-05

Optimization complete. Final v2v error: 3.3662071228027344 mm

Highest mean error: 4.672348976135254 mm for frame 69

Lowest mean error: 2.998671770095825 mm for frame 108

Saving results

Total time: 145.2036361694336
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1043/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1043.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1043
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00951720
Iteration 2/25 | Loss: 0.00951720
Iteration 3/25 | Loss: 0.00951720
Iteration 4/25 | Loss: 0.00951720
Iteration 5/25 | Loss: 0.00951719
Iteration 6/25 | Loss: 0.00319197
Iteration 7/25 | Loss: 0.00251594
Iteration 8/25 | Loss: 0.00209584
Iteration 9/25 | Loss: 0.00207795
Iteration 10/25 | Loss: 0.00180325
Iteration 11/25 | Loss: 0.00176052
Iteration 12/25 | Loss: 0.00174481
Iteration 13/25 | Loss: 0.00172282
Iteration 14/25 | Loss: 0.00166256
Iteration 15/25 | Loss: 0.00166422
Iteration 16/25 | Loss: 0.00162441
Iteration 17/25 | Loss: 0.00155766
Iteration 18/25 | Loss: 0.00153962
Iteration 19/25 | Loss: 0.00152521
Iteration 20/25 | Loss: 0.00151900
Iteration 21/25 | Loss: 0.00152426
Iteration 22/25 | Loss: 0.00150894
Iteration 23/25 | Loss: 0.00150462
Iteration 24/25 | Loss: 0.00150162
Iteration 25/25 | Loss: 0.00150173

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.24767518
Iteration 2/25 | Loss: 0.00268132
Iteration 3/25 | Loss: 0.00187292
Iteration 4/25 | Loss: 0.00187292
Iteration 5/25 | Loss: 0.00187292
Iteration 6/25 | Loss: 0.00187292
Iteration 7/25 | Loss: 0.00187292
Iteration 8/25 | Loss: 0.00187292
Iteration 9/25 | Loss: 0.00187292
Iteration 10/25 | Loss: 0.00187292
Iteration 11/25 | Loss: 0.00187292
Iteration 12/25 | Loss: 0.00187292
Iteration 13/25 | Loss: 0.00187292
Iteration 14/25 | Loss: 0.00187292
Iteration 15/25 | Loss: 0.00187292
Iteration 16/25 | Loss: 0.00187292
Iteration 17/25 | Loss: 0.00187292
Iteration 18/25 | Loss: 0.00187292
Iteration 19/25 | Loss: 0.00187292
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0018729153089225292, 0.0018729153089225292, 0.0018729153089225292, 0.0018729153089225292, 0.0018729153089225292]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018729153089225292

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00187292
Iteration 2/1000 | Loss: 0.00090056
Iteration 3/1000 | Loss: 0.00049792
Iteration 4/1000 | Loss: 0.00011504
Iteration 5/1000 | Loss: 0.00019486
Iteration 6/1000 | Loss: 0.00018062
Iteration 7/1000 | Loss: 0.00023521
Iteration 8/1000 | Loss: 0.00006477
Iteration 9/1000 | Loss: 0.00006175
Iteration 10/1000 | Loss: 0.00046227
Iteration 11/1000 | Loss: 0.00271555
Iteration 12/1000 | Loss: 0.00266611
Iteration 13/1000 | Loss: 0.00016033
Iteration 14/1000 | Loss: 0.00107230
Iteration 15/1000 | Loss: 0.00138768
Iteration 16/1000 | Loss: 0.00137834
Iteration 17/1000 | Loss: 0.00350820
Iteration 18/1000 | Loss: 0.00291060
Iteration 19/1000 | Loss: 0.00073947
Iteration 20/1000 | Loss: 0.00209688
Iteration 21/1000 | Loss: 0.00032417
Iteration 22/1000 | Loss: 0.00150022
Iteration 23/1000 | Loss: 0.00235802
Iteration 24/1000 | Loss: 0.00100674
Iteration 25/1000 | Loss: 0.00023481
Iteration 26/1000 | Loss: 0.00014919
Iteration 27/1000 | Loss: 0.00013188
Iteration 28/1000 | Loss: 0.00033044
Iteration 29/1000 | Loss: 0.00016218
Iteration 30/1000 | Loss: 0.00043886
Iteration 31/1000 | Loss: 0.00008198
Iteration 32/1000 | Loss: 0.00047813
Iteration 33/1000 | Loss: 0.00007181
Iteration 34/1000 | Loss: 0.00004915
Iteration 35/1000 | Loss: 0.00046731
Iteration 36/1000 | Loss: 0.00005077
Iteration 37/1000 | Loss: 0.00004345
Iteration 38/1000 | Loss: 0.00004033
Iteration 39/1000 | Loss: 0.00037422
Iteration 40/1000 | Loss: 0.00184827
Iteration 41/1000 | Loss: 0.00211912
Iteration 42/1000 | Loss: 0.00062740
Iteration 43/1000 | Loss: 0.00046764
Iteration 44/1000 | Loss: 0.00005518
Iteration 45/1000 | Loss: 0.00006886
Iteration 46/1000 | Loss: 0.00020714
Iteration 47/1000 | Loss: 0.00052561
Iteration 48/1000 | Loss: 0.00132434
Iteration 49/1000 | Loss: 0.00080359
Iteration 50/1000 | Loss: 0.00065791
Iteration 51/1000 | Loss: 0.00054412
Iteration 52/1000 | Loss: 0.00057585
Iteration 53/1000 | Loss: 0.00043820
Iteration 54/1000 | Loss: 0.00068446
Iteration 55/1000 | Loss: 0.00035888
Iteration 56/1000 | Loss: 0.00069225
Iteration 57/1000 | Loss: 0.00053740
Iteration 58/1000 | Loss: 0.00092750
Iteration 59/1000 | Loss: 0.00017660
Iteration 60/1000 | Loss: 0.00019417
Iteration 61/1000 | Loss: 0.00082393
Iteration 62/1000 | Loss: 0.00006332
Iteration 63/1000 | Loss: 0.00054896
Iteration 64/1000 | Loss: 0.00012726
Iteration 65/1000 | Loss: 0.00004904
Iteration 66/1000 | Loss: 0.00004221
Iteration 67/1000 | Loss: 0.00003898
Iteration 68/1000 | Loss: 0.00027581
Iteration 69/1000 | Loss: 0.00007530
Iteration 70/1000 | Loss: 0.00015856
Iteration 71/1000 | Loss: 0.00047540
Iteration 72/1000 | Loss: 0.00152623
Iteration 73/1000 | Loss: 0.00200006
Iteration 74/1000 | Loss: 0.00137257
Iteration 75/1000 | Loss: 0.00034037
Iteration 76/1000 | Loss: 0.00008542
Iteration 77/1000 | Loss: 0.00005316
Iteration 78/1000 | Loss: 0.00004391
Iteration 79/1000 | Loss: 0.00003812
Iteration 80/1000 | Loss: 0.00026321
Iteration 81/1000 | Loss: 0.00053260
Iteration 82/1000 | Loss: 0.00004749
Iteration 83/1000 | Loss: 0.00003198
Iteration 84/1000 | Loss: 0.00002881
Iteration 85/1000 | Loss: 0.00017175
Iteration 86/1000 | Loss: 0.00020272
Iteration 87/1000 | Loss: 0.00016835
Iteration 88/1000 | Loss: 0.00021664
Iteration 89/1000 | Loss: 0.00012115
Iteration 90/1000 | Loss: 0.00004271
Iteration 91/1000 | Loss: 0.00002484
Iteration 92/1000 | Loss: 0.00002403
Iteration 93/1000 | Loss: 0.00026154
Iteration 94/1000 | Loss: 0.00083650
Iteration 95/1000 | Loss: 0.00026768
Iteration 96/1000 | Loss: 0.00007845
Iteration 97/1000 | Loss: 0.00010077
Iteration 98/1000 | Loss: 0.00002815
Iteration 99/1000 | Loss: 0.00009852
Iteration 100/1000 | Loss: 0.00002579
Iteration 101/1000 | Loss: 0.00002431
Iteration 102/1000 | Loss: 0.00016144
Iteration 103/1000 | Loss: 0.00002335
Iteration 104/1000 | Loss: 0.00002266
Iteration 105/1000 | Loss: 0.00002231
Iteration 106/1000 | Loss: 0.00002197
Iteration 107/1000 | Loss: 0.00002166
Iteration 108/1000 | Loss: 0.00017000
Iteration 109/1000 | Loss: 0.00028020
Iteration 110/1000 | Loss: 0.00004362
Iteration 111/1000 | Loss: 0.00003563
Iteration 112/1000 | Loss: 0.00002649
Iteration 113/1000 | Loss: 0.00002309
Iteration 114/1000 | Loss: 0.00002093
Iteration 115/1000 | Loss: 0.00017576
Iteration 116/1000 | Loss: 0.00001893
Iteration 117/1000 | Loss: 0.00001829
Iteration 118/1000 | Loss: 0.00001785
Iteration 119/1000 | Loss: 0.00001762
Iteration 120/1000 | Loss: 0.00001737
Iteration 121/1000 | Loss: 0.00001731
Iteration 122/1000 | Loss: 0.00001724
Iteration 123/1000 | Loss: 0.00001718
Iteration 124/1000 | Loss: 0.00001712
Iteration 125/1000 | Loss: 0.00001708
Iteration 126/1000 | Loss: 0.00001706
Iteration 127/1000 | Loss: 0.00001706
Iteration 128/1000 | Loss: 0.00001706
Iteration 129/1000 | Loss: 0.00001705
Iteration 130/1000 | Loss: 0.00001705
Iteration 131/1000 | Loss: 0.00001705
Iteration 132/1000 | Loss: 0.00001704
Iteration 133/1000 | Loss: 0.00001702
Iteration 134/1000 | Loss: 0.00001701
Iteration 135/1000 | Loss: 0.00001700
Iteration 136/1000 | Loss: 0.00001699
Iteration 137/1000 | Loss: 0.00001698
Iteration 138/1000 | Loss: 0.00001697
Iteration 139/1000 | Loss: 0.00001697
Iteration 140/1000 | Loss: 0.00001697
Iteration 141/1000 | Loss: 0.00001697
Iteration 142/1000 | Loss: 0.00001697
Iteration 143/1000 | Loss: 0.00001697
Iteration 144/1000 | Loss: 0.00001697
Iteration 145/1000 | Loss: 0.00001696
Iteration 146/1000 | Loss: 0.00001696
Iteration 147/1000 | Loss: 0.00001696
Iteration 148/1000 | Loss: 0.00001696
Iteration 149/1000 | Loss: 0.00001696
Iteration 150/1000 | Loss: 0.00001696
Iteration 151/1000 | Loss: 0.00001695
Iteration 152/1000 | Loss: 0.00001695
Iteration 153/1000 | Loss: 0.00001695
Iteration 154/1000 | Loss: 0.00001695
Iteration 155/1000 | Loss: 0.00014672
Iteration 156/1000 | Loss: 0.00002721
Iteration 157/1000 | Loss: 0.00002536
Iteration 158/1000 | Loss: 0.00001714
Iteration 159/1000 | Loss: 0.00001704
Iteration 160/1000 | Loss: 0.00001703
Iteration 161/1000 | Loss: 0.00001700
Iteration 162/1000 | Loss: 0.00001699
Iteration 163/1000 | Loss: 0.00001698
Iteration 164/1000 | Loss: 0.00001697
Iteration 165/1000 | Loss: 0.00001696
Iteration 166/1000 | Loss: 0.00001696
Iteration 167/1000 | Loss: 0.00001696
Iteration 168/1000 | Loss: 0.00001692
Iteration 169/1000 | Loss: 0.00001691
Iteration 170/1000 | Loss: 0.00001690
Iteration 171/1000 | Loss: 0.00001690
Iteration 172/1000 | Loss: 0.00001689
Iteration 173/1000 | Loss: 0.00001689
Iteration 174/1000 | Loss: 0.00001689
Iteration 175/1000 | Loss: 0.00001688
Iteration 176/1000 | Loss: 0.00001688
Iteration 177/1000 | Loss: 0.00001688
Iteration 178/1000 | Loss: 0.00001688
Iteration 179/1000 | Loss: 0.00001688
Iteration 180/1000 | Loss: 0.00001688
Iteration 181/1000 | Loss: 0.00001688
Iteration 182/1000 | Loss: 0.00001688
Iteration 183/1000 | Loss: 0.00001687
Iteration 184/1000 | Loss: 0.00001687
Iteration 185/1000 | Loss: 0.00001687
Iteration 186/1000 | Loss: 0.00001686
Iteration 187/1000 | Loss: 0.00001686
Iteration 188/1000 | Loss: 0.00001686
Iteration 189/1000 | Loss: 0.00001686
Iteration 190/1000 | Loss: 0.00001686
Iteration 191/1000 | Loss: 0.00001686
Iteration 192/1000 | Loss: 0.00001686
Iteration 193/1000 | Loss: 0.00001685
Iteration 194/1000 | Loss: 0.00001685
Iteration 195/1000 | Loss: 0.00001685
Iteration 196/1000 | Loss: 0.00001685
Iteration 197/1000 | Loss: 0.00001685
Iteration 198/1000 | Loss: 0.00001685
Iteration 199/1000 | Loss: 0.00001685
Iteration 200/1000 | Loss: 0.00001685
Iteration 201/1000 | Loss: 0.00001685
Iteration 202/1000 | Loss: 0.00001685
Iteration 203/1000 | Loss: 0.00001685
Iteration 204/1000 | Loss: 0.00001685
Iteration 205/1000 | Loss: 0.00001685
Iteration 206/1000 | Loss: 0.00001685
Iteration 207/1000 | Loss: 0.00001685
Iteration 208/1000 | Loss: 0.00001685
Iteration 209/1000 | Loss: 0.00001685
Iteration 210/1000 | Loss: 0.00001685
Iteration 211/1000 | Loss: 0.00001685
Iteration 212/1000 | Loss: 0.00001685
Iteration 213/1000 | Loss: 0.00001685
Iteration 214/1000 | Loss: 0.00001685
Iteration 215/1000 | Loss: 0.00001685
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 215. Stopping optimization.
Last 5 losses: [1.6846091966726817e-05, 1.6846091966726817e-05, 1.6846091966726817e-05, 1.6846091966726817e-05, 1.6846091966726817e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6846091966726817e-05

Optimization complete. Final v2v error: 3.3855020999908447 mm

Highest mean error: 10.173436164855957 mm for frame 152

Lowest mean error: 3.0704917907714844 mm for frame 153

Saving results

Total time: 253.5529236793518
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1026/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1026.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1026
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00556430
Iteration 2/25 | Loss: 0.00146121
Iteration 3/25 | Loss: 0.00140908
Iteration 4/25 | Loss: 0.00140066
Iteration 5/25 | Loss: 0.00139773
Iteration 6/25 | Loss: 0.00139721
Iteration 7/25 | Loss: 0.00139721
Iteration 8/25 | Loss: 0.00139721
Iteration 9/25 | Loss: 0.00139721
Iteration 10/25 | Loss: 0.00139721
Iteration 11/25 | Loss: 0.00139721
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013972094748169184, 0.0013972094748169184, 0.0013972094748169184, 0.0013972094748169184, 0.0013972094748169184]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013972094748169184

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25586188
Iteration 2/25 | Loss: 0.00166634
Iteration 3/25 | Loss: 0.00166631
Iteration 4/25 | Loss: 0.00166631
Iteration 5/25 | Loss: 0.00166631
Iteration 6/25 | Loss: 0.00166631
Iteration 7/25 | Loss: 0.00166631
Iteration 8/25 | Loss: 0.00166631
Iteration 9/25 | Loss: 0.00166630
Iteration 10/25 | Loss: 0.00166630
Iteration 11/25 | Loss: 0.00166630
Iteration 12/25 | Loss: 0.00166630
Iteration 13/25 | Loss: 0.00166630
Iteration 14/25 | Loss: 0.00166630
Iteration 15/25 | Loss: 0.00166630
Iteration 16/25 | Loss: 0.00166630
Iteration 17/25 | Loss: 0.00166630
Iteration 18/25 | Loss: 0.00166630
Iteration 19/25 | Loss: 0.00166630
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0016663044225424528, 0.0016663044225424528, 0.0016663044225424528, 0.0016663044225424528, 0.0016663044225424528]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016663044225424528

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00166630
Iteration 2/1000 | Loss: 0.00003609
Iteration 3/1000 | Loss: 0.00002445
Iteration 4/1000 | Loss: 0.00002174
Iteration 5/1000 | Loss: 0.00002052
Iteration 6/1000 | Loss: 0.00001978
Iteration 7/1000 | Loss: 0.00001924
Iteration 8/1000 | Loss: 0.00001884
Iteration 9/1000 | Loss: 0.00001841
Iteration 10/1000 | Loss: 0.00001806
Iteration 11/1000 | Loss: 0.00001774
Iteration 12/1000 | Loss: 0.00001755
Iteration 13/1000 | Loss: 0.00001731
Iteration 14/1000 | Loss: 0.00001712
Iteration 15/1000 | Loss: 0.00001705
Iteration 16/1000 | Loss: 0.00001689
Iteration 17/1000 | Loss: 0.00001681
Iteration 18/1000 | Loss: 0.00001677
Iteration 19/1000 | Loss: 0.00001672
Iteration 20/1000 | Loss: 0.00001661
Iteration 21/1000 | Loss: 0.00001660
Iteration 22/1000 | Loss: 0.00001650
Iteration 23/1000 | Loss: 0.00001647
Iteration 24/1000 | Loss: 0.00001644
Iteration 25/1000 | Loss: 0.00001644
Iteration 26/1000 | Loss: 0.00001642
Iteration 27/1000 | Loss: 0.00001642
Iteration 28/1000 | Loss: 0.00001642
Iteration 29/1000 | Loss: 0.00001642
Iteration 30/1000 | Loss: 0.00001642
Iteration 31/1000 | Loss: 0.00001641
Iteration 32/1000 | Loss: 0.00001641
Iteration 33/1000 | Loss: 0.00001641
Iteration 34/1000 | Loss: 0.00001640
Iteration 35/1000 | Loss: 0.00001637
Iteration 36/1000 | Loss: 0.00001637
Iteration 37/1000 | Loss: 0.00001635
Iteration 38/1000 | Loss: 0.00001635
Iteration 39/1000 | Loss: 0.00001634
Iteration 40/1000 | Loss: 0.00001634
Iteration 41/1000 | Loss: 0.00001633
Iteration 42/1000 | Loss: 0.00001632
Iteration 43/1000 | Loss: 0.00001632
Iteration 44/1000 | Loss: 0.00001632
Iteration 45/1000 | Loss: 0.00001632
Iteration 46/1000 | Loss: 0.00001632
Iteration 47/1000 | Loss: 0.00001631
Iteration 48/1000 | Loss: 0.00001631
Iteration 49/1000 | Loss: 0.00001631
Iteration 50/1000 | Loss: 0.00001631
Iteration 51/1000 | Loss: 0.00001631
Iteration 52/1000 | Loss: 0.00001631
Iteration 53/1000 | Loss: 0.00001630
Iteration 54/1000 | Loss: 0.00001630
Iteration 55/1000 | Loss: 0.00001630
Iteration 56/1000 | Loss: 0.00001629
Iteration 57/1000 | Loss: 0.00001629
Iteration 58/1000 | Loss: 0.00001629
Iteration 59/1000 | Loss: 0.00001628
Iteration 60/1000 | Loss: 0.00001628
Iteration 61/1000 | Loss: 0.00001628
Iteration 62/1000 | Loss: 0.00001628
Iteration 63/1000 | Loss: 0.00001628
Iteration 64/1000 | Loss: 0.00001627
Iteration 65/1000 | Loss: 0.00001627
Iteration 66/1000 | Loss: 0.00001627
Iteration 67/1000 | Loss: 0.00001627
Iteration 68/1000 | Loss: 0.00001626
Iteration 69/1000 | Loss: 0.00001626
Iteration 70/1000 | Loss: 0.00001626
Iteration 71/1000 | Loss: 0.00001626
Iteration 72/1000 | Loss: 0.00001626
Iteration 73/1000 | Loss: 0.00001626
Iteration 74/1000 | Loss: 0.00001626
Iteration 75/1000 | Loss: 0.00001626
Iteration 76/1000 | Loss: 0.00001625
Iteration 77/1000 | Loss: 0.00001625
Iteration 78/1000 | Loss: 0.00001625
Iteration 79/1000 | Loss: 0.00001625
Iteration 80/1000 | Loss: 0.00001625
Iteration 81/1000 | Loss: 0.00001625
Iteration 82/1000 | Loss: 0.00001625
Iteration 83/1000 | Loss: 0.00001624
Iteration 84/1000 | Loss: 0.00001624
Iteration 85/1000 | Loss: 0.00001624
Iteration 86/1000 | Loss: 0.00001624
Iteration 87/1000 | Loss: 0.00001624
Iteration 88/1000 | Loss: 0.00001624
Iteration 89/1000 | Loss: 0.00001624
Iteration 90/1000 | Loss: 0.00001624
Iteration 91/1000 | Loss: 0.00001624
Iteration 92/1000 | Loss: 0.00001623
Iteration 93/1000 | Loss: 0.00001623
Iteration 94/1000 | Loss: 0.00001623
Iteration 95/1000 | Loss: 0.00001623
Iteration 96/1000 | Loss: 0.00001623
Iteration 97/1000 | Loss: 0.00001623
Iteration 98/1000 | Loss: 0.00001623
Iteration 99/1000 | Loss: 0.00001623
Iteration 100/1000 | Loss: 0.00001622
Iteration 101/1000 | Loss: 0.00001622
Iteration 102/1000 | Loss: 0.00001622
Iteration 103/1000 | Loss: 0.00001622
Iteration 104/1000 | Loss: 0.00001622
Iteration 105/1000 | Loss: 0.00001622
Iteration 106/1000 | Loss: 0.00001622
Iteration 107/1000 | Loss: 0.00001622
Iteration 108/1000 | Loss: 0.00001622
Iteration 109/1000 | Loss: 0.00001622
Iteration 110/1000 | Loss: 0.00001622
Iteration 111/1000 | Loss: 0.00001622
Iteration 112/1000 | Loss: 0.00001622
Iteration 113/1000 | Loss: 0.00001621
Iteration 114/1000 | Loss: 0.00001621
Iteration 115/1000 | Loss: 0.00001621
Iteration 116/1000 | Loss: 0.00001621
Iteration 117/1000 | Loss: 0.00001621
Iteration 118/1000 | Loss: 0.00001621
Iteration 119/1000 | Loss: 0.00001621
Iteration 120/1000 | Loss: 0.00001621
Iteration 121/1000 | Loss: 0.00001621
Iteration 122/1000 | Loss: 0.00001621
Iteration 123/1000 | Loss: 0.00001621
Iteration 124/1000 | Loss: 0.00001621
Iteration 125/1000 | Loss: 0.00001621
Iteration 126/1000 | Loss: 0.00001621
Iteration 127/1000 | Loss: 0.00001620
Iteration 128/1000 | Loss: 0.00001620
Iteration 129/1000 | Loss: 0.00001620
Iteration 130/1000 | Loss: 0.00001620
Iteration 131/1000 | Loss: 0.00001620
Iteration 132/1000 | Loss: 0.00001620
Iteration 133/1000 | Loss: 0.00001620
Iteration 134/1000 | Loss: 0.00001620
Iteration 135/1000 | Loss: 0.00001620
Iteration 136/1000 | Loss: 0.00001620
Iteration 137/1000 | Loss: 0.00001620
Iteration 138/1000 | Loss: 0.00001620
Iteration 139/1000 | Loss: 0.00001619
Iteration 140/1000 | Loss: 0.00001619
Iteration 141/1000 | Loss: 0.00001619
Iteration 142/1000 | Loss: 0.00001619
Iteration 143/1000 | Loss: 0.00001619
Iteration 144/1000 | Loss: 0.00001619
Iteration 145/1000 | Loss: 0.00001619
Iteration 146/1000 | Loss: 0.00001619
Iteration 147/1000 | Loss: 0.00001619
Iteration 148/1000 | Loss: 0.00001619
Iteration 149/1000 | Loss: 0.00001619
Iteration 150/1000 | Loss: 0.00001619
Iteration 151/1000 | Loss: 0.00001619
Iteration 152/1000 | Loss: 0.00001619
Iteration 153/1000 | Loss: 0.00001618
Iteration 154/1000 | Loss: 0.00001618
Iteration 155/1000 | Loss: 0.00001618
Iteration 156/1000 | Loss: 0.00001618
Iteration 157/1000 | Loss: 0.00001618
Iteration 158/1000 | Loss: 0.00001618
Iteration 159/1000 | Loss: 0.00001618
Iteration 160/1000 | Loss: 0.00001618
Iteration 161/1000 | Loss: 0.00001618
Iteration 162/1000 | Loss: 0.00001618
Iteration 163/1000 | Loss: 0.00001618
Iteration 164/1000 | Loss: 0.00001618
Iteration 165/1000 | Loss: 0.00001618
Iteration 166/1000 | Loss: 0.00001617
Iteration 167/1000 | Loss: 0.00001617
Iteration 168/1000 | Loss: 0.00001617
Iteration 169/1000 | Loss: 0.00001617
Iteration 170/1000 | Loss: 0.00001617
Iteration 171/1000 | Loss: 0.00001617
Iteration 172/1000 | Loss: 0.00001617
Iteration 173/1000 | Loss: 0.00001617
Iteration 174/1000 | Loss: 0.00001617
Iteration 175/1000 | Loss: 0.00001617
Iteration 176/1000 | Loss: 0.00001617
Iteration 177/1000 | Loss: 0.00001617
Iteration 178/1000 | Loss: 0.00001617
Iteration 179/1000 | Loss: 0.00001617
Iteration 180/1000 | Loss: 0.00001617
Iteration 181/1000 | Loss: 0.00001617
Iteration 182/1000 | Loss: 0.00001617
Iteration 183/1000 | Loss: 0.00001617
Iteration 184/1000 | Loss: 0.00001617
Iteration 185/1000 | Loss: 0.00001617
Iteration 186/1000 | Loss: 0.00001617
Iteration 187/1000 | Loss: 0.00001617
Iteration 188/1000 | Loss: 0.00001617
Iteration 189/1000 | Loss: 0.00001617
Iteration 190/1000 | Loss: 0.00001617
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 190. Stopping optimization.
Last 5 losses: [1.6166794011951424e-05, 1.6166794011951424e-05, 1.6166794011951424e-05, 1.6166794011951424e-05, 1.6166794011951424e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6166794011951424e-05

Optimization complete. Final v2v error: 3.3995187282562256 mm

Highest mean error: 3.709165096282959 mm for frame 22

Lowest mean error: 3.0026514530181885 mm for frame 136

Saving results

Total time: 44.2088828086853
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1063/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1063.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1063
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01000836
Iteration 2/25 | Loss: 0.00199659
Iteration 3/25 | Loss: 0.00165000
Iteration 4/25 | Loss: 0.00158455
Iteration 5/25 | Loss: 0.00166041
Iteration 6/25 | Loss: 0.00151484
Iteration 7/25 | Loss: 0.00145867
Iteration 8/25 | Loss: 0.00144613
Iteration 9/25 | Loss: 0.00144322
Iteration 10/25 | Loss: 0.00144309
Iteration 11/25 | Loss: 0.00144309
Iteration 12/25 | Loss: 0.00144309
Iteration 13/25 | Loss: 0.00144309
Iteration 14/25 | Loss: 0.00144309
Iteration 15/25 | Loss: 0.00144309
Iteration 16/25 | Loss: 0.00144309
Iteration 17/25 | Loss: 0.00144309
Iteration 18/25 | Loss: 0.00144309
Iteration 19/25 | Loss: 0.00144309
Iteration 20/25 | Loss: 0.00144309
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0014430880546569824, 0.0014430880546569824, 0.0014430880546569824, 0.0014430880546569824, 0.0014430880546569824]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014430880546569824

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.21194637
Iteration 2/25 | Loss: 0.00205146
Iteration 3/25 | Loss: 0.00205146
Iteration 4/25 | Loss: 0.00205146
Iteration 5/25 | Loss: 0.00205146
Iteration 6/25 | Loss: 0.00205146
Iteration 7/25 | Loss: 0.00205146
Iteration 8/25 | Loss: 0.00205146
Iteration 9/25 | Loss: 0.00205146
Iteration 10/25 | Loss: 0.00205146
Iteration 11/25 | Loss: 0.00205146
Iteration 12/25 | Loss: 0.00205146
Iteration 13/25 | Loss: 0.00205146
Iteration 14/25 | Loss: 0.00205146
Iteration 15/25 | Loss: 0.00205146
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0020514593925327063, 0.0020514593925327063, 0.0020514593925327063, 0.0020514593925327063, 0.0020514593925327063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020514593925327063

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00205146
Iteration 2/1000 | Loss: 0.00003648
Iteration 3/1000 | Loss: 0.00002648
Iteration 4/1000 | Loss: 0.00002419
Iteration 5/1000 | Loss: 0.00002323
Iteration 6/1000 | Loss: 0.00002268
Iteration 7/1000 | Loss: 0.00002207
Iteration 8/1000 | Loss: 0.00002175
Iteration 9/1000 | Loss: 0.00002146
Iteration 10/1000 | Loss: 0.00002121
Iteration 11/1000 | Loss: 0.00002097
Iteration 12/1000 | Loss: 0.00002061
Iteration 13/1000 | Loss: 0.00002033
Iteration 14/1000 | Loss: 0.00002021
Iteration 15/1000 | Loss: 0.00002020
Iteration 16/1000 | Loss: 0.00002014
Iteration 17/1000 | Loss: 0.00002013
Iteration 18/1000 | Loss: 0.00002003
Iteration 19/1000 | Loss: 0.00002002
Iteration 20/1000 | Loss: 0.00002002
Iteration 21/1000 | Loss: 0.00002002
Iteration 22/1000 | Loss: 0.00002002
Iteration 23/1000 | Loss: 0.00002002
Iteration 24/1000 | Loss: 0.00001998
Iteration 25/1000 | Loss: 0.00001998
Iteration 26/1000 | Loss: 0.00001997
Iteration 27/1000 | Loss: 0.00001997
Iteration 28/1000 | Loss: 0.00001997
Iteration 29/1000 | Loss: 0.00001996
Iteration 30/1000 | Loss: 0.00001996
Iteration 31/1000 | Loss: 0.00001996
Iteration 32/1000 | Loss: 0.00001996
Iteration 33/1000 | Loss: 0.00001995
Iteration 34/1000 | Loss: 0.00001994
Iteration 35/1000 | Loss: 0.00001993
Iteration 36/1000 | Loss: 0.00001993
Iteration 37/1000 | Loss: 0.00001993
Iteration 38/1000 | Loss: 0.00001993
Iteration 39/1000 | Loss: 0.00001993
Iteration 40/1000 | Loss: 0.00001993
Iteration 41/1000 | Loss: 0.00001992
Iteration 42/1000 | Loss: 0.00001992
Iteration 43/1000 | Loss: 0.00001992
Iteration 44/1000 | Loss: 0.00001992
Iteration 45/1000 | Loss: 0.00001992
Iteration 46/1000 | Loss: 0.00001991
Iteration 47/1000 | Loss: 0.00001991
Iteration 48/1000 | Loss: 0.00001991
Iteration 49/1000 | Loss: 0.00001991
Iteration 50/1000 | Loss: 0.00001990
Iteration 51/1000 | Loss: 0.00001990
Iteration 52/1000 | Loss: 0.00001990
Iteration 53/1000 | Loss: 0.00001989
Iteration 54/1000 | Loss: 0.00001989
Iteration 55/1000 | Loss: 0.00001989
Iteration 56/1000 | Loss: 0.00001989
Iteration 57/1000 | Loss: 0.00001988
Iteration 58/1000 | Loss: 0.00001988
Iteration 59/1000 | Loss: 0.00001988
Iteration 60/1000 | Loss: 0.00001988
Iteration 61/1000 | Loss: 0.00001988
Iteration 62/1000 | Loss: 0.00001988
Iteration 63/1000 | Loss: 0.00001988
Iteration 64/1000 | Loss: 0.00001988
Iteration 65/1000 | Loss: 0.00001988
Iteration 66/1000 | Loss: 0.00001988
Iteration 67/1000 | Loss: 0.00001988
Iteration 68/1000 | Loss: 0.00001988
Iteration 69/1000 | Loss: 0.00001988
Iteration 70/1000 | Loss: 0.00001988
Iteration 71/1000 | Loss: 0.00001988
Iteration 72/1000 | Loss: 0.00001987
Iteration 73/1000 | Loss: 0.00001987
Iteration 74/1000 | Loss: 0.00001987
Iteration 75/1000 | Loss: 0.00001987
Iteration 76/1000 | Loss: 0.00001987
Iteration 77/1000 | Loss: 0.00001987
Iteration 78/1000 | Loss: 0.00001987
Iteration 79/1000 | Loss: 0.00001987
Iteration 80/1000 | Loss: 0.00001987
Iteration 81/1000 | Loss: 0.00001986
Iteration 82/1000 | Loss: 0.00001986
Iteration 83/1000 | Loss: 0.00001986
Iteration 84/1000 | Loss: 0.00001986
Iteration 85/1000 | Loss: 0.00001986
Iteration 86/1000 | Loss: 0.00001986
Iteration 87/1000 | Loss: 0.00001986
Iteration 88/1000 | Loss: 0.00001986
Iteration 89/1000 | Loss: 0.00001986
Iteration 90/1000 | Loss: 0.00001986
Iteration 91/1000 | Loss: 0.00001985
Iteration 92/1000 | Loss: 0.00001985
Iteration 93/1000 | Loss: 0.00001985
Iteration 94/1000 | Loss: 0.00001985
Iteration 95/1000 | Loss: 0.00001985
Iteration 96/1000 | Loss: 0.00001985
Iteration 97/1000 | Loss: 0.00001984
Iteration 98/1000 | Loss: 0.00001984
Iteration 99/1000 | Loss: 0.00001984
Iteration 100/1000 | Loss: 0.00001984
Iteration 101/1000 | Loss: 0.00001984
Iteration 102/1000 | Loss: 0.00001984
Iteration 103/1000 | Loss: 0.00001984
Iteration 104/1000 | Loss: 0.00001984
Iteration 105/1000 | Loss: 0.00001984
Iteration 106/1000 | Loss: 0.00001984
Iteration 107/1000 | Loss: 0.00001984
Iteration 108/1000 | Loss: 0.00001984
Iteration 109/1000 | Loss: 0.00001984
Iteration 110/1000 | Loss: 0.00001984
Iteration 111/1000 | Loss: 0.00001984
Iteration 112/1000 | Loss: 0.00001984
Iteration 113/1000 | Loss: 0.00001984
Iteration 114/1000 | Loss: 0.00001984
Iteration 115/1000 | Loss: 0.00001984
Iteration 116/1000 | Loss: 0.00001984
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 116. Stopping optimization.
Last 5 losses: [1.9837012587231584e-05, 1.9837012587231584e-05, 1.9837012587231584e-05, 1.9837012587231584e-05, 1.9837012587231584e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9837012587231584e-05

Optimization complete. Final v2v error: 3.7943544387817383 mm

Highest mean error: 3.896719455718994 mm for frame 12

Lowest mean error: 3.605111598968506 mm for frame 174

Saving results

Total time: 42.9241828918457
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1095/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1095.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1095
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00989157
Iteration 2/25 | Loss: 0.00209042
Iteration 3/25 | Loss: 0.00163110
Iteration 4/25 | Loss: 0.00155266
Iteration 5/25 | Loss: 0.00152194
Iteration 6/25 | Loss: 0.00149714
Iteration 7/25 | Loss: 0.00149965
Iteration 8/25 | Loss: 0.00147416
Iteration 9/25 | Loss: 0.00146033
Iteration 10/25 | Loss: 0.00145484
Iteration 11/25 | Loss: 0.00145233
Iteration 12/25 | Loss: 0.00145000
Iteration 13/25 | Loss: 0.00145252
Iteration 14/25 | Loss: 0.00144491
Iteration 15/25 | Loss: 0.00144101
Iteration 16/25 | Loss: 0.00143860
Iteration 17/25 | Loss: 0.00143729
Iteration 18/25 | Loss: 0.00143872
Iteration 19/25 | Loss: 0.00143682
Iteration 20/25 | Loss: 0.00143538
Iteration 21/25 | Loss: 0.00143519
Iteration 22/25 | Loss: 0.00143679
Iteration 23/25 | Loss: 0.00143533
Iteration 24/25 | Loss: 0.00143511
Iteration 25/25 | Loss: 0.00143511

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26426733
Iteration 2/25 | Loss: 0.00263264
Iteration 3/25 | Loss: 0.00248372
Iteration 4/25 | Loss: 0.00248371
Iteration 5/25 | Loss: 0.00248371
Iteration 6/25 | Loss: 0.00248371
Iteration 7/25 | Loss: 0.00248371
Iteration 8/25 | Loss: 0.00248371
Iteration 9/25 | Loss: 0.00248371
Iteration 10/25 | Loss: 0.00248371
Iteration 11/25 | Loss: 0.00248371
Iteration 12/25 | Loss: 0.00248371
Iteration 13/25 | Loss: 0.00248371
Iteration 14/25 | Loss: 0.00248371
Iteration 15/25 | Loss: 0.00248371
Iteration 16/25 | Loss: 0.00248371
Iteration 17/25 | Loss: 0.00248371
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0024837127421051264, 0.0024837127421051264, 0.0024837127421051264, 0.0024837127421051264, 0.0024837127421051264]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0024837127421051264

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00248371
Iteration 2/1000 | Loss: 0.00168903
Iteration 3/1000 | Loss: 0.00055415
Iteration 4/1000 | Loss: 0.00016397
Iteration 5/1000 | Loss: 0.00087334
Iteration 6/1000 | Loss: 0.00235683
Iteration 7/1000 | Loss: 0.00249273
Iteration 8/1000 | Loss: 0.00152763
Iteration 9/1000 | Loss: 0.00154709
Iteration 10/1000 | Loss: 0.00051991
Iteration 11/1000 | Loss: 0.00026617
Iteration 12/1000 | Loss: 0.00009345
Iteration 13/1000 | Loss: 0.00030926
Iteration 14/1000 | Loss: 0.00024511
Iteration 15/1000 | Loss: 0.00077204
Iteration 16/1000 | Loss: 0.00011252
Iteration 17/1000 | Loss: 0.00015997
Iteration 18/1000 | Loss: 0.00028651
Iteration 19/1000 | Loss: 0.00011369
Iteration 20/1000 | Loss: 0.00127952
Iteration 21/1000 | Loss: 0.00090224
Iteration 22/1000 | Loss: 0.00034416
Iteration 23/1000 | Loss: 0.00022315
Iteration 24/1000 | Loss: 0.00065813
Iteration 25/1000 | Loss: 0.00028226
Iteration 26/1000 | Loss: 0.00016860
Iteration 27/1000 | Loss: 0.00007359
Iteration 28/1000 | Loss: 0.00073478
Iteration 29/1000 | Loss: 0.00219263
Iteration 30/1000 | Loss: 0.00105726
Iteration 31/1000 | Loss: 0.00022748
Iteration 32/1000 | Loss: 0.00056182
Iteration 33/1000 | Loss: 0.00036394
Iteration 34/1000 | Loss: 0.00006784
Iteration 35/1000 | Loss: 0.00011169
Iteration 36/1000 | Loss: 0.00009011
Iteration 37/1000 | Loss: 0.00006408
Iteration 38/1000 | Loss: 0.00063482
Iteration 39/1000 | Loss: 0.00007881
Iteration 40/1000 | Loss: 0.00006654
Iteration 41/1000 | Loss: 0.00052815
Iteration 42/1000 | Loss: 0.00095857
Iteration 43/1000 | Loss: 0.00038304
Iteration 44/1000 | Loss: 0.00016893
Iteration 45/1000 | Loss: 0.00004121
Iteration 46/1000 | Loss: 0.00030569
Iteration 47/1000 | Loss: 0.00041915
Iteration 48/1000 | Loss: 0.00009758
Iteration 49/1000 | Loss: 0.00004745
Iteration 50/1000 | Loss: 0.00005017
Iteration 51/1000 | Loss: 0.00003392
Iteration 52/1000 | Loss: 0.00003286
Iteration 53/1000 | Loss: 0.00030331
Iteration 54/1000 | Loss: 0.00011796
Iteration 55/1000 | Loss: 0.00046944
Iteration 56/1000 | Loss: 0.00089634
Iteration 57/1000 | Loss: 0.00020037
Iteration 58/1000 | Loss: 0.00005559
Iteration 59/1000 | Loss: 0.00014470
Iteration 60/1000 | Loss: 0.00005041
Iteration 61/1000 | Loss: 0.00003470
Iteration 62/1000 | Loss: 0.00003523
Iteration 63/1000 | Loss: 0.00011373
Iteration 64/1000 | Loss: 0.00004259
Iteration 65/1000 | Loss: 0.00004785
Iteration 66/1000 | Loss: 0.00006295
Iteration 67/1000 | Loss: 0.00002944
Iteration 68/1000 | Loss: 0.00004796
Iteration 69/1000 | Loss: 0.00003023
Iteration 70/1000 | Loss: 0.00002636
Iteration 71/1000 | Loss: 0.00005935
Iteration 72/1000 | Loss: 0.00003051
Iteration 73/1000 | Loss: 0.00004357
Iteration 74/1000 | Loss: 0.00008667
Iteration 75/1000 | Loss: 0.00070077
Iteration 76/1000 | Loss: 0.00007061
Iteration 77/1000 | Loss: 0.00007675
Iteration 78/1000 | Loss: 0.00005830
Iteration 79/1000 | Loss: 0.00004621
Iteration 80/1000 | Loss: 0.00002545
Iteration 81/1000 | Loss: 0.00002465
Iteration 82/1000 | Loss: 0.00007116
Iteration 83/1000 | Loss: 0.00002745
Iteration 84/1000 | Loss: 0.00002365
Iteration 85/1000 | Loss: 0.00003010
Iteration 86/1000 | Loss: 0.00002403
Iteration 87/1000 | Loss: 0.00004223
Iteration 88/1000 | Loss: 0.00002413
Iteration 89/1000 | Loss: 0.00006010
Iteration 90/1000 | Loss: 0.00011134
Iteration 91/1000 | Loss: 0.00009445
Iteration 92/1000 | Loss: 0.00044888
Iteration 93/1000 | Loss: 0.00040137
Iteration 94/1000 | Loss: 0.00078042
Iteration 95/1000 | Loss: 0.00040617
Iteration 96/1000 | Loss: 0.00147379
Iteration 97/1000 | Loss: 0.00045883
Iteration 98/1000 | Loss: 0.00006657
Iteration 99/1000 | Loss: 0.00002383
Iteration 100/1000 | Loss: 0.00002320
Iteration 101/1000 | Loss: 0.00009938
Iteration 102/1000 | Loss: 0.00003943
Iteration 103/1000 | Loss: 0.00003853
Iteration 104/1000 | Loss: 0.00003705
Iteration 105/1000 | Loss: 0.00009244
Iteration 106/1000 | Loss: 0.00003280
Iteration 107/1000 | Loss: 0.00002294
Iteration 108/1000 | Loss: 0.00011086
Iteration 109/1000 | Loss: 0.00002725
Iteration 110/1000 | Loss: 0.00016476
Iteration 111/1000 | Loss: 0.00003034
Iteration 112/1000 | Loss: 0.00008356
Iteration 113/1000 | Loss: 0.00002803
Iteration 114/1000 | Loss: 0.00008026
Iteration 115/1000 | Loss: 0.00002526
Iteration 116/1000 | Loss: 0.00009627
Iteration 117/1000 | Loss: 0.00003233
Iteration 118/1000 | Loss: 0.00006815
Iteration 119/1000 | Loss: 0.00002716
Iteration 120/1000 | Loss: 0.00003986
Iteration 121/1000 | Loss: 0.00002606
Iteration 122/1000 | Loss: 0.00004079
Iteration 123/1000 | Loss: 0.00002933
Iteration 124/1000 | Loss: 0.00005693
Iteration 125/1000 | Loss: 0.00002393
Iteration 126/1000 | Loss: 0.00002195
Iteration 127/1000 | Loss: 0.00002152
Iteration 128/1000 | Loss: 0.00004844
Iteration 129/1000 | Loss: 0.00002130
Iteration 130/1000 | Loss: 0.00002121
Iteration 131/1000 | Loss: 0.00002113
Iteration 132/1000 | Loss: 0.00005077
Iteration 133/1000 | Loss: 0.00002103
Iteration 134/1000 | Loss: 0.00002093
Iteration 135/1000 | Loss: 0.00002093
Iteration 136/1000 | Loss: 0.00002093
Iteration 137/1000 | Loss: 0.00002093
Iteration 138/1000 | Loss: 0.00002092
Iteration 139/1000 | Loss: 0.00002092
Iteration 140/1000 | Loss: 0.00002092
Iteration 141/1000 | Loss: 0.00002092
Iteration 142/1000 | Loss: 0.00002092
Iteration 143/1000 | Loss: 0.00002092
Iteration 144/1000 | Loss: 0.00002092
Iteration 145/1000 | Loss: 0.00002092
Iteration 146/1000 | Loss: 0.00002092
Iteration 147/1000 | Loss: 0.00002092
Iteration 148/1000 | Loss: 0.00002092
Iteration 149/1000 | Loss: 0.00002092
Iteration 150/1000 | Loss: 0.00002091
Iteration 151/1000 | Loss: 0.00002091
Iteration 152/1000 | Loss: 0.00002091
Iteration 153/1000 | Loss: 0.00002091
Iteration 154/1000 | Loss: 0.00002091
Iteration 155/1000 | Loss: 0.00002089
Iteration 156/1000 | Loss: 0.00002089
Iteration 157/1000 | Loss: 0.00002088
Iteration 158/1000 | Loss: 0.00002087
Iteration 159/1000 | Loss: 0.00002087
Iteration 160/1000 | Loss: 0.00002086
Iteration 161/1000 | Loss: 0.00002086
Iteration 162/1000 | Loss: 0.00002086
Iteration 163/1000 | Loss: 0.00002086
Iteration 164/1000 | Loss: 0.00002085
Iteration 165/1000 | Loss: 0.00002085
Iteration 166/1000 | Loss: 0.00002084
Iteration 167/1000 | Loss: 0.00002084
Iteration 168/1000 | Loss: 0.00002084
Iteration 169/1000 | Loss: 0.00002083
Iteration 170/1000 | Loss: 0.00002083
Iteration 171/1000 | Loss: 0.00002083
Iteration 172/1000 | Loss: 0.00002082
Iteration 173/1000 | Loss: 0.00002081
Iteration 174/1000 | Loss: 0.00002081
Iteration 175/1000 | Loss: 0.00002081
Iteration 176/1000 | Loss: 0.00004094
Iteration 177/1000 | Loss: 0.00002308
Iteration 178/1000 | Loss: 0.00006601
Iteration 179/1000 | Loss: 0.00002411
Iteration 180/1000 | Loss: 0.00002073
Iteration 181/1000 | Loss: 0.00002073
Iteration 182/1000 | Loss: 0.00002073
Iteration 183/1000 | Loss: 0.00002073
Iteration 184/1000 | Loss: 0.00002073
Iteration 185/1000 | Loss: 0.00002072
Iteration 186/1000 | Loss: 0.00002072
Iteration 187/1000 | Loss: 0.00002072
Iteration 188/1000 | Loss: 0.00002072
Iteration 189/1000 | Loss: 0.00002072
Iteration 190/1000 | Loss: 0.00002072
Iteration 191/1000 | Loss: 0.00002072
Iteration 192/1000 | Loss: 0.00002071
Iteration 193/1000 | Loss: 0.00002071
Iteration 194/1000 | Loss: 0.00002070
Iteration 195/1000 | Loss: 0.00002069
Iteration 196/1000 | Loss: 0.00002068
Iteration 197/1000 | Loss: 0.00002068
Iteration 198/1000 | Loss: 0.00002068
Iteration 199/1000 | Loss: 0.00002067
Iteration 200/1000 | Loss: 0.00002067
Iteration 201/1000 | Loss: 0.00002067
Iteration 202/1000 | Loss: 0.00002067
Iteration 203/1000 | Loss: 0.00002067
Iteration 204/1000 | Loss: 0.00002066
Iteration 205/1000 | Loss: 0.00002066
Iteration 206/1000 | Loss: 0.00002066
Iteration 207/1000 | Loss: 0.00002066
Iteration 208/1000 | Loss: 0.00002066
Iteration 209/1000 | Loss: 0.00002065
Iteration 210/1000 | Loss: 0.00002065
Iteration 211/1000 | Loss: 0.00002064
Iteration 212/1000 | Loss: 0.00002064
Iteration 213/1000 | Loss: 0.00002064
Iteration 214/1000 | Loss: 0.00002064
Iteration 215/1000 | Loss: 0.00002063
Iteration 216/1000 | Loss: 0.00002063
Iteration 217/1000 | Loss: 0.00002062
Iteration 218/1000 | Loss: 0.00002062
Iteration 219/1000 | Loss: 0.00002061
Iteration 220/1000 | Loss: 0.00002061
Iteration 221/1000 | Loss: 0.00002060
Iteration 222/1000 | Loss: 0.00002060
Iteration 223/1000 | Loss: 0.00002060
Iteration 224/1000 | Loss: 0.00002059
Iteration 225/1000 | Loss: 0.00002059
Iteration 226/1000 | Loss: 0.00002059
Iteration 227/1000 | Loss: 0.00002058
Iteration 228/1000 | Loss: 0.00002057
Iteration 229/1000 | Loss: 0.00002054
Iteration 230/1000 | Loss: 0.00002053
Iteration 231/1000 | Loss: 0.00002052
Iteration 232/1000 | Loss: 0.00002052
Iteration 233/1000 | Loss: 0.00002051
Iteration 234/1000 | Loss: 0.00002050
Iteration 235/1000 | Loss: 0.00002050
Iteration 236/1000 | Loss: 0.00003859
Iteration 237/1000 | Loss: 0.00003968
Iteration 238/1000 | Loss: 0.00002060
Iteration 239/1000 | Loss: 0.00002039
Iteration 240/1000 | Loss: 0.00002038
Iteration 241/1000 | Loss: 0.00002037
Iteration 242/1000 | Loss: 0.00002035
Iteration 243/1000 | Loss: 0.00002035
Iteration 244/1000 | Loss: 0.00002035
Iteration 245/1000 | Loss: 0.00002034
Iteration 246/1000 | Loss: 0.00002034
Iteration 247/1000 | Loss: 0.00002034
Iteration 248/1000 | Loss: 0.00002033
Iteration 249/1000 | Loss: 0.00002033
Iteration 250/1000 | Loss: 0.00002033
Iteration 251/1000 | Loss: 0.00002032
Iteration 252/1000 | Loss: 0.00002032
Iteration 253/1000 | Loss: 0.00002031
Iteration 254/1000 | Loss: 0.00002031
Iteration 255/1000 | Loss: 0.00002030
Iteration 256/1000 | Loss: 0.00002030
Iteration 257/1000 | Loss: 0.00002030
Iteration 258/1000 | Loss: 0.00002030
Iteration 259/1000 | Loss: 0.00002030
Iteration 260/1000 | Loss: 0.00002030
Iteration 261/1000 | Loss: 0.00002029
Iteration 262/1000 | Loss: 0.00002029
Iteration 263/1000 | Loss: 0.00002029
Iteration 264/1000 | Loss: 0.00002029
Iteration 265/1000 | Loss: 0.00002028
Iteration 266/1000 | Loss: 0.00002028
Iteration 267/1000 | Loss: 0.00002028
Iteration 268/1000 | Loss: 0.00002028
Iteration 269/1000 | Loss: 0.00002028
Iteration 270/1000 | Loss: 0.00002028
Iteration 271/1000 | Loss: 0.00002028
Iteration 272/1000 | Loss: 0.00002027
Iteration 273/1000 | Loss: 0.00002027
Iteration 274/1000 | Loss: 0.00002027
Iteration 275/1000 | Loss: 0.00002027
Iteration 276/1000 | Loss: 0.00002027
Iteration 277/1000 | Loss: 0.00002027
Iteration 278/1000 | Loss: 0.00002026
Iteration 279/1000 | Loss: 0.00002026
Iteration 280/1000 | Loss: 0.00002026
Iteration 281/1000 | Loss: 0.00002025
Iteration 282/1000 | Loss: 0.00002025
Iteration 283/1000 | Loss: 0.00002024
Iteration 284/1000 | Loss: 0.00002023
Iteration 285/1000 | Loss: 0.00002023
Iteration 286/1000 | Loss: 0.00002023
Iteration 287/1000 | Loss: 0.00002023
Iteration 288/1000 | Loss: 0.00002023
Iteration 289/1000 | Loss: 0.00002023
Iteration 290/1000 | Loss: 0.00002022
Iteration 291/1000 | Loss: 0.00002022
Iteration 292/1000 | Loss: 0.00002022
Iteration 293/1000 | Loss: 0.00002022
Iteration 294/1000 | Loss: 0.00002021
Iteration 295/1000 | Loss: 0.00002020
Iteration 296/1000 | Loss: 0.00002020
Iteration 297/1000 | Loss: 0.00002020
Iteration 298/1000 | Loss: 0.00002020
Iteration 299/1000 | Loss: 0.00002019
Iteration 300/1000 | Loss: 0.00002019
Iteration 301/1000 | Loss: 0.00002019
Iteration 302/1000 | Loss: 0.00002018
Iteration 303/1000 | Loss: 0.00002018
Iteration 304/1000 | Loss: 0.00002018
Iteration 305/1000 | Loss: 0.00002017
Iteration 306/1000 | Loss: 0.00002017
Iteration 307/1000 | Loss: 0.00002017
Iteration 308/1000 | Loss: 0.00002016
Iteration 309/1000 | Loss: 0.00002016
Iteration 310/1000 | Loss: 0.00002016
Iteration 311/1000 | Loss: 0.00002016
Iteration 312/1000 | Loss: 0.00002016
Iteration 313/1000 | Loss: 0.00002016
Iteration 314/1000 | Loss: 0.00002015
Iteration 315/1000 | Loss: 0.00002015
Iteration 316/1000 | Loss: 0.00002014
Iteration 317/1000 | Loss: 0.00002014
Iteration 318/1000 | Loss: 0.00002014
Iteration 319/1000 | Loss: 0.00002014
Iteration 320/1000 | Loss: 0.00002013
Iteration 321/1000 | Loss: 0.00002013
Iteration 322/1000 | Loss: 0.00002013
Iteration 323/1000 | Loss: 0.00002012
Iteration 324/1000 | Loss: 0.00002011
Iteration 325/1000 | Loss: 0.00002011
Iteration 326/1000 | Loss: 0.00002011
Iteration 327/1000 | Loss: 0.00002010
Iteration 328/1000 | Loss: 0.00002010
Iteration 329/1000 | Loss: 0.00002010
Iteration 330/1000 | Loss: 0.00002009
Iteration 331/1000 | Loss: 0.00002009
Iteration 332/1000 | Loss: 0.00002009
Iteration 333/1000 | Loss: 0.00002009
Iteration 334/1000 | Loss: 0.00002008
Iteration 335/1000 | Loss: 0.00002007
Iteration 336/1000 | Loss: 0.00002007
Iteration 337/1000 | Loss: 0.00002006
Iteration 338/1000 | Loss: 0.00002006
Iteration 339/1000 | Loss: 0.00002005
Iteration 340/1000 | Loss: 0.00002004
Iteration 341/1000 | Loss: 0.00002003
Iteration 342/1000 | Loss: 0.00002003
Iteration 343/1000 | Loss: 0.00002003
Iteration 344/1000 | Loss: 0.00002000
Iteration 345/1000 | Loss: 0.00002000
Iteration 346/1000 | Loss: 0.00001998
Iteration 347/1000 | Loss: 0.00001998
Iteration 348/1000 | Loss: 0.00001998
Iteration 349/1000 | Loss: 0.00001998
Iteration 350/1000 | Loss: 0.00001998
Iteration 351/1000 | Loss: 0.00001997
Iteration 352/1000 | Loss: 0.00001997
Iteration 353/1000 | Loss: 0.00001997
Iteration 354/1000 | Loss: 0.00001997
Iteration 355/1000 | Loss: 0.00001997
Iteration 356/1000 | Loss: 0.00001997
Iteration 357/1000 | Loss: 0.00001997
Iteration 358/1000 | Loss: 0.00001997
Iteration 359/1000 | Loss: 0.00001997
Iteration 360/1000 | Loss: 0.00001997
Iteration 361/1000 | Loss: 0.00001997
Iteration 362/1000 | Loss: 0.00001996
Iteration 363/1000 | Loss: 0.00001996
Iteration 364/1000 | Loss: 0.00001996
Iteration 365/1000 | Loss: 0.00001996
Iteration 366/1000 | Loss: 0.00001996
Iteration 367/1000 | Loss: 0.00001996
Iteration 368/1000 | Loss: 0.00001995
Iteration 369/1000 | Loss: 0.00001995
Iteration 370/1000 | Loss: 0.00001995
Iteration 371/1000 | Loss: 0.00001995
Iteration 372/1000 | Loss: 0.00001995
Iteration 373/1000 | Loss: 0.00001995
Iteration 374/1000 | Loss: 0.00002774
Iteration 375/1000 | Loss: 0.00001993
Iteration 376/1000 | Loss: 0.00001993
Iteration 377/1000 | Loss: 0.00001993
Iteration 378/1000 | Loss: 0.00001993
Iteration 379/1000 | Loss: 0.00001993
Iteration 380/1000 | Loss: 0.00001993
Iteration 381/1000 | Loss: 0.00001993
Iteration 382/1000 | Loss: 0.00001992
Iteration 383/1000 | Loss: 0.00001992
Iteration 384/1000 | Loss: 0.00001992
Iteration 385/1000 | Loss: 0.00001992
Iteration 386/1000 | Loss: 0.00001992
Iteration 387/1000 | Loss: 0.00001992
Iteration 388/1000 | Loss: 0.00001992
Iteration 389/1000 | Loss: 0.00001992
Iteration 390/1000 | Loss: 0.00001992
Iteration 391/1000 | Loss: 0.00001992
Iteration 392/1000 | Loss: 0.00001992
Iteration 393/1000 | Loss: 0.00001991
Iteration 394/1000 | Loss: 0.00001991
Iteration 395/1000 | Loss: 0.00001991
Iteration 396/1000 | Loss: 0.00001991
Iteration 397/1000 | Loss: 0.00001991
Iteration 398/1000 | Loss: 0.00001991
Iteration 399/1000 | Loss: 0.00001991
Iteration 400/1000 | Loss: 0.00001991
Iteration 401/1000 | Loss: 0.00001990
Iteration 402/1000 | Loss: 0.00001990
Iteration 403/1000 | Loss: 0.00001990
Iteration 404/1000 | Loss: 0.00001990
Iteration 405/1000 | Loss: 0.00001990
Iteration 406/1000 | Loss: 0.00001990
Iteration 407/1000 | Loss: 0.00001990
Iteration 408/1000 | Loss: 0.00001990
Iteration 409/1000 | Loss: 0.00001990
Iteration 410/1000 | Loss: 0.00001990
Iteration 411/1000 | Loss: 0.00001990
Iteration 412/1000 | Loss: 0.00001990
Iteration 413/1000 | Loss: 0.00001989
Iteration 414/1000 | Loss: 0.00001989
Iteration 415/1000 | Loss: 0.00001989
Iteration 416/1000 | Loss: 0.00001988
Iteration 417/1000 | Loss: 0.00001988
Iteration 418/1000 | Loss: 0.00002849
Iteration 419/1000 | Loss: 0.00002357
Iteration 420/1000 | Loss: 0.00001984
Iteration 421/1000 | Loss: 0.00001984
Iteration 422/1000 | Loss: 0.00001984
Iteration 423/1000 | Loss: 0.00001984
Iteration 424/1000 | Loss: 0.00001984
Iteration 425/1000 | Loss: 0.00001983
Iteration 426/1000 | Loss: 0.00001983
Iteration 427/1000 | Loss: 0.00001983
Iteration 428/1000 | Loss: 0.00001983
Iteration 429/1000 | Loss: 0.00001983
Iteration 430/1000 | Loss: 0.00001983
Iteration 431/1000 | Loss: 0.00001983
Iteration 432/1000 | Loss: 0.00001983
Iteration 433/1000 | Loss: 0.00001983
Iteration 434/1000 | Loss: 0.00001983
Iteration 435/1000 | Loss: 0.00001983
Iteration 436/1000 | Loss: 0.00001983
Iteration 437/1000 | Loss: 0.00001983
Iteration 438/1000 | Loss: 0.00001983
Iteration 439/1000 | Loss: 0.00001983
Iteration 440/1000 | Loss: 0.00001983
Iteration 441/1000 | Loss: 0.00001983
Iteration 442/1000 | Loss: 0.00001983
Iteration 443/1000 | Loss: 0.00001982
Iteration 444/1000 | Loss: 0.00001982
Iteration 445/1000 | Loss: 0.00001982
Iteration 446/1000 | Loss: 0.00001982
Iteration 447/1000 | Loss: 0.00001982
Iteration 448/1000 | Loss: 0.00001982
Iteration 449/1000 | Loss: 0.00001982
Iteration 450/1000 | Loss: 0.00001982
Iteration 451/1000 | Loss: 0.00001981
Iteration 452/1000 | Loss: 0.00001981
Iteration 453/1000 | Loss: 0.00001981
Iteration 454/1000 | Loss: 0.00001981
Iteration 455/1000 | Loss: 0.00001981
Iteration 456/1000 | Loss: 0.00001981
Iteration 457/1000 | Loss: 0.00001981
Iteration 458/1000 | Loss: 0.00001981
Iteration 459/1000 | Loss: 0.00001981
Iteration 460/1000 | Loss: 0.00001980
Iteration 461/1000 | Loss: 0.00001980
Iteration 462/1000 | Loss: 0.00001977
Iteration 463/1000 | Loss: 0.00001977
Iteration 464/1000 | Loss: 0.00001976
Iteration 465/1000 | Loss: 0.00001976
Iteration 466/1000 | Loss: 0.00001975
Iteration 467/1000 | Loss: 0.00001975
Iteration 468/1000 | Loss: 0.00001975
Iteration 469/1000 | Loss: 0.00001975
Iteration 470/1000 | Loss: 0.00001975
Iteration 471/1000 | Loss: 0.00001975
Iteration 472/1000 | Loss: 0.00001975
Iteration 473/1000 | Loss: 0.00001975
Iteration 474/1000 | Loss: 0.00001975
Iteration 475/1000 | Loss: 0.00001974
Iteration 476/1000 | Loss: 0.00001974
Iteration 477/1000 | Loss: 0.00001974
Iteration 478/1000 | Loss: 0.00001974
Iteration 479/1000 | Loss: 0.00001973
Iteration 480/1000 | Loss: 0.00001973
Iteration 481/1000 | Loss: 0.00001973
Iteration 482/1000 | Loss: 0.00001973
Iteration 483/1000 | Loss: 0.00001971
Iteration 484/1000 | Loss: 0.00003481
Iteration 485/1000 | Loss: 0.00002941
Iteration 486/1000 | Loss: 0.00008435
Iteration 487/1000 | Loss: 0.00003009
Iteration 488/1000 | Loss: 0.00001961
Iteration 489/1000 | Loss: 0.00001960
Iteration 490/1000 | Loss: 0.00001960
Iteration 491/1000 | Loss: 0.00001959
Iteration 492/1000 | Loss: 0.00001959
Iteration 493/1000 | Loss: 0.00001958
Iteration 494/1000 | Loss: 0.00001944
Iteration 495/1000 | Loss: 0.00002819
Iteration 496/1000 | Loss: 0.00001908
Iteration 497/1000 | Loss: 0.00001901
Iteration 498/1000 | Loss: 0.00006830
Iteration 499/1000 | Loss: 0.00009035
Iteration 500/1000 | Loss: 0.00032691
Iteration 501/1000 | Loss: 0.00029665
Iteration 502/1000 | Loss: 0.00015003
Iteration 503/1000 | Loss: 0.00015884
Iteration 504/1000 | Loss: 0.00002290
Iteration 505/1000 | Loss: 0.00013232
Iteration 506/1000 | Loss: 0.00019766
Iteration 507/1000 | Loss: 0.00012707
Iteration 508/1000 | Loss: 0.00003644
Iteration 509/1000 | Loss: 0.00001918
Iteration 510/1000 | Loss: 0.00002777
Iteration 511/1000 | Loss: 0.00001850
Iteration 512/1000 | Loss: 0.00001821
Iteration 513/1000 | Loss: 0.00001802
Iteration 514/1000 | Loss: 0.00001783
Iteration 515/1000 | Loss: 0.00003425
Iteration 516/1000 | Loss: 0.00001769
Iteration 517/1000 | Loss: 0.00022651
Iteration 518/1000 | Loss: 0.00013046
Iteration 519/1000 | Loss: 0.00014790
Iteration 520/1000 | Loss: 0.00005353
Iteration 521/1000 | Loss: 0.00022026
Iteration 522/1000 | Loss: 0.00019540
Iteration 523/1000 | Loss: 0.00021089
Iteration 524/1000 | Loss: 0.00004644
Iteration 525/1000 | Loss: 0.00003169
Iteration 526/1000 | Loss: 0.00001992
Iteration 527/1000 | Loss: 0.00001907
Iteration 528/1000 | Loss: 0.00001872
Iteration 529/1000 | Loss: 0.00003256
Iteration 530/1000 | Loss: 0.00001797
Iteration 531/1000 | Loss: 0.00002659
Iteration 532/1000 | Loss: 0.00002858
Iteration 533/1000 | Loss: 0.00002262
Iteration 534/1000 | Loss: 0.00001695
Iteration 535/1000 | Loss: 0.00002330
Iteration 536/1000 | Loss: 0.00001678
Iteration 537/1000 | Loss: 0.00001675
Iteration 538/1000 | Loss: 0.00001674
Iteration 539/1000 | Loss: 0.00001674
Iteration 540/1000 | Loss: 0.00001673
Iteration 541/1000 | Loss: 0.00001672
Iteration 542/1000 | Loss: 0.00001671
Iteration 543/1000 | Loss: 0.00001671
Iteration 544/1000 | Loss: 0.00003376
Iteration 545/1000 | Loss: 0.00002181
Iteration 546/1000 | Loss: 0.00001649
Iteration 547/1000 | Loss: 0.00001648
Iteration 548/1000 | Loss: 0.00001647
Iteration 549/1000 | Loss: 0.00001647
Iteration 550/1000 | Loss: 0.00001647
Iteration 551/1000 | Loss: 0.00001646
Iteration 552/1000 | Loss: 0.00001645
Iteration 553/1000 | Loss: 0.00002501
Iteration 554/1000 | Loss: 0.00025575
Iteration 555/1000 | Loss: 0.00012519
Iteration 556/1000 | Loss: 0.00002722
Iteration 557/1000 | Loss: 0.00002905
Iteration 558/1000 | Loss: 0.00005534
Iteration 559/1000 | Loss: 0.00001712
Iteration 560/1000 | Loss: 0.00017770
Iteration 561/1000 | Loss: 0.00003449
Iteration 562/1000 | Loss: 0.00003171
Iteration 563/1000 | Loss: 0.00006198
Iteration 564/1000 | Loss: 0.00003501
Iteration 565/1000 | Loss: 0.00003664
Iteration 566/1000 | Loss: 0.00001770
Iteration 567/1000 | Loss: 0.00001947
Iteration 568/1000 | Loss: 0.00001652
Iteration 569/1000 | Loss: 0.00001624
Iteration 570/1000 | Loss: 0.00001604
Iteration 571/1000 | Loss: 0.00001591
Iteration 572/1000 | Loss: 0.00001571
Iteration 573/1000 | Loss: 0.00001568
Iteration 574/1000 | Loss: 0.00001564
Iteration 575/1000 | Loss: 0.00002850
Iteration 576/1000 | Loss: 0.00010120
Iteration 577/1000 | Loss: 0.00002076
Iteration 578/1000 | Loss: 0.00004866
Iteration 579/1000 | Loss: 0.00001987
Iteration 580/1000 | Loss: 0.00001973
Iteration 581/1000 | Loss: 0.00001688
Iteration 582/1000 | Loss: 0.00001686
Iteration 583/1000 | Loss: 0.00001616
Iteration 584/1000 | Loss: 0.00001783
Iteration 585/1000 | Loss: 0.00001597
Iteration 586/1000 | Loss: 0.00003326
Iteration 587/1000 | Loss: 0.00003326
Iteration 588/1000 | Loss: 0.00018760
Iteration 589/1000 | Loss: 0.00003193
Iteration 590/1000 | Loss: 0.00003756
Iteration 591/1000 | Loss: 0.00003432
Iteration 592/1000 | Loss: 0.00030721
Iteration 593/1000 | Loss: 0.00017277
Iteration 594/1000 | Loss: 0.00016240
Iteration 595/1000 | Loss: 0.00002625
Iteration 596/1000 | Loss: 0.00009470
Iteration 597/1000 | Loss: 0.00001838
Iteration 598/1000 | Loss: 0.00002957
Iteration 599/1000 | Loss: 0.00001716
Iteration 600/1000 | Loss: 0.00001665
Iteration 601/1000 | Loss: 0.00003331
Iteration 602/1000 | Loss: 0.00002961
Iteration 603/1000 | Loss: 0.00001627
Iteration 604/1000 | Loss: 0.00001626
Iteration 605/1000 | Loss: 0.00001626
Iteration 606/1000 | Loss: 0.00001617
Iteration 607/1000 | Loss: 0.00001615
Iteration 608/1000 | Loss: 0.00001614
Iteration 609/1000 | Loss: 0.00001614
Iteration 610/1000 | Loss: 0.00001613
Iteration 611/1000 | Loss: 0.00001611
Iteration 612/1000 | Loss: 0.00001609
Iteration 613/1000 | Loss: 0.00001606
Iteration 614/1000 | Loss: 0.00001601
Iteration 615/1000 | Loss: 0.00001600
Iteration 616/1000 | Loss: 0.00001599
Iteration 617/1000 | Loss: 0.00001599
Iteration 618/1000 | Loss: 0.00001621
Iteration 619/1000 | Loss: 0.00001621
Iteration 620/1000 | Loss: 0.00001592
Iteration 621/1000 | Loss: 0.00001592
Iteration 622/1000 | Loss: 0.00001592
Iteration 623/1000 | Loss: 0.00001591
Iteration 624/1000 | Loss: 0.00001591
Iteration 625/1000 | Loss: 0.00001591
Iteration 626/1000 | Loss: 0.00001591
Iteration 627/1000 | Loss: 0.00001591
Iteration 628/1000 | Loss: 0.00001591
Iteration 629/1000 | Loss: 0.00001588
Iteration 630/1000 | Loss: 0.00001587
Iteration 631/1000 | Loss: 0.00001586
Iteration 632/1000 | Loss: 0.00001586
Iteration 633/1000 | Loss: 0.00001585
Iteration 634/1000 | Loss: 0.00001585
Iteration 635/1000 | Loss: 0.00001585
Iteration 636/1000 | Loss: 0.00001585
Iteration 637/1000 | Loss: 0.00001584
Iteration 638/1000 | Loss: 0.00001584
Iteration 639/1000 | Loss: 0.00001583
Iteration 640/1000 | Loss: 0.00001582
Iteration 641/1000 | Loss: 0.00001581
Iteration 642/1000 | Loss: 0.00001581
Iteration 643/1000 | Loss: 0.00001581
Iteration 644/1000 | Loss: 0.00003802
Iteration 645/1000 | Loss: 0.00001577
Iteration 646/1000 | Loss: 0.00001577
Iteration 647/1000 | Loss: 0.00001577
Iteration 648/1000 | Loss: 0.00001577
Iteration 649/1000 | Loss: 0.00001577
Iteration 650/1000 | Loss: 0.00001577
Iteration 651/1000 | Loss: 0.00001577
Iteration 652/1000 | Loss: 0.00001577
Iteration 653/1000 | Loss: 0.00001577
Iteration 654/1000 | Loss: 0.00001576
Iteration 655/1000 | Loss: 0.00001576
Iteration 656/1000 | Loss: 0.00001576
Iteration 657/1000 | Loss: 0.00001576
Iteration 658/1000 | Loss: 0.00001575
Iteration 659/1000 | Loss: 0.00001575
Iteration 660/1000 | Loss: 0.00001575
Iteration 661/1000 | Loss: 0.00001574
Iteration 662/1000 | Loss: 0.00001573
Iteration 663/1000 | Loss: 0.00001573
Iteration 664/1000 | Loss: 0.00001573
Iteration 665/1000 | Loss: 0.00001573
Iteration 666/1000 | Loss: 0.00001573
Iteration 667/1000 | Loss: 0.00001573
Iteration 668/1000 | Loss: 0.00001573
Iteration 669/1000 | Loss: 0.00001572
Iteration 670/1000 | Loss: 0.00001572
Iteration 671/1000 | Loss: 0.00001572
Iteration 672/1000 | Loss: 0.00002541
Iteration 673/1000 | Loss: 0.00001575
Iteration 674/1000 | Loss: 0.00001862
Iteration 675/1000 | Loss: 0.00001570
Iteration 676/1000 | Loss: 0.00001570
Iteration 677/1000 | Loss: 0.00001570
Iteration 678/1000 | Loss: 0.00001570
Iteration 679/1000 | Loss: 0.00001569
Iteration 680/1000 | Loss: 0.00001569
Iteration 681/1000 | Loss: 0.00001569
Iteration 682/1000 | Loss: 0.00001569
Iteration 683/1000 | Loss: 0.00001569
Iteration 684/1000 | Loss: 0.00001569
Iteration 685/1000 | Loss: 0.00001568
Iteration 686/1000 | Loss: 0.00001568
Iteration 687/1000 | Loss: 0.00001568
Iteration 688/1000 | Loss: 0.00001568
Iteration 689/1000 | Loss: 0.00001568
Iteration 690/1000 | Loss: 0.00001568
Iteration 691/1000 | Loss: 0.00001568
Iteration 692/1000 | Loss: 0.00001567
Iteration 693/1000 | Loss: 0.00001567
Iteration 694/1000 | Loss: 0.00001567
Iteration 695/1000 | Loss: 0.00001567
Iteration 696/1000 | Loss: 0.00001567
Iteration 697/1000 | Loss: 0.00001567
Iteration 698/1000 | Loss: 0.00001566
Iteration 699/1000 | Loss: 0.00001566
Iteration 700/1000 | Loss: 0.00001566
Iteration 701/1000 | Loss: 0.00001565
Iteration 702/1000 | Loss: 0.00001565
Iteration 703/1000 | Loss: 0.00001565
Iteration 704/1000 | Loss: 0.00001564
Iteration 705/1000 | Loss: 0.00001564
Iteration 706/1000 | Loss: 0.00001564
Iteration 707/1000 | Loss: 0.00001563
Iteration 708/1000 | Loss: 0.00001563
Iteration 709/1000 | Loss: 0.00001563
Iteration 710/1000 | Loss: 0.00001563
Iteration 711/1000 | Loss: 0.00001563
Iteration 712/1000 | Loss: 0.00001563
Iteration 713/1000 | Loss: 0.00001563
Iteration 714/1000 | Loss: 0.00001563
Iteration 715/1000 | Loss: 0.00001563
Iteration 716/1000 | Loss: 0.00001563
Iteration 717/1000 | Loss: 0.00001562
Iteration 718/1000 | Loss: 0.00001562
Iteration 719/1000 | Loss: 0.00001562
Iteration 720/1000 | Loss: 0.00001562
Iteration 721/1000 | Loss: 0.00001562
Iteration 722/1000 | Loss: 0.00001562
Iteration 723/1000 | Loss: 0.00001562
Iteration 724/1000 | Loss: 0.00001562
Iteration 725/1000 | Loss: 0.00001561
Iteration 726/1000 | Loss: 0.00001561
Iteration 727/1000 | Loss: 0.00001561
Iteration 728/1000 | Loss: 0.00001561
Iteration 729/1000 | Loss: 0.00001561
Iteration 730/1000 | Loss: 0.00001561
Iteration 731/1000 | Loss: 0.00001561
Iteration 732/1000 | Loss: 0.00001561
Iteration 733/1000 | Loss: 0.00001561
Iteration 734/1000 | Loss: 0.00001560
Iteration 735/1000 | Loss: 0.00001560
Iteration 736/1000 | Loss: 0.00001560
Iteration 737/1000 | Loss: 0.00001560
Iteration 738/1000 | Loss: 0.00001560
Iteration 739/1000 | Loss: 0.00001559
Iteration 740/1000 | Loss: 0.00001559
Iteration 741/1000 | Loss: 0.00001559
Iteration 742/1000 | Loss: 0.00001559
Iteration 743/1000 | Loss: 0.00001559
Iteration 744/1000 | Loss: 0.00001559
Iteration 745/1000 | Loss: 0.00001558
Iteration 746/1000 | Loss: 0.00001558
Iteration 747/1000 | Loss: 0.00001558
Iteration 748/1000 | Loss: 0.00001558
Iteration 749/1000 | Loss: 0.00001557
Iteration 750/1000 | Loss: 0.00001557
Iteration 751/1000 | Loss: 0.00001557
Iteration 752/1000 | Loss: 0.00001557
Iteration 753/1000 | Loss: 0.00001557
Iteration 754/1000 | Loss: 0.00001556
Iteration 755/1000 | Loss: 0.00001556
Iteration 756/1000 | Loss: 0.00001556
Iteration 757/1000 | Loss: 0.00001556
Iteration 758/1000 | Loss: 0.00001556
Iteration 759/1000 | Loss: 0.00001555
Iteration 760/1000 | Loss: 0.00001555
Iteration 761/1000 | Loss: 0.00001555
Iteration 762/1000 | Loss: 0.00001554
Iteration 763/1000 | Loss: 0.00001554
Iteration 764/1000 | Loss: 0.00001554
Iteration 765/1000 | Loss: 0.00001553
Iteration 766/1000 | Loss: 0.00001553
Iteration 767/1000 | Loss: 0.00001553
Iteration 768/1000 | Loss: 0.00001553
Iteration 769/1000 | Loss: 0.00001552
Iteration 770/1000 | Loss: 0.00001552
Iteration 771/1000 | Loss: 0.00001551
Iteration 772/1000 | Loss: 0.00001551
Iteration 773/1000 | Loss: 0.00001551
Iteration 774/1000 | Loss: 0.00001550
Iteration 775/1000 | Loss: 0.00001550
Iteration 776/1000 | Loss: 0.00001550
Iteration 777/1000 | Loss: 0.00001546
Iteration 778/1000 | Loss: 0.00001541
Iteration 779/1000 | Loss: 0.00001537
Iteration 780/1000 | Loss: 0.00001534
Iteration 781/1000 | Loss: 0.00004003
Iteration 782/1000 | Loss: 0.00001519
Iteration 783/1000 | Loss: 0.00001514
Iteration 784/1000 | Loss: 0.00001498
Iteration 785/1000 | Loss: 0.00001496
Iteration 786/1000 | Loss: 0.00002241
Iteration 787/1000 | Loss: 0.00023373
Iteration 788/1000 | Loss: 0.00004835
Iteration 789/1000 | Loss: 0.00003006
Iteration 790/1000 | Loss: 0.00003345
Iteration 791/1000 | Loss: 0.00001765
Iteration 792/1000 | Loss: 0.00001574
Iteration 793/1000 | Loss: 0.00001499
Iteration 794/1000 | Loss: 0.00001447
Iteration 795/1000 | Loss: 0.00001425
Iteration 796/1000 | Loss: 0.00001418
Iteration 797/1000 | Loss: 0.00004473
Iteration 798/1000 | Loss: 0.00001762
Iteration 799/1000 | Loss: 0.00001427
Iteration 800/1000 | Loss: 0.00001409
Iteration 801/1000 | Loss: 0.00001404
Iteration 802/1000 | Loss: 0.00001402
Iteration 803/1000 | Loss: 0.00001401
Iteration 804/1000 | Loss: 0.00001401
Iteration 805/1000 | Loss: 0.00001400
Iteration 806/1000 | Loss: 0.00001400
Iteration 807/1000 | Loss: 0.00001399
Iteration 808/1000 | Loss: 0.00001398
Iteration 809/1000 | Loss: 0.00001396
Iteration 810/1000 | Loss: 0.00001396
Iteration 811/1000 | Loss: 0.00001395
Iteration 812/1000 | Loss: 0.00001395
Iteration 813/1000 | Loss: 0.00001395
Iteration 814/1000 | Loss: 0.00003719
Iteration 815/1000 | Loss: 0.00001391
Iteration 816/1000 | Loss: 0.00001389
Iteration 817/1000 | Loss: 0.00001389
Iteration 818/1000 | Loss: 0.00001389
Iteration 819/1000 | Loss: 0.00001389
Iteration 820/1000 | Loss: 0.00001389
Iteration 821/1000 | Loss: 0.00001389
Iteration 822/1000 | Loss: 0.00001389
Iteration 823/1000 | Loss: 0.00001389
Iteration 824/1000 | Loss: 0.00001389
Iteration 825/1000 | Loss: 0.00001389
Iteration 826/1000 | Loss: 0.00001389
Iteration 827/1000 | Loss: 0.00001389
Iteration 828/1000 | Loss: 0.00001387
Iteration 829/1000 | Loss: 0.00001387
Iteration 830/1000 | Loss: 0.00001386
Iteration 831/1000 | Loss: 0.00001386
Iteration 832/1000 | Loss: 0.00001386
Iteration 833/1000 | Loss: 0.00001386
Iteration 834/1000 | Loss: 0.00001385
Iteration 835/1000 | Loss: 0.00001385
Iteration 836/1000 | Loss: 0.00001385
Iteration 837/1000 | Loss: 0.00001384
Iteration 838/1000 | Loss: 0.00001384
Iteration 839/1000 | Loss: 0.00002282
Iteration 840/1000 | Loss: 0.00001528
Iteration 841/1000 | Loss: 0.00001381
Iteration 842/1000 | Loss: 0.00001381
Iteration 843/1000 | Loss: 0.00001380
Iteration 844/1000 | Loss: 0.00001380
Iteration 845/1000 | Loss: 0.00001380
Iteration 846/1000 | Loss: 0.00001380
Iteration 847/1000 | Loss: 0.00001380
Iteration 848/1000 | Loss: 0.00001380
Iteration 849/1000 | Loss: 0.00001380
Iteration 850/1000 | Loss: 0.00001380
Iteration 851/1000 | Loss: 0.00001380
Iteration 852/1000 | Loss: 0.00001380
Iteration 853/1000 | Loss: 0.00001380
Iteration 854/1000 | Loss: 0.00001380
Iteration 855/1000 | Loss: 0.00001380
Iteration 856/1000 | Loss: 0.00001380
Iteration 857/1000 | Loss: 0.00001380
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 857. Stopping optimization.
Last 5 losses: [1.3798965483147185e-05, 1.3798965483147185e-05, 1.3798965483147185e-05, 1.3798965483147185e-05, 1.3798965483147185e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3798965483147185e-05

Optimization complete. Final v2v error: 3.1838672161102295 mm

Highest mean error: 5.285514831542969 mm for frame 26

Lowest mean error: 2.873272657394409 mm for frame 57

Saving results

Total time: 519.1633093357086
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1088/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1088.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1088
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00456426
Iteration 2/25 | Loss: 0.00154783
Iteration 3/25 | Loss: 0.00141829
Iteration 4/25 | Loss: 0.00140665
Iteration 5/25 | Loss: 0.00140435
Iteration 6/25 | Loss: 0.00140371
Iteration 7/25 | Loss: 0.00140371
Iteration 8/25 | Loss: 0.00140371
Iteration 9/25 | Loss: 0.00140371
Iteration 10/25 | Loss: 0.00140371
Iteration 11/25 | Loss: 0.00140371
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001403706963174045, 0.001403706963174045, 0.001403706963174045, 0.001403706963174045, 0.001403706963174045]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001403706963174045

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32848036
Iteration 2/25 | Loss: 0.00176016
Iteration 3/25 | Loss: 0.00176016
Iteration 4/25 | Loss: 0.00176016
Iteration 5/25 | Loss: 0.00176015
Iteration 6/25 | Loss: 0.00176015
Iteration 7/25 | Loss: 0.00176015
Iteration 8/25 | Loss: 0.00176015
Iteration 9/25 | Loss: 0.00176015
Iteration 10/25 | Loss: 0.00176015
Iteration 11/25 | Loss: 0.00176015
Iteration 12/25 | Loss: 0.00176015
Iteration 13/25 | Loss: 0.00176015
Iteration 14/25 | Loss: 0.00176015
Iteration 15/25 | Loss: 0.00176015
Iteration 16/25 | Loss: 0.00176015
Iteration 17/25 | Loss: 0.00176015
Iteration 18/25 | Loss: 0.00176015
Iteration 19/25 | Loss: 0.00176015
Iteration 20/25 | Loss: 0.00176015
Iteration 21/25 | Loss: 0.00176015
Iteration 22/25 | Loss: 0.00176015
Iteration 23/25 | Loss: 0.00176015
Iteration 24/25 | Loss: 0.00176015
Iteration 25/25 | Loss: 0.00176015

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00176015
Iteration 2/1000 | Loss: 0.00003935
Iteration 3/1000 | Loss: 0.00002783
Iteration 4/1000 | Loss: 0.00002190
Iteration 5/1000 | Loss: 0.00002051
Iteration 6/1000 | Loss: 0.00001965
Iteration 7/1000 | Loss: 0.00001908
Iteration 8/1000 | Loss: 0.00001853
Iteration 9/1000 | Loss: 0.00001815
Iteration 10/1000 | Loss: 0.00001778
Iteration 11/1000 | Loss: 0.00001748
Iteration 12/1000 | Loss: 0.00001721
Iteration 13/1000 | Loss: 0.00001704
Iteration 14/1000 | Loss: 0.00001683
Iteration 15/1000 | Loss: 0.00001671
Iteration 16/1000 | Loss: 0.00001670
Iteration 17/1000 | Loss: 0.00001657
Iteration 18/1000 | Loss: 0.00001656
Iteration 19/1000 | Loss: 0.00001655
Iteration 20/1000 | Loss: 0.00001651
Iteration 21/1000 | Loss: 0.00001646
Iteration 22/1000 | Loss: 0.00001645
Iteration 23/1000 | Loss: 0.00001644
Iteration 24/1000 | Loss: 0.00001643
Iteration 25/1000 | Loss: 0.00001643
Iteration 26/1000 | Loss: 0.00001642
Iteration 27/1000 | Loss: 0.00001641
Iteration 28/1000 | Loss: 0.00001638
Iteration 29/1000 | Loss: 0.00001637
Iteration 30/1000 | Loss: 0.00001637
Iteration 31/1000 | Loss: 0.00001637
Iteration 32/1000 | Loss: 0.00001636
Iteration 33/1000 | Loss: 0.00001636
Iteration 34/1000 | Loss: 0.00001630
Iteration 35/1000 | Loss: 0.00001628
Iteration 36/1000 | Loss: 0.00001627
Iteration 37/1000 | Loss: 0.00001627
Iteration 38/1000 | Loss: 0.00001625
Iteration 39/1000 | Loss: 0.00001625
Iteration 40/1000 | Loss: 0.00001624
Iteration 41/1000 | Loss: 0.00001623
Iteration 42/1000 | Loss: 0.00001620
Iteration 43/1000 | Loss: 0.00001619
Iteration 44/1000 | Loss: 0.00001617
Iteration 45/1000 | Loss: 0.00001617
Iteration 46/1000 | Loss: 0.00001617
Iteration 47/1000 | Loss: 0.00001616
Iteration 48/1000 | Loss: 0.00001615
Iteration 49/1000 | Loss: 0.00001614
Iteration 50/1000 | Loss: 0.00001614
Iteration 51/1000 | Loss: 0.00001613
Iteration 52/1000 | Loss: 0.00001613
Iteration 53/1000 | Loss: 0.00001613
Iteration 54/1000 | Loss: 0.00001612
Iteration 55/1000 | Loss: 0.00001612
Iteration 56/1000 | Loss: 0.00001611
Iteration 57/1000 | Loss: 0.00001611
Iteration 58/1000 | Loss: 0.00001611
Iteration 59/1000 | Loss: 0.00001610
Iteration 60/1000 | Loss: 0.00001610
Iteration 61/1000 | Loss: 0.00001610
Iteration 62/1000 | Loss: 0.00001610
Iteration 63/1000 | Loss: 0.00001610
Iteration 64/1000 | Loss: 0.00001610
Iteration 65/1000 | Loss: 0.00001609
Iteration 66/1000 | Loss: 0.00001609
Iteration 67/1000 | Loss: 0.00001609
Iteration 68/1000 | Loss: 0.00001609
Iteration 69/1000 | Loss: 0.00001609
Iteration 70/1000 | Loss: 0.00001608
Iteration 71/1000 | Loss: 0.00001608
Iteration 72/1000 | Loss: 0.00001608
Iteration 73/1000 | Loss: 0.00001608
Iteration 74/1000 | Loss: 0.00001608
Iteration 75/1000 | Loss: 0.00001607
Iteration 76/1000 | Loss: 0.00001607
Iteration 77/1000 | Loss: 0.00001607
Iteration 78/1000 | Loss: 0.00001607
Iteration 79/1000 | Loss: 0.00001606
Iteration 80/1000 | Loss: 0.00001606
Iteration 81/1000 | Loss: 0.00001606
Iteration 82/1000 | Loss: 0.00001606
Iteration 83/1000 | Loss: 0.00001605
Iteration 84/1000 | Loss: 0.00001605
Iteration 85/1000 | Loss: 0.00001605
Iteration 86/1000 | Loss: 0.00001605
Iteration 87/1000 | Loss: 0.00001605
Iteration 88/1000 | Loss: 0.00001605
Iteration 89/1000 | Loss: 0.00001605
Iteration 90/1000 | Loss: 0.00001604
Iteration 91/1000 | Loss: 0.00001604
Iteration 92/1000 | Loss: 0.00001604
Iteration 93/1000 | Loss: 0.00001604
Iteration 94/1000 | Loss: 0.00001604
Iteration 95/1000 | Loss: 0.00001603
Iteration 96/1000 | Loss: 0.00001603
Iteration 97/1000 | Loss: 0.00001603
Iteration 98/1000 | Loss: 0.00001603
Iteration 99/1000 | Loss: 0.00001602
Iteration 100/1000 | Loss: 0.00001602
Iteration 101/1000 | Loss: 0.00001602
Iteration 102/1000 | Loss: 0.00001602
Iteration 103/1000 | Loss: 0.00001602
Iteration 104/1000 | Loss: 0.00001602
Iteration 105/1000 | Loss: 0.00001602
Iteration 106/1000 | Loss: 0.00001602
Iteration 107/1000 | Loss: 0.00001602
Iteration 108/1000 | Loss: 0.00001602
Iteration 109/1000 | Loss: 0.00001601
Iteration 110/1000 | Loss: 0.00001601
Iteration 111/1000 | Loss: 0.00001601
Iteration 112/1000 | Loss: 0.00001601
Iteration 113/1000 | Loss: 0.00001600
Iteration 114/1000 | Loss: 0.00001600
Iteration 115/1000 | Loss: 0.00001600
Iteration 116/1000 | Loss: 0.00001600
Iteration 117/1000 | Loss: 0.00001600
Iteration 118/1000 | Loss: 0.00001600
Iteration 119/1000 | Loss: 0.00001600
Iteration 120/1000 | Loss: 0.00001600
Iteration 121/1000 | Loss: 0.00001600
Iteration 122/1000 | Loss: 0.00001600
Iteration 123/1000 | Loss: 0.00001599
Iteration 124/1000 | Loss: 0.00001599
Iteration 125/1000 | Loss: 0.00001599
Iteration 126/1000 | Loss: 0.00001599
Iteration 127/1000 | Loss: 0.00001599
Iteration 128/1000 | Loss: 0.00001598
Iteration 129/1000 | Loss: 0.00001598
Iteration 130/1000 | Loss: 0.00001598
Iteration 131/1000 | Loss: 0.00001598
Iteration 132/1000 | Loss: 0.00001598
Iteration 133/1000 | Loss: 0.00001598
Iteration 134/1000 | Loss: 0.00001597
Iteration 135/1000 | Loss: 0.00001597
Iteration 136/1000 | Loss: 0.00001597
Iteration 137/1000 | Loss: 0.00001597
Iteration 138/1000 | Loss: 0.00001597
Iteration 139/1000 | Loss: 0.00001597
Iteration 140/1000 | Loss: 0.00001597
Iteration 141/1000 | Loss: 0.00001597
Iteration 142/1000 | Loss: 0.00001596
Iteration 143/1000 | Loss: 0.00001596
Iteration 144/1000 | Loss: 0.00001596
Iteration 145/1000 | Loss: 0.00001596
Iteration 146/1000 | Loss: 0.00001596
Iteration 147/1000 | Loss: 0.00001596
Iteration 148/1000 | Loss: 0.00001596
Iteration 149/1000 | Loss: 0.00001596
Iteration 150/1000 | Loss: 0.00001596
Iteration 151/1000 | Loss: 0.00001596
Iteration 152/1000 | Loss: 0.00001596
Iteration 153/1000 | Loss: 0.00001596
Iteration 154/1000 | Loss: 0.00001596
Iteration 155/1000 | Loss: 0.00001596
Iteration 156/1000 | Loss: 0.00001596
Iteration 157/1000 | Loss: 0.00001596
Iteration 158/1000 | Loss: 0.00001596
Iteration 159/1000 | Loss: 0.00001596
Iteration 160/1000 | Loss: 0.00001596
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 160. Stopping optimization.
Last 5 losses: [1.5960089513100684e-05, 1.5960089513100684e-05, 1.5960089513100684e-05, 1.5960089513100684e-05, 1.5960089513100684e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5960089513100684e-05

Optimization complete. Final v2v error: 3.3305160999298096 mm

Highest mean error: 3.7804884910583496 mm for frame 15

Lowest mean error: 2.604665994644165 mm for frame 0

Saving results

Total time: 43.62537884712219
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1096
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00767336
Iteration 2/25 | Loss: 0.00165132
Iteration 3/25 | Loss: 0.00154020
Iteration 4/25 | Loss: 0.00152486
Iteration 5/25 | Loss: 0.00152111
Iteration 6/25 | Loss: 0.00152021
Iteration 7/25 | Loss: 0.00152021
Iteration 8/25 | Loss: 0.00152021
Iteration 9/25 | Loss: 0.00152021
Iteration 10/25 | Loss: 0.00152021
Iteration 11/25 | Loss: 0.00152021
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0015202080830931664, 0.0015202080830931664, 0.0015202080830931664, 0.0015202080830931664, 0.0015202080830931664]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0015202080830931664

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27895606
Iteration 2/25 | Loss: 0.00173207
Iteration 3/25 | Loss: 0.00173204
Iteration 4/25 | Loss: 0.00173204
Iteration 5/25 | Loss: 0.00173204
Iteration 6/25 | Loss: 0.00173204
Iteration 7/25 | Loss: 0.00173204
Iteration 8/25 | Loss: 0.00173204
Iteration 9/25 | Loss: 0.00173204
Iteration 10/25 | Loss: 0.00173204
Iteration 11/25 | Loss: 0.00173204
Iteration 12/25 | Loss: 0.00173204
Iteration 13/25 | Loss: 0.00173204
Iteration 14/25 | Loss: 0.00173204
Iteration 15/25 | Loss: 0.00173204
Iteration 16/25 | Loss: 0.00173204
Iteration 17/25 | Loss: 0.00173204
Iteration 18/25 | Loss: 0.00173204
Iteration 19/25 | Loss: 0.00173204
Iteration 20/25 | Loss: 0.00173204
Iteration 21/25 | Loss: 0.00173204
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0017320398474112153, 0.0017320398474112153, 0.0017320398474112153, 0.0017320398474112153, 0.0017320398474112153]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017320398474112153

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00173204
Iteration 2/1000 | Loss: 0.00005608
Iteration 3/1000 | Loss: 0.00003577
Iteration 4/1000 | Loss: 0.00003095
Iteration 5/1000 | Loss: 0.00002969
Iteration 6/1000 | Loss: 0.00002923
Iteration 7/1000 | Loss: 0.00002879
Iteration 8/1000 | Loss: 0.00002833
Iteration 9/1000 | Loss: 0.00002796
Iteration 10/1000 | Loss: 0.00002776
Iteration 11/1000 | Loss: 0.00002755
Iteration 12/1000 | Loss: 0.00002733
Iteration 13/1000 | Loss: 0.00002717
Iteration 14/1000 | Loss: 0.00002714
Iteration 15/1000 | Loss: 0.00002706
Iteration 16/1000 | Loss: 0.00002702
Iteration 17/1000 | Loss: 0.00002697
Iteration 18/1000 | Loss: 0.00002689
Iteration 19/1000 | Loss: 0.00002689
Iteration 20/1000 | Loss: 0.00002689
Iteration 21/1000 | Loss: 0.00002687
Iteration 22/1000 | Loss: 0.00002685
Iteration 23/1000 | Loss: 0.00002685
Iteration 24/1000 | Loss: 0.00002685
Iteration 25/1000 | Loss: 0.00002684
Iteration 26/1000 | Loss: 0.00002684
Iteration 27/1000 | Loss: 0.00002682
Iteration 28/1000 | Loss: 0.00002671
Iteration 29/1000 | Loss: 0.00002671
Iteration 30/1000 | Loss: 0.00002670
Iteration 31/1000 | Loss: 0.00002670
Iteration 32/1000 | Loss: 0.00002670
Iteration 33/1000 | Loss: 0.00002670
Iteration 34/1000 | Loss: 0.00002670
Iteration 35/1000 | Loss: 0.00002669
Iteration 36/1000 | Loss: 0.00002665
Iteration 37/1000 | Loss: 0.00002665
Iteration 38/1000 | Loss: 0.00002662
Iteration 39/1000 | Loss: 0.00002659
Iteration 40/1000 | Loss: 0.00002659
Iteration 41/1000 | Loss: 0.00002659
Iteration 42/1000 | Loss: 0.00002658
Iteration 43/1000 | Loss: 0.00002654
Iteration 44/1000 | Loss: 0.00002653
Iteration 45/1000 | Loss: 0.00002649
Iteration 46/1000 | Loss: 0.00002649
Iteration 47/1000 | Loss: 0.00002648
Iteration 48/1000 | Loss: 0.00002648
Iteration 49/1000 | Loss: 0.00002648
Iteration 50/1000 | Loss: 0.00002648
Iteration 51/1000 | Loss: 0.00002648
Iteration 52/1000 | Loss: 0.00002648
Iteration 53/1000 | Loss: 0.00002648
Iteration 54/1000 | Loss: 0.00002647
Iteration 55/1000 | Loss: 0.00002647
Iteration 56/1000 | Loss: 0.00002646
Iteration 57/1000 | Loss: 0.00002645
Iteration 58/1000 | Loss: 0.00002645
Iteration 59/1000 | Loss: 0.00002645
Iteration 60/1000 | Loss: 0.00002645
Iteration 61/1000 | Loss: 0.00002645
Iteration 62/1000 | Loss: 0.00002645
Iteration 63/1000 | Loss: 0.00002644
Iteration 64/1000 | Loss: 0.00002644
Iteration 65/1000 | Loss: 0.00002644
Iteration 66/1000 | Loss: 0.00002644
Iteration 67/1000 | Loss: 0.00002644
Iteration 68/1000 | Loss: 0.00002644
Iteration 69/1000 | Loss: 0.00002644
Iteration 70/1000 | Loss: 0.00002644
Iteration 71/1000 | Loss: 0.00002643
Iteration 72/1000 | Loss: 0.00002642
Iteration 73/1000 | Loss: 0.00002642
Iteration 74/1000 | Loss: 0.00002642
Iteration 75/1000 | Loss: 0.00002642
Iteration 76/1000 | Loss: 0.00002641
Iteration 77/1000 | Loss: 0.00002641
Iteration 78/1000 | Loss: 0.00002641
Iteration 79/1000 | Loss: 0.00002641
Iteration 80/1000 | Loss: 0.00002640
Iteration 81/1000 | Loss: 0.00002640
Iteration 82/1000 | Loss: 0.00002640
Iteration 83/1000 | Loss: 0.00002640
Iteration 84/1000 | Loss: 0.00002639
Iteration 85/1000 | Loss: 0.00002639
Iteration 86/1000 | Loss: 0.00002639
Iteration 87/1000 | Loss: 0.00002639
Iteration 88/1000 | Loss: 0.00002638
Iteration 89/1000 | Loss: 0.00002638
Iteration 90/1000 | Loss: 0.00002638
Iteration 91/1000 | Loss: 0.00002638
Iteration 92/1000 | Loss: 0.00002638
Iteration 93/1000 | Loss: 0.00002638
Iteration 94/1000 | Loss: 0.00002638
Iteration 95/1000 | Loss: 0.00002637
Iteration 96/1000 | Loss: 0.00002637
Iteration 97/1000 | Loss: 0.00002637
Iteration 98/1000 | Loss: 0.00002637
Iteration 99/1000 | Loss: 0.00002637
Iteration 100/1000 | Loss: 0.00002637
Iteration 101/1000 | Loss: 0.00002637
Iteration 102/1000 | Loss: 0.00002637
Iteration 103/1000 | Loss: 0.00002637
Iteration 104/1000 | Loss: 0.00002636
Iteration 105/1000 | Loss: 0.00002636
Iteration 106/1000 | Loss: 0.00002636
Iteration 107/1000 | Loss: 0.00002636
Iteration 108/1000 | Loss: 0.00002636
Iteration 109/1000 | Loss: 0.00002636
Iteration 110/1000 | Loss: 0.00002636
Iteration 111/1000 | Loss: 0.00002636
Iteration 112/1000 | Loss: 0.00002636
Iteration 113/1000 | Loss: 0.00002636
Iteration 114/1000 | Loss: 0.00002635
Iteration 115/1000 | Loss: 0.00002635
Iteration 116/1000 | Loss: 0.00002635
Iteration 117/1000 | Loss: 0.00002635
Iteration 118/1000 | Loss: 0.00002635
Iteration 119/1000 | Loss: 0.00002635
Iteration 120/1000 | Loss: 0.00002635
Iteration 121/1000 | Loss: 0.00002635
Iteration 122/1000 | Loss: 0.00002635
Iteration 123/1000 | Loss: 0.00002635
Iteration 124/1000 | Loss: 0.00002635
Iteration 125/1000 | Loss: 0.00002635
Iteration 126/1000 | Loss: 0.00002635
Iteration 127/1000 | Loss: 0.00002635
Iteration 128/1000 | Loss: 0.00002634
Iteration 129/1000 | Loss: 0.00002634
Iteration 130/1000 | Loss: 0.00002634
Iteration 131/1000 | Loss: 0.00002634
Iteration 132/1000 | Loss: 0.00002634
Iteration 133/1000 | Loss: 0.00002634
Iteration 134/1000 | Loss: 0.00002634
Iteration 135/1000 | Loss: 0.00002634
Iteration 136/1000 | Loss: 0.00002634
Iteration 137/1000 | Loss: 0.00002634
Iteration 138/1000 | Loss: 0.00002634
Iteration 139/1000 | Loss: 0.00002634
Iteration 140/1000 | Loss: 0.00002634
Iteration 141/1000 | Loss: 0.00002634
Iteration 142/1000 | Loss: 0.00002634
Iteration 143/1000 | Loss: 0.00002634
Iteration 144/1000 | Loss: 0.00002633
Iteration 145/1000 | Loss: 0.00002633
Iteration 146/1000 | Loss: 0.00002633
Iteration 147/1000 | Loss: 0.00002633
Iteration 148/1000 | Loss: 0.00002633
Iteration 149/1000 | Loss: 0.00002633
Iteration 150/1000 | Loss: 0.00002633
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [2.6334950234740973e-05, 2.6334950234740973e-05, 2.6334950234740973e-05, 2.6334950234740973e-05, 2.6334950234740973e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6334950234740973e-05

Optimization complete. Final v2v error: 4.187767505645752 mm

Highest mean error: 4.551314830780029 mm for frame 77

Lowest mean error: 3.324007034301758 mm for frame 0

Saving results

Total time: 42.613765001297
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1076/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1076.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1076
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00951850
Iteration 2/25 | Loss: 0.00194366
Iteration 3/25 | Loss: 0.00147620
Iteration 4/25 | Loss: 0.00144852
Iteration 5/25 | Loss: 0.00142531
Iteration 6/25 | Loss: 0.00140821
Iteration 7/25 | Loss: 0.00140045
Iteration 8/25 | Loss: 0.00138475
Iteration 9/25 | Loss: 0.00139981
Iteration 10/25 | Loss: 0.00136401
Iteration 11/25 | Loss: 0.00136204
Iteration 12/25 | Loss: 0.00135327
Iteration 13/25 | Loss: 0.00135235
Iteration 14/25 | Loss: 0.00135196
Iteration 15/25 | Loss: 0.00135126
Iteration 16/25 | Loss: 0.00135119
Iteration 17/25 | Loss: 0.00135119
Iteration 18/25 | Loss: 0.00135119
Iteration 19/25 | Loss: 0.00135119
Iteration 20/25 | Loss: 0.00135119
Iteration 21/25 | Loss: 0.00135118
Iteration 22/25 | Loss: 0.00135118
Iteration 23/25 | Loss: 0.00135118
Iteration 24/25 | Loss: 0.00135118
Iteration 25/25 | Loss: 0.00135118

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.75531721
Iteration 2/25 | Loss: 0.00176764
Iteration 3/25 | Loss: 0.00173338
Iteration 4/25 | Loss: 0.00173338
Iteration 5/25 | Loss: 0.00173338
Iteration 6/25 | Loss: 0.00173337
Iteration 7/25 | Loss: 0.00173337
Iteration 8/25 | Loss: 0.00173337
Iteration 9/25 | Loss: 0.00173337
Iteration 10/25 | Loss: 0.00173337
Iteration 11/25 | Loss: 0.00173337
Iteration 12/25 | Loss: 0.00173337
Iteration 13/25 | Loss: 0.00173337
Iteration 14/25 | Loss: 0.00173337
Iteration 15/25 | Loss: 0.00173337
Iteration 16/25 | Loss: 0.00173337
Iteration 17/25 | Loss: 0.00173337
Iteration 18/25 | Loss: 0.00173337
Iteration 19/25 | Loss: 0.00173337
Iteration 20/25 | Loss: 0.00173337
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.001733373268507421, 0.001733373268507421, 0.001733373268507421, 0.001733373268507421, 0.001733373268507421]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001733373268507421

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00173337
Iteration 2/1000 | Loss: 0.00008032
Iteration 3/1000 | Loss: 0.00002110
Iteration 4/1000 | Loss: 0.00003361
Iteration 5/1000 | Loss: 0.00002827
Iteration 6/1000 | Loss: 0.00003505
Iteration 7/1000 | Loss: 0.00003116
Iteration 8/1000 | Loss: 0.00001759
Iteration 9/1000 | Loss: 0.00002747
Iteration 10/1000 | Loss: 0.00002292
Iteration 11/1000 | Loss: 0.00002516
Iteration 12/1000 | Loss: 0.00001673
Iteration 13/1000 | Loss: 0.00002608
Iteration 14/1000 | Loss: 0.00001671
Iteration 15/1000 | Loss: 0.00001603
Iteration 16/1000 | Loss: 0.00003918
Iteration 17/1000 | Loss: 0.00003975
Iteration 18/1000 | Loss: 0.00001728
Iteration 19/1000 | Loss: 0.00002087
Iteration 20/1000 | Loss: 0.00001586
Iteration 21/1000 | Loss: 0.00001561
Iteration 22/1000 | Loss: 0.00001549
Iteration 23/1000 | Loss: 0.00001549
Iteration 24/1000 | Loss: 0.00001548
Iteration 25/1000 | Loss: 0.00001548
Iteration 26/1000 | Loss: 0.00001548
Iteration 27/1000 | Loss: 0.00001548
Iteration 28/1000 | Loss: 0.00001548
Iteration 29/1000 | Loss: 0.00001547
Iteration 30/1000 | Loss: 0.00001546
Iteration 31/1000 | Loss: 0.00002051
Iteration 32/1000 | Loss: 0.00001682
Iteration 33/1000 | Loss: 0.00001537
Iteration 34/1000 | Loss: 0.00001537
Iteration 35/1000 | Loss: 0.00001534
Iteration 36/1000 | Loss: 0.00001534
Iteration 37/1000 | Loss: 0.00001531
Iteration 38/1000 | Loss: 0.00001529
Iteration 39/1000 | Loss: 0.00001529
Iteration 40/1000 | Loss: 0.00001528
Iteration 41/1000 | Loss: 0.00001527
Iteration 42/1000 | Loss: 0.00001527
Iteration 43/1000 | Loss: 0.00001527
Iteration 44/1000 | Loss: 0.00001525
Iteration 45/1000 | Loss: 0.00001525
Iteration 46/1000 | Loss: 0.00003352
Iteration 47/1000 | Loss: 0.00004242
Iteration 48/1000 | Loss: 0.00001931
Iteration 49/1000 | Loss: 0.00001516
Iteration 50/1000 | Loss: 0.00001516
Iteration 51/1000 | Loss: 0.00001516
Iteration 52/1000 | Loss: 0.00001516
Iteration 53/1000 | Loss: 0.00001516
Iteration 54/1000 | Loss: 0.00001516
Iteration 55/1000 | Loss: 0.00001516
Iteration 56/1000 | Loss: 0.00001516
Iteration 57/1000 | Loss: 0.00001516
Iteration 58/1000 | Loss: 0.00001516
Iteration 59/1000 | Loss: 0.00001516
Iteration 60/1000 | Loss: 0.00001516
Iteration 61/1000 | Loss: 0.00001516
Iteration 62/1000 | Loss: 0.00001515
Iteration 63/1000 | Loss: 0.00001515
Iteration 64/1000 | Loss: 0.00002509
Iteration 65/1000 | Loss: 0.00001518
Iteration 66/1000 | Loss: 0.00001517
Iteration 67/1000 | Loss: 0.00001866
Iteration 68/1000 | Loss: 0.00001515
Iteration 69/1000 | Loss: 0.00002389
Iteration 70/1000 | Loss: 0.00002190
Iteration 71/1000 | Loss: 0.00001512
Iteration 72/1000 | Loss: 0.00001512
Iteration 73/1000 | Loss: 0.00001512
Iteration 74/1000 | Loss: 0.00001893
Iteration 75/1000 | Loss: 0.00001615
Iteration 76/1000 | Loss: 0.00001509
Iteration 77/1000 | Loss: 0.00001508
Iteration 78/1000 | Loss: 0.00001508
Iteration 79/1000 | Loss: 0.00001508
Iteration 80/1000 | Loss: 0.00001508
Iteration 81/1000 | Loss: 0.00001508
Iteration 82/1000 | Loss: 0.00001508
Iteration 83/1000 | Loss: 0.00001508
Iteration 84/1000 | Loss: 0.00001508
Iteration 85/1000 | Loss: 0.00001508
Iteration 86/1000 | Loss: 0.00001508
Iteration 87/1000 | Loss: 0.00001508
Iteration 88/1000 | Loss: 0.00001508
Iteration 89/1000 | Loss: 0.00001508
Iteration 90/1000 | Loss: 0.00001507
Iteration 91/1000 | Loss: 0.00001507
Iteration 92/1000 | Loss: 0.00001507
Iteration 93/1000 | Loss: 0.00001507
Iteration 94/1000 | Loss: 0.00001507
Iteration 95/1000 | Loss: 0.00001507
Iteration 96/1000 | Loss: 0.00001507
Iteration 97/1000 | Loss: 0.00001507
Iteration 98/1000 | Loss: 0.00001507
Iteration 99/1000 | Loss: 0.00001507
Iteration 100/1000 | Loss: 0.00001507
Iteration 101/1000 | Loss: 0.00001507
Iteration 102/1000 | Loss: 0.00001507
Iteration 103/1000 | Loss: 0.00001507
Iteration 104/1000 | Loss: 0.00001507
Iteration 105/1000 | Loss: 0.00001506
Iteration 106/1000 | Loss: 0.00001506
Iteration 107/1000 | Loss: 0.00001506
Iteration 108/1000 | Loss: 0.00001506
Iteration 109/1000 | Loss: 0.00001506
Iteration 110/1000 | Loss: 0.00001506
Iteration 111/1000 | Loss: 0.00001506
Iteration 112/1000 | Loss: 0.00001505
Iteration 113/1000 | Loss: 0.00001505
Iteration 114/1000 | Loss: 0.00002421
Iteration 115/1000 | Loss: 0.00001506
Iteration 116/1000 | Loss: 0.00001506
Iteration 117/1000 | Loss: 0.00001504
Iteration 118/1000 | Loss: 0.00001503
Iteration 119/1000 | Loss: 0.00001503
Iteration 120/1000 | Loss: 0.00001503
Iteration 121/1000 | Loss: 0.00001503
Iteration 122/1000 | Loss: 0.00001502
Iteration 123/1000 | Loss: 0.00001502
Iteration 124/1000 | Loss: 0.00001502
Iteration 125/1000 | Loss: 0.00001502
Iteration 126/1000 | Loss: 0.00001502
Iteration 127/1000 | Loss: 0.00001502
Iteration 128/1000 | Loss: 0.00001502
Iteration 129/1000 | Loss: 0.00001502
Iteration 130/1000 | Loss: 0.00001502
Iteration 131/1000 | Loss: 0.00001501
Iteration 132/1000 | Loss: 0.00001501
Iteration 133/1000 | Loss: 0.00001500
Iteration 134/1000 | Loss: 0.00001500
Iteration 135/1000 | Loss: 0.00001500
Iteration 136/1000 | Loss: 0.00001500
Iteration 137/1000 | Loss: 0.00001500
Iteration 138/1000 | Loss: 0.00001500
Iteration 139/1000 | Loss: 0.00001499
Iteration 140/1000 | Loss: 0.00001499
Iteration 141/1000 | Loss: 0.00001499
Iteration 142/1000 | Loss: 0.00001499
Iteration 143/1000 | Loss: 0.00001499
Iteration 144/1000 | Loss: 0.00001499
Iteration 145/1000 | Loss: 0.00001499
Iteration 146/1000 | Loss: 0.00001499
Iteration 147/1000 | Loss: 0.00001499
Iteration 148/1000 | Loss: 0.00001499
Iteration 149/1000 | Loss: 0.00001499
Iteration 150/1000 | Loss: 0.00001499
Iteration 151/1000 | Loss: 0.00001499
Iteration 152/1000 | Loss: 0.00001499
Iteration 153/1000 | Loss: 0.00001499
Iteration 154/1000 | Loss: 0.00001499
Iteration 155/1000 | Loss: 0.00001499
Iteration 156/1000 | Loss: 0.00001499
Iteration 157/1000 | Loss: 0.00001499
Iteration 158/1000 | Loss: 0.00001499
Iteration 159/1000 | Loss: 0.00001499
Iteration 160/1000 | Loss: 0.00001499
Iteration 161/1000 | Loss: 0.00001499
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 161. Stopping optimization.
Last 5 losses: [1.4986419955675956e-05, 1.4986419955675956e-05, 1.4986419955675956e-05, 1.4986419955675956e-05, 1.4986419955675956e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4986419955675956e-05

Optimization complete. Final v2v error: 3.3177151679992676 mm

Highest mean error: 3.722106456756592 mm for frame 191

Lowest mean error: 2.9448561668395996 mm for frame 145

Saving results

Total time: 93.69369626045227
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1075/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1075.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1075
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00887343
Iteration 2/25 | Loss: 0.00186011
Iteration 3/25 | Loss: 0.00159134
Iteration 4/25 | Loss: 0.00156917
Iteration 5/25 | Loss: 0.00154540
Iteration 6/25 | Loss: 0.00153283
Iteration 7/25 | Loss: 0.00152729
Iteration 8/25 | Loss: 0.00152779
Iteration 9/25 | Loss: 0.00153312
Iteration 10/25 | Loss: 0.00152822
Iteration 11/25 | Loss: 0.00151514
Iteration 12/25 | Loss: 0.00149903
Iteration 13/25 | Loss: 0.00149081
Iteration 14/25 | Loss: 0.00148813
Iteration 15/25 | Loss: 0.00148925
Iteration 16/25 | Loss: 0.00148844
Iteration 17/25 | Loss: 0.00148651
Iteration 18/25 | Loss: 0.00148292
Iteration 19/25 | Loss: 0.00148640
Iteration 20/25 | Loss: 0.00148541
Iteration 21/25 | Loss: 0.00148967
Iteration 22/25 | Loss: 0.00148203
Iteration 23/25 | Loss: 0.00147511
Iteration 24/25 | Loss: 0.00147393
Iteration 25/25 | Loss: 0.00147325

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.25409293
Iteration 2/25 | Loss: 0.00208266
Iteration 3/25 | Loss: 0.00208238
Iteration 4/25 | Loss: 0.00208238
Iteration 5/25 | Loss: 0.00208238
Iteration 6/25 | Loss: 0.00208238
Iteration 7/25 | Loss: 0.00208238
Iteration 8/25 | Loss: 0.00208238
Iteration 9/25 | Loss: 0.00208238
Iteration 10/25 | Loss: 0.00208238
Iteration 11/25 | Loss: 0.00208237
Iteration 12/25 | Loss: 0.00208237
Iteration 13/25 | Loss: 0.00208237
Iteration 14/25 | Loss: 0.00208237
Iteration 15/25 | Loss: 0.00208237
Iteration 16/25 | Loss: 0.00208237
Iteration 17/25 | Loss: 0.00208237
Iteration 18/25 | Loss: 0.00208237
Iteration 19/25 | Loss: 0.00208237
Iteration 20/25 | Loss: 0.00208237
Iteration 21/25 | Loss: 0.00208237
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.002082374645397067, 0.002082374645397067, 0.002082374645397067, 0.002082374645397067, 0.002082374645397067]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002082374645397067

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00208237
Iteration 2/1000 | Loss: 0.00354801
Iteration 3/1000 | Loss: 0.00760986
Iteration 4/1000 | Loss: 0.00117815
Iteration 5/1000 | Loss: 0.00067618
Iteration 6/1000 | Loss: 0.00430786
Iteration 7/1000 | Loss: 0.00181498
Iteration 8/1000 | Loss: 0.00310548
Iteration 9/1000 | Loss: 0.00056454
Iteration 10/1000 | Loss: 0.00318960
Iteration 11/1000 | Loss: 0.00024754
Iteration 12/1000 | Loss: 0.00030186
Iteration 13/1000 | Loss: 0.00238302
Iteration 14/1000 | Loss: 0.00096217
Iteration 15/1000 | Loss: 0.00006784
Iteration 16/1000 | Loss: 0.00005857
Iteration 17/1000 | Loss: 0.00017350
Iteration 18/1000 | Loss: 0.00005264
Iteration 19/1000 | Loss: 0.00034605
Iteration 20/1000 | Loss: 0.00023853
Iteration 21/1000 | Loss: 0.00021039
Iteration 22/1000 | Loss: 0.00008611
Iteration 23/1000 | Loss: 0.00006122
Iteration 24/1000 | Loss: 0.00217695
Iteration 25/1000 | Loss: 0.00204169
Iteration 26/1000 | Loss: 0.00023699
Iteration 27/1000 | Loss: 0.00218681
Iteration 28/1000 | Loss: 0.00037173
Iteration 29/1000 | Loss: 0.00106597
Iteration 30/1000 | Loss: 0.00033651
Iteration 31/1000 | Loss: 0.00023283
Iteration 32/1000 | Loss: 0.00012831
Iteration 33/1000 | Loss: 0.00006116
Iteration 34/1000 | Loss: 0.00005309
Iteration 35/1000 | Loss: 0.00223642
Iteration 36/1000 | Loss: 0.00079833
Iteration 37/1000 | Loss: 0.00018022
Iteration 38/1000 | Loss: 0.00055754
Iteration 39/1000 | Loss: 0.00155037
Iteration 40/1000 | Loss: 0.00028828
Iteration 41/1000 | Loss: 0.00201263
Iteration 42/1000 | Loss: 0.00023955
Iteration 43/1000 | Loss: 0.00079805
Iteration 44/1000 | Loss: 0.00273833
Iteration 45/1000 | Loss: 0.00215994
Iteration 46/1000 | Loss: 0.00103960
Iteration 47/1000 | Loss: 0.00186077
Iteration 48/1000 | Loss: 0.00287970
Iteration 49/1000 | Loss: 0.00205483
Iteration 50/1000 | Loss: 0.00176746
Iteration 51/1000 | Loss: 0.00111086
Iteration 52/1000 | Loss: 0.00186909
Iteration 53/1000 | Loss: 0.00268814
Iteration 54/1000 | Loss: 0.00288372
Iteration 55/1000 | Loss: 0.00292249
Iteration 56/1000 | Loss: 0.00012781
Iteration 57/1000 | Loss: 0.00029363
Iteration 58/1000 | Loss: 0.00028025
Iteration 59/1000 | Loss: 0.00028694
Iteration 60/1000 | Loss: 0.00046448
Iteration 61/1000 | Loss: 0.00031818
Iteration 62/1000 | Loss: 0.00020954
Iteration 63/1000 | Loss: 0.00015292
Iteration 64/1000 | Loss: 0.00022301
Iteration 65/1000 | Loss: 0.00026113
Iteration 66/1000 | Loss: 0.00013043
Iteration 67/1000 | Loss: 0.00009853
Iteration 68/1000 | Loss: 0.00009323
Iteration 69/1000 | Loss: 0.00013347
Iteration 70/1000 | Loss: 0.00007343
Iteration 71/1000 | Loss: 0.00013199
Iteration 72/1000 | Loss: 0.00019207
Iteration 73/1000 | Loss: 0.00081923
Iteration 74/1000 | Loss: 0.00046504
Iteration 75/1000 | Loss: 0.00013917
Iteration 76/1000 | Loss: 0.00034145
Iteration 77/1000 | Loss: 0.00005691
Iteration 78/1000 | Loss: 0.00014598
Iteration 79/1000 | Loss: 0.00011795
Iteration 80/1000 | Loss: 0.00260712
Iteration 81/1000 | Loss: 0.00099617
Iteration 82/1000 | Loss: 0.00028164
Iteration 83/1000 | Loss: 0.00045071
Iteration 84/1000 | Loss: 0.00020516
Iteration 85/1000 | Loss: 0.00054707
Iteration 86/1000 | Loss: 0.00007638
Iteration 87/1000 | Loss: 0.00006261
Iteration 88/1000 | Loss: 0.00004493
Iteration 89/1000 | Loss: 0.00004332
Iteration 90/1000 | Loss: 0.00004207
Iteration 91/1000 | Loss: 0.00290931
Iteration 92/1000 | Loss: 0.00317260
Iteration 93/1000 | Loss: 0.00246198
Iteration 94/1000 | Loss: 0.00115050
Iteration 95/1000 | Loss: 0.00199679
Iteration 96/1000 | Loss: 0.00249642
Iteration 97/1000 | Loss: 0.00014117
Iteration 98/1000 | Loss: 0.00005168
Iteration 99/1000 | Loss: 0.00004721
Iteration 100/1000 | Loss: 0.00004509
Iteration 101/1000 | Loss: 0.00014988
Iteration 102/1000 | Loss: 0.00008113
Iteration 103/1000 | Loss: 0.00014139
Iteration 104/1000 | Loss: 0.00009780
Iteration 105/1000 | Loss: 0.00013852
Iteration 106/1000 | Loss: 0.00012175
Iteration 107/1000 | Loss: 0.00030577
Iteration 108/1000 | Loss: 0.00095673
Iteration 109/1000 | Loss: 0.00252612
Iteration 110/1000 | Loss: 0.00123624
Iteration 111/1000 | Loss: 0.00227169
Iteration 112/1000 | Loss: 0.00131367
Iteration 113/1000 | Loss: 0.00122169
Iteration 114/1000 | Loss: 0.00130294
Iteration 115/1000 | Loss: 0.00088429
Iteration 116/1000 | Loss: 0.00117454
Iteration 117/1000 | Loss: 0.00176822
Iteration 118/1000 | Loss: 0.00275781
Iteration 119/1000 | Loss: 0.00189897
Iteration 120/1000 | Loss: 0.00008352
Iteration 121/1000 | Loss: 0.00010584
Iteration 122/1000 | Loss: 0.00006287
Iteration 123/1000 | Loss: 0.00073572
Iteration 124/1000 | Loss: 0.00131771
Iteration 125/1000 | Loss: 0.00156266
Iteration 126/1000 | Loss: 0.00092343
Iteration 127/1000 | Loss: 0.00080926
Iteration 128/1000 | Loss: 0.00005736
Iteration 129/1000 | Loss: 0.00006188
Iteration 130/1000 | Loss: 0.00005801
Iteration 131/1000 | Loss: 0.00005181
Iteration 132/1000 | Loss: 0.00005143
Iteration 133/1000 | Loss: 0.00004645
Iteration 134/1000 | Loss: 0.00004327
Iteration 135/1000 | Loss: 0.00018453
Iteration 136/1000 | Loss: 0.00007754
Iteration 137/1000 | Loss: 0.00004424
Iteration 138/1000 | Loss: 0.00018577
Iteration 139/1000 | Loss: 0.00143079
Iteration 140/1000 | Loss: 0.00043031
Iteration 141/1000 | Loss: 0.00135533
Iteration 142/1000 | Loss: 0.00038695
Iteration 143/1000 | Loss: 0.00059203
Iteration 144/1000 | Loss: 0.00009709
Iteration 145/1000 | Loss: 0.00004917
Iteration 146/1000 | Loss: 0.00148491
Iteration 147/1000 | Loss: 0.00026845
Iteration 148/1000 | Loss: 0.00218284
Iteration 149/1000 | Loss: 0.00031845
Iteration 150/1000 | Loss: 0.00024983
Iteration 151/1000 | Loss: 0.00029453
Iteration 152/1000 | Loss: 0.00022727
Iteration 153/1000 | Loss: 0.00004325
Iteration 154/1000 | Loss: 0.00023011
Iteration 155/1000 | Loss: 0.00021758
Iteration 156/1000 | Loss: 0.00010590
Iteration 157/1000 | Loss: 0.00018933
Iteration 158/1000 | Loss: 0.00009695
Iteration 159/1000 | Loss: 0.00016953
Iteration 160/1000 | Loss: 0.00010285
Iteration 161/1000 | Loss: 0.00015633
Iteration 162/1000 | Loss: 0.00012107
Iteration 163/1000 | Loss: 0.00015131
Iteration 164/1000 | Loss: 0.00034760
Iteration 165/1000 | Loss: 0.00014809
Iteration 166/1000 | Loss: 0.00029200
Iteration 167/1000 | Loss: 0.00037383
Iteration 168/1000 | Loss: 0.00007143
Iteration 169/1000 | Loss: 0.00038362
Iteration 170/1000 | Loss: 0.00010521
Iteration 171/1000 | Loss: 0.00125252
Iteration 172/1000 | Loss: 0.00218133
Iteration 173/1000 | Loss: 0.00181732
Iteration 174/1000 | Loss: 0.00030516
Iteration 175/1000 | Loss: 0.00063137
Iteration 176/1000 | Loss: 0.00021200
Iteration 177/1000 | Loss: 0.00019100
Iteration 178/1000 | Loss: 0.00032731
Iteration 179/1000 | Loss: 0.00322403
Iteration 180/1000 | Loss: 0.00305644
Iteration 181/1000 | Loss: 0.00037633
Iteration 182/1000 | Loss: 0.00044643
Iteration 183/1000 | Loss: 0.00020298
Iteration 184/1000 | Loss: 0.00004984
Iteration 185/1000 | Loss: 0.00012079
Iteration 186/1000 | Loss: 0.00004731
Iteration 187/1000 | Loss: 0.00015840
Iteration 188/1000 | Loss: 0.00005079
Iteration 189/1000 | Loss: 0.00017595
Iteration 190/1000 | Loss: 0.00016285
Iteration 191/1000 | Loss: 0.00004114
Iteration 192/1000 | Loss: 0.00010240
Iteration 193/1000 | Loss: 0.00004874
Iteration 194/1000 | Loss: 0.00021292
Iteration 195/1000 | Loss: 0.00020204
Iteration 196/1000 | Loss: 0.00003676
Iteration 197/1000 | Loss: 0.00003462
Iteration 198/1000 | Loss: 0.00003365
Iteration 199/1000 | Loss: 0.00017715
Iteration 200/1000 | Loss: 0.00015407
Iteration 201/1000 | Loss: 0.00011155
Iteration 202/1000 | Loss: 0.00019630
Iteration 203/1000 | Loss: 0.00005636
Iteration 204/1000 | Loss: 0.00028509
Iteration 205/1000 | Loss: 0.00003729
Iteration 206/1000 | Loss: 0.00003892
Iteration 207/1000 | Loss: 0.00027048
Iteration 208/1000 | Loss: 0.00015660
Iteration 209/1000 | Loss: 0.00013917
Iteration 210/1000 | Loss: 0.00003613
Iteration 211/1000 | Loss: 0.00010939
Iteration 212/1000 | Loss: 0.00007967
Iteration 213/1000 | Loss: 0.00003189
Iteration 214/1000 | Loss: 0.00003075
Iteration 215/1000 | Loss: 0.00003004
Iteration 216/1000 | Loss: 0.00002953
Iteration 217/1000 | Loss: 0.00002907
Iteration 218/1000 | Loss: 0.00024940
Iteration 219/1000 | Loss: 0.00014432
Iteration 220/1000 | Loss: 0.00006092
Iteration 221/1000 | Loss: 0.00003008
Iteration 222/1000 | Loss: 0.00002802
Iteration 223/1000 | Loss: 0.00002752
Iteration 224/1000 | Loss: 0.00002723
Iteration 225/1000 | Loss: 0.00002713
Iteration 226/1000 | Loss: 0.00002710
Iteration 227/1000 | Loss: 0.00002706
Iteration 228/1000 | Loss: 0.00002693
Iteration 229/1000 | Loss: 0.00002691
Iteration 230/1000 | Loss: 0.00013494
Iteration 231/1000 | Loss: 0.00018144
Iteration 232/1000 | Loss: 0.00020691
Iteration 233/1000 | Loss: 0.00004554
Iteration 234/1000 | Loss: 0.00002815
Iteration 235/1000 | Loss: 0.00002700
Iteration 236/1000 | Loss: 0.00002683
Iteration 237/1000 | Loss: 0.00002682
Iteration 238/1000 | Loss: 0.00002681
Iteration 239/1000 | Loss: 0.00002681
Iteration 240/1000 | Loss: 0.00002680
Iteration 241/1000 | Loss: 0.00002680
Iteration 242/1000 | Loss: 0.00002680
Iteration 243/1000 | Loss: 0.00002679
Iteration 244/1000 | Loss: 0.00002679
Iteration 245/1000 | Loss: 0.00002679
Iteration 246/1000 | Loss: 0.00002678
Iteration 247/1000 | Loss: 0.00002678
Iteration 248/1000 | Loss: 0.00013262
Iteration 249/1000 | Loss: 0.00004522
Iteration 250/1000 | Loss: 0.00002975
Iteration 251/1000 | Loss: 0.00002715
Iteration 252/1000 | Loss: 0.00002684
Iteration 253/1000 | Loss: 0.00015841
Iteration 254/1000 | Loss: 0.00004329
Iteration 255/1000 | Loss: 0.00002703
Iteration 256/1000 | Loss: 0.00014149
Iteration 257/1000 | Loss: 0.00009061
Iteration 258/1000 | Loss: 0.00004990
Iteration 259/1000 | Loss: 0.00016064
Iteration 260/1000 | Loss: 0.00004638
Iteration 261/1000 | Loss: 0.00028974
Iteration 262/1000 | Loss: 0.00016479
Iteration 263/1000 | Loss: 0.00007735
Iteration 264/1000 | Loss: 0.00005380
Iteration 265/1000 | Loss: 0.00002795
Iteration 266/1000 | Loss: 0.00002725
Iteration 267/1000 | Loss: 0.00002692
Iteration 268/1000 | Loss: 0.00011978
Iteration 269/1000 | Loss: 0.00017179
Iteration 270/1000 | Loss: 0.00011416
Iteration 271/1000 | Loss: 0.00010467
Iteration 272/1000 | Loss: 0.00011142
Iteration 273/1000 | Loss: 0.00005644
Iteration 274/1000 | Loss: 0.00007961
Iteration 275/1000 | Loss: 0.00005646
Iteration 276/1000 | Loss: 0.00017796
Iteration 277/1000 | Loss: 0.00029796
Iteration 278/1000 | Loss: 0.00015388
Iteration 279/1000 | Loss: 0.00011394
Iteration 280/1000 | Loss: 0.00002740
Iteration 281/1000 | Loss: 0.00002696
Iteration 282/1000 | Loss: 0.00002672
Iteration 283/1000 | Loss: 0.00002671
Iteration 284/1000 | Loss: 0.00002671
Iteration 285/1000 | Loss: 0.00002670
Iteration 286/1000 | Loss: 0.00002670
Iteration 287/1000 | Loss: 0.00002669
Iteration 288/1000 | Loss: 0.00002669
Iteration 289/1000 | Loss: 0.00002669
Iteration 290/1000 | Loss: 0.00002667
Iteration 291/1000 | Loss: 0.00002667
Iteration 292/1000 | Loss: 0.00002667
Iteration 293/1000 | Loss: 0.00002667
Iteration 294/1000 | Loss: 0.00002666
Iteration 295/1000 | Loss: 0.00002665
Iteration 296/1000 | Loss: 0.00002664
Iteration 297/1000 | Loss: 0.00002664
Iteration 298/1000 | Loss: 0.00002663
Iteration 299/1000 | Loss: 0.00002662
Iteration 300/1000 | Loss: 0.00002661
Iteration 301/1000 | Loss: 0.00002661
Iteration 302/1000 | Loss: 0.00002660
Iteration 303/1000 | Loss: 0.00002660
Iteration 304/1000 | Loss: 0.00002660
Iteration 305/1000 | Loss: 0.00002660
Iteration 306/1000 | Loss: 0.00002660
Iteration 307/1000 | Loss: 0.00002660
Iteration 308/1000 | Loss: 0.00002660
Iteration 309/1000 | Loss: 0.00002660
Iteration 310/1000 | Loss: 0.00002660
Iteration 311/1000 | Loss: 0.00002659
Iteration 312/1000 | Loss: 0.00002659
Iteration 313/1000 | Loss: 0.00002659
Iteration 314/1000 | Loss: 0.00002658
Iteration 315/1000 | Loss: 0.00002658
Iteration 316/1000 | Loss: 0.00002658
Iteration 317/1000 | Loss: 0.00002658
Iteration 318/1000 | Loss: 0.00002658
Iteration 319/1000 | Loss: 0.00002657
Iteration 320/1000 | Loss: 0.00002657
Iteration 321/1000 | Loss: 0.00002656
Iteration 322/1000 | Loss: 0.00002656
Iteration 323/1000 | Loss: 0.00002655
Iteration 324/1000 | Loss: 0.00013936
Iteration 325/1000 | Loss: 0.00004245
Iteration 326/1000 | Loss: 0.00005328
Iteration 327/1000 | Loss: 0.00003015
Iteration 328/1000 | Loss: 0.00002835
Iteration 329/1000 | Loss: 0.00002784
Iteration 330/1000 | Loss: 0.00002744
Iteration 331/1000 | Loss: 0.00002721
Iteration 332/1000 | Loss: 0.00002714
Iteration 333/1000 | Loss: 0.00002713
Iteration 334/1000 | Loss: 0.00002711
Iteration 335/1000 | Loss: 0.00002711
Iteration 336/1000 | Loss: 0.00002711
Iteration 337/1000 | Loss: 0.00002710
Iteration 338/1000 | Loss: 0.00002710
Iteration 339/1000 | Loss: 0.00002710
Iteration 340/1000 | Loss: 0.00002709
Iteration 341/1000 | Loss: 0.00002709
Iteration 342/1000 | Loss: 0.00002709
Iteration 343/1000 | Loss: 0.00002708
Iteration 344/1000 | Loss: 0.00002708
Iteration 345/1000 | Loss: 0.00002708
Iteration 346/1000 | Loss: 0.00002707
Iteration 347/1000 | Loss: 0.00002707
Iteration 348/1000 | Loss: 0.00002707
Iteration 349/1000 | Loss: 0.00002707
Iteration 350/1000 | Loss: 0.00002706
Iteration 351/1000 | Loss: 0.00002705
Iteration 352/1000 | Loss: 0.00002705
Iteration 353/1000 | Loss: 0.00002704
Iteration 354/1000 | Loss: 0.00002704
Iteration 355/1000 | Loss: 0.00002703
Iteration 356/1000 | Loss: 0.00002703
Iteration 357/1000 | Loss: 0.00002703
Iteration 358/1000 | Loss: 0.00002703
Iteration 359/1000 | Loss: 0.00002702
Iteration 360/1000 | Loss: 0.00002702
Iteration 361/1000 | Loss: 0.00002701
Iteration 362/1000 | Loss: 0.00002701
Iteration 363/1000 | Loss: 0.00002701
Iteration 364/1000 | Loss: 0.00002701
Iteration 365/1000 | Loss: 0.00002701
Iteration 366/1000 | Loss: 0.00002701
Iteration 367/1000 | Loss: 0.00002700
Iteration 368/1000 | Loss: 0.00002700
Iteration 369/1000 | Loss: 0.00002700
Iteration 370/1000 | Loss: 0.00002700
Iteration 371/1000 | Loss: 0.00002700
Iteration 372/1000 | Loss: 0.00002700
Iteration 373/1000 | Loss: 0.00002700
Iteration 374/1000 | Loss: 0.00002699
Iteration 375/1000 | Loss: 0.00002699
Iteration 376/1000 | Loss: 0.00002699
Iteration 377/1000 | Loss: 0.00002699
Iteration 378/1000 | Loss: 0.00002699
Iteration 379/1000 | Loss: 0.00002698
Iteration 380/1000 | Loss: 0.00002698
Iteration 381/1000 | Loss: 0.00002698
Iteration 382/1000 | Loss: 0.00002698
Iteration 383/1000 | Loss: 0.00002698
Iteration 384/1000 | Loss: 0.00002698
Iteration 385/1000 | Loss: 0.00002698
Iteration 386/1000 | Loss: 0.00002698
Iteration 387/1000 | Loss: 0.00002698
Iteration 388/1000 | Loss: 0.00002697
Iteration 389/1000 | Loss: 0.00002697
Iteration 390/1000 | Loss: 0.00002697
Iteration 391/1000 | Loss: 0.00002697
Iteration 392/1000 | Loss: 0.00002697
Iteration 393/1000 | Loss: 0.00002697
Iteration 394/1000 | Loss: 0.00002696
Iteration 395/1000 | Loss: 0.00002696
Iteration 396/1000 | Loss: 0.00002696
Iteration 397/1000 | Loss: 0.00002695
Iteration 398/1000 | Loss: 0.00002694
Iteration 399/1000 | Loss: 0.00002692
Iteration 400/1000 | Loss: 0.00002691
Iteration 401/1000 | Loss: 0.00002691
Iteration 402/1000 | Loss: 0.00002691
Iteration 403/1000 | Loss: 0.00002690
Iteration 404/1000 | Loss: 0.00002690
Iteration 405/1000 | Loss: 0.00002689
Iteration 406/1000 | Loss: 0.00002689
Iteration 407/1000 | Loss: 0.00002689
Iteration 408/1000 | Loss: 0.00002689
Iteration 409/1000 | Loss: 0.00002689
Iteration 410/1000 | Loss: 0.00002689
Iteration 411/1000 | Loss: 0.00002689
Iteration 412/1000 | Loss: 0.00002689
Iteration 413/1000 | Loss: 0.00002688
Iteration 414/1000 | Loss: 0.00002688
Iteration 415/1000 | Loss: 0.00002688
Iteration 416/1000 | Loss: 0.00002688
Iteration 417/1000 | Loss: 0.00002687
Iteration 418/1000 | Loss: 0.00002687
Iteration 419/1000 | Loss: 0.00002687
Iteration 420/1000 | Loss: 0.00002687
Iteration 421/1000 | Loss: 0.00002687
Iteration 422/1000 | Loss: 0.00002687
Iteration 423/1000 | Loss: 0.00002686
Iteration 424/1000 | Loss: 0.00002686
Iteration 425/1000 | Loss: 0.00002686
Iteration 426/1000 | Loss: 0.00002685
Iteration 427/1000 | Loss: 0.00002685
Iteration 428/1000 | Loss: 0.00002685
Iteration 429/1000 | Loss: 0.00002684
Iteration 430/1000 | Loss: 0.00004681
Iteration 431/1000 | Loss: 0.00004681
Iteration 432/1000 | Loss: 0.00003557
Iteration 433/1000 | Loss: 0.00002917
Iteration 434/1000 | Loss: 0.00015476
Iteration 435/1000 | Loss: 0.00010951
Iteration 436/1000 | Loss: 0.00021637
Iteration 437/1000 | Loss: 0.00015820
Iteration 438/1000 | Loss: 0.00015952
Iteration 439/1000 | Loss: 0.00016622
Iteration 440/1000 | Loss: 0.00007031
Iteration 441/1000 | Loss: 0.00007598
Iteration 442/1000 | Loss: 0.00016853
Iteration 443/1000 | Loss: 0.00012039
Iteration 444/1000 | Loss: 0.00013765
Iteration 445/1000 | Loss: 0.00005732
Iteration 446/1000 | Loss: 0.00002918
Iteration 447/1000 | Loss: 0.00010475
Iteration 448/1000 | Loss: 0.00005656
Iteration 449/1000 | Loss: 0.00006590
Iteration 450/1000 | Loss: 0.00005487
Iteration 451/1000 | Loss: 0.00006171
Iteration 452/1000 | Loss: 0.00005870
Iteration 453/1000 | Loss: 0.00005873
Iteration 454/1000 | Loss: 0.00005478
Iteration 455/1000 | Loss: 0.00004611
Iteration 456/1000 | Loss: 0.00005419
Iteration 457/1000 | Loss: 0.00006722
Iteration 458/1000 | Loss: 0.00004633
Iteration 459/1000 | Loss: 0.00004701
Iteration 460/1000 | Loss: 0.00004555
Iteration 461/1000 | Loss: 0.00005404
Iteration 462/1000 | Loss: 0.00004625
Iteration 463/1000 | Loss: 0.00004548
Iteration 464/1000 | Loss: 0.00004636
Iteration 465/1000 | Loss: 0.00022011
Iteration 466/1000 | Loss: 0.00015029
Iteration 467/1000 | Loss: 0.00014112
Iteration 468/1000 | Loss: 0.00013494
Iteration 469/1000 | Loss: 0.00010277
Iteration 470/1000 | Loss: 0.00016070
Iteration 471/1000 | Loss: 0.00011139
Iteration 472/1000 | Loss: 0.00012149
Iteration 473/1000 | Loss: 0.00007206
Iteration 474/1000 | Loss: 0.00003035
Iteration 475/1000 | Loss: 0.00002890
Iteration 476/1000 | Loss: 0.00002830
Iteration 477/1000 | Loss: 0.00020699
Iteration 478/1000 | Loss: 0.00016510
Iteration 479/1000 | Loss: 0.00005622
Iteration 480/1000 | Loss: 0.00009669
Iteration 481/1000 | Loss: 0.00015550
Iteration 482/1000 | Loss: 0.00013587
Iteration 483/1000 | Loss: 0.00010222
Iteration 484/1000 | Loss: 0.00010584
Iteration 485/1000 | Loss: 0.00012440
Iteration 486/1000 | Loss: 0.00011032
Iteration 487/1000 | Loss: 0.00016173
Iteration 488/1000 | Loss: 0.00010920
Iteration 489/1000 | Loss: 0.00014822
Iteration 490/1000 | Loss: 0.00003045
Iteration 491/1000 | Loss: 0.00010669
Iteration 492/1000 | Loss: 0.00015143
Iteration 493/1000 | Loss: 0.00011465
Iteration 494/1000 | Loss: 0.00019374
Iteration 495/1000 | Loss: 0.00012172
Iteration 496/1000 | Loss: 0.00013219
Iteration 497/1000 | Loss: 0.00017438
Iteration 498/1000 | Loss: 0.00013784
Iteration 499/1000 | Loss: 0.00004060
Iteration 500/1000 | Loss: 0.00012371
Iteration 501/1000 | Loss: 0.00013705
Iteration 502/1000 | Loss: 0.00013618
Iteration 503/1000 | Loss: 0.00020179
Iteration 504/1000 | Loss: 0.00013908
Iteration 505/1000 | Loss: 0.00020937
Iteration 506/1000 | Loss: 0.00018422
Iteration 507/1000 | Loss: 0.00016423
Iteration 508/1000 | Loss: 0.00014815
Iteration 509/1000 | Loss: 0.00022129
Iteration 510/1000 | Loss: 0.00016443
Iteration 511/1000 | Loss: 0.00017364
Iteration 512/1000 | Loss: 0.00013182
Iteration 513/1000 | Loss: 0.00020437
Iteration 514/1000 | Loss: 0.00019911
Iteration 515/1000 | Loss: 0.00013441
Iteration 516/1000 | Loss: 0.00020035
Iteration 517/1000 | Loss: 0.00011433
Iteration 518/1000 | Loss: 0.00017061
Iteration 519/1000 | Loss: 0.00008413
Iteration 520/1000 | Loss: 0.00003603
Iteration 521/1000 | Loss: 0.00004481
Iteration 522/1000 | Loss: 0.00003254
Iteration 523/1000 | Loss: 0.00003185
Iteration 524/1000 | Loss: 0.00003144
Iteration 525/1000 | Loss: 0.00003069
Iteration 526/1000 | Loss: 0.00003008
Iteration 527/1000 | Loss: 0.00009844
Iteration 528/1000 | Loss: 0.00003103
Iteration 529/1000 | Loss: 0.00012187
Iteration 530/1000 | Loss: 0.00011502
Iteration 531/1000 | Loss: 0.00026245
Iteration 532/1000 | Loss: 0.00023965
Iteration 533/1000 | Loss: 0.00022848
Iteration 534/1000 | Loss: 0.00007212
Iteration 535/1000 | Loss: 0.00004239
Iteration 536/1000 | Loss: 0.00003456
Iteration 537/1000 | Loss: 0.00003112
Iteration 538/1000 | Loss: 0.00002969
Iteration 539/1000 | Loss: 0.00002837
Iteration 540/1000 | Loss: 0.00002745
Iteration 541/1000 | Loss: 0.00002705
Iteration 542/1000 | Loss: 0.00002675
Iteration 543/1000 | Loss: 0.00002654
Iteration 544/1000 | Loss: 0.00002634
Iteration 545/1000 | Loss: 0.00002614
Iteration 546/1000 | Loss: 0.00002589
Iteration 547/1000 | Loss: 0.00002563
Iteration 548/1000 | Loss: 0.00002548
Iteration 549/1000 | Loss: 0.00002544
Iteration 550/1000 | Loss: 0.00002538
Iteration 551/1000 | Loss: 0.00002532
Iteration 552/1000 | Loss: 0.00002525
Iteration 553/1000 | Loss: 0.00002525
Iteration 554/1000 | Loss: 0.00002520
Iteration 555/1000 | Loss: 0.00002519
Iteration 556/1000 | Loss: 0.00002513
Iteration 557/1000 | Loss: 0.00002503
Iteration 558/1000 | Loss: 0.00002502
Iteration 559/1000 | Loss: 0.00002501
Iteration 560/1000 | Loss: 0.00002500
Iteration 561/1000 | Loss: 0.00002500
Iteration 562/1000 | Loss: 0.00002499
Iteration 563/1000 | Loss: 0.00002499
Iteration 564/1000 | Loss: 0.00002498
Iteration 565/1000 | Loss: 0.00002498
Iteration 566/1000 | Loss: 0.00002497
Iteration 567/1000 | Loss: 0.00002497
Iteration 568/1000 | Loss: 0.00002496
Iteration 569/1000 | Loss: 0.00002496
Iteration 570/1000 | Loss: 0.00002496
Iteration 571/1000 | Loss: 0.00002496
Iteration 572/1000 | Loss: 0.00002495
Iteration 573/1000 | Loss: 0.00002494
Iteration 574/1000 | Loss: 0.00002493
Iteration 575/1000 | Loss: 0.00002493
Iteration 576/1000 | Loss: 0.00002493
Iteration 577/1000 | Loss: 0.00002493
Iteration 578/1000 | Loss: 0.00002492
Iteration 579/1000 | Loss: 0.00002492
Iteration 580/1000 | Loss: 0.00002492
Iteration 581/1000 | Loss: 0.00002492
Iteration 582/1000 | Loss: 0.00002492
Iteration 583/1000 | Loss: 0.00002492
Iteration 584/1000 | Loss: 0.00002492
Iteration 585/1000 | Loss: 0.00002491
Iteration 586/1000 | Loss: 0.00002491
Iteration 587/1000 | Loss: 0.00002491
Iteration 588/1000 | Loss: 0.00002491
Iteration 589/1000 | Loss: 0.00002491
Iteration 590/1000 | Loss: 0.00002491
Iteration 591/1000 | Loss: 0.00002491
Iteration 592/1000 | Loss: 0.00002491
Iteration 593/1000 | Loss: 0.00002491
Iteration 594/1000 | Loss: 0.00002491
Iteration 595/1000 | Loss: 0.00002491
Iteration 596/1000 | Loss: 0.00002491
Iteration 597/1000 | Loss: 0.00002490
Iteration 598/1000 | Loss: 0.00002490
Iteration 599/1000 | Loss: 0.00002490
Iteration 600/1000 | Loss: 0.00002490
Iteration 601/1000 | Loss: 0.00002489
Iteration 602/1000 | Loss: 0.00002489
Iteration 603/1000 | Loss: 0.00002489
Iteration 604/1000 | Loss: 0.00002489
Iteration 605/1000 | Loss: 0.00002489
Iteration 606/1000 | Loss: 0.00002489
Iteration 607/1000 | Loss: 0.00002489
Iteration 608/1000 | Loss: 0.00002489
Iteration 609/1000 | Loss: 0.00002489
Iteration 610/1000 | Loss: 0.00002489
Iteration 611/1000 | Loss: 0.00002489
Iteration 612/1000 | Loss: 0.00002489
Iteration 613/1000 | Loss: 0.00002488
Iteration 614/1000 | Loss: 0.00002488
Iteration 615/1000 | Loss: 0.00002488
Iteration 616/1000 | Loss: 0.00002488
Iteration 617/1000 | Loss: 0.00002488
Iteration 618/1000 | Loss: 0.00002488
Iteration 619/1000 | Loss: 0.00002488
Iteration 620/1000 | Loss: 0.00002488
Iteration 621/1000 | Loss: 0.00002487
Iteration 622/1000 | Loss: 0.00002487
Iteration 623/1000 | Loss: 0.00002486
Iteration 624/1000 | Loss: 0.00002486
Iteration 625/1000 | Loss: 0.00002486
Iteration 626/1000 | Loss: 0.00002486
Iteration 627/1000 | Loss: 0.00002485
Iteration 628/1000 | Loss: 0.00002485
Iteration 629/1000 | Loss: 0.00002484
Iteration 630/1000 | Loss: 0.00002484
Iteration 631/1000 | Loss: 0.00002484
Iteration 632/1000 | Loss: 0.00002483
Iteration 633/1000 | Loss: 0.00002483
Iteration 634/1000 | Loss: 0.00002483
Iteration 635/1000 | Loss: 0.00002483
Iteration 636/1000 | Loss: 0.00002482
Iteration 637/1000 | Loss: 0.00002482
Iteration 638/1000 | Loss: 0.00002482
Iteration 639/1000 | Loss: 0.00002482
Iteration 640/1000 | Loss: 0.00002482
Iteration 641/1000 | Loss: 0.00002482
Iteration 642/1000 | Loss: 0.00002482
Iteration 643/1000 | Loss: 0.00002481
Iteration 644/1000 | Loss: 0.00002481
Iteration 645/1000 | Loss: 0.00002481
Iteration 646/1000 | Loss: 0.00002481
Iteration 647/1000 | Loss: 0.00002481
Iteration 648/1000 | Loss: 0.00002481
Iteration 649/1000 | Loss: 0.00002481
Iteration 650/1000 | Loss: 0.00002481
Iteration 651/1000 | Loss: 0.00002481
Iteration 652/1000 | Loss: 0.00002481
Iteration 653/1000 | Loss: 0.00002481
Iteration 654/1000 | Loss: 0.00002481
Iteration 655/1000 | Loss: 0.00002480
Iteration 656/1000 | Loss: 0.00002480
Iteration 657/1000 | Loss: 0.00002480
Iteration 658/1000 | Loss: 0.00002480
Iteration 659/1000 | Loss: 0.00002480
Iteration 660/1000 | Loss: 0.00002480
Iteration 661/1000 | Loss: 0.00002480
Iteration 662/1000 | Loss: 0.00002480
Iteration 663/1000 | Loss: 0.00002480
Iteration 664/1000 | Loss: 0.00002480
Iteration 665/1000 | Loss: 0.00002479
Iteration 666/1000 | Loss: 0.00002479
Iteration 667/1000 | Loss: 0.00002479
Iteration 668/1000 | Loss: 0.00002479
Iteration 669/1000 | Loss: 0.00002478
Iteration 670/1000 | Loss: 0.00002478
Iteration 671/1000 | Loss: 0.00002478
Iteration 672/1000 | Loss: 0.00002478
Iteration 673/1000 | Loss: 0.00002477
Iteration 674/1000 | Loss: 0.00002477
Iteration 675/1000 | Loss: 0.00002477
Iteration 676/1000 | Loss: 0.00002477
Iteration 677/1000 | Loss: 0.00002477
Iteration 678/1000 | Loss: 0.00002476
Iteration 679/1000 | Loss: 0.00002476
Iteration 680/1000 | Loss: 0.00002476
Iteration 681/1000 | Loss: 0.00002476
Iteration 682/1000 | Loss: 0.00002475
Iteration 683/1000 | Loss: 0.00002475
Iteration 684/1000 | Loss: 0.00002475
Iteration 685/1000 | Loss: 0.00002475
Iteration 686/1000 | Loss: 0.00002475
Iteration 687/1000 | Loss: 0.00002475
Iteration 688/1000 | Loss: 0.00002475
Iteration 689/1000 | Loss: 0.00002475
Iteration 690/1000 | Loss: 0.00002475
Iteration 691/1000 | Loss: 0.00002475
Iteration 692/1000 | Loss: 0.00002475
Iteration 693/1000 | Loss: 0.00002475
Iteration 694/1000 | Loss: 0.00002475
Iteration 695/1000 | Loss: 0.00002475
Iteration 696/1000 | Loss: 0.00002475
Iteration 697/1000 | Loss: 0.00002475
Iteration 698/1000 | Loss: 0.00002475
Iteration 699/1000 | Loss: 0.00002475
Iteration 700/1000 | Loss: 0.00002475
Iteration 701/1000 | Loss: 0.00002475
Iteration 702/1000 | Loss: 0.00002475
Iteration 703/1000 | Loss: 0.00002475
Iteration 704/1000 | Loss: 0.00002475
Iteration 705/1000 | Loss: 0.00002475
Iteration 706/1000 | Loss: 0.00002475
Iteration 707/1000 | Loss: 0.00002475
Iteration 708/1000 | Loss: 0.00002475
Iteration 709/1000 | Loss: 0.00002475
Iteration 710/1000 | Loss: 0.00002475
Iteration 711/1000 | Loss: 0.00002475
Iteration 712/1000 | Loss: 0.00002475
Iteration 713/1000 | Loss: 0.00002475
Iteration 714/1000 | Loss: 0.00002475
Iteration 715/1000 | Loss: 0.00002475
Iteration 716/1000 | Loss: 0.00002475
Iteration 717/1000 | Loss: 0.00002475
Iteration 718/1000 | Loss: 0.00002475
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 718. Stopping optimization.
Last 5 losses: [2.4748263967921957e-05, 2.4748263967921957e-05, 2.4748263967921957e-05, 2.4748263967921957e-05, 2.4748263967921957e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4748263967921957e-05

Optimization complete. Final v2v error: 4.16189432144165 mm

Highest mean error: 5.915792942047119 mm for frame 97

Lowest mean error: 3.1775922775268555 mm for frame 144

Saving results

Total time: 622.7381374835968
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1041/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1041.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1041
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00865594
Iteration 2/25 | Loss: 0.00380014
Iteration 3/25 | Loss: 0.00299267
Iteration 4/25 | Loss: 0.00260341
Iteration 5/25 | Loss: 0.00216612
Iteration 6/25 | Loss: 0.00208585
Iteration 7/25 | Loss: 0.00208198
Iteration 8/25 | Loss: 0.00198786
Iteration 9/25 | Loss: 0.00204408
Iteration 10/25 | Loss: 0.00216734
Iteration 11/25 | Loss: 0.00147766
Iteration 12/25 | Loss: 0.00144288
Iteration 13/25 | Loss: 0.00143652
Iteration 14/25 | Loss: 0.00143569
Iteration 15/25 | Loss: 0.00143533
Iteration 16/25 | Loss: 0.00143130
Iteration 17/25 | Loss: 0.00143019
Iteration 18/25 | Loss: 0.00142984
Iteration 19/25 | Loss: 0.00142968
Iteration 20/25 | Loss: 0.00142957
Iteration 21/25 | Loss: 0.00142946
Iteration 22/25 | Loss: 0.00142945
Iteration 23/25 | Loss: 0.00142945
Iteration 24/25 | Loss: 0.00142945
Iteration 25/25 | Loss: 0.00142944

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.23298895
Iteration 2/25 | Loss: 0.00131748
Iteration 3/25 | Loss: 0.00131748
Iteration 4/25 | Loss: 0.00131748
Iteration 5/25 | Loss: 0.00131748
Iteration 6/25 | Loss: 0.00131748
Iteration 7/25 | Loss: 0.00131748
Iteration 8/25 | Loss: 0.00131748
Iteration 9/25 | Loss: 0.00131747
Iteration 10/25 | Loss: 0.00131747
Iteration 11/25 | Loss: 0.00131747
Iteration 12/25 | Loss: 0.00131747
Iteration 13/25 | Loss: 0.00131747
Iteration 14/25 | Loss: 0.00131747
Iteration 15/25 | Loss: 0.00131747
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013174747582525015, 0.0013174747582525015, 0.0013174747582525015, 0.0013174747582525015, 0.0013174747582525015]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013174747582525015

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00131747
Iteration 2/1000 | Loss: 0.00002921
Iteration 3/1000 | Loss: 0.00002296
Iteration 4/1000 | Loss: 0.00002114
Iteration 5/1000 | Loss: 0.00002040
Iteration 6/1000 | Loss: 0.00001981
Iteration 7/1000 | Loss: 0.00001932
Iteration 8/1000 | Loss: 0.00001886
Iteration 9/1000 | Loss: 0.00001854
Iteration 10/1000 | Loss: 0.00001823
Iteration 11/1000 | Loss: 0.00001798
Iteration 12/1000 | Loss: 0.00001767
Iteration 13/1000 | Loss: 0.00001748
Iteration 14/1000 | Loss: 0.00001729
Iteration 15/1000 | Loss: 0.00001719
Iteration 16/1000 | Loss: 0.00001712
Iteration 17/1000 | Loss: 0.00001712
Iteration 18/1000 | Loss: 0.00001712
Iteration 19/1000 | Loss: 0.00001710
Iteration 20/1000 | Loss: 0.00001708
Iteration 21/1000 | Loss: 0.00001708
Iteration 22/1000 | Loss: 0.00001708
Iteration 23/1000 | Loss: 0.00001705
Iteration 24/1000 | Loss: 0.00001694
Iteration 25/1000 | Loss: 0.00001688
Iteration 26/1000 | Loss: 0.00001687
Iteration 27/1000 | Loss: 0.00001687
Iteration 28/1000 | Loss: 0.00001686
Iteration 29/1000 | Loss: 0.00001686
Iteration 30/1000 | Loss: 0.00001686
Iteration 31/1000 | Loss: 0.00001685
Iteration 32/1000 | Loss: 0.00001685
Iteration 33/1000 | Loss: 0.00001685
Iteration 34/1000 | Loss: 0.00001685
Iteration 35/1000 | Loss: 0.00001684
Iteration 36/1000 | Loss: 0.00001681
Iteration 37/1000 | Loss: 0.00001681
Iteration 38/1000 | Loss: 0.00001680
Iteration 39/1000 | Loss: 0.00001680
Iteration 40/1000 | Loss: 0.00001680
Iteration 41/1000 | Loss: 0.00001678
Iteration 42/1000 | Loss: 0.00001678
Iteration 43/1000 | Loss: 0.00001678
Iteration 44/1000 | Loss: 0.00001677
Iteration 45/1000 | Loss: 0.00001677
Iteration 46/1000 | Loss: 0.00001677
Iteration 47/1000 | Loss: 0.00001677
Iteration 48/1000 | Loss: 0.00001677
Iteration 49/1000 | Loss: 0.00001677
Iteration 50/1000 | Loss: 0.00001676
Iteration 51/1000 | Loss: 0.00001676
Iteration 52/1000 | Loss: 0.00001676
Iteration 53/1000 | Loss: 0.00001675
Iteration 54/1000 | Loss: 0.00001675
Iteration 55/1000 | Loss: 0.00001675
Iteration 56/1000 | Loss: 0.00001675
Iteration 57/1000 | Loss: 0.00001675
Iteration 58/1000 | Loss: 0.00001675
Iteration 59/1000 | Loss: 0.00001675
Iteration 60/1000 | Loss: 0.00001674
Iteration 61/1000 | Loss: 0.00001674
Iteration 62/1000 | Loss: 0.00001674
Iteration 63/1000 | Loss: 0.00001674
Iteration 64/1000 | Loss: 0.00001674
Iteration 65/1000 | Loss: 0.00001673
Iteration 66/1000 | Loss: 0.00001673
Iteration 67/1000 | Loss: 0.00001673
Iteration 68/1000 | Loss: 0.00001673
Iteration 69/1000 | Loss: 0.00017559
Iteration 70/1000 | Loss: 0.00017559
Iteration 71/1000 | Loss: 0.00017559
Iteration 72/1000 | Loss: 0.00017559
Iteration 73/1000 | Loss: 0.00017856
Iteration 74/1000 | Loss: 0.00004402
Iteration 75/1000 | Loss: 0.00002835
Iteration 76/1000 | Loss: 0.00002312
Iteration 77/1000 | Loss: 0.00002038
Iteration 78/1000 | Loss: 0.00002199
Iteration 79/1000 | Loss: 0.00002093
Iteration 80/1000 | Loss: 0.00001799
Iteration 81/1000 | Loss: 0.00001765
Iteration 82/1000 | Loss: 0.00001731
Iteration 83/1000 | Loss: 0.00001710
Iteration 84/1000 | Loss: 0.00001708
Iteration 85/1000 | Loss: 0.00001706
Iteration 86/1000 | Loss: 0.00001705
Iteration 87/1000 | Loss: 0.00001703
Iteration 88/1000 | Loss: 0.00001703
Iteration 89/1000 | Loss: 0.00001703
Iteration 90/1000 | Loss: 0.00001703
Iteration 91/1000 | Loss: 0.00001703
Iteration 92/1000 | Loss: 0.00001703
Iteration 93/1000 | Loss: 0.00001703
Iteration 94/1000 | Loss: 0.00001702
Iteration 95/1000 | Loss: 0.00001702
Iteration 96/1000 | Loss: 0.00001702
Iteration 97/1000 | Loss: 0.00001702
Iteration 98/1000 | Loss: 0.00001702
Iteration 99/1000 | Loss: 0.00001702
Iteration 100/1000 | Loss: 0.00001701
Iteration 101/1000 | Loss: 0.00001701
Iteration 102/1000 | Loss: 0.00001701
Iteration 103/1000 | Loss: 0.00001701
Iteration 104/1000 | Loss: 0.00001700
Iteration 105/1000 | Loss: 0.00001700
Iteration 106/1000 | Loss: 0.00001700
Iteration 107/1000 | Loss: 0.00001699
Iteration 108/1000 | Loss: 0.00001699
Iteration 109/1000 | Loss: 0.00001698
Iteration 110/1000 | Loss: 0.00001697
Iteration 111/1000 | Loss: 0.00001693
Iteration 112/1000 | Loss: 0.00001692
Iteration 113/1000 | Loss: 0.00001690
Iteration 114/1000 | Loss: 0.00001690
Iteration 115/1000 | Loss: 0.00001690
Iteration 116/1000 | Loss: 0.00001690
Iteration 117/1000 | Loss: 0.00001690
Iteration 118/1000 | Loss: 0.00001690
Iteration 119/1000 | Loss: 0.00001690
Iteration 120/1000 | Loss: 0.00001690
Iteration 121/1000 | Loss: 0.00001690
Iteration 122/1000 | Loss: 0.00001689
Iteration 123/1000 | Loss: 0.00001689
Iteration 124/1000 | Loss: 0.00001689
Iteration 125/1000 | Loss: 0.00001688
Iteration 126/1000 | Loss: 0.00001688
Iteration 127/1000 | Loss: 0.00001688
Iteration 128/1000 | Loss: 0.00001687
Iteration 129/1000 | Loss: 0.00001687
Iteration 130/1000 | Loss: 0.00001687
Iteration 131/1000 | Loss: 0.00001686
Iteration 132/1000 | Loss: 0.00001686
Iteration 133/1000 | Loss: 0.00001686
Iteration 134/1000 | Loss: 0.00001685
Iteration 135/1000 | Loss: 0.00001685
Iteration 136/1000 | Loss: 0.00001684
Iteration 137/1000 | Loss: 0.00001684
Iteration 138/1000 | Loss: 0.00001684
Iteration 139/1000 | Loss: 0.00001684
Iteration 140/1000 | Loss: 0.00001683
Iteration 141/1000 | Loss: 0.00001683
Iteration 142/1000 | Loss: 0.00001683
Iteration 143/1000 | Loss: 0.00001683
Iteration 144/1000 | Loss: 0.00001682
Iteration 145/1000 | Loss: 0.00001682
Iteration 146/1000 | Loss: 0.00001682
Iteration 147/1000 | Loss: 0.00001682
Iteration 148/1000 | Loss: 0.00001681
Iteration 149/1000 | Loss: 0.00001681
Iteration 150/1000 | Loss: 0.00001681
Iteration 151/1000 | Loss: 0.00001680
Iteration 152/1000 | Loss: 0.00001680
Iteration 153/1000 | Loss: 0.00001680
Iteration 154/1000 | Loss: 0.00001679
Iteration 155/1000 | Loss: 0.00001679
Iteration 156/1000 | Loss: 0.00001679
Iteration 157/1000 | Loss: 0.00001679
Iteration 158/1000 | Loss: 0.00001679
Iteration 159/1000 | Loss: 0.00001679
Iteration 160/1000 | Loss: 0.00001679
Iteration 161/1000 | Loss: 0.00001679
Iteration 162/1000 | Loss: 0.00001678
Iteration 163/1000 | Loss: 0.00001678
Iteration 164/1000 | Loss: 0.00001677
Iteration 165/1000 | Loss: 0.00001677
Iteration 166/1000 | Loss: 0.00001677
Iteration 167/1000 | Loss: 0.00001677
Iteration 168/1000 | Loss: 0.00001677
Iteration 169/1000 | Loss: 0.00001677
Iteration 170/1000 | Loss: 0.00001677
Iteration 171/1000 | Loss: 0.00001677
Iteration 172/1000 | Loss: 0.00001677
Iteration 173/1000 | Loss: 0.00001676
Iteration 174/1000 | Loss: 0.00001676
Iteration 175/1000 | Loss: 0.00001676
Iteration 176/1000 | Loss: 0.00001676
Iteration 177/1000 | Loss: 0.00001676
Iteration 178/1000 | Loss: 0.00001676
Iteration 179/1000 | Loss: 0.00001676
Iteration 180/1000 | Loss: 0.00001675
Iteration 181/1000 | Loss: 0.00001675
Iteration 182/1000 | Loss: 0.00001675
Iteration 183/1000 | Loss: 0.00001675
Iteration 184/1000 | Loss: 0.00001675
Iteration 185/1000 | Loss: 0.00001674
Iteration 186/1000 | Loss: 0.00001674
Iteration 187/1000 | Loss: 0.00001674
Iteration 188/1000 | Loss: 0.00001674
Iteration 189/1000 | Loss: 0.00001674
Iteration 190/1000 | Loss: 0.00001674
Iteration 191/1000 | Loss: 0.00001674
Iteration 192/1000 | Loss: 0.00001674
Iteration 193/1000 | Loss: 0.00001674
Iteration 194/1000 | Loss: 0.00001674
Iteration 195/1000 | Loss: 0.00001674
Iteration 196/1000 | Loss: 0.00001674
Iteration 197/1000 | Loss: 0.00001674
Iteration 198/1000 | Loss: 0.00001674
Iteration 199/1000 | Loss: 0.00001674
Iteration 200/1000 | Loss: 0.00001674
Iteration 201/1000 | Loss: 0.00001673
Iteration 202/1000 | Loss: 0.00001673
Iteration 203/1000 | Loss: 0.00001672
Iteration 204/1000 | Loss: 0.00001672
Iteration 205/1000 | Loss: 0.00001672
Iteration 206/1000 | Loss: 0.00001671
Iteration 207/1000 | Loss: 0.00001671
Iteration 208/1000 | Loss: 0.00001671
Iteration 209/1000 | Loss: 0.00001671
Iteration 210/1000 | Loss: 0.00001671
Iteration 211/1000 | Loss: 0.00001671
Iteration 212/1000 | Loss: 0.00001671
Iteration 213/1000 | Loss: 0.00001671
Iteration 214/1000 | Loss: 0.00001671
Iteration 215/1000 | Loss: 0.00001671
Iteration 216/1000 | Loss: 0.00001670
Iteration 217/1000 | Loss: 0.00001670
Iteration 218/1000 | Loss: 0.00001670
Iteration 219/1000 | Loss: 0.00001670
Iteration 220/1000 | Loss: 0.00001670
Iteration 221/1000 | Loss: 0.00001670
Iteration 222/1000 | Loss: 0.00001669
Iteration 223/1000 | Loss: 0.00001669
Iteration 224/1000 | Loss: 0.00001669
Iteration 225/1000 | Loss: 0.00001669
Iteration 226/1000 | Loss: 0.00001669
Iteration 227/1000 | Loss: 0.00001669
Iteration 228/1000 | Loss: 0.00001668
Iteration 229/1000 | Loss: 0.00001668
Iteration 230/1000 | Loss: 0.00001668
Iteration 231/1000 | Loss: 0.00001668
Iteration 232/1000 | Loss: 0.00001668
Iteration 233/1000 | Loss: 0.00001668
Iteration 234/1000 | Loss: 0.00001668
Iteration 235/1000 | Loss: 0.00001668
Iteration 236/1000 | Loss: 0.00001668
Iteration 237/1000 | Loss: 0.00001668
Iteration 238/1000 | Loss: 0.00001668
Iteration 239/1000 | Loss: 0.00001668
Iteration 240/1000 | Loss: 0.00001668
Iteration 241/1000 | Loss: 0.00001668
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 241. Stopping optimization.
Last 5 losses: [1.6676269297022372e-05, 1.6676269297022372e-05, 1.6676269297022372e-05, 1.6676269297022372e-05, 1.6676269297022372e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6676269297022372e-05

Optimization complete. Final v2v error: 3.4753410816192627 mm

Highest mean error: 6.091681957244873 mm for frame 6

Lowest mean error: 3.361063241958618 mm for frame 182

Saving results

Total time: 94.07164168357849
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1074/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1074.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1074
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00533780
Iteration 2/25 | Loss: 0.00142617
Iteration 3/25 | Loss: 0.00135808
Iteration 4/25 | Loss: 0.00134774
Iteration 5/25 | Loss: 0.00134469
Iteration 6/25 | Loss: 0.00134438
Iteration 7/25 | Loss: 0.00134438
Iteration 8/25 | Loss: 0.00134438
Iteration 9/25 | Loss: 0.00134438
Iteration 10/25 | Loss: 0.00134438
Iteration 11/25 | Loss: 0.00134438
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0013443761272355914, 0.0013443761272355914, 0.0013443761272355914, 0.0013443761272355914, 0.0013443761272355914]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013443761272355914

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.29995394
Iteration 2/25 | Loss: 0.00178921
Iteration 3/25 | Loss: 0.00178919
Iteration 4/25 | Loss: 0.00178919
Iteration 5/25 | Loss: 0.00178919
Iteration 6/25 | Loss: 0.00178919
Iteration 7/25 | Loss: 0.00178919
Iteration 8/25 | Loss: 0.00178919
Iteration 9/25 | Loss: 0.00178919
Iteration 10/25 | Loss: 0.00178919
Iteration 11/25 | Loss: 0.00178919
Iteration 12/25 | Loss: 0.00178919
Iteration 13/25 | Loss: 0.00178919
Iteration 14/25 | Loss: 0.00178919
Iteration 15/25 | Loss: 0.00178919
Iteration 16/25 | Loss: 0.00178919
Iteration 17/25 | Loss: 0.00178919
Iteration 18/25 | Loss: 0.00178919
Iteration 19/25 | Loss: 0.00178919
Iteration 20/25 | Loss: 0.00178919
Iteration 21/25 | Loss: 0.00178919
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0017891888273879886, 0.0017891888273879886, 0.0017891888273879886, 0.0017891888273879886, 0.0017891888273879886]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017891888273879886

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00178919
Iteration 2/1000 | Loss: 0.00002488
Iteration 3/1000 | Loss: 0.00001875
Iteration 4/1000 | Loss: 0.00001721
Iteration 5/1000 | Loss: 0.00001626
Iteration 6/1000 | Loss: 0.00001566
Iteration 7/1000 | Loss: 0.00001511
Iteration 8/1000 | Loss: 0.00001470
Iteration 9/1000 | Loss: 0.00001422
Iteration 10/1000 | Loss: 0.00001387
Iteration 11/1000 | Loss: 0.00001366
Iteration 12/1000 | Loss: 0.00001344
Iteration 13/1000 | Loss: 0.00001337
Iteration 14/1000 | Loss: 0.00001323
Iteration 15/1000 | Loss: 0.00001322
Iteration 16/1000 | Loss: 0.00001316
Iteration 17/1000 | Loss: 0.00001316
Iteration 18/1000 | Loss: 0.00001303
Iteration 19/1000 | Loss: 0.00001298
Iteration 20/1000 | Loss: 0.00001297
Iteration 21/1000 | Loss: 0.00001297
Iteration 22/1000 | Loss: 0.00001295
Iteration 23/1000 | Loss: 0.00001293
Iteration 24/1000 | Loss: 0.00001289
Iteration 25/1000 | Loss: 0.00001286
Iteration 26/1000 | Loss: 0.00001284
Iteration 27/1000 | Loss: 0.00001284
Iteration 28/1000 | Loss: 0.00001283
Iteration 29/1000 | Loss: 0.00001282
Iteration 30/1000 | Loss: 0.00001282
Iteration 31/1000 | Loss: 0.00001280
Iteration 32/1000 | Loss: 0.00001279
Iteration 33/1000 | Loss: 0.00001279
Iteration 34/1000 | Loss: 0.00001278
Iteration 35/1000 | Loss: 0.00001277
Iteration 36/1000 | Loss: 0.00001277
Iteration 37/1000 | Loss: 0.00001277
Iteration 38/1000 | Loss: 0.00001276
Iteration 39/1000 | Loss: 0.00001275
Iteration 40/1000 | Loss: 0.00001275
Iteration 41/1000 | Loss: 0.00001274
Iteration 42/1000 | Loss: 0.00001270
Iteration 43/1000 | Loss: 0.00001269
Iteration 44/1000 | Loss: 0.00001265
Iteration 45/1000 | Loss: 0.00001264
Iteration 46/1000 | Loss: 0.00001263
Iteration 47/1000 | Loss: 0.00001263
Iteration 48/1000 | Loss: 0.00001262
Iteration 49/1000 | Loss: 0.00001262
Iteration 50/1000 | Loss: 0.00001262
Iteration 51/1000 | Loss: 0.00001261
Iteration 52/1000 | Loss: 0.00001261
Iteration 53/1000 | Loss: 0.00001260
Iteration 54/1000 | Loss: 0.00001260
Iteration 55/1000 | Loss: 0.00001260
Iteration 56/1000 | Loss: 0.00001259
Iteration 57/1000 | Loss: 0.00001259
Iteration 58/1000 | Loss: 0.00001258
Iteration 59/1000 | Loss: 0.00001258
Iteration 60/1000 | Loss: 0.00001258
Iteration 61/1000 | Loss: 0.00001257
Iteration 62/1000 | Loss: 0.00001257
Iteration 63/1000 | Loss: 0.00001256
Iteration 64/1000 | Loss: 0.00001256
Iteration 65/1000 | Loss: 0.00001256
Iteration 66/1000 | Loss: 0.00001255
Iteration 67/1000 | Loss: 0.00001255
Iteration 68/1000 | Loss: 0.00001255
Iteration 69/1000 | Loss: 0.00001254
Iteration 70/1000 | Loss: 0.00001254
Iteration 71/1000 | Loss: 0.00001254
Iteration 72/1000 | Loss: 0.00001254
Iteration 73/1000 | Loss: 0.00001254
Iteration 74/1000 | Loss: 0.00001253
Iteration 75/1000 | Loss: 0.00001253
Iteration 76/1000 | Loss: 0.00001253
Iteration 77/1000 | Loss: 0.00001253
Iteration 78/1000 | Loss: 0.00001253
Iteration 79/1000 | Loss: 0.00001253
Iteration 80/1000 | Loss: 0.00001253
Iteration 81/1000 | Loss: 0.00001252
Iteration 82/1000 | Loss: 0.00001252
Iteration 83/1000 | Loss: 0.00001252
Iteration 84/1000 | Loss: 0.00001252
Iteration 85/1000 | Loss: 0.00001252
Iteration 86/1000 | Loss: 0.00001251
Iteration 87/1000 | Loss: 0.00001251
Iteration 88/1000 | Loss: 0.00001251
Iteration 89/1000 | Loss: 0.00001251
Iteration 90/1000 | Loss: 0.00001250
Iteration 91/1000 | Loss: 0.00001250
Iteration 92/1000 | Loss: 0.00001250
Iteration 93/1000 | Loss: 0.00001250
Iteration 94/1000 | Loss: 0.00001250
Iteration 95/1000 | Loss: 0.00001249
Iteration 96/1000 | Loss: 0.00001249
Iteration 97/1000 | Loss: 0.00001249
Iteration 98/1000 | Loss: 0.00001249
Iteration 99/1000 | Loss: 0.00001248
Iteration 100/1000 | Loss: 0.00001248
Iteration 101/1000 | Loss: 0.00001248
Iteration 102/1000 | Loss: 0.00001248
Iteration 103/1000 | Loss: 0.00001248
Iteration 104/1000 | Loss: 0.00001248
Iteration 105/1000 | Loss: 0.00001248
Iteration 106/1000 | Loss: 0.00001247
Iteration 107/1000 | Loss: 0.00001247
Iteration 108/1000 | Loss: 0.00001247
Iteration 109/1000 | Loss: 0.00001247
Iteration 110/1000 | Loss: 0.00001247
Iteration 111/1000 | Loss: 0.00001246
Iteration 112/1000 | Loss: 0.00001246
Iteration 113/1000 | Loss: 0.00001246
Iteration 114/1000 | Loss: 0.00001246
Iteration 115/1000 | Loss: 0.00001246
Iteration 116/1000 | Loss: 0.00001246
Iteration 117/1000 | Loss: 0.00001246
Iteration 118/1000 | Loss: 0.00001246
Iteration 119/1000 | Loss: 0.00001246
Iteration 120/1000 | Loss: 0.00001245
Iteration 121/1000 | Loss: 0.00001245
Iteration 122/1000 | Loss: 0.00001245
Iteration 123/1000 | Loss: 0.00001245
Iteration 124/1000 | Loss: 0.00001245
Iteration 125/1000 | Loss: 0.00001245
Iteration 126/1000 | Loss: 0.00001245
Iteration 127/1000 | Loss: 0.00001245
Iteration 128/1000 | Loss: 0.00001245
Iteration 129/1000 | Loss: 0.00001245
Iteration 130/1000 | Loss: 0.00001245
Iteration 131/1000 | Loss: 0.00001245
Iteration 132/1000 | Loss: 0.00001245
Iteration 133/1000 | Loss: 0.00001245
Iteration 134/1000 | Loss: 0.00001245
Iteration 135/1000 | Loss: 0.00001244
Iteration 136/1000 | Loss: 0.00001244
Iteration 137/1000 | Loss: 0.00001244
Iteration 138/1000 | Loss: 0.00001244
Iteration 139/1000 | Loss: 0.00001244
Iteration 140/1000 | Loss: 0.00001244
Iteration 141/1000 | Loss: 0.00001244
Iteration 142/1000 | Loss: 0.00001244
Iteration 143/1000 | Loss: 0.00001244
Iteration 144/1000 | Loss: 0.00001244
Iteration 145/1000 | Loss: 0.00001244
Iteration 146/1000 | Loss: 0.00001244
Iteration 147/1000 | Loss: 0.00001244
Iteration 148/1000 | Loss: 0.00001244
Iteration 149/1000 | Loss: 0.00001244
Iteration 150/1000 | Loss: 0.00001244
Iteration 151/1000 | Loss: 0.00001244
Iteration 152/1000 | Loss: 0.00001244
Iteration 153/1000 | Loss: 0.00001244
Iteration 154/1000 | Loss: 0.00001244
Iteration 155/1000 | Loss: 0.00001244
Iteration 156/1000 | Loss: 0.00001244
Iteration 157/1000 | Loss: 0.00001244
Iteration 158/1000 | Loss: 0.00001244
Iteration 159/1000 | Loss: 0.00001244
Iteration 160/1000 | Loss: 0.00001244
Iteration 161/1000 | Loss: 0.00001244
Iteration 162/1000 | Loss: 0.00001244
Iteration 163/1000 | Loss: 0.00001244
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [1.2442985280358698e-05, 1.2442985280358698e-05, 1.2442985280358698e-05, 1.2442985280358698e-05, 1.2442985280358698e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2442985280358698e-05

Optimization complete. Final v2v error: 3.03971266746521 mm

Highest mean error: 3.730482339859009 mm for frame 61

Lowest mean error: 2.7949280738830566 mm for frame 28

Saving results

Total time: 42.30531454086304
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1094
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01002384
Iteration 2/25 | Loss: 0.00219795
Iteration 3/25 | Loss: 0.00183200
Iteration 4/25 | Loss: 0.00174162
Iteration 5/25 | Loss: 0.00164974
Iteration 6/25 | Loss: 0.00159531
Iteration 7/25 | Loss: 0.00152627
Iteration 8/25 | Loss: 0.00152439
Iteration 9/25 | Loss: 0.00152270
Iteration 10/25 | Loss: 0.00151746
Iteration 11/25 | Loss: 0.00150404
Iteration 12/25 | Loss: 0.00150330
Iteration 13/25 | Loss: 0.00149789
Iteration 14/25 | Loss: 0.00150627
Iteration 15/25 | Loss: 0.00149022
Iteration 16/25 | Loss: 0.00148098
Iteration 17/25 | Loss: 0.00148684
Iteration 18/25 | Loss: 0.00147693
Iteration 19/25 | Loss: 0.00147180
Iteration 20/25 | Loss: 0.00147279
Iteration 21/25 | Loss: 0.00146899
Iteration 22/25 | Loss: 0.00146671
Iteration 23/25 | Loss: 0.00146342
Iteration 24/25 | Loss: 0.00146217
Iteration 25/25 | Loss: 0.00146168

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.26447582
Iteration 2/25 | Loss: 0.00285870
Iteration 3/25 | Loss: 0.00251062
Iteration 4/25 | Loss: 0.00249477
Iteration 5/25 | Loss: 0.00249477
Iteration 6/25 | Loss: 0.00249477
Iteration 7/25 | Loss: 0.00249477
Iteration 8/25 | Loss: 0.00249477
Iteration 9/25 | Loss: 0.00249477
Iteration 10/25 | Loss: 0.00249477
Iteration 11/25 | Loss: 0.00249477
Iteration 12/25 | Loss: 0.00249477
Iteration 13/25 | Loss: 0.00249477
Iteration 14/25 | Loss: 0.00249477
Iteration 15/25 | Loss: 0.00249477
Iteration 16/25 | Loss: 0.00249477
Iteration 17/25 | Loss: 0.00249477
Iteration 18/25 | Loss: 0.00249477
Iteration 19/25 | Loss: 0.00249477
Iteration 20/25 | Loss: 0.00249477
Iteration 21/25 | Loss: 0.00249477
Iteration 22/25 | Loss: 0.00249477
Iteration 23/25 | Loss: 0.00249477
Iteration 24/25 | Loss: 0.00249477
Iteration 25/25 | Loss: 0.00249477

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00249477
Iteration 2/1000 | Loss: 0.00068817
Iteration 3/1000 | Loss: 0.00227328
Iteration 4/1000 | Loss: 0.00350027
Iteration 5/1000 | Loss: 0.00221022
Iteration 6/1000 | Loss: 0.00190103
Iteration 7/1000 | Loss: 0.00051633
Iteration 8/1000 | Loss: 0.00018397
Iteration 9/1000 | Loss: 0.00034056
Iteration 10/1000 | Loss: 0.00020818
Iteration 11/1000 | Loss: 0.00009109
Iteration 12/1000 | Loss: 0.00097131
Iteration 13/1000 | Loss: 0.00017043
Iteration 14/1000 | Loss: 0.00019721
Iteration 15/1000 | Loss: 0.00008778
Iteration 16/1000 | Loss: 0.00015306
Iteration 17/1000 | Loss: 0.00010445
Iteration 18/1000 | Loss: 0.00020215
Iteration 19/1000 | Loss: 0.00047924
Iteration 20/1000 | Loss: 0.00011590
Iteration 21/1000 | Loss: 0.00010247
Iteration 22/1000 | Loss: 0.00008356
Iteration 23/1000 | Loss: 0.00008535
Iteration 24/1000 | Loss: 0.00014974
Iteration 25/1000 | Loss: 0.00010434
Iteration 26/1000 | Loss: 0.00007993
Iteration 27/1000 | Loss: 0.00007224
Iteration 28/1000 | Loss: 0.00008936
Iteration 29/1000 | Loss: 0.00008497
Iteration 30/1000 | Loss: 0.00007631
Iteration 31/1000 | Loss: 0.00007888
Iteration 32/1000 | Loss: 0.00024819
Iteration 33/1000 | Loss: 0.00009740
Iteration 34/1000 | Loss: 0.00008305
Iteration 35/1000 | Loss: 0.00007874
Iteration 36/1000 | Loss: 0.00025363
Iteration 37/1000 | Loss: 0.00013271
Iteration 38/1000 | Loss: 0.00011818
Iteration 39/1000 | Loss: 0.00007818
Iteration 40/1000 | Loss: 0.00036973
Iteration 41/1000 | Loss: 0.00026906
Iteration 42/1000 | Loss: 0.00016641
Iteration 43/1000 | Loss: 0.00009144
Iteration 44/1000 | Loss: 0.00007596
Iteration 45/1000 | Loss: 0.00007348
Iteration 46/1000 | Loss: 0.00016876
Iteration 47/1000 | Loss: 0.00013554
Iteration 48/1000 | Loss: 0.00023394
Iteration 49/1000 | Loss: 0.00068631
Iteration 50/1000 | Loss: 0.00022218
Iteration 51/1000 | Loss: 0.00017646
Iteration 52/1000 | Loss: 0.00013405
Iteration 53/1000 | Loss: 0.00009128
Iteration 54/1000 | Loss: 0.00006991
Iteration 55/1000 | Loss: 0.00012496
Iteration 56/1000 | Loss: 0.00025710
Iteration 57/1000 | Loss: 0.00007298
Iteration 58/1000 | Loss: 0.00013724
Iteration 59/1000 | Loss: 0.00010250
Iteration 60/1000 | Loss: 0.00011762
Iteration 61/1000 | Loss: 0.00009059
Iteration 62/1000 | Loss: 0.00006636
Iteration 63/1000 | Loss: 0.00010966
Iteration 64/1000 | Loss: 0.00010874
Iteration 65/1000 | Loss: 0.00009225
Iteration 66/1000 | Loss: 0.00006791
Iteration 67/1000 | Loss: 0.00007181
Iteration 68/1000 | Loss: 0.00006611
Iteration 69/1000 | Loss: 0.00007012
Iteration 70/1000 | Loss: 0.00006629
Iteration 71/1000 | Loss: 0.00006235
Iteration 72/1000 | Loss: 0.00008111
Iteration 73/1000 | Loss: 0.00023184
Iteration 74/1000 | Loss: 0.00014851
Iteration 75/1000 | Loss: 0.00014067
Iteration 76/1000 | Loss: 0.00007379
Iteration 77/1000 | Loss: 0.00008157
Iteration 78/1000 | Loss: 0.00005995
Iteration 79/1000 | Loss: 0.00006436
Iteration 80/1000 | Loss: 0.00006630
Iteration 81/1000 | Loss: 0.00006726
Iteration 82/1000 | Loss: 0.00007375
Iteration 83/1000 | Loss: 0.00006907
Iteration 84/1000 | Loss: 0.00006790
Iteration 85/1000 | Loss: 0.00006681
Iteration 86/1000 | Loss: 0.00007144
Iteration 87/1000 | Loss: 0.00006763
Iteration 88/1000 | Loss: 0.00006977
Iteration 89/1000 | Loss: 0.00006853
Iteration 90/1000 | Loss: 0.00006916
Iteration 91/1000 | Loss: 0.00006558
Iteration 92/1000 | Loss: 0.00006638
Iteration 93/1000 | Loss: 0.00006588
Iteration 94/1000 | Loss: 0.00006282
Iteration 95/1000 | Loss: 0.00007065
Iteration 96/1000 | Loss: 0.00005868
Iteration 97/1000 | Loss: 0.00012054
Iteration 98/1000 | Loss: 0.00006389
Iteration 99/1000 | Loss: 0.00008899
Iteration 100/1000 | Loss: 0.00009495
Iteration 101/1000 | Loss: 0.00009062
Iteration 102/1000 | Loss: 0.00005569
Iteration 103/1000 | Loss: 0.00009158
Iteration 104/1000 | Loss: 0.00005500
Iteration 105/1000 | Loss: 0.00005476
Iteration 106/1000 | Loss: 0.00008286
Iteration 107/1000 | Loss: 0.00005445
Iteration 108/1000 | Loss: 0.00007938
Iteration 109/1000 | Loss: 0.00018971
Iteration 110/1000 | Loss: 0.00030785
Iteration 111/1000 | Loss: 0.00021895
Iteration 112/1000 | Loss: 0.00021314
Iteration 113/1000 | Loss: 0.00012411
Iteration 114/1000 | Loss: 0.00010129
Iteration 115/1000 | Loss: 0.00005738
Iteration 116/1000 | Loss: 0.00007845
Iteration 117/1000 | Loss: 0.00018610
Iteration 118/1000 | Loss: 0.00010150
Iteration 119/1000 | Loss: 0.00005610
Iteration 120/1000 | Loss: 0.00005485
Iteration 121/1000 | Loss: 0.00005433
Iteration 122/1000 | Loss: 0.00035388
Iteration 123/1000 | Loss: 0.00024864
Iteration 124/1000 | Loss: 0.00055552
Iteration 125/1000 | Loss: 0.00055033
Iteration 126/1000 | Loss: 0.00026142
Iteration 127/1000 | Loss: 0.00006426
Iteration 128/1000 | Loss: 0.00008230
Iteration 129/1000 | Loss: 0.00006901
Iteration 130/1000 | Loss: 0.00012341
Iteration 131/1000 | Loss: 0.00005588
Iteration 132/1000 | Loss: 0.00006761
Iteration 133/1000 | Loss: 0.00005111
Iteration 134/1000 | Loss: 0.00015522
Iteration 135/1000 | Loss: 0.00021210
Iteration 136/1000 | Loss: 0.00014530
Iteration 137/1000 | Loss: 0.00012166
Iteration 138/1000 | Loss: 0.00007816
Iteration 139/1000 | Loss: 0.00006346
Iteration 140/1000 | Loss: 0.00015508
Iteration 141/1000 | Loss: 0.00056046
Iteration 142/1000 | Loss: 0.00103184
Iteration 143/1000 | Loss: 0.00092319
Iteration 144/1000 | Loss: 0.00038156
Iteration 145/1000 | Loss: 0.00007956
Iteration 146/1000 | Loss: 0.00005179
Iteration 147/1000 | Loss: 0.00005068
Iteration 148/1000 | Loss: 0.00007096
Iteration 149/1000 | Loss: 0.00004964
Iteration 150/1000 | Loss: 0.00009506
Iteration 151/1000 | Loss: 0.00005023
Iteration 152/1000 | Loss: 0.00009807
Iteration 153/1000 | Loss: 0.00005696
Iteration 154/1000 | Loss: 0.00006383
Iteration 155/1000 | Loss: 0.00005632
Iteration 156/1000 | Loss: 0.00005033
Iteration 157/1000 | Loss: 0.00004873
Iteration 158/1000 | Loss: 0.00004873
Iteration 159/1000 | Loss: 0.00004873
Iteration 160/1000 | Loss: 0.00004873
Iteration 161/1000 | Loss: 0.00004873
Iteration 162/1000 | Loss: 0.00004873
Iteration 163/1000 | Loss: 0.00004873
Iteration 164/1000 | Loss: 0.00004873
Iteration 165/1000 | Loss: 0.00004873
Iteration 166/1000 | Loss: 0.00009206
Iteration 167/1000 | Loss: 0.00004864
Iteration 168/1000 | Loss: 0.00025222
Iteration 169/1000 | Loss: 0.00012129
Iteration 170/1000 | Loss: 0.00018779
Iteration 171/1000 | Loss: 0.00013868
Iteration 172/1000 | Loss: 0.00021168
Iteration 173/1000 | Loss: 0.00005234
Iteration 174/1000 | Loss: 0.00005864
Iteration 175/1000 | Loss: 0.00004847
Iteration 176/1000 | Loss: 0.00006044
Iteration 177/1000 | Loss: 0.00012931
Iteration 178/1000 | Loss: 0.00030883
Iteration 179/1000 | Loss: 0.00010524
Iteration 180/1000 | Loss: 0.00010311
Iteration 181/1000 | Loss: 0.00004805
Iteration 182/1000 | Loss: 0.00015251
Iteration 183/1000 | Loss: 0.00011219
Iteration 184/1000 | Loss: 0.00018238
Iteration 185/1000 | Loss: 0.00010644
Iteration 186/1000 | Loss: 0.00017026
Iteration 187/1000 | Loss: 0.00006099
Iteration 188/1000 | Loss: 0.00004895
Iteration 189/1000 | Loss: 0.00006878
Iteration 190/1000 | Loss: 0.00007976
Iteration 191/1000 | Loss: 0.00004838
Iteration 192/1000 | Loss: 0.00005295
Iteration 193/1000 | Loss: 0.00004621
Iteration 194/1000 | Loss: 0.00020940
Iteration 195/1000 | Loss: 0.00044992
Iteration 196/1000 | Loss: 0.00051903
Iteration 197/1000 | Loss: 0.00011922
Iteration 198/1000 | Loss: 0.00023993
Iteration 199/1000 | Loss: 0.00015655
Iteration 200/1000 | Loss: 0.00008642
Iteration 201/1000 | Loss: 0.00006537
Iteration 202/1000 | Loss: 0.00005477
Iteration 203/1000 | Loss: 0.00004624
Iteration 204/1000 | Loss: 0.00008816
Iteration 205/1000 | Loss: 0.00004550
Iteration 206/1000 | Loss: 0.00009505
Iteration 207/1000 | Loss: 0.00004640
Iteration 208/1000 | Loss: 0.00004533
Iteration 209/1000 | Loss: 0.00004610
Iteration 210/1000 | Loss: 0.00014097
Iteration 211/1000 | Loss: 0.00036930
Iteration 212/1000 | Loss: 0.00004444
Iteration 213/1000 | Loss: 0.00004438
Iteration 214/1000 | Loss: 0.00004437
Iteration 215/1000 | Loss: 0.00004437
Iteration 216/1000 | Loss: 0.00004437
Iteration 217/1000 | Loss: 0.00004437
Iteration 218/1000 | Loss: 0.00004437
Iteration 219/1000 | Loss: 0.00004436
Iteration 220/1000 | Loss: 0.00007850
Iteration 221/1000 | Loss: 0.00022356
Iteration 222/1000 | Loss: 0.00004850
Iteration 223/1000 | Loss: 0.00004433
Iteration 224/1000 | Loss: 0.00004892
Iteration 225/1000 | Loss: 0.00004423
Iteration 226/1000 | Loss: 0.00004423
Iteration 227/1000 | Loss: 0.00004423
Iteration 228/1000 | Loss: 0.00004422
Iteration 229/1000 | Loss: 0.00004422
Iteration 230/1000 | Loss: 0.00004422
Iteration 231/1000 | Loss: 0.00004422
Iteration 232/1000 | Loss: 0.00004422
Iteration 233/1000 | Loss: 0.00004422
Iteration 234/1000 | Loss: 0.00004422
Iteration 235/1000 | Loss: 0.00004422
Iteration 236/1000 | Loss: 0.00004422
Iteration 237/1000 | Loss: 0.00004421
Iteration 238/1000 | Loss: 0.00004421
Iteration 239/1000 | Loss: 0.00004420
Iteration 240/1000 | Loss: 0.00004420
Iteration 241/1000 | Loss: 0.00004420
Iteration 242/1000 | Loss: 0.00004420
Iteration 243/1000 | Loss: 0.00004420
Iteration 244/1000 | Loss: 0.00004420
Iteration 245/1000 | Loss: 0.00004420
Iteration 246/1000 | Loss: 0.00004420
Iteration 247/1000 | Loss: 0.00004420
Iteration 248/1000 | Loss: 0.00004420
Iteration 249/1000 | Loss: 0.00004420
Iteration 250/1000 | Loss: 0.00004419
Iteration 251/1000 | Loss: 0.00004419
Iteration 252/1000 | Loss: 0.00004419
Iteration 253/1000 | Loss: 0.00004419
Iteration 254/1000 | Loss: 0.00004419
Iteration 255/1000 | Loss: 0.00004419
Iteration 256/1000 | Loss: 0.00004419
Iteration 257/1000 | Loss: 0.00004419
Iteration 258/1000 | Loss: 0.00004418
Iteration 259/1000 | Loss: 0.00004418
Iteration 260/1000 | Loss: 0.00004418
Iteration 261/1000 | Loss: 0.00004417
Iteration 262/1000 | Loss: 0.00004417
Iteration 263/1000 | Loss: 0.00008232
Iteration 264/1000 | Loss: 0.00018702
Iteration 265/1000 | Loss: 0.00013932
Iteration 266/1000 | Loss: 0.00015710
Iteration 267/1000 | Loss: 0.00005465
Iteration 268/1000 | Loss: 0.00008310
Iteration 269/1000 | Loss: 0.00004636
Iteration 270/1000 | Loss: 0.00004516
Iteration 271/1000 | Loss: 0.00010698
Iteration 272/1000 | Loss: 0.00005510
Iteration 273/1000 | Loss: 0.00004368
Iteration 274/1000 | Loss: 0.00004330
Iteration 275/1000 | Loss: 0.00008654
Iteration 276/1000 | Loss: 0.00004618
Iteration 277/1000 | Loss: 0.00005082
Iteration 278/1000 | Loss: 0.00007356
Iteration 279/1000 | Loss: 0.00004672
Iteration 280/1000 | Loss: 0.00004284
Iteration 281/1000 | Loss: 0.00004284
Iteration 282/1000 | Loss: 0.00004284
Iteration 283/1000 | Loss: 0.00004283
Iteration 284/1000 | Loss: 0.00004283
Iteration 285/1000 | Loss: 0.00004283
Iteration 286/1000 | Loss: 0.00004283
Iteration 287/1000 | Loss: 0.00004283
Iteration 288/1000 | Loss: 0.00004283
Iteration 289/1000 | Loss: 0.00004283
Iteration 290/1000 | Loss: 0.00004283
Iteration 291/1000 | Loss: 0.00004283
Iteration 292/1000 | Loss: 0.00004281
Iteration 293/1000 | Loss: 0.00004281
Iteration 294/1000 | Loss: 0.00005439
Iteration 295/1000 | Loss: 0.00004276
Iteration 296/1000 | Loss: 0.00004275
Iteration 297/1000 | Loss: 0.00004275
Iteration 298/1000 | Loss: 0.00004275
Iteration 299/1000 | Loss: 0.00004274
Iteration 300/1000 | Loss: 0.00004274
Iteration 301/1000 | Loss: 0.00004273
Iteration 302/1000 | Loss: 0.00004273
Iteration 303/1000 | Loss: 0.00004273
Iteration 304/1000 | Loss: 0.00004273
Iteration 305/1000 | Loss: 0.00004272
Iteration 306/1000 | Loss: 0.00004272
Iteration 307/1000 | Loss: 0.00007599
Iteration 308/1000 | Loss: 0.00008897
Iteration 309/1000 | Loss: 0.00004430
Iteration 310/1000 | Loss: 0.00006531
Iteration 311/1000 | Loss: 0.00013724
Iteration 312/1000 | Loss: 0.00004890
Iteration 313/1000 | Loss: 0.00004367
Iteration 314/1000 | Loss: 0.00004270
Iteration 315/1000 | Loss: 0.00004270
Iteration 316/1000 | Loss: 0.00004270
Iteration 317/1000 | Loss: 0.00004270
Iteration 318/1000 | Loss: 0.00004270
Iteration 319/1000 | Loss: 0.00004270
Iteration 320/1000 | Loss: 0.00004269
Iteration 321/1000 | Loss: 0.00004307
Iteration 322/1000 | Loss: 0.00004268
Iteration 323/1000 | Loss: 0.00004268
Iteration 324/1000 | Loss: 0.00004268
Iteration 325/1000 | Loss: 0.00004268
Iteration 326/1000 | Loss: 0.00004268
Iteration 327/1000 | Loss: 0.00004267
Iteration 328/1000 | Loss: 0.00004267
Iteration 329/1000 | Loss: 0.00004267
Iteration 330/1000 | Loss: 0.00004267
Iteration 331/1000 | Loss: 0.00004267
Iteration 332/1000 | Loss: 0.00004267
Iteration 333/1000 | Loss: 0.00004267
Iteration 334/1000 | Loss: 0.00004267
Iteration 335/1000 | Loss: 0.00004267
Iteration 336/1000 | Loss: 0.00004267
Iteration 337/1000 | Loss: 0.00004267
Iteration 338/1000 | Loss: 0.00004267
Iteration 339/1000 | Loss: 0.00004267
Iteration 340/1000 | Loss: 0.00004267
Iteration 341/1000 | Loss: 0.00004266
Iteration 342/1000 | Loss: 0.00004266
Iteration 343/1000 | Loss: 0.00004266
Iteration 344/1000 | Loss: 0.00004266
Iteration 345/1000 | Loss: 0.00004266
Iteration 346/1000 | Loss: 0.00004266
Iteration 347/1000 | Loss: 0.00004266
Iteration 348/1000 | Loss: 0.00004266
Iteration 349/1000 | Loss: 0.00004266
Iteration 350/1000 | Loss: 0.00004265
Iteration 351/1000 | Loss: 0.00004265
Iteration 352/1000 | Loss: 0.00004265
Iteration 353/1000 | Loss: 0.00004265
Iteration 354/1000 | Loss: 0.00004265
Iteration 355/1000 | Loss: 0.00004265
Iteration 356/1000 | Loss: 0.00004265
Iteration 357/1000 | Loss: 0.00004265
Iteration 358/1000 | Loss: 0.00004265
Iteration 359/1000 | Loss: 0.00004265
Iteration 360/1000 | Loss: 0.00004265
Iteration 361/1000 | Loss: 0.00004265
Iteration 362/1000 | Loss: 0.00004265
Iteration 363/1000 | Loss: 0.00004264
Iteration 364/1000 | Loss: 0.00004264
Iteration 365/1000 | Loss: 0.00004264
Iteration 366/1000 | Loss: 0.00004264
Iteration 367/1000 | Loss: 0.00004264
Iteration 368/1000 | Loss: 0.00004264
Iteration 369/1000 | Loss: 0.00004264
Iteration 370/1000 | Loss: 0.00004264
Iteration 371/1000 | Loss: 0.00004264
Iteration 372/1000 | Loss: 0.00004264
Iteration 373/1000 | Loss: 0.00004264
Iteration 374/1000 | Loss: 0.00004264
Iteration 375/1000 | Loss: 0.00004263
Iteration 376/1000 | Loss: 0.00004263
Iteration 377/1000 | Loss: 0.00004263
Iteration 378/1000 | Loss: 0.00004263
Iteration 379/1000 | Loss: 0.00004263
Iteration 380/1000 | Loss: 0.00004263
Iteration 381/1000 | Loss: 0.00004263
Iteration 382/1000 | Loss: 0.00004263
Iteration 383/1000 | Loss: 0.00004263
Iteration 384/1000 | Loss: 0.00004263
Iteration 385/1000 | Loss: 0.00004263
Iteration 386/1000 | Loss: 0.00004263
Iteration 387/1000 | Loss: 0.00004262
Iteration 388/1000 | Loss: 0.00004262
Iteration 389/1000 | Loss: 0.00004262
Iteration 390/1000 | Loss: 0.00004262
Iteration 391/1000 | Loss: 0.00004262
Iteration 392/1000 | Loss: 0.00004262
Iteration 393/1000 | Loss: 0.00004262
Iteration 394/1000 | Loss: 0.00004262
Iteration 395/1000 | Loss: 0.00004262
Iteration 396/1000 | Loss: 0.00004262
Iteration 397/1000 | Loss: 0.00004262
Iteration 398/1000 | Loss: 0.00004262
Iteration 399/1000 | Loss: 0.00004262
Iteration 400/1000 | Loss: 0.00004262
Iteration 401/1000 | Loss: 0.00005504
Iteration 402/1000 | Loss: 0.00004265
Iteration 403/1000 | Loss: 0.00004263
Iteration 404/1000 | Loss: 0.00004262
Iteration 405/1000 | Loss: 0.00004261
Iteration 406/1000 | Loss: 0.00004261
Iteration 407/1000 | Loss: 0.00005510
Iteration 408/1000 | Loss: 0.00004473
Iteration 409/1000 | Loss: 0.00004263
Iteration 410/1000 | Loss: 0.00004263
Iteration 411/1000 | Loss: 0.00004262
Iteration 412/1000 | Loss: 0.00004262
Iteration 413/1000 | Loss: 0.00004262
Iteration 414/1000 | Loss: 0.00004261
Iteration 415/1000 | Loss: 0.00004261
Iteration 416/1000 | Loss: 0.00004505
Iteration 417/1000 | Loss: 0.00004260
Iteration 418/1000 | Loss: 0.00004259
Iteration 419/1000 | Loss: 0.00004259
Iteration 420/1000 | Loss: 0.00004259
Iteration 421/1000 | Loss: 0.00004259
Iteration 422/1000 | Loss: 0.00004259
Iteration 423/1000 | Loss: 0.00004259
Iteration 424/1000 | Loss: 0.00004259
Iteration 425/1000 | Loss: 0.00004259
Iteration 426/1000 | Loss: 0.00004259
Iteration 427/1000 | Loss: 0.00004259
Iteration 428/1000 | Loss: 0.00004259
Iteration 429/1000 | Loss: 0.00004258
Iteration 430/1000 | Loss: 0.00004258
Iteration 431/1000 | Loss: 0.00004258
Iteration 432/1000 | Loss: 0.00004258
Iteration 433/1000 | Loss: 0.00004258
Iteration 434/1000 | Loss: 0.00004258
Iteration 435/1000 | Loss: 0.00004258
Iteration 436/1000 | Loss: 0.00004258
Iteration 437/1000 | Loss: 0.00004258
Iteration 438/1000 | Loss: 0.00004258
Iteration 439/1000 | Loss: 0.00004258
Iteration 440/1000 | Loss: 0.00004258
Iteration 441/1000 | Loss: 0.00004258
Iteration 442/1000 | Loss: 0.00004258
Iteration 443/1000 | Loss: 0.00004258
Iteration 444/1000 | Loss: 0.00004258
Iteration 445/1000 | Loss: 0.00004258
Iteration 446/1000 | Loss: 0.00004258
Iteration 447/1000 | Loss: 0.00004258
Iteration 448/1000 | Loss: 0.00004258
Iteration 449/1000 | Loss: 0.00004258
Iteration 450/1000 | Loss: 0.00004258
Iteration 451/1000 | Loss: 0.00004258
Iteration 452/1000 | Loss: 0.00004258
Iteration 453/1000 | Loss: 0.00004258
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 453. Stopping optimization.
Last 5 losses: [4.257971522747539e-05, 4.257971522747539e-05, 4.257971522747539e-05, 4.257971522747539e-05, 4.257971522747539e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.257971522747539e-05

Optimization complete. Final v2v error: 3.8307178020477295 mm

Highest mean error: 10.507560729980469 mm for frame 201

Lowest mean error: 2.8933358192443848 mm for frame 39

Saving results

Total time: 443.4187891483307
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1066
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01042760
Iteration 2/25 | Loss: 0.00252275
Iteration 3/25 | Loss: 0.00178637
Iteration 4/25 | Loss: 0.00170953
Iteration 5/25 | Loss: 0.00152977
Iteration 6/25 | Loss: 0.00145898
Iteration 7/25 | Loss: 0.00139527
Iteration 8/25 | Loss: 0.00137067
Iteration 9/25 | Loss: 0.00136221
Iteration 10/25 | Loss: 0.00136040
Iteration 11/25 | Loss: 0.00135973
Iteration 12/25 | Loss: 0.00135954
Iteration 13/25 | Loss: 0.00135950
Iteration 14/25 | Loss: 0.00135950
Iteration 15/25 | Loss: 0.00135950
Iteration 16/25 | Loss: 0.00135950
Iteration 17/25 | Loss: 0.00135950
Iteration 18/25 | Loss: 0.00135950
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0013595035998150706, 0.0013595035998150706, 0.0013595035998150706, 0.0013595035998150706, 0.0013595035998150706]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013595035998150706

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27681696
Iteration 2/25 | Loss: 0.00191230
Iteration 3/25 | Loss: 0.00191230
Iteration 4/25 | Loss: 0.00191230
Iteration 5/25 | Loss: 0.00191230
Iteration 6/25 | Loss: 0.00191230
Iteration 7/25 | Loss: 0.00191230
Iteration 8/25 | Loss: 0.00191230
Iteration 9/25 | Loss: 0.00191230
Iteration 10/25 | Loss: 0.00191230
Iteration 11/25 | Loss: 0.00191230
Iteration 12/25 | Loss: 0.00191230
Iteration 13/25 | Loss: 0.00191230
Iteration 14/25 | Loss: 0.00191230
Iteration 15/25 | Loss: 0.00191230
Iteration 16/25 | Loss: 0.00191230
Iteration 17/25 | Loss: 0.00191230
Iteration 18/25 | Loss: 0.00191230
Iteration 19/25 | Loss: 0.00191230
Iteration 20/25 | Loss: 0.00191230
Iteration 21/25 | Loss: 0.00191230
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0019123011734336615, 0.0019123011734336615, 0.0019123011734336615, 0.0019123011734336615, 0.0019123011734336615]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0019123011734336615

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00191230
Iteration 2/1000 | Loss: 0.00003305
Iteration 3/1000 | Loss: 0.00002609
Iteration 4/1000 | Loss: 0.00002380
Iteration 5/1000 | Loss: 0.00002252
Iteration 6/1000 | Loss: 0.00018846
Iteration 7/1000 | Loss: 0.00052451
Iteration 8/1000 | Loss: 0.00051566
Iteration 9/1000 | Loss: 0.00021345
Iteration 10/1000 | Loss: 0.00051406
Iteration 11/1000 | Loss: 0.00055058
Iteration 12/1000 | Loss: 0.00034886
Iteration 13/1000 | Loss: 0.00020896
Iteration 14/1000 | Loss: 0.00003343
Iteration 15/1000 | Loss: 0.00002809
Iteration 16/1000 | Loss: 0.00023867
Iteration 17/1000 | Loss: 0.00010329
Iteration 18/1000 | Loss: 0.00006006
Iteration 19/1000 | Loss: 0.00002400
Iteration 20/1000 | Loss: 0.00002196
Iteration 21/1000 | Loss: 0.00002100
Iteration 22/1000 | Loss: 0.00002035
Iteration 23/1000 | Loss: 0.00001995
Iteration 24/1000 | Loss: 0.00034173
Iteration 25/1000 | Loss: 0.00049413
Iteration 26/1000 | Loss: 0.00035267
Iteration 27/1000 | Loss: 0.00036694
Iteration 28/1000 | Loss: 0.00032495
Iteration 29/1000 | Loss: 0.00020954
Iteration 30/1000 | Loss: 0.00026784
Iteration 31/1000 | Loss: 0.00040768
Iteration 32/1000 | Loss: 0.00040755
Iteration 33/1000 | Loss: 0.00030111
Iteration 34/1000 | Loss: 0.00018377
Iteration 35/1000 | Loss: 0.00007927
Iteration 36/1000 | Loss: 0.00003161
Iteration 37/1000 | Loss: 0.00002714
Iteration 38/1000 | Loss: 0.00016889
Iteration 39/1000 | Loss: 0.00013318
Iteration 40/1000 | Loss: 0.00009178
Iteration 41/1000 | Loss: 0.00008961
Iteration 42/1000 | Loss: 0.00002385
Iteration 43/1000 | Loss: 0.00002280
Iteration 44/1000 | Loss: 0.00002191
Iteration 45/1000 | Loss: 0.00024192
Iteration 46/1000 | Loss: 0.00028819
Iteration 47/1000 | Loss: 0.00010782
Iteration 48/1000 | Loss: 0.00002763
Iteration 49/1000 | Loss: 0.00024627
Iteration 50/1000 | Loss: 0.00026147
Iteration 51/1000 | Loss: 0.00010814
Iteration 52/1000 | Loss: 0.00022834
Iteration 53/1000 | Loss: 0.00016697
Iteration 54/1000 | Loss: 0.00003713
Iteration 55/1000 | Loss: 0.00009388
Iteration 56/1000 | Loss: 0.00002679
Iteration 57/1000 | Loss: 0.00002507
Iteration 58/1000 | Loss: 0.00002386
Iteration 59/1000 | Loss: 0.00012097
Iteration 60/1000 | Loss: 0.00025975
Iteration 61/1000 | Loss: 0.00009998
Iteration 62/1000 | Loss: 0.00014700
Iteration 63/1000 | Loss: 0.00054745
Iteration 64/1000 | Loss: 0.00022413
Iteration 65/1000 | Loss: 0.00014961
Iteration 66/1000 | Loss: 0.00019256
Iteration 67/1000 | Loss: 0.00003009
Iteration 68/1000 | Loss: 0.00002676
Iteration 69/1000 | Loss: 0.00026506
Iteration 70/1000 | Loss: 0.00017954
Iteration 71/1000 | Loss: 0.00018942
Iteration 72/1000 | Loss: 0.00002657
Iteration 73/1000 | Loss: 0.00003488
Iteration 74/1000 | Loss: 0.00020989
Iteration 75/1000 | Loss: 0.00041731
Iteration 76/1000 | Loss: 0.00040668
Iteration 77/1000 | Loss: 0.00020253
Iteration 78/1000 | Loss: 0.00003012
Iteration 79/1000 | Loss: 0.00002825
Iteration 80/1000 | Loss: 0.00024467
Iteration 81/1000 | Loss: 0.00036441
Iteration 82/1000 | Loss: 0.00022753
Iteration 83/1000 | Loss: 0.00010123
Iteration 84/1000 | Loss: 0.00049798
Iteration 85/1000 | Loss: 0.00019085
Iteration 86/1000 | Loss: 0.00015054
Iteration 87/1000 | Loss: 0.00020107
Iteration 88/1000 | Loss: 0.00015751
Iteration 89/1000 | Loss: 0.00018193
Iteration 90/1000 | Loss: 0.00034371
Iteration 91/1000 | Loss: 0.00019182
Iteration 92/1000 | Loss: 0.00034813
Iteration 93/1000 | Loss: 0.00014156
Iteration 94/1000 | Loss: 0.00008328
Iteration 95/1000 | Loss: 0.00024914
Iteration 96/1000 | Loss: 0.00016255
Iteration 97/1000 | Loss: 0.00023711
Iteration 98/1000 | Loss: 0.00017516
Iteration 99/1000 | Loss: 0.00002684
Iteration 100/1000 | Loss: 0.00002492
Iteration 101/1000 | Loss: 0.00002281
Iteration 102/1000 | Loss: 0.00018667
Iteration 103/1000 | Loss: 0.00004252
Iteration 104/1000 | Loss: 0.00003700
Iteration 105/1000 | Loss: 0.00006894
Iteration 106/1000 | Loss: 0.00014087
Iteration 107/1000 | Loss: 0.00002473
Iteration 108/1000 | Loss: 0.00002212
Iteration 109/1000 | Loss: 0.00002062
Iteration 110/1000 | Loss: 0.00001997
Iteration 111/1000 | Loss: 0.00021937
Iteration 112/1000 | Loss: 0.00026345
Iteration 113/1000 | Loss: 0.00018661
Iteration 114/1000 | Loss: 0.00002990
Iteration 115/1000 | Loss: 0.00001915
Iteration 116/1000 | Loss: 0.00001840
Iteration 117/1000 | Loss: 0.00001804
Iteration 118/1000 | Loss: 0.00001779
Iteration 119/1000 | Loss: 0.00016112
Iteration 120/1000 | Loss: 0.00015029
Iteration 121/1000 | Loss: 0.00003998
Iteration 122/1000 | Loss: 0.00018788
Iteration 123/1000 | Loss: 0.00008069
Iteration 124/1000 | Loss: 0.00011422
Iteration 125/1000 | Loss: 0.00008638
Iteration 126/1000 | Loss: 0.00002540
Iteration 127/1000 | Loss: 0.00003335
Iteration 128/1000 | Loss: 0.00005370
Iteration 129/1000 | Loss: 0.00017524
Iteration 130/1000 | Loss: 0.00014383
Iteration 131/1000 | Loss: 0.00002992
Iteration 132/1000 | Loss: 0.00002282
Iteration 133/1000 | Loss: 0.00001950
Iteration 134/1000 | Loss: 0.00001825
Iteration 135/1000 | Loss: 0.00001754
Iteration 136/1000 | Loss: 0.00001718
Iteration 137/1000 | Loss: 0.00001664
Iteration 138/1000 | Loss: 0.00001637
Iteration 139/1000 | Loss: 0.00001621
Iteration 140/1000 | Loss: 0.00001617
Iteration 141/1000 | Loss: 0.00001616
Iteration 142/1000 | Loss: 0.00001615
Iteration 143/1000 | Loss: 0.00001615
Iteration 144/1000 | Loss: 0.00001604
Iteration 145/1000 | Loss: 0.00001598
Iteration 146/1000 | Loss: 0.00001597
Iteration 147/1000 | Loss: 0.00001597
Iteration 148/1000 | Loss: 0.00001596
Iteration 149/1000 | Loss: 0.00001596
Iteration 150/1000 | Loss: 0.00001595
Iteration 151/1000 | Loss: 0.00001595
Iteration 152/1000 | Loss: 0.00001595
Iteration 153/1000 | Loss: 0.00001595
Iteration 154/1000 | Loss: 0.00001593
Iteration 155/1000 | Loss: 0.00001593
Iteration 156/1000 | Loss: 0.00001592
Iteration 157/1000 | Loss: 0.00001592
Iteration 158/1000 | Loss: 0.00001591
Iteration 159/1000 | Loss: 0.00001586
Iteration 160/1000 | Loss: 0.00001585
Iteration 161/1000 | Loss: 0.00001585
Iteration 162/1000 | Loss: 0.00001584
Iteration 163/1000 | Loss: 0.00001584
Iteration 164/1000 | Loss: 0.00001583
Iteration 165/1000 | Loss: 0.00001583
Iteration 166/1000 | Loss: 0.00001583
Iteration 167/1000 | Loss: 0.00001583
Iteration 168/1000 | Loss: 0.00001583
Iteration 169/1000 | Loss: 0.00001583
Iteration 170/1000 | Loss: 0.00001583
Iteration 171/1000 | Loss: 0.00001583
Iteration 172/1000 | Loss: 0.00001583
Iteration 173/1000 | Loss: 0.00001583
Iteration 174/1000 | Loss: 0.00001583
Iteration 175/1000 | Loss: 0.00001583
Iteration 176/1000 | Loss: 0.00001582
Iteration 177/1000 | Loss: 0.00001582
Iteration 178/1000 | Loss: 0.00001582
Iteration 179/1000 | Loss: 0.00001582
Iteration 180/1000 | Loss: 0.00001582
Iteration 181/1000 | Loss: 0.00001582
Iteration 182/1000 | Loss: 0.00001582
Iteration 183/1000 | Loss: 0.00001582
Iteration 184/1000 | Loss: 0.00001581
Iteration 185/1000 | Loss: 0.00001581
Iteration 186/1000 | Loss: 0.00001581
Iteration 187/1000 | Loss: 0.00001580
Iteration 188/1000 | Loss: 0.00001579
Iteration 189/1000 | Loss: 0.00001579
Iteration 190/1000 | Loss: 0.00001579
Iteration 191/1000 | Loss: 0.00001579
Iteration 192/1000 | Loss: 0.00001579
Iteration 193/1000 | Loss: 0.00001579
Iteration 194/1000 | Loss: 0.00001579
Iteration 195/1000 | Loss: 0.00001579
Iteration 196/1000 | Loss: 0.00001578
Iteration 197/1000 | Loss: 0.00001578
Iteration 198/1000 | Loss: 0.00001578
Iteration 199/1000 | Loss: 0.00001577
Iteration 200/1000 | Loss: 0.00001577
Iteration 201/1000 | Loss: 0.00001577
Iteration 202/1000 | Loss: 0.00001577
Iteration 203/1000 | Loss: 0.00001577
Iteration 204/1000 | Loss: 0.00001577
Iteration 205/1000 | Loss: 0.00001577
Iteration 206/1000 | Loss: 0.00001577
Iteration 207/1000 | Loss: 0.00001577
Iteration 208/1000 | Loss: 0.00001577
Iteration 209/1000 | Loss: 0.00001577
Iteration 210/1000 | Loss: 0.00001576
Iteration 211/1000 | Loss: 0.00001576
Iteration 212/1000 | Loss: 0.00001576
Iteration 213/1000 | Loss: 0.00001576
Iteration 214/1000 | Loss: 0.00001575
Iteration 215/1000 | Loss: 0.00001575
Iteration 216/1000 | Loss: 0.00001575
Iteration 217/1000 | Loss: 0.00001575
Iteration 218/1000 | Loss: 0.00001575
Iteration 219/1000 | Loss: 0.00001574
Iteration 220/1000 | Loss: 0.00001574
Iteration 221/1000 | Loss: 0.00001574
Iteration 222/1000 | Loss: 0.00001574
Iteration 223/1000 | Loss: 0.00001574
Iteration 224/1000 | Loss: 0.00001573
Iteration 225/1000 | Loss: 0.00001573
Iteration 226/1000 | Loss: 0.00001573
Iteration 227/1000 | Loss: 0.00001573
Iteration 228/1000 | Loss: 0.00001572
Iteration 229/1000 | Loss: 0.00001571
Iteration 230/1000 | Loss: 0.00001571
Iteration 231/1000 | Loss: 0.00001571
Iteration 232/1000 | Loss: 0.00001570
Iteration 233/1000 | Loss: 0.00001570
Iteration 234/1000 | Loss: 0.00001570
Iteration 235/1000 | Loss: 0.00001570
Iteration 236/1000 | Loss: 0.00001570
Iteration 237/1000 | Loss: 0.00001570
Iteration 238/1000 | Loss: 0.00001570
Iteration 239/1000 | Loss: 0.00001570
Iteration 240/1000 | Loss: 0.00001570
Iteration 241/1000 | Loss: 0.00001570
Iteration 242/1000 | Loss: 0.00001570
Iteration 243/1000 | Loss: 0.00001569
Iteration 244/1000 | Loss: 0.00001569
Iteration 245/1000 | Loss: 0.00001569
Iteration 246/1000 | Loss: 0.00001569
Iteration 247/1000 | Loss: 0.00001569
Iteration 248/1000 | Loss: 0.00001569
Iteration 249/1000 | Loss: 0.00001569
Iteration 250/1000 | Loss: 0.00001569
Iteration 251/1000 | Loss: 0.00001569
Iteration 252/1000 | Loss: 0.00001569
Iteration 253/1000 | Loss: 0.00001569
Iteration 254/1000 | Loss: 0.00001569
Iteration 255/1000 | Loss: 0.00001569
Iteration 256/1000 | Loss: 0.00001568
Iteration 257/1000 | Loss: 0.00001568
Iteration 258/1000 | Loss: 0.00001568
Iteration 259/1000 | Loss: 0.00001568
Iteration 260/1000 | Loss: 0.00001568
Iteration 261/1000 | Loss: 0.00001568
Iteration 262/1000 | Loss: 0.00001568
Iteration 263/1000 | Loss: 0.00001568
Iteration 264/1000 | Loss: 0.00001568
Iteration 265/1000 | Loss: 0.00001568
Iteration 266/1000 | Loss: 0.00001568
Iteration 267/1000 | Loss: 0.00001568
Iteration 268/1000 | Loss: 0.00001568
Iteration 269/1000 | Loss: 0.00001568
Iteration 270/1000 | Loss: 0.00001568
Iteration 271/1000 | Loss: 0.00001567
Iteration 272/1000 | Loss: 0.00001567
Iteration 273/1000 | Loss: 0.00001567
Iteration 274/1000 | Loss: 0.00001567
Iteration 275/1000 | Loss: 0.00001567
Iteration 276/1000 | Loss: 0.00001567
Iteration 277/1000 | Loss: 0.00001567
Iteration 278/1000 | Loss: 0.00001567
Iteration 279/1000 | Loss: 0.00001567
Iteration 280/1000 | Loss: 0.00001567
Iteration 281/1000 | Loss: 0.00001567
Iteration 282/1000 | Loss: 0.00001567
Iteration 283/1000 | Loss: 0.00001567
Iteration 284/1000 | Loss: 0.00001567
Iteration 285/1000 | Loss: 0.00001567
Iteration 286/1000 | Loss: 0.00001567
Iteration 287/1000 | Loss: 0.00001567
Iteration 288/1000 | Loss: 0.00001567
Iteration 289/1000 | Loss: 0.00001567
Iteration 290/1000 | Loss: 0.00001567
Iteration 291/1000 | Loss: 0.00001567
Iteration 292/1000 | Loss: 0.00001566
Iteration 293/1000 | Loss: 0.00001566
Iteration 294/1000 | Loss: 0.00001566
Iteration 295/1000 | Loss: 0.00001566
Iteration 296/1000 | Loss: 0.00001566
Iteration 297/1000 | Loss: 0.00001566
Iteration 298/1000 | Loss: 0.00001566
Iteration 299/1000 | Loss: 0.00001566
Iteration 300/1000 | Loss: 0.00001566
Iteration 301/1000 | Loss: 0.00001566
Iteration 302/1000 | Loss: 0.00001566
Iteration 303/1000 | Loss: 0.00001566
Iteration 304/1000 | Loss: 0.00001566
Iteration 305/1000 | Loss: 0.00001566
Iteration 306/1000 | Loss: 0.00001566
Iteration 307/1000 | Loss: 0.00001566
Iteration 308/1000 | Loss: 0.00001566
Iteration 309/1000 | Loss: 0.00001566
Iteration 310/1000 | Loss: 0.00001566
Iteration 311/1000 | Loss: 0.00001566
Iteration 312/1000 | Loss: 0.00001566
Iteration 313/1000 | Loss: 0.00001566
Iteration 314/1000 | Loss: 0.00001565
Iteration 315/1000 | Loss: 0.00001565
Iteration 316/1000 | Loss: 0.00001565
Iteration 317/1000 | Loss: 0.00001565
Iteration 318/1000 | Loss: 0.00001565
Iteration 319/1000 | Loss: 0.00001565
Iteration 320/1000 | Loss: 0.00001565
Iteration 321/1000 | Loss: 0.00001565
Iteration 322/1000 | Loss: 0.00001565
Iteration 323/1000 | Loss: 0.00001565
Iteration 324/1000 | Loss: 0.00001565
Iteration 325/1000 | Loss: 0.00001565
Iteration 326/1000 | Loss: 0.00001565
Iteration 327/1000 | Loss: 0.00001565
Iteration 328/1000 | Loss: 0.00001565
Iteration 329/1000 | Loss: 0.00001565
Iteration 330/1000 | Loss: 0.00001565
Iteration 331/1000 | Loss: 0.00001565
Iteration 332/1000 | Loss: 0.00001565
Iteration 333/1000 | Loss: 0.00001565
Iteration 334/1000 | Loss: 0.00001565
Iteration 335/1000 | Loss: 0.00001565
Iteration 336/1000 | Loss: 0.00001565
Iteration 337/1000 | Loss: 0.00001565
Iteration 338/1000 | Loss: 0.00001565
Iteration 339/1000 | Loss: 0.00001565
Iteration 340/1000 | Loss: 0.00001565
Iteration 341/1000 | Loss: 0.00001565
Iteration 342/1000 | Loss: 0.00001565
Iteration 343/1000 | Loss: 0.00001565
Iteration 344/1000 | Loss: 0.00001565
Iteration 345/1000 | Loss: 0.00001565
Iteration 346/1000 | Loss: 0.00001565
Iteration 347/1000 | Loss: 0.00001565
Iteration 348/1000 | Loss: 0.00001565
Iteration 349/1000 | Loss: 0.00001565
Iteration 350/1000 | Loss: 0.00001565
Iteration 351/1000 | Loss: 0.00001565
Iteration 352/1000 | Loss: 0.00001565
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 352. Stopping optimization.
Last 5 losses: [1.5649104170734063e-05, 1.5649104170734063e-05, 1.5649104170734063e-05, 1.5649104170734063e-05, 1.5649104170734063e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5649104170734063e-05

Optimization complete. Final v2v error: 3.3889331817626953 mm

Highest mean error: 4.3135666847229 mm for frame 76

Lowest mean error: 3.211071252822876 mm for frame 49

Saving results

Total time: 236.10305523872375
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1046
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00949570
Iteration 2/25 | Loss: 0.00175498
Iteration 3/25 | Loss: 0.00140355
Iteration 4/25 | Loss: 0.00136969
Iteration 5/25 | Loss: 0.00136107
Iteration 6/25 | Loss: 0.00135380
Iteration 7/25 | Loss: 0.00135287
Iteration 8/25 | Loss: 0.00135276
Iteration 9/25 | Loss: 0.00135257
Iteration 10/25 | Loss: 0.00134998
Iteration 11/25 | Loss: 0.00134977
Iteration 12/25 | Loss: 0.00135168
Iteration 13/25 | Loss: 0.00135136
Iteration 14/25 | Loss: 0.00134936
Iteration 15/25 | Loss: 0.00134961
Iteration 16/25 | Loss: 0.00134900
Iteration 17/25 | Loss: 0.00134863
Iteration 18/25 | Loss: 0.00134860
Iteration 19/25 | Loss: 0.00134860
Iteration 20/25 | Loss: 0.00134860
Iteration 21/25 | Loss: 0.00134860
Iteration 22/25 | Loss: 0.00134860
Iteration 23/25 | Loss: 0.00134860
Iteration 24/25 | Loss: 0.00134860
Iteration 25/25 | Loss: 0.00134860

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.76691747
Iteration 2/25 | Loss: 0.00215042
Iteration 3/25 | Loss: 0.00215034
Iteration 4/25 | Loss: 0.00215034
Iteration 5/25 | Loss: 0.00215034
Iteration 6/25 | Loss: 0.00215034
Iteration 7/25 | Loss: 0.00215034
Iteration 8/25 | Loss: 0.00215034
Iteration 9/25 | Loss: 0.00215034
Iteration 10/25 | Loss: 0.00215034
Iteration 11/25 | Loss: 0.00215034
Iteration 12/25 | Loss: 0.00215034
Iteration 13/25 | Loss: 0.00215034
Iteration 14/25 | Loss: 0.00215034
Iteration 15/25 | Loss: 0.00215034
Iteration 16/25 | Loss: 0.00215034
Iteration 17/25 | Loss: 0.00215034
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0021503360476344824, 0.0021503360476344824, 0.0021503360476344824, 0.0021503360476344824, 0.0021503360476344824]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0021503360476344824

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00215034
Iteration 2/1000 | Loss: 0.00003987
Iteration 3/1000 | Loss: 0.00002991
Iteration 4/1000 | Loss: 0.00002432
Iteration 5/1000 | Loss: 0.00002254
Iteration 6/1000 | Loss: 0.00003477
Iteration 7/1000 | Loss: 0.00002427
Iteration 8/1000 | Loss: 0.00002657
Iteration 9/1000 | Loss: 0.00001912
Iteration 10/1000 | Loss: 0.00001873
Iteration 11/1000 | Loss: 0.00001843
Iteration 12/1000 | Loss: 0.00001800
Iteration 13/1000 | Loss: 0.00001773
Iteration 14/1000 | Loss: 0.00001772
Iteration 15/1000 | Loss: 0.00001754
Iteration 16/1000 | Loss: 0.00001743
Iteration 17/1000 | Loss: 0.00001731
Iteration 18/1000 | Loss: 0.00001731
Iteration 19/1000 | Loss: 0.00001716
Iteration 20/1000 | Loss: 0.00001715
Iteration 21/1000 | Loss: 0.00001711
Iteration 22/1000 | Loss: 0.00001711
Iteration 23/1000 | Loss: 0.00001703
Iteration 24/1000 | Loss: 0.00001691
Iteration 25/1000 | Loss: 0.00001689
Iteration 26/1000 | Loss: 0.00001688
Iteration 27/1000 | Loss: 0.00001687
Iteration 28/1000 | Loss: 0.00001687
Iteration 29/1000 | Loss: 0.00001686
Iteration 30/1000 | Loss: 0.00001686
Iteration 31/1000 | Loss: 0.00001685
Iteration 32/1000 | Loss: 0.00001685
Iteration 33/1000 | Loss: 0.00001684
Iteration 34/1000 | Loss: 0.00001684
Iteration 35/1000 | Loss: 0.00001683
Iteration 36/1000 | Loss: 0.00001683
Iteration 37/1000 | Loss: 0.00001683
Iteration 38/1000 | Loss: 0.00001682
Iteration 39/1000 | Loss: 0.00001682
Iteration 40/1000 | Loss: 0.00001682
Iteration 41/1000 | Loss: 0.00001681
Iteration 42/1000 | Loss: 0.00001681
Iteration 43/1000 | Loss: 0.00001681
Iteration 44/1000 | Loss: 0.00001680
Iteration 45/1000 | Loss: 0.00001680
Iteration 46/1000 | Loss: 0.00001680
Iteration 47/1000 | Loss: 0.00001680
Iteration 48/1000 | Loss: 0.00001680
Iteration 49/1000 | Loss: 0.00001680
Iteration 50/1000 | Loss: 0.00001680
Iteration 51/1000 | Loss: 0.00001680
Iteration 52/1000 | Loss: 0.00001680
Iteration 53/1000 | Loss: 0.00001679
Iteration 54/1000 | Loss: 0.00001679
Iteration 55/1000 | Loss: 0.00001679
Iteration 56/1000 | Loss: 0.00001678
Iteration 57/1000 | Loss: 0.00001678
Iteration 58/1000 | Loss: 0.00001678
Iteration 59/1000 | Loss: 0.00001677
Iteration 60/1000 | Loss: 0.00001677
Iteration 61/1000 | Loss: 0.00001677
Iteration 62/1000 | Loss: 0.00001677
Iteration 63/1000 | Loss: 0.00001676
Iteration 64/1000 | Loss: 0.00001675
Iteration 65/1000 | Loss: 0.00001675
Iteration 66/1000 | Loss: 0.00001675
Iteration 67/1000 | Loss: 0.00001675
Iteration 68/1000 | Loss: 0.00001675
Iteration 69/1000 | Loss: 0.00001675
Iteration 70/1000 | Loss: 0.00001674
Iteration 71/1000 | Loss: 0.00001673
Iteration 72/1000 | Loss: 0.00001673
Iteration 73/1000 | Loss: 0.00001673
Iteration 74/1000 | Loss: 0.00001672
Iteration 75/1000 | Loss: 0.00001672
Iteration 76/1000 | Loss: 0.00001672
Iteration 77/1000 | Loss: 0.00001672
Iteration 78/1000 | Loss: 0.00001672
Iteration 79/1000 | Loss: 0.00001672
Iteration 80/1000 | Loss: 0.00001672
Iteration 81/1000 | Loss: 0.00001672
Iteration 82/1000 | Loss: 0.00001672
Iteration 83/1000 | Loss: 0.00001672
Iteration 84/1000 | Loss: 0.00001671
Iteration 85/1000 | Loss: 0.00001671
Iteration 86/1000 | Loss: 0.00001671
Iteration 87/1000 | Loss: 0.00001670
Iteration 88/1000 | Loss: 0.00001670
Iteration 89/1000 | Loss: 0.00001670
Iteration 90/1000 | Loss: 0.00001670
Iteration 91/1000 | Loss: 0.00001669
Iteration 92/1000 | Loss: 0.00001669
Iteration 93/1000 | Loss: 0.00001669
Iteration 94/1000 | Loss: 0.00001669
Iteration 95/1000 | Loss: 0.00001668
Iteration 96/1000 | Loss: 0.00001668
Iteration 97/1000 | Loss: 0.00001668
Iteration 98/1000 | Loss: 0.00001667
Iteration 99/1000 | Loss: 0.00001667
Iteration 100/1000 | Loss: 0.00001667
Iteration 101/1000 | Loss: 0.00001666
Iteration 102/1000 | Loss: 0.00001666
Iteration 103/1000 | Loss: 0.00001666
Iteration 104/1000 | Loss: 0.00001666
Iteration 105/1000 | Loss: 0.00001666
Iteration 106/1000 | Loss: 0.00001666
Iteration 107/1000 | Loss: 0.00001666
Iteration 108/1000 | Loss: 0.00001665
Iteration 109/1000 | Loss: 0.00001665
Iteration 110/1000 | Loss: 0.00001665
Iteration 111/1000 | Loss: 0.00001665
Iteration 112/1000 | Loss: 0.00001664
Iteration 113/1000 | Loss: 0.00001664
Iteration 114/1000 | Loss: 0.00001664
Iteration 115/1000 | Loss: 0.00001664
Iteration 116/1000 | Loss: 0.00001663
Iteration 117/1000 | Loss: 0.00001663
Iteration 118/1000 | Loss: 0.00001663
Iteration 119/1000 | Loss: 0.00001663
Iteration 120/1000 | Loss: 0.00001663
Iteration 121/1000 | Loss: 0.00001663
Iteration 122/1000 | Loss: 0.00001663
Iteration 123/1000 | Loss: 0.00001663
Iteration 124/1000 | Loss: 0.00001662
Iteration 125/1000 | Loss: 0.00001662
Iteration 126/1000 | Loss: 0.00001662
Iteration 127/1000 | Loss: 0.00001662
Iteration 128/1000 | Loss: 0.00001662
Iteration 129/1000 | Loss: 0.00001662
Iteration 130/1000 | Loss: 0.00001662
Iteration 131/1000 | Loss: 0.00001662
Iteration 132/1000 | Loss: 0.00001661
Iteration 133/1000 | Loss: 0.00001661
Iteration 134/1000 | Loss: 0.00001661
Iteration 135/1000 | Loss: 0.00001661
Iteration 136/1000 | Loss: 0.00001660
Iteration 137/1000 | Loss: 0.00001660
Iteration 138/1000 | Loss: 0.00001660
Iteration 139/1000 | Loss: 0.00001660
Iteration 140/1000 | Loss: 0.00001660
Iteration 141/1000 | Loss: 0.00001660
Iteration 142/1000 | Loss: 0.00001659
Iteration 143/1000 | Loss: 0.00001659
Iteration 144/1000 | Loss: 0.00001659
Iteration 145/1000 | Loss: 0.00001659
Iteration 146/1000 | Loss: 0.00001658
Iteration 147/1000 | Loss: 0.00001658
Iteration 148/1000 | Loss: 0.00001658
Iteration 149/1000 | Loss: 0.00001658
Iteration 150/1000 | Loss: 0.00001658
Iteration 151/1000 | Loss: 0.00001658
Iteration 152/1000 | Loss: 0.00001658
Iteration 153/1000 | Loss: 0.00001658
Iteration 154/1000 | Loss: 0.00001658
Iteration 155/1000 | Loss: 0.00001658
Iteration 156/1000 | Loss: 0.00001658
Iteration 157/1000 | Loss: 0.00001657
Iteration 158/1000 | Loss: 0.00001657
Iteration 159/1000 | Loss: 0.00001657
Iteration 160/1000 | Loss: 0.00001657
Iteration 161/1000 | Loss: 0.00001657
Iteration 162/1000 | Loss: 0.00001656
Iteration 163/1000 | Loss: 0.00001656
Iteration 164/1000 | Loss: 0.00001656
Iteration 165/1000 | Loss: 0.00001656
Iteration 166/1000 | Loss: 0.00001655
Iteration 167/1000 | Loss: 0.00001655
Iteration 168/1000 | Loss: 0.00001655
Iteration 169/1000 | Loss: 0.00001655
Iteration 170/1000 | Loss: 0.00001655
Iteration 171/1000 | Loss: 0.00001655
Iteration 172/1000 | Loss: 0.00001655
Iteration 173/1000 | Loss: 0.00001655
Iteration 174/1000 | Loss: 0.00001655
Iteration 175/1000 | Loss: 0.00001655
Iteration 176/1000 | Loss: 0.00001655
Iteration 177/1000 | Loss: 0.00001655
Iteration 178/1000 | Loss: 0.00001655
Iteration 179/1000 | Loss: 0.00001655
Iteration 180/1000 | Loss: 0.00001655
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 180. Stopping optimization.
Last 5 losses: [1.6552157831029035e-05, 1.6552157831029035e-05, 1.6552157831029035e-05, 1.6552157831029035e-05, 1.6552157831029035e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6552157831029035e-05

Optimization complete. Final v2v error: 3.4583799839019775 mm

Highest mean error: 4.400033473968506 mm for frame 239

Lowest mean error: 2.877899169921875 mm for frame 135

Saving results

Total time: 75.95883011817932
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1087/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1087.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1087
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00857454
Iteration 2/25 | Loss: 0.00146610
Iteration 3/25 | Loss: 0.00137322
Iteration 4/25 | Loss: 0.00136273
Iteration 5/25 | Loss: 0.00136002
Iteration 6/25 | Loss: 0.00135983
Iteration 7/25 | Loss: 0.00135983
Iteration 8/25 | Loss: 0.00135983
Iteration 9/25 | Loss: 0.00135983
Iteration 10/25 | Loss: 0.00135983
Iteration 11/25 | Loss: 0.00135983
Iteration 12/25 | Loss: 0.00135983
Iteration 13/25 | Loss: 0.00135983
Iteration 14/25 | Loss: 0.00135983
Iteration 15/25 | Loss: 0.00135983
Iteration 16/25 | Loss: 0.00135983
Iteration 17/25 | Loss: 0.00135983
Iteration 18/25 | Loss: 0.00135983
Iteration 19/25 | Loss: 0.00135983
Iteration 20/25 | Loss: 0.00135983
Iteration 21/25 | Loss: 0.00135983
Iteration 22/25 | Loss: 0.00135983
Iteration 23/25 | Loss: 0.00135983
Iteration 24/25 | Loss: 0.00135983
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.001359830959700048, 0.001359830959700048, 0.001359830959700048, 0.001359830959700048, 0.001359830959700048]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001359830959700048

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.36450458
Iteration 2/25 | Loss: 0.00187509
Iteration 3/25 | Loss: 0.00187508
Iteration 4/25 | Loss: 0.00187508
Iteration 5/25 | Loss: 0.00187508
Iteration 6/25 | Loss: 0.00187508
Iteration 7/25 | Loss: 0.00187508
Iteration 8/25 | Loss: 0.00187508
Iteration 9/25 | Loss: 0.00187508
Iteration 10/25 | Loss: 0.00187508
Iteration 11/25 | Loss: 0.00187508
Iteration 12/25 | Loss: 0.00187508
Iteration 13/25 | Loss: 0.00187508
Iteration 14/25 | Loss: 0.00187508
Iteration 15/25 | Loss: 0.00187508
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0018750790040940046, 0.0018750790040940046, 0.0018750790040940046, 0.0018750790040940046, 0.0018750790040940046]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018750790040940046

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00187508
Iteration 2/1000 | Loss: 0.00002561
Iteration 3/1000 | Loss: 0.00001822
Iteration 4/1000 | Loss: 0.00001636
Iteration 5/1000 | Loss: 0.00001532
Iteration 6/1000 | Loss: 0.00001481
Iteration 7/1000 | Loss: 0.00001421
Iteration 8/1000 | Loss: 0.00001391
Iteration 9/1000 | Loss: 0.00001363
Iteration 10/1000 | Loss: 0.00001334
Iteration 11/1000 | Loss: 0.00001323
Iteration 12/1000 | Loss: 0.00001314
Iteration 13/1000 | Loss: 0.00001305
Iteration 14/1000 | Loss: 0.00001304
Iteration 15/1000 | Loss: 0.00001303
Iteration 16/1000 | Loss: 0.00001287
Iteration 17/1000 | Loss: 0.00001287
Iteration 18/1000 | Loss: 0.00001282
Iteration 19/1000 | Loss: 0.00001282
Iteration 20/1000 | Loss: 0.00001268
Iteration 21/1000 | Loss: 0.00001263
Iteration 22/1000 | Loss: 0.00001261
Iteration 23/1000 | Loss: 0.00001260
Iteration 24/1000 | Loss: 0.00001259
Iteration 25/1000 | Loss: 0.00001254
Iteration 26/1000 | Loss: 0.00001253
Iteration 27/1000 | Loss: 0.00001248
Iteration 28/1000 | Loss: 0.00001244
Iteration 29/1000 | Loss: 0.00001244
Iteration 30/1000 | Loss: 0.00001243
Iteration 31/1000 | Loss: 0.00001242
Iteration 32/1000 | Loss: 0.00001242
Iteration 33/1000 | Loss: 0.00001242
Iteration 34/1000 | Loss: 0.00001240
Iteration 35/1000 | Loss: 0.00001240
Iteration 36/1000 | Loss: 0.00001239
Iteration 37/1000 | Loss: 0.00001236
Iteration 38/1000 | Loss: 0.00001235
Iteration 39/1000 | Loss: 0.00001234
Iteration 40/1000 | Loss: 0.00001233
Iteration 41/1000 | Loss: 0.00001233
Iteration 42/1000 | Loss: 0.00001233
Iteration 43/1000 | Loss: 0.00001232
Iteration 44/1000 | Loss: 0.00001232
Iteration 45/1000 | Loss: 0.00001232
Iteration 46/1000 | Loss: 0.00001230
Iteration 47/1000 | Loss: 0.00001228
Iteration 48/1000 | Loss: 0.00001224
Iteration 49/1000 | Loss: 0.00001224
Iteration 50/1000 | Loss: 0.00001224
Iteration 51/1000 | Loss: 0.00001223
Iteration 52/1000 | Loss: 0.00001220
Iteration 53/1000 | Loss: 0.00001220
Iteration 54/1000 | Loss: 0.00001219
Iteration 55/1000 | Loss: 0.00001218
Iteration 56/1000 | Loss: 0.00001218
Iteration 57/1000 | Loss: 0.00001217
Iteration 58/1000 | Loss: 0.00001217
Iteration 59/1000 | Loss: 0.00001216
Iteration 60/1000 | Loss: 0.00001216
Iteration 61/1000 | Loss: 0.00001214
Iteration 62/1000 | Loss: 0.00001213
Iteration 63/1000 | Loss: 0.00001212
Iteration 64/1000 | Loss: 0.00001212
Iteration 65/1000 | Loss: 0.00001211
Iteration 66/1000 | Loss: 0.00001211
Iteration 67/1000 | Loss: 0.00001211
Iteration 68/1000 | Loss: 0.00001211
Iteration 69/1000 | Loss: 0.00001210
Iteration 70/1000 | Loss: 0.00001208
Iteration 71/1000 | Loss: 0.00001208
Iteration 72/1000 | Loss: 0.00001208
Iteration 73/1000 | Loss: 0.00001207
Iteration 74/1000 | Loss: 0.00001207
Iteration 75/1000 | Loss: 0.00001207
Iteration 76/1000 | Loss: 0.00001207
Iteration 77/1000 | Loss: 0.00001207
Iteration 78/1000 | Loss: 0.00001207
Iteration 79/1000 | Loss: 0.00001207
Iteration 80/1000 | Loss: 0.00001207
Iteration 81/1000 | Loss: 0.00001207
Iteration 82/1000 | Loss: 0.00001206
Iteration 83/1000 | Loss: 0.00001206
Iteration 84/1000 | Loss: 0.00001206
Iteration 85/1000 | Loss: 0.00001205
Iteration 86/1000 | Loss: 0.00001205
Iteration 87/1000 | Loss: 0.00001205
Iteration 88/1000 | Loss: 0.00001205
Iteration 89/1000 | Loss: 0.00001204
Iteration 90/1000 | Loss: 0.00001204
Iteration 91/1000 | Loss: 0.00001203
Iteration 92/1000 | Loss: 0.00001203
Iteration 93/1000 | Loss: 0.00001203
Iteration 94/1000 | Loss: 0.00001203
Iteration 95/1000 | Loss: 0.00001203
Iteration 96/1000 | Loss: 0.00001203
Iteration 97/1000 | Loss: 0.00001203
Iteration 98/1000 | Loss: 0.00001202
Iteration 99/1000 | Loss: 0.00001202
Iteration 100/1000 | Loss: 0.00001202
Iteration 101/1000 | Loss: 0.00001202
Iteration 102/1000 | Loss: 0.00001201
Iteration 103/1000 | Loss: 0.00001201
Iteration 104/1000 | Loss: 0.00001200
Iteration 105/1000 | Loss: 0.00001200
Iteration 106/1000 | Loss: 0.00001200
Iteration 107/1000 | Loss: 0.00001199
Iteration 108/1000 | Loss: 0.00001199
Iteration 109/1000 | Loss: 0.00001199
Iteration 110/1000 | Loss: 0.00001199
Iteration 111/1000 | Loss: 0.00001199
Iteration 112/1000 | Loss: 0.00001199
Iteration 113/1000 | Loss: 0.00001198
Iteration 114/1000 | Loss: 0.00001198
Iteration 115/1000 | Loss: 0.00001198
Iteration 116/1000 | Loss: 0.00001198
Iteration 117/1000 | Loss: 0.00001197
Iteration 118/1000 | Loss: 0.00001197
Iteration 119/1000 | Loss: 0.00001197
Iteration 120/1000 | Loss: 0.00001197
Iteration 121/1000 | Loss: 0.00001197
Iteration 122/1000 | Loss: 0.00001197
Iteration 123/1000 | Loss: 0.00001197
Iteration 124/1000 | Loss: 0.00001196
Iteration 125/1000 | Loss: 0.00001196
Iteration 126/1000 | Loss: 0.00001196
Iteration 127/1000 | Loss: 0.00001196
Iteration 128/1000 | Loss: 0.00001196
Iteration 129/1000 | Loss: 0.00001195
Iteration 130/1000 | Loss: 0.00001195
Iteration 131/1000 | Loss: 0.00001195
Iteration 132/1000 | Loss: 0.00001194
Iteration 133/1000 | Loss: 0.00001194
Iteration 134/1000 | Loss: 0.00001193
Iteration 135/1000 | Loss: 0.00001193
Iteration 136/1000 | Loss: 0.00001193
Iteration 137/1000 | Loss: 0.00001193
Iteration 138/1000 | Loss: 0.00001193
Iteration 139/1000 | Loss: 0.00001192
Iteration 140/1000 | Loss: 0.00001192
Iteration 141/1000 | Loss: 0.00001192
Iteration 142/1000 | Loss: 0.00001192
Iteration 143/1000 | Loss: 0.00001191
Iteration 144/1000 | Loss: 0.00001191
Iteration 145/1000 | Loss: 0.00001191
Iteration 146/1000 | Loss: 0.00001191
Iteration 147/1000 | Loss: 0.00001191
Iteration 148/1000 | Loss: 0.00001191
Iteration 149/1000 | Loss: 0.00001191
Iteration 150/1000 | Loss: 0.00001191
Iteration 151/1000 | Loss: 0.00001191
Iteration 152/1000 | Loss: 0.00001191
Iteration 153/1000 | Loss: 0.00001191
Iteration 154/1000 | Loss: 0.00001191
Iteration 155/1000 | Loss: 0.00001191
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 155. Stopping optimization.
Last 5 losses: [1.1905036444659345e-05, 1.1905036444659345e-05, 1.1905036444659345e-05, 1.1905036444659345e-05, 1.1905036444659345e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1905036444659345e-05

Optimization complete. Final v2v error: 2.936424732208252 mm

Highest mean error: 3.686654806137085 mm for frame 58

Lowest mean error: 2.733754873275757 mm for frame 136

Saving results

Total time: 42.31344556808472
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_carina_posed_010/1035/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1035.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_carina_posed_010/1035
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00358187
Iteration 2/25 | Loss: 0.00137424
Iteration 3/25 | Loss: 0.00132159
Iteration 4/25 | Loss: 0.00131395
Iteration 5/25 | Loss: 0.00131033
Iteration 6/25 | Loss: 0.00130979
Iteration 7/25 | Loss: 0.00130979
Iteration 8/25 | Loss: 0.00130979
Iteration 9/25 | Loss: 0.00130979
Iteration 10/25 | Loss: 0.00130979
Iteration 11/25 | Loss: 0.00130979
Iteration 12/25 | Loss: 0.00130979
Iteration 13/25 | Loss: 0.00130979
Iteration 14/25 | Loss: 0.00130979
Iteration 15/25 | Loss: 0.00130979
Iteration 16/25 | Loss: 0.00130979
Iteration 17/25 | Loss: 0.00130979
Iteration 18/25 | Loss: 0.00130979
Iteration 19/25 | Loss: 0.00130979
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0013097894843667746, 0.0013097894843667746, 0.0013097894843667746, 0.0013097894843667746, 0.0013097894843667746]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013097894843667746

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27211463
Iteration 2/25 | Loss: 0.00208012
Iteration 3/25 | Loss: 0.00208012
Iteration 4/25 | Loss: 0.00208012
Iteration 5/25 | Loss: 0.00208012
Iteration 6/25 | Loss: 0.00208012
Iteration 7/25 | Loss: 0.00208012
Iteration 8/25 | Loss: 0.00208012
Iteration 9/25 | Loss: 0.00208012
Iteration 10/25 | Loss: 0.00208012
Iteration 11/25 | Loss: 0.00208011
Iteration 12/25 | Loss: 0.00208011
Iteration 13/25 | Loss: 0.00208011
Iteration 14/25 | Loss: 0.00208011
Iteration 15/25 | Loss: 0.00208011
Iteration 16/25 | Loss: 0.00208011
Iteration 17/25 | Loss: 0.00208011
Iteration 18/25 | Loss: 0.00208011
Iteration 19/25 | Loss: 0.00208011
Iteration 20/25 | Loss: 0.00208011
Iteration 21/25 | Loss: 0.00208011
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0020801143255084753, 0.0020801143255084753, 0.0020801143255084753, 0.0020801143255084753, 0.0020801143255084753]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020801143255084753

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00208011
Iteration 2/1000 | Loss: 0.00002288
Iteration 3/1000 | Loss: 0.00001573
Iteration 4/1000 | Loss: 0.00001371
Iteration 5/1000 | Loss: 0.00001254
Iteration 6/1000 | Loss: 0.00001169
Iteration 7/1000 | Loss: 0.00001113
Iteration 8/1000 | Loss: 0.00001092
Iteration 9/1000 | Loss: 0.00001068
Iteration 10/1000 | Loss: 0.00001037
Iteration 11/1000 | Loss: 0.00001037
Iteration 12/1000 | Loss: 0.00001034
Iteration 13/1000 | Loss: 0.00001029
Iteration 14/1000 | Loss: 0.00001028
Iteration 15/1000 | Loss: 0.00001024
Iteration 16/1000 | Loss: 0.00001012
Iteration 17/1000 | Loss: 0.00001003
Iteration 18/1000 | Loss: 0.00001000
Iteration 19/1000 | Loss: 0.00000999
Iteration 20/1000 | Loss: 0.00000998
Iteration 21/1000 | Loss: 0.00000997
Iteration 22/1000 | Loss: 0.00000997
Iteration 23/1000 | Loss: 0.00000996
Iteration 24/1000 | Loss: 0.00000991
Iteration 25/1000 | Loss: 0.00000985
Iteration 26/1000 | Loss: 0.00000981
Iteration 27/1000 | Loss: 0.00000980
Iteration 28/1000 | Loss: 0.00000979
Iteration 29/1000 | Loss: 0.00000978
Iteration 30/1000 | Loss: 0.00000974
Iteration 31/1000 | Loss: 0.00000971
Iteration 32/1000 | Loss: 0.00000971
Iteration 33/1000 | Loss: 0.00000971
Iteration 34/1000 | Loss: 0.00000971
Iteration 35/1000 | Loss: 0.00000971
Iteration 36/1000 | Loss: 0.00000971
Iteration 37/1000 | Loss: 0.00000967
Iteration 38/1000 | Loss: 0.00000967
Iteration 39/1000 | Loss: 0.00000966
Iteration 40/1000 | Loss: 0.00000964
Iteration 41/1000 | Loss: 0.00000964
Iteration 42/1000 | Loss: 0.00000963
Iteration 43/1000 | Loss: 0.00000963
Iteration 44/1000 | Loss: 0.00000962
Iteration 45/1000 | Loss: 0.00000961
Iteration 46/1000 | Loss: 0.00000960
Iteration 47/1000 | Loss: 0.00000960
Iteration 48/1000 | Loss: 0.00000959
Iteration 49/1000 | Loss: 0.00000959
Iteration 50/1000 | Loss: 0.00000959
Iteration 51/1000 | Loss: 0.00000958
Iteration 52/1000 | Loss: 0.00000958
Iteration 53/1000 | Loss: 0.00000958
Iteration 54/1000 | Loss: 0.00000957
Iteration 55/1000 | Loss: 0.00000956
Iteration 56/1000 | Loss: 0.00000956
Iteration 57/1000 | Loss: 0.00000955
Iteration 58/1000 | Loss: 0.00000955
Iteration 59/1000 | Loss: 0.00000954
Iteration 60/1000 | Loss: 0.00000954
Iteration 61/1000 | Loss: 0.00000954
Iteration 62/1000 | Loss: 0.00000953
Iteration 63/1000 | Loss: 0.00000953
Iteration 64/1000 | Loss: 0.00000953
Iteration 65/1000 | Loss: 0.00000952
Iteration 66/1000 | Loss: 0.00000952
Iteration 67/1000 | Loss: 0.00000952
Iteration 68/1000 | Loss: 0.00000951
Iteration 69/1000 | Loss: 0.00000949
Iteration 70/1000 | Loss: 0.00000948
Iteration 71/1000 | Loss: 0.00000948
Iteration 72/1000 | Loss: 0.00000947
Iteration 73/1000 | Loss: 0.00000947
Iteration 74/1000 | Loss: 0.00000947
Iteration 75/1000 | Loss: 0.00000947
Iteration 76/1000 | Loss: 0.00000947
Iteration 77/1000 | Loss: 0.00000946
Iteration 78/1000 | Loss: 0.00000946
Iteration 79/1000 | Loss: 0.00000946
Iteration 80/1000 | Loss: 0.00000946
Iteration 81/1000 | Loss: 0.00000945
Iteration 82/1000 | Loss: 0.00000945
Iteration 83/1000 | Loss: 0.00000945
Iteration 84/1000 | Loss: 0.00000945
Iteration 85/1000 | Loss: 0.00000944
Iteration 86/1000 | Loss: 0.00000944
Iteration 87/1000 | Loss: 0.00000944
Iteration 88/1000 | Loss: 0.00000944
Iteration 89/1000 | Loss: 0.00000943
Iteration 90/1000 | Loss: 0.00000943
Iteration 91/1000 | Loss: 0.00000943
Iteration 92/1000 | Loss: 0.00000942
Iteration 93/1000 | Loss: 0.00000942
Iteration 94/1000 | Loss: 0.00000942
Iteration 95/1000 | Loss: 0.00000941
Iteration 96/1000 | Loss: 0.00000941
Iteration 97/1000 | Loss: 0.00000941
Iteration 98/1000 | Loss: 0.00000941
Iteration 99/1000 | Loss: 0.00000941
Iteration 100/1000 | Loss: 0.00000941
Iteration 101/1000 | Loss: 0.00000941
Iteration 102/1000 | Loss: 0.00000941
Iteration 103/1000 | Loss: 0.00000941
Iteration 104/1000 | Loss: 0.00000940
Iteration 105/1000 | Loss: 0.00000940
Iteration 106/1000 | Loss: 0.00000940
Iteration 107/1000 | Loss: 0.00000940
Iteration 108/1000 | Loss: 0.00000940
Iteration 109/1000 | Loss: 0.00000940
Iteration 110/1000 | Loss: 0.00000940
Iteration 111/1000 | Loss: 0.00000940
Iteration 112/1000 | Loss: 0.00000940
Iteration 113/1000 | Loss: 0.00000940
Iteration 114/1000 | Loss: 0.00000940
Iteration 115/1000 | Loss: 0.00000940
Iteration 116/1000 | Loss: 0.00000939
Iteration 117/1000 | Loss: 0.00000939
Iteration 118/1000 | Loss: 0.00000939
Iteration 119/1000 | Loss: 0.00000939
Iteration 120/1000 | Loss: 0.00000939
Iteration 121/1000 | Loss: 0.00000939
Iteration 122/1000 | Loss: 0.00000939
Iteration 123/1000 | Loss: 0.00000939
Iteration 124/1000 | Loss: 0.00000939
Iteration 125/1000 | Loss: 0.00000939
Iteration 126/1000 | Loss: 0.00000938
Iteration 127/1000 | Loss: 0.00000938
Iteration 128/1000 | Loss: 0.00000938
Iteration 129/1000 | Loss: 0.00000938
Iteration 130/1000 | Loss: 0.00000938
Iteration 131/1000 | Loss: 0.00000938
Iteration 132/1000 | Loss: 0.00000938
Iteration 133/1000 | Loss: 0.00000937
Iteration 134/1000 | Loss: 0.00000937
Iteration 135/1000 | Loss: 0.00000937
Iteration 136/1000 | Loss: 0.00000937
Iteration 137/1000 | Loss: 0.00000937
Iteration 138/1000 | Loss: 0.00000937
Iteration 139/1000 | Loss: 0.00000937
Iteration 140/1000 | Loss: 0.00000936
Iteration 141/1000 | Loss: 0.00000936
Iteration 142/1000 | Loss: 0.00000936
Iteration 143/1000 | Loss: 0.00000936
Iteration 144/1000 | Loss: 0.00000936
Iteration 145/1000 | Loss: 0.00000936
Iteration 146/1000 | Loss: 0.00000936
Iteration 147/1000 | Loss: 0.00000935
Iteration 148/1000 | Loss: 0.00000935
Iteration 149/1000 | Loss: 0.00000935
Iteration 150/1000 | Loss: 0.00000935
Iteration 151/1000 | Loss: 0.00000934
Iteration 152/1000 | Loss: 0.00000934
Iteration 153/1000 | Loss: 0.00000934
Iteration 154/1000 | Loss: 0.00000934
Iteration 155/1000 | Loss: 0.00000934
Iteration 156/1000 | Loss: 0.00000934
Iteration 157/1000 | Loss: 0.00000934
Iteration 158/1000 | Loss: 0.00000934
Iteration 159/1000 | Loss: 0.00000934
Iteration 160/1000 | Loss: 0.00000933
Iteration 161/1000 | Loss: 0.00000933
Iteration 162/1000 | Loss: 0.00000933
Iteration 163/1000 | Loss: 0.00000933
Iteration 164/1000 | Loss: 0.00000933
Iteration 165/1000 | Loss: 0.00000933
Iteration 166/1000 | Loss: 0.00000933
Iteration 167/1000 | Loss: 0.00000933
Iteration 168/1000 | Loss: 0.00000933
Iteration 169/1000 | Loss: 0.00000933
Iteration 170/1000 | Loss: 0.00000933
Iteration 171/1000 | Loss: 0.00000933
Iteration 172/1000 | Loss: 0.00000933
Iteration 173/1000 | Loss: 0.00000932
Iteration 174/1000 | Loss: 0.00000932
Iteration 175/1000 | Loss: 0.00000932
Iteration 176/1000 | Loss: 0.00000932
Iteration 177/1000 | Loss: 0.00000932
Iteration 178/1000 | Loss: 0.00000932
Iteration 179/1000 | Loss: 0.00000931
Iteration 180/1000 | Loss: 0.00000931
Iteration 181/1000 | Loss: 0.00000931
Iteration 182/1000 | Loss: 0.00000930
Iteration 183/1000 | Loss: 0.00000930
Iteration 184/1000 | Loss: 0.00000930
Iteration 185/1000 | Loss: 0.00000930
Iteration 186/1000 | Loss: 0.00000930
Iteration 187/1000 | Loss: 0.00000929
Iteration 188/1000 | Loss: 0.00000929
Iteration 189/1000 | Loss: 0.00000929
Iteration 190/1000 | Loss: 0.00000929
Iteration 191/1000 | Loss: 0.00000929
Iteration 192/1000 | Loss: 0.00000929
Iteration 193/1000 | Loss: 0.00000928
Iteration 194/1000 | Loss: 0.00000928
Iteration 195/1000 | Loss: 0.00000927
Iteration 196/1000 | Loss: 0.00000927
Iteration 197/1000 | Loss: 0.00000927
Iteration 198/1000 | Loss: 0.00000927
Iteration 199/1000 | Loss: 0.00000926
Iteration 200/1000 | Loss: 0.00000926
Iteration 201/1000 | Loss: 0.00000926
Iteration 202/1000 | Loss: 0.00000926
Iteration 203/1000 | Loss: 0.00000926
Iteration 204/1000 | Loss: 0.00000926
Iteration 205/1000 | Loss: 0.00000926
Iteration 206/1000 | Loss: 0.00000925
Iteration 207/1000 | Loss: 0.00000925
Iteration 208/1000 | Loss: 0.00000925
Iteration 209/1000 | Loss: 0.00000925
Iteration 210/1000 | Loss: 0.00000925
Iteration 211/1000 | Loss: 0.00000925
Iteration 212/1000 | Loss: 0.00000925
Iteration 213/1000 | Loss: 0.00000925
Iteration 214/1000 | Loss: 0.00000925
Iteration 215/1000 | Loss: 0.00000925
Iteration 216/1000 | Loss: 0.00000924
Iteration 217/1000 | Loss: 0.00000924
Iteration 218/1000 | Loss: 0.00000924
Iteration 219/1000 | Loss: 0.00000924
Iteration 220/1000 | Loss: 0.00000924
Iteration 221/1000 | Loss: 0.00000923
Iteration 222/1000 | Loss: 0.00000923
Iteration 223/1000 | Loss: 0.00000923
Iteration 224/1000 | Loss: 0.00000923
Iteration 225/1000 | Loss: 0.00000923
Iteration 226/1000 | Loss: 0.00000922
Iteration 227/1000 | Loss: 0.00000922
Iteration 228/1000 | Loss: 0.00000922
Iteration 229/1000 | Loss: 0.00000922
Iteration 230/1000 | Loss: 0.00000922
Iteration 231/1000 | Loss: 0.00000922
Iteration 232/1000 | Loss: 0.00000922
Iteration 233/1000 | Loss: 0.00000922
Iteration 234/1000 | Loss: 0.00000922
Iteration 235/1000 | Loss: 0.00000922
Iteration 236/1000 | Loss: 0.00000922
Iteration 237/1000 | Loss: 0.00000922
Iteration 238/1000 | Loss: 0.00000921
Iteration 239/1000 | Loss: 0.00000921
Iteration 240/1000 | Loss: 0.00000921
Iteration 241/1000 | Loss: 0.00000921
Iteration 242/1000 | Loss: 0.00000921
Iteration 243/1000 | Loss: 0.00000921
Iteration 244/1000 | Loss: 0.00000921
Iteration 245/1000 | Loss: 0.00000921
Iteration 246/1000 | Loss: 0.00000921
Iteration 247/1000 | Loss: 0.00000921
Iteration 248/1000 | Loss: 0.00000921
Iteration 249/1000 | Loss: 0.00000921
Iteration 250/1000 | Loss: 0.00000921
Iteration 251/1000 | Loss: 0.00000921
Iteration 252/1000 | Loss: 0.00000921
Iteration 253/1000 | Loss: 0.00000920
Iteration 254/1000 | Loss: 0.00000920
Iteration 255/1000 | Loss: 0.00000920
Iteration 256/1000 | Loss: 0.00000920
Iteration 257/1000 | Loss: 0.00000920
Iteration 258/1000 | Loss: 0.00000920
Iteration 259/1000 | Loss: 0.00000920
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 259. Stopping optimization.
Last 5 losses: [9.204671187035274e-06, 9.204671187035274e-06, 9.204671187035274e-06, 9.204671187035274e-06, 9.204671187035274e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.204671187035274e-06

Optimization complete. Final v2v error: 2.6481120586395264 mm

Highest mean error: 2.9603826999664307 mm for frame 105

Lowest mean error: 2.4144387245178223 mm for frame 21

Saving results

Total time: 46.16207146644592

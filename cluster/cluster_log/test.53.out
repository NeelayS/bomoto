Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=53, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 2968-3023
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00773434
Iteration 2/25 | Loss: 0.00147513
Iteration 3/25 | Loss: 0.00099641
Iteration 4/25 | Loss: 0.00091859
Iteration 5/25 | Loss: 0.00087401
Iteration 6/25 | Loss: 0.00085878
Iteration 7/25 | Loss: 0.00085014
Iteration 8/25 | Loss: 0.00084479
Iteration 9/25 | Loss: 0.00084269
Iteration 10/25 | Loss: 0.00083903
Iteration 11/25 | Loss: 0.00083740
Iteration 12/25 | Loss: 0.00083706
Iteration 13/25 | Loss: 0.00083637
Iteration 14/25 | Loss: 0.00083585
Iteration 15/25 | Loss: 0.00083554
Iteration 16/25 | Loss: 0.00083548
Iteration 17/25 | Loss: 0.00083548
Iteration 18/25 | Loss: 0.00083547
Iteration 19/25 | Loss: 0.00083547
Iteration 20/25 | Loss: 0.00083547
Iteration 21/25 | Loss: 0.00083547
Iteration 22/25 | Loss: 0.00083547
Iteration 23/25 | Loss: 0.00083547
Iteration 24/25 | Loss: 0.00083547
Iteration 25/25 | Loss: 0.00083547

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.06985378
Iteration 2/25 | Loss: 0.00167149
Iteration 3/25 | Loss: 0.00167137
Iteration 4/25 | Loss: 0.00167137
Iteration 5/25 | Loss: 0.00167137
Iteration 6/25 | Loss: 0.00167137
Iteration 7/25 | Loss: 0.00167137
Iteration 8/25 | Loss: 0.00167137
Iteration 9/25 | Loss: 0.00167137
Iteration 10/25 | Loss: 0.00167137
Iteration 11/25 | Loss: 0.00167137
Iteration 12/25 | Loss: 0.00167137
Iteration 13/25 | Loss: 0.00167137
Iteration 14/25 | Loss: 0.00167137
Iteration 15/25 | Loss: 0.00167137
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0016713687218725681, 0.0016713687218725681, 0.0016713687218725681, 0.0016713687218725681, 0.0016713687218725681]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016713687218725681

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00167137
Iteration 2/1000 | Loss: 0.00011929
Iteration 3/1000 | Loss: 0.00029666
Iteration 4/1000 | Loss: 0.00008790
Iteration 5/1000 | Loss: 0.00003527
Iteration 6/1000 | Loss: 0.00003028
Iteration 7/1000 | Loss: 0.00002560
Iteration 8/1000 | Loss: 0.00002372
Iteration 9/1000 | Loss: 0.00002266
Iteration 10/1000 | Loss: 0.00002169
Iteration 11/1000 | Loss: 0.00002120
Iteration 12/1000 | Loss: 0.00002080
Iteration 13/1000 | Loss: 0.00002044
Iteration 14/1000 | Loss: 0.00002018
Iteration 15/1000 | Loss: 0.00001994
Iteration 16/1000 | Loss: 0.00001992
Iteration 17/1000 | Loss: 0.00001984
Iteration 18/1000 | Loss: 0.00001980
Iteration 19/1000 | Loss: 0.00001978
Iteration 20/1000 | Loss: 0.00001976
Iteration 21/1000 | Loss: 0.00001976
Iteration 22/1000 | Loss: 0.00001974
Iteration 23/1000 | Loss: 0.00001972
Iteration 24/1000 | Loss: 0.00001969
Iteration 25/1000 | Loss: 0.00001968
Iteration 26/1000 | Loss: 0.00001967
Iteration 27/1000 | Loss: 0.00001967
Iteration 28/1000 | Loss: 0.00001966
Iteration 29/1000 | Loss: 0.00001966
Iteration 30/1000 | Loss: 0.00001965
Iteration 31/1000 | Loss: 0.00001965
Iteration 32/1000 | Loss: 0.00001965
Iteration 33/1000 | Loss: 0.00001964
Iteration 34/1000 | Loss: 0.00001963
Iteration 35/1000 | Loss: 0.00001962
Iteration 36/1000 | Loss: 0.00001962
Iteration 37/1000 | Loss: 0.00001960
Iteration 38/1000 | Loss: 0.00001959
Iteration 39/1000 | Loss: 0.00001959
Iteration 40/1000 | Loss: 0.00001956
Iteration 41/1000 | Loss: 0.00001956
Iteration 42/1000 | Loss: 0.00001955
Iteration 43/1000 | Loss: 0.00002314
Iteration 44/1000 | Loss: 0.00001968
Iteration 45/1000 | Loss: 0.00001942
Iteration 46/1000 | Loss: 0.00001941
Iteration 47/1000 | Loss: 0.00001941
Iteration 48/1000 | Loss: 0.00001941
Iteration 49/1000 | Loss: 0.00001941
Iteration 50/1000 | Loss: 0.00001940
Iteration 51/1000 | Loss: 0.00001940
Iteration 52/1000 | Loss: 0.00001940
Iteration 53/1000 | Loss: 0.00001940
Iteration 54/1000 | Loss: 0.00001940
Iteration 55/1000 | Loss: 0.00001940
Iteration 56/1000 | Loss: 0.00001939
Iteration 57/1000 | Loss: 0.00001939
Iteration 58/1000 | Loss: 0.00001939
Iteration 59/1000 | Loss: 0.00001939
Iteration 60/1000 | Loss: 0.00001939
Iteration 61/1000 | Loss: 0.00001939
Iteration 62/1000 | Loss: 0.00001939
Iteration 63/1000 | Loss: 0.00001939
Iteration 64/1000 | Loss: 0.00001939
Iteration 65/1000 | Loss: 0.00001939
Iteration 66/1000 | Loss: 0.00001939
Iteration 67/1000 | Loss: 0.00001939
Iteration 68/1000 | Loss: 0.00001939
Iteration 69/1000 | Loss: 0.00001938
Iteration 70/1000 | Loss: 0.00001938
Iteration 71/1000 | Loss: 0.00001938
Iteration 72/1000 | Loss: 0.00001938
Iteration 73/1000 | Loss: 0.00001938
Iteration 74/1000 | Loss: 0.00001937
Iteration 75/1000 | Loss: 0.00001937
Iteration 76/1000 | Loss: 0.00001937
Iteration 77/1000 | Loss: 0.00001937
Iteration 78/1000 | Loss: 0.00001937
Iteration 79/1000 | Loss: 0.00001937
Iteration 80/1000 | Loss: 0.00001937
Iteration 81/1000 | Loss: 0.00001937
Iteration 82/1000 | Loss: 0.00001936
Iteration 83/1000 | Loss: 0.00001936
Iteration 84/1000 | Loss: 0.00001936
Iteration 85/1000 | Loss: 0.00001936
Iteration 86/1000 | Loss: 0.00001936
Iteration 87/1000 | Loss: 0.00001936
Iteration 88/1000 | Loss: 0.00001936
Iteration 89/1000 | Loss: 0.00001936
Iteration 90/1000 | Loss: 0.00001936
Iteration 91/1000 | Loss: 0.00001935
Iteration 92/1000 | Loss: 0.00001935
Iteration 93/1000 | Loss: 0.00001935
Iteration 94/1000 | Loss: 0.00001935
Iteration 95/1000 | Loss: 0.00001935
Iteration 96/1000 | Loss: 0.00001935
Iteration 97/1000 | Loss: 0.00001935
Iteration 98/1000 | Loss: 0.00001935
Iteration 99/1000 | Loss: 0.00001935
Iteration 100/1000 | Loss: 0.00001934
Iteration 101/1000 | Loss: 0.00001934
Iteration 102/1000 | Loss: 0.00001934
Iteration 103/1000 | Loss: 0.00001934
Iteration 104/1000 | Loss: 0.00001934
Iteration 105/1000 | Loss: 0.00001934
Iteration 106/1000 | Loss: 0.00001934
Iteration 107/1000 | Loss: 0.00001934
Iteration 108/1000 | Loss: 0.00001934
Iteration 109/1000 | Loss: 0.00001934
Iteration 110/1000 | Loss: 0.00001934
Iteration 111/1000 | Loss: 0.00001934
Iteration 112/1000 | Loss: 0.00001933
Iteration 113/1000 | Loss: 0.00001933
Iteration 114/1000 | Loss: 0.00001933
Iteration 115/1000 | Loss: 0.00001933
Iteration 116/1000 | Loss: 0.00001933
Iteration 117/1000 | Loss: 0.00001933
Iteration 118/1000 | Loss: 0.00001933
Iteration 119/1000 | Loss: 0.00001933
Iteration 120/1000 | Loss: 0.00001933
Iteration 121/1000 | Loss: 0.00001933
Iteration 122/1000 | Loss: 0.00001932
Iteration 123/1000 | Loss: 0.00001932
Iteration 124/1000 | Loss: 0.00001932
Iteration 125/1000 | Loss: 0.00001932
Iteration 126/1000 | Loss: 0.00001932
Iteration 127/1000 | Loss: 0.00001932
Iteration 128/1000 | Loss: 0.00001932
Iteration 129/1000 | Loss: 0.00001932
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [1.9324219465488568e-05, 1.9324219465488568e-05, 1.9324219465488568e-05, 1.9324219465488568e-05, 1.9324219465488568e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9324219465488568e-05

Optimization complete. Final v2v error: 3.5883374214172363 mm

Highest mean error: 5.794032573699951 mm for frame 193

Lowest mean error: 2.7904751300811768 mm for frame 117

Saving results

Total time: 72.61083054542542
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1077
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01091306
Iteration 2/25 | Loss: 0.00197761
Iteration 3/25 | Loss: 0.00135210
Iteration 4/25 | Loss: 0.00176717
Iteration 5/25 | Loss: 0.00129787
Iteration 6/25 | Loss: 0.00111696
Iteration 7/25 | Loss: 0.00093827
Iteration 8/25 | Loss: 0.00087210
Iteration 9/25 | Loss: 0.00086595
Iteration 10/25 | Loss: 0.00080322
Iteration 11/25 | Loss: 0.00078069
Iteration 12/25 | Loss: 0.00077241
Iteration 13/25 | Loss: 0.00076599
Iteration 14/25 | Loss: 0.00075863
Iteration 15/25 | Loss: 0.00075698
Iteration 16/25 | Loss: 0.00075074
Iteration 17/25 | Loss: 0.00075089
Iteration 18/25 | Loss: 0.00075031
Iteration 19/25 | Loss: 0.00075636
Iteration 20/25 | Loss: 0.00075931
Iteration 21/25 | Loss: 0.00075854
Iteration 22/25 | Loss: 0.00075339
Iteration 23/25 | Loss: 0.00075036
Iteration 24/25 | Loss: 0.00074836
Iteration 25/25 | Loss: 0.00075055

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60243523
Iteration 2/25 | Loss: 0.00371927
Iteration 3/25 | Loss: 0.00179444
Iteration 4/25 | Loss: 0.00178501
Iteration 5/25 | Loss: 0.00178501
Iteration 6/25 | Loss: 0.00178610
Iteration 7/25 | Loss: 0.00178501
Iteration 8/25 | Loss: 0.00178501
Iteration 9/25 | Loss: 0.00178501
Iteration 10/25 | Loss: 0.00178501
Iteration 11/25 | Loss: 0.00178501
Iteration 12/25 | Loss: 0.00178501
Iteration 13/25 | Loss: 0.00178501
Iteration 14/25 | Loss: 0.00178501
Iteration 15/25 | Loss: 0.00178501
Iteration 16/25 | Loss: 0.00178501
Iteration 17/25 | Loss: 0.00178501
Iteration 18/25 | Loss: 0.00178501
Iteration 19/25 | Loss: 0.00178501
Iteration 20/25 | Loss: 0.00178501
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0017850069561973214, 0.0017850069561973214, 0.0017850069561973214, 0.0017850069561973214, 0.0017850069561973214]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017850069561973214

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00178501
Iteration 2/1000 | Loss: 0.00279392
Iteration 3/1000 | Loss: 0.00400013
Iteration 4/1000 | Loss: 0.00046746
Iteration 5/1000 | Loss: 0.00057968
Iteration 6/1000 | Loss: 0.00038092
Iteration 7/1000 | Loss: 0.00063105
Iteration 8/1000 | Loss: 0.00047159
Iteration 9/1000 | Loss: 0.00249108
Iteration 10/1000 | Loss: 0.00174184
Iteration 11/1000 | Loss: 0.00011249
Iteration 12/1000 | Loss: 0.00023064
Iteration 13/1000 | Loss: 0.00019282
Iteration 14/1000 | Loss: 0.00023601
Iteration 15/1000 | Loss: 0.00035092
Iteration 16/1000 | Loss: 0.00195275
Iteration 17/1000 | Loss: 0.00023558
Iteration 18/1000 | Loss: 0.00012633
Iteration 19/1000 | Loss: 0.00005540
Iteration 20/1000 | Loss: 0.00002807
Iteration 21/1000 | Loss: 0.00002130
Iteration 22/1000 | Loss: 0.00002484
Iteration 23/1000 | Loss: 0.00002999
Iteration 24/1000 | Loss: 0.00001841
Iteration 25/1000 | Loss: 0.00031542
Iteration 26/1000 | Loss: 0.00015812
Iteration 27/1000 | Loss: 0.00024070
Iteration 28/1000 | Loss: 0.00017102
Iteration 29/1000 | Loss: 0.00027265
Iteration 30/1000 | Loss: 0.00010123
Iteration 31/1000 | Loss: 0.00003029
Iteration 32/1000 | Loss: 0.00009489
Iteration 33/1000 | Loss: 0.00011138
Iteration 34/1000 | Loss: 0.00002684
Iteration 35/1000 | Loss: 0.00006142
Iteration 36/1000 | Loss: 0.00001891
Iteration 37/1000 | Loss: 0.00001743
Iteration 38/1000 | Loss: 0.00003005
Iteration 39/1000 | Loss: 0.00004981
Iteration 40/1000 | Loss: 0.00013425
Iteration 41/1000 | Loss: 0.00001785
Iteration 42/1000 | Loss: 0.00001535
Iteration 43/1000 | Loss: 0.00001487
Iteration 44/1000 | Loss: 0.00002245
Iteration 45/1000 | Loss: 0.00003076
Iteration 46/1000 | Loss: 0.00001536
Iteration 47/1000 | Loss: 0.00003778
Iteration 48/1000 | Loss: 0.00001285
Iteration 49/1000 | Loss: 0.00001882
Iteration 50/1000 | Loss: 0.00008370
Iteration 51/1000 | Loss: 0.00002294
Iteration 52/1000 | Loss: 0.00001956
Iteration 53/1000 | Loss: 0.00009053
Iteration 54/1000 | Loss: 0.00001335
Iteration 55/1000 | Loss: 0.00001173
Iteration 56/1000 | Loss: 0.00001838
Iteration 57/1000 | Loss: 0.00002364
Iteration 58/1000 | Loss: 0.00001153
Iteration 59/1000 | Loss: 0.00001151
Iteration 60/1000 | Loss: 0.00001146
Iteration 61/1000 | Loss: 0.00001146
Iteration 62/1000 | Loss: 0.00001146
Iteration 63/1000 | Loss: 0.00001145
Iteration 64/1000 | Loss: 0.00001145
Iteration 65/1000 | Loss: 0.00001145
Iteration 66/1000 | Loss: 0.00001144
Iteration 67/1000 | Loss: 0.00001143
Iteration 68/1000 | Loss: 0.00001142
Iteration 69/1000 | Loss: 0.00001141
Iteration 70/1000 | Loss: 0.00001141
Iteration 71/1000 | Loss: 0.00001141
Iteration 72/1000 | Loss: 0.00001141
Iteration 73/1000 | Loss: 0.00001140
Iteration 74/1000 | Loss: 0.00001137
Iteration 75/1000 | Loss: 0.00001133
Iteration 76/1000 | Loss: 0.00001131
Iteration 77/1000 | Loss: 0.00001130
Iteration 78/1000 | Loss: 0.00001130
Iteration 79/1000 | Loss: 0.00001129
Iteration 80/1000 | Loss: 0.00001129
Iteration 81/1000 | Loss: 0.00001129
Iteration 82/1000 | Loss: 0.00001127
Iteration 83/1000 | Loss: 0.00001127
Iteration 84/1000 | Loss: 0.00002163
Iteration 85/1000 | Loss: 0.00001125
Iteration 86/1000 | Loss: 0.00001125
Iteration 87/1000 | Loss: 0.00001272
Iteration 88/1000 | Loss: 0.00001125
Iteration 89/1000 | Loss: 0.00001124
Iteration 90/1000 | Loss: 0.00001124
Iteration 91/1000 | Loss: 0.00001124
Iteration 92/1000 | Loss: 0.00001123
Iteration 93/1000 | Loss: 0.00001123
Iteration 94/1000 | Loss: 0.00001123
Iteration 95/1000 | Loss: 0.00001123
Iteration 96/1000 | Loss: 0.00001123
Iteration 97/1000 | Loss: 0.00001123
Iteration 98/1000 | Loss: 0.00001123
Iteration 99/1000 | Loss: 0.00001123
Iteration 100/1000 | Loss: 0.00001123
Iteration 101/1000 | Loss: 0.00001123
Iteration 102/1000 | Loss: 0.00001122
Iteration 103/1000 | Loss: 0.00001122
Iteration 104/1000 | Loss: 0.00001122
Iteration 105/1000 | Loss: 0.00001122
Iteration 106/1000 | Loss: 0.00001122
Iteration 107/1000 | Loss: 0.00001121
Iteration 108/1000 | Loss: 0.00001121
Iteration 109/1000 | Loss: 0.00001121
Iteration 110/1000 | Loss: 0.00001121
Iteration 111/1000 | Loss: 0.00001120
Iteration 112/1000 | Loss: 0.00001120
Iteration 113/1000 | Loss: 0.00001120
Iteration 114/1000 | Loss: 0.00001120
Iteration 115/1000 | Loss: 0.00001119
Iteration 116/1000 | Loss: 0.00001119
Iteration 117/1000 | Loss: 0.00001119
Iteration 118/1000 | Loss: 0.00001118
Iteration 119/1000 | Loss: 0.00001118
Iteration 120/1000 | Loss: 0.00001118
Iteration 121/1000 | Loss: 0.00001118
Iteration 122/1000 | Loss: 0.00001118
Iteration 123/1000 | Loss: 0.00001118
Iteration 124/1000 | Loss: 0.00001118
Iteration 125/1000 | Loss: 0.00001118
Iteration 126/1000 | Loss: 0.00001118
Iteration 127/1000 | Loss: 0.00001118
Iteration 128/1000 | Loss: 0.00001117
Iteration 129/1000 | Loss: 0.00001117
Iteration 130/1000 | Loss: 0.00002165
Iteration 131/1000 | Loss: 0.00001214
Iteration 132/1000 | Loss: 0.00001116
Iteration 133/1000 | Loss: 0.00001148
Iteration 134/1000 | Loss: 0.00001113
Iteration 135/1000 | Loss: 0.00001113
Iteration 136/1000 | Loss: 0.00001113
Iteration 137/1000 | Loss: 0.00001113
Iteration 138/1000 | Loss: 0.00001113
Iteration 139/1000 | Loss: 0.00001113
Iteration 140/1000 | Loss: 0.00001113
Iteration 141/1000 | Loss: 0.00001113
Iteration 142/1000 | Loss: 0.00001113
Iteration 143/1000 | Loss: 0.00001113
Iteration 144/1000 | Loss: 0.00001113
Iteration 145/1000 | Loss: 0.00001113
Iteration 146/1000 | Loss: 0.00001112
Iteration 147/1000 | Loss: 0.00001112
Iteration 148/1000 | Loss: 0.00001112
Iteration 149/1000 | Loss: 0.00001112
Iteration 150/1000 | Loss: 0.00001112
Iteration 151/1000 | Loss: 0.00001112
Iteration 152/1000 | Loss: 0.00001112
Iteration 153/1000 | Loss: 0.00001112
Iteration 154/1000 | Loss: 0.00001112
Iteration 155/1000 | Loss: 0.00001112
Iteration 156/1000 | Loss: 0.00001112
Iteration 157/1000 | Loss: 0.00001112
Iteration 158/1000 | Loss: 0.00001112
Iteration 159/1000 | Loss: 0.00001112
Iteration 160/1000 | Loss: 0.00001112
Iteration 161/1000 | Loss: 0.00001112
Iteration 162/1000 | Loss: 0.00001112
Iteration 163/1000 | Loss: 0.00001112
Iteration 164/1000 | Loss: 0.00001112
Iteration 165/1000 | Loss: 0.00001112
Iteration 166/1000 | Loss: 0.00001112
Iteration 167/1000 | Loss: 0.00001112
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 167. Stopping optimization.
Last 5 losses: [1.1122023352072574e-05, 1.1122023352072574e-05, 1.1122023352072574e-05, 1.1122023352072574e-05, 1.1122023352072574e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1122023352072574e-05

Optimization complete. Final v2v error: 2.7977867126464844 mm

Highest mean error: 5.000760078430176 mm for frame 72

Lowest mean error: 2.3110005855560303 mm for frame 144

Saving results

Total time: 144.0585310459137
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1073/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1073.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1073
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00837741
Iteration 2/25 | Loss: 0.00091296
Iteration 3/25 | Loss: 0.00075729
Iteration 4/25 | Loss: 0.00073876
Iteration 5/25 | Loss: 0.00073368
Iteration 6/25 | Loss: 0.00073205
Iteration 7/25 | Loss: 0.00073177
Iteration 8/25 | Loss: 0.00073177
Iteration 9/25 | Loss: 0.00073177
Iteration 10/25 | Loss: 0.00073177
Iteration 11/25 | Loss: 0.00073177
Iteration 12/25 | Loss: 0.00073177
Iteration 13/25 | Loss: 0.00073177
Iteration 14/25 | Loss: 0.00073177
Iteration 15/25 | Loss: 0.00073177
Iteration 16/25 | Loss: 0.00073177
Iteration 17/25 | Loss: 0.00073177
Iteration 18/25 | Loss: 0.00073172
Iteration 19/25 | Loss: 0.00073172
Iteration 20/25 | Loss: 0.00073172
Iteration 21/25 | Loss: 0.00073172
Iteration 22/25 | Loss: 0.00073172
Iteration 23/25 | Loss: 0.00073172
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0007317158160731196, 0.0007317158160731196, 0.0007317158160731196, 0.0007317158160731196, 0.0007317158160731196]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007317158160731196

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60082912
Iteration 2/25 | Loss: 0.00120682
Iteration 3/25 | Loss: 0.00120681
Iteration 4/25 | Loss: 0.00120681
Iteration 5/25 | Loss: 0.00120681
Iteration 6/25 | Loss: 0.00120681
Iteration 7/25 | Loss: 0.00120681
Iteration 8/25 | Loss: 0.00120681
Iteration 9/25 | Loss: 0.00120681
Iteration 10/25 | Loss: 0.00120681
Iteration 11/25 | Loss: 0.00120681
Iteration 12/25 | Loss: 0.00120681
Iteration 13/25 | Loss: 0.00120681
Iteration 14/25 | Loss: 0.00120681
Iteration 15/25 | Loss: 0.00120681
Iteration 16/25 | Loss: 0.00120681
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012068120995536447, 0.0012068120995536447, 0.0012068120995536447, 0.0012068120995536447, 0.0012068120995536447]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012068120995536447

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00120681
Iteration 2/1000 | Loss: 0.00002174
Iteration 3/1000 | Loss: 0.00001377
Iteration 4/1000 | Loss: 0.00001217
Iteration 5/1000 | Loss: 0.00001163
Iteration 6/1000 | Loss: 0.00001092
Iteration 7/1000 | Loss: 0.00001061
Iteration 8/1000 | Loss: 0.00001049
Iteration 9/1000 | Loss: 0.00001048
Iteration 10/1000 | Loss: 0.00001042
Iteration 11/1000 | Loss: 0.00001041
Iteration 12/1000 | Loss: 0.00001036
Iteration 13/1000 | Loss: 0.00001035
Iteration 14/1000 | Loss: 0.00001035
Iteration 15/1000 | Loss: 0.00001035
Iteration 16/1000 | Loss: 0.00001035
Iteration 17/1000 | Loss: 0.00001035
Iteration 18/1000 | Loss: 0.00001034
Iteration 19/1000 | Loss: 0.00001034
Iteration 20/1000 | Loss: 0.00001034
Iteration 21/1000 | Loss: 0.00001032
Iteration 22/1000 | Loss: 0.00001032
Iteration 23/1000 | Loss: 0.00001031
Iteration 24/1000 | Loss: 0.00001031
Iteration 25/1000 | Loss: 0.00001031
Iteration 26/1000 | Loss: 0.00001028
Iteration 27/1000 | Loss: 0.00001026
Iteration 28/1000 | Loss: 0.00001025
Iteration 29/1000 | Loss: 0.00001024
Iteration 30/1000 | Loss: 0.00001024
Iteration 31/1000 | Loss: 0.00001023
Iteration 32/1000 | Loss: 0.00001023
Iteration 33/1000 | Loss: 0.00001023
Iteration 34/1000 | Loss: 0.00001023
Iteration 35/1000 | Loss: 0.00001022
Iteration 36/1000 | Loss: 0.00001022
Iteration 37/1000 | Loss: 0.00001022
Iteration 38/1000 | Loss: 0.00001021
Iteration 39/1000 | Loss: 0.00001020
Iteration 40/1000 | Loss: 0.00001020
Iteration 41/1000 | Loss: 0.00001019
Iteration 42/1000 | Loss: 0.00001018
Iteration 43/1000 | Loss: 0.00001018
Iteration 44/1000 | Loss: 0.00001017
Iteration 45/1000 | Loss: 0.00001017
Iteration 46/1000 | Loss: 0.00001017
Iteration 47/1000 | Loss: 0.00001016
Iteration 48/1000 | Loss: 0.00001016
Iteration 49/1000 | Loss: 0.00001015
Iteration 50/1000 | Loss: 0.00001015
Iteration 51/1000 | Loss: 0.00001015
Iteration 52/1000 | Loss: 0.00001014
Iteration 53/1000 | Loss: 0.00001014
Iteration 54/1000 | Loss: 0.00001014
Iteration 55/1000 | Loss: 0.00001014
Iteration 56/1000 | Loss: 0.00001014
Iteration 57/1000 | Loss: 0.00001014
Iteration 58/1000 | Loss: 0.00001013
Iteration 59/1000 | Loss: 0.00001013
Iteration 60/1000 | Loss: 0.00001013
Iteration 61/1000 | Loss: 0.00001013
Iteration 62/1000 | Loss: 0.00001013
Iteration 63/1000 | Loss: 0.00001012
Iteration 64/1000 | Loss: 0.00001012
Iteration 65/1000 | Loss: 0.00001011
Iteration 66/1000 | Loss: 0.00001011
Iteration 67/1000 | Loss: 0.00001011
Iteration 68/1000 | Loss: 0.00001010
Iteration 69/1000 | Loss: 0.00001010
Iteration 70/1000 | Loss: 0.00001009
Iteration 71/1000 | Loss: 0.00001009
Iteration 72/1000 | Loss: 0.00001008
Iteration 73/1000 | Loss: 0.00001008
Iteration 74/1000 | Loss: 0.00001007
Iteration 75/1000 | Loss: 0.00001007
Iteration 76/1000 | Loss: 0.00001007
Iteration 77/1000 | Loss: 0.00001007
Iteration 78/1000 | Loss: 0.00001007
Iteration 79/1000 | Loss: 0.00001006
Iteration 80/1000 | Loss: 0.00001006
Iteration 81/1000 | Loss: 0.00001006
Iteration 82/1000 | Loss: 0.00001006
Iteration 83/1000 | Loss: 0.00001006
Iteration 84/1000 | Loss: 0.00001006
Iteration 85/1000 | Loss: 0.00001005
Iteration 86/1000 | Loss: 0.00001005
Iteration 87/1000 | Loss: 0.00001005
Iteration 88/1000 | Loss: 0.00001004
Iteration 89/1000 | Loss: 0.00001004
Iteration 90/1000 | Loss: 0.00001004
Iteration 91/1000 | Loss: 0.00001004
Iteration 92/1000 | Loss: 0.00001004
Iteration 93/1000 | Loss: 0.00001004
Iteration 94/1000 | Loss: 0.00001004
Iteration 95/1000 | Loss: 0.00001003
Iteration 96/1000 | Loss: 0.00001003
Iteration 97/1000 | Loss: 0.00001003
Iteration 98/1000 | Loss: 0.00001003
Iteration 99/1000 | Loss: 0.00001003
Iteration 100/1000 | Loss: 0.00001003
Iteration 101/1000 | Loss: 0.00001003
Iteration 102/1000 | Loss: 0.00001003
Iteration 103/1000 | Loss: 0.00001003
Iteration 104/1000 | Loss: 0.00001003
Iteration 105/1000 | Loss: 0.00001003
Iteration 106/1000 | Loss: 0.00001002
Iteration 107/1000 | Loss: 0.00001002
Iteration 108/1000 | Loss: 0.00001002
Iteration 109/1000 | Loss: 0.00001002
Iteration 110/1000 | Loss: 0.00001002
Iteration 111/1000 | Loss: 0.00001002
Iteration 112/1000 | Loss: 0.00001002
Iteration 113/1000 | Loss: 0.00001002
Iteration 114/1000 | Loss: 0.00001002
Iteration 115/1000 | Loss: 0.00001002
Iteration 116/1000 | Loss: 0.00001002
Iteration 117/1000 | Loss: 0.00001002
Iteration 118/1000 | Loss: 0.00001002
Iteration 119/1000 | Loss: 0.00001001
Iteration 120/1000 | Loss: 0.00001001
Iteration 121/1000 | Loss: 0.00001001
Iteration 122/1000 | Loss: 0.00001001
Iteration 123/1000 | Loss: 0.00001001
Iteration 124/1000 | Loss: 0.00001001
Iteration 125/1000 | Loss: 0.00001001
Iteration 126/1000 | Loss: 0.00001001
Iteration 127/1000 | Loss: 0.00001001
Iteration 128/1000 | Loss: 0.00001001
Iteration 129/1000 | Loss: 0.00001001
Iteration 130/1000 | Loss: 0.00001001
Iteration 131/1000 | Loss: 0.00001001
Iteration 132/1000 | Loss: 0.00001001
Iteration 133/1000 | Loss: 0.00001001
Iteration 134/1000 | Loss: 0.00001001
Iteration 135/1000 | Loss: 0.00001001
Iteration 136/1000 | Loss: 0.00001001
Iteration 137/1000 | Loss: 0.00001001
Iteration 138/1000 | Loss: 0.00001001
Iteration 139/1000 | Loss: 0.00001001
Iteration 140/1000 | Loss: 0.00001001
Iteration 141/1000 | Loss: 0.00001001
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [1.0010250662162434e-05, 1.0010250662162434e-05, 1.0010250662162434e-05, 1.0010250662162434e-05, 1.0010250662162434e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0010250662162434e-05

Optimization complete. Final v2v error: 2.683063268661499 mm

Highest mean error: 2.8171327114105225 mm for frame 68

Lowest mean error: 2.586587429046631 mm for frame 4

Saving results

Total time: 32.49354004859924
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1094
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00424241
Iteration 2/25 | Loss: 0.00095167
Iteration 3/25 | Loss: 0.00082956
Iteration 4/25 | Loss: 0.00080901
Iteration 5/25 | Loss: 0.00080473
Iteration 6/25 | Loss: 0.00080342
Iteration 7/25 | Loss: 0.00080331
Iteration 8/25 | Loss: 0.00080331
Iteration 9/25 | Loss: 0.00080331
Iteration 10/25 | Loss: 0.00080331
Iteration 11/25 | Loss: 0.00080331
Iteration 12/25 | Loss: 0.00080331
Iteration 13/25 | Loss: 0.00080331
Iteration 14/25 | Loss: 0.00080331
Iteration 15/25 | Loss: 0.00080331
Iteration 16/25 | Loss: 0.00080331
Iteration 17/25 | Loss: 0.00080331
Iteration 18/25 | Loss: 0.00080331
Iteration 19/25 | Loss: 0.00080331
Iteration 20/25 | Loss: 0.00080331
Iteration 21/25 | Loss: 0.00080331
Iteration 22/25 | Loss: 0.00080331
Iteration 23/25 | Loss: 0.00080331
Iteration 24/25 | Loss: 0.00080331
Iteration 25/25 | Loss: 0.00080331

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59203339
Iteration 2/25 | Loss: 0.00146942
Iteration 3/25 | Loss: 0.00146942
Iteration 4/25 | Loss: 0.00146942
Iteration 5/25 | Loss: 0.00146942
Iteration 6/25 | Loss: 0.00146942
Iteration 7/25 | Loss: 0.00146942
Iteration 8/25 | Loss: 0.00146942
Iteration 9/25 | Loss: 0.00146942
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 9. Stopping optimization.
Last 5 losses: [0.0014694164274260402, 0.0014694164274260402, 0.0014694164274260402, 0.0014694164274260402, 0.0014694164274260402]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014694164274260402

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00146942
Iteration 2/1000 | Loss: 0.00003082
Iteration 3/1000 | Loss: 0.00001701
Iteration 4/1000 | Loss: 0.00001450
Iteration 5/1000 | Loss: 0.00001341
Iteration 6/1000 | Loss: 0.00001288
Iteration 7/1000 | Loss: 0.00001263
Iteration 8/1000 | Loss: 0.00001248
Iteration 9/1000 | Loss: 0.00001237
Iteration 10/1000 | Loss: 0.00001237
Iteration 11/1000 | Loss: 0.00001237
Iteration 12/1000 | Loss: 0.00001236
Iteration 13/1000 | Loss: 0.00001236
Iteration 14/1000 | Loss: 0.00001234
Iteration 15/1000 | Loss: 0.00001233
Iteration 16/1000 | Loss: 0.00001230
Iteration 17/1000 | Loss: 0.00001228
Iteration 18/1000 | Loss: 0.00001223
Iteration 19/1000 | Loss: 0.00001223
Iteration 20/1000 | Loss: 0.00001222
Iteration 21/1000 | Loss: 0.00001222
Iteration 22/1000 | Loss: 0.00001222
Iteration 23/1000 | Loss: 0.00001221
Iteration 24/1000 | Loss: 0.00001220
Iteration 25/1000 | Loss: 0.00001220
Iteration 26/1000 | Loss: 0.00001220
Iteration 27/1000 | Loss: 0.00001220
Iteration 28/1000 | Loss: 0.00001220
Iteration 29/1000 | Loss: 0.00001219
Iteration 30/1000 | Loss: 0.00001219
Iteration 31/1000 | Loss: 0.00001219
Iteration 32/1000 | Loss: 0.00001219
Iteration 33/1000 | Loss: 0.00001219
Iteration 34/1000 | Loss: 0.00001219
Iteration 35/1000 | Loss: 0.00001219
Iteration 36/1000 | Loss: 0.00001219
Iteration 37/1000 | Loss: 0.00001219
Iteration 38/1000 | Loss: 0.00001219
Iteration 39/1000 | Loss: 0.00001218
Iteration 40/1000 | Loss: 0.00001218
Iteration 41/1000 | Loss: 0.00001218
Iteration 42/1000 | Loss: 0.00001218
Iteration 43/1000 | Loss: 0.00001217
Iteration 44/1000 | Loss: 0.00001217
Iteration 45/1000 | Loss: 0.00001217
Iteration 46/1000 | Loss: 0.00001217
Iteration 47/1000 | Loss: 0.00001216
Iteration 48/1000 | Loss: 0.00001216
Iteration 49/1000 | Loss: 0.00001216
Iteration 50/1000 | Loss: 0.00001216
Iteration 51/1000 | Loss: 0.00001215
Iteration 52/1000 | Loss: 0.00001215
Iteration 53/1000 | Loss: 0.00001215
Iteration 54/1000 | Loss: 0.00001215
Iteration 55/1000 | Loss: 0.00001215
Iteration 56/1000 | Loss: 0.00001215
Iteration 57/1000 | Loss: 0.00001215
Iteration 58/1000 | Loss: 0.00001215
Iteration 59/1000 | Loss: 0.00001215
Iteration 60/1000 | Loss: 0.00001215
Iteration 61/1000 | Loss: 0.00001215
Iteration 62/1000 | Loss: 0.00001215
Iteration 63/1000 | Loss: 0.00001215
Iteration 64/1000 | Loss: 0.00001214
Iteration 65/1000 | Loss: 0.00001214
Iteration 66/1000 | Loss: 0.00001214
Iteration 67/1000 | Loss: 0.00001214
Iteration 68/1000 | Loss: 0.00001214
Iteration 69/1000 | Loss: 0.00001214
Iteration 70/1000 | Loss: 0.00001214
Iteration 71/1000 | Loss: 0.00001214
Iteration 72/1000 | Loss: 0.00001214
Iteration 73/1000 | Loss: 0.00001214
Iteration 74/1000 | Loss: 0.00001214
Iteration 75/1000 | Loss: 0.00001213
Iteration 76/1000 | Loss: 0.00001213
Iteration 77/1000 | Loss: 0.00001213
Iteration 78/1000 | Loss: 0.00001213
Iteration 79/1000 | Loss: 0.00001213
Iteration 80/1000 | Loss: 0.00001213
Iteration 81/1000 | Loss: 0.00001213
Iteration 82/1000 | Loss: 0.00001213
Iteration 83/1000 | Loss: 0.00001213
Iteration 84/1000 | Loss: 0.00001213
Iteration 85/1000 | Loss: 0.00001213
Iteration 86/1000 | Loss: 0.00001213
Iteration 87/1000 | Loss: 0.00001212
Iteration 88/1000 | Loss: 0.00001212
Iteration 89/1000 | Loss: 0.00001211
Iteration 90/1000 | Loss: 0.00001211
Iteration 91/1000 | Loss: 0.00001211
Iteration 92/1000 | Loss: 0.00001211
Iteration 93/1000 | Loss: 0.00001211
Iteration 94/1000 | Loss: 0.00001211
Iteration 95/1000 | Loss: 0.00001211
Iteration 96/1000 | Loss: 0.00001211
Iteration 97/1000 | Loss: 0.00001210
Iteration 98/1000 | Loss: 0.00001210
Iteration 99/1000 | Loss: 0.00001210
Iteration 100/1000 | Loss: 0.00001210
Iteration 101/1000 | Loss: 0.00001210
Iteration 102/1000 | Loss: 0.00001210
Iteration 103/1000 | Loss: 0.00001209
Iteration 104/1000 | Loss: 0.00001209
Iteration 105/1000 | Loss: 0.00001209
Iteration 106/1000 | Loss: 0.00001209
Iteration 107/1000 | Loss: 0.00001209
Iteration 108/1000 | Loss: 0.00001209
Iteration 109/1000 | Loss: 0.00001209
Iteration 110/1000 | Loss: 0.00001209
Iteration 111/1000 | Loss: 0.00001209
Iteration 112/1000 | Loss: 0.00001209
Iteration 113/1000 | Loss: 0.00001209
Iteration 114/1000 | Loss: 0.00001209
Iteration 115/1000 | Loss: 0.00001209
Iteration 116/1000 | Loss: 0.00001209
Iteration 117/1000 | Loss: 0.00001209
Iteration 118/1000 | Loss: 0.00001209
Iteration 119/1000 | Loss: 0.00001209
Iteration 120/1000 | Loss: 0.00001209
Iteration 121/1000 | Loss: 0.00001209
Iteration 122/1000 | Loss: 0.00001209
Iteration 123/1000 | Loss: 0.00001209
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.208803314511897e-05, 1.208803314511897e-05, 1.208803314511897e-05, 1.208803314511897e-05, 1.208803314511897e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.208803314511897e-05

Optimization complete. Final v2v error: 2.947986125946045 mm

Highest mean error: 3.2505621910095215 mm for frame 29

Lowest mean error: 2.755632162094116 mm for frame 97

Saving results

Total time: 29.668829679489136
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1084/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1084.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1084
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405779
Iteration 2/25 | Loss: 0.00097458
Iteration 3/25 | Loss: 0.00078465
Iteration 4/25 | Loss: 0.00075575
Iteration 5/25 | Loss: 0.00074666
Iteration 6/25 | Loss: 0.00074362
Iteration 7/25 | Loss: 0.00074270
Iteration 8/25 | Loss: 0.00074263
Iteration 9/25 | Loss: 0.00074263
Iteration 10/25 | Loss: 0.00074263
Iteration 11/25 | Loss: 0.00074263
Iteration 12/25 | Loss: 0.00074263
Iteration 13/25 | Loss: 0.00074263
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.00074262626003474, 0.00074262626003474, 0.00074262626003474, 0.00074262626003474, 0.00074262626003474]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00074262626003474

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46298814
Iteration 2/25 | Loss: 0.00115284
Iteration 3/25 | Loss: 0.00115282
Iteration 4/25 | Loss: 0.00115281
Iteration 5/25 | Loss: 0.00115281
Iteration 6/25 | Loss: 0.00115281
Iteration 7/25 | Loss: 0.00115281
Iteration 8/25 | Loss: 0.00115281
Iteration 9/25 | Loss: 0.00115281
Iteration 10/25 | Loss: 0.00115281
Iteration 11/25 | Loss: 0.00115281
Iteration 12/25 | Loss: 0.00115281
Iteration 13/25 | Loss: 0.00115281
Iteration 14/25 | Loss: 0.00115281
Iteration 15/25 | Loss: 0.00115281
Iteration 16/25 | Loss: 0.00115281
Iteration 17/25 | Loss: 0.00115281
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0011528122704476118, 0.0011528122704476118, 0.0011528122704476118, 0.0011528122704476118, 0.0011528122704476118]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011528122704476118

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00115281
Iteration 2/1000 | Loss: 0.00003646
Iteration 3/1000 | Loss: 0.00002280
Iteration 4/1000 | Loss: 0.00001810
Iteration 5/1000 | Loss: 0.00001693
Iteration 6/1000 | Loss: 0.00001624
Iteration 7/1000 | Loss: 0.00001548
Iteration 8/1000 | Loss: 0.00001513
Iteration 9/1000 | Loss: 0.00001480
Iteration 10/1000 | Loss: 0.00001460
Iteration 11/1000 | Loss: 0.00001451
Iteration 12/1000 | Loss: 0.00001450
Iteration 13/1000 | Loss: 0.00001445
Iteration 14/1000 | Loss: 0.00001441
Iteration 15/1000 | Loss: 0.00001438
Iteration 16/1000 | Loss: 0.00001438
Iteration 17/1000 | Loss: 0.00001437
Iteration 18/1000 | Loss: 0.00001437
Iteration 19/1000 | Loss: 0.00001434
Iteration 20/1000 | Loss: 0.00001433
Iteration 21/1000 | Loss: 0.00001431
Iteration 22/1000 | Loss: 0.00001430
Iteration 23/1000 | Loss: 0.00001430
Iteration 24/1000 | Loss: 0.00001430
Iteration 25/1000 | Loss: 0.00001428
Iteration 26/1000 | Loss: 0.00001428
Iteration 27/1000 | Loss: 0.00001426
Iteration 28/1000 | Loss: 0.00001425
Iteration 29/1000 | Loss: 0.00001424
Iteration 30/1000 | Loss: 0.00001423
Iteration 31/1000 | Loss: 0.00001422
Iteration 32/1000 | Loss: 0.00001421
Iteration 33/1000 | Loss: 0.00001421
Iteration 34/1000 | Loss: 0.00001421
Iteration 35/1000 | Loss: 0.00001420
Iteration 36/1000 | Loss: 0.00001420
Iteration 37/1000 | Loss: 0.00001419
Iteration 38/1000 | Loss: 0.00001419
Iteration 39/1000 | Loss: 0.00001419
Iteration 40/1000 | Loss: 0.00001417
Iteration 41/1000 | Loss: 0.00001417
Iteration 42/1000 | Loss: 0.00001416
Iteration 43/1000 | Loss: 0.00001416
Iteration 44/1000 | Loss: 0.00001416
Iteration 45/1000 | Loss: 0.00001415
Iteration 46/1000 | Loss: 0.00001414
Iteration 47/1000 | Loss: 0.00001414
Iteration 48/1000 | Loss: 0.00001414
Iteration 49/1000 | Loss: 0.00001413
Iteration 50/1000 | Loss: 0.00001413
Iteration 51/1000 | Loss: 0.00001412
Iteration 52/1000 | Loss: 0.00001412
Iteration 53/1000 | Loss: 0.00001412
Iteration 54/1000 | Loss: 0.00001411
Iteration 55/1000 | Loss: 0.00001410
Iteration 56/1000 | Loss: 0.00001410
Iteration 57/1000 | Loss: 0.00001410
Iteration 58/1000 | Loss: 0.00001410
Iteration 59/1000 | Loss: 0.00001409
Iteration 60/1000 | Loss: 0.00001409
Iteration 61/1000 | Loss: 0.00001409
Iteration 62/1000 | Loss: 0.00001409
Iteration 63/1000 | Loss: 0.00001408
Iteration 64/1000 | Loss: 0.00001408
Iteration 65/1000 | Loss: 0.00001408
Iteration 66/1000 | Loss: 0.00001407
Iteration 67/1000 | Loss: 0.00001405
Iteration 68/1000 | Loss: 0.00001405
Iteration 69/1000 | Loss: 0.00001405
Iteration 70/1000 | Loss: 0.00001404
Iteration 71/1000 | Loss: 0.00001404
Iteration 72/1000 | Loss: 0.00001404
Iteration 73/1000 | Loss: 0.00001404
Iteration 74/1000 | Loss: 0.00001403
Iteration 75/1000 | Loss: 0.00001403
Iteration 76/1000 | Loss: 0.00001403
Iteration 77/1000 | Loss: 0.00001403
Iteration 78/1000 | Loss: 0.00001402
Iteration 79/1000 | Loss: 0.00001402
Iteration 80/1000 | Loss: 0.00001402
Iteration 81/1000 | Loss: 0.00001402
Iteration 82/1000 | Loss: 0.00001401
Iteration 83/1000 | Loss: 0.00001401
Iteration 84/1000 | Loss: 0.00001401
Iteration 85/1000 | Loss: 0.00001400
Iteration 86/1000 | Loss: 0.00001400
Iteration 87/1000 | Loss: 0.00001400
Iteration 88/1000 | Loss: 0.00001400
Iteration 89/1000 | Loss: 0.00001400
Iteration 90/1000 | Loss: 0.00001399
Iteration 91/1000 | Loss: 0.00001399
Iteration 92/1000 | Loss: 0.00001399
Iteration 93/1000 | Loss: 0.00001399
Iteration 94/1000 | Loss: 0.00001398
Iteration 95/1000 | Loss: 0.00001397
Iteration 96/1000 | Loss: 0.00001397
Iteration 97/1000 | Loss: 0.00001396
Iteration 98/1000 | Loss: 0.00001396
Iteration 99/1000 | Loss: 0.00001396
Iteration 100/1000 | Loss: 0.00001396
Iteration 101/1000 | Loss: 0.00001396
Iteration 102/1000 | Loss: 0.00001396
Iteration 103/1000 | Loss: 0.00001396
Iteration 104/1000 | Loss: 0.00001396
Iteration 105/1000 | Loss: 0.00001396
Iteration 106/1000 | Loss: 0.00001396
Iteration 107/1000 | Loss: 0.00001395
Iteration 108/1000 | Loss: 0.00001395
Iteration 109/1000 | Loss: 0.00001395
Iteration 110/1000 | Loss: 0.00001395
Iteration 111/1000 | Loss: 0.00001395
Iteration 112/1000 | Loss: 0.00001395
Iteration 113/1000 | Loss: 0.00001394
Iteration 114/1000 | Loss: 0.00001394
Iteration 115/1000 | Loss: 0.00001394
Iteration 116/1000 | Loss: 0.00001394
Iteration 117/1000 | Loss: 0.00001393
Iteration 118/1000 | Loss: 0.00001393
Iteration 119/1000 | Loss: 0.00001393
Iteration 120/1000 | Loss: 0.00001393
Iteration 121/1000 | Loss: 0.00001393
Iteration 122/1000 | Loss: 0.00001393
Iteration 123/1000 | Loss: 0.00001393
Iteration 124/1000 | Loss: 0.00001393
Iteration 125/1000 | Loss: 0.00001392
Iteration 126/1000 | Loss: 0.00001392
Iteration 127/1000 | Loss: 0.00001392
Iteration 128/1000 | Loss: 0.00001392
Iteration 129/1000 | Loss: 0.00001392
Iteration 130/1000 | Loss: 0.00001392
Iteration 131/1000 | Loss: 0.00001392
Iteration 132/1000 | Loss: 0.00001392
Iteration 133/1000 | Loss: 0.00001392
Iteration 134/1000 | Loss: 0.00001392
Iteration 135/1000 | Loss: 0.00001392
Iteration 136/1000 | Loss: 0.00001392
Iteration 137/1000 | Loss: 0.00001392
Iteration 138/1000 | Loss: 0.00001392
Iteration 139/1000 | Loss: 0.00001392
Iteration 140/1000 | Loss: 0.00001392
Iteration 141/1000 | Loss: 0.00001392
Iteration 142/1000 | Loss: 0.00001392
Iteration 143/1000 | Loss: 0.00001392
Iteration 144/1000 | Loss: 0.00001392
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 144. Stopping optimization.
Last 5 losses: [1.3923278856964316e-05, 1.3923278856964316e-05, 1.3923278856964316e-05, 1.3923278856964316e-05, 1.3923278856964316e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3923278856964316e-05

Optimization complete. Final v2v error: 2.989946126937866 mm

Highest mean error: 5.190898895263672 mm for frame 75

Lowest mean error: 2.3848490715026855 mm for frame 109

Saving results

Total time: 38.92133140563965
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01084202
Iteration 2/25 | Loss: 0.00264610
Iteration 3/25 | Loss: 0.00158829
Iteration 4/25 | Loss: 0.00131220
Iteration 5/25 | Loss: 0.00115903
Iteration 6/25 | Loss: 0.00115477
Iteration 7/25 | Loss: 0.00112086
Iteration 8/25 | Loss: 0.00098983
Iteration 9/25 | Loss: 0.00094214
Iteration 10/25 | Loss: 0.00089725
Iteration 11/25 | Loss: 0.00087262
Iteration 12/25 | Loss: 0.00084068
Iteration 13/25 | Loss: 0.00084356
Iteration 14/25 | Loss: 0.00082659
Iteration 15/25 | Loss: 0.00080535
Iteration 16/25 | Loss: 0.00078982
Iteration 17/25 | Loss: 0.00079179
Iteration 18/25 | Loss: 0.00077655
Iteration 19/25 | Loss: 0.00077357
Iteration 20/25 | Loss: 0.00077610
Iteration 21/25 | Loss: 0.00077306
Iteration 22/25 | Loss: 0.00077558
Iteration 23/25 | Loss: 0.00077557
Iteration 24/25 | Loss: 0.00077449
Iteration 25/25 | Loss: 0.00077548

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.16263652
Iteration 2/25 | Loss: 0.00147119
Iteration 3/25 | Loss: 0.00131757
Iteration 4/25 | Loss: 0.00131757
Iteration 5/25 | Loss: 0.00131757
Iteration 6/25 | Loss: 0.00131757
Iteration 7/25 | Loss: 0.00131757
Iteration 8/25 | Loss: 0.00131757
Iteration 9/25 | Loss: 0.00131757
Iteration 10/25 | Loss: 0.00131757
Iteration 11/25 | Loss: 0.00131757
Iteration 12/25 | Loss: 0.00131757
Iteration 13/25 | Loss: 0.00131757
Iteration 14/25 | Loss: 0.00131757
Iteration 15/25 | Loss: 0.00131757
Iteration 16/25 | Loss: 0.00131757
Iteration 17/25 | Loss: 0.00131757
Iteration 18/25 | Loss: 0.00131757
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0013175709173083305, 0.0013175709173083305, 0.0013175709173083305, 0.0013175709173083305, 0.0013175709173083305]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013175709173083305

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00131757
Iteration 2/1000 | Loss: 0.00005541
Iteration 3/1000 | Loss: 0.00043369
Iteration 4/1000 | Loss: 0.00002538
Iteration 5/1000 | Loss: 0.00002236
Iteration 6/1000 | Loss: 0.00028158
Iteration 7/1000 | Loss: 0.00006284
Iteration 8/1000 | Loss: 0.00001945
Iteration 9/1000 | Loss: 0.00001879
Iteration 10/1000 | Loss: 0.00014889
Iteration 11/1000 | Loss: 0.00001928
Iteration 12/1000 | Loss: 0.00001809
Iteration 13/1000 | Loss: 0.00045531
Iteration 14/1000 | Loss: 0.00043108
Iteration 15/1000 | Loss: 0.00001998
Iteration 16/1000 | Loss: 0.00001777
Iteration 17/1000 | Loss: 0.00011851
Iteration 18/1000 | Loss: 0.00017119
Iteration 19/1000 | Loss: 0.00002857
Iteration 20/1000 | Loss: 0.00001701
Iteration 21/1000 | Loss: 0.00001557
Iteration 22/1000 | Loss: 0.00003996
Iteration 23/1000 | Loss: 0.00001772
Iteration 24/1000 | Loss: 0.00001528
Iteration 25/1000 | Loss: 0.00001520
Iteration 26/1000 | Loss: 0.00001517
Iteration 27/1000 | Loss: 0.00001517
Iteration 28/1000 | Loss: 0.00001516
Iteration 29/1000 | Loss: 0.00001516
Iteration 30/1000 | Loss: 0.00001515
Iteration 31/1000 | Loss: 0.00001515
Iteration 32/1000 | Loss: 0.00001509
Iteration 33/1000 | Loss: 0.00001507
Iteration 34/1000 | Loss: 0.00001506
Iteration 35/1000 | Loss: 0.00001504
Iteration 36/1000 | Loss: 0.00001502
Iteration 37/1000 | Loss: 0.00001502
Iteration 38/1000 | Loss: 0.00001502
Iteration 39/1000 | Loss: 0.00001501
Iteration 40/1000 | Loss: 0.00001501
Iteration 41/1000 | Loss: 0.00001501
Iteration 42/1000 | Loss: 0.00001501
Iteration 43/1000 | Loss: 0.00001501
Iteration 44/1000 | Loss: 0.00001501
Iteration 45/1000 | Loss: 0.00001500
Iteration 46/1000 | Loss: 0.00001500
Iteration 47/1000 | Loss: 0.00001500
Iteration 48/1000 | Loss: 0.00001499
Iteration 49/1000 | Loss: 0.00001499
Iteration 50/1000 | Loss: 0.00001499
Iteration 51/1000 | Loss: 0.00001498
Iteration 52/1000 | Loss: 0.00001498
Iteration 53/1000 | Loss: 0.00001498
Iteration 54/1000 | Loss: 0.00001498
Iteration 55/1000 | Loss: 0.00001497
Iteration 56/1000 | Loss: 0.00001497
Iteration 57/1000 | Loss: 0.00001497
Iteration 58/1000 | Loss: 0.00001497
Iteration 59/1000 | Loss: 0.00001497
Iteration 60/1000 | Loss: 0.00001496
Iteration 61/1000 | Loss: 0.00001496
Iteration 62/1000 | Loss: 0.00001496
Iteration 63/1000 | Loss: 0.00001495
Iteration 64/1000 | Loss: 0.00001492
Iteration 65/1000 | Loss: 0.00001492
Iteration 66/1000 | Loss: 0.00001492
Iteration 67/1000 | Loss: 0.00001492
Iteration 68/1000 | Loss: 0.00001491
Iteration 69/1000 | Loss: 0.00001491
Iteration 70/1000 | Loss: 0.00001491
Iteration 71/1000 | Loss: 0.00001491
Iteration 72/1000 | Loss: 0.00001491
Iteration 73/1000 | Loss: 0.00001491
Iteration 74/1000 | Loss: 0.00001491
Iteration 75/1000 | Loss: 0.00001491
Iteration 76/1000 | Loss: 0.00001491
Iteration 77/1000 | Loss: 0.00001490
Iteration 78/1000 | Loss: 0.00001490
Iteration 79/1000 | Loss: 0.00001490
Iteration 80/1000 | Loss: 0.00001489
Iteration 81/1000 | Loss: 0.00001489
Iteration 82/1000 | Loss: 0.00001489
Iteration 83/1000 | Loss: 0.00001489
Iteration 84/1000 | Loss: 0.00001489
Iteration 85/1000 | Loss: 0.00001489
Iteration 86/1000 | Loss: 0.00001488
Iteration 87/1000 | Loss: 0.00001488
Iteration 88/1000 | Loss: 0.00001488
Iteration 89/1000 | Loss: 0.00001488
Iteration 90/1000 | Loss: 0.00004610
Iteration 91/1000 | Loss: 0.00001488
Iteration 92/1000 | Loss: 0.00001486
Iteration 93/1000 | Loss: 0.00001483
Iteration 94/1000 | Loss: 0.00001483
Iteration 95/1000 | Loss: 0.00001483
Iteration 96/1000 | Loss: 0.00001483
Iteration 97/1000 | Loss: 0.00001483
Iteration 98/1000 | Loss: 0.00001483
Iteration 99/1000 | Loss: 0.00001483
Iteration 100/1000 | Loss: 0.00001483
Iteration 101/1000 | Loss: 0.00001483
Iteration 102/1000 | Loss: 0.00001482
Iteration 103/1000 | Loss: 0.00001482
Iteration 104/1000 | Loss: 0.00001482
Iteration 105/1000 | Loss: 0.00001482
Iteration 106/1000 | Loss: 0.00001482
Iteration 107/1000 | Loss: 0.00001482
Iteration 108/1000 | Loss: 0.00001482
Iteration 109/1000 | Loss: 0.00001481
Iteration 110/1000 | Loss: 0.00001481
Iteration 111/1000 | Loss: 0.00001481
Iteration 112/1000 | Loss: 0.00001481
Iteration 113/1000 | Loss: 0.00001481
Iteration 114/1000 | Loss: 0.00001481
Iteration 115/1000 | Loss: 0.00001481
Iteration 116/1000 | Loss: 0.00001480
Iteration 117/1000 | Loss: 0.00001480
Iteration 118/1000 | Loss: 0.00001480
Iteration 119/1000 | Loss: 0.00001480
Iteration 120/1000 | Loss: 0.00001480
Iteration 121/1000 | Loss: 0.00001480
Iteration 122/1000 | Loss: 0.00001480
Iteration 123/1000 | Loss: 0.00001480
Iteration 124/1000 | Loss: 0.00001480
Iteration 125/1000 | Loss: 0.00001480
Iteration 126/1000 | Loss: 0.00001480
Iteration 127/1000 | Loss: 0.00001480
Iteration 128/1000 | Loss: 0.00001480
Iteration 129/1000 | Loss: 0.00001480
Iteration 130/1000 | Loss: 0.00001480
Iteration 131/1000 | Loss: 0.00001480
Iteration 132/1000 | Loss: 0.00001480
Iteration 133/1000 | Loss: 0.00001480
Iteration 134/1000 | Loss: 0.00001480
Iteration 135/1000 | Loss: 0.00001480
Iteration 136/1000 | Loss: 0.00001480
Iteration 137/1000 | Loss: 0.00001480
Iteration 138/1000 | Loss: 0.00001480
Iteration 139/1000 | Loss: 0.00001480
Iteration 140/1000 | Loss: 0.00001480
Iteration 141/1000 | Loss: 0.00001480
Iteration 142/1000 | Loss: 0.00001480
Iteration 143/1000 | Loss: 0.00001480
Iteration 144/1000 | Loss: 0.00001480
Iteration 145/1000 | Loss: 0.00001480
Iteration 146/1000 | Loss: 0.00001480
Iteration 147/1000 | Loss: 0.00001480
Iteration 148/1000 | Loss: 0.00001480
Iteration 149/1000 | Loss: 0.00001480
Iteration 150/1000 | Loss: 0.00001480
Iteration 151/1000 | Loss: 0.00001480
Iteration 152/1000 | Loss: 0.00001480
Iteration 153/1000 | Loss: 0.00001480
Iteration 154/1000 | Loss: 0.00001480
Iteration 155/1000 | Loss: 0.00001480
Iteration 156/1000 | Loss: 0.00001480
Iteration 157/1000 | Loss: 0.00001480
Iteration 158/1000 | Loss: 0.00001480
Iteration 159/1000 | Loss: 0.00001480
Iteration 160/1000 | Loss: 0.00001480
Iteration 161/1000 | Loss: 0.00001480
Iteration 162/1000 | Loss: 0.00001480
Iteration 163/1000 | Loss: 0.00001480
Iteration 164/1000 | Loss: 0.00001480
Iteration 165/1000 | Loss: 0.00001480
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [1.4800226381339598e-05, 1.4800226381339598e-05, 1.4800226381339598e-05, 1.4800226381339598e-05, 1.4800226381339598e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4800226381339598e-05

Optimization complete. Final v2v error: 3.2168850898742676 mm

Highest mean error: 3.945986270904541 mm for frame 46

Lowest mean error: 2.900988817214966 mm for frame 61

Saving results

Total time: 91.43245315551758
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1086
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00975858
Iteration 2/25 | Loss: 0.00141270
Iteration 3/25 | Loss: 0.00105777
Iteration 4/25 | Loss: 0.00091397
Iteration 5/25 | Loss: 0.00088101
Iteration 6/25 | Loss: 0.00085976
Iteration 7/25 | Loss: 0.00084923
Iteration 8/25 | Loss: 0.00084928
Iteration 9/25 | Loss: 0.00084894
Iteration 10/25 | Loss: 0.00085855
Iteration 11/25 | Loss: 0.00085321
Iteration 12/25 | Loss: 0.00083296
Iteration 13/25 | Loss: 0.00082869
Iteration 14/25 | Loss: 0.00082686
Iteration 15/25 | Loss: 0.00082283
Iteration 16/25 | Loss: 0.00082569
Iteration 17/25 | Loss: 0.00082259
Iteration 18/25 | Loss: 0.00082574
Iteration 19/25 | Loss: 0.00082256
Iteration 20/25 | Loss: 0.00082256
Iteration 21/25 | Loss: 0.00082256
Iteration 22/25 | Loss: 0.00082256
Iteration 23/25 | Loss: 0.00082256
Iteration 24/25 | Loss: 0.00082256
Iteration 25/25 | Loss: 0.00082256

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.68802679
Iteration 2/25 | Loss: 0.00132984
Iteration 3/25 | Loss: 0.00132982
Iteration 4/25 | Loss: 0.00132982
Iteration 5/25 | Loss: 0.00132982
Iteration 6/25 | Loss: 0.00132982
Iteration 7/25 | Loss: 0.00132982
Iteration 8/25 | Loss: 0.00132982
Iteration 9/25 | Loss: 0.00132982
Iteration 10/25 | Loss: 0.00132982
Iteration 11/25 | Loss: 0.00132982
Iteration 12/25 | Loss: 0.00132982
Iteration 13/25 | Loss: 0.00132982
Iteration 14/25 | Loss: 0.00132982
Iteration 15/25 | Loss: 0.00132982
Iteration 16/25 | Loss: 0.00132982
Iteration 17/25 | Loss: 0.00132982
Iteration 18/25 | Loss: 0.00132982
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0013298186240717769, 0.0013298186240717769, 0.0013298186240717769, 0.0013298186240717769, 0.0013298186240717769]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013298186240717769

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00132982
Iteration 2/1000 | Loss: 0.00003919
Iteration 3/1000 | Loss: 0.00005028
Iteration 4/1000 | Loss: 0.00002420
Iteration 5/1000 | Loss: 0.00002272
Iteration 6/1000 | Loss: 0.00002177
Iteration 7/1000 | Loss: 0.00002127
Iteration 8/1000 | Loss: 0.00002079
Iteration 9/1000 | Loss: 0.00002045
Iteration 10/1000 | Loss: 0.00002019
Iteration 11/1000 | Loss: 0.00002000
Iteration 12/1000 | Loss: 0.00001990
Iteration 13/1000 | Loss: 0.00001982
Iteration 14/1000 | Loss: 0.00001976
Iteration 15/1000 | Loss: 0.00001974
Iteration 16/1000 | Loss: 0.00001972
Iteration 17/1000 | Loss: 0.00001971
Iteration 18/1000 | Loss: 0.00001971
Iteration 19/1000 | Loss: 0.00001971
Iteration 20/1000 | Loss: 0.00001971
Iteration 21/1000 | Loss: 0.00001970
Iteration 22/1000 | Loss: 0.00001970
Iteration 23/1000 | Loss: 0.00001970
Iteration 24/1000 | Loss: 0.00001969
Iteration 25/1000 | Loss: 0.00001969
Iteration 26/1000 | Loss: 0.00001969
Iteration 27/1000 | Loss: 0.00001968
Iteration 28/1000 | Loss: 0.00001968
Iteration 29/1000 | Loss: 0.00001968
Iteration 30/1000 | Loss: 0.00001967
Iteration 31/1000 | Loss: 0.00001967
Iteration 32/1000 | Loss: 0.00001967
Iteration 33/1000 | Loss: 0.00001967
Iteration 34/1000 | Loss: 0.00001966
Iteration 35/1000 | Loss: 0.00001966
Iteration 36/1000 | Loss: 0.00001966
Iteration 37/1000 | Loss: 0.00001966
Iteration 38/1000 | Loss: 0.00001965
Iteration 39/1000 | Loss: 0.00001965
Iteration 40/1000 | Loss: 0.00001965
Iteration 41/1000 | Loss: 0.00001965
Iteration 42/1000 | Loss: 0.00001965
Iteration 43/1000 | Loss: 0.00001965
Iteration 44/1000 | Loss: 0.00001964
Iteration 45/1000 | Loss: 0.00001964
Iteration 46/1000 | Loss: 0.00001964
Iteration 47/1000 | Loss: 0.00001964
Iteration 48/1000 | Loss: 0.00001964
Iteration 49/1000 | Loss: 0.00001963
Iteration 50/1000 | Loss: 0.00001963
Iteration 51/1000 | Loss: 0.00001963
Iteration 52/1000 | Loss: 0.00001963
Iteration 53/1000 | Loss: 0.00001962
Iteration 54/1000 | Loss: 0.00001962
Iteration 55/1000 | Loss: 0.00001962
Iteration 56/1000 | Loss: 0.00001962
Iteration 57/1000 | Loss: 0.00001962
Iteration 58/1000 | Loss: 0.00001962
Iteration 59/1000 | Loss: 0.00001962
Iteration 60/1000 | Loss: 0.00001962
Iteration 61/1000 | Loss: 0.00001962
Iteration 62/1000 | Loss: 0.00001962
Iteration 63/1000 | Loss: 0.00001962
Iteration 64/1000 | Loss: 0.00001961
Iteration 65/1000 | Loss: 0.00001961
Iteration 66/1000 | Loss: 0.00001961
Iteration 67/1000 | Loss: 0.00001961
Iteration 68/1000 | Loss: 0.00001961
Iteration 69/1000 | Loss: 0.00001961
Iteration 70/1000 | Loss: 0.00001961
Iteration 71/1000 | Loss: 0.00001961
Iteration 72/1000 | Loss: 0.00001961
Iteration 73/1000 | Loss: 0.00001960
Iteration 74/1000 | Loss: 0.00001960
Iteration 75/1000 | Loss: 0.00001960
Iteration 76/1000 | Loss: 0.00001960
Iteration 77/1000 | Loss: 0.00001959
Iteration 78/1000 | Loss: 0.00001959
Iteration 79/1000 | Loss: 0.00001959
Iteration 80/1000 | Loss: 0.00001958
Iteration 81/1000 | Loss: 0.00001958
Iteration 82/1000 | Loss: 0.00001958
Iteration 83/1000 | Loss: 0.00001958
Iteration 84/1000 | Loss: 0.00001958
Iteration 85/1000 | Loss: 0.00001958
Iteration 86/1000 | Loss: 0.00001958
Iteration 87/1000 | Loss: 0.00001958
Iteration 88/1000 | Loss: 0.00001958
Iteration 89/1000 | Loss: 0.00001958
Iteration 90/1000 | Loss: 0.00001958
Iteration 91/1000 | Loss: 0.00001958
Iteration 92/1000 | Loss: 0.00001958
Iteration 93/1000 | Loss: 0.00001958
Iteration 94/1000 | Loss: 0.00001958
Iteration 95/1000 | Loss: 0.00001958
Iteration 96/1000 | Loss: 0.00001958
Iteration 97/1000 | Loss: 0.00001958
Iteration 98/1000 | Loss: 0.00001958
Iteration 99/1000 | Loss: 0.00001958
Iteration 100/1000 | Loss: 0.00001958
Iteration 101/1000 | Loss: 0.00001958
Iteration 102/1000 | Loss: 0.00001958
Iteration 103/1000 | Loss: 0.00001958
Iteration 104/1000 | Loss: 0.00001958
Iteration 105/1000 | Loss: 0.00001958
Iteration 106/1000 | Loss: 0.00001958
Iteration 107/1000 | Loss: 0.00001958
Iteration 108/1000 | Loss: 0.00001958
Iteration 109/1000 | Loss: 0.00001958
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.957865788426716e-05, 1.957865788426716e-05, 1.957865788426716e-05, 1.957865788426716e-05, 1.957865788426716e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.957865788426716e-05

Optimization complete. Final v2v error: 3.729963779449463 mm

Highest mean error: 4.856204509735107 mm for frame 39

Lowest mean error: 3.167029857635498 mm for frame 200

Saving results

Total time: 58.587169885635376
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1066
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00427146
Iteration 2/25 | Loss: 0.00092454
Iteration 3/25 | Loss: 0.00082061
Iteration 4/25 | Loss: 0.00079287
Iteration 5/25 | Loss: 0.00078594
Iteration 6/25 | Loss: 0.00078427
Iteration 7/25 | Loss: 0.00078404
Iteration 8/25 | Loss: 0.00078404
Iteration 9/25 | Loss: 0.00078404
Iteration 10/25 | Loss: 0.00078404
Iteration 11/25 | Loss: 0.00078404
Iteration 12/25 | Loss: 0.00078404
Iteration 13/25 | Loss: 0.00078404
Iteration 14/25 | Loss: 0.00078404
Iteration 15/25 | Loss: 0.00078404
Iteration 16/25 | Loss: 0.00078404
Iteration 17/25 | Loss: 0.00078404
Iteration 18/25 | Loss: 0.00078404
Iteration 19/25 | Loss: 0.00078404
Iteration 20/25 | Loss: 0.00078404
Iteration 21/25 | Loss: 0.00078404
Iteration 22/25 | Loss: 0.00078404
Iteration 23/25 | Loss: 0.00078404
Iteration 24/25 | Loss: 0.00078404
Iteration 25/25 | Loss: 0.00078404

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67935288
Iteration 2/25 | Loss: 0.00124549
Iteration 3/25 | Loss: 0.00124549
Iteration 4/25 | Loss: 0.00124549
Iteration 5/25 | Loss: 0.00124549
Iteration 6/25 | Loss: 0.00124549
Iteration 7/25 | Loss: 0.00124549
Iteration 8/25 | Loss: 0.00124549
Iteration 9/25 | Loss: 0.00124549
Iteration 10/25 | Loss: 0.00124549
Iteration 11/25 | Loss: 0.00124549
Iteration 12/25 | Loss: 0.00124549
Iteration 13/25 | Loss: 0.00124549
Iteration 14/25 | Loss: 0.00124549
Iteration 15/25 | Loss: 0.00124549
Iteration 16/25 | Loss: 0.00124549
Iteration 17/25 | Loss: 0.00124549
Iteration 18/25 | Loss: 0.00124549
Iteration 19/25 | Loss: 0.00124549
Iteration 20/25 | Loss: 0.00124549
Iteration 21/25 | Loss: 0.00124549
Iteration 22/25 | Loss: 0.00124549
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0012454912066459656, 0.0012454912066459656, 0.0012454912066459656, 0.0012454912066459656, 0.0012454912066459656]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012454912066459656

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00124549
Iteration 2/1000 | Loss: 0.00003104
Iteration 3/1000 | Loss: 0.00002191
Iteration 4/1000 | Loss: 0.00002037
Iteration 5/1000 | Loss: 0.00001930
Iteration 6/1000 | Loss: 0.00001883
Iteration 7/1000 | Loss: 0.00001841
Iteration 8/1000 | Loss: 0.00001823
Iteration 9/1000 | Loss: 0.00001801
Iteration 10/1000 | Loss: 0.00001797
Iteration 11/1000 | Loss: 0.00001794
Iteration 12/1000 | Loss: 0.00001794
Iteration 13/1000 | Loss: 0.00001793
Iteration 14/1000 | Loss: 0.00001793
Iteration 15/1000 | Loss: 0.00001791
Iteration 16/1000 | Loss: 0.00001787
Iteration 17/1000 | Loss: 0.00001787
Iteration 18/1000 | Loss: 0.00001787
Iteration 19/1000 | Loss: 0.00001787
Iteration 20/1000 | Loss: 0.00001787
Iteration 21/1000 | Loss: 0.00001786
Iteration 22/1000 | Loss: 0.00001786
Iteration 23/1000 | Loss: 0.00001784
Iteration 24/1000 | Loss: 0.00001783
Iteration 25/1000 | Loss: 0.00001783
Iteration 26/1000 | Loss: 0.00001783
Iteration 27/1000 | Loss: 0.00001783
Iteration 28/1000 | Loss: 0.00001783
Iteration 29/1000 | Loss: 0.00001782
Iteration 30/1000 | Loss: 0.00001782
Iteration 31/1000 | Loss: 0.00001782
Iteration 32/1000 | Loss: 0.00001782
Iteration 33/1000 | Loss: 0.00001782
Iteration 34/1000 | Loss: 0.00001781
Iteration 35/1000 | Loss: 0.00001781
Iteration 36/1000 | Loss: 0.00001781
Iteration 37/1000 | Loss: 0.00001780
Iteration 38/1000 | Loss: 0.00001780
Iteration 39/1000 | Loss: 0.00001780
Iteration 40/1000 | Loss: 0.00001779
Iteration 41/1000 | Loss: 0.00001779
Iteration 42/1000 | Loss: 0.00001779
Iteration 43/1000 | Loss: 0.00001779
Iteration 44/1000 | Loss: 0.00001779
Iteration 45/1000 | Loss: 0.00001779
Iteration 46/1000 | Loss: 0.00001779
Iteration 47/1000 | Loss: 0.00001779
Iteration 48/1000 | Loss: 0.00001778
Iteration 49/1000 | Loss: 0.00001778
Iteration 50/1000 | Loss: 0.00001778
Iteration 51/1000 | Loss: 0.00001777
Iteration 52/1000 | Loss: 0.00001777
Iteration 53/1000 | Loss: 0.00001777
Iteration 54/1000 | Loss: 0.00001777
Iteration 55/1000 | Loss: 0.00001777
Iteration 56/1000 | Loss: 0.00001777
Iteration 57/1000 | Loss: 0.00001777
Iteration 58/1000 | Loss: 0.00001777
Iteration 59/1000 | Loss: 0.00001777
Iteration 60/1000 | Loss: 0.00001777
Iteration 61/1000 | Loss: 0.00001777
Iteration 62/1000 | Loss: 0.00001777
Iteration 63/1000 | Loss: 0.00001777
Iteration 64/1000 | Loss: 0.00001777
Iteration 65/1000 | Loss: 0.00001777
Iteration 66/1000 | Loss: 0.00001777
Iteration 67/1000 | Loss: 0.00001777
Iteration 68/1000 | Loss: 0.00001777
Iteration 69/1000 | Loss: 0.00001777
Iteration 70/1000 | Loss: 0.00001777
Iteration 71/1000 | Loss: 0.00001777
Iteration 72/1000 | Loss: 0.00001777
Iteration 73/1000 | Loss: 0.00001777
Iteration 74/1000 | Loss: 0.00001777
Iteration 75/1000 | Loss: 0.00001777
Iteration 76/1000 | Loss: 0.00001777
Iteration 77/1000 | Loss: 0.00001777
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [1.7768437828635797e-05, 1.7768437828635797e-05, 1.7768437828635797e-05, 1.7768437828635797e-05, 1.7768437828635797e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7768437828635797e-05

Optimization complete. Final v2v error: 3.537196636199951 mm

Highest mean error: 4.082921981811523 mm for frame 120

Lowest mean error: 3.357491970062256 mm for frame 106

Saving results

Total time: 29.211361169815063
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00879394
Iteration 2/25 | Loss: 0.00094804
Iteration 3/25 | Loss: 0.00077679
Iteration 4/25 | Loss: 0.00075571
Iteration 5/25 | Loss: 0.00074997
Iteration 6/25 | Loss: 0.00074794
Iteration 7/25 | Loss: 0.00074771
Iteration 8/25 | Loss: 0.00074771
Iteration 9/25 | Loss: 0.00074771
Iteration 10/25 | Loss: 0.00074771
Iteration 11/25 | Loss: 0.00074771
Iteration 12/25 | Loss: 0.00074771
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007477090111933649, 0.0007477090111933649, 0.0007477090111933649, 0.0007477090111933649, 0.0007477090111933649]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007477090111933649

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58520329
Iteration 2/25 | Loss: 0.00122456
Iteration 3/25 | Loss: 0.00122453
Iteration 4/25 | Loss: 0.00122453
Iteration 5/25 | Loss: 0.00122453
Iteration 6/25 | Loss: 0.00122452
Iteration 7/25 | Loss: 0.00122452
Iteration 8/25 | Loss: 0.00122452
Iteration 9/25 | Loss: 0.00122452
Iteration 10/25 | Loss: 0.00122452
Iteration 11/25 | Loss: 0.00122452
Iteration 12/25 | Loss: 0.00122452
Iteration 13/25 | Loss: 0.00122452
Iteration 14/25 | Loss: 0.00122452
Iteration 15/25 | Loss: 0.00122452
Iteration 16/25 | Loss: 0.00122452
Iteration 17/25 | Loss: 0.00122452
Iteration 18/25 | Loss: 0.00122452
Iteration 19/25 | Loss: 0.00122452
Iteration 20/25 | Loss: 0.00122452
Iteration 21/25 | Loss: 0.00122452
Iteration 22/25 | Loss: 0.00122452
Iteration 23/25 | Loss: 0.00122452
Iteration 24/25 | Loss: 0.00122452
Iteration 25/25 | Loss: 0.00122452

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00122452
Iteration 2/1000 | Loss: 0.00002423
Iteration 3/1000 | Loss: 0.00001716
Iteration 4/1000 | Loss: 0.00001431
Iteration 5/1000 | Loss: 0.00001316
Iteration 6/1000 | Loss: 0.00001227
Iteration 7/1000 | Loss: 0.00001220
Iteration 8/1000 | Loss: 0.00001181
Iteration 9/1000 | Loss: 0.00001156
Iteration 10/1000 | Loss: 0.00001148
Iteration 11/1000 | Loss: 0.00001143
Iteration 12/1000 | Loss: 0.00001134
Iteration 13/1000 | Loss: 0.00001124
Iteration 14/1000 | Loss: 0.00001123
Iteration 15/1000 | Loss: 0.00001122
Iteration 16/1000 | Loss: 0.00001116
Iteration 17/1000 | Loss: 0.00001109
Iteration 18/1000 | Loss: 0.00001109
Iteration 19/1000 | Loss: 0.00001108
Iteration 20/1000 | Loss: 0.00001108
Iteration 21/1000 | Loss: 0.00001106
Iteration 22/1000 | Loss: 0.00001105
Iteration 23/1000 | Loss: 0.00001104
Iteration 24/1000 | Loss: 0.00001104
Iteration 25/1000 | Loss: 0.00001104
Iteration 26/1000 | Loss: 0.00001103
Iteration 27/1000 | Loss: 0.00001102
Iteration 28/1000 | Loss: 0.00001102
Iteration 29/1000 | Loss: 0.00001101
Iteration 30/1000 | Loss: 0.00001101
Iteration 31/1000 | Loss: 0.00001100
Iteration 32/1000 | Loss: 0.00001100
Iteration 33/1000 | Loss: 0.00001100
Iteration 34/1000 | Loss: 0.00001100
Iteration 35/1000 | Loss: 0.00001100
Iteration 36/1000 | Loss: 0.00001099
Iteration 37/1000 | Loss: 0.00001099
Iteration 38/1000 | Loss: 0.00001099
Iteration 39/1000 | Loss: 0.00001099
Iteration 40/1000 | Loss: 0.00001099
Iteration 41/1000 | Loss: 0.00001099
Iteration 42/1000 | Loss: 0.00001098
Iteration 43/1000 | Loss: 0.00001098
Iteration 44/1000 | Loss: 0.00001097
Iteration 45/1000 | Loss: 0.00001097
Iteration 46/1000 | Loss: 0.00001097
Iteration 47/1000 | Loss: 0.00001096
Iteration 48/1000 | Loss: 0.00001096
Iteration 49/1000 | Loss: 0.00001096
Iteration 50/1000 | Loss: 0.00001096
Iteration 51/1000 | Loss: 0.00001096
Iteration 52/1000 | Loss: 0.00001095
Iteration 53/1000 | Loss: 0.00001095
Iteration 54/1000 | Loss: 0.00001095
Iteration 55/1000 | Loss: 0.00001095
Iteration 56/1000 | Loss: 0.00001094
Iteration 57/1000 | Loss: 0.00001094
Iteration 58/1000 | Loss: 0.00001094
Iteration 59/1000 | Loss: 0.00001094
Iteration 60/1000 | Loss: 0.00001093
Iteration 61/1000 | Loss: 0.00001093
Iteration 62/1000 | Loss: 0.00001093
Iteration 63/1000 | Loss: 0.00001093
Iteration 64/1000 | Loss: 0.00001093
Iteration 65/1000 | Loss: 0.00001093
Iteration 66/1000 | Loss: 0.00001093
Iteration 67/1000 | Loss: 0.00001093
Iteration 68/1000 | Loss: 0.00001093
Iteration 69/1000 | Loss: 0.00001093
Iteration 70/1000 | Loss: 0.00001093
Iteration 71/1000 | Loss: 0.00001093
Iteration 72/1000 | Loss: 0.00001093
Iteration 73/1000 | Loss: 0.00001093
Iteration 74/1000 | Loss: 0.00001093
Iteration 75/1000 | Loss: 0.00001093
Iteration 76/1000 | Loss: 0.00001093
Iteration 77/1000 | Loss: 0.00001093
Iteration 78/1000 | Loss: 0.00001093
Iteration 79/1000 | Loss: 0.00001093
Iteration 80/1000 | Loss: 0.00001093
Iteration 81/1000 | Loss: 0.00001093
Iteration 82/1000 | Loss: 0.00001093
Iteration 83/1000 | Loss: 0.00001093
Iteration 84/1000 | Loss: 0.00001093
Iteration 85/1000 | Loss: 0.00001093
Iteration 86/1000 | Loss: 0.00001093
Iteration 87/1000 | Loss: 0.00001093
Iteration 88/1000 | Loss: 0.00001093
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 88. Stopping optimization.
Last 5 losses: [1.0926170944003388e-05, 1.0926170944003388e-05, 1.0926170944003388e-05, 1.0926170944003388e-05, 1.0926170944003388e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0926170944003388e-05

Optimization complete. Final v2v error: 2.819389581680298 mm

Highest mean error: 2.9383513927459717 mm for frame 0

Lowest mean error: 2.675900936126709 mm for frame 146

Saving results

Total time: 30.829402685165405
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1096
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00414251
Iteration 2/25 | Loss: 0.00086942
Iteration 3/25 | Loss: 0.00076171
Iteration 4/25 | Loss: 0.00075153
Iteration 5/25 | Loss: 0.00074784
Iteration 6/25 | Loss: 0.00074679
Iteration 7/25 | Loss: 0.00074674
Iteration 8/25 | Loss: 0.00074675
Iteration 9/25 | Loss: 0.00074674
Iteration 10/25 | Loss: 0.00074674
Iteration 11/25 | Loss: 0.00074674
Iteration 12/25 | Loss: 0.00074674
Iteration 13/25 | Loss: 0.00074674
Iteration 14/25 | Loss: 0.00074674
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.000746744975913316, 0.000746744975913316, 0.000746744975913316, 0.000746744975913316, 0.000746744975913316]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000746744975913316

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60547113
Iteration 2/25 | Loss: 0.00134800
Iteration 3/25 | Loss: 0.00134800
Iteration 4/25 | Loss: 0.00134800
Iteration 5/25 | Loss: 0.00134800
Iteration 6/25 | Loss: 0.00134800
Iteration 7/25 | Loss: 0.00134800
Iteration 8/25 | Loss: 0.00134800
Iteration 9/25 | Loss: 0.00134800
Iteration 10/25 | Loss: 0.00134800
Iteration 11/25 | Loss: 0.00134800
Iteration 12/25 | Loss: 0.00134800
Iteration 13/25 | Loss: 0.00134800
Iteration 14/25 | Loss: 0.00134800
Iteration 15/25 | Loss: 0.00134800
Iteration 16/25 | Loss: 0.00134800
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0013479997869580984, 0.0013479997869580984, 0.0013479997869580984, 0.0013479997869580984, 0.0013479997869580984]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013479997869580984

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00134800
Iteration 2/1000 | Loss: 0.00002464
Iteration 3/1000 | Loss: 0.00001501
Iteration 4/1000 | Loss: 0.00001383
Iteration 5/1000 | Loss: 0.00001309
Iteration 6/1000 | Loss: 0.00001269
Iteration 7/1000 | Loss: 0.00001245
Iteration 8/1000 | Loss: 0.00001217
Iteration 9/1000 | Loss: 0.00001205
Iteration 10/1000 | Loss: 0.00001204
Iteration 11/1000 | Loss: 0.00001194
Iteration 12/1000 | Loss: 0.00001190
Iteration 13/1000 | Loss: 0.00001189
Iteration 14/1000 | Loss: 0.00001189
Iteration 15/1000 | Loss: 0.00001188
Iteration 16/1000 | Loss: 0.00001188
Iteration 17/1000 | Loss: 0.00001183
Iteration 18/1000 | Loss: 0.00001180
Iteration 19/1000 | Loss: 0.00001180
Iteration 20/1000 | Loss: 0.00001179
Iteration 21/1000 | Loss: 0.00001179
Iteration 22/1000 | Loss: 0.00001179
Iteration 23/1000 | Loss: 0.00001178
Iteration 24/1000 | Loss: 0.00001178
Iteration 25/1000 | Loss: 0.00001178
Iteration 26/1000 | Loss: 0.00001177
Iteration 27/1000 | Loss: 0.00001177
Iteration 28/1000 | Loss: 0.00001177
Iteration 29/1000 | Loss: 0.00001177
Iteration 30/1000 | Loss: 0.00001177
Iteration 31/1000 | Loss: 0.00001177
Iteration 32/1000 | Loss: 0.00001177
Iteration 33/1000 | Loss: 0.00001176
Iteration 34/1000 | Loss: 0.00001176
Iteration 35/1000 | Loss: 0.00001176
Iteration 36/1000 | Loss: 0.00001175
Iteration 37/1000 | Loss: 0.00001175
Iteration 38/1000 | Loss: 0.00001174
Iteration 39/1000 | Loss: 0.00001174
Iteration 40/1000 | Loss: 0.00001174
Iteration 41/1000 | Loss: 0.00001174
Iteration 42/1000 | Loss: 0.00001174
Iteration 43/1000 | Loss: 0.00001174
Iteration 44/1000 | Loss: 0.00001174
Iteration 45/1000 | Loss: 0.00001174
Iteration 46/1000 | Loss: 0.00001174
Iteration 47/1000 | Loss: 0.00001174
Iteration 48/1000 | Loss: 0.00001173
Iteration 49/1000 | Loss: 0.00001173
Iteration 50/1000 | Loss: 0.00001173
Iteration 51/1000 | Loss: 0.00001173
Iteration 52/1000 | Loss: 0.00001173
Iteration 53/1000 | Loss: 0.00001173
Iteration 54/1000 | Loss: 0.00001172
Iteration 55/1000 | Loss: 0.00001172
Iteration 56/1000 | Loss: 0.00001172
Iteration 57/1000 | Loss: 0.00001172
Iteration 58/1000 | Loss: 0.00001172
Iteration 59/1000 | Loss: 0.00001172
Iteration 60/1000 | Loss: 0.00001172
Iteration 61/1000 | Loss: 0.00001172
Iteration 62/1000 | Loss: 0.00001172
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 62. Stopping optimization.
Last 5 losses: [1.171638177765999e-05, 1.171638177765999e-05, 1.171638177765999e-05, 1.171638177765999e-05, 1.171638177765999e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.171638177765999e-05

Optimization complete. Final v2v error: 2.9370639324188232 mm

Highest mean error: 3.0226855278015137 mm for frame 35

Lowest mean error: 2.8302576541900635 mm for frame 57

Saving results

Total time: 26.56104874610901
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00820151
Iteration 2/25 | Loss: 0.00104998
Iteration 3/25 | Loss: 0.00082586
Iteration 4/25 | Loss: 0.00078137
Iteration 5/25 | Loss: 0.00076996
Iteration 6/25 | Loss: 0.00076842
Iteration 7/25 | Loss: 0.00076839
Iteration 8/25 | Loss: 0.00076839
Iteration 9/25 | Loss: 0.00076839
Iteration 10/25 | Loss: 0.00076839
Iteration 11/25 | Loss: 0.00076839
Iteration 12/25 | Loss: 0.00076839
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007683936273679137, 0.0007683936273679137, 0.0007683936273679137, 0.0007683936273679137, 0.0007683936273679137]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007683936273679137

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60341477
Iteration 2/25 | Loss: 0.00133537
Iteration 3/25 | Loss: 0.00133537
Iteration 4/25 | Loss: 0.00133537
Iteration 5/25 | Loss: 0.00133537
Iteration 6/25 | Loss: 0.00133537
Iteration 7/25 | Loss: 0.00133537
Iteration 8/25 | Loss: 0.00133537
Iteration 9/25 | Loss: 0.00133537
Iteration 10/25 | Loss: 0.00133537
Iteration 11/25 | Loss: 0.00133537
Iteration 12/25 | Loss: 0.00133537
Iteration 13/25 | Loss: 0.00133537
Iteration 14/25 | Loss: 0.00133537
Iteration 15/25 | Loss: 0.00133537
Iteration 16/25 | Loss: 0.00133537
Iteration 17/25 | Loss: 0.00133537
Iteration 18/25 | Loss: 0.00133537
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0013353662798181176, 0.0013353662798181176, 0.0013353662798181176, 0.0013353662798181176, 0.0013353662798181176]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013353662798181176

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00133537
Iteration 2/1000 | Loss: 0.00002292
Iteration 3/1000 | Loss: 0.00001532
Iteration 4/1000 | Loss: 0.00001412
Iteration 5/1000 | Loss: 0.00001320
Iteration 6/1000 | Loss: 0.00001285
Iteration 7/1000 | Loss: 0.00001261
Iteration 8/1000 | Loss: 0.00001248
Iteration 9/1000 | Loss: 0.00001241
Iteration 10/1000 | Loss: 0.00001234
Iteration 11/1000 | Loss: 0.00001232
Iteration 12/1000 | Loss: 0.00001229
Iteration 13/1000 | Loss: 0.00001228
Iteration 14/1000 | Loss: 0.00001228
Iteration 15/1000 | Loss: 0.00001227
Iteration 16/1000 | Loss: 0.00001227
Iteration 17/1000 | Loss: 0.00001227
Iteration 18/1000 | Loss: 0.00001226
Iteration 19/1000 | Loss: 0.00001226
Iteration 20/1000 | Loss: 0.00001225
Iteration 21/1000 | Loss: 0.00001224
Iteration 22/1000 | Loss: 0.00001220
Iteration 23/1000 | Loss: 0.00001220
Iteration 24/1000 | Loss: 0.00001219
Iteration 25/1000 | Loss: 0.00001215
Iteration 26/1000 | Loss: 0.00001212
Iteration 27/1000 | Loss: 0.00001212
Iteration 28/1000 | Loss: 0.00001211
Iteration 29/1000 | Loss: 0.00001211
Iteration 30/1000 | Loss: 0.00001210
Iteration 31/1000 | Loss: 0.00001210
Iteration 32/1000 | Loss: 0.00001209
Iteration 33/1000 | Loss: 0.00001209
Iteration 34/1000 | Loss: 0.00001208
Iteration 35/1000 | Loss: 0.00001207
Iteration 36/1000 | Loss: 0.00001207
Iteration 37/1000 | Loss: 0.00001207
Iteration 38/1000 | Loss: 0.00001206
Iteration 39/1000 | Loss: 0.00001206
Iteration 40/1000 | Loss: 0.00001206
Iteration 41/1000 | Loss: 0.00001206
Iteration 42/1000 | Loss: 0.00001205
Iteration 43/1000 | Loss: 0.00001204
Iteration 44/1000 | Loss: 0.00001204
Iteration 45/1000 | Loss: 0.00001203
Iteration 46/1000 | Loss: 0.00001200
Iteration 47/1000 | Loss: 0.00001200
Iteration 48/1000 | Loss: 0.00001200
Iteration 49/1000 | Loss: 0.00001199
Iteration 50/1000 | Loss: 0.00001199
Iteration 51/1000 | Loss: 0.00001198
Iteration 52/1000 | Loss: 0.00001198
Iteration 53/1000 | Loss: 0.00001198
Iteration 54/1000 | Loss: 0.00001197
Iteration 55/1000 | Loss: 0.00001197
Iteration 56/1000 | Loss: 0.00001197
Iteration 57/1000 | Loss: 0.00001197
Iteration 58/1000 | Loss: 0.00001197
Iteration 59/1000 | Loss: 0.00001196
Iteration 60/1000 | Loss: 0.00001196
Iteration 61/1000 | Loss: 0.00001196
Iteration 62/1000 | Loss: 0.00001196
Iteration 63/1000 | Loss: 0.00001196
Iteration 64/1000 | Loss: 0.00001196
Iteration 65/1000 | Loss: 0.00001196
Iteration 66/1000 | Loss: 0.00001196
Iteration 67/1000 | Loss: 0.00001195
Iteration 68/1000 | Loss: 0.00001195
Iteration 69/1000 | Loss: 0.00001195
Iteration 70/1000 | Loss: 0.00001195
Iteration 71/1000 | Loss: 0.00001195
Iteration 72/1000 | Loss: 0.00001195
Iteration 73/1000 | Loss: 0.00001195
Iteration 74/1000 | Loss: 0.00001195
Iteration 75/1000 | Loss: 0.00001195
Iteration 76/1000 | Loss: 0.00001195
Iteration 77/1000 | Loss: 0.00001195
Iteration 78/1000 | Loss: 0.00001195
Iteration 79/1000 | Loss: 0.00001195
Iteration 80/1000 | Loss: 0.00001195
Iteration 81/1000 | Loss: 0.00001195
Iteration 82/1000 | Loss: 0.00001195
Iteration 83/1000 | Loss: 0.00001195
Iteration 84/1000 | Loss: 0.00001195
Iteration 85/1000 | Loss: 0.00001195
Iteration 86/1000 | Loss: 0.00001195
Iteration 87/1000 | Loss: 0.00001195
Iteration 88/1000 | Loss: 0.00001195
Iteration 89/1000 | Loss: 0.00001195
Iteration 90/1000 | Loss: 0.00001195
Iteration 91/1000 | Loss: 0.00001195
Iteration 92/1000 | Loss: 0.00001195
Iteration 93/1000 | Loss: 0.00001195
Iteration 94/1000 | Loss: 0.00001195
Iteration 95/1000 | Loss: 0.00001195
Iteration 96/1000 | Loss: 0.00001195
Iteration 97/1000 | Loss: 0.00001195
Iteration 98/1000 | Loss: 0.00001195
Iteration 99/1000 | Loss: 0.00001195
Iteration 100/1000 | Loss: 0.00001195
Iteration 101/1000 | Loss: 0.00001195
Iteration 102/1000 | Loss: 0.00001195
Iteration 103/1000 | Loss: 0.00001195
Iteration 104/1000 | Loss: 0.00001195
Iteration 105/1000 | Loss: 0.00001195
Iteration 106/1000 | Loss: 0.00001195
Iteration 107/1000 | Loss: 0.00001195
Iteration 108/1000 | Loss: 0.00001195
Iteration 109/1000 | Loss: 0.00001195
Iteration 110/1000 | Loss: 0.00001195
Iteration 111/1000 | Loss: 0.00001195
Iteration 112/1000 | Loss: 0.00001195
Iteration 113/1000 | Loss: 0.00001195
Iteration 114/1000 | Loss: 0.00001195
Iteration 115/1000 | Loss: 0.00001195
Iteration 116/1000 | Loss: 0.00001195
Iteration 117/1000 | Loss: 0.00001195
Iteration 118/1000 | Loss: 0.00001195
Iteration 119/1000 | Loss: 0.00001195
Iteration 120/1000 | Loss: 0.00001195
Iteration 121/1000 | Loss: 0.00001195
Iteration 122/1000 | Loss: 0.00001195
Iteration 123/1000 | Loss: 0.00001195
Iteration 124/1000 | Loss: 0.00001195
Iteration 125/1000 | Loss: 0.00001195
Iteration 126/1000 | Loss: 0.00001195
Iteration 127/1000 | Loss: 0.00001195
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [1.1950586667808238e-05, 1.1950586667808238e-05, 1.1950586667808238e-05, 1.1950586667808238e-05, 1.1950586667808238e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1950586667808238e-05

Optimization complete. Final v2v error: 2.877321720123291 mm

Highest mean error: 3.0558016300201416 mm for frame 129

Lowest mean error: 2.6283581256866455 mm for frame 236

Saving results

Total time: 34.00687909126282
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1097/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1097.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1097
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468849
Iteration 2/25 | Loss: 0.00112056
Iteration 3/25 | Loss: 0.00077933
Iteration 4/25 | Loss: 0.00075579
Iteration 5/25 | Loss: 0.00074853
Iteration 6/25 | Loss: 0.00074636
Iteration 7/25 | Loss: 0.00074580
Iteration 8/25 | Loss: 0.00074574
Iteration 9/25 | Loss: 0.00074574
Iteration 10/25 | Loss: 0.00074574
Iteration 11/25 | Loss: 0.00074574
Iteration 12/25 | Loss: 0.00074574
Iteration 13/25 | Loss: 0.00074574
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007457437459379435, 0.0007457437459379435, 0.0007457437459379435, 0.0007457437459379435, 0.0007457437459379435]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007457437459379435

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.68479812
Iteration 2/25 | Loss: 0.00103566
Iteration 3/25 | Loss: 0.00103566
Iteration 4/25 | Loss: 0.00103566
Iteration 5/25 | Loss: 0.00103566
Iteration 6/25 | Loss: 0.00103566
Iteration 7/25 | Loss: 0.00103566
Iteration 8/25 | Loss: 0.00103566
Iteration 9/25 | Loss: 0.00103566
Iteration 10/25 | Loss: 0.00103566
Iteration 11/25 | Loss: 0.00103566
Iteration 12/25 | Loss: 0.00103566
Iteration 13/25 | Loss: 0.00103566
Iteration 14/25 | Loss: 0.00103566
Iteration 15/25 | Loss: 0.00103566
Iteration 16/25 | Loss: 0.00103566
Iteration 17/25 | Loss: 0.00103566
Iteration 18/25 | Loss: 0.00103566
Iteration 19/25 | Loss: 0.00103566
Iteration 20/25 | Loss: 0.00103566
Iteration 21/25 | Loss: 0.00103566
Iteration 22/25 | Loss: 0.00103566
Iteration 23/25 | Loss: 0.00103566
Iteration 24/25 | Loss: 0.00103566
Iteration 25/25 | Loss: 0.00103566

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00103566
Iteration 2/1000 | Loss: 0.00002890
Iteration 3/1000 | Loss: 0.00001921
Iteration 4/1000 | Loss: 0.00001751
Iteration 5/1000 | Loss: 0.00001669
Iteration 6/1000 | Loss: 0.00001627
Iteration 7/1000 | Loss: 0.00001571
Iteration 8/1000 | Loss: 0.00001538
Iteration 9/1000 | Loss: 0.00001515
Iteration 10/1000 | Loss: 0.00001497
Iteration 11/1000 | Loss: 0.00001497
Iteration 12/1000 | Loss: 0.00001485
Iteration 13/1000 | Loss: 0.00001478
Iteration 14/1000 | Loss: 0.00001478
Iteration 15/1000 | Loss: 0.00001473
Iteration 16/1000 | Loss: 0.00001473
Iteration 17/1000 | Loss: 0.00001471
Iteration 18/1000 | Loss: 0.00001471
Iteration 19/1000 | Loss: 0.00001470
Iteration 20/1000 | Loss: 0.00001467
Iteration 21/1000 | Loss: 0.00001467
Iteration 22/1000 | Loss: 0.00001466
Iteration 23/1000 | Loss: 0.00001463
Iteration 24/1000 | Loss: 0.00001463
Iteration 25/1000 | Loss: 0.00001462
Iteration 26/1000 | Loss: 0.00001462
Iteration 27/1000 | Loss: 0.00001461
Iteration 28/1000 | Loss: 0.00001461
Iteration 29/1000 | Loss: 0.00001461
Iteration 30/1000 | Loss: 0.00001459
Iteration 31/1000 | Loss: 0.00001459
Iteration 32/1000 | Loss: 0.00001459
Iteration 33/1000 | Loss: 0.00001458
Iteration 34/1000 | Loss: 0.00001458
Iteration 35/1000 | Loss: 0.00001458
Iteration 36/1000 | Loss: 0.00001455
Iteration 37/1000 | Loss: 0.00001455
Iteration 38/1000 | Loss: 0.00001455
Iteration 39/1000 | Loss: 0.00001455
Iteration 40/1000 | Loss: 0.00001454
Iteration 41/1000 | Loss: 0.00001454
Iteration 42/1000 | Loss: 0.00001454
Iteration 43/1000 | Loss: 0.00001452
Iteration 44/1000 | Loss: 0.00001451
Iteration 45/1000 | Loss: 0.00001451
Iteration 46/1000 | Loss: 0.00001450
Iteration 47/1000 | Loss: 0.00001449
Iteration 48/1000 | Loss: 0.00001449
Iteration 49/1000 | Loss: 0.00001449
Iteration 50/1000 | Loss: 0.00001448
Iteration 51/1000 | Loss: 0.00001448
Iteration 52/1000 | Loss: 0.00001448
Iteration 53/1000 | Loss: 0.00001447
Iteration 54/1000 | Loss: 0.00001447
Iteration 55/1000 | Loss: 0.00001447
Iteration 56/1000 | Loss: 0.00001447
Iteration 57/1000 | Loss: 0.00001447
Iteration 58/1000 | Loss: 0.00001447
Iteration 59/1000 | Loss: 0.00001446
Iteration 60/1000 | Loss: 0.00001446
Iteration 61/1000 | Loss: 0.00001446
Iteration 62/1000 | Loss: 0.00001446
Iteration 63/1000 | Loss: 0.00001445
Iteration 64/1000 | Loss: 0.00001445
Iteration 65/1000 | Loss: 0.00001445
Iteration 66/1000 | Loss: 0.00001445
Iteration 67/1000 | Loss: 0.00001445
Iteration 68/1000 | Loss: 0.00001445
Iteration 69/1000 | Loss: 0.00001445
Iteration 70/1000 | Loss: 0.00001445
Iteration 71/1000 | Loss: 0.00001444
Iteration 72/1000 | Loss: 0.00001444
Iteration 73/1000 | Loss: 0.00001444
Iteration 74/1000 | Loss: 0.00001444
Iteration 75/1000 | Loss: 0.00001444
Iteration 76/1000 | Loss: 0.00001444
Iteration 77/1000 | Loss: 0.00001443
Iteration 78/1000 | Loss: 0.00001443
Iteration 79/1000 | Loss: 0.00001443
Iteration 80/1000 | Loss: 0.00001443
Iteration 81/1000 | Loss: 0.00001443
Iteration 82/1000 | Loss: 0.00001443
Iteration 83/1000 | Loss: 0.00001443
Iteration 84/1000 | Loss: 0.00001443
Iteration 85/1000 | Loss: 0.00001443
Iteration 86/1000 | Loss: 0.00001443
Iteration 87/1000 | Loss: 0.00001443
Iteration 88/1000 | Loss: 0.00001442
Iteration 89/1000 | Loss: 0.00001442
Iteration 90/1000 | Loss: 0.00001442
Iteration 91/1000 | Loss: 0.00001442
Iteration 92/1000 | Loss: 0.00001442
Iteration 93/1000 | Loss: 0.00001442
Iteration 94/1000 | Loss: 0.00001442
Iteration 95/1000 | Loss: 0.00001442
Iteration 96/1000 | Loss: 0.00001442
Iteration 97/1000 | Loss: 0.00001442
Iteration 98/1000 | Loss: 0.00001442
Iteration 99/1000 | Loss: 0.00001442
Iteration 100/1000 | Loss: 0.00001442
Iteration 101/1000 | Loss: 0.00001442
Iteration 102/1000 | Loss: 0.00001442
Iteration 103/1000 | Loss: 0.00001442
Iteration 104/1000 | Loss: 0.00001441
Iteration 105/1000 | Loss: 0.00001441
Iteration 106/1000 | Loss: 0.00001441
Iteration 107/1000 | Loss: 0.00001441
Iteration 108/1000 | Loss: 0.00001441
Iteration 109/1000 | Loss: 0.00001441
Iteration 110/1000 | Loss: 0.00001441
Iteration 111/1000 | Loss: 0.00001441
Iteration 112/1000 | Loss: 0.00001441
Iteration 113/1000 | Loss: 0.00001440
Iteration 114/1000 | Loss: 0.00001440
Iteration 115/1000 | Loss: 0.00001440
Iteration 116/1000 | Loss: 0.00001440
Iteration 117/1000 | Loss: 0.00001440
Iteration 118/1000 | Loss: 0.00001440
Iteration 119/1000 | Loss: 0.00001440
Iteration 120/1000 | Loss: 0.00001439
Iteration 121/1000 | Loss: 0.00001439
Iteration 122/1000 | Loss: 0.00001439
Iteration 123/1000 | Loss: 0.00001439
Iteration 124/1000 | Loss: 0.00001439
Iteration 125/1000 | Loss: 0.00001439
Iteration 126/1000 | Loss: 0.00001439
Iteration 127/1000 | Loss: 0.00001439
Iteration 128/1000 | Loss: 0.00001439
Iteration 129/1000 | Loss: 0.00001439
Iteration 130/1000 | Loss: 0.00001439
Iteration 131/1000 | Loss: 0.00001439
Iteration 132/1000 | Loss: 0.00001438
Iteration 133/1000 | Loss: 0.00001438
Iteration 134/1000 | Loss: 0.00001438
Iteration 135/1000 | Loss: 0.00001438
Iteration 136/1000 | Loss: 0.00001438
Iteration 137/1000 | Loss: 0.00001438
Iteration 138/1000 | Loss: 0.00001438
Iteration 139/1000 | Loss: 0.00001438
Iteration 140/1000 | Loss: 0.00001438
Iteration 141/1000 | Loss: 0.00001438
Iteration 142/1000 | Loss: 0.00001438
Iteration 143/1000 | Loss: 0.00001438
Iteration 144/1000 | Loss: 0.00001438
Iteration 145/1000 | Loss: 0.00001437
Iteration 146/1000 | Loss: 0.00001437
Iteration 147/1000 | Loss: 0.00001437
Iteration 148/1000 | Loss: 0.00001437
Iteration 149/1000 | Loss: 0.00001437
Iteration 150/1000 | Loss: 0.00001437
Iteration 151/1000 | Loss: 0.00001437
Iteration 152/1000 | Loss: 0.00001437
Iteration 153/1000 | Loss: 0.00001436
Iteration 154/1000 | Loss: 0.00001436
Iteration 155/1000 | Loss: 0.00001436
Iteration 156/1000 | Loss: 0.00001436
Iteration 157/1000 | Loss: 0.00001436
Iteration 158/1000 | Loss: 0.00001436
Iteration 159/1000 | Loss: 0.00001435
Iteration 160/1000 | Loss: 0.00001435
Iteration 161/1000 | Loss: 0.00001435
Iteration 162/1000 | Loss: 0.00001435
Iteration 163/1000 | Loss: 0.00001435
Iteration 164/1000 | Loss: 0.00001435
Iteration 165/1000 | Loss: 0.00001435
Iteration 166/1000 | Loss: 0.00001435
Iteration 167/1000 | Loss: 0.00001435
Iteration 168/1000 | Loss: 0.00001435
Iteration 169/1000 | Loss: 0.00001435
Iteration 170/1000 | Loss: 0.00001434
Iteration 171/1000 | Loss: 0.00001434
Iteration 172/1000 | Loss: 0.00001434
Iteration 173/1000 | Loss: 0.00001434
Iteration 174/1000 | Loss: 0.00001434
Iteration 175/1000 | Loss: 0.00001434
Iteration 176/1000 | Loss: 0.00001434
Iteration 177/1000 | Loss: 0.00001433
Iteration 178/1000 | Loss: 0.00001433
Iteration 179/1000 | Loss: 0.00001433
Iteration 180/1000 | Loss: 0.00001433
Iteration 181/1000 | Loss: 0.00001433
Iteration 182/1000 | Loss: 0.00001433
Iteration 183/1000 | Loss: 0.00001433
Iteration 184/1000 | Loss: 0.00001433
Iteration 185/1000 | Loss: 0.00001432
Iteration 186/1000 | Loss: 0.00001432
Iteration 187/1000 | Loss: 0.00001432
Iteration 188/1000 | Loss: 0.00001432
Iteration 189/1000 | Loss: 0.00001432
Iteration 190/1000 | Loss: 0.00001432
Iteration 191/1000 | Loss: 0.00001432
Iteration 192/1000 | Loss: 0.00001432
Iteration 193/1000 | Loss: 0.00001432
Iteration 194/1000 | Loss: 0.00001432
Iteration 195/1000 | Loss: 0.00001432
Iteration 196/1000 | Loss: 0.00001431
Iteration 197/1000 | Loss: 0.00001431
Iteration 198/1000 | Loss: 0.00001431
Iteration 199/1000 | Loss: 0.00001431
Iteration 200/1000 | Loss: 0.00001431
Iteration 201/1000 | Loss: 0.00001431
Iteration 202/1000 | Loss: 0.00001431
Iteration 203/1000 | Loss: 0.00001431
Iteration 204/1000 | Loss: 0.00001431
Iteration 205/1000 | Loss: 0.00001431
Iteration 206/1000 | Loss: 0.00001431
Iteration 207/1000 | Loss: 0.00001431
Iteration 208/1000 | Loss: 0.00001431
Iteration 209/1000 | Loss: 0.00001431
Iteration 210/1000 | Loss: 0.00001430
Iteration 211/1000 | Loss: 0.00001430
Iteration 212/1000 | Loss: 0.00001430
Iteration 213/1000 | Loss: 0.00001430
Iteration 214/1000 | Loss: 0.00001430
Iteration 215/1000 | Loss: 0.00001430
Iteration 216/1000 | Loss: 0.00001430
Iteration 217/1000 | Loss: 0.00001430
Iteration 218/1000 | Loss: 0.00001430
Iteration 219/1000 | Loss: 0.00001430
Iteration 220/1000 | Loss: 0.00001430
Iteration 221/1000 | Loss: 0.00001430
Iteration 222/1000 | Loss: 0.00001430
Iteration 223/1000 | Loss: 0.00001430
Iteration 224/1000 | Loss: 0.00001430
Iteration 225/1000 | Loss: 0.00001430
Iteration 226/1000 | Loss: 0.00001430
Iteration 227/1000 | Loss: 0.00001430
Iteration 228/1000 | Loss: 0.00001430
Iteration 229/1000 | Loss: 0.00001430
Iteration 230/1000 | Loss: 0.00001430
Iteration 231/1000 | Loss: 0.00001430
Iteration 232/1000 | Loss: 0.00001430
Iteration 233/1000 | Loss: 0.00001430
Iteration 234/1000 | Loss: 0.00001430
Iteration 235/1000 | Loss: 0.00001430
Iteration 236/1000 | Loss: 0.00001430
Iteration 237/1000 | Loss: 0.00001430
Iteration 238/1000 | Loss: 0.00001430
Iteration 239/1000 | Loss: 0.00001430
Iteration 240/1000 | Loss: 0.00001430
Iteration 241/1000 | Loss: 0.00001430
Iteration 242/1000 | Loss: 0.00001430
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 242. Stopping optimization.
Last 5 losses: [1.4299575013865251e-05, 1.4299575013865251e-05, 1.4299575013865251e-05, 1.4299575013865251e-05, 1.4299575013865251e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4299575013865251e-05

Optimization complete. Final v2v error: 3.1308882236480713 mm

Highest mean error: 3.8295435905456543 mm for frame 22

Lowest mean error: 2.551410436630249 mm for frame 107

Saving results

Total time: 43.26590132713318
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00847673
Iteration 2/25 | Loss: 0.00095231
Iteration 3/25 | Loss: 0.00077048
Iteration 4/25 | Loss: 0.00074289
Iteration 5/25 | Loss: 0.00073667
Iteration 6/25 | Loss: 0.00073485
Iteration 7/25 | Loss: 0.00073426
Iteration 8/25 | Loss: 0.00073426
Iteration 9/25 | Loss: 0.00073426
Iteration 10/25 | Loss: 0.00073426
Iteration 11/25 | Loss: 0.00073426
Iteration 12/25 | Loss: 0.00073426
Iteration 13/25 | Loss: 0.00073426
Iteration 14/25 | Loss: 0.00073426
Iteration 15/25 | Loss: 0.00073426
Iteration 16/25 | Loss: 0.00073426
Iteration 17/25 | Loss: 0.00073426
Iteration 18/25 | Loss: 0.00073426
Iteration 19/25 | Loss: 0.00073426
Iteration 20/25 | Loss: 0.00073426
Iteration 21/25 | Loss: 0.00073426
Iteration 22/25 | Loss: 0.00073426
Iteration 23/25 | Loss: 0.00073426
Iteration 24/25 | Loss: 0.00073426
Iteration 25/25 | Loss: 0.00073426

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59168684
Iteration 2/25 | Loss: 0.00118406
Iteration 3/25 | Loss: 0.00118406
Iteration 4/25 | Loss: 0.00118406
Iteration 5/25 | Loss: 0.00118406
Iteration 6/25 | Loss: 0.00118406
Iteration 7/25 | Loss: 0.00118406
Iteration 8/25 | Loss: 0.00118406
Iteration 9/25 | Loss: 0.00118406
Iteration 10/25 | Loss: 0.00118406
Iteration 11/25 | Loss: 0.00118406
Iteration 12/25 | Loss: 0.00118406
Iteration 13/25 | Loss: 0.00118406
Iteration 14/25 | Loss: 0.00118406
Iteration 15/25 | Loss: 0.00118406
Iteration 16/25 | Loss: 0.00118406
Iteration 17/25 | Loss: 0.00118406
Iteration 18/25 | Loss: 0.00118406
Iteration 19/25 | Loss: 0.00118406
Iteration 20/25 | Loss: 0.00118406
Iteration 21/25 | Loss: 0.00118406
Iteration 22/25 | Loss: 0.00118406
Iteration 23/25 | Loss: 0.00118406
Iteration 24/25 | Loss: 0.00118406
Iteration 25/25 | Loss: 0.00118406

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118406
Iteration 2/1000 | Loss: 0.00002254
Iteration 3/1000 | Loss: 0.00001461
Iteration 4/1000 | Loss: 0.00001319
Iteration 5/1000 | Loss: 0.00001229
Iteration 6/1000 | Loss: 0.00001194
Iteration 7/1000 | Loss: 0.00001163
Iteration 8/1000 | Loss: 0.00001145
Iteration 9/1000 | Loss: 0.00001144
Iteration 10/1000 | Loss: 0.00001143
Iteration 11/1000 | Loss: 0.00001143
Iteration 12/1000 | Loss: 0.00001140
Iteration 13/1000 | Loss: 0.00001140
Iteration 14/1000 | Loss: 0.00001139
Iteration 15/1000 | Loss: 0.00001139
Iteration 16/1000 | Loss: 0.00001139
Iteration 17/1000 | Loss: 0.00001138
Iteration 18/1000 | Loss: 0.00001133
Iteration 19/1000 | Loss: 0.00001128
Iteration 20/1000 | Loss: 0.00001127
Iteration 21/1000 | Loss: 0.00001127
Iteration 22/1000 | Loss: 0.00001123
Iteration 23/1000 | Loss: 0.00001120
Iteration 24/1000 | Loss: 0.00001120
Iteration 25/1000 | Loss: 0.00001120
Iteration 26/1000 | Loss: 0.00001119
Iteration 27/1000 | Loss: 0.00001118
Iteration 28/1000 | Loss: 0.00001118
Iteration 29/1000 | Loss: 0.00001117
Iteration 30/1000 | Loss: 0.00001116
Iteration 31/1000 | Loss: 0.00001116
Iteration 32/1000 | Loss: 0.00001115
Iteration 33/1000 | Loss: 0.00001114
Iteration 34/1000 | Loss: 0.00001113
Iteration 35/1000 | Loss: 0.00001112
Iteration 36/1000 | Loss: 0.00001110
Iteration 37/1000 | Loss: 0.00001110
Iteration 38/1000 | Loss: 0.00001110
Iteration 39/1000 | Loss: 0.00001109
Iteration 40/1000 | Loss: 0.00001108
Iteration 41/1000 | Loss: 0.00001107
Iteration 42/1000 | Loss: 0.00001106
Iteration 43/1000 | Loss: 0.00001105
Iteration 44/1000 | Loss: 0.00001105
Iteration 45/1000 | Loss: 0.00001104
Iteration 46/1000 | Loss: 0.00001104
Iteration 47/1000 | Loss: 0.00001103
Iteration 48/1000 | Loss: 0.00001102
Iteration 49/1000 | Loss: 0.00001102
Iteration 50/1000 | Loss: 0.00001101
Iteration 51/1000 | Loss: 0.00001101
Iteration 52/1000 | Loss: 0.00001101
Iteration 53/1000 | Loss: 0.00001101
Iteration 54/1000 | Loss: 0.00001101
Iteration 55/1000 | Loss: 0.00001101
Iteration 56/1000 | Loss: 0.00001101
Iteration 57/1000 | Loss: 0.00001100
Iteration 58/1000 | Loss: 0.00001100
Iteration 59/1000 | Loss: 0.00001100
Iteration 60/1000 | Loss: 0.00001100
Iteration 61/1000 | Loss: 0.00001099
Iteration 62/1000 | Loss: 0.00001099
Iteration 63/1000 | Loss: 0.00001098
Iteration 64/1000 | Loss: 0.00001098
Iteration 65/1000 | Loss: 0.00001098
Iteration 66/1000 | Loss: 0.00001097
Iteration 67/1000 | Loss: 0.00001097
Iteration 68/1000 | Loss: 0.00001097
Iteration 69/1000 | Loss: 0.00001097
Iteration 70/1000 | Loss: 0.00001097
Iteration 71/1000 | Loss: 0.00001097
Iteration 72/1000 | Loss: 0.00001097
Iteration 73/1000 | Loss: 0.00001096
Iteration 74/1000 | Loss: 0.00001096
Iteration 75/1000 | Loss: 0.00001096
Iteration 76/1000 | Loss: 0.00001096
Iteration 77/1000 | Loss: 0.00001096
Iteration 78/1000 | Loss: 0.00001096
Iteration 79/1000 | Loss: 0.00001096
Iteration 80/1000 | Loss: 0.00001096
Iteration 81/1000 | Loss: 0.00001096
Iteration 82/1000 | Loss: 0.00001095
Iteration 83/1000 | Loss: 0.00001095
Iteration 84/1000 | Loss: 0.00001095
Iteration 85/1000 | Loss: 0.00001095
Iteration 86/1000 | Loss: 0.00001094
Iteration 87/1000 | Loss: 0.00001094
Iteration 88/1000 | Loss: 0.00001094
Iteration 89/1000 | Loss: 0.00001094
Iteration 90/1000 | Loss: 0.00001094
Iteration 91/1000 | Loss: 0.00001093
Iteration 92/1000 | Loss: 0.00001093
Iteration 93/1000 | Loss: 0.00001093
Iteration 94/1000 | Loss: 0.00001093
Iteration 95/1000 | Loss: 0.00001093
Iteration 96/1000 | Loss: 0.00001093
Iteration 97/1000 | Loss: 0.00001092
Iteration 98/1000 | Loss: 0.00001092
Iteration 99/1000 | Loss: 0.00001092
Iteration 100/1000 | Loss: 0.00001091
Iteration 101/1000 | Loss: 0.00001091
Iteration 102/1000 | Loss: 0.00001091
Iteration 103/1000 | Loss: 0.00001091
Iteration 104/1000 | Loss: 0.00001091
Iteration 105/1000 | Loss: 0.00001091
Iteration 106/1000 | Loss: 0.00001090
Iteration 107/1000 | Loss: 0.00001090
Iteration 108/1000 | Loss: 0.00001090
Iteration 109/1000 | Loss: 0.00001090
Iteration 110/1000 | Loss: 0.00001090
Iteration 111/1000 | Loss: 0.00001090
Iteration 112/1000 | Loss: 0.00001090
Iteration 113/1000 | Loss: 0.00001090
Iteration 114/1000 | Loss: 0.00001090
Iteration 115/1000 | Loss: 0.00001090
Iteration 116/1000 | Loss: 0.00001089
Iteration 117/1000 | Loss: 0.00001089
Iteration 118/1000 | Loss: 0.00001089
Iteration 119/1000 | Loss: 0.00001089
Iteration 120/1000 | Loss: 0.00001089
Iteration 121/1000 | Loss: 0.00001089
Iteration 122/1000 | Loss: 0.00001089
Iteration 123/1000 | Loss: 0.00001089
Iteration 124/1000 | Loss: 0.00001088
Iteration 125/1000 | Loss: 0.00001088
Iteration 126/1000 | Loss: 0.00001088
Iteration 127/1000 | Loss: 0.00001088
Iteration 128/1000 | Loss: 0.00001088
Iteration 129/1000 | Loss: 0.00001088
Iteration 130/1000 | Loss: 0.00001088
Iteration 131/1000 | Loss: 0.00001088
Iteration 132/1000 | Loss: 0.00001088
Iteration 133/1000 | Loss: 0.00001088
Iteration 134/1000 | Loss: 0.00001088
Iteration 135/1000 | Loss: 0.00001088
Iteration 136/1000 | Loss: 0.00001088
Iteration 137/1000 | Loss: 0.00001088
Iteration 138/1000 | Loss: 0.00001088
Iteration 139/1000 | Loss: 0.00001088
Iteration 140/1000 | Loss: 0.00001088
Iteration 141/1000 | Loss: 0.00001087
Iteration 142/1000 | Loss: 0.00001087
Iteration 143/1000 | Loss: 0.00001087
Iteration 144/1000 | Loss: 0.00001087
Iteration 145/1000 | Loss: 0.00001087
Iteration 146/1000 | Loss: 0.00001087
Iteration 147/1000 | Loss: 0.00001087
Iteration 148/1000 | Loss: 0.00001087
Iteration 149/1000 | Loss: 0.00001087
Iteration 150/1000 | Loss: 0.00001087
Iteration 151/1000 | Loss: 0.00001087
Iteration 152/1000 | Loss: 0.00001087
Iteration 153/1000 | Loss: 0.00001087
Iteration 154/1000 | Loss: 0.00001087
Iteration 155/1000 | Loss: 0.00001087
Iteration 156/1000 | Loss: 0.00001086
Iteration 157/1000 | Loss: 0.00001086
Iteration 158/1000 | Loss: 0.00001086
Iteration 159/1000 | Loss: 0.00001086
Iteration 160/1000 | Loss: 0.00001086
Iteration 161/1000 | Loss: 0.00001086
Iteration 162/1000 | Loss: 0.00001086
Iteration 163/1000 | Loss: 0.00001086
Iteration 164/1000 | Loss: 0.00001086
Iteration 165/1000 | Loss: 0.00001086
Iteration 166/1000 | Loss: 0.00001086
Iteration 167/1000 | Loss: 0.00001086
Iteration 168/1000 | Loss: 0.00001086
Iteration 169/1000 | Loss: 0.00001086
Iteration 170/1000 | Loss: 0.00001086
Iteration 171/1000 | Loss: 0.00001086
Iteration 172/1000 | Loss: 0.00001086
Iteration 173/1000 | Loss: 0.00001086
Iteration 174/1000 | Loss: 0.00001086
Iteration 175/1000 | Loss: 0.00001086
Iteration 176/1000 | Loss: 0.00001086
Iteration 177/1000 | Loss: 0.00001086
Iteration 178/1000 | Loss: 0.00001086
Iteration 179/1000 | Loss: 0.00001086
Iteration 180/1000 | Loss: 0.00001086
Iteration 181/1000 | Loss: 0.00001086
Iteration 182/1000 | Loss: 0.00001086
Iteration 183/1000 | Loss: 0.00001086
Iteration 184/1000 | Loss: 0.00001086
Iteration 185/1000 | Loss: 0.00001086
Iteration 186/1000 | Loss: 0.00001086
Iteration 187/1000 | Loss: 0.00001086
Iteration 188/1000 | Loss: 0.00001086
Iteration 189/1000 | Loss: 0.00001086
Iteration 190/1000 | Loss: 0.00001086
Iteration 191/1000 | Loss: 0.00001086
Iteration 192/1000 | Loss: 0.00001086
Iteration 193/1000 | Loss: 0.00001086
Iteration 194/1000 | Loss: 0.00001086
Iteration 195/1000 | Loss: 0.00001086
Iteration 196/1000 | Loss: 0.00001086
Iteration 197/1000 | Loss: 0.00001086
Iteration 198/1000 | Loss: 0.00001086
Iteration 199/1000 | Loss: 0.00001086
Iteration 200/1000 | Loss: 0.00001086
Iteration 201/1000 | Loss: 0.00001086
Iteration 202/1000 | Loss: 0.00001086
Iteration 203/1000 | Loss: 0.00001086
Iteration 204/1000 | Loss: 0.00001086
Iteration 205/1000 | Loss: 0.00001086
Iteration 206/1000 | Loss: 0.00001086
Iteration 207/1000 | Loss: 0.00001086
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [1.0864845535252243e-05, 1.0864845535252243e-05, 1.0864845535252243e-05, 1.0864845535252243e-05, 1.0864845535252243e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0864845535252243e-05

Optimization complete. Final v2v error: 2.7943313121795654 mm

Highest mean error: 3.188448905944824 mm for frame 45

Lowest mean error: 2.6129088401794434 mm for frame 166

Saving results

Total time: 37.66520547866821
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1039/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1039.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1039
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01090024
Iteration 2/25 | Loss: 0.00420424
Iteration 3/25 | Loss: 0.00235446
Iteration 4/25 | Loss: 0.00204078
Iteration 5/25 | Loss: 0.00187101
Iteration 6/25 | Loss: 0.00189127
Iteration 7/25 | Loss: 0.00184252
Iteration 8/25 | Loss: 0.00178673
Iteration 9/25 | Loss: 0.00176248
Iteration 10/25 | Loss: 0.00174265
Iteration 11/25 | Loss: 0.00171753
Iteration 12/25 | Loss: 0.00170545
Iteration 13/25 | Loss: 0.00168696
Iteration 14/25 | Loss: 0.00167927
Iteration 15/25 | Loss: 0.00166360
Iteration 16/25 | Loss: 0.00166075
Iteration 17/25 | Loss: 0.00165662
Iteration 18/25 | Loss: 0.00164014
Iteration 19/25 | Loss: 0.00163678
Iteration 20/25 | Loss: 0.00163611
Iteration 21/25 | Loss: 0.00164113
Iteration 22/25 | Loss: 0.00163350
Iteration 23/25 | Loss: 0.00162951
Iteration 24/25 | Loss: 0.00162712
Iteration 25/25 | Loss: 0.00162508

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 9.66176987
Iteration 2/25 | Loss: 0.01563769
Iteration 3/25 | Loss: 0.00946976
Iteration 4/25 | Loss: 0.00946973
Iteration 5/25 | Loss: 0.00946973
Iteration 6/25 | Loss: 0.00946973
Iteration 7/25 | Loss: 0.00946973
Iteration 8/25 | Loss: 0.00946973
Iteration 9/25 | Loss: 0.00946973
Iteration 10/25 | Loss: 0.00946973
Iteration 11/25 | Loss: 0.00946973
Iteration 12/25 | Loss: 0.00946973
Iteration 13/25 | Loss: 0.00946973
Iteration 14/25 | Loss: 0.00946973
Iteration 15/25 | Loss: 0.00946973
Iteration 16/25 | Loss: 0.00946973
Iteration 17/25 | Loss: 0.00946973
Iteration 18/25 | Loss: 0.00946973
Iteration 19/25 | Loss: 0.00946973
Iteration 20/25 | Loss: 0.00946973
Iteration 21/25 | Loss: 0.00946973
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.009469727985560894, 0.009469727985560894, 0.009469727985560894, 0.009469727985560894, 0.009469727985560894]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.009469727985560894

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00946973
Iteration 2/1000 | Loss: 0.00563993
Iteration 3/1000 | Loss: 0.00054254
Iteration 4/1000 | Loss: 0.00070324
Iteration 5/1000 | Loss: 0.00069903
Iteration 6/1000 | Loss: 0.00116226
Iteration 7/1000 | Loss: 0.01231300
Iteration 8/1000 | Loss: 0.00934467
Iteration 9/1000 | Loss: 0.00611358
Iteration 10/1000 | Loss: 0.00128207
Iteration 11/1000 | Loss: 0.00160809
Iteration 12/1000 | Loss: 0.00535436
Iteration 13/1000 | Loss: 0.00047383
Iteration 14/1000 | Loss: 0.00044063
Iteration 15/1000 | Loss: 0.00013337
Iteration 16/1000 | Loss: 0.00087943
Iteration 17/1000 | Loss: 0.00271833
Iteration 18/1000 | Loss: 0.00389285
Iteration 19/1000 | Loss: 0.00050820
Iteration 20/1000 | Loss: 0.00261362
Iteration 21/1000 | Loss: 0.00008273
Iteration 22/1000 | Loss: 0.00023641
Iteration 23/1000 | Loss: 0.00074534
Iteration 24/1000 | Loss: 0.00159181
Iteration 25/1000 | Loss: 0.00025442
Iteration 26/1000 | Loss: 0.00020144
Iteration 27/1000 | Loss: 0.00006227
Iteration 28/1000 | Loss: 0.00005212
Iteration 29/1000 | Loss: 0.00021046
Iteration 30/1000 | Loss: 0.00004099
Iteration 31/1000 | Loss: 0.00003626
Iteration 32/1000 | Loss: 0.00003194
Iteration 33/1000 | Loss: 0.00003525
Iteration 34/1000 | Loss: 0.00052238
Iteration 35/1000 | Loss: 0.00002910
Iteration 36/1000 | Loss: 0.00002592
Iteration 37/1000 | Loss: 0.00002436
Iteration 38/1000 | Loss: 0.00002254
Iteration 39/1000 | Loss: 0.00002159
Iteration 40/1000 | Loss: 0.00002082
Iteration 41/1000 | Loss: 0.00002034
Iteration 42/1000 | Loss: 0.00002012
Iteration 43/1000 | Loss: 0.00001985
Iteration 44/1000 | Loss: 0.00001954
Iteration 45/1000 | Loss: 0.00001930
Iteration 46/1000 | Loss: 0.00001904
Iteration 47/1000 | Loss: 0.00024669
Iteration 48/1000 | Loss: 0.00002713
Iteration 49/1000 | Loss: 0.00002150
Iteration 50/1000 | Loss: 0.00001946
Iteration 51/1000 | Loss: 0.00001828
Iteration 52/1000 | Loss: 0.00001786
Iteration 53/1000 | Loss: 0.00001769
Iteration 54/1000 | Loss: 0.00001757
Iteration 55/1000 | Loss: 0.00001756
Iteration 56/1000 | Loss: 0.00001756
Iteration 57/1000 | Loss: 0.00001756
Iteration 58/1000 | Loss: 0.00001755
Iteration 59/1000 | Loss: 0.00001755
Iteration 60/1000 | Loss: 0.00001754
Iteration 61/1000 | Loss: 0.00001754
Iteration 62/1000 | Loss: 0.00001754
Iteration 63/1000 | Loss: 0.00001753
Iteration 64/1000 | Loss: 0.00001752
Iteration 65/1000 | Loss: 0.00001751
Iteration 66/1000 | Loss: 0.00001750
Iteration 67/1000 | Loss: 0.00001745
Iteration 68/1000 | Loss: 0.00001745
Iteration 69/1000 | Loss: 0.00001744
Iteration 70/1000 | Loss: 0.00001744
Iteration 71/1000 | Loss: 0.00001744
Iteration 72/1000 | Loss: 0.00001744
Iteration 73/1000 | Loss: 0.00001744
Iteration 74/1000 | Loss: 0.00001744
Iteration 75/1000 | Loss: 0.00001744
Iteration 76/1000 | Loss: 0.00001744
Iteration 77/1000 | Loss: 0.00001744
Iteration 78/1000 | Loss: 0.00001743
Iteration 79/1000 | Loss: 0.00001743
Iteration 80/1000 | Loss: 0.00001743
Iteration 81/1000 | Loss: 0.00001743
Iteration 82/1000 | Loss: 0.00001743
Iteration 83/1000 | Loss: 0.00001743
Iteration 84/1000 | Loss: 0.00001742
Iteration 85/1000 | Loss: 0.00001742
Iteration 86/1000 | Loss: 0.00001742
Iteration 87/1000 | Loss: 0.00001742
Iteration 88/1000 | Loss: 0.00001742
Iteration 89/1000 | Loss: 0.00001741
Iteration 90/1000 | Loss: 0.00001740
Iteration 91/1000 | Loss: 0.00001740
Iteration 92/1000 | Loss: 0.00001740
Iteration 93/1000 | Loss: 0.00001739
Iteration 94/1000 | Loss: 0.00001739
Iteration 95/1000 | Loss: 0.00001739
Iteration 96/1000 | Loss: 0.00001739
Iteration 97/1000 | Loss: 0.00001739
Iteration 98/1000 | Loss: 0.00001738
Iteration 99/1000 | Loss: 0.00001738
Iteration 100/1000 | Loss: 0.00001738
Iteration 101/1000 | Loss: 0.00001738
Iteration 102/1000 | Loss: 0.00001737
Iteration 103/1000 | Loss: 0.00001737
Iteration 104/1000 | Loss: 0.00001737
Iteration 105/1000 | Loss: 0.00001737
Iteration 106/1000 | Loss: 0.00001737
Iteration 107/1000 | Loss: 0.00001737
Iteration 108/1000 | Loss: 0.00001736
Iteration 109/1000 | Loss: 0.00001736
Iteration 110/1000 | Loss: 0.00001736
Iteration 111/1000 | Loss: 0.00001736
Iteration 112/1000 | Loss: 0.00001736
Iteration 113/1000 | Loss: 0.00001736
Iteration 114/1000 | Loss: 0.00001736
Iteration 115/1000 | Loss: 0.00001736
Iteration 116/1000 | Loss: 0.00001735
Iteration 117/1000 | Loss: 0.00001735
Iteration 118/1000 | Loss: 0.00001735
Iteration 119/1000 | Loss: 0.00001735
Iteration 120/1000 | Loss: 0.00001735
Iteration 121/1000 | Loss: 0.00001735
Iteration 122/1000 | Loss: 0.00001735
Iteration 123/1000 | Loss: 0.00001735
Iteration 124/1000 | Loss: 0.00001735
Iteration 125/1000 | Loss: 0.00001735
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [1.735346631903667e-05, 1.735346631903667e-05, 1.735346631903667e-05, 1.735346631903667e-05, 1.735346631903667e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.735346631903667e-05

Optimization complete. Final v2v error: 3.478888750076294 mm

Highest mean error: 4.8421173095703125 mm for frame 81

Lowest mean error: 3.12265682220459 mm for frame 185

Saving results

Total time: 133.28009343147278
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00873501
Iteration 2/25 | Loss: 0.00095941
Iteration 3/25 | Loss: 0.00077230
Iteration 4/25 | Loss: 0.00074351
Iteration 5/25 | Loss: 0.00073844
Iteration 6/25 | Loss: 0.00073694
Iteration 7/25 | Loss: 0.00073694
Iteration 8/25 | Loss: 0.00073694
Iteration 9/25 | Loss: 0.00073694
Iteration 10/25 | Loss: 0.00073694
Iteration 11/25 | Loss: 0.00073694
Iteration 12/25 | Loss: 0.00073694
Iteration 13/25 | Loss: 0.00073694
Iteration 14/25 | Loss: 0.00073694
Iteration 15/25 | Loss: 0.00073694
Iteration 16/25 | Loss: 0.00073694
Iteration 17/25 | Loss: 0.00073694
Iteration 18/25 | Loss: 0.00073694
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007369387894868851, 0.0007369387894868851, 0.0007369387894868851, 0.0007369387894868851, 0.0007369387894868851]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007369387894868851

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59019303
Iteration 2/25 | Loss: 0.00118959
Iteration 3/25 | Loss: 0.00118959
Iteration 4/25 | Loss: 0.00118958
Iteration 5/25 | Loss: 0.00118958
Iteration 6/25 | Loss: 0.00118958
Iteration 7/25 | Loss: 0.00118958
Iteration 8/25 | Loss: 0.00118958
Iteration 9/25 | Loss: 0.00118958
Iteration 10/25 | Loss: 0.00118958
Iteration 11/25 | Loss: 0.00118958
Iteration 12/25 | Loss: 0.00118958
Iteration 13/25 | Loss: 0.00118958
Iteration 14/25 | Loss: 0.00118958
Iteration 15/25 | Loss: 0.00118958
Iteration 16/25 | Loss: 0.00118958
Iteration 17/25 | Loss: 0.00118958
Iteration 18/25 | Loss: 0.00118958
Iteration 19/25 | Loss: 0.00118958
Iteration 20/25 | Loss: 0.00118958
Iteration 21/25 | Loss: 0.00118958
Iteration 22/25 | Loss: 0.00118958
Iteration 23/25 | Loss: 0.00118958
Iteration 24/25 | Loss: 0.00118958
Iteration 25/25 | Loss: 0.00118958

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118958
Iteration 2/1000 | Loss: 0.00002267
Iteration 3/1000 | Loss: 0.00001645
Iteration 4/1000 | Loss: 0.00001483
Iteration 5/1000 | Loss: 0.00001373
Iteration 6/1000 | Loss: 0.00001323
Iteration 7/1000 | Loss: 0.00001293
Iteration 8/1000 | Loss: 0.00001272
Iteration 9/1000 | Loss: 0.00001248
Iteration 10/1000 | Loss: 0.00001242
Iteration 11/1000 | Loss: 0.00001242
Iteration 12/1000 | Loss: 0.00001225
Iteration 13/1000 | Loss: 0.00001222
Iteration 14/1000 | Loss: 0.00001217
Iteration 15/1000 | Loss: 0.00001211
Iteration 16/1000 | Loss: 0.00001211
Iteration 17/1000 | Loss: 0.00001210
Iteration 18/1000 | Loss: 0.00001204
Iteration 19/1000 | Loss: 0.00001204
Iteration 20/1000 | Loss: 0.00001204
Iteration 21/1000 | Loss: 0.00001204
Iteration 22/1000 | Loss: 0.00001203
Iteration 23/1000 | Loss: 0.00001203
Iteration 24/1000 | Loss: 0.00001202
Iteration 25/1000 | Loss: 0.00001202
Iteration 26/1000 | Loss: 0.00001201
Iteration 27/1000 | Loss: 0.00001201
Iteration 28/1000 | Loss: 0.00001200
Iteration 29/1000 | Loss: 0.00001200
Iteration 30/1000 | Loss: 0.00001199
Iteration 31/1000 | Loss: 0.00001195
Iteration 32/1000 | Loss: 0.00001190
Iteration 33/1000 | Loss: 0.00001189
Iteration 34/1000 | Loss: 0.00001189
Iteration 35/1000 | Loss: 0.00001188
Iteration 36/1000 | Loss: 0.00001188
Iteration 37/1000 | Loss: 0.00001188
Iteration 38/1000 | Loss: 0.00001186
Iteration 39/1000 | Loss: 0.00001186
Iteration 40/1000 | Loss: 0.00001185
Iteration 41/1000 | Loss: 0.00001185
Iteration 42/1000 | Loss: 0.00001185
Iteration 43/1000 | Loss: 0.00001184
Iteration 44/1000 | Loss: 0.00001184
Iteration 45/1000 | Loss: 0.00001184
Iteration 46/1000 | Loss: 0.00001184
Iteration 47/1000 | Loss: 0.00001184
Iteration 48/1000 | Loss: 0.00001184
Iteration 49/1000 | Loss: 0.00001184
Iteration 50/1000 | Loss: 0.00001183
Iteration 51/1000 | Loss: 0.00001183
Iteration 52/1000 | Loss: 0.00001182
Iteration 53/1000 | Loss: 0.00001182
Iteration 54/1000 | Loss: 0.00001182
Iteration 55/1000 | Loss: 0.00001182
Iteration 56/1000 | Loss: 0.00001181
Iteration 57/1000 | Loss: 0.00001181
Iteration 58/1000 | Loss: 0.00001181
Iteration 59/1000 | Loss: 0.00001181
Iteration 60/1000 | Loss: 0.00001181
Iteration 61/1000 | Loss: 0.00001181
Iteration 62/1000 | Loss: 0.00001181
Iteration 63/1000 | Loss: 0.00001181
Iteration 64/1000 | Loss: 0.00001181
Iteration 65/1000 | Loss: 0.00001181
Iteration 66/1000 | Loss: 0.00001181
Iteration 67/1000 | Loss: 0.00001181
Iteration 68/1000 | Loss: 0.00001181
Iteration 69/1000 | Loss: 0.00001181
Iteration 70/1000 | Loss: 0.00001180
Iteration 71/1000 | Loss: 0.00001180
Iteration 72/1000 | Loss: 0.00001179
Iteration 73/1000 | Loss: 0.00001179
Iteration 74/1000 | Loss: 0.00001179
Iteration 75/1000 | Loss: 0.00001179
Iteration 76/1000 | Loss: 0.00001179
Iteration 77/1000 | Loss: 0.00001179
Iteration 78/1000 | Loss: 0.00001179
Iteration 79/1000 | Loss: 0.00001179
Iteration 80/1000 | Loss: 0.00001178
Iteration 81/1000 | Loss: 0.00001178
Iteration 82/1000 | Loss: 0.00001178
Iteration 83/1000 | Loss: 0.00001178
Iteration 84/1000 | Loss: 0.00001178
Iteration 85/1000 | Loss: 0.00001178
Iteration 86/1000 | Loss: 0.00001178
Iteration 87/1000 | Loss: 0.00001178
Iteration 88/1000 | Loss: 0.00001178
Iteration 89/1000 | Loss: 0.00001178
Iteration 90/1000 | Loss: 0.00001178
Iteration 91/1000 | Loss: 0.00001177
Iteration 92/1000 | Loss: 0.00001177
Iteration 93/1000 | Loss: 0.00001177
Iteration 94/1000 | Loss: 0.00001177
Iteration 95/1000 | Loss: 0.00001177
Iteration 96/1000 | Loss: 0.00001177
Iteration 97/1000 | Loss: 0.00001177
Iteration 98/1000 | Loss: 0.00001177
Iteration 99/1000 | Loss: 0.00001177
Iteration 100/1000 | Loss: 0.00001177
Iteration 101/1000 | Loss: 0.00001177
Iteration 102/1000 | Loss: 0.00001177
Iteration 103/1000 | Loss: 0.00001177
Iteration 104/1000 | Loss: 0.00001177
Iteration 105/1000 | Loss: 0.00001177
Iteration 106/1000 | Loss: 0.00001177
Iteration 107/1000 | Loss: 0.00001177
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.1767266187234782e-05, 1.1767266187234782e-05, 1.1767266187234782e-05, 1.1767266187234782e-05, 1.1767266187234782e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1767266187234782e-05

Optimization complete. Final v2v error: 2.878262996673584 mm

Highest mean error: 3.0947890281677246 mm for frame 31

Lowest mean error: 2.6534125804901123 mm for frame 229

Saving results

Total time: 39.88529634475708
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1046
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00820332
Iteration 2/25 | Loss: 0.00091649
Iteration 3/25 | Loss: 0.00076611
Iteration 4/25 | Loss: 0.00074091
Iteration 5/25 | Loss: 0.00073655
Iteration 6/25 | Loss: 0.00073567
Iteration 7/25 | Loss: 0.00073567
Iteration 8/25 | Loss: 0.00073567
Iteration 9/25 | Loss: 0.00073567
Iteration 10/25 | Loss: 0.00073567
Iteration 11/25 | Loss: 0.00073567
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007356673013418913, 0.0007356673013418913, 0.0007356673013418913, 0.0007356673013418913, 0.0007356673013418913]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007356673013418913

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59300995
Iteration 2/25 | Loss: 0.00121410
Iteration 3/25 | Loss: 0.00121409
Iteration 4/25 | Loss: 0.00121409
Iteration 5/25 | Loss: 0.00121409
Iteration 6/25 | Loss: 0.00121409
Iteration 7/25 | Loss: 0.00121409
Iteration 8/25 | Loss: 0.00121409
Iteration 9/25 | Loss: 0.00121409
Iteration 10/25 | Loss: 0.00121409
Iteration 11/25 | Loss: 0.00121409
Iteration 12/25 | Loss: 0.00121409
Iteration 13/25 | Loss: 0.00121409
Iteration 14/25 | Loss: 0.00121409
Iteration 15/25 | Loss: 0.00121409
Iteration 16/25 | Loss: 0.00121409
Iteration 17/25 | Loss: 0.00121409
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012140915496274829, 0.0012140915496274829, 0.0012140915496274829, 0.0012140915496274829, 0.0012140915496274829]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012140915496274829

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00121409
Iteration 2/1000 | Loss: 0.00002238
Iteration 3/1000 | Loss: 0.00001375
Iteration 4/1000 | Loss: 0.00001246
Iteration 5/1000 | Loss: 0.00001141
Iteration 6/1000 | Loss: 0.00001108
Iteration 7/1000 | Loss: 0.00001082
Iteration 8/1000 | Loss: 0.00001079
Iteration 9/1000 | Loss: 0.00001075
Iteration 10/1000 | Loss: 0.00001075
Iteration 11/1000 | Loss: 0.00001071
Iteration 12/1000 | Loss: 0.00001065
Iteration 13/1000 | Loss: 0.00001065
Iteration 14/1000 | Loss: 0.00001062
Iteration 15/1000 | Loss: 0.00001061
Iteration 16/1000 | Loss: 0.00001056
Iteration 17/1000 | Loss: 0.00001048
Iteration 18/1000 | Loss: 0.00001048
Iteration 19/1000 | Loss: 0.00001046
Iteration 20/1000 | Loss: 0.00001045
Iteration 21/1000 | Loss: 0.00001045
Iteration 22/1000 | Loss: 0.00001043
Iteration 23/1000 | Loss: 0.00001042
Iteration 24/1000 | Loss: 0.00001042
Iteration 25/1000 | Loss: 0.00001041
Iteration 26/1000 | Loss: 0.00001041
Iteration 27/1000 | Loss: 0.00001040
Iteration 28/1000 | Loss: 0.00001040
Iteration 29/1000 | Loss: 0.00001039
Iteration 30/1000 | Loss: 0.00001038
Iteration 31/1000 | Loss: 0.00001038
Iteration 32/1000 | Loss: 0.00001038
Iteration 33/1000 | Loss: 0.00001037
Iteration 34/1000 | Loss: 0.00001037
Iteration 35/1000 | Loss: 0.00001037
Iteration 36/1000 | Loss: 0.00001036
Iteration 37/1000 | Loss: 0.00001036
Iteration 38/1000 | Loss: 0.00001036
Iteration 39/1000 | Loss: 0.00001036
Iteration 40/1000 | Loss: 0.00001036
Iteration 41/1000 | Loss: 0.00001035
Iteration 42/1000 | Loss: 0.00001035
Iteration 43/1000 | Loss: 0.00001035
Iteration 44/1000 | Loss: 0.00001034
Iteration 45/1000 | Loss: 0.00001034
Iteration 46/1000 | Loss: 0.00001034
Iteration 47/1000 | Loss: 0.00001034
Iteration 48/1000 | Loss: 0.00001033
Iteration 49/1000 | Loss: 0.00001033
Iteration 50/1000 | Loss: 0.00001033
Iteration 51/1000 | Loss: 0.00001033
Iteration 52/1000 | Loss: 0.00001032
Iteration 53/1000 | Loss: 0.00001032
Iteration 54/1000 | Loss: 0.00001032
Iteration 55/1000 | Loss: 0.00001032
Iteration 56/1000 | Loss: 0.00001031
Iteration 57/1000 | Loss: 0.00001031
Iteration 58/1000 | Loss: 0.00001031
Iteration 59/1000 | Loss: 0.00001031
Iteration 60/1000 | Loss: 0.00001030
Iteration 61/1000 | Loss: 0.00001030
Iteration 62/1000 | Loss: 0.00001030
Iteration 63/1000 | Loss: 0.00001030
Iteration 64/1000 | Loss: 0.00001029
Iteration 65/1000 | Loss: 0.00001029
Iteration 66/1000 | Loss: 0.00001029
Iteration 67/1000 | Loss: 0.00001029
Iteration 68/1000 | Loss: 0.00001029
Iteration 69/1000 | Loss: 0.00001029
Iteration 70/1000 | Loss: 0.00001029
Iteration 71/1000 | Loss: 0.00001029
Iteration 72/1000 | Loss: 0.00001029
Iteration 73/1000 | Loss: 0.00001029
Iteration 74/1000 | Loss: 0.00001029
Iteration 75/1000 | Loss: 0.00001029
Iteration 76/1000 | Loss: 0.00001028
Iteration 77/1000 | Loss: 0.00001028
Iteration 78/1000 | Loss: 0.00001028
Iteration 79/1000 | Loss: 0.00001028
Iteration 80/1000 | Loss: 0.00001028
Iteration 81/1000 | Loss: 0.00001028
Iteration 82/1000 | Loss: 0.00001028
Iteration 83/1000 | Loss: 0.00001028
Iteration 84/1000 | Loss: 0.00001028
Iteration 85/1000 | Loss: 0.00001028
Iteration 86/1000 | Loss: 0.00001028
Iteration 87/1000 | Loss: 0.00001028
Iteration 88/1000 | Loss: 0.00001028
Iteration 89/1000 | Loss: 0.00001028
Iteration 90/1000 | Loss: 0.00001028
Iteration 91/1000 | Loss: 0.00001027
Iteration 92/1000 | Loss: 0.00001027
Iteration 93/1000 | Loss: 0.00001027
Iteration 94/1000 | Loss: 0.00001027
Iteration 95/1000 | Loss: 0.00001027
Iteration 96/1000 | Loss: 0.00001027
Iteration 97/1000 | Loss: 0.00001027
Iteration 98/1000 | Loss: 0.00001027
Iteration 99/1000 | Loss: 0.00001027
Iteration 100/1000 | Loss: 0.00001027
Iteration 101/1000 | Loss: 0.00001027
Iteration 102/1000 | Loss: 0.00001027
Iteration 103/1000 | Loss: 0.00001027
Iteration 104/1000 | Loss: 0.00001027
Iteration 105/1000 | Loss: 0.00001027
Iteration 106/1000 | Loss: 0.00001027
Iteration 107/1000 | Loss: 0.00001026
Iteration 108/1000 | Loss: 0.00001026
Iteration 109/1000 | Loss: 0.00001026
Iteration 110/1000 | Loss: 0.00001026
Iteration 111/1000 | Loss: 0.00001026
Iteration 112/1000 | Loss: 0.00001026
Iteration 113/1000 | Loss: 0.00001026
Iteration 114/1000 | Loss: 0.00001026
Iteration 115/1000 | Loss: 0.00001026
Iteration 116/1000 | Loss: 0.00001026
Iteration 117/1000 | Loss: 0.00001026
Iteration 118/1000 | Loss: 0.00001026
Iteration 119/1000 | Loss: 0.00001026
Iteration 120/1000 | Loss: 0.00001025
Iteration 121/1000 | Loss: 0.00001025
Iteration 122/1000 | Loss: 0.00001025
Iteration 123/1000 | Loss: 0.00001025
Iteration 124/1000 | Loss: 0.00001025
Iteration 125/1000 | Loss: 0.00001025
Iteration 126/1000 | Loss: 0.00001025
Iteration 127/1000 | Loss: 0.00001025
Iteration 128/1000 | Loss: 0.00001025
Iteration 129/1000 | Loss: 0.00001025
Iteration 130/1000 | Loss: 0.00001025
Iteration 131/1000 | Loss: 0.00001024
Iteration 132/1000 | Loss: 0.00001024
Iteration 133/1000 | Loss: 0.00001024
Iteration 134/1000 | Loss: 0.00001024
Iteration 135/1000 | Loss: 0.00001024
Iteration 136/1000 | Loss: 0.00001024
Iteration 137/1000 | Loss: 0.00001024
Iteration 138/1000 | Loss: 0.00001024
Iteration 139/1000 | Loss: 0.00001024
Iteration 140/1000 | Loss: 0.00001023
Iteration 141/1000 | Loss: 0.00001023
Iteration 142/1000 | Loss: 0.00001023
Iteration 143/1000 | Loss: 0.00001023
Iteration 144/1000 | Loss: 0.00001023
Iteration 145/1000 | Loss: 0.00001023
Iteration 146/1000 | Loss: 0.00001023
Iteration 147/1000 | Loss: 0.00001023
Iteration 148/1000 | Loss: 0.00001023
Iteration 149/1000 | Loss: 0.00001023
Iteration 150/1000 | Loss: 0.00001023
Iteration 151/1000 | Loss: 0.00001023
Iteration 152/1000 | Loss: 0.00001023
Iteration 153/1000 | Loss: 0.00001023
Iteration 154/1000 | Loss: 0.00001023
Iteration 155/1000 | Loss: 0.00001022
Iteration 156/1000 | Loss: 0.00001022
Iteration 157/1000 | Loss: 0.00001022
Iteration 158/1000 | Loss: 0.00001022
Iteration 159/1000 | Loss: 0.00001022
Iteration 160/1000 | Loss: 0.00001022
Iteration 161/1000 | Loss: 0.00001021
Iteration 162/1000 | Loss: 0.00001021
Iteration 163/1000 | Loss: 0.00001021
Iteration 164/1000 | Loss: 0.00001020
Iteration 165/1000 | Loss: 0.00001020
Iteration 166/1000 | Loss: 0.00001020
Iteration 167/1000 | Loss: 0.00001020
Iteration 168/1000 | Loss: 0.00001020
Iteration 169/1000 | Loss: 0.00001020
Iteration 170/1000 | Loss: 0.00001020
Iteration 171/1000 | Loss: 0.00001019
Iteration 172/1000 | Loss: 0.00001019
Iteration 173/1000 | Loss: 0.00001019
Iteration 174/1000 | Loss: 0.00001019
Iteration 175/1000 | Loss: 0.00001019
Iteration 176/1000 | Loss: 0.00001019
Iteration 177/1000 | Loss: 0.00001019
Iteration 178/1000 | Loss: 0.00001019
Iteration 179/1000 | Loss: 0.00001019
Iteration 180/1000 | Loss: 0.00001019
Iteration 181/1000 | Loss: 0.00001019
Iteration 182/1000 | Loss: 0.00001019
Iteration 183/1000 | Loss: 0.00001018
Iteration 184/1000 | Loss: 0.00001018
Iteration 185/1000 | Loss: 0.00001018
Iteration 186/1000 | Loss: 0.00001018
Iteration 187/1000 | Loss: 0.00001018
Iteration 188/1000 | Loss: 0.00001018
Iteration 189/1000 | Loss: 0.00001018
Iteration 190/1000 | Loss: 0.00001018
Iteration 191/1000 | Loss: 0.00001018
Iteration 192/1000 | Loss: 0.00001018
Iteration 193/1000 | Loss: 0.00001018
Iteration 194/1000 | Loss: 0.00001017
Iteration 195/1000 | Loss: 0.00001017
Iteration 196/1000 | Loss: 0.00001017
Iteration 197/1000 | Loss: 0.00001017
Iteration 198/1000 | Loss: 0.00001017
Iteration 199/1000 | Loss: 0.00001017
Iteration 200/1000 | Loss: 0.00001017
Iteration 201/1000 | Loss: 0.00001017
Iteration 202/1000 | Loss: 0.00001017
Iteration 203/1000 | Loss: 0.00001017
Iteration 204/1000 | Loss: 0.00001017
Iteration 205/1000 | Loss: 0.00001017
Iteration 206/1000 | Loss: 0.00001016
Iteration 207/1000 | Loss: 0.00001016
Iteration 208/1000 | Loss: 0.00001016
Iteration 209/1000 | Loss: 0.00001016
Iteration 210/1000 | Loss: 0.00001016
Iteration 211/1000 | Loss: 0.00001016
Iteration 212/1000 | Loss: 0.00001016
Iteration 213/1000 | Loss: 0.00001016
Iteration 214/1000 | Loss: 0.00001016
Iteration 215/1000 | Loss: 0.00001016
Iteration 216/1000 | Loss: 0.00001016
Iteration 217/1000 | Loss: 0.00001016
Iteration 218/1000 | Loss: 0.00001016
Iteration 219/1000 | Loss: 0.00001016
Iteration 220/1000 | Loss: 0.00001016
Iteration 221/1000 | Loss: 0.00001016
Iteration 222/1000 | Loss: 0.00001016
Iteration 223/1000 | Loss: 0.00001016
Iteration 224/1000 | Loss: 0.00001016
Iteration 225/1000 | Loss: 0.00001016
Iteration 226/1000 | Loss: 0.00001016
Iteration 227/1000 | Loss: 0.00001016
Iteration 228/1000 | Loss: 0.00001016
Iteration 229/1000 | Loss: 0.00001016
Iteration 230/1000 | Loss: 0.00001016
Iteration 231/1000 | Loss: 0.00001016
Iteration 232/1000 | Loss: 0.00001016
Iteration 233/1000 | Loss: 0.00001016
Iteration 234/1000 | Loss: 0.00001016
Iteration 235/1000 | Loss: 0.00001016
Iteration 236/1000 | Loss: 0.00001016
Iteration 237/1000 | Loss: 0.00001016
Iteration 238/1000 | Loss: 0.00001016
Iteration 239/1000 | Loss: 0.00001016
Iteration 240/1000 | Loss: 0.00001016
Iteration 241/1000 | Loss: 0.00001016
Iteration 242/1000 | Loss: 0.00001016
Iteration 243/1000 | Loss: 0.00001016
Iteration 244/1000 | Loss: 0.00001016
Iteration 245/1000 | Loss: 0.00001016
Iteration 246/1000 | Loss: 0.00001016
Iteration 247/1000 | Loss: 0.00001016
Iteration 248/1000 | Loss: 0.00001016
Iteration 249/1000 | Loss: 0.00001016
Iteration 250/1000 | Loss: 0.00001016
Iteration 251/1000 | Loss: 0.00001016
Iteration 252/1000 | Loss: 0.00001016
Iteration 253/1000 | Loss: 0.00001016
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 253. Stopping optimization.
Last 5 losses: [1.015648103930289e-05, 1.015648103930289e-05, 1.015648103930289e-05, 1.015648103930289e-05, 1.015648103930289e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.015648103930289e-05

Optimization complete. Final v2v error: 2.702587604522705 mm

Highest mean error: 2.8942787647247314 mm for frame 56

Lowest mean error: 2.5542261600494385 mm for frame 196

Saving results

Total time: 39.379682540893555
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00478892
Iteration 2/25 | Loss: 0.00108228
Iteration 3/25 | Loss: 0.00084465
Iteration 4/25 | Loss: 0.00082239
Iteration 5/25 | Loss: 0.00081512
Iteration 6/25 | Loss: 0.00081271
Iteration 7/25 | Loss: 0.00081235
Iteration 8/25 | Loss: 0.00081235
Iteration 9/25 | Loss: 0.00081235
Iteration 10/25 | Loss: 0.00081235
Iteration 11/25 | Loss: 0.00081235
Iteration 12/25 | Loss: 0.00081235
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008123488514684141, 0.0008123488514684141, 0.0008123488514684141, 0.0008123488514684141, 0.0008123488514684141]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008123488514684141

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56369567
Iteration 2/25 | Loss: 0.00123110
Iteration 3/25 | Loss: 0.00123108
Iteration 4/25 | Loss: 0.00123108
Iteration 5/25 | Loss: 0.00123107
Iteration 6/25 | Loss: 0.00123107
Iteration 7/25 | Loss: 0.00123107
Iteration 8/25 | Loss: 0.00123107
Iteration 9/25 | Loss: 0.00123107
Iteration 10/25 | Loss: 0.00123107
Iteration 11/25 | Loss: 0.00123107
Iteration 12/25 | Loss: 0.00123107
Iteration 13/25 | Loss: 0.00123107
Iteration 14/25 | Loss: 0.00123107
Iteration 15/25 | Loss: 0.00123107
Iteration 16/25 | Loss: 0.00123107
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001231073634698987, 0.001231073634698987, 0.001231073634698987, 0.001231073634698987, 0.001231073634698987]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001231073634698987

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00123107
Iteration 2/1000 | Loss: 0.00003259
Iteration 3/1000 | Loss: 0.00002026
Iteration 4/1000 | Loss: 0.00001836
Iteration 5/1000 | Loss: 0.00001706
Iteration 6/1000 | Loss: 0.00001621
Iteration 7/1000 | Loss: 0.00001567
Iteration 8/1000 | Loss: 0.00001535
Iteration 9/1000 | Loss: 0.00001510
Iteration 10/1000 | Loss: 0.00001488
Iteration 11/1000 | Loss: 0.00001476
Iteration 12/1000 | Loss: 0.00001469
Iteration 13/1000 | Loss: 0.00001464
Iteration 14/1000 | Loss: 0.00001458
Iteration 15/1000 | Loss: 0.00001458
Iteration 16/1000 | Loss: 0.00001453
Iteration 17/1000 | Loss: 0.00001448
Iteration 18/1000 | Loss: 0.00001447
Iteration 19/1000 | Loss: 0.00001446
Iteration 20/1000 | Loss: 0.00001442
Iteration 21/1000 | Loss: 0.00001442
Iteration 22/1000 | Loss: 0.00001442
Iteration 23/1000 | Loss: 0.00001441
Iteration 24/1000 | Loss: 0.00001440
Iteration 25/1000 | Loss: 0.00001440
Iteration 26/1000 | Loss: 0.00001439
Iteration 27/1000 | Loss: 0.00001439
Iteration 28/1000 | Loss: 0.00001439
Iteration 29/1000 | Loss: 0.00001438
Iteration 30/1000 | Loss: 0.00001437
Iteration 31/1000 | Loss: 0.00001437
Iteration 32/1000 | Loss: 0.00001437
Iteration 33/1000 | Loss: 0.00001436
Iteration 34/1000 | Loss: 0.00001436
Iteration 35/1000 | Loss: 0.00001436
Iteration 36/1000 | Loss: 0.00001436
Iteration 37/1000 | Loss: 0.00001436
Iteration 38/1000 | Loss: 0.00001436
Iteration 39/1000 | Loss: 0.00001435
Iteration 40/1000 | Loss: 0.00001435
Iteration 41/1000 | Loss: 0.00001435
Iteration 42/1000 | Loss: 0.00001435
Iteration 43/1000 | Loss: 0.00001435
Iteration 44/1000 | Loss: 0.00001434
Iteration 45/1000 | Loss: 0.00001434
Iteration 46/1000 | Loss: 0.00001434
Iteration 47/1000 | Loss: 0.00001433
Iteration 48/1000 | Loss: 0.00001433
Iteration 49/1000 | Loss: 0.00001433
Iteration 50/1000 | Loss: 0.00001432
Iteration 51/1000 | Loss: 0.00001432
Iteration 52/1000 | Loss: 0.00001432
Iteration 53/1000 | Loss: 0.00001432
Iteration 54/1000 | Loss: 0.00001432
Iteration 55/1000 | Loss: 0.00001432
Iteration 56/1000 | Loss: 0.00001431
Iteration 57/1000 | Loss: 0.00001431
Iteration 58/1000 | Loss: 0.00001431
Iteration 59/1000 | Loss: 0.00001430
Iteration 60/1000 | Loss: 0.00001430
Iteration 61/1000 | Loss: 0.00001430
Iteration 62/1000 | Loss: 0.00001430
Iteration 63/1000 | Loss: 0.00001430
Iteration 64/1000 | Loss: 0.00001430
Iteration 65/1000 | Loss: 0.00001430
Iteration 66/1000 | Loss: 0.00001430
Iteration 67/1000 | Loss: 0.00001430
Iteration 68/1000 | Loss: 0.00001429
Iteration 69/1000 | Loss: 0.00001429
Iteration 70/1000 | Loss: 0.00001429
Iteration 71/1000 | Loss: 0.00001429
Iteration 72/1000 | Loss: 0.00001429
Iteration 73/1000 | Loss: 0.00001429
Iteration 74/1000 | Loss: 0.00001429
Iteration 75/1000 | Loss: 0.00001429
Iteration 76/1000 | Loss: 0.00001429
Iteration 77/1000 | Loss: 0.00001429
Iteration 78/1000 | Loss: 0.00001429
Iteration 79/1000 | Loss: 0.00001429
Iteration 80/1000 | Loss: 0.00001428
Iteration 81/1000 | Loss: 0.00001428
Iteration 82/1000 | Loss: 0.00001428
Iteration 83/1000 | Loss: 0.00001428
Iteration 84/1000 | Loss: 0.00001428
Iteration 85/1000 | Loss: 0.00001427
Iteration 86/1000 | Loss: 0.00001427
Iteration 87/1000 | Loss: 0.00001427
Iteration 88/1000 | Loss: 0.00001427
Iteration 89/1000 | Loss: 0.00001426
Iteration 90/1000 | Loss: 0.00001426
Iteration 91/1000 | Loss: 0.00001426
Iteration 92/1000 | Loss: 0.00001426
Iteration 93/1000 | Loss: 0.00001426
Iteration 94/1000 | Loss: 0.00001425
Iteration 95/1000 | Loss: 0.00001425
Iteration 96/1000 | Loss: 0.00001425
Iteration 97/1000 | Loss: 0.00001425
Iteration 98/1000 | Loss: 0.00001424
Iteration 99/1000 | Loss: 0.00001424
Iteration 100/1000 | Loss: 0.00001424
Iteration 101/1000 | Loss: 0.00001424
Iteration 102/1000 | Loss: 0.00001424
Iteration 103/1000 | Loss: 0.00001424
Iteration 104/1000 | Loss: 0.00001424
Iteration 105/1000 | Loss: 0.00001424
Iteration 106/1000 | Loss: 0.00001424
Iteration 107/1000 | Loss: 0.00001424
Iteration 108/1000 | Loss: 0.00001424
Iteration 109/1000 | Loss: 0.00001424
Iteration 110/1000 | Loss: 0.00001423
Iteration 111/1000 | Loss: 0.00001423
Iteration 112/1000 | Loss: 0.00001423
Iteration 113/1000 | Loss: 0.00001423
Iteration 114/1000 | Loss: 0.00001423
Iteration 115/1000 | Loss: 0.00001423
Iteration 116/1000 | Loss: 0.00001423
Iteration 117/1000 | Loss: 0.00001423
Iteration 118/1000 | Loss: 0.00001423
Iteration 119/1000 | Loss: 0.00001423
Iteration 120/1000 | Loss: 0.00001423
Iteration 121/1000 | Loss: 0.00001423
Iteration 122/1000 | Loss: 0.00001423
Iteration 123/1000 | Loss: 0.00001423
Iteration 124/1000 | Loss: 0.00001423
Iteration 125/1000 | Loss: 0.00001423
Iteration 126/1000 | Loss: 0.00001423
Iteration 127/1000 | Loss: 0.00001422
Iteration 128/1000 | Loss: 0.00001422
Iteration 129/1000 | Loss: 0.00001422
Iteration 130/1000 | Loss: 0.00001422
Iteration 131/1000 | Loss: 0.00001422
Iteration 132/1000 | Loss: 0.00001422
Iteration 133/1000 | Loss: 0.00001422
Iteration 134/1000 | Loss: 0.00001422
Iteration 135/1000 | Loss: 0.00001422
Iteration 136/1000 | Loss: 0.00001422
Iteration 137/1000 | Loss: 0.00001422
Iteration 138/1000 | Loss: 0.00001422
Iteration 139/1000 | Loss: 0.00001422
Iteration 140/1000 | Loss: 0.00001422
Iteration 141/1000 | Loss: 0.00001422
Iteration 142/1000 | Loss: 0.00001422
Iteration 143/1000 | Loss: 0.00001422
Iteration 144/1000 | Loss: 0.00001422
Iteration 145/1000 | Loss: 0.00001422
Iteration 146/1000 | Loss: 0.00001422
Iteration 147/1000 | Loss: 0.00001422
Iteration 148/1000 | Loss: 0.00001422
Iteration 149/1000 | Loss: 0.00001422
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 149. Stopping optimization.
Last 5 losses: [1.4217524039850105e-05, 1.4217524039850105e-05, 1.4217524039850105e-05, 1.4217524039850105e-05, 1.4217524039850105e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4217524039850105e-05

Optimization complete. Final v2v error: 3.190548896789551 mm

Highest mean error: 3.647548198699951 mm for frame 90

Lowest mean error: 2.8302745819091797 mm for frame 156

Saving results

Total time: 43.20793128013611
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1057/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1057.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1057
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00472410
Iteration 2/25 | Loss: 0.00096385
Iteration 3/25 | Loss: 0.00084361
Iteration 4/25 | Loss: 0.00081361
Iteration 5/25 | Loss: 0.00080821
Iteration 6/25 | Loss: 0.00080611
Iteration 7/25 | Loss: 0.00080599
Iteration 8/25 | Loss: 0.00080599
Iteration 9/25 | Loss: 0.00080599
Iteration 10/25 | Loss: 0.00080599
Iteration 11/25 | Loss: 0.00080599
Iteration 12/25 | Loss: 0.00080599
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008059853571467102, 0.0008059853571467102, 0.0008059853571467102, 0.0008059853571467102, 0.0008059853571467102]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008059853571467102

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60539341
Iteration 2/25 | Loss: 0.00127358
Iteration 3/25 | Loss: 0.00127357
Iteration 4/25 | Loss: 0.00127357
Iteration 5/25 | Loss: 0.00127357
Iteration 6/25 | Loss: 0.00127357
Iteration 7/25 | Loss: 0.00127357
Iteration 8/25 | Loss: 0.00127357
Iteration 9/25 | Loss: 0.00127357
Iteration 10/25 | Loss: 0.00127357
Iteration 11/25 | Loss: 0.00127357
Iteration 12/25 | Loss: 0.00127357
Iteration 13/25 | Loss: 0.00127357
Iteration 14/25 | Loss: 0.00127357
Iteration 15/25 | Loss: 0.00127357
Iteration 16/25 | Loss: 0.00127357
Iteration 17/25 | Loss: 0.00127357
Iteration 18/25 | Loss: 0.00127357
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0012735712807625532, 0.0012735712807625532, 0.0012735712807625532, 0.0012735712807625532, 0.0012735712807625532]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012735712807625532

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00127357
Iteration 2/1000 | Loss: 0.00004143
Iteration 3/1000 | Loss: 0.00002693
Iteration 4/1000 | Loss: 0.00002494
Iteration 5/1000 | Loss: 0.00002398
Iteration 6/1000 | Loss: 0.00002324
Iteration 7/1000 | Loss: 0.00002249
Iteration 8/1000 | Loss: 0.00002212
Iteration 9/1000 | Loss: 0.00002180
Iteration 10/1000 | Loss: 0.00002160
Iteration 11/1000 | Loss: 0.00002141
Iteration 12/1000 | Loss: 0.00002135
Iteration 13/1000 | Loss: 0.00002129
Iteration 14/1000 | Loss: 0.00002129
Iteration 15/1000 | Loss: 0.00002126
Iteration 16/1000 | Loss: 0.00002125
Iteration 17/1000 | Loss: 0.00002123
Iteration 18/1000 | Loss: 0.00002123
Iteration 19/1000 | Loss: 0.00002123
Iteration 20/1000 | Loss: 0.00002123
Iteration 21/1000 | Loss: 0.00002123
Iteration 22/1000 | Loss: 0.00002123
Iteration 23/1000 | Loss: 0.00002123
Iteration 24/1000 | Loss: 0.00002122
Iteration 25/1000 | Loss: 0.00002122
Iteration 26/1000 | Loss: 0.00002122
Iteration 27/1000 | Loss: 0.00002122
Iteration 28/1000 | Loss: 0.00002122
Iteration 29/1000 | Loss: 0.00002121
Iteration 30/1000 | Loss: 0.00002121
Iteration 31/1000 | Loss: 0.00002119
Iteration 32/1000 | Loss: 0.00002119
Iteration 33/1000 | Loss: 0.00002118
Iteration 34/1000 | Loss: 0.00002118
Iteration 35/1000 | Loss: 0.00002118
Iteration 36/1000 | Loss: 0.00002117
Iteration 37/1000 | Loss: 0.00002115
Iteration 38/1000 | Loss: 0.00002114
Iteration 39/1000 | Loss: 0.00002114
Iteration 40/1000 | Loss: 0.00002113
Iteration 41/1000 | Loss: 0.00002113
Iteration 42/1000 | Loss: 0.00002110
Iteration 43/1000 | Loss: 0.00002109
Iteration 44/1000 | Loss: 0.00002108
Iteration 45/1000 | Loss: 0.00002107
Iteration 46/1000 | Loss: 0.00002103
Iteration 47/1000 | Loss: 0.00002103
Iteration 48/1000 | Loss: 0.00002099
Iteration 49/1000 | Loss: 0.00002099
Iteration 50/1000 | Loss: 0.00002098
Iteration 51/1000 | Loss: 0.00002097
Iteration 52/1000 | Loss: 0.00002097
Iteration 53/1000 | Loss: 0.00002097
Iteration 54/1000 | Loss: 0.00002096
Iteration 55/1000 | Loss: 0.00002096
Iteration 56/1000 | Loss: 0.00002096
Iteration 57/1000 | Loss: 0.00002095
Iteration 58/1000 | Loss: 0.00002095
Iteration 59/1000 | Loss: 0.00002095
Iteration 60/1000 | Loss: 0.00002095
Iteration 61/1000 | Loss: 0.00002095
Iteration 62/1000 | Loss: 0.00002095
Iteration 63/1000 | Loss: 0.00002095
Iteration 64/1000 | Loss: 0.00002094
Iteration 65/1000 | Loss: 0.00002094
Iteration 66/1000 | Loss: 0.00002094
Iteration 67/1000 | Loss: 0.00002094
Iteration 68/1000 | Loss: 0.00002094
Iteration 69/1000 | Loss: 0.00002094
Iteration 70/1000 | Loss: 0.00002093
Iteration 71/1000 | Loss: 0.00002093
Iteration 72/1000 | Loss: 0.00002093
Iteration 73/1000 | Loss: 0.00002093
Iteration 74/1000 | Loss: 0.00002093
Iteration 75/1000 | Loss: 0.00002093
Iteration 76/1000 | Loss: 0.00002093
Iteration 77/1000 | Loss: 0.00002093
Iteration 78/1000 | Loss: 0.00002093
Iteration 79/1000 | Loss: 0.00002093
Iteration 80/1000 | Loss: 0.00002093
Iteration 81/1000 | Loss: 0.00002093
Iteration 82/1000 | Loss: 0.00002093
Iteration 83/1000 | Loss: 0.00002093
Iteration 84/1000 | Loss: 0.00002092
Iteration 85/1000 | Loss: 0.00002092
Iteration 86/1000 | Loss: 0.00002092
Iteration 87/1000 | Loss: 0.00002092
Iteration 88/1000 | Loss: 0.00002092
Iteration 89/1000 | Loss: 0.00002092
Iteration 90/1000 | Loss: 0.00002092
Iteration 91/1000 | Loss: 0.00002092
Iteration 92/1000 | Loss: 0.00002092
Iteration 93/1000 | Loss: 0.00002091
Iteration 94/1000 | Loss: 0.00002091
Iteration 95/1000 | Loss: 0.00002091
Iteration 96/1000 | Loss: 0.00002091
Iteration 97/1000 | Loss: 0.00002091
Iteration 98/1000 | Loss: 0.00002091
Iteration 99/1000 | Loss: 0.00002091
Iteration 100/1000 | Loss: 0.00002091
Iteration 101/1000 | Loss: 0.00002091
Iteration 102/1000 | Loss: 0.00002091
Iteration 103/1000 | Loss: 0.00002091
Iteration 104/1000 | Loss: 0.00002091
Iteration 105/1000 | Loss: 0.00002091
Iteration 106/1000 | Loss: 0.00002090
Iteration 107/1000 | Loss: 0.00002090
Iteration 108/1000 | Loss: 0.00002090
Iteration 109/1000 | Loss: 0.00002090
Iteration 110/1000 | Loss: 0.00002090
Iteration 111/1000 | Loss: 0.00002090
Iteration 112/1000 | Loss: 0.00002089
Iteration 113/1000 | Loss: 0.00002089
Iteration 114/1000 | Loss: 0.00002089
Iteration 115/1000 | Loss: 0.00002089
Iteration 116/1000 | Loss: 0.00002089
Iteration 117/1000 | Loss: 0.00002089
Iteration 118/1000 | Loss: 0.00002089
Iteration 119/1000 | Loss: 0.00002089
Iteration 120/1000 | Loss: 0.00002089
Iteration 121/1000 | Loss: 0.00002089
Iteration 122/1000 | Loss: 0.00002089
Iteration 123/1000 | Loss: 0.00002089
Iteration 124/1000 | Loss: 0.00002089
Iteration 125/1000 | Loss: 0.00002089
Iteration 126/1000 | Loss: 0.00002089
Iteration 127/1000 | Loss: 0.00002089
Iteration 128/1000 | Loss: 0.00002089
Iteration 129/1000 | Loss: 0.00002089
Iteration 130/1000 | Loss: 0.00002089
Iteration 131/1000 | Loss: 0.00002089
Iteration 132/1000 | Loss: 0.00002089
Iteration 133/1000 | Loss: 0.00002089
Iteration 134/1000 | Loss: 0.00002089
Iteration 135/1000 | Loss: 0.00002089
Iteration 136/1000 | Loss: 0.00002089
Iteration 137/1000 | Loss: 0.00002089
Iteration 138/1000 | Loss: 0.00002089
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [2.0887262508040294e-05, 2.0887262508040294e-05, 2.0887262508040294e-05, 2.0887262508040294e-05, 2.0887262508040294e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0887262508040294e-05

Optimization complete. Final v2v error: 3.8325424194335938 mm

Highest mean error: 4.238422393798828 mm for frame 41

Lowest mean error: 3.3348984718322754 mm for frame 66

Saving results

Total time: 41.92232847213745
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1058/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1058.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1058
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01073804
Iteration 2/25 | Loss: 0.00117843
Iteration 3/25 | Loss: 0.00082359
Iteration 4/25 | Loss: 0.00077567
Iteration 5/25 | Loss: 0.00075871
Iteration 6/25 | Loss: 0.00075469
Iteration 7/25 | Loss: 0.00075507
Iteration 8/25 | Loss: 0.00075394
Iteration 9/25 | Loss: 0.00075391
Iteration 10/25 | Loss: 0.00075390
Iteration 11/25 | Loss: 0.00075390
Iteration 12/25 | Loss: 0.00075390
Iteration 13/25 | Loss: 0.00075390
Iteration 14/25 | Loss: 0.00075390
Iteration 15/25 | Loss: 0.00075390
Iteration 16/25 | Loss: 0.00075390
Iteration 17/25 | Loss: 0.00075390
Iteration 18/25 | Loss: 0.00075389
Iteration 19/25 | Loss: 0.00075389
Iteration 20/25 | Loss: 0.00075389
Iteration 21/25 | Loss: 0.00075389
Iteration 22/25 | Loss: 0.00075389
Iteration 23/25 | Loss: 0.00075389
Iteration 24/25 | Loss: 0.00075389
Iteration 25/25 | Loss: 0.00075389

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58230114
Iteration 2/25 | Loss: 0.00119160
Iteration 3/25 | Loss: 0.00119160
Iteration 4/25 | Loss: 0.00119160
Iteration 5/25 | Loss: 0.00119160
Iteration 6/25 | Loss: 0.00119159
Iteration 7/25 | Loss: 0.00119159
Iteration 8/25 | Loss: 0.00119159
Iteration 9/25 | Loss: 0.00119159
Iteration 10/25 | Loss: 0.00119159
Iteration 11/25 | Loss: 0.00119159
Iteration 12/25 | Loss: 0.00119159
Iteration 13/25 | Loss: 0.00119159
Iteration 14/25 | Loss: 0.00119159
Iteration 15/25 | Loss: 0.00119159
Iteration 16/25 | Loss: 0.00119159
Iteration 17/25 | Loss: 0.00119159
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0011915939394384623, 0.0011915939394384623, 0.0011915939394384623, 0.0011915939394384623, 0.0011915939394384623]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011915939394384623

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00119159
Iteration 2/1000 | Loss: 0.00002831
Iteration 3/1000 | Loss: 0.00001897
Iteration 4/1000 | Loss: 0.00001785
Iteration 5/1000 | Loss: 0.00003106
Iteration 6/1000 | Loss: 0.00001787
Iteration 7/1000 | Loss: 0.00001706
Iteration 8/1000 | Loss: 0.00003644
Iteration 9/1000 | Loss: 0.00001661
Iteration 10/1000 | Loss: 0.00001631
Iteration 11/1000 | Loss: 0.00001611
Iteration 12/1000 | Loss: 0.00001605
Iteration 13/1000 | Loss: 0.00004366
Iteration 14/1000 | Loss: 0.00001592
Iteration 15/1000 | Loss: 0.00001584
Iteration 16/1000 | Loss: 0.00001583
Iteration 17/1000 | Loss: 0.00001578
Iteration 18/1000 | Loss: 0.00001574
Iteration 19/1000 | Loss: 0.00001573
Iteration 20/1000 | Loss: 0.00001573
Iteration 21/1000 | Loss: 0.00001573
Iteration 22/1000 | Loss: 0.00001572
Iteration 23/1000 | Loss: 0.00001571
Iteration 24/1000 | Loss: 0.00001570
Iteration 25/1000 | Loss: 0.00001570
Iteration 26/1000 | Loss: 0.00001569
Iteration 27/1000 | Loss: 0.00001568
Iteration 28/1000 | Loss: 0.00001567
Iteration 29/1000 | Loss: 0.00001567
Iteration 30/1000 | Loss: 0.00001566
Iteration 31/1000 | Loss: 0.00001566
Iteration 32/1000 | Loss: 0.00001566
Iteration 33/1000 | Loss: 0.00001565
Iteration 34/1000 | Loss: 0.00001565
Iteration 35/1000 | Loss: 0.00001565
Iteration 36/1000 | Loss: 0.00001563
Iteration 37/1000 | Loss: 0.00001562
Iteration 38/1000 | Loss: 0.00001562
Iteration 39/1000 | Loss: 0.00001562
Iteration 40/1000 | Loss: 0.00001562
Iteration 41/1000 | Loss: 0.00001562
Iteration 42/1000 | Loss: 0.00001562
Iteration 43/1000 | Loss: 0.00001561
Iteration 44/1000 | Loss: 0.00001561
Iteration 45/1000 | Loss: 0.00001561
Iteration 46/1000 | Loss: 0.00001561
Iteration 47/1000 | Loss: 0.00001560
Iteration 48/1000 | Loss: 0.00001560
Iteration 49/1000 | Loss: 0.00001559
Iteration 50/1000 | Loss: 0.00001559
Iteration 51/1000 | Loss: 0.00001559
Iteration 52/1000 | Loss: 0.00001556
Iteration 53/1000 | Loss: 0.00001556
Iteration 54/1000 | Loss: 0.00001555
Iteration 55/1000 | Loss: 0.00001555
Iteration 56/1000 | Loss: 0.00001555
Iteration 57/1000 | Loss: 0.00001554
Iteration 58/1000 | Loss: 0.00001554
Iteration 59/1000 | Loss: 0.00001554
Iteration 60/1000 | Loss: 0.00001554
Iteration 61/1000 | Loss: 0.00001554
Iteration 62/1000 | Loss: 0.00001554
Iteration 63/1000 | Loss: 0.00001554
Iteration 64/1000 | Loss: 0.00001554
Iteration 65/1000 | Loss: 0.00001554
Iteration 66/1000 | Loss: 0.00001554
Iteration 67/1000 | Loss: 0.00001553
Iteration 68/1000 | Loss: 0.00001553
Iteration 69/1000 | Loss: 0.00001553
Iteration 70/1000 | Loss: 0.00001552
Iteration 71/1000 | Loss: 0.00001552
Iteration 72/1000 | Loss: 0.00001551
Iteration 73/1000 | Loss: 0.00001551
Iteration 74/1000 | Loss: 0.00003388
Iteration 75/1000 | Loss: 0.00001738
Iteration 76/1000 | Loss: 0.00002005
Iteration 77/1000 | Loss: 0.00001547
Iteration 78/1000 | Loss: 0.00001547
Iteration 79/1000 | Loss: 0.00001546
Iteration 80/1000 | Loss: 0.00001546
Iteration 81/1000 | Loss: 0.00001546
Iteration 82/1000 | Loss: 0.00001546
Iteration 83/1000 | Loss: 0.00001546
Iteration 84/1000 | Loss: 0.00001546
Iteration 85/1000 | Loss: 0.00001546
Iteration 86/1000 | Loss: 0.00001546
Iteration 87/1000 | Loss: 0.00001546
Iteration 88/1000 | Loss: 0.00001546
Iteration 89/1000 | Loss: 0.00001546
Iteration 90/1000 | Loss: 0.00001546
Iteration 91/1000 | Loss: 0.00001545
Iteration 92/1000 | Loss: 0.00001545
Iteration 93/1000 | Loss: 0.00002855
Iteration 94/1000 | Loss: 0.00001547
Iteration 95/1000 | Loss: 0.00001547
Iteration 96/1000 | Loss: 0.00001547
Iteration 97/1000 | Loss: 0.00001547
Iteration 98/1000 | Loss: 0.00001546
Iteration 99/1000 | Loss: 0.00001546
Iteration 100/1000 | Loss: 0.00001546
Iteration 101/1000 | Loss: 0.00001546
Iteration 102/1000 | Loss: 0.00001546
Iteration 103/1000 | Loss: 0.00001546
Iteration 104/1000 | Loss: 0.00001546
Iteration 105/1000 | Loss: 0.00001546
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 105. Stopping optimization.
Last 5 losses: [1.5463834643014707e-05, 1.5463834643014707e-05, 1.5463834643014707e-05, 1.5463834643014707e-05, 1.5463834643014707e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5463834643014707e-05

Optimization complete. Final v2v error: 3.358651638031006 mm

Highest mean error: 3.4942891597747803 mm for frame 106

Lowest mean error: 2.964024305343628 mm for frame 0

Saving results

Total time: 44.42160105705261
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1091/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1091.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1091
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01048203
Iteration 2/25 | Loss: 0.00170527
Iteration 3/25 | Loss: 0.00104608
Iteration 4/25 | Loss: 0.00094097
Iteration 5/25 | Loss: 0.00089662
Iteration 6/25 | Loss: 0.00090937
Iteration 7/25 | Loss: 0.00088200
Iteration 8/25 | Loss: 0.00086280
Iteration 9/25 | Loss: 0.00083504
Iteration 10/25 | Loss: 0.00080387
Iteration 11/25 | Loss: 0.00079406
Iteration 12/25 | Loss: 0.00078390
Iteration 13/25 | Loss: 0.00077859
Iteration 14/25 | Loss: 0.00078189
Iteration 15/25 | Loss: 0.00077494
Iteration 16/25 | Loss: 0.00077208
Iteration 17/25 | Loss: 0.00077068
Iteration 18/25 | Loss: 0.00077046
Iteration 19/25 | Loss: 0.00077038
Iteration 20/25 | Loss: 0.00077038
Iteration 21/25 | Loss: 0.00077038
Iteration 22/25 | Loss: 0.00077038
Iteration 23/25 | Loss: 0.00077038
Iteration 24/25 | Loss: 0.00077038
Iteration 25/25 | Loss: 0.00077038

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67274165
Iteration 2/25 | Loss: 0.00134806
Iteration 3/25 | Loss: 0.00134805
Iteration 4/25 | Loss: 0.00134805
Iteration 5/25 | Loss: 0.00134805
Iteration 6/25 | Loss: 0.00134805
Iteration 7/25 | Loss: 0.00134805
Iteration 8/25 | Loss: 0.00134805
Iteration 9/25 | Loss: 0.00134805
Iteration 10/25 | Loss: 0.00134805
Iteration 11/25 | Loss: 0.00134805
Iteration 12/25 | Loss: 0.00134805
Iteration 13/25 | Loss: 0.00134805
Iteration 14/25 | Loss: 0.00126703
Iteration 15/25 | Loss: 0.00126701
Iteration 16/25 | Loss: 0.00126701
Iteration 17/25 | Loss: 0.00126700
Iteration 18/25 | Loss: 0.00126700
Iteration 19/25 | Loss: 0.00126700
Iteration 20/25 | Loss: 0.00126700
Iteration 21/25 | Loss: 0.00126700
Iteration 22/25 | Loss: 0.00126700
Iteration 23/25 | Loss: 0.00126700
Iteration 24/25 | Loss: 0.00126700
Iteration 25/25 | Loss: 0.00126700

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00126700
Iteration 2/1000 | Loss: 0.00010933
Iteration 3/1000 | Loss: 0.00001943
Iteration 4/1000 | Loss: 0.00001711
Iteration 5/1000 | Loss: 0.00001604
Iteration 6/1000 | Loss: 0.00001558
Iteration 7/1000 | Loss: 0.00001513
Iteration 8/1000 | Loss: 0.00001488
Iteration 9/1000 | Loss: 0.00051181
Iteration 10/1000 | Loss: 0.00001674
Iteration 11/1000 | Loss: 0.00001465
Iteration 12/1000 | Loss: 0.00001351
Iteration 13/1000 | Loss: 0.00001294
Iteration 14/1000 | Loss: 0.00001240
Iteration 15/1000 | Loss: 0.00001210
Iteration 16/1000 | Loss: 0.00001207
Iteration 17/1000 | Loss: 0.00001195
Iteration 18/1000 | Loss: 0.00001194
Iteration 19/1000 | Loss: 0.00001185
Iteration 20/1000 | Loss: 0.00001175
Iteration 21/1000 | Loss: 0.00001173
Iteration 22/1000 | Loss: 0.00001172
Iteration 23/1000 | Loss: 0.00001172
Iteration 24/1000 | Loss: 0.00001172
Iteration 25/1000 | Loss: 0.00001171
Iteration 26/1000 | Loss: 0.00001171
Iteration 27/1000 | Loss: 0.00001170
Iteration 28/1000 | Loss: 0.00001168
Iteration 29/1000 | Loss: 0.00001168
Iteration 30/1000 | Loss: 0.00001167
Iteration 31/1000 | Loss: 0.00001166
Iteration 32/1000 | Loss: 0.00001164
Iteration 33/1000 | Loss: 0.00001164
Iteration 34/1000 | Loss: 0.00001164
Iteration 35/1000 | Loss: 0.00001163
Iteration 36/1000 | Loss: 0.00001163
Iteration 37/1000 | Loss: 0.00001163
Iteration 38/1000 | Loss: 0.00001162
Iteration 39/1000 | Loss: 0.00001162
Iteration 40/1000 | Loss: 0.00001160
Iteration 41/1000 | Loss: 0.00001160
Iteration 42/1000 | Loss: 0.00001160
Iteration 43/1000 | Loss: 0.00001159
Iteration 44/1000 | Loss: 0.00001159
Iteration 45/1000 | Loss: 0.00001159
Iteration 46/1000 | Loss: 0.00001159
Iteration 47/1000 | Loss: 0.00001159
Iteration 48/1000 | Loss: 0.00001159
Iteration 49/1000 | Loss: 0.00001159
Iteration 50/1000 | Loss: 0.00001159
Iteration 51/1000 | Loss: 0.00001159
Iteration 52/1000 | Loss: 0.00001158
Iteration 53/1000 | Loss: 0.00001157
Iteration 54/1000 | Loss: 0.00001156
Iteration 55/1000 | Loss: 0.00001156
Iteration 56/1000 | Loss: 0.00001156
Iteration 57/1000 | Loss: 0.00001156
Iteration 58/1000 | Loss: 0.00001156
Iteration 59/1000 | Loss: 0.00001155
Iteration 60/1000 | Loss: 0.00001155
Iteration 61/1000 | Loss: 0.00001155
Iteration 62/1000 | Loss: 0.00001155
Iteration 63/1000 | Loss: 0.00001154
Iteration 64/1000 | Loss: 0.00001154
Iteration 65/1000 | Loss: 0.00001153
Iteration 66/1000 | Loss: 0.00001153
Iteration 67/1000 | Loss: 0.00001152
Iteration 68/1000 | Loss: 0.00001152
Iteration 69/1000 | Loss: 0.00001152
Iteration 70/1000 | Loss: 0.00001152
Iteration 71/1000 | Loss: 0.00001151
Iteration 72/1000 | Loss: 0.00001151
Iteration 73/1000 | Loss: 0.00001150
Iteration 74/1000 | Loss: 0.00001150
Iteration 75/1000 | Loss: 0.00001150
Iteration 76/1000 | Loss: 0.00001150
Iteration 77/1000 | Loss: 0.00001149
Iteration 78/1000 | Loss: 0.00001149
Iteration 79/1000 | Loss: 0.00001149
Iteration 80/1000 | Loss: 0.00001149
Iteration 81/1000 | Loss: 0.00001149
Iteration 82/1000 | Loss: 0.00001149
Iteration 83/1000 | Loss: 0.00001149
Iteration 84/1000 | Loss: 0.00001149
Iteration 85/1000 | Loss: 0.00001149
Iteration 86/1000 | Loss: 0.00001149
Iteration 87/1000 | Loss: 0.00001149
Iteration 88/1000 | Loss: 0.00001149
Iteration 89/1000 | Loss: 0.00001149
Iteration 90/1000 | Loss: 0.00001149
Iteration 91/1000 | Loss: 0.00001149
Iteration 92/1000 | Loss: 0.00001148
Iteration 93/1000 | Loss: 0.00001148
Iteration 94/1000 | Loss: 0.00001148
Iteration 95/1000 | Loss: 0.00001148
Iteration 96/1000 | Loss: 0.00001148
Iteration 97/1000 | Loss: 0.00001148
Iteration 98/1000 | Loss: 0.00001148
Iteration 99/1000 | Loss: 0.00001148
Iteration 100/1000 | Loss: 0.00001148
Iteration 101/1000 | Loss: 0.00001148
Iteration 102/1000 | Loss: 0.00001148
Iteration 103/1000 | Loss: 0.00001148
Iteration 104/1000 | Loss: 0.00001148
Iteration 105/1000 | Loss: 0.00001148
Iteration 106/1000 | Loss: 0.00001147
Iteration 107/1000 | Loss: 0.00001147
Iteration 108/1000 | Loss: 0.00001147
Iteration 109/1000 | Loss: 0.00001147
Iteration 110/1000 | Loss: 0.00001147
Iteration 111/1000 | Loss: 0.00001147
Iteration 112/1000 | Loss: 0.00001147
Iteration 113/1000 | Loss: 0.00001147
Iteration 114/1000 | Loss: 0.00001147
Iteration 115/1000 | Loss: 0.00001147
Iteration 116/1000 | Loss: 0.00001147
Iteration 117/1000 | Loss: 0.00001147
Iteration 118/1000 | Loss: 0.00001147
Iteration 119/1000 | Loss: 0.00001147
Iteration 120/1000 | Loss: 0.00001147
Iteration 121/1000 | Loss: 0.00001147
Iteration 122/1000 | Loss: 0.00001147
Iteration 123/1000 | Loss: 0.00001146
Iteration 124/1000 | Loss: 0.00001146
Iteration 125/1000 | Loss: 0.00001146
Iteration 126/1000 | Loss: 0.00001146
Iteration 127/1000 | Loss: 0.00001146
Iteration 128/1000 | Loss: 0.00001146
Iteration 129/1000 | Loss: 0.00001146
Iteration 130/1000 | Loss: 0.00001146
Iteration 131/1000 | Loss: 0.00001146
Iteration 132/1000 | Loss: 0.00001146
Iteration 133/1000 | Loss: 0.00001146
Iteration 134/1000 | Loss: 0.00001146
Iteration 135/1000 | Loss: 0.00001146
Iteration 136/1000 | Loss: 0.00001146
Iteration 137/1000 | Loss: 0.00001146
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 137. Stopping optimization.
Last 5 losses: [1.1462148904684e-05, 1.1462148904684e-05, 1.1462148904684e-05, 1.1462148904684e-05, 1.1462148904684e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1462148904684e-05

Optimization complete. Final v2v error: 2.872999668121338 mm

Highest mean error: 3.8541629314422607 mm for frame 66

Lowest mean error: 2.703155994415283 mm for frame 137

Saving results

Total time: 68.48767685890198
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00586153
Iteration 2/25 | Loss: 0.00122760
Iteration 3/25 | Loss: 0.00090285
Iteration 4/25 | Loss: 0.00081954
Iteration 5/25 | Loss: 0.00079719
Iteration 6/25 | Loss: 0.00078109
Iteration 7/25 | Loss: 0.00077857
Iteration 8/25 | Loss: 0.00077146
Iteration 9/25 | Loss: 0.00077088
Iteration 10/25 | Loss: 0.00077446
Iteration 11/25 | Loss: 0.00077347
Iteration 12/25 | Loss: 0.00077059
Iteration 13/25 | Loss: 0.00077055
Iteration 14/25 | Loss: 0.00077055
Iteration 15/25 | Loss: 0.00077055
Iteration 16/25 | Loss: 0.00077054
Iteration 17/25 | Loss: 0.00077054
Iteration 18/25 | Loss: 0.00077054
Iteration 19/25 | Loss: 0.00077054
Iteration 20/25 | Loss: 0.00077054
Iteration 21/25 | Loss: 0.00077054
Iteration 22/25 | Loss: 0.00077054
Iteration 23/25 | Loss: 0.00077054
Iteration 24/25 | Loss: 0.00077054
Iteration 25/25 | Loss: 0.00077054

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.38735247
Iteration 2/25 | Loss: 0.00132920
Iteration 3/25 | Loss: 0.00128630
Iteration 4/25 | Loss: 0.00128630
Iteration 5/25 | Loss: 0.00128630
Iteration 6/25 | Loss: 0.00128630
Iteration 7/25 | Loss: 0.00128630
Iteration 8/25 | Loss: 0.00128630
Iteration 9/25 | Loss: 0.00128630
Iteration 10/25 | Loss: 0.00128630
Iteration 11/25 | Loss: 0.00128630
Iteration 12/25 | Loss: 0.00128630
Iteration 13/25 | Loss: 0.00128630
Iteration 14/25 | Loss: 0.00128630
Iteration 15/25 | Loss: 0.00128630
Iteration 16/25 | Loss: 0.00128630
Iteration 17/25 | Loss: 0.00128630
Iteration 18/25 | Loss: 0.00128630
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0012862997828051448, 0.0012862997828051448, 0.0012862997828051448, 0.0012862997828051448, 0.0012862997828051448]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012862997828051448

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00128630
Iteration 2/1000 | Loss: 0.00003123
Iteration 3/1000 | Loss: 0.00002078
Iteration 4/1000 | Loss: 0.00001929
Iteration 5/1000 | Loss: 0.00001806
Iteration 6/1000 | Loss: 0.00001741
Iteration 7/1000 | Loss: 0.00041437
Iteration 8/1000 | Loss: 0.00002176
Iteration 9/1000 | Loss: 0.00001743
Iteration 10/1000 | Loss: 0.00001618
Iteration 11/1000 | Loss: 0.00001530
Iteration 12/1000 | Loss: 0.00001496
Iteration 13/1000 | Loss: 0.00001490
Iteration 14/1000 | Loss: 0.00001477
Iteration 15/1000 | Loss: 0.00001470
Iteration 16/1000 | Loss: 0.00001470
Iteration 17/1000 | Loss: 0.00001468
Iteration 18/1000 | Loss: 0.00001468
Iteration 19/1000 | Loss: 0.00001467
Iteration 20/1000 | Loss: 0.00001463
Iteration 21/1000 | Loss: 0.00001461
Iteration 22/1000 | Loss: 0.00001458
Iteration 23/1000 | Loss: 0.00001445
Iteration 24/1000 | Loss: 0.00001444
Iteration 25/1000 | Loss: 0.00001443
Iteration 26/1000 | Loss: 0.00001442
Iteration 27/1000 | Loss: 0.00001441
Iteration 28/1000 | Loss: 0.00001441
Iteration 29/1000 | Loss: 0.00001441
Iteration 30/1000 | Loss: 0.00001440
Iteration 31/1000 | Loss: 0.00001439
Iteration 32/1000 | Loss: 0.00001439
Iteration 33/1000 | Loss: 0.00001438
Iteration 34/1000 | Loss: 0.00001438
Iteration 35/1000 | Loss: 0.00001438
Iteration 36/1000 | Loss: 0.00001437
Iteration 37/1000 | Loss: 0.00001437
Iteration 38/1000 | Loss: 0.00001436
Iteration 39/1000 | Loss: 0.00001436
Iteration 40/1000 | Loss: 0.00001436
Iteration 41/1000 | Loss: 0.00001436
Iteration 42/1000 | Loss: 0.00001434
Iteration 43/1000 | Loss: 0.00001430
Iteration 44/1000 | Loss: 0.00001429
Iteration 45/1000 | Loss: 0.00001429
Iteration 46/1000 | Loss: 0.00001429
Iteration 47/1000 | Loss: 0.00001429
Iteration 48/1000 | Loss: 0.00001428
Iteration 49/1000 | Loss: 0.00001428
Iteration 50/1000 | Loss: 0.00001428
Iteration 51/1000 | Loss: 0.00001428
Iteration 52/1000 | Loss: 0.00001428
Iteration 53/1000 | Loss: 0.00001428
Iteration 54/1000 | Loss: 0.00001428
Iteration 55/1000 | Loss: 0.00001428
Iteration 56/1000 | Loss: 0.00001428
Iteration 57/1000 | Loss: 0.00001428
Iteration 58/1000 | Loss: 0.00001428
Iteration 59/1000 | Loss: 0.00001427
Iteration 60/1000 | Loss: 0.00001427
Iteration 61/1000 | Loss: 0.00001427
Iteration 62/1000 | Loss: 0.00001427
Iteration 63/1000 | Loss: 0.00001427
Iteration 64/1000 | Loss: 0.00001427
Iteration 65/1000 | Loss: 0.00001427
Iteration 66/1000 | Loss: 0.00001426
Iteration 67/1000 | Loss: 0.00001426
Iteration 68/1000 | Loss: 0.00001426
Iteration 69/1000 | Loss: 0.00001426
Iteration 70/1000 | Loss: 0.00001426
Iteration 71/1000 | Loss: 0.00001426
Iteration 72/1000 | Loss: 0.00001425
Iteration 73/1000 | Loss: 0.00001425
Iteration 74/1000 | Loss: 0.00001425
Iteration 75/1000 | Loss: 0.00001424
Iteration 76/1000 | Loss: 0.00001424
Iteration 77/1000 | Loss: 0.00001424
Iteration 78/1000 | Loss: 0.00001423
Iteration 79/1000 | Loss: 0.00001423
Iteration 80/1000 | Loss: 0.00001423
Iteration 81/1000 | Loss: 0.00001423
Iteration 82/1000 | Loss: 0.00001423
Iteration 83/1000 | Loss: 0.00001423
Iteration 84/1000 | Loss: 0.00001423
Iteration 85/1000 | Loss: 0.00001423
Iteration 86/1000 | Loss: 0.00001423
Iteration 87/1000 | Loss: 0.00001423
Iteration 88/1000 | Loss: 0.00001423
Iteration 89/1000 | Loss: 0.00001422
Iteration 90/1000 | Loss: 0.00001422
Iteration 91/1000 | Loss: 0.00001422
Iteration 92/1000 | Loss: 0.00001422
Iteration 93/1000 | Loss: 0.00001422
Iteration 94/1000 | Loss: 0.00001422
Iteration 95/1000 | Loss: 0.00001422
Iteration 96/1000 | Loss: 0.00001422
Iteration 97/1000 | Loss: 0.00001422
Iteration 98/1000 | Loss: 0.00001421
Iteration 99/1000 | Loss: 0.00001421
Iteration 100/1000 | Loss: 0.00001421
Iteration 101/1000 | Loss: 0.00001421
Iteration 102/1000 | Loss: 0.00001421
Iteration 103/1000 | Loss: 0.00001421
Iteration 104/1000 | Loss: 0.00001421
Iteration 105/1000 | Loss: 0.00001421
Iteration 106/1000 | Loss: 0.00001421
Iteration 107/1000 | Loss: 0.00001421
Iteration 108/1000 | Loss: 0.00001421
Iteration 109/1000 | Loss: 0.00001420
Iteration 110/1000 | Loss: 0.00001420
Iteration 111/1000 | Loss: 0.00001420
Iteration 112/1000 | Loss: 0.00001420
Iteration 113/1000 | Loss: 0.00001419
Iteration 114/1000 | Loss: 0.00001419
Iteration 115/1000 | Loss: 0.00001419
Iteration 116/1000 | Loss: 0.00001419
Iteration 117/1000 | Loss: 0.00001419
Iteration 118/1000 | Loss: 0.00001419
Iteration 119/1000 | Loss: 0.00001418
Iteration 120/1000 | Loss: 0.00001418
Iteration 121/1000 | Loss: 0.00001418
Iteration 122/1000 | Loss: 0.00001418
Iteration 123/1000 | Loss: 0.00001418
Iteration 124/1000 | Loss: 0.00001418
Iteration 125/1000 | Loss: 0.00001418
Iteration 126/1000 | Loss: 0.00001418
Iteration 127/1000 | Loss: 0.00001417
Iteration 128/1000 | Loss: 0.00001417
Iteration 129/1000 | Loss: 0.00001417
Iteration 130/1000 | Loss: 0.00001417
Iteration 131/1000 | Loss: 0.00001416
Iteration 132/1000 | Loss: 0.00001416
Iteration 133/1000 | Loss: 0.00001416
Iteration 134/1000 | Loss: 0.00001416
Iteration 135/1000 | Loss: 0.00001416
Iteration 136/1000 | Loss: 0.00001416
Iteration 137/1000 | Loss: 0.00001416
Iteration 138/1000 | Loss: 0.00001416
Iteration 139/1000 | Loss: 0.00001416
Iteration 140/1000 | Loss: 0.00001416
Iteration 141/1000 | Loss: 0.00001415
Iteration 142/1000 | Loss: 0.00001415
Iteration 143/1000 | Loss: 0.00001415
Iteration 144/1000 | Loss: 0.00001415
Iteration 145/1000 | Loss: 0.00001415
Iteration 146/1000 | Loss: 0.00001415
Iteration 147/1000 | Loss: 0.00001415
Iteration 148/1000 | Loss: 0.00001414
Iteration 149/1000 | Loss: 0.00001414
Iteration 150/1000 | Loss: 0.00001414
Iteration 151/1000 | Loss: 0.00001414
Iteration 152/1000 | Loss: 0.00001414
Iteration 153/1000 | Loss: 0.00001414
Iteration 154/1000 | Loss: 0.00001414
Iteration 155/1000 | Loss: 0.00001414
Iteration 156/1000 | Loss: 0.00001414
Iteration 157/1000 | Loss: 0.00001414
Iteration 158/1000 | Loss: 0.00001414
Iteration 159/1000 | Loss: 0.00001414
Iteration 160/1000 | Loss: 0.00001414
Iteration 161/1000 | Loss: 0.00001414
Iteration 162/1000 | Loss: 0.00001414
Iteration 163/1000 | Loss: 0.00001413
Iteration 164/1000 | Loss: 0.00001413
Iteration 165/1000 | Loss: 0.00001413
Iteration 166/1000 | Loss: 0.00001413
Iteration 167/1000 | Loss: 0.00001413
Iteration 168/1000 | Loss: 0.00001413
Iteration 169/1000 | Loss: 0.00001413
Iteration 170/1000 | Loss: 0.00001413
Iteration 171/1000 | Loss: 0.00001413
Iteration 172/1000 | Loss: 0.00001413
Iteration 173/1000 | Loss: 0.00001413
Iteration 174/1000 | Loss: 0.00001413
Iteration 175/1000 | Loss: 0.00001413
Iteration 176/1000 | Loss: 0.00001413
Iteration 177/1000 | Loss: 0.00001413
Iteration 178/1000 | Loss: 0.00001413
Iteration 179/1000 | Loss: 0.00001413
Iteration 180/1000 | Loss: 0.00001413
Iteration 181/1000 | Loss: 0.00001413
Iteration 182/1000 | Loss: 0.00001413
Iteration 183/1000 | Loss: 0.00001413
Iteration 184/1000 | Loss: 0.00001413
Iteration 185/1000 | Loss: 0.00001413
Iteration 186/1000 | Loss: 0.00001413
Iteration 187/1000 | Loss: 0.00001413
Iteration 188/1000 | Loss: 0.00001413
Iteration 189/1000 | Loss: 0.00001413
Iteration 190/1000 | Loss: 0.00001413
Iteration 191/1000 | Loss: 0.00001413
Iteration 192/1000 | Loss: 0.00001413
Iteration 193/1000 | Loss: 0.00001413
Iteration 194/1000 | Loss: 0.00001413
Iteration 195/1000 | Loss: 0.00001413
Iteration 196/1000 | Loss: 0.00001413
Iteration 197/1000 | Loss: 0.00001413
Iteration 198/1000 | Loss: 0.00001413
Iteration 199/1000 | Loss: 0.00001413
Iteration 200/1000 | Loss: 0.00001413
Iteration 201/1000 | Loss: 0.00001413
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 201. Stopping optimization.
Last 5 losses: [1.4130428098724224e-05, 1.4130428098724224e-05, 1.4130428098724224e-05, 1.4130428098724224e-05, 1.4130428098724224e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4130428098724224e-05

Optimization complete. Final v2v error: 3.177255153656006 mm

Highest mean error: 3.7813518047332764 mm for frame 171

Lowest mean error: 2.815870523452759 mm for frame 105

Saving results

Total time: 64.40832757949829
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1029/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1029.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1029
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00348728
Iteration 2/25 | Loss: 0.00102499
Iteration 3/25 | Loss: 0.00081654
Iteration 4/25 | Loss: 0.00077306
Iteration 5/25 | Loss: 0.00076012
Iteration 6/25 | Loss: 0.00075656
Iteration 7/25 | Loss: 0.00075562
Iteration 8/25 | Loss: 0.00075562
Iteration 9/25 | Loss: 0.00075562
Iteration 10/25 | Loss: 0.00075562
Iteration 11/25 | Loss: 0.00075562
Iteration 12/25 | Loss: 0.00075562
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007556193158961833, 0.0007556193158961833, 0.0007556193158961833, 0.0007556193158961833, 0.0007556193158961833]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007556193158961833

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60014677
Iteration 2/25 | Loss: 0.00137006
Iteration 3/25 | Loss: 0.00137005
Iteration 4/25 | Loss: 0.00137005
Iteration 5/25 | Loss: 0.00137004
Iteration 6/25 | Loss: 0.00137004
Iteration 7/25 | Loss: 0.00137004
Iteration 8/25 | Loss: 0.00137004
Iteration 9/25 | Loss: 0.00137004
Iteration 10/25 | Loss: 0.00137004
Iteration 11/25 | Loss: 0.00137004
Iteration 12/25 | Loss: 0.00137004
Iteration 13/25 | Loss: 0.00137004
Iteration 14/25 | Loss: 0.00137004
Iteration 15/25 | Loss: 0.00137004
Iteration 16/25 | Loss: 0.00137004
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001370042678900063, 0.001370042678900063, 0.001370042678900063, 0.001370042678900063, 0.001370042678900063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001370042678900063

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00137004
Iteration 2/1000 | Loss: 0.00002956
Iteration 3/1000 | Loss: 0.00002021
Iteration 4/1000 | Loss: 0.00001803
Iteration 5/1000 | Loss: 0.00001683
Iteration 6/1000 | Loss: 0.00001612
Iteration 7/1000 | Loss: 0.00001571
Iteration 8/1000 | Loss: 0.00001535
Iteration 9/1000 | Loss: 0.00001513
Iteration 10/1000 | Loss: 0.00001493
Iteration 11/1000 | Loss: 0.00001479
Iteration 12/1000 | Loss: 0.00001467
Iteration 13/1000 | Loss: 0.00001463
Iteration 14/1000 | Loss: 0.00001461
Iteration 15/1000 | Loss: 0.00001457
Iteration 16/1000 | Loss: 0.00001457
Iteration 17/1000 | Loss: 0.00001453
Iteration 18/1000 | Loss: 0.00001452
Iteration 19/1000 | Loss: 0.00001452
Iteration 20/1000 | Loss: 0.00001451
Iteration 21/1000 | Loss: 0.00001443
Iteration 22/1000 | Loss: 0.00001443
Iteration 23/1000 | Loss: 0.00001443
Iteration 24/1000 | Loss: 0.00001442
Iteration 25/1000 | Loss: 0.00001442
Iteration 26/1000 | Loss: 0.00001442
Iteration 27/1000 | Loss: 0.00001441
Iteration 28/1000 | Loss: 0.00001441
Iteration 29/1000 | Loss: 0.00001440
Iteration 30/1000 | Loss: 0.00001440
Iteration 31/1000 | Loss: 0.00001440
Iteration 32/1000 | Loss: 0.00001440
Iteration 33/1000 | Loss: 0.00001440
Iteration 34/1000 | Loss: 0.00001440
Iteration 35/1000 | Loss: 0.00001440
Iteration 36/1000 | Loss: 0.00001439
Iteration 37/1000 | Loss: 0.00001439
Iteration 38/1000 | Loss: 0.00001439
Iteration 39/1000 | Loss: 0.00001439
Iteration 40/1000 | Loss: 0.00001439
Iteration 41/1000 | Loss: 0.00001439
Iteration 42/1000 | Loss: 0.00001439
Iteration 43/1000 | Loss: 0.00001438
Iteration 44/1000 | Loss: 0.00001438
Iteration 45/1000 | Loss: 0.00001438
Iteration 46/1000 | Loss: 0.00001438
Iteration 47/1000 | Loss: 0.00001438
Iteration 48/1000 | Loss: 0.00001438
Iteration 49/1000 | Loss: 0.00001438
Iteration 50/1000 | Loss: 0.00001438
Iteration 51/1000 | Loss: 0.00001438
Iteration 52/1000 | Loss: 0.00001438
Iteration 53/1000 | Loss: 0.00001438
Iteration 54/1000 | Loss: 0.00001438
Iteration 55/1000 | Loss: 0.00001437
Iteration 56/1000 | Loss: 0.00001437
Iteration 57/1000 | Loss: 0.00001437
Iteration 58/1000 | Loss: 0.00001436
Iteration 59/1000 | Loss: 0.00001436
Iteration 60/1000 | Loss: 0.00001436
Iteration 61/1000 | Loss: 0.00001436
Iteration 62/1000 | Loss: 0.00001436
Iteration 63/1000 | Loss: 0.00001436
Iteration 64/1000 | Loss: 0.00001436
Iteration 65/1000 | Loss: 0.00001435
Iteration 66/1000 | Loss: 0.00001435
Iteration 67/1000 | Loss: 0.00001435
Iteration 68/1000 | Loss: 0.00001435
Iteration 69/1000 | Loss: 0.00001435
Iteration 70/1000 | Loss: 0.00001435
Iteration 71/1000 | Loss: 0.00001435
Iteration 72/1000 | Loss: 0.00001435
Iteration 73/1000 | Loss: 0.00001435
Iteration 74/1000 | Loss: 0.00001434
Iteration 75/1000 | Loss: 0.00001434
Iteration 76/1000 | Loss: 0.00001434
Iteration 77/1000 | Loss: 0.00001434
Iteration 78/1000 | Loss: 0.00001433
Iteration 79/1000 | Loss: 0.00001433
Iteration 80/1000 | Loss: 0.00001433
Iteration 81/1000 | Loss: 0.00001433
Iteration 82/1000 | Loss: 0.00001433
Iteration 83/1000 | Loss: 0.00001433
Iteration 84/1000 | Loss: 0.00001432
Iteration 85/1000 | Loss: 0.00001432
Iteration 86/1000 | Loss: 0.00001432
Iteration 87/1000 | Loss: 0.00001432
Iteration 88/1000 | Loss: 0.00001432
Iteration 89/1000 | Loss: 0.00001432
Iteration 90/1000 | Loss: 0.00001432
Iteration 91/1000 | Loss: 0.00001431
Iteration 92/1000 | Loss: 0.00001431
Iteration 93/1000 | Loss: 0.00001431
Iteration 94/1000 | Loss: 0.00001431
Iteration 95/1000 | Loss: 0.00001431
Iteration 96/1000 | Loss: 0.00001431
Iteration 97/1000 | Loss: 0.00001431
Iteration 98/1000 | Loss: 0.00001430
Iteration 99/1000 | Loss: 0.00001430
Iteration 100/1000 | Loss: 0.00001430
Iteration 101/1000 | Loss: 0.00001430
Iteration 102/1000 | Loss: 0.00001430
Iteration 103/1000 | Loss: 0.00001430
Iteration 104/1000 | Loss: 0.00001430
Iteration 105/1000 | Loss: 0.00001430
Iteration 106/1000 | Loss: 0.00001430
Iteration 107/1000 | Loss: 0.00001430
Iteration 108/1000 | Loss: 0.00001430
Iteration 109/1000 | Loss: 0.00001430
Iteration 110/1000 | Loss: 0.00001430
Iteration 111/1000 | Loss: 0.00001430
Iteration 112/1000 | Loss: 0.00001430
Iteration 113/1000 | Loss: 0.00001430
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [1.4303544048743788e-05, 1.4303544048743788e-05, 1.4303544048743788e-05, 1.4303544048743788e-05, 1.4303544048743788e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4303544048743788e-05

Optimization complete. Final v2v error: 3.2222936153411865 mm

Highest mean error: 3.430161952972412 mm for frame 5

Lowest mean error: 2.865018367767334 mm for frame 60

Saving results

Total time: 40.85138535499573
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1033/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1033.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1033
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00809192
Iteration 2/25 | Loss: 0.00099205
Iteration 3/25 | Loss: 0.00084426
Iteration 4/25 | Loss: 0.00080097
Iteration 5/25 | Loss: 0.00078647
Iteration 6/25 | Loss: 0.00078452
Iteration 7/25 | Loss: 0.00078385
Iteration 8/25 | Loss: 0.00078383
Iteration 9/25 | Loss: 0.00078383
Iteration 10/25 | Loss: 0.00078383
Iteration 11/25 | Loss: 0.00078383
Iteration 12/25 | Loss: 0.00078383
Iteration 13/25 | Loss: 0.00078383
Iteration 14/25 | Loss: 0.00078383
Iteration 15/25 | Loss: 0.00078383
Iteration 16/25 | Loss: 0.00078383
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007838279125280678, 0.0007838279125280678, 0.0007838279125280678, 0.0007838279125280678, 0.0007838279125280678]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007838279125280678

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55030549
Iteration 2/25 | Loss: 0.00145759
Iteration 3/25 | Loss: 0.00145759
Iteration 4/25 | Loss: 0.00145759
Iteration 5/25 | Loss: 0.00145759
Iteration 6/25 | Loss: 0.00145759
Iteration 7/25 | Loss: 0.00145759
Iteration 8/25 | Loss: 0.00145759
Iteration 9/25 | Loss: 0.00145759
Iteration 10/25 | Loss: 0.00145759
Iteration 11/25 | Loss: 0.00145759
Iteration 12/25 | Loss: 0.00145759
Iteration 13/25 | Loss: 0.00145759
Iteration 14/25 | Loss: 0.00145759
Iteration 15/25 | Loss: 0.00145759
Iteration 16/25 | Loss: 0.00145759
Iteration 17/25 | Loss: 0.00145759
Iteration 18/25 | Loss: 0.00145759
Iteration 19/25 | Loss: 0.00145759
Iteration 20/25 | Loss: 0.00145759
Iteration 21/25 | Loss: 0.00145759
Iteration 22/25 | Loss: 0.00145759
Iteration 23/25 | Loss: 0.00145759
Iteration 24/25 | Loss: 0.00145759
Iteration 25/25 | Loss: 0.00145759

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00145759
Iteration 2/1000 | Loss: 0.00003646
Iteration 3/1000 | Loss: 0.00002775
Iteration 4/1000 | Loss: 0.00002309
Iteration 5/1000 | Loss: 0.00002177
Iteration 6/1000 | Loss: 0.00002089
Iteration 7/1000 | Loss: 0.00002021
Iteration 8/1000 | Loss: 0.00001964
Iteration 9/1000 | Loss: 0.00001913
Iteration 10/1000 | Loss: 0.00001881
Iteration 11/1000 | Loss: 0.00001863
Iteration 12/1000 | Loss: 0.00001851
Iteration 13/1000 | Loss: 0.00001832
Iteration 14/1000 | Loss: 0.00001827
Iteration 15/1000 | Loss: 0.00001822
Iteration 16/1000 | Loss: 0.00001821
Iteration 17/1000 | Loss: 0.00001815
Iteration 18/1000 | Loss: 0.00001814
Iteration 19/1000 | Loss: 0.00001812
Iteration 20/1000 | Loss: 0.00001811
Iteration 21/1000 | Loss: 0.00001810
Iteration 22/1000 | Loss: 0.00001809
Iteration 23/1000 | Loss: 0.00001808
Iteration 24/1000 | Loss: 0.00001808
Iteration 25/1000 | Loss: 0.00001801
Iteration 26/1000 | Loss: 0.00001794
Iteration 27/1000 | Loss: 0.00001793
Iteration 28/1000 | Loss: 0.00001791
Iteration 29/1000 | Loss: 0.00001791
Iteration 30/1000 | Loss: 0.00001791
Iteration 31/1000 | Loss: 0.00001790
Iteration 32/1000 | Loss: 0.00001790
Iteration 33/1000 | Loss: 0.00001789
Iteration 34/1000 | Loss: 0.00001788
Iteration 35/1000 | Loss: 0.00001788
Iteration 36/1000 | Loss: 0.00001787
Iteration 37/1000 | Loss: 0.00001787
Iteration 38/1000 | Loss: 0.00001787
Iteration 39/1000 | Loss: 0.00001784
Iteration 40/1000 | Loss: 0.00001784
Iteration 41/1000 | Loss: 0.00001784
Iteration 42/1000 | Loss: 0.00001784
Iteration 43/1000 | Loss: 0.00001783
Iteration 44/1000 | Loss: 0.00001783
Iteration 45/1000 | Loss: 0.00001782
Iteration 46/1000 | Loss: 0.00001782
Iteration 47/1000 | Loss: 0.00001782
Iteration 48/1000 | Loss: 0.00001781
Iteration 49/1000 | Loss: 0.00001781
Iteration 50/1000 | Loss: 0.00001781
Iteration 51/1000 | Loss: 0.00001780
Iteration 52/1000 | Loss: 0.00001780
Iteration 53/1000 | Loss: 0.00001780
Iteration 54/1000 | Loss: 0.00001779
Iteration 55/1000 | Loss: 0.00001779
Iteration 56/1000 | Loss: 0.00001779
Iteration 57/1000 | Loss: 0.00001779
Iteration 58/1000 | Loss: 0.00001779
Iteration 59/1000 | Loss: 0.00001778
Iteration 60/1000 | Loss: 0.00001778
Iteration 61/1000 | Loss: 0.00001778
Iteration 62/1000 | Loss: 0.00001778
Iteration 63/1000 | Loss: 0.00001778
Iteration 64/1000 | Loss: 0.00001778
Iteration 65/1000 | Loss: 0.00001778
Iteration 66/1000 | Loss: 0.00001778
Iteration 67/1000 | Loss: 0.00001777
Iteration 68/1000 | Loss: 0.00001777
Iteration 69/1000 | Loss: 0.00001777
Iteration 70/1000 | Loss: 0.00001777
Iteration 71/1000 | Loss: 0.00001777
Iteration 72/1000 | Loss: 0.00001777
Iteration 73/1000 | Loss: 0.00001777
Iteration 74/1000 | Loss: 0.00001777
Iteration 75/1000 | Loss: 0.00001777
Iteration 76/1000 | Loss: 0.00001777
Iteration 77/1000 | Loss: 0.00001776
Iteration 78/1000 | Loss: 0.00001776
Iteration 79/1000 | Loss: 0.00001776
Iteration 80/1000 | Loss: 0.00001776
Iteration 81/1000 | Loss: 0.00001776
Iteration 82/1000 | Loss: 0.00001776
Iteration 83/1000 | Loss: 0.00001776
Iteration 84/1000 | Loss: 0.00001776
Iteration 85/1000 | Loss: 0.00001775
Iteration 86/1000 | Loss: 0.00001775
Iteration 87/1000 | Loss: 0.00001775
Iteration 88/1000 | Loss: 0.00001775
Iteration 89/1000 | Loss: 0.00001775
Iteration 90/1000 | Loss: 0.00001775
Iteration 91/1000 | Loss: 0.00001775
Iteration 92/1000 | Loss: 0.00001774
Iteration 93/1000 | Loss: 0.00001774
Iteration 94/1000 | Loss: 0.00001774
Iteration 95/1000 | Loss: 0.00001774
Iteration 96/1000 | Loss: 0.00001774
Iteration 97/1000 | Loss: 0.00001774
Iteration 98/1000 | Loss: 0.00001774
Iteration 99/1000 | Loss: 0.00001774
Iteration 100/1000 | Loss: 0.00001774
Iteration 101/1000 | Loss: 0.00001774
Iteration 102/1000 | Loss: 0.00001774
Iteration 103/1000 | Loss: 0.00001774
Iteration 104/1000 | Loss: 0.00001774
Iteration 105/1000 | Loss: 0.00001774
Iteration 106/1000 | Loss: 0.00001773
Iteration 107/1000 | Loss: 0.00001773
Iteration 108/1000 | Loss: 0.00001773
Iteration 109/1000 | Loss: 0.00001773
Iteration 110/1000 | Loss: 0.00001773
Iteration 111/1000 | Loss: 0.00001773
Iteration 112/1000 | Loss: 0.00001773
Iteration 113/1000 | Loss: 0.00001773
Iteration 114/1000 | Loss: 0.00001773
Iteration 115/1000 | Loss: 0.00001773
Iteration 116/1000 | Loss: 0.00001773
Iteration 117/1000 | Loss: 0.00001773
Iteration 118/1000 | Loss: 0.00001773
Iteration 119/1000 | Loss: 0.00001773
Iteration 120/1000 | Loss: 0.00001773
Iteration 121/1000 | Loss: 0.00001772
Iteration 122/1000 | Loss: 0.00001772
Iteration 123/1000 | Loss: 0.00001772
Iteration 124/1000 | Loss: 0.00001772
Iteration 125/1000 | Loss: 0.00001772
Iteration 126/1000 | Loss: 0.00001772
Iteration 127/1000 | Loss: 0.00001772
Iteration 128/1000 | Loss: 0.00001772
Iteration 129/1000 | Loss: 0.00001772
Iteration 130/1000 | Loss: 0.00001772
Iteration 131/1000 | Loss: 0.00001772
Iteration 132/1000 | Loss: 0.00001772
Iteration 133/1000 | Loss: 0.00001772
Iteration 134/1000 | Loss: 0.00001771
Iteration 135/1000 | Loss: 0.00001771
Iteration 136/1000 | Loss: 0.00001771
Iteration 137/1000 | Loss: 0.00001771
Iteration 138/1000 | Loss: 0.00001771
Iteration 139/1000 | Loss: 0.00001771
Iteration 140/1000 | Loss: 0.00001771
Iteration 141/1000 | Loss: 0.00001771
Iteration 142/1000 | Loss: 0.00001771
Iteration 143/1000 | Loss: 0.00001771
Iteration 144/1000 | Loss: 0.00001771
Iteration 145/1000 | Loss: 0.00001771
Iteration 146/1000 | Loss: 0.00001771
Iteration 147/1000 | Loss: 0.00001771
Iteration 148/1000 | Loss: 0.00001771
Iteration 149/1000 | Loss: 0.00001771
Iteration 150/1000 | Loss: 0.00001771
Iteration 151/1000 | Loss: 0.00001770
Iteration 152/1000 | Loss: 0.00001770
Iteration 153/1000 | Loss: 0.00001770
Iteration 154/1000 | Loss: 0.00001770
Iteration 155/1000 | Loss: 0.00001770
Iteration 156/1000 | Loss: 0.00001770
Iteration 157/1000 | Loss: 0.00001770
Iteration 158/1000 | Loss: 0.00001770
Iteration 159/1000 | Loss: 0.00001770
Iteration 160/1000 | Loss: 0.00001769
Iteration 161/1000 | Loss: 0.00001769
Iteration 162/1000 | Loss: 0.00001769
Iteration 163/1000 | Loss: 0.00001769
Iteration 164/1000 | Loss: 0.00001769
Iteration 165/1000 | Loss: 0.00001769
Iteration 166/1000 | Loss: 0.00001769
Iteration 167/1000 | Loss: 0.00001769
Iteration 168/1000 | Loss: 0.00001769
Iteration 169/1000 | Loss: 0.00001769
Iteration 170/1000 | Loss: 0.00001769
Iteration 171/1000 | Loss: 0.00001769
Iteration 172/1000 | Loss: 0.00001769
Iteration 173/1000 | Loss: 0.00001769
Iteration 174/1000 | Loss: 0.00001769
Iteration 175/1000 | Loss: 0.00001769
Iteration 176/1000 | Loss: 0.00001769
Iteration 177/1000 | Loss: 0.00001769
Iteration 178/1000 | Loss: 0.00001769
Iteration 179/1000 | Loss: 0.00001769
Iteration 180/1000 | Loss: 0.00001768
Iteration 181/1000 | Loss: 0.00001768
Iteration 182/1000 | Loss: 0.00001768
Iteration 183/1000 | Loss: 0.00001768
Iteration 184/1000 | Loss: 0.00001768
Iteration 185/1000 | Loss: 0.00001768
Iteration 186/1000 | Loss: 0.00001768
Iteration 187/1000 | Loss: 0.00001768
Iteration 188/1000 | Loss: 0.00001768
Iteration 189/1000 | Loss: 0.00001768
Iteration 190/1000 | Loss: 0.00001768
Iteration 191/1000 | Loss: 0.00001768
Iteration 192/1000 | Loss: 0.00001768
Iteration 193/1000 | Loss: 0.00001768
Iteration 194/1000 | Loss: 0.00001768
Iteration 195/1000 | Loss: 0.00001768
Iteration 196/1000 | Loss: 0.00001768
Iteration 197/1000 | Loss: 0.00001768
Iteration 198/1000 | Loss: 0.00001768
Iteration 199/1000 | Loss: 0.00001768
Iteration 200/1000 | Loss: 0.00001768
Iteration 201/1000 | Loss: 0.00001768
Iteration 202/1000 | Loss: 0.00001768
Iteration 203/1000 | Loss: 0.00001768
Iteration 204/1000 | Loss: 0.00001768
Iteration 205/1000 | Loss: 0.00001768
Iteration 206/1000 | Loss: 0.00001768
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 206. Stopping optimization.
Last 5 losses: [1.7681386452750303e-05, 1.7681386452750303e-05, 1.7681386452750303e-05, 1.7681386452750303e-05, 1.7681386452750303e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7681386452750303e-05

Optimization complete. Final v2v error: 3.509777784347534 mm

Highest mean error: 3.8598203659057617 mm for frame 44

Lowest mean error: 3.191986322402954 mm for frame 17

Saving results

Total time: 42.95962643623352
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1036/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1036.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1036
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01091405
Iteration 2/25 | Loss: 0.00163510
Iteration 3/25 | Loss: 0.00129795
Iteration 4/25 | Loss: 0.00141709
Iteration 5/25 | Loss: 0.00118425
Iteration 6/25 | Loss: 0.00083117
Iteration 7/25 | Loss: 0.00082552
Iteration 8/25 | Loss: 0.00079667
Iteration 9/25 | Loss: 0.00079392
Iteration 10/25 | Loss: 0.00076909
Iteration 11/25 | Loss: 0.00076841
Iteration 12/25 | Loss: 0.00076343
Iteration 13/25 | Loss: 0.00075315
Iteration 14/25 | Loss: 0.00076039
Iteration 15/25 | Loss: 0.00075308
Iteration 16/25 | Loss: 0.00075327
Iteration 17/25 | Loss: 0.00075034
Iteration 18/25 | Loss: 0.00075241
Iteration 19/25 | Loss: 0.00074783
Iteration 20/25 | Loss: 0.00074775
Iteration 21/25 | Loss: 0.00074775
Iteration 22/25 | Loss: 0.00074774
Iteration 23/25 | Loss: 0.00074774
Iteration 24/25 | Loss: 0.00074773
Iteration 25/25 | Loss: 0.00074773

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.78789115
Iteration 2/25 | Loss: 0.00121820
Iteration 3/25 | Loss: 0.00121820
Iteration 4/25 | Loss: 0.00121820
Iteration 5/25 | Loss: 0.00121820
Iteration 6/25 | Loss: 0.00121820
Iteration 7/25 | Loss: 0.00121820
Iteration 8/25 | Loss: 0.00121820
Iteration 9/25 | Loss: 0.00121820
Iteration 10/25 | Loss: 0.00121820
Iteration 11/25 | Loss: 0.00121820
Iteration 12/25 | Loss: 0.00121820
Iteration 13/25 | Loss: 0.00121820
Iteration 14/25 | Loss: 0.00121820
Iteration 15/25 | Loss: 0.00121820
Iteration 16/25 | Loss: 0.00121820
Iteration 17/25 | Loss: 0.00121820
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012182036880403757, 0.0012182036880403757, 0.0012182036880403757, 0.0012182036880403757, 0.0012182036880403757]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012182036880403757

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00121820
Iteration 2/1000 | Loss: 0.00002627
Iteration 3/1000 | Loss: 0.00001820
Iteration 4/1000 | Loss: 0.00001682
Iteration 5/1000 | Loss: 0.00001602
Iteration 6/1000 | Loss: 0.00001550
Iteration 7/1000 | Loss: 0.00001512
Iteration 8/1000 | Loss: 0.00001487
Iteration 9/1000 | Loss: 0.00001470
Iteration 10/1000 | Loss: 0.00001463
Iteration 11/1000 | Loss: 0.00001463
Iteration 12/1000 | Loss: 0.00001458
Iteration 13/1000 | Loss: 0.00001456
Iteration 14/1000 | Loss: 0.00001451
Iteration 15/1000 | Loss: 0.00001450
Iteration 16/1000 | Loss: 0.00001449
Iteration 17/1000 | Loss: 0.00001449
Iteration 18/1000 | Loss: 0.00001448
Iteration 19/1000 | Loss: 0.00001444
Iteration 20/1000 | Loss: 0.00001444
Iteration 21/1000 | Loss: 0.00001444
Iteration 22/1000 | Loss: 0.00001444
Iteration 23/1000 | Loss: 0.00001444
Iteration 24/1000 | Loss: 0.00001444
Iteration 25/1000 | Loss: 0.00001444
Iteration 26/1000 | Loss: 0.00001443
Iteration 27/1000 | Loss: 0.00001443
Iteration 28/1000 | Loss: 0.00001443
Iteration 29/1000 | Loss: 0.00001442
Iteration 30/1000 | Loss: 0.00001442
Iteration 31/1000 | Loss: 0.00001440
Iteration 32/1000 | Loss: 0.00001440
Iteration 33/1000 | Loss: 0.00001440
Iteration 34/1000 | Loss: 0.00001440
Iteration 35/1000 | Loss: 0.00001440
Iteration 36/1000 | Loss: 0.00001440
Iteration 37/1000 | Loss: 0.00001440
Iteration 38/1000 | Loss: 0.00001440
Iteration 39/1000 | Loss: 0.00001439
Iteration 40/1000 | Loss: 0.00001438
Iteration 41/1000 | Loss: 0.00001438
Iteration 42/1000 | Loss: 0.00001437
Iteration 43/1000 | Loss: 0.00001436
Iteration 44/1000 | Loss: 0.00001435
Iteration 45/1000 | Loss: 0.00001434
Iteration 46/1000 | Loss: 0.00001433
Iteration 47/1000 | Loss: 0.00001432
Iteration 48/1000 | Loss: 0.00001431
Iteration 49/1000 | Loss: 0.00001430
Iteration 50/1000 | Loss: 0.00001430
Iteration 51/1000 | Loss: 0.00001429
Iteration 52/1000 | Loss: 0.00001428
Iteration 53/1000 | Loss: 0.00001428
Iteration 54/1000 | Loss: 0.00001427
Iteration 55/1000 | Loss: 0.00001424
Iteration 56/1000 | Loss: 0.00001424
Iteration 57/1000 | Loss: 0.00001424
Iteration 58/1000 | Loss: 0.00001423
Iteration 59/1000 | Loss: 0.00001422
Iteration 60/1000 | Loss: 0.00001421
Iteration 61/1000 | Loss: 0.00001421
Iteration 62/1000 | Loss: 0.00001421
Iteration 63/1000 | Loss: 0.00001421
Iteration 64/1000 | Loss: 0.00001421
Iteration 65/1000 | Loss: 0.00001420
Iteration 66/1000 | Loss: 0.00001420
Iteration 67/1000 | Loss: 0.00001420
Iteration 68/1000 | Loss: 0.00001420
Iteration 69/1000 | Loss: 0.00001420
Iteration 70/1000 | Loss: 0.00001419
Iteration 71/1000 | Loss: 0.00001419
Iteration 72/1000 | Loss: 0.00001416
Iteration 73/1000 | Loss: 0.00001416
Iteration 74/1000 | Loss: 0.00001416
Iteration 75/1000 | Loss: 0.00001415
Iteration 76/1000 | Loss: 0.00001415
Iteration 77/1000 | Loss: 0.00001415
Iteration 78/1000 | Loss: 0.00001414
Iteration 79/1000 | Loss: 0.00001414
Iteration 80/1000 | Loss: 0.00001413
Iteration 81/1000 | Loss: 0.00001413
Iteration 82/1000 | Loss: 0.00001413
Iteration 83/1000 | Loss: 0.00001413
Iteration 84/1000 | Loss: 0.00001413
Iteration 85/1000 | Loss: 0.00001413
Iteration 86/1000 | Loss: 0.00001412
Iteration 87/1000 | Loss: 0.00001412
Iteration 88/1000 | Loss: 0.00001412
Iteration 89/1000 | Loss: 0.00001412
Iteration 90/1000 | Loss: 0.00001411
Iteration 91/1000 | Loss: 0.00001411
Iteration 92/1000 | Loss: 0.00001411
Iteration 93/1000 | Loss: 0.00001411
Iteration 94/1000 | Loss: 0.00001411
Iteration 95/1000 | Loss: 0.00001411
Iteration 96/1000 | Loss: 0.00001410
Iteration 97/1000 | Loss: 0.00001410
Iteration 98/1000 | Loss: 0.00001410
Iteration 99/1000 | Loss: 0.00001410
Iteration 100/1000 | Loss: 0.00001410
Iteration 101/1000 | Loss: 0.00001410
Iteration 102/1000 | Loss: 0.00001410
Iteration 103/1000 | Loss: 0.00001410
Iteration 104/1000 | Loss: 0.00001410
Iteration 105/1000 | Loss: 0.00001410
Iteration 106/1000 | Loss: 0.00001409
Iteration 107/1000 | Loss: 0.00001409
Iteration 108/1000 | Loss: 0.00001409
Iteration 109/1000 | Loss: 0.00001409
Iteration 110/1000 | Loss: 0.00001409
Iteration 111/1000 | Loss: 0.00001409
Iteration 112/1000 | Loss: 0.00001409
Iteration 113/1000 | Loss: 0.00001409
Iteration 114/1000 | Loss: 0.00001409
Iteration 115/1000 | Loss: 0.00001409
Iteration 116/1000 | Loss: 0.00001409
Iteration 117/1000 | Loss: 0.00001409
Iteration 118/1000 | Loss: 0.00001409
Iteration 119/1000 | Loss: 0.00001409
Iteration 120/1000 | Loss: 0.00001409
Iteration 121/1000 | Loss: 0.00001409
Iteration 122/1000 | Loss: 0.00001408
Iteration 123/1000 | Loss: 0.00001408
Iteration 124/1000 | Loss: 0.00001408
Iteration 125/1000 | Loss: 0.00001408
Iteration 126/1000 | Loss: 0.00001408
Iteration 127/1000 | Loss: 0.00001408
Iteration 128/1000 | Loss: 0.00001408
Iteration 129/1000 | Loss: 0.00001408
Iteration 130/1000 | Loss: 0.00001408
Iteration 131/1000 | Loss: 0.00001408
Iteration 132/1000 | Loss: 0.00001408
Iteration 133/1000 | Loss: 0.00001408
Iteration 134/1000 | Loss: 0.00001408
Iteration 135/1000 | Loss: 0.00001408
Iteration 136/1000 | Loss: 0.00001408
Iteration 137/1000 | Loss: 0.00001408
Iteration 138/1000 | Loss: 0.00001408
Iteration 139/1000 | Loss: 0.00001407
Iteration 140/1000 | Loss: 0.00001407
Iteration 141/1000 | Loss: 0.00001407
Iteration 142/1000 | Loss: 0.00001407
Iteration 143/1000 | Loss: 0.00001407
Iteration 144/1000 | Loss: 0.00001407
Iteration 145/1000 | Loss: 0.00001407
Iteration 146/1000 | Loss: 0.00001407
Iteration 147/1000 | Loss: 0.00001407
Iteration 148/1000 | Loss: 0.00001407
Iteration 149/1000 | Loss: 0.00001407
Iteration 150/1000 | Loss: 0.00001407
Iteration 151/1000 | Loss: 0.00001407
Iteration 152/1000 | Loss: 0.00001407
Iteration 153/1000 | Loss: 0.00001407
Iteration 154/1000 | Loss: 0.00001407
Iteration 155/1000 | Loss: 0.00001407
Iteration 156/1000 | Loss: 0.00001407
Iteration 157/1000 | Loss: 0.00001407
Iteration 158/1000 | Loss: 0.00001407
Iteration 159/1000 | Loss: 0.00001407
Iteration 160/1000 | Loss: 0.00001407
Iteration 161/1000 | Loss: 0.00001407
Iteration 162/1000 | Loss: 0.00001407
Iteration 163/1000 | Loss: 0.00001407
Iteration 164/1000 | Loss: 0.00001407
Iteration 165/1000 | Loss: 0.00001407
Iteration 166/1000 | Loss: 0.00001407
Iteration 167/1000 | Loss: 0.00001407
Iteration 168/1000 | Loss: 0.00001407
Iteration 169/1000 | Loss: 0.00001407
Iteration 170/1000 | Loss: 0.00001407
Iteration 171/1000 | Loss: 0.00001407
Iteration 172/1000 | Loss: 0.00001407
Iteration 173/1000 | Loss: 0.00001407
Iteration 174/1000 | Loss: 0.00001407
Iteration 175/1000 | Loss: 0.00001407
Iteration 176/1000 | Loss: 0.00001407
Iteration 177/1000 | Loss: 0.00001407
Iteration 178/1000 | Loss: 0.00001407
Iteration 179/1000 | Loss: 0.00001407
Iteration 180/1000 | Loss: 0.00001407
Iteration 181/1000 | Loss: 0.00001407
Iteration 182/1000 | Loss: 0.00001407
Iteration 183/1000 | Loss: 0.00001407
Iteration 184/1000 | Loss: 0.00001407
Iteration 185/1000 | Loss: 0.00001407
Iteration 186/1000 | Loss: 0.00001407
Iteration 187/1000 | Loss: 0.00001407
Iteration 188/1000 | Loss: 0.00001407
Iteration 189/1000 | Loss: 0.00001407
Iteration 190/1000 | Loss: 0.00001407
Iteration 191/1000 | Loss: 0.00001407
Iteration 192/1000 | Loss: 0.00001407
Iteration 193/1000 | Loss: 0.00001407
Iteration 194/1000 | Loss: 0.00001407
Iteration 195/1000 | Loss: 0.00001407
Iteration 196/1000 | Loss: 0.00001407
Iteration 197/1000 | Loss: 0.00001407
Iteration 198/1000 | Loss: 0.00001407
Iteration 199/1000 | Loss: 0.00001407
Iteration 200/1000 | Loss: 0.00001407
Iteration 201/1000 | Loss: 0.00001407
Iteration 202/1000 | Loss: 0.00001407
Iteration 203/1000 | Loss: 0.00001407
Iteration 204/1000 | Loss: 0.00001407
Iteration 205/1000 | Loss: 0.00001407
Iteration 206/1000 | Loss: 0.00001407
Iteration 207/1000 | Loss: 0.00001407
Iteration 208/1000 | Loss: 0.00001407
Iteration 209/1000 | Loss: 0.00001407
Iteration 210/1000 | Loss: 0.00001407
Iteration 211/1000 | Loss: 0.00001407
Iteration 212/1000 | Loss: 0.00001407
Iteration 213/1000 | Loss: 0.00001407
Iteration 214/1000 | Loss: 0.00001407
Iteration 215/1000 | Loss: 0.00001407
Iteration 216/1000 | Loss: 0.00001407
Iteration 217/1000 | Loss: 0.00001407
Iteration 218/1000 | Loss: 0.00001407
Iteration 219/1000 | Loss: 0.00001407
Iteration 220/1000 | Loss: 0.00001407
Iteration 221/1000 | Loss: 0.00001407
Iteration 222/1000 | Loss: 0.00001407
Iteration 223/1000 | Loss: 0.00001407
Iteration 224/1000 | Loss: 0.00001407
Iteration 225/1000 | Loss: 0.00001407
Iteration 226/1000 | Loss: 0.00001407
Iteration 227/1000 | Loss: 0.00001407
Iteration 228/1000 | Loss: 0.00001407
Iteration 229/1000 | Loss: 0.00001407
Iteration 230/1000 | Loss: 0.00001407
Iteration 231/1000 | Loss: 0.00001407
Iteration 232/1000 | Loss: 0.00001407
Iteration 233/1000 | Loss: 0.00001407
Iteration 234/1000 | Loss: 0.00001407
Iteration 235/1000 | Loss: 0.00001407
Iteration 236/1000 | Loss: 0.00001407
Iteration 237/1000 | Loss: 0.00001407
Iteration 238/1000 | Loss: 0.00001407
Iteration 239/1000 | Loss: 0.00001407
Iteration 240/1000 | Loss: 0.00001407
Iteration 241/1000 | Loss: 0.00001407
Iteration 242/1000 | Loss: 0.00001407
Iteration 243/1000 | Loss: 0.00001407
Iteration 244/1000 | Loss: 0.00001407
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 244. Stopping optimization.
Last 5 losses: [1.4066291441849899e-05, 1.4066291441849899e-05, 1.4066291441849899e-05, 1.4066291441849899e-05, 1.4066291441849899e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4066291441849899e-05

Optimization complete. Final v2v error: 3.1683380603790283 mm

Highest mean error: 3.320072889328003 mm for frame 6

Lowest mean error: 2.9953083992004395 mm for frame 50

Saving results

Total time: 63.65879559516907
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01040267
Iteration 2/25 | Loss: 0.00103343
Iteration 3/25 | Loss: 0.00084122
Iteration 4/25 | Loss: 0.00081027
Iteration 5/25 | Loss: 0.00079325
Iteration 6/25 | Loss: 0.00079070
Iteration 7/25 | Loss: 0.00078997
Iteration 8/25 | Loss: 0.00078978
Iteration 9/25 | Loss: 0.00078975
Iteration 10/25 | Loss: 0.00078975
Iteration 11/25 | Loss: 0.00078975
Iteration 12/25 | Loss: 0.00078975
Iteration 13/25 | Loss: 0.00078975
Iteration 14/25 | Loss: 0.00078974
Iteration 15/25 | Loss: 0.00078974
Iteration 16/25 | Loss: 0.00078974
Iteration 17/25 | Loss: 0.00078974
Iteration 18/25 | Loss: 0.00078974
Iteration 19/25 | Loss: 0.00078974
Iteration 20/25 | Loss: 0.00078974
Iteration 21/25 | Loss: 0.00078974
Iteration 22/25 | Loss: 0.00078974
Iteration 23/25 | Loss: 0.00078974
Iteration 24/25 | Loss: 0.00078974
Iteration 25/25 | Loss: 0.00078974

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 8.26968002
Iteration 2/25 | Loss: 0.00114776
Iteration 3/25 | Loss: 0.00114775
Iteration 4/25 | Loss: 0.00114775
Iteration 5/25 | Loss: 0.00114775
Iteration 6/25 | Loss: 0.00114775
Iteration 7/25 | Loss: 0.00114775
Iteration 8/25 | Loss: 0.00114775
Iteration 9/25 | Loss: 0.00114775
Iteration 10/25 | Loss: 0.00114775
Iteration 11/25 | Loss: 0.00114775
Iteration 12/25 | Loss: 0.00114775
Iteration 13/25 | Loss: 0.00114775
Iteration 14/25 | Loss: 0.00114775
Iteration 15/25 | Loss: 0.00114775
Iteration 16/25 | Loss: 0.00114775
Iteration 17/25 | Loss: 0.00114775
Iteration 18/25 | Loss: 0.00114775
Iteration 19/25 | Loss: 0.00114775
Iteration 20/25 | Loss: 0.00114775
Iteration 21/25 | Loss: 0.00114775
Iteration 22/25 | Loss: 0.00114775
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0011477518128231168, 0.0011477518128231168, 0.0011477518128231168, 0.0011477518128231168, 0.0011477518128231168]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011477518128231168

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00114775
Iteration 2/1000 | Loss: 0.00003033
Iteration 3/1000 | Loss: 0.00001896
Iteration 4/1000 | Loss: 0.00001700
Iteration 5/1000 | Loss: 0.00001608
Iteration 6/1000 | Loss: 0.00001554
Iteration 7/1000 | Loss: 0.00001511
Iteration 8/1000 | Loss: 0.00001474
Iteration 9/1000 | Loss: 0.00001453
Iteration 10/1000 | Loss: 0.00001445
Iteration 11/1000 | Loss: 0.00001428
Iteration 12/1000 | Loss: 0.00001425
Iteration 13/1000 | Loss: 0.00001423
Iteration 14/1000 | Loss: 0.00001423
Iteration 15/1000 | Loss: 0.00001422
Iteration 16/1000 | Loss: 0.00001421
Iteration 17/1000 | Loss: 0.00001415
Iteration 18/1000 | Loss: 0.00001413
Iteration 19/1000 | Loss: 0.00001410
Iteration 20/1000 | Loss: 0.00001408
Iteration 21/1000 | Loss: 0.00001407
Iteration 22/1000 | Loss: 0.00001406
Iteration 23/1000 | Loss: 0.00001406
Iteration 24/1000 | Loss: 0.00001405
Iteration 25/1000 | Loss: 0.00001404
Iteration 26/1000 | Loss: 0.00001404
Iteration 27/1000 | Loss: 0.00001403
Iteration 28/1000 | Loss: 0.00001403
Iteration 29/1000 | Loss: 0.00001403
Iteration 30/1000 | Loss: 0.00001402
Iteration 31/1000 | Loss: 0.00001402
Iteration 32/1000 | Loss: 0.00001402
Iteration 33/1000 | Loss: 0.00001402
Iteration 34/1000 | Loss: 0.00001401
Iteration 35/1000 | Loss: 0.00001401
Iteration 36/1000 | Loss: 0.00001400
Iteration 37/1000 | Loss: 0.00001399
Iteration 38/1000 | Loss: 0.00001399
Iteration 39/1000 | Loss: 0.00001399
Iteration 40/1000 | Loss: 0.00001399
Iteration 41/1000 | Loss: 0.00001399
Iteration 42/1000 | Loss: 0.00001398
Iteration 43/1000 | Loss: 0.00001397
Iteration 44/1000 | Loss: 0.00001397
Iteration 45/1000 | Loss: 0.00001395
Iteration 46/1000 | Loss: 0.00001395
Iteration 47/1000 | Loss: 0.00001395
Iteration 48/1000 | Loss: 0.00001395
Iteration 49/1000 | Loss: 0.00001395
Iteration 50/1000 | Loss: 0.00001395
Iteration 51/1000 | Loss: 0.00001395
Iteration 52/1000 | Loss: 0.00001395
Iteration 53/1000 | Loss: 0.00001395
Iteration 54/1000 | Loss: 0.00001395
Iteration 55/1000 | Loss: 0.00001394
Iteration 56/1000 | Loss: 0.00001394
Iteration 57/1000 | Loss: 0.00001394
Iteration 58/1000 | Loss: 0.00001394
Iteration 59/1000 | Loss: 0.00001394
Iteration 60/1000 | Loss: 0.00001393
Iteration 61/1000 | Loss: 0.00001393
Iteration 62/1000 | Loss: 0.00001393
Iteration 63/1000 | Loss: 0.00001393
Iteration 64/1000 | Loss: 0.00001393
Iteration 65/1000 | Loss: 0.00001393
Iteration 66/1000 | Loss: 0.00001393
Iteration 67/1000 | Loss: 0.00001393
Iteration 68/1000 | Loss: 0.00001392
Iteration 69/1000 | Loss: 0.00001392
Iteration 70/1000 | Loss: 0.00001392
Iteration 71/1000 | Loss: 0.00001391
Iteration 72/1000 | Loss: 0.00001391
Iteration 73/1000 | Loss: 0.00001391
Iteration 74/1000 | Loss: 0.00001391
Iteration 75/1000 | Loss: 0.00001391
Iteration 76/1000 | Loss: 0.00001391
Iteration 77/1000 | Loss: 0.00001391
Iteration 78/1000 | Loss: 0.00001391
Iteration 79/1000 | Loss: 0.00001391
Iteration 80/1000 | Loss: 0.00001390
Iteration 81/1000 | Loss: 0.00001390
Iteration 82/1000 | Loss: 0.00001389
Iteration 83/1000 | Loss: 0.00001389
Iteration 84/1000 | Loss: 0.00001389
Iteration 85/1000 | Loss: 0.00001389
Iteration 86/1000 | Loss: 0.00001389
Iteration 87/1000 | Loss: 0.00001389
Iteration 88/1000 | Loss: 0.00001388
Iteration 89/1000 | Loss: 0.00001388
Iteration 90/1000 | Loss: 0.00001388
Iteration 91/1000 | Loss: 0.00001388
Iteration 92/1000 | Loss: 0.00001388
Iteration 93/1000 | Loss: 0.00001388
Iteration 94/1000 | Loss: 0.00001388
Iteration 95/1000 | Loss: 0.00001388
Iteration 96/1000 | Loss: 0.00001387
Iteration 97/1000 | Loss: 0.00001387
Iteration 98/1000 | Loss: 0.00001387
Iteration 99/1000 | Loss: 0.00001387
Iteration 100/1000 | Loss: 0.00001387
Iteration 101/1000 | Loss: 0.00001387
Iteration 102/1000 | Loss: 0.00001386
Iteration 103/1000 | Loss: 0.00001386
Iteration 104/1000 | Loss: 0.00001386
Iteration 105/1000 | Loss: 0.00001386
Iteration 106/1000 | Loss: 0.00001386
Iteration 107/1000 | Loss: 0.00001386
Iteration 108/1000 | Loss: 0.00001386
Iteration 109/1000 | Loss: 0.00001386
Iteration 110/1000 | Loss: 0.00001386
Iteration 111/1000 | Loss: 0.00001386
Iteration 112/1000 | Loss: 0.00001385
Iteration 113/1000 | Loss: 0.00001385
Iteration 114/1000 | Loss: 0.00001385
Iteration 115/1000 | Loss: 0.00001385
Iteration 116/1000 | Loss: 0.00001385
Iteration 117/1000 | Loss: 0.00001385
Iteration 118/1000 | Loss: 0.00001385
Iteration 119/1000 | Loss: 0.00001385
Iteration 120/1000 | Loss: 0.00001385
Iteration 121/1000 | Loss: 0.00001385
Iteration 122/1000 | Loss: 0.00001384
Iteration 123/1000 | Loss: 0.00001384
Iteration 124/1000 | Loss: 0.00001384
Iteration 125/1000 | Loss: 0.00001384
Iteration 126/1000 | Loss: 0.00001384
Iteration 127/1000 | Loss: 0.00001384
Iteration 128/1000 | Loss: 0.00001384
Iteration 129/1000 | Loss: 0.00001384
Iteration 130/1000 | Loss: 0.00001383
Iteration 131/1000 | Loss: 0.00001383
Iteration 132/1000 | Loss: 0.00001383
Iteration 133/1000 | Loss: 0.00001383
Iteration 134/1000 | Loss: 0.00001383
Iteration 135/1000 | Loss: 0.00001383
Iteration 136/1000 | Loss: 0.00001383
Iteration 137/1000 | Loss: 0.00001383
Iteration 138/1000 | Loss: 0.00001383
Iteration 139/1000 | Loss: 0.00001383
Iteration 140/1000 | Loss: 0.00001383
Iteration 141/1000 | Loss: 0.00001383
Iteration 142/1000 | Loss: 0.00001382
Iteration 143/1000 | Loss: 0.00001382
Iteration 144/1000 | Loss: 0.00001382
Iteration 145/1000 | Loss: 0.00001382
Iteration 146/1000 | Loss: 0.00001382
Iteration 147/1000 | Loss: 0.00001382
Iteration 148/1000 | Loss: 0.00001382
Iteration 149/1000 | Loss: 0.00001382
Iteration 150/1000 | Loss: 0.00001382
Iteration 151/1000 | Loss: 0.00001382
Iteration 152/1000 | Loss: 0.00001381
Iteration 153/1000 | Loss: 0.00001381
Iteration 154/1000 | Loss: 0.00001381
Iteration 155/1000 | Loss: 0.00001381
Iteration 156/1000 | Loss: 0.00001381
Iteration 157/1000 | Loss: 0.00001381
Iteration 158/1000 | Loss: 0.00001381
Iteration 159/1000 | Loss: 0.00001381
Iteration 160/1000 | Loss: 0.00001381
Iteration 161/1000 | Loss: 0.00001381
Iteration 162/1000 | Loss: 0.00001381
Iteration 163/1000 | Loss: 0.00001381
Iteration 164/1000 | Loss: 0.00001380
Iteration 165/1000 | Loss: 0.00001380
Iteration 166/1000 | Loss: 0.00001380
Iteration 167/1000 | Loss: 0.00001380
Iteration 168/1000 | Loss: 0.00001380
Iteration 169/1000 | Loss: 0.00001380
Iteration 170/1000 | Loss: 0.00001380
Iteration 171/1000 | Loss: 0.00001380
Iteration 172/1000 | Loss: 0.00001380
Iteration 173/1000 | Loss: 0.00001380
Iteration 174/1000 | Loss: 0.00001380
Iteration 175/1000 | Loss: 0.00001380
Iteration 176/1000 | Loss: 0.00001380
Iteration 177/1000 | Loss: 0.00001380
Iteration 178/1000 | Loss: 0.00001380
Iteration 179/1000 | Loss: 0.00001380
Iteration 180/1000 | Loss: 0.00001380
Iteration 181/1000 | Loss: 0.00001380
Iteration 182/1000 | Loss: 0.00001379
Iteration 183/1000 | Loss: 0.00001379
Iteration 184/1000 | Loss: 0.00001379
Iteration 185/1000 | Loss: 0.00001379
Iteration 186/1000 | Loss: 0.00001379
Iteration 187/1000 | Loss: 0.00001379
Iteration 188/1000 | Loss: 0.00001379
Iteration 189/1000 | Loss: 0.00001379
Iteration 190/1000 | Loss: 0.00001379
Iteration 191/1000 | Loss: 0.00001379
Iteration 192/1000 | Loss: 0.00001379
Iteration 193/1000 | Loss: 0.00001379
Iteration 194/1000 | Loss: 0.00001379
Iteration 195/1000 | Loss: 0.00001378
Iteration 196/1000 | Loss: 0.00001378
Iteration 197/1000 | Loss: 0.00001378
Iteration 198/1000 | Loss: 0.00001378
Iteration 199/1000 | Loss: 0.00001378
Iteration 200/1000 | Loss: 0.00001378
Iteration 201/1000 | Loss: 0.00001378
Iteration 202/1000 | Loss: 0.00001378
Iteration 203/1000 | Loss: 0.00001378
Iteration 204/1000 | Loss: 0.00001378
Iteration 205/1000 | Loss: 0.00001378
Iteration 206/1000 | Loss: 0.00001378
Iteration 207/1000 | Loss: 0.00001377
Iteration 208/1000 | Loss: 0.00001377
Iteration 209/1000 | Loss: 0.00001377
Iteration 210/1000 | Loss: 0.00001377
Iteration 211/1000 | Loss: 0.00001377
Iteration 212/1000 | Loss: 0.00001377
Iteration 213/1000 | Loss: 0.00001377
Iteration 214/1000 | Loss: 0.00001377
Iteration 215/1000 | Loss: 0.00001377
Iteration 216/1000 | Loss: 0.00001377
Iteration 217/1000 | Loss: 0.00001377
Iteration 218/1000 | Loss: 0.00001377
Iteration 219/1000 | Loss: 0.00001377
Iteration 220/1000 | Loss: 0.00001377
Iteration 221/1000 | Loss: 0.00001376
Iteration 222/1000 | Loss: 0.00001376
Iteration 223/1000 | Loss: 0.00001376
Iteration 224/1000 | Loss: 0.00001376
Iteration 225/1000 | Loss: 0.00001376
Iteration 226/1000 | Loss: 0.00001376
Iteration 227/1000 | Loss: 0.00001376
Iteration 228/1000 | Loss: 0.00001376
Iteration 229/1000 | Loss: 0.00001376
Iteration 230/1000 | Loss: 0.00001376
Iteration 231/1000 | Loss: 0.00001376
Iteration 232/1000 | Loss: 0.00001376
Iteration 233/1000 | Loss: 0.00001376
Iteration 234/1000 | Loss: 0.00001376
Iteration 235/1000 | Loss: 0.00001376
Iteration 236/1000 | Loss: 0.00001376
Iteration 237/1000 | Loss: 0.00001376
Iteration 238/1000 | Loss: 0.00001376
Iteration 239/1000 | Loss: 0.00001376
Iteration 240/1000 | Loss: 0.00001375
Iteration 241/1000 | Loss: 0.00001375
Iteration 242/1000 | Loss: 0.00001375
Iteration 243/1000 | Loss: 0.00001375
Iteration 244/1000 | Loss: 0.00001375
Iteration 245/1000 | Loss: 0.00001375
Iteration 246/1000 | Loss: 0.00001375
Iteration 247/1000 | Loss: 0.00001375
Iteration 248/1000 | Loss: 0.00001375
Iteration 249/1000 | Loss: 0.00001375
Iteration 250/1000 | Loss: 0.00001375
Iteration 251/1000 | Loss: 0.00001375
Iteration 252/1000 | Loss: 0.00001375
Iteration 253/1000 | Loss: 0.00001375
Iteration 254/1000 | Loss: 0.00001375
Iteration 255/1000 | Loss: 0.00001375
Iteration 256/1000 | Loss: 0.00001375
Iteration 257/1000 | Loss: 0.00001375
Iteration 258/1000 | Loss: 0.00001375
Iteration 259/1000 | Loss: 0.00001375
Iteration 260/1000 | Loss: 0.00001375
Iteration 261/1000 | Loss: 0.00001375
Iteration 262/1000 | Loss: 0.00001375
Iteration 263/1000 | Loss: 0.00001375
Iteration 264/1000 | Loss: 0.00001375
Iteration 265/1000 | Loss: 0.00001375
Iteration 266/1000 | Loss: 0.00001375
Iteration 267/1000 | Loss: 0.00001375
Iteration 268/1000 | Loss: 0.00001375
Iteration 269/1000 | Loss: 0.00001375
Iteration 270/1000 | Loss: 0.00001375
Iteration 271/1000 | Loss: 0.00001375
Iteration 272/1000 | Loss: 0.00001375
Iteration 273/1000 | Loss: 0.00001375
Iteration 274/1000 | Loss: 0.00001375
Iteration 275/1000 | Loss: 0.00001375
Iteration 276/1000 | Loss: 0.00001375
Iteration 277/1000 | Loss: 0.00001375
Iteration 278/1000 | Loss: 0.00001375
Iteration 279/1000 | Loss: 0.00001375
Iteration 280/1000 | Loss: 0.00001375
Iteration 281/1000 | Loss: 0.00001375
Iteration 282/1000 | Loss: 0.00001375
Iteration 283/1000 | Loss: 0.00001375
Iteration 284/1000 | Loss: 0.00001375
Iteration 285/1000 | Loss: 0.00001375
Iteration 286/1000 | Loss: 0.00001375
Iteration 287/1000 | Loss: 0.00001375
Iteration 288/1000 | Loss: 0.00001375
Iteration 289/1000 | Loss: 0.00001375
Iteration 290/1000 | Loss: 0.00001375
Iteration 291/1000 | Loss: 0.00001375
Iteration 292/1000 | Loss: 0.00001375
Iteration 293/1000 | Loss: 0.00001375
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 293. Stopping optimization.
Last 5 losses: [1.3749609934166074e-05, 1.3749609934166074e-05, 1.3749609934166074e-05, 1.3749609934166074e-05, 1.3749609934166074e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3749609934166074e-05

Optimization complete. Final v2v error: 3.148404598236084 mm

Highest mean error: 3.415600299835205 mm for frame 15

Lowest mean error: 2.8630831241607666 mm for frame 138

Saving results

Total time: 47.48921608924866
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1072/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1072.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1072
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01022850
Iteration 2/25 | Loss: 0.00302061
Iteration 3/25 | Loss: 0.00219694
Iteration 4/25 | Loss: 0.00188614
Iteration 5/25 | Loss: 0.00166315
Iteration 6/25 | Loss: 0.00155121
Iteration 7/25 | Loss: 0.00142924
Iteration 8/25 | Loss: 0.00148742
Iteration 9/25 | Loss: 0.00130430
Iteration 10/25 | Loss: 0.00124087
Iteration 11/25 | Loss: 0.00123063
Iteration 12/25 | Loss: 0.00120818
Iteration 13/25 | Loss: 0.00119935
Iteration 14/25 | Loss: 0.00119094
Iteration 15/25 | Loss: 0.00118437
Iteration 16/25 | Loss: 0.00118630
Iteration 17/25 | Loss: 0.00117918
Iteration 18/25 | Loss: 0.00117450
Iteration 19/25 | Loss: 0.00118019
Iteration 20/25 | Loss: 0.00117037
Iteration 21/25 | Loss: 0.00116676
Iteration 22/25 | Loss: 0.00116569
Iteration 23/25 | Loss: 0.00116525
Iteration 24/25 | Loss: 0.00116499
Iteration 25/25 | Loss: 0.00116490

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.58520317
Iteration 2/25 | Loss: 0.00450591
Iteration 3/25 | Loss: 0.00357851
Iteration 4/25 | Loss: 0.00357836
Iteration 5/25 | Loss: 0.00357836
Iteration 6/25 | Loss: 0.00357836
Iteration 7/25 | Loss: 0.00357836
Iteration 8/25 | Loss: 0.00357836
Iteration 9/25 | Loss: 0.00357836
Iteration 10/25 | Loss: 0.00357836
Iteration 11/25 | Loss: 0.00357835
Iteration 12/25 | Loss: 0.00357835
Iteration 13/25 | Loss: 0.00357835
Iteration 14/25 | Loss: 0.00357835
Iteration 15/25 | Loss: 0.00357835
Iteration 16/25 | Loss: 0.00357835
Iteration 17/25 | Loss: 0.00357835
Iteration 18/25 | Loss: 0.00357835
Iteration 19/25 | Loss: 0.00357835
Iteration 20/25 | Loss: 0.00357835
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0035783543717116117, 0.0035783543717116117, 0.0035783543717116117, 0.0035783543717116117, 0.0035783543717116117]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0035783543717116117

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00357835
Iteration 2/1000 | Loss: 0.00158307
Iteration 3/1000 | Loss: 0.00055818
Iteration 4/1000 | Loss: 0.00035957
Iteration 5/1000 | Loss: 0.00029210
Iteration 6/1000 | Loss: 0.00032385
Iteration 7/1000 | Loss: 0.00025206
Iteration 8/1000 | Loss: 0.00026990
Iteration 9/1000 | Loss: 0.00028094
Iteration 10/1000 | Loss: 0.00028319
Iteration 11/1000 | Loss: 0.00048211
Iteration 12/1000 | Loss: 0.00074501
Iteration 13/1000 | Loss: 0.00044826
Iteration 14/1000 | Loss: 0.00146639
Iteration 15/1000 | Loss: 0.00053040
Iteration 16/1000 | Loss: 0.00063819
Iteration 17/1000 | Loss: 0.00042523
Iteration 18/1000 | Loss: 0.00037696
Iteration 19/1000 | Loss: 0.00039938
Iteration 20/1000 | Loss: 0.00047402
Iteration 21/1000 | Loss: 0.00236454
Iteration 22/1000 | Loss: 0.00502946
Iteration 23/1000 | Loss: 0.00329287
Iteration 24/1000 | Loss: 0.00134990
Iteration 25/1000 | Loss: 0.00029507
Iteration 26/1000 | Loss: 0.00096656
Iteration 27/1000 | Loss: 0.00141914
Iteration 28/1000 | Loss: 0.00121068
Iteration 29/1000 | Loss: 0.00050345
Iteration 30/1000 | Loss: 0.00077144
Iteration 31/1000 | Loss: 0.00078188
Iteration 32/1000 | Loss: 0.00027385
Iteration 33/1000 | Loss: 0.00036892
Iteration 34/1000 | Loss: 0.00087832
Iteration 35/1000 | Loss: 0.00044136
Iteration 36/1000 | Loss: 0.00046196
Iteration 37/1000 | Loss: 0.00087678
Iteration 38/1000 | Loss: 0.00022821
Iteration 39/1000 | Loss: 0.00055064
Iteration 40/1000 | Loss: 0.00020616
Iteration 41/1000 | Loss: 0.00047862
Iteration 42/1000 | Loss: 0.00009568
Iteration 43/1000 | Loss: 0.00008795
Iteration 44/1000 | Loss: 0.00015309
Iteration 45/1000 | Loss: 0.00010191
Iteration 46/1000 | Loss: 0.00013832
Iteration 47/1000 | Loss: 0.00006804
Iteration 48/1000 | Loss: 0.00007223
Iteration 49/1000 | Loss: 0.00037484
Iteration 50/1000 | Loss: 0.00006280
Iteration 51/1000 | Loss: 0.00004464
Iteration 52/1000 | Loss: 0.00011413
Iteration 53/1000 | Loss: 0.00005279
Iteration 54/1000 | Loss: 0.00005181
Iteration 55/1000 | Loss: 0.00011851
Iteration 56/1000 | Loss: 0.00044907
Iteration 57/1000 | Loss: 0.00005657
Iteration 58/1000 | Loss: 0.00041593
Iteration 59/1000 | Loss: 0.00003530
Iteration 60/1000 | Loss: 0.00005006
Iteration 61/1000 | Loss: 0.00004542
Iteration 62/1000 | Loss: 0.00039503
Iteration 63/1000 | Loss: 0.00002761
Iteration 64/1000 | Loss: 0.00004057
Iteration 65/1000 | Loss: 0.00002394
Iteration 66/1000 | Loss: 0.00002875
Iteration 67/1000 | Loss: 0.00003869
Iteration 68/1000 | Loss: 0.00021158
Iteration 69/1000 | Loss: 0.00004097
Iteration 70/1000 | Loss: 0.00005432
Iteration 71/1000 | Loss: 0.00004072
Iteration 72/1000 | Loss: 0.00002292
Iteration 73/1000 | Loss: 0.00002441
Iteration 74/1000 | Loss: 0.00002277
Iteration 75/1000 | Loss: 0.00002277
Iteration 76/1000 | Loss: 0.00002277
Iteration 77/1000 | Loss: 0.00002277
Iteration 78/1000 | Loss: 0.00002276
Iteration 79/1000 | Loss: 0.00002276
Iteration 80/1000 | Loss: 0.00002276
Iteration 81/1000 | Loss: 0.00002276
Iteration 82/1000 | Loss: 0.00002276
Iteration 83/1000 | Loss: 0.00002276
Iteration 84/1000 | Loss: 0.00002276
Iteration 85/1000 | Loss: 0.00002276
Iteration 86/1000 | Loss: 0.00002275
Iteration 87/1000 | Loss: 0.00002274
Iteration 88/1000 | Loss: 0.00002273
Iteration 89/1000 | Loss: 0.00002272
Iteration 90/1000 | Loss: 0.00002272
Iteration 91/1000 | Loss: 0.00002271
Iteration 92/1000 | Loss: 0.00002406
Iteration 93/1000 | Loss: 0.00002274
Iteration 94/1000 | Loss: 0.00002269
Iteration 95/1000 | Loss: 0.00002269
Iteration 96/1000 | Loss: 0.00002269
Iteration 97/1000 | Loss: 0.00002271
Iteration 98/1000 | Loss: 0.00002267
Iteration 99/1000 | Loss: 0.00002267
Iteration 100/1000 | Loss: 0.00002267
Iteration 101/1000 | Loss: 0.00002267
Iteration 102/1000 | Loss: 0.00002267
Iteration 103/1000 | Loss: 0.00002267
Iteration 104/1000 | Loss: 0.00002267
Iteration 105/1000 | Loss: 0.00002267
Iteration 106/1000 | Loss: 0.00002267
Iteration 107/1000 | Loss: 0.00002267
Iteration 108/1000 | Loss: 0.00002266
Iteration 109/1000 | Loss: 0.00002266
Iteration 110/1000 | Loss: 0.00002266
Iteration 111/1000 | Loss: 0.00002265
Iteration 112/1000 | Loss: 0.00002265
Iteration 113/1000 | Loss: 0.00002264
Iteration 114/1000 | Loss: 0.00002264
Iteration 115/1000 | Loss: 0.00002263
Iteration 116/1000 | Loss: 0.00002263
Iteration 117/1000 | Loss: 0.00002263
Iteration 118/1000 | Loss: 0.00002262
Iteration 119/1000 | Loss: 0.00002262
Iteration 120/1000 | Loss: 0.00002261
Iteration 121/1000 | Loss: 0.00002261
Iteration 122/1000 | Loss: 0.00002261
Iteration 123/1000 | Loss: 0.00002261
Iteration 124/1000 | Loss: 0.00002260
Iteration 125/1000 | Loss: 0.00002260
Iteration 126/1000 | Loss: 0.00002260
Iteration 127/1000 | Loss: 0.00002260
Iteration 128/1000 | Loss: 0.00002260
Iteration 129/1000 | Loss: 0.00002260
Iteration 130/1000 | Loss: 0.00002259
Iteration 131/1000 | Loss: 0.00002259
Iteration 132/1000 | Loss: 0.00002259
Iteration 133/1000 | Loss: 0.00002259
Iteration 134/1000 | Loss: 0.00002258
Iteration 135/1000 | Loss: 0.00002258
Iteration 136/1000 | Loss: 0.00002258
Iteration 137/1000 | Loss: 0.00002258
Iteration 138/1000 | Loss: 0.00002258
Iteration 139/1000 | Loss: 0.00002258
Iteration 140/1000 | Loss: 0.00002258
Iteration 141/1000 | Loss: 0.00002258
Iteration 142/1000 | Loss: 0.00002257
Iteration 143/1000 | Loss: 0.00002257
Iteration 144/1000 | Loss: 0.00002257
Iteration 145/1000 | Loss: 0.00002257
Iteration 146/1000 | Loss: 0.00002257
Iteration 147/1000 | Loss: 0.00002257
Iteration 148/1000 | Loss: 0.00002256
Iteration 149/1000 | Loss: 0.00002256
Iteration 150/1000 | Loss: 0.00002255
Iteration 151/1000 | Loss: 0.00002255
Iteration 152/1000 | Loss: 0.00002255
Iteration 153/1000 | Loss: 0.00002254
Iteration 154/1000 | Loss: 0.00002254
Iteration 155/1000 | Loss: 0.00002254
Iteration 156/1000 | Loss: 0.00002254
Iteration 157/1000 | Loss: 0.00002254
Iteration 158/1000 | Loss: 0.00002254
Iteration 159/1000 | Loss: 0.00002254
Iteration 160/1000 | Loss: 0.00002254
Iteration 161/1000 | Loss: 0.00002254
Iteration 162/1000 | Loss: 0.00002254
Iteration 163/1000 | Loss: 0.00002253
Iteration 164/1000 | Loss: 0.00002253
Iteration 165/1000 | Loss: 0.00002253
Iteration 166/1000 | Loss: 0.00002253
Iteration 167/1000 | Loss: 0.00002252
Iteration 168/1000 | Loss: 0.00002252
Iteration 169/1000 | Loss: 0.00002252
Iteration 170/1000 | Loss: 0.00002252
Iteration 171/1000 | Loss: 0.00002252
Iteration 172/1000 | Loss: 0.00002252
Iteration 173/1000 | Loss: 0.00002252
Iteration 174/1000 | Loss: 0.00002252
Iteration 175/1000 | Loss: 0.00002252
Iteration 176/1000 | Loss: 0.00002252
Iteration 177/1000 | Loss: 0.00002252
Iteration 178/1000 | Loss: 0.00002252
Iteration 179/1000 | Loss: 0.00002251
Iteration 180/1000 | Loss: 0.00002251
Iteration 181/1000 | Loss: 0.00002251
Iteration 182/1000 | Loss: 0.00002251
Iteration 183/1000 | Loss: 0.00002251
Iteration 184/1000 | Loss: 0.00002251
Iteration 185/1000 | Loss: 0.00002251
Iteration 186/1000 | Loss: 0.00002251
Iteration 187/1000 | Loss: 0.00002251
Iteration 188/1000 | Loss: 0.00002251
Iteration 189/1000 | Loss: 0.00002251
Iteration 190/1000 | Loss: 0.00002251
Iteration 191/1000 | Loss: 0.00002251
Iteration 192/1000 | Loss: 0.00002251
Iteration 193/1000 | Loss: 0.00002251
Iteration 194/1000 | Loss: 0.00002251
Iteration 195/1000 | Loss: 0.00002251
Iteration 196/1000 | Loss: 0.00002251
Iteration 197/1000 | Loss: 0.00002251
Iteration 198/1000 | Loss: 0.00002251
Iteration 199/1000 | Loss: 0.00002251
Iteration 200/1000 | Loss: 0.00002251
Iteration 201/1000 | Loss: 0.00002251
Iteration 202/1000 | Loss: 0.00002251
Iteration 203/1000 | Loss: 0.00002251
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 203. Stopping optimization.
Last 5 losses: [2.2507438188767992e-05, 2.2507438188767992e-05, 2.2507438188767992e-05, 2.2507438188767992e-05, 2.2507438188767992e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2507438188767992e-05

Optimization complete. Final v2v error: 3.7839269638061523 mm

Highest mean error: 11.532346725463867 mm for frame 232

Lowest mean error: 3.346024751663208 mm for frame 56

Saving results

Total time: 181.62876105308533
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1060/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1060.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1060
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00479971
Iteration 2/25 | Loss: 0.00090974
Iteration 3/25 | Loss: 0.00079425
Iteration 4/25 | Loss: 0.00077337
Iteration 5/25 | Loss: 0.00076932
Iteration 6/25 | Loss: 0.00076829
Iteration 7/25 | Loss: 0.00076795
Iteration 8/25 | Loss: 0.00076791
Iteration 9/25 | Loss: 0.00076791
Iteration 10/25 | Loss: 0.00076791
Iteration 11/25 | Loss: 0.00076791
Iteration 12/25 | Loss: 0.00076791
Iteration 13/25 | Loss: 0.00076791
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007679130067117512, 0.0007679130067117512, 0.0007679130067117512, 0.0007679130067117512, 0.0007679130067117512]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007679130067117512

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.73275781
Iteration 2/25 | Loss: 0.00117655
Iteration 3/25 | Loss: 0.00117655
Iteration 4/25 | Loss: 0.00117655
Iteration 5/25 | Loss: 0.00117655
Iteration 6/25 | Loss: 0.00117655
Iteration 7/25 | Loss: 0.00117654
Iteration 8/25 | Loss: 0.00117654
Iteration 9/25 | Loss: 0.00117654
Iteration 10/25 | Loss: 0.00117654
Iteration 11/25 | Loss: 0.00117654
Iteration 12/25 | Loss: 0.00117654
Iteration 13/25 | Loss: 0.00117654
Iteration 14/25 | Loss: 0.00117654
Iteration 15/25 | Loss: 0.00117654
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0011765441158786416, 0.0011765441158786416, 0.0011765441158786416, 0.0011765441158786416, 0.0011765441158786416]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011765441158786416

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00117654
Iteration 2/1000 | Loss: 0.00003573
Iteration 3/1000 | Loss: 0.00002181
Iteration 4/1000 | Loss: 0.00001784
Iteration 5/1000 | Loss: 0.00001664
Iteration 6/1000 | Loss: 0.00001602
Iteration 7/1000 | Loss: 0.00001557
Iteration 8/1000 | Loss: 0.00001538
Iteration 9/1000 | Loss: 0.00001516
Iteration 10/1000 | Loss: 0.00001502
Iteration 11/1000 | Loss: 0.00001498
Iteration 12/1000 | Loss: 0.00001497
Iteration 13/1000 | Loss: 0.00001497
Iteration 14/1000 | Loss: 0.00001496
Iteration 15/1000 | Loss: 0.00001495
Iteration 16/1000 | Loss: 0.00001493
Iteration 17/1000 | Loss: 0.00001492
Iteration 18/1000 | Loss: 0.00001491
Iteration 19/1000 | Loss: 0.00001491
Iteration 20/1000 | Loss: 0.00001491
Iteration 21/1000 | Loss: 0.00001486
Iteration 22/1000 | Loss: 0.00001485
Iteration 23/1000 | Loss: 0.00001485
Iteration 24/1000 | Loss: 0.00001484
Iteration 25/1000 | Loss: 0.00001482
Iteration 26/1000 | Loss: 0.00001480
Iteration 27/1000 | Loss: 0.00001480
Iteration 28/1000 | Loss: 0.00001480
Iteration 29/1000 | Loss: 0.00001478
Iteration 30/1000 | Loss: 0.00001478
Iteration 31/1000 | Loss: 0.00001478
Iteration 32/1000 | Loss: 0.00001478
Iteration 33/1000 | Loss: 0.00001477
Iteration 34/1000 | Loss: 0.00001476
Iteration 35/1000 | Loss: 0.00001476
Iteration 36/1000 | Loss: 0.00001475
Iteration 37/1000 | Loss: 0.00001474
Iteration 38/1000 | Loss: 0.00001474
Iteration 39/1000 | Loss: 0.00001474
Iteration 40/1000 | Loss: 0.00001473
Iteration 41/1000 | Loss: 0.00001473
Iteration 42/1000 | Loss: 0.00001473
Iteration 43/1000 | Loss: 0.00001472
Iteration 44/1000 | Loss: 0.00001472
Iteration 45/1000 | Loss: 0.00001472
Iteration 46/1000 | Loss: 0.00001472
Iteration 47/1000 | Loss: 0.00001472
Iteration 48/1000 | Loss: 0.00001472
Iteration 49/1000 | Loss: 0.00001472
Iteration 50/1000 | Loss: 0.00001472
Iteration 51/1000 | Loss: 0.00001472
Iteration 52/1000 | Loss: 0.00001471
Iteration 53/1000 | Loss: 0.00001471
Iteration 54/1000 | Loss: 0.00001471
Iteration 55/1000 | Loss: 0.00001471
Iteration 56/1000 | Loss: 0.00001471
Iteration 57/1000 | Loss: 0.00001471
Iteration 58/1000 | Loss: 0.00001471
Iteration 59/1000 | Loss: 0.00001470
Iteration 60/1000 | Loss: 0.00001470
Iteration 61/1000 | Loss: 0.00001470
Iteration 62/1000 | Loss: 0.00001470
Iteration 63/1000 | Loss: 0.00001470
Iteration 64/1000 | Loss: 0.00001470
Iteration 65/1000 | Loss: 0.00001470
Iteration 66/1000 | Loss: 0.00001470
Iteration 67/1000 | Loss: 0.00001470
Iteration 68/1000 | Loss: 0.00001469
Iteration 69/1000 | Loss: 0.00001469
Iteration 70/1000 | Loss: 0.00001469
Iteration 71/1000 | Loss: 0.00001469
Iteration 72/1000 | Loss: 0.00001469
Iteration 73/1000 | Loss: 0.00001469
Iteration 74/1000 | Loss: 0.00001469
Iteration 75/1000 | Loss: 0.00001469
Iteration 76/1000 | Loss: 0.00001468
Iteration 77/1000 | Loss: 0.00001468
Iteration 78/1000 | Loss: 0.00001468
Iteration 79/1000 | Loss: 0.00001468
Iteration 80/1000 | Loss: 0.00001467
Iteration 81/1000 | Loss: 0.00001467
Iteration 82/1000 | Loss: 0.00001467
Iteration 83/1000 | Loss: 0.00001467
Iteration 84/1000 | Loss: 0.00001467
Iteration 85/1000 | Loss: 0.00001467
Iteration 86/1000 | Loss: 0.00001467
Iteration 87/1000 | Loss: 0.00001466
Iteration 88/1000 | Loss: 0.00001466
Iteration 89/1000 | Loss: 0.00001466
Iteration 90/1000 | Loss: 0.00001466
Iteration 91/1000 | Loss: 0.00001466
Iteration 92/1000 | Loss: 0.00001466
Iteration 93/1000 | Loss: 0.00001466
Iteration 94/1000 | Loss: 0.00001465
Iteration 95/1000 | Loss: 0.00001465
Iteration 96/1000 | Loss: 0.00001465
Iteration 97/1000 | Loss: 0.00001465
Iteration 98/1000 | Loss: 0.00001464
Iteration 99/1000 | Loss: 0.00001464
Iteration 100/1000 | Loss: 0.00001464
Iteration 101/1000 | Loss: 0.00001464
Iteration 102/1000 | Loss: 0.00001464
Iteration 103/1000 | Loss: 0.00001464
Iteration 104/1000 | Loss: 0.00001464
Iteration 105/1000 | Loss: 0.00001463
Iteration 106/1000 | Loss: 0.00001463
Iteration 107/1000 | Loss: 0.00001463
Iteration 108/1000 | Loss: 0.00001463
Iteration 109/1000 | Loss: 0.00001463
Iteration 110/1000 | Loss: 0.00001463
Iteration 111/1000 | Loss: 0.00001463
Iteration 112/1000 | Loss: 0.00001463
Iteration 113/1000 | Loss: 0.00001463
Iteration 114/1000 | Loss: 0.00001463
Iteration 115/1000 | Loss: 0.00001462
Iteration 116/1000 | Loss: 0.00001462
Iteration 117/1000 | Loss: 0.00001462
Iteration 118/1000 | Loss: 0.00001462
Iteration 119/1000 | Loss: 0.00001462
Iteration 120/1000 | Loss: 0.00001462
Iteration 121/1000 | Loss: 0.00001462
Iteration 122/1000 | Loss: 0.00001461
Iteration 123/1000 | Loss: 0.00001461
Iteration 124/1000 | Loss: 0.00001461
Iteration 125/1000 | Loss: 0.00001461
Iteration 126/1000 | Loss: 0.00001461
Iteration 127/1000 | Loss: 0.00001461
Iteration 128/1000 | Loss: 0.00001461
Iteration 129/1000 | Loss: 0.00001461
Iteration 130/1000 | Loss: 0.00001460
Iteration 131/1000 | Loss: 0.00001460
Iteration 132/1000 | Loss: 0.00001460
Iteration 133/1000 | Loss: 0.00001460
Iteration 134/1000 | Loss: 0.00001460
Iteration 135/1000 | Loss: 0.00001460
Iteration 136/1000 | Loss: 0.00001460
Iteration 137/1000 | Loss: 0.00001460
Iteration 138/1000 | Loss: 0.00001460
Iteration 139/1000 | Loss: 0.00001459
Iteration 140/1000 | Loss: 0.00001459
Iteration 141/1000 | Loss: 0.00001459
Iteration 142/1000 | Loss: 0.00001459
Iteration 143/1000 | Loss: 0.00001458
Iteration 144/1000 | Loss: 0.00001458
Iteration 145/1000 | Loss: 0.00001458
Iteration 146/1000 | Loss: 0.00001458
Iteration 147/1000 | Loss: 0.00001457
Iteration 148/1000 | Loss: 0.00001457
Iteration 149/1000 | Loss: 0.00001457
Iteration 150/1000 | Loss: 0.00001457
Iteration 151/1000 | Loss: 0.00001457
Iteration 152/1000 | Loss: 0.00001457
Iteration 153/1000 | Loss: 0.00001457
Iteration 154/1000 | Loss: 0.00001457
Iteration 155/1000 | Loss: 0.00001457
Iteration 156/1000 | Loss: 0.00001457
Iteration 157/1000 | Loss: 0.00001457
Iteration 158/1000 | Loss: 0.00001457
Iteration 159/1000 | Loss: 0.00001456
Iteration 160/1000 | Loss: 0.00001456
Iteration 161/1000 | Loss: 0.00001456
Iteration 162/1000 | Loss: 0.00001455
Iteration 163/1000 | Loss: 0.00001455
Iteration 164/1000 | Loss: 0.00001455
Iteration 165/1000 | Loss: 0.00001455
Iteration 166/1000 | Loss: 0.00001454
Iteration 167/1000 | Loss: 0.00001454
Iteration 168/1000 | Loss: 0.00001454
Iteration 169/1000 | Loss: 0.00001454
Iteration 170/1000 | Loss: 0.00001454
Iteration 171/1000 | Loss: 0.00001454
Iteration 172/1000 | Loss: 0.00001454
Iteration 173/1000 | Loss: 0.00001454
Iteration 174/1000 | Loss: 0.00001453
Iteration 175/1000 | Loss: 0.00001453
Iteration 176/1000 | Loss: 0.00001453
Iteration 177/1000 | Loss: 0.00001453
Iteration 178/1000 | Loss: 0.00001453
Iteration 179/1000 | Loss: 0.00001453
Iteration 180/1000 | Loss: 0.00001453
Iteration 181/1000 | Loss: 0.00001452
Iteration 182/1000 | Loss: 0.00001452
Iteration 183/1000 | Loss: 0.00001452
Iteration 184/1000 | Loss: 0.00001452
Iteration 185/1000 | Loss: 0.00001452
Iteration 186/1000 | Loss: 0.00001452
Iteration 187/1000 | Loss: 0.00001452
Iteration 188/1000 | Loss: 0.00001452
Iteration 189/1000 | Loss: 0.00001452
Iteration 190/1000 | Loss: 0.00001452
Iteration 191/1000 | Loss: 0.00001452
Iteration 192/1000 | Loss: 0.00001452
Iteration 193/1000 | Loss: 0.00001452
Iteration 194/1000 | Loss: 0.00001452
Iteration 195/1000 | Loss: 0.00001452
Iteration 196/1000 | Loss: 0.00001451
Iteration 197/1000 | Loss: 0.00001451
Iteration 198/1000 | Loss: 0.00001451
Iteration 199/1000 | Loss: 0.00001451
Iteration 200/1000 | Loss: 0.00001451
Iteration 201/1000 | Loss: 0.00001451
Iteration 202/1000 | Loss: 0.00001451
Iteration 203/1000 | Loss: 0.00001451
Iteration 204/1000 | Loss: 0.00001451
Iteration 205/1000 | Loss: 0.00001451
Iteration 206/1000 | Loss: 0.00001451
Iteration 207/1000 | Loss: 0.00001451
Iteration 208/1000 | Loss: 0.00001451
Iteration 209/1000 | Loss: 0.00001451
Iteration 210/1000 | Loss: 0.00001451
Iteration 211/1000 | Loss: 0.00001451
Iteration 212/1000 | Loss: 0.00001451
Iteration 213/1000 | Loss: 0.00001451
Iteration 214/1000 | Loss: 0.00001450
Iteration 215/1000 | Loss: 0.00001450
Iteration 216/1000 | Loss: 0.00001450
Iteration 217/1000 | Loss: 0.00001450
Iteration 218/1000 | Loss: 0.00001450
Iteration 219/1000 | Loss: 0.00001450
Iteration 220/1000 | Loss: 0.00001450
Iteration 221/1000 | Loss: 0.00001450
Iteration 222/1000 | Loss: 0.00001450
Iteration 223/1000 | Loss: 0.00001450
Iteration 224/1000 | Loss: 0.00001450
Iteration 225/1000 | Loss: 0.00001450
Iteration 226/1000 | Loss: 0.00001450
Iteration 227/1000 | Loss: 0.00001450
Iteration 228/1000 | Loss: 0.00001450
Iteration 229/1000 | Loss: 0.00001450
Iteration 230/1000 | Loss: 0.00001450
Iteration 231/1000 | Loss: 0.00001450
Iteration 232/1000 | Loss: 0.00001450
Iteration 233/1000 | Loss: 0.00001450
Iteration 234/1000 | Loss: 0.00001450
Iteration 235/1000 | Loss: 0.00001450
Iteration 236/1000 | Loss: 0.00001450
Iteration 237/1000 | Loss: 0.00001449
Iteration 238/1000 | Loss: 0.00001449
Iteration 239/1000 | Loss: 0.00001449
Iteration 240/1000 | Loss: 0.00001449
Iteration 241/1000 | Loss: 0.00001449
Iteration 242/1000 | Loss: 0.00001449
Iteration 243/1000 | Loss: 0.00001449
Iteration 244/1000 | Loss: 0.00001449
Iteration 245/1000 | Loss: 0.00001449
Iteration 246/1000 | Loss: 0.00001449
Iteration 247/1000 | Loss: 0.00001449
Iteration 248/1000 | Loss: 0.00001449
Iteration 249/1000 | Loss: 0.00001449
Iteration 250/1000 | Loss: 0.00001449
Iteration 251/1000 | Loss: 0.00001449
Iteration 252/1000 | Loss: 0.00001449
Iteration 253/1000 | Loss: 0.00001449
Iteration 254/1000 | Loss: 0.00001449
Iteration 255/1000 | Loss: 0.00001449
Iteration 256/1000 | Loss: 0.00001449
Iteration 257/1000 | Loss: 0.00001449
Iteration 258/1000 | Loss: 0.00001449
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 258. Stopping optimization.
Last 5 losses: [1.4492136870103423e-05, 1.4492136870103423e-05, 1.4492136870103423e-05, 1.4492136870103423e-05, 1.4492136870103423e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4492136870103423e-05

Optimization complete. Final v2v error: 3.1968588829040527 mm

Highest mean error: 3.741201162338257 mm for frame 40

Lowest mean error: 2.970494031906128 mm for frame 96

Saving results

Total time: 41.991599798202515
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840199
Iteration 2/25 | Loss: 0.00111894
Iteration 3/25 | Loss: 0.00081299
Iteration 4/25 | Loss: 0.00077566
Iteration 5/25 | Loss: 0.00076345
Iteration 6/25 | Loss: 0.00076071
Iteration 7/25 | Loss: 0.00076000
Iteration 8/25 | Loss: 0.00075998
Iteration 9/25 | Loss: 0.00075998
Iteration 10/25 | Loss: 0.00075998
Iteration 11/25 | Loss: 0.00075998
Iteration 12/25 | Loss: 0.00075998
Iteration 13/25 | Loss: 0.00075998
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007599755772389472, 0.0007599755772389472, 0.0007599755772389472, 0.0007599755772389472, 0.0007599755772389472]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007599755772389472

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.37758005
Iteration 2/25 | Loss: 0.00112751
Iteration 3/25 | Loss: 0.00112750
Iteration 4/25 | Loss: 0.00112750
Iteration 5/25 | Loss: 0.00112750
Iteration 6/25 | Loss: 0.00112750
Iteration 7/25 | Loss: 0.00112750
Iteration 8/25 | Loss: 0.00112750
Iteration 9/25 | Loss: 0.00112750
Iteration 10/25 | Loss: 0.00112750
Iteration 11/25 | Loss: 0.00112750
Iteration 12/25 | Loss: 0.00112750
Iteration 13/25 | Loss: 0.00112750
Iteration 14/25 | Loss: 0.00112750
Iteration 15/25 | Loss: 0.00112750
Iteration 16/25 | Loss: 0.00112750
Iteration 17/25 | Loss: 0.00112750
Iteration 18/25 | Loss: 0.00112750
Iteration 19/25 | Loss: 0.00112750
Iteration 20/25 | Loss: 0.00112750
Iteration 21/25 | Loss: 0.00112750
Iteration 22/25 | Loss: 0.00112750
Iteration 23/25 | Loss: 0.00112750
Iteration 24/25 | Loss: 0.00112750
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0011274992721155286, 0.0011274992721155286, 0.0011274992721155286, 0.0011274992721155286, 0.0011274992721155286]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011274992721155286

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112750
Iteration 2/1000 | Loss: 0.00004193
Iteration 3/1000 | Loss: 0.00003048
Iteration 4/1000 | Loss: 0.00002286
Iteration 5/1000 | Loss: 0.00002108
Iteration 6/1000 | Loss: 0.00002003
Iteration 7/1000 | Loss: 0.00001923
Iteration 8/1000 | Loss: 0.00001868
Iteration 9/1000 | Loss: 0.00001828
Iteration 10/1000 | Loss: 0.00001804
Iteration 11/1000 | Loss: 0.00001787
Iteration 12/1000 | Loss: 0.00001780
Iteration 13/1000 | Loss: 0.00001769
Iteration 14/1000 | Loss: 0.00001759
Iteration 15/1000 | Loss: 0.00001751
Iteration 16/1000 | Loss: 0.00001748
Iteration 17/1000 | Loss: 0.00001736
Iteration 18/1000 | Loss: 0.00001735
Iteration 19/1000 | Loss: 0.00001733
Iteration 20/1000 | Loss: 0.00001733
Iteration 21/1000 | Loss: 0.00001730
Iteration 22/1000 | Loss: 0.00001726
Iteration 23/1000 | Loss: 0.00001726
Iteration 24/1000 | Loss: 0.00001725
Iteration 25/1000 | Loss: 0.00001720
Iteration 26/1000 | Loss: 0.00001720
Iteration 27/1000 | Loss: 0.00001720
Iteration 28/1000 | Loss: 0.00001719
Iteration 29/1000 | Loss: 0.00001717
Iteration 30/1000 | Loss: 0.00001716
Iteration 31/1000 | Loss: 0.00001715
Iteration 32/1000 | Loss: 0.00001715
Iteration 33/1000 | Loss: 0.00001715
Iteration 34/1000 | Loss: 0.00001715
Iteration 35/1000 | Loss: 0.00001715
Iteration 36/1000 | Loss: 0.00001714
Iteration 37/1000 | Loss: 0.00001714
Iteration 38/1000 | Loss: 0.00001714
Iteration 39/1000 | Loss: 0.00001714
Iteration 40/1000 | Loss: 0.00001714
Iteration 41/1000 | Loss: 0.00001713
Iteration 42/1000 | Loss: 0.00001713
Iteration 43/1000 | Loss: 0.00001713
Iteration 44/1000 | Loss: 0.00001713
Iteration 45/1000 | Loss: 0.00001713
Iteration 46/1000 | Loss: 0.00001713
Iteration 47/1000 | Loss: 0.00001713
Iteration 48/1000 | Loss: 0.00001713
Iteration 49/1000 | Loss: 0.00001712
Iteration 50/1000 | Loss: 0.00001712
Iteration 51/1000 | Loss: 0.00001712
Iteration 52/1000 | Loss: 0.00001712
Iteration 53/1000 | Loss: 0.00001711
Iteration 54/1000 | Loss: 0.00001711
Iteration 55/1000 | Loss: 0.00001711
Iteration 56/1000 | Loss: 0.00001711
Iteration 57/1000 | Loss: 0.00001710
Iteration 58/1000 | Loss: 0.00001710
Iteration 59/1000 | Loss: 0.00001710
Iteration 60/1000 | Loss: 0.00001708
Iteration 61/1000 | Loss: 0.00001708
Iteration 62/1000 | Loss: 0.00001707
Iteration 63/1000 | Loss: 0.00001707
Iteration 64/1000 | Loss: 0.00001706
Iteration 65/1000 | Loss: 0.00001706
Iteration 66/1000 | Loss: 0.00001705
Iteration 67/1000 | Loss: 0.00001704
Iteration 68/1000 | Loss: 0.00001701
Iteration 69/1000 | Loss: 0.00001701
Iteration 70/1000 | Loss: 0.00001701
Iteration 71/1000 | Loss: 0.00001700
Iteration 72/1000 | Loss: 0.00001700
Iteration 73/1000 | Loss: 0.00001699
Iteration 74/1000 | Loss: 0.00001699
Iteration 75/1000 | Loss: 0.00001697
Iteration 76/1000 | Loss: 0.00001697
Iteration 77/1000 | Loss: 0.00001696
Iteration 78/1000 | Loss: 0.00001696
Iteration 79/1000 | Loss: 0.00001696
Iteration 80/1000 | Loss: 0.00001695
Iteration 81/1000 | Loss: 0.00001695
Iteration 82/1000 | Loss: 0.00001695
Iteration 83/1000 | Loss: 0.00001694
Iteration 84/1000 | Loss: 0.00001694
Iteration 85/1000 | Loss: 0.00001694
Iteration 86/1000 | Loss: 0.00001693
Iteration 87/1000 | Loss: 0.00001693
Iteration 88/1000 | Loss: 0.00001693
Iteration 89/1000 | Loss: 0.00001692
Iteration 90/1000 | Loss: 0.00001692
Iteration 91/1000 | Loss: 0.00001692
Iteration 92/1000 | Loss: 0.00001692
Iteration 93/1000 | Loss: 0.00001692
Iteration 94/1000 | Loss: 0.00001691
Iteration 95/1000 | Loss: 0.00001691
Iteration 96/1000 | Loss: 0.00001691
Iteration 97/1000 | Loss: 0.00001691
Iteration 98/1000 | Loss: 0.00001691
Iteration 99/1000 | Loss: 0.00001691
Iteration 100/1000 | Loss: 0.00001691
Iteration 101/1000 | Loss: 0.00001691
Iteration 102/1000 | Loss: 0.00001691
Iteration 103/1000 | Loss: 0.00001691
Iteration 104/1000 | Loss: 0.00001691
Iteration 105/1000 | Loss: 0.00001690
Iteration 106/1000 | Loss: 0.00001690
Iteration 107/1000 | Loss: 0.00001690
Iteration 108/1000 | Loss: 0.00001690
Iteration 109/1000 | Loss: 0.00001690
Iteration 110/1000 | Loss: 0.00001690
Iteration 111/1000 | Loss: 0.00001690
Iteration 112/1000 | Loss: 0.00001689
Iteration 113/1000 | Loss: 0.00001689
Iteration 114/1000 | Loss: 0.00001689
Iteration 115/1000 | Loss: 0.00001689
Iteration 116/1000 | Loss: 0.00001689
Iteration 117/1000 | Loss: 0.00001689
Iteration 118/1000 | Loss: 0.00001689
Iteration 119/1000 | Loss: 0.00001689
Iteration 120/1000 | Loss: 0.00001689
Iteration 121/1000 | Loss: 0.00001689
Iteration 122/1000 | Loss: 0.00001689
Iteration 123/1000 | Loss: 0.00001689
Iteration 124/1000 | Loss: 0.00001689
Iteration 125/1000 | Loss: 0.00001689
Iteration 126/1000 | Loss: 0.00001689
Iteration 127/1000 | Loss: 0.00001689
Iteration 128/1000 | Loss: 0.00001689
Iteration 129/1000 | Loss: 0.00001689
Iteration 130/1000 | Loss: 0.00001689
Iteration 131/1000 | Loss: 0.00001689
Iteration 132/1000 | Loss: 0.00001689
Iteration 133/1000 | Loss: 0.00001689
Iteration 134/1000 | Loss: 0.00001689
Iteration 135/1000 | Loss: 0.00001689
Iteration 136/1000 | Loss: 0.00001689
Iteration 137/1000 | Loss: 0.00001689
Iteration 138/1000 | Loss: 0.00001689
Iteration 139/1000 | Loss: 0.00001689
Iteration 140/1000 | Loss: 0.00001689
Iteration 141/1000 | Loss: 0.00001689
Iteration 142/1000 | Loss: 0.00001689
Iteration 143/1000 | Loss: 0.00001689
Iteration 144/1000 | Loss: 0.00001689
Iteration 145/1000 | Loss: 0.00001689
Iteration 146/1000 | Loss: 0.00001689
Iteration 147/1000 | Loss: 0.00001689
Iteration 148/1000 | Loss: 0.00001689
Iteration 149/1000 | Loss: 0.00001689
Iteration 150/1000 | Loss: 0.00001689
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [1.6888207028387114e-05, 1.6888207028387114e-05, 1.6888207028387114e-05, 1.6888207028387114e-05, 1.6888207028387114e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6888207028387114e-05

Optimization complete. Final v2v error: 3.4034910202026367 mm

Highest mean error: 4.981978893280029 mm for frame 62

Lowest mean error: 2.813687324523926 mm for frame 89

Saving results

Total time: 42.807581424713135
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1098/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1098.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1098
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00395584
Iteration 2/25 | Loss: 0.00084732
Iteration 3/25 | Loss: 0.00076698
Iteration 4/25 | Loss: 0.00074906
Iteration 5/25 | Loss: 0.00074152
Iteration 6/25 | Loss: 0.00074004
Iteration 7/25 | Loss: 0.00073960
Iteration 8/25 | Loss: 0.00073960
Iteration 9/25 | Loss: 0.00073960
Iteration 10/25 | Loss: 0.00073960
Iteration 11/25 | Loss: 0.00073960
Iteration 12/25 | Loss: 0.00073960
Iteration 13/25 | Loss: 0.00073960
Iteration 14/25 | Loss: 0.00073960
Iteration 15/25 | Loss: 0.00073960
Iteration 16/25 | Loss: 0.00073960
Iteration 17/25 | Loss: 0.00073960
Iteration 18/25 | Loss: 0.00073960
Iteration 19/25 | Loss: 0.00073960
Iteration 20/25 | Loss: 0.00073960
Iteration 21/25 | Loss: 0.00073960
Iteration 22/25 | Loss: 0.00073960
Iteration 23/25 | Loss: 0.00073960
Iteration 24/25 | Loss: 0.00073960
Iteration 25/25 | Loss: 0.00073960

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59543133
Iteration 2/25 | Loss: 0.00118927
Iteration 3/25 | Loss: 0.00118927
Iteration 4/25 | Loss: 0.00118927
Iteration 5/25 | Loss: 0.00118927
Iteration 6/25 | Loss: 0.00118927
Iteration 7/25 | Loss: 0.00118927
Iteration 8/25 | Loss: 0.00118927
Iteration 9/25 | Loss: 0.00118927
Iteration 10/25 | Loss: 0.00118927
Iteration 11/25 | Loss: 0.00118927
Iteration 12/25 | Loss: 0.00118927
Iteration 13/25 | Loss: 0.00118927
Iteration 14/25 | Loss: 0.00118927
Iteration 15/25 | Loss: 0.00118927
Iteration 16/25 | Loss: 0.00118927
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011892685433849692, 0.0011892685433849692, 0.0011892685433849692, 0.0011892685433849692, 0.0011892685433849692]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011892685433849692

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118927
Iteration 2/1000 | Loss: 0.00002552
Iteration 3/1000 | Loss: 0.00001698
Iteration 4/1000 | Loss: 0.00001576
Iteration 5/1000 | Loss: 0.00001475
Iteration 6/1000 | Loss: 0.00001430
Iteration 7/1000 | Loss: 0.00001392
Iteration 8/1000 | Loss: 0.00001391
Iteration 9/1000 | Loss: 0.00001373
Iteration 10/1000 | Loss: 0.00001352
Iteration 11/1000 | Loss: 0.00001343
Iteration 12/1000 | Loss: 0.00001342
Iteration 13/1000 | Loss: 0.00001339
Iteration 14/1000 | Loss: 0.00001335
Iteration 15/1000 | Loss: 0.00001331
Iteration 16/1000 | Loss: 0.00001324
Iteration 17/1000 | Loss: 0.00001324
Iteration 18/1000 | Loss: 0.00001322
Iteration 19/1000 | Loss: 0.00001321
Iteration 20/1000 | Loss: 0.00001321
Iteration 21/1000 | Loss: 0.00001321
Iteration 22/1000 | Loss: 0.00001319
Iteration 23/1000 | Loss: 0.00001317
Iteration 24/1000 | Loss: 0.00001316
Iteration 25/1000 | Loss: 0.00001316
Iteration 26/1000 | Loss: 0.00001315
Iteration 27/1000 | Loss: 0.00001315
Iteration 28/1000 | Loss: 0.00001314
Iteration 29/1000 | Loss: 0.00001314
Iteration 30/1000 | Loss: 0.00001314
Iteration 31/1000 | Loss: 0.00001314
Iteration 32/1000 | Loss: 0.00001314
Iteration 33/1000 | Loss: 0.00001314
Iteration 34/1000 | Loss: 0.00001314
Iteration 35/1000 | Loss: 0.00001313
Iteration 36/1000 | Loss: 0.00001313
Iteration 37/1000 | Loss: 0.00001313
Iteration 38/1000 | Loss: 0.00001313
Iteration 39/1000 | Loss: 0.00001312
Iteration 40/1000 | Loss: 0.00001312
Iteration 41/1000 | Loss: 0.00001312
Iteration 42/1000 | Loss: 0.00001311
Iteration 43/1000 | Loss: 0.00001311
Iteration 44/1000 | Loss: 0.00001310
Iteration 45/1000 | Loss: 0.00001310
Iteration 46/1000 | Loss: 0.00001308
Iteration 47/1000 | Loss: 0.00001307
Iteration 48/1000 | Loss: 0.00001306
Iteration 49/1000 | Loss: 0.00001306
Iteration 50/1000 | Loss: 0.00001305
Iteration 51/1000 | Loss: 0.00001304
Iteration 52/1000 | Loss: 0.00001304
Iteration 53/1000 | Loss: 0.00001303
Iteration 54/1000 | Loss: 0.00001302
Iteration 55/1000 | Loss: 0.00001302
Iteration 56/1000 | Loss: 0.00001302
Iteration 57/1000 | Loss: 0.00001301
Iteration 58/1000 | Loss: 0.00001299
Iteration 59/1000 | Loss: 0.00001299
Iteration 60/1000 | Loss: 0.00001299
Iteration 61/1000 | Loss: 0.00001298
Iteration 62/1000 | Loss: 0.00001298
Iteration 63/1000 | Loss: 0.00001298
Iteration 64/1000 | Loss: 0.00001298
Iteration 65/1000 | Loss: 0.00001297
Iteration 66/1000 | Loss: 0.00001297
Iteration 67/1000 | Loss: 0.00001297
Iteration 68/1000 | Loss: 0.00001297
Iteration 69/1000 | Loss: 0.00001297
Iteration 70/1000 | Loss: 0.00001296
Iteration 71/1000 | Loss: 0.00001296
Iteration 72/1000 | Loss: 0.00001295
Iteration 73/1000 | Loss: 0.00001295
Iteration 74/1000 | Loss: 0.00001295
Iteration 75/1000 | Loss: 0.00001295
Iteration 76/1000 | Loss: 0.00001295
Iteration 77/1000 | Loss: 0.00001295
Iteration 78/1000 | Loss: 0.00001295
Iteration 79/1000 | Loss: 0.00001295
Iteration 80/1000 | Loss: 0.00001295
Iteration 81/1000 | Loss: 0.00001295
Iteration 82/1000 | Loss: 0.00001295
Iteration 83/1000 | Loss: 0.00001295
Iteration 84/1000 | Loss: 0.00001295
Iteration 85/1000 | Loss: 0.00001295
Iteration 86/1000 | Loss: 0.00001295
Iteration 87/1000 | Loss: 0.00001295
Iteration 88/1000 | Loss: 0.00001295
Iteration 89/1000 | Loss: 0.00001295
Iteration 90/1000 | Loss: 0.00001295
Iteration 91/1000 | Loss: 0.00001295
Iteration 92/1000 | Loss: 0.00001295
Iteration 93/1000 | Loss: 0.00001295
Iteration 94/1000 | Loss: 0.00001295
Iteration 95/1000 | Loss: 0.00001295
Iteration 96/1000 | Loss: 0.00001295
Iteration 97/1000 | Loss: 0.00001295
Iteration 98/1000 | Loss: 0.00001295
Iteration 99/1000 | Loss: 0.00001295
Iteration 100/1000 | Loss: 0.00001295
Iteration 101/1000 | Loss: 0.00001295
Iteration 102/1000 | Loss: 0.00001295
Iteration 103/1000 | Loss: 0.00001295
Iteration 104/1000 | Loss: 0.00001295
Iteration 105/1000 | Loss: 0.00001295
Iteration 106/1000 | Loss: 0.00001295
Iteration 107/1000 | Loss: 0.00001295
Iteration 108/1000 | Loss: 0.00001295
Iteration 109/1000 | Loss: 0.00001295
Iteration 110/1000 | Loss: 0.00001295
Iteration 111/1000 | Loss: 0.00001295
Iteration 112/1000 | Loss: 0.00001295
Iteration 113/1000 | Loss: 0.00001295
Iteration 114/1000 | Loss: 0.00001295
Iteration 115/1000 | Loss: 0.00001295
Iteration 116/1000 | Loss: 0.00001295
Iteration 117/1000 | Loss: 0.00001295
Iteration 118/1000 | Loss: 0.00001295
Iteration 119/1000 | Loss: 0.00001295
Iteration 120/1000 | Loss: 0.00001295
Iteration 121/1000 | Loss: 0.00001295
Iteration 122/1000 | Loss: 0.00001295
Iteration 123/1000 | Loss: 0.00001295
Iteration 124/1000 | Loss: 0.00001295
Iteration 125/1000 | Loss: 0.00001295
Iteration 126/1000 | Loss: 0.00001295
Iteration 127/1000 | Loss: 0.00001295
Iteration 128/1000 | Loss: 0.00001295
Iteration 129/1000 | Loss: 0.00001295
Iteration 130/1000 | Loss: 0.00001295
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 130. Stopping optimization.
Last 5 losses: [1.2946700735483319e-05, 1.2946700735483319e-05, 1.2946700735483319e-05, 1.2946700735483319e-05, 1.2946700735483319e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2946700735483319e-05

Optimization complete. Final v2v error: 3.0754828453063965 mm

Highest mean error: 3.2116332054138184 mm for frame 39

Lowest mean error: 2.960688829421997 mm for frame 0

Saving results

Total time: 34.427042961120605
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1074/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1074.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1074
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405767
Iteration 2/25 | Loss: 0.00095839
Iteration 3/25 | Loss: 0.00078051
Iteration 4/25 | Loss: 0.00075448
Iteration 5/25 | Loss: 0.00074623
Iteration 6/25 | Loss: 0.00074353
Iteration 7/25 | Loss: 0.00074269
Iteration 8/25 | Loss: 0.00074252
Iteration 9/25 | Loss: 0.00074252
Iteration 10/25 | Loss: 0.00074252
Iteration 11/25 | Loss: 0.00074252
Iteration 12/25 | Loss: 0.00074252
Iteration 13/25 | Loss: 0.00074252
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007425218354910612, 0.0007425218354910612, 0.0007425218354910612, 0.0007425218354910612, 0.0007425218354910612]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007425218354910612

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46257854
Iteration 2/25 | Loss: 0.00115175
Iteration 3/25 | Loss: 0.00115173
Iteration 4/25 | Loss: 0.00115173
Iteration 5/25 | Loss: 0.00115173
Iteration 6/25 | Loss: 0.00115173
Iteration 7/25 | Loss: 0.00115173
Iteration 8/25 | Loss: 0.00115173
Iteration 9/25 | Loss: 0.00115173
Iteration 10/25 | Loss: 0.00115173
Iteration 11/25 | Loss: 0.00115173
Iteration 12/25 | Loss: 0.00115173
Iteration 13/25 | Loss: 0.00115173
Iteration 14/25 | Loss: 0.00115173
Iteration 15/25 | Loss: 0.00115173
Iteration 16/25 | Loss: 0.00115173
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011517268139868975, 0.0011517268139868975, 0.0011517268139868975, 0.0011517268139868975, 0.0011517268139868975]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011517268139868975

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00115173
Iteration 2/1000 | Loss: 0.00003662
Iteration 3/1000 | Loss: 0.00002523
Iteration 4/1000 | Loss: 0.00001922
Iteration 5/1000 | Loss: 0.00001711
Iteration 6/1000 | Loss: 0.00001641
Iteration 7/1000 | Loss: 0.00001569
Iteration 8/1000 | Loss: 0.00001532
Iteration 9/1000 | Loss: 0.00001492
Iteration 10/1000 | Loss: 0.00001468
Iteration 11/1000 | Loss: 0.00001460
Iteration 12/1000 | Loss: 0.00001454
Iteration 13/1000 | Loss: 0.00001453
Iteration 14/1000 | Loss: 0.00001451
Iteration 15/1000 | Loss: 0.00001443
Iteration 16/1000 | Loss: 0.00001439
Iteration 17/1000 | Loss: 0.00001436
Iteration 18/1000 | Loss: 0.00001435
Iteration 19/1000 | Loss: 0.00001434
Iteration 20/1000 | Loss: 0.00001434
Iteration 21/1000 | Loss: 0.00001434
Iteration 22/1000 | Loss: 0.00001434
Iteration 23/1000 | Loss: 0.00001434
Iteration 24/1000 | Loss: 0.00001434
Iteration 25/1000 | Loss: 0.00001434
Iteration 26/1000 | Loss: 0.00001434
Iteration 27/1000 | Loss: 0.00001434
Iteration 28/1000 | Loss: 0.00001433
Iteration 29/1000 | Loss: 0.00001433
Iteration 30/1000 | Loss: 0.00001433
Iteration 31/1000 | Loss: 0.00001433
Iteration 32/1000 | Loss: 0.00001433
Iteration 33/1000 | Loss: 0.00001433
Iteration 34/1000 | Loss: 0.00001433
Iteration 35/1000 | Loss: 0.00001430
Iteration 36/1000 | Loss: 0.00001430
Iteration 37/1000 | Loss: 0.00001429
Iteration 38/1000 | Loss: 0.00001428
Iteration 39/1000 | Loss: 0.00001428
Iteration 40/1000 | Loss: 0.00001427
Iteration 41/1000 | Loss: 0.00001427
Iteration 42/1000 | Loss: 0.00001426
Iteration 43/1000 | Loss: 0.00001425
Iteration 44/1000 | Loss: 0.00001421
Iteration 45/1000 | Loss: 0.00001420
Iteration 46/1000 | Loss: 0.00001419
Iteration 47/1000 | Loss: 0.00001419
Iteration 48/1000 | Loss: 0.00001418
Iteration 49/1000 | Loss: 0.00001418
Iteration 50/1000 | Loss: 0.00001417
Iteration 51/1000 | Loss: 0.00001417
Iteration 52/1000 | Loss: 0.00001417
Iteration 53/1000 | Loss: 0.00001416
Iteration 54/1000 | Loss: 0.00001416
Iteration 55/1000 | Loss: 0.00001415
Iteration 56/1000 | Loss: 0.00001414
Iteration 57/1000 | Loss: 0.00001414
Iteration 58/1000 | Loss: 0.00001413
Iteration 59/1000 | Loss: 0.00001413
Iteration 60/1000 | Loss: 0.00001413
Iteration 61/1000 | Loss: 0.00001412
Iteration 62/1000 | Loss: 0.00001412
Iteration 63/1000 | Loss: 0.00001411
Iteration 64/1000 | Loss: 0.00001411
Iteration 65/1000 | Loss: 0.00001411
Iteration 66/1000 | Loss: 0.00001411
Iteration 67/1000 | Loss: 0.00001410
Iteration 68/1000 | Loss: 0.00001410
Iteration 69/1000 | Loss: 0.00001410
Iteration 70/1000 | Loss: 0.00001410
Iteration 71/1000 | Loss: 0.00001410
Iteration 72/1000 | Loss: 0.00001410
Iteration 73/1000 | Loss: 0.00001410
Iteration 74/1000 | Loss: 0.00001410
Iteration 75/1000 | Loss: 0.00001410
Iteration 76/1000 | Loss: 0.00001410
Iteration 77/1000 | Loss: 0.00001410
Iteration 78/1000 | Loss: 0.00001410
Iteration 79/1000 | Loss: 0.00001409
Iteration 80/1000 | Loss: 0.00001409
Iteration 81/1000 | Loss: 0.00001408
Iteration 82/1000 | Loss: 0.00001406
Iteration 83/1000 | Loss: 0.00001406
Iteration 84/1000 | Loss: 0.00001406
Iteration 85/1000 | Loss: 0.00001406
Iteration 86/1000 | Loss: 0.00001406
Iteration 87/1000 | Loss: 0.00001406
Iteration 88/1000 | Loss: 0.00001406
Iteration 89/1000 | Loss: 0.00001406
Iteration 90/1000 | Loss: 0.00001406
Iteration 91/1000 | Loss: 0.00001406
Iteration 92/1000 | Loss: 0.00001406
Iteration 93/1000 | Loss: 0.00001406
Iteration 94/1000 | Loss: 0.00001405
Iteration 95/1000 | Loss: 0.00001405
Iteration 96/1000 | Loss: 0.00001405
Iteration 97/1000 | Loss: 0.00001405
Iteration 98/1000 | Loss: 0.00001404
Iteration 99/1000 | Loss: 0.00001404
Iteration 100/1000 | Loss: 0.00001404
Iteration 101/1000 | Loss: 0.00001404
Iteration 102/1000 | Loss: 0.00001404
Iteration 103/1000 | Loss: 0.00001404
Iteration 104/1000 | Loss: 0.00001404
Iteration 105/1000 | Loss: 0.00001404
Iteration 106/1000 | Loss: 0.00001404
Iteration 107/1000 | Loss: 0.00001404
Iteration 108/1000 | Loss: 0.00001403
Iteration 109/1000 | Loss: 0.00001403
Iteration 110/1000 | Loss: 0.00001403
Iteration 111/1000 | Loss: 0.00001402
Iteration 112/1000 | Loss: 0.00001402
Iteration 113/1000 | Loss: 0.00001402
Iteration 114/1000 | Loss: 0.00001402
Iteration 115/1000 | Loss: 0.00001402
Iteration 116/1000 | Loss: 0.00001402
Iteration 117/1000 | Loss: 0.00001401
Iteration 118/1000 | Loss: 0.00001401
Iteration 119/1000 | Loss: 0.00001401
Iteration 120/1000 | Loss: 0.00001401
Iteration 121/1000 | Loss: 0.00001400
Iteration 122/1000 | Loss: 0.00001400
Iteration 123/1000 | Loss: 0.00001400
Iteration 124/1000 | Loss: 0.00001399
Iteration 125/1000 | Loss: 0.00001399
Iteration 126/1000 | Loss: 0.00001399
Iteration 127/1000 | Loss: 0.00001399
Iteration 128/1000 | Loss: 0.00001399
Iteration 129/1000 | Loss: 0.00001398
Iteration 130/1000 | Loss: 0.00001398
Iteration 131/1000 | Loss: 0.00001397
Iteration 132/1000 | Loss: 0.00001397
Iteration 133/1000 | Loss: 0.00001397
Iteration 134/1000 | Loss: 0.00001397
Iteration 135/1000 | Loss: 0.00001397
Iteration 136/1000 | Loss: 0.00001397
Iteration 137/1000 | Loss: 0.00001396
Iteration 138/1000 | Loss: 0.00001396
Iteration 139/1000 | Loss: 0.00001396
Iteration 140/1000 | Loss: 0.00001396
Iteration 141/1000 | Loss: 0.00001396
Iteration 142/1000 | Loss: 0.00001396
Iteration 143/1000 | Loss: 0.00001396
Iteration 144/1000 | Loss: 0.00001396
Iteration 145/1000 | Loss: 0.00001396
Iteration 146/1000 | Loss: 0.00001395
Iteration 147/1000 | Loss: 0.00001395
Iteration 148/1000 | Loss: 0.00001395
Iteration 149/1000 | Loss: 0.00001395
Iteration 150/1000 | Loss: 0.00001395
Iteration 151/1000 | Loss: 0.00001395
Iteration 152/1000 | Loss: 0.00001395
Iteration 153/1000 | Loss: 0.00001395
Iteration 154/1000 | Loss: 0.00001394
Iteration 155/1000 | Loss: 0.00001394
Iteration 156/1000 | Loss: 0.00001394
Iteration 157/1000 | Loss: 0.00001394
Iteration 158/1000 | Loss: 0.00001394
Iteration 159/1000 | Loss: 0.00001394
Iteration 160/1000 | Loss: 0.00001394
Iteration 161/1000 | Loss: 0.00001394
Iteration 162/1000 | Loss: 0.00001394
Iteration 163/1000 | Loss: 0.00001394
Iteration 164/1000 | Loss: 0.00001394
Iteration 165/1000 | Loss: 0.00001394
Iteration 166/1000 | Loss: 0.00001394
Iteration 167/1000 | Loss: 0.00001394
Iteration 168/1000 | Loss: 0.00001394
Iteration 169/1000 | Loss: 0.00001394
Iteration 170/1000 | Loss: 0.00001394
Iteration 171/1000 | Loss: 0.00001394
Iteration 172/1000 | Loss: 0.00001394
Iteration 173/1000 | Loss: 0.00001394
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 173. Stopping optimization.
Last 5 losses: [1.3936496543465182e-05, 1.3936496543465182e-05, 1.3936496543465182e-05, 1.3936496543465182e-05, 1.3936496543465182e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3936496543465182e-05

Optimization complete. Final v2v error: 2.9918315410614014 mm

Highest mean error: 5.1913533210754395 mm for frame 75

Lowest mean error: 2.381249189376831 mm for frame 110

Saving results

Total time: 40.69869637489319
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00499167
Iteration 2/25 | Loss: 0.00099545
Iteration 3/25 | Loss: 0.00088513
Iteration 4/25 | Loss: 0.00085860
Iteration 5/25 | Loss: 0.00085479
Iteration 6/25 | Loss: 0.00085357
Iteration 7/25 | Loss: 0.00085355
Iteration 8/25 | Loss: 0.00085355
Iteration 9/25 | Loss: 0.00085355
Iteration 10/25 | Loss: 0.00085355
Iteration 11/25 | Loss: 0.00085355
Iteration 12/25 | Loss: 0.00085355
Iteration 13/25 | Loss: 0.00085355
Iteration 14/25 | Loss: 0.00085355
Iteration 15/25 | Loss: 0.00085355
Iteration 16/25 | Loss: 0.00085355
Iteration 17/25 | Loss: 0.00085355
Iteration 18/25 | Loss: 0.00085355
Iteration 19/25 | Loss: 0.00085355
Iteration 20/25 | Loss: 0.00085355
Iteration 21/25 | Loss: 0.00085355
Iteration 22/25 | Loss: 0.00085355
Iteration 23/25 | Loss: 0.00085355
Iteration 24/25 | Loss: 0.00085355
Iteration 25/25 | Loss: 0.00085355

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54124558
Iteration 2/25 | Loss: 0.00112893
Iteration 3/25 | Loss: 0.00112892
Iteration 4/25 | Loss: 0.00112892
Iteration 5/25 | Loss: 0.00112892
Iteration 6/25 | Loss: 0.00112892
Iteration 7/25 | Loss: 0.00112892
Iteration 8/25 | Loss: 0.00112892
Iteration 9/25 | Loss: 0.00112892
Iteration 10/25 | Loss: 0.00112892
Iteration 11/25 | Loss: 0.00112892
Iteration 12/25 | Loss: 0.00112891
Iteration 13/25 | Loss: 0.00112891
Iteration 14/25 | Loss: 0.00112891
Iteration 15/25 | Loss: 0.00112891
Iteration 16/25 | Loss: 0.00112891
Iteration 17/25 | Loss: 0.00112891
Iteration 18/25 | Loss: 0.00112891
Iteration 19/25 | Loss: 0.00112891
Iteration 20/25 | Loss: 0.00112891
Iteration 21/25 | Loss: 0.00112891
Iteration 22/25 | Loss: 0.00112891
Iteration 23/25 | Loss: 0.00112892
Iteration 24/25 | Loss: 0.00112891
Iteration 25/25 | Loss: 0.00112891

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112891
Iteration 2/1000 | Loss: 0.00007069
Iteration 3/1000 | Loss: 0.00004106
Iteration 4/1000 | Loss: 0.00003649
Iteration 5/1000 | Loss: 0.00003458
Iteration 6/1000 | Loss: 0.00003356
Iteration 7/1000 | Loss: 0.00003283
Iteration 8/1000 | Loss: 0.00003221
Iteration 9/1000 | Loss: 0.00003185
Iteration 10/1000 | Loss: 0.00003153
Iteration 11/1000 | Loss: 0.00003133
Iteration 12/1000 | Loss: 0.00003112
Iteration 13/1000 | Loss: 0.00003106
Iteration 14/1000 | Loss: 0.00003104
Iteration 15/1000 | Loss: 0.00003104
Iteration 16/1000 | Loss: 0.00003101
Iteration 17/1000 | Loss: 0.00003100
Iteration 18/1000 | Loss: 0.00003094
Iteration 19/1000 | Loss: 0.00003093
Iteration 20/1000 | Loss: 0.00003089
Iteration 21/1000 | Loss: 0.00003082
Iteration 22/1000 | Loss: 0.00003075
Iteration 23/1000 | Loss: 0.00003075
Iteration 24/1000 | Loss: 0.00003075
Iteration 25/1000 | Loss: 0.00003075
Iteration 26/1000 | Loss: 0.00003075
Iteration 27/1000 | Loss: 0.00003075
Iteration 28/1000 | Loss: 0.00003075
Iteration 29/1000 | Loss: 0.00003075
Iteration 30/1000 | Loss: 0.00003075
Iteration 31/1000 | Loss: 0.00003074
Iteration 32/1000 | Loss: 0.00003074
Iteration 33/1000 | Loss: 0.00003074
Iteration 34/1000 | Loss: 0.00003073
Iteration 35/1000 | Loss: 0.00003071
Iteration 36/1000 | Loss: 0.00003071
Iteration 37/1000 | Loss: 0.00003070
Iteration 38/1000 | Loss: 0.00003070
Iteration 39/1000 | Loss: 0.00003070
Iteration 40/1000 | Loss: 0.00003069
Iteration 41/1000 | Loss: 0.00003069
Iteration 42/1000 | Loss: 0.00003068
Iteration 43/1000 | Loss: 0.00003067
Iteration 44/1000 | Loss: 0.00003067
Iteration 45/1000 | Loss: 0.00003067
Iteration 46/1000 | Loss: 0.00003067
Iteration 47/1000 | Loss: 0.00003067
Iteration 48/1000 | Loss: 0.00003067
Iteration 49/1000 | Loss: 0.00003067
Iteration 50/1000 | Loss: 0.00003067
Iteration 51/1000 | Loss: 0.00003067
Iteration 52/1000 | Loss: 0.00003066
Iteration 53/1000 | Loss: 0.00003066
Iteration 54/1000 | Loss: 0.00003066
Iteration 55/1000 | Loss: 0.00003065
Iteration 56/1000 | Loss: 0.00003064
Iteration 57/1000 | Loss: 0.00003064
Iteration 58/1000 | Loss: 0.00003064
Iteration 59/1000 | Loss: 0.00003064
Iteration 60/1000 | Loss: 0.00003063
Iteration 61/1000 | Loss: 0.00003063
Iteration 62/1000 | Loss: 0.00003063
Iteration 63/1000 | Loss: 0.00003063
Iteration 64/1000 | Loss: 0.00003063
Iteration 65/1000 | Loss: 0.00003063
Iteration 66/1000 | Loss: 0.00003063
Iteration 67/1000 | Loss: 0.00003063
Iteration 68/1000 | Loss: 0.00003063
Iteration 69/1000 | Loss: 0.00003063
Iteration 70/1000 | Loss: 0.00003062
Iteration 71/1000 | Loss: 0.00003062
Iteration 72/1000 | Loss: 0.00003061
Iteration 73/1000 | Loss: 0.00003061
Iteration 74/1000 | Loss: 0.00003061
Iteration 75/1000 | Loss: 0.00003061
Iteration 76/1000 | Loss: 0.00003061
Iteration 77/1000 | Loss: 0.00003061
Iteration 78/1000 | Loss: 0.00003061
Iteration 79/1000 | Loss: 0.00003061
Iteration 80/1000 | Loss: 0.00003061
Iteration 81/1000 | Loss: 0.00003061
Iteration 82/1000 | Loss: 0.00003060
Iteration 83/1000 | Loss: 0.00003060
Iteration 84/1000 | Loss: 0.00003060
Iteration 85/1000 | Loss: 0.00003059
Iteration 86/1000 | Loss: 0.00003059
Iteration 87/1000 | Loss: 0.00003059
Iteration 88/1000 | Loss: 0.00003059
Iteration 89/1000 | Loss: 0.00003059
Iteration 90/1000 | Loss: 0.00003059
Iteration 91/1000 | Loss: 0.00003058
Iteration 92/1000 | Loss: 0.00003058
Iteration 93/1000 | Loss: 0.00003058
Iteration 94/1000 | Loss: 0.00003058
Iteration 95/1000 | Loss: 0.00003058
Iteration 96/1000 | Loss: 0.00003058
Iteration 97/1000 | Loss: 0.00003058
Iteration 98/1000 | Loss: 0.00003058
Iteration 99/1000 | Loss: 0.00003057
Iteration 100/1000 | Loss: 0.00003057
Iteration 101/1000 | Loss: 0.00003057
Iteration 102/1000 | Loss: 0.00003057
Iteration 103/1000 | Loss: 0.00003057
Iteration 104/1000 | Loss: 0.00003057
Iteration 105/1000 | Loss: 0.00003057
Iteration 106/1000 | Loss: 0.00003057
Iteration 107/1000 | Loss: 0.00003057
Iteration 108/1000 | Loss: 0.00003057
Iteration 109/1000 | Loss: 0.00003057
Iteration 110/1000 | Loss: 0.00003057
Iteration 111/1000 | Loss: 0.00003057
Iteration 112/1000 | Loss: 0.00003057
Iteration 113/1000 | Loss: 0.00003057
Iteration 114/1000 | Loss: 0.00003057
Iteration 115/1000 | Loss: 0.00003057
Iteration 116/1000 | Loss: 0.00003057
Iteration 117/1000 | Loss: 0.00003057
Iteration 118/1000 | Loss: 0.00003057
Iteration 119/1000 | Loss: 0.00003057
Iteration 120/1000 | Loss: 0.00003057
Iteration 121/1000 | Loss: 0.00003057
Iteration 122/1000 | Loss: 0.00003057
Iteration 123/1000 | Loss: 0.00003057
Iteration 124/1000 | Loss: 0.00003057
Iteration 125/1000 | Loss: 0.00003057
Iteration 126/1000 | Loss: 0.00003057
Iteration 127/1000 | Loss: 0.00003057
Iteration 128/1000 | Loss: 0.00003057
Iteration 129/1000 | Loss: 0.00003057
Iteration 130/1000 | Loss: 0.00003057
Iteration 131/1000 | Loss: 0.00003057
Iteration 132/1000 | Loss: 0.00003057
Iteration 133/1000 | Loss: 0.00003057
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 133. Stopping optimization.
Last 5 losses: [3.0565119232051075e-05, 3.0565119232051075e-05, 3.0565119232051075e-05, 3.0565119232051075e-05, 3.0565119232051075e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.0565119232051075e-05

Optimization complete. Final v2v error: 4.351160526275635 mm

Highest mean error: 5.50551700592041 mm for frame 78

Lowest mean error: 3.715928554534912 mm for frame 111

Saving results

Total time: 39.58592987060547
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1061/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1061.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1061
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00439122
Iteration 2/25 | Loss: 0.00094519
Iteration 3/25 | Loss: 0.00079637
Iteration 4/25 | Loss: 0.00077813
Iteration 5/25 | Loss: 0.00077068
Iteration 6/25 | Loss: 0.00076887
Iteration 7/25 | Loss: 0.00076837
Iteration 8/25 | Loss: 0.00076837
Iteration 9/25 | Loss: 0.00076837
Iteration 10/25 | Loss: 0.00076837
Iteration 11/25 | Loss: 0.00076837
Iteration 12/25 | Loss: 0.00076837
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007683697622269392, 0.0007683697622269392, 0.0007683697622269392, 0.0007683697622269392, 0.0007683697622269392]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007683697622269392

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.58640289
Iteration 2/25 | Loss: 0.00120141
Iteration 3/25 | Loss: 0.00120138
Iteration 4/25 | Loss: 0.00120138
Iteration 5/25 | Loss: 0.00120138
Iteration 6/25 | Loss: 0.00120138
Iteration 7/25 | Loss: 0.00120138
Iteration 8/25 | Loss: 0.00120138
Iteration 9/25 | Loss: 0.00120138
Iteration 10/25 | Loss: 0.00120138
Iteration 11/25 | Loss: 0.00120138
Iteration 12/25 | Loss: 0.00120138
Iteration 13/25 | Loss: 0.00120138
Iteration 14/25 | Loss: 0.00120138
Iteration 15/25 | Loss: 0.00120138
Iteration 16/25 | Loss: 0.00120138
Iteration 17/25 | Loss: 0.00120138
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001201382139697671, 0.001201382139697671, 0.001201382139697671, 0.001201382139697671, 0.001201382139697671]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001201382139697671

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00120138
Iteration 2/1000 | Loss: 0.00002707
Iteration 3/1000 | Loss: 0.00002011
Iteration 4/1000 | Loss: 0.00001876
Iteration 5/1000 | Loss: 0.00001781
Iteration 6/1000 | Loss: 0.00001735
Iteration 7/1000 | Loss: 0.00001700
Iteration 8/1000 | Loss: 0.00001678
Iteration 9/1000 | Loss: 0.00001672
Iteration 10/1000 | Loss: 0.00001661
Iteration 11/1000 | Loss: 0.00001655
Iteration 12/1000 | Loss: 0.00001654
Iteration 13/1000 | Loss: 0.00001653
Iteration 14/1000 | Loss: 0.00001648
Iteration 15/1000 | Loss: 0.00001644
Iteration 16/1000 | Loss: 0.00001639
Iteration 17/1000 | Loss: 0.00001636
Iteration 18/1000 | Loss: 0.00001636
Iteration 19/1000 | Loss: 0.00001635
Iteration 20/1000 | Loss: 0.00001635
Iteration 21/1000 | Loss: 0.00001635
Iteration 22/1000 | Loss: 0.00001635
Iteration 23/1000 | Loss: 0.00001635
Iteration 24/1000 | Loss: 0.00001635
Iteration 25/1000 | Loss: 0.00001633
Iteration 26/1000 | Loss: 0.00001632
Iteration 27/1000 | Loss: 0.00001632
Iteration 28/1000 | Loss: 0.00001632
Iteration 29/1000 | Loss: 0.00001632
Iteration 30/1000 | Loss: 0.00001632
Iteration 31/1000 | Loss: 0.00001632
Iteration 32/1000 | Loss: 0.00001631
Iteration 33/1000 | Loss: 0.00001631
Iteration 34/1000 | Loss: 0.00001631
Iteration 35/1000 | Loss: 0.00001631
Iteration 36/1000 | Loss: 0.00001631
Iteration 37/1000 | Loss: 0.00001630
Iteration 38/1000 | Loss: 0.00001630
Iteration 39/1000 | Loss: 0.00001630
Iteration 40/1000 | Loss: 0.00001630
Iteration 41/1000 | Loss: 0.00001630
Iteration 42/1000 | Loss: 0.00001630
Iteration 43/1000 | Loss: 0.00001629
Iteration 44/1000 | Loss: 0.00001629
Iteration 45/1000 | Loss: 0.00001629
Iteration 46/1000 | Loss: 0.00001629
Iteration 47/1000 | Loss: 0.00001629
Iteration 48/1000 | Loss: 0.00001629
Iteration 49/1000 | Loss: 0.00001629
Iteration 50/1000 | Loss: 0.00001629
Iteration 51/1000 | Loss: 0.00001629
Iteration 52/1000 | Loss: 0.00001629
Iteration 53/1000 | Loss: 0.00001629
Iteration 54/1000 | Loss: 0.00001628
Iteration 55/1000 | Loss: 0.00001628
Iteration 56/1000 | Loss: 0.00001628
Iteration 57/1000 | Loss: 0.00001627
Iteration 58/1000 | Loss: 0.00001627
Iteration 59/1000 | Loss: 0.00001626
Iteration 60/1000 | Loss: 0.00001626
Iteration 61/1000 | Loss: 0.00001626
Iteration 62/1000 | Loss: 0.00001626
Iteration 63/1000 | Loss: 0.00001626
Iteration 64/1000 | Loss: 0.00001625
Iteration 65/1000 | Loss: 0.00001625
Iteration 66/1000 | Loss: 0.00001625
Iteration 67/1000 | Loss: 0.00001624
Iteration 68/1000 | Loss: 0.00001624
Iteration 69/1000 | Loss: 0.00001624
Iteration 70/1000 | Loss: 0.00001624
Iteration 71/1000 | Loss: 0.00001623
Iteration 72/1000 | Loss: 0.00001623
Iteration 73/1000 | Loss: 0.00001623
Iteration 74/1000 | Loss: 0.00001623
Iteration 75/1000 | Loss: 0.00001622
Iteration 76/1000 | Loss: 0.00001622
Iteration 77/1000 | Loss: 0.00001622
Iteration 78/1000 | Loss: 0.00001622
Iteration 79/1000 | Loss: 0.00001621
Iteration 80/1000 | Loss: 0.00001621
Iteration 81/1000 | Loss: 0.00001621
Iteration 82/1000 | Loss: 0.00001620
Iteration 83/1000 | Loss: 0.00001620
Iteration 84/1000 | Loss: 0.00001619
Iteration 85/1000 | Loss: 0.00001619
Iteration 86/1000 | Loss: 0.00001618
Iteration 87/1000 | Loss: 0.00001618
Iteration 88/1000 | Loss: 0.00001617
Iteration 89/1000 | Loss: 0.00001617
Iteration 90/1000 | Loss: 0.00001617
Iteration 91/1000 | Loss: 0.00001617
Iteration 92/1000 | Loss: 0.00001617
Iteration 93/1000 | Loss: 0.00001617
Iteration 94/1000 | Loss: 0.00001617
Iteration 95/1000 | Loss: 0.00001615
Iteration 96/1000 | Loss: 0.00001615
Iteration 97/1000 | Loss: 0.00001615
Iteration 98/1000 | Loss: 0.00001614
Iteration 99/1000 | Loss: 0.00001614
Iteration 100/1000 | Loss: 0.00001614
Iteration 101/1000 | Loss: 0.00001614
Iteration 102/1000 | Loss: 0.00001613
Iteration 103/1000 | Loss: 0.00001613
Iteration 104/1000 | Loss: 0.00001612
Iteration 105/1000 | Loss: 0.00001612
Iteration 106/1000 | Loss: 0.00001611
Iteration 107/1000 | Loss: 0.00001611
Iteration 108/1000 | Loss: 0.00001611
Iteration 109/1000 | Loss: 0.00001611
Iteration 110/1000 | Loss: 0.00001611
Iteration 111/1000 | Loss: 0.00001610
Iteration 112/1000 | Loss: 0.00001610
Iteration 113/1000 | Loss: 0.00001610
Iteration 114/1000 | Loss: 0.00001609
Iteration 115/1000 | Loss: 0.00001609
Iteration 116/1000 | Loss: 0.00001609
Iteration 117/1000 | Loss: 0.00001609
Iteration 118/1000 | Loss: 0.00001609
Iteration 119/1000 | Loss: 0.00001609
Iteration 120/1000 | Loss: 0.00001609
Iteration 121/1000 | Loss: 0.00001609
Iteration 122/1000 | Loss: 0.00001608
Iteration 123/1000 | Loss: 0.00001608
Iteration 124/1000 | Loss: 0.00001608
Iteration 125/1000 | Loss: 0.00001608
Iteration 126/1000 | Loss: 0.00001608
Iteration 127/1000 | Loss: 0.00001608
Iteration 128/1000 | Loss: 0.00001608
Iteration 129/1000 | Loss: 0.00001608
Iteration 130/1000 | Loss: 0.00001608
Iteration 131/1000 | Loss: 0.00001608
Iteration 132/1000 | Loss: 0.00001608
Iteration 133/1000 | Loss: 0.00001607
Iteration 134/1000 | Loss: 0.00001607
Iteration 135/1000 | Loss: 0.00001607
Iteration 136/1000 | Loss: 0.00001607
Iteration 137/1000 | Loss: 0.00001607
Iteration 138/1000 | Loss: 0.00001607
Iteration 139/1000 | Loss: 0.00001607
Iteration 140/1000 | Loss: 0.00001607
Iteration 141/1000 | Loss: 0.00001607
Iteration 142/1000 | Loss: 0.00001607
Iteration 143/1000 | Loss: 0.00001607
Iteration 144/1000 | Loss: 0.00001607
Iteration 145/1000 | Loss: 0.00001607
Iteration 146/1000 | Loss: 0.00001607
Iteration 147/1000 | Loss: 0.00001607
Iteration 148/1000 | Loss: 0.00001607
Iteration 149/1000 | Loss: 0.00001606
Iteration 150/1000 | Loss: 0.00001606
Iteration 151/1000 | Loss: 0.00001606
Iteration 152/1000 | Loss: 0.00001606
Iteration 153/1000 | Loss: 0.00001606
Iteration 154/1000 | Loss: 0.00001606
Iteration 155/1000 | Loss: 0.00001606
Iteration 156/1000 | Loss: 0.00001606
Iteration 157/1000 | Loss: 0.00001606
Iteration 158/1000 | Loss: 0.00001606
Iteration 159/1000 | Loss: 0.00001606
Iteration 160/1000 | Loss: 0.00001606
Iteration 161/1000 | Loss: 0.00001606
Iteration 162/1000 | Loss: 0.00001606
Iteration 163/1000 | Loss: 0.00001606
Iteration 164/1000 | Loss: 0.00001606
Iteration 165/1000 | Loss: 0.00001606
Iteration 166/1000 | Loss: 0.00001606
Iteration 167/1000 | Loss: 0.00001605
Iteration 168/1000 | Loss: 0.00001605
Iteration 169/1000 | Loss: 0.00001605
Iteration 170/1000 | Loss: 0.00001605
Iteration 171/1000 | Loss: 0.00001605
Iteration 172/1000 | Loss: 0.00001605
Iteration 173/1000 | Loss: 0.00001605
Iteration 174/1000 | Loss: 0.00001605
Iteration 175/1000 | Loss: 0.00001605
Iteration 176/1000 | Loss: 0.00001605
Iteration 177/1000 | Loss: 0.00001605
Iteration 178/1000 | Loss: 0.00001605
Iteration 179/1000 | Loss: 0.00001605
Iteration 180/1000 | Loss: 0.00001605
Iteration 181/1000 | Loss: 0.00001605
Iteration 182/1000 | Loss: 0.00001605
Iteration 183/1000 | Loss: 0.00001605
Iteration 184/1000 | Loss: 0.00001604
Iteration 185/1000 | Loss: 0.00001604
Iteration 186/1000 | Loss: 0.00001604
Iteration 187/1000 | Loss: 0.00001604
Iteration 188/1000 | Loss: 0.00001604
Iteration 189/1000 | Loss: 0.00001604
Iteration 190/1000 | Loss: 0.00001604
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 190. Stopping optimization.
Last 5 losses: [1.6044419680838473e-05, 1.6044419680838473e-05, 1.6044419680838473e-05, 1.6044419680838473e-05, 1.6044419680838473e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6044419680838473e-05

Optimization complete. Final v2v error: 3.362929582595825 mm

Highest mean error: 3.8462817668914795 mm for frame 107

Lowest mean error: 3.16463565826416 mm for frame 59

Saving results

Total time: 38.99724292755127
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00404589
Iteration 2/25 | Loss: 0.00090517
Iteration 3/25 | Loss: 0.00078494
Iteration 4/25 | Loss: 0.00076611
Iteration 5/25 | Loss: 0.00076274
Iteration 6/25 | Loss: 0.00076162
Iteration 7/25 | Loss: 0.00076139
Iteration 8/25 | Loss: 0.00076139
Iteration 9/25 | Loss: 0.00076139
Iteration 10/25 | Loss: 0.00076139
Iteration 11/25 | Loss: 0.00076139
Iteration 12/25 | Loss: 0.00076139
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007613886264152825, 0.0007613886264152825, 0.0007613886264152825, 0.0007613886264152825, 0.0007613886264152825]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007613886264152825

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64312100
Iteration 2/25 | Loss: 0.00128386
Iteration 3/25 | Loss: 0.00128386
Iteration 4/25 | Loss: 0.00128386
Iteration 5/25 | Loss: 0.00128385
Iteration 6/25 | Loss: 0.00128385
Iteration 7/25 | Loss: 0.00128385
Iteration 8/25 | Loss: 0.00128385
Iteration 9/25 | Loss: 0.00128385
Iteration 10/25 | Loss: 0.00128385
Iteration 11/25 | Loss: 0.00128385
Iteration 12/25 | Loss: 0.00128385
Iteration 13/25 | Loss: 0.00128385
Iteration 14/25 | Loss: 0.00128385
Iteration 15/25 | Loss: 0.00128385
Iteration 16/25 | Loss: 0.00128385
Iteration 17/25 | Loss: 0.00128385
Iteration 18/25 | Loss: 0.00128385
Iteration 19/25 | Loss: 0.00128385
Iteration 20/25 | Loss: 0.00128385
Iteration 21/25 | Loss: 0.00128385
Iteration 22/25 | Loss: 0.00128385
Iteration 23/25 | Loss: 0.00128385
Iteration 24/25 | Loss: 0.00128385
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0012838522670790553, 0.0012838522670790553, 0.0012838522670790553, 0.0012838522670790553, 0.0012838522670790553]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012838522670790553

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00128385
Iteration 2/1000 | Loss: 0.00002852
Iteration 3/1000 | Loss: 0.00001826
Iteration 4/1000 | Loss: 0.00001654
Iteration 5/1000 | Loss: 0.00001576
Iteration 6/1000 | Loss: 0.00001530
Iteration 7/1000 | Loss: 0.00001502
Iteration 8/1000 | Loss: 0.00001476
Iteration 9/1000 | Loss: 0.00001460
Iteration 10/1000 | Loss: 0.00001458
Iteration 11/1000 | Loss: 0.00001451
Iteration 12/1000 | Loss: 0.00001450
Iteration 13/1000 | Loss: 0.00001444
Iteration 14/1000 | Loss: 0.00001441
Iteration 15/1000 | Loss: 0.00001440
Iteration 16/1000 | Loss: 0.00001440
Iteration 17/1000 | Loss: 0.00001440
Iteration 18/1000 | Loss: 0.00001439
Iteration 19/1000 | Loss: 0.00001437
Iteration 20/1000 | Loss: 0.00001436
Iteration 21/1000 | Loss: 0.00001436
Iteration 22/1000 | Loss: 0.00001433
Iteration 23/1000 | Loss: 0.00001433
Iteration 24/1000 | Loss: 0.00001430
Iteration 25/1000 | Loss: 0.00001429
Iteration 26/1000 | Loss: 0.00001429
Iteration 27/1000 | Loss: 0.00001429
Iteration 28/1000 | Loss: 0.00001429
Iteration 29/1000 | Loss: 0.00001429
Iteration 30/1000 | Loss: 0.00001429
Iteration 31/1000 | Loss: 0.00001429
Iteration 32/1000 | Loss: 0.00001429
Iteration 33/1000 | Loss: 0.00001429
Iteration 34/1000 | Loss: 0.00001428
Iteration 35/1000 | Loss: 0.00001428
Iteration 36/1000 | Loss: 0.00001428
Iteration 37/1000 | Loss: 0.00001428
Iteration 38/1000 | Loss: 0.00001427
Iteration 39/1000 | Loss: 0.00001427
Iteration 40/1000 | Loss: 0.00001427
Iteration 41/1000 | Loss: 0.00001426
Iteration 42/1000 | Loss: 0.00001426
Iteration 43/1000 | Loss: 0.00001426
Iteration 44/1000 | Loss: 0.00001426
Iteration 45/1000 | Loss: 0.00001426
Iteration 46/1000 | Loss: 0.00001426
Iteration 47/1000 | Loss: 0.00001425
Iteration 48/1000 | Loss: 0.00001425
Iteration 49/1000 | Loss: 0.00001425
Iteration 50/1000 | Loss: 0.00001425
Iteration 51/1000 | Loss: 0.00001424
Iteration 52/1000 | Loss: 0.00001424
Iteration 53/1000 | Loss: 0.00001423
Iteration 54/1000 | Loss: 0.00001423
Iteration 55/1000 | Loss: 0.00001423
Iteration 56/1000 | Loss: 0.00001423
Iteration 57/1000 | Loss: 0.00001423
Iteration 58/1000 | Loss: 0.00001423
Iteration 59/1000 | Loss: 0.00001423
Iteration 60/1000 | Loss: 0.00001423
Iteration 61/1000 | Loss: 0.00001422
Iteration 62/1000 | Loss: 0.00001422
Iteration 63/1000 | Loss: 0.00001422
Iteration 64/1000 | Loss: 0.00001422
Iteration 65/1000 | Loss: 0.00001422
Iteration 66/1000 | Loss: 0.00001422
Iteration 67/1000 | Loss: 0.00001422
Iteration 68/1000 | Loss: 0.00001421
Iteration 69/1000 | Loss: 0.00001421
Iteration 70/1000 | Loss: 0.00001421
Iteration 71/1000 | Loss: 0.00001421
Iteration 72/1000 | Loss: 0.00001421
Iteration 73/1000 | Loss: 0.00001421
Iteration 74/1000 | Loss: 0.00001421
Iteration 75/1000 | Loss: 0.00001421
Iteration 76/1000 | Loss: 0.00001421
Iteration 77/1000 | Loss: 0.00001421
Iteration 78/1000 | Loss: 0.00001421
Iteration 79/1000 | Loss: 0.00001421
Iteration 80/1000 | Loss: 0.00001420
Iteration 81/1000 | Loss: 0.00001420
Iteration 82/1000 | Loss: 0.00001420
Iteration 83/1000 | Loss: 0.00001420
Iteration 84/1000 | Loss: 0.00001420
Iteration 85/1000 | Loss: 0.00001420
Iteration 86/1000 | Loss: 0.00001420
Iteration 87/1000 | Loss: 0.00001420
Iteration 88/1000 | Loss: 0.00001420
Iteration 89/1000 | Loss: 0.00001420
Iteration 90/1000 | Loss: 0.00001419
Iteration 91/1000 | Loss: 0.00001419
Iteration 92/1000 | Loss: 0.00001419
Iteration 93/1000 | Loss: 0.00001418
Iteration 94/1000 | Loss: 0.00001418
Iteration 95/1000 | Loss: 0.00001418
Iteration 96/1000 | Loss: 0.00001417
Iteration 97/1000 | Loss: 0.00001417
Iteration 98/1000 | Loss: 0.00001417
Iteration 99/1000 | Loss: 0.00001416
Iteration 100/1000 | Loss: 0.00001416
Iteration 101/1000 | Loss: 0.00001416
Iteration 102/1000 | Loss: 0.00001416
Iteration 103/1000 | Loss: 0.00001416
Iteration 104/1000 | Loss: 0.00001416
Iteration 105/1000 | Loss: 0.00001416
Iteration 106/1000 | Loss: 0.00001416
Iteration 107/1000 | Loss: 0.00001416
Iteration 108/1000 | Loss: 0.00001416
Iteration 109/1000 | Loss: 0.00001415
Iteration 110/1000 | Loss: 0.00001415
Iteration 111/1000 | Loss: 0.00001415
Iteration 112/1000 | Loss: 0.00001415
Iteration 113/1000 | Loss: 0.00001415
Iteration 114/1000 | Loss: 0.00001414
Iteration 115/1000 | Loss: 0.00001414
Iteration 116/1000 | Loss: 0.00001414
Iteration 117/1000 | Loss: 0.00001414
Iteration 118/1000 | Loss: 0.00001414
Iteration 119/1000 | Loss: 0.00001414
Iteration 120/1000 | Loss: 0.00001414
Iteration 121/1000 | Loss: 0.00001414
Iteration 122/1000 | Loss: 0.00001414
Iteration 123/1000 | Loss: 0.00001414
Iteration 124/1000 | Loss: 0.00001414
Iteration 125/1000 | Loss: 0.00001414
Iteration 126/1000 | Loss: 0.00001414
Iteration 127/1000 | Loss: 0.00001414
Iteration 128/1000 | Loss: 0.00001414
Iteration 129/1000 | Loss: 0.00001414
Iteration 130/1000 | Loss: 0.00001414
Iteration 131/1000 | Loss: 0.00001414
Iteration 132/1000 | Loss: 0.00001414
Iteration 133/1000 | Loss: 0.00001413
Iteration 134/1000 | Loss: 0.00001413
Iteration 135/1000 | Loss: 0.00001413
Iteration 136/1000 | Loss: 0.00001413
Iteration 137/1000 | Loss: 0.00001413
Iteration 138/1000 | Loss: 0.00001413
Iteration 139/1000 | Loss: 0.00001413
Iteration 140/1000 | Loss: 0.00001413
Iteration 141/1000 | Loss: 0.00001413
Iteration 142/1000 | Loss: 0.00001413
Iteration 143/1000 | Loss: 0.00001413
Iteration 144/1000 | Loss: 0.00001413
Iteration 145/1000 | Loss: 0.00001413
Iteration 146/1000 | Loss: 0.00001413
Iteration 147/1000 | Loss: 0.00001413
Iteration 148/1000 | Loss: 0.00001413
Iteration 149/1000 | Loss: 0.00001413
Iteration 150/1000 | Loss: 0.00001413
Iteration 151/1000 | Loss: 0.00001413
Iteration 152/1000 | Loss: 0.00001413
Iteration 153/1000 | Loss: 0.00001413
Iteration 154/1000 | Loss: 0.00001413
Iteration 155/1000 | Loss: 0.00001413
Iteration 156/1000 | Loss: 0.00001413
Iteration 157/1000 | Loss: 0.00001413
Iteration 158/1000 | Loss: 0.00001413
Iteration 159/1000 | Loss: 0.00001413
Iteration 160/1000 | Loss: 0.00001413
Iteration 161/1000 | Loss: 0.00001413
Iteration 162/1000 | Loss: 0.00001413
Iteration 163/1000 | Loss: 0.00001413
Iteration 164/1000 | Loss: 0.00001413
Iteration 165/1000 | Loss: 0.00001413
Iteration 166/1000 | Loss: 0.00001413
Iteration 167/1000 | Loss: 0.00001413
Iteration 168/1000 | Loss: 0.00001413
Iteration 169/1000 | Loss: 0.00001413
Iteration 170/1000 | Loss: 0.00001413
Iteration 171/1000 | Loss: 0.00001413
Iteration 172/1000 | Loss: 0.00001413
Iteration 173/1000 | Loss: 0.00001413
Iteration 174/1000 | Loss: 0.00001413
Iteration 175/1000 | Loss: 0.00001413
Iteration 176/1000 | Loss: 0.00001413
Iteration 177/1000 | Loss: 0.00001413
Iteration 178/1000 | Loss: 0.00001413
Iteration 179/1000 | Loss: 0.00001413
Iteration 180/1000 | Loss: 0.00001413
Iteration 181/1000 | Loss: 0.00001413
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.4128536349744536e-05, 1.4128536349744536e-05, 1.4128536349744536e-05, 1.4128536349744536e-05, 1.4128536349744536e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4128536349744536e-05

Optimization complete. Final v2v error: 3.195101261138916 mm

Highest mean error: 3.3672454357147217 mm for frame 44

Lowest mean error: 3.0745556354522705 mm for frame 21

Saving results

Total time: 35.18389821052551
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1082/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1082.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1082
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840340
Iteration 2/25 | Loss: 0.00142519
Iteration 3/25 | Loss: 0.00097466
Iteration 4/25 | Loss: 0.00091535
Iteration 5/25 | Loss: 0.00089462
Iteration 6/25 | Loss: 0.00088885
Iteration 7/25 | Loss: 0.00088705
Iteration 8/25 | Loss: 0.00088645
Iteration 9/25 | Loss: 0.00088645
Iteration 10/25 | Loss: 0.00088645
Iteration 11/25 | Loss: 0.00088645
Iteration 12/25 | Loss: 0.00088645
Iteration 13/25 | Loss: 0.00088645
Iteration 14/25 | Loss: 0.00088645
Iteration 15/25 | Loss: 0.00088645
Iteration 16/25 | Loss: 0.00088645
Iteration 17/25 | Loss: 0.00088645
Iteration 18/25 | Loss: 0.00088645
Iteration 19/25 | Loss: 0.00088645
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00088644924107939, 0.00088644924107939, 0.00088644924107939, 0.00088644924107939, 0.00088644924107939]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00088644924107939

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16769016
Iteration 2/25 | Loss: 0.00117567
Iteration 3/25 | Loss: 0.00117567
Iteration 4/25 | Loss: 0.00117567
Iteration 5/25 | Loss: 0.00117567
Iteration 6/25 | Loss: 0.00117567
Iteration 7/25 | Loss: 0.00117567
Iteration 8/25 | Loss: 0.00117567
Iteration 9/25 | Loss: 0.00117567
Iteration 10/25 | Loss: 0.00117567
Iteration 11/25 | Loss: 0.00117567
Iteration 12/25 | Loss: 0.00117567
Iteration 13/25 | Loss: 0.00117567
Iteration 14/25 | Loss: 0.00117567
Iteration 15/25 | Loss: 0.00117567
Iteration 16/25 | Loss: 0.00117567
Iteration 17/25 | Loss: 0.00117567
Iteration 18/25 | Loss: 0.00117567
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0011756651801988482, 0.0011756651801988482, 0.0011756651801988482, 0.0011756651801988482, 0.0011756651801988482]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011756651801988482

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00117567
Iteration 2/1000 | Loss: 0.00005809
Iteration 3/1000 | Loss: 0.00004510
Iteration 4/1000 | Loss: 0.00003909
Iteration 5/1000 | Loss: 0.00003657
Iteration 6/1000 | Loss: 0.00003492
Iteration 7/1000 | Loss: 0.00003402
Iteration 8/1000 | Loss: 0.00003313
Iteration 9/1000 | Loss: 0.00003233
Iteration 10/1000 | Loss: 0.00003187
Iteration 11/1000 | Loss: 0.00003149
Iteration 12/1000 | Loss: 0.00003109
Iteration 13/1000 | Loss: 0.00003064
Iteration 14/1000 | Loss: 0.00003028
Iteration 15/1000 | Loss: 0.00003004
Iteration 16/1000 | Loss: 0.00002983
Iteration 17/1000 | Loss: 0.00002977
Iteration 18/1000 | Loss: 0.00002971
Iteration 19/1000 | Loss: 0.00002970
Iteration 20/1000 | Loss: 0.00002957
Iteration 21/1000 | Loss: 0.00002942
Iteration 22/1000 | Loss: 0.00002935
Iteration 23/1000 | Loss: 0.00002934
Iteration 24/1000 | Loss: 0.00002932
Iteration 25/1000 | Loss: 0.00002931
Iteration 26/1000 | Loss: 0.00002929
Iteration 27/1000 | Loss: 0.00002929
Iteration 28/1000 | Loss: 0.00002928
Iteration 29/1000 | Loss: 0.00002928
Iteration 30/1000 | Loss: 0.00002927
Iteration 31/1000 | Loss: 0.00002927
Iteration 32/1000 | Loss: 0.00002926
Iteration 33/1000 | Loss: 0.00002925
Iteration 34/1000 | Loss: 0.00002925
Iteration 35/1000 | Loss: 0.00002925
Iteration 36/1000 | Loss: 0.00002925
Iteration 37/1000 | Loss: 0.00002925
Iteration 38/1000 | Loss: 0.00002925
Iteration 39/1000 | Loss: 0.00002925
Iteration 40/1000 | Loss: 0.00002924
Iteration 41/1000 | Loss: 0.00002924
Iteration 42/1000 | Loss: 0.00002924
Iteration 43/1000 | Loss: 0.00002923
Iteration 44/1000 | Loss: 0.00002923
Iteration 45/1000 | Loss: 0.00002923
Iteration 46/1000 | Loss: 0.00002922
Iteration 47/1000 | Loss: 0.00002922
Iteration 48/1000 | Loss: 0.00002922
Iteration 49/1000 | Loss: 0.00002921
Iteration 50/1000 | Loss: 0.00002921
Iteration 51/1000 | Loss: 0.00002921
Iteration 52/1000 | Loss: 0.00002921
Iteration 53/1000 | Loss: 0.00002921
Iteration 54/1000 | Loss: 0.00002920
Iteration 55/1000 | Loss: 0.00002920
Iteration 56/1000 | Loss: 0.00002919
Iteration 57/1000 | Loss: 0.00002919
Iteration 58/1000 | Loss: 0.00002919
Iteration 59/1000 | Loss: 0.00002918
Iteration 60/1000 | Loss: 0.00002918
Iteration 61/1000 | Loss: 0.00002918
Iteration 62/1000 | Loss: 0.00002917
Iteration 63/1000 | Loss: 0.00002917
Iteration 64/1000 | Loss: 0.00002917
Iteration 65/1000 | Loss: 0.00002917
Iteration 66/1000 | Loss: 0.00002916
Iteration 67/1000 | Loss: 0.00002916
Iteration 68/1000 | Loss: 0.00002916
Iteration 69/1000 | Loss: 0.00002916
Iteration 70/1000 | Loss: 0.00002915
Iteration 71/1000 | Loss: 0.00002915
Iteration 72/1000 | Loss: 0.00002915
Iteration 73/1000 | Loss: 0.00002915
Iteration 74/1000 | Loss: 0.00002914
Iteration 75/1000 | Loss: 0.00002914
Iteration 76/1000 | Loss: 0.00002913
Iteration 77/1000 | Loss: 0.00002913
Iteration 78/1000 | Loss: 0.00002912
Iteration 79/1000 | Loss: 0.00002912
Iteration 80/1000 | Loss: 0.00002912
Iteration 81/1000 | Loss: 0.00002911
Iteration 82/1000 | Loss: 0.00002911
Iteration 83/1000 | Loss: 0.00002910
Iteration 84/1000 | Loss: 0.00002910
Iteration 85/1000 | Loss: 0.00002910
Iteration 86/1000 | Loss: 0.00002909
Iteration 87/1000 | Loss: 0.00002909
Iteration 88/1000 | Loss: 0.00002908
Iteration 89/1000 | Loss: 0.00002908
Iteration 90/1000 | Loss: 0.00002907
Iteration 91/1000 | Loss: 0.00002906
Iteration 92/1000 | Loss: 0.00002906
Iteration 93/1000 | Loss: 0.00002906
Iteration 94/1000 | Loss: 0.00002906
Iteration 95/1000 | Loss: 0.00002906
Iteration 96/1000 | Loss: 0.00002906
Iteration 97/1000 | Loss: 0.00002906
Iteration 98/1000 | Loss: 0.00002906
Iteration 99/1000 | Loss: 0.00002906
Iteration 100/1000 | Loss: 0.00002906
Iteration 101/1000 | Loss: 0.00002906
Iteration 102/1000 | Loss: 0.00002906
Iteration 103/1000 | Loss: 0.00002905
Iteration 104/1000 | Loss: 0.00002905
Iteration 105/1000 | Loss: 0.00002905
Iteration 106/1000 | Loss: 0.00002905
Iteration 107/1000 | Loss: 0.00002904
Iteration 108/1000 | Loss: 0.00002904
Iteration 109/1000 | Loss: 0.00002904
Iteration 110/1000 | Loss: 0.00002903
Iteration 111/1000 | Loss: 0.00002903
Iteration 112/1000 | Loss: 0.00002903
Iteration 113/1000 | Loss: 0.00002903
Iteration 114/1000 | Loss: 0.00002902
Iteration 115/1000 | Loss: 0.00002902
Iteration 116/1000 | Loss: 0.00002902
Iteration 117/1000 | Loss: 0.00002902
Iteration 118/1000 | Loss: 0.00002902
Iteration 119/1000 | Loss: 0.00002902
Iteration 120/1000 | Loss: 0.00002902
Iteration 121/1000 | Loss: 0.00002901
Iteration 122/1000 | Loss: 0.00002901
Iteration 123/1000 | Loss: 0.00002901
Iteration 124/1000 | Loss: 0.00002901
Iteration 125/1000 | Loss: 0.00002900
Iteration 126/1000 | Loss: 0.00002900
Iteration 127/1000 | Loss: 0.00002900
Iteration 128/1000 | Loss: 0.00002900
Iteration 129/1000 | Loss: 0.00002900
Iteration 130/1000 | Loss: 0.00002900
Iteration 131/1000 | Loss: 0.00002900
Iteration 132/1000 | Loss: 0.00002899
Iteration 133/1000 | Loss: 0.00002899
Iteration 134/1000 | Loss: 0.00002898
Iteration 135/1000 | Loss: 0.00002898
Iteration 136/1000 | Loss: 0.00002898
Iteration 137/1000 | Loss: 0.00002898
Iteration 138/1000 | Loss: 0.00002897
Iteration 139/1000 | Loss: 0.00002897
Iteration 140/1000 | Loss: 0.00002896
Iteration 141/1000 | Loss: 0.00002896
Iteration 142/1000 | Loss: 0.00002896
Iteration 143/1000 | Loss: 0.00002895
Iteration 144/1000 | Loss: 0.00002895
Iteration 145/1000 | Loss: 0.00002895
Iteration 146/1000 | Loss: 0.00002895
Iteration 147/1000 | Loss: 0.00002895
Iteration 148/1000 | Loss: 0.00002895
Iteration 149/1000 | Loss: 0.00002894
Iteration 150/1000 | Loss: 0.00002894
Iteration 151/1000 | Loss: 0.00002893
Iteration 152/1000 | Loss: 0.00002893
Iteration 153/1000 | Loss: 0.00002893
Iteration 154/1000 | Loss: 0.00002893
Iteration 155/1000 | Loss: 0.00002893
Iteration 156/1000 | Loss: 0.00002893
Iteration 157/1000 | Loss: 0.00002893
Iteration 158/1000 | Loss: 0.00002893
Iteration 159/1000 | Loss: 0.00002893
Iteration 160/1000 | Loss: 0.00002893
Iteration 161/1000 | Loss: 0.00002893
Iteration 162/1000 | Loss: 0.00002893
Iteration 163/1000 | Loss: 0.00002893
Iteration 164/1000 | Loss: 0.00002893
Iteration 165/1000 | Loss: 0.00002892
Iteration 166/1000 | Loss: 0.00002892
Iteration 167/1000 | Loss: 0.00002892
Iteration 168/1000 | Loss: 0.00002892
Iteration 169/1000 | Loss: 0.00002892
Iteration 170/1000 | Loss: 0.00002892
Iteration 171/1000 | Loss: 0.00002892
Iteration 172/1000 | Loss: 0.00002892
Iteration 173/1000 | Loss: 0.00002892
Iteration 174/1000 | Loss: 0.00002892
Iteration 175/1000 | Loss: 0.00002892
Iteration 176/1000 | Loss: 0.00002891
Iteration 177/1000 | Loss: 0.00002891
Iteration 178/1000 | Loss: 0.00002891
Iteration 179/1000 | Loss: 0.00002891
Iteration 180/1000 | Loss: 0.00002891
Iteration 181/1000 | Loss: 0.00002891
Iteration 182/1000 | Loss: 0.00002891
Iteration 183/1000 | Loss: 0.00002891
Iteration 184/1000 | Loss: 0.00002891
Iteration 185/1000 | Loss: 0.00002891
Iteration 186/1000 | Loss: 0.00002891
Iteration 187/1000 | Loss: 0.00002891
Iteration 188/1000 | Loss: 0.00002891
Iteration 189/1000 | Loss: 0.00002891
Iteration 190/1000 | Loss: 0.00002890
Iteration 191/1000 | Loss: 0.00002890
Iteration 192/1000 | Loss: 0.00002890
Iteration 193/1000 | Loss: 0.00002890
Iteration 194/1000 | Loss: 0.00002890
Iteration 195/1000 | Loss: 0.00002890
Iteration 196/1000 | Loss: 0.00002889
Iteration 197/1000 | Loss: 0.00002889
Iteration 198/1000 | Loss: 0.00002889
Iteration 199/1000 | Loss: 0.00002889
Iteration 200/1000 | Loss: 0.00002889
Iteration 201/1000 | Loss: 0.00002889
Iteration 202/1000 | Loss: 0.00002889
Iteration 203/1000 | Loss: 0.00002889
Iteration 204/1000 | Loss: 0.00002889
Iteration 205/1000 | Loss: 0.00002889
Iteration 206/1000 | Loss: 0.00002889
Iteration 207/1000 | Loss: 0.00002889
Iteration 208/1000 | Loss: 0.00002889
Iteration 209/1000 | Loss: 0.00002889
Iteration 210/1000 | Loss: 0.00002888
Iteration 211/1000 | Loss: 0.00002888
Iteration 212/1000 | Loss: 0.00002888
Iteration 213/1000 | Loss: 0.00002888
Iteration 214/1000 | Loss: 0.00002888
Iteration 215/1000 | Loss: 0.00002887
Iteration 216/1000 | Loss: 0.00002887
Iteration 217/1000 | Loss: 0.00002887
Iteration 218/1000 | Loss: 0.00002887
Iteration 219/1000 | Loss: 0.00002887
Iteration 220/1000 | Loss: 0.00002886
Iteration 221/1000 | Loss: 0.00002886
Iteration 222/1000 | Loss: 0.00002886
Iteration 223/1000 | Loss: 0.00002886
Iteration 224/1000 | Loss: 0.00002886
Iteration 225/1000 | Loss: 0.00002886
Iteration 226/1000 | Loss: 0.00002886
Iteration 227/1000 | Loss: 0.00002886
Iteration 228/1000 | Loss: 0.00002885
Iteration 229/1000 | Loss: 0.00002885
Iteration 230/1000 | Loss: 0.00002885
Iteration 231/1000 | Loss: 0.00002885
Iteration 232/1000 | Loss: 0.00002885
Iteration 233/1000 | Loss: 0.00002884
Iteration 234/1000 | Loss: 0.00002884
Iteration 235/1000 | Loss: 0.00002884
Iteration 236/1000 | Loss: 0.00002884
Iteration 237/1000 | Loss: 0.00002884
Iteration 238/1000 | Loss: 0.00002884
Iteration 239/1000 | Loss: 0.00002884
Iteration 240/1000 | Loss: 0.00002884
Iteration 241/1000 | Loss: 0.00002884
Iteration 242/1000 | Loss: 0.00002884
Iteration 243/1000 | Loss: 0.00002884
Iteration 244/1000 | Loss: 0.00002884
Iteration 245/1000 | Loss: 0.00002884
Iteration 246/1000 | Loss: 0.00002884
Iteration 247/1000 | Loss: 0.00002884
Iteration 248/1000 | Loss: 0.00002884
Iteration 249/1000 | Loss: 0.00002884
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 249. Stopping optimization.
Last 5 losses: [2.8838128855568357e-05, 2.8838128855568357e-05, 2.8838128855568357e-05, 2.8838128855568357e-05, 2.8838128855568357e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8838128855568357e-05

Optimization complete. Final v2v error: 4.3294758796691895 mm

Highest mean error: 5.456780910491943 mm for frame 59

Lowest mean error: 3.579639196395874 mm for frame 129

Saving results

Total time: 57.569212198257446
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1063/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1063.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1063
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01110215
Iteration 2/25 | Loss: 0.00120173
Iteration 3/25 | Loss: 0.00086755
Iteration 4/25 | Loss: 0.00080247
Iteration 5/25 | Loss: 0.00078462
Iteration 6/25 | Loss: 0.00078101
Iteration 7/25 | Loss: 0.00077962
Iteration 8/25 | Loss: 0.00077891
Iteration 9/25 | Loss: 0.00078169
Iteration 10/25 | Loss: 0.00078356
Iteration 11/25 | Loss: 0.00078095
Iteration 12/25 | Loss: 0.00078075
Iteration 13/25 | Loss: 0.00078357
Iteration 14/25 | Loss: 0.00078378
Iteration 15/25 | Loss: 0.00078330
Iteration 16/25 | Loss: 0.00078279
Iteration 17/25 | Loss: 0.00078269
Iteration 18/25 | Loss: 0.00078393
Iteration 19/25 | Loss: 0.00078413
Iteration 20/25 | Loss: 0.00078210
Iteration 21/25 | Loss: 0.00078334
Iteration 22/25 | Loss: 0.00078343
Iteration 23/25 | Loss: 0.00078120
Iteration 24/25 | Loss: 0.00078333
Iteration 25/25 | Loss: 0.00078337

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.36943269
Iteration 2/25 | Loss: 0.00127313
Iteration 3/25 | Loss: 0.00127313
Iteration 4/25 | Loss: 0.00127313
Iteration 5/25 | Loss: 0.00127313
Iteration 6/25 | Loss: 0.00127313
Iteration 7/25 | Loss: 0.00127313
Iteration 8/25 | Loss: 0.00127313
Iteration 9/25 | Loss: 0.00127313
Iteration 10/25 | Loss: 0.00127313
Iteration 11/25 | Loss: 0.00127313
Iteration 12/25 | Loss: 0.00127313
Iteration 13/25 | Loss: 0.00127313
Iteration 14/25 | Loss: 0.00127313
Iteration 15/25 | Loss: 0.00127313
Iteration 16/25 | Loss: 0.00127313
Iteration 17/25 | Loss: 0.00127313
Iteration 18/25 | Loss: 0.00127313
Iteration 19/25 | Loss: 0.00127313
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0012731291353702545, 0.0012731291353702545, 0.0012731291353702545, 0.0012731291353702545, 0.0012731291353702545]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012731291353702545

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00127313
Iteration 2/1000 | Loss: 0.00010705
Iteration 3/1000 | Loss: 0.00004622
Iteration 4/1000 | Loss: 0.00016662
Iteration 5/1000 | Loss: 0.00014525
Iteration 6/1000 | Loss: 0.00004749
Iteration 7/1000 | Loss: 0.00012776
Iteration 8/1000 | Loss: 0.00011450
Iteration 9/1000 | Loss: 0.00006413
Iteration 10/1000 | Loss: 0.00009801
Iteration 11/1000 | Loss: 0.00008465
Iteration 12/1000 | Loss: 0.00026477
Iteration 13/1000 | Loss: 0.00010071
Iteration 14/1000 | Loss: 0.00026474
Iteration 15/1000 | Loss: 0.00011232
Iteration 16/1000 | Loss: 0.00018855
Iteration 17/1000 | Loss: 0.00004618
Iteration 18/1000 | Loss: 0.00012781
Iteration 19/1000 | Loss: 0.00016214
Iteration 20/1000 | Loss: 0.00011826
Iteration 21/1000 | Loss: 0.00014159
Iteration 22/1000 | Loss: 0.00004269
Iteration 23/1000 | Loss: 0.00004333
Iteration 24/1000 | Loss: 0.00006542
Iteration 25/1000 | Loss: 0.00003584
Iteration 26/1000 | Loss: 0.00006792
Iteration 27/1000 | Loss: 0.00004788
Iteration 28/1000 | Loss: 0.00006907
Iteration 29/1000 | Loss: 0.00007428
Iteration 30/1000 | Loss: 0.00006882
Iteration 31/1000 | Loss: 0.00016168
Iteration 32/1000 | Loss: 0.00011761
Iteration 33/1000 | Loss: 0.00012419
Iteration 34/1000 | Loss: 0.00009412
Iteration 35/1000 | Loss: 0.00006586
Iteration 36/1000 | Loss: 0.00014803
Iteration 37/1000 | Loss: 0.00010079
Iteration 38/1000 | Loss: 0.00013744
Iteration 39/1000 | Loss: 0.00016462
Iteration 40/1000 | Loss: 0.00011240
Iteration 41/1000 | Loss: 0.00010286
Iteration 42/1000 | Loss: 0.00008854
Iteration 43/1000 | Loss: 0.00010569
Iteration 44/1000 | Loss: 0.00015210
Iteration 45/1000 | Loss: 0.00016166
Iteration 46/1000 | Loss: 0.00004102
Iteration 47/1000 | Loss: 0.00019057
Iteration 48/1000 | Loss: 0.00017128
Iteration 49/1000 | Loss: 0.00008458
Iteration 50/1000 | Loss: 0.00003775
Iteration 51/1000 | Loss: 0.00003363
Iteration 52/1000 | Loss: 0.00010913
Iteration 53/1000 | Loss: 0.00013187
Iteration 54/1000 | Loss: 0.00005494
Iteration 55/1000 | Loss: 0.00010900
Iteration 56/1000 | Loss: 0.00014407
Iteration 57/1000 | Loss: 0.00012784
Iteration 58/1000 | Loss: 0.00010984
Iteration 59/1000 | Loss: 0.00011733
Iteration 60/1000 | Loss: 0.00010980
Iteration 61/1000 | Loss: 0.00010674
Iteration 62/1000 | Loss: 0.00011415
Iteration 63/1000 | Loss: 0.00007413
Iteration 64/1000 | Loss: 0.00019666
Iteration 65/1000 | Loss: 0.00010167
Iteration 66/1000 | Loss: 0.00010596
Iteration 67/1000 | Loss: 0.00013034
Iteration 68/1000 | Loss: 0.00014163
Iteration 69/1000 | Loss: 0.00020333
Iteration 70/1000 | Loss: 0.00009049
Iteration 71/1000 | Loss: 0.00013924
Iteration 72/1000 | Loss: 0.00006907
Iteration 73/1000 | Loss: 0.00003759
Iteration 74/1000 | Loss: 0.00013681
Iteration 75/1000 | Loss: 0.00032242
Iteration 76/1000 | Loss: 0.00032918
Iteration 77/1000 | Loss: 0.00013840
Iteration 78/1000 | Loss: 0.00005479
Iteration 79/1000 | Loss: 0.00023312
Iteration 80/1000 | Loss: 0.00022791
Iteration 81/1000 | Loss: 0.00010973
Iteration 82/1000 | Loss: 0.00004183
Iteration 83/1000 | Loss: 0.00004040
Iteration 84/1000 | Loss: 0.00003993
Iteration 85/1000 | Loss: 0.00003459
Iteration 86/1000 | Loss: 0.00004089
Iteration 87/1000 | Loss: 0.00004689
Iteration 88/1000 | Loss: 0.00002880
Iteration 89/1000 | Loss: 0.00003857
Iteration 90/1000 | Loss: 0.00003294
Iteration 91/1000 | Loss: 0.00004662
Iteration 92/1000 | Loss: 0.00003565
Iteration 93/1000 | Loss: 0.00003869
Iteration 94/1000 | Loss: 0.00003710
Iteration 95/1000 | Loss: 0.00003830
Iteration 96/1000 | Loss: 0.00003018
Iteration 97/1000 | Loss: 0.00003808
Iteration 98/1000 | Loss: 0.00003691
Iteration 99/1000 | Loss: 0.00003780
Iteration 100/1000 | Loss: 0.00004230
Iteration 101/1000 | Loss: 0.00003792
Iteration 102/1000 | Loss: 0.00004386
Iteration 103/1000 | Loss: 0.00004150
Iteration 104/1000 | Loss: 0.00003951
Iteration 105/1000 | Loss: 0.00003745
Iteration 106/1000 | Loss: 0.00004257
Iteration 107/1000 | Loss: 0.00003935
Iteration 108/1000 | Loss: 0.00003970
Iteration 109/1000 | Loss: 0.00003603
Iteration 110/1000 | Loss: 0.00004632
Iteration 111/1000 | Loss: 0.00003891
Iteration 112/1000 | Loss: 0.00004002
Iteration 113/1000 | Loss: 0.00003566
Iteration 114/1000 | Loss: 0.00004000
Iteration 115/1000 | Loss: 0.00003814
Iteration 116/1000 | Loss: 0.00004060
Iteration 117/1000 | Loss: 0.00004367
Iteration 118/1000 | Loss: 0.00004480
Iteration 119/1000 | Loss: 0.00003279
Iteration 120/1000 | Loss: 0.00001906
Iteration 121/1000 | Loss: 0.00003290
Iteration 122/1000 | Loss: 0.00004657
Iteration 123/1000 | Loss: 0.00003970
Iteration 124/1000 | Loss: 0.00005071
Iteration 125/1000 | Loss: 0.00003832
Iteration 126/1000 | Loss: 0.00004599
Iteration 127/1000 | Loss: 0.00003688
Iteration 128/1000 | Loss: 0.00004541
Iteration 129/1000 | Loss: 0.00003649
Iteration 130/1000 | Loss: 0.00004489
Iteration 131/1000 | Loss: 0.00004066
Iteration 132/1000 | Loss: 0.00003883
Iteration 133/1000 | Loss: 0.00003412
Iteration 134/1000 | Loss: 0.00003593
Iteration 135/1000 | Loss: 0.00002712
Iteration 136/1000 | Loss: 0.00003253
Iteration 137/1000 | Loss: 0.00001712
Iteration 138/1000 | Loss: 0.00004000
Iteration 139/1000 | Loss: 0.00002831
Iteration 140/1000 | Loss: 0.00002186
Iteration 141/1000 | Loss: 0.00002262
Iteration 142/1000 | Loss: 0.00001659
Iteration 143/1000 | Loss: 0.00004110
Iteration 144/1000 | Loss: 0.00002751
Iteration 145/1000 | Loss: 0.00002505
Iteration 146/1000 | Loss: 0.00003279
Iteration 147/1000 | Loss: 0.00002180
Iteration 148/1000 | Loss: 0.00001637
Iteration 149/1000 | Loss: 0.00001508
Iteration 150/1000 | Loss: 0.00001452
Iteration 151/1000 | Loss: 0.00001403
Iteration 152/1000 | Loss: 0.00001379
Iteration 153/1000 | Loss: 0.00001359
Iteration 154/1000 | Loss: 0.00001348
Iteration 155/1000 | Loss: 0.00001342
Iteration 156/1000 | Loss: 0.00001335
Iteration 157/1000 | Loss: 0.00001330
Iteration 158/1000 | Loss: 0.00001329
Iteration 159/1000 | Loss: 0.00001329
Iteration 160/1000 | Loss: 0.00001323
Iteration 161/1000 | Loss: 0.00001322
Iteration 162/1000 | Loss: 0.00001322
Iteration 163/1000 | Loss: 0.00001322
Iteration 164/1000 | Loss: 0.00001322
Iteration 165/1000 | Loss: 0.00001321
Iteration 166/1000 | Loss: 0.00001316
Iteration 167/1000 | Loss: 0.00001315
Iteration 168/1000 | Loss: 0.00001314
Iteration 169/1000 | Loss: 0.00001314
Iteration 170/1000 | Loss: 0.00001313
Iteration 171/1000 | Loss: 0.00001313
Iteration 172/1000 | Loss: 0.00001312
Iteration 173/1000 | Loss: 0.00001311
Iteration 174/1000 | Loss: 0.00001311
Iteration 175/1000 | Loss: 0.00001309
Iteration 176/1000 | Loss: 0.00001309
Iteration 177/1000 | Loss: 0.00001309
Iteration 178/1000 | Loss: 0.00001308
Iteration 179/1000 | Loss: 0.00001307
Iteration 180/1000 | Loss: 0.00001306
Iteration 181/1000 | Loss: 0.00001305
Iteration 182/1000 | Loss: 0.00001305
Iteration 183/1000 | Loss: 0.00001304
Iteration 184/1000 | Loss: 0.00001303
Iteration 185/1000 | Loss: 0.00001302
Iteration 186/1000 | Loss: 0.00001302
Iteration 187/1000 | Loss: 0.00001301
Iteration 188/1000 | Loss: 0.00001300
Iteration 189/1000 | Loss: 0.00001300
Iteration 190/1000 | Loss: 0.00001300
Iteration 191/1000 | Loss: 0.00001299
Iteration 192/1000 | Loss: 0.00001298
Iteration 193/1000 | Loss: 0.00001298
Iteration 194/1000 | Loss: 0.00001298
Iteration 195/1000 | Loss: 0.00001297
Iteration 196/1000 | Loss: 0.00001297
Iteration 197/1000 | Loss: 0.00001296
Iteration 198/1000 | Loss: 0.00001296
Iteration 199/1000 | Loss: 0.00001295
Iteration 200/1000 | Loss: 0.00001295
Iteration 201/1000 | Loss: 0.00001295
Iteration 202/1000 | Loss: 0.00001295
Iteration 203/1000 | Loss: 0.00001295
Iteration 204/1000 | Loss: 0.00001295
Iteration 205/1000 | Loss: 0.00001295
Iteration 206/1000 | Loss: 0.00001295
Iteration 207/1000 | Loss: 0.00001295
Iteration 208/1000 | Loss: 0.00001294
Iteration 209/1000 | Loss: 0.00001294
Iteration 210/1000 | Loss: 0.00001294
Iteration 211/1000 | Loss: 0.00001294
Iteration 212/1000 | Loss: 0.00001294
Iteration 213/1000 | Loss: 0.00001294
Iteration 214/1000 | Loss: 0.00001294
Iteration 215/1000 | Loss: 0.00001294
Iteration 216/1000 | Loss: 0.00001294
Iteration 217/1000 | Loss: 0.00001294
Iteration 218/1000 | Loss: 0.00001294
Iteration 219/1000 | Loss: 0.00001294
Iteration 220/1000 | Loss: 0.00001294
Iteration 221/1000 | Loss: 0.00001294
Iteration 222/1000 | Loss: 0.00001294
Iteration 223/1000 | Loss: 0.00001294
Iteration 224/1000 | Loss: 0.00001294
Iteration 225/1000 | Loss: 0.00001294
Iteration 226/1000 | Loss: 0.00001294
Iteration 227/1000 | Loss: 0.00001294
Iteration 228/1000 | Loss: 0.00001294
Iteration 229/1000 | Loss: 0.00001294
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 229. Stopping optimization.
Last 5 losses: [1.294283356401138e-05, 1.294283356401138e-05, 1.294283356401138e-05, 1.294283356401138e-05, 1.294283356401138e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.294283356401138e-05

Optimization complete. Final v2v error: 3.029942274093628 mm

Highest mean error: 4.584555149078369 mm for frame 103

Lowest mean error: 2.850987195968628 mm for frame 48

Saving results

Total time: 313.35236954689026
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1076/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1076.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1076
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01106527
Iteration 2/25 | Loss: 0.00242580
Iteration 3/25 | Loss: 0.00136978
Iteration 4/25 | Loss: 0.00114020
Iteration 5/25 | Loss: 0.00107410
Iteration 6/25 | Loss: 0.00100400
Iteration 7/25 | Loss: 0.00090044
Iteration 8/25 | Loss: 0.00082085
Iteration 9/25 | Loss: 0.00079115
Iteration 10/25 | Loss: 0.00078258
Iteration 11/25 | Loss: 0.00077887
Iteration 12/25 | Loss: 0.00077810
Iteration 13/25 | Loss: 0.00077800
Iteration 14/25 | Loss: 0.00077800
Iteration 15/25 | Loss: 0.00077800
Iteration 16/25 | Loss: 0.00077800
Iteration 17/25 | Loss: 0.00077800
Iteration 18/25 | Loss: 0.00077800
Iteration 19/25 | Loss: 0.00077800
Iteration 20/25 | Loss: 0.00077800
Iteration 21/25 | Loss: 0.00077800
Iteration 22/25 | Loss: 0.00077800
Iteration 23/25 | Loss: 0.00077800
Iteration 24/25 | Loss: 0.00077800
Iteration 25/25 | Loss: 0.00077800

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53755999
Iteration 2/25 | Loss: 0.00112882
Iteration 3/25 | Loss: 0.00112881
Iteration 4/25 | Loss: 0.00112881
Iteration 5/25 | Loss: 0.00112881
Iteration 6/25 | Loss: 0.00112881
Iteration 7/25 | Loss: 0.00112881
Iteration 8/25 | Loss: 0.00112881
Iteration 9/25 | Loss: 0.00112881
Iteration 10/25 | Loss: 0.00112881
Iteration 11/25 | Loss: 0.00112881
Iteration 12/25 | Loss: 0.00112881
Iteration 13/25 | Loss: 0.00112881
Iteration 14/25 | Loss: 0.00112881
Iteration 15/25 | Loss: 0.00112881
Iteration 16/25 | Loss: 0.00112881
Iteration 17/25 | Loss: 0.00112881
Iteration 18/25 | Loss: 0.00112881
Iteration 19/25 | Loss: 0.00112881
Iteration 20/25 | Loss: 0.00112881
Iteration 21/25 | Loss: 0.00112881
Iteration 22/25 | Loss: 0.00112881
Iteration 23/25 | Loss: 0.00112881
Iteration 24/25 | Loss: 0.00112881
Iteration 25/25 | Loss: 0.00112881

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112881
Iteration 2/1000 | Loss: 0.00003193
Iteration 3/1000 | Loss: 0.00002355
Iteration 4/1000 | Loss: 0.00002137
Iteration 5/1000 | Loss: 0.00002034
Iteration 6/1000 | Loss: 0.00001979
Iteration 7/1000 | Loss: 0.00001934
Iteration 8/1000 | Loss: 0.00001903
Iteration 9/1000 | Loss: 0.00001881
Iteration 10/1000 | Loss: 0.00001860
Iteration 11/1000 | Loss: 0.00001857
Iteration 12/1000 | Loss: 0.00001856
Iteration 13/1000 | Loss: 0.00001855
Iteration 14/1000 | Loss: 0.00001854
Iteration 15/1000 | Loss: 0.00001854
Iteration 16/1000 | Loss: 0.00001851
Iteration 17/1000 | Loss: 0.00001847
Iteration 18/1000 | Loss: 0.00001834
Iteration 19/1000 | Loss: 0.00001832
Iteration 20/1000 | Loss: 0.00001828
Iteration 21/1000 | Loss: 0.00001828
Iteration 22/1000 | Loss: 0.00001828
Iteration 23/1000 | Loss: 0.00001828
Iteration 24/1000 | Loss: 0.00001828
Iteration 25/1000 | Loss: 0.00001827
Iteration 26/1000 | Loss: 0.00001827
Iteration 27/1000 | Loss: 0.00001827
Iteration 28/1000 | Loss: 0.00001827
Iteration 29/1000 | Loss: 0.00001826
Iteration 30/1000 | Loss: 0.00001826
Iteration 31/1000 | Loss: 0.00001826
Iteration 32/1000 | Loss: 0.00001825
Iteration 33/1000 | Loss: 0.00001825
Iteration 34/1000 | Loss: 0.00001825
Iteration 35/1000 | Loss: 0.00001824
Iteration 36/1000 | Loss: 0.00001824
Iteration 37/1000 | Loss: 0.00001824
Iteration 38/1000 | Loss: 0.00001824
Iteration 39/1000 | Loss: 0.00001823
Iteration 40/1000 | Loss: 0.00001823
Iteration 41/1000 | Loss: 0.00001823
Iteration 42/1000 | Loss: 0.00001822
Iteration 43/1000 | Loss: 0.00001822
Iteration 44/1000 | Loss: 0.00001822
Iteration 45/1000 | Loss: 0.00001820
Iteration 46/1000 | Loss: 0.00001820
Iteration 47/1000 | Loss: 0.00001819
Iteration 48/1000 | Loss: 0.00001818
Iteration 49/1000 | Loss: 0.00001818
Iteration 50/1000 | Loss: 0.00001818
Iteration 51/1000 | Loss: 0.00001818
Iteration 52/1000 | Loss: 0.00001818
Iteration 53/1000 | Loss: 0.00001816
Iteration 54/1000 | Loss: 0.00001814
Iteration 55/1000 | Loss: 0.00001814
Iteration 56/1000 | Loss: 0.00001813
Iteration 57/1000 | Loss: 0.00001812
Iteration 58/1000 | Loss: 0.00001811
Iteration 59/1000 | Loss: 0.00001810
Iteration 60/1000 | Loss: 0.00001809
Iteration 61/1000 | Loss: 0.00001808
Iteration 62/1000 | Loss: 0.00001807
Iteration 63/1000 | Loss: 0.00001806
Iteration 64/1000 | Loss: 0.00001806
Iteration 65/1000 | Loss: 0.00001803
Iteration 66/1000 | Loss: 0.00001799
Iteration 67/1000 | Loss: 0.00001799
Iteration 68/1000 | Loss: 0.00001797
Iteration 69/1000 | Loss: 0.00001797
Iteration 70/1000 | Loss: 0.00001797
Iteration 71/1000 | Loss: 0.00001797
Iteration 72/1000 | Loss: 0.00001797
Iteration 73/1000 | Loss: 0.00001797
Iteration 74/1000 | Loss: 0.00001797
Iteration 75/1000 | Loss: 0.00001796
Iteration 76/1000 | Loss: 0.00001796
Iteration 77/1000 | Loss: 0.00001796
Iteration 78/1000 | Loss: 0.00001796
Iteration 79/1000 | Loss: 0.00001796
Iteration 80/1000 | Loss: 0.00001796
Iteration 81/1000 | Loss: 0.00001796
Iteration 82/1000 | Loss: 0.00001796
Iteration 83/1000 | Loss: 0.00001795
Iteration 84/1000 | Loss: 0.00001795
Iteration 85/1000 | Loss: 0.00001795
Iteration 86/1000 | Loss: 0.00001795
Iteration 87/1000 | Loss: 0.00001795
Iteration 88/1000 | Loss: 0.00001795
Iteration 89/1000 | Loss: 0.00001795
Iteration 90/1000 | Loss: 0.00001794
Iteration 91/1000 | Loss: 0.00001794
Iteration 92/1000 | Loss: 0.00001794
Iteration 93/1000 | Loss: 0.00001794
Iteration 94/1000 | Loss: 0.00001794
Iteration 95/1000 | Loss: 0.00001794
Iteration 96/1000 | Loss: 0.00001794
Iteration 97/1000 | Loss: 0.00001794
Iteration 98/1000 | Loss: 0.00001794
Iteration 99/1000 | Loss: 0.00001794
Iteration 100/1000 | Loss: 0.00001794
Iteration 101/1000 | Loss: 0.00001794
Iteration 102/1000 | Loss: 0.00001794
Iteration 103/1000 | Loss: 0.00001794
Iteration 104/1000 | Loss: 0.00001794
Iteration 105/1000 | Loss: 0.00001793
Iteration 106/1000 | Loss: 0.00001793
Iteration 107/1000 | Loss: 0.00001793
Iteration 108/1000 | Loss: 0.00001793
Iteration 109/1000 | Loss: 0.00001793
Iteration 110/1000 | Loss: 0.00001793
Iteration 111/1000 | Loss: 0.00001793
Iteration 112/1000 | Loss: 0.00001793
Iteration 113/1000 | Loss: 0.00001793
Iteration 114/1000 | Loss: 0.00001792
Iteration 115/1000 | Loss: 0.00001792
Iteration 116/1000 | Loss: 0.00001792
Iteration 117/1000 | Loss: 0.00001792
Iteration 118/1000 | Loss: 0.00001792
Iteration 119/1000 | Loss: 0.00001792
Iteration 120/1000 | Loss: 0.00001792
Iteration 121/1000 | Loss: 0.00001792
Iteration 122/1000 | Loss: 0.00001792
Iteration 123/1000 | Loss: 0.00001792
Iteration 124/1000 | Loss: 0.00001792
Iteration 125/1000 | Loss: 0.00001792
Iteration 126/1000 | Loss: 0.00001791
Iteration 127/1000 | Loss: 0.00001791
Iteration 128/1000 | Loss: 0.00001791
Iteration 129/1000 | Loss: 0.00001791
Iteration 130/1000 | Loss: 0.00001791
Iteration 131/1000 | Loss: 0.00001791
Iteration 132/1000 | Loss: 0.00001791
Iteration 133/1000 | Loss: 0.00001791
Iteration 134/1000 | Loss: 0.00001791
Iteration 135/1000 | Loss: 0.00001790
Iteration 136/1000 | Loss: 0.00001790
Iteration 137/1000 | Loss: 0.00001790
Iteration 138/1000 | Loss: 0.00001790
Iteration 139/1000 | Loss: 0.00001790
Iteration 140/1000 | Loss: 0.00001790
Iteration 141/1000 | Loss: 0.00001790
Iteration 142/1000 | Loss: 0.00001790
Iteration 143/1000 | Loss: 0.00001790
Iteration 144/1000 | Loss: 0.00001790
Iteration 145/1000 | Loss: 0.00001790
Iteration 146/1000 | Loss: 0.00001789
Iteration 147/1000 | Loss: 0.00001789
Iteration 148/1000 | Loss: 0.00001789
Iteration 149/1000 | Loss: 0.00001789
Iteration 150/1000 | Loss: 0.00001789
Iteration 151/1000 | Loss: 0.00001789
Iteration 152/1000 | Loss: 0.00001789
Iteration 153/1000 | Loss: 0.00001789
Iteration 154/1000 | Loss: 0.00001789
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [1.789356247172691e-05, 1.789356247172691e-05, 1.789356247172691e-05, 1.789356247172691e-05, 1.789356247172691e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.789356247172691e-05

Optimization complete. Final v2v error: 3.548312187194824 mm

Highest mean error: 3.6596250534057617 mm for frame 53

Lowest mean error: 3.3761682510375977 mm for frame 84

Saving results

Total time: 49.26551532745361
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1031/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1031.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1031
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402125
Iteration 2/25 | Loss: 0.00095968
Iteration 3/25 | Loss: 0.00078325
Iteration 4/25 | Loss: 0.00075522
Iteration 5/25 | Loss: 0.00074719
Iteration 6/25 | Loss: 0.00074457
Iteration 7/25 | Loss: 0.00074373
Iteration 8/25 | Loss: 0.00074363
Iteration 9/25 | Loss: 0.00074363
Iteration 10/25 | Loss: 0.00074363
Iteration 11/25 | Loss: 0.00074363
Iteration 12/25 | Loss: 0.00074363
Iteration 13/25 | Loss: 0.00074363
Iteration 14/25 | Loss: 0.00074363
Iteration 15/25 | Loss: 0.00074363
Iteration 16/25 | Loss: 0.00074363
Iteration 17/25 | Loss: 0.00074363
Iteration 18/25 | Loss: 0.00074363
Iteration 19/25 | Loss: 0.00074363
Iteration 20/25 | Loss: 0.00074363
Iteration 21/25 | Loss: 0.00074363
Iteration 22/25 | Loss: 0.00074363
Iteration 23/25 | Loss: 0.00074363
Iteration 24/25 | Loss: 0.00074363
Iteration 25/25 | Loss: 0.00074363

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45500219
Iteration 2/25 | Loss: 0.00114687
Iteration 3/25 | Loss: 0.00114684
Iteration 4/25 | Loss: 0.00114684
Iteration 5/25 | Loss: 0.00114684
Iteration 6/25 | Loss: 0.00114684
Iteration 7/25 | Loss: 0.00114684
Iteration 8/25 | Loss: 0.00114684
Iteration 9/25 | Loss: 0.00114684
Iteration 10/25 | Loss: 0.00114684
Iteration 11/25 | Loss: 0.00114684
Iteration 12/25 | Loss: 0.00114684
Iteration 13/25 | Loss: 0.00114684
Iteration 14/25 | Loss: 0.00114684
Iteration 15/25 | Loss: 0.00114684
Iteration 16/25 | Loss: 0.00114684
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011468379525467753, 0.0011468379525467753, 0.0011468379525467753, 0.0011468379525467753, 0.0011468379525467753]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011468379525467753

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00114684
Iteration 2/1000 | Loss: 0.00003729
Iteration 3/1000 | Loss: 0.00002529
Iteration 4/1000 | Loss: 0.00001949
Iteration 5/1000 | Loss: 0.00001738
Iteration 6/1000 | Loss: 0.00001662
Iteration 7/1000 | Loss: 0.00001585
Iteration 8/1000 | Loss: 0.00001550
Iteration 9/1000 | Loss: 0.00001520
Iteration 10/1000 | Loss: 0.00001498
Iteration 11/1000 | Loss: 0.00001485
Iteration 12/1000 | Loss: 0.00001478
Iteration 13/1000 | Loss: 0.00001477
Iteration 14/1000 | Loss: 0.00001477
Iteration 15/1000 | Loss: 0.00001476
Iteration 16/1000 | Loss: 0.00001475
Iteration 17/1000 | Loss: 0.00001473
Iteration 18/1000 | Loss: 0.00001471
Iteration 19/1000 | Loss: 0.00001471
Iteration 20/1000 | Loss: 0.00001469
Iteration 21/1000 | Loss: 0.00001469
Iteration 22/1000 | Loss: 0.00001466
Iteration 23/1000 | Loss: 0.00001460
Iteration 24/1000 | Loss: 0.00001459
Iteration 25/1000 | Loss: 0.00001458
Iteration 26/1000 | Loss: 0.00001458
Iteration 27/1000 | Loss: 0.00001454
Iteration 28/1000 | Loss: 0.00001454
Iteration 29/1000 | Loss: 0.00001449
Iteration 30/1000 | Loss: 0.00001448
Iteration 31/1000 | Loss: 0.00001446
Iteration 32/1000 | Loss: 0.00001445
Iteration 33/1000 | Loss: 0.00001443
Iteration 34/1000 | Loss: 0.00001443
Iteration 35/1000 | Loss: 0.00001443
Iteration 36/1000 | Loss: 0.00001442
Iteration 37/1000 | Loss: 0.00001442
Iteration 38/1000 | Loss: 0.00001442
Iteration 39/1000 | Loss: 0.00001442
Iteration 40/1000 | Loss: 0.00001442
Iteration 41/1000 | Loss: 0.00001442
Iteration 42/1000 | Loss: 0.00001442
Iteration 43/1000 | Loss: 0.00001442
Iteration 44/1000 | Loss: 0.00001440
Iteration 45/1000 | Loss: 0.00001440
Iteration 46/1000 | Loss: 0.00001439
Iteration 47/1000 | Loss: 0.00001439
Iteration 48/1000 | Loss: 0.00001439
Iteration 49/1000 | Loss: 0.00001438
Iteration 50/1000 | Loss: 0.00001438
Iteration 51/1000 | Loss: 0.00001438
Iteration 52/1000 | Loss: 0.00001437
Iteration 53/1000 | Loss: 0.00001437
Iteration 54/1000 | Loss: 0.00001437
Iteration 55/1000 | Loss: 0.00001436
Iteration 56/1000 | Loss: 0.00001436
Iteration 57/1000 | Loss: 0.00001435
Iteration 58/1000 | Loss: 0.00001435
Iteration 59/1000 | Loss: 0.00001435
Iteration 60/1000 | Loss: 0.00001435
Iteration 61/1000 | Loss: 0.00001435
Iteration 62/1000 | Loss: 0.00001434
Iteration 63/1000 | Loss: 0.00001433
Iteration 64/1000 | Loss: 0.00001433
Iteration 65/1000 | Loss: 0.00001432
Iteration 66/1000 | Loss: 0.00001432
Iteration 67/1000 | Loss: 0.00001431
Iteration 68/1000 | Loss: 0.00001431
Iteration 69/1000 | Loss: 0.00001431
Iteration 70/1000 | Loss: 0.00001431
Iteration 71/1000 | Loss: 0.00001430
Iteration 72/1000 | Loss: 0.00001430
Iteration 73/1000 | Loss: 0.00001429
Iteration 74/1000 | Loss: 0.00001429
Iteration 75/1000 | Loss: 0.00001429
Iteration 76/1000 | Loss: 0.00001428
Iteration 77/1000 | Loss: 0.00001428
Iteration 78/1000 | Loss: 0.00001428
Iteration 79/1000 | Loss: 0.00001428
Iteration 80/1000 | Loss: 0.00001428
Iteration 81/1000 | Loss: 0.00001427
Iteration 82/1000 | Loss: 0.00001427
Iteration 83/1000 | Loss: 0.00001427
Iteration 84/1000 | Loss: 0.00001427
Iteration 85/1000 | Loss: 0.00001426
Iteration 86/1000 | Loss: 0.00001426
Iteration 87/1000 | Loss: 0.00001425
Iteration 88/1000 | Loss: 0.00001425
Iteration 89/1000 | Loss: 0.00001425
Iteration 90/1000 | Loss: 0.00001424
Iteration 91/1000 | Loss: 0.00001424
Iteration 92/1000 | Loss: 0.00001424
Iteration 93/1000 | Loss: 0.00001424
Iteration 94/1000 | Loss: 0.00001424
Iteration 95/1000 | Loss: 0.00001423
Iteration 96/1000 | Loss: 0.00001423
Iteration 97/1000 | Loss: 0.00001423
Iteration 98/1000 | Loss: 0.00001423
Iteration 99/1000 | Loss: 0.00001423
Iteration 100/1000 | Loss: 0.00001423
Iteration 101/1000 | Loss: 0.00001423
Iteration 102/1000 | Loss: 0.00001422
Iteration 103/1000 | Loss: 0.00001422
Iteration 104/1000 | Loss: 0.00001422
Iteration 105/1000 | Loss: 0.00001421
Iteration 106/1000 | Loss: 0.00001421
Iteration 107/1000 | Loss: 0.00001421
Iteration 108/1000 | Loss: 0.00001421
Iteration 109/1000 | Loss: 0.00001421
Iteration 110/1000 | Loss: 0.00001421
Iteration 111/1000 | Loss: 0.00001421
Iteration 112/1000 | Loss: 0.00001421
Iteration 113/1000 | Loss: 0.00001420
Iteration 114/1000 | Loss: 0.00001420
Iteration 115/1000 | Loss: 0.00001420
Iteration 116/1000 | Loss: 0.00001420
Iteration 117/1000 | Loss: 0.00001420
Iteration 118/1000 | Loss: 0.00001420
Iteration 119/1000 | Loss: 0.00001420
Iteration 120/1000 | Loss: 0.00001420
Iteration 121/1000 | Loss: 0.00001420
Iteration 122/1000 | Loss: 0.00001420
Iteration 123/1000 | Loss: 0.00001420
Iteration 124/1000 | Loss: 0.00001420
Iteration 125/1000 | Loss: 0.00001420
Iteration 126/1000 | Loss: 0.00001420
Iteration 127/1000 | Loss: 0.00001420
Iteration 128/1000 | Loss: 0.00001420
Iteration 129/1000 | Loss: 0.00001420
Iteration 130/1000 | Loss: 0.00001420
Iteration 131/1000 | Loss: 0.00001420
Iteration 132/1000 | Loss: 0.00001420
Iteration 133/1000 | Loss: 0.00001420
Iteration 134/1000 | Loss: 0.00001420
Iteration 135/1000 | Loss: 0.00001420
Iteration 136/1000 | Loss: 0.00001420
Iteration 137/1000 | Loss: 0.00001420
Iteration 138/1000 | Loss: 0.00001420
Iteration 139/1000 | Loss: 0.00001420
Iteration 140/1000 | Loss: 0.00001420
Iteration 141/1000 | Loss: 0.00001420
Iteration 142/1000 | Loss: 0.00001420
Iteration 143/1000 | Loss: 0.00001420
Iteration 144/1000 | Loss: 0.00001420
Iteration 145/1000 | Loss: 0.00001420
Iteration 146/1000 | Loss: 0.00001420
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 146. Stopping optimization.
Last 5 losses: [1.4203284990799148e-05, 1.4203284990799148e-05, 1.4203284990799148e-05, 1.4203284990799148e-05, 1.4203284990799148e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4203284990799148e-05

Optimization complete. Final v2v error: 3.0185799598693848 mm

Highest mean error: 5.175421714782715 mm for frame 87

Lowest mean error: 2.3943185806274414 mm for frame 127

Saving results

Total time: 41.131418228149414
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1068/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1068.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1068
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00975881
Iteration 2/25 | Loss: 0.00149866
Iteration 3/25 | Loss: 0.00105787
Iteration 4/25 | Loss: 0.00092130
Iteration 5/25 | Loss: 0.00087256
Iteration 6/25 | Loss: 0.00086002
Iteration 7/25 | Loss: 0.00085226
Iteration 8/25 | Loss: 0.00084889
Iteration 9/25 | Loss: 0.00084321
Iteration 10/25 | Loss: 0.00083878
Iteration 11/25 | Loss: 0.00083646
Iteration 12/25 | Loss: 0.00083388
Iteration 13/25 | Loss: 0.00083166
Iteration 14/25 | Loss: 0.00083084
Iteration 15/25 | Loss: 0.00083254
Iteration 16/25 | Loss: 0.00083072
Iteration 17/25 | Loss: 0.00082914
Iteration 18/25 | Loss: 0.00082781
Iteration 19/25 | Loss: 0.00082652
Iteration 20/25 | Loss: 0.00082628
Iteration 21/25 | Loss: 0.00082624
Iteration 22/25 | Loss: 0.00082624
Iteration 23/25 | Loss: 0.00082624
Iteration 24/25 | Loss: 0.00082623
Iteration 25/25 | Loss: 0.00082623

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.68800914
Iteration 2/25 | Loss: 0.00137667
Iteration 3/25 | Loss: 0.00134326
Iteration 4/25 | Loss: 0.00134326
Iteration 5/25 | Loss: 0.00134326
Iteration 6/25 | Loss: 0.00134326
Iteration 7/25 | Loss: 0.00134326
Iteration 8/25 | Loss: 0.00134326
Iteration 9/25 | Loss: 0.00134326
Iteration 10/25 | Loss: 0.00134326
Iteration 11/25 | Loss: 0.00134326
Iteration 12/25 | Loss: 0.00134326
Iteration 13/25 | Loss: 0.00134326
Iteration 14/25 | Loss: 0.00134326
Iteration 15/25 | Loss: 0.00134326
Iteration 16/25 | Loss: 0.00134326
Iteration 17/25 | Loss: 0.00134326
Iteration 18/25 | Loss: 0.00134326
Iteration 19/25 | Loss: 0.00134326
Iteration 20/25 | Loss: 0.00134326
Iteration 21/25 | Loss: 0.00134326
Iteration 22/25 | Loss: 0.00134326
Iteration 23/25 | Loss: 0.00134326
Iteration 24/25 | Loss: 0.00134326
Iteration 25/25 | Loss: 0.00134326

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00134326
Iteration 2/1000 | Loss: 0.00004054
Iteration 3/1000 | Loss: 0.00005993
Iteration 4/1000 | Loss: 0.00002692
Iteration 5/1000 | Loss: 0.00002513
Iteration 6/1000 | Loss: 0.00002387
Iteration 7/1000 | Loss: 0.00002326
Iteration 8/1000 | Loss: 0.00002270
Iteration 9/1000 | Loss: 0.00055424
Iteration 10/1000 | Loss: 0.00002510
Iteration 11/1000 | Loss: 0.00002226
Iteration 12/1000 | Loss: 0.00002141
Iteration 13/1000 | Loss: 0.00002081
Iteration 14/1000 | Loss: 0.00002038
Iteration 15/1000 | Loss: 0.00002010
Iteration 16/1000 | Loss: 0.00002004
Iteration 17/1000 | Loss: 0.00002000
Iteration 18/1000 | Loss: 0.00001995
Iteration 19/1000 | Loss: 0.00001993
Iteration 20/1000 | Loss: 0.00001989
Iteration 21/1000 | Loss: 0.00001988
Iteration 22/1000 | Loss: 0.00001986
Iteration 23/1000 | Loss: 0.00001985
Iteration 24/1000 | Loss: 0.00001985
Iteration 25/1000 | Loss: 0.00001984
Iteration 26/1000 | Loss: 0.00001981
Iteration 27/1000 | Loss: 0.00001980
Iteration 28/1000 | Loss: 0.00001977
Iteration 29/1000 | Loss: 0.00001977
Iteration 30/1000 | Loss: 0.00001976
Iteration 31/1000 | Loss: 0.00001975
Iteration 32/1000 | Loss: 0.00001971
Iteration 33/1000 | Loss: 0.00001967
Iteration 34/1000 | Loss: 0.00001962
Iteration 35/1000 | Loss: 0.00001962
Iteration 36/1000 | Loss: 0.00001961
Iteration 37/1000 | Loss: 0.00001960
Iteration 38/1000 | Loss: 0.00001960
Iteration 39/1000 | Loss: 0.00001959
Iteration 40/1000 | Loss: 0.00001959
Iteration 41/1000 | Loss: 0.00001959
Iteration 42/1000 | Loss: 0.00001959
Iteration 43/1000 | Loss: 0.00001959
Iteration 44/1000 | Loss: 0.00001958
Iteration 45/1000 | Loss: 0.00001958
Iteration 46/1000 | Loss: 0.00001958
Iteration 47/1000 | Loss: 0.00001958
Iteration 48/1000 | Loss: 0.00001958
Iteration 49/1000 | Loss: 0.00001958
Iteration 50/1000 | Loss: 0.00001958
Iteration 51/1000 | Loss: 0.00001957
Iteration 52/1000 | Loss: 0.00001957
Iteration 53/1000 | Loss: 0.00001957
Iteration 54/1000 | Loss: 0.00001957
Iteration 55/1000 | Loss: 0.00001957
Iteration 56/1000 | Loss: 0.00001957
Iteration 57/1000 | Loss: 0.00001956
Iteration 58/1000 | Loss: 0.00001956
Iteration 59/1000 | Loss: 0.00001956
Iteration 60/1000 | Loss: 0.00001956
Iteration 61/1000 | Loss: 0.00001956
Iteration 62/1000 | Loss: 0.00001956
Iteration 63/1000 | Loss: 0.00001956
Iteration 64/1000 | Loss: 0.00001956
Iteration 65/1000 | Loss: 0.00001956
Iteration 66/1000 | Loss: 0.00001955
Iteration 67/1000 | Loss: 0.00001955
Iteration 68/1000 | Loss: 0.00001955
Iteration 69/1000 | Loss: 0.00001955
Iteration 70/1000 | Loss: 0.00001954
Iteration 71/1000 | Loss: 0.00001954
Iteration 72/1000 | Loss: 0.00001954
Iteration 73/1000 | Loss: 0.00001954
Iteration 74/1000 | Loss: 0.00001953
Iteration 75/1000 | Loss: 0.00001953
Iteration 76/1000 | Loss: 0.00001953
Iteration 77/1000 | Loss: 0.00001953
Iteration 78/1000 | Loss: 0.00001952
Iteration 79/1000 | Loss: 0.00001952
Iteration 80/1000 | Loss: 0.00001952
Iteration 81/1000 | Loss: 0.00001952
Iteration 82/1000 | Loss: 0.00001952
Iteration 83/1000 | Loss: 0.00001952
Iteration 84/1000 | Loss: 0.00001952
Iteration 85/1000 | Loss: 0.00001952
Iteration 86/1000 | Loss: 0.00001952
Iteration 87/1000 | Loss: 0.00001952
Iteration 88/1000 | Loss: 0.00001951
Iteration 89/1000 | Loss: 0.00001951
Iteration 90/1000 | Loss: 0.00001951
Iteration 91/1000 | Loss: 0.00001950
Iteration 92/1000 | Loss: 0.00001950
Iteration 93/1000 | Loss: 0.00001950
Iteration 94/1000 | Loss: 0.00001950
Iteration 95/1000 | Loss: 0.00001950
Iteration 96/1000 | Loss: 0.00001950
Iteration 97/1000 | Loss: 0.00001949
Iteration 98/1000 | Loss: 0.00001949
Iteration 99/1000 | Loss: 0.00001949
Iteration 100/1000 | Loss: 0.00001949
Iteration 101/1000 | Loss: 0.00001948
Iteration 102/1000 | Loss: 0.00001948
Iteration 103/1000 | Loss: 0.00001948
Iteration 104/1000 | Loss: 0.00001948
Iteration 105/1000 | Loss: 0.00001948
Iteration 106/1000 | Loss: 0.00001948
Iteration 107/1000 | Loss: 0.00001948
Iteration 108/1000 | Loss: 0.00001948
Iteration 109/1000 | Loss: 0.00001947
Iteration 110/1000 | Loss: 0.00001947
Iteration 111/1000 | Loss: 0.00001947
Iteration 112/1000 | Loss: 0.00001947
Iteration 113/1000 | Loss: 0.00001947
Iteration 114/1000 | Loss: 0.00001947
Iteration 115/1000 | Loss: 0.00001947
Iteration 116/1000 | Loss: 0.00001947
Iteration 117/1000 | Loss: 0.00001947
Iteration 118/1000 | Loss: 0.00001947
Iteration 119/1000 | Loss: 0.00001947
Iteration 120/1000 | Loss: 0.00001947
Iteration 121/1000 | Loss: 0.00001947
Iteration 122/1000 | Loss: 0.00001947
Iteration 123/1000 | Loss: 0.00001947
Iteration 124/1000 | Loss: 0.00001946
Iteration 125/1000 | Loss: 0.00001946
Iteration 126/1000 | Loss: 0.00001946
Iteration 127/1000 | Loss: 0.00001946
Iteration 128/1000 | Loss: 0.00001946
Iteration 129/1000 | Loss: 0.00001946
Iteration 130/1000 | Loss: 0.00001946
Iteration 131/1000 | Loss: 0.00001946
Iteration 132/1000 | Loss: 0.00001946
Iteration 133/1000 | Loss: 0.00001946
Iteration 134/1000 | Loss: 0.00001945
Iteration 135/1000 | Loss: 0.00001945
Iteration 136/1000 | Loss: 0.00001945
Iteration 137/1000 | Loss: 0.00001945
Iteration 138/1000 | Loss: 0.00001945
Iteration 139/1000 | Loss: 0.00001945
Iteration 140/1000 | Loss: 0.00001945
Iteration 141/1000 | Loss: 0.00001945
Iteration 142/1000 | Loss: 0.00001945
Iteration 143/1000 | Loss: 0.00001945
Iteration 144/1000 | Loss: 0.00001945
Iteration 145/1000 | Loss: 0.00001945
Iteration 146/1000 | Loss: 0.00001945
Iteration 147/1000 | Loss: 0.00001945
Iteration 148/1000 | Loss: 0.00001945
Iteration 149/1000 | Loss: 0.00001945
Iteration 150/1000 | Loss: 0.00001945
Iteration 151/1000 | Loss: 0.00001945
Iteration 152/1000 | Loss: 0.00001945
Iteration 153/1000 | Loss: 0.00001945
Iteration 154/1000 | Loss: 0.00001945
Iteration 155/1000 | Loss: 0.00001945
Iteration 156/1000 | Loss: 0.00001945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.944597352121491e-05, 1.944597352121491e-05, 1.944597352121491e-05, 1.944597352121491e-05, 1.944597352121491e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.944597352121491e-05

Optimization complete. Final v2v error: 3.720102310180664 mm

Highest mean error: 4.743988990783691 mm for frame 39

Lowest mean error: 3.148002862930298 mm for frame 200

Saving results

Total time: 76.85585260391235
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1081/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1081.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1081
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00691615
Iteration 2/25 | Loss: 0.00107865
Iteration 3/25 | Loss: 0.00091499
Iteration 4/25 | Loss: 0.00089578
Iteration 5/25 | Loss: 0.00088844
Iteration 6/25 | Loss: 0.00088613
Iteration 7/25 | Loss: 0.00088571
Iteration 8/25 | Loss: 0.00088571
Iteration 9/25 | Loss: 0.00088571
Iteration 10/25 | Loss: 0.00088571
Iteration 11/25 | Loss: 0.00088571
Iteration 12/25 | Loss: 0.00088571
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000885712041053921, 0.000885712041053921, 0.000885712041053921, 0.000885712041053921, 0.000885712041053921]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000885712041053921

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.25206351
Iteration 2/25 | Loss: 0.00106460
Iteration 3/25 | Loss: 0.00106456
Iteration 4/25 | Loss: 0.00106456
Iteration 5/25 | Loss: 0.00106456
Iteration 6/25 | Loss: 0.00106456
Iteration 7/25 | Loss: 0.00106456
Iteration 8/25 | Loss: 0.00106456
Iteration 9/25 | Loss: 0.00106456
Iteration 10/25 | Loss: 0.00106456
Iteration 11/25 | Loss: 0.00106456
Iteration 12/25 | Loss: 0.00106456
Iteration 13/25 | Loss: 0.00106456
Iteration 14/25 | Loss: 0.00106456
Iteration 15/25 | Loss: 0.00106456
Iteration 16/25 | Loss: 0.00106456
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001064556883648038, 0.001064556883648038, 0.001064556883648038, 0.001064556883648038, 0.001064556883648038]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001064556883648038

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00106456
Iteration 2/1000 | Loss: 0.00004274
Iteration 3/1000 | Loss: 0.00002381
Iteration 4/1000 | Loss: 0.00002136
Iteration 5/1000 | Loss: 0.00002020
Iteration 6/1000 | Loss: 0.00001976
Iteration 7/1000 | Loss: 0.00001941
Iteration 8/1000 | Loss: 0.00001913
Iteration 9/1000 | Loss: 0.00001906
Iteration 10/1000 | Loss: 0.00001900
Iteration 11/1000 | Loss: 0.00001890
Iteration 12/1000 | Loss: 0.00001888
Iteration 13/1000 | Loss: 0.00001883
Iteration 14/1000 | Loss: 0.00001881
Iteration 15/1000 | Loss: 0.00001880
Iteration 16/1000 | Loss: 0.00001880
Iteration 17/1000 | Loss: 0.00001879
Iteration 18/1000 | Loss: 0.00001878
Iteration 19/1000 | Loss: 0.00001878
Iteration 20/1000 | Loss: 0.00001878
Iteration 21/1000 | Loss: 0.00001873
Iteration 22/1000 | Loss: 0.00001869
Iteration 23/1000 | Loss: 0.00001869
Iteration 24/1000 | Loss: 0.00001868
Iteration 25/1000 | Loss: 0.00001867
Iteration 26/1000 | Loss: 0.00001867
Iteration 27/1000 | Loss: 0.00001866
Iteration 28/1000 | Loss: 0.00001866
Iteration 29/1000 | Loss: 0.00001866
Iteration 30/1000 | Loss: 0.00001865
Iteration 31/1000 | Loss: 0.00001865
Iteration 32/1000 | Loss: 0.00001865
Iteration 33/1000 | Loss: 0.00001864
Iteration 34/1000 | Loss: 0.00001864
Iteration 35/1000 | Loss: 0.00001864
Iteration 36/1000 | Loss: 0.00001864
Iteration 37/1000 | Loss: 0.00001864
Iteration 38/1000 | Loss: 0.00001864
Iteration 39/1000 | Loss: 0.00001864
Iteration 40/1000 | Loss: 0.00001864
Iteration 41/1000 | Loss: 0.00001864
Iteration 42/1000 | Loss: 0.00001864
Iteration 43/1000 | Loss: 0.00001864
Iteration 44/1000 | Loss: 0.00001864
Iteration 45/1000 | Loss: 0.00001864
Iteration 46/1000 | Loss: 0.00001864
Iteration 47/1000 | Loss: 0.00001864
Iteration 48/1000 | Loss: 0.00001864
Iteration 49/1000 | Loss: 0.00001864
Iteration 50/1000 | Loss: 0.00001864
Iteration 51/1000 | Loss: 0.00001864
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 51. Stopping optimization.
Last 5 losses: [1.8639309928403236e-05, 1.8639309928403236e-05, 1.8639309928403236e-05, 1.8639309928403236e-05, 1.8639309928403236e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8639309928403236e-05

Optimization complete. Final v2v error: 3.6544055938720703 mm

Highest mean error: 4.197690010070801 mm for frame 61

Lowest mean error: 3.3599166870117188 mm for frame 4

Saving results

Total time: 29.894867181777954
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1035/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1035.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1035
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01102275
Iteration 2/25 | Loss: 0.00289916
Iteration 3/25 | Loss: 0.00167009
Iteration 4/25 | Loss: 0.00149993
Iteration 5/25 | Loss: 0.00121370
Iteration 6/25 | Loss: 0.00121904
Iteration 7/25 | Loss: 0.00118606
Iteration 8/25 | Loss: 0.00111988
Iteration 9/25 | Loss: 0.00103640
Iteration 10/25 | Loss: 0.00100204
Iteration 11/25 | Loss: 0.00098070
Iteration 12/25 | Loss: 0.00094766
Iteration 13/25 | Loss: 0.00094027
Iteration 14/25 | Loss: 0.00093410
Iteration 15/25 | Loss: 0.00093047
Iteration 16/25 | Loss: 0.00093239
Iteration 17/25 | Loss: 0.00092797
Iteration 18/25 | Loss: 0.00092026
Iteration 19/25 | Loss: 0.00092036
Iteration 20/25 | Loss: 0.00091750
Iteration 21/25 | Loss: 0.00091849
Iteration 22/25 | Loss: 0.00091517
Iteration 23/25 | Loss: 0.00091393
Iteration 24/25 | Loss: 0.00091609
Iteration 25/25 | Loss: 0.00091406

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61934257
Iteration 2/25 | Loss: 0.00211283
Iteration 3/25 | Loss: 0.00166241
Iteration 4/25 | Loss: 0.00166241
Iteration 5/25 | Loss: 0.00166241
Iteration 6/25 | Loss: 0.00166241
Iteration 7/25 | Loss: 0.00166241
Iteration 8/25 | Loss: 0.00166241
Iteration 9/25 | Loss: 0.00166241
Iteration 10/25 | Loss: 0.00166241
Iteration 11/25 | Loss: 0.00166241
Iteration 12/25 | Loss: 0.00166241
Iteration 13/25 | Loss: 0.00166241
Iteration 14/25 | Loss: 0.00166241
Iteration 15/25 | Loss: 0.00166241
Iteration 16/25 | Loss: 0.00166241
Iteration 17/25 | Loss: 0.00166241
Iteration 18/25 | Loss: 0.00166241
Iteration 19/25 | Loss: 0.00166241
Iteration 20/25 | Loss: 0.00166241
Iteration 21/25 | Loss: 0.00166241
Iteration 22/25 | Loss: 0.00166241
Iteration 23/25 | Loss: 0.00166241
Iteration 24/25 | Loss: 0.00166241
Iteration 25/25 | Loss: 0.00166241

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00166241
Iteration 2/1000 | Loss: 0.00031395
Iteration 3/1000 | Loss: 0.00011783
Iteration 4/1000 | Loss: 0.00019285
Iteration 5/1000 | Loss: 0.00008194
Iteration 6/1000 | Loss: 0.00119548
Iteration 7/1000 | Loss: 0.00191341
Iteration 8/1000 | Loss: 0.00064878
Iteration 9/1000 | Loss: 0.00014483
Iteration 10/1000 | Loss: 0.00008594
Iteration 11/1000 | Loss: 0.00005858
Iteration 12/1000 | Loss: 0.00074653
Iteration 13/1000 | Loss: 0.00014969
Iteration 14/1000 | Loss: 0.00005543
Iteration 15/1000 | Loss: 0.00004811
Iteration 16/1000 | Loss: 0.00008410
Iteration 17/1000 | Loss: 0.00012613
Iteration 18/1000 | Loss: 0.00045520
Iteration 19/1000 | Loss: 0.00010882
Iteration 20/1000 | Loss: 0.00004101
Iteration 21/1000 | Loss: 0.00019048
Iteration 22/1000 | Loss: 0.00004578
Iteration 23/1000 | Loss: 0.00003596
Iteration 24/1000 | Loss: 0.00021454
Iteration 25/1000 | Loss: 0.00060968
Iteration 26/1000 | Loss: 0.00038437
Iteration 27/1000 | Loss: 0.00043185
Iteration 28/1000 | Loss: 0.00004333
Iteration 29/1000 | Loss: 0.00003271
Iteration 30/1000 | Loss: 0.00002964
Iteration 31/1000 | Loss: 0.00002872
Iteration 32/1000 | Loss: 0.00077153
Iteration 33/1000 | Loss: 0.00006156
Iteration 34/1000 | Loss: 0.00003116
Iteration 35/1000 | Loss: 0.00002834
Iteration 36/1000 | Loss: 0.00002689
Iteration 37/1000 | Loss: 0.00002545
Iteration 38/1000 | Loss: 0.00002456
Iteration 39/1000 | Loss: 0.00002375
Iteration 40/1000 | Loss: 0.00002344
Iteration 41/1000 | Loss: 0.00014324
Iteration 42/1000 | Loss: 0.00002666
Iteration 43/1000 | Loss: 0.00002334
Iteration 44/1000 | Loss: 0.00002289
Iteration 45/1000 | Loss: 0.00002288
Iteration 46/1000 | Loss: 0.00002284
Iteration 47/1000 | Loss: 0.00002283
Iteration 48/1000 | Loss: 0.00002283
Iteration 49/1000 | Loss: 0.00002280
Iteration 50/1000 | Loss: 0.00002279
Iteration 51/1000 | Loss: 0.00002278
Iteration 52/1000 | Loss: 0.00002277
Iteration 53/1000 | Loss: 0.00002275
Iteration 54/1000 | Loss: 0.00002273
Iteration 55/1000 | Loss: 0.00012696
Iteration 56/1000 | Loss: 0.00002462
Iteration 57/1000 | Loss: 0.00004645
Iteration 58/1000 | Loss: 0.00002976
Iteration 59/1000 | Loss: 0.00006226
Iteration 60/1000 | Loss: 0.00002261
Iteration 61/1000 | Loss: 0.00002250
Iteration 62/1000 | Loss: 0.00002247
Iteration 63/1000 | Loss: 0.00002243
Iteration 64/1000 | Loss: 0.00002243
Iteration 65/1000 | Loss: 0.00002242
Iteration 66/1000 | Loss: 0.00002242
Iteration 67/1000 | Loss: 0.00002241
Iteration 68/1000 | Loss: 0.00002238
Iteration 69/1000 | Loss: 0.00002238
Iteration 70/1000 | Loss: 0.00002237
Iteration 71/1000 | Loss: 0.00002236
Iteration 72/1000 | Loss: 0.00002236
Iteration 73/1000 | Loss: 0.00002236
Iteration 74/1000 | Loss: 0.00002236
Iteration 75/1000 | Loss: 0.00002236
Iteration 76/1000 | Loss: 0.00002236
Iteration 77/1000 | Loss: 0.00002236
Iteration 78/1000 | Loss: 0.00002236
Iteration 79/1000 | Loss: 0.00002235
Iteration 80/1000 | Loss: 0.00002235
Iteration 81/1000 | Loss: 0.00002235
Iteration 82/1000 | Loss: 0.00002235
Iteration 83/1000 | Loss: 0.00002235
Iteration 84/1000 | Loss: 0.00002235
Iteration 85/1000 | Loss: 0.00002235
Iteration 86/1000 | Loss: 0.00002234
Iteration 87/1000 | Loss: 0.00002234
Iteration 88/1000 | Loss: 0.00002233
Iteration 89/1000 | Loss: 0.00002233
Iteration 90/1000 | Loss: 0.00002233
Iteration 91/1000 | Loss: 0.00002232
Iteration 92/1000 | Loss: 0.00002232
Iteration 93/1000 | Loss: 0.00002232
Iteration 94/1000 | Loss: 0.00002232
Iteration 95/1000 | Loss: 0.00002231
Iteration 96/1000 | Loss: 0.00002231
Iteration 97/1000 | Loss: 0.00002230
Iteration 98/1000 | Loss: 0.00002230
Iteration 99/1000 | Loss: 0.00002230
Iteration 100/1000 | Loss: 0.00002230
Iteration 101/1000 | Loss: 0.00002229
Iteration 102/1000 | Loss: 0.00002229
Iteration 103/1000 | Loss: 0.00002229
Iteration 104/1000 | Loss: 0.00002229
Iteration 105/1000 | Loss: 0.00002229
Iteration 106/1000 | Loss: 0.00002229
Iteration 107/1000 | Loss: 0.00002229
Iteration 108/1000 | Loss: 0.00002229
Iteration 109/1000 | Loss: 0.00002229
Iteration 110/1000 | Loss: 0.00002229
Iteration 111/1000 | Loss: 0.00002229
Iteration 112/1000 | Loss: 0.00002228
Iteration 113/1000 | Loss: 0.00002228
Iteration 114/1000 | Loss: 0.00002228
Iteration 115/1000 | Loss: 0.00002228
Iteration 116/1000 | Loss: 0.00002228
Iteration 117/1000 | Loss: 0.00002228
Iteration 118/1000 | Loss: 0.00002228
Iteration 119/1000 | Loss: 0.00002228
Iteration 120/1000 | Loss: 0.00002228
Iteration 121/1000 | Loss: 0.00002227
Iteration 122/1000 | Loss: 0.00002227
Iteration 123/1000 | Loss: 0.00002227
Iteration 124/1000 | Loss: 0.00002227
Iteration 125/1000 | Loss: 0.00002227
Iteration 126/1000 | Loss: 0.00002227
Iteration 127/1000 | Loss: 0.00002227
Iteration 128/1000 | Loss: 0.00002227
Iteration 129/1000 | Loss: 0.00002227
Iteration 130/1000 | Loss: 0.00002227
Iteration 131/1000 | Loss: 0.00002226
Iteration 132/1000 | Loss: 0.00002226
Iteration 133/1000 | Loss: 0.00002226
Iteration 134/1000 | Loss: 0.00002226
Iteration 135/1000 | Loss: 0.00002226
Iteration 136/1000 | Loss: 0.00002226
Iteration 137/1000 | Loss: 0.00002225
Iteration 138/1000 | Loss: 0.00002225
Iteration 139/1000 | Loss: 0.00002225
Iteration 140/1000 | Loss: 0.00002225
Iteration 141/1000 | Loss: 0.00002225
Iteration 142/1000 | Loss: 0.00002225
Iteration 143/1000 | Loss: 0.00002224
Iteration 144/1000 | Loss: 0.00002224
Iteration 145/1000 | Loss: 0.00002224
Iteration 146/1000 | Loss: 0.00002224
Iteration 147/1000 | Loss: 0.00002224
Iteration 148/1000 | Loss: 0.00002224
Iteration 149/1000 | Loss: 0.00002223
Iteration 150/1000 | Loss: 0.00002222
Iteration 151/1000 | Loss: 0.00002222
Iteration 152/1000 | Loss: 0.00002222
Iteration 153/1000 | Loss: 0.00002221
Iteration 154/1000 | Loss: 0.00002221
Iteration 155/1000 | Loss: 0.00002221
Iteration 156/1000 | Loss: 0.00002220
Iteration 157/1000 | Loss: 0.00002220
Iteration 158/1000 | Loss: 0.00002220
Iteration 159/1000 | Loss: 0.00002220
Iteration 160/1000 | Loss: 0.00002220
Iteration 161/1000 | Loss: 0.00002220
Iteration 162/1000 | Loss: 0.00002220
Iteration 163/1000 | Loss: 0.00002220
Iteration 164/1000 | Loss: 0.00002220
Iteration 165/1000 | Loss: 0.00002220
Iteration 166/1000 | Loss: 0.00002219
Iteration 167/1000 | Loss: 0.00002219
Iteration 168/1000 | Loss: 0.00002219
Iteration 169/1000 | Loss: 0.00002219
Iteration 170/1000 | Loss: 0.00002219
Iteration 171/1000 | Loss: 0.00002219
Iteration 172/1000 | Loss: 0.00002218
Iteration 173/1000 | Loss: 0.00002218
Iteration 174/1000 | Loss: 0.00002218
Iteration 175/1000 | Loss: 0.00002218
Iteration 176/1000 | Loss: 0.00002218
Iteration 177/1000 | Loss: 0.00002218
Iteration 178/1000 | Loss: 0.00002217
Iteration 179/1000 | Loss: 0.00002217
Iteration 180/1000 | Loss: 0.00002217
Iteration 181/1000 | Loss: 0.00002217
Iteration 182/1000 | Loss: 0.00002217
Iteration 183/1000 | Loss: 0.00002217
Iteration 184/1000 | Loss: 0.00014101
Iteration 185/1000 | Loss: 0.00002711
Iteration 186/1000 | Loss: 0.00009836
Iteration 187/1000 | Loss: 0.00002289
Iteration 188/1000 | Loss: 0.00004710
Iteration 189/1000 | Loss: 0.00002622
Iteration 190/1000 | Loss: 0.00003694
Iteration 191/1000 | Loss: 0.00002228
Iteration 192/1000 | Loss: 0.00002223
Iteration 193/1000 | Loss: 0.00002222
Iteration 194/1000 | Loss: 0.00002219
Iteration 195/1000 | Loss: 0.00002217
Iteration 196/1000 | Loss: 0.00002217
Iteration 197/1000 | Loss: 0.00002216
Iteration 198/1000 | Loss: 0.00002216
Iteration 199/1000 | Loss: 0.00002212
Iteration 200/1000 | Loss: 0.00002211
Iteration 201/1000 | Loss: 0.00002211
Iteration 202/1000 | Loss: 0.00002211
Iteration 203/1000 | Loss: 0.00002210
Iteration 204/1000 | Loss: 0.00002210
Iteration 205/1000 | Loss: 0.00002210
Iteration 206/1000 | Loss: 0.00002210
Iteration 207/1000 | Loss: 0.00002210
Iteration 208/1000 | Loss: 0.00002209
Iteration 209/1000 | Loss: 0.00002209
Iteration 210/1000 | Loss: 0.00002209
Iteration 211/1000 | Loss: 0.00002209
Iteration 212/1000 | Loss: 0.00002209
Iteration 213/1000 | Loss: 0.00002209
Iteration 214/1000 | Loss: 0.00002209
Iteration 215/1000 | Loss: 0.00002209
Iteration 216/1000 | Loss: 0.00002209
Iteration 217/1000 | Loss: 0.00002209
Iteration 218/1000 | Loss: 0.00002209
Iteration 219/1000 | Loss: 0.00002209
Iteration 220/1000 | Loss: 0.00002209
Iteration 221/1000 | Loss: 0.00002209
Iteration 222/1000 | Loss: 0.00002209
Iteration 223/1000 | Loss: 0.00002208
Iteration 224/1000 | Loss: 0.00002208
Iteration 225/1000 | Loss: 0.00002208
Iteration 226/1000 | Loss: 0.00002208
Iteration 227/1000 | Loss: 0.00002208
Iteration 228/1000 | Loss: 0.00002208
Iteration 229/1000 | Loss: 0.00002208
Iteration 230/1000 | Loss: 0.00002208
Iteration 231/1000 | Loss: 0.00002208
Iteration 232/1000 | Loss: 0.00002208
Iteration 233/1000 | Loss: 0.00002208
Iteration 234/1000 | Loss: 0.00002208
Iteration 235/1000 | Loss: 0.00002208
Iteration 236/1000 | Loss: 0.00002208
Iteration 237/1000 | Loss: 0.00002208
Iteration 238/1000 | Loss: 0.00002208
Iteration 239/1000 | Loss: 0.00002208
Iteration 240/1000 | Loss: 0.00002208
Iteration 241/1000 | Loss: 0.00002208
Iteration 242/1000 | Loss: 0.00002208
Iteration 243/1000 | Loss: 0.00002208
Iteration 244/1000 | Loss: 0.00002208
Iteration 245/1000 | Loss: 0.00002207
Iteration 246/1000 | Loss: 0.00002207
Iteration 247/1000 | Loss: 0.00002207
Iteration 248/1000 | Loss: 0.00002207
Iteration 249/1000 | Loss: 0.00002207
Iteration 250/1000 | Loss: 0.00002207
Iteration 251/1000 | Loss: 0.00002207
Iteration 252/1000 | Loss: 0.00002207
Iteration 253/1000 | Loss: 0.00002207
Iteration 254/1000 | Loss: 0.00002207
Iteration 255/1000 | Loss: 0.00002207
Iteration 256/1000 | Loss: 0.00002207
Iteration 257/1000 | Loss: 0.00002207
Iteration 258/1000 | Loss: 0.00002207
Iteration 259/1000 | Loss: 0.00002207
Iteration 260/1000 | Loss: 0.00002207
Iteration 261/1000 | Loss: 0.00002207
Iteration 262/1000 | Loss: 0.00002207
Iteration 263/1000 | Loss: 0.00002207
Iteration 264/1000 | Loss: 0.00002207
Iteration 265/1000 | Loss: 0.00002207
Iteration 266/1000 | Loss: 0.00002207
Iteration 267/1000 | Loss: 0.00002207
Iteration 268/1000 | Loss: 0.00002207
Iteration 269/1000 | Loss: 0.00002207
Iteration 270/1000 | Loss: 0.00002207
Iteration 271/1000 | Loss: 0.00002207
Iteration 272/1000 | Loss: 0.00002207
Iteration 273/1000 | Loss: 0.00002207
Iteration 274/1000 | Loss: 0.00002207
Iteration 275/1000 | Loss: 0.00002207
Iteration 276/1000 | Loss: 0.00002207
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 276. Stopping optimization.
Last 5 losses: [2.206872886745259e-05, 2.206872886745259e-05, 2.206872886745259e-05, 2.206872886745259e-05, 2.206872886745259e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.206872886745259e-05

Optimization complete. Final v2v error: 3.865694046020508 mm

Highest mean error: 8.81675910949707 mm for frame 50

Lowest mean error: 3.3390822410583496 mm for frame 170

Saving results

Total time: 167.8297200202942
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1026/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1026.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1026
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00423980
Iteration 2/25 | Loss: 0.00093330
Iteration 3/25 | Loss: 0.00082038
Iteration 4/25 | Loss: 0.00079013
Iteration 5/25 | Loss: 0.00078162
Iteration 6/25 | Loss: 0.00077970
Iteration 7/25 | Loss: 0.00077899
Iteration 8/25 | Loss: 0.00077894
Iteration 9/25 | Loss: 0.00077894
Iteration 10/25 | Loss: 0.00077894
Iteration 11/25 | Loss: 0.00077894
Iteration 12/25 | Loss: 0.00077894
Iteration 13/25 | Loss: 0.00077894
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.000778936839196831, 0.000778936839196831, 0.000778936839196831, 0.000778936839196831, 0.000778936839196831]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000778936839196831

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.01117873
Iteration 2/25 | Loss: 0.00122370
Iteration 3/25 | Loss: 0.00122370
Iteration 4/25 | Loss: 0.00122370
Iteration 5/25 | Loss: 0.00122370
Iteration 6/25 | Loss: 0.00122370
Iteration 7/25 | Loss: 0.00122370
Iteration 8/25 | Loss: 0.00122370
Iteration 9/25 | Loss: 0.00122370
Iteration 10/25 | Loss: 0.00122370
Iteration 11/25 | Loss: 0.00122370
Iteration 12/25 | Loss: 0.00122370
Iteration 13/25 | Loss: 0.00122370
Iteration 14/25 | Loss: 0.00122370
Iteration 15/25 | Loss: 0.00122370
Iteration 16/25 | Loss: 0.00122370
Iteration 17/25 | Loss: 0.00122370
Iteration 18/25 | Loss: 0.00122370
Iteration 19/25 | Loss: 0.00122370
Iteration 20/25 | Loss: 0.00122370
Iteration 21/25 | Loss: 0.00122370
Iteration 22/25 | Loss: 0.00122370
Iteration 23/25 | Loss: 0.00122370
Iteration 24/25 | Loss: 0.00122370
Iteration 25/25 | Loss: 0.00122370

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00122370
Iteration 2/1000 | Loss: 0.00003360
Iteration 3/1000 | Loss: 0.00002236
Iteration 4/1000 | Loss: 0.00002084
Iteration 5/1000 | Loss: 0.00001968
Iteration 6/1000 | Loss: 0.00001913
Iteration 7/1000 | Loss: 0.00001866
Iteration 8/1000 | Loss: 0.00001830
Iteration 9/1000 | Loss: 0.00001810
Iteration 10/1000 | Loss: 0.00001798
Iteration 11/1000 | Loss: 0.00001791
Iteration 12/1000 | Loss: 0.00001791
Iteration 13/1000 | Loss: 0.00001787
Iteration 14/1000 | Loss: 0.00001786
Iteration 15/1000 | Loss: 0.00001785
Iteration 16/1000 | Loss: 0.00001785
Iteration 17/1000 | Loss: 0.00001785
Iteration 18/1000 | Loss: 0.00001784
Iteration 19/1000 | Loss: 0.00001784
Iteration 20/1000 | Loss: 0.00001783
Iteration 21/1000 | Loss: 0.00001782
Iteration 22/1000 | Loss: 0.00001779
Iteration 23/1000 | Loss: 0.00001777
Iteration 24/1000 | Loss: 0.00001777
Iteration 25/1000 | Loss: 0.00001777
Iteration 26/1000 | Loss: 0.00001777
Iteration 27/1000 | Loss: 0.00001777
Iteration 28/1000 | Loss: 0.00001776
Iteration 29/1000 | Loss: 0.00001776
Iteration 30/1000 | Loss: 0.00001776
Iteration 31/1000 | Loss: 0.00001776
Iteration 32/1000 | Loss: 0.00001776
Iteration 33/1000 | Loss: 0.00001776
Iteration 34/1000 | Loss: 0.00001776
Iteration 35/1000 | Loss: 0.00001776
Iteration 36/1000 | Loss: 0.00001776
Iteration 37/1000 | Loss: 0.00001776
Iteration 38/1000 | Loss: 0.00001776
Iteration 39/1000 | Loss: 0.00001776
Iteration 40/1000 | Loss: 0.00001776
Iteration 41/1000 | Loss: 0.00001776
Iteration 42/1000 | Loss: 0.00001776
Iteration 43/1000 | Loss: 0.00001776
Iteration 44/1000 | Loss: 0.00001776
Iteration 45/1000 | Loss: 0.00001776
Iteration 46/1000 | Loss: 0.00001776
Iteration 47/1000 | Loss: 0.00001776
Iteration 48/1000 | Loss: 0.00001776
Iteration 49/1000 | Loss: 0.00001776
Iteration 50/1000 | Loss: 0.00001776
Iteration 51/1000 | Loss: 0.00001776
Iteration 52/1000 | Loss: 0.00001776
Iteration 53/1000 | Loss: 0.00001776
Iteration 54/1000 | Loss: 0.00001776
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 54. Stopping optimization.
Last 5 losses: [1.7755519365891814e-05, 1.7755519365891814e-05, 1.7755519365891814e-05, 1.7755519365891814e-05, 1.7755519365891814e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7755519365891814e-05

Optimization complete. Final v2v error: 3.541795015335083 mm

Highest mean error: 4.1579437255859375 mm for frame 106

Lowest mean error: 3.354592800140381 mm for frame 130

Saving results

Total time: 29.097688674926758
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00557522
Iteration 2/25 | Loss: 0.00105570
Iteration 3/25 | Loss: 0.00086734
Iteration 4/25 | Loss: 0.00080892
Iteration 5/25 | Loss: 0.00079943
Iteration 6/25 | Loss: 0.00079787
Iteration 7/25 | Loss: 0.00079769
Iteration 8/25 | Loss: 0.00079769
Iteration 9/25 | Loss: 0.00079769
Iteration 10/25 | Loss: 0.00079769
Iteration 11/25 | Loss: 0.00079769
Iteration 12/25 | Loss: 0.00079769
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007976919878274202, 0.0007976919878274202, 0.0007976919878274202, 0.0007976919878274202, 0.0007976919878274202]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007976919878274202

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.16781235
Iteration 2/25 | Loss: 0.00127172
Iteration 3/25 | Loss: 0.00127171
Iteration 4/25 | Loss: 0.00127171
Iteration 5/25 | Loss: 0.00127171
Iteration 6/25 | Loss: 0.00127171
Iteration 7/25 | Loss: 0.00127171
Iteration 8/25 | Loss: 0.00127171
Iteration 9/25 | Loss: 0.00127171
Iteration 10/25 | Loss: 0.00127171
Iteration 11/25 | Loss: 0.00127171
Iteration 12/25 | Loss: 0.00127171
Iteration 13/25 | Loss: 0.00127171
Iteration 14/25 | Loss: 0.00127171
Iteration 15/25 | Loss: 0.00127171
Iteration 16/25 | Loss: 0.00127171
Iteration 17/25 | Loss: 0.00127171
Iteration 18/25 | Loss: 0.00127171
Iteration 19/25 | Loss: 0.00127171
Iteration 20/25 | Loss: 0.00127171
Iteration 21/25 | Loss: 0.00127171
Iteration 22/25 | Loss: 0.00127171
Iteration 23/25 | Loss: 0.00127171
Iteration 24/25 | Loss: 0.00127171
Iteration 25/25 | Loss: 0.00127171

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00127171
Iteration 2/1000 | Loss: 0.00004228
Iteration 3/1000 | Loss: 0.00002663
Iteration 4/1000 | Loss: 0.00002484
Iteration 5/1000 | Loss: 0.00002312
Iteration 6/1000 | Loss: 0.00002257
Iteration 7/1000 | Loss: 0.00002194
Iteration 8/1000 | Loss: 0.00002151
Iteration 9/1000 | Loss: 0.00002122
Iteration 10/1000 | Loss: 0.00002099
Iteration 11/1000 | Loss: 0.00002098
Iteration 12/1000 | Loss: 0.00002084
Iteration 13/1000 | Loss: 0.00002083
Iteration 14/1000 | Loss: 0.00002080
Iteration 15/1000 | Loss: 0.00002075
Iteration 16/1000 | Loss: 0.00002071
Iteration 17/1000 | Loss: 0.00002071
Iteration 18/1000 | Loss: 0.00002068
Iteration 19/1000 | Loss: 0.00002068
Iteration 20/1000 | Loss: 0.00002068
Iteration 21/1000 | Loss: 0.00002068
Iteration 22/1000 | Loss: 0.00002067
Iteration 23/1000 | Loss: 0.00002067
Iteration 24/1000 | Loss: 0.00002065
Iteration 25/1000 | Loss: 0.00002065
Iteration 26/1000 | Loss: 0.00002065
Iteration 27/1000 | Loss: 0.00002065
Iteration 28/1000 | Loss: 0.00002064
Iteration 29/1000 | Loss: 0.00002064
Iteration 30/1000 | Loss: 0.00002064
Iteration 31/1000 | Loss: 0.00002064
Iteration 32/1000 | Loss: 0.00002064
Iteration 33/1000 | Loss: 0.00002063
Iteration 34/1000 | Loss: 0.00002062
Iteration 35/1000 | Loss: 0.00002062
Iteration 36/1000 | Loss: 0.00002062
Iteration 37/1000 | Loss: 0.00002061
Iteration 38/1000 | Loss: 0.00002061
Iteration 39/1000 | Loss: 0.00002061
Iteration 40/1000 | Loss: 0.00002061
Iteration 41/1000 | Loss: 0.00002061
Iteration 42/1000 | Loss: 0.00002061
Iteration 43/1000 | Loss: 0.00002061
Iteration 44/1000 | Loss: 0.00002060
Iteration 45/1000 | Loss: 0.00002060
Iteration 46/1000 | Loss: 0.00002060
Iteration 47/1000 | Loss: 0.00002060
Iteration 48/1000 | Loss: 0.00002060
Iteration 49/1000 | Loss: 0.00002059
Iteration 50/1000 | Loss: 0.00002059
Iteration 51/1000 | Loss: 0.00002059
Iteration 52/1000 | Loss: 0.00002058
Iteration 53/1000 | Loss: 0.00002058
Iteration 54/1000 | Loss: 0.00002057
Iteration 55/1000 | Loss: 0.00002057
Iteration 56/1000 | Loss: 0.00002057
Iteration 57/1000 | Loss: 0.00002057
Iteration 58/1000 | Loss: 0.00002057
Iteration 59/1000 | Loss: 0.00002056
Iteration 60/1000 | Loss: 0.00002056
Iteration 61/1000 | Loss: 0.00002056
Iteration 62/1000 | Loss: 0.00002054
Iteration 63/1000 | Loss: 0.00002053
Iteration 64/1000 | Loss: 0.00002053
Iteration 65/1000 | Loss: 0.00002053
Iteration 66/1000 | Loss: 0.00002053
Iteration 67/1000 | Loss: 0.00002052
Iteration 68/1000 | Loss: 0.00002052
Iteration 69/1000 | Loss: 0.00002052
Iteration 70/1000 | Loss: 0.00002052
Iteration 71/1000 | Loss: 0.00002052
Iteration 72/1000 | Loss: 0.00002051
Iteration 73/1000 | Loss: 0.00002051
Iteration 74/1000 | Loss: 0.00002050
Iteration 75/1000 | Loss: 0.00002050
Iteration 76/1000 | Loss: 0.00002049
Iteration 77/1000 | Loss: 0.00002049
Iteration 78/1000 | Loss: 0.00002049
Iteration 79/1000 | Loss: 0.00002049
Iteration 80/1000 | Loss: 0.00002049
Iteration 81/1000 | Loss: 0.00002049
Iteration 82/1000 | Loss: 0.00002049
Iteration 83/1000 | Loss: 0.00002049
Iteration 84/1000 | Loss: 0.00002049
Iteration 85/1000 | Loss: 0.00002049
Iteration 86/1000 | Loss: 0.00002049
Iteration 87/1000 | Loss: 0.00002049
Iteration 88/1000 | Loss: 0.00002049
Iteration 89/1000 | Loss: 0.00002049
Iteration 90/1000 | Loss: 0.00002049
Iteration 91/1000 | Loss: 0.00002049
Iteration 92/1000 | Loss: 0.00002049
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [2.049065733444877e-05, 2.049065733444877e-05, 2.049065733444877e-05, 2.049065733444877e-05, 2.049065733444877e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.049065733444877e-05

Optimization complete. Final v2v error: 3.773526906967163 mm

Highest mean error: 4.301707744598389 mm for frame 194

Lowest mean error: 3.1780126094818115 mm for frame 87

Saving results

Total time: 34.28462052345276
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1069/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1069.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1069
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00830010
Iteration 2/25 | Loss: 0.00127545
Iteration 3/25 | Loss: 0.00093044
Iteration 4/25 | Loss: 0.00085071
Iteration 5/25 | Loss: 0.00083640
Iteration 6/25 | Loss: 0.00083465
Iteration 7/25 | Loss: 0.00083459
Iteration 8/25 | Loss: 0.00083459
Iteration 9/25 | Loss: 0.00083459
Iteration 10/25 | Loss: 0.00083459
Iteration 11/25 | Loss: 0.00083459
Iteration 12/25 | Loss: 0.00083459
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008345897658728063, 0.0008345897658728063, 0.0008345897658728063, 0.0008345897658728063, 0.0008345897658728063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008345897658728063

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61532104
Iteration 2/25 | Loss: 0.00122054
Iteration 3/25 | Loss: 0.00122047
Iteration 4/25 | Loss: 0.00122047
Iteration 5/25 | Loss: 0.00122047
Iteration 6/25 | Loss: 0.00122047
Iteration 7/25 | Loss: 0.00122047
Iteration 8/25 | Loss: 0.00122047
Iteration 9/25 | Loss: 0.00122047
Iteration 10/25 | Loss: 0.00122047
Iteration 11/25 | Loss: 0.00122047
Iteration 12/25 | Loss: 0.00122047
Iteration 13/25 | Loss: 0.00122047
Iteration 14/25 | Loss: 0.00122047
Iteration 15/25 | Loss: 0.00122047
Iteration 16/25 | Loss: 0.00122047
Iteration 17/25 | Loss: 0.00122047
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001220467034727335, 0.001220467034727335, 0.001220467034727335, 0.001220467034727335, 0.001220467034727335]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001220467034727335

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00122047
Iteration 2/1000 | Loss: 0.00005321
Iteration 3/1000 | Loss: 0.00003667
Iteration 4/1000 | Loss: 0.00002755
Iteration 5/1000 | Loss: 0.00002436
Iteration 6/1000 | Loss: 0.00002293
Iteration 7/1000 | Loss: 0.00002195
Iteration 8/1000 | Loss: 0.00002119
Iteration 9/1000 | Loss: 0.00002070
Iteration 10/1000 | Loss: 0.00002020
Iteration 11/1000 | Loss: 0.00001991
Iteration 12/1000 | Loss: 0.00001983
Iteration 13/1000 | Loss: 0.00001958
Iteration 14/1000 | Loss: 0.00001933
Iteration 15/1000 | Loss: 0.00001913
Iteration 16/1000 | Loss: 0.00001910
Iteration 17/1000 | Loss: 0.00001901
Iteration 18/1000 | Loss: 0.00001901
Iteration 19/1000 | Loss: 0.00001890
Iteration 20/1000 | Loss: 0.00001889
Iteration 21/1000 | Loss: 0.00001887
Iteration 22/1000 | Loss: 0.00001886
Iteration 23/1000 | Loss: 0.00001885
Iteration 24/1000 | Loss: 0.00001884
Iteration 25/1000 | Loss: 0.00001884
Iteration 26/1000 | Loss: 0.00001883
Iteration 27/1000 | Loss: 0.00001883
Iteration 28/1000 | Loss: 0.00001883
Iteration 29/1000 | Loss: 0.00001883
Iteration 30/1000 | Loss: 0.00001882
Iteration 31/1000 | Loss: 0.00001874
Iteration 32/1000 | Loss: 0.00001873
Iteration 33/1000 | Loss: 0.00001873
Iteration 34/1000 | Loss: 0.00001872
Iteration 35/1000 | Loss: 0.00001872
Iteration 36/1000 | Loss: 0.00001871
Iteration 37/1000 | Loss: 0.00001871
Iteration 38/1000 | Loss: 0.00001871
Iteration 39/1000 | Loss: 0.00001870
Iteration 40/1000 | Loss: 0.00001870
Iteration 41/1000 | Loss: 0.00001870
Iteration 42/1000 | Loss: 0.00001870
Iteration 43/1000 | Loss: 0.00001869
Iteration 44/1000 | Loss: 0.00001869
Iteration 45/1000 | Loss: 0.00001868
Iteration 46/1000 | Loss: 0.00001868
Iteration 47/1000 | Loss: 0.00001867
Iteration 48/1000 | Loss: 0.00001867
Iteration 49/1000 | Loss: 0.00001866
Iteration 50/1000 | Loss: 0.00001866
Iteration 51/1000 | Loss: 0.00001866
Iteration 52/1000 | Loss: 0.00001866
Iteration 53/1000 | Loss: 0.00001865
Iteration 54/1000 | Loss: 0.00001865
Iteration 55/1000 | Loss: 0.00001864
Iteration 56/1000 | Loss: 0.00001864
Iteration 57/1000 | Loss: 0.00001864
Iteration 58/1000 | Loss: 0.00001864
Iteration 59/1000 | Loss: 0.00001863
Iteration 60/1000 | Loss: 0.00001863
Iteration 61/1000 | Loss: 0.00001863
Iteration 62/1000 | Loss: 0.00001863
Iteration 63/1000 | Loss: 0.00001862
Iteration 64/1000 | Loss: 0.00001862
Iteration 65/1000 | Loss: 0.00001862
Iteration 66/1000 | Loss: 0.00001862
Iteration 67/1000 | Loss: 0.00001862
Iteration 68/1000 | Loss: 0.00001862
Iteration 69/1000 | Loss: 0.00001862
Iteration 70/1000 | Loss: 0.00001862
Iteration 71/1000 | Loss: 0.00001862
Iteration 72/1000 | Loss: 0.00001862
Iteration 73/1000 | Loss: 0.00001862
Iteration 74/1000 | Loss: 0.00001861
Iteration 75/1000 | Loss: 0.00001861
Iteration 76/1000 | Loss: 0.00001861
Iteration 77/1000 | Loss: 0.00001861
Iteration 78/1000 | Loss: 0.00001861
Iteration 79/1000 | Loss: 0.00001861
Iteration 80/1000 | Loss: 0.00001860
Iteration 81/1000 | Loss: 0.00001860
Iteration 82/1000 | Loss: 0.00001860
Iteration 83/1000 | Loss: 0.00001860
Iteration 84/1000 | Loss: 0.00001860
Iteration 85/1000 | Loss: 0.00001859
Iteration 86/1000 | Loss: 0.00001859
Iteration 87/1000 | Loss: 0.00001859
Iteration 88/1000 | Loss: 0.00001859
Iteration 89/1000 | Loss: 0.00001859
Iteration 90/1000 | Loss: 0.00001859
Iteration 91/1000 | Loss: 0.00001859
Iteration 92/1000 | Loss: 0.00001859
Iteration 93/1000 | Loss: 0.00001859
Iteration 94/1000 | Loss: 0.00001859
Iteration 95/1000 | Loss: 0.00001859
Iteration 96/1000 | Loss: 0.00001859
Iteration 97/1000 | Loss: 0.00001859
Iteration 98/1000 | Loss: 0.00001858
Iteration 99/1000 | Loss: 0.00001858
Iteration 100/1000 | Loss: 0.00001858
Iteration 101/1000 | Loss: 0.00001858
Iteration 102/1000 | Loss: 0.00001858
Iteration 103/1000 | Loss: 0.00001858
Iteration 104/1000 | Loss: 0.00001858
Iteration 105/1000 | Loss: 0.00001857
Iteration 106/1000 | Loss: 0.00001857
Iteration 107/1000 | Loss: 0.00001857
Iteration 108/1000 | Loss: 0.00001857
Iteration 109/1000 | Loss: 0.00001857
Iteration 110/1000 | Loss: 0.00001857
Iteration 111/1000 | Loss: 0.00001857
Iteration 112/1000 | Loss: 0.00001857
Iteration 113/1000 | Loss: 0.00001857
Iteration 114/1000 | Loss: 0.00001857
Iteration 115/1000 | Loss: 0.00001857
Iteration 116/1000 | Loss: 0.00001857
Iteration 117/1000 | Loss: 0.00001857
Iteration 118/1000 | Loss: 0.00001857
Iteration 119/1000 | Loss: 0.00001857
Iteration 120/1000 | Loss: 0.00001857
Iteration 121/1000 | Loss: 0.00001856
Iteration 122/1000 | Loss: 0.00001856
Iteration 123/1000 | Loss: 0.00001856
Iteration 124/1000 | Loss: 0.00001856
Iteration 125/1000 | Loss: 0.00001856
Iteration 126/1000 | Loss: 0.00001856
Iteration 127/1000 | Loss: 0.00001856
Iteration 128/1000 | Loss: 0.00001856
Iteration 129/1000 | Loss: 0.00001856
Iteration 130/1000 | Loss: 0.00001856
Iteration 131/1000 | Loss: 0.00001856
Iteration 132/1000 | Loss: 0.00001856
Iteration 133/1000 | Loss: 0.00001856
Iteration 134/1000 | Loss: 0.00001856
Iteration 135/1000 | Loss: 0.00001856
Iteration 136/1000 | Loss: 0.00001856
Iteration 137/1000 | Loss: 0.00001856
Iteration 138/1000 | Loss: 0.00001856
Iteration 139/1000 | Loss: 0.00001856
Iteration 140/1000 | Loss: 0.00001856
Iteration 141/1000 | Loss: 0.00001856
Iteration 142/1000 | Loss: 0.00001856
Iteration 143/1000 | Loss: 0.00001856
Iteration 144/1000 | Loss: 0.00001855
Iteration 145/1000 | Loss: 0.00001855
Iteration 146/1000 | Loss: 0.00001855
Iteration 147/1000 | Loss: 0.00001855
Iteration 148/1000 | Loss: 0.00001855
Iteration 149/1000 | Loss: 0.00001855
Iteration 150/1000 | Loss: 0.00001855
Iteration 151/1000 | Loss: 0.00001855
Iteration 152/1000 | Loss: 0.00001855
Iteration 153/1000 | Loss: 0.00001855
Iteration 154/1000 | Loss: 0.00001855
Iteration 155/1000 | Loss: 0.00001855
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 155. Stopping optimization.
Last 5 losses: [1.855259142757859e-05, 1.855259142757859e-05, 1.855259142757859e-05, 1.855259142757859e-05, 1.855259142757859e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.855259142757859e-05

Optimization complete. Final v2v error: 3.6515984535217285 mm

Highest mean error: 4.01138973236084 mm for frame 31

Lowest mean error: 3.3995471000671387 mm for frame 118

Saving results

Total time: 41.679978132247925
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1034/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1034.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1034
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00615670
Iteration 2/25 | Loss: 0.00163545
Iteration 3/25 | Loss: 0.00116147
Iteration 4/25 | Loss: 0.00104800
Iteration 5/25 | Loss: 0.00105746
Iteration 6/25 | Loss: 0.00098891
Iteration 7/25 | Loss: 0.00093988
Iteration 8/25 | Loss: 0.00091501
Iteration 9/25 | Loss: 0.00090521
Iteration 10/25 | Loss: 0.00090145
Iteration 11/25 | Loss: 0.00089493
Iteration 12/25 | Loss: 0.00088267
Iteration 13/25 | Loss: 0.00087708
Iteration 14/25 | Loss: 0.00087569
Iteration 15/25 | Loss: 0.00087885
Iteration 16/25 | Loss: 0.00087423
Iteration 17/25 | Loss: 0.00087565
Iteration 18/25 | Loss: 0.00087047
Iteration 19/25 | Loss: 0.00086809
Iteration 20/25 | Loss: 0.00086730
Iteration 21/25 | Loss: 0.00086703
Iteration 22/25 | Loss: 0.00086696
Iteration 23/25 | Loss: 0.00086695
Iteration 24/25 | Loss: 0.00086695
Iteration 25/25 | Loss: 0.00086695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.07188797
Iteration 2/25 | Loss: 0.00172808
Iteration 3/25 | Loss: 0.00160291
Iteration 4/25 | Loss: 0.00160291
Iteration 5/25 | Loss: 0.00160291
Iteration 6/25 | Loss: 0.00160291
Iteration 7/25 | Loss: 0.00160291
Iteration 8/25 | Loss: 0.00160291
Iteration 9/25 | Loss: 0.00160291
Iteration 10/25 | Loss: 0.00160291
Iteration 11/25 | Loss: 0.00160291
Iteration 12/25 | Loss: 0.00160291
Iteration 13/25 | Loss: 0.00160291
Iteration 14/25 | Loss: 0.00160291
Iteration 15/25 | Loss: 0.00160291
Iteration 16/25 | Loss: 0.00160291
Iteration 17/25 | Loss: 0.00160291
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0016029098769649863, 0.0016029098769649863, 0.0016029098769649863, 0.0016029098769649863, 0.0016029098769649863]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0016029098769649863

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00160291
Iteration 2/1000 | Loss: 0.00006243
Iteration 3/1000 | Loss: 0.00004948
Iteration 4/1000 | Loss: 0.00004389
Iteration 5/1000 | Loss: 0.00018653
Iteration 6/1000 | Loss: 0.00003928
Iteration 7/1000 | Loss: 0.00008763
Iteration 8/1000 | Loss: 0.00003732
Iteration 9/1000 | Loss: 0.00003516
Iteration 10/1000 | Loss: 0.00003322
Iteration 11/1000 | Loss: 0.00003211
Iteration 12/1000 | Loss: 0.00003140
Iteration 13/1000 | Loss: 0.00003089
Iteration 14/1000 | Loss: 0.00051185
Iteration 15/1000 | Loss: 0.00089695
Iteration 16/1000 | Loss: 0.00043966
Iteration 17/1000 | Loss: 0.00007423
Iteration 18/1000 | Loss: 0.00053984
Iteration 19/1000 | Loss: 0.00005407
Iteration 20/1000 | Loss: 0.00004237
Iteration 21/1000 | Loss: 0.00020523
Iteration 22/1000 | Loss: 0.00009688
Iteration 23/1000 | Loss: 0.00011340
Iteration 24/1000 | Loss: 0.00008031
Iteration 25/1000 | Loss: 0.00005036
Iteration 26/1000 | Loss: 0.00004163
Iteration 27/1000 | Loss: 0.00003026
Iteration 28/1000 | Loss: 0.00002907
Iteration 29/1000 | Loss: 0.00002814
Iteration 30/1000 | Loss: 0.00002748
Iteration 31/1000 | Loss: 0.00002702
Iteration 32/1000 | Loss: 0.00002677
Iteration 33/1000 | Loss: 0.00002674
Iteration 34/1000 | Loss: 0.00012956
Iteration 35/1000 | Loss: 0.00114500
Iteration 36/1000 | Loss: 0.00038240
Iteration 37/1000 | Loss: 0.00006787
Iteration 38/1000 | Loss: 0.00047246
Iteration 39/1000 | Loss: 0.00061301
Iteration 40/1000 | Loss: 0.00041533
Iteration 41/1000 | Loss: 0.00079351
Iteration 42/1000 | Loss: 0.00043969
Iteration 43/1000 | Loss: 0.00051065
Iteration 44/1000 | Loss: 0.00085013
Iteration 45/1000 | Loss: 0.00012168
Iteration 46/1000 | Loss: 0.00021575
Iteration 47/1000 | Loss: 0.00004383
Iteration 48/1000 | Loss: 0.00007671
Iteration 49/1000 | Loss: 0.00058433
Iteration 50/1000 | Loss: 0.00003357
Iteration 51/1000 | Loss: 0.00010239
Iteration 52/1000 | Loss: 0.00003094
Iteration 53/1000 | Loss: 0.00002917
Iteration 54/1000 | Loss: 0.00002812
Iteration 55/1000 | Loss: 0.00008400
Iteration 56/1000 | Loss: 0.00004407
Iteration 57/1000 | Loss: 0.00004971
Iteration 58/1000 | Loss: 0.00003552
Iteration 59/1000 | Loss: 0.00002627
Iteration 60/1000 | Loss: 0.00002534
Iteration 61/1000 | Loss: 0.00002441
Iteration 62/1000 | Loss: 0.00002370
Iteration 63/1000 | Loss: 0.00002311
Iteration 64/1000 | Loss: 0.00023774
Iteration 65/1000 | Loss: 0.00012801
Iteration 66/1000 | Loss: 0.00002290
Iteration 67/1000 | Loss: 0.00027085
Iteration 68/1000 | Loss: 0.00015494
Iteration 69/1000 | Loss: 0.00002358
Iteration 70/1000 | Loss: 0.00026800
Iteration 71/1000 | Loss: 0.00014780
Iteration 72/1000 | Loss: 0.00002310
Iteration 73/1000 | Loss: 0.00026797
Iteration 74/1000 | Loss: 0.00014142
Iteration 75/1000 | Loss: 0.00002435
Iteration 76/1000 | Loss: 0.00027607
Iteration 77/1000 | Loss: 0.00013099
Iteration 78/1000 | Loss: 0.00025052
Iteration 79/1000 | Loss: 0.00012820
Iteration 80/1000 | Loss: 0.00019667
Iteration 81/1000 | Loss: 0.00012702
Iteration 82/1000 | Loss: 0.00033217
Iteration 83/1000 | Loss: 0.00016310
Iteration 84/1000 | Loss: 0.00022413
Iteration 85/1000 | Loss: 0.00003154
Iteration 86/1000 | Loss: 0.00002687
Iteration 87/1000 | Loss: 0.00002588
Iteration 88/1000 | Loss: 0.00002483
Iteration 89/1000 | Loss: 0.00024590
Iteration 90/1000 | Loss: 0.00015030
Iteration 91/1000 | Loss: 0.00002448
Iteration 92/1000 | Loss: 0.00029340
Iteration 93/1000 | Loss: 0.00003390
Iteration 94/1000 | Loss: 0.00002817
Iteration 95/1000 | Loss: 0.00002501
Iteration 96/1000 | Loss: 0.00002350
Iteration 97/1000 | Loss: 0.00002276
Iteration 98/1000 | Loss: 0.00002242
Iteration 99/1000 | Loss: 0.00002218
Iteration 100/1000 | Loss: 0.00002198
Iteration 101/1000 | Loss: 0.00002192
Iteration 102/1000 | Loss: 0.00002185
Iteration 103/1000 | Loss: 0.00002181
Iteration 104/1000 | Loss: 0.00002181
Iteration 105/1000 | Loss: 0.00002181
Iteration 106/1000 | Loss: 0.00002181
Iteration 107/1000 | Loss: 0.00002181
Iteration 108/1000 | Loss: 0.00002181
Iteration 109/1000 | Loss: 0.00002180
Iteration 110/1000 | Loss: 0.00002180
Iteration 111/1000 | Loss: 0.00002180
Iteration 112/1000 | Loss: 0.00002180
Iteration 113/1000 | Loss: 0.00002179
Iteration 114/1000 | Loss: 0.00002179
Iteration 115/1000 | Loss: 0.00002177
Iteration 116/1000 | Loss: 0.00002177
Iteration 117/1000 | Loss: 0.00002176
Iteration 118/1000 | Loss: 0.00002176
Iteration 119/1000 | Loss: 0.00002174
Iteration 120/1000 | Loss: 0.00002173
Iteration 121/1000 | Loss: 0.00002172
Iteration 122/1000 | Loss: 0.00002170
Iteration 123/1000 | Loss: 0.00002170
Iteration 124/1000 | Loss: 0.00002170
Iteration 125/1000 | Loss: 0.00002169
Iteration 126/1000 | Loss: 0.00002169
Iteration 127/1000 | Loss: 0.00002169
Iteration 128/1000 | Loss: 0.00002169
Iteration 129/1000 | Loss: 0.00002169
Iteration 130/1000 | Loss: 0.00002169
Iteration 131/1000 | Loss: 0.00002169
Iteration 132/1000 | Loss: 0.00002169
Iteration 133/1000 | Loss: 0.00002169
Iteration 134/1000 | Loss: 0.00002169
Iteration 135/1000 | Loss: 0.00002167
Iteration 136/1000 | Loss: 0.00002166
Iteration 137/1000 | Loss: 0.00002166
Iteration 138/1000 | Loss: 0.00002165
Iteration 139/1000 | Loss: 0.00002164
Iteration 140/1000 | Loss: 0.00002164
Iteration 141/1000 | Loss: 0.00002164
Iteration 142/1000 | Loss: 0.00002164
Iteration 143/1000 | Loss: 0.00002163
Iteration 144/1000 | Loss: 0.00002163
Iteration 145/1000 | Loss: 0.00002163
Iteration 146/1000 | Loss: 0.00002163
Iteration 147/1000 | Loss: 0.00002163
Iteration 148/1000 | Loss: 0.00002163
Iteration 149/1000 | Loss: 0.00002163
Iteration 150/1000 | Loss: 0.00002163
Iteration 151/1000 | Loss: 0.00002163
Iteration 152/1000 | Loss: 0.00002163
Iteration 153/1000 | Loss: 0.00002163
Iteration 154/1000 | Loss: 0.00002163
Iteration 155/1000 | Loss: 0.00002163
Iteration 156/1000 | Loss: 0.00002162
Iteration 157/1000 | Loss: 0.00002162
Iteration 158/1000 | Loss: 0.00002162
Iteration 159/1000 | Loss: 0.00002162
Iteration 160/1000 | Loss: 0.00002162
Iteration 161/1000 | Loss: 0.00002162
Iteration 162/1000 | Loss: 0.00002162
Iteration 163/1000 | Loss: 0.00002162
Iteration 164/1000 | Loss: 0.00002162
Iteration 165/1000 | Loss: 0.00002162
Iteration 166/1000 | Loss: 0.00002162
Iteration 167/1000 | Loss: 0.00002162
Iteration 168/1000 | Loss: 0.00002162
Iteration 169/1000 | Loss: 0.00002162
Iteration 170/1000 | Loss: 0.00002161
Iteration 171/1000 | Loss: 0.00002161
Iteration 172/1000 | Loss: 0.00002161
Iteration 173/1000 | Loss: 0.00002161
Iteration 174/1000 | Loss: 0.00002161
Iteration 175/1000 | Loss: 0.00002161
Iteration 176/1000 | Loss: 0.00002161
Iteration 177/1000 | Loss: 0.00002161
Iteration 178/1000 | Loss: 0.00002161
Iteration 179/1000 | Loss: 0.00002160
Iteration 180/1000 | Loss: 0.00002160
Iteration 181/1000 | Loss: 0.00002160
Iteration 182/1000 | Loss: 0.00002160
Iteration 183/1000 | Loss: 0.00002160
Iteration 184/1000 | Loss: 0.00002160
Iteration 185/1000 | Loss: 0.00002160
Iteration 186/1000 | Loss: 0.00002160
Iteration 187/1000 | Loss: 0.00002160
Iteration 188/1000 | Loss: 0.00002160
Iteration 189/1000 | Loss: 0.00002160
Iteration 190/1000 | Loss: 0.00002160
Iteration 191/1000 | Loss: 0.00002160
Iteration 192/1000 | Loss: 0.00002160
Iteration 193/1000 | Loss: 0.00002160
Iteration 194/1000 | Loss: 0.00002160
Iteration 195/1000 | Loss: 0.00002160
Iteration 196/1000 | Loss: 0.00002160
Iteration 197/1000 | Loss: 0.00002160
Iteration 198/1000 | Loss: 0.00002160
Iteration 199/1000 | Loss: 0.00002160
Iteration 200/1000 | Loss: 0.00002160
Iteration 201/1000 | Loss: 0.00002160
Iteration 202/1000 | Loss: 0.00002160
Iteration 203/1000 | Loss: 0.00002160
Iteration 204/1000 | Loss: 0.00002159
Iteration 205/1000 | Loss: 0.00002159
Iteration 206/1000 | Loss: 0.00002159
Iteration 207/1000 | Loss: 0.00002159
Iteration 208/1000 | Loss: 0.00002159
Iteration 209/1000 | Loss: 0.00002159
Iteration 210/1000 | Loss: 0.00002159
Iteration 211/1000 | Loss: 0.00002159
Iteration 212/1000 | Loss: 0.00002159
Iteration 213/1000 | Loss: 0.00002159
Iteration 214/1000 | Loss: 0.00002159
Iteration 215/1000 | Loss: 0.00002159
Iteration 216/1000 | Loss: 0.00002159
Iteration 217/1000 | Loss: 0.00002159
Iteration 218/1000 | Loss: 0.00002159
Iteration 219/1000 | Loss: 0.00002159
Iteration 220/1000 | Loss: 0.00002159
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 220. Stopping optimization.
Last 5 losses: [2.159490031772293e-05, 2.159490031772293e-05, 2.159490031772293e-05, 2.159490031772293e-05, 2.159490031772293e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.159490031772293e-05

Optimization complete. Final v2v error: 3.6847729682922363 mm

Highest mean error: 11.652548789978027 mm for frame 58

Lowest mean error: 2.8825886249542236 mm for frame 172

Saving results

Total time: 214.2789442539215
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1067/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1067.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1067
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01001172
Iteration 2/25 | Loss: 0.00536127
Iteration 3/25 | Loss: 0.00238690
Iteration 4/25 | Loss: 0.00193169
Iteration 5/25 | Loss: 0.00174492
Iteration 6/25 | Loss: 0.00170032
Iteration 7/25 | Loss: 0.00156887
Iteration 8/25 | Loss: 0.00173192
Iteration 9/25 | Loss: 0.00136652
Iteration 10/25 | Loss: 0.00132322
Iteration 11/25 | Loss: 0.00127169
Iteration 12/25 | Loss: 0.00123008
Iteration 13/25 | Loss: 0.00121490
Iteration 14/25 | Loss: 0.00119026
Iteration 15/25 | Loss: 0.00115241
Iteration 16/25 | Loss: 0.00115840
Iteration 17/25 | Loss: 0.00114546
Iteration 18/25 | Loss: 0.00112454
Iteration 19/25 | Loss: 0.00110250
Iteration 20/25 | Loss: 0.00111286
Iteration 21/25 | Loss: 0.00109308
Iteration 22/25 | Loss: 0.00107246
Iteration 23/25 | Loss: 0.00105338
Iteration 24/25 | Loss: 0.00105153
Iteration 25/25 | Loss: 0.00103902

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61894405
Iteration 2/25 | Loss: 0.00577947
Iteration 3/25 | Loss: 0.00350415
Iteration 4/25 | Loss: 0.00350243
Iteration 5/25 | Loss: 0.00350243
Iteration 6/25 | Loss: 0.00350243
Iteration 7/25 | Loss: 0.00350243
Iteration 8/25 | Loss: 0.00350243
Iteration 9/25 | Loss: 0.00350243
Iteration 10/25 | Loss: 0.00350243
Iteration 11/25 | Loss: 0.00350243
Iteration 12/25 | Loss: 0.00350243
Iteration 13/25 | Loss: 0.00350243
Iteration 14/25 | Loss: 0.00350243
Iteration 15/25 | Loss: 0.00350243
Iteration 16/25 | Loss: 0.00350243
Iteration 17/25 | Loss: 0.00350243
Iteration 18/25 | Loss: 0.00350243
Iteration 19/25 | Loss: 0.00350243
Iteration 20/25 | Loss: 0.00350243
Iteration 21/25 | Loss: 0.00350243
Iteration 22/25 | Loss: 0.00350243
Iteration 23/25 | Loss: 0.00350243
Iteration 24/25 | Loss: 0.00350243
Iteration 25/25 | Loss: 0.00350243

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00350243
Iteration 2/1000 | Loss: 0.00319130
Iteration 3/1000 | Loss: 0.00361918
Iteration 4/1000 | Loss: 0.00088740
Iteration 5/1000 | Loss: 0.00083797
Iteration 6/1000 | Loss: 0.00105417
Iteration 7/1000 | Loss: 0.00127966
Iteration 8/1000 | Loss: 0.00194087
Iteration 9/1000 | Loss: 0.00338267
Iteration 10/1000 | Loss: 0.00306821
Iteration 11/1000 | Loss: 0.00322607
Iteration 12/1000 | Loss: 0.00308620
Iteration 13/1000 | Loss: 0.00579484
Iteration 14/1000 | Loss: 0.00338232
Iteration 15/1000 | Loss: 0.00310561
Iteration 16/1000 | Loss: 0.00509503
Iteration 17/1000 | Loss: 0.00647152
Iteration 18/1000 | Loss: 0.00319161
Iteration 19/1000 | Loss: 0.00208147
Iteration 20/1000 | Loss: 0.00159708
Iteration 21/1000 | Loss: 0.00161570
Iteration 22/1000 | Loss: 0.00290120
Iteration 23/1000 | Loss: 0.00116873
Iteration 24/1000 | Loss: 0.00295754
Iteration 25/1000 | Loss: 0.00115929
Iteration 26/1000 | Loss: 0.00224652
Iteration 27/1000 | Loss: 0.00113494
Iteration 28/1000 | Loss: 0.00090307
Iteration 29/1000 | Loss: 0.00104006
Iteration 30/1000 | Loss: 0.00039925
Iteration 31/1000 | Loss: 0.00049270
Iteration 32/1000 | Loss: 0.00041090
Iteration 33/1000 | Loss: 0.00029423
Iteration 34/1000 | Loss: 0.00099894
Iteration 35/1000 | Loss: 0.00123229
Iteration 36/1000 | Loss: 0.00149263
Iteration 37/1000 | Loss: 0.00078290
Iteration 38/1000 | Loss: 0.00125958
Iteration 39/1000 | Loss: 0.00025966
Iteration 40/1000 | Loss: 0.00008604
Iteration 41/1000 | Loss: 0.00016734
Iteration 42/1000 | Loss: 0.00018054
Iteration 43/1000 | Loss: 0.00028045
Iteration 44/1000 | Loss: 0.00012525
Iteration 45/1000 | Loss: 0.00013051
Iteration 46/1000 | Loss: 0.00037074
Iteration 47/1000 | Loss: 0.00010639
Iteration 48/1000 | Loss: 0.00036124
Iteration 49/1000 | Loss: 0.00065535
Iteration 50/1000 | Loss: 0.00041830
Iteration 51/1000 | Loss: 0.00081467
Iteration 52/1000 | Loss: 0.00048608
Iteration 53/1000 | Loss: 0.00047149
Iteration 54/1000 | Loss: 0.00022717
Iteration 55/1000 | Loss: 0.00064459
Iteration 56/1000 | Loss: 0.00059684
Iteration 57/1000 | Loss: 0.00022843
Iteration 58/1000 | Loss: 0.00028168
Iteration 59/1000 | Loss: 0.00015286
Iteration 60/1000 | Loss: 0.00012390
Iteration 61/1000 | Loss: 0.00005239
Iteration 62/1000 | Loss: 0.00004704
Iteration 63/1000 | Loss: 0.00014111
Iteration 64/1000 | Loss: 0.00005945
Iteration 65/1000 | Loss: 0.00010400
Iteration 66/1000 | Loss: 0.00005421
Iteration 67/1000 | Loss: 0.00006816
Iteration 68/1000 | Loss: 0.00004454
Iteration 69/1000 | Loss: 0.00005022
Iteration 70/1000 | Loss: 0.00025168
Iteration 71/1000 | Loss: 0.00007608
Iteration 72/1000 | Loss: 0.00009710
Iteration 73/1000 | Loss: 0.00037943
Iteration 74/1000 | Loss: 0.00025209
Iteration 75/1000 | Loss: 0.00024726
Iteration 76/1000 | Loss: 0.00026374
Iteration 77/1000 | Loss: 0.00021208
Iteration 78/1000 | Loss: 0.00019689
Iteration 79/1000 | Loss: 0.00006005
Iteration 80/1000 | Loss: 0.00005792
Iteration 81/1000 | Loss: 0.00022910
Iteration 82/1000 | Loss: 0.00015352
Iteration 83/1000 | Loss: 0.00018900
Iteration 84/1000 | Loss: 0.00017794
Iteration 85/1000 | Loss: 0.00005336
Iteration 86/1000 | Loss: 0.00004218
Iteration 87/1000 | Loss: 0.00007207
Iteration 88/1000 | Loss: 0.00004433
Iteration 89/1000 | Loss: 0.00021710
Iteration 90/1000 | Loss: 0.00015410
Iteration 91/1000 | Loss: 0.00019451
Iteration 92/1000 | Loss: 0.00017085
Iteration 93/1000 | Loss: 0.00009736
Iteration 94/1000 | Loss: 0.00005429
Iteration 95/1000 | Loss: 0.00028760
Iteration 96/1000 | Loss: 0.00010156
Iteration 97/1000 | Loss: 0.00025770
Iteration 98/1000 | Loss: 0.00012106
Iteration 99/1000 | Loss: 0.00012417
Iteration 100/1000 | Loss: 0.00019544
Iteration 101/1000 | Loss: 0.00018308
Iteration 102/1000 | Loss: 0.00032140
Iteration 103/1000 | Loss: 0.00022134
Iteration 104/1000 | Loss: 0.00004164
Iteration 105/1000 | Loss: 0.00022567
Iteration 106/1000 | Loss: 0.00022933
Iteration 107/1000 | Loss: 0.00018232
Iteration 108/1000 | Loss: 0.00007411
Iteration 109/1000 | Loss: 0.00004773
Iteration 110/1000 | Loss: 0.00004902
Iteration 111/1000 | Loss: 0.00004909
Iteration 112/1000 | Loss: 0.00006060
Iteration 113/1000 | Loss: 0.00003994
Iteration 114/1000 | Loss: 0.00003839
Iteration 115/1000 | Loss: 0.00004554
Iteration 116/1000 | Loss: 0.00004013
Iteration 117/1000 | Loss: 0.00008597
Iteration 118/1000 | Loss: 0.00033461
Iteration 119/1000 | Loss: 0.00021183
Iteration 120/1000 | Loss: 0.00045536
Iteration 121/1000 | Loss: 0.00027369
Iteration 122/1000 | Loss: 0.00006968
Iteration 123/1000 | Loss: 0.00004010
Iteration 124/1000 | Loss: 0.00005545
Iteration 125/1000 | Loss: 0.00004114
Iteration 126/1000 | Loss: 0.00004514
Iteration 127/1000 | Loss: 0.00018947
Iteration 128/1000 | Loss: 0.00009672
Iteration 129/1000 | Loss: 0.00022444
Iteration 130/1000 | Loss: 0.00034787
Iteration 131/1000 | Loss: 0.00010372
Iteration 132/1000 | Loss: 0.00003259
Iteration 133/1000 | Loss: 0.00003824
Iteration 134/1000 | Loss: 0.00003976
Iteration 135/1000 | Loss: 0.00003765
Iteration 136/1000 | Loss: 0.00007913
Iteration 137/1000 | Loss: 0.00004426
Iteration 138/1000 | Loss: 0.00004064
Iteration 139/1000 | Loss: 0.00004449
Iteration 140/1000 | Loss: 0.00004381
Iteration 141/1000 | Loss: 0.00003412
Iteration 142/1000 | Loss: 0.00004693
Iteration 143/1000 | Loss: 0.00003570
Iteration 144/1000 | Loss: 0.00003777
Iteration 145/1000 | Loss: 0.00003474
Iteration 146/1000 | Loss: 0.00003887
Iteration 147/1000 | Loss: 0.00004266
Iteration 148/1000 | Loss: 0.00005085
Iteration 149/1000 | Loss: 0.00004612
Iteration 150/1000 | Loss: 0.00004751
Iteration 151/1000 | Loss: 0.00005901
Iteration 152/1000 | Loss: 0.00004844
Iteration 153/1000 | Loss: 0.00005328
Iteration 154/1000 | Loss: 0.00002855
Iteration 155/1000 | Loss: 0.00002667
Iteration 156/1000 | Loss: 0.00004649
Iteration 157/1000 | Loss: 0.00002599
Iteration 158/1000 | Loss: 0.00002585
Iteration 159/1000 | Loss: 0.00002585
Iteration 160/1000 | Loss: 0.00002584
Iteration 161/1000 | Loss: 0.00002584
Iteration 162/1000 | Loss: 0.00002584
Iteration 163/1000 | Loss: 0.00002582
Iteration 164/1000 | Loss: 0.00005865
Iteration 165/1000 | Loss: 0.00002560
Iteration 166/1000 | Loss: 0.00002556
Iteration 167/1000 | Loss: 0.00002553
Iteration 168/1000 | Loss: 0.00002552
Iteration 169/1000 | Loss: 0.00002552
Iteration 170/1000 | Loss: 0.00002552
Iteration 171/1000 | Loss: 0.00002549
Iteration 172/1000 | Loss: 0.00006243
Iteration 173/1000 | Loss: 0.00002537
Iteration 174/1000 | Loss: 0.00002533
Iteration 175/1000 | Loss: 0.00002532
Iteration 176/1000 | Loss: 0.00002531
Iteration 177/1000 | Loss: 0.00002530
Iteration 178/1000 | Loss: 0.00002530
Iteration 179/1000 | Loss: 0.00002525
Iteration 180/1000 | Loss: 0.00002525
Iteration 181/1000 | Loss: 0.00002521
Iteration 182/1000 | Loss: 0.00007347
Iteration 183/1000 | Loss: 0.00002855
Iteration 184/1000 | Loss: 0.00002670
Iteration 185/1000 | Loss: 0.00002587
Iteration 186/1000 | Loss: 0.00002512
Iteration 187/1000 | Loss: 0.00002509
Iteration 188/1000 | Loss: 0.00002509
Iteration 189/1000 | Loss: 0.00002508
Iteration 190/1000 | Loss: 0.00002508
Iteration 191/1000 | Loss: 0.00002508
Iteration 192/1000 | Loss: 0.00002508
Iteration 193/1000 | Loss: 0.00002508
Iteration 194/1000 | Loss: 0.00002508
Iteration 195/1000 | Loss: 0.00002508
Iteration 196/1000 | Loss: 0.00002508
Iteration 197/1000 | Loss: 0.00002508
Iteration 198/1000 | Loss: 0.00002508
Iteration 199/1000 | Loss: 0.00002507
Iteration 200/1000 | Loss: 0.00002507
Iteration 201/1000 | Loss: 0.00002507
Iteration 202/1000 | Loss: 0.00002506
Iteration 203/1000 | Loss: 0.00002506
Iteration 204/1000 | Loss: 0.00002506
Iteration 205/1000 | Loss: 0.00004808
Iteration 206/1000 | Loss: 0.00004808
Iteration 207/1000 | Loss: 0.00009363
Iteration 208/1000 | Loss: 0.00002504
Iteration 209/1000 | Loss: 0.00002504
Iteration 210/1000 | Loss: 0.00002504
Iteration 211/1000 | Loss: 0.00002504
Iteration 212/1000 | Loss: 0.00002503
Iteration 213/1000 | Loss: 0.00002503
Iteration 214/1000 | Loss: 0.00002503
Iteration 215/1000 | Loss: 0.00004878
Iteration 216/1000 | Loss: 0.00002643
Iteration 217/1000 | Loss: 0.00002581
Iteration 218/1000 | Loss: 0.00007950
Iteration 219/1000 | Loss: 0.00002663
Iteration 220/1000 | Loss: 0.00002577
Iteration 221/1000 | Loss: 0.00002534
Iteration 222/1000 | Loss: 0.00002501
Iteration 223/1000 | Loss: 0.00002501
Iteration 224/1000 | Loss: 0.00002501
Iteration 225/1000 | Loss: 0.00002501
Iteration 226/1000 | Loss: 0.00002501
Iteration 227/1000 | Loss: 0.00002501
Iteration 228/1000 | Loss: 0.00002501
Iteration 229/1000 | Loss: 0.00002501
Iteration 230/1000 | Loss: 0.00002501
Iteration 231/1000 | Loss: 0.00002501
Iteration 232/1000 | Loss: 0.00002501
Iteration 233/1000 | Loss: 0.00002501
Iteration 234/1000 | Loss: 0.00002501
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 234. Stopping optimization.
Last 5 losses: [2.501171184121631e-05, 2.501171184121631e-05, 2.501171184121631e-05, 2.501171184121631e-05, 2.501171184121631e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.501171184121631e-05

Optimization complete. Final v2v error: 4.110357284545898 mm

Highest mean error: 5.542746067047119 mm for frame 239

Lowest mean error: 3.5577797889709473 mm for frame 43

Saving results

Total time: 338.7702522277832
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1080/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1080.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1080
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01077873
Iteration 2/25 | Loss: 0.01077873
Iteration 3/25 | Loss: 0.00142260
Iteration 4/25 | Loss: 0.00091647
Iteration 5/25 | Loss: 0.00085082
Iteration 6/25 | Loss: 0.00080435
Iteration 7/25 | Loss: 0.00079720
Iteration 8/25 | Loss: 0.00079475
Iteration 9/25 | Loss: 0.00079144
Iteration 10/25 | Loss: 0.00078476
Iteration 11/25 | Loss: 0.00078198
Iteration 12/25 | Loss: 0.00077823
Iteration 13/25 | Loss: 0.00077732
Iteration 14/25 | Loss: 0.00077684
Iteration 15/25 | Loss: 0.00077539
Iteration 16/25 | Loss: 0.00077312
Iteration 17/25 | Loss: 0.00077270
Iteration 18/25 | Loss: 0.00077161
Iteration 19/25 | Loss: 0.00077158
Iteration 20/25 | Loss: 0.00077158
Iteration 21/25 | Loss: 0.00077156
Iteration 22/25 | Loss: 0.00077156
Iteration 23/25 | Loss: 0.00077156
Iteration 24/25 | Loss: 0.00077156
Iteration 25/25 | Loss: 0.00077156

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61423230
Iteration 2/25 | Loss: 0.00135703
Iteration 3/25 | Loss: 0.00135703
Iteration 4/25 | Loss: 0.00135703
Iteration 5/25 | Loss: 0.00135703
Iteration 6/25 | Loss: 0.00135703
Iteration 7/25 | Loss: 0.00134518
Iteration 8/25 | Loss: 0.00134518
Iteration 9/25 | Loss: 0.00134518
Iteration 10/25 | Loss: 0.00134518
Iteration 11/25 | Loss: 0.00134518
Iteration 12/25 | Loss: 0.00134518
Iteration 13/25 | Loss: 0.00134518
Iteration 14/25 | Loss: 0.00134518
Iteration 15/25 | Loss: 0.00134518
Iteration 16/25 | Loss: 0.00134518
Iteration 17/25 | Loss: 0.00134518
Iteration 18/25 | Loss: 0.00134518
Iteration 19/25 | Loss: 0.00134518
Iteration 20/25 | Loss: 0.00134518
Iteration 21/25 | Loss: 0.00134518
Iteration 22/25 | Loss: 0.00134518
Iteration 23/25 | Loss: 0.00134518
Iteration 24/25 | Loss: 0.00134518
Iteration 25/25 | Loss: 0.00134518

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00134518
Iteration 2/1000 | Loss: 0.00003048
Iteration 3/1000 | Loss: 0.00002833
Iteration 4/1000 | Loss: 0.00001771
Iteration 5/1000 | Loss: 0.00002178
Iteration 6/1000 | Loss: 0.00002318
Iteration 7/1000 | Loss: 0.00001584
Iteration 8/1000 | Loss: 0.00001549
Iteration 9/1000 | Loss: 0.00001523
Iteration 10/1000 | Loss: 0.00001521
Iteration 11/1000 | Loss: 0.00001515
Iteration 12/1000 | Loss: 0.00001512
Iteration 13/1000 | Loss: 0.00001499
Iteration 14/1000 | Loss: 0.00001498
Iteration 15/1000 | Loss: 0.00001497
Iteration 16/1000 | Loss: 0.00001497
Iteration 17/1000 | Loss: 0.00001496
Iteration 18/1000 | Loss: 0.00001496
Iteration 19/1000 | Loss: 0.00001494
Iteration 20/1000 | Loss: 0.00001490
Iteration 21/1000 | Loss: 0.00001483
Iteration 22/1000 | Loss: 0.00001475
Iteration 23/1000 | Loss: 0.00001475
Iteration 24/1000 | Loss: 0.00001475
Iteration 25/1000 | Loss: 0.00001474
Iteration 26/1000 | Loss: 0.00001474
Iteration 27/1000 | Loss: 0.00001474
Iteration 28/1000 | Loss: 0.00001473
Iteration 29/1000 | Loss: 0.00001473
Iteration 30/1000 | Loss: 0.00001473
Iteration 31/1000 | Loss: 0.00001472
Iteration 32/1000 | Loss: 0.00001470
Iteration 33/1000 | Loss: 0.00001470
Iteration 34/1000 | Loss: 0.00001469
Iteration 35/1000 | Loss: 0.00001468
Iteration 36/1000 | Loss: 0.00001468
Iteration 37/1000 | Loss: 0.00001468
Iteration 38/1000 | Loss: 0.00001467
Iteration 39/1000 | Loss: 0.00001467
Iteration 40/1000 | Loss: 0.00001467
Iteration 41/1000 | Loss: 0.00001467
Iteration 42/1000 | Loss: 0.00001465
Iteration 43/1000 | Loss: 0.00001465
Iteration 44/1000 | Loss: 0.00001464
Iteration 45/1000 | Loss: 0.00001464
Iteration 46/1000 | Loss: 0.00001464
Iteration 47/1000 | Loss: 0.00001463
Iteration 48/1000 | Loss: 0.00001463
Iteration 49/1000 | Loss: 0.00001463
Iteration 50/1000 | Loss: 0.00001463
Iteration 51/1000 | Loss: 0.00001462
Iteration 52/1000 | Loss: 0.00001462
Iteration 53/1000 | Loss: 0.00001462
Iteration 54/1000 | Loss: 0.00001462
Iteration 55/1000 | Loss: 0.00001462
Iteration 56/1000 | Loss: 0.00001462
Iteration 57/1000 | Loss: 0.00001461
Iteration 58/1000 | Loss: 0.00001461
Iteration 59/1000 | Loss: 0.00001461
Iteration 60/1000 | Loss: 0.00001461
Iteration 61/1000 | Loss: 0.00001460
Iteration 62/1000 | Loss: 0.00001460
Iteration 63/1000 | Loss: 0.00001460
Iteration 64/1000 | Loss: 0.00001460
Iteration 65/1000 | Loss: 0.00001460
Iteration 66/1000 | Loss: 0.00001459
Iteration 67/1000 | Loss: 0.00001459
Iteration 68/1000 | Loss: 0.00001459
Iteration 69/1000 | Loss: 0.00001458
Iteration 70/1000 | Loss: 0.00001458
Iteration 71/1000 | Loss: 0.00001457
Iteration 72/1000 | Loss: 0.00001457
Iteration 73/1000 | Loss: 0.00001457
Iteration 74/1000 | Loss: 0.00001456
Iteration 75/1000 | Loss: 0.00001456
Iteration 76/1000 | Loss: 0.00001456
Iteration 77/1000 | Loss: 0.00001456
Iteration 78/1000 | Loss: 0.00001455
Iteration 79/1000 | Loss: 0.00001455
Iteration 80/1000 | Loss: 0.00001455
Iteration 81/1000 | Loss: 0.00001455
Iteration 82/1000 | Loss: 0.00001455
Iteration 83/1000 | Loss: 0.00001454
Iteration 84/1000 | Loss: 0.00001454
Iteration 85/1000 | Loss: 0.00001454
Iteration 86/1000 | Loss: 0.00001454
Iteration 87/1000 | Loss: 0.00001454
Iteration 88/1000 | Loss: 0.00001453
Iteration 89/1000 | Loss: 0.00001453
Iteration 90/1000 | Loss: 0.00001453
Iteration 91/1000 | Loss: 0.00001453
Iteration 92/1000 | Loss: 0.00001453
Iteration 93/1000 | Loss: 0.00001452
Iteration 94/1000 | Loss: 0.00001452
Iteration 95/1000 | Loss: 0.00001452
Iteration 96/1000 | Loss: 0.00001452
Iteration 97/1000 | Loss: 0.00001452
Iteration 98/1000 | Loss: 0.00001451
Iteration 99/1000 | Loss: 0.00001451
Iteration 100/1000 | Loss: 0.00001451
Iteration 101/1000 | Loss: 0.00001451
Iteration 102/1000 | Loss: 0.00001451
Iteration 103/1000 | Loss: 0.00001451
Iteration 104/1000 | Loss: 0.00001451
Iteration 105/1000 | Loss: 0.00001450
Iteration 106/1000 | Loss: 0.00001450
Iteration 107/1000 | Loss: 0.00001450
Iteration 108/1000 | Loss: 0.00001450
Iteration 109/1000 | Loss: 0.00001450
Iteration 110/1000 | Loss: 0.00001450
Iteration 111/1000 | Loss: 0.00001449
Iteration 112/1000 | Loss: 0.00001449
Iteration 113/1000 | Loss: 0.00001449
Iteration 114/1000 | Loss: 0.00001449
Iteration 115/1000 | Loss: 0.00001449
Iteration 116/1000 | Loss: 0.00001449
Iteration 117/1000 | Loss: 0.00001449
Iteration 118/1000 | Loss: 0.00001449
Iteration 119/1000 | Loss: 0.00001449
Iteration 120/1000 | Loss: 0.00001449
Iteration 121/1000 | Loss: 0.00001449
Iteration 122/1000 | Loss: 0.00001449
Iteration 123/1000 | Loss: 0.00001449
Iteration 124/1000 | Loss: 0.00001449
Iteration 125/1000 | Loss: 0.00001449
Iteration 126/1000 | Loss: 0.00001449
Iteration 127/1000 | Loss: 0.00001449
Iteration 128/1000 | Loss: 0.00001449
Iteration 129/1000 | Loss: 0.00001448
Iteration 130/1000 | Loss: 0.00001448
Iteration 131/1000 | Loss: 0.00001448
Iteration 132/1000 | Loss: 0.00001448
Iteration 133/1000 | Loss: 0.00001448
Iteration 134/1000 | Loss: 0.00001448
Iteration 135/1000 | Loss: 0.00001448
Iteration 136/1000 | Loss: 0.00001448
Iteration 137/1000 | Loss: 0.00001448
Iteration 138/1000 | Loss: 0.00001448
Iteration 139/1000 | Loss: 0.00001448
Iteration 140/1000 | Loss: 0.00001447
Iteration 141/1000 | Loss: 0.00001447
Iteration 142/1000 | Loss: 0.00001447
Iteration 143/1000 | Loss: 0.00001447
Iteration 144/1000 | Loss: 0.00001447
Iteration 145/1000 | Loss: 0.00001447
Iteration 146/1000 | Loss: 0.00001447
Iteration 147/1000 | Loss: 0.00001447
Iteration 148/1000 | Loss: 0.00001447
Iteration 149/1000 | Loss: 0.00001447
Iteration 150/1000 | Loss: 0.00001447
Iteration 151/1000 | Loss: 0.00001447
Iteration 152/1000 | Loss: 0.00001447
Iteration 153/1000 | Loss: 0.00001447
Iteration 154/1000 | Loss: 0.00001447
Iteration 155/1000 | Loss: 0.00001447
Iteration 156/1000 | Loss: 0.00001447
Iteration 157/1000 | Loss: 0.00001447
Iteration 158/1000 | Loss: 0.00001447
Iteration 159/1000 | Loss: 0.00001447
Iteration 160/1000 | Loss: 0.00001447
Iteration 161/1000 | Loss: 0.00001447
Iteration 162/1000 | Loss: 0.00001447
Iteration 163/1000 | Loss: 0.00001447
Iteration 164/1000 | Loss: 0.00001447
Iteration 165/1000 | Loss: 0.00001447
Iteration 166/1000 | Loss: 0.00001447
Iteration 167/1000 | Loss: 0.00001447
Iteration 168/1000 | Loss: 0.00001447
Iteration 169/1000 | Loss: 0.00001447
Iteration 170/1000 | Loss: 0.00001447
Iteration 171/1000 | Loss: 0.00001447
Iteration 172/1000 | Loss: 0.00001447
Iteration 173/1000 | Loss: 0.00001447
Iteration 174/1000 | Loss: 0.00001447
Iteration 175/1000 | Loss: 0.00001447
Iteration 176/1000 | Loss: 0.00001447
Iteration 177/1000 | Loss: 0.00001447
Iteration 178/1000 | Loss: 0.00001447
Iteration 179/1000 | Loss: 0.00001447
Iteration 180/1000 | Loss: 0.00001447
Iteration 181/1000 | Loss: 0.00001447
Iteration 182/1000 | Loss: 0.00001447
Iteration 183/1000 | Loss: 0.00001447
Iteration 184/1000 | Loss: 0.00001447
Iteration 185/1000 | Loss: 0.00001447
Iteration 186/1000 | Loss: 0.00001447
Iteration 187/1000 | Loss: 0.00001447
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 187. Stopping optimization.
Last 5 losses: [1.4473476767307147e-05, 1.4473476767307147e-05, 1.4473476767307147e-05, 1.4473476767307147e-05, 1.4473476767307147e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4473476767307147e-05

Optimization complete. Final v2v error: 3.2034828662872314 mm

Highest mean error: 3.95810604095459 mm for frame 30

Lowest mean error: 3.005922794342041 mm for frame 40

Saving results

Total time: 69.21321415901184
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1071/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1071.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1071
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00849418
Iteration 2/25 | Loss: 0.00132123
Iteration 3/25 | Loss: 0.00100046
Iteration 4/25 | Loss: 0.00090450
Iteration 5/25 | Loss: 0.00088200
Iteration 6/25 | Loss: 0.00087671
Iteration 7/25 | Loss: 0.00087558
Iteration 8/25 | Loss: 0.00087558
Iteration 9/25 | Loss: 0.00087558
Iteration 10/25 | Loss: 0.00087558
Iteration 11/25 | Loss: 0.00087558
Iteration 12/25 | Loss: 0.00087558
Iteration 13/25 | Loss: 0.00087558
Iteration 14/25 | Loss: 0.00087558
Iteration 15/25 | Loss: 0.00087558
Iteration 16/25 | Loss: 0.00087558
Iteration 17/25 | Loss: 0.00087558
Iteration 18/25 | Loss: 0.00087558
Iteration 19/25 | Loss: 0.00087558
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0008755757589824498, 0.0008755757589824498, 0.0008755757589824498, 0.0008755757589824498, 0.0008755757589824498]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008755757589824498

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.59748006
Iteration 2/25 | Loss: 0.00135910
Iteration 3/25 | Loss: 0.00135910
Iteration 4/25 | Loss: 0.00135910
Iteration 5/25 | Loss: 0.00135910
Iteration 6/25 | Loss: 0.00135909
Iteration 7/25 | Loss: 0.00135909
Iteration 8/25 | Loss: 0.00135909
Iteration 9/25 | Loss: 0.00135909
Iteration 10/25 | Loss: 0.00135909
Iteration 11/25 | Loss: 0.00135909
Iteration 12/25 | Loss: 0.00135909
Iteration 13/25 | Loss: 0.00135909
Iteration 14/25 | Loss: 0.00135909
Iteration 15/25 | Loss: 0.00135909
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0013590940507128835, 0.0013590940507128835, 0.0013590940507128835, 0.0013590940507128835, 0.0013590940507128835]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013590940507128835

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00135909
Iteration 2/1000 | Loss: 0.00004194
Iteration 3/1000 | Loss: 0.00002820
Iteration 4/1000 | Loss: 0.00002511
Iteration 5/1000 | Loss: 0.00002385
Iteration 6/1000 | Loss: 0.00002295
Iteration 7/1000 | Loss: 0.00002236
Iteration 8/1000 | Loss: 0.00002198
Iteration 9/1000 | Loss: 0.00002166
Iteration 10/1000 | Loss: 0.00002144
Iteration 11/1000 | Loss: 0.00002132
Iteration 12/1000 | Loss: 0.00002132
Iteration 13/1000 | Loss: 0.00002130
Iteration 14/1000 | Loss: 0.00002129
Iteration 15/1000 | Loss: 0.00002127
Iteration 16/1000 | Loss: 0.00002127
Iteration 17/1000 | Loss: 0.00002123
Iteration 18/1000 | Loss: 0.00002123
Iteration 19/1000 | Loss: 0.00002122
Iteration 20/1000 | Loss: 0.00002118
Iteration 21/1000 | Loss: 0.00002117
Iteration 22/1000 | Loss: 0.00002117
Iteration 23/1000 | Loss: 0.00002116
Iteration 24/1000 | Loss: 0.00002116
Iteration 25/1000 | Loss: 0.00002115
Iteration 26/1000 | Loss: 0.00002115
Iteration 27/1000 | Loss: 0.00002115
Iteration 28/1000 | Loss: 0.00002114
Iteration 29/1000 | Loss: 0.00002114
Iteration 30/1000 | Loss: 0.00002113
Iteration 31/1000 | Loss: 0.00002113
Iteration 32/1000 | Loss: 0.00002113
Iteration 33/1000 | Loss: 0.00002113
Iteration 34/1000 | Loss: 0.00002112
Iteration 35/1000 | Loss: 0.00002112
Iteration 36/1000 | Loss: 0.00002112
Iteration 37/1000 | Loss: 0.00002112
Iteration 38/1000 | Loss: 0.00002112
Iteration 39/1000 | Loss: 0.00002111
Iteration 40/1000 | Loss: 0.00002111
Iteration 41/1000 | Loss: 0.00002111
Iteration 42/1000 | Loss: 0.00002111
Iteration 43/1000 | Loss: 0.00002111
Iteration 44/1000 | Loss: 0.00002111
Iteration 45/1000 | Loss: 0.00002111
Iteration 46/1000 | Loss: 0.00002111
Iteration 47/1000 | Loss: 0.00002111
Iteration 48/1000 | Loss: 0.00002111
Iteration 49/1000 | Loss: 0.00002111
Iteration 50/1000 | Loss: 0.00002111
Iteration 51/1000 | Loss: 0.00002111
Iteration 52/1000 | Loss: 0.00002111
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 52. Stopping optimization.
Last 5 losses: [2.1112111426191404e-05, 2.1112111426191404e-05, 2.1112111426191404e-05, 2.1112111426191404e-05, 2.1112111426191404e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1112111426191404e-05

Optimization complete. Final v2v error: 3.7875735759735107 mm

Highest mean error: 4.160496711730957 mm for frame 212

Lowest mean error: 3.5738987922668457 mm for frame 237

Saving results

Total time: 33.27929925918579
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1054/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1054.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1054
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00476662
Iteration 2/25 | Loss: 0.00095768
Iteration 3/25 | Loss: 0.00077935
Iteration 4/25 | Loss: 0.00076338
Iteration 5/25 | Loss: 0.00075964
Iteration 6/25 | Loss: 0.00075876
Iteration 7/25 | Loss: 0.00075853
Iteration 8/25 | Loss: 0.00075853
Iteration 9/25 | Loss: 0.00075853
Iteration 10/25 | Loss: 0.00075853
Iteration 11/25 | Loss: 0.00075853
Iteration 12/25 | Loss: 0.00075853
Iteration 13/25 | Loss: 0.00075853
Iteration 14/25 | Loss: 0.00075853
Iteration 15/25 | Loss: 0.00075853
Iteration 16/25 | Loss: 0.00075853
Iteration 17/25 | Loss: 0.00075853
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007585349376313388, 0.0007585349376313388, 0.0007585349376313388, 0.0007585349376313388, 0.0007585349376313388]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007585349376313388

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.34244394
Iteration 2/25 | Loss: 0.00118509
Iteration 3/25 | Loss: 0.00118506
Iteration 4/25 | Loss: 0.00118506
Iteration 5/25 | Loss: 0.00118506
Iteration 6/25 | Loss: 0.00118506
Iteration 7/25 | Loss: 0.00118506
Iteration 8/25 | Loss: 0.00118506
Iteration 9/25 | Loss: 0.00118506
Iteration 10/25 | Loss: 0.00118506
Iteration 11/25 | Loss: 0.00118506
Iteration 12/25 | Loss: 0.00118506
Iteration 13/25 | Loss: 0.00118506
Iteration 14/25 | Loss: 0.00118506
Iteration 15/25 | Loss: 0.00118506
Iteration 16/25 | Loss: 0.00118506
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011850616429001093, 0.0011850616429001093, 0.0011850616429001093, 0.0011850616429001093, 0.0011850616429001093]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011850616429001093

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00118506
Iteration 2/1000 | Loss: 0.00002577
Iteration 3/1000 | Loss: 0.00001718
Iteration 4/1000 | Loss: 0.00001565
Iteration 5/1000 | Loss: 0.00001465
Iteration 6/1000 | Loss: 0.00001418
Iteration 7/1000 | Loss: 0.00001383
Iteration 8/1000 | Loss: 0.00001359
Iteration 9/1000 | Loss: 0.00001342
Iteration 10/1000 | Loss: 0.00001327
Iteration 11/1000 | Loss: 0.00001321
Iteration 12/1000 | Loss: 0.00001321
Iteration 13/1000 | Loss: 0.00001316
Iteration 14/1000 | Loss: 0.00001315
Iteration 15/1000 | Loss: 0.00001312
Iteration 16/1000 | Loss: 0.00001311
Iteration 17/1000 | Loss: 0.00001310
Iteration 18/1000 | Loss: 0.00001310
Iteration 19/1000 | Loss: 0.00001309
Iteration 20/1000 | Loss: 0.00001308
Iteration 21/1000 | Loss: 0.00001308
Iteration 22/1000 | Loss: 0.00001308
Iteration 23/1000 | Loss: 0.00001307
Iteration 24/1000 | Loss: 0.00001307
Iteration 25/1000 | Loss: 0.00001307
Iteration 26/1000 | Loss: 0.00001306
Iteration 27/1000 | Loss: 0.00001306
Iteration 28/1000 | Loss: 0.00001306
Iteration 29/1000 | Loss: 0.00001305
Iteration 30/1000 | Loss: 0.00001305
Iteration 31/1000 | Loss: 0.00001305
Iteration 32/1000 | Loss: 0.00001305
Iteration 33/1000 | Loss: 0.00001305
Iteration 34/1000 | Loss: 0.00001305
Iteration 35/1000 | Loss: 0.00001304
Iteration 36/1000 | Loss: 0.00001304
Iteration 37/1000 | Loss: 0.00001304
Iteration 38/1000 | Loss: 0.00001304
Iteration 39/1000 | Loss: 0.00001304
Iteration 40/1000 | Loss: 0.00001304
Iteration 41/1000 | Loss: 0.00001304
Iteration 42/1000 | Loss: 0.00001304
Iteration 43/1000 | Loss: 0.00001304
Iteration 44/1000 | Loss: 0.00001304
Iteration 45/1000 | Loss: 0.00001304
Iteration 46/1000 | Loss: 0.00001304
Iteration 47/1000 | Loss: 0.00001304
Iteration 48/1000 | Loss: 0.00001304
Iteration 49/1000 | Loss: 0.00001304
Iteration 50/1000 | Loss: 0.00001303
Iteration 51/1000 | Loss: 0.00001303
Iteration 52/1000 | Loss: 0.00001303
Iteration 53/1000 | Loss: 0.00001303
Iteration 54/1000 | Loss: 0.00001303
Iteration 55/1000 | Loss: 0.00001303
Iteration 56/1000 | Loss: 0.00001303
Iteration 57/1000 | Loss: 0.00001303
Iteration 58/1000 | Loss: 0.00001303
Iteration 59/1000 | Loss: 0.00001303
Iteration 60/1000 | Loss: 0.00001302
Iteration 61/1000 | Loss: 0.00001302
Iteration 62/1000 | Loss: 0.00001302
Iteration 63/1000 | Loss: 0.00001302
Iteration 64/1000 | Loss: 0.00001302
Iteration 65/1000 | Loss: 0.00001302
Iteration 66/1000 | Loss: 0.00001302
Iteration 67/1000 | Loss: 0.00001302
Iteration 68/1000 | Loss: 0.00001302
Iteration 69/1000 | Loss: 0.00001302
Iteration 70/1000 | Loss: 0.00001302
Iteration 71/1000 | Loss: 0.00001302
Iteration 72/1000 | Loss: 0.00001302
Iteration 73/1000 | Loss: 0.00001302
Iteration 74/1000 | Loss: 0.00001302
Iteration 75/1000 | Loss: 0.00001302
Iteration 76/1000 | Loss: 0.00001302
Iteration 77/1000 | Loss: 0.00001302
Iteration 78/1000 | Loss: 0.00001302
Iteration 79/1000 | Loss: 0.00001302
Iteration 80/1000 | Loss: 0.00001302
Iteration 81/1000 | Loss: 0.00001302
Iteration 82/1000 | Loss: 0.00001302
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 82. Stopping optimization.
Last 5 losses: [1.3018783647567034e-05, 1.3018783647567034e-05, 1.3018783647567034e-05, 1.3018783647567034e-05, 1.3018783647567034e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3018783647567034e-05

Optimization complete. Final v2v error: 3.0669469833374023 mm

Highest mean error: 3.3852732181549072 mm for frame 110

Lowest mean error: 2.852202892303467 mm for frame 154

Saving results

Total time: 30.792959451675415
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1087/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1087.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1087
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00926273
Iteration 2/25 | Loss: 0.00142939
Iteration 3/25 | Loss: 0.00107587
Iteration 4/25 | Loss: 0.00098178
Iteration 5/25 | Loss: 0.00094854
Iteration 6/25 | Loss: 0.00095145
Iteration 7/25 | Loss: 0.00094530
Iteration 8/25 | Loss: 0.00093318
Iteration 9/25 | Loss: 0.00092342
Iteration 10/25 | Loss: 0.00091457
Iteration 11/25 | Loss: 0.00090176
Iteration 12/25 | Loss: 0.00090152
Iteration 13/25 | Loss: 0.00089577
Iteration 14/25 | Loss: 0.00089323
Iteration 15/25 | Loss: 0.00089012
Iteration 16/25 | Loss: 0.00088817
Iteration 17/25 | Loss: 0.00088836
Iteration 18/25 | Loss: 0.00088270
Iteration 19/25 | Loss: 0.00088191
Iteration 20/25 | Loss: 0.00088184
Iteration 21/25 | Loss: 0.00088184
Iteration 22/25 | Loss: 0.00088183
Iteration 23/25 | Loss: 0.00088183
Iteration 24/25 | Loss: 0.00088183
Iteration 25/25 | Loss: 0.00088183

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.39321518
Iteration 2/25 | Loss: 0.00159798
Iteration 3/25 | Loss: 0.00159789
Iteration 4/25 | Loss: 0.00159789
Iteration 5/25 | Loss: 0.00159788
Iteration 6/25 | Loss: 0.00159788
Iteration 7/25 | Loss: 0.00159788
Iteration 8/25 | Loss: 0.00159788
Iteration 9/25 | Loss: 0.00159788
Iteration 10/25 | Loss: 0.00159788
Iteration 11/25 | Loss: 0.00159788
Iteration 12/25 | Loss: 0.00159788
Iteration 13/25 | Loss: 0.00159788
Iteration 14/25 | Loss: 0.00159788
Iteration 15/25 | Loss: 0.00159788
Iteration 16/25 | Loss: 0.00159788
Iteration 17/25 | Loss: 0.00159788
Iteration 18/25 | Loss: 0.00159788
Iteration 19/25 | Loss: 0.00159788
Iteration 20/25 | Loss: 0.00159788
Iteration 21/25 | Loss: 0.00159788
Iteration 22/25 | Loss: 0.00159788
Iteration 23/25 | Loss: 0.00159788
Iteration 24/25 | Loss: 0.00159788
Iteration 25/25 | Loss: 0.00159788

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00159788
Iteration 2/1000 | Loss: 0.00053899
Iteration 3/1000 | Loss: 0.00066136
Iteration 4/1000 | Loss: 0.00007442
Iteration 5/1000 | Loss: 0.00004776
Iteration 6/1000 | Loss: 0.00004123
Iteration 7/1000 | Loss: 0.00003882
Iteration 8/1000 | Loss: 0.00019780
Iteration 9/1000 | Loss: 0.00013803
Iteration 10/1000 | Loss: 0.00006286
Iteration 11/1000 | Loss: 0.00012377
Iteration 12/1000 | Loss: 0.00005183
Iteration 13/1000 | Loss: 0.00004667
Iteration 14/1000 | Loss: 0.00004438
Iteration 15/1000 | Loss: 0.00012568
Iteration 16/1000 | Loss: 0.00029790
Iteration 17/1000 | Loss: 0.00009539
Iteration 18/1000 | Loss: 0.00007040
Iteration 19/1000 | Loss: 0.00004681
Iteration 20/1000 | Loss: 0.00018005
Iteration 21/1000 | Loss: 0.00007740
Iteration 22/1000 | Loss: 0.00005073
Iteration 23/1000 | Loss: 0.00004331
Iteration 24/1000 | Loss: 0.00023553
Iteration 25/1000 | Loss: 0.00007492
Iteration 26/1000 | Loss: 0.00053201
Iteration 27/1000 | Loss: 0.00004452
Iteration 28/1000 | Loss: 0.00004140
Iteration 29/1000 | Loss: 0.00003987
Iteration 30/1000 | Loss: 0.00008177
Iteration 31/1000 | Loss: 0.00004008
Iteration 32/1000 | Loss: 0.00003781
Iteration 33/1000 | Loss: 0.00003653
Iteration 34/1000 | Loss: 0.00020625
Iteration 35/1000 | Loss: 0.00012849
Iteration 36/1000 | Loss: 0.00013687
Iteration 37/1000 | Loss: 0.00008953
Iteration 38/1000 | Loss: 0.00012812
Iteration 39/1000 | Loss: 0.00004134
Iteration 40/1000 | Loss: 0.00003626
Iteration 41/1000 | Loss: 0.00003481
Iteration 42/1000 | Loss: 0.00003406
Iteration 43/1000 | Loss: 0.00003313
Iteration 44/1000 | Loss: 0.00003231
Iteration 45/1000 | Loss: 0.00029374
Iteration 46/1000 | Loss: 0.00005456
Iteration 47/1000 | Loss: 0.00003871
Iteration 48/1000 | Loss: 0.00003463
Iteration 49/1000 | Loss: 0.00003389
Iteration 50/1000 | Loss: 0.00003332
Iteration 51/1000 | Loss: 0.00053452
Iteration 52/1000 | Loss: 0.00023458
Iteration 53/1000 | Loss: 0.00017960
Iteration 54/1000 | Loss: 0.00004968
Iteration 55/1000 | Loss: 0.00003986
Iteration 56/1000 | Loss: 0.00006232
Iteration 57/1000 | Loss: 0.00006191
Iteration 58/1000 | Loss: 0.00004005
Iteration 59/1000 | Loss: 0.00005286
Iteration 60/1000 | Loss: 0.00003413
Iteration 61/1000 | Loss: 0.00003187
Iteration 62/1000 | Loss: 0.00003092
Iteration 63/1000 | Loss: 0.00003022
Iteration 64/1000 | Loss: 0.00002972
Iteration 65/1000 | Loss: 0.00003672
Iteration 66/1000 | Loss: 0.00003453
Iteration 67/1000 | Loss: 0.00004360
Iteration 68/1000 | Loss: 0.00003430
Iteration 69/1000 | Loss: 0.00003121
Iteration 70/1000 | Loss: 0.00002983
Iteration 71/1000 | Loss: 0.00002918
Iteration 72/1000 | Loss: 0.00002905
Iteration 73/1000 | Loss: 0.00002905
Iteration 74/1000 | Loss: 0.00002900
Iteration 75/1000 | Loss: 0.00002899
Iteration 76/1000 | Loss: 0.00002897
Iteration 77/1000 | Loss: 0.00002895
Iteration 78/1000 | Loss: 0.00004895
Iteration 79/1000 | Loss: 0.00003450
Iteration 80/1000 | Loss: 0.00002989
Iteration 81/1000 | Loss: 0.00002941
Iteration 82/1000 | Loss: 0.00003978
Iteration 83/1000 | Loss: 0.00003392
Iteration 84/1000 | Loss: 0.00003555
Iteration 85/1000 | Loss: 0.00003389
Iteration 86/1000 | Loss: 0.00003494
Iteration 87/1000 | Loss: 0.00003306
Iteration 88/1000 | Loss: 0.00003455
Iteration 89/1000 | Loss: 0.00002917
Iteration 90/1000 | Loss: 0.00002866
Iteration 91/1000 | Loss: 0.00002831
Iteration 92/1000 | Loss: 0.00002801
Iteration 93/1000 | Loss: 0.00004332
Iteration 94/1000 | Loss: 0.00004062
Iteration 95/1000 | Loss: 0.00003245
Iteration 96/1000 | Loss: 0.00002882
Iteration 97/1000 | Loss: 0.00002786
Iteration 98/1000 | Loss: 0.00002740
Iteration 99/1000 | Loss: 0.00002718
Iteration 100/1000 | Loss: 0.00002714
Iteration 101/1000 | Loss: 0.00002709
Iteration 102/1000 | Loss: 0.00002699
Iteration 103/1000 | Loss: 0.00002698
Iteration 104/1000 | Loss: 0.00002697
Iteration 105/1000 | Loss: 0.00002696
Iteration 106/1000 | Loss: 0.00002696
Iteration 107/1000 | Loss: 0.00002695
Iteration 108/1000 | Loss: 0.00002695
Iteration 109/1000 | Loss: 0.00002694
Iteration 110/1000 | Loss: 0.00002693
Iteration 111/1000 | Loss: 0.00002693
Iteration 112/1000 | Loss: 0.00002693
Iteration 113/1000 | Loss: 0.00002692
Iteration 114/1000 | Loss: 0.00002689
Iteration 115/1000 | Loss: 0.00002689
Iteration 116/1000 | Loss: 0.00002686
Iteration 117/1000 | Loss: 0.00002685
Iteration 118/1000 | Loss: 0.00002684
Iteration 119/1000 | Loss: 0.00002684
Iteration 120/1000 | Loss: 0.00002684
Iteration 121/1000 | Loss: 0.00002683
Iteration 122/1000 | Loss: 0.00002683
Iteration 123/1000 | Loss: 0.00002683
Iteration 124/1000 | Loss: 0.00002683
Iteration 125/1000 | Loss: 0.00002683
Iteration 126/1000 | Loss: 0.00002683
Iteration 127/1000 | Loss: 0.00002682
Iteration 128/1000 | Loss: 0.00002682
Iteration 129/1000 | Loss: 0.00002682
Iteration 130/1000 | Loss: 0.00002682
Iteration 131/1000 | Loss: 0.00002682
Iteration 132/1000 | Loss: 0.00002682
Iteration 133/1000 | Loss: 0.00002682
Iteration 134/1000 | Loss: 0.00002682
Iteration 135/1000 | Loss: 0.00002682
Iteration 136/1000 | Loss: 0.00002682
Iteration 137/1000 | Loss: 0.00002682
Iteration 138/1000 | Loss: 0.00002682
Iteration 139/1000 | Loss: 0.00002682
Iteration 140/1000 | Loss: 0.00002682
Iteration 141/1000 | Loss: 0.00002682
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 141. Stopping optimization.
Last 5 losses: [2.6823225198313594e-05, 2.6823225198313594e-05, 2.6823225198313594e-05, 2.6823225198313594e-05, 2.6823225198313594e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6823225198313594e-05

Optimization complete. Final v2v error: 4.261395454406738 mm

Highest mean error: 7.633055686950684 mm for frame 97

Lowest mean error: 3.491029977798462 mm for frame 133

Saving results

Total time: 185.06653833389282
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00915095
Iteration 2/25 | Loss: 0.00096950
Iteration 3/25 | Loss: 0.00077248
Iteration 4/25 | Loss: 0.00073864
Iteration 5/25 | Loss: 0.00073233
Iteration 6/25 | Loss: 0.00073112
Iteration 7/25 | Loss: 0.00073080
Iteration 8/25 | Loss: 0.00073080
Iteration 9/25 | Loss: 0.00073080
Iteration 10/25 | Loss: 0.00073080
Iteration 11/25 | Loss: 0.00073080
Iteration 12/25 | Loss: 0.00073080
Iteration 13/25 | Loss: 0.00073080
Iteration 14/25 | Loss: 0.00073080
Iteration 15/25 | Loss: 0.00073080
Iteration 16/25 | Loss: 0.00073080
Iteration 17/25 | Loss: 0.00073080
Iteration 18/25 | Loss: 0.00073080
Iteration 19/25 | Loss: 0.00073080
Iteration 20/25 | Loss: 0.00073080
Iteration 21/25 | Loss: 0.00073080
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007307979394681752, 0.0007307979394681752, 0.0007307979394681752, 0.0007307979394681752, 0.0007307979394681752]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007307979394681752

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54221845
Iteration 2/25 | Loss: 0.00103442
Iteration 3/25 | Loss: 0.00103441
Iteration 4/25 | Loss: 0.00103441
Iteration 5/25 | Loss: 0.00103441
Iteration 6/25 | Loss: 0.00103441
Iteration 7/25 | Loss: 0.00103441
Iteration 8/25 | Loss: 0.00103441
Iteration 9/25 | Loss: 0.00103441
Iteration 10/25 | Loss: 0.00103441
Iteration 11/25 | Loss: 0.00103441
Iteration 12/25 | Loss: 0.00103441
Iteration 13/25 | Loss: 0.00103441
Iteration 14/25 | Loss: 0.00103441
Iteration 15/25 | Loss: 0.00103441
Iteration 16/25 | Loss: 0.00103441
Iteration 17/25 | Loss: 0.00103441
Iteration 18/25 | Loss: 0.00103441
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0010344103211537004, 0.0010344103211537004, 0.0010344103211537004, 0.0010344103211537004, 0.0010344103211537004]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010344103211537004

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00103441
Iteration 2/1000 | Loss: 0.00002709
Iteration 3/1000 | Loss: 0.00001708
Iteration 4/1000 | Loss: 0.00001496
Iteration 5/1000 | Loss: 0.00001404
Iteration 6/1000 | Loss: 0.00001335
Iteration 7/1000 | Loss: 0.00001293
Iteration 8/1000 | Loss: 0.00001268
Iteration 9/1000 | Loss: 0.00001254
Iteration 10/1000 | Loss: 0.00001236
Iteration 11/1000 | Loss: 0.00001231
Iteration 12/1000 | Loss: 0.00001223
Iteration 13/1000 | Loss: 0.00001214
Iteration 14/1000 | Loss: 0.00001211
Iteration 15/1000 | Loss: 0.00001211
Iteration 16/1000 | Loss: 0.00001208
Iteration 17/1000 | Loss: 0.00001208
Iteration 18/1000 | Loss: 0.00001207
Iteration 19/1000 | Loss: 0.00001201
Iteration 20/1000 | Loss: 0.00001200
Iteration 21/1000 | Loss: 0.00001199
Iteration 22/1000 | Loss: 0.00001199
Iteration 23/1000 | Loss: 0.00001198
Iteration 24/1000 | Loss: 0.00001197
Iteration 25/1000 | Loss: 0.00001197
Iteration 26/1000 | Loss: 0.00001196
Iteration 27/1000 | Loss: 0.00001196
Iteration 28/1000 | Loss: 0.00001196
Iteration 29/1000 | Loss: 0.00001195
Iteration 30/1000 | Loss: 0.00001194
Iteration 31/1000 | Loss: 0.00001193
Iteration 32/1000 | Loss: 0.00001193
Iteration 33/1000 | Loss: 0.00001192
Iteration 34/1000 | Loss: 0.00001191
Iteration 35/1000 | Loss: 0.00001190
Iteration 36/1000 | Loss: 0.00001190
Iteration 37/1000 | Loss: 0.00001189
Iteration 38/1000 | Loss: 0.00001188
Iteration 39/1000 | Loss: 0.00001188
Iteration 40/1000 | Loss: 0.00001188
Iteration 41/1000 | Loss: 0.00001188
Iteration 42/1000 | Loss: 0.00001188
Iteration 43/1000 | Loss: 0.00001188
Iteration 44/1000 | Loss: 0.00001188
Iteration 45/1000 | Loss: 0.00001188
Iteration 46/1000 | Loss: 0.00001188
Iteration 47/1000 | Loss: 0.00001188
Iteration 48/1000 | Loss: 0.00001187
Iteration 49/1000 | Loss: 0.00001187
Iteration 50/1000 | Loss: 0.00001187
Iteration 51/1000 | Loss: 0.00001187
Iteration 52/1000 | Loss: 0.00001187
Iteration 53/1000 | Loss: 0.00001186
Iteration 54/1000 | Loss: 0.00001186
Iteration 55/1000 | Loss: 0.00001185
Iteration 56/1000 | Loss: 0.00001185
Iteration 57/1000 | Loss: 0.00001185
Iteration 58/1000 | Loss: 0.00001184
Iteration 59/1000 | Loss: 0.00001184
Iteration 60/1000 | Loss: 0.00001184
Iteration 61/1000 | Loss: 0.00001184
Iteration 62/1000 | Loss: 0.00001183
Iteration 63/1000 | Loss: 0.00001183
Iteration 64/1000 | Loss: 0.00001182
Iteration 65/1000 | Loss: 0.00001182
Iteration 66/1000 | Loss: 0.00001182
Iteration 67/1000 | Loss: 0.00001182
Iteration 68/1000 | Loss: 0.00001182
Iteration 69/1000 | Loss: 0.00001182
Iteration 70/1000 | Loss: 0.00001182
Iteration 71/1000 | Loss: 0.00001182
Iteration 72/1000 | Loss: 0.00001181
Iteration 73/1000 | Loss: 0.00001181
Iteration 74/1000 | Loss: 0.00001181
Iteration 75/1000 | Loss: 0.00001181
Iteration 76/1000 | Loss: 0.00001181
Iteration 77/1000 | Loss: 0.00001181
Iteration 78/1000 | Loss: 0.00001181
Iteration 79/1000 | Loss: 0.00001181
Iteration 80/1000 | Loss: 0.00001181
Iteration 81/1000 | Loss: 0.00001181
Iteration 82/1000 | Loss: 0.00001181
Iteration 83/1000 | Loss: 0.00001181
Iteration 84/1000 | Loss: 0.00001181
Iteration 85/1000 | Loss: 0.00001181
Iteration 86/1000 | Loss: 0.00001181
Iteration 87/1000 | Loss: 0.00001181
Iteration 88/1000 | Loss: 0.00001181
Iteration 89/1000 | Loss: 0.00001180
Iteration 90/1000 | Loss: 0.00001180
Iteration 91/1000 | Loss: 0.00001180
Iteration 92/1000 | Loss: 0.00001180
Iteration 93/1000 | Loss: 0.00001179
Iteration 94/1000 | Loss: 0.00001179
Iteration 95/1000 | Loss: 0.00001179
Iteration 96/1000 | Loss: 0.00001179
Iteration 97/1000 | Loss: 0.00001178
Iteration 98/1000 | Loss: 0.00001178
Iteration 99/1000 | Loss: 0.00001178
Iteration 100/1000 | Loss: 0.00001178
Iteration 101/1000 | Loss: 0.00001178
Iteration 102/1000 | Loss: 0.00001178
Iteration 103/1000 | Loss: 0.00001178
Iteration 104/1000 | Loss: 0.00001177
Iteration 105/1000 | Loss: 0.00001177
Iteration 106/1000 | Loss: 0.00001177
Iteration 107/1000 | Loss: 0.00001176
Iteration 108/1000 | Loss: 0.00001176
Iteration 109/1000 | Loss: 0.00001176
Iteration 110/1000 | Loss: 0.00001176
Iteration 111/1000 | Loss: 0.00001176
Iteration 112/1000 | Loss: 0.00001175
Iteration 113/1000 | Loss: 0.00001175
Iteration 114/1000 | Loss: 0.00001175
Iteration 115/1000 | Loss: 0.00001175
Iteration 116/1000 | Loss: 0.00001175
Iteration 117/1000 | Loss: 0.00001175
Iteration 118/1000 | Loss: 0.00001175
Iteration 119/1000 | Loss: 0.00001175
Iteration 120/1000 | Loss: 0.00001174
Iteration 121/1000 | Loss: 0.00001174
Iteration 122/1000 | Loss: 0.00001174
Iteration 123/1000 | Loss: 0.00001174
Iteration 124/1000 | Loss: 0.00001174
Iteration 125/1000 | Loss: 0.00001173
Iteration 126/1000 | Loss: 0.00001173
Iteration 127/1000 | Loss: 0.00001173
Iteration 128/1000 | Loss: 0.00001173
Iteration 129/1000 | Loss: 0.00001173
Iteration 130/1000 | Loss: 0.00001173
Iteration 131/1000 | Loss: 0.00001173
Iteration 132/1000 | Loss: 0.00001173
Iteration 133/1000 | Loss: 0.00001173
Iteration 134/1000 | Loss: 0.00001172
Iteration 135/1000 | Loss: 0.00001172
Iteration 136/1000 | Loss: 0.00001172
Iteration 137/1000 | Loss: 0.00001172
Iteration 138/1000 | Loss: 0.00001172
Iteration 139/1000 | Loss: 0.00001172
Iteration 140/1000 | Loss: 0.00001171
Iteration 141/1000 | Loss: 0.00001171
Iteration 142/1000 | Loss: 0.00001171
Iteration 143/1000 | Loss: 0.00001171
Iteration 144/1000 | Loss: 0.00001171
Iteration 145/1000 | Loss: 0.00001171
Iteration 146/1000 | Loss: 0.00001171
Iteration 147/1000 | Loss: 0.00001171
Iteration 148/1000 | Loss: 0.00001171
Iteration 149/1000 | Loss: 0.00001171
Iteration 150/1000 | Loss: 0.00001171
Iteration 151/1000 | Loss: 0.00001171
Iteration 152/1000 | Loss: 0.00001171
Iteration 153/1000 | Loss: 0.00001171
Iteration 154/1000 | Loss: 0.00001170
Iteration 155/1000 | Loss: 0.00001170
Iteration 156/1000 | Loss: 0.00001170
Iteration 157/1000 | Loss: 0.00001170
Iteration 158/1000 | Loss: 0.00001170
Iteration 159/1000 | Loss: 0.00001170
Iteration 160/1000 | Loss: 0.00001170
Iteration 161/1000 | Loss: 0.00001170
Iteration 162/1000 | Loss: 0.00001170
Iteration 163/1000 | Loss: 0.00001170
Iteration 164/1000 | Loss: 0.00001170
Iteration 165/1000 | Loss: 0.00001170
Iteration 166/1000 | Loss: 0.00001170
Iteration 167/1000 | Loss: 0.00001170
Iteration 168/1000 | Loss: 0.00001170
Iteration 169/1000 | Loss: 0.00001169
Iteration 170/1000 | Loss: 0.00001169
Iteration 171/1000 | Loss: 0.00001169
Iteration 172/1000 | Loss: 0.00001169
Iteration 173/1000 | Loss: 0.00001169
Iteration 174/1000 | Loss: 0.00001169
Iteration 175/1000 | Loss: 0.00001169
Iteration 176/1000 | Loss: 0.00001169
Iteration 177/1000 | Loss: 0.00001169
Iteration 178/1000 | Loss: 0.00001169
Iteration 179/1000 | Loss: 0.00001169
Iteration 180/1000 | Loss: 0.00001169
Iteration 181/1000 | Loss: 0.00001169
Iteration 182/1000 | Loss: 0.00001169
Iteration 183/1000 | Loss: 0.00001169
Iteration 184/1000 | Loss: 0.00001169
Iteration 185/1000 | Loss: 0.00001168
Iteration 186/1000 | Loss: 0.00001168
Iteration 187/1000 | Loss: 0.00001168
Iteration 188/1000 | Loss: 0.00001168
Iteration 189/1000 | Loss: 0.00001168
Iteration 190/1000 | Loss: 0.00001168
Iteration 191/1000 | Loss: 0.00001168
Iteration 192/1000 | Loss: 0.00001168
Iteration 193/1000 | Loss: 0.00001168
Iteration 194/1000 | Loss: 0.00001168
Iteration 195/1000 | Loss: 0.00001168
Iteration 196/1000 | Loss: 0.00001168
Iteration 197/1000 | Loss: 0.00001168
Iteration 198/1000 | Loss: 0.00001168
Iteration 199/1000 | Loss: 0.00001168
Iteration 200/1000 | Loss: 0.00001168
Iteration 201/1000 | Loss: 0.00001168
Iteration 202/1000 | Loss: 0.00001168
Iteration 203/1000 | Loss: 0.00001168
Iteration 204/1000 | Loss: 0.00001168
Iteration 205/1000 | Loss: 0.00001168
Iteration 206/1000 | Loss: 0.00001168
Iteration 207/1000 | Loss: 0.00001168
Iteration 208/1000 | Loss: 0.00001168
Iteration 209/1000 | Loss: 0.00001167
Iteration 210/1000 | Loss: 0.00001167
Iteration 211/1000 | Loss: 0.00001167
Iteration 212/1000 | Loss: 0.00001167
Iteration 213/1000 | Loss: 0.00001167
Iteration 214/1000 | Loss: 0.00001167
Iteration 215/1000 | Loss: 0.00001167
Iteration 216/1000 | Loss: 0.00001167
Iteration 217/1000 | Loss: 0.00001167
Iteration 218/1000 | Loss: 0.00001167
Iteration 219/1000 | Loss: 0.00001167
Iteration 220/1000 | Loss: 0.00001167
Iteration 221/1000 | Loss: 0.00001167
Iteration 222/1000 | Loss: 0.00001167
Iteration 223/1000 | Loss: 0.00001167
Iteration 224/1000 | Loss: 0.00001167
Iteration 225/1000 | Loss: 0.00001167
Iteration 226/1000 | Loss: 0.00001167
Iteration 227/1000 | Loss: 0.00001167
Iteration 228/1000 | Loss: 0.00001167
Iteration 229/1000 | Loss: 0.00001167
Iteration 230/1000 | Loss: 0.00001167
Iteration 231/1000 | Loss: 0.00001167
Iteration 232/1000 | Loss: 0.00001167
Iteration 233/1000 | Loss: 0.00001167
Iteration 234/1000 | Loss: 0.00001167
Iteration 235/1000 | Loss: 0.00001167
Iteration 236/1000 | Loss: 0.00001167
Iteration 237/1000 | Loss: 0.00001167
Iteration 238/1000 | Loss: 0.00001167
Iteration 239/1000 | Loss: 0.00001167
Iteration 240/1000 | Loss: 0.00001167
Iteration 241/1000 | Loss: 0.00001167
Iteration 242/1000 | Loss: 0.00001167
Iteration 243/1000 | Loss: 0.00001167
Iteration 244/1000 | Loss: 0.00001167
Iteration 245/1000 | Loss: 0.00001167
Iteration 246/1000 | Loss: 0.00001167
Iteration 247/1000 | Loss: 0.00001167
Iteration 248/1000 | Loss: 0.00001167
Iteration 249/1000 | Loss: 0.00001167
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 249. Stopping optimization.
Last 5 losses: [1.1666500540741254e-05, 1.1666500540741254e-05, 1.1666500540741254e-05, 1.1666500540741254e-05, 1.1666500540741254e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1666500540741254e-05

Optimization complete. Final v2v error: 2.89996600151062 mm

Highest mean error: 3.773406982421875 mm for frame 59

Lowest mean error: 2.6977596282958984 mm for frame 92

Saving results

Total time: 42.11288809776306
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00906094
Iteration 2/25 | Loss: 0.00094754
Iteration 3/25 | Loss: 0.00082186
Iteration 4/25 | Loss: 0.00078905
Iteration 5/25 | Loss: 0.00078438
Iteration 6/25 | Loss: 0.00078325
Iteration 7/25 | Loss: 0.00078325
Iteration 8/25 | Loss: 0.00078325
Iteration 9/25 | Loss: 0.00078325
Iteration 10/25 | Loss: 0.00078325
Iteration 11/25 | Loss: 0.00078325
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007832525297999382, 0.0007832525297999382, 0.0007832525297999382, 0.0007832525297999382, 0.0007832525297999382]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007832525297999382

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65946817
Iteration 2/25 | Loss: 0.00110117
Iteration 3/25 | Loss: 0.00110116
Iteration 4/25 | Loss: 0.00110116
Iteration 5/25 | Loss: 0.00110116
Iteration 6/25 | Loss: 0.00110116
Iteration 7/25 | Loss: 0.00110115
Iteration 8/25 | Loss: 0.00110115
Iteration 9/25 | Loss: 0.00110115
Iteration 10/25 | Loss: 0.00110115
Iteration 11/25 | Loss: 0.00110115
Iteration 12/25 | Loss: 0.00110115
Iteration 13/25 | Loss: 0.00110115
Iteration 14/25 | Loss: 0.00110115
Iteration 15/25 | Loss: 0.00110115
Iteration 16/25 | Loss: 0.00110115
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0011011541355401278, 0.0011011541355401278, 0.0011011541355401278, 0.0011011541355401278, 0.0011011541355401278]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011011541355401278

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00110115
Iteration 2/1000 | Loss: 0.00003886
Iteration 3/1000 | Loss: 0.00002680
Iteration 4/1000 | Loss: 0.00002356
Iteration 5/1000 | Loss: 0.00002231
Iteration 6/1000 | Loss: 0.00002108
Iteration 7/1000 | Loss: 0.00002055
Iteration 8/1000 | Loss: 0.00001997
Iteration 9/1000 | Loss: 0.00001965
Iteration 10/1000 | Loss: 0.00001938
Iteration 11/1000 | Loss: 0.00001927
Iteration 12/1000 | Loss: 0.00001921
Iteration 13/1000 | Loss: 0.00001915
Iteration 14/1000 | Loss: 0.00001911
Iteration 15/1000 | Loss: 0.00001910
Iteration 16/1000 | Loss: 0.00001910
Iteration 17/1000 | Loss: 0.00001910
Iteration 18/1000 | Loss: 0.00001909
Iteration 19/1000 | Loss: 0.00001908
Iteration 20/1000 | Loss: 0.00001908
Iteration 21/1000 | Loss: 0.00001907
Iteration 22/1000 | Loss: 0.00001907
Iteration 23/1000 | Loss: 0.00001906
Iteration 24/1000 | Loss: 0.00001905
Iteration 25/1000 | Loss: 0.00001905
Iteration 26/1000 | Loss: 0.00001904
Iteration 27/1000 | Loss: 0.00001904
Iteration 28/1000 | Loss: 0.00001904
Iteration 29/1000 | Loss: 0.00001903
Iteration 30/1000 | Loss: 0.00001903
Iteration 31/1000 | Loss: 0.00001902
Iteration 32/1000 | Loss: 0.00001902
Iteration 33/1000 | Loss: 0.00001901
Iteration 34/1000 | Loss: 0.00001900
Iteration 35/1000 | Loss: 0.00001900
Iteration 36/1000 | Loss: 0.00001899
Iteration 37/1000 | Loss: 0.00001899
Iteration 38/1000 | Loss: 0.00001899
Iteration 39/1000 | Loss: 0.00001899
Iteration 40/1000 | Loss: 0.00001899
Iteration 41/1000 | Loss: 0.00001898
Iteration 42/1000 | Loss: 0.00001898
Iteration 43/1000 | Loss: 0.00001898
Iteration 44/1000 | Loss: 0.00001898
Iteration 45/1000 | Loss: 0.00001898
Iteration 46/1000 | Loss: 0.00001897
Iteration 47/1000 | Loss: 0.00001897
Iteration 48/1000 | Loss: 0.00001897
Iteration 49/1000 | Loss: 0.00001897
Iteration 50/1000 | Loss: 0.00001897
Iteration 51/1000 | Loss: 0.00001897
Iteration 52/1000 | Loss: 0.00001897
Iteration 53/1000 | Loss: 0.00001897
Iteration 54/1000 | Loss: 0.00001897
Iteration 55/1000 | Loss: 0.00001897
Iteration 56/1000 | Loss: 0.00001896
Iteration 57/1000 | Loss: 0.00001896
Iteration 58/1000 | Loss: 0.00001896
Iteration 59/1000 | Loss: 0.00001896
Iteration 60/1000 | Loss: 0.00001896
Iteration 61/1000 | Loss: 0.00001895
Iteration 62/1000 | Loss: 0.00001895
Iteration 63/1000 | Loss: 0.00001895
Iteration 64/1000 | Loss: 0.00001895
Iteration 65/1000 | Loss: 0.00001894
Iteration 66/1000 | Loss: 0.00001894
Iteration 67/1000 | Loss: 0.00001894
Iteration 68/1000 | Loss: 0.00001894
Iteration 69/1000 | Loss: 0.00001894
Iteration 70/1000 | Loss: 0.00001894
Iteration 71/1000 | Loss: 0.00001894
Iteration 72/1000 | Loss: 0.00001894
Iteration 73/1000 | Loss: 0.00001894
Iteration 74/1000 | Loss: 0.00001894
Iteration 75/1000 | Loss: 0.00001893
Iteration 76/1000 | Loss: 0.00001893
Iteration 77/1000 | Loss: 0.00001893
Iteration 78/1000 | Loss: 0.00001893
Iteration 79/1000 | Loss: 0.00001892
Iteration 80/1000 | Loss: 0.00001892
Iteration 81/1000 | Loss: 0.00001891
Iteration 82/1000 | Loss: 0.00001891
Iteration 83/1000 | Loss: 0.00001891
Iteration 84/1000 | Loss: 0.00001891
Iteration 85/1000 | Loss: 0.00001891
Iteration 86/1000 | Loss: 0.00001891
Iteration 87/1000 | Loss: 0.00001891
Iteration 88/1000 | Loss: 0.00001891
Iteration 89/1000 | Loss: 0.00001891
Iteration 90/1000 | Loss: 0.00001890
Iteration 91/1000 | Loss: 0.00001890
Iteration 92/1000 | Loss: 0.00001890
Iteration 93/1000 | Loss: 0.00001890
Iteration 94/1000 | Loss: 0.00001890
Iteration 95/1000 | Loss: 0.00001890
Iteration 96/1000 | Loss: 0.00001890
Iteration 97/1000 | Loss: 0.00001890
Iteration 98/1000 | Loss: 0.00001889
Iteration 99/1000 | Loss: 0.00001889
Iteration 100/1000 | Loss: 0.00001889
Iteration 101/1000 | Loss: 0.00001889
Iteration 102/1000 | Loss: 0.00001889
Iteration 103/1000 | Loss: 0.00001889
Iteration 104/1000 | Loss: 0.00001889
Iteration 105/1000 | Loss: 0.00001889
Iteration 106/1000 | Loss: 0.00001889
Iteration 107/1000 | Loss: 0.00001889
Iteration 108/1000 | Loss: 0.00001889
Iteration 109/1000 | Loss: 0.00001889
Iteration 110/1000 | Loss: 0.00001889
Iteration 111/1000 | Loss: 0.00001889
Iteration 112/1000 | Loss: 0.00001889
Iteration 113/1000 | Loss: 0.00001889
Iteration 114/1000 | Loss: 0.00001888
Iteration 115/1000 | Loss: 0.00001888
Iteration 116/1000 | Loss: 0.00001888
Iteration 117/1000 | Loss: 0.00001888
Iteration 118/1000 | Loss: 0.00001888
Iteration 119/1000 | Loss: 0.00001887
Iteration 120/1000 | Loss: 0.00001887
Iteration 121/1000 | Loss: 0.00001887
Iteration 122/1000 | Loss: 0.00001886
Iteration 123/1000 | Loss: 0.00001886
Iteration 124/1000 | Loss: 0.00001886
Iteration 125/1000 | Loss: 0.00001886
Iteration 126/1000 | Loss: 0.00001885
Iteration 127/1000 | Loss: 0.00001885
Iteration 128/1000 | Loss: 0.00001884
Iteration 129/1000 | Loss: 0.00001884
Iteration 130/1000 | Loss: 0.00001884
Iteration 131/1000 | Loss: 0.00001884
Iteration 132/1000 | Loss: 0.00001883
Iteration 133/1000 | Loss: 0.00001883
Iteration 134/1000 | Loss: 0.00001883
Iteration 135/1000 | Loss: 0.00001883
Iteration 136/1000 | Loss: 0.00001883
Iteration 137/1000 | Loss: 0.00001883
Iteration 138/1000 | Loss: 0.00001883
Iteration 139/1000 | Loss: 0.00001883
Iteration 140/1000 | Loss: 0.00001883
Iteration 141/1000 | Loss: 0.00001882
Iteration 142/1000 | Loss: 0.00001882
Iteration 143/1000 | Loss: 0.00001882
Iteration 144/1000 | Loss: 0.00001882
Iteration 145/1000 | Loss: 0.00001882
Iteration 146/1000 | Loss: 0.00001882
Iteration 147/1000 | Loss: 0.00001882
Iteration 148/1000 | Loss: 0.00001881
Iteration 149/1000 | Loss: 0.00001881
Iteration 150/1000 | Loss: 0.00001881
Iteration 151/1000 | Loss: 0.00001881
Iteration 152/1000 | Loss: 0.00001881
Iteration 153/1000 | Loss: 0.00001881
Iteration 154/1000 | Loss: 0.00001881
Iteration 155/1000 | Loss: 0.00001881
Iteration 156/1000 | Loss: 0.00001881
Iteration 157/1000 | Loss: 0.00001880
Iteration 158/1000 | Loss: 0.00001880
Iteration 159/1000 | Loss: 0.00001880
Iteration 160/1000 | Loss: 0.00001880
Iteration 161/1000 | Loss: 0.00001880
Iteration 162/1000 | Loss: 0.00001880
Iteration 163/1000 | Loss: 0.00001880
Iteration 164/1000 | Loss: 0.00001880
Iteration 165/1000 | Loss: 0.00001880
Iteration 166/1000 | Loss: 0.00001880
Iteration 167/1000 | Loss: 0.00001880
Iteration 168/1000 | Loss: 0.00001880
Iteration 169/1000 | Loss: 0.00001880
Iteration 170/1000 | Loss: 0.00001880
Iteration 171/1000 | Loss: 0.00001880
Iteration 172/1000 | Loss: 0.00001880
Iteration 173/1000 | Loss: 0.00001880
Iteration 174/1000 | Loss: 0.00001880
Iteration 175/1000 | Loss: 0.00001880
Iteration 176/1000 | Loss: 0.00001880
Iteration 177/1000 | Loss: 0.00001880
Iteration 178/1000 | Loss: 0.00001880
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [1.8800461475620978e-05, 1.8800461475620978e-05, 1.8800461475620978e-05, 1.8800461475620978e-05, 1.8800461475620978e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8800461475620978e-05

Optimization complete. Final v2v error: 3.6394166946411133 mm

Highest mean error: 4.6781487464904785 mm for frame 92

Lowest mean error: 3.3286187648773193 mm for frame 67

Saving results

Total time: 38.75733256340027
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1047/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1047.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1047
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00812323
Iteration 2/25 | Loss: 0.00136388
Iteration 3/25 | Loss: 0.00101909
Iteration 4/25 | Loss: 0.00092549
Iteration 5/25 | Loss: 0.00089669
Iteration 6/25 | Loss: 0.00088861
Iteration 7/25 | Loss: 0.00088553
Iteration 8/25 | Loss: 0.00088454
Iteration 9/25 | Loss: 0.00088446
Iteration 10/25 | Loss: 0.00088446
Iteration 11/25 | Loss: 0.00088446
Iteration 12/25 | Loss: 0.00088446
Iteration 13/25 | Loss: 0.00088446
Iteration 14/25 | Loss: 0.00088446
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0008844633703120053, 0.0008844633703120053, 0.0008844633703120053, 0.0008844633703120053, 0.0008844633703120053]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008844633703120053

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62178004
Iteration 2/25 | Loss: 0.00168388
Iteration 3/25 | Loss: 0.00168386
Iteration 4/25 | Loss: 0.00168386
Iteration 5/25 | Loss: 0.00168386
Iteration 6/25 | Loss: 0.00168386
Iteration 7/25 | Loss: 0.00168386
Iteration 8/25 | Loss: 0.00168386
Iteration 9/25 | Loss: 0.00168386
Iteration 10/25 | Loss: 0.00168386
Iteration 11/25 | Loss: 0.00168386
Iteration 12/25 | Loss: 0.00168386
Iteration 13/25 | Loss: 0.00168386
Iteration 14/25 | Loss: 0.00168386
Iteration 15/25 | Loss: 0.00168386
Iteration 16/25 | Loss: 0.00168386
Iteration 17/25 | Loss: 0.00168386
Iteration 18/25 | Loss: 0.00168386
Iteration 19/25 | Loss: 0.00168386
Iteration 20/25 | Loss: 0.00168386
Iteration 21/25 | Loss: 0.00168386
Iteration 22/25 | Loss: 0.00168386
Iteration 23/25 | Loss: 0.00168386
Iteration 24/25 | Loss: 0.00168386
Iteration 25/25 | Loss: 0.00168386

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00168386
Iteration 2/1000 | Loss: 0.00007178
Iteration 3/1000 | Loss: 0.00005371
Iteration 4/1000 | Loss: 0.00004543
Iteration 5/1000 | Loss: 0.00004220
Iteration 6/1000 | Loss: 0.00003987
Iteration 7/1000 | Loss: 0.00003779
Iteration 8/1000 | Loss: 0.00003641
Iteration 9/1000 | Loss: 0.00003527
Iteration 10/1000 | Loss: 0.00003454
Iteration 11/1000 | Loss: 0.00003388
Iteration 12/1000 | Loss: 0.00003346
Iteration 13/1000 | Loss: 0.00003298
Iteration 14/1000 | Loss: 0.00003268
Iteration 15/1000 | Loss: 0.00003244
Iteration 16/1000 | Loss: 0.00003224
Iteration 17/1000 | Loss: 0.00003220
Iteration 18/1000 | Loss: 0.00003218
Iteration 19/1000 | Loss: 0.00003213
Iteration 20/1000 | Loss: 0.00003204
Iteration 21/1000 | Loss: 0.00003202
Iteration 22/1000 | Loss: 0.00003202
Iteration 23/1000 | Loss: 0.00003202
Iteration 24/1000 | Loss: 0.00003202
Iteration 25/1000 | Loss: 0.00003202
Iteration 26/1000 | Loss: 0.00003202
Iteration 27/1000 | Loss: 0.00003201
Iteration 28/1000 | Loss: 0.00003201
Iteration 29/1000 | Loss: 0.00003201
Iteration 30/1000 | Loss: 0.00003201
Iteration 31/1000 | Loss: 0.00003201
Iteration 32/1000 | Loss: 0.00003200
Iteration 33/1000 | Loss: 0.00003200
Iteration 34/1000 | Loss: 0.00003200
Iteration 35/1000 | Loss: 0.00003199
Iteration 36/1000 | Loss: 0.00003199
Iteration 37/1000 | Loss: 0.00003198
Iteration 38/1000 | Loss: 0.00003198
Iteration 39/1000 | Loss: 0.00003198
Iteration 40/1000 | Loss: 0.00003198
Iteration 41/1000 | Loss: 0.00003198
Iteration 42/1000 | Loss: 0.00003197
Iteration 43/1000 | Loss: 0.00003197
Iteration 44/1000 | Loss: 0.00003197
Iteration 45/1000 | Loss: 0.00003197
Iteration 46/1000 | Loss: 0.00003196
Iteration 47/1000 | Loss: 0.00003196
Iteration 48/1000 | Loss: 0.00003195
Iteration 49/1000 | Loss: 0.00003195
Iteration 50/1000 | Loss: 0.00003195
Iteration 51/1000 | Loss: 0.00003195
Iteration 52/1000 | Loss: 0.00003195
Iteration 53/1000 | Loss: 0.00003195
Iteration 54/1000 | Loss: 0.00003195
Iteration 55/1000 | Loss: 0.00003194
Iteration 56/1000 | Loss: 0.00003194
Iteration 57/1000 | Loss: 0.00003194
Iteration 58/1000 | Loss: 0.00003193
Iteration 59/1000 | Loss: 0.00003193
Iteration 60/1000 | Loss: 0.00003193
Iteration 61/1000 | Loss: 0.00003192
Iteration 62/1000 | Loss: 0.00003192
Iteration 63/1000 | Loss: 0.00003192
Iteration 64/1000 | Loss: 0.00003192
Iteration 65/1000 | Loss: 0.00003192
Iteration 66/1000 | Loss: 0.00003192
Iteration 67/1000 | Loss: 0.00003191
Iteration 68/1000 | Loss: 0.00003191
Iteration 69/1000 | Loss: 0.00003191
Iteration 70/1000 | Loss: 0.00003191
Iteration 71/1000 | Loss: 0.00003190
Iteration 72/1000 | Loss: 0.00003190
Iteration 73/1000 | Loss: 0.00003190
Iteration 74/1000 | Loss: 0.00003190
Iteration 75/1000 | Loss: 0.00003190
Iteration 76/1000 | Loss: 0.00003190
Iteration 77/1000 | Loss: 0.00003190
Iteration 78/1000 | Loss: 0.00003190
Iteration 79/1000 | Loss: 0.00003190
Iteration 80/1000 | Loss: 0.00003190
Iteration 81/1000 | Loss: 0.00003190
Iteration 82/1000 | Loss: 0.00003190
Iteration 83/1000 | Loss: 0.00003189
Iteration 84/1000 | Loss: 0.00003189
Iteration 85/1000 | Loss: 0.00003189
Iteration 86/1000 | Loss: 0.00003189
Iteration 87/1000 | Loss: 0.00003189
Iteration 88/1000 | Loss: 0.00003189
Iteration 89/1000 | Loss: 0.00003189
Iteration 90/1000 | Loss: 0.00003188
Iteration 91/1000 | Loss: 0.00003188
Iteration 92/1000 | Loss: 0.00003188
Iteration 93/1000 | Loss: 0.00003188
Iteration 94/1000 | Loss: 0.00003187
Iteration 95/1000 | Loss: 0.00003187
Iteration 96/1000 | Loss: 0.00003187
Iteration 97/1000 | Loss: 0.00003187
Iteration 98/1000 | Loss: 0.00003187
Iteration 99/1000 | Loss: 0.00003187
Iteration 100/1000 | Loss: 0.00003187
Iteration 101/1000 | Loss: 0.00003187
Iteration 102/1000 | Loss: 0.00003187
Iteration 103/1000 | Loss: 0.00003187
Iteration 104/1000 | Loss: 0.00003187
Iteration 105/1000 | Loss: 0.00003187
Iteration 106/1000 | Loss: 0.00003187
Iteration 107/1000 | Loss: 0.00003186
Iteration 108/1000 | Loss: 0.00003186
Iteration 109/1000 | Loss: 0.00003186
Iteration 110/1000 | Loss: 0.00003186
Iteration 111/1000 | Loss: 0.00003186
Iteration 112/1000 | Loss: 0.00003186
Iteration 113/1000 | Loss: 0.00003186
Iteration 114/1000 | Loss: 0.00003186
Iteration 115/1000 | Loss: 0.00003186
Iteration 116/1000 | Loss: 0.00003186
Iteration 117/1000 | Loss: 0.00003186
Iteration 118/1000 | Loss: 0.00003186
Iteration 119/1000 | Loss: 0.00003186
Iteration 120/1000 | Loss: 0.00003186
Iteration 121/1000 | Loss: 0.00003186
Iteration 122/1000 | Loss: 0.00003186
Iteration 123/1000 | Loss: 0.00003186
Iteration 124/1000 | Loss: 0.00003186
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [3.186251342413016e-05, 3.186251342413016e-05, 3.186251342413016e-05, 3.186251342413016e-05, 3.186251342413016e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.186251342413016e-05

Optimization complete. Final v2v error: 4.564862251281738 mm

Highest mean error: 6.181521415710449 mm for frame 13

Lowest mean error: 3.5594546794891357 mm for frame 4

Saving results

Total time: 52.002962827682495
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01113474
Iteration 2/25 | Loss: 0.00270108
Iteration 3/25 | Loss: 0.00172333
Iteration 4/25 | Loss: 0.00203017
Iteration 5/25 | Loss: 0.00131728
Iteration 6/25 | Loss: 0.00101548
Iteration 7/25 | Loss: 0.00095373
Iteration 8/25 | Loss: 0.00094301
Iteration 9/25 | Loss: 0.00094000
Iteration 10/25 | Loss: 0.00094287
Iteration 11/25 | Loss: 0.00094263
Iteration 12/25 | Loss: 0.00094242
Iteration 13/25 | Loss: 0.00093973
Iteration 14/25 | Loss: 0.00093756
Iteration 15/25 | Loss: 0.00093718
Iteration 16/25 | Loss: 0.00093703
Iteration 17/25 | Loss: 0.00093695
Iteration 18/25 | Loss: 0.00093695
Iteration 19/25 | Loss: 0.00093695
Iteration 20/25 | Loss: 0.00093695
Iteration 21/25 | Loss: 0.00093695
Iteration 22/25 | Loss: 0.00093694
Iteration 23/25 | Loss: 0.00093694
Iteration 24/25 | Loss: 0.00093694
Iteration 25/25 | Loss: 0.00093694

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39298439
Iteration 2/25 | Loss: 0.00091273
Iteration 3/25 | Loss: 0.00091273
Iteration 4/25 | Loss: 0.00091272
Iteration 5/25 | Loss: 0.00091272
Iteration 6/25 | Loss: 0.00091272
Iteration 7/25 | Loss: 0.00091272
Iteration 8/25 | Loss: 0.00091272
Iteration 9/25 | Loss: 0.00091272
Iteration 10/25 | Loss: 0.00091272
Iteration 11/25 | Loss: 0.00091272
Iteration 12/25 | Loss: 0.00091272
Iteration 13/25 | Loss: 0.00091272
Iteration 14/25 | Loss: 0.00091272
Iteration 15/25 | Loss: 0.00091272
Iteration 16/25 | Loss: 0.00091272
Iteration 17/25 | Loss: 0.00091272
Iteration 18/25 | Loss: 0.00091272
Iteration 19/25 | Loss: 0.00091272
Iteration 20/25 | Loss: 0.00091272
Iteration 21/25 | Loss: 0.00091272
Iteration 22/25 | Loss: 0.00091272
Iteration 23/25 | Loss: 0.00091272
Iteration 24/25 | Loss: 0.00091272
Iteration 25/25 | Loss: 0.00091272

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00091272
Iteration 2/1000 | Loss: 0.00004327
Iteration 3/1000 | Loss: 0.00003000
Iteration 4/1000 | Loss: 0.00002765
Iteration 5/1000 | Loss: 0.00002646
Iteration 6/1000 | Loss: 0.00002547
Iteration 7/1000 | Loss: 0.00002496
Iteration 8/1000 | Loss: 0.00002458
Iteration 9/1000 | Loss: 0.00002436
Iteration 10/1000 | Loss: 0.00002425
Iteration 11/1000 | Loss: 0.00002421
Iteration 12/1000 | Loss: 0.00002420
Iteration 13/1000 | Loss: 0.00002416
Iteration 14/1000 | Loss: 0.00002415
Iteration 15/1000 | Loss: 0.00002405
Iteration 16/1000 | Loss: 0.00002403
Iteration 17/1000 | Loss: 0.00002399
Iteration 18/1000 | Loss: 0.00002399
Iteration 19/1000 | Loss: 0.00002399
Iteration 20/1000 | Loss: 0.00002397
Iteration 21/1000 | Loss: 0.00002395
Iteration 22/1000 | Loss: 0.00002394
Iteration 23/1000 | Loss: 0.00002394
Iteration 24/1000 | Loss: 0.00002394
Iteration 25/1000 | Loss: 0.00002393
Iteration 26/1000 | Loss: 0.00002392
Iteration 27/1000 | Loss: 0.00002392
Iteration 28/1000 | Loss: 0.00002392
Iteration 29/1000 | Loss: 0.00002391
Iteration 30/1000 | Loss: 0.00002391
Iteration 31/1000 | Loss: 0.00002390
Iteration 32/1000 | Loss: 0.00002389
Iteration 33/1000 | Loss: 0.00002389
Iteration 34/1000 | Loss: 0.00002389
Iteration 35/1000 | Loss: 0.00002388
Iteration 36/1000 | Loss: 0.00002388
Iteration 37/1000 | Loss: 0.00002387
Iteration 38/1000 | Loss: 0.00002387
Iteration 39/1000 | Loss: 0.00002387
Iteration 40/1000 | Loss: 0.00002387
Iteration 41/1000 | Loss: 0.00002387
Iteration 42/1000 | Loss: 0.00002386
Iteration 43/1000 | Loss: 0.00002386
Iteration 44/1000 | Loss: 0.00002386
Iteration 45/1000 | Loss: 0.00002385
Iteration 46/1000 | Loss: 0.00002385
Iteration 47/1000 | Loss: 0.00002384
Iteration 48/1000 | Loss: 0.00002384
Iteration 49/1000 | Loss: 0.00002384
Iteration 50/1000 | Loss: 0.00002384
Iteration 51/1000 | Loss: 0.00002384
Iteration 52/1000 | Loss: 0.00002384
Iteration 53/1000 | Loss: 0.00002383
Iteration 54/1000 | Loss: 0.00002383
Iteration 55/1000 | Loss: 0.00002383
Iteration 56/1000 | Loss: 0.00002383
Iteration 57/1000 | Loss: 0.00002383
Iteration 58/1000 | Loss: 0.00002383
Iteration 59/1000 | Loss: 0.00002382
Iteration 60/1000 | Loss: 0.00002382
Iteration 61/1000 | Loss: 0.00002382
Iteration 62/1000 | Loss: 0.00002382
Iteration 63/1000 | Loss: 0.00002382
Iteration 64/1000 | Loss: 0.00002381
Iteration 65/1000 | Loss: 0.00002381
Iteration 66/1000 | Loss: 0.00002381
Iteration 67/1000 | Loss: 0.00002381
Iteration 68/1000 | Loss: 0.00002381
Iteration 69/1000 | Loss: 0.00002381
Iteration 70/1000 | Loss: 0.00002381
Iteration 71/1000 | Loss: 0.00002381
Iteration 72/1000 | Loss: 0.00002381
Iteration 73/1000 | Loss: 0.00002381
Iteration 74/1000 | Loss: 0.00002381
Iteration 75/1000 | Loss: 0.00002381
Iteration 76/1000 | Loss: 0.00002381
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [2.380741534580011e-05, 2.380741534580011e-05, 2.380741534580011e-05, 2.380741534580011e-05, 2.380741534580011e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.380741534580011e-05

Optimization complete. Final v2v error: 3.8403208255767822 mm

Highest mean error: 4.356118679046631 mm for frame 237

Lowest mean error: 3.5084455013275146 mm for frame 9

Saving results

Total time: 58.29980683326721
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1065/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1065.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1065
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01053415
Iteration 2/25 | Loss: 0.00212430
Iteration 3/25 | Loss: 0.00128619
Iteration 4/25 | Loss: 0.00156250
Iteration 5/25 | Loss: 0.00113719
Iteration 6/25 | Loss: 0.00112602
Iteration 7/25 | Loss: 0.00111110
Iteration 8/25 | Loss: 0.00099218
Iteration 9/25 | Loss: 0.00090634
Iteration 10/25 | Loss: 0.00086792
Iteration 11/25 | Loss: 0.00084291
Iteration 12/25 | Loss: 0.00081448
Iteration 13/25 | Loss: 0.00079900
Iteration 14/25 | Loss: 0.00079531
Iteration 15/25 | Loss: 0.00080024
Iteration 16/25 | Loss: 0.00079913
Iteration 17/25 | Loss: 0.00079085
Iteration 18/25 | Loss: 0.00078818
Iteration 19/25 | Loss: 0.00078752
Iteration 20/25 | Loss: 0.00078738
Iteration 21/25 | Loss: 0.00078726
Iteration 22/25 | Loss: 0.00078718
Iteration 23/25 | Loss: 0.00078717
Iteration 24/25 | Loss: 0.00078716
Iteration 25/25 | Loss: 0.00078716

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.67175770
Iteration 2/25 | Loss: 0.00133568
Iteration 3/25 | Loss: 0.00133568
Iteration 4/25 | Loss: 0.00133567
Iteration 5/25 | Loss: 0.00133567
Iteration 6/25 | Loss: 0.00133567
Iteration 7/25 | Loss: 0.00133567
Iteration 8/25 | Loss: 0.00133567
Iteration 9/25 | Loss: 0.00133567
Iteration 10/25 | Loss: 0.00133567
Iteration 11/25 | Loss: 0.00133567
Iteration 12/25 | Loss: 0.00133567
Iteration 13/25 | Loss: 0.00133567
Iteration 14/25 | Loss: 0.00133567
Iteration 15/25 | Loss: 0.00133567
Iteration 16/25 | Loss: 0.00133567
Iteration 17/25 | Loss: 0.00133567
Iteration 18/25 | Loss: 0.00133567
Iteration 19/25 | Loss: 0.00133567
Iteration 20/25 | Loss: 0.00133567
Iteration 21/25 | Loss: 0.00133567
Iteration 22/25 | Loss: 0.00133567
Iteration 23/25 | Loss: 0.00133567
Iteration 24/25 | Loss: 0.00133567
Iteration 25/25 | Loss: 0.00133567

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00133567
Iteration 2/1000 | Loss: 0.00003501
Iteration 3/1000 | Loss: 0.00038624
Iteration 4/1000 | Loss: 0.00003264
Iteration 5/1000 | Loss: 0.00002615
Iteration 6/1000 | Loss: 0.00002297
Iteration 7/1000 | Loss: 0.00002103
Iteration 8/1000 | Loss: 0.00001923
Iteration 9/1000 | Loss: 0.00001842
Iteration 10/1000 | Loss: 0.00001790
Iteration 11/1000 | Loss: 0.00001742
Iteration 12/1000 | Loss: 0.00001704
Iteration 13/1000 | Loss: 0.00001679
Iteration 14/1000 | Loss: 0.00001663
Iteration 15/1000 | Loss: 0.00001655
Iteration 16/1000 | Loss: 0.00001637
Iteration 17/1000 | Loss: 0.00001635
Iteration 18/1000 | Loss: 0.00001628
Iteration 19/1000 | Loss: 0.00001628
Iteration 20/1000 | Loss: 0.00001627
Iteration 21/1000 | Loss: 0.00001627
Iteration 22/1000 | Loss: 0.00001626
Iteration 23/1000 | Loss: 0.00001626
Iteration 24/1000 | Loss: 0.00001626
Iteration 25/1000 | Loss: 0.00001626
Iteration 26/1000 | Loss: 0.00001625
Iteration 27/1000 | Loss: 0.00001625
Iteration 28/1000 | Loss: 0.00001625
Iteration 29/1000 | Loss: 0.00001625
Iteration 30/1000 | Loss: 0.00001625
Iteration 31/1000 | Loss: 0.00001625
Iteration 32/1000 | Loss: 0.00001625
Iteration 33/1000 | Loss: 0.00001625
Iteration 34/1000 | Loss: 0.00001625
Iteration 35/1000 | Loss: 0.00001625
Iteration 36/1000 | Loss: 0.00001624
Iteration 37/1000 | Loss: 0.00001624
Iteration 38/1000 | Loss: 0.00001623
Iteration 39/1000 | Loss: 0.00001623
Iteration 40/1000 | Loss: 0.00001623
Iteration 41/1000 | Loss: 0.00001622
Iteration 42/1000 | Loss: 0.00001622
Iteration 43/1000 | Loss: 0.00001621
Iteration 44/1000 | Loss: 0.00001620
Iteration 45/1000 | Loss: 0.00001619
Iteration 46/1000 | Loss: 0.00001617
Iteration 47/1000 | Loss: 0.00001617
Iteration 48/1000 | Loss: 0.00001616
Iteration 49/1000 | Loss: 0.00001616
Iteration 50/1000 | Loss: 0.00001615
Iteration 51/1000 | Loss: 0.00001614
Iteration 52/1000 | Loss: 0.00001614
Iteration 53/1000 | Loss: 0.00001614
Iteration 54/1000 | Loss: 0.00001614
Iteration 55/1000 | Loss: 0.00001613
Iteration 56/1000 | Loss: 0.00001613
Iteration 57/1000 | Loss: 0.00001613
Iteration 58/1000 | Loss: 0.00001612
Iteration 59/1000 | Loss: 0.00001612
Iteration 60/1000 | Loss: 0.00001612
Iteration 61/1000 | Loss: 0.00001612
Iteration 62/1000 | Loss: 0.00001612
Iteration 63/1000 | Loss: 0.00001612
Iteration 64/1000 | Loss: 0.00001612
Iteration 65/1000 | Loss: 0.00001611
Iteration 66/1000 | Loss: 0.00001611
Iteration 67/1000 | Loss: 0.00001611
Iteration 68/1000 | Loss: 0.00001611
Iteration 69/1000 | Loss: 0.00001610
Iteration 70/1000 | Loss: 0.00001610
Iteration 71/1000 | Loss: 0.00001610
Iteration 72/1000 | Loss: 0.00001610
Iteration 73/1000 | Loss: 0.00001609
Iteration 74/1000 | Loss: 0.00001609
Iteration 75/1000 | Loss: 0.00001609
Iteration 76/1000 | Loss: 0.00001609
Iteration 77/1000 | Loss: 0.00001609
Iteration 78/1000 | Loss: 0.00001609
Iteration 79/1000 | Loss: 0.00001609
Iteration 80/1000 | Loss: 0.00001608
Iteration 81/1000 | Loss: 0.00001608
Iteration 82/1000 | Loss: 0.00001608
Iteration 83/1000 | Loss: 0.00001608
Iteration 84/1000 | Loss: 0.00001608
Iteration 85/1000 | Loss: 0.00001608
Iteration 86/1000 | Loss: 0.00001608
Iteration 87/1000 | Loss: 0.00001608
Iteration 88/1000 | Loss: 0.00001608
Iteration 89/1000 | Loss: 0.00001607
Iteration 90/1000 | Loss: 0.00001607
Iteration 91/1000 | Loss: 0.00001607
Iteration 92/1000 | Loss: 0.00001607
Iteration 93/1000 | Loss: 0.00001607
Iteration 94/1000 | Loss: 0.00001607
Iteration 95/1000 | Loss: 0.00001607
Iteration 96/1000 | Loss: 0.00001607
Iteration 97/1000 | Loss: 0.00001607
Iteration 98/1000 | Loss: 0.00001607
Iteration 99/1000 | Loss: 0.00001607
Iteration 100/1000 | Loss: 0.00001607
Iteration 101/1000 | Loss: 0.00001607
Iteration 102/1000 | Loss: 0.00001607
Iteration 103/1000 | Loss: 0.00001607
Iteration 104/1000 | Loss: 0.00001607
Iteration 105/1000 | Loss: 0.00001606
Iteration 106/1000 | Loss: 0.00001606
Iteration 107/1000 | Loss: 0.00001606
Iteration 108/1000 | Loss: 0.00001606
Iteration 109/1000 | Loss: 0.00001606
Iteration 110/1000 | Loss: 0.00001606
Iteration 111/1000 | Loss: 0.00001606
Iteration 112/1000 | Loss: 0.00001606
Iteration 113/1000 | Loss: 0.00001606
Iteration 114/1000 | Loss: 0.00001606
Iteration 115/1000 | Loss: 0.00001606
Iteration 116/1000 | Loss: 0.00001605
Iteration 117/1000 | Loss: 0.00001605
Iteration 118/1000 | Loss: 0.00001605
Iteration 119/1000 | Loss: 0.00001605
Iteration 120/1000 | Loss: 0.00001605
Iteration 121/1000 | Loss: 0.00001605
Iteration 122/1000 | Loss: 0.00001605
Iteration 123/1000 | Loss: 0.00001604
Iteration 124/1000 | Loss: 0.00001604
Iteration 125/1000 | Loss: 0.00001604
Iteration 126/1000 | Loss: 0.00001604
Iteration 127/1000 | Loss: 0.00001604
Iteration 128/1000 | Loss: 0.00001603
Iteration 129/1000 | Loss: 0.00001603
Iteration 130/1000 | Loss: 0.00001603
Iteration 131/1000 | Loss: 0.00001603
Iteration 132/1000 | Loss: 0.00001603
Iteration 133/1000 | Loss: 0.00001603
Iteration 134/1000 | Loss: 0.00001603
Iteration 135/1000 | Loss: 0.00001603
Iteration 136/1000 | Loss: 0.00001602
Iteration 137/1000 | Loss: 0.00001602
Iteration 138/1000 | Loss: 0.00001602
Iteration 139/1000 | Loss: 0.00001602
Iteration 140/1000 | Loss: 0.00001602
Iteration 141/1000 | Loss: 0.00001602
Iteration 142/1000 | Loss: 0.00001602
Iteration 143/1000 | Loss: 0.00001602
Iteration 144/1000 | Loss: 0.00001602
Iteration 145/1000 | Loss: 0.00001602
Iteration 146/1000 | Loss: 0.00001602
Iteration 147/1000 | Loss: 0.00001602
Iteration 148/1000 | Loss: 0.00001602
Iteration 149/1000 | Loss: 0.00001602
Iteration 150/1000 | Loss: 0.00001602
Iteration 151/1000 | Loss: 0.00001601
Iteration 152/1000 | Loss: 0.00001601
Iteration 153/1000 | Loss: 0.00001601
Iteration 154/1000 | Loss: 0.00001601
Iteration 155/1000 | Loss: 0.00001601
Iteration 156/1000 | Loss: 0.00001601
Iteration 157/1000 | Loss: 0.00001601
Iteration 158/1000 | Loss: 0.00001601
Iteration 159/1000 | Loss: 0.00001601
Iteration 160/1000 | Loss: 0.00001601
Iteration 161/1000 | Loss: 0.00001601
Iteration 162/1000 | Loss: 0.00001601
Iteration 163/1000 | Loss: 0.00001601
Iteration 164/1000 | Loss: 0.00001601
Iteration 165/1000 | Loss: 0.00001601
Iteration 166/1000 | Loss: 0.00001601
Iteration 167/1000 | Loss: 0.00001601
Iteration 168/1000 | Loss: 0.00001601
Iteration 169/1000 | Loss: 0.00001600
Iteration 170/1000 | Loss: 0.00001600
Iteration 171/1000 | Loss: 0.00001600
Iteration 172/1000 | Loss: 0.00001600
Iteration 173/1000 | Loss: 0.00001600
Iteration 174/1000 | Loss: 0.00001600
Iteration 175/1000 | Loss: 0.00001600
Iteration 176/1000 | Loss: 0.00001600
Iteration 177/1000 | Loss: 0.00001600
Iteration 178/1000 | Loss: 0.00001600
Iteration 179/1000 | Loss: 0.00001600
Iteration 180/1000 | Loss: 0.00001600
Iteration 181/1000 | Loss: 0.00001599
Iteration 182/1000 | Loss: 0.00001599
Iteration 183/1000 | Loss: 0.00001599
Iteration 184/1000 | Loss: 0.00001599
Iteration 185/1000 | Loss: 0.00001599
Iteration 186/1000 | Loss: 0.00001599
Iteration 187/1000 | Loss: 0.00001599
Iteration 188/1000 | Loss: 0.00001599
Iteration 189/1000 | Loss: 0.00001599
Iteration 190/1000 | Loss: 0.00001599
Iteration 191/1000 | Loss: 0.00001599
Iteration 192/1000 | Loss: 0.00001599
Iteration 193/1000 | Loss: 0.00001599
Iteration 194/1000 | Loss: 0.00001599
Iteration 195/1000 | Loss: 0.00001599
Iteration 196/1000 | Loss: 0.00001599
Iteration 197/1000 | Loss: 0.00001598
Iteration 198/1000 | Loss: 0.00001598
Iteration 199/1000 | Loss: 0.00001598
Iteration 200/1000 | Loss: 0.00001598
Iteration 201/1000 | Loss: 0.00001598
Iteration 202/1000 | Loss: 0.00001598
Iteration 203/1000 | Loss: 0.00001598
Iteration 204/1000 | Loss: 0.00001598
Iteration 205/1000 | Loss: 0.00001598
Iteration 206/1000 | Loss: 0.00001598
Iteration 207/1000 | Loss: 0.00001598
Iteration 208/1000 | Loss: 0.00001598
Iteration 209/1000 | Loss: 0.00001598
Iteration 210/1000 | Loss: 0.00001598
Iteration 211/1000 | Loss: 0.00001597
Iteration 212/1000 | Loss: 0.00001597
Iteration 213/1000 | Loss: 0.00001597
Iteration 214/1000 | Loss: 0.00001597
Iteration 215/1000 | Loss: 0.00001597
Iteration 216/1000 | Loss: 0.00001597
Iteration 217/1000 | Loss: 0.00001597
Iteration 218/1000 | Loss: 0.00001597
Iteration 219/1000 | Loss: 0.00001597
Iteration 220/1000 | Loss: 0.00001597
Iteration 221/1000 | Loss: 0.00001597
Iteration 222/1000 | Loss: 0.00001596
Iteration 223/1000 | Loss: 0.00001596
Iteration 224/1000 | Loss: 0.00001596
Iteration 225/1000 | Loss: 0.00001596
Iteration 226/1000 | Loss: 0.00001596
Iteration 227/1000 | Loss: 0.00001596
Iteration 228/1000 | Loss: 0.00001596
Iteration 229/1000 | Loss: 0.00001596
Iteration 230/1000 | Loss: 0.00001596
Iteration 231/1000 | Loss: 0.00001596
Iteration 232/1000 | Loss: 0.00001596
Iteration 233/1000 | Loss: 0.00001596
Iteration 234/1000 | Loss: 0.00001596
Iteration 235/1000 | Loss: 0.00001596
Iteration 236/1000 | Loss: 0.00001596
Iteration 237/1000 | Loss: 0.00001596
Iteration 238/1000 | Loss: 0.00001596
Iteration 239/1000 | Loss: 0.00001596
Iteration 240/1000 | Loss: 0.00001596
Iteration 241/1000 | Loss: 0.00001596
Iteration 242/1000 | Loss: 0.00001596
Iteration 243/1000 | Loss: 0.00001596
Iteration 244/1000 | Loss: 0.00001596
Iteration 245/1000 | Loss: 0.00001596
Iteration 246/1000 | Loss: 0.00001596
Iteration 247/1000 | Loss: 0.00001596
Iteration 248/1000 | Loss: 0.00001595
Iteration 249/1000 | Loss: 0.00001595
Iteration 250/1000 | Loss: 0.00001595
Iteration 251/1000 | Loss: 0.00001595
Iteration 252/1000 | Loss: 0.00001595
Iteration 253/1000 | Loss: 0.00001595
Iteration 254/1000 | Loss: 0.00001595
Iteration 255/1000 | Loss: 0.00001595
Iteration 256/1000 | Loss: 0.00001595
Iteration 257/1000 | Loss: 0.00001595
Iteration 258/1000 | Loss: 0.00001595
Iteration 259/1000 | Loss: 0.00001595
Iteration 260/1000 | Loss: 0.00001595
Iteration 261/1000 | Loss: 0.00001595
Iteration 262/1000 | Loss: 0.00001595
Iteration 263/1000 | Loss: 0.00001595
Iteration 264/1000 | Loss: 0.00001595
Iteration 265/1000 | Loss: 0.00001595
Iteration 266/1000 | Loss: 0.00001595
Iteration 267/1000 | Loss: 0.00001595
Iteration 268/1000 | Loss: 0.00001595
Iteration 269/1000 | Loss: 0.00001595
Iteration 270/1000 | Loss: 0.00001595
Iteration 271/1000 | Loss: 0.00001595
Iteration 272/1000 | Loss: 0.00001595
Iteration 273/1000 | Loss: 0.00001595
Iteration 274/1000 | Loss: 0.00001595
Iteration 275/1000 | Loss: 0.00001595
Iteration 276/1000 | Loss: 0.00001595
Iteration 277/1000 | Loss: 0.00001595
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 277. Stopping optimization.
Last 5 losses: [1.595493267814163e-05, 1.595493267814163e-05, 1.595493267814163e-05, 1.595493267814163e-05, 1.595493267814163e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.595493267814163e-05

Optimization complete. Final v2v error: 3.3166940212249756 mm

Highest mean error: 4.418169021606445 mm for frame 61

Lowest mean error: 2.721529245376587 mm for frame 12

Saving results

Total time: 77.67431998252869
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1095/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1095.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1095
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00383280
Iteration 2/25 | Loss: 0.00096517
Iteration 3/25 | Loss: 0.00081351
Iteration 4/25 | Loss: 0.00078312
Iteration 5/25 | Loss: 0.00077453
Iteration 6/25 | Loss: 0.00077090
Iteration 7/25 | Loss: 0.00076997
Iteration 8/25 | Loss: 0.00076997
Iteration 9/25 | Loss: 0.00076997
Iteration 10/25 | Loss: 0.00076997
Iteration 11/25 | Loss: 0.00076997
Iteration 12/25 | Loss: 0.00076997
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007699711713939905, 0.0007699711713939905, 0.0007699711713939905, 0.0007699711713939905, 0.0007699711713939905]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007699711713939905

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.00600624
Iteration 2/25 | Loss: 0.00106287
Iteration 3/25 | Loss: 0.00106287
Iteration 4/25 | Loss: 0.00106287
Iteration 5/25 | Loss: 0.00106287
Iteration 6/25 | Loss: 0.00106287
Iteration 7/25 | Loss: 0.00106287
Iteration 8/25 | Loss: 0.00106287
Iteration 9/25 | Loss: 0.00106287
Iteration 10/25 | Loss: 0.00106287
Iteration 11/25 | Loss: 0.00106287
Iteration 12/25 | Loss: 0.00106287
Iteration 13/25 | Loss: 0.00106287
Iteration 14/25 | Loss: 0.00106287
Iteration 15/25 | Loss: 0.00106287
Iteration 16/25 | Loss: 0.00106287
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010628658346831799, 0.0010628658346831799, 0.0010628658346831799, 0.0010628658346831799, 0.0010628658346831799]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010628658346831799

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00106287
Iteration 2/1000 | Loss: 0.00003617
Iteration 3/1000 | Loss: 0.00002125
Iteration 4/1000 | Loss: 0.00001860
Iteration 5/1000 | Loss: 0.00001756
Iteration 6/1000 | Loss: 0.00001667
Iteration 7/1000 | Loss: 0.00001629
Iteration 8/1000 | Loss: 0.00001599
Iteration 9/1000 | Loss: 0.00001582
Iteration 10/1000 | Loss: 0.00001567
Iteration 11/1000 | Loss: 0.00001566
Iteration 12/1000 | Loss: 0.00001564
Iteration 13/1000 | Loss: 0.00001562
Iteration 14/1000 | Loss: 0.00001562
Iteration 15/1000 | Loss: 0.00001561
Iteration 16/1000 | Loss: 0.00001543
Iteration 17/1000 | Loss: 0.00001531
Iteration 18/1000 | Loss: 0.00001527
Iteration 19/1000 | Loss: 0.00001525
Iteration 20/1000 | Loss: 0.00001524
Iteration 21/1000 | Loss: 0.00001524
Iteration 22/1000 | Loss: 0.00001521
Iteration 23/1000 | Loss: 0.00001517
Iteration 24/1000 | Loss: 0.00001517
Iteration 25/1000 | Loss: 0.00001516
Iteration 26/1000 | Loss: 0.00001509
Iteration 27/1000 | Loss: 0.00001508
Iteration 28/1000 | Loss: 0.00001506
Iteration 29/1000 | Loss: 0.00001504
Iteration 30/1000 | Loss: 0.00001503
Iteration 31/1000 | Loss: 0.00001502
Iteration 32/1000 | Loss: 0.00001497
Iteration 33/1000 | Loss: 0.00001497
Iteration 34/1000 | Loss: 0.00001496
Iteration 35/1000 | Loss: 0.00001496
Iteration 36/1000 | Loss: 0.00001495
Iteration 37/1000 | Loss: 0.00001491
Iteration 38/1000 | Loss: 0.00001490
Iteration 39/1000 | Loss: 0.00001489
Iteration 40/1000 | Loss: 0.00001489
Iteration 41/1000 | Loss: 0.00001488
Iteration 42/1000 | Loss: 0.00001488
Iteration 43/1000 | Loss: 0.00001487
Iteration 44/1000 | Loss: 0.00001487
Iteration 45/1000 | Loss: 0.00001487
Iteration 46/1000 | Loss: 0.00001487
Iteration 47/1000 | Loss: 0.00001487
Iteration 48/1000 | Loss: 0.00001486
Iteration 49/1000 | Loss: 0.00001486
Iteration 50/1000 | Loss: 0.00001486
Iteration 51/1000 | Loss: 0.00001486
Iteration 52/1000 | Loss: 0.00001486
Iteration 53/1000 | Loss: 0.00001485
Iteration 54/1000 | Loss: 0.00001485
Iteration 55/1000 | Loss: 0.00001484
Iteration 56/1000 | Loss: 0.00001484
Iteration 57/1000 | Loss: 0.00001484
Iteration 58/1000 | Loss: 0.00001483
Iteration 59/1000 | Loss: 0.00001483
Iteration 60/1000 | Loss: 0.00001483
Iteration 61/1000 | Loss: 0.00001483
Iteration 62/1000 | Loss: 0.00001482
Iteration 63/1000 | Loss: 0.00001482
Iteration 64/1000 | Loss: 0.00001482
Iteration 65/1000 | Loss: 0.00001481
Iteration 66/1000 | Loss: 0.00001481
Iteration 67/1000 | Loss: 0.00001481
Iteration 68/1000 | Loss: 0.00001481
Iteration 69/1000 | Loss: 0.00001480
Iteration 70/1000 | Loss: 0.00001480
Iteration 71/1000 | Loss: 0.00001479
Iteration 72/1000 | Loss: 0.00001479
Iteration 73/1000 | Loss: 0.00001478
Iteration 74/1000 | Loss: 0.00001478
Iteration 75/1000 | Loss: 0.00001478
Iteration 76/1000 | Loss: 0.00001477
Iteration 77/1000 | Loss: 0.00001477
Iteration 78/1000 | Loss: 0.00001477
Iteration 79/1000 | Loss: 0.00001477
Iteration 80/1000 | Loss: 0.00001477
Iteration 81/1000 | Loss: 0.00001476
Iteration 82/1000 | Loss: 0.00001476
Iteration 83/1000 | Loss: 0.00001476
Iteration 84/1000 | Loss: 0.00001476
Iteration 85/1000 | Loss: 0.00001475
Iteration 86/1000 | Loss: 0.00001475
Iteration 87/1000 | Loss: 0.00001474
Iteration 88/1000 | Loss: 0.00001474
Iteration 89/1000 | Loss: 0.00001474
Iteration 90/1000 | Loss: 0.00001474
Iteration 91/1000 | Loss: 0.00001474
Iteration 92/1000 | Loss: 0.00001474
Iteration 93/1000 | Loss: 0.00001474
Iteration 94/1000 | Loss: 0.00001473
Iteration 95/1000 | Loss: 0.00001473
Iteration 96/1000 | Loss: 0.00001473
Iteration 97/1000 | Loss: 0.00001473
Iteration 98/1000 | Loss: 0.00001473
Iteration 99/1000 | Loss: 0.00001472
Iteration 100/1000 | Loss: 0.00001471
Iteration 101/1000 | Loss: 0.00001470
Iteration 102/1000 | Loss: 0.00001470
Iteration 103/1000 | Loss: 0.00001469
Iteration 104/1000 | Loss: 0.00001469
Iteration 105/1000 | Loss: 0.00001469
Iteration 106/1000 | Loss: 0.00001469
Iteration 107/1000 | Loss: 0.00001469
Iteration 108/1000 | Loss: 0.00001468
Iteration 109/1000 | Loss: 0.00001468
Iteration 110/1000 | Loss: 0.00001468
Iteration 111/1000 | Loss: 0.00001468
Iteration 112/1000 | Loss: 0.00001468
Iteration 113/1000 | Loss: 0.00001468
Iteration 114/1000 | Loss: 0.00001468
Iteration 115/1000 | Loss: 0.00001467
Iteration 116/1000 | Loss: 0.00001467
Iteration 117/1000 | Loss: 0.00001467
Iteration 118/1000 | Loss: 0.00001467
Iteration 119/1000 | Loss: 0.00001467
Iteration 120/1000 | Loss: 0.00001467
Iteration 121/1000 | Loss: 0.00001467
Iteration 122/1000 | Loss: 0.00001466
Iteration 123/1000 | Loss: 0.00001466
Iteration 124/1000 | Loss: 0.00001466
Iteration 125/1000 | Loss: 0.00001466
Iteration 126/1000 | Loss: 0.00001466
Iteration 127/1000 | Loss: 0.00001466
Iteration 128/1000 | Loss: 0.00001466
Iteration 129/1000 | Loss: 0.00001466
Iteration 130/1000 | Loss: 0.00001466
Iteration 131/1000 | Loss: 0.00001466
Iteration 132/1000 | Loss: 0.00001466
Iteration 133/1000 | Loss: 0.00001465
Iteration 134/1000 | Loss: 0.00001465
Iteration 135/1000 | Loss: 0.00001465
Iteration 136/1000 | Loss: 0.00001465
Iteration 137/1000 | Loss: 0.00001465
Iteration 138/1000 | Loss: 0.00001465
Iteration 139/1000 | Loss: 0.00001465
Iteration 140/1000 | Loss: 0.00001464
Iteration 141/1000 | Loss: 0.00001464
Iteration 142/1000 | Loss: 0.00001464
Iteration 143/1000 | Loss: 0.00001464
Iteration 144/1000 | Loss: 0.00001464
Iteration 145/1000 | Loss: 0.00001464
Iteration 146/1000 | Loss: 0.00001463
Iteration 147/1000 | Loss: 0.00001463
Iteration 148/1000 | Loss: 0.00001463
Iteration 149/1000 | Loss: 0.00001463
Iteration 150/1000 | Loss: 0.00001463
Iteration 151/1000 | Loss: 0.00001463
Iteration 152/1000 | Loss: 0.00001463
Iteration 153/1000 | Loss: 0.00001463
Iteration 154/1000 | Loss: 0.00001462
Iteration 155/1000 | Loss: 0.00001462
Iteration 156/1000 | Loss: 0.00001462
Iteration 157/1000 | Loss: 0.00001462
Iteration 158/1000 | Loss: 0.00001462
Iteration 159/1000 | Loss: 0.00001462
Iteration 160/1000 | Loss: 0.00001462
Iteration 161/1000 | Loss: 0.00001462
Iteration 162/1000 | Loss: 0.00001462
Iteration 163/1000 | Loss: 0.00001462
Iteration 164/1000 | Loss: 0.00001462
Iteration 165/1000 | Loss: 0.00001462
Iteration 166/1000 | Loss: 0.00001462
Iteration 167/1000 | Loss: 0.00001462
Iteration 168/1000 | Loss: 0.00001462
Iteration 169/1000 | Loss: 0.00001462
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 169. Stopping optimization.
Last 5 losses: [1.4616405678680167e-05, 1.4616405678680167e-05, 1.4616405678680167e-05, 1.4616405678680167e-05, 1.4616405678680167e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4616405678680167e-05

Optimization complete. Final v2v error: 3.2109386920928955 mm

Highest mean error: 3.321075439453125 mm for frame 9

Lowest mean error: 3.145677328109741 mm for frame 166

Saving results

Total time: 44.078020334243774
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_aaron_posed_009/1093/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1093.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_aaron_posed_009/1093
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00503455
Iteration 2/25 | Loss: 0.00103277
Iteration 3/25 | Loss: 0.00089227
Iteration 4/25 | Loss: 0.00085996
Iteration 5/25 | Loss: 0.00085527
Iteration 6/25 | Loss: 0.00085423
Iteration 7/25 | Loss: 0.00085423
Iteration 8/25 | Loss: 0.00085423
Iteration 9/25 | Loss: 0.00085423
Iteration 10/25 | Loss: 0.00085423
Iteration 11/25 | Loss: 0.00085423
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008542269933968782, 0.0008542269933968782, 0.0008542269933968782, 0.0008542269933968782, 0.0008542269933968782]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008542269933968782

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55091870
Iteration 2/25 | Loss: 0.00112236
Iteration 3/25 | Loss: 0.00112235
Iteration 4/25 | Loss: 0.00112235
Iteration 5/25 | Loss: 0.00112235
Iteration 6/25 | Loss: 0.00112235
Iteration 7/25 | Loss: 0.00112235
Iteration 8/25 | Loss: 0.00112235
Iteration 9/25 | Loss: 0.00112235
Iteration 10/25 | Loss: 0.00112235
Iteration 11/25 | Loss: 0.00112235
Iteration 12/25 | Loss: 0.00112235
Iteration 13/25 | Loss: 0.00112235
Iteration 14/25 | Loss: 0.00112235
Iteration 15/25 | Loss: 0.00112235
Iteration 16/25 | Loss: 0.00112235
Iteration 17/25 | Loss: 0.00112235
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001122350338846445, 0.001122350338846445, 0.001122350338846445, 0.001122350338846445, 0.001122350338846445]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001122350338846445

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00112235
Iteration 2/1000 | Loss: 0.00007053
Iteration 3/1000 | Loss: 0.00004113
Iteration 4/1000 | Loss: 0.00003724
Iteration 5/1000 | Loss: 0.00003518
Iteration 6/1000 | Loss: 0.00003426
Iteration 7/1000 | Loss: 0.00003340
Iteration 8/1000 | Loss: 0.00003283
Iteration 9/1000 | Loss: 0.00003240
Iteration 10/1000 | Loss: 0.00003212
Iteration 11/1000 | Loss: 0.00003191
Iteration 12/1000 | Loss: 0.00003181
Iteration 13/1000 | Loss: 0.00003170
Iteration 14/1000 | Loss: 0.00003169
Iteration 15/1000 | Loss: 0.00003166
Iteration 16/1000 | Loss: 0.00003157
Iteration 17/1000 | Loss: 0.00003153
Iteration 18/1000 | Loss: 0.00003142
Iteration 19/1000 | Loss: 0.00003139
Iteration 20/1000 | Loss: 0.00003139
Iteration 21/1000 | Loss: 0.00003138
Iteration 22/1000 | Loss: 0.00003136
Iteration 23/1000 | Loss: 0.00003135
Iteration 24/1000 | Loss: 0.00003135
Iteration 25/1000 | Loss: 0.00003135
Iteration 26/1000 | Loss: 0.00003134
Iteration 27/1000 | Loss: 0.00003134
Iteration 28/1000 | Loss: 0.00003134
Iteration 29/1000 | Loss: 0.00003134
Iteration 30/1000 | Loss: 0.00003133
Iteration 31/1000 | Loss: 0.00003133
Iteration 32/1000 | Loss: 0.00003132
Iteration 33/1000 | Loss: 0.00003131
Iteration 34/1000 | Loss: 0.00003130
Iteration 35/1000 | Loss: 0.00003130
Iteration 36/1000 | Loss: 0.00003130
Iteration 37/1000 | Loss: 0.00003130
Iteration 38/1000 | Loss: 0.00003130
Iteration 39/1000 | Loss: 0.00003130
Iteration 40/1000 | Loss: 0.00003130
Iteration 41/1000 | Loss: 0.00003130
Iteration 42/1000 | Loss: 0.00003130
Iteration 43/1000 | Loss: 0.00003130
Iteration 44/1000 | Loss: 0.00003130
Iteration 45/1000 | Loss: 0.00003129
Iteration 46/1000 | Loss: 0.00003129
Iteration 47/1000 | Loss: 0.00003129
Iteration 48/1000 | Loss: 0.00003129
Iteration 49/1000 | Loss: 0.00003128
Iteration 50/1000 | Loss: 0.00003128
Iteration 51/1000 | Loss: 0.00003128
Iteration 52/1000 | Loss: 0.00003127
Iteration 53/1000 | Loss: 0.00003127
Iteration 54/1000 | Loss: 0.00003126
Iteration 55/1000 | Loss: 0.00003126
Iteration 56/1000 | Loss: 0.00003126
Iteration 57/1000 | Loss: 0.00003126
Iteration 58/1000 | Loss: 0.00003126
Iteration 59/1000 | Loss: 0.00003126
Iteration 60/1000 | Loss: 0.00003126
Iteration 61/1000 | Loss: 0.00003126
Iteration 62/1000 | Loss: 0.00003125
Iteration 63/1000 | Loss: 0.00003125
Iteration 64/1000 | Loss: 0.00003125
Iteration 65/1000 | Loss: 0.00003124
Iteration 66/1000 | Loss: 0.00003124
Iteration 67/1000 | Loss: 0.00003124
Iteration 68/1000 | Loss: 0.00003124
Iteration 69/1000 | Loss: 0.00003124
Iteration 70/1000 | Loss: 0.00003124
Iteration 71/1000 | Loss: 0.00003124
Iteration 72/1000 | Loss: 0.00003124
Iteration 73/1000 | Loss: 0.00003124
Iteration 74/1000 | Loss: 0.00003124
Iteration 75/1000 | Loss: 0.00003123
Iteration 76/1000 | Loss: 0.00003123
Iteration 77/1000 | Loss: 0.00003123
Iteration 78/1000 | Loss: 0.00003123
Iteration 79/1000 | Loss: 0.00003123
Iteration 80/1000 | Loss: 0.00003123
Iteration 81/1000 | Loss: 0.00003123
Iteration 82/1000 | Loss: 0.00003123
Iteration 83/1000 | Loss: 0.00003123
Iteration 84/1000 | Loss: 0.00003123
Iteration 85/1000 | Loss: 0.00003123
Iteration 86/1000 | Loss: 0.00003123
Iteration 87/1000 | Loss: 0.00003122
Iteration 88/1000 | Loss: 0.00003122
Iteration 89/1000 | Loss: 0.00003122
Iteration 90/1000 | Loss: 0.00003122
Iteration 91/1000 | Loss: 0.00003122
Iteration 92/1000 | Loss: 0.00003122
Iteration 93/1000 | Loss: 0.00003122
Iteration 94/1000 | Loss: 0.00003122
Iteration 95/1000 | Loss: 0.00003122
Iteration 96/1000 | Loss: 0.00003122
Iteration 97/1000 | Loss: 0.00003122
Iteration 98/1000 | Loss: 0.00003122
Iteration 99/1000 | Loss: 0.00003122
Iteration 100/1000 | Loss: 0.00003122
Iteration 101/1000 | Loss: 0.00003122
Iteration 102/1000 | Loss: 0.00003122
Iteration 103/1000 | Loss: 0.00003122
Iteration 104/1000 | Loss: 0.00003122
Iteration 105/1000 | Loss: 0.00003122
Iteration 106/1000 | Loss: 0.00003122
Iteration 107/1000 | Loss: 0.00003122
Iteration 108/1000 | Loss: 0.00003122
Iteration 109/1000 | Loss: 0.00003122
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [3.1215462513500825e-05, 3.1215462513500825e-05, 3.1215462513500825e-05, 3.1215462513500825e-05, 3.1215462513500825e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.1215462513500825e-05

Optimization complete. Final v2v error: 4.357082843780518 mm

Highest mean error: 5.414502143859863 mm for frame 92

Lowest mean error: 3.6823554039001465 mm for frame 132

Saving results

Total time: 37.854637145996094

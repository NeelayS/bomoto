Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=104, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 5824-5879
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_nl_5417/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_nl_5417/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_nl_5417/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00416471
Iteration 2/25 | Loss: 0.00115383
Iteration 3/25 | Loss: 0.00089361
Iteration 4/25 | Loss: 0.00086141
Iteration 5/25 | Loss: 0.00085277
Iteration 6/25 | Loss: 0.00085136
Iteration 7/25 | Loss: 0.00085107
Iteration 8/25 | Loss: 0.00085107
Iteration 9/25 | Loss: 0.00085107
Iteration 10/25 | Loss: 0.00085107
Iteration 11/25 | Loss: 0.00085107
Iteration 12/25 | Loss: 0.00085107
Iteration 13/25 | Loss: 0.00085107
Iteration 14/25 | Loss: 0.00085107
Iteration 15/25 | Loss: 0.00085107
Iteration 16/25 | Loss: 0.00085107
Iteration 17/25 | Loss: 0.00085107
Iteration 18/25 | Loss: 0.00085107
Iteration 19/25 | Loss: 0.00085107
Iteration 20/25 | Loss: 0.00085107
Iteration 21/25 | Loss: 0.00085107
Iteration 22/25 | Loss: 0.00085107
Iteration 23/25 | Loss: 0.00085107
Iteration 24/25 | Loss: 0.00085107
Iteration 25/25 | Loss: 0.00085107

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.36106408
Iteration 2/25 | Loss: 0.00034005
Iteration 3/25 | Loss: 0.00034005
Iteration 4/25 | Loss: 0.00034005
Iteration 5/25 | Loss: 0.00034005
Iteration 6/25 | Loss: 0.00034005
Iteration 7/25 | Loss: 0.00034005
Iteration 8/25 | Loss: 0.00034005
Iteration 9/25 | Loss: 0.00034005
Iteration 10/25 | Loss: 0.00034005
Iteration 11/25 | Loss: 0.00034005
Iteration 12/25 | Loss: 0.00034005
Iteration 13/25 | Loss: 0.00034005
Iteration 14/25 | Loss: 0.00034005
Iteration 15/25 | Loss: 0.00034005
Iteration 16/25 | Loss: 0.00034005
Iteration 17/25 | Loss: 0.00034005
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0003400454006623477, 0.0003400454006623477, 0.0003400454006623477, 0.0003400454006623477, 0.0003400454006623477]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003400454006623477

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034005
Iteration 2/1000 | Loss: 0.00002356
Iteration 3/1000 | Loss: 0.00001847
Iteration 4/1000 | Loss: 0.00001640
Iteration 5/1000 | Loss: 0.00001586
Iteration 6/1000 | Loss: 0.00001530
Iteration 7/1000 | Loss: 0.00001496
Iteration 8/1000 | Loss: 0.00001479
Iteration 9/1000 | Loss: 0.00001472
Iteration 10/1000 | Loss: 0.00001456
Iteration 11/1000 | Loss: 0.00001456
Iteration 12/1000 | Loss: 0.00001451
Iteration 13/1000 | Loss: 0.00001450
Iteration 14/1000 | Loss: 0.00001449
Iteration 15/1000 | Loss: 0.00001446
Iteration 16/1000 | Loss: 0.00001445
Iteration 17/1000 | Loss: 0.00001444
Iteration 18/1000 | Loss: 0.00001444
Iteration 19/1000 | Loss: 0.00001444
Iteration 20/1000 | Loss: 0.00001443
Iteration 21/1000 | Loss: 0.00001436
Iteration 22/1000 | Loss: 0.00001432
Iteration 23/1000 | Loss: 0.00001432
Iteration 24/1000 | Loss: 0.00001432
Iteration 25/1000 | Loss: 0.00001432
Iteration 26/1000 | Loss: 0.00001428
Iteration 27/1000 | Loss: 0.00001428
Iteration 28/1000 | Loss: 0.00001428
Iteration 29/1000 | Loss: 0.00001428
Iteration 30/1000 | Loss: 0.00001428
Iteration 31/1000 | Loss: 0.00001428
Iteration 32/1000 | Loss: 0.00001428
Iteration 33/1000 | Loss: 0.00001428
Iteration 34/1000 | Loss: 0.00001428
Iteration 35/1000 | Loss: 0.00001427
Iteration 36/1000 | Loss: 0.00001427
Iteration 37/1000 | Loss: 0.00001427
Iteration 38/1000 | Loss: 0.00001426
Iteration 39/1000 | Loss: 0.00001426
Iteration 40/1000 | Loss: 0.00001426
Iteration 41/1000 | Loss: 0.00001425
Iteration 42/1000 | Loss: 0.00001425
Iteration 43/1000 | Loss: 0.00001425
Iteration 44/1000 | Loss: 0.00001424
Iteration 45/1000 | Loss: 0.00001424
Iteration 46/1000 | Loss: 0.00001424
Iteration 47/1000 | Loss: 0.00001423
Iteration 48/1000 | Loss: 0.00001423
Iteration 49/1000 | Loss: 0.00001423
Iteration 50/1000 | Loss: 0.00001422
Iteration 51/1000 | Loss: 0.00001422
Iteration 52/1000 | Loss: 0.00001422
Iteration 53/1000 | Loss: 0.00001422
Iteration 54/1000 | Loss: 0.00001422
Iteration 55/1000 | Loss: 0.00001422
Iteration 56/1000 | Loss: 0.00001421
Iteration 57/1000 | Loss: 0.00001421
Iteration 58/1000 | Loss: 0.00001421
Iteration 59/1000 | Loss: 0.00001421
Iteration 60/1000 | Loss: 0.00001421
Iteration 61/1000 | Loss: 0.00001421
Iteration 62/1000 | Loss: 0.00001421
Iteration 63/1000 | Loss: 0.00001421
Iteration 64/1000 | Loss: 0.00001420
Iteration 65/1000 | Loss: 0.00001420
Iteration 66/1000 | Loss: 0.00001419
Iteration 67/1000 | Loss: 0.00001419
Iteration 68/1000 | Loss: 0.00001419
Iteration 69/1000 | Loss: 0.00001418
Iteration 70/1000 | Loss: 0.00001418
Iteration 71/1000 | Loss: 0.00001418
Iteration 72/1000 | Loss: 0.00001418
Iteration 73/1000 | Loss: 0.00001418
Iteration 74/1000 | Loss: 0.00001418
Iteration 75/1000 | Loss: 0.00001418
Iteration 76/1000 | Loss: 0.00001418
Iteration 77/1000 | Loss: 0.00001418
Iteration 78/1000 | Loss: 0.00001417
Iteration 79/1000 | Loss: 0.00001417
Iteration 80/1000 | Loss: 0.00001417
Iteration 81/1000 | Loss: 0.00001417
Iteration 82/1000 | Loss: 0.00001417
Iteration 83/1000 | Loss: 0.00001416
Iteration 84/1000 | Loss: 0.00001416
Iteration 85/1000 | Loss: 0.00001416
Iteration 86/1000 | Loss: 0.00001416
Iteration 87/1000 | Loss: 0.00001416
Iteration 88/1000 | Loss: 0.00001416
Iteration 89/1000 | Loss: 0.00001415
Iteration 90/1000 | Loss: 0.00001415
Iteration 91/1000 | Loss: 0.00001415
Iteration 92/1000 | Loss: 0.00001415
Iteration 93/1000 | Loss: 0.00001415
Iteration 94/1000 | Loss: 0.00001415
Iteration 95/1000 | Loss: 0.00001415
Iteration 96/1000 | Loss: 0.00001414
Iteration 97/1000 | Loss: 0.00001414
Iteration 98/1000 | Loss: 0.00001414
Iteration 99/1000 | Loss: 0.00001414
Iteration 100/1000 | Loss: 0.00001414
Iteration 101/1000 | Loss: 0.00001414
Iteration 102/1000 | Loss: 0.00001414
Iteration 103/1000 | Loss: 0.00001414
Iteration 104/1000 | Loss: 0.00001414
Iteration 105/1000 | Loss: 0.00001414
Iteration 106/1000 | Loss: 0.00001414
Iteration 107/1000 | Loss: 0.00001414
Iteration 108/1000 | Loss: 0.00001414
Iteration 109/1000 | Loss: 0.00001414
Iteration 110/1000 | Loss: 0.00001413
Iteration 111/1000 | Loss: 0.00001413
Iteration 112/1000 | Loss: 0.00001413
Iteration 113/1000 | Loss: 0.00001413
Iteration 114/1000 | Loss: 0.00001413
Iteration 115/1000 | Loss: 0.00001413
Iteration 116/1000 | Loss: 0.00001413
Iteration 117/1000 | Loss: 0.00001413
Iteration 118/1000 | Loss: 0.00001413
Iteration 119/1000 | Loss: 0.00001413
Iteration 120/1000 | Loss: 0.00001413
Iteration 121/1000 | Loss: 0.00001413
Iteration 122/1000 | Loss: 0.00001413
Iteration 123/1000 | Loss: 0.00001412
Iteration 124/1000 | Loss: 0.00001412
Iteration 125/1000 | Loss: 0.00001412
Iteration 126/1000 | Loss: 0.00001412
Iteration 127/1000 | Loss: 0.00001412
Iteration 128/1000 | Loss: 0.00001412
Iteration 129/1000 | Loss: 0.00001412
Iteration 130/1000 | Loss: 0.00001412
Iteration 131/1000 | Loss: 0.00001411
Iteration 132/1000 | Loss: 0.00001411
Iteration 133/1000 | Loss: 0.00001411
Iteration 134/1000 | Loss: 0.00001411
Iteration 135/1000 | Loss: 0.00001411
Iteration 136/1000 | Loss: 0.00001411
Iteration 137/1000 | Loss: 0.00001411
Iteration 138/1000 | Loss: 0.00001411
Iteration 139/1000 | Loss: 0.00001411
Iteration 140/1000 | Loss: 0.00001411
Iteration 141/1000 | Loss: 0.00001411
Iteration 142/1000 | Loss: 0.00001411
Iteration 143/1000 | Loss: 0.00001411
Iteration 144/1000 | Loss: 0.00001411
Iteration 145/1000 | Loss: 0.00001411
Iteration 146/1000 | Loss: 0.00001411
Iteration 147/1000 | Loss: 0.00001411
Iteration 148/1000 | Loss: 0.00001411
Iteration 149/1000 | Loss: 0.00001411
Iteration 150/1000 | Loss: 0.00001410
Iteration 151/1000 | Loss: 0.00001410
Iteration 152/1000 | Loss: 0.00001410
Iteration 153/1000 | Loss: 0.00001410
Iteration 154/1000 | Loss: 0.00001410
Iteration 155/1000 | Loss: 0.00001410
Iteration 156/1000 | Loss: 0.00001410
Iteration 157/1000 | Loss: 0.00001410
Iteration 158/1000 | Loss: 0.00001410
Iteration 159/1000 | Loss: 0.00001410
Iteration 160/1000 | Loss: 0.00001410
Iteration 161/1000 | Loss: 0.00001410
Iteration 162/1000 | Loss: 0.00001410
Iteration 163/1000 | Loss: 0.00001410
Iteration 164/1000 | Loss: 0.00001410
Iteration 165/1000 | Loss: 0.00001410
Iteration 166/1000 | Loss: 0.00001409
Iteration 167/1000 | Loss: 0.00001409
Iteration 168/1000 | Loss: 0.00001409
Iteration 169/1000 | Loss: 0.00001409
Iteration 170/1000 | Loss: 0.00001409
Iteration 171/1000 | Loss: 0.00001409
Iteration 172/1000 | Loss: 0.00001409
Iteration 173/1000 | Loss: 0.00001409
Iteration 174/1000 | Loss: 0.00001409
Iteration 175/1000 | Loss: 0.00001409
Iteration 176/1000 | Loss: 0.00001409
Iteration 177/1000 | Loss: 0.00001409
Iteration 178/1000 | Loss: 0.00001409
Iteration 179/1000 | Loss: 0.00001409
Iteration 180/1000 | Loss: 0.00001409
Iteration 181/1000 | Loss: 0.00001409
Iteration 182/1000 | Loss: 0.00001409
Iteration 183/1000 | Loss: 0.00001409
Iteration 184/1000 | Loss: 0.00001409
Iteration 185/1000 | Loss: 0.00001409
Iteration 186/1000 | Loss: 0.00001409
Iteration 187/1000 | Loss: 0.00001409
Iteration 188/1000 | Loss: 0.00001409
Iteration 189/1000 | Loss: 0.00001409
Iteration 190/1000 | Loss: 0.00001409
Iteration 191/1000 | Loss: 0.00001409
Iteration 192/1000 | Loss: 0.00001409
Iteration 193/1000 | Loss: 0.00001409
Iteration 194/1000 | Loss: 0.00001409
Iteration 195/1000 | Loss: 0.00001409
Iteration 196/1000 | Loss: 0.00001409
Iteration 197/1000 | Loss: 0.00001409
Iteration 198/1000 | Loss: 0.00001409
Iteration 199/1000 | Loss: 0.00001409
Iteration 200/1000 | Loss: 0.00001409
Iteration 201/1000 | Loss: 0.00001409
Iteration 202/1000 | Loss: 0.00001409
Iteration 203/1000 | Loss: 0.00001409
Iteration 204/1000 | Loss: 0.00001409
Iteration 205/1000 | Loss: 0.00001409
Iteration 206/1000 | Loss: 0.00001409
Iteration 207/1000 | Loss: 0.00001409
Iteration 208/1000 | Loss: 0.00001409
Iteration 209/1000 | Loss: 0.00001409
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 209. Stopping optimization.
Last 5 losses: [1.4094462130742613e-05, 1.4094462130742613e-05, 1.4094462130742613e-05, 1.4094462130742613e-05, 1.4094462130742613e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4094462130742613e-05

Optimization complete. Final v2v error: 3.253519296646118 mm

Highest mean error: 3.653141736984253 mm for frame 32

Lowest mean error: 2.920264482498169 mm for frame 53

Saving results

Total time: 38.3255341053009
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00952185
Iteration 2/25 | Loss: 0.00204943
Iteration 3/25 | Loss: 0.00118854
Iteration 4/25 | Loss: 0.00112990
Iteration 5/25 | Loss: 0.00107188
Iteration 6/25 | Loss: 0.00108480
Iteration 7/25 | Loss: 0.00107414
Iteration 8/25 | Loss: 0.00105929
Iteration 9/25 | Loss: 0.00106288
Iteration 10/25 | Loss: 0.00105956
Iteration 11/25 | Loss: 0.00105440
Iteration 12/25 | Loss: 0.00105355
Iteration 13/25 | Loss: 0.00105039
Iteration 14/25 | Loss: 0.00104824
Iteration 15/25 | Loss: 0.00104704
Iteration 16/25 | Loss: 0.00104859
Iteration 17/25 | Loss: 0.00104884
Iteration 18/25 | Loss: 0.00104641
Iteration 19/25 | Loss: 0.00104921
Iteration 20/25 | Loss: 0.00104667
Iteration 21/25 | Loss: 0.00103957
Iteration 22/25 | Loss: 0.00103827
Iteration 23/25 | Loss: 0.00103779
Iteration 24/25 | Loss: 0.00103763
Iteration 25/25 | Loss: 0.00103750

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.41048527
Iteration 2/25 | Loss: 0.00213494
Iteration 3/25 | Loss: 0.00213494
Iteration 4/25 | Loss: 0.00213493
Iteration 5/25 | Loss: 0.00213493
Iteration 6/25 | Loss: 0.00213493
Iteration 7/25 | Loss: 0.00213493
Iteration 8/25 | Loss: 0.00213493
Iteration 9/25 | Loss: 0.00213493
Iteration 10/25 | Loss: 0.00213493
Iteration 11/25 | Loss: 0.00213493
Iteration 12/25 | Loss: 0.00213493
Iteration 13/25 | Loss: 0.00213493
Iteration 14/25 | Loss: 0.00213493
Iteration 15/25 | Loss: 0.00213493
Iteration 16/25 | Loss: 0.00213493
Iteration 17/25 | Loss: 0.00213493
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.002134932205080986, 0.002134932205080986, 0.002134932205080986, 0.002134932205080986, 0.002134932205080986]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002134932205080986

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00213493
Iteration 2/1000 | Loss: 0.00021318
Iteration 3/1000 | Loss: 0.00117413
Iteration 4/1000 | Loss: 0.00193646
Iteration 5/1000 | Loss: 0.00125145
Iteration 6/1000 | Loss: 0.00010192
Iteration 7/1000 | Loss: 0.00073811
Iteration 8/1000 | Loss: 0.00083778
Iteration 9/1000 | Loss: 0.00005849
Iteration 10/1000 | Loss: 0.00003901
Iteration 11/1000 | Loss: 0.00003066
Iteration 12/1000 | Loss: 0.00002615
Iteration 13/1000 | Loss: 0.00002364
Iteration 14/1000 | Loss: 0.00002207
Iteration 15/1000 | Loss: 0.00002125
Iteration 16/1000 | Loss: 0.00002033
Iteration 17/1000 | Loss: 0.00001962
Iteration 18/1000 | Loss: 0.00001912
Iteration 19/1000 | Loss: 0.00001865
Iteration 20/1000 | Loss: 0.00001821
Iteration 21/1000 | Loss: 0.00001776
Iteration 22/1000 | Loss: 0.00001743
Iteration 23/1000 | Loss: 0.00001711
Iteration 24/1000 | Loss: 0.00001691
Iteration 25/1000 | Loss: 0.00001670
Iteration 26/1000 | Loss: 0.00001661
Iteration 27/1000 | Loss: 0.00001655
Iteration 28/1000 | Loss: 0.00001639
Iteration 29/1000 | Loss: 0.00001638
Iteration 30/1000 | Loss: 0.00001626
Iteration 31/1000 | Loss: 0.00001623
Iteration 32/1000 | Loss: 0.00001622
Iteration 33/1000 | Loss: 0.00001620
Iteration 34/1000 | Loss: 0.00001620
Iteration 35/1000 | Loss: 0.00001619
Iteration 36/1000 | Loss: 0.00001618
Iteration 37/1000 | Loss: 0.00001613
Iteration 38/1000 | Loss: 0.00001612
Iteration 39/1000 | Loss: 0.00001610
Iteration 40/1000 | Loss: 0.00001610
Iteration 41/1000 | Loss: 0.00001609
Iteration 42/1000 | Loss: 0.00001609
Iteration 43/1000 | Loss: 0.00001609
Iteration 44/1000 | Loss: 0.00001609
Iteration 45/1000 | Loss: 0.00001606
Iteration 46/1000 | Loss: 0.00001605
Iteration 47/1000 | Loss: 0.00067987
Iteration 48/1000 | Loss: 0.00001883
Iteration 49/1000 | Loss: 0.00001585
Iteration 50/1000 | Loss: 0.00001493
Iteration 51/1000 | Loss: 0.00001427
Iteration 52/1000 | Loss: 0.00001380
Iteration 53/1000 | Loss: 0.00001349
Iteration 54/1000 | Loss: 0.00001347
Iteration 55/1000 | Loss: 0.00001338
Iteration 56/1000 | Loss: 0.00001318
Iteration 57/1000 | Loss: 0.00001317
Iteration 58/1000 | Loss: 0.00001312
Iteration 59/1000 | Loss: 0.00001308
Iteration 60/1000 | Loss: 0.00001307
Iteration 61/1000 | Loss: 0.00001306
Iteration 62/1000 | Loss: 0.00001306
Iteration 63/1000 | Loss: 0.00001305
Iteration 64/1000 | Loss: 0.00001305
Iteration 65/1000 | Loss: 0.00001302
Iteration 66/1000 | Loss: 0.00001302
Iteration 67/1000 | Loss: 0.00001301
Iteration 68/1000 | Loss: 0.00001301
Iteration 69/1000 | Loss: 0.00001301
Iteration 70/1000 | Loss: 0.00001301
Iteration 71/1000 | Loss: 0.00001300
Iteration 72/1000 | Loss: 0.00001299
Iteration 73/1000 | Loss: 0.00001298
Iteration 74/1000 | Loss: 0.00001298
Iteration 75/1000 | Loss: 0.00001298
Iteration 76/1000 | Loss: 0.00001298
Iteration 77/1000 | Loss: 0.00001297
Iteration 78/1000 | Loss: 0.00001297
Iteration 79/1000 | Loss: 0.00001296
Iteration 80/1000 | Loss: 0.00001296
Iteration 81/1000 | Loss: 0.00001296
Iteration 82/1000 | Loss: 0.00001295
Iteration 83/1000 | Loss: 0.00001294
Iteration 84/1000 | Loss: 0.00001294
Iteration 85/1000 | Loss: 0.00001290
Iteration 86/1000 | Loss: 0.00001288
Iteration 87/1000 | Loss: 0.00001288
Iteration 88/1000 | Loss: 0.00001287
Iteration 89/1000 | Loss: 0.00001287
Iteration 90/1000 | Loss: 0.00001287
Iteration 91/1000 | Loss: 0.00001287
Iteration 92/1000 | Loss: 0.00001286
Iteration 93/1000 | Loss: 0.00001286
Iteration 94/1000 | Loss: 0.00001286
Iteration 95/1000 | Loss: 0.00001286
Iteration 96/1000 | Loss: 0.00001286
Iteration 97/1000 | Loss: 0.00001285
Iteration 98/1000 | Loss: 0.00001285
Iteration 99/1000 | Loss: 0.00001285
Iteration 100/1000 | Loss: 0.00001284
Iteration 101/1000 | Loss: 0.00001284
Iteration 102/1000 | Loss: 0.00001284
Iteration 103/1000 | Loss: 0.00001284
Iteration 104/1000 | Loss: 0.00001284
Iteration 105/1000 | Loss: 0.00001284
Iteration 106/1000 | Loss: 0.00001283
Iteration 107/1000 | Loss: 0.00001283
Iteration 108/1000 | Loss: 0.00001283
Iteration 109/1000 | Loss: 0.00001283
Iteration 110/1000 | Loss: 0.00001282
Iteration 111/1000 | Loss: 0.00001282
Iteration 112/1000 | Loss: 0.00001282
Iteration 113/1000 | Loss: 0.00001282
Iteration 114/1000 | Loss: 0.00001282
Iteration 115/1000 | Loss: 0.00001282
Iteration 116/1000 | Loss: 0.00001282
Iteration 117/1000 | Loss: 0.00001282
Iteration 118/1000 | Loss: 0.00001282
Iteration 119/1000 | Loss: 0.00001282
Iteration 120/1000 | Loss: 0.00001281
Iteration 121/1000 | Loss: 0.00001281
Iteration 122/1000 | Loss: 0.00001281
Iteration 123/1000 | Loss: 0.00001281
Iteration 124/1000 | Loss: 0.00001281
Iteration 125/1000 | Loss: 0.00001281
Iteration 126/1000 | Loss: 0.00001281
Iteration 127/1000 | Loss: 0.00001281
Iteration 128/1000 | Loss: 0.00001281
Iteration 129/1000 | Loss: 0.00001281
Iteration 130/1000 | Loss: 0.00001281
Iteration 131/1000 | Loss: 0.00001281
Iteration 132/1000 | Loss: 0.00001281
Iteration 133/1000 | Loss: 0.00001281
Iteration 134/1000 | Loss: 0.00001281
Iteration 135/1000 | Loss: 0.00001281
Iteration 136/1000 | Loss: 0.00001280
Iteration 137/1000 | Loss: 0.00001280
Iteration 138/1000 | Loss: 0.00001280
Iteration 139/1000 | Loss: 0.00001280
Iteration 140/1000 | Loss: 0.00001280
Iteration 141/1000 | Loss: 0.00001280
Iteration 142/1000 | Loss: 0.00001280
Iteration 143/1000 | Loss: 0.00001280
Iteration 144/1000 | Loss: 0.00001280
Iteration 145/1000 | Loss: 0.00001280
Iteration 146/1000 | Loss: 0.00001279
Iteration 147/1000 | Loss: 0.00001279
Iteration 148/1000 | Loss: 0.00001279
Iteration 149/1000 | Loss: 0.00001279
Iteration 150/1000 | Loss: 0.00001279
Iteration 151/1000 | Loss: 0.00001279
Iteration 152/1000 | Loss: 0.00001279
Iteration 153/1000 | Loss: 0.00001279
Iteration 154/1000 | Loss: 0.00001279
Iteration 155/1000 | Loss: 0.00001279
Iteration 156/1000 | Loss: 0.00001279
Iteration 157/1000 | Loss: 0.00001278
Iteration 158/1000 | Loss: 0.00001278
Iteration 159/1000 | Loss: 0.00001278
Iteration 160/1000 | Loss: 0.00001278
Iteration 161/1000 | Loss: 0.00001278
Iteration 162/1000 | Loss: 0.00001278
Iteration 163/1000 | Loss: 0.00001278
Iteration 164/1000 | Loss: 0.00001278
Iteration 165/1000 | Loss: 0.00001278
Iteration 166/1000 | Loss: 0.00001278
Iteration 167/1000 | Loss: 0.00001278
Iteration 168/1000 | Loss: 0.00001278
Iteration 169/1000 | Loss: 0.00001278
Iteration 170/1000 | Loss: 0.00001278
Iteration 171/1000 | Loss: 0.00001278
Iteration 172/1000 | Loss: 0.00001278
Iteration 173/1000 | Loss: 0.00001278
Iteration 174/1000 | Loss: 0.00001278
Iteration 175/1000 | Loss: 0.00001278
Iteration 176/1000 | Loss: 0.00001278
Iteration 177/1000 | Loss: 0.00001278
Iteration 178/1000 | Loss: 0.00001278
Iteration 179/1000 | Loss: 0.00001278
Iteration 180/1000 | Loss: 0.00001278
Iteration 181/1000 | Loss: 0.00001278
Iteration 182/1000 | Loss: 0.00001278
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 182. Stopping optimization.
Last 5 losses: [1.2782966223312542e-05, 1.2782966223312542e-05, 1.2782966223312542e-05, 1.2782966223312542e-05, 1.2782966223312542e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2782966223312542e-05

Optimization complete. Final v2v error: 2.9483911991119385 mm

Highest mean error: 5.003366470336914 mm for frame 63

Lowest mean error: 2.1935479640960693 mm for frame 3

Saving results

Total time: 111.65181612968445
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402448
Iteration 2/25 | Loss: 0.00104180
Iteration 3/25 | Loss: 0.00091681
Iteration 4/25 | Loss: 0.00090561
Iteration 5/25 | Loss: 0.00090561
Iteration 6/25 | Loss: 0.00090561
Iteration 7/25 | Loss: 0.00090561
Iteration 8/25 | Loss: 0.00090561
Iteration 9/25 | Loss: 0.00090561
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 9. Stopping optimization.
Last 5 losses: [0.0009056063136085868, 0.0009056063136085868, 0.0009056063136085868, 0.0009056063136085868, 0.0009056063136085868]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009056063136085868

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45665634
Iteration 2/25 | Loss: 0.00053596
Iteration 3/25 | Loss: 0.00053596
Iteration 4/25 | Loss: 0.00053596
Iteration 5/25 | Loss: 0.00053596
Iteration 6/25 | Loss: 0.00053596
Iteration 7/25 | Loss: 0.00053596
Iteration 8/25 | Loss: 0.00053596
Iteration 9/25 | Loss: 0.00053596
Iteration 10/25 | Loss: 0.00053596
Iteration 11/25 | Loss: 0.00053596
Iteration 12/25 | Loss: 0.00053596
Iteration 13/25 | Loss: 0.00053596
Iteration 14/25 | Loss: 0.00053596
Iteration 15/25 | Loss: 0.00053596
Iteration 16/25 | Loss: 0.00053596
Iteration 17/25 | Loss: 0.00053596
Iteration 18/25 | Loss: 0.00053596
Iteration 19/25 | Loss: 0.00053596
Iteration 20/25 | Loss: 0.00053596
Iteration 21/25 | Loss: 0.00053596
Iteration 22/25 | Loss: 0.00053596
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0005359555943869054, 0.0005359555943869054, 0.0005359555943869054, 0.0005359555943869054, 0.0005359555943869054]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005359555943869054

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053596
Iteration 2/1000 | Loss: 0.00002878
Iteration 3/1000 | Loss: 0.00001706
Iteration 4/1000 | Loss: 0.00001473
Iteration 5/1000 | Loss: 0.00001408
Iteration 6/1000 | Loss: 0.00001358
Iteration 7/1000 | Loss: 0.00001314
Iteration 8/1000 | Loss: 0.00001279
Iteration 9/1000 | Loss: 0.00001265
Iteration 10/1000 | Loss: 0.00001258
Iteration 11/1000 | Loss: 0.00001244
Iteration 12/1000 | Loss: 0.00001236
Iteration 13/1000 | Loss: 0.00001236
Iteration 14/1000 | Loss: 0.00001235
Iteration 15/1000 | Loss: 0.00001234
Iteration 16/1000 | Loss: 0.00001233
Iteration 17/1000 | Loss: 0.00001233
Iteration 18/1000 | Loss: 0.00001233
Iteration 19/1000 | Loss: 0.00001233
Iteration 20/1000 | Loss: 0.00001232
Iteration 21/1000 | Loss: 0.00001231
Iteration 22/1000 | Loss: 0.00001226
Iteration 23/1000 | Loss: 0.00001225
Iteration 24/1000 | Loss: 0.00001224
Iteration 25/1000 | Loss: 0.00001223
Iteration 26/1000 | Loss: 0.00001222
Iteration 27/1000 | Loss: 0.00001221
Iteration 28/1000 | Loss: 0.00001220
Iteration 29/1000 | Loss: 0.00001220
Iteration 30/1000 | Loss: 0.00001219
Iteration 31/1000 | Loss: 0.00001219
Iteration 32/1000 | Loss: 0.00001218
Iteration 33/1000 | Loss: 0.00001218
Iteration 34/1000 | Loss: 0.00001218
Iteration 35/1000 | Loss: 0.00001218
Iteration 36/1000 | Loss: 0.00001218
Iteration 37/1000 | Loss: 0.00001217
Iteration 38/1000 | Loss: 0.00001217
Iteration 39/1000 | Loss: 0.00001217
Iteration 40/1000 | Loss: 0.00001217
Iteration 41/1000 | Loss: 0.00001217
Iteration 42/1000 | Loss: 0.00001217
Iteration 43/1000 | Loss: 0.00001217
Iteration 44/1000 | Loss: 0.00001217
Iteration 45/1000 | Loss: 0.00001217
Iteration 46/1000 | Loss: 0.00001216
Iteration 47/1000 | Loss: 0.00001216
Iteration 48/1000 | Loss: 0.00001214
Iteration 49/1000 | Loss: 0.00001214
Iteration 50/1000 | Loss: 0.00001213
Iteration 51/1000 | Loss: 0.00001213
Iteration 52/1000 | Loss: 0.00001213
Iteration 53/1000 | Loss: 0.00001213
Iteration 54/1000 | Loss: 0.00001213
Iteration 55/1000 | Loss: 0.00001213
Iteration 56/1000 | Loss: 0.00001212
Iteration 57/1000 | Loss: 0.00001212
Iteration 58/1000 | Loss: 0.00001211
Iteration 59/1000 | Loss: 0.00001211
Iteration 60/1000 | Loss: 0.00001211
Iteration 61/1000 | Loss: 0.00001211
Iteration 62/1000 | Loss: 0.00001211
Iteration 63/1000 | Loss: 0.00001210
Iteration 64/1000 | Loss: 0.00001210
Iteration 65/1000 | Loss: 0.00001210
Iteration 66/1000 | Loss: 0.00001209
Iteration 67/1000 | Loss: 0.00001209
Iteration 68/1000 | Loss: 0.00001208
Iteration 69/1000 | Loss: 0.00001208
Iteration 70/1000 | Loss: 0.00001208
Iteration 71/1000 | Loss: 0.00001208
Iteration 72/1000 | Loss: 0.00001208
Iteration 73/1000 | Loss: 0.00001208
Iteration 74/1000 | Loss: 0.00001208
Iteration 75/1000 | Loss: 0.00001207
Iteration 76/1000 | Loss: 0.00001207
Iteration 77/1000 | Loss: 0.00001207
Iteration 78/1000 | Loss: 0.00001205
Iteration 79/1000 | Loss: 0.00001205
Iteration 80/1000 | Loss: 0.00001205
Iteration 81/1000 | Loss: 0.00001204
Iteration 82/1000 | Loss: 0.00001204
Iteration 83/1000 | Loss: 0.00001204
Iteration 84/1000 | Loss: 0.00001204
Iteration 85/1000 | Loss: 0.00001204
Iteration 86/1000 | Loss: 0.00001203
Iteration 87/1000 | Loss: 0.00001203
Iteration 88/1000 | Loss: 0.00001203
Iteration 89/1000 | Loss: 0.00001203
Iteration 90/1000 | Loss: 0.00001203
Iteration 91/1000 | Loss: 0.00001202
Iteration 92/1000 | Loss: 0.00001202
Iteration 93/1000 | Loss: 0.00001202
Iteration 94/1000 | Loss: 0.00001202
Iteration 95/1000 | Loss: 0.00001202
Iteration 96/1000 | Loss: 0.00001201
Iteration 97/1000 | Loss: 0.00001201
Iteration 98/1000 | Loss: 0.00001201
Iteration 99/1000 | Loss: 0.00001201
Iteration 100/1000 | Loss: 0.00001201
Iteration 101/1000 | Loss: 0.00001201
Iteration 102/1000 | Loss: 0.00001201
Iteration 103/1000 | Loss: 0.00001201
Iteration 104/1000 | Loss: 0.00001200
Iteration 105/1000 | Loss: 0.00001200
Iteration 106/1000 | Loss: 0.00001200
Iteration 107/1000 | Loss: 0.00001200
Iteration 108/1000 | Loss: 0.00001200
Iteration 109/1000 | Loss: 0.00001200
Iteration 110/1000 | Loss: 0.00001199
Iteration 111/1000 | Loss: 0.00001199
Iteration 112/1000 | Loss: 0.00001199
Iteration 113/1000 | Loss: 0.00001199
Iteration 114/1000 | Loss: 0.00001199
Iteration 115/1000 | Loss: 0.00001199
Iteration 116/1000 | Loss: 0.00001199
Iteration 117/1000 | Loss: 0.00001198
Iteration 118/1000 | Loss: 0.00001198
Iteration 119/1000 | Loss: 0.00001198
Iteration 120/1000 | Loss: 0.00001198
Iteration 121/1000 | Loss: 0.00001198
Iteration 122/1000 | Loss: 0.00001198
Iteration 123/1000 | Loss: 0.00001198
Iteration 124/1000 | Loss: 0.00001198
Iteration 125/1000 | Loss: 0.00001198
Iteration 126/1000 | Loss: 0.00001197
Iteration 127/1000 | Loss: 0.00001197
Iteration 128/1000 | Loss: 0.00001197
Iteration 129/1000 | Loss: 0.00001197
Iteration 130/1000 | Loss: 0.00001197
Iteration 131/1000 | Loss: 0.00001197
Iteration 132/1000 | Loss: 0.00001197
Iteration 133/1000 | Loss: 0.00001197
Iteration 134/1000 | Loss: 0.00001197
Iteration 135/1000 | Loss: 0.00001197
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [1.1973558684985619e-05, 1.1973558684985619e-05, 1.1973558684985619e-05, 1.1973558684985619e-05, 1.1973558684985619e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1973558684985619e-05

Optimization complete. Final v2v error: 3.0075526237487793 mm

Highest mean error: 3.189652681350708 mm for frame 174

Lowest mean error: 2.7785701751708984 mm for frame 224

Saving results

Total time: 35.22062611579895
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00844314
Iteration 2/25 | Loss: 0.00124650
Iteration 3/25 | Loss: 0.00100993
Iteration 4/25 | Loss: 0.00098455
Iteration 5/25 | Loss: 0.00098175
Iteration 6/25 | Loss: 0.00098165
Iteration 7/25 | Loss: 0.00098165
Iteration 8/25 | Loss: 0.00098164
Iteration 9/25 | Loss: 0.00098164
Iteration 10/25 | Loss: 0.00098164
Iteration 11/25 | Loss: 0.00098164
Iteration 12/25 | Loss: 0.00098164
Iteration 13/25 | Loss: 0.00098164
Iteration 14/25 | Loss: 0.00098164
Iteration 15/25 | Loss: 0.00098164
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0009816359961405396, 0.0009816359961405396, 0.0009816359961405396, 0.0009816359961405396, 0.0009816359961405396]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009816359961405396

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.04887199
Iteration 2/25 | Loss: 0.00035698
Iteration 3/25 | Loss: 0.00035698
Iteration 4/25 | Loss: 0.00035698
Iteration 5/25 | Loss: 0.00035698
Iteration 6/25 | Loss: 0.00035698
Iteration 7/25 | Loss: 0.00035697
Iteration 8/25 | Loss: 0.00035697
Iteration 9/25 | Loss: 0.00035697
Iteration 10/25 | Loss: 0.00035697
Iteration 11/25 | Loss: 0.00035697
Iteration 12/25 | Loss: 0.00035697
Iteration 13/25 | Loss: 0.00035697
Iteration 14/25 | Loss: 0.00035697
Iteration 15/25 | Loss: 0.00035697
Iteration 16/25 | Loss: 0.00035697
Iteration 17/25 | Loss: 0.00035697
Iteration 18/25 | Loss: 0.00035697
Iteration 19/25 | Loss: 0.00035697
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0003569741384126246, 0.0003569741384126246, 0.0003569741384126246, 0.0003569741384126246, 0.0003569741384126246]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003569741384126246

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035697
Iteration 2/1000 | Loss: 0.00005059
Iteration 3/1000 | Loss: 0.00003431
Iteration 4/1000 | Loss: 0.00002688
Iteration 5/1000 | Loss: 0.00002423
Iteration 6/1000 | Loss: 0.00002312
Iteration 7/1000 | Loss: 0.00002234
Iteration 8/1000 | Loss: 0.00002176
Iteration 9/1000 | Loss: 0.00002134
Iteration 10/1000 | Loss: 0.00002104
Iteration 11/1000 | Loss: 0.00002080
Iteration 12/1000 | Loss: 0.00002057
Iteration 13/1000 | Loss: 0.00002038
Iteration 14/1000 | Loss: 0.00002032
Iteration 15/1000 | Loss: 0.00002022
Iteration 16/1000 | Loss: 0.00002017
Iteration 17/1000 | Loss: 0.00002016
Iteration 18/1000 | Loss: 0.00002015
Iteration 19/1000 | Loss: 0.00002015
Iteration 20/1000 | Loss: 0.00002014
Iteration 21/1000 | Loss: 0.00002012
Iteration 22/1000 | Loss: 0.00002012
Iteration 23/1000 | Loss: 0.00002011
Iteration 24/1000 | Loss: 0.00002011
Iteration 25/1000 | Loss: 0.00002010
Iteration 26/1000 | Loss: 0.00002010
Iteration 27/1000 | Loss: 0.00002005
Iteration 28/1000 | Loss: 0.00002002
Iteration 29/1000 | Loss: 0.00002001
Iteration 30/1000 | Loss: 0.00002001
Iteration 31/1000 | Loss: 0.00002000
Iteration 32/1000 | Loss: 0.00002000
Iteration 33/1000 | Loss: 0.00002000
Iteration 34/1000 | Loss: 0.00002000
Iteration 35/1000 | Loss: 0.00001999
Iteration 36/1000 | Loss: 0.00001999
Iteration 37/1000 | Loss: 0.00001999
Iteration 38/1000 | Loss: 0.00001999
Iteration 39/1000 | Loss: 0.00001999
Iteration 40/1000 | Loss: 0.00001999
Iteration 41/1000 | Loss: 0.00001999
Iteration 42/1000 | Loss: 0.00001999
Iteration 43/1000 | Loss: 0.00001999
Iteration 44/1000 | Loss: 0.00001998
Iteration 45/1000 | Loss: 0.00001998
Iteration 46/1000 | Loss: 0.00001996
Iteration 47/1000 | Loss: 0.00001996
Iteration 48/1000 | Loss: 0.00001994
Iteration 49/1000 | Loss: 0.00001991
Iteration 50/1000 | Loss: 0.00001991
Iteration 51/1000 | Loss: 0.00001991
Iteration 52/1000 | Loss: 0.00001991
Iteration 53/1000 | Loss: 0.00001991
Iteration 54/1000 | Loss: 0.00001991
Iteration 55/1000 | Loss: 0.00001991
Iteration 56/1000 | Loss: 0.00001991
Iteration 57/1000 | Loss: 0.00001991
Iteration 58/1000 | Loss: 0.00001991
Iteration 59/1000 | Loss: 0.00001990
Iteration 60/1000 | Loss: 0.00001990
Iteration 61/1000 | Loss: 0.00001989
Iteration 62/1000 | Loss: 0.00001987
Iteration 63/1000 | Loss: 0.00001983
Iteration 64/1000 | Loss: 0.00001982
Iteration 65/1000 | Loss: 0.00001982
Iteration 66/1000 | Loss: 0.00001982
Iteration 67/1000 | Loss: 0.00001982
Iteration 68/1000 | Loss: 0.00001981
Iteration 69/1000 | Loss: 0.00001981
Iteration 70/1000 | Loss: 0.00001981
Iteration 71/1000 | Loss: 0.00001981
Iteration 72/1000 | Loss: 0.00001981
Iteration 73/1000 | Loss: 0.00001981
Iteration 74/1000 | Loss: 0.00001981
Iteration 75/1000 | Loss: 0.00001981
Iteration 76/1000 | Loss: 0.00001981
Iteration 77/1000 | Loss: 0.00001981
Iteration 78/1000 | Loss: 0.00001981
Iteration 79/1000 | Loss: 0.00001981
Iteration 80/1000 | Loss: 0.00001981
Iteration 81/1000 | Loss: 0.00001981
Iteration 82/1000 | Loss: 0.00001980
Iteration 83/1000 | Loss: 0.00001980
Iteration 84/1000 | Loss: 0.00001980
Iteration 85/1000 | Loss: 0.00001980
Iteration 86/1000 | Loss: 0.00001980
Iteration 87/1000 | Loss: 0.00001980
Iteration 88/1000 | Loss: 0.00001980
Iteration 89/1000 | Loss: 0.00001980
Iteration 90/1000 | Loss: 0.00001980
Iteration 91/1000 | Loss: 0.00001980
Iteration 92/1000 | Loss: 0.00001980
Iteration 93/1000 | Loss: 0.00001980
Iteration 94/1000 | Loss: 0.00001979
Iteration 95/1000 | Loss: 0.00001979
Iteration 96/1000 | Loss: 0.00001979
Iteration 97/1000 | Loss: 0.00001979
Iteration 98/1000 | Loss: 0.00001979
Iteration 99/1000 | Loss: 0.00001979
Iteration 100/1000 | Loss: 0.00001978
Iteration 101/1000 | Loss: 0.00001978
Iteration 102/1000 | Loss: 0.00001978
Iteration 103/1000 | Loss: 0.00001978
Iteration 104/1000 | Loss: 0.00001978
Iteration 105/1000 | Loss: 0.00001978
Iteration 106/1000 | Loss: 0.00001977
Iteration 107/1000 | Loss: 0.00001977
Iteration 108/1000 | Loss: 0.00001977
Iteration 109/1000 | Loss: 0.00001977
Iteration 110/1000 | Loss: 0.00001977
Iteration 111/1000 | Loss: 0.00001977
Iteration 112/1000 | Loss: 0.00001977
Iteration 113/1000 | Loss: 0.00001977
Iteration 114/1000 | Loss: 0.00001977
Iteration 115/1000 | Loss: 0.00001976
Iteration 116/1000 | Loss: 0.00001976
Iteration 117/1000 | Loss: 0.00001976
Iteration 118/1000 | Loss: 0.00001976
Iteration 119/1000 | Loss: 0.00001976
Iteration 120/1000 | Loss: 0.00001976
Iteration 121/1000 | Loss: 0.00001976
Iteration 122/1000 | Loss: 0.00001976
Iteration 123/1000 | Loss: 0.00001975
Iteration 124/1000 | Loss: 0.00001975
Iteration 125/1000 | Loss: 0.00001975
Iteration 126/1000 | Loss: 0.00001975
Iteration 127/1000 | Loss: 0.00001975
Iteration 128/1000 | Loss: 0.00001975
Iteration 129/1000 | Loss: 0.00001975
Iteration 130/1000 | Loss: 0.00001975
Iteration 131/1000 | Loss: 0.00001975
Iteration 132/1000 | Loss: 0.00001975
Iteration 133/1000 | Loss: 0.00001975
Iteration 134/1000 | Loss: 0.00001975
Iteration 135/1000 | Loss: 0.00001975
Iteration 136/1000 | Loss: 0.00001975
Iteration 137/1000 | Loss: 0.00001975
Iteration 138/1000 | Loss: 0.00001975
Iteration 139/1000 | Loss: 0.00001975
Iteration 140/1000 | Loss: 0.00001975
Iteration 141/1000 | Loss: 0.00001975
Iteration 142/1000 | Loss: 0.00001975
Iteration 143/1000 | Loss: 0.00001975
Iteration 144/1000 | Loss: 0.00001975
Iteration 145/1000 | Loss: 0.00001975
Iteration 146/1000 | Loss: 0.00001975
Iteration 147/1000 | Loss: 0.00001975
Iteration 148/1000 | Loss: 0.00001975
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 148. Stopping optimization.
Last 5 losses: [1.9753821106860414e-05, 1.9753821106860414e-05, 1.9753821106860414e-05, 1.9753821106860414e-05, 1.9753821106860414e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9753821106860414e-05

Optimization complete. Final v2v error: 3.7397961616516113 mm

Highest mean error: 3.7824227809906006 mm for frame 138

Lowest mean error: 3.7108049392700195 mm for frame 62

Saving results

Total time: 38.65847659111023
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00386265
Iteration 2/25 | Loss: 0.00100370
Iteration 3/25 | Loss: 0.00087417
Iteration 4/25 | Loss: 0.00086564
Iteration 5/25 | Loss: 0.00086418
Iteration 6/25 | Loss: 0.00086384
Iteration 7/25 | Loss: 0.00086384
Iteration 8/25 | Loss: 0.00086384
Iteration 9/25 | Loss: 0.00086384
Iteration 10/25 | Loss: 0.00086384
Iteration 11/25 | Loss: 0.00086384
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008638403960503638, 0.0008638403960503638, 0.0008638403960503638, 0.0008638403960503638, 0.0008638403960503638]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008638403960503638

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44831800
Iteration 2/25 | Loss: 0.00054944
Iteration 3/25 | Loss: 0.00054943
Iteration 4/25 | Loss: 0.00054943
Iteration 5/25 | Loss: 0.00054943
Iteration 6/25 | Loss: 0.00054943
Iteration 7/25 | Loss: 0.00054943
Iteration 8/25 | Loss: 0.00054943
Iteration 9/25 | Loss: 0.00054943
Iteration 10/25 | Loss: 0.00054943
Iteration 11/25 | Loss: 0.00054943
Iteration 12/25 | Loss: 0.00054943
Iteration 13/25 | Loss: 0.00054943
Iteration 14/25 | Loss: 0.00054943
Iteration 15/25 | Loss: 0.00054943
Iteration 16/25 | Loss: 0.00054943
Iteration 17/25 | Loss: 0.00054943
Iteration 18/25 | Loss: 0.00054943
Iteration 19/25 | Loss: 0.00054943
Iteration 20/25 | Loss: 0.00054943
Iteration 21/25 | Loss: 0.00054943
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0005494302022270858, 0.0005494302022270858, 0.0005494302022270858, 0.0005494302022270858, 0.0005494302022270858]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005494302022270858

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00054943
Iteration 2/1000 | Loss: 0.00002833
Iteration 3/1000 | Loss: 0.00001880
Iteration 4/1000 | Loss: 0.00001681
Iteration 5/1000 | Loss: 0.00001582
Iteration 6/1000 | Loss: 0.00001496
Iteration 7/1000 | Loss: 0.00001442
Iteration 8/1000 | Loss: 0.00001394
Iteration 9/1000 | Loss: 0.00001361
Iteration 10/1000 | Loss: 0.00001338
Iteration 11/1000 | Loss: 0.00001320
Iteration 12/1000 | Loss: 0.00001317
Iteration 13/1000 | Loss: 0.00001304
Iteration 14/1000 | Loss: 0.00001303
Iteration 15/1000 | Loss: 0.00001297
Iteration 16/1000 | Loss: 0.00001294
Iteration 17/1000 | Loss: 0.00001293
Iteration 18/1000 | Loss: 0.00001291
Iteration 19/1000 | Loss: 0.00001290
Iteration 20/1000 | Loss: 0.00001290
Iteration 21/1000 | Loss: 0.00001289
Iteration 22/1000 | Loss: 0.00001289
Iteration 23/1000 | Loss: 0.00001288
Iteration 24/1000 | Loss: 0.00001288
Iteration 25/1000 | Loss: 0.00001287
Iteration 26/1000 | Loss: 0.00001287
Iteration 27/1000 | Loss: 0.00001286
Iteration 28/1000 | Loss: 0.00001284
Iteration 29/1000 | Loss: 0.00001284
Iteration 30/1000 | Loss: 0.00001284
Iteration 31/1000 | Loss: 0.00001284
Iteration 32/1000 | Loss: 0.00001283
Iteration 33/1000 | Loss: 0.00001283
Iteration 34/1000 | Loss: 0.00001283
Iteration 35/1000 | Loss: 0.00001283
Iteration 36/1000 | Loss: 0.00001283
Iteration 37/1000 | Loss: 0.00001283
Iteration 38/1000 | Loss: 0.00001283
Iteration 39/1000 | Loss: 0.00001283
Iteration 40/1000 | Loss: 0.00001283
Iteration 41/1000 | Loss: 0.00001283
Iteration 42/1000 | Loss: 0.00001283
Iteration 43/1000 | Loss: 0.00001283
Iteration 44/1000 | Loss: 0.00001283
Iteration 45/1000 | Loss: 0.00001283
Iteration 46/1000 | Loss: 0.00001283
Iteration 47/1000 | Loss: 0.00001283
Iteration 48/1000 | Loss: 0.00001283
Iteration 49/1000 | Loss: 0.00001283
Iteration 50/1000 | Loss: 0.00001283
Iteration 51/1000 | Loss: 0.00001283
Iteration 52/1000 | Loss: 0.00001283
Iteration 53/1000 | Loss: 0.00001283
Iteration 54/1000 | Loss: 0.00001283
Iteration 55/1000 | Loss: 0.00001283
Iteration 56/1000 | Loss: 0.00001283
Iteration 57/1000 | Loss: 0.00001283
Iteration 58/1000 | Loss: 0.00001283
Iteration 59/1000 | Loss: 0.00001283
Iteration 60/1000 | Loss: 0.00001283
Iteration 61/1000 | Loss: 0.00001283
Iteration 62/1000 | Loss: 0.00001283
Iteration 63/1000 | Loss: 0.00001283
Iteration 64/1000 | Loss: 0.00001283
Iteration 65/1000 | Loss: 0.00001283
Iteration 66/1000 | Loss: 0.00001283
Iteration 67/1000 | Loss: 0.00001283
Iteration 68/1000 | Loss: 0.00001283
Iteration 69/1000 | Loss: 0.00001283
Iteration 70/1000 | Loss: 0.00001283
Iteration 71/1000 | Loss: 0.00001283
Iteration 72/1000 | Loss: 0.00001283
Iteration 73/1000 | Loss: 0.00001283
Iteration 74/1000 | Loss: 0.00001283
Iteration 75/1000 | Loss: 0.00001283
Iteration 76/1000 | Loss: 0.00001283
Iteration 77/1000 | Loss: 0.00001283
Iteration 78/1000 | Loss: 0.00001283
Iteration 79/1000 | Loss: 0.00001283
Iteration 80/1000 | Loss: 0.00001283
Iteration 81/1000 | Loss: 0.00001283
Iteration 82/1000 | Loss: 0.00001283
Iteration 83/1000 | Loss: 0.00001283
Iteration 84/1000 | Loss: 0.00001283
Iteration 85/1000 | Loss: 0.00001283
Iteration 86/1000 | Loss: 0.00001283
Iteration 87/1000 | Loss: 0.00001283
Iteration 88/1000 | Loss: 0.00001283
Iteration 89/1000 | Loss: 0.00001283
Iteration 90/1000 | Loss: 0.00001283
Iteration 91/1000 | Loss: 0.00001283
Iteration 92/1000 | Loss: 0.00001283
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [1.2833620530727785e-05, 1.2833620530727785e-05, 1.2833620530727785e-05, 1.2833620530727785e-05, 1.2833620530727785e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2833620530727785e-05

Optimization complete. Final v2v error: 3.119654417037964 mm

Highest mean error: 3.4976768493652344 mm for frame 108

Lowest mean error: 2.540304660797119 mm for frame 177

Saving results

Total time: 30.10858654975891
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00723832
Iteration 2/25 | Loss: 0.00117007
Iteration 3/25 | Loss: 0.00097612
Iteration 4/25 | Loss: 0.00094245
Iteration 5/25 | Loss: 0.00093195
Iteration 6/25 | Loss: 0.00092888
Iteration 7/25 | Loss: 0.00092888
Iteration 8/25 | Loss: 0.00092888
Iteration 9/25 | Loss: 0.00092888
Iteration 10/25 | Loss: 0.00092888
Iteration 11/25 | Loss: 0.00092888
Iteration 12/25 | Loss: 0.00092888
Iteration 13/25 | Loss: 0.00092888
Iteration 14/25 | Loss: 0.00092888
Iteration 15/25 | Loss: 0.00092888
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0009288772707805037, 0.0009288772707805037, 0.0009288772707805037, 0.0009288772707805037, 0.0009288772707805037]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009288772707805037

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.19963288
Iteration 2/25 | Loss: 0.00096518
Iteration 3/25 | Loss: 0.00096518
Iteration 4/25 | Loss: 0.00096518
Iteration 5/25 | Loss: 0.00096518
Iteration 6/25 | Loss: 0.00096518
Iteration 7/25 | Loss: 0.00096518
Iteration 8/25 | Loss: 0.00096518
Iteration 9/25 | Loss: 0.00096518
Iteration 10/25 | Loss: 0.00096518
Iteration 11/25 | Loss: 0.00096518
Iteration 12/25 | Loss: 0.00096518
Iteration 13/25 | Loss: 0.00096518
Iteration 14/25 | Loss: 0.00096518
Iteration 15/25 | Loss: 0.00096518
Iteration 16/25 | Loss: 0.00096518
Iteration 17/25 | Loss: 0.00096518
Iteration 18/25 | Loss: 0.00096518
Iteration 19/25 | Loss: 0.00096518
Iteration 20/25 | Loss: 0.00096518
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0009651781292632222, 0.0009651781292632222, 0.0009651781292632222, 0.0009651781292632222, 0.0009651781292632222]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009651781292632222

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00096518
Iteration 2/1000 | Loss: 0.00003075
Iteration 3/1000 | Loss: 0.00002304
Iteration 4/1000 | Loss: 0.00002074
Iteration 5/1000 | Loss: 0.00001962
Iteration 6/1000 | Loss: 0.00001910
Iteration 7/1000 | Loss: 0.00001882
Iteration 8/1000 | Loss: 0.00001852
Iteration 9/1000 | Loss: 0.00001840
Iteration 10/1000 | Loss: 0.00001827
Iteration 11/1000 | Loss: 0.00001807
Iteration 12/1000 | Loss: 0.00001804
Iteration 13/1000 | Loss: 0.00001803
Iteration 14/1000 | Loss: 0.00001799
Iteration 15/1000 | Loss: 0.00001799
Iteration 16/1000 | Loss: 0.00001796
Iteration 17/1000 | Loss: 0.00001794
Iteration 18/1000 | Loss: 0.00001794
Iteration 19/1000 | Loss: 0.00001793
Iteration 20/1000 | Loss: 0.00001790
Iteration 21/1000 | Loss: 0.00001790
Iteration 22/1000 | Loss: 0.00001790
Iteration 23/1000 | Loss: 0.00001788
Iteration 24/1000 | Loss: 0.00001788
Iteration 25/1000 | Loss: 0.00001788
Iteration 26/1000 | Loss: 0.00001786
Iteration 27/1000 | Loss: 0.00001785
Iteration 28/1000 | Loss: 0.00001785
Iteration 29/1000 | Loss: 0.00001784
Iteration 30/1000 | Loss: 0.00001784
Iteration 31/1000 | Loss: 0.00001783
Iteration 32/1000 | Loss: 0.00001783
Iteration 33/1000 | Loss: 0.00001782
Iteration 34/1000 | Loss: 0.00001782
Iteration 35/1000 | Loss: 0.00001781
Iteration 36/1000 | Loss: 0.00001780
Iteration 37/1000 | Loss: 0.00001780
Iteration 38/1000 | Loss: 0.00001779
Iteration 39/1000 | Loss: 0.00001779
Iteration 40/1000 | Loss: 0.00001778
Iteration 41/1000 | Loss: 0.00001776
Iteration 42/1000 | Loss: 0.00001776
Iteration 43/1000 | Loss: 0.00001775
Iteration 44/1000 | Loss: 0.00001774
Iteration 45/1000 | Loss: 0.00001774
Iteration 46/1000 | Loss: 0.00001773
Iteration 47/1000 | Loss: 0.00001773
Iteration 48/1000 | Loss: 0.00001772
Iteration 49/1000 | Loss: 0.00001772
Iteration 50/1000 | Loss: 0.00001772
Iteration 51/1000 | Loss: 0.00001772
Iteration 52/1000 | Loss: 0.00001772
Iteration 53/1000 | Loss: 0.00001772
Iteration 54/1000 | Loss: 0.00001772
Iteration 55/1000 | Loss: 0.00001771
Iteration 56/1000 | Loss: 0.00001770
Iteration 57/1000 | Loss: 0.00001770
Iteration 58/1000 | Loss: 0.00001769
Iteration 59/1000 | Loss: 0.00001769
Iteration 60/1000 | Loss: 0.00001768
Iteration 61/1000 | Loss: 0.00001768
Iteration 62/1000 | Loss: 0.00001768
Iteration 63/1000 | Loss: 0.00001768
Iteration 64/1000 | Loss: 0.00001768
Iteration 65/1000 | Loss: 0.00001768
Iteration 66/1000 | Loss: 0.00001768
Iteration 67/1000 | Loss: 0.00001768
Iteration 68/1000 | Loss: 0.00001768
Iteration 69/1000 | Loss: 0.00001768
Iteration 70/1000 | Loss: 0.00001767
Iteration 71/1000 | Loss: 0.00001767
Iteration 72/1000 | Loss: 0.00001766
Iteration 73/1000 | Loss: 0.00001765
Iteration 74/1000 | Loss: 0.00001765
Iteration 75/1000 | Loss: 0.00001764
Iteration 76/1000 | Loss: 0.00001764
Iteration 77/1000 | Loss: 0.00001764
Iteration 78/1000 | Loss: 0.00001764
Iteration 79/1000 | Loss: 0.00001764
Iteration 80/1000 | Loss: 0.00001763
Iteration 81/1000 | Loss: 0.00001763
Iteration 82/1000 | Loss: 0.00001761
Iteration 83/1000 | Loss: 0.00001761
Iteration 84/1000 | Loss: 0.00001761
Iteration 85/1000 | Loss: 0.00001761
Iteration 86/1000 | Loss: 0.00001761
Iteration 87/1000 | Loss: 0.00001760
Iteration 88/1000 | Loss: 0.00001760
Iteration 89/1000 | Loss: 0.00001759
Iteration 90/1000 | Loss: 0.00001758
Iteration 91/1000 | Loss: 0.00001758
Iteration 92/1000 | Loss: 0.00001758
Iteration 93/1000 | Loss: 0.00001758
Iteration 94/1000 | Loss: 0.00001757
Iteration 95/1000 | Loss: 0.00001757
Iteration 96/1000 | Loss: 0.00001757
Iteration 97/1000 | Loss: 0.00001757
Iteration 98/1000 | Loss: 0.00001757
Iteration 99/1000 | Loss: 0.00001757
Iteration 100/1000 | Loss: 0.00001757
Iteration 101/1000 | Loss: 0.00001757
Iteration 102/1000 | Loss: 0.00001757
Iteration 103/1000 | Loss: 0.00001757
Iteration 104/1000 | Loss: 0.00001757
Iteration 105/1000 | Loss: 0.00001757
Iteration 106/1000 | Loss: 0.00001757
Iteration 107/1000 | Loss: 0.00001757
Iteration 108/1000 | Loss: 0.00001757
Iteration 109/1000 | Loss: 0.00001757
Iteration 110/1000 | Loss: 0.00001757
Iteration 111/1000 | Loss: 0.00001757
Iteration 112/1000 | Loss: 0.00001756
Iteration 113/1000 | Loss: 0.00001756
Iteration 114/1000 | Loss: 0.00001756
Iteration 115/1000 | Loss: 0.00001756
Iteration 116/1000 | Loss: 0.00001756
Iteration 117/1000 | Loss: 0.00001756
Iteration 118/1000 | Loss: 0.00001756
Iteration 119/1000 | Loss: 0.00001756
Iteration 120/1000 | Loss: 0.00001756
Iteration 121/1000 | Loss: 0.00001756
Iteration 122/1000 | Loss: 0.00001756
Iteration 123/1000 | Loss: 0.00001756
Iteration 124/1000 | Loss: 0.00001756
Iteration 125/1000 | Loss: 0.00001756
Iteration 126/1000 | Loss: 0.00001756
Iteration 127/1000 | Loss: 0.00001756
Iteration 128/1000 | Loss: 0.00001756
Iteration 129/1000 | Loss: 0.00001756
Iteration 130/1000 | Loss: 0.00001756
Iteration 131/1000 | Loss: 0.00001756
Iteration 132/1000 | Loss: 0.00001756
Iteration 133/1000 | Loss: 0.00001756
Iteration 134/1000 | Loss: 0.00001756
Iteration 135/1000 | Loss: 0.00001756
Iteration 136/1000 | Loss: 0.00001756
Iteration 137/1000 | Loss: 0.00001756
Iteration 138/1000 | Loss: 0.00001756
Iteration 139/1000 | Loss: 0.00001756
Iteration 140/1000 | Loss: 0.00001756
Iteration 141/1000 | Loss: 0.00001756
Iteration 142/1000 | Loss: 0.00001756
Iteration 143/1000 | Loss: 0.00001756
Iteration 144/1000 | Loss: 0.00001756
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 144. Stopping optimization.
Last 5 losses: [1.7564892914379016e-05, 1.7564892914379016e-05, 1.7564892914379016e-05, 1.7564892914379016e-05, 1.7564892914379016e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7564892914379016e-05

Optimization complete. Final v2v error: 3.516584873199463 mm

Highest mean error: 4.130383491516113 mm for frame 180

Lowest mean error: 2.956796169281006 mm for frame 17

Saving results

Total time: 39.17266249656677
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00661846
Iteration 2/25 | Loss: 0.00117184
Iteration 3/25 | Loss: 0.00096044
Iteration 4/25 | Loss: 0.00094471
Iteration 5/25 | Loss: 0.00094250
Iteration 6/25 | Loss: 0.00094192
Iteration 7/25 | Loss: 0.00094192
Iteration 8/25 | Loss: 0.00094192
Iteration 9/25 | Loss: 0.00094192
Iteration 10/25 | Loss: 0.00094192
Iteration 11/25 | Loss: 0.00094192
Iteration 12/25 | Loss: 0.00094192
Iteration 13/25 | Loss: 0.00094192
Iteration 14/25 | Loss: 0.00094192
Iteration 15/25 | Loss: 0.00094192
Iteration 16/25 | Loss: 0.00094192
Iteration 17/25 | Loss: 0.00094192
Iteration 18/25 | Loss: 0.00094192
Iteration 19/25 | Loss: 0.00094192
Iteration 20/25 | Loss: 0.00094192
Iteration 21/25 | Loss: 0.00094192
Iteration 22/25 | Loss: 0.00094192
Iteration 23/25 | Loss: 0.00094192
Iteration 24/25 | Loss: 0.00094192
Iteration 25/25 | Loss: 0.00094192

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 11.00983524
Iteration 2/25 | Loss: 0.00079028
Iteration 3/25 | Loss: 0.00079014
Iteration 4/25 | Loss: 0.00079014
Iteration 5/25 | Loss: 0.00079014
Iteration 6/25 | Loss: 0.00079014
Iteration 7/25 | Loss: 0.00079014
Iteration 8/25 | Loss: 0.00079014
Iteration 9/25 | Loss: 0.00079014
Iteration 10/25 | Loss: 0.00079014
Iteration 11/25 | Loss: 0.00079014
Iteration 12/25 | Loss: 0.00079014
Iteration 13/25 | Loss: 0.00079014
Iteration 14/25 | Loss: 0.00079014
Iteration 15/25 | Loss: 0.00079014
Iteration 16/25 | Loss: 0.00079014
Iteration 17/25 | Loss: 0.00079014
Iteration 18/25 | Loss: 0.00079014
Iteration 19/25 | Loss: 0.00079014
Iteration 20/25 | Loss: 0.00079014
Iteration 21/25 | Loss: 0.00079014
Iteration 22/25 | Loss: 0.00079014
Iteration 23/25 | Loss: 0.00079014
Iteration 24/25 | Loss: 0.00079014
Iteration 25/25 | Loss: 0.00079014

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079014
Iteration 2/1000 | Loss: 0.00006823
Iteration 3/1000 | Loss: 0.00003093
Iteration 4/1000 | Loss: 0.00002312
Iteration 5/1000 | Loss: 0.00002042
Iteration 6/1000 | Loss: 0.00001915
Iteration 7/1000 | Loss: 0.00001849
Iteration 8/1000 | Loss: 0.00001799
Iteration 9/1000 | Loss: 0.00001766
Iteration 10/1000 | Loss: 0.00001742
Iteration 11/1000 | Loss: 0.00001721
Iteration 12/1000 | Loss: 0.00001705
Iteration 13/1000 | Loss: 0.00001688
Iteration 14/1000 | Loss: 0.00001687
Iteration 15/1000 | Loss: 0.00001682
Iteration 16/1000 | Loss: 0.00001681
Iteration 17/1000 | Loss: 0.00001681
Iteration 18/1000 | Loss: 0.00001679
Iteration 19/1000 | Loss: 0.00001679
Iteration 20/1000 | Loss: 0.00001679
Iteration 21/1000 | Loss: 0.00001678
Iteration 22/1000 | Loss: 0.00001678
Iteration 23/1000 | Loss: 0.00001677
Iteration 24/1000 | Loss: 0.00001677
Iteration 25/1000 | Loss: 0.00001677
Iteration 26/1000 | Loss: 0.00001676
Iteration 27/1000 | Loss: 0.00001676
Iteration 28/1000 | Loss: 0.00001676
Iteration 29/1000 | Loss: 0.00001676
Iteration 30/1000 | Loss: 0.00001676
Iteration 31/1000 | Loss: 0.00001676
Iteration 32/1000 | Loss: 0.00001675
Iteration 33/1000 | Loss: 0.00001675
Iteration 34/1000 | Loss: 0.00001675
Iteration 35/1000 | Loss: 0.00001675
Iteration 36/1000 | Loss: 0.00001675
Iteration 37/1000 | Loss: 0.00001675
Iteration 38/1000 | Loss: 0.00001675
Iteration 39/1000 | Loss: 0.00001675
Iteration 40/1000 | Loss: 0.00001675
Iteration 41/1000 | Loss: 0.00001674
Iteration 42/1000 | Loss: 0.00001674
Iteration 43/1000 | Loss: 0.00001674
Iteration 44/1000 | Loss: 0.00001674
Iteration 45/1000 | Loss: 0.00001674
Iteration 46/1000 | Loss: 0.00001674
Iteration 47/1000 | Loss: 0.00001674
Iteration 48/1000 | Loss: 0.00001674
Iteration 49/1000 | Loss: 0.00001674
Iteration 50/1000 | Loss: 0.00001673
Iteration 51/1000 | Loss: 0.00001673
Iteration 52/1000 | Loss: 0.00001673
Iteration 53/1000 | Loss: 0.00001673
Iteration 54/1000 | Loss: 0.00001672
Iteration 55/1000 | Loss: 0.00001672
Iteration 56/1000 | Loss: 0.00001672
Iteration 57/1000 | Loss: 0.00001672
Iteration 58/1000 | Loss: 0.00001672
Iteration 59/1000 | Loss: 0.00001672
Iteration 60/1000 | Loss: 0.00001672
Iteration 61/1000 | Loss: 0.00001672
Iteration 62/1000 | Loss: 0.00001672
Iteration 63/1000 | Loss: 0.00001671
Iteration 64/1000 | Loss: 0.00001671
Iteration 65/1000 | Loss: 0.00001670
Iteration 66/1000 | Loss: 0.00001670
Iteration 67/1000 | Loss: 0.00001670
Iteration 68/1000 | Loss: 0.00001669
Iteration 69/1000 | Loss: 0.00001669
Iteration 70/1000 | Loss: 0.00001669
Iteration 71/1000 | Loss: 0.00001668
Iteration 72/1000 | Loss: 0.00001668
Iteration 73/1000 | Loss: 0.00001668
Iteration 74/1000 | Loss: 0.00001668
Iteration 75/1000 | Loss: 0.00001668
Iteration 76/1000 | Loss: 0.00001668
Iteration 77/1000 | Loss: 0.00001668
Iteration 78/1000 | Loss: 0.00001668
Iteration 79/1000 | Loss: 0.00001667
Iteration 80/1000 | Loss: 0.00001666
Iteration 81/1000 | Loss: 0.00001666
Iteration 82/1000 | Loss: 0.00001666
Iteration 83/1000 | Loss: 0.00001666
Iteration 84/1000 | Loss: 0.00001665
Iteration 85/1000 | Loss: 0.00001665
Iteration 86/1000 | Loss: 0.00001665
Iteration 87/1000 | Loss: 0.00001665
Iteration 88/1000 | Loss: 0.00001665
Iteration 89/1000 | Loss: 0.00001665
Iteration 90/1000 | Loss: 0.00001665
Iteration 91/1000 | Loss: 0.00001664
Iteration 92/1000 | Loss: 0.00001664
Iteration 93/1000 | Loss: 0.00001664
Iteration 94/1000 | Loss: 0.00001664
Iteration 95/1000 | Loss: 0.00001663
Iteration 96/1000 | Loss: 0.00001663
Iteration 97/1000 | Loss: 0.00001663
Iteration 98/1000 | Loss: 0.00001662
Iteration 99/1000 | Loss: 0.00001662
Iteration 100/1000 | Loss: 0.00001662
Iteration 101/1000 | Loss: 0.00001662
Iteration 102/1000 | Loss: 0.00001662
Iteration 103/1000 | Loss: 0.00001661
Iteration 104/1000 | Loss: 0.00001661
Iteration 105/1000 | Loss: 0.00001661
Iteration 106/1000 | Loss: 0.00001661
Iteration 107/1000 | Loss: 0.00001660
Iteration 108/1000 | Loss: 0.00001660
Iteration 109/1000 | Loss: 0.00001660
Iteration 110/1000 | Loss: 0.00001660
Iteration 111/1000 | Loss: 0.00001659
Iteration 112/1000 | Loss: 0.00001659
Iteration 113/1000 | Loss: 0.00001659
Iteration 114/1000 | Loss: 0.00001659
Iteration 115/1000 | Loss: 0.00001658
Iteration 116/1000 | Loss: 0.00001658
Iteration 117/1000 | Loss: 0.00001658
Iteration 118/1000 | Loss: 0.00001657
Iteration 119/1000 | Loss: 0.00001657
Iteration 120/1000 | Loss: 0.00001657
Iteration 121/1000 | Loss: 0.00001657
Iteration 122/1000 | Loss: 0.00001656
Iteration 123/1000 | Loss: 0.00001656
Iteration 124/1000 | Loss: 0.00001656
Iteration 125/1000 | Loss: 0.00001656
Iteration 126/1000 | Loss: 0.00001656
Iteration 127/1000 | Loss: 0.00001656
Iteration 128/1000 | Loss: 0.00001656
Iteration 129/1000 | Loss: 0.00001655
Iteration 130/1000 | Loss: 0.00001655
Iteration 131/1000 | Loss: 0.00001655
Iteration 132/1000 | Loss: 0.00001655
Iteration 133/1000 | Loss: 0.00001655
Iteration 134/1000 | Loss: 0.00001655
Iteration 135/1000 | Loss: 0.00001655
Iteration 136/1000 | Loss: 0.00001655
Iteration 137/1000 | Loss: 0.00001655
Iteration 138/1000 | Loss: 0.00001654
Iteration 139/1000 | Loss: 0.00001654
Iteration 140/1000 | Loss: 0.00001654
Iteration 141/1000 | Loss: 0.00001654
Iteration 142/1000 | Loss: 0.00001654
Iteration 143/1000 | Loss: 0.00001654
Iteration 144/1000 | Loss: 0.00001654
Iteration 145/1000 | Loss: 0.00001654
Iteration 146/1000 | Loss: 0.00001654
Iteration 147/1000 | Loss: 0.00001654
Iteration 148/1000 | Loss: 0.00001654
Iteration 149/1000 | Loss: 0.00001654
Iteration 150/1000 | Loss: 0.00001654
Iteration 151/1000 | Loss: 0.00001654
Iteration 152/1000 | Loss: 0.00001654
Iteration 153/1000 | Loss: 0.00001654
Iteration 154/1000 | Loss: 0.00001653
Iteration 155/1000 | Loss: 0.00001653
Iteration 156/1000 | Loss: 0.00001653
Iteration 157/1000 | Loss: 0.00001653
Iteration 158/1000 | Loss: 0.00001653
Iteration 159/1000 | Loss: 0.00001653
Iteration 160/1000 | Loss: 0.00001653
Iteration 161/1000 | Loss: 0.00001653
Iteration 162/1000 | Loss: 0.00001652
Iteration 163/1000 | Loss: 0.00001652
Iteration 164/1000 | Loss: 0.00001652
Iteration 165/1000 | Loss: 0.00001652
Iteration 166/1000 | Loss: 0.00001652
Iteration 167/1000 | Loss: 0.00001652
Iteration 168/1000 | Loss: 0.00001652
Iteration 169/1000 | Loss: 0.00001652
Iteration 170/1000 | Loss: 0.00001652
Iteration 171/1000 | Loss: 0.00001652
Iteration 172/1000 | Loss: 0.00001652
Iteration 173/1000 | Loss: 0.00001652
Iteration 174/1000 | Loss: 0.00001652
Iteration 175/1000 | Loss: 0.00001651
Iteration 176/1000 | Loss: 0.00001651
Iteration 177/1000 | Loss: 0.00001651
Iteration 178/1000 | Loss: 0.00001651
Iteration 179/1000 | Loss: 0.00001651
Iteration 180/1000 | Loss: 0.00001650
Iteration 181/1000 | Loss: 0.00001650
Iteration 182/1000 | Loss: 0.00001650
Iteration 183/1000 | Loss: 0.00001650
Iteration 184/1000 | Loss: 0.00001650
Iteration 185/1000 | Loss: 0.00001649
Iteration 186/1000 | Loss: 0.00001649
Iteration 187/1000 | Loss: 0.00001649
Iteration 188/1000 | Loss: 0.00001649
Iteration 189/1000 | Loss: 0.00001649
Iteration 190/1000 | Loss: 0.00001649
Iteration 191/1000 | Loss: 0.00001649
Iteration 192/1000 | Loss: 0.00001649
Iteration 193/1000 | Loss: 0.00001648
Iteration 194/1000 | Loss: 0.00001648
Iteration 195/1000 | Loss: 0.00001648
Iteration 196/1000 | Loss: 0.00001648
Iteration 197/1000 | Loss: 0.00001648
Iteration 198/1000 | Loss: 0.00001647
Iteration 199/1000 | Loss: 0.00001647
Iteration 200/1000 | Loss: 0.00001647
Iteration 201/1000 | Loss: 0.00001647
Iteration 202/1000 | Loss: 0.00001647
Iteration 203/1000 | Loss: 0.00001647
Iteration 204/1000 | Loss: 0.00001647
Iteration 205/1000 | Loss: 0.00001647
Iteration 206/1000 | Loss: 0.00001646
Iteration 207/1000 | Loss: 0.00001646
Iteration 208/1000 | Loss: 0.00001646
Iteration 209/1000 | Loss: 0.00001646
Iteration 210/1000 | Loss: 0.00001646
Iteration 211/1000 | Loss: 0.00001646
Iteration 212/1000 | Loss: 0.00001646
Iteration 213/1000 | Loss: 0.00001646
Iteration 214/1000 | Loss: 0.00001645
Iteration 215/1000 | Loss: 0.00001645
Iteration 216/1000 | Loss: 0.00001645
Iteration 217/1000 | Loss: 0.00001645
Iteration 218/1000 | Loss: 0.00001645
Iteration 219/1000 | Loss: 0.00001645
Iteration 220/1000 | Loss: 0.00001645
Iteration 221/1000 | Loss: 0.00001645
Iteration 222/1000 | Loss: 0.00001645
Iteration 223/1000 | Loss: 0.00001645
Iteration 224/1000 | Loss: 0.00001645
Iteration 225/1000 | Loss: 0.00001645
Iteration 226/1000 | Loss: 0.00001645
Iteration 227/1000 | Loss: 0.00001645
Iteration 228/1000 | Loss: 0.00001645
Iteration 229/1000 | Loss: 0.00001645
Iteration 230/1000 | Loss: 0.00001645
Iteration 231/1000 | Loss: 0.00001645
Iteration 232/1000 | Loss: 0.00001645
Iteration 233/1000 | Loss: 0.00001645
Iteration 234/1000 | Loss: 0.00001645
Iteration 235/1000 | Loss: 0.00001645
Iteration 236/1000 | Loss: 0.00001645
Iteration 237/1000 | Loss: 0.00001645
Iteration 238/1000 | Loss: 0.00001645
Iteration 239/1000 | Loss: 0.00001645
Iteration 240/1000 | Loss: 0.00001645
Iteration 241/1000 | Loss: 0.00001645
Iteration 242/1000 | Loss: 0.00001645
Iteration 243/1000 | Loss: 0.00001645
Iteration 244/1000 | Loss: 0.00001645
Iteration 245/1000 | Loss: 0.00001645
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 245. Stopping optimization.
Last 5 losses: [1.644807525735814e-05, 1.644807525735814e-05, 1.644807525735814e-05, 1.644807525735814e-05, 1.644807525735814e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.644807525735814e-05

Optimization complete. Final v2v error: 3.4247357845306396 mm

Highest mean error: 4.126372814178467 mm for frame 126

Lowest mean error: 2.752713680267334 mm for frame 6

Saving results

Total time: 43.02026152610779
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00812593
Iteration 2/25 | Loss: 0.00099357
Iteration 3/25 | Loss: 0.00078770
Iteration 4/25 | Loss: 0.00077164
Iteration 5/25 | Loss: 0.00076890
Iteration 6/25 | Loss: 0.00076860
Iteration 7/25 | Loss: 0.00076860
Iteration 8/25 | Loss: 0.00076860
Iteration 9/25 | Loss: 0.00076860
Iteration 10/25 | Loss: 0.00076860
Iteration 11/25 | Loss: 0.00076860
Iteration 12/25 | Loss: 0.00076860
Iteration 13/25 | Loss: 0.00076860
Iteration 14/25 | Loss: 0.00076860
Iteration 15/25 | Loss: 0.00076860
Iteration 16/25 | Loss: 0.00076860
Iteration 17/25 | Loss: 0.00076860
Iteration 18/25 | Loss: 0.00076860
Iteration 19/25 | Loss: 0.00076860
Iteration 20/25 | Loss: 0.00076860
Iteration 21/25 | Loss: 0.00076860
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007685961318202317, 0.0007685961318202317, 0.0007685961318202317, 0.0007685961318202317, 0.0007685961318202317]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007685961318202317

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46319640
Iteration 2/25 | Loss: 0.00059746
Iteration 3/25 | Loss: 0.00059746
Iteration 4/25 | Loss: 0.00059745
Iteration 5/25 | Loss: 0.00059745
Iteration 6/25 | Loss: 0.00059745
Iteration 7/25 | Loss: 0.00059745
Iteration 8/25 | Loss: 0.00059745
Iteration 9/25 | Loss: 0.00059745
Iteration 10/25 | Loss: 0.00059745
Iteration 11/25 | Loss: 0.00059745
Iteration 12/25 | Loss: 0.00059745
Iteration 13/25 | Loss: 0.00059745
Iteration 14/25 | Loss: 0.00059745
Iteration 15/25 | Loss: 0.00059745
Iteration 16/25 | Loss: 0.00059745
Iteration 17/25 | Loss: 0.00059745
Iteration 18/25 | Loss: 0.00059745
Iteration 19/25 | Loss: 0.00059745
Iteration 20/25 | Loss: 0.00059745
Iteration 21/25 | Loss: 0.00059745
Iteration 22/25 | Loss: 0.00059745
Iteration 23/25 | Loss: 0.00059745
Iteration 24/25 | Loss: 0.00059745
Iteration 25/25 | Loss: 0.00059745

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059745
Iteration 2/1000 | Loss: 0.00002194
Iteration 3/1000 | Loss: 0.00001152
Iteration 4/1000 | Loss: 0.00000906
Iteration 5/1000 | Loss: 0.00000817
Iteration 6/1000 | Loss: 0.00000773
Iteration 7/1000 | Loss: 0.00000728
Iteration 8/1000 | Loss: 0.00000726
Iteration 9/1000 | Loss: 0.00000713
Iteration 10/1000 | Loss: 0.00000696
Iteration 11/1000 | Loss: 0.00000696
Iteration 12/1000 | Loss: 0.00000694
Iteration 13/1000 | Loss: 0.00000693
Iteration 14/1000 | Loss: 0.00000693
Iteration 15/1000 | Loss: 0.00000692
Iteration 16/1000 | Loss: 0.00000691
Iteration 17/1000 | Loss: 0.00000690
Iteration 18/1000 | Loss: 0.00000688
Iteration 19/1000 | Loss: 0.00000687
Iteration 20/1000 | Loss: 0.00000687
Iteration 21/1000 | Loss: 0.00000682
Iteration 22/1000 | Loss: 0.00000682
Iteration 23/1000 | Loss: 0.00000682
Iteration 24/1000 | Loss: 0.00000682
Iteration 25/1000 | Loss: 0.00000682
Iteration 26/1000 | Loss: 0.00000682
Iteration 27/1000 | Loss: 0.00000682
Iteration 28/1000 | Loss: 0.00000682
Iteration 29/1000 | Loss: 0.00000682
Iteration 30/1000 | Loss: 0.00000682
Iteration 31/1000 | Loss: 0.00000682
Iteration 32/1000 | Loss: 0.00000681
Iteration 33/1000 | Loss: 0.00000681
Iteration 34/1000 | Loss: 0.00000681
Iteration 35/1000 | Loss: 0.00000681
Iteration 36/1000 | Loss: 0.00000680
Iteration 37/1000 | Loss: 0.00000679
Iteration 38/1000 | Loss: 0.00000677
Iteration 39/1000 | Loss: 0.00000677
Iteration 40/1000 | Loss: 0.00000671
Iteration 41/1000 | Loss: 0.00000669
Iteration 42/1000 | Loss: 0.00000668
Iteration 43/1000 | Loss: 0.00000668
Iteration 44/1000 | Loss: 0.00000667
Iteration 45/1000 | Loss: 0.00000667
Iteration 46/1000 | Loss: 0.00000667
Iteration 47/1000 | Loss: 0.00000666
Iteration 48/1000 | Loss: 0.00000666
Iteration 49/1000 | Loss: 0.00000665
Iteration 50/1000 | Loss: 0.00000665
Iteration 51/1000 | Loss: 0.00000665
Iteration 52/1000 | Loss: 0.00000665
Iteration 53/1000 | Loss: 0.00000664
Iteration 54/1000 | Loss: 0.00000663
Iteration 55/1000 | Loss: 0.00000663
Iteration 56/1000 | Loss: 0.00000662
Iteration 57/1000 | Loss: 0.00000662
Iteration 58/1000 | Loss: 0.00000662
Iteration 59/1000 | Loss: 0.00000662
Iteration 60/1000 | Loss: 0.00000662
Iteration 61/1000 | Loss: 0.00000662
Iteration 62/1000 | Loss: 0.00000662
Iteration 63/1000 | Loss: 0.00000662
Iteration 64/1000 | Loss: 0.00000661
Iteration 65/1000 | Loss: 0.00000661
Iteration 66/1000 | Loss: 0.00000661
Iteration 67/1000 | Loss: 0.00000661
Iteration 68/1000 | Loss: 0.00000661
Iteration 69/1000 | Loss: 0.00000661
Iteration 70/1000 | Loss: 0.00000661
Iteration 71/1000 | Loss: 0.00000661
Iteration 72/1000 | Loss: 0.00000661
Iteration 73/1000 | Loss: 0.00000661
Iteration 74/1000 | Loss: 0.00000661
Iteration 75/1000 | Loss: 0.00000661
Iteration 76/1000 | Loss: 0.00000660
Iteration 77/1000 | Loss: 0.00000660
Iteration 78/1000 | Loss: 0.00000660
Iteration 79/1000 | Loss: 0.00000660
Iteration 80/1000 | Loss: 0.00000660
Iteration 81/1000 | Loss: 0.00000660
Iteration 82/1000 | Loss: 0.00000660
Iteration 83/1000 | Loss: 0.00000660
Iteration 84/1000 | Loss: 0.00000660
Iteration 85/1000 | Loss: 0.00000660
Iteration 86/1000 | Loss: 0.00000660
Iteration 87/1000 | Loss: 0.00000660
Iteration 88/1000 | Loss: 0.00000660
Iteration 89/1000 | Loss: 0.00000660
Iteration 90/1000 | Loss: 0.00000660
Iteration 91/1000 | Loss: 0.00000660
Iteration 92/1000 | Loss: 0.00000660
Iteration 93/1000 | Loss: 0.00000660
Iteration 94/1000 | Loss: 0.00000659
Iteration 95/1000 | Loss: 0.00000659
Iteration 96/1000 | Loss: 0.00000659
Iteration 97/1000 | Loss: 0.00000659
Iteration 98/1000 | Loss: 0.00000659
Iteration 99/1000 | Loss: 0.00000659
Iteration 100/1000 | Loss: 0.00000659
Iteration 101/1000 | Loss: 0.00000658
Iteration 102/1000 | Loss: 0.00000658
Iteration 103/1000 | Loss: 0.00000658
Iteration 104/1000 | Loss: 0.00000658
Iteration 105/1000 | Loss: 0.00000658
Iteration 106/1000 | Loss: 0.00000658
Iteration 107/1000 | Loss: 0.00000658
Iteration 108/1000 | Loss: 0.00000658
Iteration 109/1000 | Loss: 0.00000658
Iteration 110/1000 | Loss: 0.00000658
Iteration 111/1000 | Loss: 0.00000658
Iteration 112/1000 | Loss: 0.00000658
Iteration 113/1000 | Loss: 0.00000658
Iteration 114/1000 | Loss: 0.00000658
Iteration 115/1000 | Loss: 0.00000658
Iteration 116/1000 | Loss: 0.00000658
Iteration 117/1000 | Loss: 0.00000658
Iteration 118/1000 | Loss: 0.00000658
Iteration 119/1000 | Loss: 0.00000658
Iteration 120/1000 | Loss: 0.00000658
Iteration 121/1000 | Loss: 0.00000658
Iteration 122/1000 | Loss: 0.00000658
Iteration 123/1000 | Loss: 0.00000658
Iteration 124/1000 | Loss: 0.00000658
Iteration 125/1000 | Loss: 0.00000658
Iteration 126/1000 | Loss: 0.00000658
Iteration 127/1000 | Loss: 0.00000658
Iteration 128/1000 | Loss: 0.00000658
Iteration 129/1000 | Loss: 0.00000658
Iteration 130/1000 | Loss: 0.00000658
Iteration 131/1000 | Loss: 0.00000658
Iteration 132/1000 | Loss: 0.00000658
Iteration 133/1000 | Loss: 0.00000658
Iteration 134/1000 | Loss: 0.00000658
Iteration 135/1000 | Loss: 0.00000658
Iteration 136/1000 | Loss: 0.00000658
Iteration 137/1000 | Loss: 0.00000658
Iteration 138/1000 | Loss: 0.00000658
Iteration 139/1000 | Loss: 0.00000658
Iteration 140/1000 | Loss: 0.00000658
Iteration 141/1000 | Loss: 0.00000658
Iteration 142/1000 | Loss: 0.00000658
Iteration 143/1000 | Loss: 0.00000658
Iteration 144/1000 | Loss: 0.00000658
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 144. Stopping optimization.
Last 5 losses: [6.580728495464427e-06, 6.580728495464427e-06, 6.580728495464427e-06, 6.580728495464427e-06, 6.580728495464427e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 6.580728495464427e-06

Optimization complete. Final v2v error: 2.1990036964416504 mm

Highest mean error: 2.3792154788970947 mm for frame 55

Lowest mean error: 2.0112874507904053 mm for frame 1

Saving results

Total time: 30.674042224884033
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00995591
Iteration 2/25 | Loss: 0.00135084
Iteration 3/25 | Loss: 0.00106263
Iteration 4/25 | Loss: 0.00092901
Iteration 5/25 | Loss: 0.00087968
Iteration 6/25 | Loss: 0.00087674
Iteration 7/25 | Loss: 0.00085855
Iteration 8/25 | Loss: 0.00084296
Iteration 9/25 | Loss: 0.00083471
Iteration 10/25 | Loss: 0.00083197
Iteration 11/25 | Loss: 0.00083034
Iteration 12/25 | Loss: 0.00083057
Iteration 13/25 | Loss: 0.00083070
Iteration 14/25 | Loss: 0.00082929
Iteration 15/25 | Loss: 0.00082777
Iteration 16/25 | Loss: 0.00082734
Iteration 17/25 | Loss: 0.00082717
Iteration 18/25 | Loss: 0.00082714
Iteration 19/25 | Loss: 0.00082714
Iteration 20/25 | Loss: 0.00082714
Iteration 21/25 | Loss: 0.00082714
Iteration 22/25 | Loss: 0.00082714
Iteration 23/25 | Loss: 0.00082714
Iteration 24/25 | Loss: 0.00082714
Iteration 25/25 | Loss: 0.00082714

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.31606245
Iteration 2/25 | Loss: 0.00064495
Iteration 3/25 | Loss: 0.00064495
Iteration 4/25 | Loss: 0.00064495
Iteration 5/25 | Loss: 0.00064494
Iteration 6/25 | Loss: 0.00064494
Iteration 7/25 | Loss: 0.00064494
Iteration 8/25 | Loss: 0.00064494
Iteration 9/25 | Loss: 0.00064494
Iteration 10/25 | Loss: 0.00064494
Iteration 11/25 | Loss: 0.00064494
Iteration 12/25 | Loss: 0.00064494
Iteration 13/25 | Loss: 0.00064494
Iteration 14/25 | Loss: 0.00064494
Iteration 15/25 | Loss: 0.00064494
Iteration 16/25 | Loss: 0.00064494
Iteration 17/25 | Loss: 0.00064494
Iteration 18/25 | Loss: 0.00064494
Iteration 19/25 | Loss: 0.00064494
Iteration 20/25 | Loss: 0.00064494
Iteration 21/25 | Loss: 0.00064494
Iteration 22/25 | Loss: 0.00064494
Iteration 23/25 | Loss: 0.00064494
Iteration 24/25 | Loss: 0.00064494
Iteration 25/25 | Loss: 0.00064494

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00064494
Iteration 2/1000 | Loss: 0.00002849
Iteration 3/1000 | Loss: 0.00001648
Iteration 4/1000 | Loss: 0.00001453
Iteration 5/1000 | Loss: 0.00001366
Iteration 6/1000 | Loss: 0.00001320
Iteration 7/1000 | Loss: 0.00001280
Iteration 8/1000 | Loss: 0.00001254
Iteration 9/1000 | Loss: 0.00001231
Iteration 10/1000 | Loss: 0.00001219
Iteration 11/1000 | Loss: 0.00001217
Iteration 12/1000 | Loss: 0.00001212
Iteration 13/1000 | Loss: 0.00001211
Iteration 14/1000 | Loss: 0.00001210
Iteration 15/1000 | Loss: 0.00001209
Iteration 16/1000 | Loss: 0.00001209
Iteration 17/1000 | Loss: 0.00001209
Iteration 18/1000 | Loss: 0.00001208
Iteration 19/1000 | Loss: 0.00001204
Iteration 20/1000 | Loss: 0.00001204
Iteration 21/1000 | Loss: 0.00001204
Iteration 22/1000 | Loss: 0.00001203
Iteration 23/1000 | Loss: 0.00001203
Iteration 24/1000 | Loss: 0.00001203
Iteration 25/1000 | Loss: 0.00001203
Iteration 26/1000 | Loss: 0.00001203
Iteration 27/1000 | Loss: 0.00001203
Iteration 28/1000 | Loss: 0.00001203
Iteration 29/1000 | Loss: 0.00001203
Iteration 30/1000 | Loss: 0.00001203
Iteration 31/1000 | Loss: 0.00001203
Iteration 32/1000 | Loss: 0.00001203
Iteration 33/1000 | Loss: 0.00001203
Iteration 34/1000 | Loss: 0.00001203
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 34. Stopping optimization.
Last 5 losses: [1.2029307072225492e-05, 1.2029307072225492e-05, 1.2029307072225492e-05, 1.2029307072225492e-05, 1.2029307072225492e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2029307072225492e-05

Optimization complete. Final v2v error: 2.9550588130950928 mm

Highest mean error: 3.630091905593872 mm for frame 0

Lowest mean error: 2.4431939125061035 mm for frame 25

Saving results

Total time: 52.11061382293701
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00464666
Iteration 2/25 | Loss: 0.00110113
Iteration 3/25 | Loss: 0.00089221
Iteration 4/25 | Loss: 0.00085808
Iteration 5/25 | Loss: 0.00084776
Iteration 6/25 | Loss: 0.00084465
Iteration 7/25 | Loss: 0.00084434
Iteration 8/25 | Loss: 0.00084434
Iteration 9/25 | Loss: 0.00084434
Iteration 10/25 | Loss: 0.00084434
Iteration 11/25 | Loss: 0.00084434
Iteration 12/25 | Loss: 0.00084434
Iteration 13/25 | Loss: 0.00084434
Iteration 14/25 | Loss: 0.00084434
Iteration 15/25 | Loss: 0.00084434
Iteration 16/25 | Loss: 0.00084434
Iteration 17/25 | Loss: 0.00084434
Iteration 18/25 | Loss: 0.00084434
Iteration 19/25 | Loss: 0.00084434
Iteration 20/25 | Loss: 0.00084434
Iteration 21/25 | Loss: 0.00084434
Iteration 22/25 | Loss: 0.00084434
Iteration 23/25 | Loss: 0.00084434
Iteration 24/25 | Loss: 0.00084434
Iteration 25/25 | Loss: 0.00084434

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.31378770
Iteration 2/25 | Loss: 0.00075857
Iteration 3/25 | Loss: 0.00075856
Iteration 4/25 | Loss: 0.00075856
Iteration 5/25 | Loss: 0.00075856
Iteration 6/25 | Loss: 0.00075856
Iteration 7/25 | Loss: 0.00075856
Iteration 8/25 | Loss: 0.00075856
Iteration 9/25 | Loss: 0.00075856
Iteration 10/25 | Loss: 0.00075856
Iteration 11/25 | Loss: 0.00075856
Iteration 12/25 | Loss: 0.00075856
Iteration 13/25 | Loss: 0.00075856
Iteration 14/25 | Loss: 0.00075856
Iteration 15/25 | Loss: 0.00075856
Iteration 16/25 | Loss: 0.00075856
Iteration 17/25 | Loss: 0.00075856
Iteration 18/25 | Loss: 0.00075856
Iteration 19/25 | Loss: 0.00075856
Iteration 20/25 | Loss: 0.00075856
Iteration 21/25 | Loss: 0.00075856
Iteration 22/25 | Loss: 0.00075856
Iteration 23/25 | Loss: 0.00075856
Iteration 24/25 | Loss: 0.00075856
Iteration 25/25 | Loss: 0.00075856

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075856
Iteration 2/1000 | Loss: 0.00003937
Iteration 3/1000 | Loss: 0.00002150
Iteration 4/1000 | Loss: 0.00001702
Iteration 5/1000 | Loss: 0.00001555
Iteration 6/1000 | Loss: 0.00001458
Iteration 7/1000 | Loss: 0.00001403
Iteration 8/1000 | Loss: 0.00001359
Iteration 9/1000 | Loss: 0.00001334
Iteration 10/1000 | Loss: 0.00001314
Iteration 11/1000 | Loss: 0.00001303
Iteration 12/1000 | Loss: 0.00001291
Iteration 13/1000 | Loss: 0.00001290
Iteration 14/1000 | Loss: 0.00001289
Iteration 15/1000 | Loss: 0.00001288
Iteration 16/1000 | Loss: 0.00001287
Iteration 17/1000 | Loss: 0.00001287
Iteration 18/1000 | Loss: 0.00001282
Iteration 19/1000 | Loss: 0.00001276
Iteration 20/1000 | Loss: 0.00001272
Iteration 21/1000 | Loss: 0.00001270
Iteration 22/1000 | Loss: 0.00001269
Iteration 23/1000 | Loss: 0.00001269
Iteration 24/1000 | Loss: 0.00001268
Iteration 25/1000 | Loss: 0.00001266
Iteration 26/1000 | Loss: 0.00001265
Iteration 27/1000 | Loss: 0.00001265
Iteration 28/1000 | Loss: 0.00001261
Iteration 29/1000 | Loss: 0.00001256
Iteration 30/1000 | Loss: 0.00001256
Iteration 31/1000 | Loss: 0.00001255
Iteration 32/1000 | Loss: 0.00001254
Iteration 33/1000 | Loss: 0.00001254
Iteration 34/1000 | Loss: 0.00001254
Iteration 35/1000 | Loss: 0.00001254
Iteration 36/1000 | Loss: 0.00001253
Iteration 37/1000 | Loss: 0.00001253
Iteration 38/1000 | Loss: 0.00001252
Iteration 39/1000 | Loss: 0.00001252
Iteration 40/1000 | Loss: 0.00001251
Iteration 41/1000 | Loss: 0.00001251
Iteration 42/1000 | Loss: 0.00001251
Iteration 43/1000 | Loss: 0.00001250
Iteration 44/1000 | Loss: 0.00001250
Iteration 45/1000 | Loss: 0.00001250
Iteration 46/1000 | Loss: 0.00001250
Iteration 47/1000 | Loss: 0.00001250
Iteration 48/1000 | Loss: 0.00001250
Iteration 49/1000 | Loss: 0.00001250
Iteration 50/1000 | Loss: 0.00001249
Iteration 51/1000 | Loss: 0.00001249
Iteration 52/1000 | Loss: 0.00001249
Iteration 53/1000 | Loss: 0.00001249
Iteration 54/1000 | Loss: 0.00001248
Iteration 55/1000 | Loss: 0.00001248
Iteration 56/1000 | Loss: 0.00001248
Iteration 57/1000 | Loss: 0.00001247
Iteration 58/1000 | Loss: 0.00001247
Iteration 59/1000 | Loss: 0.00001247
Iteration 60/1000 | Loss: 0.00001247
Iteration 61/1000 | Loss: 0.00001246
Iteration 62/1000 | Loss: 0.00001246
Iteration 63/1000 | Loss: 0.00001246
Iteration 64/1000 | Loss: 0.00001246
Iteration 65/1000 | Loss: 0.00001246
Iteration 66/1000 | Loss: 0.00001245
Iteration 67/1000 | Loss: 0.00001245
Iteration 68/1000 | Loss: 0.00001245
Iteration 69/1000 | Loss: 0.00001244
Iteration 70/1000 | Loss: 0.00001244
Iteration 71/1000 | Loss: 0.00001244
Iteration 72/1000 | Loss: 0.00001244
Iteration 73/1000 | Loss: 0.00001243
Iteration 74/1000 | Loss: 0.00001243
Iteration 75/1000 | Loss: 0.00001243
Iteration 76/1000 | Loss: 0.00001243
Iteration 77/1000 | Loss: 0.00001243
Iteration 78/1000 | Loss: 0.00001242
Iteration 79/1000 | Loss: 0.00001242
Iteration 80/1000 | Loss: 0.00001242
Iteration 81/1000 | Loss: 0.00001242
Iteration 82/1000 | Loss: 0.00001242
Iteration 83/1000 | Loss: 0.00001242
Iteration 84/1000 | Loss: 0.00001242
Iteration 85/1000 | Loss: 0.00001242
Iteration 86/1000 | Loss: 0.00001242
Iteration 87/1000 | Loss: 0.00001242
Iteration 88/1000 | Loss: 0.00001242
Iteration 89/1000 | Loss: 0.00001242
Iteration 90/1000 | Loss: 0.00001242
Iteration 91/1000 | Loss: 0.00001242
Iteration 92/1000 | Loss: 0.00001242
Iteration 93/1000 | Loss: 0.00001242
Iteration 94/1000 | Loss: 0.00001242
Iteration 95/1000 | Loss: 0.00001242
Iteration 96/1000 | Loss: 0.00001242
Iteration 97/1000 | Loss: 0.00001242
Iteration 98/1000 | Loss: 0.00001242
Iteration 99/1000 | Loss: 0.00001242
Iteration 100/1000 | Loss: 0.00001242
Iteration 101/1000 | Loss: 0.00001242
Iteration 102/1000 | Loss: 0.00001242
Iteration 103/1000 | Loss: 0.00001242
Iteration 104/1000 | Loss: 0.00001242
Iteration 105/1000 | Loss: 0.00001242
Iteration 106/1000 | Loss: 0.00001242
Iteration 107/1000 | Loss: 0.00001242
Iteration 108/1000 | Loss: 0.00001242
Iteration 109/1000 | Loss: 0.00001242
Iteration 110/1000 | Loss: 0.00001242
Iteration 111/1000 | Loss: 0.00001242
Iteration 112/1000 | Loss: 0.00001242
Iteration 113/1000 | Loss: 0.00001242
Iteration 114/1000 | Loss: 0.00001242
Iteration 115/1000 | Loss: 0.00001242
Iteration 116/1000 | Loss: 0.00001242
Iteration 117/1000 | Loss: 0.00001242
Iteration 118/1000 | Loss: 0.00001242
Iteration 119/1000 | Loss: 0.00001242
Iteration 120/1000 | Loss: 0.00001242
Iteration 121/1000 | Loss: 0.00001242
Iteration 122/1000 | Loss: 0.00001242
Iteration 123/1000 | Loss: 0.00001242
Iteration 124/1000 | Loss: 0.00001242
Iteration 125/1000 | Loss: 0.00001242
Iteration 126/1000 | Loss: 0.00001242
Iteration 127/1000 | Loss: 0.00001242
Iteration 128/1000 | Loss: 0.00001242
Iteration 129/1000 | Loss: 0.00001242
Iteration 130/1000 | Loss: 0.00001242
Iteration 131/1000 | Loss: 0.00001242
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.2415057426551357e-05, 1.2415057426551357e-05, 1.2415057426551357e-05, 1.2415057426551357e-05, 1.2415057426551357e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2415057426551357e-05

Optimization complete. Final v2v error: 2.900905132293701 mm

Highest mean error: 3.9612996578216553 mm for frame 66

Lowest mean error: 2.2828502655029297 mm for frame 225

Saving results

Total time: 41.24297380447388
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00513746
Iteration 2/25 | Loss: 0.00155823
Iteration 3/25 | Loss: 0.00111778
Iteration 4/25 | Loss: 0.00105609
Iteration 5/25 | Loss: 0.00103104
Iteration 6/25 | Loss: 0.00105430
Iteration 7/25 | Loss: 0.00105793
Iteration 8/25 | Loss: 0.00102871
Iteration 9/25 | Loss: 0.00101290
Iteration 10/25 | Loss: 0.00100775
Iteration 11/25 | Loss: 0.00100691
Iteration 12/25 | Loss: 0.00100712
Iteration 13/25 | Loss: 0.00100705
Iteration 14/25 | Loss: 0.00100631
Iteration 15/25 | Loss: 0.00100674
Iteration 16/25 | Loss: 0.00100705
Iteration 17/25 | Loss: 0.00100592
Iteration 18/25 | Loss: 0.00100926
Iteration 19/25 | Loss: 0.00100658
Iteration 20/25 | Loss: 0.00100457
Iteration 21/25 | Loss: 0.00100431
Iteration 22/25 | Loss: 0.00100472
Iteration 23/25 | Loss: 0.00100476
Iteration 24/25 | Loss: 0.00100483
Iteration 25/25 | Loss: 0.00100470

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44477618
Iteration 2/25 | Loss: 0.00070191
Iteration 3/25 | Loss: 0.00070189
Iteration 4/25 | Loss: 0.00070189
Iteration 5/25 | Loss: 0.00070189
Iteration 6/25 | Loss: 0.00070189
Iteration 7/25 | Loss: 0.00070189
Iteration 8/25 | Loss: 0.00070189
Iteration 9/25 | Loss: 0.00070189
Iteration 10/25 | Loss: 0.00070189
Iteration 11/25 | Loss: 0.00070189
Iteration 12/25 | Loss: 0.00070189
Iteration 13/25 | Loss: 0.00070189
Iteration 14/25 | Loss: 0.00070189
Iteration 15/25 | Loss: 0.00070189
Iteration 16/25 | Loss: 0.00070189
Iteration 17/25 | Loss: 0.00070189
Iteration 18/25 | Loss: 0.00070189
Iteration 19/25 | Loss: 0.00070189
Iteration 20/25 | Loss: 0.00070189
Iteration 21/25 | Loss: 0.00070189
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007018905598670244, 0.0007018905598670244, 0.0007018905598670244, 0.0007018905598670244, 0.0007018905598670244]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007018905598670244

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00070189
Iteration 2/1000 | Loss: 0.00049133
Iteration 3/1000 | Loss: 0.00065304
Iteration 4/1000 | Loss: 0.00023090
Iteration 5/1000 | Loss: 0.00057835
Iteration 6/1000 | Loss: 0.00034565
Iteration 7/1000 | Loss: 0.00047451
Iteration 8/1000 | Loss: 0.00034860
Iteration 9/1000 | Loss: 0.00015262
Iteration 10/1000 | Loss: 0.00015788
Iteration 11/1000 | Loss: 0.00006156
Iteration 12/1000 | Loss: 0.00005776
Iteration 13/1000 | Loss: 0.00004853
Iteration 14/1000 | Loss: 0.00004340
Iteration 15/1000 | Loss: 0.00004558
Iteration 16/1000 | Loss: 0.00004288
Iteration 17/1000 | Loss: 0.00004798
Iteration 18/1000 | Loss: 0.00007076
Iteration 19/1000 | Loss: 0.00009431
Iteration 20/1000 | Loss: 0.00004921
Iteration 21/1000 | Loss: 0.00007741
Iteration 22/1000 | Loss: 0.00009782
Iteration 23/1000 | Loss: 0.00006072
Iteration 24/1000 | Loss: 0.00003596
Iteration 25/1000 | Loss: 0.00003374
Iteration 26/1000 | Loss: 0.00004616
Iteration 27/1000 | Loss: 0.00004140
Iteration 28/1000 | Loss: 0.00003829
Iteration 29/1000 | Loss: 0.00003591
Iteration 30/1000 | Loss: 0.00003358
Iteration 31/1000 | Loss: 0.00003996
Iteration 32/1000 | Loss: 0.00003940
Iteration 33/1000 | Loss: 0.00004095
Iteration 34/1000 | Loss: 0.00003490
Iteration 35/1000 | Loss: 0.00003366
Iteration 36/1000 | Loss: 0.00003696
Iteration 37/1000 | Loss: 0.00004264
Iteration 38/1000 | Loss: 0.00003906
Iteration 39/1000 | Loss: 0.00003535
Iteration 40/1000 | Loss: 0.00004251
Iteration 41/1000 | Loss: 0.00003480
Iteration 42/1000 | Loss: 0.00003600
Iteration 43/1000 | Loss: 0.00004207
Iteration 44/1000 | Loss: 0.00004371
Iteration 45/1000 | Loss: 0.00003716
Iteration 46/1000 | Loss: 0.00003829
Iteration 47/1000 | Loss: 0.00003729
Iteration 48/1000 | Loss: 0.00003861
Iteration 49/1000 | Loss: 0.00003615
Iteration 50/1000 | Loss: 0.00003683
Iteration 51/1000 | Loss: 0.00003717
Iteration 52/1000 | Loss: 0.00003931
Iteration 53/1000 | Loss: 0.00005134
Iteration 54/1000 | Loss: 0.00003676
Iteration 55/1000 | Loss: 0.00004472
Iteration 56/1000 | Loss: 0.00004238
Iteration 57/1000 | Loss: 0.00005703
Iteration 58/1000 | Loss: 0.00004225
Iteration 59/1000 | Loss: 0.00007881
Iteration 60/1000 | Loss: 0.00005694
Iteration 61/1000 | Loss: 0.00004081
Iteration 62/1000 | Loss: 0.00003308
Iteration 63/1000 | Loss: 0.00003153
Iteration 64/1000 | Loss: 0.00006240
Iteration 65/1000 | Loss: 0.00004355
Iteration 66/1000 | Loss: 0.00006346
Iteration 67/1000 | Loss: 0.00005763
Iteration 68/1000 | Loss: 0.00006305
Iteration 69/1000 | Loss: 0.00003373
Iteration 70/1000 | Loss: 0.00003277
Iteration 71/1000 | Loss: 0.00003175
Iteration 72/1000 | Loss: 0.00003063
Iteration 73/1000 | Loss: 0.00003001
Iteration 74/1000 | Loss: 0.00002994
Iteration 75/1000 | Loss: 0.00002984
Iteration 76/1000 | Loss: 0.00002976
Iteration 77/1000 | Loss: 0.00006505
Iteration 78/1000 | Loss: 0.00004824
Iteration 79/1000 | Loss: 0.00002954
Iteration 80/1000 | Loss: 0.00002949
Iteration 81/1000 | Loss: 0.00002949
Iteration 82/1000 | Loss: 0.00002949
Iteration 83/1000 | Loss: 0.00002949
Iteration 84/1000 | Loss: 0.00002949
Iteration 85/1000 | Loss: 0.00002949
Iteration 86/1000 | Loss: 0.00002949
Iteration 87/1000 | Loss: 0.00002949
Iteration 88/1000 | Loss: 0.00002949
Iteration 89/1000 | Loss: 0.00002949
Iteration 90/1000 | Loss: 0.00002949
Iteration 91/1000 | Loss: 0.00002949
Iteration 92/1000 | Loss: 0.00002948
Iteration 93/1000 | Loss: 0.00002948
Iteration 94/1000 | Loss: 0.00002948
Iteration 95/1000 | Loss: 0.00002948
Iteration 96/1000 | Loss: 0.00002948
Iteration 97/1000 | Loss: 0.00002948
Iteration 98/1000 | Loss: 0.00002948
Iteration 99/1000 | Loss: 0.00002945
Iteration 100/1000 | Loss: 0.00002944
Iteration 101/1000 | Loss: 0.00002944
Iteration 102/1000 | Loss: 0.00002943
Iteration 103/1000 | Loss: 0.00002943
Iteration 104/1000 | Loss: 0.00002942
Iteration 105/1000 | Loss: 0.00002942
Iteration 106/1000 | Loss: 0.00002942
Iteration 107/1000 | Loss: 0.00002942
Iteration 108/1000 | Loss: 0.00002942
Iteration 109/1000 | Loss: 0.00002942
Iteration 110/1000 | Loss: 0.00002942
Iteration 111/1000 | Loss: 0.00002942
Iteration 112/1000 | Loss: 0.00002942
Iteration 113/1000 | Loss: 0.00002942
Iteration 114/1000 | Loss: 0.00002942
Iteration 115/1000 | Loss: 0.00002942
Iteration 116/1000 | Loss: 0.00002941
Iteration 117/1000 | Loss: 0.00002941
Iteration 118/1000 | Loss: 0.00002941
Iteration 119/1000 | Loss: 0.00002941
Iteration 120/1000 | Loss: 0.00002941
Iteration 121/1000 | Loss: 0.00002941
Iteration 122/1000 | Loss: 0.00002941
Iteration 123/1000 | Loss: 0.00002941
Iteration 124/1000 | Loss: 0.00002941
Iteration 125/1000 | Loss: 0.00002941
Iteration 126/1000 | Loss: 0.00002941
Iteration 127/1000 | Loss: 0.00002941
Iteration 128/1000 | Loss: 0.00002940
Iteration 129/1000 | Loss: 0.00002940
Iteration 130/1000 | Loss: 0.00002940
Iteration 131/1000 | Loss: 0.00006491
Iteration 132/1000 | Loss: 0.00005086
Iteration 133/1000 | Loss: 0.00006636
Iteration 134/1000 | Loss: 0.00005509
Iteration 135/1000 | Loss: 0.00007774
Iteration 136/1000 | Loss: 0.00005757
Iteration 137/1000 | Loss: 0.00007622
Iteration 138/1000 | Loss: 0.00005547
Iteration 139/1000 | Loss: 0.00003439
Iteration 140/1000 | Loss: 0.00003370
Iteration 141/1000 | Loss: 0.00011301
Iteration 142/1000 | Loss: 0.00012317
Iteration 143/1000 | Loss: 0.00005426
Iteration 144/1000 | Loss: 0.00003033
Iteration 145/1000 | Loss: 0.00002945
Iteration 146/1000 | Loss: 0.00002934
Iteration 147/1000 | Loss: 0.00002934
Iteration 148/1000 | Loss: 0.00002933
Iteration 149/1000 | Loss: 0.00002930
Iteration 150/1000 | Loss: 0.00002930
Iteration 151/1000 | Loss: 0.00002928
Iteration 152/1000 | Loss: 0.00002928
Iteration 153/1000 | Loss: 0.00002928
Iteration 154/1000 | Loss: 0.00002928
Iteration 155/1000 | Loss: 0.00002928
Iteration 156/1000 | Loss: 0.00002928
Iteration 157/1000 | Loss: 0.00002927
Iteration 158/1000 | Loss: 0.00002927
Iteration 159/1000 | Loss: 0.00002927
Iteration 160/1000 | Loss: 0.00002927
Iteration 161/1000 | Loss: 0.00002926
Iteration 162/1000 | Loss: 0.00002926
Iteration 163/1000 | Loss: 0.00002926
Iteration 164/1000 | Loss: 0.00002926
Iteration 165/1000 | Loss: 0.00002926
Iteration 166/1000 | Loss: 0.00002926
Iteration 167/1000 | Loss: 0.00002926
Iteration 168/1000 | Loss: 0.00002926
Iteration 169/1000 | Loss: 0.00002925
Iteration 170/1000 | Loss: 0.00002925
Iteration 171/1000 | Loss: 0.00002925
Iteration 172/1000 | Loss: 0.00002925
Iteration 173/1000 | Loss: 0.00002925
Iteration 174/1000 | Loss: 0.00002925
Iteration 175/1000 | Loss: 0.00002925
Iteration 176/1000 | Loss: 0.00002925
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 176. Stopping optimization.
Last 5 losses: [2.925267835962586e-05, 2.925267835962586e-05, 2.925267835962586e-05, 2.925267835962586e-05, 2.925267835962586e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.925267835962586e-05

Optimization complete. Final v2v error: 4.142183780670166 mm

Highest mean error: 5.931849956512451 mm for frame 215

Lowest mean error: 3.73783802986145 mm for frame 195

Saving results

Total time: 204.65136289596558
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01069633
Iteration 2/25 | Loss: 0.00140007
Iteration 3/25 | Loss: 0.00098145
Iteration 4/25 | Loss: 0.00096772
Iteration 5/25 | Loss: 0.00096398
Iteration 6/25 | Loss: 0.00096327
Iteration 7/25 | Loss: 0.00096327
Iteration 8/25 | Loss: 0.00096327
Iteration 9/25 | Loss: 0.00096327
Iteration 10/25 | Loss: 0.00096327
Iteration 11/25 | Loss: 0.00096327
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009632655419409275, 0.0009632655419409275, 0.0009632655419409275, 0.0009632655419409275, 0.0009632655419409275]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009632655419409275

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.42088380
Iteration 2/25 | Loss: 0.00062597
Iteration 3/25 | Loss: 0.00062596
Iteration 4/25 | Loss: 0.00062596
Iteration 5/25 | Loss: 0.00062596
Iteration 6/25 | Loss: 0.00062596
Iteration 7/25 | Loss: 0.00062596
Iteration 8/25 | Loss: 0.00062596
Iteration 9/25 | Loss: 0.00062596
Iteration 10/25 | Loss: 0.00062596
Iteration 11/25 | Loss: 0.00062596
Iteration 12/25 | Loss: 0.00062596
Iteration 13/25 | Loss: 0.00062596
Iteration 14/25 | Loss: 0.00062596
Iteration 15/25 | Loss: 0.00062596
Iteration 16/25 | Loss: 0.00062596
Iteration 17/25 | Loss: 0.00062596
Iteration 18/25 | Loss: 0.00062596
Iteration 19/25 | Loss: 0.00062596
Iteration 20/25 | Loss: 0.00062596
Iteration 21/25 | Loss: 0.00062596
Iteration 22/25 | Loss: 0.00062596
Iteration 23/25 | Loss: 0.00062596
Iteration 24/25 | Loss: 0.00062596
Iteration 25/25 | Loss: 0.00062596

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062596
Iteration 2/1000 | Loss: 0.00004994
Iteration 3/1000 | Loss: 0.00003407
Iteration 4/1000 | Loss: 0.00002898
Iteration 5/1000 | Loss: 0.00002683
Iteration 6/1000 | Loss: 0.00002579
Iteration 7/1000 | Loss: 0.00002484
Iteration 8/1000 | Loss: 0.00002426
Iteration 9/1000 | Loss: 0.00002381
Iteration 10/1000 | Loss: 0.00002339
Iteration 11/1000 | Loss: 0.00002315
Iteration 12/1000 | Loss: 0.00002291
Iteration 13/1000 | Loss: 0.00002271
Iteration 14/1000 | Loss: 0.00002257
Iteration 15/1000 | Loss: 0.00002250
Iteration 16/1000 | Loss: 0.00002241
Iteration 17/1000 | Loss: 0.00002241
Iteration 18/1000 | Loss: 0.00002238
Iteration 19/1000 | Loss: 0.00002232
Iteration 20/1000 | Loss: 0.00002225
Iteration 21/1000 | Loss: 0.00002219
Iteration 22/1000 | Loss: 0.00002217
Iteration 23/1000 | Loss: 0.00002213
Iteration 24/1000 | Loss: 0.00002213
Iteration 25/1000 | Loss: 0.00002211
Iteration 26/1000 | Loss: 0.00002210
Iteration 27/1000 | Loss: 0.00002209
Iteration 28/1000 | Loss: 0.00002204
Iteration 29/1000 | Loss: 0.00002204
Iteration 30/1000 | Loss: 0.00002204
Iteration 31/1000 | Loss: 0.00002203
Iteration 32/1000 | Loss: 0.00002200
Iteration 33/1000 | Loss: 0.00002200
Iteration 34/1000 | Loss: 0.00002200
Iteration 35/1000 | Loss: 0.00002200
Iteration 36/1000 | Loss: 0.00002199
Iteration 37/1000 | Loss: 0.00002199
Iteration 38/1000 | Loss: 0.00002199
Iteration 39/1000 | Loss: 0.00002199
Iteration 40/1000 | Loss: 0.00002198
Iteration 41/1000 | Loss: 0.00002198
Iteration 42/1000 | Loss: 0.00002198
Iteration 43/1000 | Loss: 0.00002197
Iteration 44/1000 | Loss: 0.00002196
Iteration 45/1000 | Loss: 0.00002196
Iteration 46/1000 | Loss: 0.00002195
Iteration 47/1000 | Loss: 0.00002195
Iteration 48/1000 | Loss: 0.00002194
Iteration 49/1000 | Loss: 0.00002194
Iteration 50/1000 | Loss: 0.00002194
Iteration 51/1000 | Loss: 0.00002194
Iteration 52/1000 | Loss: 0.00002194
Iteration 53/1000 | Loss: 0.00002194
Iteration 54/1000 | Loss: 0.00002194
Iteration 55/1000 | Loss: 0.00002194
Iteration 56/1000 | Loss: 0.00002194
Iteration 57/1000 | Loss: 0.00002193
Iteration 58/1000 | Loss: 0.00002193
Iteration 59/1000 | Loss: 0.00002193
Iteration 60/1000 | Loss: 0.00002193
Iteration 61/1000 | Loss: 0.00002193
Iteration 62/1000 | Loss: 0.00002193
Iteration 63/1000 | Loss: 0.00002193
Iteration 64/1000 | Loss: 0.00002193
Iteration 65/1000 | Loss: 0.00002193
Iteration 66/1000 | Loss: 0.00002193
Iteration 67/1000 | Loss: 0.00002193
Iteration 68/1000 | Loss: 0.00002192
Iteration 69/1000 | Loss: 0.00002191
Iteration 70/1000 | Loss: 0.00002191
Iteration 71/1000 | Loss: 0.00002190
Iteration 72/1000 | Loss: 0.00002190
Iteration 73/1000 | Loss: 0.00002190
Iteration 74/1000 | Loss: 0.00002189
Iteration 75/1000 | Loss: 0.00002189
Iteration 76/1000 | Loss: 0.00002189
Iteration 77/1000 | Loss: 0.00002189
Iteration 78/1000 | Loss: 0.00002189
Iteration 79/1000 | Loss: 0.00002188
Iteration 80/1000 | Loss: 0.00002188
Iteration 81/1000 | Loss: 0.00002188
Iteration 82/1000 | Loss: 0.00002188
Iteration 83/1000 | Loss: 0.00002187
Iteration 84/1000 | Loss: 0.00002187
Iteration 85/1000 | Loss: 0.00002187
Iteration 86/1000 | Loss: 0.00002187
Iteration 87/1000 | Loss: 0.00002187
Iteration 88/1000 | Loss: 0.00002187
Iteration 89/1000 | Loss: 0.00002187
Iteration 90/1000 | Loss: 0.00002186
Iteration 91/1000 | Loss: 0.00002186
Iteration 92/1000 | Loss: 0.00002186
Iteration 93/1000 | Loss: 0.00002186
Iteration 94/1000 | Loss: 0.00002186
Iteration 95/1000 | Loss: 0.00002186
Iteration 96/1000 | Loss: 0.00002186
Iteration 97/1000 | Loss: 0.00002186
Iteration 98/1000 | Loss: 0.00002186
Iteration 99/1000 | Loss: 0.00002186
Iteration 100/1000 | Loss: 0.00002186
Iteration 101/1000 | Loss: 0.00002185
Iteration 102/1000 | Loss: 0.00002185
Iteration 103/1000 | Loss: 0.00002185
Iteration 104/1000 | Loss: 0.00002185
Iteration 105/1000 | Loss: 0.00002184
Iteration 106/1000 | Loss: 0.00002184
Iteration 107/1000 | Loss: 0.00002184
Iteration 108/1000 | Loss: 0.00002184
Iteration 109/1000 | Loss: 0.00002184
Iteration 110/1000 | Loss: 0.00002183
Iteration 111/1000 | Loss: 0.00002183
Iteration 112/1000 | Loss: 0.00002183
Iteration 113/1000 | Loss: 0.00002183
Iteration 114/1000 | Loss: 0.00002183
Iteration 115/1000 | Loss: 0.00002182
Iteration 116/1000 | Loss: 0.00002182
Iteration 117/1000 | Loss: 0.00002182
Iteration 118/1000 | Loss: 0.00002182
Iteration 119/1000 | Loss: 0.00002182
Iteration 120/1000 | Loss: 0.00002182
Iteration 121/1000 | Loss: 0.00002182
Iteration 122/1000 | Loss: 0.00002181
Iteration 123/1000 | Loss: 0.00002181
Iteration 124/1000 | Loss: 0.00002181
Iteration 125/1000 | Loss: 0.00002181
Iteration 126/1000 | Loss: 0.00002181
Iteration 127/1000 | Loss: 0.00002181
Iteration 128/1000 | Loss: 0.00002180
Iteration 129/1000 | Loss: 0.00002180
Iteration 130/1000 | Loss: 0.00002180
Iteration 131/1000 | Loss: 0.00002180
Iteration 132/1000 | Loss: 0.00002180
Iteration 133/1000 | Loss: 0.00002180
Iteration 134/1000 | Loss: 0.00002180
Iteration 135/1000 | Loss: 0.00002180
Iteration 136/1000 | Loss: 0.00002180
Iteration 137/1000 | Loss: 0.00002180
Iteration 138/1000 | Loss: 0.00002180
Iteration 139/1000 | Loss: 0.00002180
Iteration 140/1000 | Loss: 0.00002180
Iteration 141/1000 | Loss: 0.00002180
Iteration 142/1000 | Loss: 0.00002180
Iteration 143/1000 | Loss: 0.00002180
Iteration 144/1000 | Loss: 0.00002180
Iteration 145/1000 | Loss: 0.00002180
Iteration 146/1000 | Loss: 0.00002180
Iteration 147/1000 | Loss: 0.00002180
Iteration 148/1000 | Loss: 0.00002180
Iteration 149/1000 | Loss: 0.00002180
Iteration 150/1000 | Loss: 0.00002180
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [2.180064984713681e-05, 2.180064984713681e-05, 2.180064984713681e-05, 2.180064984713681e-05, 2.180064984713681e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.180064984713681e-05

Optimization complete. Final v2v error: 3.7276272773742676 mm

Highest mean error: 4.80191707611084 mm for frame 26

Lowest mean error: 2.5481297969818115 mm for frame 0

Saving results

Total time: 46.655312299728394
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01005683
Iteration 2/25 | Loss: 0.00152282
Iteration 3/25 | Loss: 0.00109685
Iteration 4/25 | Loss: 0.00105911
Iteration 5/25 | Loss: 0.00105440
Iteration 6/25 | Loss: 0.00105370
Iteration 7/25 | Loss: 0.00105370
Iteration 8/25 | Loss: 0.00105370
Iteration 9/25 | Loss: 0.00105370
Iteration 10/25 | Loss: 0.00105370
Iteration 11/25 | Loss: 0.00105370
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0010536984773352742, 0.0010536984773352742, 0.0010536984773352742, 0.0010536984773352742, 0.0010536984773352742]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010536984773352742

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.90940285
Iteration 2/25 | Loss: 0.00056638
Iteration 3/25 | Loss: 0.00056634
Iteration 4/25 | Loss: 0.00056633
Iteration 5/25 | Loss: 0.00056633
Iteration 6/25 | Loss: 0.00056633
Iteration 7/25 | Loss: 0.00056633
Iteration 8/25 | Loss: 0.00056633
Iteration 9/25 | Loss: 0.00056633
Iteration 10/25 | Loss: 0.00056633
Iteration 11/25 | Loss: 0.00056633
Iteration 12/25 | Loss: 0.00056633
Iteration 13/25 | Loss: 0.00056633
Iteration 14/25 | Loss: 0.00056633
Iteration 15/25 | Loss: 0.00056633
Iteration 16/25 | Loss: 0.00056633
Iteration 17/25 | Loss: 0.00056633
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0005663326592184603, 0.0005663326592184603, 0.0005663326592184603, 0.0005663326592184603, 0.0005663326592184603]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005663326592184603

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00056633
Iteration 2/1000 | Loss: 0.00008835
Iteration 3/1000 | Loss: 0.00004799
Iteration 4/1000 | Loss: 0.00003978
Iteration 5/1000 | Loss: 0.00003738
Iteration 6/1000 | Loss: 0.00003571
Iteration 7/1000 | Loss: 0.00003497
Iteration 8/1000 | Loss: 0.00003436
Iteration 9/1000 | Loss: 0.00003386
Iteration 10/1000 | Loss: 0.00003349
Iteration 11/1000 | Loss: 0.00003317
Iteration 12/1000 | Loss: 0.00003294
Iteration 13/1000 | Loss: 0.00003277
Iteration 14/1000 | Loss: 0.00003253
Iteration 15/1000 | Loss: 0.00003223
Iteration 16/1000 | Loss: 0.00003202
Iteration 17/1000 | Loss: 0.00003195
Iteration 18/1000 | Loss: 0.00003177
Iteration 19/1000 | Loss: 0.00003164
Iteration 20/1000 | Loss: 0.00003157
Iteration 21/1000 | Loss: 0.00003143
Iteration 22/1000 | Loss: 0.00003136
Iteration 23/1000 | Loss: 0.00003136
Iteration 24/1000 | Loss: 0.00003134
Iteration 25/1000 | Loss: 0.00003133
Iteration 26/1000 | Loss: 0.00003131
Iteration 27/1000 | Loss: 0.00003130
Iteration 28/1000 | Loss: 0.00003130
Iteration 29/1000 | Loss: 0.00003130
Iteration 30/1000 | Loss: 0.00003130
Iteration 31/1000 | Loss: 0.00003129
Iteration 32/1000 | Loss: 0.00003125
Iteration 33/1000 | Loss: 0.00003125
Iteration 34/1000 | Loss: 0.00003125
Iteration 35/1000 | Loss: 0.00003125
Iteration 36/1000 | Loss: 0.00003125
Iteration 37/1000 | Loss: 0.00003125
Iteration 38/1000 | Loss: 0.00003125
Iteration 39/1000 | Loss: 0.00003125
Iteration 40/1000 | Loss: 0.00003125
Iteration 41/1000 | Loss: 0.00003125
Iteration 42/1000 | Loss: 0.00003125
Iteration 43/1000 | Loss: 0.00003125
Iteration 44/1000 | Loss: 0.00003125
Iteration 45/1000 | Loss: 0.00003125
Iteration 46/1000 | Loss: 0.00003125
Iteration 47/1000 | Loss: 0.00003125
Iteration 48/1000 | Loss: 0.00003125
Iteration 49/1000 | Loss: 0.00003125
Iteration 50/1000 | Loss: 0.00003125
Iteration 51/1000 | Loss: 0.00003125
Iteration 52/1000 | Loss: 0.00003125
Iteration 53/1000 | Loss: 0.00003125
Iteration 54/1000 | Loss: 0.00003125
Iteration 55/1000 | Loss: 0.00003125
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 55. Stopping optimization.
Last 5 losses: [3.1252726330421865e-05, 3.1252726330421865e-05, 3.1252726330421865e-05, 3.1252726330421865e-05, 3.1252726330421865e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.1252726330421865e-05

Optimization complete. Final v2v error: 4.418194770812988 mm

Highest mean error: 5.444344997406006 mm for frame 120

Lowest mean error: 3.496885299682617 mm for frame 81

Saving results

Total time: 44.88720107078552
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00814547
Iteration 2/25 | Loss: 0.00086261
Iteration 3/25 | Loss: 0.00077856
Iteration 4/25 | Loss: 0.00076732
Iteration 5/25 | Loss: 0.00076404
Iteration 6/25 | Loss: 0.00076340
Iteration 7/25 | Loss: 0.00076340
Iteration 8/25 | Loss: 0.00076340
Iteration 9/25 | Loss: 0.00076340
Iteration 10/25 | Loss: 0.00076340
Iteration 11/25 | Loss: 0.00076340
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007634001085534692, 0.0007634001085534692, 0.0007634001085534692, 0.0007634001085534692, 0.0007634001085534692]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007634001085534692

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48554552
Iteration 2/25 | Loss: 0.00061241
Iteration 3/25 | Loss: 0.00061241
Iteration 4/25 | Loss: 0.00061240
Iteration 5/25 | Loss: 0.00061240
Iteration 6/25 | Loss: 0.00061240
Iteration 7/25 | Loss: 0.00061240
Iteration 8/25 | Loss: 0.00061240
Iteration 9/25 | Loss: 0.00061240
Iteration 10/25 | Loss: 0.00061240
Iteration 11/25 | Loss: 0.00061240
Iteration 12/25 | Loss: 0.00061240
Iteration 13/25 | Loss: 0.00061240
Iteration 14/25 | Loss: 0.00061240
Iteration 15/25 | Loss: 0.00061240
Iteration 16/25 | Loss: 0.00061240
Iteration 17/25 | Loss: 0.00061240
Iteration 18/25 | Loss: 0.00061240
Iteration 19/25 | Loss: 0.00061240
Iteration 20/25 | Loss: 0.00061240
Iteration 21/25 | Loss: 0.00061240
Iteration 22/25 | Loss: 0.00061240
Iteration 23/25 | Loss: 0.00061240
Iteration 24/25 | Loss: 0.00061240
Iteration 25/25 | Loss: 0.00061240

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061240
Iteration 2/1000 | Loss: 0.00001692
Iteration 3/1000 | Loss: 0.00001145
Iteration 4/1000 | Loss: 0.00001039
Iteration 5/1000 | Loss: 0.00000989
Iteration 6/1000 | Loss: 0.00000948
Iteration 7/1000 | Loss: 0.00000930
Iteration 8/1000 | Loss: 0.00000911
Iteration 9/1000 | Loss: 0.00000904
Iteration 10/1000 | Loss: 0.00000900
Iteration 11/1000 | Loss: 0.00000899
Iteration 12/1000 | Loss: 0.00000899
Iteration 13/1000 | Loss: 0.00000898
Iteration 14/1000 | Loss: 0.00000895
Iteration 15/1000 | Loss: 0.00000893
Iteration 16/1000 | Loss: 0.00000892
Iteration 17/1000 | Loss: 0.00000891
Iteration 18/1000 | Loss: 0.00000890
Iteration 19/1000 | Loss: 0.00000890
Iteration 20/1000 | Loss: 0.00000888
Iteration 21/1000 | Loss: 0.00000885
Iteration 22/1000 | Loss: 0.00000885
Iteration 23/1000 | Loss: 0.00000885
Iteration 24/1000 | Loss: 0.00000885
Iteration 25/1000 | Loss: 0.00000885
Iteration 26/1000 | Loss: 0.00000885
Iteration 27/1000 | Loss: 0.00000885
Iteration 28/1000 | Loss: 0.00000885
Iteration 29/1000 | Loss: 0.00000884
Iteration 30/1000 | Loss: 0.00000884
Iteration 31/1000 | Loss: 0.00000884
Iteration 32/1000 | Loss: 0.00000884
Iteration 33/1000 | Loss: 0.00000884
Iteration 34/1000 | Loss: 0.00000884
Iteration 35/1000 | Loss: 0.00000884
Iteration 36/1000 | Loss: 0.00000883
Iteration 37/1000 | Loss: 0.00000882
Iteration 38/1000 | Loss: 0.00000882
Iteration 39/1000 | Loss: 0.00000881
Iteration 40/1000 | Loss: 0.00000881
Iteration 41/1000 | Loss: 0.00000880
Iteration 42/1000 | Loss: 0.00000880
Iteration 43/1000 | Loss: 0.00000880
Iteration 44/1000 | Loss: 0.00000879
Iteration 45/1000 | Loss: 0.00000878
Iteration 46/1000 | Loss: 0.00000877
Iteration 47/1000 | Loss: 0.00000877
Iteration 48/1000 | Loss: 0.00000876
Iteration 49/1000 | Loss: 0.00000876
Iteration 50/1000 | Loss: 0.00000876
Iteration 51/1000 | Loss: 0.00000876
Iteration 52/1000 | Loss: 0.00000876
Iteration 53/1000 | Loss: 0.00000875
Iteration 54/1000 | Loss: 0.00000875
Iteration 55/1000 | Loss: 0.00000875
Iteration 56/1000 | Loss: 0.00000875
Iteration 57/1000 | Loss: 0.00000875
Iteration 58/1000 | Loss: 0.00000874
Iteration 59/1000 | Loss: 0.00000874
Iteration 60/1000 | Loss: 0.00000874
Iteration 61/1000 | Loss: 0.00000874
Iteration 62/1000 | Loss: 0.00000874
Iteration 63/1000 | Loss: 0.00000874
Iteration 64/1000 | Loss: 0.00000874
Iteration 65/1000 | Loss: 0.00000874
Iteration 66/1000 | Loss: 0.00000874
Iteration 67/1000 | Loss: 0.00000874
Iteration 68/1000 | Loss: 0.00000874
Iteration 69/1000 | Loss: 0.00000874
Iteration 70/1000 | Loss: 0.00000873
Iteration 71/1000 | Loss: 0.00000873
Iteration 72/1000 | Loss: 0.00000873
Iteration 73/1000 | Loss: 0.00000873
Iteration 74/1000 | Loss: 0.00000873
Iteration 75/1000 | Loss: 0.00000873
Iteration 76/1000 | Loss: 0.00000873
Iteration 77/1000 | Loss: 0.00000873
Iteration 78/1000 | Loss: 0.00000873
Iteration 79/1000 | Loss: 0.00000873
Iteration 80/1000 | Loss: 0.00000873
Iteration 81/1000 | Loss: 0.00000873
Iteration 82/1000 | Loss: 0.00000873
Iteration 83/1000 | Loss: 0.00000873
Iteration 84/1000 | Loss: 0.00000873
Iteration 85/1000 | Loss: 0.00000873
Iteration 86/1000 | Loss: 0.00000873
Iteration 87/1000 | Loss: 0.00000873
Iteration 88/1000 | Loss: 0.00000873
Iteration 89/1000 | Loss: 0.00000873
Iteration 90/1000 | Loss: 0.00000873
Iteration 91/1000 | Loss: 0.00000873
Iteration 92/1000 | Loss: 0.00000873
Iteration 93/1000 | Loss: 0.00000873
Iteration 94/1000 | Loss: 0.00000873
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [8.73369845066918e-06, 8.73369845066918e-06, 8.73369845066918e-06, 8.73369845066918e-06, 8.73369845066918e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.73369845066918e-06

Optimization complete. Final v2v error: 2.5141830444335938 mm

Highest mean error: 2.9557790756225586 mm for frame 94

Lowest mean error: 2.0213446617126465 mm for frame 142

Saving results

Total time: 27.287904500961304
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00456352
Iteration 2/25 | Loss: 0.00098388
Iteration 3/25 | Loss: 0.00089356
Iteration 4/25 | Loss: 0.00088108
Iteration 5/25 | Loss: 0.00087656
Iteration 6/25 | Loss: 0.00087516
Iteration 7/25 | Loss: 0.00087516
Iteration 8/25 | Loss: 0.00087516
Iteration 9/25 | Loss: 0.00087516
Iteration 10/25 | Loss: 0.00087516
Iteration 11/25 | Loss: 0.00087516
Iteration 12/25 | Loss: 0.00087516
Iteration 13/25 | Loss: 0.00087516
Iteration 14/25 | Loss: 0.00087516
Iteration 15/25 | Loss: 0.00087516
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008751593995839357, 0.0008751593995839357, 0.0008751593995839357, 0.0008751593995839357, 0.0008751593995839357]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008751593995839357

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47094393
Iteration 2/25 | Loss: 0.00073289
Iteration 3/25 | Loss: 0.00073289
Iteration 4/25 | Loss: 0.00073289
Iteration 5/25 | Loss: 0.00073289
Iteration 6/25 | Loss: 0.00073289
Iteration 7/25 | Loss: 0.00073289
Iteration 8/25 | Loss: 0.00073289
Iteration 9/25 | Loss: 0.00073289
Iteration 10/25 | Loss: 0.00073289
Iteration 11/25 | Loss: 0.00073289
Iteration 12/25 | Loss: 0.00073289
Iteration 13/25 | Loss: 0.00073289
Iteration 14/25 | Loss: 0.00073289
Iteration 15/25 | Loss: 0.00073289
Iteration 16/25 | Loss: 0.00073289
Iteration 17/25 | Loss: 0.00073289
Iteration 18/25 | Loss: 0.00073289
Iteration 19/25 | Loss: 0.00073289
Iteration 20/25 | Loss: 0.00073289
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0007328905048780143, 0.0007328905048780143, 0.0007328905048780143, 0.0007328905048780143, 0.0007328905048780143]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007328905048780143

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073289
Iteration 2/1000 | Loss: 0.00003915
Iteration 3/1000 | Loss: 0.00002481
Iteration 4/1000 | Loss: 0.00002209
Iteration 5/1000 | Loss: 0.00002106
Iteration 6/1000 | Loss: 0.00002031
Iteration 7/1000 | Loss: 0.00001972
Iteration 8/1000 | Loss: 0.00001928
Iteration 9/1000 | Loss: 0.00001897
Iteration 10/1000 | Loss: 0.00001869
Iteration 11/1000 | Loss: 0.00001851
Iteration 12/1000 | Loss: 0.00001835
Iteration 13/1000 | Loss: 0.00001830
Iteration 14/1000 | Loss: 0.00001825
Iteration 15/1000 | Loss: 0.00001818
Iteration 16/1000 | Loss: 0.00001818
Iteration 17/1000 | Loss: 0.00001818
Iteration 18/1000 | Loss: 0.00001818
Iteration 19/1000 | Loss: 0.00001816
Iteration 20/1000 | Loss: 0.00001816
Iteration 21/1000 | Loss: 0.00001815
Iteration 22/1000 | Loss: 0.00001814
Iteration 23/1000 | Loss: 0.00001814
Iteration 24/1000 | Loss: 0.00001813
Iteration 25/1000 | Loss: 0.00001813
Iteration 26/1000 | Loss: 0.00001813
Iteration 27/1000 | Loss: 0.00001812
Iteration 28/1000 | Loss: 0.00001811
Iteration 29/1000 | Loss: 0.00001810
Iteration 30/1000 | Loss: 0.00001810
Iteration 31/1000 | Loss: 0.00001809
Iteration 32/1000 | Loss: 0.00001809
Iteration 33/1000 | Loss: 0.00001807
Iteration 34/1000 | Loss: 0.00001806
Iteration 35/1000 | Loss: 0.00001805
Iteration 36/1000 | Loss: 0.00001805
Iteration 37/1000 | Loss: 0.00001804
Iteration 38/1000 | Loss: 0.00001804
Iteration 39/1000 | Loss: 0.00001803
Iteration 40/1000 | Loss: 0.00001803
Iteration 41/1000 | Loss: 0.00001801
Iteration 42/1000 | Loss: 0.00001801
Iteration 43/1000 | Loss: 0.00001801
Iteration 44/1000 | Loss: 0.00001800
Iteration 45/1000 | Loss: 0.00001800
Iteration 46/1000 | Loss: 0.00001800
Iteration 47/1000 | Loss: 0.00001800
Iteration 48/1000 | Loss: 0.00001800
Iteration 49/1000 | Loss: 0.00001800
Iteration 50/1000 | Loss: 0.00001799
Iteration 51/1000 | Loss: 0.00001799
Iteration 52/1000 | Loss: 0.00001798
Iteration 53/1000 | Loss: 0.00001798
Iteration 54/1000 | Loss: 0.00001797
Iteration 55/1000 | Loss: 0.00001797
Iteration 56/1000 | Loss: 0.00001797
Iteration 57/1000 | Loss: 0.00001797
Iteration 58/1000 | Loss: 0.00001797
Iteration 59/1000 | Loss: 0.00001796
Iteration 60/1000 | Loss: 0.00001796
Iteration 61/1000 | Loss: 0.00001796
Iteration 62/1000 | Loss: 0.00001795
Iteration 63/1000 | Loss: 0.00001795
Iteration 64/1000 | Loss: 0.00001794
Iteration 65/1000 | Loss: 0.00001794
Iteration 66/1000 | Loss: 0.00001793
Iteration 67/1000 | Loss: 0.00001793
Iteration 68/1000 | Loss: 0.00001793
Iteration 69/1000 | Loss: 0.00001793
Iteration 70/1000 | Loss: 0.00001792
Iteration 71/1000 | Loss: 0.00001792
Iteration 72/1000 | Loss: 0.00001792
Iteration 73/1000 | Loss: 0.00001791
Iteration 74/1000 | Loss: 0.00001791
Iteration 75/1000 | Loss: 0.00001790
Iteration 76/1000 | Loss: 0.00001790
Iteration 77/1000 | Loss: 0.00001790
Iteration 78/1000 | Loss: 0.00001790
Iteration 79/1000 | Loss: 0.00001790
Iteration 80/1000 | Loss: 0.00001790
Iteration 81/1000 | Loss: 0.00001790
Iteration 82/1000 | Loss: 0.00001790
Iteration 83/1000 | Loss: 0.00001790
Iteration 84/1000 | Loss: 0.00001790
Iteration 85/1000 | Loss: 0.00001790
Iteration 86/1000 | Loss: 0.00001790
Iteration 87/1000 | Loss: 0.00001790
Iteration 88/1000 | Loss: 0.00001789
Iteration 89/1000 | Loss: 0.00001789
Iteration 90/1000 | Loss: 0.00001789
Iteration 91/1000 | Loss: 0.00001789
Iteration 92/1000 | Loss: 0.00001789
Iteration 93/1000 | Loss: 0.00001789
Iteration 94/1000 | Loss: 0.00001788
Iteration 95/1000 | Loss: 0.00001788
Iteration 96/1000 | Loss: 0.00001788
Iteration 97/1000 | Loss: 0.00001788
Iteration 98/1000 | Loss: 0.00001788
Iteration 99/1000 | Loss: 0.00001788
Iteration 100/1000 | Loss: 0.00001788
Iteration 101/1000 | Loss: 0.00001788
Iteration 102/1000 | Loss: 0.00001788
Iteration 103/1000 | Loss: 0.00001788
Iteration 104/1000 | Loss: 0.00001787
Iteration 105/1000 | Loss: 0.00001787
Iteration 106/1000 | Loss: 0.00001787
Iteration 107/1000 | Loss: 0.00001787
Iteration 108/1000 | Loss: 0.00001787
Iteration 109/1000 | Loss: 0.00001787
Iteration 110/1000 | Loss: 0.00001787
Iteration 111/1000 | Loss: 0.00001787
Iteration 112/1000 | Loss: 0.00001787
Iteration 113/1000 | Loss: 0.00001787
Iteration 114/1000 | Loss: 0.00001786
Iteration 115/1000 | Loss: 0.00001786
Iteration 116/1000 | Loss: 0.00001786
Iteration 117/1000 | Loss: 0.00001786
Iteration 118/1000 | Loss: 0.00001786
Iteration 119/1000 | Loss: 0.00001786
Iteration 120/1000 | Loss: 0.00001786
Iteration 121/1000 | Loss: 0.00001786
Iteration 122/1000 | Loss: 0.00001785
Iteration 123/1000 | Loss: 0.00001785
Iteration 124/1000 | Loss: 0.00001785
Iteration 125/1000 | Loss: 0.00001785
Iteration 126/1000 | Loss: 0.00001785
Iteration 127/1000 | Loss: 0.00001785
Iteration 128/1000 | Loss: 0.00001785
Iteration 129/1000 | Loss: 0.00001784
Iteration 130/1000 | Loss: 0.00001784
Iteration 131/1000 | Loss: 0.00001784
Iteration 132/1000 | Loss: 0.00001784
Iteration 133/1000 | Loss: 0.00001784
Iteration 134/1000 | Loss: 0.00001784
Iteration 135/1000 | Loss: 0.00001784
Iteration 136/1000 | Loss: 0.00001784
Iteration 137/1000 | Loss: 0.00001784
Iteration 138/1000 | Loss: 0.00001783
Iteration 139/1000 | Loss: 0.00001783
Iteration 140/1000 | Loss: 0.00001783
Iteration 141/1000 | Loss: 0.00001783
Iteration 142/1000 | Loss: 0.00001782
Iteration 143/1000 | Loss: 0.00001782
Iteration 144/1000 | Loss: 0.00001782
Iteration 145/1000 | Loss: 0.00001782
Iteration 146/1000 | Loss: 0.00001782
Iteration 147/1000 | Loss: 0.00001782
Iteration 148/1000 | Loss: 0.00001782
Iteration 149/1000 | Loss: 0.00001782
Iteration 150/1000 | Loss: 0.00001782
Iteration 151/1000 | Loss: 0.00001781
Iteration 152/1000 | Loss: 0.00001781
Iteration 153/1000 | Loss: 0.00001781
Iteration 154/1000 | Loss: 0.00001780
Iteration 155/1000 | Loss: 0.00001780
Iteration 156/1000 | Loss: 0.00001780
Iteration 157/1000 | Loss: 0.00001780
Iteration 158/1000 | Loss: 0.00001779
Iteration 159/1000 | Loss: 0.00001779
Iteration 160/1000 | Loss: 0.00001779
Iteration 161/1000 | Loss: 0.00001779
Iteration 162/1000 | Loss: 0.00001779
Iteration 163/1000 | Loss: 0.00001779
Iteration 164/1000 | Loss: 0.00001778
Iteration 165/1000 | Loss: 0.00001778
Iteration 166/1000 | Loss: 0.00001778
Iteration 167/1000 | Loss: 0.00001778
Iteration 168/1000 | Loss: 0.00001778
Iteration 169/1000 | Loss: 0.00001778
Iteration 170/1000 | Loss: 0.00001778
Iteration 171/1000 | Loss: 0.00001778
Iteration 172/1000 | Loss: 0.00001778
Iteration 173/1000 | Loss: 0.00001778
Iteration 174/1000 | Loss: 0.00001778
Iteration 175/1000 | Loss: 0.00001778
Iteration 176/1000 | Loss: 0.00001778
Iteration 177/1000 | Loss: 0.00001777
Iteration 178/1000 | Loss: 0.00001777
Iteration 179/1000 | Loss: 0.00001777
Iteration 180/1000 | Loss: 0.00001777
Iteration 181/1000 | Loss: 0.00001777
Iteration 182/1000 | Loss: 0.00001777
Iteration 183/1000 | Loss: 0.00001777
Iteration 184/1000 | Loss: 0.00001777
Iteration 185/1000 | Loss: 0.00001777
Iteration 186/1000 | Loss: 0.00001777
Iteration 187/1000 | Loss: 0.00001776
Iteration 188/1000 | Loss: 0.00001776
Iteration 189/1000 | Loss: 0.00001776
Iteration 190/1000 | Loss: 0.00001776
Iteration 191/1000 | Loss: 0.00001776
Iteration 192/1000 | Loss: 0.00001776
Iteration 193/1000 | Loss: 0.00001775
Iteration 194/1000 | Loss: 0.00001775
Iteration 195/1000 | Loss: 0.00001775
Iteration 196/1000 | Loss: 0.00001775
Iteration 197/1000 | Loss: 0.00001775
Iteration 198/1000 | Loss: 0.00001775
Iteration 199/1000 | Loss: 0.00001775
Iteration 200/1000 | Loss: 0.00001775
Iteration 201/1000 | Loss: 0.00001775
Iteration 202/1000 | Loss: 0.00001775
Iteration 203/1000 | Loss: 0.00001775
Iteration 204/1000 | Loss: 0.00001775
Iteration 205/1000 | Loss: 0.00001775
Iteration 206/1000 | Loss: 0.00001775
Iteration 207/1000 | Loss: 0.00001774
Iteration 208/1000 | Loss: 0.00001774
Iteration 209/1000 | Loss: 0.00001774
Iteration 210/1000 | Loss: 0.00001774
Iteration 211/1000 | Loss: 0.00001774
Iteration 212/1000 | Loss: 0.00001774
Iteration 213/1000 | Loss: 0.00001774
Iteration 214/1000 | Loss: 0.00001774
Iteration 215/1000 | Loss: 0.00001774
Iteration 216/1000 | Loss: 0.00001774
Iteration 217/1000 | Loss: 0.00001774
Iteration 218/1000 | Loss: 0.00001774
Iteration 219/1000 | Loss: 0.00001774
Iteration 220/1000 | Loss: 0.00001774
Iteration 221/1000 | Loss: 0.00001774
Iteration 222/1000 | Loss: 0.00001774
Iteration 223/1000 | Loss: 0.00001774
Iteration 224/1000 | Loss: 0.00001774
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 224. Stopping optimization.
Last 5 losses: [1.7743224816513248e-05, 1.7743224816513248e-05, 1.7743224816513248e-05, 1.7743224816513248e-05, 1.7743224816513248e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7743224816513248e-05

Optimization complete. Final v2v error: 3.577955722808838 mm

Highest mean error: 4.083907127380371 mm for frame 192

Lowest mean error: 2.8623905181884766 mm for frame 66

Saving results

Total time: 48.178191900253296
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00827573
Iteration 2/25 | Loss: 0.00127245
Iteration 3/25 | Loss: 0.00102591
Iteration 4/25 | Loss: 0.00099708
Iteration 5/25 | Loss: 0.00099023
Iteration 6/25 | Loss: 0.00098904
Iteration 7/25 | Loss: 0.00098904
Iteration 8/25 | Loss: 0.00098904
Iteration 9/25 | Loss: 0.00098904
Iteration 10/25 | Loss: 0.00098904
Iteration 11/25 | Loss: 0.00098904
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009890437358990312, 0.0009890437358990312, 0.0009890437358990312, 0.0009890437358990312, 0.0009890437358990312]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009890437358990312

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.12704659
Iteration 2/25 | Loss: 0.00071360
Iteration 3/25 | Loss: 0.00071360
Iteration 4/25 | Loss: 0.00071360
Iteration 5/25 | Loss: 0.00071360
Iteration 6/25 | Loss: 0.00071360
Iteration 7/25 | Loss: 0.00071359
Iteration 8/25 | Loss: 0.00071359
Iteration 9/25 | Loss: 0.00071359
Iteration 10/25 | Loss: 0.00071359
Iteration 11/25 | Loss: 0.00071359
Iteration 12/25 | Loss: 0.00071359
Iteration 13/25 | Loss: 0.00071359
Iteration 14/25 | Loss: 0.00071359
Iteration 15/25 | Loss: 0.00071359
Iteration 16/25 | Loss: 0.00071359
Iteration 17/25 | Loss: 0.00071359
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007135935593396425, 0.0007135935593396425, 0.0007135935593396425, 0.0007135935593396425, 0.0007135935593396425]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007135935593396425

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071359
Iteration 2/1000 | Loss: 0.00006539
Iteration 3/1000 | Loss: 0.00004441
Iteration 4/1000 | Loss: 0.00003704
Iteration 5/1000 | Loss: 0.00003492
Iteration 6/1000 | Loss: 0.00003373
Iteration 7/1000 | Loss: 0.00003256
Iteration 8/1000 | Loss: 0.00003176
Iteration 9/1000 | Loss: 0.00003111
Iteration 10/1000 | Loss: 0.00003056
Iteration 11/1000 | Loss: 0.00003000
Iteration 12/1000 | Loss: 0.00002969
Iteration 13/1000 | Loss: 0.00002946
Iteration 14/1000 | Loss: 0.00002915
Iteration 15/1000 | Loss: 0.00002896
Iteration 16/1000 | Loss: 0.00002894
Iteration 17/1000 | Loss: 0.00002874
Iteration 18/1000 | Loss: 0.00002860
Iteration 19/1000 | Loss: 0.00002860
Iteration 20/1000 | Loss: 0.00002851
Iteration 21/1000 | Loss: 0.00002844
Iteration 22/1000 | Loss: 0.00002844
Iteration 23/1000 | Loss: 0.00002840
Iteration 24/1000 | Loss: 0.00002837
Iteration 25/1000 | Loss: 0.00002829
Iteration 26/1000 | Loss: 0.00002819
Iteration 27/1000 | Loss: 0.00002815
Iteration 28/1000 | Loss: 0.00002815
Iteration 29/1000 | Loss: 0.00002815
Iteration 30/1000 | Loss: 0.00002815
Iteration 31/1000 | Loss: 0.00002815
Iteration 32/1000 | Loss: 0.00002815
Iteration 33/1000 | Loss: 0.00002814
Iteration 34/1000 | Loss: 0.00002814
Iteration 35/1000 | Loss: 0.00002814
Iteration 36/1000 | Loss: 0.00002814
Iteration 37/1000 | Loss: 0.00002814
Iteration 38/1000 | Loss: 0.00002814
Iteration 39/1000 | Loss: 0.00002808
Iteration 40/1000 | Loss: 0.00002805
Iteration 41/1000 | Loss: 0.00002802
Iteration 42/1000 | Loss: 0.00002800
Iteration 43/1000 | Loss: 0.00002800
Iteration 44/1000 | Loss: 0.00002799
Iteration 45/1000 | Loss: 0.00002799
Iteration 46/1000 | Loss: 0.00002799
Iteration 47/1000 | Loss: 0.00002793
Iteration 48/1000 | Loss: 0.00002793
Iteration 49/1000 | Loss: 0.00002793
Iteration 50/1000 | Loss: 0.00002792
Iteration 51/1000 | Loss: 0.00002792
Iteration 52/1000 | Loss: 0.00002791
Iteration 53/1000 | Loss: 0.00002791
Iteration 54/1000 | Loss: 0.00002791
Iteration 55/1000 | Loss: 0.00002791
Iteration 56/1000 | Loss: 0.00002791
Iteration 57/1000 | Loss: 0.00002791
Iteration 58/1000 | Loss: 0.00002791
Iteration 59/1000 | Loss: 0.00002791
Iteration 60/1000 | Loss: 0.00002791
Iteration 61/1000 | Loss: 0.00002790
Iteration 62/1000 | Loss: 0.00002790
Iteration 63/1000 | Loss: 0.00002790
Iteration 64/1000 | Loss: 0.00002790
Iteration 65/1000 | Loss: 0.00002790
Iteration 66/1000 | Loss: 0.00002790
Iteration 67/1000 | Loss: 0.00002790
Iteration 68/1000 | Loss: 0.00002790
Iteration 69/1000 | Loss: 0.00002790
Iteration 70/1000 | Loss: 0.00002790
Iteration 71/1000 | Loss: 0.00002789
Iteration 72/1000 | Loss: 0.00002789
Iteration 73/1000 | Loss: 0.00002789
Iteration 74/1000 | Loss: 0.00002789
Iteration 75/1000 | Loss: 0.00002789
Iteration 76/1000 | Loss: 0.00002788
Iteration 77/1000 | Loss: 0.00002788
Iteration 78/1000 | Loss: 0.00002788
Iteration 79/1000 | Loss: 0.00002788
Iteration 80/1000 | Loss: 0.00002788
Iteration 81/1000 | Loss: 0.00002788
Iteration 82/1000 | Loss: 0.00002788
Iteration 83/1000 | Loss: 0.00002787
Iteration 84/1000 | Loss: 0.00002787
Iteration 85/1000 | Loss: 0.00002787
Iteration 86/1000 | Loss: 0.00002787
Iteration 87/1000 | Loss: 0.00002787
Iteration 88/1000 | Loss: 0.00002787
Iteration 89/1000 | Loss: 0.00002787
Iteration 90/1000 | Loss: 0.00002787
Iteration 91/1000 | Loss: 0.00002787
Iteration 92/1000 | Loss: 0.00002787
Iteration 93/1000 | Loss: 0.00002787
Iteration 94/1000 | Loss: 0.00002787
Iteration 95/1000 | Loss: 0.00002787
Iteration 96/1000 | Loss: 0.00002787
Iteration 97/1000 | Loss: 0.00002787
Iteration 98/1000 | Loss: 0.00002787
Iteration 99/1000 | Loss: 0.00002787
Iteration 100/1000 | Loss: 0.00002787
Iteration 101/1000 | Loss: 0.00002786
Iteration 102/1000 | Loss: 0.00002786
Iteration 103/1000 | Loss: 0.00002786
Iteration 104/1000 | Loss: 0.00002786
Iteration 105/1000 | Loss: 0.00002786
Iteration 106/1000 | Loss: 0.00002786
Iteration 107/1000 | Loss: 0.00002786
Iteration 108/1000 | Loss: 0.00002786
Iteration 109/1000 | Loss: 0.00002785
Iteration 110/1000 | Loss: 0.00002785
Iteration 111/1000 | Loss: 0.00002785
Iteration 112/1000 | Loss: 0.00002785
Iteration 113/1000 | Loss: 0.00002785
Iteration 114/1000 | Loss: 0.00002785
Iteration 115/1000 | Loss: 0.00002785
Iteration 116/1000 | Loss: 0.00002785
Iteration 117/1000 | Loss: 0.00002785
Iteration 118/1000 | Loss: 0.00002785
Iteration 119/1000 | Loss: 0.00002785
Iteration 120/1000 | Loss: 0.00002785
Iteration 121/1000 | Loss: 0.00002785
Iteration 122/1000 | Loss: 0.00002784
Iteration 123/1000 | Loss: 0.00002784
Iteration 124/1000 | Loss: 0.00002784
Iteration 125/1000 | Loss: 0.00002784
Iteration 126/1000 | Loss: 0.00002784
Iteration 127/1000 | Loss: 0.00002784
Iteration 128/1000 | Loss: 0.00002784
Iteration 129/1000 | Loss: 0.00002784
Iteration 130/1000 | Loss: 0.00002784
Iteration 131/1000 | Loss: 0.00002784
Iteration 132/1000 | Loss: 0.00002784
Iteration 133/1000 | Loss: 0.00002784
Iteration 134/1000 | Loss: 0.00002784
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 134. Stopping optimization.
Last 5 losses: [2.7841522751259618e-05, 2.7841522751259618e-05, 2.7841522751259618e-05, 2.7841522751259618e-05, 2.7841522751259618e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7841522751259618e-05

Optimization complete. Final v2v error: 4.186737060546875 mm

Highest mean error: 5.914881229400635 mm for frame 36

Lowest mean error: 2.846695899963379 mm for frame 0

Saving results

Total time: 53.50689649581909
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01023468
Iteration 2/25 | Loss: 0.00162258
Iteration 3/25 | Loss: 0.00111869
Iteration 4/25 | Loss: 0.00097464
Iteration 5/25 | Loss: 0.00093283
Iteration 6/25 | Loss: 0.00095204
Iteration 7/25 | Loss: 0.00094641
Iteration 8/25 | Loss: 0.00092869
Iteration 9/25 | Loss: 0.00092236
Iteration 10/25 | Loss: 0.00091278
Iteration 11/25 | Loss: 0.00088630
Iteration 12/25 | Loss: 0.00086801
Iteration 13/25 | Loss: 0.00086467
Iteration 14/25 | Loss: 0.00086336
Iteration 15/25 | Loss: 0.00086321
Iteration 16/25 | Loss: 0.00086319
Iteration 17/25 | Loss: 0.00086319
Iteration 18/25 | Loss: 0.00086319
Iteration 19/25 | Loss: 0.00086319
Iteration 20/25 | Loss: 0.00086319
Iteration 21/25 | Loss: 0.00086319
Iteration 22/25 | Loss: 0.00086319
Iteration 23/25 | Loss: 0.00086319
Iteration 24/25 | Loss: 0.00086318
Iteration 25/25 | Loss: 0.00086318

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.75644577
Iteration 2/25 | Loss: 0.00058846
Iteration 3/25 | Loss: 0.00058845
Iteration 4/25 | Loss: 0.00058845
Iteration 5/25 | Loss: 0.00058845
Iteration 6/25 | Loss: 0.00058845
Iteration 7/25 | Loss: 0.00058845
Iteration 8/25 | Loss: 0.00058845
Iteration 9/25 | Loss: 0.00058845
Iteration 10/25 | Loss: 0.00058845
Iteration 11/25 | Loss: 0.00058845
Iteration 12/25 | Loss: 0.00058845
Iteration 13/25 | Loss: 0.00058845
Iteration 14/25 | Loss: 0.00058845
Iteration 15/25 | Loss: 0.00058845
Iteration 16/25 | Loss: 0.00058845
Iteration 17/25 | Loss: 0.00058845
Iteration 18/25 | Loss: 0.00058845
Iteration 19/25 | Loss: 0.00058845
Iteration 20/25 | Loss: 0.00058845
Iteration 21/25 | Loss: 0.00058845
Iteration 22/25 | Loss: 0.00058845
Iteration 23/25 | Loss: 0.00058845
Iteration 24/25 | Loss: 0.00058845
Iteration 25/25 | Loss: 0.00058845
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0005884479614906013, 0.0005884479614906013, 0.0005884479614906013, 0.0005884479614906013, 0.0005884479614906013]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005884479614906013

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00058845
Iteration 2/1000 | Loss: 0.00037814
Iteration 3/1000 | Loss: 0.00031353
Iteration 4/1000 | Loss: 0.00032441
Iteration 5/1000 | Loss: 0.00003268
Iteration 6/1000 | Loss: 0.00002572
Iteration 7/1000 | Loss: 0.00002180
Iteration 8/1000 | Loss: 0.00002040
Iteration 9/1000 | Loss: 0.00001928
Iteration 10/1000 | Loss: 0.00001796
Iteration 11/1000 | Loss: 0.00001704
Iteration 12/1000 | Loss: 0.00001659
Iteration 13/1000 | Loss: 0.00001619
Iteration 14/1000 | Loss: 0.00001576
Iteration 15/1000 | Loss: 0.00001527
Iteration 16/1000 | Loss: 0.00001491
Iteration 17/1000 | Loss: 0.00001450
Iteration 18/1000 | Loss: 0.00001437
Iteration 19/1000 | Loss: 0.00001413
Iteration 20/1000 | Loss: 0.00001405
Iteration 21/1000 | Loss: 0.00001395
Iteration 22/1000 | Loss: 0.00001394
Iteration 23/1000 | Loss: 0.00001393
Iteration 24/1000 | Loss: 0.00001391
Iteration 25/1000 | Loss: 0.00001390
Iteration 26/1000 | Loss: 0.00001389
Iteration 27/1000 | Loss: 0.00001389
Iteration 28/1000 | Loss: 0.00001388
Iteration 29/1000 | Loss: 0.00001387
Iteration 30/1000 | Loss: 0.00001382
Iteration 31/1000 | Loss: 0.00001381
Iteration 32/1000 | Loss: 0.00001381
Iteration 33/1000 | Loss: 0.00001381
Iteration 34/1000 | Loss: 0.00001381
Iteration 35/1000 | Loss: 0.00001380
Iteration 36/1000 | Loss: 0.00001379
Iteration 37/1000 | Loss: 0.00001379
Iteration 38/1000 | Loss: 0.00001379
Iteration 39/1000 | Loss: 0.00001378
Iteration 40/1000 | Loss: 0.00001378
Iteration 41/1000 | Loss: 0.00001377
Iteration 42/1000 | Loss: 0.00001377
Iteration 43/1000 | Loss: 0.00001376
Iteration 44/1000 | Loss: 0.00001376
Iteration 45/1000 | Loss: 0.00001376
Iteration 46/1000 | Loss: 0.00001375
Iteration 47/1000 | Loss: 0.00001375
Iteration 48/1000 | Loss: 0.00001375
Iteration 49/1000 | Loss: 0.00001375
Iteration 50/1000 | Loss: 0.00001374
Iteration 51/1000 | Loss: 0.00001374
Iteration 52/1000 | Loss: 0.00001373
Iteration 53/1000 | Loss: 0.00001373
Iteration 54/1000 | Loss: 0.00001373
Iteration 55/1000 | Loss: 0.00001373
Iteration 56/1000 | Loss: 0.00001373
Iteration 57/1000 | Loss: 0.00001373
Iteration 58/1000 | Loss: 0.00001373
Iteration 59/1000 | Loss: 0.00001373
Iteration 60/1000 | Loss: 0.00001373
Iteration 61/1000 | Loss: 0.00001372
Iteration 62/1000 | Loss: 0.00001372
Iteration 63/1000 | Loss: 0.00001372
Iteration 64/1000 | Loss: 0.00001372
Iteration 65/1000 | Loss: 0.00001372
Iteration 66/1000 | Loss: 0.00001371
Iteration 67/1000 | Loss: 0.00001371
Iteration 68/1000 | Loss: 0.00001371
Iteration 69/1000 | Loss: 0.00001371
Iteration 70/1000 | Loss: 0.00001371
Iteration 71/1000 | Loss: 0.00001371
Iteration 72/1000 | Loss: 0.00001370
Iteration 73/1000 | Loss: 0.00001370
Iteration 74/1000 | Loss: 0.00001370
Iteration 75/1000 | Loss: 0.00001370
Iteration 76/1000 | Loss: 0.00001370
Iteration 77/1000 | Loss: 0.00001370
Iteration 78/1000 | Loss: 0.00001369
Iteration 79/1000 | Loss: 0.00001369
Iteration 80/1000 | Loss: 0.00001369
Iteration 81/1000 | Loss: 0.00001369
Iteration 82/1000 | Loss: 0.00001369
Iteration 83/1000 | Loss: 0.00001369
Iteration 84/1000 | Loss: 0.00001369
Iteration 85/1000 | Loss: 0.00001369
Iteration 86/1000 | Loss: 0.00001369
Iteration 87/1000 | Loss: 0.00001368
Iteration 88/1000 | Loss: 0.00001368
Iteration 89/1000 | Loss: 0.00001368
Iteration 90/1000 | Loss: 0.00001368
Iteration 91/1000 | Loss: 0.00001368
Iteration 92/1000 | Loss: 0.00001368
Iteration 93/1000 | Loss: 0.00001368
Iteration 94/1000 | Loss: 0.00001368
Iteration 95/1000 | Loss: 0.00001368
Iteration 96/1000 | Loss: 0.00001368
Iteration 97/1000 | Loss: 0.00001368
Iteration 98/1000 | Loss: 0.00001368
Iteration 99/1000 | Loss: 0.00001368
Iteration 100/1000 | Loss: 0.00001367
Iteration 101/1000 | Loss: 0.00001367
Iteration 102/1000 | Loss: 0.00001367
Iteration 103/1000 | Loss: 0.00001367
Iteration 104/1000 | Loss: 0.00001367
Iteration 105/1000 | Loss: 0.00001367
Iteration 106/1000 | Loss: 0.00001367
Iteration 107/1000 | Loss: 0.00001367
Iteration 108/1000 | Loss: 0.00001367
Iteration 109/1000 | Loss: 0.00001367
Iteration 110/1000 | Loss: 0.00001367
Iteration 111/1000 | Loss: 0.00001367
Iteration 112/1000 | Loss: 0.00001367
Iteration 113/1000 | Loss: 0.00001367
Iteration 114/1000 | Loss: 0.00001367
Iteration 115/1000 | Loss: 0.00001367
Iteration 116/1000 | Loss: 0.00001366
Iteration 117/1000 | Loss: 0.00001366
Iteration 118/1000 | Loss: 0.00001366
Iteration 119/1000 | Loss: 0.00001366
Iteration 120/1000 | Loss: 0.00001366
Iteration 121/1000 | Loss: 0.00001366
Iteration 122/1000 | Loss: 0.00001366
Iteration 123/1000 | Loss: 0.00001366
Iteration 124/1000 | Loss: 0.00001366
Iteration 125/1000 | Loss: 0.00001366
Iteration 126/1000 | Loss: 0.00001366
Iteration 127/1000 | Loss: 0.00001365
Iteration 128/1000 | Loss: 0.00001365
Iteration 129/1000 | Loss: 0.00001365
Iteration 130/1000 | Loss: 0.00001365
Iteration 131/1000 | Loss: 0.00001365
Iteration 132/1000 | Loss: 0.00001365
Iteration 133/1000 | Loss: 0.00001365
Iteration 134/1000 | Loss: 0.00001365
Iteration 135/1000 | Loss: 0.00001365
Iteration 136/1000 | Loss: 0.00001365
Iteration 137/1000 | Loss: 0.00001365
Iteration 138/1000 | Loss: 0.00001365
Iteration 139/1000 | Loss: 0.00001365
Iteration 140/1000 | Loss: 0.00001364
Iteration 141/1000 | Loss: 0.00001364
Iteration 142/1000 | Loss: 0.00001364
Iteration 143/1000 | Loss: 0.00001364
Iteration 144/1000 | Loss: 0.00001364
Iteration 145/1000 | Loss: 0.00001364
Iteration 146/1000 | Loss: 0.00001364
Iteration 147/1000 | Loss: 0.00001364
Iteration 148/1000 | Loss: 0.00001364
Iteration 149/1000 | Loss: 0.00001364
Iteration 150/1000 | Loss: 0.00001364
Iteration 151/1000 | Loss: 0.00001363
Iteration 152/1000 | Loss: 0.00001363
Iteration 153/1000 | Loss: 0.00001363
Iteration 154/1000 | Loss: 0.00001363
Iteration 155/1000 | Loss: 0.00001363
Iteration 156/1000 | Loss: 0.00001363
Iteration 157/1000 | Loss: 0.00001363
Iteration 158/1000 | Loss: 0.00001363
Iteration 159/1000 | Loss: 0.00001363
Iteration 160/1000 | Loss: 0.00001363
Iteration 161/1000 | Loss: 0.00001363
Iteration 162/1000 | Loss: 0.00001363
Iteration 163/1000 | Loss: 0.00001363
Iteration 164/1000 | Loss: 0.00001363
Iteration 165/1000 | Loss: 0.00001363
Iteration 166/1000 | Loss: 0.00001363
Iteration 167/1000 | Loss: 0.00001363
Iteration 168/1000 | Loss: 0.00001363
Iteration 169/1000 | Loss: 0.00001363
Iteration 170/1000 | Loss: 0.00001362
Iteration 171/1000 | Loss: 0.00001362
Iteration 172/1000 | Loss: 0.00001362
Iteration 173/1000 | Loss: 0.00001362
Iteration 174/1000 | Loss: 0.00001362
Iteration 175/1000 | Loss: 0.00001362
Iteration 176/1000 | Loss: 0.00001362
Iteration 177/1000 | Loss: 0.00001362
Iteration 178/1000 | Loss: 0.00001362
Iteration 179/1000 | Loss: 0.00001362
Iteration 180/1000 | Loss: 0.00001362
Iteration 181/1000 | Loss: 0.00001362
Iteration 182/1000 | Loss: 0.00001362
Iteration 183/1000 | Loss: 0.00001362
Iteration 184/1000 | Loss: 0.00001362
Iteration 185/1000 | Loss: 0.00001362
Iteration 186/1000 | Loss: 0.00001362
Iteration 187/1000 | Loss: 0.00001362
Iteration 188/1000 | Loss: 0.00001362
Iteration 189/1000 | Loss: 0.00001362
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 189. Stopping optimization.
Last 5 losses: [1.3618085176858585e-05, 1.3618085176858585e-05, 1.3618085176858585e-05, 1.3618085176858585e-05, 1.3618085176858585e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3618085176858585e-05

Optimization complete. Final v2v error: 2.8725621700286865 mm

Highest mean error: 4.833492279052734 mm for frame 84

Lowest mean error: 2.289418935775757 mm for frame 130

Saving results

Total time: 65.00944972038269
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01017083
Iteration 2/25 | Loss: 0.00243662
Iteration 3/25 | Loss: 0.00135393
Iteration 4/25 | Loss: 0.00120273
Iteration 5/25 | Loss: 0.00115226
Iteration 6/25 | Loss: 0.00111807
Iteration 7/25 | Loss: 0.00112827
Iteration 8/25 | Loss: 0.00109530
Iteration 9/25 | Loss: 0.00102414
Iteration 10/25 | Loss: 0.00097864
Iteration 11/25 | Loss: 0.00089826
Iteration 12/25 | Loss: 0.00081037
Iteration 13/25 | Loss: 0.00079738
Iteration 14/25 | Loss: 0.00079319
Iteration 15/25 | Loss: 0.00079224
Iteration 16/25 | Loss: 0.00079203
Iteration 17/25 | Loss: 0.00079200
Iteration 18/25 | Loss: 0.00079199
Iteration 19/25 | Loss: 0.00079199
Iteration 20/25 | Loss: 0.00079199
Iteration 21/25 | Loss: 0.00079199
Iteration 22/25 | Loss: 0.00079199
Iteration 23/25 | Loss: 0.00079199
Iteration 24/25 | Loss: 0.00079199
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.0007919924682937562, 0.0007919924682937562, 0.0007919924682937562, 0.0007919924682937562, 0.0007919924682937562]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007919924682937562

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55716813
Iteration 2/25 | Loss: 0.00068816
Iteration 3/25 | Loss: 0.00068029
Iteration 4/25 | Loss: 0.00068029
Iteration 5/25 | Loss: 0.00068029
Iteration 6/25 | Loss: 0.00068029
Iteration 7/25 | Loss: 0.00068029
Iteration 8/25 | Loss: 0.00068029
Iteration 9/25 | Loss: 0.00068029
Iteration 10/25 | Loss: 0.00068028
Iteration 11/25 | Loss: 0.00068028
Iteration 12/25 | Loss: 0.00068028
Iteration 13/25 | Loss: 0.00068028
Iteration 14/25 | Loss: 0.00068028
Iteration 15/25 | Loss: 0.00068028
Iteration 16/25 | Loss: 0.00068028
Iteration 17/25 | Loss: 0.00068028
Iteration 18/25 | Loss: 0.00068028
Iteration 19/25 | Loss: 0.00068028
Iteration 20/25 | Loss: 0.00068028
Iteration 21/25 | Loss: 0.00068028
Iteration 22/25 | Loss: 0.00068028
Iteration 23/25 | Loss: 0.00068028
Iteration 24/25 | Loss: 0.00068028
Iteration 25/25 | Loss: 0.00068028

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00068028
Iteration 2/1000 | Loss: 0.00004778
Iteration 3/1000 | Loss: 0.00002833
Iteration 4/1000 | Loss: 0.00001944
Iteration 5/1000 | Loss: 0.00001670
Iteration 6/1000 | Loss: 0.00001568
Iteration 7/1000 | Loss: 0.00001496
Iteration 8/1000 | Loss: 0.00001445
Iteration 9/1000 | Loss: 0.00001407
Iteration 10/1000 | Loss: 0.00001384
Iteration 11/1000 | Loss: 0.00001378
Iteration 12/1000 | Loss: 0.00001358
Iteration 13/1000 | Loss: 0.00001353
Iteration 14/1000 | Loss: 0.00001348
Iteration 15/1000 | Loss: 0.00001340
Iteration 16/1000 | Loss: 0.00001328
Iteration 17/1000 | Loss: 0.00001324
Iteration 18/1000 | Loss: 0.00001319
Iteration 19/1000 | Loss: 0.00001317
Iteration 20/1000 | Loss: 0.00001317
Iteration 21/1000 | Loss: 0.00001316
Iteration 22/1000 | Loss: 0.00001315
Iteration 23/1000 | Loss: 0.00001315
Iteration 24/1000 | Loss: 0.00001314
Iteration 25/1000 | Loss: 0.00001314
Iteration 26/1000 | Loss: 0.00001313
Iteration 27/1000 | Loss: 0.00001313
Iteration 28/1000 | Loss: 0.00001312
Iteration 29/1000 | Loss: 0.00001311
Iteration 30/1000 | Loss: 0.00001311
Iteration 31/1000 | Loss: 0.00001310
Iteration 32/1000 | Loss: 0.00001310
Iteration 33/1000 | Loss: 0.00001310
Iteration 34/1000 | Loss: 0.00001309
Iteration 35/1000 | Loss: 0.00001308
Iteration 36/1000 | Loss: 0.00001308
Iteration 37/1000 | Loss: 0.00001308
Iteration 38/1000 | Loss: 0.00070699
Iteration 39/1000 | Loss: 0.00078806
Iteration 40/1000 | Loss: 0.00029078
Iteration 41/1000 | Loss: 0.00108652
Iteration 42/1000 | Loss: 0.00050254
Iteration 43/1000 | Loss: 0.00009252
Iteration 44/1000 | Loss: 0.00001828
Iteration 45/1000 | Loss: 0.00001536
Iteration 46/1000 | Loss: 0.00001195
Iteration 47/1000 | Loss: 0.00001066
Iteration 48/1000 | Loss: 0.00016872
Iteration 49/1000 | Loss: 0.00001109
Iteration 50/1000 | Loss: 0.00001011
Iteration 51/1000 | Loss: 0.00000972
Iteration 52/1000 | Loss: 0.00000955
Iteration 53/1000 | Loss: 0.00000952
Iteration 54/1000 | Loss: 0.00000951
Iteration 55/1000 | Loss: 0.00000947
Iteration 56/1000 | Loss: 0.00000942
Iteration 57/1000 | Loss: 0.00000938
Iteration 58/1000 | Loss: 0.00000937
Iteration 59/1000 | Loss: 0.00000933
Iteration 60/1000 | Loss: 0.00000932
Iteration 61/1000 | Loss: 0.00000932
Iteration 62/1000 | Loss: 0.00000931
Iteration 63/1000 | Loss: 0.00000931
Iteration 64/1000 | Loss: 0.00000930
Iteration 65/1000 | Loss: 0.00000927
Iteration 66/1000 | Loss: 0.00000927
Iteration 67/1000 | Loss: 0.00000927
Iteration 68/1000 | Loss: 0.00000927
Iteration 69/1000 | Loss: 0.00000927
Iteration 70/1000 | Loss: 0.00000927
Iteration 71/1000 | Loss: 0.00000926
Iteration 72/1000 | Loss: 0.00000926
Iteration 73/1000 | Loss: 0.00000926
Iteration 74/1000 | Loss: 0.00000926
Iteration 75/1000 | Loss: 0.00000926
Iteration 76/1000 | Loss: 0.00000926
Iteration 77/1000 | Loss: 0.00000926
Iteration 78/1000 | Loss: 0.00000926
Iteration 79/1000 | Loss: 0.00000926
Iteration 80/1000 | Loss: 0.00000926
Iteration 81/1000 | Loss: 0.00000926
Iteration 82/1000 | Loss: 0.00000926
Iteration 83/1000 | Loss: 0.00000925
Iteration 84/1000 | Loss: 0.00000924
Iteration 85/1000 | Loss: 0.00000924
Iteration 86/1000 | Loss: 0.00000924
Iteration 87/1000 | Loss: 0.00000924
Iteration 88/1000 | Loss: 0.00000924
Iteration 89/1000 | Loss: 0.00000924
Iteration 90/1000 | Loss: 0.00000924
Iteration 91/1000 | Loss: 0.00000924
Iteration 92/1000 | Loss: 0.00000924
Iteration 93/1000 | Loss: 0.00000924
Iteration 94/1000 | Loss: 0.00000923
Iteration 95/1000 | Loss: 0.00000923
Iteration 96/1000 | Loss: 0.00000923
Iteration 97/1000 | Loss: 0.00000923
Iteration 98/1000 | Loss: 0.00000923
Iteration 99/1000 | Loss: 0.00000923
Iteration 100/1000 | Loss: 0.00000923
Iteration 101/1000 | Loss: 0.00000923
Iteration 102/1000 | Loss: 0.00000923
Iteration 103/1000 | Loss: 0.00000923
Iteration 104/1000 | Loss: 0.00000922
Iteration 105/1000 | Loss: 0.00000922
Iteration 106/1000 | Loss: 0.00000921
Iteration 107/1000 | Loss: 0.00000921
Iteration 108/1000 | Loss: 0.00000921
Iteration 109/1000 | Loss: 0.00000921
Iteration 110/1000 | Loss: 0.00000921
Iteration 111/1000 | Loss: 0.00000921
Iteration 112/1000 | Loss: 0.00000921
Iteration 113/1000 | Loss: 0.00000920
Iteration 114/1000 | Loss: 0.00000920
Iteration 115/1000 | Loss: 0.00000920
Iteration 116/1000 | Loss: 0.00000920
Iteration 117/1000 | Loss: 0.00000920
Iteration 118/1000 | Loss: 0.00000920
Iteration 119/1000 | Loss: 0.00000920
Iteration 120/1000 | Loss: 0.00000920
Iteration 121/1000 | Loss: 0.00000920
Iteration 122/1000 | Loss: 0.00000919
Iteration 123/1000 | Loss: 0.00000919
Iteration 124/1000 | Loss: 0.00000919
Iteration 125/1000 | Loss: 0.00000919
Iteration 126/1000 | Loss: 0.00000919
Iteration 127/1000 | Loss: 0.00000919
Iteration 128/1000 | Loss: 0.00000919
Iteration 129/1000 | Loss: 0.00000919
Iteration 130/1000 | Loss: 0.00000919
Iteration 131/1000 | Loss: 0.00000919
Iteration 132/1000 | Loss: 0.00000919
Iteration 133/1000 | Loss: 0.00000919
Iteration 134/1000 | Loss: 0.00000919
Iteration 135/1000 | Loss: 0.00000919
Iteration 136/1000 | Loss: 0.00000919
Iteration 137/1000 | Loss: 0.00000919
Iteration 138/1000 | Loss: 0.00000919
Iteration 139/1000 | Loss: 0.00000919
Iteration 140/1000 | Loss: 0.00000919
Iteration 141/1000 | Loss: 0.00000919
Iteration 142/1000 | Loss: 0.00000919
Iteration 143/1000 | Loss: 0.00000919
Iteration 144/1000 | Loss: 0.00000919
Iteration 145/1000 | Loss: 0.00000919
Iteration 146/1000 | Loss: 0.00000919
Iteration 147/1000 | Loss: 0.00000919
Iteration 148/1000 | Loss: 0.00000919
Iteration 149/1000 | Loss: 0.00000919
Iteration 150/1000 | Loss: 0.00000919
Iteration 151/1000 | Loss: 0.00000919
Iteration 152/1000 | Loss: 0.00000919
Iteration 153/1000 | Loss: 0.00000919
Iteration 154/1000 | Loss: 0.00000919
Iteration 155/1000 | Loss: 0.00000919
Iteration 156/1000 | Loss: 0.00000919
Iteration 157/1000 | Loss: 0.00000919
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 157. Stopping optimization.
Last 5 losses: [9.18648856895743e-06, 9.18648856895743e-06, 9.18648856895743e-06, 9.18648856895743e-06, 9.18648856895743e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.18648856895743e-06

Optimization complete. Final v2v error: 2.523141622543335 mm

Highest mean error: 4.071511268615723 mm for frame 81

Lowest mean error: 1.9624072313308716 mm for frame 131

Saving results

Total time: 78.06517028808594
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00422285
Iteration 2/25 | Loss: 0.00090710
Iteration 3/25 | Loss: 0.00082663
Iteration 4/25 | Loss: 0.00081923
Iteration 5/25 | Loss: 0.00081677
Iteration 6/25 | Loss: 0.00081664
Iteration 7/25 | Loss: 0.00081664
Iteration 8/25 | Loss: 0.00081664
Iteration 9/25 | Loss: 0.00081664
Iteration 10/25 | Loss: 0.00081664
Iteration 11/25 | Loss: 0.00081664
Iteration 12/25 | Loss: 0.00081664
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008166449260897934, 0.0008166449260897934, 0.0008166449260897934, 0.0008166449260897934, 0.0008166449260897934]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008166449260897934

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47125113
Iteration 2/25 | Loss: 0.00068893
Iteration 3/25 | Loss: 0.00068893
Iteration 4/25 | Loss: 0.00068893
Iteration 5/25 | Loss: 0.00068893
Iteration 6/25 | Loss: 0.00068893
Iteration 7/25 | Loss: 0.00068893
Iteration 8/25 | Loss: 0.00068893
Iteration 9/25 | Loss: 0.00068893
Iteration 10/25 | Loss: 0.00068893
Iteration 11/25 | Loss: 0.00068893
Iteration 12/25 | Loss: 0.00068893
Iteration 13/25 | Loss: 0.00068893
Iteration 14/25 | Loss: 0.00068893
Iteration 15/25 | Loss: 0.00068893
Iteration 16/25 | Loss: 0.00068893
Iteration 17/25 | Loss: 0.00068893
Iteration 18/25 | Loss: 0.00068893
Iteration 19/25 | Loss: 0.00068893
Iteration 20/25 | Loss: 0.00068893
Iteration 21/25 | Loss: 0.00068893
Iteration 22/25 | Loss: 0.00068893
Iteration 23/25 | Loss: 0.00068893
Iteration 24/25 | Loss: 0.00068893
Iteration 25/25 | Loss: 0.00068893

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00068893
Iteration 2/1000 | Loss: 0.00001988
Iteration 3/1000 | Loss: 0.00001294
Iteration 4/1000 | Loss: 0.00001157
Iteration 5/1000 | Loss: 0.00001102
Iteration 6/1000 | Loss: 0.00001046
Iteration 7/1000 | Loss: 0.00001012
Iteration 8/1000 | Loss: 0.00000998
Iteration 9/1000 | Loss: 0.00000996
Iteration 10/1000 | Loss: 0.00000992
Iteration 11/1000 | Loss: 0.00000991
Iteration 12/1000 | Loss: 0.00000986
Iteration 13/1000 | Loss: 0.00000979
Iteration 14/1000 | Loss: 0.00000978
Iteration 15/1000 | Loss: 0.00000977
Iteration 16/1000 | Loss: 0.00000975
Iteration 17/1000 | Loss: 0.00000975
Iteration 18/1000 | Loss: 0.00000974
Iteration 19/1000 | Loss: 0.00000974
Iteration 20/1000 | Loss: 0.00000974
Iteration 21/1000 | Loss: 0.00000973
Iteration 22/1000 | Loss: 0.00000972
Iteration 23/1000 | Loss: 0.00000965
Iteration 24/1000 | Loss: 0.00000964
Iteration 25/1000 | Loss: 0.00000963
Iteration 26/1000 | Loss: 0.00000963
Iteration 27/1000 | Loss: 0.00000962
Iteration 28/1000 | Loss: 0.00000962
Iteration 29/1000 | Loss: 0.00000962
Iteration 30/1000 | Loss: 0.00000962
Iteration 31/1000 | Loss: 0.00000962
Iteration 32/1000 | Loss: 0.00000962
Iteration 33/1000 | Loss: 0.00000962
Iteration 34/1000 | Loss: 0.00000962
Iteration 35/1000 | Loss: 0.00000962
Iteration 36/1000 | Loss: 0.00000962
Iteration 37/1000 | Loss: 0.00000962
Iteration 38/1000 | Loss: 0.00000961
Iteration 39/1000 | Loss: 0.00000961
Iteration 40/1000 | Loss: 0.00000961
Iteration 41/1000 | Loss: 0.00000960
Iteration 42/1000 | Loss: 0.00000960
Iteration 43/1000 | Loss: 0.00000959
Iteration 44/1000 | Loss: 0.00000958
Iteration 45/1000 | Loss: 0.00000958
Iteration 46/1000 | Loss: 0.00000958
Iteration 47/1000 | Loss: 0.00000957
Iteration 48/1000 | Loss: 0.00000957
Iteration 49/1000 | Loss: 0.00000957
Iteration 50/1000 | Loss: 0.00000957
Iteration 51/1000 | Loss: 0.00000957
Iteration 52/1000 | Loss: 0.00000956
Iteration 53/1000 | Loss: 0.00000956
Iteration 54/1000 | Loss: 0.00000956
Iteration 55/1000 | Loss: 0.00000956
Iteration 56/1000 | Loss: 0.00000956
Iteration 57/1000 | Loss: 0.00000956
Iteration 58/1000 | Loss: 0.00000955
Iteration 59/1000 | Loss: 0.00000955
Iteration 60/1000 | Loss: 0.00000955
Iteration 61/1000 | Loss: 0.00000954
Iteration 62/1000 | Loss: 0.00000954
Iteration 63/1000 | Loss: 0.00000954
Iteration 64/1000 | Loss: 0.00000953
Iteration 65/1000 | Loss: 0.00000953
Iteration 66/1000 | Loss: 0.00000953
Iteration 67/1000 | Loss: 0.00000953
Iteration 68/1000 | Loss: 0.00000953
Iteration 69/1000 | Loss: 0.00000952
Iteration 70/1000 | Loss: 0.00000952
Iteration 71/1000 | Loss: 0.00000952
Iteration 72/1000 | Loss: 0.00000952
Iteration 73/1000 | Loss: 0.00000952
Iteration 74/1000 | Loss: 0.00000952
Iteration 75/1000 | Loss: 0.00000951
Iteration 76/1000 | Loss: 0.00000951
Iteration 77/1000 | Loss: 0.00000951
Iteration 78/1000 | Loss: 0.00000951
Iteration 79/1000 | Loss: 0.00000951
Iteration 80/1000 | Loss: 0.00000951
Iteration 81/1000 | Loss: 0.00000951
Iteration 82/1000 | Loss: 0.00000951
Iteration 83/1000 | Loss: 0.00000950
Iteration 84/1000 | Loss: 0.00000950
Iteration 85/1000 | Loss: 0.00000950
Iteration 86/1000 | Loss: 0.00000950
Iteration 87/1000 | Loss: 0.00000950
Iteration 88/1000 | Loss: 0.00000950
Iteration 89/1000 | Loss: 0.00000950
Iteration 90/1000 | Loss: 0.00000950
Iteration 91/1000 | Loss: 0.00000950
Iteration 92/1000 | Loss: 0.00000950
Iteration 93/1000 | Loss: 0.00000950
Iteration 94/1000 | Loss: 0.00000950
Iteration 95/1000 | Loss: 0.00000950
Iteration 96/1000 | Loss: 0.00000949
Iteration 97/1000 | Loss: 0.00000949
Iteration 98/1000 | Loss: 0.00000949
Iteration 99/1000 | Loss: 0.00000949
Iteration 100/1000 | Loss: 0.00000949
Iteration 101/1000 | Loss: 0.00000949
Iteration 102/1000 | Loss: 0.00000949
Iteration 103/1000 | Loss: 0.00000948
Iteration 104/1000 | Loss: 0.00000948
Iteration 105/1000 | Loss: 0.00000948
Iteration 106/1000 | Loss: 0.00000948
Iteration 107/1000 | Loss: 0.00000948
Iteration 108/1000 | Loss: 0.00000948
Iteration 109/1000 | Loss: 0.00000948
Iteration 110/1000 | Loss: 0.00000948
Iteration 111/1000 | Loss: 0.00000948
Iteration 112/1000 | Loss: 0.00000948
Iteration 113/1000 | Loss: 0.00000948
Iteration 114/1000 | Loss: 0.00000948
Iteration 115/1000 | Loss: 0.00000948
Iteration 116/1000 | Loss: 0.00000948
Iteration 117/1000 | Loss: 0.00000948
Iteration 118/1000 | Loss: 0.00000948
Iteration 119/1000 | Loss: 0.00000948
Iteration 120/1000 | Loss: 0.00000948
Iteration 121/1000 | Loss: 0.00000947
Iteration 122/1000 | Loss: 0.00000947
Iteration 123/1000 | Loss: 0.00000947
Iteration 124/1000 | Loss: 0.00000947
Iteration 125/1000 | Loss: 0.00000947
Iteration 126/1000 | Loss: 0.00000947
Iteration 127/1000 | Loss: 0.00000947
Iteration 128/1000 | Loss: 0.00000947
Iteration 129/1000 | Loss: 0.00000947
Iteration 130/1000 | Loss: 0.00000947
Iteration 131/1000 | Loss: 0.00000947
Iteration 132/1000 | Loss: 0.00000946
Iteration 133/1000 | Loss: 0.00000946
Iteration 134/1000 | Loss: 0.00000946
Iteration 135/1000 | Loss: 0.00000946
Iteration 136/1000 | Loss: 0.00000946
Iteration 137/1000 | Loss: 0.00000946
Iteration 138/1000 | Loss: 0.00000946
Iteration 139/1000 | Loss: 0.00000946
Iteration 140/1000 | Loss: 0.00000946
Iteration 141/1000 | Loss: 0.00000946
Iteration 142/1000 | Loss: 0.00000946
Iteration 143/1000 | Loss: 0.00000946
Iteration 144/1000 | Loss: 0.00000946
Iteration 145/1000 | Loss: 0.00000946
Iteration 146/1000 | Loss: 0.00000946
Iteration 147/1000 | Loss: 0.00000946
Iteration 148/1000 | Loss: 0.00000946
Iteration 149/1000 | Loss: 0.00000945
Iteration 150/1000 | Loss: 0.00000945
Iteration 151/1000 | Loss: 0.00000945
Iteration 152/1000 | Loss: 0.00000945
Iteration 153/1000 | Loss: 0.00000945
Iteration 154/1000 | Loss: 0.00000945
Iteration 155/1000 | Loss: 0.00000945
Iteration 156/1000 | Loss: 0.00000945
Iteration 157/1000 | Loss: 0.00000945
Iteration 158/1000 | Loss: 0.00000945
Iteration 159/1000 | Loss: 0.00000945
Iteration 160/1000 | Loss: 0.00000945
Iteration 161/1000 | Loss: 0.00000945
Iteration 162/1000 | Loss: 0.00000944
Iteration 163/1000 | Loss: 0.00000944
Iteration 164/1000 | Loss: 0.00000944
Iteration 165/1000 | Loss: 0.00000944
Iteration 166/1000 | Loss: 0.00000944
Iteration 167/1000 | Loss: 0.00000944
Iteration 168/1000 | Loss: 0.00000944
Iteration 169/1000 | Loss: 0.00000944
Iteration 170/1000 | Loss: 0.00000944
Iteration 171/1000 | Loss: 0.00000944
Iteration 172/1000 | Loss: 0.00000944
Iteration 173/1000 | Loss: 0.00000944
Iteration 174/1000 | Loss: 0.00000944
Iteration 175/1000 | Loss: 0.00000944
Iteration 176/1000 | Loss: 0.00000944
Iteration 177/1000 | Loss: 0.00000944
Iteration 178/1000 | Loss: 0.00000943
Iteration 179/1000 | Loss: 0.00000943
Iteration 180/1000 | Loss: 0.00000943
Iteration 181/1000 | Loss: 0.00000943
Iteration 182/1000 | Loss: 0.00000943
Iteration 183/1000 | Loss: 0.00000943
Iteration 184/1000 | Loss: 0.00000943
Iteration 185/1000 | Loss: 0.00000943
Iteration 186/1000 | Loss: 0.00000942
Iteration 187/1000 | Loss: 0.00000942
Iteration 188/1000 | Loss: 0.00000942
Iteration 189/1000 | Loss: 0.00000942
Iteration 190/1000 | Loss: 0.00000942
Iteration 191/1000 | Loss: 0.00000942
Iteration 192/1000 | Loss: 0.00000942
Iteration 193/1000 | Loss: 0.00000942
Iteration 194/1000 | Loss: 0.00000942
Iteration 195/1000 | Loss: 0.00000942
Iteration 196/1000 | Loss: 0.00000942
Iteration 197/1000 | Loss: 0.00000942
Iteration 198/1000 | Loss: 0.00000942
Iteration 199/1000 | Loss: 0.00000942
Iteration 200/1000 | Loss: 0.00000942
Iteration 201/1000 | Loss: 0.00000942
Iteration 202/1000 | Loss: 0.00000942
Iteration 203/1000 | Loss: 0.00000942
Iteration 204/1000 | Loss: 0.00000942
Iteration 205/1000 | Loss: 0.00000942
Iteration 206/1000 | Loss: 0.00000942
Iteration 207/1000 | Loss: 0.00000942
Iteration 208/1000 | Loss: 0.00000942
Iteration 209/1000 | Loss: 0.00000942
Iteration 210/1000 | Loss: 0.00000942
Iteration 211/1000 | Loss: 0.00000942
Iteration 212/1000 | Loss: 0.00000942
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 212. Stopping optimization.
Last 5 losses: [9.421664799447171e-06, 9.421664799447171e-06, 9.421664799447171e-06, 9.421664799447171e-06, 9.421664799447171e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.421664799447171e-06

Optimization complete. Final v2v error: 2.6629245281219482 mm

Highest mean error: 2.8987107276916504 mm for frame 84

Lowest mean error: 2.4172048568725586 mm for frame 6

Saving results

Total time: 38.40311074256897
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00950745
Iteration 2/25 | Loss: 0.00206382
Iteration 3/25 | Loss: 0.00128761
Iteration 4/25 | Loss: 0.00118643
Iteration 5/25 | Loss: 0.00114024
Iteration 6/25 | Loss: 0.00115508
Iteration 7/25 | Loss: 0.00114239
Iteration 8/25 | Loss: 0.00112355
Iteration 9/25 | Loss: 0.00111375
Iteration 10/25 | Loss: 0.00112523
Iteration 11/25 | Loss: 0.00111312
Iteration 12/25 | Loss: 0.00110897
Iteration 13/25 | Loss: 0.00110300
Iteration 14/25 | Loss: 0.00110190
Iteration 15/25 | Loss: 0.00109599
Iteration 16/25 | Loss: 0.00109970
Iteration 17/25 | Loss: 0.00110437
Iteration 18/25 | Loss: 0.00109122
Iteration 19/25 | Loss: 0.00109298
Iteration 20/25 | Loss: 0.00109080
Iteration 21/25 | Loss: 0.00109424
Iteration 22/25 | Loss: 0.00109319
Iteration 23/25 | Loss: 0.00109370
Iteration 24/25 | Loss: 0.00109147
Iteration 25/25 | Loss: 0.00109359

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.41024828
Iteration 2/25 | Loss: 0.00249158
Iteration 3/25 | Loss: 0.00249158
Iteration 4/25 | Loss: 0.00249158
Iteration 5/25 | Loss: 0.00249158
Iteration 6/25 | Loss: 0.00249158
Iteration 7/25 | Loss: 0.00249158
Iteration 8/25 | Loss: 0.00249158
Iteration 9/25 | Loss: 0.00249158
Iteration 10/25 | Loss: 0.00249158
Iteration 11/25 | Loss: 0.00249158
Iteration 12/25 | Loss: 0.00249158
Iteration 13/25 | Loss: 0.00249158
Iteration 14/25 | Loss: 0.00249158
Iteration 15/25 | Loss: 0.00249158
Iteration 16/25 | Loss: 0.00249158
Iteration 17/25 | Loss: 0.00249158
Iteration 18/25 | Loss: 0.00249158
Iteration 19/25 | Loss: 0.00249158
Iteration 20/25 | Loss: 0.00249158
Iteration 21/25 | Loss: 0.00249158
Iteration 22/25 | Loss: 0.00249158
Iteration 23/25 | Loss: 0.00249158
Iteration 24/25 | Loss: 0.00249158
Iteration 25/25 | Loss: 0.00249158

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00249158
Iteration 2/1000 | Loss: 0.00047832
Iteration 3/1000 | Loss: 0.00056501
Iteration 4/1000 | Loss: 0.00285674
Iteration 5/1000 | Loss: 0.00118563
Iteration 6/1000 | Loss: 0.00097381
Iteration 7/1000 | Loss: 0.00210665
Iteration 8/1000 | Loss: 0.00013299
Iteration 9/1000 | Loss: 0.00008769
Iteration 10/1000 | Loss: 0.00006636
Iteration 11/1000 | Loss: 0.00093395
Iteration 12/1000 | Loss: 0.00017902
Iteration 13/1000 | Loss: 0.00005252
Iteration 14/1000 | Loss: 0.00004349
Iteration 15/1000 | Loss: 0.00003856
Iteration 16/1000 | Loss: 0.00003472
Iteration 17/1000 | Loss: 0.00018141
Iteration 18/1000 | Loss: 0.00005713
Iteration 19/1000 | Loss: 0.00015436
Iteration 20/1000 | Loss: 0.00007959
Iteration 21/1000 | Loss: 0.00021259
Iteration 22/1000 | Loss: 0.00017473
Iteration 23/1000 | Loss: 0.00003137
Iteration 24/1000 | Loss: 0.00002955
Iteration 25/1000 | Loss: 0.00002812
Iteration 26/1000 | Loss: 0.00004031
Iteration 27/1000 | Loss: 0.00003669
Iteration 28/1000 | Loss: 0.00003935
Iteration 29/1000 | Loss: 0.00010223
Iteration 30/1000 | Loss: 0.00151912
Iteration 31/1000 | Loss: 0.00034653
Iteration 32/1000 | Loss: 0.00032245
Iteration 33/1000 | Loss: 0.00018263
Iteration 34/1000 | Loss: 0.00007135
Iteration 35/1000 | Loss: 0.00017747
Iteration 36/1000 | Loss: 0.00003296
Iteration 37/1000 | Loss: 0.00003081
Iteration 38/1000 | Loss: 0.00002794
Iteration 39/1000 | Loss: 0.00002695
Iteration 40/1000 | Loss: 0.00002640
Iteration 41/1000 | Loss: 0.00078204
Iteration 42/1000 | Loss: 0.00010901
Iteration 43/1000 | Loss: 0.00004479
Iteration 44/1000 | Loss: 0.00003374
Iteration 45/1000 | Loss: 0.00003030
Iteration 46/1000 | Loss: 0.00002864
Iteration 47/1000 | Loss: 0.00023480
Iteration 48/1000 | Loss: 0.00102340
Iteration 49/1000 | Loss: 0.00059123
Iteration 50/1000 | Loss: 0.00061363
Iteration 51/1000 | Loss: 0.00064630
Iteration 52/1000 | Loss: 0.00032595
Iteration 53/1000 | Loss: 0.00004887
Iteration 54/1000 | Loss: 0.00003161
Iteration 55/1000 | Loss: 0.00086635
Iteration 56/1000 | Loss: 0.00004143
Iteration 57/1000 | Loss: 0.00031238
Iteration 58/1000 | Loss: 0.00020325
Iteration 59/1000 | Loss: 0.00003552
Iteration 60/1000 | Loss: 0.00002991
Iteration 61/1000 | Loss: 0.00002717
Iteration 62/1000 | Loss: 0.00002443
Iteration 63/1000 | Loss: 0.00002236
Iteration 64/1000 | Loss: 0.00002107
Iteration 65/1000 | Loss: 0.00002027
Iteration 66/1000 | Loss: 0.00001954
Iteration 67/1000 | Loss: 0.00001884
Iteration 68/1000 | Loss: 0.00001823
Iteration 69/1000 | Loss: 0.00001793
Iteration 70/1000 | Loss: 0.00001768
Iteration 71/1000 | Loss: 0.00001768
Iteration 72/1000 | Loss: 0.00001750
Iteration 73/1000 | Loss: 0.00020270
Iteration 74/1000 | Loss: 0.00002538
Iteration 75/1000 | Loss: 0.00019493
Iteration 76/1000 | Loss: 0.00002577
Iteration 77/1000 | Loss: 0.00002159
Iteration 78/1000 | Loss: 0.00001984
Iteration 79/1000 | Loss: 0.00001876
Iteration 80/1000 | Loss: 0.00023324
Iteration 81/1000 | Loss: 0.00002293
Iteration 82/1000 | Loss: 0.00001955
Iteration 83/1000 | Loss: 0.00003532
Iteration 84/1000 | Loss: 0.00002137
Iteration 85/1000 | Loss: 0.00022873
Iteration 86/1000 | Loss: 0.00025244
Iteration 87/1000 | Loss: 0.00022501
Iteration 88/1000 | Loss: 0.00024603
Iteration 89/1000 | Loss: 0.00026837
Iteration 90/1000 | Loss: 0.00024901
Iteration 91/1000 | Loss: 0.00001997
Iteration 92/1000 | Loss: 0.00025417
Iteration 93/1000 | Loss: 0.00023837
Iteration 94/1000 | Loss: 0.00026977
Iteration 95/1000 | Loss: 0.00023489
Iteration 96/1000 | Loss: 0.00021383
Iteration 97/1000 | Loss: 0.00050043
Iteration 98/1000 | Loss: 0.00034426
Iteration 99/1000 | Loss: 0.00072112
Iteration 100/1000 | Loss: 0.00003508
Iteration 101/1000 | Loss: 0.00002487
Iteration 102/1000 | Loss: 0.00002133
Iteration 103/1000 | Loss: 0.00001943
Iteration 104/1000 | Loss: 0.00001789
Iteration 105/1000 | Loss: 0.00019293
Iteration 106/1000 | Loss: 0.00003477
Iteration 107/1000 | Loss: 0.00002115
Iteration 108/1000 | Loss: 0.00001836
Iteration 109/1000 | Loss: 0.00001742
Iteration 110/1000 | Loss: 0.00001648
Iteration 111/1000 | Loss: 0.00001551
Iteration 112/1000 | Loss: 0.00001503
Iteration 113/1000 | Loss: 0.00001498
Iteration 114/1000 | Loss: 0.00001474
Iteration 115/1000 | Loss: 0.00001453
Iteration 116/1000 | Loss: 0.00001452
Iteration 117/1000 | Loss: 0.00001448
Iteration 118/1000 | Loss: 0.00001447
Iteration 119/1000 | Loss: 0.00001445
Iteration 120/1000 | Loss: 0.00001444
Iteration 121/1000 | Loss: 0.00001442
Iteration 122/1000 | Loss: 0.00001442
Iteration 123/1000 | Loss: 0.00001441
Iteration 124/1000 | Loss: 0.00001439
Iteration 125/1000 | Loss: 0.00001438
Iteration 126/1000 | Loss: 0.00001437
Iteration 127/1000 | Loss: 0.00001436
Iteration 128/1000 | Loss: 0.00001436
Iteration 129/1000 | Loss: 0.00001435
Iteration 130/1000 | Loss: 0.00001435
Iteration 131/1000 | Loss: 0.00001434
Iteration 132/1000 | Loss: 0.00001433
Iteration 133/1000 | Loss: 0.00001427
Iteration 134/1000 | Loss: 0.00001424
Iteration 135/1000 | Loss: 0.00001423
Iteration 136/1000 | Loss: 0.00001423
Iteration 137/1000 | Loss: 0.00001422
Iteration 138/1000 | Loss: 0.00001422
Iteration 139/1000 | Loss: 0.00001421
Iteration 140/1000 | Loss: 0.00001421
Iteration 141/1000 | Loss: 0.00001421
Iteration 142/1000 | Loss: 0.00001421
Iteration 143/1000 | Loss: 0.00001420
Iteration 144/1000 | Loss: 0.00001420
Iteration 145/1000 | Loss: 0.00001419
Iteration 146/1000 | Loss: 0.00001419
Iteration 147/1000 | Loss: 0.00001419
Iteration 148/1000 | Loss: 0.00001418
Iteration 149/1000 | Loss: 0.00001418
Iteration 150/1000 | Loss: 0.00001417
Iteration 151/1000 | Loss: 0.00001416
Iteration 152/1000 | Loss: 0.00001416
Iteration 153/1000 | Loss: 0.00001416
Iteration 154/1000 | Loss: 0.00001415
Iteration 155/1000 | Loss: 0.00001415
Iteration 156/1000 | Loss: 0.00001415
Iteration 157/1000 | Loss: 0.00001414
Iteration 158/1000 | Loss: 0.00001414
Iteration 159/1000 | Loss: 0.00001414
Iteration 160/1000 | Loss: 0.00001414
Iteration 161/1000 | Loss: 0.00001414
Iteration 162/1000 | Loss: 0.00001414
Iteration 163/1000 | Loss: 0.00001414
Iteration 164/1000 | Loss: 0.00001413
Iteration 165/1000 | Loss: 0.00001413
Iteration 166/1000 | Loss: 0.00001413
Iteration 167/1000 | Loss: 0.00001413
Iteration 168/1000 | Loss: 0.00001413
Iteration 169/1000 | Loss: 0.00001413
Iteration 170/1000 | Loss: 0.00001413
Iteration 171/1000 | Loss: 0.00001413
Iteration 172/1000 | Loss: 0.00001413
Iteration 173/1000 | Loss: 0.00001413
Iteration 174/1000 | Loss: 0.00001413
Iteration 175/1000 | Loss: 0.00001412
Iteration 176/1000 | Loss: 0.00001412
Iteration 177/1000 | Loss: 0.00001412
Iteration 178/1000 | Loss: 0.00001412
Iteration 179/1000 | Loss: 0.00001412
Iteration 180/1000 | Loss: 0.00001412
Iteration 181/1000 | Loss: 0.00001412
Iteration 182/1000 | Loss: 0.00001412
Iteration 183/1000 | Loss: 0.00001412
Iteration 184/1000 | Loss: 0.00001412
Iteration 185/1000 | Loss: 0.00001411
Iteration 186/1000 | Loss: 0.00001411
Iteration 187/1000 | Loss: 0.00001411
Iteration 188/1000 | Loss: 0.00001411
Iteration 189/1000 | Loss: 0.00001411
Iteration 190/1000 | Loss: 0.00001411
Iteration 191/1000 | Loss: 0.00001411
Iteration 192/1000 | Loss: 0.00001410
Iteration 193/1000 | Loss: 0.00001410
Iteration 194/1000 | Loss: 0.00001410
Iteration 195/1000 | Loss: 0.00001410
Iteration 196/1000 | Loss: 0.00001410
Iteration 197/1000 | Loss: 0.00001410
Iteration 198/1000 | Loss: 0.00001410
Iteration 199/1000 | Loss: 0.00001410
Iteration 200/1000 | Loss: 0.00001410
Iteration 201/1000 | Loss: 0.00001410
Iteration 202/1000 | Loss: 0.00001410
Iteration 203/1000 | Loss: 0.00001410
Iteration 204/1000 | Loss: 0.00001410
Iteration 205/1000 | Loss: 0.00001409
Iteration 206/1000 | Loss: 0.00001409
Iteration 207/1000 | Loss: 0.00001409
Iteration 208/1000 | Loss: 0.00001409
Iteration 209/1000 | Loss: 0.00001409
Iteration 210/1000 | Loss: 0.00001409
Iteration 211/1000 | Loss: 0.00001409
Iteration 212/1000 | Loss: 0.00001409
Iteration 213/1000 | Loss: 0.00001409
Iteration 214/1000 | Loss: 0.00001409
Iteration 215/1000 | Loss: 0.00001409
Iteration 216/1000 | Loss: 0.00001409
Iteration 217/1000 | Loss: 0.00001409
Iteration 218/1000 | Loss: 0.00001409
Iteration 219/1000 | Loss: 0.00001409
Iteration 220/1000 | Loss: 0.00001408
Iteration 221/1000 | Loss: 0.00001408
Iteration 222/1000 | Loss: 0.00001408
Iteration 223/1000 | Loss: 0.00001408
Iteration 224/1000 | Loss: 0.00001408
Iteration 225/1000 | Loss: 0.00001408
Iteration 226/1000 | Loss: 0.00001408
Iteration 227/1000 | Loss: 0.00001408
Iteration 228/1000 | Loss: 0.00001408
Iteration 229/1000 | Loss: 0.00001408
Iteration 230/1000 | Loss: 0.00001408
Iteration 231/1000 | Loss: 0.00001407
Iteration 232/1000 | Loss: 0.00001407
Iteration 233/1000 | Loss: 0.00001407
Iteration 234/1000 | Loss: 0.00001407
Iteration 235/1000 | Loss: 0.00001407
Iteration 236/1000 | Loss: 0.00001407
Iteration 237/1000 | Loss: 0.00001407
Iteration 238/1000 | Loss: 0.00001407
Iteration 239/1000 | Loss: 0.00001407
Iteration 240/1000 | Loss: 0.00001407
Iteration 241/1000 | Loss: 0.00001407
Iteration 242/1000 | Loss: 0.00001407
Iteration 243/1000 | Loss: 0.00001407
Iteration 244/1000 | Loss: 0.00001407
Iteration 245/1000 | Loss: 0.00001407
Iteration 246/1000 | Loss: 0.00001407
Iteration 247/1000 | Loss: 0.00001407
Iteration 248/1000 | Loss: 0.00001407
Iteration 249/1000 | Loss: 0.00001407
Iteration 250/1000 | Loss: 0.00001407
Iteration 251/1000 | Loss: 0.00001407
Iteration 252/1000 | Loss: 0.00001406
Iteration 253/1000 | Loss: 0.00001406
Iteration 254/1000 | Loss: 0.00001406
Iteration 255/1000 | Loss: 0.00001406
Iteration 256/1000 | Loss: 0.00001406
Iteration 257/1000 | Loss: 0.00001406
Iteration 258/1000 | Loss: 0.00001406
Iteration 259/1000 | Loss: 0.00001406
Iteration 260/1000 | Loss: 0.00001406
Iteration 261/1000 | Loss: 0.00001406
Iteration 262/1000 | Loss: 0.00001406
Iteration 263/1000 | Loss: 0.00001406
Iteration 264/1000 | Loss: 0.00001406
Iteration 265/1000 | Loss: 0.00001406
Iteration 266/1000 | Loss: 0.00001406
Iteration 267/1000 | Loss: 0.00001406
Iteration 268/1000 | Loss: 0.00001406
Iteration 269/1000 | Loss: 0.00001406
Iteration 270/1000 | Loss: 0.00001406
Iteration 271/1000 | Loss: 0.00001406
Iteration 272/1000 | Loss: 0.00001406
Iteration 273/1000 | Loss: 0.00001406
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 273. Stopping optimization.
Last 5 losses: [1.4062969967199024e-05, 1.4062969967199024e-05, 1.4062969967199024e-05, 1.4062969967199024e-05, 1.4062969967199024e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4062969967199024e-05

Optimization complete. Final v2v error: 3.1262311935424805 mm

Highest mean error: 5.106446743011475 mm for frame 62

Lowest mean error: 2.528517484664917 mm for frame 3

Saving results

Total time: 218.05827689170837
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00842419
Iteration 2/25 | Loss: 0.00117406
Iteration 3/25 | Loss: 0.00094028
Iteration 4/25 | Loss: 0.00092171
Iteration 5/25 | Loss: 0.00091889
Iteration 6/25 | Loss: 0.00091870
Iteration 7/25 | Loss: 0.00091870
Iteration 8/25 | Loss: 0.00091870
Iteration 9/25 | Loss: 0.00091870
Iteration 10/25 | Loss: 0.00091870
Iteration 11/25 | Loss: 0.00091870
Iteration 12/25 | Loss: 0.00091870
Iteration 13/25 | Loss: 0.00091870
Iteration 14/25 | Loss: 0.00091870
Iteration 15/25 | Loss: 0.00091870
Iteration 16/25 | Loss: 0.00091870
Iteration 17/25 | Loss: 0.00091870
Iteration 18/25 | Loss: 0.00091870
Iteration 19/25 | Loss: 0.00091870
Iteration 20/25 | Loss: 0.00091870
Iteration 21/25 | Loss: 0.00091870
Iteration 22/25 | Loss: 0.00091870
Iteration 23/25 | Loss: 0.00091870
Iteration 24/25 | Loss: 0.00091870
Iteration 25/25 | Loss: 0.00091870

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.40478706
Iteration 2/25 | Loss: 0.00080052
Iteration 3/25 | Loss: 0.00080050
Iteration 4/25 | Loss: 0.00080050
Iteration 5/25 | Loss: 0.00080050
Iteration 6/25 | Loss: 0.00080050
Iteration 7/25 | Loss: 0.00080050
Iteration 8/25 | Loss: 0.00080050
Iteration 9/25 | Loss: 0.00080050
Iteration 10/25 | Loss: 0.00080050
Iteration 11/25 | Loss: 0.00080050
Iteration 12/25 | Loss: 0.00080050
Iteration 13/25 | Loss: 0.00080050
Iteration 14/25 | Loss: 0.00080050
Iteration 15/25 | Loss: 0.00080050
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0008004954433999956, 0.0008004954433999956, 0.0008004954433999956, 0.0008004954433999956, 0.0008004954433999956]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008004954433999956

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00080050
Iteration 2/1000 | Loss: 0.00004503
Iteration 3/1000 | Loss: 0.00002568
Iteration 4/1000 | Loss: 0.00001789
Iteration 5/1000 | Loss: 0.00001644
Iteration 6/1000 | Loss: 0.00001552
Iteration 7/1000 | Loss: 0.00001482
Iteration 8/1000 | Loss: 0.00001439
Iteration 9/1000 | Loss: 0.00001403
Iteration 10/1000 | Loss: 0.00001370
Iteration 11/1000 | Loss: 0.00001367
Iteration 12/1000 | Loss: 0.00001344
Iteration 13/1000 | Loss: 0.00001336
Iteration 14/1000 | Loss: 0.00001325
Iteration 15/1000 | Loss: 0.00001318
Iteration 16/1000 | Loss: 0.00001315
Iteration 17/1000 | Loss: 0.00001315
Iteration 18/1000 | Loss: 0.00001313
Iteration 19/1000 | Loss: 0.00001311
Iteration 20/1000 | Loss: 0.00001311
Iteration 21/1000 | Loss: 0.00001310
Iteration 22/1000 | Loss: 0.00001310
Iteration 23/1000 | Loss: 0.00001309
Iteration 24/1000 | Loss: 0.00001308
Iteration 25/1000 | Loss: 0.00001308
Iteration 26/1000 | Loss: 0.00001307
Iteration 27/1000 | Loss: 0.00001307
Iteration 28/1000 | Loss: 0.00001306
Iteration 29/1000 | Loss: 0.00001306
Iteration 30/1000 | Loss: 0.00001306
Iteration 31/1000 | Loss: 0.00001305
Iteration 32/1000 | Loss: 0.00001305
Iteration 33/1000 | Loss: 0.00001305
Iteration 34/1000 | Loss: 0.00001305
Iteration 35/1000 | Loss: 0.00001304
Iteration 36/1000 | Loss: 0.00001304
Iteration 37/1000 | Loss: 0.00001304
Iteration 38/1000 | Loss: 0.00001304
Iteration 39/1000 | Loss: 0.00001303
Iteration 40/1000 | Loss: 0.00001303
Iteration 41/1000 | Loss: 0.00001303
Iteration 42/1000 | Loss: 0.00001303
Iteration 43/1000 | Loss: 0.00001302
Iteration 44/1000 | Loss: 0.00001302
Iteration 45/1000 | Loss: 0.00001302
Iteration 46/1000 | Loss: 0.00001302
Iteration 47/1000 | Loss: 0.00001301
Iteration 48/1000 | Loss: 0.00001301
Iteration 49/1000 | Loss: 0.00001300
Iteration 50/1000 | Loss: 0.00001300
Iteration 51/1000 | Loss: 0.00001300
Iteration 52/1000 | Loss: 0.00001300
Iteration 53/1000 | Loss: 0.00001299
Iteration 54/1000 | Loss: 0.00001299
Iteration 55/1000 | Loss: 0.00001299
Iteration 56/1000 | Loss: 0.00001298
Iteration 57/1000 | Loss: 0.00001298
Iteration 58/1000 | Loss: 0.00001297
Iteration 59/1000 | Loss: 0.00001297
Iteration 60/1000 | Loss: 0.00001297
Iteration 61/1000 | Loss: 0.00001297
Iteration 62/1000 | Loss: 0.00001297
Iteration 63/1000 | Loss: 0.00001297
Iteration 64/1000 | Loss: 0.00001297
Iteration 65/1000 | Loss: 0.00001297
Iteration 66/1000 | Loss: 0.00001297
Iteration 67/1000 | Loss: 0.00001297
Iteration 68/1000 | Loss: 0.00001297
Iteration 69/1000 | Loss: 0.00001297
Iteration 70/1000 | Loss: 0.00001296
Iteration 71/1000 | Loss: 0.00001296
Iteration 72/1000 | Loss: 0.00001296
Iteration 73/1000 | Loss: 0.00001296
Iteration 74/1000 | Loss: 0.00001296
Iteration 75/1000 | Loss: 0.00001296
Iteration 76/1000 | Loss: 0.00001296
Iteration 77/1000 | Loss: 0.00001295
Iteration 78/1000 | Loss: 0.00001295
Iteration 79/1000 | Loss: 0.00001295
Iteration 80/1000 | Loss: 0.00001295
Iteration 81/1000 | Loss: 0.00001295
Iteration 82/1000 | Loss: 0.00001295
Iteration 83/1000 | Loss: 0.00001294
Iteration 84/1000 | Loss: 0.00001294
Iteration 85/1000 | Loss: 0.00001294
Iteration 86/1000 | Loss: 0.00001294
Iteration 87/1000 | Loss: 0.00001294
Iteration 88/1000 | Loss: 0.00001294
Iteration 89/1000 | Loss: 0.00001294
Iteration 90/1000 | Loss: 0.00001293
Iteration 91/1000 | Loss: 0.00001293
Iteration 92/1000 | Loss: 0.00001293
Iteration 93/1000 | Loss: 0.00001293
Iteration 94/1000 | Loss: 0.00001293
Iteration 95/1000 | Loss: 0.00001293
Iteration 96/1000 | Loss: 0.00001292
Iteration 97/1000 | Loss: 0.00001292
Iteration 98/1000 | Loss: 0.00001292
Iteration 99/1000 | Loss: 0.00001292
Iteration 100/1000 | Loss: 0.00001292
Iteration 101/1000 | Loss: 0.00001292
Iteration 102/1000 | Loss: 0.00001292
Iteration 103/1000 | Loss: 0.00001292
Iteration 104/1000 | Loss: 0.00001292
Iteration 105/1000 | Loss: 0.00001291
Iteration 106/1000 | Loss: 0.00001291
Iteration 107/1000 | Loss: 0.00001291
Iteration 108/1000 | Loss: 0.00001291
Iteration 109/1000 | Loss: 0.00001291
Iteration 110/1000 | Loss: 0.00001291
Iteration 111/1000 | Loss: 0.00001291
Iteration 112/1000 | Loss: 0.00001291
Iteration 113/1000 | Loss: 0.00001291
Iteration 114/1000 | Loss: 0.00001291
Iteration 115/1000 | Loss: 0.00001291
Iteration 116/1000 | Loss: 0.00001291
Iteration 117/1000 | Loss: 0.00001291
Iteration 118/1000 | Loss: 0.00001291
Iteration 119/1000 | Loss: 0.00001291
Iteration 120/1000 | Loss: 0.00001290
Iteration 121/1000 | Loss: 0.00001290
Iteration 122/1000 | Loss: 0.00001290
Iteration 123/1000 | Loss: 0.00001290
Iteration 124/1000 | Loss: 0.00001290
Iteration 125/1000 | Loss: 0.00001290
Iteration 126/1000 | Loss: 0.00001290
Iteration 127/1000 | Loss: 0.00001290
Iteration 128/1000 | Loss: 0.00001290
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [1.2903376045869663e-05, 1.2903376045869663e-05, 1.2903376045869663e-05, 1.2903376045869663e-05, 1.2903376045869663e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2903376045869663e-05

Optimization complete. Final v2v error: 3.096916675567627 mm

Highest mean error: 3.6302080154418945 mm for frame 20

Lowest mean error: 2.733754873275757 mm for frame 116

Saving results

Total time: 36.0755889415741
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00857772
Iteration 2/25 | Loss: 0.00144166
Iteration 3/25 | Loss: 0.00106243
Iteration 4/25 | Loss: 0.00102121
Iteration 5/25 | Loss: 0.00101842
Iteration 6/25 | Loss: 0.00101842
Iteration 7/25 | Loss: 0.00101842
Iteration 8/25 | Loss: 0.00101842
Iteration 9/25 | Loss: 0.00101842
Iteration 10/25 | Loss: 0.00101842
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0010184233542531729, 0.0010184233542531729, 0.0010184233542531729, 0.0010184233542531729, 0.0010184233542531729]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010184233542531729

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.22798252
Iteration 2/25 | Loss: 0.00065321
Iteration 3/25 | Loss: 0.00065318
Iteration 4/25 | Loss: 0.00065318
Iteration 5/25 | Loss: 0.00065318
Iteration 6/25 | Loss: 0.00065318
Iteration 7/25 | Loss: 0.00065318
Iteration 8/25 | Loss: 0.00065318
Iteration 9/25 | Loss: 0.00065318
Iteration 10/25 | Loss: 0.00065318
Iteration 11/25 | Loss: 0.00065318
Iteration 12/25 | Loss: 0.00065318
Iteration 13/25 | Loss: 0.00065318
Iteration 14/25 | Loss: 0.00065318
Iteration 15/25 | Loss: 0.00065318
Iteration 16/25 | Loss: 0.00065318
Iteration 17/25 | Loss: 0.00065318
Iteration 18/25 | Loss: 0.00065318
Iteration 19/25 | Loss: 0.00065318
Iteration 20/25 | Loss: 0.00065318
Iteration 21/25 | Loss: 0.00065318
Iteration 22/25 | Loss: 0.00065318
Iteration 23/25 | Loss: 0.00065318
Iteration 24/25 | Loss: 0.00065318
Iteration 25/25 | Loss: 0.00065318

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065318
Iteration 2/1000 | Loss: 0.00006426
Iteration 3/1000 | Loss: 0.00003329
Iteration 4/1000 | Loss: 0.00002670
Iteration 5/1000 | Loss: 0.00002414
Iteration 6/1000 | Loss: 0.00002223
Iteration 7/1000 | Loss: 0.00002127
Iteration 8/1000 | Loss: 0.00002073
Iteration 9/1000 | Loss: 0.00002000
Iteration 10/1000 | Loss: 0.00001951
Iteration 11/1000 | Loss: 0.00001920
Iteration 12/1000 | Loss: 0.00001892
Iteration 13/1000 | Loss: 0.00001864
Iteration 14/1000 | Loss: 0.00001849
Iteration 15/1000 | Loss: 0.00001837
Iteration 16/1000 | Loss: 0.00001833
Iteration 17/1000 | Loss: 0.00001833
Iteration 18/1000 | Loss: 0.00001830
Iteration 19/1000 | Loss: 0.00001830
Iteration 20/1000 | Loss: 0.00001829
Iteration 21/1000 | Loss: 0.00001828
Iteration 22/1000 | Loss: 0.00001823
Iteration 23/1000 | Loss: 0.00001823
Iteration 24/1000 | Loss: 0.00001823
Iteration 25/1000 | Loss: 0.00001822
Iteration 26/1000 | Loss: 0.00001821
Iteration 27/1000 | Loss: 0.00001821
Iteration 28/1000 | Loss: 0.00001821
Iteration 29/1000 | Loss: 0.00001821
Iteration 30/1000 | Loss: 0.00001821
Iteration 31/1000 | Loss: 0.00001821
Iteration 32/1000 | Loss: 0.00001821
Iteration 33/1000 | Loss: 0.00001820
Iteration 34/1000 | Loss: 0.00001820
Iteration 35/1000 | Loss: 0.00001820
Iteration 36/1000 | Loss: 0.00001820
Iteration 37/1000 | Loss: 0.00001820
Iteration 38/1000 | Loss: 0.00001820
Iteration 39/1000 | Loss: 0.00001819
Iteration 40/1000 | Loss: 0.00001819
Iteration 41/1000 | Loss: 0.00001818
Iteration 42/1000 | Loss: 0.00001818
Iteration 43/1000 | Loss: 0.00001818
Iteration 44/1000 | Loss: 0.00001818
Iteration 45/1000 | Loss: 0.00001817
Iteration 46/1000 | Loss: 0.00001817
Iteration 47/1000 | Loss: 0.00001817
Iteration 48/1000 | Loss: 0.00001817
Iteration 49/1000 | Loss: 0.00001817
Iteration 50/1000 | Loss: 0.00001817
Iteration 51/1000 | Loss: 0.00001817
Iteration 52/1000 | Loss: 0.00001816
Iteration 53/1000 | Loss: 0.00001816
Iteration 54/1000 | Loss: 0.00001816
Iteration 55/1000 | Loss: 0.00001816
Iteration 56/1000 | Loss: 0.00001815
Iteration 57/1000 | Loss: 0.00001815
Iteration 58/1000 | Loss: 0.00001815
Iteration 59/1000 | Loss: 0.00001815
Iteration 60/1000 | Loss: 0.00001815
Iteration 61/1000 | Loss: 0.00001815
Iteration 62/1000 | Loss: 0.00001814
Iteration 63/1000 | Loss: 0.00001814
Iteration 64/1000 | Loss: 0.00001814
Iteration 65/1000 | Loss: 0.00001814
Iteration 66/1000 | Loss: 0.00001813
Iteration 67/1000 | Loss: 0.00001813
Iteration 68/1000 | Loss: 0.00001813
Iteration 69/1000 | Loss: 0.00001813
Iteration 70/1000 | Loss: 0.00001813
Iteration 71/1000 | Loss: 0.00001813
Iteration 72/1000 | Loss: 0.00001813
Iteration 73/1000 | Loss: 0.00001812
Iteration 74/1000 | Loss: 0.00001812
Iteration 75/1000 | Loss: 0.00001812
Iteration 76/1000 | Loss: 0.00001811
Iteration 77/1000 | Loss: 0.00001811
Iteration 78/1000 | Loss: 0.00001810
Iteration 79/1000 | Loss: 0.00001810
Iteration 80/1000 | Loss: 0.00001809
Iteration 81/1000 | Loss: 0.00001808
Iteration 82/1000 | Loss: 0.00001808
Iteration 83/1000 | Loss: 0.00001808
Iteration 84/1000 | Loss: 0.00001808
Iteration 85/1000 | Loss: 0.00001808
Iteration 86/1000 | Loss: 0.00001808
Iteration 87/1000 | Loss: 0.00001808
Iteration 88/1000 | Loss: 0.00001808
Iteration 89/1000 | Loss: 0.00001808
Iteration 90/1000 | Loss: 0.00001808
Iteration 91/1000 | Loss: 0.00001808
Iteration 92/1000 | Loss: 0.00001807
Iteration 93/1000 | Loss: 0.00001807
Iteration 94/1000 | Loss: 0.00001807
Iteration 95/1000 | Loss: 0.00001806
Iteration 96/1000 | Loss: 0.00001806
Iteration 97/1000 | Loss: 0.00001806
Iteration 98/1000 | Loss: 0.00001806
Iteration 99/1000 | Loss: 0.00001806
Iteration 100/1000 | Loss: 0.00001806
Iteration 101/1000 | Loss: 0.00001806
Iteration 102/1000 | Loss: 0.00001806
Iteration 103/1000 | Loss: 0.00001806
Iteration 104/1000 | Loss: 0.00001805
Iteration 105/1000 | Loss: 0.00001805
Iteration 106/1000 | Loss: 0.00001805
Iteration 107/1000 | Loss: 0.00001805
Iteration 108/1000 | Loss: 0.00001804
Iteration 109/1000 | Loss: 0.00001804
Iteration 110/1000 | Loss: 0.00001804
Iteration 111/1000 | Loss: 0.00001804
Iteration 112/1000 | Loss: 0.00001804
Iteration 113/1000 | Loss: 0.00001803
Iteration 114/1000 | Loss: 0.00001803
Iteration 115/1000 | Loss: 0.00001803
Iteration 116/1000 | Loss: 0.00001803
Iteration 117/1000 | Loss: 0.00001802
Iteration 118/1000 | Loss: 0.00001802
Iteration 119/1000 | Loss: 0.00001802
Iteration 120/1000 | Loss: 0.00001802
Iteration 121/1000 | Loss: 0.00001802
Iteration 122/1000 | Loss: 0.00001802
Iteration 123/1000 | Loss: 0.00001802
Iteration 124/1000 | Loss: 0.00001802
Iteration 125/1000 | Loss: 0.00001802
Iteration 126/1000 | Loss: 0.00001801
Iteration 127/1000 | Loss: 0.00001801
Iteration 128/1000 | Loss: 0.00001801
Iteration 129/1000 | Loss: 0.00001800
Iteration 130/1000 | Loss: 0.00001800
Iteration 131/1000 | Loss: 0.00001800
Iteration 132/1000 | Loss: 0.00001800
Iteration 133/1000 | Loss: 0.00001799
Iteration 134/1000 | Loss: 0.00001799
Iteration 135/1000 | Loss: 0.00001799
Iteration 136/1000 | Loss: 0.00001799
Iteration 137/1000 | Loss: 0.00001798
Iteration 138/1000 | Loss: 0.00001798
Iteration 139/1000 | Loss: 0.00001798
Iteration 140/1000 | Loss: 0.00001798
Iteration 141/1000 | Loss: 0.00001797
Iteration 142/1000 | Loss: 0.00001797
Iteration 143/1000 | Loss: 0.00001797
Iteration 144/1000 | Loss: 0.00001797
Iteration 145/1000 | Loss: 0.00001797
Iteration 146/1000 | Loss: 0.00001797
Iteration 147/1000 | Loss: 0.00001797
Iteration 148/1000 | Loss: 0.00001797
Iteration 149/1000 | Loss: 0.00001797
Iteration 150/1000 | Loss: 0.00001796
Iteration 151/1000 | Loss: 0.00001796
Iteration 152/1000 | Loss: 0.00001796
Iteration 153/1000 | Loss: 0.00001796
Iteration 154/1000 | Loss: 0.00001796
Iteration 155/1000 | Loss: 0.00001795
Iteration 156/1000 | Loss: 0.00001795
Iteration 157/1000 | Loss: 0.00001795
Iteration 158/1000 | Loss: 0.00001795
Iteration 159/1000 | Loss: 0.00001795
Iteration 160/1000 | Loss: 0.00001794
Iteration 161/1000 | Loss: 0.00001794
Iteration 162/1000 | Loss: 0.00001794
Iteration 163/1000 | Loss: 0.00001794
Iteration 164/1000 | Loss: 0.00001794
Iteration 165/1000 | Loss: 0.00001794
Iteration 166/1000 | Loss: 0.00001794
Iteration 167/1000 | Loss: 0.00001794
Iteration 168/1000 | Loss: 0.00001794
Iteration 169/1000 | Loss: 0.00001794
Iteration 170/1000 | Loss: 0.00001794
Iteration 171/1000 | Loss: 0.00001794
Iteration 172/1000 | Loss: 0.00001794
Iteration 173/1000 | Loss: 0.00001794
Iteration 174/1000 | Loss: 0.00001794
Iteration 175/1000 | Loss: 0.00001794
Iteration 176/1000 | Loss: 0.00001794
Iteration 177/1000 | Loss: 0.00001794
Iteration 178/1000 | Loss: 0.00001794
Iteration 179/1000 | Loss: 0.00001794
Iteration 180/1000 | Loss: 0.00001794
Iteration 181/1000 | Loss: 0.00001794
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.7941150872502476e-05, 1.7941150872502476e-05, 1.7941150872502476e-05, 1.7941150872502476e-05, 1.7941150872502476e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7941150872502476e-05

Optimization complete. Final v2v error: 3.6785330772399902 mm

Highest mean error: 4.224420070648193 mm for frame 150

Lowest mean error: 3.39550518989563 mm for frame 203

Saving results

Total time: 46.3928484916687
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00844344
Iteration 2/25 | Loss: 0.00112833
Iteration 3/25 | Loss: 0.00085358
Iteration 4/25 | Loss: 0.00081108
Iteration 5/25 | Loss: 0.00080795
Iteration 6/25 | Loss: 0.00080697
Iteration 7/25 | Loss: 0.00080675
Iteration 8/25 | Loss: 0.00080675
Iteration 9/25 | Loss: 0.00080675
Iteration 10/25 | Loss: 0.00080675
Iteration 11/25 | Loss: 0.00080675
Iteration 12/25 | Loss: 0.00080675
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008067548042163253, 0.0008067548042163253, 0.0008067548042163253, 0.0008067548042163253, 0.0008067548042163253]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008067548042163253

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.73280478
Iteration 2/25 | Loss: 0.00072444
Iteration 3/25 | Loss: 0.00072443
Iteration 4/25 | Loss: 0.00072443
Iteration 5/25 | Loss: 0.00072442
Iteration 6/25 | Loss: 0.00072442
Iteration 7/25 | Loss: 0.00072442
Iteration 8/25 | Loss: 0.00072442
Iteration 9/25 | Loss: 0.00072442
Iteration 10/25 | Loss: 0.00072442
Iteration 11/25 | Loss: 0.00072442
Iteration 12/25 | Loss: 0.00072442
Iteration 13/25 | Loss: 0.00072442
Iteration 14/25 | Loss: 0.00072442
Iteration 15/25 | Loss: 0.00072442
Iteration 16/25 | Loss: 0.00072442
Iteration 17/25 | Loss: 0.00072442
Iteration 18/25 | Loss: 0.00072442
Iteration 19/25 | Loss: 0.00072442
Iteration 20/25 | Loss: 0.00072442
Iteration 21/25 | Loss: 0.00072442
Iteration 22/25 | Loss: 0.00072442
Iteration 23/25 | Loss: 0.00072442
Iteration 24/25 | Loss: 0.00072442
Iteration 25/25 | Loss: 0.00072442

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00072442
Iteration 2/1000 | Loss: 0.00002234
Iteration 3/1000 | Loss: 0.00001296
Iteration 4/1000 | Loss: 0.00001014
Iteration 5/1000 | Loss: 0.00000950
Iteration 6/1000 | Loss: 0.00000914
Iteration 7/1000 | Loss: 0.00000895
Iteration 8/1000 | Loss: 0.00000875
Iteration 9/1000 | Loss: 0.00000854
Iteration 10/1000 | Loss: 0.00000849
Iteration 11/1000 | Loss: 0.00000839
Iteration 12/1000 | Loss: 0.00000830
Iteration 13/1000 | Loss: 0.00000828
Iteration 14/1000 | Loss: 0.00000828
Iteration 15/1000 | Loss: 0.00000828
Iteration 16/1000 | Loss: 0.00000827
Iteration 17/1000 | Loss: 0.00000826
Iteration 18/1000 | Loss: 0.00000826
Iteration 19/1000 | Loss: 0.00000826
Iteration 20/1000 | Loss: 0.00000826
Iteration 21/1000 | Loss: 0.00000825
Iteration 22/1000 | Loss: 0.00000825
Iteration 23/1000 | Loss: 0.00000825
Iteration 24/1000 | Loss: 0.00000825
Iteration 25/1000 | Loss: 0.00000825
Iteration 26/1000 | Loss: 0.00000824
Iteration 27/1000 | Loss: 0.00000823
Iteration 28/1000 | Loss: 0.00000823
Iteration 29/1000 | Loss: 0.00000822
Iteration 30/1000 | Loss: 0.00000822
Iteration 31/1000 | Loss: 0.00000822
Iteration 32/1000 | Loss: 0.00000822
Iteration 33/1000 | Loss: 0.00000822
Iteration 34/1000 | Loss: 0.00000822
Iteration 35/1000 | Loss: 0.00000821
Iteration 36/1000 | Loss: 0.00000821
Iteration 37/1000 | Loss: 0.00000821
Iteration 38/1000 | Loss: 0.00000821
Iteration 39/1000 | Loss: 0.00000821
Iteration 40/1000 | Loss: 0.00000820
Iteration 41/1000 | Loss: 0.00000820
Iteration 42/1000 | Loss: 0.00000819
Iteration 43/1000 | Loss: 0.00000819
Iteration 44/1000 | Loss: 0.00000819
Iteration 45/1000 | Loss: 0.00000819
Iteration 46/1000 | Loss: 0.00000819
Iteration 47/1000 | Loss: 0.00000819
Iteration 48/1000 | Loss: 0.00000819
Iteration 49/1000 | Loss: 0.00000819
Iteration 50/1000 | Loss: 0.00000819
Iteration 51/1000 | Loss: 0.00000818
Iteration 52/1000 | Loss: 0.00000818
Iteration 53/1000 | Loss: 0.00000817
Iteration 54/1000 | Loss: 0.00000817
Iteration 55/1000 | Loss: 0.00000817
Iteration 56/1000 | Loss: 0.00000817
Iteration 57/1000 | Loss: 0.00000816
Iteration 58/1000 | Loss: 0.00000816
Iteration 59/1000 | Loss: 0.00000816
Iteration 60/1000 | Loss: 0.00000816
Iteration 61/1000 | Loss: 0.00000816
Iteration 62/1000 | Loss: 0.00000816
Iteration 63/1000 | Loss: 0.00000816
Iteration 64/1000 | Loss: 0.00000816
Iteration 65/1000 | Loss: 0.00000816
Iteration 66/1000 | Loss: 0.00000816
Iteration 67/1000 | Loss: 0.00000816
Iteration 68/1000 | Loss: 0.00000816
Iteration 69/1000 | Loss: 0.00000816
Iteration 70/1000 | Loss: 0.00000816
Iteration 71/1000 | Loss: 0.00000815
Iteration 72/1000 | Loss: 0.00000815
Iteration 73/1000 | Loss: 0.00000815
Iteration 74/1000 | Loss: 0.00000815
Iteration 75/1000 | Loss: 0.00000815
Iteration 76/1000 | Loss: 0.00000815
Iteration 77/1000 | Loss: 0.00000815
Iteration 78/1000 | Loss: 0.00000815
Iteration 79/1000 | Loss: 0.00000815
Iteration 80/1000 | Loss: 0.00000815
Iteration 81/1000 | Loss: 0.00000815
Iteration 82/1000 | Loss: 0.00000815
Iteration 83/1000 | Loss: 0.00000815
Iteration 84/1000 | Loss: 0.00000815
Iteration 85/1000 | Loss: 0.00000815
Iteration 86/1000 | Loss: 0.00000814
Iteration 87/1000 | Loss: 0.00000814
Iteration 88/1000 | Loss: 0.00000814
Iteration 89/1000 | Loss: 0.00000814
Iteration 90/1000 | Loss: 0.00000814
Iteration 91/1000 | Loss: 0.00000814
Iteration 92/1000 | Loss: 0.00000814
Iteration 93/1000 | Loss: 0.00000814
Iteration 94/1000 | Loss: 0.00000814
Iteration 95/1000 | Loss: 0.00000814
Iteration 96/1000 | Loss: 0.00000814
Iteration 97/1000 | Loss: 0.00000814
Iteration 98/1000 | Loss: 0.00000814
Iteration 99/1000 | Loss: 0.00000814
Iteration 100/1000 | Loss: 0.00000813
Iteration 101/1000 | Loss: 0.00000813
Iteration 102/1000 | Loss: 0.00000813
Iteration 103/1000 | Loss: 0.00000813
Iteration 104/1000 | Loss: 0.00000813
Iteration 105/1000 | Loss: 0.00000813
Iteration 106/1000 | Loss: 0.00000813
Iteration 107/1000 | Loss: 0.00000813
Iteration 108/1000 | Loss: 0.00000813
Iteration 109/1000 | Loss: 0.00000813
Iteration 110/1000 | Loss: 0.00000813
Iteration 111/1000 | Loss: 0.00000813
Iteration 112/1000 | Loss: 0.00000813
Iteration 113/1000 | Loss: 0.00000813
Iteration 114/1000 | Loss: 0.00000813
Iteration 115/1000 | Loss: 0.00000813
Iteration 116/1000 | Loss: 0.00000813
Iteration 117/1000 | Loss: 0.00000813
Iteration 118/1000 | Loss: 0.00000813
Iteration 119/1000 | Loss: 0.00000813
Iteration 120/1000 | Loss: 0.00000813
Iteration 121/1000 | Loss: 0.00000813
Iteration 122/1000 | Loss: 0.00000813
Iteration 123/1000 | Loss: 0.00000813
Iteration 124/1000 | Loss: 0.00000813
Iteration 125/1000 | Loss: 0.00000813
Iteration 126/1000 | Loss: 0.00000813
Iteration 127/1000 | Loss: 0.00000813
Iteration 128/1000 | Loss: 0.00000813
Iteration 129/1000 | Loss: 0.00000813
Iteration 130/1000 | Loss: 0.00000813
Iteration 131/1000 | Loss: 0.00000813
Iteration 132/1000 | Loss: 0.00000813
Iteration 133/1000 | Loss: 0.00000813
Iteration 134/1000 | Loss: 0.00000813
Iteration 135/1000 | Loss: 0.00000813
Iteration 136/1000 | Loss: 0.00000813
Iteration 137/1000 | Loss: 0.00000813
Iteration 138/1000 | Loss: 0.00000813
Iteration 139/1000 | Loss: 0.00000813
Iteration 140/1000 | Loss: 0.00000813
Iteration 141/1000 | Loss: 0.00000813
Iteration 142/1000 | Loss: 0.00000813
Iteration 143/1000 | Loss: 0.00000813
Iteration 144/1000 | Loss: 0.00000813
Iteration 145/1000 | Loss: 0.00000813
Iteration 146/1000 | Loss: 0.00000813
Iteration 147/1000 | Loss: 0.00000813
Iteration 148/1000 | Loss: 0.00000813
Iteration 149/1000 | Loss: 0.00000813
Iteration 150/1000 | Loss: 0.00000813
Iteration 151/1000 | Loss: 0.00000813
Iteration 152/1000 | Loss: 0.00000813
Iteration 153/1000 | Loss: 0.00000813
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 153. Stopping optimization.
Last 5 losses: [8.130265996442176e-06, 8.130265996442176e-06, 8.130265996442176e-06, 8.130265996442176e-06, 8.130265996442176e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.130265996442176e-06

Optimization complete. Final v2v error: 2.4475960731506348 mm

Highest mean error: 3.0389244556427 mm for frame 239

Lowest mean error: 2.1173758506774902 mm for frame 103

Saving results

Total time: 37.077467918395996
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00770153
Iteration 2/25 | Loss: 0.00106869
Iteration 3/25 | Loss: 0.00090447
Iteration 4/25 | Loss: 0.00086773
Iteration 5/25 | Loss: 0.00085358
Iteration 6/25 | Loss: 0.00084943
Iteration 7/25 | Loss: 0.00084852
Iteration 8/25 | Loss: 0.00084852
Iteration 9/25 | Loss: 0.00084852
Iteration 10/25 | Loss: 0.00084852
Iteration 11/25 | Loss: 0.00084852
Iteration 12/25 | Loss: 0.00084852
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008485182770527899, 0.0008485182770527899, 0.0008485182770527899, 0.0008485182770527899, 0.0008485182770527899]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008485182770527899

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.42553914
Iteration 2/25 | Loss: 0.00086847
Iteration 3/25 | Loss: 0.00086847
Iteration 4/25 | Loss: 0.00086847
Iteration 5/25 | Loss: 0.00086846
Iteration 6/25 | Loss: 0.00086846
Iteration 7/25 | Loss: 0.00086846
Iteration 8/25 | Loss: 0.00086846
Iteration 9/25 | Loss: 0.00086846
Iteration 10/25 | Loss: 0.00086846
Iteration 11/25 | Loss: 0.00086846
Iteration 12/25 | Loss: 0.00086846
Iteration 13/25 | Loss: 0.00086846
Iteration 14/25 | Loss: 0.00086846
Iteration 15/25 | Loss: 0.00086846
Iteration 16/25 | Loss: 0.00086846
Iteration 17/25 | Loss: 0.00086846
Iteration 18/25 | Loss: 0.00086846
Iteration 19/25 | Loss: 0.00086846
Iteration 20/25 | Loss: 0.00086846
Iteration 21/25 | Loss: 0.00086846
Iteration 22/25 | Loss: 0.00086846
Iteration 23/25 | Loss: 0.00086846
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0008684635395184159, 0.0008684635395184159, 0.0008684635395184159, 0.0008684635395184159, 0.0008684635395184159]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008684635395184159

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00086846
Iteration 2/1000 | Loss: 0.00004498
Iteration 3/1000 | Loss: 0.00002339
Iteration 4/1000 | Loss: 0.00001937
Iteration 5/1000 | Loss: 0.00001833
Iteration 6/1000 | Loss: 0.00001734
Iteration 7/1000 | Loss: 0.00001671
Iteration 8/1000 | Loss: 0.00001620
Iteration 9/1000 | Loss: 0.00001577
Iteration 10/1000 | Loss: 0.00001536
Iteration 11/1000 | Loss: 0.00001513
Iteration 12/1000 | Loss: 0.00001499
Iteration 13/1000 | Loss: 0.00001494
Iteration 14/1000 | Loss: 0.00001489
Iteration 15/1000 | Loss: 0.00001479
Iteration 16/1000 | Loss: 0.00001472
Iteration 17/1000 | Loss: 0.00001468
Iteration 18/1000 | Loss: 0.00001468
Iteration 19/1000 | Loss: 0.00001467
Iteration 20/1000 | Loss: 0.00001466
Iteration 21/1000 | Loss: 0.00001465
Iteration 22/1000 | Loss: 0.00001462
Iteration 23/1000 | Loss: 0.00001462
Iteration 24/1000 | Loss: 0.00001462
Iteration 25/1000 | Loss: 0.00001461
Iteration 26/1000 | Loss: 0.00001461
Iteration 27/1000 | Loss: 0.00001460
Iteration 28/1000 | Loss: 0.00001460
Iteration 29/1000 | Loss: 0.00001460
Iteration 30/1000 | Loss: 0.00001460
Iteration 31/1000 | Loss: 0.00001460
Iteration 32/1000 | Loss: 0.00001460
Iteration 33/1000 | Loss: 0.00001459
Iteration 34/1000 | Loss: 0.00001459
Iteration 35/1000 | Loss: 0.00001459
Iteration 36/1000 | Loss: 0.00001459
Iteration 37/1000 | Loss: 0.00001458
Iteration 38/1000 | Loss: 0.00001458
Iteration 39/1000 | Loss: 0.00001458
Iteration 40/1000 | Loss: 0.00001457
Iteration 41/1000 | Loss: 0.00001457
Iteration 42/1000 | Loss: 0.00001457
Iteration 43/1000 | Loss: 0.00001456
Iteration 44/1000 | Loss: 0.00001456
Iteration 45/1000 | Loss: 0.00001456
Iteration 46/1000 | Loss: 0.00001455
Iteration 47/1000 | Loss: 0.00001455
Iteration 48/1000 | Loss: 0.00001455
Iteration 49/1000 | Loss: 0.00001454
Iteration 50/1000 | Loss: 0.00001454
Iteration 51/1000 | Loss: 0.00001454
Iteration 52/1000 | Loss: 0.00001454
Iteration 53/1000 | Loss: 0.00001453
Iteration 54/1000 | Loss: 0.00001453
Iteration 55/1000 | Loss: 0.00001453
Iteration 56/1000 | Loss: 0.00001452
Iteration 57/1000 | Loss: 0.00001452
Iteration 58/1000 | Loss: 0.00001452
Iteration 59/1000 | Loss: 0.00001451
Iteration 60/1000 | Loss: 0.00001451
Iteration 61/1000 | Loss: 0.00001451
Iteration 62/1000 | Loss: 0.00001450
Iteration 63/1000 | Loss: 0.00001450
Iteration 64/1000 | Loss: 0.00001450
Iteration 65/1000 | Loss: 0.00001450
Iteration 66/1000 | Loss: 0.00001449
Iteration 67/1000 | Loss: 0.00001449
Iteration 68/1000 | Loss: 0.00001449
Iteration 69/1000 | Loss: 0.00001449
Iteration 70/1000 | Loss: 0.00001449
Iteration 71/1000 | Loss: 0.00001449
Iteration 72/1000 | Loss: 0.00001449
Iteration 73/1000 | Loss: 0.00001448
Iteration 74/1000 | Loss: 0.00001448
Iteration 75/1000 | Loss: 0.00001448
Iteration 76/1000 | Loss: 0.00001448
Iteration 77/1000 | Loss: 0.00001448
Iteration 78/1000 | Loss: 0.00001447
Iteration 79/1000 | Loss: 0.00001447
Iteration 80/1000 | Loss: 0.00001447
Iteration 81/1000 | Loss: 0.00001446
Iteration 82/1000 | Loss: 0.00001446
Iteration 83/1000 | Loss: 0.00001446
Iteration 84/1000 | Loss: 0.00001446
Iteration 85/1000 | Loss: 0.00001446
Iteration 86/1000 | Loss: 0.00001446
Iteration 87/1000 | Loss: 0.00001446
Iteration 88/1000 | Loss: 0.00001446
Iteration 89/1000 | Loss: 0.00001445
Iteration 90/1000 | Loss: 0.00001445
Iteration 91/1000 | Loss: 0.00001445
Iteration 92/1000 | Loss: 0.00001445
Iteration 93/1000 | Loss: 0.00001445
Iteration 94/1000 | Loss: 0.00001445
Iteration 95/1000 | Loss: 0.00001445
Iteration 96/1000 | Loss: 0.00001445
Iteration 97/1000 | Loss: 0.00001445
Iteration 98/1000 | Loss: 0.00001444
Iteration 99/1000 | Loss: 0.00001444
Iteration 100/1000 | Loss: 0.00001444
Iteration 101/1000 | Loss: 0.00001444
Iteration 102/1000 | Loss: 0.00001444
Iteration 103/1000 | Loss: 0.00001444
Iteration 104/1000 | Loss: 0.00001444
Iteration 105/1000 | Loss: 0.00001444
Iteration 106/1000 | Loss: 0.00001444
Iteration 107/1000 | Loss: 0.00001444
Iteration 108/1000 | Loss: 0.00001443
Iteration 109/1000 | Loss: 0.00001443
Iteration 110/1000 | Loss: 0.00001443
Iteration 111/1000 | Loss: 0.00001443
Iteration 112/1000 | Loss: 0.00001443
Iteration 113/1000 | Loss: 0.00001443
Iteration 114/1000 | Loss: 0.00001443
Iteration 115/1000 | Loss: 0.00001443
Iteration 116/1000 | Loss: 0.00001442
Iteration 117/1000 | Loss: 0.00001442
Iteration 118/1000 | Loss: 0.00001442
Iteration 119/1000 | Loss: 0.00001442
Iteration 120/1000 | Loss: 0.00001442
Iteration 121/1000 | Loss: 0.00001442
Iteration 122/1000 | Loss: 0.00001442
Iteration 123/1000 | Loss: 0.00001441
Iteration 124/1000 | Loss: 0.00001441
Iteration 125/1000 | Loss: 0.00001441
Iteration 126/1000 | Loss: 0.00001441
Iteration 127/1000 | Loss: 0.00001441
Iteration 128/1000 | Loss: 0.00001441
Iteration 129/1000 | Loss: 0.00001441
Iteration 130/1000 | Loss: 0.00001441
Iteration 131/1000 | Loss: 0.00001441
Iteration 132/1000 | Loss: 0.00001441
Iteration 133/1000 | Loss: 0.00001441
Iteration 134/1000 | Loss: 0.00001441
Iteration 135/1000 | Loss: 0.00001441
Iteration 136/1000 | Loss: 0.00001441
Iteration 137/1000 | Loss: 0.00001441
Iteration 138/1000 | Loss: 0.00001441
Iteration 139/1000 | Loss: 0.00001441
Iteration 140/1000 | Loss: 0.00001441
Iteration 141/1000 | Loss: 0.00001441
Iteration 142/1000 | Loss: 0.00001441
Iteration 143/1000 | Loss: 0.00001441
Iteration 144/1000 | Loss: 0.00001441
Iteration 145/1000 | Loss: 0.00001441
Iteration 146/1000 | Loss: 0.00001441
Iteration 147/1000 | Loss: 0.00001441
Iteration 148/1000 | Loss: 0.00001441
Iteration 149/1000 | Loss: 0.00001441
Iteration 150/1000 | Loss: 0.00001441
Iteration 151/1000 | Loss: 0.00001441
Iteration 152/1000 | Loss: 0.00001441
Iteration 153/1000 | Loss: 0.00001441
Iteration 154/1000 | Loss: 0.00001441
Iteration 155/1000 | Loss: 0.00001441
Iteration 156/1000 | Loss: 0.00001441
Iteration 157/1000 | Loss: 0.00001441
Iteration 158/1000 | Loss: 0.00001441
Iteration 159/1000 | Loss: 0.00001441
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 159. Stopping optimization.
Last 5 losses: [1.4407321941689588e-05, 1.4407321941689588e-05, 1.4407321941689588e-05, 1.4407321941689588e-05, 1.4407321941689588e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4407321941689588e-05

Optimization complete. Final v2v error: 3.198791980743408 mm

Highest mean error: 4.112527370452881 mm for frame 73

Lowest mean error: 2.4409401416778564 mm for frame 148

Saving results

Total time: 45.64087915420532
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00698588
Iteration 2/25 | Loss: 0.00095525
Iteration 3/25 | Loss: 0.00085677
Iteration 4/25 | Loss: 0.00083912
Iteration 5/25 | Loss: 0.00083244
Iteration 6/25 | Loss: 0.00082960
Iteration 7/25 | Loss: 0.00082883
Iteration 8/25 | Loss: 0.00082883
Iteration 9/25 | Loss: 0.00082883
Iteration 10/25 | Loss: 0.00082883
Iteration 11/25 | Loss: 0.00082883
Iteration 12/25 | Loss: 0.00082883
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008288295357488096, 0.0008288295357488096, 0.0008288295357488096, 0.0008288295357488096, 0.0008288295357488096]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008288295357488096

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 8.86061192
Iteration 2/25 | Loss: 0.00084835
Iteration 3/25 | Loss: 0.00084832
Iteration 4/25 | Loss: 0.00084832
Iteration 5/25 | Loss: 0.00084832
Iteration 6/25 | Loss: 0.00084832
Iteration 7/25 | Loss: 0.00084832
Iteration 8/25 | Loss: 0.00084832
Iteration 9/25 | Loss: 0.00084832
Iteration 10/25 | Loss: 0.00084832
Iteration 11/25 | Loss: 0.00084832
Iteration 12/25 | Loss: 0.00084832
Iteration 13/25 | Loss: 0.00084832
Iteration 14/25 | Loss: 0.00084832
Iteration 15/25 | Loss: 0.00084831
Iteration 16/25 | Loss: 0.00084831
Iteration 17/25 | Loss: 0.00084831
Iteration 18/25 | Loss: 0.00084831
Iteration 19/25 | Loss: 0.00084831
Iteration 20/25 | Loss: 0.00084831
Iteration 21/25 | Loss: 0.00084831
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0008483148994855583, 0.0008483148994855583, 0.0008483148994855583, 0.0008483148994855583, 0.0008483148994855583]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008483148994855583

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00084831
Iteration 2/1000 | Loss: 0.00002579
Iteration 3/1000 | Loss: 0.00001429
Iteration 4/1000 | Loss: 0.00001189
Iteration 5/1000 | Loss: 0.00001100
Iteration 6/1000 | Loss: 0.00001056
Iteration 7/1000 | Loss: 0.00001021
Iteration 8/1000 | Loss: 0.00001007
Iteration 9/1000 | Loss: 0.00001005
Iteration 10/1000 | Loss: 0.00000990
Iteration 11/1000 | Loss: 0.00000980
Iteration 12/1000 | Loss: 0.00000978
Iteration 13/1000 | Loss: 0.00000976
Iteration 14/1000 | Loss: 0.00000976
Iteration 15/1000 | Loss: 0.00000973
Iteration 16/1000 | Loss: 0.00000971
Iteration 17/1000 | Loss: 0.00000971
Iteration 18/1000 | Loss: 0.00000970
Iteration 19/1000 | Loss: 0.00000970
Iteration 20/1000 | Loss: 0.00000969
Iteration 21/1000 | Loss: 0.00000969
Iteration 22/1000 | Loss: 0.00000969
Iteration 23/1000 | Loss: 0.00000968
Iteration 24/1000 | Loss: 0.00000965
Iteration 25/1000 | Loss: 0.00000965
Iteration 26/1000 | Loss: 0.00000965
Iteration 27/1000 | Loss: 0.00000964
Iteration 28/1000 | Loss: 0.00000964
Iteration 29/1000 | Loss: 0.00000964
Iteration 30/1000 | Loss: 0.00000963
Iteration 31/1000 | Loss: 0.00000963
Iteration 32/1000 | Loss: 0.00000963
Iteration 33/1000 | Loss: 0.00000963
Iteration 34/1000 | Loss: 0.00000962
Iteration 35/1000 | Loss: 0.00000961
Iteration 36/1000 | Loss: 0.00000961
Iteration 37/1000 | Loss: 0.00000961
Iteration 38/1000 | Loss: 0.00000961
Iteration 39/1000 | Loss: 0.00000960
Iteration 40/1000 | Loss: 0.00000960
Iteration 41/1000 | Loss: 0.00000960
Iteration 42/1000 | Loss: 0.00000960
Iteration 43/1000 | Loss: 0.00000960
Iteration 44/1000 | Loss: 0.00000960
Iteration 45/1000 | Loss: 0.00000960
Iteration 46/1000 | Loss: 0.00000960
Iteration 47/1000 | Loss: 0.00000960
Iteration 48/1000 | Loss: 0.00000959
Iteration 49/1000 | Loss: 0.00000959
Iteration 50/1000 | Loss: 0.00000959
Iteration 51/1000 | Loss: 0.00000959
Iteration 52/1000 | Loss: 0.00000959
Iteration 53/1000 | Loss: 0.00000957
Iteration 54/1000 | Loss: 0.00000957
Iteration 55/1000 | Loss: 0.00000957
Iteration 56/1000 | Loss: 0.00000957
Iteration 57/1000 | Loss: 0.00000956
Iteration 58/1000 | Loss: 0.00000956
Iteration 59/1000 | Loss: 0.00000956
Iteration 60/1000 | Loss: 0.00000955
Iteration 61/1000 | Loss: 0.00000955
Iteration 62/1000 | Loss: 0.00000955
Iteration 63/1000 | Loss: 0.00000955
Iteration 64/1000 | Loss: 0.00000955
Iteration 65/1000 | Loss: 0.00000955
Iteration 66/1000 | Loss: 0.00000955
Iteration 67/1000 | Loss: 0.00000954
Iteration 68/1000 | Loss: 0.00000954
Iteration 69/1000 | Loss: 0.00000954
Iteration 70/1000 | Loss: 0.00000954
Iteration 71/1000 | Loss: 0.00000954
Iteration 72/1000 | Loss: 0.00000954
Iteration 73/1000 | Loss: 0.00000954
Iteration 74/1000 | Loss: 0.00000954
Iteration 75/1000 | Loss: 0.00000954
Iteration 76/1000 | Loss: 0.00000954
Iteration 77/1000 | Loss: 0.00000954
Iteration 78/1000 | Loss: 0.00000954
Iteration 79/1000 | Loss: 0.00000954
Iteration 80/1000 | Loss: 0.00000954
Iteration 81/1000 | Loss: 0.00000954
Iteration 82/1000 | Loss: 0.00000954
Iteration 83/1000 | Loss: 0.00000954
Iteration 84/1000 | Loss: 0.00000954
Iteration 85/1000 | Loss: 0.00000954
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [9.540135579300113e-06, 9.540135579300113e-06, 9.540135579300113e-06, 9.540135579300113e-06, 9.540135579300113e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.540135579300113e-06

Optimization complete. Final v2v error: 2.669811725616455 mm

Highest mean error: 3.0050389766693115 mm for frame 48

Lowest mean error: 2.4255130290985107 mm for frame 166

Saving results

Total time: 30.099090099334717
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_25_nl_2229/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_25_nl_2229/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00983667
Iteration 2/25 | Loss: 0.00154992
Iteration 3/25 | Loss: 0.00123174
Iteration 4/25 | Loss: 0.00121234
Iteration 5/25 | Loss: 0.00120981
Iteration 6/25 | Loss: 0.00120903
Iteration 7/25 | Loss: 0.00120903
Iteration 8/25 | Loss: 0.00120903
Iteration 9/25 | Loss: 0.00120903
Iteration 10/25 | Loss: 0.00120903
Iteration 11/25 | Loss: 0.00120903
Iteration 12/25 | Loss: 0.00120903
Iteration 13/25 | Loss: 0.00120903
Iteration 14/25 | Loss: 0.00120903
Iteration 15/25 | Loss: 0.00120903
Iteration 16/25 | Loss: 0.00120903
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0012090335367247462, 0.0012090335367247462, 0.0012090335367247462, 0.0012090335367247462, 0.0012090335367247462]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012090335367247462

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.48307860
Iteration 2/25 | Loss: 0.00053635
Iteration 3/25 | Loss: 0.00053635
Iteration 4/25 | Loss: 0.00053634
Iteration 5/25 | Loss: 0.00053634
Iteration 6/25 | Loss: 0.00053634
Iteration 7/25 | Loss: 0.00053634
Iteration 8/25 | Loss: 0.00053634
Iteration 9/25 | Loss: 0.00053634
Iteration 10/25 | Loss: 0.00053634
Iteration 11/25 | Loss: 0.00053634
Iteration 12/25 | Loss: 0.00053634
Iteration 13/25 | Loss: 0.00053634
Iteration 14/25 | Loss: 0.00053634
Iteration 15/25 | Loss: 0.00053634
Iteration 16/25 | Loss: 0.00053634
Iteration 17/25 | Loss: 0.00053634
Iteration 18/25 | Loss: 0.00053634
Iteration 19/25 | Loss: 0.00053634
Iteration 20/25 | Loss: 0.00053634
Iteration 21/25 | Loss: 0.00053634
Iteration 22/25 | Loss: 0.00053634
Iteration 23/25 | Loss: 0.00053634
Iteration 24/25 | Loss: 0.00053634
Iteration 25/25 | Loss: 0.00053634

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053634
Iteration 2/1000 | Loss: 0.00007941
Iteration 3/1000 | Loss: 0.00005554
Iteration 4/1000 | Loss: 0.00004594
Iteration 5/1000 | Loss: 0.00004321
Iteration 6/1000 | Loss: 0.00004181
Iteration 7/1000 | Loss: 0.00004072
Iteration 8/1000 | Loss: 0.00003985
Iteration 9/1000 | Loss: 0.00003912
Iteration 10/1000 | Loss: 0.00003802
Iteration 11/1000 | Loss: 0.00003737
Iteration 12/1000 | Loss: 0.00003694
Iteration 13/1000 | Loss: 0.00003665
Iteration 14/1000 | Loss: 0.00003647
Iteration 15/1000 | Loss: 0.00003622
Iteration 16/1000 | Loss: 0.00003601
Iteration 17/1000 | Loss: 0.00003580
Iteration 18/1000 | Loss: 0.00003549
Iteration 19/1000 | Loss: 0.00003530
Iteration 20/1000 | Loss: 0.00003515
Iteration 21/1000 | Loss: 0.00003496
Iteration 22/1000 | Loss: 0.00003480
Iteration 23/1000 | Loss: 0.00003473
Iteration 24/1000 | Loss: 0.00003457
Iteration 25/1000 | Loss: 0.00003450
Iteration 26/1000 | Loss: 0.00003450
Iteration 27/1000 | Loss: 0.00003441
Iteration 28/1000 | Loss: 0.00003440
Iteration 29/1000 | Loss: 0.00003440
Iteration 30/1000 | Loss: 0.00003440
Iteration 31/1000 | Loss: 0.00003440
Iteration 32/1000 | Loss: 0.00003440
Iteration 33/1000 | Loss: 0.00003440
Iteration 34/1000 | Loss: 0.00003439
Iteration 35/1000 | Loss: 0.00003439
Iteration 36/1000 | Loss: 0.00003439
Iteration 37/1000 | Loss: 0.00003438
Iteration 38/1000 | Loss: 0.00003437
Iteration 39/1000 | Loss: 0.00003437
Iteration 40/1000 | Loss: 0.00003436
Iteration 41/1000 | Loss: 0.00003436
Iteration 42/1000 | Loss: 0.00003436
Iteration 43/1000 | Loss: 0.00003436
Iteration 44/1000 | Loss: 0.00003436
Iteration 45/1000 | Loss: 0.00003435
Iteration 46/1000 | Loss: 0.00003434
Iteration 47/1000 | Loss: 0.00003434
Iteration 48/1000 | Loss: 0.00003434
Iteration 49/1000 | Loss: 0.00003431
Iteration 50/1000 | Loss: 0.00003431
Iteration 51/1000 | Loss: 0.00003430
Iteration 52/1000 | Loss: 0.00003430
Iteration 53/1000 | Loss: 0.00003429
Iteration 54/1000 | Loss: 0.00003429
Iteration 55/1000 | Loss: 0.00003429
Iteration 56/1000 | Loss: 0.00003427
Iteration 57/1000 | Loss: 0.00003426
Iteration 58/1000 | Loss: 0.00003426
Iteration 59/1000 | Loss: 0.00003426
Iteration 60/1000 | Loss: 0.00003425
Iteration 61/1000 | Loss: 0.00003425
Iteration 62/1000 | Loss: 0.00003425
Iteration 63/1000 | Loss: 0.00003425
Iteration 64/1000 | Loss: 0.00003425
Iteration 65/1000 | Loss: 0.00003425
Iteration 66/1000 | Loss: 0.00003425
Iteration 67/1000 | Loss: 0.00003425
Iteration 68/1000 | Loss: 0.00003425
Iteration 69/1000 | Loss: 0.00003425
Iteration 70/1000 | Loss: 0.00003425
Iteration 71/1000 | Loss: 0.00003425
Iteration 72/1000 | Loss: 0.00003424
Iteration 73/1000 | Loss: 0.00003424
Iteration 74/1000 | Loss: 0.00003424
Iteration 75/1000 | Loss: 0.00003424
Iteration 76/1000 | Loss: 0.00003424
Iteration 77/1000 | Loss: 0.00003423
Iteration 78/1000 | Loss: 0.00003423
Iteration 79/1000 | Loss: 0.00003423
Iteration 80/1000 | Loss: 0.00003423
Iteration 81/1000 | Loss: 0.00003423
Iteration 82/1000 | Loss: 0.00003423
Iteration 83/1000 | Loss: 0.00003423
Iteration 84/1000 | Loss: 0.00003423
Iteration 85/1000 | Loss: 0.00003423
Iteration 86/1000 | Loss: 0.00003422
Iteration 87/1000 | Loss: 0.00003422
Iteration 88/1000 | Loss: 0.00003422
Iteration 89/1000 | Loss: 0.00003422
Iteration 90/1000 | Loss: 0.00003422
Iteration 91/1000 | Loss: 0.00003422
Iteration 92/1000 | Loss: 0.00003422
Iteration 93/1000 | Loss: 0.00003422
Iteration 94/1000 | Loss: 0.00003422
Iteration 95/1000 | Loss: 0.00003421
Iteration 96/1000 | Loss: 0.00003421
Iteration 97/1000 | Loss: 0.00003421
Iteration 98/1000 | Loss: 0.00003421
Iteration 99/1000 | Loss: 0.00003421
Iteration 100/1000 | Loss: 0.00003421
Iteration 101/1000 | Loss: 0.00003421
Iteration 102/1000 | Loss: 0.00003421
Iteration 103/1000 | Loss: 0.00003421
Iteration 104/1000 | Loss: 0.00003421
Iteration 105/1000 | Loss: 0.00003421
Iteration 106/1000 | Loss: 0.00003420
Iteration 107/1000 | Loss: 0.00003420
Iteration 108/1000 | Loss: 0.00003420
Iteration 109/1000 | Loss: 0.00003420
Iteration 110/1000 | Loss: 0.00003420
Iteration 111/1000 | Loss: 0.00003420
Iteration 112/1000 | Loss: 0.00003420
Iteration 113/1000 | Loss: 0.00003420
Iteration 114/1000 | Loss: 0.00003420
Iteration 115/1000 | Loss: 0.00003419
Iteration 116/1000 | Loss: 0.00003419
Iteration 117/1000 | Loss: 0.00003419
Iteration 118/1000 | Loss: 0.00003419
Iteration 119/1000 | Loss: 0.00003419
Iteration 120/1000 | Loss: 0.00003419
Iteration 121/1000 | Loss: 0.00003419
Iteration 122/1000 | Loss: 0.00003419
Iteration 123/1000 | Loss: 0.00003418
Iteration 124/1000 | Loss: 0.00003418
Iteration 125/1000 | Loss: 0.00003418
Iteration 126/1000 | Loss: 0.00003418
Iteration 127/1000 | Loss: 0.00003418
Iteration 128/1000 | Loss: 0.00003418
Iteration 129/1000 | Loss: 0.00003418
Iteration 130/1000 | Loss: 0.00003418
Iteration 131/1000 | Loss: 0.00003418
Iteration 132/1000 | Loss: 0.00003418
Iteration 133/1000 | Loss: 0.00003418
Iteration 134/1000 | Loss: 0.00003418
Iteration 135/1000 | Loss: 0.00003418
Iteration 136/1000 | Loss: 0.00003418
Iteration 137/1000 | Loss: 0.00003418
Iteration 138/1000 | Loss: 0.00003418
Iteration 139/1000 | Loss: 0.00003418
Iteration 140/1000 | Loss: 0.00003418
Iteration 141/1000 | Loss: 0.00003418
Iteration 142/1000 | Loss: 0.00003418
Iteration 143/1000 | Loss: 0.00003418
Iteration 144/1000 | Loss: 0.00003418
Iteration 145/1000 | Loss: 0.00003418
Iteration 146/1000 | Loss: 0.00003418
Iteration 147/1000 | Loss: 0.00003418
Iteration 148/1000 | Loss: 0.00003418
Iteration 149/1000 | Loss: 0.00003418
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 149. Stopping optimization.
Last 5 losses: [3.417785046622157e-05, 3.417785046622157e-05, 3.417785046622157e-05, 3.417785046622157e-05, 3.417785046622157e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.417785046622157e-05

Optimization complete. Final v2v error: 4.814827919006348 mm

Highest mean error: 4.99835729598999 mm for frame 103

Lowest mean error: 4.360696792602539 mm for frame 14

Saving results

Total time: 52.884241819381714
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00508864
Iteration 2/25 | Loss: 0.00146420
Iteration 3/25 | Loss: 0.00128418
Iteration 4/25 | Loss: 0.00126722
Iteration 5/25 | Loss: 0.00126246
Iteration 6/25 | Loss: 0.00126084
Iteration 7/25 | Loss: 0.00126037
Iteration 8/25 | Loss: 0.00126037
Iteration 9/25 | Loss: 0.00126037
Iteration 10/25 | Loss: 0.00126037
Iteration 11/25 | Loss: 0.00126037
Iteration 12/25 | Loss: 0.00126037
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001260368269868195, 0.001260368269868195, 0.001260368269868195, 0.001260368269868195, 0.001260368269868195]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001260368269868195

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.17322457
Iteration 2/25 | Loss: 0.00300256
Iteration 3/25 | Loss: 0.00300256
Iteration 4/25 | Loss: 0.00300256
Iteration 5/25 | Loss: 0.00300256
Iteration 6/25 | Loss: 0.00300256
Iteration 7/25 | Loss: 0.00300256
Iteration 8/25 | Loss: 0.00300256
Iteration 9/25 | Loss: 0.00300256
Iteration 10/25 | Loss: 0.00300255
Iteration 11/25 | Loss: 0.00300255
Iteration 12/25 | Loss: 0.00300255
Iteration 13/25 | Loss: 0.00300255
Iteration 14/25 | Loss: 0.00300255
Iteration 15/25 | Loss: 0.00300255
Iteration 16/25 | Loss: 0.00300255
Iteration 17/25 | Loss: 0.00300255
Iteration 18/25 | Loss: 0.00300255
Iteration 19/25 | Loss: 0.00300255
Iteration 20/25 | Loss: 0.00300255
Iteration 21/25 | Loss: 0.00300255
Iteration 22/25 | Loss: 0.00300255
Iteration 23/25 | Loss: 0.00300255
Iteration 24/25 | Loss: 0.00300255
Iteration 25/25 | Loss: 0.00300255

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00300255
Iteration 2/1000 | Loss: 0.00007748
Iteration 3/1000 | Loss: 0.00004399
Iteration 4/1000 | Loss: 0.00003314
Iteration 5/1000 | Loss: 0.00003059
Iteration 6/1000 | Loss: 0.00002920
Iteration 7/1000 | Loss: 0.00002842
Iteration 8/1000 | Loss: 0.00002770
Iteration 9/1000 | Loss: 0.00002723
Iteration 10/1000 | Loss: 0.00002684
Iteration 11/1000 | Loss: 0.00002653
Iteration 12/1000 | Loss: 0.00002629
Iteration 13/1000 | Loss: 0.00002612
Iteration 14/1000 | Loss: 0.00002598
Iteration 15/1000 | Loss: 0.00002586
Iteration 16/1000 | Loss: 0.00002580
Iteration 17/1000 | Loss: 0.00002573
Iteration 18/1000 | Loss: 0.00002572
Iteration 19/1000 | Loss: 0.00002570
Iteration 20/1000 | Loss: 0.00002566
Iteration 21/1000 | Loss: 0.00002566
Iteration 22/1000 | Loss: 0.00002563
Iteration 23/1000 | Loss: 0.00002561
Iteration 24/1000 | Loss: 0.00002561
Iteration 25/1000 | Loss: 0.00002557
Iteration 26/1000 | Loss: 0.00002556
Iteration 27/1000 | Loss: 0.00002556
Iteration 28/1000 | Loss: 0.00002555
Iteration 29/1000 | Loss: 0.00002554
Iteration 30/1000 | Loss: 0.00002554
Iteration 31/1000 | Loss: 0.00002554
Iteration 32/1000 | Loss: 0.00002554
Iteration 33/1000 | Loss: 0.00002554
Iteration 34/1000 | Loss: 0.00002554
Iteration 35/1000 | Loss: 0.00002554
Iteration 36/1000 | Loss: 0.00002553
Iteration 37/1000 | Loss: 0.00002553
Iteration 38/1000 | Loss: 0.00002552
Iteration 39/1000 | Loss: 0.00002552
Iteration 40/1000 | Loss: 0.00002552
Iteration 41/1000 | Loss: 0.00002551
Iteration 42/1000 | Loss: 0.00002550
Iteration 43/1000 | Loss: 0.00002550
Iteration 44/1000 | Loss: 0.00002550
Iteration 45/1000 | Loss: 0.00002550
Iteration 46/1000 | Loss: 0.00002548
Iteration 47/1000 | Loss: 0.00002548
Iteration 48/1000 | Loss: 0.00002548
Iteration 49/1000 | Loss: 0.00002548
Iteration 50/1000 | Loss: 0.00002548
Iteration 51/1000 | Loss: 0.00002548
Iteration 52/1000 | Loss: 0.00002548
Iteration 53/1000 | Loss: 0.00002548
Iteration 54/1000 | Loss: 0.00002548
Iteration 55/1000 | Loss: 0.00002548
Iteration 56/1000 | Loss: 0.00002547
Iteration 57/1000 | Loss: 0.00002547
Iteration 58/1000 | Loss: 0.00002546
Iteration 59/1000 | Loss: 0.00002546
Iteration 60/1000 | Loss: 0.00002546
Iteration 61/1000 | Loss: 0.00002545
Iteration 62/1000 | Loss: 0.00002545
Iteration 63/1000 | Loss: 0.00002545
Iteration 64/1000 | Loss: 0.00002544
Iteration 65/1000 | Loss: 0.00002544
Iteration 66/1000 | Loss: 0.00002543
Iteration 67/1000 | Loss: 0.00002543
Iteration 68/1000 | Loss: 0.00002543
Iteration 69/1000 | Loss: 0.00002543
Iteration 70/1000 | Loss: 0.00002543
Iteration 71/1000 | Loss: 0.00002543
Iteration 72/1000 | Loss: 0.00002543
Iteration 73/1000 | Loss: 0.00002543
Iteration 74/1000 | Loss: 0.00002543
Iteration 75/1000 | Loss: 0.00002543
Iteration 76/1000 | Loss: 0.00002543
Iteration 77/1000 | Loss: 0.00002543
Iteration 78/1000 | Loss: 0.00002543
Iteration 79/1000 | Loss: 0.00002542
Iteration 80/1000 | Loss: 0.00002542
Iteration 81/1000 | Loss: 0.00002542
Iteration 82/1000 | Loss: 0.00002542
Iteration 83/1000 | Loss: 0.00002542
Iteration 84/1000 | Loss: 0.00002542
Iteration 85/1000 | Loss: 0.00002542
Iteration 86/1000 | Loss: 0.00002542
Iteration 87/1000 | Loss: 0.00002542
Iteration 88/1000 | Loss: 0.00002542
Iteration 89/1000 | Loss: 0.00002542
Iteration 90/1000 | Loss: 0.00002542
Iteration 91/1000 | Loss: 0.00002541
Iteration 92/1000 | Loss: 0.00002541
Iteration 93/1000 | Loss: 0.00002541
Iteration 94/1000 | Loss: 0.00002541
Iteration 95/1000 | Loss: 0.00002540
Iteration 96/1000 | Loss: 0.00002540
Iteration 97/1000 | Loss: 0.00002540
Iteration 98/1000 | Loss: 0.00002540
Iteration 99/1000 | Loss: 0.00002540
Iteration 100/1000 | Loss: 0.00002540
Iteration 101/1000 | Loss: 0.00002539
Iteration 102/1000 | Loss: 0.00002539
Iteration 103/1000 | Loss: 0.00002539
Iteration 104/1000 | Loss: 0.00002539
Iteration 105/1000 | Loss: 0.00002539
Iteration 106/1000 | Loss: 0.00002539
Iteration 107/1000 | Loss: 0.00002539
Iteration 108/1000 | Loss: 0.00002538
Iteration 109/1000 | Loss: 0.00002538
Iteration 110/1000 | Loss: 0.00002538
Iteration 111/1000 | Loss: 0.00002538
Iteration 112/1000 | Loss: 0.00002537
Iteration 113/1000 | Loss: 0.00002537
Iteration 114/1000 | Loss: 0.00002537
Iteration 115/1000 | Loss: 0.00002537
Iteration 116/1000 | Loss: 0.00002536
Iteration 117/1000 | Loss: 0.00002536
Iteration 118/1000 | Loss: 0.00002535
Iteration 119/1000 | Loss: 0.00002535
Iteration 120/1000 | Loss: 0.00002535
Iteration 121/1000 | Loss: 0.00002535
Iteration 122/1000 | Loss: 0.00002535
Iteration 123/1000 | Loss: 0.00002535
Iteration 124/1000 | Loss: 0.00002535
Iteration 125/1000 | Loss: 0.00002535
Iteration 126/1000 | Loss: 0.00002535
Iteration 127/1000 | Loss: 0.00002535
Iteration 128/1000 | Loss: 0.00002535
Iteration 129/1000 | Loss: 0.00002534
Iteration 130/1000 | Loss: 0.00002534
Iteration 131/1000 | Loss: 0.00002534
Iteration 132/1000 | Loss: 0.00002534
Iteration 133/1000 | Loss: 0.00002534
Iteration 134/1000 | Loss: 0.00002534
Iteration 135/1000 | Loss: 0.00002533
Iteration 136/1000 | Loss: 0.00002533
Iteration 137/1000 | Loss: 0.00002533
Iteration 138/1000 | Loss: 0.00002532
Iteration 139/1000 | Loss: 0.00002532
Iteration 140/1000 | Loss: 0.00002532
Iteration 141/1000 | Loss: 0.00002532
Iteration 142/1000 | Loss: 0.00002532
Iteration 143/1000 | Loss: 0.00002532
Iteration 144/1000 | Loss: 0.00002532
Iteration 145/1000 | Loss: 0.00002532
Iteration 146/1000 | Loss: 0.00002532
Iteration 147/1000 | Loss: 0.00002532
Iteration 148/1000 | Loss: 0.00002532
Iteration 149/1000 | Loss: 0.00002532
Iteration 150/1000 | Loss: 0.00002532
Iteration 151/1000 | Loss: 0.00002532
Iteration 152/1000 | Loss: 0.00002532
Iteration 153/1000 | Loss: 0.00002532
Iteration 154/1000 | Loss: 0.00002532
Iteration 155/1000 | Loss: 0.00002532
Iteration 156/1000 | Loss: 0.00002532
Iteration 157/1000 | Loss: 0.00002532
Iteration 158/1000 | Loss: 0.00002532
Iteration 159/1000 | Loss: 0.00002532
Iteration 160/1000 | Loss: 0.00002532
Iteration 161/1000 | Loss: 0.00002532
Iteration 162/1000 | Loss: 0.00002532
Iteration 163/1000 | Loss: 0.00002532
Iteration 164/1000 | Loss: 0.00002532
Iteration 165/1000 | Loss: 0.00002532
Iteration 166/1000 | Loss: 0.00002532
Iteration 167/1000 | Loss: 0.00002532
Iteration 168/1000 | Loss: 0.00002532
Iteration 169/1000 | Loss: 0.00002532
Iteration 170/1000 | Loss: 0.00002531
Iteration 171/1000 | Loss: 0.00002531
Iteration 172/1000 | Loss: 0.00002531
Iteration 173/1000 | Loss: 0.00002531
Iteration 174/1000 | Loss: 0.00002531
Iteration 175/1000 | Loss: 0.00002531
Iteration 176/1000 | Loss: 0.00002531
Iteration 177/1000 | Loss: 0.00002531
Iteration 178/1000 | Loss: 0.00002531
Iteration 179/1000 | Loss: 0.00002531
Iteration 180/1000 | Loss: 0.00002531
Iteration 181/1000 | Loss: 0.00002531
Iteration 182/1000 | Loss: 0.00002531
Iteration 183/1000 | Loss: 0.00002531
Iteration 184/1000 | Loss: 0.00002531
Iteration 185/1000 | Loss: 0.00002531
Iteration 186/1000 | Loss: 0.00002531
Iteration 187/1000 | Loss: 0.00002531
Iteration 188/1000 | Loss: 0.00002531
Iteration 189/1000 | Loss: 0.00002531
Iteration 190/1000 | Loss: 0.00002531
Iteration 191/1000 | Loss: 0.00002531
Iteration 192/1000 | Loss: 0.00002531
Iteration 193/1000 | Loss: 0.00002531
Iteration 194/1000 | Loss: 0.00002531
Iteration 195/1000 | Loss: 0.00002531
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 195. Stopping optimization.
Last 5 losses: [2.5313434889540076e-05, 2.5313434889540076e-05, 2.5313434889540076e-05, 2.5313434889540076e-05, 2.5313434889540076e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5313434889540076e-05

Optimization complete. Final v2v error: 3.972998857498169 mm

Highest mean error: 5.4687676429748535 mm for frame 106

Lowest mean error: 2.9206671714782715 mm for frame 78

Saving results

Total time: 46.02553057670593
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00903972
Iteration 2/25 | Loss: 0.00142883
Iteration 3/25 | Loss: 0.00132723
Iteration 4/25 | Loss: 0.00130332
Iteration 5/25 | Loss: 0.00129228
Iteration 6/25 | Loss: 0.00128980
Iteration 7/25 | Loss: 0.00128980
Iteration 8/25 | Loss: 0.00128980
Iteration 9/25 | Loss: 0.00128980
Iteration 10/25 | Loss: 0.00128980
Iteration 11/25 | Loss: 0.00128980
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0012898043496534228, 0.0012898043496534228, 0.0012898043496534228, 0.0012898043496534228, 0.0012898043496534228]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012898043496534228

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.14776134
Iteration 2/25 | Loss: 0.00297435
Iteration 3/25 | Loss: 0.00297435
Iteration 4/25 | Loss: 0.00297435
Iteration 5/25 | Loss: 0.00297435
Iteration 6/25 | Loss: 0.00297435
Iteration 7/25 | Loss: 0.00297435
Iteration 8/25 | Loss: 0.00297435
Iteration 9/25 | Loss: 0.00297435
Iteration 10/25 | Loss: 0.00297435
Iteration 11/25 | Loss: 0.00297435
Iteration 12/25 | Loss: 0.00297435
Iteration 13/25 | Loss: 0.00297435
Iteration 14/25 | Loss: 0.00297435
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0029743497725576162, 0.0029743497725576162, 0.0029743497725576162, 0.0029743497725576162, 0.0029743497725576162]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0029743497725576162

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00297435
Iteration 2/1000 | Loss: 0.00003681
Iteration 3/1000 | Loss: 0.00002627
Iteration 4/1000 | Loss: 0.00002485
Iteration 5/1000 | Loss: 0.00002357
Iteration 6/1000 | Loss: 0.00002234
Iteration 7/1000 | Loss: 0.00002169
Iteration 8/1000 | Loss: 0.00002144
Iteration 9/1000 | Loss: 0.00002117
Iteration 10/1000 | Loss: 0.00002095
Iteration 11/1000 | Loss: 0.00002092
Iteration 12/1000 | Loss: 0.00002090
Iteration 13/1000 | Loss: 0.00002089
Iteration 14/1000 | Loss: 0.00002083
Iteration 15/1000 | Loss: 0.00002076
Iteration 16/1000 | Loss: 0.00002075
Iteration 17/1000 | Loss: 0.00002075
Iteration 18/1000 | Loss: 0.00002075
Iteration 19/1000 | Loss: 0.00002075
Iteration 20/1000 | Loss: 0.00002075
Iteration 21/1000 | Loss: 0.00002075
Iteration 22/1000 | Loss: 0.00002075
Iteration 23/1000 | Loss: 0.00002075
Iteration 24/1000 | Loss: 0.00002075
Iteration 25/1000 | Loss: 0.00002075
Iteration 26/1000 | Loss: 0.00002074
Iteration 27/1000 | Loss: 0.00002074
Iteration 28/1000 | Loss: 0.00002069
Iteration 29/1000 | Loss: 0.00002069
Iteration 30/1000 | Loss: 0.00002069
Iteration 31/1000 | Loss: 0.00002069
Iteration 32/1000 | Loss: 0.00002068
Iteration 33/1000 | Loss: 0.00002068
Iteration 34/1000 | Loss: 0.00002063
Iteration 35/1000 | Loss: 0.00002063
Iteration 36/1000 | Loss: 0.00002063
Iteration 37/1000 | Loss: 0.00002062
Iteration 38/1000 | Loss: 0.00002061
Iteration 39/1000 | Loss: 0.00002060
Iteration 40/1000 | Loss: 0.00002060
Iteration 41/1000 | Loss: 0.00002059
Iteration 42/1000 | Loss: 0.00002059
Iteration 43/1000 | Loss: 0.00002058
Iteration 44/1000 | Loss: 0.00002058
Iteration 45/1000 | Loss: 0.00002058
Iteration 46/1000 | Loss: 0.00002058
Iteration 47/1000 | Loss: 0.00002057
Iteration 48/1000 | Loss: 0.00002057
Iteration 49/1000 | Loss: 0.00002057
Iteration 50/1000 | Loss: 0.00002056
Iteration 51/1000 | Loss: 0.00002056
Iteration 52/1000 | Loss: 0.00002056
Iteration 53/1000 | Loss: 0.00002055
Iteration 54/1000 | Loss: 0.00002055
Iteration 55/1000 | Loss: 0.00002054
Iteration 56/1000 | Loss: 0.00002054
Iteration 57/1000 | Loss: 0.00002053
Iteration 58/1000 | Loss: 0.00002053
Iteration 59/1000 | Loss: 0.00002053
Iteration 60/1000 | Loss: 0.00002053
Iteration 61/1000 | Loss: 0.00002053
Iteration 62/1000 | Loss: 0.00002053
Iteration 63/1000 | Loss: 0.00002053
Iteration 64/1000 | Loss: 0.00002053
Iteration 65/1000 | Loss: 0.00002053
Iteration 66/1000 | Loss: 0.00002053
Iteration 67/1000 | Loss: 0.00002053
Iteration 68/1000 | Loss: 0.00002053
Iteration 69/1000 | Loss: 0.00002052
Iteration 70/1000 | Loss: 0.00002052
Iteration 71/1000 | Loss: 0.00002052
Iteration 72/1000 | Loss: 0.00002052
Iteration 73/1000 | Loss: 0.00002052
Iteration 74/1000 | Loss: 0.00002052
Iteration 75/1000 | Loss: 0.00002051
Iteration 76/1000 | Loss: 0.00002051
Iteration 77/1000 | Loss: 0.00002051
Iteration 78/1000 | Loss: 0.00002051
Iteration 79/1000 | Loss: 0.00002051
Iteration 80/1000 | Loss: 0.00002051
Iteration 81/1000 | Loss: 0.00002050
Iteration 82/1000 | Loss: 0.00002050
Iteration 83/1000 | Loss: 0.00002050
Iteration 84/1000 | Loss: 0.00002050
Iteration 85/1000 | Loss: 0.00002050
Iteration 86/1000 | Loss: 0.00002050
Iteration 87/1000 | Loss: 0.00002050
Iteration 88/1000 | Loss: 0.00002050
Iteration 89/1000 | Loss: 0.00002050
Iteration 90/1000 | Loss: 0.00002050
Iteration 91/1000 | Loss: 0.00002050
Iteration 92/1000 | Loss: 0.00002050
Iteration 93/1000 | Loss: 0.00002050
Iteration 94/1000 | Loss: 0.00002050
Iteration 95/1000 | Loss: 0.00002050
Iteration 96/1000 | Loss: 0.00002050
Iteration 97/1000 | Loss: 0.00002050
Iteration 98/1000 | Loss: 0.00002050
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 98. Stopping optimization.
Last 5 losses: [2.0502950064837933e-05, 2.0502950064837933e-05, 2.0502950064837933e-05, 2.0502950064837933e-05, 2.0502950064837933e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0502950064837933e-05

Optimization complete. Final v2v error: 3.81774640083313 mm

Highest mean error: 4.115686416625977 mm for frame 36

Lowest mean error: 3.5228395462036133 mm for frame 175

Saving results

Total time: 34.07943654060364
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00568117
Iteration 2/25 | Loss: 0.00145468
Iteration 3/25 | Loss: 0.00127016
Iteration 4/25 | Loss: 0.00118305
Iteration 5/25 | Loss: 0.00118079
Iteration 6/25 | Loss: 0.00118221
Iteration 7/25 | Loss: 0.00118051
Iteration 8/25 | Loss: 0.00117992
Iteration 9/25 | Loss: 0.00117914
Iteration 10/25 | Loss: 0.00117846
Iteration 11/25 | Loss: 0.00117825
Iteration 12/25 | Loss: 0.00117814
Iteration 13/25 | Loss: 0.00117811
Iteration 14/25 | Loss: 0.00117809
Iteration 15/25 | Loss: 0.00117809
Iteration 16/25 | Loss: 0.00117809
Iteration 17/25 | Loss: 0.00117809
Iteration 18/25 | Loss: 0.00117809
Iteration 19/25 | Loss: 0.00117808
Iteration 20/25 | Loss: 0.00117808
Iteration 21/25 | Loss: 0.00117808
Iteration 22/25 | Loss: 0.00117808
Iteration 23/25 | Loss: 0.00117808
Iteration 24/25 | Loss: 0.00117808
Iteration 25/25 | Loss: 0.00117808

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.02388000
Iteration 2/25 | Loss: 0.00254335
Iteration 3/25 | Loss: 0.00252749
Iteration 4/25 | Loss: 0.00252749
Iteration 5/25 | Loss: 0.00252749
Iteration 6/25 | Loss: 0.00252749
Iteration 7/25 | Loss: 0.00252749
Iteration 8/25 | Loss: 0.00252749
Iteration 9/25 | Loss: 0.00252749
Iteration 10/25 | Loss: 0.00252749
Iteration 11/25 | Loss: 0.00252749
Iteration 12/25 | Loss: 0.00252749
Iteration 13/25 | Loss: 0.00252749
Iteration 14/25 | Loss: 0.00252749
Iteration 15/25 | Loss: 0.00252749
Iteration 16/25 | Loss: 0.00252749
Iteration 17/25 | Loss: 0.00252749
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0025274851359426975, 0.0025274851359426975, 0.0025274851359426975, 0.0025274851359426975, 0.0025274851359426975]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0025274851359426975

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00252749
Iteration 2/1000 | Loss: 0.00003839
Iteration 3/1000 | Loss: 0.00001716
Iteration 4/1000 | Loss: 0.00001533
Iteration 5/1000 | Loss: 0.00001436
Iteration 6/1000 | Loss: 0.00001364
Iteration 7/1000 | Loss: 0.00001304
Iteration 8/1000 | Loss: 0.00001262
Iteration 9/1000 | Loss: 0.00001233
Iteration 10/1000 | Loss: 0.00001214
Iteration 11/1000 | Loss: 0.00001209
Iteration 12/1000 | Loss: 0.00001209
Iteration 13/1000 | Loss: 0.00001208
Iteration 14/1000 | Loss: 0.00001207
Iteration 15/1000 | Loss: 0.00001198
Iteration 16/1000 | Loss: 0.00001193
Iteration 17/1000 | Loss: 0.00001192
Iteration 18/1000 | Loss: 0.00001191
Iteration 19/1000 | Loss: 0.00001190
Iteration 20/1000 | Loss: 0.00001184
Iteration 21/1000 | Loss: 0.00001182
Iteration 22/1000 | Loss: 0.00001178
Iteration 23/1000 | Loss: 0.00001177
Iteration 24/1000 | Loss: 0.00001177
Iteration 25/1000 | Loss: 0.00001176
Iteration 26/1000 | Loss: 0.00001173
Iteration 27/1000 | Loss: 0.00001172
Iteration 28/1000 | Loss: 0.00001171
Iteration 29/1000 | Loss: 0.00001171
Iteration 30/1000 | Loss: 0.00001168
Iteration 31/1000 | Loss: 0.00001165
Iteration 32/1000 | Loss: 0.00001165
Iteration 33/1000 | Loss: 0.00001165
Iteration 34/1000 | Loss: 0.00001165
Iteration 35/1000 | Loss: 0.00001165
Iteration 36/1000 | Loss: 0.00001164
Iteration 37/1000 | Loss: 0.00001164
Iteration 38/1000 | Loss: 0.00001164
Iteration 39/1000 | Loss: 0.00001164
Iteration 40/1000 | Loss: 0.00001164
Iteration 41/1000 | Loss: 0.00001164
Iteration 42/1000 | Loss: 0.00001161
Iteration 43/1000 | Loss: 0.00001161
Iteration 44/1000 | Loss: 0.00001161
Iteration 45/1000 | Loss: 0.00001161
Iteration 46/1000 | Loss: 0.00001161
Iteration 47/1000 | Loss: 0.00001160
Iteration 48/1000 | Loss: 0.00001160
Iteration 49/1000 | Loss: 0.00001160
Iteration 50/1000 | Loss: 0.00001159
Iteration 51/1000 | Loss: 0.00001159
Iteration 52/1000 | Loss: 0.00001159
Iteration 53/1000 | Loss: 0.00001158
Iteration 54/1000 | Loss: 0.00001158
Iteration 55/1000 | Loss: 0.00001158
Iteration 56/1000 | Loss: 0.00001157
Iteration 57/1000 | Loss: 0.00001157
Iteration 58/1000 | Loss: 0.00001157
Iteration 59/1000 | Loss: 0.00001157
Iteration 60/1000 | Loss: 0.00001156
Iteration 61/1000 | Loss: 0.00001155
Iteration 62/1000 | Loss: 0.00001155
Iteration 63/1000 | Loss: 0.00001154
Iteration 64/1000 | Loss: 0.00001154
Iteration 65/1000 | Loss: 0.00001154
Iteration 66/1000 | Loss: 0.00001154
Iteration 67/1000 | Loss: 0.00001153
Iteration 68/1000 | Loss: 0.00001153
Iteration 69/1000 | Loss: 0.00001153
Iteration 70/1000 | Loss: 0.00001153
Iteration 71/1000 | Loss: 0.00001153
Iteration 72/1000 | Loss: 0.00001153
Iteration 73/1000 | Loss: 0.00001153
Iteration 74/1000 | Loss: 0.00001153
Iteration 75/1000 | Loss: 0.00001153
Iteration 76/1000 | Loss: 0.00001152
Iteration 77/1000 | Loss: 0.00001152
Iteration 78/1000 | Loss: 0.00001151
Iteration 79/1000 | Loss: 0.00001151
Iteration 80/1000 | Loss: 0.00001151
Iteration 81/1000 | Loss: 0.00001151
Iteration 82/1000 | Loss: 0.00001151
Iteration 83/1000 | Loss: 0.00001151
Iteration 84/1000 | Loss: 0.00001151
Iteration 85/1000 | Loss: 0.00001151
Iteration 86/1000 | Loss: 0.00001151
Iteration 87/1000 | Loss: 0.00001151
Iteration 88/1000 | Loss: 0.00001151
Iteration 89/1000 | Loss: 0.00001150
Iteration 90/1000 | Loss: 0.00001150
Iteration 91/1000 | Loss: 0.00001150
Iteration 92/1000 | Loss: 0.00001150
Iteration 93/1000 | Loss: 0.00001150
Iteration 94/1000 | Loss: 0.00001150
Iteration 95/1000 | Loss: 0.00001150
Iteration 96/1000 | Loss: 0.00001150
Iteration 97/1000 | Loss: 0.00001149
Iteration 98/1000 | Loss: 0.00001149
Iteration 99/1000 | Loss: 0.00001149
Iteration 100/1000 | Loss: 0.00001148
Iteration 101/1000 | Loss: 0.00001148
Iteration 102/1000 | Loss: 0.00001148
Iteration 103/1000 | Loss: 0.00001148
Iteration 104/1000 | Loss: 0.00001148
Iteration 105/1000 | Loss: 0.00001148
Iteration 106/1000 | Loss: 0.00001148
Iteration 107/1000 | Loss: 0.00001148
Iteration 108/1000 | Loss: 0.00001148
Iteration 109/1000 | Loss: 0.00001148
Iteration 110/1000 | Loss: 0.00001148
Iteration 111/1000 | Loss: 0.00001148
Iteration 112/1000 | Loss: 0.00001148
Iteration 113/1000 | Loss: 0.00001147
Iteration 114/1000 | Loss: 0.00001147
Iteration 115/1000 | Loss: 0.00001147
Iteration 116/1000 | Loss: 0.00001147
Iteration 117/1000 | Loss: 0.00001147
Iteration 118/1000 | Loss: 0.00001147
Iteration 119/1000 | Loss: 0.00001147
Iteration 120/1000 | Loss: 0.00001147
Iteration 121/1000 | Loss: 0.00001147
Iteration 122/1000 | Loss: 0.00001147
Iteration 123/1000 | Loss: 0.00001147
Iteration 124/1000 | Loss: 0.00001147
Iteration 125/1000 | Loss: 0.00001147
Iteration 126/1000 | Loss: 0.00001147
Iteration 127/1000 | Loss: 0.00001146
Iteration 128/1000 | Loss: 0.00001146
Iteration 129/1000 | Loss: 0.00001146
Iteration 130/1000 | Loss: 0.00001146
Iteration 131/1000 | Loss: 0.00001146
Iteration 132/1000 | Loss: 0.00001146
Iteration 133/1000 | Loss: 0.00001146
Iteration 134/1000 | Loss: 0.00001146
Iteration 135/1000 | Loss: 0.00001146
Iteration 136/1000 | Loss: 0.00001146
Iteration 137/1000 | Loss: 0.00001146
Iteration 138/1000 | Loss: 0.00001145
Iteration 139/1000 | Loss: 0.00001145
Iteration 140/1000 | Loss: 0.00001145
Iteration 141/1000 | Loss: 0.00001145
Iteration 142/1000 | Loss: 0.00001145
Iteration 143/1000 | Loss: 0.00001145
Iteration 144/1000 | Loss: 0.00001145
Iteration 145/1000 | Loss: 0.00001145
Iteration 146/1000 | Loss: 0.00001145
Iteration 147/1000 | Loss: 0.00001145
Iteration 148/1000 | Loss: 0.00001145
Iteration 149/1000 | Loss: 0.00001145
Iteration 150/1000 | Loss: 0.00001145
Iteration 151/1000 | Loss: 0.00001145
Iteration 152/1000 | Loss: 0.00001145
Iteration 153/1000 | Loss: 0.00001145
Iteration 154/1000 | Loss: 0.00001145
Iteration 155/1000 | Loss: 0.00001145
Iteration 156/1000 | Loss: 0.00001145
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.1447673387010582e-05, 1.1447673387010582e-05, 1.1447673387010582e-05, 1.1447673387010582e-05, 1.1447673387010582e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1447673387010582e-05

Optimization complete. Final v2v error: 2.860175132751465 mm

Highest mean error: 3.299102306365967 mm for frame 165

Lowest mean error: 2.5619678497314453 mm for frame 148

Saving results

Total time: 56.647555351257324
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00388641
Iteration 2/25 | Loss: 0.00127321
Iteration 3/25 | Loss: 0.00119136
Iteration 4/25 | Loss: 0.00118431
Iteration 5/25 | Loss: 0.00118273
Iteration 6/25 | Loss: 0.00118228
Iteration 7/25 | Loss: 0.00118228
Iteration 8/25 | Loss: 0.00118228
Iteration 9/25 | Loss: 0.00118228
Iteration 10/25 | Loss: 0.00118228
Iteration 11/25 | Loss: 0.00118228
Iteration 12/25 | Loss: 0.00118228
Iteration 13/25 | Loss: 0.00118228
Iteration 14/25 | Loss: 0.00118228
Iteration 15/25 | Loss: 0.00118228
Iteration 16/25 | Loss: 0.00118228
Iteration 17/25 | Loss: 0.00118228
Iteration 18/25 | Loss: 0.00118228
Iteration 19/25 | Loss: 0.00118228
Iteration 20/25 | Loss: 0.00118228
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0011822765227407217, 0.0011822765227407217, 0.0011822765227407217, 0.0011822765227407217, 0.0011822765227407217]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011822765227407217

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46987510
Iteration 2/25 | Loss: 0.00248895
Iteration 3/25 | Loss: 0.00248894
Iteration 4/25 | Loss: 0.00248894
Iteration 5/25 | Loss: 0.00248894
Iteration 6/25 | Loss: 0.00248894
Iteration 7/25 | Loss: 0.00248894
Iteration 8/25 | Loss: 0.00248894
Iteration 9/25 | Loss: 0.00248894
Iteration 10/25 | Loss: 0.00248894
Iteration 11/25 | Loss: 0.00248894
Iteration 12/25 | Loss: 0.00248894
Iteration 13/25 | Loss: 0.00248894
Iteration 14/25 | Loss: 0.00248894
Iteration 15/25 | Loss: 0.00248894
Iteration 16/25 | Loss: 0.00248894
Iteration 17/25 | Loss: 0.00248894
Iteration 18/25 | Loss: 0.00248894
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0024889404885470867, 0.0024889404885470867, 0.0024889404885470867, 0.0024889404885470867, 0.0024889404885470867]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0024889404885470867

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00248894
Iteration 2/1000 | Loss: 0.00002236
Iteration 3/1000 | Loss: 0.00001443
Iteration 4/1000 | Loss: 0.00001284
Iteration 5/1000 | Loss: 0.00001204
Iteration 6/1000 | Loss: 0.00001138
Iteration 7/1000 | Loss: 0.00001080
Iteration 8/1000 | Loss: 0.00001040
Iteration 9/1000 | Loss: 0.00001021
Iteration 10/1000 | Loss: 0.00001007
Iteration 11/1000 | Loss: 0.00001005
Iteration 12/1000 | Loss: 0.00000998
Iteration 13/1000 | Loss: 0.00000996
Iteration 14/1000 | Loss: 0.00000992
Iteration 15/1000 | Loss: 0.00000991
Iteration 16/1000 | Loss: 0.00000989
Iteration 17/1000 | Loss: 0.00000986
Iteration 18/1000 | Loss: 0.00000984
Iteration 19/1000 | Loss: 0.00000984
Iteration 20/1000 | Loss: 0.00000983
Iteration 21/1000 | Loss: 0.00000977
Iteration 22/1000 | Loss: 0.00000973
Iteration 23/1000 | Loss: 0.00000970
Iteration 24/1000 | Loss: 0.00000970
Iteration 25/1000 | Loss: 0.00000968
Iteration 26/1000 | Loss: 0.00000968
Iteration 27/1000 | Loss: 0.00000967
Iteration 28/1000 | Loss: 0.00000967
Iteration 29/1000 | Loss: 0.00000966
Iteration 30/1000 | Loss: 0.00000966
Iteration 31/1000 | Loss: 0.00000965
Iteration 32/1000 | Loss: 0.00000965
Iteration 33/1000 | Loss: 0.00000965
Iteration 34/1000 | Loss: 0.00000963
Iteration 35/1000 | Loss: 0.00000963
Iteration 36/1000 | Loss: 0.00000963
Iteration 37/1000 | Loss: 0.00000962
Iteration 38/1000 | Loss: 0.00000961
Iteration 39/1000 | Loss: 0.00000961
Iteration 40/1000 | Loss: 0.00000961
Iteration 41/1000 | Loss: 0.00000960
Iteration 42/1000 | Loss: 0.00000957
Iteration 43/1000 | Loss: 0.00000957
Iteration 44/1000 | Loss: 0.00000957
Iteration 45/1000 | Loss: 0.00000957
Iteration 46/1000 | Loss: 0.00000957
Iteration 47/1000 | Loss: 0.00000956
Iteration 48/1000 | Loss: 0.00000956
Iteration 49/1000 | Loss: 0.00000956
Iteration 50/1000 | Loss: 0.00000956
Iteration 51/1000 | Loss: 0.00000956
Iteration 52/1000 | Loss: 0.00000956
Iteration 53/1000 | Loss: 0.00000955
Iteration 54/1000 | Loss: 0.00000955
Iteration 55/1000 | Loss: 0.00000954
Iteration 56/1000 | Loss: 0.00000954
Iteration 57/1000 | Loss: 0.00000953
Iteration 58/1000 | Loss: 0.00000953
Iteration 59/1000 | Loss: 0.00000953
Iteration 60/1000 | Loss: 0.00000953
Iteration 61/1000 | Loss: 0.00000953
Iteration 62/1000 | Loss: 0.00000953
Iteration 63/1000 | Loss: 0.00000952
Iteration 64/1000 | Loss: 0.00000952
Iteration 65/1000 | Loss: 0.00000952
Iteration 66/1000 | Loss: 0.00000951
Iteration 67/1000 | Loss: 0.00000951
Iteration 68/1000 | Loss: 0.00000951
Iteration 69/1000 | Loss: 0.00000951
Iteration 70/1000 | Loss: 0.00000951
Iteration 71/1000 | Loss: 0.00000951
Iteration 72/1000 | Loss: 0.00000950
Iteration 73/1000 | Loss: 0.00000950
Iteration 74/1000 | Loss: 0.00000950
Iteration 75/1000 | Loss: 0.00000950
Iteration 76/1000 | Loss: 0.00000950
Iteration 77/1000 | Loss: 0.00000950
Iteration 78/1000 | Loss: 0.00000950
Iteration 79/1000 | Loss: 0.00000949
Iteration 80/1000 | Loss: 0.00000949
Iteration 81/1000 | Loss: 0.00000949
Iteration 82/1000 | Loss: 0.00000949
Iteration 83/1000 | Loss: 0.00000949
Iteration 84/1000 | Loss: 0.00000949
Iteration 85/1000 | Loss: 0.00000948
Iteration 86/1000 | Loss: 0.00000948
Iteration 87/1000 | Loss: 0.00000948
Iteration 88/1000 | Loss: 0.00000948
Iteration 89/1000 | Loss: 0.00000948
Iteration 90/1000 | Loss: 0.00000947
Iteration 91/1000 | Loss: 0.00000947
Iteration 92/1000 | Loss: 0.00000947
Iteration 93/1000 | Loss: 0.00000947
Iteration 94/1000 | Loss: 0.00000947
Iteration 95/1000 | Loss: 0.00000947
Iteration 96/1000 | Loss: 0.00000947
Iteration 97/1000 | Loss: 0.00000947
Iteration 98/1000 | Loss: 0.00000947
Iteration 99/1000 | Loss: 0.00000947
Iteration 100/1000 | Loss: 0.00000947
Iteration 101/1000 | Loss: 0.00000946
Iteration 102/1000 | Loss: 0.00000946
Iteration 103/1000 | Loss: 0.00000946
Iteration 104/1000 | Loss: 0.00000946
Iteration 105/1000 | Loss: 0.00000946
Iteration 106/1000 | Loss: 0.00000946
Iteration 107/1000 | Loss: 0.00000946
Iteration 108/1000 | Loss: 0.00000946
Iteration 109/1000 | Loss: 0.00000946
Iteration 110/1000 | Loss: 0.00000946
Iteration 111/1000 | Loss: 0.00000946
Iteration 112/1000 | Loss: 0.00000946
Iteration 113/1000 | Loss: 0.00000946
Iteration 114/1000 | Loss: 0.00000946
Iteration 115/1000 | Loss: 0.00000946
Iteration 116/1000 | Loss: 0.00000945
Iteration 117/1000 | Loss: 0.00000945
Iteration 118/1000 | Loss: 0.00000945
Iteration 119/1000 | Loss: 0.00000945
Iteration 120/1000 | Loss: 0.00000945
Iteration 121/1000 | Loss: 0.00000945
Iteration 122/1000 | Loss: 0.00000945
Iteration 123/1000 | Loss: 0.00000945
Iteration 124/1000 | Loss: 0.00000945
Iteration 125/1000 | Loss: 0.00000945
Iteration 126/1000 | Loss: 0.00000945
Iteration 127/1000 | Loss: 0.00000945
Iteration 128/1000 | Loss: 0.00000945
Iteration 129/1000 | Loss: 0.00000945
Iteration 130/1000 | Loss: 0.00000945
Iteration 131/1000 | Loss: 0.00000945
Iteration 132/1000 | Loss: 0.00000945
Iteration 133/1000 | Loss: 0.00000945
Iteration 134/1000 | Loss: 0.00000945
Iteration 135/1000 | Loss: 0.00000945
Iteration 136/1000 | Loss: 0.00000945
Iteration 137/1000 | Loss: 0.00000945
Iteration 138/1000 | Loss: 0.00000945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 138. Stopping optimization.
Last 5 losses: [9.44947350944858e-06, 9.44947350944858e-06, 9.44947350944858e-06, 9.44947350944858e-06, 9.44947350944858e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.44947350944858e-06

Optimization complete. Final v2v error: 2.6229522228240967 mm

Highest mean error: 2.9838919639587402 mm for frame 74

Lowest mean error: 2.441480875015259 mm for frame 2

Saving results

Total time: 33.53667855262756
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01072238
Iteration 2/25 | Loss: 0.00370268
Iteration 3/25 | Loss: 0.00203315
Iteration 4/25 | Loss: 0.00171903
Iteration 5/25 | Loss: 0.00164849
Iteration 6/25 | Loss: 0.00150863
Iteration 7/25 | Loss: 0.00141414
Iteration 8/25 | Loss: 0.00130966
Iteration 9/25 | Loss: 0.00127436
Iteration 10/25 | Loss: 0.00125379
Iteration 11/25 | Loss: 0.00124906
Iteration 12/25 | Loss: 0.00124706
Iteration 13/25 | Loss: 0.00123952
Iteration 14/25 | Loss: 0.00123163
Iteration 15/25 | Loss: 0.00123205
Iteration 16/25 | Loss: 0.00122954
Iteration 17/25 | Loss: 0.00123067
Iteration 18/25 | Loss: 0.00122992
Iteration 19/25 | Loss: 0.00122860
Iteration 20/25 | Loss: 0.00122687
Iteration 21/25 | Loss: 0.00122516
Iteration 22/25 | Loss: 0.00121993
Iteration 23/25 | Loss: 0.00122348
Iteration 24/25 | Loss: 0.00122757
Iteration 25/25 | Loss: 0.00122557

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30501580
Iteration 2/25 | Loss: 0.00249759
Iteration 3/25 | Loss: 0.00249758
Iteration 4/25 | Loss: 0.00249758
Iteration 5/25 | Loss: 0.00248043
Iteration 6/25 | Loss: 0.00248043
Iteration 7/25 | Loss: 0.00248043
Iteration 8/25 | Loss: 0.00248043
Iteration 9/25 | Loss: 0.00248043
Iteration 10/25 | Loss: 0.00248043
Iteration 11/25 | Loss: 0.00248043
Iteration 12/25 | Loss: 0.00248043
Iteration 13/25 | Loss: 0.00248043
Iteration 14/25 | Loss: 0.00248043
Iteration 15/25 | Loss: 0.00248043
Iteration 16/25 | Loss: 0.00248043
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.002480428433045745, 0.002480428433045745, 0.002480428433045745, 0.002480428433045745, 0.002480428433045745]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002480428433045745

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00248043
Iteration 2/1000 | Loss: 0.00017640
Iteration 3/1000 | Loss: 0.00013229
Iteration 4/1000 | Loss: 0.00012597
Iteration 5/1000 | Loss: 0.00013409
Iteration 6/1000 | Loss: 0.00011305
Iteration 7/1000 | Loss: 0.00012924
Iteration 8/1000 | Loss: 0.00007897
Iteration 9/1000 | Loss: 0.00012334
Iteration 10/1000 | Loss: 0.00016767
Iteration 11/1000 | Loss: 0.00011192
Iteration 12/1000 | Loss: 0.00010965
Iteration 13/1000 | Loss: 0.00021926
Iteration 14/1000 | Loss: 0.00010941
Iteration 15/1000 | Loss: 0.00008738
Iteration 16/1000 | Loss: 0.00005582
Iteration 17/1000 | Loss: 0.00005684
Iteration 18/1000 | Loss: 0.00004807
Iteration 19/1000 | Loss: 0.00047887
Iteration 20/1000 | Loss: 0.00011552
Iteration 21/1000 | Loss: 0.00006183
Iteration 22/1000 | Loss: 0.00003567
Iteration 23/1000 | Loss: 0.00015361
Iteration 24/1000 | Loss: 0.00004353
Iteration 25/1000 | Loss: 0.00004302
Iteration 26/1000 | Loss: 0.00004089
Iteration 27/1000 | Loss: 0.00002689
Iteration 28/1000 | Loss: 0.00002520
Iteration 29/1000 | Loss: 0.00003556
Iteration 30/1000 | Loss: 0.00002684
Iteration 31/1000 | Loss: 0.00011680
Iteration 32/1000 | Loss: 0.00012360
Iteration 33/1000 | Loss: 0.00014802
Iteration 34/1000 | Loss: 0.00006233
Iteration 35/1000 | Loss: 0.00003677
Iteration 36/1000 | Loss: 0.00016491
Iteration 37/1000 | Loss: 0.00008091
Iteration 38/1000 | Loss: 0.00002884
Iteration 39/1000 | Loss: 0.00007150
Iteration 40/1000 | Loss: 0.00003341
Iteration 41/1000 | Loss: 0.00016077
Iteration 42/1000 | Loss: 0.00002820
Iteration 43/1000 | Loss: 0.00002634
Iteration 44/1000 | Loss: 0.00008422
Iteration 45/1000 | Loss: 0.00003760
Iteration 46/1000 | Loss: 0.00002779
Iteration 47/1000 | Loss: 0.00002744
Iteration 48/1000 | Loss: 0.00003749
Iteration 49/1000 | Loss: 0.00004815
Iteration 50/1000 | Loss: 0.00003715
Iteration 51/1000 | Loss: 0.00003085
Iteration 52/1000 | Loss: 0.00004044
Iteration 53/1000 | Loss: 0.00003576
Iteration 54/1000 | Loss: 0.00003532
Iteration 55/1000 | Loss: 0.00004371
Iteration 56/1000 | Loss: 0.00003800
Iteration 57/1000 | Loss: 0.00005240
Iteration 58/1000 | Loss: 0.00003856
Iteration 59/1000 | Loss: 0.00003437
Iteration 60/1000 | Loss: 0.00003711
Iteration 61/1000 | Loss: 0.00003044
Iteration 62/1000 | Loss: 0.00003565
Iteration 63/1000 | Loss: 0.00003380
Iteration 64/1000 | Loss: 0.00003520
Iteration 65/1000 | Loss: 0.00003326
Iteration 66/1000 | Loss: 0.00003079
Iteration 67/1000 | Loss: 0.00002952
Iteration 68/1000 | Loss: 0.00002896
Iteration 69/1000 | Loss: 0.00002950
Iteration 70/1000 | Loss: 0.00003145
Iteration 71/1000 | Loss: 0.00002899
Iteration 72/1000 | Loss: 0.00006834
Iteration 73/1000 | Loss: 0.00003615
Iteration 74/1000 | Loss: 0.00002928
Iteration 75/1000 | Loss: 0.00002972
Iteration 76/1000 | Loss: 0.00002986
Iteration 77/1000 | Loss: 0.00003350
Iteration 78/1000 | Loss: 0.00002939
Iteration 79/1000 | Loss: 0.00002741
Iteration 80/1000 | Loss: 0.00002941
Iteration 81/1000 | Loss: 0.00002880
Iteration 82/1000 | Loss: 0.00003353
Iteration 83/1000 | Loss: 0.00004414
Iteration 84/1000 | Loss: 0.00003292
Iteration 85/1000 | Loss: 0.00004146
Iteration 86/1000 | Loss: 0.00003077
Iteration 87/1000 | Loss: 0.00004154
Iteration 88/1000 | Loss: 0.00006201
Iteration 89/1000 | Loss: 0.00006015
Iteration 90/1000 | Loss: 0.00002864
Iteration 91/1000 | Loss: 0.00003565
Iteration 92/1000 | Loss: 0.00005497
Iteration 93/1000 | Loss: 0.00002773
Iteration 94/1000 | Loss: 0.00002257
Iteration 95/1000 | Loss: 0.00003390
Iteration 96/1000 | Loss: 0.00002840
Iteration 97/1000 | Loss: 0.00002972
Iteration 98/1000 | Loss: 0.00002774
Iteration 99/1000 | Loss: 0.00003536
Iteration 100/1000 | Loss: 0.00002847
Iteration 101/1000 | Loss: 0.00002227
Iteration 102/1000 | Loss: 0.00002106
Iteration 103/1000 | Loss: 0.00002141
Iteration 104/1000 | Loss: 0.00007703
Iteration 105/1000 | Loss: 0.00003425
Iteration 106/1000 | Loss: 0.00002032
Iteration 107/1000 | Loss: 0.00008742
Iteration 108/1000 | Loss: 0.00001867
Iteration 109/1000 | Loss: 0.00001823
Iteration 110/1000 | Loss: 0.00002292
Iteration 111/1000 | Loss: 0.00039077
Iteration 112/1000 | Loss: 0.00002467
Iteration 113/1000 | Loss: 0.00002411
Iteration 114/1000 | Loss: 0.00003165
Iteration 115/1000 | Loss: 0.00002593
Iteration 116/1000 | Loss: 0.00007718
Iteration 117/1000 | Loss: 0.00001776
Iteration 118/1000 | Loss: 0.00015094
Iteration 119/1000 | Loss: 0.00001849
Iteration 120/1000 | Loss: 0.00001731
Iteration 121/1000 | Loss: 0.00003657
Iteration 122/1000 | Loss: 0.00001700
Iteration 123/1000 | Loss: 0.00002182
Iteration 124/1000 | Loss: 0.00001755
Iteration 125/1000 | Loss: 0.00001731
Iteration 126/1000 | Loss: 0.00001641
Iteration 127/1000 | Loss: 0.00001811
Iteration 128/1000 | Loss: 0.00004475
Iteration 129/1000 | Loss: 0.00001678
Iteration 130/1000 | Loss: 0.00002151
Iteration 131/1000 | Loss: 0.00001625
Iteration 132/1000 | Loss: 0.00001720
Iteration 133/1000 | Loss: 0.00001623
Iteration 134/1000 | Loss: 0.00001724
Iteration 135/1000 | Loss: 0.00001618
Iteration 136/1000 | Loss: 0.00001713
Iteration 137/1000 | Loss: 0.00001715
Iteration 138/1000 | Loss: 0.00012547
Iteration 139/1000 | Loss: 0.00002156
Iteration 140/1000 | Loss: 0.00004197
Iteration 141/1000 | Loss: 0.00001631
Iteration 142/1000 | Loss: 0.00002076
Iteration 143/1000 | Loss: 0.00001591
Iteration 144/1000 | Loss: 0.00001584
Iteration 145/1000 | Loss: 0.00001775
Iteration 146/1000 | Loss: 0.00001569
Iteration 147/1000 | Loss: 0.00001567
Iteration 148/1000 | Loss: 0.00001558
Iteration 149/1000 | Loss: 0.00001558
Iteration 150/1000 | Loss: 0.00001558
Iteration 151/1000 | Loss: 0.00001555
Iteration 152/1000 | Loss: 0.00001555
Iteration 153/1000 | Loss: 0.00001554
Iteration 154/1000 | Loss: 0.00001554
Iteration 155/1000 | Loss: 0.00001553
Iteration 156/1000 | Loss: 0.00001553
Iteration 157/1000 | Loss: 0.00001553
Iteration 158/1000 | Loss: 0.00001553
Iteration 159/1000 | Loss: 0.00001553
Iteration 160/1000 | Loss: 0.00001553
Iteration 161/1000 | Loss: 0.00001553
Iteration 162/1000 | Loss: 0.00001552
Iteration 163/1000 | Loss: 0.00001552
Iteration 164/1000 | Loss: 0.00001552
Iteration 165/1000 | Loss: 0.00001552
Iteration 166/1000 | Loss: 0.00001552
Iteration 167/1000 | Loss: 0.00014482
Iteration 168/1000 | Loss: 0.00042785
Iteration 169/1000 | Loss: 0.00003434
Iteration 170/1000 | Loss: 0.00002514
Iteration 171/1000 | Loss: 0.00003669
Iteration 172/1000 | Loss: 0.00017014
Iteration 173/1000 | Loss: 0.00002746
Iteration 174/1000 | Loss: 0.00002192
Iteration 175/1000 | Loss: 0.00001838
Iteration 176/1000 | Loss: 0.00001728
Iteration 177/1000 | Loss: 0.00001681
Iteration 178/1000 | Loss: 0.00001682
Iteration 179/1000 | Loss: 0.00002068
Iteration 180/1000 | Loss: 0.00001832
Iteration 181/1000 | Loss: 0.00001978
Iteration 182/1000 | Loss: 0.00001775
Iteration 183/1000 | Loss: 0.00001690
Iteration 184/1000 | Loss: 0.00001558
Iteration 185/1000 | Loss: 0.00001517
Iteration 186/1000 | Loss: 0.00001464
Iteration 187/1000 | Loss: 0.00001882
Iteration 188/1000 | Loss: 0.00001452
Iteration 189/1000 | Loss: 0.00001514
Iteration 190/1000 | Loss: 0.00001423
Iteration 191/1000 | Loss: 0.00001379
Iteration 192/1000 | Loss: 0.00001376
Iteration 193/1000 | Loss: 0.00001375
Iteration 194/1000 | Loss: 0.00001375
Iteration 195/1000 | Loss: 0.00001375
Iteration 196/1000 | Loss: 0.00001375
Iteration 197/1000 | Loss: 0.00001375
Iteration 198/1000 | Loss: 0.00001375
Iteration 199/1000 | Loss: 0.00001375
Iteration 200/1000 | Loss: 0.00001375
Iteration 201/1000 | Loss: 0.00001375
Iteration 202/1000 | Loss: 0.00001375
Iteration 203/1000 | Loss: 0.00001375
Iteration 204/1000 | Loss: 0.00001375
Iteration 205/1000 | Loss: 0.00001375
Iteration 206/1000 | Loss: 0.00001375
Iteration 207/1000 | Loss: 0.00001375
Iteration 208/1000 | Loss: 0.00001375
Iteration 209/1000 | Loss: 0.00001375
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 209. Stopping optimization.
Last 5 losses: [1.3754613974015228e-05, 1.3754613974015228e-05, 1.3754613974015228e-05, 1.3754613974015228e-05, 1.3754613974015228e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3754613974015228e-05

Optimization complete. Final v2v error: 2.918496608734131 mm

Highest mean error: 11.234313011169434 mm for frame 181

Lowest mean error: 2.4815306663513184 mm for frame 13

Saving results

Total time: 320.4014286994934
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01080802
Iteration 2/25 | Loss: 0.00235123
Iteration 3/25 | Loss: 0.00184096
Iteration 4/25 | Loss: 0.00185319
Iteration 5/25 | Loss: 0.00146634
Iteration 6/25 | Loss: 0.00140247
Iteration 7/25 | Loss: 0.00139702
Iteration 8/25 | Loss: 0.00139925
Iteration 9/25 | Loss: 0.00139563
Iteration 10/25 | Loss: 0.00139448
Iteration 11/25 | Loss: 0.00139413
Iteration 12/25 | Loss: 0.00139397
Iteration 13/25 | Loss: 0.00139385
Iteration 14/25 | Loss: 0.00139384
Iteration 15/25 | Loss: 0.00139383
Iteration 16/25 | Loss: 0.00139383
Iteration 17/25 | Loss: 0.00139383
Iteration 18/25 | Loss: 0.00139383
Iteration 19/25 | Loss: 0.00139383
Iteration 20/25 | Loss: 0.00139383
Iteration 21/25 | Loss: 0.00139383
Iteration 22/25 | Loss: 0.00139383
Iteration 23/25 | Loss: 0.00139383
Iteration 24/25 | Loss: 0.00139382
Iteration 25/25 | Loss: 0.00139382

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16328466
Iteration 2/25 | Loss: 0.00353419
Iteration 3/25 | Loss: 0.00353419
Iteration 4/25 | Loss: 0.00353419
Iteration 5/25 | Loss: 0.00353419
Iteration 6/25 | Loss: 0.00353419
Iteration 7/25 | Loss: 0.00353419
Iteration 8/25 | Loss: 0.00353419
Iteration 9/25 | Loss: 0.00353419
Iteration 10/25 | Loss: 0.00353419
Iteration 11/25 | Loss: 0.00353419
Iteration 12/25 | Loss: 0.00353419
Iteration 13/25 | Loss: 0.00353419
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0035341917537152767, 0.0035341917537152767, 0.0035341917537152767, 0.0035341917537152767, 0.0035341917537152767]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0035341917537152767

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00353419
Iteration 2/1000 | Loss: 0.00030786
Iteration 3/1000 | Loss: 0.00016894
Iteration 4/1000 | Loss: 0.00015026
Iteration 5/1000 | Loss: 0.00008070
Iteration 6/1000 | Loss: 0.00013357
Iteration 7/1000 | Loss: 0.00009792
Iteration 8/1000 | Loss: 0.00006042
Iteration 9/1000 | Loss: 0.00005332
Iteration 10/1000 | Loss: 0.00005013
Iteration 11/1000 | Loss: 0.00009269
Iteration 12/1000 | Loss: 0.00004980
Iteration 13/1000 | Loss: 0.00003886
Iteration 14/1000 | Loss: 0.00003996
Iteration 15/1000 | Loss: 0.00003909
Iteration 16/1000 | Loss: 0.00003676
Iteration 17/1000 | Loss: 0.00003160
Iteration 18/1000 | Loss: 0.00003025
Iteration 19/1000 | Loss: 0.00004062
Iteration 20/1000 | Loss: 0.00003936
Iteration 21/1000 | Loss: 0.00004171
Iteration 22/1000 | Loss: 0.00003879
Iteration 23/1000 | Loss: 0.00002980
Iteration 24/1000 | Loss: 0.00005242
Iteration 25/1000 | Loss: 0.00003470
Iteration 26/1000 | Loss: 0.00002851
Iteration 27/1000 | Loss: 0.00003195
Iteration 28/1000 | Loss: 0.00003463
Iteration 29/1000 | Loss: 0.00003986
Iteration 30/1000 | Loss: 0.00003797
Iteration 31/1000 | Loss: 0.00003367
Iteration 32/1000 | Loss: 0.00003279
Iteration 33/1000 | Loss: 0.00003618
Iteration 34/1000 | Loss: 0.00004925
Iteration 35/1000 | Loss: 0.00003553
Iteration 36/1000 | Loss: 0.00004018
Iteration 37/1000 | Loss: 0.00003436
Iteration 38/1000 | Loss: 0.00002874
Iteration 39/1000 | Loss: 0.00003413
Iteration 40/1000 | Loss: 0.00002987
Iteration 41/1000 | Loss: 0.00003733
Iteration 42/1000 | Loss: 0.00003706
Iteration 43/1000 | Loss: 0.00003439
Iteration 44/1000 | Loss: 0.00002675
Iteration 45/1000 | Loss: 0.00003784
Iteration 46/1000 | Loss: 0.00005281
Iteration 47/1000 | Loss: 0.00003454
Iteration 48/1000 | Loss: 0.00002845
Iteration 49/1000 | Loss: 0.00003699
Iteration 50/1000 | Loss: 0.00002979
Iteration 51/1000 | Loss: 0.00002687
Iteration 52/1000 | Loss: 0.00003130
Iteration 53/1000 | Loss: 0.00003078
Iteration 54/1000 | Loss: 0.00003253
Iteration 55/1000 | Loss: 0.00002870
Iteration 56/1000 | Loss: 0.00003360
Iteration 57/1000 | Loss: 0.00004998
Iteration 58/1000 | Loss: 0.00003687
Iteration 59/1000 | Loss: 0.00004152
Iteration 60/1000 | Loss: 0.00003236
Iteration 61/1000 | Loss: 0.00003254
Iteration 62/1000 | Loss: 0.00003302
Iteration 63/1000 | Loss: 0.00003834
Iteration 64/1000 | Loss: 0.00003986
Iteration 65/1000 | Loss: 0.00005042
Iteration 66/1000 | Loss: 0.00003196
Iteration 67/1000 | Loss: 0.00002806
Iteration 68/1000 | Loss: 0.00004168
Iteration 69/1000 | Loss: 0.00002834
Iteration 70/1000 | Loss: 0.00002901
Iteration 71/1000 | Loss: 0.00003105
Iteration 72/1000 | Loss: 0.00002889
Iteration 73/1000 | Loss: 0.00003431
Iteration 74/1000 | Loss: 0.00002930
Iteration 75/1000 | Loss: 0.00004089
Iteration 76/1000 | Loss: 0.00003099
Iteration 77/1000 | Loss: 0.00003969
Iteration 78/1000 | Loss: 0.00003717
Iteration 79/1000 | Loss: 0.00003863
Iteration 80/1000 | Loss: 0.00002542
Iteration 81/1000 | Loss: 0.00002433
Iteration 82/1000 | Loss: 0.00002406
Iteration 83/1000 | Loss: 0.00002399
Iteration 84/1000 | Loss: 0.00002388
Iteration 85/1000 | Loss: 0.00002369
Iteration 86/1000 | Loss: 0.00002349
Iteration 87/1000 | Loss: 0.00002347
Iteration 88/1000 | Loss: 0.00002345
Iteration 89/1000 | Loss: 0.00002344
Iteration 90/1000 | Loss: 0.00002343
Iteration 91/1000 | Loss: 0.00002343
Iteration 92/1000 | Loss: 0.00002338
Iteration 93/1000 | Loss: 0.00002338
Iteration 94/1000 | Loss: 0.00002337
Iteration 95/1000 | Loss: 0.00002336
Iteration 96/1000 | Loss: 0.00002336
Iteration 97/1000 | Loss: 0.00002336
Iteration 98/1000 | Loss: 0.00002336
Iteration 99/1000 | Loss: 0.00002335
Iteration 100/1000 | Loss: 0.00002335
Iteration 101/1000 | Loss: 0.00002334
Iteration 102/1000 | Loss: 0.00002334
Iteration 103/1000 | Loss: 0.00002334
Iteration 104/1000 | Loss: 0.00002333
Iteration 105/1000 | Loss: 0.00002332
Iteration 106/1000 | Loss: 0.00002331
Iteration 107/1000 | Loss: 0.00002330
Iteration 108/1000 | Loss: 0.00002330
Iteration 109/1000 | Loss: 0.00002330
Iteration 110/1000 | Loss: 0.00002329
Iteration 111/1000 | Loss: 0.00002329
Iteration 112/1000 | Loss: 0.00002329
Iteration 113/1000 | Loss: 0.00002328
Iteration 114/1000 | Loss: 0.00002327
Iteration 115/1000 | Loss: 0.00002327
Iteration 116/1000 | Loss: 0.00002326
Iteration 117/1000 | Loss: 0.00002326
Iteration 118/1000 | Loss: 0.00002326
Iteration 119/1000 | Loss: 0.00002326
Iteration 120/1000 | Loss: 0.00002326
Iteration 121/1000 | Loss: 0.00002326
Iteration 122/1000 | Loss: 0.00002326
Iteration 123/1000 | Loss: 0.00002325
Iteration 124/1000 | Loss: 0.00002325
Iteration 125/1000 | Loss: 0.00002325
Iteration 126/1000 | Loss: 0.00002324
Iteration 127/1000 | Loss: 0.00002324
Iteration 128/1000 | Loss: 0.00002324
Iteration 129/1000 | Loss: 0.00002324
Iteration 130/1000 | Loss: 0.00002323
Iteration 131/1000 | Loss: 0.00002323
Iteration 132/1000 | Loss: 0.00002322
Iteration 133/1000 | Loss: 0.00002322
Iteration 134/1000 | Loss: 0.00002322
Iteration 135/1000 | Loss: 0.00002322
Iteration 136/1000 | Loss: 0.00002322
Iteration 137/1000 | Loss: 0.00002322
Iteration 138/1000 | Loss: 0.00002322
Iteration 139/1000 | Loss: 0.00002322
Iteration 140/1000 | Loss: 0.00002322
Iteration 141/1000 | Loss: 0.00002322
Iteration 142/1000 | Loss: 0.00002321
Iteration 143/1000 | Loss: 0.00002321
Iteration 144/1000 | Loss: 0.00002321
Iteration 145/1000 | Loss: 0.00002320
Iteration 146/1000 | Loss: 0.00002320
Iteration 147/1000 | Loss: 0.00002319
Iteration 148/1000 | Loss: 0.00002319
Iteration 149/1000 | Loss: 0.00002318
Iteration 150/1000 | Loss: 0.00002317
Iteration 151/1000 | Loss: 0.00002317
Iteration 152/1000 | Loss: 0.00002317
Iteration 153/1000 | Loss: 0.00002317
Iteration 154/1000 | Loss: 0.00002317
Iteration 155/1000 | Loss: 0.00002317
Iteration 156/1000 | Loss: 0.00002317
Iteration 157/1000 | Loss: 0.00002317
Iteration 158/1000 | Loss: 0.00002317
Iteration 159/1000 | Loss: 0.00002316
Iteration 160/1000 | Loss: 0.00002316
Iteration 161/1000 | Loss: 0.00002316
Iteration 162/1000 | Loss: 0.00002315
Iteration 163/1000 | Loss: 0.00002315
Iteration 164/1000 | Loss: 0.00002315
Iteration 165/1000 | Loss: 0.00002315
Iteration 166/1000 | Loss: 0.00002314
Iteration 167/1000 | Loss: 0.00002314
Iteration 168/1000 | Loss: 0.00002314
Iteration 169/1000 | Loss: 0.00002314
Iteration 170/1000 | Loss: 0.00002314
Iteration 171/1000 | Loss: 0.00002314
Iteration 172/1000 | Loss: 0.00002314
Iteration 173/1000 | Loss: 0.00002314
Iteration 174/1000 | Loss: 0.00002314
Iteration 175/1000 | Loss: 0.00002314
Iteration 176/1000 | Loss: 0.00002314
Iteration 177/1000 | Loss: 0.00002313
Iteration 178/1000 | Loss: 0.00002313
Iteration 179/1000 | Loss: 0.00002312
Iteration 180/1000 | Loss: 0.00002312
Iteration 181/1000 | Loss: 0.00002312
Iteration 182/1000 | Loss: 0.00002312
Iteration 183/1000 | Loss: 0.00002312
Iteration 184/1000 | Loss: 0.00002312
Iteration 185/1000 | Loss: 0.00002312
Iteration 186/1000 | Loss: 0.00002312
Iteration 187/1000 | Loss: 0.00002312
Iteration 188/1000 | Loss: 0.00002312
Iteration 189/1000 | Loss: 0.00002311
Iteration 190/1000 | Loss: 0.00002311
Iteration 191/1000 | Loss: 0.00002311
Iteration 192/1000 | Loss: 0.00002311
Iteration 193/1000 | Loss: 0.00002311
Iteration 194/1000 | Loss: 0.00002311
Iteration 195/1000 | Loss: 0.00002311
Iteration 196/1000 | Loss: 0.00002311
Iteration 197/1000 | Loss: 0.00002311
Iteration 198/1000 | Loss: 0.00002311
Iteration 199/1000 | Loss: 0.00002311
Iteration 200/1000 | Loss: 0.00002311
Iteration 201/1000 | Loss: 0.00002311
Iteration 202/1000 | Loss: 0.00002311
Iteration 203/1000 | Loss: 0.00002311
Iteration 204/1000 | Loss: 0.00002311
Iteration 205/1000 | Loss: 0.00002310
Iteration 206/1000 | Loss: 0.00002310
Iteration 207/1000 | Loss: 0.00002310
Iteration 208/1000 | Loss: 0.00002310
Iteration 209/1000 | Loss: 0.00002310
Iteration 210/1000 | Loss: 0.00002310
Iteration 211/1000 | Loss: 0.00002310
Iteration 212/1000 | Loss: 0.00002310
Iteration 213/1000 | Loss: 0.00002310
Iteration 214/1000 | Loss: 0.00002310
Iteration 215/1000 | Loss: 0.00002310
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 215. Stopping optimization.
Last 5 losses: [2.3099933969206177e-05, 2.3099933969206177e-05, 2.3099933969206177e-05, 2.3099933969206177e-05, 2.3099933969206177e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3099933969206177e-05

Optimization complete. Final v2v error: 4.174440383911133 mm

Highest mean error: 4.840402603149414 mm for frame 5

Lowest mean error: 4.024547100067139 mm for frame 40

Saving results

Total time: 173.2476770877838
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405048
Iteration 2/25 | Loss: 0.00126683
Iteration 3/25 | Loss: 0.00118840
Iteration 4/25 | Loss: 0.00118004
Iteration 5/25 | Loss: 0.00117810
Iteration 6/25 | Loss: 0.00117759
Iteration 7/25 | Loss: 0.00117759
Iteration 8/25 | Loss: 0.00117759
Iteration 9/25 | Loss: 0.00117759
Iteration 10/25 | Loss: 0.00117759
Iteration 11/25 | Loss: 0.00117759
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001177590573206544, 0.001177590573206544, 0.001177590573206544, 0.001177590573206544, 0.001177590573206544]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001177590573206544

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.13596737
Iteration 2/25 | Loss: 0.00243790
Iteration 3/25 | Loss: 0.00243790
Iteration 4/25 | Loss: 0.00243790
Iteration 5/25 | Loss: 0.00243790
Iteration 6/25 | Loss: 0.00243790
Iteration 7/25 | Loss: 0.00243790
Iteration 8/25 | Loss: 0.00243790
Iteration 9/25 | Loss: 0.00243790
Iteration 10/25 | Loss: 0.00243790
Iteration 11/25 | Loss: 0.00243790
Iteration 12/25 | Loss: 0.00243790
Iteration 13/25 | Loss: 0.00243790
Iteration 14/25 | Loss: 0.00243790
Iteration 15/25 | Loss: 0.00243790
Iteration 16/25 | Loss: 0.00243790
Iteration 17/25 | Loss: 0.00243790
Iteration 18/25 | Loss: 0.00243790
Iteration 19/25 | Loss: 0.00243790
Iteration 20/25 | Loss: 0.00243790
Iteration 21/25 | Loss: 0.00243790
Iteration 22/25 | Loss: 0.00243790
Iteration 23/25 | Loss: 0.00243790
Iteration 24/25 | Loss: 0.00243790
Iteration 25/25 | Loss: 0.00243790

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00243790
Iteration 2/1000 | Loss: 0.00001821
Iteration 3/1000 | Loss: 0.00001168
Iteration 4/1000 | Loss: 0.00001051
Iteration 5/1000 | Loss: 0.00000972
Iteration 6/1000 | Loss: 0.00000941
Iteration 7/1000 | Loss: 0.00000885
Iteration 8/1000 | Loss: 0.00000855
Iteration 9/1000 | Loss: 0.00000853
Iteration 10/1000 | Loss: 0.00000837
Iteration 11/1000 | Loss: 0.00000825
Iteration 12/1000 | Loss: 0.00000821
Iteration 13/1000 | Loss: 0.00000819
Iteration 14/1000 | Loss: 0.00000818
Iteration 15/1000 | Loss: 0.00000817
Iteration 16/1000 | Loss: 0.00000817
Iteration 17/1000 | Loss: 0.00000816
Iteration 18/1000 | Loss: 0.00000816
Iteration 19/1000 | Loss: 0.00000816
Iteration 20/1000 | Loss: 0.00000816
Iteration 21/1000 | Loss: 0.00000816
Iteration 22/1000 | Loss: 0.00000816
Iteration 23/1000 | Loss: 0.00000816
Iteration 24/1000 | Loss: 0.00000815
Iteration 25/1000 | Loss: 0.00000815
Iteration 26/1000 | Loss: 0.00000815
Iteration 27/1000 | Loss: 0.00000814
Iteration 28/1000 | Loss: 0.00000814
Iteration 29/1000 | Loss: 0.00000813
Iteration 30/1000 | Loss: 0.00000812
Iteration 31/1000 | Loss: 0.00000812
Iteration 32/1000 | Loss: 0.00000811
Iteration 33/1000 | Loss: 0.00000810
Iteration 34/1000 | Loss: 0.00000809
Iteration 35/1000 | Loss: 0.00000809
Iteration 36/1000 | Loss: 0.00000808
Iteration 37/1000 | Loss: 0.00000808
Iteration 38/1000 | Loss: 0.00000807
Iteration 39/1000 | Loss: 0.00000807
Iteration 40/1000 | Loss: 0.00000807
Iteration 41/1000 | Loss: 0.00000806
Iteration 42/1000 | Loss: 0.00000806
Iteration 43/1000 | Loss: 0.00000805
Iteration 44/1000 | Loss: 0.00000801
Iteration 45/1000 | Loss: 0.00000801
Iteration 46/1000 | Loss: 0.00000801
Iteration 47/1000 | Loss: 0.00000801
Iteration 48/1000 | Loss: 0.00000801
Iteration 49/1000 | Loss: 0.00000801
Iteration 50/1000 | Loss: 0.00000801
Iteration 51/1000 | Loss: 0.00000801
Iteration 52/1000 | Loss: 0.00000801
Iteration 53/1000 | Loss: 0.00000801
Iteration 54/1000 | Loss: 0.00000800
Iteration 55/1000 | Loss: 0.00000800
Iteration 56/1000 | Loss: 0.00000800
Iteration 57/1000 | Loss: 0.00000800
Iteration 58/1000 | Loss: 0.00000800
Iteration 59/1000 | Loss: 0.00000800
Iteration 60/1000 | Loss: 0.00000800
Iteration 61/1000 | Loss: 0.00000800
Iteration 62/1000 | Loss: 0.00000799
Iteration 63/1000 | Loss: 0.00000799
Iteration 64/1000 | Loss: 0.00000798
Iteration 65/1000 | Loss: 0.00000798
Iteration 66/1000 | Loss: 0.00000797
Iteration 67/1000 | Loss: 0.00000797
Iteration 68/1000 | Loss: 0.00000797
Iteration 69/1000 | Loss: 0.00000797
Iteration 70/1000 | Loss: 0.00000796
Iteration 71/1000 | Loss: 0.00000796
Iteration 72/1000 | Loss: 0.00000796
Iteration 73/1000 | Loss: 0.00000796
Iteration 74/1000 | Loss: 0.00000795
Iteration 75/1000 | Loss: 0.00000795
Iteration 76/1000 | Loss: 0.00000795
Iteration 77/1000 | Loss: 0.00000794
Iteration 78/1000 | Loss: 0.00000794
Iteration 79/1000 | Loss: 0.00000794
Iteration 80/1000 | Loss: 0.00000794
Iteration 81/1000 | Loss: 0.00000794
Iteration 82/1000 | Loss: 0.00000794
Iteration 83/1000 | Loss: 0.00000794
Iteration 84/1000 | Loss: 0.00000794
Iteration 85/1000 | Loss: 0.00000794
Iteration 86/1000 | Loss: 0.00000794
Iteration 87/1000 | Loss: 0.00000794
Iteration 88/1000 | Loss: 0.00000794
Iteration 89/1000 | Loss: 0.00000794
Iteration 90/1000 | Loss: 0.00000794
Iteration 91/1000 | Loss: 0.00000794
Iteration 92/1000 | Loss: 0.00000794
Iteration 93/1000 | Loss: 0.00000793
Iteration 94/1000 | Loss: 0.00000793
Iteration 95/1000 | Loss: 0.00000792
Iteration 96/1000 | Loss: 0.00000791
Iteration 97/1000 | Loss: 0.00000791
Iteration 98/1000 | Loss: 0.00000791
Iteration 99/1000 | Loss: 0.00000791
Iteration 100/1000 | Loss: 0.00000791
Iteration 101/1000 | Loss: 0.00000790
Iteration 102/1000 | Loss: 0.00000790
Iteration 103/1000 | Loss: 0.00000790
Iteration 104/1000 | Loss: 0.00000790
Iteration 105/1000 | Loss: 0.00000790
Iteration 106/1000 | Loss: 0.00000790
Iteration 107/1000 | Loss: 0.00000790
Iteration 108/1000 | Loss: 0.00000790
Iteration 109/1000 | Loss: 0.00000789
Iteration 110/1000 | Loss: 0.00000789
Iteration 111/1000 | Loss: 0.00000789
Iteration 112/1000 | Loss: 0.00000789
Iteration 113/1000 | Loss: 0.00000789
Iteration 114/1000 | Loss: 0.00000788
Iteration 115/1000 | Loss: 0.00000788
Iteration 116/1000 | Loss: 0.00000788
Iteration 117/1000 | Loss: 0.00000788
Iteration 118/1000 | Loss: 0.00000788
Iteration 119/1000 | Loss: 0.00000788
Iteration 120/1000 | Loss: 0.00000788
Iteration 121/1000 | Loss: 0.00000788
Iteration 122/1000 | Loss: 0.00000788
Iteration 123/1000 | Loss: 0.00000788
Iteration 124/1000 | Loss: 0.00000788
Iteration 125/1000 | Loss: 0.00000788
Iteration 126/1000 | Loss: 0.00000788
Iteration 127/1000 | Loss: 0.00000788
Iteration 128/1000 | Loss: 0.00000788
Iteration 129/1000 | Loss: 0.00000788
Iteration 130/1000 | Loss: 0.00000787
Iteration 131/1000 | Loss: 0.00000787
Iteration 132/1000 | Loss: 0.00000787
Iteration 133/1000 | Loss: 0.00000787
Iteration 134/1000 | Loss: 0.00000787
Iteration 135/1000 | Loss: 0.00000787
Iteration 136/1000 | Loss: 0.00000787
Iteration 137/1000 | Loss: 0.00000787
Iteration 138/1000 | Loss: 0.00000787
Iteration 139/1000 | Loss: 0.00000787
Iteration 140/1000 | Loss: 0.00000787
Iteration 141/1000 | Loss: 0.00000787
Iteration 142/1000 | Loss: 0.00000787
Iteration 143/1000 | Loss: 0.00000787
Iteration 144/1000 | Loss: 0.00000787
Iteration 145/1000 | Loss: 0.00000787
Iteration 146/1000 | Loss: 0.00000787
Iteration 147/1000 | Loss: 0.00000787
Iteration 148/1000 | Loss: 0.00000787
Iteration 149/1000 | Loss: 0.00000787
Iteration 150/1000 | Loss: 0.00000787
Iteration 151/1000 | Loss: 0.00000787
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [7.867639396863524e-06, 7.867639396863524e-06, 7.867639396863524e-06, 7.867639396863524e-06, 7.867639396863524e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 7.867639396863524e-06

Optimization complete. Final v2v error: 2.400174140930176 mm

Highest mean error: 2.601417064666748 mm for frame 70

Lowest mean error: 2.275885820388794 mm for frame 140

Saving results

Total time: 31.583542108535767
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00881185
Iteration 2/25 | Loss: 0.00207860
Iteration 3/25 | Loss: 0.00151417
Iteration 4/25 | Loss: 0.00146281
Iteration 5/25 | Loss: 0.00145945
Iteration 6/25 | Loss: 0.00145945
Iteration 7/25 | Loss: 0.00145945
Iteration 8/25 | Loss: 0.00145945
Iteration 9/25 | Loss: 0.00145945
Iteration 10/25 | Loss: 0.00145945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0014594508102163672, 0.0014594508102163672, 0.0014594508102163672, 0.0014594508102163672, 0.0014594508102163672]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014594508102163672

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.10263467
Iteration 2/25 | Loss: 0.00208602
Iteration 3/25 | Loss: 0.00208600
Iteration 4/25 | Loss: 0.00208600
Iteration 5/25 | Loss: 0.00208600
Iteration 6/25 | Loss: 0.00208600
Iteration 7/25 | Loss: 0.00208600
Iteration 8/25 | Loss: 0.00208599
Iteration 9/25 | Loss: 0.00208599
Iteration 10/25 | Loss: 0.00208599
Iteration 11/25 | Loss: 0.00208599
Iteration 12/25 | Loss: 0.00208599
Iteration 13/25 | Loss: 0.00208599
Iteration 14/25 | Loss: 0.00208599
Iteration 15/25 | Loss: 0.00208599
Iteration 16/25 | Loss: 0.00208599
Iteration 17/25 | Loss: 0.00208599
Iteration 18/25 | Loss: 0.00208599
Iteration 19/25 | Loss: 0.00208599
Iteration 20/25 | Loss: 0.00208599
Iteration 21/25 | Loss: 0.00208599
Iteration 22/25 | Loss: 0.00208599
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0020859944634139538, 0.0020859944634139538, 0.0020859944634139538, 0.0020859944634139538, 0.0020859944634139538]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0020859944634139538

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00208599
Iteration 2/1000 | Loss: 0.00007406
Iteration 3/1000 | Loss: 0.00003891
Iteration 4/1000 | Loss: 0.00003237
Iteration 5/1000 | Loss: 0.00003037
Iteration 6/1000 | Loss: 0.00002872
Iteration 7/1000 | Loss: 0.00002736
Iteration 8/1000 | Loss: 0.00002618
Iteration 9/1000 | Loss: 0.00002567
Iteration 10/1000 | Loss: 0.00002527
Iteration 11/1000 | Loss: 0.00002512
Iteration 12/1000 | Loss: 0.00002492
Iteration 13/1000 | Loss: 0.00002483
Iteration 14/1000 | Loss: 0.00002473
Iteration 15/1000 | Loss: 0.00002472
Iteration 16/1000 | Loss: 0.00002466
Iteration 17/1000 | Loss: 0.00002466
Iteration 18/1000 | Loss: 0.00002464
Iteration 19/1000 | Loss: 0.00002464
Iteration 20/1000 | Loss: 0.00002462
Iteration 21/1000 | Loss: 0.00002462
Iteration 22/1000 | Loss: 0.00002462
Iteration 23/1000 | Loss: 0.00002462
Iteration 24/1000 | Loss: 0.00002461
Iteration 25/1000 | Loss: 0.00002461
Iteration 26/1000 | Loss: 0.00002461
Iteration 27/1000 | Loss: 0.00002460
Iteration 28/1000 | Loss: 0.00002460
Iteration 29/1000 | Loss: 0.00002460
Iteration 30/1000 | Loss: 0.00002459
Iteration 31/1000 | Loss: 0.00002459
Iteration 32/1000 | Loss: 0.00002458
Iteration 33/1000 | Loss: 0.00002458
Iteration 34/1000 | Loss: 0.00002458
Iteration 35/1000 | Loss: 0.00002457
Iteration 36/1000 | Loss: 0.00002455
Iteration 37/1000 | Loss: 0.00002455
Iteration 38/1000 | Loss: 0.00002455
Iteration 39/1000 | Loss: 0.00002455
Iteration 40/1000 | Loss: 0.00002455
Iteration 41/1000 | Loss: 0.00002455
Iteration 42/1000 | Loss: 0.00002454
Iteration 43/1000 | Loss: 0.00002454
Iteration 44/1000 | Loss: 0.00002454
Iteration 45/1000 | Loss: 0.00002454
Iteration 46/1000 | Loss: 0.00002454
Iteration 47/1000 | Loss: 0.00002454
Iteration 48/1000 | Loss: 0.00002454
Iteration 49/1000 | Loss: 0.00002453
Iteration 50/1000 | Loss: 0.00002453
Iteration 51/1000 | Loss: 0.00002453
Iteration 52/1000 | Loss: 0.00002453
Iteration 53/1000 | Loss: 0.00002453
Iteration 54/1000 | Loss: 0.00002452
Iteration 55/1000 | Loss: 0.00002452
Iteration 56/1000 | Loss: 0.00002452
Iteration 57/1000 | Loss: 0.00002452
Iteration 58/1000 | Loss: 0.00002452
Iteration 59/1000 | Loss: 0.00002452
Iteration 60/1000 | Loss: 0.00002451
Iteration 61/1000 | Loss: 0.00002451
Iteration 62/1000 | Loss: 0.00002451
Iteration 63/1000 | Loss: 0.00002451
Iteration 64/1000 | Loss: 0.00002451
Iteration 65/1000 | Loss: 0.00002451
Iteration 66/1000 | Loss: 0.00002450
Iteration 67/1000 | Loss: 0.00002450
Iteration 68/1000 | Loss: 0.00002450
Iteration 69/1000 | Loss: 0.00002450
Iteration 70/1000 | Loss: 0.00002450
Iteration 71/1000 | Loss: 0.00002450
Iteration 72/1000 | Loss: 0.00002450
Iteration 73/1000 | Loss: 0.00002450
Iteration 74/1000 | Loss: 0.00002450
Iteration 75/1000 | Loss: 0.00002449
Iteration 76/1000 | Loss: 0.00002449
Iteration 77/1000 | Loss: 0.00002449
Iteration 78/1000 | Loss: 0.00002449
Iteration 79/1000 | Loss: 0.00002449
Iteration 80/1000 | Loss: 0.00002449
Iteration 81/1000 | Loss: 0.00002449
Iteration 82/1000 | Loss: 0.00002449
Iteration 83/1000 | Loss: 0.00002449
Iteration 84/1000 | Loss: 0.00002449
Iteration 85/1000 | Loss: 0.00002449
Iteration 86/1000 | Loss: 0.00002448
Iteration 87/1000 | Loss: 0.00002448
Iteration 88/1000 | Loss: 0.00002448
Iteration 89/1000 | Loss: 0.00002448
Iteration 90/1000 | Loss: 0.00002448
Iteration 91/1000 | Loss: 0.00002448
Iteration 92/1000 | Loss: 0.00002448
Iteration 93/1000 | Loss: 0.00002448
Iteration 94/1000 | Loss: 0.00002448
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [2.448469058435876e-05, 2.448469058435876e-05, 2.448469058435876e-05, 2.448469058435876e-05, 2.448469058435876e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.448469058435876e-05

Optimization complete. Final v2v error: 4.280188083648682 mm

Highest mean error: 4.613622188568115 mm for frame 89

Lowest mean error: 4.012148380279541 mm for frame 4

Saving results

Total time: 36.37578225135803
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00999297
Iteration 2/25 | Loss: 0.00245034
Iteration 3/25 | Loss: 0.00177848
Iteration 4/25 | Loss: 0.00165359
Iteration 5/25 | Loss: 0.00151404
Iteration 6/25 | Loss: 0.00148121
Iteration 7/25 | Loss: 0.00152796
Iteration 8/25 | Loss: 0.00146799
Iteration 9/25 | Loss: 0.00151264
Iteration 10/25 | Loss: 0.00142710
Iteration 11/25 | Loss: 0.00133248
Iteration 12/25 | Loss: 0.00130914
Iteration 13/25 | Loss: 0.00130998
Iteration 14/25 | Loss: 0.00130408
Iteration 15/25 | Loss: 0.00129614
Iteration 16/25 | Loss: 0.00129276
Iteration 17/25 | Loss: 0.00129128
Iteration 18/25 | Loss: 0.00129220
Iteration 19/25 | Loss: 0.00129206
Iteration 20/25 | Loss: 0.00129099
Iteration 21/25 | Loss: 0.00129293
Iteration 22/25 | Loss: 0.00129196
Iteration 23/25 | Loss: 0.00129096
Iteration 24/25 | Loss: 0.00129285
Iteration 25/25 | Loss: 0.00129187

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16479397
Iteration 2/25 | Loss: 0.00336662
Iteration 3/25 | Loss: 0.00336583
Iteration 4/25 | Loss: 0.00336583
Iteration 5/25 | Loss: 0.00336583
Iteration 6/25 | Loss: 0.00336583
Iteration 7/25 | Loss: 0.00336583
Iteration 8/25 | Loss: 0.00336583
Iteration 9/25 | Loss: 0.00336583
Iteration 10/25 | Loss: 0.00336583
Iteration 11/25 | Loss: 0.00336583
Iteration 12/25 | Loss: 0.00336583
Iteration 13/25 | Loss: 0.00336583
Iteration 14/25 | Loss: 0.00336583
Iteration 15/25 | Loss: 0.00336583
Iteration 16/25 | Loss: 0.00336583
Iteration 17/25 | Loss: 0.00336583
Iteration 18/25 | Loss: 0.00336583
Iteration 19/25 | Loss: 0.00336583
Iteration 20/25 | Loss: 0.00336583
Iteration 21/25 | Loss: 0.00336583
Iteration 22/25 | Loss: 0.00336583
Iteration 23/25 | Loss: 0.00336583
Iteration 24/25 | Loss: 0.00336583
Iteration 25/25 | Loss: 0.00336583

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00336583
Iteration 2/1000 | Loss: 0.00013714
Iteration 3/1000 | Loss: 0.00011659
Iteration 4/1000 | Loss: 0.00007906
Iteration 5/1000 | Loss: 0.00007696
Iteration 6/1000 | Loss: 0.00006861
Iteration 7/1000 | Loss: 0.00007410
Iteration 8/1000 | Loss: 0.00006325
Iteration 9/1000 | Loss: 0.00006886
Iteration 10/1000 | Loss: 0.00051838
Iteration 11/1000 | Loss: 0.00007429
Iteration 12/1000 | Loss: 0.00005437
Iteration 13/1000 | Loss: 0.00006724
Iteration 14/1000 | Loss: 0.00005550
Iteration 15/1000 | Loss: 0.00007901
Iteration 16/1000 | Loss: 0.00046014
Iteration 17/1000 | Loss: 0.00010931
Iteration 18/1000 | Loss: 0.00005570
Iteration 19/1000 | Loss: 0.00005632
Iteration 20/1000 | Loss: 0.00005787
Iteration 21/1000 | Loss: 0.00004665
Iteration 22/1000 | Loss: 0.00004424
Iteration 23/1000 | Loss: 0.00004660
Iteration 24/1000 | Loss: 0.00005589
Iteration 25/1000 | Loss: 0.00006619
Iteration 26/1000 | Loss: 0.00004118
Iteration 27/1000 | Loss: 0.00005882
Iteration 28/1000 | Loss: 0.00004089
Iteration 29/1000 | Loss: 0.00005842
Iteration 30/1000 | Loss: 0.00005879
Iteration 31/1000 | Loss: 0.00005753
Iteration 32/1000 | Loss: 0.00005714
Iteration 33/1000 | Loss: 0.00007602
Iteration 34/1000 | Loss: 0.00004474
Iteration 35/1000 | Loss: 0.00003947
Iteration 36/1000 | Loss: 0.00003685
Iteration 37/1000 | Loss: 0.00003549
Iteration 38/1000 | Loss: 0.00003474
Iteration 39/1000 | Loss: 0.00003519
Iteration 40/1000 | Loss: 0.00003427
Iteration 41/1000 | Loss: 0.00003439
Iteration 42/1000 | Loss: 0.00003404
Iteration 43/1000 | Loss: 0.00003365
Iteration 44/1000 | Loss: 0.00003347
Iteration 45/1000 | Loss: 0.00003346
Iteration 46/1000 | Loss: 0.00003346
Iteration 47/1000 | Loss: 0.00003343
Iteration 48/1000 | Loss: 0.00003342
Iteration 49/1000 | Loss: 0.00003342
Iteration 50/1000 | Loss: 0.00003342
Iteration 51/1000 | Loss: 0.00003342
Iteration 52/1000 | Loss: 0.00003342
Iteration 53/1000 | Loss: 0.00003341
Iteration 54/1000 | Loss: 0.00003341
Iteration 55/1000 | Loss: 0.00003340
Iteration 56/1000 | Loss: 0.00003340
Iteration 57/1000 | Loss: 0.00003340
Iteration 58/1000 | Loss: 0.00003339
Iteration 59/1000 | Loss: 0.00003339
Iteration 60/1000 | Loss: 0.00003339
Iteration 61/1000 | Loss: 0.00003339
Iteration 62/1000 | Loss: 0.00003339
Iteration 63/1000 | Loss: 0.00003338
Iteration 64/1000 | Loss: 0.00003338
Iteration 65/1000 | Loss: 0.00003337
Iteration 66/1000 | Loss: 0.00003337
Iteration 67/1000 | Loss: 0.00003337
Iteration 68/1000 | Loss: 0.00004183
Iteration 69/1000 | Loss: 0.00003335
Iteration 70/1000 | Loss: 0.00003332
Iteration 71/1000 | Loss: 0.00003332
Iteration 72/1000 | Loss: 0.00003332
Iteration 73/1000 | Loss: 0.00003332
Iteration 74/1000 | Loss: 0.00003332
Iteration 75/1000 | Loss: 0.00003331
Iteration 76/1000 | Loss: 0.00003331
Iteration 77/1000 | Loss: 0.00003331
Iteration 78/1000 | Loss: 0.00003331
Iteration 79/1000 | Loss: 0.00003331
Iteration 80/1000 | Loss: 0.00003331
Iteration 81/1000 | Loss: 0.00003331
Iteration 82/1000 | Loss: 0.00003331
Iteration 83/1000 | Loss: 0.00003322
Iteration 84/1000 | Loss: 0.00003321
Iteration 85/1000 | Loss: 0.00003313
Iteration 86/1000 | Loss: 0.00003312
Iteration 87/1000 | Loss: 0.00003310
Iteration 88/1000 | Loss: 0.00003310
Iteration 89/1000 | Loss: 0.00061338
Iteration 90/1000 | Loss: 0.00007934
Iteration 91/1000 | Loss: 0.00008058
Iteration 92/1000 | Loss: 0.00004143
Iteration 93/1000 | Loss: 0.00004000
Iteration 94/1000 | Loss: 0.00064568
Iteration 95/1000 | Loss: 0.00106487
Iteration 96/1000 | Loss: 0.00088043
Iteration 97/1000 | Loss: 0.00038793
Iteration 98/1000 | Loss: 0.00056001
Iteration 99/1000 | Loss: 0.00023789
Iteration 100/1000 | Loss: 0.00058555
Iteration 101/1000 | Loss: 0.00025614
Iteration 102/1000 | Loss: 0.00033949
Iteration 103/1000 | Loss: 0.00026185
Iteration 104/1000 | Loss: 0.00003844
Iteration 105/1000 | Loss: 0.00004115
Iteration 106/1000 | Loss: 0.00004174
Iteration 107/1000 | Loss: 0.00003589
Iteration 108/1000 | Loss: 0.00004553
Iteration 109/1000 | Loss: 0.00003541
Iteration 110/1000 | Loss: 0.00003977
Iteration 111/1000 | Loss: 0.00003488
Iteration 112/1000 | Loss: 0.00003485
Iteration 113/1000 | Loss: 0.00065732
Iteration 114/1000 | Loss: 0.00064386
Iteration 115/1000 | Loss: 0.00007179
Iteration 116/1000 | Loss: 0.00045517
Iteration 117/1000 | Loss: 0.00009326
Iteration 118/1000 | Loss: 0.00003834
Iteration 119/1000 | Loss: 0.00035147
Iteration 120/1000 | Loss: 0.00063012
Iteration 121/1000 | Loss: 0.00004293
Iteration 122/1000 | Loss: 0.00034270
Iteration 123/1000 | Loss: 0.00059177
Iteration 124/1000 | Loss: 0.00005018
Iteration 125/1000 | Loss: 0.00003375
Iteration 126/1000 | Loss: 0.00003320
Iteration 127/1000 | Loss: 0.00003255
Iteration 128/1000 | Loss: 0.00003232
Iteration 129/1000 | Loss: 0.00003229
Iteration 130/1000 | Loss: 0.00003222
Iteration 131/1000 | Loss: 0.00003267
Iteration 132/1000 | Loss: 0.00003215
Iteration 133/1000 | Loss: 0.00003209
Iteration 134/1000 | Loss: 0.00003185
Iteration 135/1000 | Loss: 0.00003184
Iteration 136/1000 | Loss: 0.00003183
Iteration 137/1000 | Loss: 0.00003183
Iteration 138/1000 | Loss: 0.00003182
Iteration 139/1000 | Loss: 0.00003179
Iteration 140/1000 | Loss: 0.00003178
Iteration 141/1000 | Loss: 0.00003288
Iteration 142/1000 | Loss: 0.00032028
Iteration 143/1000 | Loss: 0.00057987
Iteration 144/1000 | Loss: 0.00050057
Iteration 145/1000 | Loss: 0.00056654
Iteration 146/1000 | Loss: 0.00026762
Iteration 147/1000 | Loss: 0.00027183
Iteration 148/1000 | Loss: 0.00051525
Iteration 149/1000 | Loss: 0.00086765
Iteration 150/1000 | Loss: 0.00050518
Iteration 151/1000 | Loss: 0.00041562
Iteration 152/1000 | Loss: 0.00005819
Iteration 153/1000 | Loss: 0.00004744
Iteration 154/1000 | Loss: 0.00003620
Iteration 155/1000 | Loss: 0.00003518
Iteration 156/1000 | Loss: 0.00077645
Iteration 157/1000 | Loss: 0.00015134
Iteration 158/1000 | Loss: 0.00005223
Iteration 159/1000 | Loss: 0.00003982
Iteration 160/1000 | Loss: 0.00003601
Iteration 161/1000 | Loss: 0.00005490
Iteration 162/1000 | Loss: 0.00003494
Iteration 163/1000 | Loss: 0.00003465
Iteration 164/1000 | Loss: 0.00003420
Iteration 165/1000 | Loss: 0.00077774
Iteration 166/1000 | Loss: 0.00065669
Iteration 167/1000 | Loss: 0.00034210
Iteration 168/1000 | Loss: 0.00096010
Iteration 169/1000 | Loss: 0.00026530
Iteration 170/1000 | Loss: 0.00009808
Iteration 171/1000 | Loss: 0.00004540
Iteration 172/1000 | Loss: 0.00005913
Iteration 173/1000 | Loss: 0.00003338
Iteration 174/1000 | Loss: 0.00003182
Iteration 175/1000 | Loss: 0.00003087
Iteration 176/1000 | Loss: 0.00007089
Iteration 177/1000 | Loss: 0.00003043
Iteration 178/1000 | Loss: 0.00003023
Iteration 179/1000 | Loss: 0.00003015
Iteration 180/1000 | Loss: 0.00003014
Iteration 181/1000 | Loss: 0.00003007
Iteration 182/1000 | Loss: 0.00003006
Iteration 183/1000 | Loss: 0.00003059
Iteration 184/1000 | Loss: 0.00003024
Iteration 185/1000 | Loss: 0.00003003
Iteration 186/1000 | Loss: 0.00003003
Iteration 187/1000 | Loss: 0.00003003
Iteration 188/1000 | Loss: 0.00003003
Iteration 189/1000 | Loss: 0.00003003
Iteration 190/1000 | Loss: 0.00003002
Iteration 191/1000 | Loss: 0.00003002
Iteration 192/1000 | Loss: 0.00003002
Iteration 193/1000 | Loss: 0.00003002
Iteration 194/1000 | Loss: 0.00003002
Iteration 195/1000 | Loss: 0.00003001
Iteration 196/1000 | Loss: 0.00003001
Iteration 197/1000 | Loss: 0.00003000
Iteration 198/1000 | Loss: 0.00003000
Iteration 199/1000 | Loss: 0.00003000
Iteration 200/1000 | Loss: 0.00003000
Iteration 201/1000 | Loss: 0.00003000
Iteration 202/1000 | Loss: 0.00003000
Iteration 203/1000 | Loss: 0.00002999
Iteration 204/1000 | Loss: 0.00002999
Iteration 205/1000 | Loss: 0.00002999
Iteration 206/1000 | Loss: 0.00002999
Iteration 207/1000 | Loss: 0.00002999
Iteration 208/1000 | Loss: 0.00002999
Iteration 209/1000 | Loss: 0.00002999
Iteration 210/1000 | Loss: 0.00002999
Iteration 211/1000 | Loss: 0.00002999
Iteration 212/1000 | Loss: 0.00002999
Iteration 213/1000 | Loss: 0.00002999
Iteration 214/1000 | Loss: 0.00002999
Iteration 215/1000 | Loss: 0.00002999
Iteration 216/1000 | Loss: 0.00002999
Iteration 217/1000 | Loss: 0.00002999
Iteration 218/1000 | Loss: 0.00002999
Iteration 219/1000 | Loss: 0.00002999
Iteration 220/1000 | Loss: 0.00002999
Iteration 221/1000 | Loss: 0.00002999
Iteration 222/1000 | Loss: 0.00002999
Iteration 223/1000 | Loss: 0.00002999
Iteration 224/1000 | Loss: 0.00002999
Iteration 225/1000 | Loss: 0.00002999
Iteration 226/1000 | Loss: 0.00002999
Iteration 227/1000 | Loss: 0.00002999
Iteration 228/1000 | Loss: 0.00002999
Iteration 229/1000 | Loss: 0.00002999
Iteration 230/1000 | Loss: 0.00002999
Iteration 231/1000 | Loss: 0.00002999
Iteration 232/1000 | Loss: 0.00002999
Iteration 233/1000 | Loss: 0.00002999
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 233. Stopping optimization.
Last 5 losses: [2.998936724907253e-05, 2.998936724907253e-05, 2.998936724907253e-05, 2.998936724907253e-05, 2.998936724907253e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.998936724907253e-05

Optimization complete. Final v2v error: 3.9303479194641113 mm

Highest mean error: 12.400932312011719 mm for frame 63

Lowest mean error: 2.594249725341797 mm for frame 24

Saving results

Total time: 230.47164011001587
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00409101
Iteration 2/25 | Loss: 0.00133754
Iteration 3/25 | Loss: 0.00122071
Iteration 4/25 | Loss: 0.00120932
Iteration 5/25 | Loss: 0.00120702
Iteration 6/25 | Loss: 0.00120657
Iteration 7/25 | Loss: 0.00120657
Iteration 8/25 | Loss: 0.00120657
Iteration 9/25 | Loss: 0.00120657
Iteration 10/25 | Loss: 0.00120657
Iteration 11/25 | Loss: 0.00120657
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0012065700720995665, 0.0012065700720995665, 0.0012065700720995665, 0.0012065700720995665, 0.0012065700720995665]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012065700720995665

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.15796649
Iteration 2/25 | Loss: 0.00254156
Iteration 3/25 | Loss: 0.00254155
Iteration 4/25 | Loss: 0.00254155
Iteration 5/25 | Loss: 0.00254155
Iteration 6/25 | Loss: 0.00254155
Iteration 7/25 | Loss: 0.00254155
Iteration 8/25 | Loss: 0.00254155
Iteration 9/25 | Loss: 0.00254155
Iteration 10/25 | Loss: 0.00254155
Iteration 11/25 | Loss: 0.00254155
Iteration 12/25 | Loss: 0.00254155
Iteration 13/25 | Loss: 0.00254155
Iteration 14/25 | Loss: 0.00254155
Iteration 15/25 | Loss: 0.00254155
Iteration 16/25 | Loss: 0.00254155
Iteration 17/25 | Loss: 0.00254155
Iteration 18/25 | Loss: 0.00254155
Iteration 19/25 | Loss: 0.00254155
Iteration 20/25 | Loss: 0.00254155
Iteration 21/25 | Loss: 0.00254155
Iteration 22/25 | Loss: 0.00254155
Iteration 23/25 | Loss: 0.00254155
Iteration 24/25 | Loss: 0.00254155
Iteration 25/25 | Loss: 0.00254155

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00254155
Iteration 2/1000 | Loss: 0.00002046
Iteration 3/1000 | Loss: 0.00001453
Iteration 4/1000 | Loss: 0.00001300
Iteration 5/1000 | Loss: 0.00001225
Iteration 6/1000 | Loss: 0.00001163
Iteration 7/1000 | Loss: 0.00001119
Iteration 8/1000 | Loss: 0.00001116
Iteration 9/1000 | Loss: 0.00001092
Iteration 10/1000 | Loss: 0.00001078
Iteration 11/1000 | Loss: 0.00001071
Iteration 12/1000 | Loss: 0.00001070
Iteration 13/1000 | Loss: 0.00001070
Iteration 14/1000 | Loss: 0.00001066
Iteration 15/1000 | Loss: 0.00001063
Iteration 16/1000 | Loss: 0.00001062
Iteration 17/1000 | Loss: 0.00001055
Iteration 18/1000 | Loss: 0.00001055
Iteration 19/1000 | Loss: 0.00001048
Iteration 20/1000 | Loss: 0.00001046
Iteration 21/1000 | Loss: 0.00001045
Iteration 22/1000 | Loss: 0.00001045
Iteration 23/1000 | Loss: 0.00001044
Iteration 24/1000 | Loss: 0.00001044
Iteration 25/1000 | Loss: 0.00001040
Iteration 26/1000 | Loss: 0.00001039
Iteration 27/1000 | Loss: 0.00001039
Iteration 28/1000 | Loss: 0.00001039
Iteration 29/1000 | Loss: 0.00001039
Iteration 30/1000 | Loss: 0.00001039
Iteration 31/1000 | Loss: 0.00001039
Iteration 32/1000 | Loss: 0.00001039
Iteration 33/1000 | Loss: 0.00001039
Iteration 34/1000 | Loss: 0.00001039
Iteration 35/1000 | Loss: 0.00001038
Iteration 36/1000 | Loss: 0.00001038
Iteration 37/1000 | Loss: 0.00001038
Iteration 38/1000 | Loss: 0.00001037
Iteration 39/1000 | Loss: 0.00001037
Iteration 40/1000 | Loss: 0.00001037
Iteration 41/1000 | Loss: 0.00001037
Iteration 42/1000 | Loss: 0.00001037
Iteration 43/1000 | Loss: 0.00001036
Iteration 44/1000 | Loss: 0.00001036
Iteration 45/1000 | Loss: 0.00001036
Iteration 46/1000 | Loss: 0.00001036
Iteration 47/1000 | Loss: 0.00001035
Iteration 48/1000 | Loss: 0.00001035
Iteration 49/1000 | Loss: 0.00001035
Iteration 50/1000 | Loss: 0.00001035
Iteration 51/1000 | Loss: 0.00001035
Iteration 52/1000 | Loss: 0.00001034
Iteration 53/1000 | Loss: 0.00001034
Iteration 54/1000 | Loss: 0.00001033
Iteration 55/1000 | Loss: 0.00001033
Iteration 56/1000 | Loss: 0.00001033
Iteration 57/1000 | Loss: 0.00001033
Iteration 58/1000 | Loss: 0.00001033
Iteration 59/1000 | Loss: 0.00001033
Iteration 60/1000 | Loss: 0.00001032
Iteration 61/1000 | Loss: 0.00001032
Iteration 62/1000 | Loss: 0.00001032
Iteration 63/1000 | Loss: 0.00001032
Iteration 64/1000 | Loss: 0.00001032
Iteration 65/1000 | Loss: 0.00001031
Iteration 66/1000 | Loss: 0.00001031
Iteration 67/1000 | Loss: 0.00001031
Iteration 68/1000 | Loss: 0.00001031
Iteration 69/1000 | Loss: 0.00001031
Iteration 70/1000 | Loss: 0.00001031
Iteration 71/1000 | Loss: 0.00001031
Iteration 72/1000 | Loss: 0.00001030
Iteration 73/1000 | Loss: 0.00001030
Iteration 74/1000 | Loss: 0.00001030
Iteration 75/1000 | Loss: 0.00001030
Iteration 76/1000 | Loss: 0.00001030
Iteration 77/1000 | Loss: 0.00001030
Iteration 78/1000 | Loss: 0.00001030
Iteration 79/1000 | Loss: 0.00001030
Iteration 80/1000 | Loss: 0.00001030
Iteration 81/1000 | Loss: 0.00001030
Iteration 82/1000 | Loss: 0.00001030
Iteration 83/1000 | Loss: 0.00001030
Iteration 84/1000 | Loss: 0.00001030
Iteration 85/1000 | Loss: 0.00001030
Iteration 86/1000 | Loss: 0.00001029
Iteration 87/1000 | Loss: 0.00001029
Iteration 88/1000 | Loss: 0.00001029
Iteration 89/1000 | Loss: 0.00001029
Iteration 90/1000 | Loss: 0.00001028
Iteration 91/1000 | Loss: 0.00001028
Iteration 92/1000 | Loss: 0.00001028
Iteration 93/1000 | Loss: 0.00001028
Iteration 94/1000 | Loss: 0.00001028
Iteration 95/1000 | Loss: 0.00001028
Iteration 96/1000 | Loss: 0.00001028
Iteration 97/1000 | Loss: 0.00001027
Iteration 98/1000 | Loss: 0.00001027
Iteration 99/1000 | Loss: 0.00001027
Iteration 100/1000 | Loss: 0.00001026
Iteration 101/1000 | Loss: 0.00001026
Iteration 102/1000 | Loss: 0.00001026
Iteration 103/1000 | Loss: 0.00001026
Iteration 104/1000 | Loss: 0.00001026
Iteration 105/1000 | Loss: 0.00001026
Iteration 106/1000 | Loss: 0.00001026
Iteration 107/1000 | Loss: 0.00001026
Iteration 108/1000 | Loss: 0.00001026
Iteration 109/1000 | Loss: 0.00001026
Iteration 110/1000 | Loss: 0.00001026
Iteration 111/1000 | Loss: 0.00001026
Iteration 112/1000 | Loss: 0.00001026
Iteration 113/1000 | Loss: 0.00001026
Iteration 114/1000 | Loss: 0.00001026
Iteration 115/1000 | Loss: 0.00001026
Iteration 116/1000 | Loss: 0.00001025
Iteration 117/1000 | Loss: 0.00001025
Iteration 118/1000 | Loss: 0.00001025
Iteration 119/1000 | Loss: 0.00001025
Iteration 120/1000 | Loss: 0.00001025
Iteration 121/1000 | Loss: 0.00001025
Iteration 122/1000 | Loss: 0.00001025
Iteration 123/1000 | Loss: 0.00001025
Iteration 124/1000 | Loss: 0.00001025
Iteration 125/1000 | Loss: 0.00001025
Iteration 126/1000 | Loss: 0.00001025
Iteration 127/1000 | Loss: 0.00001025
Iteration 128/1000 | Loss: 0.00001025
Iteration 129/1000 | Loss: 0.00001025
Iteration 130/1000 | Loss: 0.00001024
Iteration 131/1000 | Loss: 0.00001024
Iteration 132/1000 | Loss: 0.00001024
Iteration 133/1000 | Loss: 0.00001024
Iteration 134/1000 | Loss: 0.00001024
Iteration 135/1000 | Loss: 0.00001024
Iteration 136/1000 | Loss: 0.00001024
Iteration 137/1000 | Loss: 0.00001024
Iteration 138/1000 | Loss: 0.00001024
Iteration 139/1000 | Loss: 0.00001024
Iteration 140/1000 | Loss: 0.00001024
Iteration 141/1000 | Loss: 0.00001024
Iteration 142/1000 | Loss: 0.00001024
Iteration 143/1000 | Loss: 0.00001023
Iteration 144/1000 | Loss: 0.00001023
Iteration 145/1000 | Loss: 0.00001023
Iteration 146/1000 | Loss: 0.00001023
Iteration 147/1000 | Loss: 0.00001023
Iteration 148/1000 | Loss: 0.00001023
Iteration 149/1000 | Loss: 0.00001023
Iteration 150/1000 | Loss: 0.00001023
Iteration 151/1000 | Loss: 0.00001023
Iteration 152/1000 | Loss: 0.00001023
Iteration 153/1000 | Loss: 0.00001023
Iteration 154/1000 | Loss: 0.00001023
Iteration 155/1000 | Loss: 0.00001022
Iteration 156/1000 | Loss: 0.00001022
Iteration 157/1000 | Loss: 0.00001022
Iteration 158/1000 | Loss: 0.00001022
Iteration 159/1000 | Loss: 0.00001022
Iteration 160/1000 | Loss: 0.00001022
Iteration 161/1000 | Loss: 0.00001022
Iteration 162/1000 | Loss: 0.00001022
Iteration 163/1000 | Loss: 0.00001022
Iteration 164/1000 | Loss: 0.00001022
Iteration 165/1000 | Loss: 0.00001022
Iteration 166/1000 | Loss: 0.00001022
Iteration 167/1000 | Loss: 0.00001022
Iteration 168/1000 | Loss: 0.00001022
Iteration 169/1000 | Loss: 0.00001022
Iteration 170/1000 | Loss: 0.00001022
Iteration 171/1000 | Loss: 0.00001022
Iteration 172/1000 | Loss: 0.00001022
Iteration 173/1000 | Loss: 0.00001022
Iteration 174/1000 | Loss: 0.00001022
Iteration 175/1000 | Loss: 0.00001022
Iteration 176/1000 | Loss: 0.00001022
Iteration 177/1000 | Loss: 0.00001022
Iteration 178/1000 | Loss: 0.00001022
Iteration 179/1000 | Loss: 0.00001022
Iteration 180/1000 | Loss: 0.00001022
Iteration 181/1000 | Loss: 0.00001022
Iteration 182/1000 | Loss: 0.00001022
Iteration 183/1000 | Loss: 0.00001022
Iteration 184/1000 | Loss: 0.00001022
Iteration 185/1000 | Loss: 0.00001022
Iteration 186/1000 | Loss: 0.00001022
Iteration 187/1000 | Loss: 0.00001022
Iteration 188/1000 | Loss: 0.00001022
Iteration 189/1000 | Loss: 0.00001022
Iteration 190/1000 | Loss: 0.00001022
Iteration 191/1000 | Loss: 0.00001022
Iteration 192/1000 | Loss: 0.00001022
Iteration 193/1000 | Loss: 0.00001022
Iteration 194/1000 | Loss: 0.00001022
Iteration 195/1000 | Loss: 0.00001022
Iteration 196/1000 | Loss: 0.00001022
Iteration 197/1000 | Loss: 0.00001022
Iteration 198/1000 | Loss: 0.00001022
Iteration 199/1000 | Loss: 0.00001022
Iteration 200/1000 | Loss: 0.00001022
Iteration 201/1000 | Loss: 0.00001022
Iteration 202/1000 | Loss: 0.00001022
Iteration 203/1000 | Loss: 0.00001022
Iteration 204/1000 | Loss: 0.00001022
Iteration 205/1000 | Loss: 0.00001022
Iteration 206/1000 | Loss: 0.00001022
Iteration 207/1000 | Loss: 0.00001022
Iteration 208/1000 | Loss: 0.00001022
Iteration 209/1000 | Loss: 0.00001022
Iteration 210/1000 | Loss: 0.00001022
Iteration 211/1000 | Loss: 0.00001022
Iteration 212/1000 | Loss: 0.00001022
Iteration 213/1000 | Loss: 0.00001022
Iteration 214/1000 | Loss: 0.00001022
Iteration 215/1000 | Loss: 0.00001022
Iteration 216/1000 | Loss: 0.00001022
Iteration 217/1000 | Loss: 0.00001022
Iteration 218/1000 | Loss: 0.00001022
Iteration 219/1000 | Loss: 0.00001022
Iteration 220/1000 | Loss: 0.00001022
Iteration 221/1000 | Loss: 0.00001022
Iteration 222/1000 | Loss: 0.00001022
Iteration 223/1000 | Loss: 0.00001022
Iteration 224/1000 | Loss: 0.00001022
Iteration 225/1000 | Loss: 0.00001022
Iteration 226/1000 | Loss: 0.00001022
Iteration 227/1000 | Loss: 0.00001022
Iteration 228/1000 | Loss: 0.00001022
Iteration 229/1000 | Loss: 0.00001022
Iteration 230/1000 | Loss: 0.00001022
Iteration 231/1000 | Loss: 0.00001022
Iteration 232/1000 | Loss: 0.00001022
Iteration 233/1000 | Loss: 0.00001022
Iteration 234/1000 | Loss: 0.00001022
Iteration 235/1000 | Loss: 0.00001022
Iteration 236/1000 | Loss: 0.00001022
Iteration 237/1000 | Loss: 0.00001022
Iteration 238/1000 | Loss: 0.00001022
Iteration 239/1000 | Loss: 0.00001022
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 239. Stopping optimization.
Last 5 losses: [1.0218923307547811e-05, 1.0218923307547811e-05, 1.0218923307547811e-05, 1.0218923307547811e-05, 1.0218923307547811e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0218923307547811e-05

Optimization complete. Final v2v error: 2.7427310943603516 mm

Highest mean error: 3.229994773864746 mm for frame 115

Lowest mean error: 2.3323745727539062 mm for frame 0

Saving results

Total time: 36.7586145401001
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00881209
Iteration 2/25 | Loss: 0.00155068
Iteration 3/25 | Loss: 0.00130227
Iteration 4/25 | Loss: 0.00123407
Iteration 5/25 | Loss: 0.00124255
Iteration 6/25 | Loss: 0.00123808
Iteration 7/25 | Loss: 0.00122993
Iteration 8/25 | Loss: 0.00122555
Iteration 9/25 | Loss: 0.00121723
Iteration 10/25 | Loss: 0.00121619
Iteration 11/25 | Loss: 0.00120893
Iteration 12/25 | Loss: 0.00120459
Iteration 13/25 | Loss: 0.00120018
Iteration 14/25 | Loss: 0.00119914
Iteration 15/25 | Loss: 0.00119873
Iteration 16/25 | Loss: 0.00119863
Iteration 17/25 | Loss: 0.00119855
Iteration 18/25 | Loss: 0.00119855
Iteration 19/25 | Loss: 0.00119855
Iteration 20/25 | Loss: 0.00119855
Iteration 21/25 | Loss: 0.00119855
Iteration 22/25 | Loss: 0.00119855
Iteration 23/25 | Loss: 0.00119855
Iteration 24/25 | Loss: 0.00119855
Iteration 25/25 | Loss: 0.00119855

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.72949123
Iteration 2/25 | Loss: 0.00263523
Iteration 3/25 | Loss: 0.00263522
Iteration 4/25 | Loss: 0.00263522
Iteration 5/25 | Loss: 0.00263522
Iteration 6/25 | Loss: 0.00263522
Iteration 7/25 | Loss: 0.00263522
Iteration 8/25 | Loss: 0.00263522
Iteration 9/25 | Loss: 0.00263522
Iteration 10/25 | Loss: 0.00263522
Iteration 11/25 | Loss: 0.00263522
Iteration 12/25 | Loss: 0.00263522
Iteration 13/25 | Loss: 0.00263522
Iteration 14/25 | Loss: 0.00263522
Iteration 15/25 | Loss: 0.00263522
Iteration 16/25 | Loss: 0.00263522
Iteration 17/25 | Loss: 0.00263522
Iteration 18/25 | Loss: 0.00263522
Iteration 19/25 | Loss: 0.00263522
Iteration 20/25 | Loss: 0.00263522
Iteration 21/25 | Loss: 0.00263522
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0026352168060839176, 0.0026352168060839176, 0.0026352168060839176, 0.0026352168060839176, 0.0026352168060839176]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0026352168060839176

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00263522
Iteration 2/1000 | Loss: 0.00002351
Iteration 3/1000 | Loss: 0.00001810
Iteration 4/1000 | Loss: 0.00001618
Iteration 5/1000 | Loss: 0.00001521
Iteration 6/1000 | Loss: 0.00001450
Iteration 7/1000 | Loss: 0.00001402
Iteration 8/1000 | Loss: 0.00001371
Iteration 9/1000 | Loss: 0.00001355
Iteration 10/1000 | Loss: 0.00001341
Iteration 11/1000 | Loss: 0.00001341
Iteration 12/1000 | Loss: 0.00001340
Iteration 13/1000 | Loss: 0.00001338
Iteration 14/1000 | Loss: 0.00001333
Iteration 15/1000 | Loss: 0.00001333
Iteration 16/1000 | Loss: 0.00001326
Iteration 17/1000 | Loss: 0.00001326
Iteration 18/1000 | Loss: 0.00001325
Iteration 19/1000 | Loss: 0.00001321
Iteration 20/1000 | Loss: 0.00001321
Iteration 21/1000 | Loss: 0.00001320
Iteration 22/1000 | Loss: 0.00001320
Iteration 23/1000 | Loss: 0.00001320
Iteration 24/1000 | Loss: 0.00001320
Iteration 25/1000 | Loss: 0.00001320
Iteration 26/1000 | Loss: 0.00001319
Iteration 27/1000 | Loss: 0.00001316
Iteration 28/1000 | Loss: 0.00001307
Iteration 29/1000 | Loss: 0.00001307
Iteration 30/1000 | Loss: 0.00001307
Iteration 31/1000 | Loss: 0.00001306
Iteration 32/1000 | Loss: 0.00001306
Iteration 33/1000 | Loss: 0.00001306
Iteration 34/1000 | Loss: 0.00001305
Iteration 35/1000 | Loss: 0.00001304
Iteration 36/1000 | Loss: 0.00001304
Iteration 37/1000 | Loss: 0.00001303
Iteration 38/1000 | Loss: 0.00001303
Iteration 39/1000 | Loss: 0.00001303
Iteration 40/1000 | Loss: 0.00001302
Iteration 41/1000 | Loss: 0.00001302
Iteration 42/1000 | Loss: 0.00001302
Iteration 43/1000 | Loss: 0.00001302
Iteration 44/1000 | Loss: 0.00001301
Iteration 45/1000 | Loss: 0.00001301
Iteration 46/1000 | Loss: 0.00001301
Iteration 47/1000 | Loss: 0.00001301
Iteration 48/1000 | Loss: 0.00001301
Iteration 49/1000 | Loss: 0.00001301
Iteration 50/1000 | Loss: 0.00001301
Iteration 51/1000 | Loss: 0.00001300
Iteration 52/1000 | Loss: 0.00001300
Iteration 53/1000 | Loss: 0.00001300
Iteration 54/1000 | Loss: 0.00001300
Iteration 55/1000 | Loss: 0.00001300
Iteration 56/1000 | Loss: 0.00001300
Iteration 57/1000 | Loss: 0.00001299
Iteration 58/1000 | Loss: 0.00001299
Iteration 59/1000 | Loss: 0.00001299
Iteration 60/1000 | Loss: 0.00001299
Iteration 61/1000 | Loss: 0.00001299
Iteration 62/1000 | Loss: 0.00001298
Iteration 63/1000 | Loss: 0.00001298
Iteration 64/1000 | Loss: 0.00001298
Iteration 65/1000 | Loss: 0.00001298
Iteration 66/1000 | Loss: 0.00001298
Iteration 67/1000 | Loss: 0.00001298
Iteration 68/1000 | Loss: 0.00001297
Iteration 69/1000 | Loss: 0.00001297
Iteration 70/1000 | Loss: 0.00001297
Iteration 71/1000 | Loss: 0.00001297
Iteration 72/1000 | Loss: 0.00001296
Iteration 73/1000 | Loss: 0.00001296
Iteration 74/1000 | Loss: 0.00001296
Iteration 75/1000 | Loss: 0.00001296
Iteration 76/1000 | Loss: 0.00001296
Iteration 77/1000 | Loss: 0.00001296
Iteration 78/1000 | Loss: 0.00001296
Iteration 79/1000 | Loss: 0.00001296
Iteration 80/1000 | Loss: 0.00001296
Iteration 81/1000 | Loss: 0.00001296
Iteration 82/1000 | Loss: 0.00001296
Iteration 83/1000 | Loss: 0.00001296
Iteration 84/1000 | Loss: 0.00001296
Iteration 85/1000 | Loss: 0.00001296
Iteration 86/1000 | Loss: 0.00001296
Iteration 87/1000 | Loss: 0.00001296
Iteration 88/1000 | Loss: 0.00001296
Iteration 89/1000 | Loss: 0.00001296
Iteration 90/1000 | Loss: 0.00001296
Iteration 91/1000 | Loss: 0.00001296
Iteration 92/1000 | Loss: 0.00001296
Iteration 93/1000 | Loss: 0.00001296
Iteration 94/1000 | Loss: 0.00001296
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.2958242223248817e-05, 1.2958242223248817e-05, 1.2958242223248817e-05, 1.2958242223248817e-05, 1.2958242223248817e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2958242223248817e-05

Optimization complete. Final v2v error: 3.1128649711608887 mm

Highest mean error: 8.27222728729248 mm for frame 153

Lowest mean error: 2.6411592960357666 mm for frame 224

Saving results

Total time: 58.685866832733154
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00879562
Iteration 2/25 | Loss: 0.00170027
Iteration 3/25 | Loss: 0.00128562
Iteration 4/25 | Loss: 0.00124646
Iteration 5/25 | Loss: 0.00124333
Iteration 6/25 | Loss: 0.00124333
Iteration 7/25 | Loss: 0.00124333
Iteration 8/25 | Loss: 0.00124333
Iteration 9/25 | Loss: 0.00124333
Iteration 10/25 | Loss: 0.00124333
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0012433252995833755, 0.0012433252995833755, 0.0012433252995833755, 0.0012433252995833755, 0.0012433252995833755]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012433252995833755

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46188796
Iteration 2/25 | Loss: 0.00205004
Iteration 3/25 | Loss: 0.00205003
Iteration 4/25 | Loss: 0.00205003
Iteration 5/25 | Loss: 0.00205003
Iteration 6/25 | Loss: 0.00205003
Iteration 7/25 | Loss: 0.00205003
Iteration 8/25 | Loss: 0.00205003
Iteration 9/25 | Loss: 0.00205003
Iteration 10/25 | Loss: 0.00205003
Iteration 11/25 | Loss: 0.00205003
Iteration 12/25 | Loss: 0.00205003
Iteration 13/25 | Loss: 0.00205003
Iteration 14/25 | Loss: 0.00205003
Iteration 15/25 | Loss: 0.00205003
Iteration 16/25 | Loss: 0.00205003
Iteration 17/25 | Loss: 0.00205003
Iteration 18/25 | Loss: 0.00205003
Iteration 19/25 | Loss: 0.00205003
Iteration 20/25 | Loss: 0.00205003
Iteration 21/25 | Loss: 0.00205003
Iteration 22/25 | Loss: 0.00205003
Iteration 23/25 | Loss: 0.00205003
Iteration 24/25 | Loss: 0.00205003
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.002050030278041959, 0.002050030278041959, 0.002050030278041959, 0.002050030278041959, 0.002050030278041959]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002050030278041959

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00205003
Iteration 2/1000 | Loss: 0.00003515
Iteration 3/1000 | Loss: 0.00002029
Iteration 4/1000 | Loss: 0.00001713
Iteration 5/1000 | Loss: 0.00001609
Iteration 6/1000 | Loss: 0.00001547
Iteration 7/1000 | Loss: 0.00001503
Iteration 8/1000 | Loss: 0.00001470
Iteration 9/1000 | Loss: 0.00001430
Iteration 10/1000 | Loss: 0.00001415
Iteration 11/1000 | Loss: 0.00001402
Iteration 12/1000 | Loss: 0.00001391
Iteration 13/1000 | Loss: 0.00001390
Iteration 14/1000 | Loss: 0.00001388
Iteration 15/1000 | Loss: 0.00001386
Iteration 16/1000 | Loss: 0.00001385
Iteration 17/1000 | Loss: 0.00001385
Iteration 18/1000 | Loss: 0.00001384
Iteration 19/1000 | Loss: 0.00001383
Iteration 20/1000 | Loss: 0.00001382
Iteration 21/1000 | Loss: 0.00001382
Iteration 22/1000 | Loss: 0.00001381
Iteration 23/1000 | Loss: 0.00001375
Iteration 24/1000 | Loss: 0.00001370
Iteration 25/1000 | Loss: 0.00001363
Iteration 26/1000 | Loss: 0.00001362
Iteration 27/1000 | Loss: 0.00001362
Iteration 28/1000 | Loss: 0.00001361
Iteration 29/1000 | Loss: 0.00001361
Iteration 30/1000 | Loss: 0.00001360
Iteration 31/1000 | Loss: 0.00001359
Iteration 32/1000 | Loss: 0.00001359
Iteration 33/1000 | Loss: 0.00001359
Iteration 34/1000 | Loss: 0.00001357
Iteration 35/1000 | Loss: 0.00001356
Iteration 36/1000 | Loss: 0.00001355
Iteration 37/1000 | Loss: 0.00001355
Iteration 38/1000 | Loss: 0.00001354
Iteration 39/1000 | Loss: 0.00001354
Iteration 40/1000 | Loss: 0.00001354
Iteration 41/1000 | Loss: 0.00001353
Iteration 42/1000 | Loss: 0.00001353
Iteration 43/1000 | Loss: 0.00001353
Iteration 44/1000 | Loss: 0.00001353
Iteration 45/1000 | Loss: 0.00001352
Iteration 46/1000 | Loss: 0.00001352
Iteration 47/1000 | Loss: 0.00001352
Iteration 48/1000 | Loss: 0.00001351
Iteration 49/1000 | Loss: 0.00001351
Iteration 50/1000 | Loss: 0.00001350
Iteration 51/1000 | Loss: 0.00001350
Iteration 52/1000 | Loss: 0.00001350
Iteration 53/1000 | Loss: 0.00001350
Iteration 54/1000 | Loss: 0.00001350
Iteration 55/1000 | Loss: 0.00001349
Iteration 56/1000 | Loss: 0.00001349
Iteration 57/1000 | Loss: 0.00001349
Iteration 58/1000 | Loss: 0.00001348
Iteration 59/1000 | Loss: 0.00001348
Iteration 60/1000 | Loss: 0.00001348
Iteration 61/1000 | Loss: 0.00001348
Iteration 62/1000 | Loss: 0.00001348
Iteration 63/1000 | Loss: 0.00001347
Iteration 64/1000 | Loss: 0.00001347
Iteration 65/1000 | Loss: 0.00001347
Iteration 66/1000 | Loss: 0.00001347
Iteration 67/1000 | Loss: 0.00001347
Iteration 68/1000 | Loss: 0.00001347
Iteration 69/1000 | Loss: 0.00001347
Iteration 70/1000 | Loss: 0.00001347
Iteration 71/1000 | Loss: 0.00001347
Iteration 72/1000 | Loss: 0.00001347
Iteration 73/1000 | Loss: 0.00001347
Iteration 74/1000 | Loss: 0.00001347
Iteration 75/1000 | Loss: 0.00001347
Iteration 76/1000 | Loss: 0.00001347
Iteration 77/1000 | Loss: 0.00001347
Iteration 78/1000 | Loss: 0.00001347
Iteration 79/1000 | Loss: 0.00001347
Iteration 80/1000 | Loss: 0.00001347
Iteration 81/1000 | Loss: 0.00001347
Iteration 82/1000 | Loss: 0.00001347
Iteration 83/1000 | Loss: 0.00001347
Iteration 84/1000 | Loss: 0.00001347
Iteration 85/1000 | Loss: 0.00001347
Iteration 86/1000 | Loss: 0.00001347
Iteration 87/1000 | Loss: 0.00001347
Iteration 88/1000 | Loss: 0.00001347
Iteration 89/1000 | Loss: 0.00001347
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 89. Stopping optimization.
Last 5 losses: [1.3469378245645203e-05, 1.3469378245645203e-05, 1.3469378245645203e-05, 1.3469378245645203e-05, 1.3469378245645203e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3469378245645203e-05

Optimization complete. Final v2v error: 3.194000244140625 mm

Highest mean error: 3.476571559906006 mm for frame 222

Lowest mean error: 2.944903612136841 mm for frame 13

Saving results

Total time: 35.718087911605835
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01062262
Iteration 2/25 | Loss: 0.00314084
Iteration 3/25 | Loss: 0.00203496
Iteration 4/25 | Loss: 0.00199612
Iteration 5/25 | Loss: 0.00162458
Iteration 6/25 | Loss: 0.00152603
Iteration 7/25 | Loss: 0.00142000
Iteration 8/25 | Loss: 0.00136634
Iteration 9/25 | Loss: 0.00132984
Iteration 10/25 | Loss: 0.00132362
Iteration 11/25 | Loss: 0.00131954
Iteration 12/25 | Loss: 0.00131794
Iteration 13/25 | Loss: 0.00131686
Iteration 14/25 | Loss: 0.00131649
Iteration 15/25 | Loss: 0.00131630
Iteration 16/25 | Loss: 0.00131618
Iteration 17/25 | Loss: 0.00131614
Iteration 18/25 | Loss: 0.00131613
Iteration 19/25 | Loss: 0.00131613
Iteration 20/25 | Loss: 0.00131613
Iteration 21/25 | Loss: 0.00131613
Iteration 22/25 | Loss: 0.00131613
Iteration 23/25 | Loss: 0.00131613
Iteration 24/25 | Loss: 0.00131612
Iteration 25/25 | Loss: 0.00131612

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.15575337
Iteration 2/25 | Loss: 0.00348790
Iteration 3/25 | Loss: 0.00348790
Iteration 4/25 | Loss: 0.00348790
Iteration 5/25 | Loss: 0.00348790
Iteration 6/25 | Loss: 0.00348790
Iteration 7/25 | Loss: 0.00348790
Iteration 8/25 | Loss: 0.00348790
Iteration 9/25 | Loss: 0.00348790
Iteration 10/25 | Loss: 0.00348790
Iteration 11/25 | Loss: 0.00348790
Iteration 12/25 | Loss: 0.00348790
Iteration 13/25 | Loss: 0.00348790
Iteration 14/25 | Loss: 0.00348790
Iteration 15/25 | Loss: 0.00348790
Iteration 16/25 | Loss: 0.00348790
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.003487895941361785, 0.003487895941361785, 0.003487895941361785, 0.003487895941361785, 0.003487895941361785]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003487895941361785

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00348790
Iteration 2/1000 | Loss: 0.00034866
Iteration 3/1000 | Loss: 0.00019538
Iteration 4/1000 | Loss: 0.00022992
Iteration 5/1000 | Loss: 0.00016496
Iteration 6/1000 | Loss: 0.00054108
Iteration 7/1000 | Loss: 0.00042107
Iteration 8/1000 | Loss: 0.00015680
Iteration 9/1000 | Loss: 0.00034485
Iteration 10/1000 | Loss: 0.00007975
Iteration 11/1000 | Loss: 0.00021375
Iteration 12/1000 | Loss: 0.00006738
Iteration 13/1000 | Loss: 0.00004867
Iteration 14/1000 | Loss: 0.00003819
Iteration 15/1000 | Loss: 0.00003602
Iteration 16/1000 | Loss: 0.00008424
Iteration 17/1000 | Loss: 0.00004609
Iteration 18/1000 | Loss: 0.00006192
Iteration 19/1000 | Loss: 0.00025176
Iteration 20/1000 | Loss: 0.00003850
Iteration 21/1000 | Loss: 0.00010256
Iteration 22/1000 | Loss: 0.00004553
Iteration 23/1000 | Loss: 0.00003309
Iteration 24/1000 | Loss: 0.00003648
Iteration 25/1000 | Loss: 0.00010839
Iteration 26/1000 | Loss: 0.00023220
Iteration 27/1000 | Loss: 0.00008014
Iteration 28/1000 | Loss: 0.00005731
Iteration 29/1000 | Loss: 0.00003859
Iteration 30/1000 | Loss: 0.00004117
Iteration 31/1000 | Loss: 0.00004635
Iteration 32/1000 | Loss: 0.00007799
Iteration 33/1000 | Loss: 0.00004289
Iteration 34/1000 | Loss: 0.00003045
Iteration 35/1000 | Loss: 0.00004928
Iteration 36/1000 | Loss: 0.00005554
Iteration 37/1000 | Loss: 0.00017202
Iteration 38/1000 | Loss: 0.00010072
Iteration 39/1000 | Loss: 0.00003059
Iteration 40/1000 | Loss: 0.00005199
Iteration 41/1000 | Loss: 0.00005349
Iteration 42/1000 | Loss: 0.00006772
Iteration 43/1000 | Loss: 0.00007527
Iteration 44/1000 | Loss: 0.00010164
Iteration 45/1000 | Loss: 0.00003865
Iteration 46/1000 | Loss: 0.00004933
Iteration 47/1000 | Loss: 0.00003923
Iteration 48/1000 | Loss: 0.00003446
Iteration 49/1000 | Loss: 0.00002987
Iteration 50/1000 | Loss: 0.00002985
Iteration 51/1000 | Loss: 0.00002985
Iteration 52/1000 | Loss: 0.00002985
Iteration 53/1000 | Loss: 0.00002984
Iteration 54/1000 | Loss: 0.00002984
Iteration 55/1000 | Loss: 0.00002984
Iteration 56/1000 | Loss: 0.00002984
Iteration 57/1000 | Loss: 0.00002984
Iteration 58/1000 | Loss: 0.00002983
Iteration 59/1000 | Loss: 0.00002983
Iteration 60/1000 | Loss: 0.00002983
Iteration 61/1000 | Loss: 0.00002982
Iteration 62/1000 | Loss: 0.00004507
Iteration 63/1000 | Loss: 0.00006416
Iteration 64/1000 | Loss: 0.00065321
Iteration 65/1000 | Loss: 0.00043499
Iteration 66/1000 | Loss: 0.00016865
Iteration 67/1000 | Loss: 0.00013479
Iteration 68/1000 | Loss: 0.00016541
Iteration 69/1000 | Loss: 0.00014033
Iteration 70/1000 | Loss: 0.00009120
Iteration 71/1000 | Loss: 0.00007503
Iteration 72/1000 | Loss: 0.00009266
Iteration 73/1000 | Loss: 0.00003523
Iteration 74/1000 | Loss: 0.00002078
Iteration 75/1000 | Loss: 0.00003395
Iteration 76/1000 | Loss: 0.00004270
Iteration 77/1000 | Loss: 0.00002174
Iteration 78/1000 | Loss: 0.00010366
Iteration 79/1000 | Loss: 0.00001793
Iteration 80/1000 | Loss: 0.00003848
Iteration 81/1000 | Loss: 0.00011201
Iteration 82/1000 | Loss: 0.00005046
Iteration 83/1000 | Loss: 0.00001867
Iteration 84/1000 | Loss: 0.00002639
Iteration 85/1000 | Loss: 0.00001690
Iteration 86/1000 | Loss: 0.00006813
Iteration 87/1000 | Loss: 0.00007736
Iteration 88/1000 | Loss: 0.00006521
Iteration 89/1000 | Loss: 0.00002196
Iteration 90/1000 | Loss: 0.00004068
Iteration 91/1000 | Loss: 0.00001849
Iteration 92/1000 | Loss: 0.00001675
Iteration 93/1000 | Loss: 0.00003389
Iteration 94/1000 | Loss: 0.00001669
Iteration 95/1000 | Loss: 0.00003250
Iteration 96/1000 | Loss: 0.00001666
Iteration 97/1000 | Loss: 0.00001661
Iteration 98/1000 | Loss: 0.00002154
Iteration 99/1000 | Loss: 0.00001664
Iteration 100/1000 | Loss: 0.00001663
Iteration 101/1000 | Loss: 0.00001662
Iteration 102/1000 | Loss: 0.00001661
Iteration 103/1000 | Loss: 0.00002782
Iteration 104/1000 | Loss: 0.00002166
Iteration 105/1000 | Loss: 0.00002054
Iteration 106/1000 | Loss: 0.00001660
Iteration 107/1000 | Loss: 0.00001659
Iteration 108/1000 | Loss: 0.00001659
Iteration 109/1000 | Loss: 0.00001658
Iteration 110/1000 | Loss: 0.00001658
Iteration 111/1000 | Loss: 0.00001658
Iteration 112/1000 | Loss: 0.00001657
Iteration 113/1000 | Loss: 0.00001657
Iteration 114/1000 | Loss: 0.00001657
Iteration 115/1000 | Loss: 0.00001656
Iteration 116/1000 | Loss: 0.00001656
Iteration 117/1000 | Loss: 0.00001656
Iteration 118/1000 | Loss: 0.00001656
Iteration 119/1000 | Loss: 0.00001656
Iteration 120/1000 | Loss: 0.00001656
Iteration 121/1000 | Loss: 0.00001656
Iteration 122/1000 | Loss: 0.00001656
Iteration 123/1000 | Loss: 0.00001656
Iteration 124/1000 | Loss: 0.00001656
Iteration 125/1000 | Loss: 0.00001655
Iteration 126/1000 | Loss: 0.00001655
Iteration 127/1000 | Loss: 0.00001655
Iteration 128/1000 | Loss: 0.00001655
Iteration 129/1000 | Loss: 0.00001655
Iteration 130/1000 | Loss: 0.00001655
Iteration 131/1000 | Loss: 0.00001655
Iteration 132/1000 | Loss: 0.00001655
Iteration 133/1000 | Loss: 0.00001655
Iteration 134/1000 | Loss: 0.00001655
Iteration 135/1000 | Loss: 0.00001655
Iteration 136/1000 | Loss: 0.00001655
Iteration 137/1000 | Loss: 0.00001655
Iteration 138/1000 | Loss: 0.00001655
Iteration 139/1000 | Loss: 0.00001655
Iteration 140/1000 | Loss: 0.00001655
Iteration 141/1000 | Loss: 0.00001655
Iteration 142/1000 | Loss: 0.00001655
Iteration 143/1000 | Loss: 0.00001655
Iteration 144/1000 | Loss: 0.00001655
Iteration 145/1000 | Loss: 0.00001655
Iteration 146/1000 | Loss: 0.00001654
Iteration 147/1000 | Loss: 0.00001654
Iteration 148/1000 | Loss: 0.00001654
Iteration 149/1000 | Loss: 0.00001654
Iteration 150/1000 | Loss: 0.00001654
Iteration 151/1000 | Loss: 0.00001654
Iteration 152/1000 | Loss: 0.00001654
Iteration 153/1000 | Loss: 0.00001654
Iteration 154/1000 | Loss: 0.00001654
Iteration 155/1000 | Loss: 0.00001654
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 155. Stopping optimization.
Last 5 losses: [1.654361949476879e-05, 1.654361949476879e-05, 1.654361949476879e-05, 1.654361949476879e-05, 1.654361949476879e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.654361949476879e-05

Optimization complete. Final v2v error: 3.371520757675171 mm

Highest mean error: 9.370814323425293 mm for frame 127

Lowest mean error: 3.197378396987915 mm for frame 5

Saving results

Total time: 171.84147787094116
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00787311
Iteration 2/25 | Loss: 0.00189150
Iteration 3/25 | Loss: 0.00135432
Iteration 4/25 | Loss: 0.00126114
Iteration 5/25 | Loss: 0.00124543
Iteration 6/25 | Loss: 0.00124672
Iteration 7/25 | Loss: 0.00122198
Iteration 8/25 | Loss: 0.00121087
Iteration 9/25 | Loss: 0.00120233
Iteration 10/25 | Loss: 0.00119906
Iteration 11/25 | Loss: 0.00119577
Iteration 12/25 | Loss: 0.00119672
Iteration 13/25 | Loss: 0.00119518
Iteration 14/25 | Loss: 0.00119165
Iteration 15/25 | Loss: 0.00119245
Iteration 16/25 | Loss: 0.00119108
Iteration 17/25 | Loss: 0.00118965
Iteration 18/25 | Loss: 0.00119051
Iteration 19/25 | Loss: 0.00118939
Iteration 20/25 | Loss: 0.00118972
Iteration 21/25 | Loss: 0.00118975
Iteration 22/25 | Loss: 0.00118956
Iteration 23/25 | Loss: 0.00119021
Iteration 24/25 | Loss: 0.00119025
Iteration 25/25 | Loss: 0.00119123

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.91630340
Iteration 2/25 | Loss: 0.00269737
Iteration 3/25 | Loss: 0.00269737
Iteration 4/25 | Loss: 0.00267821
Iteration 5/25 | Loss: 0.00267821
Iteration 6/25 | Loss: 0.00267821
Iteration 7/25 | Loss: 0.00267821
Iteration 8/25 | Loss: 0.00267821
Iteration 9/25 | Loss: 0.00267821
Iteration 10/25 | Loss: 0.00267821
Iteration 11/25 | Loss: 0.00267821
Iteration 12/25 | Loss: 0.00267821
Iteration 13/25 | Loss: 0.00267821
Iteration 14/25 | Loss: 0.00267821
Iteration 15/25 | Loss: 0.00267821
Iteration 16/25 | Loss: 0.00267821
Iteration 17/25 | Loss: 0.00267821
Iteration 18/25 | Loss: 0.00267821
Iteration 19/25 | Loss: 0.00267821
Iteration 20/25 | Loss: 0.00267821
Iteration 21/25 | Loss: 0.00267821
Iteration 22/25 | Loss: 0.00267821
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.002678210148587823, 0.002678210148587823, 0.002678210148587823, 0.002678210148587823, 0.002678210148587823]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002678210148587823

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00267821
Iteration 2/1000 | Loss: 0.00005315
Iteration 3/1000 | Loss: 0.00003191
Iteration 4/1000 | Loss: 0.00004249
Iteration 5/1000 | Loss: 0.00003009
Iteration 6/1000 | Loss: 0.00002456
Iteration 7/1000 | Loss: 0.00007847
Iteration 8/1000 | Loss: 0.00003508
Iteration 9/1000 | Loss: 0.00003772
Iteration 10/1000 | Loss: 0.00003632
Iteration 11/1000 | Loss: 0.00003451
Iteration 12/1000 | Loss: 0.00003690
Iteration 13/1000 | Loss: 0.00003412
Iteration 14/1000 | Loss: 0.00003288
Iteration 15/1000 | Loss: 0.00003191
Iteration 16/1000 | Loss: 0.00002505
Iteration 17/1000 | Loss: 0.00030223
Iteration 18/1000 | Loss: 0.00082988
Iteration 19/1000 | Loss: 0.00065607
Iteration 20/1000 | Loss: 0.00085133
Iteration 21/1000 | Loss: 0.00053957
Iteration 22/1000 | Loss: 0.00045804
Iteration 23/1000 | Loss: 0.00019916
Iteration 24/1000 | Loss: 0.00065280
Iteration 25/1000 | Loss: 0.00002593
Iteration 26/1000 | Loss: 0.00002065
Iteration 27/1000 | Loss: 0.00001984
Iteration 28/1000 | Loss: 0.00001996
Iteration 29/1000 | Loss: 0.00001850
Iteration 30/1000 | Loss: 0.00001876
Iteration 31/1000 | Loss: 0.00001862
Iteration 32/1000 | Loss: 0.00001810
Iteration 33/1000 | Loss: 0.00001810
Iteration 34/1000 | Loss: 0.00001810
Iteration 35/1000 | Loss: 0.00001810
Iteration 36/1000 | Loss: 0.00001809
Iteration 37/1000 | Loss: 0.00001809
Iteration 38/1000 | Loss: 0.00001809
Iteration 39/1000 | Loss: 0.00001809
Iteration 40/1000 | Loss: 0.00001809
Iteration 41/1000 | Loss: 0.00001806
Iteration 42/1000 | Loss: 0.00001802
Iteration 43/1000 | Loss: 0.00004693
Iteration 44/1000 | Loss: 0.00003477
Iteration 45/1000 | Loss: 0.00002626
Iteration 46/1000 | Loss: 0.00004338
Iteration 47/1000 | Loss: 0.00002342
Iteration 48/1000 | Loss: 0.00001774
Iteration 49/1000 | Loss: 0.00001769
Iteration 50/1000 | Loss: 0.00001769
Iteration 51/1000 | Loss: 0.00001768
Iteration 52/1000 | Loss: 0.00001768
Iteration 53/1000 | Loss: 0.00001768
Iteration 54/1000 | Loss: 0.00001768
Iteration 55/1000 | Loss: 0.00001768
Iteration 56/1000 | Loss: 0.00001768
Iteration 57/1000 | Loss: 0.00001768
Iteration 58/1000 | Loss: 0.00001768
Iteration 59/1000 | Loss: 0.00001768
Iteration 60/1000 | Loss: 0.00001768
Iteration 61/1000 | Loss: 0.00001767
Iteration 62/1000 | Loss: 0.00001767
Iteration 63/1000 | Loss: 0.00001767
Iteration 64/1000 | Loss: 0.00001767
Iteration 65/1000 | Loss: 0.00001766
Iteration 66/1000 | Loss: 0.00001766
Iteration 67/1000 | Loss: 0.00001766
Iteration 68/1000 | Loss: 0.00001766
Iteration 69/1000 | Loss: 0.00001766
Iteration 70/1000 | Loss: 0.00002235
Iteration 71/1000 | Loss: 0.00004802
Iteration 72/1000 | Loss: 0.00002154
Iteration 73/1000 | Loss: 0.00002477
Iteration 74/1000 | Loss: 0.00001770
Iteration 75/1000 | Loss: 0.00001768
Iteration 76/1000 | Loss: 0.00001768
Iteration 77/1000 | Loss: 0.00001768
Iteration 78/1000 | Loss: 0.00001791
Iteration 79/1000 | Loss: 0.00001869
Iteration 80/1000 | Loss: 0.00001762
Iteration 81/1000 | Loss: 0.00001762
Iteration 82/1000 | Loss: 0.00001761
Iteration 83/1000 | Loss: 0.00001761
Iteration 84/1000 | Loss: 0.00001761
Iteration 85/1000 | Loss: 0.00001761
Iteration 86/1000 | Loss: 0.00001761
Iteration 87/1000 | Loss: 0.00001761
Iteration 88/1000 | Loss: 0.00001761
Iteration 89/1000 | Loss: 0.00001761
Iteration 90/1000 | Loss: 0.00001761
Iteration 91/1000 | Loss: 0.00001761
Iteration 92/1000 | Loss: 0.00001761
Iteration 93/1000 | Loss: 0.00001760
Iteration 94/1000 | Loss: 0.00001760
Iteration 95/1000 | Loss: 0.00001760
Iteration 96/1000 | Loss: 0.00001760
Iteration 97/1000 | Loss: 0.00001760
Iteration 98/1000 | Loss: 0.00001760
Iteration 99/1000 | Loss: 0.00001760
Iteration 100/1000 | Loss: 0.00001760
Iteration 101/1000 | Loss: 0.00001760
Iteration 102/1000 | Loss: 0.00001760
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.759910628607031e-05, 1.759910628607031e-05, 1.759910628607031e-05, 1.759910628607031e-05, 1.759910628607031e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.759910628607031e-05

Optimization complete. Final v2v error: 2.9476420879364014 mm

Highest mean error: 22.0673828125 mm for frame 126

Lowest mean error: 2.537904739379883 mm for frame 170

Saving results

Total time: 116.96185946464539
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435878
Iteration 2/25 | Loss: 0.00133150
Iteration 3/25 | Loss: 0.00121538
Iteration 4/25 | Loss: 0.00120494
Iteration 5/25 | Loss: 0.00120145
Iteration 6/25 | Loss: 0.00120043
Iteration 7/25 | Loss: 0.00120021
Iteration 8/25 | Loss: 0.00120021
Iteration 9/25 | Loss: 0.00120021
Iteration 10/25 | Loss: 0.00120021
Iteration 11/25 | Loss: 0.00120021
Iteration 12/25 | Loss: 0.00120021
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012002079747617245, 0.0012002079747617245, 0.0012002079747617245, 0.0012002079747617245, 0.0012002079747617245]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012002079747617245

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.28426600
Iteration 2/25 | Loss: 0.00258213
Iteration 3/25 | Loss: 0.00258213
Iteration 4/25 | Loss: 0.00258213
Iteration 5/25 | Loss: 0.00258212
Iteration 6/25 | Loss: 0.00258212
Iteration 7/25 | Loss: 0.00258212
Iteration 8/25 | Loss: 0.00258212
Iteration 9/25 | Loss: 0.00258212
Iteration 10/25 | Loss: 0.00258212
Iteration 11/25 | Loss: 0.00258212
Iteration 12/25 | Loss: 0.00258212
Iteration 13/25 | Loss: 0.00258212
Iteration 14/25 | Loss: 0.00258212
Iteration 15/25 | Loss: 0.00258212
Iteration 16/25 | Loss: 0.00258212
Iteration 17/25 | Loss: 0.00258212
Iteration 18/25 | Loss: 0.00258212
Iteration 19/25 | Loss: 0.00258212
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.002582123037427664, 0.002582123037427664, 0.002582123037427664, 0.002582123037427664, 0.002582123037427664]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002582123037427664

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00258212
Iteration 2/1000 | Loss: 0.00004169
Iteration 3/1000 | Loss: 0.00002103
Iteration 4/1000 | Loss: 0.00001627
Iteration 5/1000 | Loss: 0.00001532
Iteration 6/1000 | Loss: 0.00001448
Iteration 7/1000 | Loss: 0.00001384
Iteration 8/1000 | Loss: 0.00001346
Iteration 9/1000 | Loss: 0.00001306
Iteration 10/1000 | Loss: 0.00001280
Iteration 11/1000 | Loss: 0.00001260
Iteration 12/1000 | Loss: 0.00001255
Iteration 13/1000 | Loss: 0.00001243
Iteration 14/1000 | Loss: 0.00001239
Iteration 15/1000 | Loss: 0.00001237
Iteration 16/1000 | Loss: 0.00001235
Iteration 17/1000 | Loss: 0.00001235
Iteration 18/1000 | Loss: 0.00001234
Iteration 19/1000 | Loss: 0.00001233
Iteration 20/1000 | Loss: 0.00001233
Iteration 21/1000 | Loss: 0.00001232
Iteration 22/1000 | Loss: 0.00001231
Iteration 23/1000 | Loss: 0.00001230
Iteration 24/1000 | Loss: 0.00001230
Iteration 25/1000 | Loss: 0.00001229
Iteration 26/1000 | Loss: 0.00001227
Iteration 27/1000 | Loss: 0.00001226
Iteration 28/1000 | Loss: 0.00001225
Iteration 29/1000 | Loss: 0.00001225
Iteration 30/1000 | Loss: 0.00001225
Iteration 31/1000 | Loss: 0.00001224
Iteration 32/1000 | Loss: 0.00001224
Iteration 33/1000 | Loss: 0.00001223
Iteration 34/1000 | Loss: 0.00001223
Iteration 35/1000 | Loss: 0.00001223
Iteration 36/1000 | Loss: 0.00001222
Iteration 37/1000 | Loss: 0.00001222
Iteration 38/1000 | Loss: 0.00001221
Iteration 39/1000 | Loss: 0.00001221
Iteration 40/1000 | Loss: 0.00001221
Iteration 41/1000 | Loss: 0.00001221
Iteration 42/1000 | Loss: 0.00001220
Iteration 43/1000 | Loss: 0.00001220
Iteration 44/1000 | Loss: 0.00001219
Iteration 45/1000 | Loss: 0.00001218
Iteration 46/1000 | Loss: 0.00001218
Iteration 47/1000 | Loss: 0.00001217
Iteration 48/1000 | Loss: 0.00001216
Iteration 49/1000 | Loss: 0.00001216
Iteration 50/1000 | Loss: 0.00001213
Iteration 51/1000 | Loss: 0.00001213
Iteration 52/1000 | Loss: 0.00001212
Iteration 53/1000 | Loss: 0.00001212
Iteration 54/1000 | Loss: 0.00001212
Iteration 55/1000 | Loss: 0.00001212
Iteration 56/1000 | Loss: 0.00001212
Iteration 57/1000 | Loss: 0.00001211
Iteration 58/1000 | Loss: 0.00001210
Iteration 59/1000 | Loss: 0.00001210
Iteration 60/1000 | Loss: 0.00001209
Iteration 61/1000 | Loss: 0.00001209
Iteration 62/1000 | Loss: 0.00001209
Iteration 63/1000 | Loss: 0.00001208
Iteration 64/1000 | Loss: 0.00001208
Iteration 65/1000 | Loss: 0.00001208
Iteration 66/1000 | Loss: 0.00001208
Iteration 67/1000 | Loss: 0.00001208
Iteration 68/1000 | Loss: 0.00001208
Iteration 69/1000 | Loss: 0.00001207
Iteration 70/1000 | Loss: 0.00001207
Iteration 71/1000 | Loss: 0.00001207
Iteration 72/1000 | Loss: 0.00001207
Iteration 73/1000 | Loss: 0.00001206
Iteration 74/1000 | Loss: 0.00001206
Iteration 75/1000 | Loss: 0.00001206
Iteration 76/1000 | Loss: 0.00001205
Iteration 77/1000 | Loss: 0.00001205
Iteration 78/1000 | Loss: 0.00001205
Iteration 79/1000 | Loss: 0.00001205
Iteration 80/1000 | Loss: 0.00001205
Iteration 81/1000 | Loss: 0.00001205
Iteration 82/1000 | Loss: 0.00001204
Iteration 83/1000 | Loss: 0.00001204
Iteration 84/1000 | Loss: 0.00001204
Iteration 85/1000 | Loss: 0.00001204
Iteration 86/1000 | Loss: 0.00001204
Iteration 87/1000 | Loss: 0.00001204
Iteration 88/1000 | Loss: 0.00001203
Iteration 89/1000 | Loss: 0.00001203
Iteration 90/1000 | Loss: 0.00001203
Iteration 91/1000 | Loss: 0.00001203
Iteration 92/1000 | Loss: 0.00001203
Iteration 93/1000 | Loss: 0.00001203
Iteration 94/1000 | Loss: 0.00001202
Iteration 95/1000 | Loss: 0.00001202
Iteration 96/1000 | Loss: 0.00001202
Iteration 97/1000 | Loss: 0.00001202
Iteration 98/1000 | Loss: 0.00001202
Iteration 99/1000 | Loss: 0.00001202
Iteration 100/1000 | Loss: 0.00001202
Iteration 101/1000 | Loss: 0.00001202
Iteration 102/1000 | Loss: 0.00001201
Iteration 103/1000 | Loss: 0.00001201
Iteration 104/1000 | Loss: 0.00001201
Iteration 105/1000 | Loss: 0.00001201
Iteration 106/1000 | Loss: 0.00001201
Iteration 107/1000 | Loss: 0.00001201
Iteration 108/1000 | Loss: 0.00001201
Iteration 109/1000 | Loss: 0.00001201
Iteration 110/1000 | Loss: 0.00001201
Iteration 111/1000 | Loss: 0.00001201
Iteration 112/1000 | Loss: 0.00001201
Iteration 113/1000 | Loss: 0.00001201
Iteration 114/1000 | Loss: 0.00001201
Iteration 115/1000 | Loss: 0.00001201
Iteration 116/1000 | Loss: 0.00001200
Iteration 117/1000 | Loss: 0.00001200
Iteration 118/1000 | Loss: 0.00001200
Iteration 119/1000 | Loss: 0.00001200
Iteration 120/1000 | Loss: 0.00001200
Iteration 121/1000 | Loss: 0.00001200
Iteration 122/1000 | Loss: 0.00001200
Iteration 123/1000 | Loss: 0.00001200
Iteration 124/1000 | Loss: 0.00001200
Iteration 125/1000 | Loss: 0.00001200
Iteration 126/1000 | Loss: 0.00001200
Iteration 127/1000 | Loss: 0.00001200
Iteration 128/1000 | Loss: 0.00001200
Iteration 129/1000 | Loss: 0.00001200
Iteration 130/1000 | Loss: 0.00001200
Iteration 131/1000 | Loss: 0.00001200
Iteration 132/1000 | Loss: 0.00001199
Iteration 133/1000 | Loss: 0.00001199
Iteration 134/1000 | Loss: 0.00001199
Iteration 135/1000 | Loss: 0.00001199
Iteration 136/1000 | Loss: 0.00001199
Iteration 137/1000 | Loss: 0.00001199
Iteration 138/1000 | Loss: 0.00001199
Iteration 139/1000 | Loss: 0.00001199
Iteration 140/1000 | Loss: 0.00001199
Iteration 141/1000 | Loss: 0.00001198
Iteration 142/1000 | Loss: 0.00001198
Iteration 143/1000 | Loss: 0.00001198
Iteration 144/1000 | Loss: 0.00001198
Iteration 145/1000 | Loss: 0.00001198
Iteration 146/1000 | Loss: 0.00001198
Iteration 147/1000 | Loss: 0.00001198
Iteration 148/1000 | Loss: 0.00001198
Iteration 149/1000 | Loss: 0.00001198
Iteration 150/1000 | Loss: 0.00001198
Iteration 151/1000 | Loss: 0.00001198
Iteration 152/1000 | Loss: 0.00001198
Iteration 153/1000 | Loss: 0.00001198
Iteration 154/1000 | Loss: 0.00001198
Iteration 155/1000 | Loss: 0.00001198
Iteration 156/1000 | Loss: 0.00001197
Iteration 157/1000 | Loss: 0.00001197
Iteration 158/1000 | Loss: 0.00001197
Iteration 159/1000 | Loss: 0.00001197
Iteration 160/1000 | Loss: 0.00001197
Iteration 161/1000 | Loss: 0.00001197
Iteration 162/1000 | Loss: 0.00001197
Iteration 163/1000 | Loss: 0.00001197
Iteration 164/1000 | Loss: 0.00001197
Iteration 165/1000 | Loss: 0.00001197
Iteration 166/1000 | Loss: 0.00001197
Iteration 167/1000 | Loss: 0.00001197
Iteration 168/1000 | Loss: 0.00001197
Iteration 169/1000 | Loss: 0.00001197
Iteration 170/1000 | Loss: 0.00001197
Iteration 171/1000 | Loss: 0.00001197
Iteration 172/1000 | Loss: 0.00001197
Iteration 173/1000 | Loss: 0.00001197
Iteration 174/1000 | Loss: 0.00001197
Iteration 175/1000 | Loss: 0.00001197
Iteration 176/1000 | Loss: 0.00001197
Iteration 177/1000 | Loss: 0.00001197
Iteration 178/1000 | Loss: 0.00001197
Iteration 179/1000 | Loss: 0.00001196
Iteration 180/1000 | Loss: 0.00001196
Iteration 181/1000 | Loss: 0.00001196
Iteration 182/1000 | Loss: 0.00001196
Iteration 183/1000 | Loss: 0.00001196
Iteration 184/1000 | Loss: 0.00001196
Iteration 185/1000 | Loss: 0.00001196
Iteration 186/1000 | Loss: 0.00001196
Iteration 187/1000 | Loss: 0.00001196
Iteration 188/1000 | Loss: 0.00001196
Iteration 189/1000 | Loss: 0.00001196
Iteration 190/1000 | Loss: 0.00001196
Iteration 191/1000 | Loss: 0.00001196
Iteration 192/1000 | Loss: 0.00001196
Iteration 193/1000 | Loss: 0.00001196
Iteration 194/1000 | Loss: 0.00001196
Iteration 195/1000 | Loss: 0.00001196
Iteration 196/1000 | Loss: 0.00001196
Iteration 197/1000 | Loss: 0.00001196
Iteration 198/1000 | Loss: 0.00001196
Iteration 199/1000 | Loss: 0.00001196
Iteration 200/1000 | Loss: 0.00001196
Iteration 201/1000 | Loss: 0.00001196
Iteration 202/1000 | Loss: 0.00001196
Iteration 203/1000 | Loss: 0.00001196
Iteration 204/1000 | Loss: 0.00001196
Iteration 205/1000 | Loss: 0.00001196
Iteration 206/1000 | Loss: 0.00001196
Iteration 207/1000 | Loss: 0.00001196
Iteration 208/1000 | Loss: 0.00001196
Iteration 209/1000 | Loss: 0.00001196
Iteration 210/1000 | Loss: 0.00001196
Iteration 211/1000 | Loss: 0.00001196
Iteration 212/1000 | Loss: 0.00001196
Iteration 213/1000 | Loss: 0.00001196
Iteration 214/1000 | Loss: 0.00001196
Iteration 215/1000 | Loss: 0.00001196
Iteration 216/1000 | Loss: 0.00001196
Iteration 217/1000 | Loss: 0.00001196
Iteration 218/1000 | Loss: 0.00001196
Iteration 219/1000 | Loss: 0.00001196
Iteration 220/1000 | Loss: 0.00001196
Iteration 221/1000 | Loss: 0.00001196
Iteration 222/1000 | Loss: 0.00001196
Iteration 223/1000 | Loss: 0.00001196
Iteration 224/1000 | Loss: 0.00001196
Iteration 225/1000 | Loss: 0.00001196
Iteration 226/1000 | Loss: 0.00001196
Iteration 227/1000 | Loss: 0.00001196
Iteration 228/1000 | Loss: 0.00001196
Iteration 229/1000 | Loss: 0.00001196
Iteration 230/1000 | Loss: 0.00001196
Iteration 231/1000 | Loss: 0.00001196
Iteration 232/1000 | Loss: 0.00001196
Iteration 233/1000 | Loss: 0.00001196
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 233. Stopping optimization.
Last 5 losses: [1.1956434718740638e-05, 1.1956434718740638e-05, 1.1956434718740638e-05, 1.1956434718740638e-05, 1.1956434718740638e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1956434718740638e-05

Optimization complete. Final v2v error: 2.893580436706543 mm

Highest mean error: 3.936008930206299 mm for frame 47

Lowest mean error: 2.4661037921905518 mm for frame 111

Saving results

Total time: 41.60151982307434
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00860540
Iteration 2/25 | Loss: 0.00135549
Iteration 3/25 | Loss: 0.00123641
Iteration 4/25 | Loss: 0.00123106
Iteration 5/25 | Loss: 0.00123004
Iteration 6/25 | Loss: 0.00123004
Iteration 7/25 | Loss: 0.00123004
Iteration 8/25 | Loss: 0.00123004
Iteration 9/25 | Loss: 0.00123004
Iteration 10/25 | Loss: 0.00123004
Iteration 11/25 | Loss: 0.00123004
Iteration 12/25 | Loss: 0.00123004
Iteration 13/25 | Loss: 0.00123004
Iteration 14/25 | Loss: 0.00123004
Iteration 15/25 | Loss: 0.00123004
Iteration 16/25 | Loss: 0.00123004
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.001230041147209704, 0.001230041147209704, 0.001230041147209704, 0.001230041147209704, 0.001230041147209704]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001230041147209704

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16927886
Iteration 2/25 | Loss: 0.00275285
Iteration 3/25 | Loss: 0.00275285
Iteration 4/25 | Loss: 0.00275285
Iteration 5/25 | Loss: 0.00275285
Iteration 6/25 | Loss: 0.00275285
Iteration 7/25 | Loss: 0.00275285
Iteration 8/25 | Loss: 0.00275285
Iteration 9/25 | Loss: 0.00275285
Iteration 10/25 | Loss: 0.00275285
Iteration 11/25 | Loss: 0.00275285
Iteration 12/25 | Loss: 0.00275285
Iteration 13/25 | Loss: 0.00275285
Iteration 14/25 | Loss: 0.00275285
Iteration 15/25 | Loss: 0.00275285
Iteration 16/25 | Loss: 0.00275285
Iteration 17/25 | Loss: 0.00275285
Iteration 18/25 | Loss: 0.00275285
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.002752845175564289, 0.002752845175564289, 0.002752845175564289, 0.002752845175564289, 0.002752845175564289]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002752845175564289

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00275285
Iteration 2/1000 | Loss: 0.00003660
Iteration 3/1000 | Loss: 0.00002137
Iteration 4/1000 | Loss: 0.00001659
Iteration 5/1000 | Loss: 0.00001516
Iteration 6/1000 | Loss: 0.00001430
Iteration 7/1000 | Loss: 0.00001366
Iteration 8/1000 | Loss: 0.00001298
Iteration 9/1000 | Loss: 0.00001256
Iteration 10/1000 | Loss: 0.00001225
Iteration 11/1000 | Loss: 0.00001199
Iteration 12/1000 | Loss: 0.00001198
Iteration 13/1000 | Loss: 0.00001197
Iteration 14/1000 | Loss: 0.00001197
Iteration 15/1000 | Loss: 0.00001195
Iteration 16/1000 | Loss: 0.00001192
Iteration 17/1000 | Loss: 0.00001191
Iteration 18/1000 | Loss: 0.00001189
Iteration 19/1000 | Loss: 0.00001188
Iteration 20/1000 | Loss: 0.00001187
Iteration 21/1000 | Loss: 0.00001183
Iteration 22/1000 | Loss: 0.00001181
Iteration 23/1000 | Loss: 0.00001180
Iteration 24/1000 | Loss: 0.00001179
Iteration 25/1000 | Loss: 0.00001179
Iteration 26/1000 | Loss: 0.00001176
Iteration 27/1000 | Loss: 0.00001175
Iteration 28/1000 | Loss: 0.00001175
Iteration 29/1000 | Loss: 0.00001174
Iteration 30/1000 | Loss: 0.00001170
Iteration 31/1000 | Loss: 0.00001168
Iteration 32/1000 | Loss: 0.00001168
Iteration 33/1000 | Loss: 0.00001167
Iteration 34/1000 | Loss: 0.00001167
Iteration 35/1000 | Loss: 0.00001166
Iteration 36/1000 | Loss: 0.00001166
Iteration 37/1000 | Loss: 0.00001164
Iteration 38/1000 | Loss: 0.00001164
Iteration 39/1000 | Loss: 0.00001164
Iteration 40/1000 | Loss: 0.00001163
Iteration 41/1000 | Loss: 0.00001163
Iteration 42/1000 | Loss: 0.00001163
Iteration 43/1000 | Loss: 0.00001161
Iteration 44/1000 | Loss: 0.00001160
Iteration 45/1000 | Loss: 0.00001160
Iteration 46/1000 | Loss: 0.00001159
Iteration 47/1000 | Loss: 0.00001159
Iteration 48/1000 | Loss: 0.00001159
Iteration 49/1000 | Loss: 0.00001158
Iteration 50/1000 | Loss: 0.00001158
Iteration 51/1000 | Loss: 0.00001158
Iteration 52/1000 | Loss: 0.00001158
Iteration 53/1000 | Loss: 0.00001158
Iteration 54/1000 | Loss: 0.00001157
Iteration 55/1000 | Loss: 0.00001156
Iteration 56/1000 | Loss: 0.00001156
Iteration 57/1000 | Loss: 0.00001155
Iteration 58/1000 | Loss: 0.00001155
Iteration 59/1000 | Loss: 0.00001154
Iteration 60/1000 | Loss: 0.00001154
Iteration 61/1000 | Loss: 0.00001154
Iteration 62/1000 | Loss: 0.00001153
Iteration 63/1000 | Loss: 0.00001153
Iteration 64/1000 | Loss: 0.00001153
Iteration 65/1000 | Loss: 0.00001153
Iteration 66/1000 | Loss: 0.00001152
Iteration 67/1000 | Loss: 0.00001152
Iteration 68/1000 | Loss: 0.00001151
Iteration 69/1000 | Loss: 0.00001151
Iteration 70/1000 | Loss: 0.00001151
Iteration 71/1000 | Loss: 0.00001151
Iteration 72/1000 | Loss: 0.00001151
Iteration 73/1000 | Loss: 0.00001150
Iteration 74/1000 | Loss: 0.00001150
Iteration 75/1000 | Loss: 0.00001150
Iteration 76/1000 | Loss: 0.00001150
Iteration 77/1000 | Loss: 0.00001149
Iteration 78/1000 | Loss: 0.00001149
Iteration 79/1000 | Loss: 0.00001149
Iteration 80/1000 | Loss: 0.00001148
Iteration 81/1000 | Loss: 0.00001148
Iteration 82/1000 | Loss: 0.00001148
Iteration 83/1000 | Loss: 0.00001148
Iteration 84/1000 | Loss: 0.00001148
Iteration 85/1000 | Loss: 0.00001147
Iteration 86/1000 | Loss: 0.00001147
Iteration 87/1000 | Loss: 0.00001147
Iteration 88/1000 | Loss: 0.00001147
Iteration 89/1000 | Loss: 0.00001147
Iteration 90/1000 | Loss: 0.00001147
Iteration 91/1000 | Loss: 0.00001147
Iteration 92/1000 | Loss: 0.00001147
Iteration 93/1000 | Loss: 0.00001147
Iteration 94/1000 | Loss: 0.00001147
Iteration 95/1000 | Loss: 0.00001147
Iteration 96/1000 | Loss: 0.00001146
Iteration 97/1000 | Loss: 0.00001146
Iteration 98/1000 | Loss: 0.00001146
Iteration 99/1000 | Loss: 0.00001146
Iteration 100/1000 | Loss: 0.00001146
Iteration 101/1000 | Loss: 0.00001146
Iteration 102/1000 | Loss: 0.00001146
Iteration 103/1000 | Loss: 0.00001146
Iteration 104/1000 | Loss: 0.00001146
Iteration 105/1000 | Loss: 0.00001146
Iteration 106/1000 | Loss: 0.00001146
Iteration 107/1000 | Loss: 0.00001146
Iteration 108/1000 | Loss: 0.00001145
Iteration 109/1000 | Loss: 0.00001145
Iteration 110/1000 | Loss: 0.00001145
Iteration 111/1000 | Loss: 0.00001145
Iteration 112/1000 | Loss: 0.00001145
Iteration 113/1000 | Loss: 0.00001145
Iteration 114/1000 | Loss: 0.00001145
Iteration 115/1000 | Loss: 0.00001145
Iteration 116/1000 | Loss: 0.00001145
Iteration 117/1000 | Loss: 0.00001145
Iteration 118/1000 | Loss: 0.00001145
Iteration 119/1000 | Loss: 0.00001145
Iteration 120/1000 | Loss: 0.00001145
Iteration 121/1000 | Loss: 0.00001145
Iteration 122/1000 | Loss: 0.00001144
Iteration 123/1000 | Loss: 0.00001144
Iteration 124/1000 | Loss: 0.00001144
Iteration 125/1000 | Loss: 0.00001144
Iteration 126/1000 | Loss: 0.00001144
Iteration 127/1000 | Loss: 0.00001144
Iteration 128/1000 | Loss: 0.00001144
Iteration 129/1000 | Loss: 0.00001144
Iteration 130/1000 | Loss: 0.00001144
Iteration 131/1000 | Loss: 0.00001144
Iteration 132/1000 | Loss: 0.00001144
Iteration 133/1000 | Loss: 0.00001144
Iteration 134/1000 | Loss: 0.00001144
Iteration 135/1000 | Loss: 0.00001144
Iteration 136/1000 | Loss: 0.00001144
Iteration 137/1000 | Loss: 0.00001144
Iteration 138/1000 | Loss: 0.00001144
Iteration 139/1000 | Loss: 0.00001144
Iteration 140/1000 | Loss: 0.00001144
Iteration 141/1000 | Loss: 0.00001144
Iteration 142/1000 | Loss: 0.00001144
Iteration 143/1000 | Loss: 0.00001144
Iteration 144/1000 | Loss: 0.00001143
Iteration 145/1000 | Loss: 0.00001143
Iteration 146/1000 | Loss: 0.00001143
Iteration 147/1000 | Loss: 0.00001143
Iteration 148/1000 | Loss: 0.00001143
Iteration 149/1000 | Loss: 0.00001143
Iteration 150/1000 | Loss: 0.00001143
Iteration 151/1000 | Loss: 0.00001143
Iteration 152/1000 | Loss: 0.00001143
Iteration 153/1000 | Loss: 0.00001143
Iteration 154/1000 | Loss: 0.00001143
Iteration 155/1000 | Loss: 0.00001143
Iteration 156/1000 | Loss: 0.00001143
Iteration 157/1000 | Loss: 0.00001143
Iteration 158/1000 | Loss: 0.00001143
Iteration 159/1000 | Loss: 0.00001143
Iteration 160/1000 | Loss: 0.00001143
Iteration 161/1000 | Loss: 0.00001143
Iteration 162/1000 | Loss: 0.00001143
Iteration 163/1000 | Loss: 0.00001143
Iteration 164/1000 | Loss: 0.00001143
Iteration 165/1000 | Loss: 0.00001143
Iteration 166/1000 | Loss: 0.00001143
Iteration 167/1000 | Loss: 0.00001143
Iteration 168/1000 | Loss: 0.00001143
Iteration 169/1000 | Loss: 0.00001143
Iteration 170/1000 | Loss: 0.00001143
Iteration 171/1000 | Loss: 0.00001143
Iteration 172/1000 | Loss: 0.00001143
Iteration 173/1000 | Loss: 0.00001143
Iteration 174/1000 | Loss: 0.00001143
Iteration 175/1000 | Loss: 0.00001143
Iteration 176/1000 | Loss: 0.00001143
Iteration 177/1000 | Loss: 0.00001143
Iteration 178/1000 | Loss: 0.00001143
Iteration 179/1000 | Loss: 0.00001143
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 179. Stopping optimization.
Last 5 losses: [1.1432566680014133e-05, 1.1432566680014133e-05, 1.1432566680014133e-05, 1.1432566680014133e-05, 1.1432566680014133e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1432566680014133e-05

Optimization complete. Final v2v error: 2.8498613834381104 mm

Highest mean error: 3.6882386207580566 mm for frame 69

Lowest mean error: 2.444289445877075 mm for frame 17

Saving results

Total time: 36.87635898590088
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00438274
Iteration 2/25 | Loss: 0.00128349
Iteration 3/25 | Loss: 0.00119655
Iteration 4/25 | Loss: 0.00118534
Iteration 5/25 | Loss: 0.00118150
Iteration 6/25 | Loss: 0.00118065
Iteration 7/25 | Loss: 0.00118060
Iteration 8/25 | Loss: 0.00118060
Iteration 9/25 | Loss: 0.00118060
Iteration 10/25 | Loss: 0.00118060
Iteration 11/25 | Loss: 0.00118060
Iteration 12/25 | Loss: 0.00118060
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011806013062596321, 0.0011806013062596321, 0.0011806013062596321, 0.0011806013062596321, 0.0011806013062596321]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011806013062596321

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.21491766
Iteration 2/25 | Loss: 0.00257998
Iteration 3/25 | Loss: 0.00257998
Iteration 4/25 | Loss: 0.00257998
Iteration 5/25 | Loss: 0.00257998
Iteration 6/25 | Loss: 0.00257998
Iteration 7/25 | Loss: 0.00257998
Iteration 8/25 | Loss: 0.00257998
Iteration 9/25 | Loss: 0.00257998
Iteration 10/25 | Loss: 0.00257998
Iteration 11/25 | Loss: 0.00257998
Iteration 12/25 | Loss: 0.00257998
Iteration 13/25 | Loss: 0.00257998
Iteration 14/25 | Loss: 0.00257998
Iteration 15/25 | Loss: 0.00257998
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.002579975640401244, 0.002579975640401244, 0.002579975640401244, 0.002579975640401244, 0.002579975640401244]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002579975640401244

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00257998
Iteration 2/1000 | Loss: 0.00002516
Iteration 3/1000 | Loss: 0.00001748
Iteration 4/1000 | Loss: 0.00001576
Iteration 5/1000 | Loss: 0.00001480
Iteration 6/1000 | Loss: 0.00001421
Iteration 7/1000 | Loss: 0.00001357
Iteration 8/1000 | Loss: 0.00001319
Iteration 9/1000 | Loss: 0.00001300
Iteration 10/1000 | Loss: 0.00001297
Iteration 11/1000 | Loss: 0.00001296
Iteration 12/1000 | Loss: 0.00001295
Iteration 13/1000 | Loss: 0.00001288
Iteration 14/1000 | Loss: 0.00001287
Iteration 15/1000 | Loss: 0.00001286
Iteration 16/1000 | Loss: 0.00001283
Iteration 17/1000 | Loss: 0.00001279
Iteration 18/1000 | Loss: 0.00001278
Iteration 19/1000 | Loss: 0.00001277
Iteration 20/1000 | Loss: 0.00001277
Iteration 21/1000 | Loss: 0.00001274
Iteration 22/1000 | Loss: 0.00001273
Iteration 23/1000 | Loss: 0.00001273
Iteration 24/1000 | Loss: 0.00001272
Iteration 25/1000 | Loss: 0.00001272
Iteration 26/1000 | Loss: 0.00001271
Iteration 27/1000 | Loss: 0.00001271
Iteration 28/1000 | Loss: 0.00001266
Iteration 29/1000 | Loss: 0.00001266
Iteration 30/1000 | Loss: 0.00001263
Iteration 31/1000 | Loss: 0.00001263
Iteration 32/1000 | Loss: 0.00001262
Iteration 33/1000 | Loss: 0.00001262
Iteration 34/1000 | Loss: 0.00001261
Iteration 35/1000 | Loss: 0.00001260
Iteration 36/1000 | Loss: 0.00001260
Iteration 37/1000 | Loss: 0.00001260
Iteration 38/1000 | Loss: 0.00001259
Iteration 39/1000 | Loss: 0.00001259
Iteration 40/1000 | Loss: 0.00001259
Iteration 41/1000 | Loss: 0.00001259
Iteration 42/1000 | Loss: 0.00001259
Iteration 43/1000 | Loss: 0.00001258
Iteration 44/1000 | Loss: 0.00001258
Iteration 45/1000 | Loss: 0.00001257
Iteration 46/1000 | Loss: 0.00001257
Iteration 47/1000 | Loss: 0.00001257
Iteration 48/1000 | Loss: 0.00001257
Iteration 49/1000 | Loss: 0.00001257
Iteration 50/1000 | Loss: 0.00001257
Iteration 51/1000 | Loss: 0.00001257
Iteration 52/1000 | Loss: 0.00001257
Iteration 53/1000 | Loss: 0.00001257
Iteration 54/1000 | Loss: 0.00001257
Iteration 55/1000 | Loss: 0.00001256
Iteration 56/1000 | Loss: 0.00001256
Iteration 57/1000 | Loss: 0.00001256
Iteration 58/1000 | Loss: 0.00001255
Iteration 59/1000 | Loss: 0.00001255
Iteration 60/1000 | Loss: 0.00001255
Iteration 61/1000 | Loss: 0.00001254
Iteration 62/1000 | Loss: 0.00001254
Iteration 63/1000 | Loss: 0.00001254
Iteration 64/1000 | Loss: 0.00001253
Iteration 65/1000 | Loss: 0.00001253
Iteration 66/1000 | Loss: 0.00001253
Iteration 67/1000 | Loss: 0.00001253
Iteration 68/1000 | Loss: 0.00001252
Iteration 69/1000 | Loss: 0.00001252
Iteration 70/1000 | Loss: 0.00001252
Iteration 71/1000 | Loss: 0.00001252
Iteration 72/1000 | Loss: 0.00001252
Iteration 73/1000 | Loss: 0.00001252
Iteration 74/1000 | Loss: 0.00001252
Iteration 75/1000 | Loss: 0.00001252
Iteration 76/1000 | Loss: 0.00001252
Iteration 77/1000 | Loss: 0.00001252
Iteration 78/1000 | Loss: 0.00001251
Iteration 79/1000 | Loss: 0.00001251
Iteration 80/1000 | Loss: 0.00001251
Iteration 81/1000 | Loss: 0.00001251
Iteration 82/1000 | Loss: 0.00001251
Iteration 83/1000 | Loss: 0.00001251
Iteration 84/1000 | Loss: 0.00001250
Iteration 85/1000 | Loss: 0.00001250
Iteration 86/1000 | Loss: 0.00001250
Iteration 87/1000 | Loss: 0.00001250
Iteration 88/1000 | Loss: 0.00001250
Iteration 89/1000 | Loss: 0.00001250
Iteration 90/1000 | Loss: 0.00001250
Iteration 91/1000 | Loss: 0.00001250
Iteration 92/1000 | Loss: 0.00001249
Iteration 93/1000 | Loss: 0.00001249
Iteration 94/1000 | Loss: 0.00001249
Iteration 95/1000 | Loss: 0.00001249
Iteration 96/1000 | Loss: 0.00001249
Iteration 97/1000 | Loss: 0.00001249
Iteration 98/1000 | Loss: 0.00001249
Iteration 99/1000 | Loss: 0.00001249
Iteration 100/1000 | Loss: 0.00001249
Iteration 101/1000 | Loss: 0.00001249
Iteration 102/1000 | Loss: 0.00001249
Iteration 103/1000 | Loss: 0.00001248
Iteration 104/1000 | Loss: 0.00001248
Iteration 105/1000 | Loss: 0.00001248
Iteration 106/1000 | Loss: 0.00001248
Iteration 107/1000 | Loss: 0.00001248
Iteration 108/1000 | Loss: 0.00001248
Iteration 109/1000 | Loss: 0.00001248
Iteration 110/1000 | Loss: 0.00001248
Iteration 111/1000 | Loss: 0.00001248
Iteration 112/1000 | Loss: 0.00001248
Iteration 113/1000 | Loss: 0.00001248
Iteration 114/1000 | Loss: 0.00001248
Iteration 115/1000 | Loss: 0.00001248
Iteration 116/1000 | Loss: 0.00001248
Iteration 117/1000 | Loss: 0.00001248
Iteration 118/1000 | Loss: 0.00001247
Iteration 119/1000 | Loss: 0.00001247
Iteration 120/1000 | Loss: 0.00001247
Iteration 121/1000 | Loss: 0.00001247
Iteration 122/1000 | Loss: 0.00001247
Iteration 123/1000 | Loss: 0.00001247
Iteration 124/1000 | Loss: 0.00001247
Iteration 125/1000 | Loss: 0.00001247
Iteration 126/1000 | Loss: 0.00001247
Iteration 127/1000 | Loss: 0.00001246
Iteration 128/1000 | Loss: 0.00001246
Iteration 129/1000 | Loss: 0.00001246
Iteration 130/1000 | Loss: 0.00001246
Iteration 131/1000 | Loss: 0.00001246
Iteration 132/1000 | Loss: 0.00001246
Iteration 133/1000 | Loss: 0.00001246
Iteration 134/1000 | Loss: 0.00001246
Iteration 135/1000 | Loss: 0.00001246
Iteration 136/1000 | Loss: 0.00001246
Iteration 137/1000 | Loss: 0.00001246
Iteration 138/1000 | Loss: 0.00001246
Iteration 139/1000 | Loss: 0.00001246
Iteration 140/1000 | Loss: 0.00001246
Iteration 141/1000 | Loss: 0.00001245
Iteration 142/1000 | Loss: 0.00001245
Iteration 143/1000 | Loss: 0.00001245
Iteration 144/1000 | Loss: 0.00001245
Iteration 145/1000 | Loss: 0.00001245
Iteration 146/1000 | Loss: 0.00001245
Iteration 147/1000 | Loss: 0.00001245
Iteration 148/1000 | Loss: 0.00001245
Iteration 149/1000 | Loss: 0.00001245
Iteration 150/1000 | Loss: 0.00001245
Iteration 151/1000 | Loss: 0.00001244
Iteration 152/1000 | Loss: 0.00001244
Iteration 153/1000 | Loss: 0.00001244
Iteration 154/1000 | Loss: 0.00001244
Iteration 155/1000 | Loss: 0.00001244
Iteration 156/1000 | Loss: 0.00001244
Iteration 157/1000 | Loss: 0.00001244
Iteration 158/1000 | Loss: 0.00001244
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 158. Stopping optimization.
Last 5 losses: [1.2444279491319321e-05, 1.2444279491319321e-05, 1.2444279491319321e-05, 1.2444279491319321e-05, 1.2444279491319321e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2444279491319321e-05

Optimization complete. Final v2v error: 2.947723627090454 mm

Highest mean error: 3.5683608055114746 mm for frame 18

Lowest mean error: 2.6123416423797607 mm for frame 40

Saving results

Total time: 33.05718231201172
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01093373
Iteration 2/25 | Loss: 0.01093373
Iteration 3/25 | Loss: 0.01093373
Iteration 4/25 | Loss: 0.00368491
Iteration 5/25 | Loss: 0.00243622
Iteration 6/25 | Loss: 0.00205925
Iteration 7/25 | Loss: 0.00183985
Iteration 8/25 | Loss: 0.00176510
Iteration 9/25 | Loss: 0.00170992
Iteration 10/25 | Loss: 0.00166141
Iteration 11/25 | Loss: 0.00161705
Iteration 12/25 | Loss: 0.00160444
Iteration 13/25 | Loss: 0.00157746
Iteration 14/25 | Loss: 0.00157546
Iteration 15/25 | Loss: 0.00157408
Iteration 16/25 | Loss: 0.00157632
Iteration 17/25 | Loss: 0.00156788
Iteration 18/25 | Loss: 0.00156513
Iteration 19/25 | Loss: 0.00156631
Iteration 20/25 | Loss: 0.00155591
Iteration 21/25 | Loss: 0.00155410
Iteration 22/25 | Loss: 0.00155263
Iteration 23/25 | Loss: 0.00155619
Iteration 24/25 | Loss: 0.00155408
Iteration 25/25 | Loss: 0.00155147

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.13195360
Iteration 2/25 | Loss: 0.00482981
Iteration 3/25 | Loss: 0.00482981
Iteration 4/25 | Loss: 0.00469906
Iteration 5/25 | Loss: 0.00469903
Iteration 6/25 | Loss: 0.00469903
Iteration 7/25 | Loss: 0.00469903
Iteration 8/25 | Loss: 0.00469902
Iteration 9/25 | Loss: 0.00469902
Iteration 10/25 | Loss: 0.00469902
Iteration 11/25 | Loss: 0.00469902
Iteration 12/25 | Loss: 0.00469902
Iteration 13/25 | Loss: 0.00469902
Iteration 14/25 | Loss: 0.00469902
Iteration 15/25 | Loss: 0.00469902
Iteration 16/25 | Loss: 0.00469902
Iteration 17/25 | Loss: 0.00469902
Iteration 18/25 | Loss: 0.00469902
Iteration 19/25 | Loss: 0.00469902
Iteration 20/25 | Loss: 0.00469902
Iteration 21/25 | Loss: 0.00469902
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.004699022509157658, 0.004699022509157658, 0.004699022509157658, 0.004699022509157658, 0.004699022509157658]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004699022509157658

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00469902
Iteration 2/1000 | Loss: 0.00116026
Iteration 3/1000 | Loss: 0.00067057
Iteration 4/1000 | Loss: 0.00069117
Iteration 5/1000 | Loss: 0.00091338
Iteration 6/1000 | Loss: 0.00086256
Iteration 7/1000 | Loss: 0.00070546
Iteration 8/1000 | Loss: 0.00043391
Iteration 9/1000 | Loss: 0.00040094
Iteration 10/1000 | Loss: 0.00038564
Iteration 11/1000 | Loss: 0.00036747
Iteration 12/1000 | Loss: 0.00048158
Iteration 13/1000 | Loss: 0.00037257
Iteration 14/1000 | Loss: 0.00035978
Iteration 15/1000 | Loss: 0.00028238
Iteration 16/1000 | Loss: 0.00062931
Iteration 17/1000 | Loss: 0.00053944
Iteration 18/1000 | Loss: 0.00031281
Iteration 19/1000 | Loss: 0.00057313
Iteration 20/1000 | Loss: 0.00023072
Iteration 21/1000 | Loss: 0.00042161
Iteration 22/1000 | Loss: 0.00023644
Iteration 23/1000 | Loss: 0.00046045
Iteration 24/1000 | Loss: 0.00037189
Iteration 25/1000 | Loss: 0.00068165
Iteration 26/1000 | Loss: 0.00038524
Iteration 27/1000 | Loss: 0.00137041
Iteration 28/1000 | Loss: 0.00162714
Iteration 29/1000 | Loss: 0.00094590
Iteration 30/1000 | Loss: 0.00103090
Iteration 31/1000 | Loss: 0.00131276
Iteration 32/1000 | Loss: 0.00078360
Iteration 33/1000 | Loss: 0.00127570
Iteration 34/1000 | Loss: 0.00092246
Iteration 35/1000 | Loss: 0.00115404
Iteration 36/1000 | Loss: 0.00059691
Iteration 37/1000 | Loss: 0.00073639
Iteration 38/1000 | Loss: 0.00034748
Iteration 39/1000 | Loss: 0.00022358
Iteration 40/1000 | Loss: 0.00058870
Iteration 41/1000 | Loss: 0.00102982
Iteration 42/1000 | Loss: 0.00070193
Iteration 43/1000 | Loss: 0.00054645
Iteration 44/1000 | Loss: 0.00073064
Iteration 45/1000 | Loss: 0.00059896
Iteration 46/1000 | Loss: 0.00038790
Iteration 47/1000 | Loss: 0.00126534
Iteration 48/1000 | Loss: 0.00055538
Iteration 49/1000 | Loss: 0.00103623
Iteration 50/1000 | Loss: 0.00124542
Iteration 51/1000 | Loss: 0.00067944
Iteration 52/1000 | Loss: 0.00076923
Iteration 53/1000 | Loss: 0.00086451
Iteration 54/1000 | Loss: 0.00069116
Iteration 55/1000 | Loss: 0.00054231
Iteration 56/1000 | Loss: 0.00043258
Iteration 57/1000 | Loss: 0.00032077
Iteration 58/1000 | Loss: 0.00039987
Iteration 59/1000 | Loss: 0.00034275
Iteration 60/1000 | Loss: 0.00047462
Iteration 61/1000 | Loss: 0.00070149
Iteration 62/1000 | Loss: 0.00028974
Iteration 63/1000 | Loss: 0.00020190
Iteration 64/1000 | Loss: 0.00022378
Iteration 65/1000 | Loss: 0.00026992
Iteration 66/1000 | Loss: 0.00031504
Iteration 67/1000 | Loss: 0.00019508
Iteration 68/1000 | Loss: 0.00021870
Iteration 69/1000 | Loss: 0.00016056
Iteration 70/1000 | Loss: 0.00016202
Iteration 71/1000 | Loss: 0.00047365
Iteration 72/1000 | Loss: 0.00031977
Iteration 73/1000 | Loss: 0.00070914
Iteration 74/1000 | Loss: 0.00014849
Iteration 75/1000 | Loss: 0.00015652
Iteration 76/1000 | Loss: 0.00043993
Iteration 77/1000 | Loss: 0.00018806
Iteration 78/1000 | Loss: 0.00090326
Iteration 79/1000 | Loss: 0.00069335
Iteration 80/1000 | Loss: 0.00048168
Iteration 81/1000 | Loss: 0.00068009
Iteration 82/1000 | Loss: 0.00042756
Iteration 83/1000 | Loss: 0.00015223
Iteration 84/1000 | Loss: 0.00018977
Iteration 85/1000 | Loss: 0.00014848
Iteration 86/1000 | Loss: 0.00028790
Iteration 87/1000 | Loss: 0.00025293
Iteration 88/1000 | Loss: 0.00036360
Iteration 89/1000 | Loss: 0.00111916
Iteration 90/1000 | Loss: 0.00173745
Iteration 91/1000 | Loss: 0.00223087
Iteration 92/1000 | Loss: 0.00082437
Iteration 93/1000 | Loss: 0.00060947
Iteration 94/1000 | Loss: 0.00055936
Iteration 95/1000 | Loss: 0.00048737
Iteration 96/1000 | Loss: 0.00016359
Iteration 97/1000 | Loss: 0.00018003
Iteration 98/1000 | Loss: 0.00016080
Iteration 99/1000 | Loss: 0.00101909
Iteration 100/1000 | Loss: 0.00081483
Iteration 101/1000 | Loss: 0.00017797
Iteration 102/1000 | Loss: 0.00017422
Iteration 103/1000 | Loss: 0.00013752
Iteration 104/1000 | Loss: 0.00058775
Iteration 105/1000 | Loss: 0.00039798
Iteration 106/1000 | Loss: 0.00059324
Iteration 107/1000 | Loss: 0.00037085
Iteration 108/1000 | Loss: 0.00041237
Iteration 109/1000 | Loss: 0.00073383
Iteration 110/1000 | Loss: 0.00037494
Iteration 111/1000 | Loss: 0.00014990
Iteration 112/1000 | Loss: 0.00033279
Iteration 113/1000 | Loss: 0.00023331
Iteration 114/1000 | Loss: 0.00047368
Iteration 115/1000 | Loss: 0.00048312
Iteration 116/1000 | Loss: 0.00023087
Iteration 117/1000 | Loss: 0.00017061
Iteration 118/1000 | Loss: 0.00060314
Iteration 119/1000 | Loss: 0.00066159
Iteration 120/1000 | Loss: 0.00076189
Iteration 121/1000 | Loss: 0.00102001
Iteration 122/1000 | Loss: 0.00034558
Iteration 123/1000 | Loss: 0.00051934
Iteration 124/1000 | Loss: 0.00084033
Iteration 125/1000 | Loss: 0.00124598
Iteration 126/1000 | Loss: 0.00105698
Iteration 127/1000 | Loss: 0.00014898
Iteration 128/1000 | Loss: 0.00020783
Iteration 129/1000 | Loss: 0.00029843
Iteration 130/1000 | Loss: 0.00020382
Iteration 131/1000 | Loss: 0.00017905
Iteration 132/1000 | Loss: 0.00014233
Iteration 133/1000 | Loss: 0.00014294
Iteration 134/1000 | Loss: 0.00013102
Iteration 135/1000 | Loss: 0.00013854
Iteration 136/1000 | Loss: 0.00012817
Iteration 137/1000 | Loss: 0.00014111
Iteration 138/1000 | Loss: 0.00052262
Iteration 139/1000 | Loss: 0.00021941
Iteration 140/1000 | Loss: 0.00032492
Iteration 141/1000 | Loss: 0.00044205
Iteration 142/1000 | Loss: 0.00046557
Iteration 143/1000 | Loss: 0.00072851
Iteration 144/1000 | Loss: 0.00051910
Iteration 145/1000 | Loss: 0.00103126
Iteration 146/1000 | Loss: 0.00066767
Iteration 147/1000 | Loss: 0.00098781
Iteration 148/1000 | Loss: 0.00064165
Iteration 149/1000 | Loss: 0.00093351
Iteration 150/1000 | Loss: 0.00064051
Iteration 151/1000 | Loss: 0.00014535
Iteration 152/1000 | Loss: 0.00055053
Iteration 153/1000 | Loss: 0.00014389
Iteration 154/1000 | Loss: 0.00063245
Iteration 155/1000 | Loss: 0.00014605
Iteration 156/1000 | Loss: 0.00068073
Iteration 157/1000 | Loss: 0.00034525
Iteration 158/1000 | Loss: 0.00016320
Iteration 159/1000 | Loss: 0.00015014
Iteration 160/1000 | Loss: 0.00012771
Iteration 161/1000 | Loss: 0.00014200
Iteration 162/1000 | Loss: 0.00068891
Iteration 163/1000 | Loss: 0.00050280
Iteration 164/1000 | Loss: 0.00036046
Iteration 165/1000 | Loss: 0.00012691
Iteration 166/1000 | Loss: 0.00012352
Iteration 167/1000 | Loss: 0.00012108
Iteration 168/1000 | Loss: 0.00012957
Iteration 169/1000 | Loss: 0.00012278
Iteration 170/1000 | Loss: 0.00012431
Iteration 171/1000 | Loss: 0.00011802
Iteration 172/1000 | Loss: 0.00036494
Iteration 173/1000 | Loss: 0.00037243
Iteration 174/1000 | Loss: 0.00057852
Iteration 175/1000 | Loss: 0.00012622
Iteration 176/1000 | Loss: 0.00013150
Iteration 177/1000 | Loss: 0.00013811
Iteration 178/1000 | Loss: 0.00011843
Iteration 179/1000 | Loss: 0.00011657
Iteration 180/1000 | Loss: 0.00011562
Iteration 181/1000 | Loss: 0.00011500
Iteration 182/1000 | Loss: 0.00011471
Iteration 183/1000 | Loss: 0.00011453
Iteration 184/1000 | Loss: 0.00011450
Iteration 185/1000 | Loss: 0.00011449
Iteration 186/1000 | Loss: 0.00011437
Iteration 187/1000 | Loss: 0.00011430
Iteration 188/1000 | Loss: 0.00011426
Iteration 189/1000 | Loss: 0.00011418
Iteration 190/1000 | Loss: 0.00011418
Iteration 191/1000 | Loss: 0.00011417
Iteration 192/1000 | Loss: 0.00011417
Iteration 193/1000 | Loss: 0.00011416
Iteration 194/1000 | Loss: 0.00011415
Iteration 195/1000 | Loss: 0.00011414
Iteration 196/1000 | Loss: 0.00011414
Iteration 197/1000 | Loss: 0.00011412
Iteration 198/1000 | Loss: 0.00011410
Iteration 199/1000 | Loss: 0.00011410
Iteration 200/1000 | Loss: 0.00011410
Iteration 201/1000 | Loss: 0.00011410
Iteration 202/1000 | Loss: 0.00011410
Iteration 203/1000 | Loss: 0.00011408
Iteration 204/1000 | Loss: 0.00011408
Iteration 205/1000 | Loss: 0.00011408
Iteration 206/1000 | Loss: 0.00011407
Iteration 207/1000 | Loss: 0.00011407
Iteration 208/1000 | Loss: 0.00011407
Iteration 209/1000 | Loss: 0.00011407
Iteration 210/1000 | Loss: 0.00011407
Iteration 211/1000 | Loss: 0.00011406
Iteration 212/1000 | Loss: 0.00011406
Iteration 213/1000 | Loss: 0.00012470
Iteration 214/1000 | Loss: 0.00011412
Iteration 215/1000 | Loss: 0.00011401
Iteration 216/1000 | Loss: 0.00011401
Iteration 217/1000 | Loss: 0.00011400
Iteration 218/1000 | Loss: 0.00011400
Iteration 219/1000 | Loss: 0.00011399
Iteration 220/1000 | Loss: 0.00011399
Iteration 221/1000 | Loss: 0.00011399
Iteration 222/1000 | Loss: 0.00011399
Iteration 223/1000 | Loss: 0.00011399
Iteration 224/1000 | Loss: 0.00011399
Iteration 225/1000 | Loss: 0.00011399
Iteration 226/1000 | Loss: 0.00011399
Iteration 227/1000 | Loss: 0.00011398
Iteration 228/1000 | Loss: 0.00011398
Iteration 229/1000 | Loss: 0.00011398
Iteration 230/1000 | Loss: 0.00011398
Iteration 231/1000 | Loss: 0.00011398
Iteration 232/1000 | Loss: 0.00011398
Iteration 233/1000 | Loss: 0.00011398
Iteration 234/1000 | Loss: 0.00011398
Iteration 235/1000 | Loss: 0.00011398
Iteration 236/1000 | Loss: 0.00011398
Iteration 237/1000 | Loss: 0.00011398
Iteration 238/1000 | Loss: 0.00011398
Iteration 239/1000 | Loss: 0.00011398
Iteration 240/1000 | Loss: 0.00012026
Iteration 241/1000 | Loss: 0.00011400
Iteration 242/1000 | Loss: 0.00011400
Iteration 243/1000 | Loss: 0.00011400
Iteration 244/1000 | Loss: 0.00011400
Iteration 245/1000 | Loss: 0.00011400
Iteration 246/1000 | Loss: 0.00011400
Iteration 247/1000 | Loss: 0.00011400
Iteration 248/1000 | Loss: 0.00011400
Iteration 249/1000 | Loss: 0.00011400
Iteration 250/1000 | Loss: 0.00011400
Iteration 251/1000 | Loss: 0.00011400
Iteration 252/1000 | Loss: 0.00011400
Iteration 253/1000 | Loss: 0.00011400
Iteration 254/1000 | Loss: 0.00011399
Iteration 255/1000 | Loss: 0.00011399
Iteration 256/1000 | Loss: 0.00011399
Iteration 257/1000 | Loss: 0.00011399
Iteration 258/1000 | Loss: 0.00011399
Iteration 259/1000 | Loss: 0.00011399
Iteration 260/1000 | Loss: 0.00011399
Iteration 261/1000 | Loss: 0.00011399
Iteration 262/1000 | Loss: 0.00011399
Iteration 263/1000 | Loss: 0.00011399
Iteration 264/1000 | Loss: 0.00011399
Iteration 265/1000 | Loss: 0.00011399
Iteration 266/1000 | Loss: 0.00011399
Iteration 267/1000 | Loss: 0.00011399
Iteration 268/1000 | Loss: 0.00011399
Iteration 269/1000 | Loss: 0.00011399
Iteration 270/1000 | Loss: 0.00011399
Iteration 271/1000 | Loss: 0.00011399
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 271. Stopping optimization.
Last 5 losses: [0.00011398900096537545, 0.00011398900096537545, 0.00011398900096537545, 0.00011398900096537545, 0.00011398900096537545]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00011398900096537545

Optimization complete. Final v2v error: 5.1676740646362305 mm

Highest mean error: 20.846357345581055 mm for frame 26

Lowest mean error: 2.7390151023864746 mm for frame 90

Saving results

Total time: 329.31647276878357
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01045990
Iteration 2/25 | Loss: 0.00251684
Iteration 3/25 | Loss: 0.00181656
Iteration 4/25 | Loss: 0.00182043
Iteration 5/25 | Loss: 0.00170275
Iteration 6/25 | Loss: 0.00144510
Iteration 7/25 | Loss: 0.00137882
Iteration 8/25 | Loss: 0.00136962
Iteration 9/25 | Loss: 0.00135925
Iteration 10/25 | Loss: 0.00135712
Iteration 11/25 | Loss: 0.00135637
Iteration 12/25 | Loss: 0.00136104
Iteration 13/25 | Loss: 0.00136070
Iteration 14/25 | Loss: 0.00135282
Iteration 15/25 | Loss: 0.00135082
Iteration 16/25 | Loss: 0.00135538
Iteration 17/25 | Loss: 0.00135133
Iteration 18/25 | Loss: 0.00135054
Iteration 19/25 | Loss: 0.00135203
Iteration 20/25 | Loss: 0.00135119
Iteration 21/25 | Loss: 0.00134792
Iteration 22/25 | Loss: 0.00135095
Iteration 23/25 | Loss: 0.00134538
Iteration 24/25 | Loss: 0.00134493
Iteration 25/25 | Loss: 0.00134485

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16176057
Iteration 2/25 | Loss: 0.00410532
Iteration 3/25 | Loss: 0.00364041
Iteration 4/25 | Loss: 0.00364041
Iteration 5/25 | Loss: 0.00364041
Iteration 6/25 | Loss: 0.00364041
Iteration 7/25 | Loss: 0.00364041
Iteration 8/25 | Loss: 0.00364041
Iteration 9/25 | Loss: 0.00364041
Iteration 10/25 | Loss: 0.00364041
Iteration 11/25 | Loss: 0.00364041
Iteration 12/25 | Loss: 0.00364041
Iteration 13/25 | Loss: 0.00364041
Iteration 14/25 | Loss: 0.00364041
Iteration 15/25 | Loss: 0.00364041
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.003640410490334034, 0.003640410490334034, 0.003640410490334034, 0.003640410490334034, 0.003640410490334034]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.003640410490334034

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00364041
Iteration 2/1000 | Loss: 0.00022624
Iteration 3/1000 | Loss: 0.00020873
Iteration 4/1000 | Loss: 0.00017907
Iteration 5/1000 | Loss: 0.00017405
Iteration 6/1000 | Loss: 0.00035587
Iteration 7/1000 | Loss: 0.00011311
Iteration 8/1000 | Loss: 0.00047480
Iteration 9/1000 | Loss: 0.00003708
Iteration 10/1000 | Loss: 0.00003120
Iteration 11/1000 | Loss: 0.00002727
Iteration 12/1000 | Loss: 0.00002463
Iteration 13/1000 | Loss: 0.00002310
Iteration 14/1000 | Loss: 0.00005260
Iteration 15/1000 | Loss: 0.00017594
Iteration 16/1000 | Loss: 0.00003560
Iteration 17/1000 | Loss: 0.00002134
Iteration 18/1000 | Loss: 0.00002066
Iteration 19/1000 | Loss: 0.00019472
Iteration 20/1000 | Loss: 0.00009532
Iteration 21/1000 | Loss: 0.00012504
Iteration 22/1000 | Loss: 0.00002379
Iteration 23/1000 | Loss: 0.00005636
Iteration 24/1000 | Loss: 0.00007452
Iteration 25/1000 | Loss: 0.00007258
Iteration 26/1000 | Loss: 0.00012006
Iteration 27/1000 | Loss: 0.00003372
Iteration 28/1000 | Loss: 0.00002016
Iteration 29/1000 | Loss: 0.00001985
Iteration 30/1000 | Loss: 0.00024600
Iteration 31/1000 | Loss: 0.00015542
Iteration 32/1000 | Loss: 0.00013500
Iteration 33/1000 | Loss: 0.00002581
Iteration 34/1000 | Loss: 0.00006806
Iteration 35/1000 | Loss: 0.00002360
Iteration 36/1000 | Loss: 0.00002713
Iteration 37/1000 | Loss: 0.00010260
Iteration 38/1000 | Loss: 0.00002072
Iteration 39/1000 | Loss: 0.00003773
Iteration 40/1000 | Loss: 0.00002050
Iteration 41/1000 | Loss: 0.00001948
Iteration 42/1000 | Loss: 0.00008808
Iteration 43/1000 | Loss: 0.00009641
Iteration 44/1000 | Loss: 0.00002395
Iteration 45/1000 | Loss: 0.00006222
Iteration 46/1000 | Loss: 0.00019028
Iteration 47/1000 | Loss: 0.00021541
Iteration 48/1000 | Loss: 0.00026672
Iteration 49/1000 | Loss: 0.00018954
Iteration 50/1000 | Loss: 0.00005136
Iteration 51/1000 | Loss: 0.00025027
Iteration 52/1000 | Loss: 0.00004848
Iteration 53/1000 | Loss: 0.00004047
Iteration 54/1000 | Loss: 0.00003758
Iteration 55/1000 | Loss: 0.00002431
Iteration 56/1000 | Loss: 0.00004367
Iteration 57/1000 | Loss: 0.00002028
Iteration 58/1000 | Loss: 0.00001932
Iteration 59/1000 | Loss: 0.00003753
Iteration 60/1000 | Loss: 0.00011089
Iteration 61/1000 | Loss: 0.00008368
Iteration 62/1000 | Loss: 0.00001869
Iteration 63/1000 | Loss: 0.00011234
Iteration 64/1000 | Loss: 0.00002432
Iteration 65/1000 | Loss: 0.00003976
Iteration 66/1000 | Loss: 0.00001748
Iteration 67/1000 | Loss: 0.00004573
Iteration 68/1000 | Loss: 0.00003375
Iteration 69/1000 | Loss: 0.00001712
Iteration 70/1000 | Loss: 0.00001683
Iteration 71/1000 | Loss: 0.00004850
Iteration 72/1000 | Loss: 0.00008369
Iteration 73/1000 | Loss: 0.00009258
Iteration 74/1000 | Loss: 0.00002421
Iteration 75/1000 | Loss: 0.00001642
Iteration 76/1000 | Loss: 0.00001641
Iteration 77/1000 | Loss: 0.00001629
Iteration 78/1000 | Loss: 0.00001626
Iteration 79/1000 | Loss: 0.00001622
Iteration 80/1000 | Loss: 0.00009497
Iteration 81/1000 | Loss: 0.00002032
Iteration 82/1000 | Loss: 0.00002670
Iteration 83/1000 | Loss: 0.00001613
Iteration 84/1000 | Loss: 0.00001610
Iteration 85/1000 | Loss: 0.00001609
Iteration 86/1000 | Loss: 0.00001609
Iteration 87/1000 | Loss: 0.00001608
Iteration 88/1000 | Loss: 0.00003400
Iteration 89/1000 | Loss: 0.00001610
Iteration 90/1000 | Loss: 0.00001603
Iteration 91/1000 | Loss: 0.00001602
Iteration 92/1000 | Loss: 0.00001602
Iteration 93/1000 | Loss: 0.00001601
Iteration 94/1000 | Loss: 0.00001601
Iteration 95/1000 | Loss: 0.00001600
Iteration 96/1000 | Loss: 0.00001600
Iteration 97/1000 | Loss: 0.00001599
Iteration 98/1000 | Loss: 0.00001599
Iteration 99/1000 | Loss: 0.00001594
Iteration 100/1000 | Loss: 0.00001594
Iteration 101/1000 | Loss: 0.00001592
Iteration 102/1000 | Loss: 0.00001592
Iteration 103/1000 | Loss: 0.00001591
Iteration 104/1000 | Loss: 0.00001591
Iteration 105/1000 | Loss: 0.00001591
Iteration 106/1000 | Loss: 0.00001591
Iteration 107/1000 | Loss: 0.00001591
Iteration 108/1000 | Loss: 0.00001591
Iteration 109/1000 | Loss: 0.00001591
Iteration 110/1000 | Loss: 0.00001591
Iteration 111/1000 | Loss: 0.00001591
Iteration 112/1000 | Loss: 0.00001591
Iteration 113/1000 | Loss: 0.00001591
Iteration 114/1000 | Loss: 0.00001591
Iteration 115/1000 | Loss: 0.00001590
Iteration 116/1000 | Loss: 0.00001590
Iteration 117/1000 | Loss: 0.00001590
Iteration 118/1000 | Loss: 0.00001590
Iteration 119/1000 | Loss: 0.00001589
Iteration 120/1000 | Loss: 0.00001589
Iteration 121/1000 | Loss: 0.00001589
Iteration 122/1000 | Loss: 0.00001589
Iteration 123/1000 | Loss: 0.00001588
Iteration 124/1000 | Loss: 0.00001587
Iteration 125/1000 | Loss: 0.00001587
Iteration 126/1000 | Loss: 0.00001587
Iteration 127/1000 | Loss: 0.00001586
Iteration 128/1000 | Loss: 0.00001586
Iteration 129/1000 | Loss: 0.00001586
Iteration 130/1000 | Loss: 0.00001586
Iteration 131/1000 | Loss: 0.00001586
Iteration 132/1000 | Loss: 0.00001585
Iteration 133/1000 | Loss: 0.00001585
Iteration 134/1000 | Loss: 0.00001585
Iteration 135/1000 | Loss: 0.00001585
Iteration 136/1000 | Loss: 0.00001585
Iteration 137/1000 | Loss: 0.00001585
Iteration 138/1000 | Loss: 0.00001585
Iteration 139/1000 | Loss: 0.00001585
Iteration 140/1000 | Loss: 0.00001585
Iteration 141/1000 | Loss: 0.00001585
Iteration 142/1000 | Loss: 0.00001585
Iteration 143/1000 | Loss: 0.00001585
Iteration 144/1000 | Loss: 0.00001585
Iteration 145/1000 | Loss: 0.00001585
Iteration 146/1000 | Loss: 0.00001585
Iteration 147/1000 | Loss: 0.00001585
Iteration 148/1000 | Loss: 0.00001585
Iteration 149/1000 | Loss: 0.00001585
Iteration 150/1000 | Loss: 0.00001585
Iteration 151/1000 | Loss: 0.00001585
Iteration 152/1000 | Loss: 0.00001585
Iteration 153/1000 | Loss: 0.00001585
Iteration 154/1000 | Loss: 0.00001585
Iteration 155/1000 | Loss: 0.00001585
Iteration 156/1000 | Loss: 0.00001585
Iteration 157/1000 | Loss: 0.00001585
Iteration 158/1000 | Loss: 0.00001585
Iteration 159/1000 | Loss: 0.00001585
Iteration 160/1000 | Loss: 0.00001585
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 160. Stopping optimization.
Last 5 losses: [1.5849382180022076e-05, 1.5849382180022076e-05, 1.5849382180022076e-05, 1.5849382180022076e-05, 1.5849382180022076e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5849382180022076e-05

Optimization complete. Final v2v error: 3.4051015377044678 mm

Highest mean error: 4.430540084838867 mm for frame 120

Lowest mean error: 3.0707004070281982 mm for frame 122

Saving results

Total time: 166.19670844078064
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00931605
Iteration 2/25 | Loss: 0.00160596
Iteration 3/25 | Loss: 0.00135854
Iteration 4/25 | Loss: 0.00131317
Iteration 5/25 | Loss: 0.00129711
Iteration 6/25 | Loss: 0.00129321
Iteration 7/25 | Loss: 0.00129193
Iteration 8/25 | Loss: 0.00129193
Iteration 9/25 | Loss: 0.00129193
Iteration 10/25 | Loss: 0.00129193
Iteration 11/25 | Loss: 0.00129193
Iteration 12/25 | Loss: 0.00129193
Iteration 13/25 | Loss: 0.00129193
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0012919349828734994, 0.0012919349828734994, 0.0012919349828734994, 0.0012919349828734994, 0.0012919349828734994]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012919349828734994

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.27554166
Iteration 2/25 | Loss: 0.00282204
Iteration 3/25 | Loss: 0.00282204
Iteration 4/25 | Loss: 0.00282204
Iteration 5/25 | Loss: 0.00282204
Iteration 6/25 | Loss: 0.00282204
Iteration 7/25 | Loss: 0.00282204
Iteration 8/25 | Loss: 0.00282204
Iteration 9/25 | Loss: 0.00282204
Iteration 10/25 | Loss: 0.00282204
Iteration 11/25 | Loss: 0.00282204
Iteration 12/25 | Loss: 0.00282204
Iteration 13/25 | Loss: 0.00282204
Iteration 14/25 | Loss: 0.00282204
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.002822037087753415, 0.002822037087753415, 0.002822037087753415, 0.002822037087753415, 0.002822037087753415]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002822037087753415

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00282204
Iteration 2/1000 | Loss: 0.00007485
Iteration 3/1000 | Loss: 0.00004516
Iteration 4/1000 | Loss: 0.00003574
Iteration 5/1000 | Loss: 0.00003358
Iteration 6/1000 | Loss: 0.00003199
Iteration 7/1000 | Loss: 0.00003095
Iteration 8/1000 | Loss: 0.00003008
Iteration 9/1000 | Loss: 0.00002947
Iteration 10/1000 | Loss: 0.00002900
Iteration 11/1000 | Loss: 0.00002862
Iteration 12/1000 | Loss: 0.00002835
Iteration 13/1000 | Loss: 0.00002816
Iteration 14/1000 | Loss: 0.00002795
Iteration 15/1000 | Loss: 0.00002785
Iteration 16/1000 | Loss: 0.00002783
Iteration 17/1000 | Loss: 0.00002783
Iteration 18/1000 | Loss: 0.00002782
Iteration 19/1000 | Loss: 0.00002781
Iteration 20/1000 | Loss: 0.00002779
Iteration 21/1000 | Loss: 0.00002772
Iteration 22/1000 | Loss: 0.00002769
Iteration 23/1000 | Loss: 0.00002768
Iteration 24/1000 | Loss: 0.00002767
Iteration 25/1000 | Loss: 0.00002767
Iteration 26/1000 | Loss: 0.00002766
Iteration 27/1000 | Loss: 0.00002766
Iteration 28/1000 | Loss: 0.00002765
Iteration 29/1000 | Loss: 0.00002764
Iteration 30/1000 | Loss: 0.00002763
Iteration 31/1000 | Loss: 0.00002762
Iteration 32/1000 | Loss: 0.00002762
Iteration 33/1000 | Loss: 0.00002761
Iteration 34/1000 | Loss: 0.00002761
Iteration 35/1000 | Loss: 0.00002760
Iteration 36/1000 | Loss: 0.00002758
Iteration 37/1000 | Loss: 0.00002758
Iteration 38/1000 | Loss: 0.00002757
Iteration 39/1000 | Loss: 0.00002757
Iteration 40/1000 | Loss: 0.00002757
Iteration 41/1000 | Loss: 0.00002757
Iteration 42/1000 | Loss: 0.00002756
Iteration 43/1000 | Loss: 0.00002756
Iteration 44/1000 | Loss: 0.00002756
Iteration 45/1000 | Loss: 0.00002756
Iteration 46/1000 | Loss: 0.00002755
Iteration 47/1000 | Loss: 0.00002755
Iteration 48/1000 | Loss: 0.00002754
Iteration 49/1000 | Loss: 0.00002754
Iteration 50/1000 | Loss: 0.00002754
Iteration 51/1000 | Loss: 0.00002753
Iteration 52/1000 | Loss: 0.00002753
Iteration 53/1000 | Loss: 0.00002753
Iteration 54/1000 | Loss: 0.00002752
Iteration 55/1000 | Loss: 0.00002752
Iteration 56/1000 | Loss: 0.00002752
Iteration 57/1000 | Loss: 0.00002752
Iteration 58/1000 | Loss: 0.00002752
Iteration 59/1000 | Loss: 0.00002752
Iteration 60/1000 | Loss: 0.00002751
Iteration 61/1000 | Loss: 0.00002751
Iteration 62/1000 | Loss: 0.00002751
Iteration 63/1000 | Loss: 0.00002751
Iteration 64/1000 | Loss: 0.00002751
Iteration 65/1000 | Loss: 0.00002751
Iteration 66/1000 | Loss: 0.00002750
Iteration 67/1000 | Loss: 0.00002750
Iteration 68/1000 | Loss: 0.00002750
Iteration 69/1000 | Loss: 0.00002749
Iteration 70/1000 | Loss: 0.00002749
Iteration 71/1000 | Loss: 0.00002749
Iteration 72/1000 | Loss: 0.00002749
Iteration 73/1000 | Loss: 0.00002748
Iteration 74/1000 | Loss: 0.00002748
Iteration 75/1000 | Loss: 0.00002748
Iteration 76/1000 | Loss: 0.00002748
Iteration 77/1000 | Loss: 0.00002747
Iteration 78/1000 | Loss: 0.00002747
Iteration 79/1000 | Loss: 0.00002747
Iteration 80/1000 | Loss: 0.00002747
Iteration 81/1000 | Loss: 0.00002746
Iteration 82/1000 | Loss: 0.00002746
Iteration 83/1000 | Loss: 0.00002746
Iteration 84/1000 | Loss: 0.00002746
Iteration 85/1000 | Loss: 0.00002745
Iteration 86/1000 | Loss: 0.00002745
Iteration 87/1000 | Loss: 0.00002745
Iteration 88/1000 | Loss: 0.00002745
Iteration 89/1000 | Loss: 0.00002745
Iteration 90/1000 | Loss: 0.00002745
Iteration 91/1000 | Loss: 0.00002745
Iteration 92/1000 | Loss: 0.00002745
Iteration 93/1000 | Loss: 0.00002745
Iteration 94/1000 | Loss: 0.00002745
Iteration 95/1000 | Loss: 0.00002744
Iteration 96/1000 | Loss: 0.00002744
Iteration 97/1000 | Loss: 0.00002744
Iteration 98/1000 | Loss: 0.00002744
Iteration 99/1000 | Loss: 0.00002743
Iteration 100/1000 | Loss: 0.00002743
Iteration 101/1000 | Loss: 0.00002743
Iteration 102/1000 | Loss: 0.00002743
Iteration 103/1000 | Loss: 0.00002742
Iteration 104/1000 | Loss: 0.00002742
Iteration 105/1000 | Loss: 0.00002742
Iteration 106/1000 | Loss: 0.00002742
Iteration 107/1000 | Loss: 0.00002742
Iteration 108/1000 | Loss: 0.00002742
Iteration 109/1000 | Loss: 0.00002742
Iteration 110/1000 | Loss: 0.00002741
Iteration 111/1000 | Loss: 0.00002741
Iteration 112/1000 | Loss: 0.00002741
Iteration 113/1000 | Loss: 0.00002741
Iteration 114/1000 | Loss: 0.00002741
Iteration 115/1000 | Loss: 0.00002741
Iteration 116/1000 | Loss: 0.00002741
Iteration 117/1000 | Loss: 0.00002741
Iteration 118/1000 | Loss: 0.00002741
Iteration 119/1000 | Loss: 0.00002741
Iteration 120/1000 | Loss: 0.00002741
Iteration 121/1000 | Loss: 0.00002741
Iteration 122/1000 | Loss: 0.00002740
Iteration 123/1000 | Loss: 0.00002740
Iteration 124/1000 | Loss: 0.00002740
Iteration 125/1000 | Loss: 0.00002740
Iteration 126/1000 | Loss: 0.00002740
Iteration 127/1000 | Loss: 0.00002740
Iteration 128/1000 | Loss: 0.00002739
Iteration 129/1000 | Loss: 0.00002739
Iteration 130/1000 | Loss: 0.00002739
Iteration 131/1000 | Loss: 0.00002739
Iteration 132/1000 | Loss: 0.00002738
Iteration 133/1000 | Loss: 0.00002738
Iteration 134/1000 | Loss: 0.00002738
Iteration 135/1000 | Loss: 0.00002738
Iteration 136/1000 | Loss: 0.00002738
Iteration 137/1000 | Loss: 0.00002738
Iteration 138/1000 | Loss: 0.00002738
Iteration 139/1000 | Loss: 0.00002738
Iteration 140/1000 | Loss: 0.00002738
Iteration 141/1000 | Loss: 0.00002737
Iteration 142/1000 | Loss: 0.00002737
Iteration 143/1000 | Loss: 0.00002737
Iteration 144/1000 | Loss: 0.00002737
Iteration 145/1000 | Loss: 0.00002736
Iteration 146/1000 | Loss: 0.00002736
Iteration 147/1000 | Loss: 0.00002736
Iteration 148/1000 | Loss: 0.00002736
Iteration 149/1000 | Loss: 0.00002736
Iteration 150/1000 | Loss: 0.00002736
Iteration 151/1000 | Loss: 0.00002735
Iteration 152/1000 | Loss: 0.00002735
Iteration 153/1000 | Loss: 0.00002735
Iteration 154/1000 | Loss: 0.00002735
Iteration 155/1000 | Loss: 0.00002735
Iteration 156/1000 | Loss: 0.00002735
Iteration 157/1000 | Loss: 0.00002735
Iteration 158/1000 | Loss: 0.00002735
Iteration 159/1000 | Loss: 0.00002735
Iteration 160/1000 | Loss: 0.00002734
Iteration 161/1000 | Loss: 0.00002734
Iteration 162/1000 | Loss: 0.00002734
Iteration 163/1000 | Loss: 0.00002734
Iteration 164/1000 | Loss: 0.00002734
Iteration 165/1000 | Loss: 0.00002733
Iteration 166/1000 | Loss: 0.00002733
Iteration 167/1000 | Loss: 0.00002733
Iteration 168/1000 | Loss: 0.00002733
Iteration 169/1000 | Loss: 0.00002733
Iteration 170/1000 | Loss: 0.00002733
Iteration 171/1000 | Loss: 0.00002733
Iteration 172/1000 | Loss: 0.00002732
Iteration 173/1000 | Loss: 0.00002732
Iteration 174/1000 | Loss: 0.00002732
Iteration 175/1000 | Loss: 0.00002732
Iteration 176/1000 | Loss: 0.00002732
Iteration 177/1000 | Loss: 0.00002732
Iteration 178/1000 | Loss: 0.00002732
Iteration 179/1000 | Loss: 0.00002732
Iteration 180/1000 | Loss: 0.00002732
Iteration 181/1000 | Loss: 0.00002732
Iteration 182/1000 | Loss: 0.00002732
Iteration 183/1000 | Loss: 0.00002732
Iteration 184/1000 | Loss: 0.00002731
Iteration 185/1000 | Loss: 0.00002731
Iteration 186/1000 | Loss: 0.00002731
Iteration 187/1000 | Loss: 0.00002731
Iteration 188/1000 | Loss: 0.00002731
Iteration 189/1000 | Loss: 0.00002731
Iteration 190/1000 | Loss: 0.00002731
Iteration 191/1000 | Loss: 0.00002731
Iteration 192/1000 | Loss: 0.00002731
Iteration 193/1000 | Loss: 0.00002731
Iteration 194/1000 | Loss: 0.00002731
Iteration 195/1000 | Loss: 0.00002731
Iteration 196/1000 | Loss: 0.00002731
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 196. Stopping optimization.
Last 5 losses: [2.7313450118526816e-05, 2.7313450118526816e-05, 2.7313450118526816e-05, 2.7313450118526816e-05, 2.7313450118526816e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7313450118526816e-05

Optimization complete. Final v2v error: 4.132144927978516 mm

Highest mean error: 7.0137152671813965 mm for frame 117

Lowest mean error: 2.803769588470459 mm for frame 74

Saving results

Total time: 45.71403694152832
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00951208
Iteration 2/25 | Loss: 0.00220296
Iteration 3/25 | Loss: 0.00182510
Iteration 4/25 | Loss: 0.00149507
Iteration 5/25 | Loss: 0.00142850
Iteration 6/25 | Loss: 0.00137983
Iteration 7/25 | Loss: 0.00134506
Iteration 8/25 | Loss: 0.00133143
Iteration 9/25 | Loss: 0.00132887
Iteration 10/25 | Loss: 0.00131759
Iteration 11/25 | Loss: 0.00130257
Iteration 12/25 | Loss: 0.00129989
Iteration 13/25 | Loss: 0.00129844
Iteration 14/25 | Loss: 0.00130145
Iteration 15/25 | Loss: 0.00129442
Iteration 16/25 | Loss: 0.00129190
Iteration 17/25 | Loss: 0.00129152
Iteration 18/25 | Loss: 0.00129136
Iteration 19/25 | Loss: 0.00129128
Iteration 20/25 | Loss: 0.00129127
Iteration 21/25 | Loss: 0.00129127
Iteration 22/25 | Loss: 0.00129127
Iteration 23/25 | Loss: 0.00129127
Iteration 24/25 | Loss: 0.00129127
Iteration 25/25 | Loss: 0.00129127

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.22716820
Iteration 2/25 | Loss: 0.00225752
Iteration 3/25 | Loss: 0.00225752
Iteration 4/25 | Loss: 0.00225752
Iteration 5/25 | Loss: 0.00225751
Iteration 6/25 | Loss: 0.00225751
Iteration 7/25 | Loss: 0.00225751
Iteration 8/25 | Loss: 0.00225751
Iteration 9/25 | Loss: 0.00225751
Iteration 10/25 | Loss: 0.00225751
Iteration 11/25 | Loss: 0.00225751
Iteration 12/25 | Loss: 0.00225751
Iteration 13/25 | Loss: 0.00225751
Iteration 14/25 | Loss: 0.00225751
Iteration 15/25 | Loss: 0.00225751
Iteration 16/25 | Loss: 0.00225751
Iteration 17/25 | Loss: 0.00225751
Iteration 18/25 | Loss: 0.00225751
Iteration 19/25 | Loss: 0.00225751
Iteration 20/25 | Loss: 0.00225751
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0022575119510293007, 0.0022575119510293007, 0.0022575119510293007, 0.0022575119510293007, 0.0022575119510293007]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0022575119510293007

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00225751
Iteration 2/1000 | Loss: 0.00009197
Iteration 3/1000 | Loss: 0.00005832
Iteration 4/1000 | Loss: 0.00005077
Iteration 5/1000 | Loss: 0.00004796
Iteration 6/1000 | Loss: 0.00004577
Iteration 7/1000 | Loss: 0.00004384
Iteration 8/1000 | Loss: 0.00004237
Iteration 9/1000 | Loss: 0.00004114
Iteration 10/1000 | Loss: 0.00004039
Iteration 11/1000 | Loss: 0.00003979
Iteration 12/1000 | Loss: 0.00003941
Iteration 13/1000 | Loss: 0.00003901
Iteration 14/1000 | Loss: 0.00003870
Iteration 15/1000 | Loss: 0.00003852
Iteration 16/1000 | Loss: 0.00003852
Iteration 17/1000 | Loss: 0.00003840
Iteration 18/1000 | Loss: 0.00003827
Iteration 19/1000 | Loss: 0.00003825
Iteration 20/1000 | Loss: 0.00003820
Iteration 21/1000 | Loss: 0.00003816
Iteration 22/1000 | Loss: 0.00003811
Iteration 23/1000 | Loss: 0.00120502
Iteration 24/1000 | Loss: 0.00049185
Iteration 25/1000 | Loss: 0.00008426
Iteration 26/1000 | Loss: 0.00006303
Iteration 27/1000 | Loss: 0.00004338
Iteration 28/1000 | Loss: 0.00098099
Iteration 29/1000 | Loss: 0.00070804
Iteration 30/1000 | Loss: 0.00033771
Iteration 31/1000 | Loss: 0.00092247
Iteration 32/1000 | Loss: 0.00090668
Iteration 33/1000 | Loss: 0.00046505
Iteration 34/1000 | Loss: 0.00025924
Iteration 35/1000 | Loss: 0.00026360
Iteration 36/1000 | Loss: 0.00004526
Iteration 37/1000 | Loss: 0.00028901
Iteration 38/1000 | Loss: 0.00022484
Iteration 39/1000 | Loss: 0.00004360
Iteration 40/1000 | Loss: 0.00003830
Iteration 41/1000 | Loss: 0.00003475
Iteration 42/1000 | Loss: 0.00010053
Iteration 43/1000 | Loss: 0.00003590
Iteration 44/1000 | Loss: 0.00003224
Iteration 45/1000 | Loss: 0.00003057
Iteration 46/1000 | Loss: 0.00002931
Iteration 47/1000 | Loss: 0.00002874
Iteration 48/1000 | Loss: 0.00002834
Iteration 49/1000 | Loss: 0.00002804
Iteration 50/1000 | Loss: 0.00002772
Iteration 51/1000 | Loss: 0.00002742
Iteration 52/1000 | Loss: 0.00002720
Iteration 53/1000 | Loss: 0.00002701
Iteration 54/1000 | Loss: 0.00002680
Iteration 55/1000 | Loss: 0.00002680
Iteration 56/1000 | Loss: 0.00002677
Iteration 57/1000 | Loss: 0.00002663
Iteration 58/1000 | Loss: 0.00002661
Iteration 59/1000 | Loss: 0.00002660
Iteration 60/1000 | Loss: 0.00002660
Iteration 61/1000 | Loss: 0.00002659
Iteration 62/1000 | Loss: 0.00002659
Iteration 63/1000 | Loss: 0.00002659
Iteration 64/1000 | Loss: 0.00002658
Iteration 65/1000 | Loss: 0.00002657
Iteration 66/1000 | Loss: 0.00002657
Iteration 67/1000 | Loss: 0.00002657
Iteration 68/1000 | Loss: 0.00002655
Iteration 69/1000 | Loss: 0.00002655
Iteration 70/1000 | Loss: 0.00002655
Iteration 71/1000 | Loss: 0.00002654
Iteration 72/1000 | Loss: 0.00002654
Iteration 73/1000 | Loss: 0.00002654
Iteration 74/1000 | Loss: 0.00002654
Iteration 75/1000 | Loss: 0.00002654
Iteration 76/1000 | Loss: 0.00002654
Iteration 77/1000 | Loss: 0.00002654
Iteration 78/1000 | Loss: 0.00002654
Iteration 79/1000 | Loss: 0.00002654
Iteration 80/1000 | Loss: 0.00002654
Iteration 81/1000 | Loss: 0.00002654
Iteration 82/1000 | Loss: 0.00002654
Iteration 83/1000 | Loss: 0.00002654
Iteration 84/1000 | Loss: 0.00002654
Iteration 85/1000 | Loss: 0.00002653
Iteration 86/1000 | Loss: 0.00002653
Iteration 87/1000 | Loss: 0.00002653
Iteration 88/1000 | Loss: 0.00002653
Iteration 89/1000 | Loss: 0.00002653
Iteration 90/1000 | Loss: 0.00002653
Iteration 91/1000 | Loss: 0.00002653
Iteration 92/1000 | Loss: 0.00002652
Iteration 93/1000 | Loss: 0.00002652
Iteration 94/1000 | Loss: 0.00002652
Iteration 95/1000 | Loss: 0.00002652
Iteration 96/1000 | Loss: 0.00002652
Iteration 97/1000 | Loss: 0.00002651
Iteration 98/1000 | Loss: 0.00002651
Iteration 99/1000 | Loss: 0.00002651
Iteration 100/1000 | Loss: 0.00002651
Iteration 101/1000 | Loss: 0.00002651
Iteration 102/1000 | Loss: 0.00002651
Iteration 103/1000 | Loss: 0.00002651
Iteration 104/1000 | Loss: 0.00002651
Iteration 105/1000 | Loss: 0.00002651
Iteration 106/1000 | Loss: 0.00002651
Iteration 107/1000 | Loss: 0.00002650
Iteration 108/1000 | Loss: 0.00002650
Iteration 109/1000 | Loss: 0.00002650
Iteration 110/1000 | Loss: 0.00002649
Iteration 111/1000 | Loss: 0.00002649
Iteration 112/1000 | Loss: 0.00002649
Iteration 113/1000 | Loss: 0.00002649
Iteration 114/1000 | Loss: 0.00002649
Iteration 115/1000 | Loss: 0.00002648
Iteration 116/1000 | Loss: 0.00002648
Iteration 117/1000 | Loss: 0.00002648
Iteration 118/1000 | Loss: 0.00002648
Iteration 119/1000 | Loss: 0.00002648
Iteration 120/1000 | Loss: 0.00002648
Iteration 121/1000 | Loss: 0.00002648
Iteration 122/1000 | Loss: 0.00002647
Iteration 123/1000 | Loss: 0.00002647
Iteration 124/1000 | Loss: 0.00002647
Iteration 125/1000 | Loss: 0.00002647
Iteration 126/1000 | Loss: 0.00002646
Iteration 127/1000 | Loss: 0.00002646
Iteration 128/1000 | Loss: 0.00002646
Iteration 129/1000 | Loss: 0.00002646
Iteration 130/1000 | Loss: 0.00002645
Iteration 131/1000 | Loss: 0.00002645
Iteration 132/1000 | Loss: 0.00002645
Iteration 133/1000 | Loss: 0.00002645
Iteration 134/1000 | Loss: 0.00002645
Iteration 135/1000 | Loss: 0.00002645
Iteration 136/1000 | Loss: 0.00002645
Iteration 137/1000 | Loss: 0.00002645
Iteration 138/1000 | Loss: 0.00002644
Iteration 139/1000 | Loss: 0.00002644
Iteration 140/1000 | Loss: 0.00002644
Iteration 141/1000 | Loss: 0.00002644
Iteration 142/1000 | Loss: 0.00002644
Iteration 143/1000 | Loss: 0.00002644
Iteration 144/1000 | Loss: 0.00002644
Iteration 145/1000 | Loss: 0.00002643
Iteration 146/1000 | Loss: 0.00002643
Iteration 147/1000 | Loss: 0.00002643
Iteration 148/1000 | Loss: 0.00002643
Iteration 149/1000 | Loss: 0.00002643
Iteration 150/1000 | Loss: 0.00002643
Iteration 151/1000 | Loss: 0.00002643
Iteration 152/1000 | Loss: 0.00002643
Iteration 153/1000 | Loss: 0.00002643
Iteration 154/1000 | Loss: 0.00002643
Iteration 155/1000 | Loss: 0.00002643
Iteration 156/1000 | Loss: 0.00002643
Iteration 157/1000 | Loss: 0.00002643
Iteration 158/1000 | Loss: 0.00002643
Iteration 159/1000 | Loss: 0.00002643
Iteration 160/1000 | Loss: 0.00002642
Iteration 161/1000 | Loss: 0.00002642
Iteration 162/1000 | Loss: 0.00002642
Iteration 163/1000 | Loss: 0.00002642
Iteration 164/1000 | Loss: 0.00002642
Iteration 165/1000 | Loss: 0.00002642
Iteration 166/1000 | Loss: 0.00002642
Iteration 167/1000 | Loss: 0.00002642
Iteration 168/1000 | Loss: 0.00002642
Iteration 169/1000 | Loss: 0.00002642
Iteration 170/1000 | Loss: 0.00002642
Iteration 171/1000 | Loss: 0.00002642
Iteration 172/1000 | Loss: 0.00002642
Iteration 173/1000 | Loss: 0.00002642
Iteration 174/1000 | Loss: 0.00002642
Iteration 175/1000 | Loss: 0.00002642
Iteration 176/1000 | Loss: 0.00002642
Iteration 177/1000 | Loss: 0.00002641
Iteration 178/1000 | Loss: 0.00002641
Iteration 179/1000 | Loss: 0.00002641
Iteration 180/1000 | Loss: 0.00002641
Iteration 181/1000 | Loss: 0.00002641
Iteration 182/1000 | Loss: 0.00002641
Iteration 183/1000 | Loss: 0.00002641
Iteration 184/1000 | Loss: 0.00002641
Iteration 185/1000 | Loss: 0.00002641
Iteration 186/1000 | Loss: 0.00002640
Iteration 187/1000 | Loss: 0.00002640
Iteration 188/1000 | Loss: 0.00002640
Iteration 189/1000 | Loss: 0.00002640
Iteration 190/1000 | Loss: 0.00002640
Iteration 191/1000 | Loss: 0.00002640
Iteration 192/1000 | Loss: 0.00002640
Iteration 193/1000 | Loss: 0.00002640
Iteration 194/1000 | Loss: 0.00002640
Iteration 195/1000 | Loss: 0.00002640
Iteration 196/1000 | Loss: 0.00002640
Iteration 197/1000 | Loss: 0.00002640
Iteration 198/1000 | Loss: 0.00002640
Iteration 199/1000 | Loss: 0.00002640
Iteration 200/1000 | Loss: 0.00002640
Iteration 201/1000 | Loss: 0.00002640
Iteration 202/1000 | Loss: 0.00002639
Iteration 203/1000 | Loss: 0.00002639
Iteration 204/1000 | Loss: 0.00002639
Iteration 205/1000 | Loss: 0.00002639
Iteration 206/1000 | Loss: 0.00002639
Iteration 207/1000 | Loss: 0.00002639
Iteration 208/1000 | Loss: 0.00002639
Iteration 209/1000 | Loss: 0.00002639
Iteration 210/1000 | Loss: 0.00002639
Iteration 211/1000 | Loss: 0.00002638
Iteration 212/1000 | Loss: 0.00002638
Iteration 213/1000 | Loss: 0.00002638
Iteration 214/1000 | Loss: 0.00002638
Iteration 215/1000 | Loss: 0.00002638
Iteration 216/1000 | Loss: 0.00002638
Iteration 217/1000 | Loss: 0.00002638
Iteration 218/1000 | Loss: 0.00002638
Iteration 219/1000 | Loss: 0.00002638
Iteration 220/1000 | Loss: 0.00002637
Iteration 221/1000 | Loss: 0.00002637
Iteration 222/1000 | Loss: 0.00002637
Iteration 223/1000 | Loss: 0.00002637
Iteration 224/1000 | Loss: 0.00002637
Iteration 225/1000 | Loss: 0.00002637
Iteration 226/1000 | Loss: 0.00002637
Iteration 227/1000 | Loss: 0.00002637
Iteration 228/1000 | Loss: 0.00002637
Iteration 229/1000 | Loss: 0.00002637
Iteration 230/1000 | Loss: 0.00002637
Iteration 231/1000 | Loss: 0.00002637
Iteration 232/1000 | Loss: 0.00002637
Iteration 233/1000 | Loss: 0.00002637
Iteration 234/1000 | Loss: 0.00002637
Iteration 235/1000 | Loss: 0.00002637
Iteration 236/1000 | Loss: 0.00002637
Iteration 237/1000 | Loss: 0.00002637
Iteration 238/1000 | Loss: 0.00002637
Iteration 239/1000 | Loss: 0.00002637
Iteration 240/1000 | Loss: 0.00002637
Iteration 241/1000 | Loss: 0.00002637
Iteration 242/1000 | Loss: 0.00002637
Iteration 243/1000 | Loss: 0.00002637
Iteration 244/1000 | Loss: 0.00002637
Iteration 245/1000 | Loss: 0.00002637
Iteration 246/1000 | Loss: 0.00002637
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 246. Stopping optimization.
Last 5 losses: [2.6366491510998458e-05, 2.6366491510998458e-05, 2.6366491510998458e-05, 2.6366491510998458e-05, 2.6366491510998458e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6366491510998458e-05

Optimization complete. Final v2v error: 3.9001893997192383 mm

Highest mean error: 5.742403984069824 mm for frame 114

Lowest mean error: 2.8176400661468506 mm for frame 51

Saving results

Total time: 115.62429761886597
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00890743
Iteration 2/25 | Loss: 0.00128575
Iteration 3/25 | Loss: 0.00119044
Iteration 4/25 | Loss: 0.00118410
Iteration 5/25 | Loss: 0.00118322
Iteration 6/25 | Loss: 0.00118322
Iteration 7/25 | Loss: 0.00118322
Iteration 8/25 | Loss: 0.00118322
Iteration 9/25 | Loss: 0.00118322
Iteration 10/25 | Loss: 0.00118322
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0011832244927063584, 0.0011832244927063584, 0.0011832244927063584, 0.0011832244927063584, 0.0011832244927063584]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011832244927063584

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.75343132
Iteration 2/25 | Loss: 0.00233726
Iteration 3/25 | Loss: 0.00233726
Iteration 4/25 | Loss: 0.00233726
Iteration 5/25 | Loss: 0.00233726
Iteration 6/25 | Loss: 0.00233726
Iteration 7/25 | Loss: 0.00233726
Iteration 8/25 | Loss: 0.00233726
Iteration 9/25 | Loss: 0.00233726
Iteration 10/25 | Loss: 0.00233726
Iteration 11/25 | Loss: 0.00233726
Iteration 12/25 | Loss: 0.00233726
Iteration 13/25 | Loss: 0.00233726
Iteration 14/25 | Loss: 0.00233726
Iteration 15/25 | Loss: 0.00233726
Iteration 16/25 | Loss: 0.00233726
Iteration 17/25 | Loss: 0.00233726
Iteration 18/25 | Loss: 0.00233726
Iteration 19/25 | Loss: 0.00233726
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.002337256446480751, 0.002337256446480751, 0.002337256446480751, 0.002337256446480751, 0.002337256446480751]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002337256446480751

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00233726
Iteration 2/1000 | Loss: 0.00001977
Iteration 3/1000 | Loss: 0.00001344
Iteration 4/1000 | Loss: 0.00001204
Iteration 5/1000 | Loss: 0.00001132
Iteration 6/1000 | Loss: 0.00001078
Iteration 7/1000 | Loss: 0.00001077
Iteration 8/1000 | Loss: 0.00001044
Iteration 9/1000 | Loss: 0.00001034
Iteration 10/1000 | Loss: 0.00001010
Iteration 11/1000 | Loss: 0.00001009
Iteration 12/1000 | Loss: 0.00001008
Iteration 13/1000 | Loss: 0.00001007
Iteration 14/1000 | Loss: 0.00000998
Iteration 15/1000 | Loss: 0.00000995
Iteration 16/1000 | Loss: 0.00000994
Iteration 17/1000 | Loss: 0.00000993
Iteration 18/1000 | Loss: 0.00000992
Iteration 19/1000 | Loss: 0.00000989
Iteration 20/1000 | Loss: 0.00000989
Iteration 21/1000 | Loss: 0.00000988
Iteration 22/1000 | Loss: 0.00000987
Iteration 23/1000 | Loss: 0.00000987
Iteration 24/1000 | Loss: 0.00000987
Iteration 25/1000 | Loss: 0.00000986
Iteration 26/1000 | Loss: 0.00000986
Iteration 27/1000 | Loss: 0.00000986
Iteration 28/1000 | Loss: 0.00000985
Iteration 29/1000 | Loss: 0.00000983
Iteration 30/1000 | Loss: 0.00000981
Iteration 31/1000 | Loss: 0.00000981
Iteration 32/1000 | Loss: 0.00000981
Iteration 33/1000 | Loss: 0.00000981
Iteration 34/1000 | Loss: 0.00000981
Iteration 35/1000 | Loss: 0.00000981
Iteration 36/1000 | Loss: 0.00000981
Iteration 37/1000 | Loss: 0.00000981
Iteration 38/1000 | Loss: 0.00000981
Iteration 39/1000 | Loss: 0.00000981
Iteration 40/1000 | Loss: 0.00000980
Iteration 41/1000 | Loss: 0.00000980
Iteration 42/1000 | Loss: 0.00000980
Iteration 43/1000 | Loss: 0.00000980
Iteration 44/1000 | Loss: 0.00000979
Iteration 45/1000 | Loss: 0.00000979
Iteration 46/1000 | Loss: 0.00000978
Iteration 47/1000 | Loss: 0.00000978
Iteration 48/1000 | Loss: 0.00000973
Iteration 49/1000 | Loss: 0.00000973
Iteration 50/1000 | Loss: 0.00000972
Iteration 51/1000 | Loss: 0.00000972
Iteration 52/1000 | Loss: 0.00000972
Iteration 53/1000 | Loss: 0.00000972
Iteration 54/1000 | Loss: 0.00000971
Iteration 55/1000 | Loss: 0.00000971
Iteration 56/1000 | Loss: 0.00000971
Iteration 57/1000 | Loss: 0.00000970
Iteration 58/1000 | Loss: 0.00000970
Iteration 59/1000 | Loss: 0.00000970
Iteration 60/1000 | Loss: 0.00000969
Iteration 61/1000 | Loss: 0.00000969
Iteration 62/1000 | Loss: 0.00000969
Iteration 63/1000 | Loss: 0.00000969
Iteration 64/1000 | Loss: 0.00000969
Iteration 65/1000 | Loss: 0.00000969
Iteration 66/1000 | Loss: 0.00000969
Iteration 67/1000 | Loss: 0.00000969
Iteration 68/1000 | Loss: 0.00000969
Iteration 69/1000 | Loss: 0.00000968
Iteration 70/1000 | Loss: 0.00000968
Iteration 71/1000 | Loss: 0.00000968
Iteration 72/1000 | Loss: 0.00000968
Iteration 73/1000 | Loss: 0.00000968
Iteration 74/1000 | Loss: 0.00000968
Iteration 75/1000 | Loss: 0.00000968
Iteration 76/1000 | Loss: 0.00000967
Iteration 77/1000 | Loss: 0.00000967
Iteration 78/1000 | Loss: 0.00000967
Iteration 79/1000 | Loss: 0.00000967
Iteration 80/1000 | Loss: 0.00000967
Iteration 81/1000 | Loss: 0.00000967
Iteration 82/1000 | Loss: 0.00000966
Iteration 83/1000 | Loss: 0.00000966
Iteration 84/1000 | Loss: 0.00000966
Iteration 85/1000 | Loss: 0.00000965
Iteration 86/1000 | Loss: 0.00000965
Iteration 87/1000 | Loss: 0.00000965
Iteration 88/1000 | Loss: 0.00000965
Iteration 89/1000 | Loss: 0.00000965
Iteration 90/1000 | Loss: 0.00000965
Iteration 91/1000 | Loss: 0.00000965
Iteration 92/1000 | Loss: 0.00000965
Iteration 93/1000 | Loss: 0.00000965
Iteration 94/1000 | Loss: 0.00000965
Iteration 95/1000 | Loss: 0.00000965
Iteration 96/1000 | Loss: 0.00000965
Iteration 97/1000 | Loss: 0.00000965
Iteration 98/1000 | Loss: 0.00000965
Iteration 99/1000 | Loss: 0.00000965
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 99. Stopping optimization.
Last 5 losses: [9.65427989285672e-06, 9.65427989285672e-06, 9.65427989285672e-06, 9.65427989285672e-06, 9.65427989285672e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.65427989285672e-06

Optimization complete. Final v2v error: 2.6488826274871826 mm

Highest mean error: 2.9029033184051514 mm for frame 132

Lowest mean error: 2.4458086490631104 mm for frame 49

Saving results

Total time: 30.261136770248413
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01064556
Iteration 2/25 | Loss: 0.00243810
Iteration 3/25 | Loss: 0.00169517
Iteration 4/25 | Loss: 0.00171732
Iteration 5/25 | Loss: 0.00154947
Iteration 6/25 | Loss: 0.00136876
Iteration 7/25 | Loss: 0.00130806
Iteration 8/25 | Loss: 0.00129316
Iteration 9/25 | Loss: 0.00128758
Iteration 10/25 | Loss: 0.00129185
Iteration 11/25 | Loss: 0.00129161
Iteration 12/25 | Loss: 0.00128648
Iteration 13/25 | Loss: 0.00128078
Iteration 14/25 | Loss: 0.00127766
Iteration 15/25 | Loss: 0.00127792
Iteration 16/25 | Loss: 0.00127736
Iteration 17/25 | Loss: 0.00127755
Iteration 18/25 | Loss: 0.00127744
Iteration 19/25 | Loss: 0.00127638
Iteration 20/25 | Loss: 0.00127756
Iteration 21/25 | Loss: 0.00127706
Iteration 22/25 | Loss: 0.00127644
Iteration 23/25 | Loss: 0.00127729
Iteration 24/25 | Loss: 0.00127764
Iteration 25/25 | Loss: 0.00127695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.13061285
Iteration 2/25 | Loss: 0.00259748
Iteration 3/25 | Loss: 0.00259748
Iteration 4/25 | Loss: 0.00259748
Iteration 5/25 | Loss: 0.00259748
Iteration 6/25 | Loss: 0.00259748
Iteration 7/25 | Loss: 0.00259748
Iteration 8/25 | Loss: 0.00259748
Iteration 9/25 | Loss: 0.00259748
Iteration 10/25 | Loss: 0.00259748
Iteration 11/25 | Loss: 0.00259748
Iteration 12/25 | Loss: 0.00259748
Iteration 13/25 | Loss: 0.00259748
Iteration 14/25 | Loss: 0.00259748
Iteration 15/25 | Loss: 0.00259748
Iteration 16/25 | Loss: 0.00259748
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.002597477752715349, 0.002597477752715349, 0.002597477752715349, 0.002597477752715349, 0.002597477752715349]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002597477752715349

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00259748
Iteration 2/1000 | Loss: 0.00010342
Iteration 3/1000 | Loss: 0.00005899
Iteration 4/1000 | Loss: 0.00004923
Iteration 5/1000 | Loss: 0.00004907
Iteration 6/1000 | Loss: 0.00003938
Iteration 7/1000 | Loss: 0.00002937
Iteration 8/1000 | Loss: 0.00004668
Iteration 9/1000 | Loss: 0.00004342
Iteration 10/1000 | Loss: 0.00003318
Iteration 11/1000 | Loss: 0.00003653
Iteration 12/1000 | Loss: 0.00003983
Iteration 13/1000 | Loss: 0.00004126
Iteration 14/1000 | Loss: 0.00003639
Iteration 15/1000 | Loss: 0.00004246
Iteration 16/1000 | Loss: 0.00004041
Iteration 17/1000 | Loss: 0.00003955
Iteration 18/1000 | Loss: 0.00002979
Iteration 19/1000 | Loss: 0.00002939
Iteration 20/1000 | Loss: 0.00003582
Iteration 21/1000 | Loss: 0.00003674
Iteration 22/1000 | Loss: 0.00003555
Iteration 23/1000 | Loss: 0.00003393
Iteration 24/1000 | Loss: 0.00004274
Iteration 25/1000 | Loss: 0.00003207
Iteration 26/1000 | Loss: 0.00003256
Iteration 27/1000 | Loss: 0.00003657
Iteration 28/1000 | Loss: 0.00002703
Iteration 29/1000 | Loss: 0.00003593
Iteration 30/1000 | Loss: 0.00002629
Iteration 31/1000 | Loss: 0.00003471
Iteration 32/1000 | Loss: 0.00003301
Iteration 33/1000 | Loss: 0.00003555
Iteration 34/1000 | Loss: 0.00003342
Iteration 35/1000 | Loss: 0.00003459
Iteration 36/1000 | Loss: 0.00004384
Iteration 37/1000 | Loss: 0.00004050
Iteration 38/1000 | Loss: 0.00003679
Iteration 39/1000 | Loss: 0.00004293
Iteration 40/1000 | Loss: 0.00003295
Iteration 41/1000 | Loss: 0.00004145
Iteration 42/1000 | Loss: 0.00002823
Iteration 43/1000 | Loss: 0.00002521
Iteration 44/1000 | Loss: 0.00003368
Iteration 45/1000 | Loss: 0.00003206
Iteration 46/1000 | Loss: 0.00002834
Iteration 47/1000 | Loss: 0.00003212
Iteration 48/1000 | Loss: 0.00002768
Iteration 49/1000 | Loss: 0.00002997
Iteration 50/1000 | Loss: 0.00002715
Iteration 51/1000 | Loss: 0.00002255
Iteration 52/1000 | Loss: 0.00002768
Iteration 53/1000 | Loss: 0.00002892
Iteration 54/1000 | Loss: 0.00002513
Iteration 55/1000 | Loss: 0.00002634
Iteration 56/1000 | Loss: 0.00003329
Iteration 57/1000 | Loss: 0.00002937
Iteration 58/1000 | Loss: 0.00003072
Iteration 59/1000 | Loss: 0.00002935
Iteration 60/1000 | Loss: 0.00003280
Iteration 61/1000 | Loss: 0.00003083
Iteration 62/1000 | Loss: 0.00003130
Iteration 63/1000 | Loss: 0.00003679
Iteration 64/1000 | Loss: 0.00003093
Iteration 65/1000 | Loss: 0.00003685
Iteration 66/1000 | Loss: 0.00002136
Iteration 67/1000 | Loss: 0.00002011
Iteration 68/1000 | Loss: 0.00001922
Iteration 69/1000 | Loss: 0.00001876
Iteration 70/1000 | Loss: 0.00001824
Iteration 71/1000 | Loss: 0.00001800
Iteration 72/1000 | Loss: 0.00001789
Iteration 73/1000 | Loss: 0.00001787
Iteration 74/1000 | Loss: 0.00001785
Iteration 75/1000 | Loss: 0.00001784
Iteration 76/1000 | Loss: 0.00001780
Iteration 77/1000 | Loss: 0.00001774
Iteration 78/1000 | Loss: 0.00001773
Iteration 79/1000 | Loss: 0.00001773
Iteration 80/1000 | Loss: 0.00001772
Iteration 81/1000 | Loss: 0.00001772
Iteration 82/1000 | Loss: 0.00001771
Iteration 83/1000 | Loss: 0.00001771
Iteration 84/1000 | Loss: 0.00001769
Iteration 85/1000 | Loss: 0.00001767
Iteration 86/1000 | Loss: 0.00001766
Iteration 87/1000 | Loss: 0.00001766
Iteration 88/1000 | Loss: 0.00001764
Iteration 89/1000 | Loss: 0.00001764
Iteration 90/1000 | Loss: 0.00001764
Iteration 91/1000 | Loss: 0.00001764
Iteration 92/1000 | Loss: 0.00001764
Iteration 93/1000 | Loss: 0.00001764
Iteration 94/1000 | Loss: 0.00001764
Iteration 95/1000 | Loss: 0.00001764
Iteration 96/1000 | Loss: 0.00001764
Iteration 97/1000 | Loss: 0.00001764
Iteration 98/1000 | Loss: 0.00001763
Iteration 99/1000 | Loss: 0.00001763
Iteration 100/1000 | Loss: 0.00001762
Iteration 101/1000 | Loss: 0.00001762
Iteration 102/1000 | Loss: 0.00001762
Iteration 103/1000 | Loss: 0.00001761
Iteration 104/1000 | Loss: 0.00001761
Iteration 105/1000 | Loss: 0.00001761
Iteration 106/1000 | Loss: 0.00001761
Iteration 107/1000 | Loss: 0.00001761
Iteration 108/1000 | Loss: 0.00001760
Iteration 109/1000 | Loss: 0.00001760
Iteration 110/1000 | Loss: 0.00001760
Iteration 111/1000 | Loss: 0.00001760
Iteration 112/1000 | Loss: 0.00001759
Iteration 113/1000 | Loss: 0.00001759
Iteration 114/1000 | Loss: 0.00001759
Iteration 115/1000 | Loss: 0.00001759
Iteration 116/1000 | Loss: 0.00001759
Iteration 117/1000 | Loss: 0.00001759
Iteration 118/1000 | Loss: 0.00001759
Iteration 119/1000 | Loss: 0.00001759
Iteration 120/1000 | Loss: 0.00001759
Iteration 121/1000 | Loss: 0.00001759
Iteration 122/1000 | Loss: 0.00001759
Iteration 123/1000 | Loss: 0.00001759
Iteration 124/1000 | Loss: 0.00001758
Iteration 125/1000 | Loss: 0.00001758
Iteration 126/1000 | Loss: 0.00001758
Iteration 127/1000 | Loss: 0.00001758
Iteration 128/1000 | Loss: 0.00001758
Iteration 129/1000 | Loss: 0.00001758
Iteration 130/1000 | Loss: 0.00001758
Iteration 131/1000 | Loss: 0.00001758
Iteration 132/1000 | Loss: 0.00001758
Iteration 133/1000 | Loss: 0.00001758
Iteration 134/1000 | Loss: 0.00001758
Iteration 135/1000 | Loss: 0.00001758
Iteration 136/1000 | Loss: 0.00001757
Iteration 137/1000 | Loss: 0.00001757
Iteration 138/1000 | Loss: 0.00001757
Iteration 139/1000 | Loss: 0.00001757
Iteration 140/1000 | Loss: 0.00001757
Iteration 141/1000 | Loss: 0.00001757
Iteration 142/1000 | Loss: 0.00001757
Iteration 143/1000 | Loss: 0.00001756
Iteration 144/1000 | Loss: 0.00001756
Iteration 145/1000 | Loss: 0.00001756
Iteration 146/1000 | Loss: 0.00001756
Iteration 147/1000 | Loss: 0.00001756
Iteration 148/1000 | Loss: 0.00001756
Iteration 149/1000 | Loss: 0.00001756
Iteration 150/1000 | Loss: 0.00001756
Iteration 151/1000 | Loss: 0.00001756
Iteration 152/1000 | Loss: 0.00001756
Iteration 153/1000 | Loss: 0.00001756
Iteration 154/1000 | Loss: 0.00001756
Iteration 155/1000 | Loss: 0.00001756
Iteration 156/1000 | Loss: 0.00001756
Iteration 157/1000 | Loss: 0.00001756
Iteration 158/1000 | Loss: 0.00001756
Iteration 159/1000 | Loss: 0.00001756
Iteration 160/1000 | Loss: 0.00001755
Iteration 161/1000 | Loss: 0.00001755
Iteration 162/1000 | Loss: 0.00001755
Iteration 163/1000 | Loss: 0.00001755
Iteration 164/1000 | Loss: 0.00001755
Iteration 165/1000 | Loss: 0.00001755
Iteration 166/1000 | Loss: 0.00001755
Iteration 167/1000 | Loss: 0.00001755
Iteration 168/1000 | Loss: 0.00001755
Iteration 169/1000 | Loss: 0.00001755
Iteration 170/1000 | Loss: 0.00001755
Iteration 171/1000 | Loss: 0.00001755
Iteration 172/1000 | Loss: 0.00001755
Iteration 173/1000 | Loss: 0.00001755
Iteration 174/1000 | Loss: 0.00001755
Iteration 175/1000 | Loss: 0.00001754
Iteration 176/1000 | Loss: 0.00001754
Iteration 177/1000 | Loss: 0.00001754
Iteration 178/1000 | Loss: 0.00001754
Iteration 179/1000 | Loss: 0.00001754
Iteration 180/1000 | Loss: 0.00001754
Iteration 181/1000 | Loss: 0.00001754
Iteration 182/1000 | Loss: 0.00001754
Iteration 183/1000 | Loss: 0.00001754
Iteration 184/1000 | Loss: 0.00001754
Iteration 185/1000 | Loss: 0.00001754
Iteration 186/1000 | Loss: 0.00001754
Iteration 187/1000 | Loss: 0.00001754
Iteration 188/1000 | Loss: 0.00001754
Iteration 189/1000 | Loss: 0.00001754
Iteration 190/1000 | Loss: 0.00001754
Iteration 191/1000 | Loss: 0.00001754
Iteration 192/1000 | Loss: 0.00001754
Iteration 193/1000 | Loss: 0.00001754
Iteration 194/1000 | Loss: 0.00001754
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 194. Stopping optimization.
Last 5 losses: [1.7539550754008815e-05, 1.7539550754008815e-05, 1.7539550754008815e-05, 1.7539550754008815e-05, 1.7539550754008815e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7539550754008815e-05

Optimization complete. Final v2v error: 3.479670286178589 mm

Highest mean error: 4.433094024658203 mm for frame 205

Lowest mean error: 3.2806313037872314 mm for frame 211

Saving results

Total time: 177.47101879119873
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00498899
Iteration 2/25 | Loss: 0.00142823
Iteration 3/25 | Loss: 0.00127675
Iteration 4/25 | Loss: 0.00126147
Iteration 5/25 | Loss: 0.00125814
Iteration 6/25 | Loss: 0.00125738
Iteration 7/25 | Loss: 0.00125738
Iteration 8/25 | Loss: 0.00125738
Iteration 9/25 | Loss: 0.00125738
Iteration 10/25 | Loss: 0.00125738
Iteration 11/25 | Loss: 0.00125738
Iteration 12/25 | Loss: 0.00125738
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012573824496939778, 0.0012573824496939778, 0.0012573824496939778, 0.0012573824496939778, 0.0012573824496939778]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012573824496939778

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.25536728
Iteration 2/25 | Loss: 0.00215895
Iteration 3/25 | Loss: 0.00215894
Iteration 4/25 | Loss: 0.00215894
Iteration 5/25 | Loss: 0.00215894
Iteration 6/25 | Loss: 0.00215894
Iteration 7/25 | Loss: 0.00215894
Iteration 8/25 | Loss: 0.00215894
Iteration 9/25 | Loss: 0.00215894
Iteration 10/25 | Loss: 0.00215894
Iteration 11/25 | Loss: 0.00215894
Iteration 12/25 | Loss: 0.00215894
Iteration 13/25 | Loss: 0.00215894
Iteration 14/25 | Loss: 0.00215894
Iteration 15/25 | Loss: 0.00215894
Iteration 16/25 | Loss: 0.00215894
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0021589351817965508, 0.0021589351817965508, 0.0021589351817965508, 0.0021589351817965508, 0.0021589351817965508]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0021589351817965508

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00215894
Iteration 2/1000 | Loss: 0.00003147
Iteration 3/1000 | Loss: 0.00001954
Iteration 4/1000 | Loss: 0.00001750
Iteration 5/1000 | Loss: 0.00001656
Iteration 6/1000 | Loss: 0.00001609
Iteration 7/1000 | Loss: 0.00001566
Iteration 8/1000 | Loss: 0.00001526
Iteration 9/1000 | Loss: 0.00001494
Iteration 10/1000 | Loss: 0.00001476
Iteration 11/1000 | Loss: 0.00001474
Iteration 12/1000 | Loss: 0.00001471
Iteration 13/1000 | Loss: 0.00001470
Iteration 14/1000 | Loss: 0.00001463
Iteration 15/1000 | Loss: 0.00001462
Iteration 16/1000 | Loss: 0.00001459
Iteration 17/1000 | Loss: 0.00001458
Iteration 18/1000 | Loss: 0.00001458
Iteration 19/1000 | Loss: 0.00001457
Iteration 20/1000 | Loss: 0.00001456
Iteration 21/1000 | Loss: 0.00001454
Iteration 22/1000 | Loss: 0.00001449
Iteration 23/1000 | Loss: 0.00001449
Iteration 24/1000 | Loss: 0.00001442
Iteration 25/1000 | Loss: 0.00001442
Iteration 26/1000 | Loss: 0.00001440
Iteration 27/1000 | Loss: 0.00001440
Iteration 28/1000 | Loss: 0.00001439
Iteration 29/1000 | Loss: 0.00001438
Iteration 30/1000 | Loss: 0.00001438
Iteration 31/1000 | Loss: 0.00001437
Iteration 32/1000 | Loss: 0.00001437
Iteration 33/1000 | Loss: 0.00001436
Iteration 34/1000 | Loss: 0.00001436
Iteration 35/1000 | Loss: 0.00001434
Iteration 36/1000 | Loss: 0.00001433
Iteration 37/1000 | Loss: 0.00001433
Iteration 38/1000 | Loss: 0.00001433
Iteration 39/1000 | Loss: 0.00001433
Iteration 40/1000 | Loss: 0.00001433
Iteration 41/1000 | Loss: 0.00001433
Iteration 42/1000 | Loss: 0.00001433
Iteration 43/1000 | Loss: 0.00001433
Iteration 44/1000 | Loss: 0.00001433
Iteration 45/1000 | Loss: 0.00001432
Iteration 46/1000 | Loss: 0.00001432
Iteration 47/1000 | Loss: 0.00001432
Iteration 48/1000 | Loss: 0.00001431
Iteration 49/1000 | Loss: 0.00001431
Iteration 50/1000 | Loss: 0.00001431
Iteration 51/1000 | Loss: 0.00001431
Iteration 52/1000 | Loss: 0.00001431
Iteration 53/1000 | Loss: 0.00001431
Iteration 54/1000 | Loss: 0.00001431
Iteration 55/1000 | Loss: 0.00001431
Iteration 56/1000 | Loss: 0.00001430
Iteration 57/1000 | Loss: 0.00001430
Iteration 58/1000 | Loss: 0.00001430
Iteration 59/1000 | Loss: 0.00001430
Iteration 60/1000 | Loss: 0.00001430
Iteration 61/1000 | Loss: 0.00001430
Iteration 62/1000 | Loss: 0.00001430
Iteration 63/1000 | Loss: 0.00001429
Iteration 64/1000 | Loss: 0.00001429
Iteration 65/1000 | Loss: 0.00001429
Iteration 66/1000 | Loss: 0.00001428
Iteration 67/1000 | Loss: 0.00001428
Iteration 68/1000 | Loss: 0.00001428
Iteration 69/1000 | Loss: 0.00001427
Iteration 70/1000 | Loss: 0.00001427
Iteration 71/1000 | Loss: 0.00001427
Iteration 72/1000 | Loss: 0.00001427
Iteration 73/1000 | Loss: 0.00001427
Iteration 74/1000 | Loss: 0.00001426
Iteration 75/1000 | Loss: 0.00001426
Iteration 76/1000 | Loss: 0.00001425
Iteration 77/1000 | Loss: 0.00001425
Iteration 78/1000 | Loss: 0.00001425
Iteration 79/1000 | Loss: 0.00001424
Iteration 80/1000 | Loss: 0.00001424
Iteration 81/1000 | Loss: 0.00001424
Iteration 82/1000 | Loss: 0.00001424
Iteration 83/1000 | Loss: 0.00001423
Iteration 84/1000 | Loss: 0.00001423
Iteration 85/1000 | Loss: 0.00001423
Iteration 86/1000 | Loss: 0.00001423
Iteration 87/1000 | Loss: 0.00001423
Iteration 88/1000 | Loss: 0.00001422
Iteration 89/1000 | Loss: 0.00001422
Iteration 90/1000 | Loss: 0.00001422
Iteration 91/1000 | Loss: 0.00001422
Iteration 92/1000 | Loss: 0.00001422
Iteration 93/1000 | Loss: 0.00001422
Iteration 94/1000 | Loss: 0.00001422
Iteration 95/1000 | Loss: 0.00001422
Iteration 96/1000 | Loss: 0.00001422
Iteration 97/1000 | Loss: 0.00001422
Iteration 98/1000 | Loss: 0.00001422
Iteration 99/1000 | Loss: 0.00001422
Iteration 100/1000 | Loss: 0.00001422
Iteration 101/1000 | Loss: 0.00001422
Iteration 102/1000 | Loss: 0.00001422
Iteration 103/1000 | Loss: 0.00001421
Iteration 104/1000 | Loss: 0.00001421
Iteration 105/1000 | Loss: 0.00001421
Iteration 106/1000 | Loss: 0.00001421
Iteration 107/1000 | Loss: 0.00001421
Iteration 108/1000 | Loss: 0.00001421
Iteration 109/1000 | Loss: 0.00001421
Iteration 110/1000 | Loss: 0.00001421
Iteration 111/1000 | Loss: 0.00001421
Iteration 112/1000 | Loss: 0.00001420
Iteration 113/1000 | Loss: 0.00001420
Iteration 114/1000 | Loss: 0.00001420
Iteration 115/1000 | Loss: 0.00001420
Iteration 116/1000 | Loss: 0.00001420
Iteration 117/1000 | Loss: 0.00001420
Iteration 118/1000 | Loss: 0.00001420
Iteration 119/1000 | Loss: 0.00001420
Iteration 120/1000 | Loss: 0.00001420
Iteration 121/1000 | Loss: 0.00001420
Iteration 122/1000 | Loss: 0.00001420
Iteration 123/1000 | Loss: 0.00001420
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.4201940757629927e-05, 1.4201940757629927e-05, 1.4201940757629927e-05, 1.4201940757629927e-05, 1.4201940757629927e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4201940757629927e-05

Optimization complete. Final v2v error: 3.232670545578003 mm

Highest mean error: 3.7442610263824463 mm for frame 85

Lowest mean error: 2.675339460372925 mm for frame 168

Saving results

Total time: 34.72933340072632
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_35_us_1060/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_35_us_1060/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01070267
Iteration 2/25 | Loss: 0.00193370
Iteration 3/25 | Loss: 0.00163417
Iteration 4/25 | Loss: 0.00154694
Iteration 5/25 | Loss: 0.00144205
Iteration 6/25 | Loss: 0.00144390
Iteration 7/25 | Loss: 0.00134978
Iteration 8/25 | Loss: 0.00127601
Iteration 9/25 | Loss: 0.00125411
Iteration 10/25 | Loss: 0.00128643
Iteration 11/25 | Loss: 0.00126741
Iteration 12/25 | Loss: 0.00124904
Iteration 13/25 | Loss: 0.00123501
Iteration 14/25 | Loss: 0.00122760
Iteration 15/25 | Loss: 0.00122113
Iteration 16/25 | Loss: 0.00121899
Iteration 17/25 | Loss: 0.00121914
Iteration 18/25 | Loss: 0.00121969
Iteration 19/25 | Loss: 0.00121783
Iteration 20/25 | Loss: 0.00122210
Iteration 21/25 | Loss: 0.00121107
Iteration 22/25 | Loss: 0.00120547
Iteration 23/25 | Loss: 0.00120444
Iteration 24/25 | Loss: 0.00120406
Iteration 25/25 | Loss: 0.00120392

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.30026054
Iteration 2/25 | Loss: 0.00280795
Iteration 3/25 | Loss: 0.00280795
Iteration 4/25 | Loss: 0.00280795
Iteration 5/25 | Loss: 0.00280795
Iteration 6/25 | Loss: 0.00280794
Iteration 7/25 | Loss: 0.00280794
Iteration 8/25 | Loss: 0.00280794
Iteration 9/25 | Loss: 0.00280794
Iteration 10/25 | Loss: 0.00280794
Iteration 11/25 | Loss: 0.00280794
Iteration 12/25 | Loss: 0.00280794
Iteration 13/25 | Loss: 0.00280794
Iteration 14/25 | Loss: 0.00280794
Iteration 15/25 | Loss: 0.00280794
Iteration 16/25 | Loss: 0.00280794
Iteration 17/25 | Loss: 0.00280794
Iteration 18/25 | Loss: 0.00280794
Iteration 19/25 | Loss: 0.00280794
Iteration 20/25 | Loss: 0.00280794
Iteration 21/25 | Loss: 0.00280794
Iteration 22/25 | Loss: 0.00280794
Iteration 23/25 | Loss: 0.00280794
Iteration 24/25 | Loss: 0.00280794
Iteration 25/25 | Loss: 0.00280794

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00280794
Iteration 2/1000 | Loss: 0.00006422
Iteration 3/1000 | Loss: 0.00023969
Iteration 4/1000 | Loss: 0.00011574
Iteration 5/1000 | Loss: 0.00017433
Iteration 6/1000 | Loss: 0.00018586
Iteration 7/1000 | Loss: 0.00015194
Iteration 8/1000 | Loss: 0.00022613
Iteration 9/1000 | Loss: 0.00011111
Iteration 10/1000 | Loss: 0.00020481
Iteration 11/1000 | Loss: 0.00008688
Iteration 12/1000 | Loss: 0.00009570
Iteration 13/1000 | Loss: 0.00008655
Iteration 14/1000 | Loss: 0.00020191
Iteration 15/1000 | Loss: 0.00008756
Iteration 16/1000 | Loss: 0.00014159
Iteration 17/1000 | Loss: 0.00007819
Iteration 18/1000 | Loss: 0.00021683
Iteration 19/1000 | Loss: 0.00010297
Iteration 20/1000 | Loss: 0.00020759
Iteration 21/1000 | Loss: 0.00012333
Iteration 22/1000 | Loss: 0.00014541
Iteration 23/1000 | Loss: 0.00014183
Iteration 24/1000 | Loss: 0.00011798
Iteration 25/1000 | Loss: 0.00017865
Iteration 26/1000 | Loss: 0.00026908
Iteration 27/1000 | Loss: 0.00012844
Iteration 28/1000 | Loss: 0.00017597
Iteration 29/1000 | Loss: 0.00027715
Iteration 30/1000 | Loss: 0.00005845
Iteration 31/1000 | Loss: 0.00005245
Iteration 32/1000 | Loss: 0.00002441
Iteration 33/1000 | Loss: 0.00001846
Iteration 34/1000 | Loss: 0.00001572
Iteration 35/1000 | Loss: 0.00001387
Iteration 36/1000 | Loss: 0.00001282
Iteration 37/1000 | Loss: 0.00001218
Iteration 38/1000 | Loss: 0.00001182
Iteration 39/1000 | Loss: 0.00001153
Iteration 40/1000 | Loss: 0.00001132
Iteration 41/1000 | Loss: 0.00001119
Iteration 42/1000 | Loss: 0.00001119
Iteration 43/1000 | Loss: 0.00001118
Iteration 44/1000 | Loss: 0.00001118
Iteration 45/1000 | Loss: 0.00001116
Iteration 46/1000 | Loss: 0.00001115
Iteration 47/1000 | Loss: 0.00001103
Iteration 48/1000 | Loss: 0.00001101
Iteration 49/1000 | Loss: 0.00001097
Iteration 50/1000 | Loss: 0.00001084
Iteration 51/1000 | Loss: 0.00001084
Iteration 52/1000 | Loss: 0.00001083
Iteration 53/1000 | Loss: 0.00001083
Iteration 54/1000 | Loss: 0.00001082
Iteration 55/1000 | Loss: 0.00001082
Iteration 56/1000 | Loss: 0.00001082
Iteration 57/1000 | Loss: 0.00001082
Iteration 58/1000 | Loss: 0.00001082
Iteration 59/1000 | Loss: 0.00001081
Iteration 60/1000 | Loss: 0.00001080
Iteration 61/1000 | Loss: 0.00001080
Iteration 62/1000 | Loss: 0.00001080
Iteration 63/1000 | Loss: 0.00001080
Iteration 64/1000 | Loss: 0.00001079
Iteration 65/1000 | Loss: 0.00001079
Iteration 66/1000 | Loss: 0.00001078
Iteration 67/1000 | Loss: 0.00001078
Iteration 68/1000 | Loss: 0.00001078
Iteration 69/1000 | Loss: 0.00001078
Iteration 70/1000 | Loss: 0.00001077
Iteration 71/1000 | Loss: 0.00001077
Iteration 72/1000 | Loss: 0.00001077
Iteration 73/1000 | Loss: 0.00001077
Iteration 74/1000 | Loss: 0.00001077
Iteration 75/1000 | Loss: 0.00001077
Iteration 76/1000 | Loss: 0.00001077
Iteration 77/1000 | Loss: 0.00001077
Iteration 78/1000 | Loss: 0.00001076
Iteration 79/1000 | Loss: 0.00001076
Iteration 80/1000 | Loss: 0.00001075
Iteration 81/1000 | Loss: 0.00001075
Iteration 82/1000 | Loss: 0.00001074
Iteration 83/1000 | Loss: 0.00001074
Iteration 84/1000 | Loss: 0.00001073
Iteration 85/1000 | Loss: 0.00001073
Iteration 86/1000 | Loss: 0.00001073
Iteration 87/1000 | Loss: 0.00001073
Iteration 88/1000 | Loss: 0.00001073
Iteration 89/1000 | Loss: 0.00001072
Iteration 90/1000 | Loss: 0.00001072
Iteration 91/1000 | Loss: 0.00001072
Iteration 92/1000 | Loss: 0.00001071
Iteration 93/1000 | Loss: 0.00001071
Iteration 94/1000 | Loss: 0.00001070
Iteration 95/1000 | Loss: 0.00001070
Iteration 96/1000 | Loss: 0.00001070
Iteration 97/1000 | Loss: 0.00001070
Iteration 98/1000 | Loss: 0.00001070
Iteration 99/1000 | Loss: 0.00001070
Iteration 100/1000 | Loss: 0.00001070
Iteration 101/1000 | Loss: 0.00001069
Iteration 102/1000 | Loss: 0.00001069
Iteration 103/1000 | Loss: 0.00001069
Iteration 104/1000 | Loss: 0.00001069
Iteration 105/1000 | Loss: 0.00001068
Iteration 106/1000 | Loss: 0.00001068
Iteration 107/1000 | Loss: 0.00001068
Iteration 108/1000 | Loss: 0.00001068
Iteration 109/1000 | Loss: 0.00001068
Iteration 110/1000 | Loss: 0.00001067
Iteration 111/1000 | Loss: 0.00001067
Iteration 112/1000 | Loss: 0.00001067
Iteration 113/1000 | Loss: 0.00001067
Iteration 114/1000 | Loss: 0.00001067
Iteration 115/1000 | Loss: 0.00001067
Iteration 116/1000 | Loss: 0.00001067
Iteration 117/1000 | Loss: 0.00001067
Iteration 118/1000 | Loss: 0.00001067
Iteration 119/1000 | Loss: 0.00001067
Iteration 120/1000 | Loss: 0.00001067
Iteration 121/1000 | Loss: 0.00001066
Iteration 122/1000 | Loss: 0.00001066
Iteration 123/1000 | Loss: 0.00001066
Iteration 124/1000 | Loss: 0.00001066
Iteration 125/1000 | Loss: 0.00001066
Iteration 126/1000 | Loss: 0.00001066
Iteration 127/1000 | Loss: 0.00001066
Iteration 128/1000 | Loss: 0.00001066
Iteration 129/1000 | Loss: 0.00001066
Iteration 130/1000 | Loss: 0.00001066
Iteration 131/1000 | Loss: 0.00001065
Iteration 132/1000 | Loss: 0.00001065
Iteration 133/1000 | Loss: 0.00001065
Iteration 134/1000 | Loss: 0.00001065
Iteration 135/1000 | Loss: 0.00001065
Iteration 136/1000 | Loss: 0.00001064
Iteration 137/1000 | Loss: 0.00001064
Iteration 138/1000 | Loss: 0.00001064
Iteration 139/1000 | Loss: 0.00001064
Iteration 140/1000 | Loss: 0.00001064
Iteration 141/1000 | Loss: 0.00001064
Iteration 142/1000 | Loss: 0.00001064
Iteration 143/1000 | Loss: 0.00001064
Iteration 144/1000 | Loss: 0.00001064
Iteration 145/1000 | Loss: 0.00001064
Iteration 146/1000 | Loss: 0.00001064
Iteration 147/1000 | Loss: 0.00001064
Iteration 148/1000 | Loss: 0.00001064
Iteration 149/1000 | Loss: 0.00001064
Iteration 150/1000 | Loss: 0.00001064
Iteration 151/1000 | Loss: 0.00001064
Iteration 152/1000 | Loss: 0.00001064
Iteration 153/1000 | Loss: 0.00001064
Iteration 154/1000 | Loss: 0.00001064
Iteration 155/1000 | Loss: 0.00001064
Iteration 156/1000 | Loss: 0.00001064
Iteration 157/1000 | Loss: 0.00001064
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 157. Stopping optimization.
Last 5 losses: [1.0641869266692083e-05, 1.0641869266692083e-05, 1.0641869266692083e-05, 1.0641869266692083e-05, 1.0641869266692083e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0641869266692083e-05

Optimization complete. Final v2v error: 2.746303081512451 mm

Highest mean error: 4.878212928771973 mm for frame 72

Lowest mean error: 2.3296008110046387 mm for frame 6

Saving results

Total time: 114.01409006118774
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_30_us_1269/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00869132
Iteration 2/25 | Loss: 0.00124695
Iteration 3/25 | Loss: 0.00111063
Iteration 4/25 | Loss: 0.00109735
Iteration 5/25 | Loss: 0.00109460
Iteration 6/25 | Loss: 0.00109438
Iteration 7/25 | Loss: 0.00109438
Iteration 8/25 | Loss: 0.00109438
Iteration 9/25 | Loss: 0.00109438
Iteration 10/25 | Loss: 0.00109438
Iteration 11/25 | Loss: 0.00109438
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0010943807428702712, 0.0010943807428702712, 0.0010943807428702712, 0.0010943807428702712, 0.0010943807428702712]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010943807428702712

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41158092
Iteration 2/25 | Loss: 0.00123933
Iteration 3/25 | Loss: 0.00123933
Iteration 4/25 | Loss: 0.00123932
Iteration 5/25 | Loss: 0.00123932
Iteration 6/25 | Loss: 0.00123932
Iteration 7/25 | Loss: 0.00123932
Iteration 8/25 | Loss: 0.00123932
Iteration 9/25 | Loss: 0.00123932
Iteration 10/25 | Loss: 0.00123932
Iteration 11/25 | Loss: 0.00123932
Iteration 12/25 | Loss: 0.00123932
Iteration 13/25 | Loss: 0.00123932
Iteration 14/25 | Loss: 0.00123932
Iteration 15/25 | Loss: 0.00123932
Iteration 16/25 | Loss: 0.00123932
Iteration 17/25 | Loss: 0.00123932
Iteration 18/25 | Loss: 0.00123932
Iteration 19/25 | Loss: 0.00123932
Iteration 20/25 | Loss: 0.00123932
Iteration 21/25 | Loss: 0.00123932
Iteration 22/25 | Loss: 0.00123932
Iteration 23/25 | Loss: 0.00123932
Iteration 24/25 | Loss: 0.00123932
Iteration 25/25 | Loss: 0.00123932

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00123932
Iteration 2/1000 | Loss: 0.00003770
Iteration 3/1000 | Loss: 0.00002113
Iteration 4/1000 | Loss: 0.00001673
Iteration 5/1000 | Loss: 0.00001405
Iteration 6/1000 | Loss: 0.00001327
Iteration 7/1000 | Loss: 0.00001285
Iteration 8/1000 | Loss: 0.00001257
Iteration 9/1000 | Loss: 0.00001250
Iteration 10/1000 | Loss: 0.00001230
Iteration 11/1000 | Loss: 0.00001223
Iteration 12/1000 | Loss: 0.00001214
Iteration 13/1000 | Loss: 0.00001210
Iteration 14/1000 | Loss: 0.00001208
Iteration 15/1000 | Loss: 0.00001202
Iteration 16/1000 | Loss: 0.00001199
Iteration 17/1000 | Loss: 0.00001199
Iteration 18/1000 | Loss: 0.00001198
Iteration 19/1000 | Loss: 0.00001198
Iteration 20/1000 | Loss: 0.00001198
Iteration 21/1000 | Loss: 0.00001195
Iteration 22/1000 | Loss: 0.00001195
Iteration 23/1000 | Loss: 0.00001195
Iteration 24/1000 | Loss: 0.00001194
Iteration 25/1000 | Loss: 0.00001193
Iteration 26/1000 | Loss: 0.00001193
Iteration 27/1000 | Loss: 0.00001192
Iteration 28/1000 | Loss: 0.00001192
Iteration 29/1000 | Loss: 0.00001192
Iteration 30/1000 | Loss: 0.00001192
Iteration 31/1000 | Loss: 0.00001192
Iteration 32/1000 | Loss: 0.00001192
Iteration 33/1000 | Loss: 0.00001192
Iteration 34/1000 | Loss: 0.00001191
Iteration 35/1000 | Loss: 0.00001191
Iteration 36/1000 | Loss: 0.00001191
Iteration 37/1000 | Loss: 0.00001191
Iteration 38/1000 | Loss: 0.00001191
Iteration 39/1000 | Loss: 0.00001191
Iteration 40/1000 | Loss: 0.00001191
Iteration 41/1000 | Loss: 0.00001191
Iteration 42/1000 | Loss: 0.00001191
Iteration 43/1000 | Loss: 0.00001191
Iteration 44/1000 | Loss: 0.00001191
Iteration 45/1000 | Loss: 0.00001191
Iteration 46/1000 | Loss: 0.00001190
Iteration 47/1000 | Loss: 0.00001190
Iteration 48/1000 | Loss: 0.00001190
Iteration 49/1000 | Loss: 0.00001190
Iteration 50/1000 | Loss: 0.00001190
Iteration 51/1000 | Loss: 0.00001190
Iteration 52/1000 | Loss: 0.00001190
Iteration 53/1000 | Loss: 0.00001189
Iteration 54/1000 | Loss: 0.00001189
Iteration 55/1000 | Loss: 0.00001189
Iteration 56/1000 | Loss: 0.00001188
Iteration 57/1000 | Loss: 0.00001188
Iteration 58/1000 | Loss: 0.00001188
Iteration 59/1000 | Loss: 0.00001187
Iteration 60/1000 | Loss: 0.00001187
Iteration 61/1000 | Loss: 0.00001187
Iteration 62/1000 | Loss: 0.00001186
Iteration 63/1000 | Loss: 0.00001186
Iteration 64/1000 | Loss: 0.00001186
Iteration 65/1000 | Loss: 0.00001185
Iteration 66/1000 | Loss: 0.00001185
Iteration 67/1000 | Loss: 0.00001185
Iteration 68/1000 | Loss: 0.00001185
Iteration 69/1000 | Loss: 0.00001185
Iteration 70/1000 | Loss: 0.00001185
Iteration 71/1000 | Loss: 0.00001185
Iteration 72/1000 | Loss: 0.00001185
Iteration 73/1000 | Loss: 0.00001185
Iteration 74/1000 | Loss: 0.00001185
Iteration 75/1000 | Loss: 0.00001185
Iteration 76/1000 | Loss: 0.00001185
Iteration 77/1000 | Loss: 0.00001185
Iteration 78/1000 | Loss: 0.00001184
Iteration 79/1000 | Loss: 0.00001184
Iteration 80/1000 | Loss: 0.00001184
Iteration 81/1000 | Loss: 0.00001184
Iteration 82/1000 | Loss: 0.00001184
Iteration 83/1000 | Loss: 0.00001184
Iteration 84/1000 | Loss: 0.00001184
Iteration 85/1000 | Loss: 0.00001184
Iteration 86/1000 | Loss: 0.00001184
Iteration 87/1000 | Loss: 0.00001184
Iteration 88/1000 | Loss: 0.00001184
Iteration 89/1000 | Loss: 0.00001184
Iteration 90/1000 | Loss: 0.00001183
Iteration 91/1000 | Loss: 0.00001183
Iteration 92/1000 | Loss: 0.00001183
Iteration 93/1000 | Loss: 0.00001183
Iteration 94/1000 | Loss: 0.00001183
Iteration 95/1000 | Loss: 0.00001183
Iteration 96/1000 | Loss: 0.00001183
Iteration 97/1000 | Loss: 0.00001182
Iteration 98/1000 | Loss: 0.00001182
Iteration 99/1000 | Loss: 0.00001182
Iteration 100/1000 | Loss: 0.00001182
Iteration 101/1000 | Loss: 0.00001182
Iteration 102/1000 | Loss: 0.00001182
Iteration 103/1000 | Loss: 0.00001182
Iteration 104/1000 | Loss: 0.00001182
Iteration 105/1000 | Loss: 0.00001182
Iteration 106/1000 | Loss: 0.00001182
Iteration 107/1000 | Loss: 0.00001182
Iteration 108/1000 | Loss: 0.00001182
Iteration 109/1000 | Loss: 0.00001182
Iteration 110/1000 | Loss: 0.00001182
Iteration 111/1000 | Loss: 0.00001182
Iteration 112/1000 | Loss: 0.00001182
Iteration 113/1000 | Loss: 0.00001182
Iteration 114/1000 | Loss: 0.00001182
Iteration 115/1000 | Loss: 0.00001182
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 115. Stopping optimization.
Last 5 losses: [1.1817699487437494e-05, 1.1817699487437494e-05, 1.1817699487437494e-05, 1.1817699487437494e-05, 1.1817699487437494e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1817699487437494e-05

Optimization complete. Final v2v error: 2.883486270904541 mm

Highest mean error: 3.520704746246338 mm for frame 111

Lowest mean error: 2.5898544788360596 mm for frame 2

Saving results

Total time: 31.130256175994873
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_30_us_1269/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00889726
Iteration 2/25 | Loss: 0.00171923
Iteration 3/25 | Loss: 0.00133675
Iteration 4/25 | Loss: 0.00131498
Iteration 5/25 | Loss: 0.00131351
Iteration 6/25 | Loss: 0.00131351
Iteration 7/25 | Loss: 0.00131351
Iteration 8/25 | Loss: 0.00131351
Iteration 9/25 | Loss: 0.00131351
Iteration 10/25 | Loss: 0.00131351
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0013135143090039492, 0.0013135143090039492, 0.0013135143090039492, 0.0013135143090039492, 0.0013135143090039492]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0013135143090039492

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.13465333
Iteration 2/25 | Loss: 0.00080953
Iteration 3/25 | Loss: 0.00080953
Iteration 4/25 | Loss: 0.00080953
Iteration 5/25 | Loss: 0.00080953
Iteration 6/25 | Loss: 0.00080953
Iteration 7/25 | Loss: 0.00080953
Iteration 8/25 | Loss: 0.00080953
Iteration 9/25 | Loss: 0.00080953
Iteration 10/25 | Loss: 0.00080953
Iteration 11/25 | Loss: 0.00080953
Iteration 12/25 | Loss: 0.00080953
Iteration 13/25 | Loss: 0.00080953
Iteration 14/25 | Loss: 0.00080953
Iteration 15/25 | Loss: 0.00080953
Iteration 16/25 | Loss: 0.00080953
Iteration 17/25 | Loss: 0.00080953
Iteration 18/25 | Loss: 0.00080953
Iteration 19/25 | Loss: 0.00080953
Iteration 20/25 | Loss: 0.00080953
Iteration 21/25 | Loss: 0.00080953
Iteration 22/25 | Loss: 0.00080953
Iteration 23/25 | Loss: 0.00080953
Iteration 24/25 | Loss: 0.00080953
Iteration 25/25 | Loss: 0.00080953

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00080953
Iteration 2/1000 | Loss: 0.00005332
Iteration 3/1000 | Loss: 0.00003002
Iteration 4/1000 | Loss: 0.00002479
Iteration 5/1000 | Loss: 0.00002175
Iteration 6/1000 | Loss: 0.00002054
Iteration 7/1000 | Loss: 0.00001974
Iteration 8/1000 | Loss: 0.00001936
Iteration 9/1000 | Loss: 0.00001904
Iteration 10/1000 | Loss: 0.00001878
Iteration 11/1000 | Loss: 0.00001856
Iteration 12/1000 | Loss: 0.00001841
Iteration 13/1000 | Loss: 0.00001822
Iteration 14/1000 | Loss: 0.00001809
Iteration 15/1000 | Loss: 0.00001806
Iteration 16/1000 | Loss: 0.00001785
Iteration 17/1000 | Loss: 0.00001777
Iteration 18/1000 | Loss: 0.00001770
Iteration 19/1000 | Loss: 0.00001759
Iteration 20/1000 | Loss: 0.00001759
Iteration 21/1000 | Loss: 0.00001758
Iteration 22/1000 | Loss: 0.00001757
Iteration 23/1000 | Loss: 0.00001757
Iteration 24/1000 | Loss: 0.00001757
Iteration 25/1000 | Loss: 0.00001756
Iteration 26/1000 | Loss: 0.00001755
Iteration 27/1000 | Loss: 0.00001754
Iteration 28/1000 | Loss: 0.00001753
Iteration 29/1000 | Loss: 0.00001753
Iteration 30/1000 | Loss: 0.00001753
Iteration 31/1000 | Loss: 0.00001753
Iteration 32/1000 | Loss: 0.00001752
Iteration 33/1000 | Loss: 0.00001752
Iteration 34/1000 | Loss: 0.00001752
Iteration 35/1000 | Loss: 0.00001752
Iteration 36/1000 | Loss: 0.00001752
Iteration 37/1000 | Loss: 0.00001752
Iteration 38/1000 | Loss: 0.00001751
Iteration 39/1000 | Loss: 0.00001751
Iteration 40/1000 | Loss: 0.00001751
Iteration 41/1000 | Loss: 0.00001750
Iteration 42/1000 | Loss: 0.00001749
Iteration 43/1000 | Loss: 0.00001744
Iteration 44/1000 | Loss: 0.00001743
Iteration 45/1000 | Loss: 0.00001739
Iteration 46/1000 | Loss: 0.00001738
Iteration 47/1000 | Loss: 0.00001737
Iteration 48/1000 | Loss: 0.00001735
Iteration 49/1000 | Loss: 0.00001735
Iteration 50/1000 | Loss: 0.00001735
Iteration 51/1000 | Loss: 0.00001734
Iteration 52/1000 | Loss: 0.00001734
Iteration 53/1000 | Loss: 0.00001734
Iteration 54/1000 | Loss: 0.00001734
Iteration 55/1000 | Loss: 0.00001734
Iteration 56/1000 | Loss: 0.00001733
Iteration 57/1000 | Loss: 0.00001733
Iteration 58/1000 | Loss: 0.00001733
Iteration 59/1000 | Loss: 0.00001732
Iteration 60/1000 | Loss: 0.00001732
Iteration 61/1000 | Loss: 0.00001732
Iteration 62/1000 | Loss: 0.00001732
Iteration 63/1000 | Loss: 0.00001731
Iteration 64/1000 | Loss: 0.00001731
Iteration 65/1000 | Loss: 0.00001731
Iteration 66/1000 | Loss: 0.00001731
Iteration 67/1000 | Loss: 0.00001731
Iteration 68/1000 | Loss: 0.00001731
Iteration 69/1000 | Loss: 0.00001731
Iteration 70/1000 | Loss: 0.00001731
Iteration 71/1000 | Loss: 0.00001731
Iteration 72/1000 | Loss: 0.00001731
Iteration 73/1000 | Loss: 0.00001731
Iteration 74/1000 | Loss: 0.00001730
Iteration 75/1000 | Loss: 0.00001730
Iteration 76/1000 | Loss: 0.00001730
Iteration 77/1000 | Loss: 0.00001730
Iteration 78/1000 | Loss: 0.00001730
Iteration 79/1000 | Loss: 0.00001729
Iteration 80/1000 | Loss: 0.00001729
Iteration 81/1000 | Loss: 0.00001729
Iteration 82/1000 | Loss: 0.00001729
Iteration 83/1000 | Loss: 0.00001729
Iteration 84/1000 | Loss: 0.00001729
Iteration 85/1000 | Loss: 0.00001729
Iteration 86/1000 | Loss: 0.00001729
Iteration 87/1000 | Loss: 0.00001729
Iteration 88/1000 | Loss: 0.00001729
Iteration 89/1000 | Loss: 0.00001728
Iteration 90/1000 | Loss: 0.00001728
Iteration 91/1000 | Loss: 0.00001728
Iteration 92/1000 | Loss: 0.00001728
Iteration 93/1000 | Loss: 0.00001728
Iteration 94/1000 | Loss: 0.00001728
Iteration 95/1000 | Loss: 0.00001728
Iteration 96/1000 | Loss: 0.00001728
Iteration 97/1000 | Loss: 0.00001727
Iteration 98/1000 | Loss: 0.00001727
Iteration 99/1000 | Loss: 0.00001727
Iteration 100/1000 | Loss: 0.00001727
Iteration 101/1000 | Loss: 0.00001727
Iteration 102/1000 | Loss: 0.00001727
Iteration 103/1000 | Loss: 0.00001727
Iteration 104/1000 | Loss: 0.00001727
Iteration 105/1000 | Loss: 0.00001727
Iteration 106/1000 | Loss: 0.00001727
Iteration 107/1000 | Loss: 0.00001727
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 107. Stopping optimization.
Last 5 losses: [1.727399830997456e-05, 1.727399830997456e-05, 1.727399830997456e-05, 1.727399830997456e-05, 1.727399830997456e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.727399830997456e-05

Optimization complete. Final v2v error: 3.5312576293945312 mm

Highest mean error: 3.7071757316589355 mm for frame 125

Lowest mean error: 3.3382763862609863 mm for frame 38

Saving results

Total time: 36.9081768989563
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_30_us_1269/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01049083
Iteration 2/25 | Loss: 0.00219529
Iteration 3/25 | Loss: 0.00171067
Iteration 4/25 | Loss: 0.00158316
Iteration 5/25 | Loss: 0.00151862
Iteration 6/25 | Loss: 0.00143935
Iteration 7/25 | Loss: 0.00126288
Iteration 8/25 | Loss: 0.00121185
Iteration 9/25 | Loss: 0.00118810
Iteration 10/25 | Loss: 0.00119793
Iteration 11/25 | Loss: 0.00117436
Iteration 12/25 | Loss: 0.00117236
Iteration 13/25 | Loss: 0.00116960
Iteration 14/25 | Loss: 0.00116708
Iteration 15/25 | Loss: 0.00116179
Iteration 16/25 | Loss: 0.00115453
Iteration 17/25 | Loss: 0.00114698
Iteration 18/25 | Loss: 0.00115828
Iteration 19/25 | Loss: 0.00115612
Iteration 20/25 | Loss: 0.00115916
Iteration 21/25 | Loss: 0.00114544
Iteration 22/25 | Loss: 0.00113685
Iteration 23/25 | Loss: 0.00113465
Iteration 24/25 | Loss: 0.00113944
Iteration 25/25 | Loss: 0.00113661

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.33512974
Iteration 2/25 | Loss: 0.00136089
Iteration 3/25 | Loss: 0.00136089
Iteration 4/25 | Loss: 0.00136089
Iteration 5/25 | Loss: 0.00136089
Iteration 6/25 | Loss: 0.00136089
Iteration 7/25 | Loss: 0.00136089
Iteration 8/25 | Loss: 0.00136089
Iteration 9/25 | Loss: 0.00136089
Iteration 10/25 | Loss: 0.00136089
Iteration 11/25 | Loss: 0.00136089
Iteration 12/25 | Loss: 0.00136089
Iteration 13/25 | Loss: 0.00136089
Iteration 14/25 | Loss: 0.00136089
Iteration 15/25 | Loss: 0.00136089
Iteration 16/25 | Loss: 0.00136089
Iteration 17/25 | Loss: 0.00136089
Iteration 18/25 | Loss: 0.00136089
Iteration 19/25 | Loss: 0.00136089
Iteration 20/25 | Loss: 0.00136089
Iteration 21/25 | Loss: 0.00136089
Iteration 22/25 | Loss: 0.00136089
Iteration 23/25 | Loss: 0.00136089
Iteration 24/25 | Loss: 0.00136089
Iteration 25/25 | Loss: 0.00136089

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00136089
Iteration 2/1000 | Loss: 0.00014609
Iteration 3/1000 | Loss: 0.00005329
Iteration 4/1000 | Loss: 0.00009913
Iteration 5/1000 | Loss: 0.00012342
Iteration 6/1000 | Loss: 0.00004241
Iteration 7/1000 | Loss: 0.00005487
Iteration 8/1000 | Loss: 0.00005390
Iteration 9/1000 | Loss: 0.00015228
Iteration 10/1000 | Loss: 0.00019248
Iteration 11/1000 | Loss: 0.00015659
Iteration 12/1000 | Loss: 0.00017933
Iteration 13/1000 | Loss: 0.00005246
Iteration 14/1000 | Loss: 0.00005304
Iteration 15/1000 | Loss: 0.00016992
Iteration 16/1000 | Loss: 0.00019917
Iteration 17/1000 | Loss: 0.00040117
Iteration 18/1000 | Loss: 0.00005811
Iteration 19/1000 | Loss: 0.00018973
Iteration 20/1000 | Loss: 0.00020572
Iteration 21/1000 | Loss: 0.00003493
Iteration 22/1000 | Loss: 0.00026350
Iteration 23/1000 | Loss: 0.00027282
Iteration 24/1000 | Loss: 0.00025959
Iteration 25/1000 | Loss: 0.00034419
Iteration 26/1000 | Loss: 0.00003044
Iteration 27/1000 | Loss: 0.00002160
Iteration 28/1000 | Loss: 0.00002025
Iteration 29/1000 | Loss: 0.00001932
Iteration 30/1000 | Loss: 0.00001854
Iteration 31/1000 | Loss: 0.00001811
Iteration 32/1000 | Loss: 0.00001769
Iteration 33/1000 | Loss: 0.00052563
Iteration 34/1000 | Loss: 0.00002198
Iteration 35/1000 | Loss: 0.00001803
Iteration 36/1000 | Loss: 0.00001702
Iteration 37/1000 | Loss: 0.00001608
Iteration 38/1000 | Loss: 0.00001532
Iteration 39/1000 | Loss: 0.00001497
Iteration 40/1000 | Loss: 0.00001479
Iteration 41/1000 | Loss: 0.00001471
Iteration 42/1000 | Loss: 0.00001471
Iteration 43/1000 | Loss: 0.00001470
Iteration 44/1000 | Loss: 0.00001470
Iteration 45/1000 | Loss: 0.00001469
Iteration 46/1000 | Loss: 0.00001468
Iteration 47/1000 | Loss: 0.00001468
Iteration 48/1000 | Loss: 0.00001466
Iteration 49/1000 | Loss: 0.00001465
Iteration 50/1000 | Loss: 0.00001465
Iteration 51/1000 | Loss: 0.00001460
Iteration 52/1000 | Loss: 0.00001456
Iteration 53/1000 | Loss: 0.00001455
Iteration 54/1000 | Loss: 0.00001449
Iteration 55/1000 | Loss: 0.00001447
Iteration 56/1000 | Loss: 0.00001442
Iteration 57/1000 | Loss: 0.00001436
Iteration 58/1000 | Loss: 0.00001431
Iteration 59/1000 | Loss: 0.00001431
Iteration 60/1000 | Loss: 0.00001431
Iteration 61/1000 | Loss: 0.00001431
Iteration 62/1000 | Loss: 0.00001431
Iteration 63/1000 | Loss: 0.00001429
Iteration 64/1000 | Loss: 0.00001428
Iteration 65/1000 | Loss: 0.00001428
Iteration 66/1000 | Loss: 0.00001428
Iteration 67/1000 | Loss: 0.00001427
Iteration 68/1000 | Loss: 0.00001427
Iteration 69/1000 | Loss: 0.00001427
Iteration 70/1000 | Loss: 0.00001426
Iteration 71/1000 | Loss: 0.00001426
Iteration 72/1000 | Loss: 0.00001426
Iteration 73/1000 | Loss: 0.00001425
Iteration 74/1000 | Loss: 0.00001425
Iteration 75/1000 | Loss: 0.00001425
Iteration 76/1000 | Loss: 0.00001424
Iteration 77/1000 | Loss: 0.00001424
Iteration 78/1000 | Loss: 0.00001423
Iteration 79/1000 | Loss: 0.00001423
Iteration 80/1000 | Loss: 0.00001423
Iteration 81/1000 | Loss: 0.00001422
Iteration 82/1000 | Loss: 0.00001422
Iteration 83/1000 | Loss: 0.00001422
Iteration 84/1000 | Loss: 0.00001422
Iteration 85/1000 | Loss: 0.00001422
Iteration 86/1000 | Loss: 0.00001422
Iteration 87/1000 | Loss: 0.00001422
Iteration 88/1000 | Loss: 0.00001422
Iteration 89/1000 | Loss: 0.00001422
Iteration 90/1000 | Loss: 0.00001422
Iteration 91/1000 | Loss: 0.00001422
Iteration 92/1000 | Loss: 0.00001422
Iteration 93/1000 | Loss: 0.00001421
Iteration 94/1000 | Loss: 0.00001421
Iteration 95/1000 | Loss: 0.00001421
Iteration 96/1000 | Loss: 0.00001421
Iteration 97/1000 | Loss: 0.00001421
Iteration 98/1000 | Loss: 0.00001421
Iteration 99/1000 | Loss: 0.00001421
Iteration 100/1000 | Loss: 0.00001421
Iteration 101/1000 | Loss: 0.00001421
Iteration 102/1000 | Loss: 0.00001421
Iteration 103/1000 | Loss: 0.00001420
Iteration 104/1000 | Loss: 0.00001419
Iteration 105/1000 | Loss: 0.00001418
Iteration 106/1000 | Loss: 0.00001418
Iteration 107/1000 | Loss: 0.00001417
Iteration 108/1000 | Loss: 0.00001417
Iteration 109/1000 | Loss: 0.00001416
Iteration 110/1000 | Loss: 0.00001416
Iteration 111/1000 | Loss: 0.00001416
Iteration 112/1000 | Loss: 0.00001416
Iteration 113/1000 | Loss: 0.00001416
Iteration 114/1000 | Loss: 0.00001415
Iteration 115/1000 | Loss: 0.00001415
Iteration 116/1000 | Loss: 0.00001415
Iteration 117/1000 | Loss: 0.00001415
Iteration 118/1000 | Loss: 0.00001415
Iteration 119/1000 | Loss: 0.00001415
Iteration 120/1000 | Loss: 0.00001414
Iteration 121/1000 | Loss: 0.00001414
Iteration 122/1000 | Loss: 0.00001414
Iteration 123/1000 | Loss: 0.00001414
Iteration 124/1000 | Loss: 0.00001414
Iteration 125/1000 | Loss: 0.00001414
Iteration 126/1000 | Loss: 0.00001414
Iteration 127/1000 | Loss: 0.00001414
Iteration 128/1000 | Loss: 0.00001414
Iteration 129/1000 | Loss: 0.00001414
Iteration 130/1000 | Loss: 0.00001414
Iteration 131/1000 | Loss: 0.00001413
Iteration 132/1000 | Loss: 0.00001413
Iteration 133/1000 | Loss: 0.00001413
Iteration 134/1000 | Loss: 0.00001413
Iteration 135/1000 | Loss: 0.00001413
Iteration 136/1000 | Loss: 0.00001413
Iteration 137/1000 | Loss: 0.00001413
Iteration 138/1000 | Loss: 0.00001413
Iteration 139/1000 | Loss: 0.00001413
Iteration 140/1000 | Loss: 0.00001413
Iteration 141/1000 | Loss: 0.00001412
Iteration 142/1000 | Loss: 0.00001412
Iteration 143/1000 | Loss: 0.00001412
Iteration 144/1000 | Loss: 0.00001412
Iteration 145/1000 | Loss: 0.00001412
Iteration 146/1000 | Loss: 0.00001412
Iteration 147/1000 | Loss: 0.00001412
Iteration 148/1000 | Loss: 0.00001412
Iteration 149/1000 | Loss: 0.00001412
Iteration 150/1000 | Loss: 0.00001412
Iteration 151/1000 | Loss: 0.00001412
Iteration 152/1000 | Loss: 0.00001412
Iteration 153/1000 | Loss: 0.00001411
Iteration 154/1000 | Loss: 0.00001411
Iteration 155/1000 | Loss: 0.00001411
Iteration 156/1000 | Loss: 0.00001411
Iteration 157/1000 | Loss: 0.00001411
Iteration 158/1000 | Loss: 0.00001411
Iteration 159/1000 | Loss: 0.00001411
Iteration 160/1000 | Loss: 0.00001411
Iteration 161/1000 | Loss: 0.00001411
Iteration 162/1000 | Loss: 0.00001411
Iteration 163/1000 | Loss: 0.00001411
Iteration 164/1000 | Loss: 0.00001411
Iteration 165/1000 | Loss: 0.00001411
Iteration 166/1000 | Loss: 0.00001411
Iteration 167/1000 | Loss: 0.00001411
Iteration 168/1000 | Loss: 0.00001411
Iteration 169/1000 | Loss: 0.00001411
Iteration 170/1000 | Loss: 0.00001411
Iteration 171/1000 | Loss: 0.00001411
Iteration 172/1000 | Loss: 0.00001411
Iteration 173/1000 | Loss: 0.00001411
Iteration 174/1000 | Loss: 0.00001410
Iteration 175/1000 | Loss: 0.00001410
Iteration 176/1000 | Loss: 0.00001410
Iteration 177/1000 | Loss: 0.00001410
Iteration 178/1000 | Loss: 0.00001410
Iteration 179/1000 | Loss: 0.00001410
Iteration 180/1000 | Loss: 0.00001410
Iteration 181/1000 | Loss: 0.00001410
Iteration 182/1000 | Loss: 0.00001410
Iteration 183/1000 | Loss: 0.00001410
Iteration 184/1000 | Loss: 0.00001410
Iteration 185/1000 | Loss: 0.00001410
Iteration 186/1000 | Loss: 0.00001410
Iteration 187/1000 | Loss: 0.00001410
Iteration 188/1000 | Loss: 0.00001410
Iteration 189/1000 | Loss: 0.00001410
Iteration 190/1000 | Loss: 0.00001409
Iteration 191/1000 | Loss: 0.00001409
Iteration 192/1000 | Loss: 0.00001409
Iteration 193/1000 | Loss: 0.00001409
Iteration 194/1000 | Loss: 0.00001409
Iteration 195/1000 | Loss: 0.00001409
Iteration 196/1000 | Loss: 0.00001409
Iteration 197/1000 | Loss: 0.00001409
Iteration 198/1000 | Loss: 0.00001409
Iteration 199/1000 | Loss: 0.00001409
Iteration 200/1000 | Loss: 0.00001409
Iteration 201/1000 | Loss: 0.00001409
Iteration 202/1000 | Loss: 0.00001409
Iteration 203/1000 | Loss: 0.00001409
Iteration 204/1000 | Loss: 0.00001409
Iteration 205/1000 | Loss: 0.00001409
Iteration 206/1000 | Loss: 0.00001408
Iteration 207/1000 | Loss: 0.00001408
Iteration 208/1000 | Loss: 0.00001408
Iteration 209/1000 | Loss: 0.00001408
Iteration 210/1000 | Loss: 0.00001408
Iteration 211/1000 | Loss: 0.00001408
Iteration 212/1000 | Loss: 0.00001408
Iteration 213/1000 | Loss: 0.00001408
Iteration 214/1000 | Loss: 0.00001408
Iteration 215/1000 | Loss: 0.00001408
Iteration 216/1000 | Loss: 0.00001408
Iteration 217/1000 | Loss: 0.00001408
Iteration 218/1000 | Loss: 0.00001408
Iteration 219/1000 | Loss: 0.00001408
Iteration 220/1000 | Loss: 0.00001408
Iteration 221/1000 | Loss: 0.00001408
Iteration 222/1000 | Loss: 0.00001408
Iteration 223/1000 | Loss: 0.00001408
Iteration 224/1000 | Loss: 0.00001408
Iteration 225/1000 | Loss: 0.00001408
Iteration 226/1000 | Loss: 0.00001407
Iteration 227/1000 | Loss: 0.00001407
Iteration 228/1000 | Loss: 0.00001407
Iteration 229/1000 | Loss: 0.00001407
Iteration 230/1000 | Loss: 0.00001407
Iteration 231/1000 | Loss: 0.00001407
Iteration 232/1000 | Loss: 0.00001407
Iteration 233/1000 | Loss: 0.00001407
Iteration 234/1000 | Loss: 0.00001407
Iteration 235/1000 | Loss: 0.00001407
Iteration 236/1000 | Loss: 0.00001407
Iteration 237/1000 | Loss: 0.00001407
Iteration 238/1000 | Loss: 0.00001407
Iteration 239/1000 | Loss: 0.00001407
Iteration 240/1000 | Loss: 0.00001407
Iteration 241/1000 | Loss: 0.00001407
Iteration 242/1000 | Loss: 0.00001407
Iteration 243/1000 | Loss: 0.00001407
Iteration 244/1000 | Loss: 0.00001407
Iteration 245/1000 | Loss: 0.00001407
Iteration 246/1000 | Loss: 0.00001407
Iteration 247/1000 | Loss: 0.00001407
Iteration 248/1000 | Loss: 0.00001407
Iteration 249/1000 | Loss: 0.00001407
Iteration 250/1000 | Loss: 0.00001406
Iteration 251/1000 | Loss: 0.00001406
Iteration 252/1000 | Loss: 0.00001406
Iteration 253/1000 | Loss: 0.00001406
Iteration 254/1000 | Loss: 0.00001406
Iteration 255/1000 | Loss: 0.00001406
Iteration 256/1000 | Loss: 0.00001406
Iteration 257/1000 | Loss: 0.00001406
Iteration 258/1000 | Loss: 0.00001406
Iteration 259/1000 | Loss: 0.00001406
Iteration 260/1000 | Loss: 0.00001406
Iteration 261/1000 | Loss: 0.00001406
Iteration 262/1000 | Loss: 0.00001406
Iteration 263/1000 | Loss: 0.00001406
Iteration 264/1000 | Loss: 0.00001406
Iteration 265/1000 | Loss: 0.00001406
Iteration 266/1000 | Loss: 0.00001406
Iteration 267/1000 | Loss: 0.00001406
Iteration 268/1000 | Loss: 0.00001406
Iteration 269/1000 | Loss: 0.00001406
Iteration 270/1000 | Loss: 0.00001406
Iteration 271/1000 | Loss: 0.00001406
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 271. Stopping optimization.
Last 5 losses: [1.4063235539651942e-05, 1.4063235539651942e-05, 1.4063235539651942e-05, 1.4063235539651942e-05, 1.4063235539651942e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4063235539651942e-05

Optimization complete. Final v2v error: 3.127800703048706 mm

Highest mean error: 4.258346080780029 mm for frame 68

Lowest mean error: 2.6460468769073486 mm for frame 8

Saving results

Total time: 119.60264658927917
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_30_us_1269/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00969421
Iteration 2/25 | Loss: 0.00157924
Iteration 3/25 | Loss: 0.00135525
Iteration 4/25 | Loss: 0.00118902
Iteration 5/25 | Loss: 0.00114120
Iteration 6/25 | Loss: 0.00112646
Iteration 7/25 | Loss: 0.00112109
Iteration 8/25 | Loss: 0.00112687
Iteration 9/25 | Loss: 0.00112121
Iteration 10/25 | Loss: 0.00111890
Iteration 11/25 | Loss: 0.00111457
Iteration 12/25 | Loss: 0.00111291
Iteration 13/25 | Loss: 0.00111230
Iteration 14/25 | Loss: 0.00111212
Iteration 15/25 | Loss: 0.00111211
Iteration 16/25 | Loss: 0.00111211
Iteration 17/25 | Loss: 0.00111211
Iteration 18/25 | Loss: 0.00111211
Iteration 19/25 | Loss: 0.00111211
Iteration 20/25 | Loss: 0.00111210
Iteration 21/25 | Loss: 0.00111210
Iteration 22/25 | Loss: 0.00111210
Iteration 23/25 | Loss: 0.00111210
Iteration 24/25 | Loss: 0.00111210
Iteration 25/25 | Loss: 0.00111210

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43364739
Iteration 2/25 | Loss: 0.00129606
Iteration 3/25 | Loss: 0.00125318
Iteration 4/25 | Loss: 0.00125318
Iteration 5/25 | Loss: 0.00125318
Iteration 6/25 | Loss: 0.00125318
Iteration 7/25 | Loss: 0.00125318
Iteration 8/25 | Loss: 0.00125318
Iteration 9/25 | Loss: 0.00125318
Iteration 10/25 | Loss: 0.00125318
Iteration 11/25 | Loss: 0.00125317
Iteration 12/25 | Loss: 0.00125317
Iteration 13/25 | Loss: 0.00125317
Iteration 14/25 | Loss: 0.00125317
Iteration 15/25 | Loss: 0.00125317
Iteration 16/25 | Loss: 0.00125317
Iteration 17/25 | Loss: 0.00125317
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0012531743850558996, 0.0012531743850558996, 0.0012531743850558996, 0.0012531743850558996, 0.0012531743850558996]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012531743850558996

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00125317
Iteration 2/1000 | Loss: 0.00007324
Iteration 3/1000 | Loss: 0.00011630
Iteration 4/1000 | Loss: 0.00041806
Iteration 5/1000 | Loss: 0.00002362
Iteration 6/1000 | Loss: 0.00001967
Iteration 7/1000 | Loss: 0.00018065
Iteration 8/1000 | Loss: 0.00033710
Iteration 9/1000 | Loss: 0.00001772
Iteration 10/1000 | Loss: 0.00017633
Iteration 11/1000 | Loss: 0.00001715
Iteration 12/1000 | Loss: 0.00001647
Iteration 13/1000 | Loss: 0.00001618
Iteration 14/1000 | Loss: 0.00001599
Iteration 15/1000 | Loss: 0.00001585
Iteration 16/1000 | Loss: 0.00001582
Iteration 17/1000 | Loss: 0.00001581
Iteration 18/1000 | Loss: 0.00001580
Iteration 19/1000 | Loss: 0.00001579
Iteration 20/1000 | Loss: 0.00001579
Iteration 21/1000 | Loss: 0.00001570
Iteration 22/1000 | Loss: 0.00001567
Iteration 23/1000 | Loss: 0.00001566
Iteration 24/1000 | Loss: 0.00001564
Iteration 25/1000 | Loss: 0.00001564
Iteration 26/1000 | Loss: 0.00001564
Iteration 27/1000 | Loss: 0.00001563
Iteration 28/1000 | Loss: 0.00001563
Iteration 29/1000 | Loss: 0.00001563
Iteration 30/1000 | Loss: 0.00001562
Iteration 31/1000 | Loss: 0.00001562
Iteration 32/1000 | Loss: 0.00001562
Iteration 33/1000 | Loss: 0.00001561
Iteration 34/1000 | Loss: 0.00001561
Iteration 35/1000 | Loss: 0.00001561
Iteration 36/1000 | Loss: 0.00001561
Iteration 37/1000 | Loss: 0.00001561
Iteration 38/1000 | Loss: 0.00001560
Iteration 39/1000 | Loss: 0.00001560
Iteration 40/1000 | Loss: 0.00001559
Iteration 41/1000 | Loss: 0.00001559
Iteration 42/1000 | Loss: 0.00001559
Iteration 43/1000 | Loss: 0.00001558
Iteration 44/1000 | Loss: 0.00001558
Iteration 45/1000 | Loss: 0.00001558
Iteration 46/1000 | Loss: 0.00001558
Iteration 47/1000 | Loss: 0.00001557
Iteration 48/1000 | Loss: 0.00001557
Iteration 49/1000 | Loss: 0.00001556
Iteration 50/1000 | Loss: 0.00001556
Iteration 51/1000 | Loss: 0.00001556
Iteration 52/1000 | Loss: 0.00001556
Iteration 53/1000 | Loss: 0.00001556
Iteration 54/1000 | Loss: 0.00001556
Iteration 55/1000 | Loss: 0.00001555
Iteration 56/1000 | Loss: 0.00001555
Iteration 57/1000 | Loss: 0.00001555
Iteration 58/1000 | Loss: 0.00001555
Iteration 59/1000 | Loss: 0.00001555
Iteration 60/1000 | Loss: 0.00001555
Iteration 61/1000 | Loss: 0.00001554
Iteration 62/1000 | Loss: 0.00001554
Iteration 63/1000 | Loss: 0.00001553
Iteration 64/1000 | Loss: 0.00001553
Iteration 65/1000 | Loss: 0.00001552
Iteration 66/1000 | Loss: 0.00001552
Iteration 67/1000 | Loss: 0.00001552
Iteration 68/1000 | Loss: 0.00001552
Iteration 69/1000 | Loss: 0.00001551
Iteration 70/1000 | Loss: 0.00001551
Iteration 71/1000 | Loss: 0.00001551
Iteration 72/1000 | Loss: 0.00001551
Iteration 73/1000 | Loss: 0.00001550
Iteration 74/1000 | Loss: 0.00001550
Iteration 75/1000 | Loss: 0.00001550
Iteration 76/1000 | Loss: 0.00001550
Iteration 77/1000 | Loss: 0.00001550
Iteration 78/1000 | Loss: 0.00001549
Iteration 79/1000 | Loss: 0.00001549
Iteration 80/1000 | Loss: 0.00001549
Iteration 81/1000 | Loss: 0.00001549
Iteration 82/1000 | Loss: 0.00001549
Iteration 83/1000 | Loss: 0.00001549
Iteration 84/1000 | Loss: 0.00001549
Iteration 85/1000 | Loss: 0.00001549
Iteration 86/1000 | Loss: 0.00001549
Iteration 87/1000 | Loss: 0.00001549
Iteration 88/1000 | Loss: 0.00001548
Iteration 89/1000 | Loss: 0.00001548
Iteration 90/1000 | Loss: 0.00001548
Iteration 91/1000 | Loss: 0.00001548
Iteration 92/1000 | Loss: 0.00001548
Iteration 93/1000 | Loss: 0.00001548
Iteration 94/1000 | Loss: 0.00001547
Iteration 95/1000 | Loss: 0.00001547
Iteration 96/1000 | Loss: 0.00001547
Iteration 97/1000 | Loss: 0.00001546
Iteration 98/1000 | Loss: 0.00001546
Iteration 99/1000 | Loss: 0.00001546
Iteration 100/1000 | Loss: 0.00001546
Iteration 101/1000 | Loss: 0.00001546
Iteration 102/1000 | Loss: 0.00001546
Iteration 103/1000 | Loss: 0.00001546
Iteration 104/1000 | Loss: 0.00001546
Iteration 105/1000 | Loss: 0.00001546
Iteration 106/1000 | Loss: 0.00001546
Iteration 107/1000 | Loss: 0.00001546
Iteration 108/1000 | Loss: 0.00001546
Iteration 109/1000 | Loss: 0.00001546
Iteration 110/1000 | Loss: 0.00001546
Iteration 111/1000 | Loss: 0.00001546
Iteration 112/1000 | Loss: 0.00001545
Iteration 113/1000 | Loss: 0.00001545
Iteration 114/1000 | Loss: 0.00001545
Iteration 115/1000 | Loss: 0.00001545
Iteration 116/1000 | Loss: 0.00001545
Iteration 117/1000 | Loss: 0.00001544
Iteration 118/1000 | Loss: 0.00001544
Iteration 119/1000 | Loss: 0.00001544
Iteration 120/1000 | Loss: 0.00001544
Iteration 121/1000 | Loss: 0.00001543
Iteration 122/1000 | Loss: 0.00001543
Iteration 123/1000 | Loss: 0.00001543
Iteration 124/1000 | Loss: 0.00001543
Iteration 125/1000 | Loss: 0.00001543
Iteration 126/1000 | Loss: 0.00001543
Iteration 127/1000 | Loss: 0.00001543
Iteration 128/1000 | Loss: 0.00001543
Iteration 129/1000 | Loss: 0.00001543
Iteration 130/1000 | Loss: 0.00001543
Iteration 131/1000 | Loss: 0.00001542
Iteration 132/1000 | Loss: 0.00001542
Iteration 133/1000 | Loss: 0.00001542
Iteration 134/1000 | Loss: 0.00001542
Iteration 135/1000 | Loss: 0.00001542
Iteration 136/1000 | Loss: 0.00001542
Iteration 137/1000 | Loss: 0.00001542
Iteration 138/1000 | Loss: 0.00001542
Iteration 139/1000 | Loss: 0.00001542
Iteration 140/1000 | Loss: 0.00001542
Iteration 141/1000 | Loss: 0.00001541
Iteration 142/1000 | Loss: 0.00001541
Iteration 143/1000 | Loss: 0.00001541
Iteration 144/1000 | Loss: 0.00001541
Iteration 145/1000 | Loss: 0.00001541
Iteration 146/1000 | Loss: 0.00001541
Iteration 147/1000 | Loss: 0.00001541
Iteration 148/1000 | Loss: 0.00001541
Iteration 149/1000 | Loss: 0.00001541
Iteration 150/1000 | Loss: 0.00001541
Iteration 151/1000 | Loss: 0.00001541
Iteration 152/1000 | Loss: 0.00001541
Iteration 153/1000 | Loss: 0.00001541
Iteration 154/1000 | Loss: 0.00001541
Iteration 155/1000 | Loss: 0.00001541
Iteration 156/1000 | Loss: 0.00001541
Iteration 157/1000 | Loss: 0.00001541
Iteration 158/1000 | Loss: 0.00001541
Iteration 159/1000 | Loss: 0.00001540
Iteration 160/1000 | Loss: 0.00001540
Iteration 161/1000 | Loss: 0.00001540
Iteration 162/1000 | Loss: 0.00001540
Iteration 163/1000 | Loss: 0.00001540
Iteration 164/1000 | Loss: 0.00001540
Iteration 165/1000 | Loss: 0.00001540
Iteration 166/1000 | Loss: 0.00001540
Iteration 167/1000 | Loss: 0.00001540
Iteration 168/1000 | Loss: 0.00001540
Iteration 169/1000 | Loss: 0.00001540
Iteration 170/1000 | Loss: 0.00001540
Iteration 171/1000 | Loss: 0.00001540
Iteration 172/1000 | Loss: 0.00001539
Iteration 173/1000 | Loss: 0.00001539
Iteration 174/1000 | Loss: 0.00001539
Iteration 175/1000 | Loss: 0.00001539
Iteration 176/1000 | Loss: 0.00001539
Iteration 177/1000 | Loss: 0.00001539
Iteration 178/1000 | Loss: 0.00001539
Iteration 179/1000 | Loss: 0.00001539
Iteration 180/1000 | Loss: 0.00001539
Iteration 181/1000 | Loss: 0.00001539
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.5393472494906746e-05, 1.5393472494906746e-05, 1.5393472494906746e-05, 1.5393472494906746e-05, 1.5393472494906746e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5393472494906746e-05

Optimization complete. Final v2v error: 3.276653289794922 mm

Highest mean error: 4.024521350860596 mm for frame 38

Lowest mean error: 2.6672842502593994 mm for frame 199

Saving results

Total time: 62.54160761833191
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/female_30_us_1269/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/female_30_us_1269/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00210653
Iteration 2/25 | Loss: 0.00125842
Iteration 3/25 | Loss: 0.00115625
Iteration 4/25 | Loss: 0.00112298
Iteration 5/25 | Loss: 0.00111481
Iteration 6/25 | Loss: 0.00111283
Iteration 7/25 | Loss: 0.00111207
Iteration 8/25 | Loss: 0.00111207
Iteration 9/25 | Loss: 0.00111207
Iteration 10/25 | Loss: 0.00111207
Iteration 11/25 | Loss: 0.00111207
Iteration 12/25 | Loss: 0.00111207
Iteration 13/25 | Loss: 0.00111207
Iteration 14/25 | Loss: 0.00111207
Iteration 15/25 | Loss: 0.00111207
Iteration 16/25 | Loss: 0.00111207
Iteration 17/25 | Loss: 0.00111205
Iteration 18/25 | Loss: 0.00111204
Iteration 19/25 | Loss: 0.00111204
Iteration 20/25 | Loss: 0.00111204
Iteration 21/25 | Loss: 0.00111204
Iteration 22/25 | Loss: 0.00111204
Iteration 23/25 | Loss: 0.00111204
Iteration 24/25 | Loss: 0.00111204
Iteration 25/25 | Loss: 0.00111204

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.28259623
Iteration 2/25 | Loss: 0.00291097
Iteration 3/25 | Loss: 0.00291097
Iteration 4/25 | Loss: 0.00291097
Iteration 5/25 | Loss: 0.00291097
Iteration 6/25 | Loss: 0.00291097
Iteration 7/25 | Loss: 0.00291097
Iteration 8/25 | Loss: 0.00291097
Iteration 9/25 | Loss: 0.00291097
Iteration 10/25 | Loss: 0.00291097
Iteration 11/25 | Loss: 0.00291097
Iteration 12/25 | Loss: 0.00291097
Iteration 13/25 | Loss: 0.00291097
Iteration 14/25 | Loss: 0.00291097
Iteration 15/25 | Loss: 0.00291097
Iteration 16/25 | Loss: 0.00291097
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0029109709430485964, 0.0029109709430485964, 0.0029109709430485964, 0.0029109709430485964, 0.0029109709430485964]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0029109709430485964

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00291097
Iteration 2/1000 | Loss: 0.00004410
Iteration 3/1000 | Loss: 0.00002381
Iteration 4/1000 | Loss: 0.00002024
Iteration 5/1000 | Loss: 0.00001840
Iteration 6/1000 | Loss: 0.00001749
Iteration 7/1000 | Loss: 0.00001706
Iteration 8/1000 | Loss: 0.00001658
Iteration 9/1000 | Loss: 0.00001634
Iteration 10/1000 | Loss: 0.00001633
Iteration 11/1000 | Loss: 0.00001628
Iteration 12/1000 | Loss: 0.00001627
Iteration 13/1000 | Loss: 0.00001622
Iteration 14/1000 | Loss: 0.00001621
Iteration 15/1000 | Loss: 0.00001620
Iteration 16/1000 | Loss: 0.00001619
Iteration 17/1000 | Loss: 0.00001619
Iteration 18/1000 | Loss: 0.00001614
Iteration 19/1000 | Loss: 0.00001613
Iteration 20/1000 | Loss: 0.00001610
Iteration 21/1000 | Loss: 0.00001610
Iteration 22/1000 | Loss: 0.00001609
Iteration 23/1000 | Loss: 0.00001607
Iteration 24/1000 | Loss: 0.00001607
Iteration 25/1000 | Loss: 0.00001607
Iteration 26/1000 | Loss: 0.00001607
Iteration 27/1000 | Loss: 0.00001607
Iteration 28/1000 | Loss: 0.00001607
Iteration 29/1000 | Loss: 0.00001606
Iteration 30/1000 | Loss: 0.00001605
Iteration 31/1000 | Loss: 0.00001605
Iteration 32/1000 | Loss: 0.00001605
Iteration 33/1000 | Loss: 0.00001605
Iteration 34/1000 | Loss: 0.00001605
Iteration 35/1000 | Loss: 0.00001605
Iteration 36/1000 | Loss: 0.00001605
Iteration 37/1000 | Loss: 0.00001604
Iteration 38/1000 | Loss: 0.00001604
Iteration 39/1000 | Loss: 0.00001604
Iteration 40/1000 | Loss: 0.00001604
Iteration 41/1000 | Loss: 0.00001604
Iteration 42/1000 | Loss: 0.00001604
Iteration 43/1000 | Loss: 0.00001604
Iteration 44/1000 | Loss: 0.00001603
Iteration 45/1000 | Loss: 0.00001602
Iteration 46/1000 | Loss: 0.00001601
Iteration 47/1000 | Loss: 0.00001600
Iteration 48/1000 | Loss: 0.00001600
Iteration 49/1000 | Loss: 0.00001599
Iteration 50/1000 | Loss: 0.00001599
Iteration 51/1000 | Loss: 0.00001599
Iteration 52/1000 | Loss: 0.00001599
Iteration 53/1000 | Loss: 0.00001599
Iteration 54/1000 | Loss: 0.00001599
Iteration 55/1000 | Loss: 0.00001599
Iteration 56/1000 | Loss: 0.00001599
Iteration 57/1000 | Loss: 0.00001598
Iteration 58/1000 | Loss: 0.00001598
Iteration 59/1000 | Loss: 0.00001598
Iteration 60/1000 | Loss: 0.00001598
Iteration 61/1000 | Loss: 0.00001598
Iteration 62/1000 | Loss: 0.00001598
Iteration 63/1000 | Loss: 0.00001598
Iteration 64/1000 | Loss: 0.00001598
Iteration 65/1000 | Loss: 0.00001598
Iteration 66/1000 | Loss: 0.00001598
Iteration 67/1000 | Loss: 0.00001598
Iteration 68/1000 | Loss: 0.00001598
Iteration 69/1000 | Loss: 0.00001598
Iteration 70/1000 | Loss: 0.00001598
Iteration 71/1000 | Loss: 0.00001598
Iteration 72/1000 | Loss: 0.00001598
Iteration 73/1000 | Loss: 0.00001598
Iteration 74/1000 | Loss: 0.00001598
Iteration 75/1000 | Loss: 0.00001598
Iteration 76/1000 | Loss: 0.00001598
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [1.5976778740878217e-05, 1.5976778740878217e-05, 1.5976778740878217e-05, 1.5976778740878217e-05, 1.5976778740878217e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5976778740878217e-05

Optimization complete. Final v2v error: 3.355088949203491 mm

Highest mean error: 3.8018798828125 mm for frame 159

Lowest mean error: 2.992194175720215 mm for frame 102

Saving results

Total time: 28.877786874771118

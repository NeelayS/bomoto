Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=172, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 9632-9687
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1064/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1064.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1064
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00491075
Iteration 2/25 | Loss: 0.00144895
Iteration 3/25 | Loss: 0.00093916
Iteration 4/25 | Loss: 0.00082522
Iteration 5/25 | Loss: 0.00080772
Iteration 6/25 | Loss: 0.00080361
Iteration 7/25 | Loss: 0.00080269
Iteration 8/25 | Loss: 0.00080269
Iteration 9/25 | Loss: 0.00080269
Iteration 10/25 | Loss: 0.00080269
Iteration 11/25 | Loss: 0.00080269
Iteration 12/25 | Loss: 0.00080269
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008026949944905937, 0.0008026949944905937, 0.0008026949944905937, 0.0008026949944905937, 0.0008026949944905937]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008026949944905937

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60551560
Iteration 2/25 | Loss: 0.00048988
Iteration 3/25 | Loss: 0.00048988
Iteration 4/25 | Loss: 0.00048988
Iteration 5/25 | Loss: 0.00048988
Iteration 6/25 | Loss: 0.00048988
Iteration 7/25 | Loss: 0.00048988
Iteration 8/25 | Loss: 0.00048988
Iteration 9/25 | Loss: 0.00048988
Iteration 10/25 | Loss: 0.00048988
Iteration 11/25 | Loss: 0.00048988
Iteration 12/25 | Loss: 0.00048988
Iteration 13/25 | Loss: 0.00048988
Iteration 14/25 | Loss: 0.00048988
Iteration 15/25 | Loss: 0.00048988
Iteration 16/25 | Loss: 0.00048988
Iteration 17/25 | Loss: 0.00048988
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004898783518001437, 0.0004898783518001437, 0.0004898783518001437, 0.0004898783518001437, 0.0004898783518001437]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004898783518001437

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048988
Iteration 2/1000 | Loss: 0.00003218
Iteration 3/1000 | Loss: 0.00002382
Iteration 4/1000 | Loss: 0.00002152
Iteration 5/1000 | Loss: 0.00002039
Iteration 6/1000 | Loss: 0.00001960
Iteration 7/1000 | Loss: 0.00001911
Iteration 8/1000 | Loss: 0.00001865
Iteration 9/1000 | Loss: 0.00001847
Iteration 10/1000 | Loss: 0.00001824
Iteration 11/1000 | Loss: 0.00001811
Iteration 12/1000 | Loss: 0.00001794
Iteration 13/1000 | Loss: 0.00001786
Iteration 14/1000 | Loss: 0.00001783
Iteration 15/1000 | Loss: 0.00001781
Iteration 16/1000 | Loss: 0.00001773
Iteration 17/1000 | Loss: 0.00001766
Iteration 18/1000 | Loss: 0.00001766
Iteration 19/1000 | Loss: 0.00001764
Iteration 20/1000 | Loss: 0.00001764
Iteration 21/1000 | Loss: 0.00001764
Iteration 22/1000 | Loss: 0.00001764
Iteration 23/1000 | Loss: 0.00001764
Iteration 24/1000 | Loss: 0.00001764
Iteration 25/1000 | Loss: 0.00001764
Iteration 26/1000 | Loss: 0.00001764
Iteration 27/1000 | Loss: 0.00001764
Iteration 28/1000 | Loss: 0.00001763
Iteration 29/1000 | Loss: 0.00001763
Iteration 30/1000 | Loss: 0.00001763
Iteration 31/1000 | Loss: 0.00001763
Iteration 32/1000 | Loss: 0.00001763
Iteration 33/1000 | Loss: 0.00001763
Iteration 34/1000 | Loss: 0.00001763
Iteration 35/1000 | Loss: 0.00001763
Iteration 36/1000 | Loss: 0.00001763
Iteration 37/1000 | Loss: 0.00001762
Iteration 38/1000 | Loss: 0.00001762
Iteration 39/1000 | Loss: 0.00001762
Iteration 40/1000 | Loss: 0.00001762
Iteration 41/1000 | Loss: 0.00001761
Iteration 42/1000 | Loss: 0.00001761
Iteration 43/1000 | Loss: 0.00001761
Iteration 44/1000 | Loss: 0.00001761
Iteration 45/1000 | Loss: 0.00001761
Iteration 46/1000 | Loss: 0.00001761
Iteration 47/1000 | Loss: 0.00001761
Iteration 48/1000 | Loss: 0.00001760
Iteration 49/1000 | Loss: 0.00001760
Iteration 50/1000 | Loss: 0.00001760
Iteration 51/1000 | Loss: 0.00001759
Iteration 52/1000 | Loss: 0.00001759
Iteration 53/1000 | Loss: 0.00001758
Iteration 54/1000 | Loss: 0.00001758
Iteration 55/1000 | Loss: 0.00001758
Iteration 56/1000 | Loss: 0.00001758
Iteration 57/1000 | Loss: 0.00001758
Iteration 58/1000 | Loss: 0.00001758
Iteration 59/1000 | Loss: 0.00001757
Iteration 60/1000 | Loss: 0.00001757
Iteration 61/1000 | Loss: 0.00001757
Iteration 62/1000 | Loss: 0.00001756
Iteration 63/1000 | Loss: 0.00001756
Iteration 64/1000 | Loss: 0.00001756
Iteration 65/1000 | Loss: 0.00001756
Iteration 66/1000 | Loss: 0.00001756
Iteration 67/1000 | Loss: 0.00001756
Iteration 68/1000 | Loss: 0.00001756
Iteration 69/1000 | Loss: 0.00001756
Iteration 70/1000 | Loss: 0.00001756
Iteration 71/1000 | Loss: 0.00001756
Iteration 72/1000 | Loss: 0.00001755
Iteration 73/1000 | Loss: 0.00001755
Iteration 74/1000 | Loss: 0.00001755
Iteration 75/1000 | Loss: 0.00001755
Iteration 76/1000 | Loss: 0.00001755
Iteration 77/1000 | Loss: 0.00001755
Iteration 78/1000 | Loss: 0.00001755
Iteration 79/1000 | Loss: 0.00001755
Iteration 80/1000 | Loss: 0.00001755
Iteration 81/1000 | Loss: 0.00001755
Iteration 82/1000 | Loss: 0.00001755
Iteration 83/1000 | Loss: 0.00001755
Iteration 84/1000 | Loss: 0.00001755
Iteration 85/1000 | Loss: 0.00001755
Iteration 86/1000 | Loss: 0.00001755
Iteration 87/1000 | Loss: 0.00001755
Iteration 88/1000 | Loss: 0.00001755
Iteration 89/1000 | Loss: 0.00001755
Iteration 90/1000 | Loss: 0.00001755
Iteration 91/1000 | Loss: 0.00001755
Iteration 92/1000 | Loss: 0.00001755
Iteration 93/1000 | Loss: 0.00001755
Iteration 94/1000 | Loss: 0.00001755
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.754891491145827e-05, 1.754891491145827e-05, 1.754891491145827e-05, 1.754891491145827e-05, 1.754891491145827e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.754891491145827e-05

Optimization complete. Final v2v error: 3.562532424926758 mm

Highest mean error: 3.94732928276062 mm for frame 149

Lowest mean error: 3.219921112060547 mm for frame 133

Saving results

Total time: 37.53988075256348
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00782542
Iteration 2/25 | Loss: 0.00148091
Iteration 3/25 | Loss: 0.00098592
Iteration 4/25 | Loss: 0.00100031
Iteration 5/25 | Loss: 0.00096274
Iteration 6/25 | Loss: 0.00085926
Iteration 7/25 | Loss: 0.00086162
Iteration 8/25 | Loss: 0.00082596
Iteration 9/25 | Loss: 0.00083446
Iteration 10/25 | Loss: 0.00082050
Iteration 11/25 | Loss: 0.00081580
Iteration 12/25 | Loss: 0.00081404
Iteration 13/25 | Loss: 0.00081394
Iteration 14/25 | Loss: 0.00081394
Iteration 15/25 | Loss: 0.00081394
Iteration 16/25 | Loss: 0.00081394
Iteration 17/25 | Loss: 0.00081394
Iteration 18/25 | Loss: 0.00081393
Iteration 19/25 | Loss: 0.00081393
Iteration 20/25 | Loss: 0.00081393
Iteration 21/25 | Loss: 0.00081393
Iteration 22/25 | Loss: 0.00081393
Iteration 23/25 | Loss: 0.00081393
Iteration 24/25 | Loss: 0.00081393
Iteration 25/25 | Loss: 0.00081393

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.92549634
Iteration 2/25 | Loss: 0.00053534
Iteration 3/25 | Loss: 0.00053533
Iteration 4/25 | Loss: 0.00053533
Iteration 5/25 | Loss: 0.00053533
Iteration 6/25 | Loss: 0.00053533
Iteration 7/25 | Loss: 0.00053533
Iteration 8/25 | Loss: 0.00053533
Iteration 9/25 | Loss: 0.00053533
Iteration 10/25 | Loss: 0.00053533
Iteration 11/25 | Loss: 0.00053533
Iteration 12/25 | Loss: 0.00053533
Iteration 13/25 | Loss: 0.00053533
Iteration 14/25 | Loss: 0.00053533
Iteration 15/25 | Loss: 0.00053533
Iteration 16/25 | Loss: 0.00053533
Iteration 17/25 | Loss: 0.00053533
Iteration 18/25 | Loss: 0.00053533
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005353313172236085, 0.0005353313172236085, 0.0005353313172236085, 0.0005353313172236085, 0.0005353313172236085]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005353313172236085

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053533
Iteration 2/1000 | Loss: 0.00004159
Iteration 3/1000 | Loss: 0.00003072
Iteration 4/1000 | Loss: 0.00002586
Iteration 5/1000 | Loss: 0.00002403
Iteration 6/1000 | Loss: 0.00002244
Iteration 7/1000 | Loss: 0.00002178
Iteration 8/1000 | Loss: 0.00002112
Iteration 9/1000 | Loss: 0.00002071
Iteration 10/1000 | Loss: 0.00002042
Iteration 11/1000 | Loss: 0.00002017
Iteration 12/1000 | Loss: 0.00002012
Iteration 13/1000 | Loss: 0.00002009
Iteration 14/1000 | Loss: 0.00001995
Iteration 15/1000 | Loss: 0.00001977
Iteration 16/1000 | Loss: 0.00001976
Iteration 17/1000 | Loss: 0.00001966
Iteration 18/1000 | Loss: 0.00001965
Iteration 19/1000 | Loss: 0.00001962
Iteration 20/1000 | Loss: 0.00001961
Iteration 21/1000 | Loss: 0.00001961
Iteration 22/1000 | Loss: 0.00001959
Iteration 23/1000 | Loss: 0.00001959
Iteration 24/1000 | Loss: 0.00001959
Iteration 25/1000 | Loss: 0.00001957
Iteration 26/1000 | Loss: 0.00001957
Iteration 27/1000 | Loss: 0.00001957
Iteration 28/1000 | Loss: 0.00001957
Iteration 29/1000 | Loss: 0.00001957
Iteration 30/1000 | Loss: 0.00001957
Iteration 31/1000 | Loss: 0.00001957
Iteration 32/1000 | Loss: 0.00001956
Iteration 33/1000 | Loss: 0.00001956
Iteration 34/1000 | Loss: 0.00001956
Iteration 35/1000 | Loss: 0.00001955
Iteration 36/1000 | Loss: 0.00001955
Iteration 37/1000 | Loss: 0.00001954
Iteration 38/1000 | Loss: 0.00001954
Iteration 39/1000 | Loss: 0.00001954
Iteration 40/1000 | Loss: 0.00001954
Iteration 41/1000 | Loss: 0.00001954
Iteration 42/1000 | Loss: 0.00001954
Iteration 43/1000 | Loss: 0.00001953
Iteration 44/1000 | Loss: 0.00001953
Iteration 45/1000 | Loss: 0.00001953
Iteration 46/1000 | Loss: 0.00001953
Iteration 47/1000 | Loss: 0.00001953
Iteration 48/1000 | Loss: 0.00001953
Iteration 49/1000 | Loss: 0.00001953
Iteration 50/1000 | Loss: 0.00001953
Iteration 51/1000 | Loss: 0.00001952
Iteration 52/1000 | Loss: 0.00001952
Iteration 53/1000 | Loss: 0.00001952
Iteration 54/1000 | Loss: 0.00001952
Iteration 55/1000 | Loss: 0.00001952
Iteration 56/1000 | Loss: 0.00001952
Iteration 57/1000 | Loss: 0.00001951
Iteration 58/1000 | Loss: 0.00001951
Iteration 59/1000 | Loss: 0.00001951
Iteration 60/1000 | Loss: 0.00001951
Iteration 61/1000 | Loss: 0.00001951
Iteration 62/1000 | Loss: 0.00001951
Iteration 63/1000 | Loss: 0.00001950
Iteration 64/1000 | Loss: 0.00001950
Iteration 65/1000 | Loss: 0.00001950
Iteration 66/1000 | Loss: 0.00001950
Iteration 67/1000 | Loss: 0.00001950
Iteration 68/1000 | Loss: 0.00001950
Iteration 69/1000 | Loss: 0.00001949
Iteration 70/1000 | Loss: 0.00001949
Iteration 71/1000 | Loss: 0.00001949
Iteration 72/1000 | Loss: 0.00001949
Iteration 73/1000 | Loss: 0.00001949
Iteration 74/1000 | Loss: 0.00001949
Iteration 75/1000 | Loss: 0.00001948
Iteration 76/1000 | Loss: 0.00001948
Iteration 77/1000 | Loss: 0.00001948
Iteration 78/1000 | Loss: 0.00001948
Iteration 79/1000 | Loss: 0.00001948
Iteration 80/1000 | Loss: 0.00001948
Iteration 81/1000 | Loss: 0.00001948
Iteration 82/1000 | Loss: 0.00001948
Iteration 83/1000 | Loss: 0.00001947
Iteration 84/1000 | Loss: 0.00001947
Iteration 85/1000 | Loss: 0.00001947
Iteration 86/1000 | Loss: 0.00001947
Iteration 87/1000 | Loss: 0.00001947
Iteration 88/1000 | Loss: 0.00001947
Iteration 89/1000 | Loss: 0.00001947
Iteration 90/1000 | Loss: 0.00001946
Iteration 91/1000 | Loss: 0.00001946
Iteration 92/1000 | Loss: 0.00001946
Iteration 93/1000 | Loss: 0.00001946
Iteration 94/1000 | Loss: 0.00001946
Iteration 95/1000 | Loss: 0.00001946
Iteration 96/1000 | Loss: 0.00001946
Iteration 97/1000 | Loss: 0.00001945
Iteration 98/1000 | Loss: 0.00001945
Iteration 99/1000 | Loss: 0.00001945
Iteration 100/1000 | Loss: 0.00001945
Iteration 101/1000 | Loss: 0.00001945
Iteration 102/1000 | Loss: 0.00001944
Iteration 103/1000 | Loss: 0.00001944
Iteration 104/1000 | Loss: 0.00001944
Iteration 105/1000 | Loss: 0.00001944
Iteration 106/1000 | Loss: 0.00001944
Iteration 107/1000 | Loss: 0.00001944
Iteration 108/1000 | Loss: 0.00001943
Iteration 109/1000 | Loss: 0.00001943
Iteration 110/1000 | Loss: 0.00001943
Iteration 111/1000 | Loss: 0.00001943
Iteration 112/1000 | Loss: 0.00001943
Iteration 113/1000 | Loss: 0.00001942
Iteration 114/1000 | Loss: 0.00001942
Iteration 115/1000 | Loss: 0.00001942
Iteration 116/1000 | Loss: 0.00001942
Iteration 117/1000 | Loss: 0.00001942
Iteration 118/1000 | Loss: 0.00001941
Iteration 119/1000 | Loss: 0.00001941
Iteration 120/1000 | Loss: 0.00001941
Iteration 121/1000 | Loss: 0.00001941
Iteration 122/1000 | Loss: 0.00001941
Iteration 123/1000 | Loss: 0.00001941
Iteration 124/1000 | Loss: 0.00001941
Iteration 125/1000 | Loss: 0.00001940
Iteration 126/1000 | Loss: 0.00001940
Iteration 127/1000 | Loss: 0.00001940
Iteration 128/1000 | Loss: 0.00001940
Iteration 129/1000 | Loss: 0.00001940
Iteration 130/1000 | Loss: 0.00001940
Iteration 131/1000 | Loss: 0.00001940
Iteration 132/1000 | Loss: 0.00001940
Iteration 133/1000 | Loss: 0.00001940
Iteration 134/1000 | Loss: 0.00001940
Iteration 135/1000 | Loss: 0.00001939
Iteration 136/1000 | Loss: 0.00001939
Iteration 137/1000 | Loss: 0.00001939
Iteration 138/1000 | Loss: 0.00001939
Iteration 139/1000 | Loss: 0.00001939
Iteration 140/1000 | Loss: 0.00001939
Iteration 141/1000 | Loss: 0.00001939
Iteration 142/1000 | Loss: 0.00001939
Iteration 143/1000 | Loss: 0.00001939
Iteration 144/1000 | Loss: 0.00001938
Iteration 145/1000 | Loss: 0.00001938
Iteration 146/1000 | Loss: 0.00001938
Iteration 147/1000 | Loss: 0.00001938
Iteration 148/1000 | Loss: 0.00001938
Iteration 149/1000 | Loss: 0.00001938
Iteration 150/1000 | Loss: 0.00001938
Iteration 151/1000 | Loss: 0.00001938
Iteration 152/1000 | Loss: 0.00001938
Iteration 153/1000 | Loss: 0.00001938
Iteration 154/1000 | Loss: 0.00001938
Iteration 155/1000 | Loss: 0.00001938
Iteration 156/1000 | Loss: 0.00001938
Iteration 157/1000 | Loss: 0.00001938
Iteration 158/1000 | Loss: 0.00001938
Iteration 159/1000 | Loss: 0.00001938
Iteration 160/1000 | Loss: 0.00001937
Iteration 161/1000 | Loss: 0.00001937
Iteration 162/1000 | Loss: 0.00001937
Iteration 163/1000 | Loss: 0.00001937
Iteration 164/1000 | Loss: 0.00001937
Iteration 165/1000 | Loss: 0.00001937
Iteration 166/1000 | Loss: 0.00001937
Iteration 167/1000 | Loss: 0.00001937
Iteration 168/1000 | Loss: 0.00001937
Iteration 169/1000 | Loss: 0.00001937
Iteration 170/1000 | Loss: 0.00001937
Iteration 171/1000 | Loss: 0.00001937
Iteration 172/1000 | Loss: 0.00001937
Iteration 173/1000 | Loss: 0.00001937
Iteration 174/1000 | Loss: 0.00001937
Iteration 175/1000 | Loss: 0.00001936
Iteration 176/1000 | Loss: 0.00001936
Iteration 177/1000 | Loss: 0.00001936
Iteration 178/1000 | Loss: 0.00001936
Iteration 179/1000 | Loss: 0.00001936
Iteration 180/1000 | Loss: 0.00001936
Iteration 181/1000 | Loss: 0.00001936
Iteration 182/1000 | Loss: 0.00001936
Iteration 183/1000 | Loss: 0.00001935
Iteration 184/1000 | Loss: 0.00001935
Iteration 185/1000 | Loss: 0.00001935
Iteration 186/1000 | Loss: 0.00001935
Iteration 187/1000 | Loss: 0.00001935
Iteration 188/1000 | Loss: 0.00001935
Iteration 189/1000 | Loss: 0.00001935
Iteration 190/1000 | Loss: 0.00001935
Iteration 191/1000 | Loss: 0.00001935
Iteration 192/1000 | Loss: 0.00001935
Iteration 193/1000 | Loss: 0.00001935
Iteration 194/1000 | Loss: 0.00001935
Iteration 195/1000 | Loss: 0.00001935
Iteration 196/1000 | Loss: 0.00001935
Iteration 197/1000 | Loss: 0.00001935
Iteration 198/1000 | Loss: 0.00001935
Iteration 199/1000 | Loss: 0.00001935
Iteration 200/1000 | Loss: 0.00001935
Iteration 201/1000 | Loss: 0.00001935
Iteration 202/1000 | Loss: 0.00001935
Iteration 203/1000 | Loss: 0.00001935
Iteration 204/1000 | Loss: 0.00001935
Iteration 205/1000 | Loss: 0.00001935
Iteration 206/1000 | Loss: 0.00001935
Iteration 207/1000 | Loss: 0.00001935
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [1.9345543478266336e-05, 1.9345543478266336e-05, 1.9345543478266336e-05, 1.9345543478266336e-05, 1.9345543478266336e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9345543478266336e-05

Optimization complete. Final v2v error: 3.5895867347717285 mm

Highest mean error: 4.6743879318237305 mm for frame 26

Lowest mean error: 2.825284957885742 mm for frame 47

Saving results

Total time: 63.4071409702301
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00890057
Iteration 2/25 | Loss: 0.00128259
Iteration 3/25 | Loss: 0.00092476
Iteration 4/25 | Loss: 0.00087038
Iteration 5/25 | Loss: 0.00086134
Iteration 6/25 | Loss: 0.00085960
Iteration 7/25 | Loss: 0.00085939
Iteration 8/25 | Loss: 0.00085939
Iteration 9/25 | Loss: 0.00085939
Iteration 10/25 | Loss: 0.00085939
Iteration 11/25 | Loss: 0.00085939
Iteration 12/25 | Loss: 0.00085939
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000859389896504581, 0.000859389896504581, 0.000859389896504581, 0.000859389896504581, 0.000859389896504581]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000859389896504581

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.03629792
Iteration 2/25 | Loss: 0.00045086
Iteration 3/25 | Loss: 0.00045086
Iteration 4/25 | Loss: 0.00045086
Iteration 5/25 | Loss: 0.00045086
Iteration 6/25 | Loss: 0.00045086
Iteration 7/25 | Loss: 0.00045086
Iteration 8/25 | Loss: 0.00045086
Iteration 9/25 | Loss: 0.00045086
Iteration 10/25 | Loss: 0.00045086
Iteration 11/25 | Loss: 0.00045086
Iteration 12/25 | Loss: 0.00045086
Iteration 13/25 | Loss: 0.00045086
Iteration 14/25 | Loss: 0.00045086
Iteration 15/25 | Loss: 0.00045086
Iteration 16/25 | Loss: 0.00045086
Iteration 17/25 | Loss: 0.00045086
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004508571291808039, 0.0004508571291808039, 0.0004508571291808039, 0.0004508571291808039, 0.0004508571291808039]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004508571291808039

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045086
Iteration 2/1000 | Loss: 0.00005912
Iteration 3/1000 | Loss: 0.00004175
Iteration 4/1000 | Loss: 0.00003568
Iteration 5/1000 | Loss: 0.00003284
Iteration 6/1000 | Loss: 0.00003133
Iteration 7/1000 | Loss: 0.00003014
Iteration 8/1000 | Loss: 0.00002935
Iteration 9/1000 | Loss: 0.00002884
Iteration 10/1000 | Loss: 0.00002849
Iteration 11/1000 | Loss: 0.00002841
Iteration 12/1000 | Loss: 0.00002812
Iteration 13/1000 | Loss: 0.00002795
Iteration 14/1000 | Loss: 0.00002793
Iteration 15/1000 | Loss: 0.00002787
Iteration 16/1000 | Loss: 0.00002783
Iteration 17/1000 | Loss: 0.00002776
Iteration 18/1000 | Loss: 0.00002776
Iteration 19/1000 | Loss: 0.00002775
Iteration 20/1000 | Loss: 0.00002774
Iteration 21/1000 | Loss: 0.00002773
Iteration 22/1000 | Loss: 0.00002773
Iteration 23/1000 | Loss: 0.00002773
Iteration 24/1000 | Loss: 0.00002773
Iteration 25/1000 | Loss: 0.00002773
Iteration 26/1000 | Loss: 0.00002771
Iteration 27/1000 | Loss: 0.00002771
Iteration 28/1000 | Loss: 0.00002769
Iteration 29/1000 | Loss: 0.00002769
Iteration 30/1000 | Loss: 0.00002768
Iteration 31/1000 | Loss: 0.00002768
Iteration 32/1000 | Loss: 0.00002768
Iteration 33/1000 | Loss: 0.00002768
Iteration 34/1000 | Loss: 0.00002768
Iteration 35/1000 | Loss: 0.00002768
Iteration 36/1000 | Loss: 0.00002767
Iteration 37/1000 | Loss: 0.00002767
Iteration 38/1000 | Loss: 0.00002767
Iteration 39/1000 | Loss: 0.00002767
Iteration 40/1000 | Loss: 0.00002767
Iteration 41/1000 | Loss: 0.00002767
Iteration 42/1000 | Loss: 0.00002767
Iteration 43/1000 | Loss: 0.00002767
Iteration 44/1000 | Loss: 0.00002767
Iteration 45/1000 | Loss: 0.00002767
Iteration 46/1000 | Loss: 0.00002767
Iteration 47/1000 | Loss: 0.00002767
Iteration 48/1000 | Loss: 0.00002767
Iteration 49/1000 | Loss: 0.00002767
Iteration 50/1000 | Loss: 0.00002767
Iteration 51/1000 | Loss: 0.00002767
Iteration 52/1000 | Loss: 0.00002767
Iteration 53/1000 | Loss: 0.00002767
Iteration 54/1000 | Loss: 0.00002767
Iteration 55/1000 | Loss: 0.00002767
Iteration 56/1000 | Loss: 0.00002767
Iteration 57/1000 | Loss: 0.00002767
Iteration 58/1000 | Loss: 0.00002767
Iteration 59/1000 | Loss: 0.00002767
Iteration 60/1000 | Loss: 0.00002767
Iteration 61/1000 | Loss: 0.00002767
Iteration 62/1000 | Loss: 0.00002767
Iteration 63/1000 | Loss: 0.00002767
Iteration 64/1000 | Loss: 0.00002767
Iteration 65/1000 | Loss: 0.00002767
Iteration 66/1000 | Loss: 0.00002767
Iteration 67/1000 | Loss: 0.00002767
Iteration 68/1000 | Loss: 0.00002767
Iteration 69/1000 | Loss: 0.00002767
Iteration 70/1000 | Loss: 0.00002767
Iteration 71/1000 | Loss: 0.00002767
Iteration 72/1000 | Loss: 0.00002767
Iteration 73/1000 | Loss: 0.00002767
Iteration 74/1000 | Loss: 0.00002767
Iteration 75/1000 | Loss: 0.00002767
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 75. Stopping optimization.
Last 5 losses: [2.766614852589555e-05, 2.766614852589555e-05, 2.766614852589555e-05, 2.766614852589555e-05, 2.766614852589555e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.766614852589555e-05

Optimization complete. Final v2v error: 4.453545093536377 mm

Highest mean error: 4.9662628173828125 mm for frame 32

Lowest mean error: 4.037203311920166 mm for frame 112

Saving results

Total time: 32.56706523895264
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1065/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1065.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1065
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00477773
Iteration 2/25 | Loss: 0.00110949
Iteration 3/25 | Loss: 0.00083861
Iteration 4/25 | Loss: 0.00078536
Iteration 5/25 | Loss: 0.00077473
Iteration 6/25 | Loss: 0.00077279
Iteration 7/25 | Loss: 0.00077234
Iteration 8/25 | Loss: 0.00077234
Iteration 9/25 | Loss: 0.00077234
Iteration 10/25 | Loss: 0.00077234
Iteration 11/25 | Loss: 0.00077234
Iteration 12/25 | Loss: 0.00077234
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007723412709310651, 0.0007723412709310651, 0.0007723412709310651, 0.0007723412709310651, 0.0007723412709310651]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007723412709310651

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.39621210
Iteration 2/25 | Loss: 0.00047566
Iteration 3/25 | Loss: 0.00047562
Iteration 4/25 | Loss: 0.00047562
Iteration 5/25 | Loss: 0.00047562
Iteration 6/25 | Loss: 0.00047562
Iteration 7/25 | Loss: 0.00047562
Iteration 8/25 | Loss: 0.00047562
Iteration 9/25 | Loss: 0.00047562
Iteration 10/25 | Loss: 0.00047562
Iteration 11/25 | Loss: 0.00047562
Iteration 12/25 | Loss: 0.00047562
Iteration 13/25 | Loss: 0.00047562
Iteration 14/25 | Loss: 0.00047562
Iteration 15/25 | Loss: 0.00047562
Iteration 16/25 | Loss: 0.00047562
Iteration 17/25 | Loss: 0.00047562
Iteration 18/25 | Loss: 0.00047562
Iteration 19/25 | Loss: 0.00047562
Iteration 20/25 | Loss: 0.00047562
Iteration 21/25 | Loss: 0.00047562
Iteration 22/25 | Loss: 0.00047562
Iteration 23/25 | Loss: 0.00047562
Iteration 24/25 | Loss: 0.00047562
Iteration 25/25 | Loss: 0.00047562

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047562
Iteration 2/1000 | Loss: 0.00003403
Iteration 3/1000 | Loss: 0.00002364
Iteration 4/1000 | Loss: 0.00002116
Iteration 5/1000 | Loss: 0.00002007
Iteration 6/1000 | Loss: 0.00001923
Iteration 7/1000 | Loss: 0.00001867
Iteration 8/1000 | Loss: 0.00001829
Iteration 9/1000 | Loss: 0.00001796
Iteration 10/1000 | Loss: 0.00001788
Iteration 11/1000 | Loss: 0.00001779
Iteration 12/1000 | Loss: 0.00001759
Iteration 13/1000 | Loss: 0.00001749
Iteration 14/1000 | Loss: 0.00001748
Iteration 15/1000 | Loss: 0.00001748
Iteration 16/1000 | Loss: 0.00001733
Iteration 17/1000 | Loss: 0.00001726
Iteration 18/1000 | Loss: 0.00001723
Iteration 19/1000 | Loss: 0.00001723
Iteration 20/1000 | Loss: 0.00001722
Iteration 21/1000 | Loss: 0.00001721
Iteration 22/1000 | Loss: 0.00001716
Iteration 23/1000 | Loss: 0.00001716
Iteration 24/1000 | Loss: 0.00001713
Iteration 25/1000 | Loss: 0.00001712
Iteration 26/1000 | Loss: 0.00001712
Iteration 27/1000 | Loss: 0.00001710
Iteration 28/1000 | Loss: 0.00001710
Iteration 29/1000 | Loss: 0.00001710
Iteration 30/1000 | Loss: 0.00001709
Iteration 31/1000 | Loss: 0.00001709
Iteration 32/1000 | Loss: 0.00001708
Iteration 33/1000 | Loss: 0.00001708
Iteration 34/1000 | Loss: 0.00001707
Iteration 35/1000 | Loss: 0.00001707
Iteration 36/1000 | Loss: 0.00001707
Iteration 37/1000 | Loss: 0.00001706
Iteration 38/1000 | Loss: 0.00001706
Iteration 39/1000 | Loss: 0.00001706
Iteration 40/1000 | Loss: 0.00001705
Iteration 41/1000 | Loss: 0.00001705
Iteration 42/1000 | Loss: 0.00001704
Iteration 43/1000 | Loss: 0.00001704
Iteration 44/1000 | Loss: 0.00001704
Iteration 45/1000 | Loss: 0.00001703
Iteration 46/1000 | Loss: 0.00001703
Iteration 47/1000 | Loss: 0.00001703
Iteration 48/1000 | Loss: 0.00001703
Iteration 49/1000 | Loss: 0.00001702
Iteration 50/1000 | Loss: 0.00001702
Iteration 51/1000 | Loss: 0.00001702
Iteration 52/1000 | Loss: 0.00001701
Iteration 53/1000 | Loss: 0.00001701
Iteration 54/1000 | Loss: 0.00001701
Iteration 55/1000 | Loss: 0.00001701
Iteration 56/1000 | Loss: 0.00001700
Iteration 57/1000 | Loss: 0.00001700
Iteration 58/1000 | Loss: 0.00001700
Iteration 59/1000 | Loss: 0.00001699
Iteration 60/1000 | Loss: 0.00001699
Iteration 61/1000 | Loss: 0.00001698
Iteration 62/1000 | Loss: 0.00001698
Iteration 63/1000 | Loss: 0.00001698
Iteration 64/1000 | Loss: 0.00001697
Iteration 65/1000 | Loss: 0.00001697
Iteration 66/1000 | Loss: 0.00001697
Iteration 67/1000 | Loss: 0.00001696
Iteration 68/1000 | Loss: 0.00001696
Iteration 69/1000 | Loss: 0.00001696
Iteration 70/1000 | Loss: 0.00001696
Iteration 71/1000 | Loss: 0.00001696
Iteration 72/1000 | Loss: 0.00001696
Iteration 73/1000 | Loss: 0.00001695
Iteration 74/1000 | Loss: 0.00001695
Iteration 75/1000 | Loss: 0.00001695
Iteration 76/1000 | Loss: 0.00001695
Iteration 77/1000 | Loss: 0.00001695
Iteration 78/1000 | Loss: 0.00001695
Iteration 79/1000 | Loss: 0.00001695
Iteration 80/1000 | Loss: 0.00001694
Iteration 81/1000 | Loss: 0.00001694
Iteration 82/1000 | Loss: 0.00001694
Iteration 83/1000 | Loss: 0.00001694
Iteration 84/1000 | Loss: 0.00001694
Iteration 85/1000 | Loss: 0.00001693
Iteration 86/1000 | Loss: 0.00001693
Iteration 87/1000 | Loss: 0.00001693
Iteration 88/1000 | Loss: 0.00001693
Iteration 89/1000 | Loss: 0.00001693
Iteration 90/1000 | Loss: 0.00001693
Iteration 91/1000 | Loss: 0.00001693
Iteration 92/1000 | Loss: 0.00001692
Iteration 93/1000 | Loss: 0.00001692
Iteration 94/1000 | Loss: 0.00001692
Iteration 95/1000 | Loss: 0.00001692
Iteration 96/1000 | Loss: 0.00001692
Iteration 97/1000 | Loss: 0.00001692
Iteration 98/1000 | Loss: 0.00001692
Iteration 99/1000 | Loss: 0.00001692
Iteration 100/1000 | Loss: 0.00001691
Iteration 101/1000 | Loss: 0.00001691
Iteration 102/1000 | Loss: 0.00001691
Iteration 103/1000 | Loss: 0.00001691
Iteration 104/1000 | Loss: 0.00001691
Iteration 105/1000 | Loss: 0.00001690
Iteration 106/1000 | Loss: 0.00001690
Iteration 107/1000 | Loss: 0.00001690
Iteration 108/1000 | Loss: 0.00001690
Iteration 109/1000 | Loss: 0.00001690
Iteration 110/1000 | Loss: 0.00001689
Iteration 111/1000 | Loss: 0.00001689
Iteration 112/1000 | Loss: 0.00001689
Iteration 113/1000 | Loss: 0.00001688
Iteration 114/1000 | Loss: 0.00001688
Iteration 115/1000 | Loss: 0.00001688
Iteration 116/1000 | Loss: 0.00001688
Iteration 117/1000 | Loss: 0.00001687
Iteration 118/1000 | Loss: 0.00001687
Iteration 119/1000 | Loss: 0.00001687
Iteration 120/1000 | Loss: 0.00001687
Iteration 121/1000 | Loss: 0.00001686
Iteration 122/1000 | Loss: 0.00001686
Iteration 123/1000 | Loss: 0.00001686
Iteration 124/1000 | Loss: 0.00001686
Iteration 125/1000 | Loss: 0.00001686
Iteration 126/1000 | Loss: 0.00001686
Iteration 127/1000 | Loss: 0.00001686
Iteration 128/1000 | Loss: 0.00001686
Iteration 129/1000 | Loss: 0.00001686
Iteration 130/1000 | Loss: 0.00001686
Iteration 131/1000 | Loss: 0.00001686
Iteration 132/1000 | Loss: 0.00001686
Iteration 133/1000 | Loss: 0.00001686
Iteration 134/1000 | Loss: 0.00001686
Iteration 135/1000 | Loss: 0.00001686
Iteration 136/1000 | Loss: 0.00001686
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 136. Stopping optimization.
Last 5 losses: [1.6858746676007286e-05, 1.6858746676007286e-05, 1.6858746676007286e-05, 1.6858746676007286e-05, 1.6858746676007286e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6858746676007286e-05

Optimization complete. Final v2v error: 3.4362690448760986 mm

Highest mean error: 4.473793983459473 mm for frame 33

Lowest mean error: 2.857326030731201 mm for frame 79

Saving results

Total time: 45.47339200973511
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1069/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1069.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1069
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01044348
Iteration 2/25 | Loss: 0.01044348
Iteration 3/25 | Loss: 0.01044348
Iteration 4/25 | Loss: 0.01044348
Iteration 5/25 | Loss: 0.01044348
Iteration 6/25 | Loss: 0.01044347
Iteration 7/25 | Loss: 0.01044347
Iteration 8/25 | Loss: 0.01044347
Iteration 9/25 | Loss: 0.01044347
Iteration 10/25 | Loss: 0.01044347
Iteration 11/25 | Loss: 0.01044347
Iteration 12/25 | Loss: 0.01044347
Iteration 13/25 | Loss: 0.01044347
Iteration 14/25 | Loss: 0.01044347
Iteration 15/25 | Loss: 0.01044347
Iteration 16/25 | Loss: 0.01044347
Iteration 17/25 | Loss: 0.01044346
Iteration 18/25 | Loss: 0.01044346
Iteration 19/25 | Loss: 0.01044346
Iteration 20/25 | Loss: 0.01044346
Iteration 21/25 | Loss: 0.01044346
Iteration 22/25 | Loss: 0.01044346
Iteration 23/25 | Loss: 0.01044346
Iteration 24/25 | Loss: 0.01044346
Iteration 25/25 | Loss: 0.01044346

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80788612
Iteration 2/25 | Loss: 0.11368274
Iteration 3/25 | Loss: 0.10818468
Iteration 4/25 | Loss: 0.10687171
Iteration 5/25 | Loss: 0.10687171
Iteration 6/25 | Loss: 0.10687172
Iteration 7/25 | Loss: 0.10687172
Iteration 8/25 | Loss: 0.10687172
Iteration 9/25 | Loss: 0.10687172
Iteration 10/25 | Loss: 0.10687172
Iteration 11/25 | Loss: 0.10687172
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.10687171667814255, 0.10687171667814255, 0.10687171667814255, 0.10687171667814255, 0.10687171667814255]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.10687171667814255

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.10687172
Iteration 2/1000 | Loss: 0.00345945
Iteration 3/1000 | Loss: 0.00725907
Iteration 4/1000 | Loss: 0.00179640
Iteration 5/1000 | Loss: 0.00124538
Iteration 6/1000 | Loss: 0.00031762
Iteration 7/1000 | Loss: 0.00050998
Iteration 8/1000 | Loss: 0.00008855
Iteration 9/1000 | Loss: 0.00013175
Iteration 10/1000 | Loss: 0.00017780
Iteration 11/1000 | Loss: 0.00060404
Iteration 12/1000 | Loss: 0.00006389
Iteration 13/1000 | Loss: 0.00081470
Iteration 14/1000 | Loss: 0.00028106
Iteration 15/1000 | Loss: 0.00006653
Iteration 16/1000 | Loss: 0.00014156
Iteration 17/1000 | Loss: 0.00004656
Iteration 18/1000 | Loss: 0.00021100
Iteration 19/1000 | Loss: 0.00012785
Iteration 20/1000 | Loss: 0.00004123
Iteration 21/1000 | Loss: 0.00005336
Iteration 22/1000 | Loss: 0.00014918
Iteration 23/1000 | Loss: 0.00026526
Iteration 24/1000 | Loss: 0.00005585
Iteration 25/1000 | Loss: 0.00005697
Iteration 26/1000 | Loss: 0.00014005
Iteration 27/1000 | Loss: 0.00003228
Iteration 28/1000 | Loss: 0.00008470
Iteration 29/1000 | Loss: 0.00005908
Iteration 30/1000 | Loss: 0.00006620
Iteration 31/1000 | Loss: 0.00001973
Iteration 32/1000 | Loss: 0.00009664
Iteration 33/1000 | Loss: 0.00002839
Iteration 34/1000 | Loss: 0.00005982
Iteration 35/1000 | Loss: 0.00002109
Iteration 36/1000 | Loss: 0.00006895
Iteration 37/1000 | Loss: 0.00007448
Iteration 38/1000 | Loss: 0.00002628
Iteration 39/1000 | Loss: 0.00002158
Iteration 40/1000 | Loss: 0.00007538
Iteration 41/1000 | Loss: 0.00009153
Iteration 42/1000 | Loss: 0.00060482
Iteration 43/1000 | Loss: 0.00002966
Iteration 44/1000 | Loss: 0.00003764
Iteration 45/1000 | Loss: 0.00003918
Iteration 46/1000 | Loss: 0.00002166
Iteration 47/1000 | Loss: 0.00003522
Iteration 48/1000 | Loss: 0.00006770
Iteration 49/1000 | Loss: 0.00017679
Iteration 50/1000 | Loss: 0.00007535
Iteration 51/1000 | Loss: 0.00022377
Iteration 52/1000 | Loss: 0.00004851
Iteration 53/1000 | Loss: 0.00002815
Iteration 54/1000 | Loss: 0.00001747
Iteration 55/1000 | Loss: 0.00001950
Iteration 56/1000 | Loss: 0.00001694
Iteration 57/1000 | Loss: 0.00001685
Iteration 58/1000 | Loss: 0.00001685
Iteration 59/1000 | Loss: 0.00001685
Iteration 60/1000 | Loss: 0.00001685
Iteration 61/1000 | Loss: 0.00001684
Iteration 62/1000 | Loss: 0.00001849
Iteration 63/1000 | Loss: 0.00002120
Iteration 64/1000 | Loss: 0.00002364
Iteration 65/1000 | Loss: 0.00001819
Iteration 66/1000 | Loss: 0.00001819
Iteration 67/1000 | Loss: 0.00005097
Iteration 68/1000 | Loss: 0.00001740
Iteration 69/1000 | Loss: 0.00002060
Iteration 70/1000 | Loss: 0.00001693
Iteration 71/1000 | Loss: 0.00001676
Iteration 72/1000 | Loss: 0.00001676
Iteration 73/1000 | Loss: 0.00001676
Iteration 74/1000 | Loss: 0.00001676
Iteration 75/1000 | Loss: 0.00001676
Iteration 76/1000 | Loss: 0.00001675
Iteration 77/1000 | Loss: 0.00001675
Iteration 78/1000 | Loss: 0.00001675
Iteration 79/1000 | Loss: 0.00001675
Iteration 80/1000 | Loss: 0.00001675
Iteration 81/1000 | Loss: 0.00001675
Iteration 82/1000 | Loss: 0.00001675
Iteration 83/1000 | Loss: 0.00001675
Iteration 84/1000 | Loss: 0.00001674
Iteration 85/1000 | Loss: 0.00001674
Iteration 86/1000 | Loss: 0.00001674
Iteration 87/1000 | Loss: 0.00001674
Iteration 88/1000 | Loss: 0.00001674
Iteration 89/1000 | Loss: 0.00001674
Iteration 90/1000 | Loss: 0.00001674
Iteration 91/1000 | Loss: 0.00001674
Iteration 92/1000 | Loss: 0.00001674
Iteration 93/1000 | Loss: 0.00001674
Iteration 94/1000 | Loss: 0.00001674
Iteration 95/1000 | Loss: 0.00001674
Iteration 96/1000 | Loss: 0.00001673
Iteration 97/1000 | Loss: 0.00002027
Iteration 98/1000 | Loss: 0.00001801
Iteration 99/1000 | Loss: 0.00002288
Iteration 100/1000 | Loss: 0.00001687
Iteration 101/1000 | Loss: 0.00001670
Iteration 102/1000 | Loss: 0.00001670
Iteration 103/1000 | Loss: 0.00001670
Iteration 104/1000 | Loss: 0.00001670
Iteration 105/1000 | Loss: 0.00001670
Iteration 106/1000 | Loss: 0.00001670
Iteration 107/1000 | Loss: 0.00001670
Iteration 108/1000 | Loss: 0.00001669
Iteration 109/1000 | Loss: 0.00001669
Iteration 110/1000 | Loss: 0.00001669
Iteration 111/1000 | Loss: 0.00001669
Iteration 112/1000 | Loss: 0.00001669
Iteration 113/1000 | Loss: 0.00001669
Iteration 114/1000 | Loss: 0.00001669
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 114. Stopping optimization.
Last 5 losses: [1.6694661098881625e-05, 1.6694661098881625e-05, 1.6694661098881625e-05, 1.6694661098881625e-05, 1.6694661098881625e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6694661098881625e-05

Optimization complete. Final v2v error: 3.450631856918335 mm

Highest mean error: 3.6252129077911377 mm for frame 180

Lowest mean error: 3.2459867000579834 mm for frame 218

Saving results

Total time: 108.95537114143372
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01062396
Iteration 2/25 | Loss: 0.00240861
Iteration 3/25 | Loss: 0.00155429
Iteration 4/25 | Loss: 0.00125752
Iteration 5/25 | Loss: 0.00115968
Iteration 6/25 | Loss: 0.00113034
Iteration 7/25 | Loss: 0.00111691
Iteration 8/25 | Loss: 0.00109860
Iteration 9/25 | Loss: 0.00106004
Iteration 10/25 | Loss: 0.00103544
Iteration 11/25 | Loss: 0.00103676
Iteration 12/25 | Loss: 0.00104439
Iteration 13/25 | Loss: 0.00101636
Iteration 14/25 | Loss: 0.00100797
Iteration 15/25 | Loss: 0.00101125
Iteration 16/25 | Loss: 0.00099857
Iteration 17/25 | Loss: 0.00095870
Iteration 18/25 | Loss: 0.00094631
Iteration 19/25 | Loss: 0.00094287
Iteration 20/25 | Loss: 0.00093284
Iteration 21/25 | Loss: 0.00093370
Iteration 22/25 | Loss: 0.00093117
Iteration 23/25 | Loss: 0.00092551
Iteration 24/25 | Loss: 0.00092206
Iteration 25/25 | Loss: 0.00092697

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54544795
Iteration 2/25 | Loss: 0.00086865
Iteration 3/25 | Loss: 0.00086865
Iteration 4/25 | Loss: 0.00080967
Iteration 5/25 | Loss: 0.00080967
Iteration 6/25 | Loss: 0.00080967
Iteration 7/25 | Loss: 0.00080966
Iteration 8/25 | Loss: 0.00080966
Iteration 9/25 | Loss: 0.00080966
Iteration 10/25 | Loss: 0.00080966
Iteration 11/25 | Loss: 0.00080966
Iteration 12/25 | Loss: 0.00080966
Iteration 13/25 | Loss: 0.00080966
Iteration 14/25 | Loss: 0.00080966
Iteration 15/25 | Loss: 0.00080966
Iteration 16/25 | Loss: 0.00080966
Iteration 17/25 | Loss: 0.00080966
Iteration 18/25 | Loss: 0.00080966
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0008096634992398322, 0.0008096634992398322, 0.0008096634992398322, 0.0008096634992398322, 0.0008096634992398322]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008096634992398322

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00080966
Iteration 2/1000 | Loss: 0.00024020
Iteration 3/1000 | Loss: 0.00056509
Iteration 4/1000 | Loss: 0.00110771
Iteration 5/1000 | Loss: 0.00032581
Iteration 6/1000 | Loss: 0.00047930
Iteration 7/1000 | Loss: 0.00043295
Iteration 8/1000 | Loss: 0.00043172
Iteration 9/1000 | Loss: 0.00043209
Iteration 10/1000 | Loss: 0.00076393
Iteration 11/1000 | Loss: 0.00030654
Iteration 12/1000 | Loss: 0.00025147
Iteration 13/1000 | Loss: 0.00023589
Iteration 14/1000 | Loss: 0.00023605
Iteration 15/1000 | Loss: 0.00041083
Iteration 16/1000 | Loss: 0.00072532
Iteration 17/1000 | Loss: 0.00081404
Iteration 18/1000 | Loss: 0.00125081
Iteration 19/1000 | Loss: 0.00029787
Iteration 20/1000 | Loss: 0.00045930
Iteration 21/1000 | Loss: 0.00030032
Iteration 22/1000 | Loss: 0.00021823
Iteration 23/1000 | Loss: 0.00031669
Iteration 24/1000 | Loss: 0.00027894
Iteration 25/1000 | Loss: 0.00012116
Iteration 26/1000 | Loss: 0.00020350
Iteration 27/1000 | Loss: 0.00027951
Iteration 28/1000 | Loss: 0.00019478
Iteration 29/1000 | Loss: 0.00028931
Iteration 30/1000 | Loss: 0.00030434
Iteration 31/1000 | Loss: 0.00030487
Iteration 32/1000 | Loss: 0.00041726
Iteration 33/1000 | Loss: 0.00029875
Iteration 34/1000 | Loss: 0.00030604
Iteration 35/1000 | Loss: 0.00037879
Iteration 36/1000 | Loss: 0.00187978
Iteration 37/1000 | Loss: 0.00040104
Iteration 38/1000 | Loss: 0.00046996
Iteration 39/1000 | Loss: 0.00022714
Iteration 40/1000 | Loss: 0.00029140
Iteration 41/1000 | Loss: 0.00039552
Iteration 42/1000 | Loss: 0.00026441
Iteration 43/1000 | Loss: 0.00024172
Iteration 44/1000 | Loss: 0.00040513
Iteration 45/1000 | Loss: 0.00028596
Iteration 46/1000 | Loss: 0.00031131
Iteration 47/1000 | Loss: 0.00120253
Iteration 48/1000 | Loss: 0.00006254
Iteration 49/1000 | Loss: 0.00004191
Iteration 50/1000 | Loss: 0.00012923
Iteration 51/1000 | Loss: 0.00004347
Iteration 52/1000 | Loss: 0.00018518
Iteration 53/1000 | Loss: 0.00007972
Iteration 54/1000 | Loss: 0.00007854
Iteration 55/1000 | Loss: 0.00004886
Iteration 56/1000 | Loss: 0.00003345
Iteration 57/1000 | Loss: 0.00019462
Iteration 58/1000 | Loss: 0.00009969
Iteration 59/1000 | Loss: 0.00017544
Iteration 60/1000 | Loss: 0.00015050
Iteration 61/1000 | Loss: 0.00024704
Iteration 62/1000 | Loss: 0.00038339
Iteration 63/1000 | Loss: 0.00025374
Iteration 64/1000 | Loss: 0.00065310
Iteration 65/1000 | Loss: 0.00011519
Iteration 66/1000 | Loss: 0.00004404
Iteration 67/1000 | Loss: 0.00014112
Iteration 68/1000 | Loss: 0.00004585
Iteration 69/1000 | Loss: 0.00003231
Iteration 70/1000 | Loss: 0.00003050
Iteration 71/1000 | Loss: 0.00002993
Iteration 72/1000 | Loss: 0.00004025
Iteration 73/1000 | Loss: 0.00003005
Iteration 74/1000 | Loss: 0.00002900
Iteration 75/1000 | Loss: 0.00002814
Iteration 76/1000 | Loss: 0.00002735
Iteration 77/1000 | Loss: 0.00017937
Iteration 78/1000 | Loss: 0.00091658
Iteration 79/1000 | Loss: 0.00344855
Iteration 80/1000 | Loss: 0.00020403
Iteration 81/1000 | Loss: 0.00160952
Iteration 82/1000 | Loss: 0.00051189
Iteration 83/1000 | Loss: 0.00131176
Iteration 84/1000 | Loss: 0.00032367
Iteration 85/1000 | Loss: 0.00002930
Iteration 86/1000 | Loss: 0.00002748
Iteration 87/1000 | Loss: 0.00002665
Iteration 88/1000 | Loss: 0.00002621
Iteration 89/1000 | Loss: 0.00002609
Iteration 90/1000 | Loss: 0.00027005
Iteration 91/1000 | Loss: 0.00003537
Iteration 92/1000 | Loss: 0.00002595
Iteration 93/1000 | Loss: 0.00003901
Iteration 94/1000 | Loss: 0.00003291
Iteration 95/1000 | Loss: 0.00002583
Iteration 96/1000 | Loss: 0.00002582
Iteration 97/1000 | Loss: 0.00002582
Iteration 98/1000 | Loss: 0.00002582
Iteration 99/1000 | Loss: 0.00002582
Iteration 100/1000 | Loss: 0.00002582
Iteration 101/1000 | Loss: 0.00002582
Iteration 102/1000 | Loss: 0.00002581
Iteration 103/1000 | Loss: 0.00002581
Iteration 104/1000 | Loss: 0.00002581
Iteration 105/1000 | Loss: 0.00002579
Iteration 106/1000 | Loss: 0.00002579
Iteration 107/1000 | Loss: 0.00002573
Iteration 108/1000 | Loss: 0.00002573
Iteration 109/1000 | Loss: 0.00002571
Iteration 110/1000 | Loss: 0.00002571
Iteration 111/1000 | Loss: 0.00002569
Iteration 112/1000 | Loss: 0.00002569
Iteration 113/1000 | Loss: 0.00002569
Iteration 114/1000 | Loss: 0.00002569
Iteration 115/1000 | Loss: 0.00002569
Iteration 116/1000 | Loss: 0.00002569
Iteration 117/1000 | Loss: 0.00002569
Iteration 118/1000 | Loss: 0.00002569
Iteration 119/1000 | Loss: 0.00002569
Iteration 120/1000 | Loss: 0.00002569
Iteration 121/1000 | Loss: 0.00002569
Iteration 122/1000 | Loss: 0.00002568
Iteration 123/1000 | Loss: 0.00002568
Iteration 124/1000 | Loss: 0.00002567
Iteration 125/1000 | Loss: 0.00002567
Iteration 126/1000 | Loss: 0.00002566
Iteration 127/1000 | Loss: 0.00002566
Iteration 128/1000 | Loss: 0.00002566
Iteration 129/1000 | Loss: 0.00002566
Iteration 130/1000 | Loss: 0.00002565
Iteration 131/1000 | Loss: 0.00002565
Iteration 132/1000 | Loss: 0.00002565
Iteration 133/1000 | Loss: 0.00002565
Iteration 134/1000 | Loss: 0.00002565
Iteration 135/1000 | Loss: 0.00002565
Iteration 136/1000 | Loss: 0.00002565
Iteration 137/1000 | Loss: 0.00002564
Iteration 138/1000 | Loss: 0.00002564
Iteration 139/1000 | Loss: 0.00002564
Iteration 140/1000 | Loss: 0.00002564
Iteration 141/1000 | Loss: 0.00002564
Iteration 142/1000 | Loss: 0.00002564
Iteration 143/1000 | Loss: 0.00002563
Iteration 144/1000 | Loss: 0.00002563
Iteration 145/1000 | Loss: 0.00002563
Iteration 146/1000 | Loss: 0.00002563
Iteration 147/1000 | Loss: 0.00002562
Iteration 148/1000 | Loss: 0.00002562
Iteration 149/1000 | Loss: 0.00002562
Iteration 150/1000 | Loss: 0.00002562
Iteration 151/1000 | Loss: 0.00002562
Iteration 152/1000 | Loss: 0.00002561
Iteration 153/1000 | Loss: 0.00002561
Iteration 154/1000 | Loss: 0.00002561
Iteration 155/1000 | Loss: 0.00002561
Iteration 156/1000 | Loss: 0.00002561
Iteration 157/1000 | Loss: 0.00002561
Iteration 158/1000 | Loss: 0.00002561
Iteration 159/1000 | Loss: 0.00002561
Iteration 160/1000 | Loss: 0.00002561
Iteration 161/1000 | Loss: 0.00002561
Iteration 162/1000 | Loss: 0.00002561
Iteration 163/1000 | Loss: 0.00002561
Iteration 164/1000 | Loss: 0.00002560
Iteration 165/1000 | Loss: 0.00002560
Iteration 166/1000 | Loss: 0.00002560
Iteration 167/1000 | Loss: 0.00002560
Iteration 168/1000 | Loss: 0.00002560
Iteration 169/1000 | Loss: 0.00002560
Iteration 170/1000 | Loss: 0.00002560
Iteration 171/1000 | Loss: 0.00002560
Iteration 172/1000 | Loss: 0.00002560
Iteration 173/1000 | Loss: 0.00002560
Iteration 174/1000 | Loss: 0.00002560
Iteration 175/1000 | Loss: 0.00002560
Iteration 176/1000 | Loss: 0.00002560
Iteration 177/1000 | Loss: 0.00002560
Iteration 178/1000 | Loss: 0.00002560
Iteration 179/1000 | Loss: 0.00002560
Iteration 180/1000 | Loss: 0.00002560
Iteration 181/1000 | Loss: 0.00002560
Iteration 182/1000 | Loss: 0.00002560
Iteration 183/1000 | Loss: 0.00002560
Iteration 184/1000 | Loss: 0.00002559
Iteration 185/1000 | Loss: 0.00002559
Iteration 186/1000 | Loss: 0.00002559
Iteration 187/1000 | Loss: 0.00002559
Iteration 188/1000 | Loss: 0.00002559
Iteration 189/1000 | Loss: 0.00002559
Iteration 190/1000 | Loss: 0.00002559
Iteration 191/1000 | Loss: 0.00002559
Iteration 192/1000 | Loss: 0.00002559
Iteration 193/1000 | Loss: 0.00002559
Iteration 194/1000 | Loss: 0.00002559
Iteration 195/1000 | Loss: 0.00002559
Iteration 196/1000 | Loss: 0.00002559
Iteration 197/1000 | Loss: 0.00002559
Iteration 198/1000 | Loss: 0.00002559
Iteration 199/1000 | Loss: 0.00002559
Iteration 200/1000 | Loss: 0.00002558
Iteration 201/1000 | Loss: 0.00002558
Iteration 202/1000 | Loss: 0.00002558
Iteration 203/1000 | Loss: 0.00002558
Iteration 204/1000 | Loss: 0.00002558
Iteration 205/1000 | Loss: 0.00002558
Iteration 206/1000 | Loss: 0.00002558
Iteration 207/1000 | Loss: 0.00002558
Iteration 208/1000 | Loss: 0.00002558
Iteration 209/1000 | Loss: 0.00002558
Iteration 210/1000 | Loss: 0.00002558
Iteration 211/1000 | Loss: 0.00002558
Iteration 212/1000 | Loss: 0.00002558
Iteration 213/1000 | Loss: 0.00002558
Iteration 214/1000 | Loss: 0.00002558
Iteration 215/1000 | Loss: 0.00002558
Iteration 216/1000 | Loss: 0.00002557
Iteration 217/1000 | Loss: 0.00002557
Iteration 218/1000 | Loss: 0.00002557
Iteration 219/1000 | Loss: 0.00002557
Iteration 220/1000 | Loss: 0.00002557
Iteration 221/1000 | Loss: 0.00002557
Iteration 222/1000 | Loss: 0.00002557
Iteration 223/1000 | Loss: 0.00002557
Iteration 224/1000 | Loss: 0.00002557
Iteration 225/1000 | Loss: 0.00002557
Iteration 226/1000 | Loss: 0.00002557
Iteration 227/1000 | Loss: 0.00002557
Iteration 228/1000 | Loss: 0.00002557
Iteration 229/1000 | Loss: 0.00002557
Iteration 230/1000 | Loss: 0.00002556
Iteration 231/1000 | Loss: 0.00002556
Iteration 232/1000 | Loss: 0.00002556
Iteration 233/1000 | Loss: 0.00002556
Iteration 234/1000 | Loss: 0.00002556
Iteration 235/1000 | Loss: 0.00002556
Iteration 236/1000 | Loss: 0.00002556
Iteration 237/1000 | Loss: 0.00002556
Iteration 238/1000 | Loss: 0.00002556
Iteration 239/1000 | Loss: 0.00002556
Iteration 240/1000 | Loss: 0.00002556
Iteration 241/1000 | Loss: 0.00002556
Iteration 242/1000 | Loss: 0.00002556
Iteration 243/1000 | Loss: 0.00002556
Iteration 244/1000 | Loss: 0.00002556
Iteration 245/1000 | Loss: 0.00002556
Iteration 246/1000 | Loss: 0.00002556
Iteration 247/1000 | Loss: 0.00002556
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 247. Stopping optimization.
Last 5 losses: [2.556275467213709e-05, 2.556275467213709e-05, 2.556275467213709e-05, 2.556275467213709e-05, 2.556275467213709e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.556275467213709e-05

Optimization complete. Final v2v error: 4.1958465576171875 mm

Highest mean error: 5.87957239151001 mm for frame 65

Lowest mean error: 3.6427574157714844 mm for frame 195

Saving results

Total time: 197.71943616867065
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1027/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1027.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1027
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00905102
Iteration 2/25 | Loss: 0.00104994
Iteration 3/25 | Loss: 0.00087312
Iteration 4/25 | Loss: 0.00082507
Iteration 5/25 | Loss: 0.00081415
Iteration 6/25 | Loss: 0.00081098
Iteration 7/25 | Loss: 0.00081012
Iteration 8/25 | Loss: 0.00081011
Iteration 9/25 | Loss: 0.00081011
Iteration 10/25 | Loss: 0.00081011
Iteration 11/25 | Loss: 0.00081011
Iteration 12/25 | Loss: 0.00081011
Iteration 13/25 | Loss: 0.00081011
Iteration 14/25 | Loss: 0.00081011
Iteration 15/25 | Loss: 0.00081011
Iteration 16/25 | Loss: 0.00081011
Iteration 17/25 | Loss: 0.00081011
Iteration 18/25 | Loss: 0.00081011
Iteration 19/25 | Loss: 0.00081011
Iteration 20/25 | Loss: 0.00081011
Iteration 21/25 | Loss: 0.00081011
Iteration 22/25 | Loss: 0.00081011
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0008101118146441877, 0.0008101118146441877, 0.0008101118146441877, 0.0008101118146441877, 0.0008101118146441877]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008101118146441877

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48353291
Iteration 2/25 | Loss: 0.00043660
Iteration 3/25 | Loss: 0.00043656
Iteration 4/25 | Loss: 0.00043656
Iteration 5/25 | Loss: 0.00043656
Iteration 6/25 | Loss: 0.00043656
Iteration 7/25 | Loss: 0.00043656
Iteration 8/25 | Loss: 0.00043656
Iteration 9/25 | Loss: 0.00043656
Iteration 10/25 | Loss: 0.00043656
Iteration 11/25 | Loss: 0.00043656
Iteration 12/25 | Loss: 0.00043656
Iteration 13/25 | Loss: 0.00043656
Iteration 14/25 | Loss: 0.00043656
Iteration 15/25 | Loss: 0.00043656
Iteration 16/25 | Loss: 0.00043656
Iteration 17/25 | Loss: 0.00043656
Iteration 18/25 | Loss: 0.00043656
Iteration 19/25 | Loss: 0.00043656
Iteration 20/25 | Loss: 0.00043656
Iteration 21/25 | Loss: 0.00043656
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0004365608037915081, 0.0004365608037915081, 0.0004365608037915081, 0.0004365608037915081, 0.0004365608037915081]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004365608037915081

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043656
Iteration 2/1000 | Loss: 0.00005152
Iteration 3/1000 | Loss: 0.00003800
Iteration 4/1000 | Loss: 0.00003160
Iteration 5/1000 | Loss: 0.00003000
Iteration 6/1000 | Loss: 0.00002858
Iteration 7/1000 | Loss: 0.00002742
Iteration 8/1000 | Loss: 0.00002669
Iteration 9/1000 | Loss: 0.00002602
Iteration 10/1000 | Loss: 0.00002567
Iteration 11/1000 | Loss: 0.00002546
Iteration 12/1000 | Loss: 0.00002523
Iteration 13/1000 | Loss: 0.00002504
Iteration 14/1000 | Loss: 0.00002491
Iteration 15/1000 | Loss: 0.00002483
Iteration 16/1000 | Loss: 0.00002478
Iteration 17/1000 | Loss: 0.00002478
Iteration 18/1000 | Loss: 0.00002477
Iteration 19/1000 | Loss: 0.00002477
Iteration 20/1000 | Loss: 0.00002476
Iteration 21/1000 | Loss: 0.00002474
Iteration 22/1000 | Loss: 0.00002474
Iteration 23/1000 | Loss: 0.00002472
Iteration 24/1000 | Loss: 0.00002472
Iteration 25/1000 | Loss: 0.00002471
Iteration 26/1000 | Loss: 0.00002471
Iteration 27/1000 | Loss: 0.00002471
Iteration 28/1000 | Loss: 0.00002471
Iteration 29/1000 | Loss: 0.00002471
Iteration 30/1000 | Loss: 0.00002470
Iteration 31/1000 | Loss: 0.00002470
Iteration 32/1000 | Loss: 0.00002470
Iteration 33/1000 | Loss: 0.00002469
Iteration 34/1000 | Loss: 0.00002469
Iteration 35/1000 | Loss: 0.00002468
Iteration 36/1000 | Loss: 0.00002468
Iteration 37/1000 | Loss: 0.00002468
Iteration 38/1000 | Loss: 0.00002467
Iteration 39/1000 | Loss: 0.00002467
Iteration 40/1000 | Loss: 0.00002467
Iteration 41/1000 | Loss: 0.00002467
Iteration 42/1000 | Loss: 0.00002466
Iteration 43/1000 | Loss: 0.00002465
Iteration 44/1000 | Loss: 0.00002465
Iteration 45/1000 | Loss: 0.00002465
Iteration 46/1000 | Loss: 0.00002464
Iteration 47/1000 | Loss: 0.00002464
Iteration 48/1000 | Loss: 0.00002464
Iteration 49/1000 | Loss: 0.00002463
Iteration 50/1000 | Loss: 0.00002463
Iteration 51/1000 | Loss: 0.00002463
Iteration 52/1000 | Loss: 0.00002462
Iteration 53/1000 | Loss: 0.00002462
Iteration 54/1000 | Loss: 0.00002461
Iteration 55/1000 | Loss: 0.00002461
Iteration 56/1000 | Loss: 0.00002461
Iteration 57/1000 | Loss: 0.00002461
Iteration 58/1000 | Loss: 0.00002461
Iteration 59/1000 | Loss: 0.00002460
Iteration 60/1000 | Loss: 0.00002460
Iteration 61/1000 | Loss: 0.00002460
Iteration 62/1000 | Loss: 0.00002460
Iteration 63/1000 | Loss: 0.00002459
Iteration 64/1000 | Loss: 0.00002459
Iteration 65/1000 | Loss: 0.00002459
Iteration 66/1000 | Loss: 0.00002458
Iteration 67/1000 | Loss: 0.00002458
Iteration 68/1000 | Loss: 0.00002457
Iteration 69/1000 | Loss: 0.00002457
Iteration 70/1000 | Loss: 0.00002457
Iteration 71/1000 | Loss: 0.00002457
Iteration 72/1000 | Loss: 0.00002457
Iteration 73/1000 | Loss: 0.00002457
Iteration 74/1000 | Loss: 0.00002457
Iteration 75/1000 | Loss: 0.00002457
Iteration 76/1000 | Loss: 0.00002456
Iteration 77/1000 | Loss: 0.00002456
Iteration 78/1000 | Loss: 0.00002456
Iteration 79/1000 | Loss: 0.00002456
Iteration 80/1000 | Loss: 0.00002455
Iteration 81/1000 | Loss: 0.00002455
Iteration 82/1000 | Loss: 0.00002455
Iteration 83/1000 | Loss: 0.00002454
Iteration 84/1000 | Loss: 0.00002454
Iteration 85/1000 | Loss: 0.00002454
Iteration 86/1000 | Loss: 0.00002454
Iteration 87/1000 | Loss: 0.00002453
Iteration 88/1000 | Loss: 0.00002453
Iteration 89/1000 | Loss: 0.00002453
Iteration 90/1000 | Loss: 0.00002453
Iteration 91/1000 | Loss: 0.00002453
Iteration 92/1000 | Loss: 0.00002453
Iteration 93/1000 | Loss: 0.00002452
Iteration 94/1000 | Loss: 0.00002452
Iteration 95/1000 | Loss: 0.00002451
Iteration 96/1000 | Loss: 0.00002451
Iteration 97/1000 | Loss: 0.00002451
Iteration 98/1000 | Loss: 0.00002451
Iteration 99/1000 | Loss: 0.00002451
Iteration 100/1000 | Loss: 0.00002451
Iteration 101/1000 | Loss: 0.00002451
Iteration 102/1000 | Loss: 0.00002450
Iteration 103/1000 | Loss: 0.00002450
Iteration 104/1000 | Loss: 0.00002450
Iteration 105/1000 | Loss: 0.00002450
Iteration 106/1000 | Loss: 0.00002450
Iteration 107/1000 | Loss: 0.00002450
Iteration 108/1000 | Loss: 0.00002450
Iteration 109/1000 | Loss: 0.00002450
Iteration 110/1000 | Loss: 0.00002450
Iteration 111/1000 | Loss: 0.00002450
Iteration 112/1000 | Loss: 0.00002450
Iteration 113/1000 | Loss: 0.00002449
Iteration 114/1000 | Loss: 0.00002449
Iteration 115/1000 | Loss: 0.00002449
Iteration 116/1000 | Loss: 0.00002449
Iteration 117/1000 | Loss: 0.00002449
Iteration 118/1000 | Loss: 0.00002449
Iteration 119/1000 | Loss: 0.00002449
Iteration 120/1000 | Loss: 0.00002449
Iteration 121/1000 | Loss: 0.00002449
Iteration 122/1000 | Loss: 0.00002449
Iteration 123/1000 | Loss: 0.00002449
Iteration 124/1000 | Loss: 0.00002449
Iteration 125/1000 | Loss: 0.00002449
Iteration 126/1000 | Loss: 0.00002449
Iteration 127/1000 | Loss: 0.00002449
Iteration 128/1000 | Loss: 0.00002449
Iteration 129/1000 | Loss: 0.00002449
Iteration 130/1000 | Loss: 0.00002449
Iteration 131/1000 | Loss: 0.00002449
Iteration 132/1000 | Loss: 0.00002449
Iteration 133/1000 | Loss: 0.00002449
Iteration 134/1000 | Loss: 0.00002449
Iteration 135/1000 | Loss: 0.00002449
Iteration 136/1000 | Loss: 0.00002449
Iteration 137/1000 | Loss: 0.00002449
Iteration 138/1000 | Loss: 0.00002449
Iteration 139/1000 | Loss: 0.00002449
Iteration 140/1000 | Loss: 0.00002449
Iteration 141/1000 | Loss: 0.00002449
Iteration 142/1000 | Loss: 0.00002449
Iteration 143/1000 | Loss: 0.00002449
Iteration 144/1000 | Loss: 0.00002449
Iteration 145/1000 | Loss: 0.00002449
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [2.4488032067893073e-05, 2.4488032067893073e-05, 2.4488032067893073e-05, 2.4488032067893073e-05, 2.4488032067893073e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4488032067893073e-05

Optimization complete. Final v2v error: 4.049513816833496 mm

Highest mean error: 5.646362781524658 mm for frame 68

Lowest mean error: 3.301182508468628 mm for frame 98

Saving results

Total time: 40.32555103302002
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00419925
Iteration 2/25 | Loss: 0.00088134
Iteration 3/25 | Loss: 0.00077658
Iteration 4/25 | Loss: 0.00076832
Iteration 5/25 | Loss: 0.00076554
Iteration 6/25 | Loss: 0.00076513
Iteration 7/25 | Loss: 0.00076513
Iteration 8/25 | Loss: 0.00076513
Iteration 9/25 | Loss: 0.00076513
Iteration 10/25 | Loss: 0.00076513
Iteration 11/25 | Loss: 0.00076513
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007651266059838235, 0.0007651266059838235, 0.0007651266059838235, 0.0007651266059838235, 0.0007651266059838235]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007651266059838235

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51560080
Iteration 2/25 | Loss: 0.00050680
Iteration 3/25 | Loss: 0.00050680
Iteration 4/25 | Loss: 0.00050680
Iteration 5/25 | Loss: 0.00050680
Iteration 6/25 | Loss: 0.00050680
Iteration 7/25 | Loss: 0.00050680
Iteration 8/25 | Loss: 0.00050680
Iteration 9/25 | Loss: 0.00050680
Iteration 10/25 | Loss: 0.00050680
Iteration 11/25 | Loss: 0.00050680
Iteration 12/25 | Loss: 0.00050680
Iteration 13/25 | Loss: 0.00050680
Iteration 14/25 | Loss: 0.00050680
Iteration 15/25 | Loss: 0.00050680
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0005068012978881598, 0.0005068012978881598, 0.0005068012978881598, 0.0005068012978881598, 0.0005068012978881598]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005068012978881598

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050680
Iteration 2/1000 | Loss: 0.00001842
Iteration 3/1000 | Loss: 0.00001524
Iteration 4/1000 | Loss: 0.00001451
Iteration 5/1000 | Loss: 0.00001390
Iteration 6/1000 | Loss: 0.00001365
Iteration 7/1000 | Loss: 0.00001341
Iteration 8/1000 | Loss: 0.00001335
Iteration 9/1000 | Loss: 0.00001325
Iteration 10/1000 | Loss: 0.00001325
Iteration 11/1000 | Loss: 0.00001320
Iteration 12/1000 | Loss: 0.00001320
Iteration 13/1000 | Loss: 0.00001320
Iteration 14/1000 | Loss: 0.00001319
Iteration 15/1000 | Loss: 0.00001319
Iteration 16/1000 | Loss: 0.00001319
Iteration 17/1000 | Loss: 0.00001319
Iteration 18/1000 | Loss: 0.00001318
Iteration 19/1000 | Loss: 0.00001317
Iteration 20/1000 | Loss: 0.00001317
Iteration 21/1000 | Loss: 0.00001316
Iteration 22/1000 | Loss: 0.00001315
Iteration 23/1000 | Loss: 0.00001315
Iteration 24/1000 | Loss: 0.00001315
Iteration 25/1000 | Loss: 0.00001313
Iteration 26/1000 | Loss: 0.00001313
Iteration 27/1000 | Loss: 0.00001313
Iteration 28/1000 | Loss: 0.00001313
Iteration 29/1000 | Loss: 0.00001312
Iteration 30/1000 | Loss: 0.00001312
Iteration 31/1000 | Loss: 0.00001312
Iteration 32/1000 | Loss: 0.00001312
Iteration 33/1000 | Loss: 0.00001312
Iteration 34/1000 | Loss: 0.00001312
Iteration 35/1000 | Loss: 0.00001312
Iteration 36/1000 | Loss: 0.00001312
Iteration 37/1000 | Loss: 0.00001312
Iteration 38/1000 | Loss: 0.00001311
Iteration 39/1000 | Loss: 0.00001311
Iteration 40/1000 | Loss: 0.00001311
Iteration 41/1000 | Loss: 0.00001311
Iteration 42/1000 | Loss: 0.00001310
Iteration 43/1000 | Loss: 0.00001309
Iteration 44/1000 | Loss: 0.00001309
Iteration 45/1000 | Loss: 0.00001309
Iteration 46/1000 | Loss: 0.00001309
Iteration 47/1000 | Loss: 0.00001308
Iteration 48/1000 | Loss: 0.00001308
Iteration 49/1000 | Loss: 0.00001308
Iteration 50/1000 | Loss: 0.00001308
Iteration 51/1000 | Loss: 0.00001308
Iteration 52/1000 | Loss: 0.00001308
Iteration 53/1000 | Loss: 0.00001308
Iteration 54/1000 | Loss: 0.00001308
Iteration 55/1000 | Loss: 0.00001308
Iteration 56/1000 | Loss: 0.00001308
Iteration 57/1000 | Loss: 0.00001308
Iteration 58/1000 | Loss: 0.00001307
Iteration 59/1000 | Loss: 0.00001307
Iteration 60/1000 | Loss: 0.00001307
Iteration 61/1000 | Loss: 0.00001307
Iteration 62/1000 | Loss: 0.00001307
Iteration 63/1000 | Loss: 0.00001307
Iteration 64/1000 | Loss: 0.00001307
Iteration 65/1000 | Loss: 0.00001307
Iteration 66/1000 | Loss: 0.00001307
Iteration 67/1000 | Loss: 0.00001307
Iteration 68/1000 | Loss: 0.00001307
Iteration 69/1000 | Loss: 0.00001307
Iteration 70/1000 | Loss: 0.00001306
Iteration 71/1000 | Loss: 0.00001306
Iteration 72/1000 | Loss: 0.00001306
Iteration 73/1000 | Loss: 0.00001306
Iteration 74/1000 | Loss: 0.00001306
Iteration 75/1000 | Loss: 0.00001306
Iteration 76/1000 | Loss: 0.00001306
Iteration 77/1000 | Loss: 0.00001306
Iteration 78/1000 | Loss: 0.00001306
Iteration 79/1000 | Loss: 0.00001306
Iteration 80/1000 | Loss: 0.00001306
Iteration 81/1000 | Loss: 0.00001306
Iteration 82/1000 | Loss: 0.00001306
Iteration 83/1000 | Loss: 0.00001306
Iteration 84/1000 | Loss: 0.00001306
Iteration 85/1000 | Loss: 0.00001306
Iteration 86/1000 | Loss: 0.00001306
Iteration 87/1000 | Loss: 0.00001306
Iteration 88/1000 | Loss: 0.00001306
Iteration 89/1000 | Loss: 0.00001306
Iteration 90/1000 | Loss: 0.00001306
Iteration 91/1000 | Loss: 0.00001306
Iteration 92/1000 | Loss: 0.00001306
Iteration 93/1000 | Loss: 0.00001306
Iteration 94/1000 | Loss: 0.00001306
Iteration 95/1000 | Loss: 0.00001306
Iteration 96/1000 | Loss: 0.00001306
Iteration 97/1000 | Loss: 0.00001306
Iteration 98/1000 | Loss: 0.00001306
Iteration 99/1000 | Loss: 0.00001306
Iteration 100/1000 | Loss: 0.00001306
Iteration 101/1000 | Loss: 0.00001306
Iteration 102/1000 | Loss: 0.00001306
Iteration 103/1000 | Loss: 0.00001306
Iteration 104/1000 | Loss: 0.00001306
Iteration 105/1000 | Loss: 0.00001306
Iteration 106/1000 | Loss: 0.00001306
Iteration 107/1000 | Loss: 0.00001306
Iteration 108/1000 | Loss: 0.00001306
Iteration 109/1000 | Loss: 0.00001306
Iteration 110/1000 | Loss: 0.00001306
Iteration 111/1000 | Loss: 0.00001306
Iteration 112/1000 | Loss: 0.00001306
Iteration 113/1000 | Loss: 0.00001306
Iteration 114/1000 | Loss: 0.00001306
Iteration 115/1000 | Loss: 0.00001306
Iteration 116/1000 | Loss: 0.00001306
Iteration 117/1000 | Loss: 0.00001306
Iteration 118/1000 | Loss: 0.00001306
Iteration 119/1000 | Loss: 0.00001306
Iteration 120/1000 | Loss: 0.00001306
Iteration 121/1000 | Loss: 0.00001306
Iteration 122/1000 | Loss: 0.00001306
Iteration 123/1000 | Loss: 0.00001306
Iteration 124/1000 | Loss: 0.00001306
Iteration 125/1000 | Loss: 0.00001306
Iteration 126/1000 | Loss: 0.00001306
Iteration 127/1000 | Loss: 0.00001306
Iteration 128/1000 | Loss: 0.00001306
Iteration 129/1000 | Loss: 0.00001306
Iteration 130/1000 | Loss: 0.00001306
Iteration 131/1000 | Loss: 0.00001306
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.3056413990852889e-05, 1.3056413990852889e-05, 1.3056413990852889e-05, 1.3056413990852889e-05, 1.3056413990852889e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3056413990852889e-05

Optimization complete. Final v2v error: 3.049065351486206 mm

Highest mean error: 3.0879807472229004 mm for frame 86

Lowest mean error: 3.00622820854187 mm for frame 117

Saving results

Total time: 28.712894201278687
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1086/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1086.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1086
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00413938
Iteration 2/25 | Loss: 0.00109314
Iteration 3/25 | Loss: 0.00084561
Iteration 4/25 | Loss: 0.00079055
Iteration 5/25 | Loss: 0.00077237
Iteration 6/25 | Loss: 0.00076778
Iteration 7/25 | Loss: 0.00076689
Iteration 8/25 | Loss: 0.00076689
Iteration 9/25 | Loss: 0.00076689
Iteration 10/25 | Loss: 0.00076689
Iteration 11/25 | Loss: 0.00076689
Iteration 12/25 | Loss: 0.00076689
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007668923935852945, 0.0007668923935852945, 0.0007668923935852945, 0.0007668923935852945, 0.0007668923935852945]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007668923935852945

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51077127
Iteration 2/25 | Loss: 0.00050076
Iteration 3/25 | Loss: 0.00050076
Iteration 4/25 | Loss: 0.00050076
Iteration 5/25 | Loss: 0.00050075
Iteration 6/25 | Loss: 0.00050075
Iteration 7/25 | Loss: 0.00050075
Iteration 8/25 | Loss: 0.00050075
Iteration 9/25 | Loss: 0.00050075
Iteration 10/25 | Loss: 0.00050075
Iteration 11/25 | Loss: 0.00050075
Iteration 12/25 | Loss: 0.00050075
Iteration 13/25 | Loss: 0.00050075
Iteration 14/25 | Loss: 0.00050075
Iteration 15/25 | Loss: 0.00050075
Iteration 16/25 | Loss: 0.00050075
Iteration 17/25 | Loss: 0.00050075
Iteration 18/25 | Loss: 0.00050075
Iteration 19/25 | Loss: 0.00050075
Iteration 20/25 | Loss: 0.00050075
Iteration 21/25 | Loss: 0.00050075
Iteration 22/25 | Loss: 0.00050075
Iteration 23/25 | Loss: 0.00050075
Iteration 24/25 | Loss: 0.00050075
Iteration 25/25 | Loss: 0.00050075

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050075
Iteration 2/1000 | Loss: 0.00002810
Iteration 3/1000 | Loss: 0.00002111
Iteration 4/1000 | Loss: 0.00001900
Iteration 5/1000 | Loss: 0.00001773
Iteration 6/1000 | Loss: 0.00001683
Iteration 7/1000 | Loss: 0.00001641
Iteration 8/1000 | Loss: 0.00001604
Iteration 9/1000 | Loss: 0.00001580
Iteration 10/1000 | Loss: 0.00001561
Iteration 11/1000 | Loss: 0.00001550
Iteration 12/1000 | Loss: 0.00001548
Iteration 13/1000 | Loss: 0.00001543
Iteration 14/1000 | Loss: 0.00001540
Iteration 15/1000 | Loss: 0.00001539
Iteration 16/1000 | Loss: 0.00001536
Iteration 17/1000 | Loss: 0.00001534
Iteration 18/1000 | Loss: 0.00001534
Iteration 19/1000 | Loss: 0.00001532
Iteration 20/1000 | Loss: 0.00001531
Iteration 21/1000 | Loss: 0.00001531
Iteration 22/1000 | Loss: 0.00001530
Iteration 23/1000 | Loss: 0.00001530
Iteration 24/1000 | Loss: 0.00001529
Iteration 25/1000 | Loss: 0.00001529
Iteration 26/1000 | Loss: 0.00001529
Iteration 27/1000 | Loss: 0.00001528
Iteration 28/1000 | Loss: 0.00001528
Iteration 29/1000 | Loss: 0.00001527
Iteration 30/1000 | Loss: 0.00001526
Iteration 31/1000 | Loss: 0.00001525
Iteration 32/1000 | Loss: 0.00001524
Iteration 33/1000 | Loss: 0.00001524
Iteration 34/1000 | Loss: 0.00001523
Iteration 35/1000 | Loss: 0.00001523
Iteration 36/1000 | Loss: 0.00001523
Iteration 37/1000 | Loss: 0.00001522
Iteration 38/1000 | Loss: 0.00001519
Iteration 39/1000 | Loss: 0.00001518
Iteration 40/1000 | Loss: 0.00001518
Iteration 41/1000 | Loss: 0.00001518
Iteration 42/1000 | Loss: 0.00001518
Iteration 43/1000 | Loss: 0.00001518
Iteration 44/1000 | Loss: 0.00001518
Iteration 45/1000 | Loss: 0.00001518
Iteration 46/1000 | Loss: 0.00001518
Iteration 47/1000 | Loss: 0.00001518
Iteration 48/1000 | Loss: 0.00001518
Iteration 49/1000 | Loss: 0.00001517
Iteration 50/1000 | Loss: 0.00001517
Iteration 51/1000 | Loss: 0.00001516
Iteration 52/1000 | Loss: 0.00001515
Iteration 53/1000 | Loss: 0.00001515
Iteration 54/1000 | Loss: 0.00001515
Iteration 55/1000 | Loss: 0.00001515
Iteration 56/1000 | Loss: 0.00001515
Iteration 57/1000 | Loss: 0.00001515
Iteration 58/1000 | Loss: 0.00001515
Iteration 59/1000 | Loss: 0.00001515
Iteration 60/1000 | Loss: 0.00001515
Iteration 61/1000 | Loss: 0.00001514
Iteration 62/1000 | Loss: 0.00001514
Iteration 63/1000 | Loss: 0.00001514
Iteration 64/1000 | Loss: 0.00001514
Iteration 65/1000 | Loss: 0.00001514
Iteration 66/1000 | Loss: 0.00001514
Iteration 67/1000 | Loss: 0.00001513
Iteration 68/1000 | Loss: 0.00001513
Iteration 69/1000 | Loss: 0.00001513
Iteration 70/1000 | Loss: 0.00001512
Iteration 71/1000 | Loss: 0.00001512
Iteration 72/1000 | Loss: 0.00001512
Iteration 73/1000 | Loss: 0.00001512
Iteration 74/1000 | Loss: 0.00001512
Iteration 75/1000 | Loss: 0.00001512
Iteration 76/1000 | Loss: 0.00001512
Iteration 77/1000 | Loss: 0.00001512
Iteration 78/1000 | Loss: 0.00001512
Iteration 79/1000 | Loss: 0.00001512
Iteration 80/1000 | Loss: 0.00001512
Iteration 81/1000 | Loss: 0.00001511
Iteration 82/1000 | Loss: 0.00001511
Iteration 83/1000 | Loss: 0.00001511
Iteration 84/1000 | Loss: 0.00001511
Iteration 85/1000 | Loss: 0.00001510
Iteration 86/1000 | Loss: 0.00001510
Iteration 87/1000 | Loss: 0.00001510
Iteration 88/1000 | Loss: 0.00001510
Iteration 89/1000 | Loss: 0.00001510
Iteration 90/1000 | Loss: 0.00001510
Iteration 91/1000 | Loss: 0.00001510
Iteration 92/1000 | Loss: 0.00001510
Iteration 93/1000 | Loss: 0.00001510
Iteration 94/1000 | Loss: 0.00001510
Iteration 95/1000 | Loss: 0.00001510
Iteration 96/1000 | Loss: 0.00001510
Iteration 97/1000 | Loss: 0.00001510
Iteration 98/1000 | Loss: 0.00001510
Iteration 99/1000 | Loss: 0.00001510
Iteration 100/1000 | Loss: 0.00001510
Iteration 101/1000 | Loss: 0.00001510
Iteration 102/1000 | Loss: 0.00001510
Iteration 103/1000 | Loss: 0.00001510
Iteration 104/1000 | Loss: 0.00001510
Iteration 105/1000 | Loss: 0.00001510
Iteration 106/1000 | Loss: 0.00001510
Iteration 107/1000 | Loss: 0.00001510
Iteration 108/1000 | Loss: 0.00001510
Iteration 109/1000 | Loss: 0.00001510
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.509962385171093e-05, 1.509962385171093e-05, 1.509962385171093e-05, 1.509962385171093e-05, 1.509962385171093e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.509962385171093e-05

Optimization complete. Final v2v error: 3.2788479328155518 mm

Highest mean error: 3.7193899154663086 mm for frame 111

Lowest mean error: 3.0387258529663086 mm for frame 52

Saving results

Total time: 37.98860764503479
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00442650
Iteration 2/25 | Loss: 0.00169614
Iteration 3/25 | Loss: 0.00122080
Iteration 4/25 | Loss: 0.00106857
Iteration 5/25 | Loss: 0.00104274
Iteration 6/25 | Loss: 0.00104353
Iteration 7/25 | Loss: 0.00105067
Iteration 8/25 | Loss: 0.00105066
Iteration 9/25 | Loss: 0.00104561
Iteration 10/25 | Loss: 0.00107756
Iteration 11/25 | Loss: 0.00106769
Iteration 12/25 | Loss: 0.00104884
Iteration 13/25 | Loss: 0.00101710
Iteration 14/25 | Loss: 0.00099652
Iteration 15/25 | Loss: 0.00097822
Iteration 16/25 | Loss: 0.00097436
Iteration 17/25 | Loss: 0.00097877
Iteration 18/25 | Loss: 0.00097259
Iteration 19/25 | Loss: 0.00096790
Iteration 20/25 | Loss: 0.00096626
Iteration 21/25 | Loss: 0.00096542
Iteration 22/25 | Loss: 0.00096523
Iteration 23/25 | Loss: 0.00096522
Iteration 24/25 | Loss: 0.00096522
Iteration 25/25 | Loss: 0.00096522

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51277637
Iteration 2/25 | Loss: 0.00095834
Iteration 3/25 | Loss: 0.00095834
Iteration 4/25 | Loss: 0.00095834
Iteration 5/25 | Loss: 0.00095834
Iteration 6/25 | Loss: 0.00095834
Iteration 7/25 | Loss: 0.00095834
Iteration 8/25 | Loss: 0.00095834
Iteration 9/25 | Loss: 0.00095834
Iteration 10/25 | Loss: 0.00095834
Iteration 11/25 | Loss: 0.00095834
Iteration 12/25 | Loss: 0.00095834
Iteration 13/25 | Loss: 0.00095834
Iteration 14/25 | Loss: 0.00095834
Iteration 15/25 | Loss: 0.00095834
Iteration 16/25 | Loss: 0.00095834
Iteration 17/25 | Loss: 0.00095834
Iteration 18/25 | Loss: 0.00095834
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009583415812812746, 0.0009583415812812746, 0.0009583415812812746, 0.0009583415812812746, 0.0009583415812812746]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009583415812812746

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00095834
Iteration 2/1000 | Loss: 0.00541662
Iteration 3/1000 | Loss: 0.00200013
Iteration 4/1000 | Loss: 0.00146650
Iteration 5/1000 | Loss: 0.00173841
Iteration 6/1000 | Loss: 0.00222454
Iteration 7/1000 | Loss: 0.00118091
Iteration 8/1000 | Loss: 0.00270226
Iteration 9/1000 | Loss: 0.00221406
Iteration 10/1000 | Loss: 0.00241033
Iteration 11/1000 | Loss: 0.00278355
Iteration 12/1000 | Loss: 0.00428467
Iteration 13/1000 | Loss: 0.00151477
Iteration 14/1000 | Loss: 0.00277522
Iteration 15/1000 | Loss: 0.00140154
Iteration 16/1000 | Loss: 0.00051163
Iteration 17/1000 | Loss: 0.00018050
Iteration 18/1000 | Loss: 0.00027678
Iteration 19/1000 | Loss: 0.00029811
Iteration 20/1000 | Loss: 0.00034030
Iteration 21/1000 | Loss: 0.00018504
Iteration 22/1000 | Loss: 0.00010676
Iteration 23/1000 | Loss: 0.00009562
Iteration 24/1000 | Loss: 0.00032763
Iteration 25/1000 | Loss: 0.00137561
Iteration 26/1000 | Loss: 0.00033731
Iteration 27/1000 | Loss: 0.00015084
Iteration 28/1000 | Loss: 0.00009416
Iteration 29/1000 | Loss: 0.00007819
Iteration 30/1000 | Loss: 0.00006624
Iteration 31/1000 | Loss: 0.00005824
Iteration 32/1000 | Loss: 0.00005483
Iteration 33/1000 | Loss: 0.00016548
Iteration 34/1000 | Loss: 0.00013351
Iteration 35/1000 | Loss: 0.00035868
Iteration 36/1000 | Loss: 0.00018616
Iteration 37/1000 | Loss: 0.00017543
Iteration 38/1000 | Loss: 0.00011601
Iteration 39/1000 | Loss: 0.00018693
Iteration 40/1000 | Loss: 0.00011274
Iteration 41/1000 | Loss: 0.00017605
Iteration 42/1000 | Loss: 0.00011233
Iteration 43/1000 | Loss: 0.00018725
Iteration 44/1000 | Loss: 0.00011131
Iteration 45/1000 | Loss: 0.00009473
Iteration 46/1000 | Loss: 0.00044215
Iteration 47/1000 | Loss: 0.00011024
Iteration 48/1000 | Loss: 0.00006334
Iteration 49/1000 | Loss: 0.00012154
Iteration 50/1000 | Loss: 0.00017522
Iteration 51/1000 | Loss: 0.00012104
Iteration 52/1000 | Loss: 0.00005392
Iteration 53/1000 | Loss: 0.00004860
Iteration 54/1000 | Loss: 0.00004609
Iteration 55/1000 | Loss: 0.00006249
Iteration 56/1000 | Loss: 0.00021579
Iteration 57/1000 | Loss: 0.00031959
Iteration 58/1000 | Loss: 0.00017196
Iteration 59/1000 | Loss: 0.00015490
Iteration 60/1000 | Loss: 0.00005033
Iteration 61/1000 | Loss: 0.00004794
Iteration 62/1000 | Loss: 0.00004525
Iteration 63/1000 | Loss: 0.00004413
Iteration 64/1000 | Loss: 0.00004497
Iteration 65/1000 | Loss: 0.00004257
Iteration 66/1000 | Loss: 0.00004184
Iteration 67/1000 | Loss: 0.00004122
Iteration 68/1000 | Loss: 0.00004062
Iteration 69/1000 | Loss: 0.00004030
Iteration 70/1000 | Loss: 0.00004006
Iteration 71/1000 | Loss: 0.00003982
Iteration 72/1000 | Loss: 0.00003954
Iteration 73/1000 | Loss: 0.00003926
Iteration 74/1000 | Loss: 0.00003916
Iteration 75/1000 | Loss: 0.00003913
Iteration 76/1000 | Loss: 0.00003912
Iteration 77/1000 | Loss: 0.00003912
Iteration 78/1000 | Loss: 0.00003911
Iteration 79/1000 | Loss: 0.00003911
Iteration 80/1000 | Loss: 0.00003911
Iteration 81/1000 | Loss: 0.00003910
Iteration 82/1000 | Loss: 0.00003910
Iteration 83/1000 | Loss: 0.00003909
Iteration 84/1000 | Loss: 0.00003909
Iteration 85/1000 | Loss: 0.00003909
Iteration 86/1000 | Loss: 0.00003908
Iteration 87/1000 | Loss: 0.00003908
Iteration 88/1000 | Loss: 0.00003908
Iteration 89/1000 | Loss: 0.00003907
Iteration 90/1000 | Loss: 0.00003904
Iteration 91/1000 | Loss: 0.00003901
Iteration 92/1000 | Loss: 0.00003900
Iteration 93/1000 | Loss: 0.00003900
Iteration 94/1000 | Loss: 0.00003899
Iteration 95/1000 | Loss: 0.00003898
Iteration 96/1000 | Loss: 0.00003897
Iteration 97/1000 | Loss: 0.00003895
Iteration 98/1000 | Loss: 0.00003892
Iteration 99/1000 | Loss: 0.00003892
Iteration 100/1000 | Loss: 0.00003891
Iteration 101/1000 | Loss: 0.00003891
Iteration 102/1000 | Loss: 0.00003890
Iteration 103/1000 | Loss: 0.00003890
Iteration 104/1000 | Loss: 0.00003890
Iteration 105/1000 | Loss: 0.00003889
Iteration 106/1000 | Loss: 0.00003889
Iteration 107/1000 | Loss: 0.00003889
Iteration 108/1000 | Loss: 0.00003888
Iteration 109/1000 | Loss: 0.00003888
Iteration 110/1000 | Loss: 0.00003888
Iteration 111/1000 | Loss: 0.00003888
Iteration 112/1000 | Loss: 0.00003888
Iteration 113/1000 | Loss: 0.00003887
Iteration 114/1000 | Loss: 0.00003887
Iteration 115/1000 | Loss: 0.00003887
Iteration 116/1000 | Loss: 0.00003887
Iteration 117/1000 | Loss: 0.00003887
Iteration 118/1000 | Loss: 0.00003886
Iteration 119/1000 | Loss: 0.00003886
Iteration 120/1000 | Loss: 0.00003886
Iteration 121/1000 | Loss: 0.00003886
Iteration 122/1000 | Loss: 0.00003885
Iteration 123/1000 | Loss: 0.00003885
Iteration 124/1000 | Loss: 0.00003885
Iteration 125/1000 | Loss: 0.00003885
Iteration 126/1000 | Loss: 0.00003885
Iteration 127/1000 | Loss: 0.00003885
Iteration 128/1000 | Loss: 0.00003885
Iteration 129/1000 | Loss: 0.00003884
Iteration 130/1000 | Loss: 0.00003884
Iteration 131/1000 | Loss: 0.00003884
Iteration 132/1000 | Loss: 0.00003884
Iteration 133/1000 | Loss: 0.00003884
Iteration 134/1000 | Loss: 0.00003884
Iteration 135/1000 | Loss: 0.00003884
Iteration 136/1000 | Loss: 0.00003884
Iteration 137/1000 | Loss: 0.00003884
Iteration 138/1000 | Loss: 0.00003883
Iteration 139/1000 | Loss: 0.00003883
Iteration 140/1000 | Loss: 0.00003883
Iteration 141/1000 | Loss: 0.00003883
Iteration 142/1000 | Loss: 0.00003883
Iteration 143/1000 | Loss: 0.00003883
Iteration 144/1000 | Loss: 0.00003882
Iteration 145/1000 | Loss: 0.00003882
Iteration 146/1000 | Loss: 0.00003882
Iteration 147/1000 | Loss: 0.00003882
Iteration 148/1000 | Loss: 0.00003881
Iteration 149/1000 | Loss: 0.00003881
Iteration 150/1000 | Loss: 0.00003881
Iteration 151/1000 | Loss: 0.00003881
Iteration 152/1000 | Loss: 0.00003881
Iteration 153/1000 | Loss: 0.00003881
Iteration 154/1000 | Loss: 0.00003880
Iteration 155/1000 | Loss: 0.00003880
Iteration 156/1000 | Loss: 0.00003879
Iteration 157/1000 | Loss: 0.00003879
Iteration 158/1000 | Loss: 0.00003879
Iteration 159/1000 | Loss: 0.00003879
Iteration 160/1000 | Loss: 0.00003879
Iteration 161/1000 | Loss: 0.00003878
Iteration 162/1000 | Loss: 0.00003878
Iteration 163/1000 | Loss: 0.00003878
Iteration 164/1000 | Loss: 0.00003878
Iteration 165/1000 | Loss: 0.00003878
Iteration 166/1000 | Loss: 0.00003878
Iteration 167/1000 | Loss: 0.00003878
Iteration 168/1000 | Loss: 0.00003878
Iteration 169/1000 | Loss: 0.00003878
Iteration 170/1000 | Loss: 0.00003878
Iteration 171/1000 | Loss: 0.00003878
Iteration 172/1000 | Loss: 0.00003878
Iteration 173/1000 | Loss: 0.00003878
Iteration 174/1000 | Loss: 0.00003877
Iteration 175/1000 | Loss: 0.00003877
Iteration 176/1000 | Loss: 0.00003877
Iteration 177/1000 | Loss: 0.00003877
Iteration 178/1000 | Loss: 0.00003877
Iteration 179/1000 | Loss: 0.00003877
Iteration 180/1000 | Loss: 0.00003877
Iteration 181/1000 | Loss: 0.00003877
Iteration 182/1000 | Loss: 0.00003877
Iteration 183/1000 | Loss: 0.00003877
Iteration 184/1000 | Loss: 0.00003876
Iteration 185/1000 | Loss: 0.00003876
Iteration 186/1000 | Loss: 0.00003876
Iteration 187/1000 | Loss: 0.00003876
Iteration 188/1000 | Loss: 0.00003876
Iteration 189/1000 | Loss: 0.00003876
Iteration 190/1000 | Loss: 0.00003876
Iteration 191/1000 | Loss: 0.00003876
Iteration 192/1000 | Loss: 0.00003876
Iteration 193/1000 | Loss: 0.00003875
Iteration 194/1000 | Loss: 0.00003875
Iteration 195/1000 | Loss: 0.00003875
Iteration 196/1000 | Loss: 0.00003875
Iteration 197/1000 | Loss: 0.00003875
Iteration 198/1000 | Loss: 0.00003875
Iteration 199/1000 | Loss: 0.00003874
Iteration 200/1000 | Loss: 0.00003874
Iteration 201/1000 | Loss: 0.00003874
Iteration 202/1000 | Loss: 0.00003874
Iteration 203/1000 | Loss: 0.00003874
Iteration 204/1000 | Loss: 0.00003874
Iteration 205/1000 | Loss: 0.00003874
Iteration 206/1000 | Loss: 0.00003874
Iteration 207/1000 | Loss: 0.00003873
Iteration 208/1000 | Loss: 0.00003873
Iteration 209/1000 | Loss: 0.00003873
Iteration 210/1000 | Loss: 0.00003873
Iteration 211/1000 | Loss: 0.00003873
Iteration 212/1000 | Loss: 0.00003873
Iteration 213/1000 | Loss: 0.00003873
Iteration 214/1000 | Loss: 0.00003873
Iteration 215/1000 | Loss: 0.00003873
Iteration 216/1000 | Loss: 0.00003873
Iteration 217/1000 | Loss: 0.00003873
Iteration 218/1000 | Loss: 0.00003873
Iteration 219/1000 | Loss: 0.00003873
Iteration 220/1000 | Loss: 0.00003873
Iteration 221/1000 | Loss: 0.00003872
Iteration 222/1000 | Loss: 0.00003872
Iteration 223/1000 | Loss: 0.00003872
Iteration 224/1000 | Loss: 0.00003872
Iteration 225/1000 | Loss: 0.00003872
Iteration 226/1000 | Loss: 0.00003872
Iteration 227/1000 | Loss: 0.00003872
Iteration 228/1000 | Loss: 0.00003872
Iteration 229/1000 | Loss: 0.00003872
Iteration 230/1000 | Loss: 0.00003872
Iteration 231/1000 | Loss: 0.00003872
Iteration 232/1000 | Loss: 0.00003872
Iteration 233/1000 | Loss: 0.00003872
Iteration 234/1000 | Loss: 0.00003872
Iteration 235/1000 | Loss: 0.00003872
Iteration 236/1000 | Loss: 0.00003872
Iteration 237/1000 | Loss: 0.00003872
Iteration 238/1000 | Loss: 0.00003872
Iteration 239/1000 | Loss: 0.00003872
Iteration 240/1000 | Loss: 0.00003872
Iteration 241/1000 | Loss: 0.00003872
Iteration 242/1000 | Loss: 0.00003872
Iteration 243/1000 | Loss: 0.00003872
Iteration 244/1000 | Loss: 0.00003872
Iteration 245/1000 | Loss: 0.00003872
Iteration 246/1000 | Loss: 0.00003872
Iteration 247/1000 | Loss: 0.00003872
Iteration 248/1000 | Loss: 0.00003872
Iteration 249/1000 | Loss: 0.00003872
Iteration 250/1000 | Loss: 0.00003872
Iteration 251/1000 | Loss: 0.00003872
Iteration 252/1000 | Loss: 0.00003872
Iteration 253/1000 | Loss: 0.00003872
Iteration 254/1000 | Loss: 0.00003872
Iteration 255/1000 | Loss: 0.00003872
Iteration 256/1000 | Loss: 0.00003872
Iteration 257/1000 | Loss: 0.00003872
Iteration 258/1000 | Loss: 0.00003872
Iteration 259/1000 | Loss: 0.00003872
Iteration 260/1000 | Loss: 0.00003872
Iteration 261/1000 | Loss: 0.00003872
Iteration 262/1000 | Loss: 0.00003872
Iteration 263/1000 | Loss: 0.00003872
Iteration 264/1000 | Loss: 0.00003872
Iteration 265/1000 | Loss: 0.00003872
Iteration 266/1000 | Loss: 0.00003872
Iteration 267/1000 | Loss: 0.00003872
Iteration 268/1000 | Loss: 0.00003872
Iteration 269/1000 | Loss: 0.00003872
Iteration 270/1000 | Loss: 0.00003872
Iteration 271/1000 | Loss: 0.00003872
Iteration 272/1000 | Loss: 0.00003872
Iteration 273/1000 | Loss: 0.00003872
Iteration 274/1000 | Loss: 0.00003872
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 274. Stopping optimization.
Last 5 losses: [3.872048182529397e-05, 3.872048182529397e-05, 3.872048182529397e-05, 3.872048182529397e-05, 3.872048182529397e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.872048182529397e-05

Optimization complete. Final v2v error: 4.347786903381348 mm

Highest mean error: 5.744070053100586 mm for frame 231

Lowest mean error: 3.694627285003662 mm for frame 6

Saving results

Total time: 177.84810519218445
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435295
Iteration 2/25 | Loss: 0.00108625
Iteration 3/25 | Loss: 0.00079764
Iteration 4/25 | Loss: 0.00076747
Iteration 5/25 | Loss: 0.00075955
Iteration 6/25 | Loss: 0.00075633
Iteration 7/25 | Loss: 0.00075543
Iteration 8/25 | Loss: 0.00075527
Iteration 9/25 | Loss: 0.00075527
Iteration 10/25 | Loss: 0.00075527
Iteration 11/25 | Loss: 0.00075527
Iteration 12/25 | Loss: 0.00075527
Iteration 13/25 | Loss: 0.00075527
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.000755269662477076, 0.000755269662477076, 0.000755269662477076, 0.000755269662477076, 0.000755269662477076]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000755269662477076

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53844094
Iteration 2/25 | Loss: 0.00044094
Iteration 3/25 | Loss: 0.00044092
Iteration 4/25 | Loss: 0.00044092
Iteration 5/25 | Loss: 0.00044092
Iteration 6/25 | Loss: 0.00044092
Iteration 7/25 | Loss: 0.00044092
Iteration 8/25 | Loss: 0.00044092
Iteration 9/25 | Loss: 0.00044092
Iteration 10/25 | Loss: 0.00044092
Iteration 11/25 | Loss: 0.00044092
Iteration 12/25 | Loss: 0.00044092
Iteration 13/25 | Loss: 0.00044092
Iteration 14/25 | Loss: 0.00044092
Iteration 15/25 | Loss: 0.00044092
Iteration 16/25 | Loss: 0.00044092
Iteration 17/25 | Loss: 0.00044092
Iteration 18/25 | Loss: 0.00044092
Iteration 19/25 | Loss: 0.00044092
Iteration 20/25 | Loss: 0.00044092
Iteration 21/25 | Loss: 0.00044092
Iteration 22/25 | Loss: 0.00044092
Iteration 23/25 | Loss: 0.00044092
Iteration 24/25 | Loss: 0.00044092
Iteration 25/25 | Loss: 0.00044092

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044092
Iteration 2/1000 | Loss: 0.00003319
Iteration 3/1000 | Loss: 0.00001901
Iteration 4/1000 | Loss: 0.00001644
Iteration 5/1000 | Loss: 0.00001543
Iteration 6/1000 | Loss: 0.00001494
Iteration 7/1000 | Loss: 0.00001463
Iteration 8/1000 | Loss: 0.00001436
Iteration 9/1000 | Loss: 0.00001417
Iteration 10/1000 | Loss: 0.00001410
Iteration 11/1000 | Loss: 0.00001397
Iteration 12/1000 | Loss: 0.00001394
Iteration 13/1000 | Loss: 0.00001390
Iteration 14/1000 | Loss: 0.00001386
Iteration 15/1000 | Loss: 0.00001385
Iteration 16/1000 | Loss: 0.00001383
Iteration 17/1000 | Loss: 0.00001383
Iteration 18/1000 | Loss: 0.00001382
Iteration 19/1000 | Loss: 0.00001382
Iteration 20/1000 | Loss: 0.00001381
Iteration 21/1000 | Loss: 0.00001380
Iteration 22/1000 | Loss: 0.00001380
Iteration 23/1000 | Loss: 0.00001379
Iteration 24/1000 | Loss: 0.00001379
Iteration 25/1000 | Loss: 0.00001379
Iteration 26/1000 | Loss: 0.00001378
Iteration 27/1000 | Loss: 0.00001378
Iteration 28/1000 | Loss: 0.00001377
Iteration 29/1000 | Loss: 0.00001377
Iteration 30/1000 | Loss: 0.00001376
Iteration 31/1000 | Loss: 0.00001376
Iteration 32/1000 | Loss: 0.00001375
Iteration 33/1000 | Loss: 0.00001375
Iteration 34/1000 | Loss: 0.00001374
Iteration 35/1000 | Loss: 0.00001374
Iteration 36/1000 | Loss: 0.00001374
Iteration 37/1000 | Loss: 0.00001374
Iteration 38/1000 | Loss: 0.00001374
Iteration 39/1000 | Loss: 0.00001374
Iteration 40/1000 | Loss: 0.00001373
Iteration 41/1000 | Loss: 0.00001373
Iteration 42/1000 | Loss: 0.00001372
Iteration 43/1000 | Loss: 0.00001371
Iteration 44/1000 | Loss: 0.00001371
Iteration 45/1000 | Loss: 0.00001371
Iteration 46/1000 | Loss: 0.00001371
Iteration 47/1000 | Loss: 0.00001370
Iteration 48/1000 | Loss: 0.00001369
Iteration 49/1000 | Loss: 0.00001369
Iteration 50/1000 | Loss: 0.00001369
Iteration 51/1000 | Loss: 0.00001369
Iteration 52/1000 | Loss: 0.00001369
Iteration 53/1000 | Loss: 0.00001368
Iteration 54/1000 | Loss: 0.00001368
Iteration 55/1000 | Loss: 0.00001368
Iteration 56/1000 | Loss: 0.00001368
Iteration 57/1000 | Loss: 0.00001368
Iteration 58/1000 | Loss: 0.00001367
Iteration 59/1000 | Loss: 0.00001367
Iteration 60/1000 | Loss: 0.00001367
Iteration 61/1000 | Loss: 0.00001366
Iteration 62/1000 | Loss: 0.00001366
Iteration 63/1000 | Loss: 0.00001366
Iteration 64/1000 | Loss: 0.00001365
Iteration 65/1000 | Loss: 0.00001365
Iteration 66/1000 | Loss: 0.00001364
Iteration 67/1000 | Loss: 0.00001363
Iteration 68/1000 | Loss: 0.00001363
Iteration 69/1000 | Loss: 0.00001363
Iteration 70/1000 | Loss: 0.00001363
Iteration 71/1000 | Loss: 0.00001362
Iteration 72/1000 | Loss: 0.00001362
Iteration 73/1000 | Loss: 0.00001362
Iteration 74/1000 | Loss: 0.00001362
Iteration 75/1000 | Loss: 0.00001362
Iteration 76/1000 | Loss: 0.00001361
Iteration 77/1000 | Loss: 0.00001361
Iteration 78/1000 | Loss: 0.00001361
Iteration 79/1000 | Loss: 0.00001361
Iteration 80/1000 | Loss: 0.00001360
Iteration 81/1000 | Loss: 0.00001360
Iteration 82/1000 | Loss: 0.00001360
Iteration 83/1000 | Loss: 0.00001360
Iteration 84/1000 | Loss: 0.00001359
Iteration 85/1000 | Loss: 0.00001359
Iteration 86/1000 | Loss: 0.00001359
Iteration 87/1000 | Loss: 0.00001359
Iteration 88/1000 | Loss: 0.00001358
Iteration 89/1000 | Loss: 0.00001358
Iteration 90/1000 | Loss: 0.00001358
Iteration 91/1000 | Loss: 0.00001358
Iteration 92/1000 | Loss: 0.00001357
Iteration 93/1000 | Loss: 0.00001357
Iteration 94/1000 | Loss: 0.00001357
Iteration 95/1000 | Loss: 0.00001357
Iteration 96/1000 | Loss: 0.00001357
Iteration 97/1000 | Loss: 0.00001356
Iteration 98/1000 | Loss: 0.00001356
Iteration 99/1000 | Loss: 0.00001356
Iteration 100/1000 | Loss: 0.00001356
Iteration 101/1000 | Loss: 0.00001355
Iteration 102/1000 | Loss: 0.00001355
Iteration 103/1000 | Loss: 0.00001355
Iteration 104/1000 | Loss: 0.00001355
Iteration 105/1000 | Loss: 0.00001355
Iteration 106/1000 | Loss: 0.00001355
Iteration 107/1000 | Loss: 0.00001355
Iteration 108/1000 | Loss: 0.00001355
Iteration 109/1000 | Loss: 0.00001354
Iteration 110/1000 | Loss: 0.00001354
Iteration 111/1000 | Loss: 0.00001354
Iteration 112/1000 | Loss: 0.00001354
Iteration 113/1000 | Loss: 0.00001354
Iteration 114/1000 | Loss: 0.00001354
Iteration 115/1000 | Loss: 0.00001354
Iteration 116/1000 | Loss: 0.00001354
Iteration 117/1000 | Loss: 0.00001354
Iteration 118/1000 | Loss: 0.00001354
Iteration 119/1000 | Loss: 0.00001354
Iteration 120/1000 | Loss: 0.00001353
Iteration 121/1000 | Loss: 0.00001353
Iteration 122/1000 | Loss: 0.00001353
Iteration 123/1000 | Loss: 0.00001353
Iteration 124/1000 | Loss: 0.00001353
Iteration 125/1000 | Loss: 0.00001353
Iteration 126/1000 | Loss: 0.00001353
Iteration 127/1000 | Loss: 0.00001353
Iteration 128/1000 | Loss: 0.00001353
Iteration 129/1000 | Loss: 0.00001353
Iteration 130/1000 | Loss: 0.00001353
Iteration 131/1000 | Loss: 0.00001353
Iteration 132/1000 | Loss: 0.00001353
Iteration 133/1000 | Loss: 0.00001353
Iteration 134/1000 | Loss: 0.00001353
Iteration 135/1000 | Loss: 0.00001353
Iteration 136/1000 | Loss: 0.00001353
Iteration 137/1000 | Loss: 0.00001353
Iteration 138/1000 | Loss: 0.00001353
Iteration 139/1000 | Loss: 0.00001353
Iteration 140/1000 | Loss: 0.00001353
Iteration 141/1000 | Loss: 0.00001353
Iteration 142/1000 | Loss: 0.00001353
Iteration 143/1000 | Loss: 0.00001353
Iteration 144/1000 | Loss: 0.00001353
Iteration 145/1000 | Loss: 0.00001353
Iteration 146/1000 | Loss: 0.00001353
Iteration 147/1000 | Loss: 0.00001353
Iteration 148/1000 | Loss: 0.00001353
Iteration 149/1000 | Loss: 0.00001353
Iteration 150/1000 | Loss: 0.00001353
Iteration 151/1000 | Loss: 0.00001353
Iteration 152/1000 | Loss: 0.00001353
Iteration 153/1000 | Loss: 0.00001353
Iteration 154/1000 | Loss: 0.00001353
Iteration 155/1000 | Loss: 0.00001353
Iteration 156/1000 | Loss: 0.00001353
Iteration 157/1000 | Loss: 0.00001353
Iteration 158/1000 | Loss: 0.00001353
Iteration 159/1000 | Loss: 0.00001353
Iteration 160/1000 | Loss: 0.00001353
Iteration 161/1000 | Loss: 0.00001353
Iteration 162/1000 | Loss: 0.00001353
Iteration 163/1000 | Loss: 0.00001353
Iteration 164/1000 | Loss: 0.00001353
Iteration 165/1000 | Loss: 0.00001353
Iteration 166/1000 | Loss: 0.00001353
Iteration 167/1000 | Loss: 0.00001353
Iteration 168/1000 | Loss: 0.00001353
Iteration 169/1000 | Loss: 0.00001353
Iteration 170/1000 | Loss: 0.00001353
Iteration 171/1000 | Loss: 0.00001353
Iteration 172/1000 | Loss: 0.00001353
Iteration 173/1000 | Loss: 0.00001353
Iteration 174/1000 | Loss: 0.00001353
Iteration 175/1000 | Loss: 0.00001353
Iteration 176/1000 | Loss: 0.00001353
Iteration 177/1000 | Loss: 0.00001353
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.3528731869882904e-05, 1.3528731869882904e-05, 1.3528731869882904e-05, 1.3528731869882904e-05, 1.3528731869882904e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3528731869882904e-05

Optimization complete. Final v2v error: 3.017230749130249 mm

Highest mean error: 3.981933832168579 mm for frame 56

Lowest mean error: 2.351323127746582 mm for frame 119

Saving results

Total time: 38.04526996612549
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1089/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1089.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1089
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00422351
Iteration 2/25 | Loss: 0.00090075
Iteration 3/25 | Loss: 0.00075477
Iteration 4/25 | Loss: 0.00073519
Iteration 5/25 | Loss: 0.00072799
Iteration 6/25 | Loss: 0.00072581
Iteration 7/25 | Loss: 0.00072532
Iteration 8/25 | Loss: 0.00072532
Iteration 9/25 | Loss: 0.00072532
Iteration 10/25 | Loss: 0.00072532
Iteration 11/25 | Loss: 0.00072532
Iteration 12/25 | Loss: 0.00072532
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007253165822476149, 0.0007253165822476149, 0.0007253165822476149, 0.0007253165822476149, 0.0007253165822476149]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007253165822476149

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48127866
Iteration 2/25 | Loss: 0.00049856
Iteration 3/25 | Loss: 0.00049856
Iteration 4/25 | Loss: 0.00049856
Iteration 5/25 | Loss: 0.00049856
Iteration 6/25 | Loss: 0.00049856
Iteration 7/25 | Loss: 0.00049856
Iteration 8/25 | Loss: 0.00049856
Iteration 9/25 | Loss: 0.00049856
Iteration 10/25 | Loss: 0.00049856
Iteration 11/25 | Loss: 0.00049856
Iteration 12/25 | Loss: 0.00049856
Iteration 13/25 | Loss: 0.00049856
Iteration 14/25 | Loss: 0.00049856
Iteration 15/25 | Loss: 0.00049856
Iteration 16/25 | Loss: 0.00049856
Iteration 17/25 | Loss: 0.00049856
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004985550767742097, 0.0004985550767742097, 0.0004985550767742097, 0.0004985550767742097, 0.0004985550767742097]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004985550767742097

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049856
Iteration 2/1000 | Loss: 0.00002300
Iteration 3/1000 | Loss: 0.00001609
Iteration 4/1000 | Loss: 0.00001480
Iteration 5/1000 | Loss: 0.00001383
Iteration 6/1000 | Loss: 0.00001312
Iteration 7/1000 | Loss: 0.00001284
Iteration 8/1000 | Loss: 0.00001254
Iteration 9/1000 | Loss: 0.00001236
Iteration 10/1000 | Loss: 0.00001217
Iteration 11/1000 | Loss: 0.00001209
Iteration 12/1000 | Loss: 0.00001200
Iteration 13/1000 | Loss: 0.00001194
Iteration 14/1000 | Loss: 0.00001191
Iteration 15/1000 | Loss: 0.00001191
Iteration 16/1000 | Loss: 0.00001189
Iteration 17/1000 | Loss: 0.00001187
Iteration 18/1000 | Loss: 0.00001186
Iteration 19/1000 | Loss: 0.00001186
Iteration 20/1000 | Loss: 0.00001183
Iteration 21/1000 | Loss: 0.00001183
Iteration 22/1000 | Loss: 0.00001181
Iteration 23/1000 | Loss: 0.00001181
Iteration 24/1000 | Loss: 0.00001181
Iteration 25/1000 | Loss: 0.00001180
Iteration 26/1000 | Loss: 0.00001180
Iteration 27/1000 | Loss: 0.00001179
Iteration 28/1000 | Loss: 0.00001179
Iteration 29/1000 | Loss: 0.00001178
Iteration 30/1000 | Loss: 0.00001178
Iteration 31/1000 | Loss: 0.00001177
Iteration 32/1000 | Loss: 0.00001177
Iteration 33/1000 | Loss: 0.00001177
Iteration 34/1000 | Loss: 0.00001177
Iteration 35/1000 | Loss: 0.00001177
Iteration 36/1000 | Loss: 0.00001177
Iteration 37/1000 | Loss: 0.00001177
Iteration 38/1000 | Loss: 0.00001177
Iteration 39/1000 | Loss: 0.00001177
Iteration 40/1000 | Loss: 0.00001177
Iteration 41/1000 | Loss: 0.00001176
Iteration 42/1000 | Loss: 0.00001176
Iteration 43/1000 | Loss: 0.00001176
Iteration 44/1000 | Loss: 0.00001175
Iteration 45/1000 | Loss: 0.00001175
Iteration 46/1000 | Loss: 0.00001175
Iteration 47/1000 | Loss: 0.00001175
Iteration 48/1000 | Loss: 0.00001175
Iteration 49/1000 | Loss: 0.00001175
Iteration 50/1000 | Loss: 0.00001174
Iteration 51/1000 | Loss: 0.00001174
Iteration 52/1000 | Loss: 0.00001174
Iteration 53/1000 | Loss: 0.00001174
Iteration 54/1000 | Loss: 0.00001174
Iteration 55/1000 | Loss: 0.00001174
Iteration 56/1000 | Loss: 0.00001173
Iteration 57/1000 | Loss: 0.00001173
Iteration 58/1000 | Loss: 0.00001173
Iteration 59/1000 | Loss: 0.00001173
Iteration 60/1000 | Loss: 0.00001173
Iteration 61/1000 | Loss: 0.00001173
Iteration 62/1000 | Loss: 0.00001173
Iteration 63/1000 | Loss: 0.00001173
Iteration 64/1000 | Loss: 0.00001173
Iteration 65/1000 | Loss: 0.00001173
Iteration 66/1000 | Loss: 0.00001172
Iteration 67/1000 | Loss: 0.00001172
Iteration 68/1000 | Loss: 0.00001172
Iteration 69/1000 | Loss: 0.00001172
Iteration 70/1000 | Loss: 0.00001172
Iteration 71/1000 | Loss: 0.00001172
Iteration 72/1000 | Loss: 0.00001171
Iteration 73/1000 | Loss: 0.00001171
Iteration 74/1000 | Loss: 0.00001171
Iteration 75/1000 | Loss: 0.00001171
Iteration 76/1000 | Loss: 0.00001171
Iteration 77/1000 | Loss: 0.00001171
Iteration 78/1000 | Loss: 0.00001171
Iteration 79/1000 | Loss: 0.00001170
Iteration 80/1000 | Loss: 0.00001170
Iteration 81/1000 | Loss: 0.00001170
Iteration 82/1000 | Loss: 0.00001169
Iteration 83/1000 | Loss: 0.00001169
Iteration 84/1000 | Loss: 0.00001169
Iteration 85/1000 | Loss: 0.00001169
Iteration 86/1000 | Loss: 0.00001168
Iteration 87/1000 | Loss: 0.00001168
Iteration 88/1000 | Loss: 0.00001168
Iteration 89/1000 | Loss: 0.00001168
Iteration 90/1000 | Loss: 0.00001168
Iteration 91/1000 | Loss: 0.00001168
Iteration 92/1000 | Loss: 0.00001168
Iteration 93/1000 | Loss: 0.00001168
Iteration 94/1000 | Loss: 0.00001168
Iteration 95/1000 | Loss: 0.00001167
Iteration 96/1000 | Loss: 0.00001167
Iteration 97/1000 | Loss: 0.00001167
Iteration 98/1000 | Loss: 0.00001167
Iteration 99/1000 | Loss: 0.00001167
Iteration 100/1000 | Loss: 0.00001167
Iteration 101/1000 | Loss: 0.00001167
Iteration 102/1000 | Loss: 0.00001166
Iteration 103/1000 | Loss: 0.00001166
Iteration 104/1000 | Loss: 0.00001166
Iteration 105/1000 | Loss: 0.00001166
Iteration 106/1000 | Loss: 0.00001166
Iteration 107/1000 | Loss: 0.00001166
Iteration 108/1000 | Loss: 0.00001165
Iteration 109/1000 | Loss: 0.00001165
Iteration 110/1000 | Loss: 0.00001165
Iteration 111/1000 | Loss: 0.00001165
Iteration 112/1000 | Loss: 0.00001165
Iteration 113/1000 | Loss: 0.00001165
Iteration 114/1000 | Loss: 0.00001165
Iteration 115/1000 | Loss: 0.00001165
Iteration 116/1000 | Loss: 0.00001165
Iteration 117/1000 | Loss: 0.00001165
Iteration 118/1000 | Loss: 0.00001165
Iteration 119/1000 | Loss: 0.00001165
Iteration 120/1000 | Loss: 0.00001165
Iteration 121/1000 | Loss: 0.00001165
Iteration 122/1000 | Loss: 0.00001165
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 122. Stopping optimization.
Last 5 losses: [1.1653592991933692e-05, 1.1653592991933692e-05, 1.1653592991933692e-05, 1.1653592991933692e-05, 1.1653592991933692e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1653592991933692e-05

Optimization complete. Final v2v error: 2.9186134338378906 mm

Highest mean error: 3.774127244949341 mm for frame 55

Lowest mean error: 2.669677734375 mm for frame 88

Saving results

Total time: 40.217138051986694
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1036/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1036.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1036
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00413321
Iteration 2/25 | Loss: 0.00098113
Iteration 3/25 | Loss: 0.00085430
Iteration 4/25 | Loss: 0.00082515
Iteration 5/25 | Loss: 0.00081642
Iteration 6/25 | Loss: 0.00081514
Iteration 7/25 | Loss: 0.00081469
Iteration 8/25 | Loss: 0.00081469
Iteration 9/25 | Loss: 0.00081469
Iteration 10/25 | Loss: 0.00081469
Iteration 11/25 | Loss: 0.00081469
Iteration 12/25 | Loss: 0.00081469
Iteration 13/25 | Loss: 0.00081469
Iteration 14/25 | Loss: 0.00081469
Iteration 15/25 | Loss: 0.00081469
Iteration 16/25 | Loss: 0.00081469
Iteration 17/25 | Loss: 0.00081469
Iteration 18/25 | Loss: 0.00081469
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0008146872860379517, 0.0008146872860379517, 0.0008146872860379517, 0.0008146872860379517, 0.0008146872860379517]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008146872860379517

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49765885
Iteration 2/25 | Loss: 0.00049176
Iteration 3/25 | Loss: 0.00049176
Iteration 4/25 | Loss: 0.00049176
Iteration 5/25 | Loss: 0.00049175
Iteration 6/25 | Loss: 0.00049175
Iteration 7/25 | Loss: 0.00049175
Iteration 8/25 | Loss: 0.00049175
Iteration 9/25 | Loss: 0.00049175
Iteration 10/25 | Loss: 0.00049175
Iteration 11/25 | Loss: 0.00049175
Iteration 12/25 | Loss: 0.00049175
Iteration 13/25 | Loss: 0.00049175
Iteration 14/25 | Loss: 0.00049175
Iteration 15/25 | Loss: 0.00049175
Iteration 16/25 | Loss: 0.00049175
Iteration 17/25 | Loss: 0.00049175
Iteration 18/25 | Loss: 0.00049175
Iteration 19/25 | Loss: 0.00049175
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0004917532205581665, 0.0004917532205581665, 0.0004917532205581665, 0.0004917532205581665, 0.0004917532205581665]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004917532205581665

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049175
Iteration 2/1000 | Loss: 0.00004975
Iteration 3/1000 | Loss: 0.00003195
Iteration 4/1000 | Loss: 0.00002969
Iteration 5/1000 | Loss: 0.00002863
Iteration 6/1000 | Loss: 0.00002765
Iteration 7/1000 | Loss: 0.00002693
Iteration 8/1000 | Loss: 0.00002640
Iteration 9/1000 | Loss: 0.00002608
Iteration 10/1000 | Loss: 0.00002583
Iteration 11/1000 | Loss: 0.00002563
Iteration 12/1000 | Loss: 0.00002543
Iteration 13/1000 | Loss: 0.00002532
Iteration 14/1000 | Loss: 0.00002524
Iteration 15/1000 | Loss: 0.00002523
Iteration 16/1000 | Loss: 0.00002522
Iteration 17/1000 | Loss: 0.00002522
Iteration 18/1000 | Loss: 0.00002521
Iteration 19/1000 | Loss: 0.00002519
Iteration 20/1000 | Loss: 0.00002519
Iteration 21/1000 | Loss: 0.00002517
Iteration 22/1000 | Loss: 0.00002516
Iteration 23/1000 | Loss: 0.00002512
Iteration 24/1000 | Loss: 0.00002512
Iteration 25/1000 | Loss: 0.00002511
Iteration 26/1000 | Loss: 0.00002501
Iteration 27/1000 | Loss: 0.00002496
Iteration 28/1000 | Loss: 0.00002492
Iteration 29/1000 | Loss: 0.00002492
Iteration 30/1000 | Loss: 0.00002491
Iteration 31/1000 | Loss: 0.00002491
Iteration 32/1000 | Loss: 0.00002491
Iteration 33/1000 | Loss: 0.00002491
Iteration 34/1000 | Loss: 0.00002491
Iteration 35/1000 | Loss: 0.00002491
Iteration 36/1000 | Loss: 0.00002491
Iteration 37/1000 | Loss: 0.00002491
Iteration 38/1000 | Loss: 0.00002491
Iteration 39/1000 | Loss: 0.00002491
Iteration 40/1000 | Loss: 0.00002491
Iteration 41/1000 | Loss: 0.00002491
Iteration 42/1000 | Loss: 0.00002490
Iteration 43/1000 | Loss: 0.00002490
Iteration 44/1000 | Loss: 0.00002490
Iteration 45/1000 | Loss: 0.00002489
Iteration 46/1000 | Loss: 0.00002489
Iteration 47/1000 | Loss: 0.00002489
Iteration 48/1000 | Loss: 0.00002488
Iteration 49/1000 | Loss: 0.00002488
Iteration 50/1000 | Loss: 0.00002488
Iteration 51/1000 | Loss: 0.00002488
Iteration 52/1000 | Loss: 0.00002488
Iteration 53/1000 | Loss: 0.00002487
Iteration 54/1000 | Loss: 0.00002487
Iteration 55/1000 | Loss: 0.00002487
Iteration 56/1000 | Loss: 0.00002487
Iteration 57/1000 | Loss: 0.00002487
Iteration 58/1000 | Loss: 0.00002486
Iteration 59/1000 | Loss: 0.00002486
Iteration 60/1000 | Loss: 0.00002486
Iteration 61/1000 | Loss: 0.00002486
Iteration 62/1000 | Loss: 0.00002486
Iteration 63/1000 | Loss: 0.00002486
Iteration 64/1000 | Loss: 0.00002486
Iteration 65/1000 | Loss: 0.00002486
Iteration 66/1000 | Loss: 0.00002486
Iteration 67/1000 | Loss: 0.00002486
Iteration 68/1000 | Loss: 0.00002486
Iteration 69/1000 | Loss: 0.00002486
Iteration 70/1000 | Loss: 0.00002486
Iteration 71/1000 | Loss: 0.00002486
Iteration 72/1000 | Loss: 0.00002485
Iteration 73/1000 | Loss: 0.00002485
Iteration 74/1000 | Loss: 0.00002485
Iteration 75/1000 | Loss: 0.00002485
Iteration 76/1000 | Loss: 0.00002485
Iteration 77/1000 | Loss: 0.00002485
Iteration 78/1000 | Loss: 0.00002485
Iteration 79/1000 | Loss: 0.00002485
Iteration 80/1000 | Loss: 0.00002484
Iteration 81/1000 | Loss: 0.00002484
Iteration 82/1000 | Loss: 0.00002484
Iteration 83/1000 | Loss: 0.00002484
Iteration 84/1000 | Loss: 0.00002484
Iteration 85/1000 | Loss: 0.00002483
Iteration 86/1000 | Loss: 0.00002483
Iteration 87/1000 | Loss: 0.00002483
Iteration 88/1000 | Loss: 0.00002483
Iteration 89/1000 | Loss: 0.00002483
Iteration 90/1000 | Loss: 0.00002483
Iteration 91/1000 | Loss: 0.00002483
Iteration 92/1000 | Loss: 0.00002483
Iteration 93/1000 | Loss: 0.00002483
Iteration 94/1000 | Loss: 0.00002483
Iteration 95/1000 | Loss: 0.00002483
Iteration 96/1000 | Loss: 0.00002483
Iteration 97/1000 | Loss: 0.00002483
Iteration 98/1000 | Loss: 0.00002483
Iteration 99/1000 | Loss: 0.00002483
Iteration 100/1000 | Loss: 0.00002483
Iteration 101/1000 | Loss: 0.00002483
Iteration 102/1000 | Loss: 0.00002483
Iteration 103/1000 | Loss: 0.00002483
Iteration 104/1000 | Loss: 0.00002483
Iteration 105/1000 | Loss: 0.00002483
Iteration 106/1000 | Loss: 0.00002483
Iteration 107/1000 | Loss: 0.00002483
Iteration 108/1000 | Loss: 0.00002483
Iteration 109/1000 | Loss: 0.00002483
Iteration 110/1000 | Loss: 0.00002483
Iteration 111/1000 | Loss: 0.00002483
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 111. Stopping optimization.
Last 5 losses: [2.483080061210785e-05, 2.483080061210785e-05, 2.483080061210785e-05, 2.483080061210785e-05, 2.483080061210785e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.483080061210785e-05

Optimization complete. Final v2v error: 4.133048057556152 mm

Highest mean error: 4.521796703338623 mm for frame 15

Lowest mean error: 3.7456679344177246 mm for frame 33

Saving results

Total time: 36.33779788017273
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1054/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1054.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1054
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00883736
Iteration 2/25 | Loss: 0.00090470
Iteration 3/25 | Loss: 0.00075831
Iteration 4/25 | Loss: 0.00073751
Iteration 5/25 | Loss: 0.00073059
Iteration 6/25 | Loss: 0.00072937
Iteration 7/25 | Loss: 0.00072937
Iteration 8/25 | Loss: 0.00072937
Iteration 9/25 | Loss: 0.00072937
Iteration 10/25 | Loss: 0.00072937
Iteration 11/25 | Loss: 0.00072937
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007293707458302379, 0.0007293707458302379, 0.0007293707458302379, 0.0007293707458302379, 0.0007293707458302379]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007293707458302379

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.88758945
Iteration 2/25 | Loss: 0.00048101
Iteration 3/25 | Loss: 0.00048101
Iteration 4/25 | Loss: 0.00048101
Iteration 5/25 | Loss: 0.00048101
Iteration 6/25 | Loss: 0.00048101
Iteration 7/25 | Loss: 0.00048101
Iteration 8/25 | Loss: 0.00048101
Iteration 9/25 | Loss: 0.00048101
Iteration 10/25 | Loss: 0.00048101
Iteration 11/25 | Loss: 0.00048101
Iteration 12/25 | Loss: 0.00048101
Iteration 13/25 | Loss: 0.00048101
Iteration 14/25 | Loss: 0.00048101
Iteration 15/25 | Loss: 0.00048101
Iteration 16/25 | Loss: 0.00048101
Iteration 17/25 | Loss: 0.00048101
Iteration 18/25 | Loss: 0.00048101
Iteration 19/25 | Loss: 0.00048101
Iteration 20/25 | Loss: 0.00048101
Iteration 21/25 | Loss: 0.00048101
Iteration 22/25 | Loss: 0.00048101
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00048100869753398, 0.00048100869753398, 0.00048100869753398, 0.00048100869753398, 0.00048100869753398]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00048100869753398

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048101
Iteration 2/1000 | Loss: 0.00001894
Iteration 3/1000 | Loss: 0.00001463
Iteration 4/1000 | Loss: 0.00001381
Iteration 5/1000 | Loss: 0.00001301
Iteration 6/1000 | Loss: 0.00001289
Iteration 7/1000 | Loss: 0.00001259
Iteration 8/1000 | Loss: 0.00001252
Iteration 9/1000 | Loss: 0.00001237
Iteration 10/1000 | Loss: 0.00001218
Iteration 11/1000 | Loss: 0.00001210
Iteration 12/1000 | Loss: 0.00001208
Iteration 13/1000 | Loss: 0.00001195
Iteration 14/1000 | Loss: 0.00001193
Iteration 15/1000 | Loss: 0.00001190
Iteration 16/1000 | Loss: 0.00001188
Iteration 17/1000 | Loss: 0.00001187
Iteration 18/1000 | Loss: 0.00001186
Iteration 19/1000 | Loss: 0.00001186
Iteration 20/1000 | Loss: 0.00001183
Iteration 21/1000 | Loss: 0.00001181
Iteration 22/1000 | Loss: 0.00001176
Iteration 23/1000 | Loss: 0.00001176
Iteration 24/1000 | Loss: 0.00001176
Iteration 25/1000 | Loss: 0.00001175
Iteration 26/1000 | Loss: 0.00001175
Iteration 27/1000 | Loss: 0.00001174
Iteration 28/1000 | Loss: 0.00001174
Iteration 29/1000 | Loss: 0.00001174
Iteration 30/1000 | Loss: 0.00001174
Iteration 31/1000 | Loss: 0.00001174
Iteration 32/1000 | Loss: 0.00001174
Iteration 33/1000 | Loss: 0.00001173
Iteration 34/1000 | Loss: 0.00001173
Iteration 35/1000 | Loss: 0.00001173
Iteration 36/1000 | Loss: 0.00001172
Iteration 37/1000 | Loss: 0.00001172
Iteration 38/1000 | Loss: 0.00001171
Iteration 39/1000 | Loss: 0.00001166
Iteration 40/1000 | Loss: 0.00001163
Iteration 41/1000 | Loss: 0.00001162
Iteration 42/1000 | Loss: 0.00001162
Iteration 43/1000 | Loss: 0.00001161
Iteration 44/1000 | Loss: 0.00001160
Iteration 45/1000 | Loss: 0.00001160
Iteration 46/1000 | Loss: 0.00001159
Iteration 47/1000 | Loss: 0.00001159
Iteration 48/1000 | Loss: 0.00001156
Iteration 49/1000 | Loss: 0.00001155
Iteration 50/1000 | Loss: 0.00001155
Iteration 51/1000 | Loss: 0.00001155
Iteration 52/1000 | Loss: 0.00001154
Iteration 53/1000 | Loss: 0.00001154
Iteration 54/1000 | Loss: 0.00001153
Iteration 55/1000 | Loss: 0.00001153
Iteration 56/1000 | Loss: 0.00001153
Iteration 57/1000 | Loss: 0.00001153
Iteration 58/1000 | Loss: 0.00001153
Iteration 59/1000 | Loss: 0.00001153
Iteration 60/1000 | Loss: 0.00001153
Iteration 61/1000 | Loss: 0.00001153
Iteration 62/1000 | Loss: 0.00001152
Iteration 63/1000 | Loss: 0.00001152
Iteration 64/1000 | Loss: 0.00001152
Iteration 65/1000 | Loss: 0.00001152
Iteration 66/1000 | Loss: 0.00001151
Iteration 67/1000 | Loss: 0.00001151
Iteration 68/1000 | Loss: 0.00001151
Iteration 69/1000 | Loss: 0.00001151
Iteration 70/1000 | Loss: 0.00001150
Iteration 71/1000 | Loss: 0.00001150
Iteration 72/1000 | Loss: 0.00001150
Iteration 73/1000 | Loss: 0.00001150
Iteration 74/1000 | Loss: 0.00001150
Iteration 75/1000 | Loss: 0.00001150
Iteration 76/1000 | Loss: 0.00001150
Iteration 77/1000 | Loss: 0.00001150
Iteration 78/1000 | Loss: 0.00001150
Iteration 79/1000 | Loss: 0.00001150
Iteration 80/1000 | Loss: 0.00001150
Iteration 81/1000 | Loss: 0.00001150
Iteration 82/1000 | Loss: 0.00001149
Iteration 83/1000 | Loss: 0.00001149
Iteration 84/1000 | Loss: 0.00001149
Iteration 85/1000 | Loss: 0.00001149
Iteration 86/1000 | Loss: 0.00001149
Iteration 87/1000 | Loss: 0.00001149
Iteration 88/1000 | Loss: 0.00001149
Iteration 89/1000 | Loss: 0.00001149
Iteration 90/1000 | Loss: 0.00001149
Iteration 91/1000 | Loss: 0.00001149
Iteration 92/1000 | Loss: 0.00001149
Iteration 93/1000 | Loss: 0.00001149
Iteration 94/1000 | Loss: 0.00001149
Iteration 95/1000 | Loss: 0.00001149
Iteration 96/1000 | Loss: 0.00001149
Iteration 97/1000 | Loss: 0.00001149
Iteration 98/1000 | Loss: 0.00001149
Iteration 99/1000 | Loss: 0.00001149
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 99. Stopping optimization.
Last 5 losses: [1.1489497410366312e-05, 1.1489497410366312e-05, 1.1489497410366312e-05, 1.1489497410366312e-05, 1.1489497410366312e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1489497410366312e-05

Optimization complete. Final v2v error: 2.8690969944000244 mm

Highest mean error: 3.321990728378296 mm for frame 157

Lowest mean error: 2.6671273708343506 mm for frame 217

Saving results

Total time: 36.58723735809326
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00900280
Iteration 2/25 | Loss: 0.00147863
Iteration 3/25 | Loss: 0.00104894
Iteration 4/25 | Loss: 0.00095944
Iteration 5/25 | Loss: 0.00094319
Iteration 6/25 | Loss: 0.00094353
Iteration 7/25 | Loss: 0.00093803
Iteration 8/25 | Loss: 0.00091742
Iteration 9/25 | Loss: 0.00090596
Iteration 10/25 | Loss: 0.00090271
Iteration 11/25 | Loss: 0.00090151
Iteration 12/25 | Loss: 0.00090114
Iteration 13/25 | Loss: 0.00090260
Iteration 14/25 | Loss: 0.00090043
Iteration 15/25 | Loss: 0.00090196
Iteration 16/25 | Loss: 0.00089695
Iteration 17/25 | Loss: 0.00089532
Iteration 18/25 | Loss: 0.00089481
Iteration 19/25 | Loss: 0.00089460
Iteration 20/25 | Loss: 0.00089460
Iteration 21/25 | Loss: 0.00089459
Iteration 22/25 | Loss: 0.00089459
Iteration 23/25 | Loss: 0.00089459
Iteration 24/25 | Loss: 0.00089459
Iteration 25/25 | Loss: 0.00089459

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.02713108
Iteration 2/25 | Loss: 0.00046610
Iteration 3/25 | Loss: 0.00046610
Iteration 4/25 | Loss: 0.00046610
Iteration 5/25 | Loss: 0.00046610
Iteration 6/25 | Loss: 0.00046610
Iteration 7/25 | Loss: 0.00046610
Iteration 8/25 | Loss: 0.00046610
Iteration 9/25 | Loss: 0.00046609
Iteration 10/25 | Loss: 0.00046609
Iteration 11/25 | Loss: 0.00046609
Iteration 12/25 | Loss: 0.00046609
Iteration 13/25 | Loss: 0.00046609
Iteration 14/25 | Loss: 0.00046609
Iteration 15/25 | Loss: 0.00046609
Iteration 16/25 | Loss: 0.00046609
Iteration 17/25 | Loss: 0.00046609
Iteration 18/25 | Loss: 0.00046609
Iteration 19/25 | Loss: 0.00046609
Iteration 20/25 | Loss: 0.00046609
Iteration 21/25 | Loss: 0.00046609
Iteration 22/25 | Loss: 0.00046609
Iteration 23/25 | Loss: 0.00046609
Iteration 24/25 | Loss: 0.00046609
Iteration 25/25 | Loss: 0.00046609
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0004660944687202573, 0.0004660944687202573, 0.0004660944687202573, 0.0004660944687202573, 0.0004660944687202573]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004660944687202573

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046609
Iteration 2/1000 | Loss: 0.00004216
Iteration 3/1000 | Loss: 0.00003388
Iteration 4/1000 | Loss: 0.00003168
Iteration 5/1000 | Loss: 0.00003042
Iteration 6/1000 | Loss: 0.00002949
Iteration 7/1000 | Loss: 0.00002849
Iteration 8/1000 | Loss: 0.00002808
Iteration 9/1000 | Loss: 0.00002785
Iteration 10/1000 | Loss: 0.00002770
Iteration 11/1000 | Loss: 0.00002769
Iteration 12/1000 | Loss: 0.00002768
Iteration 13/1000 | Loss: 0.00002765
Iteration 14/1000 | Loss: 0.00002765
Iteration 15/1000 | Loss: 0.00002764
Iteration 16/1000 | Loss: 0.00002762
Iteration 17/1000 | Loss: 0.00002757
Iteration 18/1000 | Loss: 0.00002757
Iteration 19/1000 | Loss: 0.00002757
Iteration 20/1000 | Loss: 0.00002757
Iteration 21/1000 | Loss: 0.00002757
Iteration 22/1000 | Loss: 0.00002757
Iteration 23/1000 | Loss: 0.00002756
Iteration 24/1000 | Loss: 0.00002756
Iteration 25/1000 | Loss: 0.00002756
Iteration 26/1000 | Loss: 0.00002756
Iteration 27/1000 | Loss: 0.00002756
Iteration 28/1000 | Loss: 0.00002755
Iteration 29/1000 | Loss: 0.00002755
Iteration 30/1000 | Loss: 0.00002755
Iteration 31/1000 | Loss: 0.00002754
Iteration 32/1000 | Loss: 0.00002753
Iteration 33/1000 | Loss: 0.00002752
Iteration 34/1000 | Loss: 0.00002748
Iteration 35/1000 | Loss: 0.00002747
Iteration 36/1000 | Loss: 0.00002746
Iteration 37/1000 | Loss: 0.00002746
Iteration 38/1000 | Loss: 0.00002746
Iteration 39/1000 | Loss: 0.00002746
Iteration 40/1000 | Loss: 0.00002746
Iteration 41/1000 | Loss: 0.00002746
Iteration 42/1000 | Loss: 0.00002745
Iteration 43/1000 | Loss: 0.00002745
Iteration 44/1000 | Loss: 0.00002745
Iteration 45/1000 | Loss: 0.00002745
Iteration 46/1000 | Loss: 0.00002745
Iteration 47/1000 | Loss: 0.00002745
Iteration 48/1000 | Loss: 0.00002745
Iteration 49/1000 | Loss: 0.00002745
Iteration 50/1000 | Loss: 0.00002745
Iteration 51/1000 | Loss: 0.00002745
Iteration 52/1000 | Loss: 0.00002745
Iteration 53/1000 | Loss: 0.00002745
Iteration 54/1000 | Loss: 0.00002745
Iteration 55/1000 | Loss: 0.00002745
Iteration 56/1000 | Loss: 0.00002745
Iteration 57/1000 | Loss: 0.00002745
Iteration 58/1000 | Loss: 0.00002744
Iteration 59/1000 | Loss: 0.00002744
Iteration 60/1000 | Loss: 0.00002744
Iteration 61/1000 | Loss: 0.00002744
Iteration 62/1000 | Loss: 0.00002744
Iteration 63/1000 | Loss: 0.00002744
Iteration 64/1000 | Loss: 0.00002744
Iteration 65/1000 | Loss: 0.00002744
Iteration 66/1000 | Loss: 0.00002744
Iteration 67/1000 | Loss: 0.00002744
Iteration 68/1000 | Loss: 0.00002744
Iteration 69/1000 | Loss: 0.00002744
Iteration 70/1000 | Loss: 0.00002744
Iteration 71/1000 | Loss: 0.00002744
Iteration 72/1000 | Loss: 0.00002743
Iteration 73/1000 | Loss: 0.00002743
Iteration 74/1000 | Loss: 0.00002743
Iteration 75/1000 | Loss: 0.00002743
Iteration 76/1000 | Loss: 0.00002743
Iteration 77/1000 | Loss: 0.00002743
Iteration 78/1000 | Loss: 0.00002743
Iteration 79/1000 | Loss: 0.00002743
Iteration 80/1000 | Loss: 0.00002743
Iteration 81/1000 | Loss: 0.00002743
Iteration 82/1000 | Loss: 0.00002743
Iteration 83/1000 | Loss: 0.00002743
Iteration 84/1000 | Loss: 0.00002743
Iteration 85/1000 | Loss: 0.00002743
Iteration 86/1000 | Loss: 0.00002743
Iteration 87/1000 | Loss: 0.00002743
Iteration 88/1000 | Loss: 0.00002743
Iteration 89/1000 | Loss: 0.00002742
Iteration 90/1000 | Loss: 0.00002742
Iteration 91/1000 | Loss: 0.00002742
Iteration 92/1000 | Loss: 0.00002742
Iteration 93/1000 | Loss: 0.00002742
Iteration 94/1000 | Loss: 0.00002742
Iteration 95/1000 | Loss: 0.00002742
Iteration 96/1000 | Loss: 0.00002742
Iteration 97/1000 | Loss: 0.00002742
Iteration 98/1000 | Loss: 0.00002742
Iteration 99/1000 | Loss: 0.00002742
Iteration 100/1000 | Loss: 0.00002742
Iteration 101/1000 | Loss: 0.00002742
Iteration 102/1000 | Loss: 0.00002742
Iteration 103/1000 | Loss: 0.00002742
Iteration 104/1000 | Loss: 0.00002742
Iteration 105/1000 | Loss: 0.00002742
Iteration 106/1000 | Loss: 0.00002742
Iteration 107/1000 | Loss: 0.00002742
Iteration 108/1000 | Loss: 0.00002742
Iteration 109/1000 | Loss: 0.00002742
Iteration 110/1000 | Loss: 0.00002742
Iteration 111/1000 | Loss: 0.00002742
Iteration 112/1000 | Loss: 0.00002742
Iteration 113/1000 | Loss: 0.00002742
Iteration 114/1000 | Loss: 0.00002742
Iteration 115/1000 | Loss: 0.00002742
Iteration 116/1000 | Loss: 0.00002742
Iteration 117/1000 | Loss: 0.00002742
Iteration 118/1000 | Loss: 0.00002742
Iteration 119/1000 | Loss: 0.00002742
Iteration 120/1000 | Loss: 0.00002742
Iteration 121/1000 | Loss: 0.00002742
Iteration 122/1000 | Loss: 0.00002742
Iteration 123/1000 | Loss: 0.00002742
Iteration 124/1000 | Loss: 0.00002742
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [2.7416708689997904e-05, 2.7416708689997904e-05, 2.7416708689997904e-05, 2.7416708689997904e-05, 2.7416708689997904e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7416708689997904e-05

Optimization complete. Final v2v error: 4.406285762786865 mm

Highest mean error: 4.6410603523254395 mm for frame 41

Lowest mean error: 4.256977558135986 mm for frame 144

Saving results

Total time: 54.59086585044861
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1053/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1053.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1053
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00997080
Iteration 2/25 | Loss: 0.00997080
Iteration 3/25 | Loss: 0.00997080
Iteration 4/25 | Loss: 0.00997079
Iteration 5/25 | Loss: 0.00997079
Iteration 6/25 | Loss: 0.00392360
Iteration 7/25 | Loss: 0.00223928
Iteration 8/25 | Loss: 0.00208302
Iteration 9/25 | Loss: 0.00195590
Iteration 10/25 | Loss: 0.00189637
Iteration 11/25 | Loss: 0.00183049
Iteration 12/25 | Loss: 0.00187655
Iteration 13/25 | Loss: 0.00211308
Iteration 14/25 | Loss: 0.00156818
Iteration 15/25 | Loss: 0.00118130
Iteration 16/25 | Loss: 0.00096040
Iteration 17/25 | Loss: 0.00088721
Iteration 18/25 | Loss: 0.00086868
Iteration 19/25 | Loss: 0.00086570
Iteration 20/25 | Loss: 0.00086413
Iteration 21/25 | Loss: 0.00086332
Iteration 22/25 | Loss: 0.00086193
Iteration 23/25 | Loss: 0.00086109
Iteration 24/25 | Loss: 0.00086069
Iteration 25/25 | Loss: 0.00086039

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49069953
Iteration 2/25 | Loss: 0.00087765
Iteration 3/25 | Loss: 0.00087765
Iteration 4/25 | Loss: 0.00087765
Iteration 5/25 | Loss: 0.00087765
Iteration 6/25 | Loss: 0.00087765
Iteration 7/25 | Loss: 0.00087765
Iteration 8/25 | Loss: 0.00087765
Iteration 9/25 | Loss: 0.00087765
Iteration 10/25 | Loss: 0.00087765
Iteration 11/25 | Loss: 0.00087765
Iteration 12/25 | Loss: 0.00087765
Iteration 13/25 | Loss: 0.00087765
Iteration 14/25 | Loss: 0.00087765
Iteration 15/25 | Loss: 0.00087765
Iteration 16/25 | Loss: 0.00087765
Iteration 17/25 | Loss: 0.00087765
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0008776456234045327, 0.0008776456234045327, 0.0008776456234045327, 0.0008776456234045327, 0.0008776456234045327]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008776456234045327

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00087765
Iteration 2/1000 | Loss: 0.00010145
Iteration 3/1000 | Loss: 0.00007788
Iteration 4/1000 | Loss: 0.00006496
Iteration 5/1000 | Loss: 0.00005555
Iteration 6/1000 | Loss: 0.00005137
Iteration 7/1000 | Loss: 0.00004863
Iteration 8/1000 | Loss: 0.00026935
Iteration 9/1000 | Loss: 0.00267971
Iteration 10/1000 | Loss: 0.00012955
Iteration 11/1000 | Loss: 0.00007069
Iteration 12/1000 | Loss: 0.00004973
Iteration 13/1000 | Loss: 0.00003384
Iteration 14/1000 | Loss: 0.00002556
Iteration 15/1000 | Loss: 0.00002109
Iteration 16/1000 | Loss: 0.00001869
Iteration 17/1000 | Loss: 0.00001743
Iteration 18/1000 | Loss: 0.00001629
Iteration 19/1000 | Loss: 0.00001559
Iteration 20/1000 | Loss: 0.00001530
Iteration 21/1000 | Loss: 0.00001503
Iteration 22/1000 | Loss: 0.00001474
Iteration 23/1000 | Loss: 0.00001459
Iteration 24/1000 | Loss: 0.00001451
Iteration 25/1000 | Loss: 0.00001446
Iteration 26/1000 | Loss: 0.00001446
Iteration 27/1000 | Loss: 0.00001445
Iteration 28/1000 | Loss: 0.00001444
Iteration 29/1000 | Loss: 0.00001444
Iteration 30/1000 | Loss: 0.00001444
Iteration 31/1000 | Loss: 0.00001444
Iteration 32/1000 | Loss: 0.00001442
Iteration 33/1000 | Loss: 0.00001442
Iteration 34/1000 | Loss: 0.00001441
Iteration 35/1000 | Loss: 0.00001441
Iteration 36/1000 | Loss: 0.00001437
Iteration 37/1000 | Loss: 0.00001437
Iteration 38/1000 | Loss: 0.00001436
Iteration 39/1000 | Loss: 0.00001436
Iteration 40/1000 | Loss: 0.00001436
Iteration 41/1000 | Loss: 0.00001436
Iteration 42/1000 | Loss: 0.00001435
Iteration 43/1000 | Loss: 0.00001435
Iteration 44/1000 | Loss: 0.00001435
Iteration 45/1000 | Loss: 0.00001434
Iteration 46/1000 | Loss: 0.00001434
Iteration 47/1000 | Loss: 0.00001434
Iteration 48/1000 | Loss: 0.00001433
Iteration 49/1000 | Loss: 0.00001433
Iteration 50/1000 | Loss: 0.00001433
Iteration 51/1000 | Loss: 0.00001433
Iteration 52/1000 | Loss: 0.00001433
Iteration 53/1000 | Loss: 0.00001432
Iteration 54/1000 | Loss: 0.00001432
Iteration 55/1000 | Loss: 0.00001432
Iteration 56/1000 | Loss: 0.00001432
Iteration 57/1000 | Loss: 0.00001432
Iteration 58/1000 | Loss: 0.00001432
Iteration 59/1000 | Loss: 0.00001432
Iteration 60/1000 | Loss: 0.00001432
Iteration 61/1000 | Loss: 0.00001432
Iteration 62/1000 | Loss: 0.00001432
Iteration 63/1000 | Loss: 0.00001432
Iteration 64/1000 | Loss: 0.00001432
Iteration 65/1000 | Loss: 0.00001432
Iteration 66/1000 | Loss: 0.00001432
Iteration 67/1000 | Loss: 0.00001432
Iteration 68/1000 | Loss: 0.00001432
Iteration 69/1000 | Loss: 0.00001432
Iteration 70/1000 | Loss: 0.00001432
Iteration 71/1000 | Loss: 0.00001432
Iteration 72/1000 | Loss: 0.00001432
Iteration 73/1000 | Loss: 0.00001432
Iteration 74/1000 | Loss: 0.00001432
Iteration 75/1000 | Loss: 0.00001432
Iteration 76/1000 | Loss: 0.00001432
Iteration 77/1000 | Loss: 0.00001432
Iteration 78/1000 | Loss: 0.00001432
Iteration 79/1000 | Loss: 0.00001432
Iteration 80/1000 | Loss: 0.00001432
Iteration 81/1000 | Loss: 0.00001432
Iteration 82/1000 | Loss: 0.00001432
Iteration 83/1000 | Loss: 0.00001432
Iteration 84/1000 | Loss: 0.00001432
Iteration 85/1000 | Loss: 0.00001432
Iteration 86/1000 | Loss: 0.00001432
Iteration 87/1000 | Loss: 0.00001432
Iteration 88/1000 | Loss: 0.00001432
Iteration 89/1000 | Loss: 0.00001432
Iteration 90/1000 | Loss: 0.00001432
Iteration 91/1000 | Loss: 0.00001432
Iteration 92/1000 | Loss: 0.00001432
Iteration 93/1000 | Loss: 0.00001432
Iteration 94/1000 | Loss: 0.00001432
Iteration 95/1000 | Loss: 0.00001432
Iteration 96/1000 | Loss: 0.00001432
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 96. Stopping optimization.
Last 5 losses: [1.4318072317109909e-05, 1.4318072317109909e-05, 1.4318072317109909e-05, 1.4318072317109909e-05, 1.4318072317109909e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4318072317109909e-05

Optimization complete. Final v2v error: 3.215841054916382 mm

Highest mean error: 3.5906577110290527 mm for frame 84

Lowest mean error: 3.052464485168457 mm for frame 3

Saving results

Total time: 87.36521244049072
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1037/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1037.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1037
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00426060
Iteration 2/25 | Loss: 0.00109858
Iteration 3/25 | Loss: 0.00079411
Iteration 4/25 | Loss: 0.00076764
Iteration 5/25 | Loss: 0.00076278
Iteration 6/25 | Loss: 0.00076072
Iteration 7/25 | Loss: 0.00076028
Iteration 8/25 | Loss: 0.00076028
Iteration 9/25 | Loss: 0.00076028
Iteration 10/25 | Loss: 0.00076028
Iteration 11/25 | Loss: 0.00076028
Iteration 12/25 | Loss: 0.00076028
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007602848927490413, 0.0007602848927490413, 0.0007602848927490413, 0.0007602848927490413, 0.0007602848927490413]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007602848927490413

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.94274282
Iteration 2/25 | Loss: 0.00049590
Iteration 3/25 | Loss: 0.00049589
Iteration 4/25 | Loss: 0.00049589
Iteration 5/25 | Loss: 0.00049589
Iteration 6/25 | Loss: 0.00049589
Iteration 7/25 | Loss: 0.00049589
Iteration 8/25 | Loss: 0.00049589
Iteration 9/25 | Loss: 0.00049589
Iteration 10/25 | Loss: 0.00049589
Iteration 11/25 | Loss: 0.00049589
Iteration 12/25 | Loss: 0.00049589
Iteration 13/25 | Loss: 0.00049589
Iteration 14/25 | Loss: 0.00049589
Iteration 15/25 | Loss: 0.00049589
Iteration 16/25 | Loss: 0.00049589
Iteration 17/25 | Loss: 0.00049589
Iteration 18/25 | Loss: 0.00049589
Iteration 19/25 | Loss: 0.00049589
Iteration 20/25 | Loss: 0.00049589
Iteration 21/25 | Loss: 0.00049589
Iteration 22/25 | Loss: 0.00049589
Iteration 23/25 | Loss: 0.00049589
Iteration 24/25 | Loss: 0.00049589
Iteration 25/25 | Loss: 0.00049589

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049589
Iteration 2/1000 | Loss: 0.00002486
Iteration 3/1000 | Loss: 0.00001715
Iteration 4/1000 | Loss: 0.00001515
Iteration 5/1000 | Loss: 0.00001447
Iteration 6/1000 | Loss: 0.00001387
Iteration 7/1000 | Loss: 0.00001351
Iteration 8/1000 | Loss: 0.00001324
Iteration 9/1000 | Loss: 0.00001301
Iteration 10/1000 | Loss: 0.00001295
Iteration 11/1000 | Loss: 0.00001290
Iteration 12/1000 | Loss: 0.00001287
Iteration 13/1000 | Loss: 0.00001286
Iteration 14/1000 | Loss: 0.00001285
Iteration 15/1000 | Loss: 0.00001284
Iteration 16/1000 | Loss: 0.00001283
Iteration 17/1000 | Loss: 0.00001272
Iteration 18/1000 | Loss: 0.00001269
Iteration 19/1000 | Loss: 0.00001267
Iteration 20/1000 | Loss: 0.00001266
Iteration 21/1000 | Loss: 0.00001266
Iteration 22/1000 | Loss: 0.00001264
Iteration 23/1000 | Loss: 0.00001260
Iteration 24/1000 | Loss: 0.00001260
Iteration 25/1000 | Loss: 0.00001258
Iteration 26/1000 | Loss: 0.00001258
Iteration 27/1000 | Loss: 0.00001257
Iteration 28/1000 | Loss: 0.00001256
Iteration 29/1000 | Loss: 0.00001256
Iteration 30/1000 | Loss: 0.00001255
Iteration 31/1000 | Loss: 0.00001255
Iteration 32/1000 | Loss: 0.00001255
Iteration 33/1000 | Loss: 0.00001254
Iteration 34/1000 | Loss: 0.00001253
Iteration 35/1000 | Loss: 0.00001252
Iteration 36/1000 | Loss: 0.00001252
Iteration 37/1000 | Loss: 0.00001251
Iteration 38/1000 | Loss: 0.00001251
Iteration 39/1000 | Loss: 0.00001250
Iteration 40/1000 | Loss: 0.00001250
Iteration 41/1000 | Loss: 0.00001250
Iteration 42/1000 | Loss: 0.00001249
Iteration 43/1000 | Loss: 0.00001249
Iteration 44/1000 | Loss: 0.00001249
Iteration 45/1000 | Loss: 0.00001249
Iteration 46/1000 | Loss: 0.00001249
Iteration 47/1000 | Loss: 0.00001248
Iteration 48/1000 | Loss: 0.00001248
Iteration 49/1000 | Loss: 0.00001248
Iteration 50/1000 | Loss: 0.00001248
Iteration 51/1000 | Loss: 0.00001248
Iteration 52/1000 | Loss: 0.00001247
Iteration 53/1000 | Loss: 0.00001247
Iteration 54/1000 | Loss: 0.00001246
Iteration 55/1000 | Loss: 0.00001246
Iteration 56/1000 | Loss: 0.00001246
Iteration 57/1000 | Loss: 0.00001245
Iteration 58/1000 | Loss: 0.00001245
Iteration 59/1000 | Loss: 0.00001244
Iteration 60/1000 | Loss: 0.00001244
Iteration 61/1000 | Loss: 0.00001244
Iteration 62/1000 | Loss: 0.00001243
Iteration 63/1000 | Loss: 0.00001243
Iteration 64/1000 | Loss: 0.00001243
Iteration 65/1000 | Loss: 0.00001243
Iteration 66/1000 | Loss: 0.00001243
Iteration 67/1000 | Loss: 0.00001243
Iteration 68/1000 | Loss: 0.00001242
Iteration 69/1000 | Loss: 0.00001242
Iteration 70/1000 | Loss: 0.00001242
Iteration 71/1000 | Loss: 0.00001242
Iteration 72/1000 | Loss: 0.00001242
Iteration 73/1000 | Loss: 0.00001242
Iteration 74/1000 | Loss: 0.00001242
Iteration 75/1000 | Loss: 0.00001242
Iteration 76/1000 | Loss: 0.00001242
Iteration 77/1000 | Loss: 0.00001242
Iteration 78/1000 | Loss: 0.00001242
Iteration 79/1000 | Loss: 0.00001242
Iteration 80/1000 | Loss: 0.00001242
Iteration 81/1000 | Loss: 0.00001242
Iteration 82/1000 | Loss: 0.00001242
Iteration 83/1000 | Loss: 0.00001241
Iteration 84/1000 | Loss: 0.00001241
Iteration 85/1000 | Loss: 0.00001241
Iteration 86/1000 | Loss: 0.00001241
Iteration 87/1000 | Loss: 0.00001241
Iteration 88/1000 | Loss: 0.00001241
Iteration 89/1000 | Loss: 0.00001241
Iteration 90/1000 | Loss: 0.00001241
Iteration 91/1000 | Loss: 0.00001240
Iteration 92/1000 | Loss: 0.00001240
Iteration 93/1000 | Loss: 0.00001240
Iteration 94/1000 | Loss: 0.00001240
Iteration 95/1000 | Loss: 0.00001240
Iteration 96/1000 | Loss: 0.00001240
Iteration 97/1000 | Loss: 0.00001240
Iteration 98/1000 | Loss: 0.00001240
Iteration 99/1000 | Loss: 0.00001240
Iteration 100/1000 | Loss: 0.00001240
Iteration 101/1000 | Loss: 0.00001240
Iteration 102/1000 | Loss: 0.00001240
Iteration 103/1000 | Loss: 0.00001240
Iteration 104/1000 | Loss: 0.00001240
Iteration 105/1000 | Loss: 0.00001240
Iteration 106/1000 | Loss: 0.00001240
Iteration 107/1000 | Loss: 0.00001240
Iteration 108/1000 | Loss: 0.00001239
Iteration 109/1000 | Loss: 0.00001239
Iteration 110/1000 | Loss: 0.00001239
Iteration 111/1000 | Loss: 0.00001238
Iteration 112/1000 | Loss: 0.00001238
Iteration 113/1000 | Loss: 0.00001238
Iteration 114/1000 | Loss: 0.00001238
Iteration 115/1000 | Loss: 0.00001238
Iteration 116/1000 | Loss: 0.00001238
Iteration 117/1000 | Loss: 0.00001238
Iteration 118/1000 | Loss: 0.00001238
Iteration 119/1000 | Loss: 0.00001237
Iteration 120/1000 | Loss: 0.00001237
Iteration 121/1000 | Loss: 0.00001237
Iteration 122/1000 | Loss: 0.00001237
Iteration 123/1000 | Loss: 0.00001237
Iteration 124/1000 | Loss: 0.00001236
Iteration 125/1000 | Loss: 0.00001236
Iteration 126/1000 | Loss: 0.00001236
Iteration 127/1000 | Loss: 0.00001236
Iteration 128/1000 | Loss: 0.00001236
Iteration 129/1000 | Loss: 0.00001236
Iteration 130/1000 | Loss: 0.00001236
Iteration 131/1000 | Loss: 0.00001236
Iteration 132/1000 | Loss: 0.00001236
Iteration 133/1000 | Loss: 0.00001235
Iteration 134/1000 | Loss: 0.00001235
Iteration 135/1000 | Loss: 0.00001235
Iteration 136/1000 | Loss: 0.00001235
Iteration 137/1000 | Loss: 0.00001234
Iteration 138/1000 | Loss: 0.00001234
Iteration 139/1000 | Loss: 0.00001234
Iteration 140/1000 | Loss: 0.00001234
Iteration 141/1000 | Loss: 0.00001234
Iteration 142/1000 | Loss: 0.00001234
Iteration 143/1000 | Loss: 0.00001234
Iteration 144/1000 | Loss: 0.00001234
Iteration 145/1000 | Loss: 0.00001234
Iteration 146/1000 | Loss: 0.00001234
Iteration 147/1000 | Loss: 0.00001234
Iteration 148/1000 | Loss: 0.00001234
Iteration 149/1000 | Loss: 0.00001233
Iteration 150/1000 | Loss: 0.00001233
Iteration 151/1000 | Loss: 0.00001233
Iteration 152/1000 | Loss: 0.00001233
Iteration 153/1000 | Loss: 0.00001233
Iteration 154/1000 | Loss: 0.00001233
Iteration 155/1000 | Loss: 0.00001233
Iteration 156/1000 | Loss: 0.00001233
Iteration 157/1000 | Loss: 0.00001233
Iteration 158/1000 | Loss: 0.00001233
Iteration 159/1000 | Loss: 0.00001233
Iteration 160/1000 | Loss: 0.00001233
Iteration 161/1000 | Loss: 0.00001233
Iteration 162/1000 | Loss: 0.00001233
Iteration 163/1000 | Loss: 0.00001233
Iteration 164/1000 | Loss: 0.00001233
Iteration 165/1000 | Loss: 0.00001233
Iteration 166/1000 | Loss: 0.00001233
Iteration 167/1000 | Loss: 0.00001232
Iteration 168/1000 | Loss: 0.00001232
Iteration 169/1000 | Loss: 0.00001232
Iteration 170/1000 | Loss: 0.00001232
Iteration 171/1000 | Loss: 0.00001232
Iteration 172/1000 | Loss: 0.00001232
Iteration 173/1000 | Loss: 0.00001232
Iteration 174/1000 | Loss: 0.00001232
Iteration 175/1000 | Loss: 0.00001232
Iteration 176/1000 | Loss: 0.00001232
Iteration 177/1000 | Loss: 0.00001232
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.2323976989137009e-05, 1.2323976989137009e-05, 1.2323976989137009e-05, 1.2323976989137009e-05, 1.2323976989137009e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2323976989137009e-05

Optimization complete. Final v2v error: 2.9982259273529053 mm

Highest mean error: 3.4831461906433105 mm for frame 86

Lowest mean error: 2.7849743366241455 mm for frame 6

Saving results

Total time: 37.499887228012085
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_046/1051/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1051.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_046/1051
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00837934
Iteration 2/25 | Loss: 0.00119372
Iteration 3/25 | Loss: 0.00080483
Iteration 4/25 | Loss: 0.00075159
Iteration 5/25 | Loss: 0.00074302
Iteration 6/25 | Loss: 0.00074095
Iteration 7/25 | Loss: 0.00073987
Iteration 8/25 | Loss: 0.00073981
Iteration 9/25 | Loss: 0.00073981
Iteration 10/25 | Loss: 0.00073981
Iteration 11/25 | Loss: 0.00073981
Iteration 12/25 | Loss: 0.00073981
Iteration 13/25 | Loss: 0.00073981
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007398137240670621, 0.0007398137240670621, 0.0007398137240670621, 0.0007398137240670621, 0.0007398137240670621]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007398137240670621

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50124729
Iteration 2/25 | Loss: 0.00047396
Iteration 3/25 | Loss: 0.00047396
Iteration 4/25 | Loss: 0.00047396
Iteration 5/25 | Loss: 0.00047396
Iteration 6/25 | Loss: 0.00047396
Iteration 7/25 | Loss: 0.00047396
Iteration 8/25 | Loss: 0.00047396
Iteration 9/25 | Loss: 0.00047396
Iteration 10/25 | Loss: 0.00047396
Iteration 11/25 | Loss: 0.00047396
Iteration 12/25 | Loss: 0.00047396
Iteration 13/25 | Loss: 0.00047396
Iteration 14/25 | Loss: 0.00047396
Iteration 15/25 | Loss: 0.00047396
Iteration 16/25 | Loss: 0.00047396
Iteration 17/25 | Loss: 0.00047396
Iteration 18/25 | Loss: 0.00047396
Iteration 19/25 | Loss: 0.00047396
Iteration 20/25 | Loss: 0.00047396
Iteration 21/25 | Loss: 0.00047396
Iteration 22/25 | Loss: 0.00047396
Iteration 23/25 | Loss: 0.00047396
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00047395849833264947, 0.00047395849833264947, 0.00047395849833264947, 0.00047395849833264947, 0.00047395849833264947]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00047395849833264947

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047396
Iteration 2/1000 | Loss: 0.00001931
Iteration 3/1000 | Loss: 0.00001401
Iteration 4/1000 | Loss: 0.00001314
Iteration 5/1000 | Loss: 0.00001256
Iteration 6/1000 | Loss: 0.00001209
Iteration 7/1000 | Loss: 0.00001179
Iteration 8/1000 | Loss: 0.00001162
Iteration 9/1000 | Loss: 0.00001155
Iteration 10/1000 | Loss: 0.00001151
Iteration 11/1000 | Loss: 0.00001142
Iteration 12/1000 | Loss: 0.00001140
Iteration 13/1000 | Loss: 0.00001137
Iteration 14/1000 | Loss: 0.00001136
Iteration 15/1000 | Loss: 0.00001136
Iteration 16/1000 | Loss: 0.00001134
Iteration 17/1000 | Loss: 0.00001133
Iteration 18/1000 | Loss: 0.00001132
Iteration 19/1000 | Loss: 0.00001131
Iteration 20/1000 | Loss: 0.00001130
Iteration 21/1000 | Loss: 0.00001129
Iteration 22/1000 | Loss: 0.00001125
Iteration 23/1000 | Loss: 0.00001124
Iteration 24/1000 | Loss: 0.00001123
Iteration 25/1000 | Loss: 0.00001123
Iteration 26/1000 | Loss: 0.00001122
Iteration 27/1000 | Loss: 0.00001122
Iteration 28/1000 | Loss: 0.00001122
Iteration 29/1000 | Loss: 0.00001121
Iteration 30/1000 | Loss: 0.00001120
Iteration 31/1000 | Loss: 0.00001120
Iteration 32/1000 | Loss: 0.00001120
Iteration 33/1000 | Loss: 0.00001120
Iteration 34/1000 | Loss: 0.00001120
Iteration 35/1000 | Loss: 0.00001120
Iteration 36/1000 | Loss: 0.00001119
Iteration 37/1000 | Loss: 0.00001119
Iteration 38/1000 | Loss: 0.00001118
Iteration 39/1000 | Loss: 0.00001118
Iteration 40/1000 | Loss: 0.00001118
Iteration 41/1000 | Loss: 0.00001116
Iteration 42/1000 | Loss: 0.00001116
Iteration 43/1000 | Loss: 0.00001116
Iteration 44/1000 | Loss: 0.00001115
Iteration 45/1000 | Loss: 0.00001115
Iteration 46/1000 | Loss: 0.00001115
Iteration 47/1000 | Loss: 0.00001115
Iteration 48/1000 | Loss: 0.00001114
Iteration 49/1000 | Loss: 0.00001113
Iteration 50/1000 | Loss: 0.00001113
Iteration 51/1000 | Loss: 0.00001112
Iteration 52/1000 | Loss: 0.00001112
Iteration 53/1000 | Loss: 0.00001112
Iteration 54/1000 | Loss: 0.00001111
Iteration 55/1000 | Loss: 0.00001111
Iteration 56/1000 | Loss: 0.00001111
Iteration 57/1000 | Loss: 0.00001111
Iteration 58/1000 | Loss: 0.00001111
Iteration 59/1000 | Loss: 0.00001110
Iteration 60/1000 | Loss: 0.00001110
Iteration 61/1000 | Loss: 0.00001110
Iteration 62/1000 | Loss: 0.00001110
Iteration 63/1000 | Loss: 0.00001109
Iteration 64/1000 | Loss: 0.00001109
Iteration 65/1000 | Loss: 0.00001109
Iteration 66/1000 | Loss: 0.00001109
Iteration 67/1000 | Loss: 0.00001109
Iteration 68/1000 | Loss: 0.00001109
Iteration 69/1000 | Loss: 0.00001109
Iteration 70/1000 | Loss: 0.00001109
Iteration 71/1000 | Loss: 0.00001108
Iteration 72/1000 | Loss: 0.00001108
Iteration 73/1000 | Loss: 0.00001108
Iteration 74/1000 | Loss: 0.00001108
Iteration 75/1000 | Loss: 0.00001108
Iteration 76/1000 | Loss: 0.00001108
Iteration 77/1000 | Loss: 0.00001108
Iteration 78/1000 | Loss: 0.00001108
Iteration 79/1000 | Loss: 0.00001108
Iteration 80/1000 | Loss: 0.00001108
Iteration 81/1000 | Loss: 0.00001108
Iteration 82/1000 | Loss: 0.00001107
Iteration 83/1000 | Loss: 0.00001107
Iteration 84/1000 | Loss: 0.00001107
Iteration 85/1000 | Loss: 0.00001107
Iteration 86/1000 | Loss: 0.00001107
Iteration 87/1000 | Loss: 0.00001107
Iteration 88/1000 | Loss: 0.00001107
Iteration 89/1000 | Loss: 0.00001107
Iteration 90/1000 | Loss: 0.00001107
Iteration 91/1000 | Loss: 0.00001107
Iteration 92/1000 | Loss: 0.00001107
Iteration 93/1000 | Loss: 0.00001107
Iteration 94/1000 | Loss: 0.00001107
Iteration 95/1000 | Loss: 0.00001107
Iteration 96/1000 | Loss: 0.00001107
Iteration 97/1000 | Loss: 0.00001106
Iteration 98/1000 | Loss: 0.00001106
Iteration 99/1000 | Loss: 0.00001106
Iteration 100/1000 | Loss: 0.00001106
Iteration 101/1000 | Loss: 0.00001106
Iteration 102/1000 | Loss: 0.00001106
Iteration 103/1000 | Loss: 0.00001106
Iteration 104/1000 | Loss: 0.00001106
Iteration 105/1000 | Loss: 0.00001106
Iteration 106/1000 | Loss: 0.00001106
Iteration 107/1000 | Loss: 0.00001106
Iteration 108/1000 | Loss: 0.00001106
Iteration 109/1000 | Loss: 0.00001106
Iteration 110/1000 | Loss: 0.00001106
Iteration 111/1000 | Loss: 0.00001106
Iteration 112/1000 | Loss: 0.00001106
Iteration 113/1000 | Loss: 0.00001106
Iteration 114/1000 | Loss: 0.00001106
Iteration 115/1000 | Loss: 0.00001106
Iteration 116/1000 | Loss: 0.00001106
Iteration 117/1000 | Loss: 0.00001106
Iteration 118/1000 | Loss: 0.00001106
Iteration 119/1000 | Loss: 0.00001105
Iteration 120/1000 | Loss: 0.00001105
Iteration 121/1000 | Loss: 0.00001105
Iteration 122/1000 | Loss: 0.00001105
Iteration 123/1000 | Loss: 0.00001105
Iteration 124/1000 | Loss: 0.00001105
Iteration 125/1000 | Loss: 0.00001105
Iteration 126/1000 | Loss: 0.00001105
Iteration 127/1000 | Loss: 0.00001104
Iteration 128/1000 | Loss: 0.00001104
Iteration 129/1000 | Loss: 0.00001104
Iteration 130/1000 | Loss: 0.00001104
Iteration 131/1000 | Loss: 0.00001103
Iteration 132/1000 | Loss: 0.00001103
Iteration 133/1000 | Loss: 0.00001103
Iteration 134/1000 | Loss: 0.00001102
Iteration 135/1000 | Loss: 0.00001102
Iteration 136/1000 | Loss: 0.00001102
Iteration 137/1000 | Loss: 0.00001102
Iteration 138/1000 | Loss: 0.00001102
Iteration 139/1000 | Loss: 0.00001102
Iteration 140/1000 | Loss: 0.00001102
Iteration 141/1000 | Loss: 0.00001102
Iteration 142/1000 | Loss: 0.00001102
Iteration 143/1000 | Loss: 0.00001102
Iteration 144/1000 | Loss: 0.00001102
Iteration 145/1000 | Loss: 0.00001102
Iteration 146/1000 | Loss: 0.00001102
Iteration 147/1000 | Loss: 0.00001102
Iteration 148/1000 | Loss: 0.00001101
Iteration 149/1000 | Loss: 0.00001101
Iteration 150/1000 | Loss: 0.00001101
Iteration 151/1000 | Loss: 0.00001101
Iteration 152/1000 | Loss: 0.00001101
Iteration 153/1000 | Loss: 0.00001101
Iteration 154/1000 | Loss: 0.00001101
Iteration 155/1000 | Loss: 0.00001101
Iteration 156/1000 | Loss: 0.00001101
Iteration 157/1000 | Loss: 0.00001101
Iteration 158/1000 | Loss: 0.00001101
Iteration 159/1000 | Loss: 0.00001101
Iteration 160/1000 | Loss: 0.00001100
Iteration 161/1000 | Loss: 0.00001100
Iteration 162/1000 | Loss: 0.00001100
Iteration 163/1000 | Loss: 0.00001100
Iteration 164/1000 | Loss: 0.00001100
Iteration 165/1000 | Loss: 0.00001100
Iteration 166/1000 | Loss: 0.00001100
Iteration 167/1000 | Loss: 0.00001100
Iteration 168/1000 | Loss: 0.00001100
Iteration 169/1000 | Loss: 0.00001099
Iteration 170/1000 | Loss: 0.00001099
Iteration 171/1000 | Loss: 0.00001099
Iteration 172/1000 | Loss: 0.00001099
Iteration 173/1000 | Loss: 0.00001099
Iteration 174/1000 | Loss: 0.00001099
Iteration 175/1000 | Loss: 0.00001099
Iteration 176/1000 | Loss: 0.00001099
Iteration 177/1000 | Loss: 0.00001099
Iteration 178/1000 | Loss: 0.00001099
Iteration 179/1000 | Loss: 0.00001098
Iteration 180/1000 | Loss: 0.00001098
Iteration 181/1000 | Loss: 0.00001098
Iteration 182/1000 | Loss: 0.00001098
Iteration 183/1000 | Loss: 0.00001098
Iteration 184/1000 | Loss: 0.00001098
Iteration 185/1000 | Loss: 0.00001098
Iteration 186/1000 | Loss: 0.00001098
Iteration 187/1000 | Loss: 0.00001098
Iteration 188/1000 | Loss: 0.00001098
Iteration 189/1000 | Loss: 0.00001098
Iteration 190/1000 | Loss: 0.00001098
Iteration 191/1000 | Loss: 0.00001098
Iteration 192/1000 | Loss: 0.00001098
Iteration 193/1000 | Loss: 0.00001098
Iteration 194/1000 | Loss: 0.00001098
Iteration 195/1000 | Loss: 0.00001098
Iteration 196/1000 | Loss: 0.00001098
Iteration 197/1000 | Loss: 0.00001098
Iteration 198/1000 | Loss: 0.00001098
Iteration 199/1000 | Loss: 0.00001098
Iteration 200/1000 | Loss: 0.00001098
Iteration 201/1000 | Loss: 0.00001098
Iteration 202/1000 | Loss: 0.00001098
Iteration 203/1000 | Loss: 0.00001098
Iteration 204/1000 | Loss: 0.00001098
Iteration 205/1000 | Loss: 0.00001098
Iteration 206/1000 | Loss: 0.00001098
Iteration 207/1000 | Loss: 0.00001098
Iteration 208/1000 | Loss: 0.00001098
Iteration 209/1000 | Loss: 0.00001098
Iteration 210/1000 | Loss: 0.00001098
Iteration 211/1000 | Loss: 0.00001098
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 211. Stopping optimization.
Last 5 losses: [1.0982630556100048e-05, 1.0982630556100048e-05, 1.0982630556100048e-05, 1.0982630556100048e-05, 1.0982630556100048e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0982630556100048e-05

Optimization complete. Final v2v error: 2.796443223953247 mm

Highest mean error: 3.071833372116089 mm for frame 58

Lowest mean error: 2.5921144485473633 mm for frame 3

Saving results

Total time: 39.051382303237915
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01115112
Iteration 2/25 | Loss: 0.00227072
Iteration 3/25 | Loss: 0.00181931
Iteration 4/25 | Loss: 0.00142185
Iteration 5/25 | Loss: 0.00125030
Iteration 6/25 | Loss: 0.00121104
Iteration 7/25 | Loss: 0.00112735
Iteration 8/25 | Loss: 0.00107323
Iteration 9/25 | Loss: 0.00104833
Iteration 10/25 | Loss: 0.00102627
Iteration 11/25 | Loss: 0.00101699
Iteration 12/25 | Loss: 0.00101361
Iteration 13/25 | Loss: 0.00101566
Iteration 14/25 | Loss: 0.00100950
Iteration 15/25 | Loss: 0.00100814
Iteration 16/25 | Loss: 0.00100773
Iteration 17/25 | Loss: 0.00100761
Iteration 18/25 | Loss: 0.00100759
Iteration 19/25 | Loss: 0.00100757
Iteration 20/25 | Loss: 0.00100757
Iteration 21/25 | Loss: 0.00100757
Iteration 22/25 | Loss: 0.00100756
Iteration 23/25 | Loss: 0.00100756
Iteration 24/25 | Loss: 0.00100756
Iteration 25/25 | Loss: 0.00100756

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80144823
Iteration 2/25 | Loss: 0.00511732
Iteration 3/25 | Loss: 0.00491676
Iteration 4/25 | Loss: 0.00491676
Iteration 5/25 | Loss: 0.00491676
Iteration 6/25 | Loss: 0.00491676
Iteration 7/25 | Loss: 0.00491676
Iteration 8/25 | Loss: 0.00491676
Iteration 9/25 | Loss: 0.00491676
Iteration 10/25 | Loss: 0.00491676
Iteration 11/25 | Loss: 0.00491676
Iteration 12/25 | Loss: 0.00491676
Iteration 13/25 | Loss: 0.00491676
Iteration 14/25 | Loss: 0.00491676
Iteration 15/25 | Loss: 0.00491676
Iteration 16/25 | Loss: 0.00491676
Iteration 17/25 | Loss: 0.00491676
Iteration 18/25 | Loss: 0.00491676
Iteration 19/25 | Loss: 0.00491676
Iteration 20/25 | Loss: 0.00491676
Iteration 21/25 | Loss: 0.00491676
Iteration 22/25 | Loss: 0.00491676
Iteration 23/25 | Loss: 0.00491676
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00491675827652216, 0.00491675827652216, 0.00491675827652216, 0.00491675827652216, 0.00491675827652216]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00491675827652216

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00491676
Iteration 2/1000 | Loss: 0.00003439
Iteration 3/1000 | Loss: 0.00013669
Iteration 4/1000 | Loss: 0.00029972
Iteration 5/1000 | Loss: 0.00007185
Iteration 6/1000 | Loss: 0.00002399
Iteration 7/1000 | Loss: 0.00005844
Iteration 8/1000 | Loss: 0.00002188
Iteration 9/1000 | Loss: 0.00006975
Iteration 10/1000 | Loss: 0.00020262
Iteration 11/1000 | Loss: 0.00027877
Iteration 12/1000 | Loss: 0.00014275
Iteration 13/1000 | Loss: 0.00002513
Iteration 14/1000 | Loss: 0.00002143
Iteration 15/1000 | Loss: 0.00001999
Iteration 16/1000 | Loss: 0.00001960
Iteration 17/1000 | Loss: 0.00001924
Iteration 18/1000 | Loss: 0.00008109
Iteration 19/1000 | Loss: 0.00006678
Iteration 20/1000 | Loss: 0.00001902
Iteration 21/1000 | Loss: 0.00001881
Iteration 22/1000 | Loss: 0.00001878
Iteration 23/1000 | Loss: 0.00001868
Iteration 24/1000 | Loss: 0.00001858
Iteration 25/1000 | Loss: 0.00001855
Iteration 26/1000 | Loss: 0.00001854
Iteration 27/1000 | Loss: 0.00001847
Iteration 28/1000 | Loss: 0.00001845
Iteration 29/1000 | Loss: 0.00001844
Iteration 30/1000 | Loss: 0.00001843
Iteration 31/1000 | Loss: 0.00001843
Iteration 32/1000 | Loss: 0.00001838
Iteration 33/1000 | Loss: 0.00001835
Iteration 34/1000 | Loss: 0.00001835
Iteration 35/1000 | Loss: 0.00001835
Iteration 36/1000 | Loss: 0.00001834
Iteration 37/1000 | Loss: 0.00001834
Iteration 38/1000 | Loss: 0.00001833
Iteration 39/1000 | Loss: 0.00006157
Iteration 40/1000 | Loss: 0.00012701
Iteration 41/1000 | Loss: 0.00002857
Iteration 42/1000 | Loss: 0.00001841
Iteration 43/1000 | Loss: 0.00001840
Iteration 44/1000 | Loss: 0.00001839
Iteration 45/1000 | Loss: 0.00001838
Iteration 46/1000 | Loss: 0.00001837
Iteration 47/1000 | Loss: 0.00001837
Iteration 48/1000 | Loss: 0.00001837
Iteration 49/1000 | Loss: 0.00001836
Iteration 50/1000 | Loss: 0.00001835
Iteration 51/1000 | Loss: 0.00001831
Iteration 52/1000 | Loss: 0.00001831
Iteration 53/1000 | Loss: 0.00001831
Iteration 54/1000 | Loss: 0.00001831
Iteration 55/1000 | Loss: 0.00001831
Iteration 56/1000 | Loss: 0.00001831
Iteration 57/1000 | Loss: 0.00001831
Iteration 58/1000 | Loss: 0.00001831
Iteration 59/1000 | Loss: 0.00001831
Iteration 60/1000 | Loss: 0.00001831
Iteration 61/1000 | Loss: 0.00001831
Iteration 62/1000 | Loss: 0.00001831
Iteration 63/1000 | Loss: 0.00001830
Iteration 64/1000 | Loss: 0.00001830
Iteration 65/1000 | Loss: 0.00001830
Iteration 66/1000 | Loss: 0.00004510
Iteration 67/1000 | Loss: 0.00002066
Iteration 68/1000 | Loss: 0.00002067
Iteration 69/1000 | Loss: 0.00001830
Iteration 70/1000 | Loss: 0.00001830
Iteration 71/1000 | Loss: 0.00001830
Iteration 72/1000 | Loss: 0.00001830
Iteration 73/1000 | Loss: 0.00001830
Iteration 74/1000 | Loss: 0.00001830
Iteration 75/1000 | Loss: 0.00001830
Iteration 76/1000 | Loss: 0.00001830
Iteration 77/1000 | Loss: 0.00001830
Iteration 78/1000 | Loss: 0.00001830
Iteration 79/1000 | Loss: 0.00001830
Iteration 80/1000 | Loss: 0.00001830
Iteration 81/1000 | Loss: 0.00001830
Iteration 82/1000 | Loss: 0.00001830
Iteration 83/1000 | Loss: 0.00001830
Iteration 84/1000 | Loss: 0.00001830
Iteration 85/1000 | Loss: 0.00001830
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [1.8298658687854186e-05, 1.8298658687854186e-05, 1.8298658687854186e-05, 1.8298658687854186e-05, 1.8298658687854186e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8298658687854186e-05

Optimization complete. Final v2v error: 3.585906744003296 mm

Highest mean error: 9.34080982208252 mm for frame 178

Lowest mean error: 3.2357935905456543 mm for frame 91

Saving results

Total time: 87.47225570678711
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405646
Iteration 2/25 | Loss: 0.00102286
Iteration 3/25 | Loss: 0.00093409
Iteration 4/25 | Loss: 0.00092247
Iteration 5/25 | Loss: 0.00092048
Iteration 6/25 | Loss: 0.00092048
Iteration 7/25 | Loss: 0.00092048
Iteration 8/25 | Loss: 0.00092048
Iteration 9/25 | Loss: 0.00092048
Iteration 10/25 | Loss: 0.00092048
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.0009204779635183513, 0.0009204779635183513, 0.0009204779635183513, 0.0009204779635183513, 0.0009204779635183513]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009204779635183513

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79712665
Iteration 2/25 | Loss: 0.00470964
Iteration 3/25 | Loss: 0.00470964
Iteration 4/25 | Loss: 0.00470964
Iteration 5/25 | Loss: 0.00470964
Iteration 6/25 | Loss: 0.00470964
Iteration 7/25 | Loss: 0.00470964
Iteration 8/25 | Loss: 0.00470964
Iteration 9/25 | Loss: 0.00470964
Iteration 10/25 | Loss: 0.00470964
Iteration 11/25 | Loss: 0.00470963
Iteration 12/25 | Loss: 0.00470964
Iteration 13/25 | Loss: 0.00470963
Iteration 14/25 | Loss: 0.00470963
Iteration 15/25 | Loss: 0.00470963
Iteration 16/25 | Loss: 0.00470963
Iteration 17/25 | Loss: 0.00470963
Iteration 18/25 | Loss: 0.00470963
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.004709634929895401, 0.004709634929895401, 0.004709634929895401, 0.004709634929895401, 0.004709634929895401]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004709634929895401

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00470963
Iteration 2/1000 | Loss: 0.00002061
Iteration 3/1000 | Loss: 0.00001614
Iteration 4/1000 | Loss: 0.00001527
Iteration 5/1000 | Loss: 0.00001443
Iteration 6/1000 | Loss: 0.00001405
Iteration 7/1000 | Loss: 0.00001369
Iteration 8/1000 | Loss: 0.00001350
Iteration 9/1000 | Loss: 0.00001349
Iteration 10/1000 | Loss: 0.00001348
Iteration 11/1000 | Loss: 0.00001341
Iteration 12/1000 | Loss: 0.00001341
Iteration 13/1000 | Loss: 0.00001341
Iteration 14/1000 | Loss: 0.00001341
Iteration 15/1000 | Loss: 0.00001341
Iteration 16/1000 | Loss: 0.00001341
Iteration 17/1000 | Loss: 0.00001340
Iteration 18/1000 | Loss: 0.00001340
Iteration 19/1000 | Loss: 0.00001339
Iteration 20/1000 | Loss: 0.00001337
Iteration 21/1000 | Loss: 0.00001335
Iteration 22/1000 | Loss: 0.00001335
Iteration 23/1000 | Loss: 0.00001335
Iteration 24/1000 | Loss: 0.00001335
Iteration 25/1000 | Loss: 0.00001333
Iteration 26/1000 | Loss: 0.00001333
Iteration 27/1000 | Loss: 0.00001332
Iteration 28/1000 | Loss: 0.00001332
Iteration 29/1000 | Loss: 0.00001331
Iteration 30/1000 | Loss: 0.00001330
Iteration 31/1000 | Loss: 0.00001330
Iteration 32/1000 | Loss: 0.00001330
Iteration 33/1000 | Loss: 0.00001327
Iteration 34/1000 | Loss: 0.00001327
Iteration 35/1000 | Loss: 0.00001326
Iteration 36/1000 | Loss: 0.00001325
Iteration 37/1000 | Loss: 0.00001324
Iteration 38/1000 | Loss: 0.00001323
Iteration 39/1000 | Loss: 0.00001323
Iteration 40/1000 | Loss: 0.00001323
Iteration 41/1000 | Loss: 0.00001322
Iteration 42/1000 | Loss: 0.00001322
Iteration 43/1000 | Loss: 0.00001322
Iteration 44/1000 | Loss: 0.00001321
Iteration 45/1000 | Loss: 0.00001320
Iteration 46/1000 | Loss: 0.00001319
Iteration 47/1000 | Loss: 0.00001319
Iteration 48/1000 | Loss: 0.00001319
Iteration 49/1000 | Loss: 0.00001319
Iteration 50/1000 | Loss: 0.00001318
Iteration 51/1000 | Loss: 0.00001318
Iteration 52/1000 | Loss: 0.00001318
Iteration 53/1000 | Loss: 0.00001318
Iteration 54/1000 | Loss: 0.00001318
Iteration 55/1000 | Loss: 0.00001318
Iteration 56/1000 | Loss: 0.00001318
Iteration 57/1000 | Loss: 0.00001318
Iteration 58/1000 | Loss: 0.00001318
Iteration 59/1000 | Loss: 0.00001318
Iteration 60/1000 | Loss: 0.00001318
Iteration 61/1000 | Loss: 0.00001318
Iteration 62/1000 | Loss: 0.00001318
Iteration 63/1000 | Loss: 0.00001317
Iteration 64/1000 | Loss: 0.00001317
Iteration 65/1000 | Loss: 0.00001317
Iteration 66/1000 | Loss: 0.00001316
Iteration 67/1000 | Loss: 0.00001316
Iteration 68/1000 | Loss: 0.00001316
Iteration 69/1000 | Loss: 0.00001316
Iteration 70/1000 | Loss: 0.00001316
Iteration 71/1000 | Loss: 0.00001316
Iteration 72/1000 | Loss: 0.00001316
Iteration 73/1000 | Loss: 0.00001316
Iteration 74/1000 | Loss: 0.00001316
Iteration 75/1000 | Loss: 0.00001316
Iteration 76/1000 | Loss: 0.00001315
Iteration 77/1000 | Loss: 0.00001315
Iteration 78/1000 | Loss: 0.00001315
Iteration 79/1000 | Loss: 0.00001315
Iteration 80/1000 | Loss: 0.00001315
Iteration 81/1000 | Loss: 0.00001315
Iteration 82/1000 | Loss: 0.00001315
Iteration 83/1000 | Loss: 0.00001315
Iteration 84/1000 | Loss: 0.00001315
Iteration 85/1000 | Loss: 0.00001315
Iteration 86/1000 | Loss: 0.00001315
Iteration 87/1000 | Loss: 0.00001315
Iteration 88/1000 | Loss: 0.00001315
Iteration 89/1000 | Loss: 0.00001314
Iteration 90/1000 | Loss: 0.00001314
Iteration 91/1000 | Loss: 0.00001314
Iteration 92/1000 | Loss: 0.00001314
Iteration 93/1000 | Loss: 0.00001314
Iteration 94/1000 | Loss: 0.00001314
Iteration 95/1000 | Loss: 0.00001314
Iteration 96/1000 | Loss: 0.00001314
Iteration 97/1000 | Loss: 0.00001314
Iteration 98/1000 | Loss: 0.00001314
Iteration 99/1000 | Loss: 0.00001314
Iteration 100/1000 | Loss: 0.00001314
Iteration 101/1000 | Loss: 0.00001314
Iteration 102/1000 | Loss: 0.00001314
Iteration 103/1000 | Loss: 0.00001314
Iteration 104/1000 | Loss: 0.00001314
Iteration 105/1000 | Loss: 0.00001314
Iteration 106/1000 | Loss: 0.00001314
Iteration 107/1000 | Loss: 0.00001314
Iteration 108/1000 | Loss: 0.00001314
Iteration 109/1000 | Loss: 0.00001313
Iteration 110/1000 | Loss: 0.00001313
Iteration 111/1000 | Loss: 0.00001313
Iteration 112/1000 | Loss: 0.00001313
Iteration 113/1000 | Loss: 0.00001313
Iteration 114/1000 | Loss: 0.00001313
Iteration 115/1000 | Loss: 0.00001313
Iteration 116/1000 | Loss: 0.00001313
Iteration 117/1000 | Loss: 0.00001313
Iteration 118/1000 | Loss: 0.00001313
Iteration 119/1000 | Loss: 0.00001313
Iteration 120/1000 | Loss: 0.00001313
Iteration 121/1000 | Loss: 0.00001313
Iteration 122/1000 | Loss: 0.00001313
Iteration 123/1000 | Loss: 0.00001313
Iteration 124/1000 | Loss: 0.00001312
Iteration 125/1000 | Loss: 0.00001312
Iteration 126/1000 | Loss: 0.00001312
Iteration 127/1000 | Loss: 0.00001312
Iteration 128/1000 | Loss: 0.00001312
Iteration 129/1000 | Loss: 0.00001312
Iteration 130/1000 | Loss: 0.00001312
Iteration 131/1000 | Loss: 0.00001312
Iteration 132/1000 | Loss: 0.00001312
Iteration 133/1000 | Loss: 0.00001312
Iteration 134/1000 | Loss: 0.00001312
Iteration 135/1000 | Loss: 0.00001312
Iteration 136/1000 | Loss: 0.00001312
Iteration 137/1000 | Loss: 0.00001312
Iteration 138/1000 | Loss: 0.00001311
Iteration 139/1000 | Loss: 0.00001311
Iteration 140/1000 | Loss: 0.00001311
Iteration 141/1000 | Loss: 0.00001311
Iteration 142/1000 | Loss: 0.00001311
Iteration 143/1000 | Loss: 0.00001311
Iteration 144/1000 | Loss: 0.00001311
Iteration 145/1000 | Loss: 0.00001311
Iteration 146/1000 | Loss: 0.00001311
Iteration 147/1000 | Loss: 0.00001311
Iteration 148/1000 | Loss: 0.00001311
Iteration 149/1000 | Loss: 0.00001311
Iteration 150/1000 | Loss: 0.00001311
Iteration 151/1000 | Loss: 0.00001311
Iteration 152/1000 | Loss: 0.00001311
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 152. Stopping optimization.
Last 5 losses: [1.3111956832290161e-05, 1.3111956832290161e-05, 1.3111956832290161e-05, 1.3111956832290161e-05, 1.3111956832290161e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3111956832290161e-05

Optimization complete. Final v2v error: 3.11440372467041 mm

Highest mean error: 3.30473256111145 mm for frame 181

Lowest mean error: 2.7685866355895996 mm for frame 1

Saving results

Total time: 32.58774733543396
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01104645
Iteration 2/25 | Loss: 0.00351847
Iteration 3/25 | Loss: 0.00233904
Iteration 4/25 | Loss: 0.00197631
Iteration 5/25 | Loss: 0.00183898
Iteration 6/25 | Loss: 0.00171705
Iteration 7/25 | Loss: 0.00168691
Iteration 8/25 | Loss: 0.00162846
Iteration 9/25 | Loss: 0.00154174
Iteration 10/25 | Loss: 0.00151413
Iteration 11/25 | Loss: 0.00145800
Iteration 12/25 | Loss: 0.00141112
Iteration 13/25 | Loss: 0.00139566
Iteration 14/25 | Loss: 0.00138442
Iteration 15/25 | Loss: 0.00137128
Iteration 16/25 | Loss: 0.00136977
Iteration 17/25 | Loss: 0.00136046
Iteration 18/25 | Loss: 0.00135101
Iteration 19/25 | Loss: 0.00133286
Iteration 20/25 | Loss: 0.00132318
Iteration 21/25 | Loss: 0.00131360
Iteration 22/25 | Loss: 0.00131499
Iteration 23/25 | Loss: 0.00130387
Iteration 24/25 | Loss: 0.00130070
Iteration 25/25 | Loss: 0.00129979

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.84559226
Iteration 2/25 | Loss: 0.00803687
Iteration 3/25 | Loss: 0.00801004
Iteration 4/25 | Loss: 0.00801003
Iteration 5/25 | Loss: 0.00801003
Iteration 6/25 | Loss: 0.00801003
Iteration 7/25 | Loss: 0.00801003
Iteration 8/25 | Loss: 0.00801003
Iteration 9/25 | Loss: 0.00801003
Iteration 10/25 | Loss: 0.00801003
Iteration 11/25 | Loss: 0.00801003
Iteration 12/25 | Loss: 0.00801003
Iteration 13/25 | Loss: 0.00801003
Iteration 14/25 | Loss: 0.00801003
Iteration 15/25 | Loss: 0.00801003
Iteration 16/25 | Loss: 0.00801003
Iteration 17/25 | Loss: 0.00801003
Iteration 18/25 | Loss: 0.00801003
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.008010027930140495, 0.008010027930140495, 0.008010027930140495, 0.008010027930140495, 0.008010027930140495]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.008010027930140495

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00801003
Iteration 2/1000 | Loss: 0.00075987
Iteration 3/1000 | Loss: 0.00057695
Iteration 4/1000 | Loss: 0.00225228
Iteration 5/1000 | Loss: 0.00182823
Iteration 6/1000 | Loss: 0.00076686
Iteration 7/1000 | Loss: 0.00076082
Iteration 8/1000 | Loss: 0.00131326
Iteration 9/1000 | Loss: 0.00127324
Iteration 10/1000 | Loss: 0.00096959
Iteration 11/1000 | Loss: 0.00038208
Iteration 12/1000 | Loss: 0.00071053
Iteration 13/1000 | Loss: 0.00128992
Iteration 14/1000 | Loss: 0.00130199
Iteration 15/1000 | Loss: 0.00031677
Iteration 16/1000 | Loss: 0.00020380
Iteration 17/1000 | Loss: 0.00019999
Iteration 18/1000 | Loss: 0.00017297
Iteration 19/1000 | Loss: 0.00017746
Iteration 20/1000 | Loss: 0.00087069
Iteration 21/1000 | Loss: 0.00017748
Iteration 22/1000 | Loss: 0.00082421
Iteration 23/1000 | Loss: 0.00063208
Iteration 24/1000 | Loss: 0.00064860
Iteration 25/1000 | Loss: 0.00017773
Iteration 26/1000 | Loss: 0.00224092
Iteration 27/1000 | Loss: 0.00439379
Iteration 28/1000 | Loss: 0.00105091
Iteration 29/1000 | Loss: 0.00051810
Iteration 30/1000 | Loss: 0.00036941
Iteration 31/1000 | Loss: 0.00019396
Iteration 32/1000 | Loss: 0.00017360
Iteration 33/1000 | Loss: 0.00046188
Iteration 34/1000 | Loss: 0.00015049
Iteration 35/1000 | Loss: 0.00020841
Iteration 36/1000 | Loss: 0.00041736
Iteration 37/1000 | Loss: 0.00010303
Iteration 38/1000 | Loss: 0.00032661
Iteration 39/1000 | Loss: 0.00010278
Iteration 40/1000 | Loss: 0.00009273
Iteration 41/1000 | Loss: 0.00011356
Iteration 42/1000 | Loss: 0.00009334
Iteration 43/1000 | Loss: 0.00032482
Iteration 44/1000 | Loss: 0.00030523
Iteration 45/1000 | Loss: 0.00010939
Iteration 46/1000 | Loss: 0.00010581
Iteration 47/1000 | Loss: 0.00045068
Iteration 48/1000 | Loss: 0.00082794
Iteration 49/1000 | Loss: 0.00010629
Iteration 50/1000 | Loss: 0.00020380
Iteration 51/1000 | Loss: 0.00007817
Iteration 52/1000 | Loss: 0.00009381
Iteration 53/1000 | Loss: 0.00007760
Iteration 54/1000 | Loss: 0.00036953
Iteration 55/1000 | Loss: 0.00008901
Iteration 56/1000 | Loss: 0.00007600
Iteration 57/1000 | Loss: 0.00010753
Iteration 58/1000 | Loss: 0.00009378
Iteration 59/1000 | Loss: 0.00010678
Iteration 60/1000 | Loss: 0.00008252
Iteration 61/1000 | Loss: 0.00008934
Iteration 62/1000 | Loss: 0.00012437
Iteration 63/1000 | Loss: 0.00012081
Iteration 64/1000 | Loss: 0.00008787
Iteration 65/1000 | Loss: 0.00009660
Iteration 66/1000 | Loss: 0.00051096
Iteration 67/1000 | Loss: 0.00008124
Iteration 68/1000 | Loss: 0.00007113
Iteration 69/1000 | Loss: 0.00148090
Iteration 70/1000 | Loss: 0.00067408
Iteration 71/1000 | Loss: 0.00013873
Iteration 72/1000 | Loss: 0.00009287
Iteration 73/1000 | Loss: 0.00007549
Iteration 74/1000 | Loss: 0.00115944
Iteration 75/1000 | Loss: 0.00194276
Iteration 76/1000 | Loss: 0.00069939
Iteration 77/1000 | Loss: 0.00139346
Iteration 78/1000 | Loss: 0.00027986
Iteration 79/1000 | Loss: 0.00031234
Iteration 80/1000 | Loss: 0.00011186
Iteration 81/1000 | Loss: 0.00026003
Iteration 82/1000 | Loss: 0.00038109
Iteration 83/1000 | Loss: 0.00036235
Iteration 84/1000 | Loss: 0.00036165
Iteration 85/1000 | Loss: 0.00040395
Iteration 86/1000 | Loss: 0.00019103
Iteration 87/1000 | Loss: 0.00007783
Iteration 88/1000 | Loss: 0.00033061
Iteration 89/1000 | Loss: 0.00099620
Iteration 90/1000 | Loss: 0.00042119
Iteration 91/1000 | Loss: 0.00015420
Iteration 92/1000 | Loss: 0.00080333
Iteration 93/1000 | Loss: 0.00085171
Iteration 94/1000 | Loss: 0.00050318
Iteration 95/1000 | Loss: 0.00087147
Iteration 96/1000 | Loss: 0.00062625
Iteration 97/1000 | Loss: 0.00057762
Iteration 98/1000 | Loss: 0.00050126
Iteration 99/1000 | Loss: 0.00054806
Iteration 100/1000 | Loss: 0.00024542
Iteration 101/1000 | Loss: 0.00043518
Iteration 102/1000 | Loss: 0.00037934
Iteration 103/1000 | Loss: 0.00043012
Iteration 104/1000 | Loss: 0.00020969
Iteration 105/1000 | Loss: 0.00021244
Iteration 106/1000 | Loss: 0.00025485
Iteration 107/1000 | Loss: 0.00047321
Iteration 108/1000 | Loss: 0.00027276
Iteration 109/1000 | Loss: 0.00028494
Iteration 110/1000 | Loss: 0.00029783
Iteration 111/1000 | Loss: 0.00048419
Iteration 112/1000 | Loss: 0.00037132
Iteration 113/1000 | Loss: 0.00021226
Iteration 114/1000 | Loss: 0.00072950
Iteration 115/1000 | Loss: 0.00035376
Iteration 116/1000 | Loss: 0.00035270
Iteration 117/1000 | Loss: 0.00034264
Iteration 118/1000 | Loss: 0.00038360
Iteration 119/1000 | Loss: 0.00093331
Iteration 120/1000 | Loss: 0.00038419
Iteration 121/1000 | Loss: 0.00068335
Iteration 122/1000 | Loss: 0.00059286
Iteration 123/1000 | Loss: 0.00087877
Iteration 124/1000 | Loss: 0.00046956
Iteration 125/1000 | Loss: 0.00070635
Iteration 126/1000 | Loss: 0.00045328
Iteration 127/1000 | Loss: 0.00091705
Iteration 128/1000 | Loss: 0.00048367
Iteration 129/1000 | Loss: 0.00088402
Iteration 130/1000 | Loss: 0.00058468
Iteration 131/1000 | Loss: 0.00078043
Iteration 132/1000 | Loss: 0.00059768
Iteration 133/1000 | Loss: 0.00015736
Iteration 134/1000 | Loss: 0.00035229
Iteration 135/1000 | Loss: 0.00041771
Iteration 136/1000 | Loss: 0.00037549
Iteration 137/1000 | Loss: 0.00026253
Iteration 138/1000 | Loss: 0.00039267
Iteration 139/1000 | Loss: 0.00027995
Iteration 140/1000 | Loss: 0.00010921
Iteration 141/1000 | Loss: 0.00006868
Iteration 142/1000 | Loss: 0.00054960
Iteration 143/1000 | Loss: 0.00017817
Iteration 144/1000 | Loss: 0.00053779
Iteration 145/1000 | Loss: 0.00051760
Iteration 146/1000 | Loss: 0.00007278
Iteration 147/1000 | Loss: 0.00021683
Iteration 148/1000 | Loss: 0.00005993
Iteration 149/1000 | Loss: 0.00009481
Iteration 150/1000 | Loss: 0.00005978
Iteration 151/1000 | Loss: 0.00049926
Iteration 152/1000 | Loss: 0.00006033
Iteration 153/1000 | Loss: 0.00006137
Iteration 154/1000 | Loss: 0.00052254
Iteration 155/1000 | Loss: 0.00026275
Iteration 156/1000 | Loss: 0.00021759
Iteration 157/1000 | Loss: 0.00005190
Iteration 158/1000 | Loss: 0.00006109
Iteration 159/1000 | Loss: 0.00005629
Iteration 160/1000 | Loss: 0.00005748
Iteration 161/1000 | Loss: 0.00005321
Iteration 162/1000 | Loss: 0.00056667
Iteration 163/1000 | Loss: 0.00005403
Iteration 164/1000 | Loss: 0.00006421
Iteration 165/1000 | Loss: 0.00004266
Iteration 166/1000 | Loss: 0.00017608
Iteration 167/1000 | Loss: 0.00003490
Iteration 168/1000 | Loss: 0.00047565
Iteration 169/1000 | Loss: 0.00008127
Iteration 170/1000 | Loss: 0.00015232
Iteration 171/1000 | Loss: 0.00003664
Iteration 172/1000 | Loss: 0.00003611
Iteration 173/1000 | Loss: 0.00003754
Iteration 174/1000 | Loss: 0.00003820
Iteration 175/1000 | Loss: 0.00003759
Iteration 176/1000 | Loss: 0.00003483
Iteration 177/1000 | Loss: 0.00003862
Iteration 178/1000 | Loss: 0.00003429
Iteration 179/1000 | Loss: 0.00003122
Iteration 180/1000 | Loss: 0.00002991
Iteration 181/1000 | Loss: 0.00003525
Iteration 182/1000 | Loss: 0.00003345
Iteration 183/1000 | Loss: 0.00003404
Iteration 184/1000 | Loss: 0.00002889
Iteration 185/1000 | Loss: 0.00027606
Iteration 186/1000 | Loss: 0.00020657
Iteration 187/1000 | Loss: 0.00023369
Iteration 188/1000 | Loss: 0.00025796
Iteration 189/1000 | Loss: 0.00040145
Iteration 190/1000 | Loss: 0.00026624
Iteration 191/1000 | Loss: 0.00044770
Iteration 192/1000 | Loss: 0.00043309
Iteration 193/1000 | Loss: 0.00008771
Iteration 194/1000 | Loss: 0.00006581
Iteration 195/1000 | Loss: 0.00014861
Iteration 196/1000 | Loss: 0.00027355
Iteration 197/1000 | Loss: 0.00017865
Iteration 198/1000 | Loss: 0.00041153
Iteration 199/1000 | Loss: 0.00018429
Iteration 200/1000 | Loss: 0.00003788
Iteration 201/1000 | Loss: 0.00004240
Iteration 202/1000 | Loss: 0.00019637
Iteration 203/1000 | Loss: 0.00002922
Iteration 204/1000 | Loss: 0.00027326
Iteration 205/1000 | Loss: 0.00014943
Iteration 206/1000 | Loss: 0.00005079
Iteration 207/1000 | Loss: 0.00006310
Iteration 208/1000 | Loss: 0.00003299
Iteration 209/1000 | Loss: 0.00002980
Iteration 210/1000 | Loss: 0.00002878
Iteration 211/1000 | Loss: 0.00002687
Iteration 212/1000 | Loss: 0.00002614
Iteration 213/1000 | Loss: 0.00002561
Iteration 214/1000 | Loss: 0.00002815
Iteration 215/1000 | Loss: 0.00004753
Iteration 216/1000 | Loss: 0.00002529
Iteration 217/1000 | Loss: 0.00002481
Iteration 218/1000 | Loss: 0.00002478
Iteration 219/1000 | Loss: 0.00002478
Iteration 220/1000 | Loss: 0.00002478
Iteration 221/1000 | Loss: 0.00002478
Iteration 222/1000 | Loss: 0.00002477
Iteration 223/1000 | Loss: 0.00002477
Iteration 224/1000 | Loss: 0.00002687
Iteration 225/1000 | Loss: 0.00002716
Iteration 226/1000 | Loss: 0.00002478
Iteration 227/1000 | Loss: 0.00002470
Iteration 228/1000 | Loss: 0.00002470
Iteration 229/1000 | Loss: 0.00002470
Iteration 230/1000 | Loss: 0.00002469
Iteration 231/1000 | Loss: 0.00002470
Iteration 232/1000 | Loss: 0.00002474
Iteration 233/1000 | Loss: 0.00002473
Iteration 234/1000 | Loss: 0.00002473
Iteration 235/1000 | Loss: 0.00002468
Iteration 236/1000 | Loss: 0.00002468
Iteration 237/1000 | Loss: 0.00002468
Iteration 238/1000 | Loss: 0.00002468
Iteration 239/1000 | Loss: 0.00002468
Iteration 240/1000 | Loss: 0.00002468
Iteration 241/1000 | Loss: 0.00002468
Iteration 242/1000 | Loss: 0.00002468
Iteration 243/1000 | Loss: 0.00002468
Iteration 244/1000 | Loss: 0.00002468
Iteration 245/1000 | Loss: 0.00002468
Iteration 246/1000 | Loss: 0.00002468
Iteration 247/1000 | Loss: 0.00002468
Iteration 248/1000 | Loss: 0.00002468
Iteration 249/1000 | Loss: 0.00002468
Iteration 250/1000 | Loss: 0.00002468
Iteration 251/1000 | Loss: 0.00002468
Iteration 252/1000 | Loss: 0.00002468
Iteration 253/1000 | Loss: 0.00002468
Iteration 254/1000 | Loss: 0.00002468
Iteration 255/1000 | Loss: 0.00002468
Iteration 256/1000 | Loss: 0.00002468
Iteration 257/1000 | Loss: 0.00002468
Iteration 258/1000 | Loss: 0.00002468
Iteration 259/1000 | Loss: 0.00002468
Iteration 260/1000 | Loss: 0.00002468
Iteration 261/1000 | Loss: 0.00002468
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 261. Stopping optimization.
Last 5 losses: [2.467969352437649e-05, 2.467969352437649e-05, 2.467969352437649e-05, 2.467969352437649e-05, 2.467969352437649e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.467969352437649e-05

Optimization complete. Final v2v error: 3.3809621334075928 mm

Highest mean error: 11.632473945617676 mm for frame 202

Lowest mean error: 2.643062114715576 mm for frame 152

Saving results

Total time: 404.0110375881195
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00468317
Iteration 2/25 | Loss: 0.00109893
Iteration 3/25 | Loss: 0.00097289
Iteration 4/25 | Loss: 0.00096028
Iteration 5/25 | Loss: 0.00095572
Iteration 6/25 | Loss: 0.00095486
Iteration 7/25 | Loss: 0.00095486
Iteration 8/25 | Loss: 0.00095486
Iteration 9/25 | Loss: 0.00095486
Iteration 10/25 | Loss: 0.00095486
Iteration 11/25 | Loss: 0.00095486
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009548570378683507, 0.0009548570378683507, 0.0009548570378683507, 0.0009548570378683507, 0.0009548570378683507]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009548570378683507

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79034770
Iteration 2/25 | Loss: 0.00447585
Iteration 3/25 | Loss: 0.00447585
Iteration 4/25 | Loss: 0.00447585
Iteration 5/25 | Loss: 0.00447585
Iteration 6/25 | Loss: 0.00447585
Iteration 7/25 | Loss: 0.00447585
Iteration 8/25 | Loss: 0.00447585
Iteration 9/25 | Loss: 0.00447585
Iteration 10/25 | Loss: 0.00447585
Iteration 11/25 | Loss: 0.00447585
Iteration 12/25 | Loss: 0.00447585
Iteration 13/25 | Loss: 0.00447585
Iteration 14/25 | Loss: 0.00447585
Iteration 15/25 | Loss: 0.00447585
Iteration 16/25 | Loss: 0.00447585
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.004475851077586412, 0.004475851077586412, 0.004475851077586412, 0.004475851077586412, 0.004475851077586412]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004475851077586412

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00447585
Iteration 2/1000 | Loss: 0.00003318
Iteration 3/1000 | Loss: 0.00002525
Iteration 4/1000 | Loss: 0.00002269
Iteration 5/1000 | Loss: 0.00002143
Iteration 6/1000 | Loss: 0.00002060
Iteration 7/1000 | Loss: 0.00002011
Iteration 8/1000 | Loss: 0.00001965
Iteration 9/1000 | Loss: 0.00001941
Iteration 10/1000 | Loss: 0.00001931
Iteration 11/1000 | Loss: 0.00001914
Iteration 12/1000 | Loss: 0.00001897
Iteration 13/1000 | Loss: 0.00001893
Iteration 14/1000 | Loss: 0.00001890
Iteration 15/1000 | Loss: 0.00001880
Iteration 16/1000 | Loss: 0.00001880
Iteration 17/1000 | Loss: 0.00001878
Iteration 18/1000 | Loss: 0.00001877
Iteration 19/1000 | Loss: 0.00001877
Iteration 20/1000 | Loss: 0.00001876
Iteration 21/1000 | Loss: 0.00001876
Iteration 22/1000 | Loss: 0.00001875
Iteration 23/1000 | Loss: 0.00001875
Iteration 24/1000 | Loss: 0.00001874
Iteration 25/1000 | Loss: 0.00001874
Iteration 26/1000 | Loss: 0.00001873
Iteration 27/1000 | Loss: 0.00001873
Iteration 28/1000 | Loss: 0.00001872
Iteration 29/1000 | Loss: 0.00001872
Iteration 30/1000 | Loss: 0.00001871
Iteration 31/1000 | Loss: 0.00001871
Iteration 32/1000 | Loss: 0.00001870
Iteration 33/1000 | Loss: 0.00001870
Iteration 34/1000 | Loss: 0.00001868
Iteration 35/1000 | Loss: 0.00001868
Iteration 36/1000 | Loss: 0.00001868
Iteration 37/1000 | Loss: 0.00001868
Iteration 38/1000 | Loss: 0.00001868
Iteration 39/1000 | Loss: 0.00001868
Iteration 40/1000 | Loss: 0.00001868
Iteration 41/1000 | Loss: 0.00001868
Iteration 42/1000 | Loss: 0.00001868
Iteration 43/1000 | Loss: 0.00001868
Iteration 44/1000 | Loss: 0.00001868
Iteration 45/1000 | Loss: 0.00001867
Iteration 46/1000 | Loss: 0.00001867
Iteration 47/1000 | Loss: 0.00001867
Iteration 48/1000 | Loss: 0.00001866
Iteration 49/1000 | Loss: 0.00001866
Iteration 50/1000 | Loss: 0.00001866
Iteration 51/1000 | Loss: 0.00001866
Iteration 52/1000 | Loss: 0.00001866
Iteration 53/1000 | Loss: 0.00001866
Iteration 54/1000 | Loss: 0.00001866
Iteration 55/1000 | Loss: 0.00001866
Iteration 56/1000 | Loss: 0.00001866
Iteration 57/1000 | Loss: 0.00001866
Iteration 58/1000 | Loss: 0.00001865
Iteration 59/1000 | Loss: 0.00001865
Iteration 60/1000 | Loss: 0.00001865
Iteration 61/1000 | Loss: 0.00001865
Iteration 62/1000 | Loss: 0.00001865
Iteration 63/1000 | Loss: 0.00001865
Iteration 64/1000 | Loss: 0.00001864
Iteration 65/1000 | Loss: 0.00001864
Iteration 66/1000 | Loss: 0.00001864
Iteration 67/1000 | Loss: 0.00001864
Iteration 68/1000 | Loss: 0.00001863
Iteration 69/1000 | Loss: 0.00001863
Iteration 70/1000 | Loss: 0.00001863
Iteration 71/1000 | Loss: 0.00001862
Iteration 72/1000 | Loss: 0.00001862
Iteration 73/1000 | Loss: 0.00001862
Iteration 74/1000 | Loss: 0.00001861
Iteration 75/1000 | Loss: 0.00001861
Iteration 76/1000 | Loss: 0.00001861
Iteration 77/1000 | Loss: 0.00001860
Iteration 78/1000 | Loss: 0.00001860
Iteration 79/1000 | Loss: 0.00001860
Iteration 80/1000 | Loss: 0.00001860
Iteration 81/1000 | Loss: 0.00001860
Iteration 82/1000 | Loss: 0.00001860
Iteration 83/1000 | Loss: 0.00001860
Iteration 84/1000 | Loss: 0.00001860
Iteration 85/1000 | Loss: 0.00001860
Iteration 86/1000 | Loss: 0.00001860
Iteration 87/1000 | Loss: 0.00001860
Iteration 88/1000 | Loss: 0.00001859
Iteration 89/1000 | Loss: 0.00001859
Iteration 90/1000 | Loss: 0.00001859
Iteration 91/1000 | Loss: 0.00001859
Iteration 92/1000 | Loss: 0.00001859
Iteration 93/1000 | Loss: 0.00001858
Iteration 94/1000 | Loss: 0.00001858
Iteration 95/1000 | Loss: 0.00001858
Iteration 96/1000 | Loss: 0.00001858
Iteration 97/1000 | Loss: 0.00001858
Iteration 98/1000 | Loss: 0.00001857
Iteration 99/1000 | Loss: 0.00001857
Iteration 100/1000 | Loss: 0.00001857
Iteration 101/1000 | Loss: 0.00001857
Iteration 102/1000 | Loss: 0.00001857
Iteration 103/1000 | Loss: 0.00001857
Iteration 104/1000 | Loss: 0.00001857
Iteration 105/1000 | Loss: 0.00001857
Iteration 106/1000 | Loss: 0.00001857
Iteration 107/1000 | Loss: 0.00001856
Iteration 108/1000 | Loss: 0.00001856
Iteration 109/1000 | Loss: 0.00001856
Iteration 110/1000 | Loss: 0.00001856
Iteration 111/1000 | Loss: 0.00001856
Iteration 112/1000 | Loss: 0.00001856
Iteration 113/1000 | Loss: 0.00001856
Iteration 114/1000 | Loss: 0.00001855
Iteration 115/1000 | Loss: 0.00001855
Iteration 116/1000 | Loss: 0.00001855
Iteration 117/1000 | Loss: 0.00001855
Iteration 118/1000 | Loss: 0.00001855
Iteration 119/1000 | Loss: 0.00001855
Iteration 120/1000 | Loss: 0.00001855
Iteration 121/1000 | Loss: 0.00001855
Iteration 122/1000 | Loss: 0.00001855
Iteration 123/1000 | Loss: 0.00001855
Iteration 124/1000 | Loss: 0.00001855
Iteration 125/1000 | Loss: 0.00001855
Iteration 126/1000 | Loss: 0.00001854
Iteration 127/1000 | Loss: 0.00001854
Iteration 128/1000 | Loss: 0.00001854
Iteration 129/1000 | Loss: 0.00001854
Iteration 130/1000 | Loss: 0.00001854
Iteration 131/1000 | Loss: 0.00001854
Iteration 132/1000 | Loss: 0.00001854
Iteration 133/1000 | Loss: 0.00001854
Iteration 134/1000 | Loss: 0.00001854
Iteration 135/1000 | Loss: 0.00001854
Iteration 136/1000 | Loss: 0.00001853
Iteration 137/1000 | Loss: 0.00001853
Iteration 138/1000 | Loss: 0.00001853
Iteration 139/1000 | Loss: 0.00001853
Iteration 140/1000 | Loss: 0.00001853
Iteration 141/1000 | Loss: 0.00001853
Iteration 142/1000 | Loss: 0.00001853
Iteration 143/1000 | Loss: 0.00001853
Iteration 144/1000 | Loss: 0.00001853
Iteration 145/1000 | Loss: 0.00001853
Iteration 146/1000 | Loss: 0.00001853
Iteration 147/1000 | Loss: 0.00001852
Iteration 148/1000 | Loss: 0.00001852
Iteration 149/1000 | Loss: 0.00001852
Iteration 150/1000 | Loss: 0.00001852
Iteration 151/1000 | Loss: 0.00001852
Iteration 152/1000 | Loss: 0.00001852
Iteration 153/1000 | Loss: 0.00001852
Iteration 154/1000 | Loss: 0.00001852
Iteration 155/1000 | Loss: 0.00001852
Iteration 156/1000 | Loss: 0.00001852
Iteration 157/1000 | Loss: 0.00001851
Iteration 158/1000 | Loss: 0.00001851
Iteration 159/1000 | Loss: 0.00001851
Iteration 160/1000 | Loss: 0.00001851
Iteration 161/1000 | Loss: 0.00001851
Iteration 162/1000 | Loss: 0.00001851
Iteration 163/1000 | Loss: 0.00001851
Iteration 164/1000 | Loss: 0.00001851
Iteration 165/1000 | Loss: 0.00001851
Iteration 166/1000 | Loss: 0.00001851
Iteration 167/1000 | Loss: 0.00001851
Iteration 168/1000 | Loss: 0.00001851
Iteration 169/1000 | Loss: 0.00001851
Iteration 170/1000 | Loss: 0.00001851
Iteration 171/1000 | Loss: 0.00001851
Iteration 172/1000 | Loss: 0.00001851
Iteration 173/1000 | Loss: 0.00001851
Iteration 174/1000 | Loss: 0.00001851
Iteration 175/1000 | Loss: 0.00001851
Iteration 176/1000 | Loss: 0.00001851
Iteration 177/1000 | Loss: 0.00001851
Iteration 178/1000 | Loss: 0.00001851
Iteration 179/1000 | Loss: 0.00001851
Iteration 180/1000 | Loss: 0.00001851
Iteration 181/1000 | Loss: 0.00001851
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 181. Stopping optimization.
Last 5 losses: [1.8505148545955308e-05, 1.8505148545955308e-05, 1.8505148545955308e-05, 1.8505148545955308e-05, 1.8505148545955308e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8505148545955308e-05

Optimization complete. Final v2v error: 3.6960220336914062 mm

Highest mean error: 4.069496154785156 mm for frame 220

Lowest mean error: 3.2214431762695312 mm for frame 3

Saving results

Total time: 42.79845881462097
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00914776
Iteration 2/25 | Loss: 0.00113759
Iteration 3/25 | Loss: 0.00096727
Iteration 4/25 | Loss: 0.00094087
Iteration 5/25 | Loss: 0.00093394
Iteration 6/25 | Loss: 0.00093215
Iteration 7/25 | Loss: 0.00093215
Iteration 8/25 | Loss: 0.00093215
Iteration 9/25 | Loss: 0.00093215
Iteration 10/25 | Loss: 0.00093215
Iteration 11/25 | Loss: 0.00093215
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0009321487159468234, 0.0009321487159468234, 0.0009321487159468234, 0.0009321487159468234, 0.0009321487159468234]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009321487159468234

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80749774
Iteration 2/25 | Loss: 0.00457516
Iteration 3/25 | Loss: 0.00457516
Iteration 4/25 | Loss: 0.00457516
Iteration 5/25 | Loss: 0.00457516
Iteration 6/25 | Loss: 0.00457516
Iteration 7/25 | Loss: 0.00457516
Iteration 8/25 | Loss: 0.00457515
Iteration 9/25 | Loss: 0.00457515
Iteration 10/25 | Loss: 0.00457515
Iteration 11/25 | Loss: 0.00457515
Iteration 12/25 | Loss: 0.00457515
Iteration 13/25 | Loss: 0.00457515
Iteration 14/25 | Loss: 0.00457515
Iteration 15/25 | Loss: 0.00457515
Iteration 16/25 | Loss: 0.00457515
Iteration 17/25 | Loss: 0.00457515
Iteration 18/25 | Loss: 0.00457515
Iteration 19/25 | Loss: 0.00457515
Iteration 20/25 | Loss: 0.00457515
Iteration 21/25 | Loss: 0.00457515
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.004575153812766075, 0.004575153812766075, 0.004575153812766075, 0.004575153812766075, 0.004575153812766075]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004575153812766075

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00457515
Iteration 2/1000 | Loss: 0.00002150
Iteration 3/1000 | Loss: 0.00001722
Iteration 4/1000 | Loss: 0.00001509
Iteration 5/1000 | Loss: 0.00001410
Iteration 6/1000 | Loss: 0.00001356
Iteration 7/1000 | Loss: 0.00001327
Iteration 8/1000 | Loss: 0.00001316
Iteration 9/1000 | Loss: 0.00001295
Iteration 10/1000 | Loss: 0.00001291
Iteration 11/1000 | Loss: 0.00001291
Iteration 12/1000 | Loss: 0.00001285
Iteration 13/1000 | Loss: 0.00001284
Iteration 14/1000 | Loss: 0.00001283
Iteration 15/1000 | Loss: 0.00001279
Iteration 16/1000 | Loss: 0.00001275
Iteration 17/1000 | Loss: 0.00001274
Iteration 18/1000 | Loss: 0.00001269
Iteration 19/1000 | Loss: 0.00001267
Iteration 20/1000 | Loss: 0.00001267
Iteration 21/1000 | Loss: 0.00001266
Iteration 22/1000 | Loss: 0.00001265
Iteration 23/1000 | Loss: 0.00001264
Iteration 24/1000 | Loss: 0.00001260
Iteration 25/1000 | Loss: 0.00001260
Iteration 26/1000 | Loss: 0.00001259
Iteration 27/1000 | Loss: 0.00001252
Iteration 28/1000 | Loss: 0.00001252
Iteration 29/1000 | Loss: 0.00001251
Iteration 30/1000 | Loss: 0.00001251
Iteration 31/1000 | Loss: 0.00001249
Iteration 32/1000 | Loss: 0.00001248
Iteration 33/1000 | Loss: 0.00001248
Iteration 34/1000 | Loss: 0.00001248
Iteration 35/1000 | Loss: 0.00001248
Iteration 36/1000 | Loss: 0.00001248
Iteration 37/1000 | Loss: 0.00001247
Iteration 38/1000 | Loss: 0.00001247
Iteration 39/1000 | Loss: 0.00001247
Iteration 40/1000 | Loss: 0.00001246
Iteration 41/1000 | Loss: 0.00001246
Iteration 42/1000 | Loss: 0.00001246
Iteration 43/1000 | Loss: 0.00001245
Iteration 44/1000 | Loss: 0.00001245
Iteration 45/1000 | Loss: 0.00001245
Iteration 46/1000 | Loss: 0.00001244
Iteration 47/1000 | Loss: 0.00001244
Iteration 48/1000 | Loss: 0.00001244
Iteration 49/1000 | Loss: 0.00001244
Iteration 50/1000 | Loss: 0.00001243
Iteration 51/1000 | Loss: 0.00001243
Iteration 52/1000 | Loss: 0.00001243
Iteration 53/1000 | Loss: 0.00001243
Iteration 54/1000 | Loss: 0.00001242
Iteration 55/1000 | Loss: 0.00001242
Iteration 56/1000 | Loss: 0.00001241
Iteration 57/1000 | Loss: 0.00001241
Iteration 58/1000 | Loss: 0.00001241
Iteration 59/1000 | Loss: 0.00001241
Iteration 60/1000 | Loss: 0.00001240
Iteration 61/1000 | Loss: 0.00001240
Iteration 62/1000 | Loss: 0.00001240
Iteration 63/1000 | Loss: 0.00001240
Iteration 64/1000 | Loss: 0.00001240
Iteration 65/1000 | Loss: 0.00001240
Iteration 66/1000 | Loss: 0.00001240
Iteration 67/1000 | Loss: 0.00001240
Iteration 68/1000 | Loss: 0.00001240
Iteration 69/1000 | Loss: 0.00001240
Iteration 70/1000 | Loss: 0.00001240
Iteration 71/1000 | Loss: 0.00001240
Iteration 72/1000 | Loss: 0.00001240
Iteration 73/1000 | Loss: 0.00001239
Iteration 74/1000 | Loss: 0.00001239
Iteration 75/1000 | Loss: 0.00001239
Iteration 76/1000 | Loss: 0.00001239
Iteration 77/1000 | Loss: 0.00001239
Iteration 78/1000 | Loss: 0.00001239
Iteration 79/1000 | Loss: 0.00001239
Iteration 80/1000 | Loss: 0.00001238
Iteration 81/1000 | Loss: 0.00001238
Iteration 82/1000 | Loss: 0.00001238
Iteration 83/1000 | Loss: 0.00001238
Iteration 84/1000 | Loss: 0.00001238
Iteration 85/1000 | Loss: 0.00001238
Iteration 86/1000 | Loss: 0.00001238
Iteration 87/1000 | Loss: 0.00001238
Iteration 88/1000 | Loss: 0.00001238
Iteration 89/1000 | Loss: 0.00001238
Iteration 90/1000 | Loss: 0.00001238
Iteration 91/1000 | Loss: 0.00001238
Iteration 92/1000 | Loss: 0.00001238
Iteration 93/1000 | Loss: 0.00001238
Iteration 94/1000 | Loss: 0.00001238
Iteration 95/1000 | Loss: 0.00001238
Iteration 96/1000 | Loss: 0.00001238
Iteration 97/1000 | Loss: 0.00001238
Iteration 98/1000 | Loss: 0.00001238
Iteration 99/1000 | Loss: 0.00001238
Iteration 100/1000 | Loss: 0.00001238
Iteration 101/1000 | Loss: 0.00001238
Iteration 102/1000 | Loss: 0.00001238
Iteration 103/1000 | Loss: 0.00001238
Iteration 104/1000 | Loss: 0.00001238
Iteration 105/1000 | Loss: 0.00001238
Iteration 106/1000 | Loss: 0.00001238
Iteration 107/1000 | Loss: 0.00001238
Iteration 108/1000 | Loss: 0.00001238
Iteration 109/1000 | Loss: 0.00001238
Iteration 110/1000 | Loss: 0.00001238
Iteration 111/1000 | Loss: 0.00001238
Iteration 112/1000 | Loss: 0.00001238
Iteration 113/1000 | Loss: 0.00001238
Iteration 114/1000 | Loss: 0.00001238
Iteration 115/1000 | Loss: 0.00001238
Iteration 116/1000 | Loss: 0.00001238
Iteration 117/1000 | Loss: 0.00001238
Iteration 118/1000 | Loss: 0.00001238
Iteration 119/1000 | Loss: 0.00001238
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [1.2381599844957236e-05, 1.2381599844957236e-05, 1.2381599844957236e-05, 1.2381599844957236e-05, 1.2381599844957236e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2381599844957236e-05

Optimization complete. Final v2v error: 3.0720839500427246 mm

Highest mean error: 3.3036911487579346 mm for frame 39

Lowest mean error: 2.8795998096466064 mm for frame 123

Saving results

Total time: 37.05298185348511
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00433859
Iteration 2/25 | Loss: 0.00115835
Iteration 3/25 | Loss: 0.00103679
Iteration 4/25 | Loss: 0.00102117
Iteration 5/25 | Loss: 0.00101682
Iteration 6/25 | Loss: 0.00101650
Iteration 7/25 | Loss: 0.00101650
Iteration 8/25 | Loss: 0.00101650
Iteration 9/25 | Loss: 0.00101650
Iteration 10/25 | Loss: 0.00101650
Iteration 11/25 | Loss: 0.00101650
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.001016499474644661, 0.001016499474644661, 0.001016499474644661, 0.001016499474644661, 0.001016499474644661]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001016499474644661

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.02208471
Iteration 2/25 | Loss: 0.00568707
Iteration 3/25 | Loss: 0.00568707
Iteration 4/25 | Loss: 0.00568707
Iteration 5/25 | Loss: 0.00568707
Iteration 6/25 | Loss: 0.00568707
Iteration 7/25 | Loss: 0.00568707
Iteration 8/25 | Loss: 0.00568707
Iteration 9/25 | Loss: 0.00568707
Iteration 10/25 | Loss: 0.00568707
Iteration 11/25 | Loss: 0.00568707
Iteration 12/25 | Loss: 0.00568707
Iteration 13/25 | Loss: 0.00568707
Iteration 14/25 | Loss: 0.00568707
Iteration 15/25 | Loss: 0.00568707
Iteration 16/25 | Loss: 0.00568707
Iteration 17/25 | Loss: 0.00568707
Iteration 18/25 | Loss: 0.00568707
Iteration 19/25 | Loss: 0.00568707
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.005687069613486528, 0.005687069613486528, 0.005687069613486528, 0.005687069613486528, 0.005687069613486528]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005687069613486528

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00568707
Iteration 2/1000 | Loss: 0.00003286
Iteration 3/1000 | Loss: 0.00002212
Iteration 4/1000 | Loss: 0.00001868
Iteration 5/1000 | Loss: 0.00001749
Iteration 6/1000 | Loss: 0.00001676
Iteration 7/1000 | Loss: 0.00001630
Iteration 8/1000 | Loss: 0.00001605
Iteration 9/1000 | Loss: 0.00001578
Iteration 10/1000 | Loss: 0.00001557
Iteration 11/1000 | Loss: 0.00001551
Iteration 12/1000 | Loss: 0.00001548
Iteration 13/1000 | Loss: 0.00001548
Iteration 14/1000 | Loss: 0.00001546
Iteration 15/1000 | Loss: 0.00001545
Iteration 16/1000 | Loss: 0.00001545
Iteration 17/1000 | Loss: 0.00001544
Iteration 18/1000 | Loss: 0.00001544
Iteration 19/1000 | Loss: 0.00001544
Iteration 20/1000 | Loss: 0.00001543
Iteration 21/1000 | Loss: 0.00001543
Iteration 22/1000 | Loss: 0.00001543
Iteration 23/1000 | Loss: 0.00001542
Iteration 24/1000 | Loss: 0.00001540
Iteration 25/1000 | Loss: 0.00001539
Iteration 26/1000 | Loss: 0.00001539
Iteration 27/1000 | Loss: 0.00001539
Iteration 28/1000 | Loss: 0.00001539
Iteration 29/1000 | Loss: 0.00001539
Iteration 30/1000 | Loss: 0.00001538
Iteration 31/1000 | Loss: 0.00001538
Iteration 32/1000 | Loss: 0.00001538
Iteration 33/1000 | Loss: 0.00001537
Iteration 34/1000 | Loss: 0.00001532
Iteration 35/1000 | Loss: 0.00001527
Iteration 36/1000 | Loss: 0.00001527
Iteration 37/1000 | Loss: 0.00001526
Iteration 38/1000 | Loss: 0.00001522
Iteration 39/1000 | Loss: 0.00001521
Iteration 40/1000 | Loss: 0.00001520
Iteration 41/1000 | Loss: 0.00001520
Iteration 42/1000 | Loss: 0.00001519
Iteration 43/1000 | Loss: 0.00001519
Iteration 44/1000 | Loss: 0.00001518
Iteration 45/1000 | Loss: 0.00001518
Iteration 46/1000 | Loss: 0.00001518
Iteration 47/1000 | Loss: 0.00001517
Iteration 48/1000 | Loss: 0.00001517
Iteration 49/1000 | Loss: 0.00001517
Iteration 50/1000 | Loss: 0.00001517
Iteration 51/1000 | Loss: 0.00001517
Iteration 52/1000 | Loss: 0.00001517
Iteration 53/1000 | Loss: 0.00001517
Iteration 54/1000 | Loss: 0.00001516
Iteration 55/1000 | Loss: 0.00001516
Iteration 56/1000 | Loss: 0.00001516
Iteration 57/1000 | Loss: 0.00001516
Iteration 58/1000 | Loss: 0.00001516
Iteration 59/1000 | Loss: 0.00001516
Iteration 60/1000 | Loss: 0.00001516
Iteration 61/1000 | Loss: 0.00001516
Iteration 62/1000 | Loss: 0.00001516
Iteration 63/1000 | Loss: 0.00001515
Iteration 64/1000 | Loss: 0.00001515
Iteration 65/1000 | Loss: 0.00001514
Iteration 66/1000 | Loss: 0.00001514
Iteration 67/1000 | Loss: 0.00001514
Iteration 68/1000 | Loss: 0.00001514
Iteration 69/1000 | Loss: 0.00001514
Iteration 70/1000 | Loss: 0.00001514
Iteration 71/1000 | Loss: 0.00001514
Iteration 72/1000 | Loss: 0.00001514
Iteration 73/1000 | Loss: 0.00001514
Iteration 74/1000 | Loss: 0.00001514
Iteration 75/1000 | Loss: 0.00001514
Iteration 76/1000 | Loss: 0.00001514
Iteration 77/1000 | Loss: 0.00001513
Iteration 78/1000 | Loss: 0.00001513
Iteration 79/1000 | Loss: 0.00001513
Iteration 80/1000 | Loss: 0.00001513
Iteration 81/1000 | Loss: 0.00001513
Iteration 82/1000 | Loss: 0.00001513
Iteration 83/1000 | Loss: 0.00001512
Iteration 84/1000 | Loss: 0.00001512
Iteration 85/1000 | Loss: 0.00001512
Iteration 86/1000 | Loss: 0.00001512
Iteration 87/1000 | Loss: 0.00001512
Iteration 88/1000 | Loss: 0.00001512
Iteration 89/1000 | Loss: 0.00001512
Iteration 90/1000 | Loss: 0.00001511
Iteration 91/1000 | Loss: 0.00001511
Iteration 92/1000 | Loss: 0.00001511
Iteration 93/1000 | Loss: 0.00001511
Iteration 94/1000 | Loss: 0.00001511
Iteration 95/1000 | Loss: 0.00001511
Iteration 96/1000 | Loss: 0.00001511
Iteration 97/1000 | Loss: 0.00001511
Iteration 98/1000 | Loss: 0.00001511
Iteration 99/1000 | Loss: 0.00001511
Iteration 100/1000 | Loss: 0.00001511
Iteration 101/1000 | Loss: 0.00001511
Iteration 102/1000 | Loss: 0.00001511
Iteration 103/1000 | Loss: 0.00001511
Iteration 104/1000 | Loss: 0.00001511
Iteration 105/1000 | Loss: 0.00001511
Iteration 106/1000 | Loss: 0.00001511
Iteration 107/1000 | Loss: 0.00001511
Iteration 108/1000 | Loss: 0.00001511
Iteration 109/1000 | Loss: 0.00001511
Iteration 110/1000 | Loss: 0.00001511
Iteration 111/1000 | Loss: 0.00001511
Iteration 112/1000 | Loss: 0.00001511
Iteration 113/1000 | Loss: 0.00001511
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [1.5107871149666607e-05, 1.5107871149666607e-05, 1.5107871149666607e-05, 1.5107871149666607e-05, 1.5107871149666607e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5107871149666607e-05

Optimization complete. Final v2v error: 3.4069578647613525 mm

Highest mean error: 4.017984867095947 mm for frame 154

Lowest mean error: 2.9220004081726074 mm for frame 266

Saving results

Total time: 36.90291666984558
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00808261
Iteration 2/25 | Loss: 0.00171439
Iteration 3/25 | Loss: 0.00121429
Iteration 4/25 | Loss: 0.00108657
Iteration 5/25 | Loss: 0.00107563
Iteration 6/25 | Loss: 0.00107505
Iteration 7/25 | Loss: 0.00107505
Iteration 8/25 | Loss: 0.00107505
Iteration 9/25 | Loss: 0.00107505
Iteration 10/25 | Loss: 0.00107505
Iteration 11/25 | Loss: 0.00107505
Iteration 12/25 | Loss: 0.00107505
Iteration 13/25 | Loss: 0.00107505
Iteration 14/25 | Loss: 0.00107505
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0010750471847131848, 0.0010750471847131848, 0.0010750471847131848, 0.0010750471847131848, 0.0010750471847131848]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010750471847131848

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.20641851
Iteration 2/25 | Loss: 0.00510958
Iteration 3/25 | Loss: 0.00510954
Iteration 4/25 | Loss: 0.00510954
Iteration 5/25 | Loss: 0.00510954
Iteration 6/25 | Loss: 0.00510954
Iteration 7/25 | Loss: 0.00510953
Iteration 8/25 | Loss: 0.00510953
Iteration 9/25 | Loss: 0.00510953
Iteration 10/25 | Loss: 0.00510953
Iteration 11/25 | Loss: 0.00510953
Iteration 12/25 | Loss: 0.00510953
Iteration 13/25 | Loss: 0.00510953
Iteration 14/25 | Loss: 0.00510953
Iteration 15/25 | Loss: 0.00510953
Iteration 16/25 | Loss: 0.00510953
Iteration 17/25 | Loss: 0.00510953
Iteration 18/25 | Loss: 0.00510953
Iteration 19/25 | Loss: 0.00510953
Iteration 20/25 | Loss: 0.00510953
Iteration 21/25 | Loss: 0.00510953
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.00510953227058053, 0.00510953227058053, 0.00510953227058053, 0.00510953227058053, 0.00510953227058053]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00510953227058053

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00510953
Iteration 2/1000 | Loss: 0.00003916
Iteration 3/1000 | Loss: 0.00002799
Iteration 4/1000 | Loss: 0.00002525
Iteration 5/1000 | Loss: 0.00002350
Iteration 6/1000 | Loss: 0.00002269
Iteration 7/1000 | Loss: 0.00002216
Iteration 8/1000 | Loss: 0.00002180
Iteration 9/1000 | Loss: 0.00002142
Iteration 10/1000 | Loss: 0.00002116
Iteration 11/1000 | Loss: 0.00002100
Iteration 12/1000 | Loss: 0.00002098
Iteration 13/1000 | Loss: 0.00002097
Iteration 14/1000 | Loss: 0.00002097
Iteration 15/1000 | Loss: 0.00002095
Iteration 16/1000 | Loss: 0.00002091
Iteration 17/1000 | Loss: 0.00002091
Iteration 18/1000 | Loss: 0.00002091
Iteration 19/1000 | Loss: 0.00002091
Iteration 20/1000 | Loss: 0.00002091
Iteration 21/1000 | Loss: 0.00002090
Iteration 22/1000 | Loss: 0.00002090
Iteration 23/1000 | Loss: 0.00002088
Iteration 24/1000 | Loss: 0.00002087
Iteration 25/1000 | Loss: 0.00002087
Iteration 26/1000 | Loss: 0.00002087
Iteration 27/1000 | Loss: 0.00002085
Iteration 28/1000 | Loss: 0.00002085
Iteration 29/1000 | Loss: 0.00002084
Iteration 30/1000 | Loss: 0.00002084
Iteration 31/1000 | Loss: 0.00002083
Iteration 32/1000 | Loss: 0.00002083
Iteration 33/1000 | Loss: 0.00002083
Iteration 34/1000 | Loss: 0.00002082
Iteration 35/1000 | Loss: 0.00002082
Iteration 36/1000 | Loss: 0.00002082
Iteration 37/1000 | Loss: 0.00002081
Iteration 38/1000 | Loss: 0.00002081
Iteration 39/1000 | Loss: 0.00002081
Iteration 40/1000 | Loss: 0.00002081
Iteration 41/1000 | Loss: 0.00002080
Iteration 42/1000 | Loss: 0.00002080
Iteration 43/1000 | Loss: 0.00002080
Iteration 44/1000 | Loss: 0.00002079
Iteration 45/1000 | Loss: 0.00002079
Iteration 46/1000 | Loss: 0.00002079
Iteration 47/1000 | Loss: 0.00002079
Iteration 48/1000 | Loss: 0.00002078
Iteration 49/1000 | Loss: 0.00002078
Iteration 50/1000 | Loss: 0.00002078
Iteration 51/1000 | Loss: 0.00002078
Iteration 52/1000 | Loss: 0.00002077
Iteration 53/1000 | Loss: 0.00002077
Iteration 54/1000 | Loss: 0.00002077
Iteration 55/1000 | Loss: 0.00002077
Iteration 56/1000 | Loss: 0.00002077
Iteration 57/1000 | Loss: 0.00002076
Iteration 58/1000 | Loss: 0.00002076
Iteration 59/1000 | Loss: 0.00002076
Iteration 60/1000 | Loss: 0.00002076
Iteration 61/1000 | Loss: 0.00002076
Iteration 62/1000 | Loss: 0.00002075
Iteration 63/1000 | Loss: 0.00002075
Iteration 64/1000 | Loss: 0.00002075
Iteration 65/1000 | Loss: 0.00002075
Iteration 66/1000 | Loss: 0.00002075
Iteration 67/1000 | Loss: 0.00002074
Iteration 68/1000 | Loss: 0.00002074
Iteration 69/1000 | Loss: 0.00002074
Iteration 70/1000 | Loss: 0.00002074
Iteration 71/1000 | Loss: 0.00002074
Iteration 72/1000 | Loss: 0.00002074
Iteration 73/1000 | Loss: 0.00002074
Iteration 74/1000 | Loss: 0.00002074
Iteration 75/1000 | Loss: 0.00002074
Iteration 76/1000 | Loss: 0.00002073
Iteration 77/1000 | Loss: 0.00002073
Iteration 78/1000 | Loss: 0.00002073
Iteration 79/1000 | Loss: 0.00002073
Iteration 80/1000 | Loss: 0.00002073
Iteration 81/1000 | Loss: 0.00002073
Iteration 82/1000 | Loss: 0.00002073
Iteration 83/1000 | Loss: 0.00002073
Iteration 84/1000 | Loss: 0.00002073
Iteration 85/1000 | Loss: 0.00002073
Iteration 86/1000 | Loss: 0.00002073
Iteration 87/1000 | Loss: 0.00002073
Iteration 88/1000 | Loss: 0.00002073
Iteration 89/1000 | Loss: 0.00002073
Iteration 90/1000 | Loss: 0.00002073
Iteration 91/1000 | Loss: 0.00002073
Iteration 92/1000 | Loss: 0.00002073
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 92. Stopping optimization.
Last 5 losses: [2.0730985852424055e-05, 2.0730985852424055e-05, 2.0730985852424055e-05, 2.0730985852424055e-05, 2.0730985852424055e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0730985852424055e-05

Optimization complete. Final v2v error: 3.772289514541626 mm

Highest mean error: 4.246648788452148 mm for frame 238

Lowest mean error: 3.510957956314087 mm for frame 154

Saving results

Total time: 35.98936986923218
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01010673
Iteration 2/25 | Loss: 0.00146116
Iteration 3/25 | Loss: 0.00110625
Iteration 4/25 | Loss: 0.00107644
Iteration 5/25 | Loss: 0.00106939
Iteration 6/25 | Loss: 0.00106750
Iteration 7/25 | Loss: 0.00106750
Iteration 8/25 | Loss: 0.00106750
Iteration 9/25 | Loss: 0.00106750
Iteration 10/25 | Loss: 0.00106750
Iteration 11/25 | Loss: 0.00106750
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0010675046360120177, 0.0010675046360120177, 0.0010675046360120177, 0.0010675046360120177, 0.0010675046360120177]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010675046360120177

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.12973046
Iteration 2/25 | Loss: 0.00455564
Iteration 3/25 | Loss: 0.00455563
Iteration 4/25 | Loss: 0.00455563
Iteration 5/25 | Loss: 0.00455563
Iteration 6/25 | Loss: 0.00455563
Iteration 7/25 | Loss: 0.00455563
Iteration 8/25 | Loss: 0.00455563
Iteration 9/25 | Loss: 0.00455563
Iteration 10/25 | Loss: 0.00455563
Iteration 11/25 | Loss: 0.00455563
Iteration 12/25 | Loss: 0.00455563
Iteration 13/25 | Loss: 0.00455563
Iteration 14/25 | Loss: 0.00455563
Iteration 15/25 | Loss: 0.00455563
Iteration 16/25 | Loss: 0.00455563
Iteration 17/25 | Loss: 0.00455563
Iteration 18/25 | Loss: 0.00455563
Iteration 19/25 | Loss: 0.00455563
Iteration 20/25 | Loss: 0.00455563
Iteration 21/25 | Loss: 0.00455563
Iteration 22/25 | Loss: 0.00455563
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.004555628169327974, 0.004555628169327974, 0.004555628169327974, 0.004555628169327974, 0.004555628169327974]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004555628169327974

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00455563
Iteration 2/1000 | Loss: 0.00005989
Iteration 3/1000 | Loss: 0.00003951
Iteration 4/1000 | Loss: 0.00003050
Iteration 5/1000 | Loss: 0.00002758
Iteration 6/1000 | Loss: 0.00002578
Iteration 7/1000 | Loss: 0.00002481
Iteration 8/1000 | Loss: 0.00002414
Iteration 9/1000 | Loss: 0.00002376
Iteration 10/1000 | Loss: 0.00002351
Iteration 11/1000 | Loss: 0.00002332
Iteration 12/1000 | Loss: 0.00002324
Iteration 13/1000 | Loss: 0.00002320
Iteration 14/1000 | Loss: 0.00002319
Iteration 15/1000 | Loss: 0.00002319
Iteration 16/1000 | Loss: 0.00002317
Iteration 17/1000 | Loss: 0.00002315
Iteration 18/1000 | Loss: 0.00002314
Iteration 19/1000 | Loss: 0.00002313
Iteration 20/1000 | Loss: 0.00002299
Iteration 21/1000 | Loss: 0.00002292
Iteration 22/1000 | Loss: 0.00002291
Iteration 23/1000 | Loss: 0.00002290
Iteration 24/1000 | Loss: 0.00002289
Iteration 25/1000 | Loss: 0.00002289
Iteration 26/1000 | Loss: 0.00002288
Iteration 27/1000 | Loss: 0.00002288
Iteration 28/1000 | Loss: 0.00002287
Iteration 29/1000 | Loss: 0.00002287
Iteration 30/1000 | Loss: 0.00002286
Iteration 31/1000 | Loss: 0.00002286
Iteration 32/1000 | Loss: 0.00002286
Iteration 33/1000 | Loss: 0.00002286
Iteration 34/1000 | Loss: 0.00002286
Iteration 35/1000 | Loss: 0.00002285
Iteration 36/1000 | Loss: 0.00002285
Iteration 37/1000 | Loss: 0.00002285
Iteration 38/1000 | Loss: 0.00002284
Iteration 39/1000 | Loss: 0.00002284
Iteration 40/1000 | Loss: 0.00002284
Iteration 41/1000 | Loss: 0.00002283
Iteration 42/1000 | Loss: 0.00002283
Iteration 43/1000 | Loss: 0.00002283
Iteration 44/1000 | Loss: 0.00002282
Iteration 45/1000 | Loss: 0.00002282
Iteration 46/1000 | Loss: 0.00002282
Iteration 47/1000 | Loss: 0.00002282
Iteration 48/1000 | Loss: 0.00002281
Iteration 49/1000 | Loss: 0.00002281
Iteration 50/1000 | Loss: 0.00002281
Iteration 51/1000 | Loss: 0.00002281
Iteration 52/1000 | Loss: 0.00002281
Iteration 53/1000 | Loss: 0.00002280
Iteration 54/1000 | Loss: 0.00002280
Iteration 55/1000 | Loss: 0.00002280
Iteration 56/1000 | Loss: 0.00002280
Iteration 57/1000 | Loss: 0.00002280
Iteration 58/1000 | Loss: 0.00002280
Iteration 59/1000 | Loss: 0.00002280
Iteration 60/1000 | Loss: 0.00002279
Iteration 61/1000 | Loss: 0.00002279
Iteration 62/1000 | Loss: 0.00002279
Iteration 63/1000 | Loss: 0.00002279
Iteration 64/1000 | Loss: 0.00002279
Iteration 65/1000 | Loss: 0.00002279
Iteration 66/1000 | Loss: 0.00002278
Iteration 67/1000 | Loss: 0.00002278
Iteration 68/1000 | Loss: 0.00002278
Iteration 69/1000 | Loss: 0.00002277
Iteration 70/1000 | Loss: 0.00002277
Iteration 71/1000 | Loss: 0.00002277
Iteration 72/1000 | Loss: 0.00002277
Iteration 73/1000 | Loss: 0.00002276
Iteration 74/1000 | Loss: 0.00002276
Iteration 75/1000 | Loss: 0.00002276
Iteration 76/1000 | Loss: 0.00002276
Iteration 77/1000 | Loss: 0.00002276
Iteration 78/1000 | Loss: 0.00002276
Iteration 79/1000 | Loss: 0.00002276
Iteration 80/1000 | Loss: 0.00002276
Iteration 81/1000 | Loss: 0.00002276
Iteration 82/1000 | Loss: 0.00002276
Iteration 83/1000 | Loss: 0.00002276
Iteration 84/1000 | Loss: 0.00002276
Iteration 85/1000 | Loss: 0.00002276
Iteration 86/1000 | Loss: 0.00002276
Iteration 87/1000 | Loss: 0.00002275
Iteration 88/1000 | Loss: 0.00002275
Iteration 89/1000 | Loss: 0.00002275
Iteration 90/1000 | Loss: 0.00002275
Iteration 91/1000 | Loss: 0.00002275
Iteration 92/1000 | Loss: 0.00002275
Iteration 93/1000 | Loss: 0.00002274
Iteration 94/1000 | Loss: 0.00002274
Iteration 95/1000 | Loss: 0.00002274
Iteration 96/1000 | Loss: 0.00002274
Iteration 97/1000 | Loss: 0.00002274
Iteration 98/1000 | Loss: 0.00002274
Iteration 99/1000 | Loss: 0.00002274
Iteration 100/1000 | Loss: 0.00002273
Iteration 101/1000 | Loss: 0.00002273
Iteration 102/1000 | Loss: 0.00002273
Iteration 103/1000 | Loss: 0.00002273
Iteration 104/1000 | Loss: 0.00002273
Iteration 105/1000 | Loss: 0.00002273
Iteration 106/1000 | Loss: 0.00002273
Iteration 107/1000 | Loss: 0.00002273
Iteration 108/1000 | Loss: 0.00002273
Iteration 109/1000 | Loss: 0.00002273
Iteration 110/1000 | Loss: 0.00002273
Iteration 111/1000 | Loss: 0.00002273
Iteration 112/1000 | Loss: 0.00002273
Iteration 113/1000 | Loss: 0.00002273
Iteration 114/1000 | Loss: 0.00002273
Iteration 115/1000 | Loss: 0.00002273
Iteration 116/1000 | Loss: 0.00002273
Iteration 117/1000 | Loss: 0.00002273
Iteration 118/1000 | Loss: 0.00002273
Iteration 119/1000 | Loss: 0.00002273
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 119. Stopping optimization.
Last 5 losses: [2.2728296244167723e-05, 2.2728296244167723e-05, 2.2728296244167723e-05, 2.2728296244167723e-05, 2.2728296244167723e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2728296244167723e-05

Optimization complete. Final v2v error: 3.9958748817443848 mm

Highest mean error: 5.0138068199157715 mm for frame 206

Lowest mean error: 3.2432804107666016 mm for frame 124

Saving results

Total time: 40.73167586326599
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00805013
Iteration 2/25 | Loss: 0.00129250
Iteration 3/25 | Loss: 0.00108804
Iteration 4/25 | Loss: 0.00097453
Iteration 5/25 | Loss: 0.00093712
Iteration 6/25 | Loss: 0.00093423
Iteration 7/25 | Loss: 0.00093343
Iteration 8/25 | Loss: 0.00093316
Iteration 9/25 | Loss: 0.00093306
Iteration 10/25 | Loss: 0.00093306
Iteration 11/25 | Loss: 0.00093306
Iteration 12/25 | Loss: 0.00093306
Iteration 13/25 | Loss: 0.00093306
Iteration 14/25 | Loss: 0.00093306
Iteration 15/25 | Loss: 0.00093305
Iteration 16/25 | Loss: 0.00093305
Iteration 17/25 | Loss: 0.00093305
Iteration 18/25 | Loss: 0.00093305
Iteration 19/25 | Loss: 0.00093305
Iteration 20/25 | Loss: 0.00093305
Iteration 21/25 | Loss: 0.00093305
Iteration 22/25 | Loss: 0.00093305
Iteration 23/25 | Loss: 0.00093305
Iteration 24/25 | Loss: 0.00093305
Iteration 25/25 | Loss: 0.00093305

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.22491884
Iteration 2/25 | Loss: 0.00470439
Iteration 3/25 | Loss: 0.00470439
Iteration 4/25 | Loss: 0.00470439
Iteration 5/25 | Loss: 0.00470439
Iteration 6/25 | Loss: 0.00470439
Iteration 7/25 | Loss: 0.00470439
Iteration 8/25 | Loss: 0.00470439
Iteration 9/25 | Loss: 0.00470439
Iteration 10/25 | Loss: 0.00470439
Iteration 11/25 | Loss: 0.00470439
Iteration 12/25 | Loss: 0.00470439
Iteration 13/25 | Loss: 0.00470439
Iteration 14/25 | Loss: 0.00470439
Iteration 15/25 | Loss: 0.00470439
Iteration 16/25 | Loss: 0.00470439
Iteration 17/25 | Loss: 0.00470439
Iteration 18/25 | Loss: 0.00470439
Iteration 19/25 | Loss: 0.00470439
Iteration 20/25 | Loss: 0.00470439
Iteration 21/25 | Loss: 0.00470439
Iteration 22/25 | Loss: 0.00470439
Iteration 23/25 | Loss: 0.00470439
Iteration 24/25 | Loss: 0.00470439
Iteration 25/25 | Loss: 0.00470439

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00470439
Iteration 2/1000 | Loss: 0.00002558
Iteration 3/1000 | Loss: 0.00002111
Iteration 4/1000 | Loss: 0.00002011
Iteration 5/1000 | Loss: 0.00001924
Iteration 6/1000 | Loss: 0.00001866
Iteration 7/1000 | Loss: 0.00001825
Iteration 8/1000 | Loss: 0.00001796
Iteration 9/1000 | Loss: 0.00001787
Iteration 10/1000 | Loss: 0.00001782
Iteration 11/1000 | Loss: 0.00001781
Iteration 12/1000 | Loss: 0.00001777
Iteration 13/1000 | Loss: 0.00001776
Iteration 14/1000 | Loss: 0.00001776
Iteration 15/1000 | Loss: 0.00001768
Iteration 16/1000 | Loss: 0.00001759
Iteration 17/1000 | Loss: 0.00001757
Iteration 18/1000 | Loss: 0.00001757
Iteration 19/1000 | Loss: 0.00001757
Iteration 20/1000 | Loss: 0.00001757
Iteration 21/1000 | Loss: 0.00001757
Iteration 22/1000 | Loss: 0.00001756
Iteration 23/1000 | Loss: 0.00001756
Iteration 24/1000 | Loss: 0.00001756
Iteration 25/1000 | Loss: 0.00001755
Iteration 26/1000 | Loss: 0.00001755
Iteration 27/1000 | Loss: 0.00001754
Iteration 28/1000 | Loss: 0.00001754
Iteration 29/1000 | Loss: 0.00001753
Iteration 30/1000 | Loss: 0.00001753
Iteration 31/1000 | Loss: 0.00001752
Iteration 32/1000 | Loss: 0.00001752
Iteration 33/1000 | Loss: 0.00001751
Iteration 34/1000 | Loss: 0.00001751
Iteration 35/1000 | Loss: 0.00001750
Iteration 36/1000 | Loss: 0.00001750
Iteration 37/1000 | Loss: 0.00001750
Iteration 38/1000 | Loss: 0.00001749
Iteration 39/1000 | Loss: 0.00001749
Iteration 40/1000 | Loss: 0.00001748
Iteration 41/1000 | Loss: 0.00001748
Iteration 42/1000 | Loss: 0.00001746
Iteration 43/1000 | Loss: 0.00001746
Iteration 44/1000 | Loss: 0.00001745
Iteration 45/1000 | Loss: 0.00001745
Iteration 46/1000 | Loss: 0.00001744
Iteration 47/1000 | Loss: 0.00001744
Iteration 48/1000 | Loss: 0.00001744
Iteration 49/1000 | Loss: 0.00001744
Iteration 50/1000 | Loss: 0.00001744
Iteration 51/1000 | Loss: 0.00001744
Iteration 52/1000 | Loss: 0.00001743
Iteration 53/1000 | Loss: 0.00001743
Iteration 54/1000 | Loss: 0.00001742
Iteration 55/1000 | Loss: 0.00001742
Iteration 56/1000 | Loss: 0.00001742
Iteration 57/1000 | Loss: 0.00001742
Iteration 58/1000 | Loss: 0.00001742
Iteration 59/1000 | Loss: 0.00001742
Iteration 60/1000 | Loss: 0.00001742
Iteration 61/1000 | Loss: 0.00001742
Iteration 62/1000 | Loss: 0.00001741
Iteration 63/1000 | Loss: 0.00001741
Iteration 64/1000 | Loss: 0.00001741
Iteration 65/1000 | Loss: 0.00001741
Iteration 66/1000 | Loss: 0.00001741
Iteration 67/1000 | Loss: 0.00001741
Iteration 68/1000 | Loss: 0.00001741
Iteration 69/1000 | Loss: 0.00001741
Iteration 70/1000 | Loss: 0.00001741
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 70. Stopping optimization.
Last 5 losses: [1.741276719258167e-05, 1.741276719258167e-05, 1.741276719258167e-05, 1.741276719258167e-05, 1.741276719258167e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.741276719258167e-05

Optimization complete. Final v2v error: 3.6001906394958496 mm

Highest mean error: 3.931272268295288 mm for frame 98

Lowest mean error: 3.3759243488311768 mm for frame 190

Saving results

Total time: 35.838955879211426
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00297614
Iteration 2/25 | Loss: 0.00132462
Iteration 3/25 | Loss: 0.00106903
Iteration 4/25 | Loss: 0.00100957
Iteration 5/25 | Loss: 0.00098852
Iteration 6/25 | Loss: 0.00098416
Iteration 7/25 | Loss: 0.00098285
Iteration 8/25 | Loss: 0.00098285
Iteration 9/25 | Loss: 0.00098285
Iteration 10/25 | Loss: 0.00098285
Iteration 11/25 | Loss: 0.00098285
Iteration 12/25 | Loss: 0.00098285
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009828510228544474, 0.0009828510228544474, 0.0009828510228544474, 0.0009828510228544474, 0.0009828510228544474]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009828510228544474

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.85746837
Iteration 2/25 | Loss: 0.00572145
Iteration 3/25 | Loss: 0.00572145
Iteration 4/25 | Loss: 0.00572145
Iteration 5/25 | Loss: 0.00572144
Iteration 6/25 | Loss: 0.00572144
Iteration 7/25 | Loss: 0.00572144
Iteration 8/25 | Loss: 0.00572144
Iteration 9/25 | Loss: 0.00572144
Iteration 10/25 | Loss: 0.00572144
Iteration 11/25 | Loss: 0.00572144
Iteration 12/25 | Loss: 0.00572144
Iteration 13/25 | Loss: 0.00572144
Iteration 14/25 | Loss: 0.00572144
Iteration 15/25 | Loss: 0.00572144
Iteration 16/25 | Loss: 0.00572144
Iteration 17/25 | Loss: 0.00572144
Iteration 18/25 | Loss: 0.00572144
Iteration 19/25 | Loss: 0.00572144
Iteration 20/25 | Loss: 0.00572144
Iteration 21/25 | Loss: 0.00572144
Iteration 22/25 | Loss: 0.00572144
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.005721442401409149, 0.005721442401409149, 0.005721442401409149, 0.005721442401409149, 0.005721442401409149]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005721442401409149

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00572144
Iteration 2/1000 | Loss: 0.00004681
Iteration 3/1000 | Loss: 0.00002961
Iteration 4/1000 | Loss: 0.00002490
Iteration 5/1000 | Loss: 0.00002342
Iteration 6/1000 | Loss: 0.00002221
Iteration 7/1000 | Loss: 0.00002161
Iteration 8/1000 | Loss: 0.00002111
Iteration 9/1000 | Loss: 0.00002070
Iteration 10/1000 | Loss: 0.00002043
Iteration 11/1000 | Loss: 0.00002020
Iteration 12/1000 | Loss: 0.00002002
Iteration 13/1000 | Loss: 0.00001992
Iteration 14/1000 | Loss: 0.00001991
Iteration 15/1000 | Loss: 0.00001990
Iteration 16/1000 | Loss: 0.00001990
Iteration 17/1000 | Loss: 0.00001989
Iteration 18/1000 | Loss: 0.00001984
Iteration 19/1000 | Loss: 0.00001971
Iteration 20/1000 | Loss: 0.00001971
Iteration 21/1000 | Loss: 0.00001970
Iteration 22/1000 | Loss: 0.00001969
Iteration 23/1000 | Loss: 0.00001969
Iteration 24/1000 | Loss: 0.00001966
Iteration 25/1000 | Loss: 0.00001965
Iteration 26/1000 | Loss: 0.00001963
Iteration 27/1000 | Loss: 0.00001963
Iteration 28/1000 | Loss: 0.00001962
Iteration 29/1000 | Loss: 0.00001961
Iteration 30/1000 | Loss: 0.00001961
Iteration 31/1000 | Loss: 0.00001960
Iteration 32/1000 | Loss: 0.00001960
Iteration 33/1000 | Loss: 0.00001960
Iteration 34/1000 | Loss: 0.00001959
Iteration 35/1000 | Loss: 0.00001959
Iteration 36/1000 | Loss: 0.00001958
Iteration 37/1000 | Loss: 0.00001957
Iteration 38/1000 | Loss: 0.00001957
Iteration 39/1000 | Loss: 0.00001956
Iteration 40/1000 | Loss: 0.00001955
Iteration 41/1000 | Loss: 0.00001955
Iteration 42/1000 | Loss: 0.00001954
Iteration 43/1000 | Loss: 0.00001954
Iteration 44/1000 | Loss: 0.00001953
Iteration 45/1000 | Loss: 0.00001953
Iteration 46/1000 | Loss: 0.00001952
Iteration 47/1000 | Loss: 0.00001952
Iteration 48/1000 | Loss: 0.00001952
Iteration 49/1000 | Loss: 0.00001951
Iteration 50/1000 | Loss: 0.00001951
Iteration 51/1000 | Loss: 0.00001950
Iteration 52/1000 | Loss: 0.00001950
Iteration 53/1000 | Loss: 0.00001950
Iteration 54/1000 | Loss: 0.00001950
Iteration 55/1000 | Loss: 0.00001949
Iteration 56/1000 | Loss: 0.00001949
Iteration 57/1000 | Loss: 0.00001949
Iteration 58/1000 | Loss: 0.00001949
Iteration 59/1000 | Loss: 0.00001948
Iteration 60/1000 | Loss: 0.00001948
Iteration 61/1000 | Loss: 0.00001948
Iteration 62/1000 | Loss: 0.00001948
Iteration 63/1000 | Loss: 0.00001947
Iteration 64/1000 | Loss: 0.00001947
Iteration 65/1000 | Loss: 0.00001947
Iteration 66/1000 | Loss: 0.00001947
Iteration 67/1000 | Loss: 0.00001947
Iteration 68/1000 | Loss: 0.00001947
Iteration 69/1000 | Loss: 0.00001947
Iteration 70/1000 | Loss: 0.00001947
Iteration 71/1000 | Loss: 0.00001946
Iteration 72/1000 | Loss: 0.00001946
Iteration 73/1000 | Loss: 0.00001946
Iteration 74/1000 | Loss: 0.00001946
Iteration 75/1000 | Loss: 0.00001946
Iteration 76/1000 | Loss: 0.00001946
Iteration 77/1000 | Loss: 0.00001946
Iteration 78/1000 | Loss: 0.00001946
Iteration 79/1000 | Loss: 0.00001946
Iteration 80/1000 | Loss: 0.00001946
Iteration 81/1000 | Loss: 0.00001946
Iteration 82/1000 | Loss: 0.00001946
Iteration 83/1000 | Loss: 0.00001946
Iteration 84/1000 | Loss: 0.00001946
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 84. Stopping optimization.
Last 5 losses: [1.946412339748349e-05, 1.946412339748349e-05, 1.946412339748349e-05, 1.946412339748349e-05, 1.946412339748349e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.946412339748349e-05

Optimization complete. Final v2v error: 3.81695556640625 mm

Highest mean error: 4.027848720550537 mm for frame 110

Lowest mean error: 3.320490837097168 mm for frame 0

Saving results

Total time: 41.96613550186157
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01155922
Iteration 2/25 | Loss: 0.00217535
Iteration 3/25 | Loss: 0.00138735
Iteration 4/25 | Loss: 0.00128152
Iteration 5/25 | Loss: 0.00127502
Iteration 6/25 | Loss: 0.00122389
Iteration 7/25 | Loss: 0.00118624
Iteration 8/25 | Loss: 0.00116264
Iteration 9/25 | Loss: 0.00114835
Iteration 10/25 | Loss: 0.00114614
Iteration 11/25 | Loss: 0.00114448
Iteration 12/25 | Loss: 0.00113906
Iteration 13/25 | Loss: 0.00114153
Iteration 14/25 | Loss: 0.00114533
Iteration 15/25 | Loss: 0.00113673
Iteration 16/25 | Loss: 0.00113987
Iteration 17/25 | Loss: 0.00113093
Iteration 18/25 | Loss: 0.00113919
Iteration 19/25 | Loss: 0.00113299
Iteration 20/25 | Loss: 0.00112903
Iteration 21/25 | Loss: 0.00113644
Iteration 22/25 | Loss: 0.00112262
Iteration 23/25 | Loss: 0.00112695
Iteration 24/25 | Loss: 0.00112518
Iteration 25/25 | Loss: 0.00113324

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.55475092
Iteration 2/25 | Loss: 0.00459244
Iteration 3/25 | Loss: 0.00449653
Iteration 4/25 | Loss: 0.00449653
Iteration 5/25 | Loss: 0.00449652
Iteration 6/25 | Loss: 0.00449652
Iteration 7/25 | Loss: 0.00449652
Iteration 8/25 | Loss: 0.00449652
Iteration 9/25 | Loss: 0.00449652
Iteration 10/25 | Loss: 0.00449652
Iteration 11/25 | Loss: 0.00449652
Iteration 12/25 | Loss: 0.00449652
Iteration 13/25 | Loss: 0.00449652
Iteration 14/25 | Loss: 0.00449652
Iteration 15/25 | Loss: 0.00449652
Iteration 16/25 | Loss: 0.00449652
Iteration 17/25 | Loss: 0.00449652
Iteration 18/25 | Loss: 0.00449652
Iteration 19/25 | Loss: 0.00449652
Iteration 20/25 | Loss: 0.00449652
Iteration 21/25 | Loss: 0.00449652
Iteration 22/25 | Loss: 0.00449652
Iteration 23/25 | Loss: 0.00449652
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.004496523179113865, 0.004496523179113865, 0.004496523179113865, 0.004496523179113865, 0.004496523179113865]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004496523179113865

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00449652
Iteration 2/1000 | Loss: 0.00016680
Iteration 3/1000 | Loss: 0.00024073
Iteration 4/1000 | Loss: 0.00021313
Iteration 5/1000 | Loss: 0.00020590
Iteration 6/1000 | Loss: 0.00013432
Iteration 7/1000 | Loss: 0.00029368
Iteration 8/1000 | Loss: 0.00013145
Iteration 9/1000 | Loss: 0.00020392
Iteration 10/1000 | Loss: 0.00006226
Iteration 11/1000 | Loss: 0.00009329
Iteration 12/1000 | Loss: 0.00013470
Iteration 13/1000 | Loss: 0.00012036
Iteration 14/1000 | Loss: 0.00008501
Iteration 15/1000 | Loss: 0.00006940
Iteration 16/1000 | Loss: 0.00004839
Iteration 17/1000 | Loss: 0.00034150
Iteration 18/1000 | Loss: 0.00020578
Iteration 19/1000 | Loss: 0.00004787
Iteration 20/1000 | Loss: 0.00004402
Iteration 21/1000 | Loss: 0.00004561
Iteration 22/1000 | Loss: 0.00019032
Iteration 23/1000 | Loss: 0.00020645
Iteration 24/1000 | Loss: 0.00004356
Iteration 25/1000 | Loss: 0.00045704
Iteration 26/1000 | Loss: 0.00039519
Iteration 27/1000 | Loss: 0.00036827
Iteration 28/1000 | Loss: 0.00039065
Iteration 29/1000 | Loss: 0.00035027
Iteration 30/1000 | Loss: 0.00042481
Iteration 31/1000 | Loss: 0.00032106
Iteration 32/1000 | Loss: 0.00011268
Iteration 33/1000 | Loss: 0.00004027
Iteration 34/1000 | Loss: 0.00003769
Iteration 35/1000 | Loss: 0.00036226
Iteration 36/1000 | Loss: 0.00043810
Iteration 37/1000 | Loss: 0.00015640
Iteration 38/1000 | Loss: 0.00037711
Iteration 39/1000 | Loss: 0.00031038
Iteration 40/1000 | Loss: 0.00018984
Iteration 41/1000 | Loss: 0.00006107
Iteration 42/1000 | Loss: 0.00098536
Iteration 43/1000 | Loss: 0.00007634
Iteration 44/1000 | Loss: 0.00004134
Iteration 45/1000 | Loss: 0.00005306
Iteration 46/1000 | Loss: 0.00003403
Iteration 47/1000 | Loss: 0.00022845
Iteration 48/1000 | Loss: 0.00003452
Iteration 49/1000 | Loss: 0.00008811
Iteration 50/1000 | Loss: 0.00003434
Iteration 51/1000 | Loss: 0.00003201
Iteration 52/1000 | Loss: 0.00007195
Iteration 53/1000 | Loss: 0.00026752
Iteration 54/1000 | Loss: 0.00016135
Iteration 55/1000 | Loss: 0.00013193
Iteration 56/1000 | Loss: 0.00009304
Iteration 57/1000 | Loss: 0.00017133
Iteration 58/1000 | Loss: 0.00013632
Iteration 59/1000 | Loss: 0.00006257
Iteration 60/1000 | Loss: 0.00003673
Iteration 61/1000 | Loss: 0.00003018
Iteration 62/1000 | Loss: 0.00002948
Iteration 63/1000 | Loss: 0.00003649
Iteration 64/1000 | Loss: 0.00002925
Iteration 65/1000 | Loss: 0.00002816
Iteration 66/1000 | Loss: 0.00003468
Iteration 67/1000 | Loss: 0.00002678
Iteration 68/1000 | Loss: 0.00002647
Iteration 69/1000 | Loss: 0.00005941
Iteration 70/1000 | Loss: 0.00004676
Iteration 71/1000 | Loss: 0.00005177
Iteration 72/1000 | Loss: 0.00003539
Iteration 73/1000 | Loss: 0.00003677
Iteration 74/1000 | Loss: 0.00003603
Iteration 75/1000 | Loss: 0.00003797
Iteration 76/1000 | Loss: 0.00003573
Iteration 77/1000 | Loss: 0.00003494
Iteration 78/1000 | Loss: 0.00003538
Iteration 79/1000 | Loss: 0.00002949
Iteration 80/1000 | Loss: 0.00003584
Iteration 81/1000 | Loss: 0.00003689
Iteration 82/1000 | Loss: 0.00003168
Iteration 83/1000 | Loss: 0.00003015
Iteration 84/1000 | Loss: 0.00002613
Iteration 85/1000 | Loss: 0.00002579
Iteration 86/1000 | Loss: 0.00003522
Iteration 87/1000 | Loss: 0.00003550
Iteration 88/1000 | Loss: 0.00002640
Iteration 89/1000 | Loss: 0.00003477
Iteration 90/1000 | Loss: 0.00003545
Iteration 91/1000 | Loss: 0.00027264
Iteration 92/1000 | Loss: 0.00019798
Iteration 93/1000 | Loss: 0.00008686
Iteration 94/1000 | Loss: 0.00003658
Iteration 95/1000 | Loss: 0.00002719
Iteration 96/1000 | Loss: 0.00002649
Iteration 97/1000 | Loss: 0.00002614
Iteration 98/1000 | Loss: 0.00002566
Iteration 99/1000 | Loss: 0.00002890
Iteration 100/1000 | Loss: 0.00002520
Iteration 101/1000 | Loss: 0.00002520
Iteration 102/1000 | Loss: 0.00002515
Iteration 103/1000 | Loss: 0.00002514
Iteration 104/1000 | Loss: 0.00003372
Iteration 105/1000 | Loss: 0.00002505
Iteration 106/1000 | Loss: 0.00002499
Iteration 107/1000 | Loss: 0.00002496
Iteration 108/1000 | Loss: 0.00002495
Iteration 109/1000 | Loss: 0.00002495
Iteration 110/1000 | Loss: 0.00002494
Iteration 111/1000 | Loss: 0.00002491
Iteration 112/1000 | Loss: 0.00002490
Iteration 113/1000 | Loss: 0.00002490
Iteration 114/1000 | Loss: 0.00002487
Iteration 115/1000 | Loss: 0.00002486
Iteration 116/1000 | Loss: 0.00002485
Iteration 117/1000 | Loss: 0.00002485
Iteration 118/1000 | Loss: 0.00002485
Iteration 119/1000 | Loss: 0.00002485
Iteration 120/1000 | Loss: 0.00002485
Iteration 121/1000 | Loss: 0.00002485
Iteration 122/1000 | Loss: 0.00002485
Iteration 123/1000 | Loss: 0.00002484
Iteration 124/1000 | Loss: 0.00002484
Iteration 125/1000 | Loss: 0.00002484
Iteration 126/1000 | Loss: 0.00002483
Iteration 127/1000 | Loss: 0.00002483
Iteration 128/1000 | Loss: 0.00002483
Iteration 129/1000 | Loss: 0.00002483
Iteration 130/1000 | Loss: 0.00002483
Iteration 131/1000 | Loss: 0.00002482
Iteration 132/1000 | Loss: 0.00002482
Iteration 133/1000 | Loss: 0.00002482
Iteration 134/1000 | Loss: 0.00002482
Iteration 135/1000 | Loss: 0.00002482
Iteration 136/1000 | Loss: 0.00002482
Iteration 137/1000 | Loss: 0.00002482
Iteration 138/1000 | Loss: 0.00002482
Iteration 139/1000 | Loss: 0.00002482
Iteration 140/1000 | Loss: 0.00002482
Iteration 141/1000 | Loss: 0.00002481
Iteration 142/1000 | Loss: 0.00002481
Iteration 143/1000 | Loss: 0.00002481
Iteration 144/1000 | Loss: 0.00002481
Iteration 145/1000 | Loss: 0.00002481
Iteration 146/1000 | Loss: 0.00002480
Iteration 147/1000 | Loss: 0.00002480
Iteration 148/1000 | Loss: 0.00002480
Iteration 149/1000 | Loss: 0.00002480
Iteration 150/1000 | Loss: 0.00002480
Iteration 151/1000 | Loss: 0.00002479
Iteration 152/1000 | Loss: 0.00002479
Iteration 153/1000 | Loss: 0.00002479
Iteration 154/1000 | Loss: 0.00002478
Iteration 155/1000 | Loss: 0.00002478
Iteration 156/1000 | Loss: 0.00002478
Iteration 157/1000 | Loss: 0.00002477
Iteration 158/1000 | Loss: 0.00002477
Iteration 159/1000 | Loss: 0.00002476
Iteration 160/1000 | Loss: 0.00002476
Iteration 161/1000 | Loss: 0.00002476
Iteration 162/1000 | Loss: 0.00002476
Iteration 163/1000 | Loss: 0.00002475
Iteration 164/1000 | Loss: 0.00002475
Iteration 165/1000 | Loss: 0.00002475
Iteration 166/1000 | Loss: 0.00002475
Iteration 167/1000 | Loss: 0.00002474
Iteration 168/1000 | Loss: 0.00002474
Iteration 169/1000 | Loss: 0.00002474
Iteration 170/1000 | Loss: 0.00002474
Iteration 171/1000 | Loss: 0.00002474
Iteration 172/1000 | Loss: 0.00002474
Iteration 173/1000 | Loss: 0.00002474
Iteration 174/1000 | Loss: 0.00002474
Iteration 175/1000 | Loss: 0.00002474
Iteration 176/1000 | Loss: 0.00002474
Iteration 177/1000 | Loss: 0.00002474
Iteration 178/1000 | Loss: 0.00002474
Iteration 179/1000 | Loss: 0.00002474
Iteration 180/1000 | Loss: 0.00002474
Iteration 181/1000 | Loss: 0.00002474
Iteration 182/1000 | Loss: 0.00003778
Iteration 183/1000 | Loss: 0.00003778
Iteration 184/1000 | Loss: 0.00002620
Iteration 185/1000 | Loss: 0.00002495
Iteration 186/1000 | Loss: 0.00002472
Iteration 187/1000 | Loss: 0.00002471
Iteration 188/1000 | Loss: 0.00002470
Iteration 189/1000 | Loss: 0.00002470
Iteration 190/1000 | Loss: 0.00002470
Iteration 191/1000 | Loss: 0.00002470
Iteration 192/1000 | Loss: 0.00002470
Iteration 193/1000 | Loss: 0.00002470
Iteration 194/1000 | Loss: 0.00002470
Iteration 195/1000 | Loss: 0.00002470
Iteration 196/1000 | Loss: 0.00002470
Iteration 197/1000 | Loss: 0.00002470
Iteration 198/1000 | Loss: 0.00002470
Iteration 199/1000 | Loss: 0.00002470
Iteration 200/1000 | Loss: 0.00002470
Iteration 201/1000 | Loss: 0.00002470
Iteration 202/1000 | Loss: 0.00002470
Iteration 203/1000 | Loss: 0.00002470
Iteration 204/1000 | Loss: 0.00002470
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 204. Stopping optimization.
Last 5 losses: [2.4698743800399825e-05, 2.4698743800399825e-05, 2.4698743800399825e-05, 2.4698743800399825e-05, 2.4698743800399825e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4698743800399825e-05

Optimization complete. Final v2v error: 4.247466087341309 mm

Highest mean error: 5.665770530700684 mm for frame 181

Lowest mean error: 3.6080877780914307 mm for frame 0

Saving results

Total time: 226.4726848602295
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00457025
Iteration 2/25 | Loss: 0.00116338
Iteration 3/25 | Loss: 0.00104554
Iteration 4/25 | Loss: 0.00101250
Iteration 5/25 | Loss: 0.00100696
Iteration 6/25 | Loss: 0.00100518
Iteration 7/25 | Loss: 0.00100477
Iteration 8/25 | Loss: 0.00100477
Iteration 9/25 | Loss: 0.00100477
Iteration 10/25 | Loss: 0.00100477
Iteration 11/25 | Loss: 0.00100477
Iteration 12/25 | Loss: 0.00100477
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010047747055068612, 0.0010047747055068612, 0.0010047747055068612, 0.0010047747055068612, 0.0010047747055068612]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010047747055068612

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.86558592
Iteration 2/25 | Loss: 0.00635706
Iteration 3/25 | Loss: 0.00635705
Iteration 4/25 | Loss: 0.00635705
Iteration 5/25 | Loss: 0.00635705
Iteration 6/25 | Loss: 0.00635705
Iteration 7/25 | Loss: 0.00635705
Iteration 8/25 | Loss: 0.00635705
Iteration 9/25 | Loss: 0.00635705
Iteration 10/25 | Loss: 0.00635705
Iteration 11/25 | Loss: 0.00635705
Iteration 12/25 | Loss: 0.00635705
Iteration 13/25 | Loss: 0.00635705
Iteration 14/25 | Loss: 0.00635705
Iteration 15/25 | Loss: 0.00635705
Iteration 16/25 | Loss: 0.00635705
Iteration 17/25 | Loss: 0.00635705
Iteration 18/25 | Loss: 0.00635705
Iteration 19/25 | Loss: 0.00635705
Iteration 20/25 | Loss: 0.00635705
Iteration 21/25 | Loss: 0.00635705
Iteration 22/25 | Loss: 0.00635705
Iteration 23/25 | Loss: 0.00635705
Iteration 24/25 | Loss: 0.00635705
Iteration 25/25 | Loss: 0.00635705

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00635705
Iteration 2/1000 | Loss: 0.00005766
Iteration 3/1000 | Loss: 0.00003567
Iteration 4/1000 | Loss: 0.00003043
Iteration 5/1000 | Loss: 0.00002768
Iteration 6/1000 | Loss: 0.00002634
Iteration 7/1000 | Loss: 0.00002529
Iteration 8/1000 | Loss: 0.00002443
Iteration 9/1000 | Loss: 0.00002380
Iteration 10/1000 | Loss: 0.00002334
Iteration 11/1000 | Loss: 0.00002303
Iteration 12/1000 | Loss: 0.00002281
Iteration 13/1000 | Loss: 0.00002276
Iteration 14/1000 | Loss: 0.00002268
Iteration 15/1000 | Loss: 0.00002250
Iteration 16/1000 | Loss: 0.00002232
Iteration 17/1000 | Loss: 0.00002225
Iteration 18/1000 | Loss: 0.00002223
Iteration 19/1000 | Loss: 0.00002218
Iteration 20/1000 | Loss: 0.00002214
Iteration 21/1000 | Loss: 0.00002214
Iteration 22/1000 | Loss: 0.00002213
Iteration 23/1000 | Loss: 0.00002209
Iteration 24/1000 | Loss: 0.00002202
Iteration 25/1000 | Loss: 0.00002201
Iteration 26/1000 | Loss: 0.00002199
Iteration 27/1000 | Loss: 0.00002198
Iteration 28/1000 | Loss: 0.00002198
Iteration 29/1000 | Loss: 0.00002197
Iteration 30/1000 | Loss: 0.00002197
Iteration 31/1000 | Loss: 0.00002196
Iteration 32/1000 | Loss: 0.00002194
Iteration 33/1000 | Loss: 0.00002193
Iteration 34/1000 | Loss: 0.00002193
Iteration 35/1000 | Loss: 0.00002193
Iteration 36/1000 | Loss: 0.00002192
Iteration 37/1000 | Loss: 0.00002191
Iteration 38/1000 | Loss: 0.00002191
Iteration 39/1000 | Loss: 0.00002190
Iteration 40/1000 | Loss: 0.00002190
Iteration 41/1000 | Loss: 0.00002189
Iteration 42/1000 | Loss: 0.00002189
Iteration 43/1000 | Loss: 0.00002189
Iteration 44/1000 | Loss: 0.00002188
Iteration 45/1000 | Loss: 0.00002188
Iteration 46/1000 | Loss: 0.00002187
Iteration 47/1000 | Loss: 0.00002187
Iteration 48/1000 | Loss: 0.00002187
Iteration 49/1000 | Loss: 0.00002186
Iteration 50/1000 | Loss: 0.00002186
Iteration 51/1000 | Loss: 0.00002186
Iteration 52/1000 | Loss: 0.00002186
Iteration 53/1000 | Loss: 0.00002185
Iteration 54/1000 | Loss: 0.00002185
Iteration 55/1000 | Loss: 0.00002185
Iteration 56/1000 | Loss: 0.00002185
Iteration 57/1000 | Loss: 0.00002185
Iteration 58/1000 | Loss: 0.00002185
Iteration 59/1000 | Loss: 0.00002185
Iteration 60/1000 | Loss: 0.00002185
Iteration 61/1000 | Loss: 0.00002185
Iteration 62/1000 | Loss: 0.00002185
Iteration 63/1000 | Loss: 0.00002185
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 63. Stopping optimization.
Last 5 losses: [2.185488301620353e-05, 2.185488301620353e-05, 2.185488301620353e-05, 2.185488301620353e-05, 2.185488301620353e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.185488301620353e-05

Optimization complete. Final v2v error: 3.9927806854248047 mm

Highest mean error: 4.6572370529174805 mm for frame 181

Lowest mean error: 3.5172693729400635 mm for frame 229

Saving results

Total time: 42.94884967803955
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00896756
Iteration 2/25 | Loss: 0.00119860
Iteration 3/25 | Loss: 0.00104510
Iteration 4/25 | Loss: 0.00102312
Iteration 5/25 | Loss: 0.00101620
Iteration 6/25 | Loss: 0.00101466
Iteration 7/25 | Loss: 0.00101440
Iteration 8/25 | Loss: 0.00101440
Iteration 9/25 | Loss: 0.00101440
Iteration 10/25 | Loss: 0.00101440
Iteration 11/25 | Loss: 0.00101440
Iteration 12/25 | Loss: 0.00101440
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010144035331904888, 0.0010144035331904888, 0.0010144035331904888, 0.0010144035331904888, 0.0010144035331904888]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010144035331904888

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.92647469
Iteration 2/25 | Loss: 0.00530242
Iteration 3/25 | Loss: 0.00530241
Iteration 4/25 | Loss: 0.00530241
Iteration 5/25 | Loss: 0.00530241
Iteration 6/25 | Loss: 0.00530241
Iteration 7/25 | Loss: 0.00530241
Iteration 8/25 | Loss: 0.00530241
Iteration 9/25 | Loss: 0.00530241
Iteration 10/25 | Loss: 0.00530241
Iteration 11/25 | Loss: 0.00530241
Iteration 12/25 | Loss: 0.00530241
Iteration 13/25 | Loss: 0.00530241
Iteration 14/25 | Loss: 0.00530241
Iteration 15/25 | Loss: 0.00530241
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.005302409175783396, 0.005302409175783396, 0.005302409175783396, 0.005302409175783396, 0.005302409175783396]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005302409175783396

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00530241
Iteration 2/1000 | Loss: 0.00003150
Iteration 3/1000 | Loss: 0.00002247
Iteration 4/1000 | Loss: 0.00002053
Iteration 5/1000 | Loss: 0.00001943
Iteration 6/1000 | Loss: 0.00001846
Iteration 7/1000 | Loss: 0.00001793
Iteration 8/1000 | Loss: 0.00001749
Iteration 9/1000 | Loss: 0.00001724
Iteration 10/1000 | Loss: 0.00001706
Iteration 11/1000 | Loss: 0.00001683
Iteration 12/1000 | Loss: 0.00001676
Iteration 13/1000 | Loss: 0.00001675
Iteration 14/1000 | Loss: 0.00001668
Iteration 15/1000 | Loss: 0.00001660
Iteration 16/1000 | Loss: 0.00001656
Iteration 17/1000 | Loss: 0.00001652
Iteration 18/1000 | Loss: 0.00001652
Iteration 19/1000 | Loss: 0.00001651
Iteration 20/1000 | Loss: 0.00001650
Iteration 21/1000 | Loss: 0.00001649
Iteration 22/1000 | Loss: 0.00001649
Iteration 23/1000 | Loss: 0.00001648
Iteration 24/1000 | Loss: 0.00001645
Iteration 25/1000 | Loss: 0.00001644
Iteration 26/1000 | Loss: 0.00001640
Iteration 27/1000 | Loss: 0.00001639
Iteration 28/1000 | Loss: 0.00001638
Iteration 29/1000 | Loss: 0.00001638
Iteration 30/1000 | Loss: 0.00001638
Iteration 31/1000 | Loss: 0.00001637
Iteration 32/1000 | Loss: 0.00001637
Iteration 33/1000 | Loss: 0.00001636
Iteration 34/1000 | Loss: 0.00001636
Iteration 35/1000 | Loss: 0.00001636
Iteration 36/1000 | Loss: 0.00001635
Iteration 37/1000 | Loss: 0.00001635
Iteration 38/1000 | Loss: 0.00001635
Iteration 39/1000 | Loss: 0.00001635
Iteration 40/1000 | Loss: 0.00001634
Iteration 41/1000 | Loss: 0.00001634
Iteration 42/1000 | Loss: 0.00001633
Iteration 43/1000 | Loss: 0.00001633
Iteration 44/1000 | Loss: 0.00001633
Iteration 45/1000 | Loss: 0.00001633
Iteration 46/1000 | Loss: 0.00001632
Iteration 47/1000 | Loss: 0.00001632
Iteration 48/1000 | Loss: 0.00001632
Iteration 49/1000 | Loss: 0.00001632
Iteration 50/1000 | Loss: 0.00001631
Iteration 51/1000 | Loss: 0.00001631
Iteration 52/1000 | Loss: 0.00001631
Iteration 53/1000 | Loss: 0.00001630
Iteration 54/1000 | Loss: 0.00001630
Iteration 55/1000 | Loss: 0.00001630
Iteration 56/1000 | Loss: 0.00001630
Iteration 57/1000 | Loss: 0.00001630
Iteration 58/1000 | Loss: 0.00001630
Iteration 59/1000 | Loss: 0.00001630
Iteration 60/1000 | Loss: 0.00001630
Iteration 61/1000 | Loss: 0.00001630
Iteration 62/1000 | Loss: 0.00001630
Iteration 63/1000 | Loss: 0.00001630
Iteration 64/1000 | Loss: 0.00001630
Iteration 65/1000 | Loss: 0.00001630
Iteration 66/1000 | Loss: 0.00001630
Iteration 67/1000 | Loss: 0.00001630
Iteration 68/1000 | Loss: 0.00001630
Iteration 69/1000 | Loss: 0.00001629
Iteration 70/1000 | Loss: 0.00001629
Iteration 71/1000 | Loss: 0.00001629
Iteration 72/1000 | Loss: 0.00001629
Iteration 73/1000 | Loss: 0.00001629
Iteration 74/1000 | Loss: 0.00001629
Iteration 75/1000 | Loss: 0.00001629
Iteration 76/1000 | Loss: 0.00001629
Iteration 77/1000 | Loss: 0.00001629
Iteration 78/1000 | Loss: 0.00001628
Iteration 79/1000 | Loss: 0.00001628
Iteration 80/1000 | Loss: 0.00001628
Iteration 81/1000 | Loss: 0.00001628
Iteration 82/1000 | Loss: 0.00001628
Iteration 83/1000 | Loss: 0.00001628
Iteration 84/1000 | Loss: 0.00001628
Iteration 85/1000 | Loss: 0.00001628
Iteration 86/1000 | Loss: 0.00001628
Iteration 87/1000 | Loss: 0.00001628
Iteration 88/1000 | Loss: 0.00001628
Iteration 89/1000 | Loss: 0.00001628
Iteration 90/1000 | Loss: 0.00001628
Iteration 91/1000 | Loss: 0.00001628
Iteration 92/1000 | Loss: 0.00001628
Iteration 93/1000 | Loss: 0.00001628
Iteration 94/1000 | Loss: 0.00001628
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 94. Stopping optimization.
Last 5 losses: [1.6280298950732686e-05, 1.6280298950732686e-05, 1.6280298950732686e-05, 1.6280298950732686e-05, 1.6280298950732686e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6280298950732686e-05

Optimization complete. Final v2v error: 3.4247100353240967 mm

Highest mean error: 4.0239787101745605 mm for frame 67

Lowest mean error: 2.9957475662231445 mm for frame 77

Saving results

Total time: 34.850586891174316
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00905643
Iteration 2/25 | Loss: 0.00191372
Iteration 3/25 | Loss: 0.00132385
Iteration 4/25 | Loss: 0.00129375
Iteration 5/25 | Loss: 0.00128651
Iteration 6/25 | Loss: 0.00128470
Iteration 7/25 | Loss: 0.00128452
Iteration 8/25 | Loss: 0.00128452
Iteration 9/25 | Loss: 0.00128452
Iteration 10/25 | Loss: 0.00128452
Iteration 11/25 | Loss: 0.00128452
Iteration 12/25 | Loss: 0.00128452
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0012845247983932495, 0.0012845247983932495, 0.0012845247983932495, 0.0012845247983932495, 0.0012845247983932495]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0012845247983932495

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.77882063
Iteration 2/25 | Loss: 0.00184672
Iteration 3/25 | Loss: 0.00184672
Iteration 4/25 | Loss: 0.00184671
Iteration 5/25 | Loss: 0.00184671
Iteration 6/25 | Loss: 0.00184671
Iteration 7/25 | Loss: 0.00184671
Iteration 8/25 | Loss: 0.00184671
Iteration 9/25 | Loss: 0.00184671
Iteration 10/25 | Loss: 0.00184671
Iteration 11/25 | Loss: 0.00184671
Iteration 12/25 | Loss: 0.00184671
Iteration 13/25 | Loss: 0.00184671
Iteration 14/25 | Loss: 0.00184671
Iteration 15/25 | Loss: 0.00184671
Iteration 16/25 | Loss: 0.00184671
Iteration 17/25 | Loss: 0.00184671
Iteration 18/25 | Loss: 0.00184671
Iteration 19/25 | Loss: 0.00184671
Iteration 20/25 | Loss: 0.00184671
Iteration 21/25 | Loss: 0.00184671
Iteration 22/25 | Loss: 0.00184671
Iteration 23/25 | Loss: 0.00184671
Iteration 24/25 | Loss: 0.00184671
Iteration 25/25 | Loss: 0.00184671

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00184671
Iteration 2/1000 | Loss: 0.00008839
Iteration 3/1000 | Loss: 0.00006461
Iteration 4/1000 | Loss: 0.00005826
Iteration 5/1000 | Loss: 0.00005473
Iteration 6/1000 | Loss: 0.00005304
Iteration 7/1000 | Loss: 0.00005221
Iteration 8/1000 | Loss: 0.00005110
Iteration 9/1000 | Loss: 0.00005025
Iteration 10/1000 | Loss: 0.00004952
Iteration 11/1000 | Loss: 0.00004890
Iteration 12/1000 | Loss: 0.00004833
Iteration 13/1000 | Loss: 0.00004773
Iteration 14/1000 | Loss: 0.00004719
Iteration 15/1000 | Loss: 0.00004688
Iteration 16/1000 | Loss: 0.00004660
Iteration 17/1000 | Loss: 0.00004638
Iteration 18/1000 | Loss: 0.00004620
Iteration 19/1000 | Loss: 0.00004606
Iteration 20/1000 | Loss: 0.00004605
Iteration 21/1000 | Loss: 0.00004599
Iteration 22/1000 | Loss: 0.00004593
Iteration 23/1000 | Loss: 0.00004587
Iteration 24/1000 | Loss: 0.00004587
Iteration 25/1000 | Loss: 0.00004585
Iteration 26/1000 | Loss: 0.00004584
Iteration 27/1000 | Loss: 0.00004584
Iteration 28/1000 | Loss: 0.00004583
Iteration 29/1000 | Loss: 0.00004583
Iteration 30/1000 | Loss: 0.00004581
Iteration 31/1000 | Loss: 0.00004581
Iteration 32/1000 | Loss: 0.00004580
Iteration 33/1000 | Loss: 0.00004579
Iteration 34/1000 | Loss: 0.00004579
Iteration 35/1000 | Loss: 0.00004579
Iteration 36/1000 | Loss: 0.00004579
Iteration 37/1000 | Loss: 0.00004579
Iteration 38/1000 | Loss: 0.00004579
Iteration 39/1000 | Loss: 0.00004579
Iteration 40/1000 | Loss: 0.00004578
Iteration 41/1000 | Loss: 0.00004578
Iteration 42/1000 | Loss: 0.00004578
Iteration 43/1000 | Loss: 0.00004578
Iteration 44/1000 | Loss: 0.00004577
Iteration 45/1000 | Loss: 0.00004576
Iteration 46/1000 | Loss: 0.00004575
Iteration 47/1000 | Loss: 0.00004575
Iteration 48/1000 | Loss: 0.00004574
Iteration 49/1000 | Loss: 0.00004574
Iteration 50/1000 | Loss: 0.00004574
Iteration 51/1000 | Loss: 0.00004574
Iteration 52/1000 | Loss: 0.00004574
Iteration 53/1000 | Loss: 0.00004574
Iteration 54/1000 | Loss: 0.00004574
Iteration 55/1000 | Loss: 0.00004574
Iteration 56/1000 | Loss: 0.00004574
Iteration 57/1000 | Loss: 0.00004574
Iteration 58/1000 | Loss: 0.00004572
Iteration 59/1000 | Loss: 0.00004572
Iteration 60/1000 | Loss: 0.00004571
Iteration 61/1000 | Loss: 0.00004571
Iteration 62/1000 | Loss: 0.00004570
Iteration 63/1000 | Loss: 0.00004570
Iteration 64/1000 | Loss: 0.00004570
Iteration 65/1000 | Loss: 0.00004569
Iteration 66/1000 | Loss: 0.00004569
Iteration 67/1000 | Loss: 0.00004569
Iteration 68/1000 | Loss: 0.00004568
Iteration 69/1000 | Loss: 0.00004567
Iteration 70/1000 | Loss: 0.00004567
Iteration 71/1000 | Loss: 0.00004567
Iteration 72/1000 | Loss: 0.00004567
Iteration 73/1000 | Loss: 0.00004567
Iteration 74/1000 | Loss: 0.00004567
Iteration 75/1000 | Loss: 0.00004567
Iteration 76/1000 | Loss: 0.00004567
Iteration 77/1000 | Loss: 0.00004567
Iteration 78/1000 | Loss: 0.00004567
Iteration 79/1000 | Loss: 0.00004567
Iteration 80/1000 | Loss: 0.00004567
Iteration 81/1000 | Loss: 0.00004566
Iteration 82/1000 | Loss: 0.00004566
Iteration 83/1000 | Loss: 0.00004566
Iteration 84/1000 | Loss: 0.00004566
Iteration 85/1000 | Loss: 0.00004565
Iteration 86/1000 | Loss: 0.00004564
Iteration 87/1000 | Loss: 0.00004564
Iteration 88/1000 | Loss: 0.00004564
Iteration 89/1000 | Loss: 0.00004564
Iteration 90/1000 | Loss: 0.00004564
Iteration 91/1000 | Loss: 0.00004564
Iteration 92/1000 | Loss: 0.00004564
Iteration 93/1000 | Loss: 0.00004564
Iteration 94/1000 | Loss: 0.00004564
Iteration 95/1000 | Loss: 0.00004564
Iteration 96/1000 | Loss: 0.00004564
Iteration 97/1000 | Loss: 0.00004563
Iteration 98/1000 | Loss: 0.00004563
Iteration 99/1000 | Loss: 0.00004563
Iteration 100/1000 | Loss: 0.00004563
Iteration 101/1000 | Loss: 0.00004563
Iteration 102/1000 | Loss: 0.00004562
Iteration 103/1000 | Loss: 0.00004562
Iteration 104/1000 | Loss: 0.00004562
Iteration 105/1000 | Loss: 0.00004561
Iteration 106/1000 | Loss: 0.00004561
Iteration 107/1000 | Loss: 0.00004561
Iteration 108/1000 | Loss: 0.00004561
Iteration 109/1000 | Loss: 0.00004561
Iteration 110/1000 | Loss: 0.00004561
Iteration 111/1000 | Loss: 0.00004560
Iteration 112/1000 | Loss: 0.00004560
Iteration 113/1000 | Loss: 0.00004560
Iteration 114/1000 | Loss: 0.00004560
Iteration 115/1000 | Loss: 0.00004560
Iteration 116/1000 | Loss: 0.00004560
Iteration 117/1000 | Loss: 0.00004559
Iteration 118/1000 | Loss: 0.00004559
Iteration 119/1000 | Loss: 0.00004559
Iteration 120/1000 | Loss: 0.00004559
Iteration 121/1000 | Loss: 0.00004558
Iteration 122/1000 | Loss: 0.00004558
Iteration 123/1000 | Loss: 0.00004558
Iteration 124/1000 | Loss: 0.00004558
Iteration 125/1000 | Loss: 0.00004558
Iteration 126/1000 | Loss: 0.00004558
Iteration 127/1000 | Loss: 0.00004558
Iteration 128/1000 | Loss: 0.00004558
Iteration 129/1000 | Loss: 0.00004557
Iteration 130/1000 | Loss: 0.00004557
Iteration 131/1000 | Loss: 0.00004557
Iteration 132/1000 | Loss: 0.00004557
Iteration 133/1000 | Loss: 0.00004556
Iteration 134/1000 | Loss: 0.00004556
Iteration 135/1000 | Loss: 0.00004556
Iteration 136/1000 | Loss: 0.00004556
Iteration 137/1000 | Loss: 0.00004556
Iteration 138/1000 | Loss: 0.00004556
Iteration 139/1000 | Loss: 0.00004555
Iteration 140/1000 | Loss: 0.00004555
Iteration 141/1000 | Loss: 0.00004555
Iteration 142/1000 | Loss: 0.00004555
Iteration 143/1000 | Loss: 0.00004554
Iteration 144/1000 | Loss: 0.00004554
Iteration 145/1000 | Loss: 0.00004554
Iteration 146/1000 | Loss: 0.00004554
Iteration 147/1000 | Loss: 0.00004554
Iteration 148/1000 | Loss: 0.00004554
Iteration 149/1000 | Loss: 0.00004554
Iteration 150/1000 | Loss: 0.00004554
Iteration 151/1000 | Loss: 0.00004554
Iteration 152/1000 | Loss: 0.00004554
Iteration 153/1000 | Loss: 0.00004554
Iteration 154/1000 | Loss: 0.00004554
Iteration 155/1000 | Loss: 0.00004554
Iteration 156/1000 | Loss: 0.00004554
Iteration 157/1000 | Loss: 0.00004553
Iteration 158/1000 | Loss: 0.00004553
Iteration 159/1000 | Loss: 0.00004553
Iteration 160/1000 | Loss: 0.00004553
Iteration 161/1000 | Loss: 0.00004553
Iteration 162/1000 | Loss: 0.00004553
Iteration 163/1000 | Loss: 0.00004553
Iteration 164/1000 | Loss: 0.00004553
Iteration 165/1000 | Loss: 0.00004553
Iteration 166/1000 | Loss: 0.00004553
Iteration 167/1000 | Loss: 0.00004553
Iteration 168/1000 | Loss: 0.00004553
Iteration 169/1000 | Loss: 0.00004553
Iteration 170/1000 | Loss: 0.00004553
Iteration 171/1000 | Loss: 0.00004552
Iteration 172/1000 | Loss: 0.00004552
Iteration 173/1000 | Loss: 0.00004552
Iteration 174/1000 | Loss: 0.00004552
Iteration 175/1000 | Loss: 0.00004552
Iteration 176/1000 | Loss: 0.00004552
Iteration 177/1000 | Loss: 0.00004552
Iteration 178/1000 | Loss: 0.00004552
Iteration 179/1000 | Loss: 0.00004552
Iteration 180/1000 | Loss: 0.00004552
Iteration 181/1000 | Loss: 0.00004551
Iteration 182/1000 | Loss: 0.00004551
Iteration 183/1000 | Loss: 0.00004551
Iteration 184/1000 | Loss: 0.00004551
Iteration 185/1000 | Loss: 0.00004551
Iteration 186/1000 | Loss: 0.00004551
Iteration 187/1000 | Loss: 0.00004551
Iteration 188/1000 | Loss: 0.00004551
Iteration 189/1000 | Loss: 0.00004551
Iteration 190/1000 | Loss: 0.00004551
Iteration 191/1000 | Loss: 0.00004551
Iteration 192/1000 | Loss: 0.00004551
Iteration 193/1000 | Loss: 0.00004551
Iteration 194/1000 | Loss: 0.00004551
Iteration 195/1000 | Loss: 0.00004551
Iteration 196/1000 | Loss: 0.00004551
Iteration 197/1000 | Loss: 0.00004551
Iteration 198/1000 | Loss: 0.00004551
Iteration 199/1000 | Loss: 0.00004551
Iteration 200/1000 | Loss: 0.00004551
Iteration 201/1000 | Loss: 0.00004551
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 201. Stopping optimization.
Last 5 losses: [4.551333040581085e-05, 4.551333040581085e-05, 4.551333040581085e-05, 4.551333040581085e-05, 4.551333040581085e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.551333040581085e-05

Optimization complete. Final v2v error: 5.496450901031494 mm

Highest mean error: 6.4006667137146 mm for frame 164

Lowest mean error: 3.766876220703125 mm for frame 1

Saving results

Total time: 52.17971324920654
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00511022
Iteration 2/25 | Loss: 0.00129131
Iteration 3/25 | Loss: 0.00114394
Iteration 4/25 | Loss: 0.00110615
Iteration 5/25 | Loss: 0.00109316
Iteration 6/25 | Loss: 0.00109091
Iteration 7/25 | Loss: 0.00109036
Iteration 8/25 | Loss: 0.00109034
Iteration 9/25 | Loss: 0.00109034
Iteration 10/25 | Loss: 0.00109034
Iteration 11/25 | Loss: 0.00109034
Iteration 12/25 | Loss: 0.00109034
Iteration 13/25 | Loss: 0.00109034
Iteration 14/25 | Loss: 0.00109034
Iteration 15/25 | Loss: 0.00109034
Iteration 16/25 | Loss: 0.00109034
Iteration 17/25 | Loss: 0.00109034
Iteration 18/25 | Loss: 0.00109034
Iteration 19/25 | Loss: 0.00109034
Iteration 20/25 | Loss: 0.00109034
Iteration 21/25 | Loss: 0.00109034
Iteration 22/25 | Loss: 0.00109034
Iteration 23/25 | Loss: 0.00109034
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0010903432266786695, 0.0010903432266786695, 0.0010903432266786695, 0.0010903432266786695, 0.0010903432266786695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010903432266786695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.92277348
Iteration 2/25 | Loss: 0.00815628
Iteration 3/25 | Loss: 0.00815628
Iteration 4/25 | Loss: 0.00815627
Iteration 5/25 | Loss: 0.00815627
Iteration 6/25 | Loss: 0.00815627
Iteration 7/25 | Loss: 0.00815627
Iteration 8/25 | Loss: 0.00815627
Iteration 9/25 | Loss: 0.00815627
Iteration 10/25 | Loss: 0.00815627
Iteration 11/25 | Loss: 0.00815627
Iteration 12/25 | Loss: 0.00815627
Iteration 13/25 | Loss: 0.00815627
Iteration 14/25 | Loss: 0.00815627
Iteration 15/25 | Loss: 0.00815627
Iteration 16/25 | Loss: 0.00815627
Iteration 17/25 | Loss: 0.00815627
Iteration 18/25 | Loss: 0.00815627
Iteration 19/25 | Loss: 0.00815627
Iteration 20/25 | Loss: 0.00815627
Iteration 21/25 | Loss: 0.00815627
Iteration 22/25 | Loss: 0.00815627
Iteration 23/25 | Loss: 0.00815627
Iteration 24/25 | Loss: 0.00815627
Iteration 25/25 | Loss: 0.00815627

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00815627
Iteration 2/1000 | Loss: 0.00005168
Iteration 3/1000 | Loss: 0.00002850
Iteration 4/1000 | Loss: 0.00002498
Iteration 5/1000 | Loss: 0.00002305
Iteration 6/1000 | Loss: 0.00002149
Iteration 7/1000 | Loss: 0.00002074
Iteration 8/1000 | Loss: 0.00002008
Iteration 9/1000 | Loss: 0.00001968
Iteration 10/1000 | Loss: 0.00001938
Iteration 11/1000 | Loss: 0.00001933
Iteration 12/1000 | Loss: 0.00001914
Iteration 13/1000 | Loss: 0.00001899
Iteration 14/1000 | Loss: 0.00001886
Iteration 15/1000 | Loss: 0.00001876
Iteration 16/1000 | Loss: 0.00001871
Iteration 17/1000 | Loss: 0.00001866
Iteration 18/1000 | Loss: 0.00001856
Iteration 19/1000 | Loss: 0.00001855
Iteration 20/1000 | Loss: 0.00001851
Iteration 21/1000 | Loss: 0.00001851
Iteration 22/1000 | Loss: 0.00001846
Iteration 23/1000 | Loss: 0.00001846
Iteration 24/1000 | Loss: 0.00001845
Iteration 25/1000 | Loss: 0.00001845
Iteration 26/1000 | Loss: 0.00001844
Iteration 27/1000 | Loss: 0.00001842
Iteration 28/1000 | Loss: 0.00001840
Iteration 29/1000 | Loss: 0.00001840
Iteration 30/1000 | Loss: 0.00001840
Iteration 31/1000 | Loss: 0.00001840
Iteration 32/1000 | Loss: 0.00001839
Iteration 33/1000 | Loss: 0.00001839
Iteration 34/1000 | Loss: 0.00001839
Iteration 35/1000 | Loss: 0.00001839
Iteration 36/1000 | Loss: 0.00001839
Iteration 37/1000 | Loss: 0.00001839
Iteration 38/1000 | Loss: 0.00001839
Iteration 39/1000 | Loss: 0.00001839
Iteration 40/1000 | Loss: 0.00001839
Iteration 41/1000 | Loss: 0.00001839
Iteration 42/1000 | Loss: 0.00001839
Iteration 43/1000 | Loss: 0.00001839
Iteration 44/1000 | Loss: 0.00001839
Iteration 45/1000 | Loss: 0.00001838
Iteration 46/1000 | Loss: 0.00001838
Iteration 47/1000 | Loss: 0.00001838
Iteration 48/1000 | Loss: 0.00001838
Iteration 49/1000 | Loss: 0.00001838
Iteration 50/1000 | Loss: 0.00001837
Iteration 51/1000 | Loss: 0.00001837
Iteration 52/1000 | Loss: 0.00001837
Iteration 53/1000 | Loss: 0.00001837
Iteration 54/1000 | Loss: 0.00001837
Iteration 55/1000 | Loss: 0.00001837
Iteration 56/1000 | Loss: 0.00001837
Iteration 57/1000 | Loss: 0.00001837
Iteration 58/1000 | Loss: 0.00001837
Iteration 59/1000 | Loss: 0.00001837
Iteration 60/1000 | Loss: 0.00001836
Iteration 61/1000 | Loss: 0.00001836
Iteration 62/1000 | Loss: 0.00001836
Iteration 63/1000 | Loss: 0.00001836
Iteration 64/1000 | Loss: 0.00001836
Iteration 65/1000 | Loss: 0.00001836
Iteration 66/1000 | Loss: 0.00001836
Iteration 67/1000 | Loss: 0.00001836
Iteration 68/1000 | Loss: 0.00001836
Iteration 69/1000 | Loss: 0.00001836
Iteration 70/1000 | Loss: 0.00001836
Iteration 71/1000 | Loss: 0.00001836
Iteration 72/1000 | Loss: 0.00001836
Iteration 73/1000 | Loss: 0.00001836
Iteration 74/1000 | Loss: 0.00001836
Iteration 75/1000 | Loss: 0.00001836
Iteration 76/1000 | Loss: 0.00001836
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 76. Stopping optimization.
Last 5 losses: [1.8364784409641288e-05, 1.8364784409641288e-05, 1.8364784409641288e-05, 1.8364784409641288e-05, 1.8364784409641288e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8364784409641288e-05

Optimization complete. Final v2v error: 3.550769567489624 mm

Highest mean error: 4.031150817871094 mm for frame 182

Lowest mean error: 3.2340593338012695 mm for frame 136

Saving results

Total time: 37.91000580787659
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00409782
Iteration 2/25 | Loss: 0.00107213
Iteration 3/25 | Loss: 0.00093566
Iteration 4/25 | Loss: 0.00091923
Iteration 5/25 | Loss: 0.00091465
Iteration 6/25 | Loss: 0.00091330
Iteration 7/25 | Loss: 0.00091301
Iteration 8/25 | Loss: 0.00091301
Iteration 9/25 | Loss: 0.00091301
Iteration 10/25 | Loss: 0.00091301
Iteration 11/25 | Loss: 0.00091301
Iteration 12/25 | Loss: 0.00091301
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009130072430707514, 0.0009130072430707514, 0.0009130072430707514, 0.0009130072430707514, 0.0009130072430707514]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009130072430707514

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.80628729
Iteration 2/25 | Loss: 0.00443184
Iteration 3/25 | Loss: 0.00443184
Iteration 4/25 | Loss: 0.00443183
Iteration 5/25 | Loss: 0.00443183
Iteration 6/25 | Loss: 0.00443183
Iteration 7/25 | Loss: 0.00443183
Iteration 8/25 | Loss: 0.00443183
Iteration 9/25 | Loss: 0.00443183
Iteration 10/25 | Loss: 0.00443183
Iteration 11/25 | Loss: 0.00443183
Iteration 12/25 | Loss: 0.00443183
Iteration 13/25 | Loss: 0.00443183
Iteration 14/25 | Loss: 0.00443183
Iteration 15/25 | Loss: 0.00443183
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.004431831184774637, 0.004431831184774637, 0.004431831184774637, 0.004431831184774637, 0.004431831184774637]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004431831184774637

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00443183
Iteration 2/1000 | Loss: 0.00002578
Iteration 3/1000 | Loss: 0.00001850
Iteration 4/1000 | Loss: 0.00001577
Iteration 5/1000 | Loss: 0.00001472
Iteration 6/1000 | Loss: 0.00001392
Iteration 7/1000 | Loss: 0.00001360
Iteration 8/1000 | Loss: 0.00001330
Iteration 9/1000 | Loss: 0.00001310
Iteration 10/1000 | Loss: 0.00001309
Iteration 11/1000 | Loss: 0.00001307
Iteration 12/1000 | Loss: 0.00001306
Iteration 13/1000 | Loss: 0.00001306
Iteration 14/1000 | Loss: 0.00001301
Iteration 15/1000 | Loss: 0.00001300
Iteration 16/1000 | Loss: 0.00001299
Iteration 17/1000 | Loss: 0.00001299
Iteration 18/1000 | Loss: 0.00001298
Iteration 19/1000 | Loss: 0.00001297
Iteration 20/1000 | Loss: 0.00001297
Iteration 21/1000 | Loss: 0.00001295
Iteration 22/1000 | Loss: 0.00001294
Iteration 23/1000 | Loss: 0.00001293
Iteration 24/1000 | Loss: 0.00001293
Iteration 25/1000 | Loss: 0.00001293
Iteration 26/1000 | Loss: 0.00001292
Iteration 27/1000 | Loss: 0.00001291
Iteration 28/1000 | Loss: 0.00001291
Iteration 29/1000 | Loss: 0.00001291
Iteration 30/1000 | Loss: 0.00001291
Iteration 31/1000 | Loss: 0.00001291
Iteration 32/1000 | Loss: 0.00001291
Iteration 33/1000 | Loss: 0.00001289
Iteration 34/1000 | Loss: 0.00001288
Iteration 35/1000 | Loss: 0.00001288
Iteration 36/1000 | Loss: 0.00001287
Iteration 37/1000 | Loss: 0.00001286
Iteration 38/1000 | Loss: 0.00001286
Iteration 39/1000 | Loss: 0.00001285
Iteration 40/1000 | Loss: 0.00001285
Iteration 41/1000 | Loss: 0.00001284
Iteration 42/1000 | Loss: 0.00001284
Iteration 43/1000 | Loss: 0.00001284
Iteration 44/1000 | Loss: 0.00001283
Iteration 45/1000 | Loss: 0.00001283
Iteration 46/1000 | Loss: 0.00001282
Iteration 47/1000 | Loss: 0.00001281
Iteration 48/1000 | Loss: 0.00001280
Iteration 49/1000 | Loss: 0.00001279
Iteration 50/1000 | Loss: 0.00001279
Iteration 51/1000 | Loss: 0.00001279
Iteration 52/1000 | Loss: 0.00001278
Iteration 53/1000 | Loss: 0.00001277
Iteration 54/1000 | Loss: 0.00001277
Iteration 55/1000 | Loss: 0.00001276
Iteration 56/1000 | Loss: 0.00001276
Iteration 57/1000 | Loss: 0.00001275
Iteration 58/1000 | Loss: 0.00001275
Iteration 59/1000 | Loss: 0.00001274
Iteration 60/1000 | Loss: 0.00001274
Iteration 61/1000 | Loss: 0.00001274
Iteration 62/1000 | Loss: 0.00001273
Iteration 63/1000 | Loss: 0.00001273
Iteration 64/1000 | Loss: 0.00001272
Iteration 65/1000 | Loss: 0.00001272
Iteration 66/1000 | Loss: 0.00001272
Iteration 67/1000 | Loss: 0.00001272
Iteration 68/1000 | Loss: 0.00001271
Iteration 69/1000 | Loss: 0.00001271
Iteration 70/1000 | Loss: 0.00001271
Iteration 71/1000 | Loss: 0.00001271
Iteration 72/1000 | Loss: 0.00001271
Iteration 73/1000 | Loss: 0.00001271
Iteration 74/1000 | Loss: 0.00001271
Iteration 75/1000 | Loss: 0.00001271
Iteration 76/1000 | Loss: 0.00001271
Iteration 77/1000 | Loss: 0.00001270
Iteration 78/1000 | Loss: 0.00001270
Iteration 79/1000 | Loss: 0.00001270
Iteration 80/1000 | Loss: 0.00001270
Iteration 81/1000 | Loss: 0.00001270
Iteration 82/1000 | Loss: 0.00001270
Iteration 83/1000 | Loss: 0.00001270
Iteration 84/1000 | Loss: 0.00001270
Iteration 85/1000 | Loss: 0.00001270
Iteration 86/1000 | Loss: 0.00001269
Iteration 87/1000 | Loss: 0.00001269
Iteration 88/1000 | Loss: 0.00001269
Iteration 89/1000 | Loss: 0.00001269
Iteration 90/1000 | Loss: 0.00001269
Iteration 91/1000 | Loss: 0.00001268
Iteration 92/1000 | Loss: 0.00001268
Iteration 93/1000 | Loss: 0.00001268
Iteration 94/1000 | Loss: 0.00001268
Iteration 95/1000 | Loss: 0.00001267
Iteration 96/1000 | Loss: 0.00001267
Iteration 97/1000 | Loss: 0.00001267
Iteration 98/1000 | Loss: 0.00001267
Iteration 99/1000 | Loss: 0.00001267
Iteration 100/1000 | Loss: 0.00001267
Iteration 101/1000 | Loss: 0.00001267
Iteration 102/1000 | Loss: 0.00001267
Iteration 103/1000 | Loss: 0.00001266
Iteration 104/1000 | Loss: 0.00001266
Iteration 105/1000 | Loss: 0.00001266
Iteration 106/1000 | Loss: 0.00001266
Iteration 107/1000 | Loss: 0.00001266
Iteration 108/1000 | Loss: 0.00001266
Iteration 109/1000 | Loss: 0.00001266
Iteration 110/1000 | Loss: 0.00001266
Iteration 111/1000 | Loss: 0.00001266
Iteration 112/1000 | Loss: 0.00001266
Iteration 113/1000 | Loss: 0.00001266
Iteration 114/1000 | Loss: 0.00001266
Iteration 115/1000 | Loss: 0.00001266
Iteration 116/1000 | Loss: 0.00001265
Iteration 117/1000 | Loss: 0.00001265
Iteration 118/1000 | Loss: 0.00001265
Iteration 119/1000 | Loss: 0.00001265
Iteration 120/1000 | Loss: 0.00001265
Iteration 121/1000 | Loss: 0.00001265
Iteration 122/1000 | Loss: 0.00001265
Iteration 123/1000 | Loss: 0.00001265
Iteration 124/1000 | Loss: 0.00001265
Iteration 125/1000 | Loss: 0.00001265
Iteration 126/1000 | Loss: 0.00001265
Iteration 127/1000 | Loss: 0.00001264
Iteration 128/1000 | Loss: 0.00001264
Iteration 129/1000 | Loss: 0.00001264
Iteration 130/1000 | Loss: 0.00001264
Iteration 131/1000 | Loss: 0.00001264
Iteration 132/1000 | Loss: 0.00001264
Iteration 133/1000 | Loss: 0.00001264
Iteration 134/1000 | Loss: 0.00001264
Iteration 135/1000 | Loss: 0.00001264
Iteration 136/1000 | Loss: 0.00001263
Iteration 137/1000 | Loss: 0.00001263
Iteration 138/1000 | Loss: 0.00001263
Iteration 139/1000 | Loss: 0.00001263
Iteration 140/1000 | Loss: 0.00001263
Iteration 141/1000 | Loss: 0.00001263
Iteration 142/1000 | Loss: 0.00001263
Iteration 143/1000 | Loss: 0.00001263
Iteration 144/1000 | Loss: 0.00001263
Iteration 145/1000 | Loss: 0.00001263
Iteration 146/1000 | Loss: 0.00001263
Iteration 147/1000 | Loss: 0.00001263
Iteration 148/1000 | Loss: 0.00001263
Iteration 149/1000 | Loss: 0.00001263
Iteration 150/1000 | Loss: 0.00001263
Iteration 151/1000 | Loss: 0.00001263
Iteration 152/1000 | Loss: 0.00001263
Iteration 153/1000 | Loss: 0.00001263
Iteration 154/1000 | Loss: 0.00001263
Iteration 155/1000 | Loss: 0.00001263
Iteration 156/1000 | Loss: 0.00001263
Iteration 157/1000 | Loss: 0.00001263
Iteration 158/1000 | Loss: 0.00001263
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 158. Stopping optimization.
Last 5 losses: [1.2625197086890694e-05, 1.2625197086890694e-05, 1.2625197086890694e-05, 1.2625197086890694e-05, 1.2625197086890694e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2625197086890694e-05

Optimization complete. Final v2v error: 3.07974910736084 mm

Highest mean error: 3.8831064701080322 mm for frame 64

Lowest mean error: 2.839665412902832 mm for frame 93

Saving results

Total time: 34.14656972885132
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00547583
Iteration 2/25 | Loss: 0.00114534
Iteration 3/25 | Loss: 0.00104367
Iteration 4/25 | Loss: 0.00101998
Iteration 5/25 | Loss: 0.00101630
Iteration 6/25 | Loss: 0.00101605
Iteration 7/25 | Loss: 0.00101605
Iteration 8/25 | Loss: 0.00101605
Iteration 9/25 | Loss: 0.00101605
Iteration 10/25 | Loss: 0.00101605
Iteration 11/25 | Loss: 0.00101605
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0010160461533814669, 0.0010160461533814669, 0.0010160461533814669, 0.0010160461533814669, 0.0010160461533814669]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010160461533814669

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79315567
Iteration 2/25 | Loss: 0.00434106
Iteration 3/25 | Loss: 0.00434102
Iteration 4/25 | Loss: 0.00434102
Iteration 5/25 | Loss: 0.00434102
Iteration 6/25 | Loss: 0.00434102
Iteration 7/25 | Loss: 0.00434102
Iteration 8/25 | Loss: 0.00434102
Iteration 9/25 | Loss: 0.00434102
Iteration 10/25 | Loss: 0.00434102
Iteration 11/25 | Loss: 0.00434102
Iteration 12/25 | Loss: 0.00434102
Iteration 13/25 | Loss: 0.00434102
Iteration 14/25 | Loss: 0.00434102
Iteration 15/25 | Loss: 0.00434102
Iteration 16/25 | Loss: 0.00434102
Iteration 17/25 | Loss: 0.00434102
Iteration 18/25 | Loss: 0.00434102
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.004341019317507744, 0.004341019317507744, 0.004341019317507744, 0.004341019317507744, 0.004341019317507744]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004341019317507744

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00434102
Iteration 2/1000 | Loss: 0.00004552
Iteration 3/1000 | Loss: 0.00003471
Iteration 4/1000 | Loss: 0.00002990
Iteration 5/1000 | Loss: 0.00002758
Iteration 6/1000 | Loss: 0.00002592
Iteration 7/1000 | Loss: 0.00002516
Iteration 8/1000 | Loss: 0.00002435
Iteration 9/1000 | Loss: 0.00002369
Iteration 10/1000 | Loss: 0.00002331
Iteration 11/1000 | Loss: 0.00002302
Iteration 12/1000 | Loss: 0.00002277
Iteration 13/1000 | Loss: 0.00002255
Iteration 14/1000 | Loss: 0.00002238
Iteration 15/1000 | Loss: 0.00002233
Iteration 16/1000 | Loss: 0.00002230
Iteration 17/1000 | Loss: 0.00002225
Iteration 18/1000 | Loss: 0.00002223
Iteration 19/1000 | Loss: 0.00002217
Iteration 20/1000 | Loss: 0.00002216
Iteration 21/1000 | Loss: 0.00002215
Iteration 22/1000 | Loss: 0.00002215
Iteration 23/1000 | Loss: 0.00002214
Iteration 24/1000 | Loss: 0.00002213
Iteration 25/1000 | Loss: 0.00002210
Iteration 26/1000 | Loss: 0.00002210
Iteration 27/1000 | Loss: 0.00002209
Iteration 28/1000 | Loss: 0.00002209
Iteration 29/1000 | Loss: 0.00002209
Iteration 30/1000 | Loss: 0.00002209
Iteration 31/1000 | Loss: 0.00002208
Iteration 32/1000 | Loss: 0.00002208
Iteration 33/1000 | Loss: 0.00002207
Iteration 34/1000 | Loss: 0.00002207
Iteration 35/1000 | Loss: 0.00002207
Iteration 36/1000 | Loss: 0.00002207
Iteration 37/1000 | Loss: 0.00002206
Iteration 38/1000 | Loss: 0.00002206
Iteration 39/1000 | Loss: 0.00002206
Iteration 40/1000 | Loss: 0.00002206
Iteration 41/1000 | Loss: 0.00002206
Iteration 42/1000 | Loss: 0.00002206
Iteration 43/1000 | Loss: 0.00002205
Iteration 44/1000 | Loss: 0.00002205
Iteration 45/1000 | Loss: 0.00002204
Iteration 46/1000 | Loss: 0.00002204
Iteration 47/1000 | Loss: 0.00002203
Iteration 48/1000 | Loss: 0.00002203
Iteration 49/1000 | Loss: 0.00002203
Iteration 50/1000 | Loss: 0.00002202
Iteration 51/1000 | Loss: 0.00002202
Iteration 52/1000 | Loss: 0.00002202
Iteration 53/1000 | Loss: 0.00002201
Iteration 54/1000 | Loss: 0.00002201
Iteration 55/1000 | Loss: 0.00002201
Iteration 56/1000 | Loss: 0.00002201
Iteration 57/1000 | Loss: 0.00002201
Iteration 58/1000 | Loss: 0.00002201
Iteration 59/1000 | Loss: 0.00002201
Iteration 60/1000 | Loss: 0.00002201
Iteration 61/1000 | Loss: 0.00002200
Iteration 62/1000 | Loss: 0.00002200
Iteration 63/1000 | Loss: 0.00002200
Iteration 64/1000 | Loss: 0.00002199
Iteration 65/1000 | Loss: 0.00002199
Iteration 66/1000 | Loss: 0.00002199
Iteration 67/1000 | Loss: 0.00002199
Iteration 68/1000 | Loss: 0.00002198
Iteration 69/1000 | Loss: 0.00002198
Iteration 70/1000 | Loss: 0.00002198
Iteration 71/1000 | Loss: 0.00002198
Iteration 72/1000 | Loss: 0.00002198
Iteration 73/1000 | Loss: 0.00002198
Iteration 74/1000 | Loss: 0.00002197
Iteration 75/1000 | Loss: 0.00002197
Iteration 76/1000 | Loss: 0.00002197
Iteration 77/1000 | Loss: 0.00002197
Iteration 78/1000 | Loss: 0.00002197
Iteration 79/1000 | Loss: 0.00002197
Iteration 80/1000 | Loss: 0.00002196
Iteration 81/1000 | Loss: 0.00002196
Iteration 82/1000 | Loss: 0.00002196
Iteration 83/1000 | Loss: 0.00002196
Iteration 84/1000 | Loss: 0.00002195
Iteration 85/1000 | Loss: 0.00002195
Iteration 86/1000 | Loss: 0.00002195
Iteration 87/1000 | Loss: 0.00002194
Iteration 88/1000 | Loss: 0.00002194
Iteration 89/1000 | Loss: 0.00002194
Iteration 90/1000 | Loss: 0.00002194
Iteration 91/1000 | Loss: 0.00002194
Iteration 92/1000 | Loss: 0.00002194
Iteration 93/1000 | Loss: 0.00002194
Iteration 94/1000 | Loss: 0.00002193
Iteration 95/1000 | Loss: 0.00002193
Iteration 96/1000 | Loss: 0.00002193
Iteration 97/1000 | Loss: 0.00002193
Iteration 98/1000 | Loss: 0.00002193
Iteration 99/1000 | Loss: 0.00002193
Iteration 100/1000 | Loss: 0.00002193
Iteration 101/1000 | Loss: 0.00002192
Iteration 102/1000 | Loss: 0.00002192
Iteration 103/1000 | Loss: 0.00002192
Iteration 104/1000 | Loss: 0.00002191
Iteration 105/1000 | Loss: 0.00002191
Iteration 106/1000 | Loss: 0.00002191
Iteration 107/1000 | Loss: 0.00002191
Iteration 108/1000 | Loss: 0.00002191
Iteration 109/1000 | Loss: 0.00002191
Iteration 110/1000 | Loss: 0.00002190
Iteration 111/1000 | Loss: 0.00002190
Iteration 112/1000 | Loss: 0.00002190
Iteration 113/1000 | Loss: 0.00002190
Iteration 114/1000 | Loss: 0.00002190
Iteration 115/1000 | Loss: 0.00002190
Iteration 116/1000 | Loss: 0.00002190
Iteration 117/1000 | Loss: 0.00002190
Iteration 118/1000 | Loss: 0.00002190
Iteration 119/1000 | Loss: 0.00002190
Iteration 120/1000 | Loss: 0.00002189
Iteration 121/1000 | Loss: 0.00002189
Iteration 122/1000 | Loss: 0.00002189
Iteration 123/1000 | Loss: 0.00002189
Iteration 124/1000 | Loss: 0.00002189
Iteration 125/1000 | Loss: 0.00002189
Iteration 126/1000 | Loss: 0.00002189
Iteration 127/1000 | Loss: 0.00002189
Iteration 128/1000 | Loss: 0.00002189
Iteration 129/1000 | Loss: 0.00002189
Iteration 130/1000 | Loss: 0.00002189
Iteration 131/1000 | Loss: 0.00002189
Iteration 132/1000 | Loss: 0.00002189
Iteration 133/1000 | Loss: 0.00002189
Iteration 134/1000 | Loss: 0.00002189
Iteration 135/1000 | Loss: 0.00002188
Iteration 136/1000 | Loss: 0.00002188
Iteration 137/1000 | Loss: 0.00002188
Iteration 138/1000 | Loss: 0.00002188
Iteration 139/1000 | Loss: 0.00002188
Iteration 140/1000 | Loss: 0.00002188
Iteration 141/1000 | Loss: 0.00002188
Iteration 142/1000 | Loss: 0.00002188
Iteration 143/1000 | Loss: 0.00002188
Iteration 144/1000 | Loss: 0.00002188
Iteration 145/1000 | Loss: 0.00002187
Iteration 146/1000 | Loss: 0.00002187
Iteration 147/1000 | Loss: 0.00002187
Iteration 148/1000 | Loss: 0.00002187
Iteration 149/1000 | Loss: 0.00002187
Iteration 150/1000 | Loss: 0.00002187
Iteration 151/1000 | Loss: 0.00002187
Iteration 152/1000 | Loss: 0.00002187
Iteration 153/1000 | Loss: 0.00002187
Iteration 154/1000 | Loss: 0.00002187
Iteration 155/1000 | Loss: 0.00002187
Iteration 156/1000 | Loss: 0.00002187
Iteration 157/1000 | Loss: 0.00002187
Iteration 158/1000 | Loss: 0.00002187
Iteration 159/1000 | Loss: 0.00002187
Iteration 160/1000 | Loss: 0.00002187
Iteration 161/1000 | Loss: 0.00002187
Iteration 162/1000 | Loss: 0.00002187
Iteration 163/1000 | Loss: 0.00002187
Iteration 164/1000 | Loss: 0.00002187
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 164. Stopping optimization.
Last 5 losses: [2.186809797422029e-05, 2.186809797422029e-05, 2.186809797422029e-05, 2.186809797422029e-05, 2.186809797422029e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.186809797422029e-05

Optimization complete. Final v2v error: 3.9791958332061768 mm

Highest mean error: 4.907533168792725 mm for frame 157

Lowest mean error: 3.3594062328338623 mm for frame 188

Saving results

Total time: 46.002464294433594
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00972064
Iteration 2/25 | Loss: 0.00191729
Iteration 3/25 | Loss: 0.00129251
Iteration 4/25 | Loss: 0.00117974
Iteration 5/25 | Loss: 0.00114707
Iteration 6/25 | Loss: 0.00108019
Iteration 7/25 | Loss: 0.00106846
Iteration 8/25 | Loss: 0.00106613
Iteration 9/25 | Loss: 0.00106550
Iteration 10/25 | Loss: 0.00106522
Iteration 11/25 | Loss: 0.00106513
Iteration 12/25 | Loss: 0.00106513
Iteration 13/25 | Loss: 0.00106513
Iteration 14/25 | Loss: 0.00106513
Iteration 15/25 | Loss: 0.00106513
Iteration 16/25 | Loss: 0.00106513
Iteration 17/25 | Loss: 0.00106513
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0010651270858943462, 0.0010651270858943462, 0.0010651270858943462, 0.0010651270858943462, 0.0010651270858943462]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010651270858943462

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.00185299
Iteration 2/25 | Loss: 0.00470350
Iteration 3/25 | Loss: 0.00470350
Iteration 4/25 | Loss: 0.00470350
Iteration 5/25 | Loss: 0.00470350
Iteration 6/25 | Loss: 0.00470350
Iteration 7/25 | Loss: 0.00470350
Iteration 8/25 | Loss: 0.00470350
Iteration 9/25 | Loss: 0.00470350
Iteration 10/25 | Loss: 0.00470350
Iteration 11/25 | Loss: 0.00470350
Iteration 12/25 | Loss: 0.00470349
Iteration 13/25 | Loss: 0.00470350
Iteration 14/25 | Loss: 0.00470350
Iteration 15/25 | Loss: 0.00470350
Iteration 16/25 | Loss: 0.00470350
Iteration 17/25 | Loss: 0.00470350
Iteration 18/25 | Loss: 0.00470350
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0047034951858222485, 0.0047034951858222485, 0.0047034951858222485, 0.0047034951858222485, 0.0047034951858222485]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0047034951858222485

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00470350
Iteration 2/1000 | Loss: 0.00005086
Iteration 3/1000 | Loss: 0.00003641
Iteration 4/1000 | Loss: 0.00003287
Iteration 5/1000 | Loss: 0.00003064
Iteration 6/1000 | Loss: 0.00002897
Iteration 7/1000 | Loss: 0.00002794
Iteration 8/1000 | Loss: 0.00002728
Iteration 9/1000 | Loss: 0.00002686
Iteration 10/1000 | Loss: 0.00002646
Iteration 11/1000 | Loss: 0.00002615
Iteration 12/1000 | Loss: 0.00002591
Iteration 13/1000 | Loss: 0.00002579
Iteration 14/1000 | Loss: 0.00002564
Iteration 15/1000 | Loss: 0.00002551
Iteration 16/1000 | Loss: 0.00002548
Iteration 17/1000 | Loss: 0.00002547
Iteration 18/1000 | Loss: 0.00002546
Iteration 19/1000 | Loss: 0.00002545
Iteration 20/1000 | Loss: 0.00002545
Iteration 21/1000 | Loss: 0.00002545
Iteration 22/1000 | Loss: 0.00002543
Iteration 23/1000 | Loss: 0.00002543
Iteration 24/1000 | Loss: 0.00002543
Iteration 25/1000 | Loss: 0.00002543
Iteration 26/1000 | Loss: 0.00002542
Iteration 27/1000 | Loss: 0.00002542
Iteration 28/1000 | Loss: 0.00002542
Iteration 29/1000 | Loss: 0.00002542
Iteration 30/1000 | Loss: 0.00002542
Iteration 31/1000 | Loss: 0.00002540
Iteration 32/1000 | Loss: 0.00002540
Iteration 33/1000 | Loss: 0.00002539
Iteration 34/1000 | Loss: 0.00002539
Iteration 35/1000 | Loss: 0.00002539
Iteration 36/1000 | Loss: 0.00002538
Iteration 37/1000 | Loss: 0.00002538
Iteration 38/1000 | Loss: 0.00002538
Iteration 39/1000 | Loss: 0.00002538
Iteration 40/1000 | Loss: 0.00002537
Iteration 41/1000 | Loss: 0.00002537
Iteration 42/1000 | Loss: 0.00002537
Iteration 43/1000 | Loss: 0.00002536
Iteration 44/1000 | Loss: 0.00002536
Iteration 45/1000 | Loss: 0.00002536
Iteration 46/1000 | Loss: 0.00002535
Iteration 47/1000 | Loss: 0.00002535
Iteration 48/1000 | Loss: 0.00002535
Iteration 49/1000 | Loss: 0.00002534
Iteration 50/1000 | Loss: 0.00002533
Iteration 51/1000 | Loss: 0.00002533
Iteration 52/1000 | Loss: 0.00002533
Iteration 53/1000 | Loss: 0.00002532
Iteration 54/1000 | Loss: 0.00002532
Iteration 55/1000 | Loss: 0.00002532
Iteration 56/1000 | Loss: 0.00002532
Iteration 57/1000 | Loss: 0.00002532
Iteration 58/1000 | Loss: 0.00002532
Iteration 59/1000 | Loss: 0.00002532
Iteration 60/1000 | Loss: 0.00002531
Iteration 61/1000 | Loss: 0.00002531
Iteration 62/1000 | Loss: 0.00002531
Iteration 63/1000 | Loss: 0.00002531
Iteration 64/1000 | Loss: 0.00002531
Iteration 65/1000 | Loss: 0.00002530
Iteration 66/1000 | Loss: 0.00002530
Iteration 67/1000 | Loss: 0.00002530
Iteration 68/1000 | Loss: 0.00002530
Iteration 69/1000 | Loss: 0.00002530
Iteration 70/1000 | Loss: 0.00002530
Iteration 71/1000 | Loss: 0.00002530
Iteration 72/1000 | Loss: 0.00002529
Iteration 73/1000 | Loss: 0.00002529
Iteration 74/1000 | Loss: 0.00002529
Iteration 75/1000 | Loss: 0.00002529
Iteration 76/1000 | Loss: 0.00002528
Iteration 77/1000 | Loss: 0.00002528
Iteration 78/1000 | Loss: 0.00002528
Iteration 79/1000 | Loss: 0.00002528
Iteration 80/1000 | Loss: 0.00002528
Iteration 81/1000 | Loss: 0.00002528
Iteration 82/1000 | Loss: 0.00002528
Iteration 83/1000 | Loss: 0.00002528
Iteration 84/1000 | Loss: 0.00002528
Iteration 85/1000 | Loss: 0.00002528
Iteration 86/1000 | Loss: 0.00002527
Iteration 87/1000 | Loss: 0.00002527
Iteration 88/1000 | Loss: 0.00002527
Iteration 89/1000 | Loss: 0.00002527
Iteration 90/1000 | Loss: 0.00002527
Iteration 91/1000 | Loss: 0.00002527
Iteration 92/1000 | Loss: 0.00002527
Iteration 93/1000 | Loss: 0.00002527
Iteration 94/1000 | Loss: 0.00002527
Iteration 95/1000 | Loss: 0.00002527
Iteration 96/1000 | Loss: 0.00002527
Iteration 97/1000 | Loss: 0.00002526
Iteration 98/1000 | Loss: 0.00002526
Iteration 99/1000 | Loss: 0.00002526
Iteration 100/1000 | Loss: 0.00002526
Iteration 101/1000 | Loss: 0.00002526
Iteration 102/1000 | Loss: 0.00002526
Iteration 103/1000 | Loss: 0.00002526
Iteration 104/1000 | Loss: 0.00002526
Iteration 105/1000 | Loss: 0.00002526
Iteration 106/1000 | Loss: 0.00002525
Iteration 107/1000 | Loss: 0.00002525
Iteration 108/1000 | Loss: 0.00002525
Iteration 109/1000 | Loss: 0.00002525
Iteration 110/1000 | Loss: 0.00002525
Iteration 111/1000 | Loss: 0.00002524
Iteration 112/1000 | Loss: 0.00002524
Iteration 113/1000 | Loss: 0.00002524
Iteration 114/1000 | Loss: 0.00002524
Iteration 115/1000 | Loss: 0.00002523
Iteration 116/1000 | Loss: 0.00002523
Iteration 117/1000 | Loss: 0.00002523
Iteration 118/1000 | Loss: 0.00002523
Iteration 119/1000 | Loss: 0.00002522
Iteration 120/1000 | Loss: 0.00002522
Iteration 121/1000 | Loss: 0.00002522
Iteration 122/1000 | Loss: 0.00002522
Iteration 123/1000 | Loss: 0.00002522
Iteration 124/1000 | Loss: 0.00002522
Iteration 125/1000 | Loss: 0.00002521
Iteration 126/1000 | Loss: 0.00002521
Iteration 127/1000 | Loss: 0.00002521
Iteration 128/1000 | Loss: 0.00002521
Iteration 129/1000 | Loss: 0.00002521
Iteration 130/1000 | Loss: 0.00002520
Iteration 131/1000 | Loss: 0.00002520
Iteration 132/1000 | Loss: 0.00002520
Iteration 133/1000 | Loss: 0.00002520
Iteration 134/1000 | Loss: 0.00002519
Iteration 135/1000 | Loss: 0.00002519
Iteration 136/1000 | Loss: 0.00002519
Iteration 137/1000 | Loss: 0.00002519
Iteration 138/1000 | Loss: 0.00002519
Iteration 139/1000 | Loss: 0.00002519
Iteration 140/1000 | Loss: 0.00002518
Iteration 141/1000 | Loss: 0.00002518
Iteration 142/1000 | Loss: 0.00002518
Iteration 143/1000 | Loss: 0.00002518
Iteration 144/1000 | Loss: 0.00002518
Iteration 145/1000 | Loss: 0.00002518
Iteration 146/1000 | Loss: 0.00002518
Iteration 147/1000 | Loss: 0.00002518
Iteration 148/1000 | Loss: 0.00002518
Iteration 149/1000 | Loss: 0.00002518
Iteration 150/1000 | Loss: 0.00002518
Iteration 151/1000 | Loss: 0.00002518
Iteration 152/1000 | Loss: 0.00002518
Iteration 153/1000 | Loss: 0.00002518
Iteration 154/1000 | Loss: 0.00002517
Iteration 155/1000 | Loss: 0.00002517
Iteration 156/1000 | Loss: 0.00002517
Iteration 157/1000 | Loss: 0.00002517
Iteration 158/1000 | Loss: 0.00002517
Iteration 159/1000 | Loss: 0.00002517
Iteration 160/1000 | Loss: 0.00002517
Iteration 161/1000 | Loss: 0.00002516
Iteration 162/1000 | Loss: 0.00002516
Iteration 163/1000 | Loss: 0.00002516
Iteration 164/1000 | Loss: 0.00002516
Iteration 165/1000 | Loss: 0.00002516
Iteration 166/1000 | Loss: 0.00002516
Iteration 167/1000 | Loss: 0.00002516
Iteration 168/1000 | Loss: 0.00002516
Iteration 169/1000 | Loss: 0.00002516
Iteration 170/1000 | Loss: 0.00002516
Iteration 171/1000 | Loss: 0.00002516
Iteration 172/1000 | Loss: 0.00002515
Iteration 173/1000 | Loss: 0.00002515
Iteration 174/1000 | Loss: 0.00002515
Iteration 175/1000 | Loss: 0.00002515
Iteration 176/1000 | Loss: 0.00002515
Iteration 177/1000 | Loss: 0.00002515
Iteration 178/1000 | Loss: 0.00002515
Iteration 179/1000 | Loss: 0.00002515
Iteration 180/1000 | Loss: 0.00002515
Iteration 181/1000 | Loss: 0.00002515
Iteration 182/1000 | Loss: 0.00002515
Iteration 183/1000 | Loss: 0.00002515
Iteration 184/1000 | Loss: 0.00002515
Iteration 185/1000 | Loss: 0.00002515
Iteration 186/1000 | Loss: 0.00002515
Iteration 187/1000 | Loss: 0.00002515
Iteration 188/1000 | Loss: 0.00002515
Iteration 189/1000 | Loss: 0.00002515
Iteration 190/1000 | Loss: 0.00002515
Iteration 191/1000 | Loss: 0.00002515
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 191. Stopping optimization.
Last 5 losses: [2.5154778995784e-05, 2.5154778995784e-05, 2.5154778995784e-05, 2.5154778995784e-05, 2.5154778995784e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.5154778995784e-05

Optimization complete. Final v2v error: 4.178415775299072 mm

Highest mean error: 5.400728702545166 mm for frame 91

Lowest mean error: 3.4254767894744873 mm for frame 9

Saving results

Total time: 49.75072526931763
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01002867
Iteration 2/25 | Loss: 0.00265183
Iteration 3/25 | Loss: 0.00323744
Iteration 4/25 | Loss: 0.00123993
Iteration 5/25 | Loss: 0.00108071
Iteration 6/25 | Loss: 0.00106912
Iteration 7/25 | Loss: 0.00106595
Iteration 8/25 | Loss: 0.00106510
Iteration 9/25 | Loss: 0.00106478
Iteration 10/25 | Loss: 0.00106463
Iteration 11/25 | Loss: 0.00106460
Iteration 12/25 | Loss: 0.00106460
Iteration 13/25 | Loss: 0.00106460
Iteration 14/25 | Loss: 0.00106460
Iteration 15/25 | Loss: 0.00106460
Iteration 16/25 | Loss: 0.00106460
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010645956499502063, 0.0010645956499502063, 0.0010645956499502063, 0.0010645956499502063, 0.0010645956499502063]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010645956499502063

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.77000141
Iteration 2/25 | Loss: 0.00456891
Iteration 3/25 | Loss: 0.00456889
Iteration 4/25 | Loss: 0.00456889
Iteration 5/25 | Loss: 0.00456889
Iteration 6/25 | Loss: 0.00456889
Iteration 7/25 | Loss: 0.00456889
Iteration 8/25 | Loss: 0.00456889
Iteration 9/25 | Loss: 0.00456889
Iteration 10/25 | Loss: 0.00456889
Iteration 11/25 | Loss: 0.00456889
Iteration 12/25 | Loss: 0.00456889
Iteration 13/25 | Loss: 0.00456889
Iteration 14/25 | Loss: 0.00456889
Iteration 15/25 | Loss: 0.00456889
Iteration 16/25 | Loss: 0.00456889
Iteration 17/25 | Loss: 0.00456889
Iteration 18/25 | Loss: 0.00456889
Iteration 19/25 | Loss: 0.00456889
Iteration 20/25 | Loss: 0.00456889
Iteration 21/25 | Loss: 0.00456889
Iteration 22/25 | Loss: 0.00456889
Iteration 23/25 | Loss: 0.00456889
Iteration 24/25 | Loss: 0.00456889
Iteration 25/25 | Loss: 0.00456889

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00456889
Iteration 2/1000 | Loss: 0.00006079
Iteration 3/1000 | Loss: 0.00004306
Iteration 4/1000 | Loss: 0.00003545
Iteration 5/1000 | Loss: 0.00003338
Iteration 6/1000 | Loss: 0.00003189
Iteration 7/1000 | Loss: 0.00003089
Iteration 8/1000 | Loss: 0.00003006
Iteration 9/1000 | Loss: 0.00002947
Iteration 10/1000 | Loss: 0.00002884
Iteration 11/1000 | Loss: 0.00002850
Iteration 12/1000 | Loss: 0.00002826
Iteration 13/1000 | Loss: 0.00002804
Iteration 14/1000 | Loss: 0.00002785
Iteration 15/1000 | Loss: 0.00002769
Iteration 16/1000 | Loss: 0.00002761
Iteration 17/1000 | Loss: 0.00002756
Iteration 18/1000 | Loss: 0.00002754
Iteration 19/1000 | Loss: 0.00002753
Iteration 20/1000 | Loss: 0.00002752
Iteration 21/1000 | Loss: 0.00002752
Iteration 22/1000 | Loss: 0.00002751
Iteration 23/1000 | Loss: 0.00002750
Iteration 24/1000 | Loss: 0.00002747
Iteration 25/1000 | Loss: 0.00002746
Iteration 26/1000 | Loss: 0.00002746
Iteration 27/1000 | Loss: 0.00002745
Iteration 28/1000 | Loss: 0.00002745
Iteration 29/1000 | Loss: 0.00002745
Iteration 30/1000 | Loss: 0.00002744
Iteration 31/1000 | Loss: 0.00002744
Iteration 32/1000 | Loss: 0.00002743
Iteration 33/1000 | Loss: 0.00002742
Iteration 34/1000 | Loss: 0.00002741
Iteration 35/1000 | Loss: 0.00002740
Iteration 36/1000 | Loss: 0.00002737
Iteration 37/1000 | Loss: 0.00002737
Iteration 38/1000 | Loss: 0.00002733
Iteration 39/1000 | Loss: 0.00002733
Iteration 40/1000 | Loss: 0.00002732
Iteration 41/1000 | Loss: 0.00002732
Iteration 42/1000 | Loss: 0.00002731
Iteration 43/1000 | Loss: 0.00002731
Iteration 44/1000 | Loss: 0.00002730
Iteration 45/1000 | Loss: 0.00002730
Iteration 46/1000 | Loss: 0.00002729
Iteration 47/1000 | Loss: 0.00002729
Iteration 48/1000 | Loss: 0.00002729
Iteration 49/1000 | Loss: 0.00002728
Iteration 50/1000 | Loss: 0.00002728
Iteration 51/1000 | Loss: 0.00002727
Iteration 52/1000 | Loss: 0.00002727
Iteration 53/1000 | Loss: 0.00002727
Iteration 54/1000 | Loss: 0.00002727
Iteration 55/1000 | Loss: 0.00002726
Iteration 56/1000 | Loss: 0.00002726
Iteration 57/1000 | Loss: 0.00002725
Iteration 58/1000 | Loss: 0.00002725
Iteration 59/1000 | Loss: 0.00002725
Iteration 60/1000 | Loss: 0.00002725
Iteration 61/1000 | Loss: 0.00002724
Iteration 62/1000 | Loss: 0.00002724
Iteration 63/1000 | Loss: 0.00002723
Iteration 64/1000 | Loss: 0.00002722
Iteration 65/1000 | Loss: 0.00002722
Iteration 66/1000 | Loss: 0.00002722
Iteration 67/1000 | Loss: 0.00002721
Iteration 68/1000 | Loss: 0.00002721
Iteration 69/1000 | Loss: 0.00002721
Iteration 70/1000 | Loss: 0.00002720
Iteration 71/1000 | Loss: 0.00002720
Iteration 72/1000 | Loss: 0.00002720
Iteration 73/1000 | Loss: 0.00002720
Iteration 74/1000 | Loss: 0.00002720
Iteration 75/1000 | Loss: 0.00002720
Iteration 76/1000 | Loss: 0.00002720
Iteration 77/1000 | Loss: 0.00002720
Iteration 78/1000 | Loss: 0.00002719
Iteration 79/1000 | Loss: 0.00002719
Iteration 80/1000 | Loss: 0.00002719
Iteration 81/1000 | Loss: 0.00002719
Iteration 82/1000 | Loss: 0.00002718
Iteration 83/1000 | Loss: 0.00002718
Iteration 84/1000 | Loss: 0.00002718
Iteration 85/1000 | Loss: 0.00002718
Iteration 86/1000 | Loss: 0.00002717
Iteration 87/1000 | Loss: 0.00002717
Iteration 88/1000 | Loss: 0.00002717
Iteration 89/1000 | Loss: 0.00002717
Iteration 90/1000 | Loss: 0.00002717
Iteration 91/1000 | Loss: 0.00002717
Iteration 92/1000 | Loss: 0.00002716
Iteration 93/1000 | Loss: 0.00002716
Iteration 94/1000 | Loss: 0.00002716
Iteration 95/1000 | Loss: 0.00002716
Iteration 96/1000 | Loss: 0.00002716
Iteration 97/1000 | Loss: 0.00002716
Iteration 98/1000 | Loss: 0.00002716
Iteration 99/1000 | Loss: 0.00002716
Iteration 100/1000 | Loss: 0.00002716
Iteration 101/1000 | Loss: 0.00002716
Iteration 102/1000 | Loss: 0.00002716
Iteration 103/1000 | Loss: 0.00002716
Iteration 104/1000 | Loss: 0.00002716
Iteration 105/1000 | Loss: 0.00002715
Iteration 106/1000 | Loss: 0.00002715
Iteration 107/1000 | Loss: 0.00002715
Iteration 108/1000 | Loss: 0.00002715
Iteration 109/1000 | Loss: 0.00002715
Iteration 110/1000 | Loss: 0.00002714
Iteration 111/1000 | Loss: 0.00002714
Iteration 112/1000 | Loss: 0.00002714
Iteration 113/1000 | Loss: 0.00002714
Iteration 114/1000 | Loss: 0.00002714
Iteration 115/1000 | Loss: 0.00002714
Iteration 116/1000 | Loss: 0.00002714
Iteration 117/1000 | Loss: 0.00002714
Iteration 118/1000 | Loss: 0.00002714
Iteration 119/1000 | Loss: 0.00002714
Iteration 120/1000 | Loss: 0.00002714
Iteration 121/1000 | Loss: 0.00002714
Iteration 122/1000 | Loss: 0.00002714
Iteration 123/1000 | Loss: 0.00002714
Iteration 124/1000 | Loss: 0.00002714
Iteration 125/1000 | Loss: 0.00002714
Iteration 126/1000 | Loss: 0.00002714
Iteration 127/1000 | Loss: 0.00002714
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 127. Stopping optimization.
Last 5 losses: [2.714009679039009e-05, 2.714009679039009e-05, 2.714009679039009e-05, 2.714009679039009e-05, 2.714009679039009e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.714009679039009e-05

Optimization complete. Final v2v error: 4.193638801574707 mm

Highest mean error: 6.904212474822998 mm for frame 91

Lowest mean error: 3.3296892642974854 mm for frame 8

Saving results

Total time: 49.40328764915466
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00467725
Iteration 2/25 | Loss: 0.00120295
Iteration 3/25 | Loss: 0.00104833
Iteration 4/25 | Loss: 0.00102256
Iteration 5/25 | Loss: 0.00101537
Iteration 6/25 | Loss: 0.00101426
Iteration 7/25 | Loss: 0.00101412
Iteration 8/25 | Loss: 0.00101412
Iteration 9/25 | Loss: 0.00101412
Iteration 10/25 | Loss: 0.00101412
Iteration 11/25 | Loss: 0.00101412
Iteration 12/25 | Loss: 0.00101412
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010141178499907255, 0.0010141178499907255, 0.0010141178499907255, 0.0010141178499907255, 0.0010141178499907255]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010141178499907255

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.74932611
Iteration 2/25 | Loss: 0.00505854
Iteration 3/25 | Loss: 0.00505853
Iteration 4/25 | Loss: 0.00505853
Iteration 5/25 | Loss: 0.00505853
Iteration 6/25 | Loss: 0.00505853
Iteration 7/25 | Loss: 0.00505853
Iteration 8/25 | Loss: 0.00505853
Iteration 9/25 | Loss: 0.00505853
Iteration 10/25 | Loss: 0.00505853
Iteration 11/25 | Loss: 0.00505853
Iteration 12/25 | Loss: 0.00505853
Iteration 13/25 | Loss: 0.00505853
Iteration 14/25 | Loss: 0.00505853
Iteration 15/25 | Loss: 0.00505853
Iteration 16/25 | Loss: 0.00505853
Iteration 17/25 | Loss: 0.00505853
Iteration 18/25 | Loss: 0.00505853
Iteration 19/25 | Loss: 0.00505853
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.005058532115072012, 0.005058532115072012, 0.005058532115072012, 0.005058532115072012, 0.005058532115072012]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005058532115072012

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00505853
Iteration 2/1000 | Loss: 0.00005320
Iteration 3/1000 | Loss: 0.00003447
Iteration 4/1000 | Loss: 0.00002969
Iteration 5/1000 | Loss: 0.00002783
Iteration 6/1000 | Loss: 0.00002686
Iteration 7/1000 | Loss: 0.00002604
Iteration 8/1000 | Loss: 0.00002550
Iteration 9/1000 | Loss: 0.00002504
Iteration 10/1000 | Loss: 0.00002469
Iteration 11/1000 | Loss: 0.00002447
Iteration 12/1000 | Loss: 0.00002426
Iteration 13/1000 | Loss: 0.00002421
Iteration 14/1000 | Loss: 0.00002416
Iteration 15/1000 | Loss: 0.00002407
Iteration 16/1000 | Loss: 0.00002403
Iteration 17/1000 | Loss: 0.00002401
Iteration 18/1000 | Loss: 0.00002400
Iteration 19/1000 | Loss: 0.00002397
Iteration 20/1000 | Loss: 0.00002396
Iteration 21/1000 | Loss: 0.00002395
Iteration 22/1000 | Loss: 0.00002395
Iteration 23/1000 | Loss: 0.00002395
Iteration 24/1000 | Loss: 0.00002394
Iteration 25/1000 | Loss: 0.00002394
Iteration 26/1000 | Loss: 0.00002393
Iteration 27/1000 | Loss: 0.00002393
Iteration 28/1000 | Loss: 0.00002392
Iteration 29/1000 | Loss: 0.00002391
Iteration 30/1000 | Loss: 0.00002391
Iteration 31/1000 | Loss: 0.00002391
Iteration 32/1000 | Loss: 0.00002390
Iteration 33/1000 | Loss: 0.00002389
Iteration 34/1000 | Loss: 0.00002388
Iteration 35/1000 | Loss: 0.00002388
Iteration 36/1000 | Loss: 0.00002387
Iteration 37/1000 | Loss: 0.00002386
Iteration 38/1000 | Loss: 0.00002386
Iteration 39/1000 | Loss: 0.00002385
Iteration 40/1000 | Loss: 0.00002385
Iteration 41/1000 | Loss: 0.00002385
Iteration 42/1000 | Loss: 0.00002385
Iteration 43/1000 | Loss: 0.00002385
Iteration 44/1000 | Loss: 0.00002384
Iteration 45/1000 | Loss: 0.00002384
Iteration 46/1000 | Loss: 0.00002384
Iteration 47/1000 | Loss: 0.00002383
Iteration 48/1000 | Loss: 0.00002383
Iteration 49/1000 | Loss: 0.00002383
Iteration 50/1000 | Loss: 0.00002382
Iteration 51/1000 | Loss: 0.00002382
Iteration 52/1000 | Loss: 0.00002382
Iteration 53/1000 | Loss: 0.00002382
Iteration 54/1000 | Loss: 0.00002381
Iteration 55/1000 | Loss: 0.00002381
Iteration 56/1000 | Loss: 0.00002381
Iteration 57/1000 | Loss: 0.00002381
Iteration 58/1000 | Loss: 0.00002381
Iteration 59/1000 | Loss: 0.00002381
Iteration 60/1000 | Loss: 0.00002381
Iteration 61/1000 | Loss: 0.00002381
Iteration 62/1000 | Loss: 0.00002380
Iteration 63/1000 | Loss: 0.00002380
Iteration 64/1000 | Loss: 0.00002380
Iteration 65/1000 | Loss: 0.00002380
Iteration 66/1000 | Loss: 0.00002380
Iteration 67/1000 | Loss: 0.00002380
Iteration 68/1000 | Loss: 0.00002380
Iteration 69/1000 | Loss: 0.00002380
Iteration 70/1000 | Loss: 0.00002380
Iteration 71/1000 | Loss: 0.00002380
Iteration 72/1000 | Loss: 0.00002380
Iteration 73/1000 | Loss: 0.00002380
Iteration 74/1000 | Loss: 0.00002379
Iteration 75/1000 | Loss: 0.00002379
Iteration 76/1000 | Loss: 0.00002379
Iteration 77/1000 | Loss: 0.00002379
Iteration 78/1000 | Loss: 0.00002379
Iteration 79/1000 | Loss: 0.00002379
Iteration 80/1000 | Loss: 0.00002379
Iteration 81/1000 | Loss: 0.00002379
Iteration 82/1000 | Loss: 0.00002379
Iteration 83/1000 | Loss: 0.00002379
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 83. Stopping optimization.
Last 5 losses: [2.3792643332853913e-05, 2.3792643332853913e-05, 2.3792643332853913e-05, 2.3792643332853913e-05, 2.3792643332853913e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3792643332853913e-05

Optimization complete. Final v2v error: 4.033313274383545 mm

Highest mean error: 4.494912147521973 mm for frame 101

Lowest mean error: 3.738892078399658 mm for frame 111

Saving results

Total time: 33.78414535522461
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01124541
Iteration 2/25 | Loss: 0.00263763
Iteration 3/25 | Loss: 0.00225917
Iteration 4/25 | Loss: 0.00198876
Iteration 5/25 | Loss: 0.00195728
Iteration 6/25 | Loss: 0.00172684
Iteration 7/25 | Loss: 0.00152830
Iteration 8/25 | Loss: 0.00140802
Iteration 9/25 | Loss: 0.00130755
Iteration 10/25 | Loss: 0.00122503
Iteration 11/25 | Loss: 0.00118482
Iteration 12/25 | Loss: 0.00115408
Iteration 13/25 | Loss: 0.00112101
Iteration 14/25 | Loss: 0.00110126
Iteration 15/25 | Loss: 0.00110159
Iteration 16/25 | Loss: 0.00110663
Iteration 17/25 | Loss: 0.00109637
Iteration 18/25 | Loss: 0.00109086
Iteration 19/25 | Loss: 0.00109004
Iteration 20/25 | Loss: 0.00108990
Iteration 21/25 | Loss: 0.00108987
Iteration 22/25 | Loss: 0.00108987
Iteration 23/25 | Loss: 0.00108987
Iteration 24/25 | Loss: 0.00108987
Iteration 25/25 | Loss: 0.00108987

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.87155688
Iteration 2/25 | Loss: 0.00447159
Iteration 3/25 | Loss: 0.00447158
Iteration 4/25 | Loss: 0.00447158
Iteration 5/25 | Loss: 0.00447158
Iteration 6/25 | Loss: 0.00447157
Iteration 7/25 | Loss: 0.00447158
Iteration 8/25 | Loss: 0.00447158
Iteration 9/25 | Loss: 0.00447157
Iteration 10/25 | Loss: 0.00447157
Iteration 11/25 | Loss: 0.00447157
Iteration 12/25 | Loss: 0.00447157
Iteration 13/25 | Loss: 0.00447157
Iteration 14/25 | Loss: 0.00447157
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0044715749099850655, 0.0044715749099850655, 0.0044715749099850655, 0.0044715749099850655, 0.0044715749099850655]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0044715749099850655

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00447157
Iteration 2/1000 | Loss: 0.00006277
Iteration 3/1000 | Loss: 0.00004834
Iteration 4/1000 | Loss: 0.00004289
Iteration 5/1000 | Loss: 0.00003910
Iteration 6/1000 | Loss: 0.00003664
Iteration 7/1000 | Loss: 0.00003469
Iteration 8/1000 | Loss: 0.00003347
Iteration 9/1000 | Loss: 0.00003213
Iteration 10/1000 | Loss: 0.00003098
Iteration 11/1000 | Loss: 0.00002982
Iteration 12/1000 | Loss: 0.00035510
Iteration 13/1000 | Loss: 0.00042648
Iteration 14/1000 | Loss: 0.00004213
Iteration 15/1000 | Loss: 0.00003430
Iteration 16/1000 | Loss: 0.00002998
Iteration 17/1000 | Loss: 0.00002521
Iteration 18/1000 | Loss: 0.00002330
Iteration 19/1000 | Loss: 0.00002226
Iteration 20/1000 | Loss: 0.00002188
Iteration 21/1000 | Loss: 0.00002146
Iteration 22/1000 | Loss: 0.00002116
Iteration 23/1000 | Loss: 0.00002096
Iteration 24/1000 | Loss: 0.00002091
Iteration 25/1000 | Loss: 0.00002083
Iteration 26/1000 | Loss: 0.00002080
Iteration 27/1000 | Loss: 0.00002080
Iteration 28/1000 | Loss: 0.00002080
Iteration 29/1000 | Loss: 0.00002080
Iteration 30/1000 | Loss: 0.00002079
Iteration 31/1000 | Loss: 0.00002079
Iteration 32/1000 | Loss: 0.00002079
Iteration 33/1000 | Loss: 0.00002079
Iteration 34/1000 | Loss: 0.00002079
Iteration 35/1000 | Loss: 0.00002079
Iteration 36/1000 | Loss: 0.00002079
Iteration 37/1000 | Loss: 0.00002079
Iteration 38/1000 | Loss: 0.00002076
Iteration 39/1000 | Loss: 0.00002076
Iteration 40/1000 | Loss: 0.00002074
Iteration 41/1000 | Loss: 0.00002074
Iteration 42/1000 | Loss: 0.00002074
Iteration 43/1000 | Loss: 0.00002074
Iteration 44/1000 | Loss: 0.00002074
Iteration 45/1000 | Loss: 0.00002073
Iteration 46/1000 | Loss: 0.00002073
Iteration 47/1000 | Loss: 0.00002073
Iteration 48/1000 | Loss: 0.00002072
Iteration 49/1000 | Loss: 0.00002071
Iteration 50/1000 | Loss: 0.00002070
Iteration 51/1000 | Loss: 0.00002070
Iteration 52/1000 | Loss: 0.00002066
Iteration 53/1000 | Loss: 0.00002064
Iteration 54/1000 | Loss: 0.00002064
Iteration 55/1000 | Loss: 0.00002064
Iteration 56/1000 | Loss: 0.00002063
Iteration 57/1000 | Loss: 0.00002063
Iteration 58/1000 | Loss: 0.00002063
Iteration 59/1000 | Loss: 0.00002062
Iteration 60/1000 | Loss: 0.00002062
Iteration 61/1000 | Loss: 0.00002061
Iteration 62/1000 | Loss: 0.00002061
Iteration 63/1000 | Loss: 0.00002061
Iteration 64/1000 | Loss: 0.00002061
Iteration 65/1000 | Loss: 0.00002060
Iteration 66/1000 | Loss: 0.00002060
Iteration 67/1000 | Loss: 0.00002060
Iteration 68/1000 | Loss: 0.00002060
Iteration 69/1000 | Loss: 0.00002060
Iteration 70/1000 | Loss: 0.00002060
Iteration 71/1000 | Loss: 0.00002060
Iteration 72/1000 | Loss: 0.00002060
Iteration 73/1000 | Loss: 0.00002060
Iteration 74/1000 | Loss: 0.00002060
Iteration 75/1000 | Loss: 0.00002060
Iteration 76/1000 | Loss: 0.00002060
Iteration 77/1000 | Loss: 0.00002060
Iteration 78/1000 | Loss: 0.00002059
Iteration 79/1000 | Loss: 0.00002059
Iteration 80/1000 | Loss: 0.00002059
Iteration 81/1000 | Loss: 0.00002059
Iteration 82/1000 | Loss: 0.00002059
Iteration 83/1000 | Loss: 0.00002059
Iteration 84/1000 | Loss: 0.00002059
Iteration 85/1000 | Loss: 0.00002059
Iteration 86/1000 | Loss: 0.00002059
Iteration 87/1000 | Loss: 0.00002059
Iteration 88/1000 | Loss: 0.00002058
Iteration 89/1000 | Loss: 0.00002058
Iteration 90/1000 | Loss: 0.00002058
Iteration 91/1000 | Loss: 0.00002058
Iteration 92/1000 | Loss: 0.00002058
Iteration 93/1000 | Loss: 0.00002058
Iteration 94/1000 | Loss: 0.00002058
Iteration 95/1000 | Loss: 0.00002058
Iteration 96/1000 | Loss: 0.00002058
Iteration 97/1000 | Loss: 0.00002058
Iteration 98/1000 | Loss: 0.00002058
Iteration 99/1000 | Loss: 0.00002058
Iteration 100/1000 | Loss: 0.00002058
Iteration 101/1000 | Loss: 0.00002058
Iteration 102/1000 | Loss: 0.00002058
Iteration 103/1000 | Loss: 0.00002058
Iteration 104/1000 | Loss: 0.00002058
Iteration 105/1000 | Loss: 0.00002057
Iteration 106/1000 | Loss: 0.00002057
Iteration 107/1000 | Loss: 0.00002057
Iteration 108/1000 | Loss: 0.00002057
Iteration 109/1000 | Loss: 0.00002057
Iteration 110/1000 | Loss: 0.00002057
Iteration 111/1000 | Loss: 0.00002057
Iteration 112/1000 | Loss: 0.00002057
Iteration 113/1000 | Loss: 0.00002057
Iteration 114/1000 | Loss: 0.00002057
Iteration 115/1000 | Loss: 0.00002057
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 115. Stopping optimization.
Last 5 losses: [2.0574250811478123e-05, 2.0574250811478123e-05, 2.0574250811478123e-05, 2.0574250811478123e-05, 2.0574250811478123e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0574250811478123e-05

Optimization complete. Final v2v error: 3.8750696182250977 mm

Highest mean error: 4.098060131072998 mm for frame 176

Lowest mean error: 3.703505516052246 mm for frame 12

Saving results

Total time: 78.20487141609192
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01018846
Iteration 2/25 | Loss: 0.00165722
Iteration 3/25 | Loss: 0.00136776
Iteration 4/25 | Loss: 0.00130864
Iteration 5/25 | Loss: 0.00128774
Iteration 6/25 | Loss: 0.00128743
Iteration 7/25 | Loss: 0.00127731
Iteration 8/25 | Loss: 0.00127588
Iteration 9/25 | Loss: 0.00126095
Iteration 10/25 | Loss: 0.00125767
Iteration 11/25 | Loss: 0.00125206
Iteration 12/25 | Loss: 0.00125068
Iteration 13/25 | Loss: 0.00125229
Iteration 14/25 | Loss: 0.00125302
Iteration 15/25 | Loss: 0.00124854
Iteration 16/25 | Loss: 0.00124954
Iteration 17/25 | Loss: 0.00125029
Iteration 18/25 | Loss: 0.00124261
Iteration 19/25 | Loss: 0.00124002
Iteration 20/25 | Loss: 0.00123920
Iteration 21/25 | Loss: 0.00123903
Iteration 22/25 | Loss: 0.00123886
Iteration 23/25 | Loss: 0.00123868
Iteration 24/25 | Loss: 0.00123845
Iteration 25/25 | Loss: 0.00123803

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.74462342
Iteration 2/25 | Loss: 0.00538026
Iteration 3/25 | Loss: 0.00538026
Iteration 4/25 | Loss: 0.00538026
Iteration 5/25 | Loss: 0.00538026
Iteration 6/25 | Loss: 0.00538026
Iteration 7/25 | Loss: 0.00538026
Iteration 8/25 | Loss: 0.00538026
Iteration 9/25 | Loss: 0.00538026
Iteration 10/25 | Loss: 0.00538026
Iteration 11/25 | Loss: 0.00538026
Iteration 12/25 | Loss: 0.00538026
Iteration 13/25 | Loss: 0.00538026
Iteration 14/25 | Loss: 0.00538026
Iteration 15/25 | Loss: 0.00538026
Iteration 16/25 | Loss: 0.00538026
Iteration 17/25 | Loss: 0.00538026
Iteration 18/25 | Loss: 0.00538026
Iteration 19/25 | Loss: 0.00538026
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00538025563582778, 0.00538025563582778, 0.00538025563582778, 0.00538025563582778, 0.00538025563582778]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00538025563582778

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00538026
Iteration 2/1000 | Loss: 0.00033647
Iteration 3/1000 | Loss: 0.00039056
Iteration 4/1000 | Loss: 0.00057509
Iteration 5/1000 | Loss: 0.00029161
Iteration 6/1000 | Loss: 0.00029481
Iteration 7/1000 | Loss: 0.00046915
Iteration 8/1000 | Loss: 0.00027533
Iteration 9/1000 | Loss: 0.00023664
Iteration 10/1000 | Loss: 0.00079949
Iteration 11/1000 | Loss: 0.00037838
Iteration 12/1000 | Loss: 0.00019814
Iteration 13/1000 | Loss: 0.00089025
Iteration 14/1000 | Loss: 0.00029294
Iteration 15/1000 | Loss: 0.00030320
Iteration 16/1000 | Loss: 0.00017068
Iteration 17/1000 | Loss: 0.00017651
Iteration 18/1000 | Loss: 0.00104898
Iteration 19/1000 | Loss: 0.00011661
Iteration 20/1000 | Loss: 0.00008922
Iteration 21/1000 | Loss: 0.00007730
Iteration 22/1000 | Loss: 0.00030185
Iteration 23/1000 | Loss: 0.00021543
Iteration 24/1000 | Loss: 0.00026336
Iteration 25/1000 | Loss: 0.00022513
Iteration 26/1000 | Loss: 0.00021395
Iteration 27/1000 | Loss: 0.00010396
Iteration 28/1000 | Loss: 0.00007037
Iteration 29/1000 | Loss: 0.00006621
Iteration 30/1000 | Loss: 0.00119618
Iteration 31/1000 | Loss: 0.00583185
Iteration 32/1000 | Loss: 0.00046545
Iteration 33/1000 | Loss: 0.00025454
Iteration 34/1000 | Loss: 0.00016323
Iteration 35/1000 | Loss: 0.00015278
Iteration 36/1000 | Loss: 0.00014042
Iteration 37/1000 | Loss: 0.00010519
Iteration 38/1000 | Loss: 0.00006397
Iteration 39/1000 | Loss: 0.00005350
Iteration 40/1000 | Loss: 0.00004509
Iteration 41/1000 | Loss: 0.00003983
Iteration 42/1000 | Loss: 0.00013705
Iteration 43/1000 | Loss: 0.00010155
Iteration 44/1000 | Loss: 0.00008463
Iteration 45/1000 | Loss: 0.00003717
Iteration 46/1000 | Loss: 0.00003493
Iteration 47/1000 | Loss: 0.00003395
Iteration 48/1000 | Loss: 0.00003322
Iteration 49/1000 | Loss: 0.00003248
Iteration 50/1000 | Loss: 0.00003203
Iteration 51/1000 | Loss: 0.00003155
Iteration 52/1000 | Loss: 0.00003104
Iteration 53/1000 | Loss: 0.00003076
Iteration 54/1000 | Loss: 0.00003057
Iteration 55/1000 | Loss: 0.00003031
Iteration 56/1000 | Loss: 0.00003017
Iteration 57/1000 | Loss: 0.00003015
Iteration 58/1000 | Loss: 0.00003014
Iteration 59/1000 | Loss: 0.00003014
Iteration 60/1000 | Loss: 0.00003013
Iteration 61/1000 | Loss: 0.00003013
Iteration 62/1000 | Loss: 0.00003013
Iteration 63/1000 | Loss: 0.00003008
Iteration 64/1000 | Loss: 0.00003006
Iteration 65/1000 | Loss: 0.00003006
Iteration 66/1000 | Loss: 0.00003006
Iteration 67/1000 | Loss: 0.00003005
Iteration 68/1000 | Loss: 0.00003005
Iteration 69/1000 | Loss: 0.00003005
Iteration 70/1000 | Loss: 0.00003005
Iteration 71/1000 | Loss: 0.00003005
Iteration 72/1000 | Loss: 0.00003005
Iteration 73/1000 | Loss: 0.00003005
Iteration 74/1000 | Loss: 0.00003005
Iteration 75/1000 | Loss: 0.00003005
Iteration 76/1000 | Loss: 0.00003005
Iteration 77/1000 | Loss: 0.00003004
Iteration 78/1000 | Loss: 0.00003004
Iteration 79/1000 | Loss: 0.00003003
Iteration 80/1000 | Loss: 0.00003002
Iteration 81/1000 | Loss: 0.00003002
Iteration 82/1000 | Loss: 0.00003001
Iteration 83/1000 | Loss: 0.00003000
Iteration 84/1000 | Loss: 0.00003000
Iteration 85/1000 | Loss: 0.00003000
Iteration 86/1000 | Loss: 0.00002999
Iteration 87/1000 | Loss: 0.00002999
Iteration 88/1000 | Loss: 0.00002998
Iteration 89/1000 | Loss: 0.00002998
Iteration 90/1000 | Loss: 0.00002998
Iteration 91/1000 | Loss: 0.00002997
Iteration 92/1000 | Loss: 0.00002997
Iteration 93/1000 | Loss: 0.00002997
Iteration 94/1000 | Loss: 0.00002997
Iteration 95/1000 | Loss: 0.00002997
Iteration 96/1000 | Loss: 0.00002997
Iteration 97/1000 | Loss: 0.00002996
Iteration 98/1000 | Loss: 0.00002996
Iteration 99/1000 | Loss: 0.00002996
Iteration 100/1000 | Loss: 0.00002995
Iteration 101/1000 | Loss: 0.00002995
Iteration 102/1000 | Loss: 0.00002995
Iteration 103/1000 | Loss: 0.00002995
Iteration 104/1000 | Loss: 0.00002995
Iteration 105/1000 | Loss: 0.00002995
Iteration 106/1000 | Loss: 0.00002995
Iteration 107/1000 | Loss: 0.00002995
Iteration 108/1000 | Loss: 0.00002994
Iteration 109/1000 | Loss: 0.00002994
Iteration 110/1000 | Loss: 0.00002994
Iteration 111/1000 | Loss: 0.00002994
Iteration 112/1000 | Loss: 0.00002994
Iteration 113/1000 | Loss: 0.00002994
Iteration 114/1000 | Loss: 0.00002993
Iteration 115/1000 | Loss: 0.00002993
Iteration 116/1000 | Loss: 0.00002993
Iteration 117/1000 | Loss: 0.00002993
Iteration 118/1000 | Loss: 0.00002993
Iteration 119/1000 | Loss: 0.00002993
Iteration 120/1000 | Loss: 0.00002993
Iteration 121/1000 | Loss: 0.00002993
Iteration 122/1000 | Loss: 0.00002992
Iteration 123/1000 | Loss: 0.00002992
Iteration 124/1000 | Loss: 0.00002992
Iteration 125/1000 | Loss: 0.00002992
Iteration 126/1000 | Loss: 0.00002992
Iteration 127/1000 | Loss: 0.00002992
Iteration 128/1000 | Loss: 0.00002991
Iteration 129/1000 | Loss: 0.00002991
Iteration 130/1000 | Loss: 0.00002991
Iteration 131/1000 | Loss: 0.00002991
Iteration 132/1000 | Loss: 0.00002991
Iteration 133/1000 | Loss: 0.00002991
Iteration 134/1000 | Loss: 0.00002991
Iteration 135/1000 | Loss: 0.00002990
Iteration 136/1000 | Loss: 0.00002990
Iteration 137/1000 | Loss: 0.00002990
Iteration 138/1000 | Loss: 0.00002990
Iteration 139/1000 | Loss: 0.00002990
Iteration 140/1000 | Loss: 0.00002989
Iteration 141/1000 | Loss: 0.00002989
Iteration 142/1000 | Loss: 0.00002989
Iteration 143/1000 | Loss: 0.00002989
Iteration 144/1000 | Loss: 0.00002989
Iteration 145/1000 | Loss: 0.00002989
Iteration 146/1000 | Loss: 0.00002989
Iteration 147/1000 | Loss: 0.00002989
Iteration 148/1000 | Loss: 0.00002989
Iteration 149/1000 | Loss: 0.00002989
Iteration 150/1000 | Loss: 0.00002989
Iteration 151/1000 | Loss: 0.00002989
Iteration 152/1000 | Loss: 0.00002989
Iteration 153/1000 | Loss: 0.00002989
Iteration 154/1000 | Loss: 0.00002989
Iteration 155/1000 | Loss: 0.00002989
Iteration 156/1000 | Loss: 0.00002989
Iteration 157/1000 | Loss: 0.00002989
Iteration 158/1000 | Loss: 0.00002989
Iteration 159/1000 | Loss: 0.00002988
Iteration 160/1000 | Loss: 0.00002988
Iteration 161/1000 | Loss: 0.00002988
Iteration 162/1000 | Loss: 0.00002988
Iteration 163/1000 | Loss: 0.00002988
Iteration 164/1000 | Loss: 0.00002988
Iteration 165/1000 | Loss: 0.00002988
Iteration 166/1000 | Loss: 0.00002988
Iteration 167/1000 | Loss: 0.00002988
Iteration 168/1000 | Loss: 0.00002988
Iteration 169/1000 | Loss: 0.00002988
Iteration 170/1000 | Loss: 0.00002988
Iteration 171/1000 | Loss: 0.00002988
Iteration 172/1000 | Loss: 0.00002988
Iteration 173/1000 | Loss: 0.00002988
Iteration 174/1000 | Loss: 0.00002988
Iteration 175/1000 | Loss: 0.00002988
Iteration 176/1000 | Loss: 0.00002988
Iteration 177/1000 | Loss: 0.00002988
Iteration 178/1000 | Loss: 0.00002988
Iteration 179/1000 | Loss: 0.00002988
Iteration 180/1000 | Loss: 0.00002988
Iteration 181/1000 | Loss: 0.00002988
Iteration 182/1000 | Loss: 0.00002988
Iteration 183/1000 | Loss: 0.00002988
Iteration 184/1000 | Loss: 0.00002988
Iteration 185/1000 | Loss: 0.00002988
Iteration 186/1000 | Loss: 0.00002988
Iteration 187/1000 | Loss: 0.00002988
Iteration 188/1000 | Loss: 0.00002988
Iteration 189/1000 | Loss: 0.00002988
Iteration 190/1000 | Loss: 0.00002988
Iteration 191/1000 | Loss: 0.00002988
Iteration 192/1000 | Loss: 0.00002988
Iteration 193/1000 | Loss: 0.00002988
Iteration 194/1000 | Loss: 0.00002988
Iteration 195/1000 | Loss: 0.00002988
Iteration 196/1000 | Loss: 0.00002988
Iteration 197/1000 | Loss: 0.00002988
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 197. Stopping optimization.
Last 5 losses: [2.9881060982006602e-05, 2.9881060982006602e-05, 2.9881060982006602e-05, 2.9881060982006602e-05, 2.9881060982006602e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9881060982006602e-05

Optimization complete. Final v2v error: 4.566421985626221 mm

Highest mean error: 5.710321426391602 mm for frame 116

Lowest mean error: 3.9035744667053223 mm for frame 103

Saving results

Total time: 151.30875086784363
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01030899
Iteration 2/25 | Loss: 0.00183664
Iteration 3/25 | Loss: 0.00121749
Iteration 4/25 | Loss: 0.00117108
Iteration 5/25 | Loss: 0.00115398
Iteration 6/25 | Loss: 0.00114907
Iteration 7/25 | Loss: 0.00114845
Iteration 8/25 | Loss: 0.00114845
Iteration 9/25 | Loss: 0.00114845
Iteration 10/25 | Loss: 0.00114845
Iteration 11/25 | Loss: 0.00114845
Iteration 12/25 | Loss: 0.00114845
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011484476272016764, 0.0011484476272016764, 0.0011484476272016764, 0.0011484476272016764, 0.0011484476272016764]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011484476272016764

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.11156571
Iteration 2/25 | Loss: 0.00334802
Iteration 3/25 | Loss: 0.00334802
Iteration 4/25 | Loss: 0.00334801
Iteration 5/25 | Loss: 0.00334801
Iteration 6/25 | Loss: 0.00334801
Iteration 7/25 | Loss: 0.00334801
Iteration 8/25 | Loss: 0.00334801
Iteration 9/25 | Loss: 0.00334801
Iteration 10/25 | Loss: 0.00334801
Iteration 11/25 | Loss: 0.00334801
Iteration 12/25 | Loss: 0.00334801
Iteration 13/25 | Loss: 0.00334801
Iteration 14/25 | Loss: 0.00334801
Iteration 15/25 | Loss: 0.00334801
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.0033480129204690456, 0.0033480129204690456, 0.0033480129204690456, 0.0033480129204690456, 0.0033480129204690456]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0033480129204690456

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00334801
Iteration 2/1000 | Loss: 0.00006793
Iteration 3/1000 | Loss: 0.00005163
Iteration 4/1000 | Loss: 0.00004625
Iteration 5/1000 | Loss: 0.00004394
Iteration 6/1000 | Loss: 0.00004276
Iteration 7/1000 | Loss: 0.00004179
Iteration 8/1000 | Loss: 0.00004105
Iteration 9/1000 | Loss: 0.00004054
Iteration 10/1000 | Loss: 0.00004009
Iteration 11/1000 | Loss: 0.00003970
Iteration 12/1000 | Loss: 0.00003948
Iteration 13/1000 | Loss: 0.00003932
Iteration 14/1000 | Loss: 0.00003915
Iteration 15/1000 | Loss: 0.00003896
Iteration 16/1000 | Loss: 0.00003881
Iteration 17/1000 | Loss: 0.00003874
Iteration 18/1000 | Loss: 0.00003863
Iteration 19/1000 | Loss: 0.00003860
Iteration 20/1000 | Loss: 0.00003857
Iteration 21/1000 | Loss: 0.00003856
Iteration 22/1000 | Loss: 0.00003856
Iteration 23/1000 | Loss: 0.00003856
Iteration 24/1000 | Loss: 0.00003855
Iteration 25/1000 | Loss: 0.00003855
Iteration 26/1000 | Loss: 0.00003854
Iteration 27/1000 | Loss: 0.00003854
Iteration 28/1000 | Loss: 0.00003854
Iteration 29/1000 | Loss: 0.00003854
Iteration 30/1000 | Loss: 0.00003853
Iteration 31/1000 | Loss: 0.00003850
Iteration 32/1000 | Loss: 0.00003850
Iteration 33/1000 | Loss: 0.00003850
Iteration 34/1000 | Loss: 0.00003850
Iteration 35/1000 | Loss: 0.00003849
Iteration 36/1000 | Loss: 0.00003849
Iteration 37/1000 | Loss: 0.00003849
Iteration 38/1000 | Loss: 0.00003849
Iteration 39/1000 | Loss: 0.00003848
Iteration 40/1000 | Loss: 0.00003846
Iteration 41/1000 | Loss: 0.00003843
Iteration 42/1000 | Loss: 0.00003843
Iteration 43/1000 | Loss: 0.00003842
Iteration 44/1000 | Loss: 0.00003840
Iteration 45/1000 | Loss: 0.00003840
Iteration 46/1000 | Loss: 0.00003840
Iteration 47/1000 | Loss: 0.00003840
Iteration 48/1000 | Loss: 0.00003840
Iteration 49/1000 | Loss: 0.00003840
Iteration 50/1000 | Loss: 0.00003840
Iteration 51/1000 | Loss: 0.00003840
Iteration 52/1000 | Loss: 0.00003840
Iteration 53/1000 | Loss: 0.00003839
Iteration 54/1000 | Loss: 0.00003839
Iteration 55/1000 | Loss: 0.00003839
Iteration 56/1000 | Loss: 0.00003839
Iteration 57/1000 | Loss: 0.00003838
Iteration 58/1000 | Loss: 0.00003837
Iteration 59/1000 | Loss: 0.00003837
Iteration 60/1000 | Loss: 0.00003837
Iteration 61/1000 | Loss: 0.00003837
Iteration 62/1000 | Loss: 0.00003837
Iteration 63/1000 | Loss: 0.00003836
Iteration 64/1000 | Loss: 0.00003836
Iteration 65/1000 | Loss: 0.00003836
Iteration 66/1000 | Loss: 0.00003836
Iteration 67/1000 | Loss: 0.00003836
Iteration 68/1000 | Loss: 0.00003836
Iteration 69/1000 | Loss: 0.00003836
Iteration 70/1000 | Loss: 0.00003836
Iteration 71/1000 | Loss: 0.00003836
Iteration 72/1000 | Loss: 0.00003836
Iteration 73/1000 | Loss: 0.00003836
Iteration 74/1000 | Loss: 0.00003836
Iteration 75/1000 | Loss: 0.00003834
Iteration 76/1000 | Loss: 0.00003834
Iteration 77/1000 | Loss: 0.00003833
Iteration 78/1000 | Loss: 0.00003833
Iteration 79/1000 | Loss: 0.00003833
Iteration 80/1000 | Loss: 0.00003832
Iteration 81/1000 | Loss: 0.00003832
Iteration 82/1000 | Loss: 0.00003831
Iteration 83/1000 | Loss: 0.00003831
Iteration 84/1000 | Loss: 0.00003831
Iteration 85/1000 | Loss: 0.00003830
Iteration 86/1000 | Loss: 0.00003830
Iteration 87/1000 | Loss: 0.00003830
Iteration 88/1000 | Loss: 0.00003829
Iteration 89/1000 | Loss: 0.00003829
Iteration 90/1000 | Loss: 0.00003829
Iteration 91/1000 | Loss: 0.00003828
Iteration 92/1000 | Loss: 0.00003828
Iteration 93/1000 | Loss: 0.00003828
Iteration 94/1000 | Loss: 0.00003828
Iteration 95/1000 | Loss: 0.00003828
Iteration 96/1000 | Loss: 0.00003828
Iteration 97/1000 | Loss: 0.00003828
Iteration 98/1000 | Loss: 0.00003828
Iteration 99/1000 | Loss: 0.00003828
Iteration 100/1000 | Loss: 0.00003828
Iteration 101/1000 | Loss: 0.00003827
Iteration 102/1000 | Loss: 0.00003827
Iteration 103/1000 | Loss: 0.00003827
Iteration 104/1000 | Loss: 0.00003827
Iteration 105/1000 | Loss: 0.00003827
Iteration 106/1000 | Loss: 0.00003827
Iteration 107/1000 | Loss: 0.00003827
Iteration 108/1000 | Loss: 0.00003827
Iteration 109/1000 | Loss: 0.00003827
Iteration 110/1000 | Loss: 0.00003827
Iteration 111/1000 | Loss: 0.00003827
Iteration 112/1000 | Loss: 0.00003827
Iteration 113/1000 | Loss: 0.00003827
Iteration 114/1000 | Loss: 0.00003826
Iteration 115/1000 | Loss: 0.00003826
Iteration 116/1000 | Loss: 0.00003826
Iteration 117/1000 | Loss: 0.00003826
Iteration 118/1000 | Loss: 0.00003826
Iteration 119/1000 | Loss: 0.00003826
Iteration 120/1000 | Loss: 0.00003825
Iteration 121/1000 | Loss: 0.00003825
Iteration 122/1000 | Loss: 0.00003825
Iteration 123/1000 | Loss: 0.00003825
Iteration 124/1000 | Loss: 0.00003825
Iteration 125/1000 | Loss: 0.00003825
Iteration 126/1000 | Loss: 0.00003825
Iteration 127/1000 | Loss: 0.00003825
Iteration 128/1000 | Loss: 0.00003825
Iteration 129/1000 | Loss: 0.00003825
Iteration 130/1000 | Loss: 0.00003824
Iteration 131/1000 | Loss: 0.00003824
Iteration 132/1000 | Loss: 0.00003824
Iteration 133/1000 | Loss: 0.00003824
Iteration 134/1000 | Loss: 0.00003824
Iteration 135/1000 | Loss: 0.00003824
Iteration 136/1000 | Loss: 0.00003824
Iteration 137/1000 | Loss: 0.00003823
Iteration 138/1000 | Loss: 0.00003823
Iteration 139/1000 | Loss: 0.00003823
Iteration 140/1000 | Loss: 0.00003823
Iteration 141/1000 | Loss: 0.00003823
Iteration 142/1000 | Loss: 0.00003823
Iteration 143/1000 | Loss: 0.00003823
Iteration 144/1000 | Loss: 0.00003823
Iteration 145/1000 | Loss: 0.00003823
Iteration 146/1000 | Loss: 0.00003823
Iteration 147/1000 | Loss: 0.00003822
Iteration 148/1000 | Loss: 0.00003822
Iteration 149/1000 | Loss: 0.00003822
Iteration 150/1000 | Loss: 0.00003822
Iteration 151/1000 | Loss: 0.00003822
Iteration 152/1000 | Loss: 0.00003822
Iteration 153/1000 | Loss: 0.00003822
Iteration 154/1000 | Loss: 0.00003822
Iteration 155/1000 | Loss: 0.00003822
Iteration 156/1000 | Loss: 0.00003822
Iteration 157/1000 | Loss: 0.00003822
Iteration 158/1000 | Loss: 0.00003822
Iteration 159/1000 | Loss: 0.00003821
Iteration 160/1000 | Loss: 0.00003821
Iteration 161/1000 | Loss: 0.00003821
Iteration 162/1000 | Loss: 0.00003821
Iteration 163/1000 | Loss: 0.00003821
Iteration 164/1000 | Loss: 0.00003821
Iteration 165/1000 | Loss: 0.00003821
Iteration 166/1000 | Loss: 0.00003820
Iteration 167/1000 | Loss: 0.00003820
Iteration 168/1000 | Loss: 0.00003820
Iteration 169/1000 | Loss: 0.00003820
Iteration 170/1000 | Loss: 0.00003819
Iteration 171/1000 | Loss: 0.00003819
Iteration 172/1000 | Loss: 0.00003819
Iteration 173/1000 | Loss: 0.00003819
Iteration 174/1000 | Loss: 0.00003819
Iteration 175/1000 | Loss: 0.00003819
Iteration 176/1000 | Loss: 0.00003819
Iteration 177/1000 | Loss: 0.00003819
Iteration 178/1000 | Loss: 0.00003819
Iteration 179/1000 | Loss: 0.00003818
Iteration 180/1000 | Loss: 0.00003818
Iteration 181/1000 | Loss: 0.00003818
Iteration 182/1000 | Loss: 0.00003818
Iteration 183/1000 | Loss: 0.00003818
Iteration 184/1000 | Loss: 0.00003818
Iteration 185/1000 | Loss: 0.00003818
Iteration 186/1000 | Loss: 0.00003818
Iteration 187/1000 | Loss: 0.00003818
Iteration 188/1000 | Loss: 0.00003817
Iteration 189/1000 | Loss: 0.00003817
Iteration 190/1000 | Loss: 0.00003817
Iteration 191/1000 | Loss: 0.00003817
Iteration 192/1000 | Loss: 0.00003817
Iteration 193/1000 | Loss: 0.00003816
Iteration 194/1000 | Loss: 0.00003816
Iteration 195/1000 | Loss: 0.00003816
Iteration 196/1000 | Loss: 0.00003816
Iteration 197/1000 | Loss: 0.00003816
Iteration 198/1000 | Loss: 0.00003815
Iteration 199/1000 | Loss: 0.00003815
Iteration 200/1000 | Loss: 0.00003815
Iteration 201/1000 | Loss: 0.00003815
Iteration 202/1000 | Loss: 0.00003815
Iteration 203/1000 | Loss: 0.00003815
Iteration 204/1000 | Loss: 0.00003815
Iteration 205/1000 | Loss: 0.00003815
Iteration 206/1000 | Loss: 0.00003815
Iteration 207/1000 | Loss: 0.00003815
Iteration 208/1000 | Loss: 0.00003815
Iteration 209/1000 | Loss: 0.00003815
Iteration 210/1000 | Loss: 0.00003815
Iteration 211/1000 | Loss: 0.00003815
Iteration 212/1000 | Loss: 0.00003815
Iteration 213/1000 | Loss: 0.00003815
Iteration 214/1000 | Loss: 0.00003815
Iteration 215/1000 | Loss: 0.00003815
Iteration 216/1000 | Loss: 0.00003815
Iteration 217/1000 | Loss: 0.00003815
Iteration 218/1000 | Loss: 0.00003815
Iteration 219/1000 | Loss: 0.00003815
Iteration 220/1000 | Loss: 0.00003815
Iteration 221/1000 | Loss: 0.00003815
Iteration 222/1000 | Loss: 0.00003815
Iteration 223/1000 | Loss: 0.00003815
Iteration 224/1000 | Loss: 0.00003815
Iteration 225/1000 | Loss: 0.00003815
Iteration 226/1000 | Loss: 0.00003815
Iteration 227/1000 | Loss: 0.00003815
Iteration 228/1000 | Loss: 0.00003815
Iteration 229/1000 | Loss: 0.00003815
Iteration 230/1000 | Loss: 0.00003815
Iteration 231/1000 | Loss: 0.00003815
Iteration 232/1000 | Loss: 0.00003815
Iteration 233/1000 | Loss: 0.00003815
Iteration 234/1000 | Loss: 0.00003815
Iteration 235/1000 | Loss: 0.00003815
Iteration 236/1000 | Loss: 0.00003815
Iteration 237/1000 | Loss: 0.00003815
Iteration 238/1000 | Loss: 0.00003815
Iteration 239/1000 | Loss: 0.00003815
Iteration 240/1000 | Loss: 0.00003815
Iteration 241/1000 | Loss: 0.00003815
Iteration 242/1000 | Loss: 0.00003815
Iteration 243/1000 | Loss: 0.00003815
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 243. Stopping optimization.
Last 5 losses: [3.815102172666229e-05, 3.815102172666229e-05, 3.815102172666229e-05, 3.815102172666229e-05, 3.815102172666229e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.815102172666229e-05

Optimization complete. Final v2v error: 5.007164001464844 mm

Highest mean error: 6.568130970001221 mm for frame 117

Lowest mean error: 3.8096346855163574 mm for frame 1

Saving results

Total time: 56.456807136535645
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00914173
Iteration 2/25 | Loss: 0.00121498
Iteration 3/25 | Loss: 0.00098619
Iteration 4/25 | Loss: 0.00095693
Iteration 5/25 | Loss: 0.00095282
Iteration 6/25 | Loss: 0.00095158
Iteration 7/25 | Loss: 0.00095158
Iteration 8/25 | Loss: 0.00095158
Iteration 9/25 | Loss: 0.00095158
Iteration 10/25 | Loss: 0.00095158
Iteration 11/25 | Loss: 0.00095158
Iteration 12/25 | Loss: 0.00095158
Iteration 13/25 | Loss: 0.00095158
Iteration 14/25 | Loss: 0.00095158
Iteration 15/25 | Loss: 0.00095158
Iteration 16/25 | Loss: 0.00095158
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0009515820420347154, 0.0009515820420347154, 0.0009515820420347154, 0.0009515820420347154, 0.0009515820420347154]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009515820420347154

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.86221087
Iteration 2/25 | Loss: 0.00508342
Iteration 3/25 | Loss: 0.00508342
Iteration 4/25 | Loss: 0.00508342
Iteration 5/25 | Loss: 0.00508342
Iteration 6/25 | Loss: 0.00508341
Iteration 7/25 | Loss: 0.00508341
Iteration 8/25 | Loss: 0.00508341
Iteration 9/25 | Loss: 0.00508341
Iteration 10/25 | Loss: 0.00508341
Iteration 11/25 | Loss: 0.00508341
Iteration 12/25 | Loss: 0.00508341
Iteration 13/25 | Loss: 0.00508341
Iteration 14/25 | Loss: 0.00508341
Iteration 15/25 | Loss: 0.00508341
Iteration 16/25 | Loss: 0.00508341
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.005083412863314152, 0.005083412863314152, 0.005083412863314152, 0.005083412863314152, 0.005083412863314152]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.005083412863314152

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00508341
Iteration 2/1000 | Loss: 0.00003469
Iteration 3/1000 | Loss: 0.00002390
Iteration 4/1000 | Loss: 0.00002081
Iteration 5/1000 | Loss: 0.00001971
Iteration 6/1000 | Loss: 0.00001873
Iteration 7/1000 | Loss: 0.00001802
Iteration 8/1000 | Loss: 0.00001765
Iteration 9/1000 | Loss: 0.00001735
Iteration 10/1000 | Loss: 0.00001716
Iteration 11/1000 | Loss: 0.00001715
Iteration 12/1000 | Loss: 0.00001711
Iteration 13/1000 | Loss: 0.00001702
Iteration 14/1000 | Loss: 0.00001702
Iteration 15/1000 | Loss: 0.00001702
Iteration 16/1000 | Loss: 0.00001702
Iteration 17/1000 | Loss: 0.00001699
Iteration 18/1000 | Loss: 0.00001699
Iteration 19/1000 | Loss: 0.00001697
Iteration 20/1000 | Loss: 0.00001689
Iteration 21/1000 | Loss: 0.00001687
Iteration 22/1000 | Loss: 0.00001686
Iteration 23/1000 | Loss: 0.00001686
Iteration 24/1000 | Loss: 0.00001685
Iteration 25/1000 | Loss: 0.00001685
Iteration 26/1000 | Loss: 0.00001684
Iteration 27/1000 | Loss: 0.00001684
Iteration 28/1000 | Loss: 0.00001683
Iteration 29/1000 | Loss: 0.00001683
Iteration 30/1000 | Loss: 0.00001683
Iteration 31/1000 | Loss: 0.00001683
Iteration 32/1000 | Loss: 0.00001683
Iteration 33/1000 | Loss: 0.00001682
Iteration 34/1000 | Loss: 0.00001682
Iteration 35/1000 | Loss: 0.00001682
Iteration 36/1000 | Loss: 0.00001680
Iteration 37/1000 | Loss: 0.00001677
Iteration 38/1000 | Loss: 0.00001677
Iteration 39/1000 | Loss: 0.00001677
Iteration 40/1000 | Loss: 0.00001676
Iteration 41/1000 | Loss: 0.00001676
Iteration 42/1000 | Loss: 0.00001669
Iteration 43/1000 | Loss: 0.00001667
Iteration 44/1000 | Loss: 0.00001667
Iteration 45/1000 | Loss: 0.00001667
Iteration 46/1000 | Loss: 0.00001667
Iteration 47/1000 | Loss: 0.00001667
Iteration 48/1000 | Loss: 0.00001667
Iteration 49/1000 | Loss: 0.00001666
Iteration 50/1000 | Loss: 0.00001666
Iteration 51/1000 | Loss: 0.00001666
Iteration 52/1000 | Loss: 0.00001666
Iteration 53/1000 | Loss: 0.00001666
Iteration 54/1000 | Loss: 0.00001666
Iteration 55/1000 | Loss: 0.00001666
Iteration 56/1000 | Loss: 0.00001666
Iteration 57/1000 | Loss: 0.00001665
Iteration 58/1000 | Loss: 0.00001664
Iteration 59/1000 | Loss: 0.00001664
Iteration 60/1000 | Loss: 0.00001664
Iteration 61/1000 | Loss: 0.00001664
Iteration 62/1000 | Loss: 0.00001664
Iteration 63/1000 | Loss: 0.00001663
Iteration 64/1000 | Loss: 0.00001663
Iteration 65/1000 | Loss: 0.00001663
Iteration 66/1000 | Loss: 0.00001662
Iteration 67/1000 | Loss: 0.00001662
Iteration 68/1000 | Loss: 0.00001662
Iteration 69/1000 | Loss: 0.00001661
Iteration 70/1000 | Loss: 0.00001661
Iteration 71/1000 | Loss: 0.00001661
Iteration 72/1000 | Loss: 0.00001661
Iteration 73/1000 | Loss: 0.00001661
Iteration 74/1000 | Loss: 0.00001661
Iteration 75/1000 | Loss: 0.00001661
Iteration 76/1000 | Loss: 0.00001661
Iteration 77/1000 | Loss: 0.00001661
Iteration 78/1000 | Loss: 0.00001661
Iteration 79/1000 | Loss: 0.00001661
Iteration 80/1000 | Loss: 0.00001661
Iteration 81/1000 | Loss: 0.00001661
Iteration 82/1000 | Loss: 0.00001661
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 82. Stopping optimization.
Last 5 losses: [1.6606929420959204e-05, 1.6606929420959204e-05, 1.6606929420959204e-05, 1.6606929420959204e-05, 1.6606929420959204e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6606929420959204e-05

Optimization complete. Final v2v error: 3.541630983352661 mm

Highest mean error: 3.8805742263793945 mm for frame 114

Lowest mean error: 3.2168312072753906 mm for frame 221

Saving results

Total time: 36.056790828704834
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_26_us_2312/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_26_us_2312/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01006613
Iteration 2/25 | Loss: 0.00206655
Iteration 3/25 | Loss: 0.00143172
Iteration 4/25 | Loss: 0.00135154
Iteration 5/25 | Loss: 0.00132186
Iteration 6/25 | Loss: 0.00130136
Iteration 7/25 | Loss: 0.00129238
Iteration 8/25 | Loss: 0.00127113
Iteration 9/25 | Loss: 0.00124217
Iteration 10/25 | Loss: 0.00124293
Iteration 11/25 | Loss: 0.00123105
Iteration 12/25 | Loss: 0.00123050
Iteration 13/25 | Loss: 0.00121544
Iteration 14/25 | Loss: 0.00120970
Iteration 15/25 | Loss: 0.00121085
Iteration 16/25 | Loss: 0.00120293
Iteration 17/25 | Loss: 0.00121016
Iteration 18/25 | Loss: 0.00120983
Iteration 19/25 | Loss: 0.00120748
Iteration 20/25 | Loss: 0.00121021
Iteration 21/25 | Loss: 0.00121545
Iteration 22/25 | Loss: 0.00120961
Iteration 23/25 | Loss: 0.00120617
Iteration 24/25 | Loss: 0.00120708
Iteration 25/25 | Loss: 0.00121174

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.78531408
Iteration 2/25 | Loss: 0.00640877
Iteration 3/25 | Loss: 0.00640877
Iteration 4/25 | Loss: 0.00640877
Iteration 5/25 | Loss: 0.00640877
Iteration 6/25 | Loss: 0.00640877
Iteration 7/25 | Loss: 0.00640877
Iteration 8/25 | Loss: 0.00640877
Iteration 9/25 | Loss: 0.00640877
Iteration 10/25 | Loss: 0.00640877
Iteration 11/25 | Loss: 0.00640877
Iteration 12/25 | Loss: 0.00640877
Iteration 13/25 | Loss: 0.00640877
Iteration 14/25 | Loss: 0.00640877
Iteration 15/25 | Loss: 0.00640877
Iteration 16/25 | Loss: 0.00640877
Iteration 17/25 | Loss: 0.00640877
Iteration 18/25 | Loss: 0.00640877
Iteration 19/25 | Loss: 0.00640877
Iteration 20/25 | Loss: 0.00640877
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.00640877103433013, 0.00640877103433013, 0.00640877103433013, 0.00640877103433013, 0.00640877103433013]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00640877103433013

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00640877
Iteration 2/1000 | Loss: 0.00044134
Iteration 3/1000 | Loss: 0.00578854
Iteration 4/1000 | Loss: 0.00478234
Iteration 5/1000 | Loss: 0.00604682
Iteration 6/1000 | Loss: 0.00287762
Iteration 7/1000 | Loss: 0.00153315
Iteration 8/1000 | Loss: 0.00029715
Iteration 9/1000 | Loss: 0.00433690
Iteration 10/1000 | Loss: 0.00207422
Iteration 11/1000 | Loss: 0.00301320
Iteration 12/1000 | Loss: 0.00096508
Iteration 13/1000 | Loss: 0.00063235
Iteration 14/1000 | Loss: 0.00023576
Iteration 15/1000 | Loss: 0.00039190
Iteration 16/1000 | Loss: 0.00080056
Iteration 17/1000 | Loss: 0.00040262
Iteration 18/1000 | Loss: 0.00078389
Iteration 19/1000 | Loss: 0.00019580
Iteration 20/1000 | Loss: 0.00061352
Iteration 21/1000 | Loss: 0.00029675
Iteration 22/1000 | Loss: 0.00030176
Iteration 23/1000 | Loss: 0.00006831
Iteration 24/1000 | Loss: 0.00005398
Iteration 25/1000 | Loss: 0.00004869
Iteration 26/1000 | Loss: 0.00156504
Iteration 27/1000 | Loss: 0.00101541
Iteration 28/1000 | Loss: 0.00006553
Iteration 29/1000 | Loss: 0.00008279
Iteration 30/1000 | Loss: 0.00099280
Iteration 31/1000 | Loss: 0.00053735
Iteration 32/1000 | Loss: 0.00004847
Iteration 33/1000 | Loss: 0.00072026
Iteration 34/1000 | Loss: 0.00007099
Iteration 35/1000 | Loss: 0.00004184
Iteration 36/1000 | Loss: 0.00003837
Iteration 37/1000 | Loss: 0.00019663
Iteration 38/1000 | Loss: 0.00021847
Iteration 39/1000 | Loss: 0.00022051
Iteration 40/1000 | Loss: 0.00058679
Iteration 41/1000 | Loss: 0.00012995
Iteration 42/1000 | Loss: 0.00003578
Iteration 43/1000 | Loss: 0.00003158
Iteration 44/1000 | Loss: 0.00011778
Iteration 45/1000 | Loss: 0.00003564
Iteration 46/1000 | Loss: 0.00003177
Iteration 47/1000 | Loss: 0.00018740
Iteration 48/1000 | Loss: 0.00012283
Iteration 49/1000 | Loss: 0.00002864
Iteration 50/1000 | Loss: 0.00004469
Iteration 51/1000 | Loss: 0.00002634
Iteration 52/1000 | Loss: 0.00022392
Iteration 53/1000 | Loss: 0.00011406
Iteration 54/1000 | Loss: 0.00020641
Iteration 55/1000 | Loss: 0.00005579
Iteration 56/1000 | Loss: 0.00002757
Iteration 57/1000 | Loss: 0.00008278
Iteration 58/1000 | Loss: 0.00016985
Iteration 59/1000 | Loss: 0.00013997
Iteration 60/1000 | Loss: 0.00017903
Iteration 61/1000 | Loss: 0.00007063
Iteration 62/1000 | Loss: 0.00005369
Iteration 63/1000 | Loss: 0.00006144
Iteration 64/1000 | Loss: 0.00019367
Iteration 65/1000 | Loss: 0.00013505
Iteration 66/1000 | Loss: 0.00019022
Iteration 67/1000 | Loss: 0.00006654
Iteration 68/1000 | Loss: 0.00002892
Iteration 69/1000 | Loss: 0.00002760
Iteration 70/1000 | Loss: 0.00005135
Iteration 71/1000 | Loss: 0.00029729
Iteration 72/1000 | Loss: 0.00013882
Iteration 73/1000 | Loss: 0.00010616
Iteration 74/1000 | Loss: 0.00012519
Iteration 75/1000 | Loss: 0.00011136
Iteration 76/1000 | Loss: 0.00014606
Iteration 77/1000 | Loss: 0.00004028
Iteration 78/1000 | Loss: 0.00003113
Iteration 79/1000 | Loss: 0.00007308
Iteration 80/1000 | Loss: 0.00002668
Iteration 81/1000 | Loss: 0.00017401
Iteration 82/1000 | Loss: 0.00017848
Iteration 83/1000 | Loss: 0.00033759
Iteration 84/1000 | Loss: 0.00020823
Iteration 85/1000 | Loss: 0.00022541
Iteration 86/1000 | Loss: 0.00015995
Iteration 87/1000 | Loss: 0.00014270
Iteration 88/1000 | Loss: 0.00009347
Iteration 89/1000 | Loss: 0.00006497
Iteration 90/1000 | Loss: 0.00024777
Iteration 91/1000 | Loss: 0.00024512
Iteration 92/1000 | Loss: 0.00011567
Iteration 93/1000 | Loss: 0.00026673
Iteration 94/1000 | Loss: 0.00008911
Iteration 95/1000 | Loss: 0.00005201
Iteration 96/1000 | Loss: 0.00005174
Iteration 97/1000 | Loss: 0.00002794
Iteration 98/1000 | Loss: 0.00002607
Iteration 99/1000 | Loss: 0.00002508
Iteration 100/1000 | Loss: 0.00002434
Iteration 101/1000 | Loss: 0.00002361
Iteration 102/1000 | Loss: 0.00003849
Iteration 103/1000 | Loss: 0.00002696
Iteration 104/1000 | Loss: 0.00002475
Iteration 105/1000 | Loss: 0.00002352
Iteration 106/1000 | Loss: 0.00002284
Iteration 107/1000 | Loss: 0.00002242
Iteration 108/1000 | Loss: 0.00002202
Iteration 109/1000 | Loss: 0.00002178
Iteration 110/1000 | Loss: 0.00002172
Iteration 111/1000 | Loss: 0.00002170
Iteration 112/1000 | Loss: 0.00002169
Iteration 113/1000 | Loss: 0.00002169
Iteration 114/1000 | Loss: 0.00002168
Iteration 115/1000 | Loss: 0.00002168
Iteration 116/1000 | Loss: 0.00002168
Iteration 117/1000 | Loss: 0.00002167
Iteration 118/1000 | Loss: 0.00002167
Iteration 119/1000 | Loss: 0.00002166
Iteration 120/1000 | Loss: 0.00002165
Iteration 121/1000 | Loss: 0.00002165
Iteration 122/1000 | Loss: 0.00002164
Iteration 123/1000 | Loss: 0.00002164
Iteration 124/1000 | Loss: 0.00002163
Iteration 125/1000 | Loss: 0.00002163
Iteration 126/1000 | Loss: 0.00002162
Iteration 127/1000 | Loss: 0.00002162
Iteration 128/1000 | Loss: 0.00002162
Iteration 129/1000 | Loss: 0.00002162
Iteration 130/1000 | Loss: 0.00002161
Iteration 131/1000 | Loss: 0.00002161
Iteration 132/1000 | Loss: 0.00002161
Iteration 133/1000 | Loss: 0.00002161
Iteration 134/1000 | Loss: 0.00002160
Iteration 135/1000 | Loss: 0.00002160
Iteration 136/1000 | Loss: 0.00002160
Iteration 137/1000 | Loss: 0.00002159
Iteration 138/1000 | Loss: 0.00002159
Iteration 139/1000 | Loss: 0.00002158
Iteration 140/1000 | Loss: 0.00002158
Iteration 141/1000 | Loss: 0.00002158
Iteration 142/1000 | Loss: 0.00002158
Iteration 143/1000 | Loss: 0.00002158
Iteration 144/1000 | Loss: 0.00002157
Iteration 145/1000 | Loss: 0.00002157
Iteration 146/1000 | Loss: 0.00002157
Iteration 147/1000 | Loss: 0.00002157
Iteration 148/1000 | Loss: 0.00002156
Iteration 149/1000 | Loss: 0.00002156
Iteration 150/1000 | Loss: 0.00002156
Iteration 151/1000 | Loss: 0.00002155
Iteration 152/1000 | Loss: 0.00002155
Iteration 153/1000 | Loss: 0.00002155
Iteration 154/1000 | Loss: 0.00002155
Iteration 155/1000 | Loss: 0.00002155
Iteration 156/1000 | Loss: 0.00002155
Iteration 157/1000 | Loss: 0.00002155
Iteration 158/1000 | Loss: 0.00002154
Iteration 159/1000 | Loss: 0.00002154
Iteration 160/1000 | Loss: 0.00002154
Iteration 161/1000 | Loss: 0.00002154
Iteration 162/1000 | Loss: 0.00002154
Iteration 163/1000 | Loss: 0.00002154
Iteration 164/1000 | Loss: 0.00002154
Iteration 165/1000 | Loss: 0.00002154
Iteration 166/1000 | Loss: 0.00002153
Iteration 167/1000 | Loss: 0.00002153
Iteration 168/1000 | Loss: 0.00002153
Iteration 169/1000 | Loss: 0.00002153
Iteration 170/1000 | Loss: 0.00002153
Iteration 171/1000 | Loss: 0.00002153
Iteration 172/1000 | Loss: 0.00002153
Iteration 173/1000 | Loss: 0.00002153
Iteration 174/1000 | Loss: 0.00002153
Iteration 175/1000 | Loss: 0.00002153
Iteration 176/1000 | Loss: 0.00002153
Iteration 177/1000 | Loss: 0.00002153
Iteration 178/1000 | Loss: 0.00002153
Iteration 179/1000 | Loss: 0.00002153
Iteration 180/1000 | Loss: 0.00002153
Iteration 181/1000 | Loss: 0.00002153
Iteration 182/1000 | Loss: 0.00002153
Iteration 183/1000 | Loss: 0.00002153
Iteration 184/1000 | Loss: 0.00002153
Iteration 185/1000 | Loss: 0.00002152
Iteration 186/1000 | Loss: 0.00002152
Iteration 187/1000 | Loss: 0.00002152
Iteration 188/1000 | Loss: 0.00002152
Iteration 189/1000 | Loss: 0.00002152
Iteration 190/1000 | Loss: 0.00002152
Iteration 191/1000 | Loss: 0.00002152
Iteration 192/1000 | Loss: 0.00002152
Iteration 193/1000 | Loss: 0.00002152
Iteration 194/1000 | Loss: 0.00002152
Iteration 195/1000 | Loss: 0.00002152
Iteration 196/1000 | Loss: 0.00002152
Iteration 197/1000 | Loss: 0.00002152
Iteration 198/1000 | Loss: 0.00002152
Iteration 199/1000 | Loss: 0.00002152
Iteration 200/1000 | Loss: 0.00002151
Iteration 201/1000 | Loss: 0.00002151
Iteration 202/1000 | Loss: 0.00002151
Iteration 203/1000 | Loss: 0.00002151
Iteration 204/1000 | Loss: 0.00002151
Iteration 205/1000 | Loss: 0.00002151
Iteration 206/1000 | Loss: 0.00002151
Iteration 207/1000 | Loss: 0.00002151
Iteration 208/1000 | Loss: 0.00002151
Iteration 209/1000 | Loss: 0.00002151
Iteration 210/1000 | Loss: 0.00002151
Iteration 211/1000 | Loss: 0.00002151
Iteration 212/1000 | Loss: 0.00002151
Iteration 213/1000 | Loss: 0.00002151
Iteration 214/1000 | Loss: 0.00002151
Iteration 215/1000 | Loss: 0.00002151
Iteration 216/1000 | Loss: 0.00002151
Iteration 217/1000 | Loss: 0.00002151
Iteration 218/1000 | Loss: 0.00002151
Iteration 219/1000 | Loss: 0.00002150
Iteration 220/1000 | Loss: 0.00002150
Iteration 221/1000 | Loss: 0.00002150
Iteration 222/1000 | Loss: 0.00002150
Iteration 223/1000 | Loss: 0.00002150
Iteration 224/1000 | Loss: 0.00002150
Iteration 225/1000 | Loss: 0.00002150
Iteration 226/1000 | Loss: 0.00002150
Iteration 227/1000 | Loss: 0.00002150
Iteration 228/1000 | Loss: 0.00002150
Iteration 229/1000 | Loss: 0.00002150
Iteration 230/1000 | Loss: 0.00002150
Iteration 231/1000 | Loss: 0.00002150
Iteration 232/1000 | Loss: 0.00002149
Iteration 233/1000 | Loss: 0.00002149
Iteration 234/1000 | Loss: 0.00002149
Iteration 235/1000 | Loss: 0.00002149
Iteration 236/1000 | Loss: 0.00002149
Iteration 237/1000 | Loss: 0.00002149
Iteration 238/1000 | Loss: 0.00002149
Iteration 239/1000 | Loss: 0.00002149
Iteration 240/1000 | Loss: 0.00002149
Iteration 241/1000 | Loss: 0.00002149
Iteration 242/1000 | Loss: 0.00002149
Iteration 243/1000 | Loss: 0.00002149
Iteration 244/1000 | Loss: 0.00002149
Iteration 245/1000 | Loss: 0.00002149
Iteration 246/1000 | Loss: 0.00002149
Iteration 247/1000 | Loss: 0.00002149
Iteration 248/1000 | Loss: 0.00002149
Iteration 249/1000 | Loss: 0.00002149
Iteration 250/1000 | Loss: 0.00002149
Iteration 251/1000 | Loss: 0.00002149
Iteration 252/1000 | Loss: 0.00002148
Iteration 253/1000 | Loss: 0.00002148
Iteration 254/1000 | Loss: 0.00002148
Iteration 255/1000 | Loss: 0.00002148
Iteration 256/1000 | Loss: 0.00002148
Iteration 257/1000 | Loss: 0.00002148
Iteration 258/1000 | Loss: 0.00002148
Iteration 259/1000 | Loss: 0.00002148
Iteration 260/1000 | Loss: 0.00002148
Iteration 261/1000 | Loss: 0.00002148
Iteration 262/1000 | Loss: 0.00002148
Iteration 263/1000 | Loss: 0.00002148
Iteration 264/1000 | Loss: 0.00002148
Iteration 265/1000 | Loss: 0.00002148
Iteration 266/1000 | Loss: 0.00002148
Iteration 267/1000 | Loss: 0.00002148
Iteration 268/1000 | Loss: 0.00002148
Iteration 269/1000 | Loss: 0.00002148
Iteration 270/1000 | Loss: 0.00002148
Iteration 271/1000 | Loss: 0.00002148
Iteration 272/1000 | Loss: 0.00002148
Iteration 273/1000 | Loss: 0.00002148
Iteration 274/1000 | Loss: 0.00002148
Iteration 275/1000 | Loss: 0.00002148
Iteration 276/1000 | Loss: 0.00002148
Iteration 277/1000 | Loss: 0.00002148
Iteration 278/1000 | Loss: 0.00002148
Iteration 279/1000 | Loss: 0.00002148
Iteration 280/1000 | Loss: 0.00002148
Iteration 281/1000 | Loss: 0.00002148
Iteration 282/1000 | Loss: 0.00002148
Iteration 283/1000 | Loss: 0.00002148
Iteration 284/1000 | Loss: 0.00002148
Iteration 285/1000 | Loss: 0.00002148
Iteration 286/1000 | Loss: 0.00002148
Iteration 287/1000 | Loss: 0.00002148
Iteration 288/1000 | Loss: 0.00002148
Iteration 289/1000 | Loss: 0.00002148
Iteration 290/1000 | Loss: 0.00002148
Iteration 291/1000 | Loss: 0.00002148
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 291. Stopping optimization.
Last 5 losses: [2.1483983800862916e-05, 2.1483983800862916e-05, 2.1483983800862916e-05, 2.1483983800862916e-05, 2.1483983800862916e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1483983800862916e-05

Optimization complete. Final v2v error: 3.843470335006714 mm

Highest mean error: 8.925140380859375 mm for frame 106

Lowest mean error: 3.1654999256134033 mm for frame 120

Saving results

Total time: 210.6474735736847
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00451000
Iteration 2/25 | Loss: 0.00107886
Iteration 3/25 | Loss: 0.00097235
Iteration 4/25 | Loss: 0.00093856
Iteration 5/25 | Loss: 0.00092632
Iteration 6/25 | Loss: 0.00092387
Iteration 7/25 | Loss: 0.00092329
Iteration 8/25 | Loss: 0.00092329
Iteration 9/25 | Loss: 0.00092329
Iteration 10/25 | Loss: 0.00092329
Iteration 11/25 | Loss: 0.00092329
Iteration 12/25 | Loss: 0.00092329
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009232870652340353, 0.0009232870652340353, 0.0009232870652340353, 0.0009232870652340353, 0.0009232870652340353]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009232870652340353

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46566939
Iteration 2/25 | Loss: 0.00078868
Iteration 3/25 | Loss: 0.00078868
Iteration 4/25 | Loss: 0.00078868
Iteration 5/25 | Loss: 0.00078868
Iteration 6/25 | Loss: 0.00078868
Iteration 7/25 | Loss: 0.00078868
Iteration 8/25 | Loss: 0.00078868
Iteration 9/25 | Loss: 0.00078868
Iteration 10/25 | Loss: 0.00078868
Iteration 11/25 | Loss: 0.00078868
Iteration 12/25 | Loss: 0.00078868
Iteration 13/25 | Loss: 0.00078868
Iteration 14/25 | Loss: 0.00078868
Iteration 15/25 | Loss: 0.00078868
Iteration 16/25 | Loss: 0.00078868
Iteration 17/25 | Loss: 0.00078868
Iteration 18/25 | Loss: 0.00078868
Iteration 19/25 | Loss: 0.00078868
Iteration 20/25 | Loss: 0.00078868
Iteration 21/25 | Loss: 0.00078868
Iteration 22/25 | Loss: 0.00078868
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0007886769017204642, 0.0007886769017204642, 0.0007886769017204642, 0.0007886769017204642, 0.0007886769017204642]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007886769017204642

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078868
Iteration 2/1000 | Loss: 0.00003734
Iteration 3/1000 | Loss: 0.00002733
Iteration 4/1000 | Loss: 0.00002435
Iteration 5/1000 | Loss: 0.00002318
Iteration 6/1000 | Loss: 0.00002237
Iteration 7/1000 | Loss: 0.00002185
Iteration 8/1000 | Loss: 0.00002150
Iteration 9/1000 | Loss: 0.00002141
Iteration 10/1000 | Loss: 0.00002138
Iteration 11/1000 | Loss: 0.00002134
Iteration 12/1000 | Loss: 0.00002134
Iteration 13/1000 | Loss: 0.00002132
Iteration 14/1000 | Loss: 0.00002130
Iteration 15/1000 | Loss: 0.00002129
Iteration 16/1000 | Loss: 0.00002128
Iteration 17/1000 | Loss: 0.00002128
Iteration 18/1000 | Loss: 0.00002128
Iteration 19/1000 | Loss: 0.00002128
Iteration 20/1000 | Loss: 0.00002127
Iteration 21/1000 | Loss: 0.00002125
Iteration 22/1000 | Loss: 0.00002125
Iteration 23/1000 | Loss: 0.00002124
Iteration 24/1000 | Loss: 0.00002124
Iteration 25/1000 | Loss: 0.00002123
Iteration 26/1000 | Loss: 0.00002123
Iteration 27/1000 | Loss: 0.00002123
Iteration 28/1000 | Loss: 0.00002123
Iteration 29/1000 | Loss: 0.00002122
Iteration 30/1000 | Loss: 0.00002122
Iteration 31/1000 | Loss: 0.00002122
Iteration 32/1000 | Loss: 0.00002122
Iteration 33/1000 | Loss: 0.00002122
Iteration 34/1000 | Loss: 0.00002121
Iteration 35/1000 | Loss: 0.00002121
Iteration 36/1000 | Loss: 0.00002121
Iteration 37/1000 | Loss: 0.00002121
Iteration 38/1000 | Loss: 0.00002121
Iteration 39/1000 | Loss: 0.00002121
Iteration 40/1000 | Loss: 0.00002121
Iteration 41/1000 | Loss: 0.00002121
Iteration 42/1000 | Loss: 0.00002121
Iteration 43/1000 | Loss: 0.00002121
Iteration 44/1000 | Loss: 0.00002121
Iteration 45/1000 | Loss: 0.00002121
Iteration 46/1000 | Loss: 0.00002121
Iteration 47/1000 | Loss: 0.00002120
Iteration 48/1000 | Loss: 0.00002120
Iteration 49/1000 | Loss: 0.00002120
Iteration 50/1000 | Loss: 0.00002120
Iteration 51/1000 | Loss: 0.00002120
Iteration 52/1000 | Loss: 0.00002120
Iteration 53/1000 | Loss: 0.00002120
Iteration 54/1000 | Loss: 0.00002120
Iteration 55/1000 | Loss: 0.00002120
Iteration 56/1000 | Loss: 0.00002120
Iteration 57/1000 | Loss: 0.00002119
Iteration 58/1000 | Loss: 0.00002119
Iteration 59/1000 | Loss: 0.00002119
Iteration 60/1000 | Loss: 0.00002119
Iteration 61/1000 | Loss: 0.00002119
Iteration 62/1000 | Loss: 0.00002119
Iteration 63/1000 | Loss: 0.00002119
Iteration 64/1000 | Loss: 0.00002119
Iteration 65/1000 | Loss: 0.00002119
Iteration 66/1000 | Loss: 0.00002119
Iteration 67/1000 | Loss: 0.00002119
Iteration 68/1000 | Loss: 0.00002119
Iteration 69/1000 | Loss: 0.00002119
Iteration 70/1000 | Loss: 0.00002119
Iteration 71/1000 | Loss: 0.00002119
Iteration 72/1000 | Loss: 0.00002119
Iteration 73/1000 | Loss: 0.00002119
Iteration 74/1000 | Loss: 0.00002119
Iteration 75/1000 | Loss: 0.00002118
Iteration 76/1000 | Loss: 0.00002118
Iteration 77/1000 | Loss: 0.00002118
Iteration 78/1000 | Loss: 0.00002118
Iteration 79/1000 | Loss: 0.00002118
Iteration 80/1000 | Loss: 0.00002118
Iteration 81/1000 | Loss: 0.00002118
Iteration 82/1000 | Loss: 0.00002118
Iteration 83/1000 | Loss: 0.00002118
Iteration 84/1000 | Loss: 0.00002118
Iteration 85/1000 | Loss: 0.00002118
Iteration 86/1000 | Loss: 0.00002118
Iteration 87/1000 | Loss: 0.00002118
Iteration 88/1000 | Loss: 0.00002118
Iteration 89/1000 | Loss: 0.00002118
Iteration 90/1000 | Loss: 0.00002118
Iteration 91/1000 | Loss: 0.00002118
Iteration 92/1000 | Loss: 0.00002118
Iteration 93/1000 | Loss: 0.00002118
Iteration 94/1000 | Loss: 0.00002118
Iteration 95/1000 | Loss: 0.00002118
Iteration 96/1000 | Loss: 0.00002118
Iteration 97/1000 | Loss: 0.00002118
Iteration 98/1000 | Loss: 0.00002118
Iteration 99/1000 | Loss: 0.00002118
Iteration 100/1000 | Loss: 0.00002118
Iteration 101/1000 | Loss: 0.00002118
Iteration 102/1000 | Loss: 0.00002118
Iteration 103/1000 | Loss: 0.00002118
Iteration 104/1000 | Loss: 0.00002118
Iteration 105/1000 | Loss: 0.00002118
Iteration 106/1000 | Loss: 0.00002118
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [2.1175450456212275e-05, 2.1175450456212275e-05, 2.1175450456212275e-05, 2.1175450456212275e-05, 2.1175450456212275e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1175450456212275e-05

Optimization complete. Final v2v error: 3.910956859588623 mm

Highest mean error: 4.16995096206665 mm for frame 59

Lowest mean error: 3.672268867492676 mm for frame 0

Saving results

Total time: 29.160680055618286
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00606986
Iteration 2/25 | Loss: 0.00108623
Iteration 3/25 | Loss: 0.00097338
Iteration 4/25 | Loss: 0.00094514
Iteration 5/25 | Loss: 0.00093584
Iteration 6/25 | Loss: 0.00093298
Iteration 7/25 | Loss: 0.00093232
Iteration 8/25 | Loss: 0.00093232
Iteration 9/25 | Loss: 0.00093232
Iteration 10/25 | Loss: 0.00093232
Iteration 11/25 | Loss: 0.00093232
Iteration 12/25 | Loss: 0.00093232
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009323214180767536, 0.0009323214180767536, 0.0009323214180767536, 0.0009323214180767536, 0.0009323214180767536]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009323214180767536

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62435770
Iteration 2/25 | Loss: 0.00077807
Iteration 3/25 | Loss: 0.00077807
Iteration 4/25 | Loss: 0.00077807
Iteration 5/25 | Loss: 0.00077807
Iteration 6/25 | Loss: 0.00077807
Iteration 7/25 | Loss: 0.00077807
Iteration 8/25 | Loss: 0.00077807
Iteration 9/25 | Loss: 0.00077807
Iteration 10/25 | Loss: 0.00077807
Iteration 11/25 | Loss: 0.00077807
Iteration 12/25 | Loss: 0.00077807
Iteration 13/25 | Loss: 0.00077807
Iteration 14/25 | Loss: 0.00077807
Iteration 15/25 | Loss: 0.00077807
Iteration 16/25 | Loss: 0.00077807
Iteration 17/25 | Loss: 0.00077807
Iteration 18/25 | Loss: 0.00077807
Iteration 19/25 | Loss: 0.00077807
Iteration 20/25 | Loss: 0.00077807
Iteration 21/25 | Loss: 0.00077807
Iteration 22/25 | Loss: 0.00077807
Iteration 23/25 | Loss: 0.00077807
Iteration 24/25 | Loss: 0.00077807
Iteration 25/25 | Loss: 0.00077807

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00077807
Iteration 2/1000 | Loss: 0.00003065
Iteration 3/1000 | Loss: 0.00002388
Iteration 4/1000 | Loss: 0.00002166
Iteration 5/1000 | Loss: 0.00002075
Iteration 6/1000 | Loss: 0.00002000
Iteration 7/1000 | Loss: 0.00001960
Iteration 8/1000 | Loss: 0.00001932
Iteration 9/1000 | Loss: 0.00001917
Iteration 10/1000 | Loss: 0.00001914
Iteration 11/1000 | Loss: 0.00001914
Iteration 12/1000 | Loss: 0.00001912
Iteration 13/1000 | Loss: 0.00001912
Iteration 14/1000 | Loss: 0.00001909
Iteration 15/1000 | Loss: 0.00001909
Iteration 16/1000 | Loss: 0.00001909
Iteration 17/1000 | Loss: 0.00001909
Iteration 18/1000 | Loss: 0.00001909
Iteration 19/1000 | Loss: 0.00001909
Iteration 20/1000 | Loss: 0.00001908
Iteration 21/1000 | Loss: 0.00001908
Iteration 22/1000 | Loss: 0.00001908
Iteration 23/1000 | Loss: 0.00001908
Iteration 24/1000 | Loss: 0.00001905
Iteration 25/1000 | Loss: 0.00001905
Iteration 26/1000 | Loss: 0.00001904
Iteration 27/1000 | Loss: 0.00001904
Iteration 28/1000 | Loss: 0.00001903
Iteration 29/1000 | Loss: 0.00001903
Iteration 30/1000 | Loss: 0.00001903
Iteration 31/1000 | Loss: 0.00001903
Iteration 32/1000 | Loss: 0.00001903
Iteration 33/1000 | Loss: 0.00001902
Iteration 34/1000 | Loss: 0.00001901
Iteration 35/1000 | Loss: 0.00001901
Iteration 36/1000 | Loss: 0.00001900
Iteration 37/1000 | Loss: 0.00001900
Iteration 38/1000 | Loss: 0.00001899
Iteration 39/1000 | Loss: 0.00001899
Iteration 40/1000 | Loss: 0.00001899
Iteration 41/1000 | Loss: 0.00001899
Iteration 42/1000 | Loss: 0.00001899
Iteration 43/1000 | Loss: 0.00001899
Iteration 44/1000 | Loss: 0.00001899
Iteration 45/1000 | Loss: 0.00001898
Iteration 46/1000 | Loss: 0.00001896
Iteration 47/1000 | Loss: 0.00001896
Iteration 48/1000 | Loss: 0.00001896
Iteration 49/1000 | Loss: 0.00001896
Iteration 50/1000 | Loss: 0.00001896
Iteration 51/1000 | Loss: 0.00001896
Iteration 52/1000 | Loss: 0.00001896
Iteration 53/1000 | Loss: 0.00001896
Iteration 54/1000 | Loss: 0.00001896
Iteration 55/1000 | Loss: 0.00001896
Iteration 56/1000 | Loss: 0.00001896
Iteration 57/1000 | Loss: 0.00001896
Iteration 58/1000 | Loss: 0.00001896
Iteration 59/1000 | Loss: 0.00001895
Iteration 60/1000 | Loss: 0.00001895
Iteration 61/1000 | Loss: 0.00001895
Iteration 62/1000 | Loss: 0.00001895
Iteration 63/1000 | Loss: 0.00001895
Iteration 64/1000 | Loss: 0.00001895
Iteration 65/1000 | Loss: 0.00001895
Iteration 66/1000 | Loss: 0.00001895
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 66. Stopping optimization.
Last 5 losses: [1.89549336937489e-05, 1.89549336937489e-05, 1.89549336937489e-05, 1.89549336937489e-05, 1.89549336937489e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.89549336937489e-05

Optimization complete. Final v2v error: 3.736288070678711 mm

Highest mean error: 4.048594951629639 mm for frame 110

Lowest mean error: 3.434959888458252 mm for frame 78

Saving results

Total time: 27.17862296104431
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00779442
Iteration 2/25 | Loss: 0.00103793
Iteration 3/25 | Loss: 0.00091325
Iteration 4/25 | Loss: 0.00089395
Iteration 5/25 | Loss: 0.00088782
Iteration 6/25 | Loss: 0.00088607
Iteration 7/25 | Loss: 0.00088590
Iteration 8/25 | Loss: 0.00088590
Iteration 9/25 | Loss: 0.00088590
Iteration 10/25 | Loss: 0.00088590
Iteration 11/25 | Loss: 0.00088590
Iteration 12/25 | Loss: 0.00088590
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008858994115144014, 0.0008858994115144014, 0.0008858994115144014, 0.0008858994115144014, 0.0008858994115144014]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008858994115144014

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.62685740
Iteration 2/25 | Loss: 0.00075975
Iteration 3/25 | Loss: 0.00075975
Iteration 4/25 | Loss: 0.00075975
Iteration 5/25 | Loss: 0.00075974
Iteration 6/25 | Loss: 0.00075974
Iteration 7/25 | Loss: 0.00075974
Iteration 8/25 | Loss: 0.00075974
Iteration 9/25 | Loss: 0.00075974
Iteration 10/25 | Loss: 0.00075974
Iteration 11/25 | Loss: 0.00075974
Iteration 12/25 | Loss: 0.00075974
Iteration 13/25 | Loss: 0.00075974
Iteration 14/25 | Loss: 0.00075974
Iteration 15/25 | Loss: 0.00075974
Iteration 16/25 | Loss: 0.00075974
Iteration 17/25 | Loss: 0.00075974
Iteration 18/25 | Loss: 0.00075974
Iteration 19/25 | Loss: 0.00075974
Iteration 20/25 | Loss: 0.00075974
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0007597433286719024, 0.0007597433286719024, 0.0007597433286719024, 0.0007597433286719024, 0.0007597433286719024]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007597433286719024

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075974
Iteration 2/1000 | Loss: 0.00002442
Iteration 3/1000 | Loss: 0.00001973
Iteration 4/1000 | Loss: 0.00001870
Iteration 5/1000 | Loss: 0.00001782
Iteration 6/1000 | Loss: 0.00001735
Iteration 7/1000 | Loss: 0.00001696
Iteration 8/1000 | Loss: 0.00001678
Iteration 9/1000 | Loss: 0.00001675
Iteration 10/1000 | Loss: 0.00001673
Iteration 11/1000 | Loss: 0.00001672
Iteration 12/1000 | Loss: 0.00001672
Iteration 13/1000 | Loss: 0.00001672
Iteration 14/1000 | Loss: 0.00001671
Iteration 15/1000 | Loss: 0.00001670
Iteration 16/1000 | Loss: 0.00001668
Iteration 17/1000 | Loss: 0.00001668
Iteration 18/1000 | Loss: 0.00001668
Iteration 19/1000 | Loss: 0.00001668
Iteration 20/1000 | Loss: 0.00001668
Iteration 21/1000 | Loss: 0.00001668
Iteration 22/1000 | Loss: 0.00001667
Iteration 23/1000 | Loss: 0.00001667
Iteration 24/1000 | Loss: 0.00001665
Iteration 25/1000 | Loss: 0.00001664
Iteration 26/1000 | Loss: 0.00001664
Iteration 27/1000 | Loss: 0.00001664
Iteration 28/1000 | Loss: 0.00001663
Iteration 29/1000 | Loss: 0.00001663
Iteration 30/1000 | Loss: 0.00001660
Iteration 31/1000 | Loss: 0.00001660
Iteration 32/1000 | Loss: 0.00001660
Iteration 33/1000 | Loss: 0.00001659
Iteration 34/1000 | Loss: 0.00001659
Iteration 35/1000 | Loss: 0.00001658
Iteration 36/1000 | Loss: 0.00001657
Iteration 37/1000 | Loss: 0.00001657
Iteration 38/1000 | Loss: 0.00001656
Iteration 39/1000 | Loss: 0.00001656
Iteration 40/1000 | Loss: 0.00001656
Iteration 41/1000 | Loss: 0.00001656
Iteration 42/1000 | Loss: 0.00001656
Iteration 43/1000 | Loss: 0.00001655
Iteration 44/1000 | Loss: 0.00001655
Iteration 45/1000 | Loss: 0.00001655
Iteration 46/1000 | Loss: 0.00001655
Iteration 47/1000 | Loss: 0.00001654
Iteration 48/1000 | Loss: 0.00001654
Iteration 49/1000 | Loss: 0.00001654
Iteration 50/1000 | Loss: 0.00001653
Iteration 51/1000 | Loss: 0.00001653
Iteration 52/1000 | Loss: 0.00001653
Iteration 53/1000 | Loss: 0.00001653
Iteration 54/1000 | Loss: 0.00001653
Iteration 55/1000 | Loss: 0.00001653
Iteration 56/1000 | Loss: 0.00001652
Iteration 57/1000 | Loss: 0.00001652
Iteration 58/1000 | Loss: 0.00001652
Iteration 59/1000 | Loss: 0.00001651
Iteration 60/1000 | Loss: 0.00001651
Iteration 61/1000 | Loss: 0.00001651
Iteration 62/1000 | Loss: 0.00001651
Iteration 63/1000 | Loss: 0.00001651
Iteration 64/1000 | Loss: 0.00001651
Iteration 65/1000 | Loss: 0.00001651
Iteration 66/1000 | Loss: 0.00001650
Iteration 67/1000 | Loss: 0.00001650
Iteration 68/1000 | Loss: 0.00001650
Iteration 69/1000 | Loss: 0.00001650
Iteration 70/1000 | Loss: 0.00001650
Iteration 71/1000 | Loss: 0.00001650
Iteration 72/1000 | Loss: 0.00001650
Iteration 73/1000 | Loss: 0.00001649
Iteration 74/1000 | Loss: 0.00001649
Iteration 75/1000 | Loss: 0.00001649
Iteration 76/1000 | Loss: 0.00001649
Iteration 77/1000 | Loss: 0.00001649
Iteration 78/1000 | Loss: 0.00001649
Iteration 79/1000 | Loss: 0.00001649
Iteration 80/1000 | Loss: 0.00001649
Iteration 81/1000 | Loss: 0.00001649
Iteration 82/1000 | Loss: 0.00001649
Iteration 83/1000 | Loss: 0.00001649
Iteration 84/1000 | Loss: 0.00001649
Iteration 85/1000 | Loss: 0.00001649
Iteration 86/1000 | Loss: 0.00001649
Iteration 87/1000 | Loss: 0.00001649
Iteration 88/1000 | Loss: 0.00001649
Iteration 89/1000 | Loss: 0.00001649
Iteration 90/1000 | Loss: 0.00001649
Iteration 91/1000 | Loss: 0.00001649
Iteration 92/1000 | Loss: 0.00001649
Iteration 93/1000 | Loss: 0.00001649
Iteration 94/1000 | Loss: 0.00001649
Iteration 95/1000 | Loss: 0.00001649
Iteration 96/1000 | Loss: 0.00001649
Iteration 97/1000 | Loss: 0.00001649
Iteration 98/1000 | Loss: 0.00001649
Iteration 99/1000 | Loss: 0.00001649
Iteration 100/1000 | Loss: 0.00001649
Iteration 101/1000 | Loss: 0.00001649
Iteration 102/1000 | Loss: 0.00001649
Iteration 103/1000 | Loss: 0.00001649
Iteration 104/1000 | Loss: 0.00001649
Iteration 105/1000 | Loss: 0.00001649
Iteration 106/1000 | Loss: 0.00001649
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.6489910194650292e-05, 1.6489910194650292e-05, 1.6489910194650292e-05, 1.6489910194650292e-05, 1.6489910194650292e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6489910194650292e-05

Optimization complete. Final v2v error: 3.5026400089263916 mm

Highest mean error: 4.0662617683410645 mm for frame 115

Lowest mean error: 2.8990392684936523 mm for frame 194

Saving results

Total time: 28.978963375091553
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00562503
Iteration 2/25 | Loss: 0.00146614
Iteration 3/25 | Loss: 0.00108102
Iteration 4/25 | Loss: 0.00102118
Iteration 5/25 | Loss: 0.00100871
Iteration 6/25 | Loss: 0.00100622
Iteration 7/25 | Loss: 0.00100601
Iteration 8/25 | Loss: 0.00100601
Iteration 9/25 | Loss: 0.00100601
Iteration 10/25 | Loss: 0.00100601
Iteration 11/25 | Loss: 0.00100601
Iteration 12/25 | Loss: 0.00100601
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010060096392408013, 0.0010060096392408013, 0.0010060096392408013, 0.0010060096392408013, 0.0010060096392408013]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010060096392408013

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.69010222
Iteration 2/25 | Loss: 0.00089790
Iteration 3/25 | Loss: 0.00089789
Iteration 4/25 | Loss: 0.00089789
Iteration 5/25 | Loss: 0.00089789
Iteration 6/25 | Loss: 0.00089789
Iteration 7/25 | Loss: 0.00089789
Iteration 8/25 | Loss: 0.00089789
Iteration 9/25 | Loss: 0.00089789
Iteration 10/25 | Loss: 0.00089789
Iteration 11/25 | Loss: 0.00089789
Iteration 12/25 | Loss: 0.00089789
Iteration 13/25 | Loss: 0.00089789
Iteration 14/25 | Loss: 0.00089789
Iteration 15/25 | Loss: 0.00089789
Iteration 16/25 | Loss: 0.00089789
Iteration 17/25 | Loss: 0.00089789
Iteration 18/25 | Loss: 0.00089789
Iteration 19/25 | Loss: 0.00089789
Iteration 20/25 | Loss: 0.00089789
Iteration 21/25 | Loss: 0.00089789
Iteration 22/25 | Loss: 0.00089789
Iteration 23/25 | Loss: 0.00089789
Iteration 24/25 | Loss: 0.00089789
Iteration 25/25 | Loss: 0.00089789

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00089789
Iteration 2/1000 | Loss: 0.00005146
Iteration 3/1000 | Loss: 0.00003782
Iteration 4/1000 | Loss: 0.00003351
Iteration 5/1000 | Loss: 0.00003212
Iteration 6/1000 | Loss: 0.00003065
Iteration 7/1000 | Loss: 0.00003009
Iteration 8/1000 | Loss: 0.00002945
Iteration 9/1000 | Loss: 0.00002900
Iteration 10/1000 | Loss: 0.00002864
Iteration 11/1000 | Loss: 0.00002839
Iteration 12/1000 | Loss: 0.00002820
Iteration 13/1000 | Loss: 0.00002809
Iteration 14/1000 | Loss: 0.00002799
Iteration 15/1000 | Loss: 0.00002790
Iteration 16/1000 | Loss: 0.00002784
Iteration 17/1000 | Loss: 0.00002784
Iteration 18/1000 | Loss: 0.00002774
Iteration 19/1000 | Loss: 0.00002770
Iteration 20/1000 | Loss: 0.00002767
Iteration 21/1000 | Loss: 0.00002767
Iteration 22/1000 | Loss: 0.00002764
Iteration 23/1000 | Loss: 0.00002764
Iteration 24/1000 | Loss: 0.00002763
Iteration 25/1000 | Loss: 0.00002763
Iteration 26/1000 | Loss: 0.00002761
Iteration 27/1000 | Loss: 0.00002761
Iteration 28/1000 | Loss: 0.00002760
Iteration 29/1000 | Loss: 0.00002760
Iteration 30/1000 | Loss: 0.00002760
Iteration 31/1000 | Loss: 0.00002760
Iteration 32/1000 | Loss: 0.00002760
Iteration 33/1000 | Loss: 0.00002760
Iteration 34/1000 | Loss: 0.00002760
Iteration 35/1000 | Loss: 0.00002759
Iteration 36/1000 | Loss: 0.00002759
Iteration 37/1000 | Loss: 0.00002759
Iteration 38/1000 | Loss: 0.00002759
Iteration 39/1000 | Loss: 0.00002759
Iteration 40/1000 | Loss: 0.00002759
Iteration 41/1000 | Loss: 0.00002759
Iteration 42/1000 | Loss: 0.00002759
Iteration 43/1000 | Loss: 0.00002759
Iteration 44/1000 | Loss: 0.00002759
Iteration 45/1000 | Loss: 0.00002759
Iteration 46/1000 | Loss: 0.00002759
Iteration 47/1000 | Loss: 0.00002758
Iteration 48/1000 | Loss: 0.00002758
Iteration 49/1000 | Loss: 0.00002758
Iteration 50/1000 | Loss: 0.00002758
Iteration 51/1000 | Loss: 0.00002758
Iteration 52/1000 | Loss: 0.00002758
Iteration 53/1000 | Loss: 0.00002758
Iteration 54/1000 | Loss: 0.00002757
Iteration 55/1000 | Loss: 0.00002757
Iteration 56/1000 | Loss: 0.00002757
Iteration 57/1000 | Loss: 0.00002757
Iteration 58/1000 | Loss: 0.00002756
Iteration 59/1000 | Loss: 0.00002756
Iteration 60/1000 | Loss: 0.00002756
Iteration 61/1000 | Loss: 0.00002756
Iteration 62/1000 | Loss: 0.00002756
Iteration 63/1000 | Loss: 0.00002756
Iteration 64/1000 | Loss: 0.00002755
Iteration 65/1000 | Loss: 0.00002755
Iteration 66/1000 | Loss: 0.00002755
Iteration 67/1000 | Loss: 0.00002755
Iteration 68/1000 | Loss: 0.00002755
Iteration 69/1000 | Loss: 0.00002755
Iteration 70/1000 | Loss: 0.00002755
Iteration 71/1000 | Loss: 0.00002754
Iteration 72/1000 | Loss: 0.00002754
Iteration 73/1000 | Loss: 0.00002753
Iteration 74/1000 | Loss: 0.00002753
Iteration 75/1000 | Loss: 0.00002753
Iteration 76/1000 | Loss: 0.00002752
Iteration 77/1000 | Loss: 0.00002752
Iteration 78/1000 | Loss: 0.00002752
Iteration 79/1000 | Loss: 0.00002751
Iteration 80/1000 | Loss: 0.00002751
Iteration 81/1000 | Loss: 0.00002751
Iteration 82/1000 | Loss: 0.00002750
Iteration 83/1000 | Loss: 0.00002749
Iteration 84/1000 | Loss: 0.00002749
Iteration 85/1000 | Loss: 0.00002749
Iteration 86/1000 | Loss: 0.00002749
Iteration 87/1000 | Loss: 0.00002749
Iteration 88/1000 | Loss: 0.00002749
Iteration 89/1000 | Loss: 0.00002748
Iteration 90/1000 | Loss: 0.00002747
Iteration 91/1000 | Loss: 0.00002747
Iteration 92/1000 | Loss: 0.00002747
Iteration 93/1000 | Loss: 0.00002746
Iteration 94/1000 | Loss: 0.00002746
Iteration 95/1000 | Loss: 0.00002746
Iteration 96/1000 | Loss: 0.00002746
Iteration 97/1000 | Loss: 0.00002746
Iteration 98/1000 | Loss: 0.00002746
Iteration 99/1000 | Loss: 0.00002746
Iteration 100/1000 | Loss: 0.00002746
Iteration 101/1000 | Loss: 0.00002746
Iteration 102/1000 | Loss: 0.00002746
Iteration 103/1000 | Loss: 0.00002746
Iteration 104/1000 | Loss: 0.00002746
Iteration 105/1000 | Loss: 0.00002746
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 105. Stopping optimization.
Last 5 losses: [2.7461010176921263e-05, 2.7461010176921263e-05, 2.7461010176921263e-05, 2.7461010176921263e-05, 2.7461010176921263e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7461010176921263e-05

Optimization complete. Final v2v error: 4.491333961486816 mm

Highest mean error: 4.7525715827941895 mm for frame 191

Lowest mean error: 3.909754991531372 mm for frame 11

Saving results

Total time: 46.555569648742676
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00686839
Iteration 2/25 | Loss: 0.00145443
Iteration 3/25 | Loss: 0.00099840
Iteration 4/25 | Loss: 0.00093770
Iteration 5/25 | Loss: 0.00089832
Iteration 6/25 | Loss: 0.00089330
Iteration 7/25 | Loss: 0.00089210
Iteration 8/25 | Loss: 0.00089174
Iteration 9/25 | Loss: 0.00089167
Iteration 10/25 | Loss: 0.00089167
Iteration 11/25 | Loss: 0.00089167
Iteration 12/25 | Loss: 0.00089167
Iteration 13/25 | Loss: 0.00089167
Iteration 14/25 | Loss: 0.00089167
Iteration 15/25 | Loss: 0.00089167
Iteration 16/25 | Loss: 0.00089167
Iteration 17/25 | Loss: 0.00089167
Iteration 18/25 | Loss: 0.00089167
Iteration 19/25 | Loss: 0.00089167
Iteration 20/25 | Loss: 0.00089167
Iteration 21/25 | Loss: 0.00089167
Iteration 22/25 | Loss: 0.00089167
Iteration 23/25 | Loss: 0.00089167
Iteration 24/25 | Loss: 0.00089167
Iteration 25/25 | Loss: 0.00089167

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.02881813
Iteration 2/25 | Loss: 0.00073191
Iteration 3/25 | Loss: 0.00073186
Iteration 4/25 | Loss: 0.00073186
Iteration 5/25 | Loss: 0.00073186
Iteration 6/25 | Loss: 0.00073186
Iteration 7/25 | Loss: 0.00073186
Iteration 8/25 | Loss: 0.00073186
Iteration 9/25 | Loss: 0.00073186
Iteration 10/25 | Loss: 0.00073186
Iteration 11/25 | Loss: 0.00073186
Iteration 12/25 | Loss: 0.00073186
Iteration 13/25 | Loss: 0.00073186
Iteration 14/25 | Loss: 0.00073186
Iteration 15/25 | Loss: 0.00073186
Iteration 16/25 | Loss: 0.00073186
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007318599964492023, 0.0007318599964492023, 0.0007318599964492023, 0.0007318599964492023, 0.0007318599964492023]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007318599964492023

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073186
Iteration 2/1000 | Loss: 0.00002730
Iteration 3/1000 | Loss: 0.00001941
Iteration 4/1000 | Loss: 0.00001841
Iteration 5/1000 | Loss: 0.00001764
Iteration 6/1000 | Loss: 0.00001716
Iteration 7/1000 | Loss: 0.00001679
Iteration 8/1000 | Loss: 0.00001658
Iteration 9/1000 | Loss: 0.00001640
Iteration 10/1000 | Loss: 0.00001631
Iteration 11/1000 | Loss: 0.00001630
Iteration 12/1000 | Loss: 0.00001629
Iteration 13/1000 | Loss: 0.00001627
Iteration 14/1000 | Loss: 0.00001626
Iteration 15/1000 | Loss: 0.00001625
Iteration 16/1000 | Loss: 0.00001623
Iteration 17/1000 | Loss: 0.00001621
Iteration 18/1000 | Loss: 0.00001615
Iteration 19/1000 | Loss: 0.00001614
Iteration 20/1000 | Loss: 0.00001613
Iteration 21/1000 | Loss: 0.00001613
Iteration 22/1000 | Loss: 0.00001613
Iteration 23/1000 | Loss: 0.00001612
Iteration 24/1000 | Loss: 0.00001612
Iteration 25/1000 | Loss: 0.00001612
Iteration 26/1000 | Loss: 0.00001612
Iteration 27/1000 | Loss: 0.00001611
Iteration 28/1000 | Loss: 0.00001611
Iteration 29/1000 | Loss: 0.00001610
Iteration 30/1000 | Loss: 0.00001610
Iteration 31/1000 | Loss: 0.00001609
Iteration 32/1000 | Loss: 0.00001608
Iteration 33/1000 | Loss: 0.00001608
Iteration 34/1000 | Loss: 0.00001607
Iteration 35/1000 | Loss: 0.00001606
Iteration 36/1000 | Loss: 0.00001606
Iteration 37/1000 | Loss: 0.00001606
Iteration 38/1000 | Loss: 0.00001605
Iteration 39/1000 | Loss: 0.00001605
Iteration 40/1000 | Loss: 0.00001605
Iteration 41/1000 | Loss: 0.00001605
Iteration 42/1000 | Loss: 0.00001605
Iteration 43/1000 | Loss: 0.00001604
Iteration 44/1000 | Loss: 0.00001604
Iteration 45/1000 | Loss: 0.00001604
Iteration 46/1000 | Loss: 0.00001603
Iteration 47/1000 | Loss: 0.00001603
Iteration 48/1000 | Loss: 0.00001603
Iteration 49/1000 | Loss: 0.00001602
Iteration 50/1000 | Loss: 0.00001602
Iteration 51/1000 | Loss: 0.00001602
Iteration 52/1000 | Loss: 0.00001601
Iteration 53/1000 | Loss: 0.00001601
Iteration 54/1000 | Loss: 0.00001601
Iteration 55/1000 | Loss: 0.00001600
Iteration 56/1000 | Loss: 0.00001600
Iteration 57/1000 | Loss: 0.00001600
Iteration 58/1000 | Loss: 0.00001599
Iteration 59/1000 | Loss: 0.00001599
Iteration 60/1000 | Loss: 0.00001598
Iteration 61/1000 | Loss: 0.00001598
Iteration 62/1000 | Loss: 0.00001598
Iteration 63/1000 | Loss: 0.00001598
Iteration 64/1000 | Loss: 0.00001598
Iteration 65/1000 | Loss: 0.00001598
Iteration 66/1000 | Loss: 0.00001597
Iteration 67/1000 | Loss: 0.00001597
Iteration 68/1000 | Loss: 0.00001597
Iteration 69/1000 | Loss: 0.00001597
Iteration 70/1000 | Loss: 0.00001597
Iteration 71/1000 | Loss: 0.00001597
Iteration 72/1000 | Loss: 0.00001597
Iteration 73/1000 | Loss: 0.00001596
Iteration 74/1000 | Loss: 0.00001596
Iteration 75/1000 | Loss: 0.00001596
Iteration 76/1000 | Loss: 0.00001596
Iteration 77/1000 | Loss: 0.00001595
Iteration 78/1000 | Loss: 0.00001595
Iteration 79/1000 | Loss: 0.00001595
Iteration 80/1000 | Loss: 0.00001594
Iteration 81/1000 | Loss: 0.00001594
Iteration 82/1000 | Loss: 0.00001594
Iteration 83/1000 | Loss: 0.00001594
Iteration 84/1000 | Loss: 0.00001594
Iteration 85/1000 | Loss: 0.00001594
Iteration 86/1000 | Loss: 0.00001594
Iteration 87/1000 | Loss: 0.00001594
Iteration 88/1000 | Loss: 0.00001593
Iteration 89/1000 | Loss: 0.00001593
Iteration 90/1000 | Loss: 0.00001593
Iteration 91/1000 | Loss: 0.00001593
Iteration 92/1000 | Loss: 0.00001593
Iteration 93/1000 | Loss: 0.00001593
Iteration 94/1000 | Loss: 0.00001593
Iteration 95/1000 | Loss: 0.00001593
Iteration 96/1000 | Loss: 0.00001593
Iteration 97/1000 | Loss: 0.00001593
Iteration 98/1000 | Loss: 0.00001592
Iteration 99/1000 | Loss: 0.00001592
Iteration 100/1000 | Loss: 0.00001592
Iteration 101/1000 | Loss: 0.00001592
Iteration 102/1000 | Loss: 0.00001592
Iteration 103/1000 | Loss: 0.00001592
Iteration 104/1000 | Loss: 0.00001592
Iteration 105/1000 | Loss: 0.00001591
Iteration 106/1000 | Loss: 0.00001591
Iteration 107/1000 | Loss: 0.00001591
Iteration 108/1000 | Loss: 0.00001591
Iteration 109/1000 | Loss: 0.00001591
Iteration 110/1000 | Loss: 0.00001591
Iteration 111/1000 | Loss: 0.00001591
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 111. Stopping optimization.
Last 5 losses: [1.5910154615994543e-05, 1.5910154615994543e-05, 1.5910154615994543e-05, 1.5910154615994543e-05, 1.5910154615994543e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5910154615994543e-05

Optimization complete. Final v2v error: 3.3937571048736572 mm

Highest mean error: 4.478456974029541 mm for frame 93

Lowest mean error: 2.884059429168701 mm for frame 54

Saving results

Total time: 42.126415967941284
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00644616
Iteration 2/25 | Loss: 0.00101489
Iteration 3/25 | Loss: 0.00091573
Iteration 4/25 | Loss: 0.00089380
Iteration 5/25 | Loss: 0.00088672
Iteration 6/25 | Loss: 0.00088453
Iteration 7/25 | Loss: 0.00088414
Iteration 8/25 | Loss: 0.00088414
Iteration 9/25 | Loss: 0.00088414
Iteration 10/25 | Loss: 0.00088414
Iteration 11/25 | Loss: 0.00088414
Iteration 12/25 | Loss: 0.00088414
Iteration 13/25 | Loss: 0.00088414
Iteration 14/25 | Loss: 0.00088414
Iteration 15/25 | Loss: 0.00088414
Iteration 16/25 | Loss: 0.00088414
Iteration 17/25 | Loss: 0.00088414
Iteration 18/25 | Loss: 0.00088414
Iteration 19/25 | Loss: 0.00088414
Iteration 20/25 | Loss: 0.00088414
Iteration 21/25 | Loss: 0.00088414
Iteration 22/25 | Loss: 0.00088414
Iteration 23/25 | Loss: 0.00088414
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0008841389790177345, 0.0008841389790177345, 0.0008841389790177345, 0.0008841389790177345, 0.0008841389790177345]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008841389790177345

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.04827642
Iteration 2/25 | Loss: 0.00079219
Iteration 3/25 | Loss: 0.00079219
Iteration 4/25 | Loss: 0.00079219
Iteration 5/25 | Loss: 0.00079219
Iteration 6/25 | Loss: 0.00079219
Iteration 7/25 | Loss: 0.00079219
Iteration 8/25 | Loss: 0.00079219
Iteration 9/25 | Loss: 0.00079219
Iteration 10/25 | Loss: 0.00079219
Iteration 11/25 | Loss: 0.00079219
Iteration 12/25 | Loss: 0.00079219
Iteration 13/25 | Loss: 0.00079219
Iteration 14/25 | Loss: 0.00079219
Iteration 15/25 | Loss: 0.00079219
Iteration 16/25 | Loss: 0.00079219
Iteration 17/25 | Loss: 0.00079219
Iteration 18/25 | Loss: 0.00079219
Iteration 19/25 | Loss: 0.00079219
Iteration 20/25 | Loss: 0.00079219
Iteration 21/25 | Loss: 0.00079219
Iteration 22/25 | Loss: 0.00079219
Iteration 23/25 | Loss: 0.00079219
Iteration 24/25 | Loss: 0.00079219
Iteration 25/25 | Loss: 0.00079219
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0007921874057501554, 0.0007921874057501554, 0.0007921874057501554, 0.0007921874057501554, 0.0007921874057501554]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007921874057501554

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079219
Iteration 2/1000 | Loss: 0.00001958
Iteration 3/1000 | Loss: 0.00001496
Iteration 4/1000 | Loss: 0.00001415
Iteration 5/1000 | Loss: 0.00001348
Iteration 6/1000 | Loss: 0.00001316
Iteration 7/1000 | Loss: 0.00001302
Iteration 8/1000 | Loss: 0.00001301
Iteration 9/1000 | Loss: 0.00001293
Iteration 10/1000 | Loss: 0.00001293
Iteration 11/1000 | Loss: 0.00001293
Iteration 12/1000 | Loss: 0.00001293
Iteration 13/1000 | Loss: 0.00001293
Iteration 14/1000 | Loss: 0.00001293
Iteration 15/1000 | Loss: 0.00001290
Iteration 16/1000 | Loss: 0.00001289
Iteration 17/1000 | Loss: 0.00001289
Iteration 18/1000 | Loss: 0.00001289
Iteration 19/1000 | Loss: 0.00001289
Iteration 20/1000 | Loss: 0.00001289
Iteration 21/1000 | Loss: 0.00001289
Iteration 22/1000 | Loss: 0.00001289
Iteration 23/1000 | Loss: 0.00001289
Iteration 24/1000 | Loss: 0.00001288
Iteration 25/1000 | Loss: 0.00001287
Iteration 26/1000 | Loss: 0.00001287
Iteration 27/1000 | Loss: 0.00001286
Iteration 28/1000 | Loss: 0.00001286
Iteration 29/1000 | Loss: 0.00001286
Iteration 30/1000 | Loss: 0.00001285
Iteration 31/1000 | Loss: 0.00001284
Iteration 32/1000 | Loss: 0.00001284
Iteration 33/1000 | Loss: 0.00001284
Iteration 34/1000 | Loss: 0.00001284
Iteration 35/1000 | Loss: 0.00001284
Iteration 36/1000 | Loss: 0.00001284
Iteration 37/1000 | Loss: 0.00001283
Iteration 38/1000 | Loss: 0.00001283
Iteration 39/1000 | Loss: 0.00001283
Iteration 40/1000 | Loss: 0.00001283
Iteration 41/1000 | Loss: 0.00001282
Iteration 42/1000 | Loss: 0.00001282
Iteration 43/1000 | Loss: 0.00001282
Iteration 44/1000 | Loss: 0.00001282
Iteration 45/1000 | Loss: 0.00001281
Iteration 46/1000 | Loss: 0.00001281
Iteration 47/1000 | Loss: 0.00001281
Iteration 48/1000 | Loss: 0.00001281
Iteration 49/1000 | Loss: 0.00001281
Iteration 50/1000 | Loss: 0.00001280
Iteration 51/1000 | Loss: 0.00001279
Iteration 52/1000 | Loss: 0.00001279
Iteration 53/1000 | Loss: 0.00001279
Iteration 54/1000 | Loss: 0.00001279
Iteration 55/1000 | Loss: 0.00001279
Iteration 56/1000 | Loss: 0.00001279
Iteration 57/1000 | Loss: 0.00001279
Iteration 58/1000 | Loss: 0.00001279
Iteration 59/1000 | Loss: 0.00001279
Iteration 60/1000 | Loss: 0.00001279
Iteration 61/1000 | Loss: 0.00001279
Iteration 62/1000 | Loss: 0.00001279
Iteration 63/1000 | Loss: 0.00001278
Iteration 64/1000 | Loss: 0.00001278
Iteration 65/1000 | Loss: 0.00001278
Iteration 66/1000 | Loss: 0.00001278
Iteration 67/1000 | Loss: 0.00001278
Iteration 68/1000 | Loss: 0.00001277
Iteration 69/1000 | Loss: 0.00001277
Iteration 70/1000 | Loss: 0.00001277
Iteration 71/1000 | Loss: 0.00001277
Iteration 72/1000 | Loss: 0.00001276
Iteration 73/1000 | Loss: 0.00001276
Iteration 74/1000 | Loss: 0.00001276
Iteration 75/1000 | Loss: 0.00001276
Iteration 76/1000 | Loss: 0.00001276
Iteration 77/1000 | Loss: 0.00001276
Iteration 78/1000 | Loss: 0.00001276
Iteration 79/1000 | Loss: 0.00001276
Iteration 80/1000 | Loss: 0.00001276
Iteration 81/1000 | Loss: 0.00001276
Iteration 82/1000 | Loss: 0.00001275
Iteration 83/1000 | Loss: 0.00001275
Iteration 84/1000 | Loss: 0.00001275
Iteration 85/1000 | Loss: 0.00001275
Iteration 86/1000 | Loss: 0.00001275
Iteration 87/1000 | Loss: 0.00001275
Iteration 88/1000 | Loss: 0.00001275
Iteration 89/1000 | Loss: 0.00001275
Iteration 90/1000 | Loss: 0.00001275
Iteration 91/1000 | Loss: 0.00001275
Iteration 92/1000 | Loss: 0.00001275
Iteration 93/1000 | Loss: 0.00001275
Iteration 94/1000 | Loss: 0.00001275
Iteration 95/1000 | Loss: 0.00001275
Iteration 96/1000 | Loss: 0.00001275
Iteration 97/1000 | Loss: 0.00001275
Iteration 98/1000 | Loss: 0.00001275
Iteration 99/1000 | Loss: 0.00001275
Iteration 100/1000 | Loss: 0.00001275
Iteration 101/1000 | Loss: 0.00001275
Iteration 102/1000 | Loss: 0.00001275
Iteration 103/1000 | Loss: 0.00001275
Iteration 104/1000 | Loss: 0.00001275
Iteration 105/1000 | Loss: 0.00001275
Iteration 106/1000 | Loss: 0.00001275
Iteration 107/1000 | Loss: 0.00001275
Iteration 108/1000 | Loss: 0.00001275
Iteration 109/1000 | Loss: 0.00001275
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 109. Stopping optimization.
Last 5 losses: [1.2746389984386042e-05, 1.2746389984386042e-05, 1.2746389984386042e-05, 1.2746389984386042e-05, 1.2746389984386042e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2746389984386042e-05

Optimization complete. Final v2v error: 3.033121347427368 mm

Highest mean error: 3.333444356918335 mm for frame 105

Lowest mean error: 2.68536639213562 mm for frame 75

Saving results

Total time: 26.837538957595825
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00417376
Iteration 2/25 | Loss: 0.00103806
Iteration 3/25 | Loss: 0.00092289
Iteration 4/25 | Loss: 0.00089920
Iteration 5/25 | Loss: 0.00089006
Iteration 6/25 | Loss: 0.00088785
Iteration 7/25 | Loss: 0.00088717
Iteration 8/25 | Loss: 0.00088716
Iteration 9/25 | Loss: 0.00088716
Iteration 10/25 | Loss: 0.00088716
Iteration 11/25 | Loss: 0.00088716
Iteration 12/25 | Loss: 0.00088716
Iteration 13/25 | Loss: 0.00088716
Iteration 14/25 | Loss: 0.00088716
Iteration 15/25 | Loss: 0.00088716
Iteration 16/25 | Loss: 0.00088716
Iteration 17/25 | Loss: 0.00088716
Iteration 18/25 | Loss: 0.00088716
Iteration 19/25 | Loss: 0.00088716
Iteration 20/25 | Loss: 0.00088716
Iteration 21/25 | Loss: 0.00088716
Iteration 22/25 | Loss: 0.00088716
Iteration 23/25 | Loss: 0.00088716
Iteration 24/25 | Loss: 0.00088716
Iteration 25/25 | Loss: 0.00088716

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.95440722
Iteration 2/25 | Loss: 0.00077561
Iteration 3/25 | Loss: 0.00077561
Iteration 4/25 | Loss: 0.00077561
Iteration 5/25 | Loss: 0.00077560
Iteration 6/25 | Loss: 0.00077560
Iteration 7/25 | Loss: 0.00077560
Iteration 8/25 | Loss: 0.00077560
Iteration 9/25 | Loss: 0.00077560
Iteration 10/25 | Loss: 0.00077560
Iteration 11/25 | Loss: 0.00077560
Iteration 12/25 | Loss: 0.00077560
Iteration 13/25 | Loss: 0.00077560
Iteration 14/25 | Loss: 0.00077560
Iteration 15/25 | Loss: 0.00077560
Iteration 16/25 | Loss: 0.00077560
Iteration 17/25 | Loss: 0.00077560
Iteration 18/25 | Loss: 0.00077560
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007756025297567248, 0.0007756025297567248, 0.0007756025297567248, 0.0007756025297567248, 0.0007756025297567248]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007756025297567248

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00077560
Iteration 2/1000 | Loss: 0.00002312
Iteration 3/1000 | Loss: 0.00001890
Iteration 4/1000 | Loss: 0.00001746
Iteration 5/1000 | Loss: 0.00001688
Iteration 6/1000 | Loss: 0.00001655
Iteration 7/1000 | Loss: 0.00001620
Iteration 8/1000 | Loss: 0.00001595
Iteration 9/1000 | Loss: 0.00001583
Iteration 10/1000 | Loss: 0.00001583
Iteration 11/1000 | Loss: 0.00001582
Iteration 12/1000 | Loss: 0.00001580
Iteration 13/1000 | Loss: 0.00001579
Iteration 14/1000 | Loss: 0.00001579
Iteration 15/1000 | Loss: 0.00001578
Iteration 16/1000 | Loss: 0.00001578
Iteration 17/1000 | Loss: 0.00001577
Iteration 18/1000 | Loss: 0.00001577
Iteration 19/1000 | Loss: 0.00001574
Iteration 20/1000 | Loss: 0.00001574
Iteration 21/1000 | Loss: 0.00001574
Iteration 22/1000 | Loss: 0.00001573
Iteration 23/1000 | Loss: 0.00001573
Iteration 24/1000 | Loss: 0.00001573
Iteration 25/1000 | Loss: 0.00001572
Iteration 26/1000 | Loss: 0.00001572
Iteration 27/1000 | Loss: 0.00001572
Iteration 28/1000 | Loss: 0.00001571
Iteration 29/1000 | Loss: 0.00001571
Iteration 30/1000 | Loss: 0.00001570
Iteration 31/1000 | Loss: 0.00001570
Iteration 32/1000 | Loss: 0.00001570
Iteration 33/1000 | Loss: 0.00001570
Iteration 34/1000 | Loss: 0.00001570
Iteration 35/1000 | Loss: 0.00001569
Iteration 36/1000 | Loss: 0.00001569
Iteration 37/1000 | Loss: 0.00001569
Iteration 38/1000 | Loss: 0.00001568
Iteration 39/1000 | Loss: 0.00001568
Iteration 40/1000 | Loss: 0.00001568
Iteration 41/1000 | Loss: 0.00001568
Iteration 42/1000 | Loss: 0.00001567
Iteration 43/1000 | Loss: 0.00001567
Iteration 44/1000 | Loss: 0.00001567
Iteration 45/1000 | Loss: 0.00001567
Iteration 46/1000 | Loss: 0.00001567
Iteration 47/1000 | Loss: 0.00001566
Iteration 48/1000 | Loss: 0.00001566
Iteration 49/1000 | Loss: 0.00001566
Iteration 50/1000 | Loss: 0.00001566
Iteration 51/1000 | Loss: 0.00001566
Iteration 52/1000 | Loss: 0.00001566
Iteration 53/1000 | Loss: 0.00001566
Iteration 54/1000 | Loss: 0.00001566
Iteration 55/1000 | Loss: 0.00001566
Iteration 56/1000 | Loss: 0.00001566
Iteration 57/1000 | Loss: 0.00001566
Iteration 58/1000 | Loss: 0.00001566
Iteration 59/1000 | Loss: 0.00001566
Iteration 60/1000 | Loss: 0.00001566
Iteration 61/1000 | Loss: 0.00001566
Iteration 62/1000 | Loss: 0.00001566
Iteration 63/1000 | Loss: 0.00001566
Iteration 64/1000 | Loss: 0.00001566
Iteration 65/1000 | Loss: 0.00001566
Iteration 66/1000 | Loss: 0.00001566
Iteration 67/1000 | Loss: 0.00001566
Iteration 68/1000 | Loss: 0.00001566
Iteration 69/1000 | Loss: 0.00001566
Iteration 70/1000 | Loss: 0.00001566
Iteration 71/1000 | Loss: 0.00001566
Iteration 72/1000 | Loss: 0.00001566
Iteration 73/1000 | Loss: 0.00001566
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 73. Stopping optimization.
Last 5 losses: [1.565685852256138e-05, 1.565685852256138e-05, 1.565685852256138e-05, 1.565685852256138e-05, 1.565685852256138e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.565685852256138e-05

Optimization complete. Final v2v error: 3.4043266773223877 mm

Highest mean error: 3.6541953086853027 mm for frame 45

Lowest mean error: 3.111643075942993 mm for frame 137

Saving results

Total time: 26.626394271850586
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00417735
Iteration 2/25 | Loss: 0.00105941
Iteration 3/25 | Loss: 0.00096995
Iteration 4/25 | Loss: 0.00094664
Iteration 5/25 | Loss: 0.00093798
Iteration 6/25 | Loss: 0.00093460
Iteration 7/25 | Loss: 0.00093333
Iteration 8/25 | Loss: 0.00093324
Iteration 9/25 | Loss: 0.00093324
Iteration 10/25 | Loss: 0.00093324
Iteration 11/25 | Loss: 0.00093324
Iteration 12/25 | Loss: 0.00093324
Iteration 13/25 | Loss: 0.00093324
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0009332414483651519, 0.0009332414483651519, 0.0009332414483651519, 0.0009332414483651519, 0.0009332414483651519]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009332414483651519

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56110907
Iteration 2/25 | Loss: 0.00101440
Iteration 3/25 | Loss: 0.00101440
Iteration 4/25 | Loss: 0.00101440
Iteration 5/25 | Loss: 0.00101440
Iteration 6/25 | Loss: 0.00101440
Iteration 7/25 | Loss: 0.00101440
Iteration 8/25 | Loss: 0.00101440
Iteration 9/25 | Loss: 0.00101440
Iteration 10/25 | Loss: 0.00101440
Iteration 11/25 | Loss: 0.00101440
Iteration 12/25 | Loss: 0.00101440
Iteration 13/25 | Loss: 0.00101440
Iteration 14/25 | Loss: 0.00101440
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0010143963154405355, 0.0010143963154405355, 0.0010143963154405355, 0.0010143963154405355, 0.0010143963154405355]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010143963154405355

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00101440
Iteration 2/1000 | Loss: 0.00003551
Iteration 3/1000 | Loss: 0.00002473
Iteration 4/1000 | Loss: 0.00002188
Iteration 5/1000 | Loss: 0.00002041
Iteration 6/1000 | Loss: 0.00001959
Iteration 7/1000 | Loss: 0.00001904
Iteration 8/1000 | Loss: 0.00001861
Iteration 9/1000 | Loss: 0.00001830
Iteration 10/1000 | Loss: 0.00001808
Iteration 11/1000 | Loss: 0.00001791
Iteration 12/1000 | Loss: 0.00001788
Iteration 13/1000 | Loss: 0.00001780
Iteration 14/1000 | Loss: 0.00001780
Iteration 15/1000 | Loss: 0.00001775
Iteration 16/1000 | Loss: 0.00001774
Iteration 17/1000 | Loss: 0.00001773
Iteration 18/1000 | Loss: 0.00001772
Iteration 19/1000 | Loss: 0.00001772
Iteration 20/1000 | Loss: 0.00001771
Iteration 21/1000 | Loss: 0.00001771
Iteration 22/1000 | Loss: 0.00001770
Iteration 23/1000 | Loss: 0.00001769
Iteration 24/1000 | Loss: 0.00001769
Iteration 25/1000 | Loss: 0.00001767
Iteration 26/1000 | Loss: 0.00001765
Iteration 27/1000 | Loss: 0.00001765
Iteration 28/1000 | Loss: 0.00001764
Iteration 29/1000 | Loss: 0.00001764
Iteration 30/1000 | Loss: 0.00001763
Iteration 31/1000 | Loss: 0.00001763
Iteration 32/1000 | Loss: 0.00001763
Iteration 33/1000 | Loss: 0.00001762
Iteration 34/1000 | Loss: 0.00001760
Iteration 35/1000 | Loss: 0.00001760
Iteration 36/1000 | Loss: 0.00001759
Iteration 37/1000 | Loss: 0.00001759
Iteration 38/1000 | Loss: 0.00001758
Iteration 39/1000 | Loss: 0.00001758
Iteration 40/1000 | Loss: 0.00001758
Iteration 41/1000 | Loss: 0.00001757
Iteration 42/1000 | Loss: 0.00001757
Iteration 43/1000 | Loss: 0.00001756
Iteration 44/1000 | Loss: 0.00001756
Iteration 45/1000 | Loss: 0.00001753
Iteration 46/1000 | Loss: 0.00001753
Iteration 47/1000 | Loss: 0.00001752
Iteration 48/1000 | Loss: 0.00001752
Iteration 49/1000 | Loss: 0.00001752
Iteration 50/1000 | Loss: 0.00001751
Iteration 51/1000 | Loss: 0.00001751
Iteration 52/1000 | Loss: 0.00001751
Iteration 53/1000 | Loss: 0.00001750
Iteration 54/1000 | Loss: 0.00001750
Iteration 55/1000 | Loss: 0.00001749
Iteration 56/1000 | Loss: 0.00001749
Iteration 57/1000 | Loss: 0.00001748
Iteration 58/1000 | Loss: 0.00001748
Iteration 59/1000 | Loss: 0.00001748
Iteration 60/1000 | Loss: 0.00001748
Iteration 61/1000 | Loss: 0.00001748
Iteration 62/1000 | Loss: 0.00001748
Iteration 63/1000 | Loss: 0.00001748
Iteration 64/1000 | Loss: 0.00001747
Iteration 65/1000 | Loss: 0.00001747
Iteration 66/1000 | Loss: 0.00001747
Iteration 67/1000 | Loss: 0.00001747
Iteration 68/1000 | Loss: 0.00001747
Iteration 69/1000 | Loss: 0.00001747
Iteration 70/1000 | Loss: 0.00001747
Iteration 71/1000 | Loss: 0.00001747
Iteration 72/1000 | Loss: 0.00001747
Iteration 73/1000 | Loss: 0.00001747
Iteration 74/1000 | Loss: 0.00001747
Iteration 75/1000 | Loss: 0.00001746
Iteration 76/1000 | Loss: 0.00001746
Iteration 77/1000 | Loss: 0.00001746
Iteration 78/1000 | Loss: 0.00001746
Iteration 79/1000 | Loss: 0.00001746
Iteration 80/1000 | Loss: 0.00001745
Iteration 81/1000 | Loss: 0.00001745
Iteration 82/1000 | Loss: 0.00001745
Iteration 83/1000 | Loss: 0.00001745
Iteration 84/1000 | Loss: 0.00001745
Iteration 85/1000 | Loss: 0.00001745
Iteration 86/1000 | Loss: 0.00001745
Iteration 87/1000 | Loss: 0.00001745
Iteration 88/1000 | Loss: 0.00001745
Iteration 89/1000 | Loss: 0.00001745
Iteration 90/1000 | Loss: 0.00001745
Iteration 91/1000 | Loss: 0.00001745
Iteration 92/1000 | Loss: 0.00001745
Iteration 93/1000 | Loss: 0.00001744
Iteration 94/1000 | Loss: 0.00001744
Iteration 95/1000 | Loss: 0.00001744
Iteration 96/1000 | Loss: 0.00001744
Iteration 97/1000 | Loss: 0.00001744
Iteration 98/1000 | Loss: 0.00001744
Iteration 99/1000 | Loss: 0.00001744
Iteration 100/1000 | Loss: 0.00001744
Iteration 101/1000 | Loss: 0.00001744
Iteration 102/1000 | Loss: 0.00001744
Iteration 103/1000 | Loss: 0.00001744
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 103. Stopping optimization.
Last 5 losses: [1.744311703077983e-05, 1.744311703077983e-05, 1.744311703077983e-05, 1.744311703077983e-05, 1.744311703077983e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.744311703077983e-05

Optimization complete. Final v2v error: 3.5256283283233643 mm

Highest mean error: 4.074647426605225 mm for frame 78

Lowest mean error: 3.107405662536621 mm for frame 214

Saving results

Total time: 39.02634000778198
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00887088
Iteration 2/25 | Loss: 0.00121812
Iteration 3/25 | Loss: 0.00102658
Iteration 4/25 | Loss: 0.00099125
Iteration 5/25 | Loss: 0.00098068
Iteration 6/25 | Loss: 0.00097733
Iteration 7/25 | Loss: 0.00098054
Iteration 8/25 | Loss: 0.00097855
Iteration 9/25 | Loss: 0.00097448
Iteration 10/25 | Loss: 0.00097241
Iteration 11/25 | Loss: 0.00097147
Iteration 12/25 | Loss: 0.00097111
Iteration 13/25 | Loss: 0.00097103
Iteration 14/25 | Loss: 0.00097094
Iteration 15/25 | Loss: 0.00097088
Iteration 16/25 | Loss: 0.00097087
Iteration 17/25 | Loss: 0.00097087
Iteration 18/25 | Loss: 0.00097087
Iteration 19/25 | Loss: 0.00097087
Iteration 20/25 | Loss: 0.00097087
Iteration 21/25 | Loss: 0.00097087
Iteration 22/25 | Loss: 0.00097086
Iteration 23/25 | Loss: 0.00097086
Iteration 24/25 | Loss: 0.00097086
Iteration 25/25 | Loss: 0.00097086

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51238024
Iteration 2/25 | Loss: 0.00185745
Iteration 3/25 | Loss: 0.00185744
Iteration 4/25 | Loss: 0.00185744
Iteration 5/25 | Loss: 0.00185744
Iteration 6/25 | Loss: 0.00185744
Iteration 7/25 | Loss: 0.00185744
Iteration 8/25 | Loss: 0.00185744
Iteration 9/25 | Loss: 0.00185744
Iteration 10/25 | Loss: 0.00185744
Iteration 11/25 | Loss: 0.00185744
Iteration 12/25 | Loss: 0.00185744
Iteration 13/25 | Loss: 0.00185744
Iteration 14/25 | Loss: 0.00185744
Iteration 15/25 | Loss: 0.00185744
Iteration 16/25 | Loss: 0.00185744
Iteration 17/25 | Loss: 0.00185744
Iteration 18/25 | Loss: 0.00185744
Iteration 19/25 | Loss: 0.00185744
Iteration 20/25 | Loss: 0.00185744
Iteration 21/25 | Loss: 0.00185744
Iteration 22/25 | Loss: 0.00185744
Iteration 23/25 | Loss: 0.00185744
Iteration 24/25 | Loss: 0.00185744
Iteration 25/25 | Loss: 0.00185744

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00185744
Iteration 2/1000 | Loss: 0.00018682
Iteration 3/1000 | Loss: 0.00013187
Iteration 4/1000 | Loss: 0.00011395
Iteration 5/1000 | Loss: 0.00010270
Iteration 6/1000 | Loss: 0.00009593
Iteration 7/1000 | Loss: 0.00009257
Iteration 8/1000 | Loss: 0.00008873
Iteration 9/1000 | Loss: 0.00128240
Iteration 10/1000 | Loss: 0.00011511
Iteration 11/1000 | Loss: 0.00008589
Iteration 12/1000 | Loss: 0.00059288
Iteration 13/1000 | Loss: 0.00009656
Iteration 14/1000 | Loss: 0.00008638
Iteration 15/1000 | Loss: 0.00007785
Iteration 16/1000 | Loss: 0.00007488
Iteration 17/1000 | Loss: 0.00054398
Iteration 18/1000 | Loss: 0.00008267
Iteration 19/1000 | Loss: 0.00007048
Iteration 20/1000 | Loss: 0.00006863
Iteration 21/1000 | Loss: 0.00006739
Iteration 22/1000 | Loss: 0.00134730
Iteration 23/1000 | Loss: 0.00020446
Iteration 24/1000 | Loss: 0.00006811
Iteration 25/1000 | Loss: 0.00209140
Iteration 26/1000 | Loss: 0.00687047
Iteration 27/1000 | Loss: 0.00256162
Iteration 28/1000 | Loss: 0.00017049
Iteration 29/1000 | Loss: 0.00006320
Iteration 30/1000 | Loss: 0.00058902
Iteration 31/1000 | Loss: 0.00006541
Iteration 32/1000 | Loss: 0.00062029
Iteration 33/1000 | Loss: 0.00067109
Iteration 34/1000 | Loss: 0.00006125
Iteration 35/1000 | Loss: 0.00146404
Iteration 36/1000 | Loss: 0.00212290
Iteration 37/1000 | Loss: 0.00029616
Iteration 38/1000 | Loss: 0.00074590
Iteration 39/1000 | Loss: 0.00020777
Iteration 40/1000 | Loss: 0.00008143
Iteration 41/1000 | Loss: 0.00006038
Iteration 42/1000 | Loss: 0.00005238
Iteration 43/1000 | Loss: 0.00062880
Iteration 44/1000 | Loss: 0.00047491
Iteration 45/1000 | Loss: 0.00132737
Iteration 46/1000 | Loss: 0.00005247
Iteration 47/1000 | Loss: 0.00004240
Iteration 48/1000 | Loss: 0.00003855
Iteration 49/1000 | Loss: 0.00003648
Iteration 50/1000 | Loss: 0.00030417
Iteration 51/1000 | Loss: 0.00009536
Iteration 52/1000 | Loss: 0.00028524
Iteration 53/1000 | Loss: 0.00035339
Iteration 54/1000 | Loss: 0.00010770
Iteration 55/1000 | Loss: 0.00029389
Iteration 56/1000 | Loss: 0.00012947
Iteration 57/1000 | Loss: 0.00005458
Iteration 58/1000 | Loss: 0.00049064
Iteration 59/1000 | Loss: 0.00015743
Iteration 60/1000 | Loss: 0.00016943
Iteration 61/1000 | Loss: 0.00029999
Iteration 62/1000 | Loss: 0.00004871
Iteration 63/1000 | Loss: 0.00004107
Iteration 64/1000 | Loss: 0.00003453
Iteration 65/1000 | Loss: 0.00003096
Iteration 66/1000 | Loss: 0.00002886
Iteration 67/1000 | Loss: 0.00002793
Iteration 68/1000 | Loss: 0.00067255
Iteration 69/1000 | Loss: 0.00003398
Iteration 70/1000 | Loss: 0.00002644
Iteration 71/1000 | Loss: 0.00002566
Iteration 72/1000 | Loss: 0.00141004
Iteration 73/1000 | Loss: 0.00095867
Iteration 74/1000 | Loss: 0.00035099
Iteration 75/1000 | Loss: 0.00072792
Iteration 76/1000 | Loss: 0.00021272
Iteration 77/1000 | Loss: 0.00002382
Iteration 78/1000 | Loss: 0.00002178
Iteration 79/1000 | Loss: 0.00002067
Iteration 80/1000 | Loss: 0.00002000
Iteration 81/1000 | Loss: 0.00001952
Iteration 82/1000 | Loss: 0.00001919
Iteration 83/1000 | Loss: 0.00001892
Iteration 84/1000 | Loss: 0.00001877
Iteration 85/1000 | Loss: 0.00001874
Iteration 86/1000 | Loss: 0.00001868
Iteration 87/1000 | Loss: 0.00001860
Iteration 88/1000 | Loss: 0.00090064
Iteration 89/1000 | Loss: 0.00005077
Iteration 90/1000 | Loss: 0.00002721
Iteration 91/1000 | Loss: 0.00029828
Iteration 92/1000 | Loss: 0.00062799
Iteration 93/1000 | Loss: 0.00028123
Iteration 94/1000 | Loss: 0.00063283
Iteration 95/1000 | Loss: 0.00011794
Iteration 96/1000 | Loss: 0.00001981
Iteration 97/1000 | Loss: 0.00001892
Iteration 98/1000 | Loss: 0.00001867
Iteration 99/1000 | Loss: 0.00001847
Iteration 100/1000 | Loss: 0.00001837
Iteration 101/1000 | Loss: 0.00001834
Iteration 102/1000 | Loss: 0.00001834
Iteration 103/1000 | Loss: 0.00001833
Iteration 104/1000 | Loss: 0.00001832
Iteration 105/1000 | Loss: 0.00001832
Iteration 106/1000 | Loss: 0.00001832
Iteration 107/1000 | Loss: 0.00001831
Iteration 108/1000 | Loss: 0.00001831
Iteration 109/1000 | Loss: 0.00001831
Iteration 110/1000 | Loss: 0.00001830
Iteration 111/1000 | Loss: 0.00001830
Iteration 112/1000 | Loss: 0.00001830
Iteration 113/1000 | Loss: 0.00001830
Iteration 114/1000 | Loss: 0.00001830
Iteration 115/1000 | Loss: 0.00001829
Iteration 116/1000 | Loss: 0.00001829
Iteration 117/1000 | Loss: 0.00001829
Iteration 118/1000 | Loss: 0.00001829
Iteration 119/1000 | Loss: 0.00001829
Iteration 120/1000 | Loss: 0.00001829
Iteration 121/1000 | Loss: 0.00001829
Iteration 122/1000 | Loss: 0.00001829
Iteration 123/1000 | Loss: 0.00001829
Iteration 124/1000 | Loss: 0.00001829
Iteration 125/1000 | Loss: 0.00001829
Iteration 126/1000 | Loss: 0.00001829
Iteration 127/1000 | Loss: 0.00001828
Iteration 128/1000 | Loss: 0.00001828
Iteration 129/1000 | Loss: 0.00001828
Iteration 130/1000 | Loss: 0.00001828
Iteration 131/1000 | Loss: 0.00001828
Iteration 132/1000 | Loss: 0.00001828
Iteration 133/1000 | Loss: 0.00001828
Iteration 134/1000 | Loss: 0.00001828
Iteration 135/1000 | Loss: 0.00001828
Iteration 136/1000 | Loss: 0.00001828
Iteration 137/1000 | Loss: 0.00001828
Iteration 138/1000 | Loss: 0.00001828
Iteration 139/1000 | Loss: 0.00001828
Iteration 140/1000 | Loss: 0.00001828
Iteration 141/1000 | Loss: 0.00001828
Iteration 142/1000 | Loss: 0.00001827
Iteration 143/1000 | Loss: 0.00001827
Iteration 144/1000 | Loss: 0.00001827
Iteration 145/1000 | Loss: 0.00001827
Iteration 146/1000 | Loss: 0.00001827
Iteration 147/1000 | Loss: 0.00001826
Iteration 148/1000 | Loss: 0.00001826
Iteration 149/1000 | Loss: 0.00001826
Iteration 150/1000 | Loss: 0.00001826
Iteration 151/1000 | Loss: 0.00001826
Iteration 152/1000 | Loss: 0.00001826
Iteration 153/1000 | Loss: 0.00001826
Iteration 154/1000 | Loss: 0.00001826
Iteration 155/1000 | Loss: 0.00001826
Iteration 156/1000 | Loss: 0.00001826
Iteration 157/1000 | Loss: 0.00001826
Iteration 158/1000 | Loss: 0.00001826
Iteration 159/1000 | Loss: 0.00001825
Iteration 160/1000 | Loss: 0.00001825
Iteration 161/1000 | Loss: 0.00001825
Iteration 162/1000 | Loss: 0.00001825
Iteration 163/1000 | Loss: 0.00001825
Iteration 164/1000 | Loss: 0.00001824
Iteration 165/1000 | Loss: 0.00001824
Iteration 166/1000 | Loss: 0.00001824
Iteration 167/1000 | Loss: 0.00001824
Iteration 168/1000 | Loss: 0.00001824
Iteration 169/1000 | Loss: 0.00001824
Iteration 170/1000 | Loss: 0.00001824
Iteration 171/1000 | Loss: 0.00001824
Iteration 172/1000 | Loss: 0.00001824
Iteration 173/1000 | Loss: 0.00001824
Iteration 174/1000 | Loss: 0.00001824
Iteration 175/1000 | Loss: 0.00001824
Iteration 176/1000 | Loss: 0.00001824
Iteration 177/1000 | Loss: 0.00001824
Iteration 178/1000 | Loss: 0.00001823
Iteration 179/1000 | Loss: 0.00001823
Iteration 180/1000 | Loss: 0.00001823
Iteration 181/1000 | Loss: 0.00001823
Iteration 182/1000 | Loss: 0.00001823
Iteration 183/1000 | Loss: 0.00001823
Iteration 184/1000 | Loss: 0.00001823
Iteration 185/1000 | Loss: 0.00001823
Iteration 186/1000 | Loss: 0.00001823
Iteration 187/1000 | Loss: 0.00001823
Iteration 188/1000 | Loss: 0.00001823
Iteration 189/1000 | Loss: 0.00001823
Iteration 190/1000 | Loss: 0.00001823
Iteration 191/1000 | Loss: 0.00001823
Iteration 192/1000 | Loss: 0.00001823
Iteration 193/1000 | Loss: 0.00001823
Iteration 194/1000 | Loss: 0.00001823
Iteration 195/1000 | Loss: 0.00001823
Iteration 196/1000 | Loss: 0.00001823
Iteration 197/1000 | Loss: 0.00001823
Iteration 198/1000 | Loss: 0.00001823
Iteration 199/1000 | Loss: 0.00001823
Iteration 200/1000 | Loss: 0.00001823
Iteration 201/1000 | Loss: 0.00001822
Iteration 202/1000 | Loss: 0.00001822
Iteration 203/1000 | Loss: 0.00001822
Iteration 204/1000 | Loss: 0.00001822
Iteration 205/1000 | Loss: 0.00001822
Iteration 206/1000 | Loss: 0.00001822
Iteration 207/1000 | Loss: 0.00001822
Iteration 208/1000 | Loss: 0.00001822
Iteration 209/1000 | Loss: 0.00001822
Iteration 210/1000 | Loss: 0.00001822
Iteration 211/1000 | Loss: 0.00001822
Iteration 212/1000 | Loss: 0.00001822
Iteration 213/1000 | Loss: 0.00001822
Iteration 214/1000 | Loss: 0.00001822
Iteration 215/1000 | Loss: 0.00001822
Iteration 216/1000 | Loss: 0.00001822
Iteration 217/1000 | Loss: 0.00001822
Iteration 218/1000 | Loss: 0.00001822
Iteration 219/1000 | Loss: 0.00001822
Iteration 220/1000 | Loss: 0.00001822
Iteration 221/1000 | Loss: 0.00001822
Iteration 222/1000 | Loss: 0.00001822
Iteration 223/1000 | Loss: 0.00001822
Iteration 224/1000 | Loss: 0.00001822
Iteration 225/1000 | Loss: 0.00001822
Iteration 226/1000 | Loss: 0.00001822
Iteration 227/1000 | Loss: 0.00001822
Iteration 228/1000 | Loss: 0.00001821
Iteration 229/1000 | Loss: 0.00001821
Iteration 230/1000 | Loss: 0.00001821
Iteration 231/1000 | Loss: 0.00001821
Iteration 232/1000 | Loss: 0.00001821
Iteration 233/1000 | Loss: 0.00001821
Iteration 234/1000 | Loss: 0.00001821
Iteration 235/1000 | Loss: 0.00001821
Iteration 236/1000 | Loss: 0.00001821
Iteration 237/1000 | Loss: 0.00001821
Iteration 238/1000 | Loss: 0.00001821
Iteration 239/1000 | Loss: 0.00001821
Iteration 240/1000 | Loss: 0.00001821
Iteration 241/1000 | Loss: 0.00001821
Iteration 242/1000 | Loss: 0.00001821
Iteration 243/1000 | Loss: 0.00001821
Iteration 244/1000 | Loss: 0.00001821
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 244. Stopping optimization.
Last 5 losses: [1.821077057684306e-05, 1.821077057684306e-05, 1.821077057684306e-05, 1.821077057684306e-05, 1.821077057684306e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.821077057684306e-05

Optimization complete. Final v2v error: 3.3323676586151123 mm

Highest mean error: 13.698847770690918 mm for frame 85

Lowest mean error: 2.8484833240509033 mm for frame 39

Saving results

Total time: 179.44576215744019
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405731
Iteration 2/25 | Loss: 0.00113936
Iteration 3/25 | Loss: 0.00093181
Iteration 4/25 | Loss: 0.00091537
Iteration 5/25 | Loss: 0.00090645
Iteration 6/25 | Loss: 0.00090390
Iteration 7/25 | Loss: 0.00090361
Iteration 8/25 | Loss: 0.00090361
Iteration 9/25 | Loss: 0.00090361
Iteration 10/25 | Loss: 0.00090361
Iteration 11/25 | Loss: 0.00090361
Iteration 12/25 | Loss: 0.00090361
Iteration 13/25 | Loss: 0.00090361
Iteration 14/25 | Loss: 0.00090361
Iteration 15/25 | Loss: 0.00090361
Iteration 16/25 | Loss: 0.00090361
Iteration 17/25 | Loss: 0.00090361
Iteration 18/25 | Loss: 0.00090361
Iteration 19/25 | Loss: 0.00090361
Iteration 20/25 | Loss: 0.00090361
Iteration 21/25 | Loss: 0.00090361
Iteration 22/25 | Loss: 0.00090361
Iteration 23/25 | Loss: 0.00090361
Iteration 24/25 | Loss: 0.00090361
Iteration 25/25 | Loss: 0.00090361

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79537654
Iteration 2/25 | Loss: 0.00094410
Iteration 3/25 | Loss: 0.00094410
Iteration 4/25 | Loss: 0.00094409
Iteration 5/25 | Loss: 0.00094409
Iteration 6/25 | Loss: 0.00094409
Iteration 7/25 | Loss: 0.00094409
Iteration 8/25 | Loss: 0.00094409
Iteration 9/25 | Loss: 0.00094409
Iteration 10/25 | Loss: 0.00094409
Iteration 11/25 | Loss: 0.00094409
Iteration 12/25 | Loss: 0.00094409
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009440932772122324, 0.0009440932772122324, 0.0009440932772122324, 0.0009440932772122324, 0.0009440932772122324]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009440932772122324

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00094409
Iteration 2/1000 | Loss: 0.00002580
Iteration 3/1000 | Loss: 0.00001974
Iteration 4/1000 | Loss: 0.00001793
Iteration 5/1000 | Loss: 0.00001730
Iteration 6/1000 | Loss: 0.00001658
Iteration 7/1000 | Loss: 0.00001616
Iteration 8/1000 | Loss: 0.00001592
Iteration 9/1000 | Loss: 0.00001585
Iteration 10/1000 | Loss: 0.00001585
Iteration 11/1000 | Loss: 0.00001573
Iteration 12/1000 | Loss: 0.00001569
Iteration 13/1000 | Loss: 0.00001568
Iteration 14/1000 | Loss: 0.00001567
Iteration 15/1000 | Loss: 0.00001566
Iteration 16/1000 | Loss: 0.00001566
Iteration 17/1000 | Loss: 0.00001565
Iteration 18/1000 | Loss: 0.00001560
Iteration 19/1000 | Loss: 0.00001560
Iteration 20/1000 | Loss: 0.00001559
Iteration 21/1000 | Loss: 0.00001552
Iteration 22/1000 | Loss: 0.00001544
Iteration 23/1000 | Loss: 0.00001543
Iteration 24/1000 | Loss: 0.00001541
Iteration 25/1000 | Loss: 0.00001541
Iteration 26/1000 | Loss: 0.00001540
Iteration 27/1000 | Loss: 0.00001540
Iteration 28/1000 | Loss: 0.00001540
Iteration 29/1000 | Loss: 0.00001540
Iteration 30/1000 | Loss: 0.00001539
Iteration 31/1000 | Loss: 0.00001539
Iteration 32/1000 | Loss: 0.00001538
Iteration 33/1000 | Loss: 0.00001538
Iteration 34/1000 | Loss: 0.00001537
Iteration 35/1000 | Loss: 0.00001537
Iteration 36/1000 | Loss: 0.00001536
Iteration 37/1000 | Loss: 0.00001536
Iteration 38/1000 | Loss: 0.00001536
Iteration 39/1000 | Loss: 0.00001535
Iteration 40/1000 | Loss: 0.00001535
Iteration 41/1000 | Loss: 0.00001534
Iteration 42/1000 | Loss: 0.00001533
Iteration 43/1000 | Loss: 0.00001533
Iteration 44/1000 | Loss: 0.00001533
Iteration 45/1000 | Loss: 0.00001532
Iteration 46/1000 | Loss: 0.00001532
Iteration 47/1000 | Loss: 0.00001532
Iteration 48/1000 | Loss: 0.00001532
Iteration 49/1000 | Loss: 0.00001532
Iteration 50/1000 | Loss: 0.00001532
Iteration 51/1000 | Loss: 0.00001532
Iteration 52/1000 | Loss: 0.00001532
Iteration 53/1000 | Loss: 0.00001532
Iteration 54/1000 | Loss: 0.00001532
Iteration 55/1000 | Loss: 0.00001531
Iteration 56/1000 | Loss: 0.00001531
Iteration 57/1000 | Loss: 0.00001530
Iteration 58/1000 | Loss: 0.00001530
Iteration 59/1000 | Loss: 0.00001530
Iteration 60/1000 | Loss: 0.00001530
Iteration 61/1000 | Loss: 0.00001530
Iteration 62/1000 | Loss: 0.00001530
Iteration 63/1000 | Loss: 0.00001530
Iteration 64/1000 | Loss: 0.00001530
Iteration 65/1000 | Loss: 0.00001529
Iteration 66/1000 | Loss: 0.00001529
Iteration 67/1000 | Loss: 0.00001529
Iteration 68/1000 | Loss: 0.00001529
Iteration 69/1000 | Loss: 0.00001529
Iteration 70/1000 | Loss: 0.00001528
Iteration 71/1000 | Loss: 0.00001528
Iteration 72/1000 | Loss: 0.00001527
Iteration 73/1000 | Loss: 0.00001527
Iteration 74/1000 | Loss: 0.00001527
Iteration 75/1000 | Loss: 0.00001527
Iteration 76/1000 | Loss: 0.00001527
Iteration 77/1000 | Loss: 0.00001527
Iteration 78/1000 | Loss: 0.00001527
Iteration 79/1000 | Loss: 0.00001527
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 79. Stopping optimization.
Last 5 losses: [1.527122367406264e-05, 1.527122367406264e-05, 1.527122367406264e-05, 1.527122367406264e-05, 1.527122367406264e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.527122367406264e-05

Optimization complete. Final v2v error: 3.433565139770508 mm

Highest mean error: 3.792860746383667 mm for frame 149

Lowest mean error: 3.0601563453674316 mm for frame 244

Saving results

Total time: 34.30437517166138
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01161669
Iteration 2/25 | Loss: 0.01161669
Iteration 3/25 | Loss: 0.01161669
Iteration 4/25 | Loss: 0.00199004
Iteration 5/25 | Loss: 0.00124636
Iteration 6/25 | Loss: 0.00109564
Iteration 7/25 | Loss: 0.00104831
Iteration 8/25 | Loss: 0.00100354
Iteration 9/25 | Loss: 0.00099601
Iteration 10/25 | Loss: 0.00099750
Iteration 11/25 | Loss: 0.00097240
Iteration 12/25 | Loss: 0.00095970
Iteration 13/25 | Loss: 0.00095154
Iteration 14/25 | Loss: 0.00094493
Iteration 15/25 | Loss: 0.00093513
Iteration 16/25 | Loss: 0.00093254
Iteration 17/25 | Loss: 0.00093169
Iteration 18/25 | Loss: 0.00092990
Iteration 19/25 | Loss: 0.00092911
Iteration 20/25 | Loss: 0.00092858
Iteration 21/25 | Loss: 0.00092840
Iteration 22/25 | Loss: 0.00092827
Iteration 23/25 | Loss: 0.00092946
Iteration 24/25 | Loss: 0.00092802
Iteration 25/25 | Loss: 0.00092736

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.69864774
Iteration 2/25 | Loss: 0.00109820
Iteration 3/25 | Loss: 0.00109820
Iteration 4/25 | Loss: 0.00109820
Iteration 5/25 | Loss: 0.00109820
Iteration 6/25 | Loss: 0.00109820
Iteration 7/25 | Loss: 0.00109820
Iteration 8/25 | Loss: 0.00109820
Iteration 9/25 | Loss: 0.00109820
Iteration 10/25 | Loss: 0.00109820
Iteration 11/25 | Loss: 0.00109820
Iteration 12/25 | Loss: 0.00109820
Iteration 13/25 | Loss: 0.00109820
Iteration 14/25 | Loss: 0.00109820
Iteration 15/25 | Loss: 0.00109820
Iteration 16/25 | Loss: 0.00109820
Iteration 17/25 | Loss: 0.00109820
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00109819823410362, 0.00109819823410362, 0.00109819823410362, 0.00109819823410362, 0.00109819823410362]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00109819823410362

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00109820
Iteration 2/1000 | Loss: 0.00025033
Iteration 3/1000 | Loss: 0.00006789
Iteration 4/1000 | Loss: 0.00007846
Iteration 5/1000 | Loss: 0.00003868
Iteration 6/1000 | Loss: 0.00003462
Iteration 7/1000 | Loss: 0.00020824
Iteration 8/1000 | Loss: 0.00009254
Iteration 9/1000 | Loss: 0.00004956
Iteration 10/1000 | Loss: 0.00003506
Iteration 11/1000 | Loss: 0.00004121
Iteration 12/1000 | Loss: 0.00003637
Iteration 13/1000 | Loss: 0.00002996
Iteration 14/1000 | Loss: 0.00002754
Iteration 15/1000 | Loss: 0.00009356
Iteration 16/1000 | Loss: 0.00002579
Iteration 17/1000 | Loss: 0.00002528
Iteration 18/1000 | Loss: 0.00002498
Iteration 19/1000 | Loss: 0.00002480
Iteration 20/1000 | Loss: 0.00020473
Iteration 21/1000 | Loss: 0.00003378
Iteration 22/1000 | Loss: 0.00002893
Iteration 23/1000 | Loss: 0.00002680
Iteration 24/1000 | Loss: 0.00002549
Iteration 25/1000 | Loss: 0.00002449
Iteration 26/1000 | Loss: 0.00002412
Iteration 27/1000 | Loss: 0.00002399
Iteration 28/1000 | Loss: 0.00003540
Iteration 29/1000 | Loss: 0.00002384
Iteration 30/1000 | Loss: 0.00002382
Iteration 31/1000 | Loss: 0.00002380
Iteration 32/1000 | Loss: 0.00002377
Iteration 33/1000 | Loss: 0.00002374
Iteration 34/1000 | Loss: 0.00002373
Iteration 35/1000 | Loss: 0.00002372
Iteration 36/1000 | Loss: 0.00002372
Iteration 37/1000 | Loss: 0.00002372
Iteration 38/1000 | Loss: 0.00003188
Iteration 39/1000 | Loss: 0.00003608
Iteration 40/1000 | Loss: 0.00002374
Iteration 41/1000 | Loss: 0.00002367
Iteration 42/1000 | Loss: 0.00002367
Iteration 43/1000 | Loss: 0.00002366
Iteration 44/1000 | Loss: 0.00002366
Iteration 45/1000 | Loss: 0.00002365
Iteration 46/1000 | Loss: 0.00002365
Iteration 47/1000 | Loss: 0.00002365
Iteration 48/1000 | Loss: 0.00002365
Iteration 49/1000 | Loss: 0.00002364
Iteration 50/1000 | Loss: 0.00002364
Iteration 51/1000 | Loss: 0.00002364
Iteration 52/1000 | Loss: 0.00002364
Iteration 53/1000 | Loss: 0.00002364
Iteration 54/1000 | Loss: 0.00002364
Iteration 55/1000 | Loss: 0.00002363
Iteration 56/1000 | Loss: 0.00002363
Iteration 57/1000 | Loss: 0.00002363
Iteration 58/1000 | Loss: 0.00002363
Iteration 59/1000 | Loss: 0.00002363
Iteration 60/1000 | Loss: 0.00002362
Iteration 61/1000 | Loss: 0.00002362
Iteration 62/1000 | Loss: 0.00002362
Iteration 63/1000 | Loss: 0.00002362
Iteration 64/1000 | Loss: 0.00002362
Iteration 65/1000 | Loss: 0.00002362
Iteration 66/1000 | Loss: 0.00002362
Iteration 67/1000 | Loss: 0.00002362
Iteration 68/1000 | Loss: 0.00002361
Iteration 69/1000 | Loss: 0.00002361
Iteration 70/1000 | Loss: 0.00002361
Iteration 71/1000 | Loss: 0.00002361
Iteration 72/1000 | Loss: 0.00002361
Iteration 73/1000 | Loss: 0.00002361
Iteration 74/1000 | Loss: 0.00002361
Iteration 75/1000 | Loss: 0.00002361
Iteration 76/1000 | Loss: 0.00002360
Iteration 77/1000 | Loss: 0.00002360
Iteration 78/1000 | Loss: 0.00002360
Iteration 79/1000 | Loss: 0.00002360
Iteration 80/1000 | Loss: 0.00002359
Iteration 81/1000 | Loss: 0.00002359
Iteration 82/1000 | Loss: 0.00002359
Iteration 83/1000 | Loss: 0.00002359
Iteration 84/1000 | Loss: 0.00002358
Iteration 85/1000 | Loss: 0.00002358
Iteration 86/1000 | Loss: 0.00002358
Iteration 87/1000 | Loss: 0.00002358
Iteration 88/1000 | Loss: 0.00002358
Iteration 89/1000 | Loss: 0.00002358
Iteration 90/1000 | Loss: 0.00002358
Iteration 91/1000 | Loss: 0.00002358
Iteration 92/1000 | Loss: 0.00002358
Iteration 93/1000 | Loss: 0.00002358
Iteration 94/1000 | Loss: 0.00002357
Iteration 95/1000 | Loss: 0.00002357
Iteration 96/1000 | Loss: 0.00002357
Iteration 97/1000 | Loss: 0.00002357
Iteration 98/1000 | Loss: 0.00002357
Iteration 99/1000 | Loss: 0.00002357
Iteration 100/1000 | Loss: 0.00002357
Iteration 101/1000 | Loss: 0.00002357
Iteration 102/1000 | Loss: 0.00002357
Iteration 103/1000 | Loss: 0.00002357
Iteration 104/1000 | Loss: 0.00002357
Iteration 105/1000 | Loss: 0.00002357
Iteration 106/1000 | Loss: 0.00002357
Iteration 107/1000 | Loss: 0.00002357
Iteration 108/1000 | Loss: 0.00002357
Iteration 109/1000 | Loss: 0.00002357
Iteration 110/1000 | Loss: 0.00002357
Iteration 111/1000 | Loss: 0.00002357
Iteration 112/1000 | Loss: 0.00002357
Iteration 113/1000 | Loss: 0.00002357
Iteration 114/1000 | Loss: 0.00002357
Iteration 115/1000 | Loss: 0.00002357
Iteration 116/1000 | Loss: 0.00002357
Iteration 117/1000 | Loss: 0.00002357
Iteration 118/1000 | Loss: 0.00002357
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 118. Stopping optimization.
Last 5 losses: [2.3567123207612894e-05, 2.3567123207612894e-05, 2.3567123207612894e-05, 2.3567123207612894e-05, 2.3567123207612894e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3567123207612894e-05

Optimization complete. Final v2v error: 3.7231993675231934 mm

Highest mean error: 22.296823501586914 mm for frame 205

Lowest mean error: 3.1973917484283447 mm for frame 108

Saving results

Total time: 103.14061093330383
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01137420
Iteration 2/25 | Loss: 0.01137420
Iteration 3/25 | Loss: 0.00282004
Iteration 4/25 | Loss: 0.00174844
Iteration 5/25 | Loss: 0.00141796
Iteration 6/25 | Loss: 0.00129110
Iteration 7/25 | Loss: 0.00110809
Iteration 8/25 | Loss: 0.00100758
Iteration 9/25 | Loss: 0.00097826
Iteration 10/25 | Loss: 0.00094056
Iteration 11/25 | Loss: 0.00092059
Iteration 12/25 | Loss: 0.00090701
Iteration 13/25 | Loss: 0.00090463
Iteration 14/25 | Loss: 0.00090444
Iteration 15/25 | Loss: 0.00090166
Iteration 16/25 | Loss: 0.00089988
Iteration 17/25 | Loss: 0.00089754
Iteration 18/25 | Loss: 0.00089840
Iteration 19/25 | Loss: 0.00089718
Iteration 20/25 | Loss: 0.00089684
Iteration 21/25 | Loss: 0.00089648
Iteration 22/25 | Loss: 0.00089629
Iteration 23/25 | Loss: 0.00089618
Iteration 24/25 | Loss: 0.00089594
Iteration 25/25 | Loss: 0.00089534

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46350765
Iteration 2/25 | Loss: 0.00073148
Iteration 3/25 | Loss: 0.00073148
Iteration 4/25 | Loss: 0.00073148
Iteration 5/25 | Loss: 0.00073148
Iteration 6/25 | Loss: 0.00073148
Iteration 7/25 | Loss: 0.00073148
Iteration 8/25 | Loss: 0.00073147
Iteration 9/25 | Loss: 0.00073147
Iteration 10/25 | Loss: 0.00073147
Iteration 11/25 | Loss: 0.00073147
Iteration 12/25 | Loss: 0.00073147
Iteration 13/25 | Loss: 0.00073147
Iteration 14/25 | Loss: 0.00073147
Iteration 15/25 | Loss: 0.00073147
Iteration 16/25 | Loss: 0.00073147
Iteration 17/25 | Loss: 0.00073147
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007314744289033115, 0.0007314744289033115, 0.0007314744289033115, 0.0007314744289033115, 0.0007314744289033115]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007314744289033115

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073147
Iteration 2/1000 | Loss: 0.00005648
Iteration 3/1000 | Loss: 0.00025163
Iteration 4/1000 | Loss: 0.00004635
Iteration 5/1000 | Loss: 0.00004139
Iteration 6/1000 | Loss: 0.00003949
Iteration 7/1000 | Loss: 0.00003800
Iteration 8/1000 | Loss: 0.00003676
Iteration 9/1000 | Loss: 0.00003617
Iteration 10/1000 | Loss: 0.00003550
Iteration 11/1000 | Loss: 0.00003506
Iteration 12/1000 | Loss: 0.00003481
Iteration 13/1000 | Loss: 0.00003479
Iteration 14/1000 | Loss: 0.00003466
Iteration 15/1000 | Loss: 0.00003457
Iteration 16/1000 | Loss: 0.00003455
Iteration 17/1000 | Loss: 0.00003455
Iteration 18/1000 | Loss: 0.00003455
Iteration 19/1000 | Loss: 0.00003455
Iteration 20/1000 | Loss: 0.00003455
Iteration 21/1000 | Loss: 0.00003455
Iteration 22/1000 | Loss: 0.00003455
Iteration 23/1000 | Loss: 0.00003455
Iteration 24/1000 | Loss: 0.00003455
Iteration 25/1000 | Loss: 0.00003454
Iteration 26/1000 | Loss: 0.00003454
Iteration 27/1000 | Loss: 0.00003454
Iteration 28/1000 | Loss: 0.00003454
Iteration 29/1000 | Loss: 0.00003454
Iteration 30/1000 | Loss: 0.00003454
Iteration 31/1000 | Loss: 0.00003454
Iteration 32/1000 | Loss: 0.00003453
Iteration 33/1000 | Loss: 0.00003453
Iteration 34/1000 | Loss: 0.00003452
Iteration 35/1000 | Loss: 0.00003452
Iteration 36/1000 | Loss: 0.00003451
Iteration 37/1000 | Loss: 0.00003451
Iteration 38/1000 | Loss: 0.00003451
Iteration 39/1000 | Loss: 0.00003451
Iteration 40/1000 | Loss: 0.00003450
Iteration 41/1000 | Loss: 0.00003450
Iteration 42/1000 | Loss: 0.00003450
Iteration 43/1000 | Loss: 0.00003449
Iteration 44/1000 | Loss: 0.00003448
Iteration 45/1000 | Loss: 0.00003448
Iteration 46/1000 | Loss: 0.00003446
Iteration 47/1000 | Loss: 0.00003446
Iteration 48/1000 | Loss: 0.00003446
Iteration 49/1000 | Loss: 0.00003446
Iteration 50/1000 | Loss: 0.00003445
Iteration 51/1000 | Loss: 0.00003445
Iteration 52/1000 | Loss: 0.00003445
Iteration 53/1000 | Loss: 0.00003444
Iteration 54/1000 | Loss: 0.00003444
Iteration 55/1000 | Loss: 0.00003442
Iteration 56/1000 | Loss: 0.00003442
Iteration 57/1000 | Loss: 0.00003442
Iteration 58/1000 | Loss: 0.00003442
Iteration 59/1000 | Loss: 0.00003442
Iteration 60/1000 | Loss: 0.00003442
Iteration 61/1000 | Loss: 0.00003442
Iteration 62/1000 | Loss: 0.00003442
Iteration 63/1000 | Loss: 0.00003442
Iteration 64/1000 | Loss: 0.00003442
Iteration 65/1000 | Loss: 0.00003442
Iteration 66/1000 | Loss: 0.00003442
Iteration 67/1000 | Loss: 0.00003441
Iteration 68/1000 | Loss: 0.00003441
Iteration 69/1000 | Loss: 0.00003441
Iteration 70/1000 | Loss: 0.00003440
Iteration 71/1000 | Loss: 0.00003440
Iteration 72/1000 | Loss: 0.00003439
Iteration 73/1000 | Loss: 0.00003438
Iteration 74/1000 | Loss: 0.00003438
Iteration 75/1000 | Loss: 0.00003438
Iteration 76/1000 | Loss: 0.00003438
Iteration 77/1000 | Loss: 0.00003438
Iteration 78/1000 | Loss: 0.00003438
Iteration 79/1000 | Loss: 0.00003438
Iteration 80/1000 | Loss: 0.00003438
Iteration 81/1000 | Loss: 0.00003438
Iteration 82/1000 | Loss: 0.00003438
Iteration 83/1000 | Loss: 0.00003438
Iteration 84/1000 | Loss: 0.00003438
Iteration 85/1000 | Loss: 0.00003438
Iteration 86/1000 | Loss: 0.00003437
Iteration 87/1000 | Loss: 0.00003437
Iteration 88/1000 | Loss: 0.00003437
Iteration 89/1000 | Loss: 0.00003437
Iteration 90/1000 | Loss: 0.00003436
Iteration 91/1000 | Loss: 0.00003436
Iteration 92/1000 | Loss: 0.00003436
Iteration 93/1000 | Loss: 0.00003436
Iteration 94/1000 | Loss: 0.00003436
Iteration 95/1000 | Loss: 0.00003436
Iteration 96/1000 | Loss: 0.00003435
Iteration 97/1000 | Loss: 0.00003435
Iteration 98/1000 | Loss: 0.00003435
Iteration 99/1000 | Loss: 0.00003435
Iteration 100/1000 | Loss: 0.00003435
Iteration 101/1000 | Loss: 0.00003435
Iteration 102/1000 | Loss: 0.00003435
Iteration 103/1000 | Loss: 0.00003435
Iteration 104/1000 | Loss: 0.00003435
Iteration 105/1000 | Loss: 0.00003435
Iteration 106/1000 | Loss: 0.00003435
Iteration 107/1000 | Loss: 0.00003435
Iteration 108/1000 | Loss: 0.00003435
Iteration 109/1000 | Loss: 0.00003435
Iteration 110/1000 | Loss: 0.00003435
Iteration 111/1000 | Loss: 0.00003434
Iteration 112/1000 | Loss: 0.00003434
Iteration 113/1000 | Loss: 0.00003434
Iteration 114/1000 | Loss: 0.00003434
Iteration 115/1000 | Loss: 0.00003434
Iteration 116/1000 | Loss: 0.00003434
Iteration 117/1000 | Loss: 0.00003433
Iteration 118/1000 | Loss: 0.00003433
Iteration 119/1000 | Loss: 0.00003433
Iteration 120/1000 | Loss: 0.00003433
Iteration 121/1000 | Loss: 0.00003433
Iteration 122/1000 | Loss: 0.00003433
Iteration 123/1000 | Loss: 0.00003433
Iteration 124/1000 | Loss: 0.00003432
Iteration 125/1000 | Loss: 0.00003432
Iteration 126/1000 | Loss: 0.00003432
Iteration 127/1000 | Loss: 0.00003432
Iteration 128/1000 | Loss: 0.00003432
Iteration 129/1000 | Loss: 0.00003432
Iteration 130/1000 | Loss: 0.00003432
Iteration 131/1000 | Loss: 0.00003431
Iteration 132/1000 | Loss: 0.00003431
Iteration 133/1000 | Loss: 0.00003431
Iteration 134/1000 | Loss: 0.00003431
Iteration 135/1000 | Loss: 0.00003430
Iteration 136/1000 | Loss: 0.00003430
Iteration 137/1000 | Loss: 0.00003430
Iteration 138/1000 | Loss: 0.00003430
Iteration 139/1000 | Loss: 0.00003430
Iteration 140/1000 | Loss: 0.00003430
Iteration 141/1000 | Loss: 0.00003430
Iteration 142/1000 | Loss: 0.00003429
Iteration 143/1000 | Loss: 0.00003429
Iteration 144/1000 | Loss: 0.00003429
Iteration 145/1000 | Loss: 0.00003429
Iteration 146/1000 | Loss: 0.00003429
Iteration 147/1000 | Loss: 0.00003429
Iteration 148/1000 | Loss: 0.00003429
Iteration 149/1000 | Loss: 0.00003429
Iteration 150/1000 | Loss: 0.00003429
Iteration 151/1000 | Loss: 0.00003429
Iteration 152/1000 | Loss: 0.00003429
Iteration 153/1000 | Loss: 0.00003429
Iteration 154/1000 | Loss: 0.00003428
Iteration 155/1000 | Loss: 0.00003428
Iteration 156/1000 | Loss: 0.00003428
Iteration 157/1000 | Loss: 0.00003428
Iteration 158/1000 | Loss: 0.00003428
Iteration 159/1000 | Loss: 0.00003428
Iteration 160/1000 | Loss: 0.00003428
Iteration 161/1000 | Loss: 0.00003428
Iteration 162/1000 | Loss: 0.00003428
Iteration 163/1000 | Loss: 0.00003428
Iteration 164/1000 | Loss: 0.00003428
Iteration 165/1000 | Loss: 0.00003428
Iteration 166/1000 | Loss: 0.00003428
Iteration 167/1000 | Loss: 0.00003428
Iteration 168/1000 | Loss: 0.00003427
Iteration 169/1000 | Loss: 0.00003427
Iteration 170/1000 | Loss: 0.00003427
Iteration 171/1000 | Loss: 0.00003427
Iteration 172/1000 | Loss: 0.00003427
Iteration 173/1000 | Loss: 0.00003427
Iteration 174/1000 | Loss: 0.00003427
Iteration 175/1000 | Loss: 0.00003427
Iteration 176/1000 | Loss: 0.00003427
Iteration 177/1000 | Loss: 0.00003427
Iteration 178/1000 | Loss: 0.00003426
Iteration 179/1000 | Loss: 0.00003426
Iteration 180/1000 | Loss: 0.00003426
Iteration 181/1000 | Loss: 0.00003426
Iteration 182/1000 | Loss: 0.00003426
Iteration 183/1000 | Loss: 0.00003426
Iteration 184/1000 | Loss: 0.00003425
Iteration 185/1000 | Loss: 0.00003425
Iteration 186/1000 | Loss: 0.00003425
Iteration 187/1000 | Loss: 0.00003425
Iteration 188/1000 | Loss: 0.00003425
Iteration 189/1000 | Loss: 0.00003425
Iteration 190/1000 | Loss: 0.00003425
Iteration 191/1000 | Loss: 0.00003425
Iteration 192/1000 | Loss: 0.00003425
Iteration 193/1000 | Loss: 0.00003425
Iteration 194/1000 | Loss: 0.00003425
Iteration 195/1000 | Loss: 0.00003424
Iteration 196/1000 | Loss: 0.00003424
Iteration 197/1000 | Loss: 0.00003424
Iteration 198/1000 | Loss: 0.00003424
Iteration 199/1000 | Loss: 0.00003424
Iteration 200/1000 | Loss: 0.00003424
Iteration 201/1000 | Loss: 0.00003424
Iteration 202/1000 | Loss: 0.00003424
Iteration 203/1000 | Loss: 0.00003424
Iteration 204/1000 | Loss: 0.00003424
Iteration 205/1000 | Loss: 0.00003424
Iteration 206/1000 | Loss: 0.00003424
Iteration 207/1000 | Loss: 0.00003424
Iteration 208/1000 | Loss: 0.00003424
Iteration 209/1000 | Loss: 0.00003424
Iteration 210/1000 | Loss: 0.00003423
Iteration 211/1000 | Loss: 0.00003423
Iteration 212/1000 | Loss: 0.00003423
Iteration 213/1000 | Loss: 0.00003423
Iteration 214/1000 | Loss: 0.00003423
Iteration 215/1000 | Loss: 0.00003423
Iteration 216/1000 | Loss: 0.00003423
Iteration 217/1000 | Loss: 0.00003423
Iteration 218/1000 | Loss: 0.00003423
Iteration 219/1000 | Loss: 0.00003423
Iteration 220/1000 | Loss: 0.00003423
Iteration 221/1000 | Loss: 0.00003423
Iteration 222/1000 | Loss: 0.00003423
Iteration 223/1000 | Loss: 0.00003423
Iteration 224/1000 | Loss: 0.00003423
Iteration 225/1000 | Loss: 0.00003423
Iteration 226/1000 | Loss: 0.00003423
Iteration 227/1000 | Loss: 0.00003423
Iteration 228/1000 | Loss: 0.00003423
Iteration 229/1000 | Loss: 0.00003423
Iteration 230/1000 | Loss: 0.00003422
Iteration 231/1000 | Loss: 0.00003422
Iteration 232/1000 | Loss: 0.00003422
Iteration 233/1000 | Loss: 0.00003422
Iteration 234/1000 | Loss: 0.00003422
Iteration 235/1000 | Loss: 0.00003422
Iteration 236/1000 | Loss: 0.00003421
Iteration 237/1000 | Loss: 0.00003421
Iteration 238/1000 | Loss: 0.00003421
Iteration 239/1000 | Loss: 0.00003421
Iteration 240/1000 | Loss: 0.00003421
Iteration 241/1000 | Loss: 0.00003421
Iteration 242/1000 | Loss: 0.00003421
Iteration 243/1000 | Loss: 0.00003421
Iteration 244/1000 | Loss: 0.00003421
Iteration 245/1000 | Loss: 0.00003421
Iteration 246/1000 | Loss: 0.00003421
Iteration 247/1000 | Loss: 0.00003420
Iteration 248/1000 | Loss: 0.00003420
Iteration 249/1000 | Loss: 0.00003420
Iteration 250/1000 | Loss: 0.00003420
Iteration 251/1000 | Loss: 0.00003420
Iteration 252/1000 | Loss: 0.00003420
Iteration 253/1000 | Loss: 0.00003420
Iteration 254/1000 | Loss: 0.00003420
Iteration 255/1000 | Loss: 0.00003420
Iteration 256/1000 | Loss: 0.00003420
Iteration 257/1000 | Loss: 0.00003419
Iteration 258/1000 | Loss: 0.00003419
Iteration 259/1000 | Loss: 0.00003419
Iteration 260/1000 | Loss: 0.00003419
Iteration 261/1000 | Loss: 0.00003419
Iteration 262/1000 | Loss: 0.00003419
Iteration 263/1000 | Loss: 0.00003419
Iteration 264/1000 | Loss: 0.00003419
Iteration 265/1000 | Loss: 0.00003419
Iteration 266/1000 | Loss: 0.00003419
Iteration 267/1000 | Loss: 0.00003419
Iteration 268/1000 | Loss: 0.00003419
Iteration 269/1000 | Loss: 0.00003419
Iteration 270/1000 | Loss: 0.00003419
Iteration 271/1000 | Loss: 0.00003418
Iteration 272/1000 | Loss: 0.00003418
Iteration 273/1000 | Loss: 0.00003418
Iteration 274/1000 | Loss: 0.00003418
Iteration 275/1000 | Loss: 0.00003418
Iteration 276/1000 | Loss: 0.00003418
Iteration 277/1000 | Loss: 0.00003418
Iteration 278/1000 | Loss: 0.00003418
Iteration 279/1000 | Loss: 0.00003418
Iteration 280/1000 | Loss: 0.00003418
Iteration 281/1000 | Loss: 0.00003418
Iteration 282/1000 | Loss: 0.00003418
Iteration 283/1000 | Loss: 0.00003418
Iteration 284/1000 | Loss: 0.00003418
Iteration 285/1000 | Loss: 0.00003417
Iteration 286/1000 | Loss: 0.00003417
Iteration 287/1000 | Loss: 0.00003417
Iteration 288/1000 | Loss: 0.00003417
Iteration 289/1000 | Loss: 0.00003417
Iteration 290/1000 | Loss: 0.00003417
Iteration 291/1000 | Loss: 0.00003417
Iteration 292/1000 | Loss: 0.00003417
Iteration 293/1000 | Loss: 0.00003417
Iteration 294/1000 | Loss: 0.00003417
Iteration 295/1000 | Loss: 0.00003417
Iteration 296/1000 | Loss: 0.00003417
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 296. Stopping optimization.
Last 5 losses: [3.417328480281867e-05, 3.417328480281867e-05, 3.417328480281867e-05, 3.417328480281867e-05, 3.417328480281867e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.417328480281867e-05

Optimization complete. Final v2v error: 4.535902500152588 mm

Highest mean error: 21.52882194519043 mm for frame 48

Lowest mean error: 3.9069623947143555 mm for frame 191

Saving results

Total time: 84.07164573669434
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_32_us_1386/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_32_us_1386/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00869323
Iteration 2/25 | Loss: 0.00144616
Iteration 3/25 | Loss: 0.00103068
Iteration 4/25 | Loss: 0.00096079
Iteration 5/25 | Loss: 0.00094654
Iteration 6/25 | Loss: 0.00094471
Iteration 7/25 | Loss: 0.00094471
Iteration 8/25 | Loss: 0.00094471
Iteration 9/25 | Loss: 0.00094471
Iteration 10/25 | Loss: 0.00094471
Iteration 11/25 | Loss: 0.00094471
Iteration 12/25 | Loss: 0.00094471
Iteration 13/25 | Loss: 0.00094471
Iteration 14/25 | Loss: 0.00094471
Iteration 15/25 | Loss: 0.00094471
Iteration 16/25 | Loss: 0.00094471
Iteration 17/25 | Loss: 0.00094471
Iteration 18/25 | Loss: 0.00094471
Iteration 19/25 | Loss: 0.00094471
Iteration 20/25 | Loss: 0.00094471
Iteration 21/25 | Loss: 0.00094471
Iteration 22/25 | Loss: 0.00094471
Iteration 23/25 | Loss: 0.00094471
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.000944713014177978, 0.000944713014177978, 0.000944713014177978, 0.000944713014177978, 0.000944713014177978]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000944713014177978

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56552017
Iteration 2/25 | Loss: 0.00103279
Iteration 3/25 | Loss: 0.00103278
Iteration 4/25 | Loss: 0.00103278
Iteration 5/25 | Loss: 0.00103278
Iteration 6/25 | Loss: 0.00103278
Iteration 7/25 | Loss: 0.00103278
Iteration 8/25 | Loss: 0.00103278
Iteration 9/25 | Loss: 0.00103278
Iteration 10/25 | Loss: 0.00103278
Iteration 11/25 | Loss: 0.00103278
Iteration 12/25 | Loss: 0.00103278
Iteration 13/25 | Loss: 0.00103278
Iteration 14/25 | Loss: 0.00103278
Iteration 15/25 | Loss: 0.00103278
Iteration 16/25 | Loss: 0.00103278
Iteration 17/25 | Loss: 0.00103278
Iteration 18/25 | Loss: 0.00103278
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0010327796917408705, 0.0010327796917408705, 0.0010327796917408705, 0.0010327796917408705, 0.0010327796917408705]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010327796917408705

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00103278
Iteration 2/1000 | Loss: 0.00003076
Iteration 3/1000 | Loss: 0.00002299
Iteration 4/1000 | Loss: 0.00002139
Iteration 5/1000 | Loss: 0.00002027
Iteration 6/1000 | Loss: 0.00001975
Iteration 7/1000 | Loss: 0.00001929
Iteration 8/1000 | Loss: 0.00001892
Iteration 9/1000 | Loss: 0.00001873
Iteration 10/1000 | Loss: 0.00001871
Iteration 11/1000 | Loss: 0.00001868
Iteration 12/1000 | Loss: 0.00001863
Iteration 13/1000 | Loss: 0.00001856
Iteration 14/1000 | Loss: 0.00001855
Iteration 15/1000 | Loss: 0.00001853
Iteration 16/1000 | Loss: 0.00001852
Iteration 17/1000 | Loss: 0.00001852
Iteration 18/1000 | Loss: 0.00001851
Iteration 19/1000 | Loss: 0.00001849
Iteration 20/1000 | Loss: 0.00001849
Iteration 21/1000 | Loss: 0.00001848
Iteration 22/1000 | Loss: 0.00001848
Iteration 23/1000 | Loss: 0.00001846
Iteration 24/1000 | Loss: 0.00001846
Iteration 25/1000 | Loss: 0.00001846
Iteration 26/1000 | Loss: 0.00001845
Iteration 27/1000 | Loss: 0.00001845
Iteration 28/1000 | Loss: 0.00001845
Iteration 29/1000 | Loss: 0.00001843
Iteration 30/1000 | Loss: 0.00001843
Iteration 31/1000 | Loss: 0.00001843
Iteration 32/1000 | Loss: 0.00001843
Iteration 33/1000 | Loss: 0.00001842
Iteration 34/1000 | Loss: 0.00001841
Iteration 35/1000 | Loss: 0.00001841
Iteration 36/1000 | Loss: 0.00001840
Iteration 37/1000 | Loss: 0.00001840
Iteration 38/1000 | Loss: 0.00001840
Iteration 39/1000 | Loss: 0.00001840
Iteration 40/1000 | Loss: 0.00001840
Iteration 41/1000 | Loss: 0.00001839
Iteration 42/1000 | Loss: 0.00001839
Iteration 43/1000 | Loss: 0.00001839
Iteration 44/1000 | Loss: 0.00001839
Iteration 45/1000 | Loss: 0.00001839
Iteration 46/1000 | Loss: 0.00001838
Iteration 47/1000 | Loss: 0.00001838
Iteration 48/1000 | Loss: 0.00001838
Iteration 49/1000 | Loss: 0.00001838
Iteration 50/1000 | Loss: 0.00001838
Iteration 51/1000 | Loss: 0.00001837
Iteration 52/1000 | Loss: 0.00001837
Iteration 53/1000 | Loss: 0.00001837
Iteration 54/1000 | Loss: 0.00001837
Iteration 55/1000 | Loss: 0.00001837
Iteration 56/1000 | Loss: 0.00001837
Iteration 57/1000 | Loss: 0.00001837
Iteration 58/1000 | Loss: 0.00001837
Iteration 59/1000 | Loss: 0.00001836
Iteration 60/1000 | Loss: 0.00001836
Iteration 61/1000 | Loss: 0.00001836
Iteration 62/1000 | Loss: 0.00001836
Iteration 63/1000 | Loss: 0.00001836
Iteration 64/1000 | Loss: 0.00001836
Iteration 65/1000 | Loss: 0.00001836
Iteration 66/1000 | Loss: 0.00001836
Iteration 67/1000 | Loss: 0.00001836
Iteration 68/1000 | Loss: 0.00001836
Iteration 69/1000 | Loss: 0.00001836
Iteration 70/1000 | Loss: 0.00001836
Iteration 71/1000 | Loss: 0.00001836
Iteration 72/1000 | Loss: 0.00001835
Iteration 73/1000 | Loss: 0.00001835
Iteration 74/1000 | Loss: 0.00001835
Iteration 75/1000 | Loss: 0.00001835
Iteration 76/1000 | Loss: 0.00001835
Iteration 77/1000 | Loss: 0.00001835
Iteration 78/1000 | Loss: 0.00001835
Iteration 79/1000 | Loss: 0.00001835
Iteration 80/1000 | Loss: 0.00001835
Iteration 81/1000 | Loss: 0.00001835
Iteration 82/1000 | Loss: 0.00001835
Iteration 83/1000 | Loss: 0.00001834
Iteration 84/1000 | Loss: 0.00001834
Iteration 85/1000 | Loss: 0.00001834
Iteration 86/1000 | Loss: 0.00001834
Iteration 87/1000 | Loss: 0.00001834
Iteration 88/1000 | Loss: 0.00001834
Iteration 89/1000 | Loss: 0.00001834
Iteration 90/1000 | Loss: 0.00001834
Iteration 91/1000 | Loss: 0.00001834
Iteration 92/1000 | Loss: 0.00001834
Iteration 93/1000 | Loss: 0.00001834
Iteration 94/1000 | Loss: 0.00001834
Iteration 95/1000 | Loss: 0.00001834
Iteration 96/1000 | Loss: 0.00001834
Iteration 97/1000 | Loss: 0.00001834
Iteration 98/1000 | Loss: 0.00001834
Iteration 99/1000 | Loss: 0.00001834
Iteration 100/1000 | Loss: 0.00001834
Iteration 101/1000 | Loss: 0.00001834
Iteration 102/1000 | Loss: 0.00001834
Iteration 103/1000 | Loss: 0.00001834
Iteration 104/1000 | Loss: 0.00001834
Iteration 105/1000 | Loss: 0.00001834
Iteration 106/1000 | Loss: 0.00001834
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.8336613720748574e-05, 1.8336613720748574e-05, 1.8336613720748574e-05, 1.8336613720748574e-05, 1.8336613720748574e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8336613720748574e-05

Optimization complete. Final v2v error: 3.7090835571289062 mm

Highest mean error: 4.043621063232422 mm for frame 9

Lowest mean error: 3.436042070388794 mm for frame 239

Saving results

Total time: 34.68667793273926

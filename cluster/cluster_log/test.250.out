Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=250, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 14000-14055
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1025/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1025.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1025
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00973751
Iteration 2/25 | Loss: 0.00164412
Iteration 3/25 | Loss: 0.00102176
Iteration 4/25 | Loss: 0.00097241
Iteration 5/25 | Loss: 0.00095561
Iteration 6/25 | Loss: 0.00095077
Iteration 7/25 | Loss: 0.00094992
Iteration 8/25 | Loss: 0.00094992
Iteration 9/25 | Loss: 0.00094992
Iteration 10/25 | Loss: 0.00094992
Iteration 11/25 | Loss: 0.00094992
Iteration 12/25 | Loss: 0.00094992
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009499242878518999, 0.0009499242878518999, 0.0009499242878518999, 0.0009499242878518999, 0.0009499242878518999]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009499242878518999

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.97029662
Iteration 2/25 | Loss: 0.00041991
Iteration 3/25 | Loss: 0.00041990
Iteration 4/25 | Loss: 0.00041990
Iteration 5/25 | Loss: 0.00041990
Iteration 6/25 | Loss: 0.00041990
Iteration 7/25 | Loss: 0.00041990
Iteration 8/25 | Loss: 0.00041990
Iteration 9/25 | Loss: 0.00041990
Iteration 10/25 | Loss: 0.00041990
Iteration 11/25 | Loss: 0.00041990
Iteration 12/25 | Loss: 0.00041990
Iteration 13/25 | Loss: 0.00041990
Iteration 14/25 | Loss: 0.00041990
Iteration 15/25 | Loss: 0.00041990
Iteration 16/25 | Loss: 0.00041990
Iteration 17/25 | Loss: 0.00041990
Iteration 18/25 | Loss: 0.00041990
Iteration 19/25 | Loss: 0.00041990
Iteration 20/25 | Loss: 0.00041990
Iteration 21/25 | Loss: 0.00041990
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0004199009563308209, 0.0004199009563308209, 0.0004199009563308209, 0.0004199009563308209, 0.0004199009563308209]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004199009563308209

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041990
Iteration 2/1000 | Loss: 0.00006910
Iteration 3/1000 | Loss: 0.00004417
Iteration 4/1000 | Loss: 0.00004045
Iteration 5/1000 | Loss: 0.00003867
Iteration 6/1000 | Loss: 0.00003783
Iteration 7/1000 | Loss: 0.00003686
Iteration 8/1000 | Loss: 0.00003609
Iteration 9/1000 | Loss: 0.00003567
Iteration 10/1000 | Loss: 0.00003534
Iteration 11/1000 | Loss: 0.00003507
Iteration 12/1000 | Loss: 0.00003479
Iteration 13/1000 | Loss: 0.00003451
Iteration 14/1000 | Loss: 0.00003433
Iteration 15/1000 | Loss: 0.00003412
Iteration 16/1000 | Loss: 0.00003396
Iteration 17/1000 | Loss: 0.00003391
Iteration 18/1000 | Loss: 0.00003388
Iteration 19/1000 | Loss: 0.00003386
Iteration 20/1000 | Loss: 0.00003376
Iteration 21/1000 | Loss: 0.00003374
Iteration 22/1000 | Loss: 0.00003374
Iteration 23/1000 | Loss: 0.00003370
Iteration 24/1000 | Loss: 0.00003369
Iteration 25/1000 | Loss: 0.00003369
Iteration 26/1000 | Loss: 0.00003369
Iteration 27/1000 | Loss: 0.00003367
Iteration 28/1000 | Loss: 0.00003362
Iteration 29/1000 | Loss: 0.00003360
Iteration 30/1000 | Loss: 0.00003360
Iteration 31/1000 | Loss: 0.00003359
Iteration 32/1000 | Loss: 0.00003357
Iteration 33/1000 | Loss: 0.00003357
Iteration 34/1000 | Loss: 0.00003356
Iteration 35/1000 | Loss: 0.00003355
Iteration 36/1000 | Loss: 0.00003355
Iteration 37/1000 | Loss: 0.00003355
Iteration 38/1000 | Loss: 0.00003355
Iteration 39/1000 | Loss: 0.00003354
Iteration 40/1000 | Loss: 0.00003354
Iteration 41/1000 | Loss: 0.00003354
Iteration 42/1000 | Loss: 0.00003353
Iteration 43/1000 | Loss: 0.00003353
Iteration 44/1000 | Loss: 0.00003352
Iteration 45/1000 | Loss: 0.00003352
Iteration 46/1000 | Loss: 0.00003352
Iteration 47/1000 | Loss: 0.00003351
Iteration 48/1000 | Loss: 0.00003351
Iteration 49/1000 | Loss: 0.00003351
Iteration 50/1000 | Loss: 0.00003351
Iteration 51/1000 | Loss: 0.00003351
Iteration 52/1000 | Loss: 0.00003351
Iteration 53/1000 | Loss: 0.00003351
Iteration 54/1000 | Loss: 0.00003351
Iteration 55/1000 | Loss: 0.00003351
Iteration 56/1000 | Loss: 0.00003351
Iteration 57/1000 | Loss: 0.00003351
Iteration 58/1000 | Loss: 0.00003351
Iteration 59/1000 | Loss: 0.00003350
Iteration 60/1000 | Loss: 0.00003350
Iteration 61/1000 | Loss: 0.00003350
Iteration 62/1000 | Loss: 0.00003348
Iteration 63/1000 | Loss: 0.00003348
Iteration 64/1000 | Loss: 0.00003348
Iteration 65/1000 | Loss: 0.00003348
Iteration 66/1000 | Loss: 0.00003348
Iteration 67/1000 | Loss: 0.00003348
Iteration 68/1000 | Loss: 0.00003348
Iteration 69/1000 | Loss: 0.00003348
Iteration 70/1000 | Loss: 0.00003347
Iteration 71/1000 | Loss: 0.00003347
Iteration 72/1000 | Loss: 0.00003347
Iteration 73/1000 | Loss: 0.00003347
Iteration 74/1000 | Loss: 0.00003347
Iteration 75/1000 | Loss: 0.00003347
Iteration 76/1000 | Loss: 0.00003347
Iteration 77/1000 | Loss: 0.00003347
Iteration 78/1000 | Loss: 0.00003347
Iteration 79/1000 | Loss: 0.00003347
Iteration 80/1000 | Loss: 0.00003347
Iteration 81/1000 | Loss: 0.00003347
Iteration 82/1000 | Loss: 0.00003347
Iteration 83/1000 | Loss: 0.00003347
Iteration 84/1000 | Loss: 0.00003347
Iteration 85/1000 | Loss: 0.00003347
Iteration 86/1000 | Loss: 0.00003347
Iteration 87/1000 | Loss: 0.00003347
Iteration 88/1000 | Loss: 0.00003347
Iteration 89/1000 | Loss: 0.00003346
Iteration 90/1000 | Loss: 0.00003346
Iteration 91/1000 | Loss: 0.00003346
Iteration 92/1000 | Loss: 0.00003346
Iteration 93/1000 | Loss: 0.00003346
Iteration 94/1000 | Loss: 0.00003346
Iteration 95/1000 | Loss: 0.00003346
Iteration 96/1000 | Loss: 0.00003345
Iteration 97/1000 | Loss: 0.00003345
Iteration 98/1000 | Loss: 0.00003345
Iteration 99/1000 | Loss: 0.00003345
Iteration 100/1000 | Loss: 0.00003345
Iteration 101/1000 | Loss: 0.00003344
Iteration 102/1000 | Loss: 0.00003344
Iteration 103/1000 | Loss: 0.00003344
Iteration 104/1000 | Loss: 0.00003344
Iteration 105/1000 | Loss: 0.00003344
Iteration 106/1000 | Loss: 0.00003343
Iteration 107/1000 | Loss: 0.00003343
Iteration 108/1000 | Loss: 0.00003343
Iteration 109/1000 | Loss: 0.00003343
Iteration 110/1000 | Loss: 0.00003343
Iteration 111/1000 | Loss: 0.00003343
Iteration 112/1000 | Loss: 0.00003342
Iteration 113/1000 | Loss: 0.00003342
Iteration 114/1000 | Loss: 0.00003342
Iteration 115/1000 | Loss: 0.00003342
Iteration 116/1000 | Loss: 0.00003342
Iteration 117/1000 | Loss: 0.00003342
Iteration 118/1000 | Loss: 0.00003342
Iteration 119/1000 | Loss: 0.00003342
Iteration 120/1000 | Loss: 0.00003342
Iteration 121/1000 | Loss: 0.00003342
Iteration 122/1000 | Loss: 0.00003342
Iteration 123/1000 | Loss: 0.00003342
Iteration 124/1000 | Loss: 0.00003342
Iteration 125/1000 | Loss: 0.00003342
Iteration 126/1000 | Loss: 0.00003342
Iteration 127/1000 | Loss: 0.00003342
Iteration 128/1000 | Loss: 0.00003342
Iteration 129/1000 | Loss: 0.00003342
Iteration 130/1000 | Loss: 0.00003342
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 130. Stopping optimization.
Last 5 losses: [3.341742558404803e-05, 3.341742558404803e-05, 3.341742558404803e-05, 3.341742558404803e-05, 3.341742558404803e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.341742558404803e-05

Optimization complete. Final v2v error: 4.771697521209717 mm

Highest mean error: 6.11011266708374 mm for frame 118

Lowest mean error: 3.9745359420776367 mm for frame 0

Saving results

Total time: 53.30014967918396
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1055/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1055.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1055
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00699531
Iteration 2/25 | Loss: 0.00126113
Iteration 3/25 | Loss: 0.00100055
Iteration 4/25 | Loss: 0.00092485
Iteration 5/25 | Loss: 0.00089324
Iteration 6/25 | Loss: 0.00088016
Iteration 7/25 | Loss: 0.00087925
Iteration 8/25 | Loss: 0.00086982
Iteration 9/25 | Loss: 0.00086946
Iteration 10/25 | Loss: 0.00087178
Iteration 11/25 | Loss: 0.00086749
Iteration 12/25 | Loss: 0.00089238
Iteration 13/25 | Loss: 0.00086237
Iteration 14/25 | Loss: 0.00085706
Iteration 15/25 | Loss: 0.00085621
Iteration 16/25 | Loss: 0.00085610
Iteration 17/25 | Loss: 0.00085610
Iteration 18/25 | Loss: 0.00085610
Iteration 19/25 | Loss: 0.00085610
Iteration 20/25 | Loss: 0.00085610
Iteration 21/25 | Loss: 0.00085609
Iteration 22/25 | Loss: 0.00085609
Iteration 23/25 | Loss: 0.00085609
Iteration 24/25 | Loss: 0.00085609
Iteration 25/25 | Loss: 0.00085609

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.54892302
Iteration 2/25 | Loss: 0.00067236
Iteration 3/25 | Loss: 0.00067236
Iteration 4/25 | Loss: 0.00067236
Iteration 5/25 | Loss: 0.00067236
Iteration 6/25 | Loss: 0.00067236
Iteration 7/25 | Loss: 0.00067236
Iteration 8/25 | Loss: 0.00067236
Iteration 9/25 | Loss: 0.00067236
Iteration 10/25 | Loss: 0.00067236
Iteration 11/25 | Loss: 0.00067236
Iteration 12/25 | Loss: 0.00067236
Iteration 13/25 | Loss: 0.00067236
Iteration 14/25 | Loss: 0.00067236
Iteration 15/25 | Loss: 0.00067236
Iteration 16/25 | Loss: 0.00067236
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006723551778122783, 0.0006723551778122783, 0.0006723551778122783, 0.0006723551778122783, 0.0006723551778122783]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006723551778122783

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00067236
Iteration 2/1000 | Loss: 0.00005535
Iteration 3/1000 | Loss: 0.00003523
Iteration 4/1000 | Loss: 0.00002949
Iteration 5/1000 | Loss: 0.00002813
Iteration 6/1000 | Loss: 0.00002704
Iteration 7/1000 | Loss: 0.00002651
Iteration 8/1000 | Loss: 0.00002613
Iteration 9/1000 | Loss: 0.00002582
Iteration 10/1000 | Loss: 0.00002546
Iteration 11/1000 | Loss: 0.00002519
Iteration 12/1000 | Loss: 0.00002497
Iteration 13/1000 | Loss: 0.00002483
Iteration 14/1000 | Loss: 0.00002470
Iteration 15/1000 | Loss: 0.00002456
Iteration 16/1000 | Loss: 0.00002450
Iteration 17/1000 | Loss: 0.00002445
Iteration 18/1000 | Loss: 0.00002445
Iteration 19/1000 | Loss: 0.00002444
Iteration 20/1000 | Loss: 0.00002443
Iteration 21/1000 | Loss: 0.00002443
Iteration 22/1000 | Loss: 0.00002442
Iteration 23/1000 | Loss: 0.00002442
Iteration 24/1000 | Loss: 0.00002441
Iteration 25/1000 | Loss: 0.00002440
Iteration 26/1000 | Loss: 0.00002440
Iteration 27/1000 | Loss: 0.00002439
Iteration 28/1000 | Loss: 0.00002439
Iteration 29/1000 | Loss: 0.00002439
Iteration 30/1000 | Loss: 0.00002439
Iteration 31/1000 | Loss: 0.00002438
Iteration 32/1000 | Loss: 0.00002438
Iteration 33/1000 | Loss: 0.00002438
Iteration 34/1000 | Loss: 0.00002438
Iteration 35/1000 | Loss: 0.00002438
Iteration 36/1000 | Loss: 0.00002437
Iteration 37/1000 | Loss: 0.00002437
Iteration 38/1000 | Loss: 0.00002437
Iteration 39/1000 | Loss: 0.00002436
Iteration 40/1000 | Loss: 0.00002436
Iteration 41/1000 | Loss: 0.00002436
Iteration 42/1000 | Loss: 0.00002436
Iteration 43/1000 | Loss: 0.00002436
Iteration 44/1000 | Loss: 0.00002436
Iteration 45/1000 | Loss: 0.00002436
Iteration 46/1000 | Loss: 0.00002435
Iteration 47/1000 | Loss: 0.00002435
Iteration 48/1000 | Loss: 0.00002435
Iteration 49/1000 | Loss: 0.00002435
Iteration 50/1000 | Loss: 0.00002435
Iteration 51/1000 | Loss: 0.00002435
Iteration 52/1000 | Loss: 0.00002434
Iteration 53/1000 | Loss: 0.00002434
Iteration 54/1000 | Loss: 0.00002434
Iteration 55/1000 | Loss: 0.00002434
Iteration 56/1000 | Loss: 0.00002434
Iteration 57/1000 | Loss: 0.00002434
Iteration 58/1000 | Loss: 0.00002434
Iteration 59/1000 | Loss: 0.00002434
Iteration 60/1000 | Loss: 0.00002434
Iteration 61/1000 | Loss: 0.00002434
Iteration 62/1000 | Loss: 0.00002433
Iteration 63/1000 | Loss: 0.00002433
Iteration 64/1000 | Loss: 0.00002433
Iteration 65/1000 | Loss: 0.00002433
Iteration 66/1000 | Loss: 0.00002433
Iteration 67/1000 | Loss: 0.00002433
Iteration 68/1000 | Loss: 0.00002433
Iteration 69/1000 | Loss: 0.00002433
Iteration 70/1000 | Loss: 0.00002433
Iteration 71/1000 | Loss: 0.00002433
Iteration 72/1000 | Loss: 0.00002433
Iteration 73/1000 | Loss: 0.00002433
Iteration 74/1000 | Loss: 0.00002433
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 74. Stopping optimization.
Last 5 losses: [2.4331473468919285e-05, 2.4331473468919285e-05, 2.4331473468919285e-05, 2.4331473468919285e-05, 2.4331473468919285e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.4331473468919285e-05

Optimization complete. Final v2v error: 4.156473636627197 mm

Highest mean error: 4.685278415679932 mm for frame 123

Lowest mean error: 3.12149977684021 mm for frame 180

Saving results

Total time: 56.02151155471802
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00380829
Iteration 2/25 | Loss: 0.00084177
Iteration 3/25 | Loss: 0.00074397
Iteration 4/25 | Loss: 0.00073042
Iteration 5/25 | Loss: 0.00072591
Iteration 6/25 | Loss: 0.00072536
Iteration 7/25 | Loss: 0.00072536
Iteration 8/25 | Loss: 0.00072536
Iteration 9/25 | Loss: 0.00072536
Iteration 10/25 | Loss: 0.00072536
Iteration 11/25 | Loss: 0.00072536
Iteration 12/25 | Loss: 0.00072536
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007253572694025934, 0.0007253572694025934, 0.0007253572694025934, 0.0007253572694025934, 0.0007253572694025934]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007253572694025934

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50318158
Iteration 2/25 | Loss: 0.00045060
Iteration 3/25 | Loss: 0.00045059
Iteration 4/25 | Loss: 0.00045059
Iteration 5/25 | Loss: 0.00045059
Iteration 6/25 | Loss: 0.00045059
Iteration 7/25 | Loss: 0.00045059
Iteration 8/25 | Loss: 0.00045059
Iteration 9/25 | Loss: 0.00045059
Iteration 10/25 | Loss: 0.00045059
Iteration 11/25 | Loss: 0.00045059
Iteration 12/25 | Loss: 0.00045059
Iteration 13/25 | Loss: 0.00045059
Iteration 14/25 | Loss: 0.00045059
Iteration 15/25 | Loss: 0.00045059
Iteration 16/25 | Loss: 0.00045059
Iteration 17/25 | Loss: 0.00045059
Iteration 18/25 | Loss: 0.00045059
Iteration 19/25 | Loss: 0.00045059
Iteration 20/25 | Loss: 0.00045059
Iteration 21/25 | Loss: 0.00045059
Iteration 22/25 | Loss: 0.00045059
Iteration 23/25 | Loss: 0.00045059
Iteration 24/25 | Loss: 0.00045059
Iteration 25/25 | Loss: 0.00045059
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.000450591032858938, 0.000450591032858938, 0.000450591032858938, 0.000450591032858938, 0.000450591032858938]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000450591032858938

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045059
Iteration 2/1000 | Loss: 0.00002101
Iteration 3/1000 | Loss: 0.00001532
Iteration 4/1000 | Loss: 0.00001403
Iteration 5/1000 | Loss: 0.00001353
Iteration 6/1000 | Loss: 0.00001306
Iteration 7/1000 | Loss: 0.00001291
Iteration 8/1000 | Loss: 0.00001272
Iteration 9/1000 | Loss: 0.00001267
Iteration 10/1000 | Loss: 0.00001262
Iteration 11/1000 | Loss: 0.00001252
Iteration 12/1000 | Loss: 0.00001244
Iteration 13/1000 | Loss: 0.00001238
Iteration 14/1000 | Loss: 0.00001238
Iteration 15/1000 | Loss: 0.00001237
Iteration 16/1000 | Loss: 0.00001236
Iteration 17/1000 | Loss: 0.00001236
Iteration 18/1000 | Loss: 0.00001235
Iteration 19/1000 | Loss: 0.00001235
Iteration 20/1000 | Loss: 0.00001234
Iteration 21/1000 | Loss: 0.00001234
Iteration 22/1000 | Loss: 0.00001230
Iteration 23/1000 | Loss: 0.00001224
Iteration 24/1000 | Loss: 0.00001223
Iteration 25/1000 | Loss: 0.00001221
Iteration 26/1000 | Loss: 0.00001220
Iteration 27/1000 | Loss: 0.00001219
Iteration 28/1000 | Loss: 0.00001219
Iteration 29/1000 | Loss: 0.00001219
Iteration 30/1000 | Loss: 0.00001219
Iteration 31/1000 | Loss: 0.00001218
Iteration 32/1000 | Loss: 0.00001218
Iteration 33/1000 | Loss: 0.00001218
Iteration 34/1000 | Loss: 0.00001217
Iteration 35/1000 | Loss: 0.00001217
Iteration 36/1000 | Loss: 0.00001216
Iteration 37/1000 | Loss: 0.00001216
Iteration 38/1000 | Loss: 0.00001215
Iteration 39/1000 | Loss: 0.00001215
Iteration 40/1000 | Loss: 0.00001215
Iteration 41/1000 | Loss: 0.00001213
Iteration 42/1000 | Loss: 0.00001211
Iteration 43/1000 | Loss: 0.00001211
Iteration 44/1000 | Loss: 0.00001210
Iteration 45/1000 | Loss: 0.00001210
Iteration 46/1000 | Loss: 0.00001210
Iteration 47/1000 | Loss: 0.00001209
Iteration 48/1000 | Loss: 0.00001205
Iteration 49/1000 | Loss: 0.00001205
Iteration 50/1000 | Loss: 0.00001205
Iteration 51/1000 | Loss: 0.00001204
Iteration 52/1000 | Loss: 0.00001204
Iteration 53/1000 | Loss: 0.00001203
Iteration 54/1000 | Loss: 0.00001203
Iteration 55/1000 | Loss: 0.00001202
Iteration 56/1000 | Loss: 0.00001202
Iteration 57/1000 | Loss: 0.00001201
Iteration 58/1000 | Loss: 0.00001201
Iteration 59/1000 | Loss: 0.00001200
Iteration 60/1000 | Loss: 0.00001197
Iteration 61/1000 | Loss: 0.00001196
Iteration 62/1000 | Loss: 0.00001195
Iteration 63/1000 | Loss: 0.00001194
Iteration 64/1000 | Loss: 0.00001194
Iteration 65/1000 | Loss: 0.00001193
Iteration 66/1000 | Loss: 0.00001193
Iteration 67/1000 | Loss: 0.00001193
Iteration 68/1000 | Loss: 0.00001193
Iteration 69/1000 | Loss: 0.00001193
Iteration 70/1000 | Loss: 0.00001193
Iteration 71/1000 | Loss: 0.00001193
Iteration 72/1000 | Loss: 0.00001193
Iteration 73/1000 | Loss: 0.00001193
Iteration 74/1000 | Loss: 0.00001193
Iteration 75/1000 | Loss: 0.00001193
Iteration 76/1000 | Loss: 0.00001193
Iteration 77/1000 | Loss: 0.00001192
Iteration 78/1000 | Loss: 0.00001192
Iteration 79/1000 | Loss: 0.00001192
Iteration 80/1000 | Loss: 0.00001191
Iteration 81/1000 | Loss: 0.00001191
Iteration 82/1000 | Loss: 0.00001191
Iteration 83/1000 | Loss: 0.00001191
Iteration 84/1000 | Loss: 0.00001190
Iteration 85/1000 | Loss: 0.00001190
Iteration 86/1000 | Loss: 0.00001190
Iteration 87/1000 | Loss: 0.00001190
Iteration 88/1000 | Loss: 0.00001190
Iteration 89/1000 | Loss: 0.00001190
Iteration 90/1000 | Loss: 0.00001190
Iteration 91/1000 | Loss: 0.00001190
Iteration 92/1000 | Loss: 0.00001190
Iteration 93/1000 | Loss: 0.00001189
Iteration 94/1000 | Loss: 0.00001189
Iteration 95/1000 | Loss: 0.00001189
Iteration 96/1000 | Loss: 0.00001189
Iteration 97/1000 | Loss: 0.00001189
Iteration 98/1000 | Loss: 0.00001189
Iteration 99/1000 | Loss: 0.00001189
Iteration 100/1000 | Loss: 0.00001189
Iteration 101/1000 | Loss: 0.00001189
Iteration 102/1000 | Loss: 0.00001189
Iteration 103/1000 | Loss: 0.00001189
Iteration 104/1000 | Loss: 0.00001189
Iteration 105/1000 | Loss: 0.00001189
Iteration 106/1000 | Loss: 0.00001189
Iteration 107/1000 | Loss: 0.00001189
Iteration 108/1000 | Loss: 0.00001189
Iteration 109/1000 | Loss: 0.00001189
Iteration 110/1000 | Loss: 0.00001189
Iteration 111/1000 | Loss: 0.00001189
Iteration 112/1000 | Loss: 0.00001189
Iteration 113/1000 | Loss: 0.00001189
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 113. Stopping optimization.
Last 5 losses: [1.1894819181179628e-05, 1.1894819181179628e-05, 1.1894819181179628e-05, 1.1894819181179628e-05, 1.1894819181179628e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1894819181179628e-05

Optimization complete. Final v2v error: 2.9318504333496094 mm

Highest mean error: 3.0296080112457275 mm for frame 179

Lowest mean error: 2.849261522293091 mm for frame 63

Saving results

Total time: 35.69445514678955
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1056/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1056.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1056
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01052084
Iteration 2/25 | Loss: 0.00239749
Iteration 3/25 | Loss: 0.00286295
Iteration 4/25 | Loss: 0.00168579
Iteration 5/25 | Loss: 0.00107453
Iteration 6/25 | Loss: 0.00099720
Iteration 7/25 | Loss: 0.00093288
Iteration 8/25 | Loss: 0.00090795
Iteration 9/25 | Loss: 0.00089111
Iteration 10/25 | Loss: 0.00089258
Iteration 11/25 | Loss: 0.00086125
Iteration 12/25 | Loss: 0.00084866
Iteration 13/25 | Loss: 0.00083993
Iteration 14/25 | Loss: 0.00083775
Iteration 15/25 | Loss: 0.00083687
Iteration 16/25 | Loss: 0.00083539
Iteration 17/25 | Loss: 0.00083651
Iteration 18/25 | Loss: 0.00083236
Iteration 19/25 | Loss: 0.00083071
Iteration 20/25 | Loss: 0.00082867
Iteration 21/25 | Loss: 0.00082682
Iteration 22/25 | Loss: 0.00082622
Iteration 23/25 | Loss: 0.00082577
Iteration 24/25 | Loss: 0.00082572
Iteration 25/25 | Loss: 0.00082572

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.57447708
Iteration 2/25 | Loss: 0.00055594
Iteration 3/25 | Loss: 0.00048770
Iteration 4/25 | Loss: 0.00048769
Iteration 5/25 | Loss: 0.00048769
Iteration 6/25 | Loss: 0.00048769
Iteration 7/25 | Loss: 0.00048769
Iteration 8/25 | Loss: 0.00048769
Iteration 9/25 | Loss: 0.00048769
Iteration 10/25 | Loss: 0.00048769
Iteration 11/25 | Loss: 0.00048769
Iteration 12/25 | Loss: 0.00048769
Iteration 13/25 | Loss: 0.00048769
Iteration 14/25 | Loss: 0.00048769
Iteration 15/25 | Loss: 0.00048769
Iteration 16/25 | Loss: 0.00048769
Iteration 17/25 | Loss: 0.00048769
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004876924504060298, 0.0004876924504060298, 0.0004876924504060298, 0.0004876924504060298, 0.0004876924504060298]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004876924504060298

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048769
Iteration 2/1000 | Loss: 0.00003870
Iteration 3/1000 | Loss: 0.00002683
Iteration 4/1000 | Loss: 0.00002474
Iteration 5/1000 | Loss: 0.00045324
Iteration 6/1000 | Loss: 0.00137394
Iteration 7/1000 | Loss: 0.00002450
Iteration 8/1000 | Loss: 0.00002201
Iteration 9/1000 | Loss: 0.00002095
Iteration 10/1000 | Loss: 0.00002028
Iteration 11/1000 | Loss: 0.00001983
Iteration 12/1000 | Loss: 0.00001960
Iteration 13/1000 | Loss: 0.00001959
Iteration 14/1000 | Loss: 0.00001937
Iteration 15/1000 | Loss: 0.00001919
Iteration 16/1000 | Loss: 0.00001901
Iteration 17/1000 | Loss: 0.00001887
Iteration 18/1000 | Loss: 0.00001886
Iteration 19/1000 | Loss: 0.00001886
Iteration 20/1000 | Loss: 0.00001886
Iteration 21/1000 | Loss: 0.00001880
Iteration 22/1000 | Loss: 0.00001880
Iteration 23/1000 | Loss: 0.00001878
Iteration 24/1000 | Loss: 0.00001877
Iteration 25/1000 | Loss: 0.00001877
Iteration 26/1000 | Loss: 0.00001876
Iteration 27/1000 | Loss: 0.00001876
Iteration 28/1000 | Loss: 0.00001876
Iteration 29/1000 | Loss: 0.00001876
Iteration 30/1000 | Loss: 0.00001876
Iteration 31/1000 | Loss: 0.00001875
Iteration 32/1000 | Loss: 0.00001875
Iteration 33/1000 | Loss: 0.00001875
Iteration 34/1000 | Loss: 0.00001874
Iteration 35/1000 | Loss: 0.00001874
Iteration 36/1000 | Loss: 0.00001874
Iteration 37/1000 | Loss: 0.00001874
Iteration 38/1000 | Loss: 0.00001874
Iteration 39/1000 | Loss: 0.00001874
Iteration 40/1000 | Loss: 0.00001874
Iteration 41/1000 | Loss: 0.00001874
Iteration 42/1000 | Loss: 0.00001874
Iteration 43/1000 | Loss: 0.00001873
Iteration 44/1000 | Loss: 0.00001873
Iteration 45/1000 | Loss: 0.00001873
Iteration 46/1000 | Loss: 0.00001873
Iteration 47/1000 | Loss: 0.00001873
Iteration 48/1000 | Loss: 0.00001873
Iteration 49/1000 | Loss: 0.00001873
Iteration 50/1000 | Loss: 0.00001873
Iteration 51/1000 | Loss: 0.00001872
Iteration 52/1000 | Loss: 0.00001872
Iteration 53/1000 | Loss: 0.00001872
Iteration 54/1000 | Loss: 0.00001872
Iteration 55/1000 | Loss: 0.00001872
Iteration 56/1000 | Loss: 0.00001872
Iteration 57/1000 | Loss: 0.00001872
Iteration 58/1000 | Loss: 0.00001871
Iteration 59/1000 | Loss: 0.00001871
Iteration 60/1000 | Loss: 0.00001871
Iteration 61/1000 | Loss: 0.00001871
Iteration 62/1000 | Loss: 0.00001871
Iteration 63/1000 | Loss: 0.00001870
Iteration 64/1000 | Loss: 0.00001870
Iteration 65/1000 | Loss: 0.00001870
Iteration 66/1000 | Loss: 0.00001870
Iteration 67/1000 | Loss: 0.00001869
Iteration 68/1000 | Loss: 0.00001869
Iteration 69/1000 | Loss: 0.00001869
Iteration 70/1000 | Loss: 0.00001869
Iteration 71/1000 | Loss: 0.00001869
Iteration 72/1000 | Loss: 0.00001869
Iteration 73/1000 | Loss: 0.00001868
Iteration 74/1000 | Loss: 0.00001868
Iteration 75/1000 | Loss: 0.00001868
Iteration 76/1000 | Loss: 0.00001867
Iteration 77/1000 | Loss: 0.00001867
Iteration 78/1000 | Loss: 0.00001867
Iteration 79/1000 | Loss: 0.00001867
Iteration 80/1000 | Loss: 0.00001867
Iteration 81/1000 | Loss: 0.00001867
Iteration 82/1000 | Loss: 0.00001867
Iteration 83/1000 | Loss: 0.00001867
Iteration 84/1000 | Loss: 0.00001867
Iteration 85/1000 | Loss: 0.00001867
Iteration 86/1000 | Loss: 0.00001867
Iteration 87/1000 | Loss: 0.00001867
Iteration 88/1000 | Loss: 0.00001867
Iteration 89/1000 | Loss: 0.00001866
Iteration 90/1000 | Loss: 0.00001866
Iteration 91/1000 | Loss: 0.00001866
Iteration 92/1000 | Loss: 0.00001866
Iteration 93/1000 | Loss: 0.00001866
Iteration 94/1000 | Loss: 0.00001866
Iteration 95/1000 | Loss: 0.00001866
Iteration 96/1000 | Loss: 0.00001865
Iteration 97/1000 | Loss: 0.00001865
Iteration 98/1000 | Loss: 0.00001865
Iteration 99/1000 | Loss: 0.00001865
Iteration 100/1000 | Loss: 0.00001865
Iteration 101/1000 | Loss: 0.00001865
Iteration 102/1000 | Loss: 0.00001865
Iteration 103/1000 | Loss: 0.00001864
Iteration 104/1000 | Loss: 0.00001864
Iteration 105/1000 | Loss: 0.00001864
Iteration 106/1000 | Loss: 0.00001864
Iteration 107/1000 | Loss: 0.00001864
Iteration 108/1000 | Loss: 0.00001864
Iteration 109/1000 | Loss: 0.00001864
Iteration 110/1000 | Loss: 0.00001864
Iteration 111/1000 | Loss: 0.00001864
Iteration 112/1000 | Loss: 0.00001864
Iteration 113/1000 | Loss: 0.00001864
Iteration 114/1000 | Loss: 0.00001864
Iteration 115/1000 | Loss: 0.00001863
Iteration 116/1000 | Loss: 0.00001863
Iteration 117/1000 | Loss: 0.00001863
Iteration 118/1000 | Loss: 0.00001862
Iteration 119/1000 | Loss: 0.00001862
Iteration 120/1000 | Loss: 0.00001862
Iteration 121/1000 | Loss: 0.00001862
Iteration 122/1000 | Loss: 0.00001862
Iteration 123/1000 | Loss: 0.00001861
Iteration 124/1000 | Loss: 0.00001861
Iteration 125/1000 | Loss: 0.00001861
Iteration 126/1000 | Loss: 0.00001861
Iteration 127/1000 | Loss: 0.00001861
Iteration 128/1000 | Loss: 0.00001861
Iteration 129/1000 | Loss: 0.00001860
Iteration 130/1000 | Loss: 0.00001860
Iteration 131/1000 | Loss: 0.00001860
Iteration 132/1000 | Loss: 0.00001860
Iteration 133/1000 | Loss: 0.00001860
Iteration 134/1000 | Loss: 0.00001860
Iteration 135/1000 | Loss: 0.00001859
Iteration 136/1000 | Loss: 0.00001859
Iteration 137/1000 | Loss: 0.00001859
Iteration 138/1000 | Loss: 0.00001859
Iteration 139/1000 | Loss: 0.00001859
Iteration 140/1000 | Loss: 0.00001859
Iteration 141/1000 | Loss: 0.00001859
Iteration 142/1000 | Loss: 0.00001858
Iteration 143/1000 | Loss: 0.00001858
Iteration 144/1000 | Loss: 0.00001858
Iteration 145/1000 | Loss: 0.00001858
Iteration 146/1000 | Loss: 0.00001858
Iteration 147/1000 | Loss: 0.00001858
Iteration 148/1000 | Loss: 0.00001858
Iteration 149/1000 | Loss: 0.00001858
Iteration 150/1000 | Loss: 0.00001858
Iteration 151/1000 | Loss: 0.00001858
Iteration 152/1000 | Loss: 0.00001858
Iteration 153/1000 | Loss: 0.00001858
Iteration 154/1000 | Loss: 0.00001858
Iteration 155/1000 | Loss: 0.00001858
Iteration 156/1000 | Loss: 0.00001858
Iteration 157/1000 | Loss: 0.00001857
Iteration 158/1000 | Loss: 0.00001857
Iteration 159/1000 | Loss: 0.00001857
Iteration 160/1000 | Loss: 0.00001857
Iteration 161/1000 | Loss: 0.00001857
Iteration 162/1000 | Loss: 0.00001857
Iteration 163/1000 | Loss: 0.00001857
Iteration 164/1000 | Loss: 0.00001857
Iteration 165/1000 | Loss: 0.00001856
Iteration 166/1000 | Loss: 0.00001856
Iteration 167/1000 | Loss: 0.00001856
Iteration 168/1000 | Loss: 0.00001856
Iteration 169/1000 | Loss: 0.00001856
Iteration 170/1000 | Loss: 0.00001856
Iteration 171/1000 | Loss: 0.00001856
Iteration 172/1000 | Loss: 0.00001855
Iteration 173/1000 | Loss: 0.00001855
Iteration 174/1000 | Loss: 0.00001855
Iteration 175/1000 | Loss: 0.00001855
Iteration 176/1000 | Loss: 0.00001855
Iteration 177/1000 | Loss: 0.00001855
Iteration 178/1000 | Loss: 0.00001854
Iteration 179/1000 | Loss: 0.00001854
Iteration 180/1000 | Loss: 0.00001854
Iteration 181/1000 | Loss: 0.00001854
Iteration 182/1000 | Loss: 0.00001854
Iteration 183/1000 | Loss: 0.00001854
Iteration 184/1000 | Loss: 0.00001854
Iteration 185/1000 | Loss: 0.00001854
Iteration 186/1000 | Loss: 0.00001854
Iteration 187/1000 | Loss: 0.00001854
Iteration 188/1000 | Loss: 0.00001854
Iteration 189/1000 | Loss: 0.00001854
Iteration 190/1000 | Loss: 0.00001853
Iteration 191/1000 | Loss: 0.00001853
Iteration 192/1000 | Loss: 0.00001853
Iteration 193/1000 | Loss: 0.00001853
Iteration 194/1000 | Loss: 0.00001853
Iteration 195/1000 | Loss: 0.00001853
Iteration 196/1000 | Loss: 0.00001853
Iteration 197/1000 | Loss: 0.00001853
Iteration 198/1000 | Loss: 0.00001853
Iteration 199/1000 | Loss: 0.00001853
Iteration 200/1000 | Loss: 0.00001853
Iteration 201/1000 | Loss: 0.00001853
Iteration 202/1000 | Loss: 0.00001853
Iteration 203/1000 | Loss: 0.00001853
Iteration 204/1000 | Loss: 0.00001853
Iteration 205/1000 | Loss: 0.00001853
Iteration 206/1000 | Loss: 0.00001853
Iteration 207/1000 | Loss: 0.00001853
Iteration 208/1000 | Loss: 0.00001853
Iteration 209/1000 | Loss: 0.00001853
Iteration 210/1000 | Loss: 0.00001853
Iteration 211/1000 | Loss: 0.00001853
Iteration 212/1000 | Loss: 0.00001853
Iteration 213/1000 | Loss: 0.00001853
Iteration 214/1000 | Loss: 0.00001853
Iteration 215/1000 | Loss: 0.00001853
Iteration 216/1000 | Loss: 0.00001853
Iteration 217/1000 | Loss: 0.00001853
Iteration 218/1000 | Loss: 0.00001853
Iteration 219/1000 | Loss: 0.00001853
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 219. Stopping optimization.
Last 5 losses: [1.852511013566982e-05, 1.852511013566982e-05, 1.852511013566982e-05, 1.852511013566982e-05, 1.852511013566982e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.852511013566982e-05

Optimization complete. Final v2v error: 3.5671627521514893 mm

Highest mean error: 5.109656810760498 mm for frame 110

Lowest mean error: 2.959681987762451 mm for frame 170

Saving results

Total time: 90.46281266212463
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1099/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1099.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1099
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00811748
Iteration 2/25 | Loss: 0.00117573
Iteration 3/25 | Loss: 0.00091903
Iteration 4/25 | Loss: 0.00086542
Iteration 5/25 | Loss: 0.00084685
Iteration 6/25 | Loss: 0.00084245
Iteration 7/25 | Loss: 0.00084068
Iteration 8/25 | Loss: 0.00084040
Iteration 9/25 | Loss: 0.00084040
Iteration 10/25 | Loss: 0.00084040
Iteration 11/25 | Loss: 0.00084040
Iteration 12/25 | Loss: 0.00084040
Iteration 13/25 | Loss: 0.00084040
Iteration 14/25 | Loss: 0.00084040
Iteration 15/25 | Loss: 0.00084040
Iteration 16/25 | Loss: 0.00084040
Iteration 17/25 | Loss: 0.00084040
Iteration 18/25 | Loss: 0.00084040
Iteration 19/25 | Loss: 0.00084040
Iteration 20/25 | Loss: 0.00084040
Iteration 21/25 | Loss: 0.00084040
Iteration 22/25 | Loss: 0.00084040
Iteration 23/25 | Loss: 0.00084040
Iteration 24/25 | Loss: 0.00084040
Iteration 25/25 | Loss: 0.00084040
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0008404009859077632, 0.0008404009859077632, 0.0008404009859077632, 0.0008404009859077632, 0.0008404009859077632]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008404009859077632

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53884411
Iteration 2/25 | Loss: 0.00082208
Iteration 3/25 | Loss: 0.00082208
Iteration 4/25 | Loss: 0.00082208
Iteration 5/25 | Loss: 0.00082208
Iteration 6/25 | Loss: 0.00082208
Iteration 7/25 | Loss: 0.00082208
Iteration 8/25 | Loss: 0.00082208
Iteration 9/25 | Loss: 0.00082208
Iteration 10/25 | Loss: 0.00082208
Iteration 11/25 | Loss: 0.00082208
Iteration 12/25 | Loss: 0.00082208
Iteration 13/25 | Loss: 0.00082208
Iteration 14/25 | Loss: 0.00082208
Iteration 15/25 | Loss: 0.00082208
Iteration 16/25 | Loss: 0.00082208
Iteration 17/25 | Loss: 0.00082208
Iteration 18/25 | Loss: 0.00082208
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0008220762247219682, 0.0008220762247219682, 0.0008220762247219682, 0.0008220762247219682, 0.0008220762247219682]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008220762247219682

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00082208
Iteration 2/1000 | Loss: 0.00005383
Iteration 3/1000 | Loss: 0.00004385
Iteration 4/1000 | Loss: 0.00003353
Iteration 5/1000 | Loss: 0.00003035
Iteration 6/1000 | Loss: 0.00002844
Iteration 7/1000 | Loss: 0.00002691
Iteration 8/1000 | Loss: 0.00002607
Iteration 9/1000 | Loss: 0.00002553
Iteration 10/1000 | Loss: 0.00002515
Iteration 11/1000 | Loss: 0.00002493
Iteration 12/1000 | Loss: 0.00002474
Iteration 13/1000 | Loss: 0.00002454
Iteration 14/1000 | Loss: 0.00002452
Iteration 15/1000 | Loss: 0.00002445
Iteration 16/1000 | Loss: 0.00002440
Iteration 17/1000 | Loss: 0.00002426
Iteration 18/1000 | Loss: 0.00002426
Iteration 19/1000 | Loss: 0.00002422
Iteration 20/1000 | Loss: 0.00002420
Iteration 21/1000 | Loss: 0.00002419
Iteration 22/1000 | Loss: 0.00002419
Iteration 23/1000 | Loss: 0.00002418
Iteration 24/1000 | Loss: 0.00002418
Iteration 25/1000 | Loss: 0.00002413
Iteration 26/1000 | Loss: 0.00002412
Iteration 27/1000 | Loss: 0.00002412
Iteration 28/1000 | Loss: 0.00002411
Iteration 29/1000 | Loss: 0.00002411
Iteration 30/1000 | Loss: 0.00002411
Iteration 31/1000 | Loss: 0.00002410
Iteration 32/1000 | Loss: 0.00002409
Iteration 33/1000 | Loss: 0.00002409
Iteration 34/1000 | Loss: 0.00002408
Iteration 35/1000 | Loss: 0.00002408
Iteration 36/1000 | Loss: 0.00002408
Iteration 37/1000 | Loss: 0.00002407
Iteration 38/1000 | Loss: 0.00002407
Iteration 39/1000 | Loss: 0.00002404
Iteration 40/1000 | Loss: 0.00002402
Iteration 41/1000 | Loss: 0.00002402
Iteration 42/1000 | Loss: 0.00002402
Iteration 43/1000 | Loss: 0.00002402
Iteration 44/1000 | Loss: 0.00002402
Iteration 45/1000 | Loss: 0.00002401
Iteration 46/1000 | Loss: 0.00002401
Iteration 47/1000 | Loss: 0.00002401
Iteration 48/1000 | Loss: 0.00002401
Iteration 49/1000 | Loss: 0.00002401
Iteration 50/1000 | Loss: 0.00002401
Iteration 51/1000 | Loss: 0.00002401
Iteration 52/1000 | Loss: 0.00002401
Iteration 53/1000 | Loss: 0.00002401
Iteration 54/1000 | Loss: 0.00002401
Iteration 55/1000 | Loss: 0.00002401
Iteration 56/1000 | Loss: 0.00002401
Iteration 57/1000 | Loss: 0.00002401
Iteration 58/1000 | Loss: 0.00002400
Iteration 59/1000 | Loss: 0.00002400
Iteration 60/1000 | Loss: 0.00002400
Iteration 61/1000 | Loss: 0.00002400
Iteration 62/1000 | Loss: 0.00002400
Iteration 63/1000 | Loss: 0.00002400
Iteration 64/1000 | Loss: 0.00002400
Iteration 65/1000 | Loss: 0.00002400
Iteration 66/1000 | Loss: 0.00002399
Iteration 67/1000 | Loss: 0.00002399
Iteration 68/1000 | Loss: 0.00002398
Iteration 69/1000 | Loss: 0.00002398
Iteration 70/1000 | Loss: 0.00002398
Iteration 71/1000 | Loss: 0.00002398
Iteration 72/1000 | Loss: 0.00002398
Iteration 73/1000 | Loss: 0.00002398
Iteration 74/1000 | Loss: 0.00002398
Iteration 75/1000 | Loss: 0.00002397
Iteration 76/1000 | Loss: 0.00002397
Iteration 77/1000 | Loss: 0.00002397
Iteration 78/1000 | Loss: 0.00002397
Iteration 79/1000 | Loss: 0.00002397
Iteration 80/1000 | Loss: 0.00002397
Iteration 81/1000 | Loss: 0.00002397
Iteration 82/1000 | Loss: 0.00002397
Iteration 83/1000 | Loss: 0.00002397
Iteration 84/1000 | Loss: 0.00002397
Iteration 85/1000 | Loss: 0.00002397
Iteration 86/1000 | Loss: 0.00002396
Iteration 87/1000 | Loss: 0.00002396
Iteration 88/1000 | Loss: 0.00002396
Iteration 89/1000 | Loss: 0.00002396
Iteration 90/1000 | Loss: 0.00002396
Iteration 91/1000 | Loss: 0.00002396
Iteration 92/1000 | Loss: 0.00002396
Iteration 93/1000 | Loss: 0.00002395
Iteration 94/1000 | Loss: 0.00002395
Iteration 95/1000 | Loss: 0.00002395
Iteration 96/1000 | Loss: 0.00002395
Iteration 97/1000 | Loss: 0.00002394
Iteration 98/1000 | Loss: 0.00002394
Iteration 99/1000 | Loss: 0.00002394
Iteration 100/1000 | Loss: 0.00002394
Iteration 101/1000 | Loss: 0.00002394
Iteration 102/1000 | Loss: 0.00002394
Iteration 103/1000 | Loss: 0.00002394
Iteration 104/1000 | Loss: 0.00002394
Iteration 105/1000 | Loss: 0.00002393
Iteration 106/1000 | Loss: 0.00002393
Iteration 107/1000 | Loss: 0.00002393
Iteration 108/1000 | Loss: 0.00002392
Iteration 109/1000 | Loss: 0.00002392
Iteration 110/1000 | Loss: 0.00002392
Iteration 111/1000 | Loss: 0.00002392
Iteration 112/1000 | Loss: 0.00002392
Iteration 113/1000 | Loss: 0.00002392
Iteration 114/1000 | Loss: 0.00002392
Iteration 115/1000 | Loss: 0.00002391
Iteration 116/1000 | Loss: 0.00002391
Iteration 117/1000 | Loss: 0.00002391
Iteration 118/1000 | Loss: 0.00002391
Iteration 119/1000 | Loss: 0.00002391
Iteration 120/1000 | Loss: 0.00002391
Iteration 121/1000 | Loss: 0.00002390
Iteration 122/1000 | Loss: 0.00002390
Iteration 123/1000 | Loss: 0.00002390
Iteration 124/1000 | Loss: 0.00002390
Iteration 125/1000 | Loss: 0.00002390
Iteration 126/1000 | Loss: 0.00002389
Iteration 127/1000 | Loss: 0.00002389
Iteration 128/1000 | Loss: 0.00002389
Iteration 129/1000 | Loss: 0.00002389
Iteration 130/1000 | Loss: 0.00002389
Iteration 131/1000 | Loss: 0.00002388
Iteration 132/1000 | Loss: 0.00002388
Iteration 133/1000 | Loss: 0.00002388
Iteration 134/1000 | Loss: 0.00002387
Iteration 135/1000 | Loss: 0.00002387
Iteration 136/1000 | Loss: 0.00002387
Iteration 137/1000 | Loss: 0.00002387
Iteration 138/1000 | Loss: 0.00002387
Iteration 139/1000 | Loss: 0.00002387
Iteration 140/1000 | Loss: 0.00002387
Iteration 141/1000 | Loss: 0.00002386
Iteration 142/1000 | Loss: 0.00002386
Iteration 143/1000 | Loss: 0.00002386
Iteration 144/1000 | Loss: 0.00002386
Iteration 145/1000 | Loss: 0.00002386
Iteration 146/1000 | Loss: 0.00002385
Iteration 147/1000 | Loss: 0.00002385
Iteration 148/1000 | Loss: 0.00002385
Iteration 149/1000 | Loss: 0.00002385
Iteration 150/1000 | Loss: 0.00002385
Iteration 151/1000 | Loss: 0.00002385
Iteration 152/1000 | Loss: 0.00002385
Iteration 153/1000 | Loss: 0.00002385
Iteration 154/1000 | Loss: 0.00002385
Iteration 155/1000 | Loss: 0.00002385
Iteration 156/1000 | Loss: 0.00002385
Iteration 157/1000 | Loss: 0.00002385
Iteration 158/1000 | Loss: 0.00002385
Iteration 159/1000 | Loss: 0.00002385
Iteration 160/1000 | Loss: 0.00002385
Iteration 161/1000 | Loss: 0.00002385
Iteration 162/1000 | Loss: 0.00002385
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 162. Stopping optimization.
Last 5 losses: [2.3847616830607876e-05, 2.3847616830607876e-05, 2.3847616830607876e-05, 2.3847616830607876e-05, 2.3847616830607876e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.3847616830607876e-05

Optimization complete. Final v2v error: 3.947606325149536 mm

Highest mean error: 4.54527473449707 mm for frame 123

Lowest mean error: 3.308875799179077 mm for frame 0

Saving results

Total time: 44.073755502700806
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1083/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1083.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1083
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00999176
Iteration 2/25 | Loss: 0.00999176
Iteration 3/25 | Loss: 0.00430739
Iteration 4/25 | Loss: 0.00265835
Iteration 5/25 | Loss: 0.00223783
Iteration 6/25 | Loss: 0.00184914
Iteration 7/25 | Loss: 0.00196997
Iteration 8/25 | Loss: 0.00175502
Iteration 9/25 | Loss: 0.00159944
Iteration 10/25 | Loss: 0.00153626
Iteration 11/25 | Loss: 0.00153650
Iteration 12/25 | Loss: 0.00150615
Iteration 13/25 | Loss: 0.00149931
Iteration 14/25 | Loss: 0.00149437
Iteration 15/25 | Loss: 0.00149558
Iteration 16/25 | Loss: 0.00149392
Iteration 17/25 | Loss: 0.00149349
Iteration 18/25 | Loss: 0.00149328
Iteration 19/25 | Loss: 0.00149294
Iteration 20/25 | Loss: 0.00149204
Iteration 21/25 | Loss: 0.00149311
Iteration 22/25 | Loss: 0.00149252
Iteration 23/25 | Loss: 0.00149339
Iteration 24/25 | Loss: 0.00149100
Iteration 25/25 | Loss: 0.00149050

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49284577
Iteration 2/25 | Loss: 0.01445025
Iteration 3/25 | Loss: 0.00899499
Iteration 4/25 | Loss: 0.00899494
Iteration 5/25 | Loss: 0.00899494
Iteration 6/25 | Loss: 0.00899494
Iteration 7/25 | Loss: 0.00899494
Iteration 8/25 | Loss: 0.00899494
Iteration 9/25 | Loss: 0.00899494
Iteration 10/25 | Loss: 0.00899494
Iteration 11/25 | Loss: 0.00899494
Iteration 12/25 | Loss: 0.00899494
Iteration 13/25 | Loss: 0.00899494
Iteration 14/25 | Loss: 0.00899494
Iteration 15/25 | Loss: 0.00899494
Iteration 16/25 | Loss: 0.00899494
Iteration 17/25 | Loss: 0.00899494
Iteration 18/25 | Loss: 0.00899494
Iteration 19/25 | Loss: 0.00899494
Iteration 20/25 | Loss: 0.00899494
Iteration 21/25 | Loss: 0.00899494
Iteration 22/25 | Loss: 0.00899494
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00899493508040905, 0.00899493508040905, 0.00899493508040905, 0.00899493508040905, 0.00899493508040905]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00899493508040905

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00899494
Iteration 2/1000 | Loss: 0.00624986
Iteration 3/1000 | Loss: 0.00521055
Iteration 4/1000 | Loss: 0.00132902
Iteration 5/1000 | Loss: 0.00077346
Iteration 6/1000 | Loss: 0.01109845
Iteration 7/1000 | Loss: 0.00076403
Iteration 8/1000 | Loss: 0.00115965
Iteration 9/1000 | Loss: 0.00060623
Iteration 10/1000 | Loss: 0.00048836
Iteration 11/1000 | Loss: 0.00062225
Iteration 12/1000 | Loss: 0.00173978
Iteration 13/1000 | Loss: 0.00060161
Iteration 14/1000 | Loss: 0.00038929
Iteration 15/1000 | Loss: 0.00037559
Iteration 16/1000 | Loss: 0.00064514
Iteration 17/1000 | Loss: 0.00036520
Iteration 18/1000 | Loss: 0.00049398
Iteration 19/1000 | Loss: 0.00051301
Iteration 20/1000 | Loss: 0.00128914
Iteration 21/1000 | Loss: 0.00194018
Iteration 22/1000 | Loss: 0.00126220
Iteration 23/1000 | Loss: 0.00219345
Iteration 24/1000 | Loss: 0.00117194
Iteration 25/1000 | Loss: 0.00034172
Iteration 26/1000 | Loss: 0.00037894
Iteration 27/1000 | Loss: 0.00057451
Iteration 28/1000 | Loss: 0.00084303
Iteration 29/1000 | Loss: 0.00489821
Iteration 30/1000 | Loss: 0.00079439
Iteration 31/1000 | Loss: 0.00080837
Iteration 32/1000 | Loss: 0.00071365
Iteration 33/1000 | Loss: 0.00066240
Iteration 34/1000 | Loss: 0.00031120
Iteration 35/1000 | Loss: 0.00064687
Iteration 36/1000 | Loss: 0.00067696
Iteration 37/1000 | Loss: 0.00047479
Iteration 38/1000 | Loss: 0.00033277
Iteration 39/1000 | Loss: 0.00084971
Iteration 40/1000 | Loss: 0.00068083
Iteration 41/1000 | Loss: 0.00026351
Iteration 42/1000 | Loss: 0.00044848
Iteration 43/1000 | Loss: 0.00026057
Iteration 44/1000 | Loss: 0.00031745
Iteration 45/1000 | Loss: 0.00025729
Iteration 46/1000 | Loss: 0.00099327
Iteration 47/1000 | Loss: 0.00035830
Iteration 48/1000 | Loss: 0.00049025
Iteration 49/1000 | Loss: 0.00035345
Iteration 50/1000 | Loss: 0.00025359
Iteration 51/1000 | Loss: 0.00071315
Iteration 52/1000 | Loss: 0.00033186
Iteration 53/1000 | Loss: 0.00059444
Iteration 54/1000 | Loss: 0.00210472
Iteration 55/1000 | Loss: 0.01192685
Iteration 56/1000 | Loss: 0.01416313
Iteration 57/1000 | Loss: 0.00192121
Iteration 58/1000 | Loss: 0.00350454
Iteration 59/1000 | Loss: 0.00646941
Iteration 60/1000 | Loss: 0.00041519
Iteration 61/1000 | Loss: 0.00386021
Iteration 62/1000 | Loss: 0.00187437
Iteration 63/1000 | Loss: 0.01220467
Iteration 64/1000 | Loss: 0.00039184
Iteration 65/1000 | Loss: 0.00447648
Iteration 66/1000 | Loss: 0.00394624
Iteration 67/1000 | Loss: 0.00031001
Iteration 68/1000 | Loss: 0.00039317
Iteration 69/1000 | Loss: 0.00011384
Iteration 70/1000 | Loss: 0.00027393
Iteration 71/1000 | Loss: 0.00006660
Iteration 72/1000 | Loss: 0.00010158
Iteration 73/1000 | Loss: 0.00004528
Iteration 74/1000 | Loss: 0.00066395
Iteration 75/1000 | Loss: 0.00106414
Iteration 76/1000 | Loss: 0.00010680
Iteration 77/1000 | Loss: 0.00003079
Iteration 78/1000 | Loss: 0.00014423
Iteration 79/1000 | Loss: 0.00025541
Iteration 80/1000 | Loss: 0.00064048
Iteration 81/1000 | Loss: 0.00002712
Iteration 82/1000 | Loss: 0.00002592
Iteration 83/1000 | Loss: 0.00012206
Iteration 84/1000 | Loss: 0.00002496
Iteration 85/1000 | Loss: 0.00008810
Iteration 86/1000 | Loss: 0.00007944
Iteration 87/1000 | Loss: 0.00036769
Iteration 88/1000 | Loss: 0.00032625
Iteration 89/1000 | Loss: 0.00005693
Iteration 90/1000 | Loss: 0.00009843
Iteration 91/1000 | Loss: 0.00017720
Iteration 92/1000 | Loss: 0.00011234
Iteration 93/1000 | Loss: 0.00005484
Iteration 94/1000 | Loss: 0.00025091
Iteration 95/1000 | Loss: 0.00021725
Iteration 96/1000 | Loss: 0.00013037
Iteration 97/1000 | Loss: 0.00015161
Iteration 98/1000 | Loss: 0.00002373
Iteration 99/1000 | Loss: 0.00002338
Iteration 100/1000 | Loss: 0.00002297
Iteration 101/1000 | Loss: 0.00009251
Iteration 102/1000 | Loss: 0.00002314
Iteration 103/1000 | Loss: 0.00010257
Iteration 104/1000 | Loss: 0.00053585
Iteration 105/1000 | Loss: 0.00003346
Iteration 106/1000 | Loss: 0.00002261
Iteration 107/1000 | Loss: 0.00008773
Iteration 108/1000 | Loss: 0.00004446
Iteration 109/1000 | Loss: 0.00003677
Iteration 110/1000 | Loss: 0.00002275
Iteration 111/1000 | Loss: 0.00002233
Iteration 112/1000 | Loss: 0.00002226
Iteration 113/1000 | Loss: 0.00002213
Iteration 114/1000 | Loss: 0.00002209
Iteration 115/1000 | Loss: 0.00002202
Iteration 116/1000 | Loss: 0.00002202
Iteration 117/1000 | Loss: 0.00002200
Iteration 118/1000 | Loss: 0.00002200
Iteration 119/1000 | Loss: 0.00002200
Iteration 120/1000 | Loss: 0.00002199
Iteration 121/1000 | Loss: 0.00002199
Iteration 122/1000 | Loss: 0.00002199
Iteration 123/1000 | Loss: 0.00002198
Iteration 124/1000 | Loss: 0.00002198
Iteration 125/1000 | Loss: 0.00002197
Iteration 126/1000 | Loss: 0.00002196
Iteration 127/1000 | Loss: 0.00002196
Iteration 128/1000 | Loss: 0.00002195
Iteration 129/1000 | Loss: 0.00002195
Iteration 130/1000 | Loss: 0.00002195
Iteration 131/1000 | Loss: 0.00002194
Iteration 132/1000 | Loss: 0.00002193
Iteration 133/1000 | Loss: 0.00002192
Iteration 134/1000 | Loss: 0.00002192
Iteration 135/1000 | Loss: 0.00002192
Iteration 136/1000 | Loss: 0.00002192
Iteration 137/1000 | Loss: 0.00002192
Iteration 138/1000 | Loss: 0.00002192
Iteration 139/1000 | Loss: 0.00002192
Iteration 140/1000 | Loss: 0.00002191
Iteration 141/1000 | Loss: 0.00002191
Iteration 142/1000 | Loss: 0.00002191
Iteration 143/1000 | Loss: 0.00002190
Iteration 144/1000 | Loss: 0.00002190
Iteration 145/1000 | Loss: 0.00002189
Iteration 146/1000 | Loss: 0.00002189
Iteration 147/1000 | Loss: 0.00002189
Iteration 148/1000 | Loss: 0.00002188
Iteration 149/1000 | Loss: 0.00002188
Iteration 150/1000 | Loss: 0.00002188
Iteration 151/1000 | Loss: 0.00002187
Iteration 152/1000 | Loss: 0.00002187
Iteration 153/1000 | Loss: 0.00002187
Iteration 154/1000 | Loss: 0.00002187
Iteration 155/1000 | Loss: 0.00002186
Iteration 156/1000 | Loss: 0.00002186
Iteration 157/1000 | Loss: 0.00002185
Iteration 158/1000 | Loss: 0.00002185
Iteration 159/1000 | Loss: 0.00002185
Iteration 160/1000 | Loss: 0.00002185
Iteration 161/1000 | Loss: 0.00002185
Iteration 162/1000 | Loss: 0.00002185
Iteration 163/1000 | Loss: 0.00002185
Iteration 164/1000 | Loss: 0.00002184
Iteration 165/1000 | Loss: 0.00002184
Iteration 166/1000 | Loss: 0.00002184
Iteration 167/1000 | Loss: 0.00002183
Iteration 168/1000 | Loss: 0.00002183
Iteration 169/1000 | Loss: 0.00007329
Iteration 170/1000 | Loss: 0.00002185
Iteration 171/1000 | Loss: 0.00002185
Iteration 172/1000 | Loss: 0.00002184
Iteration 173/1000 | Loss: 0.00002183
Iteration 174/1000 | Loss: 0.00002183
Iteration 175/1000 | Loss: 0.00002182
Iteration 176/1000 | Loss: 0.00002182
Iteration 177/1000 | Loss: 0.00002182
Iteration 178/1000 | Loss: 0.00002181
Iteration 179/1000 | Loss: 0.00002181
Iteration 180/1000 | Loss: 0.00002181
Iteration 181/1000 | Loss: 0.00002180
Iteration 182/1000 | Loss: 0.00002180
Iteration 183/1000 | Loss: 0.00002180
Iteration 184/1000 | Loss: 0.00002179
Iteration 185/1000 | Loss: 0.00002179
Iteration 186/1000 | Loss: 0.00002179
Iteration 187/1000 | Loss: 0.00002179
Iteration 188/1000 | Loss: 0.00002179
Iteration 189/1000 | Loss: 0.00002179
Iteration 190/1000 | Loss: 0.00002178
Iteration 191/1000 | Loss: 0.00002178
Iteration 192/1000 | Loss: 0.00002178
Iteration 193/1000 | Loss: 0.00002178
Iteration 194/1000 | Loss: 0.00002178
Iteration 195/1000 | Loss: 0.00002177
Iteration 196/1000 | Loss: 0.00002177
Iteration 197/1000 | Loss: 0.00002177
Iteration 198/1000 | Loss: 0.00002177
Iteration 199/1000 | Loss: 0.00002177
Iteration 200/1000 | Loss: 0.00002177
Iteration 201/1000 | Loss: 0.00002177
Iteration 202/1000 | Loss: 0.00002177
Iteration 203/1000 | Loss: 0.00002177
Iteration 204/1000 | Loss: 0.00002177
Iteration 205/1000 | Loss: 0.00002176
Iteration 206/1000 | Loss: 0.00002176
Iteration 207/1000 | Loss: 0.00002176
Iteration 208/1000 | Loss: 0.00002176
Iteration 209/1000 | Loss: 0.00002176
Iteration 210/1000 | Loss: 0.00002176
Iteration 211/1000 | Loss: 0.00002175
Iteration 212/1000 | Loss: 0.00002175
Iteration 213/1000 | Loss: 0.00002175
Iteration 214/1000 | Loss: 0.00002175
Iteration 215/1000 | Loss: 0.00002175
Iteration 216/1000 | Loss: 0.00002175
Iteration 217/1000 | Loss: 0.00002175
Iteration 218/1000 | Loss: 0.00002175
Iteration 219/1000 | Loss: 0.00002174
Iteration 220/1000 | Loss: 0.00002174
Iteration 221/1000 | Loss: 0.00002174
Iteration 222/1000 | Loss: 0.00002174
Iteration 223/1000 | Loss: 0.00002174
Iteration 224/1000 | Loss: 0.00002174
Iteration 225/1000 | Loss: 0.00002174
Iteration 226/1000 | Loss: 0.00002174
Iteration 227/1000 | Loss: 0.00002174
Iteration 228/1000 | Loss: 0.00002174
Iteration 229/1000 | Loss: 0.00002174
Iteration 230/1000 | Loss: 0.00002174
Iteration 231/1000 | Loss: 0.00002174
Iteration 232/1000 | Loss: 0.00002174
Iteration 233/1000 | Loss: 0.00002174
Iteration 234/1000 | Loss: 0.00002174
Iteration 235/1000 | Loss: 0.00002174
Iteration 236/1000 | Loss: 0.00002174
Iteration 237/1000 | Loss: 0.00002174
Iteration 238/1000 | Loss: 0.00002174
Iteration 239/1000 | Loss: 0.00002174
Iteration 240/1000 | Loss: 0.00002174
Iteration 241/1000 | Loss: 0.00002174
Iteration 242/1000 | Loss: 0.00002174
Iteration 243/1000 | Loss: 0.00002174
Iteration 244/1000 | Loss: 0.00002174
Iteration 245/1000 | Loss: 0.00002174
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 245. Stopping optimization.
Last 5 losses: [2.1735173504566774e-05, 2.1735173504566774e-05, 2.1735173504566774e-05, 2.1735173504566774e-05, 2.1735173504566774e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1735173504566774e-05

Optimization complete. Final v2v error: 3.9797005653381348 mm

Highest mean error: 4.598316669464111 mm for frame 208

Lowest mean error: 3.620328664779663 mm for frame 16

Saving results

Total time: 245.60706424713135
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00990137
Iteration 2/25 | Loss: 0.00118536
Iteration 3/25 | Loss: 0.00090233
Iteration 4/25 | Loss: 0.00086613
Iteration 5/25 | Loss: 0.00085698
Iteration 6/25 | Loss: 0.00085498
Iteration 7/25 | Loss: 0.00085462
Iteration 8/25 | Loss: 0.00085462
Iteration 9/25 | Loss: 0.00085462
Iteration 10/25 | Loss: 0.00085462
Iteration 11/25 | Loss: 0.00085462
Iteration 12/25 | Loss: 0.00085462
Iteration 13/25 | Loss: 0.00085462
Iteration 14/25 | Loss: 0.00085462
Iteration 15/25 | Loss: 0.00085462
Iteration 16/25 | Loss: 0.00085462
Iteration 17/25 | Loss: 0.00085462
Iteration 18/25 | Loss: 0.00085462
Iteration 19/25 | Loss: 0.00085462
Iteration 20/25 | Loss: 0.00085462
Iteration 21/25 | Loss: 0.00085462
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0008546173921786249, 0.0008546173921786249, 0.0008546173921786249, 0.0008546173921786249, 0.0008546173921786249]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008546173921786249

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49600637
Iteration 2/25 | Loss: 0.00049566
Iteration 3/25 | Loss: 0.00049566
Iteration 4/25 | Loss: 0.00049566
Iteration 5/25 | Loss: 0.00049566
Iteration 6/25 | Loss: 0.00049565
Iteration 7/25 | Loss: 0.00049565
Iteration 8/25 | Loss: 0.00049565
Iteration 9/25 | Loss: 0.00049565
Iteration 10/25 | Loss: 0.00049565
Iteration 11/25 | Loss: 0.00049565
Iteration 12/25 | Loss: 0.00049565
Iteration 13/25 | Loss: 0.00049565
Iteration 14/25 | Loss: 0.00049565
Iteration 15/25 | Loss: 0.00049565
Iteration 16/25 | Loss: 0.00049565
Iteration 17/25 | Loss: 0.00049565
Iteration 18/25 | Loss: 0.00049565
Iteration 19/25 | Loss: 0.00049565
Iteration 20/25 | Loss: 0.00049565
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0004956541233696043, 0.0004956541233696043, 0.0004956541233696043, 0.0004956541233696043, 0.0004956541233696043]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004956541233696043

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049565
Iteration 2/1000 | Loss: 0.00003519
Iteration 3/1000 | Loss: 0.00002927
Iteration 4/1000 | Loss: 0.00002714
Iteration 5/1000 | Loss: 0.00002577
Iteration 6/1000 | Loss: 0.00002501
Iteration 7/1000 | Loss: 0.00002429
Iteration 8/1000 | Loss: 0.00002391
Iteration 9/1000 | Loss: 0.00002362
Iteration 10/1000 | Loss: 0.00002339
Iteration 11/1000 | Loss: 0.00002321
Iteration 12/1000 | Loss: 0.00002318
Iteration 13/1000 | Loss: 0.00002307
Iteration 14/1000 | Loss: 0.00002304
Iteration 15/1000 | Loss: 0.00002303
Iteration 16/1000 | Loss: 0.00002302
Iteration 17/1000 | Loss: 0.00002302
Iteration 18/1000 | Loss: 0.00002302
Iteration 19/1000 | Loss: 0.00002301
Iteration 20/1000 | Loss: 0.00002301
Iteration 21/1000 | Loss: 0.00002300
Iteration 22/1000 | Loss: 0.00002300
Iteration 23/1000 | Loss: 0.00002299
Iteration 24/1000 | Loss: 0.00002298
Iteration 25/1000 | Loss: 0.00002298
Iteration 26/1000 | Loss: 0.00002298
Iteration 27/1000 | Loss: 0.00002297
Iteration 28/1000 | Loss: 0.00002297
Iteration 29/1000 | Loss: 0.00002296
Iteration 30/1000 | Loss: 0.00002296
Iteration 31/1000 | Loss: 0.00002295
Iteration 32/1000 | Loss: 0.00002295
Iteration 33/1000 | Loss: 0.00002295
Iteration 34/1000 | Loss: 0.00002295
Iteration 35/1000 | Loss: 0.00002295
Iteration 36/1000 | Loss: 0.00002294
Iteration 37/1000 | Loss: 0.00002294
Iteration 38/1000 | Loss: 0.00002294
Iteration 39/1000 | Loss: 0.00002293
Iteration 40/1000 | Loss: 0.00002293
Iteration 41/1000 | Loss: 0.00002292
Iteration 42/1000 | Loss: 0.00002292
Iteration 43/1000 | Loss: 0.00002292
Iteration 44/1000 | Loss: 0.00002291
Iteration 45/1000 | Loss: 0.00002291
Iteration 46/1000 | Loss: 0.00002291
Iteration 47/1000 | Loss: 0.00002290
Iteration 48/1000 | Loss: 0.00002290
Iteration 49/1000 | Loss: 0.00002290
Iteration 50/1000 | Loss: 0.00002289
Iteration 51/1000 | Loss: 0.00002289
Iteration 52/1000 | Loss: 0.00002288
Iteration 53/1000 | Loss: 0.00002288
Iteration 54/1000 | Loss: 0.00002288
Iteration 55/1000 | Loss: 0.00002288
Iteration 56/1000 | Loss: 0.00002287
Iteration 57/1000 | Loss: 0.00002287
Iteration 58/1000 | Loss: 0.00002287
Iteration 59/1000 | Loss: 0.00002287
Iteration 60/1000 | Loss: 0.00002287
Iteration 61/1000 | Loss: 0.00002287
Iteration 62/1000 | Loss: 0.00002287
Iteration 63/1000 | Loss: 0.00002287
Iteration 64/1000 | Loss: 0.00002286
Iteration 65/1000 | Loss: 0.00002286
Iteration 66/1000 | Loss: 0.00002286
Iteration 67/1000 | Loss: 0.00002285
Iteration 68/1000 | Loss: 0.00002285
Iteration 69/1000 | Loss: 0.00002285
Iteration 70/1000 | Loss: 0.00002285
Iteration 71/1000 | Loss: 0.00002285
Iteration 72/1000 | Loss: 0.00002285
Iteration 73/1000 | Loss: 0.00002284
Iteration 74/1000 | Loss: 0.00002284
Iteration 75/1000 | Loss: 0.00002284
Iteration 76/1000 | Loss: 0.00002284
Iteration 77/1000 | Loss: 0.00002284
Iteration 78/1000 | Loss: 0.00002284
Iteration 79/1000 | Loss: 0.00002284
Iteration 80/1000 | Loss: 0.00002284
Iteration 81/1000 | Loss: 0.00002284
Iteration 82/1000 | Loss: 0.00002283
Iteration 83/1000 | Loss: 0.00002283
Iteration 84/1000 | Loss: 0.00002283
Iteration 85/1000 | Loss: 0.00002283
Iteration 86/1000 | Loss: 0.00002283
Iteration 87/1000 | Loss: 0.00002283
Iteration 88/1000 | Loss: 0.00002283
Iteration 89/1000 | Loss: 0.00002282
Iteration 90/1000 | Loss: 0.00002282
Iteration 91/1000 | Loss: 0.00002282
Iteration 92/1000 | Loss: 0.00002282
Iteration 93/1000 | Loss: 0.00002282
Iteration 94/1000 | Loss: 0.00002282
Iteration 95/1000 | Loss: 0.00002282
Iteration 96/1000 | Loss: 0.00002282
Iteration 97/1000 | Loss: 0.00002282
Iteration 98/1000 | Loss: 0.00002282
Iteration 99/1000 | Loss: 0.00002282
Iteration 100/1000 | Loss: 0.00002282
Iteration 101/1000 | Loss: 0.00002281
Iteration 102/1000 | Loss: 0.00002281
Iteration 103/1000 | Loss: 0.00002281
Iteration 104/1000 | Loss: 0.00002281
Iteration 105/1000 | Loss: 0.00002281
Iteration 106/1000 | Loss: 0.00002281
Iteration 107/1000 | Loss: 0.00002280
Iteration 108/1000 | Loss: 0.00002280
Iteration 109/1000 | Loss: 0.00002280
Iteration 110/1000 | Loss: 0.00002280
Iteration 111/1000 | Loss: 0.00002280
Iteration 112/1000 | Loss: 0.00002280
Iteration 113/1000 | Loss: 0.00002280
Iteration 114/1000 | Loss: 0.00002280
Iteration 115/1000 | Loss: 0.00002280
Iteration 116/1000 | Loss: 0.00002280
Iteration 117/1000 | Loss: 0.00002280
Iteration 118/1000 | Loss: 0.00002280
Iteration 119/1000 | Loss: 0.00002280
Iteration 120/1000 | Loss: 0.00002280
Iteration 121/1000 | Loss: 0.00002280
Iteration 122/1000 | Loss: 0.00002280
Iteration 123/1000 | Loss: 0.00002280
Iteration 124/1000 | Loss: 0.00002280
Iteration 125/1000 | Loss: 0.00002280
Iteration 126/1000 | Loss: 0.00002280
Iteration 127/1000 | Loss: 0.00002280
Iteration 128/1000 | Loss: 0.00002280
Iteration 129/1000 | Loss: 0.00002280
Iteration 130/1000 | Loss: 0.00002280
Iteration 131/1000 | Loss: 0.00002280
Iteration 132/1000 | Loss: 0.00002280
Iteration 133/1000 | Loss: 0.00002280
Iteration 134/1000 | Loss: 0.00002280
Iteration 135/1000 | Loss: 0.00002280
Iteration 136/1000 | Loss: 0.00002280
Iteration 137/1000 | Loss: 0.00002280
Iteration 138/1000 | Loss: 0.00002280
Iteration 139/1000 | Loss: 0.00002280
Iteration 140/1000 | Loss: 0.00002280
Iteration 141/1000 | Loss: 0.00002280
Iteration 142/1000 | Loss: 0.00002280
Iteration 143/1000 | Loss: 0.00002280
Iteration 144/1000 | Loss: 0.00002280
Iteration 145/1000 | Loss: 0.00002280
Iteration 146/1000 | Loss: 0.00002280
Iteration 147/1000 | Loss: 0.00002280
Iteration 148/1000 | Loss: 0.00002280
Iteration 149/1000 | Loss: 0.00002280
Iteration 150/1000 | Loss: 0.00002280
Iteration 151/1000 | Loss: 0.00002280
Iteration 152/1000 | Loss: 0.00002280
Iteration 153/1000 | Loss: 0.00002280
Iteration 154/1000 | Loss: 0.00002280
Iteration 155/1000 | Loss: 0.00002280
Iteration 156/1000 | Loss: 0.00002280
Iteration 157/1000 | Loss: 0.00002280
Iteration 158/1000 | Loss: 0.00002280
Iteration 159/1000 | Loss: 0.00002280
Iteration 160/1000 | Loss: 0.00002280
Iteration 161/1000 | Loss: 0.00002280
Iteration 162/1000 | Loss: 0.00002280
Iteration 163/1000 | Loss: 0.00002280
Iteration 164/1000 | Loss: 0.00002280
Iteration 165/1000 | Loss: 0.00002280
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [2.279811815242283e-05, 2.279811815242283e-05, 2.279811815242283e-05, 2.279811815242283e-05, 2.279811815242283e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.279811815242283e-05

Optimization complete. Final v2v error: 3.9737722873687744 mm

Highest mean error: 4.08391809463501 mm for frame 93

Lowest mean error: 3.7150495052337646 mm for frame 151

Saving results

Total time: 36.494797468185425
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1028/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1028.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1028
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00779703
Iteration 2/25 | Loss: 0.00106979
Iteration 3/25 | Loss: 0.00086278
Iteration 4/25 | Loss: 0.00082677
Iteration 5/25 | Loss: 0.00081531
Iteration 6/25 | Loss: 0.00081240
Iteration 7/25 | Loss: 0.00081162
Iteration 8/25 | Loss: 0.00081162
Iteration 9/25 | Loss: 0.00081162
Iteration 10/25 | Loss: 0.00081162
Iteration 11/25 | Loss: 0.00081162
Iteration 12/25 | Loss: 0.00081162
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008116182289086282, 0.0008116182289086282, 0.0008116182289086282, 0.0008116182289086282, 0.0008116182289086282]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008116182289086282

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.75715923
Iteration 2/25 | Loss: 0.00061166
Iteration 3/25 | Loss: 0.00061163
Iteration 4/25 | Loss: 0.00061163
Iteration 5/25 | Loss: 0.00061163
Iteration 6/25 | Loss: 0.00061163
Iteration 7/25 | Loss: 0.00061163
Iteration 8/25 | Loss: 0.00061163
Iteration 9/25 | Loss: 0.00061163
Iteration 10/25 | Loss: 0.00061163
Iteration 11/25 | Loss: 0.00061163
Iteration 12/25 | Loss: 0.00061163
Iteration 13/25 | Loss: 0.00061163
Iteration 14/25 | Loss: 0.00061163
Iteration 15/25 | Loss: 0.00061163
Iteration 16/25 | Loss: 0.00061163
Iteration 17/25 | Loss: 0.00061163
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006116284639574587, 0.0006116284639574587, 0.0006116284639574587, 0.0006116284639574587, 0.0006116284639574587]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006116284639574587

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00061163
Iteration 2/1000 | Loss: 0.00004776
Iteration 3/1000 | Loss: 0.00002630
Iteration 4/1000 | Loss: 0.00001997
Iteration 5/1000 | Loss: 0.00001878
Iteration 6/1000 | Loss: 0.00001794
Iteration 7/1000 | Loss: 0.00001753
Iteration 8/1000 | Loss: 0.00001732
Iteration 9/1000 | Loss: 0.00001709
Iteration 10/1000 | Loss: 0.00001701
Iteration 11/1000 | Loss: 0.00001700
Iteration 12/1000 | Loss: 0.00001699
Iteration 13/1000 | Loss: 0.00001699
Iteration 14/1000 | Loss: 0.00001698
Iteration 15/1000 | Loss: 0.00001698
Iteration 16/1000 | Loss: 0.00001697
Iteration 17/1000 | Loss: 0.00001690
Iteration 18/1000 | Loss: 0.00001685
Iteration 19/1000 | Loss: 0.00001684
Iteration 20/1000 | Loss: 0.00001683
Iteration 21/1000 | Loss: 0.00001683
Iteration 22/1000 | Loss: 0.00001683
Iteration 23/1000 | Loss: 0.00001683
Iteration 24/1000 | Loss: 0.00001682
Iteration 25/1000 | Loss: 0.00001682
Iteration 26/1000 | Loss: 0.00001680
Iteration 27/1000 | Loss: 0.00001680
Iteration 28/1000 | Loss: 0.00001680
Iteration 29/1000 | Loss: 0.00001679
Iteration 30/1000 | Loss: 0.00001679
Iteration 31/1000 | Loss: 0.00001679
Iteration 32/1000 | Loss: 0.00001678
Iteration 33/1000 | Loss: 0.00001678
Iteration 34/1000 | Loss: 0.00001678
Iteration 35/1000 | Loss: 0.00001677
Iteration 36/1000 | Loss: 0.00001676
Iteration 37/1000 | Loss: 0.00001676
Iteration 38/1000 | Loss: 0.00001675
Iteration 39/1000 | Loss: 0.00001675
Iteration 40/1000 | Loss: 0.00001674
Iteration 41/1000 | Loss: 0.00001674
Iteration 42/1000 | Loss: 0.00001673
Iteration 43/1000 | Loss: 0.00001673
Iteration 44/1000 | Loss: 0.00001672
Iteration 45/1000 | Loss: 0.00001672
Iteration 46/1000 | Loss: 0.00001672
Iteration 47/1000 | Loss: 0.00001671
Iteration 48/1000 | Loss: 0.00001670
Iteration 49/1000 | Loss: 0.00001670
Iteration 50/1000 | Loss: 0.00001670
Iteration 51/1000 | Loss: 0.00001669
Iteration 52/1000 | Loss: 0.00001669
Iteration 53/1000 | Loss: 0.00001668
Iteration 54/1000 | Loss: 0.00001668
Iteration 55/1000 | Loss: 0.00001668
Iteration 56/1000 | Loss: 0.00001668
Iteration 57/1000 | Loss: 0.00001668
Iteration 58/1000 | Loss: 0.00001667
Iteration 59/1000 | Loss: 0.00001667
Iteration 60/1000 | Loss: 0.00001667
Iteration 61/1000 | Loss: 0.00001667
Iteration 62/1000 | Loss: 0.00001667
Iteration 63/1000 | Loss: 0.00001666
Iteration 64/1000 | Loss: 0.00001666
Iteration 65/1000 | Loss: 0.00001666
Iteration 66/1000 | Loss: 0.00001666
Iteration 67/1000 | Loss: 0.00001666
Iteration 68/1000 | Loss: 0.00001666
Iteration 69/1000 | Loss: 0.00001666
Iteration 70/1000 | Loss: 0.00001666
Iteration 71/1000 | Loss: 0.00001666
Iteration 72/1000 | Loss: 0.00001666
Iteration 73/1000 | Loss: 0.00001665
Iteration 74/1000 | Loss: 0.00001665
Iteration 75/1000 | Loss: 0.00001665
Iteration 76/1000 | Loss: 0.00001665
Iteration 77/1000 | Loss: 0.00001664
Iteration 78/1000 | Loss: 0.00001664
Iteration 79/1000 | Loss: 0.00001664
Iteration 80/1000 | Loss: 0.00001664
Iteration 81/1000 | Loss: 0.00001664
Iteration 82/1000 | Loss: 0.00001664
Iteration 83/1000 | Loss: 0.00001664
Iteration 84/1000 | Loss: 0.00001664
Iteration 85/1000 | Loss: 0.00001664
Iteration 86/1000 | Loss: 0.00001664
Iteration 87/1000 | Loss: 0.00001663
Iteration 88/1000 | Loss: 0.00001663
Iteration 89/1000 | Loss: 0.00001663
Iteration 90/1000 | Loss: 0.00001663
Iteration 91/1000 | Loss: 0.00001663
Iteration 92/1000 | Loss: 0.00001663
Iteration 93/1000 | Loss: 0.00001663
Iteration 94/1000 | Loss: 0.00001663
Iteration 95/1000 | Loss: 0.00001662
Iteration 96/1000 | Loss: 0.00001662
Iteration 97/1000 | Loss: 0.00001662
Iteration 98/1000 | Loss: 0.00001662
Iteration 99/1000 | Loss: 0.00001662
Iteration 100/1000 | Loss: 0.00001662
Iteration 101/1000 | Loss: 0.00001662
Iteration 102/1000 | Loss: 0.00001662
Iteration 103/1000 | Loss: 0.00001662
Iteration 104/1000 | Loss: 0.00001662
Iteration 105/1000 | Loss: 0.00001662
Iteration 106/1000 | Loss: 0.00001662
Iteration 107/1000 | Loss: 0.00001662
Iteration 108/1000 | Loss: 0.00001662
Iteration 109/1000 | Loss: 0.00001662
Iteration 110/1000 | Loss: 0.00001661
Iteration 111/1000 | Loss: 0.00001661
Iteration 112/1000 | Loss: 0.00001661
Iteration 113/1000 | Loss: 0.00001661
Iteration 114/1000 | Loss: 0.00001661
Iteration 115/1000 | Loss: 0.00001661
Iteration 116/1000 | Loss: 0.00001661
Iteration 117/1000 | Loss: 0.00001661
Iteration 118/1000 | Loss: 0.00001661
Iteration 119/1000 | Loss: 0.00001661
Iteration 120/1000 | Loss: 0.00001661
Iteration 121/1000 | Loss: 0.00001661
Iteration 122/1000 | Loss: 0.00001661
Iteration 123/1000 | Loss: 0.00001661
Iteration 124/1000 | Loss: 0.00001660
Iteration 125/1000 | Loss: 0.00001660
Iteration 126/1000 | Loss: 0.00001660
Iteration 127/1000 | Loss: 0.00001660
Iteration 128/1000 | Loss: 0.00001660
Iteration 129/1000 | Loss: 0.00001660
Iteration 130/1000 | Loss: 0.00001660
Iteration 131/1000 | Loss: 0.00001660
Iteration 132/1000 | Loss: 0.00001660
Iteration 133/1000 | Loss: 0.00001659
Iteration 134/1000 | Loss: 0.00001659
Iteration 135/1000 | Loss: 0.00001659
Iteration 136/1000 | Loss: 0.00001659
Iteration 137/1000 | Loss: 0.00001659
Iteration 138/1000 | Loss: 0.00001659
Iteration 139/1000 | Loss: 0.00001659
Iteration 140/1000 | Loss: 0.00001659
Iteration 141/1000 | Loss: 0.00001659
Iteration 142/1000 | Loss: 0.00001659
Iteration 143/1000 | Loss: 0.00001659
Iteration 144/1000 | Loss: 0.00001659
Iteration 145/1000 | Loss: 0.00001659
Iteration 146/1000 | Loss: 0.00001659
Iteration 147/1000 | Loss: 0.00001659
Iteration 148/1000 | Loss: 0.00001659
Iteration 149/1000 | Loss: 0.00001659
Iteration 150/1000 | Loss: 0.00001659
Iteration 151/1000 | Loss: 0.00001659
Iteration 152/1000 | Loss: 0.00001659
Iteration 153/1000 | Loss: 0.00001659
Iteration 154/1000 | Loss: 0.00001659
Iteration 155/1000 | Loss: 0.00001659
Iteration 156/1000 | Loss: 0.00001659
Iteration 157/1000 | Loss: 0.00001659
Iteration 158/1000 | Loss: 0.00001659
Iteration 159/1000 | Loss: 0.00001659
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 159. Stopping optimization.
Last 5 losses: [1.65892797667766e-05, 1.65892797667766e-05, 1.65892797667766e-05, 1.65892797667766e-05, 1.65892797667766e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.65892797667766e-05

Optimization complete. Final v2v error: 3.4558939933776855 mm

Highest mean error: 3.934532403945923 mm for frame 48

Lowest mean error: 2.934041976928711 mm for frame 5

Saving results

Total time: 34.84809923171997
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1071/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1071.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1071
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00471451
Iteration 2/25 | Loss: 0.00097858
Iteration 3/25 | Loss: 0.00083875
Iteration 4/25 | Loss: 0.00081172
Iteration 5/25 | Loss: 0.00080577
Iteration 6/25 | Loss: 0.00080369
Iteration 7/25 | Loss: 0.00080311
Iteration 8/25 | Loss: 0.00080311
Iteration 9/25 | Loss: 0.00080311
Iteration 10/25 | Loss: 0.00080311
Iteration 11/25 | Loss: 0.00080311
Iteration 12/25 | Loss: 0.00080311
Iteration 13/25 | Loss: 0.00080311
Iteration 14/25 | Loss: 0.00080311
Iteration 15/25 | Loss: 0.00080311
Iteration 16/25 | Loss: 0.00080311
Iteration 17/25 | Loss: 0.00080311
Iteration 18/25 | Loss: 0.00080311
Iteration 19/25 | Loss: 0.00080311
Iteration 20/25 | Loss: 0.00080311
Iteration 21/25 | Loss: 0.00080311
Iteration 22/25 | Loss: 0.00080311
Iteration 23/25 | Loss: 0.00080311
Iteration 24/25 | Loss: 0.00080311
Iteration 25/25 | Loss: 0.00080311

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.22249722
Iteration 2/25 | Loss: 0.00048928
Iteration 3/25 | Loss: 0.00048927
Iteration 4/25 | Loss: 0.00048927
Iteration 5/25 | Loss: 0.00048926
Iteration 6/25 | Loss: 0.00048926
Iteration 7/25 | Loss: 0.00048926
Iteration 8/25 | Loss: 0.00048926
Iteration 9/25 | Loss: 0.00048926
Iteration 10/25 | Loss: 0.00048926
Iteration 11/25 | Loss: 0.00048926
Iteration 12/25 | Loss: 0.00048926
Iteration 13/25 | Loss: 0.00048926
Iteration 14/25 | Loss: 0.00048926
Iteration 15/25 | Loss: 0.00048926
Iteration 16/25 | Loss: 0.00048926
Iteration 17/25 | Loss: 0.00048926
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.000489262689370662, 0.000489262689370662, 0.000489262689370662, 0.000489262689370662, 0.000489262689370662]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000489262689370662

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048926
Iteration 2/1000 | Loss: 0.00003347
Iteration 3/1000 | Loss: 0.00002345
Iteration 4/1000 | Loss: 0.00002230
Iteration 5/1000 | Loss: 0.00002136
Iteration 6/1000 | Loss: 0.00002093
Iteration 7/1000 | Loss: 0.00002055
Iteration 8/1000 | Loss: 0.00002029
Iteration 9/1000 | Loss: 0.00002016
Iteration 10/1000 | Loss: 0.00002005
Iteration 11/1000 | Loss: 0.00002004
Iteration 12/1000 | Loss: 0.00001993
Iteration 13/1000 | Loss: 0.00001991
Iteration 14/1000 | Loss: 0.00001990
Iteration 15/1000 | Loss: 0.00001990
Iteration 16/1000 | Loss: 0.00001989
Iteration 17/1000 | Loss: 0.00001988
Iteration 18/1000 | Loss: 0.00001984
Iteration 19/1000 | Loss: 0.00001978
Iteration 20/1000 | Loss: 0.00001978
Iteration 21/1000 | Loss: 0.00001977
Iteration 22/1000 | Loss: 0.00001977
Iteration 23/1000 | Loss: 0.00001975
Iteration 24/1000 | Loss: 0.00001974
Iteration 25/1000 | Loss: 0.00001974
Iteration 26/1000 | Loss: 0.00001974
Iteration 27/1000 | Loss: 0.00001974
Iteration 28/1000 | Loss: 0.00001974
Iteration 29/1000 | Loss: 0.00001974
Iteration 30/1000 | Loss: 0.00001974
Iteration 31/1000 | Loss: 0.00001974
Iteration 32/1000 | Loss: 0.00001974
Iteration 33/1000 | Loss: 0.00001974
Iteration 34/1000 | Loss: 0.00001974
Iteration 35/1000 | Loss: 0.00001974
Iteration 36/1000 | Loss: 0.00001974
Iteration 37/1000 | Loss: 0.00001973
Iteration 38/1000 | Loss: 0.00001973
Iteration 39/1000 | Loss: 0.00001972
Iteration 40/1000 | Loss: 0.00001972
Iteration 41/1000 | Loss: 0.00001972
Iteration 42/1000 | Loss: 0.00001972
Iteration 43/1000 | Loss: 0.00001972
Iteration 44/1000 | Loss: 0.00001972
Iteration 45/1000 | Loss: 0.00001971
Iteration 46/1000 | Loss: 0.00001971
Iteration 47/1000 | Loss: 0.00001971
Iteration 48/1000 | Loss: 0.00001971
Iteration 49/1000 | Loss: 0.00001971
Iteration 50/1000 | Loss: 0.00001971
Iteration 51/1000 | Loss: 0.00001971
Iteration 52/1000 | Loss: 0.00001971
Iteration 53/1000 | Loss: 0.00001971
Iteration 54/1000 | Loss: 0.00001970
Iteration 55/1000 | Loss: 0.00001970
Iteration 56/1000 | Loss: 0.00001970
Iteration 57/1000 | Loss: 0.00001970
Iteration 58/1000 | Loss: 0.00001970
Iteration 59/1000 | Loss: 0.00001969
Iteration 60/1000 | Loss: 0.00001969
Iteration 61/1000 | Loss: 0.00001969
Iteration 62/1000 | Loss: 0.00001968
Iteration 63/1000 | Loss: 0.00001968
Iteration 64/1000 | Loss: 0.00001968
Iteration 65/1000 | Loss: 0.00001968
Iteration 66/1000 | Loss: 0.00001967
Iteration 67/1000 | Loss: 0.00001967
Iteration 68/1000 | Loss: 0.00001966
Iteration 69/1000 | Loss: 0.00001966
Iteration 70/1000 | Loss: 0.00001965
Iteration 71/1000 | Loss: 0.00001965
Iteration 72/1000 | Loss: 0.00001965
Iteration 73/1000 | Loss: 0.00001965
Iteration 74/1000 | Loss: 0.00001965
Iteration 75/1000 | Loss: 0.00001965
Iteration 76/1000 | Loss: 0.00001965
Iteration 77/1000 | Loss: 0.00001965
Iteration 78/1000 | Loss: 0.00001965
Iteration 79/1000 | Loss: 0.00001965
Iteration 80/1000 | Loss: 0.00001965
Iteration 81/1000 | Loss: 0.00001964
Iteration 82/1000 | Loss: 0.00001964
Iteration 83/1000 | Loss: 0.00001964
Iteration 84/1000 | Loss: 0.00001964
Iteration 85/1000 | Loss: 0.00001964
Iteration 86/1000 | Loss: 0.00001964
Iteration 87/1000 | Loss: 0.00001963
Iteration 88/1000 | Loss: 0.00001963
Iteration 89/1000 | Loss: 0.00001962
Iteration 90/1000 | Loss: 0.00001962
Iteration 91/1000 | Loss: 0.00001961
Iteration 92/1000 | Loss: 0.00001961
Iteration 93/1000 | Loss: 0.00001961
Iteration 94/1000 | Loss: 0.00001960
Iteration 95/1000 | Loss: 0.00001960
Iteration 96/1000 | Loss: 0.00001960
Iteration 97/1000 | Loss: 0.00001960
Iteration 98/1000 | Loss: 0.00001959
Iteration 99/1000 | Loss: 0.00001959
Iteration 100/1000 | Loss: 0.00001959
Iteration 101/1000 | Loss: 0.00001958
Iteration 102/1000 | Loss: 0.00001957
Iteration 103/1000 | Loss: 0.00001957
Iteration 104/1000 | Loss: 0.00001956
Iteration 105/1000 | Loss: 0.00001956
Iteration 106/1000 | Loss: 0.00001956
Iteration 107/1000 | Loss: 0.00001955
Iteration 108/1000 | Loss: 0.00001955
Iteration 109/1000 | Loss: 0.00001955
Iteration 110/1000 | Loss: 0.00001955
Iteration 111/1000 | Loss: 0.00001955
Iteration 112/1000 | Loss: 0.00001954
Iteration 113/1000 | Loss: 0.00001954
Iteration 114/1000 | Loss: 0.00001954
Iteration 115/1000 | Loss: 0.00001954
Iteration 116/1000 | Loss: 0.00001953
Iteration 117/1000 | Loss: 0.00001953
Iteration 118/1000 | Loss: 0.00001953
Iteration 119/1000 | Loss: 0.00001953
Iteration 120/1000 | Loss: 0.00001953
Iteration 121/1000 | Loss: 0.00001952
Iteration 122/1000 | Loss: 0.00001952
Iteration 123/1000 | Loss: 0.00001952
Iteration 124/1000 | Loss: 0.00001951
Iteration 125/1000 | Loss: 0.00001951
Iteration 126/1000 | Loss: 0.00001951
Iteration 127/1000 | Loss: 0.00001951
Iteration 128/1000 | Loss: 0.00001951
Iteration 129/1000 | Loss: 0.00001951
Iteration 130/1000 | Loss: 0.00001951
Iteration 131/1000 | Loss: 0.00001951
Iteration 132/1000 | Loss: 0.00001950
Iteration 133/1000 | Loss: 0.00001950
Iteration 134/1000 | Loss: 0.00001950
Iteration 135/1000 | Loss: 0.00001950
Iteration 136/1000 | Loss: 0.00001950
Iteration 137/1000 | Loss: 0.00001950
Iteration 138/1000 | Loss: 0.00001950
Iteration 139/1000 | Loss: 0.00001950
Iteration 140/1000 | Loss: 0.00001950
Iteration 141/1000 | Loss: 0.00001950
Iteration 142/1000 | Loss: 0.00001950
Iteration 143/1000 | Loss: 0.00001950
Iteration 144/1000 | Loss: 0.00001949
Iteration 145/1000 | Loss: 0.00001949
Iteration 146/1000 | Loss: 0.00001949
Iteration 147/1000 | Loss: 0.00001949
Iteration 148/1000 | Loss: 0.00001949
Iteration 149/1000 | Loss: 0.00001949
Iteration 150/1000 | Loss: 0.00001949
Iteration 151/1000 | Loss: 0.00001949
Iteration 152/1000 | Loss: 0.00001948
Iteration 153/1000 | Loss: 0.00001948
Iteration 154/1000 | Loss: 0.00001948
Iteration 155/1000 | Loss: 0.00001948
Iteration 156/1000 | Loss: 0.00001948
Iteration 157/1000 | Loss: 0.00001948
Iteration 158/1000 | Loss: 0.00001948
Iteration 159/1000 | Loss: 0.00001948
Iteration 160/1000 | Loss: 0.00001948
Iteration 161/1000 | Loss: 0.00001948
Iteration 162/1000 | Loss: 0.00001948
Iteration 163/1000 | Loss: 0.00001948
Iteration 164/1000 | Loss: 0.00001948
Iteration 165/1000 | Loss: 0.00001947
Iteration 166/1000 | Loss: 0.00001947
Iteration 167/1000 | Loss: 0.00001947
Iteration 168/1000 | Loss: 0.00001947
Iteration 169/1000 | Loss: 0.00001947
Iteration 170/1000 | Loss: 0.00001947
Iteration 171/1000 | Loss: 0.00001947
Iteration 172/1000 | Loss: 0.00001947
Iteration 173/1000 | Loss: 0.00001947
Iteration 174/1000 | Loss: 0.00001947
Iteration 175/1000 | Loss: 0.00001947
Iteration 176/1000 | Loss: 0.00001947
Iteration 177/1000 | Loss: 0.00001947
Iteration 178/1000 | Loss: 0.00001947
Iteration 179/1000 | Loss: 0.00001947
Iteration 180/1000 | Loss: 0.00001946
Iteration 181/1000 | Loss: 0.00001946
Iteration 182/1000 | Loss: 0.00001946
Iteration 183/1000 | Loss: 0.00001946
Iteration 184/1000 | Loss: 0.00001946
Iteration 185/1000 | Loss: 0.00001946
Iteration 186/1000 | Loss: 0.00001946
Iteration 187/1000 | Loss: 0.00001946
Iteration 188/1000 | Loss: 0.00001946
Iteration 189/1000 | Loss: 0.00001946
Iteration 190/1000 | Loss: 0.00001946
Iteration 191/1000 | Loss: 0.00001946
Iteration 192/1000 | Loss: 0.00001946
Iteration 193/1000 | Loss: 0.00001946
Iteration 194/1000 | Loss: 0.00001946
Iteration 195/1000 | Loss: 0.00001946
Iteration 196/1000 | Loss: 0.00001946
Iteration 197/1000 | Loss: 0.00001946
Iteration 198/1000 | Loss: 0.00001946
Iteration 199/1000 | Loss: 0.00001945
Iteration 200/1000 | Loss: 0.00001945
Iteration 201/1000 | Loss: 0.00001945
Iteration 202/1000 | Loss: 0.00001945
Iteration 203/1000 | Loss: 0.00001945
Iteration 204/1000 | Loss: 0.00001945
Iteration 205/1000 | Loss: 0.00001945
Iteration 206/1000 | Loss: 0.00001945
Iteration 207/1000 | Loss: 0.00001945
Iteration 208/1000 | Loss: 0.00001945
Iteration 209/1000 | Loss: 0.00001945
Iteration 210/1000 | Loss: 0.00001945
Iteration 211/1000 | Loss: 0.00001945
Iteration 212/1000 | Loss: 0.00001945
Iteration 213/1000 | Loss: 0.00001945
Iteration 214/1000 | Loss: 0.00001945
Iteration 215/1000 | Loss: 0.00001945
Iteration 216/1000 | Loss: 0.00001945
Iteration 217/1000 | Loss: 0.00001945
Iteration 218/1000 | Loss: 0.00001945
Iteration 219/1000 | Loss: 0.00001945
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 219. Stopping optimization.
Last 5 losses: [1.9450295440037735e-05, 1.9450295440037735e-05, 1.9450295440037735e-05, 1.9450295440037735e-05, 1.9450295440037735e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9450295440037735e-05

Optimization complete. Final v2v error: 3.7040677070617676 mm

Highest mean error: 4.328385829925537 mm for frame 183

Lowest mean error: 3.4705631732940674 mm for frame 147

Saving results

Total time: 42.7398202419281
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1085/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1085.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1085
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00787718
Iteration 2/25 | Loss: 0.00122645
Iteration 3/25 | Loss: 0.00098938
Iteration 4/25 | Loss: 0.00091933
Iteration 5/25 | Loss: 0.00089256
Iteration 6/25 | Loss: 0.00088851
Iteration 7/25 | Loss: 0.00088242
Iteration 8/25 | Loss: 0.00088093
Iteration 9/25 | Loss: 0.00088062
Iteration 10/25 | Loss: 0.00088054
Iteration 11/25 | Loss: 0.00088047
Iteration 12/25 | Loss: 0.00088041
Iteration 13/25 | Loss: 0.00088040
Iteration 14/25 | Loss: 0.00088040
Iteration 15/25 | Loss: 0.00088040
Iteration 16/25 | Loss: 0.00088039
Iteration 17/25 | Loss: 0.00088031
Iteration 18/25 | Loss: 0.00088017
Iteration 19/25 | Loss: 0.00087997
Iteration 20/25 | Loss: 0.00087974
Iteration 21/25 | Loss: 0.00087937
Iteration 22/25 | Loss: 0.00088208
Iteration 23/25 | Loss: 0.00088174
Iteration 24/25 | Loss: 0.00088048
Iteration 25/25 | Loss: 0.00088106

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.99075794
Iteration 2/25 | Loss: 0.00059140
Iteration 3/25 | Loss: 0.00059122
Iteration 4/25 | Loss: 0.00059122
Iteration 5/25 | Loss: 0.00059121
Iteration 6/25 | Loss: 0.00059121
Iteration 7/25 | Loss: 0.00059121
Iteration 8/25 | Loss: 0.00059121
Iteration 9/25 | Loss: 0.00059121
Iteration 10/25 | Loss: 0.00059121
Iteration 11/25 | Loss: 0.00059121
Iteration 12/25 | Loss: 0.00059121
Iteration 13/25 | Loss: 0.00059121
Iteration 14/25 | Loss: 0.00059121
Iteration 15/25 | Loss: 0.00059121
Iteration 16/25 | Loss: 0.00059121
Iteration 17/25 | Loss: 0.00059121
Iteration 18/25 | Loss: 0.00059121
Iteration 19/25 | Loss: 0.00059121
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000591213523875922, 0.000591213523875922, 0.000591213523875922, 0.000591213523875922, 0.000591213523875922]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000591213523875922

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00059121
Iteration 2/1000 | Loss: 0.00016566
Iteration 3/1000 | Loss: 0.00012266
Iteration 4/1000 | Loss: 0.00010883
Iteration 5/1000 | Loss: 0.00017063
Iteration 6/1000 | Loss: 0.00016403
Iteration 7/1000 | Loss: 0.00015988
Iteration 8/1000 | Loss: 0.00016063
Iteration 9/1000 | Loss: 0.00015711
Iteration 10/1000 | Loss: 0.00015947
Iteration 11/1000 | Loss: 0.00011523
Iteration 12/1000 | Loss: 0.00016365
Iteration 13/1000 | Loss: 0.00011929
Iteration 14/1000 | Loss: 0.00016954
Iteration 15/1000 | Loss: 0.00015779
Iteration 16/1000 | Loss: 0.00015867
Iteration 17/1000 | Loss: 0.00015518
Iteration 18/1000 | Loss: 0.00015786
Iteration 19/1000 | Loss: 0.00018982
Iteration 20/1000 | Loss: 0.00015326
Iteration 21/1000 | Loss: 0.00018915
Iteration 22/1000 | Loss: 0.00013752
Iteration 23/1000 | Loss: 0.00013352
Iteration 24/1000 | Loss: 0.00019990
Iteration 25/1000 | Loss: 0.00004372
Iteration 26/1000 | Loss: 0.00012181
Iteration 27/1000 | Loss: 0.00010908
Iteration 28/1000 | Loss: 0.00007616
Iteration 29/1000 | Loss: 0.00013242
Iteration 30/1000 | Loss: 0.00021715
Iteration 31/1000 | Loss: 0.00021300
Iteration 32/1000 | Loss: 0.00014611
Iteration 33/1000 | Loss: 0.00010928
Iteration 34/1000 | Loss: 0.00003327
Iteration 35/1000 | Loss: 0.00004862
Iteration 36/1000 | Loss: 0.00013157
Iteration 37/1000 | Loss: 0.00004941
Iteration 38/1000 | Loss: 0.00005383
Iteration 39/1000 | Loss: 0.00007886
Iteration 40/1000 | Loss: 0.00013447
Iteration 41/1000 | Loss: 0.00009844
Iteration 42/1000 | Loss: 0.00014026
Iteration 43/1000 | Loss: 0.00009659
Iteration 44/1000 | Loss: 0.00012433
Iteration 45/1000 | Loss: 0.00011559
Iteration 46/1000 | Loss: 0.00011141
Iteration 47/1000 | Loss: 0.00005606
Iteration 48/1000 | Loss: 0.00006956
Iteration 49/1000 | Loss: 0.00011481
Iteration 50/1000 | Loss: 0.00009301
Iteration 51/1000 | Loss: 0.00015625
Iteration 52/1000 | Loss: 0.00006643
Iteration 53/1000 | Loss: 0.00006146
Iteration 54/1000 | Loss: 0.00009080
Iteration 55/1000 | Loss: 0.00012718
Iteration 56/1000 | Loss: 0.00008213
Iteration 57/1000 | Loss: 0.00014499
Iteration 58/1000 | Loss: 0.00016587
Iteration 59/1000 | Loss: 0.00014861
Iteration 60/1000 | Loss: 0.00011438
Iteration 61/1000 | Loss: 0.00013300
Iteration 62/1000 | Loss: 0.00004133
Iteration 63/1000 | Loss: 0.00004805
Iteration 64/1000 | Loss: 0.00015360
Iteration 65/1000 | Loss: 0.00010217
Iteration 66/1000 | Loss: 0.00020809
Iteration 67/1000 | Loss: 0.00022156
Iteration 68/1000 | Loss: 0.00016931
Iteration 69/1000 | Loss: 0.00017968
Iteration 70/1000 | Loss: 0.00011418
Iteration 71/1000 | Loss: 0.00009323
Iteration 72/1000 | Loss: 0.00025130
Iteration 73/1000 | Loss: 0.00022405
Iteration 74/1000 | Loss: 0.00019574
Iteration 75/1000 | Loss: 0.00030552
Iteration 76/1000 | Loss: 0.00014048
Iteration 77/1000 | Loss: 0.00014199
Iteration 78/1000 | Loss: 0.00031402
Iteration 79/1000 | Loss: 0.00011060
Iteration 80/1000 | Loss: 0.00012126
Iteration 81/1000 | Loss: 0.00007688
Iteration 82/1000 | Loss: 0.00011621
Iteration 83/1000 | Loss: 0.00009451
Iteration 84/1000 | Loss: 0.00009325
Iteration 85/1000 | Loss: 0.00018787
Iteration 86/1000 | Loss: 0.00008820
Iteration 87/1000 | Loss: 0.00009507
Iteration 88/1000 | Loss: 0.00018033
Iteration 89/1000 | Loss: 0.00020697
Iteration 90/1000 | Loss: 0.00005800
Iteration 91/1000 | Loss: 0.00014622
Iteration 92/1000 | Loss: 0.00012561
Iteration 93/1000 | Loss: 0.00013098
Iteration 94/1000 | Loss: 0.00023967
Iteration 95/1000 | Loss: 0.00014049
Iteration 96/1000 | Loss: 0.00014116
Iteration 97/1000 | Loss: 0.00009833
Iteration 98/1000 | Loss: 0.00014284
Iteration 99/1000 | Loss: 0.00014021
Iteration 100/1000 | Loss: 0.00009669
Iteration 101/1000 | Loss: 0.00011311
Iteration 102/1000 | Loss: 0.00011073
Iteration 103/1000 | Loss: 0.00008970
Iteration 104/1000 | Loss: 0.00010849
Iteration 105/1000 | Loss: 0.00008688
Iteration 106/1000 | Loss: 0.00010858
Iteration 107/1000 | Loss: 0.00010639
Iteration 108/1000 | Loss: 0.00011465
Iteration 109/1000 | Loss: 0.00029412
Iteration 110/1000 | Loss: 0.00015113
Iteration 111/1000 | Loss: 0.00019282
Iteration 112/1000 | Loss: 0.00020540
Iteration 113/1000 | Loss: 0.00003880
Iteration 114/1000 | Loss: 0.00003457
Iteration 115/1000 | Loss: 0.00003204
Iteration 116/1000 | Loss: 0.00003147
Iteration 117/1000 | Loss: 0.00003097
Iteration 118/1000 | Loss: 0.00003047
Iteration 119/1000 | Loss: 0.00003010
Iteration 120/1000 | Loss: 0.00002978
Iteration 121/1000 | Loss: 0.00002951
Iteration 122/1000 | Loss: 0.00002925
Iteration 123/1000 | Loss: 0.00002922
Iteration 124/1000 | Loss: 0.00002915
Iteration 125/1000 | Loss: 0.00002905
Iteration 126/1000 | Loss: 0.00002900
Iteration 127/1000 | Loss: 0.00002900
Iteration 128/1000 | Loss: 0.00002899
Iteration 129/1000 | Loss: 0.00002899
Iteration 130/1000 | Loss: 0.00002898
Iteration 131/1000 | Loss: 0.00002898
Iteration 132/1000 | Loss: 0.00002898
Iteration 133/1000 | Loss: 0.00002897
Iteration 134/1000 | Loss: 0.00002897
Iteration 135/1000 | Loss: 0.00002897
Iteration 136/1000 | Loss: 0.00002897
Iteration 137/1000 | Loss: 0.00002897
Iteration 138/1000 | Loss: 0.00002896
Iteration 139/1000 | Loss: 0.00002896
Iteration 140/1000 | Loss: 0.00002896
Iteration 141/1000 | Loss: 0.00002896
Iteration 142/1000 | Loss: 0.00002896
Iteration 143/1000 | Loss: 0.00002895
Iteration 144/1000 | Loss: 0.00002895
Iteration 145/1000 | Loss: 0.00002893
Iteration 146/1000 | Loss: 0.00002893
Iteration 147/1000 | Loss: 0.00002892
Iteration 148/1000 | Loss: 0.00002889
Iteration 149/1000 | Loss: 0.00002889
Iteration 150/1000 | Loss: 0.00002888
Iteration 151/1000 | Loss: 0.00002887
Iteration 152/1000 | Loss: 0.00002887
Iteration 153/1000 | Loss: 0.00002886
Iteration 154/1000 | Loss: 0.00002886
Iteration 155/1000 | Loss: 0.00002886
Iteration 156/1000 | Loss: 0.00002885
Iteration 157/1000 | Loss: 0.00002885
Iteration 158/1000 | Loss: 0.00002885
Iteration 159/1000 | Loss: 0.00002884
Iteration 160/1000 | Loss: 0.00002884
Iteration 161/1000 | Loss: 0.00002884
Iteration 162/1000 | Loss: 0.00002883
Iteration 163/1000 | Loss: 0.00002883
Iteration 164/1000 | Loss: 0.00002883
Iteration 165/1000 | Loss: 0.00002882
Iteration 166/1000 | Loss: 0.00002882
Iteration 167/1000 | Loss: 0.00002882
Iteration 168/1000 | Loss: 0.00002881
Iteration 169/1000 | Loss: 0.00002881
Iteration 170/1000 | Loss: 0.00002880
Iteration 171/1000 | Loss: 0.00002880
Iteration 172/1000 | Loss: 0.00002879
Iteration 173/1000 | Loss: 0.00002879
Iteration 174/1000 | Loss: 0.00002878
Iteration 175/1000 | Loss: 0.00002878
Iteration 176/1000 | Loss: 0.00002878
Iteration 177/1000 | Loss: 0.00002878
Iteration 178/1000 | Loss: 0.00002878
Iteration 179/1000 | Loss: 0.00002877
Iteration 180/1000 | Loss: 0.00002877
Iteration 181/1000 | Loss: 0.00002875
Iteration 182/1000 | Loss: 0.00002875
Iteration 183/1000 | Loss: 0.00002873
Iteration 184/1000 | Loss: 0.00002872
Iteration 185/1000 | Loss: 0.00002872
Iteration 186/1000 | Loss: 0.00002871
Iteration 187/1000 | Loss: 0.00002871
Iteration 188/1000 | Loss: 0.00002870
Iteration 189/1000 | Loss: 0.00002870
Iteration 190/1000 | Loss: 0.00002870
Iteration 191/1000 | Loss: 0.00002870
Iteration 192/1000 | Loss: 0.00002870
Iteration 193/1000 | Loss: 0.00002870
Iteration 194/1000 | Loss: 0.00002870
Iteration 195/1000 | Loss: 0.00002870
Iteration 196/1000 | Loss: 0.00002870
Iteration 197/1000 | Loss: 0.00002870
Iteration 198/1000 | Loss: 0.00002870
Iteration 199/1000 | Loss: 0.00002870
Iteration 200/1000 | Loss: 0.00002869
Iteration 201/1000 | Loss: 0.00002869
Iteration 202/1000 | Loss: 0.00002869
Iteration 203/1000 | Loss: 0.00002869
Iteration 204/1000 | Loss: 0.00002869
Iteration 205/1000 | Loss: 0.00002869
Iteration 206/1000 | Loss: 0.00002869
Iteration 207/1000 | Loss: 0.00002869
Iteration 208/1000 | Loss: 0.00002869
Iteration 209/1000 | Loss: 0.00002869
Iteration 210/1000 | Loss: 0.00002868
Iteration 211/1000 | Loss: 0.00002868
Iteration 212/1000 | Loss: 0.00002868
Iteration 213/1000 | Loss: 0.00002868
Iteration 214/1000 | Loss: 0.00002867
Iteration 215/1000 | Loss: 0.00002867
Iteration 216/1000 | Loss: 0.00002867
Iteration 217/1000 | Loss: 0.00002867
Iteration 218/1000 | Loss: 0.00002867
Iteration 219/1000 | Loss: 0.00002867
Iteration 220/1000 | Loss: 0.00002867
Iteration 221/1000 | Loss: 0.00002867
Iteration 222/1000 | Loss: 0.00002866
Iteration 223/1000 | Loss: 0.00002866
Iteration 224/1000 | Loss: 0.00002866
Iteration 225/1000 | Loss: 0.00002866
Iteration 226/1000 | Loss: 0.00002866
Iteration 227/1000 | Loss: 0.00002865
Iteration 228/1000 | Loss: 0.00002865
Iteration 229/1000 | Loss: 0.00002865
Iteration 230/1000 | Loss: 0.00002865
Iteration 231/1000 | Loss: 0.00002865
Iteration 232/1000 | Loss: 0.00002865
Iteration 233/1000 | Loss: 0.00002864
Iteration 234/1000 | Loss: 0.00002864
Iteration 235/1000 | Loss: 0.00002864
Iteration 236/1000 | Loss: 0.00002864
Iteration 237/1000 | Loss: 0.00002864
Iteration 238/1000 | Loss: 0.00002864
Iteration 239/1000 | Loss: 0.00002863
Iteration 240/1000 | Loss: 0.00002863
Iteration 241/1000 | Loss: 0.00002863
Iteration 242/1000 | Loss: 0.00002863
Iteration 243/1000 | Loss: 0.00002863
Iteration 244/1000 | Loss: 0.00002863
Iteration 245/1000 | Loss: 0.00002862
Iteration 246/1000 | Loss: 0.00002862
Iteration 247/1000 | Loss: 0.00002862
Iteration 248/1000 | Loss: 0.00002862
Iteration 249/1000 | Loss: 0.00002862
Iteration 250/1000 | Loss: 0.00002861
Iteration 251/1000 | Loss: 0.00002861
Iteration 252/1000 | Loss: 0.00002861
Iteration 253/1000 | Loss: 0.00002861
Iteration 254/1000 | Loss: 0.00002860
Iteration 255/1000 | Loss: 0.00002860
Iteration 256/1000 | Loss: 0.00002860
Iteration 257/1000 | Loss: 0.00002860
Iteration 258/1000 | Loss: 0.00002860
Iteration 259/1000 | Loss: 0.00002859
Iteration 260/1000 | Loss: 0.00002859
Iteration 261/1000 | Loss: 0.00002859
Iteration 262/1000 | Loss: 0.00002858
Iteration 263/1000 | Loss: 0.00002858
Iteration 264/1000 | Loss: 0.00002858
Iteration 265/1000 | Loss: 0.00002858
Iteration 266/1000 | Loss: 0.00002857
Iteration 267/1000 | Loss: 0.00002857
Iteration 268/1000 | Loss: 0.00002857
Iteration 269/1000 | Loss: 0.00002857
Iteration 270/1000 | Loss: 0.00002857
Iteration 271/1000 | Loss: 0.00002857
Iteration 272/1000 | Loss: 0.00002857
Iteration 273/1000 | Loss: 0.00002857
Iteration 274/1000 | Loss: 0.00002856
Iteration 275/1000 | Loss: 0.00002856
Iteration 276/1000 | Loss: 0.00002856
Iteration 277/1000 | Loss: 0.00002856
Iteration 278/1000 | Loss: 0.00002856
Iteration 279/1000 | Loss: 0.00002856
Iteration 280/1000 | Loss: 0.00002856
Iteration 281/1000 | Loss: 0.00002856
Iteration 282/1000 | Loss: 0.00002856
Iteration 283/1000 | Loss: 0.00002856
Iteration 284/1000 | Loss: 0.00002856
Iteration 285/1000 | Loss: 0.00002855
Iteration 286/1000 | Loss: 0.00002855
Iteration 287/1000 | Loss: 0.00002855
Iteration 288/1000 | Loss: 0.00002855
Iteration 289/1000 | Loss: 0.00002855
Iteration 290/1000 | Loss: 0.00002855
Iteration 291/1000 | Loss: 0.00002855
Iteration 292/1000 | Loss: 0.00002855
Iteration 293/1000 | Loss: 0.00002855
Iteration 294/1000 | Loss: 0.00002855
Iteration 295/1000 | Loss: 0.00002855
Iteration 296/1000 | Loss: 0.00002855
Iteration 297/1000 | Loss: 0.00002855
Iteration 298/1000 | Loss: 0.00002855
Iteration 299/1000 | Loss: 0.00002855
Iteration 300/1000 | Loss: 0.00002855
Iteration 301/1000 | Loss: 0.00002855
Iteration 302/1000 | Loss: 0.00002855
Iteration 303/1000 | Loss: 0.00002855
Iteration 304/1000 | Loss: 0.00002855
Iteration 305/1000 | Loss: 0.00002855
Iteration 306/1000 | Loss: 0.00002855
Iteration 307/1000 | Loss: 0.00002855
Iteration 308/1000 | Loss: 0.00002855
Iteration 309/1000 | Loss: 0.00002855
Iteration 310/1000 | Loss: 0.00002855
Iteration 311/1000 | Loss: 0.00002855
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 311. Stopping optimization.
Last 5 losses: [2.8548052796395496e-05, 2.8548052796395496e-05, 2.8548052796395496e-05, 2.8548052796395496e-05, 2.8548052796395496e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8548052796395496e-05

Optimization complete. Final v2v error: 4.415836811065674 mm

Highest mean error: 6.2909464836120605 mm for frame 106

Lowest mean error: 3.341153621673584 mm for frame 231

Saving results

Total time: 262.8686110973358
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00402794
Iteration 2/25 | Loss: 0.00109983
Iteration 3/25 | Loss: 0.00078013
Iteration 4/25 | Loss: 0.00074442
Iteration 5/25 | Loss: 0.00073207
Iteration 6/25 | Loss: 0.00072872
Iteration 7/25 | Loss: 0.00072780
Iteration 8/25 | Loss: 0.00072780
Iteration 9/25 | Loss: 0.00072780
Iteration 10/25 | Loss: 0.00072780
Iteration 11/25 | Loss: 0.00072780
Iteration 12/25 | Loss: 0.00072780
Iteration 13/25 | Loss: 0.00072780
Iteration 14/25 | Loss: 0.00072780
Iteration 15/25 | Loss: 0.00072780
Iteration 16/25 | Loss: 0.00072780
Iteration 17/25 | Loss: 0.00072780
Iteration 18/25 | Loss: 0.00072780
Iteration 19/25 | Loss: 0.00072780
Iteration 20/25 | Loss: 0.00072780
Iteration 21/25 | Loss: 0.00072780
Iteration 22/25 | Loss: 0.00072780
Iteration 23/25 | Loss: 0.00072780
Iteration 24/25 | Loss: 0.00072780
Iteration 25/25 | Loss: 0.00072780

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55052221
Iteration 2/25 | Loss: 0.00043752
Iteration 3/25 | Loss: 0.00043752
Iteration 4/25 | Loss: 0.00043752
Iteration 5/25 | Loss: 0.00043752
Iteration 6/25 | Loss: 0.00043752
Iteration 7/25 | Loss: 0.00043752
Iteration 8/25 | Loss: 0.00043752
Iteration 9/25 | Loss: 0.00043752
Iteration 10/25 | Loss: 0.00043752
Iteration 11/25 | Loss: 0.00043752
Iteration 12/25 | Loss: 0.00043752
Iteration 13/25 | Loss: 0.00043752
Iteration 14/25 | Loss: 0.00043752
Iteration 15/25 | Loss: 0.00043752
Iteration 16/25 | Loss: 0.00043752
Iteration 17/25 | Loss: 0.00043752
Iteration 18/25 | Loss: 0.00043752
Iteration 19/25 | Loss: 0.00043752
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0004375157586764544, 0.0004375157586764544, 0.0004375157586764544, 0.0004375157586764544, 0.0004375157586764544]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004375157586764544

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043752
Iteration 2/1000 | Loss: 0.00002927
Iteration 3/1000 | Loss: 0.00002003
Iteration 4/1000 | Loss: 0.00001904
Iteration 5/1000 | Loss: 0.00001836
Iteration 6/1000 | Loss: 0.00001759
Iteration 7/1000 | Loss: 0.00001715
Iteration 8/1000 | Loss: 0.00001683
Iteration 9/1000 | Loss: 0.00001660
Iteration 10/1000 | Loss: 0.00001641
Iteration 11/1000 | Loss: 0.00001633
Iteration 12/1000 | Loss: 0.00001619
Iteration 13/1000 | Loss: 0.00001607
Iteration 14/1000 | Loss: 0.00001599
Iteration 15/1000 | Loss: 0.00001599
Iteration 16/1000 | Loss: 0.00001593
Iteration 17/1000 | Loss: 0.00001593
Iteration 18/1000 | Loss: 0.00001591
Iteration 19/1000 | Loss: 0.00001589
Iteration 20/1000 | Loss: 0.00001586
Iteration 21/1000 | Loss: 0.00001585
Iteration 22/1000 | Loss: 0.00001584
Iteration 23/1000 | Loss: 0.00001582
Iteration 24/1000 | Loss: 0.00001580
Iteration 25/1000 | Loss: 0.00001578
Iteration 26/1000 | Loss: 0.00001578
Iteration 27/1000 | Loss: 0.00001577
Iteration 28/1000 | Loss: 0.00001575
Iteration 29/1000 | Loss: 0.00001574
Iteration 30/1000 | Loss: 0.00001573
Iteration 31/1000 | Loss: 0.00001572
Iteration 32/1000 | Loss: 0.00001572
Iteration 33/1000 | Loss: 0.00001571
Iteration 34/1000 | Loss: 0.00001571
Iteration 35/1000 | Loss: 0.00001571
Iteration 36/1000 | Loss: 0.00001571
Iteration 37/1000 | Loss: 0.00001571
Iteration 38/1000 | Loss: 0.00001571
Iteration 39/1000 | Loss: 0.00001570
Iteration 40/1000 | Loss: 0.00001570
Iteration 41/1000 | Loss: 0.00001570
Iteration 42/1000 | Loss: 0.00001569
Iteration 43/1000 | Loss: 0.00001569
Iteration 44/1000 | Loss: 0.00001569
Iteration 45/1000 | Loss: 0.00001568
Iteration 46/1000 | Loss: 0.00001568
Iteration 47/1000 | Loss: 0.00001568
Iteration 48/1000 | Loss: 0.00001568
Iteration 49/1000 | Loss: 0.00001567
Iteration 50/1000 | Loss: 0.00001567
Iteration 51/1000 | Loss: 0.00001567
Iteration 52/1000 | Loss: 0.00001567
Iteration 53/1000 | Loss: 0.00001567
Iteration 54/1000 | Loss: 0.00001567
Iteration 55/1000 | Loss: 0.00001567
Iteration 56/1000 | Loss: 0.00001567
Iteration 57/1000 | Loss: 0.00001567
Iteration 58/1000 | Loss: 0.00001567
Iteration 59/1000 | Loss: 0.00001566
Iteration 60/1000 | Loss: 0.00001566
Iteration 61/1000 | Loss: 0.00001566
Iteration 62/1000 | Loss: 0.00001566
Iteration 63/1000 | Loss: 0.00001566
Iteration 64/1000 | Loss: 0.00001565
Iteration 65/1000 | Loss: 0.00001565
Iteration 66/1000 | Loss: 0.00001565
Iteration 67/1000 | Loss: 0.00001565
Iteration 68/1000 | Loss: 0.00001565
Iteration 69/1000 | Loss: 0.00001564
Iteration 70/1000 | Loss: 0.00001564
Iteration 71/1000 | Loss: 0.00001564
Iteration 72/1000 | Loss: 0.00001563
Iteration 73/1000 | Loss: 0.00001563
Iteration 74/1000 | Loss: 0.00001563
Iteration 75/1000 | Loss: 0.00001562
Iteration 76/1000 | Loss: 0.00001562
Iteration 77/1000 | Loss: 0.00001562
Iteration 78/1000 | Loss: 0.00001562
Iteration 79/1000 | Loss: 0.00001562
Iteration 80/1000 | Loss: 0.00001562
Iteration 81/1000 | Loss: 0.00001561
Iteration 82/1000 | Loss: 0.00001561
Iteration 83/1000 | Loss: 0.00001561
Iteration 84/1000 | Loss: 0.00001561
Iteration 85/1000 | Loss: 0.00001560
Iteration 86/1000 | Loss: 0.00001560
Iteration 87/1000 | Loss: 0.00001560
Iteration 88/1000 | Loss: 0.00001560
Iteration 89/1000 | Loss: 0.00001560
Iteration 90/1000 | Loss: 0.00001560
Iteration 91/1000 | Loss: 0.00001560
Iteration 92/1000 | Loss: 0.00001560
Iteration 93/1000 | Loss: 0.00001560
Iteration 94/1000 | Loss: 0.00001559
Iteration 95/1000 | Loss: 0.00001559
Iteration 96/1000 | Loss: 0.00001559
Iteration 97/1000 | Loss: 0.00001559
Iteration 98/1000 | Loss: 0.00001559
Iteration 99/1000 | Loss: 0.00001559
Iteration 100/1000 | Loss: 0.00001559
Iteration 101/1000 | Loss: 0.00001559
Iteration 102/1000 | Loss: 0.00001559
Iteration 103/1000 | Loss: 0.00001559
Iteration 104/1000 | Loss: 0.00001559
Iteration 105/1000 | Loss: 0.00001559
Iteration 106/1000 | Loss: 0.00001559
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.5591023839078844e-05, 1.5591023839078844e-05, 1.5591023839078844e-05, 1.5591023839078844e-05, 1.5591023839078844e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5591023839078844e-05

Optimization complete. Final v2v error: 3.3065669536590576 mm

Highest mean error: 3.8210747241973877 mm for frame 135

Lowest mean error: 2.7910714149475098 mm for frame 117

Saving results

Total time: 41.04790782928467
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1070/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1070.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1070
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00924732
Iteration 2/25 | Loss: 0.00180943
Iteration 3/25 | Loss: 0.00120250
Iteration 4/25 | Loss: 0.00109164
Iteration 5/25 | Loss: 0.00102330
Iteration 6/25 | Loss: 0.00098965
Iteration 7/25 | Loss: 0.00098466
Iteration 8/25 | Loss: 0.00096995
Iteration 9/25 | Loss: 0.00096030
Iteration 10/25 | Loss: 0.00094380
Iteration 11/25 | Loss: 0.00095825
Iteration 12/25 | Loss: 0.00095826
Iteration 13/25 | Loss: 0.00095330
Iteration 14/25 | Loss: 0.00094923
Iteration 15/25 | Loss: 0.00093619
Iteration 16/25 | Loss: 0.00098963
Iteration 17/25 | Loss: 0.00096677
Iteration 18/25 | Loss: 0.00093446
Iteration 19/25 | Loss: 0.00091788
Iteration 20/25 | Loss: 0.00092096
Iteration 21/25 | Loss: 0.00092734
Iteration 22/25 | Loss: 0.00091040
Iteration 23/25 | Loss: 0.00091079
Iteration 24/25 | Loss: 0.00090372
Iteration 25/25 | Loss: 0.00090956

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.78719318
Iteration 2/25 | Loss: 0.00192183
Iteration 3/25 | Loss: 0.00192130
Iteration 4/25 | Loss: 0.00192130
Iteration 5/25 | Loss: 0.00192130
Iteration 6/25 | Loss: 0.00192130
Iteration 7/25 | Loss: 0.00192130
Iteration 8/25 | Loss: 0.00192130
Iteration 9/25 | Loss: 0.00192130
Iteration 10/25 | Loss: 0.00192130
Iteration 11/25 | Loss: 0.00192130
Iteration 12/25 | Loss: 0.00192130
Iteration 13/25 | Loss: 0.00192130
Iteration 14/25 | Loss: 0.00192130
Iteration 15/25 | Loss: 0.00192130
Iteration 16/25 | Loss: 0.00192130
Iteration 17/25 | Loss: 0.00192130
Iteration 18/25 | Loss: 0.00192130
Iteration 19/25 | Loss: 0.00192130
Iteration 20/25 | Loss: 0.00192130
Iteration 21/25 | Loss: 0.00192130
Iteration 22/25 | Loss: 0.00192130
Iteration 23/25 | Loss: 0.00192130
Iteration 24/25 | Loss: 0.00192130
Iteration 25/25 | Loss: 0.00192130
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.001921295071952045, 0.001921295071952045, 0.001921295071952045, 0.001921295071952045, 0.001921295071952045]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001921295071952045

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00192130
Iteration 2/1000 | Loss: 0.00475688
Iteration 3/1000 | Loss: 0.00125821
Iteration 4/1000 | Loss: 0.00751670
Iteration 5/1000 | Loss: 0.00121487
Iteration 6/1000 | Loss: 0.00839106
Iteration 7/1000 | Loss: 0.00248573
Iteration 8/1000 | Loss: 0.00170106
Iteration 9/1000 | Loss: 0.00557346
Iteration 10/1000 | Loss: 0.00104706
Iteration 11/1000 | Loss: 0.00099545
Iteration 12/1000 | Loss: 0.00087540
Iteration 13/1000 | Loss: 0.00096565
Iteration 14/1000 | Loss: 0.00087342
Iteration 15/1000 | Loss: 0.00097098
Iteration 16/1000 | Loss: 0.00195725
Iteration 17/1000 | Loss: 0.00156334
Iteration 18/1000 | Loss: 0.00463553
Iteration 19/1000 | Loss: 0.00168453
Iteration 20/1000 | Loss: 0.00512292
Iteration 21/1000 | Loss: 0.00159534
Iteration 22/1000 | Loss: 0.00201701
Iteration 23/1000 | Loss: 0.00095475
Iteration 24/1000 | Loss: 0.00078922
Iteration 25/1000 | Loss: 0.00044163
Iteration 26/1000 | Loss: 0.00059255
Iteration 27/1000 | Loss: 0.00121543
Iteration 28/1000 | Loss: 0.00046845
Iteration 29/1000 | Loss: 0.00041175
Iteration 30/1000 | Loss: 0.00022491
Iteration 31/1000 | Loss: 0.00015405
Iteration 32/1000 | Loss: 0.00101878
Iteration 33/1000 | Loss: 0.00118941
Iteration 34/1000 | Loss: 0.00090953
Iteration 35/1000 | Loss: 0.00013825
Iteration 36/1000 | Loss: 0.00005973
Iteration 37/1000 | Loss: 0.00061285
Iteration 38/1000 | Loss: 0.00040484
Iteration 39/1000 | Loss: 0.00056201
Iteration 40/1000 | Loss: 0.00402420
Iteration 41/1000 | Loss: 0.00025269
Iteration 42/1000 | Loss: 0.00007859
Iteration 43/1000 | Loss: 0.00038362
Iteration 44/1000 | Loss: 0.00024275
Iteration 45/1000 | Loss: 0.00004674
Iteration 46/1000 | Loss: 0.00045888
Iteration 47/1000 | Loss: 0.00004539
Iteration 48/1000 | Loss: 0.00003840
Iteration 49/1000 | Loss: 0.00003560
Iteration 50/1000 | Loss: 0.00003399
Iteration 51/1000 | Loss: 0.00003139
Iteration 52/1000 | Loss: 0.00002965
Iteration 53/1000 | Loss: 0.00002900
Iteration 54/1000 | Loss: 0.00002840
Iteration 55/1000 | Loss: 0.00002814
Iteration 56/1000 | Loss: 0.00002799
Iteration 57/1000 | Loss: 0.00002784
Iteration 58/1000 | Loss: 0.00002766
Iteration 59/1000 | Loss: 0.00002746
Iteration 60/1000 | Loss: 0.00002745
Iteration 61/1000 | Loss: 0.00002739
Iteration 62/1000 | Loss: 0.00002737
Iteration 63/1000 | Loss: 0.00002721
Iteration 64/1000 | Loss: 0.00002712
Iteration 65/1000 | Loss: 0.00002711
Iteration 66/1000 | Loss: 0.00002710
Iteration 67/1000 | Loss: 0.00002704
Iteration 68/1000 | Loss: 0.00002703
Iteration 69/1000 | Loss: 0.00002703
Iteration 70/1000 | Loss: 0.00002703
Iteration 71/1000 | Loss: 0.00002703
Iteration 72/1000 | Loss: 0.00002702
Iteration 73/1000 | Loss: 0.00002702
Iteration 74/1000 | Loss: 0.00002702
Iteration 75/1000 | Loss: 0.00002702
Iteration 76/1000 | Loss: 0.00002701
Iteration 77/1000 | Loss: 0.00002701
Iteration 78/1000 | Loss: 0.00002701
Iteration 79/1000 | Loss: 0.00002701
Iteration 80/1000 | Loss: 0.00002701
Iteration 81/1000 | Loss: 0.00002701
Iteration 82/1000 | Loss: 0.00002701
Iteration 83/1000 | Loss: 0.00002700
Iteration 84/1000 | Loss: 0.00002700
Iteration 85/1000 | Loss: 0.00002700
Iteration 86/1000 | Loss: 0.00002699
Iteration 87/1000 | Loss: 0.00002699
Iteration 88/1000 | Loss: 0.00002699
Iteration 89/1000 | Loss: 0.00002699
Iteration 90/1000 | Loss: 0.00002698
Iteration 91/1000 | Loss: 0.00002698
Iteration 92/1000 | Loss: 0.00002698
Iteration 93/1000 | Loss: 0.00002698
Iteration 94/1000 | Loss: 0.00002698
Iteration 95/1000 | Loss: 0.00002697
Iteration 96/1000 | Loss: 0.00002697
Iteration 97/1000 | Loss: 0.00002697
Iteration 98/1000 | Loss: 0.00002697
Iteration 99/1000 | Loss: 0.00002696
Iteration 100/1000 | Loss: 0.00002696
Iteration 101/1000 | Loss: 0.00002696
Iteration 102/1000 | Loss: 0.00002696
Iteration 103/1000 | Loss: 0.00002696
Iteration 104/1000 | Loss: 0.00002696
Iteration 105/1000 | Loss: 0.00002695
Iteration 106/1000 | Loss: 0.00002695
Iteration 107/1000 | Loss: 0.00002695
Iteration 108/1000 | Loss: 0.00002695
Iteration 109/1000 | Loss: 0.00002695
Iteration 110/1000 | Loss: 0.00002695
Iteration 111/1000 | Loss: 0.00002695
Iteration 112/1000 | Loss: 0.00002694
Iteration 113/1000 | Loss: 0.00002694
Iteration 114/1000 | Loss: 0.00002694
Iteration 115/1000 | Loss: 0.00002694
Iteration 116/1000 | Loss: 0.00002694
Iteration 117/1000 | Loss: 0.00002693
Iteration 118/1000 | Loss: 0.00002693
Iteration 119/1000 | Loss: 0.00002693
Iteration 120/1000 | Loss: 0.00002693
Iteration 121/1000 | Loss: 0.00002692
Iteration 122/1000 | Loss: 0.00002692
Iteration 123/1000 | Loss: 0.00002692
Iteration 124/1000 | Loss: 0.00002692
Iteration 125/1000 | Loss: 0.00002691
Iteration 126/1000 | Loss: 0.00002691
Iteration 127/1000 | Loss: 0.00002691
Iteration 128/1000 | Loss: 0.00002690
Iteration 129/1000 | Loss: 0.00002690
Iteration 130/1000 | Loss: 0.00002690
Iteration 131/1000 | Loss: 0.00002690
Iteration 132/1000 | Loss: 0.00002689
Iteration 133/1000 | Loss: 0.00002689
Iteration 134/1000 | Loss: 0.00002689
Iteration 135/1000 | Loss: 0.00002689
Iteration 136/1000 | Loss: 0.00002688
Iteration 137/1000 | Loss: 0.00002688
Iteration 138/1000 | Loss: 0.00002688
Iteration 139/1000 | Loss: 0.00002686
Iteration 140/1000 | Loss: 0.00002686
Iteration 141/1000 | Loss: 0.00002685
Iteration 142/1000 | Loss: 0.00002684
Iteration 143/1000 | Loss: 0.00002684
Iteration 144/1000 | Loss: 0.00002684
Iteration 145/1000 | Loss: 0.00002684
Iteration 146/1000 | Loss: 0.00002684
Iteration 147/1000 | Loss: 0.00002683
Iteration 148/1000 | Loss: 0.00002683
Iteration 149/1000 | Loss: 0.00002683
Iteration 150/1000 | Loss: 0.00002683
Iteration 151/1000 | Loss: 0.00002683
Iteration 152/1000 | Loss: 0.00002682
Iteration 153/1000 | Loss: 0.00002682
Iteration 154/1000 | Loss: 0.00002682
Iteration 155/1000 | Loss: 0.00002682
Iteration 156/1000 | Loss: 0.00002682
Iteration 157/1000 | Loss: 0.00002682
Iteration 158/1000 | Loss: 0.00002682
Iteration 159/1000 | Loss: 0.00002681
Iteration 160/1000 | Loss: 0.00002681
Iteration 161/1000 | Loss: 0.00002681
Iteration 162/1000 | Loss: 0.00002681
Iteration 163/1000 | Loss: 0.00002681
Iteration 164/1000 | Loss: 0.00002681
Iteration 165/1000 | Loss: 0.00002681
Iteration 166/1000 | Loss: 0.00002681
Iteration 167/1000 | Loss: 0.00002681
Iteration 168/1000 | Loss: 0.00002681
Iteration 169/1000 | Loss: 0.00002681
Iteration 170/1000 | Loss: 0.00002681
Iteration 171/1000 | Loss: 0.00002681
Iteration 172/1000 | Loss: 0.00002681
Iteration 173/1000 | Loss: 0.00002681
Iteration 174/1000 | Loss: 0.00002681
Iteration 175/1000 | Loss: 0.00002681
Iteration 176/1000 | Loss: 0.00002681
Iteration 177/1000 | Loss: 0.00002681
Iteration 178/1000 | Loss: 0.00002681
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 178. Stopping optimization.
Last 5 losses: [2.68085568677634e-05, 2.68085568677634e-05, 2.68085568677634e-05, 2.68085568677634e-05, 2.68085568677634e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.68085568677634e-05

Optimization complete. Final v2v error: 4.192749977111816 mm

Highest mean error: 6.601045608520508 mm for frame 137

Lowest mean error: 3.0583977699279785 mm for frame 48

Saving results

Total time: 165.36763954162598
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1049/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1049.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1049
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00337014
Iteration 2/25 | Loss: 0.00081616
Iteration 3/25 | Loss: 0.00070192
Iteration 4/25 | Loss: 0.00068530
Iteration 5/25 | Loss: 0.00068003
Iteration 6/25 | Loss: 0.00067823
Iteration 7/25 | Loss: 0.00067784
Iteration 8/25 | Loss: 0.00067784
Iteration 9/25 | Loss: 0.00067784
Iteration 10/25 | Loss: 0.00067784
Iteration 11/25 | Loss: 0.00067784
Iteration 12/25 | Loss: 0.00067784
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0006778420647606254, 0.0006778420647606254, 0.0006778420647606254, 0.0006778420647606254, 0.0006778420647606254]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006778420647606254

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50905776
Iteration 2/25 | Loss: 0.00049807
Iteration 3/25 | Loss: 0.00049807
Iteration 4/25 | Loss: 0.00049807
Iteration 5/25 | Loss: 0.00049807
Iteration 6/25 | Loss: 0.00049807
Iteration 7/25 | Loss: 0.00049807
Iteration 8/25 | Loss: 0.00049807
Iteration 9/25 | Loss: 0.00049807
Iteration 10/25 | Loss: 0.00049807
Iteration 11/25 | Loss: 0.00049807
Iteration 12/25 | Loss: 0.00049807
Iteration 13/25 | Loss: 0.00049807
Iteration 14/25 | Loss: 0.00049807
Iteration 15/25 | Loss: 0.00049807
Iteration 16/25 | Loss: 0.00049807
Iteration 17/25 | Loss: 0.00049807
Iteration 18/25 | Loss: 0.00049807
Iteration 19/25 | Loss: 0.00049807
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000498069915920496, 0.000498069915920496, 0.000498069915920496, 0.000498069915920496, 0.000498069915920496]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000498069915920496

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049807
Iteration 2/1000 | Loss: 0.00002085
Iteration 3/1000 | Loss: 0.00001031
Iteration 4/1000 | Loss: 0.00000957
Iteration 5/1000 | Loss: 0.00000890
Iteration 6/1000 | Loss: 0.00000869
Iteration 7/1000 | Loss: 0.00000860
Iteration 8/1000 | Loss: 0.00000846
Iteration 9/1000 | Loss: 0.00000842
Iteration 10/1000 | Loss: 0.00000841
Iteration 11/1000 | Loss: 0.00000837
Iteration 12/1000 | Loss: 0.00000835
Iteration 13/1000 | Loss: 0.00000835
Iteration 14/1000 | Loss: 0.00000834
Iteration 15/1000 | Loss: 0.00000834
Iteration 16/1000 | Loss: 0.00000833
Iteration 17/1000 | Loss: 0.00000833
Iteration 18/1000 | Loss: 0.00000833
Iteration 19/1000 | Loss: 0.00000830
Iteration 20/1000 | Loss: 0.00000828
Iteration 21/1000 | Loss: 0.00000828
Iteration 22/1000 | Loss: 0.00000827
Iteration 23/1000 | Loss: 0.00000827
Iteration 24/1000 | Loss: 0.00000826
Iteration 25/1000 | Loss: 0.00000823
Iteration 26/1000 | Loss: 0.00000823
Iteration 27/1000 | Loss: 0.00000823
Iteration 28/1000 | Loss: 0.00000822
Iteration 29/1000 | Loss: 0.00000822
Iteration 30/1000 | Loss: 0.00000821
Iteration 31/1000 | Loss: 0.00000821
Iteration 32/1000 | Loss: 0.00000820
Iteration 33/1000 | Loss: 0.00000820
Iteration 34/1000 | Loss: 0.00000819
Iteration 35/1000 | Loss: 0.00000819
Iteration 36/1000 | Loss: 0.00000818
Iteration 37/1000 | Loss: 0.00000818
Iteration 38/1000 | Loss: 0.00000818
Iteration 39/1000 | Loss: 0.00000818
Iteration 40/1000 | Loss: 0.00000817
Iteration 41/1000 | Loss: 0.00000817
Iteration 42/1000 | Loss: 0.00000817
Iteration 43/1000 | Loss: 0.00000817
Iteration 44/1000 | Loss: 0.00000816
Iteration 45/1000 | Loss: 0.00000816
Iteration 46/1000 | Loss: 0.00000816
Iteration 47/1000 | Loss: 0.00000816
Iteration 48/1000 | Loss: 0.00000816
Iteration 49/1000 | Loss: 0.00000815
Iteration 50/1000 | Loss: 0.00000815
Iteration 51/1000 | Loss: 0.00000815
Iteration 52/1000 | Loss: 0.00000815
Iteration 53/1000 | Loss: 0.00000815
Iteration 54/1000 | Loss: 0.00000815
Iteration 55/1000 | Loss: 0.00000815
Iteration 56/1000 | Loss: 0.00000815
Iteration 57/1000 | Loss: 0.00000815
Iteration 58/1000 | Loss: 0.00000814
Iteration 59/1000 | Loss: 0.00000814
Iteration 60/1000 | Loss: 0.00000814
Iteration 61/1000 | Loss: 0.00000814
Iteration 62/1000 | Loss: 0.00000814
Iteration 63/1000 | Loss: 0.00000813
Iteration 64/1000 | Loss: 0.00000813
Iteration 65/1000 | Loss: 0.00000812
Iteration 66/1000 | Loss: 0.00000812
Iteration 67/1000 | Loss: 0.00000812
Iteration 68/1000 | Loss: 0.00000812
Iteration 69/1000 | Loss: 0.00000811
Iteration 70/1000 | Loss: 0.00000811
Iteration 71/1000 | Loss: 0.00000811
Iteration 72/1000 | Loss: 0.00000811
Iteration 73/1000 | Loss: 0.00000811
Iteration 74/1000 | Loss: 0.00000811
Iteration 75/1000 | Loss: 0.00000810
Iteration 76/1000 | Loss: 0.00000810
Iteration 77/1000 | Loss: 0.00000810
Iteration 78/1000 | Loss: 0.00000810
Iteration 79/1000 | Loss: 0.00000809
Iteration 80/1000 | Loss: 0.00000809
Iteration 81/1000 | Loss: 0.00000809
Iteration 82/1000 | Loss: 0.00000809
Iteration 83/1000 | Loss: 0.00000808
Iteration 84/1000 | Loss: 0.00000808
Iteration 85/1000 | Loss: 0.00000808
Iteration 86/1000 | Loss: 0.00000808
Iteration 87/1000 | Loss: 0.00000808
Iteration 88/1000 | Loss: 0.00000808
Iteration 89/1000 | Loss: 0.00000807
Iteration 90/1000 | Loss: 0.00000807
Iteration 91/1000 | Loss: 0.00000807
Iteration 92/1000 | Loss: 0.00000807
Iteration 93/1000 | Loss: 0.00000807
Iteration 94/1000 | Loss: 0.00000807
Iteration 95/1000 | Loss: 0.00000807
Iteration 96/1000 | Loss: 0.00000807
Iteration 97/1000 | Loss: 0.00000807
Iteration 98/1000 | Loss: 0.00000807
Iteration 99/1000 | Loss: 0.00000806
Iteration 100/1000 | Loss: 0.00000806
Iteration 101/1000 | Loss: 0.00000806
Iteration 102/1000 | Loss: 0.00000806
Iteration 103/1000 | Loss: 0.00000806
Iteration 104/1000 | Loss: 0.00000806
Iteration 105/1000 | Loss: 0.00000805
Iteration 106/1000 | Loss: 0.00000805
Iteration 107/1000 | Loss: 0.00000805
Iteration 108/1000 | Loss: 0.00000805
Iteration 109/1000 | Loss: 0.00000805
Iteration 110/1000 | Loss: 0.00000805
Iteration 111/1000 | Loss: 0.00000805
Iteration 112/1000 | Loss: 0.00000805
Iteration 113/1000 | Loss: 0.00000805
Iteration 114/1000 | Loss: 0.00000805
Iteration 115/1000 | Loss: 0.00000805
Iteration 116/1000 | Loss: 0.00000805
Iteration 117/1000 | Loss: 0.00000805
Iteration 118/1000 | Loss: 0.00000805
Iteration 119/1000 | Loss: 0.00000804
Iteration 120/1000 | Loss: 0.00000804
Iteration 121/1000 | Loss: 0.00000804
Iteration 122/1000 | Loss: 0.00000804
Iteration 123/1000 | Loss: 0.00000804
Iteration 124/1000 | Loss: 0.00000804
Iteration 125/1000 | Loss: 0.00000804
Iteration 126/1000 | Loss: 0.00000804
Iteration 127/1000 | Loss: 0.00000804
Iteration 128/1000 | Loss: 0.00000804
Iteration 129/1000 | Loss: 0.00000804
Iteration 130/1000 | Loss: 0.00000804
Iteration 131/1000 | Loss: 0.00000804
Iteration 132/1000 | Loss: 0.00000804
Iteration 133/1000 | Loss: 0.00000804
Iteration 134/1000 | Loss: 0.00000804
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 134. Stopping optimization.
Last 5 losses: [8.04074625193607e-06, 8.04074625193607e-06, 8.04074625193607e-06, 8.04074625193607e-06, 8.04074625193607e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.04074625193607e-06

Optimization complete. Final v2v error: 2.4621078968048096 mm

Highest mean error: 2.705034017562866 mm for frame 127

Lowest mean error: 2.2602427005767822 mm for frame 24

Saving results

Total time: 31.691343069076538
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1068/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1068.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1068
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00577503
Iteration 2/25 | Loss: 0.00097074
Iteration 3/25 | Loss: 0.00082169
Iteration 4/25 | Loss: 0.00077892
Iteration 5/25 | Loss: 0.00077123
Iteration 6/25 | Loss: 0.00076906
Iteration 7/25 | Loss: 0.00076857
Iteration 8/25 | Loss: 0.00076857
Iteration 9/25 | Loss: 0.00076857
Iteration 10/25 | Loss: 0.00076857
Iteration 11/25 | Loss: 0.00076857
Iteration 12/25 | Loss: 0.00076857
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000768565631005913, 0.000768565631005913, 0.000768565631005913, 0.000768565631005913, 0.000768565631005913]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000768565631005913

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.61971080
Iteration 2/25 | Loss: 0.00049872
Iteration 3/25 | Loss: 0.00049872
Iteration 4/25 | Loss: 0.00049872
Iteration 5/25 | Loss: 0.00049872
Iteration 6/25 | Loss: 0.00049872
Iteration 7/25 | Loss: 0.00049872
Iteration 8/25 | Loss: 0.00049872
Iteration 9/25 | Loss: 0.00049872
Iteration 10/25 | Loss: 0.00049872
Iteration 11/25 | Loss: 0.00049872
Iteration 12/25 | Loss: 0.00049872
Iteration 13/25 | Loss: 0.00049872
Iteration 14/25 | Loss: 0.00049872
Iteration 15/25 | Loss: 0.00049872
Iteration 16/25 | Loss: 0.00049872
Iteration 17/25 | Loss: 0.00049872
Iteration 18/25 | Loss: 0.00049872
Iteration 19/25 | Loss: 0.00049872
Iteration 20/25 | Loss: 0.00049872
Iteration 21/25 | Loss: 0.00049872
Iteration 22/25 | Loss: 0.00049872
Iteration 23/25 | Loss: 0.00049872
Iteration 24/25 | Loss: 0.00049872
Iteration 25/25 | Loss: 0.00049872

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049872
Iteration 2/1000 | Loss: 0.00002835
Iteration 3/1000 | Loss: 0.00001882
Iteration 4/1000 | Loss: 0.00001739
Iteration 5/1000 | Loss: 0.00001667
Iteration 6/1000 | Loss: 0.00001623
Iteration 7/1000 | Loss: 0.00001594
Iteration 8/1000 | Loss: 0.00001573
Iteration 9/1000 | Loss: 0.00001556
Iteration 10/1000 | Loss: 0.00001540
Iteration 11/1000 | Loss: 0.00001538
Iteration 12/1000 | Loss: 0.00001530
Iteration 13/1000 | Loss: 0.00001516
Iteration 14/1000 | Loss: 0.00001515
Iteration 15/1000 | Loss: 0.00001515
Iteration 16/1000 | Loss: 0.00001514
Iteration 17/1000 | Loss: 0.00001513
Iteration 18/1000 | Loss: 0.00001507
Iteration 19/1000 | Loss: 0.00001506
Iteration 20/1000 | Loss: 0.00001505
Iteration 21/1000 | Loss: 0.00001505
Iteration 22/1000 | Loss: 0.00001499
Iteration 23/1000 | Loss: 0.00001498
Iteration 24/1000 | Loss: 0.00001498
Iteration 25/1000 | Loss: 0.00001496
Iteration 26/1000 | Loss: 0.00001496
Iteration 27/1000 | Loss: 0.00001495
Iteration 28/1000 | Loss: 0.00001494
Iteration 29/1000 | Loss: 0.00001493
Iteration 30/1000 | Loss: 0.00001493
Iteration 31/1000 | Loss: 0.00001493
Iteration 32/1000 | Loss: 0.00001493
Iteration 33/1000 | Loss: 0.00001493
Iteration 34/1000 | Loss: 0.00001492
Iteration 35/1000 | Loss: 0.00001492
Iteration 36/1000 | Loss: 0.00001492
Iteration 37/1000 | Loss: 0.00001492
Iteration 38/1000 | Loss: 0.00001490
Iteration 39/1000 | Loss: 0.00001487
Iteration 40/1000 | Loss: 0.00001485
Iteration 41/1000 | Loss: 0.00001485
Iteration 42/1000 | Loss: 0.00001484
Iteration 43/1000 | Loss: 0.00001483
Iteration 44/1000 | Loss: 0.00001483
Iteration 45/1000 | Loss: 0.00001483
Iteration 46/1000 | Loss: 0.00001482
Iteration 47/1000 | Loss: 0.00001482
Iteration 48/1000 | Loss: 0.00001482
Iteration 49/1000 | Loss: 0.00001482
Iteration 50/1000 | Loss: 0.00001481
Iteration 51/1000 | Loss: 0.00001481
Iteration 52/1000 | Loss: 0.00001481
Iteration 53/1000 | Loss: 0.00001481
Iteration 54/1000 | Loss: 0.00001481
Iteration 55/1000 | Loss: 0.00001481
Iteration 56/1000 | Loss: 0.00001480
Iteration 57/1000 | Loss: 0.00001480
Iteration 58/1000 | Loss: 0.00001480
Iteration 59/1000 | Loss: 0.00001480
Iteration 60/1000 | Loss: 0.00001480
Iteration 61/1000 | Loss: 0.00001479
Iteration 62/1000 | Loss: 0.00001479
Iteration 63/1000 | Loss: 0.00001479
Iteration 64/1000 | Loss: 0.00001478
Iteration 65/1000 | Loss: 0.00001478
Iteration 66/1000 | Loss: 0.00001478
Iteration 67/1000 | Loss: 0.00001478
Iteration 68/1000 | Loss: 0.00001478
Iteration 69/1000 | Loss: 0.00001478
Iteration 70/1000 | Loss: 0.00001478
Iteration 71/1000 | Loss: 0.00001478
Iteration 72/1000 | Loss: 0.00001478
Iteration 73/1000 | Loss: 0.00001478
Iteration 74/1000 | Loss: 0.00001478
Iteration 75/1000 | Loss: 0.00001478
Iteration 76/1000 | Loss: 0.00001477
Iteration 77/1000 | Loss: 0.00001477
Iteration 78/1000 | Loss: 0.00001477
Iteration 79/1000 | Loss: 0.00001477
Iteration 80/1000 | Loss: 0.00001477
Iteration 81/1000 | Loss: 0.00001477
Iteration 82/1000 | Loss: 0.00001477
Iteration 83/1000 | Loss: 0.00001477
Iteration 84/1000 | Loss: 0.00001477
Iteration 85/1000 | Loss: 0.00001477
Iteration 86/1000 | Loss: 0.00001477
Iteration 87/1000 | Loss: 0.00001477
Iteration 88/1000 | Loss: 0.00001476
Iteration 89/1000 | Loss: 0.00001476
Iteration 90/1000 | Loss: 0.00001476
Iteration 91/1000 | Loss: 0.00001476
Iteration 92/1000 | Loss: 0.00001476
Iteration 93/1000 | Loss: 0.00001476
Iteration 94/1000 | Loss: 0.00001476
Iteration 95/1000 | Loss: 0.00001476
Iteration 96/1000 | Loss: 0.00001476
Iteration 97/1000 | Loss: 0.00001476
Iteration 98/1000 | Loss: 0.00001476
Iteration 99/1000 | Loss: 0.00001476
Iteration 100/1000 | Loss: 0.00001476
Iteration 101/1000 | Loss: 0.00001476
Iteration 102/1000 | Loss: 0.00001476
Iteration 103/1000 | Loss: 0.00001476
Iteration 104/1000 | Loss: 0.00001476
Iteration 105/1000 | Loss: 0.00001475
Iteration 106/1000 | Loss: 0.00001475
Iteration 107/1000 | Loss: 0.00001475
Iteration 108/1000 | Loss: 0.00001475
Iteration 109/1000 | Loss: 0.00001475
Iteration 110/1000 | Loss: 0.00001475
Iteration 111/1000 | Loss: 0.00001475
Iteration 112/1000 | Loss: 0.00001475
Iteration 113/1000 | Loss: 0.00001475
Iteration 114/1000 | Loss: 0.00001475
Iteration 115/1000 | Loss: 0.00001475
Iteration 116/1000 | Loss: 0.00001475
Iteration 117/1000 | Loss: 0.00001475
Iteration 118/1000 | Loss: 0.00001475
Iteration 119/1000 | Loss: 0.00001475
Iteration 120/1000 | Loss: 0.00001475
Iteration 121/1000 | Loss: 0.00001475
Iteration 122/1000 | Loss: 0.00001475
Iteration 123/1000 | Loss: 0.00001475
Iteration 124/1000 | Loss: 0.00001475
Iteration 125/1000 | Loss: 0.00001475
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [1.4747203749720939e-05, 1.4747203749720939e-05, 1.4747203749720939e-05, 1.4747203749720939e-05, 1.4747203749720939e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4747203749720939e-05

Optimization complete. Final v2v error: 3.266077995300293 mm

Highest mean error: 3.6197586059570312 mm for frame 8

Lowest mean error: 3.0242202281951904 mm for frame 95

Saving results

Total time: 36.60829305648804
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1079/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1079.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1079
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01064769
Iteration 2/25 | Loss: 0.00195539
Iteration 3/25 | Loss: 0.00148033
Iteration 4/25 | Loss: 0.00140843
Iteration 5/25 | Loss: 0.00194779
Iteration 6/25 | Loss: 0.00171436
Iteration 7/25 | Loss: 0.00181027
Iteration 8/25 | Loss: 0.00192889
Iteration 9/25 | Loss: 0.00174288
Iteration 10/25 | Loss: 0.00149553
Iteration 11/25 | Loss: 0.00144627
Iteration 12/25 | Loss: 0.00131731
Iteration 13/25 | Loss: 0.00119915
Iteration 14/25 | Loss: 0.00113018
Iteration 15/25 | Loss: 0.00108083
Iteration 16/25 | Loss: 0.00103386
Iteration 17/25 | Loss: 0.00100944
Iteration 18/25 | Loss: 0.00097635
Iteration 19/25 | Loss: 0.00094620
Iteration 20/25 | Loss: 0.00092495
Iteration 21/25 | Loss: 0.00090595
Iteration 22/25 | Loss: 0.00089830
Iteration 23/25 | Loss: 0.00088465
Iteration 24/25 | Loss: 0.00089131
Iteration 25/25 | Loss: 0.00088998

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46047223
Iteration 2/25 | Loss: 0.00185466
Iteration 3/25 | Loss: 0.00171622
Iteration 4/25 | Loss: 0.00171622
Iteration 5/25 | Loss: 0.00171622
Iteration 6/25 | Loss: 0.00171622
Iteration 7/25 | Loss: 0.00171622
Iteration 8/25 | Loss: 0.00171622
Iteration 9/25 | Loss: 0.00171622
Iteration 10/25 | Loss: 0.00171622
Iteration 11/25 | Loss: 0.00171622
Iteration 12/25 | Loss: 0.00171622
Iteration 13/25 | Loss: 0.00171622
Iteration 14/25 | Loss: 0.00171622
Iteration 15/25 | Loss: 0.00171622
Iteration 16/25 | Loss: 0.00171622
Iteration 17/25 | Loss: 0.00171622
Iteration 18/25 | Loss: 0.00171622
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0017162174917757511, 0.0017162174917757511, 0.0017162174917757511, 0.0017162174917757511, 0.0017162174917757511]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0017162174917757511

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00171622
Iteration 2/1000 | Loss: 0.00119956
Iteration 3/1000 | Loss: 0.00033876
Iteration 4/1000 | Loss: 0.00093626
Iteration 5/1000 | Loss: 0.00083160
Iteration 6/1000 | Loss: 0.00089685
Iteration 7/1000 | Loss: 0.00049528
Iteration 8/1000 | Loss: 0.00086715
Iteration 9/1000 | Loss: 0.00039352
Iteration 10/1000 | Loss: 0.00047447
Iteration 11/1000 | Loss: 0.00090112
Iteration 12/1000 | Loss: 0.00127504
Iteration 13/1000 | Loss: 0.00128604
Iteration 14/1000 | Loss: 0.00097710
Iteration 15/1000 | Loss: 0.00114900
Iteration 16/1000 | Loss: 0.00080130
Iteration 17/1000 | Loss: 0.00056859
Iteration 18/1000 | Loss: 0.00076289
Iteration 19/1000 | Loss: 0.00094323
Iteration 20/1000 | Loss: 0.00073449
Iteration 21/1000 | Loss: 0.00061286
Iteration 22/1000 | Loss: 0.00084221
Iteration 23/1000 | Loss: 0.00054782
Iteration 24/1000 | Loss: 0.00162756
Iteration 25/1000 | Loss: 0.00096845
Iteration 26/1000 | Loss: 0.00070269
Iteration 27/1000 | Loss: 0.00085109
Iteration 28/1000 | Loss: 0.00051808
Iteration 29/1000 | Loss: 0.00036370
Iteration 30/1000 | Loss: 0.00082734
Iteration 31/1000 | Loss: 0.00071553
Iteration 32/1000 | Loss: 0.00085470
Iteration 33/1000 | Loss: 0.00112811
Iteration 34/1000 | Loss: 0.00069556
Iteration 35/1000 | Loss: 0.00107878
Iteration 36/1000 | Loss: 0.00091794
Iteration 37/1000 | Loss: 0.00164965
Iteration 38/1000 | Loss: 0.00101344
Iteration 39/1000 | Loss: 0.00062289
Iteration 40/1000 | Loss: 0.00039703
Iteration 41/1000 | Loss: 0.00023661
Iteration 42/1000 | Loss: 0.00037411
Iteration 43/1000 | Loss: 0.00061821
Iteration 44/1000 | Loss: 0.00040804
Iteration 45/1000 | Loss: 0.00058992
Iteration 46/1000 | Loss: 0.00121583
Iteration 47/1000 | Loss: 0.00130254
Iteration 48/1000 | Loss: 0.00125247
Iteration 49/1000 | Loss: 0.00164228
Iteration 50/1000 | Loss: 0.00096551
Iteration 51/1000 | Loss: 0.00153741
Iteration 52/1000 | Loss: 0.00036224
Iteration 53/1000 | Loss: 0.00037357
Iteration 54/1000 | Loss: 0.00067344
Iteration 55/1000 | Loss: 0.00124036
Iteration 56/1000 | Loss: 0.00025109
Iteration 57/1000 | Loss: 0.00072199
Iteration 58/1000 | Loss: 0.00076488
Iteration 59/1000 | Loss: 0.00073770
Iteration 60/1000 | Loss: 0.00047314
Iteration 61/1000 | Loss: 0.00034091
Iteration 62/1000 | Loss: 0.00044196
Iteration 63/1000 | Loss: 0.00091280
Iteration 64/1000 | Loss: 0.00070955
Iteration 65/1000 | Loss: 0.00028830
Iteration 66/1000 | Loss: 0.00047022
Iteration 67/1000 | Loss: 0.00029763
Iteration 68/1000 | Loss: 0.00029562
Iteration 69/1000 | Loss: 0.00028893
Iteration 70/1000 | Loss: 0.00030583
Iteration 71/1000 | Loss: 0.00029741
Iteration 72/1000 | Loss: 0.00088786
Iteration 73/1000 | Loss: 0.00072113
Iteration 74/1000 | Loss: 0.00041685
Iteration 75/1000 | Loss: 0.00049157
Iteration 76/1000 | Loss: 0.00034627
Iteration 77/1000 | Loss: 0.00040657
Iteration 78/1000 | Loss: 0.00042002
Iteration 79/1000 | Loss: 0.00037353
Iteration 80/1000 | Loss: 0.00035146
Iteration 81/1000 | Loss: 0.00033227
Iteration 82/1000 | Loss: 0.00041064
Iteration 83/1000 | Loss: 0.00053294
Iteration 84/1000 | Loss: 0.00043191
Iteration 85/1000 | Loss: 0.00051278
Iteration 86/1000 | Loss: 0.00044286
Iteration 87/1000 | Loss: 0.00031649
Iteration 88/1000 | Loss: 0.00057557
Iteration 89/1000 | Loss: 0.00028274
Iteration 90/1000 | Loss: 0.00031908
Iteration 91/1000 | Loss: 0.00007576
Iteration 92/1000 | Loss: 0.00006158
Iteration 93/1000 | Loss: 0.00048821
Iteration 94/1000 | Loss: 0.00048746
Iteration 95/1000 | Loss: 0.00062737
Iteration 96/1000 | Loss: 0.00006335
Iteration 97/1000 | Loss: 0.00034404
Iteration 98/1000 | Loss: 0.00024274
Iteration 99/1000 | Loss: 0.00025795
Iteration 100/1000 | Loss: 0.00023227
Iteration 101/1000 | Loss: 0.00005750
Iteration 102/1000 | Loss: 0.00026003
Iteration 103/1000 | Loss: 0.00021736
Iteration 104/1000 | Loss: 0.00024703
Iteration 105/1000 | Loss: 0.00003663
Iteration 106/1000 | Loss: 0.00003401
Iteration 107/1000 | Loss: 0.00023449
Iteration 108/1000 | Loss: 0.00051872
Iteration 109/1000 | Loss: 0.00024429
Iteration 110/1000 | Loss: 0.00011122
Iteration 111/1000 | Loss: 0.00004355
Iteration 112/1000 | Loss: 0.00003517
Iteration 113/1000 | Loss: 0.00003221
Iteration 114/1000 | Loss: 0.00023713
Iteration 115/1000 | Loss: 0.00003579
Iteration 116/1000 | Loss: 0.00003016
Iteration 117/1000 | Loss: 0.00002702
Iteration 118/1000 | Loss: 0.00002549
Iteration 119/1000 | Loss: 0.00002449
Iteration 120/1000 | Loss: 0.00002369
Iteration 121/1000 | Loss: 0.00025944
Iteration 122/1000 | Loss: 0.00042112
Iteration 123/1000 | Loss: 0.00024467
Iteration 124/1000 | Loss: 0.00017946
Iteration 125/1000 | Loss: 0.00017399
Iteration 126/1000 | Loss: 0.00003200
Iteration 127/1000 | Loss: 0.00002830
Iteration 128/1000 | Loss: 0.00002530
Iteration 129/1000 | Loss: 0.00018225
Iteration 130/1000 | Loss: 0.00003626
Iteration 131/1000 | Loss: 0.00002772
Iteration 132/1000 | Loss: 0.00002479
Iteration 133/1000 | Loss: 0.00025269
Iteration 134/1000 | Loss: 0.00019016
Iteration 135/1000 | Loss: 0.00022552
Iteration 136/1000 | Loss: 0.00022942
Iteration 137/1000 | Loss: 0.00024408
Iteration 138/1000 | Loss: 0.00018923
Iteration 139/1000 | Loss: 0.00005182
Iteration 140/1000 | Loss: 0.00003040
Iteration 141/1000 | Loss: 0.00002635
Iteration 142/1000 | Loss: 0.00002523
Iteration 143/1000 | Loss: 0.00023800
Iteration 144/1000 | Loss: 0.00052063
Iteration 145/1000 | Loss: 0.00003920
Iteration 146/1000 | Loss: 0.00003125
Iteration 147/1000 | Loss: 0.00002928
Iteration 148/1000 | Loss: 0.00028477
Iteration 149/1000 | Loss: 0.00004469
Iteration 150/1000 | Loss: 0.00003432
Iteration 151/1000 | Loss: 0.00018408
Iteration 152/1000 | Loss: 0.00013702
Iteration 153/1000 | Loss: 0.00005968
Iteration 154/1000 | Loss: 0.00022812
Iteration 155/1000 | Loss: 0.00004698
Iteration 156/1000 | Loss: 0.00002989
Iteration 157/1000 | Loss: 0.00002668
Iteration 158/1000 | Loss: 0.00002544
Iteration 159/1000 | Loss: 0.00002435
Iteration 160/1000 | Loss: 0.00002286
Iteration 161/1000 | Loss: 0.00002191
Iteration 162/1000 | Loss: 0.00002111
Iteration 163/1000 | Loss: 0.00002052
Iteration 164/1000 | Loss: 0.00002006
Iteration 165/1000 | Loss: 0.00001968
Iteration 166/1000 | Loss: 0.00001943
Iteration 167/1000 | Loss: 0.00022721
Iteration 168/1000 | Loss: 0.00002604
Iteration 169/1000 | Loss: 0.00002371
Iteration 170/1000 | Loss: 0.00002145
Iteration 171/1000 | Loss: 0.00002078
Iteration 172/1000 | Loss: 0.00002060
Iteration 173/1000 | Loss: 0.00002020
Iteration 174/1000 | Loss: 0.00001988
Iteration 175/1000 | Loss: 0.00023574
Iteration 176/1000 | Loss: 0.00025461
Iteration 177/1000 | Loss: 0.00003121
Iteration 178/1000 | Loss: 0.00002621
Iteration 179/1000 | Loss: 0.00023510
Iteration 180/1000 | Loss: 0.00046729
Iteration 181/1000 | Loss: 0.00046880
Iteration 182/1000 | Loss: 0.00064986
Iteration 183/1000 | Loss: 0.00038513
Iteration 184/1000 | Loss: 0.00031404
Iteration 185/1000 | Loss: 0.00012177
Iteration 186/1000 | Loss: 0.00003519
Iteration 187/1000 | Loss: 0.00002906
Iteration 188/1000 | Loss: 0.00019565
Iteration 189/1000 | Loss: 0.00003847
Iteration 190/1000 | Loss: 0.00002964
Iteration 191/1000 | Loss: 0.00002713
Iteration 192/1000 | Loss: 0.00002521
Iteration 193/1000 | Loss: 0.00002420
Iteration 194/1000 | Loss: 0.00026709
Iteration 195/1000 | Loss: 0.00034314
Iteration 196/1000 | Loss: 0.00032382
Iteration 197/1000 | Loss: 0.00034886
Iteration 198/1000 | Loss: 0.00003501
Iteration 199/1000 | Loss: 0.00002622
Iteration 200/1000 | Loss: 0.00002340
Iteration 201/1000 | Loss: 0.00002136
Iteration 202/1000 | Loss: 0.00002025
Iteration 203/1000 | Loss: 0.00001956
Iteration 204/1000 | Loss: 0.00001882
Iteration 205/1000 | Loss: 0.00001849
Iteration 206/1000 | Loss: 0.00001816
Iteration 207/1000 | Loss: 0.00001796
Iteration 208/1000 | Loss: 0.00001791
Iteration 209/1000 | Loss: 0.00001789
Iteration 210/1000 | Loss: 0.00001788
Iteration 211/1000 | Loss: 0.00001787
Iteration 212/1000 | Loss: 0.00001783
Iteration 213/1000 | Loss: 0.00001783
Iteration 214/1000 | Loss: 0.00001777
Iteration 215/1000 | Loss: 0.00001775
Iteration 216/1000 | Loss: 0.00001775
Iteration 217/1000 | Loss: 0.00001773
Iteration 218/1000 | Loss: 0.00001768
Iteration 219/1000 | Loss: 0.00001766
Iteration 220/1000 | Loss: 0.00001765
Iteration 221/1000 | Loss: 0.00001765
Iteration 222/1000 | Loss: 0.00001764
Iteration 223/1000 | Loss: 0.00001763
Iteration 224/1000 | Loss: 0.00001763
Iteration 225/1000 | Loss: 0.00001763
Iteration 226/1000 | Loss: 0.00001762
Iteration 227/1000 | Loss: 0.00001762
Iteration 228/1000 | Loss: 0.00001762
Iteration 229/1000 | Loss: 0.00001761
Iteration 230/1000 | Loss: 0.00001761
Iteration 231/1000 | Loss: 0.00001761
Iteration 232/1000 | Loss: 0.00001760
Iteration 233/1000 | Loss: 0.00001760
Iteration 234/1000 | Loss: 0.00001760
Iteration 235/1000 | Loss: 0.00001759
Iteration 236/1000 | Loss: 0.00001759
Iteration 237/1000 | Loss: 0.00001759
Iteration 238/1000 | Loss: 0.00001758
Iteration 239/1000 | Loss: 0.00001758
Iteration 240/1000 | Loss: 0.00001758
Iteration 241/1000 | Loss: 0.00001758
Iteration 242/1000 | Loss: 0.00001758
Iteration 243/1000 | Loss: 0.00001758
Iteration 244/1000 | Loss: 0.00001758
Iteration 245/1000 | Loss: 0.00001757
Iteration 246/1000 | Loss: 0.00001757
Iteration 247/1000 | Loss: 0.00001757
Iteration 248/1000 | Loss: 0.00001757
Iteration 249/1000 | Loss: 0.00001757
Iteration 250/1000 | Loss: 0.00001757
Iteration 251/1000 | Loss: 0.00001757
Iteration 252/1000 | Loss: 0.00001756
Iteration 253/1000 | Loss: 0.00001756
Iteration 254/1000 | Loss: 0.00001756
Iteration 255/1000 | Loss: 0.00001756
Iteration 256/1000 | Loss: 0.00001755
Iteration 257/1000 | Loss: 0.00001755
Iteration 258/1000 | Loss: 0.00001755
Iteration 259/1000 | Loss: 0.00001755
Iteration 260/1000 | Loss: 0.00001754
Iteration 261/1000 | Loss: 0.00001754
Iteration 262/1000 | Loss: 0.00001754
Iteration 263/1000 | Loss: 0.00001754
Iteration 264/1000 | Loss: 0.00001754
Iteration 265/1000 | Loss: 0.00022529
Iteration 266/1000 | Loss: 0.00002242
Iteration 267/1000 | Loss: 0.00002013
Iteration 268/1000 | Loss: 0.00001912
Iteration 269/1000 | Loss: 0.00026192
Iteration 270/1000 | Loss: 0.00058898
Iteration 271/1000 | Loss: 0.00023027
Iteration 272/1000 | Loss: 0.00025016
Iteration 273/1000 | Loss: 0.00021645
Iteration 274/1000 | Loss: 0.00023824
Iteration 275/1000 | Loss: 0.00020831
Iteration 276/1000 | Loss: 0.00023068
Iteration 277/1000 | Loss: 0.00011843
Iteration 278/1000 | Loss: 0.00012597
Iteration 279/1000 | Loss: 0.00025244
Iteration 280/1000 | Loss: 0.00019792
Iteration 281/1000 | Loss: 0.00025014
Iteration 282/1000 | Loss: 0.00003771
Iteration 283/1000 | Loss: 0.00002834
Iteration 284/1000 | Loss: 0.00002510
Iteration 285/1000 | Loss: 0.00002206
Iteration 286/1000 | Loss: 0.00002016
Iteration 287/1000 | Loss: 0.00001929
Iteration 288/1000 | Loss: 0.00001846
Iteration 289/1000 | Loss: 0.00001781
Iteration 290/1000 | Loss: 0.00001752
Iteration 291/1000 | Loss: 0.00001726
Iteration 292/1000 | Loss: 0.00001710
Iteration 293/1000 | Loss: 0.00001700
Iteration 294/1000 | Loss: 0.00001694
Iteration 295/1000 | Loss: 0.00001694
Iteration 296/1000 | Loss: 0.00001693
Iteration 297/1000 | Loss: 0.00001693
Iteration 298/1000 | Loss: 0.00001693
Iteration 299/1000 | Loss: 0.00001693
Iteration 300/1000 | Loss: 0.00001693
Iteration 301/1000 | Loss: 0.00001693
Iteration 302/1000 | Loss: 0.00001692
Iteration 303/1000 | Loss: 0.00001691
Iteration 304/1000 | Loss: 0.00001691
Iteration 305/1000 | Loss: 0.00001691
Iteration 306/1000 | Loss: 0.00001690
Iteration 307/1000 | Loss: 0.00001690
Iteration 308/1000 | Loss: 0.00001690
Iteration 309/1000 | Loss: 0.00001690
Iteration 310/1000 | Loss: 0.00001690
Iteration 311/1000 | Loss: 0.00001690
Iteration 312/1000 | Loss: 0.00001690
Iteration 313/1000 | Loss: 0.00001690
Iteration 314/1000 | Loss: 0.00001690
Iteration 315/1000 | Loss: 0.00001690
Iteration 316/1000 | Loss: 0.00001687
Iteration 317/1000 | Loss: 0.00001687
Iteration 318/1000 | Loss: 0.00001687
Iteration 319/1000 | Loss: 0.00001687
Iteration 320/1000 | Loss: 0.00001686
Iteration 321/1000 | Loss: 0.00001686
Iteration 322/1000 | Loss: 0.00001686
Iteration 323/1000 | Loss: 0.00001686
Iteration 324/1000 | Loss: 0.00001686
Iteration 325/1000 | Loss: 0.00001686
Iteration 326/1000 | Loss: 0.00001686
Iteration 327/1000 | Loss: 0.00001684
Iteration 328/1000 | Loss: 0.00001683
Iteration 329/1000 | Loss: 0.00001683
Iteration 330/1000 | Loss: 0.00001683
Iteration 331/1000 | Loss: 0.00001683
Iteration 332/1000 | Loss: 0.00001683
Iteration 333/1000 | Loss: 0.00001683
Iteration 334/1000 | Loss: 0.00001683
Iteration 335/1000 | Loss: 0.00001683
Iteration 336/1000 | Loss: 0.00001682
Iteration 337/1000 | Loss: 0.00001682
Iteration 338/1000 | Loss: 0.00001682
Iteration 339/1000 | Loss: 0.00001682
Iteration 340/1000 | Loss: 0.00001682
Iteration 341/1000 | Loss: 0.00001682
Iteration 342/1000 | Loss: 0.00001681
Iteration 343/1000 | Loss: 0.00001681
Iteration 344/1000 | Loss: 0.00001681
Iteration 345/1000 | Loss: 0.00001681
Iteration 346/1000 | Loss: 0.00001681
Iteration 347/1000 | Loss: 0.00001680
Iteration 348/1000 | Loss: 0.00001680
Iteration 349/1000 | Loss: 0.00001680
Iteration 350/1000 | Loss: 0.00001679
Iteration 351/1000 | Loss: 0.00001679
Iteration 352/1000 | Loss: 0.00001678
Iteration 353/1000 | Loss: 0.00001678
Iteration 354/1000 | Loss: 0.00001678
Iteration 355/1000 | Loss: 0.00001678
Iteration 356/1000 | Loss: 0.00001678
Iteration 357/1000 | Loss: 0.00001677
Iteration 358/1000 | Loss: 0.00001677
Iteration 359/1000 | Loss: 0.00001677
Iteration 360/1000 | Loss: 0.00001677
Iteration 361/1000 | Loss: 0.00001677
Iteration 362/1000 | Loss: 0.00001677
Iteration 363/1000 | Loss: 0.00001677
Iteration 364/1000 | Loss: 0.00001677
Iteration 365/1000 | Loss: 0.00001677
Iteration 366/1000 | Loss: 0.00001677
Iteration 367/1000 | Loss: 0.00001677
Iteration 368/1000 | Loss: 0.00001676
Iteration 369/1000 | Loss: 0.00001675
Iteration 370/1000 | Loss: 0.00001674
Iteration 371/1000 | Loss: 0.00001673
Iteration 372/1000 | Loss: 0.00001671
Iteration 373/1000 | Loss: 0.00001671
Iteration 374/1000 | Loss: 0.00001671
Iteration 375/1000 | Loss: 0.00001671
Iteration 376/1000 | Loss: 0.00001671
Iteration 377/1000 | Loss: 0.00001671
Iteration 378/1000 | Loss: 0.00001666
Iteration 379/1000 | Loss: 0.00001666
Iteration 380/1000 | Loss: 0.00001666
Iteration 381/1000 | Loss: 0.00001666
Iteration 382/1000 | Loss: 0.00001666
Iteration 383/1000 | Loss: 0.00001666
Iteration 384/1000 | Loss: 0.00001666
Iteration 385/1000 | Loss: 0.00001665
Iteration 386/1000 | Loss: 0.00001664
Iteration 387/1000 | Loss: 0.00001663
Iteration 388/1000 | Loss: 0.00001663
Iteration 389/1000 | Loss: 0.00001660
Iteration 390/1000 | Loss: 0.00001660
Iteration 391/1000 | Loss: 0.00001659
Iteration 392/1000 | Loss: 0.00001659
Iteration 393/1000 | Loss: 0.00001659
Iteration 394/1000 | Loss: 0.00001658
Iteration 395/1000 | Loss: 0.00001658
Iteration 396/1000 | Loss: 0.00001658
Iteration 397/1000 | Loss: 0.00001658
Iteration 398/1000 | Loss: 0.00001658
Iteration 399/1000 | Loss: 0.00001658
Iteration 400/1000 | Loss: 0.00001658
Iteration 401/1000 | Loss: 0.00001656
Iteration 402/1000 | Loss: 0.00001656
Iteration 403/1000 | Loss: 0.00001654
Iteration 404/1000 | Loss: 0.00001654
Iteration 405/1000 | Loss: 0.00001654
Iteration 406/1000 | Loss: 0.00001654
Iteration 407/1000 | Loss: 0.00001654
Iteration 408/1000 | Loss: 0.00001652
Iteration 409/1000 | Loss: 0.00001645
Iteration 410/1000 | Loss: 0.00001643
Iteration 411/1000 | Loss: 0.00001642
Iteration 412/1000 | Loss: 0.00001641
Iteration 413/1000 | Loss: 0.00001639
Iteration 414/1000 | Loss: 0.00001638
Iteration 415/1000 | Loss: 0.00001637
Iteration 416/1000 | Loss: 0.00001635
Iteration 417/1000 | Loss: 0.00001634
Iteration 418/1000 | Loss: 0.00001630
Iteration 419/1000 | Loss: 0.00001627
Iteration 420/1000 | Loss: 0.00001627
Iteration 421/1000 | Loss: 0.00001626
Iteration 422/1000 | Loss: 0.00001625
Iteration 423/1000 | Loss: 0.00001622
Iteration 424/1000 | Loss: 0.00001622
Iteration 425/1000 | Loss: 0.00001622
Iteration 426/1000 | Loss: 0.00001621
Iteration 427/1000 | Loss: 0.00001618
Iteration 428/1000 | Loss: 0.00001617
Iteration 429/1000 | Loss: 0.00001617
Iteration 430/1000 | Loss: 0.00001617
Iteration 431/1000 | Loss: 0.00001616
Iteration 432/1000 | Loss: 0.00001610
Iteration 433/1000 | Loss: 0.00001606
Iteration 434/1000 | Loss: 0.00001606
Iteration 435/1000 | Loss: 0.00001606
Iteration 436/1000 | Loss: 0.00001606
Iteration 437/1000 | Loss: 0.00001606
Iteration 438/1000 | Loss: 0.00001606
Iteration 439/1000 | Loss: 0.00001606
Iteration 440/1000 | Loss: 0.00001606
Iteration 441/1000 | Loss: 0.00001605
Iteration 442/1000 | Loss: 0.00001604
Iteration 443/1000 | Loss: 0.00001604
Iteration 444/1000 | Loss: 0.00001602
Iteration 445/1000 | Loss: 0.00001601
Iteration 446/1000 | Loss: 0.00001601
Iteration 447/1000 | Loss: 0.00001601
Iteration 448/1000 | Loss: 0.00001600
Iteration 449/1000 | Loss: 0.00001599
Iteration 450/1000 | Loss: 0.00001599
Iteration 451/1000 | Loss: 0.00001598
Iteration 452/1000 | Loss: 0.00001598
Iteration 453/1000 | Loss: 0.00001598
Iteration 454/1000 | Loss: 0.00001598
Iteration 455/1000 | Loss: 0.00001598
Iteration 456/1000 | Loss: 0.00001598
Iteration 457/1000 | Loss: 0.00001598
Iteration 458/1000 | Loss: 0.00001598
Iteration 459/1000 | Loss: 0.00001598
Iteration 460/1000 | Loss: 0.00001598
Iteration 461/1000 | Loss: 0.00001598
Iteration 462/1000 | Loss: 0.00001597
Iteration 463/1000 | Loss: 0.00001596
Iteration 464/1000 | Loss: 0.00001596
Iteration 465/1000 | Loss: 0.00001595
Iteration 466/1000 | Loss: 0.00021239
Iteration 467/1000 | Loss: 0.00016200
Iteration 468/1000 | Loss: 0.00012781
Iteration 469/1000 | Loss: 0.00017972
Iteration 470/1000 | Loss: 0.00008139
Iteration 471/1000 | Loss: 0.00051619
Iteration 472/1000 | Loss: 0.00002624
Iteration 473/1000 | Loss: 0.00005161
Iteration 474/1000 | Loss: 0.00029874
Iteration 475/1000 | Loss: 0.00003276
Iteration 476/1000 | Loss: 0.00018756
Iteration 477/1000 | Loss: 0.00002931
Iteration 478/1000 | Loss: 0.00002370
Iteration 479/1000 | Loss: 0.00002198
Iteration 480/1000 | Loss: 0.00032312
Iteration 481/1000 | Loss: 0.00005026
Iteration 482/1000 | Loss: 0.00003014
Iteration 483/1000 | Loss: 0.00002348
Iteration 484/1000 | Loss: 0.00055390
Iteration 485/1000 | Loss: 0.00002198
Iteration 486/1000 | Loss: 0.00001931
Iteration 487/1000 | Loss: 0.00001767
Iteration 488/1000 | Loss: 0.00031521
Iteration 489/1000 | Loss: 0.00018984
Iteration 490/1000 | Loss: 0.00002702
Iteration 491/1000 | Loss: 0.00001965
Iteration 492/1000 | Loss: 0.00001784
Iteration 493/1000 | Loss: 0.00034457
Iteration 494/1000 | Loss: 0.00024355
Iteration 495/1000 | Loss: 0.00002396
Iteration 496/1000 | Loss: 0.00001708
Iteration 497/1000 | Loss: 0.00001600
Iteration 498/1000 | Loss: 0.00001539
Iteration 499/1000 | Loss: 0.00001509
Iteration 500/1000 | Loss: 0.00001481
Iteration 501/1000 | Loss: 0.00001463
Iteration 502/1000 | Loss: 0.00001457
Iteration 503/1000 | Loss: 0.00001457
Iteration 504/1000 | Loss: 0.00001456
Iteration 505/1000 | Loss: 0.00001455
Iteration 506/1000 | Loss: 0.00001449
Iteration 507/1000 | Loss: 0.00001448
Iteration 508/1000 | Loss: 0.00001448
Iteration 509/1000 | Loss: 0.00001444
Iteration 510/1000 | Loss: 0.00001444
Iteration 511/1000 | Loss: 0.00001444
Iteration 512/1000 | Loss: 0.00001444
Iteration 513/1000 | Loss: 0.00001444
Iteration 514/1000 | Loss: 0.00001443
Iteration 515/1000 | Loss: 0.00001442
Iteration 516/1000 | Loss: 0.00001440
Iteration 517/1000 | Loss: 0.00001440
Iteration 518/1000 | Loss: 0.00001439
Iteration 519/1000 | Loss: 0.00001439
Iteration 520/1000 | Loss: 0.00001439
Iteration 521/1000 | Loss: 0.00001439
Iteration 522/1000 | Loss: 0.00001439
Iteration 523/1000 | Loss: 0.00001438
Iteration 524/1000 | Loss: 0.00001438
Iteration 525/1000 | Loss: 0.00001438
Iteration 526/1000 | Loss: 0.00001438
Iteration 527/1000 | Loss: 0.00001438
Iteration 528/1000 | Loss: 0.00001437
Iteration 529/1000 | Loss: 0.00001437
Iteration 530/1000 | Loss: 0.00001437
Iteration 531/1000 | Loss: 0.00001437
Iteration 532/1000 | Loss: 0.00001437
Iteration 533/1000 | Loss: 0.00001437
Iteration 534/1000 | Loss: 0.00001437
Iteration 535/1000 | Loss: 0.00001437
Iteration 536/1000 | Loss: 0.00001437
Iteration 537/1000 | Loss: 0.00001437
Iteration 538/1000 | Loss: 0.00001437
Iteration 539/1000 | Loss: 0.00001437
Iteration 540/1000 | Loss: 0.00001437
Iteration 541/1000 | Loss: 0.00001437
Iteration 542/1000 | Loss: 0.00001437
Iteration 543/1000 | Loss: 0.00001437
Iteration 544/1000 | Loss: 0.00001437
Iteration 545/1000 | Loss: 0.00001437
Iteration 546/1000 | Loss: 0.00001437
Iteration 547/1000 | Loss: 0.00001437
Iteration 548/1000 | Loss: 0.00001437
Iteration 549/1000 | Loss: 0.00001436
Iteration 550/1000 | Loss: 0.00001436
Iteration 551/1000 | Loss: 0.00001436
Iteration 552/1000 | Loss: 0.00001436
Iteration 553/1000 | Loss: 0.00001436
Iteration 554/1000 | Loss: 0.00001436
Iteration 555/1000 | Loss: 0.00001436
Iteration 556/1000 | Loss: 0.00001436
Iteration 557/1000 | Loss: 0.00001436
Iteration 558/1000 | Loss: 0.00001436
Iteration 559/1000 | Loss: 0.00001436
Iteration 560/1000 | Loss: 0.00001436
Iteration 561/1000 | Loss: 0.00001436
Iteration 562/1000 | Loss: 0.00001436
Iteration 563/1000 | Loss: 0.00001436
Iteration 564/1000 | Loss: 0.00001436
Iteration 565/1000 | Loss: 0.00001436
Iteration 566/1000 | Loss: 0.00001436
Iteration 567/1000 | Loss: 0.00001436
Iteration 568/1000 | Loss: 0.00001436
Iteration 569/1000 | Loss: 0.00001436
Iteration 570/1000 | Loss: 0.00001436
Iteration 571/1000 | Loss: 0.00001436
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 571. Stopping optimization.
Last 5 losses: [1.4363736227096524e-05, 1.4363736227096524e-05, 1.4363736227096524e-05, 1.4363736227096524e-05, 1.4363736227096524e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4363736227096524e-05

Optimization complete. Final v2v error: 3.21598744392395 mm

Highest mean error: 4.989475250244141 mm for frame 189

Lowest mean error: 3.066037654876709 mm for frame 36

Saving results

Total time: 489.1443519592285
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00405732
Iteration 2/25 | Loss: 0.00090933
Iteration 3/25 | Loss: 0.00081078
Iteration 4/25 | Loss: 0.00078941
Iteration 5/25 | Loss: 0.00078295
Iteration 6/25 | Loss: 0.00078150
Iteration 7/25 | Loss: 0.00078141
Iteration 8/25 | Loss: 0.00078141
Iteration 9/25 | Loss: 0.00078141
Iteration 10/25 | Loss: 0.00078141
Iteration 11/25 | Loss: 0.00078141
Iteration 12/25 | Loss: 0.00078141
Iteration 13/25 | Loss: 0.00078141
Iteration 14/25 | Loss: 0.00078141
Iteration 15/25 | Loss: 0.00078141
Iteration 16/25 | Loss: 0.00078141
Iteration 17/25 | Loss: 0.00078141
Iteration 18/25 | Loss: 0.00078141
Iteration 19/25 | Loss: 0.00078141
Iteration 20/25 | Loss: 0.00078141
Iteration 21/25 | Loss: 0.00078141
Iteration 22/25 | Loss: 0.00078141
Iteration 23/25 | Loss: 0.00078141
Iteration 24/25 | Loss: 0.00078141
Iteration 25/25 | Loss: 0.00078141

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.46371698
Iteration 2/25 | Loss: 0.00046163
Iteration 3/25 | Loss: 0.00046161
Iteration 4/25 | Loss: 0.00046161
Iteration 5/25 | Loss: 0.00046161
Iteration 6/25 | Loss: 0.00046161
Iteration 7/25 | Loss: 0.00046161
Iteration 8/25 | Loss: 0.00046161
Iteration 9/25 | Loss: 0.00046161
Iteration 10/25 | Loss: 0.00046161
Iteration 11/25 | Loss: 0.00046161
Iteration 12/25 | Loss: 0.00046161
Iteration 13/25 | Loss: 0.00046161
Iteration 14/25 | Loss: 0.00046161
Iteration 15/25 | Loss: 0.00046161
Iteration 16/25 | Loss: 0.00046161
Iteration 17/25 | Loss: 0.00046161
Iteration 18/25 | Loss: 0.00046161
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.00046160773490555584, 0.00046160773490555584, 0.00046160773490555584, 0.00046160773490555584, 0.00046160773490555584]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00046160773490555584

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046161
Iteration 2/1000 | Loss: 0.00003084
Iteration 3/1000 | Loss: 0.00002479
Iteration 4/1000 | Loss: 0.00002355
Iteration 5/1000 | Loss: 0.00002250
Iteration 6/1000 | Loss: 0.00002217
Iteration 7/1000 | Loss: 0.00002170
Iteration 8/1000 | Loss: 0.00002147
Iteration 9/1000 | Loss: 0.00002121
Iteration 10/1000 | Loss: 0.00002120
Iteration 11/1000 | Loss: 0.00002109
Iteration 12/1000 | Loss: 0.00002109
Iteration 13/1000 | Loss: 0.00002094
Iteration 14/1000 | Loss: 0.00002094
Iteration 15/1000 | Loss: 0.00002084
Iteration 16/1000 | Loss: 0.00002083
Iteration 17/1000 | Loss: 0.00002083
Iteration 18/1000 | Loss: 0.00002082
Iteration 19/1000 | Loss: 0.00002080
Iteration 20/1000 | Loss: 0.00002078
Iteration 21/1000 | Loss: 0.00002077
Iteration 22/1000 | Loss: 0.00002077
Iteration 23/1000 | Loss: 0.00002077
Iteration 24/1000 | Loss: 0.00002076
Iteration 25/1000 | Loss: 0.00002076
Iteration 26/1000 | Loss: 0.00002075
Iteration 27/1000 | Loss: 0.00002072
Iteration 28/1000 | Loss: 0.00002071
Iteration 29/1000 | Loss: 0.00002071
Iteration 30/1000 | Loss: 0.00002071
Iteration 31/1000 | Loss: 0.00002070
Iteration 32/1000 | Loss: 0.00002070
Iteration 33/1000 | Loss: 0.00002070
Iteration 34/1000 | Loss: 0.00002067
Iteration 35/1000 | Loss: 0.00002066
Iteration 36/1000 | Loss: 0.00002066
Iteration 37/1000 | Loss: 0.00002066
Iteration 38/1000 | Loss: 0.00002065
Iteration 39/1000 | Loss: 0.00002065
Iteration 40/1000 | Loss: 0.00002063
Iteration 41/1000 | Loss: 0.00002062
Iteration 42/1000 | Loss: 0.00002061
Iteration 43/1000 | Loss: 0.00002061
Iteration 44/1000 | Loss: 0.00002060
Iteration 45/1000 | Loss: 0.00002058
Iteration 46/1000 | Loss: 0.00002057
Iteration 47/1000 | Loss: 0.00002053
Iteration 48/1000 | Loss: 0.00002049
Iteration 49/1000 | Loss: 0.00002049
Iteration 50/1000 | Loss: 0.00002048
Iteration 51/1000 | Loss: 0.00002048
Iteration 52/1000 | Loss: 0.00002047
Iteration 53/1000 | Loss: 0.00002047
Iteration 54/1000 | Loss: 0.00002045
Iteration 55/1000 | Loss: 0.00002045
Iteration 56/1000 | Loss: 0.00002045
Iteration 57/1000 | Loss: 0.00002044
Iteration 58/1000 | Loss: 0.00002044
Iteration 59/1000 | Loss: 0.00002043
Iteration 60/1000 | Loss: 0.00002043
Iteration 61/1000 | Loss: 0.00002043
Iteration 62/1000 | Loss: 0.00002042
Iteration 63/1000 | Loss: 0.00002042
Iteration 64/1000 | Loss: 0.00002042
Iteration 65/1000 | Loss: 0.00002042
Iteration 66/1000 | Loss: 0.00002041
Iteration 67/1000 | Loss: 0.00002041
Iteration 68/1000 | Loss: 0.00002041
Iteration 69/1000 | Loss: 0.00002040
Iteration 70/1000 | Loss: 0.00002040
Iteration 71/1000 | Loss: 0.00002040
Iteration 72/1000 | Loss: 0.00002039
Iteration 73/1000 | Loss: 0.00002039
Iteration 74/1000 | Loss: 0.00002039
Iteration 75/1000 | Loss: 0.00002039
Iteration 76/1000 | Loss: 0.00002039
Iteration 77/1000 | Loss: 0.00002039
Iteration 78/1000 | Loss: 0.00002038
Iteration 79/1000 | Loss: 0.00002038
Iteration 80/1000 | Loss: 0.00002038
Iteration 81/1000 | Loss: 0.00002038
Iteration 82/1000 | Loss: 0.00002038
Iteration 83/1000 | Loss: 0.00002038
Iteration 84/1000 | Loss: 0.00002038
Iteration 85/1000 | Loss: 0.00002038
Iteration 86/1000 | Loss: 0.00002038
Iteration 87/1000 | Loss: 0.00002038
Iteration 88/1000 | Loss: 0.00002038
Iteration 89/1000 | Loss: 0.00002038
Iteration 90/1000 | Loss: 0.00002038
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 90. Stopping optimization.
Last 5 losses: [2.0382369257276878e-05, 2.0382369257276878e-05, 2.0382369257276878e-05, 2.0382369257276878e-05, 2.0382369257276878e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0382369257276878e-05

Optimization complete. Final v2v error: 3.7199556827545166 mm

Highest mean error: 4.333033561706543 mm for frame 89

Lowest mean error: 3.3479461669921875 mm for frame 68

Saving results

Total time: 35.05881953239441
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1090/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1090.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1090
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00438216
Iteration 2/25 | Loss: 0.00089320
Iteration 3/25 | Loss: 0.00078354
Iteration 4/25 | Loss: 0.00075447
Iteration 5/25 | Loss: 0.00075095
Iteration 6/25 | Loss: 0.00075034
Iteration 7/25 | Loss: 0.00075034
Iteration 8/25 | Loss: 0.00075034
Iteration 9/25 | Loss: 0.00075034
Iteration 10/25 | Loss: 0.00075034
Iteration 11/25 | Loss: 0.00075034
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.000750342442188412, 0.000750342442188412, 0.000750342442188412, 0.000750342442188412, 0.000750342442188412]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000750342442188412

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64605689
Iteration 2/25 | Loss: 0.00044034
Iteration 3/25 | Loss: 0.00044034
Iteration 4/25 | Loss: 0.00044034
Iteration 5/25 | Loss: 0.00044034
Iteration 6/25 | Loss: 0.00044034
Iteration 7/25 | Loss: 0.00044034
Iteration 8/25 | Loss: 0.00044034
Iteration 9/25 | Loss: 0.00044034
Iteration 10/25 | Loss: 0.00044034
Iteration 11/25 | Loss: 0.00044034
Iteration 12/25 | Loss: 0.00044034
Iteration 13/25 | Loss: 0.00044034
Iteration 14/25 | Loss: 0.00044034
Iteration 15/25 | Loss: 0.00044034
Iteration 16/25 | Loss: 0.00044034
Iteration 17/25 | Loss: 0.00044034
Iteration 18/25 | Loss: 0.00044034
Iteration 19/25 | Loss: 0.00044034
Iteration 20/25 | Loss: 0.00044034
Iteration 21/25 | Loss: 0.00044034
Iteration 22/25 | Loss: 0.00044034
Iteration 23/25 | Loss: 0.00044034
Iteration 24/25 | Loss: 0.00044034
Iteration 25/25 | Loss: 0.00044034

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044034
Iteration 2/1000 | Loss: 0.00003288
Iteration 3/1000 | Loss: 0.00002010
Iteration 4/1000 | Loss: 0.00001839
Iteration 5/1000 | Loss: 0.00001724
Iteration 6/1000 | Loss: 0.00001676
Iteration 7/1000 | Loss: 0.00001637
Iteration 8/1000 | Loss: 0.00001612
Iteration 9/1000 | Loss: 0.00001602
Iteration 10/1000 | Loss: 0.00001594
Iteration 11/1000 | Loss: 0.00001579
Iteration 12/1000 | Loss: 0.00001576
Iteration 13/1000 | Loss: 0.00001576
Iteration 14/1000 | Loss: 0.00001571
Iteration 15/1000 | Loss: 0.00001570
Iteration 16/1000 | Loss: 0.00001570
Iteration 17/1000 | Loss: 0.00001570
Iteration 18/1000 | Loss: 0.00001569
Iteration 19/1000 | Loss: 0.00001569
Iteration 20/1000 | Loss: 0.00001569
Iteration 21/1000 | Loss: 0.00001564
Iteration 22/1000 | Loss: 0.00001563
Iteration 23/1000 | Loss: 0.00001561
Iteration 24/1000 | Loss: 0.00001560
Iteration 25/1000 | Loss: 0.00001560
Iteration 26/1000 | Loss: 0.00001560
Iteration 27/1000 | Loss: 0.00001559
Iteration 28/1000 | Loss: 0.00001559
Iteration 29/1000 | Loss: 0.00001559
Iteration 30/1000 | Loss: 0.00001555
Iteration 31/1000 | Loss: 0.00001555
Iteration 32/1000 | Loss: 0.00001555
Iteration 33/1000 | Loss: 0.00001555
Iteration 34/1000 | Loss: 0.00001555
Iteration 35/1000 | Loss: 0.00001555
Iteration 36/1000 | Loss: 0.00001555
Iteration 37/1000 | Loss: 0.00001555
Iteration 38/1000 | Loss: 0.00001555
Iteration 39/1000 | Loss: 0.00001554
Iteration 40/1000 | Loss: 0.00001554
Iteration 41/1000 | Loss: 0.00001554
Iteration 42/1000 | Loss: 0.00001554
Iteration 43/1000 | Loss: 0.00001553
Iteration 44/1000 | Loss: 0.00001553
Iteration 45/1000 | Loss: 0.00001553
Iteration 46/1000 | Loss: 0.00001552
Iteration 47/1000 | Loss: 0.00001552
Iteration 48/1000 | Loss: 0.00001552
Iteration 49/1000 | Loss: 0.00001551
Iteration 50/1000 | Loss: 0.00001551
Iteration 51/1000 | Loss: 0.00001551
Iteration 52/1000 | Loss: 0.00001551
Iteration 53/1000 | Loss: 0.00001550
Iteration 54/1000 | Loss: 0.00001549
Iteration 55/1000 | Loss: 0.00001549
Iteration 56/1000 | Loss: 0.00001548
Iteration 57/1000 | Loss: 0.00001548
Iteration 58/1000 | Loss: 0.00001548
Iteration 59/1000 | Loss: 0.00001547
Iteration 60/1000 | Loss: 0.00001546
Iteration 61/1000 | Loss: 0.00001546
Iteration 62/1000 | Loss: 0.00001546
Iteration 63/1000 | Loss: 0.00001546
Iteration 64/1000 | Loss: 0.00001546
Iteration 65/1000 | Loss: 0.00001545
Iteration 66/1000 | Loss: 0.00001544
Iteration 67/1000 | Loss: 0.00001544
Iteration 68/1000 | Loss: 0.00001544
Iteration 69/1000 | Loss: 0.00001544
Iteration 70/1000 | Loss: 0.00001544
Iteration 71/1000 | Loss: 0.00001543
Iteration 72/1000 | Loss: 0.00001542
Iteration 73/1000 | Loss: 0.00001542
Iteration 74/1000 | Loss: 0.00001540
Iteration 75/1000 | Loss: 0.00001539
Iteration 76/1000 | Loss: 0.00001539
Iteration 77/1000 | Loss: 0.00001539
Iteration 78/1000 | Loss: 0.00001539
Iteration 79/1000 | Loss: 0.00001539
Iteration 80/1000 | Loss: 0.00001539
Iteration 81/1000 | Loss: 0.00001538
Iteration 82/1000 | Loss: 0.00001537
Iteration 83/1000 | Loss: 0.00001537
Iteration 84/1000 | Loss: 0.00001537
Iteration 85/1000 | Loss: 0.00001537
Iteration 86/1000 | Loss: 0.00001536
Iteration 87/1000 | Loss: 0.00001536
Iteration 88/1000 | Loss: 0.00001536
Iteration 89/1000 | Loss: 0.00001535
Iteration 90/1000 | Loss: 0.00001535
Iteration 91/1000 | Loss: 0.00001535
Iteration 92/1000 | Loss: 0.00001535
Iteration 93/1000 | Loss: 0.00001535
Iteration 94/1000 | Loss: 0.00001534
Iteration 95/1000 | Loss: 0.00001534
Iteration 96/1000 | Loss: 0.00001534
Iteration 97/1000 | Loss: 0.00001534
Iteration 98/1000 | Loss: 0.00001533
Iteration 99/1000 | Loss: 0.00001533
Iteration 100/1000 | Loss: 0.00001533
Iteration 101/1000 | Loss: 0.00001532
Iteration 102/1000 | Loss: 0.00001532
Iteration 103/1000 | Loss: 0.00001532
Iteration 104/1000 | Loss: 0.00001532
Iteration 105/1000 | Loss: 0.00001531
Iteration 106/1000 | Loss: 0.00001531
Iteration 107/1000 | Loss: 0.00001531
Iteration 108/1000 | Loss: 0.00001531
Iteration 109/1000 | Loss: 0.00001531
Iteration 110/1000 | Loss: 0.00001531
Iteration 111/1000 | Loss: 0.00001531
Iteration 112/1000 | Loss: 0.00001531
Iteration 113/1000 | Loss: 0.00001531
Iteration 114/1000 | Loss: 0.00001531
Iteration 115/1000 | Loss: 0.00001531
Iteration 116/1000 | Loss: 0.00001531
Iteration 117/1000 | Loss: 0.00001531
Iteration 118/1000 | Loss: 0.00001530
Iteration 119/1000 | Loss: 0.00001530
Iteration 120/1000 | Loss: 0.00001530
Iteration 121/1000 | Loss: 0.00001530
Iteration 122/1000 | Loss: 0.00001530
Iteration 123/1000 | Loss: 0.00001530
Iteration 124/1000 | Loss: 0.00001530
Iteration 125/1000 | Loss: 0.00001530
Iteration 126/1000 | Loss: 0.00001530
Iteration 127/1000 | Loss: 0.00001530
Iteration 128/1000 | Loss: 0.00001529
Iteration 129/1000 | Loss: 0.00001529
Iteration 130/1000 | Loss: 0.00001529
Iteration 131/1000 | Loss: 0.00001529
Iteration 132/1000 | Loss: 0.00001529
Iteration 133/1000 | Loss: 0.00001529
Iteration 134/1000 | Loss: 0.00001528
Iteration 135/1000 | Loss: 0.00001528
Iteration 136/1000 | Loss: 0.00001528
Iteration 137/1000 | Loss: 0.00001528
Iteration 138/1000 | Loss: 0.00001528
Iteration 139/1000 | Loss: 0.00001528
Iteration 140/1000 | Loss: 0.00001528
Iteration 141/1000 | Loss: 0.00001528
Iteration 142/1000 | Loss: 0.00001528
Iteration 143/1000 | Loss: 0.00001528
Iteration 144/1000 | Loss: 0.00001528
Iteration 145/1000 | Loss: 0.00001528
Iteration 146/1000 | Loss: 0.00001528
Iteration 147/1000 | Loss: 0.00001528
Iteration 148/1000 | Loss: 0.00001527
Iteration 149/1000 | Loss: 0.00001527
Iteration 150/1000 | Loss: 0.00001527
Iteration 151/1000 | Loss: 0.00001527
Iteration 152/1000 | Loss: 0.00001527
Iteration 153/1000 | Loss: 0.00001527
Iteration 154/1000 | Loss: 0.00001527
Iteration 155/1000 | Loss: 0.00001527
Iteration 156/1000 | Loss: 0.00001526
Iteration 157/1000 | Loss: 0.00001526
Iteration 158/1000 | Loss: 0.00001526
Iteration 159/1000 | Loss: 0.00001526
Iteration 160/1000 | Loss: 0.00001526
Iteration 161/1000 | Loss: 0.00001526
Iteration 162/1000 | Loss: 0.00001526
Iteration 163/1000 | Loss: 0.00001526
Iteration 164/1000 | Loss: 0.00001526
Iteration 165/1000 | Loss: 0.00001526
Iteration 166/1000 | Loss: 0.00001526
Iteration 167/1000 | Loss: 0.00001526
Iteration 168/1000 | Loss: 0.00001526
Iteration 169/1000 | Loss: 0.00001525
Iteration 170/1000 | Loss: 0.00001525
Iteration 171/1000 | Loss: 0.00001525
Iteration 172/1000 | Loss: 0.00001525
Iteration 173/1000 | Loss: 0.00001525
Iteration 174/1000 | Loss: 0.00001525
Iteration 175/1000 | Loss: 0.00001525
Iteration 176/1000 | Loss: 0.00001525
Iteration 177/1000 | Loss: 0.00001525
Iteration 178/1000 | Loss: 0.00001525
Iteration 179/1000 | Loss: 0.00001525
Iteration 180/1000 | Loss: 0.00001525
Iteration 181/1000 | Loss: 0.00001525
Iteration 182/1000 | Loss: 0.00001525
Iteration 183/1000 | Loss: 0.00001525
Iteration 184/1000 | Loss: 0.00001525
Iteration 185/1000 | Loss: 0.00001525
Iteration 186/1000 | Loss: 0.00001525
Iteration 187/1000 | Loss: 0.00001525
Iteration 188/1000 | Loss: 0.00001525
Iteration 189/1000 | Loss: 0.00001524
Iteration 190/1000 | Loss: 0.00001524
Iteration 191/1000 | Loss: 0.00001524
Iteration 192/1000 | Loss: 0.00001524
Iteration 193/1000 | Loss: 0.00001524
Iteration 194/1000 | Loss: 0.00001524
Iteration 195/1000 | Loss: 0.00001524
Iteration 196/1000 | Loss: 0.00001524
Iteration 197/1000 | Loss: 0.00001524
Iteration 198/1000 | Loss: 0.00001524
Iteration 199/1000 | Loss: 0.00001524
Iteration 200/1000 | Loss: 0.00001524
Iteration 201/1000 | Loss: 0.00001524
Iteration 202/1000 | Loss: 0.00001524
Iteration 203/1000 | Loss: 0.00001524
Iteration 204/1000 | Loss: 0.00001524
Iteration 205/1000 | Loss: 0.00001524
Iteration 206/1000 | Loss: 0.00001524
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 206. Stopping optimization.
Last 5 losses: [1.524480012449203e-05, 1.524480012449203e-05, 1.524480012449203e-05, 1.524480012449203e-05, 1.524480012449203e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.524480012449203e-05

Optimization complete. Final v2v error: 3.323870897293091 mm

Highest mean error: 3.8316657543182373 mm for frame 113

Lowest mean error: 3.1800594329833984 mm for frame 89

Saving results

Total time: 38.76383399963379
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00989483
Iteration 2/25 | Loss: 0.00498963
Iteration 3/25 | Loss: 0.00352731
Iteration 4/25 | Loss: 0.00277415
Iteration 5/25 | Loss: 0.00228193
Iteration 6/25 | Loss: 0.00203614
Iteration 7/25 | Loss: 0.00188693
Iteration 8/25 | Loss: 0.00178739
Iteration 9/25 | Loss: 0.00180286
Iteration 10/25 | Loss: 0.00170375
Iteration 11/25 | Loss: 0.00158549
Iteration 12/25 | Loss: 0.00151620
Iteration 13/25 | Loss: 0.00147354
Iteration 14/25 | Loss: 0.00146123
Iteration 15/25 | Loss: 0.00143971
Iteration 16/25 | Loss: 0.00143856
Iteration 17/25 | Loss: 0.00142921
Iteration 18/25 | Loss: 0.00142597
Iteration 19/25 | Loss: 0.00141691
Iteration 20/25 | Loss: 0.00140667
Iteration 21/25 | Loss: 0.00139954
Iteration 22/25 | Loss: 0.00139363
Iteration 23/25 | Loss: 0.00140034
Iteration 24/25 | Loss: 0.00139492
Iteration 25/25 | Loss: 0.00138715

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48950624
Iteration 2/25 | Loss: 0.00677869
Iteration 3/25 | Loss: 0.00660083
Iteration 4/25 | Loss: 0.00660083
Iteration 5/25 | Loss: 0.00660083
Iteration 6/25 | Loss: 0.00660083
Iteration 7/25 | Loss: 0.00660083
Iteration 8/25 | Loss: 0.00660083
Iteration 9/25 | Loss: 0.00660083
Iteration 10/25 | Loss: 0.00660083
Iteration 11/25 | Loss: 0.00660083
Iteration 12/25 | Loss: 0.00660083
Iteration 13/25 | Loss: 0.00660083
Iteration 14/25 | Loss: 0.00660083
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.006600826513022184, 0.006600826513022184, 0.006600826513022184, 0.006600826513022184, 0.006600826513022184]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.006600826513022184

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00660083
Iteration 2/1000 | Loss: 0.00245627
Iteration 3/1000 | Loss: 0.00170896
Iteration 4/1000 | Loss: 0.00131627
Iteration 5/1000 | Loss: 0.00067252
Iteration 6/1000 | Loss: 0.00049762
Iteration 7/1000 | Loss: 0.00050492
Iteration 8/1000 | Loss: 0.00039889
Iteration 9/1000 | Loss: 0.00033583
Iteration 10/1000 | Loss: 0.00028433
Iteration 11/1000 | Loss: 0.00043328
Iteration 12/1000 | Loss: 0.00027451
Iteration 13/1000 | Loss: 0.00024923
Iteration 14/1000 | Loss: 0.00024069
Iteration 15/1000 | Loss: 0.00022849
Iteration 16/1000 | Loss: 0.00020848
Iteration 17/1000 | Loss: 0.00140115
Iteration 18/1000 | Loss: 0.00420235
Iteration 19/1000 | Loss: 0.00999845
Iteration 20/1000 | Loss: 0.00121325
Iteration 21/1000 | Loss: 0.00038776
Iteration 22/1000 | Loss: 0.00022690
Iteration 23/1000 | Loss: 0.00023014
Iteration 24/1000 | Loss: 0.00038463
Iteration 25/1000 | Loss: 0.00012939
Iteration 26/1000 | Loss: 0.00012658
Iteration 27/1000 | Loss: 0.00010062
Iteration 28/1000 | Loss: 0.00009267
Iteration 29/1000 | Loss: 0.00008766
Iteration 30/1000 | Loss: 0.00008326
Iteration 31/1000 | Loss: 0.00008030
Iteration 32/1000 | Loss: 0.00007855
Iteration 33/1000 | Loss: 0.00007707
Iteration 34/1000 | Loss: 0.00007585
Iteration 35/1000 | Loss: 0.00028214
Iteration 36/1000 | Loss: 0.00007648
Iteration 37/1000 | Loss: 0.00007424
Iteration 38/1000 | Loss: 0.00007252
Iteration 39/1000 | Loss: 0.00007160
Iteration 40/1000 | Loss: 0.00007088
Iteration 41/1000 | Loss: 0.00007056
Iteration 42/1000 | Loss: 0.00007027
Iteration 43/1000 | Loss: 0.00007002
Iteration 44/1000 | Loss: 0.00022906
Iteration 45/1000 | Loss: 0.00019221
Iteration 46/1000 | Loss: 0.00007394
Iteration 47/1000 | Loss: 0.00007080
Iteration 48/1000 | Loss: 0.00006889
Iteration 49/1000 | Loss: 0.00006755
Iteration 50/1000 | Loss: 0.00006649
Iteration 51/1000 | Loss: 0.00006606
Iteration 52/1000 | Loss: 0.00006578
Iteration 53/1000 | Loss: 0.00033258
Iteration 54/1000 | Loss: 0.00006752
Iteration 55/1000 | Loss: 0.00006566
Iteration 56/1000 | Loss: 0.00006472
Iteration 57/1000 | Loss: 0.00006377
Iteration 58/1000 | Loss: 0.00006323
Iteration 59/1000 | Loss: 0.00073738
Iteration 60/1000 | Loss: 0.00032484
Iteration 61/1000 | Loss: 0.00006442
Iteration 62/1000 | Loss: 0.00006309
Iteration 63/1000 | Loss: 0.00006282
Iteration 64/1000 | Loss: 0.00071749
Iteration 65/1000 | Loss: 0.00025500
Iteration 66/1000 | Loss: 0.00009012
Iteration 67/1000 | Loss: 0.00017608
Iteration 68/1000 | Loss: 0.00006926
Iteration 69/1000 | Loss: 0.00009561
Iteration 70/1000 | Loss: 0.00088383
Iteration 71/1000 | Loss: 0.00104987
Iteration 72/1000 | Loss: 0.00020833
Iteration 73/1000 | Loss: 0.00019602
Iteration 74/1000 | Loss: 0.00018029
Iteration 75/1000 | Loss: 0.00018497
Iteration 76/1000 | Loss: 0.00017481
Iteration 77/1000 | Loss: 0.00007394
Iteration 78/1000 | Loss: 0.00006880
Iteration 79/1000 | Loss: 0.00006425
Iteration 80/1000 | Loss: 0.00006196
Iteration 81/1000 | Loss: 0.00005983
Iteration 82/1000 | Loss: 0.00072015
Iteration 83/1000 | Loss: 0.00032274
Iteration 84/1000 | Loss: 0.00030856
Iteration 85/1000 | Loss: 0.00025800
Iteration 86/1000 | Loss: 0.00006027
Iteration 87/1000 | Loss: 0.00005752
Iteration 88/1000 | Loss: 0.00005659
Iteration 89/1000 | Loss: 0.00005581
Iteration 90/1000 | Loss: 0.00005531
Iteration 91/1000 | Loss: 0.00005488
Iteration 92/1000 | Loss: 0.00005454
Iteration 93/1000 | Loss: 0.00005445
Iteration 94/1000 | Loss: 0.00072814
Iteration 95/1000 | Loss: 0.00045846
Iteration 96/1000 | Loss: 0.00007422
Iteration 97/1000 | Loss: 0.00005641
Iteration 98/1000 | Loss: 0.00005502
Iteration 99/1000 | Loss: 0.00005445
Iteration 100/1000 | Loss: 0.00005420
Iteration 101/1000 | Loss: 0.00005419
Iteration 102/1000 | Loss: 0.00005415
Iteration 103/1000 | Loss: 0.00005415
Iteration 104/1000 | Loss: 0.00005414
Iteration 105/1000 | Loss: 0.00026441
Iteration 106/1000 | Loss: 0.00203878
Iteration 107/1000 | Loss: 0.00012213
Iteration 108/1000 | Loss: 0.00006381
Iteration 109/1000 | Loss: 0.00005280
Iteration 110/1000 | Loss: 0.00004893
Iteration 111/1000 | Loss: 0.00004700
Iteration 112/1000 | Loss: 0.00004566
Iteration 113/1000 | Loss: 0.00004507
Iteration 114/1000 | Loss: 0.00004456
Iteration 115/1000 | Loss: 0.00004420
Iteration 116/1000 | Loss: 0.00004407
Iteration 117/1000 | Loss: 0.00004393
Iteration 118/1000 | Loss: 0.00004391
Iteration 119/1000 | Loss: 0.00004389
Iteration 120/1000 | Loss: 0.00004387
Iteration 121/1000 | Loss: 0.00004387
Iteration 122/1000 | Loss: 0.00004387
Iteration 123/1000 | Loss: 0.00004387
Iteration 124/1000 | Loss: 0.00004386
Iteration 125/1000 | Loss: 0.00004385
Iteration 126/1000 | Loss: 0.00004384
Iteration 127/1000 | Loss: 0.00004384
Iteration 128/1000 | Loss: 0.00004383
Iteration 129/1000 | Loss: 0.00004383
Iteration 130/1000 | Loss: 0.00004383
Iteration 131/1000 | Loss: 0.00004383
Iteration 132/1000 | Loss: 0.00004383
Iteration 133/1000 | Loss: 0.00004383
Iteration 134/1000 | Loss: 0.00004383
Iteration 135/1000 | Loss: 0.00004382
Iteration 136/1000 | Loss: 0.00004382
Iteration 137/1000 | Loss: 0.00004382
Iteration 138/1000 | Loss: 0.00004382
Iteration 139/1000 | Loss: 0.00004382
Iteration 140/1000 | Loss: 0.00004382
Iteration 141/1000 | Loss: 0.00004381
Iteration 142/1000 | Loss: 0.00004381
Iteration 143/1000 | Loss: 0.00004381
Iteration 144/1000 | Loss: 0.00004380
Iteration 145/1000 | Loss: 0.00004380
Iteration 146/1000 | Loss: 0.00004380
Iteration 147/1000 | Loss: 0.00071855
Iteration 148/1000 | Loss: 0.00028116
Iteration 149/1000 | Loss: 0.00004937
Iteration 150/1000 | Loss: 0.00004389
Iteration 151/1000 | Loss: 0.00004382
Iteration 152/1000 | Loss: 0.00004381
Iteration 153/1000 | Loss: 0.00004379
Iteration 154/1000 | Loss: 0.00004379
Iteration 155/1000 | Loss: 0.00004379
Iteration 156/1000 | Loss: 0.00004379
Iteration 157/1000 | Loss: 0.00004379
Iteration 158/1000 | Loss: 0.00004379
Iteration 159/1000 | Loss: 0.00004379
Iteration 160/1000 | Loss: 0.00004378
Iteration 161/1000 | Loss: 0.00004378
Iteration 162/1000 | Loss: 0.00004378
Iteration 163/1000 | Loss: 0.00004378
Iteration 164/1000 | Loss: 0.00004378
Iteration 165/1000 | Loss: 0.00004377
Iteration 166/1000 | Loss: 0.00004377
Iteration 167/1000 | Loss: 0.00004377
Iteration 168/1000 | Loss: 0.00004377
Iteration 169/1000 | Loss: 0.00004377
Iteration 170/1000 | Loss: 0.00004377
Iteration 171/1000 | Loss: 0.00004377
Iteration 172/1000 | Loss: 0.00004376
Iteration 173/1000 | Loss: 0.00004376
Iteration 174/1000 | Loss: 0.00004376
Iteration 175/1000 | Loss: 0.00004376
Iteration 176/1000 | Loss: 0.00004375
Iteration 177/1000 | Loss: 0.00004375
Iteration 178/1000 | Loss: 0.00004375
Iteration 179/1000 | Loss: 0.00004375
Iteration 180/1000 | Loss: 0.00004375
Iteration 181/1000 | Loss: 0.00004375
Iteration 182/1000 | Loss: 0.00004374
Iteration 183/1000 | Loss: 0.00004374
Iteration 184/1000 | Loss: 0.00004374
Iteration 185/1000 | Loss: 0.00004374
Iteration 186/1000 | Loss: 0.00004374
Iteration 187/1000 | Loss: 0.00004374
Iteration 188/1000 | Loss: 0.00004374
Iteration 189/1000 | Loss: 0.00004373
Iteration 190/1000 | Loss: 0.00004373
Iteration 191/1000 | Loss: 0.00004373
Iteration 192/1000 | Loss: 0.00004373
Iteration 193/1000 | Loss: 0.00004373
Iteration 194/1000 | Loss: 0.00004372
Iteration 195/1000 | Loss: 0.00004372
Iteration 196/1000 | Loss: 0.00004372
Iteration 197/1000 | Loss: 0.00004372
Iteration 198/1000 | Loss: 0.00004372
Iteration 199/1000 | Loss: 0.00004371
Iteration 200/1000 | Loss: 0.00004371
Iteration 201/1000 | Loss: 0.00004371
Iteration 202/1000 | Loss: 0.00004371
Iteration 203/1000 | Loss: 0.00004371
Iteration 204/1000 | Loss: 0.00004371
Iteration 205/1000 | Loss: 0.00004371
Iteration 206/1000 | Loss: 0.00004371
Iteration 207/1000 | Loss: 0.00004371
Iteration 208/1000 | Loss: 0.00004371
Iteration 209/1000 | Loss: 0.00004371
Iteration 210/1000 | Loss: 0.00004371
Iteration 211/1000 | Loss: 0.00004371
Iteration 212/1000 | Loss: 0.00004371
Iteration 213/1000 | Loss: 0.00004371
Iteration 214/1000 | Loss: 0.00004371
Iteration 215/1000 | Loss: 0.00004371
Iteration 216/1000 | Loss: 0.00004371
Iteration 217/1000 | Loss: 0.00004371
Iteration 218/1000 | Loss: 0.00004371
Iteration 219/1000 | Loss: 0.00004371
Iteration 220/1000 | Loss: 0.00004371
Iteration 221/1000 | Loss: 0.00004371
Iteration 222/1000 | Loss: 0.00004371
Iteration 223/1000 | Loss: 0.00004371
Iteration 224/1000 | Loss: 0.00004371
Iteration 225/1000 | Loss: 0.00004371
Iteration 226/1000 | Loss: 0.00004371
Iteration 227/1000 | Loss: 0.00004371
Iteration 228/1000 | Loss: 0.00004371
Iteration 229/1000 | Loss: 0.00004371
Iteration 230/1000 | Loss: 0.00004371
Iteration 231/1000 | Loss: 0.00004371
Iteration 232/1000 | Loss: 0.00004371
Iteration 233/1000 | Loss: 0.00004371
Iteration 234/1000 | Loss: 0.00004371
Iteration 235/1000 | Loss: 0.00004371
Iteration 236/1000 | Loss: 0.00004371
Iteration 237/1000 | Loss: 0.00004371
Iteration 238/1000 | Loss: 0.00004371
Iteration 239/1000 | Loss: 0.00004371
Iteration 240/1000 | Loss: 0.00004371
Iteration 241/1000 | Loss: 0.00004371
Iteration 242/1000 | Loss: 0.00004371
Iteration 243/1000 | Loss: 0.00004371
Iteration 244/1000 | Loss: 0.00004371
Iteration 245/1000 | Loss: 0.00004371
Iteration 246/1000 | Loss: 0.00004371
Iteration 247/1000 | Loss: 0.00004371
Iteration 248/1000 | Loss: 0.00004371
Iteration 249/1000 | Loss: 0.00004371
Iteration 250/1000 | Loss: 0.00004371
Iteration 251/1000 | Loss: 0.00004371
Iteration 252/1000 | Loss: 0.00004371
Iteration 253/1000 | Loss: 0.00004371
Iteration 254/1000 | Loss: 0.00004371
Iteration 255/1000 | Loss: 0.00004371
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 255. Stopping optimization.
Last 5 losses: [4.370626629679464e-05, 4.370626629679464e-05, 4.370626629679464e-05, 4.370626629679464e-05, 4.370626629679464e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 4.370626629679464e-05

Optimization complete. Final v2v error: 4.115732192993164 mm

Highest mean error: 13.878152847290039 mm for frame 188

Lowest mean error: 3.5501151084899902 mm for frame 235

Saving results

Total time: 252.7175087928772
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1034/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1034.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1034
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01045275
Iteration 2/25 | Loss: 0.00305842
Iteration 3/25 | Loss: 0.00191981
Iteration 4/25 | Loss: 0.00168576
Iteration 5/25 | Loss: 0.00144438
Iteration 6/25 | Loss: 0.00143965
Iteration 7/25 | Loss: 0.00128958
Iteration 8/25 | Loss: 0.00117741
Iteration 9/25 | Loss: 0.00110456
Iteration 10/25 | Loss: 0.00104451
Iteration 11/25 | Loss: 0.00101304
Iteration 12/25 | Loss: 0.00099160
Iteration 13/25 | Loss: 0.00099762
Iteration 14/25 | Loss: 0.00096900
Iteration 15/25 | Loss: 0.00095764
Iteration 16/25 | Loss: 0.00096276
Iteration 17/25 | Loss: 0.00095716
Iteration 18/25 | Loss: 0.00095071
Iteration 19/25 | Loss: 0.00095240
Iteration 20/25 | Loss: 0.00095350
Iteration 21/25 | Loss: 0.00094612
Iteration 22/25 | Loss: 0.00093786
Iteration 23/25 | Loss: 0.00093632
Iteration 24/25 | Loss: 0.00093336
Iteration 25/25 | Loss: 0.00094148

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51215768
Iteration 2/25 | Loss: 0.00317795
Iteration 3/25 | Loss: 0.00193904
Iteration 4/25 | Loss: 0.00193904
Iteration 5/25 | Loss: 0.00193904
Iteration 6/25 | Loss: 0.00193904
Iteration 7/25 | Loss: 0.00193904
Iteration 8/25 | Loss: 0.00193904
Iteration 9/25 | Loss: 0.00193904
Iteration 10/25 | Loss: 0.00193904
Iteration 11/25 | Loss: 0.00193904
Iteration 12/25 | Loss: 0.00193904
Iteration 13/25 | Loss: 0.00193904
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.001939038629643619, 0.001939038629643619, 0.001939038629643619, 0.001939038629643619, 0.001939038629643619]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001939038629643619

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00193904
Iteration 2/1000 | Loss: 0.00152463
Iteration 3/1000 | Loss: 0.00161846
Iteration 4/1000 | Loss: 0.00077592
Iteration 5/1000 | Loss: 0.00066470
Iteration 6/1000 | Loss: 0.00037041
Iteration 7/1000 | Loss: 0.00073952
Iteration 8/1000 | Loss: 0.00117361
Iteration 9/1000 | Loss: 0.00103973
Iteration 10/1000 | Loss: 0.00019719
Iteration 11/1000 | Loss: 0.00022523
Iteration 12/1000 | Loss: 0.00018391
Iteration 13/1000 | Loss: 0.00012682
Iteration 14/1000 | Loss: 0.00065232
Iteration 15/1000 | Loss: 0.00048029
Iteration 16/1000 | Loss: 0.00025821
Iteration 17/1000 | Loss: 0.00020365
Iteration 18/1000 | Loss: 0.00075612
Iteration 19/1000 | Loss: 0.00099028
Iteration 20/1000 | Loss: 0.00148430
Iteration 21/1000 | Loss: 0.00058996
Iteration 22/1000 | Loss: 0.00054305
Iteration 23/1000 | Loss: 0.00038373
Iteration 24/1000 | Loss: 0.00104884
Iteration 25/1000 | Loss: 0.00093253
Iteration 26/1000 | Loss: 0.00047297
Iteration 27/1000 | Loss: 0.00022655
Iteration 28/1000 | Loss: 0.00118247
Iteration 29/1000 | Loss: 0.00106328
Iteration 30/1000 | Loss: 0.00052514
Iteration 31/1000 | Loss: 0.00029247
Iteration 32/1000 | Loss: 0.00016192
Iteration 33/1000 | Loss: 0.00056632
Iteration 34/1000 | Loss: 0.00229303
Iteration 35/1000 | Loss: 0.00042808
Iteration 36/1000 | Loss: 0.00021438
Iteration 37/1000 | Loss: 0.00032660
Iteration 38/1000 | Loss: 0.00027768
Iteration 39/1000 | Loss: 0.00019199
Iteration 40/1000 | Loss: 0.00007282
Iteration 41/1000 | Loss: 0.00083479
Iteration 42/1000 | Loss: 0.00013824
Iteration 43/1000 | Loss: 0.00019159
Iteration 44/1000 | Loss: 0.00006324
Iteration 45/1000 | Loss: 0.00005885
Iteration 46/1000 | Loss: 0.00056077
Iteration 47/1000 | Loss: 0.00084344
Iteration 48/1000 | Loss: 0.00008434
Iteration 49/1000 | Loss: 0.00056269
Iteration 50/1000 | Loss: 0.00035869
Iteration 51/1000 | Loss: 0.00054745
Iteration 52/1000 | Loss: 0.00006675
Iteration 53/1000 | Loss: 0.00005406
Iteration 54/1000 | Loss: 0.00059177
Iteration 55/1000 | Loss: 0.00005908
Iteration 56/1000 | Loss: 0.00056597
Iteration 57/1000 | Loss: 0.00079673
Iteration 58/1000 | Loss: 0.00069717
Iteration 59/1000 | Loss: 0.00068633
Iteration 60/1000 | Loss: 0.00028116
Iteration 61/1000 | Loss: 0.00062449
Iteration 62/1000 | Loss: 0.00016718
Iteration 63/1000 | Loss: 0.00041179
Iteration 64/1000 | Loss: 0.00040245
Iteration 65/1000 | Loss: 0.00034686
Iteration 66/1000 | Loss: 0.00022758
Iteration 67/1000 | Loss: 0.00015456
Iteration 68/1000 | Loss: 0.00011276
Iteration 69/1000 | Loss: 0.00003751
Iteration 70/1000 | Loss: 0.00003363
Iteration 71/1000 | Loss: 0.00004079
Iteration 72/1000 | Loss: 0.00002971
Iteration 73/1000 | Loss: 0.00002856
Iteration 74/1000 | Loss: 0.00003717
Iteration 75/1000 | Loss: 0.00002735
Iteration 76/1000 | Loss: 0.00002669
Iteration 77/1000 | Loss: 0.00015450
Iteration 78/1000 | Loss: 0.00003128
Iteration 79/1000 | Loss: 0.00002918
Iteration 80/1000 | Loss: 0.00046291
Iteration 81/1000 | Loss: 0.00029383
Iteration 82/1000 | Loss: 0.00052474
Iteration 83/1000 | Loss: 0.00018556
Iteration 84/1000 | Loss: 0.00004588
Iteration 85/1000 | Loss: 0.00003542
Iteration 86/1000 | Loss: 0.00003174
Iteration 87/1000 | Loss: 0.00002841
Iteration 88/1000 | Loss: 0.00002603
Iteration 89/1000 | Loss: 0.00002504
Iteration 90/1000 | Loss: 0.00002422
Iteration 91/1000 | Loss: 0.00002354
Iteration 92/1000 | Loss: 0.00004183
Iteration 93/1000 | Loss: 0.00002266
Iteration 94/1000 | Loss: 0.00025024
Iteration 95/1000 | Loss: 0.00029302
Iteration 96/1000 | Loss: 0.00041537
Iteration 97/1000 | Loss: 0.00003546
Iteration 98/1000 | Loss: 0.00002665
Iteration 99/1000 | Loss: 0.00026471
Iteration 100/1000 | Loss: 0.00003406
Iteration 101/1000 | Loss: 0.00017853
Iteration 102/1000 | Loss: 0.00008557
Iteration 103/1000 | Loss: 0.00002779
Iteration 104/1000 | Loss: 0.00002527
Iteration 105/1000 | Loss: 0.00002416
Iteration 106/1000 | Loss: 0.00002355
Iteration 107/1000 | Loss: 0.00021299
Iteration 108/1000 | Loss: 0.00017500
Iteration 109/1000 | Loss: 0.00003052
Iteration 110/1000 | Loss: 0.00002289
Iteration 111/1000 | Loss: 0.00028036
Iteration 112/1000 | Loss: 0.00017187
Iteration 113/1000 | Loss: 0.00006881
Iteration 114/1000 | Loss: 0.00002866
Iteration 115/1000 | Loss: 0.00002507
Iteration 116/1000 | Loss: 0.00028444
Iteration 117/1000 | Loss: 0.00020807
Iteration 118/1000 | Loss: 0.00002952
Iteration 119/1000 | Loss: 0.00005804
Iteration 120/1000 | Loss: 0.00002098
Iteration 121/1000 | Loss: 0.00002012
Iteration 122/1000 | Loss: 0.00004249
Iteration 123/1000 | Loss: 0.00001958
Iteration 124/1000 | Loss: 0.00001872
Iteration 125/1000 | Loss: 0.00001840
Iteration 126/1000 | Loss: 0.00001809
Iteration 127/1000 | Loss: 0.00001794
Iteration 128/1000 | Loss: 0.00001793
Iteration 129/1000 | Loss: 0.00001787
Iteration 130/1000 | Loss: 0.00001782
Iteration 131/1000 | Loss: 0.00001779
Iteration 132/1000 | Loss: 0.00001778
Iteration 133/1000 | Loss: 0.00002880
Iteration 134/1000 | Loss: 0.00002483
Iteration 135/1000 | Loss: 0.00001858
Iteration 136/1000 | Loss: 0.00001783
Iteration 137/1000 | Loss: 0.00002653
Iteration 138/1000 | Loss: 0.00004281
Iteration 139/1000 | Loss: 0.00002401
Iteration 140/1000 | Loss: 0.00001798
Iteration 141/1000 | Loss: 0.00001754
Iteration 142/1000 | Loss: 0.00001736
Iteration 143/1000 | Loss: 0.00001726
Iteration 144/1000 | Loss: 0.00001726
Iteration 145/1000 | Loss: 0.00001725
Iteration 146/1000 | Loss: 0.00002723
Iteration 147/1000 | Loss: 0.00001871
Iteration 148/1000 | Loss: 0.00001718
Iteration 149/1000 | Loss: 0.00001717
Iteration 150/1000 | Loss: 0.00001717
Iteration 151/1000 | Loss: 0.00001717
Iteration 152/1000 | Loss: 0.00001717
Iteration 153/1000 | Loss: 0.00001717
Iteration 154/1000 | Loss: 0.00001717
Iteration 155/1000 | Loss: 0.00001717
Iteration 156/1000 | Loss: 0.00001717
Iteration 157/1000 | Loss: 0.00001717
Iteration 158/1000 | Loss: 0.00001716
Iteration 159/1000 | Loss: 0.00001715
Iteration 160/1000 | Loss: 0.00001715
Iteration 161/1000 | Loss: 0.00001715
Iteration 162/1000 | Loss: 0.00001714
Iteration 163/1000 | Loss: 0.00001714
Iteration 164/1000 | Loss: 0.00001714
Iteration 165/1000 | Loss: 0.00001713
Iteration 166/1000 | Loss: 0.00001713
Iteration 167/1000 | Loss: 0.00001713
Iteration 168/1000 | Loss: 0.00001712
Iteration 169/1000 | Loss: 0.00001711
Iteration 170/1000 | Loss: 0.00001711
Iteration 171/1000 | Loss: 0.00001711
Iteration 172/1000 | Loss: 0.00001710
Iteration 173/1000 | Loss: 0.00001710
Iteration 174/1000 | Loss: 0.00001705
Iteration 175/1000 | Loss: 0.00001701
Iteration 176/1000 | Loss: 0.00001700
Iteration 177/1000 | Loss: 0.00001693
Iteration 178/1000 | Loss: 0.00001693
Iteration 179/1000 | Loss: 0.00001691
Iteration 180/1000 | Loss: 0.00001691
Iteration 181/1000 | Loss: 0.00001690
Iteration 182/1000 | Loss: 0.00001689
Iteration 183/1000 | Loss: 0.00001689
Iteration 184/1000 | Loss: 0.00001688
Iteration 185/1000 | Loss: 0.00001688
Iteration 186/1000 | Loss: 0.00001688
Iteration 187/1000 | Loss: 0.00001687
Iteration 188/1000 | Loss: 0.00001687
Iteration 189/1000 | Loss: 0.00001686
Iteration 190/1000 | Loss: 0.00001686
Iteration 191/1000 | Loss: 0.00001686
Iteration 192/1000 | Loss: 0.00001685
Iteration 193/1000 | Loss: 0.00001685
Iteration 194/1000 | Loss: 0.00001684
Iteration 195/1000 | Loss: 0.00001682
Iteration 196/1000 | Loss: 0.00001682
Iteration 197/1000 | Loss: 0.00001682
Iteration 198/1000 | Loss: 0.00001681
Iteration 199/1000 | Loss: 0.00001681
Iteration 200/1000 | Loss: 0.00001681
Iteration 201/1000 | Loss: 0.00001681
Iteration 202/1000 | Loss: 0.00001681
Iteration 203/1000 | Loss: 0.00001681
Iteration 204/1000 | Loss: 0.00001680
Iteration 205/1000 | Loss: 0.00001680
Iteration 206/1000 | Loss: 0.00001680
Iteration 207/1000 | Loss: 0.00001680
Iteration 208/1000 | Loss: 0.00001680
Iteration 209/1000 | Loss: 0.00001680
Iteration 210/1000 | Loss: 0.00001680
Iteration 211/1000 | Loss: 0.00001680
Iteration 212/1000 | Loss: 0.00001679
Iteration 213/1000 | Loss: 0.00001679
Iteration 214/1000 | Loss: 0.00001679
Iteration 215/1000 | Loss: 0.00001679
Iteration 216/1000 | Loss: 0.00001679
Iteration 217/1000 | Loss: 0.00001678
Iteration 218/1000 | Loss: 0.00001678
Iteration 219/1000 | Loss: 0.00001678
Iteration 220/1000 | Loss: 0.00001678
Iteration 221/1000 | Loss: 0.00001677
Iteration 222/1000 | Loss: 0.00001677
Iteration 223/1000 | Loss: 0.00001677
Iteration 224/1000 | Loss: 0.00001677
Iteration 225/1000 | Loss: 0.00001677
Iteration 226/1000 | Loss: 0.00001677
Iteration 227/1000 | Loss: 0.00001677
Iteration 228/1000 | Loss: 0.00001677
Iteration 229/1000 | Loss: 0.00001677
Iteration 230/1000 | Loss: 0.00001677
Iteration 231/1000 | Loss: 0.00001677
Iteration 232/1000 | Loss: 0.00001677
Iteration 233/1000 | Loss: 0.00001677
Iteration 234/1000 | Loss: 0.00001676
Iteration 235/1000 | Loss: 0.00001676
Iteration 236/1000 | Loss: 0.00001676
Iteration 237/1000 | Loss: 0.00001676
Iteration 238/1000 | Loss: 0.00001676
Iteration 239/1000 | Loss: 0.00001676
Iteration 240/1000 | Loss: 0.00001676
Iteration 241/1000 | Loss: 0.00001676
Iteration 242/1000 | Loss: 0.00001675
Iteration 243/1000 | Loss: 0.00001675
Iteration 244/1000 | Loss: 0.00001675
Iteration 245/1000 | Loss: 0.00001675
Iteration 246/1000 | Loss: 0.00001675
Iteration 247/1000 | Loss: 0.00001675
Iteration 248/1000 | Loss: 0.00001675
Iteration 249/1000 | Loss: 0.00001675
Iteration 250/1000 | Loss: 0.00001675
Iteration 251/1000 | Loss: 0.00001675
Iteration 252/1000 | Loss: 0.00001675
Iteration 253/1000 | Loss: 0.00001675
Iteration 254/1000 | Loss: 0.00001675
Iteration 255/1000 | Loss: 0.00001675
Iteration 256/1000 | Loss: 0.00001675
Iteration 257/1000 | Loss: 0.00001675
Iteration 258/1000 | Loss: 0.00001674
Iteration 259/1000 | Loss: 0.00001674
Iteration 260/1000 | Loss: 0.00001674
Iteration 261/1000 | Loss: 0.00001674
Iteration 262/1000 | Loss: 0.00001674
Iteration 263/1000 | Loss: 0.00001674
Iteration 264/1000 | Loss: 0.00001674
Iteration 265/1000 | Loss: 0.00001674
Iteration 266/1000 | Loss: 0.00001674
Iteration 267/1000 | Loss: 0.00001674
Iteration 268/1000 | Loss: 0.00001674
Iteration 269/1000 | Loss: 0.00001674
Iteration 270/1000 | Loss: 0.00001674
Iteration 271/1000 | Loss: 0.00001674
Iteration 272/1000 | Loss: 0.00001674
Iteration 273/1000 | Loss: 0.00001674
Iteration 274/1000 | Loss: 0.00001674
Iteration 275/1000 | Loss: 0.00001674
Iteration 276/1000 | Loss: 0.00001674
Iteration 277/1000 | Loss: 0.00001674
Iteration 278/1000 | Loss: 0.00001674
Iteration 279/1000 | Loss: 0.00001674
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 279. Stopping optimization.
Last 5 losses: [1.6735530152800493e-05, 1.6735530152800493e-05, 1.6735530152800493e-05, 1.6735530152800493e-05, 1.6735530152800493e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6735530152800493e-05

Optimization complete. Final v2v error: 3.34948468208313 mm

Highest mean error: 6.048201084136963 mm for frame 14

Lowest mean error: 2.9814677238464355 mm for frame 221

Saving results

Total time: 295.1934027671814
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00474661
Iteration 2/25 | Loss: 0.00099250
Iteration 3/25 | Loss: 0.00080230
Iteration 4/25 | Loss: 0.00076738
Iteration 5/25 | Loss: 0.00075902
Iteration 6/25 | Loss: 0.00075718
Iteration 7/25 | Loss: 0.00075698
Iteration 8/25 | Loss: 0.00075698
Iteration 9/25 | Loss: 0.00075694
Iteration 10/25 | Loss: 0.00075694
Iteration 11/25 | Loss: 0.00075694
Iteration 12/25 | Loss: 0.00075694
Iteration 13/25 | Loss: 0.00075694
Iteration 14/25 | Loss: 0.00075694
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.000756937253754586, 0.000756937253754586, 0.000756937253754586, 0.000756937253754586, 0.000756937253754586]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000756937253754586

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.81570190
Iteration 2/25 | Loss: 0.00034842
Iteration 3/25 | Loss: 0.00034842
Iteration 4/25 | Loss: 0.00034842
Iteration 5/25 | Loss: 0.00034842
Iteration 6/25 | Loss: 0.00034842
Iteration 7/25 | Loss: 0.00034842
Iteration 8/25 | Loss: 0.00034842
Iteration 9/25 | Loss: 0.00034842
Iteration 10/25 | Loss: 0.00034842
Iteration 11/25 | Loss: 0.00034841
Iteration 12/25 | Loss: 0.00034841
Iteration 13/25 | Loss: 0.00034841
Iteration 14/25 | Loss: 0.00034841
Iteration 15/25 | Loss: 0.00034841
Iteration 16/25 | Loss: 0.00034841
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0003484149638097733, 0.0003484149638097733, 0.0003484149638097733, 0.0003484149638097733, 0.0003484149638097733]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0003484149638097733

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00034841
Iteration 2/1000 | Loss: 0.00002995
Iteration 3/1000 | Loss: 0.00002500
Iteration 4/1000 | Loss: 0.00002371
Iteration 5/1000 | Loss: 0.00002277
Iteration 6/1000 | Loss: 0.00002202
Iteration 7/1000 | Loss: 0.00002151
Iteration 8/1000 | Loss: 0.00002103
Iteration 9/1000 | Loss: 0.00002076
Iteration 10/1000 | Loss: 0.00002053
Iteration 11/1000 | Loss: 0.00002050
Iteration 12/1000 | Loss: 0.00002027
Iteration 13/1000 | Loss: 0.00002026
Iteration 14/1000 | Loss: 0.00002023
Iteration 15/1000 | Loss: 0.00002008
Iteration 16/1000 | Loss: 0.00001995
Iteration 17/1000 | Loss: 0.00001994
Iteration 18/1000 | Loss: 0.00001991
Iteration 19/1000 | Loss: 0.00001990
Iteration 20/1000 | Loss: 0.00001990
Iteration 21/1000 | Loss: 0.00001989
Iteration 22/1000 | Loss: 0.00001987
Iteration 23/1000 | Loss: 0.00001987
Iteration 24/1000 | Loss: 0.00001987
Iteration 25/1000 | Loss: 0.00001987
Iteration 26/1000 | Loss: 0.00001987
Iteration 27/1000 | Loss: 0.00001987
Iteration 28/1000 | Loss: 0.00001987
Iteration 29/1000 | Loss: 0.00001987
Iteration 30/1000 | Loss: 0.00001987
Iteration 31/1000 | Loss: 0.00001986
Iteration 32/1000 | Loss: 0.00001985
Iteration 33/1000 | Loss: 0.00001984
Iteration 34/1000 | Loss: 0.00001983
Iteration 35/1000 | Loss: 0.00001983
Iteration 36/1000 | Loss: 0.00001983
Iteration 37/1000 | Loss: 0.00001983
Iteration 38/1000 | Loss: 0.00001983
Iteration 39/1000 | Loss: 0.00001983
Iteration 40/1000 | Loss: 0.00001983
Iteration 41/1000 | Loss: 0.00001983
Iteration 42/1000 | Loss: 0.00001983
Iteration 43/1000 | Loss: 0.00001982
Iteration 44/1000 | Loss: 0.00001981
Iteration 45/1000 | Loss: 0.00001979
Iteration 46/1000 | Loss: 0.00001978
Iteration 47/1000 | Loss: 0.00001977
Iteration 48/1000 | Loss: 0.00001975
Iteration 49/1000 | Loss: 0.00001975
Iteration 50/1000 | Loss: 0.00001975
Iteration 51/1000 | Loss: 0.00001975
Iteration 52/1000 | Loss: 0.00001974
Iteration 53/1000 | Loss: 0.00001974
Iteration 54/1000 | Loss: 0.00001974
Iteration 55/1000 | Loss: 0.00001974
Iteration 56/1000 | Loss: 0.00001974
Iteration 57/1000 | Loss: 0.00001974
Iteration 58/1000 | Loss: 0.00001974
Iteration 59/1000 | Loss: 0.00001974
Iteration 60/1000 | Loss: 0.00001974
Iteration 61/1000 | Loss: 0.00001971
Iteration 62/1000 | Loss: 0.00001971
Iteration 63/1000 | Loss: 0.00001970
Iteration 64/1000 | Loss: 0.00001970
Iteration 65/1000 | Loss: 0.00001970
Iteration 66/1000 | Loss: 0.00001970
Iteration 67/1000 | Loss: 0.00001970
Iteration 68/1000 | Loss: 0.00001970
Iteration 69/1000 | Loss: 0.00001970
Iteration 70/1000 | Loss: 0.00001970
Iteration 71/1000 | Loss: 0.00001968
Iteration 72/1000 | Loss: 0.00001968
Iteration 73/1000 | Loss: 0.00001968
Iteration 74/1000 | Loss: 0.00001968
Iteration 75/1000 | Loss: 0.00001968
Iteration 76/1000 | Loss: 0.00001967
Iteration 77/1000 | Loss: 0.00001967
Iteration 78/1000 | Loss: 0.00001967
Iteration 79/1000 | Loss: 0.00001967
Iteration 80/1000 | Loss: 0.00001965
Iteration 81/1000 | Loss: 0.00001965
Iteration 82/1000 | Loss: 0.00001964
Iteration 83/1000 | Loss: 0.00001964
Iteration 84/1000 | Loss: 0.00001964
Iteration 85/1000 | Loss: 0.00001964
Iteration 86/1000 | Loss: 0.00001963
Iteration 87/1000 | Loss: 0.00001963
Iteration 88/1000 | Loss: 0.00001963
Iteration 89/1000 | Loss: 0.00001963
Iteration 90/1000 | Loss: 0.00001963
Iteration 91/1000 | Loss: 0.00001963
Iteration 92/1000 | Loss: 0.00001960
Iteration 93/1000 | Loss: 0.00001960
Iteration 94/1000 | Loss: 0.00001960
Iteration 95/1000 | Loss: 0.00001959
Iteration 96/1000 | Loss: 0.00001959
Iteration 97/1000 | Loss: 0.00001958
Iteration 98/1000 | Loss: 0.00001958
Iteration 99/1000 | Loss: 0.00001958
Iteration 100/1000 | Loss: 0.00001958
Iteration 101/1000 | Loss: 0.00001958
Iteration 102/1000 | Loss: 0.00001957
Iteration 103/1000 | Loss: 0.00001957
Iteration 104/1000 | Loss: 0.00001957
Iteration 105/1000 | Loss: 0.00001957
Iteration 106/1000 | Loss: 0.00001957
Iteration 107/1000 | Loss: 0.00001956
Iteration 108/1000 | Loss: 0.00001955
Iteration 109/1000 | Loss: 0.00001955
Iteration 110/1000 | Loss: 0.00001955
Iteration 111/1000 | Loss: 0.00001954
Iteration 112/1000 | Loss: 0.00001954
Iteration 113/1000 | Loss: 0.00001954
Iteration 114/1000 | Loss: 0.00001954
Iteration 115/1000 | Loss: 0.00001954
Iteration 116/1000 | Loss: 0.00001954
Iteration 117/1000 | Loss: 0.00001954
Iteration 118/1000 | Loss: 0.00001954
Iteration 119/1000 | Loss: 0.00001954
Iteration 120/1000 | Loss: 0.00001954
Iteration 121/1000 | Loss: 0.00001953
Iteration 122/1000 | Loss: 0.00001953
Iteration 123/1000 | Loss: 0.00001953
Iteration 124/1000 | Loss: 0.00001953
Iteration 125/1000 | Loss: 0.00001953
Iteration 126/1000 | Loss: 0.00001952
Iteration 127/1000 | Loss: 0.00001952
Iteration 128/1000 | Loss: 0.00001952
Iteration 129/1000 | Loss: 0.00001952
Iteration 130/1000 | Loss: 0.00001952
Iteration 131/1000 | Loss: 0.00001952
Iteration 132/1000 | Loss: 0.00001951
Iteration 133/1000 | Loss: 0.00001951
Iteration 134/1000 | Loss: 0.00001951
Iteration 135/1000 | Loss: 0.00001951
Iteration 136/1000 | Loss: 0.00001951
Iteration 137/1000 | Loss: 0.00001951
Iteration 138/1000 | Loss: 0.00001951
Iteration 139/1000 | Loss: 0.00001951
Iteration 140/1000 | Loss: 0.00001951
Iteration 141/1000 | Loss: 0.00001951
Iteration 142/1000 | Loss: 0.00001950
Iteration 143/1000 | Loss: 0.00001950
Iteration 144/1000 | Loss: 0.00001950
Iteration 145/1000 | Loss: 0.00001950
Iteration 146/1000 | Loss: 0.00001950
Iteration 147/1000 | Loss: 0.00001949
Iteration 148/1000 | Loss: 0.00001949
Iteration 149/1000 | Loss: 0.00001949
Iteration 150/1000 | Loss: 0.00001949
Iteration 151/1000 | Loss: 0.00001949
Iteration 152/1000 | Loss: 0.00001949
Iteration 153/1000 | Loss: 0.00001949
Iteration 154/1000 | Loss: 0.00001949
Iteration 155/1000 | Loss: 0.00001949
Iteration 156/1000 | Loss: 0.00001949
Iteration 157/1000 | Loss: 0.00001949
Iteration 158/1000 | Loss: 0.00001949
Iteration 159/1000 | Loss: 0.00001948
Iteration 160/1000 | Loss: 0.00001948
Iteration 161/1000 | Loss: 0.00001948
Iteration 162/1000 | Loss: 0.00001948
Iteration 163/1000 | Loss: 0.00001948
Iteration 164/1000 | Loss: 0.00001948
Iteration 165/1000 | Loss: 0.00001948
Iteration 166/1000 | Loss: 0.00001947
Iteration 167/1000 | Loss: 0.00001947
Iteration 168/1000 | Loss: 0.00001947
Iteration 169/1000 | Loss: 0.00001947
Iteration 170/1000 | Loss: 0.00001947
Iteration 171/1000 | Loss: 0.00001947
Iteration 172/1000 | Loss: 0.00001947
Iteration 173/1000 | Loss: 0.00001946
Iteration 174/1000 | Loss: 0.00001946
Iteration 175/1000 | Loss: 0.00001946
Iteration 176/1000 | Loss: 0.00001946
Iteration 177/1000 | Loss: 0.00001946
Iteration 178/1000 | Loss: 0.00001946
Iteration 179/1000 | Loss: 0.00001946
Iteration 180/1000 | Loss: 0.00001946
Iteration 181/1000 | Loss: 0.00001946
Iteration 182/1000 | Loss: 0.00001946
Iteration 183/1000 | Loss: 0.00001945
Iteration 184/1000 | Loss: 0.00001945
Iteration 185/1000 | Loss: 0.00001945
Iteration 186/1000 | Loss: 0.00001945
Iteration 187/1000 | Loss: 0.00001945
Iteration 188/1000 | Loss: 0.00001944
Iteration 189/1000 | Loss: 0.00001944
Iteration 190/1000 | Loss: 0.00001944
Iteration 191/1000 | Loss: 0.00001944
Iteration 192/1000 | Loss: 0.00001944
Iteration 193/1000 | Loss: 0.00001944
Iteration 194/1000 | Loss: 0.00001944
Iteration 195/1000 | Loss: 0.00001943
Iteration 196/1000 | Loss: 0.00001943
Iteration 197/1000 | Loss: 0.00001943
Iteration 198/1000 | Loss: 0.00001943
Iteration 199/1000 | Loss: 0.00001943
Iteration 200/1000 | Loss: 0.00001943
Iteration 201/1000 | Loss: 0.00001943
Iteration 202/1000 | Loss: 0.00001942
Iteration 203/1000 | Loss: 0.00001942
Iteration 204/1000 | Loss: 0.00001942
Iteration 205/1000 | Loss: 0.00001942
Iteration 206/1000 | Loss: 0.00001941
Iteration 207/1000 | Loss: 0.00001941
Iteration 208/1000 | Loss: 0.00001941
Iteration 209/1000 | Loss: 0.00001941
Iteration 210/1000 | Loss: 0.00001941
Iteration 211/1000 | Loss: 0.00001941
Iteration 212/1000 | Loss: 0.00001941
Iteration 213/1000 | Loss: 0.00001941
Iteration 214/1000 | Loss: 0.00001941
Iteration 215/1000 | Loss: 0.00001940
Iteration 216/1000 | Loss: 0.00001940
Iteration 217/1000 | Loss: 0.00001940
Iteration 218/1000 | Loss: 0.00001940
Iteration 219/1000 | Loss: 0.00001940
Iteration 220/1000 | Loss: 0.00001940
Iteration 221/1000 | Loss: 0.00001940
Iteration 222/1000 | Loss: 0.00001940
Iteration 223/1000 | Loss: 0.00001940
Iteration 224/1000 | Loss: 0.00001940
Iteration 225/1000 | Loss: 0.00001940
Iteration 226/1000 | Loss: 0.00001940
Iteration 227/1000 | Loss: 0.00001940
Iteration 228/1000 | Loss: 0.00001940
Iteration 229/1000 | Loss: 0.00001940
Iteration 230/1000 | Loss: 0.00001940
Iteration 231/1000 | Loss: 0.00001940
Iteration 232/1000 | Loss: 0.00001940
Iteration 233/1000 | Loss: 0.00001940
Iteration 234/1000 | Loss: 0.00001940
Iteration 235/1000 | Loss: 0.00001940
Iteration 236/1000 | Loss: 0.00001940
Iteration 237/1000 | Loss: 0.00001940
Iteration 238/1000 | Loss: 0.00001940
Iteration 239/1000 | Loss: 0.00001940
Iteration 240/1000 | Loss: 0.00001940
Iteration 241/1000 | Loss: 0.00001940
Iteration 242/1000 | Loss: 0.00001940
Iteration 243/1000 | Loss: 0.00001940
Iteration 244/1000 | Loss: 0.00001940
Iteration 245/1000 | Loss: 0.00001940
Iteration 246/1000 | Loss: 0.00001940
Iteration 247/1000 | Loss: 0.00001940
Iteration 248/1000 | Loss: 0.00001940
Iteration 249/1000 | Loss: 0.00001940
Iteration 250/1000 | Loss: 0.00001940
Iteration 251/1000 | Loss: 0.00001940
Iteration 252/1000 | Loss: 0.00001940
Iteration 253/1000 | Loss: 0.00001940
Iteration 254/1000 | Loss: 0.00001940
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 254. Stopping optimization.
Last 5 losses: [1.9396997231524438e-05, 1.9396997231524438e-05, 1.9396997231524438e-05, 1.9396997231524438e-05, 1.9396997231524438e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9396997231524438e-05

Optimization complete. Final v2v error: 3.7574462890625 mm

Highest mean error: 4.618962287902832 mm for frame 259

Lowest mean error: 3.552449941635132 mm for frame 54

Saving results

Total time: 54.910441160202026
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1052/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1052.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1052
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01127141
Iteration 2/25 | Loss: 0.00215062
Iteration 3/25 | Loss: 0.00143724
Iteration 4/25 | Loss: 0.00126262
Iteration 5/25 | Loss: 0.00143458
Iteration 6/25 | Loss: 0.00152940
Iteration 7/25 | Loss: 0.00144128
Iteration 8/25 | Loss: 0.00132595
Iteration 9/25 | Loss: 0.00127138
Iteration 10/25 | Loss: 0.00116796
Iteration 11/25 | Loss: 0.00115462
Iteration 12/25 | Loss: 0.00119736
Iteration 13/25 | Loss: 0.00116585
Iteration 14/25 | Loss: 0.00110551
Iteration 15/25 | Loss: 0.00105102
Iteration 16/25 | Loss: 0.00101815
Iteration 17/25 | Loss: 0.00101890
Iteration 18/25 | Loss: 0.00103738
Iteration 19/25 | Loss: 0.00097206
Iteration 20/25 | Loss: 0.00095210
Iteration 21/25 | Loss: 0.00093286
Iteration 22/25 | Loss: 0.00091929
Iteration 23/25 | Loss: 0.00091176
Iteration 24/25 | Loss: 0.00090221
Iteration 25/25 | Loss: 0.00088762

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.31670105
Iteration 2/25 | Loss: 0.00189641
Iteration 3/25 | Loss: 0.00142009
Iteration 4/25 | Loss: 0.00142009
Iteration 5/25 | Loss: 0.00142009
Iteration 6/25 | Loss: 0.00142009
Iteration 7/25 | Loss: 0.00142009
Iteration 8/25 | Loss: 0.00142009
Iteration 9/25 | Loss: 0.00142009
Iteration 10/25 | Loss: 0.00142009
Iteration 11/25 | Loss: 0.00142009
Iteration 12/25 | Loss: 0.00142009
Iteration 13/25 | Loss: 0.00142009
Iteration 14/25 | Loss: 0.00142009
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0014200946316123009, 0.0014200946316123009, 0.0014200946316123009, 0.0014200946316123009, 0.0014200946316123009]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014200946316123009

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00142009
Iteration 2/1000 | Loss: 0.00157429
Iteration 3/1000 | Loss: 0.00160359
Iteration 4/1000 | Loss: 0.00100287
Iteration 5/1000 | Loss: 0.00030012
Iteration 6/1000 | Loss: 0.00083895
Iteration 7/1000 | Loss: 0.00110273
Iteration 8/1000 | Loss: 0.00082873
Iteration 9/1000 | Loss: 0.00101888
Iteration 10/1000 | Loss: 0.00111112
Iteration 11/1000 | Loss: 0.00078671
Iteration 12/1000 | Loss: 0.00066714
Iteration 13/1000 | Loss: 0.00046864
Iteration 14/1000 | Loss: 0.00037572
Iteration 15/1000 | Loss: 0.00043225
Iteration 16/1000 | Loss: 0.00065031
Iteration 17/1000 | Loss: 0.00037306
Iteration 18/1000 | Loss: 0.00110223
Iteration 19/1000 | Loss: 0.00088608
Iteration 20/1000 | Loss: 0.00109102
Iteration 21/1000 | Loss: 0.00133906
Iteration 22/1000 | Loss: 0.00127093
Iteration 23/1000 | Loss: 0.00214332
Iteration 24/1000 | Loss: 0.00202149
Iteration 25/1000 | Loss: 0.00125055
Iteration 26/1000 | Loss: 0.00106886
Iteration 27/1000 | Loss: 0.00095732
Iteration 28/1000 | Loss: 0.00039869
Iteration 29/1000 | Loss: 0.00036434
Iteration 30/1000 | Loss: 0.00091671
Iteration 31/1000 | Loss: 0.00087221
Iteration 32/1000 | Loss: 0.00059682
Iteration 33/1000 | Loss: 0.00055183
Iteration 34/1000 | Loss: 0.00072802
Iteration 35/1000 | Loss: 0.00068283
Iteration 36/1000 | Loss: 0.00089403
Iteration 37/1000 | Loss: 0.00034086
Iteration 38/1000 | Loss: 0.00145900
Iteration 39/1000 | Loss: 0.00095021
Iteration 40/1000 | Loss: 0.00050697
Iteration 41/1000 | Loss: 0.00076596
Iteration 42/1000 | Loss: 0.00045944
Iteration 43/1000 | Loss: 0.00041915
Iteration 44/1000 | Loss: 0.00054047
Iteration 45/1000 | Loss: 0.00037465
Iteration 46/1000 | Loss: 0.00034779
Iteration 47/1000 | Loss: 0.00150131
Iteration 48/1000 | Loss: 0.00048686
Iteration 49/1000 | Loss: 0.00028582
Iteration 50/1000 | Loss: 0.00035929
Iteration 51/1000 | Loss: 0.00031132
Iteration 52/1000 | Loss: 0.00032934
Iteration 53/1000 | Loss: 0.00051529
Iteration 54/1000 | Loss: 0.00046611
Iteration 55/1000 | Loss: 0.00017677
Iteration 56/1000 | Loss: 0.00036027
Iteration 57/1000 | Loss: 0.00023076
Iteration 58/1000 | Loss: 0.00071919
Iteration 59/1000 | Loss: 0.00056927
Iteration 60/1000 | Loss: 0.00037655
Iteration 61/1000 | Loss: 0.00029322
Iteration 62/1000 | Loss: 0.00017092
Iteration 63/1000 | Loss: 0.00036578
Iteration 64/1000 | Loss: 0.00032213
Iteration 65/1000 | Loss: 0.00025210
Iteration 66/1000 | Loss: 0.00020934
Iteration 67/1000 | Loss: 0.00024334
Iteration 68/1000 | Loss: 0.00022994
Iteration 69/1000 | Loss: 0.00032280
Iteration 70/1000 | Loss: 0.00027662
Iteration 71/1000 | Loss: 0.00022974
Iteration 72/1000 | Loss: 0.00027098
Iteration 73/1000 | Loss: 0.00077960
Iteration 74/1000 | Loss: 0.00016813
Iteration 75/1000 | Loss: 0.00019716
Iteration 76/1000 | Loss: 0.00036959
Iteration 77/1000 | Loss: 0.00019670
Iteration 78/1000 | Loss: 0.00015829
Iteration 79/1000 | Loss: 0.00008130
Iteration 80/1000 | Loss: 0.00021504
Iteration 81/1000 | Loss: 0.00017862
Iteration 82/1000 | Loss: 0.00021894
Iteration 83/1000 | Loss: 0.00015863
Iteration 84/1000 | Loss: 0.00020112
Iteration 85/1000 | Loss: 0.00029915
Iteration 86/1000 | Loss: 0.00032166
Iteration 87/1000 | Loss: 0.00009705
Iteration 88/1000 | Loss: 0.00014613
Iteration 89/1000 | Loss: 0.00086924
Iteration 90/1000 | Loss: 0.00077094
Iteration 91/1000 | Loss: 0.00058045
Iteration 92/1000 | Loss: 0.00021721
Iteration 93/1000 | Loss: 0.00036559
Iteration 94/1000 | Loss: 0.00024513
Iteration 95/1000 | Loss: 0.00008843
Iteration 96/1000 | Loss: 0.00008026
Iteration 97/1000 | Loss: 0.00041539
Iteration 98/1000 | Loss: 0.00057432
Iteration 99/1000 | Loss: 0.00011451
Iteration 100/1000 | Loss: 0.00007130
Iteration 101/1000 | Loss: 0.00042794
Iteration 102/1000 | Loss: 0.00057664
Iteration 103/1000 | Loss: 0.00006866
Iteration 104/1000 | Loss: 0.00091349
Iteration 105/1000 | Loss: 0.00120996
Iteration 106/1000 | Loss: 0.00042164
Iteration 107/1000 | Loss: 0.00030804
Iteration 108/1000 | Loss: 0.00073055
Iteration 109/1000 | Loss: 0.00109060
Iteration 110/1000 | Loss: 0.00089073
Iteration 111/1000 | Loss: 0.00139132
Iteration 112/1000 | Loss: 0.00010518
Iteration 113/1000 | Loss: 0.00005583
Iteration 114/1000 | Loss: 0.00094618
Iteration 115/1000 | Loss: 0.00046899
Iteration 116/1000 | Loss: 0.00094971
Iteration 117/1000 | Loss: 0.00058015
Iteration 118/1000 | Loss: 0.00121477
Iteration 119/1000 | Loss: 0.00040003
Iteration 120/1000 | Loss: 0.00027266
Iteration 121/1000 | Loss: 0.00023715
Iteration 122/1000 | Loss: 0.00036774
Iteration 123/1000 | Loss: 0.00019938
Iteration 124/1000 | Loss: 0.00012611
Iteration 125/1000 | Loss: 0.00003699
Iteration 126/1000 | Loss: 0.00003324
Iteration 127/1000 | Loss: 0.00003171
Iteration 128/1000 | Loss: 0.00003075
Iteration 129/1000 | Loss: 0.00033856
Iteration 130/1000 | Loss: 0.00028021
Iteration 131/1000 | Loss: 0.00008909
Iteration 132/1000 | Loss: 0.00003353
Iteration 133/1000 | Loss: 0.00003068
Iteration 134/1000 | Loss: 0.00002931
Iteration 135/1000 | Loss: 0.00002873
Iteration 136/1000 | Loss: 0.00002812
Iteration 137/1000 | Loss: 0.00051285
Iteration 138/1000 | Loss: 0.00045452
Iteration 139/1000 | Loss: 0.00047280
Iteration 140/1000 | Loss: 0.00066148
Iteration 141/1000 | Loss: 0.00105682
Iteration 142/1000 | Loss: 0.00011476
Iteration 143/1000 | Loss: 0.00005119
Iteration 144/1000 | Loss: 0.00013138
Iteration 145/1000 | Loss: 0.00002868
Iteration 146/1000 | Loss: 0.00002589
Iteration 147/1000 | Loss: 0.00002401
Iteration 148/1000 | Loss: 0.00002291
Iteration 149/1000 | Loss: 0.00002224
Iteration 150/1000 | Loss: 0.00002175
Iteration 151/1000 | Loss: 0.00002128
Iteration 152/1000 | Loss: 0.00002097
Iteration 153/1000 | Loss: 0.00002074
Iteration 154/1000 | Loss: 0.00002070
Iteration 155/1000 | Loss: 0.00002066
Iteration 156/1000 | Loss: 0.00002065
Iteration 157/1000 | Loss: 0.00002065
Iteration 158/1000 | Loss: 0.00002064
Iteration 159/1000 | Loss: 0.00002064
Iteration 160/1000 | Loss: 0.00002062
Iteration 161/1000 | Loss: 0.00002060
Iteration 162/1000 | Loss: 0.00002060
Iteration 163/1000 | Loss: 0.00002060
Iteration 164/1000 | Loss: 0.00002059
Iteration 165/1000 | Loss: 0.00002059
Iteration 166/1000 | Loss: 0.00002059
Iteration 167/1000 | Loss: 0.00002059
Iteration 168/1000 | Loss: 0.00002058
Iteration 169/1000 | Loss: 0.00002058
Iteration 170/1000 | Loss: 0.00002058
Iteration 171/1000 | Loss: 0.00002058
Iteration 172/1000 | Loss: 0.00002058
Iteration 173/1000 | Loss: 0.00002058
Iteration 174/1000 | Loss: 0.00002058
Iteration 175/1000 | Loss: 0.00002057
Iteration 176/1000 | Loss: 0.00002057
Iteration 177/1000 | Loss: 0.00002057
Iteration 178/1000 | Loss: 0.00002057
Iteration 179/1000 | Loss: 0.00002057
Iteration 180/1000 | Loss: 0.00002056
Iteration 181/1000 | Loss: 0.00002056
Iteration 182/1000 | Loss: 0.00002056
Iteration 183/1000 | Loss: 0.00002056
Iteration 184/1000 | Loss: 0.00002056
Iteration 185/1000 | Loss: 0.00002055
Iteration 186/1000 | Loss: 0.00002055
Iteration 187/1000 | Loss: 0.00002055
Iteration 188/1000 | Loss: 0.00002054
Iteration 189/1000 | Loss: 0.00002054
Iteration 190/1000 | Loss: 0.00002054
Iteration 191/1000 | Loss: 0.00002053
Iteration 192/1000 | Loss: 0.00002053
Iteration 193/1000 | Loss: 0.00002053
Iteration 194/1000 | Loss: 0.00002052
Iteration 195/1000 | Loss: 0.00002052
Iteration 196/1000 | Loss: 0.00002052
Iteration 197/1000 | Loss: 0.00002052
Iteration 198/1000 | Loss: 0.00002052
Iteration 199/1000 | Loss: 0.00002052
Iteration 200/1000 | Loss: 0.00002052
Iteration 201/1000 | Loss: 0.00002052
Iteration 202/1000 | Loss: 0.00002052
Iteration 203/1000 | Loss: 0.00002052
Iteration 204/1000 | Loss: 0.00002052
Iteration 205/1000 | Loss: 0.00002051
Iteration 206/1000 | Loss: 0.00002051
Iteration 207/1000 | Loss: 0.00002051
Iteration 208/1000 | Loss: 0.00002051
Iteration 209/1000 | Loss: 0.00002051
Iteration 210/1000 | Loss: 0.00002051
Iteration 211/1000 | Loss: 0.00002051
Iteration 212/1000 | Loss: 0.00002051
Iteration 213/1000 | Loss: 0.00002051
Iteration 214/1000 | Loss: 0.00002051
Iteration 215/1000 | Loss: 0.00002050
Iteration 216/1000 | Loss: 0.00002050
Iteration 217/1000 | Loss: 0.00002050
Iteration 218/1000 | Loss: 0.00002050
Iteration 219/1000 | Loss: 0.00002050
Iteration 220/1000 | Loss: 0.00002050
Iteration 221/1000 | Loss: 0.00002050
Iteration 222/1000 | Loss: 0.00002050
Iteration 223/1000 | Loss: 0.00002050
Iteration 224/1000 | Loss: 0.00002050
Iteration 225/1000 | Loss: 0.00002050
Iteration 226/1000 | Loss: 0.00002050
Iteration 227/1000 | Loss: 0.00002050
Iteration 228/1000 | Loss: 0.00002050
Iteration 229/1000 | Loss: 0.00002050
Iteration 230/1000 | Loss: 0.00002050
Iteration 231/1000 | Loss: 0.00002050
Iteration 232/1000 | Loss: 0.00002049
Iteration 233/1000 | Loss: 0.00002049
Iteration 234/1000 | Loss: 0.00002049
Iteration 235/1000 | Loss: 0.00002049
Iteration 236/1000 | Loss: 0.00002049
Iteration 237/1000 | Loss: 0.00002049
Iteration 238/1000 | Loss: 0.00002049
Iteration 239/1000 | Loss: 0.00002049
Iteration 240/1000 | Loss: 0.00002049
Iteration 241/1000 | Loss: 0.00002049
Iteration 242/1000 | Loss: 0.00002049
Iteration 243/1000 | Loss: 0.00002049
Iteration 244/1000 | Loss: 0.00002049
Iteration 245/1000 | Loss: 0.00002049
Iteration 246/1000 | Loss: 0.00002049
Iteration 247/1000 | Loss: 0.00002049
Iteration 248/1000 | Loss: 0.00002049
Iteration 249/1000 | Loss: 0.00002049
Iteration 250/1000 | Loss: 0.00002049
Iteration 251/1000 | Loss: 0.00002049
Iteration 252/1000 | Loss: 0.00002049
Iteration 253/1000 | Loss: 0.00002049
Iteration 254/1000 | Loss: 0.00002049
Iteration 255/1000 | Loss: 0.00002049
Iteration 256/1000 | Loss: 0.00002049
Iteration 257/1000 | Loss: 0.00002049
Iteration 258/1000 | Loss: 0.00002049
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 258. Stopping optimization.
Last 5 losses: [2.048669193754904e-05, 2.048669193754904e-05, 2.048669193754904e-05, 2.048669193754904e-05, 2.048669193754904e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.048669193754904e-05

Optimization complete. Final v2v error: 3.8542966842651367 mm

Highest mean error: 4.312459945678711 mm for frame 42

Lowest mean error: 3.592188835144043 mm for frame 28

Saving results

Total time: 267.6456563472748
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1029/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1029.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1029
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01052052
Iteration 2/25 | Loss: 0.00248022
Iteration 3/25 | Loss: 0.00291002
Iteration 4/25 | Loss: 0.00183171
Iteration 5/25 | Loss: 0.00118115
Iteration 6/25 | Loss: 0.00111970
Iteration 7/25 | Loss: 0.00094098
Iteration 8/25 | Loss: 0.00093719
Iteration 9/25 | Loss: 0.00091631
Iteration 10/25 | Loss: 0.00087062
Iteration 11/25 | Loss: 0.00085941
Iteration 12/25 | Loss: 0.00085406
Iteration 13/25 | Loss: 0.00084555
Iteration 14/25 | Loss: 0.00083607
Iteration 15/25 | Loss: 0.00083357
Iteration 16/25 | Loss: 0.00082947
Iteration 17/25 | Loss: 0.00083014
Iteration 18/25 | Loss: 0.00082757
Iteration 19/25 | Loss: 0.00082859
Iteration 20/25 | Loss: 0.00082893
Iteration 21/25 | Loss: 0.00083079
Iteration 22/25 | Loss: 0.00082908
Iteration 23/25 | Loss: 0.00082806
Iteration 24/25 | Loss: 0.00082836
Iteration 25/25 | Loss: 0.00082699

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56666589
Iteration 2/25 | Loss: 0.00064816
Iteration 3/25 | Loss: 0.00052545
Iteration 4/25 | Loss: 0.00052545
Iteration 5/25 | Loss: 0.00052545
Iteration 6/25 | Loss: 0.00052545
Iteration 7/25 | Loss: 0.00052545
Iteration 8/25 | Loss: 0.00052545
Iteration 9/25 | Loss: 0.00052545
Iteration 10/25 | Loss: 0.00052545
Iteration 11/25 | Loss: 0.00052545
Iteration 12/25 | Loss: 0.00052545
Iteration 13/25 | Loss: 0.00052545
Iteration 14/25 | Loss: 0.00052545
Iteration 15/25 | Loss: 0.00052545
Iteration 16/25 | Loss: 0.00052545
Iteration 17/25 | Loss: 0.00052545
Iteration 18/25 | Loss: 0.00052545
Iteration 19/25 | Loss: 0.00052545
Iteration 20/25 | Loss: 0.00052545
Iteration 21/25 | Loss: 0.00052545
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0005254496936686337, 0.0005254496936686337, 0.0005254496936686337, 0.0005254496936686337, 0.0005254496936686337]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005254496936686337

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052545
Iteration 2/1000 | Loss: 0.00018159
Iteration 3/1000 | Loss: 0.00023440
Iteration 4/1000 | Loss: 0.00017465
Iteration 5/1000 | Loss: 0.00018297
Iteration 6/1000 | Loss: 0.00016110
Iteration 7/1000 | Loss: 0.00019317
Iteration 8/1000 | Loss: 0.00015689
Iteration 9/1000 | Loss: 0.00002692
Iteration 10/1000 | Loss: 0.00017382
Iteration 11/1000 | Loss: 0.00002314
Iteration 12/1000 | Loss: 0.00002166
Iteration 13/1000 | Loss: 0.00002085
Iteration 14/1000 | Loss: 0.00002024
Iteration 15/1000 | Loss: 0.00001979
Iteration 16/1000 | Loss: 0.00023601
Iteration 17/1000 | Loss: 0.00007579
Iteration 18/1000 | Loss: 0.00001956
Iteration 19/1000 | Loss: 0.00001934
Iteration 20/1000 | Loss: 0.00001918
Iteration 21/1000 | Loss: 0.00001909
Iteration 22/1000 | Loss: 0.00022187
Iteration 23/1000 | Loss: 0.00002005
Iteration 24/1000 | Loss: 0.00001892
Iteration 25/1000 | Loss: 0.00001889
Iteration 26/1000 | Loss: 0.00001888
Iteration 27/1000 | Loss: 0.00001888
Iteration 28/1000 | Loss: 0.00001888
Iteration 29/1000 | Loss: 0.00001887
Iteration 30/1000 | Loss: 0.00001887
Iteration 31/1000 | Loss: 0.00001883
Iteration 32/1000 | Loss: 0.00001882
Iteration 33/1000 | Loss: 0.00001881
Iteration 34/1000 | Loss: 0.00001881
Iteration 35/1000 | Loss: 0.00001880
Iteration 36/1000 | Loss: 0.00001880
Iteration 37/1000 | Loss: 0.00001879
Iteration 38/1000 | Loss: 0.00001879
Iteration 39/1000 | Loss: 0.00001879
Iteration 40/1000 | Loss: 0.00001879
Iteration 41/1000 | Loss: 0.00001879
Iteration 42/1000 | Loss: 0.00001879
Iteration 43/1000 | Loss: 0.00001879
Iteration 44/1000 | Loss: 0.00001879
Iteration 45/1000 | Loss: 0.00001879
Iteration 46/1000 | Loss: 0.00001879
Iteration 47/1000 | Loss: 0.00001878
Iteration 48/1000 | Loss: 0.00001878
Iteration 49/1000 | Loss: 0.00001878
Iteration 50/1000 | Loss: 0.00001878
Iteration 51/1000 | Loss: 0.00001877
Iteration 52/1000 | Loss: 0.00001877
Iteration 53/1000 | Loss: 0.00001876
Iteration 54/1000 | Loss: 0.00001876
Iteration 55/1000 | Loss: 0.00001876
Iteration 56/1000 | Loss: 0.00001875
Iteration 57/1000 | Loss: 0.00001875
Iteration 58/1000 | Loss: 0.00001875
Iteration 59/1000 | Loss: 0.00001874
Iteration 60/1000 | Loss: 0.00001874
Iteration 61/1000 | Loss: 0.00001874
Iteration 62/1000 | Loss: 0.00001874
Iteration 63/1000 | Loss: 0.00001874
Iteration 64/1000 | Loss: 0.00001873
Iteration 65/1000 | Loss: 0.00001873
Iteration 66/1000 | Loss: 0.00001873
Iteration 67/1000 | Loss: 0.00001873
Iteration 68/1000 | Loss: 0.00001873
Iteration 69/1000 | Loss: 0.00001873
Iteration 70/1000 | Loss: 0.00001873
Iteration 71/1000 | Loss: 0.00001872
Iteration 72/1000 | Loss: 0.00001872
Iteration 73/1000 | Loss: 0.00001872
Iteration 74/1000 | Loss: 0.00001871
Iteration 75/1000 | Loss: 0.00001871
Iteration 76/1000 | Loss: 0.00001871
Iteration 77/1000 | Loss: 0.00001870
Iteration 78/1000 | Loss: 0.00001870
Iteration 79/1000 | Loss: 0.00001870
Iteration 80/1000 | Loss: 0.00001869
Iteration 81/1000 | Loss: 0.00001869
Iteration 82/1000 | Loss: 0.00001869
Iteration 83/1000 | Loss: 0.00001868
Iteration 84/1000 | Loss: 0.00001868
Iteration 85/1000 | Loss: 0.00001866
Iteration 86/1000 | Loss: 0.00001866
Iteration 87/1000 | Loss: 0.00001865
Iteration 88/1000 | Loss: 0.00001865
Iteration 89/1000 | Loss: 0.00001865
Iteration 90/1000 | Loss: 0.00001864
Iteration 91/1000 | Loss: 0.00001864
Iteration 92/1000 | Loss: 0.00001864
Iteration 93/1000 | Loss: 0.00001864
Iteration 94/1000 | Loss: 0.00001864
Iteration 95/1000 | Loss: 0.00001863
Iteration 96/1000 | Loss: 0.00001863
Iteration 97/1000 | Loss: 0.00001863
Iteration 98/1000 | Loss: 0.00001862
Iteration 99/1000 | Loss: 0.00001862
Iteration 100/1000 | Loss: 0.00001862
Iteration 101/1000 | Loss: 0.00001862
Iteration 102/1000 | Loss: 0.00001861
Iteration 103/1000 | Loss: 0.00001861
Iteration 104/1000 | Loss: 0.00001861
Iteration 105/1000 | Loss: 0.00001860
Iteration 106/1000 | Loss: 0.00001860
Iteration 107/1000 | Loss: 0.00001860
Iteration 108/1000 | Loss: 0.00001860
Iteration 109/1000 | Loss: 0.00001860
Iteration 110/1000 | Loss: 0.00001859
Iteration 111/1000 | Loss: 0.00001859
Iteration 112/1000 | Loss: 0.00001859
Iteration 113/1000 | Loss: 0.00001859
Iteration 114/1000 | Loss: 0.00001859
Iteration 115/1000 | Loss: 0.00001859
Iteration 116/1000 | Loss: 0.00001859
Iteration 117/1000 | Loss: 0.00001859
Iteration 118/1000 | Loss: 0.00001858
Iteration 119/1000 | Loss: 0.00001858
Iteration 120/1000 | Loss: 0.00001858
Iteration 121/1000 | Loss: 0.00001858
Iteration 122/1000 | Loss: 0.00001858
Iteration 123/1000 | Loss: 0.00001858
Iteration 124/1000 | Loss: 0.00001858
Iteration 125/1000 | Loss: 0.00001858
Iteration 126/1000 | Loss: 0.00001858
Iteration 127/1000 | Loss: 0.00001857
Iteration 128/1000 | Loss: 0.00001857
Iteration 129/1000 | Loss: 0.00001857
Iteration 130/1000 | Loss: 0.00001857
Iteration 131/1000 | Loss: 0.00001857
Iteration 132/1000 | Loss: 0.00001857
Iteration 133/1000 | Loss: 0.00001857
Iteration 134/1000 | Loss: 0.00001857
Iteration 135/1000 | Loss: 0.00001856
Iteration 136/1000 | Loss: 0.00001856
Iteration 137/1000 | Loss: 0.00001856
Iteration 138/1000 | Loss: 0.00001856
Iteration 139/1000 | Loss: 0.00001856
Iteration 140/1000 | Loss: 0.00001856
Iteration 141/1000 | Loss: 0.00001856
Iteration 142/1000 | Loss: 0.00001856
Iteration 143/1000 | Loss: 0.00001855
Iteration 144/1000 | Loss: 0.00001855
Iteration 145/1000 | Loss: 0.00001855
Iteration 146/1000 | Loss: 0.00001855
Iteration 147/1000 | Loss: 0.00001854
Iteration 148/1000 | Loss: 0.00001854
Iteration 149/1000 | Loss: 0.00001853
Iteration 150/1000 | Loss: 0.00001852
Iteration 151/1000 | Loss: 0.00001852
Iteration 152/1000 | Loss: 0.00001852
Iteration 153/1000 | Loss: 0.00001852
Iteration 154/1000 | Loss: 0.00001852
Iteration 155/1000 | Loss: 0.00001852
Iteration 156/1000 | Loss: 0.00001852
Iteration 157/1000 | Loss: 0.00001852
Iteration 158/1000 | Loss: 0.00001852
Iteration 159/1000 | Loss: 0.00001852
Iteration 160/1000 | Loss: 0.00001852
Iteration 161/1000 | Loss: 0.00001851
Iteration 162/1000 | Loss: 0.00001851
Iteration 163/1000 | Loss: 0.00001851
Iteration 164/1000 | Loss: 0.00001851
Iteration 165/1000 | Loss: 0.00001850
Iteration 166/1000 | Loss: 0.00001850
Iteration 167/1000 | Loss: 0.00001850
Iteration 168/1000 | Loss: 0.00001849
Iteration 169/1000 | Loss: 0.00001849
Iteration 170/1000 | Loss: 0.00001849
Iteration 171/1000 | Loss: 0.00001848
Iteration 172/1000 | Loss: 0.00001848
Iteration 173/1000 | Loss: 0.00001848
Iteration 174/1000 | Loss: 0.00001848
Iteration 175/1000 | Loss: 0.00001847
Iteration 176/1000 | Loss: 0.00001847
Iteration 177/1000 | Loss: 0.00001847
Iteration 178/1000 | Loss: 0.00001847
Iteration 179/1000 | Loss: 0.00001847
Iteration 180/1000 | Loss: 0.00001847
Iteration 181/1000 | Loss: 0.00001847
Iteration 182/1000 | Loss: 0.00001847
Iteration 183/1000 | Loss: 0.00001846
Iteration 184/1000 | Loss: 0.00001846
Iteration 185/1000 | Loss: 0.00001846
Iteration 186/1000 | Loss: 0.00001846
Iteration 187/1000 | Loss: 0.00001846
Iteration 188/1000 | Loss: 0.00001846
Iteration 189/1000 | Loss: 0.00001846
Iteration 190/1000 | Loss: 0.00001846
Iteration 191/1000 | Loss: 0.00001846
Iteration 192/1000 | Loss: 0.00001845
Iteration 193/1000 | Loss: 0.00001845
Iteration 194/1000 | Loss: 0.00001845
Iteration 195/1000 | Loss: 0.00001845
Iteration 196/1000 | Loss: 0.00001845
Iteration 197/1000 | Loss: 0.00001845
Iteration 198/1000 | Loss: 0.00001845
Iteration 199/1000 | Loss: 0.00001845
Iteration 200/1000 | Loss: 0.00001845
Iteration 201/1000 | Loss: 0.00001845
Iteration 202/1000 | Loss: 0.00001845
Iteration 203/1000 | Loss: 0.00001845
Iteration 204/1000 | Loss: 0.00001845
Iteration 205/1000 | Loss: 0.00001845
Iteration 206/1000 | Loss: 0.00001845
Iteration 207/1000 | Loss: 0.00001845
Iteration 208/1000 | Loss: 0.00001845
Iteration 209/1000 | Loss: 0.00001845
Iteration 210/1000 | Loss: 0.00001845
Iteration 211/1000 | Loss: 0.00001845
Iteration 212/1000 | Loss: 0.00001845
Iteration 213/1000 | Loss: 0.00001845
Iteration 214/1000 | Loss: 0.00001845
Iteration 215/1000 | Loss: 0.00001845
Iteration 216/1000 | Loss: 0.00001845
Iteration 217/1000 | Loss: 0.00001845
Iteration 218/1000 | Loss: 0.00001845
Iteration 219/1000 | Loss: 0.00001845
Iteration 220/1000 | Loss: 0.00001845
Iteration 221/1000 | Loss: 0.00001845
Iteration 222/1000 | Loss: 0.00001845
Iteration 223/1000 | Loss: 0.00001845
Iteration 224/1000 | Loss: 0.00001845
Iteration 225/1000 | Loss: 0.00001845
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 225. Stopping optimization.
Last 5 losses: [1.8447050024406053e-05, 1.8447050024406053e-05, 1.8447050024406053e-05, 1.8447050024406053e-05, 1.8447050024406053e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8447050024406053e-05

Optimization complete. Final v2v error: 3.560512065887451 mm

Highest mean error: 5.095442295074463 mm for frame 108

Lowest mean error: 2.951648712158203 mm for frame 183

Saving results

Total time: 108.84925603866577
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00839692
Iteration 2/25 | Loss: 0.00122929
Iteration 3/25 | Loss: 0.00086417
Iteration 4/25 | Loss: 0.00083041
Iteration 5/25 | Loss: 0.00082224
Iteration 6/25 | Loss: 0.00081900
Iteration 7/25 | Loss: 0.00082613
Iteration 8/25 | Loss: 0.00082487
Iteration 9/25 | Loss: 0.00082240
Iteration 10/25 | Loss: 0.00082557
Iteration 11/25 | Loss: 0.00082482
Iteration 12/25 | Loss: 0.00081640
Iteration 13/25 | Loss: 0.00081354
Iteration 14/25 | Loss: 0.00081327
Iteration 15/25 | Loss: 0.00081491
Iteration 16/25 | Loss: 0.00081302
Iteration 17/25 | Loss: 0.00080978
Iteration 18/25 | Loss: 0.00080867
Iteration 19/25 | Loss: 0.00080817
Iteration 20/25 | Loss: 0.00080793
Iteration 21/25 | Loss: 0.00080788
Iteration 22/25 | Loss: 0.00080788
Iteration 23/25 | Loss: 0.00080788
Iteration 24/25 | Loss: 0.00080788
Iteration 25/25 | Loss: 0.00080788

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.45846844
Iteration 2/25 | Loss: 0.00053455
Iteration 3/25 | Loss: 0.00053455
Iteration 4/25 | Loss: 0.00053455
Iteration 5/25 | Loss: 0.00053455
Iteration 6/25 | Loss: 0.00053455
Iteration 7/25 | Loss: 0.00053455
Iteration 8/25 | Loss: 0.00053455
Iteration 9/25 | Loss: 0.00053455
Iteration 10/25 | Loss: 0.00053455
Iteration 11/25 | Loss: 0.00053455
Iteration 12/25 | Loss: 0.00053455
Iteration 13/25 | Loss: 0.00053455
Iteration 14/25 | Loss: 0.00053455
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0005345501122064888, 0.0005345501122064888, 0.0005345501122064888, 0.0005345501122064888, 0.0005345501122064888]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005345501122064888

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053455
Iteration 2/1000 | Loss: 0.00003634
Iteration 3/1000 | Loss: 0.00002383
Iteration 4/1000 | Loss: 0.00002103
Iteration 5/1000 | Loss: 0.00001992
Iteration 6/1000 | Loss: 0.00001923
Iteration 7/1000 | Loss: 0.00001871
Iteration 8/1000 | Loss: 0.00001832
Iteration 9/1000 | Loss: 0.00001804
Iteration 10/1000 | Loss: 0.00001790
Iteration 11/1000 | Loss: 0.00001780
Iteration 12/1000 | Loss: 0.00001777
Iteration 13/1000 | Loss: 0.00001776
Iteration 14/1000 | Loss: 0.00001773
Iteration 15/1000 | Loss: 0.00001768
Iteration 16/1000 | Loss: 0.00001767
Iteration 17/1000 | Loss: 0.00001765
Iteration 18/1000 | Loss: 0.00001764
Iteration 19/1000 | Loss: 0.00001764
Iteration 20/1000 | Loss: 0.00001763
Iteration 21/1000 | Loss: 0.00001763
Iteration 22/1000 | Loss: 0.00001763
Iteration 23/1000 | Loss: 0.00001762
Iteration 24/1000 | Loss: 0.00001762
Iteration 25/1000 | Loss: 0.00001761
Iteration 26/1000 | Loss: 0.00001760
Iteration 27/1000 | Loss: 0.00001760
Iteration 28/1000 | Loss: 0.00001759
Iteration 29/1000 | Loss: 0.00001759
Iteration 30/1000 | Loss: 0.00001758
Iteration 31/1000 | Loss: 0.00001758
Iteration 32/1000 | Loss: 0.00001756
Iteration 33/1000 | Loss: 0.00001755
Iteration 34/1000 | Loss: 0.00001754
Iteration 35/1000 | Loss: 0.00001754
Iteration 36/1000 | Loss: 0.00001753
Iteration 37/1000 | Loss: 0.00001753
Iteration 38/1000 | Loss: 0.00001753
Iteration 39/1000 | Loss: 0.00001752
Iteration 40/1000 | Loss: 0.00001752
Iteration 41/1000 | Loss: 0.00001751
Iteration 42/1000 | Loss: 0.00001750
Iteration 43/1000 | Loss: 0.00001750
Iteration 44/1000 | Loss: 0.00001750
Iteration 45/1000 | Loss: 0.00001750
Iteration 46/1000 | Loss: 0.00001750
Iteration 47/1000 | Loss: 0.00001750
Iteration 48/1000 | Loss: 0.00001750
Iteration 49/1000 | Loss: 0.00001749
Iteration 50/1000 | Loss: 0.00001749
Iteration 51/1000 | Loss: 0.00001749
Iteration 52/1000 | Loss: 0.00001748
Iteration 53/1000 | Loss: 0.00001748
Iteration 54/1000 | Loss: 0.00001747
Iteration 55/1000 | Loss: 0.00001747
Iteration 56/1000 | Loss: 0.00001747
Iteration 57/1000 | Loss: 0.00001746
Iteration 58/1000 | Loss: 0.00001746
Iteration 59/1000 | Loss: 0.00001746
Iteration 60/1000 | Loss: 0.00001746
Iteration 61/1000 | Loss: 0.00001746
Iteration 62/1000 | Loss: 0.00001746
Iteration 63/1000 | Loss: 0.00001745
Iteration 64/1000 | Loss: 0.00001745
Iteration 65/1000 | Loss: 0.00001745
Iteration 66/1000 | Loss: 0.00001745
Iteration 67/1000 | Loss: 0.00001745
Iteration 68/1000 | Loss: 0.00001745
Iteration 69/1000 | Loss: 0.00001745
Iteration 70/1000 | Loss: 0.00001745
Iteration 71/1000 | Loss: 0.00001745
Iteration 72/1000 | Loss: 0.00001744
Iteration 73/1000 | Loss: 0.00001744
Iteration 74/1000 | Loss: 0.00001744
Iteration 75/1000 | Loss: 0.00001743
Iteration 76/1000 | Loss: 0.00001743
Iteration 77/1000 | Loss: 0.00001743
Iteration 78/1000 | Loss: 0.00001743
Iteration 79/1000 | Loss: 0.00001743
Iteration 80/1000 | Loss: 0.00001743
Iteration 81/1000 | Loss: 0.00001743
Iteration 82/1000 | Loss: 0.00001743
Iteration 83/1000 | Loss: 0.00001743
Iteration 84/1000 | Loss: 0.00001742
Iteration 85/1000 | Loss: 0.00001742
Iteration 86/1000 | Loss: 0.00001742
Iteration 87/1000 | Loss: 0.00001742
Iteration 88/1000 | Loss: 0.00001742
Iteration 89/1000 | Loss: 0.00001741
Iteration 90/1000 | Loss: 0.00001741
Iteration 91/1000 | Loss: 0.00001741
Iteration 92/1000 | Loss: 0.00001741
Iteration 93/1000 | Loss: 0.00001741
Iteration 94/1000 | Loss: 0.00001741
Iteration 95/1000 | Loss: 0.00001741
Iteration 96/1000 | Loss: 0.00001740
Iteration 97/1000 | Loss: 0.00001740
Iteration 98/1000 | Loss: 0.00001740
Iteration 99/1000 | Loss: 0.00001739
Iteration 100/1000 | Loss: 0.00001739
Iteration 101/1000 | Loss: 0.00001739
Iteration 102/1000 | Loss: 0.00001739
Iteration 103/1000 | Loss: 0.00001739
Iteration 104/1000 | Loss: 0.00001738
Iteration 105/1000 | Loss: 0.00001738
Iteration 106/1000 | Loss: 0.00001738
Iteration 107/1000 | Loss: 0.00001738
Iteration 108/1000 | Loss: 0.00001738
Iteration 109/1000 | Loss: 0.00001738
Iteration 110/1000 | Loss: 0.00001738
Iteration 111/1000 | Loss: 0.00001738
Iteration 112/1000 | Loss: 0.00001738
Iteration 113/1000 | Loss: 0.00001738
Iteration 114/1000 | Loss: 0.00001737
Iteration 115/1000 | Loss: 0.00001737
Iteration 116/1000 | Loss: 0.00001737
Iteration 117/1000 | Loss: 0.00001737
Iteration 118/1000 | Loss: 0.00001737
Iteration 119/1000 | Loss: 0.00001737
Iteration 120/1000 | Loss: 0.00001736
Iteration 121/1000 | Loss: 0.00001736
Iteration 122/1000 | Loss: 0.00001736
Iteration 123/1000 | Loss: 0.00001736
Iteration 124/1000 | Loss: 0.00001736
Iteration 125/1000 | Loss: 0.00001736
Iteration 126/1000 | Loss: 0.00001736
Iteration 127/1000 | Loss: 0.00001736
Iteration 128/1000 | Loss: 0.00001735
Iteration 129/1000 | Loss: 0.00001735
Iteration 130/1000 | Loss: 0.00001735
Iteration 131/1000 | Loss: 0.00001735
Iteration 132/1000 | Loss: 0.00001735
Iteration 133/1000 | Loss: 0.00001735
Iteration 134/1000 | Loss: 0.00001734
Iteration 135/1000 | Loss: 0.00001734
Iteration 136/1000 | Loss: 0.00001734
Iteration 137/1000 | Loss: 0.00001734
Iteration 138/1000 | Loss: 0.00001734
Iteration 139/1000 | Loss: 0.00001734
Iteration 140/1000 | Loss: 0.00001734
Iteration 141/1000 | Loss: 0.00001734
Iteration 142/1000 | Loss: 0.00001734
Iteration 143/1000 | Loss: 0.00001733
Iteration 144/1000 | Loss: 0.00001733
Iteration 145/1000 | Loss: 0.00001733
Iteration 146/1000 | Loss: 0.00001733
Iteration 147/1000 | Loss: 0.00001733
Iteration 148/1000 | Loss: 0.00001733
Iteration 149/1000 | Loss: 0.00001733
Iteration 150/1000 | Loss: 0.00001733
Iteration 151/1000 | Loss: 0.00001733
Iteration 152/1000 | Loss: 0.00001733
Iteration 153/1000 | Loss: 0.00001733
Iteration 154/1000 | Loss: 0.00001733
Iteration 155/1000 | Loss: 0.00001733
Iteration 156/1000 | Loss: 0.00001733
Iteration 157/1000 | Loss: 0.00001733
Iteration 158/1000 | Loss: 0.00001733
Iteration 159/1000 | Loss: 0.00001733
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 159. Stopping optimization.
Last 5 losses: [1.7333437426714227e-05, 1.7333437426714227e-05, 1.7333437426714227e-05, 1.7333437426714227e-05, 1.7333437426714227e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7333437426714227e-05

Optimization complete. Final v2v error: 3.4510719776153564 mm

Highest mean error: 4.1025309562683105 mm for frame 96

Lowest mean error: 2.946265935897827 mm for frame 48

Saving results

Total time: 60.96545386314392
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1033/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1033.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1033
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00406888
Iteration 2/25 | Loss: 0.00085358
Iteration 3/25 | Loss: 0.00074863
Iteration 4/25 | Loss: 0.00073358
Iteration 5/25 | Loss: 0.00072802
Iteration 6/25 | Loss: 0.00072670
Iteration 7/25 | Loss: 0.00072662
Iteration 8/25 | Loss: 0.00072662
Iteration 9/25 | Loss: 0.00072662
Iteration 10/25 | Loss: 0.00072662
Iteration 11/25 | Loss: 0.00072662
Iteration 12/25 | Loss: 0.00072662
Iteration 13/25 | Loss: 0.00072662
Iteration 14/25 | Loss: 0.00072662
Iteration 15/25 | Loss: 0.00072662
Iteration 16/25 | Loss: 0.00072662
Iteration 17/25 | Loss: 0.00072662
Iteration 18/25 | Loss: 0.00072662
Iteration 19/25 | Loss: 0.00072662
Iteration 20/25 | Loss: 0.00072662
Iteration 21/25 | Loss: 0.00072662
Iteration 22/25 | Loss: 0.00072662
Iteration 23/25 | Loss: 0.00072662
Iteration 24/25 | Loss: 0.00072662
Iteration 25/25 | Loss: 0.00072662

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50383151
Iteration 2/25 | Loss: 0.00049065
Iteration 3/25 | Loss: 0.00049065
Iteration 4/25 | Loss: 0.00049065
Iteration 5/25 | Loss: 0.00049065
Iteration 6/25 | Loss: 0.00049064
Iteration 7/25 | Loss: 0.00049064
Iteration 8/25 | Loss: 0.00049064
Iteration 9/25 | Loss: 0.00049064
Iteration 10/25 | Loss: 0.00049064
Iteration 11/25 | Loss: 0.00049064
Iteration 12/25 | Loss: 0.00049064
Iteration 13/25 | Loss: 0.00049064
Iteration 14/25 | Loss: 0.00049064
Iteration 15/25 | Loss: 0.00049064
Iteration 16/25 | Loss: 0.00049064
Iteration 17/25 | Loss: 0.00049064
Iteration 18/25 | Loss: 0.00049064
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0004906432004645467, 0.0004906432004645467, 0.0004906432004645467, 0.0004906432004645467, 0.0004906432004645467]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004906432004645467

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049064
Iteration 2/1000 | Loss: 0.00002370
Iteration 3/1000 | Loss: 0.00001678
Iteration 4/1000 | Loss: 0.00001510
Iteration 5/1000 | Loss: 0.00001406
Iteration 6/1000 | Loss: 0.00001362
Iteration 7/1000 | Loss: 0.00001336
Iteration 8/1000 | Loss: 0.00001324
Iteration 9/1000 | Loss: 0.00001305
Iteration 10/1000 | Loss: 0.00001288
Iteration 11/1000 | Loss: 0.00001287
Iteration 12/1000 | Loss: 0.00001278
Iteration 13/1000 | Loss: 0.00001268
Iteration 14/1000 | Loss: 0.00001263
Iteration 15/1000 | Loss: 0.00001260
Iteration 16/1000 | Loss: 0.00001260
Iteration 17/1000 | Loss: 0.00001260
Iteration 18/1000 | Loss: 0.00001259
Iteration 19/1000 | Loss: 0.00001256
Iteration 20/1000 | Loss: 0.00001255
Iteration 21/1000 | Loss: 0.00001254
Iteration 22/1000 | Loss: 0.00001252
Iteration 23/1000 | Loss: 0.00001252
Iteration 24/1000 | Loss: 0.00001247
Iteration 25/1000 | Loss: 0.00001247
Iteration 26/1000 | Loss: 0.00001247
Iteration 27/1000 | Loss: 0.00001247
Iteration 28/1000 | Loss: 0.00001246
Iteration 29/1000 | Loss: 0.00001246
Iteration 30/1000 | Loss: 0.00001246
Iteration 31/1000 | Loss: 0.00001246
Iteration 32/1000 | Loss: 0.00001246
Iteration 33/1000 | Loss: 0.00001246
Iteration 34/1000 | Loss: 0.00001246
Iteration 35/1000 | Loss: 0.00001246
Iteration 36/1000 | Loss: 0.00001245
Iteration 37/1000 | Loss: 0.00001244
Iteration 38/1000 | Loss: 0.00001244
Iteration 39/1000 | Loss: 0.00001243
Iteration 40/1000 | Loss: 0.00001242
Iteration 41/1000 | Loss: 0.00001242
Iteration 42/1000 | Loss: 0.00001242
Iteration 43/1000 | Loss: 0.00001241
Iteration 44/1000 | Loss: 0.00001241
Iteration 45/1000 | Loss: 0.00001241
Iteration 46/1000 | Loss: 0.00001240
Iteration 47/1000 | Loss: 0.00001240
Iteration 48/1000 | Loss: 0.00001240
Iteration 49/1000 | Loss: 0.00001239
Iteration 50/1000 | Loss: 0.00001239
Iteration 51/1000 | Loss: 0.00001238
Iteration 52/1000 | Loss: 0.00001238
Iteration 53/1000 | Loss: 0.00001237
Iteration 54/1000 | Loss: 0.00001237
Iteration 55/1000 | Loss: 0.00001237
Iteration 56/1000 | Loss: 0.00001237
Iteration 57/1000 | Loss: 0.00001237
Iteration 58/1000 | Loss: 0.00001237
Iteration 59/1000 | Loss: 0.00001237
Iteration 60/1000 | Loss: 0.00001237
Iteration 61/1000 | Loss: 0.00001236
Iteration 62/1000 | Loss: 0.00001235
Iteration 63/1000 | Loss: 0.00001233
Iteration 64/1000 | Loss: 0.00001233
Iteration 65/1000 | Loss: 0.00001232
Iteration 66/1000 | Loss: 0.00001232
Iteration 67/1000 | Loss: 0.00001231
Iteration 68/1000 | Loss: 0.00001228
Iteration 69/1000 | Loss: 0.00001228
Iteration 70/1000 | Loss: 0.00001227
Iteration 71/1000 | Loss: 0.00001227
Iteration 72/1000 | Loss: 0.00001227
Iteration 73/1000 | Loss: 0.00001226
Iteration 74/1000 | Loss: 0.00001226
Iteration 75/1000 | Loss: 0.00001225
Iteration 76/1000 | Loss: 0.00001225
Iteration 77/1000 | Loss: 0.00001224
Iteration 78/1000 | Loss: 0.00001224
Iteration 79/1000 | Loss: 0.00001223
Iteration 80/1000 | Loss: 0.00001223
Iteration 81/1000 | Loss: 0.00001223
Iteration 82/1000 | Loss: 0.00001223
Iteration 83/1000 | Loss: 0.00001222
Iteration 84/1000 | Loss: 0.00001222
Iteration 85/1000 | Loss: 0.00001221
Iteration 86/1000 | Loss: 0.00001221
Iteration 87/1000 | Loss: 0.00001221
Iteration 88/1000 | Loss: 0.00001221
Iteration 89/1000 | Loss: 0.00001221
Iteration 90/1000 | Loss: 0.00001221
Iteration 91/1000 | Loss: 0.00001221
Iteration 92/1000 | Loss: 0.00001221
Iteration 93/1000 | Loss: 0.00001221
Iteration 94/1000 | Loss: 0.00001221
Iteration 95/1000 | Loss: 0.00001221
Iteration 96/1000 | Loss: 0.00001220
Iteration 97/1000 | Loss: 0.00001220
Iteration 98/1000 | Loss: 0.00001220
Iteration 99/1000 | Loss: 0.00001220
Iteration 100/1000 | Loss: 0.00001220
Iteration 101/1000 | Loss: 0.00001220
Iteration 102/1000 | Loss: 0.00001220
Iteration 103/1000 | Loss: 0.00001220
Iteration 104/1000 | Loss: 0.00001219
Iteration 105/1000 | Loss: 0.00001219
Iteration 106/1000 | Loss: 0.00001219
Iteration 107/1000 | Loss: 0.00001219
Iteration 108/1000 | Loss: 0.00001219
Iteration 109/1000 | Loss: 0.00001219
Iteration 110/1000 | Loss: 0.00001219
Iteration 111/1000 | Loss: 0.00001218
Iteration 112/1000 | Loss: 0.00001218
Iteration 113/1000 | Loss: 0.00001218
Iteration 114/1000 | Loss: 0.00001218
Iteration 115/1000 | Loss: 0.00001218
Iteration 116/1000 | Loss: 0.00001218
Iteration 117/1000 | Loss: 0.00001218
Iteration 118/1000 | Loss: 0.00001217
Iteration 119/1000 | Loss: 0.00001217
Iteration 120/1000 | Loss: 0.00001217
Iteration 121/1000 | Loss: 0.00001217
Iteration 122/1000 | Loss: 0.00001216
Iteration 123/1000 | Loss: 0.00001216
Iteration 124/1000 | Loss: 0.00001216
Iteration 125/1000 | Loss: 0.00001215
Iteration 126/1000 | Loss: 0.00001215
Iteration 127/1000 | Loss: 0.00001215
Iteration 128/1000 | Loss: 0.00001215
Iteration 129/1000 | Loss: 0.00001215
Iteration 130/1000 | Loss: 0.00001215
Iteration 131/1000 | Loss: 0.00001215
Iteration 132/1000 | Loss: 0.00001215
Iteration 133/1000 | Loss: 0.00001214
Iteration 134/1000 | Loss: 0.00001214
Iteration 135/1000 | Loss: 0.00001214
Iteration 136/1000 | Loss: 0.00001214
Iteration 137/1000 | Loss: 0.00001214
Iteration 138/1000 | Loss: 0.00001214
Iteration 139/1000 | Loss: 0.00001214
Iteration 140/1000 | Loss: 0.00001214
Iteration 141/1000 | Loss: 0.00001213
Iteration 142/1000 | Loss: 0.00001213
Iteration 143/1000 | Loss: 0.00001213
Iteration 144/1000 | Loss: 0.00001213
Iteration 145/1000 | Loss: 0.00001213
Iteration 146/1000 | Loss: 0.00001213
Iteration 147/1000 | Loss: 0.00001213
Iteration 148/1000 | Loss: 0.00001213
Iteration 149/1000 | Loss: 0.00001212
Iteration 150/1000 | Loss: 0.00001212
Iteration 151/1000 | Loss: 0.00001212
Iteration 152/1000 | Loss: 0.00001212
Iteration 153/1000 | Loss: 0.00001212
Iteration 154/1000 | Loss: 0.00001212
Iteration 155/1000 | Loss: 0.00001212
Iteration 156/1000 | Loss: 0.00001212
Iteration 157/1000 | Loss: 0.00001212
Iteration 158/1000 | Loss: 0.00001212
Iteration 159/1000 | Loss: 0.00001212
Iteration 160/1000 | Loss: 0.00001211
Iteration 161/1000 | Loss: 0.00001211
Iteration 162/1000 | Loss: 0.00001211
Iteration 163/1000 | Loss: 0.00001211
Iteration 164/1000 | Loss: 0.00001211
Iteration 165/1000 | Loss: 0.00001211
Iteration 166/1000 | Loss: 0.00001211
Iteration 167/1000 | Loss: 0.00001211
Iteration 168/1000 | Loss: 0.00001211
Iteration 169/1000 | Loss: 0.00001211
Iteration 170/1000 | Loss: 0.00001211
Iteration 171/1000 | Loss: 0.00001211
Iteration 172/1000 | Loss: 0.00001211
Iteration 173/1000 | Loss: 0.00001211
Iteration 174/1000 | Loss: 0.00001211
Iteration 175/1000 | Loss: 0.00001211
Iteration 176/1000 | Loss: 0.00001211
Iteration 177/1000 | Loss: 0.00001211
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 177. Stopping optimization.
Last 5 losses: [1.2110524039599113e-05, 1.2110524039599113e-05, 1.2110524039599113e-05, 1.2110524039599113e-05, 1.2110524039599113e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2110524039599113e-05

Optimization complete. Final v2v error: 2.97855281829834 mm

Highest mean error: 3.563237190246582 mm for frame 229

Lowest mean error: 2.6252737045288086 mm for frame 120

Saving results

Total time: 43.14763641357422
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00502567
Iteration 2/25 | Loss: 0.00117505
Iteration 3/25 | Loss: 0.00084615
Iteration 4/25 | Loss: 0.00080183
Iteration 5/25 | Loss: 0.00079021
Iteration 6/25 | Loss: 0.00078836
Iteration 7/25 | Loss: 0.00078822
Iteration 8/25 | Loss: 0.00078822
Iteration 9/25 | Loss: 0.00078822
Iteration 10/25 | Loss: 0.00078822
Iteration 11/25 | Loss: 0.00078822
Iteration 12/25 | Loss: 0.00078822
Iteration 13/25 | Loss: 0.00078822
Iteration 14/25 | Loss: 0.00078822
Iteration 15/25 | Loss: 0.00078822
Iteration 16/25 | Loss: 0.00078822
Iteration 17/25 | Loss: 0.00078822
Iteration 18/25 | Loss: 0.00078822
Iteration 19/25 | Loss: 0.00078822
Iteration 20/25 | Loss: 0.00078822
Iteration 21/25 | Loss: 0.00078822
Iteration 22/25 | Loss: 0.00078822
Iteration 23/25 | Loss: 0.00078822
Iteration 24/25 | Loss: 0.00078822
Iteration 25/25 | Loss: 0.00078822

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.67949730
Iteration 2/25 | Loss: 0.00037067
Iteration 3/25 | Loss: 0.00037067
Iteration 4/25 | Loss: 0.00037067
Iteration 5/25 | Loss: 0.00037067
Iteration 6/25 | Loss: 0.00037067
Iteration 7/25 | Loss: 0.00037067
Iteration 8/25 | Loss: 0.00037067
Iteration 9/25 | Loss: 0.00037067
Iteration 10/25 | Loss: 0.00037067
Iteration 11/25 | Loss: 0.00037067
Iteration 12/25 | Loss: 0.00037067
Iteration 13/25 | Loss: 0.00037067
Iteration 14/25 | Loss: 0.00037067
Iteration 15/25 | Loss: 0.00037067
Iteration 16/25 | Loss: 0.00037067
Iteration 17/25 | Loss: 0.00037067
Iteration 18/25 | Loss: 0.00037067
Iteration 19/25 | Loss: 0.00037067
Iteration 20/25 | Loss: 0.00037067
Iteration 21/25 | Loss: 0.00037067
Iteration 22/25 | Loss: 0.00037067
Iteration 23/25 | Loss: 0.00037067
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00037066504592075944, 0.00037066504592075944, 0.00037066504592075944, 0.00037066504592075944, 0.00037066504592075944]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00037066504592075944

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00037067
Iteration 2/1000 | Loss: 0.00003843
Iteration 3/1000 | Loss: 0.00002526
Iteration 4/1000 | Loss: 0.00002308
Iteration 5/1000 | Loss: 0.00002200
Iteration 6/1000 | Loss: 0.00002112
Iteration 7/1000 | Loss: 0.00002036
Iteration 8/1000 | Loss: 0.00001985
Iteration 9/1000 | Loss: 0.00001952
Iteration 10/1000 | Loss: 0.00001930
Iteration 11/1000 | Loss: 0.00001914
Iteration 12/1000 | Loss: 0.00001913
Iteration 13/1000 | Loss: 0.00001896
Iteration 14/1000 | Loss: 0.00001885
Iteration 15/1000 | Loss: 0.00001867
Iteration 16/1000 | Loss: 0.00001864
Iteration 17/1000 | Loss: 0.00001864
Iteration 18/1000 | Loss: 0.00001859
Iteration 19/1000 | Loss: 0.00001859
Iteration 20/1000 | Loss: 0.00001858
Iteration 21/1000 | Loss: 0.00001858
Iteration 22/1000 | Loss: 0.00001854
Iteration 23/1000 | Loss: 0.00001854
Iteration 24/1000 | Loss: 0.00001853
Iteration 25/1000 | Loss: 0.00001853
Iteration 26/1000 | Loss: 0.00001848
Iteration 27/1000 | Loss: 0.00001848
Iteration 28/1000 | Loss: 0.00001847
Iteration 29/1000 | Loss: 0.00001847
Iteration 30/1000 | Loss: 0.00001846
Iteration 31/1000 | Loss: 0.00001845
Iteration 32/1000 | Loss: 0.00001844
Iteration 33/1000 | Loss: 0.00001844
Iteration 34/1000 | Loss: 0.00001844
Iteration 35/1000 | Loss: 0.00001842
Iteration 36/1000 | Loss: 0.00001841
Iteration 37/1000 | Loss: 0.00001841
Iteration 38/1000 | Loss: 0.00001840
Iteration 39/1000 | Loss: 0.00001840
Iteration 40/1000 | Loss: 0.00001840
Iteration 41/1000 | Loss: 0.00001839
Iteration 42/1000 | Loss: 0.00001838
Iteration 43/1000 | Loss: 0.00001836
Iteration 44/1000 | Loss: 0.00001835
Iteration 45/1000 | Loss: 0.00001835
Iteration 46/1000 | Loss: 0.00001835
Iteration 47/1000 | Loss: 0.00001832
Iteration 48/1000 | Loss: 0.00001831
Iteration 49/1000 | Loss: 0.00001831
Iteration 50/1000 | Loss: 0.00001830
Iteration 51/1000 | Loss: 0.00001829
Iteration 52/1000 | Loss: 0.00001829
Iteration 53/1000 | Loss: 0.00001828
Iteration 54/1000 | Loss: 0.00001827
Iteration 55/1000 | Loss: 0.00001827
Iteration 56/1000 | Loss: 0.00001827
Iteration 57/1000 | Loss: 0.00001827
Iteration 58/1000 | Loss: 0.00001827
Iteration 59/1000 | Loss: 0.00001827
Iteration 60/1000 | Loss: 0.00001827
Iteration 61/1000 | Loss: 0.00001827
Iteration 62/1000 | Loss: 0.00001827
Iteration 63/1000 | Loss: 0.00001826
Iteration 64/1000 | Loss: 0.00001826
Iteration 65/1000 | Loss: 0.00001826
Iteration 66/1000 | Loss: 0.00001825
Iteration 67/1000 | Loss: 0.00001825
Iteration 68/1000 | Loss: 0.00001825
Iteration 69/1000 | Loss: 0.00001825
Iteration 70/1000 | Loss: 0.00001824
Iteration 71/1000 | Loss: 0.00001824
Iteration 72/1000 | Loss: 0.00001824
Iteration 73/1000 | Loss: 0.00001824
Iteration 74/1000 | Loss: 0.00001823
Iteration 75/1000 | Loss: 0.00001823
Iteration 76/1000 | Loss: 0.00001823
Iteration 77/1000 | Loss: 0.00001823
Iteration 78/1000 | Loss: 0.00001823
Iteration 79/1000 | Loss: 0.00001823
Iteration 80/1000 | Loss: 0.00001823
Iteration 81/1000 | Loss: 0.00001823
Iteration 82/1000 | Loss: 0.00001823
Iteration 83/1000 | Loss: 0.00001823
Iteration 84/1000 | Loss: 0.00001822
Iteration 85/1000 | Loss: 0.00001822
Iteration 86/1000 | Loss: 0.00001822
Iteration 87/1000 | Loss: 0.00001822
Iteration 88/1000 | Loss: 0.00001821
Iteration 89/1000 | Loss: 0.00001821
Iteration 90/1000 | Loss: 0.00001821
Iteration 91/1000 | Loss: 0.00001821
Iteration 92/1000 | Loss: 0.00001820
Iteration 93/1000 | Loss: 0.00001820
Iteration 94/1000 | Loss: 0.00001820
Iteration 95/1000 | Loss: 0.00001819
Iteration 96/1000 | Loss: 0.00001819
Iteration 97/1000 | Loss: 0.00001818
Iteration 98/1000 | Loss: 0.00001818
Iteration 99/1000 | Loss: 0.00001818
Iteration 100/1000 | Loss: 0.00001817
Iteration 101/1000 | Loss: 0.00001817
Iteration 102/1000 | Loss: 0.00001817
Iteration 103/1000 | Loss: 0.00001817
Iteration 104/1000 | Loss: 0.00001817
Iteration 105/1000 | Loss: 0.00001816
Iteration 106/1000 | Loss: 0.00001816
Iteration 107/1000 | Loss: 0.00001816
Iteration 108/1000 | Loss: 0.00001816
Iteration 109/1000 | Loss: 0.00001816
Iteration 110/1000 | Loss: 0.00001816
Iteration 111/1000 | Loss: 0.00001816
Iteration 112/1000 | Loss: 0.00001816
Iteration 113/1000 | Loss: 0.00001816
Iteration 114/1000 | Loss: 0.00001815
Iteration 115/1000 | Loss: 0.00001815
Iteration 116/1000 | Loss: 0.00001815
Iteration 117/1000 | Loss: 0.00001815
Iteration 118/1000 | Loss: 0.00001815
Iteration 119/1000 | Loss: 0.00001815
Iteration 120/1000 | Loss: 0.00001815
Iteration 121/1000 | Loss: 0.00001814
Iteration 122/1000 | Loss: 0.00001814
Iteration 123/1000 | Loss: 0.00001814
Iteration 124/1000 | Loss: 0.00001814
Iteration 125/1000 | Loss: 0.00001814
Iteration 126/1000 | Loss: 0.00001813
Iteration 127/1000 | Loss: 0.00001813
Iteration 128/1000 | Loss: 0.00001813
Iteration 129/1000 | Loss: 0.00001813
Iteration 130/1000 | Loss: 0.00001813
Iteration 131/1000 | Loss: 0.00001812
Iteration 132/1000 | Loss: 0.00001812
Iteration 133/1000 | Loss: 0.00001812
Iteration 134/1000 | Loss: 0.00001812
Iteration 135/1000 | Loss: 0.00001811
Iteration 136/1000 | Loss: 0.00001811
Iteration 137/1000 | Loss: 0.00001811
Iteration 138/1000 | Loss: 0.00001811
Iteration 139/1000 | Loss: 0.00001810
Iteration 140/1000 | Loss: 0.00001810
Iteration 141/1000 | Loss: 0.00001810
Iteration 142/1000 | Loss: 0.00001810
Iteration 143/1000 | Loss: 0.00001809
Iteration 144/1000 | Loss: 0.00001809
Iteration 145/1000 | Loss: 0.00001809
Iteration 146/1000 | Loss: 0.00001808
Iteration 147/1000 | Loss: 0.00001808
Iteration 148/1000 | Loss: 0.00001808
Iteration 149/1000 | Loss: 0.00001807
Iteration 150/1000 | Loss: 0.00001807
Iteration 151/1000 | Loss: 0.00001807
Iteration 152/1000 | Loss: 0.00001807
Iteration 153/1000 | Loss: 0.00001806
Iteration 154/1000 | Loss: 0.00001806
Iteration 155/1000 | Loss: 0.00001806
Iteration 156/1000 | Loss: 0.00001806
Iteration 157/1000 | Loss: 0.00001805
Iteration 158/1000 | Loss: 0.00001805
Iteration 159/1000 | Loss: 0.00001805
Iteration 160/1000 | Loss: 0.00001805
Iteration 161/1000 | Loss: 0.00001804
Iteration 162/1000 | Loss: 0.00001804
Iteration 163/1000 | Loss: 0.00001804
Iteration 164/1000 | Loss: 0.00001804
Iteration 165/1000 | Loss: 0.00001803
Iteration 166/1000 | Loss: 0.00001803
Iteration 167/1000 | Loss: 0.00001803
Iteration 168/1000 | Loss: 0.00001803
Iteration 169/1000 | Loss: 0.00001803
Iteration 170/1000 | Loss: 0.00001803
Iteration 171/1000 | Loss: 0.00001803
Iteration 172/1000 | Loss: 0.00001803
Iteration 173/1000 | Loss: 0.00001803
Iteration 174/1000 | Loss: 0.00001803
Iteration 175/1000 | Loss: 0.00001803
Iteration 176/1000 | Loss: 0.00001802
Iteration 177/1000 | Loss: 0.00001802
Iteration 178/1000 | Loss: 0.00001802
Iteration 179/1000 | Loss: 0.00001802
Iteration 180/1000 | Loss: 0.00001802
Iteration 181/1000 | Loss: 0.00001801
Iteration 182/1000 | Loss: 0.00001801
Iteration 183/1000 | Loss: 0.00001801
Iteration 184/1000 | Loss: 0.00001801
Iteration 185/1000 | Loss: 0.00001801
Iteration 186/1000 | Loss: 0.00001801
Iteration 187/1000 | Loss: 0.00001801
Iteration 188/1000 | Loss: 0.00001801
Iteration 189/1000 | Loss: 0.00001800
Iteration 190/1000 | Loss: 0.00001800
Iteration 191/1000 | Loss: 0.00001800
Iteration 192/1000 | Loss: 0.00001800
Iteration 193/1000 | Loss: 0.00001800
Iteration 194/1000 | Loss: 0.00001800
Iteration 195/1000 | Loss: 0.00001800
Iteration 196/1000 | Loss: 0.00001800
Iteration 197/1000 | Loss: 0.00001800
Iteration 198/1000 | Loss: 0.00001799
Iteration 199/1000 | Loss: 0.00001799
Iteration 200/1000 | Loss: 0.00001799
Iteration 201/1000 | Loss: 0.00001799
Iteration 202/1000 | Loss: 0.00001799
Iteration 203/1000 | Loss: 0.00001799
Iteration 204/1000 | Loss: 0.00001798
Iteration 205/1000 | Loss: 0.00001798
Iteration 206/1000 | Loss: 0.00001798
Iteration 207/1000 | Loss: 0.00001798
Iteration 208/1000 | Loss: 0.00001798
Iteration 209/1000 | Loss: 0.00001798
Iteration 210/1000 | Loss: 0.00001798
Iteration 211/1000 | Loss: 0.00001798
Iteration 212/1000 | Loss: 0.00001798
Iteration 213/1000 | Loss: 0.00001798
Iteration 214/1000 | Loss: 0.00001798
Iteration 215/1000 | Loss: 0.00001798
Iteration 216/1000 | Loss: 0.00001798
Iteration 217/1000 | Loss: 0.00001798
Iteration 218/1000 | Loss: 0.00001798
Iteration 219/1000 | Loss: 0.00001798
Iteration 220/1000 | Loss: 0.00001798
Iteration 221/1000 | Loss: 0.00001798
Iteration 222/1000 | Loss: 0.00001798
Iteration 223/1000 | Loss: 0.00001798
Iteration 224/1000 | Loss: 0.00001798
Iteration 225/1000 | Loss: 0.00001798
Iteration 226/1000 | Loss: 0.00001798
Iteration 227/1000 | Loss: 0.00001798
Iteration 228/1000 | Loss: 0.00001798
Iteration 229/1000 | Loss: 0.00001798
Iteration 230/1000 | Loss: 0.00001798
Iteration 231/1000 | Loss: 0.00001798
Iteration 232/1000 | Loss: 0.00001798
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 232. Stopping optimization.
Last 5 losses: [1.7977372408495285e-05, 1.7977372408495285e-05, 1.7977372408495285e-05, 1.7977372408495285e-05, 1.7977372408495285e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7977372408495285e-05

Optimization complete. Final v2v error: 3.588440418243408 mm

Highest mean error: 3.971911907196045 mm for frame 236

Lowest mean error: 3.275815725326538 mm for frame 1

Saving results

Total time: 55.83001184463501
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1043/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1043.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1043
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00987563
Iteration 2/25 | Loss: 0.00987563
Iteration 3/25 | Loss: 0.00987563
Iteration 4/25 | Loss: 0.00987563
Iteration 5/25 | Loss: 0.00987562
Iteration 6/25 | Loss: 0.00987562
Iteration 7/25 | Loss: 0.00987562
Iteration 8/25 | Loss: 0.00987562
Iteration 9/25 | Loss: 0.00987562
Iteration 10/25 | Loss: 0.00987561
Iteration 11/25 | Loss: 0.00987561
Iteration 12/25 | Loss: 0.00987561
Iteration 13/25 | Loss: 0.00987561
Iteration 14/25 | Loss: 0.00987560
Iteration 15/25 | Loss: 0.00987560
Iteration 16/25 | Loss: 0.00987560
Iteration 17/25 | Loss: 0.00987560
Iteration 18/25 | Loss: 0.00987559
Iteration 19/25 | Loss: 0.00987559
Iteration 20/25 | Loss: 0.00987559
Iteration 21/25 | Loss: 0.00987559
Iteration 22/25 | Loss: 0.00987558
Iteration 23/25 | Loss: 0.00987558
Iteration 24/25 | Loss: 0.00987558
Iteration 25/25 | Loss: 0.00987558

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.79353321
Iteration 2/25 | Loss: 0.19498499
Iteration 3/25 | Loss: 0.19498488
Iteration 4/25 | Loss: 0.19498488
Iteration 5/25 | Loss: 0.19498485
Iteration 6/25 | Loss: 0.19498484
Iteration 7/25 | Loss: 0.19498484
Iteration 8/25 | Loss: 0.19498485
Iteration 9/25 | Loss: 0.19498482
Iteration 10/25 | Loss: 0.19498481
Iteration 11/25 | Loss: 0.19498481
Iteration 12/25 | Loss: 0.19498481
Iteration 13/25 | Loss: 0.19498481
Iteration 14/25 | Loss: 0.19498481
Iteration 15/25 | Loss: 0.19498481
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 15. Stopping optimization.
Last 5 losses: [0.1949848085641861, 0.1949848085641861, 0.1949848085641861, 0.1949848085641861, 0.1949848085641861]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.1949848085641861

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.19498481
Iteration 2/1000 | Loss: 0.00294044
Iteration 3/1000 | Loss: 0.00102006
Iteration 4/1000 | Loss: 0.00039194
Iteration 5/1000 | Loss: 0.00019756
Iteration 6/1000 | Loss: 0.00011419
Iteration 7/1000 | Loss: 0.00007587
Iteration 8/1000 | Loss: 0.00005929
Iteration 9/1000 | Loss: 0.00004624
Iteration 10/1000 | Loss: 0.00003897
Iteration 11/1000 | Loss: 0.00003434
Iteration 12/1000 | Loss: 0.00003107
Iteration 13/1000 | Loss: 0.00002950
Iteration 14/1000 | Loss: 0.00002781
Iteration 15/1000 | Loss: 0.00002529
Iteration 16/1000 | Loss: 0.00002284
Iteration 17/1000 | Loss: 0.00002135
Iteration 18/1000 | Loss: 0.00002027
Iteration 19/1000 | Loss: 0.00001941
Iteration 20/1000 | Loss: 0.00001884
Iteration 21/1000 | Loss: 0.00001838
Iteration 22/1000 | Loss: 0.00001803
Iteration 23/1000 | Loss: 0.00001776
Iteration 24/1000 | Loss: 0.00001770
Iteration 25/1000 | Loss: 0.00001764
Iteration 26/1000 | Loss: 0.00001739
Iteration 27/1000 | Loss: 0.00001713
Iteration 28/1000 | Loss: 0.00001704
Iteration 29/1000 | Loss: 0.00001699
Iteration 30/1000 | Loss: 0.00001698
Iteration 31/1000 | Loss: 0.00001698
Iteration 32/1000 | Loss: 0.00001698
Iteration 33/1000 | Loss: 0.00001697
Iteration 34/1000 | Loss: 0.00001694
Iteration 35/1000 | Loss: 0.00001692
Iteration 36/1000 | Loss: 0.00001689
Iteration 37/1000 | Loss: 0.00001689
Iteration 38/1000 | Loss: 0.00001688
Iteration 39/1000 | Loss: 0.00001688
Iteration 40/1000 | Loss: 0.00001683
Iteration 41/1000 | Loss: 0.00001683
Iteration 42/1000 | Loss: 0.00001681
Iteration 43/1000 | Loss: 0.00001681
Iteration 44/1000 | Loss: 0.00001680
Iteration 45/1000 | Loss: 0.00001680
Iteration 46/1000 | Loss: 0.00001680
Iteration 47/1000 | Loss: 0.00001679
Iteration 48/1000 | Loss: 0.00001679
Iteration 49/1000 | Loss: 0.00001679
Iteration 50/1000 | Loss: 0.00001679
Iteration 51/1000 | Loss: 0.00001679
Iteration 52/1000 | Loss: 0.00001679
Iteration 53/1000 | Loss: 0.00001679
Iteration 54/1000 | Loss: 0.00001678
Iteration 55/1000 | Loss: 0.00001678
Iteration 56/1000 | Loss: 0.00001678
Iteration 57/1000 | Loss: 0.00001678
Iteration 58/1000 | Loss: 0.00001678
Iteration 59/1000 | Loss: 0.00001678
Iteration 60/1000 | Loss: 0.00001678
Iteration 61/1000 | Loss: 0.00001678
Iteration 62/1000 | Loss: 0.00001678
Iteration 63/1000 | Loss: 0.00001678
Iteration 64/1000 | Loss: 0.00001677
Iteration 65/1000 | Loss: 0.00001677
Iteration 66/1000 | Loss: 0.00001677
Iteration 67/1000 | Loss: 0.00001677
Iteration 68/1000 | Loss: 0.00001677
Iteration 69/1000 | Loss: 0.00001677
Iteration 70/1000 | Loss: 0.00001677
Iteration 71/1000 | Loss: 0.00001677
Iteration 72/1000 | Loss: 0.00001676
Iteration 73/1000 | Loss: 0.00001676
Iteration 74/1000 | Loss: 0.00001676
Iteration 75/1000 | Loss: 0.00001676
Iteration 76/1000 | Loss: 0.00001676
Iteration 77/1000 | Loss: 0.00001676
Iteration 78/1000 | Loss: 0.00001676
Iteration 79/1000 | Loss: 0.00001676
Iteration 80/1000 | Loss: 0.00001676
Iteration 81/1000 | Loss: 0.00001676
Iteration 82/1000 | Loss: 0.00001676
Iteration 83/1000 | Loss: 0.00001676
Iteration 84/1000 | Loss: 0.00001676
Iteration 85/1000 | Loss: 0.00001676
Iteration 86/1000 | Loss: 0.00001676
Iteration 87/1000 | Loss: 0.00001676
Iteration 88/1000 | Loss: 0.00001675
Iteration 89/1000 | Loss: 0.00001675
Iteration 90/1000 | Loss: 0.00001675
Iteration 91/1000 | Loss: 0.00001675
Iteration 92/1000 | Loss: 0.00001675
Iteration 93/1000 | Loss: 0.00001675
Iteration 94/1000 | Loss: 0.00001675
Iteration 95/1000 | Loss: 0.00001675
Iteration 96/1000 | Loss: 0.00001675
Iteration 97/1000 | Loss: 0.00001675
Iteration 98/1000 | Loss: 0.00001675
Iteration 99/1000 | Loss: 0.00001675
Iteration 100/1000 | Loss: 0.00001675
Iteration 101/1000 | Loss: 0.00001674
Iteration 102/1000 | Loss: 0.00001674
Iteration 103/1000 | Loss: 0.00001674
Iteration 104/1000 | Loss: 0.00001674
Iteration 105/1000 | Loss: 0.00001674
Iteration 106/1000 | Loss: 0.00001673
Iteration 107/1000 | Loss: 0.00001673
Iteration 108/1000 | Loss: 0.00001673
Iteration 109/1000 | Loss: 0.00001673
Iteration 110/1000 | Loss: 0.00001673
Iteration 111/1000 | Loss: 0.00001673
Iteration 112/1000 | Loss: 0.00001673
Iteration 113/1000 | Loss: 0.00001673
Iteration 114/1000 | Loss: 0.00001673
Iteration 115/1000 | Loss: 0.00001673
Iteration 116/1000 | Loss: 0.00001673
Iteration 117/1000 | Loss: 0.00001673
Iteration 118/1000 | Loss: 0.00001673
Iteration 119/1000 | Loss: 0.00001673
Iteration 120/1000 | Loss: 0.00001673
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 120. Stopping optimization.
Last 5 losses: [1.6732585208956152e-05, 1.6732585208956152e-05, 1.6732585208956152e-05, 1.6732585208956152e-05, 1.6732585208956152e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6732585208956152e-05

Optimization complete. Final v2v error: 3.526881217956543 mm

Highest mean error: 4.048801422119141 mm for frame 141

Lowest mean error: 3.3184776306152344 mm for frame 21

Saving results

Total time: 58.48188924789429
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1026/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1026.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1026
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00808867
Iteration 2/25 | Loss: 0.00131454
Iteration 3/25 | Loss: 0.00085392
Iteration 4/25 | Loss: 0.00083374
Iteration 5/25 | Loss: 0.00079615
Iteration 6/25 | Loss: 0.00079107
Iteration 7/25 | Loss: 0.00080897
Iteration 8/25 | Loss: 0.00078735
Iteration 9/25 | Loss: 0.00078318
Iteration 10/25 | Loss: 0.00078065
Iteration 11/25 | Loss: 0.00077991
Iteration 12/25 | Loss: 0.00077852
Iteration 13/25 | Loss: 0.00077761
Iteration 14/25 | Loss: 0.00077714
Iteration 15/25 | Loss: 0.00077679
Iteration 16/25 | Loss: 0.00077671
Iteration 17/25 | Loss: 0.00077671
Iteration 18/25 | Loss: 0.00077671
Iteration 19/25 | Loss: 0.00077671
Iteration 20/25 | Loss: 0.00077671
Iteration 21/25 | Loss: 0.00077671
Iteration 22/25 | Loss: 0.00077671
Iteration 23/25 | Loss: 0.00077671
Iteration 24/25 | Loss: 0.00077671
Iteration 25/25 | Loss: 0.00077671

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 8.03062248
Iteration 2/25 | Loss: 0.00052213
Iteration 3/25 | Loss: 0.00052205
Iteration 4/25 | Loss: 0.00052205
Iteration 5/25 | Loss: 0.00052205
Iteration 6/25 | Loss: 0.00052205
Iteration 7/25 | Loss: 0.00052205
Iteration 8/25 | Loss: 0.00052205
Iteration 9/25 | Loss: 0.00052205
Iteration 10/25 | Loss: 0.00052205
Iteration 11/25 | Loss: 0.00052204
Iteration 12/25 | Loss: 0.00052204
Iteration 13/25 | Loss: 0.00052204
Iteration 14/25 | Loss: 0.00052204
Iteration 15/25 | Loss: 0.00052204
Iteration 16/25 | Loss: 0.00052204
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0005220448365435004, 0.0005220448365435004, 0.0005220448365435004, 0.0005220448365435004, 0.0005220448365435004]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005220448365435004

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052204
Iteration 2/1000 | Loss: 0.00002834
Iteration 3/1000 | Loss: 0.00001826
Iteration 4/1000 | Loss: 0.00001713
Iteration 5/1000 | Loss: 0.00001632
Iteration 6/1000 | Loss: 0.00001586
Iteration 7/1000 | Loss: 0.00001556
Iteration 8/1000 | Loss: 0.00001535
Iteration 9/1000 | Loss: 0.00001521
Iteration 10/1000 | Loss: 0.00001520
Iteration 11/1000 | Loss: 0.00001512
Iteration 12/1000 | Loss: 0.00001504
Iteration 13/1000 | Loss: 0.00001498
Iteration 14/1000 | Loss: 0.00001497
Iteration 15/1000 | Loss: 0.00001496
Iteration 16/1000 | Loss: 0.00001495
Iteration 17/1000 | Loss: 0.00001488
Iteration 18/1000 | Loss: 0.00001480
Iteration 19/1000 | Loss: 0.00001478
Iteration 20/1000 | Loss: 0.00001477
Iteration 21/1000 | Loss: 0.00001476
Iteration 22/1000 | Loss: 0.00001476
Iteration 23/1000 | Loss: 0.00001474
Iteration 24/1000 | Loss: 0.00001474
Iteration 25/1000 | Loss: 0.00001474
Iteration 26/1000 | Loss: 0.00001474
Iteration 27/1000 | Loss: 0.00001473
Iteration 28/1000 | Loss: 0.00001473
Iteration 29/1000 | Loss: 0.00001473
Iteration 30/1000 | Loss: 0.00001472
Iteration 31/1000 | Loss: 0.00001472
Iteration 32/1000 | Loss: 0.00001472
Iteration 33/1000 | Loss: 0.00001472
Iteration 34/1000 | Loss: 0.00001472
Iteration 35/1000 | Loss: 0.00001471
Iteration 36/1000 | Loss: 0.00001471
Iteration 37/1000 | Loss: 0.00001471
Iteration 38/1000 | Loss: 0.00001471
Iteration 39/1000 | Loss: 0.00001471
Iteration 40/1000 | Loss: 0.00001471
Iteration 41/1000 | Loss: 0.00001470
Iteration 42/1000 | Loss: 0.00001470
Iteration 43/1000 | Loss: 0.00001470
Iteration 44/1000 | Loss: 0.00001470
Iteration 45/1000 | Loss: 0.00001470
Iteration 46/1000 | Loss: 0.00001470
Iteration 47/1000 | Loss: 0.00001470
Iteration 48/1000 | Loss: 0.00001470
Iteration 49/1000 | Loss: 0.00001469
Iteration 50/1000 | Loss: 0.00001469
Iteration 51/1000 | Loss: 0.00001469
Iteration 52/1000 | Loss: 0.00001469
Iteration 53/1000 | Loss: 0.00001469
Iteration 54/1000 | Loss: 0.00001469
Iteration 55/1000 | Loss: 0.00001469
Iteration 56/1000 | Loss: 0.00001468
Iteration 57/1000 | Loss: 0.00001468
Iteration 58/1000 | Loss: 0.00001468
Iteration 59/1000 | Loss: 0.00001467
Iteration 60/1000 | Loss: 0.00001467
Iteration 61/1000 | Loss: 0.00001467
Iteration 62/1000 | Loss: 0.00001466
Iteration 63/1000 | Loss: 0.00001466
Iteration 64/1000 | Loss: 0.00001466
Iteration 65/1000 | Loss: 0.00001466
Iteration 66/1000 | Loss: 0.00001466
Iteration 67/1000 | Loss: 0.00001466
Iteration 68/1000 | Loss: 0.00001465
Iteration 69/1000 | Loss: 0.00001465
Iteration 70/1000 | Loss: 0.00001465
Iteration 71/1000 | Loss: 0.00001465
Iteration 72/1000 | Loss: 0.00001465
Iteration 73/1000 | Loss: 0.00001464
Iteration 74/1000 | Loss: 0.00001464
Iteration 75/1000 | Loss: 0.00001464
Iteration 76/1000 | Loss: 0.00001463
Iteration 77/1000 | Loss: 0.00001463
Iteration 78/1000 | Loss: 0.00001463
Iteration 79/1000 | Loss: 0.00001462
Iteration 80/1000 | Loss: 0.00001462
Iteration 81/1000 | Loss: 0.00001462
Iteration 82/1000 | Loss: 0.00001461
Iteration 83/1000 | Loss: 0.00001461
Iteration 84/1000 | Loss: 0.00001460
Iteration 85/1000 | Loss: 0.00001460
Iteration 86/1000 | Loss: 0.00001458
Iteration 87/1000 | Loss: 0.00001458
Iteration 88/1000 | Loss: 0.00001457
Iteration 89/1000 | Loss: 0.00001457
Iteration 90/1000 | Loss: 0.00001457
Iteration 91/1000 | Loss: 0.00001457
Iteration 92/1000 | Loss: 0.00001456
Iteration 93/1000 | Loss: 0.00001456
Iteration 94/1000 | Loss: 0.00001455
Iteration 95/1000 | Loss: 0.00001455
Iteration 96/1000 | Loss: 0.00001455
Iteration 97/1000 | Loss: 0.00001455
Iteration 98/1000 | Loss: 0.00001454
Iteration 99/1000 | Loss: 0.00001454
Iteration 100/1000 | Loss: 0.00001454
Iteration 101/1000 | Loss: 0.00001454
Iteration 102/1000 | Loss: 0.00001454
Iteration 103/1000 | Loss: 0.00001454
Iteration 104/1000 | Loss: 0.00001453
Iteration 105/1000 | Loss: 0.00001453
Iteration 106/1000 | Loss: 0.00001453
Iteration 107/1000 | Loss: 0.00001453
Iteration 108/1000 | Loss: 0.00001452
Iteration 109/1000 | Loss: 0.00001452
Iteration 110/1000 | Loss: 0.00001452
Iteration 111/1000 | Loss: 0.00001452
Iteration 112/1000 | Loss: 0.00001452
Iteration 113/1000 | Loss: 0.00001452
Iteration 114/1000 | Loss: 0.00001452
Iteration 115/1000 | Loss: 0.00001451
Iteration 116/1000 | Loss: 0.00001451
Iteration 117/1000 | Loss: 0.00001451
Iteration 118/1000 | Loss: 0.00001451
Iteration 119/1000 | Loss: 0.00001451
Iteration 120/1000 | Loss: 0.00001451
Iteration 121/1000 | Loss: 0.00001451
Iteration 122/1000 | Loss: 0.00001451
Iteration 123/1000 | Loss: 0.00001451
Iteration 124/1000 | Loss: 0.00001451
Iteration 125/1000 | Loss: 0.00001450
Iteration 126/1000 | Loss: 0.00001450
Iteration 127/1000 | Loss: 0.00001450
Iteration 128/1000 | Loss: 0.00001450
Iteration 129/1000 | Loss: 0.00001450
Iteration 130/1000 | Loss: 0.00001450
Iteration 131/1000 | Loss: 0.00001450
Iteration 132/1000 | Loss: 0.00001450
Iteration 133/1000 | Loss: 0.00001450
Iteration 134/1000 | Loss: 0.00001450
Iteration 135/1000 | Loss: 0.00001450
Iteration 136/1000 | Loss: 0.00001450
Iteration 137/1000 | Loss: 0.00001450
Iteration 138/1000 | Loss: 0.00001450
Iteration 139/1000 | Loss: 0.00001450
Iteration 140/1000 | Loss: 0.00001450
Iteration 141/1000 | Loss: 0.00001450
Iteration 142/1000 | Loss: 0.00001450
Iteration 143/1000 | Loss: 0.00001450
Iteration 144/1000 | Loss: 0.00001450
Iteration 145/1000 | Loss: 0.00001450
Iteration 146/1000 | Loss: 0.00001450
Iteration 147/1000 | Loss: 0.00001450
Iteration 148/1000 | Loss: 0.00001450
Iteration 149/1000 | Loss: 0.00001450
Iteration 150/1000 | Loss: 0.00001450
Iteration 151/1000 | Loss: 0.00001450
Iteration 152/1000 | Loss: 0.00001450
Iteration 153/1000 | Loss: 0.00001450
Iteration 154/1000 | Loss: 0.00001450
Iteration 155/1000 | Loss: 0.00001450
Iteration 156/1000 | Loss: 0.00001450
Iteration 157/1000 | Loss: 0.00001450
Iteration 158/1000 | Loss: 0.00001450
Iteration 159/1000 | Loss: 0.00001450
Iteration 160/1000 | Loss: 0.00001450
Iteration 161/1000 | Loss: 0.00001450
Iteration 162/1000 | Loss: 0.00001450
Iteration 163/1000 | Loss: 0.00001450
Iteration 164/1000 | Loss: 0.00001450
Iteration 165/1000 | Loss: 0.00001450
Iteration 166/1000 | Loss: 0.00001450
Iteration 167/1000 | Loss: 0.00001450
Iteration 168/1000 | Loss: 0.00001450
Iteration 169/1000 | Loss: 0.00001450
Iteration 170/1000 | Loss: 0.00001450
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 170. Stopping optimization.
Last 5 losses: [1.4497198208118789e-05, 1.4497198208118789e-05, 1.4497198208118789e-05, 1.4497198208118789e-05, 1.4497198208118789e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4497198208118789e-05

Optimization complete. Final v2v error: 3.2213134765625 mm

Highest mean error: 3.6946470737457275 mm for frame 165

Lowest mean error: 2.7770469188690186 mm for frame 120

Saving results

Total time: 57.94748830795288
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1063/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1063.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1063
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00801714
Iteration 2/25 | Loss: 0.00111339
Iteration 3/25 | Loss: 0.00085675
Iteration 4/25 | Loss: 0.00080428
Iteration 5/25 | Loss: 0.00079482
Iteration 6/25 | Loss: 0.00079329
Iteration 7/25 | Loss: 0.00079294
Iteration 8/25 | Loss: 0.00079294
Iteration 9/25 | Loss: 0.00079294
Iteration 10/25 | Loss: 0.00079294
Iteration 11/25 | Loss: 0.00079294
Iteration 12/25 | Loss: 0.00079294
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007929393905214965, 0.0007929393905214965, 0.0007929393905214965, 0.0007929393905214965, 0.0007929393905214965]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007929393905214965

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41406178
Iteration 2/25 | Loss: 0.00053116
Iteration 3/25 | Loss: 0.00053116
Iteration 4/25 | Loss: 0.00053116
Iteration 5/25 | Loss: 0.00053116
Iteration 6/25 | Loss: 0.00053116
Iteration 7/25 | Loss: 0.00053116
Iteration 8/25 | Loss: 0.00053116
Iteration 9/25 | Loss: 0.00053116
Iteration 10/25 | Loss: 0.00053116
Iteration 11/25 | Loss: 0.00053116
Iteration 12/25 | Loss: 0.00053116
Iteration 13/25 | Loss: 0.00053116
Iteration 14/25 | Loss: 0.00053116
Iteration 15/25 | Loss: 0.00053116
Iteration 16/25 | Loss: 0.00053116
Iteration 17/25 | Loss: 0.00053116
Iteration 18/25 | Loss: 0.00053116
Iteration 19/25 | Loss: 0.00053116
Iteration 20/25 | Loss: 0.00053116
Iteration 21/25 | Loss: 0.00053116
Iteration 22/25 | Loss: 0.00053116
Iteration 23/25 | Loss: 0.00053116
Iteration 24/25 | Loss: 0.00053116
Iteration 25/25 | Loss: 0.00053116

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053116
Iteration 2/1000 | Loss: 0.00003794
Iteration 3/1000 | Loss: 0.00002993
Iteration 4/1000 | Loss: 0.00002609
Iteration 5/1000 | Loss: 0.00002490
Iteration 6/1000 | Loss: 0.00002365
Iteration 7/1000 | Loss: 0.00002304
Iteration 8/1000 | Loss: 0.00002235
Iteration 9/1000 | Loss: 0.00002197
Iteration 10/1000 | Loss: 0.00002186
Iteration 11/1000 | Loss: 0.00002181
Iteration 12/1000 | Loss: 0.00002172
Iteration 13/1000 | Loss: 0.00002159
Iteration 14/1000 | Loss: 0.00002152
Iteration 15/1000 | Loss: 0.00002137
Iteration 16/1000 | Loss: 0.00002128
Iteration 17/1000 | Loss: 0.00002123
Iteration 18/1000 | Loss: 0.00002116
Iteration 19/1000 | Loss: 0.00002112
Iteration 20/1000 | Loss: 0.00002111
Iteration 21/1000 | Loss: 0.00002110
Iteration 22/1000 | Loss: 0.00002107
Iteration 23/1000 | Loss: 0.00002107
Iteration 24/1000 | Loss: 0.00002106
Iteration 25/1000 | Loss: 0.00002105
Iteration 26/1000 | Loss: 0.00002105
Iteration 27/1000 | Loss: 0.00002104
Iteration 28/1000 | Loss: 0.00002104
Iteration 29/1000 | Loss: 0.00002104
Iteration 30/1000 | Loss: 0.00002101
Iteration 31/1000 | Loss: 0.00002101
Iteration 32/1000 | Loss: 0.00002101
Iteration 33/1000 | Loss: 0.00002101
Iteration 34/1000 | Loss: 0.00002100
Iteration 35/1000 | Loss: 0.00002099
Iteration 36/1000 | Loss: 0.00002098
Iteration 37/1000 | Loss: 0.00002098
Iteration 38/1000 | Loss: 0.00002098
Iteration 39/1000 | Loss: 0.00002097
Iteration 40/1000 | Loss: 0.00002097
Iteration 41/1000 | Loss: 0.00002096
Iteration 42/1000 | Loss: 0.00002096
Iteration 43/1000 | Loss: 0.00002096
Iteration 44/1000 | Loss: 0.00002096
Iteration 45/1000 | Loss: 0.00002095
Iteration 46/1000 | Loss: 0.00002095
Iteration 47/1000 | Loss: 0.00002095
Iteration 48/1000 | Loss: 0.00002095
Iteration 49/1000 | Loss: 0.00002095
Iteration 50/1000 | Loss: 0.00002095
Iteration 51/1000 | Loss: 0.00002095
Iteration 52/1000 | Loss: 0.00002095
Iteration 53/1000 | Loss: 0.00002095
Iteration 54/1000 | Loss: 0.00002095
Iteration 55/1000 | Loss: 0.00002095
Iteration 56/1000 | Loss: 0.00002094
Iteration 57/1000 | Loss: 0.00002094
Iteration 58/1000 | Loss: 0.00002094
Iteration 59/1000 | Loss: 0.00002094
Iteration 60/1000 | Loss: 0.00002094
Iteration 61/1000 | Loss: 0.00002094
Iteration 62/1000 | Loss: 0.00002094
Iteration 63/1000 | Loss: 0.00002094
Iteration 64/1000 | Loss: 0.00002094
Iteration 65/1000 | Loss: 0.00002094
Iteration 66/1000 | Loss: 0.00002094
Iteration 67/1000 | Loss: 0.00002094
Iteration 68/1000 | Loss: 0.00002094
Iteration 69/1000 | Loss: 0.00002094
Iteration 70/1000 | Loss: 0.00002094
Iteration 71/1000 | Loss: 0.00002094
Iteration 72/1000 | Loss: 0.00002094
Iteration 73/1000 | Loss: 0.00002094
Iteration 74/1000 | Loss: 0.00002094
Iteration 75/1000 | Loss: 0.00002094
Iteration 76/1000 | Loss: 0.00002094
Iteration 77/1000 | Loss: 0.00002094
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [2.0935247448505834e-05, 2.0935247448505834e-05, 2.0935247448505834e-05, 2.0935247448505834e-05, 2.0935247448505834e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0935247448505834e-05

Optimization complete. Final v2v error: 3.8406434059143066 mm

Highest mean error: 4.252811431884766 mm for frame 117

Lowest mean error: 3.100585699081421 mm for frame 63

Saving results

Total time: 33.78430414199829
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1095/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1095.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1095
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00398125
Iteration 2/25 | Loss: 0.00096552
Iteration 3/25 | Loss: 0.00083069
Iteration 4/25 | Loss: 0.00080349
Iteration 5/25 | Loss: 0.00079855
Iteration 6/25 | Loss: 0.00079739
Iteration 7/25 | Loss: 0.00079708
Iteration 8/25 | Loss: 0.00079708
Iteration 9/25 | Loss: 0.00079708
Iteration 10/25 | Loss: 0.00079708
Iteration 11/25 | Loss: 0.00079708
Iteration 12/25 | Loss: 0.00079708
Iteration 13/25 | Loss: 0.00079708
Iteration 14/25 | Loss: 0.00079708
Iteration 15/25 | Loss: 0.00079708
Iteration 16/25 | Loss: 0.00079708
Iteration 17/25 | Loss: 0.00079708
Iteration 18/25 | Loss: 0.00079708
Iteration 19/25 | Loss: 0.00079708
Iteration 20/25 | Loss: 0.00079708
Iteration 21/25 | Loss: 0.00079708
Iteration 22/25 | Loss: 0.00079708
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0007970785372890532, 0.0007970785372890532, 0.0007970785372890532, 0.0007970785372890532, 0.0007970785372890532]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007970785372890532

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.45462751
Iteration 2/25 | Loss: 0.00048657
Iteration 3/25 | Loss: 0.00048657
Iteration 4/25 | Loss: 0.00048657
Iteration 5/25 | Loss: 0.00048656
Iteration 6/25 | Loss: 0.00048656
Iteration 7/25 | Loss: 0.00048656
Iteration 8/25 | Loss: 0.00048656
Iteration 9/25 | Loss: 0.00048656
Iteration 10/25 | Loss: 0.00048656
Iteration 11/25 | Loss: 0.00048656
Iteration 12/25 | Loss: 0.00048656
Iteration 13/25 | Loss: 0.00048656
Iteration 14/25 | Loss: 0.00048656
Iteration 15/25 | Loss: 0.00048656
Iteration 16/25 | Loss: 0.00048656
Iteration 17/25 | Loss: 0.00048656
Iteration 18/25 | Loss: 0.00048656
Iteration 19/25 | Loss: 0.00048656
Iteration 20/25 | Loss: 0.00048656
Iteration 21/25 | Loss: 0.00048656
Iteration 22/25 | Loss: 0.00048656
Iteration 23/25 | Loss: 0.00048656
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0004865631344728172, 0.0004865631344728172, 0.0004865631344728172, 0.0004865631344728172, 0.0004865631344728172]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004865631344728172

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048656
Iteration 2/1000 | Loss: 0.00005896
Iteration 3/1000 | Loss: 0.00003883
Iteration 4/1000 | Loss: 0.00003279
Iteration 5/1000 | Loss: 0.00003076
Iteration 6/1000 | Loss: 0.00002919
Iteration 7/1000 | Loss: 0.00002835
Iteration 8/1000 | Loss: 0.00002754
Iteration 9/1000 | Loss: 0.00002683
Iteration 10/1000 | Loss: 0.00002645
Iteration 11/1000 | Loss: 0.00002617
Iteration 12/1000 | Loss: 0.00002591
Iteration 13/1000 | Loss: 0.00002566
Iteration 14/1000 | Loss: 0.00002542
Iteration 15/1000 | Loss: 0.00002523
Iteration 16/1000 | Loss: 0.00002520
Iteration 17/1000 | Loss: 0.00002514
Iteration 18/1000 | Loss: 0.00002508
Iteration 19/1000 | Loss: 0.00002508
Iteration 20/1000 | Loss: 0.00002503
Iteration 21/1000 | Loss: 0.00002497
Iteration 22/1000 | Loss: 0.00002492
Iteration 23/1000 | Loss: 0.00002492
Iteration 24/1000 | Loss: 0.00002492
Iteration 25/1000 | Loss: 0.00002492
Iteration 26/1000 | Loss: 0.00002492
Iteration 27/1000 | Loss: 0.00002492
Iteration 28/1000 | Loss: 0.00002491
Iteration 29/1000 | Loss: 0.00002490
Iteration 30/1000 | Loss: 0.00002490
Iteration 31/1000 | Loss: 0.00002490
Iteration 32/1000 | Loss: 0.00002490
Iteration 33/1000 | Loss: 0.00002490
Iteration 34/1000 | Loss: 0.00002490
Iteration 35/1000 | Loss: 0.00002490
Iteration 36/1000 | Loss: 0.00002490
Iteration 37/1000 | Loss: 0.00002490
Iteration 38/1000 | Loss: 0.00002490
Iteration 39/1000 | Loss: 0.00002489
Iteration 40/1000 | Loss: 0.00002489
Iteration 41/1000 | Loss: 0.00002489
Iteration 42/1000 | Loss: 0.00002489
Iteration 43/1000 | Loss: 0.00002489
Iteration 44/1000 | Loss: 0.00002489
Iteration 45/1000 | Loss: 0.00002489
Iteration 46/1000 | Loss: 0.00002488
Iteration 47/1000 | Loss: 0.00002488
Iteration 48/1000 | Loss: 0.00002488
Iteration 49/1000 | Loss: 0.00002488
Iteration 50/1000 | Loss: 0.00002488
Iteration 51/1000 | Loss: 0.00002487
Iteration 52/1000 | Loss: 0.00002487
Iteration 53/1000 | Loss: 0.00002487
Iteration 54/1000 | Loss: 0.00002486
Iteration 55/1000 | Loss: 0.00002486
Iteration 56/1000 | Loss: 0.00002486
Iteration 57/1000 | Loss: 0.00002486
Iteration 58/1000 | Loss: 0.00002485
Iteration 59/1000 | Loss: 0.00002485
Iteration 60/1000 | Loss: 0.00002485
Iteration 61/1000 | Loss: 0.00002485
Iteration 62/1000 | Loss: 0.00002485
Iteration 63/1000 | Loss: 0.00002485
Iteration 64/1000 | Loss: 0.00002485
Iteration 65/1000 | Loss: 0.00002485
Iteration 66/1000 | Loss: 0.00002485
Iteration 67/1000 | Loss: 0.00002485
Iteration 68/1000 | Loss: 0.00002485
Iteration 69/1000 | Loss: 0.00002484
Iteration 70/1000 | Loss: 0.00002484
Iteration 71/1000 | Loss: 0.00002484
Iteration 72/1000 | Loss: 0.00002484
Iteration 73/1000 | Loss: 0.00002484
Iteration 74/1000 | Loss: 0.00002484
Iteration 75/1000 | Loss: 0.00002483
Iteration 76/1000 | Loss: 0.00002483
Iteration 77/1000 | Loss: 0.00002483
Iteration 78/1000 | Loss: 0.00002483
Iteration 79/1000 | Loss: 0.00002483
Iteration 80/1000 | Loss: 0.00002483
Iteration 81/1000 | Loss: 0.00002483
Iteration 82/1000 | Loss: 0.00002483
Iteration 83/1000 | Loss: 0.00002482
Iteration 84/1000 | Loss: 0.00002482
Iteration 85/1000 | Loss: 0.00002482
Iteration 86/1000 | Loss: 0.00002482
Iteration 87/1000 | Loss: 0.00002482
Iteration 88/1000 | Loss: 0.00002481
Iteration 89/1000 | Loss: 0.00002481
Iteration 90/1000 | Loss: 0.00002481
Iteration 91/1000 | Loss: 0.00002481
Iteration 92/1000 | Loss: 0.00002481
Iteration 93/1000 | Loss: 0.00002481
Iteration 94/1000 | Loss: 0.00002481
Iteration 95/1000 | Loss: 0.00002481
Iteration 96/1000 | Loss: 0.00002481
Iteration 97/1000 | Loss: 0.00002481
Iteration 98/1000 | Loss: 0.00002481
Iteration 99/1000 | Loss: 0.00002481
Iteration 100/1000 | Loss: 0.00002481
Iteration 101/1000 | Loss: 0.00002480
Iteration 102/1000 | Loss: 0.00002480
Iteration 103/1000 | Loss: 0.00002480
Iteration 104/1000 | Loss: 0.00002480
Iteration 105/1000 | Loss: 0.00002480
Iteration 106/1000 | Loss: 0.00002480
Iteration 107/1000 | Loss: 0.00002480
Iteration 108/1000 | Loss: 0.00002480
Iteration 109/1000 | Loss: 0.00002480
Iteration 110/1000 | Loss: 0.00002480
Iteration 111/1000 | Loss: 0.00002480
Iteration 112/1000 | Loss: 0.00002479
Iteration 113/1000 | Loss: 0.00002479
Iteration 114/1000 | Loss: 0.00002479
Iteration 115/1000 | Loss: 0.00002479
Iteration 116/1000 | Loss: 0.00002479
Iteration 117/1000 | Loss: 0.00002479
Iteration 118/1000 | Loss: 0.00002478
Iteration 119/1000 | Loss: 0.00002478
Iteration 120/1000 | Loss: 0.00002478
Iteration 121/1000 | Loss: 0.00002478
Iteration 122/1000 | Loss: 0.00002478
Iteration 123/1000 | Loss: 0.00002478
Iteration 124/1000 | Loss: 0.00002477
Iteration 125/1000 | Loss: 0.00002477
Iteration 126/1000 | Loss: 0.00002477
Iteration 127/1000 | Loss: 0.00002477
Iteration 128/1000 | Loss: 0.00002477
Iteration 129/1000 | Loss: 0.00002477
Iteration 130/1000 | Loss: 0.00002477
Iteration 131/1000 | Loss: 0.00002477
Iteration 132/1000 | Loss: 0.00002477
Iteration 133/1000 | Loss: 0.00002477
Iteration 134/1000 | Loss: 0.00002477
Iteration 135/1000 | Loss: 0.00002476
Iteration 136/1000 | Loss: 0.00002476
Iteration 137/1000 | Loss: 0.00002476
Iteration 138/1000 | Loss: 0.00002476
Iteration 139/1000 | Loss: 0.00002476
Iteration 140/1000 | Loss: 0.00002476
Iteration 141/1000 | Loss: 0.00002476
Iteration 142/1000 | Loss: 0.00002476
Iteration 143/1000 | Loss: 0.00002476
Iteration 144/1000 | Loss: 0.00002476
Iteration 145/1000 | Loss: 0.00002475
Iteration 146/1000 | Loss: 0.00002475
Iteration 147/1000 | Loss: 0.00002475
Iteration 148/1000 | Loss: 0.00002475
Iteration 149/1000 | Loss: 0.00002475
Iteration 150/1000 | Loss: 0.00002475
Iteration 151/1000 | Loss: 0.00002475
Iteration 152/1000 | Loss: 0.00002475
Iteration 153/1000 | Loss: 0.00002475
Iteration 154/1000 | Loss: 0.00002475
Iteration 155/1000 | Loss: 0.00002474
Iteration 156/1000 | Loss: 0.00002474
Iteration 157/1000 | Loss: 0.00002474
Iteration 158/1000 | Loss: 0.00002474
Iteration 159/1000 | Loss: 0.00002474
Iteration 160/1000 | Loss: 0.00002474
Iteration 161/1000 | Loss: 0.00002474
Iteration 162/1000 | Loss: 0.00002474
Iteration 163/1000 | Loss: 0.00002474
Iteration 164/1000 | Loss: 0.00002473
Iteration 165/1000 | Loss: 0.00002473
Iteration 166/1000 | Loss: 0.00002473
Iteration 167/1000 | Loss: 0.00002473
Iteration 168/1000 | Loss: 0.00002473
Iteration 169/1000 | Loss: 0.00002473
Iteration 170/1000 | Loss: 0.00002473
Iteration 171/1000 | Loss: 0.00002473
Iteration 172/1000 | Loss: 0.00002473
Iteration 173/1000 | Loss: 0.00002473
Iteration 174/1000 | Loss: 0.00002472
Iteration 175/1000 | Loss: 0.00002472
Iteration 176/1000 | Loss: 0.00002472
Iteration 177/1000 | Loss: 0.00002472
Iteration 178/1000 | Loss: 0.00002472
Iteration 179/1000 | Loss: 0.00002472
Iteration 180/1000 | Loss: 0.00002472
Iteration 181/1000 | Loss: 0.00002472
Iteration 182/1000 | Loss: 0.00002472
Iteration 183/1000 | Loss: 0.00002472
Iteration 184/1000 | Loss: 0.00002472
Iteration 185/1000 | Loss: 0.00002471
Iteration 186/1000 | Loss: 0.00002471
Iteration 187/1000 | Loss: 0.00002471
Iteration 188/1000 | Loss: 0.00002471
Iteration 189/1000 | Loss: 0.00002471
Iteration 190/1000 | Loss: 0.00002471
Iteration 191/1000 | Loss: 0.00002471
Iteration 192/1000 | Loss: 0.00002471
Iteration 193/1000 | Loss: 0.00002471
Iteration 194/1000 | Loss: 0.00002471
Iteration 195/1000 | Loss: 0.00002471
Iteration 196/1000 | Loss: 0.00002470
Iteration 197/1000 | Loss: 0.00002470
Iteration 198/1000 | Loss: 0.00002470
Iteration 199/1000 | Loss: 0.00002470
Iteration 200/1000 | Loss: 0.00002470
Iteration 201/1000 | Loss: 0.00002470
Iteration 202/1000 | Loss: 0.00002470
Iteration 203/1000 | Loss: 0.00002470
Iteration 204/1000 | Loss: 0.00002470
Iteration 205/1000 | Loss: 0.00002470
Iteration 206/1000 | Loss: 0.00002470
Iteration 207/1000 | Loss: 0.00002470
Iteration 208/1000 | Loss: 0.00002470
Iteration 209/1000 | Loss: 0.00002470
Iteration 210/1000 | Loss: 0.00002470
Iteration 211/1000 | Loss: 0.00002470
Iteration 212/1000 | Loss: 0.00002470
Iteration 213/1000 | Loss: 0.00002470
Iteration 214/1000 | Loss: 0.00002470
Iteration 215/1000 | Loss: 0.00002470
Iteration 216/1000 | Loss: 0.00002470
Iteration 217/1000 | Loss: 0.00002470
Iteration 218/1000 | Loss: 0.00002470
Iteration 219/1000 | Loss: 0.00002470
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 219. Stopping optimization.
Last 5 losses: [2.469582250341773e-05, 2.469582250341773e-05, 2.469582250341773e-05, 2.469582250341773e-05, 2.469582250341773e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.469582250341773e-05

Optimization complete. Final v2v error: 4.03265905380249 mm

Highest mean error: 4.237024307250977 mm for frame 106

Lowest mean error: 3.8405706882476807 mm for frame 42

Saving results

Total time: 49.08224105834961
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1088/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1088.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1088
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01068597
Iteration 2/25 | Loss: 0.00179720
Iteration 3/25 | Loss: 0.00121179
Iteration 4/25 | Loss: 0.00107427
Iteration 5/25 | Loss: 0.00110741
Iteration 6/25 | Loss: 0.00100116
Iteration 7/25 | Loss: 0.00103653
Iteration 8/25 | Loss: 0.00091415
Iteration 9/25 | Loss: 0.00088806
Iteration 10/25 | Loss: 0.00086790
Iteration 11/25 | Loss: 0.00086249
Iteration 12/25 | Loss: 0.00085347
Iteration 13/25 | Loss: 0.00086110
Iteration 14/25 | Loss: 0.00093558
Iteration 15/25 | Loss: 0.00096052
Iteration 16/25 | Loss: 0.00093320
Iteration 17/25 | Loss: 0.00082309
Iteration 18/25 | Loss: 0.00080091
Iteration 19/25 | Loss: 0.00079698
Iteration 20/25 | Loss: 0.00086707
Iteration 21/25 | Loss: 0.00083415
Iteration 22/25 | Loss: 0.00080503
Iteration 23/25 | Loss: 0.00079784
Iteration 24/25 | Loss: 0.00079456
Iteration 25/25 | Loss: 0.00079368

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65426040
Iteration 2/25 | Loss: 0.00078558
Iteration 3/25 | Loss: 0.00078557
Iteration 4/25 | Loss: 0.00078557
Iteration 5/25 | Loss: 0.00078557
Iteration 6/25 | Loss: 0.00078557
Iteration 7/25 | Loss: 0.00078557
Iteration 8/25 | Loss: 0.00078557
Iteration 9/25 | Loss: 0.00078557
Iteration 10/25 | Loss: 0.00078557
Iteration 11/25 | Loss: 0.00078557
Iteration 12/25 | Loss: 0.00078557
Iteration 13/25 | Loss: 0.00078557
Iteration 14/25 | Loss: 0.00078557
Iteration 15/25 | Loss: 0.00078557
Iteration 16/25 | Loss: 0.00078557
Iteration 17/25 | Loss: 0.00078557
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0007855715230107307, 0.0007855715230107307, 0.0007855715230107307, 0.0007855715230107307, 0.0007855715230107307]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007855715230107307

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00078557
Iteration 2/1000 | Loss: 0.00429503
Iteration 3/1000 | Loss: 0.00008993
Iteration 4/1000 | Loss: 0.00218489
Iteration 5/1000 | Loss: 0.00417770
Iteration 6/1000 | Loss: 0.00206883
Iteration 7/1000 | Loss: 0.00145778
Iteration 8/1000 | Loss: 0.00007166
Iteration 9/1000 | Loss: 0.00218905
Iteration 10/1000 | Loss: 0.00259489
Iteration 11/1000 | Loss: 0.00148495
Iteration 12/1000 | Loss: 0.00080969
Iteration 13/1000 | Loss: 0.00248027
Iteration 14/1000 | Loss: 0.00047454
Iteration 15/1000 | Loss: 0.00025777
Iteration 16/1000 | Loss: 0.00167187
Iteration 17/1000 | Loss: 0.00042506
Iteration 18/1000 | Loss: 0.00032195
Iteration 19/1000 | Loss: 0.00032953
Iteration 20/1000 | Loss: 0.00014221
Iteration 21/1000 | Loss: 0.00171245
Iteration 22/1000 | Loss: 0.00151156
Iteration 23/1000 | Loss: 0.00242746
Iteration 24/1000 | Loss: 0.00175816
Iteration 25/1000 | Loss: 0.00142769
Iteration 26/1000 | Loss: 0.00198157
Iteration 27/1000 | Loss: 0.00275255
Iteration 28/1000 | Loss: 0.00211854
Iteration 29/1000 | Loss: 0.00022156
Iteration 30/1000 | Loss: 0.00005777
Iteration 31/1000 | Loss: 0.00011411
Iteration 32/1000 | Loss: 0.00150085
Iteration 33/1000 | Loss: 0.00283230
Iteration 34/1000 | Loss: 0.00258637
Iteration 35/1000 | Loss: 0.00249281
Iteration 36/1000 | Loss: 0.00537147
Iteration 37/1000 | Loss: 0.00656887
Iteration 38/1000 | Loss: 0.00279974
Iteration 39/1000 | Loss: 0.00468942
Iteration 40/1000 | Loss: 0.00319564
Iteration 41/1000 | Loss: 0.00375243
Iteration 42/1000 | Loss: 0.00241612
Iteration 43/1000 | Loss: 0.00211914
Iteration 44/1000 | Loss: 0.00210148
Iteration 45/1000 | Loss: 0.00238117
Iteration 46/1000 | Loss: 0.00114414
Iteration 47/1000 | Loss: 0.00131072
Iteration 48/1000 | Loss: 0.00110780
Iteration 49/1000 | Loss: 0.00100795
Iteration 50/1000 | Loss: 0.00145580
Iteration 51/1000 | Loss: 0.00019640
Iteration 52/1000 | Loss: 0.00142334
Iteration 53/1000 | Loss: 0.00107954
Iteration 54/1000 | Loss: 0.00107716
Iteration 55/1000 | Loss: 0.00031083
Iteration 56/1000 | Loss: 0.00076978
Iteration 57/1000 | Loss: 0.00007971
Iteration 58/1000 | Loss: 0.00216815
Iteration 59/1000 | Loss: 0.00202663
Iteration 60/1000 | Loss: 0.00005907
Iteration 61/1000 | Loss: 0.00194385
Iteration 62/1000 | Loss: 0.00225175
Iteration 63/1000 | Loss: 0.00171519
Iteration 64/1000 | Loss: 0.00003913
Iteration 65/1000 | Loss: 0.00003133
Iteration 66/1000 | Loss: 0.00002752
Iteration 67/1000 | Loss: 0.00002552
Iteration 68/1000 | Loss: 0.00002445
Iteration 69/1000 | Loss: 0.00055217
Iteration 70/1000 | Loss: 0.00063876
Iteration 71/1000 | Loss: 0.00140037
Iteration 72/1000 | Loss: 0.00144625
Iteration 73/1000 | Loss: 0.00086745
Iteration 74/1000 | Loss: 0.00102480
Iteration 75/1000 | Loss: 0.00125032
Iteration 76/1000 | Loss: 0.00135889
Iteration 77/1000 | Loss: 0.00152992
Iteration 78/1000 | Loss: 0.00273589
Iteration 79/1000 | Loss: 0.00091324
Iteration 80/1000 | Loss: 0.00148356
Iteration 81/1000 | Loss: 0.00105454
Iteration 82/1000 | Loss: 0.00131822
Iteration 83/1000 | Loss: 0.00169618
Iteration 84/1000 | Loss: 0.00243041
Iteration 85/1000 | Loss: 0.00104590
Iteration 86/1000 | Loss: 0.00163071
Iteration 87/1000 | Loss: 0.00082598
Iteration 88/1000 | Loss: 0.00112226
Iteration 89/1000 | Loss: 0.00112809
Iteration 90/1000 | Loss: 0.00220591
Iteration 91/1000 | Loss: 0.00222864
Iteration 92/1000 | Loss: 0.00007758
Iteration 93/1000 | Loss: 0.00004406
Iteration 94/1000 | Loss: 0.00012999
Iteration 95/1000 | Loss: 0.00002687
Iteration 96/1000 | Loss: 0.00001922
Iteration 97/1000 | Loss: 0.00001602
Iteration 98/1000 | Loss: 0.00016021
Iteration 99/1000 | Loss: 0.00002154
Iteration 100/1000 | Loss: 0.00001627
Iteration 101/1000 | Loss: 0.00001417
Iteration 102/1000 | Loss: 0.00001323
Iteration 103/1000 | Loss: 0.00001294
Iteration 104/1000 | Loss: 0.00001269
Iteration 105/1000 | Loss: 0.00001251
Iteration 106/1000 | Loss: 0.00001236
Iteration 107/1000 | Loss: 0.00001230
Iteration 108/1000 | Loss: 0.00001219
Iteration 109/1000 | Loss: 0.00001219
Iteration 110/1000 | Loss: 0.00001219
Iteration 111/1000 | Loss: 0.00001219
Iteration 112/1000 | Loss: 0.00001219
Iteration 113/1000 | Loss: 0.00001218
Iteration 114/1000 | Loss: 0.00001217
Iteration 115/1000 | Loss: 0.00001217
Iteration 116/1000 | Loss: 0.00001216
Iteration 117/1000 | Loss: 0.00001216
Iteration 118/1000 | Loss: 0.00001216
Iteration 119/1000 | Loss: 0.00001216
Iteration 120/1000 | Loss: 0.00001216
Iteration 121/1000 | Loss: 0.00001216
Iteration 122/1000 | Loss: 0.00001216
Iteration 123/1000 | Loss: 0.00001216
Iteration 124/1000 | Loss: 0.00001215
Iteration 125/1000 | Loss: 0.00001215
Iteration 126/1000 | Loss: 0.00001215
Iteration 127/1000 | Loss: 0.00001215
Iteration 128/1000 | Loss: 0.00001214
Iteration 129/1000 | Loss: 0.00001214
Iteration 130/1000 | Loss: 0.00001213
Iteration 131/1000 | Loss: 0.00001213
Iteration 132/1000 | Loss: 0.00001212
Iteration 133/1000 | Loss: 0.00001212
Iteration 134/1000 | Loss: 0.00001212
Iteration 135/1000 | Loss: 0.00001211
Iteration 136/1000 | Loss: 0.00001211
Iteration 137/1000 | Loss: 0.00001211
Iteration 138/1000 | Loss: 0.00001211
Iteration 139/1000 | Loss: 0.00001210
Iteration 140/1000 | Loss: 0.00001210
Iteration 141/1000 | Loss: 0.00001210
Iteration 142/1000 | Loss: 0.00001210
Iteration 143/1000 | Loss: 0.00001210
Iteration 144/1000 | Loss: 0.00001209
Iteration 145/1000 | Loss: 0.00001209
Iteration 146/1000 | Loss: 0.00001209
Iteration 147/1000 | Loss: 0.00001208
Iteration 148/1000 | Loss: 0.00001208
Iteration 149/1000 | Loss: 0.00001208
Iteration 150/1000 | Loss: 0.00001208
Iteration 151/1000 | Loss: 0.00001208
Iteration 152/1000 | Loss: 0.00001208
Iteration 153/1000 | Loss: 0.00001207
Iteration 154/1000 | Loss: 0.00001207
Iteration 155/1000 | Loss: 0.00001207
Iteration 156/1000 | Loss: 0.00001207
Iteration 157/1000 | Loss: 0.00001207
Iteration 158/1000 | Loss: 0.00001207
Iteration 159/1000 | Loss: 0.00001206
Iteration 160/1000 | Loss: 0.00001206
Iteration 161/1000 | Loss: 0.00001206
Iteration 162/1000 | Loss: 0.00001206
Iteration 163/1000 | Loss: 0.00001206
Iteration 164/1000 | Loss: 0.00001205
Iteration 165/1000 | Loss: 0.00001205
Iteration 166/1000 | Loss: 0.00001205
Iteration 167/1000 | Loss: 0.00001205
Iteration 168/1000 | Loss: 0.00001205
Iteration 169/1000 | Loss: 0.00001205
Iteration 170/1000 | Loss: 0.00001205
Iteration 171/1000 | Loss: 0.00001204
Iteration 172/1000 | Loss: 0.00001204
Iteration 173/1000 | Loss: 0.00001204
Iteration 174/1000 | Loss: 0.00001204
Iteration 175/1000 | Loss: 0.00001204
Iteration 176/1000 | Loss: 0.00001203
Iteration 177/1000 | Loss: 0.00001203
Iteration 178/1000 | Loss: 0.00001203
Iteration 179/1000 | Loss: 0.00001203
Iteration 180/1000 | Loss: 0.00001203
Iteration 181/1000 | Loss: 0.00001202
Iteration 182/1000 | Loss: 0.00001202
Iteration 183/1000 | Loss: 0.00001202
Iteration 184/1000 | Loss: 0.00001201
Iteration 185/1000 | Loss: 0.00001201
Iteration 186/1000 | Loss: 0.00001200
Iteration 187/1000 | Loss: 0.00001200
Iteration 188/1000 | Loss: 0.00001200
Iteration 189/1000 | Loss: 0.00001200
Iteration 190/1000 | Loss: 0.00001199
Iteration 191/1000 | Loss: 0.00001199
Iteration 192/1000 | Loss: 0.00001199
Iteration 193/1000 | Loss: 0.00001199
Iteration 194/1000 | Loss: 0.00001199
Iteration 195/1000 | Loss: 0.00001199
Iteration 196/1000 | Loss: 0.00001199
Iteration 197/1000 | Loss: 0.00001199
Iteration 198/1000 | Loss: 0.00001199
Iteration 199/1000 | Loss: 0.00001199
Iteration 200/1000 | Loss: 0.00001199
Iteration 201/1000 | Loss: 0.00001199
Iteration 202/1000 | Loss: 0.00001199
Iteration 203/1000 | Loss: 0.00001199
Iteration 204/1000 | Loss: 0.00001199
Iteration 205/1000 | Loss: 0.00001199
Iteration 206/1000 | Loss: 0.00001199
Iteration 207/1000 | Loss: 0.00001199
Iteration 208/1000 | Loss: 0.00001198
Iteration 209/1000 | Loss: 0.00001198
Iteration 210/1000 | Loss: 0.00001198
Iteration 211/1000 | Loss: 0.00001198
Iteration 212/1000 | Loss: 0.00001198
Iteration 213/1000 | Loss: 0.00001198
Iteration 214/1000 | Loss: 0.00001198
Iteration 215/1000 | Loss: 0.00001198
Iteration 216/1000 | Loss: 0.00001198
Iteration 217/1000 | Loss: 0.00001198
Iteration 218/1000 | Loss: 0.00001198
Iteration 219/1000 | Loss: 0.00001198
Iteration 220/1000 | Loss: 0.00001198
Iteration 221/1000 | Loss: 0.00001198
Iteration 222/1000 | Loss: 0.00001198
Iteration 223/1000 | Loss: 0.00001198
Iteration 224/1000 | Loss: 0.00001198
Iteration 225/1000 | Loss: 0.00001198
Iteration 226/1000 | Loss: 0.00001198
Iteration 227/1000 | Loss: 0.00001198
Iteration 228/1000 | Loss: 0.00001198
Iteration 229/1000 | Loss: 0.00001198
Iteration 230/1000 | Loss: 0.00001198
Iteration 231/1000 | Loss: 0.00001198
Iteration 232/1000 | Loss: 0.00001198
Iteration 233/1000 | Loss: 0.00001198
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 233. Stopping optimization.
Last 5 losses: [1.1984262528130785e-05, 1.1984262528130785e-05, 1.1984262528130785e-05, 1.1984262528130785e-05, 1.1984262528130785e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1984262528130785e-05

Optimization complete. Final v2v error: 2.9361846446990967 mm

Highest mean error: 4.143699645996094 mm for frame 47

Lowest mean error: 2.7333688735961914 mm for frame 0

Saving results

Total time: 205.856849193573
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1096/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1096.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1096
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00395656
Iteration 2/25 | Loss: 0.00084114
Iteration 3/25 | Loss: 0.00073747
Iteration 4/25 | Loss: 0.00072006
Iteration 5/25 | Loss: 0.00071479
Iteration 6/25 | Loss: 0.00071380
Iteration 7/25 | Loss: 0.00071380
Iteration 8/25 | Loss: 0.00071380
Iteration 9/25 | Loss: 0.00071380
Iteration 10/25 | Loss: 0.00071380
Iteration 11/25 | Loss: 0.00071380
Iteration 12/25 | Loss: 0.00071380
Iteration 13/25 | Loss: 0.00071380
Iteration 14/25 | Loss: 0.00071380
Iteration 15/25 | Loss: 0.00071380
Iteration 16/25 | Loss: 0.00071380
Iteration 17/25 | Loss: 0.00071380
Iteration 18/25 | Loss: 0.00071380
Iteration 19/25 | Loss: 0.00071380
Iteration 20/25 | Loss: 0.00071380
Iteration 21/25 | Loss: 0.00071380
Iteration 22/25 | Loss: 0.00071380
Iteration 23/25 | Loss: 0.00071380
Iteration 24/25 | Loss: 0.00071380
Iteration 25/25 | Loss: 0.00071380

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.09118891
Iteration 2/25 | Loss: 0.00045009
Iteration 3/25 | Loss: 0.00045009
Iteration 4/25 | Loss: 0.00045009
Iteration 5/25 | Loss: 0.00045008
Iteration 6/25 | Loss: 0.00045008
Iteration 7/25 | Loss: 0.00045008
Iteration 8/25 | Loss: 0.00045008
Iteration 9/25 | Loss: 0.00045008
Iteration 10/25 | Loss: 0.00045008
Iteration 11/25 | Loss: 0.00045008
Iteration 12/25 | Loss: 0.00045008
Iteration 13/25 | Loss: 0.00045008
Iteration 14/25 | Loss: 0.00045008
Iteration 15/25 | Loss: 0.00045008
Iteration 16/25 | Loss: 0.00045008
Iteration 17/25 | Loss: 0.00045008
Iteration 18/25 | Loss: 0.00045008
Iteration 19/25 | Loss: 0.00045008
Iteration 20/25 | Loss: 0.00045008
Iteration 21/25 | Loss: 0.00045008
Iteration 22/25 | Loss: 0.00045008
Iteration 23/25 | Loss: 0.00045008
Iteration 24/25 | Loss: 0.00045008
Iteration 25/25 | Loss: 0.00045008

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00045008
Iteration 2/1000 | Loss: 0.00002127
Iteration 3/1000 | Loss: 0.00001708
Iteration 4/1000 | Loss: 0.00001590
Iteration 5/1000 | Loss: 0.00001492
Iteration 6/1000 | Loss: 0.00001439
Iteration 7/1000 | Loss: 0.00001410
Iteration 8/1000 | Loss: 0.00001386
Iteration 9/1000 | Loss: 0.00001366
Iteration 10/1000 | Loss: 0.00001363
Iteration 11/1000 | Loss: 0.00001358
Iteration 12/1000 | Loss: 0.00001357
Iteration 13/1000 | Loss: 0.00001355
Iteration 14/1000 | Loss: 0.00001354
Iteration 15/1000 | Loss: 0.00001354
Iteration 16/1000 | Loss: 0.00001354
Iteration 17/1000 | Loss: 0.00001354
Iteration 18/1000 | Loss: 0.00001353
Iteration 19/1000 | Loss: 0.00001350
Iteration 20/1000 | Loss: 0.00001348
Iteration 21/1000 | Loss: 0.00001348
Iteration 22/1000 | Loss: 0.00001348
Iteration 23/1000 | Loss: 0.00001346
Iteration 24/1000 | Loss: 0.00001342
Iteration 25/1000 | Loss: 0.00001342
Iteration 26/1000 | Loss: 0.00001341
Iteration 27/1000 | Loss: 0.00001334
Iteration 28/1000 | Loss: 0.00001334
Iteration 29/1000 | Loss: 0.00001333
Iteration 30/1000 | Loss: 0.00001333
Iteration 31/1000 | Loss: 0.00001332
Iteration 32/1000 | Loss: 0.00001332
Iteration 33/1000 | Loss: 0.00001331
Iteration 34/1000 | Loss: 0.00001331
Iteration 35/1000 | Loss: 0.00001331
Iteration 36/1000 | Loss: 0.00001330
Iteration 37/1000 | Loss: 0.00001329
Iteration 38/1000 | Loss: 0.00001329
Iteration 39/1000 | Loss: 0.00001329
Iteration 40/1000 | Loss: 0.00001328
Iteration 41/1000 | Loss: 0.00001327
Iteration 42/1000 | Loss: 0.00001325
Iteration 43/1000 | Loss: 0.00001325
Iteration 44/1000 | Loss: 0.00001324
Iteration 45/1000 | Loss: 0.00001324
Iteration 46/1000 | Loss: 0.00001321
Iteration 47/1000 | Loss: 0.00001321
Iteration 48/1000 | Loss: 0.00001320
Iteration 49/1000 | Loss: 0.00001317
Iteration 50/1000 | Loss: 0.00001316
Iteration 51/1000 | Loss: 0.00001315
Iteration 52/1000 | Loss: 0.00001315
Iteration 53/1000 | Loss: 0.00001315
Iteration 54/1000 | Loss: 0.00001308
Iteration 55/1000 | Loss: 0.00001308
Iteration 56/1000 | Loss: 0.00001308
Iteration 57/1000 | Loss: 0.00001308
Iteration 58/1000 | Loss: 0.00001307
Iteration 59/1000 | Loss: 0.00001306
Iteration 60/1000 | Loss: 0.00001305
Iteration 61/1000 | Loss: 0.00001305
Iteration 62/1000 | Loss: 0.00001305
Iteration 63/1000 | Loss: 0.00001305
Iteration 64/1000 | Loss: 0.00001305
Iteration 65/1000 | Loss: 0.00001305
Iteration 66/1000 | Loss: 0.00001305
Iteration 67/1000 | Loss: 0.00001305
Iteration 68/1000 | Loss: 0.00001304
Iteration 69/1000 | Loss: 0.00001304
Iteration 70/1000 | Loss: 0.00001304
Iteration 71/1000 | Loss: 0.00001304
Iteration 72/1000 | Loss: 0.00001304
Iteration 73/1000 | Loss: 0.00001303
Iteration 74/1000 | Loss: 0.00001303
Iteration 75/1000 | Loss: 0.00001303
Iteration 76/1000 | Loss: 0.00001303
Iteration 77/1000 | Loss: 0.00001303
Iteration 78/1000 | Loss: 0.00001303
Iteration 79/1000 | Loss: 0.00001303
Iteration 80/1000 | Loss: 0.00001303
Iteration 81/1000 | Loss: 0.00001303
Iteration 82/1000 | Loss: 0.00001303
Iteration 83/1000 | Loss: 0.00001303
Iteration 84/1000 | Loss: 0.00001303
Iteration 85/1000 | Loss: 0.00001302
Iteration 86/1000 | Loss: 0.00001302
Iteration 87/1000 | Loss: 0.00001302
Iteration 88/1000 | Loss: 0.00001302
Iteration 89/1000 | Loss: 0.00001302
Iteration 90/1000 | Loss: 0.00001302
Iteration 91/1000 | Loss: 0.00001302
Iteration 92/1000 | Loss: 0.00001302
Iteration 93/1000 | Loss: 0.00001302
Iteration 94/1000 | Loss: 0.00001302
Iteration 95/1000 | Loss: 0.00001302
Iteration 96/1000 | Loss: 0.00001302
Iteration 97/1000 | Loss: 0.00001302
Iteration 98/1000 | Loss: 0.00001301
Iteration 99/1000 | Loss: 0.00001301
Iteration 100/1000 | Loss: 0.00001301
Iteration 101/1000 | Loss: 0.00001301
Iteration 102/1000 | Loss: 0.00001301
Iteration 103/1000 | Loss: 0.00001301
Iteration 104/1000 | Loss: 0.00001301
Iteration 105/1000 | Loss: 0.00001301
Iteration 106/1000 | Loss: 0.00001301
Iteration 107/1000 | Loss: 0.00001301
Iteration 108/1000 | Loss: 0.00001300
Iteration 109/1000 | Loss: 0.00001300
Iteration 110/1000 | Loss: 0.00001300
Iteration 111/1000 | Loss: 0.00001300
Iteration 112/1000 | Loss: 0.00001300
Iteration 113/1000 | Loss: 0.00001300
Iteration 114/1000 | Loss: 0.00001300
Iteration 115/1000 | Loss: 0.00001299
Iteration 116/1000 | Loss: 0.00001299
Iteration 117/1000 | Loss: 0.00001299
Iteration 118/1000 | Loss: 0.00001299
Iteration 119/1000 | Loss: 0.00001299
Iteration 120/1000 | Loss: 0.00001299
Iteration 121/1000 | Loss: 0.00001299
Iteration 122/1000 | Loss: 0.00001299
Iteration 123/1000 | Loss: 0.00001299
Iteration 124/1000 | Loss: 0.00001299
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 124. Stopping optimization.
Last 5 losses: [1.2990648428967688e-05, 1.2990648428967688e-05, 1.2990648428967688e-05, 1.2990648428967688e-05, 1.2990648428967688e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2990648428967688e-05

Optimization complete. Final v2v error: 3.0823922157287598 mm

Highest mean error: 3.3281731605529785 mm for frame 139

Lowest mean error: 2.978564977645874 mm for frame 203

Saving results

Total time: 38.734381437301636
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1076/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1076.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1076
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01033398
Iteration 2/25 | Loss: 0.00356986
Iteration 3/25 | Loss: 0.00170551
Iteration 4/25 | Loss: 0.00146048
Iteration 5/25 | Loss: 0.00137647
Iteration 6/25 | Loss: 0.00135912
Iteration 7/25 | Loss: 0.00141424
Iteration 8/25 | Loss: 0.00132368
Iteration 9/25 | Loss: 0.00120153
Iteration 10/25 | Loss: 0.00111998
Iteration 11/25 | Loss: 0.00105296
Iteration 12/25 | Loss: 0.00103492
Iteration 13/25 | Loss: 0.00101188
Iteration 14/25 | Loss: 0.00099203
Iteration 15/25 | Loss: 0.00097905
Iteration 16/25 | Loss: 0.00098176
Iteration 17/25 | Loss: 0.00097222
Iteration 18/25 | Loss: 0.00096917
Iteration 19/25 | Loss: 0.00096612
Iteration 20/25 | Loss: 0.00095944
Iteration 21/25 | Loss: 0.00095670
Iteration 22/25 | Loss: 0.00095918
Iteration 23/25 | Loss: 0.00095652
Iteration 24/25 | Loss: 0.00096015
Iteration 25/25 | Loss: 0.00095543

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.56728947
Iteration 2/25 | Loss: 0.00262490
Iteration 3/25 | Loss: 0.00259070
Iteration 4/25 | Loss: 0.00259070
Iteration 5/25 | Loss: 0.00259070
Iteration 6/25 | Loss: 0.00259070
Iteration 7/25 | Loss: 0.00259070
Iteration 8/25 | Loss: 0.00259070
Iteration 9/25 | Loss: 0.00259070
Iteration 10/25 | Loss: 0.00259070
Iteration 11/25 | Loss: 0.00259070
Iteration 12/25 | Loss: 0.00259070
Iteration 13/25 | Loss: 0.00259070
Iteration 14/25 | Loss: 0.00259070
Iteration 15/25 | Loss: 0.00259070
Iteration 16/25 | Loss: 0.00259070
Iteration 17/25 | Loss: 0.00259070
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0025906998198479414, 0.0025906998198479414, 0.0025906998198479414, 0.0025906998198479414, 0.0025906998198479414]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0025906998198479414

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00259070
Iteration 2/1000 | Loss: 0.00242738
Iteration 3/1000 | Loss: 0.00077444
Iteration 4/1000 | Loss: 0.00117371
Iteration 5/1000 | Loss: 0.00099076
Iteration 6/1000 | Loss: 0.00081864
Iteration 7/1000 | Loss: 0.00165339
Iteration 8/1000 | Loss: 0.00091613
Iteration 9/1000 | Loss: 0.00346216
Iteration 10/1000 | Loss: 0.00231335
Iteration 11/1000 | Loss: 0.00104801
Iteration 12/1000 | Loss: 0.00262312
Iteration 13/1000 | Loss: 0.00198994
Iteration 14/1000 | Loss: 0.00205619
Iteration 15/1000 | Loss: 0.00142442
Iteration 16/1000 | Loss: 0.00123246
Iteration 17/1000 | Loss: 0.00344178
Iteration 18/1000 | Loss: 0.00120024
Iteration 19/1000 | Loss: 0.00114709
Iteration 20/1000 | Loss: 0.00070788
Iteration 21/1000 | Loss: 0.00102327
Iteration 22/1000 | Loss: 0.00029631
Iteration 23/1000 | Loss: 0.00172237
Iteration 24/1000 | Loss: 0.00040343
Iteration 25/1000 | Loss: 0.00030396
Iteration 26/1000 | Loss: 0.00106423
Iteration 27/1000 | Loss: 0.00125190
Iteration 28/1000 | Loss: 0.00110742
Iteration 29/1000 | Loss: 0.00099598
Iteration 30/1000 | Loss: 0.00094228
Iteration 31/1000 | Loss: 0.00111080
Iteration 32/1000 | Loss: 0.00076302
Iteration 33/1000 | Loss: 0.00088255
Iteration 34/1000 | Loss: 0.00062818
Iteration 35/1000 | Loss: 0.00055190
Iteration 36/1000 | Loss: 0.00095643
Iteration 37/1000 | Loss: 0.00041010
Iteration 38/1000 | Loss: 0.00071379
Iteration 39/1000 | Loss: 0.00039906
Iteration 40/1000 | Loss: 0.00112021
Iteration 41/1000 | Loss: 0.00043204
Iteration 42/1000 | Loss: 0.00044844
Iteration 43/1000 | Loss: 0.00113353
Iteration 44/1000 | Loss: 0.00085063
Iteration 45/1000 | Loss: 0.00128848
Iteration 46/1000 | Loss: 0.00111106
Iteration 47/1000 | Loss: 0.00081649
Iteration 48/1000 | Loss: 0.00053481
Iteration 49/1000 | Loss: 0.00062656
Iteration 50/1000 | Loss: 0.00024315
Iteration 51/1000 | Loss: 0.00152582
Iteration 52/1000 | Loss: 0.00067877
Iteration 53/1000 | Loss: 0.00047740
Iteration 54/1000 | Loss: 0.00045877
Iteration 55/1000 | Loss: 0.00184416
Iteration 56/1000 | Loss: 0.00109085
Iteration 57/1000 | Loss: 0.00129110
Iteration 58/1000 | Loss: 0.00050848
Iteration 59/1000 | Loss: 0.00066116
Iteration 60/1000 | Loss: 0.00055892
Iteration 61/1000 | Loss: 0.00023124
Iteration 62/1000 | Loss: 0.00046654
Iteration 63/1000 | Loss: 0.00036213
Iteration 64/1000 | Loss: 0.00033290
Iteration 65/1000 | Loss: 0.00033401
Iteration 66/1000 | Loss: 0.00047194
Iteration 67/1000 | Loss: 0.00108113
Iteration 68/1000 | Loss: 0.00089055
Iteration 69/1000 | Loss: 0.00088688
Iteration 70/1000 | Loss: 0.00229941
Iteration 71/1000 | Loss: 0.00042933
Iteration 72/1000 | Loss: 0.00061697
Iteration 73/1000 | Loss: 0.00072129
Iteration 74/1000 | Loss: 0.00166270
Iteration 75/1000 | Loss: 0.00137319
Iteration 76/1000 | Loss: 0.00057592
Iteration 77/1000 | Loss: 0.00060524
Iteration 78/1000 | Loss: 0.00034823
Iteration 79/1000 | Loss: 0.00107685
Iteration 80/1000 | Loss: 0.00056616
Iteration 81/1000 | Loss: 0.00013957
Iteration 82/1000 | Loss: 0.00032523
Iteration 83/1000 | Loss: 0.00006688
Iteration 84/1000 | Loss: 0.00017216
Iteration 85/1000 | Loss: 0.00036483
Iteration 86/1000 | Loss: 0.00039115
Iteration 87/1000 | Loss: 0.00023013
Iteration 88/1000 | Loss: 0.00227994
Iteration 89/1000 | Loss: 0.00063876
Iteration 90/1000 | Loss: 0.00167923
Iteration 91/1000 | Loss: 0.00061207
Iteration 92/1000 | Loss: 0.00066359
Iteration 93/1000 | Loss: 0.00027244
Iteration 94/1000 | Loss: 0.00018026
Iteration 95/1000 | Loss: 0.00005313
Iteration 96/1000 | Loss: 0.00005764
Iteration 97/1000 | Loss: 0.00011522
Iteration 98/1000 | Loss: 0.00004981
Iteration 99/1000 | Loss: 0.00015612
Iteration 100/1000 | Loss: 0.00013155
Iteration 101/1000 | Loss: 0.00032962
Iteration 102/1000 | Loss: 0.00167705
Iteration 103/1000 | Loss: 0.00132319
Iteration 104/1000 | Loss: 0.00016034
Iteration 105/1000 | Loss: 0.00020997
Iteration 106/1000 | Loss: 0.00008352
Iteration 107/1000 | Loss: 0.00048382
Iteration 108/1000 | Loss: 0.00080889
Iteration 109/1000 | Loss: 0.00032764
Iteration 110/1000 | Loss: 0.00037906
Iteration 111/1000 | Loss: 0.00044571
Iteration 112/1000 | Loss: 0.00039449
Iteration 113/1000 | Loss: 0.00055139
Iteration 114/1000 | Loss: 0.00035431
Iteration 115/1000 | Loss: 0.00048391
Iteration 116/1000 | Loss: 0.00043900
Iteration 117/1000 | Loss: 0.00035037
Iteration 118/1000 | Loss: 0.00044539
Iteration 119/1000 | Loss: 0.00020630
Iteration 120/1000 | Loss: 0.00009158
Iteration 121/1000 | Loss: 0.00016808
Iteration 122/1000 | Loss: 0.00016907
Iteration 123/1000 | Loss: 0.00009503
Iteration 124/1000 | Loss: 0.00009730
Iteration 125/1000 | Loss: 0.00011400
Iteration 126/1000 | Loss: 0.00155494
Iteration 127/1000 | Loss: 0.00069742
Iteration 128/1000 | Loss: 0.00058644
Iteration 129/1000 | Loss: 0.00004723
Iteration 130/1000 | Loss: 0.00004554
Iteration 131/1000 | Loss: 0.00006163
Iteration 132/1000 | Loss: 0.00004264
Iteration 133/1000 | Loss: 0.00003929
Iteration 134/1000 | Loss: 0.00003297
Iteration 135/1000 | Loss: 0.00004973
Iteration 136/1000 | Loss: 0.00004158
Iteration 137/1000 | Loss: 0.00021944
Iteration 138/1000 | Loss: 0.00003589
Iteration 139/1000 | Loss: 0.00005443
Iteration 140/1000 | Loss: 0.00002359
Iteration 141/1000 | Loss: 0.00002124
Iteration 142/1000 | Loss: 0.00001997
Iteration 143/1000 | Loss: 0.00001916
Iteration 144/1000 | Loss: 0.00001843
Iteration 145/1000 | Loss: 0.00002488
Iteration 146/1000 | Loss: 0.00025918
Iteration 147/1000 | Loss: 0.00019910
Iteration 148/1000 | Loss: 0.00002003
Iteration 149/1000 | Loss: 0.00001726
Iteration 150/1000 | Loss: 0.00001655
Iteration 151/1000 | Loss: 0.00026497
Iteration 152/1000 | Loss: 0.00019095
Iteration 153/1000 | Loss: 0.00022261
Iteration 154/1000 | Loss: 0.00003062
Iteration 155/1000 | Loss: 0.00004436
Iteration 156/1000 | Loss: 0.00001791
Iteration 157/1000 | Loss: 0.00001634
Iteration 158/1000 | Loss: 0.00001558
Iteration 159/1000 | Loss: 0.00001525
Iteration 160/1000 | Loss: 0.00001505
Iteration 161/1000 | Loss: 0.00001501
Iteration 162/1000 | Loss: 0.00001501
Iteration 163/1000 | Loss: 0.00001500
Iteration 164/1000 | Loss: 0.00001499
Iteration 165/1000 | Loss: 0.00001498
Iteration 166/1000 | Loss: 0.00001496
Iteration 167/1000 | Loss: 0.00001496
Iteration 168/1000 | Loss: 0.00001489
Iteration 169/1000 | Loss: 0.00001488
Iteration 170/1000 | Loss: 0.00001486
Iteration 171/1000 | Loss: 0.00001484
Iteration 172/1000 | Loss: 0.00001481
Iteration 173/1000 | Loss: 0.00001480
Iteration 174/1000 | Loss: 0.00001480
Iteration 175/1000 | Loss: 0.00001477
Iteration 176/1000 | Loss: 0.00001477
Iteration 177/1000 | Loss: 0.00001469
Iteration 178/1000 | Loss: 0.00001469
Iteration 179/1000 | Loss: 0.00001467
Iteration 180/1000 | Loss: 0.00001466
Iteration 181/1000 | Loss: 0.00001466
Iteration 182/1000 | Loss: 0.00001466
Iteration 183/1000 | Loss: 0.00001466
Iteration 184/1000 | Loss: 0.00001466
Iteration 185/1000 | Loss: 0.00001465
Iteration 186/1000 | Loss: 0.00001465
Iteration 187/1000 | Loss: 0.00001465
Iteration 188/1000 | Loss: 0.00001465
Iteration 189/1000 | Loss: 0.00001464
Iteration 190/1000 | Loss: 0.00001464
Iteration 191/1000 | Loss: 0.00001464
Iteration 192/1000 | Loss: 0.00001464
Iteration 193/1000 | Loss: 0.00001463
Iteration 194/1000 | Loss: 0.00001463
Iteration 195/1000 | Loss: 0.00001462
Iteration 196/1000 | Loss: 0.00001462
Iteration 197/1000 | Loss: 0.00001462
Iteration 198/1000 | Loss: 0.00001462
Iteration 199/1000 | Loss: 0.00001461
Iteration 200/1000 | Loss: 0.00001461
Iteration 201/1000 | Loss: 0.00001461
Iteration 202/1000 | Loss: 0.00001461
Iteration 203/1000 | Loss: 0.00001460
Iteration 204/1000 | Loss: 0.00001460
Iteration 205/1000 | Loss: 0.00001460
Iteration 206/1000 | Loss: 0.00001460
Iteration 207/1000 | Loss: 0.00001459
Iteration 208/1000 | Loss: 0.00001459
Iteration 209/1000 | Loss: 0.00001459
Iteration 210/1000 | Loss: 0.00001459
Iteration 211/1000 | Loss: 0.00001459
Iteration 212/1000 | Loss: 0.00001458
Iteration 213/1000 | Loss: 0.00001458
Iteration 214/1000 | Loss: 0.00001458
Iteration 215/1000 | Loss: 0.00001458
Iteration 216/1000 | Loss: 0.00001458
Iteration 217/1000 | Loss: 0.00001458
Iteration 218/1000 | Loss: 0.00001458
Iteration 219/1000 | Loss: 0.00001457
Iteration 220/1000 | Loss: 0.00001457
Iteration 221/1000 | Loss: 0.00001457
Iteration 222/1000 | Loss: 0.00001457
Iteration 223/1000 | Loss: 0.00001457
Iteration 224/1000 | Loss: 0.00001457
Iteration 225/1000 | Loss: 0.00001457
Iteration 226/1000 | Loss: 0.00001457
Iteration 227/1000 | Loss: 0.00001456
Iteration 228/1000 | Loss: 0.00001456
Iteration 229/1000 | Loss: 0.00001456
Iteration 230/1000 | Loss: 0.00001456
Iteration 231/1000 | Loss: 0.00001456
Iteration 232/1000 | Loss: 0.00001456
Iteration 233/1000 | Loss: 0.00001456
Iteration 234/1000 | Loss: 0.00001456
Iteration 235/1000 | Loss: 0.00001456
Iteration 236/1000 | Loss: 0.00001456
Iteration 237/1000 | Loss: 0.00001455
Iteration 238/1000 | Loss: 0.00001455
Iteration 239/1000 | Loss: 0.00001455
Iteration 240/1000 | Loss: 0.00001455
Iteration 241/1000 | Loss: 0.00001455
Iteration 242/1000 | Loss: 0.00001454
Iteration 243/1000 | Loss: 0.00001454
Iteration 244/1000 | Loss: 0.00001454
Iteration 245/1000 | Loss: 0.00001454
Iteration 246/1000 | Loss: 0.00001453
Iteration 247/1000 | Loss: 0.00001453
Iteration 248/1000 | Loss: 0.00001453
Iteration 249/1000 | Loss: 0.00001453
Iteration 250/1000 | Loss: 0.00001453
Iteration 251/1000 | Loss: 0.00001453
Iteration 252/1000 | Loss: 0.00001452
Iteration 253/1000 | Loss: 0.00001452
Iteration 254/1000 | Loss: 0.00001452
Iteration 255/1000 | Loss: 0.00001452
Iteration 256/1000 | Loss: 0.00001452
Iteration 257/1000 | Loss: 0.00001452
Iteration 258/1000 | Loss: 0.00001452
Iteration 259/1000 | Loss: 0.00001452
Iteration 260/1000 | Loss: 0.00001452
Iteration 261/1000 | Loss: 0.00001452
Iteration 262/1000 | Loss: 0.00001452
Iteration 263/1000 | Loss: 0.00001452
Iteration 264/1000 | Loss: 0.00001452
Iteration 265/1000 | Loss: 0.00001452
Iteration 266/1000 | Loss: 0.00001452
Iteration 267/1000 | Loss: 0.00001452
Iteration 268/1000 | Loss: 0.00001452
Iteration 269/1000 | Loss: 0.00001452
Iteration 270/1000 | Loss: 0.00001452
Iteration 271/1000 | Loss: 0.00001452
Iteration 272/1000 | Loss: 0.00001452
Iteration 273/1000 | Loss: 0.00001452
Iteration 274/1000 | Loss: 0.00001452
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 274. Stopping optimization.
Last 5 losses: [1.4515285329252947e-05, 1.4515285329252947e-05, 1.4515285329252947e-05, 1.4515285329252947e-05, 1.4515285329252947e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4515285329252947e-05

Optimization complete. Final v2v error: 3.1768929958343506 mm

Highest mean error: 4.555177688598633 mm for frame 47

Lowest mean error: 2.389131784439087 mm for frame 21

Saving results

Total time: 323.255259513855
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1075/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1075.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1075
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00897901
Iteration 2/25 | Loss: 0.00139259
Iteration 3/25 | Loss: 0.00109273
Iteration 4/25 | Loss: 0.00101433
Iteration 5/25 | Loss: 0.00098297
Iteration 6/25 | Loss: 0.00097419
Iteration 7/25 | Loss: 0.00099381
Iteration 8/25 | Loss: 0.00097682
Iteration 9/25 | Loss: 0.00094437
Iteration 10/25 | Loss: 0.00097071
Iteration 11/25 | Loss: 0.00092269
Iteration 12/25 | Loss: 0.00092215
Iteration 13/25 | Loss: 0.00090358
Iteration 14/25 | Loss: 0.00088662
Iteration 15/25 | Loss: 0.00087931
Iteration 16/25 | Loss: 0.00087965
Iteration 17/25 | Loss: 0.00087357
Iteration 18/25 | Loss: 0.00087044
Iteration 19/25 | Loss: 0.00086606
Iteration 20/25 | Loss: 0.00087645
Iteration 21/25 | Loss: 0.00087796
Iteration 22/25 | Loss: 0.00088920
Iteration 23/25 | Loss: 0.00088201
Iteration 24/25 | Loss: 0.00087472
Iteration 25/25 | Loss: 0.00088440

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51585007
Iteration 2/25 | Loss: 0.00180001
Iteration 3/25 | Loss: 0.00180001
Iteration 4/25 | Loss: 0.00180001
Iteration 5/25 | Loss: 0.00180001
Iteration 6/25 | Loss: 0.00180001
Iteration 7/25 | Loss: 0.00180001
Iteration 8/25 | Loss: 0.00180001
Iteration 9/25 | Loss: 0.00180001
Iteration 10/25 | Loss: 0.00180001
Iteration 11/25 | Loss: 0.00180001
Iteration 12/25 | Loss: 0.00180001
Iteration 13/25 | Loss: 0.00180001
Iteration 14/25 | Loss: 0.00180001
Iteration 15/25 | Loss: 0.00180001
Iteration 16/25 | Loss: 0.00180001
Iteration 17/25 | Loss: 0.00180001
Iteration 18/25 | Loss: 0.00180001
Iteration 19/25 | Loss: 0.00180001
Iteration 20/25 | Loss: 0.00180001
Iteration 21/25 | Loss: 0.00180001
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0018000106792896986, 0.0018000106792896986, 0.0018000106792896986, 0.0018000106792896986, 0.0018000106792896986]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0018000106792896986

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00180001
Iteration 2/1000 | Loss: 0.00130409
Iteration 3/1000 | Loss: 0.00071806
Iteration 4/1000 | Loss: 0.00011548
Iteration 5/1000 | Loss: 0.00022346
Iteration 6/1000 | Loss: 0.00037595
Iteration 7/1000 | Loss: 0.00022113
Iteration 8/1000 | Loss: 0.00032971
Iteration 9/1000 | Loss: 0.00016924
Iteration 10/1000 | Loss: 0.00026534
Iteration 11/1000 | Loss: 0.00024153
Iteration 12/1000 | Loss: 0.00030806
Iteration 13/1000 | Loss: 0.00032493
Iteration 14/1000 | Loss: 0.00046775
Iteration 15/1000 | Loss: 0.00028521
Iteration 16/1000 | Loss: 0.00027031
Iteration 17/1000 | Loss: 0.00043438
Iteration 18/1000 | Loss: 0.00025338
Iteration 19/1000 | Loss: 0.00051165
Iteration 20/1000 | Loss: 0.00042361
Iteration 21/1000 | Loss: 0.00022171
Iteration 22/1000 | Loss: 0.00016199
Iteration 23/1000 | Loss: 0.00019360
Iteration 24/1000 | Loss: 0.00030894
Iteration 25/1000 | Loss: 0.00013858
Iteration 26/1000 | Loss: 0.00023396
Iteration 27/1000 | Loss: 0.00020321
Iteration 28/1000 | Loss: 0.00022354
Iteration 29/1000 | Loss: 0.00013696
Iteration 30/1000 | Loss: 0.00011802
Iteration 31/1000 | Loss: 0.00005786
Iteration 32/1000 | Loss: 0.00014970
Iteration 33/1000 | Loss: 0.00082187
Iteration 34/1000 | Loss: 0.00060500
Iteration 35/1000 | Loss: 0.00037552
Iteration 36/1000 | Loss: 0.00035998
Iteration 37/1000 | Loss: 0.00066819
Iteration 38/1000 | Loss: 0.00069642
Iteration 39/1000 | Loss: 0.00068691
Iteration 40/1000 | Loss: 0.00163519
Iteration 41/1000 | Loss: 0.00079593
Iteration 42/1000 | Loss: 0.00063213
Iteration 43/1000 | Loss: 0.00009300
Iteration 44/1000 | Loss: 0.00006358
Iteration 45/1000 | Loss: 0.00005564
Iteration 46/1000 | Loss: 0.00005135
Iteration 47/1000 | Loss: 0.00004758
Iteration 48/1000 | Loss: 0.00006842
Iteration 49/1000 | Loss: 0.00011796
Iteration 50/1000 | Loss: 0.00004088
Iteration 51/1000 | Loss: 0.00003777
Iteration 52/1000 | Loss: 0.00019127
Iteration 53/1000 | Loss: 0.00016701
Iteration 54/1000 | Loss: 0.00003352
Iteration 55/1000 | Loss: 0.00003192
Iteration 56/1000 | Loss: 0.00003092
Iteration 57/1000 | Loss: 0.00020219
Iteration 58/1000 | Loss: 0.00016751
Iteration 59/1000 | Loss: 0.00018703
Iteration 60/1000 | Loss: 0.00018248
Iteration 61/1000 | Loss: 0.00017329
Iteration 62/1000 | Loss: 0.00019295
Iteration 63/1000 | Loss: 0.00015081
Iteration 64/1000 | Loss: 0.00014079
Iteration 65/1000 | Loss: 0.00015838
Iteration 66/1000 | Loss: 0.00017137
Iteration 67/1000 | Loss: 0.00036835
Iteration 68/1000 | Loss: 0.00022122
Iteration 69/1000 | Loss: 0.00003583
Iteration 70/1000 | Loss: 0.00003462
Iteration 71/1000 | Loss: 0.00029548
Iteration 72/1000 | Loss: 0.00012941
Iteration 73/1000 | Loss: 0.00004682
Iteration 74/1000 | Loss: 0.00016646
Iteration 75/1000 | Loss: 0.00012805
Iteration 76/1000 | Loss: 0.00011744
Iteration 77/1000 | Loss: 0.00003516
Iteration 78/1000 | Loss: 0.00012641
Iteration 79/1000 | Loss: 0.00009551
Iteration 80/1000 | Loss: 0.00013069
Iteration 81/1000 | Loss: 0.00010643
Iteration 82/1000 | Loss: 0.00003640
Iteration 83/1000 | Loss: 0.00034313
Iteration 84/1000 | Loss: 0.00023454
Iteration 85/1000 | Loss: 0.00061496
Iteration 86/1000 | Loss: 0.00067632
Iteration 87/1000 | Loss: 0.00040540
Iteration 88/1000 | Loss: 0.00053323
Iteration 89/1000 | Loss: 0.00043613
Iteration 90/1000 | Loss: 0.00044552
Iteration 91/1000 | Loss: 0.00029894
Iteration 92/1000 | Loss: 0.00026798
Iteration 93/1000 | Loss: 0.00028846
Iteration 94/1000 | Loss: 0.00005366
Iteration 95/1000 | Loss: 0.00065973
Iteration 96/1000 | Loss: 0.00103930
Iteration 97/1000 | Loss: 0.00045688
Iteration 98/1000 | Loss: 0.00041358
Iteration 99/1000 | Loss: 0.00035922
Iteration 100/1000 | Loss: 0.00062036
Iteration 101/1000 | Loss: 0.00037792
Iteration 102/1000 | Loss: 0.00045701
Iteration 103/1000 | Loss: 0.00004065
Iteration 104/1000 | Loss: 0.00003515
Iteration 105/1000 | Loss: 0.00028857
Iteration 106/1000 | Loss: 0.00045516
Iteration 107/1000 | Loss: 0.00037477
Iteration 108/1000 | Loss: 0.00016631
Iteration 109/1000 | Loss: 0.00018932
Iteration 110/1000 | Loss: 0.00016007
Iteration 111/1000 | Loss: 0.00004021
Iteration 112/1000 | Loss: 0.00004081
Iteration 113/1000 | Loss: 0.00003651
Iteration 114/1000 | Loss: 0.00003344
Iteration 115/1000 | Loss: 0.00003205
Iteration 116/1000 | Loss: 0.00003086
Iteration 117/1000 | Loss: 0.00003031
Iteration 118/1000 | Loss: 0.00002988
Iteration 119/1000 | Loss: 0.00022086
Iteration 120/1000 | Loss: 0.00072046
Iteration 121/1000 | Loss: 0.00038544
Iteration 122/1000 | Loss: 0.00049339
Iteration 123/1000 | Loss: 0.00013563
Iteration 124/1000 | Loss: 0.00005461
Iteration 125/1000 | Loss: 0.00016851
Iteration 126/1000 | Loss: 0.00004241
Iteration 127/1000 | Loss: 0.00003819
Iteration 128/1000 | Loss: 0.00003550
Iteration 129/1000 | Loss: 0.00031711
Iteration 130/1000 | Loss: 0.00027789
Iteration 131/1000 | Loss: 0.00028451
Iteration 132/1000 | Loss: 0.00020626
Iteration 133/1000 | Loss: 0.00020491
Iteration 134/1000 | Loss: 0.00012007
Iteration 135/1000 | Loss: 0.00045297
Iteration 136/1000 | Loss: 0.00004398
Iteration 137/1000 | Loss: 0.00003824
Iteration 138/1000 | Loss: 0.00003508
Iteration 139/1000 | Loss: 0.00036041
Iteration 140/1000 | Loss: 0.00013455
Iteration 141/1000 | Loss: 0.00020168
Iteration 142/1000 | Loss: 0.00017166
Iteration 143/1000 | Loss: 0.00004112
Iteration 144/1000 | Loss: 0.00003558
Iteration 145/1000 | Loss: 0.00003182
Iteration 146/1000 | Loss: 0.00002960
Iteration 147/1000 | Loss: 0.00002823
Iteration 148/1000 | Loss: 0.00002751
Iteration 149/1000 | Loss: 0.00034615
Iteration 150/1000 | Loss: 0.00008923
Iteration 151/1000 | Loss: 0.00030947
Iteration 152/1000 | Loss: 0.00041299
Iteration 153/1000 | Loss: 0.00028456
Iteration 154/1000 | Loss: 0.00009477
Iteration 155/1000 | Loss: 0.00004827
Iteration 156/1000 | Loss: 0.00003123
Iteration 157/1000 | Loss: 0.00004256
Iteration 158/1000 | Loss: 0.00003057
Iteration 159/1000 | Loss: 0.00002876
Iteration 160/1000 | Loss: 0.00002771
Iteration 161/1000 | Loss: 0.00013604
Iteration 162/1000 | Loss: 0.00003445
Iteration 163/1000 | Loss: 0.00002945
Iteration 164/1000 | Loss: 0.00002764
Iteration 165/1000 | Loss: 0.00002675
Iteration 166/1000 | Loss: 0.00022966
Iteration 167/1000 | Loss: 0.00017264
Iteration 168/1000 | Loss: 0.00002626
Iteration 169/1000 | Loss: 0.00002377
Iteration 170/1000 | Loss: 0.00002327
Iteration 171/1000 | Loss: 0.00002282
Iteration 172/1000 | Loss: 0.00002269
Iteration 173/1000 | Loss: 0.00002259
Iteration 174/1000 | Loss: 0.00002251
Iteration 175/1000 | Loss: 0.00002248
Iteration 176/1000 | Loss: 0.00002238
Iteration 177/1000 | Loss: 0.00002235
Iteration 178/1000 | Loss: 0.00002235
Iteration 179/1000 | Loss: 0.00002235
Iteration 180/1000 | Loss: 0.00002235
Iteration 181/1000 | Loss: 0.00002234
Iteration 182/1000 | Loss: 0.00002234
Iteration 183/1000 | Loss: 0.00002234
Iteration 184/1000 | Loss: 0.00002233
Iteration 185/1000 | Loss: 0.00002233
Iteration 186/1000 | Loss: 0.00002232
Iteration 187/1000 | Loss: 0.00002232
Iteration 188/1000 | Loss: 0.00002232
Iteration 189/1000 | Loss: 0.00002232
Iteration 190/1000 | Loss: 0.00002232
Iteration 191/1000 | Loss: 0.00002232
Iteration 192/1000 | Loss: 0.00002231
Iteration 193/1000 | Loss: 0.00002231
Iteration 194/1000 | Loss: 0.00002231
Iteration 195/1000 | Loss: 0.00002231
Iteration 196/1000 | Loss: 0.00002231
Iteration 197/1000 | Loss: 0.00002231
Iteration 198/1000 | Loss: 0.00002230
Iteration 199/1000 | Loss: 0.00002228
Iteration 200/1000 | Loss: 0.00002228
Iteration 201/1000 | Loss: 0.00002227
Iteration 202/1000 | Loss: 0.00002226
Iteration 203/1000 | Loss: 0.00002226
Iteration 204/1000 | Loss: 0.00002225
Iteration 205/1000 | Loss: 0.00002225
Iteration 206/1000 | Loss: 0.00002224
Iteration 207/1000 | Loss: 0.00002224
Iteration 208/1000 | Loss: 0.00002223
Iteration 209/1000 | Loss: 0.00002223
Iteration 210/1000 | Loss: 0.00002220
Iteration 211/1000 | Loss: 0.00002218
Iteration 212/1000 | Loss: 0.00002218
Iteration 213/1000 | Loss: 0.00002217
Iteration 214/1000 | Loss: 0.00002217
Iteration 215/1000 | Loss: 0.00002216
Iteration 216/1000 | Loss: 0.00002216
Iteration 217/1000 | Loss: 0.00002216
Iteration 218/1000 | Loss: 0.00002216
Iteration 219/1000 | Loss: 0.00002215
Iteration 220/1000 | Loss: 0.00002215
Iteration 221/1000 | Loss: 0.00002215
Iteration 222/1000 | Loss: 0.00002215
Iteration 223/1000 | Loss: 0.00002215
Iteration 224/1000 | Loss: 0.00002215
Iteration 225/1000 | Loss: 0.00002214
Iteration 226/1000 | Loss: 0.00002214
Iteration 227/1000 | Loss: 0.00002214
Iteration 228/1000 | Loss: 0.00002214
Iteration 229/1000 | Loss: 0.00002214
Iteration 230/1000 | Loss: 0.00002214
Iteration 231/1000 | Loss: 0.00002213
Iteration 232/1000 | Loss: 0.00002213
Iteration 233/1000 | Loss: 0.00002213
Iteration 234/1000 | Loss: 0.00002213
Iteration 235/1000 | Loss: 0.00002212
Iteration 236/1000 | Loss: 0.00002212
Iteration 237/1000 | Loss: 0.00002212
Iteration 238/1000 | Loss: 0.00002211
Iteration 239/1000 | Loss: 0.00002211
Iteration 240/1000 | Loss: 0.00002211
Iteration 241/1000 | Loss: 0.00002211
Iteration 242/1000 | Loss: 0.00002211
Iteration 243/1000 | Loss: 0.00002210
Iteration 244/1000 | Loss: 0.00002210
Iteration 245/1000 | Loss: 0.00002210
Iteration 246/1000 | Loss: 0.00002210
Iteration 247/1000 | Loss: 0.00002210
Iteration 248/1000 | Loss: 0.00002209
Iteration 249/1000 | Loss: 0.00002209
Iteration 250/1000 | Loss: 0.00002209
Iteration 251/1000 | Loss: 0.00002209
Iteration 252/1000 | Loss: 0.00002209
Iteration 253/1000 | Loss: 0.00002209
Iteration 254/1000 | Loss: 0.00002208
Iteration 255/1000 | Loss: 0.00002208
Iteration 256/1000 | Loss: 0.00002208
Iteration 257/1000 | Loss: 0.00002208
Iteration 258/1000 | Loss: 0.00002208
Iteration 259/1000 | Loss: 0.00002208
Iteration 260/1000 | Loss: 0.00002208
Iteration 261/1000 | Loss: 0.00002208
Iteration 262/1000 | Loss: 0.00002208
Iteration 263/1000 | Loss: 0.00002207
Iteration 264/1000 | Loss: 0.00002207
Iteration 265/1000 | Loss: 0.00002207
Iteration 266/1000 | Loss: 0.00002207
Iteration 267/1000 | Loss: 0.00002207
Iteration 268/1000 | Loss: 0.00002207
Iteration 269/1000 | Loss: 0.00002207
Iteration 270/1000 | Loss: 0.00002207
Iteration 271/1000 | Loss: 0.00002207
Iteration 272/1000 | Loss: 0.00002207
Iteration 273/1000 | Loss: 0.00002207
Iteration 274/1000 | Loss: 0.00002207
Iteration 275/1000 | Loss: 0.00002207
Iteration 276/1000 | Loss: 0.00002207
Iteration 277/1000 | Loss: 0.00002206
Iteration 278/1000 | Loss: 0.00002206
Iteration 279/1000 | Loss: 0.00002206
Iteration 280/1000 | Loss: 0.00002206
Iteration 281/1000 | Loss: 0.00002206
Iteration 282/1000 | Loss: 0.00002206
Iteration 283/1000 | Loss: 0.00002206
Iteration 284/1000 | Loss: 0.00002206
Iteration 285/1000 | Loss: 0.00002206
Iteration 286/1000 | Loss: 0.00002206
Iteration 287/1000 | Loss: 0.00002206
Iteration 288/1000 | Loss: 0.00002206
Iteration 289/1000 | Loss: 0.00002205
Iteration 290/1000 | Loss: 0.00002205
Iteration 291/1000 | Loss: 0.00002205
Iteration 292/1000 | Loss: 0.00002205
Iteration 293/1000 | Loss: 0.00002205
Iteration 294/1000 | Loss: 0.00002205
Iteration 295/1000 | Loss: 0.00002205
Iteration 296/1000 | Loss: 0.00002205
Iteration 297/1000 | Loss: 0.00002205
Iteration 298/1000 | Loss: 0.00002205
Iteration 299/1000 | Loss: 0.00002205
Iteration 300/1000 | Loss: 0.00002205
Iteration 301/1000 | Loss: 0.00002204
Iteration 302/1000 | Loss: 0.00002204
Iteration 303/1000 | Loss: 0.00002204
Iteration 304/1000 | Loss: 0.00002204
Iteration 305/1000 | Loss: 0.00002204
Iteration 306/1000 | Loss: 0.00002204
Iteration 307/1000 | Loss: 0.00002204
Iteration 308/1000 | Loss: 0.00002204
Iteration 309/1000 | Loss: 0.00002203
Iteration 310/1000 | Loss: 0.00002203
Iteration 311/1000 | Loss: 0.00002203
Iteration 312/1000 | Loss: 0.00002203
Iteration 313/1000 | Loss: 0.00002203
Iteration 314/1000 | Loss: 0.00002203
Iteration 315/1000 | Loss: 0.00002203
Iteration 316/1000 | Loss: 0.00002203
Iteration 317/1000 | Loss: 0.00002203
Iteration 318/1000 | Loss: 0.00002202
Iteration 319/1000 | Loss: 0.00002202
Iteration 320/1000 | Loss: 0.00002202
Iteration 321/1000 | Loss: 0.00002202
Iteration 322/1000 | Loss: 0.00002202
Iteration 323/1000 | Loss: 0.00002202
Iteration 324/1000 | Loss: 0.00002202
Iteration 325/1000 | Loss: 0.00002202
Iteration 326/1000 | Loss: 0.00002202
Iteration 327/1000 | Loss: 0.00002202
Iteration 328/1000 | Loss: 0.00002202
Iteration 329/1000 | Loss: 0.00002202
Iteration 330/1000 | Loss: 0.00002202
Iteration 331/1000 | Loss: 0.00002202
Iteration 332/1000 | Loss: 0.00002202
Iteration 333/1000 | Loss: 0.00002202
Iteration 334/1000 | Loss: 0.00002202
Iteration 335/1000 | Loss: 0.00002202
Iteration 336/1000 | Loss: 0.00002202
Iteration 337/1000 | Loss: 0.00002202
Iteration 338/1000 | Loss: 0.00002201
Iteration 339/1000 | Loss: 0.00002201
Iteration 340/1000 | Loss: 0.00002201
Iteration 341/1000 | Loss: 0.00002201
Iteration 342/1000 | Loss: 0.00002201
Iteration 343/1000 | Loss: 0.00002201
Iteration 344/1000 | Loss: 0.00002201
Iteration 345/1000 | Loss: 0.00002201
Iteration 346/1000 | Loss: 0.00002201
Iteration 347/1000 | Loss: 0.00002201
Iteration 348/1000 | Loss: 0.00002201
Iteration 349/1000 | Loss: 0.00002201
Iteration 350/1000 | Loss: 0.00002201
Iteration 351/1000 | Loss: 0.00002201
Iteration 352/1000 | Loss: 0.00002201
Iteration 353/1000 | Loss: 0.00002201
Iteration 354/1000 | Loss: 0.00002201
Iteration 355/1000 | Loss: 0.00002201
Iteration 356/1000 | Loss: 0.00002201
Iteration 357/1000 | Loss: 0.00002200
Iteration 358/1000 | Loss: 0.00002200
Iteration 359/1000 | Loss: 0.00002200
Iteration 360/1000 | Loss: 0.00002200
Iteration 361/1000 | Loss: 0.00002200
Iteration 362/1000 | Loss: 0.00002200
Iteration 363/1000 | Loss: 0.00002200
Iteration 364/1000 | Loss: 0.00002200
Iteration 365/1000 | Loss: 0.00002200
Iteration 366/1000 | Loss: 0.00002200
Iteration 367/1000 | Loss: 0.00002200
Iteration 368/1000 | Loss: 0.00002200
Iteration 369/1000 | Loss: 0.00002200
Iteration 370/1000 | Loss: 0.00002200
Iteration 371/1000 | Loss: 0.00002200
Iteration 372/1000 | Loss: 0.00002200
Iteration 373/1000 | Loss: 0.00002200
Iteration 374/1000 | Loss: 0.00002200
Iteration 375/1000 | Loss: 0.00002200
Iteration 376/1000 | Loss: 0.00002200
Iteration 377/1000 | Loss: 0.00002200
Iteration 378/1000 | Loss: 0.00002200
Iteration 379/1000 | Loss: 0.00002200
Iteration 380/1000 | Loss: 0.00002200
Iteration 381/1000 | Loss: 0.00002200
Iteration 382/1000 | Loss: 0.00002200
Iteration 383/1000 | Loss: 0.00002200
Iteration 384/1000 | Loss: 0.00002200
Iteration 385/1000 | Loss: 0.00002200
Iteration 386/1000 | Loss: 0.00002200
Iteration 387/1000 | Loss: 0.00002200
Iteration 388/1000 | Loss: 0.00002200
Iteration 389/1000 | Loss: 0.00002200
Iteration 390/1000 | Loss: 0.00002200
Iteration 391/1000 | Loss: 0.00002200
Iteration 392/1000 | Loss: 0.00002200
Iteration 393/1000 | Loss: 0.00002200
Iteration 394/1000 | Loss: 0.00002200
Iteration 395/1000 | Loss: 0.00002200
Iteration 396/1000 | Loss: 0.00002200
Iteration 397/1000 | Loss: 0.00002200
Iteration 398/1000 | Loss: 0.00002200
Iteration 399/1000 | Loss: 0.00002200
Iteration 400/1000 | Loss: 0.00002200
Iteration 401/1000 | Loss: 0.00002200
Iteration 402/1000 | Loss: 0.00002200
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 402. Stopping optimization.
Last 5 losses: [2.1999707314535044e-05, 2.1999707314535044e-05, 2.1999707314535044e-05, 2.1999707314535044e-05, 2.1999707314535044e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1999707314535044e-05

Optimization complete. Final v2v error: 3.7592544555664062 mm

Highest mean error: 6.911771774291992 mm for frame 90

Lowest mean error: 2.9453322887420654 mm for frame 149

Saving results

Total time: 308.7518141269684
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1041/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1041.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1041
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00757859
Iteration 2/25 | Loss: 0.00139586
Iteration 3/25 | Loss: 0.00094915
Iteration 4/25 | Loss: 0.00086307
Iteration 5/25 | Loss: 0.00083325
Iteration 6/25 | Loss: 0.00083096
Iteration 7/25 | Loss: 0.00082641
Iteration 8/25 | Loss: 0.00082868
Iteration 9/25 | Loss: 0.00082575
Iteration 10/25 | Loss: 0.00082570
Iteration 11/25 | Loss: 0.00082570
Iteration 12/25 | Loss: 0.00082570
Iteration 13/25 | Loss: 0.00082570
Iteration 14/25 | Loss: 0.00082569
Iteration 15/25 | Loss: 0.00082569
Iteration 16/25 | Loss: 0.00082569
Iteration 17/25 | Loss: 0.00082569
Iteration 18/25 | Loss: 0.00082569
Iteration 19/25 | Loss: 0.00082569
Iteration 20/25 | Loss: 0.00082569
Iteration 21/25 | Loss: 0.00082569
Iteration 22/25 | Loss: 0.00082569
Iteration 23/25 | Loss: 0.00082569
Iteration 24/25 | Loss: 0.00082568
Iteration 25/25 | Loss: 0.00082568

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.42527056
Iteration 2/25 | Loss: 0.00055047
Iteration 3/25 | Loss: 0.00055045
Iteration 4/25 | Loss: 0.00055045
Iteration 5/25 | Loss: 0.00055045
Iteration 6/25 | Loss: 0.00055045
Iteration 7/25 | Loss: 0.00055045
Iteration 8/25 | Loss: 0.00055045
Iteration 9/25 | Loss: 0.00055045
Iteration 10/25 | Loss: 0.00055045
Iteration 11/25 | Loss: 0.00055045
Iteration 12/25 | Loss: 0.00055045
Iteration 13/25 | Loss: 0.00055045
Iteration 14/25 | Loss: 0.00055045
Iteration 15/25 | Loss: 0.00055045
Iteration 16/25 | Loss: 0.00055045
Iteration 17/25 | Loss: 0.00055045
Iteration 18/25 | Loss: 0.00055045
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005504511063918471, 0.0005504511063918471, 0.0005504511063918471, 0.0005504511063918471, 0.0005504511063918471]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005504511063918471

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00055045
Iteration 2/1000 | Loss: 0.00003831
Iteration 3/1000 | Loss: 0.00002596
Iteration 4/1000 | Loss: 0.00002353
Iteration 5/1000 | Loss: 0.00002235
Iteration 6/1000 | Loss: 0.00002181
Iteration 7/1000 | Loss: 0.00002138
Iteration 8/1000 | Loss: 0.00002111
Iteration 9/1000 | Loss: 0.00002078
Iteration 10/1000 | Loss: 0.00002070
Iteration 11/1000 | Loss: 0.00002057
Iteration 12/1000 | Loss: 0.00002052
Iteration 13/1000 | Loss: 0.00002051
Iteration 14/1000 | Loss: 0.00002051
Iteration 15/1000 | Loss: 0.00002050
Iteration 16/1000 | Loss: 0.00002049
Iteration 17/1000 | Loss: 0.00002048
Iteration 18/1000 | Loss: 0.00002044
Iteration 19/1000 | Loss: 0.00002044
Iteration 20/1000 | Loss: 0.00002043
Iteration 21/1000 | Loss: 0.00002034
Iteration 22/1000 | Loss: 0.00002030
Iteration 23/1000 | Loss: 0.00002027
Iteration 24/1000 | Loss: 0.00002023
Iteration 25/1000 | Loss: 0.00002023
Iteration 26/1000 | Loss: 0.00002022
Iteration 27/1000 | Loss: 0.00002021
Iteration 28/1000 | Loss: 0.00002021
Iteration 29/1000 | Loss: 0.00002021
Iteration 30/1000 | Loss: 0.00002020
Iteration 31/1000 | Loss: 0.00002019
Iteration 32/1000 | Loss: 0.00002019
Iteration 33/1000 | Loss: 0.00002018
Iteration 34/1000 | Loss: 0.00002018
Iteration 35/1000 | Loss: 0.00002015
Iteration 36/1000 | Loss: 0.00002014
Iteration 37/1000 | Loss: 0.00002011
Iteration 38/1000 | Loss: 0.00002011
Iteration 39/1000 | Loss: 0.00002009
Iteration 40/1000 | Loss: 0.00002008
Iteration 41/1000 | Loss: 0.00002008
Iteration 42/1000 | Loss: 0.00002008
Iteration 43/1000 | Loss: 0.00002007
Iteration 44/1000 | Loss: 0.00002007
Iteration 45/1000 | Loss: 0.00002007
Iteration 46/1000 | Loss: 0.00002007
Iteration 47/1000 | Loss: 0.00002007
Iteration 48/1000 | Loss: 0.00002007
Iteration 49/1000 | Loss: 0.00002007
Iteration 50/1000 | Loss: 0.00002006
Iteration 51/1000 | Loss: 0.00002006
Iteration 52/1000 | Loss: 0.00002005
Iteration 53/1000 | Loss: 0.00002005
Iteration 54/1000 | Loss: 0.00002005
Iteration 55/1000 | Loss: 0.00002005
Iteration 56/1000 | Loss: 0.00002005
Iteration 57/1000 | Loss: 0.00002005
Iteration 58/1000 | Loss: 0.00002005
Iteration 59/1000 | Loss: 0.00002005
Iteration 60/1000 | Loss: 0.00002005
Iteration 61/1000 | Loss: 0.00002005
Iteration 62/1000 | Loss: 0.00002005
Iteration 63/1000 | Loss: 0.00002004
Iteration 64/1000 | Loss: 0.00002004
Iteration 65/1000 | Loss: 0.00002004
Iteration 66/1000 | Loss: 0.00002004
Iteration 67/1000 | Loss: 0.00002004
Iteration 68/1000 | Loss: 0.00002004
Iteration 69/1000 | Loss: 0.00002003
Iteration 70/1000 | Loss: 0.00002003
Iteration 71/1000 | Loss: 0.00002003
Iteration 72/1000 | Loss: 0.00002003
Iteration 73/1000 | Loss: 0.00002002
Iteration 74/1000 | Loss: 0.00002002
Iteration 75/1000 | Loss: 0.00002002
Iteration 76/1000 | Loss: 0.00002002
Iteration 77/1000 | Loss: 0.00002002
Iteration 78/1000 | Loss: 0.00002001
Iteration 79/1000 | Loss: 0.00002001
Iteration 80/1000 | Loss: 0.00002001
Iteration 81/1000 | Loss: 0.00002001
Iteration 82/1000 | Loss: 0.00002001
Iteration 83/1000 | Loss: 0.00002000
Iteration 84/1000 | Loss: 0.00002000
Iteration 85/1000 | Loss: 0.00002000
Iteration 86/1000 | Loss: 0.00002000
Iteration 87/1000 | Loss: 0.00002000
Iteration 88/1000 | Loss: 0.00002000
Iteration 89/1000 | Loss: 0.00002000
Iteration 90/1000 | Loss: 0.00001999
Iteration 91/1000 | Loss: 0.00001999
Iteration 92/1000 | Loss: 0.00001999
Iteration 93/1000 | Loss: 0.00001999
Iteration 94/1000 | Loss: 0.00001999
Iteration 95/1000 | Loss: 0.00001999
Iteration 96/1000 | Loss: 0.00001999
Iteration 97/1000 | Loss: 0.00001999
Iteration 98/1000 | Loss: 0.00001998
Iteration 99/1000 | Loss: 0.00001998
Iteration 100/1000 | Loss: 0.00001998
Iteration 101/1000 | Loss: 0.00001998
Iteration 102/1000 | Loss: 0.00001998
Iteration 103/1000 | Loss: 0.00001998
Iteration 104/1000 | Loss: 0.00001997
Iteration 105/1000 | Loss: 0.00001997
Iteration 106/1000 | Loss: 0.00001997
Iteration 107/1000 | Loss: 0.00001997
Iteration 108/1000 | Loss: 0.00001997
Iteration 109/1000 | Loss: 0.00001997
Iteration 110/1000 | Loss: 0.00001997
Iteration 111/1000 | Loss: 0.00001997
Iteration 112/1000 | Loss: 0.00001997
Iteration 113/1000 | Loss: 0.00001997
Iteration 114/1000 | Loss: 0.00001997
Iteration 115/1000 | Loss: 0.00001997
Iteration 116/1000 | Loss: 0.00001996
Iteration 117/1000 | Loss: 0.00001996
Iteration 118/1000 | Loss: 0.00001996
Iteration 119/1000 | Loss: 0.00001996
Iteration 120/1000 | Loss: 0.00001996
Iteration 121/1000 | Loss: 0.00001996
Iteration 122/1000 | Loss: 0.00001996
Iteration 123/1000 | Loss: 0.00001996
Iteration 124/1000 | Loss: 0.00001996
Iteration 125/1000 | Loss: 0.00001996
Iteration 126/1000 | Loss: 0.00001996
Iteration 127/1000 | Loss: 0.00001996
Iteration 128/1000 | Loss: 0.00001996
Iteration 129/1000 | Loss: 0.00001996
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [1.9956545656896196e-05, 1.9956545656896196e-05, 1.9956545656896196e-05, 1.9956545656896196e-05, 1.9956545656896196e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9956545656896196e-05

Optimization complete. Final v2v error: 3.765558958053589 mm

Highest mean error: 4.159787654876709 mm for frame 233

Lowest mean error: 3.304142475128174 mm for frame 144

Saving results

Total time: 49.08869290351868
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1074/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1074.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1074
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00599929
Iteration 2/25 | Loss: 0.00113372
Iteration 3/25 | Loss: 0.00089971
Iteration 4/25 | Loss: 0.00079033
Iteration 5/25 | Loss: 0.00075212
Iteration 6/25 | Loss: 0.00073964
Iteration 7/25 | Loss: 0.00073936
Iteration 8/25 | Loss: 0.00073567
Iteration 9/25 | Loss: 0.00073266
Iteration 10/25 | Loss: 0.00073136
Iteration 11/25 | Loss: 0.00073000
Iteration 12/25 | Loss: 0.00073150
Iteration 13/25 | Loss: 0.00072451
Iteration 14/25 | Loss: 0.00072325
Iteration 15/25 | Loss: 0.00072231
Iteration 16/25 | Loss: 0.00072175
Iteration 17/25 | Loss: 0.00072152
Iteration 18/25 | Loss: 0.00072138
Iteration 19/25 | Loss: 0.00072127
Iteration 20/25 | Loss: 0.00072120
Iteration 21/25 | Loss: 0.00072119
Iteration 22/25 | Loss: 0.00072119
Iteration 23/25 | Loss: 0.00072119
Iteration 24/25 | Loss: 0.00072119
Iteration 25/25 | Loss: 0.00072119

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.32787824
Iteration 2/25 | Loss: 0.00046508
Iteration 3/25 | Loss: 0.00046508
Iteration 4/25 | Loss: 0.00046508
Iteration 5/25 | Loss: 0.00046507
Iteration 6/25 | Loss: 0.00046507
Iteration 7/25 | Loss: 0.00046507
Iteration 8/25 | Loss: 0.00046507
Iteration 9/25 | Loss: 0.00046507
Iteration 10/25 | Loss: 0.00046507
Iteration 11/25 | Loss: 0.00046507
Iteration 12/25 | Loss: 0.00046507
Iteration 13/25 | Loss: 0.00046507
Iteration 14/25 | Loss: 0.00046507
Iteration 15/25 | Loss: 0.00046507
Iteration 16/25 | Loss: 0.00046507
Iteration 17/25 | Loss: 0.00046507
Iteration 18/25 | Loss: 0.00046507
Iteration 19/25 | Loss: 0.00046507
Iteration 20/25 | Loss: 0.00046507
Iteration 21/25 | Loss: 0.00046507
Iteration 22/25 | Loss: 0.00046507
Iteration 23/25 | Loss: 0.00046507
Iteration 24/25 | Loss: 0.00046507
Iteration 25/25 | Loss: 0.00046507

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046507
Iteration 2/1000 | Loss: 0.00002342
Iteration 3/1000 | Loss: 0.00001624
Iteration 4/1000 | Loss: 0.00001508
Iteration 5/1000 | Loss: 0.00001438
Iteration 6/1000 | Loss: 0.00001391
Iteration 7/1000 | Loss: 0.00001355
Iteration 8/1000 | Loss: 0.00001332
Iteration 9/1000 | Loss: 0.00001312
Iteration 10/1000 | Loss: 0.00040802
Iteration 11/1000 | Loss: 0.00002602
Iteration 12/1000 | Loss: 0.00001353
Iteration 13/1000 | Loss: 0.00001238
Iteration 14/1000 | Loss: 0.00001190
Iteration 15/1000 | Loss: 0.00002682
Iteration 16/1000 | Loss: 0.00001358
Iteration 17/1000 | Loss: 0.00001145
Iteration 18/1000 | Loss: 0.00001143
Iteration 19/1000 | Loss: 0.00001136
Iteration 20/1000 | Loss: 0.00001133
Iteration 21/1000 | Loss: 0.00001133
Iteration 22/1000 | Loss: 0.00001132
Iteration 23/1000 | Loss: 0.00001132
Iteration 24/1000 | Loss: 0.00001130
Iteration 25/1000 | Loss: 0.00001130
Iteration 26/1000 | Loss: 0.00001129
Iteration 27/1000 | Loss: 0.00001124
Iteration 28/1000 | Loss: 0.00001124
Iteration 29/1000 | Loss: 0.00001123
Iteration 30/1000 | Loss: 0.00001122
Iteration 31/1000 | Loss: 0.00001122
Iteration 32/1000 | Loss: 0.00001121
Iteration 33/1000 | Loss: 0.00001121
Iteration 34/1000 | Loss: 0.00001121
Iteration 35/1000 | Loss: 0.00001120
Iteration 36/1000 | Loss: 0.00001119
Iteration 37/1000 | Loss: 0.00001118
Iteration 38/1000 | Loss: 0.00001117
Iteration 39/1000 | Loss: 0.00001117
Iteration 40/1000 | Loss: 0.00001117
Iteration 41/1000 | Loss: 0.00001116
Iteration 42/1000 | Loss: 0.00001116
Iteration 43/1000 | Loss: 0.00001116
Iteration 44/1000 | Loss: 0.00001115
Iteration 45/1000 | Loss: 0.00001115
Iteration 46/1000 | Loss: 0.00001114
Iteration 47/1000 | Loss: 0.00001114
Iteration 48/1000 | Loss: 0.00001114
Iteration 49/1000 | Loss: 0.00001114
Iteration 50/1000 | Loss: 0.00001113
Iteration 51/1000 | Loss: 0.00001113
Iteration 52/1000 | Loss: 0.00001112
Iteration 53/1000 | Loss: 0.00001110
Iteration 54/1000 | Loss: 0.00001110
Iteration 55/1000 | Loss: 0.00001110
Iteration 56/1000 | Loss: 0.00001110
Iteration 57/1000 | Loss: 0.00001110
Iteration 58/1000 | Loss: 0.00001110
Iteration 59/1000 | Loss: 0.00001110
Iteration 60/1000 | Loss: 0.00001109
Iteration 61/1000 | Loss: 0.00001109
Iteration 62/1000 | Loss: 0.00001109
Iteration 63/1000 | Loss: 0.00001108
Iteration 64/1000 | Loss: 0.00001108
Iteration 65/1000 | Loss: 0.00001108
Iteration 66/1000 | Loss: 0.00001108
Iteration 67/1000 | Loss: 0.00001107
Iteration 68/1000 | Loss: 0.00001107
Iteration 69/1000 | Loss: 0.00001106
Iteration 70/1000 | Loss: 0.00001106
Iteration 71/1000 | Loss: 0.00001106
Iteration 72/1000 | Loss: 0.00001106
Iteration 73/1000 | Loss: 0.00001106
Iteration 74/1000 | Loss: 0.00001106
Iteration 75/1000 | Loss: 0.00001106
Iteration 76/1000 | Loss: 0.00001105
Iteration 77/1000 | Loss: 0.00001105
Iteration 78/1000 | Loss: 0.00001105
Iteration 79/1000 | Loss: 0.00001104
Iteration 80/1000 | Loss: 0.00001104
Iteration 81/1000 | Loss: 0.00001104
Iteration 82/1000 | Loss: 0.00001103
Iteration 83/1000 | Loss: 0.00001103
Iteration 84/1000 | Loss: 0.00001103
Iteration 85/1000 | Loss: 0.00001103
Iteration 86/1000 | Loss: 0.00001103
Iteration 87/1000 | Loss: 0.00001103
Iteration 88/1000 | Loss: 0.00001102
Iteration 89/1000 | Loss: 0.00001102
Iteration 90/1000 | Loss: 0.00001102
Iteration 91/1000 | Loss: 0.00001102
Iteration 92/1000 | Loss: 0.00001102
Iteration 93/1000 | Loss: 0.00001102
Iteration 94/1000 | Loss: 0.00001102
Iteration 95/1000 | Loss: 0.00001102
Iteration 96/1000 | Loss: 0.00001102
Iteration 97/1000 | Loss: 0.00001101
Iteration 98/1000 | Loss: 0.00001101
Iteration 99/1000 | Loss: 0.00001101
Iteration 100/1000 | Loss: 0.00001101
Iteration 101/1000 | Loss: 0.00001101
Iteration 102/1000 | Loss: 0.00001100
Iteration 103/1000 | Loss: 0.00001100
Iteration 104/1000 | Loss: 0.00001100
Iteration 105/1000 | Loss: 0.00001100
Iteration 106/1000 | Loss: 0.00001099
Iteration 107/1000 | Loss: 0.00001099
Iteration 108/1000 | Loss: 0.00001099
Iteration 109/1000 | Loss: 0.00001098
Iteration 110/1000 | Loss: 0.00001098
Iteration 111/1000 | Loss: 0.00001098
Iteration 112/1000 | Loss: 0.00001098
Iteration 113/1000 | Loss: 0.00001098
Iteration 114/1000 | Loss: 0.00001098
Iteration 115/1000 | Loss: 0.00001098
Iteration 116/1000 | Loss: 0.00001098
Iteration 117/1000 | Loss: 0.00001098
Iteration 118/1000 | Loss: 0.00001097
Iteration 119/1000 | Loss: 0.00001097
Iteration 120/1000 | Loss: 0.00001097
Iteration 121/1000 | Loss: 0.00001097
Iteration 122/1000 | Loss: 0.00001097
Iteration 123/1000 | Loss: 0.00001097
Iteration 124/1000 | Loss: 0.00001097
Iteration 125/1000 | Loss: 0.00001097
Iteration 126/1000 | Loss: 0.00001097
Iteration 127/1000 | Loss: 0.00001097
Iteration 128/1000 | Loss: 0.00001097
Iteration 129/1000 | Loss: 0.00001097
Iteration 130/1000 | Loss: 0.00001097
Iteration 131/1000 | Loss: 0.00001097
Iteration 132/1000 | Loss: 0.00001096
Iteration 133/1000 | Loss: 0.00001096
Iteration 134/1000 | Loss: 0.00001096
Iteration 135/1000 | Loss: 0.00001096
Iteration 136/1000 | Loss: 0.00001096
Iteration 137/1000 | Loss: 0.00001096
Iteration 138/1000 | Loss: 0.00001096
Iteration 139/1000 | Loss: 0.00001096
Iteration 140/1000 | Loss: 0.00001096
Iteration 141/1000 | Loss: 0.00001096
Iteration 142/1000 | Loss: 0.00001095
Iteration 143/1000 | Loss: 0.00001095
Iteration 144/1000 | Loss: 0.00001095
Iteration 145/1000 | Loss: 0.00001095
Iteration 146/1000 | Loss: 0.00001095
Iteration 147/1000 | Loss: 0.00001095
Iteration 148/1000 | Loss: 0.00001095
Iteration 149/1000 | Loss: 0.00001094
Iteration 150/1000 | Loss: 0.00001094
Iteration 151/1000 | Loss: 0.00001094
Iteration 152/1000 | Loss: 0.00001094
Iteration 153/1000 | Loss: 0.00001094
Iteration 154/1000 | Loss: 0.00001094
Iteration 155/1000 | Loss: 0.00001094
Iteration 156/1000 | Loss: 0.00001094
Iteration 157/1000 | Loss: 0.00001094
Iteration 158/1000 | Loss: 0.00001094
Iteration 159/1000 | Loss: 0.00001094
Iteration 160/1000 | Loss: 0.00001094
Iteration 161/1000 | Loss: 0.00001093
Iteration 162/1000 | Loss: 0.00001093
Iteration 163/1000 | Loss: 0.00001093
Iteration 164/1000 | Loss: 0.00001093
Iteration 165/1000 | Loss: 0.00001093
Iteration 166/1000 | Loss: 0.00001093
Iteration 167/1000 | Loss: 0.00001093
Iteration 168/1000 | Loss: 0.00001093
Iteration 169/1000 | Loss: 0.00001093
Iteration 170/1000 | Loss: 0.00001093
Iteration 171/1000 | Loss: 0.00001093
Iteration 172/1000 | Loss: 0.00001093
Iteration 173/1000 | Loss: 0.00001093
Iteration 174/1000 | Loss: 0.00001093
Iteration 175/1000 | Loss: 0.00001093
Iteration 176/1000 | Loss: 0.00001093
Iteration 177/1000 | Loss: 0.00001093
Iteration 178/1000 | Loss: 0.00001093
Iteration 179/1000 | Loss: 0.00001093
Iteration 180/1000 | Loss: 0.00001093
Iteration 181/1000 | Loss: 0.00001093
Iteration 182/1000 | Loss: 0.00001093
Iteration 183/1000 | Loss: 0.00001093
Iteration 184/1000 | Loss: 0.00001093
Iteration 185/1000 | Loss: 0.00001093
Iteration 186/1000 | Loss: 0.00001093
Iteration 187/1000 | Loss: 0.00001093
Iteration 188/1000 | Loss: 0.00001093
Iteration 189/1000 | Loss: 0.00001093
Iteration 190/1000 | Loss: 0.00001093
Iteration 191/1000 | Loss: 0.00001093
Iteration 192/1000 | Loss: 0.00001093
Iteration 193/1000 | Loss: 0.00001093
Iteration 194/1000 | Loss: 0.00001093
Iteration 195/1000 | Loss: 0.00001093
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 195. Stopping optimization.
Last 5 losses: [1.0926764844043646e-05, 1.0926764844043646e-05, 1.0926764844043646e-05, 1.0926764844043646e-05, 1.0926764844043646e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.0926764844043646e-05

Optimization complete. Final v2v error: 2.8125152587890625 mm

Highest mean error: 3.986818313598633 mm for frame 195

Lowest mean error: 2.5525424480438232 mm for frame 178

Saving results

Total time: 82.86640000343323
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1094/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1094.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1094
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00778058
Iteration 2/25 | Loss: 0.00160730
Iteration 3/25 | Loss: 0.00109091
Iteration 4/25 | Loss: 0.00095746
Iteration 5/25 | Loss: 0.00096213
Iteration 6/25 | Loss: 0.00096163
Iteration 7/25 | Loss: 0.00093119
Iteration 8/25 | Loss: 0.00089868
Iteration 9/25 | Loss: 0.00089588
Iteration 10/25 | Loss: 0.00088899
Iteration 11/25 | Loss: 0.00088211
Iteration 12/25 | Loss: 0.00087451
Iteration 13/25 | Loss: 0.00087096
Iteration 14/25 | Loss: 0.00086928
Iteration 15/25 | Loss: 0.00087023
Iteration 16/25 | Loss: 0.00086865
Iteration 17/25 | Loss: 0.00086512
Iteration 18/25 | Loss: 0.00086417
Iteration 19/25 | Loss: 0.00086382
Iteration 20/25 | Loss: 0.00086371
Iteration 21/25 | Loss: 0.00086371
Iteration 22/25 | Loss: 0.00086370
Iteration 23/25 | Loss: 0.00086370
Iteration 24/25 | Loss: 0.00086370
Iteration 25/25 | Loss: 0.00086369

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52649689
Iteration 2/25 | Loss: 0.00115035
Iteration 3/25 | Loss: 0.00115034
Iteration 4/25 | Loss: 0.00115034
Iteration 5/25 | Loss: 0.00115034
Iteration 6/25 | Loss: 0.00115034
Iteration 7/25 | Loss: 0.00115033
Iteration 8/25 | Loss: 0.00115033
Iteration 9/25 | Loss: 0.00115033
Iteration 10/25 | Loss: 0.00115033
Iteration 11/25 | Loss: 0.00115033
Iteration 12/25 | Loss: 0.00115033
Iteration 13/25 | Loss: 0.00115033
Iteration 14/25 | Loss: 0.00115033
Iteration 15/25 | Loss: 0.00115033
Iteration 16/25 | Loss: 0.00115033
Iteration 17/25 | Loss: 0.00115033
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.00115033402107656, 0.00115033402107656, 0.00115033402107656, 0.00115033402107656, 0.00115033402107656]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00115033402107656

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00115033
Iteration 2/1000 | Loss: 0.00012316
Iteration 3/1000 | Loss: 0.00007846
Iteration 4/1000 | Loss: 0.00006478
Iteration 5/1000 | Loss: 0.00007609
Iteration 6/1000 | Loss: 0.00006464
Iteration 7/1000 | Loss: 0.00005538
Iteration 8/1000 | Loss: 0.00005818
Iteration 9/1000 | Loss: 0.00004998
Iteration 10/1000 | Loss: 0.00005953
Iteration 11/1000 | Loss: 0.00004693
Iteration 12/1000 | Loss: 0.00004496
Iteration 13/1000 | Loss: 0.00004436
Iteration 14/1000 | Loss: 0.00004385
Iteration 15/1000 | Loss: 0.00005717
Iteration 16/1000 | Loss: 0.00005036
Iteration 17/1000 | Loss: 0.00080964
Iteration 18/1000 | Loss: 0.00174274
Iteration 19/1000 | Loss: 0.00020716
Iteration 20/1000 | Loss: 0.00007736
Iteration 21/1000 | Loss: 0.00006300
Iteration 22/1000 | Loss: 0.00006338
Iteration 23/1000 | Loss: 0.00005321
Iteration 24/1000 | Loss: 0.00005038
Iteration 25/1000 | Loss: 0.00004845
Iteration 26/1000 | Loss: 0.00004601
Iteration 27/1000 | Loss: 0.00004217
Iteration 28/1000 | Loss: 0.00003910
Iteration 29/1000 | Loss: 0.00003577
Iteration 30/1000 | Loss: 0.00003301
Iteration 31/1000 | Loss: 0.00003141
Iteration 32/1000 | Loss: 0.00003057
Iteration 33/1000 | Loss: 0.00002996
Iteration 34/1000 | Loss: 0.00002956
Iteration 35/1000 | Loss: 0.00002933
Iteration 36/1000 | Loss: 0.00002921
Iteration 37/1000 | Loss: 0.00002915
Iteration 38/1000 | Loss: 0.00002906
Iteration 39/1000 | Loss: 0.00002902
Iteration 40/1000 | Loss: 0.00002899
Iteration 41/1000 | Loss: 0.00002899
Iteration 42/1000 | Loss: 0.00002897
Iteration 43/1000 | Loss: 0.00002896
Iteration 44/1000 | Loss: 0.00002896
Iteration 45/1000 | Loss: 0.00002895
Iteration 46/1000 | Loss: 0.00002895
Iteration 47/1000 | Loss: 0.00002893
Iteration 48/1000 | Loss: 0.00002893
Iteration 49/1000 | Loss: 0.00002893
Iteration 50/1000 | Loss: 0.00002892
Iteration 51/1000 | Loss: 0.00002890
Iteration 52/1000 | Loss: 0.00002889
Iteration 53/1000 | Loss: 0.00002889
Iteration 54/1000 | Loss: 0.00002887
Iteration 55/1000 | Loss: 0.00002886
Iteration 56/1000 | Loss: 0.00002886
Iteration 57/1000 | Loss: 0.00002886
Iteration 58/1000 | Loss: 0.00002885
Iteration 59/1000 | Loss: 0.00002883
Iteration 60/1000 | Loss: 0.00002883
Iteration 61/1000 | Loss: 0.00002883
Iteration 62/1000 | Loss: 0.00002882
Iteration 63/1000 | Loss: 0.00002880
Iteration 64/1000 | Loss: 0.00002879
Iteration 65/1000 | Loss: 0.00002879
Iteration 66/1000 | Loss: 0.00002876
Iteration 67/1000 | Loss: 0.00002876
Iteration 68/1000 | Loss: 0.00002875
Iteration 69/1000 | Loss: 0.00002871
Iteration 70/1000 | Loss: 0.00002871
Iteration 71/1000 | Loss: 0.00002871
Iteration 72/1000 | Loss: 0.00002870
Iteration 73/1000 | Loss: 0.00002869
Iteration 74/1000 | Loss: 0.00002869
Iteration 75/1000 | Loss: 0.00002869
Iteration 76/1000 | Loss: 0.00002869
Iteration 77/1000 | Loss: 0.00002868
Iteration 78/1000 | Loss: 0.00002867
Iteration 79/1000 | Loss: 0.00002867
Iteration 80/1000 | Loss: 0.00002867
Iteration 81/1000 | Loss: 0.00002866
Iteration 82/1000 | Loss: 0.00002866
Iteration 83/1000 | Loss: 0.00002865
Iteration 84/1000 | Loss: 0.00002864
Iteration 85/1000 | Loss: 0.00002864
Iteration 86/1000 | Loss: 0.00002864
Iteration 87/1000 | Loss: 0.00002864
Iteration 88/1000 | Loss: 0.00002864
Iteration 89/1000 | Loss: 0.00002864
Iteration 90/1000 | Loss: 0.00002864
Iteration 91/1000 | Loss: 0.00002863
Iteration 92/1000 | Loss: 0.00002863
Iteration 93/1000 | Loss: 0.00002863
Iteration 94/1000 | Loss: 0.00002863
Iteration 95/1000 | Loss: 0.00002863
Iteration 96/1000 | Loss: 0.00002863
Iteration 97/1000 | Loss: 0.00002863
Iteration 98/1000 | Loss: 0.00002863
Iteration 99/1000 | Loss: 0.00002862
Iteration 100/1000 | Loss: 0.00002862
Iteration 101/1000 | Loss: 0.00002862
Iteration 102/1000 | Loss: 0.00002862
Iteration 103/1000 | Loss: 0.00002862
Iteration 104/1000 | Loss: 0.00002862
Iteration 105/1000 | Loss: 0.00002862
Iteration 106/1000 | Loss: 0.00002862
Iteration 107/1000 | Loss: 0.00002861
Iteration 108/1000 | Loss: 0.00002861
Iteration 109/1000 | Loss: 0.00002861
Iteration 110/1000 | Loss: 0.00002861
Iteration 111/1000 | Loss: 0.00002860
Iteration 112/1000 | Loss: 0.00002860
Iteration 113/1000 | Loss: 0.00002860
Iteration 114/1000 | Loss: 0.00002860
Iteration 115/1000 | Loss: 0.00002860
Iteration 116/1000 | Loss: 0.00002860
Iteration 117/1000 | Loss: 0.00002859
Iteration 118/1000 | Loss: 0.00002859
Iteration 119/1000 | Loss: 0.00002859
Iteration 120/1000 | Loss: 0.00002859
Iteration 121/1000 | Loss: 0.00002859
Iteration 122/1000 | Loss: 0.00002859
Iteration 123/1000 | Loss: 0.00002858
Iteration 124/1000 | Loss: 0.00002858
Iteration 125/1000 | Loss: 0.00002858
Iteration 126/1000 | Loss: 0.00002858
Iteration 127/1000 | Loss: 0.00002858
Iteration 128/1000 | Loss: 0.00002857
Iteration 129/1000 | Loss: 0.00002857
Iteration 130/1000 | Loss: 0.00002857
Iteration 131/1000 | Loss: 0.00002857
Iteration 132/1000 | Loss: 0.00002857
Iteration 133/1000 | Loss: 0.00002857
Iteration 134/1000 | Loss: 0.00002857
Iteration 135/1000 | Loss: 0.00002857
Iteration 136/1000 | Loss: 0.00002856
Iteration 137/1000 | Loss: 0.00002856
Iteration 138/1000 | Loss: 0.00002856
Iteration 139/1000 | Loss: 0.00002856
Iteration 140/1000 | Loss: 0.00002856
Iteration 141/1000 | Loss: 0.00002856
Iteration 142/1000 | Loss: 0.00002856
Iteration 143/1000 | Loss: 0.00002856
Iteration 144/1000 | Loss: 0.00002856
Iteration 145/1000 | Loss: 0.00002855
Iteration 146/1000 | Loss: 0.00002855
Iteration 147/1000 | Loss: 0.00002855
Iteration 148/1000 | Loss: 0.00002855
Iteration 149/1000 | Loss: 0.00002855
Iteration 150/1000 | Loss: 0.00002855
Iteration 151/1000 | Loss: 0.00002855
Iteration 152/1000 | Loss: 0.00002855
Iteration 153/1000 | Loss: 0.00002855
Iteration 154/1000 | Loss: 0.00002855
Iteration 155/1000 | Loss: 0.00002855
Iteration 156/1000 | Loss: 0.00002855
Iteration 157/1000 | Loss: 0.00002855
Iteration 158/1000 | Loss: 0.00002855
Iteration 159/1000 | Loss: 0.00002855
Iteration 160/1000 | Loss: 0.00002855
Iteration 161/1000 | Loss: 0.00002855
Iteration 162/1000 | Loss: 0.00002855
Iteration 163/1000 | Loss: 0.00002855
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 163. Stopping optimization.
Last 5 losses: [2.8545364330057055e-05, 2.8545364330057055e-05, 2.8545364330057055e-05, 2.8545364330057055e-05, 2.8545364330057055e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8545364330057055e-05

Optimization complete. Final v2v error: 4.196474552154541 mm

Highest mean error: 6.641116619110107 mm for frame 27

Lowest mean error: 3.3937790393829346 mm for frame 104

Saving results

Total time: 114.130056142807
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1066/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1066.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1066
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00925586
Iteration 2/25 | Loss: 0.00325785
Iteration 3/25 | Loss: 0.00204645
Iteration 4/25 | Loss: 0.00162419
Iteration 5/25 | Loss: 0.00143684
Iteration 6/25 | Loss: 0.00135747
Iteration 7/25 | Loss: 0.00123867
Iteration 8/25 | Loss: 0.00117941
Iteration 9/25 | Loss: 0.00119810
Iteration 10/25 | Loss: 0.00110077
Iteration 11/25 | Loss: 0.00106242
Iteration 12/25 | Loss: 0.00104201
Iteration 13/25 | Loss: 0.00103311
Iteration 14/25 | Loss: 0.00103089
Iteration 15/25 | Loss: 0.00102990
Iteration 16/25 | Loss: 0.00102936
Iteration 17/25 | Loss: 0.00103307
Iteration 18/25 | Loss: 0.00102823
Iteration 19/25 | Loss: 0.00102548
Iteration 20/25 | Loss: 0.00102854
Iteration 21/25 | Loss: 0.00102329
Iteration 22/25 | Loss: 0.00103172
Iteration 23/25 | Loss: 0.00101931
Iteration 24/25 | Loss: 0.00101832
Iteration 25/25 | Loss: 0.00101355

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.70209265
Iteration 2/25 | Loss: 0.00314726
Iteration 3/25 | Loss: 0.00292309
Iteration 4/25 | Loss: 0.00292309
Iteration 5/25 | Loss: 0.00292308
Iteration 6/25 | Loss: 0.00292308
Iteration 7/25 | Loss: 0.00292308
Iteration 8/25 | Loss: 0.00292308
Iteration 9/25 | Loss: 0.00292308
Iteration 10/25 | Loss: 0.00292308
Iteration 11/25 | Loss: 0.00292308
Iteration 12/25 | Loss: 0.00292308
Iteration 13/25 | Loss: 0.00292308
Iteration 14/25 | Loss: 0.00292308
Iteration 15/25 | Loss: 0.00292308
Iteration 16/25 | Loss: 0.00292308
Iteration 17/25 | Loss: 0.00292308
Iteration 18/25 | Loss: 0.00292308
Iteration 19/25 | Loss: 0.00292308
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0029230830259621143, 0.0029230830259621143, 0.0029230830259621143, 0.0029230830259621143, 0.0029230830259621143]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0029230830259621143

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00292308
Iteration 2/1000 | Loss: 0.00193589
Iteration 3/1000 | Loss: 0.00124079
Iteration 4/1000 | Loss: 0.00243232
Iteration 5/1000 | Loss: 0.00425344
Iteration 6/1000 | Loss: 0.00407587
Iteration 7/1000 | Loss: 0.00488786
Iteration 8/1000 | Loss: 0.00033436
Iteration 9/1000 | Loss: 0.00313261
Iteration 10/1000 | Loss: 0.00047256
Iteration 11/1000 | Loss: 0.00201574
Iteration 12/1000 | Loss: 0.00052271
Iteration 13/1000 | Loss: 0.00040416
Iteration 14/1000 | Loss: 0.00080240
Iteration 15/1000 | Loss: 0.00160988
Iteration 16/1000 | Loss: 0.00025635
Iteration 17/1000 | Loss: 0.00142736
Iteration 18/1000 | Loss: 0.00032563
Iteration 19/1000 | Loss: 0.00008931
Iteration 20/1000 | Loss: 0.00094427
Iteration 21/1000 | Loss: 0.00109808
Iteration 22/1000 | Loss: 0.00113464
Iteration 23/1000 | Loss: 0.00057794
Iteration 24/1000 | Loss: 0.00056995
Iteration 25/1000 | Loss: 0.00120215
Iteration 26/1000 | Loss: 0.00033652
Iteration 27/1000 | Loss: 0.00053322
Iteration 28/1000 | Loss: 0.00074161
Iteration 29/1000 | Loss: 0.00230572
Iteration 30/1000 | Loss: 0.00090824
Iteration 31/1000 | Loss: 0.00055013
Iteration 32/1000 | Loss: 0.00105959
Iteration 33/1000 | Loss: 0.00038254
Iteration 34/1000 | Loss: 0.00013464
Iteration 35/1000 | Loss: 0.00023720
Iteration 36/1000 | Loss: 0.00027669
Iteration 37/1000 | Loss: 0.00049725
Iteration 38/1000 | Loss: 0.00068851
Iteration 39/1000 | Loss: 0.00126548
Iteration 40/1000 | Loss: 0.00125871
Iteration 41/1000 | Loss: 0.00195553
Iteration 42/1000 | Loss: 0.00039465
Iteration 43/1000 | Loss: 0.00170610
Iteration 44/1000 | Loss: 0.00016947
Iteration 45/1000 | Loss: 0.00063020
Iteration 46/1000 | Loss: 0.00082680
Iteration 47/1000 | Loss: 0.00080530
Iteration 48/1000 | Loss: 0.00125613
Iteration 49/1000 | Loss: 0.00069986
Iteration 50/1000 | Loss: 0.00056003
Iteration 51/1000 | Loss: 0.00074820
Iteration 52/1000 | Loss: 0.00110195
Iteration 53/1000 | Loss: 0.00081716
Iteration 54/1000 | Loss: 0.00068687
Iteration 55/1000 | Loss: 0.00068678
Iteration 56/1000 | Loss: 0.00129848
Iteration 57/1000 | Loss: 0.00034676
Iteration 58/1000 | Loss: 0.00009610
Iteration 59/1000 | Loss: 0.00044349
Iteration 60/1000 | Loss: 0.00027300
Iteration 61/1000 | Loss: 0.00009849
Iteration 62/1000 | Loss: 0.00073919
Iteration 63/1000 | Loss: 0.00047139
Iteration 64/1000 | Loss: 0.00086055
Iteration 65/1000 | Loss: 0.00031584
Iteration 66/1000 | Loss: 0.00005842
Iteration 67/1000 | Loss: 0.00065030
Iteration 68/1000 | Loss: 0.00098615
Iteration 69/1000 | Loss: 0.00121932
Iteration 70/1000 | Loss: 0.00185126
Iteration 71/1000 | Loss: 0.00068338
Iteration 72/1000 | Loss: 0.00007934
Iteration 73/1000 | Loss: 0.00005606
Iteration 74/1000 | Loss: 0.00011712
Iteration 75/1000 | Loss: 0.00003186
Iteration 76/1000 | Loss: 0.00002853
Iteration 77/1000 | Loss: 0.00002678
Iteration 78/1000 | Loss: 0.00002581
Iteration 79/1000 | Loss: 0.00037690
Iteration 80/1000 | Loss: 0.00006270
Iteration 81/1000 | Loss: 0.00003388
Iteration 82/1000 | Loss: 0.00002429
Iteration 83/1000 | Loss: 0.00002272
Iteration 84/1000 | Loss: 0.00002165
Iteration 85/1000 | Loss: 0.00002103
Iteration 86/1000 | Loss: 0.00002059
Iteration 87/1000 | Loss: 0.00002036
Iteration 88/1000 | Loss: 0.00002005
Iteration 89/1000 | Loss: 0.00001994
Iteration 90/1000 | Loss: 0.00001984
Iteration 91/1000 | Loss: 0.00001980
Iteration 92/1000 | Loss: 0.00001977
Iteration 93/1000 | Loss: 0.00001976
Iteration 94/1000 | Loss: 0.00001976
Iteration 95/1000 | Loss: 0.00001974
Iteration 96/1000 | Loss: 0.00001972
Iteration 97/1000 | Loss: 0.00001964
Iteration 98/1000 | Loss: 0.00001946
Iteration 99/1000 | Loss: 0.00001941
Iteration 100/1000 | Loss: 0.00001934
Iteration 101/1000 | Loss: 0.00001933
Iteration 102/1000 | Loss: 0.00001933
Iteration 103/1000 | Loss: 0.00001932
Iteration 104/1000 | Loss: 0.00001932
Iteration 105/1000 | Loss: 0.00001932
Iteration 106/1000 | Loss: 0.00001931
Iteration 107/1000 | Loss: 0.00001931
Iteration 108/1000 | Loss: 0.00001930
Iteration 109/1000 | Loss: 0.00001930
Iteration 110/1000 | Loss: 0.00001929
Iteration 111/1000 | Loss: 0.00001927
Iteration 112/1000 | Loss: 0.00001927
Iteration 113/1000 | Loss: 0.00001923
Iteration 114/1000 | Loss: 0.00001922
Iteration 115/1000 | Loss: 0.00001922
Iteration 116/1000 | Loss: 0.00001922
Iteration 117/1000 | Loss: 0.00001922
Iteration 118/1000 | Loss: 0.00001922
Iteration 119/1000 | Loss: 0.00001922
Iteration 120/1000 | Loss: 0.00001922
Iteration 121/1000 | Loss: 0.00001922
Iteration 122/1000 | Loss: 0.00001922
Iteration 123/1000 | Loss: 0.00001921
Iteration 124/1000 | Loss: 0.00001921
Iteration 125/1000 | Loss: 0.00001921
Iteration 126/1000 | Loss: 0.00001920
Iteration 127/1000 | Loss: 0.00001920
Iteration 128/1000 | Loss: 0.00001920
Iteration 129/1000 | Loss: 0.00001919
Iteration 130/1000 | Loss: 0.00001919
Iteration 131/1000 | Loss: 0.00001918
Iteration 132/1000 | Loss: 0.00001917
Iteration 133/1000 | Loss: 0.00001917
Iteration 134/1000 | Loss: 0.00001917
Iteration 135/1000 | Loss: 0.00001917
Iteration 136/1000 | Loss: 0.00001916
Iteration 137/1000 | Loss: 0.00001916
Iteration 138/1000 | Loss: 0.00001915
Iteration 139/1000 | Loss: 0.00001915
Iteration 140/1000 | Loss: 0.00001915
Iteration 141/1000 | Loss: 0.00001914
Iteration 142/1000 | Loss: 0.00001914
Iteration 143/1000 | Loss: 0.00001913
Iteration 144/1000 | Loss: 0.00001913
Iteration 145/1000 | Loss: 0.00001912
Iteration 146/1000 | Loss: 0.00001912
Iteration 147/1000 | Loss: 0.00001911
Iteration 148/1000 | Loss: 0.00001911
Iteration 149/1000 | Loss: 0.00001910
Iteration 150/1000 | Loss: 0.00001910
Iteration 151/1000 | Loss: 0.00001910
Iteration 152/1000 | Loss: 0.00001910
Iteration 153/1000 | Loss: 0.00001909
Iteration 154/1000 | Loss: 0.00001909
Iteration 155/1000 | Loss: 0.00001909
Iteration 156/1000 | Loss: 0.00001908
Iteration 157/1000 | Loss: 0.00001908
Iteration 158/1000 | Loss: 0.00001908
Iteration 159/1000 | Loss: 0.00001907
Iteration 160/1000 | Loss: 0.00001907
Iteration 161/1000 | Loss: 0.00001906
Iteration 162/1000 | Loss: 0.00001905
Iteration 163/1000 | Loss: 0.00001905
Iteration 164/1000 | Loss: 0.00001904
Iteration 165/1000 | Loss: 0.00001904
Iteration 166/1000 | Loss: 0.00001904
Iteration 167/1000 | Loss: 0.00001904
Iteration 168/1000 | Loss: 0.00001904
Iteration 169/1000 | Loss: 0.00001904
Iteration 170/1000 | Loss: 0.00001904
Iteration 171/1000 | Loss: 0.00001904
Iteration 172/1000 | Loss: 0.00001904
Iteration 173/1000 | Loss: 0.00001904
Iteration 174/1000 | Loss: 0.00001903
Iteration 175/1000 | Loss: 0.00001903
Iteration 176/1000 | Loss: 0.00001903
Iteration 177/1000 | Loss: 0.00001903
Iteration 178/1000 | Loss: 0.00001903
Iteration 179/1000 | Loss: 0.00001902
Iteration 180/1000 | Loss: 0.00001902
Iteration 181/1000 | Loss: 0.00001902
Iteration 182/1000 | Loss: 0.00001902
Iteration 183/1000 | Loss: 0.00001902
Iteration 184/1000 | Loss: 0.00001902
Iteration 185/1000 | Loss: 0.00001902
Iteration 186/1000 | Loss: 0.00001902
Iteration 187/1000 | Loss: 0.00001902
Iteration 188/1000 | Loss: 0.00001902
Iteration 189/1000 | Loss: 0.00001902
Iteration 190/1000 | Loss: 0.00001901
Iteration 191/1000 | Loss: 0.00001901
Iteration 192/1000 | Loss: 0.00001901
Iteration 193/1000 | Loss: 0.00001901
Iteration 194/1000 | Loss: 0.00001901
Iteration 195/1000 | Loss: 0.00001901
Iteration 196/1000 | Loss: 0.00001901
Iteration 197/1000 | Loss: 0.00001901
Iteration 198/1000 | Loss: 0.00001901
Iteration 199/1000 | Loss: 0.00001901
Iteration 200/1000 | Loss: 0.00001901
Iteration 201/1000 | Loss: 0.00001901
Iteration 202/1000 | Loss: 0.00001901
Iteration 203/1000 | Loss: 0.00001901
Iteration 204/1000 | Loss: 0.00001901
Iteration 205/1000 | Loss: 0.00001901
Iteration 206/1000 | Loss: 0.00001901
Iteration 207/1000 | Loss: 0.00001901
Iteration 208/1000 | Loss: 0.00001901
Iteration 209/1000 | Loss: 0.00001901
Iteration 210/1000 | Loss: 0.00001901
Iteration 211/1000 | Loss: 0.00001901
Iteration 212/1000 | Loss: 0.00001900
Iteration 213/1000 | Loss: 0.00001900
Iteration 214/1000 | Loss: 0.00001900
Iteration 215/1000 | Loss: 0.00001900
Iteration 216/1000 | Loss: 0.00001900
Iteration 217/1000 | Loss: 0.00001900
Iteration 218/1000 | Loss: 0.00001900
Iteration 219/1000 | Loss: 0.00001900
Iteration 220/1000 | Loss: 0.00001900
Iteration 221/1000 | Loss: 0.00001900
Iteration 222/1000 | Loss: 0.00001900
Iteration 223/1000 | Loss: 0.00001900
Iteration 224/1000 | Loss: 0.00001900
Iteration 225/1000 | Loss: 0.00001900
Iteration 226/1000 | Loss: 0.00001900
Iteration 227/1000 | Loss: 0.00001900
Iteration 228/1000 | Loss: 0.00001900
Iteration 229/1000 | Loss: 0.00001899
Iteration 230/1000 | Loss: 0.00001899
Iteration 231/1000 | Loss: 0.00001899
Iteration 232/1000 | Loss: 0.00001899
Iteration 233/1000 | Loss: 0.00001899
Iteration 234/1000 | Loss: 0.00001899
Iteration 235/1000 | Loss: 0.00001898
Iteration 236/1000 | Loss: 0.00001898
Iteration 237/1000 | Loss: 0.00001898
Iteration 238/1000 | Loss: 0.00001898
Iteration 239/1000 | Loss: 0.00001898
Iteration 240/1000 | Loss: 0.00001898
Iteration 241/1000 | Loss: 0.00001898
Iteration 242/1000 | Loss: 0.00001898
Iteration 243/1000 | Loss: 0.00001898
Iteration 244/1000 | Loss: 0.00001897
Iteration 245/1000 | Loss: 0.00001897
Iteration 246/1000 | Loss: 0.00001897
Iteration 247/1000 | Loss: 0.00001897
Iteration 248/1000 | Loss: 0.00001897
Iteration 249/1000 | Loss: 0.00001897
Iteration 250/1000 | Loss: 0.00001897
Iteration 251/1000 | Loss: 0.00001897
Iteration 252/1000 | Loss: 0.00001897
Iteration 253/1000 | Loss: 0.00001897
Iteration 254/1000 | Loss: 0.00001897
Iteration 255/1000 | Loss: 0.00001897
Iteration 256/1000 | Loss: 0.00001897
Iteration 257/1000 | Loss: 0.00001897
Iteration 258/1000 | Loss: 0.00001897
Iteration 259/1000 | Loss: 0.00001897
Iteration 260/1000 | Loss: 0.00001897
Iteration 261/1000 | Loss: 0.00001897
Iteration 262/1000 | Loss: 0.00001897
Iteration 263/1000 | Loss: 0.00001896
Iteration 264/1000 | Loss: 0.00001896
Iteration 265/1000 | Loss: 0.00001896
Iteration 266/1000 | Loss: 0.00001896
Iteration 267/1000 | Loss: 0.00001896
Iteration 268/1000 | Loss: 0.00001896
Iteration 269/1000 | Loss: 0.00001896
Iteration 270/1000 | Loss: 0.00001896
Iteration 271/1000 | Loss: 0.00001896
Iteration 272/1000 | Loss: 0.00001896
Iteration 273/1000 | Loss: 0.00001896
Iteration 274/1000 | Loss: 0.00001896
Iteration 275/1000 | Loss: 0.00001896
Iteration 276/1000 | Loss: 0.00001896
Iteration 277/1000 | Loss: 0.00001896
Iteration 278/1000 | Loss: 0.00001896
Iteration 279/1000 | Loss: 0.00001896
Iteration 280/1000 | Loss: 0.00001896
Iteration 281/1000 | Loss: 0.00001896
Iteration 282/1000 | Loss: 0.00001896
Iteration 283/1000 | Loss: 0.00001896
Iteration 284/1000 | Loss: 0.00001896
Iteration 285/1000 | Loss: 0.00001896
Iteration 286/1000 | Loss: 0.00001896
Iteration 287/1000 | Loss: 0.00001896
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 287. Stopping optimization.
Last 5 losses: [1.8963202819577418e-05, 1.8963202819577418e-05, 1.8963202819577418e-05, 1.8963202819577418e-05, 1.8963202819577418e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8963202819577418e-05

Optimization complete. Final v2v error: 3.638174295425415 mm

Highest mean error: 5.724422454833984 mm for frame 77

Lowest mean error: 3.063776731491089 mm for frame 124

Saving results

Total time: 203.42785906791687
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1046/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1046.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1046
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00621173
Iteration 2/25 | Loss: 0.00137333
Iteration 3/25 | Loss: 0.00091121
Iteration 4/25 | Loss: 0.00080701
Iteration 5/25 | Loss: 0.00078902
Iteration 6/25 | Loss: 0.00076792
Iteration 7/25 | Loss: 0.00075865
Iteration 8/25 | Loss: 0.00076093
Iteration 9/25 | Loss: 0.00075662
Iteration 10/25 | Loss: 0.00076772
Iteration 11/25 | Loss: 0.00075215
Iteration 12/25 | Loss: 0.00074786
Iteration 13/25 | Loss: 0.00075015
Iteration 14/25 | Loss: 0.00074254
Iteration 15/25 | Loss: 0.00074144
Iteration 16/25 | Loss: 0.00073901
Iteration 17/25 | Loss: 0.00073581
Iteration 18/25 | Loss: 0.00073705
Iteration 19/25 | Loss: 0.00073620
Iteration 20/25 | Loss: 0.00073456
Iteration 21/25 | Loss: 0.00073562
Iteration 22/25 | Loss: 0.00073640
Iteration 23/25 | Loss: 0.00073470
Iteration 24/25 | Loss: 0.00073436
Iteration 25/25 | Loss: 0.00073436

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 4.71848106
Iteration 2/25 | Loss: 0.00054291
Iteration 3/25 | Loss: 0.00053153
Iteration 4/25 | Loss: 0.00053153
Iteration 5/25 | Loss: 0.00053153
Iteration 6/25 | Loss: 0.00053153
Iteration 7/25 | Loss: 0.00053153
Iteration 8/25 | Loss: 0.00053153
Iteration 9/25 | Loss: 0.00053153
Iteration 10/25 | Loss: 0.00053153
Iteration 11/25 | Loss: 0.00053152
Iteration 12/25 | Loss: 0.00053152
Iteration 13/25 | Loss: 0.00053152
Iteration 14/25 | Loss: 0.00053152
Iteration 15/25 | Loss: 0.00053152
Iteration 16/25 | Loss: 0.00053152
Iteration 17/25 | Loss: 0.00053152
Iteration 18/25 | Loss: 0.00053152
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005315245944075286, 0.0005315245944075286, 0.0005315245944075286, 0.0005315245944075286, 0.0005315245944075286]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005315245944075286

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053152
Iteration 2/1000 | Loss: 0.00003984
Iteration 3/1000 | Loss: 0.00002697
Iteration 4/1000 | Loss: 0.00003012
Iteration 5/1000 | Loss: 0.00001765
Iteration 6/1000 | Loss: 0.00001918
Iteration 7/1000 | Loss: 0.00003302
Iteration 8/1000 | Loss: 0.00001410
Iteration 9/1000 | Loss: 0.00001710
Iteration 10/1000 | Loss: 0.00001353
Iteration 11/1000 | Loss: 0.00001340
Iteration 12/1000 | Loss: 0.00001338
Iteration 13/1000 | Loss: 0.00001320
Iteration 14/1000 | Loss: 0.00001301
Iteration 15/1000 | Loss: 0.00001297
Iteration 16/1000 | Loss: 0.00003432
Iteration 17/1000 | Loss: 0.00001284
Iteration 18/1000 | Loss: 0.00001282
Iteration 19/1000 | Loss: 0.00001282
Iteration 20/1000 | Loss: 0.00001282
Iteration 21/1000 | Loss: 0.00001282
Iteration 22/1000 | Loss: 0.00001282
Iteration 23/1000 | Loss: 0.00001282
Iteration 24/1000 | Loss: 0.00001282
Iteration 25/1000 | Loss: 0.00001281
Iteration 26/1000 | Loss: 0.00001280
Iteration 27/1000 | Loss: 0.00004136
Iteration 28/1000 | Loss: 0.00001282
Iteration 29/1000 | Loss: 0.00001275
Iteration 30/1000 | Loss: 0.00001274
Iteration 31/1000 | Loss: 0.00001274
Iteration 32/1000 | Loss: 0.00001274
Iteration 33/1000 | Loss: 0.00001274
Iteration 34/1000 | Loss: 0.00001274
Iteration 35/1000 | Loss: 0.00001273
Iteration 36/1000 | Loss: 0.00001273
Iteration 37/1000 | Loss: 0.00001272
Iteration 38/1000 | Loss: 0.00001272
Iteration 39/1000 | Loss: 0.00001271
Iteration 40/1000 | Loss: 0.00001270
Iteration 41/1000 | Loss: 0.00001270
Iteration 42/1000 | Loss: 0.00001270
Iteration 43/1000 | Loss: 0.00001270
Iteration 44/1000 | Loss: 0.00001269
Iteration 45/1000 | Loss: 0.00001269
Iteration 46/1000 | Loss: 0.00001268
Iteration 47/1000 | Loss: 0.00001268
Iteration 48/1000 | Loss: 0.00001268
Iteration 49/1000 | Loss: 0.00001267
Iteration 50/1000 | Loss: 0.00003343
Iteration 51/1000 | Loss: 0.00001270
Iteration 52/1000 | Loss: 0.00001266
Iteration 53/1000 | Loss: 0.00001266
Iteration 54/1000 | Loss: 0.00001265
Iteration 55/1000 | Loss: 0.00001265
Iteration 56/1000 | Loss: 0.00001264
Iteration 57/1000 | Loss: 0.00001264
Iteration 58/1000 | Loss: 0.00001264
Iteration 59/1000 | Loss: 0.00001264
Iteration 60/1000 | Loss: 0.00001263
Iteration 61/1000 | Loss: 0.00001263
Iteration 62/1000 | Loss: 0.00001263
Iteration 63/1000 | Loss: 0.00001263
Iteration 64/1000 | Loss: 0.00001262
Iteration 65/1000 | Loss: 0.00003047
Iteration 66/1000 | Loss: 0.00001264
Iteration 67/1000 | Loss: 0.00001739
Iteration 68/1000 | Loss: 0.00001259
Iteration 69/1000 | Loss: 0.00001259
Iteration 70/1000 | Loss: 0.00001259
Iteration 71/1000 | Loss: 0.00001259
Iteration 72/1000 | Loss: 0.00001259
Iteration 73/1000 | Loss: 0.00001259
Iteration 74/1000 | Loss: 0.00001258
Iteration 75/1000 | Loss: 0.00001258
Iteration 76/1000 | Loss: 0.00001258
Iteration 77/1000 | Loss: 0.00001258
Iteration 78/1000 | Loss: 0.00001257
Iteration 79/1000 | Loss: 0.00001384
Iteration 80/1000 | Loss: 0.00001256
Iteration 81/1000 | Loss: 0.00001256
Iteration 82/1000 | Loss: 0.00001255
Iteration 83/1000 | Loss: 0.00001255
Iteration 84/1000 | Loss: 0.00001255
Iteration 85/1000 | Loss: 0.00001255
Iteration 86/1000 | Loss: 0.00001255
Iteration 87/1000 | Loss: 0.00001255
Iteration 88/1000 | Loss: 0.00001255
Iteration 89/1000 | Loss: 0.00001254
Iteration 90/1000 | Loss: 0.00002754
Iteration 91/1000 | Loss: 0.00001456
Iteration 92/1000 | Loss: 0.00001252
Iteration 93/1000 | Loss: 0.00001252
Iteration 94/1000 | Loss: 0.00001252
Iteration 95/1000 | Loss: 0.00001252
Iteration 96/1000 | Loss: 0.00001252
Iteration 97/1000 | Loss: 0.00001252
Iteration 98/1000 | Loss: 0.00001252
Iteration 99/1000 | Loss: 0.00001252
Iteration 100/1000 | Loss: 0.00001252
Iteration 101/1000 | Loss: 0.00001252
Iteration 102/1000 | Loss: 0.00001251
Iteration 103/1000 | Loss: 0.00001251
Iteration 104/1000 | Loss: 0.00001671
Iteration 105/1000 | Loss: 0.00001248
Iteration 106/1000 | Loss: 0.00001248
Iteration 107/1000 | Loss: 0.00001248
Iteration 108/1000 | Loss: 0.00001248
Iteration 109/1000 | Loss: 0.00001248
Iteration 110/1000 | Loss: 0.00001248
Iteration 111/1000 | Loss: 0.00001248
Iteration 112/1000 | Loss: 0.00001248
Iteration 113/1000 | Loss: 0.00001248
Iteration 114/1000 | Loss: 0.00001248
Iteration 115/1000 | Loss: 0.00001248
Iteration 116/1000 | Loss: 0.00001248
Iteration 117/1000 | Loss: 0.00001248
Iteration 118/1000 | Loss: 0.00001248
Iteration 119/1000 | Loss: 0.00001248
Iteration 120/1000 | Loss: 0.00001248
Iteration 121/1000 | Loss: 0.00001248
Iteration 122/1000 | Loss: 0.00001248
Iteration 123/1000 | Loss: 0.00001248
Iteration 124/1000 | Loss: 0.00001248
Iteration 125/1000 | Loss: 0.00001248
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [1.2477514246711507e-05, 1.2477514246711507e-05, 1.2477514246711507e-05, 1.2477514246711507e-05, 1.2477514246711507e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2477514246711507e-05

Optimization complete. Final v2v error: 3.008427619934082 mm

Highest mean error: 3.4075989723205566 mm for frame 16

Lowest mean error: 2.655014753341675 mm for frame 158

Saving results

Total time: 91.85119867324829
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1087/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1087.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1087
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00528032
Iteration 2/25 | Loss: 0.00129773
Iteration 3/25 | Loss: 0.00087409
Iteration 4/25 | Loss: 0.00082625
Iteration 5/25 | Loss: 0.00081592
Iteration 6/25 | Loss: 0.00081399
Iteration 7/25 | Loss: 0.00081342
Iteration 8/25 | Loss: 0.00081342
Iteration 9/25 | Loss: 0.00081342
Iteration 10/25 | Loss: 0.00081342
Iteration 11/25 | Loss: 0.00081342
Iteration 12/25 | Loss: 0.00081342
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008134227246046066, 0.0008134227246046066, 0.0008134227246046066, 0.0008134227246046066, 0.0008134227246046066]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008134227246046066

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41366994
Iteration 2/25 | Loss: 0.00043330
Iteration 3/25 | Loss: 0.00043327
Iteration 4/25 | Loss: 0.00043327
Iteration 5/25 | Loss: 0.00043327
Iteration 6/25 | Loss: 0.00043327
Iteration 7/25 | Loss: 0.00043327
Iteration 8/25 | Loss: 0.00043327
Iteration 9/25 | Loss: 0.00043327
Iteration 10/25 | Loss: 0.00043327
Iteration 11/25 | Loss: 0.00043327
Iteration 12/25 | Loss: 0.00043327
Iteration 13/25 | Loss: 0.00043327
Iteration 14/25 | Loss: 0.00043327
Iteration 15/25 | Loss: 0.00043327
Iteration 16/25 | Loss: 0.00043327
Iteration 17/25 | Loss: 0.00043327
Iteration 18/25 | Loss: 0.00043327
Iteration 19/25 | Loss: 0.00043327
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0004332702956162393, 0.0004332702956162393, 0.0004332702956162393, 0.0004332702956162393, 0.0004332702956162393]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004332702956162393

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043327
Iteration 2/1000 | Loss: 0.00004840
Iteration 3/1000 | Loss: 0.00002973
Iteration 4/1000 | Loss: 0.00002660
Iteration 5/1000 | Loss: 0.00002537
Iteration 6/1000 | Loss: 0.00002444
Iteration 7/1000 | Loss: 0.00002390
Iteration 8/1000 | Loss: 0.00002346
Iteration 9/1000 | Loss: 0.00002303
Iteration 10/1000 | Loss: 0.00002274
Iteration 11/1000 | Loss: 0.00002249
Iteration 12/1000 | Loss: 0.00002228
Iteration 13/1000 | Loss: 0.00002216
Iteration 14/1000 | Loss: 0.00002211
Iteration 15/1000 | Loss: 0.00002206
Iteration 16/1000 | Loss: 0.00002199
Iteration 17/1000 | Loss: 0.00002199
Iteration 18/1000 | Loss: 0.00002199
Iteration 19/1000 | Loss: 0.00002198
Iteration 20/1000 | Loss: 0.00002198
Iteration 21/1000 | Loss: 0.00002196
Iteration 22/1000 | Loss: 0.00002196
Iteration 23/1000 | Loss: 0.00002195
Iteration 24/1000 | Loss: 0.00002194
Iteration 25/1000 | Loss: 0.00002194
Iteration 26/1000 | Loss: 0.00002194
Iteration 27/1000 | Loss: 0.00002194
Iteration 28/1000 | Loss: 0.00002194
Iteration 29/1000 | Loss: 0.00002194
Iteration 30/1000 | Loss: 0.00002193
Iteration 31/1000 | Loss: 0.00002192
Iteration 32/1000 | Loss: 0.00002192
Iteration 33/1000 | Loss: 0.00002191
Iteration 34/1000 | Loss: 0.00002191
Iteration 35/1000 | Loss: 0.00002191
Iteration 36/1000 | Loss: 0.00002190
Iteration 37/1000 | Loss: 0.00002189
Iteration 38/1000 | Loss: 0.00002189
Iteration 39/1000 | Loss: 0.00002189
Iteration 40/1000 | Loss: 0.00002189
Iteration 41/1000 | Loss: 0.00002189
Iteration 42/1000 | Loss: 0.00002189
Iteration 43/1000 | Loss: 0.00002188
Iteration 44/1000 | Loss: 0.00002188
Iteration 45/1000 | Loss: 0.00002187
Iteration 46/1000 | Loss: 0.00002185
Iteration 47/1000 | Loss: 0.00002184
Iteration 48/1000 | Loss: 0.00002184
Iteration 49/1000 | Loss: 0.00002184
Iteration 50/1000 | Loss: 0.00002182
Iteration 51/1000 | Loss: 0.00002182
Iteration 52/1000 | Loss: 0.00002182
Iteration 53/1000 | Loss: 0.00002182
Iteration 54/1000 | Loss: 0.00002181
Iteration 55/1000 | Loss: 0.00002181
Iteration 56/1000 | Loss: 0.00002180
Iteration 57/1000 | Loss: 0.00002179
Iteration 58/1000 | Loss: 0.00002179
Iteration 59/1000 | Loss: 0.00002179
Iteration 60/1000 | Loss: 0.00002179
Iteration 61/1000 | Loss: 0.00002178
Iteration 62/1000 | Loss: 0.00002177
Iteration 63/1000 | Loss: 0.00002177
Iteration 64/1000 | Loss: 0.00002177
Iteration 65/1000 | Loss: 0.00002176
Iteration 66/1000 | Loss: 0.00002176
Iteration 67/1000 | Loss: 0.00002175
Iteration 68/1000 | Loss: 0.00002175
Iteration 69/1000 | Loss: 0.00002175
Iteration 70/1000 | Loss: 0.00002174
Iteration 71/1000 | Loss: 0.00002174
Iteration 72/1000 | Loss: 0.00002173
Iteration 73/1000 | Loss: 0.00002173
Iteration 74/1000 | Loss: 0.00002172
Iteration 75/1000 | Loss: 0.00002171
Iteration 76/1000 | Loss: 0.00002171
Iteration 77/1000 | Loss: 0.00002170
Iteration 78/1000 | Loss: 0.00002170
Iteration 79/1000 | Loss: 0.00002169
Iteration 80/1000 | Loss: 0.00002169
Iteration 81/1000 | Loss: 0.00002167
Iteration 82/1000 | Loss: 0.00002167
Iteration 83/1000 | Loss: 0.00002167
Iteration 84/1000 | Loss: 0.00002167
Iteration 85/1000 | Loss: 0.00002167
Iteration 86/1000 | Loss: 0.00002167
Iteration 87/1000 | Loss: 0.00002167
Iteration 88/1000 | Loss: 0.00002167
Iteration 89/1000 | Loss: 0.00002167
Iteration 90/1000 | Loss: 0.00002166
Iteration 91/1000 | Loss: 0.00002166
Iteration 92/1000 | Loss: 0.00002166
Iteration 93/1000 | Loss: 0.00002166
Iteration 94/1000 | Loss: 0.00002166
Iteration 95/1000 | Loss: 0.00002165
Iteration 96/1000 | Loss: 0.00002165
Iteration 97/1000 | Loss: 0.00002165
Iteration 98/1000 | Loss: 0.00002165
Iteration 99/1000 | Loss: 0.00002165
Iteration 100/1000 | Loss: 0.00002165
Iteration 101/1000 | Loss: 0.00002165
Iteration 102/1000 | Loss: 0.00002165
Iteration 103/1000 | Loss: 0.00002165
Iteration 104/1000 | Loss: 0.00002165
Iteration 105/1000 | Loss: 0.00002165
Iteration 106/1000 | Loss: 0.00002164
Iteration 107/1000 | Loss: 0.00002164
Iteration 108/1000 | Loss: 0.00002164
Iteration 109/1000 | Loss: 0.00002164
Iteration 110/1000 | Loss: 0.00002164
Iteration 111/1000 | Loss: 0.00002164
Iteration 112/1000 | Loss: 0.00002164
Iteration 113/1000 | Loss: 0.00002164
Iteration 114/1000 | Loss: 0.00002164
Iteration 115/1000 | Loss: 0.00002164
Iteration 116/1000 | Loss: 0.00002163
Iteration 117/1000 | Loss: 0.00002163
Iteration 118/1000 | Loss: 0.00002163
Iteration 119/1000 | Loss: 0.00002163
Iteration 120/1000 | Loss: 0.00002163
Iteration 121/1000 | Loss: 0.00002162
Iteration 122/1000 | Loss: 0.00002162
Iteration 123/1000 | Loss: 0.00002162
Iteration 124/1000 | Loss: 0.00002162
Iteration 125/1000 | Loss: 0.00002161
Iteration 126/1000 | Loss: 0.00002161
Iteration 127/1000 | Loss: 0.00002161
Iteration 128/1000 | Loss: 0.00002161
Iteration 129/1000 | Loss: 0.00002161
Iteration 130/1000 | Loss: 0.00002161
Iteration 131/1000 | Loss: 0.00002161
Iteration 132/1000 | Loss: 0.00002161
Iteration 133/1000 | Loss: 0.00002161
Iteration 134/1000 | Loss: 0.00002161
Iteration 135/1000 | Loss: 0.00002161
Iteration 136/1000 | Loss: 0.00002161
Iteration 137/1000 | Loss: 0.00002161
Iteration 138/1000 | Loss: 0.00002160
Iteration 139/1000 | Loss: 0.00002160
Iteration 140/1000 | Loss: 0.00002160
Iteration 141/1000 | Loss: 0.00002160
Iteration 142/1000 | Loss: 0.00002160
Iteration 143/1000 | Loss: 0.00002159
Iteration 144/1000 | Loss: 0.00002159
Iteration 145/1000 | Loss: 0.00002159
Iteration 146/1000 | Loss: 0.00002159
Iteration 147/1000 | Loss: 0.00002159
Iteration 148/1000 | Loss: 0.00002158
Iteration 149/1000 | Loss: 0.00002158
Iteration 150/1000 | Loss: 0.00002158
Iteration 151/1000 | Loss: 0.00002158
Iteration 152/1000 | Loss: 0.00002158
Iteration 153/1000 | Loss: 0.00002158
Iteration 154/1000 | Loss: 0.00002158
Iteration 155/1000 | Loss: 0.00002158
Iteration 156/1000 | Loss: 0.00002157
Iteration 157/1000 | Loss: 0.00002157
Iteration 158/1000 | Loss: 0.00002157
Iteration 159/1000 | Loss: 0.00002157
Iteration 160/1000 | Loss: 0.00002157
Iteration 161/1000 | Loss: 0.00002157
Iteration 162/1000 | Loss: 0.00002157
Iteration 163/1000 | Loss: 0.00002157
Iteration 164/1000 | Loss: 0.00002157
Iteration 165/1000 | Loss: 0.00002156
Iteration 166/1000 | Loss: 0.00002156
Iteration 167/1000 | Loss: 0.00002156
Iteration 168/1000 | Loss: 0.00002156
Iteration 169/1000 | Loss: 0.00002156
Iteration 170/1000 | Loss: 0.00002156
Iteration 171/1000 | Loss: 0.00002155
Iteration 172/1000 | Loss: 0.00002155
Iteration 173/1000 | Loss: 0.00002155
Iteration 174/1000 | Loss: 0.00002155
Iteration 175/1000 | Loss: 0.00002155
Iteration 176/1000 | Loss: 0.00002155
Iteration 177/1000 | Loss: 0.00002155
Iteration 178/1000 | Loss: 0.00002155
Iteration 179/1000 | Loss: 0.00002155
Iteration 180/1000 | Loss: 0.00002155
Iteration 181/1000 | Loss: 0.00002154
Iteration 182/1000 | Loss: 0.00002154
Iteration 183/1000 | Loss: 0.00002154
Iteration 184/1000 | Loss: 0.00002154
Iteration 185/1000 | Loss: 0.00002154
Iteration 186/1000 | Loss: 0.00002154
Iteration 187/1000 | Loss: 0.00002154
Iteration 188/1000 | Loss: 0.00002154
Iteration 189/1000 | Loss: 0.00002154
Iteration 190/1000 | Loss: 0.00002154
Iteration 191/1000 | Loss: 0.00002154
Iteration 192/1000 | Loss: 0.00002154
Iteration 193/1000 | Loss: 0.00002154
Iteration 194/1000 | Loss: 0.00002153
Iteration 195/1000 | Loss: 0.00002153
Iteration 196/1000 | Loss: 0.00002153
Iteration 197/1000 | Loss: 0.00002153
Iteration 198/1000 | Loss: 0.00002153
Iteration 199/1000 | Loss: 0.00002153
Iteration 200/1000 | Loss: 0.00002153
Iteration 201/1000 | Loss: 0.00002153
Iteration 202/1000 | Loss: 0.00002152
Iteration 203/1000 | Loss: 0.00002152
Iteration 204/1000 | Loss: 0.00002152
Iteration 205/1000 | Loss: 0.00002152
Iteration 206/1000 | Loss: 0.00002152
Iteration 207/1000 | Loss: 0.00002152
Iteration 208/1000 | Loss: 0.00002152
Iteration 209/1000 | Loss: 0.00002152
Iteration 210/1000 | Loss: 0.00002152
Iteration 211/1000 | Loss: 0.00002152
Iteration 212/1000 | Loss: 0.00002152
Iteration 213/1000 | Loss: 0.00002151
Iteration 214/1000 | Loss: 0.00002151
Iteration 215/1000 | Loss: 0.00002151
Iteration 216/1000 | Loss: 0.00002151
Iteration 217/1000 | Loss: 0.00002151
Iteration 218/1000 | Loss: 0.00002151
Iteration 219/1000 | Loss: 0.00002151
Iteration 220/1000 | Loss: 0.00002151
Iteration 221/1000 | Loss: 0.00002151
Iteration 222/1000 | Loss: 0.00002151
Iteration 223/1000 | Loss: 0.00002151
Iteration 224/1000 | Loss: 0.00002151
Iteration 225/1000 | Loss: 0.00002150
Iteration 226/1000 | Loss: 0.00002150
Iteration 227/1000 | Loss: 0.00002150
Iteration 228/1000 | Loss: 0.00002150
Iteration 229/1000 | Loss: 0.00002150
Iteration 230/1000 | Loss: 0.00002150
Iteration 231/1000 | Loss: 0.00002150
Iteration 232/1000 | Loss: 0.00002150
Iteration 233/1000 | Loss: 0.00002150
Iteration 234/1000 | Loss: 0.00002150
Iteration 235/1000 | Loss: 0.00002150
Iteration 236/1000 | Loss: 0.00002150
Iteration 237/1000 | Loss: 0.00002150
Iteration 238/1000 | Loss: 0.00002150
Iteration 239/1000 | Loss: 0.00002150
Iteration 240/1000 | Loss: 0.00002150
Iteration 241/1000 | Loss: 0.00002150
Iteration 242/1000 | Loss: 0.00002149
Iteration 243/1000 | Loss: 0.00002149
Iteration 244/1000 | Loss: 0.00002149
Iteration 245/1000 | Loss: 0.00002149
Iteration 246/1000 | Loss: 0.00002149
Iteration 247/1000 | Loss: 0.00002149
Iteration 248/1000 | Loss: 0.00002149
Iteration 249/1000 | Loss: 0.00002149
Iteration 250/1000 | Loss: 0.00002149
Iteration 251/1000 | Loss: 0.00002149
Iteration 252/1000 | Loss: 0.00002149
Iteration 253/1000 | Loss: 0.00002149
Iteration 254/1000 | Loss: 0.00002148
Iteration 255/1000 | Loss: 0.00002148
Iteration 256/1000 | Loss: 0.00002148
Iteration 257/1000 | Loss: 0.00002148
Iteration 258/1000 | Loss: 0.00002148
Iteration 259/1000 | Loss: 0.00002148
Iteration 260/1000 | Loss: 0.00002148
Iteration 261/1000 | Loss: 0.00002148
Iteration 262/1000 | Loss: 0.00002148
Iteration 263/1000 | Loss: 0.00002148
Iteration 264/1000 | Loss: 0.00002148
Iteration 265/1000 | Loss: 0.00002148
Iteration 266/1000 | Loss: 0.00002148
Iteration 267/1000 | Loss: 0.00002148
Iteration 268/1000 | Loss: 0.00002148
Iteration 269/1000 | Loss: 0.00002147
Iteration 270/1000 | Loss: 0.00002147
Iteration 271/1000 | Loss: 0.00002147
Iteration 272/1000 | Loss: 0.00002147
Iteration 273/1000 | Loss: 0.00002147
Iteration 274/1000 | Loss: 0.00002147
Iteration 275/1000 | Loss: 0.00002147
Iteration 276/1000 | Loss: 0.00002147
Iteration 277/1000 | Loss: 0.00002147
Iteration 278/1000 | Loss: 0.00002146
Iteration 279/1000 | Loss: 0.00002146
Iteration 280/1000 | Loss: 0.00002146
Iteration 281/1000 | Loss: 0.00002146
Iteration 282/1000 | Loss: 0.00002146
Iteration 283/1000 | Loss: 0.00002146
Iteration 284/1000 | Loss: 0.00002146
Iteration 285/1000 | Loss: 0.00002146
Iteration 286/1000 | Loss: 0.00002146
Iteration 287/1000 | Loss: 0.00002146
Iteration 288/1000 | Loss: 0.00002146
Iteration 289/1000 | Loss: 0.00002146
Iteration 290/1000 | Loss: 0.00002146
Iteration 291/1000 | Loss: 0.00002146
Iteration 292/1000 | Loss: 0.00002146
Iteration 293/1000 | Loss: 0.00002146
Iteration 294/1000 | Loss: 0.00002146
Iteration 295/1000 | Loss: 0.00002146
Iteration 296/1000 | Loss: 0.00002146
Iteration 297/1000 | Loss: 0.00002146
Iteration 298/1000 | Loss: 0.00002146
Iteration 299/1000 | Loss: 0.00002146
Iteration 300/1000 | Loss: 0.00002146
Iteration 301/1000 | Loss: 0.00002146
Iteration 302/1000 | Loss: 0.00002146
Iteration 303/1000 | Loss: 0.00002146
Iteration 304/1000 | Loss: 0.00002146
Iteration 305/1000 | Loss: 0.00002146
Iteration 306/1000 | Loss: 0.00002146
Iteration 307/1000 | Loss: 0.00002146
Iteration 308/1000 | Loss: 0.00002146
Iteration 309/1000 | Loss: 0.00002146
Iteration 310/1000 | Loss: 0.00002146
Iteration 311/1000 | Loss: 0.00002146
Iteration 312/1000 | Loss: 0.00002146
Iteration 313/1000 | Loss: 0.00002146
Iteration 314/1000 | Loss: 0.00002146
Iteration 315/1000 | Loss: 0.00002146
Iteration 316/1000 | Loss: 0.00002146
Iteration 317/1000 | Loss: 0.00002146
Iteration 318/1000 | Loss: 0.00002146
Iteration 319/1000 | Loss: 0.00002146
Iteration 320/1000 | Loss: 0.00002146
Iteration 321/1000 | Loss: 0.00002146
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 321. Stopping optimization.
Last 5 losses: [2.1462483346113004e-05, 2.1462483346113004e-05, 2.1462483346113004e-05, 2.1462483346113004e-05, 2.1462483346113004e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1462483346113004e-05

Optimization complete. Final v2v error: 3.7604691982269287 mm

Highest mean error: 5.677300453186035 mm for frame 57

Lowest mean error: 2.7895283699035645 mm for frame 124

Saving results

Total time: 51.829704999923706
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1035/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1035.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1035
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01021173
Iteration 2/25 | Loss: 0.01021173
Iteration 3/25 | Loss: 0.00481220
Iteration 4/25 | Loss: 0.00326854
Iteration 5/25 | Loss: 0.00266096
Iteration 6/25 | Loss: 0.00229216
Iteration 7/25 | Loss: 0.00213479
Iteration 8/25 | Loss: 0.00197619
Iteration 9/25 | Loss: 0.00188543
Iteration 10/25 | Loss: 0.00180967
Iteration 11/25 | Loss: 0.00176924
Iteration 12/25 | Loss: 0.00176187
Iteration 13/25 | Loss: 0.00179553
Iteration 14/25 | Loss: 0.00173923
Iteration 15/25 | Loss: 0.00149424
Iteration 16/25 | Loss: 0.00142840
Iteration 17/25 | Loss: 0.00134758
Iteration 18/25 | Loss: 0.00131549
Iteration 19/25 | Loss: 0.00130251
Iteration 20/25 | Loss: 0.00128096
Iteration 21/25 | Loss: 0.00125852
Iteration 22/25 | Loss: 0.00126094
Iteration 23/25 | Loss: 0.00123789
Iteration 24/25 | Loss: 0.00125748
Iteration 25/25 | Loss: 0.00123758

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47727990
Iteration 2/25 | Loss: 0.00519449
Iteration 3/25 | Loss: 0.00452646
Iteration 4/25 | Loss: 0.00452645
Iteration 5/25 | Loss: 0.00452644
Iteration 6/25 | Loss: 0.00452644
Iteration 7/25 | Loss: 0.00452644
Iteration 8/25 | Loss: 0.00452644
Iteration 9/25 | Loss: 0.00452644
Iteration 10/25 | Loss: 0.00452644
Iteration 11/25 | Loss: 0.00452644
Iteration 12/25 | Loss: 0.00452644
Iteration 13/25 | Loss: 0.00452644
Iteration 14/25 | Loss: 0.00452644
Iteration 15/25 | Loss: 0.00452644
Iteration 16/25 | Loss: 0.00452644
Iteration 17/25 | Loss: 0.00452644
Iteration 18/25 | Loss: 0.00452644
Iteration 19/25 | Loss: 0.00452644
Iteration 20/25 | Loss: 0.00452644
Iteration 21/25 | Loss: 0.00452644
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.004526443313807249, 0.004526443313807249, 0.004526443313807249, 0.004526443313807249, 0.004526443313807249]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004526443313807249

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00452644
Iteration 2/1000 | Loss: 0.00539365
Iteration 3/1000 | Loss: 0.00214258
Iteration 4/1000 | Loss: 0.00129382
Iteration 5/1000 | Loss: 0.00095676
Iteration 6/1000 | Loss: 0.00090464
Iteration 7/1000 | Loss: 0.00095816
Iteration 8/1000 | Loss: 0.00086107
Iteration 9/1000 | Loss: 0.00112312
Iteration 10/1000 | Loss: 0.00042931
Iteration 11/1000 | Loss: 0.00082136
Iteration 12/1000 | Loss: 0.00027803
Iteration 13/1000 | Loss: 0.00036714
Iteration 14/1000 | Loss: 0.00017264
Iteration 15/1000 | Loss: 0.00019456
Iteration 16/1000 | Loss: 0.00018121
Iteration 17/1000 | Loss: 0.00067911
Iteration 18/1000 | Loss: 0.00048760
Iteration 19/1000 | Loss: 0.00012087
Iteration 20/1000 | Loss: 0.00019069
Iteration 21/1000 | Loss: 0.00013184
Iteration 22/1000 | Loss: 0.00016769
Iteration 23/1000 | Loss: 0.00040343
Iteration 24/1000 | Loss: 0.00013924
Iteration 25/1000 | Loss: 0.00045327
Iteration 26/1000 | Loss: 0.00021545
Iteration 27/1000 | Loss: 0.00046155
Iteration 28/1000 | Loss: 0.00017229
Iteration 29/1000 | Loss: 0.00032741
Iteration 30/1000 | Loss: 0.00016178
Iteration 31/1000 | Loss: 0.00010548
Iteration 32/1000 | Loss: 0.00012921
Iteration 33/1000 | Loss: 0.00018783
Iteration 34/1000 | Loss: 0.00012263
Iteration 35/1000 | Loss: 0.00040216
Iteration 36/1000 | Loss: 0.00055111
Iteration 37/1000 | Loss: 0.00056658
Iteration 38/1000 | Loss: 0.00024274
Iteration 39/1000 | Loss: 0.00013677
Iteration 40/1000 | Loss: 0.00010116
Iteration 41/1000 | Loss: 0.00010335
Iteration 42/1000 | Loss: 0.00020290
Iteration 43/1000 | Loss: 0.00022490
Iteration 44/1000 | Loss: 0.00009456
Iteration 45/1000 | Loss: 0.00017672
Iteration 46/1000 | Loss: 0.00008908
Iteration 47/1000 | Loss: 0.00008633
Iteration 48/1000 | Loss: 0.00033381
Iteration 49/1000 | Loss: 0.00032207
Iteration 50/1000 | Loss: 0.00013323
Iteration 51/1000 | Loss: 0.00008409
Iteration 52/1000 | Loss: 0.00026715
Iteration 53/1000 | Loss: 0.00020552
Iteration 54/1000 | Loss: 0.00041001
Iteration 55/1000 | Loss: 0.00052464
Iteration 56/1000 | Loss: 0.00063732
Iteration 57/1000 | Loss: 0.00169253
Iteration 58/1000 | Loss: 0.00077976
Iteration 59/1000 | Loss: 0.00027799
Iteration 60/1000 | Loss: 0.00043711
Iteration 61/1000 | Loss: 0.00157497
Iteration 62/1000 | Loss: 0.00049421
Iteration 63/1000 | Loss: 0.00044314
Iteration 64/1000 | Loss: 0.00042061
Iteration 65/1000 | Loss: 0.00011134
Iteration 66/1000 | Loss: 0.00007807
Iteration 67/1000 | Loss: 0.00024782
Iteration 68/1000 | Loss: 0.00031690
Iteration 69/1000 | Loss: 0.00015517
Iteration 70/1000 | Loss: 0.00010925
Iteration 71/1000 | Loss: 0.00009078
Iteration 72/1000 | Loss: 0.00030360
Iteration 73/1000 | Loss: 0.00019380
Iteration 74/1000 | Loss: 0.00015298
Iteration 75/1000 | Loss: 0.00005235
Iteration 76/1000 | Loss: 0.00023000
Iteration 77/1000 | Loss: 0.00005322
Iteration 78/1000 | Loss: 0.00044720
Iteration 79/1000 | Loss: 0.00073258
Iteration 80/1000 | Loss: 0.00087980
Iteration 81/1000 | Loss: 0.00085353
Iteration 82/1000 | Loss: 0.00059784
Iteration 83/1000 | Loss: 0.00018195
Iteration 84/1000 | Loss: 0.00009742
Iteration 85/1000 | Loss: 0.00020636
Iteration 86/1000 | Loss: 0.00014347
Iteration 87/1000 | Loss: 0.00013521
Iteration 88/1000 | Loss: 0.00012046
Iteration 89/1000 | Loss: 0.00005030
Iteration 90/1000 | Loss: 0.00024369
Iteration 91/1000 | Loss: 0.00015813
Iteration 92/1000 | Loss: 0.00011601
Iteration 93/1000 | Loss: 0.00005064
Iteration 94/1000 | Loss: 0.00019781
Iteration 95/1000 | Loss: 0.00023196
Iteration 96/1000 | Loss: 0.00004696
Iteration 97/1000 | Loss: 0.00019910
Iteration 98/1000 | Loss: 0.00019177
Iteration 99/1000 | Loss: 0.00017073
Iteration 100/1000 | Loss: 0.00087762
Iteration 101/1000 | Loss: 0.00119018
Iteration 102/1000 | Loss: 0.00014990
Iteration 103/1000 | Loss: 0.00017475
Iteration 104/1000 | Loss: 0.00019542
Iteration 105/1000 | Loss: 0.00004834
Iteration 106/1000 | Loss: 0.00005431
Iteration 107/1000 | Loss: 0.00004307
Iteration 108/1000 | Loss: 0.00005974
Iteration 109/1000 | Loss: 0.00024370
Iteration 110/1000 | Loss: 0.00017900
Iteration 111/1000 | Loss: 0.00019461
Iteration 112/1000 | Loss: 0.00009771
Iteration 113/1000 | Loss: 0.00016200
Iteration 114/1000 | Loss: 0.00012188
Iteration 115/1000 | Loss: 0.00028374
Iteration 116/1000 | Loss: 0.00004185
Iteration 117/1000 | Loss: 0.00026721
Iteration 118/1000 | Loss: 0.00009292
Iteration 119/1000 | Loss: 0.00012174
Iteration 120/1000 | Loss: 0.00005017
Iteration 121/1000 | Loss: 0.00030873
Iteration 122/1000 | Loss: 0.00036111
Iteration 123/1000 | Loss: 0.00005553
Iteration 124/1000 | Loss: 0.00006828
Iteration 125/1000 | Loss: 0.00009078
Iteration 126/1000 | Loss: 0.00004073
Iteration 127/1000 | Loss: 0.00009190
Iteration 128/1000 | Loss: 0.00003911
Iteration 129/1000 | Loss: 0.00011285
Iteration 130/1000 | Loss: 0.00003824
Iteration 131/1000 | Loss: 0.00009538
Iteration 132/1000 | Loss: 0.00003805
Iteration 133/1000 | Loss: 0.00003768
Iteration 134/1000 | Loss: 0.00003744
Iteration 135/1000 | Loss: 0.00003735
Iteration 136/1000 | Loss: 0.00009403
Iteration 137/1000 | Loss: 0.00004444
Iteration 138/1000 | Loss: 0.00003701
Iteration 139/1000 | Loss: 0.00004933
Iteration 140/1000 | Loss: 0.00003696
Iteration 141/1000 | Loss: 0.00003700
Iteration 142/1000 | Loss: 0.00003700
Iteration 143/1000 | Loss: 0.00032386
Iteration 144/1000 | Loss: 0.00031030
Iteration 145/1000 | Loss: 0.00024823
Iteration 146/1000 | Loss: 0.00005438
Iteration 147/1000 | Loss: 0.00019895
Iteration 148/1000 | Loss: 0.00006852
Iteration 149/1000 | Loss: 0.00003669
Iteration 150/1000 | Loss: 0.00022616
Iteration 151/1000 | Loss: 0.00019864
Iteration 152/1000 | Loss: 0.00040904
Iteration 153/1000 | Loss: 0.00008939
Iteration 154/1000 | Loss: 0.00029251
Iteration 155/1000 | Loss: 0.00006984
Iteration 156/1000 | Loss: 0.00010347
Iteration 157/1000 | Loss: 0.00003491
Iteration 158/1000 | Loss: 0.00003374
Iteration 159/1000 | Loss: 0.00017647
Iteration 160/1000 | Loss: 0.00004341
Iteration 161/1000 | Loss: 0.00014813
Iteration 162/1000 | Loss: 0.00003360
Iteration 163/1000 | Loss: 0.00003270
Iteration 164/1000 | Loss: 0.00003234
Iteration 165/1000 | Loss: 0.00003209
Iteration 166/1000 | Loss: 0.00003198
Iteration 167/1000 | Loss: 0.00003178
Iteration 168/1000 | Loss: 0.00003173
Iteration 169/1000 | Loss: 0.00003167
Iteration 170/1000 | Loss: 0.00003167
Iteration 171/1000 | Loss: 0.00003166
Iteration 172/1000 | Loss: 0.00003166
Iteration 173/1000 | Loss: 0.00003165
Iteration 174/1000 | Loss: 0.00003165
Iteration 175/1000 | Loss: 0.00003164
Iteration 176/1000 | Loss: 0.00003163
Iteration 177/1000 | Loss: 0.00003161
Iteration 178/1000 | Loss: 0.00003161
Iteration 179/1000 | Loss: 0.00003164
Iteration 180/1000 | Loss: 0.00003164
Iteration 181/1000 | Loss: 0.00003163
Iteration 182/1000 | Loss: 0.00003162
Iteration 183/1000 | Loss: 0.00003154
Iteration 184/1000 | Loss: 0.00018568
Iteration 185/1000 | Loss: 0.00003190
Iteration 186/1000 | Loss: 0.00003156
Iteration 187/1000 | Loss: 0.00003150
Iteration 188/1000 | Loss: 0.00003149
Iteration 189/1000 | Loss: 0.00003149
Iteration 190/1000 | Loss: 0.00003148
Iteration 191/1000 | Loss: 0.00003153
Iteration 192/1000 | Loss: 0.00003151
Iteration 193/1000 | Loss: 0.00003151
Iteration 194/1000 | Loss: 0.00003151
Iteration 195/1000 | Loss: 0.00003151
Iteration 196/1000 | Loss: 0.00003148
Iteration 197/1000 | Loss: 0.00003150
Iteration 198/1000 | Loss: 0.00003150
Iteration 199/1000 | Loss: 0.00003148
Iteration 200/1000 | Loss: 0.00003148
Iteration 201/1000 | Loss: 0.00003148
Iteration 202/1000 | Loss: 0.00003148
Iteration 203/1000 | Loss: 0.00003148
Iteration 204/1000 | Loss: 0.00003148
Iteration 205/1000 | Loss: 0.00003148
Iteration 206/1000 | Loss: 0.00003148
Iteration 207/1000 | Loss: 0.00003148
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 207. Stopping optimization.
Last 5 losses: [3.147682946291752e-05, 3.147682946291752e-05, 3.147682946291752e-05, 3.147682946291752e-05, 3.147682946291752e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.147682946291752e-05

Optimization complete. Final v2v error: 3.719743013381958 mm

Highest mean error: 12.081762313842773 mm for frame 132

Lowest mean error: 3.109016180038452 mm for frame 14

Saving results

Total time: 331.5215754508972
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1093/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1093.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1093
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00838498
Iteration 2/25 | Loss: 0.00119581
Iteration 3/25 | Loss: 0.00085567
Iteration 4/25 | Loss: 0.00082628
Iteration 5/25 | Loss: 0.00082096
Iteration 6/25 | Loss: 0.00081936
Iteration 7/25 | Loss: 0.00081931
Iteration 8/25 | Loss: 0.00081931
Iteration 9/25 | Loss: 0.00081931
Iteration 10/25 | Loss: 0.00081931
Iteration 11/25 | Loss: 0.00081931
Iteration 12/25 | Loss: 0.00081931
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008193110697902739, 0.0008193110697902739, 0.0008193110697902739, 0.0008193110697902739, 0.0008193110697902739]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008193110697902739

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35182190
Iteration 2/25 | Loss: 0.00053473
Iteration 3/25 | Loss: 0.00053470
Iteration 4/25 | Loss: 0.00053470
Iteration 5/25 | Loss: 0.00053470
Iteration 6/25 | Loss: 0.00053470
Iteration 7/25 | Loss: 0.00053469
Iteration 8/25 | Loss: 0.00053469
Iteration 9/25 | Loss: 0.00053469
Iteration 10/25 | Loss: 0.00053469
Iteration 11/25 | Loss: 0.00053469
Iteration 12/25 | Loss: 0.00053469
Iteration 13/25 | Loss: 0.00053469
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0005346948164515197, 0.0005346948164515197, 0.0005346948164515197, 0.0005346948164515197, 0.0005346948164515197]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005346948164515197

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00053469
Iteration 2/1000 | Loss: 0.00002624
Iteration 3/1000 | Loss: 0.00001950
Iteration 4/1000 | Loss: 0.00001790
Iteration 5/1000 | Loss: 0.00001702
Iteration 6/1000 | Loss: 0.00001647
Iteration 7/1000 | Loss: 0.00001611
Iteration 8/1000 | Loss: 0.00001584
Iteration 9/1000 | Loss: 0.00001571
Iteration 10/1000 | Loss: 0.00001568
Iteration 11/1000 | Loss: 0.00001567
Iteration 12/1000 | Loss: 0.00001567
Iteration 13/1000 | Loss: 0.00001562
Iteration 14/1000 | Loss: 0.00001561
Iteration 15/1000 | Loss: 0.00001558
Iteration 16/1000 | Loss: 0.00001558
Iteration 17/1000 | Loss: 0.00001557
Iteration 18/1000 | Loss: 0.00001557
Iteration 19/1000 | Loss: 0.00001556
Iteration 20/1000 | Loss: 0.00001553
Iteration 21/1000 | Loss: 0.00001553
Iteration 22/1000 | Loss: 0.00001552
Iteration 23/1000 | Loss: 0.00001552
Iteration 24/1000 | Loss: 0.00001551
Iteration 25/1000 | Loss: 0.00001551
Iteration 26/1000 | Loss: 0.00001550
Iteration 27/1000 | Loss: 0.00001547
Iteration 28/1000 | Loss: 0.00001547
Iteration 29/1000 | Loss: 0.00001546
Iteration 30/1000 | Loss: 0.00001545
Iteration 31/1000 | Loss: 0.00001545
Iteration 32/1000 | Loss: 0.00001545
Iteration 33/1000 | Loss: 0.00001545
Iteration 34/1000 | Loss: 0.00001545
Iteration 35/1000 | Loss: 0.00001545
Iteration 36/1000 | Loss: 0.00001545
Iteration 37/1000 | Loss: 0.00001545
Iteration 38/1000 | Loss: 0.00001544
Iteration 39/1000 | Loss: 0.00001544
Iteration 40/1000 | Loss: 0.00001544
Iteration 41/1000 | Loss: 0.00001542
Iteration 42/1000 | Loss: 0.00001542
Iteration 43/1000 | Loss: 0.00001542
Iteration 44/1000 | Loss: 0.00001541
Iteration 45/1000 | Loss: 0.00001541
Iteration 46/1000 | Loss: 0.00001540
Iteration 47/1000 | Loss: 0.00001540
Iteration 48/1000 | Loss: 0.00001540
Iteration 49/1000 | Loss: 0.00001539
Iteration 50/1000 | Loss: 0.00001539
Iteration 51/1000 | Loss: 0.00001539
Iteration 52/1000 | Loss: 0.00001539
Iteration 53/1000 | Loss: 0.00001538
Iteration 54/1000 | Loss: 0.00001538
Iteration 55/1000 | Loss: 0.00001538
Iteration 56/1000 | Loss: 0.00001537
Iteration 57/1000 | Loss: 0.00001537
Iteration 58/1000 | Loss: 0.00001537
Iteration 59/1000 | Loss: 0.00001537
Iteration 60/1000 | Loss: 0.00001537
Iteration 61/1000 | Loss: 0.00001536
Iteration 62/1000 | Loss: 0.00001536
Iteration 63/1000 | Loss: 0.00001536
Iteration 64/1000 | Loss: 0.00001536
Iteration 65/1000 | Loss: 0.00001536
Iteration 66/1000 | Loss: 0.00001535
Iteration 67/1000 | Loss: 0.00001535
Iteration 68/1000 | Loss: 0.00001535
Iteration 69/1000 | Loss: 0.00001535
Iteration 70/1000 | Loss: 0.00001535
Iteration 71/1000 | Loss: 0.00001535
Iteration 72/1000 | Loss: 0.00001535
Iteration 73/1000 | Loss: 0.00001535
Iteration 74/1000 | Loss: 0.00001535
Iteration 75/1000 | Loss: 0.00001535
Iteration 76/1000 | Loss: 0.00001535
Iteration 77/1000 | Loss: 0.00001535
Iteration 78/1000 | Loss: 0.00001535
Iteration 79/1000 | Loss: 0.00001535
Iteration 80/1000 | Loss: 0.00001535
Iteration 81/1000 | Loss: 0.00001534
Iteration 82/1000 | Loss: 0.00001534
Iteration 83/1000 | Loss: 0.00001534
Iteration 84/1000 | Loss: 0.00001534
Iteration 85/1000 | Loss: 0.00001534
Iteration 86/1000 | Loss: 0.00001534
Iteration 87/1000 | Loss: 0.00001534
Iteration 88/1000 | Loss: 0.00001534
Iteration 89/1000 | Loss: 0.00001534
Iteration 90/1000 | Loss: 0.00001533
Iteration 91/1000 | Loss: 0.00001533
Iteration 92/1000 | Loss: 0.00001533
Iteration 93/1000 | Loss: 0.00001533
Iteration 94/1000 | Loss: 0.00001533
Iteration 95/1000 | Loss: 0.00001533
Iteration 96/1000 | Loss: 0.00001533
Iteration 97/1000 | Loss: 0.00001533
Iteration 98/1000 | Loss: 0.00001533
Iteration 99/1000 | Loss: 0.00001533
Iteration 100/1000 | Loss: 0.00001533
Iteration 101/1000 | Loss: 0.00001532
Iteration 102/1000 | Loss: 0.00001532
Iteration 103/1000 | Loss: 0.00001532
Iteration 104/1000 | Loss: 0.00001532
Iteration 105/1000 | Loss: 0.00001532
Iteration 106/1000 | Loss: 0.00001532
Iteration 107/1000 | Loss: 0.00001532
Iteration 108/1000 | Loss: 0.00001531
Iteration 109/1000 | Loss: 0.00001531
Iteration 110/1000 | Loss: 0.00001531
Iteration 111/1000 | Loss: 0.00001531
Iteration 112/1000 | Loss: 0.00001531
Iteration 113/1000 | Loss: 0.00001531
Iteration 114/1000 | Loss: 0.00001531
Iteration 115/1000 | Loss: 0.00001530
Iteration 116/1000 | Loss: 0.00001530
Iteration 117/1000 | Loss: 0.00001530
Iteration 118/1000 | Loss: 0.00001530
Iteration 119/1000 | Loss: 0.00001530
Iteration 120/1000 | Loss: 0.00001530
Iteration 121/1000 | Loss: 0.00001530
Iteration 122/1000 | Loss: 0.00001530
Iteration 123/1000 | Loss: 0.00001530
Iteration 124/1000 | Loss: 0.00001530
Iteration 125/1000 | Loss: 0.00001530
Iteration 126/1000 | Loss: 0.00001530
Iteration 127/1000 | Loss: 0.00001530
Iteration 128/1000 | Loss: 0.00001530
Iteration 129/1000 | Loss: 0.00001530
Iteration 130/1000 | Loss: 0.00001529
Iteration 131/1000 | Loss: 0.00001529
Iteration 132/1000 | Loss: 0.00001529
Iteration 133/1000 | Loss: 0.00001529
Iteration 134/1000 | Loss: 0.00001529
Iteration 135/1000 | Loss: 0.00001529
Iteration 136/1000 | Loss: 0.00001529
Iteration 137/1000 | Loss: 0.00001529
Iteration 138/1000 | Loss: 0.00001529
Iteration 139/1000 | Loss: 0.00001529
Iteration 140/1000 | Loss: 0.00001529
Iteration 141/1000 | Loss: 0.00001529
Iteration 142/1000 | Loss: 0.00001529
Iteration 143/1000 | Loss: 0.00001529
Iteration 144/1000 | Loss: 0.00001529
Iteration 145/1000 | Loss: 0.00001529
Iteration 146/1000 | Loss: 0.00001529
Iteration 147/1000 | Loss: 0.00001528
Iteration 148/1000 | Loss: 0.00001528
Iteration 149/1000 | Loss: 0.00001528
Iteration 150/1000 | Loss: 0.00001528
Iteration 151/1000 | Loss: 0.00001528
Iteration 152/1000 | Loss: 0.00001528
Iteration 153/1000 | Loss: 0.00001528
Iteration 154/1000 | Loss: 0.00001527
Iteration 155/1000 | Loss: 0.00001527
Iteration 156/1000 | Loss: 0.00001527
Iteration 157/1000 | Loss: 0.00001527
Iteration 158/1000 | Loss: 0.00001527
Iteration 159/1000 | Loss: 0.00001527
Iteration 160/1000 | Loss: 0.00001527
Iteration 161/1000 | Loss: 0.00001527
Iteration 162/1000 | Loss: 0.00001527
Iteration 163/1000 | Loss: 0.00001527
Iteration 164/1000 | Loss: 0.00001527
Iteration 165/1000 | Loss: 0.00001527
Iteration 166/1000 | Loss: 0.00001527
Iteration 167/1000 | Loss: 0.00001527
Iteration 168/1000 | Loss: 0.00001527
Iteration 169/1000 | Loss: 0.00001527
Iteration 170/1000 | Loss: 0.00001527
Iteration 171/1000 | Loss: 0.00001527
Iteration 172/1000 | Loss: 0.00001527
Iteration 173/1000 | Loss: 0.00001527
Iteration 174/1000 | Loss: 0.00001527
Iteration 175/1000 | Loss: 0.00001527
Iteration 176/1000 | Loss: 0.00001527
Iteration 177/1000 | Loss: 0.00001527
Iteration 178/1000 | Loss: 0.00001527
Iteration 179/1000 | Loss: 0.00001527
Iteration 180/1000 | Loss: 0.00001527
Iteration 181/1000 | Loss: 0.00001527
Iteration 182/1000 | Loss: 0.00001527
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 182. Stopping optimization.
Last 5 losses: [1.526931555417832e-05, 1.526931555417832e-05, 1.526931555417832e-05, 1.526931555417832e-05, 1.526931555417832e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.526931555417832e-05

Optimization complete. Final v2v error: 3.3148574829101562 mm

Highest mean error: 3.5341720581054688 mm for frame 158

Lowest mean error: 3.093883514404297 mm for frame 72

Saving results

Total time: 39.444143533706665
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1098/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1098.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1098
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00452102
Iteration 2/25 | Loss: 0.00094956
Iteration 3/25 | Loss: 0.00081088
Iteration 4/25 | Loss: 0.00076685
Iteration 5/25 | Loss: 0.00075316
Iteration 6/25 | Loss: 0.00075112
Iteration 7/25 | Loss: 0.00075040
Iteration 8/25 | Loss: 0.00075035
Iteration 9/25 | Loss: 0.00075035
Iteration 10/25 | Loss: 0.00075035
Iteration 11/25 | Loss: 0.00075035
Iteration 12/25 | Loss: 0.00075035
Iteration 13/25 | Loss: 0.00075035
Iteration 14/25 | Loss: 0.00075035
Iteration 15/25 | Loss: 0.00075035
Iteration 16/25 | Loss: 0.00075035
Iteration 17/25 | Loss: 0.00075035
Iteration 18/25 | Loss: 0.00075035
Iteration 19/25 | Loss: 0.00075035
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0007503516972064972, 0.0007503516972064972, 0.0007503516972064972, 0.0007503516972064972, 0.0007503516972064972]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007503516972064972

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.37583590
Iteration 2/25 | Loss: 0.00048877
Iteration 3/25 | Loss: 0.00048873
Iteration 4/25 | Loss: 0.00048873
Iteration 5/25 | Loss: 0.00048873
Iteration 6/25 | Loss: 0.00048873
Iteration 7/25 | Loss: 0.00048873
Iteration 8/25 | Loss: 0.00048873
Iteration 9/25 | Loss: 0.00048873
Iteration 10/25 | Loss: 0.00048873
Iteration 11/25 | Loss: 0.00048873
Iteration 12/25 | Loss: 0.00048873
Iteration 13/25 | Loss: 0.00048873
Iteration 14/25 | Loss: 0.00048873
Iteration 15/25 | Loss: 0.00048873
Iteration 16/25 | Loss: 0.00048873
Iteration 17/25 | Loss: 0.00048873
Iteration 18/25 | Loss: 0.00048873
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.000488726538605988, 0.000488726538605988, 0.000488726538605988, 0.000488726538605988, 0.000488726538605988]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000488726538605988

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00048873
Iteration 2/1000 | Loss: 0.00003603
Iteration 3/1000 | Loss: 0.00002629
Iteration 4/1000 | Loss: 0.00002110
Iteration 5/1000 | Loss: 0.00001964
Iteration 6/1000 | Loss: 0.00001846
Iteration 7/1000 | Loss: 0.00001777
Iteration 8/1000 | Loss: 0.00001722
Iteration 9/1000 | Loss: 0.00001695
Iteration 10/1000 | Loss: 0.00001679
Iteration 11/1000 | Loss: 0.00001676
Iteration 12/1000 | Loss: 0.00001674
Iteration 13/1000 | Loss: 0.00001674
Iteration 14/1000 | Loss: 0.00001668
Iteration 15/1000 | Loss: 0.00001662
Iteration 16/1000 | Loss: 0.00001658
Iteration 17/1000 | Loss: 0.00001657
Iteration 18/1000 | Loss: 0.00001656
Iteration 19/1000 | Loss: 0.00001655
Iteration 20/1000 | Loss: 0.00001650
Iteration 21/1000 | Loss: 0.00001649
Iteration 22/1000 | Loss: 0.00001649
Iteration 23/1000 | Loss: 0.00001646
Iteration 24/1000 | Loss: 0.00001642
Iteration 25/1000 | Loss: 0.00001641
Iteration 26/1000 | Loss: 0.00001641
Iteration 27/1000 | Loss: 0.00001640
Iteration 28/1000 | Loss: 0.00001639
Iteration 29/1000 | Loss: 0.00001639
Iteration 30/1000 | Loss: 0.00001638
Iteration 31/1000 | Loss: 0.00001638
Iteration 32/1000 | Loss: 0.00001637
Iteration 33/1000 | Loss: 0.00001637
Iteration 34/1000 | Loss: 0.00001636
Iteration 35/1000 | Loss: 0.00001636
Iteration 36/1000 | Loss: 0.00001636
Iteration 37/1000 | Loss: 0.00001635
Iteration 38/1000 | Loss: 0.00001635
Iteration 39/1000 | Loss: 0.00001634
Iteration 40/1000 | Loss: 0.00001633
Iteration 41/1000 | Loss: 0.00001632
Iteration 42/1000 | Loss: 0.00001632
Iteration 43/1000 | Loss: 0.00001631
Iteration 44/1000 | Loss: 0.00001630
Iteration 45/1000 | Loss: 0.00001630
Iteration 46/1000 | Loss: 0.00001630
Iteration 47/1000 | Loss: 0.00001629
Iteration 48/1000 | Loss: 0.00001629
Iteration 49/1000 | Loss: 0.00001629
Iteration 50/1000 | Loss: 0.00001628
Iteration 51/1000 | Loss: 0.00001628
Iteration 52/1000 | Loss: 0.00001628
Iteration 53/1000 | Loss: 0.00001628
Iteration 54/1000 | Loss: 0.00001627
Iteration 55/1000 | Loss: 0.00001626
Iteration 56/1000 | Loss: 0.00001626
Iteration 57/1000 | Loss: 0.00001625
Iteration 58/1000 | Loss: 0.00001625
Iteration 59/1000 | Loss: 0.00001625
Iteration 60/1000 | Loss: 0.00001625
Iteration 61/1000 | Loss: 0.00001625
Iteration 62/1000 | Loss: 0.00001625
Iteration 63/1000 | Loss: 0.00001625
Iteration 64/1000 | Loss: 0.00001625
Iteration 65/1000 | Loss: 0.00001625
Iteration 66/1000 | Loss: 0.00001625
Iteration 67/1000 | Loss: 0.00001625
Iteration 68/1000 | Loss: 0.00001625
Iteration 69/1000 | Loss: 0.00001624
Iteration 70/1000 | Loss: 0.00001624
Iteration 71/1000 | Loss: 0.00001624
Iteration 72/1000 | Loss: 0.00001624
Iteration 73/1000 | Loss: 0.00001623
Iteration 74/1000 | Loss: 0.00001623
Iteration 75/1000 | Loss: 0.00001622
Iteration 76/1000 | Loss: 0.00001622
Iteration 77/1000 | Loss: 0.00001622
Iteration 78/1000 | Loss: 0.00001622
Iteration 79/1000 | Loss: 0.00001622
Iteration 80/1000 | Loss: 0.00001622
Iteration 81/1000 | Loss: 0.00001621
Iteration 82/1000 | Loss: 0.00001621
Iteration 83/1000 | Loss: 0.00001621
Iteration 84/1000 | Loss: 0.00001621
Iteration 85/1000 | Loss: 0.00001621
Iteration 86/1000 | Loss: 0.00001620
Iteration 87/1000 | Loss: 0.00001620
Iteration 88/1000 | Loss: 0.00001620
Iteration 89/1000 | Loss: 0.00001620
Iteration 90/1000 | Loss: 0.00001620
Iteration 91/1000 | Loss: 0.00001619
Iteration 92/1000 | Loss: 0.00001619
Iteration 93/1000 | Loss: 0.00001619
Iteration 94/1000 | Loss: 0.00001619
Iteration 95/1000 | Loss: 0.00001618
Iteration 96/1000 | Loss: 0.00001618
Iteration 97/1000 | Loss: 0.00001618
Iteration 98/1000 | Loss: 0.00001618
Iteration 99/1000 | Loss: 0.00001618
Iteration 100/1000 | Loss: 0.00001618
Iteration 101/1000 | Loss: 0.00001618
Iteration 102/1000 | Loss: 0.00001618
Iteration 103/1000 | Loss: 0.00001618
Iteration 104/1000 | Loss: 0.00001618
Iteration 105/1000 | Loss: 0.00001618
Iteration 106/1000 | Loss: 0.00001617
Iteration 107/1000 | Loss: 0.00001617
Iteration 108/1000 | Loss: 0.00001617
Iteration 109/1000 | Loss: 0.00001617
Iteration 110/1000 | Loss: 0.00001617
Iteration 111/1000 | Loss: 0.00001617
Iteration 112/1000 | Loss: 0.00001617
Iteration 113/1000 | Loss: 0.00001617
Iteration 114/1000 | Loss: 0.00001617
Iteration 115/1000 | Loss: 0.00001616
Iteration 116/1000 | Loss: 0.00001616
Iteration 117/1000 | Loss: 0.00001616
Iteration 118/1000 | Loss: 0.00001616
Iteration 119/1000 | Loss: 0.00001616
Iteration 120/1000 | Loss: 0.00001616
Iteration 121/1000 | Loss: 0.00001616
Iteration 122/1000 | Loss: 0.00001616
Iteration 123/1000 | Loss: 0.00001616
Iteration 124/1000 | Loss: 0.00001616
Iteration 125/1000 | Loss: 0.00001616
Iteration 126/1000 | Loss: 0.00001616
Iteration 127/1000 | Loss: 0.00001616
Iteration 128/1000 | Loss: 0.00001616
Iteration 129/1000 | Loss: 0.00001616
Iteration 130/1000 | Loss: 0.00001616
Iteration 131/1000 | Loss: 0.00001616
Iteration 132/1000 | Loss: 0.00001616
Iteration 133/1000 | Loss: 0.00001616
Iteration 134/1000 | Loss: 0.00001616
Iteration 135/1000 | Loss: 0.00001616
Iteration 136/1000 | Loss: 0.00001616
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 136. Stopping optimization.
Last 5 losses: [1.615958899492398e-05, 1.615958899492398e-05, 1.615958899492398e-05, 1.615958899492398e-05, 1.615958899492398e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.615958899492398e-05

Optimization complete. Final v2v error: 3.409823179244995 mm

Highest mean error: 3.6905839443206787 mm for frame 87

Lowest mean error: 3.2180168628692627 mm for frame 133

Saving results

Total time: 38.52765440940857
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00554347
Iteration 2/25 | Loss: 0.00107612
Iteration 3/25 | Loss: 0.00086422
Iteration 4/25 | Loss: 0.00081793
Iteration 5/25 | Loss: 0.00079081
Iteration 6/25 | Loss: 0.00079781
Iteration 7/25 | Loss: 0.00077734
Iteration 8/25 | Loss: 0.00077285
Iteration 9/25 | Loss: 0.00077012
Iteration 10/25 | Loss: 0.00076977
Iteration 11/25 | Loss: 0.00076968
Iteration 12/25 | Loss: 0.00076966
Iteration 13/25 | Loss: 0.00076966
Iteration 14/25 | Loss: 0.00076966
Iteration 15/25 | Loss: 0.00076966
Iteration 16/25 | Loss: 0.00076966
Iteration 17/25 | Loss: 0.00076965
Iteration 18/25 | Loss: 0.00076965
Iteration 19/25 | Loss: 0.00076965
Iteration 20/25 | Loss: 0.00076965
Iteration 21/25 | Loss: 0.00076965
Iteration 22/25 | Loss: 0.00076965
Iteration 23/25 | Loss: 0.00076965
Iteration 24/25 | Loss: 0.00076965
Iteration 25/25 | Loss: 0.00076965

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.92193973
Iteration 2/25 | Loss: 0.00049965
Iteration 3/25 | Loss: 0.00049963
Iteration 4/25 | Loss: 0.00049963
Iteration 5/25 | Loss: 0.00049963
Iteration 6/25 | Loss: 0.00049963
Iteration 7/25 | Loss: 0.00049963
Iteration 8/25 | Loss: 0.00049963
Iteration 9/25 | Loss: 0.00049963
Iteration 10/25 | Loss: 0.00049963
Iteration 11/25 | Loss: 0.00049963
Iteration 12/25 | Loss: 0.00049963
Iteration 13/25 | Loss: 0.00049963
Iteration 14/25 | Loss: 0.00049963
Iteration 15/25 | Loss: 0.00049963
Iteration 16/25 | Loss: 0.00049963
Iteration 17/25 | Loss: 0.00049963
Iteration 18/25 | Loss: 0.00049963
Iteration 19/25 | Loss: 0.00049963
Iteration 20/25 | Loss: 0.00049963
Iteration 21/25 | Loss: 0.00049963
Iteration 22/25 | Loss: 0.00049963
Iteration 23/25 | Loss: 0.00049963
Iteration 24/25 | Loss: 0.00049963
Iteration 25/25 | Loss: 0.00049963

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049963
Iteration 2/1000 | Loss: 0.00003661
Iteration 3/1000 | Loss: 0.00002633
Iteration 4/1000 | Loss: 0.00002416
Iteration 5/1000 | Loss: 0.00002276
Iteration 6/1000 | Loss: 0.00002170
Iteration 7/1000 | Loss: 0.00002105
Iteration 8/1000 | Loss: 0.00002055
Iteration 9/1000 | Loss: 0.00002023
Iteration 10/1000 | Loss: 0.00001993
Iteration 11/1000 | Loss: 0.00001973
Iteration 12/1000 | Loss: 0.00001958
Iteration 13/1000 | Loss: 0.00001958
Iteration 14/1000 | Loss: 0.00001946
Iteration 15/1000 | Loss: 0.00001943
Iteration 16/1000 | Loss: 0.00001942
Iteration 17/1000 | Loss: 0.00001941
Iteration 18/1000 | Loss: 0.00001941
Iteration 19/1000 | Loss: 0.00001940
Iteration 20/1000 | Loss: 0.00001939
Iteration 21/1000 | Loss: 0.00001936
Iteration 22/1000 | Loss: 0.00001936
Iteration 23/1000 | Loss: 0.00001936
Iteration 24/1000 | Loss: 0.00001934
Iteration 25/1000 | Loss: 0.00001934
Iteration 26/1000 | Loss: 0.00001933
Iteration 27/1000 | Loss: 0.00001933
Iteration 28/1000 | Loss: 0.00001933
Iteration 29/1000 | Loss: 0.00001933
Iteration 30/1000 | Loss: 0.00001933
Iteration 31/1000 | Loss: 0.00001932
Iteration 32/1000 | Loss: 0.00001932
Iteration 33/1000 | Loss: 0.00001932
Iteration 34/1000 | Loss: 0.00001932
Iteration 35/1000 | Loss: 0.00001932
Iteration 36/1000 | Loss: 0.00001931
Iteration 37/1000 | Loss: 0.00001931
Iteration 38/1000 | Loss: 0.00001931
Iteration 39/1000 | Loss: 0.00001931
Iteration 40/1000 | Loss: 0.00001930
Iteration 41/1000 | Loss: 0.00001930
Iteration 42/1000 | Loss: 0.00001929
Iteration 43/1000 | Loss: 0.00001929
Iteration 44/1000 | Loss: 0.00001928
Iteration 45/1000 | Loss: 0.00001928
Iteration 46/1000 | Loss: 0.00001927
Iteration 47/1000 | Loss: 0.00001927
Iteration 48/1000 | Loss: 0.00001925
Iteration 49/1000 | Loss: 0.00001925
Iteration 50/1000 | Loss: 0.00001924
Iteration 51/1000 | Loss: 0.00001924
Iteration 52/1000 | Loss: 0.00001923
Iteration 53/1000 | Loss: 0.00001923
Iteration 54/1000 | Loss: 0.00001923
Iteration 55/1000 | Loss: 0.00001923
Iteration 56/1000 | Loss: 0.00001922
Iteration 57/1000 | Loss: 0.00001922
Iteration 58/1000 | Loss: 0.00001922
Iteration 59/1000 | Loss: 0.00001922
Iteration 60/1000 | Loss: 0.00001922
Iteration 61/1000 | Loss: 0.00001922
Iteration 62/1000 | Loss: 0.00001921
Iteration 63/1000 | Loss: 0.00001921
Iteration 64/1000 | Loss: 0.00001921
Iteration 65/1000 | Loss: 0.00001921
Iteration 66/1000 | Loss: 0.00001921
Iteration 67/1000 | Loss: 0.00001920
Iteration 68/1000 | Loss: 0.00001920
Iteration 69/1000 | Loss: 0.00001920
Iteration 70/1000 | Loss: 0.00001920
Iteration 71/1000 | Loss: 0.00001920
Iteration 72/1000 | Loss: 0.00001920
Iteration 73/1000 | Loss: 0.00001919
Iteration 74/1000 | Loss: 0.00001919
Iteration 75/1000 | Loss: 0.00001919
Iteration 76/1000 | Loss: 0.00001919
Iteration 77/1000 | Loss: 0.00001919
Iteration 78/1000 | Loss: 0.00001919
Iteration 79/1000 | Loss: 0.00001919
Iteration 80/1000 | Loss: 0.00001918
Iteration 81/1000 | Loss: 0.00001918
Iteration 82/1000 | Loss: 0.00001918
Iteration 83/1000 | Loss: 0.00001918
Iteration 84/1000 | Loss: 0.00001918
Iteration 85/1000 | Loss: 0.00001918
Iteration 86/1000 | Loss: 0.00001917
Iteration 87/1000 | Loss: 0.00001917
Iteration 88/1000 | Loss: 0.00001917
Iteration 89/1000 | Loss: 0.00001917
Iteration 90/1000 | Loss: 0.00001917
Iteration 91/1000 | Loss: 0.00001917
Iteration 92/1000 | Loss: 0.00001916
Iteration 93/1000 | Loss: 0.00001916
Iteration 94/1000 | Loss: 0.00001916
Iteration 95/1000 | Loss: 0.00001916
Iteration 96/1000 | Loss: 0.00001916
Iteration 97/1000 | Loss: 0.00001916
Iteration 98/1000 | Loss: 0.00001915
Iteration 99/1000 | Loss: 0.00001915
Iteration 100/1000 | Loss: 0.00001915
Iteration 101/1000 | Loss: 0.00001915
Iteration 102/1000 | Loss: 0.00001915
Iteration 103/1000 | Loss: 0.00001915
Iteration 104/1000 | Loss: 0.00001915
Iteration 105/1000 | Loss: 0.00001914
Iteration 106/1000 | Loss: 0.00001914
Iteration 107/1000 | Loss: 0.00001914
Iteration 108/1000 | Loss: 0.00001914
Iteration 109/1000 | Loss: 0.00001914
Iteration 110/1000 | Loss: 0.00001914
Iteration 111/1000 | Loss: 0.00001914
Iteration 112/1000 | Loss: 0.00001914
Iteration 113/1000 | Loss: 0.00001914
Iteration 114/1000 | Loss: 0.00001914
Iteration 115/1000 | Loss: 0.00001913
Iteration 116/1000 | Loss: 0.00001913
Iteration 117/1000 | Loss: 0.00001913
Iteration 118/1000 | Loss: 0.00001913
Iteration 119/1000 | Loss: 0.00001913
Iteration 120/1000 | Loss: 0.00001913
Iteration 121/1000 | Loss: 0.00001913
Iteration 122/1000 | Loss: 0.00001913
Iteration 123/1000 | Loss: 0.00001913
Iteration 124/1000 | Loss: 0.00001913
Iteration 125/1000 | Loss: 0.00001912
Iteration 126/1000 | Loss: 0.00001912
Iteration 127/1000 | Loss: 0.00001912
Iteration 128/1000 | Loss: 0.00001912
Iteration 129/1000 | Loss: 0.00001912
Iteration 130/1000 | Loss: 0.00001912
Iteration 131/1000 | Loss: 0.00001912
Iteration 132/1000 | Loss: 0.00001912
Iteration 133/1000 | Loss: 0.00001912
Iteration 134/1000 | Loss: 0.00001911
Iteration 135/1000 | Loss: 0.00001911
Iteration 136/1000 | Loss: 0.00001911
Iteration 137/1000 | Loss: 0.00001911
Iteration 138/1000 | Loss: 0.00001911
Iteration 139/1000 | Loss: 0.00001911
Iteration 140/1000 | Loss: 0.00001911
Iteration 141/1000 | Loss: 0.00001911
Iteration 142/1000 | Loss: 0.00001911
Iteration 143/1000 | Loss: 0.00001911
Iteration 144/1000 | Loss: 0.00001911
Iteration 145/1000 | Loss: 0.00001911
Iteration 146/1000 | Loss: 0.00001911
Iteration 147/1000 | Loss: 0.00001911
Iteration 148/1000 | Loss: 0.00001911
Iteration 149/1000 | Loss: 0.00001911
Iteration 150/1000 | Loss: 0.00001911
Iteration 151/1000 | Loss: 0.00001911
Iteration 152/1000 | Loss: 0.00001911
Iteration 153/1000 | Loss: 0.00001911
Iteration 154/1000 | Loss: 0.00001911
Iteration 155/1000 | Loss: 0.00001911
Iteration 156/1000 | Loss: 0.00001911
Iteration 157/1000 | Loss: 0.00001911
Iteration 158/1000 | Loss: 0.00001911
Iteration 159/1000 | Loss: 0.00001911
Iteration 160/1000 | Loss: 0.00001911
Iteration 161/1000 | Loss: 0.00001911
Iteration 162/1000 | Loss: 0.00001911
Iteration 163/1000 | Loss: 0.00001911
Iteration 164/1000 | Loss: 0.00001911
Iteration 165/1000 | Loss: 0.00001911
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 165. Stopping optimization.
Last 5 losses: [1.911040635604877e-05, 1.911040635604877e-05, 1.911040635604877e-05, 1.911040635604877e-05, 1.911040635604877e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.911040635604877e-05

Optimization complete. Final v2v error: 3.6125056743621826 mm

Highest mean error: 4.622580528259277 mm for frame 107

Lowest mean error: 3.0655314922332764 mm for frame 72

Saving results

Total time: 57.15378785133362
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00461529
Iteration 2/25 | Loss: 0.00099474
Iteration 3/25 | Loss: 0.00086576
Iteration 4/25 | Loss: 0.00082917
Iteration 5/25 | Loss: 0.00082389
Iteration 6/25 | Loss: 0.00082322
Iteration 7/25 | Loss: 0.00082322
Iteration 8/25 | Loss: 0.00082322
Iteration 9/25 | Loss: 0.00082322
Iteration 10/25 | Loss: 0.00082322
Iteration 11/25 | Loss: 0.00082322
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0008232223917730153, 0.0008232223917730153, 0.0008232223917730153, 0.0008232223917730153, 0.0008232223917730153]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008232223917730153

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.53589749
Iteration 2/25 | Loss: 0.00052791
Iteration 3/25 | Loss: 0.00052791
Iteration 4/25 | Loss: 0.00052791
Iteration 5/25 | Loss: 0.00052791
Iteration 6/25 | Loss: 0.00052791
Iteration 7/25 | Loss: 0.00052791
Iteration 8/25 | Loss: 0.00052791
Iteration 9/25 | Loss: 0.00052791
Iteration 10/25 | Loss: 0.00052791
Iteration 11/25 | Loss: 0.00052791
Iteration 12/25 | Loss: 0.00052791
Iteration 13/25 | Loss: 0.00052791
Iteration 14/25 | Loss: 0.00052791
Iteration 15/25 | Loss: 0.00052791
Iteration 16/25 | Loss: 0.00052791
Iteration 17/25 | Loss: 0.00052791
Iteration 18/25 | Loss: 0.00052791
Iteration 19/25 | Loss: 0.00052791
Iteration 20/25 | Loss: 0.00052791
Iteration 21/25 | Loss: 0.00052791
Iteration 22/25 | Loss: 0.00052791
Iteration 23/25 | Loss: 0.00052791
Iteration 24/25 | Loss: 0.00052791
Iteration 25/25 | Loss: 0.00052791

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00052791
Iteration 2/1000 | Loss: 0.00004935
Iteration 3/1000 | Loss: 0.00003461
Iteration 4/1000 | Loss: 0.00003197
Iteration 5/1000 | Loss: 0.00003008
Iteration 6/1000 | Loss: 0.00002921
Iteration 7/1000 | Loss: 0.00002834
Iteration 8/1000 | Loss: 0.00002779
Iteration 9/1000 | Loss: 0.00002735
Iteration 10/1000 | Loss: 0.00002705
Iteration 11/1000 | Loss: 0.00002677
Iteration 12/1000 | Loss: 0.00002656
Iteration 13/1000 | Loss: 0.00002650
Iteration 14/1000 | Loss: 0.00002639
Iteration 15/1000 | Loss: 0.00002626
Iteration 16/1000 | Loss: 0.00002622
Iteration 17/1000 | Loss: 0.00002621
Iteration 18/1000 | Loss: 0.00002621
Iteration 19/1000 | Loss: 0.00002616
Iteration 20/1000 | Loss: 0.00002616
Iteration 21/1000 | Loss: 0.00002616
Iteration 22/1000 | Loss: 0.00002616
Iteration 23/1000 | Loss: 0.00002616
Iteration 24/1000 | Loss: 0.00002616
Iteration 25/1000 | Loss: 0.00002614
Iteration 26/1000 | Loss: 0.00002614
Iteration 27/1000 | Loss: 0.00002613
Iteration 28/1000 | Loss: 0.00002612
Iteration 29/1000 | Loss: 0.00002612
Iteration 30/1000 | Loss: 0.00002612
Iteration 31/1000 | Loss: 0.00002612
Iteration 32/1000 | Loss: 0.00002612
Iteration 33/1000 | Loss: 0.00002611
Iteration 34/1000 | Loss: 0.00002611
Iteration 35/1000 | Loss: 0.00002611
Iteration 36/1000 | Loss: 0.00002611
Iteration 37/1000 | Loss: 0.00002611
Iteration 38/1000 | Loss: 0.00002611
Iteration 39/1000 | Loss: 0.00002610
Iteration 40/1000 | Loss: 0.00002610
Iteration 41/1000 | Loss: 0.00002609
Iteration 42/1000 | Loss: 0.00002609
Iteration 43/1000 | Loss: 0.00002609
Iteration 44/1000 | Loss: 0.00002608
Iteration 45/1000 | Loss: 0.00002608
Iteration 46/1000 | Loss: 0.00002608
Iteration 47/1000 | Loss: 0.00002608
Iteration 48/1000 | Loss: 0.00002607
Iteration 49/1000 | Loss: 0.00002607
Iteration 50/1000 | Loss: 0.00002607
Iteration 51/1000 | Loss: 0.00002607
Iteration 52/1000 | Loss: 0.00002606
Iteration 53/1000 | Loss: 0.00002606
Iteration 54/1000 | Loss: 0.00002606
Iteration 55/1000 | Loss: 0.00002606
Iteration 56/1000 | Loss: 0.00002606
Iteration 57/1000 | Loss: 0.00002606
Iteration 58/1000 | Loss: 0.00002606
Iteration 59/1000 | Loss: 0.00002605
Iteration 60/1000 | Loss: 0.00002605
Iteration 61/1000 | Loss: 0.00002605
Iteration 62/1000 | Loss: 0.00002605
Iteration 63/1000 | Loss: 0.00002605
Iteration 64/1000 | Loss: 0.00002605
Iteration 65/1000 | Loss: 0.00002605
Iteration 66/1000 | Loss: 0.00002605
Iteration 67/1000 | Loss: 0.00002604
Iteration 68/1000 | Loss: 0.00002604
Iteration 69/1000 | Loss: 0.00002604
Iteration 70/1000 | Loss: 0.00002604
Iteration 71/1000 | Loss: 0.00002604
Iteration 72/1000 | Loss: 0.00002603
Iteration 73/1000 | Loss: 0.00002603
Iteration 74/1000 | Loss: 0.00002602
Iteration 75/1000 | Loss: 0.00002602
Iteration 76/1000 | Loss: 0.00002602
Iteration 77/1000 | Loss: 0.00002602
Iteration 78/1000 | Loss: 0.00002601
Iteration 79/1000 | Loss: 0.00002601
Iteration 80/1000 | Loss: 0.00002601
Iteration 81/1000 | Loss: 0.00002601
Iteration 82/1000 | Loss: 0.00002600
Iteration 83/1000 | Loss: 0.00002600
Iteration 84/1000 | Loss: 0.00002600
Iteration 85/1000 | Loss: 0.00002599
Iteration 86/1000 | Loss: 0.00002599
Iteration 87/1000 | Loss: 0.00002598
Iteration 88/1000 | Loss: 0.00002598
Iteration 89/1000 | Loss: 0.00002598
Iteration 90/1000 | Loss: 0.00002598
Iteration 91/1000 | Loss: 0.00002598
Iteration 92/1000 | Loss: 0.00002598
Iteration 93/1000 | Loss: 0.00002598
Iteration 94/1000 | Loss: 0.00002597
Iteration 95/1000 | Loss: 0.00002597
Iteration 96/1000 | Loss: 0.00002597
Iteration 97/1000 | Loss: 0.00002597
Iteration 98/1000 | Loss: 0.00002597
Iteration 99/1000 | Loss: 0.00002597
Iteration 100/1000 | Loss: 0.00002597
Iteration 101/1000 | Loss: 0.00002596
Iteration 102/1000 | Loss: 0.00002596
Iteration 103/1000 | Loss: 0.00002596
Iteration 104/1000 | Loss: 0.00002596
Iteration 105/1000 | Loss: 0.00002596
Iteration 106/1000 | Loss: 0.00002596
Iteration 107/1000 | Loss: 0.00002596
Iteration 108/1000 | Loss: 0.00002595
Iteration 109/1000 | Loss: 0.00002595
Iteration 110/1000 | Loss: 0.00002595
Iteration 111/1000 | Loss: 0.00002595
Iteration 112/1000 | Loss: 0.00002595
Iteration 113/1000 | Loss: 0.00002595
Iteration 114/1000 | Loss: 0.00002595
Iteration 115/1000 | Loss: 0.00002595
Iteration 116/1000 | Loss: 0.00002595
Iteration 117/1000 | Loss: 0.00002595
Iteration 118/1000 | Loss: 0.00002595
Iteration 119/1000 | Loss: 0.00002595
Iteration 120/1000 | Loss: 0.00002595
Iteration 121/1000 | Loss: 0.00002595
Iteration 122/1000 | Loss: 0.00002595
Iteration 123/1000 | Loss: 0.00002595
Iteration 124/1000 | Loss: 0.00002595
Iteration 125/1000 | Loss: 0.00002595
Iteration 126/1000 | Loss: 0.00002595
Iteration 127/1000 | Loss: 0.00002595
Iteration 128/1000 | Loss: 0.00002595
Iteration 129/1000 | Loss: 0.00002595
Iteration 130/1000 | Loss: 0.00002595
Iteration 131/1000 | Loss: 0.00002595
Iteration 132/1000 | Loss: 0.00002595
Iteration 133/1000 | Loss: 0.00002595
Iteration 134/1000 | Loss: 0.00002595
Iteration 135/1000 | Loss: 0.00002595
Iteration 136/1000 | Loss: 0.00002595
Iteration 137/1000 | Loss: 0.00002595
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 137. Stopping optimization.
Last 5 losses: [2.594846228021197e-05, 2.594846228021197e-05, 2.594846228021197e-05, 2.594846228021197e-05, 2.594846228021197e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.594846228021197e-05

Optimization complete. Final v2v error: 4.232341766357422 mm

Highest mean error: 4.634597301483154 mm for frame 31

Lowest mean error: 3.9759409427642822 mm for frame 72

Saving results

Total time: 39.15720009803772
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1097/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1097.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1097
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00816629
Iteration 2/25 | Loss: 0.00133164
Iteration 3/25 | Loss: 0.00091117
Iteration 4/25 | Loss: 0.00078944
Iteration 5/25 | Loss: 0.00076307
Iteration 6/25 | Loss: 0.00075713
Iteration 7/25 | Loss: 0.00075645
Iteration 8/25 | Loss: 0.00075645
Iteration 9/25 | Loss: 0.00075645
Iteration 10/25 | Loss: 0.00075645
Iteration 11/25 | Loss: 0.00075645
Iteration 12/25 | Loss: 0.00075645
Iteration 13/25 | Loss: 0.00075645
Iteration 14/25 | Loss: 0.00075645
Iteration 15/25 | Loss: 0.00075645
Iteration 16/25 | Loss: 0.00075645
Iteration 17/25 | Loss: 0.00075645
Iteration 18/25 | Loss: 0.00075645
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007564489496871829, 0.0007564489496871829, 0.0007564489496871829, 0.0007564489496871829, 0.0007564489496871829]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007564489496871829

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50469637
Iteration 2/25 | Loss: 0.00051211
Iteration 3/25 | Loss: 0.00051210
Iteration 4/25 | Loss: 0.00051210
Iteration 5/25 | Loss: 0.00051210
Iteration 6/25 | Loss: 0.00051210
Iteration 7/25 | Loss: 0.00051210
Iteration 8/25 | Loss: 0.00051210
Iteration 9/25 | Loss: 0.00051210
Iteration 10/25 | Loss: 0.00051210
Iteration 11/25 | Loss: 0.00051210
Iteration 12/25 | Loss: 0.00051210
Iteration 13/25 | Loss: 0.00051210
Iteration 14/25 | Loss: 0.00051210
Iteration 15/25 | Loss: 0.00051210
Iteration 16/25 | Loss: 0.00051210
Iteration 17/25 | Loss: 0.00051210
Iteration 18/25 | Loss: 0.00051210
Iteration 19/25 | Loss: 0.00051210
Iteration 20/25 | Loss: 0.00051210
Iteration 21/25 | Loss: 0.00051210
Iteration 22/25 | Loss: 0.00051210
Iteration 23/25 | Loss: 0.00051210
Iteration 24/25 | Loss: 0.00051210
Iteration 25/25 | Loss: 0.00051210
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0005121006979607046, 0.0005121006979607046, 0.0005121006979607046, 0.0005121006979607046, 0.0005121006979607046]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005121006979607046

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00051210
Iteration 2/1000 | Loss: 0.00002902
Iteration 3/1000 | Loss: 0.00002137
Iteration 4/1000 | Loss: 0.00001908
Iteration 5/1000 | Loss: 0.00001741
Iteration 6/1000 | Loss: 0.00001619
Iteration 7/1000 | Loss: 0.00001549
Iteration 8/1000 | Loss: 0.00001493
Iteration 9/1000 | Loss: 0.00001466
Iteration 10/1000 | Loss: 0.00001439
Iteration 11/1000 | Loss: 0.00001421
Iteration 12/1000 | Loss: 0.00001393
Iteration 13/1000 | Loss: 0.00001386
Iteration 14/1000 | Loss: 0.00001383
Iteration 15/1000 | Loss: 0.00001378
Iteration 16/1000 | Loss: 0.00001375
Iteration 17/1000 | Loss: 0.00001374
Iteration 18/1000 | Loss: 0.00001374
Iteration 19/1000 | Loss: 0.00001372
Iteration 20/1000 | Loss: 0.00001372
Iteration 21/1000 | Loss: 0.00001371
Iteration 22/1000 | Loss: 0.00001370
Iteration 23/1000 | Loss: 0.00001369
Iteration 24/1000 | Loss: 0.00001369
Iteration 25/1000 | Loss: 0.00001368
Iteration 26/1000 | Loss: 0.00001368
Iteration 27/1000 | Loss: 0.00001367
Iteration 28/1000 | Loss: 0.00001366
Iteration 29/1000 | Loss: 0.00001365
Iteration 30/1000 | Loss: 0.00001365
Iteration 31/1000 | Loss: 0.00001364
Iteration 32/1000 | Loss: 0.00001364
Iteration 33/1000 | Loss: 0.00001364
Iteration 34/1000 | Loss: 0.00001364
Iteration 35/1000 | Loss: 0.00001363
Iteration 36/1000 | Loss: 0.00001363
Iteration 37/1000 | Loss: 0.00001363
Iteration 38/1000 | Loss: 0.00001363
Iteration 39/1000 | Loss: 0.00001362
Iteration 40/1000 | Loss: 0.00001362
Iteration 41/1000 | Loss: 0.00001362
Iteration 42/1000 | Loss: 0.00001361
Iteration 43/1000 | Loss: 0.00001361
Iteration 44/1000 | Loss: 0.00001361
Iteration 45/1000 | Loss: 0.00001360
Iteration 46/1000 | Loss: 0.00001360
Iteration 47/1000 | Loss: 0.00001359
Iteration 48/1000 | Loss: 0.00001358
Iteration 49/1000 | Loss: 0.00001358
Iteration 50/1000 | Loss: 0.00001357
Iteration 51/1000 | Loss: 0.00001357
Iteration 52/1000 | Loss: 0.00001357
Iteration 53/1000 | Loss: 0.00001357
Iteration 54/1000 | Loss: 0.00001356
Iteration 55/1000 | Loss: 0.00001356
Iteration 56/1000 | Loss: 0.00001356
Iteration 57/1000 | Loss: 0.00001356
Iteration 58/1000 | Loss: 0.00001356
Iteration 59/1000 | Loss: 0.00001355
Iteration 60/1000 | Loss: 0.00001355
Iteration 61/1000 | Loss: 0.00001355
Iteration 62/1000 | Loss: 0.00001354
Iteration 63/1000 | Loss: 0.00001354
Iteration 64/1000 | Loss: 0.00001354
Iteration 65/1000 | Loss: 0.00001353
Iteration 66/1000 | Loss: 0.00001353
Iteration 67/1000 | Loss: 0.00001353
Iteration 68/1000 | Loss: 0.00001352
Iteration 69/1000 | Loss: 0.00001352
Iteration 70/1000 | Loss: 0.00001352
Iteration 71/1000 | Loss: 0.00001350
Iteration 72/1000 | Loss: 0.00001350
Iteration 73/1000 | Loss: 0.00001350
Iteration 74/1000 | Loss: 0.00001350
Iteration 75/1000 | Loss: 0.00001350
Iteration 76/1000 | Loss: 0.00001350
Iteration 77/1000 | Loss: 0.00001350
Iteration 78/1000 | Loss: 0.00001349
Iteration 79/1000 | Loss: 0.00001349
Iteration 80/1000 | Loss: 0.00001349
Iteration 81/1000 | Loss: 0.00001348
Iteration 82/1000 | Loss: 0.00001348
Iteration 83/1000 | Loss: 0.00001347
Iteration 84/1000 | Loss: 0.00001347
Iteration 85/1000 | Loss: 0.00001347
Iteration 86/1000 | Loss: 0.00001347
Iteration 87/1000 | Loss: 0.00001347
Iteration 88/1000 | Loss: 0.00001347
Iteration 89/1000 | Loss: 0.00001347
Iteration 90/1000 | Loss: 0.00001347
Iteration 91/1000 | Loss: 0.00001347
Iteration 92/1000 | Loss: 0.00001346
Iteration 93/1000 | Loss: 0.00001346
Iteration 94/1000 | Loss: 0.00001345
Iteration 95/1000 | Loss: 0.00001345
Iteration 96/1000 | Loss: 0.00001345
Iteration 97/1000 | Loss: 0.00001344
Iteration 98/1000 | Loss: 0.00001344
Iteration 99/1000 | Loss: 0.00001344
Iteration 100/1000 | Loss: 0.00001344
Iteration 101/1000 | Loss: 0.00001344
Iteration 102/1000 | Loss: 0.00001343
Iteration 103/1000 | Loss: 0.00001343
Iteration 104/1000 | Loss: 0.00001343
Iteration 105/1000 | Loss: 0.00001343
Iteration 106/1000 | Loss: 0.00001343
Iteration 107/1000 | Loss: 0.00001343
Iteration 108/1000 | Loss: 0.00001343
Iteration 109/1000 | Loss: 0.00001343
Iteration 110/1000 | Loss: 0.00001343
Iteration 111/1000 | Loss: 0.00001343
Iteration 112/1000 | Loss: 0.00001343
Iteration 113/1000 | Loss: 0.00001343
Iteration 114/1000 | Loss: 0.00001343
Iteration 115/1000 | Loss: 0.00001343
Iteration 116/1000 | Loss: 0.00001343
Iteration 117/1000 | Loss: 0.00001343
Iteration 118/1000 | Loss: 0.00001343
Iteration 119/1000 | Loss: 0.00001343
Iteration 120/1000 | Loss: 0.00001343
Iteration 121/1000 | Loss: 0.00001343
Iteration 122/1000 | Loss: 0.00001343
Iteration 123/1000 | Loss: 0.00001343
Iteration 124/1000 | Loss: 0.00001343
Iteration 125/1000 | Loss: 0.00001343
Iteration 126/1000 | Loss: 0.00001343
Iteration 127/1000 | Loss: 0.00001343
Iteration 128/1000 | Loss: 0.00001343
Iteration 129/1000 | Loss: 0.00001343
Iteration 130/1000 | Loss: 0.00001343
Iteration 131/1000 | Loss: 0.00001343
Iteration 132/1000 | Loss: 0.00001343
Iteration 133/1000 | Loss: 0.00001343
Iteration 134/1000 | Loss: 0.00001343
Iteration 135/1000 | Loss: 0.00001343
Iteration 136/1000 | Loss: 0.00001343
Iteration 137/1000 | Loss: 0.00001343
Iteration 138/1000 | Loss: 0.00001343
Iteration 139/1000 | Loss: 0.00001343
Iteration 140/1000 | Loss: 0.00001343
Iteration 141/1000 | Loss: 0.00001343
Iteration 142/1000 | Loss: 0.00001343
Iteration 143/1000 | Loss: 0.00001343
Iteration 144/1000 | Loss: 0.00001343
Iteration 145/1000 | Loss: 0.00001343
Iteration 146/1000 | Loss: 0.00001343
Iteration 147/1000 | Loss: 0.00001343
Iteration 148/1000 | Loss: 0.00001343
Iteration 149/1000 | Loss: 0.00001343
Iteration 150/1000 | Loss: 0.00001343
Iteration 151/1000 | Loss: 0.00001343
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 151. Stopping optimization.
Last 5 losses: [1.3427043995761778e-05, 1.3427043995761778e-05, 1.3427043995761778e-05, 1.3427043995761778e-05, 1.3427043995761778e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3427043995761778e-05

Optimization complete. Final v2v error: 3.1101624965667725 mm

Highest mean error: 3.5199904441833496 mm for frame 196

Lowest mean error: 2.833244562149048 mm for frame 123

Saving results

Total time: 45.72109866142273
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1062/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1062.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1062
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00515657
Iteration 2/25 | Loss: 0.00106997
Iteration 3/25 | Loss: 0.00082815
Iteration 4/25 | Loss: 0.00078518
Iteration 5/25 | Loss: 0.00077173
Iteration 6/25 | Loss: 0.00076833
Iteration 7/25 | Loss: 0.00076732
Iteration 8/25 | Loss: 0.00076703
Iteration 9/25 | Loss: 0.00076703
Iteration 10/25 | Loss: 0.00076703
Iteration 11/25 | Loss: 0.00076703
Iteration 12/25 | Loss: 0.00076703
Iteration 13/25 | Loss: 0.00076703
Iteration 14/25 | Loss: 0.00076703
Iteration 15/25 | Loss: 0.00076703
Iteration 16/25 | Loss: 0.00076703
Iteration 17/25 | Loss: 0.00076703
Iteration 18/25 | Loss: 0.00076703
Iteration 19/25 | Loss: 0.00076703
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.000767033314332366, 0.000767033314332366, 0.000767033314332366, 0.000767033314332366, 0.000767033314332366]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000767033314332366

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.54995060
Iteration 2/25 | Loss: 0.00060730
Iteration 3/25 | Loss: 0.00060730
Iteration 4/25 | Loss: 0.00060730
Iteration 5/25 | Loss: 0.00060730
Iteration 6/25 | Loss: 0.00060730
Iteration 7/25 | Loss: 0.00060730
Iteration 8/25 | Loss: 0.00060730
Iteration 9/25 | Loss: 0.00060730
Iteration 10/25 | Loss: 0.00060730
Iteration 11/25 | Loss: 0.00060730
Iteration 12/25 | Loss: 0.00060730
Iteration 13/25 | Loss: 0.00060730
Iteration 14/25 | Loss: 0.00060730
Iteration 15/25 | Loss: 0.00060730
Iteration 16/25 | Loss: 0.00060730
Iteration 17/25 | Loss: 0.00060730
Iteration 18/25 | Loss: 0.00060730
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006073009571991861, 0.0006073009571991861, 0.0006073009571991861, 0.0006073009571991861, 0.0006073009571991861]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006073009571991861

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00060730
Iteration 2/1000 | Loss: 0.00003021
Iteration 3/1000 | Loss: 0.00002089
Iteration 4/1000 | Loss: 0.00001741
Iteration 5/1000 | Loss: 0.00001602
Iteration 6/1000 | Loss: 0.00001530
Iteration 7/1000 | Loss: 0.00001486
Iteration 8/1000 | Loss: 0.00001454
Iteration 9/1000 | Loss: 0.00001427
Iteration 10/1000 | Loss: 0.00001412
Iteration 11/1000 | Loss: 0.00001394
Iteration 12/1000 | Loss: 0.00001388
Iteration 13/1000 | Loss: 0.00001377
Iteration 14/1000 | Loss: 0.00001373
Iteration 15/1000 | Loss: 0.00001372
Iteration 16/1000 | Loss: 0.00001371
Iteration 17/1000 | Loss: 0.00001369
Iteration 18/1000 | Loss: 0.00001363
Iteration 19/1000 | Loss: 0.00001362
Iteration 20/1000 | Loss: 0.00001360
Iteration 21/1000 | Loss: 0.00001357
Iteration 22/1000 | Loss: 0.00001355
Iteration 23/1000 | Loss: 0.00001354
Iteration 24/1000 | Loss: 0.00001353
Iteration 25/1000 | Loss: 0.00001352
Iteration 26/1000 | Loss: 0.00001351
Iteration 27/1000 | Loss: 0.00001350
Iteration 28/1000 | Loss: 0.00001349
Iteration 29/1000 | Loss: 0.00001348
Iteration 30/1000 | Loss: 0.00001348
Iteration 31/1000 | Loss: 0.00001347
Iteration 32/1000 | Loss: 0.00001347
Iteration 33/1000 | Loss: 0.00001347
Iteration 34/1000 | Loss: 0.00001346
Iteration 35/1000 | Loss: 0.00001346
Iteration 36/1000 | Loss: 0.00001345
Iteration 37/1000 | Loss: 0.00001345
Iteration 38/1000 | Loss: 0.00001344
Iteration 39/1000 | Loss: 0.00001344
Iteration 40/1000 | Loss: 0.00001343
Iteration 41/1000 | Loss: 0.00001343
Iteration 42/1000 | Loss: 0.00001343
Iteration 43/1000 | Loss: 0.00001342
Iteration 44/1000 | Loss: 0.00001342
Iteration 45/1000 | Loss: 0.00001341
Iteration 46/1000 | Loss: 0.00001341
Iteration 47/1000 | Loss: 0.00001340
Iteration 48/1000 | Loss: 0.00001340
Iteration 49/1000 | Loss: 0.00001340
Iteration 50/1000 | Loss: 0.00001339
Iteration 51/1000 | Loss: 0.00001339
Iteration 52/1000 | Loss: 0.00001338
Iteration 53/1000 | Loss: 0.00001338
Iteration 54/1000 | Loss: 0.00001338
Iteration 55/1000 | Loss: 0.00001337
Iteration 56/1000 | Loss: 0.00001337
Iteration 57/1000 | Loss: 0.00001337
Iteration 58/1000 | Loss: 0.00001337
Iteration 59/1000 | Loss: 0.00001337
Iteration 60/1000 | Loss: 0.00001336
Iteration 61/1000 | Loss: 0.00001336
Iteration 62/1000 | Loss: 0.00001336
Iteration 63/1000 | Loss: 0.00001336
Iteration 64/1000 | Loss: 0.00001336
Iteration 65/1000 | Loss: 0.00001336
Iteration 66/1000 | Loss: 0.00001335
Iteration 67/1000 | Loss: 0.00001335
Iteration 68/1000 | Loss: 0.00001335
Iteration 69/1000 | Loss: 0.00001335
Iteration 70/1000 | Loss: 0.00001334
Iteration 71/1000 | Loss: 0.00001334
Iteration 72/1000 | Loss: 0.00001334
Iteration 73/1000 | Loss: 0.00001334
Iteration 74/1000 | Loss: 0.00001334
Iteration 75/1000 | Loss: 0.00001334
Iteration 76/1000 | Loss: 0.00001334
Iteration 77/1000 | Loss: 0.00001334
Iteration 78/1000 | Loss: 0.00001334
Iteration 79/1000 | Loss: 0.00001333
Iteration 80/1000 | Loss: 0.00001333
Iteration 81/1000 | Loss: 0.00001333
Iteration 82/1000 | Loss: 0.00001333
Iteration 83/1000 | Loss: 0.00001333
Iteration 84/1000 | Loss: 0.00001333
Iteration 85/1000 | Loss: 0.00001332
Iteration 86/1000 | Loss: 0.00001332
Iteration 87/1000 | Loss: 0.00001332
Iteration 88/1000 | Loss: 0.00001332
Iteration 89/1000 | Loss: 0.00001331
Iteration 90/1000 | Loss: 0.00001331
Iteration 91/1000 | Loss: 0.00001331
Iteration 92/1000 | Loss: 0.00001331
Iteration 93/1000 | Loss: 0.00001331
Iteration 94/1000 | Loss: 0.00001331
Iteration 95/1000 | Loss: 0.00001331
Iteration 96/1000 | Loss: 0.00001330
Iteration 97/1000 | Loss: 0.00001330
Iteration 98/1000 | Loss: 0.00001330
Iteration 99/1000 | Loss: 0.00001330
Iteration 100/1000 | Loss: 0.00001330
Iteration 101/1000 | Loss: 0.00001329
Iteration 102/1000 | Loss: 0.00001329
Iteration 103/1000 | Loss: 0.00001329
Iteration 104/1000 | Loss: 0.00001329
Iteration 105/1000 | Loss: 0.00001329
Iteration 106/1000 | Loss: 0.00001329
Iteration 107/1000 | Loss: 0.00001329
Iteration 108/1000 | Loss: 0.00001329
Iteration 109/1000 | Loss: 0.00001329
Iteration 110/1000 | Loss: 0.00001329
Iteration 111/1000 | Loss: 0.00001329
Iteration 112/1000 | Loss: 0.00001329
Iteration 113/1000 | Loss: 0.00001329
Iteration 114/1000 | Loss: 0.00001329
Iteration 115/1000 | Loss: 0.00001329
Iteration 116/1000 | Loss: 0.00001329
Iteration 117/1000 | Loss: 0.00001329
Iteration 118/1000 | Loss: 0.00001329
Iteration 119/1000 | Loss: 0.00001328
Iteration 120/1000 | Loss: 0.00001328
Iteration 121/1000 | Loss: 0.00001328
Iteration 122/1000 | Loss: 0.00001328
Iteration 123/1000 | Loss: 0.00001328
Iteration 124/1000 | Loss: 0.00001328
Iteration 125/1000 | Loss: 0.00001328
Iteration 126/1000 | Loss: 0.00001328
Iteration 127/1000 | Loss: 0.00001327
Iteration 128/1000 | Loss: 0.00001327
Iteration 129/1000 | Loss: 0.00001327
Iteration 130/1000 | Loss: 0.00001327
Iteration 131/1000 | Loss: 0.00001327
Iteration 132/1000 | Loss: 0.00001327
Iteration 133/1000 | Loss: 0.00001327
Iteration 134/1000 | Loss: 0.00001327
Iteration 135/1000 | Loss: 0.00001327
Iteration 136/1000 | Loss: 0.00001327
Iteration 137/1000 | Loss: 0.00001327
Iteration 138/1000 | Loss: 0.00001327
Iteration 139/1000 | Loss: 0.00001327
Iteration 140/1000 | Loss: 0.00001327
Iteration 141/1000 | Loss: 0.00001327
Iteration 142/1000 | Loss: 0.00001327
Iteration 143/1000 | Loss: 0.00001327
Iteration 144/1000 | Loss: 0.00001327
Iteration 145/1000 | Loss: 0.00001327
Iteration 146/1000 | Loss: 0.00001327
Iteration 147/1000 | Loss: 0.00001327
Iteration 148/1000 | Loss: 0.00001327
Iteration 149/1000 | Loss: 0.00001327
Iteration 150/1000 | Loss: 0.00001327
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 150. Stopping optimization.
Last 5 losses: [1.3272664546093438e-05, 1.3272664546093438e-05, 1.3272664546093438e-05, 1.3272664546093438e-05, 1.3272664546093438e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3272664546093438e-05

Optimization complete. Final v2v error: 3.0842831134796143 mm

Highest mean error: 3.3979861736297607 mm for frame 124

Lowest mean error: 2.7875802516937256 mm for frame 91

Saving results

Total time: 40.99734306335449
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1050/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1050.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1050
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00782693
Iteration 2/25 | Loss: 0.00089261
Iteration 3/25 | Loss: 0.00078371
Iteration 4/25 | Loss: 0.00075760
Iteration 5/25 | Loss: 0.00074873
Iteration 6/25 | Loss: 0.00074745
Iteration 7/25 | Loss: 0.00074699
Iteration 8/25 | Loss: 0.00074693
Iteration 9/25 | Loss: 0.00074693
Iteration 10/25 | Loss: 0.00074693
Iteration 11/25 | Loss: 0.00074693
Iteration 12/25 | Loss: 0.00074693
Iteration 13/25 | Loss: 0.00074693
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007469334523193538, 0.0007469334523193538, 0.0007469334523193538, 0.0007469334523193538, 0.0007469334523193538]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007469334523193538

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47063279
Iteration 2/25 | Loss: 0.00047011
Iteration 3/25 | Loss: 0.00047011
Iteration 4/25 | Loss: 0.00047010
Iteration 5/25 | Loss: 0.00047010
Iteration 6/25 | Loss: 0.00047010
Iteration 7/25 | Loss: 0.00047010
Iteration 8/25 | Loss: 0.00047010
Iteration 9/25 | Loss: 0.00047010
Iteration 10/25 | Loss: 0.00047010
Iteration 11/25 | Loss: 0.00047010
Iteration 12/25 | Loss: 0.00047010
Iteration 13/25 | Loss: 0.00047010
Iteration 14/25 | Loss: 0.00047010
Iteration 15/25 | Loss: 0.00047010
Iteration 16/25 | Loss: 0.00047010
Iteration 17/25 | Loss: 0.00047010
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004701019497588277, 0.0004701019497588277, 0.0004701019497588277, 0.0004701019497588277, 0.0004701019497588277]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004701019497588277

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047010
Iteration 2/1000 | Loss: 0.00003911
Iteration 3/1000 | Loss: 0.00002481
Iteration 4/1000 | Loss: 0.00002114
Iteration 5/1000 | Loss: 0.00002010
Iteration 6/1000 | Loss: 0.00001935
Iteration 7/1000 | Loss: 0.00001897
Iteration 8/1000 | Loss: 0.00001844
Iteration 9/1000 | Loss: 0.00001812
Iteration 10/1000 | Loss: 0.00001786
Iteration 11/1000 | Loss: 0.00001765
Iteration 12/1000 | Loss: 0.00001745
Iteration 13/1000 | Loss: 0.00001739
Iteration 14/1000 | Loss: 0.00001733
Iteration 15/1000 | Loss: 0.00001726
Iteration 16/1000 | Loss: 0.00001726
Iteration 17/1000 | Loss: 0.00001725
Iteration 18/1000 | Loss: 0.00001723
Iteration 19/1000 | Loss: 0.00001722
Iteration 20/1000 | Loss: 0.00001721
Iteration 21/1000 | Loss: 0.00001720
Iteration 22/1000 | Loss: 0.00001720
Iteration 23/1000 | Loss: 0.00001716
Iteration 24/1000 | Loss: 0.00001711
Iteration 25/1000 | Loss: 0.00001711
Iteration 26/1000 | Loss: 0.00001710
Iteration 27/1000 | Loss: 0.00001709
Iteration 28/1000 | Loss: 0.00001709
Iteration 29/1000 | Loss: 0.00001708
Iteration 30/1000 | Loss: 0.00001707
Iteration 31/1000 | Loss: 0.00001707
Iteration 32/1000 | Loss: 0.00001707
Iteration 33/1000 | Loss: 0.00001706
Iteration 34/1000 | Loss: 0.00001706
Iteration 35/1000 | Loss: 0.00001706
Iteration 36/1000 | Loss: 0.00001705
Iteration 37/1000 | Loss: 0.00001705
Iteration 38/1000 | Loss: 0.00001704
Iteration 39/1000 | Loss: 0.00001703
Iteration 40/1000 | Loss: 0.00001703
Iteration 41/1000 | Loss: 0.00001703
Iteration 42/1000 | Loss: 0.00001703
Iteration 43/1000 | Loss: 0.00001703
Iteration 44/1000 | Loss: 0.00001703
Iteration 45/1000 | Loss: 0.00001703
Iteration 46/1000 | Loss: 0.00001703
Iteration 47/1000 | Loss: 0.00001703
Iteration 48/1000 | Loss: 0.00001703
Iteration 49/1000 | Loss: 0.00001702
Iteration 50/1000 | Loss: 0.00001702
Iteration 51/1000 | Loss: 0.00001702
Iteration 52/1000 | Loss: 0.00001702
Iteration 53/1000 | Loss: 0.00001702
Iteration 54/1000 | Loss: 0.00001702
Iteration 55/1000 | Loss: 0.00001701
Iteration 56/1000 | Loss: 0.00001700
Iteration 57/1000 | Loss: 0.00001700
Iteration 58/1000 | Loss: 0.00001699
Iteration 59/1000 | Loss: 0.00001699
Iteration 60/1000 | Loss: 0.00001699
Iteration 61/1000 | Loss: 0.00001699
Iteration 62/1000 | Loss: 0.00001699
Iteration 63/1000 | Loss: 0.00001699
Iteration 64/1000 | Loss: 0.00001698
Iteration 65/1000 | Loss: 0.00001698
Iteration 66/1000 | Loss: 0.00001698
Iteration 67/1000 | Loss: 0.00001698
Iteration 68/1000 | Loss: 0.00001698
Iteration 69/1000 | Loss: 0.00001698
Iteration 70/1000 | Loss: 0.00001698
Iteration 71/1000 | Loss: 0.00001698
Iteration 72/1000 | Loss: 0.00001698
Iteration 73/1000 | Loss: 0.00001698
Iteration 74/1000 | Loss: 0.00001698
Iteration 75/1000 | Loss: 0.00001698
Iteration 76/1000 | Loss: 0.00001698
Iteration 77/1000 | Loss: 0.00001698
Iteration 78/1000 | Loss: 0.00001698
Iteration 79/1000 | Loss: 0.00001698
Iteration 80/1000 | Loss: 0.00001698
Iteration 81/1000 | Loss: 0.00001698
Iteration 82/1000 | Loss: 0.00001698
Iteration 83/1000 | Loss: 0.00001698
Iteration 84/1000 | Loss: 0.00001697
Iteration 85/1000 | Loss: 0.00001697
Iteration 86/1000 | Loss: 0.00001697
Iteration 87/1000 | Loss: 0.00001697
Iteration 88/1000 | Loss: 0.00001697
Iteration 89/1000 | Loss: 0.00001697
Iteration 90/1000 | Loss: 0.00001697
Iteration 91/1000 | Loss: 0.00001697
Iteration 92/1000 | Loss: 0.00001697
Iteration 93/1000 | Loss: 0.00001697
Iteration 94/1000 | Loss: 0.00001697
Iteration 95/1000 | Loss: 0.00001697
Iteration 96/1000 | Loss: 0.00001697
Iteration 97/1000 | Loss: 0.00001697
Iteration 98/1000 | Loss: 0.00001697
Iteration 99/1000 | Loss: 0.00001697
Iteration 100/1000 | Loss: 0.00001696
Iteration 101/1000 | Loss: 0.00001696
Iteration 102/1000 | Loss: 0.00001696
Iteration 103/1000 | Loss: 0.00001696
Iteration 104/1000 | Loss: 0.00001696
Iteration 105/1000 | Loss: 0.00001696
Iteration 106/1000 | Loss: 0.00001696
Iteration 107/1000 | Loss: 0.00001696
Iteration 108/1000 | Loss: 0.00001696
Iteration 109/1000 | Loss: 0.00001696
Iteration 110/1000 | Loss: 0.00001696
Iteration 111/1000 | Loss: 0.00001696
Iteration 112/1000 | Loss: 0.00001696
Iteration 113/1000 | Loss: 0.00001696
Iteration 114/1000 | Loss: 0.00001696
Iteration 115/1000 | Loss: 0.00001696
Iteration 116/1000 | Loss: 0.00001696
Iteration 117/1000 | Loss: 0.00001696
Iteration 118/1000 | Loss: 0.00001696
Iteration 119/1000 | Loss: 0.00001695
Iteration 120/1000 | Loss: 0.00001695
Iteration 121/1000 | Loss: 0.00001695
Iteration 122/1000 | Loss: 0.00001695
Iteration 123/1000 | Loss: 0.00001695
Iteration 124/1000 | Loss: 0.00001695
Iteration 125/1000 | Loss: 0.00001695
Iteration 126/1000 | Loss: 0.00001695
Iteration 127/1000 | Loss: 0.00001695
Iteration 128/1000 | Loss: 0.00001695
Iteration 129/1000 | Loss: 0.00001695
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 129. Stopping optimization.
Last 5 losses: [1.6952275473158807e-05, 1.6952275473158807e-05, 1.6952275473158807e-05, 1.6952275473158807e-05, 1.6952275473158807e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6952275473158807e-05

Optimization complete. Final v2v error: 3.508265256881714 mm

Highest mean error: 3.797822952270508 mm for frame 98

Lowest mean error: 3.3549721240997314 mm for frame 47

Saving results

Total time: 37.924999952316284
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1080/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1080.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1080
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00408203
Iteration 2/25 | Loss: 0.00093457
Iteration 3/25 | Loss: 0.00080694
Iteration 4/25 | Loss: 0.00078365
Iteration 5/25 | Loss: 0.00077520
Iteration 6/25 | Loss: 0.00077411
Iteration 7/25 | Loss: 0.00077411
Iteration 8/25 | Loss: 0.00077411
Iteration 9/25 | Loss: 0.00077411
Iteration 10/25 | Loss: 0.00077411
Iteration 11/25 | Loss: 0.00077411
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007741067092865705, 0.0007741067092865705, 0.0007741067092865705, 0.0007741067092865705, 0.0007741067092865705]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007741067092865705

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.55732751
Iteration 2/25 | Loss: 0.00043728
Iteration 3/25 | Loss: 0.00043725
Iteration 4/25 | Loss: 0.00043725
Iteration 5/25 | Loss: 0.00043725
Iteration 6/25 | Loss: 0.00043725
Iteration 7/25 | Loss: 0.00043725
Iteration 8/25 | Loss: 0.00043724
Iteration 9/25 | Loss: 0.00043724
Iteration 10/25 | Loss: 0.00043724
Iteration 11/25 | Loss: 0.00043724
Iteration 12/25 | Loss: 0.00043724
Iteration 13/25 | Loss: 0.00043724
Iteration 14/25 | Loss: 0.00043724
Iteration 15/25 | Loss: 0.00043724
Iteration 16/25 | Loss: 0.00043724
Iteration 17/25 | Loss: 0.00043724
Iteration 18/25 | Loss: 0.00043724
Iteration 19/25 | Loss: 0.00043724
Iteration 20/25 | Loss: 0.00043724
Iteration 21/25 | Loss: 0.00043724
Iteration 22/25 | Loss: 0.00043724
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0004372440744191408, 0.0004372440744191408, 0.0004372440744191408, 0.0004372440744191408, 0.0004372440744191408]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004372440744191408

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043724
Iteration 2/1000 | Loss: 0.00003550
Iteration 3/1000 | Loss: 0.00002590
Iteration 4/1000 | Loss: 0.00002431
Iteration 5/1000 | Loss: 0.00002344
Iteration 6/1000 | Loss: 0.00002279
Iteration 7/1000 | Loss: 0.00002233
Iteration 8/1000 | Loss: 0.00002191
Iteration 9/1000 | Loss: 0.00002160
Iteration 10/1000 | Loss: 0.00002138
Iteration 11/1000 | Loss: 0.00002130
Iteration 12/1000 | Loss: 0.00002129
Iteration 13/1000 | Loss: 0.00002129
Iteration 14/1000 | Loss: 0.00002109
Iteration 15/1000 | Loss: 0.00002106
Iteration 16/1000 | Loss: 0.00002105
Iteration 17/1000 | Loss: 0.00002103
Iteration 18/1000 | Loss: 0.00002102
Iteration 19/1000 | Loss: 0.00002102
Iteration 20/1000 | Loss: 0.00002101
Iteration 21/1000 | Loss: 0.00002101
Iteration 22/1000 | Loss: 0.00002100
Iteration 23/1000 | Loss: 0.00002100
Iteration 24/1000 | Loss: 0.00002099
Iteration 25/1000 | Loss: 0.00002099
Iteration 26/1000 | Loss: 0.00002099
Iteration 27/1000 | Loss: 0.00002099
Iteration 28/1000 | Loss: 0.00002099
Iteration 29/1000 | Loss: 0.00002099
Iteration 30/1000 | Loss: 0.00002099
Iteration 31/1000 | Loss: 0.00002098
Iteration 32/1000 | Loss: 0.00002098
Iteration 33/1000 | Loss: 0.00002098
Iteration 34/1000 | Loss: 0.00002098
Iteration 35/1000 | Loss: 0.00002098
Iteration 36/1000 | Loss: 0.00002098
Iteration 37/1000 | Loss: 0.00002098
Iteration 38/1000 | Loss: 0.00002097
Iteration 39/1000 | Loss: 0.00002097
Iteration 40/1000 | Loss: 0.00002097
Iteration 41/1000 | Loss: 0.00002097
Iteration 42/1000 | Loss: 0.00002096
Iteration 43/1000 | Loss: 0.00002096
Iteration 44/1000 | Loss: 0.00002096
Iteration 45/1000 | Loss: 0.00002096
Iteration 46/1000 | Loss: 0.00002096
Iteration 47/1000 | Loss: 0.00002096
Iteration 48/1000 | Loss: 0.00002095
Iteration 49/1000 | Loss: 0.00002095
Iteration 50/1000 | Loss: 0.00002095
Iteration 51/1000 | Loss: 0.00002094
Iteration 52/1000 | Loss: 0.00002094
Iteration 53/1000 | Loss: 0.00002094
Iteration 54/1000 | Loss: 0.00002094
Iteration 55/1000 | Loss: 0.00002094
Iteration 56/1000 | Loss: 0.00002094
Iteration 57/1000 | Loss: 0.00002094
Iteration 58/1000 | Loss: 0.00002094
Iteration 59/1000 | Loss: 0.00002094
Iteration 60/1000 | Loss: 0.00002094
Iteration 61/1000 | Loss: 0.00002094
Iteration 62/1000 | Loss: 0.00002093
Iteration 63/1000 | Loss: 0.00002093
Iteration 64/1000 | Loss: 0.00002093
Iteration 65/1000 | Loss: 0.00002092
Iteration 66/1000 | Loss: 0.00002092
Iteration 67/1000 | Loss: 0.00002092
Iteration 68/1000 | Loss: 0.00002091
Iteration 69/1000 | Loss: 0.00002091
Iteration 70/1000 | Loss: 0.00002090
Iteration 71/1000 | Loss: 0.00002090
Iteration 72/1000 | Loss: 0.00002090
Iteration 73/1000 | Loss: 0.00002089
Iteration 74/1000 | Loss: 0.00002089
Iteration 75/1000 | Loss: 0.00002088
Iteration 76/1000 | Loss: 0.00002088
Iteration 77/1000 | Loss: 0.00002087
Iteration 78/1000 | Loss: 0.00002087
Iteration 79/1000 | Loss: 0.00002086
Iteration 80/1000 | Loss: 0.00002086
Iteration 81/1000 | Loss: 0.00002086
Iteration 82/1000 | Loss: 0.00002086
Iteration 83/1000 | Loss: 0.00002086
Iteration 84/1000 | Loss: 0.00002086
Iteration 85/1000 | Loss: 0.00002085
Iteration 86/1000 | Loss: 0.00002084
Iteration 87/1000 | Loss: 0.00002084
Iteration 88/1000 | Loss: 0.00002084
Iteration 89/1000 | Loss: 0.00002084
Iteration 90/1000 | Loss: 0.00002084
Iteration 91/1000 | Loss: 0.00002083
Iteration 92/1000 | Loss: 0.00002083
Iteration 93/1000 | Loss: 0.00002083
Iteration 94/1000 | Loss: 0.00002082
Iteration 95/1000 | Loss: 0.00002082
Iteration 96/1000 | Loss: 0.00002082
Iteration 97/1000 | Loss: 0.00002082
Iteration 98/1000 | Loss: 0.00002082
Iteration 99/1000 | Loss: 0.00002082
Iteration 100/1000 | Loss: 0.00002082
Iteration 101/1000 | Loss: 0.00002082
Iteration 102/1000 | Loss: 0.00002082
Iteration 103/1000 | Loss: 0.00002081
Iteration 104/1000 | Loss: 0.00002081
Iteration 105/1000 | Loss: 0.00002081
Iteration 106/1000 | Loss: 0.00002081
Iteration 107/1000 | Loss: 0.00002081
Iteration 108/1000 | Loss: 0.00002081
Iteration 109/1000 | Loss: 0.00002081
Iteration 110/1000 | Loss: 0.00002081
Iteration 111/1000 | Loss: 0.00002080
Iteration 112/1000 | Loss: 0.00002080
Iteration 113/1000 | Loss: 0.00002080
Iteration 114/1000 | Loss: 0.00002080
Iteration 115/1000 | Loss: 0.00002079
Iteration 116/1000 | Loss: 0.00002079
Iteration 117/1000 | Loss: 0.00002079
Iteration 118/1000 | Loss: 0.00002079
Iteration 119/1000 | Loss: 0.00002079
Iteration 120/1000 | Loss: 0.00002079
Iteration 121/1000 | Loss: 0.00002079
Iteration 122/1000 | Loss: 0.00002079
Iteration 123/1000 | Loss: 0.00002079
Iteration 124/1000 | Loss: 0.00002079
Iteration 125/1000 | Loss: 0.00002079
Iteration 126/1000 | Loss: 0.00002079
Iteration 127/1000 | Loss: 0.00002079
Iteration 128/1000 | Loss: 0.00002079
Iteration 129/1000 | Loss: 0.00002079
Iteration 130/1000 | Loss: 0.00002078
Iteration 131/1000 | Loss: 0.00002078
Iteration 132/1000 | Loss: 0.00002078
Iteration 133/1000 | Loss: 0.00002078
Iteration 134/1000 | Loss: 0.00002078
Iteration 135/1000 | Loss: 0.00002078
Iteration 136/1000 | Loss: 0.00002078
Iteration 137/1000 | Loss: 0.00002078
Iteration 138/1000 | Loss: 0.00002078
Iteration 139/1000 | Loss: 0.00002078
Iteration 140/1000 | Loss: 0.00002078
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 140. Stopping optimization.
Last 5 losses: [2.0782352294190787e-05, 2.0782352294190787e-05, 2.0782352294190787e-05, 2.0782352294190787e-05, 2.0782352294190787e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0782352294190787e-05

Optimization complete. Final v2v error: 3.851477861404419 mm

Highest mean error: 4.048403263092041 mm for frame 105

Lowest mean error: 3.674527645111084 mm for frame 59

Saving results

Total time: 36.32189130783081
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00893460
Iteration 2/25 | Loss: 0.00129294
Iteration 3/25 | Loss: 0.00087287
Iteration 4/25 | Loss: 0.00081422
Iteration 5/25 | Loss: 0.00080559
Iteration 6/25 | Loss: 0.00080381
Iteration 7/25 | Loss: 0.00080376
Iteration 8/25 | Loss: 0.00080376
Iteration 9/25 | Loss: 0.00080376
Iteration 10/25 | Loss: 0.00080376
Iteration 11/25 | Loss: 0.00080376
Iteration 12/25 | Loss: 0.00080376
Iteration 13/25 | Loss: 0.00080376
Iteration 14/25 | Loss: 0.00080376
Iteration 15/25 | Loss: 0.00080376
Iteration 16/25 | Loss: 0.00080376
Iteration 17/25 | Loss: 0.00080376
Iteration 18/25 | Loss: 0.00080376
Iteration 19/25 | Loss: 0.00080376
Iteration 20/25 | Loss: 0.00080376
Iteration 21/25 | Loss: 0.00080376
Iteration 22/25 | Loss: 0.00080376
Iteration 23/25 | Loss: 0.00080376
Iteration 24/25 | Loss: 0.00080376
Iteration 25/25 | Loss: 0.00080376

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 6.48979139
Iteration 2/25 | Loss: 0.00044628
Iteration 3/25 | Loss: 0.00044628
Iteration 4/25 | Loss: 0.00044628
Iteration 5/25 | Loss: 0.00044628
Iteration 6/25 | Loss: 0.00044628
Iteration 7/25 | Loss: 0.00044628
Iteration 8/25 | Loss: 0.00044628
Iteration 9/25 | Loss: 0.00044628
Iteration 10/25 | Loss: 0.00044628
Iteration 11/25 | Loss: 0.00044628
Iteration 12/25 | Loss: 0.00044628
Iteration 13/25 | Loss: 0.00044628
Iteration 14/25 | Loss: 0.00044628
Iteration 15/25 | Loss: 0.00044628
Iteration 16/25 | Loss: 0.00044628
Iteration 17/25 | Loss: 0.00044628
Iteration 18/25 | Loss: 0.00044628
Iteration 19/25 | Loss: 0.00044628
Iteration 20/25 | Loss: 0.00044628
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.00044627601164393127, 0.00044627601164393127, 0.00044627601164393127, 0.00044627601164393127, 0.00044627601164393127]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00044627601164393127

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044628
Iteration 2/1000 | Loss: 0.00002640
Iteration 3/1000 | Loss: 0.00001739
Iteration 4/1000 | Loss: 0.00001479
Iteration 5/1000 | Loss: 0.00001404
Iteration 6/1000 | Loss: 0.00001350
Iteration 7/1000 | Loss: 0.00001338
Iteration 8/1000 | Loss: 0.00001326
Iteration 9/1000 | Loss: 0.00001310
Iteration 10/1000 | Loss: 0.00001287
Iteration 11/1000 | Loss: 0.00001278
Iteration 12/1000 | Loss: 0.00001277
Iteration 13/1000 | Loss: 0.00001277
Iteration 14/1000 | Loss: 0.00001272
Iteration 15/1000 | Loss: 0.00001270
Iteration 16/1000 | Loss: 0.00001269
Iteration 17/1000 | Loss: 0.00001268
Iteration 18/1000 | Loss: 0.00001261
Iteration 19/1000 | Loss: 0.00001261
Iteration 20/1000 | Loss: 0.00001253
Iteration 21/1000 | Loss: 0.00001249
Iteration 22/1000 | Loss: 0.00001248
Iteration 23/1000 | Loss: 0.00001248
Iteration 24/1000 | Loss: 0.00001247
Iteration 25/1000 | Loss: 0.00001246
Iteration 26/1000 | Loss: 0.00001246
Iteration 27/1000 | Loss: 0.00001245
Iteration 28/1000 | Loss: 0.00001245
Iteration 29/1000 | Loss: 0.00001245
Iteration 30/1000 | Loss: 0.00001244
Iteration 31/1000 | Loss: 0.00001244
Iteration 32/1000 | Loss: 0.00001244
Iteration 33/1000 | Loss: 0.00001241
Iteration 34/1000 | Loss: 0.00001240
Iteration 35/1000 | Loss: 0.00001239
Iteration 36/1000 | Loss: 0.00001239
Iteration 37/1000 | Loss: 0.00001237
Iteration 38/1000 | Loss: 0.00001232
Iteration 39/1000 | Loss: 0.00001231
Iteration 40/1000 | Loss: 0.00001230
Iteration 41/1000 | Loss: 0.00001229
Iteration 42/1000 | Loss: 0.00001229
Iteration 43/1000 | Loss: 0.00001229
Iteration 44/1000 | Loss: 0.00001229
Iteration 45/1000 | Loss: 0.00001229
Iteration 46/1000 | Loss: 0.00001229
Iteration 47/1000 | Loss: 0.00001228
Iteration 48/1000 | Loss: 0.00001228
Iteration 49/1000 | Loss: 0.00001228
Iteration 50/1000 | Loss: 0.00001228
Iteration 51/1000 | Loss: 0.00001228
Iteration 52/1000 | Loss: 0.00001228
Iteration 53/1000 | Loss: 0.00001227
Iteration 54/1000 | Loss: 0.00001227
Iteration 55/1000 | Loss: 0.00001226
Iteration 56/1000 | Loss: 0.00001226
Iteration 57/1000 | Loss: 0.00001226
Iteration 58/1000 | Loss: 0.00001226
Iteration 59/1000 | Loss: 0.00001225
Iteration 60/1000 | Loss: 0.00001225
Iteration 61/1000 | Loss: 0.00001224
Iteration 62/1000 | Loss: 0.00001224
Iteration 63/1000 | Loss: 0.00001224
Iteration 64/1000 | Loss: 0.00001224
Iteration 65/1000 | Loss: 0.00001224
Iteration 66/1000 | Loss: 0.00001224
Iteration 67/1000 | Loss: 0.00001223
Iteration 68/1000 | Loss: 0.00001223
Iteration 69/1000 | Loss: 0.00001223
Iteration 70/1000 | Loss: 0.00001223
Iteration 71/1000 | Loss: 0.00001223
Iteration 72/1000 | Loss: 0.00001223
Iteration 73/1000 | Loss: 0.00001223
Iteration 74/1000 | Loss: 0.00001223
Iteration 75/1000 | Loss: 0.00001223
Iteration 76/1000 | Loss: 0.00001223
Iteration 77/1000 | Loss: 0.00001223
Iteration 78/1000 | Loss: 0.00001223
Iteration 79/1000 | Loss: 0.00001223
Iteration 80/1000 | Loss: 0.00001223
Iteration 81/1000 | Loss: 0.00001223
Iteration 82/1000 | Loss: 0.00001223
Iteration 83/1000 | Loss: 0.00001223
Iteration 84/1000 | Loss: 0.00001223
Iteration 85/1000 | Loss: 0.00001222
Iteration 86/1000 | Loss: 0.00001222
Iteration 87/1000 | Loss: 0.00001222
Iteration 88/1000 | Loss: 0.00001222
Iteration 89/1000 | Loss: 0.00001222
Iteration 90/1000 | Loss: 0.00001222
Iteration 91/1000 | Loss: 0.00001222
Iteration 92/1000 | Loss: 0.00001222
Iteration 93/1000 | Loss: 0.00001222
Iteration 94/1000 | Loss: 0.00001222
Iteration 95/1000 | Loss: 0.00001222
Iteration 96/1000 | Loss: 0.00001222
Iteration 97/1000 | Loss: 0.00001222
Iteration 98/1000 | Loss: 0.00001221
Iteration 99/1000 | Loss: 0.00001221
Iteration 100/1000 | Loss: 0.00001221
Iteration 101/1000 | Loss: 0.00001221
Iteration 102/1000 | Loss: 0.00001221
Iteration 103/1000 | Loss: 0.00001221
Iteration 104/1000 | Loss: 0.00001221
Iteration 105/1000 | Loss: 0.00001221
Iteration 106/1000 | Loss: 0.00001221
Iteration 107/1000 | Loss: 0.00001221
Iteration 108/1000 | Loss: 0.00001221
Iteration 109/1000 | Loss: 0.00001221
Iteration 110/1000 | Loss: 0.00001221
Iteration 111/1000 | Loss: 0.00001221
Iteration 112/1000 | Loss: 0.00001221
Iteration 113/1000 | Loss: 0.00001221
Iteration 114/1000 | Loss: 0.00001221
Iteration 115/1000 | Loss: 0.00001221
Iteration 116/1000 | Loss: 0.00001221
Iteration 117/1000 | Loss: 0.00001221
Iteration 118/1000 | Loss: 0.00001221
Iteration 119/1000 | Loss: 0.00001221
Iteration 120/1000 | Loss: 0.00001221
Iteration 121/1000 | Loss: 0.00001221
Iteration 122/1000 | Loss: 0.00001221
Iteration 123/1000 | Loss: 0.00001221
Iteration 124/1000 | Loss: 0.00001221
Iteration 125/1000 | Loss: 0.00001221
Iteration 126/1000 | Loss: 0.00001221
Iteration 127/1000 | Loss: 0.00001221
Iteration 128/1000 | Loss: 0.00001221
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 128. Stopping optimization.
Last 5 losses: [1.221283309860155e-05, 1.221283309860155e-05, 1.221283309860155e-05, 1.221283309860155e-05, 1.221283309860155e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.221283309860155e-05

Optimization complete. Final v2v error: 2.9341278076171875 mm

Highest mean error: 3.09163498878479 mm for frame 123

Lowest mean error: 2.7615976333618164 mm for frame 205

Saving results

Total time: 39.087788105010986
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00594736
Iteration 2/25 | Loss: 0.00094694
Iteration 3/25 | Loss: 0.00084595
Iteration 4/25 | Loss: 0.00081119
Iteration 5/25 | Loss: 0.00080015
Iteration 6/25 | Loss: 0.00079814
Iteration 7/25 | Loss: 0.00079730
Iteration 8/25 | Loss: 0.00079730
Iteration 9/25 | Loss: 0.00079730
Iteration 10/25 | Loss: 0.00079730
Iteration 11/25 | Loss: 0.00079730
Iteration 12/25 | Loss: 0.00079730
Iteration 13/25 | Loss: 0.00079730
Iteration 14/25 | Loss: 0.00079730
Iteration 15/25 | Loss: 0.00079730
Iteration 16/25 | Loss: 0.00079730
Iteration 17/25 | Loss: 0.00079730
Iteration 18/25 | Loss: 0.00079730
Iteration 19/25 | Loss: 0.00079730
Iteration 20/25 | Loss: 0.00079730
Iteration 21/25 | Loss: 0.00079730
Iteration 22/25 | Loss: 0.00079730
Iteration 23/25 | Loss: 0.00079730
Iteration 24/25 | Loss: 0.00079730
Iteration 25/25 | Loss: 0.00079730

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.26919484
Iteration 2/25 | Loss: 0.00050932
Iteration 3/25 | Loss: 0.00050931
Iteration 4/25 | Loss: 0.00050931
Iteration 5/25 | Loss: 0.00050931
Iteration 6/25 | Loss: 0.00050931
Iteration 7/25 | Loss: 0.00050931
Iteration 8/25 | Loss: 0.00050931
Iteration 9/25 | Loss: 0.00050931
Iteration 10/25 | Loss: 0.00050931
Iteration 11/25 | Loss: 0.00050931
Iteration 12/25 | Loss: 0.00050931
Iteration 13/25 | Loss: 0.00050931
Iteration 14/25 | Loss: 0.00050931
Iteration 15/25 | Loss: 0.00050931
Iteration 16/25 | Loss: 0.00050931
Iteration 17/25 | Loss: 0.00050931
Iteration 18/25 | Loss: 0.00050931
Iteration 19/25 | Loss: 0.00050931
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0005093124927952886, 0.0005093124927952886, 0.0005093124927952886, 0.0005093124927952886, 0.0005093124927952886]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005093124927952886

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050931
Iteration 2/1000 | Loss: 0.00003553
Iteration 3/1000 | Loss: 0.00002849
Iteration 4/1000 | Loss: 0.00002705
Iteration 5/1000 | Loss: 0.00002562
Iteration 6/1000 | Loss: 0.00002507
Iteration 7/1000 | Loss: 0.00002434
Iteration 8/1000 | Loss: 0.00002401
Iteration 9/1000 | Loss: 0.00002374
Iteration 10/1000 | Loss: 0.00002357
Iteration 11/1000 | Loss: 0.00002340
Iteration 12/1000 | Loss: 0.00002327
Iteration 13/1000 | Loss: 0.00002327
Iteration 14/1000 | Loss: 0.00002325
Iteration 15/1000 | Loss: 0.00002325
Iteration 16/1000 | Loss: 0.00002324
Iteration 17/1000 | Loss: 0.00002324
Iteration 18/1000 | Loss: 0.00002323
Iteration 19/1000 | Loss: 0.00002323
Iteration 20/1000 | Loss: 0.00002322
Iteration 21/1000 | Loss: 0.00002322
Iteration 22/1000 | Loss: 0.00002322
Iteration 23/1000 | Loss: 0.00002322
Iteration 24/1000 | Loss: 0.00002317
Iteration 25/1000 | Loss: 0.00002315
Iteration 26/1000 | Loss: 0.00002310
Iteration 27/1000 | Loss: 0.00002306
Iteration 28/1000 | Loss: 0.00002305
Iteration 29/1000 | Loss: 0.00002303
Iteration 30/1000 | Loss: 0.00002302
Iteration 31/1000 | Loss: 0.00002300
Iteration 32/1000 | Loss: 0.00002299
Iteration 33/1000 | Loss: 0.00002298
Iteration 34/1000 | Loss: 0.00002297
Iteration 35/1000 | Loss: 0.00002297
Iteration 36/1000 | Loss: 0.00002297
Iteration 37/1000 | Loss: 0.00002296
Iteration 38/1000 | Loss: 0.00002296
Iteration 39/1000 | Loss: 0.00002296
Iteration 40/1000 | Loss: 0.00002295
Iteration 41/1000 | Loss: 0.00002295
Iteration 42/1000 | Loss: 0.00002294
Iteration 43/1000 | Loss: 0.00002294
Iteration 44/1000 | Loss: 0.00002294
Iteration 45/1000 | Loss: 0.00002294
Iteration 46/1000 | Loss: 0.00002294
Iteration 47/1000 | Loss: 0.00002294
Iteration 48/1000 | Loss: 0.00002293
Iteration 49/1000 | Loss: 0.00002293
Iteration 50/1000 | Loss: 0.00002293
Iteration 51/1000 | Loss: 0.00002293
Iteration 52/1000 | Loss: 0.00002292
Iteration 53/1000 | Loss: 0.00002292
Iteration 54/1000 | Loss: 0.00002291
Iteration 55/1000 | Loss: 0.00002291
Iteration 56/1000 | Loss: 0.00002291
Iteration 57/1000 | Loss: 0.00002291
Iteration 58/1000 | Loss: 0.00002291
Iteration 59/1000 | Loss: 0.00002291
Iteration 60/1000 | Loss: 0.00002291
Iteration 61/1000 | Loss: 0.00002291
Iteration 62/1000 | Loss: 0.00002291
Iteration 63/1000 | Loss: 0.00002291
Iteration 64/1000 | Loss: 0.00002291
Iteration 65/1000 | Loss: 0.00002290
Iteration 66/1000 | Loss: 0.00002290
Iteration 67/1000 | Loss: 0.00002289
Iteration 68/1000 | Loss: 0.00002289
Iteration 69/1000 | Loss: 0.00002289
Iteration 70/1000 | Loss: 0.00002289
Iteration 71/1000 | Loss: 0.00002289
Iteration 72/1000 | Loss: 0.00002289
Iteration 73/1000 | Loss: 0.00002288
Iteration 74/1000 | Loss: 0.00002288
Iteration 75/1000 | Loss: 0.00002288
Iteration 76/1000 | Loss: 0.00002288
Iteration 77/1000 | Loss: 0.00002288
Iteration 78/1000 | Loss: 0.00002288
Iteration 79/1000 | Loss: 0.00002287
Iteration 80/1000 | Loss: 0.00002287
Iteration 81/1000 | Loss: 0.00002287
Iteration 82/1000 | Loss: 0.00002287
Iteration 83/1000 | Loss: 0.00002287
Iteration 84/1000 | Loss: 0.00002286
Iteration 85/1000 | Loss: 0.00002286
Iteration 86/1000 | Loss: 0.00002286
Iteration 87/1000 | Loss: 0.00002285
Iteration 88/1000 | Loss: 0.00002285
Iteration 89/1000 | Loss: 0.00002285
Iteration 90/1000 | Loss: 0.00002285
Iteration 91/1000 | Loss: 0.00002284
Iteration 92/1000 | Loss: 0.00002284
Iteration 93/1000 | Loss: 0.00002284
Iteration 94/1000 | Loss: 0.00002284
Iteration 95/1000 | Loss: 0.00002283
Iteration 96/1000 | Loss: 0.00002283
Iteration 97/1000 | Loss: 0.00002283
Iteration 98/1000 | Loss: 0.00002282
Iteration 99/1000 | Loss: 0.00002282
Iteration 100/1000 | Loss: 0.00002282
Iteration 101/1000 | Loss: 0.00002282
Iteration 102/1000 | Loss: 0.00002282
Iteration 103/1000 | Loss: 0.00002282
Iteration 104/1000 | Loss: 0.00002282
Iteration 105/1000 | Loss: 0.00002282
Iteration 106/1000 | Loss: 0.00002282
Iteration 107/1000 | Loss: 0.00002282
Iteration 108/1000 | Loss: 0.00002282
Iteration 109/1000 | Loss: 0.00002282
Iteration 110/1000 | Loss: 0.00002282
Iteration 111/1000 | Loss: 0.00002282
Iteration 112/1000 | Loss: 0.00002282
Iteration 113/1000 | Loss: 0.00002282
Iteration 114/1000 | Loss: 0.00002282
Iteration 115/1000 | Loss: 0.00002282
Iteration 116/1000 | Loss: 0.00002282
Iteration 117/1000 | Loss: 0.00002281
Iteration 118/1000 | Loss: 0.00002281
Iteration 119/1000 | Loss: 0.00002281
Iteration 120/1000 | Loss: 0.00002281
Iteration 121/1000 | Loss: 0.00002281
Iteration 122/1000 | Loss: 0.00002281
Iteration 123/1000 | Loss: 0.00002281
Iteration 124/1000 | Loss: 0.00002281
Iteration 125/1000 | Loss: 0.00002281
Iteration 126/1000 | Loss: 0.00002281
Iteration 127/1000 | Loss: 0.00002281
Iteration 128/1000 | Loss: 0.00002281
Iteration 129/1000 | Loss: 0.00002281
Iteration 130/1000 | Loss: 0.00002281
Iteration 131/1000 | Loss: 0.00002280
Iteration 132/1000 | Loss: 0.00002280
Iteration 133/1000 | Loss: 0.00002280
Iteration 134/1000 | Loss: 0.00002280
Iteration 135/1000 | Loss: 0.00002280
Iteration 136/1000 | Loss: 0.00002280
Iteration 137/1000 | Loss: 0.00002280
Iteration 138/1000 | Loss: 0.00002280
Iteration 139/1000 | Loss: 0.00002280
Iteration 140/1000 | Loss: 0.00002280
Iteration 141/1000 | Loss: 0.00002280
Iteration 142/1000 | Loss: 0.00002280
Iteration 143/1000 | Loss: 0.00002280
Iteration 144/1000 | Loss: 0.00002280
Iteration 145/1000 | Loss: 0.00002280
Iteration 146/1000 | Loss: 0.00002280
Iteration 147/1000 | Loss: 0.00002280
Iteration 148/1000 | Loss: 0.00002280
Iteration 149/1000 | Loss: 0.00002280
Iteration 150/1000 | Loss: 0.00002280
Iteration 151/1000 | Loss: 0.00002280
Iteration 152/1000 | Loss: 0.00002280
Iteration 153/1000 | Loss: 0.00002280
Iteration 154/1000 | Loss: 0.00002280
Iteration 155/1000 | Loss: 0.00002280
Iteration 156/1000 | Loss: 0.00002280
Iteration 157/1000 | Loss: 0.00002280
Iteration 158/1000 | Loss: 0.00002280
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 158. Stopping optimization.
Last 5 losses: [2.28010267164791e-05, 2.28010267164791e-05, 2.28010267164791e-05, 2.28010267164791e-05, 2.28010267164791e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.28010267164791e-05

Optimization complete. Final v2v error: 3.9814975261688232 mm

Highest mean error: 4.226442337036133 mm for frame 94

Lowest mean error: 3.7987828254699707 mm for frame 122

Saving results

Total time: 40.42283892631531
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1032/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1032.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1032
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00387203
Iteration 2/25 | Loss: 0.00083569
Iteration 3/25 | Loss: 0.00072929
Iteration 4/25 | Loss: 0.00071116
Iteration 5/25 | Loss: 0.00070850
Iteration 6/25 | Loss: 0.00070794
Iteration 7/25 | Loss: 0.00070794
Iteration 8/25 | Loss: 0.00070794
Iteration 9/25 | Loss: 0.00070794
Iteration 10/25 | Loss: 0.00070794
Iteration 11/25 | Loss: 0.00070794
Iteration 12/25 | Loss: 0.00070794
Iteration 13/25 | Loss: 0.00070794
Iteration 14/25 | Loss: 0.00070794
Iteration 15/25 | Loss: 0.00070794
Iteration 16/25 | Loss: 0.00070794
Iteration 17/25 | Loss: 0.00070794
Iteration 18/25 | Loss: 0.00070794
Iteration 19/25 | Loss: 0.00070794
Iteration 20/25 | Loss: 0.00070794
Iteration 21/25 | Loss: 0.00070794
Iteration 22/25 | Loss: 0.00070794
Iteration 23/25 | Loss: 0.00070794
Iteration 24/25 | Loss: 0.00070794
Iteration 25/25 | Loss: 0.00070794

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.50143957
Iteration 2/25 | Loss: 0.00047080
Iteration 3/25 | Loss: 0.00047080
Iteration 4/25 | Loss: 0.00047080
Iteration 5/25 | Loss: 0.00047080
Iteration 6/25 | Loss: 0.00047080
Iteration 7/25 | Loss: 0.00047080
Iteration 8/25 | Loss: 0.00047080
Iteration 9/25 | Loss: 0.00047080
Iteration 10/25 | Loss: 0.00047080
Iteration 11/25 | Loss: 0.00047080
Iteration 12/25 | Loss: 0.00047080
Iteration 13/25 | Loss: 0.00047080
Iteration 14/25 | Loss: 0.00047080
Iteration 15/25 | Loss: 0.00047080
Iteration 16/25 | Loss: 0.00047080
Iteration 17/25 | Loss: 0.00047080
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0004707978223450482, 0.0004707978223450482, 0.0004707978223450482, 0.0004707978223450482, 0.0004707978223450482]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004707978223450482

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00047080
Iteration 2/1000 | Loss: 0.00002004
Iteration 3/1000 | Loss: 0.00001490
Iteration 4/1000 | Loss: 0.00001376
Iteration 5/1000 | Loss: 0.00001330
Iteration 6/1000 | Loss: 0.00001295
Iteration 7/1000 | Loss: 0.00001273
Iteration 8/1000 | Loss: 0.00001264
Iteration 9/1000 | Loss: 0.00001259
Iteration 10/1000 | Loss: 0.00001256
Iteration 11/1000 | Loss: 0.00001252
Iteration 12/1000 | Loss: 0.00001245
Iteration 13/1000 | Loss: 0.00001243
Iteration 14/1000 | Loss: 0.00001243
Iteration 15/1000 | Loss: 0.00001242
Iteration 16/1000 | Loss: 0.00001242
Iteration 17/1000 | Loss: 0.00001235
Iteration 18/1000 | Loss: 0.00001234
Iteration 19/1000 | Loss: 0.00001233
Iteration 20/1000 | Loss: 0.00001232
Iteration 21/1000 | Loss: 0.00001228
Iteration 22/1000 | Loss: 0.00001228
Iteration 23/1000 | Loss: 0.00001225
Iteration 24/1000 | Loss: 0.00001217
Iteration 25/1000 | Loss: 0.00001213
Iteration 26/1000 | Loss: 0.00001213
Iteration 27/1000 | Loss: 0.00001211
Iteration 28/1000 | Loss: 0.00001206
Iteration 29/1000 | Loss: 0.00001205
Iteration 30/1000 | Loss: 0.00001205
Iteration 31/1000 | Loss: 0.00001203
Iteration 32/1000 | Loss: 0.00001202
Iteration 33/1000 | Loss: 0.00001202
Iteration 34/1000 | Loss: 0.00001202
Iteration 35/1000 | Loss: 0.00001201
Iteration 36/1000 | Loss: 0.00001201
Iteration 37/1000 | Loss: 0.00001200
Iteration 38/1000 | Loss: 0.00001199
Iteration 39/1000 | Loss: 0.00001199
Iteration 40/1000 | Loss: 0.00001198
Iteration 41/1000 | Loss: 0.00001198
Iteration 42/1000 | Loss: 0.00001198
Iteration 43/1000 | Loss: 0.00001198
Iteration 44/1000 | Loss: 0.00001196
Iteration 45/1000 | Loss: 0.00001191
Iteration 46/1000 | Loss: 0.00001189
Iteration 47/1000 | Loss: 0.00001189
Iteration 48/1000 | Loss: 0.00001188
Iteration 49/1000 | Loss: 0.00001182
Iteration 50/1000 | Loss: 0.00001182
Iteration 51/1000 | Loss: 0.00001182
Iteration 52/1000 | Loss: 0.00001182
Iteration 53/1000 | Loss: 0.00001181
Iteration 54/1000 | Loss: 0.00001179
Iteration 55/1000 | Loss: 0.00001179
Iteration 56/1000 | Loss: 0.00001178
Iteration 57/1000 | Loss: 0.00001178
Iteration 58/1000 | Loss: 0.00001178
Iteration 59/1000 | Loss: 0.00001177
Iteration 60/1000 | Loss: 0.00001177
Iteration 61/1000 | Loss: 0.00001177
Iteration 62/1000 | Loss: 0.00001176
Iteration 63/1000 | Loss: 0.00001176
Iteration 64/1000 | Loss: 0.00001175
Iteration 65/1000 | Loss: 0.00001175
Iteration 66/1000 | Loss: 0.00001175
Iteration 67/1000 | Loss: 0.00001175
Iteration 68/1000 | Loss: 0.00001175
Iteration 69/1000 | Loss: 0.00001175
Iteration 70/1000 | Loss: 0.00001175
Iteration 71/1000 | Loss: 0.00001175
Iteration 72/1000 | Loss: 0.00001175
Iteration 73/1000 | Loss: 0.00001175
Iteration 74/1000 | Loss: 0.00001175
Iteration 75/1000 | Loss: 0.00001175
Iteration 76/1000 | Loss: 0.00001175
Iteration 77/1000 | Loss: 0.00001175
Iteration 78/1000 | Loss: 0.00001175
Iteration 79/1000 | Loss: 0.00001175
Iteration 80/1000 | Loss: 0.00001175
Iteration 81/1000 | Loss: 0.00001175
Iteration 82/1000 | Loss: 0.00001175
Iteration 83/1000 | Loss: 0.00001175
Iteration 84/1000 | Loss: 0.00001175
Iteration 85/1000 | Loss: 0.00001175
Iteration 86/1000 | Loss: 0.00001175
Iteration 87/1000 | Loss: 0.00001175
Iteration 88/1000 | Loss: 0.00001175
Iteration 89/1000 | Loss: 0.00001175
Iteration 90/1000 | Loss: 0.00001175
Iteration 91/1000 | Loss: 0.00001175
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 91. Stopping optimization.
Last 5 losses: [1.1747272765205707e-05, 1.1747272765205707e-05, 1.1747272765205707e-05, 1.1747272765205707e-05, 1.1747272765205707e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1747272765205707e-05

Optimization complete. Final v2v error: 2.9296255111694336 mm

Highest mean error: 3.2164247035980225 mm for frame 98

Lowest mean error: 2.7987382411956787 mm for frame 121

Saving results

Total time: 34.59560227394104
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1058/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1058.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1058
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00967907
Iteration 2/25 | Loss: 0.00268193
Iteration 3/25 | Loss: 0.00173364
Iteration 4/25 | Loss: 0.00153446
Iteration 5/25 | Loss: 0.00146035
Iteration 6/25 | Loss: 0.00128176
Iteration 7/25 | Loss: 0.00116524
Iteration 8/25 | Loss: 0.00103759
Iteration 9/25 | Loss: 0.00100849
Iteration 10/25 | Loss: 0.00100877
Iteration 11/25 | Loss: 0.00095943
Iteration 12/25 | Loss: 0.00095337
Iteration 13/25 | Loss: 0.00094365
Iteration 14/25 | Loss: 0.00093424
Iteration 15/25 | Loss: 0.00092756
Iteration 16/25 | Loss: 0.00092570
Iteration 17/25 | Loss: 0.00092483
Iteration 18/25 | Loss: 0.00092452
Iteration 19/25 | Loss: 0.00092450
Iteration 20/25 | Loss: 0.00092449
Iteration 21/25 | Loss: 0.00092449
Iteration 22/25 | Loss: 0.00092449
Iteration 23/25 | Loss: 0.00092449
Iteration 24/25 | Loss: 0.00092448
Iteration 25/25 | Loss: 0.00092448

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.52969933
Iteration 2/25 | Loss: 0.00104561
Iteration 3/25 | Loss: 0.00104560
Iteration 4/25 | Loss: 0.00104560
Iteration 5/25 | Loss: 0.00104560
Iteration 6/25 | Loss: 0.00104560
Iteration 7/25 | Loss: 0.00104560
Iteration 8/25 | Loss: 0.00104560
Iteration 9/25 | Loss: 0.00104560
Iteration 10/25 | Loss: 0.00104560
Iteration 11/25 | Loss: 0.00104560
Iteration 12/25 | Loss: 0.00104560
Iteration 13/25 | Loss: 0.00104560
Iteration 14/25 | Loss: 0.00104560
Iteration 15/25 | Loss: 0.00104560
Iteration 16/25 | Loss: 0.00104560
Iteration 17/25 | Loss: 0.00104560
Iteration 18/25 | Loss: 0.00104560
Iteration 19/25 | Loss: 0.00104560
Iteration 20/25 | Loss: 0.00104560
Iteration 21/25 | Loss: 0.00104560
Iteration 22/25 | Loss: 0.00104560
Iteration 23/25 | Loss: 0.00104560
Iteration 24/25 | Loss: 0.00104560
Iteration 25/25 | Loss: 0.00104560

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00104560
Iteration 2/1000 | Loss: 0.00586304
Iteration 3/1000 | Loss: 0.00265788
Iteration 4/1000 | Loss: 0.00177388
Iteration 5/1000 | Loss: 0.00065864
Iteration 6/1000 | Loss: 0.00030598
Iteration 7/1000 | Loss: 0.00071137
Iteration 8/1000 | Loss: 0.00043622
Iteration 9/1000 | Loss: 0.00027210
Iteration 10/1000 | Loss: 0.00032038
Iteration 11/1000 | Loss: 0.00046334
Iteration 12/1000 | Loss: 0.00036047
Iteration 13/1000 | Loss: 0.00022211
Iteration 14/1000 | Loss: 0.00022636
Iteration 15/1000 | Loss: 0.00020217
Iteration 16/1000 | Loss: 0.00049196
Iteration 17/1000 | Loss: 0.00164884
Iteration 18/1000 | Loss: 0.00161036
Iteration 19/1000 | Loss: 0.00293801
Iteration 20/1000 | Loss: 0.00211088
Iteration 21/1000 | Loss: 0.00073485
Iteration 22/1000 | Loss: 0.00122356
Iteration 23/1000 | Loss: 0.00113929
Iteration 24/1000 | Loss: 0.00035552
Iteration 25/1000 | Loss: 0.00048219
Iteration 26/1000 | Loss: 0.00031840
Iteration 27/1000 | Loss: 0.00020919
Iteration 28/1000 | Loss: 0.00042397
Iteration 29/1000 | Loss: 0.00012519
Iteration 30/1000 | Loss: 0.00078629
Iteration 31/1000 | Loss: 0.00042248
Iteration 32/1000 | Loss: 0.00041248
Iteration 33/1000 | Loss: 0.00078193
Iteration 34/1000 | Loss: 0.00033197
Iteration 35/1000 | Loss: 0.00030594
Iteration 36/1000 | Loss: 0.00032452
Iteration 37/1000 | Loss: 0.00028915
Iteration 38/1000 | Loss: 0.00036105
Iteration 39/1000 | Loss: 0.00012652
Iteration 40/1000 | Loss: 0.00024671
Iteration 41/1000 | Loss: 0.00039035
Iteration 42/1000 | Loss: 0.00010194
Iteration 43/1000 | Loss: 0.00091174
Iteration 44/1000 | Loss: 0.00043075
Iteration 45/1000 | Loss: 0.00026318
Iteration 46/1000 | Loss: 0.00025306
Iteration 47/1000 | Loss: 0.00009565
Iteration 48/1000 | Loss: 0.00008469
Iteration 49/1000 | Loss: 0.00034724
Iteration 50/1000 | Loss: 0.00010011
Iteration 51/1000 | Loss: 0.00026755
Iteration 52/1000 | Loss: 0.00006857
Iteration 53/1000 | Loss: 0.00020975
Iteration 54/1000 | Loss: 0.00006330
Iteration 55/1000 | Loss: 0.00005888
Iteration 56/1000 | Loss: 0.00008104
Iteration 57/1000 | Loss: 0.00062528
Iteration 58/1000 | Loss: 0.00091122
Iteration 59/1000 | Loss: 0.00023057
Iteration 60/1000 | Loss: 0.00015045
Iteration 61/1000 | Loss: 0.00005997
Iteration 62/1000 | Loss: 0.00005644
Iteration 63/1000 | Loss: 0.00031972
Iteration 64/1000 | Loss: 0.00045950
Iteration 65/1000 | Loss: 0.00007883
Iteration 66/1000 | Loss: 0.00005612
Iteration 67/1000 | Loss: 0.00005471
Iteration 68/1000 | Loss: 0.00004254
Iteration 69/1000 | Loss: 0.00004166
Iteration 70/1000 | Loss: 0.00014599
Iteration 71/1000 | Loss: 0.00003688
Iteration 72/1000 | Loss: 0.00004045
Iteration 73/1000 | Loss: 0.00003577
Iteration 74/1000 | Loss: 0.00003077
Iteration 75/1000 | Loss: 0.00002917
Iteration 76/1000 | Loss: 0.00002782
Iteration 77/1000 | Loss: 0.00002666
Iteration 78/1000 | Loss: 0.00002592
Iteration 79/1000 | Loss: 0.00002512
Iteration 80/1000 | Loss: 0.00002458
Iteration 81/1000 | Loss: 0.00002416
Iteration 82/1000 | Loss: 0.00002383
Iteration 83/1000 | Loss: 0.00002361
Iteration 84/1000 | Loss: 0.00002343
Iteration 85/1000 | Loss: 0.00002340
Iteration 86/1000 | Loss: 0.00002338
Iteration 87/1000 | Loss: 0.00002336
Iteration 88/1000 | Loss: 0.00002328
Iteration 89/1000 | Loss: 0.00002324
Iteration 90/1000 | Loss: 0.00002321
Iteration 91/1000 | Loss: 0.00002319
Iteration 92/1000 | Loss: 0.00002313
Iteration 93/1000 | Loss: 0.00002313
Iteration 94/1000 | Loss: 0.00002313
Iteration 95/1000 | Loss: 0.00002313
Iteration 96/1000 | Loss: 0.00002313
Iteration 97/1000 | Loss: 0.00002313
Iteration 98/1000 | Loss: 0.00002313
Iteration 99/1000 | Loss: 0.00002313
Iteration 100/1000 | Loss: 0.00002313
Iteration 101/1000 | Loss: 0.00002312
Iteration 102/1000 | Loss: 0.00002312
Iteration 103/1000 | Loss: 0.00002312
Iteration 104/1000 | Loss: 0.00002311
Iteration 105/1000 | Loss: 0.00002307
Iteration 106/1000 | Loss: 0.00002306
Iteration 107/1000 | Loss: 0.00002306
Iteration 108/1000 | Loss: 0.00002305
Iteration 109/1000 | Loss: 0.00002305
Iteration 110/1000 | Loss: 0.00002304
Iteration 111/1000 | Loss: 0.00002304
Iteration 112/1000 | Loss: 0.00002304
Iteration 113/1000 | Loss: 0.00002303
Iteration 114/1000 | Loss: 0.00002303
Iteration 115/1000 | Loss: 0.00002302
Iteration 116/1000 | Loss: 0.00002302
Iteration 117/1000 | Loss: 0.00002301
Iteration 118/1000 | Loss: 0.00002300
Iteration 119/1000 | Loss: 0.00002300
Iteration 120/1000 | Loss: 0.00002300
Iteration 121/1000 | Loss: 0.00002300
Iteration 122/1000 | Loss: 0.00002300
Iteration 123/1000 | Loss: 0.00002300
Iteration 124/1000 | Loss: 0.00002300
Iteration 125/1000 | Loss: 0.00002299
Iteration 126/1000 | Loss: 0.00002299
Iteration 127/1000 | Loss: 0.00002299
Iteration 128/1000 | Loss: 0.00002299
Iteration 129/1000 | Loss: 0.00002298
Iteration 130/1000 | Loss: 0.00002298
Iteration 131/1000 | Loss: 0.00002297
Iteration 132/1000 | Loss: 0.00002297
Iteration 133/1000 | Loss: 0.00002297
Iteration 134/1000 | Loss: 0.00002297
Iteration 135/1000 | Loss: 0.00002297
Iteration 136/1000 | Loss: 0.00002296
Iteration 137/1000 | Loss: 0.00002296
Iteration 138/1000 | Loss: 0.00002296
Iteration 139/1000 | Loss: 0.00002296
Iteration 140/1000 | Loss: 0.00002296
Iteration 141/1000 | Loss: 0.00002296
Iteration 142/1000 | Loss: 0.00002296
Iteration 143/1000 | Loss: 0.00002296
Iteration 144/1000 | Loss: 0.00002296
Iteration 145/1000 | Loss: 0.00002296
Iteration 146/1000 | Loss: 0.00002296
Iteration 147/1000 | Loss: 0.00002295
Iteration 148/1000 | Loss: 0.00002295
Iteration 149/1000 | Loss: 0.00002295
Iteration 150/1000 | Loss: 0.00002294
Iteration 151/1000 | Loss: 0.00002294
Iteration 152/1000 | Loss: 0.00002294
Iteration 153/1000 | Loss: 0.00002294
Iteration 154/1000 | Loss: 0.00002294
Iteration 155/1000 | Loss: 0.00002293
Iteration 156/1000 | Loss: 0.00002293
Iteration 157/1000 | Loss: 0.00002293
Iteration 158/1000 | Loss: 0.00002293
Iteration 159/1000 | Loss: 0.00002293
Iteration 160/1000 | Loss: 0.00002292
Iteration 161/1000 | Loss: 0.00002292
Iteration 162/1000 | Loss: 0.00002292
Iteration 163/1000 | Loss: 0.00002292
Iteration 164/1000 | Loss: 0.00002291
Iteration 165/1000 | Loss: 0.00002291
Iteration 166/1000 | Loss: 0.00002291
Iteration 167/1000 | Loss: 0.00002291
Iteration 168/1000 | Loss: 0.00002291
Iteration 169/1000 | Loss: 0.00002291
Iteration 170/1000 | Loss: 0.00002291
Iteration 171/1000 | Loss: 0.00002291
Iteration 172/1000 | Loss: 0.00002291
Iteration 173/1000 | Loss: 0.00002291
Iteration 174/1000 | Loss: 0.00002290
Iteration 175/1000 | Loss: 0.00002290
Iteration 176/1000 | Loss: 0.00002290
Iteration 177/1000 | Loss: 0.00002290
Iteration 178/1000 | Loss: 0.00002290
Iteration 179/1000 | Loss: 0.00002290
Iteration 180/1000 | Loss: 0.00002290
Iteration 181/1000 | Loss: 0.00002290
Iteration 182/1000 | Loss: 0.00002289
Iteration 183/1000 | Loss: 0.00002289
Iteration 184/1000 | Loss: 0.00002289
Iteration 185/1000 | Loss: 0.00002289
Iteration 186/1000 | Loss: 0.00002288
Iteration 187/1000 | Loss: 0.00002288
Iteration 188/1000 | Loss: 0.00002288
Iteration 189/1000 | Loss: 0.00002288
Iteration 190/1000 | Loss: 0.00002288
Iteration 191/1000 | Loss: 0.00002288
Iteration 192/1000 | Loss: 0.00002288
Iteration 193/1000 | Loss: 0.00002288
Iteration 194/1000 | Loss: 0.00002287
Iteration 195/1000 | Loss: 0.00002287
Iteration 196/1000 | Loss: 0.00002287
Iteration 197/1000 | Loss: 0.00002287
Iteration 198/1000 | Loss: 0.00002287
Iteration 199/1000 | Loss: 0.00002287
Iteration 200/1000 | Loss: 0.00002287
Iteration 201/1000 | Loss: 0.00002287
Iteration 202/1000 | Loss: 0.00002287
Iteration 203/1000 | Loss: 0.00002287
Iteration 204/1000 | Loss: 0.00002287
Iteration 205/1000 | Loss: 0.00002287
Iteration 206/1000 | Loss: 0.00002287
Iteration 207/1000 | Loss: 0.00002287
Iteration 208/1000 | Loss: 0.00002287
Iteration 209/1000 | Loss: 0.00002287
Iteration 210/1000 | Loss: 0.00002287
Iteration 211/1000 | Loss: 0.00002286
Iteration 212/1000 | Loss: 0.00002286
Iteration 213/1000 | Loss: 0.00002286
Iteration 214/1000 | Loss: 0.00002286
Iteration 215/1000 | Loss: 0.00002286
Iteration 216/1000 | Loss: 0.00002286
Iteration 217/1000 | Loss: 0.00002286
Iteration 218/1000 | Loss: 0.00002286
Iteration 219/1000 | Loss: 0.00002286
Iteration 220/1000 | Loss: 0.00002286
Iteration 221/1000 | Loss: 0.00002286
Iteration 222/1000 | Loss: 0.00002286
Iteration 223/1000 | Loss: 0.00002286
Iteration 224/1000 | Loss: 0.00002286
Iteration 225/1000 | Loss: 0.00002286
Iteration 226/1000 | Loss: 0.00002286
Iteration 227/1000 | Loss: 0.00002286
Iteration 228/1000 | Loss: 0.00002286
Iteration 229/1000 | Loss: 0.00002286
Iteration 230/1000 | Loss: 0.00002286
Iteration 231/1000 | Loss: 0.00002286
Iteration 232/1000 | Loss: 0.00002286
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 232. Stopping optimization.
Last 5 losses: [2.2864507627673447e-05, 2.2864507627673447e-05, 2.2864507627673447e-05, 2.2864507627673447e-05, 2.2864507627673447e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2864507627673447e-05

Optimization complete. Final v2v error: 3.5942294597625732 mm

Highest mean error: 6.787199020385742 mm for frame 68

Lowest mean error: 2.8179123401641846 mm for frame 123

Saving results

Total time: 161.7507679462433
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1044/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1044.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1044
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00698672
Iteration 2/25 | Loss: 0.00149710
Iteration 3/25 | Loss: 0.00106158
Iteration 4/25 | Loss: 0.00092690
Iteration 5/25 | Loss: 0.00091466
Iteration 6/25 | Loss: 0.00086841
Iteration 7/25 | Loss: 0.00086011
Iteration 8/25 | Loss: 0.00085785
Iteration 9/25 | Loss: 0.00086712
Iteration 10/25 | Loss: 0.00086198
Iteration 11/25 | Loss: 0.00084907
Iteration 12/25 | Loss: 0.00084651
Iteration 13/25 | Loss: 0.00084373
Iteration 14/25 | Loss: 0.00084935
Iteration 15/25 | Loss: 0.00084379
Iteration 16/25 | Loss: 0.00084465
Iteration 17/25 | Loss: 0.00084200
Iteration 18/25 | Loss: 0.00084045
Iteration 19/25 | Loss: 0.00083997
Iteration 20/25 | Loss: 0.00084453
Iteration 21/25 | Loss: 0.00084284
Iteration 22/25 | Loss: 0.00083910
Iteration 23/25 | Loss: 0.00083933
Iteration 24/25 | Loss: 0.00084012
Iteration 25/25 | Loss: 0.00084038

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.38361907
Iteration 2/25 | Loss: 0.00093311
Iteration 3/25 | Loss: 0.00076422
Iteration 4/25 | Loss: 0.00076421
Iteration 5/25 | Loss: 0.00076421
Iteration 6/25 | Loss: 0.00076421
Iteration 7/25 | Loss: 0.00076421
Iteration 8/25 | Loss: 0.00076421
Iteration 9/25 | Loss: 0.00076421
Iteration 10/25 | Loss: 0.00076421
Iteration 11/25 | Loss: 0.00076421
Iteration 12/25 | Loss: 0.00076421
Iteration 13/25 | Loss: 0.00076421
Iteration 14/25 | Loss: 0.00076421
Iteration 15/25 | Loss: 0.00076421
Iteration 16/25 | Loss: 0.00076421
Iteration 17/25 | Loss: 0.00076421
Iteration 18/25 | Loss: 0.00076421
Iteration 19/25 | Loss: 0.00076421
Iteration 20/25 | Loss: 0.00076421
Iteration 21/25 | Loss: 0.00076421
Iteration 22/25 | Loss: 0.00076421
Iteration 23/25 | Loss: 0.00076421
Iteration 24/25 | Loss: 0.00076421
Iteration 25/25 | Loss: 0.00076421

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00076421
Iteration 2/1000 | Loss: 0.00023664
Iteration 3/1000 | Loss: 0.00003690
Iteration 4/1000 | Loss: 0.00003004
Iteration 5/1000 | Loss: 0.00002694
Iteration 6/1000 | Loss: 0.00002477
Iteration 7/1000 | Loss: 0.00004303
Iteration 8/1000 | Loss: 0.00002324
Iteration 9/1000 | Loss: 0.00002188
Iteration 10/1000 | Loss: 0.00002108
Iteration 11/1000 | Loss: 0.00014917
Iteration 12/1000 | Loss: 0.00002464
Iteration 13/1000 | Loss: 0.00002039
Iteration 14/1000 | Loss: 0.00001914
Iteration 15/1000 | Loss: 0.00001796
Iteration 16/1000 | Loss: 0.00001731
Iteration 17/1000 | Loss: 0.00001709
Iteration 18/1000 | Loss: 0.00026196
Iteration 19/1000 | Loss: 0.00016873
Iteration 20/1000 | Loss: 0.00001779
Iteration 21/1000 | Loss: 0.00001688
Iteration 22/1000 | Loss: 0.00001673
Iteration 23/1000 | Loss: 0.00026802
Iteration 24/1000 | Loss: 0.00012278
Iteration 25/1000 | Loss: 0.00025999
Iteration 26/1000 | Loss: 0.00014073
Iteration 27/1000 | Loss: 0.00031184
Iteration 28/1000 | Loss: 0.00015529
Iteration 29/1000 | Loss: 0.00004275
Iteration 30/1000 | Loss: 0.00002040
Iteration 31/1000 | Loss: 0.00011351
Iteration 32/1000 | Loss: 0.00040506
Iteration 33/1000 | Loss: 0.00012166
Iteration 34/1000 | Loss: 0.00002062
Iteration 35/1000 | Loss: 0.00001750
Iteration 36/1000 | Loss: 0.00001701
Iteration 37/1000 | Loss: 0.00001664
Iteration 38/1000 | Loss: 0.00001659
Iteration 39/1000 | Loss: 0.00001655
Iteration 40/1000 | Loss: 0.00001653
Iteration 41/1000 | Loss: 0.00001652
Iteration 42/1000 | Loss: 0.00001652
Iteration 43/1000 | Loss: 0.00001652
Iteration 44/1000 | Loss: 0.00001651
Iteration 45/1000 | Loss: 0.00001650
Iteration 46/1000 | Loss: 0.00001650
Iteration 47/1000 | Loss: 0.00001650
Iteration 48/1000 | Loss: 0.00001650
Iteration 49/1000 | Loss: 0.00001649
Iteration 50/1000 | Loss: 0.00001649
Iteration 51/1000 | Loss: 0.00001649
Iteration 52/1000 | Loss: 0.00001649
Iteration 53/1000 | Loss: 0.00001648
Iteration 54/1000 | Loss: 0.00001648
Iteration 55/1000 | Loss: 0.00001648
Iteration 56/1000 | Loss: 0.00001648
Iteration 57/1000 | Loss: 0.00001648
Iteration 58/1000 | Loss: 0.00001648
Iteration 59/1000 | Loss: 0.00001648
Iteration 60/1000 | Loss: 0.00001647
Iteration 61/1000 | Loss: 0.00001647
Iteration 62/1000 | Loss: 0.00001647
Iteration 63/1000 | Loss: 0.00001647
Iteration 64/1000 | Loss: 0.00001647
Iteration 65/1000 | Loss: 0.00001647
Iteration 66/1000 | Loss: 0.00001647
Iteration 67/1000 | Loss: 0.00001647
Iteration 68/1000 | Loss: 0.00001647
Iteration 69/1000 | Loss: 0.00001646
Iteration 70/1000 | Loss: 0.00001646
Iteration 71/1000 | Loss: 0.00001646
Iteration 72/1000 | Loss: 0.00001646
Iteration 73/1000 | Loss: 0.00001646
Iteration 74/1000 | Loss: 0.00001646
Iteration 75/1000 | Loss: 0.00001646
Iteration 76/1000 | Loss: 0.00001646
Iteration 77/1000 | Loss: 0.00001646
Iteration 78/1000 | Loss: 0.00001646
Iteration 79/1000 | Loss: 0.00001646
Iteration 80/1000 | Loss: 0.00001646
Iteration 81/1000 | Loss: 0.00001646
Iteration 82/1000 | Loss: 0.00001645
Iteration 83/1000 | Loss: 0.00001645
Iteration 84/1000 | Loss: 0.00001645
Iteration 85/1000 | Loss: 0.00001645
Iteration 86/1000 | Loss: 0.00001645
Iteration 87/1000 | Loss: 0.00001645
Iteration 88/1000 | Loss: 0.00001644
Iteration 89/1000 | Loss: 0.00001644
Iteration 90/1000 | Loss: 0.00001644
Iteration 91/1000 | Loss: 0.00001644
Iteration 92/1000 | Loss: 0.00001644
Iteration 93/1000 | Loss: 0.00001644
Iteration 94/1000 | Loss: 0.00001644
Iteration 95/1000 | Loss: 0.00001644
Iteration 96/1000 | Loss: 0.00001644
Iteration 97/1000 | Loss: 0.00001644
Iteration 98/1000 | Loss: 0.00001643
Iteration 99/1000 | Loss: 0.00001643
Iteration 100/1000 | Loss: 0.00001643
Iteration 101/1000 | Loss: 0.00001643
Iteration 102/1000 | Loss: 0.00001643
Iteration 103/1000 | Loss: 0.00001643
Iteration 104/1000 | Loss: 0.00027855
Iteration 105/1000 | Loss: 0.00010220
Iteration 106/1000 | Loss: 0.00001890
Iteration 107/1000 | Loss: 0.00001671
Iteration 108/1000 | Loss: 0.00001644
Iteration 109/1000 | Loss: 0.00001644
Iteration 110/1000 | Loss: 0.00001643
Iteration 111/1000 | Loss: 0.00001642
Iteration 112/1000 | Loss: 0.00001642
Iteration 113/1000 | Loss: 0.00001642
Iteration 114/1000 | Loss: 0.00001642
Iteration 115/1000 | Loss: 0.00028460
Iteration 116/1000 | Loss: 0.00010540
Iteration 117/1000 | Loss: 0.00022980
Iteration 118/1000 | Loss: 0.00009804
Iteration 119/1000 | Loss: 0.00001711
Iteration 120/1000 | Loss: 0.00001656
Iteration 121/1000 | Loss: 0.00001645
Iteration 122/1000 | Loss: 0.00001644
Iteration 123/1000 | Loss: 0.00001643
Iteration 124/1000 | Loss: 0.00001643
Iteration 125/1000 | Loss: 0.00001643
Iteration 126/1000 | Loss: 0.00001643
Iteration 127/1000 | Loss: 0.00001643
Iteration 128/1000 | Loss: 0.00001643
Iteration 129/1000 | Loss: 0.00001643
Iteration 130/1000 | Loss: 0.00001643
Iteration 131/1000 | Loss: 0.00001643
Iteration 132/1000 | Loss: 0.00001642
Iteration 133/1000 | Loss: 0.00001642
Iteration 134/1000 | Loss: 0.00001642
Iteration 135/1000 | Loss: 0.00001642
Iteration 136/1000 | Loss: 0.00001642
Iteration 137/1000 | Loss: 0.00001642
Iteration 138/1000 | Loss: 0.00001642
Iteration 139/1000 | Loss: 0.00001641
Iteration 140/1000 | Loss: 0.00001641
Iteration 141/1000 | Loss: 0.00027043
Iteration 142/1000 | Loss: 0.00008873
Iteration 143/1000 | Loss: 0.00002112
Iteration 144/1000 | Loss: 0.00001781
Iteration 145/1000 | Loss: 0.00001711
Iteration 146/1000 | Loss: 0.00001681
Iteration 147/1000 | Loss: 0.00001662
Iteration 148/1000 | Loss: 0.00001659
Iteration 149/1000 | Loss: 0.00001658
Iteration 150/1000 | Loss: 0.00001657
Iteration 151/1000 | Loss: 0.00001657
Iteration 152/1000 | Loss: 0.00001657
Iteration 153/1000 | Loss: 0.00001657
Iteration 154/1000 | Loss: 0.00001656
Iteration 155/1000 | Loss: 0.00001656
Iteration 156/1000 | Loss: 0.00001656
Iteration 157/1000 | Loss: 0.00001656
Iteration 158/1000 | Loss: 0.00001655
Iteration 159/1000 | Loss: 0.00001655
Iteration 160/1000 | Loss: 0.00001655
Iteration 161/1000 | Loss: 0.00001654
Iteration 162/1000 | Loss: 0.00001654
Iteration 163/1000 | Loss: 0.00001654
Iteration 164/1000 | Loss: 0.00001654
Iteration 165/1000 | Loss: 0.00001654
Iteration 166/1000 | Loss: 0.00001653
Iteration 167/1000 | Loss: 0.00001653
Iteration 168/1000 | Loss: 0.00001653
Iteration 169/1000 | Loss: 0.00001653
Iteration 170/1000 | Loss: 0.00001653
Iteration 171/1000 | Loss: 0.00001653
Iteration 172/1000 | Loss: 0.00001653
Iteration 173/1000 | Loss: 0.00001653
Iteration 174/1000 | Loss: 0.00001653
Iteration 175/1000 | Loss: 0.00001653
Iteration 176/1000 | Loss: 0.00001653
Iteration 177/1000 | Loss: 0.00001653
Iteration 178/1000 | Loss: 0.00001653
Iteration 179/1000 | Loss: 0.00001653
Iteration 180/1000 | Loss: 0.00001652
Iteration 181/1000 | Loss: 0.00001652
Iteration 182/1000 | Loss: 0.00001652
Iteration 183/1000 | Loss: 0.00001652
Iteration 184/1000 | Loss: 0.00001652
Iteration 185/1000 | Loss: 0.00001652
Iteration 186/1000 | Loss: 0.00001652
Iteration 187/1000 | Loss: 0.00001651
Iteration 188/1000 | Loss: 0.00001651
Iteration 189/1000 | Loss: 0.00001651
Iteration 190/1000 | Loss: 0.00001651
Iteration 191/1000 | Loss: 0.00001651
Iteration 192/1000 | Loss: 0.00001651
Iteration 193/1000 | Loss: 0.00001650
Iteration 194/1000 | Loss: 0.00001650
Iteration 195/1000 | Loss: 0.00001650
Iteration 196/1000 | Loss: 0.00001650
Iteration 197/1000 | Loss: 0.00001650
Iteration 198/1000 | Loss: 0.00001649
Iteration 199/1000 | Loss: 0.00001649
Iteration 200/1000 | Loss: 0.00001649
Iteration 201/1000 | Loss: 0.00001649
Iteration 202/1000 | Loss: 0.00001648
Iteration 203/1000 | Loss: 0.00001648
Iteration 204/1000 | Loss: 0.00001648
Iteration 205/1000 | Loss: 0.00001648
Iteration 206/1000 | Loss: 0.00001648
Iteration 207/1000 | Loss: 0.00001647
Iteration 208/1000 | Loss: 0.00001647
Iteration 209/1000 | Loss: 0.00001647
Iteration 210/1000 | Loss: 0.00001647
Iteration 211/1000 | Loss: 0.00001647
Iteration 212/1000 | Loss: 0.00001647
Iteration 213/1000 | Loss: 0.00001647
Iteration 214/1000 | Loss: 0.00001646
Iteration 215/1000 | Loss: 0.00001646
Iteration 216/1000 | Loss: 0.00001646
Iteration 217/1000 | Loss: 0.00001646
Iteration 218/1000 | Loss: 0.00001646
Iteration 219/1000 | Loss: 0.00001646
Iteration 220/1000 | Loss: 0.00001646
Iteration 221/1000 | Loss: 0.00001646
Iteration 222/1000 | Loss: 0.00001646
Iteration 223/1000 | Loss: 0.00001646
Iteration 224/1000 | Loss: 0.00001646
Iteration 225/1000 | Loss: 0.00001646
Iteration 226/1000 | Loss: 0.00001646
Iteration 227/1000 | Loss: 0.00001645
Iteration 228/1000 | Loss: 0.00001645
Iteration 229/1000 | Loss: 0.00001645
Iteration 230/1000 | Loss: 0.00001645
Iteration 231/1000 | Loss: 0.00001645
Iteration 232/1000 | Loss: 0.00001645
Iteration 233/1000 | Loss: 0.00001645
Iteration 234/1000 | Loss: 0.00001644
Iteration 235/1000 | Loss: 0.00001644
Iteration 236/1000 | Loss: 0.00001644
Iteration 237/1000 | Loss: 0.00001644
Iteration 238/1000 | Loss: 0.00001644
Iteration 239/1000 | Loss: 0.00001644
Iteration 240/1000 | Loss: 0.00001644
Iteration 241/1000 | Loss: 0.00001644
Iteration 242/1000 | Loss: 0.00001644
Iteration 243/1000 | Loss: 0.00001643
Iteration 244/1000 | Loss: 0.00001643
Iteration 245/1000 | Loss: 0.00001643
Iteration 246/1000 | Loss: 0.00001643
Iteration 247/1000 | Loss: 0.00001643
Iteration 248/1000 | Loss: 0.00001643
Iteration 249/1000 | Loss: 0.00001643
Iteration 250/1000 | Loss: 0.00001643
Iteration 251/1000 | Loss: 0.00001643
Iteration 252/1000 | Loss: 0.00001643
Iteration 253/1000 | Loss: 0.00001642
Iteration 254/1000 | Loss: 0.00001642
Iteration 255/1000 | Loss: 0.00001642
Iteration 256/1000 | Loss: 0.00001642
Iteration 257/1000 | Loss: 0.00001642
Iteration 258/1000 | Loss: 0.00001642
Iteration 259/1000 | Loss: 0.00001642
Iteration 260/1000 | Loss: 0.00001642
Iteration 261/1000 | Loss: 0.00001642
Iteration 262/1000 | Loss: 0.00001642
Iteration 263/1000 | Loss: 0.00001642
Iteration 264/1000 | Loss: 0.00001642
Iteration 265/1000 | Loss: 0.00001642
Iteration 266/1000 | Loss: 0.00001642
Iteration 267/1000 | Loss: 0.00001642
Iteration 268/1000 | Loss: 0.00001642
Iteration 269/1000 | Loss: 0.00001642
Iteration 270/1000 | Loss: 0.00001642
Iteration 271/1000 | Loss: 0.00001641
Iteration 272/1000 | Loss: 0.00001641
Iteration 273/1000 | Loss: 0.00001641
Iteration 274/1000 | Loss: 0.00001641
Iteration 275/1000 | Loss: 0.00001641
Iteration 276/1000 | Loss: 0.00001641
Iteration 277/1000 | Loss: 0.00001641
Iteration 278/1000 | Loss: 0.00001641
Iteration 279/1000 | Loss: 0.00001641
Iteration 280/1000 | Loss: 0.00001641
Iteration 281/1000 | Loss: 0.00001641
Iteration 282/1000 | Loss: 0.00001641
Iteration 283/1000 | Loss: 0.00001641
Iteration 284/1000 | Loss: 0.00001641
Iteration 285/1000 | Loss: 0.00001641
Iteration 286/1000 | Loss: 0.00001640
Iteration 287/1000 | Loss: 0.00001640
Iteration 288/1000 | Loss: 0.00001640
Iteration 289/1000 | Loss: 0.00001640
Iteration 290/1000 | Loss: 0.00001640
Iteration 291/1000 | Loss: 0.00001640
Iteration 292/1000 | Loss: 0.00001640
Iteration 293/1000 | Loss: 0.00001640
Iteration 294/1000 | Loss: 0.00001640
Iteration 295/1000 | Loss: 0.00001640
Iteration 296/1000 | Loss: 0.00001640
Iteration 297/1000 | Loss: 0.00001640
Iteration 298/1000 | Loss: 0.00001640
Iteration 299/1000 | Loss: 0.00001640
Iteration 300/1000 | Loss: 0.00001640
Iteration 301/1000 | Loss: 0.00001640
Iteration 302/1000 | Loss: 0.00001640
Iteration 303/1000 | Loss: 0.00001640
Iteration 304/1000 | Loss: 0.00001640
Iteration 305/1000 | Loss: 0.00001640
Iteration 306/1000 | Loss: 0.00001640
Iteration 307/1000 | Loss: 0.00001640
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 307. Stopping optimization.
Last 5 losses: [1.6397143554058857e-05, 1.6397143554058857e-05, 1.6397143554058857e-05, 1.6397143554058857e-05, 1.6397143554058857e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6397143554058857e-05

Optimization complete. Final v2v error: 3.3828506469726562 mm

Highest mean error: 6.463791847229004 mm for frame 17

Lowest mean error: 2.8801109790802 mm for frame 132

Saving results

Total time: 144.49283862113953
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1077/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1077.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1077
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01027248
Iteration 2/25 | Loss: 0.01027247
Iteration 3/25 | Loss: 0.01027247
Iteration 4/25 | Loss: 0.00270507
Iteration 5/25 | Loss: 0.00185552
Iteration 6/25 | Loss: 0.00161571
Iteration 7/25 | Loss: 0.00153368
Iteration 8/25 | Loss: 0.00157720
Iteration 9/25 | Loss: 0.00150874
Iteration 10/25 | Loss: 0.00140033
Iteration 11/25 | Loss: 0.00135595
Iteration 12/25 | Loss: 0.00127707
Iteration 13/25 | Loss: 0.00124931
Iteration 14/25 | Loss: 0.00121224
Iteration 15/25 | Loss: 0.00118959
Iteration 16/25 | Loss: 0.00118056
Iteration 17/25 | Loss: 0.00117770
Iteration 18/25 | Loss: 0.00115545
Iteration 19/25 | Loss: 0.00115389
Iteration 20/25 | Loss: 0.00113648
Iteration 21/25 | Loss: 0.00113884
Iteration 22/25 | Loss: 0.00113020
Iteration 23/25 | Loss: 0.00111551
Iteration 24/25 | Loss: 0.00112065
Iteration 25/25 | Loss: 0.00112222

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.65313315
Iteration 2/25 | Loss: 0.00415222
Iteration 3/25 | Loss: 0.00236155
Iteration 4/25 | Loss: 0.00236154
Iteration 5/25 | Loss: 0.00236154
Iteration 6/25 | Loss: 0.00236154
Iteration 7/25 | Loss: 0.00236154
Iteration 8/25 | Loss: 0.00236154
Iteration 9/25 | Loss: 0.00236154
Iteration 10/25 | Loss: 0.00236154
Iteration 11/25 | Loss: 0.00236154
Iteration 12/25 | Loss: 0.00236154
Iteration 13/25 | Loss: 0.00236154
Iteration 14/25 | Loss: 0.00236154
Iteration 15/25 | Loss: 0.00236154
Iteration 16/25 | Loss: 0.00236154
Iteration 17/25 | Loss: 0.00236154
Iteration 18/25 | Loss: 0.00236154
Iteration 19/25 | Loss: 0.00236154
Iteration 20/25 | Loss: 0.00236154
Iteration 21/25 | Loss: 0.00236154
Iteration 22/25 | Loss: 0.00236154
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00236154324375093, 0.00236154324375093, 0.00236154324375093, 0.00236154324375093, 0.00236154324375093]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00236154324375093

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00236154
Iteration 2/1000 | Loss: 0.00078912
Iteration 3/1000 | Loss: 0.00071372
Iteration 4/1000 | Loss: 0.00146743
Iteration 5/1000 | Loss: 0.00082564
Iteration 6/1000 | Loss: 0.00182469
Iteration 7/1000 | Loss: 0.00149612
Iteration 8/1000 | Loss: 0.00060972
Iteration 9/1000 | Loss: 0.00127983
Iteration 10/1000 | Loss: 0.00082617
Iteration 11/1000 | Loss: 0.00063470
Iteration 12/1000 | Loss: 0.00086469
Iteration 13/1000 | Loss: 0.00135781
Iteration 14/1000 | Loss: 0.00202500
Iteration 15/1000 | Loss: 0.00118347
Iteration 16/1000 | Loss: 0.00104173
Iteration 17/1000 | Loss: 0.00076443
Iteration 18/1000 | Loss: 0.00040452
Iteration 19/1000 | Loss: 0.00055460
Iteration 20/1000 | Loss: 0.00056278
Iteration 21/1000 | Loss: 0.00052396
Iteration 22/1000 | Loss: 0.00052066
Iteration 23/1000 | Loss: 0.00028346
Iteration 24/1000 | Loss: 0.00033252
Iteration 25/1000 | Loss: 0.00054137
Iteration 26/1000 | Loss: 0.00074789
Iteration 27/1000 | Loss: 0.00079370
Iteration 28/1000 | Loss: 0.00052994
Iteration 29/1000 | Loss: 0.00042392
Iteration 30/1000 | Loss: 0.00043231
Iteration 31/1000 | Loss: 0.00068826
Iteration 32/1000 | Loss: 0.00026722
Iteration 33/1000 | Loss: 0.00052636
Iteration 34/1000 | Loss: 0.00106478
Iteration 35/1000 | Loss: 0.00112917
Iteration 36/1000 | Loss: 0.00089535
Iteration 37/1000 | Loss: 0.00044484
Iteration 38/1000 | Loss: 0.00022817
Iteration 39/1000 | Loss: 0.00022346
Iteration 40/1000 | Loss: 0.00022436
Iteration 41/1000 | Loss: 0.00022163
Iteration 42/1000 | Loss: 0.00018692
Iteration 43/1000 | Loss: 0.00023916
Iteration 44/1000 | Loss: 0.00025984
Iteration 45/1000 | Loss: 0.00014268
Iteration 46/1000 | Loss: 0.00028531
Iteration 47/1000 | Loss: 0.00013404
Iteration 48/1000 | Loss: 0.00013755
Iteration 49/1000 | Loss: 0.00021238
Iteration 50/1000 | Loss: 0.00024546
Iteration 51/1000 | Loss: 0.00018143
Iteration 52/1000 | Loss: 0.00013382
Iteration 53/1000 | Loss: 0.00033833
Iteration 54/1000 | Loss: 0.00027051
Iteration 55/1000 | Loss: 0.00028598
Iteration 56/1000 | Loss: 0.00025399
Iteration 57/1000 | Loss: 0.00107742
Iteration 58/1000 | Loss: 0.00045155
Iteration 59/1000 | Loss: 0.00024422
Iteration 60/1000 | Loss: 0.00016954
Iteration 61/1000 | Loss: 0.00020454
Iteration 62/1000 | Loss: 0.00012662
Iteration 63/1000 | Loss: 0.00028821
Iteration 64/1000 | Loss: 0.00015811
Iteration 65/1000 | Loss: 0.00054052
Iteration 66/1000 | Loss: 0.00048279
Iteration 67/1000 | Loss: 0.00023181
Iteration 68/1000 | Loss: 0.00024821
Iteration 69/1000 | Loss: 0.00023003
Iteration 70/1000 | Loss: 0.00021998
Iteration 71/1000 | Loss: 0.00023001
Iteration 72/1000 | Loss: 0.00012225
Iteration 73/1000 | Loss: 0.00019619
Iteration 74/1000 | Loss: 0.00014690
Iteration 75/1000 | Loss: 0.00011752
Iteration 76/1000 | Loss: 0.00041419
Iteration 77/1000 | Loss: 0.00025974
Iteration 78/1000 | Loss: 0.00090413
Iteration 79/1000 | Loss: 0.00032035
Iteration 80/1000 | Loss: 0.00010999
Iteration 81/1000 | Loss: 0.00011974
Iteration 82/1000 | Loss: 0.00019098
Iteration 83/1000 | Loss: 0.00011526
Iteration 84/1000 | Loss: 0.00014749
Iteration 85/1000 | Loss: 0.00011284
Iteration 86/1000 | Loss: 0.00011697
Iteration 87/1000 | Loss: 0.00011401
Iteration 88/1000 | Loss: 0.00011446
Iteration 89/1000 | Loss: 0.00014166
Iteration 90/1000 | Loss: 0.00012271
Iteration 91/1000 | Loss: 0.00022499
Iteration 92/1000 | Loss: 0.00045048
Iteration 93/1000 | Loss: 0.00022080
Iteration 94/1000 | Loss: 0.00011166
Iteration 95/1000 | Loss: 0.00011183
Iteration 96/1000 | Loss: 0.00024472
Iteration 97/1000 | Loss: 0.00027623
Iteration 98/1000 | Loss: 0.00014653
Iteration 99/1000 | Loss: 0.00010201
Iteration 100/1000 | Loss: 0.00010130
Iteration 101/1000 | Loss: 0.00010757
Iteration 102/1000 | Loss: 0.00011406
Iteration 103/1000 | Loss: 0.00010421
Iteration 104/1000 | Loss: 0.00011474
Iteration 105/1000 | Loss: 0.00022363
Iteration 106/1000 | Loss: 0.00010467
Iteration 107/1000 | Loss: 0.00021765
Iteration 108/1000 | Loss: 0.00028958
Iteration 109/1000 | Loss: 0.00163741
Iteration 110/1000 | Loss: 0.00063113
Iteration 111/1000 | Loss: 0.00025778
Iteration 112/1000 | Loss: 0.00016585
Iteration 113/1000 | Loss: 0.00051321
Iteration 114/1000 | Loss: 0.00016738
Iteration 115/1000 | Loss: 0.00016222
Iteration 116/1000 | Loss: 0.00018065
Iteration 117/1000 | Loss: 0.00017606
Iteration 118/1000 | Loss: 0.00060006
Iteration 119/1000 | Loss: 0.00070745
Iteration 120/1000 | Loss: 0.00019508
Iteration 121/1000 | Loss: 0.00046837
Iteration 122/1000 | Loss: 0.00058097
Iteration 123/1000 | Loss: 0.00021747
Iteration 124/1000 | Loss: 0.00009934
Iteration 125/1000 | Loss: 0.00025069
Iteration 126/1000 | Loss: 0.00071633
Iteration 127/1000 | Loss: 0.00030667
Iteration 128/1000 | Loss: 0.00045823
Iteration 129/1000 | Loss: 0.00009753
Iteration 130/1000 | Loss: 0.00011313
Iteration 131/1000 | Loss: 0.00009373
Iteration 132/1000 | Loss: 0.00009256
Iteration 133/1000 | Loss: 0.00056032
Iteration 134/1000 | Loss: 0.00019410
Iteration 135/1000 | Loss: 0.00036609
Iteration 136/1000 | Loss: 0.00009534
Iteration 137/1000 | Loss: 0.00009268
Iteration 138/1000 | Loss: 0.00009113
Iteration 139/1000 | Loss: 0.00053540
Iteration 140/1000 | Loss: 0.00008990
Iteration 141/1000 | Loss: 0.00028311
Iteration 142/1000 | Loss: 0.00021651
Iteration 143/1000 | Loss: 0.00027675
Iteration 144/1000 | Loss: 0.00015562
Iteration 145/1000 | Loss: 0.00026549
Iteration 146/1000 | Loss: 0.00013953
Iteration 147/1000 | Loss: 0.00009194
Iteration 148/1000 | Loss: 0.00023055
Iteration 149/1000 | Loss: 0.00016523
Iteration 150/1000 | Loss: 0.00022703
Iteration 151/1000 | Loss: 0.00009283
Iteration 152/1000 | Loss: 0.00009080
Iteration 153/1000 | Loss: 0.00008996
Iteration 154/1000 | Loss: 0.00008930
Iteration 155/1000 | Loss: 0.00008882
Iteration 156/1000 | Loss: 0.00022472
Iteration 157/1000 | Loss: 0.00009430
Iteration 158/1000 | Loss: 0.00009122
Iteration 159/1000 | Loss: 0.00008963
Iteration 160/1000 | Loss: 0.00021083
Iteration 161/1000 | Loss: 0.00018908
Iteration 162/1000 | Loss: 0.00015217
Iteration 163/1000 | Loss: 0.00075184
Iteration 164/1000 | Loss: 0.00022969
Iteration 165/1000 | Loss: 0.00021083
Iteration 166/1000 | Loss: 0.00019969
Iteration 167/1000 | Loss: 0.00015936
Iteration 168/1000 | Loss: 0.00011924
Iteration 169/1000 | Loss: 0.00061708
Iteration 170/1000 | Loss: 0.00022222
Iteration 171/1000 | Loss: 0.00027244
Iteration 172/1000 | Loss: 0.00011185
Iteration 173/1000 | Loss: 0.00009837
Iteration 174/1000 | Loss: 0.00009391
Iteration 175/1000 | Loss: 0.00009022
Iteration 176/1000 | Loss: 0.00008850
Iteration 177/1000 | Loss: 0.00008739
Iteration 178/1000 | Loss: 0.00008665
Iteration 179/1000 | Loss: 0.00008557
Iteration 180/1000 | Loss: 0.00008502
Iteration 181/1000 | Loss: 0.00008462
Iteration 182/1000 | Loss: 0.00008436
Iteration 183/1000 | Loss: 0.00010463
Iteration 184/1000 | Loss: 0.00009603
Iteration 185/1000 | Loss: 0.00010413
Iteration 186/1000 | Loss: 0.00009550
Iteration 187/1000 | Loss: 0.00009962
Iteration 188/1000 | Loss: 0.00011550
Iteration 189/1000 | Loss: 0.00011668
Iteration 190/1000 | Loss: 0.00009620
Iteration 191/1000 | Loss: 0.00008696
Iteration 192/1000 | Loss: 0.00008595
Iteration 193/1000 | Loss: 0.00010310
Iteration 194/1000 | Loss: 0.00008568
Iteration 195/1000 | Loss: 0.00010204
Iteration 196/1000 | Loss: 0.00009213
Iteration 197/1000 | Loss: 0.00009911
Iteration 198/1000 | Loss: 0.00010984
Iteration 199/1000 | Loss: 0.00010280
Iteration 200/1000 | Loss: 0.00009530
Iteration 201/1000 | Loss: 0.00010176
Iteration 202/1000 | Loss: 0.00009868
Iteration 203/1000 | Loss: 0.00009674
Iteration 204/1000 | Loss: 0.00010427
Iteration 205/1000 | Loss: 0.00009906
Iteration 206/1000 | Loss: 0.00008855
Iteration 207/1000 | Loss: 0.00008724
Iteration 208/1000 | Loss: 0.00008645
Iteration 209/1000 | Loss: 0.00008579
Iteration 210/1000 | Loss: 0.00008528
Iteration 211/1000 | Loss: 0.00008497
Iteration 212/1000 | Loss: 0.00009419
Iteration 213/1000 | Loss: 0.00008662
Iteration 214/1000 | Loss: 0.00009545
Iteration 215/1000 | Loss: 0.00009492
Iteration 216/1000 | Loss: 0.00009272
Iteration 217/1000 | Loss: 0.00009925
Iteration 218/1000 | Loss: 0.00009482
Iteration 219/1000 | Loss: 0.00009480
Iteration 220/1000 | Loss: 0.00008682
Iteration 221/1000 | Loss: 0.00009428
Iteration 222/1000 | Loss: 0.00009573
Iteration 223/1000 | Loss: 0.00009160
Iteration 224/1000 | Loss: 0.00009305
Iteration 225/1000 | Loss: 0.00009396
Iteration 226/1000 | Loss: 0.00009278
Iteration 227/1000 | Loss: 0.00009381
Iteration 228/1000 | Loss: 0.00009216
Iteration 229/1000 | Loss: 0.00009325
Iteration 230/1000 | Loss: 0.00008938
Iteration 231/1000 | Loss: 0.00009429
Iteration 232/1000 | Loss: 0.00009729
Iteration 233/1000 | Loss: 0.00009546
Iteration 234/1000 | Loss: 0.00009333
Iteration 235/1000 | Loss: 0.00008984
Iteration 236/1000 | Loss: 0.00009810
Iteration 237/1000 | Loss: 0.00008493
Iteration 238/1000 | Loss: 0.00008450
Iteration 239/1000 | Loss: 0.00008424
Iteration 240/1000 | Loss: 0.00008407
Iteration 241/1000 | Loss: 0.00008406
Iteration 242/1000 | Loss: 0.00008398
Iteration 243/1000 | Loss: 0.00008398
Iteration 244/1000 | Loss: 0.00008395
Iteration 245/1000 | Loss: 0.00008395
Iteration 246/1000 | Loss: 0.00008395
Iteration 247/1000 | Loss: 0.00008394
Iteration 248/1000 | Loss: 0.00008392
Iteration 249/1000 | Loss: 0.00008392
Iteration 250/1000 | Loss: 0.00008391
Iteration 251/1000 | Loss: 0.00008391
Iteration 252/1000 | Loss: 0.00008390
Iteration 253/1000 | Loss: 0.00008390
Iteration 254/1000 | Loss: 0.00008389
Iteration 255/1000 | Loss: 0.00008388
Iteration 256/1000 | Loss: 0.00008387
Iteration 257/1000 | Loss: 0.00008387
Iteration 258/1000 | Loss: 0.00008384
Iteration 259/1000 | Loss: 0.00008382
Iteration 260/1000 | Loss: 0.00008381
Iteration 261/1000 | Loss: 0.00008381
Iteration 262/1000 | Loss: 0.00008373
Iteration 263/1000 | Loss: 0.00008370
Iteration 264/1000 | Loss: 0.00008368
Iteration 265/1000 | Loss: 0.00008368
Iteration 266/1000 | Loss: 0.00008367
Iteration 267/1000 | Loss: 0.00008367
Iteration 268/1000 | Loss: 0.00008367
Iteration 269/1000 | Loss: 0.00008367
Iteration 270/1000 | Loss: 0.00008367
Iteration 271/1000 | Loss: 0.00008367
Iteration 272/1000 | Loss: 0.00008367
Iteration 273/1000 | Loss: 0.00008367
Iteration 274/1000 | Loss: 0.00008367
Iteration 275/1000 | Loss: 0.00008366
Iteration 276/1000 | Loss: 0.00008366
Iteration 277/1000 | Loss: 0.00008366
Iteration 278/1000 | Loss: 0.00008366
Iteration 279/1000 | Loss: 0.00008366
Iteration 280/1000 | Loss: 0.00008366
Iteration 281/1000 | Loss: 0.00008365
Iteration 282/1000 | Loss: 0.00008364
Iteration 283/1000 | Loss: 0.00008364
Iteration 284/1000 | Loss: 0.00008364
Iteration 285/1000 | Loss: 0.00008363
Iteration 286/1000 | Loss: 0.00008363
Iteration 287/1000 | Loss: 0.00008363
Iteration 288/1000 | Loss: 0.00008362
Iteration 289/1000 | Loss: 0.00008362
Iteration 290/1000 | Loss: 0.00008362
Iteration 291/1000 | Loss: 0.00008362
Iteration 292/1000 | Loss: 0.00008362
Iteration 293/1000 | Loss: 0.00008361
Iteration 294/1000 | Loss: 0.00008361
Iteration 295/1000 | Loss: 0.00008361
Iteration 296/1000 | Loss: 0.00008361
Iteration 297/1000 | Loss: 0.00008360
Iteration 298/1000 | Loss: 0.00008360
Iteration 299/1000 | Loss: 0.00008360
Iteration 300/1000 | Loss: 0.00008360
Iteration 301/1000 | Loss: 0.00008360
Iteration 302/1000 | Loss: 0.00008360
Iteration 303/1000 | Loss: 0.00008360
Iteration 304/1000 | Loss: 0.00008359
Iteration 305/1000 | Loss: 0.00008359
Iteration 306/1000 | Loss: 0.00008359
Iteration 307/1000 | Loss: 0.00008359
Iteration 308/1000 | Loss: 0.00008359
Iteration 309/1000 | Loss: 0.00008359
Iteration 310/1000 | Loss: 0.00008358
Iteration 311/1000 | Loss: 0.00008358
Iteration 312/1000 | Loss: 0.00008357
Iteration 313/1000 | Loss: 0.00008357
Iteration 314/1000 | Loss: 0.00008357
Iteration 315/1000 | Loss: 0.00008357
Iteration 316/1000 | Loss: 0.00008356
Iteration 317/1000 | Loss: 0.00008356
Iteration 318/1000 | Loss: 0.00008356
Iteration 319/1000 | Loss: 0.00008356
Iteration 320/1000 | Loss: 0.00008356
Iteration 321/1000 | Loss: 0.00008356
Iteration 322/1000 | Loss: 0.00008356
Iteration 323/1000 | Loss: 0.00008356
Iteration 324/1000 | Loss: 0.00008356
Iteration 325/1000 | Loss: 0.00008356
Iteration 326/1000 | Loss: 0.00008356
Iteration 327/1000 | Loss: 0.00008355
Iteration 328/1000 | Loss: 0.00008355
Iteration 329/1000 | Loss: 0.00008355
Iteration 330/1000 | Loss: 0.00008355
Iteration 331/1000 | Loss: 0.00008355
Iteration 332/1000 | Loss: 0.00008355
Iteration 333/1000 | Loss: 0.00008354
Iteration 334/1000 | Loss: 0.00008354
Iteration 335/1000 | Loss: 0.00008354
Iteration 336/1000 | Loss: 0.00008354
Iteration 337/1000 | Loss: 0.00008354
Iteration 338/1000 | Loss: 0.00008354
Iteration 339/1000 | Loss: 0.00008354
Iteration 340/1000 | Loss: 0.00008354
Iteration 341/1000 | Loss: 0.00008354
Iteration 342/1000 | Loss: 0.00008354
Iteration 343/1000 | Loss: 0.00008354
Iteration 344/1000 | Loss: 0.00008354
Iteration 345/1000 | Loss: 0.00008354
Iteration 346/1000 | Loss: 0.00008354
Iteration 347/1000 | Loss: 0.00008354
Iteration 348/1000 | Loss: 0.00008354
Iteration 349/1000 | Loss: 0.00008354
Iteration 350/1000 | Loss: 0.00008354
Iteration 351/1000 | Loss: 0.00008354
Iteration 352/1000 | Loss: 0.00008353
Iteration 353/1000 | Loss: 0.00008353
Iteration 354/1000 | Loss: 0.00008353
Iteration 355/1000 | Loss: 0.00008353
Iteration 356/1000 | Loss: 0.00008353
Iteration 357/1000 | Loss: 0.00008353
Iteration 358/1000 | Loss: 0.00008353
Iteration 359/1000 | Loss: 0.00008353
Iteration 360/1000 | Loss: 0.00008353
Iteration 361/1000 | Loss: 0.00008353
Iteration 362/1000 | Loss: 0.00008353
Iteration 363/1000 | Loss: 0.00008353
Iteration 364/1000 | Loss: 0.00008352
Iteration 365/1000 | Loss: 0.00008352
Iteration 366/1000 | Loss: 0.00008352
Iteration 367/1000 | Loss: 0.00008352
Iteration 368/1000 | Loss: 0.00008352
Iteration 369/1000 | Loss: 0.00008352
Iteration 370/1000 | Loss: 0.00008352
Iteration 371/1000 | Loss: 0.00008352
Iteration 372/1000 | Loss: 0.00008352
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 372. Stopping optimization.
Last 5 losses: [8.352431905223057e-05, 8.352431905223057e-05, 8.352431905223057e-05, 8.352431905223057e-05, 8.352431905223057e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.352431905223057e-05

Optimization complete. Final v2v error: 5.479078769683838 mm

Highest mean error: 12.434782981872559 mm for frame 201

Lowest mean error: 3.5044915676116943 mm for frame 36

Saving results

Total time: 452.73397517204285
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1047/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1047.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1047
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00793847
Iteration 2/25 | Loss: 0.00146137
Iteration 3/25 | Loss: 0.00120315
Iteration 4/25 | Loss: 0.00115468
Iteration 5/25 | Loss: 0.00113975
Iteration 6/25 | Loss: 0.00113621
Iteration 7/25 | Loss: 0.00113568
Iteration 8/25 | Loss: 0.00113568
Iteration 9/25 | Loss: 0.00113568
Iteration 10/25 | Loss: 0.00113568
Iteration 11/25 | Loss: 0.00113568
Iteration 12/25 | Loss: 0.00113568
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0011356777977198362, 0.0011356777977198362, 0.0011356777977198362, 0.0011356777977198362, 0.0011356777977198362]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011356777977198362

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.94032186
Iteration 2/25 | Loss: 0.00079511
Iteration 3/25 | Loss: 0.00079511
Iteration 4/25 | Loss: 0.00079511
Iteration 5/25 | Loss: 0.00079511
Iteration 6/25 | Loss: 0.00079511
Iteration 7/25 | Loss: 0.00079511
Iteration 8/25 | Loss: 0.00079511
Iteration 9/25 | Loss: 0.00079511
Iteration 10/25 | Loss: 0.00079511
Iteration 11/25 | Loss: 0.00079511
Iteration 12/25 | Loss: 0.00079511
Iteration 13/25 | Loss: 0.00079511
Iteration 14/25 | Loss: 0.00079511
Iteration 15/25 | Loss: 0.00079511
Iteration 16/25 | Loss: 0.00079511
Iteration 17/25 | Loss: 0.00079511
Iteration 18/25 | Loss: 0.00079511
Iteration 19/25 | Loss: 0.00079511
Iteration 20/25 | Loss: 0.00079511
Iteration 21/25 | Loss: 0.00079511
Iteration 22/25 | Loss: 0.00079511
Iteration 23/25 | Loss: 0.00079511
Iteration 24/25 | Loss: 0.00079511
Iteration 25/25 | Loss: 0.00079511
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.0007951108855195343, 0.0007951108855195343, 0.0007951108855195343, 0.0007951108855195343, 0.0007951108855195343]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007951108855195343

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00079511
Iteration 2/1000 | Loss: 0.00009206
Iteration 3/1000 | Loss: 0.00007246
Iteration 4/1000 | Loss: 0.00006681
Iteration 5/1000 | Loss: 0.00006341
Iteration 6/1000 | Loss: 0.00006091
Iteration 7/1000 | Loss: 0.00005943
Iteration 8/1000 | Loss: 0.00005863
Iteration 9/1000 | Loss: 0.00005809
Iteration 10/1000 | Loss: 0.00005765
Iteration 11/1000 | Loss: 0.00005733
Iteration 12/1000 | Loss: 0.00005711
Iteration 13/1000 | Loss: 0.00005683
Iteration 14/1000 | Loss: 0.00005658
Iteration 15/1000 | Loss: 0.00005653
Iteration 16/1000 | Loss: 0.00005640
Iteration 17/1000 | Loss: 0.00005638
Iteration 18/1000 | Loss: 0.00005628
Iteration 19/1000 | Loss: 0.00005624
Iteration 20/1000 | Loss: 0.00005622
Iteration 21/1000 | Loss: 0.00005606
Iteration 22/1000 | Loss: 0.00005594
Iteration 23/1000 | Loss: 0.00005579
Iteration 24/1000 | Loss: 0.00005572
Iteration 25/1000 | Loss: 0.00005569
Iteration 26/1000 | Loss: 0.00005569
Iteration 27/1000 | Loss: 0.00005566
Iteration 28/1000 | Loss: 0.00005565
Iteration 29/1000 | Loss: 0.00005547
Iteration 30/1000 | Loss: 0.00005544
Iteration 31/1000 | Loss: 0.00005543
Iteration 32/1000 | Loss: 0.00005542
Iteration 33/1000 | Loss: 0.00005541
Iteration 34/1000 | Loss: 0.00005531
Iteration 35/1000 | Loss: 0.00005530
Iteration 36/1000 | Loss: 0.00005530
Iteration 37/1000 | Loss: 0.00005529
Iteration 38/1000 | Loss: 0.00005529
Iteration 39/1000 | Loss: 0.00005528
Iteration 40/1000 | Loss: 0.00005528
Iteration 41/1000 | Loss: 0.00005527
Iteration 42/1000 | Loss: 0.00005527
Iteration 43/1000 | Loss: 0.00005527
Iteration 44/1000 | Loss: 0.00005526
Iteration 45/1000 | Loss: 0.00005526
Iteration 46/1000 | Loss: 0.00005526
Iteration 47/1000 | Loss: 0.00005525
Iteration 48/1000 | Loss: 0.00005525
Iteration 49/1000 | Loss: 0.00005525
Iteration 50/1000 | Loss: 0.00005524
Iteration 51/1000 | Loss: 0.00005524
Iteration 52/1000 | Loss: 0.00005524
Iteration 53/1000 | Loss: 0.00005524
Iteration 54/1000 | Loss: 0.00005523
Iteration 55/1000 | Loss: 0.00005523
Iteration 56/1000 | Loss: 0.00005523
Iteration 57/1000 | Loss: 0.00005522
Iteration 58/1000 | Loss: 0.00005522
Iteration 59/1000 | Loss: 0.00005522
Iteration 60/1000 | Loss: 0.00005522
Iteration 61/1000 | Loss: 0.00005521
Iteration 62/1000 | Loss: 0.00005521
Iteration 63/1000 | Loss: 0.00005521
Iteration 64/1000 | Loss: 0.00005521
Iteration 65/1000 | Loss: 0.00005521
Iteration 66/1000 | Loss: 0.00005521
Iteration 67/1000 | Loss: 0.00005520
Iteration 68/1000 | Loss: 0.00005520
Iteration 69/1000 | Loss: 0.00005520
Iteration 70/1000 | Loss: 0.00005520
Iteration 71/1000 | Loss: 0.00005520
Iteration 72/1000 | Loss: 0.00005520
Iteration 73/1000 | Loss: 0.00005519
Iteration 74/1000 | Loss: 0.00005519
Iteration 75/1000 | Loss: 0.00005519
Iteration 76/1000 | Loss: 0.00005518
Iteration 77/1000 | Loss: 0.00005518
Iteration 78/1000 | Loss: 0.00005518
Iteration 79/1000 | Loss: 0.00005518
Iteration 80/1000 | Loss: 0.00005518
Iteration 81/1000 | Loss: 0.00005518
Iteration 82/1000 | Loss: 0.00005517
Iteration 83/1000 | Loss: 0.00005517
Iteration 84/1000 | Loss: 0.00005517
Iteration 85/1000 | Loss: 0.00005517
Iteration 86/1000 | Loss: 0.00005517
Iteration 87/1000 | Loss: 0.00005516
Iteration 88/1000 | Loss: 0.00005516
Iteration 89/1000 | Loss: 0.00005516
Iteration 90/1000 | Loss: 0.00005516
Iteration 91/1000 | Loss: 0.00005516
Iteration 92/1000 | Loss: 0.00005515
Iteration 93/1000 | Loss: 0.00005515
Iteration 94/1000 | Loss: 0.00005515
Iteration 95/1000 | Loss: 0.00005514
Iteration 96/1000 | Loss: 0.00005514
Iteration 97/1000 | Loss: 0.00005514
Iteration 98/1000 | Loss: 0.00005514
Iteration 99/1000 | Loss: 0.00005514
Iteration 100/1000 | Loss: 0.00005514
Iteration 101/1000 | Loss: 0.00005514
Iteration 102/1000 | Loss: 0.00005514
Iteration 103/1000 | Loss: 0.00005513
Iteration 104/1000 | Loss: 0.00005513
Iteration 105/1000 | Loss: 0.00005513
Iteration 106/1000 | Loss: 0.00005513
Iteration 107/1000 | Loss: 0.00005513
Iteration 108/1000 | Loss: 0.00005513
Iteration 109/1000 | Loss: 0.00005513
Iteration 110/1000 | Loss: 0.00005513
Iteration 111/1000 | Loss: 0.00005513
Iteration 112/1000 | Loss: 0.00005513
Iteration 113/1000 | Loss: 0.00005513
Iteration 114/1000 | Loss: 0.00005513
Iteration 115/1000 | Loss: 0.00005513
Iteration 116/1000 | Loss: 0.00005512
Iteration 117/1000 | Loss: 0.00005512
Iteration 118/1000 | Loss: 0.00005512
Iteration 119/1000 | Loss: 0.00005512
Iteration 120/1000 | Loss: 0.00005512
Iteration 121/1000 | Loss: 0.00005512
Iteration 122/1000 | Loss: 0.00005512
Iteration 123/1000 | Loss: 0.00005512
Iteration 124/1000 | Loss: 0.00005512
Iteration 125/1000 | Loss: 0.00005512
Iteration 126/1000 | Loss: 0.00005512
Iteration 127/1000 | Loss: 0.00005512
Iteration 128/1000 | Loss: 0.00005512
Iteration 129/1000 | Loss: 0.00005512
Iteration 130/1000 | Loss: 0.00005512
Iteration 131/1000 | Loss: 0.00005512
Iteration 132/1000 | Loss: 0.00005512
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 132. Stopping optimization.
Last 5 losses: [5.512090865522623e-05, 5.512090865522623e-05, 5.512090865522623e-05, 5.512090865522623e-05, 5.512090865522623e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.512090865522623e-05

Optimization complete. Final v2v error: 5.842516899108887 mm

Highest mean error: 7.9735870361328125 mm for frame 120

Lowest mean error: 4.753388404846191 mm for frame 155

Saving results

Total time: 56.51920247077942
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_eric_posed_035/1059/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1059.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_eric_posed_035/1059
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00591345
Iteration 2/25 | Loss: 0.00124728
Iteration 3/25 | Loss: 0.00093425
Iteration 4/25 | Loss: 0.00089113
Iteration 5/25 | Loss: 0.00087994
Iteration 6/25 | Loss: 0.00087874
Iteration 7/25 | Loss: 0.00087874
Iteration 8/25 | Loss: 0.00087874
Iteration 9/25 | Loss: 0.00087874
Iteration 10/25 | Loss: 0.00087874
Iteration 11/25 | Loss: 0.00087874
Iteration 12/25 | Loss: 0.00087874
Iteration 13/25 | Loss: 0.00087874
Iteration 14/25 | Loss: 0.00087874
Iteration 15/25 | Loss: 0.00087874
Iteration 16/25 | Loss: 0.00087874
Iteration 17/25 | Loss: 0.00087874
Iteration 18/25 | Loss: 0.00087874
Iteration 19/25 | Loss: 0.00087874
Iteration 20/25 | Loss: 0.00087874
Iteration 21/25 | Loss: 0.00087874
Iteration 22/25 | Loss: 0.00087874
Iteration 23/25 | Loss: 0.00087874
Iteration 24/25 | Loss: 0.00087874
Iteration 25/25 | Loss: 0.00087874

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.06185579
Iteration 2/25 | Loss: 0.00050496
Iteration 3/25 | Loss: 0.00050496
Iteration 4/25 | Loss: 0.00050496
Iteration 5/25 | Loss: 0.00050496
Iteration 6/25 | Loss: 0.00050496
Iteration 7/25 | Loss: 0.00050496
Iteration 8/25 | Loss: 0.00050496
Iteration 9/25 | Loss: 0.00050496
Iteration 10/25 | Loss: 0.00050496
Iteration 11/25 | Loss: 0.00050496
Iteration 12/25 | Loss: 0.00050496
Iteration 13/25 | Loss: 0.00050496
Iteration 14/25 | Loss: 0.00050496
Iteration 15/25 | Loss: 0.00050496
Iteration 16/25 | Loss: 0.00050496
Iteration 17/25 | Loss: 0.00050496
Iteration 18/25 | Loss: 0.00050496
Iteration 19/25 | Loss: 0.00050496
Iteration 20/25 | Loss: 0.00050496
Iteration 21/25 | Loss: 0.00050496
Iteration 22/25 | Loss: 0.00050496
Iteration 23/25 | Loss: 0.00050496
Iteration 24/25 | Loss: 0.00050496
Iteration 25/25 | Loss: 0.00050496

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050496
Iteration 2/1000 | Loss: 0.00003405
Iteration 3/1000 | Loss: 0.00002620
Iteration 4/1000 | Loss: 0.00002347
Iteration 5/1000 | Loss: 0.00002169
Iteration 6/1000 | Loss: 0.00002108
Iteration 7/1000 | Loss: 0.00002057
Iteration 8/1000 | Loss: 0.00002029
Iteration 9/1000 | Loss: 0.00002018
Iteration 10/1000 | Loss: 0.00001995
Iteration 11/1000 | Loss: 0.00001983
Iteration 12/1000 | Loss: 0.00001981
Iteration 13/1000 | Loss: 0.00001978
Iteration 14/1000 | Loss: 0.00001977
Iteration 15/1000 | Loss: 0.00001975
Iteration 16/1000 | Loss: 0.00001975
Iteration 17/1000 | Loss: 0.00001974
Iteration 18/1000 | Loss: 0.00001973
Iteration 19/1000 | Loss: 0.00001973
Iteration 20/1000 | Loss: 0.00001972
Iteration 21/1000 | Loss: 0.00001972
Iteration 22/1000 | Loss: 0.00001970
Iteration 23/1000 | Loss: 0.00001970
Iteration 24/1000 | Loss: 0.00001966
Iteration 25/1000 | Loss: 0.00001961
Iteration 26/1000 | Loss: 0.00001960
Iteration 27/1000 | Loss: 0.00001959
Iteration 28/1000 | Loss: 0.00001958
Iteration 29/1000 | Loss: 0.00001958
Iteration 30/1000 | Loss: 0.00001958
Iteration 31/1000 | Loss: 0.00001958
Iteration 32/1000 | Loss: 0.00001957
Iteration 33/1000 | Loss: 0.00001956
Iteration 34/1000 | Loss: 0.00001956
Iteration 35/1000 | Loss: 0.00001956
Iteration 36/1000 | Loss: 0.00001956
Iteration 37/1000 | Loss: 0.00001956
Iteration 38/1000 | Loss: 0.00001956
Iteration 39/1000 | Loss: 0.00001956
Iteration 40/1000 | Loss: 0.00001956
Iteration 41/1000 | Loss: 0.00001956
Iteration 42/1000 | Loss: 0.00001955
Iteration 43/1000 | Loss: 0.00001955
Iteration 44/1000 | Loss: 0.00001955
Iteration 45/1000 | Loss: 0.00001955
Iteration 46/1000 | Loss: 0.00001955
Iteration 47/1000 | Loss: 0.00001955
Iteration 48/1000 | Loss: 0.00001955
Iteration 49/1000 | Loss: 0.00001953
Iteration 50/1000 | Loss: 0.00001953
Iteration 51/1000 | Loss: 0.00001953
Iteration 52/1000 | Loss: 0.00001953
Iteration 53/1000 | Loss: 0.00001952
Iteration 54/1000 | Loss: 0.00001952
Iteration 55/1000 | Loss: 0.00001952
Iteration 56/1000 | Loss: 0.00001952
Iteration 57/1000 | Loss: 0.00001952
Iteration 58/1000 | Loss: 0.00001952
Iteration 59/1000 | Loss: 0.00001952
Iteration 60/1000 | Loss: 0.00001951
Iteration 61/1000 | Loss: 0.00001951
Iteration 62/1000 | Loss: 0.00001951
Iteration 63/1000 | Loss: 0.00001951
Iteration 64/1000 | Loss: 0.00001951
Iteration 65/1000 | Loss: 0.00001951
Iteration 66/1000 | Loss: 0.00001951
Iteration 67/1000 | Loss: 0.00001951
Iteration 68/1000 | Loss: 0.00001951
Iteration 69/1000 | Loss: 0.00001951
Iteration 70/1000 | Loss: 0.00001950
Iteration 71/1000 | Loss: 0.00001950
Iteration 72/1000 | Loss: 0.00001950
Iteration 73/1000 | Loss: 0.00001950
Iteration 74/1000 | Loss: 0.00001950
Iteration 75/1000 | Loss: 0.00001950
Iteration 76/1000 | Loss: 0.00001950
Iteration 77/1000 | Loss: 0.00001950
Iteration 78/1000 | Loss: 0.00001950
Iteration 79/1000 | Loss: 0.00001950
Iteration 80/1000 | Loss: 0.00001950
Iteration 81/1000 | Loss: 0.00001950
Iteration 82/1000 | Loss: 0.00001949
Iteration 83/1000 | Loss: 0.00001949
Iteration 84/1000 | Loss: 0.00001949
Iteration 85/1000 | Loss: 0.00001949
Iteration 86/1000 | Loss: 0.00001949
Iteration 87/1000 | Loss: 0.00001949
Iteration 88/1000 | Loss: 0.00001949
Iteration 89/1000 | Loss: 0.00001949
Iteration 90/1000 | Loss: 0.00001949
Iteration 91/1000 | Loss: 0.00001949
Iteration 92/1000 | Loss: 0.00001949
Iteration 93/1000 | Loss: 0.00001949
Iteration 94/1000 | Loss: 0.00001949
Iteration 95/1000 | Loss: 0.00001949
Iteration 96/1000 | Loss: 0.00001949
Iteration 97/1000 | Loss: 0.00001948
Iteration 98/1000 | Loss: 0.00001948
Iteration 99/1000 | Loss: 0.00001948
Iteration 100/1000 | Loss: 0.00001948
Iteration 101/1000 | Loss: 0.00001948
Iteration 102/1000 | Loss: 0.00001948
Iteration 103/1000 | Loss: 0.00001948
Iteration 104/1000 | Loss: 0.00001948
Iteration 105/1000 | Loss: 0.00001948
Iteration 106/1000 | Loss: 0.00001948
Iteration 107/1000 | Loss: 0.00001948
Iteration 108/1000 | Loss: 0.00001948
Iteration 109/1000 | Loss: 0.00001948
Iteration 110/1000 | Loss: 0.00001948
Iteration 111/1000 | Loss: 0.00001948
Iteration 112/1000 | Loss: 0.00001948
Iteration 113/1000 | Loss: 0.00001947
Iteration 114/1000 | Loss: 0.00001947
Iteration 115/1000 | Loss: 0.00001947
Iteration 116/1000 | Loss: 0.00001947
Iteration 117/1000 | Loss: 0.00001947
Iteration 118/1000 | Loss: 0.00001947
Iteration 119/1000 | Loss: 0.00001947
Iteration 120/1000 | Loss: 0.00001947
Iteration 121/1000 | Loss: 0.00001947
Iteration 122/1000 | Loss: 0.00001947
Iteration 123/1000 | Loss: 0.00001947
Iteration 124/1000 | Loss: 0.00001947
Iteration 125/1000 | Loss: 0.00001947
Iteration 126/1000 | Loss: 0.00001947
Iteration 127/1000 | Loss: 0.00001947
Iteration 128/1000 | Loss: 0.00001947
Iteration 129/1000 | Loss: 0.00001947
Iteration 130/1000 | Loss: 0.00001947
Iteration 131/1000 | Loss: 0.00001946
Iteration 132/1000 | Loss: 0.00001946
Iteration 133/1000 | Loss: 0.00001946
Iteration 134/1000 | Loss: 0.00001946
Iteration 135/1000 | Loss: 0.00001946
Iteration 136/1000 | Loss: 0.00001946
Iteration 137/1000 | Loss: 0.00001946
Iteration 138/1000 | Loss: 0.00001946
Iteration 139/1000 | Loss: 0.00001946
Iteration 140/1000 | Loss: 0.00001946
Iteration 141/1000 | Loss: 0.00001946
Iteration 142/1000 | Loss: 0.00001946
Iteration 143/1000 | Loss: 0.00001946
Iteration 144/1000 | Loss: 0.00001946
Iteration 145/1000 | Loss: 0.00001946
Iteration 146/1000 | Loss: 0.00001945
Iteration 147/1000 | Loss: 0.00001945
Iteration 148/1000 | Loss: 0.00001945
Iteration 149/1000 | Loss: 0.00001945
Iteration 150/1000 | Loss: 0.00001945
Iteration 151/1000 | Loss: 0.00001945
Iteration 152/1000 | Loss: 0.00001945
Iteration 153/1000 | Loss: 0.00001945
Iteration 154/1000 | Loss: 0.00001945
Iteration 155/1000 | Loss: 0.00001945
Iteration 156/1000 | Loss: 0.00001945
Iteration 157/1000 | Loss: 0.00001944
Iteration 158/1000 | Loss: 0.00001944
Iteration 159/1000 | Loss: 0.00001944
Iteration 160/1000 | Loss: 0.00001944
Iteration 161/1000 | Loss: 0.00001944
Iteration 162/1000 | Loss: 0.00001944
Iteration 163/1000 | Loss: 0.00001944
Iteration 164/1000 | Loss: 0.00001944
Iteration 165/1000 | Loss: 0.00001944
Iteration 166/1000 | Loss: 0.00001944
Iteration 167/1000 | Loss: 0.00001944
Iteration 168/1000 | Loss: 0.00001944
Iteration 169/1000 | Loss: 0.00001944
Iteration 170/1000 | Loss: 0.00001944
Iteration 171/1000 | Loss: 0.00001944
Iteration 172/1000 | Loss: 0.00001944
Iteration 173/1000 | Loss: 0.00001944
Iteration 174/1000 | Loss: 0.00001943
Iteration 175/1000 | Loss: 0.00001943
Iteration 176/1000 | Loss: 0.00001943
Iteration 177/1000 | Loss: 0.00001943
Iteration 178/1000 | Loss: 0.00001943
Iteration 179/1000 | Loss: 0.00001943
Iteration 180/1000 | Loss: 0.00001943
Iteration 181/1000 | Loss: 0.00001943
Iteration 182/1000 | Loss: 0.00001943
Iteration 183/1000 | Loss: 0.00001943
Iteration 184/1000 | Loss: 0.00001943
Iteration 185/1000 | Loss: 0.00001943
Iteration 186/1000 | Loss: 0.00001943
Iteration 187/1000 | Loss: 0.00001943
Iteration 188/1000 | Loss: 0.00001943
Iteration 189/1000 | Loss: 0.00001943
Iteration 190/1000 | Loss: 0.00001943
Iteration 191/1000 | Loss: 0.00001943
Iteration 192/1000 | Loss: 0.00001943
Iteration 193/1000 | Loss: 0.00001943
Iteration 194/1000 | Loss: 0.00001943
Iteration 195/1000 | Loss: 0.00001943
Iteration 196/1000 | Loss: 0.00001943
Iteration 197/1000 | Loss: 0.00001943
Iteration 198/1000 | Loss: 0.00001943
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 198. Stopping optimization.
Last 5 losses: [1.9425831851549447e-05, 1.9425831851549447e-05, 1.9425831851549447e-05, 1.9425831851549447e-05, 1.9425831851549447e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9425831851549447e-05

Optimization complete. Final v2v error: 3.692976713180542 mm

Highest mean error: 4.026883125305176 mm for frame 113

Lowest mean error: 3.398658275604248 mm for frame 38

Saving results

Total time: 38.02346444129944

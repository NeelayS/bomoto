Namespace(object_key=None, cluster_batch_size=56, cluster_start_idx=83, opts=[], cfg_id=0, cluster=False, bid=10, memory=64000, gpu_min_mem=12000, gpu_arch=['tesla', 'quadro', 'rtx'], num_cpus=8, input_dir='/is/cluster/sbhor/smpl_ground_truth_corr/', output_dir='/is/cluster/fast/sbhor/star_bedlam_bomoto/', cfg='/is/cluster/fast/sbhor/bomoto/configs/params_dataset.yaml')

Starting the conversion process at location /is/cluster/fast/sbhor/star_bedlam_bomoto/conversion_log.log.
running 56 files in the range 4648-4703
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_021/1045/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_021/1045.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_021/1045
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01052419
Iteration 2/25 | Loss: 0.00184287
Iteration 3/25 | Loss: 0.00149387
Iteration 4/25 | Loss: 0.00147033
Iteration 5/25 | Loss: 0.00146396
Iteration 6/25 | Loss: 0.00146254
Iteration 7/25 | Loss: 0.00146245
Iteration 8/25 | Loss: 0.00146245
Iteration 9/25 | Loss: 0.00146245
Iteration 10/25 | Loss: 0.00146245
Iteration 11/25 | Loss: 0.00146245
Iteration 12/25 | Loss: 0.00146245
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0014624473406001925, 0.0014624473406001925, 0.0014624473406001925, 0.0014624473406001925, 0.0014624473406001925]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0014624473406001925

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.94299716
Iteration 2/25 | Loss: 0.00107351
Iteration 3/25 | Loss: 0.00107351
Iteration 4/25 | Loss: 0.00107351
Iteration 5/25 | Loss: 0.00107351
Iteration 6/25 | Loss: 0.00107351
Iteration 7/25 | Loss: 0.00107351
Iteration 8/25 | Loss: 0.00107351
Iteration 9/25 | Loss: 0.00107351
Iteration 10/25 | Loss: 0.00107351
Iteration 11/25 | Loss: 0.00107351
Iteration 12/25 | Loss: 0.00107351
Iteration 13/25 | Loss: 0.00107351
Iteration 14/25 | Loss: 0.00107351
Iteration 15/25 | Loss: 0.00107351
Iteration 16/25 | Loss: 0.00107351
Iteration 17/25 | Loss: 0.00107351
Iteration 18/25 | Loss: 0.00107351
Iteration 19/25 | Loss: 0.00107351
Iteration 20/25 | Loss: 0.00107351
Iteration 21/25 | Loss: 0.00107351
Iteration 22/25 | Loss: 0.00107351
Iteration 23/25 | Loss: 0.00107351
Iteration 24/25 | Loss: 0.00107351
Iteration 25/25 | Loss: 0.00107351
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.001073508057743311, 0.001073508057743311, 0.001073508057743311, 0.001073508057743311, 0.001073508057743311]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001073508057743311

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00107351
Iteration 2/1000 | Loss: 0.00004797
Iteration 3/1000 | Loss: 0.00003632
Iteration 4/1000 | Loss: 0.00003230
Iteration 5/1000 | Loss: 0.00003098
Iteration 6/1000 | Loss: 0.00003006
Iteration 7/1000 | Loss: 0.00002945
Iteration 8/1000 | Loss: 0.00002898
Iteration 9/1000 | Loss: 0.00002864
Iteration 10/1000 | Loss: 0.00002822
Iteration 11/1000 | Loss: 0.00002786
Iteration 12/1000 | Loss: 0.00002758
Iteration 13/1000 | Loss: 0.00002733
Iteration 14/1000 | Loss: 0.00002714
Iteration 15/1000 | Loss: 0.00002691
Iteration 16/1000 | Loss: 0.00002671
Iteration 17/1000 | Loss: 0.00002669
Iteration 18/1000 | Loss: 0.00002662
Iteration 19/1000 | Loss: 0.00002658
Iteration 20/1000 | Loss: 0.00002654
Iteration 21/1000 | Loss: 0.00002654
Iteration 22/1000 | Loss: 0.00002653
Iteration 23/1000 | Loss: 0.00002650
Iteration 24/1000 | Loss: 0.00002637
Iteration 25/1000 | Loss: 0.00002637
Iteration 26/1000 | Loss: 0.00002635
Iteration 27/1000 | Loss: 0.00002631
Iteration 28/1000 | Loss: 0.00002631
Iteration 29/1000 | Loss: 0.00002629
Iteration 30/1000 | Loss: 0.00002629
Iteration 31/1000 | Loss: 0.00002629
Iteration 32/1000 | Loss: 0.00002628
Iteration 33/1000 | Loss: 0.00002628
Iteration 34/1000 | Loss: 0.00002628
Iteration 35/1000 | Loss: 0.00002627
Iteration 36/1000 | Loss: 0.00002626
Iteration 37/1000 | Loss: 0.00002626
Iteration 38/1000 | Loss: 0.00002626
Iteration 39/1000 | Loss: 0.00002625
Iteration 40/1000 | Loss: 0.00002625
Iteration 41/1000 | Loss: 0.00002624
Iteration 42/1000 | Loss: 0.00002624
Iteration 43/1000 | Loss: 0.00002624
Iteration 44/1000 | Loss: 0.00002624
Iteration 45/1000 | Loss: 0.00002623
Iteration 46/1000 | Loss: 0.00002623
Iteration 47/1000 | Loss: 0.00002623
Iteration 48/1000 | Loss: 0.00002622
Iteration 49/1000 | Loss: 0.00002622
Iteration 50/1000 | Loss: 0.00002621
Iteration 51/1000 | Loss: 0.00002621
Iteration 52/1000 | Loss: 0.00002621
Iteration 53/1000 | Loss: 0.00002621
Iteration 54/1000 | Loss: 0.00002620
Iteration 55/1000 | Loss: 0.00002620
Iteration 56/1000 | Loss: 0.00002620
Iteration 57/1000 | Loss: 0.00002620
Iteration 58/1000 | Loss: 0.00002620
Iteration 59/1000 | Loss: 0.00002619
Iteration 60/1000 | Loss: 0.00002619
Iteration 61/1000 | Loss: 0.00002618
Iteration 62/1000 | Loss: 0.00002618
Iteration 63/1000 | Loss: 0.00002618
Iteration 64/1000 | Loss: 0.00002618
Iteration 65/1000 | Loss: 0.00002617
Iteration 66/1000 | Loss: 0.00002617
Iteration 67/1000 | Loss: 0.00002617
Iteration 68/1000 | Loss: 0.00002616
Iteration 69/1000 | Loss: 0.00002616
Iteration 70/1000 | Loss: 0.00002616
Iteration 71/1000 | Loss: 0.00002615
Iteration 72/1000 | Loss: 0.00002615
Iteration 73/1000 | Loss: 0.00002615
Iteration 74/1000 | Loss: 0.00002615
Iteration 75/1000 | Loss: 0.00002615
Iteration 76/1000 | Loss: 0.00002614
Iteration 77/1000 | Loss: 0.00002614
Iteration 78/1000 | Loss: 0.00002614
Iteration 79/1000 | Loss: 0.00002614
Iteration 80/1000 | Loss: 0.00002614
Iteration 81/1000 | Loss: 0.00002614
Iteration 82/1000 | Loss: 0.00002614
Iteration 83/1000 | Loss: 0.00002614
Iteration 84/1000 | Loss: 0.00002614
Iteration 85/1000 | Loss: 0.00002614
Iteration 86/1000 | Loss: 0.00002614
Iteration 87/1000 | Loss: 0.00002614
Iteration 88/1000 | Loss: 0.00002614
Iteration 89/1000 | Loss: 0.00002614
Iteration 90/1000 | Loss: 0.00002613
Iteration 91/1000 | Loss: 0.00002613
Iteration 92/1000 | Loss: 0.00002613
Iteration 93/1000 | Loss: 0.00002613
Iteration 94/1000 | Loss: 0.00002613
Iteration 95/1000 | Loss: 0.00002613
Iteration 96/1000 | Loss: 0.00002613
Iteration 97/1000 | Loss: 0.00002613
Iteration 98/1000 | Loss: 0.00002612
Iteration 99/1000 | Loss: 0.00002612
Iteration 100/1000 | Loss: 0.00002612
Iteration 101/1000 | Loss: 0.00002612
Iteration 102/1000 | Loss: 0.00002612
Iteration 103/1000 | Loss: 0.00002612
Iteration 104/1000 | Loss: 0.00002612
Iteration 105/1000 | Loss: 0.00002612
Iteration 106/1000 | Loss: 0.00002611
Iteration 107/1000 | Loss: 0.00002611
Iteration 108/1000 | Loss: 0.00002611
Iteration 109/1000 | Loss: 0.00002611
Iteration 110/1000 | Loss: 0.00002611
Iteration 111/1000 | Loss: 0.00002611
Iteration 112/1000 | Loss: 0.00002611
Iteration 113/1000 | Loss: 0.00002611
Iteration 114/1000 | Loss: 0.00002611
Iteration 115/1000 | Loss: 0.00002611
Iteration 116/1000 | Loss: 0.00002611
Iteration 117/1000 | Loss: 0.00002611
Iteration 118/1000 | Loss: 0.00002611
Iteration 119/1000 | Loss: 0.00002611
Iteration 120/1000 | Loss: 0.00002610
Iteration 121/1000 | Loss: 0.00002610
Iteration 122/1000 | Loss: 0.00002610
Iteration 123/1000 | Loss: 0.00002610
Iteration 124/1000 | Loss: 0.00002610
Iteration 125/1000 | Loss: 0.00002610
Iteration 126/1000 | Loss: 0.00002610
Iteration 127/1000 | Loss: 0.00002610
Iteration 128/1000 | Loss: 0.00002610
Iteration 129/1000 | Loss: 0.00002610
Iteration 130/1000 | Loss: 0.00002610
Iteration 131/1000 | Loss: 0.00002610
Iteration 132/1000 | Loss: 0.00002610
Iteration 133/1000 | Loss: 0.00002610
Iteration 134/1000 | Loss: 0.00002610
Iteration 135/1000 | Loss: 0.00002609
Iteration 136/1000 | Loss: 0.00002609
Iteration 137/1000 | Loss: 0.00002609
Iteration 138/1000 | Loss: 0.00002609
Iteration 139/1000 | Loss: 0.00002609
Iteration 140/1000 | Loss: 0.00002609
Iteration 141/1000 | Loss: 0.00002609
Iteration 142/1000 | Loss: 0.00002609
Iteration 143/1000 | Loss: 0.00002609
Iteration 144/1000 | Loss: 0.00002609
Iteration 145/1000 | Loss: 0.00002609
Iteration 146/1000 | Loss: 0.00002609
Iteration 147/1000 | Loss: 0.00002609
Iteration 148/1000 | Loss: 0.00002609
Iteration 149/1000 | Loss: 0.00002609
Iteration 150/1000 | Loss: 0.00002608
Iteration 151/1000 | Loss: 0.00002608
Iteration 152/1000 | Loss: 0.00002608
Iteration 153/1000 | Loss: 0.00002608
Iteration 154/1000 | Loss: 0.00002608
Iteration 155/1000 | Loss: 0.00002608
Iteration 156/1000 | Loss: 0.00002608
Iteration 157/1000 | Loss: 0.00002608
Iteration 158/1000 | Loss: 0.00002608
Iteration 159/1000 | Loss: 0.00002608
Iteration 160/1000 | Loss: 0.00002608
Iteration 161/1000 | Loss: 0.00002608
Iteration 162/1000 | Loss: 0.00002608
Iteration 163/1000 | Loss: 0.00002608
Iteration 164/1000 | Loss: 0.00002608
Iteration 165/1000 | Loss: 0.00002608
Iteration 166/1000 | Loss: 0.00002608
Iteration 167/1000 | Loss: 0.00002608
Iteration 168/1000 | Loss: 0.00002608
Iteration 169/1000 | Loss: 0.00002608
Iteration 170/1000 | Loss: 0.00002608
Iteration 171/1000 | Loss: 0.00002608
Iteration 172/1000 | Loss: 0.00002608
Iteration 173/1000 | Loss: 0.00002608
Iteration 174/1000 | Loss: 0.00002608
Iteration 175/1000 | Loss: 0.00002608
Iteration 176/1000 | Loss: 0.00002608
Iteration 177/1000 | Loss: 0.00002608
Iteration 178/1000 | Loss: 0.00002608
Iteration 179/1000 | Loss: 0.00002608
Iteration 180/1000 | Loss: 0.00002608
Iteration 181/1000 | Loss: 0.00002608
Iteration 182/1000 | Loss: 0.00002608
Iteration 183/1000 | Loss: 0.00002608
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 183. Stopping optimization.
Last 5 losses: [2.6077615984831937e-05, 2.6077615984831937e-05, 2.6077615984831937e-05, 2.6077615984831937e-05, 2.6077615984831937e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.6077615984831937e-05

Optimization complete. Final v2v error: 4.251163959503174 mm

Highest mean error: 5.1323652267456055 mm for frame 139

Lowest mean error: 3.5744469165802 mm for frame 25

Saving results

Total time: 49.17030882835388
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_christine_posed_021/1048/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_021/1048.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_christine_posed_021/1048
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00816591
Iteration 2/25 | Loss: 0.00146987
Iteration 3/25 | Loss: 0.00136268
Iteration 4/25 | Loss: 0.00134973
Iteration 5/25 | Loss: 0.00134556
Iteration 6/25 | Loss: 0.00134489
Iteration 7/25 | Loss: 0.00134489
Iteration 8/25 | Loss: 0.00134489
Iteration 9/25 | Loss: 0.00134489
Iteration 10/25 | Loss: 0.00134489
Iteration 11/25 | Loss: 0.00134489
Iteration 12/25 | Loss: 0.00134489
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.001344894291833043, 0.001344894291833043, 0.001344894291833043, 0.001344894291833043, 0.001344894291833043]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001344894291833043

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.72019041
Iteration 2/25 | Loss: 0.00102884
Iteration 3/25 | Loss: 0.00102883
Iteration 4/25 | Loss: 0.00102883
Iteration 5/25 | Loss: 0.00102883
Iteration 6/25 | Loss: 0.00102883
Iteration 7/25 | Loss: 0.00102883
Iteration 8/25 | Loss: 0.00102883
Iteration 9/25 | Loss: 0.00102883
Iteration 10/25 | Loss: 0.00102883
Iteration 11/25 | Loss: 0.00102883
Iteration 12/25 | Loss: 0.00102883
Iteration 13/25 | Loss: 0.00102883
Iteration 14/25 | Loss: 0.00102883
Iteration 15/25 | Loss: 0.00102883
Iteration 16/25 | Loss: 0.00102883
Iteration 17/25 | Loss: 0.00102883
Iteration 18/25 | Loss: 0.00102883
Iteration 19/25 | Loss: 0.00102883
Iteration 20/25 | Loss: 0.00102883
Iteration 21/25 | Loss: 0.00102883
Iteration 22/25 | Loss: 0.00102883
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0010288263438269496, 0.0010288263438269496, 0.0010288263438269496, 0.0010288263438269496, 0.0010288263438269496]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010288263438269496

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00102883
Iteration 2/1000 | Loss: 0.00003453
Iteration 3/1000 | Loss: 0.00002406
Iteration 4/1000 | Loss: 0.00002197
Iteration 5/1000 | Loss: 0.00002092
Iteration 6/1000 | Loss: 0.00002015
Iteration 7/1000 | Loss: 0.00001973
Iteration 8/1000 | Loss: 0.00001947
Iteration 9/1000 | Loss: 0.00001919
Iteration 10/1000 | Loss: 0.00001883
Iteration 11/1000 | Loss: 0.00001872
Iteration 12/1000 | Loss: 0.00001866
Iteration 13/1000 | Loss: 0.00001866
Iteration 14/1000 | Loss: 0.00001860
Iteration 15/1000 | Loss: 0.00001852
Iteration 16/1000 | Loss: 0.00001845
Iteration 17/1000 | Loss: 0.00001838
Iteration 18/1000 | Loss: 0.00001835
Iteration 19/1000 | Loss: 0.00001835
Iteration 20/1000 | Loss: 0.00001834
Iteration 21/1000 | Loss: 0.00001834
Iteration 22/1000 | Loss: 0.00001829
Iteration 23/1000 | Loss: 0.00001827
Iteration 24/1000 | Loss: 0.00001826
Iteration 25/1000 | Loss: 0.00001826
Iteration 26/1000 | Loss: 0.00001821
Iteration 27/1000 | Loss: 0.00001819
Iteration 28/1000 | Loss: 0.00001817
Iteration 29/1000 | Loss: 0.00001814
Iteration 30/1000 | Loss: 0.00001811
Iteration 31/1000 | Loss: 0.00001811
Iteration 32/1000 | Loss: 0.00001809
Iteration 33/1000 | Loss: 0.00001808
Iteration 34/1000 | Loss: 0.00001808
Iteration 35/1000 | Loss: 0.00001808
Iteration 36/1000 | Loss: 0.00001808
Iteration 37/1000 | Loss: 0.00001807
Iteration 38/1000 | Loss: 0.00001807
Iteration 39/1000 | Loss: 0.00001805
Iteration 40/1000 | Loss: 0.00001804
Iteration 41/1000 | Loss: 0.00001804
Iteration 42/1000 | Loss: 0.00001804
Iteration 43/1000 | Loss: 0.00001804
Iteration 44/1000 | Loss: 0.00001803
Iteration 45/1000 | Loss: 0.00001803
Iteration 46/1000 | Loss: 0.00001803
Iteration 47/1000 | Loss: 0.00001802
Iteration 48/1000 | Loss: 0.00001802
Iteration 49/1000 | Loss: 0.00001802
Iteration 50/1000 | Loss: 0.00001801
Iteration 51/1000 | Loss: 0.00001801
Iteration 52/1000 | Loss: 0.00001800
Iteration 53/1000 | Loss: 0.00001800
Iteration 54/1000 | Loss: 0.00001800
Iteration 55/1000 | Loss: 0.00001800
Iteration 56/1000 | Loss: 0.00001799
Iteration 57/1000 | Loss: 0.00001799
Iteration 58/1000 | Loss: 0.00001799
Iteration 59/1000 | Loss: 0.00001797
Iteration 60/1000 | Loss: 0.00001797
Iteration 61/1000 | Loss: 0.00001797
Iteration 62/1000 | Loss: 0.00001797
Iteration 63/1000 | Loss: 0.00001797
Iteration 64/1000 | Loss: 0.00001797
Iteration 65/1000 | Loss: 0.00001797
Iteration 66/1000 | Loss: 0.00001797
Iteration 67/1000 | Loss: 0.00001797
Iteration 68/1000 | Loss: 0.00001797
Iteration 69/1000 | Loss: 0.00001797
Iteration 70/1000 | Loss: 0.00001797
Iteration 71/1000 | Loss: 0.00001797
Iteration 72/1000 | Loss: 0.00001796
Iteration 73/1000 | Loss: 0.00001796
Iteration 74/1000 | Loss: 0.00001796
Iteration 75/1000 | Loss: 0.00001796
Iteration 76/1000 | Loss: 0.00001796
Iteration 77/1000 | Loss: 0.00001796
Iteration 78/1000 | Loss: 0.00001796
Iteration 79/1000 | Loss: 0.00001796
Iteration 80/1000 | Loss: 0.00001796
Iteration 81/1000 | Loss: 0.00001796
Iteration 82/1000 | Loss: 0.00001796
Iteration 83/1000 | Loss: 0.00001796
Iteration 84/1000 | Loss: 0.00001796
Iteration 85/1000 | Loss: 0.00001796
Iteration 86/1000 | Loss: 0.00001796
Iteration 87/1000 | Loss: 0.00001796
Iteration 88/1000 | Loss: 0.00001796
Iteration 89/1000 | Loss: 0.00001796
Iteration 90/1000 | Loss: 0.00001796
Iteration 91/1000 | Loss: 0.00001796
Iteration 92/1000 | Loss: 0.00001796
Iteration 93/1000 | Loss: 0.00001796
Iteration 94/1000 | Loss: 0.00001796
Iteration 95/1000 | Loss: 0.00001796
Iteration 96/1000 | Loss: 0.00001796
Iteration 97/1000 | Loss: 0.00001796
Iteration 98/1000 | Loss: 0.00001796
Iteration 99/1000 | Loss: 0.00001796
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 99. Stopping optimization.
Last 5 losses: [1.7962815036298707e-05, 1.7962815036298707e-05, 1.7962815036298707e-05, 1.7962815036298707e-05, 1.7962815036298707e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7962815036298707e-05

Optimization complete. Final v2v error: 3.453756332397461 mm

Highest mean error: 4.905380725860596 mm for frame 166

Lowest mean error: 2.9696877002716064 mm for frame 26

Saving results

Total time: 40.14374017715454
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00920172
Iteration 2/25 | Loss: 0.00150876
Iteration 3/25 | Loss: 0.00120850
Iteration 4/25 | Loss: 0.00114907
Iteration 5/25 | Loss: 0.00113042
Iteration 6/25 | Loss: 0.00113188
Iteration 7/25 | Loss: 0.00111240
Iteration 8/25 | Loss: 0.00109050
Iteration 9/25 | Loss: 0.00107614
Iteration 10/25 | Loss: 0.00105750
Iteration 11/25 | Loss: 0.00105484
Iteration 12/25 | Loss: 0.00105467
Iteration 13/25 | Loss: 0.00105464
Iteration 14/25 | Loss: 0.00105464
Iteration 15/25 | Loss: 0.00105464
Iteration 16/25 | Loss: 0.00105464
Iteration 17/25 | Loss: 0.00105464
Iteration 18/25 | Loss: 0.00105464
Iteration 19/25 | Loss: 0.00105464
Iteration 20/25 | Loss: 0.00105464
Iteration 21/25 | Loss: 0.00105464
Iteration 22/25 | Loss: 0.00105464
Iteration 23/25 | Loss: 0.00105464
Iteration 24/25 | Loss: 0.00105464
Iteration 25/25 | Loss: 0.00105463

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.01585984
Iteration 2/25 | Loss: 0.00073790
Iteration 3/25 | Loss: 0.00073789
Iteration 4/25 | Loss: 0.00073789
Iteration 5/25 | Loss: 0.00073789
Iteration 6/25 | Loss: 0.00073789
Iteration 7/25 | Loss: 0.00073789
Iteration 8/25 | Loss: 0.00073789
Iteration 9/25 | Loss: 0.00073789
Iteration 10/25 | Loss: 0.00073789
Iteration 11/25 | Loss: 0.00073789
Iteration 12/25 | Loss: 0.00073789
Iteration 13/25 | Loss: 0.00073789
Iteration 14/25 | Loss: 0.00073789
Iteration 15/25 | Loss: 0.00073789
Iteration 16/25 | Loss: 0.00073789
Iteration 17/25 | Loss: 0.00073789
Iteration 18/25 | Loss: 0.00073789
Iteration 19/25 | Loss: 0.00073789
Iteration 20/25 | Loss: 0.00073789
Iteration 21/25 | Loss: 0.00073789
Iteration 22/25 | Loss: 0.00073789
Iteration 23/25 | Loss: 0.00073789
Iteration 24/25 | Loss: 0.00073789
Iteration 25/25 | Loss: 0.00073789

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073789
Iteration 2/1000 | Loss: 0.00004029
Iteration 3/1000 | Loss: 0.00003279
Iteration 4/1000 | Loss: 0.00003001
Iteration 5/1000 | Loss: 0.00002870
Iteration 6/1000 | Loss: 0.00002753
Iteration 7/1000 | Loss: 0.00002685
Iteration 8/1000 | Loss: 0.00002625
Iteration 9/1000 | Loss: 0.00002598
Iteration 10/1000 | Loss: 0.00002585
Iteration 11/1000 | Loss: 0.00002576
Iteration 12/1000 | Loss: 0.00002574
Iteration 13/1000 | Loss: 0.00002572
Iteration 14/1000 | Loss: 0.00002572
Iteration 15/1000 | Loss: 0.00002572
Iteration 16/1000 | Loss: 0.00002572
Iteration 17/1000 | Loss: 0.00002572
Iteration 18/1000 | Loss: 0.00002572
Iteration 19/1000 | Loss: 0.00002572
Iteration 20/1000 | Loss: 0.00002572
Iteration 21/1000 | Loss: 0.00002571
Iteration 22/1000 | Loss: 0.00002571
Iteration 23/1000 | Loss: 0.00002571
Iteration 24/1000 | Loss: 0.00002571
Iteration 25/1000 | Loss: 0.00002571
Iteration 26/1000 | Loss: 0.00002571
Iteration 27/1000 | Loss: 0.00002571
Iteration 28/1000 | Loss: 0.00002571
Iteration 29/1000 | Loss: 0.00002571
Iteration 30/1000 | Loss: 0.00002571
Iteration 31/1000 | Loss: 0.00002571
Iteration 32/1000 | Loss: 0.00002571
Iteration 33/1000 | Loss: 0.00002571
Iteration 34/1000 | Loss: 0.00002571
Iteration 35/1000 | Loss: 0.00002571
Iteration 36/1000 | Loss: 0.00002571
Iteration 37/1000 | Loss: 0.00002571
Iteration 38/1000 | Loss: 0.00002571
Iteration 39/1000 | Loss: 0.00002571
Iteration 40/1000 | Loss: 0.00002571
Iteration 41/1000 | Loss: 0.00002571
Iteration 42/1000 | Loss: 0.00002571
Iteration 43/1000 | Loss: 0.00002571
Iteration 44/1000 | Loss: 0.00002571
Iteration 45/1000 | Loss: 0.00002571
Iteration 46/1000 | Loss: 0.00002571
Iteration 47/1000 | Loss: 0.00002571
Iteration 48/1000 | Loss: 0.00002571
Iteration 49/1000 | Loss: 0.00002571
Iteration 50/1000 | Loss: 0.00002571
Iteration 51/1000 | Loss: 0.00002571
Iteration 52/1000 | Loss: 0.00002571
Iteration 53/1000 | Loss: 0.00002571
Iteration 54/1000 | Loss: 0.00002571
Iteration 55/1000 | Loss: 0.00002571
Iteration 56/1000 | Loss: 0.00002571
Iteration 57/1000 | Loss: 0.00002571
Iteration 58/1000 | Loss: 0.00002571
Iteration 59/1000 | Loss: 0.00002571
Iteration 60/1000 | Loss: 0.00002571
Iteration 61/1000 | Loss: 0.00002571
Iteration 62/1000 | Loss: 0.00002571
Iteration 63/1000 | Loss: 0.00002571
Iteration 64/1000 | Loss: 0.00002571
Iteration 65/1000 | Loss: 0.00002571
Iteration 66/1000 | Loss: 0.00002571
Iteration 67/1000 | Loss: 0.00002571
Iteration 68/1000 | Loss: 0.00002571
Iteration 69/1000 | Loss: 0.00002571
Iteration 70/1000 | Loss: 0.00002571
Iteration 71/1000 | Loss: 0.00002571
Iteration 72/1000 | Loss: 0.00002571
Iteration 73/1000 | Loss: 0.00002571
Iteration 74/1000 | Loss: 0.00002571
Iteration 75/1000 | Loss: 0.00002571
Iteration 76/1000 | Loss: 0.00002571
Iteration 77/1000 | Loss: 0.00002571
Iteration 78/1000 | Loss: 0.00002571
Iteration 79/1000 | Loss: 0.00002571
Iteration 80/1000 | Loss: 0.00002571
Iteration 81/1000 | Loss: 0.00002571
Iteration 82/1000 | Loss: 0.00002571
Iteration 83/1000 | Loss: 0.00002571
Iteration 84/1000 | Loss: 0.00002571
Iteration 85/1000 | Loss: 0.00002571
Iteration 86/1000 | Loss: 0.00002571
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 86. Stopping optimization.
Last 5 losses: [2.571022014308255e-05, 2.571022014308255e-05, 2.571022014308255e-05, 2.571022014308255e-05, 2.571022014308255e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.571022014308255e-05

Optimization complete. Final v2v error: 4.312763214111328 mm

Highest mean error: 4.622373104095459 mm for frame 81

Lowest mean error: 3.978761911392212 mm for frame 31

Saving results

Total time: 39.230770111083984
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00735854
Iteration 2/25 | Loss: 0.00162194
Iteration 3/25 | Loss: 0.00112225
Iteration 4/25 | Loss: 0.00101175
Iteration 5/25 | Loss: 0.00094049
Iteration 6/25 | Loss: 0.00094142
Iteration 7/25 | Loss: 0.00091798
Iteration 8/25 | Loss: 0.00090601
Iteration 9/25 | Loss: 0.00089824
Iteration 10/25 | Loss: 0.00088927
Iteration 11/25 | Loss: 0.00088634
Iteration 12/25 | Loss: 0.00089371
Iteration 13/25 | Loss: 0.00089911
Iteration 14/25 | Loss: 0.00089350
Iteration 15/25 | Loss: 0.00089539
Iteration 16/25 | Loss: 0.00089222
Iteration 17/25 | Loss: 0.00088344
Iteration 18/25 | Loss: 0.00088398
Iteration 19/25 | Loss: 0.00088155
Iteration 20/25 | Loss: 0.00087949
Iteration 21/25 | Loss: 0.00088795
Iteration 22/25 | Loss: 0.00088351
Iteration 23/25 | Loss: 0.00087870
Iteration 24/25 | Loss: 0.00087869
Iteration 25/25 | Loss: 0.00087869

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.36132812
Iteration 2/25 | Loss: 0.00065913
Iteration 3/25 | Loss: 0.00065909
Iteration 4/25 | Loss: 0.00065909
Iteration 5/25 | Loss: 0.00065908
Iteration 6/25 | Loss: 0.00065908
Iteration 7/25 | Loss: 0.00065908
Iteration 8/25 | Loss: 0.00065908
Iteration 9/25 | Loss: 0.00065908
Iteration 10/25 | Loss: 0.00065908
Iteration 11/25 | Loss: 0.00065908
Iteration 12/25 | Loss: 0.00065908
Iteration 13/25 | Loss: 0.00065908
Iteration 14/25 | Loss: 0.00065908
Iteration 15/25 | Loss: 0.00065908
Iteration 16/25 | Loss: 0.00065908
Iteration 17/25 | Loss: 0.00065908
Iteration 18/25 | Loss: 0.00065908
Iteration 19/25 | Loss: 0.00065908
Iteration 20/25 | Loss: 0.00065908
Iteration 21/25 | Loss: 0.00065908
Iteration 22/25 | Loss: 0.00065908
Iteration 23/25 | Loss: 0.00065908
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.000659083656501025, 0.000659083656501025, 0.000659083656501025, 0.000659083656501025, 0.000659083656501025]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000659083656501025

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065908
Iteration 2/1000 | Loss: 0.00004279
Iteration 3/1000 | Loss: 0.00003200
Iteration 4/1000 | Loss: 0.00002822
Iteration 5/1000 | Loss: 0.00002664
Iteration 6/1000 | Loss: 0.00002565
Iteration 7/1000 | Loss: 0.00002452
Iteration 8/1000 | Loss: 0.00002395
Iteration 9/1000 | Loss: 0.00002363
Iteration 10/1000 | Loss: 0.00002344
Iteration 11/1000 | Loss: 0.00016816
Iteration 12/1000 | Loss: 0.00002474
Iteration 13/1000 | Loss: 0.00016718
Iteration 14/1000 | Loss: 0.00002254
Iteration 15/1000 | Loss: 0.00002181
Iteration 16/1000 | Loss: 0.00002130
Iteration 17/1000 | Loss: 0.00002104
Iteration 18/1000 | Loss: 0.00002096
Iteration 19/1000 | Loss: 0.00002079
Iteration 20/1000 | Loss: 0.00002077
Iteration 21/1000 | Loss: 0.00002076
Iteration 22/1000 | Loss: 0.00002075
Iteration 23/1000 | Loss: 0.00002073
Iteration 24/1000 | Loss: 0.00002073
Iteration 25/1000 | Loss: 0.00002073
Iteration 26/1000 | Loss: 0.00002072
Iteration 27/1000 | Loss: 0.00002072
Iteration 28/1000 | Loss: 0.00002072
Iteration 29/1000 | Loss: 0.00002072
Iteration 30/1000 | Loss: 0.00002072
Iteration 31/1000 | Loss: 0.00002071
Iteration 32/1000 | Loss: 0.00002071
Iteration 33/1000 | Loss: 0.00002070
Iteration 34/1000 | Loss: 0.00002070
Iteration 35/1000 | Loss: 0.00002069
Iteration 36/1000 | Loss: 0.00002068
Iteration 37/1000 | Loss: 0.00002068
Iteration 38/1000 | Loss: 0.00002068
Iteration 39/1000 | Loss: 0.00002067
Iteration 40/1000 | Loss: 0.00002067
Iteration 41/1000 | Loss: 0.00002067
Iteration 42/1000 | Loss: 0.00002067
Iteration 43/1000 | Loss: 0.00002067
Iteration 44/1000 | Loss: 0.00002067
Iteration 45/1000 | Loss: 0.00002067
Iteration 46/1000 | Loss: 0.00002067
Iteration 47/1000 | Loss: 0.00002067
Iteration 48/1000 | Loss: 0.00002067
Iteration 49/1000 | Loss: 0.00002067
Iteration 50/1000 | Loss: 0.00002067
Iteration 51/1000 | Loss: 0.00002067
Iteration 52/1000 | Loss: 0.00002066
Iteration 53/1000 | Loss: 0.00002066
Iteration 54/1000 | Loss: 0.00002066
Iteration 55/1000 | Loss: 0.00002065
Iteration 56/1000 | Loss: 0.00002065
Iteration 57/1000 | Loss: 0.00002065
Iteration 58/1000 | Loss: 0.00002064
Iteration 59/1000 | Loss: 0.00002064
Iteration 60/1000 | Loss: 0.00002064
Iteration 61/1000 | Loss: 0.00002063
Iteration 62/1000 | Loss: 0.00002063
Iteration 63/1000 | Loss: 0.00002062
Iteration 64/1000 | Loss: 0.00002062
Iteration 65/1000 | Loss: 0.00002062
Iteration 66/1000 | Loss: 0.00002061
Iteration 67/1000 | Loss: 0.00002061
Iteration 68/1000 | Loss: 0.00002061
Iteration 69/1000 | Loss: 0.00002061
Iteration 70/1000 | Loss: 0.00002061
Iteration 71/1000 | Loss: 0.00002061
Iteration 72/1000 | Loss: 0.00002060
Iteration 73/1000 | Loss: 0.00002059
Iteration 74/1000 | Loss: 0.00002059
Iteration 75/1000 | Loss: 0.00002059
Iteration 76/1000 | Loss: 0.00002058
Iteration 77/1000 | Loss: 0.00002058
Iteration 78/1000 | Loss: 0.00002058
Iteration 79/1000 | Loss: 0.00002058
Iteration 80/1000 | Loss: 0.00002058
Iteration 81/1000 | Loss: 0.00002058
Iteration 82/1000 | Loss: 0.00002058
Iteration 83/1000 | Loss: 0.00002057
Iteration 84/1000 | Loss: 0.00002057
Iteration 85/1000 | Loss: 0.00002057
Iteration 86/1000 | Loss: 0.00002057
Iteration 87/1000 | Loss: 0.00002057
Iteration 88/1000 | Loss: 0.00002057
Iteration 89/1000 | Loss: 0.00002057
Iteration 90/1000 | Loss: 0.00002056
Iteration 91/1000 | Loss: 0.00002056
Iteration 92/1000 | Loss: 0.00002056
Iteration 93/1000 | Loss: 0.00002056
Iteration 94/1000 | Loss: 0.00002056
Iteration 95/1000 | Loss: 0.00002056
Iteration 96/1000 | Loss: 0.00002056
Iteration 97/1000 | Loss: 0.00002055
Iteration 98/1000 | Loss: 0.00002055
Iteration 99/1000 | Loss: 0.00002055
Iteration 100/1000 | Loss: 0.00002055
Iteration 101/1000 | Loss: 0.00002055
Iteration 102/1000 | Loss: 0.00002055
Iteration 103/1000 | Loss: 0.00002055
Iteration 104/1000 | Loss: 0.00002055
Iteration 105/1000 | Loss: 0.00002055
Iteration 106/1000 | Loss: 0.00002054
Iteration 107/1000 | Loss: 0.00002054
Iteration 108/1000 | Loss: 0.00002054
Iteration 109/1000 | Loss: 0.00002054
Iteration 110/1000 | Loss: 0.00002054
Iteration 111/1000 | Loss: 0.00002054
Iteration 112/1000 | Loss: 0.00002053
Iteration 113/1000 | Loss: 0.00002053
Iteration 114/1000 | Loss: 0.00002053
Iteration 115/1000 | Loss: 0.00002052
Iteration 116/1000 | Loss: 0.00002052
Iteration 117/1000 | Loss: 0.00002052
Iteration 118/1000 | Loss: 0.00002052
Iteration 119/1000 | Loss: 0.00002051
Iteration 120/1000 | Loss: 0.00002051
Iteration 121/1000 | Loss: 0.00002051
Iteration 122/1000 | Loss: 0.00002051
Iteration 123/1000 | Loss: 0.00002051
Iteration 124/1000 | Loss: 0.00002051
Iteration 125/1000 | Loss: 0.00002051
Iteration 126/1000 | Loss: 0.00002051
Iteration 127/1000 | Loss: 0.00002051
Iteration 128/1000 | Loss: 0.00002051
Iteration 129/1000 | Loss: 0.00002051
Iteration 130/1000 | Loss: 0.00002051
Iteration 131/1000 | Loss: 0.00002050
Iteration 132/1000 | Loss: 0.00002050
Iteration 133/1000 | Loss: 0.00002050
Iteration 134/1000 | Loss: 0.00002050
Iteration 135/1000 | Loss: 0.00002050
Iteration 136/1000 | Loss: 0.00002050
Iteration 137/1000 | Loss: 0.00002050
Iteration 138/1000 | Loss: 0.00002050
Iteration 139/1000 | Loss: 0.00002050
Iteration 140/1000 | Loss: 0.00002050
Iteration 141/1000 | Loss: 0.00002050
Iteration 142/1000 | Loss: 0.00002050
Iteration 143/1000 | Loss: 0.00002050
Iteration 144/1000 | Loss: 0.00002050
Iteration 145/1000 | Loss: 0.00002050
Iteration 146/1000 | Loss: 0.00002050
Iteration 147/1000 | Loss: 0.00002050
Iteration 148/1000 | Loss: 0.00002050
Iteration 149/1000 | Loss: 0.00002050
Iteration 150/1000 | Loss: 0.00002050
Iteration 151/1000 | Loss: 0.00002050
Iteration 152/1000 | Loss: 0.00002050
Iteration 153/1000 | Loss: 0.00002050
Iteration 154/1000 | Loss: 0.00002050
Iteration 155/1000 | Loss: 0.00002050
Iteration 156/1000 | Loss: 0.00002050
Iteration 157/1000 | Loss: 0.00002050
Iteration 158/1000 | Loss: 0.00002050
Iteration 159/1000 | Loss: 0.00002050
Iteration 160/1000 | Loss: 0.00002050
Iteration 161/1000 | Loss: 0.00002050
Iteration 162/1000 | Loss: 0.00002050
Iteration 163/1000 | Loss: 0.00002050
Iteration 164/1000 | Loss: 0.00002050
Iteration 165/1000 | Loss: 0.00002050
Iteration 166/1000 | Loss: 0.00002050
Iteration 167/1000 | Loss: 0.00002050
Iteration 168/1000 | Loss: 0.00002050
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 168. Stopping optimization.
Last 5 losses: [2.0502480765571818e-05, 2.0502480765571818e-05, 2.0502480765571818e-05, 2.0502480765571818e-05, 2.0502480765571818e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0502480765571818e-05

Optimization complete. Final v2v error: 3.8793692588806152 mm

Highest mean error: 9.705801963806152 mm for frame 29

Lowest mean error: 3.191504716873169 mm for frame 2

Saving results

Total time: 75.1900200843811
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00968121
Iteration 2/25 | Loss: 0.00318619
Iteration 3/25 | Loss: 0.00218695
Iteration 4/25 | Loss: 0.00164389
Iteration 5/25 | Loss: 0.00153307
Iteration 6/25 | Loss: 0.00147483
Iteration 7/25 | Loss: 0.00141676
Iteration 8/25 | Loss: 0.00139555
Iteration 9/25 | Loss: 0.00142984
Iteration 10/25 | Loss: 0.00142245
Iteration 11/25 | Loss: 0.00140014
Iteration 12/25 | Loss: 0.00137359
Iteration 13/25 | Loss: 0.00136092
Iteration 14/25 | Loss: 0.00135309
Iteration 15/25 | Loss: 0.00133271
Iteration 16/25 | Loss: 0.00133360
Iteration 17/25 | Loss: 0.00133401
Iteration 18/25 | Loss: 0.00132804
Iteration 19/25 | Loss: 0.00134205
Iteration 20/25 | Loss: 0.00133743
Iteration 21/25 | Loss: 0.00133855
Iteration 22/25 | Loss: 0.00134014
Iteration 23/25 | Loss: 0.00128937
Iteration 24/25 | Loss: 0.00127459
Iteration 25/25 | Loss: 0.00127191

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.39817405
Iteration 2/25 | Loss: 0.00425634
Iteration 3/25 | Loss: 0.00390855
Iteration 4/25 | Loss: 0.00390855
Iteration 5/25 | Loss: 0.00390855
Iteration 6/25 | Loss: 0.00390855
Iteration 7/25 | Loss: 0.00390855
Iteration 8/25 | Loss: 0.00390855
Iteration 9/25 | Loss: 0.00390855
Iteration 10/25 | Loss: 0.00390855
Iteration 11/25 | Loss: 0.00390855
Iteration 12/25 | Loss: 0.00390855
Iteration 13/25 | Loss: 0.00390855
Iteration 14/25 | Loss: 0.00390855
Iteration 15/25 | Loss: 0.00390855
Iteration 16/25 | Loss: 0.00390855
Iteration 17/25 | Loss: 0.00390855
Iteration 18/25 | Loss: 0.00390855
Iteration 19/25 | Loss: 0.00390855
Iteration 20/25 | Loss: 0.00390855
Iteration 21/25 | Loss: 0.00390855
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.00390854524448514, 0.00390854524448514, 0.00390854524448514, 0.00390854524448514, 0.00390854524448514]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00390854524448514

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00390855
Iteration 2/1000 | Loss: 0.00156029
Iteration 3/1000 | Loss: 0.00675977
Iteration 4/1000 | Loss: 0.00899598
Iteration 5/1000 | Loss: 0.00062915
Iteration 6/1000 | Loss: 0.00828102
Iteration 7/1000 | Loss: 0.00057058
Iteration 8/1000 | Loss: 0.00037753
Iteration 9/1000 | Loss: 0.00017207
Iteration 10/1000 | Loss: 0.00286140
Iteration 11/1000 | Loss: 0.00068950
Iteration 12/1000 | Loss: 0.00138608
Iteration 13/1000 | Loss: 0.00193623
Iteration 14/1000 | Loss: 0.00030298
Iteration 15/1000 | Loss: 0.00040821
Iteration 16/1000 | Loss: 0.00011704
Iteration 17/1000 | Loss: 0.00179523
Iteration 18/1000 | Loss: 0.00071487
Iteration 19/1000 | Loss: 0.00012347
Iteration 20/1000 | Loss: 0.00029988
Iteration 21/1000 | Loss: 0.00026056
Iteration 22/1000 | Loss: 0.00029652
Iteration 23/1000 | Loss: 0.00021345
Iteration 24/1000 | Loss: 0.00026054
Iteration 25/1000 | Loss: 0.00008556
Iteration 26/1000 | Loss: 0.00251918
Iteration 27/1000 | Loss: 0.00241153
Iteration 28/1000 | Loss: 0.00015591
Iteration 29/1000 | Loss: 0.00018974
Iteration 30/1000 | Loss: 0.00108428
Iteration 31/1000 | Loss: 0.00056532
Iteration 32/1000 | Loss: 0.00014823
Iteration 33/1000 | Loss: 0.00011830
Iteration 34/1000 | Loss: 0.00025514
Iteration 35/1000 | Loss: 0.00019233
Iteration 36/1000 | Loss: 0.00005065
Iteration 37/1000 | Loss: 0.00037800
Iteration 38/1000 | Loss: 0.00004542
Iteration 39/1000 | Loss: 0.00004308
Iteration 40/1000 | Loss: 0.00006707
Iteration 41/1000 | Loss: 0.00004087
Iteration 42/1000 | Loss: 0.00025972
Iteration 43/1000 | Loss: 0.00011209
Iteration 44/1000 | Loss: 0.00004549
Iteration 45/1000 | Loss: 0.00003943
Iteration 46/1000 | Loss: 0.00021498
Iteration 47/1000 | Loss: 0.00020689
Iteration 48/1000 | Loss: 0.00008724
Iteration 49/1000 | Loss: 0.00005301
Iteration 50/1000 | Loss: 0.00003928
Iteration 51/1000 | Loss: 0.00003809
Iteration 52/1000 | Loss: 0.00003739
Iteration 53/1000 | Loss: 0.00003688
Iteration 54/1000 | Loss: 0.00022770
Iteration 55/1000 | Loss: 0.00003695
Iteration 56/1000 | Loss: 0.00003628
Iteration 57/1000 | Loss: 0.00003604
Iteration 58/1000 | Loss: 0.00054399
Iteration 59/1000 | Loss: 0.00018268
Iteration 60/1000 | Loss: 0.00003613
Iteration 61/1000 | Loss: 0.00005769
Iteration 62/1000 | Loss: 0.00003344
Iteration 63/1000 | Loss: 0.00003252
Iteration 64/1000 | Loss: 0.00003196
Iteration 65/1000 | Loss: 0.00014908
Iteration 66/1000 | Loss: 0.00003166
Iteration 67/1000 | Loss: 0.00003129
Iteration 68/1000 | Loss: 0.00003124
Iteration 69/1000 | Loss: 0.00003124
Iteration 70/1000 | Loss: 0.00003119
Iteration 71/1000 | Loss: 0.00003102
Iteration 72/1000 | Loss: 0.00003098
Iteration 73/1000 | Loss: 0.00003095
Iteration 74/1000 | Loss: 0.00003094
Iteration 75/1000 | Loss: 0.00003093
Iteration 76/1000 | Loss: 0.00003093
Iteration 77/1000 | Loss: 0.00003092
Iteration 78/1000 | Loss: 0.00003091
Iteration 79/1000 | Loss: 0.00003091
Iteration 80/1000 | Loss: 0.00003091
Iteration 81/1000 | Loss: 0.00003091
Iteration 82/1000 | Loss: 0.00003091
Iteration 83/1000 | Loss: 0.00003088
Iteration 84/1000 | Loss: 0.00003088
Iteration 85/1000 | Loss: 0.00003088
Iteration 86/1000 | Loss: 0.00003088
Iteration 87/1000 | Loss: 0.00003087
Iteration 88/1000 | Loss: 0.00003087
Iteration 89/1000 | Loss: 0.00003087
Iteration 90/1000 | Loss: 0.00003087
Iteration 91/1000 | Loss: 0.00003087
Iteration 92/1000 | Loss: 0.00003087
Iteration 93/1000 | Loss: 0.00003085
Iteration 94/1000 | Loss: 0.00003085
Iteration 95/1000 | Loss: 0.00003084
Iteration 96/1000 | Loss: 0.00003084
Iteration 97/1000 | Loss: 0.00003084
Iteration 98/1000 | Loss: 0.00003082
Iteration 99/1000 | Loss: 0.00003082
Iteration 100/1000 | Loss: 0.00003082
Iteration 101/1000 | Loss: 0.00003082
Iteration 102/1000 | Loss: 0.00003082
Iteration 103/1000 | Loss: 0.00003082
Iteration 104/1000 | Loss: 0.00003082
Iteration 105/1000 | Loss: 0.00003082
Iteration 106/1000 | Loss: 0.00003081
Iteration 107/1000 | Loss: 0.00003081
Iteration 108/1000 | Loss: 0.00003081
Iteration 109/1000 | Loss: 0.00003081
Iteration 110/1000 | Loss: 0.00003080
Iteration 111/1000 | Loss: 0.00003080
Iteration 112/1000 | Loss: 0.00003080
Iteration 113/1000 | Loss: 0.00003080
Iteration 114/1000 | Loss: 0.00003080
Iteration 115/1000 | Loss: 0.00003080
Iteration 116/1000 | Loss: 0.00003080
Iteration 117/1000 | Loss: 0.00003080
Iteration 118/1000 | Loss: 0.00003080
Iteration 119/1000 | Loss: 0.00003080
Iteration 120/1000 | Loss: 0.00003080
Iteration 121/1000 | Loss: 0.00003079
Iteration 122/1000 | Loss: 0.00003079
Iteration 123/1000 | Loss: 0.00003079
Iteration 124/1000 | Loss: 0.00003079
Iteration 125/1000 | Loss: 0.00003079
Iteration 126/1000 | Loss: 0.00003079
Iteration 127/1000 | Loss: 0.00003079
Iteration 128/1000 | Loss: 0.00003079
Iteration 129/1000 | Loss: 0.00003079
Iteration 130/1000 | Loss: 0.00003079
Iteration 131/1000 | Loss: 0.00003079
Iteration 132/1000 | Loss: 0.00003079
Iteration 133/1000 | Loss: 0.00003079
Iteration 134/1000 | Loss: 0.00003079
Iteration 135/1000 | Loss: 0.00003079
Iteration 136/1000 | Loss: 0.00003079
Iteration 137/1000 | Loss: 0.00003079
Iteration 138/1000 | Loss: 0.00003079
Iteration 139/1000 | Loss: 0.00003079
Iteration 140/1000 | Loss: 0.00003079
Iteration 141/1000 | Loss: 0.00003079
Iteration 142/1000 | Loss: 0.00003079
Iteration 143/1000 | Loss: 0.00003079
Iteration 144/1000 | Loss: 0.00003079
Iteration 145/1000 | Loss: 0.00003079
Iteration 146/1000 | Loss: 0.00003079
Iteration 147/1000 | Loss: 0.00003079
Iteration 148/1000 | Loss: 0.00003079
Iteration 149/1000 | Loss: 0.00003079
Iteration 150/1000 | Loss: 0.00003079
Iteration 151/1000 | Loss: 0.00003079
Iteration 152/1000 | Loss: 0.00003079
Iteration 153/1000 | Loss: 0.00003079
Iteration 154/1000 | Loss: 0.00003079
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [3.079083762713708e-05, 3.079083762713708e-05, 3.079083762713708e-05, 3.079083762713708e-05, 3.079083762713708e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.079083762713708e-05

Optimization complete. Final v2v error: 4.534706115722656 mm

Highest mean error: 6.692119598388672 mm for frame 40

Lowest mean error: 2.873384475708008 mm for frame 4

Saving results

Total time: 143.75814819335938
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01149905
Iteration 2/25 | Loss: 0.00343984
Iteration 3/25 | Loss: 0.00235316
Iteration 4/25 | Loss: 0.00215975
Iteration 5/25 | Loss: 0.00206898
Iteration 6/25 | Loss: 0.00209956
Iteration 7/25 | Loss: 0.00191708
Iteration 8/25 | Loss: 0.00168468
Iteration 9/25 | Loss: 0.00159375
Iteration 10/25 | Loss: 0.00149635
Iteration 11/25 | Loss: 0.00145380
Iteration 12/25 | Loss: 0.00142111
Iteration 13/25 | Loss: 0.00138944
Iteration 14/25 | Loss: 0.00136180
Iteration 15/25 | Loss: 0.00134420
Iteration 16/25 | Loss: 0.00133436
Iteration 17/25 | Loss: 0.00132782
Iteration 18/25 | Loss: 0.00132632
Iteration 19/25 | Loss: 0.00132479
Iteration 20/25 | Loss: 0.00132206
Iteration 21/25 | Loss: 0.00132149
Iteration 22/25 | Loss: 0.00132118
Iteration 23/25 | Loss: 0.00132092
Iteration 24/25 | Loss: 0.00132060
Iteration 25/25 | Loss: 0.00132033

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.66088963
Iteration 2/25 | Loss: 0.00333918
Iteration 3/25 | Loss: 0.00333918
Iteration 4/25 | Loss: 0.00333918
Iteration 5/25 | Loss: 0.00333918
Iteration 6/25 | Loss: 0.00333918
Iteration 7/25 | Loss: 0.00333918
Iteration 8/25 | Loss: 0.00333918
Iteration 9/25 | Loss: 0.00333918
Iteration 10/25 | Loss: 0.00333918
Iteration 11/25 | Loss: 0.00333918
Iteration 12/25 | Loss: 0.00333918
Iteration 13/25 | Loss: 0.00333918
Iteration 14/25 | Loss: 0.00333918
Iteration 15/25 | Loss: 0.00333918
Iteration 16/25 | Loss: 0.00333918
Iteration 17/25 | Loss: 0.00333918
Iteration 18/25 | Loss: 0.00333918
Iteration 19/25 | Loss: 0.00333918
Iteration 20/25 | Loss: 0.00333918
Iteration 21/25 | Loss: 0.00333918
Iteration 22/25 | Loss: 0.00333918
Iteration 23/25 | Loss: 0.00333918
Iteration 24/25 | Loss: 0.00333918
Iteration 25/25 | Loss: 0.00333918

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00333918
Iteration 2/1000 | Loss: 0.00058699
Iteration 3/1000 | Loss: 0.00076864
Iteration 4/1000 | Loss: 0.00037331
Iteration 5/1000 | Loss: 0.00029524
Iteration 6/1000 | Loss: 0.00024309
Iteration 7/1000 | Loss: 0.00021841
Iteration 8/1000 | Loss: 0.00054682
Iteration 9/1000 | Loss: 0.00045487
Iteration 10/1000 | Loss: 0.00174286
Iteration 11/1000 | Loss: 0.00327474
Iteration 12/1000 | Loss: 0.00070745
Iteration 13/1000 | Loss: 0.00038543
Iteration 14/1000 | Loss: 0.00020393
Iteration 15/1000 | Loss: 0.00019605
Iteration 16/1000 | Loss: 0.00017230
Iteration 17/1000 | Loss: 0.00016525
Iteration 18/1000 | Loss: 0.00016131
Iteration 19/1000 | Loss: 0.00015809
Iteration 20/1000 | Loss: 0.00015662
Iteration 21/1000 | Loss: 0.00015554
Iteration 22/1000 | Loss: 0.00069691
Iteration 23/1000 | Loss: 0.00016352
Iteration 24/1000 | Loss: 0.00015645
Iteration 25/1000 | Loss: 0.00015352
Iteration 26/1000 | Loss: 0.00015175
Iteration 27/1000 | Loss: 0.00015094
Iteration 28/1000 | Loss: 0.00015058
Iteration 29/1000 | Loss: 0.00015032
Iteration 30/1000 | Loss: 0.00015013
Iteration 31/1000 | Loss: 0.00015004
Iteration 32/1000 | Loss: 0.00015004
Iteration 33/1000 | Loss: 0.00015003
Iteration 34/1000 | Loss: 0.00015002
Iteration 35/1000 | Loss: 0.00014999
Iteration 36/1000 | Loss: 0.00014998
Iteration 37/1000 | Loss: 0.00014996
Iteration 38/1000 | Loss: 0.00014995
Iteration 39/1000 | Loss: 0.00014995
Iteration 40/1000 | Loss: 0.00014991
Iteration 41/1000 | Loss: 0.00014987
Iteration 42/1000 | Loss: 0.00014986
Iteration 43/1000 | Loss: 0.00014986
Iteration 44/1000 | Loss: 0.00014985
Iteration 45/1000 | Loss: 0.00014983
Iteration 46/1000 | Loss: 0.00014983
Iteration 47/1000 | Loss: 0.00014983
Iteration 48/1000 | Loss: 0.00014983
Iteration 49/1000 | Loss: 0.00014983
Iteration 50/1000 | Loss: 0.00014982
Iteration 51/1000 | Loss: 0.00014982
Iteration 52/1000 | Loss: 0.00014981
Iteration 53/1000 | Loss: 0.00014981
Iteration 54/1000 | Loss: 0.00014980
Iteration 55/1000 | Loss: 0.00014980
Iteration 56/1000 | Loss: 0.00014979
Iteration 57/1000 | Loss: 0.00014978
Iteration 58/1000 | Loss: 0.00014978
Iteration 59/1000 | Loss: 0.00014978
Iteration 60/1000 | Loss: 0.00014978
Iteration 61/1000 | Loss: 0.00014978
Iteration 62/1000 | Loss: 0.00014978
Iteration 63/1000 | Loss: 0.00014977
Iteration 64/1000 | Loss: 0.00014977
Iteration 65/1000 | Loss: 0.00014977
Iteration 66/1000 | Loss: 0.00014977
Iteration 67/1000 | Loss: 0.00014977
Iteration 68/1000 | Loss: 0.00014977
Iteration 69/1000 | Loss: 0.00014977
Iteration 70/1000 | Loss: 0.00014975
Iteration 71/1000 | Loss: 0.00014975
Iteration 72/1000 | Loss: 0.00014974
Iteration 73/1000 | Loss: 0.00014974
Iteration 74/1000 | Loss: 0.00014974
Iteration 75/1000 | Loss: 0.00014974
Iteration 76/1000 | Loss: 0.00014973
Iteration 77/1000 | Loss: 0.00014973
Iteration 78/1000 | Loss: 0.00014973
Iteration 79/1000 | Loss: 0.00014973
Iteration 80/1000 | Loss: 0.00014973
Iteration 81/1000 | Loss: 0.00014972
Iteration 82/1000 | Loss: 0.00014972
Iteration 83/1000 | Loss: 0.00014972
Iteration 84/1000 | Loss: 0.00014972
Iteration 85/1000 | Loss: 0.00014972
Iteration 86/1000 | Loss: 0.00014972
Iteration 87/1000 | Loss: 0.00014972
Iteration 88/1000 | Loss: 0.00014971
Iteration 89/1000 | Loss: 0.00014971
Iteration 90/1000 | Loss: 0.00014971
Iteration 91/1000 | Loss: 0.00014971
Iteration 92/1000 | Loss: 0.00014971
Iteration 93/1000 | Loss: 0.00014971
Iteration 94/1000 | Loss: 0.00014971
Iteration 95/1000 | Loss: 0.00014971
Iteration 96/1000 | Loss: 0.00014971
Iteration 97/1000 | Loss: 0.00014971
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 97. Stopping optimization.
Last 5 losses: [0.00014971169002819806, 0.00014971169002819806, 0.00014971169002819806, 0.00014971169002819806, 0.00014971169002819806]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00014971169002819806

Optimization complete. Final v2v error: 6.891283988952637 mm

Highest mean error: 12.788841247558594 mm for frame 51

Lowest mean error: 4.850550651550293 mm for frame 31

Saving results

Total time: 94.99685621261597
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00858191
Iteration 2/25 | Loss: 0.00103744
Iteration 3/25 | Loss: 0.00089053
Iteration 4/25 | Loss: 0.00087019
Iteration 5/25 | Loss: 0.00086464
Iteration 6/25 | Loss: 0.00086314
Iteration 7/25 | Loss: 0.00086310
Iteration 8/25 | Loss: 0.00086310
Iteration 9/25 | Loss: 0.00086310
Iteration 10/25 | Loss: 0.00086310
Iteration 11/25 | Loss: 0.00086310
Iteration 12/25 | Loss: 0.00086310
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008630951051600277, 0.0008630951051600277, 0.0008630951051600277, 0.0008630951051600277, 0.0008630951051600277]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008630951051600277

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48335767
Iteration 2/25 | Loss: 0.00062743
Iteration 3/25 | Loss: 0.00062743
Iteration 4/25 | Loss: 0.00062743
Iteration 5/25 | Loss: 0.00062743
Iteration 6/25 | Loss: 0.00062743
Iteration 7/25 | Loss: 0.00062743
Iteration 8/25 | Loss: 0.00062743
Iteration 9/25 | Loss: 0.00062743
Iteration 10/25 | Loss: 0.00062743
Iteration 11/25 | Loss: 0.00062743
Iteration 12/25 | Loss: 0.00062743
Iteration 13/25 | Loss: 0.00062743
Iteration 14/25 | Loss: 0.00062743
Iteration 15/25 | Loss: 0.00062743
Iteration 16/25 | Loss: 0.00062743
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0006274284096434712, 0.0006274284096434712, 0.0006274284096434712, 0.0006274284096434712, 0.0006274284096434712]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006274284096434712

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062743
Iteration 2/1000 | Loss: 0.00002031
Iteration 3/1000 | Loss: 0.00001656
Iteration 4/1000 | Loss: 0.00001537
Iteration 5/1000 | Loss: 0.00001479
Iteration 6/1000 | Loss: 0.00001436
Iteration 7/1000 | Loss: 0.00001414
Iteration 8/1000 | Loss: 0.00001409
Iteration 9/1000 | Loss: 0.00001409
Iteration 10/1000 | Loss: 0.00001402
Iteration 11/1000 | Loss: 0.00001402
Iteration 12/1000 | Loss: 0.00001400
Iteration 13/1000 | Loss: 0.00001398
Iteration 14/1000 | Loss: 0.00001398
Iteration 15/1000 | Loss: 0.00001397
Iteration 16/1000 | Loss: 0.00001397
Iteration 17/1000 | Loss: 0.00001397
Iteration 18/1000 | Loss: 0.00001397
Iteration 19/1000 | Loss: 0.00001397
Iteration 20/1000 | Loss: 0.00001397
Iteration 21/1000 | Loss: 0.00001397
Iteration 22/1000 | Loss: 0.00001397
Iteration 23/1000 | Loss: 0.00001397
Iteration 24/1000 | Loss: 0.00001396
Iteration 25/1000 | Loss: 0.00001395
Iteration 26/1000 | Loss: 0.00001392
Iteration 27/1000 | Loss: 0.00001392
Iteration 28/1000 | Loss: 0.00001392
Iteration 29/1000 | Loss: 0.00001392
Iteration 30/1000 | Loss: 0.00001392
Iteration 31/1000 | Loss: 0.00001392
Iteration 32/1000 | Loss: 0.00001392
Iteration 33/1000 | Loss: 0.00001392
Iteration 34/1000 | Loss: 0.00001392
Iteration 35/1000 | Loss: 0.00001392
Iteration 36/1000 | Loss: 0.00001392
Iteration 37/1000 | Loss: 0.00001391
Iteration 38/1000 | Loss: 0.00001391
Iteration 39/1000 | Loss: 0.00001391
Iteration 40/1000 | Loss: 0.00001389
Iteration 41/1000 | Loss: 0.00001388
Iteration 42/1000 | Loss: 0.00001388
Iteration 43/1000 | Loss: 0.00001386
Iteration 44/1000 | Loss: 0.00001386
Iteration 45/1000 | Loss: 0.00001385
Iteration 46/1000 | Loss: 0.00001385
Iteration 47/1000 | Loss: 0.00001385
Iteration 48/1000 | Loss: 0.00001385
Iteration 49/1000 | Loss: 0.00001384
Iteration 50/1000 | Loss: 0.00001384
Iteration 51/1000 | Loss: 0.00001384
Iteration 52/1000 | Loss: 0.00001384
Iteration 53/1000 | Loss: 0.00001384
Iteration 54/1000 | Loss: 0.00001384
Iteration 55/1000 | Loss: 0.00001383
Iteration 56/1000 | Loss: 0.00001383
Iteration 57/1000 | Loss: 0.00001383
Iteration 58/1000 | Loss: 0.00001383
Iteration 59/1000 | Loss: 0.00001382
Iteration 60/1000 | Loss: 0.00001382
Iteration 61/1000 | Loss: 0.00001382
Iteration 62/1000 | Loss: 0.00001382
Iteration 63/1000 | Loss: 0.00001382
Iteration 64/1000 | Loss: 0.00001382
Iteration 65/1000 | Loss: 0.00001381
Iteration 66/1000 | Loss: 0.00001381
Iteration 67/1000 | Loss: 0.00001381
Iteration 68/1000 | Loss: 0.00001381
Iteration 69/1000 | Loss: 0.00001381
Iteration 70/1000 | Loss: 0.00001381
Iteration 71/1000 | Loss: 0.00001381
Iteration 72/1000 | Loss: 0.00001381
Iteration 73/1000 | Loss: 0.00001381
Iteration 74/1000 | Loss: 0.00001381
Iteration 75/1000 | Loss: 0.00001381
Iteration 76/1000 | Loss: 0.00001381
Iteration 77/1000 | Loss: 0.00001381
Iteration 78/1000 | Loss: 0.00001381
Iteration 79/1000 | Loss: 0.00001380
Iteration 80/1000 | Loss: 0.00001380
Iteration 81/1000 | Loss: 0.00001380
Iteration 82/1000 | Loss: 0.00001379
Iteration 83/1000 | Loss: 0.00001379
Iteration 84/1000 | Loss: 0.00001379
Iteration 85/1000 | Loss: 0.00001379
Iteration 86/1000 | Loss: 0.00001379
Iteration 87/1000 | Loss: 0.00001379
Iteration 88/1000 | Loss: 0.00001379
Iteration 89/1000 | Loss: 0.00001379
Iteration 90/1000 | Loss: 0.00001379
Iteration 91/1000 | Loss: 0.00001379
Iteration 92/1000 | Loss: 0.00001379
Iteration 93/1000 | Loss: 0.00001379
Iteration 94/1000 | Loss: 0.00001379
Iteration 95/1000 | Loss: 0.00001379
Iteration 96/1000 | Loss: 0.00001378
Iteration 97/1000 | Loss: 0.00001378
Iteration 98/1000 | Loss: 0.00001378
Iteration 99/1000 | Loss: 0.00001377
Iteration 100/1000 | Loss: 0.00001377
Iteration 101/1000 | Loss: 0.00001377
Iteration 102/1000 | Loss: 0.00001377
Iteration 103/1000 | Loss: 0.00001377
Iteration 104/1000 | Loss: 0.00001377
Iteration 105/1000 | Loss: 0.00001377
Iteration 106/1000 | Loss: 0.00001377
Iteration 107/1000 | Loss: 0.00001377
Iteration 108/1000 | Loss: 0.00001377
Iteration 109/1000 | Loss: 0.00001377
Iteration 110/1000 | Loss: 0.00001376
Iteration 111/1000 | Loss: 0.00001376
Iteration 112/1000 | Loss: 0.00001376
Iteration 113/1000 | Loss: 0.00001376
Iteration 114/1000 | Loss: 0.00001376
Iteration 115/1000 | Loss: 0.00001376
Iteration 116/1000 | Loss: 0.00001376
Iteration 117/1000 | Loss: 0.00001376
Iteration 118/1000 | Loss: 0.00001376
Iteration 119/1000 | Loss: 0.00001376
Iteration 120/1000 | Loss: 0.00001376
Iteration 121/1000 | Loss: 0.00001376
Iteration 122/1000 | Loss: 0.00001376
Iteration 123/1000 | Loss: 0.00001376
Iteration 124/1000 | Loss: 0.00001376
Iteration 125/1000 | Loss: 0.00001375
Iteration 126/1000 | Loss: 0.00001375
Iteration 127/1000 | Loss: 0.00001375
Iteration 128/1000 | Loss: 0.00001375
Iteration 129/1000 | Loss: 0.00001375
Iteration 130/1000 | Loss: 0.00001375
Iteration 131/1000 | Loss: 0.00001375
Iteration 132/1000 | Loss: 0.00001375
Iteration 133/1000 | Loss: 0.00001375
Iteration 134/1000 | Loss: 0.00001375
Iteration 135/1000 | Loss: 0.00001375
Iteration 136/1000 | Loss: 0.00001375
Iteration 137/1000 | Loss: 0.00001375
Iteration 138/1000 | Loss: 0.00001375
Iteration 139/1000 | Loss: 0.00001375
Iteration 140/1000 | Loss: 0.00001375
Iteration 141/1000 | Loss: 0.00001375
Iteration 142/1000 | Loss: 0.00001375
Iteration 143/1000 | Loss: 0.00001374
Iteration 144/1000 | Loss: 0.00001374
Iteration 145/1000 | Loss: 0.00001374
Iteration 146/1000 | Loss: 0.00001374
Iteration 147/1000 | Loss: 0.00001374
Iteration 148/1000 | Loss: 0.00001373
Iteration 149/1000 | Loss: 0.00001373
Iteration 150/1000 | Loss: 0.00001373
Iteration 151/1000 | Loss: 0.00001373
Iteration 152/1000 | Loss: 0.00001373
Iteration 153/1000 | Loss: 0.00001373
Iteration 154/1000 | Loss: 0.00001373
Iteration 155/1000 | Loss: 0.00001373
Iteration 156/1000 | Loss: 0.00001373
Iteration 157/1000 | Loss: 0.00001373
Iteration 158/1000 | Loss: 0.00001373
Iteration 159/1000 | Loss: 0.00001373
Iteration 160/1000 | Loss: 0.00001373
Iteration 161/1000 | Loss: 0.00001373
Iteration 162/1000 | Loss: 0.00001373
Iteration 163/1000 | Loss: 0.00001373
Iteration 164/1000 | Loss: 0.00001372
Iteration 165/1000 | Loss: 0.00001372
Iteration 166/1000 | Loss: 0.00001372
Iteration 167/1000 | Loss: 0.00001372
Iteration 168/1000 | Loss: 0.00001372
Iteration 169/1000 | Loss: 0.00001372
Iteration 170/1000 | Loss: 0.00001372
Iteration 171/1000 | Loss: 0.00001372
Iteration 172/1000 | Loss: 0.00001372
Iteration 173/1000 | Loss: 0.00001372
Iteration 174/1000 | Loss: 0.00001372
Iteration 175/1000 | Loss: 0.00001372
Iteration 176/1000 | Loss: 0.00001372
Iteration 177/1000 | Loss: 0.00001372
Iteration 178/1000 | Loss: 0.00001372
Iteration 179/1000 | Loss: 0.00001372
Iteration 180/1000 | Loss: 0.00001372
Iteration 181/1000 | Loss: 0.00001372
Iteration 182/1000 | Loss: 0.00001371
Iteration 183/1000 | Loss: 0.00001371
Iteration 184/1000 | Loss: 0.00001371
Iteration 185/1000 | Loss: 0.00001371
Iteration 186/1000 | Loss: 0.00001371
Iteration 187/1000 | Loss: 0.00001371
Iteration 188/1000 | Loss: 0.00001371
Iteration 189/1000 | Loss: 0.00001371
Iteration 190/1000 | Loss: 0.00001371
Iteration 191/1000 | Loss: 0.00001371
Iteration 192/1000 | Loss: 0.00001371
Iteration 193/1000 | Loss: 0.00001371
Iteration 194/1000 | Loss: 0.00001371
Iteration 195/1000 | Loss: 0.00001371
Iteration 196/1000 | Loss: 0.00001371
Iteration 197/1000 | Loss: 0.00001371
Iteration 198/1000 | Loss: 0.00001371
Iteration 199/1000 | Loss: 0.00001371
Iteration 200/1000 | Loss: 0.00001371
Iteration 201/1000 | Loss: 0.00001370
Iteration 202/1000 | Loss: 0.00001370
Iteration 203/1000 | Loss: 0.00001370
Iteration 204/1000 | Loss: 0.00001370
Iteration 205/1000 | Loss: 0.00001370
Iteration 206/1000 | Loss: 0.00001370
Iteration 207/1000 | Loss: 0.00001370
Iteration 208/1000 | Loss: 0.00001370
Iteration 209/1000 | Loss: 0.00001370
Iteration 210/1000 | Loss: 0.00001370
Iteration 211/1000 | Loss: 0.00001370
Iteration 212/1000 | Loss: 0.00001370
Iteration 213/1000 | Loss: 0.00001370
Iteration 214/1000 | Loss: 0.00001370
Iteration 215/1000 | Loss: 0.00001370
Iteration 216/1000 | Loss: 0.00001370
Iteration 217/1000 | Loss: 0.00001370
Iteration 218/1000 | Loss: 0.00001370
Iteration 219/1000 | Loss: 0.00001370
Iteration 220/1000 | Loss: 0.00001370
Iteration 221/1000 | Loss: 0.00001370
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 221. Stopping optimization.
Last 5 losses: [1.3704590855923016e-05, 1.3704590855923016e-05, 1.3704590855923016e-05, 1.3704590855923016e-05, 1.3704590855923016e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3704590855923016e-05

Optimization complete. Final v2v error: 3.177293062210083 mm

Highest mean error: 3.4195034503936768 mm for frame 52

Lowest mean error: 2.9671084880828857 mm for frame 207

Saving results

Total time: 34.98073720932007
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01108572
Iteration 2/25 | Loss: 0.00195525
Iteration 3/25 | Loss: 0.00126484
Iteration 4/25 | Loss: 0.00108741
Iteration 5/25 | Loss: 0.00104286
Iteration 6/25 | Loss: 0.00102755
Iteration 7/25 | Loss: 0.00102074
Iteration 8/25 | Loss: 0.00100974
Iteration 9/25 | Loss: 0.00100129
Iteration 10/25 | Loss: 0.00098845
Iteration 11/25 | Loss: 0.00098541
Iteration 12/25 | Loss: 0.00098389
Iteration 13/25 | Loss: 0.00098358
Iteration 14/25 | Loss: 0.00098344
Iteration 15/25 | Loss: 0.00098343
Iteration 16/25 | Loss: 0.00098343
Iteration 17/25 | Loss: 0.00098343
Iteration 18/25 | Loss: 0.00098343
Iteration 19/25 | Loss: 0.00098343
Iteration 20/25 | Loss: 0.00098342
Iteration 21/25 | Loss: 0.00098342
Iteration 22/25 | Loss: 0.00098342
Iteration 23/25 | Loss: 0.00098342
Iteration 24/25 | Loss: 0.00098342
Iteration 25/25 | Loss: 0.00098342

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.46913433
Iteration 2/25 | Loss: 0.00065207
Iteration 3/25 | Loss: 0.00065207
Iteration 4/25 | Loss: 0.00065207
Iteration 5/25 | Loss: 0.00065207
Iteration 6/25 | Loss: 0.00065207
Iteration 7/25 | Loss: 0.00065207
Iteration 8/25 | Loss: 0.00065207
Iteration 9/25 | Loss: 0.00065207
Iteration 10/25 | Loss: 0.00065207
Iteration 11/25 | Loss: 0.00065207
Iteration 12/25 | Loss: 0.00065207
Iteration 13/25 | Loss: 0.00065207
Iteration 14/25 | Loss: 0.00065207
Iteration 15/25 | Loss: 0.00065207
Iteration 16/25 | Loss: 0.00065207
Iteration 17/25 | Loss: 0.00065207
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006520659080706537, 0.0006520659080706537, 0.0006520659080706537, 0.0006520659080706537, 0.0006520659080706537]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006520659080706537

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00065207
Iteration 2/1000 | Loss: 0.00004080
Iteration 3/1000 | Loss: 0.00003500
Iteration 4/1000 | Loss: 0.00003204
Iteration 5/1000 | Loss: 0.00003084
Iteration 6/1000 | Loss: 0.00003019
Iteration 7/1000 | Loss: 0.00002978
Iteration 8/1000 | Loss: 0.00002956
Iteration 9/1000 | Loss: 0.00002941
Iteration 10/1000 | Loss: 0.00002930
Iteration 11/1000 | Loss: 0.00002922
Iteration 12/1000 | Loss: 0.00002922
Iteration 13/1000 | Loss: 0.00002922
Iteration 14/1000 | Loss: 0.00002922
Iteration 15/1000 | Loss: 0.00002922
Iteration 16/1000 | Loss: 0.00002922
Iteration 17/1000 | Loss: 0.00002921
Iteration 18/1000 | Loss: 0.00002921
Iteration 19/1000 | Loss: 0.00002921
Iteration 20/1000 | Loss: 0.00002919
Iteration 21/1000 | Loss: 0.00002918
Iteration 22/1000 | Loss: 0.00002918
Iteration 23/1000 | Loss: 0.00002918
Iteration 24/1000 | Loss: 0.00002918
Iteration 25/1000 | Loss: 0.00002918
Iteration 26/1000 | Loss: 0.00002918
Iteration 27/1000 | Loss: 0.00002918
Iteration 28/1000 | Loss: 0.00002917
Iteration 29/1000 | Loss: 0.00002917
Iteration 30/1000 | Loss: 0.00002916
Iteration 31/1000 | Loss: 0.00002916
Iteration 32/1000 | Loss: 0.00002916
Iteration 33/1000 | Loss: 0.00002915
Iteration 34/1000 | Loss: 0.00002915
Iteration 35/1000 | Loss: 0.00002915
Iteration 36/1000 | Loss: 0.00002915
Iteration 37/1000 | Loss: 0.00002915
Iteration 38/1000 | Loss: 0.00002915
Iteration 39/1000 | Loss: 0.00002915
Iteration 40/1000 | Loss: 0.00002915
Iteration 41/1000 | Loss: 0.00002915
Iteration 42/1000 | Loss: 0.00002915
Iteration 43/1000 | Loss: 0.00002915
Iteration 44/1000 | Loss: 0.00002915
Iteration 45/1000 | Loss: 0.00002915
Iteration 46/1000 | Loss: 0.00002914
Iteration 47/1000 | Loss: 0.00002914
Iteration 48/1000 | Loss: 0.00002914
Iteration 49/1000 | Loss: 0.00002913
Iteration 50/1000 | Loss: 0.00002913
Iteration 51/1000 | Loss: 0.00002913
Iteration 52/1000 | Loss: 0.00002913
Iteration 53/1000 | Loss: 0.00002913
Iteration 54/1000 | Loss: 0.00002913
Iteration 55/1000 | Loss: 0.00002912
Iteration 56/1000 | Loss: 0.00002912
Iteration 57/1000 | Loss: 0.00002912
Iteration 58/1000 | Loss: 0.00002912
Iteration 59/1000 | Loss: 0.00002912
Iteration 60/1000 | Loss: 0.00002912
Iteration 61/1000 | Loss: 0.00002912
Iteration 62/1000 | Loss: 0.00002911
Iteration 63/1000 | Loss: 0.00002911
Iteration 64/1000 | Loss: 0.00002911
Iteration 65/1000 | Loss: 0.00002911
Iteration 66/1000 | Loss: 0.00002911
Iteration 67/1000 | Loss: 0.00002911
Iteration 68/1000 | Loss: 0.00002911
Iteration 69/1000 | Loss: 0.00002911
Iteration 70/1000 | Loss: 0.00002911
Iteration 71/1000 | Loss: 0.00002911
Iteration 72/1000 | Loss: 0.00002911
Iteration 73/1000 | Loss: 0.00002911
Iteration 74/1000 | Loss: 0.00002911
Iteration 75/1000 | Loss: 0.00002911
Iteration 76/1000 | Loss: 0.00002911
Iteration 77/1000 | Loss: 0.00002911
Iteration 78/1000 | Loss: 0.00002911
Iteration 79/1000 | Loss: 0.00002911
Iteration 80/1000 | Loss: 0.00002911
Iteration 81/1000 | Loss: 0.00002911
Iteration 82/1000 | Loss: 0.00002911
Iteration 83/1000 | Loss: 0.00002911
Iteration 84/1000 | Loss: 0.00002911
Iteration 85/1000 | Loss: 0.00002911
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [2.9109001843607984e-05, 2.9109001843607984e-05, 2.9109001843607984e-05, 2.9109001843607984e-05, 2.9109001843607984e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9109001843607984e-05

Optimization complete. Final v2v error: 4.6965765953063965 mm

Highest mean error: 4.89738655090332 mm for frame 88

Lowest mean error: 4.250936031341553 mm for frame 0

Saving results

Total time: 39.57297325134277
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00365986
Iteration 2/25 | Loss: 0.00100400
Iteration 3/25 | Loss: 0.00089543
Iteration 4/25 | Loss: 0.00087884
Iteration 5/25 | Loss: 0.00087490
Iteration 6/25 | Loss: 0.00087366
Iteration 7/25 | Loss: 0.00087351
Iteration 8/25 | Loss: 0.00087351
Iteration 9/25 | Loss: 0.00087351
Iteration 10/25 | Loss: 0.00087351
Iteration 11/25 | Loss: 0.00087351
Iteration 12/25 | Loss: 0.00087351
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008735115407034755, 0.0008735115407034755, 0.0008735115407034755, 0.0008735115407034755, 0.0008735115407034755]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008735115407034755

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48872769
Iteration 2/25 | Loss: 0.00075688
Iteration 3/25 | Loss: 0.00075688
Iteration 4/25 | Loss: 0.00075688
Iteration 5/25 | Loss: 0.00075688
Iteration 6/25 | Loss: 0.00075688
Iteration 7/25 | Loss: 0.00075688
Iteration 8/25 | Loss: 0.00075688
Iteration 9/25 | Loss: 0.00075688
Iteration 10/25 | Loss: 0.00075688
Iteration 11/25 | Loss: 0.00075688
Iteration 12/25 | Loss: 0.00075688
Iteration 13/25 | Loss: 0.00075688
Iteration 14/25 | Loss: 0.00075688
Iteration 15/25 | Loss: 0.00075688
Iteration 16/25 | Loss: 0.00075688
Iteration 17/25 | Loss: 0.00075688
Iteration 18/25 | Loss: 0.00075688
Iteration 19/25 | Loss: 0.00075688
Iteration 20/25 | Loss: 0.00075688
Iteration 21/25 | Loss: 0.00075688
Iteration 22/25 | Loss: 0.00075688
Iteration 23/25 | Loss: 0.00075688
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0007568803848698735, 0.0007568803848698735, 0.0007568803848698735, 0.0007568803848698735, 0.0007568803848698735]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007568803848698735

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00075688
Iteration 2/1000 | Loss: 0.00002996
Iteration 3/1000 | Loss: 0.00001980
Iteration 4/1000 | Loss: 0.00001716
Iteration 5/1000 | Loss: 0.00001598
Iteration 6/1000 | Loss: 0.00001530
Iteration 7/1000 | Loss: 0.00001506
Iteration 8/1000 | Loss: 0.00001482
Iteration 9/1000 | Loss: 0.00001470
Iteration 10/1000 | Loss: 0.00001467
Iteration 11/1000 | Loss: 0.00001457
Iteration 12/1000 | Loss: 0.00001455
Iteration 13/1000 | Loss: 0.00001444
Iteration 14/1000 | Loss: 0.00001442
Iteration 15/1000 | Loss: 0.00001439
Iteration 16/1000 | Loss: 0.00001436
Iteration 17/1000 | Loss: 0.00001434
Iteration 18/1000 | Loss: 0.00001434
Iteration 19/1000 | Loss: 0.00001433
Iteration 20/1000 | Loss: 0.00001432
Iteration 21/1000 | Loss: 0.00001431
Iteration 22/1000 | Loss: 0.00001431
Iteration 23/1000 | Loss: 0.00001428
Iteration 24/1000 | Loss: 0.00001428
Iteration 25/1000 | Loss: 0.00001426
Iteration 26/1000 | Loss: 0.00001426
Iteration 27/1000 | Loss: 0.00001425
Iteration 28/1000 | Loss: 0.00001425
Iteration 29/1000 | Loss: 0.00001425
Iteration 30/1000 | Loss: 0.00001424
Iteration 31/1000 | Loss: 0.00001424
Iteration 32/1000 | Loss: 0.00001424
Iteration 33/1000 | Loss: 0.00001424
Iteration 34/1000 | Loss: 0.00001424
Iteration 35/1000 | Loss: 0.00001424
Iteration 36/1000 | Loss: 0.00001424
Iteration 37/1000 | Loss: 0.00001423
Iteration 38/1000 | Loss: 0.00001423
Iteration 39/1000 | Loss: 0.00001423
Iteration 40/1000 | Loss: 0.00001423
Iteration 41/1000 | Loss: 0.00001423
Iteration 42/1000 | Loss: 0.00001423
Iteration 43/1000 | Loss: 0.00001423
Iteration 44/1000 | Loss: 0.00001423
Iteration 45/1000 | Loss: 0.00001423
Iteration 46/1000 | Loss: 0.00001423
Iteration 47/1000 | Loss: 0.00001423
Iteration 48/1000 | Loss: 0.00001422
Iteration 49/1000 | Loss: 0.00001422
Iteration 50/1000 | Loss: 0.00001422
Iteration 51/1000 | Loss: 0.00001422
Iteration 52/1000 | Loss: 0.00001421
Iteration 53/1000 | Loss: 0.00001421
Iteration 54/1000 | Loss: 0.00001421
Iteration 55/1000 | Loss: 0.00001421
Iteration 56/1000 | Loss: 0.00001420
Iteration 57/1000 | Loss: 0.00001420
Iteration 58/1000 | Loss: 0.00001420
Iteration 59/1000 | Loss: 0.00001420
Iteration 60/1000 | Loss: 0.00001420
Iteration 61/1000 | Loss: 0.00001420
Iteration 62/1000 | Loss: 0.00001420
Iteration 63/1000 | Loss: 0.00001420
Iteration 64/1000 | Loss: 0.00001420
Iteration 65/1000 | Loss: 0.00001420
Iteration 66/1000 | Loss: 0.00001420
Iteration 67/1000 | Loss: 0.00001420
Iteration 68/1000 | Loss: 0.00001420
Iteration 69/1000 | Loss: 0.00001420
Iteration 70/1000 | Loss: 0.00001420
Iteration 71/1000 | Loss: 0.00001420
Iteration 72/1000 | Loss: 0.00001420
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 72. Stopping optimization.
Last 5 losses: [1.4203013051883318e-05, 1.4203013051883318e-05, 1.4203013051883318e-05, 1.4203013051883318e-05, 1.4203013051883318e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4203013051883318e-05

Optimization complete. Final v2v error: 3.3028788566589355 mm

Highest mean error: 4.160623073577881 mm for frame 10

Lowest mean error: 2.7564425468444824 mm for frame 94

Saving results

Total time: 27.763953924179077
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00416575
Iteration 2/25 | Loss: 0.00105802
Iteration 3/25 | Loss: 0.00093814
Iteration 4/25 | Loss: 0.00091795
Iteration 5/25 | Loss: 0.00091257
Iteration 6/25 | Loss: 0.00091115
Iteration 7/25 | Loss: 0.00091070
Iteration 8/25 | Loss: 0.00091070
Iteration 9/25 | Loss: 0.00091070
Iteration 10/25 | Loss: 0.00091070
Iteration 11/25 | Loss: 0.00091070
Iteration 12/25 | Loss: 0.00091070
Iteration 13/25 | Loss: 0.00091070
Iteration 14/25 | Loss: 0.00091070
Iteration 15/25 | Loss: 0.00091070
Iteration 16/25 | Loss: 0.00091070
Iteration 17/25 | Loss: 0.00091070
Iteration 18/25 | Loss: 0.00091070
Iteration 19/25 | Loss: 0.00091070
Iteration 20/25 | Loss: 0.00091070
Iteration 21/25 | Loss: 0.00091070
Iteration 22/25 | Loss: 0.00091070
Iteration 23/25 | Loss: 0.00091070
Iteration 24/25 | Loss: 0.00091070
Iteration 25/25 | Loss: 0.00091070

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.51223111
Iteration 2/25 | Loss: 0.00071127
Iteration 3/25 | Loss: 0.00071127
Iteration 4/25 | Loss: 0.00071127
Iteration 5/25 | Loss: 0.00071127
Iteration 6/25 | Loss: 0.00071127
Iteration 7/25 | Loss: 0.00071127
Iteration 8/25 | Loss: 0.00071127
Iteration 9/25 | Loss: 0.00071127
Iteration 10/25 | Loss: 0.00071127
Iteration 11/25 | Loss: 0.00071127
Iteration 12/25 | Loss: 0.00071127
Iteration 13/25 | Loss: 0.00071127
Iteration 14/25 | Loss: 0.00071127
Iteration 15/25 | Loss: 0.00071127
Iteration 16/25 | Loss: 0.00071127
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0007112692110240459, 0.0007112692110240459, 0.0007112692110240459, 0.0007112692110240459, 0.0007112692110240459]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007112692110240459

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00071127
Iteration 2/1000 | Loss: 0.00002981
Iteration 3/1000 | Loss: 0.00002187
Iteration 4/1000 | Loss: 0.00001971
Iteration 5/1000 | Loss: 0.00001836
Iteration 6/1000 | Loss: 0.00001754
Iteration 7/1000 | Loss: 0.00001703
Iteration 8/1000 | Loss: 0.00001668
Iteration 9/1000 | Loss: 0.00001650
Iteration 10/1000 | Loss: 0.00001639
Iteration 11/1000 | Loss: 0.00001624
Iteration 12/1000 | Loss: 0.00001622
Iteration 13/1000 | Loss: 0.00001610
Iteration 14/1000 | Loss: 0.00001609
Iteration 15/1000 | Loss: 0.00001605
Iteration 16/1000 | Loss: 0.00001601
Iteration 17/1000 | Loss: 0.00001587
Iteration 18/1000 | Loss: 0.00001583
Iteration 19/1000 | Loss: 0.00001583
Iteration 20/1000 | Loss: 0.00001583
Iteration 21/1000 | Loss: 0.00001582
Iteration 22/1000 | Loss: 0.00001581
Iteration 23/1000 | Loss: 0.00001580
Iteration 24/1000 | Loss: 0.00001579
Iteration 25/1000 | Loss: 0.00001577
Iteration 26/1000 | Loss: 0.00001574
Iteration 27/1000 | Loss: 0.00001574
Iteration 28/1000 | Loss: 0.00001573
Iteration 29/1000 | Loss: 0.00001573
Iteration 30/1000 | Loss: 0.00001573
Iteration 31/1000 | Loss: 0.00001573
Iteration 32/1000 | Loss: 0.00001573
Iteration 33/1000 | Loss: 0.00001573
Iteration 34/1000 | Loss: 0.00001573
Iteration 35/1000 | Loss: 0.00001572
Iteration 36/1000 | Loss: 0.00001572
Iteration 37/1000 | Loss: 0.00001572
Iteration 38/1000 | Loss: 0.00001572
Iteration 39/1000 | Loss: 0.00001572
Iteration 40/1000 | Loss: 0.00001571
Iteration 41/1000 | Loss: 0.00001571
Iteration 42/1000 | Loss: 0.00001571
Iteration 43/1000 | Loss: 0.00001571
Iteration 44/1000 | Loss: 0.00001569
Iteration 45/1000 | Loss: 0.00001569
Iteration 46/1000 | Loss: 0.00001568
Iteration 47/1000 | Loss: 0.00001568
Iteration 48/1000 | Loss: 0.00001568
Iteration 49/1000 | Loss: 0.00001568
Iteration 50/1000 | Loss: 0.00001568
Iteration 51/1000 | Loss: 0.00001568
Iteration 52/1000 | Loss: 0.00001568
Iteration 53/1000 | Loss: 0.00001568
Iteration 54/1000 | Loss: 0.00001568
Iteration 55/1000 | Loss: 0.00001568
Iteration 56/1000 | Loss: 0.00001568
Iteration 57/1000 | Loss: 0.00001567
Iteration 58/1000 | Loss: 0.00001567
Iteration 59/1000 | Loss: 0.00001567
Iteration 60/1000 | Loss: 0.00001567
Iteration 61/1000 | Loss: 0.00001567
Iteration 62/1000 | Loss: 0.00001567
Iteration 63/1000 | Loss: 0.00001567
Iteration 64/1000 | Loss: 0.00001567
Iteration 65/1000 | Loss: 0.00001566
Iteration 66/1000 | Loss: 0.00001566
Iteration 67/1000 | Loss: 0.00001566
Iteration 68/1000 | Loss: 0.00001565
Iteration 69/1000 | Loss: 0.00001565
Iteration 70/1000 | Loss: 0.00001565
Iteration 71/1000 | Loss: 0.00001565
Iteration 72/1000 | Loss: 0.00001565
Iteration 73/1000 | Loss: 0.00001565
Iteration 74/1000 | Loss: 0.00001564
Iteration 75/1000 | Loss: 0.00001564
Iteration 76/1000 | Loss: 0.00001564
Iteration 77/1000 | Loss: 0.00001564
Iteration 78/1000 | Loss: 0.00001564
Iteration 79/1000 | Loss: 0.00001564
Iteration 80/1000 | Loss: 0.00001564
Iteration 81/1000 | Loss: 0.00001564
Iteration 82/1000 | Loss: 0.00001564
Iteration 83/1000 | Loss: 0.00001563
Iteration 84/1000 | Loss: 0.00001563
Iteration 85/1000 | Loss: 0.00001563
Iteration 86/1000 | Loss: 0.00001563
Iteration 87/1000 | Loss: 0.00001563
Iteration 88/1000 | Loss: 0.00001562
Iteration 89/1000 | Loss: 0.00001562
Iteration 90/1000 | Loss: 0.00001562
Iteration 91/1000 | Loss: 0.00001562
Iteration 92/1000 | Loss: 0.00001562
Iteration 93/1000 | Loss: 0.00001561
Iteration 94/1000 | Loss: 0.00001561
Iteration 95/1000 | Loss: 0.00001561
Iteration 96/1000 | Loss: 0.00001561
Iteration 97/1000 | Loss: 0.00001561
Iteration 98/1000 | Loss: 0.00001561
Iteration 99/1000 | Loss: 0.00001560
Iteration 100/1000 | Loss: 0.00001560
Iteration 101/1000 | Loss: 0.00001560
Iteration 102/1000 | Loss: 0.00001560
Iteration 103/1000 | Loss: 0.00001560
Iteration 104/1000 | Loss: 0.00001560
Iteration 105/1000 | Loss: 0.00001560
Iteration 106/1000 | Loss: 0.00001560
Iteration 107/1000 | Loss: 0.00001560
Iteration 108/1000 | Loss: 0.00001560
Iteration 109/1000 | Loss: 0.00001560
Iteration 110/1000 | Loss: 0.00001560
Iteration 111/1000 | Loss: 0.00001559
Iteration 112/1000 | Loss: 0.00001559
Iteration 113/1000 | Loss: 0.00001559
Iteration 114/1000 | Loss: 0.00001559
Iteration 115/1000 | Loss: 0.00001559
Iteration 116/1000 | Loss: 0.00001559
Iteration 117/1000 | Loss: 0.00001559
Iteration 118/1000 | Loss: 0.00001559
Iteration 119/1000 | Loss: 0.00001559
Iteration 120/1000 | Loss: 0.00001558
Iteration 121/1000 | Loss: 0.00001558
Iteration 122/1000 | Loss: 0.00001558
Iteration 123/1000 | Loss: 0.00001557
Iteration 124/1000 | Loss: 0.00001557
Iteration 125/1000 | Loss: 0.00001556
Iteration 126/1000 | Loss: 0.00001556
Iteration 127/1000 | Loss: 0.00001556
Iteration 128/1000 | Loss: 0.00001556
Iteration 129/1000 | Loss: 0.00001556
Iteration 130/1000 | Loss: 0.00001556
Iteration 131/1000 | Loss: 0.00001555
Iteration 132/1000 | Loss: 0.00001555
Iteration 133/1000 | Loss: 0.00001555
Iteration 134/1000 | Loss: 0.00001555
Iteration 135/1000 | Loss: 0.00001555
Iteration 136/1000 | Loss: 0.00001555
Iteration 137/1000 | Loss: 0.00001555
Iteration 138/1000 | Loss: 0.00001554
Iteration 139/1000 | Loss: 0.00001554
Iteration 140/1000 | Loss: 0.00001554
Iteration 141/1000 | Loss: 0.00001554
Iteration 142/1000 | Loss: 0.00001554
Iteration 143/1000 | Loss: 0.00001554
Iteration 144/1000 | Loss: 0.00001554
Iteration 145/1000 | Loss: 0.00001554
Iteration 146/1000 | Loss: 0.00001554
Iteration 147/1000 | Loss: 0.00001554
Iteration 148/1000 | Loss: 0.00001554
Iteration 149/1000 | Loss: 0.00001554
Iteration 150/1000 | Loss: 0.00001554
Iteration 151/1000 | Loss: 0.00001554
Iteration 152/1000 | Loss: 0.00001553
Iteration 153/1000 | Loss: 0.00001553
Iteration 154/1000 | Loss: 0.00001553
Iteration 155/1000 | Loss: 0.00001553
Iteration 156/1000 | Loss: 0.00001553
Iteration 157/1000 | Loss: 0.00001553
Iteration 158/1000 | Loss: 0.00001553
Iteration 159/1000 | Loss: 0.00001553
Iteration 160/1000 | Loss: 0.00001553
Iteration 161/1000 | Loss: 0.00001552
Iteration 162/1000 | Loss: 0.00001552
Iteration 163/1000 | Loss: 0.00001552
Iteration 164/1000 | Loss: 0.00001552
Iteration 165/1000 | Loss: 0.00001552
Iteration 166/1000 | Loss: 0.00001552
Iteration 167/1000 | Loss: 0.00001552
Iteration 168/1000 | Loss: 0.00001552
Iteration 169/1000 | Loss: 0.00001552
Iteration 170/1000 | Loss: 0.00001552
Iteration 171/1000 | Loss: 0.00001552
Iteration 172/1000 | Loss: 0.00001552
Iteration 173/1000 | Loss: 0.00001552
Iteration 174/1000 | Loss: 0.00001552
Iteration 175/1000 | Loss: 0.00001552
Iteration 176/1000 | Loss: 0.00001552
Iteration 177/1000 | Loss: 0.00001551
Iteration 178/1000 | Loss: 0.00001551
Iteration 179/1000 | Loss: 0.00001551
Iteration 180/1000 | Loss: 0.00001551
Iteration 181/1000 | Loss: 0.00001551
Iteration 182/1000 | Loss: 0.00001551
Iteration 183/1000 | Loss: 0.00001551
Iteration 184/1000 | Loss: 0.00001551
Iteration 185/1000 | Loss: 0.00001551
Iteration 186/1000 | Loss: 0.00001551
Iteration 187/1000 | Loss: 0.00001551
Iteration 188/1000 | Loss: 0.00001551
Iteration 189/1000 | Loss: 0.00001551
Iteration 190/1000 | Loss: 0.00001551
Iteration 191/1000 | Loss: 0.00001551
Iteration 192/1000 | Loss: 0.00001551
Iteration 193/1000 | Loss: 0.00001551
Iteration 194/1000 | Loss: 0.00001550
Iteration 195/1000 | Loss: 0.00001550
Iteration 196/1000 | Loss: 0.00001550
Iteration 197/1000 | Loss: 0.00001550
Iteration 198/1000 | Loss: 0.00001550
Iteration 199/1000 | Loss: 0.00001550
Iteration 200/1000 | Loss: 0.00001550
Iteration 201/1000 | Loss: 0.00001550
Iteration 202/1000 | Loss: 0.00001550
Iteration 203/1000 | Loss: 0.00001550
Iteration 204/1000 | Loss: 0.00001550
Iteration 205/1000 | Loss: 0.00001549
Iteration 206/1000 | Loss: 0.00001549
Iteration 207/1000 | Loss: 0.00001549
Iteration 208/1000 | Loss: 0.00001549
Iteration 209/1000 | Loss: 0.00001549
Iteration 210/1000 | Loss: 0.00001549
Iteration 211/1000 | Loss: 0.00001549
Iteration 212/1000 | Loss: 0.00001548
Iteration 213/1000 | Loss: 0.00001548
Iteration 214/1000 | Loss: 0.00001548
Iteration 215/1000 | Loss: 0.00001548
Iteration 216/1000 | Loss: 0.00001548
Iteration 217/1000 | Loss: 0.00001548
Iteration 218/1000 | Loss: 0.00001548
Iteration 219/1000 | Loss: 0.00001548
Iteration 220/1000 | Loss: 0.00001548
Iteration 221/1000 | Loss: 0.00001548
Iteration 222/1000 | Loss: 0.00001548
Iteration 223/1000 | Loss: 0.00001548
Iteration 224/1000 | Loss: 0.00001548
Iteration 225/1000 | Loss: 0.00001548
Iteration 226/1000 | Loss: 0.00001548
Iteration 227/1000 | Loss: 0.00001548
Iteration 228/1000 | Loss: 0.00001548
Iteration 229/1000 | Loss: 0.00001548
Iteration 230/1000 | Loss: 0.00001548
Iteration 231/1000 | Loss: 0.00001548
Iteration 232/1000 | Loss: 0.00001548
Iteration 233/1000 | Loss: 0.00001548
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 233. Stopping optimization.
Last 5 losses: [1.54752706293948e-05, 1.54752706293948e-05, 1.54752706293948e-05, 1.54752706293948e-05, 1.54752706293948e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.54752706293948e-05

Optimization complete. Final v2v error: 3.3005595207214355 mm

Highest mean error: 3.503826379776001 mm for frame 28

Lowest mean error: 3.1599462032318115 mm for frame 65

Saving results

Total time: 40.66300940513611
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00499325
Iteration 2/25 | Loss: 0.00102120
Iteration 3/25 | Loss: 0.00091012
Iteration 4/25 | Loss: 0.00089344
Iteration 5/25 | Loss: 0.00088829
Iteration 6/25 | Loss: 0.00088683
Iteration 7/25 | Loss: 0.00088641
Iteration 8/25 | Loss: 0.00088641
Iteration 9/25 | Loss: 0.00088641
Iteration 10/25 | Loss: 0.00088641
Iteration 11/25 | Loss: 0.00088641
Iteration 12/25 | Loss: 0.00088641
Iteration 13/25 | Loss: 0.00088641
Iteration 14/25 | Loss: 0.00088641
Iteration 15/25 | Loss: 0.00088641
Iteration 16/25 | Loss: 0.00088641
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0008864104165695608, 0.0008864104165695608, 0.0008864104165695608, 0.0008864104165695608, 0.0008864104165695608]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008864104165695608

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.18837214
Iteration 2/25 | Loss: 0.00063157
Iteration 3/25 | Loss: 0.00063156
Iteration 4/25 | Loss: 0.00063156
Iteration 5/25 | Loss: 0.00063156
Iteration 6/25 | Loss: 0.00063156
Iteration 7/25 | Loss: 0.00063156
Iteration 8/25 | Loss: 0.00063156
Iteration 9/25 | Loss: 0.00063156
Iteration 10/25 | Loss: 0.00063156
Iteration 11/25 | Loss: 0.00063156
Iteration 12/25 | Loss: 0.00063156
Iteration 13/25 | Loss: 0.00063156
Iteration 14/25 | Loss: 0.00063156
Iteration 15/25 | Loss: 0.00063156
Iteration 16/25 | Loss: 0.00063156
Iteration 17/25 | Loss: 0.00063156
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006315598147921264, 0.0006315598147921264, 0.0006315598147921264, 0.0006315598147921264, 0.0006315598147921264]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006315598147921264

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00063156
Iteration 2/1000 | Loss: 0.00002244
Iteration 3/1000 | Loss: 0.00001860
Iteration 4/1000 | Loss: 0.00001722
Iteration 5/1000 | Loss: 0.00001654
Iteration 6/1000 | Loss: 0.00001598
Iteration 7/1000 | Loss: 0.00001573
Iteration 8/1000 | Loss: 0.00001570
Iteration 9/1000 | Loss: 0.00001568
Iteration 10/1000 | Loss: 0.00001561
Iteration 11/1000 | Loss: 0.00001560
Iteration 12/1000 | Loss: 0.00001559
Iteration 13/1000 | Loss: 0.00001558
Iteration 14/1000 | Loss: 0.00001558
Iteration 15/1000 | Loss: 0.00001557
Iteration 16/1000 | Loss: 0.00001557
Iteration 17/1000 | Loss: 0.00001557
Iteration 18/1000 | Loss: 0.00001556
Iteration 19/1000 | Loss: 0.00001555
Iteration 20/1000 | Loss: 0.00001553
Iteration 21/1000 | Loss: 0.00001552
Iteration 22/1000 | Loss: 0.00001552
Iteration 23/1000 | Loss: 0.00001551
Iteration 24/1000 | Loss: 0.00001550
Iteration 25/1000 | Loss: 0.00001549
Iteration 26/1000 | Loss: 0.00001549
Iteration 27/1000 | Loss: 0.00001548
Iteration 28/1000 | Loss: 0.00001548
Iteration 29/1000 | Loss: 0.00001547
Iteration 30/1000 | Loss: 0.00001547
Iteration 31/1000 | Loss: 0.00001547
Iteration 32/1000 | Loss: 0.00001547
Iteration 33/1000 | Loss: 0.00001546
Iteration 34/1000 | Loss: 0.00001546
Iteration 35/1000 | Loss: 0.00001545
Iteration 36/1000 | Loss: 0.00001545
Iteration 37/1000 | Loss: 0.00001545
Iteration 38/1000 | Loss: 0.00001544
Iteration 39/1000 | Loss: 0.00001544
Iteration 40/1000 | Loss: 0.00001543
Iteration 41/1000 | Loss: 0.00001543
Iteration 42/1000 | Loss: 0.00001543
Iteration 43/1000 | Loss: 0.00001542
Iteration 44/1000 | Loss: 0.00001541
Iteration 45/1000 | Loss: 0.00001541
Iteration 46/1000 | Loss: 0.00001541
Iteration 47/1000 | Loss: 0.00001541
Iteration 48/1000 | Loss: 0.00001541
Iteration 49/1000 | Loss: 0.00001541
Iteration 50/1000 | Loss: 0.00001541
Iteration 51/1000 | Loss: 0.00001541
Iteration 52/1000 | Loss: 0.00001541
Iteration 53/1000 | Loss: 0.00001541
Iteration 54/1000 | Loss: 0.00001541
Iteration 55/1000 | Loss: 0.00001541
Iteration 56/1000 | Loss: 0.00001540
Iteration 57/1000 | Loss: 0.00001540
Iteration 58/1000 | Loss: 0.00001540
Iteration 59/1000 | Loss: 0.00001540
Iteration 60/1000 | Loss: 0.00001539
Iteration 61/1000 | Loss: 0.00001539
Iteration 62/1000 | Loss: 0.00001539
Iteration 63/1000 | Loss: 0.00001539
Iteration 64/1000 | Loss: 0.00001539
Iteration 65/1000 | Loss: 0.00001539
Iteration 66/1000 | Loss: 0.00001539
Iteration 67/1000 | Loss: 0.00001539
Iteration 68/1000 | Loss: 0.00001538
Iteration 69/1000 | Loss: 0.00001538
Iteration 70/1000 | Loss: 0.00001538
Iteration 71/1000 | Loss: 0.00001538
Iteration 72/1000 | Loss: 0.00001537
Iteration 73/1000 | Loss: 0.00001537
Iteration 74/1000 | Loss: 0.00001537
Iteration 75/1000 | Loss: 0.00001537
Iteration 76/1000 | Loss: 0.00001537
Iteration 77/1000 | Loss: 0.00001536
Iteration 78/1000 | Loss: 0.00001536
Iteration 79/1000 | Loss: 0.00001536
Iteration 80/1000 | Loss: 0.00001536
Iteration 81/1000 | Loss: 0.00001536
Iteration 82/1000 | Loss: 0.00001536
Iteration 83/1000 | Loss: 0.00001536
Iteration 84/1000 | Loss: 0.00001535
Iteration 85/1000 | Loss: 0.00001535
Iteration 86/1000 | Loss: 0.00001535
Iteration 87/1000 | Loss: 0.00001535
Iteration 88/1000 | Loss: 0.00001535
Iteration 89/1000 | Loss: 0.00001535
Iteration 90/1000 | Loss: 0.00001534
Iteration 91/1000 | Loss: 0.00001534
Iteration 92/1000 | Loss: 0.00001534
Iteration 93/1000 | Loss: 0.00001534
Iteration 94/1000 | Loss: 0.00001534
Iteration 95/1000 | Loss: 0.00001534
Iteration 96/1000 | Loss: 0.00001534
Iteration 97/1000 | Loss: 0.00001534
Iteration 98/1000 | Loss: 0.00001533
Iteration 99/1000 | Loss: 0.00001533
Iteration 100/1000 | Loss: 0.00001533
Iteration 101/1000 | Loss: 0.00001533
Iteration 102/1000 | Loss: 0.00001533
Iteration 103/1000 | Loss: 0.00001533
Iteration 104/1000 | Loss: 0.00001533
Iteration 105/1000 | Loss: 0.00001533
Iteration 106/1000 | Loss: 0.00001533
Iteration 107/1000 | Loss: 0.00001533
Iteration 108/1000 | Loss: 0.00001533
Iteration 109/1000 | Loss: 0.00001532
Iteration 110/1000 | Loss: 0.00001532
Iteration 111/1000 | Loss: 0.00001532
Iteration 112/1000 | Loss: 0.00001532
Iteration 113/1000 | Loss: 0.00001532
Iteration 114/1000 | Loss: 0.00001532
Iteration 115/1000 | Loss: 0.00001532
Iteration 116/1000 | Loss: 0.00001532
Iteration 117/1000 | Loss: 0.00001532
Iteration 118/1000 | Loss: 0.00001532
Iteration 119/1000 | Loss: 0.00001532
Iteration 120/1000 | Loss: 0.00001532
Iteration 121/1000 | Loss: 0.00001532
Iteration 122/1000 | Loss: 0.00001532
Iteration 123/1000 | Loss: 0.00001532
Iteration 124/1000 | Loss: 0.00001532
Iteration 125/1000 | Loss: 0.00001532
Iteration 126/1000 | Loss: 0.00001532
Iteration 127/1000 | Loss: 0.00001532
Iteration 128/1000 | Loss: 0.00001532
Iteration 129/1000 | Loss: 0.00001532
Iteration 130/1000 | Loss: 0.00001532
Iteration 131/1000 | Loss: 0.00001532
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 131. Stopping optimization.
Last 5 losses: [1.5318166333599947e-05, 1.5318166333599947e-05, 1.5318166333599947e-05, 1.5318166333599947e-05, 1.5318166333599947e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5318166333599947e-05

Optimization complete. Final v2v error: 3.349545955657959 mm

Highest mean error: 3.697148084640503 mm for frame 45

Lowest mean error: 2.9311811923980713 mm for frame 59

Saving results

Total time: 28.456605672836304
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01076740
Iteration 2/25 | Loss: 0.00340826
Iteration 3/25 | Loss: 0.00232646
Iteration 4/25 | Loss: 0.00185924
Iteration 5/25 | Loss: 0.00197097
Iteration 6/25 | Loss: 0.00192932
Iteration 7/25 | Loss: 0.00163620
Iteration 8/25 | Loss: 0.00148562
Iteration 9/25 | Loss: 0.00144137
Iteration 10/25 | Loss: 0.00140891
Iteration 11/25 | Loss: 0.00140405
Iteration 12/25 | Loss: 0.00139931
Iteration 13/25 | Loss: 0.00139291
Iteration 14/25 | Loss: 0.00139010
Iteration 15/25 | Loss: 0.00138785
Iteration 16/25 | Loss: 0.00138741
Iteration 17/25 | Loss: 0.00138575
Iteration 18/25 | Loss: 0.00138545
Iteration 19/25 | Loss: 0.00138809
Iteration 20/25 | Loss: 0.00138626
Iteration 21/25 | Loss: 0.00139732
Iteration 22/25 | Loss: 0.00139007
Iteration 23/25 | Loss: 0.00138630
Iteration 24/25 | Loss: 0.00139423
Iteration 25/25 | Loss: 0.00138850

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.49727011
Iteration 2/25 | Loss: 0.00513193
Iteration 3/25 | Loss: 0.00495427
Iteration 4/25 | Loss: 0.00495427
Iteration 5/25 | Loss: 0.00495426
Iteration 6/25 | Loss: 0.00495426
Iteration 7/25 | Loss: 0.00495426
Iteration 8/25 | Loss: 0.00495426
Iteration 9/25 | Loss: 0.00495426
Iteration 10/25 | Loss: 0.00495426
Iteration 11/25 | Loss: 0.00495426
Iteration 12/25 | Loss: 0.00495426
Iteration 13/25 | Loss: 0.00495426
Iteration 14/25 | Loss: 0.00495426
Iteration 15/25 | Loss: 0.00495426
Iteration 16/25 | Loss: 0.00495426
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.004954262636601925, 0.004954262636601925, 0.004954262636601925, 0.004954262636601925, 0.004954262636601925]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.004954262636601925

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00495426
Iteration 2/1000 | Loss: 0.00101230
Iteration 3/1000 | Loss: 0.01245665
Iteration 4/1000 | Loss: 0.00805097
Iteration 5/1000 | Loss: 0.01719414
Iteration 6/1000 | Loss: 0.00499121
Iteration 7/1000 | Loss: 0.00316896
Iteration 8/1000 | Loss: 0.00096062
Iteration 9/1000 | Loss: 0.00393959
Iteration 10/1000 | Loss: 0.00036465
Iteration 11/1000 | Loss: 0.00296847
Iteration 12/1000 | Loss: 0.00179318
Iteration 13/1000 | Loss: 0.00109180
Iteration 14/1000 | Loss: 0.00045066
Iteration 15/1000 | Loss: 0.00088795
Iteration 16/1000 | Loss: 0.00110660
Iteration 17/1000 | Loss: 0.00564067
Iteration 18/1000 | Loss: 0.00118743
Iteration 19/1000 | Loss: 0.00168624
Iteration 20/1000 | Loss: 0.00219693
Iteration 21/1000 | Loss: 0.00036926
Iteration 22/1000 | Loss: 0.00022480
Iteration 23/1000 | Loss: 0.00009710
Iteration 24/1000 | Loss: 0.00053909
Iteration 25/1000 | Loss: 0.00008240
Iteration 26/1000 | Loss: 0.00092151
Iteration 27/1000 | Loss: 0.00006321
Iteration 28/1000 | Loss: 0.00007428
Iteration 29/1000 | Loss: 0.00035253
Iteration 30/1000 | Loss: 0.00015668
Iteration 31/1000 | Loss: 0.00005570
Iteration 32/1000 | Loss: 0.00016667
Iteration 33/1000 | Loss: 0.00010989
Iteration 34/1000 | Loss: 0.00005213
Iteration 35/1000 | Loss: 0.00004725
Iteration 36/1000 | Loss: 0.00004541
Iteration 37/1000 | Loss: 0.00004393
Iteration 38/1000 | Loss: 0.00004276
Iteration 39/1000 | Loss: 0.00004209
Iteration 40/1000 | Loss: 0.00004131
Iteration 41/1000 | Loss: 0.00004075
Iteration 42/1000 | Loss: 0.00004026
Iteration 43/1000 | Loss: 0.00005040
Iteration 44/1000 | Loss: 0.00004154
Iteration 45/1000 | Loss: 0.00004001
Iteration 46/1000 | Loss: 0.00104619
Iteration 47/1000 | Loss: 0.00092735
Iteration 48/1000 | Loss: 0.00013706
Iteration 49/1000 | Loss: 0.00005310
Iteration 50/1000 | Loss: 0.00004868
Iteration 51/1000 | Loss: 0.00004051
Iteration 52/1000 | Loss: 0.00003886
Iteration 53/1000 | Loss: 0.00003853
Iteration 54/1000 | Loss: 0.00003832
Iteration 55/1000 | Loss: 0.00003811
Iteration 56/1000 | Loss: 0.00003805
Iteration 57/1000 | Loss: 0.00003796
Iteration 58/1000 | Loss: 0.00003784
Iteration 59/1000 | Loss: 0.00003779
Iteration 60/1000 | Loss: 0.00003774
Iteration 61/1000 | Loss: 0.00003773
Iteration 62/1000 | Loss: 0.00003769
Iteration 63/1000 | Loss: 0.00003769
Iteration 64/1000 | Loss: 0.00003768
Iteration 65/1000 | Loss: 0.00003763
Iteration 66/1000 | Loss: 0.00003763
Iteration 67/1000 | Loss: 0.00003761
Iteration 68/1000 | Loss: 0.00003761
Iteration 69/1000 | Loss: 0.00003761
Iteration 70/1000 | Loss: 0.00003760
Iteration 71/1000 | Loss: 0.00003760
Iteration 72/1000 | Loss: 0.00003759
Iteration 73/1000 | Loss: 0.00003758
Iteration 74/1000 | Loss: 0.00003757
Iteration 75/1000 | Loss: 0.00003757
Iteration 76/1000 | Loss: 0.00003757
Iteration 77/1000 | Loss: 0.00003757
Iteration 78/1000 | Loss: 0.00003756
Iteration 79/1000 | Loss: 0.00003756
Iteration 80/1000 | Loss: 0.00003756
Iteration 81/1000 | Loss: 0.00003756
Iteration 82/1000 | Loss: 0.00003755
Iteration 83/1000 | Loss: 0.00003755
Iteration 84/1000 | Loss: 0.00003755
Iteration 85/1000 | Loss: 0.00003755
Iteration 86/1000 | Loss: 0.00003754
Iteration 87/1000 | Loss: 0.00003754
Iteration 88/1000 | Loss: 0.00003754
Iteration 89/1000 | Loss: 0.00003754
Iteration 90/1000 | Loss: 0.00003753
Iteration 91/1000 | Loss: 0.00003753
Iteration 92/1000 | Loss: 0.00003753
Iteration 93/1000 | Loss: 0.00003753
Iteration 94/1000 | Loss: 0.00003752
Iteration 95/1000 | Loss: 0.00003752
Iteration 96/1000 | Loss: 0.00003752
Iteration 97/1000 | Loss: 0.00003751
Iteration 98/1000 | Loss: 0.00003751
Iteration 99/1000 | Loss: 0.00003750
Iteration 100/1000 | Loss: 0.00003750
Iteration 101/1000 | Loss: 0.00003750
Iteration 102/1000 | Loss: 0.00003750
Iteration 103/1000 | Loss: 0.00003750
Iteration 104/1000 | Loss: 0.00003749
Iteration 105/1000 | Loss: 0.00003749
Iteration 106/1000 | Loss: 0.00003749
Iteration 107/1000 | Loss: 0.00003749
Iteration 108/1000 | Loss: 0.00003749
Iteration 109/1000 | Loss: 0.00003749
Iteration 110/1000 | Loss: 0.00003748
Iteration 111/1000 | Loss: 0.00003748
Iteration 112/1000 | Loss: 0.00003748
Iteration 113/1000 | Loss: 0.00003748
Iteration 114/1000 | Loss: 0.00003748
Iteration 115/1000 | Loss: 0.00003747
Iteration 116/1000 | Loss: 0.00003747
Iteration 117/1000 | Loss: 0.00003747
Iteration 118/1000 | Loss: 0.00003746
Iteration 119/1000 | Loss: 0.00003746
Iteration 120/1000 | Loss: 0.00103010
Iteration 121/1000 | Loss: 0.00005976
Iteration 122/1000 | Loss: 0.00004685
Iteration 123/1000 | Loss: 0.00004074
Iteration 124/1000 | Loss: 0.00003725
Iteration 125/1000 | Loss: 0.00003598
Iteration 126/1000 | Loss: 0.00003524
Iteration 127/1000 | Loss: 0.00003473
Iteration 128/1000 | Loss: 0.00003446
Iteration 129/1000 | Loss: 0.00003428
Iteration 130/1000 | Loss: 0.00003424
Iteration 131/1000 | Loss: 0.00003420
Iteration 132/1000 | Loss: 0.00003418
Iteration 133/1000 | Loss: 0.00003417
Iteration 134/1000 | Loss: 0.00003416
Iteration 135/1000 | Loss: 0.00003415
Iteration 136/1000 | Loss: 0.00003415
Iteration 137/1000 | Loss: 0.00003414
Iteration 138/1000 | Loss: 0.00003413
Iteration 139/1000 | Loss: 0.00003413
Iteration 140/1000 | Loss: 0.00003413
Iteration 141/1000 | Loss: 0.00003412
Iteration 142/1000 | Loss: 0.00003412
Iteration 143/1000 | Loss: 0.00003411
Iteration 144/1000 | Loss: 0.00003411
Iteration 145/1000 | Loss: 0.00003410
Iteration 146/1000 | Loss: 0.00003410
Iteration 147/1000 | Loss: 0.00003409
Iteration 148/1000 | Loss: 0.00003409
Iteration 149/1000 | Loss: 0.00003409
Iteration 150/1000 | Loss: 0.00003408
Iteration 151/1000 | Loss: 0.00003408
Iteration 152/1000 | Loss: 0.00003408
Iteration 153/1000 | Loss: 0.00003407
Iteration 154/1000 | Loss: 0.00003407
Iteration 155/1000 | Loss: 0.00003407
Iteration 156/1000 | Loss: 0.00003406
Iteration 157/1000 | Loss: 0.00003406
Iteration 158/1000 | Loss: 0.00003405
Iteration 159/1000 | Loss: 0.00003405
Iteration 160/1000 | Loss: 0.00003405
Iteration 161/1000 | Loss: 0.00003403
Iteration 162/1000 | Loss: 0.00003403
Iteration 163/1000 | Loss: 0.00003402
Iteration 164/1000 | Loss: 0.00003402
Iteration 165/1000 | Loss: 0.00003402
Iteration 166/1000 | Loss: 0.00003401
Iteration 167/1000 | Loss: 0.00003401
Iteration 168/1000 | Loss: 0.00003401
Iteration 169/1000 | Loss: 0.00003401
Iteration 170/1000 | Loss: 0.00003400
Iteration 171/1000 | Loss: 0.00003400
Iteration 172/1000 | Loss: 0.00003400
Iteration 173/1000 | Loss: 0.00003400
Iteration 174/1000 | Loss: 0.00003400
Iteration 175/1000 | Loss: 0.00003400
Iteration 176/1000 | Loss: 0.00003400
Iteration 177/1000 | Loss: 0.00003400
Iteration 178/1000 | Loss: 0.00003399
Iteration 179/1000 | Loss: 0.00003399
Iteration 180/1000 | Loss: 0.00003398
Iteration 181/1000 | Loss: 0.00003398
Iteration 182/1000 | Loss: 0.00003398
Iteration 183/1000 | Loss: 0.00003398
Iteration 184/1000 | Loss: 0.00003397
Iteration 185/1000 | Loss: 0.00003397
Iteration 186/1000 | Loss: 0.00003397
Iteration 187/1000 | Loss: 0.00003397
Iteration 188/1000 | Loss: 0.00003396
Iteration 189/1000 | Loss: 0.00003396
Iteration 190/1000 | Loss: 0.00003396
Iteration 191/1000 | Loss: 0.00003396
Iteration 192/1000 | Loss: 0.00003396
Iteration 193/1000 | Loss: 0.00003396
Iteration 194/1000 | Loss: 0.00003396
Iteration 195/1000 | Loss: 0.00003395
Iteration 196/1000 | Loss: 0.00003395
Iteration 197/1000 | Loss: 0.00003395
Iteration 198/1000 | Loss: 0.00003395
Iteration 199/1000 | Loss: 0.00003395
Iteration 200/1000 | Loss: 0.00003395
Iteration 201/1000 | Loss: 0.00003395
Iteration 202/1000 | Loss: 0.00003395
Iteration 203/1000 | Loss: 0.00003395
Iteration 204/1000 | Loss: 0.00003395
Iteration 205/1000 | Loss: 0.00003394
Iteration 206/1000 | Loss: 0.00003394
Iteration 207/1000 | Loss: 0.00003394
Iteration 208/1000 | Loss: 0.00003394
Iteration 209/1000 | Loss: 0.00003394
Iteration 210/1000 | Loss: 0.00003394
Iteration 211/1000 | Loss: 0.00003394
Iteration 212/1000 | Loss: 0.00003394
Iteration 213/1000 | Loss: 0.00003394
Iteration 214/1000 | Loss: 0.00003394
Iteration 215/1000 | Loss: 0.00003394
Iteration 216/1000 | Loss: 0.00003394
Iteration 217/1000 | Loss: 0.00003394
Iteration 218/1000 | Loss: 0.00003394
Iteration 219/1000 | Loss: 0.00003394
Iteration 220/1000 | Loss: 0.00003394
Iteration 221/1000 | Loss: 0.00003394
Iteration 222/1000 | Loss: 0.00003394
Iteration 223/1000 | Loss: 0.00003393
Iteration 224/1000 | Loss: 0.00003393
Iteration 225/1000 | Loss: 0.00003393
Iteration 226/1000 | Loss: 0.00003393
Iteration 227/1000 | Loss: 0.00003393
Iteration 228/1000 | Loss: 0.00003393
Iteration 229/1000 | Loss: 0.00003393
Iteration 230/1000 | Loss: 0.00003393
Iteration 231/1000 | Loss: 0.00003393
Iteration 232/1000 | Loss: 0.00003393
Iteration 233/1000 | Loss: 0.00003393
Iteration 234/1000 | Loss: 0.00003393
Iteration 235/1000 | Loss: 0.00003393
Iteration 236/1000 | Loss: 0.00003393
Iteration 237/1000 | Loss: 0.00003393
Iteration 238/1000 | Loss: 0.00003393
Iteration 239/1000 | Loss: 0.00003393
Iteration 240/1000 | Loss: 0.00003393
Iteration 241/1000 | Loss: 0.00003393
Iteration 242/1000 | Loss: 0.00003393
Iteration 243/1000 | Loss: 0.00003393
Iteration 244/1000 | Loss: 0.00003393
Iteration 245/1000 | Loss: 0.00003393
Iteration 246/1000 | Loss: 0.00003393
Iteration 247/1000 | Loss: 0.00003393
Iteration 248/1000 | Loss: 0.00003393
Iteration 249/1000 | Loss: 0.00003393
Iteration 250/1000 | Loss: 0.00003393
Iteration 251/1000 | Loss: 0.00003393
Iteration 252/1000 | Loss: 0.00003393
Iteration 253/1000 | Loss: 0.00003393
Iteration 254/1000 | Loss: 0.00003393
Iteration 255/1000 | Loss: 0.00003393
Iteration 256/1000 | Loss: 0.00003393
Iteration 257/1000 | Loss: 0.00003393
Iteration 258/1000 | Loss: 0.00003393
Iteration 259/1000 | Loss: 0.00003393
Iteration 260/1000 | Loss: 0.00003393
Iteration 261/1000 | Loss: 0.00003393
Iteration 262/1000 | Loss: 0.00003393
Iteration 263/1000 | Loss: 0.00003393
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 263. Stopping optimization.
Last 5 losses: [3.3932632504729554e-05, 3.3932632504729554e-05, 3.3932632504729554e-05, 3.3932632504729554e-05, 3.3932632504729554e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.3932632504729554e-05

Optimization complete. Final v2v error: 4.573720932006836 mm

Highest mean error: 14.478768348693848 mm for frame 44

Lowest mean error: 3.470351219177246 mm for frame 198

Saving results

Total time: 162.7246537208557
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00443140
Iteration 2/25 | Loss: 0.00102266
Iteration 3/25 | Loss: 0.00093792
Iteration 4/25 | Loss: 0.00091446
Iteration 5/25 | Loss: 0.00090588
Iteration 6/25 | Loss: 0.00090393
Iteration 7/25 | Loss: 0.00090348
Iteration 8/25 | Loss: 0.00090348
Iteration 9/25 | Loss: 0.00090348
Iteration 10/25 | Loss: 0.00090348
Iteration 11/25 | Loss: 0.00090348
Iteration 12/25 | Loss: 0.00090348
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000903480511624366, 0.000903480511624366, 0.000903480511624366, 0.000903480511624366, 0.000903480511624366]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000903480511624366

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.60861802
Iteration 2/25 | Loss: 0.00062982
Iteration 3/25 | Loss: 0.00062982
Iteration 4/25 | Loss: 0.00062981
Iteration 5/25 | Loss: 0.00062981
Iteration 6/25 | Loss: 0.00062981
Iteration 7/25 | Loss: 0.00062981
Iteration 8/25 | Loss: 0.00062981
Iteration 9/25 | Loss: 0.00062981
Iteration 10/25 | Loss: 0.00062981
Iteration 11/25 | Loss: 0.00062981
Iteration 12/25 | Loss: 0.00062981
Iteration 13/25 | Loss: 0.00062981
Iteration 14/25 | Loss: 0.00062981
Iteration 15/25 | Loss: 0.00062981
Iteration 16/25 | Loss: 0.00062981
Iteration 17/25 | Loss: 0.00062981
Iteration 18/25 | Loss: 0.00062981
Iteration 19/25 | Loss: 0.00062981
Iteration 20/25 | Loss: 0.00062981
Iteration 21/25 | Loss: 0.00062981
Iteration 22/25 | Loss: 0.00062981
Iteration 23/25 | Loss: 0.00062981
Iteration 24/25 | Loss: 0.00062981
Iteration 25/25 | Loss: 0.00062981

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00062981
Iteration 2/1000 | Loss: 0.00003430
Iteration 3/1000 | Loss: 0.00002713
Iteration 4/1000 | Loss: 0.00002457
Iteration 5/1000 | Loss: 0.00002345
Iteration 6/1000 | Loss: 0.00002261
Iteration 7/1000 | Loss: 0.00002224
Iteration 8/1000 | Loss: 0.00002194
Iteration 9/1000 | Loss: 0.00002187
Iteration 10/1000 | Loss: 0.00002182
Iteration 11/1000 | Loss: 0.00002175
Iteration 12/1000 | Loss: 0.00002166
Iteration 13/1000 | Loss: 0.00002160
Iteration 14/1000 | Loss: 0.00002160
Iteration 15/1000 | Loss: 0.00002158
Iteration 16/1000 | Loss: 0.00002158
Iteration 17/1000 | Loss: 0.00002157
Iteration 18/1000 | Loss: 0.00002157
Iteration 19/1000 | Loss: 0.00002157
Iteration 20/1000 | Loss: 0.00002157
Iteration 21/1000 | Loss: 0.00002156
Iteration 22/1000 | Loss: 0.00002156
Iteration 23/1000 | Loss: 0.00002155
Iteration 24/1000 | Loss: 0.00002154
Iteration 25/1000 | Loss: 0.00002154
Iteration 26/1000 | Loss: 0.00002154
Iteration 27/1000 | Loss: 0.00002154
Iteration 28/1000 | Loss: 0.00002154
Iteration 29/1000 | Loss: 0.00002154
Iteration 30/1000 | Loss: 0.00002153
Iteration 31/1000 | Loss: 0.00002153
Iteration 32/1000 | Loss: 0.00002153
Iteration 33/1000 | Loss: 0.00002153
Iteration 34/1000 | Loss: 0.00002153
Iteration 35/1000 | Loss: 0.00002153
Iteration 36/1000 | Loss: 0.00002153
Iteration 37/1000 | Loss: 0.00002153
Iteration 38/1000 | Loss: 0.00002153
Iteration 39/1000 | Loss: 0.00002153
Iteration 40/1000 | Loss: 0.00002153
Iteration 41/1000 | Loss: 0.00002153
Iteration 42/1000 | Loss: 0.00002153
Iteration 43/1000 | Loss: 0.00002153
Iteration 44/1000 | Loss: 0.00002153
Iteration 45/1000 | Loss: 0.00002153
Iteration 46/1000 | Loss: 0.00002152
Iteration 47/1000 | Loss: 0.00002152
Iteration 48/1000 | Loss: 0.00002152
Iteration 49/1000 | Loss: 0.00002152
Iteration 50/1000 | Loss: 0.00002152
Iteration 51/1000 | Loss: 0.00002152
Iteration 52/1000 | Loss: 0.00002152
Iteration 53/1000 | Loss: 0.00002152
Iteration 54/1000 | Loss: 0.00002152
Iteration 55/1000 | Loss: 0.00002152
Iteration 56/1000 | Loss: 0.00002151
Iteration 57/1000 | Loss: 0.00002151
Iteration 58/1000 | Loss: 0.00002151
Iteration 59/1000 | Loss: 0.00002151
Iteration 60/1000 | Loss: 0.00002151
Iteration 61/1000 | Loss: 0.00002151
Iteration 62/1000 | Loss: 0.00002151
Iteration 63/1000 | Loss: 0.00002151
Iteration 64/1000 | Loss: 0.00002151
Iteration 65/1000 | Loss: 0.00002151
Iteration 66/1000 | Loss: 0.00002151
Iteration 67/1000 | Loss: 0.00002151
Iteration 68/1000 | Loss: 0.00002151
Iteration 69/1000 | Loss: 0.00002151
Iteration 70/1000 | Loss: 0.00002151
Iteration 71/1000 | Loss: 0.00002151
Iteration 72/1000 | Loss: 0.00002151
Iteration 73/1000 | Loss: 0.00002150
Iteration 74/1000 | Loss: 0.00002150
Iteration 75/1000 | Loss: 0.00002150
Iteration 76/1000 | Loss: 0.00002150
Iteration 77/1000 | Loss: 0.00002150
Iteration 78/1000 | Loss: 0.00002150
Iteration 79/1000 | Loss: 0.00002150
Iteration 80/1000 | Loss: 0.00002150
Iteration 81/1000 | Loss: 0.00002150
Iteration 82/1000 | Loss: 0.00002150
Iteration 83/1000 | Loss: 0.00002150
Iteration 84/1000 | Loss: 0.00002150
Iteration 85/1000 | Loss: 0.00002150
Iteration 86/1000 | Loss: 0.00002150
Iteration 87/1000 | Loss: 0.00002150
Iteration 88/1000 | Loss: 0.00002150
Iteration 89/1000 | Loss: 0.00002150
Iteration 90/1000 | Loss: 0.00002150
Iteration 91/1000 | Loss: 0.00002150
Iteration 92/1000 | Loss: 0.00002150
Iteration 93/1000 | Loss: 0.00002150
Iteration 94/1000 | Loss: 0.00002150
Iteration 95/1000 | Loss: 0.00002150
Iteration 96/1000 | Loss: 0.00002150
Iteration 97/1000 | Loss: 0.00002150
Iteration 98/1000 | Loss: 0.00002150
Iteration 99/1000 | Loss: 0.00002150
Iteration 100/1000 | Loss: 0.00002150
Iteration 101/1000 | Loss: 0.00002150
Iteration 102/1000 | Loss: 0.00002150
Iteration 103/1000 | Loss: 0.00002150
Iteration 104/1000 | Loss: 0.00002150
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 104. Stopping optimization.
Last 5 losses: [2.1499756257981062e-05, 2.1499756257981062e-05, 2.1499756257981062e-05, 2.1499756257981062e-05, 2.1499756257981062e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1499756257981062e-05

Optimization complete. Final v2v error: 3.9606940746307373 mm

Highest mean error: 4.212953090667725 mm for frame 130

Lowest mean error: 3.5334932804107666 mm for frame 101

Saving results

Total time: 28.300055027008057
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00367823
Iteration 2/25 | Loss: 0.00100004
Iteration 3/25 | Loss: 0.00090217
Iteration 4/25 | Loss: 0.00087839
Iteration 5/25 | Loss: 0.00087511
Iteration 6/25 | Loss: 0.00087383
Iteration 7/25 | Loss: 0.00087378
Iteration 8/25 | Loss: 0.00087378
Iteration 9/25 | Loss: 0.00087378
Iteration 10/25 | Loss: 0.00087378
Iteration 11/25 | Loss: 0.00087378
Iteration 12/25 | Loss: 0.00087378
Iteration 13/25 | Loss: 0.00087378
Iteration 14/25 | Loss: 0.00087378
Iteration 15/25 | Loss: 0.00087378
Iteration 16/25 | Loss: 0.00087378
Iteration 17/25 | Loss: 0.00087378
Iteration 18/25 | Loss: 0.00087378
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0008737780153751373, 0.0008737780153751373, 0.0008737780153751373, 0.0008737780153751373, 0.0008737780153751373]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008737780153751373

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50665843
Iteration 2/25 | Loss: 0.00068095
Iteration 3/25 | Loss: 0.00068095
Iteration 4/25 | Loss: 0.00068095
Iteration 5/25 | Loss: 0.00068095
Iteration 6/25 | Loss: 0.00068095
Iteration 7/25 | Loss: 0.00068095
Iteration 8/25 | Loss: 0.00068095
Iteration 9/25 | Loss: 0.00068095
Iteration 10/25 | Loss: 0.00068095
Iteration 11/25 | Loss: 0.00068095
Iteration 12/25 | Loss: 0.00068095
Iteration 13/25 | Loss: 0.00068095
Iteration 14/25 | Loss: 0.00068095
Iteration 15/25 | Loss: 0.00068095
Iteration 16/25 | Loss: 0.00068095
Iteration 17/25 | Loss: 0.00068095
Iteration 18/25 | Loss: 0.00068095
Iteration 19/25 | Loss: 0.00068095
Iteration 20/25 | Loss: 0.00068095
Iteration 21/25 | Loss: 0.00068095
Iteration 22/25 | Loss: 0.00068095
Iteration 23/25 | Loss: 0.00068095
Iteration 24/25 | Loss: 0.00068095
Iteration 25/25 | Loss: 0.00068095

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00068095
Iteration 2/1000 | Loss: 0.00002896
Iteration 3/1000 | Loss: 0.00002012
Iteration 4/1000 | Loss: 0.00001796
Iteration 5/1000 | Loss: 0.00001689
Iteration 6/1000 | Loss: 0.00001641
Iteration 7/1000 | Loss: 0.00001611
Iteration 8/1000 | Loss: 0.00001604
Iteration 9/1000 | Loss: 0.00001600
Iteration 10/1000 | Loss: 0.00001597
Iteration 11/1000 | Loss: 0.00001596
Iteration 12/1000 | Loss: 0.00001596
Iteration 13/1000 | Loss: 0.00001595
Iteration 14/1000 | Loss: 0.00001594
Iteration 15/1000 | Loss: 0.00001589
Iteration 16/1000 | Loss: 0.00001588
Iteration 17/1000 | Loss: 0.00001587
Iteration 18/1000 | Loss: 0.00001585
Iteration 19/1000 | Loss: 0.00001584
Iteration 20/1000 | Loss: 0.00001584
Iteration 21/1000 | Loss: 0.00001583
Iteration 22/1000 | Loss: 0.00001583
Iteration 23/1000 | Loss: 0.00001579
Iteration 24/1000 | Loss: 0.00001577
Iteration 25/1000 | Loss: 0.00001577
Iteration 26/1000 | Loss: 0.00001577
Iteration 27/1000 | Loss: 0.00001574
Iteration 28/1000 | Loss: 0.00001574
Iteration 29/1000 | Loss: 0.00001574
Iteration 30/1000 | Loss: 0.00001574
Iteration 31/1000 | Loss: 0.00001573
Iteration 32/1000 | Loss: 0.00001573
Iteration 33/1000 | Loss: 0.00001573
Iteration 34/1000 | Loss: 0.00001573
Iteration 35/1000 | Loss: 0.00001573
Iteration 36/1000 | Loss: 0.00001573
Iteration 37/1000 | Loss: 0.00001573
Iteration 38/1000 | Loss: 0.00001573
Iteration 39/1000 | Loss: 0.00001573
Iteration 40/1000 | Loss: 0.00001573
Iteration 41/1000 | Loss: 0.00001572
Iteration 42/1000 | Loss: 0.00001572
Iteration 43/1000 | Loss: 0.00001572
Iteration 44/1000 | Loss: 0.00001572
Iteration 45/1000 | Loss: 0.00001571
Iteration 46/1000 | Loss: 0.00001571
Iteration 47/1000 | Loss: 0.00001570
Iteration 48/1000 | Loss: 0.00001570
Iteration 49/1000 | Loss: 0.00001570
Iteration 50/1000 | Loss: 0.00001570
Iteration 51/1000 | Loss: 0.00001570
Iteration 52/1000 | Loss: 0.00001569
Iteration 53/1000 | Loss: 0.00001569
Iteration 54/1000 | Loss: 0.00001569
Iteration 55/1000 | Loss: 0.00001569
Iteration 56/1000 | Loss: 0.00001569
Iteration 57/1000 | Loss: 0.00001569
Iteration 58/1000 | Loss: 0.00001569
Iteration 59/1000 | Loss: 0.00001569
Iteration 60/1000 | Loss: 0.00001569
Iteration 61/1000 | Loss: 0.00001568
Iteration 62/1000 | Loss: 0.00001568
Iteration 63/1000 | Loss: 0.00001568
Iteration 64/1000 | Loss: 0.00001568
Iteration 65/1000 | Loss: 0.00001568
Iteration 66/1000 | Loss: 0.00001568
Iteration 67/1000 | Loss: 0.00001568
Iteration 68/1000 | Loss: 0.00001568
Iteration 69/1000 | Loss: 0.00001568
Iteration 70/1000 | Loss: 0.00001568
Iteration 71/1000 | Loss: 0.00001568
Iteration 72/1000 | Loss: 0.00001568
Iteration 73/1000 | Loss: 0.00001568
Iteration 74/1000 | Loss: 0.00001568
Iteration 75/1000 | Loss: 0.00001568
Iteration 76/1000 | Loss: 0.00001568
Iteration 77/1000 | Loss: 0.00001568
Iteration 78/1000 | Loss: 0.00001568
Iteration 79/1000 | Loss: 0.00001568
Iteration 80/1000 | Loss: 0.00001567
Iteration 81/1000 | Loss: 0.00001567
Iteration 82/1000 | Loss: 0.00001567
Iteration 83/1000 | Loss: 0.00001567
Iteration 84/1000 | Loss: 0.00001567
Iteration 85/1000 | Loss: 0.00001567
Iteration 86/1000 | Loss: 0.00001567
Iteration 87/1000 | Loss: 0.00001567
Iteration 88/1000 | Loss: 0.00001567
Iteration 89/1000 | Loss: 0.00001567
Iteration 90/1000 | Loss: 0.00001567
Iteration 91/1000 | Loss: 0.00001567
Iteration 92/1000 | Loss: 0.00001567
Iteration 93/1000 | Loss: 0.00001567
Iteration 94/1000 | Loss: 0.00001567
Iteration 95/1000 | Loss: 0.00001567
Iteration 96/1000 | Loss: 0.00001567
Iteration 97/1000 | Loss: 0.00001567
Iteration 98/1000 | Loss: 0.00001567
Iteration 99/1000 | Loss: 0.00001567
Iteration 100/1000 | Loss: 0.00001567
Iteration 101/1000 | Loss: 0.00001567
Iteration 102/1000 | Loss: 0.00001566
Iteration 103/1000 | Loss: 0.00001566
Iteration 104/1000 | Loss: 0.00001566
Iteration 105/1000 | Loss: 0.00001566
Iteration 106/1000 | Loss: 0.00001566
Iteration 107/1000 | Loss: 0.00001566
Iteration 108/1000 | Loss: 0.00001566
Iteration 109/1000 | Loss: 0.00001566
Iteration 110/1000 | Loss: 0.00001566
Iteration 111/1000 | Loss: 0.00001566
Iteration 112/1000 | Loss: 0.00001566
Iteration 113/1000 | Loss: 0.00001566
Iteration 114/1000 | Loss: 0.00001566
Iteration 115/1000 | Loss: 0.00001566
Iteration 116/1000 | Loss: 0.00001566
Iteration 117/1000 | Loss: 0.00001566
Iteration 118/1000 | Loss: 0.00001566
Iteration 119/1000 | Loss: 0.00001566
Iteration 120/1000 | Loss: 0.00001566
Iteration 121/1000 | Loss: 0.00001566
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 121. Stopping optimization.
Last 5 losses: [1.5662526493542828e-05, 1.5662526493542828e-05, 1.5662526493542828e-05, 1.5662526493542828e-05, 1.5662526493542828e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.5662526493542828e-05

Optimization complete. Final v2v error: 3.4336304664611816 mm

Highest mean error: 3.7258505821228027 mm for frame 3

Lowest mean error: 3.165708541870117 mm for frame 123

Saving results

Total time: 27.503476858139038
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00521823
Iteration 2/25 | Loss: 0.00112443
Iteration 3/25 | Loss: 0.00100468
Iteration 4/25 | Loss: 0.00097671
Iteration 5/25 | Loss: 0.00096535
Iteration 6/25 | Loss: 0.00096311
Iteration 7/25 | Loss: 0.00096254
Iteration 8/25 | Loss: 0.00096254
Iteration 9/25 | Loss: 0.00096254
Iteration 10/25 | Loss: 0.00096254
Iteration 11/25 | Loss: 0.00096254
Iteration 12/25 | Loss: 0.00096254
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.000962544116191566, 0.000962544116191566, 0.000962544116191566, 0.000962544116191566, 0.000962544116191566]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000962544116191566

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.44141448
Iteration 2/25 | Loss: 0.00050302
Iteration 3/25 | Loss: 0.00050301
Iteration 4/25 | Loss: 0.00050301
Iteration 5/25 | Loss: 0.00050301
Iteration 6/25 | Loss: 0.00050301
Iteration 7/25 | Loss: 0.00050301
Iteration 8/25 | Loss: 0.00050301
Iteration 9/25 | Loss: 0.00050301
Iteration 10/25 | Loss: 0.00050301
Iteration 11/25 | Loss: 0.00050301
Iteration 12/25 | Loss: 0.00050301
Iteration 13/25 | Loss: 0.00050301
Iteration 14/25 | Loss: 0.00050301
Iteration 15/25 | Loss: 0.00050301
Iteration 16/25 | Loss: 0.00050301
Iteration 17/25 | Loss: 0.00050301
Iteration 18/25 | Loss: 0.00050301
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0005030077882111073, 0.0005030077882111073, 0.0005030077882111073, 0.0005030077882111073, 0.0005030077882111073]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0005030077882111073

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00050301
Iteration 2/1000 | Loss: 0.00005502
Iteration 3/1000 | Loss: 0.00004282
Iteration 4/1000 | Loss: 0.00003787
Iteration 5/1000 | Loss: 0.00003609
Iteration 6/1000 | Loss: 0.00003511
Iteration 7/1000 | Loss: 0.00003436
Iteration 8/1000 | Loss: 0.00003388
Iteration 9/1000 | Loss: 0.00003352
Iteration 10/1000 | Loss: 0.00003337
Iteration 11/1000 | Loss: 0.00003336
Iteration 12/1000 | Loss: 0.00003331
Iteration 13/1000 | Loss: 0.00003329
Iteration 14/1000 | Loss: 0.00003325
Iteration 15/1000 | Loss: 0.00003323
Iteration 16/1000 | Loss: 0.00003322
Iteration 17/1000 | Loss: 0.00003322
Iteration 18/1000 | Loss: 0.00003320
Iteration 19/1000 | Loss: 0.00003320
Iteration 20/1000 | Loss: 0.00003320
Iteration 21/1000 | Loss: 0.00003319
Iteration 22/1000 | Loss: 0.00003319
Iteration 23/1000 | Loss: 0.00003319
Iteration 24/1000 | Loss: 0.00003319
Iteration 25/1000 | Loss: 0.00003319
Iteration 26/1000 | Loss: 0.00003318
Iteration 27/1000 | Loss: 0.00003318
Iteration 28/1000 | Loss: 0.00003318
Iteration 29/1000 | Loss: 0.00003318
Iteration 30/1000 | Loss: 0.00003318
Iteration 31/1000 | Loss: 0.00003318
Iteration 32/1000 | Loss: 0.00003317
Iteration 33/1000 | Loss: 0.00003317
Iteration 34/1000 | Loss: 0.00003317
Iteration 35/1000 | Loss: 0.00003317
Iteration 36/1000 | Loss: 0.00003317
Iteration 37/1000 | Loss: 0.00003317
Iteration 38/1000 | Loss: 0.00003317
Iteration 39/1000 | Loss: 0.00003316
Iteration 40/1000 | Loss: 0.00003316
Iteration 41/1000 | Loss: 0.00003316
Iteration 42/1000 | Loss: 0.00003316
Iteration 43/1000 | Loss: 0.00003316
Iteration 44/1000 | Loss: 0.00003316
Iteration 45/1000 | Loss: 0.00003316
Iteration 46/1000 | Loss: 0.00003316
Iteration 47/1000 | Loss: 0.00003316
Iteration 48/1000 | Loss: 0.00003316
Iteration 49/1000 | Loss: 0.00003315
Iteration 50/1000 | Loss: 0.00003315
Iteration 51/1000 | Loss: 0.00003315
Iteration 52/1000 | Loss: 0.00003315
Iteration 53/1000 | Loss: 0.00003315
Iteration 54/1000 | Loss: 0.00003315
Iteration 55/1000 | Loss: 0.00003315
Iteration 56/1000 | Loss: 0.00003315
Iteration 57/1000 | Loss: 0.00003315
Iteration 58/1000 | Loss: 0.00003315
Iteration 59/1000 | Loss: 0.00003315
Iteration 60/1000 | Loss: 0.00003315
Iteration 61/1000 | Loss: 0.00003315
Iteration 62/1000 | Loss: 0.00003315
Iteration 63/1000 | Loss: 0.00003315
Iteration 64/1000 | Loss: 0.00003315
Iteration 65/1000 | Loss: 0.00003315
Iteration 66/1000 | Loss: 0.00003315
Iteration 67/1000 | Loss: 0.00003315
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 67. Stopping optimization.
Last 5 losses: [3.3149743103422225e-05, 3.3149743103422225e-05, 3.3149743103422225e-05, 3.3149743103422225e-05, 3.3149743103422225e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.3149743103422225e-05

Optimization complete. Final v2v error: 4.432797908782959 mm

Highest mean error: 5.783473491668701 mm for frame 93

Lowest mean error: 3.7558274269104004 mm for frame 28

Saving results

Total time: 29.53547477722168
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00869233
Iteration 2/25 | Loss: 0.00124591
Iteration 3/25 | Loss: 0.00102347
Iteration 4/25 | Loss: 0.00098568
Iteration 5/25 | Loss: 0.00097598
Iteration 6/25 | Loss: 0.00097427
Iteration 7/25 | Loss: 0.00097427
Iteration 8/25 | Loss: 0.00097427
Iteration 9/25 | Loss: 0.00097427
Iteration 10/25 | Loss: 0.00097427
Iteration 11/25 | Loss: 0.00097427
Iteration 12/25 | Loss: 0.00097427
Iteration 13/25 | Loss: 0.00097427
Iteration 14/25 | Loss: 0.00097427
Iteration 15/25 | Loss: 0.00097427
Iteration 16/25 | Loss: 0.00097427
Iteration 17/25 | Loss: 0.00097427
Iteration 18/25 | Loss: 0.00097427
Iteration 19/25 | Loss: 0.00097427
Iteration 20/25 | Loss: 0.00097427
Iteration 21/25 | Loss: 0.00097427
Iteration 22/25 | Loss: 0.00097427
Iteration 23/25 | Loss: 0.00097427
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0009742729598656297, 0.0009742729598656297, 0.0009742729598656297, 0.0009742729598656297, 0.0009742729598656297]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009742729598656297

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.86755168
Iteration 2/25 | Loss: 0.00089759
Iteration 3/25 | Loss: 0.00089758
Iteration 4/25 | Loss: 0.00089758
Iteration 5/25 | Loss: 0.00089758
Iteration 6/25 | Loss: 0.00089758
Iteration 7/25 | Loss: 0.00089758
Iteration 8/25 | Loss: 0.00089758
Iteration 9/25 | Loss: 0.00089758
Iteration 10/25 | Loss: 0.00089758
Iteration 11/25 | Loss: 0.00089758
Iteration 12/25 | Loss: 0.00089758
Iteration 13/25 | Loss: 0.00089758
Iteration 14/25 | Loss: 0.00089758
Iteration 15/25 | Loss: 0.00089758
Iteration 16/25 | Loss: 0.00089758
Iteration 17/25 | Loss: 0.00089758
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0008975816308520734, 0.0008975816308520734, 0.0008975816308520734, 0.0008975816308520734, 0.0008975816308520734]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008975816308520734

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00089758
Iteration 2/1000 | Loss: 0.00003008
Iteration 3/1000 | Loss: 0.00002257
Iteration 4/1000 | Loss: 0.00002058
Iteration 5/1000 | Loss: 0.00001949
Iteration 6/1000 | Loss: 0.00001868
Iteration 7/1000 | Loss: 0.00001825
Iteration 8/1000 | Loss: 0.00001792
Iteration 9/1000 | Loss: 0.00001779
Iteration 10/1000 | Loss: 0.00001778
Iteration 11/1000 | Loss: 0.00001774
Iteration 12/1000 | Loss: 0.00001773
Iteration 13/1000 | Loss: 0.00001765
Iteration 14/1000 | Loss: 0.00001761
Iteration 15/1000 | Loss: 0.00001760
Iteration 16/1000 | Loss: 0.00001758
Iteration 17/1000 | Loss: 0.00001752
Iteration 18/1000 | Loss: 0.00001749
Iteration 19/1000 | Loss: 0.00001746
Iteration 20/1000 | Loss: 0.00001745
Iteration 21/1000 | Loss: 0.00001744
Iteration 22/1000 | Loss: 0.00001744
Iteration 23/1000 | Loss: 0.00001744
Iteration 24/1000 | Loss: 0.00001744
Iteration 25/1000 | Loss: 0.00001744
Iteration 26/1000 | Loss: 0.00001744
Iteration 27/1000 | Loss: 0.00001744
Iteration 28/1000 | Loss: 0.00001743
Iteration 29/1000 | Loss: 0.00001743
Iteration 30/1000 | Loss: 0.00001743
Iteration 31/1000 | Loss: 0.00001743
Iteration 32/1000 | Loss: 0.00001742
Iteration 33/1000 | Loss: 0.00001742
Iteration 34/1000 | Loss: 0.00001742
Iteration 35/1000 | Loss: 0.00001742
Iteration 36/1000 | Loss: 0.00001742
Iteration 37/1000 | Loss: 0.00001742
Iteration 38/1000 | Loss: 0.00001742
Iteration 39/1000 | Loss: 0.00001742
Iteration 40/1000 | Loss: 0.00001742
Iteration 41/1000 | Loss: 0.00001742
Iteration 42/1000 | Loss: 0.00001741
Iteration 43/1000 | Loss: 0.00001741
Iteration 44/1000 | Loss: 0.00001741
Iteration 45/1000 | Loss: 0.00001741
Iteration 46/1000 | Loss: 0.00001740
Iteration 47/1000 | Loss: 0.00001740
Iteration 48/1000 | Loss: 0.00001740
Iteration 49/1000 | Loss: 0.00001740
Iteration 50/1000 | Loss: 0.00001740
Iteration 51/1000 | Loss: 0.00001740
Iteration 52/1000 | Loss: 0.00001740
Iteration 53/1000 | Loss: 0.00001739
Iteration 54/1000 | Loss: 0.00001739
Iteration 55/1000 | Loss: 0.00001739
Iteration 56/1000 | Loss: 0.00001738
Iteration 57/1000 | Loss: 0.00001738
Iteration 58/1000 | Loss: 0.00001738
Iteration 59/1000 | Loss: 0.00001737
Iteration 60/1000 | Loss: 0.00001737
Iteration 61/1000 | Loss: 0.00001737
Iteration 62/1000 | Loss: 0.00001737
Iteration 63/1000 | Loss: 0.00001737
Iteration 64/1000 | Loss: 0.00001737
Iteration 65/1000 | Loss: 0.00001737
Iteration 66/1000 | Loss: 0.00001737
Iteration 67/1000 | Loss: 0.00001737
Iteration 68/1000 | Loss: 0.00001737
Iteration 69/1000 | Loss: 0.00001737
Iteration 70/1000 | Loss: 0.00001737
Iteration 71/1000 | Loss: 0.00001737
Iteration 72/1000 | Loss: 0.00001737
Iteration 73/1000 | Loss: 0.00001737
Iteration 74/1000 | Loss: 0.00001737
Iteration 75/1000 | Loss: 0.00001737
Iteration 76/1000 | Loss: 0.00001737
Iteration 77/1000 | Loss: 0.00001737
Iteration 78/1000 | Loss: 0.00001737
Iteration 79/1000 | Loss: 0.00001737
Iteration 80/1000 | Loss: 0.00001737
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 80. Stopping optimization.
Last 5 losses: [1.7368171029374935e-05, 1.7368171029374935e-05, 1.7368171029374935e-05, 1.7368171029374935e-05, 1.7368171029374935e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7368171029374935e-05

Optimization complete. Final v2v error: 3.5869011878967285 mm

Highest mean error: 4.327025890350342 mm for frame 201

Lowest mean error: 3.0623068809509277 mm for frame 170

Saving results

Total time: 31.944159507751465
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00407904
Iteration 2/25 | Loss: 0.00106269
Iteration 3/25 | Loss: 0.00092243
Iteration 4/25 | Loss: 0.00091146
Iteration 5/25 | Loss: 0.00090483
Iteration 6/25 | Loss: 0.00090250
Iteration 7/25 | Loss: 0.00090213
Iteration 8/25 | Loss: 0.00090213
Iteration 9/25 | Loss: 0.00090213
Iteration 10/25 | Loss: 0.00090213
Iteration 11/25 | Loss: 0.00090213
Iteration 12/25 | Loss: 0.00090213
Iteration 13/25 | Loss: 0.00090213
Iteration 14/25 | Loss: 0.00090213
Iteration 15/25 | Loss: 0.00090213
Iteration 16/25 | Loss: 0.00090213
Iteration 17/25 | Loss: 0.00090213
Iteration 18/25 | Loss: 0.00090213
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0009021313162520528, 0.0009021313162520528, 0.0009021313162520528, 0.0009021313162520528, 0.0009021313162520528]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009021313162520528

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.64591002
Iteration 2/25 | Loss: 0.00076145
Iteration 3/25 | Loss: 0.00076145
Iteration 4/25 | Loss: 0.00076145
Iteration 5/25 | Loss: 0.00076145
Iteration 6/25 | Loss: 0.00076145
Iteration 7/25 | Loss: 0.00076145
Iteration 8/25 | Loss: 0.00076145
Iteration 9/25 | Loss: 0.00076145
Iteration 10/25 | Loss: 0.00076145
Iteration 11/25 | Loss: 0.00076145
Iteration 12/25 | Loss: 0.00076145
Iteration 13/25 | Loss: 0.00076145
Iteration 14/25 | Loss: 0.00076145
Iteration 15/25 | Loss: 0.00076145
Iteration 16/25 | Loss: 0.00076145
Iteration 17/25 | Loss: 0.00076145
Iteration 18/25 | Loss: 0.00076145
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007614488713443279, 0.0007614488713443279, 0.0007614488713443279, 0.0007614488713443279, 0.0007614488713443279]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007614488713443279

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00076145
Iteration 2/1000 | Loss: 0.00002804
Iteration 3/1000 | Loss: 0.00001945
Iteration 4/1000 | Loss: 0.00001769
Iteration 5/1000 | Loss: 0.00001670
Iteration 6/1000 | Loss: 0.00001614
Iteration 7/1000 | Loss: 0.00001580
Iteration 8/1000 | Loss: 0.00001557
Iteration 9/1000 | Loss: 0.00001557
Iteration 10/1000 | Loss: 0.00001551
Iteration 11/1000 | Loss: 0.00001551
Iteration 12/1000 | Loss: 0.00001551
Iteration 13/1000 | Loss: 0.00001550
Iteration 14/1000 | Loss: 0.00001549
Iteration 15/1000 | Loss: 0.00001535
Iteration 16/1000 | Loss: 0.00001535
Iteration 17/1000 | Loss: 0.00001528
Iteration 18/1000 | Loss: 0.00001528
Iteration 19/1000 | Loss: 0.00001527
Iteration 20/1000 | Loss: 0.00001527
Iteration 21/1000 | Loss: 0.00001524
Iteration 22/1000 | Loss: 0.00001524
Iteration 23/1000 | Loss: 0.00001523
Iteration 24/1000 | Loss: 0.00001523
Iteration 25/1000 | Loss: 0.00001520
Iteration 26/1000 | Loss: 0.00001517
Iteration 27/1000 | Loss: 0.00001517
Iteration 28/1000 | Loss: 0.00001516
Iteration 29/1000 | Loss: 0.00001516
Iteration 30/1000 | Loss: 0.00001515
Iteration 31/1000 | Loss: 0.00001514
Iteration 32/1000 | Loss: 0.00001514
Iteration 33/1000 | Loss: 0.00001513
Iteration 34/1000 | Loss: 0.00001513
Iteration 35/1000 | Loss: 0.00001512
Iteration 36/1000 | Loss: 0.00001512
Iteration 37/1000 | Loss: 0.00001512
Iteration 38/1000 | Loss: 0.00001511
Iteration 39/1000 | Loss: 0.00001510
Iteration 40/1000 | Loss: 0.00001510
Iteration 41/1000 | Loss: 0.00001509
Iteration 42/1000 | Loss: 0.00001509
Iteration 43/1000 | Loss: 0.00001508
Iteration 44/1000 | Loss: 0.00001508
Iteration 45/1000 | Loss: 0.00001507
Iteration 46/1000 | Loss: 0.00001506
Iteration 47/1000 | Loss: 0.00001506
Iteration 48/1000 | Loss: 0.00001506
Iteration 49/1000 | Loss: 0.00001505
Iteration 50/1000 | Loss: 0.00001505
Iteration 51/1000 | Loss: 0.00001503
Iteration 52/1000 | Loss: 0.00001503
Iteration 53/1000 | Loss: 0.00001503
Iteration 54/1000 | Loss: 0.00001502
Iteration 55/1000 | Loss: 0.00001502
Iteration 56/1000 | Loss: 0.00001502
Iteration 57/1000 | Loss: 0.00001502
Iteration 58/1000 | Loss: 0.00001502
Iteration 59/1000 | Loss: 0.00001502
Iteration 60/1000 | Loss: 0.00001502
Iteration 61/1000 | Loss: 0.00001502
Iteration 62/1000 | Loss: 0.00001501
Iteration 63/1000 | Loss: 0.00001501
Iteration 64/1000 | Loss: 0.00001501
Iteration 65/1000 | Loss: 0.00001501
Iteration 66/1000 | Loss: 0.00001501
Iteration 67/1000 | Loss: 0.00001501
Iteration 68/1000 | Loss: 0.00001500
Iteration 69/1000 | Loss: 0.00001500
Iteration 70/1000 | Loss: 0.00001500
Iteration 71/1000 | Loss: 0.00001500
Iteration 72/1000 | Loss: 0.00001500
Iteration 73/1000 | Loss: 0.00001500
Iteration 74/1000 | Loss: 0.00001499
Iteration 75/1000 | Loss: 0.00001499
Iteration 76/1000 | Loss: 0.00001499
Iteration 77/1000 | Loss: 0.00001499
Iteration 78/1000 | Loss: 0.00001499
Iteration 79/1000 | Loss: 0.00001499
Iteration 80/1000 | Loss: 0.00001499
Iteration 81/1000 | Loss: 0.00001498
Iteration 82/1000 | Loss: 0.00001497
Iteration 83/1000 | Loss: 0.00001497
Iteration 84/1000 | Loss: 0.00001497
Iteration 85/1000 | Loss: 0.00001497
Iteration 86/1000 | Loss: 0.00001497
Iteration 87/1000 | Loss: 0.00001497
Iteration 88/1000 | Loss: 0.00001497
Iteration 89/1000 | Loss: 0.00001497
Iteration 90/1000 | Loss: 0.00001497
Iteration 91/1000 | Loss: 0.00001497
Iteration 92/1000 | Loss: 0.00001497
Iteration 93/1000 | Loss: 0.00001497
Iteration 94/1000 | Loss: 0.00001497
Iteration 95/1000 | Loss: 0.00001496
Iteration 96/1000 | Loss: 0.00001496
Iteration 97/1000 | Loss: 0.00001496
Iteration 98/1000 | Loss: 0.00001496
Iteration 99/1000 | Loss: 0.00001496
Iteration 100/1000 | Loss: 0.00001496
Iteration 101/1000 | Loss: 0.00001495
Iteration 102/1000 | Loss: 0.00001495
Iteration 103/1000 | Loss: 0.00001495
Iteration 104/1000 | Loss: 0.00001495
Iteration 105/1000 | Loss: 0.00001495
Iteration 106/1000 | Loss: 0.00001495
Iteration 107/1000 | Loss: 0.00001495
Iteration 108/1000 | Loss: 0.00001495
Iteration 109/1000 | Loss: 0.00001494
Iteration 110/1000 | Loss: 0.00001494
Iteration 111/1000 | Loss: 0.00001494
Iteration 112/1000 | Loss: 0.00001494
Iteration 113/1000 | Loss: 0.00001494
Iteration 114/1000 | Loss: 0.00001494
Iteration 115/1000 | Loss: 0.00001494
Iteration 116/1000 | Loss: 0.00001494
Iteration 117/1000 | Loss: 0.00001494
Iteration 118/1000 | Loss: 0.00001494
Iteration 119/1000 | Loss: 0.00001494
Iteration 120/1000 | Loss: 0.00001494
Iteration 121/1000 | Loss: 0.00001494
Iteration 122/1000 | Loss: 0.00001493
Iteration 123/1000 | Loss: 0.00001493
Iteration 124/1000 | Loss: 0.00001493
Iteration 125/1000 | Loss: 0.00001493
Iteration 126/1000 | Loss: 0.00001493
Iteration 127/1000 | Loss: 0.00001493
Iteration 128/1000 | Loss: 0.00001493
Iteration 129/1000 | Loss: 0.00001493
Iteration 130/1000 | Loss: 0.00001493
Iteration 131/1000 | Loss: 0.00001493
Iteration 132/1000 | Loss: 0.00001493
Iteration 133/1000 | Loss: 0.00001493
Iteration 134/1000 | Loss: 0.00001493
Iteration 135/1000 | Loss: 0.00001493
Iteration 136/1000 | Loss: 0.00001493
Iteration 137/1000 | Loss: 0.00001493
Iteration 138/1000 | Loss: 0.00001493
Iteration 139/1000 | Loss: 0.00001493
Iteration 140/1000 | Loss: 0.00001493
Iteration 141/1000 | Loss: 0.00001493
Iteration 142/1000 | Loss: 0.00001493
Iteration 143/1000 | Loss: 0.00001493
Iteration 144/1000 | Loss: 0.00001493
Iteration 145/1000 | Loss: 0.00001493
Iteration 146/1000 | Loss: 0.00001493
Iteration 147/1000 | Loss: 0.00001493
Iteration 148/1000 | Loss: 0.00001493
Iteration 149/1000 | Loss: 0.00001493
Iteration 150/1000 | Loss: 0.00001493
Iteration 151/1000 | Loss: 0.00001493
Iteration 152/1000 | Loss: 0.00001493
Iteration 153/1000 | Loss: 0.00001493
Iteration 154/1000 | Loss: 0.00001493
Iteration 155/1000 | Loss: 0.00001493
Iteration 156/1000 | Loss: 0.00001493
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 156. Stopping optimization.
Last 5 losses: [1.4927675692888442e-05, 1.4927675692888442e-05, 1.4927675692888442e-05, 1.4927675692888442e-05, 1.4927675692888442e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.4927675692888442e-05

Optimization complete. Final v2v error: 3.3830652236938477 mm

Highest mean error: 3.5962271690368652 mm for frame 82

Lowest mean error: 2.972022533416748 mm for frame 2

Saving results

Total time: 37.75323843955994
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01074457
Iteration 2/25 | Loss: 0.00323460
Iteration 3/25 | Loss: 0.00208173
Iteration 4/25 | Loss: 0.00179898
Iteration 5/25 | Loss: 0.00165209
Iteration 6/25 | Loss: 0.00156390
Iteration 7/25 | Loss: 0.00149458
Iteration 8/25 | Loss: 0.00147840
Iteration 9/25 | Loss: 0.00144975
Iteration 10/25 | Loss: 0.00150790
Iteration 11/25 | Loss: 0.00138177
Iteration 12/25 | Loss: 0.00134071
Iteration 13/25 | Loss: 0.00128724
Iteration 14/25 | Loss: 0.00126234
Iteration 15/25 | Loss: 0.00125715
Iteration 16/25 | Loss: 0.00124996
Iteration 17/25 | Loss: 0.00123212
Iteration 18/25 | Loss: 0.00122363
Iteration 19/25 | Loss: 0.00122311
Iteration 20/25 | Loss: 0.00122217
Iteration 21/25 | Loss: 0.00122206
Iteration 22/25 | Loss: 0.00122317
Iteration 23/25 | Loss: 0.00122196
Iteration 24/25 | Loss: 0.00122902
Iteration 25/25 | Loss: 0.00122040

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50758612
Iteration 2/25 | Loss: 0.00218838
Iteration 3/25 | Loss: 0.00217908
Iteration 4/25 | Loss: 0.00217908
Iteration 5/25 | Loss: 0.00217908
Iteration 6/25 | Loss: 0.00217908
Iteration 7/25 | Loss: 0.00217908
Iteration 8/25 | Loss: 0.00217908
Iteration 9/25 | Loss: 0.00217908
Iteration 10/25 | Loss: 0.00217908
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 10. Stopping optimization.
Last 5 losses: [0.002179081318899989, 0.002179081318899989, 0.002179081318899989, 0.002179081318899989, 0.002179081318899989]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002179081318899989

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00217908
Iteration 2/1000 | Loss: 0.00038663
Iteration 3/1000 | Loss: 0.00041888
Iteration 4/1000 | Loss: 0.00084420
Iteration 5/1000 | Loss: 0.00123441
Iteration 6/1000 | Loss: 0.00044718
Iteration 7/1000 | Loss: 0.00014942
Iteration 8/1000 | Loss: 0.00123641
Iteration 9/1000 | Loss: 0.00015119
Iteration 10/1000 | Loss: 0.00013306
Iteration 11/1000 | Loss: 0.00011275
Iteration 12/1000 | Loss: 0.00010647
Iteration 13/1000 | Loss: 0.00013587
Iteration 14/1000 | Loss: 0.00010592
Iteration 15/1000 | Loss: 0.00010260
Iteration 16/1000 | Loss: 0.00010026
Iteration 17/1000 | Loss: 0.00009906
Iteration 18/1000 | Loss: 0.00009798
Iteration 19/1000 | Loss: 0.00009710
Iteration 20/1000 | Loss: 0.00009634
Iteration 21/1000 | Loss: 0.00010804
Iteration 22/1000 | Loss: 0.00012533
Iteration 23/1000 | Loss: 0.00010100
Iteration 24/1000 | Loss: 0.00010719
Iteration 25/1000 | Loss: 0.00011607
Iteration 26/1000 | Loss: 0.00010347
Iteration 27/1000 | Loss: 0.00010011
Iteration 28/1000 | Loss: 0.00011069
Iteration 29/1000 | Loss: 0.00010464
Iteration 30/1000 | Loss: 0.00010271
Iteration 31/1000 | Loss: 0.00010650
Iteration 32/1000 | Loss: 0.00010213
Iteration 33/1000 | Loss: 0.00009552
Iteration 34/1000 | Loss: 0.00010537
Iteration 35/1000 | Loss: 0.00010185
Iteration 36/1000 | Loss: 0.00009646
Iteration 37/1000 | Loss: 0.00009573
Iteration 38/1000 | Loss: 0.00009497
Iteration 39/1000 | Loss: 0.00009488
Iteration 40/1000 | Loss: 0.00009469
Iteration 41/1000 | Loss: 0.00009438
Iteration 42/1000 | Loss: 0.00009431
Iteration 43/1000 | Loss: 0.00009403
Iteration 44/1000 | Loss: 0.00009400
Iteration 45/1000 | Loss: 0.00009399
Iteration 46/1000 | Loss: 0.00009398
Iteration 47/1000 | Loss: 0.00009382
Iteration 48/1000 | Loss: 0.00009377
Iteration 49/1000 | Loss: 0.00009376
Iteration 50/1000 | Loss: 0.00009371
Iteration 51/1000 | Loss: 0.00009369
Iteration 52/1000 | Loss: 0.00009363
Iteration 53/1000 | Loss: 0.00011036
Iteration 54/1000 | Loss: 0.00010424
Iteration 55/1000 | Loss: 0.00011159
Iteration 56/1000 | Loss: 0.00010034
Iteration 57/1000 | Loss: 0.00009498
Iteration 58/1000 | Loss: 0.00010908
Iteration 59/1000 | Loss: 0.00010179
Iteration 60/1000 | Loss: 0.00011071
Iteration 61/1000 | Loss: 0.00010215
Iteration 62/1000 | Loss: 0.00009893
Iteration 63/1000 | Loss: 0.00010930
Iteration 64/1000 | Loss: 0.00010106
Iteration 65/1000 | Loss: 0.00009833
Iteration 66/1000 | Loss: 0.00010889
Iteration 67/1000 | Loss: 0.00009680
Iteration 68/1000 | Loss: 0.00009295
Iteration 69/1000 | Loss: 0.00009266
Iteration 70/1000 | Loss: 0.00009244
Iteration 71/1000 | Loss: 0.00009224
Iteration 72/1000 | Loss: 0.00009222
Iteration 73/1000 | Loss: 0.00009222
Iteration 74/1000 | Loss: 0.00009221
Iteration 75/1000 | Loss: 0.00009221
Iteration 76/1000 | Loss: 0.00009220
Iteration 77/1000 | Loss: 0.00009219
Iteration 78/1000 | Loss: 0.00009218
Iteration 79/1000 | Loss: 0.00009215
Iteration 80/1000 | Loss: 0.00009215
Iteration 81/1000 | Loss: 0.00009213
Iteration 82/1000 | Loss: 0.00009213
Iteration 83/1000 | Loss: 0.00009212
Iteration 84/1000 | Loss: 0.00009212
Iteration 85/1000 | Loss: 0.00009211
Iteration 86/1000 | Loss: 0.00009211
Iteration 87/1000 | Loss: 0.00009210
Iteration 88/1000 | Loss: 0.00009209
Iteration 89/1000 | Loss: 0.00009209
Iteration 90/1000 | Loss: 0.00009209
Iteration 91/1000 | Loss: 0.00009208
Iteration 92/1000 | Loss: 0.00009208
Iteration 93/1000 | Loss: 0.00009208
Iteration 94/1000 | Loss: 0.00009208
Iteration 95/1000 | Loss: 0.00009207
Iteration 96/1000 | Loss: 0.00009207
Iteration 97/1000 | Loss: 0.00009206
Iteration 98/1000 | Loss: 0.00009206
Iteration 99/1000 | Loss: 0.00009204
Iteration 100/1000 | Loss: 0.00009200
Iteration 101/1000 | Loss: 0.00009198
Iteration 102/1000 | Loss: 0.00009198
Iteration 103/1000 | Loss: 0.00009197
Iteration 104/1000 | Loss: 0.00009193
Iteration 105/1000 | Loss: 0.00009193
Iteration 106/1000 | Loss: 0.00009192
Iteration 107/1000 | Loss: 0.00009191
Iteration 108/1000 | Loss: 0.00010157
Iteration 109/1000 | Loss: 0.00009773
Iteration 110/1000 | Loss: 0.00009618
Iteration 111/1000 | Loss: 0.00009507
Iteration 112/1000 | Loss: 0.00009440
Iteration 113/1000 | Loss: 0.00009418
Iteration 114/1000 | Loss: 0.00010078
Iteration 115/1000 | Loss: 0.00009795
Iteration 116/1000 | Loss: 0.00010036
Iteration 117/1000 | Loss: 0.00009608
Iteration 118/1000 | Loss: 0.00010846
Iteration 119/1000 | Loss: 0.00009771
Iteration 120/1000 | Loss: 0.00010035
Iteration 121/1000 | Loss: 0.00009622
Iteration 122/1000 | Loss: 0.00010092
Iteration 123/1000 | Loss: 0.00010904
Iteration 124/1000 | Loss: 0.00009763
Iteration 125/1000 | Loss: 0.00010047
Iteration 126/1000 | Loss: 0.00010204
Iteration 127/1000 | Loss: 0.00010877
Iteration 128/1000 | Loss: 0.00009876
Iteration 129/1000 | Loss: 0.00010068
Iteration 130/1000 | Loss: 0.00010059
Iteration 131/1000 | Loss: 0.00011269
Iteration 132/1000 | Loss: 0.00009632
Iteration 133/1000 | Loss: 0.00009327
Iteration 134/1000 | Loss: 0.00009208
Iteration 135/1000 | Loss: 0.00009153
Iteration 136/1000 | Loss: 0.00009128
Iteration 137/1000 | Loss: 0.00009111
Iteration 138/1000 | Loss: 0.00009100
Iteration 139/1000 | Loss: 0.00009093
Iteration 140/1000 | Loss: 0.00009093
Iteration 141/1000 | Loss: 0.00009087
Iteration 142/1000 | Loss: 0.00009086
Iteration 143/1000 | Loss: 0.00009085
Iteration 144/1000 | Loss: 0.00009085
Iteration 145/1000 | Loss: 0.00009085
Iteration 146/1000 | Loss: 0.00009084
Iteration 147/1000 | Loss: 0.00009084
Iteration 148/1000 | Loss: 0.00009084
Iteration 149/1000 | Loss: 0.00009084
Iteration 150/1000 | Loss: 0.00009084
Iteration 151/1000 | Loss: 0.00009084
Iteration 152/1000 | Loss: 0.00009083
Iteration 153/1000 | Loss: 0.00009083
Iteration 154/1000 | Loss: 0.00009083
Iteration 155/1000 | Loss: 0.00009083
Iteration 156/1000 | Loss: 0.00009083
Iteration 157/1000 | Loss: 0.00009083
Iteration 158/1000 | Loss: 0.00009083
Iteration 159/1000 | Loss: 0.00009082
Iteration 160/1000 | Loss: 0.00009081
Iteration 161/1000 | Loss: 0.00009081
Iteration 162/1000 | Loss: 0.00009080
Iteration 163/1000 | Loss: 0.00009080
Iteration 164/1000 | Loss: 0.00009080
Iteration 165/1000 | Loss: 0.00009079
Iteration 166/1000 | Loss: 0.00009079
Iteration 167/1000 | Loss: 0.00009079
Iteration 168/1000 | Loss: 0.00009078
Iteration 169/1000 | Loss: 0.00009078
Iteration 170/1000 | Loss: 0.00009078
Iteration 171/1000 | Loss: 0.00009078
Iteration 172/1000 | Loss: 0.00009077
Iteration 173/1000 | Loss: 0.00009077
Iteration 174/1000 | Loss: 0.00009077
Iteration 175/1000 | Loss: 0.00009076
Iteration 176/1000 | Loss: 0.00009076
Iteration 177/1000 | Loss: 0.00009076
Iteration 178/1000 | Loss: 0.00009076
Iteration 179/1000 | Loss: 0.00009076
Iteration 180/1000 | Loss: 0.00009076
Iteration 181/1000 | Loss: 0.00009076
Iteration 182/1000 | Loss: 0.00009076
Iteration 183/1000 | Loss: 0.00009076
Iteration 184/1000 | Loss: 0.00009076
Iteration 185/1000 | Loss: 0.00009076
Iteration 186/1000 | Loss: 0.00009075
Iteration 187/1000 | Loss: 0.00009075
Iteration 188/1000 | Loss: 0.00009075
Iteration 189/1000 | Loss: 0.00009075
Iteration 190/1000 | Loss: 0.00009075
Iteration 191/1000 | Loss: 0.00009075
Iteration 192/1000 | Loss: 0.00009075
Iteration 193/1000 | Loss: 0.00009075
Iteration 194/1000 | Loss: 0.00009075
Iteration 195/1000 | Loss: 0.00009075
Iteration 196/1000 | Loss: 0.00009075
Iteration 197/1000 | Loss: 0.00009075
Iteration 198/1000 | Loss: 0.00009075
Iteration 199/1000 | Loss: 0.00009075
Iteration 200/1000 | Loss: 0.00009075
Iteration 201/1000 | Loss: 0.00009075
Iteration 202/1000 | Loss: 0.00009075
Iteration 203/1000 | Loss: 0.00009075
Iteration 204/1000 | Loss: 0.00009075
Iteration 205/1000 | Loss: 0.00009075
Iteration 206/1000 | Loss: 0.00009075
Iteration 207/1000 | Loss: 0.00009075
Iteration 208/1000 | Loss: 0.00009075
Iteration 209/1000 | Loss: 0.00009075
Iteration 210/1000 | Loss: 0.00009075
Iteration 211/1000 | Loss: 0.00009075
Iteration 212/1000 | Loss: 0.00009075
Iteration 213/1000 | Loss: 0.00009075
Iteration 214/1000 | Loss: 0.00009075
Iteration 215/1000 | Loss: 0.00009075
Iteration 216/1000 | Loss: 0.00009075
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 216. Stopping optimization.
Last 5 losses: [9.074979607248679e-05, 9.074979607248679e-05, 9.074979607248679e-05, 9.074979607248679e-05, 9.074979607248679e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 9.074979607248679e-05

Optimization complete. Final v2v error: 5.7290802001953125 mm

Highest mean error: 12.374919891357422 mm for frame 9

Lowest mean error: 3.789965867996216 mm for frame 27

Saving results

Total time: 180.03596711158752
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00435758
Iteration 2/25 | Loss: 0.00115465
Iteration 3/25 | Loss: 0.00099498
Iteration 4/25 | Loss: 0.00096894
Iteration 5/25 | Loss: 0.00095840
Iteration 6/25 | Loss: 0.00095603
Iteration 7/25 | Loss: 0.00095496
Iteration 8/25 | Loss: 0.00095476
Iteration 9/25 | Loss: 0.00095476
Iteration 10/25 | Loss: 0.00095476
Iteration 11/25 | Loss: 0.00095476
Iteration 12/25 | Loss: 0.00095476
Iteration 13/25 | Loss: 0.00095476
Iteration 14/25 | Loss: 0.00095476
Iteration 15/25 | Loss: 0.00095476
Iteration 16/25 | Loss: 0.00095476
Iteration 17/25 | Loss: 0.00095476
Iteration 18/25 | Loss: 0.00095476
Iteration 19/25 | Loss: 0.00095476
Iteration 20/25 | Loss: 0.00095476
Iteration 21/25 | Loss: 0.00095476
Iteration 22/25 | Loss: 0.00095476
Iteration 23/25 | Loss: 0.00095476
Iteration 24/25 | Loss: 0.00095476
Iteration 25/25 | Loss: 0.00095476

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.96262121
Iteration 2/25 | Loss: 0.00069209
Iteration 3/25 | Loss: 0.00069206
Iteration 4/25 | Loss: 0.00069206
Iteration 5/25 | Loss: 0.00069206
Iteration 6/25 | Loss: 0.00069206
Iteration 7/25 | Loss: 0.00069206
Iteration 8/25 | Loss: 0.00069206
Iteration 9/25 | Loss: 0.00069206
Iteration 10/25 | Loss: 0.00069206
Iteration 11/25 | Loss: 0.00069206
Iteration 12/25 | Loss: 0.00069206
Iteration 13/25 | Loss: 0.00069206
Iteration 14/25 | Loss: 0.00069206
Iteration 15/25 | Loss: 0.00069206
Iteration 16/25 | Loss: 0.00069206
Iteration 17/25 | Loss: 0.00069206
Iteration 18/25 | Loss: 0.00069206
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0006920565501786768, 0.0006920565501786768, 0.0006920565501786768, 0.0006920565501786768, 0.0006920565501786768]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006920565501786768

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00069206
Iteration 2/1000 | Loss: 0.00004730
Iteration 3/1000 | Loss: 0.00003649
Iteration 4/1000 | Loss: 0.00003257
Iteration 5/1000 | Loss: 0.00003093
Iteration 6/1000 | Loss: 0.00002971
Iteration 7/1000 | Loss: 0.00002903
Iteration 8/1000 | Loss: 0.00002868
Iteration 9/1000 | Loss: 0.00002848
Iteration 10/1000 | Loss: 0.00002823
Iteration 11/1000 | Loss: 0.00002820
Iteration 12/1000 | Loss: 0.00002817
Iteration 13/1000 | Loss: 0.00002817
Iteration 14/1000 | Loss: 0.00002813
Iteration 15/1000 | Loss: 0.00002812
Iteration 16/1000 | Loss: 0.00002812
Iteration 17/1000 | Loss: 0.00002808
Iteration 18/1000 | Loss: 0.00002808
Iteration 19/1000 | Loss: 0.00002808
Iteration 20/1000 | Loss: 0.00002807
Iteration 21/1000 | Loss: 0.00002807
Iteration 22/1000 | Loss: 0.00002806
Iteration 23/1000 | Loss: 0.00002806
Iteration 24/1000 | Loss: 0.00002805
Iteration 25/1000 | Loss: 0.00002805
Iteration 26/1000 | Loss: 0.00002805
Iteration 27/1000 | Loss: 0.00002804
Iteration 28/1000 | Loss: 0.00002804
Iteration 29/1000 | Loss: 0.00002804
Iteration 30/1000 | Loss: 0.00002804
Iteration 31/1000 | Loss: 0.00002803
Iteration 32/1000 | Loss: 0.00002803
Iteration 33/1000 | Loss: 0.00002803
Iteration 34/1000 | Loss: 0.00002803
Iteration 35/1000 | Loss: 0.00002803
Iteration 36/1000 | Loss: 0.00002803
Iteration 37/1000 | Loss: 0.00002803
Iteration 38/1000 | Loss: 0.00002803
Iteration 39/1000 | Loss: 0.00002803
Iteration 40/1000 | Loss: 0.00002803
Iteration 41/1000 | Loss: 0.00002802
Iteration 42/1000 | Loss: 0.00002802
Iteration 43/1000 | Loss: 0.00002802
Iteration 44/1000 | Loss: 0.00002802
Iteration 45/1000 | Loss: 0.00002802
Iteration 46/1000 | Loss: 0.00002802
Iteration 47/1000 | Loss: 0.00002802
Iteration 48/1000 | Loss: 0.00002801
Iteration 49/1000 | Loss: 0.00002801
Iteration 50/1000 | Loss: 0.00002801
Iteration 51/1000 | Loss: 0.00002801
Iteration 52/1000 | Loss: 0.00002801
Iteration 53/1000 | Loss: 0.00002801
Iteration 54/1000 | Loss: 0.00002801
Iteration 55/1000 | Loss: 0.00002801
Iteration 56/1000 | Loss: 0.00002801
Iteration 57/1000 | Loss: 0.00002801
Iteration 58/1000 | Loss: 0.00002800
Iteration 59/1000 | Loss: 0.00002800
Iteration 60/1000 | Loss: 0.00002800
Iteration 61/1000 | Loss: 0.00002800
Iteration 62/1000 | Loss: 0.00002800
Iteration 63/1000 | Loss: 0.00002800
Iteration 64/1000 | Loss: 0.00002800
Iteration 65/1000 | Loss: 0.00002800
Iteration 66/1000 | Loss: 0.00002800
Iteration 67/1000 | Loss: 0.00002799
Iteration 68/1000 | Loss: 0.00002799
Iteration 69/1000 | Loss: 0.00002799
Iteration 70/1000 | Loss: 0.00002799
Iteration 71/1000 | Loss: 0.00002799
Iteration 72/1000 | Loss: 0.00002799
Iteration 73/1000 | Loss: 0.00002799
Iteration 74/1000 | Loss: 0.00002799
Iteration 75/1000 | Loss: 0.00002799
Iteration 76/1000 | Loss: 0.00002799
Iteration 77/1000 | Loss: 0.00002799
Iteration 78/1000 | Loss: 0.00002799
Iteration 79/1000 | Loss: 0.00002799
Iteration 80/1000 | Loss: 0.00002799
Iteration 81/1000 | Loss: 0.00002798
Iteration 82/1000 | Loss: 0.00002798
Iteration 83/1000 | Loss: 0.00002798
Iteration 84/1000 | Loss: 0.00002798
Iteration 85/1000 | Loss: 0.00002798
Iteration 86/1000 | Loss: 0.00002798
Iteration 87/1000 | Loss: 0.00002798
Iteration 88/1000 | Loss: 0.00002798
Iteration 89/1000 | Loss: 0.00002798
Iteration 90/1000 | Loss: 0.00002798
Iteration 91/1000 | Loss: 0.00002798
Iteration 92/1000 | Loss: 0.00002798
Iteration 93/1000 | Loss: 0.00002798
Iteration 94/1000 | Loss: 0.00002798
Iteration 95/1000 | Loss: 0.00002797
Iteration 96/1000 | Loss: 0.00002797
Iteration 97/1000 | Loss: 0.00002797
Iteration 98/1000 | Loss: 0.00002797
Iteration 99/1000 | Loss: 0.00002797
Iteration 100/1000 | Loss: 0.00002797
Iteration 101/1000 | Loss: 0.00002797
Iteration 102/1000 | Loss: 0.00002797
Iteration 103/1000 | Loss: 0.00002797
Iteration 104/1000 | Loss: 0.00002797
Iteration 105/1000 | Loss: 0.00002797
Iteration 106/1000 | Loss: 0.00002797
Iteration 107/1000 | Loss: 0.00002797
Iteration 108/1000 | Loss: 0.00002797
Iteration 109/1000 | Loss: 0.00002797
Iteration 110/1000 | Loss: 0.00002797
Iteration 111/1000 | Loss: 0.00002797
Iteration 112/1000 | Loss: 0.00002797
Iteration 113/1000 | Loss: 0.00002797
Iteration 114/1000 | Loss: 0.00002797
Iteration 115/1000 | Loss: 0.00002797
Iteration 116/1000 | Loss: 0.00002797
Iteration 117/1000 | Loss: 0.00002797
Iteration 118/1000 | Loss: 0.00002797
Iteration 119/1000 | Loss: 0.00002797
Iteration 120/1000 | Loss: 0.00002797
Iteration 121/1000 | Loss: 0.00002797
Iteration 122/1000 | Loss: 0.00002797
Iteration 123/1000 | Loss: 0.00002797
Iteration 124/1000 | Loss: 0.00002797
Iteration 125/1000 | Loss: 0.00002797
Iteration 126/1000 | Loss: 0.00002797
Iteration 127/1000 | Loss: 0.00002797
Iteration 128/1000 | Loss: 0.00002797
Iteration 129/1000 | Loss: 0.00002797
Iteration 130/1000 | Loss: 0.00002797
Iteration 131/1000 | Loss: 0.00002797
Iteration 132/1000 | Loss: 0.00002797
Iteration 133/1000 | Loss: 0.00002797
Iteration 134/1000 | Loss: 0.00002797
Iteration 135/1000 | Loss: 0.00002797
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [2.7965879780822434e-05, 2.7965879780822434e-05, 2.7965879780822434e-05, 2.7965879780822434e-05, 2.7965879780822434e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7965879780822434e-05

Optimization complete. Final v2v error: 4.4519195556640625 mm

Highest mean error: 4.787740707397461 mm for frame 48

Lowest mean error: 4.023659706115723 mm for frame 58

Saving results

Total time: 32.011653900146484
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00880074
Iteration 2/25 | Loss: 0.00161959
Iteration 3/25 | Loss: 0.00113550
Iteration 4/25 | Loss: 0.00108414
Iteration 5/25 | Loss: 0.00106518
Iteration 6/25 | Loss: 0.00106086
Iteration 7/25 | Loss: 0.00105948
Iteration 8/25 | Loss: 0.00105913
Iteration 9/25 | Loss: 0.00105913
Iteration 10/25 | Loss: 0.00105913
Iteration 11/25 | Loss: 0.00105913
Iteration 12/25 | Loss: 0.00105913
Iteration 13/25 | Loss: 0.00105913
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0010591298341751099, 0.0010591298341751099, 0.0010591298341751099, 0.0010591298341751099, 0.0010591298341751099]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010591298341751099

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.16240466
Iteration 2/25 | Loss: 0.00072708
Iteration 3/25 | Loss: 0.00072708
Iteration 4/25 | Loss: 0.00072708
Iteration 5/25 | Loss: 0.00072708
Iteration 6/25 | Loss: 0.00072708
Iteration 7/25 | Loss: 0.00072708
Iteration 8/25 | Loss: 0.00072708
Iteration 9/25 | Loss: 0.00072708
Iteration 10/25 | Loss: 0.00072708
Iteration 11/25 | Loss: 0.00072708
Iteration 12/25 | Loss: 0.00072708
Iteration 13/25 | Loss: 0.00072708
Iteration 14/25 | Loss: 0.00072708
Iteration 15/25 | Loss: 0.00072708
Iteration 16/25 | Loss: 0.00072708
Iteration 17/25 | Loss: 0.00072708
Iteration 18/25 | Loss: 0.00072708
Iteration 19/25 | Loss: 0.00072708
Iteration 20/25 | Loss: 0.00072708
Iteration 21/25 | Loss: 0.00072708
Iteration 22/25 | Loss: 0.00072708
Iteration 23/25 | Loss: 0.00072708
Iteration 24/25 | Loss: 0.00072708
Iteration 25/25 | Loss: 0.00072708

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00072708
Iteration 2/1000 | Loss: 0.00005454
Iteration 3/1000 | Loss: 0.00003911
Iteration 4/1000 | Loss: 0.00003502
Iteration 5/1000 | Loss: 0.00003277
Iteration 6/1000 | Loss: 0.00003160
Iteration 7/1000 | Loss: 0.00003055
Iteration 8/1000 | Loss: 0.00002949
Iteration 9/1000 | Loss: 0.00002879
Iteration 10/1000 | Loss: 0.00002828
Iteration 11/1000 | Loss: 0.00002778
Iteration 12/1000 | Loss: 0.00002743
Iteration 13/1000 | Loss: 0.00002713
Iteration 14/1000 | Loss: 0.00002697
Iteration 15/1000 | Loss: 0.00002688
Iteration 16/1000 | Loss: 0.00002675
Iteration 17/1000 | Loss: 0.00002671
Iteration 18/1000 | Loss: 0.00002665
Iteration 19/1000 | Loss: 0.00002665
Iteration 20/1000 | Loss: 0.00002665
Iteration 21/1000 | Loss: 0.00002664
Iteration 22/1000 | Loss: 0.00002664
Iteration 23/1000 | Loss: 0.00002664
Iteration 24/1000 | Loss: 0.00002663
Iteration 25/1000 | Loss: 0.00002662
Iteration 26/1000 | Loss: 0.00002662
Iteration 27/1000 | Loss: 0.00002662
Iteration 28/1000 | Loss: 0.00002661
Iteration 29/1000 | Loss: 0.00002661
Iteration 30/1000 | Loss: 0.00002661
Iteration 31/1000 | Loss: 0.00002660
Iteration 32/1000 | Loss: 0.00002660
Iteration 33/1000 | Loss: 0.00002660
Iteration 34/1000 | Loss: 0.00002660
Iteration 35/1000 | Loss: 0.00002660
Iteration 36/1000 | Loss: 0.00002660
Iteration 37/1000 | Loss: 0.00002660
Iteration 38/1000 | Loss: 0.00002659
Iteration 39/1000 | Loss: 0.00002659
Iteration 40/1000 | Loss: 0.00002659
Iteration 41/1000 | Loss: 0.00002659
Iteration 42/1000 | Loss: 0.00002659
Iteration 43/1000 | Loss: 0.00002659
Iteration 44/1000 | Loss: 0.00002659
Iteration 45/1000 | Loss: 0.00002659
Iteration 46/1000 | Loss: 0.00002659
Iteration 47/1000 | Loss: 0.00002659
Iteration 48/1000 | Loss: 0.00002659
Iteration 49/1000 | Loss: 0.00002659
Iteration 50/1000 | Loss: 0.00002659
Iteration 51/1000 | Loss: 0.00002659
Iteration 52/1000 | Loss: 0.00002659
Iteration 53/1000 | Loss: 0.00002659
Iteration 54/1000 | Loss: 0.00002659
Iteration 55/1000 | Loss: 0.00002659
Iteration 56/1000 | Loss: 0.00002659
Iteration 57/1000 | Loss: 0.00002659
Iteration 58/1000 | Loss: 0.00002659
Iteration 59/1000 | Loss: 0.00002659
Iteration 60/1000 | Loss: 0.00002659
Iteration 61/1000 | Loss: 0.00002659
Iteration 62/1000 | Loss: 0.00002659
Iteration 63/1000 | Loss: 0.00002659
Iteration 64/1000 | Loss: 0.00002659
Iteration 65/1000 | Loss: 0.00002659
Iteration 66/1000 | Loss: 0.00002659
Iteration 67/1000 | Loss: 0.00002659
Iteration 68/1000 | Loss: 0.00002659
Iteration 69/1000 | Loss: 0.00002659
Iteration 70/1000 | Loss: 0.00002659
Iteration 71/1000 | Loss: 0.00002659
Iteration 72/1000 | Loss: 0.00002659
Iteration 73/1000 | Loss: 0.00002659
Iteration 74/1000 | Loss: 0.00002659
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 74. Stopping optimization.
Last 5 losses: [2.65892540483037e-05, 2.65892540483037e-05, 2.65892540483037e-05, 2.65892540483037e-05, 2.65892540483037e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.65892540483037e-05

Optimization complete. Final v2v error: 4.129017353057861 mm

Highest mean error: 5.435291767120361 mm for frame 147

Lowest mean error: 3.1935880184173584 mm for frame 0

Saving results

Total time: 37.003767251968384
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00855220
Iteration 2/25 | Loss: 0.00117281
Iteration 3/25 | Loss: 0.00099220
Iteration 4/25 | Loss: 0.00094949
Iteration 5/25 | Loss: 0.00093442
Iteration 6/25 | Loss: 0.00093211
Iteration 7/25 | Loss: 0.00093153
Iteration 8/25 | Loss: 0.00093153
Iteration 9/25 | Loss: 0.00093153
Iteration 10/25 | Loss: 0.00093153
Iteration 11/25 | Loss: 0.00093153
Iteration 12/25 | Loss: 0.00093153
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009315289207734168, 0.0009315289207734168, 0.0009315289207734168, 0.0009315289207734168, 0.0009315289207734168]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009315289207734168

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.36146116
Iteration 2/25 | Loss: 0.00067251
Iteration 3/25 | Loss: 0.00067251
Iteration 4/25 | Loss: 0.00067251
Iteration 5/25 | Loss: 0.00067251
Iteration 6/25 | Loss: 0.00067251
Iteration 7/25 | Loss: 0.00067251
Iteration 8/25 | Loss: 0.00067250
Iteration 9/25 | Loss: 0.00067250
Iteration 10/25 | Loss: 0.00067250
Iteration 11/25 | Loss: 0.00067250
Iteration 12/25 | Loss: 0.00067250
Iteration 13/25 | Loss: 0.00067250
Iteration 14/25 | Loss: 0.00067250
Iteration 15/25 | Loss: 0.00067250
Iteration 16/25 | Loss: 0.00067250
Iteration 17/25 | Loss: 0.00067250
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.0006725043640471995, 0.0006725043640471995, 0.0006725043640471995, 0.0006725043640471995, 0.0006725043640471995]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006725043640471995

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00067250
Iteration 2/1000 | Loss: 0.00003138
Iteration 3/1000 | Loss: 0.00002476
Iteration 4/1000 | Loss: 0.00002263
Iteration 5/1000 | Loss: 0.00002152
Iteration 6/1000 | Loss: 0.00002099
Iteration 7/1000 | Loss: 0.00002059
Iteration 8/1000 | Loss: 0.00002053
Iteration 9/1000 | Loss: 0.00002043
Iteration 10/1000 | Loss: 0.00002042
Iteration 11/1000 | Loss: 0.00002042
Iteration 12/1000 | Loss: 0.00002042
Iteration 13/1000 | Loss: 0.00002010
Iteration 14/1000 | Loss: 0.00001988
Iteration 15/1000 | Loss: 0.00001986
Iteration 16/1000 | Loss: 0.00001985
Iteration 17/1000 | Loss: 0.00001971
Iteration 18/1000 | Loss: 0.00001969
Iteration 19/1000 | Loss: 0.00001966
Iteration 20/1000 | Loss: 0.00001963
Iteration 21/1000 | Loss: 0.00001961
Iteration 22/1000 | Loss: 0.00001961
Iteration 23/1000 | Loss: 0.00001961
Iteration 24/1000 | Loss: 0.00001960
Iteration 25/1000 | Loss: 0.00001960
Iteration 26/1000 | Loss: 0.00001960
Iteration 27/1000 | Loss: 0.00001960
Iteration 28/1000 | Loss: 0.00001960
Iteration 29/1000 | Loss: 0.00001960
Iteration 30/1000 | Loss: 0.00001960
Iteration 31/1000 | Loss: 0.00001960
Iteration 32/1000 | Loss: 0.00001960
Iteration 33/1000 | Loss: 0.00001960
Iteration 34/1000 | Loss: 0.00001960
Iteration 35/1000 | Loss: 0.00001960
Iteration 36/1000 | Loss: 0.00001960
Iteration 37/1000 | Loss: 0.00001960
Iteration 38/1000 | Loss: 0.00001960
Iteration 39/1000 | Loss: 0.00001959
Iteration 40/1000 | Loss: 0.00001959
Iteration 41/1000 | Loss: 0.00001959
Iteration 42/1000 | Loss: 0.00001959
Iteration 43/1000 | Loss: 0.00001959
Iteration 44/1000 | Loss: 0.00001959
Iteration 45/1000 | Loss: 0.00001959
Iteration 46/1000 | Loss: 0.00001959
Iteration 47/1000 | Loss: 0.00001958
Iteration 48/1000 | Loss: 0.00001958
Iteration 49/1000 | Loss: 0.00001957
Iteration 50/1000 | Loss: 0.00001957
Iteration 51/1000 | Loss: 0.00001957
Iteration 52/1000 | Loss: 0.00001957
Iteration 53/1000 | Loss: 0.00001957
Iteration 54/1000 | Loss: 0.00001957
Iteration 55/1000 | Loss: 0.00001957
Iteration 56/1000 | Loss: 0.00001957
Iteration 57/1000 | Loss: 0.00001957
Iteration 58/1000 | Loss: 0.00001957
Iteration 59/1000 | Loss: 0.00001957
Iteration 60/1000 | Loss: 0.00001957
Iteration 61/1000 | Loss: 0.00001957
Iteration 62/1000 | Loss: 0.00001957
Iteration 63/1000 | Loss: 0.00001957
Iteration 64/1000 | Loss: 0.00001957
Iteration 65/1000 | Loss: 0.00001957
Iteration 66/1000 | Loss: 0.00001957
Iteration 67/1000 | Loss: 0.00001957
Iteration 68/1000 | Loss: 0.00001957
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 68. Stopping optimization.
Last 5 losses: [1.9568897187127732e-05, 1.9568897187127732e-05, 1.9568897187127732e-05, 1.9568897187127732e-05, 1.9568897187127732e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9568897187127732e-05

Optimization complete. Final v2v error: 3.9035134315490723 mm

Highest mean error: 4.324237823486328 mm for frame 3

Lowest mean error: 3.707890748977661 mm for frame 44

Saving results

Total time: 27.231303453445435
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00866760
Iteration 2/25 | Loss: 0.00124941
Iteration 3/25 | Loss: 0.00099771
Iteration 4/25 | Loss: 0.00096243
Iteration 5/25 | Loss: 0.00095363
Iteration 6/25 | Loss: 0.00095121
Iteration 7/25 | Loss: 0.00095063
Iteration 8/25 | Loss: 0.00095053
Iteration 9/25 | Loss: 0.00095053
Iteration 10/25 | Loss: 0.00095053
Iteration 11/25 | Loss: 0.00095053
Iteration 12/25 | Loss: 0.00095053
Iteration 13/25 | Loss: 0.00095053
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.000950526911765337, 0.000950526911765337, 0.000950526911765337, 0.000950526911765337, 0.000950526911765337]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000950526911765337

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48235154
Iteration 2/25 | Loss: 0.00069490
Iteration 3/25 | Loss: 0.00069490
Iteration 4/25 | Loss: 0.00069490
Iteration 5/25 | Loss: 0.00069490
Iteration 6/25 | Loss: 0.00069490
Iteration 7/25 | Loss: 0.00069490
Iteration 8/25 | Loss: 0.00069490
Iteration 9/25 | Loss: 0.00069490
Iteration 10/25 | Loss: 0.00069490
Iteration 11/25 | Loss: 0.00069490
Iteration 12/25 | Loss: 0.00069490
Iteration 13/25 | Loss: 0.00069490
Iteration 14/25 | Loss: 0.00069490
Iteration 15/25 | Loss: 0.00069490
Iteration 16/25 | Loss: 0.00069490
Iteration 17/25 | Loss: 0.00069490
Iteration 18/25 | Loss: 0.00069490
Iteration 19/25 | Loss: 0.00069490
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.0006948952213861048, 0.0006948952213861048, 0.0006948952213861048, 0.0006948952213861048, 0.0006948952213861048]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006948952213861048

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00069490
Iteration 2/1000 | Loss: 0.00003321
Iteration 3/1000 | Loss: 0.00002641
Iteration 4/1000 | Loss: 0.00002366
Iteration 5/1000 | Loss: 0.00002245
Iteration 6/1000 | Loss: 0.00002173
Iteration 7/1000 | Loss: 0.00002114
Iteration 8/1000 | Loss: 0.00002068
Iteration 9/1000 | Loss: 0.00002037
Iteration 10/1000 | Loss: 0.00002036
Iteration 11/1000 | Loss: 0.00002022
Iteration 12/1000 | Loss: 0.00002017
Iteration 13/1000 | Loss: 0.00002017
Iteration 14/1000 | Loss: 0.00002015
Iteration 15/1000 | Loss: 0.00002011
Iteration 16/1000 | Loss: 0.00002006
Iteration 17/1000 | Loss: 0.00002003
Iteration 18/1000 | Loss: 0.00002000
Iteration 19/1000 | Loss: 0.00001999
Iteration 20/1000 | Loss: 0.00001998
Iteration 21/1000 | Loss: 0.00001997
Iteration 22/1000 | Loss: 0.00001997
Iteration 23/1000 | Loss: 0.00001996
Iteration 24/1000 | Loss: 0.00001996
Iteration 25/1000 | Loss: 0.00001995
Iteration 26/1000 | Loss: 0.00001995
Iteration 27/1000 | Loss: 0.00001995
Iteration 28/1000 | Loss: 0.00001995
Iteration 29/1000 | Loss: 0.00001995
Iteration 30/1000 | Loss: 0.00001995
Iteration 31/1000 | Loss: 0.00001995
Iteration 32/1000 | Loss: 0.00001995
Iteration 33/1000 | Loss: 0.00001995
Iteration 34/1000 | Loss: 0.00001995
Iteration 35/1000 | Loss: 0.00001995
Iteration 36/1000 | Loss: 0.00001995
Iteration 37/1000 | Loss: 0.00001994
Iteration 38/1000 | Loss: 0.00001994
Iteration 39/1000 | Loss: 0.00001994
Iteration 40/1000 | Loss: 0.00001994
Iteration 41/1000 | Loss: 0.00001994
Iteration 42/1000 | Loss: 0.00001994
Iteration 43/1000 | Loss: 0.00001994
Iteration 44/1000 | Loss: 0.00001994
Iteration 45/1000 | Loss: 0.00001994
Iteration 46/1000 | Loss: 0.00001994
Iteration 47/1000 | Loss: 0.00001994
Iteration 48/1000 | Loss: 0.00001994
Iteration 49/1000 | Loss: 0.00001993
Iteration 50/1000 | Loss: 0.00001993
Iteration 51/1000 | Loss: 0.00001993
Iteration 52/1000 | Loss: 0.00001993
Iteration 53/1000 | Loss: 0.00001993
Iteration 54/1000 | Loss: 0.00001992
Iteration 55/1000 | Loss: 0.00001992
Iteration 56/1000 | Loss: 0.00001992
Iteration 57/1000 | Loss: 0.00001992
Iteration 58/1000 | Loss: 0.00001991
Iteration 59/1000 | Loss: 0.00001991
Iteration 60/1000 | Loss: 0.00001991
Iteration 61/1000 | Loss: 0.00001991
Iteration 62/1000 | Loss: 0.00001991
Iteration 63/1000 | Loss: 0.00001991
Iteration 64/1000 | Loss: 0.00001990
Iteration 65/1000 | Loss: 0.00001990
Iteration 66/1000 | Loss: 0.00001990
Iteration 67/1000 | Loss: 0.00001990
Iteration 68/1000 | Loss: 0.00001990
Iteration 69/1000 | Loss: 0.00001990
Iteration 70/1000 | Loss: 0.00001990
Iteration 71/1000 | Loss: 0.00001990
Iteration 72/1000 | Loss: 0.00001990
Iteration 73/1000 | Loss: 0.00001990
Iteration 74/1000 | Loss: 0.00001990
Iteration 75/1000 | Loss: 0.00001989
Iteration 76/1000 | Loss: 0.00001989
Iteration 77/1000 | Loss: 0.00001989
Iteration 78/1000 | Loss: 0.00001989
Iteration 79/1000 | Loss: 0.00001989
Iteration 80/1000 | Loss: 0.00001988
Iteration 81/1000 | Loss: 0.00001988
Iteration 82/1000 | Loss: 0.00001988
Iteration 83/1000 | Loss: 0.00001988
Iteration 84/1000 | Loss: 0.00001988
Iteration 85/1000 | Loss: 0.00001988
Iteration 86/1000 | Loss: 0.00001988
Iteration 87/1000 | Loss: 0.00001988
Iteration 88/1000 | Loss: 0.00001988
Iteration 89/1000 | Loss: 0.00001988
Iteration 90/1000 | Loss: 0.00001987
Iteration 91/1000 | Loss: 0.00001987
Iteration 92/1000 | Loss: 0.00001987
Iteration 93/1000 | Loss: 0.00001987
Iteration 94/1000 | Loss: 0.00001987
Iteration 95/1000 | Loss: 0.00001987
Iteration 96/1000 | Loss: 0.00001987
Iteration 97/1000 | Loss: 0.00001987
Iteration 98/1000 | Loss: 0.00001987
Iteration 99/1000 | Loss: 0.00001987
Iteration 100/1000 | Loss: 0.00001987
Iteration 101/1000 | Loss: 0.00001987
Iteration 102/1000 | Loss: 0.00001986
Iteration 103/1000 | Loss: 0.00001986
Iteration 104/1000 | Loss: 0.00001986
Iteration 105/1000 | Loss: 0.00001986
Iteration 106/1000 | Loss: 0.00001986
Iteration 107/1000 | Loss: 0.00001986
Iteration 108/1000 | Loss: 0.00001986
Iteration 109/1000 | Loss: 0.00001986
Iteration 110/1000 | Loss: 0.00001986
Iteration 111/1000 | Loss: 0.00001986
Iteration 112/1000 | Loss: 0.00001986
Iteration 113/1000 | Loss: 0.00001986
Iteration 114/1000 | Loss: 0.00001986
Iteration 115/1000 | Loss: 0.00001986
Iteration 116/1000 | Loss: 0.00001986
Iteration 117/1000 | Loss: 0.00001986
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 117. Stopping optimization.
Last 5 losses: [1.9862303815898485e-05, 1.9862303815898485e-05, 1.9862303815898485e-05, 1.9862303815898485e-05, 1.9862303815898485e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9862303815898485e-05

Optimization complete. Final v2v error: 3.688265323638916 mm

Highest mean error: 3.987290859222412 mm for frame 63

Lowest mean error: 3.265911340713501 mm for frame 2

Saving results

Total time: 31.751500606536865
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00805941
Iteration 2/25 | Loss: 0.00149410
Iteration 3/25 | Loss: 0.00107804
Iteration 4/25 | Loss: 0.00101122
Iteration 5/25 | Loss: 0.00097299
Iteration 6/25 | Loss: 0.00095891
Iteration 7/25 | Loss: 0.00095493
Iteration 8/25 | Loss: 0.00095374
Iteration 9/25 | Loss: 0.00095283
Iteration 10/25 | Loss: 0.00095782
Iteration 11/25 | Loss: 0.00095452
Iteration 12/25 | Loss: 0.00095445
Iteration 13/25 | Loss: 0.00095122
Iteration 14/25 | Loss: 0.00094828
Iteration 15/25 | Loss: 0.00094716
Iteration 16/25 | Loss: 0.00094679
Iteration 17/25 | Loss: 0.00094664
Iteration 18/25 | Loss: 0.00094659
Iteration 19/25 | Loss: 0.00094659
Iteration 20/25 | Loss: 0.00094659
Iteration 21/25 | Loss: 0.00094659
Iteration 22/25 | Loss: 0.00094659
Iteration 23/25 | Loss: 0.00094659
Iteration 24/25 | Loss: 0.00094658
Iteration 25/25 | Loss: 0.00094658

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 8.84162235
Iteration 2/25 | Loss: 0.00098736
Iteration 3/25 | Loss: 0.00089896
Iteration 4/25 | Loss: 0.00089896
Iteration 5/25 | Loss: 0.00089896
Iteration 6/25 | Loss: 0.00089896
Iteration 7/25 | Loss: 0.00089896
Iteration 8/25 | Loss: 0.00089896
Iteration 9/25 | Loss: 0.00089896
Iteration 10/25 | Loss: 0.00089896
Iteration 11/25 | Loss: 0.00089896
Iteration 12/25 | Loss: 0.00089896
Iteration 13/25 | Loss: 0.00089896
Iteration 14/25 | Loss: 0.00089896
Iteration 15/25 | Loss: 0.00089896
Iteration 16/25 | Loss: 0.00089896
Iteration 17/25 | Loss: 0.00089896
Iteration 18/25 | Loss: 0.00089896
Iteration 19/25 | Loss: 0.00089896
Iteration 20/25 | Loss: 0.00089896
Iteration 21/25 | Loss: 0.00089896
Iteration 22/25 | Loss: 0.00089896
Iteration 23/25 | Loss: 0.00089896
Iteration 24/25 | Loss: 0.00089896
Iteration 25/25 | Loss: 0.00089896

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00089896
Iteration 2/1000 | Loss: 0.00004065
Iteration 3/1000 | Loss: 0.00002959
Iteration 4/1000 | Loss: 0.00002628
Iteration 5/1000 | Loss: 0.00002447
Iteration 6/1000 | Loss: 0.00002334
Iteration 7/1000 | Loss: 0.00002256
Iteration 8/1000 | Loss: 0.00002216
Iteration 9/1000 | Loss: 0.00002174
Iteration 10/1000 | Loss: 0.00002148
Iteration 11/1000 | Loss: 0.00002139
Iteration 12/1000 | Loss: 0.00002124
Iteration 13/1000 | Loss: 0.00002123
Iteration 14/1000 | Loss: 0.00002114
Iteration 15/1000 | Loss: 0.00002112
Iteration 16/1000 | Loss: 0.00002111
Iteration 17/1000 | Loss: 0.00002105
Iteration 18/1000 | Loss: 0.00002100
Iteration 19/1000 | Loss: 0.00002100
Iteration 20/1000 | Loss: 0.00002098
Iteration 21/1000 | Loss: 0.00002098
Iteration 22/1000 | Loss: 0.00002097
Iteration 23/1000 | Loss: 0.00002096
Iteration 24/1000 | Loss: 0.00002094
Iteration 25/1000 | Loss: 0.00002092
Iteration 26/1000 | Loss: 0.00002092
Iteration 27/1000 | Loss: 0.00002091
Iteration 28/1000 | Loss: 0.00002091
Iteration 29/1000 | Loss: 0.00002090
Iteration 30/1000 | Loss: 0.00002090
Iteration 31/1000 | Loss: 0.00002089
Iteration 32/1000 | Loss: 0.00002089
Iteration 33/1000 | Loss: 0.00002088
Iteration 34/1000 | Loss: 0.00002088
Iteration 35/1000 | Loss: 0.00002088
Iteration 36/1000 | Loss: 0.00002087
Iteration 37/1000 | Loss: 0.00002087
Iteration 38/1000 | Loss: 0.00002087
Iteration 39/1000 | Loss: 0.00002086
Iteration 40/1000 | Loss: 0.00002086
Iteration 41/1000 | Loss: 0.00002085
Iteration 42/1000 | Loss: 0.00002085
Iteration 43/1000 | Loss: 0.00002085
Iteration 44/1000 | Loss: 0.00002084
Iteration 45/1000 | Loss: 0.00002084
Iteration 46/1000 | Loss: 0.00002083
Iteration 47/1000 | Loss: 0.00002083
Iteration 48/1000 | Loss: 0.00002083
Iteration 49/1000 | Loss: 0.00002082
Iteration 50/1000 | Loss: 0.00002082
Iteration 51/1000 | Loss: 0.00002081
Iteration 52/1000 | Loss: 0.00002081
Iteration 53/1000 | Loss: 0.00002080
Iteration 54/1000 | Loss: 0.00002080
Iteration 55/1000 | Loss: 0.00002080
Iteration 56/1000 | Loss: 0.00002080
Iteration 57/1000 | Loss: 0.00002079
Iteration 58/1000 | Loss: 0.00002079
Iteration 59/1000 | Loss: 0.00002078
Iteration 60/1000 | Loss: 0.00002078
Iteration 61/1000 | Loss: 0.00002078
Iteration 62/1000 | Loss: 0.00002077
Iteration 63/1000 | Loss: 0.00002077
Iteration 64/1000 | Loss: 0.00002077
Iteration 65/1000 | Loss: 0.00002077
Iteration 66/1000 | Loss: 0.00002076
Iteration 67/1000 | Loss: 0.00002076
Iteration 68/1000 | Loss: 0.00002076
Iteration 69/1000 | Loss: 0.00002075
Iteration 70/1000 | Loss: 0.00002075
Iteration 71/1000 | Loss: 0.00002075
Iteration 72/1000 | Loss: 0.00002075
Iteration 73/1000 | Loss: 0.00002075
Iteration 74/1000 | Loss: 0.00002074
Iteration 75/1000 | Loss: 0.00002074
Iteration 76/1000 | Loss: 0.00002074
Iteration 77/1000 | Loss: 0.00002074
Iteration 78/1000 | Loss: 0.00002074
Iteration 79/1000 | Loss: 0.00002074
Iteration 80/1000 | Loss: 0.00002073
Iteration 81/1000 | Loss: 0.00002073
Iteration 82/1000 | Loss: 0.00002073
Iteration 83/1000 | Loss: 0.00002073
Iteration 84/1000 | Loss: 0.00002073
Iteration 85/1000 | Loss: 0.00002073
Iteration 86/1000 | Loss: 0.00002073
Iteration 87/1000 | Loss: 0.00002073
Iteration 88/1000 | Loss: 0.00002073
Iteration 89/1000 | Loss: 0.00002073
Iteration 90/1000 | Loss: 0.00002073
Iteration 91/1000 | Loss: 0.00002072
Iteration 92/1000 | Loss: 0.00002072
Iteration 93/1000 | Loss: 0.00002072
Iteration 94/1000 | Loss: 0.00002072
Iteration 95/1000 | Loss: 0.00002072
Iteration 96/1000 | Loss: 0.00002072
Iteration 97/1000 | Loss: 0.00002072
Iteration 98/1000 | Loss: 0.00002072
Iteration 99/1000 | Loss: 0.00002072
Iteration 100/1000 | Loss: 0.00002072
Iteration 101/1000 | Loss: 0.00002071
Iteration 102/1000 | Loss: 0.00002071
Iteration 103/1000 | Loss: 0.00002071
Iteration 104/1000 | Loss: 0.00002071
Iteration 105/1000 | Loss: 0.00002071
Iteration 106/1000 | Loss: 0.00002071
Iteration 107/1000 | Loss: 0.00002071
Iteration 108/1000 | Loss: 0.00002071
Iteration 109/1000 | Loss: 0.00002071
Iteration 110/1000 | Loss: 0.00002071
Iteration 111/1000 | Loss: 0.00002071
Iteration 112/1000 | Loss: 0.00002070
Iteration 113/1000 | Loss: 0.00002070
Iteration 114/1000 | Loss: 0.00002070
Iteration 115/1000 | Loss: 0.00002070
Iteration 116/1000 | Loss: 0.00002070
Iteration 117/1000 | Loss: 0.00002070
Iteration 118/1000 | Loss: 0.00002070
Iteration 119/1000 | Loss: 0.00002070
Iteration 120/1000 | Loss: 0.00002070
Iteration 121/1000 | Loss: 0.00002070
Iteration 122/1000 | Loss: 0.00002069
Iteration 123/1000 | Loss: 0.00002069
Iteration 124/1000 | Loss: 0.00002069
Iteration 125/1000 | Loss: 0.00002069
Iteration 126/1000 | Loss: 0.00002069
Iteration 127/1000 | Loss: 0.00002069
Iteration 128/1000 | Loss: 0.00002069
Iteration 129/1000 | Loss: 0.00002069
Iteration 130/1000 | Loss: 0.00002069
Iteration 131/1000 | Loss: 0.00002069
Iteration 132/1000 | Loss: 0.00002069
Iteration 133/1000 | Loss: 0.00002069
Iteration 134/1000 | Loss: 0.00002069
Iteration 135/1000 | Loss: 0.00002069
Iteration 136/1000 | Loss: 0.00002069
Iteration 137/1000 | Loss: 0.00002068
Iteration 138/1000 | Loss: 0.00002068
Iteration 139/1000 | Loss: 0.00002068
Iteration 140/1000 | Loss: 0.00002068
Iteration 141/1000 | Loss: 0.00002068
Iteration 142/1000 | Loss: 0.00002068
Iteration 143/1000 | Loss: 0.00002068
Iteration 144/1000 | Loss: 0.00002068
Iteration 145/1000 | Loss: 0.00002068
Iteration 146/1000 | Loss: 0.00002067
Iteration 147/1000 | Loss: 0.00002067
Iteration 148/1000 | Loss: 0.00002067
Iteration 149/1000 | Loss: 0.00002067
Iteration 150/1000 | Loss: 0.00002067
Iteration 151/1000 | Loss: 0.00002067
Iteration 152/1000 | Loss: 0.00002067
Iteration 153/1000 | Loss: 0.00002067
Iteration 154/1000 | Loss: 0.00002067
Iteration 155/1000 | Loss: 0.00002067
Iteration 156/1000 | Loss: 0.00002066
Iteration 157/1000 | Loss: 0.00002066
Iteration 158/1000 | Loss: 0.00002066
Iteration 159/1000 | Loss: 0.00002066
Iteration 160/1000 | Loss: 0.00002066
Iteration 161/1000 | Loss: 0.00002066
Iteration 162/1000 | Loss: 0.00002066
Iteration 163/1000 | Loss: 0.00002066
Iteration 164/1000 | Loss: 0.00002066
Iteration 165/1000 | Loss: 0.00002066
Iteration 166/1000 | Loss: 0.00002066
Iteration 167/1000 | Loss: 0.00002066
Iteration 168/1000 | Loss: 0.00002066
Iteration 169/1000 | Loss: 0.00002065
Iteration 170/1000 | Loss: 0.00002065
Iteration 171/1000 | Loss: 0.00002065
Iteration 172/1000 | Loss: 0.00002065
Iteration 173/1000 | Loss: 0.00002065
Iteration 174/1000 | Loss: 0.00002065
Iteration 175/1000 | Loss: 0.00002065
Iteration 176/1000 | Loss: 0.00002064
Iteration 177/1000 | Loss: 0.00002064
Iteration 178/1000 | Loss: 0.00002064
Iteration 179/1000 | Loss: 0.00002064
Iteration 180/1000 | Loss: 0.00002064
Iteration 181/1000 | Loss: 0.00002064
Iteration 182/1000 | Loss: 0.00002064
Iteration 183/1000 | Loss: 0.00002064
Iteration 184/1000 | Loss: 0.00002064
Iteration 185/1000 | Loss: 0.00002064
Iteration 186/1000 | Loss: 0.00002064
Iteration 187/1000 | Loss: 0.00002064
Iteration 188/1000 | Loss: 0.00002064
Iteration 189/1000 | Loss: 0.00002064
Iteration 190/1000 | Loss: 0.00002064
Iteration 191/1000 | Loss: 0.00002064
Iteration 192/1000 | Loss: 0.00002064
Iteration 193/1000 | Loss: 0.00002063
Iteration 194/1000 | Loss: 0.00002063
Iteration 195/1000 | Loss: 0.00002063
Iteration 196/1000 | Loss: 0.00002063
Iteration 197/1000 | Loss: 0.00002063
Iteration 198/1000 | Loss: 0.00002063
Iteration 199/1000 | Loss: 0.00002063
Iteration 200/1000 | Loss: 0.00002063
Iteration 201/1000 | Loss: 0.00002063
Iteration 202/1000 | Loss: 0.00002063
Iteration 203/1000 | Loss: 0.00002063
Iteration 204/1000 | Loss: 0.00002063
Iteration 205/1000 | Loss: 0.00002063
Iteration 206/1000 | Loss: 0.00002063
Iteration 207/1000 | Loss: 0.00002063
Iteration 208/1000 | Loss: 0.00002063
Iteration 209/1000 | Loss: 0.00002062
Iteration 210/1000 | Loss: 0.00002062
Iteration 211/1000 | Loss: 0.00002062
Iteration 212/1000 | Loss: 0.00002062
Iteration 213/1000 | Loss: 0.00002062
Iteration 214/1000 | Loss: 0.00002062
Iteration 215/1000 | Loss: 0.00002062
Iteration 216/1000 | Loss: 0.00002062
Iteration 217/1000 | Loss: 0.00002062
Iteration 218/1000 | Loss: 0.00002062
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 218. Stopping optimization.
Last 5 losses: [2.0624109311029315e-05, 2.0624109311029315e-05, 2.0624109311029315e-05, 2.0624109311029315e-05, 2.0624109311029315e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0624109311029315e-05

Optimization complete. Final v2v error: 3.887633800506592 mm

Highest mean error: 4.686220645904541 mm for frame 104

Lowest mean error: 3.2604286670684814 mm for frame 226

Saving results

Total time: 70.03190541267395
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00840450
Iteration 2/25 | Loss: 0.00128915
Iteration 3/25 | Loss: 0.00107177
Iteration 4/25 | Loss: 0.00102596
Iteration 5/25 | Loss: 0.00101175
Iteration 6/25 | Loss: 0.00100956
Iteration 7/25 | Loss: 0.00100935
Iteration 8/25 | Loss: 0.00100935
Iteration 9/25 | Loss: 0.00100935
Iteration 10/25 | Loss: 0.00100935
Iteration 11/25 | Loss: 0.00100935
Iteration 12/25 | Loss: 0.00100935
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0010093484306707978, 0.0010093484306707978, 0.0010093484306707978, 0.0010093484306707978, 0.0010093484306707978]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010093484306707978

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.47917879
Iteration 2/25 | Loss: 0.00085433
Iteration 3/25 | Loss: 0.00085430
Iteration 4/25 | Loss: 0.00085430
Iteration 5/25 | Loss: 0.00085430
Iteration 6/25 | Loss: 0.00085430
Iteration 7/25 | Loss: 0.00085429
Iteration 8/25 | Loss: 0.00085429
Iteration 9/25 | Loss: 0.00085429
Iteration 10/25 | Loss: 0.00085429
Iteration 11/25 | Loss: 0.00085429
Iteration 12/25 | Loss: 0.00085429
Iteration 13/25 | Loss: 0.00085429
Iteration 14/25 | Loss: 0.00085429
Iteration 15/25 | Loss: 0.00085429
Iteration 16/25 | Loss: 0.00085429
Iteration 17/25 | Loss: 0.00085429
Iteration 18/25 | Loss: 0.00085429
Iteration 19/25 | Loss: 0.00085429
Iteration 20/25 | Loss: 0.00085429
Iteration 21/25 | Loss: 0.00085429
Iteration 22/25 | Loss: 0.00085429
Iteration 23/25 | Loss: 0.00085429
Iteration 24/25 | Loss: 0.00085429
Iteration 25/25 | Loss: 0.00085429

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00085429
Iteration 2/1000 | Loss: 0.00004090
Iteration 3/1000 | Loss: 0.00002963
Iteration 4/1000 | Loss: 0.00002613
Iteration 5/1000 | Loss: 0.00002511
Iteration 6/1000 | Loss: 0.00002413
Iteration 7/1000 | Loss: 0.00002355
Iteration 8/1000 | Loss: 0.00002302
Iteration 9/1000 | Loss: 0.00002271
Iteration 10/1000 | Loss: 0.00002258
Iteration 11/1000 | Loss: 0.00002252
Iteration 12/1000 | Loss: 0.00002240
Iteration 13/1000 | Loss: 0.00002231
Iteration 14/1000 | Loss: 0.00002231
Iteration 15/1000 | Loss: 0.00002226
Iteration 16/1000 | Loss: 0.00002226
Iteration 17/1000 | Loss: 0.00002224
Iteration 18/1000 | Loss: 0.00002224
Iteration 19/1000 | Loss: 0.00002224
Iteration 20/1000 | Loss: 0.00002224
Iteration 21/1000 | Loss: 0.00002224
Iteration 22/1000 | Loss: 0.00002224
Iteration 23/1000 | Loss: 0.00002224
Iteration 24/1000 | Loss: 0.00002224
Iteration 25/1000 | Loss: 0.00002224
Iteration 26/1000 | Loss: 0.00002224
Iteration 27/1000 | Loss: 0.00002224
Iteration 28/1000 | Loss: 0.00002223
Iteration 29/1000 | Loss: 0.00002223
Iteration 30/1000 | Loss: 0.00002223
Iteration 31/1000 | Loss: 0.00002223
Iteration 32/1000 | Loss: 0.00002222
Iteration 33/1000 | Loss: 0.00002222
Iteration 34/1000 | Loss: 0.00002222
Iteration 35/1000 | Loss: 0.00002222
Iteration 36/1000 | Loss: 0.00002221
Iteration 37/1000 | Loss: 0.00002221
Iteration 38/1000 | Loss: 0.00002221
Iteration 39/1000 | Loss: 0.00002221
Iteration 40/1000 | Loss: 0.00002221
Iteration 41/1000 | Loss: 0.00002220
Iteration 42/1000 | Loss: 0.00002220
Iteration 43/1000 | Loss: 0.00002220
Iteration 44/1000 | Loss: 0.00002219
Iteration 45/1000 | Loss: 0.00002219
Iteration 46/1000 | Loss: 0.00002219
Iteration 47/1000 | Loss: 0.00002219
Iteration 48/1000 | Loss: 0.00002219
Iteration 49/1000 | Loss: 0.00002218
Iteration 50/1000 | Loss: 0.00002218
Iteration 51/1000 | Loss: 0.00002218
Iteration 52/1000 | Loss: 0.00002218
Iteration 53/1000 | Loss: 0.00002218
Iteration 54/1000 | Loss: 0.00002218
Iteration 55/1000 | Loss: 0.00002217
Iteration 56/1000 | Loss: 0.00002217
Iteration 57/1000 | Loss: 0.00002217
Iteration 58/1000 | Loss: 0.00002216
Iteration 59/1000 | Loss: 0.00002216
Iteration 60/1000 | Loss: 0.00002216
Iteration 61/1000 | Loss: 0.00002216
Iteration 62/1000 | Loss: 0.00002216
Iteration 63/1000 | Loss: 0.00002216
Iteration 64/1000 | Loss: 0.00002216
Iteration 65/1000 | Loss: 0.00002216
Iteration 66/1000 | Loss: 0.00002216
Iteration 67/1000 | Loss: 0.00002216
Iteration 68/1000 | Loss: 0.00002216
Iteration 69/1000 | Loss: 0.00002215
Iteration 70/1000 | Loss: 0.00002215
Iteration 71/1000 | Loss: 0.00002215
Iteration 72/1000 | Loss: 0.00002215
Iteration 73/1000 | Loss: 0.00002215
Iteration 74/1000 | Loss: 0.00002215
Iteration 75/1000 | Loss: 0.00002215
Iteration 76/1000 | Loss: 0.00002215
Iteration 77/1000 | Loss: 0.00002215
Iteration 78/1000 | Loss: 0.00002215
Iteration 79/1000 | Loss: 0.00002214
Iteration 80/1000 | Loss: 0.00002214
Iteration 81/1000 | Loss: 0.00002214
Iteration 82/1000 | Loss: 0.00002214
Iteration 83/1000 | Loss: 0.00002214
Iteration 84/1000 | Loss: 0.00002214
Iteration 85/1000 | Loss: 0.00002214
Iteration 86/1000 | Loss: 0.00002214
Iteration 87/1000 | Loss: 0.00002214
Iteration 88/1000 | Loss: 0.00002214
Iteration 89/1000 | Loss: 0.00002214
Iteration 90/1000 | Loss: 0.00002214
Iteration 91/1000 | Loss: 0.00002214
Iteration 92/1000 | Loss: 0.00002214
Iteration 93/1000 | Loss: 0.00002214
Iteration 94/1000 | Loss: 0.00002214
Iteration 95/1000 | Loss: 0.00002214
Iteration 96/1000 | Loss: 0.00002214
Iteration 97/1000 | Loss: 0.00002214
Iteration 98/1000 | Loss: 0.00002214
Iteration 99/1000 | Loss: 0.00002214
Iteration 100/1000 | Loss: 0.00002214
Iteration 101/1000 | Loss: 0.00002214
Iteration 102/1000 | Loss: 0.00002214
Iteration 103/1000 | Loss: 0.00002214
Iteration 104/1000 | Loss: 0.00002214
Iteration 105/1000 | Loss: 0.00002214
Iteration 106/1000 | Loss: 0.00002214
Iteration 107/1000 | Loss: 0.00002214
Iteration 108/1000 | Loss: 0.00002214
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 108. Stopping optimization.
Last 5 losses: [2.213733569078613e-05, 2.213733569078613e-05, 2.213733569078613e-05, 2.213733569078613e-05, 2.213733569078613e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.213733569078613e-05

Optimization complete. Final v2v error: 4.078195571899414 mm

Highest mean error: 4.430536270141602 mm for frame 174

Lowest mean error: 3.5860252380371094 mm for frame 9

Saving results

Total time: 36.70389914512634
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00884677
Iteration 2/25 | Loss: 0.00121623
Iteration 3/25 | Loss: 0.00102716
Iteration 4/25 | Loss: 0.00099095
Iteration 5/25 | Loss: 0.00098126
Iteration 6/25 | Loss: 0.00097825
Iteration 7/25 | Loss: 0.00097724
Iteration 8/25 | Loss: 0.00098112
Iteration 9/25 | Loss: 0.00097961
Iteration 10/25 | Loss: 0.00097876
Iteration 11/25 | Loss: 0.00097810
Iteration 12/25 | Loss: 0.00097774
Iteration 13/25 | Loss: 0.00097604
Iteration 14/25 | Loss: 0.00097581
Iteration 15/25 | Loss: 0.00097569
Iteration 16/25 | Loss: 0.00097560
Iteration 17/25 | Loss: 0.00097559
Iteration 18/25 | Loss: 0.00097559
Iteration 19/25 | Loss: 0.00097559
Iteration 20/25 | Loss: 0.00097559
Iteration 21/25 | Loss: 0.00097558
Iteration 22/25 | Loss: 0.00097558
Iteration 23/25 | Loss: 0.00097845
Iteration 24/25 | Loss: 0.00097812
Iteration 25/25 | Loss: 0.00097527

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48305535
Iteration 2/25 | Loss: 0.00169010
Iteration 3/25 | Loss: 0.00169009
Iteration 4/25 | Loss: 0.00169009
Iteration 5/25 | Loss: 0.00169009
Iteration 6/25 | Loss: 0.00169009
Iteration 7/25 | Loss: 0.00169009
Iteration 8/25 | Loss: 0.00169009
Iteration 9/25 | Loss: 0.00169009
Iteration 10/25 | Loss: 0.00169009
Iteration 11/25 | Loss: 0.00169009
Iteration 12/25 | Loss: 0.00169009
Iteration 13/25 | Loss: 0.00169009
Iteration 14/25 | Loss: 0.00169009
Iteration 15/25 | Loss: 0.00169009
Iteration 16/25 | Loss: 0.00169009
Iteration 17/25 | Loss: 0.00169009
Iteration 18/25 | Loss: 0.00169009
Iteration 19/25 | Loss: 0.00169009
Iteration 20/25 | Loss: 0.00169009
Iteration 21/25 | Loss: 0.00169009
Iteration 22/25 | Loss: 0.00169009
Iteration 23/25 | Loss: 0.00169009
Iteration 24/25 | Loss: 0.00169009
Iteration 25/25 | Loss: 0.00169009

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00169009
Iteration 2/1000 | Loss: 0.00019217
Iteration 3/1000 | Loss: 0.00021963
Iteration 4/1000 | Loss: 0.00021010
Iteration 5/1000 | Loss: 0.00023173
Iteration 6/1000 | Loss: 0.00051062
Iteration 7/1000 | Loss: 0.00011427
Iteration 8/1000 | Loss: 0.00020924
Iteration 9/1000 | Loss: 0.00010170
Iteration 10/1000 | Loss: 0.00020711
Iteration 11/1000 | Loss: 0.00025918
Iteration 12/1000 | Loss: 0.00019603
Iteration 13/1000 | Loss: 0.00026169
Iteration 14/1000 | Loss: 0.00021100
Iteration 15/1000 | Loss: 0.00022099
Iteration 16/1000 | Loss: 0.00037844
Iteration 17/1000 | Loss: 0.00009282
Iteration 18/1000 | Loss: 0.00008112
Iteration 19/1000 | Loss: 0.00007640
Iteration 20/1000 | Loss: 0.00007275
Iteration 21/1000 | Loss: 0.00021207
Iteration 22/1000 | Loss: 0.00120041
Iteration 23/1000 | Loss: 0.00129263
Iteration 24/1000 | Loss: 0.00008052
Iteration 25/1000 | Loss: 0.00006513
Iteration 26/1000 | Loss: 0.00080212
Iteration 27/1000 | Loss: 0.00047842
Iteration 28/1000 | Loss: 0.00120810
Iteration 29/1000 | Loss: 0.00006038
Iteration 30/1000 | Loss: 0.00005244
Iteration 31/1000 | Loss: 0.00118735
Iteration 32/1000 | Loss: 0.00005629
Iteration 33/1000 | Loss: 0.00129456
Iteration 34/1000 | Loss: 0.00005383
Iteration 35/1000 | Loss: 0.00132779
Iteration 36/1000 | Loss: 0.00007775
Iteration 37/1000 | Loss: 0.00004937
Iteration 38/1000 | Loss: 0.00003820
Iteration 39/1000 | Loss: 0.00003245
Iteration 40/1000 | Loss: 0.00070752
Iteration 41/1000 | Loss: 0.00003123
Iteration 42/1000 | Loss: 0.00002702
Iteration 43/1000 | Loss: 0.00002527
Iteration 44/1000 | Loss: 0.00002363
Iteration 45/1000 | Loss: 0.00002249
Iteration 46/1000 | Loss: 0.00002167
Iteration 47/1000 | Loss: 0.00002115
Iteration 48/1000 | Loss: 0.00002068
Iteration 49/1000 | Loss: 0.00002027
Iteration 50/1000 | Loss: 0.00059402
Iteration 51/1000 | Loss: 0.00070436
Iteration 52/1000 | Loss: 0.00005732
Iteration 53/1000 | Loss: 0.00003509
Iteration 54/1000 | Loss: 0.00002567
Iteration 55/1000 | Loss: 0.00002092
Iteration 56/1000 | Loss: 0.00001864
Iteration 57/1000 | Loss: 0.00001752
Iteration 58/1000 | Loss: 0.00001701
Iteration 59/1000 | Loss: 0.00001658
Iteration 60/1000 | Loss: 0.00001627
Iteration 61/1000 | Loss: 0.00001607
Iteration 62/1000 | Loss: 0.00001605
Iteration 63/1000 | Loss: 0.00001602
Iteration 64/1000 | Loss: 0.00001602
Iteration 65/1000 | Loss: 0.00001601
Iteration 66/1000 | Loss: 0.00001600
Iteration 67/1000 | Loss: 0.00001600
Iteration 68/1000 | Loss: 0.00001600
Iteration 69/1000 | Loss: 0.00001599
Iteration 70/1000 | Loss: 0.00001599
Iteration 71/1000 | Loss: 0.00001598
Iteration 72/1000 | Loss: 0.00001598
Iteration 73/1000 | Loss: 0.00001598
Iteration 74/1000 | Loss: 0.00001598
Iteration 75/1000 | Loss: 0.00001597
Iteration 76/1000 | Loss: 0.00001597
Iteration 77/1000 | Loss: 0.00001597
Iteration 78/1000 | Loss: 0.00001597
Iteration 79/1000 | Loss: 0.00001597
Iteration 80/1000 | Loss: 0.00001596
Iteration 81/1000 | Loss: 0.00001596
Iteration 82/1000 | Loss: 0.00001595
Iteration 83/1000 | Loss: 0.00001595
Iteration 84/1000 | Loss: 0.00001595
Iteration 85/1000 | Loss: 0.00001594
Iteration 86/1000 | Loss: 0.00001594
Iteration 87/1000 | Loss: 0.00001594
Iteration 88/1000 | Loss: 0.00001593
Iteration 89/1000 | Loss: 0.00001593
Iteration 90/1000 | Loss: 0.00001591
Iteration 91/1000 | Loss: 0.00001590
Iteration 92/1000 | Loss: 0.00001589
Iteration 93/1000 | Loss: 0.00001588
Iteration 94/1000 | Loss: 0.00001588
Iteration 95/1000 | Loss: 0.00001588
Iteration 96/1000 | Loss: 0.00001588
Iteration 97/1000 | Loss: 0.00001588
Iteration 98/1000 | Loss: 0.00001588
Iteration 99/1000 | Loss: 0.00001588
Iteration 100/1000 | Loss: 0.00001588
Iteration 101/1000 | Loss: 0.00001587
Iteration 102/1000 | Loss: 0.00001587
Iteration 103/1000 | Loss: 0.00001587
Iteration 104/1000 | Loss: 0.00001587
Iteration 105/1000 | Loss: 0.00001587
Iteration 106/1000 | Loss: 0.00001587
Iteration 107/1000 | Loss: 0.00001584
Iteration 108/1000 | Loss: 0.00001581
Iteration 109/1000 | Loss: 0.00001580
Iteration 110/1000 | Loss: 0.00001579
Iteration 111/1000 | Loss: 0.00001579
Iteration 112/1000 | Loss: 0.00001578
Iteration 113/1000 | Loss: 0.00001578
Iteration 114/1000 | Loss: 0.00001578
Iteration 115/1000 | Loss: 0.00001578
Iteration 116/1000 | Loss: 0.00001578
Iteration 117/1000 | Loss: 0.00001577
Iteration 118/1000 | Loss: 0.00001577
Iteration 119/1000 | Loss: 0.00001577
Iteration 120/1000 | Loss: 0.00001576
Iteration 121/1000 | Loss: 0.00001576
Iteration 122/1000 | Loss: 0.00001576
Iteration 123/1000 | Loss: 0.00001576
Iteration 124/1000 | Loss: 0.00001576
Iteration 125/1000 | Loss: 0.00001575
Iteration 126/1000 | Loss: 0.00001575
Iteration 127/1000 | Loss: 0.00001575
Iteration 128/1000 | Loss: 0.00001574
Iteration 129/1000 | Loss: 0.00001574
Iteration 130/1000 | Loss: 0.00001574
Iteration 131/1000 | Loss: 0.00001574
Iteration 132/1000 | Loss: 0.00001574
Iteration 133/1000 | Loss: 0.00001574
Iteration 134/1000 | Loss: 0.00001574
Iteration 135/1000 | Loss: 0.00001573
Iteration 136/1000 | Loss: 0.00001573
Iteration 137/1000 | Loss: 0.00001573
Iteration 138/1000 | Loss: 0.00001572
Iteration 139/1000 | Loss: 0.00001572
Iteration 140/1000 | Loss: 0.00001572
Iteration 141/1000 | Loss: 0.00001571
Iteration 142/1000 | Loss: 0.00001571
Iteration 143/1000 | Loss: 0.00001571
Iteration 144/1000 | Loss: 0.00001571
Iteration 145/1000 | Loss: 0.00001571
Iteration 146/1000 | Loss: 0.00001570
Iteration 147/1000 | Loss: 0.00001570
Iteration 148/1000 | Loss: 0.00001570
Iteration 149/1000 | Loss: 0.00001570
Iteration 150/1000 | Loss: 0.00001570
Iteration 151/1000 | Loss: 0.00001569
Iteration 152/1000 | Loss: 0.00001569
Iteration 153/1000 | Loss: 0.00001569
Iteration 154/1000 | Loss: 0.00001569
Iteration 155/1000 | Loss: 0.00001569
Iteration 156/1000 | Loss: 0.00001569
Iteration 157/1000 | Loss: 0.00001569
Iteration 158/1000 | Loss: 0.00001569
Iteration 159/1000 | Loss: 0.00001568
Iteration 160/1000 | Loss: 0.00001568
Iteration 161/1000 | Loss: 0.00001568
Iteration 162/1000 | Loss: 0.00001568
Iteration 163/1000 | Loss: 0.00001567
Iteration 164/1000 | Loss: 0.00001567
Iteration 165/1000 | Loss: 0.00001567
Iteration 166/1000 | Loss: 0.00001567
Iteration 167/1000 | Loss: 0.00001567
Iteration 168/1000 | Loss: 0.00001567
Iteration 169/1000 | Loss: 0.00001567
Iteration 170/1000 | Loss: 0.00001567
Iteration 171/1000 | Loss: 0.00001567
Iteration 172/1000 | Loss: 0.00001567
Iteration 173/1000 | Loss: 0.00001566
Iteration 174/1000 | Loss: 0.00001566
Iteration 175/1000 | Loss: 0.00001566
Iteration 176/1000 | Loss: 0.00001566
Iteration 177/1000 | Loss: 0.00001566
Iteration 178/1000 | Loss: 0.00001566
Iteration 179/1000 | Loss: 0.00001566
Iteration 180/1000 | Loss: 0.00001566
Iteration 181/1000 | Loss: 0.00001566
Iteration 182/1000 | Loss: 0.00001566
Iteration 183/1000 | Loss: 0.00001565
Iteration 184/1000 | Loss: 0.00001565
Iteration 185/1000 | Loss: 0.00001565
Iteration 186/1000 | Loss: 0.00001565
Iteration 187/1000 | Loss: 0.00001565
Iteration 188/1000 | Loss: 0.00001565
Iteration 189/1000 | Loss: 0.00001565
Iteration 190/1000 | Loss: 0.00001565
Iteration 191/1000 | Loss: 0.00001565
Iteration 192/1000 | Loss: 0.00001565
Iteration 193/1000 | Loss: 0.00001565
Iteration 194/1000 | Loss: 0.00001565
Iteration 195/1000 | Loss: 0.00001565
Iteration 196/1000 | Loss: 0.00001565
Iteration 197/1000 | Loss: 0.00001565
Iteration 198/1000 | Loss: 0.00001565
Iteration 199/1000 | Loss: 0.00001565
Iteration 200/1000 | Loss: 0.00001564
Iteration 201/1000 | Loss: 0.00001564
Iteration 202/1000 | Loss: 0.00001564
Iteration 203/1000 | Loss: 0.00001564
Iteration 204/1000 | Loss: 0.00001564
Iteration 205/1000 | Loss: 0.00001564
Iteration 206/1000 | Loss: 0.00001564
Iteration 207/1000 | Loss: 0.00001564
Iteration 208/1000 | Loss: 0.00001564
Iteration 209/1000 | Loss: 0.00001564
Iteration 210/1000 | Loss: 0.00001564
Iteration 211/1000 | Loss: 0.00001564
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 211. Stopping optimization.
Last 5 losses: [1.564247031637933e-05, 1.564247031637933e-05, 1.564247031637933e-05, 1.564247031637933e-05, 1.564247031637933e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.564247031637933e-05

Optimization complete. Final v2v error: 3.3236169815063477 mm

Highest mean error: 4.822851181030273 mm for frame 100

Lowest mean error: 2.744396924972534 mm for frame 58

Saving results

Total time: 135.25152134895325
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00653019
Iteration 2/25 | Loss: 0.00147483
Iteration 3/25 | Loss: 0.00121652
Iteration 4/25 | Loss: 0.00113220
Iteration 5/25 | Loss: 0.00115158
Iteration 6/25 | Loss: 0.00114310
Iteration 7/25 | Loss: 0.00108009
Iteration 8/25 | Loss: 0.00104132
Iteration 9/25 | Loss: 0.00102626
Iteration 10/25 | Loss: 0.00102315
Iteration 11/25 | Loss: 0.00102228
Iteration 12/25 | Loss: 0.00102210
Iteration 13/25 | Loss: 0.00102206
Iteration 14/25 | Loss: 0.00102206
Iteration 15/25 | Loss: 0.00102205
Iteration 16/25 | Loss: 0.00102205
Iteration 17/25 | Loss: 0.00102205
Iteration 18/25 | Loss: 0.00102205
Iteration 19/25 | Loss: 0.00102205
Iteration 20/25 | Loss: 0.00102205
Iteration 21/25 | Loss: 0.00102205
Iteration 22/25 | Loss: 0.00102204
Iteration 23/25 | Loss: 0.00102204
Iteration 24/25 | Loss: 0.00102204
Iteration 25/25 | Loss: 0.00102204

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.36268926
Iteration 2/25 | Loss: 0.00070337
Iteration 3/25 | Loss: 0.00070326
Iteration 4/25 | Loss: 0.00070326
Iteration 5/25 | Loss: 0.00070326
Iteration 6/25 | Loss: 0.00070326
Iteration 7/25 | Loss: 0.00070326
Iteration 8/25 | Loss: 0.00070326
Iteration 9/25 | Loss: 0.00070326
Iteration 10/25 | Loss: 0.00070326
Iteration 11/25 | Loss: 0.00070326
Iteration 12/25 | Loss: 0.00070326
Iteration 13/25 | Loss: 0.00070326
Iteration 14/25 | Loss: 0.00070326
Iteration 15/25 | Loss: 0.00070326
Iteration 16/25 | Loss: 0.00070326
Iteration 17/25 | Loss: 0.00070326
Iteration 18/25 | Loss: 0.00070326
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 18. Stopping optimization.
Last 5 losses: [0.0007032568100839853, 0.0007032568100839853, 0.0007032568100839853, 0.0007032568100839853, 0.0007032568100839853]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007032568100839853

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00070326
Iteration 2/1000 | Loss: 0.00007675
Iteration 3/1000 | Loss: 0.00005193
Iteration 4/1000 | Loss: 0.00004347
Iteration 5/1000 | Loss: 0.00004066
Iteration 6/1000 | Loss: 0.00003881
Iteration 7/1000 | Loss: 0.00003674
Iteration 8/1000 | Loss: 0.00003595
Iteration 9/1000 | Loss: 0.00003518
Iteration 10/1000 | Loss: 0.00003463
Iteration 11/1000 | Loss: 0.00003415
Iteration 12/1000 | Loss: 0.00003380
Iteration 13/1000 | Loss: 0.00003342
Iteration 14/1000 | Loss: 0.00003315
Iteration 15/1000 | Loss: 0.00003287
Iteration 16/1000 | Loss: 0.00038271
Iteration 17/1000 | Loss: 0.00004362
Iteration 18/1000 | Loss: 0.00003890
Iteration 19/1000 | Loss: 0.00003758
Iteration 20/1000 | Loss: 0.00003535
Iteration 21/1000 | Loss: 0.00003418
Iteration 22/1000 | Loss: 0.00004243
Iteration 23/1000 | Loss: 0.00003348
Iteration 24/1000 | Loss: 0.00003293
Iteration 25/1000 | Loss: 0.00003249
Iteration 26/1000 | Loss: 0.00003226
Iteration 27/1000 | Loss: 0.00003202
Iteration 28/1000 | Loss: 0.00003162
Iteration 29/1000 | Loss: 0.00003135
Iteration 30/1000 | Loss: 0.00003129
Iteration 31/1000 | Loss: 0.00003126
Iteration 32/1000 | Loss: 0.00003125
Iteration 33/1000 | Loss: 0.00003125
Iteration 34/1000 | Loss: 0.00003124
Iteration 35/1000 | Loss: 0.00003123
Iteration 36/1000 | Loss: 0.00003122
Iteration 37/1000 | Loss: 0.00003122
Iteration 38/1000 | Loss: 0.00003122
Iteration 39/1000 | Loss: 0.00003120
Iteration 40/1000 | Loss: 0.00003119
Iteration 41/1000 | Loss: 0.00003119
Iteration 42/1000 | Loss: 0.00003118
Iteration 43/1000 | Loss: 0.00003117
Iteration 44/1000 | Loss: 0.00003116
Iteration 45/1000 | Loss: 0.00003116
Iteration 46/1000 | Loss: 0.00003116
Iteration 47/1000 | Loss: 0.00003115
Iteration 48/1000 | Loss: 0.00003115
Iteration 49/1000 | Loss: 0.00003114
Iteration 50/1000 | Loss: 0.00003113
Iteration 51/1000 | Loss: 0.00003113
Iteration 52/1000 | Loss: 0.00003113
Iteration 53/1000 | Loss: 0.00003113
Iteration 54/1000 | Loss: 0.00003113
Iteration 55/1000 | Loss: 0.00003112
Iteration 56/1000 | Loss: 0.00003111
Iteration 57/1000 | Loss: 0.00003111
Iteration 58/1000 | Loss: 0.00003110
Iteration 59/1000 | Loss: 0.00003110
Iteration 60/1000 | Loss: 0.00003110
Iteration 61/1000 | Loss: 0.00003109
Iteration 62/1000 | Loss: 0.00003109
Iteration 63/1000 | Loss: 0.00003109
Iteration 64/1000 | Loss: 0.00003109
Iteration 65/1000 | Loss: 0.00003108
Iteration 66/1000 | Loss: 0.00003108
Iteration 67/1000 | Loss: 0.00003108
Iteration 68/1000 | Loss: 0.00003108
Iteration 69/1000 | Loss: 0.00003107
Iteration 70/1000 | Loss: 0.00003107
Iteration 71/1000 | Loss: 0.00003107
Iteration 72/1000 | Loss: 0.00003107
Iteration 73/1000 | Loss: 0.00003107
Iteration 74/1000 | Loss: 0.00003106
Iteration 75/1000 | Loss: 0.00003106
Iteration 76/1000 | Loss: 0.00003106
Iteration 77/1000 | Loss: 0.00003106
Iteration 78/1000 | Loss: 0.00003106
Iteration 79/1000 | Loss: 0.00003105
Iteration 80/1000 | Loss: 0.00003105
Iteration 81/1000 | Loss: 0.00003105
Iteration 82/1000 | Loss: 0.00003105
Iteration 83/1000 | Loss: 0.00003105
Iteration 84/1000 | Loss: 0.00003104
Iteration 85/1000 | Loss: 0.00003104
Iteration 86/1000 | Loss: 0.00003104
Iteration 87/1000 | Loss: 0.00003104
Iteration 88/1000 | Loss: 0.00003104
Iteration 89/1000 | Loss: 0.00003103
Iteration 90/1000 | Loss: 0.00003103
Iteration 91/1000 | Loss: 0.00003103
Iteration 92/1000 | Loss: 0.00003103
Iteration 93/1000 | Loss: 0.00003102
Iteration 94/1000 | Loss: 0.00003102
Iteration 95/1000 | Loss: 0.00003102
Iteration 96/1000 | Loss: 0.00003102
Iteration 97/1000 | Loss: 0.00003102
Iteration 98/1000 | Loss: 0.00003102
Iteration 99/1000 | Loss: 0.00003102
Iteration 100/1000 | Loss: 0.00003102
Iteration 101/1000 | Loss: 0.00003102
Iteration 102/1000 | Loss: 0.00003102
Iteration 103/1000 | Loss: 0.00003102
Iteration 104/1000 | Loss: 0.00003102
Iteration 105/1000 | Loss: 0.00003102
Iteration 106/1000 | Loss: 0.00003101
Iteration 107/1000 | Loss: 0.00003101
Iteration 108/1000 | Loss: 0.00003101
Iteration 109/1000 | Loss: 0.00003101
Iteration 110/1000 | Loss: 0.00003101
Iteration 111/1000 | Loss: 0.00003101
Iteration 112/1000 | Loss: 0.00003101
Iteration 113/1000 | Loss: 0.00003100
Iteration 114/1000 | Loss: 0.00003100
Iteration 115/1000 | Loss: 0.00003100
Iteration 116/1000 | Loss: 0.00003100
Iteration 117/1000 | Loss: 0.00003100
Iteration 118/1000 | Loss: 0.00003100
Iteration 119/1000 | Loss: 0.00003100
Iteration 120/1000 | Loss: 0.00003100
Iteration 121/1000 | Loss: 0.00003100
Iteration 122/1000 | Loss: 0.00003100
Iteration 123/1000 | Loss: 0.00003100
Iteration 124/1000 | Loss: 0.00003099
Iteration 125/1000 | Loss: 0.00003099
Iteration 126/1000 | Loss: 0.00003099
Iteration 127/1000 | Loss: 0.00003099
Iteration 128/1000 | Loss: 0.00003099
Iteration 129/1000 | Loss: 0.00003099
Iteration 130/1000 | Loss: 0.00003098
Iteration 131/1000 | Loss: 0.00003098
Iteration 132/1000 | Loss: 0.00003098
Iteration 133/1000 | Loss: 0.00003098
Iteration 134/1000 | Loss: 0.00003098
Iteration 135/1000 | Loss: 0.00003098
Iteration 136/1000 | Loss: 0.00003098
Iteration 137/1000 | Loss: 0.00003098
Iteration 138/1000 | Loss: 0.00003098
Iteration 139/1000 | Loss: 0.00003098
Iteration 140/1000 | Loss: 0.00003098
Iteration 141/1000 | Loss: 0.00003098
Iteration 142/1000 | Loss: 0.00003098
Iteration 143/1000 | Loss: 0.00003098
Iteration 144/1000 | Loss: 0.00003098
Iteration 145/1000 | Loss: 0.00003098
Iteration 146/1000 | Loss: 0.00003098
Iteration 147/1000 | Loss: 0.00003098
Iteration 148/1000 | Loss: 0.00003098
Iteration 149/1000 | Loss: 0.00003098
Iteration 150/1000 | Loss: 0.00003098
Iteration 151/1000 | Loss: 0.00003098
Iteration 152/1000 | Loss: 0.00003098
Iteration 153/1000 | Loss: 0.00003098
Iteration 154/1000 | Loss: 0.00003098
Iteration 155/1000 | Loss: 0.00003098
Iteration 156/1000 | Loss: 0.00003098
Iteration 157/1000 | Loss: 0.00003098
Iteration 158/1000 | Loss: 0.00003098
Iteration 159/1000 | Loss: 0.00003098
Iteration 160/1000 | Loss: 0.00003098
Iteration 161/1000 | Loss: 0.00003098
Iteration 162/1000 | Loss: 0.00003098
Iteration 163/1000 | Loss: 0.00003098
Iteration 164/1000 | Loss: 0.00003098
Iteration 165/1000 | Loss: 0.00003098
Iteration 166/1000 | Loss: 0.00003098
Iteration 167/1000 | Loss: 0.00003098
Iteration 168/1000 | Loss: 0.00003098
Iteration 169/1000 | Loss: 0.00003098
Iteration 170/1000 | Loss: 0.00003098
Iteration 171/1000 | Loss: 0.00003098
Iteration 172/1000 | Loss: 0.00003098
Iteration 173/1000 | Loss: 0.00003098
Iteration 174/1000 | Loss: 0.00003098
Iteration 175/1000 | Loss: 0.00003098
Iteration 176/1000 | Loss: 0.00003098
Iteration 177/1000 | Loss: 0.00003098
Iteration 178/1000 | Loss: 0.00003098
Iteration 179/1000 | Loss: 0.00003098
Iteration 180/1000 | Loss: 0.00003098
Iteration 181/1000 | Loss: 0.00003098
Iteration 182/1000 | Loss: 0.00003098
Iteration 183/1000 | Loss: 0.00003098
Iteration 184/1000 | Loss: 0.00003098
Iteration 185/1000 | Loss: 0.00003098
Iteration 186/1000 | Loss: 0.00003098
Iteration 187/1000 | Loss: 0.00003098
Iteration 188/1000 | Loss: 0.00003098
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 188. Stopping optimization.
Last 5 losses: [3.0977742426330224e-05, 3.0977742426330224e-05, 3.0977742426330224e-05, 3.0977742426330224e-05, 3.0977742426330224e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.0977742426330224e-05

Optimization complete. Final v2v error: 4.512518405914307 mm

Highest mean error: 6.11088228225708 mm for frame 138

Lowest mean error: 3.4579110145568848 mm for frame 0

Saving results

Total time: 72.49335312843323
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_34_us_1371/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_34_us_1371/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01125170
Iteration 2/25 | Loss: 0.01125170
Iteration 3/25 | Loss: 0.00340903
Iteration 4/25 | Loss: 0.00171730
Iteration 5/25 | Loss: 0.00162087
Iteration 6/25 | Loss: 0.00148786
Iteration 7/25 | Loss: 0.00138610
Iteration 8/25 | Loss: 0.00133319
Iteration 9/25 | Loss: 0.00127981
Iteration 10/25 | Loss: 0.00124498
Iteration 11/25 | Loss: 0.00122891
Iteration 12/25 | Loss: 0.00121590
Iteration 13/25 | Loss: 0.00121580
Iteration 14/25 | Loss: 0.00120377
Iteration 15/25 | Loss: 0.00120235
Iteration 16/25 | Loss: 0.00118816
Iteration 17/25 | Loss: 0.00117667
Iteration 18/25 | Loss: 0.00117310
Iteration 19/25 | Loss: 0.00116898
Iteration 20/25 | Loss: 0.00116671
Iteration 21/25 | Loss: 0.00116191
Iteration 22/25 | Loss: 0.00115980
Iteration 23/25 | Loss: 0.00115851
Iteration 24/25 | Loss: 0.00115798
Iteration 25/25 | Loss: 0.00115766

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.41213036
Iteration 2/25 | Loss: 0.00479568
Iteration 3/25 | Loss: 0.00346149
Iteration 4/25 | Loss: 0.00346149
Iteration 5/25 | Loss: 0.00346149
Iteration 6/25 | Loss: 0.00346149
Iteration 7/25 | Loss: 0.00346149
Iteration 8/25 | Loss: 0.00346149
Iteration 9/25 | Loss: 0.00346149
Iteration 10/25 | Loss: 0.00346149
Iteration 11/25 | Loss: 0.00346149
Iteration 12/25 | Loss: 0.00346149
Iteration 13/25 | Loss: 0.00346149
Iteration 14/25 | Loss: 0.00346149
Iteration 15/25 | Loss: 0.00346149
Iteration 16/25 | Loss: 0.00346149
Iteration 17/25 | Loss: 0.00346149
Iteration 18/25 | Loss: 0.00346149
Iteration 19/25 | Loss: 0.00346149
Iteration 20/25 | Loss: 0.00346149
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.0034614908508956432, 0.0034614908508956432, 0.0034614908508956432, 0.0034614908508956432, 0.0034614908508956432]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0034614908508956432

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00346149
Iteration 2/1000 | Loss: 0.00143551
Iteration 3/1000 | Loss: 0.00161518
Iteration 4/1000 | Loss: 0.00188877
Iteration 5/1000 | Loss: 0.00333566
Iteration 6/1000 | Loss: 0.00191825
Iteration 7/1000 | Loss: 0.00064591
Iteration 8/1000 | Loss: 0.00125539
Iteration 9/1000 | Loss: 0.00072482
Iteration 10/1000 | Loss: 0.00898351
Iteration 11/1000 | Loss: 0.00353698
Iteration 12/1000 | Loss: 0.00153693
Iteration 13/1000 | Loss: 0.00399266
Iteration 14/1000 | Loss: 0.00085968
Iteration 15/1000 | Loss: 0.01553016
Iteration 16/1000 | Loss: 0.00270715
Iteration 17/1000 | Loss: 0.00096545
Iteration 18/1000 | Loss: 0.00069896
Iteration 19/1000 | Loss: 0.01052082
Iteration 20/1000 | Loss: 0.00267320
Iteration 21/1000 | Loss: 0.00209667
Iteration 22/1000 | Loss: 0.00134515
Iteration 23/1000 | Loss: 0.00350648
Iteration 24/1000 | Loss: 0.00047030
Iteration 25/1000 | Loss: 0.00363509
Iteration 26/1000 | Loss: 0.00075504
Iteration 27/1000 | Loss: 0.00314005
Iteration 28/1000 | Loss: 0.00488654
Iteration 29/1000 | Loss: 0.00326348
Iteration 30/1000 | Loss: 0.00182700
Iteration 31/1000 | Loss: 0.00173740
Iteration 32/1000 | Loss: 0.00099031
Iteration 33/1000 | Loss: 0.00211557
Iteration 34/1000 | Loss: 0.00102111
Iteration 35/1000 | Loss: 0.00037557
Iteration 36/1000 | Loss: 0.00048327
Iteration 37/1000 | Loss: 0.00317665
Iteration 38/1000 | Loss: 0.00182441
Iteration 39/1000 | Loss: 0.00106096
Iteration 40/1000 | Loss: 0.00124445
Iteration 41/1000 | Loss: 0.00108367
Iteration 42/1000 | Loss: 0.00261419
Iteration 43/1000 | Loss: 0.00243805
Iteration 44/1000 | Loss: 0.00223826
Iteration 45/1000 | Loss: 0.00152918
Iteration 46/1000 | Loss: 0.00061081
Iteration 47/1000 | Loss: 0.00038450
Iteration 48/1000 | Loss: 0.00234594
Iteration 49/1000 | Loss: 0.00075203
Iteration 50/1000 | Loss: 0.00140598
Iteration 51/1000 | Loss: 0.00166391
Iteration 52/1000 | Loss: 0.00237727
Iteration 53/1000 | Loss: 0.00089858
Iteration 54/1000 | Loss: 0.00221178
Iteration 55/1000 | Loss: 0.00119836
Iteration 56/1000 | Loss: 0.00128220
Iteration 57/1000 | Loss: 0.00221751
Iteration 58/1000 | Loss: 0.00147810
Iteration 59/1000 | Loss: 0.00090999
Iteration 60/1000 | Loss: 0.00131099
Iteration 61/1000 | Loss: 0.00112143
Iteration 62/1000 | Loss: 0.00059891
Iteration 63/1000 | Loss: 0.00028744
Iteration 64/1000 | Loss: 0.00094893
Iteration 65/1000 | Loss: 0.00045747
Iteration 66/1000 | Loss: 0.00019348
Iteration 67/1000 | Loss: 0.00015710
Iteration 68/1000 | Loss: 0.00036693
Iteration 69/1000 | Loss: 0.00118567
Iteration 70/1000 | Loss: 0.00323165
Iteration 71/1000 | Loss: 0.00148972
Iteration 72/1000 | Loss: 0.00092262
Iteration 73/1000 | Loss: 0.00091060
Iteration 74/1000 | Loss: 0.00037970
Iteration 75/1000 | Loss: 0.00036239
Iteration 76/1000 | Loss: 0.00039307
Iteration 77/1000 | Loss: 0.00018715
Iteration 78/1000 | Loss: 0.00200503
Iteration 79/1000 | Loss: 0.00142110
Iteration 80/1000 | Loss: 0.00029922
Iteration 81/1000 | Loss: 0.00041816
Iteration 82/1000 | Loss: 0.00033329
Iteration 83/1000 | Loss: 0.00043122
Iteration 84/1000 | Loss: 0.00021583
Iteration 85/1000 | Loss: 0.00180649
Iteration 86/1000 | Loss: 0.00017076
Iteration 87/1000 | Loss: 0.00076754
Iteration 88/1000 | Loss: 0.00082838
Iteration 89/1000 | Loss: 0.00070797
Iteration 90/1000 | Loss: 0.00028242
Iteration 91/1000 | Loss: 0.00012630
Iteration 92/1000 | Loss: 0.00113157
Iteration 93/1000 | Loss: 0.00016423
Iteration 94/1000 | Loss: 0.00029008
Iteration 95/1000 | Loss: 0.00017780
Iteration 96/1000 | Loss: 0.00031953
Iteration 97/1000 | Loss: 0.00011270
Iteration 98/1000 | Loss: 0.00079811
Iteration 99/1000 | Loss: 0.00077547
Iteration 100/1000 | Loss: 0.00010665
Iteration 101/1000 | Loss: 0.00015738
Iteration 102/1000 | Loss: 0.00011352
Iteration 103/1000 | Loss: 0.00012693
Iteration 104/1000 | Loss: 0.00008176
Iteration 105/1000 | Loss: 0.00012003
Iteration 106/1000 | Loss: 0.00007377
Iteration 107/1000 | Loss: 0.00076099
Iteration 108/1000 | Loss: 0.00028328
Iteration 109/1000 | Loss: 0.00035054
Iteration 110/1000 | Loss: 0.00015338
Iteration 111/1000 | Loss: 0.00027906
Iteration 112/1000 | Loss: 0.00014867
Iteration 113/1000 | Loss: 0.00007653
Iteration 114/1000 | Loss: 0.00014576
Iteration 115/1000 | Loss: 0.00120839
Iteration 116/1000 | Loss: 0.00189140
Iteration 117/1000 | Loss: 0.00110053
Iteration 118/1000 | Loss: 0.00010627
Iteration 119/1000 | Loss: 0.00014320
Iteration 120/1000 | Loss: 0.00014603
Iteration 121/1000 | Loss: 0.00007253
Iteration 122/1000 | Loss: 0.00024267
Iteration 123/1000 | Loss: 0.00007903
Iteration 124/1000 | Loss: 0.00053416
Iteration 125/1000 | Loss: 0.00006897
Iteration 126/1000 | Loss: 0.00007864
Iteration 127/1000 | Loss: 0.00041117
Iteration 128/1000 | Loss: 0.00038026
Iteration 129/1000 | Loss: 0.00007701
Iteration 130/1000 | Loss: 0.00008070
Iteration 131/1000 | Loss: 0.00005934
Iteration 132/1000 | Loss: 0.00075898
Iteration 133/1000 | Loss: 0.00007671
Iteration 134/1000 | Loss: 0.00012135
Iteration 135/1000 | Loss: 0.00006064
Iteration 136/1000 | Loss: 0.00005998
Iteration 137/1000 | Loss: 0.00005690
Iteration 138/1000 | Loss: 0.00008078
Iteration 139/1000 | Loss: 0.00005554
Iteration 140/1000 | Loss: 0.00005812
Iteration 141/1000 | Loss: 0.00005451
Iteration 142/1000 | Loss: 0.00022303
Iteration 143/1000 | Loss: 0.00005636
Iteration 144/1000 | Loss: 0.00005302
Iteration 145/1000 | Loss: 0.00005251
Iteration 146/1000 | Loss: 0.00005214
Iteration 147/1000 | Loss: 0.00006883
Iteration 148/1000 | Loss: 0.00005724
Iteration 149/1000 | Loss: 0.00005196
Iteration 150/1000 | Loss: 0.00005168
Iteration 151/1000 | Loss: 0.00005168
Iteration 152/1000 | Loss: 0.00005158
Iteration 153/1000 | Loss: 0.00005153
Iteration 154/1000 | Loss: 0.00005153
Iteration 155/1000 | Loss: 0.00005153
Iteration 156/1000 | Loss: 0.00005152
Iteration 157/1000 | Loss: 0.00005152
Iteration 158/1000 | Loss: 0.00005152
Iteration 159/1000 | Loss: 0.00005151
Iteration 160/1000 | Loss: 0.00005151
Iteration 161/1000 | Loss: 0.00005382
Iteration 162/1000 | Loss: 0.00005145
Iteration 163/1000 | Loss: 0.00005145
Iteration 164/1000 | Loss: 0.00005145
Iteration 165/1000 | Loss: 0.00005145
Iteration 166/1000 | Loss: 0.00005145
Iteration 167/1000 | Loss: 0.00005145
Iteration 168/1000 | Loss: 0.00005145
Iteration 169/1000 | Loss: 0.00005144
Iteration 170/1000 | Loss: 0.00005144
Iteration 171/1000 | Loss: 0.00005144
Iteration 172/1000 | Loss: 0.00005144
Iteration 173/1000 | Loss: 0.00005144
Iteration 174/1000 | Loss: 0.00005144
Iteration 175/1000 | Loss: 0.00005144
Iteration 176/1000 | Loss: 0.00005143
Iteration 177/1000 | Loss: 0.00005143
Iteration 178/1000 | Loss: 0.00005296
Iteration 179/1000 | Loss: 0.00005141
Iteration 180/1000 | Loss: 0.00005141
Iteration 181/1000 | Loss: 0.00005141
Iteration 182/1000 | Loss: 0.00005140
Iteration 183/1000 | Loss: 0.00005140
Iteration 184/1000 | Loss: 0.00005140
Iteration 185/1000 | Loss: 0.00005140
Iteration 186/1000 | Loss: 0.00005140
Iteration 187/1000 | Loss: 0.00005140
Iteration 188/1000 | Loss: 0.00005140
Iteration 189/1000 | Loss: 0.00005140
Iteration 190/1000 | Loss: 0.00005140
Iteration 191/1000 | Loss: 0.00005140
Iteration 192/1000 | Loss: 0.00005140
Iteration 193/1000 | Loss: 0.00005892
Iteration 194/1000 | Loss: 0.00005178
Iteration 195/1000 | Loss: 0.00005140
Iteration 196/1000 | Loss: 0.00005140
Iteration 197/1000 | Loss: 0.00005140
Iteration 198/1000 | Loss: 0.00005140
Iteration 199/1000 | Loss: 0.00005140
Iteration 200/1000 | Loss: 0.00005139
Iteration 201/1000 | Loss: 0.00005139
Iteration 202/1000 | Loss: 0.00005139
Iteration 203/1000 | Loss: 0.00005139
Iteration 204/1000 | Loss: 0.00005139
Iteration 205/1000 | Loss: 0.00005139
Iteration 206/1000 | Loss: 0.00005139
Iteration 207/1000 | Loss: 0.00005139
Iteration 208/1000 | Loss: 0.00005139
Iteration 209/1000 | Loss: 0.00005139
Iteration 210/1000 | Loss: 0.00005139
Iteration 211/1000 | Loss: 0.00005138
Iteration 212/1000 | Loss: 0.00005138
Iteration 213/1000 | Loss: 0.00005138
Iteration 214/1000 | Loss: 0.00005137
Iteration 215/1000 | Loss: 0.00005137
Iteration 216/1000 | Loss: 0.00005137
Iteration 217/1000 | Loss: 0.00005137
Iteration 218/1000 | Loss: 0.00005137
Iteration 219/1000 | Loss: 0.00005136
Iteration 220/1000 | Loss: 0.00005136
Iteration 221/1000 | Loss: 0.00005136
Iteration 222/1000 | Loss: 0.00005525
Iteration 223/1000 | Loss: 0.00005525
Iteration 224/1000 | Loss: 0.00005159
Iteration 225/1000 | Loss: 0.00007715
Iteration 226/1000 | Loss: 0.00005327
Iteration 227/1000 | Loss: 0.00005131
Iteration 228/1000 | Loss: 0.00005131
Iteration 229/1000 | Loss: 0.00005131
Iteration 230/1000 | Loss: 0.00005131
Iteration 231/1000 | Loss: 0.00005131
Iteration 232/1000 | Loss: 0.00005131
Iteration 233/1000 | Loss: 0.00005130
Iteration 234/1000 | Loss: 0.00005130
Iteration 235/1000 | Loss: 0.00005130
Iteration 236/1000 | Loss: 0.00005130
Iteration 237/1000 | Loss: 0.00005130
Iteration 238/1000 | Loss: 0.00005130
Iteration 239/1000 | Loss: 0.00005129
Iteration 240/1000 | Loss: 0.00005129
Iteration 241/1000 | Loss: 0.00005129
Iteration 242/1000 | Loss: 0.00005129
Iteration 243/1000 | Loss: 0.00005129
Iteration 244/1000 | Loss: 0.00005129
Iteration 245/1000 | Loss: 0.00005129
Iteration 246/1000 | Loss: 0.00005129
Iteration 247/1000 | Loss: 0.00005129
Iteration 248/1000 | Loss: 0.00005129
Iteration 249/1000 | Loss: 0.00005129
Iteration 250/1000 | Loss: 0.00005129
Iteration 251/1000 | Loss: 0.00005129
Iteration 252/1000 | Loss: 0.00005129
Iteration 253/1000 | Loss: 0.00005129
Iteration 254/1000 | Loss: 0.00005129
Iteration 255/1000 | Loss: 0.00005129
Iteration 256/1000 | Loss: 0.00005129
Iteration 257/1000 | Loss: 0.00005129
Iteration 258/1000 | Loss: 0.00005129
Iteration 259/1000 | Loss: 0.00005129
Iteration 260/1000 | Loss: 0.00005129
Iteration 261/1000 | Loss: 0.00005129
Iteration 262/1000 | Loss: 0.00005129
Iteration 263/1000 | Loss: 0.00005129
Iteration 264/1000 | Loss: 0.00005129
Iteration 265/1000 | Loss: 0.00005129
Iteration 266/1000 | Loss: 0.00005129
Iteration 267/1000 | Loss: 0.00005129
Iteration 268/1000 | Loss: 0.00005129
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 268. Stopping optimization.
Last 5 losses: [5.1292598072905093e-05, 5.1292598072905093e-05, 5.1292598072905093e-05, 5.1292598072905093e-05, 5.1292598072905093e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 5.1292598072905093e-05

Optimization complete. Final v2v error: 4.5629706382751465 mm

Highest mean error: 21.471981048583984 mm for frame 177

Lowest mean error: 3.4198672771453857 mm for frame 73

Saving results

Total time: 301.24050855636597
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0008/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0008.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0008
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00401892
Iteration 2/25 | Loss: 0.00096301
Iteration 3/25 | Loss: 0.00077476
Iteration 4/25 | Loss: 0.00075386
Iteration 5/25 | Loss: 0.00074611
Iteration 6/25 | Loss: 0.00074422
Iteration 7/25 | Loss: 0.00074379
Iteration 8/25 | Loss: 0.00074379
Iteration 9/25 | Loss: 0.00074379
Iteration 10/25 | Loss: 0.00074379
Iteration 11/25 | Loss: 0.00074379
Iteration 12/25 | Loss: 0.00074379
Iteration 13/25 | Loss: 0.00074379
Iteration 14/25 | Loss: 0.00074379
Iteration 15/25 | Loss: 0.00074379
Iteration 16/25 | Loss: 0.00074379
Iteration 17/25 | Loss: 0.00074379
Iteration 18/25 | Loss: 0.00074379
Iteration 19/25 | Loss: 0.00074379
Iteration 20/25 | Loss: 0.00074379
Iteration 21/25 | Loss: 0.00074379
Iteration 22/25 | Loss: 0.00074379
Iteration 23/25 | Loss: 0.00074379
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0007437941385433078, 0.0007437941385433078, 0.0007437941385433078, 0.0007437941385433078, 0.0007437941385433078]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007437941385433078

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.37638354
Iteration 2/25 | Loss: 0.00036850
Iteration 3/25 | Loss: 0.00036850
Iteration 4/25 | Loss: 0.00036850
Iteration 5/25 | Loss: 0.00036850
Iteration 6/25 | Loss: 0.00036850
Iteration 7/25 | Loss: 0.00036850
Iteration 8/25 | Loss: 0.00036850
Iteration 9/25 | Loss: 0.00036850
Iteration 10/25 | Loss: 0.00036849
Iteration 11/25 | Loss: 0.00036849
Iteration 12/25 | Loss: 0.00036849
Iteration 13/25 | Loss: 0.00036849
Iteration 14/25 | Loss: 0.00036849
Iteration 15/25 | Loss: 0.00036849
Iteration 16/25 | Loss: 0.00036849
Iteration 17/25 | Loss: 0.00036849
Iteration 18/25 | Loss: 0.00036849
Iteration 19/25 | Loss: 0.00036849
Iteration 20/25 | Loss: 0.00036849
Iteration 21/25 | Loss: 0.00036849
Iteration 22/25 | Loss: 0.00036849
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00036849488969892263, 0.00036849488969892263, 0.00036849488969892263, 0.00036849488969892263, 0.00036849488969892263]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00036849488969892263

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00036849
Iteration 2/1000 | Loss: 0.00003322
Iteration 3/1000 | Loss: 0.00002232
Iteration 4/1000 | Loss: 0.00002031
Iteration 5/1000 | Loss: 0.00001930
Iteration 6/1000 | Loss: 0.00001859
Iteration 7/1000 | Loss: 0.00001816
Iteration 8/1000 | Loss: 0.00001787
Iteration 9/1000 | Loss: 0.00001785
Iteration 10/1000 | Loss: 0.00001774
Iteration 11/1000 | Loss: 0.00001773
Iteration 12/1000 | Loss: 0.00001766
Iteration 13/1000 | Loss: 0.00001761
Iteration 14/1000 | Loss: 0.00001761
Iteration 15/1000 | Loss: 0.00001760
Iteration 16/1000 | Loss: 0.00001760
Iteration 17/1000 | Loss: 0.00001759
Iteration 18/1000 | Loss: 0.00001759
Iteration 19/1000 | Loss: 0.00001753
Iteration 20/1000 | Loss: 0.00001752
Iteration 21/1000 | Loss: 0.00001751
Iteration 22/1000 | Loss: 0.00001751
Iteration 23/1000 | Loss: 0.00001750
Iteration 24/1000 | Loss: 0.00001749
Iteration 25/1000 | Loss: 0.00001748
Iteration 26/1000 | Loss: 0.00001746
Iteration 27/1000 | Loss: 0.00001743
Iteration 28/1000 | Loss: 0.00001742
Iteration 29/1000 | Loss: 0.00001741
Iteration 30/1000 | Loss: 0.00001741
Iteration 31/1000 | Loss: 0.00001740
Iteration 32/1000 | Loss: 0.00001740
Iteration 33/1000 | Loss: 0.00001739
Iteration 34/1000 | Loss: 0.00001739
Iteration 35/1000 | Loss: 0.00001739
Iteration 36/1000 | Loss: 0.00001738
Iteration 37/1000 | Loss: 0.00001738
Iteration 38/1000 | Loss: 0.00001738
Iteration 39/1000 | Loss: 0.00001738
Iteration 40/1000 | Loss: 0.00001737
Iteration 41/1000 | Loss: 0.00001737
Iteration 42/1000 | Loss: 0.00001736
Iteration 43/1000 | Loss: 0.00001735
Iteration 44/1000 | Loss: 0.00001735
Iteration 45/1000 | Loss: 0.00001735
Iteration 46/1000 | Loss: 0.00001734
Iteration 47/1000 | Loss: 0.00001734
Iteration 48/1000 | Loss: 0.00001734
Iteration 49/1000 | Loss: 0.00001734
Iteration 50/1000 | Loss: 0.00001734
Iteration 51/1000 | Loss: 0.00001734
Iteration 52/1000 | Loss: 0.00001733
Iteration 53/1000 | Loss: 0.00001733
Iteration 54/1000 | Loss: 0.00001733
Iteration 55/1000 | Loss: 0.00001732
Iteration 56/1000 | Loss: 0.00001732
Iteration 57/1000 | Loss: 0.00001732
Iteration 58/1000 | Loss: 0.00001731
Iteration 59/1000 | Loss: 0.00001731
Iteration 60/1000 | Loss: 0.00001731
Iteration 61/1000 | Loss: 0.00001731
Iteration 62/1000 | Loss: 0.00001731
Iteration 63/1000 | Loss: 0.00001730
Iteration 64/1000 | Loss: 0.00001730
Iteration 65/1000 | Loss: 0.00001730
Iteration 66/1000 | Loss: 0.00001729
Iteration 67/1000 | Loss: 0.00001729
Iteration 68/1000 | Loss: 0.00001729
Iteration 69/1000 | Loss: 0.00001728
Iteration 70/1000 | Loss: 0.00001728
Iteration 71/1000 | Loss: 0.00001727
Iteration 72/1000 | Loss: 0.00001727
Iteration 73/1000 | Loss: 0.00001727
Iteration 74/1000 | Loss: 0.00001727
Iteration 75/1000 | Loss: 0.00001727
Iteration 76/1000 | Loss: 0.00001726
Iteration 77/1000 | Loss: 0.00001726
Iteration 78/1000 | Loss: 0.00001726
Iteration 79/1000 | Loss: 0.00001725
Iteration 80/1000 | Loss: 0.00001725
Iteration 81/1000 | Loss: 0.00001725
Iteration 82/1000 | Loss: 0.00001724
Iteration 83/1000 | Loss: 0.00001724
Iteration 84/1000 | Loss: 0.00001724
Iteration 85/1000 | Loss: 0.00001724
Iteration 86/1000 | Loss: 0.00001724
Iteration 87/1000 | Loss: 0.00001724
Iteration 88/1000 | Loss: 0.00001724
Iteration 89/1000 | Loss: 0.00001724
Iteration 90/1000 | Loss: 0.00001724
Iteration 91/1000 | Loss: 0.00001723
Iteration 92/1000 | Loss: 0.00001723
Iteration 93/1000 | Loss: 0.00001723
Iteration 94/1000 | Loss: 0.00001723
Iteration 95/1000 | Loss: 0.00001723
Iteration 96/1000 | Loss: 0.00001723
Iteration 97/1000 | Loss: 0.00001722
Iteration 98/1000 | Loss: 0.00001722
Iteration 99/1000 | Loss: 0.00001722
Iteration 100/1000 | Loss: 0.00001722
Iteration 101/1000 | Loss: 0.00001722
Iteration 102/1000 | Loss: 0.00001722
Iteration 103/1000 | Loss: 0.00001722
Iteration 104/1000 | Loss: 0.00001721
Iteration 105/1000 | Loss: 0.00001721
Iteration 106/1000 | Loss: 0.00001721
Iteration 107/1000 | Loss: 0.00001721
Iteration 108/1000 | Loss: 0.00001721
Iteration 109/1000 | Loss: 0.00001720
Iteration 110/1000 | Loss: 0.00001720
Iteration 111/1000 | Loss: 0.00001720
Iteration 112/1000 | Loss: 0.00001720
Iteration 113/1000 | Loss: 0.00001720
Iteration 114/1000 | Loss: 0.00001720
Iteration 115/1000 | Loss: 0.00001720
Iteration 116/1000 | Loss: 0.00001720
Iteration 117/1000 | Loss: 0.00001720
Iteration 118/1000 | Loss: 0.00001720
Iteration 119/1000 | Loss: 0.00001720
Iteration 120/1000 | Loss: 0.00001720
Iteration 121/1000 | Loss: 0.00001720
Iteration 122/1000 | Loss: 0.00001720
Iteration 123/1000 | Loss: 0.00001719
Iteration 124/1000 | Loss: 0.00001719
Iteration 125/1000 | Loss: 0.00001719
Iteration 126/1000 | Loss: 0.00001719
Iteration 127/1000 | Loss: 0.00001719
Iteration 128/1000 | Loss: 0.00001719
Iteration 129/1000 | Loss: 0.00001719
Iteration 130/1000 | Loss: 0.00001719
Iteration 131/1000 | Loss: 0.00001719
Iteration 132/1000 | Loss: 0.00001719
Iteration 133/1000 | Loss: 0.00001718
Iteration 134/1000 | Loss: 0.00001718
Iteration 135/1000 | Loss: 0.00001718
Iteration 136/1000 | Loss: 0.00001718
Iteration 137/1000 | Loss: 0.00001718
Iteration 138/1000 | Loss: 0.00001718
Iteration 139/1000 | Loss: 0.00001718
Iteration 140/1000 | Loss: 0.00001718
Iteration 141/1000 | Loss: 0.00001718
Iteration 142/1000 | Loss: 0.00001718
Iteration 143/1000 | Loss: 0.00001718
Iteration 144/1000 | Loss: 0.00001718
Iteration 145/1000 | Loss: 0.00001718
Iteration 146/1000 | Loss: 0.00001718
Iteration 147/1000 | Loss: 0.00001718
Iteration 148/1000 | Loss: 0.00001718
Iteration 149/1000 | Loss: 0.00001718
Iteration 150/1000 | Loss: 0.00001718
Iteration 151/1000 | Loss: 0.00001718
Iteration 152/1000 | Loss: 0.00001718
Iteration 153/1000 | Loss: 0.00001718
Iteration 154/1000 | Loss: 0.00001718
Iteration 155/1000 | Loss: 0.00001718
Iteration 156/1000 | Loss: 0.00001718
Iteration 157/1000 | Loss: 0.00001718
Iteration 158/1000 | Loss: 0.00001718
Iteration 159/1000 | Loss: 0.00001718
Iteration 160/1000 | Loss: 0.00001718
Iteration 161/1000 | Loss: 0.00001718
Iteration 162/1000 | Loss: 0.00001718
Iteration 163/1000 | Loss: 0.00001718
Iteration 164/1000 | Loss: 0.00001718
Iteration 165/1000 | Loss: 0.00001718
Iteration 166/1000 | Loss: 0.00001718
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 166. Stopping optimization.
Last 5 losses: [1.717966006253846e-05, 1.717966006253846e-05, 1.717966006253846e-05, 1.717966006253846e-05, 1.717966006253846e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.717966006253846e-05

Optimization complete. Final v2v error: 3.5352771282196045 mm

Highest mean error: 3.8008923530578613 mm for frame 64

Lowest mean error: 3.315284013748169 mm for frame 178

Saving results

Total time: 36.03894329071045
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0014/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0014.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0014
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01104862
Iteration 2/25 | Loss: 0.00257723
Iteration 3/25 | Loss: 0.00148122
Iteration 4/25 | Loss: 0.00122865
Iteration 5/25 | Loss: 0.00102807
Iteration 6/25 | Loss: 0.00099349
Iteration 7/25 | Loss: 0.00088029
Iteration 8/25 | Loss: 0.00088753
Iteration 9/25 | Loss: 0.00079349
Iteration 10/25 | Loss: 0.00075583
Iteration 11/25 | Loss: 0.00071965
Iteration 12/25 | Loss: 0.00070673
Iteration 13/25 | Loss: 0.00069708
Iteration 14/25 | Loss: 0.00069482
Iteration 15/25 | Loss: 0.00070093
Iteration 16/25 | Loss: 0.00069142
Iteration 17/25 | Loss: 0.00068786
Iteration 18/25 | Loss: 0.00068449
Iteration 19/25 | Loss: 0.00068436
Iteration 20/25 | Loss: 0.00068358
Iteration 21/25 | Loss: 0.00068373
Iteration 22/25 | Loss: 0.00068373
Iteration 23/25 | Loss: 0.00068336
Iteration 24/25 | Loss: 0.00068321
Iteration 25/25 | Loss: 0.00068367

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.48898685
Iteration 2/25 | Loss: 0.00249425
Iteration 3/25 | Loss: 0.00046043
Iteration 4/25 | Loss: 0.00046034
Iteration 5/25 | Loss: 0.00046034
Iteration 6/25 | Loss: 0.00046034
Iteration 7/25 | Loss: 0.00046034
Iteration 8/25 | Loss: 0.00046034
Iteration 9/25 | Loss: 0.00046034
Iteration 10/25 | Loss: 0.00046034
Iteration 11/25 | Loss: 0.00046034
Iteration 12/25 | Loss: 0.00046034
Iteration 13/25 | Loss: 0.00046034
Iteration 14/25 | Loss: 0.00046034
Iteration 15/25 | Loss: 0.00046034
Iteration 16/25 | Loss: 0.00046034
Iteration 17/25 | Loss: 0.00046034
Iteration 18/25 | Loss: 0.00046034
Iteration 19/25 | Loss: 0.00046034
Iteration 20/25 | Loss: 0.00046034
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 20. Stopping optimization.
Last 5 losses: [0.000460341339930892, 0.000460341339930892, 0.000460341339930892, 0.000460341339930892, 0.000460341339930892]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000460341339930892

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00046034
Iteration 2/1000 | Loss: 0.00019057
Iteration 3/1000 | Loss: 0.00033432
Iteration 4/1000 | Loss: 0.00042374
Iteration 5/1000 | Loss: 0.00034724
Iteration 6/1000 | Loss: 0.00033267
Iteration 7/1000 | Loss: 0.00017515
Iteration 8/1000 | Loss: 0.00018170
Iteration 9/1000 | Loss: 0.00016429
Iteration 10/1000 | Loss: 0.00014008
Iteration 11/1000 | Loss: 0.00015512
Iteration 12/1000 | Loss: 0.00018111
Iteration 13/1000 | Loss: 0.00018500
Iteration 14/1000 | Loss: 0.00015529
Iteration 15/1000 | Loss: 0.00016224
Iteration 16/1000 | Loss: 0.00016153
Iteration 17/1000 | Loss: 0.00016982
Iteration 18/1000 | Loss: 0.00017804
Iteration 19/1000 | Loss: 0.00016493
Iteration 20/1000 | Loss: 0.00006518
Iteration 21/1000 | Loss: 0.00018414
Iteration 22/1000 | Loss: 0.00008901
Iteration 23/1000 | Loss: 0.00013901
Iteration 24/1000 | Loss: 0.00011406
Iteration 25/1000 | Loss: 0.00014719
Iteration 26/1000 | Loss: 0.00012252
Iteration 27/1000 | Loss: 0.00007670
Iteration 28/1000 | Loss: 0.00014793
Iteration 29/1000 | Loss: 0.00011268
Iteration 30/1000 | Loss: 0.00013042
Iteration 31/1000 | Loss: 0.00015359
Iteration 32/1000 | Loss: 0.00009773
Iteration 33/1000 | Loss: 0.00018690
Iteration 34/1000 | Loss: 0.00006259
Iteration 35/1000 | Loss: 0.00015128
Iteration 36/1000 | Loss: 0.00015312
Iteration 37/1000 | Loss: 0.00032479
Iteration 38/1000 | Loss: 0.00020866
Iteration 39/1000 | Loss: 0.00010525
Iteration 40/1000 | Loss: 0.00015758
Iteration 41/1000 | Loss: 0.00025152
Iteration 42/1000 | Loss: 0.00004638
Iteration 43/1000 | Loss: 0.00005593
Iteration 44/1000 | Loss: 0.00004444
Iteration 45/1000 | Loss: 0.00004331
Iteration 46/1000 | Loss: 0.00004758
Iteration 47/1000 | Loss: 0.00004373
Iteration 48/1000 | Loss: 0.00004326
Iteration 49/1000 | Loss: 0.00004364
Iteration 50/1000 | Loss: 0.00003307
Iteration 51/1000 | Loss: 0.00003439
Iteration 52/1000 | Loss: 0.00004184
Iteration 53/1000 | Loss: 0.00004111
Iteration 54/1000 | Loss: 0.00004255
Iteration 55/1000 | Loss: 0.00101793
Iteration 56/1000 | Loss: 0.00043150
Iteration 57/1000 | Loss: 0.00074782
Iteration 58/1000 | Loss: 0.00020284
Iteration 59/1000 | Loss: 0.00016265
Iteration 60/1000 | Loss: 0.00013166
Iteration 61/1000 | Loss: 0.00010125
Iteration 62/1000 | Loss: 0.00026979
Iteration 63/1000 | Loss: 0.00013019
Iteration 64/1000 | Loss: 0.00008149
Iteration 65/1000 | Loss: 0.00023351
Iteration 66/1000 | Loss: 0.00017008
Iteration 67/1000 | Loss: 0.00010199
Iteration 68/1000 | Loss: 0.00017315
Iteration 69/1000 | Loss: 0.00027135
Iteration 70/1000 | Loss: 0.00016644
Iteration 71/1000 | Loss: 0.00020744
Iteration 72/1000 | Loss: 0.00002947
Iteration 73/1000 | Loss: 0.00022844
Iteration 74/1000 | Loss: 0.00004263
Iteration 75/1000 | Loss: 0.00004602
Iteration 76/1000 | Loss: 0.00019850
Iteration 77/1000 | Loss: 0.00017659
Iteration 78/1000 | Loss: 0.00002543
Iteration 79/1000 | Loss: 0.00004123
Iteration 80/1000 | Loss: 0.00022206
Iteration 81/1000 | Loss: 0.00002224
Iteration 82/1000 | Loss: 0.00002160
Iteration 83/1000 | Loss: 0.00001928
Iteration 84/1000 | Loss: 0.00001770
Iteration 85/1000 | Loss: 0.00001647
Iteration 86/1000 | Loss: 0.00001764
Iteration 87/1000 | Loss: 0.00001471
Iteration 88/1000 | Loss: 0.00001614
Iteration 89/1000 | Loss: 0.00001430
Iteration 90/1000 | Loss: 0.00001400
Iteration 91/1000 | Loss: 0.00001448
Iteration 92/1000 | Loss: 0.00001363
Iteration 93/1000 | Loss: 0.00001418
Iteration 94/1000 | Loss: 0.00001358
Iteration 95/1000 | Loss: 0.00001358
Iteration 96/1000 | Loss: 0.00001358
Iteration 97/1000 | Loss: 0.00001358
Iteration 98/1000 | Loss: 0.00001358
Iteration 99/1000 | Loss: 0.00001358
Iteration 100/1000 | Loss: 0.00001358
Iteration 101/1000 | Loss: 0.00001357
Iteration 102/1000 | Loss: 0.00001357
Iteration 103/1000 | Loss: 0.00001357
Iteration 104/1000 | Loss: 0.00001354
Iteration 105/1000 | Loss: 0.00001353
Iteration 106/1000 | Loss: 0.00001352
Iteration 107/1000 | Loss: 0.00001350
Iteration 108/1000 | Loss: 0.00001350
Iteration 109/1000 | Loss: 0.00001350
Iteration 110/1000 | Loss: 0.00001350
Iteration 111/1000 | Loss: 0.00001350
Iteration 112/1000 | Loss: 0.00001350
Iteration 113/1000 | Loss: 0.00001350
Iteration 114/1000 | Loss: 0.00001350
Iteration 115/1000 | Loss: 0.00001349
Iteration 116/1000 | Loss: 0.00001349
Iteration 117/1000 | Loss: 0.00001349
Iteration 118/1000 | Loss: 0.00001349
Iteration 119/1000 | Loss: 0.00001348
Iteration 120/1000 | Loss: 0.00001348
Iteration 121/1000 | Loss: 0.00001347
Iteration 122/1000 | Loss: 0.00001346
Iteration 123/1000 | Loss: 0.00001343
Iteration 124/1000 | Loss: 0.00001343
Iteration 125/1000 | Loss: 0.00001343
Iteration 126/1000 | Loss: 0.00001343
Iteration 127/1000 | Loss: 0.00001343
Iteration 128/1000 | Loss: 0.00001343
Iteration 129/1000 | Loss: 0.00001342
Iteration 130/1000 | Loss: 0.00001342
Iteration 131/1000 | Loss: 0.00001451
Iteration 132/1000 | Loss: 0.00001451
Iteration 133/1000 | Loss: 0.00001432
Iteration 134/1000 | Loss: 0.00001533
Iteration 135/1000 | Loss: 0.00001333
Iteration 136/1000 | Loss: 0.00001333
Iteration 137/1000 | Loss: 0.00001333
Iteration 138/1000 | Loss: 0.00001332
Iteration 139/1000 | Loss: 0.00001332
Iteration 140/1000 | Loss: 0.00001332
Iteration 141/1000 | Loss: 0.00001332
Iteration 142/1000 | Loss: 0.00001332
Iteration 143/1000 | Loss: 0.00001332
Iteration 144/1000 | Loss: 0.00001332
Iteration 145/1000 | Loss: 0.00001332
Iteration 146/1000 | Loss: 0.00001332
Iteration 147/1000 | Loss: 0.00001332
Iteration 148/1000 | Loss: 0.00001332
Iteration 149/1000 | Loss: 0.00001332
Iteration 150/1000 | Loss: 0.00001332
Iteration 151/1000 | Loss: 0.00001332
Iteration 152/1000 | Loss: 0.00001332
Iteration 153/1000 | Loss: 0.00001332
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 153. Stopping optimization.
Last 5 losses: [1.332350257143844e-05, 1.332350257143844e-05, 1.332350257143844e-05, 1.332350257143844e-05, 1.332350257143844e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.332350257143844e-05

Optimization complete. Final v2v error: 3.0931475162506104 mm

Highest mean error: 9.506442070007324 mm for frame 56

Lowest mean error: 2.717240333557129 mm for frame 103

Saving results

Total time: 181.76018810272217
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0001/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0001.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0001
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00502230
Iteration 2/25 | Loss: 0.00089043
Iteration 3/25 | Loss: 0.00076038
Iteration 4/25 | Loss: 0.00073628
Iteration 5/25 | Loss: 0.00072720
Iteration 6/25 | Loss: 0.00072550
Iteration 7/25 | Loss: 0.00072535
Iteration 8/25 | Loss: 0.00072535
Iteration 9/25 | Loss: 0.00072535
Iteration 10/25 | Loss: 0.00072535
Iteration 11/25 | Loss: 0.00072535
Iteration 12/25 | Loss: 0.00072535
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007253544754348695, 0.0007253544754348695, 0.0007253544754348695, 0.0007253544754348695, 0.0007253544754348695]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007253544754348695

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.38881898
Iteration 2/25 | Loss: 0.00030646
Iteration 3/25 | Loss: 0.00030642
Iteration 4/25 | Loss: 0.00030642
Iteration 5/25 | Loss: 0.00030642
Iteration 6/25 | Loss: 0.00030642
Iteration 7/25 | Loss: 0.00030642
Iteration 8/25 | Loss: 0.00030642
Iteration 9/25 | Loss: 0.00030642
Iteration 10/25 | Loss: 0.00030642
Iteration 11/25 | Loss: 0.00030642
Iteration 12/25 | Loss: 0.00030642
Iteration 13/25 | Loss: 0.00030642
Iteration 14/25 | Loss: 0.00030642
Iteration 15/25 | Loss: 0.00030642
Iteration 16/25 | Loss: 0.00030642
Iteration 17/25 | Loss: 0.00030642
Iteration 18/25 | Loss: 0.00030642
Iteration 19/25 | Loss: 0.00030642
Iteration 20/25 | Loss: 0.00030642
Iteration 21/25 | Loss: 0.00030642
Iteration 22/25 | Loss: 0.00030642
Iteration 23/25 | Loss: 0.00030642
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00030641682678833604, 0.00030641682678833604, 0.00030641682678833604, 0.00030641682678833604, 0.00030641682678833604]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00030641682678833604

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00030642
Iteration 2/1000 | Loss: 0.00003245
Iteration 3/1000 | Loss: 0.00001848
Iteration 4/1000 | Loss: 0.00001543
Iteration 5/1000 | Loss: 0.00001450
Iteration 6/1000 | Loss: 0.00001382
Iteration 7/1000 | Loss: 0.00001330
Iteration 8/1000 | Loss: 0.00001290
Iteration 9/1000 | Loss: 0.00001270
Iteration 10/1000 | Loss: 0.00001262
Iteration 11/1000 | Loss: 0.00001258
Iteration 12/1000 | Loss: 0.00001254
Iteration 13/1000 | Loss: 0.00001254
Iteration 14/1000 | Loss: 0.00001250
Iteration 15/1000 | Loss: 0.00001244
Iteration 16/1000 | Loss: 0.00001244
Iteration 17/1000 | Loss: 0.00001238
Iteration 18/1000 | Loss: 0.00001236
Iteration 19/1000 | Loss: 0.00001235
Iteration 20/1000 | Loss: 0.00001234
Iteration 21/1000 | Loss: 0.00001234
Iteration 22/1000 | Loss: 0.00001234
Iteration 23/1000 | Loss: 0.00001232
Iteration 24/1000 | Loss: 0.00001231
Iteration 25/1000 | Loss: 0.00001228
Iteration 26/1000 | Loss: 0.00001227
Iteration 27/1000 | Loss: 0.00001225
Iteration 28/1000 | Loss: 0.00001225
Iteration 29/1000 | Loss: 0.00001225
Iteration 30/1000 | Loss: 0.00001225
Iteration 31/1000 | Loss: 0.00001225
Iteration 32/1000 | Loss: 0.00001225
Iteration 33/1000 | Loss: 0.00001224
Iteration 34/1000 | Loss: 0.00001224
Iteration 35/1000 | Loss: 0.00001224
Iteration 36/1000 | Loss: 0.00001224
Iteration 37/1000 | Loss: 0.00001224
Iteration 38/1000 | Loss: 0.00001224
Iteration 39/1000 | Loss: 0.00001224
Iteration 40/1000 | Loss: 0.00001224
Iteration 41/1000 | Loss: 0.00001224
Iteration 42/1000 | Loss: 0.00001223
Iteration 43/1000 | Loss: 0.00001222
Iteration 44/1000 | Loss: 0.00001222
Iteration 45/1000 | Loss: 0.00001221
Iteration 46/1000 | Loss: 0.00001221
Iteration 47/1000 | Loss: 0.00001221
Iteration 48/1000 | Loss: 0.00001221
Iteration 49/1000 | Loss: 0.00001220
Iteration 50/1000 | Loss: 0.00001220
Iteration 51/1000 | Loss: 0.00001220
Iteration 52/1000 | Loss: 0.00001219
Iteration 53/1000 | Loss: 0.00001219
Iteration 54/1000 | Loss: 0.00001219
Iteration 55/1000 | Loss: 0.00001218
Iteration 56/1000 | Loss: 0.00001218
Iteration 57/1000 | Loss: 0.00001218
Iteration 58/1000 | Loss: 0.00001218
Iteration 59/1000 | Loss: 0.00001217
Iteration 60/1000 | Loss: 0.00001217
Iteration 61/1000 | Loss: 0.00001217
Iteration 62/1000 | Loss: 0.00001217
Iteration 63/1000 | Loss: 0.00001217
Iteration 64/1000 | Loss: 0.00001217
Iteration 65/1000 | Loss: 0.00001216
Iteration 66/1000 | Loss: 0.00001216
Iteration 67/1000 | Loss: 0.00001216
Iteration 68/1000 | Loss: 0.00001216
Iteration 69/1000 | Loss: 0.00001215
Iteration 70/1000 | Loss: 0.00001215
Iteration 71/1000 | Loss: 0.00001215
Iteration 72/1000 | Loss: 0.00001215
Iteration 73/1000 | Loss: 0.00001214
Iteration 74/1000 | Loss: 0.00001214
Iteration 75/1000 | Loss: 0.00001214
Iteration 76/1000 | Loss: 0.00001214
Iteration 77/1000 | Loss: 0.00001214
Iteration 78/1000 | Loss: 0.00001214
Iteration 79/1000 | Loss: 0.00001214
Iteration 80/1000 | Loss: 0.00001214
Iteration 81/1000 | Loss: 0.00001214
Iteration 82/1000 | Loss: 0.00001213
Iteration 83/1000 | Loss: 0.00001213
Iteration 84/1000 | Loss: 0.00001213
Iteration 85/1000 | Loss: 0.00001213
Iteration 86/1000 | Loss: 0.00001213
Iteration 87/1000 | Loss: 0.00001213
Iteration 88/1000 | Loss: 0.00001212
Iteration 89/1000 | Loss: 0.00001212
Iteration 90/1000 | Loss: 0.00001212
Iteration 91/1000 | Loss: 0.00001212
Iteration 92/1000 | Loss: 0.00001212
Iteration 93/1000 | Loss: 0.00001212
Iteration 94/1000 | Loss: 0.00001212
Iteration 95/1000 | Loss: 0.00001212
Iteration 96/1000 | Loss: 0.00001212
Iteration 97/1000 | Loss: 0.00001212
Iteration 98/1000 | Loss: 0.00001212
Iteration 99/1000 | Loss: 0.00001212
Iteration 100/1000 | Loss: 0.00001212
Iteration 101/1000 | Loss: 0.00001212
Iteration 102/1000 | Loss: 0.00001212
Iteration 103/1000 | Loss: 0.00001212
Iteration 104/1000 | Loss: 0.00001212
Iteration 105/1000 | Loss: 0.00001212
Iteration 106/1000 | Loss: 0.00001212
Iteration 107/1000 | Loss: 0.00001212
Iteration 108/1000 | Loss: 0.00001212
Iteration 109/1000 | Loss: 0.00001212
Iteration 110/1000 | Loss: 0.00001212
Iteration 111/1000 | Loss: 0.00001212
Iteration 112/1000 | Loss: 0.00001212
Iteration 113/1000 | Loss: 0.00001212
Iteration 114/1000 | Loss: 0.00001212
Iteration 115/1000 | Loss: 0.00001212
Iteration 116/1000 | Loss: 0.00001212
Iteration 117/1000 | Loss: 0.00001212
Iteration 118/1000 | Loss: 0.00001212
Iteration 119/1000 | Loss: 0.00001212
Iteration 120/1000 | Loss: 0.00001212
Iteration 121/1000 | Loss: 0.00001212
Iteration 122/1000 | Loss: 0.00001212
Iteration 123/1000 | Loss: 0.00001212
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 123. Stopping optimization.
Last 5 losses: [1.2117424375901464e-05, 1.2117424375901464e-05, 1.2117424375901464e-05, 1.2117424375901464e-05, 1.2117424375901464e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2117424375901464e-05

Optimization complete. Final v2v error: 3.0458431243896484 mm

Highest mean error: 3.519458532333374 mm for frame 139

Lowest mean error: 2.7501211166381836 mm for frame 57

Saving results

Total time: 32.22610139846802
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0011/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0011.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0011
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00836800
Iteration 2/25 | Loss: 0.00113839
Iteration 3/25 | Loss: 0.00081061
Iteration 4/25 | Loss: 0.00075914
Iteration 5/25 | Loss: 0.00074031
Iteration 6/25 | Loss: 0.00072796
Iteration 7/25 | Loss: 0.00072662
Iteration 8/25 | Loss: 0.00072400
Iteration 9/25 | Loss: 0.00072390
Iteration 10/25 | Loss: 0.00072389
Iteration 11/25 | Loss: 0.00072389
Iteration 12/25 | Loss: 0.00072389
Iteration 13/25 | Loss: 0.00072389
Iteration 14/25 | Loss: 0.00072389
Iteration 15/25 | Loss: 0.00072389
Iteration 16/25 | Loss: 0.00072389
Iteration 17/25 | Loss: 0.00072389
Iteration 18/25 | Loss: 0.00072389
Iteration 19/25 | Loss: 0.00072389
Iteration 20/25 | Loss: 0.00072389
Iteration 21/25 | Loss: 0.00072389
Iteration 22/25 | Loss: 0.00072389
Iteration 23/25 | Loss: 0.00072389
Iteration 24/25 | Loss: 0.00072389
Iteration 25/25 | Loss: 0.00072389

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.64080739
Iteration 2/25 | Loss: 0.00024914
Iteration 3/25 | Loss: 0.00024914
Iteration 4/25 | Loss: 0.00024914
Iteration 5/25 | Loss: 0.00024914
Iteration 6/25 | Loss: 0.00023928
Iteration 7/25 | Loss: 0.00023928
Iteration 8/25 | Loss: 0.00023928
Iteration 9/25 | Loss: 0.00023928
Iteration 10/25 | Loss: 0.00023928
Iteration 11/25 | Loss: 0.00023928
Iteration 12/25 | Loss: 0.00023928
Iteration 13/25 | Loss: 0.00023928
Iteration 14/25 | Loss: 0.00023928
Iteration 15/25 | Loss: 0.00023928
Iteration 16/25 | Loss: 0.00023928
Iteration 17/25 | Loss: 0.00023928
Iteration 18/25 | Loss: 0.00023928
Iteration 19/25 | Loss: 0.00023928
Iteration 20/25 | Loss: 0.00023928
Iteration 21/25 | Loss: 0.00023928
Iteration 22/25 | Loss: 0.00023928
Iteration 23/25 | Loss: 0.00023928
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0002392834285274148, 0.0002392834285274148, 0.0002392834285274148, 0.0002392834285274148, 0.0002392834285274148]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0002392834285274148

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00023928
Iteration 2/1000 | Loss: 0.00002960
Iteration 3/1000 | Loss: 0.00002923
Iteration 4/1000 | Loss: 0.00002006
Iteration 5/1000 | Loss: 0.00002626
Iteration 6/1000 | Loss: 0.00001880
Iteration 7/1000 | Loss: 0.00003316
Iteration 8/1000 | Loss: 0.00002048
Iteration 9/1000 | Loss: 0.00001780
Iteration 10/1000 | Loss: 0.00001779
Iteration 11/1000 | Loss: 0.00001778
Iteration 12/1000 | Loss: 0.00001763
Iteration 13/1000 | Loss: 0.00001762
Iteration 14/1000 | Loss: 0.00001756
Iteration 15/1000 | Loss: 0.00001751
Iteration 16/1000 | Loss: 0.00001749
Iteration 17/1000 | Loss: 0.00001745
Iteration 18/1000 | Loss: 0.00001740
Iteration 19/1000 | Loss: 0.00002942
Iteration 20/1000 | Loss: 0.00001734
Iteration 21/1000 | Loss: 0.00002284
Iteration 22/1000 | Loss: 0.00001730
Iteration 23/1000 | Loss: 0.00001729
Iteration 24/1000 | Loss: 0.00001729
Iteration 25/1000 | Loss: 0.00001728
Iteration 26/1000 | Loss: 0.00001728
Iteration 27/1000 | Loss: 0.00001727
Iteration 28/1000 | Loss: 0.00001727
Iteration 29/1000 | Loss: 0.00001726
Iteration 30/1000 | Loss: 0.00001726
Iteration 31/1000 | Loss: 0.00001726
Iteration 32/1000 | Loss: 0.00001726
Iteration 33/1000 | Loss: 0.00001725
Iteration 34/1000 | Loss: 0.00001725
Iteration 35/1000 | Loss: 0.00001723
Iteration 36/1000 | Loss: 0.00001722
Iteration 37/1000 | Loss: 0.00001722
Iteration 38/1000 | Loss: 0.00001722
Iteration 39/1000 | Loss: 0.00001721
Iteration 40/1000 | Loss: 0.00001721
Iteration 41/1000 | Loss: 0.00001721
Iteration 42/1000 | Loss: 0.00001720
Iteration 43/1000 | Loss: 0.00001720
Iteration 44/1000 | Loss: 0.00001720
Iteration 45/1000 | Loss: 0.00001720
Iteration 46/1000 | Loss: 0.00001719
Iteration 47/1000 | Loss: 0.00001719
Iteration 48/1000 | Loss: 0.00001719
Iteration 49/1000 | Loss: 0.00001719
Iteration 50/1000 | Loss: 0.00001718
Iteration 51/1000 | Loss: 0.00001718
Iteration 52/1000 | Loss: 0.00001718
Iteration 53/1000 | Loss: 0.00001717
Iteration 54/1000 | Loss: 0.00001717
Iteration 55/1000 | Loss: 0.00001717
Iteration 56/1000 | Loss: 0.00001716
Iteration 57/1000 | Loss: 0.00001716
Iteration 58/1000 | Loss: 0.00001716
Iteration 59/1000 | Loss: 0.00001716
Iteration 60/1000 | Loss: 0.00001716
Iteration 61/1000 | Loss: 0.00001716
Iteration 62/1000 | Loss: 0.00001716
Iteration 63/1000 | Loss: 0.00001716
Iteration 64/1000 | Loss: 0.00001716
Iteration 65/1000 | Loss: 0.00001716
Iteration 66/1000 | Loss: 0.00001716
Iteration 67/1000 | Loss: 0.00001716
Iteration 68/1000 | Loss: 0.00001716
Iteration 69/1000 | Loss: 0.00001716
Iteration 70/1000 | Loss: 0.00001716
Iteration 71/1000 | Loss: 0.00001716
Iteration 72/1000 | Loss: 0.00001716
Iteration 73/1000 | Loss: 0.00001716
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 73. Stopping optimization.
Last 5 losses: [1.7161131836473942e-05, 1.7161131836473942e-05, 1.7161131836473942e-05, 1.7161131836473942e-05, 1.7161131836473942e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7161131836473942e-05

Optimization complete. Final v2v error: 3.5343425273895264 mm

Highest mean error: 3.865339517593384 mm for frame 51

Lowest mean error: 3.1760880947113037 mm for frame 162

Saving results

Total time: 43.93708348274231
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0000/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0000.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0000
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00607478
Iteration 2/25 | Loss: 0.00127143
Iteration 3/25 | Loss: 0.00097224
Iteration 4/25 | Loss: 0.00092313
Iteration 5/25 | Loss: 0.00090890
Iteration 6/25 | Loss: 0.00090627
Iteration 7/25 | Loss: 0.00090604
Iteration 8/25 | Loss: 0.00090604
Iteration 9/25 | Loss: 0.00090604
Iteration 10/25 | Loss: 0.00090604
Iteration 11/25 | Loss: 0.00090604
Iteration 12/25 | Loss: 0.00090604
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009060394950211048, 0.0009060394950211048, 0.0009060394950211048, 0.0009060394950211048, 0.0009060394950211048]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009060394950211048

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.95418262
Iteration 2/25 | Loss: 0.00049843
Iteration 3/25 | Loss: 0.00049839
Iteration 4/25 | Loss: 0.00049839
Iteration 5/25 | Loss: 0.00049839
Iteration 6/25 | Loss: 0.00049838
Iteration 7/25 | Loss: 0.00049838
Iteration 8/25 | Loss: 0.00049838
Iteration 9/25 | Loss: 0.00049838
Iteration 10/25 | Loss: 0.00049838
Iteration 11/25 | Loss: 0.00049838
Iteration 12/25 | Loss: 0.00049838
Iteration 13/25 | Loss: 0.00049838
Iteration 14/25 | Loss: 0.00049838
Iteration 15/25 | Loss: 0.00049838
Iteration 16/25 | Loss: 0.00049838
Iteration 17/25 | Loss: 0.00049838
Iteration 18/25 | Loss: 0.00049838
Iteration 19/25 | Loss: 0.00049838
Iteration 20/25 | Loss: 0.00049838
Iteration 21/25 | Loss: 0.00049838
Iteration 22/25 | Loss: 0.00049838
Iteration 23/25 | Loss: 0.00049838
Iteration 24/25 | Loss: 0.00049838
Iteration 25/25 | Loss: 0.00049838

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00049838
Iteration 2/1000 | Loss: 0.00004714
Iteration 3/1000 | Loss: 0.00003202
Iteration 4/1000 | Loss: 0.00002741
Iteration 5/1000 | Loss: 0.00002479
Iteration 6/1000 | Loss: 0.00002381
Iteration 7/1000 | Loss: 0.00002327
Iteration 8/1000 | Loss: 0.00002273
Iteration 9/1000 | Loss: 0.00002228
Iteration 10/1000 | Loss: 0.00002203
Iteration 11/1000 | Loss: 0.00002177
Iteration 12/1000 | Loss: 0.00002162
Iteration 13/1000 | Loss: 0.00002147
Iteration 14/1000 | Loss: 0.00002145
Iteration 15/1000 | Loss: 0.00002145
Iteration 16/1000 | Loss: 0.00002144
Iteration 17/1000 | Loss: 0.00002144
Iteration 18/1000 | Loss: 0.00002139
Iteration 19/1000 | Loss: 0.00002138
Iteration 20/1000 | Loss: 0.00002136
Iteration 21/1000 | Loss: 0.00002135
Iteration 22/1000 | Loss: 0.00002135
Iteration 23/1000 | Loss: 0.00002135
Iteration 24/1000 | Loss: 0.00002135
Iteration 25/1000 | Loss: 0.00002134
Iteration 26/1000 | Loss: 0.00002133
Iteration 27/1000 | Loss: 0.00002133
Iteration 28/1000 | Loss: 0.00002131
Iteration 29/1000 | Loss: 0.00002131
Iteration 30/1000 | Loss: 0.00002130
Iteration 31/1000 | Loss: 0.00002130
Iteration 32/1000 | Loss: 0.00002129
Iteration 33/1000 | Loss: 0.00002129
Iteration 34/1000 | Loss: 0.00002129
Iteration 35/1000 | Loss: 0.00002128
Iteration 36/1000 | Loss: 0.00002127
Iteration 37/1000 | Loss: 0.00002126
Iteration 38/1000 | Loss: 0.00002126
Iteration 39/1000 | Loss: 0.00002126
Iteration 40/1000 | Loss: 0.00002126
Iteration 41/1000 | Loss: 0.00002126
Iteration 42/1000 | Loss: 0.00002126
Iteration 43/1000 | Loss: 0.00002126
Iteration 44/1000 | Loss: 0.00002126
Iteration 45/1000 | Loss: 0.00002126
Iteration 46/1000 | Loss: 0.00002126
Iteration 47/1000 | Loss: 0.00002126
Iteration 48/1000 | Loss: 0.00002126
Iteration 49/1000 | Loss: 0.00002126
Iteration 50/1000 | Loss: 0.00002126
Iteration 51/1000 | Loss: 0.00002125
Iteration 52/1000 | Loss: 0.00002125
Iteration 53/1000 | Loss: 0.00002125
Iteration 54/1000 | Loss: 0.00002125
Iteration 55/1000 | Loss: 0.00002125
Iteration 56/1000 | Loss: 0.00002125
Iteration 57/1000 | Loss: 0.00002125
Iteration 58/1000 | Loss: 0.00002124
Iteration 59/1000 | Loss: 0.00002124
Iteration 60/1000 | Loss: 0.00002124
Iteration 61/1000 | Loss: 0.00002123
Iteration 62/1000 | Loss: 0.00002123
Iteration 63/1000 | Loss: 0.00002123
Iteration 64/1000 | Loss: 0.00002122
Iteration 65/1000 | Loss: 0.00002121
Iteration 66/1000 | Loss: 0.00002121
Iteration 67/1000 | Loss: 0.00002121
Iteration 68/1000 | Loss: 0.00002121
Iteration 69/1000 | Loss: 0.00002121
Iteration 70/1000 | Loss: 0.00002121
Iteration 71/1000 | Loss: 0.00002121
Iteration 72/1000 | Loss: 0.00002120
Iteration 73/1000 | Loss: 0.00002120
Iteration 74/1000 | Loss: 0.00002120
Iteration 75/1000 | Loss: 0.00002119
Iteration 76/1000 | Loss: 0.00002119
Iteration 77/1000 | Loss: 0.00002119
Iteration 78/1000 | Loss: 0.00002118
Iteration 79/1000 | Loss: 0.00002118
Iteration 80/1000 | Loss: 0.00002118
Iteration 81/1000 | Loss: 0.00002118
Iteration 82/1000 | Loss: 0.00002118
Iteration 83/1000 | Loss: 0.00002118
Iteration 84/1000 | Loss: 0.00002118
Iteration 85/1000 | Loss: 0.00002118
Iteration 86/1000 | Loss: 0.00002118
Iteration 87/1000 | Loss: 0.00002117
Iteration 88/1000 | Loss: 0.00002117
Iteration 89/1000 | Loss: 0.00002117
Iteration 90/1000 | Loss: 0.00002117
Iteration 91/1000 | Loss: 0.00002117
Iteration 92/1000 | Loss: 0.00002117
Iteration 93/1000 | Loss: 0.00002117
Iteration 94/1000 | Loss: 0.00002117
Iteration 95/1000 | Loss: 0.00002117
Iteration 96/1000 | Loss: 0.00002116
Iteration 97/1000 | Loss: 0.00002116
Iteration 98/1000 | Loss: 0.00002116
Iteration 99/1000 | Loss: 0.00002116
Iteration 100/1000 | Loss: 0.00002116
Iteration 101/1000 | Loss: 0.00002116
Iteration 102/1000 | Loss: 0.00002116
Iteration 103/1000 | Loss: 0.00002116
Iteration 104/1000 | Loss: 0.00002116
Iteration 105/1000 | Loss: 0.00002116
Iteration 106/1000 | Loss: 0.00002116
Iteration 107/1000 | Loss: 0.00002116
Iteration 108/1000 | Loss: 0.00002115
Iteration 109/1000 | Loss: 0.00002115
Iteration 110/1000 | Loss: 0.00002115
Iteration 111/1000 | Loss: 0.00002115
Iteration 112/1000 | Loss: 0.00002115
Iteration 113/1000 | Loss: 0.00002115
Iteration 114/1000 | Loss: 0.00002115
Iteration 115/1000 | Loss: 0.00002115
Iteration 116/1000 | Loss: 0.00002115
Iteration 117/1000 | Loss: 0.00002115
Iteration 118/1000 | Loss: 0.00002115
Iteration 119/1000 | Loss: 0.00002115
Iteration 120/1000 | Loss: 0.00002115
Iteration 121/1000 | Loss: 0.00002115
Iteration 122/1000 | Loss: 0.00002115
Iteration 123/1000 | Loss: 0.00002115
Iteration 124/1000 | Loss: 0.00002115
Iteration 125/1000 | Loss: 0.00002115
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 125. Stopping optimization.
Last 5 losses: [2.1146493963897228e-05, 2.1146493963897228e-05, 2.1146493963897228e-05, 2.1146493963897228e-05, 2.1146493963897228e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1146493963897228e-05

Optimization complete. Final v2v error: 3.8939664363861084 mm

Highest mean error: 4.1837992668151855 mm for frame 27

Lowest mean error: 3.5665040016174316 mm for frame 12

Saving results

Total time: 35.41680145263672
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0002/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0002.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0002
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01069390
Iteration 2/25 | Loss: 0.00220829
Iteration 3/25 | Loss: 0.00144552
Iteration 4/25 | Loss: 0.00126103
Iteration 5/25 | Loss: 0.00115245
Iteration 6/25 | Loss: 0.00125033
Iteration 7/25 | Loss: 0.00104385
Iteration 8/25 | Loss: 0.00092461
Iteration 9/25 | Loss: 0.00086732
Iteration 10/25 | Loss: 0.00082922
Iteration 11/25 | Loss: 0.00082150
Iteration 12/25 | Loss: 0.00081018
Iteration 13/25 | Loss: 0.00079039
Iteration 14/25 | Loss: 0.00077910
Iteration 15/25 | Loss: 0.00077301
Iteration 16/25 | Loss: 0.00077426
Iteration 17/25 | Loss: 0.00078253
Iteration 18/25 | Loss: 0.00077733
Iteration 19/25 | Loss: 0.00077040
Iteration 20/25 | Loss: 0.00076864
Iteration 21/25 | Loss: 0.00076175
Iteration 22/25 | Loss: 0.00075861
Iteration 23/25 | Loss: 0.00074828
Iteration 24/25 | Loss: 0.00074601
Iteration 25/25 | Loss: 0.00074669

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.43673205
Iteration 2/25 | Loss: 0.00052399
Iteration 3/25 | Loss: 0.00042538
Iteration 4/25 | Loss: 0.00042538
Iteration 5/25 | Loss: 0.00042538
Iteration 6/25 | Loss: 0.00042538
Iteration 7/25 | Loss: 0.00042538
Iteration 8/25 | Loss: 0.00042538
Iteration 9/25 | Loss: 0.00042538
Iteration 10/25 | Loss: 0.00042538
Iteration 11/25 | Loss: 0.00042538
Iteration 12/25 | Loss: 0.00042538
Iteration 13/25 | Loss: 0.00042538
Iteration 14/25 | Loss: 0.00042538
Iteration 15/25 | Loss: 0.00042538
Iteration 16/25 | Loss: 0.00042538
Iteration 17/25 | Loss: 0.00042538
Iteration 18/25 | Loss: 0.00042538
Iteration 19/25 | Loss: 0.00042538
Iteration 20/25 | Loss: 0.00042538
Iteration 21/25 | Loss: 0.00042538
Iteration 22/25 | Loss: 0.00042538
Iteration 23/25 | Loss: 0.00042538
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0004253797233104706, 0.0004253797233104706, 0.0004253797233104706, 0.0004253797233104706, 0.0004253797233104706]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0004253797233104706

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00042538
Iteration 2/1000 | Loss: 0.00020307
Iteration 3/1000 | Loss: 0.00013148
Iteration 4/1000 | Loss: 0.00015904
Iteration 5/1000 | Loss: 0.00003551
Iteration 6/1000 | Loss: 0.00019143
Iteration 7/1000 | Loss: 0.00022450
Iteration 8/1000 | Loss: 0.00004970
Iteration 9/1000 | Loss: 0.00014159
Iteration 10/1000 | Loss: 0.00016636
Iteration 11/1000 | Loss: 0.00019797
Iteration 12/1000 | Loss: 0.00013567
Iteration 13/1000 | Loss: 0.00029833
Iteration 14/1000 | Loss: 0.00039176
Iteration 15/1000 | Loss: 0.00013668
Iteration 16/1000 | Loss: 0.00079853
Iteration 17/1000 | Loss: 0.00018832
Iteration 18/1000 | Loss: 0.00004047
Iteration 19/1000 | Loss: 0.00003068
Iteration 20/1000 | Loss: 0.00002688
Iteration 21/1000 | Loss: 0.00002239
Iteration 22/1000 | Loss: 0.00002022
Iteration 23/1000 | Loss: 0.00001923
Iteration 24/1000 | Loss: 0.00001823
Iteration 25/1000 | Loss: 0.00001752
Iteration 26/1000 | Loss: 0.00001704
Iteration 27/1000 | Loss: 0.00001675
Iteration 28/1000 | Loss: 0.00001648
Iteration 29/1000 | Loss: 0.00001631
Iteration 30/1000 | Loss: 0.00001628
Iteration 31/1000 | Loss: 0.00001627
Iteration 32/1000 | Loss: 0.00001624
Iteration 33/1000 | Loss: 0.00001606
Iteration 34/1000 | Loss: 0.00001602
Iteration 35/1000 | Loss: 0.00001597
Iteration 36/1000 | Loss: 0.00001596
Iteration 37/1000 | Loss: 0.00001580
Iteration 38/1000 | Loss: 0.00001577
Iteration 39/1000 | Loss: 0.00001576
Iteration 40/1000 | Loss: 0.00001575
Iteration 41/1000 | Loss: 0.00001574
Iteration 42/1000 | Loss: 0.00001573
Iteration 43/1000 | Loss: 0.00001573
Iteration 44/1000 | Loss: 0.00001568
Iteration 45/1000 | Loss: 0.00001568
Iteration 46/1000 | Loss: 0.00001567
Iteration 47/1000 | Loss: 0.00001566
Iteration 48/1000 | Loss: 0.00001566
Iteration 49/1000 | Loss: 0.00001565
Iteration 50/1000 | Loss: 0.00001564
Iteration 51/1000 | Loss: 0.00001562
Iteration 52/1000 | Loss: 0.00001562
Iteration 53/1000 | Loss: 0.00001561
Iteration 54/1000 | Loss: 0.00001560
Iteration 55/1000 | Loss: 0.00001560
Iteration 56/1000 | Loss: 0.00001559
Iteration 57/1000 | Loss: 0.00001559
Iteration 58/1000 | Loss: 0.00001558
Iteration 59/1000 | Loss: 0.00001557
Iteration 60/1000 | Loss: 0.00001557
Iteration 61/1000 | Loss: 0.00001557
Iteration 62/1000 | Loss: 0.00001556
Iteration 63/1000 | Loss: 0.00001555
Iteration 64/1000 | Loss: 0.00001550
Iteration 65/1000 | Loss: 0.00001548
Iteration 66/1000 | Loss: 0.00001547
Iteration 67/1000 | Loss: 0.00001546
Iteration 68/1000 | Loss: 0.00001545
Iteration 69/1000 | Loss: 0.00001542
Iteration 70/1000 | Loss: 0.00001542
Iteration 71/1000 | Loss: 0.00001542
Iteration 72/1000 | Loss: 0.00001542
Iteration 73/1000 | Loss: 0.00001542
Iteration 74/1000 | Loss: 0.00001542
Iteration 75/1000 | Loss: 0.00001542
Iteration 76/1000 | Loss: 0.00001542
Iteration 77/1000 | Loss: 0.00001541
Iteration 78/1000 | Loss: 0.00001541
Iteration 79/1000 | Loss: 0.00001541
Iteration 80/1000 | Loss: 0.00001541
Iteration 81/1000 | Loss: 0.00001539
Iteration 82/1000 | Loss: 0.00001539
Iteration 83/1000 | Loss: 0.00001538
Iteration 84/1000 | Loss: 0.00001538
Iteration 85/1000 | Loss: 0.00001538
Iteration 86/1000 | Loss: 0.00001537
Iteration 87/1000 | Loss: 0.00001537
Iteration 88/1000 | Loss: 0.00001537
Iteration 89/1000 | Loss: 0.00001537
Iteration 90/1000 | Loss: 0.00001536
Iteration 91/1000 | Loss: 0.00001536
Iteration 92/1000 | Loss: 0.00001535
Iteration 93/1000 | Loss: 0.00001535
Iteration 94/1000 | Loss: 0.00001535
Iteration 95/1000 | Loss: 0.00001535
Iteration 96/1000 | Loss: 0.00001534
Iteration 97/1000 | Loss: 0.00001534
Iteration 98/1000 | Loss: 0.00001534
Iteration 99/1000 | Loss: 0.00001534
Iteration 100/1000 | Loss: 0.00001534
Iteration 101/1000 | Loss: 0.00001534
Iteration 102/1000 | Loss: 0.00001533
Iteration 103/1000 | Loss: 0.00001533
Iteration 104/1000 | Loss: 0.00001533
Iteration 105/1000 | Loss: 0.00001533
Iteration 106/1000 | Loss: 0.00001533
Iteration 107/1000 | Loss: 0.00001532
Iteration 108/1000 | Loss: 0.00001532
Iteration 109/1000 | Loss: 0.00001532
Iteration 110/1000 | Loss: 0.00001531
Iteration 111/1000 | Loss: 0.00001531
Iteration 112/1000 | Loss: 0.00001531
Iteration 113/1000 | Loss: 0.00001531
Iteration 114/1000 | Loss: 0.00001531
Iteration 115/1000 | Loss: 0.00001531
Iteration 116/1000 | Loss: 0.00001531
Iteration 117/1000 | Loss: 0.00001531
Iteration 118/1000 | Loss: 0.00001531
Iteration 119/1000 | Loss: 0.00001531
Iteration 120/1000 | Loss: 0.00001531
Iteration 121/1000 | Loss: 0.00001530
Iteration 122/1000 | Loss: 0.00001530
Iteration 123/1000 | Loss: 0.00001530
Iteration 124/1000 | Loss: 0.00001530
Iteration 125/1000 | Loss: 0.00001530
Iteration 126/1000 | Loss: 0.00001530
Iteration 127/1000 | Loss: 0.00001530
Iteration 128/1000 | Loss: 0.00001530
Iteration 129/1000 | Loss: 0.00001530
Iteration 130/1000 | Loss: 0.00001530
Iteration 131/1000 | Loss: 0.00001530
Iteration 132/1000 | Loss: 0.00001529
Iteration 133/1000 | Loss: 0.00001529
Iteration 134/1000 | Loss: 0.00001529
Iteration 135/1000 | Loss: 0.00001529
Iteration 136/1000 | Loss: 0.00001529
Iteration 137/1000 | Loss: 0.00001529
Iteration 138/1000 | Loss: 0.00001529
Iteration 139/1000 | Loss: 0.00001529
Iteration 140/1000 | Loss: 0.00001529
Iteration 141/1000 | Loss: 0.00001529
Iteration 142/1000 | Loss: 0.00001528
Iteration 143/1000 | Loss: 0.00001528
Iteration 144/1000 | Loss: 0.00001528
Iteration 145/1000 | Loss: 0.00001528
Iteration 146/1000 | Loss: 0.00001528
Iteration 147/1000 | Loss: 0.00001528
Iteration 148/1000 | Loss: 0.00001528
Iteration 149/1000 | Loss: 0.00001528
Iteration 150/1000 | Loss: 0.00001528
Iteration 151/1000 | Loss: 0.00001528
Iteration 152/1000 | Loss: 0.00001528
Iteration 153/1000 | Loss: 0.00001528
Iteration 154/1000 | Loss: 0.00001527
Iteration 155/1000 | Loss: 0.00001527
Iteration 156/1000 | Loss: 0.00001527
Iteration 157/1000 | Loss: 0.00001527
Iteration 158/1000 | Loss: 0.00001527
Iteration 159/1000 | Loss: 0.00001527
Iteration 160/1000 | Loss: 0.00001527
Iteration 161/1000 | Loss: 0.00001527
Iteration 162/1000 | Loss: 0.00001527
Iteration 163/1000 | Loss: 0.00001527
Iteration 164/1000 | Loss: 0.00001527
Iteration 165/1000 | Loss: 0.00001527
Iteration 166/1000 | Loss: 0.00001527
Iteration 167/1000 | Loss: 0.00001527
Iteration 168/1000 | Loss: 0.00001527
Iteration 169/1000 | Loss: 0.00001527
Iteration 170/1000 | Loss: 0.00001526
Iteration 171/1000 | Loss: 0.00001526
Iteration 172/1000 | Loss: 0.00001526
Iteration 173/1000 | Loss: 0.00001526
Iteration 174/1000 | Loss: 0.00001526
Iteration 175/1000 | Loss: 0.00001526
Iteration 176/1000 | Loss: 0.00001526
Iteration 177/1000 | Loss: 0.00001526
Iteration 178/1000 | Loss: 0.00001526
Iteration 179/1000 | Loss: 0.00001526
Iteration 180/1000 | Loss: 0.00001526
Iteration 181/1000 | Loss: 0.00001526
Iteration 182/1000 | Loss: 0.00001526
Iteration 183/1000 | Loss: 0.00001526
Iteration 184/1000 | Loss: 0.00001526
Iteration 185/1000 | Loss: 0.00001526
Iteration 186/1000 | Loss: 0.00001526
Iteration 187/1000 | Loss: 0.00001526
Iteration 188/1000 | Loss: 0.00001526
Iteration 189/1000 | Loss: 0.00001526
Iteration 190/1000 | Loss: 0.00001526
Iteration 191/1000 | Loss: 0.00001526
Iteration 192/1000 | Loss: 0.00001526
Iteration 193/1000 | Loss: 0.00001526
Iteration 194/1000 | Loss: 0.00001526
Iteration 195/1000 | Loss: 0.00001526
Iteration 196/1000 | Loss: 0.00001526
Iteration 197/1000 | Loss: 0.00001526
Iteration 198/1000 | Loss: 0.00001526
Iteration 199/1000 | Loss: 0.00001526
Iteration 200/1000 | Loss: 0.00001526
Iteration 201/1000 | Loss: 0.00001526
Iteration 202/1000 | Loss: 0.00001526
Iteration 203/1000 | Loss: 0.00001526
Iteration 204/1000 | Loss: 0.00001526
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 204. Stopping optimization.
Last 5 losses: [1.525937841506675e-05, 1.525937841506675e-05, 1.525937841506675e-05, 1.525937841506675e-05, 1.525937841506675e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.525937841506675e-05

Optimization complete. Final v2v error: 3.277313232421875 mm

Highest mean error: 5.32957124710083 mm for frame 66

Lowest mean error: 2.6053736209869385 mm for frame 160

Saving results

Total time: 103.2309398651123
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0022/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0022.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0022
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00959516
Iteration 2/25 | Loss: 0.00097485
Iteration 3/25 | Loss: 0.00085763
Iteration 4/25 | Loss: 0.00081553
Iteration 5/25 | Loss: 0.00080590
Iteration 6/25 | Loss: 0.00080373
Iteration 7/25 | Loss: 0.00080373
Iteration 8/25 | Loss: 0.00080373
Iteration 9/25 | Loss: 0.00080373
Iteration 10/25 | Loss: 0.00080373
Iteration 11/25 | Loss: 0.00080373
Iteration 12/25 | Loss: 0.00080373
Iteration 13/25 | Loss: 0.00080373
Iteration 14/25 | Loss: 0.00080373
Iteration 15/25 | Loss: 0.00080373
Iteration 16/25 | Loss: 0.00080373
Iteration 17/25 | Loss: 0.00080373
Iteration 18/25 | Loss: 0.00080373
Iteration 19/25 | Loss: 0.00080373
Iteration 20/25 | Loss: 0.00080373
Iteration 21/25 | Loss: 0.00080373
Iteration 22/25 | Loss: 0.00080373
Iteration 23/25 | Loss: 0.00080373
Iteration 24/25 | Loss: 0.00080373
Iteration 25/25 | Loss: 0.00080373

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.32436359
Iteration 2/25 | Loss: 0.00031277
Iteration 3/25 | Loss: 0.00031277
Iteration 4/25 | Loss: 0.00031277
Iteration 5/25 | Loss: 0.00031277
Iteration 6/25 | Loss: 0.00031277
Iteration 7/25 | Loss: 0.00031277
Iteration 8/25 | Loss: 0.00031277
Iteration 9/25 | Loss: 0.00031277
Iteration 10/25 | Loss: 0.00031277
Iteration 11/25 | Loss: 0.00031277
Iteration 12/25 | Loss: 0.00031277
Iteration 13/25 | Loss: 0.00031277
Iteration 14/25 | Loss: 0.00031277
Iteration 15/25 | Loss: 0.00031277
Iteration 16/25 | Loss: 0.00031277
Iteration 17/25 | Loss: 0.00031277
Iteration 18/25 | Loss: 0.00031277
Iteration 19/25 | Loss: 0.00031277
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 19. Stopping optimization.
Last 5 losses: [0.00031276565277948976, 0.00031276565277948976, 0.00031276565277948976, 0.00031276565277948976, 0.00031276565277948976]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00031276565277948976

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031277
Iteration 2/1000 | Loss: 0.00004343
Iteration 3/1000 | Loss: 0.00002777
Iteration 4/1000 | Loss: 0.00002471
Iteration 5/1000 | Loss: 0.00002350
Iteration 6/1000 | Loss: 0.00002242
Iteration 7/1000 | Loss: 0.00002172
Iteration 8/1000 | Loss: 0.00002114
Iteration 9/1000 | Loss: 0.00002064
Iteration 10/1000 | Loss: 0.00002039
Iteration 11/1000 | Loss: 0.00002027
Iteration 12/1000 | Loss: 0.00002022
Iteration 13/1000 | Loss: 0.00002017
Iteration 14/1000 | Loss: 0.00002012
Iteration 15/1000 | Loss: 0.00002010
Iteration 16/1000 | Loss: 0.00002010
Iteration 17/1000 | Loss: 0.00002009
Iteration 18/1000 | Loss: 0.00002009
Iteration 19/1000 | Loss: 0.00002004
Iteration 20/1000 | Loss: 0.00002003
Iteration 21/1000 | Loss: 0.00002002
Iteration 22/1000 | Loss: 0.00002001
Iteration 23/1000 | Loss: 0.00002001
Iteration 24/1000 | Loss: 0.00001999
Iteration 25/1000 | Loss: 0.00001998
Iteration 26/1000 | Loss: 0.00001998
Iteration 27/1000 | Loss: 0.00001998
Iteration 28/1000 | Loss: 0.00001997
Iteration 29/1000 | Loss: 0.00001997
Iteration 30/1000 | Loss: 0.00001997
Iteration 31/1000 | Loss: 0.00001997
Iteration 32/1000 | Loss: 0.00001996
Iteration 33/1000 | Loss: 0.00001996
Iteration 34/1000 | Loss: 0.00001996
Iteration 35/1000 | Loss: 0.00001996
Iteration 36/1000 | Loss: 0.00001995
Iteration 37/1000 | Loss: 0.00001995
Iteration 38/1000 | Loss: 0.00001995
Iteration 39/1000 | Loss: 0.00001994
Iteration 40/1000 | Loss: 0.00001994
Iteration 41/1000 | Loss: 0.00001994
Iteration 42/1000 | Loss: 0.00001994
Iteration 43/1000 | Loss: 0.00001993
Iteration 44/1000 | Loss: 0.00001993
Iteration 45/1000 | Loss: 0.00001993
Iteration 46/1000 | Loss: 0.00001993
Iteration 47/1000 | Loss: 0.00001992
Iteration 48/1000 | Loss: 0.00001992
Iteration 49/1000 | Loss: 0.00001992
Iteration 50/1000 | Loss: 0.00001992
Iteration 51/1000 | Loss: 0.00001992
Iteration 52/1000 | Loss: 0.00001991
Iteration 53/1000 | Loss: 0.00001991
Iteration 54/1000 | Loss: 0.00001991
Iteration 55/1000 | Loss: 0.00001990
Iteration 56/1000 | Loss: 0.00001990
Iteration 57/1000 | Loss: 0.00001990
Iteration 58/1000 | Loss: 0.00001990
Iteration 59/1000 | Loss: 0.00001990
Iteration 60/1000 | Loss: 0.00001989
Iteration 61/1000 | Loss: 0.00001989
Iteration 62/1000 | Loss: 0.00001989
Iteration 63/1000 | Loss: 0.00001989
Iteration 64/1000 | Loss: 0.00001989
Iteration 65/1000 | Loss: 0.00001989
Iteration 66/1000 | Loss: 0.00001989
Iteration 67/1000 | Loss: 0.00001989
Iteration 68/1000 | Loss: 0.00001989
Iteration 69/1000 | Loss: 0.00001989
Iteration 70/1000 | Loss: 0.00001989
Iteration 71/1000 | Loss: 0.00001989
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 71. Stopping optimization.
Last 5 losses: [1.98876532522263e-05, 1.98876532522263e-05, 1.98876532522263e-05, 1.98876532522263e-05, 1.98876532522263e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.98876532522263e-05

Optimization complete. Final v2v error: 3.7237114906311035 mm

Highest mean error: 4.117070198059082 mm for frame 37

Lowest mean error: 3.1474480628967285 mm for frame 145

Saving results

Total time: 33.95608401298523
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0021/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0021.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0021
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01149948
Iteration 2/25 | Loss: 0.00146766
Iteration 3/25 | Loss: 0.00109456
Iteration 4/25 | Loss: 0.00113629
Iteration 5/25 | Loss: 0.00108749
Iteration 6/25 | Loss: 0.00101173
Iteration 7/25 | Loss: 0.00098240
Iteration 8/25 | Loss: 0.00094675
Iteration 9/25 | Loss: 0.00093376
Iteration 10/25 | Loss: 0.00091182
Iteration 11/25 | Loss: 0.00091633
Iteration 12/25 | Loss: 0.00096122
Iteration 13/25 | Loss: 0.00095822
Iteration 14/25 | Loss: 0.00088997
Iteration 15/25 | Loss: 0.00089094
Iteration 16/25 | Loss: 0.00088775
Iteration 17/25 | Loss: 0.00089022
Iteration 18/25 | Loss: 0.00089016
Iteration 19/25 | Loss: 0.00088872
Iteration 20/25 | Loss: 0.00088902
Iteration 21/25 | Loss: 0.00089009
Iteration 22/25 | Loss: 0.00088887
Iteration 23/25 | Loss: 0.00088977
Iteration 24/25 | Loss: 0.00089027
Iteration 25/25 | Loss: 0.00089026

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.49395549
Iteration 2/25 | Loss: 0.00035008
Iteration 3/25 | Loss: 0.00035005
Iteration 4/25 | Loss: 0.00035005
Iteration 5/25 | Loss: 0.00035005
Iteration 6/25 | Loss: 0.00035005
Iteration 7/25 | Loss: 0.00035005
Iteration 8/25 | Loss: 0.00035005
Iteration 9/25 | Loss: 0.00035005
Iteration 10/25 | Loss: 0.00035005
Iteration 11/25 | Loss: 0.00035005
Iteration 12/25 | Loss: 0.00035005
Iteration 13/25 | Loss: 0.00035005
Iteration 14/25 | Loss: 0.00035005
Iteration 15/25 | Loss: 0.00035005
Iteration 16/25 | Loss: 0.00035005
Iteration 17/25 | Loss: 0.00035005
Iteration 18/25 | Loss: 0.00035005
Iteration 19/25 | Loss: 0.00035005
Iteration 20/25 | Loss: 0.00035005
Iteration 21/25 | Loss: 0.00035005
Iteration 22/25 | Loss: 0.00035005
Iteration 23/25 | Loss: 0.00035005
Iteration 24/25 | Loss: 0.00035005
Iteration 25/25 | Loss: 0.00035005

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035005
Iteration 2/1000 | Loss: 0.00016528
Iteration 3/1000 | Loss: 0.00009064
Iteration 4/1000 | Loss: 0.00021911
Iteration 5/1000 | Loss: 0.00009735
Iteration 6/1000 | Loss: 0.00004273
Iteration 7/1000 | Loss: 0.00009900
Iteration 8/1000 | Loss: 0.00008828
Iteration 9/1000 | Loss: 0.00008090
Iteration 10/1000 | Loss: 0.00008696
Iteration 11/1000 | Loss: 0.00020046
Iteration 12/1000 | Loss: 0.00007997
Iteration 13/1000 | Loss: 0.00004355
Iteration 14/1000 | Loss: 0.00003425
Iteration 15/1000 | Loss: 0.00003200
Iteration 16/1000 | Loss: 0.00003115
Iteration 17/1000 | Loss: 0.00003064
Iteration 18/1000 | Loss: 0.00003023
Iteration 19/1000 | Loss: 0.00002990
Iteration 20/1000 | Loss: 0.00002965
Iteration 21/1000 | Loss: 0.00002952
Iteration 22/1000 | Loss: 0.00002952
Iteration 23/1000 | Loss: 0.00002948
Iteration 24/1000 | Loss: 0.00002946
Iteration 25/1000 | Loss: 0.00002946
Iteration 26/1000 | Loss: 0.00002946
Iteration 27/1000 | Loss: 0.00002946
Iteration 28/1000 | Loss: 0.00002945
Iteration 29/1000 | Loss: 0.00002945
Iteration 30/1000 | Loss: 0.00008023
Iteration 31/1000 | Loss: 0.00002953
Iteration 32/1000 | Loss: 0.00002949
Iteration 33/1000 | Loss: 0.00002942
Iteration 34/1000 | Loss: 0.00002942
Iteration 35/1000 | Loss: 0.00002942
Iteration 36/1000 | Loss: 0.00002938
Iteration 37/1000 | Loss: 0.00002938
Iteration 38/1000 | Loss: 0.00002937
Iteration 39/1000 | Loss: 0.00002937
Iteration 40/1000 | Loss: 0.00002937
Iteration 41/1000 | Loss: 0.00002937
Iteration 42/1000 | Loss: 0.00002937
Iteration 43/1000 | Loss: 0.00002937
Iteration 44/1000 | Loss: 0.00002936
Iteration 45/1000 | Loss: 0.00002936
Iteration 46/1000 | Loss: 0.00002936
Iteration 47/1000 | Loss: 0.00002936
Iteration 48/1000 | Loss: 0.00002936
Iteration 49/1000 | Loss: 0.00002936
Iteration 50/1000 | Loss: 0.00002935
Iteration 51/1000 | Loss: 0.00002935
Iteration 52/1000 | Loss: 0.00002935
Iteration 53/1000 | Loss: 0.00002935
Iteration 54/1000 | Loss: 0.00002935
Iteration 55/1000 | Loss: 0.00002935
Iteration 56/1000 | Loss: 0.00002935
Iteration 57/1000 | Loss: 0.00002935
Iteration 58/1000 | Loss: 0.00002935
Iteration 59/1000 | Loss: 0.00002935
Iteration 60/1000 | Loss: 0.00002935
Iteration 61/1000 | Loss: 0.00002935
Iteration 62/1000 | Loss: 0.00002935
Iteration 63/1000 | Loss: 0.00002935
Iteration 64/1000 | Loss: 0.00002935
Iteration 65/1000 | Loss: 0.00002935
Iteration 66/1000 | Loss: 0.00002935
Iteration 67/1000 | Loss: 0.00002934
Iteration 68/1000 | Loss: 0.00002934
Iteration 69/1000 | Loss: 0.00002934
Iteration 70/1000 | Loss: 0.00002934
Iteration 71/1000 | Loss: 0.00002934
Iteration 72/1000 | Loss: 0.00002934
Iteration 73/1000 | Loss: 0.00002934
Iteration 74/1000 | Loss: 0.00002934
Iteration 75/1000 | Loss: 0.00002934
Iteration 76/1000 | Loss: 0.00002934
Iteration 77/1000 | Loss: 0.00002934
Iteration 78/1000 | Loss: 0.00002934
Iteration 79/1000 | Loss: 0.00002934
Iteration 80/1000 | Loss: 0.00002934
Iteration 81/1000 | Loss: 0.00002934
Iteration 82/1000 | Loss: 0.00002934
Iteration 83/1000 | Loss: 0.00002934
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 83. Stopping optimization.
Last 5 losses: [2.9339633329072967e-05, 2.9339633329072967e-05, 2.9339633329072967e-05, 2.9339633329072967e-05, 2.9339633329072967e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.9339633329072967e-05

Optimization complete. Final v2v error: 4.6523613929748535 mm

Highest mean error: 5.107113361358643 mm for frame 14

Lowest mean error: 4.039182186126709 mm for frame 106

Saving results

Total time: 76.51362228393555
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01112264
Iteration 2/25 | Loss: 0.00252323
Iteration 3/25 | Loss: 0.00169408
Iteration 4/25 | Loss: 0.00146553
Iteration 5/25 | Loss: 0.00215517
Iteration 6/25 | Loss: 0.00229643
Iteration 7/25 | Loss: 0.00209683
Iteration 8/25 | Loss: 0.00206636
Iteration 9/25 | Loss: 0.00193546
Iteration 10/25 | Loss: 0.00164333
Iteration 11/25 | Loss: 0.00140160
Iteration 12/25 | Loss: 0.00132057
Iteration 13/25 | Loss: 0.00124584
Iteration 14/25 | Loss: 0.00123525
Iteration 15/25 | Loss: 0.00119281
Iteration 16/25 | Loss: 0.00118141
Iteration 17/25 | Loss: 0.00119387
Iteration 18/25 | Loss: 0.00115123
Iteration 19/25 | Loss: 0.00113663
Iteration 20/25 | Loss: 0.00111709
Iteration 21/25 | Loss: 0.00112585
Iteration 22/25 | Loss: 0.00112633
Iteration 23/25 | Loss: 0.00116429
Iteration 24/25 | Loss: 0.00119508
Iteration 25/25 | Loss: 0.00117653

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.34598744
Iteration 2/25 | Loss: 0.00468714
Iteration 3/25 | Loss: 0.00430659
Iteration 4/25 | Loss: 0.00430659
Iteration 5/25 | Loss: 0.00430659
Iteration 6/25 | Loss: 0.00430659
Iteration 7/25 | Loss: 0.00430659
Iteration 8/25 | Loss: 0.00430659
Iteration 9/25 | Loss: 0.00430659
Iteration 10/25 | Loss: 0.00430659
Iteration 11/25 | Loss: 0.00430659
Iteration 12/25 | Loss: 0.00430659
Iteration 13/25 | Loss: 0.00430659
Iteration 14/25 | Loss: 0.00430659
Iteration 15/25 | Loss: 0.00430659
Iteration 16/25 | Loss: 0.00430659
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0043065897189080715, 0.0043065897189080715, 0.0043065897189080715, 0.0043065897189080715, 0.0043065897189080715]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0043065897189080715

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00430659
Iteration 2/1000 | Loss: 0.00337333
Iteration 3/1000 | Loss: 0.00275253
Iteration 4/1000 | Loss: 0.00291021
Iteration 5/1000 | Loss: 0.00282435
Iteration 6/1000 | Loss: 0.00393684
Iteration 7/1000 | Loss: 0.00332442
Iteration 8/1000 | Loss: 0.00337298
Iteration 9/1000 | Loss: 0.00327243
Iteration 10/1000 | Loss: 0.00302660
Iteration 11/1000 | Loss: 0.00295573
Iteration 12/1000 | Loss: 0.00309587
Iteration 13/1000 | Loss: 0.00328254
Iteration 14/1000 | Loss: 0.00601831
Iteration 15/1000 | Loss: 0.00574354
Iteration 16/1000 | Loss: 0.00243533
Iteration 17/1000 | Loss: 0.00418461
Iteration 18/1000 | Loss: 0.00263209
Iteration 19/1000 | Loss: 0.00276669
Iteration 20/1000 | Loss: 0.00381016
Iteration 21/1000 | Loss: 0.00316243
Iteration 22/1000 | Loss: 0.00281046
Iteration 23/1000 | Loss: 0.00341770
Iteration 24/1000 | Loss: 0.00203639
Iteration 25/1000 | Loss: 0.00191309
Iteration 26/1000 | Loss: 0.00239915
Iteration 27/1000 | Loss: 0.00167026
Iteration 28/1000 | Loss: 0.00126698
Iteration 29/1000 | Loss: 0.00157817
Iteration 30/1000 | Loss: 0.00174570
Iteration 31/1000 | Loss: 0.00166369
Iteration 32/1000 | Loss: 0.00096652
Iteration 33/1000 | Loss: 0.00140092
Iteration 34/1000 | Loss: 0.00111420
Iteration 35/1000 | Loss: 0.00232748
Iteration 36/1000 | Loss: 0.00218043
Iteration 37/1000 | Loss: 0.00084198
Iteration 38/1000 | Loss: 0.00134441
Iteration 39/1000 | Loss: 0.00186350
Iteration 40/1000 | Loss: 0.00134797
Iteration 41/1000 | Loss: 0.00160429
Iteration 42/1000 | Loss: 0.00136960
Iteration 43/1000 | Loss: 0.00133897
Iteration 44/1000 | Loss: 0.00130501
Iteration 45/1000 | Loss: 0.00120313
Iteration 46/1000 | Loss: 0.00145932
Iteration 47/1000 | Loss: 0.00112304
Iteration 48/1000 | Loss: 0.00105451
Iteration 49/1000 | Loss: 0.00111878
Iteration 50/1000 | Loss: 0.00253245
Iteration 51/1000 | Loss: 0.00131511
Iteration 52/1000 | Loss: 0.00179227
Iteration 53/1000 | Loss: 0.00075070
Iteration 54/1000 | Loss: 0.00170833
Iteration 55/1000 | Loss: 0.00148119
Iteration 56/1000 | Loss: 0.00087045
Iteration 57/1000 | Loss: 0.00083811
Iteration 58/1000 | Loss: 0.00056433
Iteration 59/1000 | Loss: 0.00045726
Iteration 60/1000 | Loss: 0.00102226
Iteration 61/1000 | Loss: 0.00112015
Iteration 62/1000 | Loss: 0.00089790
Iteration 63/1000 | Loss: 0.00104258
Iteration 64/1000 | Loss: 0.00092591
Iteration 65/1000 | Loss: 0.00083494
Iteration 66/1000 | Loss: 0.00064014
Iteration 67/1000 | Loss: 0.00110758
Iteration 68/1000 | Loss: 0.00141263
Iteration 69/1000 | Loss: 0.00099477
Iteration 70/1000 | Loss: 0.00092273
Iteration 71/1000 | Loss: 0.00115582
Iteration 72/1000 | Loss: 0.00093984
Iteration 73/1000 | Loss: 0.00059123
Iteration 74/1000 | Loss: 0.00056491
Iteration 75/1000 | Loss: 0.00077566
Iteration 76/1000 | Loss: 0.00041324
Iteration 77/1000 | Loss: 0.00093548
Iteration 78/1000 | Loss: 0.00072319
Iteration 79/1000 | Loss: 0.00108256
Iteration 80/1000 | Loss: 0.00039649
Iteration 81/1000 | Loss: 0.00132075
Iteration 82/1000 | Loss: 0.00051880
Iteration 83/1000 | Loss: 0.00032052
Iteration 84/1000 | Loss: 0.00109090
Iteration 85/1000 | Loss: 0.00067841
Iteration 86/1000 | Loss: 0.00057535
Iteration 87/1000 | Loss: 0.00088931
Iteration 88/1000 | Loss: 0.00063909
Iteration 89/1000 | Loss: 0.00059923
Iteration 90/1000 | Loss: 0.00071131
Iteration 91/1000 | Loss: 0.00029032
Iteration 92/1000 | Loss: 0.00055915
Iteration 93/1000 | Loss: 0.00030948
Iteration 94/1000 | Loss: 0.00018482
Iteration 95/1000 | Loss: 0.00033816
Iteration 96/1000 | Loss: 0.00064664
Iteration 97/1000 | Loss: 0.00047260
Iteration 98/1000 | Loss: 0.00024319
Iteration 99/1000 | Loss: 0.00068795
Iteration 100/1000 | Loss: 0.00047113
Iteration 101/1000 | Loss: 0.00050809
Iteration 102/1000 | Loss: 0.00097528
Iteration 103/1000 | Loss: 0.00084797
Iteration 104/1000 | Loss: 0.00062823
Iteration 105/1000 | Loss: 0.00060582
Iteration 106/1000 | Loss: 0.00066169
Iteration 107/1000 | Loss: 0.00043694
Iteration 108/1000 | Loss: 0.00014546
Iteration 109/1000 | Loss: 0.00051602
Iteration 110/1000 | Loss: 0.00041602
Iteration 111/1000 | Loss: 0.00021933
Iteration 112/1000 | Loss: 0.00033903
Iteration 113/1000 | Loss: 0.00032352
Iteration 114/1000 | Loss: 0.00026384
Iteration 115/1000 | Loss: 0.00017222
Iteration 116/1000 | Loss: 0.00054114
Iteration 117/1000 | Loss: 0.00030964
Iteration 118/1000 | Loss: 0.00035830
Iteration 119/1000 | Loss: 0.00027202
Iteration 120/1000 | Loss: 0.00038584
Iteration 121/1000 | Loss: 0.00043773
Iteration 122/1000 | Loss: 0.00018465
Iteration 123/1000 | Loss: 0.00060910
Iteration 124/1000 | Loss: 0.00027144
Iteration 125/1000 | Loss: 0.00013119
Iteration 126/1000 | Loss: 0.00026635
Iteration 127/1000 | Loss: 0.00022480
Iteration 128/1000 | Loss: 0.00022984
Iteration 129/1000 | Loss: 0.00023883
Iteration 130/1000 | Loss: 0.00031185
Iteration 131/1000 | Loss: 0.00071616
Iteration 132/1000 | Loss: 0.00053002
Iteration 133/1000 | Loss: 0.00058324
Iteration 134/1000 | Loss: 0.00037547
Iteration 135/1000 | Loss: 0.00078476
Iteration 136/1000 | Loss: 0.00020003
Iteration 137/1000 | Loss: 0.00018275
Iteration 138/1000 | Loss: 0.00026806
Iteration 139/1000 | Loss: 0.00015174
Iteration 140/1000 | Loss: 0.00086948
Iteration 141/1000 | Loss: 0.00049271
Iteration 142/1000 | Loss: 0.00061398
Iteration 143/1000 | Loss: 0.00069338
Iteration 144/1000 | Loss: 0.00059262
Iteration 145/1000 | Loss: 0.00077142
Iteration 146/1000 | Loss: 0.00048130
Iteration 147/1000 | Loss: 0.00032673
Iteration 148/1000 | Loss: 0.00027499
Iteration 149/1000 | Loss: 0.00015981
Iteration 150/1000 | Loss: 0.00048186
Iteration 151/1000 | Loss: 0.00053306
Iteration 152/1000 | Loss: 0.00122915
Iteration 153/1000 | Loss: 0.00064969
Iteration 154/1000 | Loss: 0.00122335
Iteration 155/1000 | Loss: 0.00063603
Iteration 156/1000 | Loss: 0.00045422
Iteration 157/1000 | Loss: 0.00059195
Iteration 158/1000 | Loss: 0.00071942
Iteration 159/1000 | Loss: 0.00119481
Iteration 160/1000 | Loss: 0.00069687
Iteration 161/1000 | Loss: 0.00132922
Iteration 162/1000 | Loss: 0.00031667
Iteration 163/1000 | Loss: 0.00023414
Iteration 164/1000 | Loss: 0.00013263
Iteration 165/1000 | Loss: 0.00033230
Iteration 166/1000 | Loss: 0.00016250
Iteration 167/1000 | Loss: 0.00032281
Iteration 168/1000 | Loss: 0.00048541
Iteration 169/1000 | Loss: 0.00095882
Iteration 170/1000 | Loss: 0.00040103
Iteration 171/1000 | Loss: 0.00040381
Iteration 172/1000 | Loss: 0.00043070
Iteration 173/1000 | Loss: 0.00020976
Iteration 174/1000 | Loss: 0.00030449
Iteration 175/1000 | Loss: 0.00022468
Iteration 176/1000 | Loss: 0.00014590
Iteration 177/1000 | Loss: 0.00012834
Iteration 178/1000 | Loss: 0.00037377
Iteration 179/1000 | Loss: 0.00014568
Iteration 180/1000 | Loss: 0.00015477
Iteration 181/1000 | Loss: 0.00016478
Iteration 182/1000 | Loss: 0.00012951
Iteration 183/1000 | Loss: 0.00014129
Iteration 184/1000 | Loss: 0.00012841
Iteration 185/1000 | Loss: 0.00018510
Iteration 186/1000 | Loss: 0.00012883
Iteration 187/1000 | Loss: 0.00033490
Iteration 188/1000 | Loss: 0.00025774
Iteration 189/1000 | Loss: 0.00011989
Iteration 190/1000 | Loss: 0.00015511
Iteration 191/1000 | Loss: 0.00012987
Iteration 192/1000 | Loss: 0.00015412
Iteration 193/1000 | Loss: 0.00012695
Iteration 194/1000 | Loss: 0.00014111
Iteration 195/1000 | Loss: 0.00011589
Iteration 196/1000 | Loss: 0.00036179
Iteration 197/1000 | Loss: 0.00012016
Iteration 198/1000 | Loss: 0.00007126
Iteration 199/1000 | Loss: 0.00010140
Iteration 200/1000 | Loss: 0.00011291
Iteration 201/1000 | Loss: 0.00012961
Iteration 202/1000 | Loss: 0.00012986
Iteration 203/1000 | Loss: 0.00014613
Iteration 204/1000 | Loss: 0.00013080
Iteration 205/1000 | Loss: 0.00013878
Iteration 206/1000 | Loss: 0.00012803
Iteration 207/1000 | Loss: 0.00012290
Iteration 208/1000 | Loss: 0.00011668
Iteration 209/1000 | Loss: 0.00013775
Iteration 210/1000 | Loss: 0.00011679
Iteration 211/1000 | Loss: 0.00013356
Iteration 212/1000 | Loss: 0.00012625
Iteration 213/1000 | Loss: 0.00013385
Iteration 214/1000 | Loss: 0.00011986
Iteration 215/1000 | Loss: 0.00012901
Iteration 216/1000 | Loss: 0.00014828
Iteration 217/1000 | Loss: 0.00014810
Iteration 218/1000 | Loss: 0.00014036
Iteration 219/1000 | Loss: 0.00010543
Iteration 220/1000 | Loss: 0.00013433
Iteration 221/1000 | Loss: 0.00010583
Iteration 222/1000 | Loss: 0.00008356
Iteration 223/1000 | Loss: 0.00012601
Iteration 224/1000 | Loss: 0.00013710
Iteration 225/1000 | Loss: 0.00012943
Iteration 226/1000 | Loss: 0.00011622
Iteration 227/1000 | Loss: 0.00012667
Iteration 228/1000 | Loss: 0.00013190
Iteration 229/1000 | Loss: 0.00013380
Iteration 230/1000 | Loss: 0.00013621
Iteration 231/1000 | Loss: 0.00013426
Iteration 232/1000 | Loss: 0.00013716
Iteration 233/1000 | Loss: 0.00013611
Iteration 234/1000 | Loss: 0.00011779
Iteration 235/1000 | Loss: 0.00013338
Iteration 236/1000 | Loss: 0.00013914
Iteration 237/1000 | Loss: 0.00013018
Iteration 238/1000 | Loss: 0.00013411
Iteration 239/1000 | Loss: 0.00009794
Iteration 240/1000 | Loss: 0.00008620
Iteration 241/1000 | Loss: 0.00009110
Iteration 242/1000 | Loss: 0.00010125
Iteration 243/1000 | Loss: 0.00014710
Iteration 244/1000 | Loss: 0.00012565
Iteration 245/1000 | Loss: 0.00014180
Iteration 246/1000 | Loss: 0.00009392
Iteration 247/1000 | Loss: 0.00005444
Iteration 248/1000 | Loss: 0.00012893
Iteration 249/1000 | Loss: 0.00009613
Iteration 250/1000 | Loss: 0.00011475
Iteration 251/1000 | Loss: 0.00011337
Iteration 252/1000 | Loss: 0.00009936
Iteration 253/1000 | Loss: 0.00013740
Iteration 254/1000 | Loss: 0.00014551
Iteration 255/1000 | Loss: 0.00013151
Iteration 256/1000 | Loss: 0.00011763
Iteration 257/1000 | Loss: 0.00014664
Iteration 258/1000 | Loss: 0.00013573
Iteration 259/1000 | Loss: 0.00015474
Iteration 260/1000 | Loss: 0.00012367
Iteration 261/1000 | Loss: 0.00013272
Iteration 262/1000 | Loss: 0.00012948
Iteration 263/1000 | Loss: 0.00013912
Iteration 264/1000 | Loss: 0.00015000
Iteration 265/1000 | Loss: 0.00014077
Iteration 266/1000 | Loss: 0.00014222
Iteration 267/1000 | Loss: 0.00013166
Iteration 268/1000 | Loss: 0.00013204
Iteration 269/1000 | Loss: 0.00010986
Iteration 270/1000 | Loss: 0.00014577
Iteration 271/1000 | Loss: 0.00014479
Iteration 272/1000 | Loss: 0.00016287
Iteration 273/1000 | Loss: 0.00012981
Iteration 274/1000 | Loss: 0.00014739
Iteration 275/1000 | Loss: 0.00012623
Iteration 276/1000 | Loss: 0.00014167
Iteration 277/1000 | Loss: 0.00013188
Iteration 278/1000 | Loss: 0.00013933
Iteration 279/1000 | Loss: 0.00013694
Iteration 280/1000 | Loss: 0.00013872
Iteration 281/1000 | Loss: 0.00013661
Iteration 282/1000 | Loss: 0.00015133
Iteration 283/1000 | Loss: 0.00013913
Iteration 284/1000 | Loss: 0.00012908
Iteration 285/1000 | Loss: 0.00014146
Iteration 286/1000 | Loss: 0.00014760
Iteration 287/1000 | Loss: 0.00014496
Iteration 288/1000 | Loss: 0.00013302
Iteration 289/1000 | Loss: 0.00013158
Iteration 290/1000 | Loss: 0.00012011
Iteration 291/1000 | Loss: 0.00012970
Iteration 292/1000 | Loss: 0.00010908
Iteration 293/1000 | Loss: 0.00013105
Iteration 294/1000 | Loss: 0.00012611
Iteration 295/1000 | Loss: 0.00011595
Iteration 296/1000 | Loss: 0.00008992
Iteration 297/1000 | Loss: 0.00010826
Iteration 298/1000 | Loss: 0.00012535
Iteration 299/1000 | Loss: 0.00012279
Iteration 300/1000 | Loss: 0.00012091
Iteration 301/1000 | Loss: 0.00016053
Iteration 302/1000 | Loss: 0.00017181
Iteration 303/1000 | Loss: 0.00007131
Iteration 304/1000 | Loss: 0.00007331
Iteration 305/1000 | Loss: 0.00007424
Iteration 306/1000 | Loss: 0.00006785
Iteration 307/1000 | Loss: 0.00006896
Iteration 308/1000 | Loss: 0.00007745
Iteration 309/1000 | Loss: 0.00007518
Iteration 310/1000 | Loss: 0.00007135
Iteration 311/1000 | Loss: 0.00004925
Iteration 312/1000 | Loss: 0.00006251
Iteration 313/1000 | Loss: 0.00007472
Iteration 314/1000 | Loss: 0.00006506
Iteration 315/1000 | Loss: 0.00006222
Iteration 316/1000 | Loss: 0.00006640
Iteration 317/1000 | Loss: 0.00004587
Iteration 318/1000 | Loss: 0.00005878
Iteration 319/1000 | Loss: 0.00007056
Iteration 320/1000 | Loss: 0.00006859
Iteration 321/1000 | Loss: 0.00007211
Iteration 322/1000 | Loss: 0.00007067
Iteration 323/1000 | Loss: 0.00007732
Iteration 324/1000 | Loss: 0.00007068
Iteration 325/1000 | Loss: 0.00005326
Iteration 326/1000 | Loss: 0.00003251
Iteration 327/1000 | Loss: 0.00002597
Iteration 328/1000 | Loss: 0.00002375
Iteration 329/1000 | Loss: 0.00002264
Iteration 330/1000 | Loss: 0.00002188
Iteration 331/1000 | Loss: 0.00002119
Iteration 332/1000 | Loss: 0.00002076
Iteration 333/1000 | Loss: 0.00002035
Iteration 334/1000 | Loss: 0.00002009
Iteration 335/1000 | Loss: 0.00001991
Iteration 336/1000 | Loss: 0.00001988
Iteration 337/1000 | Loss: 0.00001988
Iteration 338/1000 | Loss: 0.00001987
Iteration 339/1000 | Loss: 0.00001982
Iteration 340/1000 | Loss: 0.00001981
Iteration 341/1000 | Loss: 0.00001979
Iteration 342/1000 | Loss: 0.00001968
Iteration 343/1000 | Loss: 0.00001966
Iteration 344/1000 | Loss: 0.00001965
Iteration 345/1000 | Loss: 0.00001965
Iteration 346/1000 | Loss: 0.00001965
Iteration 347/1000 | Loss: 0.00001965
Iteration 348/1000 | Loss: 0.00001965
Iteration 349/1000 | Loss: 0.00001965
Iteration 350/1000 | Loss: 0.00001965
Iteration 351/1000 | Loss: 0.00001964
Iteration 352/1000 | Loss: 0.00001962
Iteration 353/1000 | Loss: 0.00001961
Iteration 354/1000 | Loss: 0.00001961
Iteration 355/1000 | Loss: 0.00001961
Iteration 356/1000 | Loss: 0.00001960
Iteration 357/1000 | Loss: 0.00001960
Iteration 358/1000 | Loss: 0.00001960
Iteration 359/1000 | Loss: 0.00001959
Iteration 360/1000 | Loss: 0.00001959
Iteration 361/1000 | Loss: 0.00001959
Iteration 362/1000 | Loss: 0.00001959
Iteration 363/1000 | Loss: 0.00001958
Iteration 364/1000 | Loss: 0.00001958
Iteration 365/1000 | Loss: 0.00001958
Iteration 366/1000 | Loss: 0.00001958
Iteration 367/1000 | Loss: 0.00001958
Iteration 368/1000 | Loss: 0.00001957
Iteration 369/1000 | Loss: 0.00001957
Iteration 370/1000 | Loss: 0.00001956
Iteration 371/1000 | Loss: 0.00001956
Iteration 372/1000 | Loss: 0.00001956
Iteration 373/1000 | Loss: 0.00001956
Iteration 374/1000 | Loss: 0.00001955
Iteration 375/1000 | Loss: 0.00001955
Iteration 376/1000 | Loss: 0.00001954
Iteration 377/1000 | Loss: 0.00001954
Iteration 378/1000 | Loss: 0.00001954
Iteration 379/1000 | Loss: 0.00001953
Iteration 380/1000 | Loss: 0.00001953
Iteration 381/1000 | Loss: 0.00001953
Iteration 382/1000 | Loss: 0.00001953
Iteration 383/1000 | Loss: 0.00001953
Iteration 384/1000 | Loss: 0.00001953
Iteration 385/1000 | Loss: 0.00001953
Iteration 386/1000 | Loss: 0.00001953
Iteration 387/1000 | Loss: 0.00001952
Iteration 388/1000 | Loss: 0.00001952
Iteration 389/1000 | Loss: 0.00001952
Iteration 390/1000 | Loss: 0.00001952
Iteration 391/1000 | Loss: 0.00001952
Iteration 392/1000 | Loss: 0.00001952
Iteration 393/1000 | Loss: 0.00001952
Iteration 394/1000 | Loss: 0.00001952
Iteration 395/1000 | Loss: 0.00001951
Iteration 396/1000 | Loss: 0.00001951
Iteration 397/1000 | Loss: 0.00001950
Iteration 398/1000 | Loss: 0.00001950
Iteration 399/1000 | Loss: 0.00001950
Iteration 400/1000 | Loss: 0.00001950
Iteration 401/1000 | Loss: 0.00001950
Iteration 402/1000 | Loss: 0.00001950
Iteration 403/1000 | Loss: 0.00001950
Iteration 404/1000 | Loss: 0.00001950
Iteration 405/1000 | Loss: 0.00001950
Iteration 406/1000 | Loss: 0.00001950
Iteration 407/1000 | Loss: 0.00001950
Iteration 408/1000 | Loss: 0.00001950
Iteration 409/1000 | Loss: 0.00001950
Iteration 410/1000 | Loss: 0.00001949
Iteration 411/1000 | Loss: 0.00001949
Iteration 412/1000 | Loss: 0.00001949
Iteration 413/1000 | Loss: 0.00001949
Iteration 414/1000 | Loss: 0.00001949
Iteration 415/1000 | Loss: 0.00001949
Iteration 416/1000 | Loss: 0.00001949
Iteration 417/1000 | Loss: 0.00001949
Iteration 418/1000 | Loss: 0.00001949
Iteration 419/1000 | Loss: 0.00001949
Iteration 420/1000 | Loss: 0.00001949
Iteration 421/1000 | Loss: 0.00001949
Iteration 422/1000 | Loss: 0.00001949
Iteration 423/1000 | Loss: 0.00001949
Iteration 424/1000 | Loss: 0.00001948
Iteration 425/1000 | Loss: 0.00001948
Iteration 426/1000 | Loss: 0.00001948
Iteration 427/1000 | Loss: 0.00001948
Iteration 428/1000 | Loss: 0.00001948
Iteration 429/1000 | Loss: 0.00001948
Iteration 430/1000 | Loss: 0.00001948
Iteration 431/1000 | Loss: 0.00001948
Iteration 432/1000 | Loss: 0.00001948
Iteration 433/1000 | Loss: 0.00001948
Iteration 434/1000 | Loss: 0.00001948
Iteration 435/1000 | Loss: 0.00001948
Iteration 436/1000 | Loss: 0.00001948
Iteration 437/1000 | Loss: 0.00001948
Iteration 438/1000 | Loss: 0.00001948
Iteration 439/1000 | Loss: 0.00001948
Iteration 440/1000 | Loss: 0.00001948
Iteration 441/1000 | Loss: 0.00001947
Iteration 442/1000 | Loss: 0.00001947
Iteration 443/1000 | Loss: 0.00001947
Iteration 444/1000 | Loss: 0.00001947
Iteration 445/1000 | Loss: 0.00001947
Iteration 446/1000 | Loss: 0.00001947
Iteration 447/1000 | Loss: 0.00001947
Iteration 448/1000 | Loss: 0.00001947
Iteration 449/1000 | Loss: 0.00001947
Iteration 450/1000 | Loss: 0.00001947
Iteration 451/1000 | Loss: 0.00001947
Iteration 452/1000 | Loss: 0.00001947
Iteration 453/1000 | Loss: 0.00001947
Iteration 454/1000 | Loss: 0.00001947
Iteration 455/1000 | Loss: 0.00001947
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 455. Stopping optimization.
Last 5 losses: [1.9468769096420147e-05, 1.9468769096420147e-05, 1.9468769096420147e-05, 1.9468769096420147e-05, 1.9468769096420147e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9468769096420147e-05

Optimization complete. Final v2v error: 3.7867748737335205 mm

Highest mean error: 4.129026412963867 mm for frame 191

Lowest mean error: 3.374263048171997 mm for frame 49

Saving results

Total time: 530.3763332366943
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0005/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0005.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0005
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00464331
Iteration 2/25 | Loss: 0.00102816
Iteration 3/25 | Loss: 0.00077804
Iteration 4/25 | Loss: 0.00074677
Iteration 5/25 | Loss: 0.00074101
Iteration 6/25 | Loss: 0.00074007
Iteration 7/25 | Loss: 0.00074007
Iteration 8/25 | Loss: 0.00074007
Iteration 9/25 | Loss: 0.00074007
Iteration 10/25 | Loss: 0.00074007
Iteration 11/25 | Loss: 0.00074007
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007400688482448459, 0.0007400688482448459, 0.0007400688482448459, 0.0007400688482448459, 0.0007400688482448459]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007400688482448459

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.37609208
Iteration 2/25 | Loss: 0.00039851
Iteration 3/25 | Loss: 0.00039850
Iteration 4/25 | Loss: 0.00039850
Iteration 5/25 | Loss: 0.00039850
Iteration 6/25 | Loss: 0.00039850
Iteration 7/25 | Loss: 0.00039850
Iteration 8/25 | Loss: 0.00039850
Iteration 9/25 | Loss: 0.00039850
Iteration 10/25 | Loss: 0.00039850
Iteration 11/25 | Loss: 0.00039850
Iteration 12/25 | Loss: 0.00039850
Iteration 13/25 | Loss: 0.00039850
Iteration 14/25 | Loss: 0.00039850
Iteration 15/25 | Loss: 0.00039850
Iteration 16/25 | Loss: 0.00039850
Iteration 17/25 | Loss: 0.00039850
Iteration 18/25 | Loss: 0.00039850
Iteration 19/25 | Loss: 0.00039850
Iteration 20/25 | Loss: 0.00039850
Iteration 21/25 | Loss: 0.00039850
Iteration 22/25 | Loss: 0.00039850
Iteration 23/25 | Loss: 0.00039850
Iteration 24/25 | Loss: 0.00039850
Iteration 25/25 | Loss: 0.00039850

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039850
Iteration 2/1000 | Loss: 0.00002918
Iteration 3/1000 | Loss: 0.00001723
Iteration 4/1000 | Loss: 0.00001585
Iteration 5/1000 | Loss: 0.00001521
Iteration 6/1000 | Loss: 0.00001470
Iteration 7/1000 | Loss: 0.00001423
Iteration 8/1000 | Loss: 0.00001399
Iteration 9/1000 | Loss: 0.00001385
Iteration 10/1000 | Loss: 0.00001379
Iteration 11/1000 | Loss: 0.00001378
Iteration 12/1000 | Loss: 0.00001378
Iteration 13/1000 | Loss: 0.00001378
Iteration 14/1000 | Loss: 0.00001369
Iteration 15/1000 | Loss: 0.00001365
Iteration 16/1000 | Loss: 0.00001364
Iteration 17/1000 | Loss: 0.00001363
Iteration 18/1000 | Loss: 0.00001347
Iteration 19/1000 | Loss: 0.00001339
Iteration 20/1000 | Loss: 0.00001337
Iteration 21/1000 | Loss: 0.00001335
Iteration 22/1000 | Loss: 0.00001335
Iteration 23/1000 | Loss: 0.00001334
Iteration 24/1000 | Loss: 0.00001333
Iteration 25/1000 | Loss: 0.00001333
Iteration 26/1000 | Loss: 0.00001333
Iteration 27/1000 | Loss: 0.00001332
Iteration 28/1000 | Loss: 0.00001332
Iteration 29/1000 | Loss: 0.00001332
Iteration 30/1000 | Loss: 0.00001331
Iteration 31/1000 | Loss: 0.00001330
Iteration 32/1000 | Loss: 0.00001330
Iteration 33/1000 | Loss: 0.00001330
Iteration 34/1000 | Loss: 0.00001329
Iteration 35/1000 | Loss: 0.00001329
Iteration 36/1000 | Loss: 0.00001328
Iteration 37/1000 | Loss: 0.00001327
Iteration 38/1000 | Loss: 0.00001327
Iteration 39/1000 | Loss: 0.00001327
Iteration 40/1000 | Loss: 0.00001326
Iteration 41/1000 | Loss: 0.00001326
Iteration 42/1000 | Loss: 0.00001325
Iteration 43/1000 | Loss: 0.00001324
Iteration 44/1000 | Loss: 0.00001324
Iteration 45/1000 | Loss: 0.00001324
Iteration 46/1000 | Loss: 0.00001324
Iteration 47/1000 | Loss: 0.00001324
Iteration 48/1000 | Loss: 0.00001324
Iteration 49/1000 | Loss: 0.00001324
Iteration 50/1000 | Loss: 0.00001324
Iteration 51/1000 | Loss: 0.00001324
Iteration 52/1000 | Loss: 0.00001324
Iteration 53/1000 | Loss: 0.00001324
Iteration 54/1000 | Loss: 0.00001323
Iteration 55/1000 | Loss: 0.00001323
Iteration 56/1000 | Loss: 0.00001323
Iteration 57/1000 | Loss: 0.00001323
Iteration 58/1000 | Loss: 0.00001323
Iteration 59/1000 | Loss: 0.00001323
Iteration 60/1000 | Loss: 0.00001322
Iteration 61/1000 | Loss: 0.00001322
Iteration 62/1000 | Loss: 0.00001321
Iteration 63/1000 | Loss: 0.00001320
Iteration 64/1000 | Loss: 0.00001320
Iteration 65/1000 | Loss: 0.00001320
Iteration 66/1000 | Loss: 0.00001320
Iteration 67/1000 | Loss: 0.00001320
Iteration 68/1000 | Loss: 0.00001320
Iteration 69/1000 | Loss: 0.00001320
Iteration 70/1000 | Loss: 0.00001319
Iteration 71/1000 | Loss: 0.00001319
Iteration 72/1000 | Loss: 0.00001318
Iteration 73/1000 | Loss: 0.00001318
Iteration 74/1000 | Loss: 0.00001318
Iteration 75/1000 | Loss: 0.00001318
Iteration 76/1000 | Loss: 0.00001318
Iteration 77/1000 | Loss: 0.00001318
Iteration 78/1000 | Loss: 0.00001318
Iteration 79/1000 | Loss: 0.00001318
Iteration 80/1000 | Loss: 0.00001318
Iteration 81/1000 | Loss: 0.00001318
Iteration 82/1000 | Loss: 0.00001318
Iteration 83/1000 | Loss: 0.00001318
Iteration 84/1000 | Loss: 0.00001318
Iteration 85/1000 | Loss: 0.00001318
Iteration 86/1000 | Loss: 0.00001318
Iteration 87/1000 | Loss: 0.00001317
Iteration 88/1000 | Loss: 0.00001317
Iteration 89/1000 | Loss: 0.00001317
Iteration 90/1000 | Loss: 0.00001317
Iteration 91/1000 | Loss: 0.00001317
Iteration 92/1000 | Loss: 0.00001317
Iteration 93/1000 | Loss: 0.00001317
Iteration 94/1000 | Loss: 0.00001317
Iteration 95/1000 | Loss: 0.00001317
Iteration 96/1000 | Loss: 0.00001317
Iteration 97/1000 | Loss: 0.00001317
Iteration 98/1000 | Loss: 0.00001317
Iteration 99/1000 | Loss: 0.00001317
Iteration 100/1000 | Loss: 0.00001317
Iteration 101/1000 | Loss: 0.00001317
Iteration 102/1000 | Loss: 0.00001317
Iteration 103/1000 | Loss: 0.00001317
Iteration 104/1000 | Loss: 0.00001317
Iteration 105/1000 | Loss: 0.00001317
Iteration 106/1000 | Loss: 0.00001317
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 106. Stopping optimization.
Last 5 losses: [1.316807720286306e-05, 1.316807720286306e-05, 1.316807720286306e-05, 1.316807720286306e-05, 1.316807720286306e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.316807720286306e-05

Optimization complete. Final v2v error: 3.0627377033233643 mm

Highest mean error: 3.57661509513855 mm for frame 0

Lowest mean error: 2.7837932109832764 mm for frame 43

Saving results

Total time: 30.397336959838867
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0010/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0010.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0010
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00894174
Iteration 2/25 | Loss: 0.00092000
Iteration 3/25 | Loss: 0.00074444
Iteration 4/25 | Loss: 0.00071911
Iteration 5/25 | Loss: 0.00070911
Iteration 6/25 | Loss: 0.00070771
Iteration 7/25 | Loss: 0.00070771
Iteration 8/25 | Loss: 0.00070771
Iteration 9/25 | Loss: 0.00070771
Iteration 10/25 | Loss: 0.00070771
Iteration 11/25 | Loss: 0.00070771
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.000707711442373693, 0.000707711442373693, 0.000707711442373693, 0.000707711442373693, 0.000707711442373693]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000707711442373693

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.38517880
Iteration 2/25 | Loss: 0.00032249
Iteration 3/25 | Loss: 0.00032249
Iteration 4/25 | Loss: 0.00032249
Iteration 5/25 | Loss: 0.00032249
Iteration 6/25 | Loss: 0.00032249
Iteration 7/25 | Loss: 0.00032249
Iteration 8/25 | Loss: 0.00032249
Iteration 9/25 | Loss: 0.00032249
Iteration 10/25 | Loss: 0.00032249
Iteration 11/25 | Loss: 0.00032249
Iteration 12/25 | Loss: 0.00032249
Iteration 13/25 | Loss: 0.00032249
Iteration 14/25 | Loss: 0.00032249
Iteration 15/25 | Loss: 0.00032249
Iteration 16/25 | Loss: 0.00032249
Iteration 17/25 | Loss: 0.00032249
Iteration 18/25 | Loss: 0.00032249
Iteration 19/25 | Loss: 0.00032249
Iteration 20/25 | Loss: 0.00032249
Iteration 21/25 | Loss: 0.00032249
Iteration 22/25 | Loss: 0.00032249
Iteration 23/25 | Loss: 0.00032249
Iteration 24/25 | Loss: 0.00032249
Iteration 25/25 | Loss: 0.00032249
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00032248743809759617, 0.00032248743809759617, 0.00032248743809759617, 0.00032248743809759617, 0.00032248743809759617]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00032248743809759617

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00032249
Iteration 2/1000 | Loss: 0.00003158
Iteration 3/1000 | Loss: 0.00001899
Iteration 4/1000 | Loss: 0.00001730
Iteration 5/1000 | Loss: 0.00001598
Iteration 6/1000 | Loss: 0.00001537
Iteration 7/1000 | Loss: 0.00001497
Iteration 8/1000 | Loss: 0.00001459
Iteration 9/1000 | Loss: 0.00001442
Iteration 10/1000 | Loss: 0.00001441
Iteration 11/1000 | Loss: 0.00001441
Iteration 12/1000 | Loss: 0.00001439
Iteration 13/1000 | Loss: 0.00001433
Iteration 14/1000 | Loss: 0.00001432
Iteration 15/1000 | Loss: 0.00001431
Iteration 16/1000 | Loss: 0.00001430
Iteration 17/1000 | Loss: 0.00001428
Iteration 18/1000 | Loss: 0.00001427
Iteration 19/1000 | Loss: 0.00001427
Iteration 20/1000 | Loss: 0.00001427
Iteration 21/1000 | Loss: 0.00001427
Iteration 22/1000 | Loss: 0.00001426
Iteration 23/1000 | Loss: 0.00001425
Iteration 24/1000 | Loss: 0.00001419
Iteration 25/1000 | Loss: 0.00001416
Iteration 26/1000 | Loss: 0.00001416
Iteration 27/1000 | Loss: 0.00001416
Iteration 28/1000 | Loss: 0.00001415
Iteration 29/1000 | Loss: 0.00001415
Iteration 30/1000 | Loss: 0.00001414
Iteration 31/1000 | Loss: 0.00001414
Iteration 32/1000 | Loss: 0.00001413
Iteration 33/1000 | Loss: 0.00001413
Iteration 34/1000 | Loss: 0.00001413
Iteration 35/1000 | Loss: 0.00001412
Iteration 36/1000 | Loss: 0.00001412
Iteration 37/1000 | Loss: 0.00001412
Iteration 38/1000 | Loss: 0.00001412
Iteration 39/1000 | Loss: 0.00001411
Iteration 40/1000 | Loss: 0.00001411
Iteration 41/1000 | Loss: 0.00001411
Iteration 42/1000 | Loss: 0.00001411
Iteration 43/1000 | Loss: 0.00001411
Iteration 44/1000 | Loss: 0.00001411
Iteration 45/1000 | Loss: 0.00001411
Iteration 46/1000 | Loss: 0.00001411
Iteration 47/1000 | Loss: 0.00001411
Iteration 48/1000 | Loss: 0.00001411
Iteration 49/1000 | Loss: 0.00001410
Iteration 50/1000 | Loss: 0.00001410
Iteration 51/1000 | Loss: 0.00001410
Iteration 52/1000 | Loss: 0.00001410
Iteration 53/1000 | Loss: 0.00001410
Iteration 54/1000 | Loss: 0.00001410
Iteration 55/1000 | Loss: 0.00001410
Iteration 56/1000 | Loss: 0.00001410
Iteration 57/1000 | Loss: 0.00001410
Iteration 58/1000 | Loss: 0.00001410
Iteration 59/1000 | Loss: 0.00001410
Iteration 60/1000 | Loss: 0.00001410
Iteration 61/1000 | Loss: 0.00001410
Iteration 62/1000 | Loss: 0.00001409
Iteration 63/1000 | Loss: 0.00001409
Iteration 64/1000 | Loss: 0.00001408
Iteration 65/1000 | Loss: 0.00001408
Iteration 66/1000 | Loss: 0.00001408
Iteration 67/1000 | Loss: 0.00001407
Iteration 68/1000 | Loss: 0.00001407
Iteration 69/1000 | Loss: 0.00001407
Iteration 70/1000 | Loss: 0.00001406
Iteration 71/1000 | Loss: 0.00001406
Iteration 72/1000 | Loss: 0.00001405
Iteration 73/1000 | Loss: 0.00001405
Iteration 74/1000 | Loss: 0.00001405
Iteration 75/1000 | Loss: 0.00001404
Iteration 76/1000 | Loss: 0.00001404
Iteration 77/1000 | Loss: 0.00001404
Iteration 78/1000 | Loss: 0.00001404
Iteration 79/1000 | Loss: 0.00001404
Iteration 80/1000 | Loss: 0.00001404
Iteration 81/1000 | Loss: 0.00001404
Iteration 82/1000 | Loss: 0.00001404
Iteration 83/1000 | Loss: 0.00001404
Iteration 84/1000 | Loss: 0.00001404
Iteration 85/1000 | Loss: 0.00001404
Iteration 86/1000 | Loss: 0.00001404
Iteration 87/1000 | Loss: 0.00001403
Iteration 88/1000 | Loss: 0.00001403
Iteration 89/1000 | Loss: 0.00001403
Iteration 90/1000 | Loss: 0.00001403
Iteration 91/1000 | Loss: 0.00001403
Iteration 92/1000 | Loss: 0.00001403
Iteration 93/1000 | Loss: 0.00001402
Iteration 94/1000 | Loss: 0.00001402
Iteration 95/1000 | Loss: 0.00001402
Iteration 96/1000 | Loss: 0.00001401
Iteration 97/1000 | Loss: 0.00001401
Iteration 98/1000 | Loss: 0.00001401
Iteration 99/1000 | Loss: 0.00001401
Iteration 100/1000 | Loss: 0.00001400
Iteration 101/1000 | Loss: 0.00001400
Iteration 102/1000 | Loss: 0.00001400
Iteration 103/1000 | Loss: 0.00001400
Iteration 104/1000 | Loss: 0.00001400
Iteration 105/1000 | Loss: 0.00001400
Iteration 106/1000 | Loss: 0.00001399
Iteration 107/1000 | Loss: 0.00001399
Iteration 108/1000 | Loss: 0.00001399
Iteration 109/1000 | Loss: 0.00001399
Iteration 110/1000 | Loss: 0.00001398
Iteration 111/1000 | Loss: 0.00001398
Iteration 112/1000 | Loss: 0.00001398
Iteration 113/1000 | Loss: 0.00001398
Iteration 114/1000 | Loss: 0.00001398
Iteration 115/1000 | Loss: 0.00001398
Iteration 116/1000 | Loss: 0.00001398
Iteration 117/1000 | Loss: 0.00001397
Iteration 118/1000 | Loss: 0.00001397
Iteration 119/1000 | Loss: 0.00001397
Iteration 120/1000 | Loss: 0.00001397
Iteration 121/1000 | Loss: 0.00001397
Iteration 122/1000 | Loss: 0.00001397
Iteration 123/1000 | Loss: 0.00001397
Iteration 124/1000 | Loss: 0.00001397
Iteration 125/1000 | Loss: 0.00001397
Iteration 126/1000 | Loss: 0.00001397
Iteration 127/1000 | Loss: 0.00001397
Iteration 128/1000 | Loss: 0.00001397
Iteration 129/1000 | Loss: 0.00001397
Iteration 130/1000 | Loss: 0.00001397
Iteration 131/1000 | Loss: 0.00001397
Iteration 132/1000 | Loss: 0.00001397
Iteration 133/1000 | Loss: 0.00001397
Iteration 134/1000 | Loss: 0.00001397
Iteration 135/1000 | Loss: 0.00001397
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 135. Stopping optimization.
Last 5 losses: [1.3970118743600324e-05, 1.3970118743600324e-05, 1.3970118743600324e-05, 1.3970118743600324e-05, 1.3970118743600324e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.3970118743600324e-05

Optimization complete. Final v2v error: 3.201946258544922 mm

Highest mean error: 3.5423569679260254 mm for frame 31

Lowest mean error: 2.9168343544006348 mm for frame 265

Saving results

Total time: 36.277167558670044
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0004/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0004.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0004
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00678940
Iteration 2/25 | Loss: 0.00096204
Iteration 3/25 | Loss: 0.00077220
Iteration 4/25 | Loss: 0.00073989
Iteration 5/25 | Loss: 0.00072970
Iteration 6/25 | Loss: 0.00072765
Iteration 7/25 | Loss: 0.00072742
Iteration 8/25 | Loss: 0.00072742
Iteration 9/25 | Loss: 0.00072742
Iteration 10/25 | Loss: 0.00072742
Iteration 11/25 | Loss: 0.00072742
Iteration 12/25 | Loss: 0.00072742
Iteration 13/25 | Loss: 0.00072742
Iteration 14/25 | Loss: 0.00072742
Iteration 15/25 | Loss: 0.00072742
Iteration 16/25 | Loss: 0.00072742
Iteration 17/25 | Loss: 0.00072742
Iteration 18/25 | Loss: 0.00072742
Iteration 19/25 | Loss: 0.00072742
Iteration 20/25 | Loss: 0.00072742
Iteration 21/25 | Loss: 0.00072742
Iteration 22/25 | Loss: 0.00072742
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.0007274242234416306, 0.0007274242234416306, 0.0007274242234416306, 0.0007274242234416306, 0.0007274242234416306]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007274242234416306

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.09914827
Iteration 2/25 | Loss: 0.00023260
Iteration 3/25 | Loss: 0.00023250
Iteration 4/25 | Loss: 0.00023250
Iteration 5/25 | Loss: 0.00023250
Iteration 6/25 | Loss: 0.00023250
Iteration 7/25 | Loss: 0.00023250
Iteration 8/25 | Loss: 0.00023250
Iteration 9/25 | Loss: 0.00023250
Iteration 10/25 | Loss: 0.00023250
Iteration 11/25 | Loss: 0.00023250
Iteration 12/25 | Loss: 0.00023250
Iteration 13/25 | Loss: 0.00023250
Iteration 14/25 | Loss: 0.00023250
Iteration 15/25 | Loss: 0.00023250
Iteration 16/25 | Loss: 0.00023250
Iteration 17/25 | Loss: 0.00023250
Iteration 18/25 | Loss: 0.00023250
Iteration 19/25 | Loss: 0.00023250
Iteration 20/25 | Loss: 0.00023250
Iteration 21/25 | Loss: 0.00023250
Iteration 22/25 | Loss: 0.00023250
Iteration 23/25 | Loss: 0.00023250
Iteration 24/25 | Loss: 0.00023250
Iteration 25/25 | Loss: 0.00023250

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00023250
Iteration 2/1000 | Loss: 0.00003519
Iteration 3/1000 | Loss: 0.00002447
Iteration 4/1000 | Loss: 0.00002265
Iteration 5/1000 | Loss: 0.00002105
Iteration 6/1000 | Loss: 0.00002010
Iteration 7/1000 | Loss: 0.00001944
Iteration 8/1000 | Loss: 0.00001905
Iteration 9/1000 | Loss: 0.00001886
Iteration 10/1000 | Loss: 0.00001876
Iteration 11/1000 | Loss: 0.00001875
Iteration 12/1000 | Loss: 0.00001874
Iteration 13/1000 | Loss: 0.00001871
Iteration 14/1000 | Loss: 0.00001870
Iteration 15/1000 | Loss: 0.00001869
Iteration 16/1000 | Loss: 0.00001868
Iteration 17/1000 | Loss: 0.00001861
Iteration 18/1000 | Loss: 0.00001861
Iteration 19/1000 | Loss: 0.00001861
Iteration 20/1000 | Loss: 0.00001860
Iteration 21/1000 | Loss: 0.00001860
Iteration 22/1000 | Loss: 0.00001860
Iteration 23/1000 | Loss: 0.00001859
Iteration 24/1000 | Loss: 0.00001859
Iteration 25/1000 | Loss: 0.00001858
Iteration 26/1000 | Loss: 0.00001858
Iteration 27/1000 | Loss: 0.00001857
Iteration 28/1000 | Loss: 0.00001857
Iteration 29/1000 | Loss: 0.00001857
Iteration 30/1000 | Loss: 0.00001857
Iteration 31/1000 | Loss: 0.00001857
Iteration 32/1000 | Loss: 0.00001856
Iteration 33/1000 | Loss: 0.00001856
Iteration 34/1000 | Loss: 0.00001856
Iteration 35/1000 | Loss: 0.00001856
Iteration 36/1000 | Loss: 0.00001856
Iteration 37/1000 | Loss: 0.00001855
Iteration 38/1000 | Loss: 0.00001855
Iteration 39/1000 | Loss: 0.00001855
Iteration 40/1000 | Loss: 0.00001854
Iteration 41/1000 | Loss: 0.00001854
Iteration 42/1000 | Loss: 0.00001854
Iteration 43/1000 | Loss: 0.00001853
Iteration 44/1000 | Loss: 0.00001853
Iteration 45/1000 | Loss: 0.00001853
Iteration 46/1000 | Loss: 0.00001853
Iteration 47/1000 | Loss: 0.00001853
Iteration 48/1000 | Loss: 0.00001852
Iteration 49/1000 | Loss: 0.00001852
Iteration 50/1000 | Loss: 0.00001852
Iteration 51/1000 | Loss: 0.00001851
Iteration 52/1000 | Loss: 0.00001851
Iteration 53/1000 | Loss: 0.00001851
Iteration 54/1000 | Loss: 0.00001850
Iteration 55/1000 | Loss: 0.00001850
Iteration 56/1000 | Loss: 0.00001850
Iteration 57/1000 | Loss: 0.00001850
Iteration 58/1000 | Loss: 0.00001849
Iteration 59/1000 | Loss: 0.00001849
Iteration 60/1000 | Loss: 0.00001849
Iteration 61/1000 | Loss: 0.00001849
Iteration 62/1000 | Loss: 0.00001849
Iteration 63/1000 | Loss: 0.00001849
Iteration 64/1000 | Loss: 0.00001849
Iteration 65/1000 | Loss: 0.00001848
Iteration 66/1000 | Loss: 0.00001848
Iteration 67/1000 | Loss: 0.00001848
Iteration 68/1000 | Loss: 0.00001848
Iteration 69/1000 | Loss: 0.00001848
Iteration 70/1000 | Loss: 0.00001847
Iteration 71/1000 | Loss: 0.00001847
Iteration 72/1000 | Loss: 0.00001847
Iteration 73/1000 | Loss: 0.00001847
Iteration 74/1000 | Loss: 0.00001846
Iteration 75/1000 | Loss: 0.00001846
Iteration 76/1000 | Loss: 0.00001846
Iteration 77/1000 | Loss: 0.00001845
Iteration 78/1000 | Loss: 0.00001845
Iteration 79/1000 | Loss: 0.00001845
Iteration 80/1000 | Loss: 0.00001845
Iteration 81/1000 | Loss: 0.00001845
Iteration 82/1000 | Loss: 0.00001845
Iteration 83/1000 | Loss: 0.00001844
Iteration 84/1000 | Loss: 0.00001844
Iteration 85/1000 | Loss: 0.00001843
Iteration 86/1000 | Loss: 0.00001843
Iteration 87/1000 | Loss: 0.00001842
Iteration 88/1000 | Loss: 0.00001842
Iteration 89/1000 | Loss: 0.00001842
Iteration 90/1000 | Loss: 0.00001841
Iteration 91/1000 | Loss: 0.00001841
Iteration 92/1000 | Loss: 0.00001841
Iteration 93/1000 | Loss: 0.00001840
Iteration 94/1000 | Loss: 0.00001840
Iteration 95/1000 | Loss: 0.00001840
Iteration 96/1000 | Loss: 0.00001840
Iteration 97/1000 | Loss: 0.00001840
Iteration 98/1000 | Loss: 0.00001839
Iteration 99/1000 | Loss: 0.00001839
Iteration 100/1000 | Loss: 0.00001839
Iteration 101/1000 | Loss: 0.00001839
Iteration 102/1000 | Loss: 0.00001839
Iteration 103/1000 | Loss: 0.00001839
Iteration 104/1000 | Loss: 0.00001839
Iteration 105/1000 | Loss: 0.00001839
Iteration 106/1000 | Loss: 0.00001839
Iteration 107/1000 | Loss: 0.00001839
Iteration 108/1000 | Loss: 0.00001839
Iteration 109/1000 | Loss: 0.00001838
Iteration 110/1000 | Loss: 0.00001838
Iteration 111/1000 | Loss: 0.00001838
Iteration 112/1000 | Loss: 0.00001838
Iteration 113/1000 | Loss: 0.00001838
Iteration 114/1000 | Loss: 0.00001838
Iteration 115/1000 | Loss: 0.00001838
Iteration 116/1000 | Loss: 0.00001838
Iteration 117/1000 | Loss: 0.00001838
Iteration 118/1000 | Loss: 0.00001838
Iteration 119/1000 | Loss: 0.00001838
Iteration 120/1000 | Loss: 0.00001838
Iteration 121/1000 | Loss: 0.00001838
Iteration 122/1000 | Loss: 0.00001838
Iteration 123/1000 | Loss: 0.00001838
Iteration 124/1000 | Loss: 0.00001838
Iteration 125/1000 | Loss: 0.00001838
Iteration 126/1000 | Loss: 0.00001838
Iteration 127/1000 | Loss: 0.00001838
Iteration 128/1000 | Loss: 0.00001837
Iteration 129/1000 | Loss: 0.00001837
Iteration 130/1000 | Loss: 0.00001837
Iteration 131/1000 | Loss: 0.00001837
Iteration 132/1000 | Loss: 0.00001837
Iteration 133/1000 | Loss: 0.00001837
Iteration 134/1000 | Loss: 0.00001837
Iteration 135/1000 | Loss: 0.00001837
Iteration 136/1000 | Loss: 0.00001837
Iteration 137/1000 | Loss: 0.00001837
Iteration 138/1000 | Loss: 0.00001837
Iteration 139/1000 | Loss: 0.00001837
Iteration 140/1000 | Loss: 0.00001837
Iteration 141/1000 | Loss: 0.00001837
Iteration 142/1000 | Loss: 0.00001837
Iteration 143/1000 | Loss: 0.00001837
Iteration 144/1000 | Loss: 0.00001837
Iteration 145/1000 | Loss: 0.00001837
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [1.8374217688688077e-05, 1.8374217688688077e-05, 1.8374217688688077e-05, 1.8374217688688077e-05, 1.8374217688688077e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.8374217688688077e-05

Optimization complete. Final v2v error: 3.649578094482422 mm

Highest mean error: 3.8934648036956787 mm for frame 88

Lowest mean error: 3.1039695739746094 mm for frame 162

Saving results

Total time: 33.6487832069397
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0017/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0017.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0017
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01031535
Iteration 2/25 | Loss: 0.00211126
Iteration 3/25 | Loss: 0.00119625
Iteration 4/25 | Loss: 0.00094901
Iteration 5/25 | Loss: 0.00095691
Iteration 6/25 | Loss: 0.00086348
Iteration 7/25 | Loss: 0.00083626
Iteration 8/25 | Loss: 0.00082236
Iteration 9/25 | Loss: 0.00082419
Iteration 10/25 | Loss: 0.00081918
Iteration 11/25 | Loss: 0.00081135
Iteration 12/25 | Loss: 0.00080806
Iteration 13/25 | Loss: 0.00080375
Iteration 14/25 | Loss: 0.00080478
Iteration 15/25 | Loss: 0.00080557
Iteration 16/25 | Loss: 0.00080257
Iteration 17/25 | Loss: 0.00080257
Iteration 18/25 | Loss: 0.00080257
Iteration 19/25 | Loss: 0.00080257
Iteration 20/25 | Loss: 0.00080257
Iteration 21/25 | Loss: 0.00080257
Iteration 22/25 | Loss: 0.00080257
Iteration 23/25 | Loss: 0.00080257
Iteration 24/25 | Loss: 0.00080257
Iteration 25/25 | Loss: 0.00080245

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.87806177
Iteration 2/25 | Loss: 0.00025650
Iteration 3/25 | Loss: 0.00025650
Iteration 4/25 | Loss: 0.00025650
Iteration 5/25 | Loss: 0.00025650
Iteration 6/25 | Loss: 0.00025650
Iteration 7/25 | Loss: 0.00025650
Iteration 8/25 | Loss: 0.00025650
Iteration 9/25 | Loss: 0.00025650
Iteration 10/25 | Loss: 0.00025650
Iteration 11/25 | Loss: 0.00025650
Iteration 12/25 | Loss: 0.00025650
Iteration 13/25 | Loss: 0.00025650
Iteration 14/25 | Loss: 0.00025650
Iteration 15/25 | Loss: 0.00025650
Iteration 16/25 | Loss: 0.00025650
Iteration 17/25 | Loss: 0.00025650
Iteration 18/25 | Loss: 0.00025650
Iteration 19/25 | Loss: 0.00025650
Iteration 20/25 | Loss: 0.00025650
Iteration 21/25 | Loss: 0.00025650
Iteration 22/25 | Loss: 0.00025650
Iteration 23/25 | Loss: 0.00025650
Iteration 24/25 | Loss: 0.00025650
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 24. Stopping optimization.
Last 5 losses: [0.00025649761664681137, 0.00025649761664681137, 0.00025649761664681137, 0.00025649761664681137, 0.00025649761664681137]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00025649761664681137

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00025650
Iteration 2/1000 | Loss: 0.00004026
Iteration 3/1000 | Loss: 0.00002869
Iteration 4/1000 | Loss: 0.00002640
Iteration 5/1000 | Loss: 0.00012570
Iteration 6/1000 | Loss: 0.00033616
Iteration 7/1000 | Loss: 0.00002573
Iteration 8/1000 | Loss: 0.00011965
Iteration 9/1000 | Loss: 0.00010036
Iteration 10/1000 | Loss: 0.00016158
Iteration 11/1000 | Loss: 0.00011669
Iteration 12/1000 | Loss: 0.00002401
Iteration 13/1000 | Loss: 0.00011677
Iteration 14/1000 | Loss: 0.00002337
Iteration 15/1000 | Loss: 0.00006807
Iteration 16/1000 | Loss: 0.00004297
Iteration 17/1000 | Loss: 0.00002259
Iteration 18/1000 | Loss: 0.00002223
Iteration 19/1000 | Loss: 0.00002215
Iteration 20/1000 | Loss: 0.00002199
Iteration 21/1000 | Loss: 0.00002193
Iteration 22/1000 | Loss: 0.00002190
Iteration 23/1000 | Loss: 0.00002189
Iteration 24/1000 | Loss: 0.00002189
Iteration 25/1000 | Loss: 0.00002186
Iteration 26/1000 | Loss: 0.00002181
Iteration 27/1000 | Loss: 0.00002181
Iteration 28/1000 | Loss: 0.00002178
Iteration 29/1000 | Loss: 0.00002178
Iteration 30/1000 | Loss: 0.00002177
Iteration 31/1000 | Loss: 0.00002177
Iteration 32/1000 | Loss: 0.00002177
Iteration 33/1000 | Loss: 0.00002176
Iteration 34/1000 | Loss: 0.00002176
Iteration 35/1000 | Loss: 0.00002176
Iteration 36/1000 | Loss: 0.00002175
Iteration 37/1000 | Loss: 0.00002175
Iteration 38/1000 | Loss: 0.00002174
Iteration 39/1000 | Loss: 0.00002174
Iteration 40/1000 | Loss: 0.00002173
Iteration 41/1000 | Loss: 0.00002173
Iteration 42/1000 | Loss: 0.00002172
Iteration 43/1000 | Loss: 0.00002172
Iteration 44/1000 | Loss: 0.00002171
Iteration 45/1000 | Loss: 0.00002171
Iteration 46/1000 | Loss: 0.00002171
Iteration 47/1000 | Loss: 0.00002171
Iteration 48/1000 | Loss: 0.00002171
Iteration 49/1000 | Loss: 0.00002170
Iteration 50/1000 | Loss: 0.00002170
Iteration 51/1000 | Loss: 0.00002170
Iteration 52/1000 | Loss: 0.00002170
Iteration 53/1000 | Loss: 0.00002170
Iteration 54/1000 | Loss: 0.00002169
Iteration 55/1000 | Loss: 0.00002168
Iteration 56/1000 | Loss: 0.00002168
Iteration 57/1000 | Loss: 0.00002168
Iteration 58/1000 | Loss: 0.00002167
Iteration 59/1000 | Loss: 0.00002167
Iteration 60/1000 | Loss: 0.00002167
Iteration 61/1000 | Loss: 0.00002166
Iteration 62/1000 | Loss: 0.00002166
Iteration 63/1000 | Loss: 0.00002166
Iteration 64/1000 | Loss: 0.00002165
Iteration 65/1000 | Loss: 0.00002165
Iteration 66/1000 | Loss: 0.00002165
Iteration 67/1000 | Loss: 0.00002165
Iteration 68/1000 | Loss: 0.00002164
Iteration 69/1000 | Loss: 0.00002164
Iteration 70/1000 | Loss: 0.00002164
Iteration 71/1000 | Loss: 0.00002164
Iteration 72/1000 | Loss: 0.00002164
Iteration 73/1000 | Loss: 0.00002164
Iteration 74/1000 | Loss: 0.00002163
Iteration 75/1000 | Loss: 0.00002163
Iteration 76/1000 | Loss: 0.00002163
Iteration 77/1000 | Loss: 0.00002163
Iteration 78/1000 | Loss: 0.00002162
Iteration 79/1000 | Loss: 0.00002162
Iteration 80/1000 | Loss: 0.00002161
Iteration 81/1000 | Loss: 0.00002161
Iteration 82/1000 | Loss: 0.00002161
Iteration 83/1000 | Loss: 0.00002161
Iteration 84/1000 | Loss: 0.00012298
Iteration 85/1000 | Loss: 0.00026977
Iteration 86/1000 | Loss: 0.00002561
Iteration 87/1000 | Loss: 0.00003146
Iteration 88/1000 | Loss: 0.00002175
Iteration 89/1000 | Loss: 0.00005471
Iteration 90/1000 | Loss: 0.00002174
Iteration 91/1000 | Loss: 0.00005014
Iteration 92/1000 | Loss: 0.00004369
Iteration 93/1000 | Loss: 0.00002179
Iteration 94/1000 | Loss: 0.00002161
Iteration 95/1000 | Loss: 0.00002161
Iteration 96/1000 | Loss: 0.00002161
Iteration 97/1000 | Loss: 0.00002160
Iteration 98/1000 | Loss: 0.00002160
Iteration 99/1000 | Loss: 0.00002160
Iteration 100/1000 | Loss: 0.00002160
Iteration 101/1000 | Loss: 0.00002160
Iteration 102/1000 | Loss: 0.00002160
Iteration 103/1000 | Loss: 0.00002160
Iteration 104/1000 | Loss: 0.00002160
Iteration 105/1000 | Loss: 0.00002160
Iteration 106/1000 | Loss: 0.00002160
Iteration 107/1000 | Loss: 0.00002160
Iteration 108/1000 | Loss: 0.00002159
Iteration 109/1000 | Loss: 0.00002159
Iteration 110/1000 | Loss: 0.00002159
Iteration 111/1000 | Loss: 0.00002159
Iteration 112/1000 | Loss: 0.00002159
Iteration 113/1000 | Loss: 0.00002159
Iteration 114/1000 | Loss: 0.00002159
Iteration 115/1000 | Loss: 0.00002159
Iteration 116/1000 | Loss: 0.00002159
Iteration 117/1000 | Loss: 0.00002159
Iteration 118/1000 | Loss: 0.00002158
Iteration 119/1000 | Loss: 0.00002158
Iteration 120/1000 | Loss: 0.00002158
Iteration 121/1000 | Loss: 0.00002158
Iteration 122/1000 | Loss: 0.00002158
Iteration 123/1000 | Loss: 0.00005793
Iteration 124/1000 | Loss: 0.00002170
Iteration 125/1000 | Loss: 0.00005775
Iteration 126/1000 | Loss: 0.00002171
Iteration 127/1000 | Loss: 0.00002157
Iteration 128/1000 | Loss: 0.00002157
Iteration 129/1000 | Loss: 0.00002155
Iteration 130/1000 | Loss: 0.00002155
Iteration 131/1000 | Loss: 0.00002155
Iteration 132/1000 | Loss: 0.00002155
Iteration 133/1000 | Loss: 0.00002154
Iteration 134/1000 | Loss: 0.00002154
Iteration 135/1000 | Loss: 0.00002154
Iteration 136/1000 | Loss: 0.00002154
Iteration 137/1000 | Loss: 0.00002154
Iteration 138/1000 | Loss: 0.00002154
Iteration 139/1000 | Loss: 0.00002153
Iteration 140/1000 | Loss: 0.00002153
Iteration 141/1000 | Loss: 0.00002153
Iteration 142/1000 | Loss: 0.00002153
Iteration 143/1000 | Loss: 0.00002153
Iteration 144/1000 | Loss: 0.00002153
Iteration 145/1000 | Loss: 0.00002152
Iteration 146/1000 | Loss: 0.00002152
Iteration 147/1000 | Loss: 0.00002152
Iteration 148/1000 | Loss: 0.00002152
Iteration 149/1000 | Loss: 0.00002152
Iteration 150/1000 | Loss: 0.00002152
Iteration 151/1000 | Loss: 0.00002152
Iteration 152/1000 | Loss: 0.00002152
Iteration 153/1000 | Loss: 0.00002152
Iteration 154/1000 | Loss: 0.00002152
Iteration 155/1000 | Loss: 0.00002152
Iteration 156/1000 | Loss: 0.00002152
Iteration 157/1000 | Loss: 0.00002152
Iteration 158/1000 | Loss: 0.00002152
Iteration 159/1000 | Loss: 0.00002152
Iteration 160/1000 | Loss: 0.00002152
Iteration 161/1000 | Loss: 0.00002152
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 161. Stopping optimization.
Last 5 losses: [2.1521420421777293e-05, 2.1521420421777293e-05, 2.1521420421777293e-05, 2.1521420421777293e-05, 2.1521420421777293e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.1521420421777293e-05

Optimization complete. Final v2v error: 3.9476497173309326 mm

Highest mean error: 4.6541619300842285 mm for frame 191

Lowest mean error: 3.140507221221924 mm for frame 96

Saving results

Total time: 93.76524329185486
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01151974
Iteration 2/25 | Loss: 0.00175348
Iteration 3/25 | Loss: 0.00204724
Iteration 4/25 | Loss: 0.00128108
Iteration 5/25 | Loss: 0.00123263
Iteration 6/25 | Loss: 0.00110450
Iteration 7/25 | Loss: 0.00108687
Iteration 8/25 | Loss: 0.00094870
Iteration 9/25 | Loss: 0.00089533
Iteration 10/25 | Loss: 0.00092884
Iteration 11/25 | Loss: 0.00090025
Iteration 12/25 | Loss: 0.00087798
Iteration 13/25 | Loss: 0.00091315
Iteration 14/25 | Loss: 0.00094629
Iteration 15/25 | Loss: 0.00091161
Iteration 16/25 | Loss: 0.00090325
Iteration 17/25 | Loss: 0.00087040
Iteration 18/25 | Loss: 0.00085289
Iteration 19/25 | Loss: 0.00084690
Iteration 20/25 | Loss: 0.00084638
Iteration 21/25 | Loss: 0.00084628
Iteration 22/25 | Loss: 0.00084626
Iteration 23/25 | Loss: 0.00084626
Iteration 24/25 | Loss: 0.00084626
Iteration 25/25 | Loss: 0.00084626

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.50919008
Iteration 2/25 | Loss: 0.00044105
Iteration 3/25 | Loss: 0.00039778
Iteration 4/25 | Loss: 0.00039778
Iteration 5/25 | Loss: 0.00039778
Iteration 6/25 | Loss: 0.00039778
Iteration 7/25 | Loss: 0.00039778
Iteration 8/25 | Loss: 0.00039778
Iteration 9/25 | Loss: 0.00039778
Iteration 10/25 | Loss: 0.00039778
Iteration 11/25 | Loss: 0.00039778
Iteration 12/25 | Loss: 0.00039778
Iteration 13/25 | Loss: 0.00039778
Iteration 14/25 | Loss: 0.00039778
Iteration 15/25 | Loss: 0.00039778
Iteration 16/25 | Loss: 0.00039778
Iteration 17/25 | Loss: 0.00039778
Iteration 18/25 | Loss: 0.00039778
Iteration 19/25 | Loss: 0.00039778
Iteration 20/25 | Loss: 0.00039778
Iteration 21/25 | Loss: 0.00039778
Iteration 22/25 | Loss: 0.00039778
Iteration 23/25 | Loss: 0.00039778
Iteration 24/25 | Loss: 0.00039778
Iteration 25/25 | Loss: 0.00039778
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.000397781579522416, 0.000397781579522416, 0.000397781579522416, 0.000397781579522416, 0.000397781579522416]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000397781579522416

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00039778
Iteration 2/1000 | Loss: 0.00347654
Iteration 3/1000 | Loss: 0.00618452
Iteration 4/1000 | Loss: 0.00009566
Iteration 5/1000 | Loss: 0.00063109
Iteration 6/1000 | Loss: 0.00053680
Iteration 7/1000 | Loss: 0.00005434
Iteration 8/1000 | Loss: 0.00004450
Iteration 9/1000 | Loss: 0.00005004
Iteration 10/1000 | Loss: 0.00004058
Iteration 11/1000 | Loss: 0.00298739
Iteration 12/1000 | Loss: 0.00212423
Iteration 13/1000 | Loss: 0.00323254
Iteration 14/1000 | Loss: 0.00025600
Iteration 15/1000 | Loss: 0.00006693
Iteration 16/1000 | Loss: 0.00004332
Iteration 17/1000 | Loss: 0.00004317
Iteration 18/1000 | Loss: 0.00003473
Iteration 19/1000 | Loss: 0.00003074
Iteration 20/1000 | Loss: 0.00002943
Iteration 21/1000 | Loss: 0.00003054
Iteration 22/1000 | Loss: 0.00002824
Iteration 23/1000 | Loss: 0.00002782
Iteration 24/1000 | Loss: 0.00002764
Iteration 25/1000 | Loss: 0.00005916
Iteration 26/1000 | Loss: 0.00003712
Iteration 27/1000 | Loss: 0.00002749
Iteration 28/1000 | Loss: 0.00002738
Iteration 29/1000 | Loss: 0.00004880
Iteration 30/1000 | Loss: 0.00003147
Iteration 31/1000 | Loss: 0.00002721
Iteration 32/1000 | Loss: 0.00002721
Iteration 33/1000 | Loss: 0.00002721
Iteration 34/1000 | Loss: 0.00002721
Iteration 35/1000 | Loss: 0.00002721
Iteration 36/1000 | Loss: 0.00002721
Iteration 37/1000 | Loss: 0.00002721
Iteration 38/1000 | Loss: 0.00002721
Iteration 39/1000 | Loss: 0.00002721
Iteration 40/1000 | Loss: 0.00002721
Iteration 41/1000 | Loss: 0.00002721
Iteration 42/1000 | Loss: 0.00002721
Iteration 43/1000 | Loss: 0.00002721
Iteration 44/1000 | Loss: 0.00002721
Iteration 45/1000 | Loss: 0.00002721
Iteration 46/1000 | Loss: 0.00002721
Iteration 47/1000 | Loss: 0.00002721
Iteration 48/1000 | Loss: 0.00002721
Iteration 49/1000 | Loss: 0.00002721
Iteration 50/1000 | Loss: 0.00002721
Iteration 51/1000 | Loss: 0.00002721
Iteration 52/1000 | Loss: 0.00002721
Iteration 53/1000 | Loss: 0.00002721
Iteration 54/1000 | Loss: 0.00002721
Iteration 55/1000 | Loss: 0.00002721
Iteration 56/1000 | Loss: 0.00002721
Iteration 57/1000 | Loss: 0.00002721
Iteration 58/1000 | Loss: 0.00002721
Iteration 59/1000 | Loss: 0.00002721
Iteration 60/1000 | Loss: 0.00002721
Iteration 61/1000 | Loss: 0.00002721
Iteration 62/1000 | Loss: 0.00002721
Iteration 63/1000 | Loss: 0.00002721
Iteration 64/1000 | Loss: 0.00002721
Iteration 65/1000 | Loss: 0.00002721
Iteration 66/1000 | Loss: 0.00002721
Iteration 67/1000 | Loss: 0.00002721
Iteration 68/1000 | Loss: 0.00002721
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 68. Stopping optimization.
Last 5 losses: [2.7209473046241328e-05, 2.7209473046241328e-05, 2.7209473046241328e-05, 2.7209473046241328e-05, 2.7209473046241328e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.7209473046241328e-05

Optimization complete. Final v2v error: 4.430046081542969 mm

Highest mean error: 6.754599571228027 mm for frame 74

Lowest mean error: 3.5717992782592773 mm for frame 0

Saving results

Total time: 80.19914102554321
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0015/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0015.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0015
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00614894
Iteration 2/25 | Loss: 0.00087618
Iteration 3/25 | Loss: 0.00075807
Iteration 4/25 | Loss: 0.00073456
Iteration 5/25 | Loss: 0.00072543
Iteration 6/25 | Loss: 0.00072336
Iteration 7/25 | Loss: 0.00072315
Iteration 8/25 | Loss: 0.00072315
Iteration 9/25 | Loss: 0.00072315
Iteration 10/25 | Loss: 0.00072315
Iteration 11/25 | Loss: 0.00072315
Iteration 12/25 | Loss: 0.00072315
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007231472991406918, 0.0007231472991406918, 0.0007231472991406918, 0.0007231472991406918, 0.0007231472991406918]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007231472991406918

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 3.08723903
Iteration 2/25 | Loss: 0.00026900
Iteration 3/25 | Loss: 0.00026900
Iteration 4/25 | Loss: 0.00026900
Iteration 5/25 | Loss: 0.00026900
Iteration 6/25 | Loss: 0.00026900
Iteration 7/25 | Loss: 0.00026900
Iteration 8/25 | Loss: 0.00026900
Iteration 9/25 | Loss: 0.00026900
Iteration 10/25 | Loss: 0.00026900
Iteration 11/25 | Loss: 0.00026900
Iteration 12/25 | Loss: 0.00026900
Iteration 13/25 | Loss: 0.00026900
Iteration 14/25 | Loss: 0.00026900
Iteration 15/25 | Loss: 0.00026900
Iteration 16/25 | Loss: 0.00026900
Iteration 17/25 | Loss: 0.00026900
Iteration 18/25 | Loss: 0.00026900
Iteration 19/25 | Loss: 0.00026900
Iteration 20/25 | Loss: 0.00026900
Iteration 21/25 | Loss: 0.00026900
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.000268999399850145, 0.000268999399850145, 0.000268999399850145, 0.000268999399850145, 0.000268999399850145]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000268999399850145

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00026900
Iteration 2/1000 | Loss: 0.00003385
Iteration 3/1000 | Loss: 0.00002041
Iteration 4/1000 | Loss: 0.00001896
Iteration 5/1000 | Loss: 0.00001782
Iteration 6/1000 | Loss: 0.00001726
Iteration 7/1000 | Loss: 0.00001676
Iteration 8/1000 | Loss: 0.00001652
Iteration 9/1000 | Loss: 0.00001651
Iteration 10/1000 | Loss: 0.00001644
Iteration 11/1000 | Loss: 0.00001644
Iteration 12/1000 | Loss: 0.00001643
Iteration 13/1000 | Loss: 0.00001634
Iteration 14/1000 | Loss: 0.00001633
Iteration 15/1000 | Loss: 0.00001632
Iteration 16/1000 | Loss: 0.00001632
Iteration 17/1000 | Loss: 0.00001631
Iteration 18/1000 | Loss: 0.00001630
Iteration 19/1000 | Loss: 0.00001629
Iteration 20/1000 | Loss: 0.00001628
Iteration 21/1000 | Loss: 0.00001627
Iteration 22/1000 | Loss: 0.00001626
Iteration 23/1000 | Loss: 0.00001626
Iteration 24/1000 | Loss: 0.00001626
Iteration 25/1000 | Loss: 0.00001626
Iteration 26/1000 | Loss: 0.00001625
Iteration 27/1000 | Loss: 0.00001624
Iteration 28/1000 | Loss: 0.00001624
Iteration 29/1000 | Loss: 0.00001623
Iteration 30/1000 | Loss: 0.00001622
Iteration 31/1000 | Loss: 0.00001621
Iteration 32/1000 | Loss: 0.00001621
Iteration 33/1000 | Loss: 0.00001620
Iteration 34/1000 | Loss: 0.00001620
Iteration 35/1000 | Loss: 0.00001620
Iteration 36/1000 | Loss: 0.00001619
Iteration 37/1000 | Loss: 0.00001619
Iteration 38/1000 | Loss: 0.00001618
Iteration 39/1000 | Loss: 0.00001617
Iteration 40/1000 | Loss: 0.00001616
Iteration 41/1000 | Loss: 0.00001616
Iteration 42/1000 | Loss: 0.00001616
Iteration 43/1000 | Loss: 0.00001615
Iteration 44/1000 | Loss: 0.00001615
Iteration 45/1000 | Loss: 0.00001615
Iteration 46/1000 | Loss: 0.00001615
Iteration 47/1000 | Loss: 0.00001615
Iteration 48/1000 | Loss: 0.00001615
Iteration 49/1000 | Loss: 0.00001615
Iteration 50/1000 | Loss: 0.00001615
Iteration 51/1000 | Loss: 0.00001615
Iteration 52/1000 | Loss: 0.00001615
Iteration 53/1000 | Loss: 0.00001614
Iteration 54/1000 | Loss: 0.00001614
Iteration 55/1000 | Loss: 0.00001614
Iteration 56/1000 | Loss: 0.00001614
Iteration 57/1000 | Loss: 0.00001614
Iteration 58/1000 | Loss: 0.00001613
Iteration 59/1000 | Loss: 0.00001613
Iteration 60/1000 | Loss: 0.00001613
Iteration 61/1000 | Loss: 0.00001613
Iteration 62/1000 | Loss: 0.00001613
Iteration 63/1000 | Loss: 0.00001612
Iteration 64/1000 | Loss: 0.00001612
Iteration 65/1000 | Loss: 0.00001612
Iteration 66/1000 | Loss: 0.00001612
Iteration 67/1000 | Loss: 0.00001612
Iteration 68/1000 | Loss: 0.00001612
Iteration 69/1000 | Loss: 0.00001611
Iteration 70/1000 | Loss: 0.00001611
Iteration 71/1000 | Loss: 0.00001611
Iteration 72/1000 | Loss: 0.00001611
Iteration 73/1000 | Loss: 0.00001611
Iteration 74/1000 | Loss: 0.00001611
Iteration 75/1000 | Loss: 0.00001610
Iteration 76/1000 | Loss: 0.00001610
Iteration 77/1000 | Loss: 0.00001610
Iteration 78/1000 | Loss: 0.00001609
Iteration 79/1000 | Loss: 0.00001609
Iteration 80/1000 | Loss: 0.00001609
Iteration 81/1000 | Loss: 0.00001608
Iteration 82/1000 | Loss: 0.00001608
Iteration 83/1000 | Loss: 0.00001608
Iteration 84/1000 | Loss: 0.00001608
Iteration 85/1000 | Loss: 0.00001608
Iteration 86/1000 | Loss: 0.00001608
Iteration 87/1000 | Loss: 0.00001608
Iteration 88/1000 | Loss: 0.00001607
Iteration 89/1000 | Loss: 0.00001607
Iteration 90/1000 | Loss: 0.00001607
Iteration 91/1000 | Loss: 0.00001607
Iteration 92/1000 | Loss: 0.00001607
Iteration 93/1000 | Loss: 0.00001607
Iteration 94/1000 | Loss: 0.00001607
Iteration 95/1000 | Loss: 0.00001607
Iteration 96/1000 | Loss: 0.00001607
Iteration 97/1000 | Loss: 0.00001606
Iteration 98/1000 | Loss: 0.00001606
Iteration 99/1000 | Loss: 0.00001606
Iteration 100/1000 | Loss: 0.00001606
Iteration 101/1000 | Loss: 0.00001606
Iteration 102/1000 | Loss: 0.00001606
Iteration 103/1000 | Loss: 0.00001606
Iteration 104/1000 | Loss: 0.00001606
Iteration 105/1000 | Loss: 0.00001606
Iteration 106/1000 | Loss: 0.00001606
Iteration 107/1000 | Loss: 0.00001606
Iteration 108/1000 | Loss: 0.00001606
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 108. Stopping optimization.
Last 5 losses: [1.6055086234700866e-05, 1.6055086234700866e-05, 1.6055086234700866e-05, 1.6055086234700866e-05, 1.6055086234700866e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.6055086234700866e-05

Optimization complete. Final v2v error: 3.4250261783599854 mm

Highest mean error: 3.6350393295288086 mm for frame 151

Lowest mean error: 3.1379284858703613 mm for frame 75

Saving results

Total time: 29.905248403549194
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0016/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0016.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0016
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00497494
Iteration 2/25 | Loss: 0.00094409
Iteration 3/25 | Loss: 0.00080733
Iteration 4/25 | Loss: 0.00077498
Iteration 5/25 | Loss: 0.00076434
Iteration 6/25 | Loss: 0.00076259
Iteration 7/25 | Loss: 0.00076247
Iteration 8/25 | Loss: 0.00076247
Iteration 9/25 | Loss: 0.00076247
Iteration 10/25 | Loss: 0.00076247
Iteration 11/25 | Loss: 0.00076247
Iteration 12/25 | Loss: 0.00076247
Iteration 13/25 | Loss: 0.00076247
Iteration 14/25 | Loss: 0.00076247
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 14. Stopping optimization.
Last 5 losses: [0.0007624698919244111, 0.0007624698919244111, 0.0007624698919244111, 0.0007624698919244111, 0.0007624698919244111]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007624698919244111

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39168179
Iteration 2/25 | Loss: 0.00035436
Iteration 3/25 | Loss: 0.00035432
Iteration 4/25 | Loss: 0.00035432
Iteration 5/25 | Loss: 0.00035432
Iteration 6/25 | Loss: 0.00035432
Iteration 7/25 | Loss: 0.00035432
Iteration 8/25 | Loss: 0.00035432
Iteration 9/25 | Loss: 0.00035432
Iteration 10/25 | Loss: 0.00035432
Iteration 11/25 | Loss: 0.00035432
Iteration 12/25 | Loss: 0.00035432
Iteration 13/25 | Loss: 0.00035432
Iteration 14/25 | Loss: 0.00035432
Iteration 15/25 | Loss: 0.00035432
Iteration 16/25 | Loss: 0.00035432
Iteration 17/25 | Loss: 0.00035432
Iteration 18/25 | Loss: 0.00035432
Iteration 19/25 | Loss: 0.00035432
Iteration 20/25 | Loss: 0.00035432
Iteration 21/25 | Loss: 0.00035432
Iteration 22/25 | Loss: 0.00035432
Iteration 23/25 | Loss: 0.00035432
Iteration 24/25 | Loss: 0.00035432
Iteration 25/25 | Loss: 0.00035432
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 25. Stopping optimization.
Last 5 losses: [0.00035431847209110856, 0.00035431847209110856, 0.00035431847209110856, 0.00035431847209110856, 0.00035431847209110856]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00035431847209110856

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00035432
Iteration 2/1000 | Loss: 0.00004357
Iteration 3/1000 | Loss: 0.00002555
Iteration 4/1000 | Loss: 0.00002215
Iteration 5/1000 | Loss: 0.00002091
Iteration 6/1000 | Loss: 0.00002003
Iteration 7/1000 | Loss: 0.00001932
Iteration 8/1000 | Loss: 0.00001877
Iteration 9/1000 | Loss: 0.00001853
Iteration 10/1000 | Loss: 0.00001836
Iteration 11/1000 | Loss: 0.00001834
Iteration 12/1000 | Loss: 0.00001833
Iteration 13/1000 | Loss: 0.00001832
Iteration 14/1000 | Loss: 0.00001830
Iteration 15/1000 | Loss: 0.00001826
Iteration 16/1000 | Loss: 0.00001824
Iteration 17/1000 | Loss: 0.00001816
Iteration 18/1000 | Loss: 0.00001813
Iteration 19/1000 | Loss: 0.00001808
Iteration 20/1000 | Loss: 0.00001808
Iteration 21/1000 | Loss: 0.00001807
Iteration 22/1000 | Loss: 0.00001807
Iteration 23/1000 | Loss: 0.00001806
Iteration 24/1000 | Loss: 0.00001806
Iteration 25/1000 | Loss: 0.00001805
Iteration 26/1000 | Loss: 0.00001803
Iteration 27/1000 | Loss: 0.00001803
Iteration 28/1000 | Loss: 0.00001803
Iteration 29/1000 | Loss: 0.00001803
Iteration 30/1000 | Loss: 0.00001803
Iteration 31/1000 | Loss: 0.00001802
Iteration 32/1000 | Loss: 0.00001802
Iteration 33/1000 | Loss: 0.00001802
Iteration 34/1000 | Loss: 0.00001800
Iteration 35/1000 | Loss: 0.00001800
Iteration 36/1000 | Loss: 0.00001799
Iteration 37/1000 | Loss: 0.00001799
Iteration 38/1000 | Loss: 0.00001799
Iteration 39/1000 | Loss: 0.00001799
Iteration 40/1000 | Loss: 0.00001799
Iteration 41/1000 | Loss: 0.00001799
Iteration 42/1000 | Loss: 0.00001799
Iteration 43/1000 | Loss: 0.00001799
Iteration 44/1000 | Loss: 0.00001799
Iteration 45/1000 | Loss: 0.00001799
Iteration 46/1000 | Loss: 0.00001799
Iteration 47/1000 | Loss: 0.00001799
Iteration 48/1000 | Loss: 0.00001798
Iteration 49/1000 | Loss: 0.00001798
Iteration 50/1000 | Loss: 0.00001798
Iteration 51/1000 | Loss: 0.00001798
Iteration 52/1000 | Loss: 0.00001798
Iteration 53/1000 | Loss: 0.00001797
Iteration 54/1000 | Loss: 0.00001797
Iteration 55/1000 | Loss: 0.00001796
Iteration 56/1000 | Loss: 0.00001796
Iteration 57/1000 | Loss: 0.00001795
Iteration 58/1000 | Loss: 0.00001795
Iteration 59/1000 | Loss: 0.00001795
Iteration 60/1000 | Loss: 0.00001795
Iteration 61/1000 | Loss: 0.00001795
Iteration 62/1000 | Loss: 0.00001794
Iteration 63/1000 | Loss: 0.00001794
Iteration 64/1000 | Loss: 0.00001794
Iteration 65/1000 | Loss: 0.00001794
Iteration 66/1000 | Loss: 0.00001794
Iteration 67/1000 | Loss: 0.00001794
Iteration 68/1000 | Loss: 0.00001794
Iteration 69/1000 | Loss: 0.00001794
Iteration 70/1000 | Loss: 0.00001793
Iteration 71/1000 | Loss: 0.00001793
Iteration 72/1000 | Loss: 0.00001793
Iteration 73/1000 | Loss: 0.00001793
Iteration 74/1000 | Loss: 0.00001793
Iteration 75/1000 | Loss: 0.00001792
Iteration 76/1000 | Loss: 0.00001792
Iteration 77/1000 | Loss: 0.00001792
Iteration 78/1000 | Loss: 0.00001792
Iteration 79/1000 | Loss: 0.00001792
Iteration 80/1000 | Loss: 0.00001792
Iteration 81/1000 | Loss: 0.00001792
Iteration 82/1000 | Loss: 0.00001792
Iteration 83/1000 | Loss: 0.00001792
Iteration 84/1000 | Loss: 0.00001792
Iteration 85/1000 | Loss: 0.00001792
Iteration 86/1000 | Loss: 0.00001792
Iteration 87/1000 | Loss: 0.00001792
Iteration 88/1000 | Loss: 0.00001792
Iteration 89/1000 | Loss: 0.00001792
Iteration 90/1000 | Loss: 0.00001792
Iteration 91/1000 | Loss: 0.00001792
Iteration 92/1000 | Loss: 0.00001792
Iteration 93/1000 | Loss: 0.00001792
Iteration 94/1000 | Loss: 0.00001791
Iteration 95/1000 | Loss: 0.00001791
Iteration 96/1000 | Loss: 0.00001791
Iteration 97/1000 | Loss: 0.00001791
Iteration 98/1000 | Loss: 0.00001791
Iteration 99/1000 | Loss: 0.00001790
Iteration 100/1000 | Loss: 0.00001790
Iteration 101/1000 | Loss: 0.00001790
Iteration 102/1000 | Loss: 0.00001790
Iteration 103/1000 | Loss: 0.00001790
Iteration 104/1000 | Loss: 0.00001790
Iteration 105/1000 | Loss: 0.00001790
Iteration 106/1000 | Loss: 0.00001790
Iteration 107/1000 | Loss: 0.00001790
Iteration 108/1000 | Loss: 0.00001790
Iteration 109/1000 | Loss: 0.00001790
Iteration 110/1000 | Loss: 0.00001790
Iteration 111/1000 | Loss: 0.00001789
Iteration 112/1000 | Loss: 0.00001789
Iteration 113/1000 | Loss: 0.00001789
Iteration 114/1000 | Loss: 0.00001789
Iteration 115/1000 | Loss: 0.00001789
Iteration 116/1000 | Loss: 0.00001789
Iteration 117/1000 | Loss: 0.00001789
Iteration 118/1000 | Loss: 0.00001789
Iteration 119/1000 | Loss: 0.00001789
Iteration 120/1000 | Loss: 0.00001789
Iteration 121/1000 | Loss: 0.00001789
Iteration 122/1000 | Loss: 0.00001789
Iteration 123/1000 | Loss: 0.00001789
Iteration 124/1000 | Loss: 0.00001789
Iteration 125/1000 | Loss: 0.00001789
Iteration 126/1000 | Loss: 0.00001789
Iteration 127/1000 | Loss: 0.00001789
Iteration 128/1000 | Loss: 0.00001789
Iteration 129/1000 | Loss: 0.00001789
Iteration 130/1000 | Loss: 0.00001789
Iteration 131/1000 | Loss: 0.00001789
Iteration 132/1000 | Loss: 0.00001789
Iteration 133/1000 | Loss: 0.00001789
Iteration 134/1000 | Loss: 0.00001789
Iteration 135/1000 | Loss: 0.00001789
Iteration 136/1000 | Loss: 0.00001789
Iteration 137/1000 | Loss: 0.00001789
Iteration 138/1000 | Loss: 0.00001789
Iteration 139/1000 | Loss: 0.00001789
Iteration 140/1000 | Loss: 0.00001789
Iteration 141/1000 | Loss: 0.00001789
Iteration 142/1000 | Loss: 0.00001789
Iteration 143/1000 | Loss: 0.00001789
Iteration 144/1000 | Loss: 0.00001789
Iteration 145/1000 | Loss: 0.00001789
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 145. Stopping optimization.
Last 5 losses: [1.7886846762849018e-05, 1.7886846762849018e-05, 1.7886846762849018e-05, 1.7886846762849018e-05, 1.7886846762849018e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7886846762849018e-05

Optimization complete. Final v2v error: 3.672980546951294 mm

Highest mean error: 4.384462356567383 mm for frame 50

Lowest mean error: 3.3569135665893555 mm for frame 147

Saving results

Total time: 33.02677059173584
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0006/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0006.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0006
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00800097
Iteration 2/25 | Loss: 0.00107037
Iteration 3/25 | Loss: 0.00092065
Iteration 4/25 | Loss: 0.00089302
Iteration 5/25 | Loss: 0.00088632
Iteration 6/25 | Loss: 0.00088520
Iteration 7/25 | Loss: 0.00088510
Iteration 8/25 | Loss: 0.00088510
Iteration 9/25 | Loss: 0.00088510
Iteration 10/25 | Loss: 0.00088510
Iteration 11/25 | Loss: 0.00088510
Iteration 12/25 | Loss: 0.00088510
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0008850967860780656, 0.0008850967860780656, 0.0008850967860780656, 0.0008850967860780656, 0.0008850967860780656]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0008850967860780656

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39420545
Iteration 2/25 | Loss: 0.00044214
Iteration 3/25 | Loss: 0.00044205
Iteration 4/25 | Loss: 0.00044205
Iteration 5/25 | Loss: 0.00044205
Iteration 6/25 | Loss: 0.00044205
Iteration 7/25 | Loss: 0.00044205
Iteration 8/25 | Loss: 0.00044205
Iteration 9/25 | Loss: 0.00044205
Iteration 10/25 | Loss: 0.00044205
Iteration 11/25 | Loss: 0.00044205
Iteration 12/25 | Loss: 0.00044205
Iteration 13/25 | Loss: 0.00044205
Iteration 14/25 | Loss: 0.00044205
Iteration 15/25 | Loss: 0.00044205
Iteration 16/25 | Loss: 0.00044205
Iteration 17/25 | Loss: 0.00044205
Iteration 18/25 | Loss: 0.00044205
Iteration 19/25 | Loss: 0.00044205
Iteration 20/25 | Loss: 0.00044205
Iteration 21/25 | Loss: 0.00044205
Iteration 22/25 | Loss: 0.00044205
Iteration 23/25 | Loss: 0.00044205
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.00044204937876202166, 0.00044204937876202166, 0.00044204937876202166, 0.00044204937876202166, 0.00044204937876202166]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00044204937876202166

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00044205
Iteration 2/1000 | Loss: 0.00006096
Iteration 3/1000 | Loss: 0.00004145
Iteration 4/1000 | Loss: 0.00003615
Iteration 5/1000 | Loss: 0.00003342
Iteration 6/1000 | Loss: 0.00003185
Iteration 7/1000 | Loss: 0.00003064
Iteration 8/1000 | Loss: 0.00002985
Iteration 9/1000 | Loss: 0.00002931
Iteration 10/1000 | Loss: 0.00002893
Iteration 11/1000 | Loss: 0.00002872
Iteration 12/1000 | Loss: 0.00002870
Iteration 13/1000 | Loss: 0.00002853
Iteration 14/1000 | Loss: 0.00002848
Iteration 15/1000 | Loss: 0.00002847
Iteration 16/1000 | Loss: 0.00002846
Iteration 17/1000 | Loss: 0.00002845
Iteration 18/1000 | Loss: 0.00002845
Iteration 19/1000 | Loss: 0.00002845
Iteration 20/1000 | Loss: 0.00002845
Iteration 21/1000 | Loss: 0.00002844
Iteration 22/1000 | Loss: 0.00002843
Iteration 23/1000 | Loss: 0.00002843
Iteration 24/1000 | Loss: 0.00002841
Iteration 25/1000 | Loss: 0.00002840
Iteration 26/1000 | Loss: 0.00002840
Iteration 27/1000 | Loss: 0.00002840
Iteration 28/1000 | Loss: 0.00002839
Iteration 29/1000 | Loss: 0.00002839
Iteration 30/1000 | Loss: 0.00002839
Iteration 31/1000 | Loss: 0.00002837
Iteration 32/1000 | Loss: 0.00002837
Iteration 33/1000 | Loss: 0.00002837
Iteration 34/1000 | Loss: 0.00002837
Iteration 35/1000 | Loss: 0.00002837
Iteration 36/1000 | Loss: 0.00002837
Iteration 37/1000 | Loss: 0.00002837
Iteration 38/1000 | Loss: 0.00002837
Iteration 39/1000 | Loss: 0.00002837
Iteration 40/1000 | Loss: 0.00002837
Iteration 41/1000 | Loss: 0.00002837
Iteration 42/1000 | Loss: 0.00002837
Iteration 43/1000 | Loss: 0.00002837
Iteration 44/1000 | Loss: 0.00002837
Iteration 45/1000 | Loss: 0.00002837
Iteration 46/1000 | Loss: 0.00002837
Iteration 47/1000 | Loss: 0.00002837
Iteration 48/1000 | Loss: 0.00002837
Iteration 49/1000 | Loss: 0.00002837
Iteration 50/1000 | Loss: 0.00002837
Iteration 51/1000 | Loss: 0.00002837
Iteration 52/1000 | Loss: 0.00002837
Iteration 53/1000 | Loss: 0.00002837
Iteration 54/1000 | Loss: 0.00002837
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 54. Stopping optimization.
Last 5 losses: [2.8366612241370603e-05, 2.8366612241370603e-05, 2.8366612241370603e-05, 2.8366612241370603e-05, 2.8366612241370603e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8366612241370603e-05

Optimization complete. Final v2v error: 4.5241007804870605 mm

Highest mean error: 5.02167272567749 mm for frame 43

Lowest mean error: 3.921171188354492 mm for frame 11

Saving results

Total time: 28.813565969467163
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0023/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0023.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0023
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00992652
Iteration 2/25 | Loss: 0.00110098
Iteration 3/25 | Loss: 0.00082301
Iteration 4/25 | Loss: 0.00078303
Iteration 5/25 | Loss: 0.00076956
Iteration 6/25 | Loss: 0.00076724
Iteration 7/25 | Loss: 0.00076707
Iteration 8/25 | Loss: 0.00076707
Iteration 9/25 | Loss: 0.00076707
Iteration 10/25 | Loss: 0.00076707
Iteration 11/25 | Loss: 0.00076707
Iteration 12/25 | Loss: 0.00076707
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0007670724880881608, 0.0007670724880881608, 0.0007670724880881608, 0.0007670724880881608, 0.0007670724880881608]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007670724880881608

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 2.49549747
Iteration 2/25 | Loss: 0.00031015
Iteration 3/25 | Loss: 0.00031015
Iteration 4/25 | Loss: 0.00031015
Iteration 5/25 | Loss: 0.00031015
Iteration 6/25 | Loss: 0.00031015
Iteration 7/25 | Loss: 0.00031015
Iteration 8/25 | Loss: 0.00031015
Iteration 9/25 | Loss: 0.00031015
Iteration 10/25 | Loss: 0.00031015
Iteration 11/25 | Loss: 0.00031015
Iteration 12/25 | Loss: 0.00031015
Iteration 13/25 | Loss: 0.00031015
Iteration 14/25 | Loss: 0.00031015
Iteration 15/25 | Loss: 0.00031015
Iteration 16/25 | Loss: 0.00031015
Iteration 17/25 | Loss: 0.00031015
Iteration 18/25 | Loss: 0.00031015
Iteration 19/25 | Loss: 0.00031015
Iteration 20/25 | Loss: 0.00031015
Iteration 21/25 | Loss: 0.00031015
Iteration 22/25 | Loss: 0.00031015
Iteration 23/25 | Loss: 0.00031015
Iteration 24/25 | Loss: 0.00031015
Iteration 25/25 | Loss: 0.00031015

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00031015
Iteration 2/1000 | Loss: 0.00003763
Iteration 3/1000 | Loss: 0.00002355
Iteration 4/1000 | Loss: 0.00002149
Iteration 5/1000 | Loss: 0.00002021
Iteration 6/1000 | Loss: 0.00001943
Iteration 7/1000 | Loss: 0.00001886
Iteration 8/1000 | Loss: 0.00001828
Iteration 9/1000 | Loss: 0.00001802
Iteration 10/1000 | Loss: 0.00001788
Iteration 11/1000 | Loss: 0.00001787
Iteration 12/1000 | Loss: 0.00001785
Iteration 13/1000 | Loss: 0.00001779
Iteration 14/1000 | Loss: 0.00001776
Iteration 15/1000 | Loss: 0.00001775
Iteration 16/1000 | Loss: 0.00001775
Iteration 17/1000 | Loss: 0.00001773
Iteration 18/1000 | Loss: 0.00001773
Iteration 19/1000 | Loss: 0.00001772
Iteration 20/1000 | Loss: 0.00001771
Iteration 21/1000 | Loss: 0.00001766
Iteration 22/1000 | Loss: 0.00001765
Iteration 23/1000 | Loss: 0.00001765
Iteration 24/1000 | Loss: 0.00001762
Iteration 25/1000 | Loss: 0.00001762
Iteration 26/1000 | Loss: 0.00001761
Iteration 27/1000 | Loss: 0.00001760
Iteration 28/1000 | Loss: 0.00001760
Iteration 29/1000 | Loss: 0.00001760
Iteration 30/1000 | Loss: 0.00001760
Iteration 31/1000 | Loss: 0.00001759
Iteration 32/1000 | Loss: 0.00001758
Iteration 33/1000 | Loss: 0.00001758
Iteration 34/1000 | Loss: 0.00001758
Iteration 35/1000 | Loss: 0.00001757
Iteration 36/1000 | Loss: 0.00001757
Iteration 37/1000 | Loss: 0.00001756
Iteration 38/1000 | Loss: 0.00001756
Iteration 39/1000 | Loss: 0.00001756
Iteration 40/1000 | Loss: 0.00001755
Iteration 41/1000 | Loss: 0.00001755
Iteration 42/1000 | Loss: 0.00001754
Iteration 43/1000 | Loss: 0.00001754
Iteration 44/1000 | Loss: 0.00001754
Iteration 45/1000 | Loss: 0.00001753
Iteration 46/1000 | Loss: 0.00001753
Iteration 47/1000 | Loss: 0.00001752
Iteration 48/1000 | Loss: 0.00001752
Iteration 49/1000 | Loss: 0.00001752
Iteration 50/1000 | Loss: 0.00001751
Iteration 51/1000 | Loss: 0.00001751
Iteration 52/1000 | Loss: 0.00001751
Iteration 53/1000 | Loss: 0.00001751
Iteration 54/1000 | Loss: 0.00001751
Iteration 55/1000 | Loss: 0.00001751
Iteration 56/1000 | Loss: 0.00001750
Iteration 57/1000 | Loss: 0.00001750
Iteration 58/1000 | Loss: 0.00001750
Iteration 59/1000 | Loss: 0.00001750
Iteration 60/1000 | Loss: 0.00001750
Iteration 61/1000 | Loss: 0.00001749
Iteration 62/1000 | Loss: 0.00001749
Iteration 63/1000 | Loss: 0.00001749
Iteration 64/1000 | Loss: 0.00001749
Iteration 65/1000 | Loss: 0.00001749
Iteration 66/1000 | Loss: 0.00001749
Iteration 67/1000 | Loss: 0.00001749
Iteration 68/1000 | Loss: 0.00001749
Iteration 69/1000 | Loss: 0.00001749
Iteration 70/1000 | Loss: 0.00001749
Iteration 71/1000 | Loss: 0.00001749
Iteration 72/1000 | Loss: 0.00001749
Iteration 73/1000 | Loss: 0.00001749
Iteration 74/1000 | Loss: 0.00001749
Iteration 75/1000 | Loss: 0.00001749
Iteration 76/1000 | Loss: 0.00001749
Iteration 77/1000 | Loss: 0.00001749
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 77. Stopping optimization.
Last 5 losses: [1.7494501662440598e-05, 1.7494501662440598e-05, 1.7494501662440598e-05, 1.7494501662440598e-05, 1.7494501662440598e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7494501662440598e-05

Optimization complete. Final v2v error: 3.5828380584716797 mm

Highest mean error: 4.082237243652344 mm for frame 15

Lowest mean error: 3.1871273517608643 mm for frame 175

Saving results

Total time: 32.08726143836975
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0024/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0024.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0024
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00817825
Iteration 2/25 | Loss: 0.00111717
Iteration 3/25 | Loss: 0.00090117
Iteration 4/25 | Loss: 0.00085160
Iteration 5/25 | Loss: 0.00083900
Iteration 6/25 | Loss: 0.00083801
Iteration 7/25 | Loss: 0.00083801
Iteration 8/25 | Loss: 0.00083801
Iteration 9/25 | Loss: 0.00083801
Iteration 10/25 | Loss: 0.00083801
Iteration 11/25 | Loss: 0.00083801
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.000838013191241771, 0.000838013191241771, 0.000838013191241771, 0.000838013191241771, 0.000838013191241771]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.000838013191241771

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.36716652
Iteration 2/25 | Loss: 0.00041090
Iteration 3/25 | Loss: 0.00041085
Iteration 4/25 | Loss: 0.00041085
Iteration 5/25 | Loss: 0.00041085
Iteration 6/25 | Loss: 0.00041085
Iteration 7/25 | Loss: 0.00041085
Iteration 8/25 | Loss: 0.00041085
Iteration 9/25 | Loss: 0.00041085
Iteration 10/25 | Loss: 0.00041085
Iteration 11/25 | Loss: 0.00041085
Iteration 12/25 | Loss: 0.00041085
Iteration 13/25 | Loss: 0.00041085
Iteration 14/25 | Loss: 0.00041085
Iteration 15/25 | Loss: 0.00041085
Iteration 16/25 | Loss: 0.00041085
Iteration 17/25 | Loss: 0.00041085
Iteration 18/25 | Loss: 0.00041085
Iteration 19/25 | Loss: 0.00041085
Iteration 20/25 | Loss: 0.00041085
Iteration 21/25 | Loss: 0.00041085
Iteration 22/25 | Loss: 0.00041085
Iteration 23/25 | Loss: 0.00041085
Iteration 24/25 | Loss: 0.00041085
Iteration 25/25 | Loss: 0.00041085

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00041085
Iteration 2/1000 | Loss: 0.00004804
Iteration 3/1000 | Loss: 0.00003156
Iteration 4/1000 | Loss: 0.00002820
Iteration 5/1000 | Loss: 0.00002617
Iteration 6/1000 | Loss: 0.00002488
Iteration 7/1000 | Loss: 0.00002409
Iteration 8/1000 | Loss: 0.00002356
Iteration 9/1000 | Loss: 0.00002323
Iteration 10/1000 | Loss: 0.00002313
Iteration 11/1000 | Loss: 0.00002298
Iteration 12/1000 | Loss: 0.00002276
Iteration 13/1000 | Loss: 0.00002259
Iteration 14/1000 | Loss: 0.00002256
Iteration 15/1000 | Loss: 0.00002256
Iteration 16/1000 | Loss: 0.00002247
Iteration 17/1000 | Loss: 0.00002246
Iteration 18/1000 | Loss: 0.00002246
Iteration 19/1000 | Loss: 0.00002245
Iteration 20/1000 | Loss: 0.00002244
Iteration 21/1000 | Loss: 0.00002244
Iteration 22/1000 | Loss: 0.00002243
Iteration 23/1000 | Loss: 0.00002243
Iteration 24/1000 | Loss: 0.00002242
Iteration 25/1000 | Loss: 0.00002242
Iteration 26/1000 | Loss: 0.00002241
Iteration 27/1000 | Loss: 0.00002241
Iteration 28/1000 | Loss: 0.00002241
Iteration 29/1000 | Loss: 0.00002241
Iteration 30/1000 | Loss: 0.00002241
Iteration 31/1000 | Loss: 0.00002240
Iteration 32/1000 | Loss: 0.00002240
Iteration 33/1000 | Loss: 0.00002240
Iteration 34/1000 | Loss: 0.00002240
Iteration 35/1000 | Loss: 0.00002240
Iteration 36/1000 | Loss: 0.00002240
Iteration 37/1000 | Loss: 0.00002240
Iteration 38/1000 | Loss: 0.00002240
Iteration 39/1000 | Loss: 0.00002239
Iteration 40/1000 | Loss: 0.00002239
Iteration 41/1000 | Loss: 0.00002239
Iteration 42/1000 | Loss: 0.00002239
Iteration 43/1000 | Loss: 0.00002239
Iteration 44/1000 | Loss: 0.00002239
Iteration 45/1000 | Loss: 0.00002239
Iteration 46/1000 | Loss: 0.00002239
Iteration 47/1000 | Loss: 0.00002238
Iteration 48/1000 | Loss: 0.00002238
Iteration 49/1000 | Loss: 0.00002238
Iteration 50/1000 | Loss: 0.00002238
Iteration 51/1000 | Loss: 0.00002238
Iteration 52/1000 | Loss: 0.00002238
Iteration 53/1000 | Loss: 0.00002238
Iteration 54/1000 | Loss: 0.00002238
Iteration 55/1000 | Loss: 0.00002237
Iteration 56/1000 | Loss: 0.00002237
Iteration 57/1000 | Loss: 0.00002237
Iteration 58/1000 | Loss: 0.00002237
Iteration 59/1000 | Loss: 0.00002237
Iteration 60/1000 | Loss: 0.00002237
Iteration 61/1000 | Loss: 0.00002237
Iteration 62/1000 | Loss: 0.00002236
Iteration 63/1000 | Loss: 0.00002236
Iteration 64/1000 | Loss: 0.00002236
Iteration 65/1000 | Loss: 0.00002236
Iteration 66/1000 | Loss: 0.00002236
Iteration 67/1000 | Loss: 0.00002235
Iteration 68/1000 | Loss: 0.00002235
Iteration 69/1000 | Loss: 0.00002235
Iteration 70/1000 | Loss: 0.00002235
Iteration 71/1000 | Loss: 0.00002235
Iteration 72/1000 | Loss: 0.00002235
Iteration 73/1000 | Loss: 0.00002235
Iteration 74/1000 | Loss: 0.00002235
Iteration 75/1000 | Loss: 0.00002235
Iteration 76/1000 | Loss: 0.00002235
Iteration 77/1000 | Loss: 0.00002235
Iteration 78/1000 | Loss: 0.00002235
Iteration 79/1000 | Loss: 0.00002235
Iteration 80/1000 | Loss: 0.00002235
Iteration 81/1000 | Loss: 0.00002234
Iteration 82/1000 | Loss: 0.00002234
Iteration 83/1000 | Loss: 0.00002234
Iteration 84/1000 | Loss: 0.00002234
Iteration 85/1000 | Loss: 0.00002234
Iteration 86/1000 | Loss: 0.00002234
Iteration 87/1000 | Loss: 0.00002234
Iteration 88/1000 | Loss: 0.00002234
Iteration 89/1000 | Loss: 0.00002234
Iteration 90/1000 | Loss: 0.00002234
Iteration 91/1000 | Loss: 0.00002234
Iteration 92/1000 | Loss: 0.00002234
Iteration 93/1000 | Loss: 0.00002234
Iteration 94/1000 | Loss: 0.00002233
Iteration 95/1000 | Loss: 0.00002233
Iteration 96/1000 | Loss: 0.00002233
Iteration 97/1000 | Loss: 0.00002233
Iteration 98/1000 | Loss: 0.00002233
Iteration 99/1000 | Loss: 0.00002233
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 99. Stopping optimization.
Last 5 losses: [2.2334696041070856e-05, 2.2334696041070856e-05, 2.2334696041070856e-05, 2.2334696041070856e-05, 2.2334696041070856e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.2334696041070856e-05

Optimization complete. Final v2v error: 4.057365417480469 mm

Highest mean error: 4.41334867477417 mm for frame 156

Lowest mean error: 3.598008394241333 mm for frame 100

Saving results

Total time: 35.57284998893738
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0012/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0012.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0012
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00424333
Iteration 2/25 | Loss: 0.00091351
Iteration 3/25 | Loss: 0.00075536
Iteration 4/25 | Loss: 0.00073286
Iteration 5/25 | Loss: 0.00072556
Iteration 6/25 | Loss: 0.00072349
Iteration 7/25 | Loss: 0.00072311
Iteration 8/25 | Loss: 0.00072310
Iteration 9/25 | Loss: 0.00072310
Iteration 10/25 | Loss: 0.00072310
Iteration 11/25 | Loss: 0.00072310
Iteration 12/25 | Loss: 0.00072310
Iteration 13/25 | Loss: 0.00072310
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007230966002680361, 0.0007230966002680361, 0.0007230966002680361, 0.0007230966002680361, 0.0007230966002680361]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007230966002680361

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 5.50798178
Iteration 2/25 | Loss: 0.00024350
Iteration 3/25 | Loss: 0.00024349
Iteration 4/25 | Loss: 0.00024349
Iteration 5/25 | Loss: 0.00024348
Iteration 6/25 | Loss: 0.00024348
Iteration 7/25 | Loss: 0.00024348
Iteration 8/25 | Loss: 0.00024348
Iteration 9/25 | Loss: 0.00024348
Iteration 10/25 | Loss: 0.00024348
Iteration 11/25 | Loss: 0.00024348
Iteration 12/25 | Loss: 0.00024348
Iteration 13/25 | Loss: 0.00024348
Iteration 14/25 | Loss: 0.00024348
Iteration 15/25 | Loss: 0.00024348
Iteration 16/25 | Loss: 0.00024348
Iteration 17/25 | Loss: 0.00024348
Iteration 18/25 | Loss: 0.00024348
Iteration 19/25 | Loss: 0.00024348
Iteration 20/25 | Loss: 0.00024348
Iteration 21/25 | Loss: 0.00024348
Iteration 22/25 | Loss: 0.00024348
Iteration 23/25 | Loss: 0.00024348
Iteration 24/25 | Loss: 0.00024348
Iteration 25/25 | Loss: 0.00024348

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00024348
Iteration 2/1000 | Loss: 0.00003169
Iteration 3/1000 | Loss: 0.00002178
Iteration 4/1000 | Loss: 0.00002053
Iteration 5/1000 | Loss: 0.00001942
Iteration 6/1000 | Loss: 0.00001886
Iteration 7/1000 | Loss: 0.00001835
Iteration 8/1000 | Loss: 0.00001804
Iteration 9/1000 | Loss: 0.00001799
Iteration 10/1000 | Loss: 0.00001790
Iteration 11/1000 | Loss: 0.00001789
Iteration 12/1000 | Loss: 0.00001787
Iteration 13/1000 | Loss: 0.00001786
Iteration 14/1000 | Loss: 0.00001786
Iteration 15/1000 | Loss: 0.00001785
Iteration 16/1000 | Loss: 0.00001784
Iteration 17/1000 | Loss: 0.00001783
Iteration 18/1000 | Loss: 0.00001783
Iteration 19/1000 | Loss: 0.00001781
Iteration 20/1000 | Loss: 0.00001781
Iteration 21/1000 | Loss: 0.00001779
Iteration 22/1000 | Loss: 0.00001774
Iteration 23/1000 | Loss: 0.00001772
Iteration 24/1000 | Loss: 0.00001772
Iteration 25/1000 | Loss: 0.00001771
Iteration 26/1000 | Loss: 0.00001771
Iteration 27/1000 | Loss: 0.00001770
Iteration 28/1000 | Loss: 0.00001769
Iteration 29/1000 | Loss: 0.00001769
Iteration 30/1000 | Loss: 0.00001769
Iteration 31/1000 | Loss: 0.00001768
Iteration 32/1000 | Loss: 0.00001768
Iteration 33/1000 | Loss: 0.00001768
Iteration 34/1000 | Loss: 0.00001768
Iteration 35/1000 | Loss: 0.00001767
Iteration 36/1000 | Loss: 0.00001767
Iteration 37/1000 | Loss: 0.00001767
Iteration 38/1000 | Loss: 0.00001767
Iteration 39/1000 | Loss: 0.00001766
Iteration 40/1000 | Loss: 0.00001766
Iteration 41/1000 | Loss: 0.00001765
Iteration 42/1000 | Loss: 0.00001765
Iteration 43/1000 | Loss: 0.00001765
Iteration 44/1000 | Loss: 0.00001764
Iteration 45/1000 | Loss: 0.00001764
Iteration 46/1000 | Loss: 0.00001764
Iteration 47/1000 | Loss: 0.00001764
Iteration 48/1000 | Loss: 0.00001764
Iteration 49/1000 | Loss: 0.00001764
Iteration 50/1000 | Loss: 0.00001764
Iteration 51/1000 | Loss: 0.00001764
Iteration 52/1000 | Loss: 0.00001764
Iteration 53/1000 | Loss: 0.00001764
Iteration 54/1000 | Loss: 0.00001764
Iteration 55/1000 | Loss: 0.00001764
Iteration 56/1000 | Loss: 0.00001764
Iteration 57/1000 | Loss: 0.00001764
Iteration 58/1000 | Loss: 0.00001764
Iteration 59/1000 | Loss: 0.00001764
Iteration 60/1000 | Loss: 0.00001764
Iteration 61/1000 | Loss: 0.00001764
Iteration 62/1000 | Loss: 0.00001764
Iteration 63/1000 | Loss: 0.00001764
Iteration 64/1000 | Loss: 0.00001763
Iteration 65/1000 | Loss: 0.00001763
Iteration 66/1000 | Loss: 0.00001763
Iteration 67/1000 | Loss: 0.00001763
Iteration 68/1000 | Loss: 0.00001763
Iteration 69/1000 | Loss: 0.00001763
Iteration 70/1000 | Loss: 0.00001763
Iteration 71/1000 | Loss: 0.00001763
Iteration 72/1000 | Loss: 0.00001763
Iteration 73/1000 | Loss: 0.00001763
Iteration 74/1000 | Loss: 0.00001763
Iteration 75/1000 | Loss: 0.00001763
Iteration 76/1000 | Loss: 0.00001763
Iteration 77/1000 | Loss: 0.00001763
Iteration 78/1000 | Loss: 0.00001763
Iteration 79/1000 | Loss: 0.00001763
Iteration 80/1000 | Loss: 0.00001763
Iteration 81/1000 | Loss: 0.00001763
Iteration 82/1000 | Loss: 0.00001763
Iteration 83/1000 | Loss: 0.00001763
Iteration 84/1000 | Loss: 0.00001763
Iteration 85/1000 | Loss: 0.00001763
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 85. Stopping optimization.
Last 5 losses: [1.7634711184655316e-05, 1.7634711184655316e-05, 1.7634711184655316e-05, 1.7634711184655316e-05, 1.7634711184655316e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.7634711184655316e-05

Optimization complete. Final v2v error: 3.6091461181640625 mm

Highest mean error: 4.354525089263916 mm for frame 71

Lowest mean error: 3.2765750885009766 mm for frame 9

Saving results

Total time: 27.988887548446655
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0007/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0007.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0007
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00809175
Iteration 2/25 | Loss: 0.00156818
Iteration 3/25 | Loss: 0.00106808
Iteration 4/25 | Loss: 0.00094582
Iteration 5/25 | Loss: 0.00092211
Iteration 6/25 | Loss: 0.00091591
Iteration 7/25 | Loss: 0.00091463
Iteration 8/25 | Loss: 0.00091463
Iteration 9/25 | Loss: 0.00091463
Iteration 10/25 | Loss: 0.00091463
Iteration 11/25 | Loss: 0.00091463
Iteration 12/25 | Loss: 0.00091463
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.0009146271622739732, 0.0009146271622739732, 0.0009146271622739732, 0.0009146271622739732, 0.0009146271622739732]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0009146271622739732

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.17907131
Iteration 2/25 | Loss: 0.00043250
Iteration 3/25 | Loss: 0.00043248
Iteration 4/25 | Loss: 0.00043248
Iteration 5/25 | Loss: 0.00043248
Iteration 6/25 | Loss: 0.00043248
Iteration 7/25 | Loss: 0.00043248
Iteration 8/25 | Loss: 0.00043248
Iteration 9/25 | Loss: 0.00043248
Iteration 10/25 | Loss: 0.00043248
Iteration 11/25 | Loss: 0.00043248
Iteration 12/25 | Loss: 0.00043248
Iteration 13/25 | Loss: 0.00043248
Iteration 14/25 | Loss: 0.00043248
Iteration 15/25 | Loss: 0.00043248
Iteration 16/25 | Loss: 0.00043248
Iteration 17/25 | Loss: 0.00043248
Iteration 18/25 | Loss: 0.00043248
Iteration 19/25 | Loss: 0.00043248
Iteration 20/25 | Loss: 0.00043248
Iteration 21/25 | Loss: 0.00043248
Iteration 22/25 | Loss: 0.00043248
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00043247902067378163, 0.00043247902067378163, 0.00043247902067378163, 0.00043247902067378163, 0.00043247902067378163]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00043247902067378163

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043248
Iteration 2/1000 | Loss: 0.00007504
Iteration 3/1000 | Loss: 0.00004506
Iteration 4/1000 | Loss: 0.00003902
Iteration 5/1000 | Loss: 0.00003686
Iteration 6/1000 | Loss: 0.00003511
Iteration 7/1000 | Loss: 0.00003398
Iteration 8/1000 | Loss: 0.00003313
Iteration 9/1000 | Loss: 0.00003250
Iteration 10/1000 | Loss: 0.00003208
Iteration 11/1000 | Loss: 0.00003173
Iteration 12/1000 | Loss: 0.00003148
Iteration 13/1000 | Loss: 0.00003132
Iteration 14/1000 | Loss: 0.00003115
Iteration 15/1000 | Loss: 0.00003098
Iteration 16/1000 | Loss: 0.00003096
Iteration 17/1000 | Loss: 0.00003091
Iteration 18/1000 | Loss: 0.00003082
Iteration 19/1000 | Loss: 0.00003078
Iteration 20/1000 | Loss: 0.00003078
Iteration 21/1000 | Loss: 0.00003078
Iteration 22/1000 | Loss: 0.00003077
Iteration 23/1000 | Loss: 0.00003077
Iteration 24/1000 | Loss: 0.00003076
Iteration 25/1000 | Loss: 0.00003076
Iteration 26/1000 | Loss: 0.00003075
Iteration 27/1000 | Loss: 0.00003075
Iteration 28/1000 | Loss: 0.00003074
Iteration 29/1000 | Loss: 0.00003074
Iteration 30/1000 | Loss: 0.00003074
Iteration 31/1000 | Loss: 0.00003074
Iteration 32/1000 | Loss: 0.00003074
Iteration 33/1000 | Loss: 0.00003074
Iteration 34/1000 | Loss: 0.00003073
Iteration 35/1000 | Loss: 0.00003073
Iteration 36/1000 | Loss: 0.00003073
Iteration 37/1000 | Loss: 0.00003073
Iteration 38/1000 | Loss: 0.00003073
Iteration 39/1000 | Loss: 0.00003073
Iteration 40/1000 | Loss: 0.00003073
Iteration 41/1000 | Loss: 0.00003073
Iteration 42/1000 | Loss: 0.00003073
Iteration 43/1000 | Loss: 0.00003073
Iteration 44/1000 | Loss: 0.00003073
Iteration 45/1000 | Loss: 0.00003071
Iteration 46/1000 | Loss: 0.00003071
Iteration 47/1000 | Loss: 0.00003071
Iteration 48/1000 | Loss: 0.00003070
Iteration 49/1000 | Loss: 0.00003070
Iteration 50/1000 | Loss: 0.00003070
Iteration 51/1000 | Loss: 0.00003070
Iteration 52/1000 | Loss: 0.00003070
Iteration 53/1000 | Loss: 0.00003070
Iteration 54/1000 | Loss: 0.00003070
Iteration 55/1000 | Loss: 0.00003070
Iteration 56/1000 | Loss: 0.00003070
Iteration 57/1000 | Loss: 0.00003069
Iteration 58/1000 | Loss: 0.00003069
Iteration 59/1000 | Loss: 0.00003069
Iteration 60/1000 | Loss: 0.00003069
Iteration 61/1000 | Loss: 0.00003069
Iteration 62/1000 | Loss: 0.00003069
Iteration 63/1000 | Loss: 0.00003069
Iteration 64/1000 | Loss: 0.00003068
Iteration 65/1000 | Loss: 0.00003068
Iteration 66/1000 | Loss: 0.00003068
Iteration 67/1000 | Loss: 0.00003068
Iteration 68/1000 | Loss: 0.00003068
Iteration 69/1000 | Loss: 0.00003068
Iteration 70/1000 | Loss: 0.00003067
Iteration 71/1000 | Loss: 0.00003067
Iteration 72/1000 | Loss: 0.00003067
Iteration 73/1000 | Loss: 0.00003067
Iteration 74/1000 | Loss: 0.00003067
Iteration 75/1000 | Loss: 0.00003067
Iteration 76/1000 | Loss: 0.00003067
Iteration 77/1000 | Loss: 0.00003067
Iteration 78/1000 | Loss: 0.00003067
Iteration 79/1000 | Loss: 0.00003067
Iteration 80/1000 | Loss: 0.00003067
Iteration 81/1000 | Loss: 0.00003067
Iteration 82/1000 | Loss: 0.00003067
Iteration 83/1000 | Loss: 0.00003066
Iteration 84/1000 | Loss: 0.00003066
Iteration 85/1000 | Loss: 0.00003066
Iteration 86/1000 | Loss: 0.00003066
Iteration 87/1000 | Loss: 0.00003066
Iteration 88/1000 | Loss: 0.00003066
Iteration 89/1000 | Loss: 0.00003066
Iteration 90/1000 | Loss: 0.00003066
Iteration 91/1000 | Loss: 0.00003066
Iteration 92/1000 | Loss: 0.00003066
Iteration 93/1000 | Loss: 0.00003066
Iteration 94/1000 | Loss: 0.00003066
Iteration 95/1000 | Loss: 0.00003065
Iteration 96/1000 | Loss: 0.00003065
Iteration 97/1000 | Loss: 0.00003065
Iteration 98/1000 | Loss: 0.00003065
Iteration 99/1000 | Loss: 0.00003065
Iteration 100/1000 | Loss: 0.00003065
Iteration 101/1000 | Loss: 0.00003065
Iteration 102/1000 | Loss: 0.00003064
Iteration 103/1000 | Loss: 0.00003064
Iteration 104/1000 | Loss: 0.00003064
Iteration 105/1000 | Loss: 0.00003064
Iteration 106/1000 | Loss: 0.00003064
Iteration 107/1000 | Loss: 0.00003064
Iteration 108/1000 | Loss: 0.00003064
Iteration 109/1000 | Loss: 0.00003064
Iteration 110/1000 | Loss: 0.00003064
Iteration 111/1000 | Loss: 0.00003064
Iteration 112/1000 | Loss: 0.00003064
Iteration 113/1000 | Loss: 0.00003063
Iteration 114/1000 | Loss: 0.00003063
Iteration 115/1000 | Loss: 0.00003063
Iteration 116/1000 | Loss: 0.00003063
Iteration 117/1000 | Loss: 0.00003063
Iteration 118/1000 | Loss: 0.00003063
Iteration 119/1000 | Loss: 0.00003063
Iteration 120/1000 | Loss: 0.00003063
Iteration 121/1000 | Loss: 0.00003063
Iteration 122/1000 | Loss: 0.00003063
Iteration 123/1000 | Loss: 0.00003063
Iteration 124/1000 | Loss: 0.00003063
Iteration 125/1000 | Loss: 0.00003063
Iteration 126/1000 | Loss: 0.00003062
Iteration 127/1000 | Loss: 0.00003062
Iteration 128/1000 | Loss: 0.00003062
Iteration 129/1000 | Loss: 0.00003062
Iteration 130/1000 | Loss: 0.00003062
Iteration 131/1000 | Loss: 0.00003062
Iteration 132/1000 | Loss: 0.00003061
Iteration 133/1000 | Loss: 0.00003061
Iteration 134/1000 | Loss: 0.00003061
Iteration 135/1000 | Loss: 0.00003061
Iteration 136/1000 | Loss: 0.00003061
Iteration 137/1000 | Loss: 0.00003061
Iteration 138/1000 | Loss: 0.00003061
Iteration 139/1000 | Loss: 0.00003061
Iteration 140/1000 | Loss: 0.00003061
Iteration 141/1000 | Loss: 0.00003061
Iteration 142/1000 | Loss: 0.00003061
Iteration 143/1000 | Loss: 0.00003061
Iteration 144/1000 | Loss: 0.00003061
Iteration 145/1000 | Loss: 0.00003061
Iteration 146/1000 | Loss: 0.00003061
Iteration 147/1000 | Loss: 0.00003061
Iteration 148/1000 | Loss: 0.00003061
Iteration 149/1000 | Loss: 0.00003061
Iteration 150/1000 | Loss: 0.00003061
Iteration 151/1000 | Loss: 0.00003061
Iteration 152/1000 | Loss: 0.00003061
Iteration 153/1000 | Loss: 0.00003061
Iteration 154/1000 | Loss: 0.00003061
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 154. Stopping optimization.
Last 5 losses: [3.060766539420001e-05, 3.060766539420001e-05, 3.060766539420001e-05, 3.060766539420001e-05, 3.060766539420001e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 3.060766539420001e-05

Optimization complete. Final v2v error: 4.633979797363281 mm

Highest mean error: 6.031572341918945 mm for frame 75

Lowest mean error: 3.5478360652923584 mm for frame 171

Saving results

Total time: 47.66045093536377
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0003/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0003.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0003
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00828417
Iteration 2/25 | Loss: 0.00106040
Iteration 3/25 | Loss: 0.00079166
Iteration 4/25 | Loss: 0.00076426
Iteration 5/25 | Loss: 0.00075822
Iteration 6/25 | Loss: 0.00075743
Iteration 7/25 | Loss: 0.00075743
Iteration 8/25 | Loss: 0.00075743
Iteration 9/25 | Loss: 0.00075743
Iteration 10/25 | Loss: 0.00075743
Iteration 11/25 | Loss: 0.00075743
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 11. Stopping optimization.
Last 5 losses: [0.0007574316114187241, 0.0007574316114187241, 0.0007574316114187241, 0.0007574316114187241, 0.0007574316114187241]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007574316114187241

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.35963643
Iteration 2/25 | Loss: 0.00043003
Iteration 3/25 | Loss: 0.00043001
Iteration 4/25 | Loss: 0.00043001
Iteration 5/25 | Loss: 0.00043001
Iteration 6/25 | Loss: 0.00043001
Iteration 7/25 | Loss: 0.00043001
Iteration 8/25 | Loss: 0.00043001
Iteration 9/25 | Loss: 0.00043001
Iteration 10/25 | Loss: 0.00043001
Iteration 11/25 | Loss: 0.00043001
Iteration 12/25 | Loss: 0.00043001
Iteration 13/25 | Loss: 0.00043001
Iteration 14/25 | Loss: 0.00043001
Iteration 15/25 | Loss: 0.00043001
Iteration 16/25 | Loss: 0.00043001
Iteration 17/25 | Loss: 0.00043001
Iteration 18/25 | Loss: 0.00043001
Iteration 19/25 | Loss: 0.00043001
Iteration 20/25 | Loss: 0.00043001
Iteration 21/25 | Loss: 0.00043001
Iteration 22/25 | Loss: 0.00043001
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 22. Stopping optimization.
Last 5 losses: [0.00043000944424420595, 0.00043000944424420595, 0.00043000944424420595, 0.00043000944424420595, 0.00043000944424420595]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00043000944424420595

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00043001
Iteration 2/1000 | Loss: 0.00003928
Iteration 3/1000 | Loss: 0.00002614
Iteration 4/1000 | Loss: 0.00002412
Iteration 5/1000 | Loss: 0.00002293
Iteration 6/1000 | Loss: 0.00002207
Iteration 7/1000 | Loss: 0.00002133
Iteration 8/1000 | Loss: 0.00002077
Iteration 9/1000 | Loss: 0.00002049
Iteration 10/1000 | Loss: 0.00002034
Iteration 11/1000 | Loss: 0.00002031
Iteration 12/1000 | Loss: 0.00002028
Iteration 13/1000 | Loss: 0.00002025
Iteration 14/1000 | Loss: 0.00002019
Iteration 15/1000 | Loss: 0.00002017
Iteration 16/1000 | Loss: 0.00002017
Iteration 17/1000 | Loss: 0.00002016
Iteration 18/1000 | Loss: 0.00002016
Iteration 19/1000 | Loss: 0.00002016
Iteration 20/1000 | Loss: 0.00002015
Iteration 21/1000 | Loss: 0.00002013
Iteration 22/1000 | Loss: 0.00002013
Iteration 23/1000 | Loss: 0.00002012
Iteration 24/1000 | Loss: 0.00002010
Iteration 25/1000 | Loss: 0.00002009
Iteration 26/1000 | Loss: 0.00002008
Iteration 27/1000 | Loss: 0.00002007
Iteration 28/1000 | Loss: 0.00002007
Iteration 29/1000 | Loss: 0.00002007
Iteration 30/1000 | Loss: 0.00002007
Iteration 31/1000 | Loss: 0.00002007
Iteration 32/1000 | Loss: 0.00002007
Iteration 33/1000 | Loss: 0.00002007
Iteration 34/1000 | Loss: 0.00002006
Iteration 35/1000 | Loss: 0.00002006
Iteration 36/1000 | Loss: 0.00002005
Iteration 37/1000 | Loss: 0.00002005
Iteration 38/1000 | Loss: 0.00002005
Iteration 39/1000 | Loss: 0.00002004
Iteration 40/1000 | Loss: 0.00002004
Iteration 41/1000 | Loss: 0.00002004
Iteration 42/1000 | Loss: 0.00002004
Iteration 43/1000 | Loss: 0.00002004
Iteration 44/1000 | Loss: 0.00002004
Iteration 45/1000 | Loss: 0.00002004
Iteration 46/1000 | Loss: 0.00002003
Iteration 47/1000 | Loss: 0.00002003
Iteration 48/1000 | Loss: 0.00002003
Iteration 49/1000 | Loss: 0.00002003
Iteration 50/1000 | Loss: 0.00002003
Iteration 51/1000 | Loss: 0.00002003
Iteration 52/1000 | Loss: 0.00002003
Iteration 53/1000 | Loss: 0.00002003
Iteration 54/1000 | Loss: 0.00002003
Iteration 55/1000 | Loss: 0.00002003
Iteration 56/1000 | Loss: 0.00002002
Iteration 57/1000 | Loss: 0.00002002
Iteration 58/1000 | Loss: 0.00002001
Iteration 59/1000 | Loss: 0.00002001
Iteration 60/1000 | Loss: 0.00002001
Iteration 61/1000 | Loss: 0.00002001
Iteration 62/1000 | Loss: 0.00002001
Iteration 63/1000 | Loss: 0.00002000
Iteration 64/1000 | Loss: 0.00002000
Iteration 65/1000 | Loss: 0.00002000
Iteration 66/1000 | Loss: 0.00002000
Iteration 67/1000 | Loss: 0.00002000
Iteration 68/1000 | Loss: 0.00002000
Iteration 69/1000 | Loss: 0.00002000
Iteration 70/1000 | Loss: 0.00002000
Iteration 71/1000 | Loss: 0.00002000
Iteration 72/1000 | Loss: 0.00002000
Iteration 73/1000 | Loss: 0.00002000
Iteration 74/1000 | Loss: 0.00002000
Iteration 75/1000 | Loss: 0.00001999
Iteration 76/1000 | Loss: 0.00001999
Iteration 77/1000 | Loss: 0.00001999
Iteration 78/1000 | Loss: 0.00001999
Iteration 79/1000 | Loss: 0.00001999
Iteration 80/1000 | Loss: 0.00001999
Iteration 81/1000 | Loss: 0.00001998
Iteration 82/1000 | Loss: 0.00001998
Iteration 83/1000 | Loss: 0.00001998
Iteration 84/1000 | Loss: 0.00001998
Iteration 85/1000 | Loss: 0.00001997
Iteration 86/1000 | Loss: 0.00001997
Iteration 87/1000 | Loss: 0.00001997
Iteration 88/1000 | Loss: 0.00001996
Iteration 89/1000 | Loss: 0.00001996
Iteration 90/1000 | Loss: 0.00001996
Iteration 91/1000 | Loss: 0.00001996
Iteration 92/1000 | Loss: 0.00001996
Iteration 93/1000 | Loss: 0.00001996
Iteration 94/1000 | Loss: 0.00001996
Iteration 95/1000 | Loss: 0.00001996
Iteration 96/1000 | Loss: 0.00001996
Iteration 97/1000 | Loss: 0.00001996
Iteration 98/1000 | Loss: 0.00001996
Iteration 99/1000 | Loss: 0.00001996
Iteration 100/1000 | Loss: 0.00001996
Iteration 101/1000 | Loss: 0.00001996
Iteration 102/1000 | Loss: 0.00001996
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 102. Stopping optimization.
Last 5 losses: [1.9955587049480528e-05, 1.9955587049480528e-05, 1.9955587049480528e-05, 1.9955587049480528e-05, 1.9955587049480528e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9955587049480528e-05

Optimization complete. Final v2v error: 3.855968952178955 mm

Highest mean error: 4.255357265472412 mm for frame 118

Lowest mean error: 3.4634575843811035 mm for frame 43

Saving results

Total time: 28.96374225616455
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0018/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0018.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0018
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01064654
Iteration 2/25 | Loss: 0.00217922
Iteration 3/25 | Loss: 0.00157824
Iteration 4/25 | Loss: 0.00140108
Iteration 5/25 | Loss: 0.00153741
Iteration 6/25 | Loss: 0.00130708
Iteration 7/25 | Loss: 0.00105083
Iteration 8/25 | Loss: 0.00097680
Iteration 9/25 | Loss: 0.00093403
Iteration 10/25 | Loss: 0.00089095
Iteration 11/25 | Loss: 0.00086666
Iteration 12/25 | Loss: 0.00085640
Iteration 13/25 | Loss: 0.00084431
Iteration 14/25 | Loss: 0.00083506
Iteration 15/25 | Loss: 0.00083312
Iteration 16/25 | Loss: 0.00083304
Iteration 17/25 | Loss: 0.00083399
Iteration 18/25 | Loss: 0.00083022
Iteration 19/25 | Loss: 0.00082824
Iteration 20/25 | Loss: 0.00082807
Iteration 21/25 | Loss: 0.00082363
Iteration 22/25 | Loss: 0.00083262
Iteration 23/25 | Loss: 0.00082997
Iteration 24/25 | Loss: 0.00082658
Iteration 25/25 | Loss: 0.00082173

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39183283
Iteration 2/25 | Loss: 0.00100035
Iteration 3/25 | Loss: 0.00100035
Iteration 4/25 | Loss: 0.00100034
Iteration 5/25 | Loss: 0.00100034
Iteration 6/25 | Loss: 0.00100034
Iteration 7/25 | Loss: 0.00100034
Iteration 8/25 | Loss: 0.00100034
Iteration 9/25 | Loss: 0.00100034
Iteration 10/25 | Loss: 0.00100034
Iteration 11/25 | Loss: 0.00100034
Iteration 12/25 | Loss: 0.00100034
Iteration 13/25 | Loss: 0.00100034
Iteration 14/25 | Loss: 0.00100034
Iteration 15/25 | Loss: 0.00100034
Iteration 16/25 | Loss: 0.00100034
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 16. Stopping optimization.
Last 5 losses: [0.0010003437055274844, 0.0010003437055274844, 0.0010003437055274844, 0.0010003437055274844, 0.0010003437055274844]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0010003437055274844

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00100034
Iteration 2/1000 | Loss: 0.00055206
Iteration 3/1000 | Loss: 0.00026837
Iteration 4/1000 | Loss: 0.00019375
Iteration 5/1000 | Loss: 0.00009772
Iteration 6/1000 | Loss: 0.00007622
Iteration 7/1000 | Loss: 0.00006846
Iteration 8/1000 | Loss: 0.00029621
Iteration 9/1000 | Loss: 0.00007414
Iteration 10/1000 | Loss: 0.00006769
Iteration 11/1000 | Loss: 0.00030145
Iteration 12/1000 | Loss: 0.00151078
Iteration 13/1000 | Loss: 0.00025588
Iteration 14/1000 | Loss: 0.00012714
Iteration 15/1000 | Loss: 0.00007644
Iteration 16/1000 | Loss: 0.00004533
Iteration 17/1000 | Loss: 0.00003720
Iteration 18/1000 | Loss: 0.00003140
Iteration 19/1000 | Loss: 0.00002719
Iteration 20/1000 | Loss: 0.00002497
Iteration 21/1000 | Loss: 0.00002328
Iteration 22/1000 | Loss: 0.00002218
Iteration 23/1000 | Loss: 0.00002153
Iteration 24/1000 | Loss: 0.00004344
Iteration 25/1000 | Loss: 0.00003646
Iteration 26/1000 | Loss: 0.00002446
Iteration 27/1000 | Loss: 0.00004017
Iteration 28/1000 | Loss: 0.00003521
Iteration 29/1000 | Loss: 0.00003795
Iteration 30/1000 | Loss: 0.00002151
Iteration 31/1000 | Loss: 0.00002034
Iteration 32/1000 | Loss: 0.00001967
Iteration 33/1000 | Loss: 0.00001925
Iteration 34/1000 | Loss: 0.00001907
Iteration 35/1000 | Loss: 0.00001888
Iteration 36/1000 | Loss: 0.00001885
Iteration 37/1000 | Loss: 0.00001885
Iteration 38/1000 | Loss: 0.00001883
Iteration 39/1000 | Loss: 0.00001882
Iteration 40/1000 | Loss: 0.00001882
Iteration 41/1000 | Loss: 0.00001881
Iteration 42/1000 | Loss: 0.00001878
Iteration 43/1000 | Loss: 0.00001877
Iteration 44/1000 | Loss: 0.00001876
Iteration 45/1000 | Loss: 0.00001876
Iteration 46/1000 | Loss: 0.00001876
Iteration 47/1000 | Loss: 0.00001875
Iteration 48/1000 | Loss: 0.00001874
Iteration 49/1000 | Loss: 0.00001874
Iteration 50/1000 | Loss: 0.00001874
Iteration 51/1000 | Loss: 0.00001873
Iteration 52/1000 | Loss: 0.00001873
Iteration 53/1000 | Loss: 0.00001873
Iteration 54/1000 | Loss: 0.00001872
Iteration 55/1000 | Loss: 0.00001872
Iteration 56/1000 | Loss: 0.00001872
Iteration 57/1000 | Loss: 0.00001871
Iteration 58/1000 | Loss: 0.00001871
Iteration 59/1000 | Loss: 0.00001871
Iteration 60/1000 | Loss: 0.00001871
Iteration 61/1000 | Loss: 0.00001871
Iteration 62/1000 | Loss: 0.00001870
Iteration 63/1000 | Loss: 0.00001870
Iteration 64/1000 | Loss: 0.00001870
Iteration 65/1000 | Loss: 0.00001870
Iteration 66/1000 | Loss: 0.00001869
Iteration 67/1000 | Loss: 0.00001869
Iteration 68/1000 | Loss: 0.00001869
Iteration 69/1000 | Loss: 0.00001868
Iteration 70/1000 | Loss: 0.00001868
Iteration 71/1000 | Loss: 0.00001868
Iteration 72/1000 | Loss: 0.00001868
Iteration 73/1000 | Loss: 0.00001868
Iteration 74/1000 | Loss: 0.00001867
Iteration 75/1000 | Loss: 0.00001867
Iteration 76/1000 | Loss: 0.00001867
Iteration 77/1000 | Loss: 0.00001866
Iteration 78/1000 | Loss: 0.00001866
Iteration 79/1000 | Loss: 0.00001866
Iteration 80/1000 | Loss: 0.00001865
Iteration 81/1000 | Loss: 0.00001865
Iteration 82/1000 | Loss: 0.00001865
Iteration 83/1000 | Loss: 0.00001864
Iteration 84/1000 | Loss: 0.00001864
Iteration 85/1000 | Loss: 0.00001863
Iteration 86/1000 | Loss: 0.00001863
Iteration 87/1000 | Loss: 0.00001863
Iteration 88/1000 | Loss: 0.00001862
Iteration 89/1000 | Loss: 0.00001862
Iteration 90/1000 | Loss: 0.00001862
Iteration 91/1000 | Loss: 0.00001861
Iteration 92/1000 | Loss: 0.00001861
Iteration 93/1000 | Loss: 0.00001861
Iteration 94/1000 | Loss: 0.00001861
Iteration 95/1000 | Loss: 0.00001861
Iteration 96/1000 | Loss: 0.00001861
Iteration 97/1000 | Loss: 0.00001861
Iteration 98/1000 | Loss: 0.00001861
Iteration 99/1000 | Loss: 0.00001860
Iteration 100/1000 | Loss: 0.00001860
Iteration 101/1000 | Loss: 0.00001860
Iteration 102/1000 | Loss: 0.00001860
Iteration 103/1000 | Loss: 0.00001860
Iteration 104/1000 | Loss: 0.00001860
Iteration 105/1000 | Loss: 0.00001860
Iteration 106/1000 | Loss: 0.00001859
Iteration 107/1000 | Loss: 0.00001859
Iteration 108/1000 | Loss: 0.00001859
Iteration 109/1000 | Loss: 0.00001859
Iteration 110/1000 | Loss: 0.00001859
Iteration 111/1000 | Loss: 0.00001859
Iteration 112/1000 | Loss: 0.00001859
Iteration 113/1000 | Loss: 0.00001859
Iteration 114/1000 | Loss: 0.00001859
Iteration 115/1000 | Loss: 0.00001859
Iteration 116/1000 | Loss: 0.00001859
Iteration 117/1000 | Loss: 0.00001859
Iteration 118/1000 | Loss: 0.00001859
Iteration 119/1000 | Loss: 0.00001859
Iteration 120/1000 | Loss: 0.00001859
Iteration 121/1000 | Loss: 0.00001859
Iteration 122/1000 | Loss: 0.00001858
Iteration 123/1000 | Loss: 0.00001858
Iteration 124/1000 | Loss: 0.00001858
Iteration 125/1000 | Loss: 0.00001858
Iteration 126/1000 | Loss: 0.00001858
Iteration 127/1000 | Loss: 0.00001857
Iteration 128/1000 | Loss: 0.00001857
Iteration 129/1000 | Loss: 0.00001857
Iteration 130/1000 | Loss: 0.00001857
Iteration 131/1000 | Loss: 0.00001857
Iteration 132/1000 | Loss: 0.00001857
Iteration 133/1000 | Loss: 0.00001857
Iteration 134/1000 | Loss: 0.00001857
Iteration 135/1000 | Loss: 0.00001857
Iteration 136/1000 | Loss: 0.00001857
Iteration 137/1000 | Loss: 0.00001857
Iteration 138/1000 | Loss: 0.00001856
Iteration 139/1000 | Loss: 0.00001856
Iteration 140/1000 | Loss: 0.00001856
Iteration 141/1000 | Loss: 0.00001856
Iteration 142/1000 | Loss: 0.00001856
Iteration 143/1000 | Loss: 0.00001856
Iteration 144/1000 | Loss: 0.00001856
Iteration 145/1000 | Loss: 0.00001856
Iteration 146/1000 | Loss: 0.00001856
Iteration 147/1000 | Loss: 0.00001856
Iteration 148/1000 | Loss: 0.00001855
Iteration 149/1000 | Loss: 0.00001855
Iteration 150/1000 | Loss: 0.00001855
Iteration 151/1000 | Loss: 0.00001854
Iteration 152/1000 | Loss: 0.00001854
Iteration 153/1000 | Loss: 0.00001854
Iteration 154/1000 | Loss: 0.00001854
Iteration 155/1000 | Loss: 0.00001853
Iteration 156/1000 | Loss: 0.00001853
Iteration 157/1000 | Loss: 0.00001853
Iteration 158/1000 | Loss: 0.00001853
Iteration 159/1000 | Loss: 0.00001853
Iteration 160/1000 | Loss: 0.00001853
Iteration 161/1000 | Loss: 0.00001853
Iteration 162/1000 | Loss: 0.00001853
Iteration 163/1000 | Loss: 0.00001853
Iteration 164/1000 | Loss: 0.00001853
Iteration 165/1000 | Loss: 0.00026214
Iteration 166/1000 | Loss: 0.00002713
Iteration 167/1000 | Loss: 0.00002462
Iteration 168/1000 | Loss: 0.00002329
Iteration 169/1000 | Loss: 0.00002231
Iteration 170/1000 | Loss: 0.00006307
Iteration 171/1000 | Loss: 0.00002129
Iteration 172/1000 | Loss: 0.00002071
Iteration 173/1000 | Loss: 0.00007004
Iteration 174/1000 | Loss: 0.00001991
Iteration 175/1000 | Loss: 0.00001984
Iteration 176/1000 | Loss: 0.00001968
Iteration 177/1000 | Loss: 0.00001963
Iteration 178/1000 | Loss: 0.00001959
Iteration 179/1000 | Loss: 0.00001959
Iteration 180/1000 | Loss: 0.00001959
Iteration 181/1000 | Loss: 0.00001958
Iteration 182/1000 | Loss: 0.00001958
Iteration 183/1000 | Loss: 0.00001958
Iteration 184/1000 | Loss: 0.00001958
Iteration 185/1000 | Loss: 0.00001957
Iteration 186/1000 | Loss: 0.00001957
Iteration 187/1000 | Loss: 0.00001957
Iteration 188/1000 | Loss: 0.00001957
Iteration 189/1000 | Loss: 0.00001956
Iteration 190/1000 | Loss: 0.00001956
Iteration 191/1000 | Loss: 0.00001956
Iteration 192/1000 | Loss: 0.00001956
Iteration 193/1000 | Loss: 0.00001956
Iteration 194/1000 | Loss: 0.00001956
Iteration 195/1000 | Loss: 0.00001956
Iteration 196/1000 | Loss: 0.00001955
Iteration 197/1000 | Loss: 0.00001955
Iteration 198/1000 | Loss: 0.00001955
Iteration 199/1000 | Loss: 0.00001955
Iteration 200/1000 | Loss: 0.00001955
Iteration 201/1000 | Loss: 0.00001955
Iteration 202/1000 | Loss: 0.00001955
Iteration 203/1000 | Loss: 0.00001955
Iteration 204/1000 | Loss: 0.00001955
Iteration 205/1000 | Loss: 0.00001955
Iteration 206/1000 | Loss: 0.00001955
Iteration 207/1000 | Loss: 0.00001955
Iteration 208/1000 | Loss: 0.00001955
Iteration 209/1000 | Loss: 0.00001954
Iteration 210/1000 | Loss: 0.00001954
Iteration 211/1000 | Loss: 0.00001954
Iteration 212/1000 | Loss: 0.00001954
Iteration 213/1000 | Loss: 0.00001954
Iteration 214/1000 | Loss: 0.00001954
Iteration 215/1000 | Loss: 0.00001954
Iteration 216/1000 | Loss: 0.00001953
Iteration 217/1000 | Loss: 0.00001953
Iteration 218/1000 | Loss: 0.00001953
Iteration 219/1000 | Loss: 0.00001952
Iteration 220/1000 | Loss: 0.00001952
Iteration 221/1000 | Loss: 0.00001952
Iteration 222/1000 | Loss: 0.00001952
Iteration 223/1000 | Loss: 0.00001952
Iteration 224/1000 | Loss: 0.00001951
Iteration 225/1000 | Loss: 0.00001951
Iteration 226/1000 | Loss: 0.00001951
Iteration 227/1000 | Loss: 0.00001951
Iteration 228/1000 | Loss: 0.00001951
Iteration 229/1000 | Loss: 0.00001951
Iteration 230/1000 | Loss: 0.00001951
Iteration 231/1000 | Loss: 0.00001951
Iteration 232/1000 | Loss: 0.00001951
Iteration 233/1000 | Loss: 0.00001951
Iteration 234/1000 | Loss: 0.00001951
Iteration 235/1000 | Loss: 0.00001951
Iteration 236/1000 | Loss: 0.00001951
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 236. Stopping optimization.
Last 5 losses: [1.9508426703396253e-05, 1.9508426703396253e-05, 1.9508426703396253e-05, 1.9508426703396253e-05, 1.9508426703396253e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.9508426703396253e-05

Optimization complete. Final v2v error: 3.591120719909668 mm

Highest mean error: 8.033413887023926 mm for frame 81

Lowest mean error: 3.028909921646118 mm for frame 146

Saving results

Total time: 120.26220846176147
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0019/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0019.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0019
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00832841
Iteration 2/25 | Loss: 0.00120749
Iteration 3/25 | Loss: 0.00079301
Iteration 4/25 | Loss: 0.00073234
Iteration 5/25 | Loss: 0.00071886
Iteration 6/25 | Loss: 0.00071410
Iteration 7/25 | Loss: 0.00071270
Iteration 8/25 | Loss: 0.00071257
Iteration 9/25 | Loss: 0.00071257
Iteration 10/25 | Loss: 0.00071257
Iteration 11/25 | Loss: 0.00071257
Iteration 12/25 | Loss: 0.00071257
Iteration 13/25 | Loss: 0.00071257
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0007125717820599675, 0.0007125717820599675, 0.0007125717820599675, 0.0007125717820599675, 0.0007125717820599675]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007125717820599675

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39156878
Iteration 2/25 | Loss: 0.00025610
Iteration 3/25 | Loss: 0.00025610
Iteration 4/25 | Loss: 0.00025610
Iteration 5/25 | Loss: 0.00025610
Iteration 6/25 | Loss: 0.00025610
Iteration 7/25 | Loss: 0.00025610
Iteration 8/25 | Loss: 0.00025610
Iteration 9/25 | Loss: 0.00025610
Iteration 10/25 | Loss: 0.00025610
Iteration 11/25 | Loss: 0.00025610
Iteration 12/25 | Loss: 0.00025610
Iteration 13/25 | Loss: 0.00025610
Iteration 14/25 | Loss: 0.00025610
Iteration 15/25 | Loss: 0.00025610
Iteration 16/25 | Loss: 0.00025610
Iteration 17/25 | Loss: 0.00025610
Iteration 18/25 | Loss: 0.00025610
Iteration 19/25 | Loss: 0.00025610
Iteration 20/25 | Loss: 0.00025610
Iteration 21/25 | Loss: 0.00025610
Iteration 22/25 | Loss: 0.00025610
Iteration 23/25 | Loss: 0.00025610
Iteration 24/25 | Loss: 0.00025610
Iteration 25/25 | Loss: 0.00025610

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00025610
Iteration 2/1000 | Loss: 0.00002560
Iteration 3/1000 | Loss: 0.00001671
Iteration 4/1000 | Loss: 0.00001516
Iteration 5/1000 | Loss: 0.00001431
Iteration 6/1000 | Loss: 0.00001389
Iteration 7/1000 | Loss: 0.00001355
Iteration 8/1000 | Loss: 0.00001321
Iteration 9/1000 | Loss: 0.00001300
Iteration 10/1000 | Loss: 0.00001295
Iteration 11/1000 | Loss: 0.00001294
Iteration 12/1000 | Loss: 0.00001279
Iteration 13/1000 | Loss: 0.00001273
Iteration 14/1000 | Loss: 0.00001262
Iteration 15/1000 | Loss: 0.00001262
Iteration 16/1000 | Loss: 0.00001262
Iteration 17/1000 | Loss: 0.00001261
Iteration 18/1000 | Loss: 0.00001261
Iteration 19/1000 | Loss: 0.00001260
Iteration 20/1000 | Loss: 0.00001260
Iteration 21/1000 | Loss: 0.00001259
Iteration 22/1000 | Loss: 0.00001259
Iteration 23/1000 | Loss: 0.00001259
Iteration 24/1000 | Loss: 0.00001258
Iteration 25/1000 | Loss: 0.00001258
Iteration 26/1000 | Loss: 0.00001257
Iteration 27/1000 | Loss: 0.00001257
Iteration 28/1000 | Loss: 0.00001255
Iteration 29/1000 | Loss: 0.00001255
Iteration 30/1000 | Loss: 0.00001254
Iteration 31/1000 | Loss: 0.00001254
Iteration 32/1000 | Loss: 0.00001254
Iteration 33/1000 | Loss: 0.00001254
Iteration 34/1000 | Loss: 0.00001254
Iteration 35/1000 | Loss: 0.00001253
Iteration 36/1000 | Loss: 0.00001253
Iteration 37/1000 | Loss: 0.00001253
Iteration 38/1000 | Loss: 0.00001253
Iteration 39/1000 | Loss: 0.00001252
Iteration 40/1000 | Loss: 0.00001252
Iteration 41/1000 | Loss: 0.00001252
Iteration 42/1000 | Loss: 0.00001252
Iteration 43/1000 | Loss: 0.00001252
Iteration 44/1000 | Loss: 0.00001252
Iteration 45/1000 | Loss: 0.00001252
Iteration 46/1000 | Loss: 0.00001251
Iteration 47/1000 | Loss: 0.00001251
Iteration 48/1000 | Loss: 0.00001251
Iteration 49/1000 | Loss: 0.00001251
Iteration 50/1000 | Loss: 0.00001251
Iteration 51/1000 | Loss: 0.00001251
Iteration 52/1000 | Loss: 0.00001251
Iteration 53/1000 | Loss: 0.00001250
Iteration 54/1000 | Loss: 0.00001250
Iteration 55/1000 | Loss: 0.00001250
Iteration 56/1000 | Loss: 0.00001250
Iteration 57/1000 | Loss: 0.00001250
Iteration 58/1000 | Loss: 0.00001250
Iteration 59/1000 | Loss: 0.00001250
Iteration 60/1000 | Loss: 0.00001250
Iteration 61/1000 | Loss: 0.00001250
Iteration 62/1000 | Loss: 0.00001250
Iteration 63/1000 | Loss: 0.00001250
Iteration 64/1000 | Loss: 0.00001249
Iteration 65/1000 | Loss: 0.00001249
Iteration 66/1000 | Loss: 0.00001249
Iteration 67/1000 | Loss: 0.00001248
Iteration 68/1000 | Loss: 0.00001248
Iteration 69/1000 | Loss: 0.00001248
Iteration 70/1000 | Loss: 0.00001248
Iteration 71/1000 | Loss: 0.00001248
Iteration 72/1000 | Loss: 0.00001248
Iteration 73/1000 | Loss: 0.00001248
Iteration 74/1000 | Loss: 0.00001248
Iteration 75/1000 | Loss: 0.00001247
Iteration 76/1000 | Loss: 0.00001247
Iteration 77/1000 | Loss: 0.00001247
Iteration 78/1000 | Loss: 0.00001247
Iteration 79/1000 | Loss: 0.00001247
Iteration 80/1000 | Loss: 0.00001246
Iteration 81/1000 | Loss: 0.00001246
Iteration 82/1000 | Loss: 0.00001246
Iteration 83/1000 | Loss: 0.00001246
Iteration 84/1000 | Loss: 0.00001246
Iteration 85/1000 | Loss: 0.00001246
Iteration 86/1000 | Loss: 0.00001246
Iteration 87/1000 | Loss: 0.00001245
Iteration 88/1000 | Loss: 0.00001245
Iteration 89/1000 | Loss: 0.00001245
Iteration 90/1000 | Loss: 0.00001245
Iteration 91/1000 | Loss: 0.00001245
Iteration 92/1000 | Loss: 0.00001245
Iteration 93/1000 | Loss: 0.00001245
Iteration 94/1000 | Loss: 0.00001245
Iteration 95/1000 | Loss: 0.00001245
Iteration 96/1000 | Loss: 0.00001245
Iteration 97/1000 | Loss: 0.00001244
Iteration 98/1000 | Loss: 0.00001244
Iteration 99/1000 | Loss: 0.00001244
Iteration 100/1000 | Loss: 0.00001244
Iteration 101/1000 | Loss: 0.00001244
Iteration 102/1000 | Loss: 0.00001244
Iteration 103/1000 | Loss: 0.00001244
Iteration 104/1000 | Loss: 0.00001244
Iteration 105/1000 | Loss: 0.00001243
Iteration 106/1000 | Loss: 0.00001243
Iteration 107/1000 | Loss: 0.00001243
Iteration 108/1000 | Loss: 0.00001243
Iteration 109/1000 | Loss: 0.00001243
Iteration 110/1000 | Loss: 0.00001243
Iteration 111/1000 | Loss: 0.00001243
Iteration 112/1000 | Loss: 0.00001243
Iteration 113/1000 | Loss: 0.00001243
Iteration 114/1000 | Loss: 0.00001242
Iteration 115/1000 | Loss: 0.00001242
Iteration 116/1000 | Loss: 0.00001242
Iteration 117/1000 | Loss: 0.00001242
Iteration 118/1000 | Loss: 0.00001242
Iteration 119/1000 | Loss: 0.00001242
Iteration 120/1000 | Loss: 0.00001242
Iteration 121/1000 | Loss: 0.00001242
Iteration 122/1000 | Loss: 0.00001242
Iteration 123/1000 | Loss: 0.00001242
Iteration 124/1000 | Loss: 0.00001242
Iteration 125/1000 | Loss: 0.00001242
Iteration 126/1000 | Loss: 0.00001242
Iteration 127/1000 | Loss: 0.00001242
Iteration 128/1000 | Loss: 0.00001242
Iteration 129/1000 | Loss: 0.00001242
Iteration 130/1000 | Loss: 0.00001242
Iteration 131/1000 | Loss: 0.00001242
Iteration 132/1000 | Loss: 0.00001242
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 132. Stopping optimization.
Last 5 losses: [1.2422431609593332e-05, 1.2422431609593332e-05, 1.2422431609593332e-05, 1.2422431609593332e-05, 1.2422431609593332e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.2422431609593332e-05

Optimization complete. Final v2v error: 2.9641823768615723 mm

Highest mean error: 3.3355519771575928 mm for frame 162

Lowest mean error: 2.346165657043457 mm for frame 0

Saving results

Total time: 39.531662940979004
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/male_31_us_0424/0009/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0009.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/male_31_us_0424/0009
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00846162
Iteration 2/25 | Loss: 0.00091482
Iteration 3/25 | Loss: 0.00073073
Iteration 4/25 | Loss: 0.00070636
Iteration 5/25 | Loss: 0.00069772
Iteration 6/25 | Loss: 0.00069567
Iteration 7/25 | Loss: 0.00069545
Iteration 8/25 | Loss: 0.00069545
Iteration 9/25 | Loss: 0.00069545
Iteration 10/25 | Loss: 0.00069545
Iteration 11/25 | Loss: 0.00069545
Iteration 12/25 | Loss: 0.00069545
Iteration 13/25 | Loss: 0.00069545
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 13. Stopping optimization.
Last 5 losses: [0.0006954454584047198, 0.0006954454584047198, 0.0006954454584047198, 0.0006954454584047198, 0.0006954454584047198]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0006954454584047198

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.39451230
Iteration 2/25 | Loss: 0.00029080
Iteration 3/25 | Loss: 0.00029080
Iteration 4/25 | Loss: 0.00029080
Iteration 5/25 | Loss: 0.00029080
Iteration 6/25 | Loss: 0.00029080
Iteration 7/25 | Loss: 0.00029080
Iteration 8/25 | Loss: 0.00029080
Iteration 9/25 | Loss: 0.00029080
Iteration 10/25 | Loss: 0.00029080
Iteration 11/25 | Loss: 0.00029080
Iteration 12/25 | Loss: 0.00029080
Iteration 13/25 | Loss: 0.00029080
Iteration 14/25 | Loss: 0.00029080
Iteration 15/25 | Loss: 0.00029080
Iteration 16/25 | Loss: 0.00029080
Iteration 17/25 | Loss: 0.00029080
Iteration 18/25 | Loss: 0.00029080
Iteration 19/25 | Loss: 0.00029080
Iteration 20/25 | Loss: 0.00029080
Iteration 21/25 | Loss: 0.00029080
Iteration 22/25 | Loss: 0.00029080
Iteration 23/25 | Loss: 0.00029080
Iteration 24/25 | Loss: 0.00029080
Iteration 25/25 | Loss: 0.00029080

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00029080
Iteration 2/1000 | Loss: 0.00002805
Iteration 3/1000 | Loss: 0.00001550
Iteration 4/1000 | Loss: 0.00001392
Iteration 5/1000 | Loss: 0.00001307
Iteration 6/1000 | Loss: 0.00001289
Iteration 7/1000 | Loss: 0.00001255
Iteration 8/1000 | Loss: 0.00001233
Iteration 9/1000 | Loss: 0.00001221
Iteration 10/1000 | Loss: 0.00001215
Iteration 11/1000 | Loss: 0.00001214
Iteration 12/1000 | Loss: 0.00001214
Iteration 13/1000 | Loss: 0.00001211
Iteration 14/1000 | Loss: 0.00001211
Iteration 15/1000 | Loss: 0.00001210
Iteration 16/1000 | Loss: 0.00001210
Iteration 17/1000 | Loss: 0.00001210
Iteration 18/1000 | Loss: 0.00001210
Iteration 19/1000 | Loss: 0.00001210
Iteration 20/1000 | Loss: 0.00001210
Iteration 21/1000 | Loss: 0.00001210
Iteration 22/1000 | Loss: 0.00001210
Iteration 23/1000 | Loss: 0.00001207
Iteration 24/1000 | Loss: 0.00001205
Iteration 25/1000 | Loss: 0.00001205
Iteration 26/1000 | Loss: 0.00001205
Iteration 27/1000 | Loss: 0.00001205
Iteration 28/1000 | Loss: 0.00001205
Iteration 29/1000 | Loss: 0.00001204
Iteration 30/1000 | Loss: 0.00001204
Iteration 31/1000 | Loss: 0.00001201
Iteration 32/1000 | Loss: 0.00001197
Iteration 33/1000 | Loss: 0.00001195
Iteration 34/1000 | Loss: 0.00001195
Iteration 35/1000 | Loss: 0.00001194
Iteration 36/1000 | Loss: 0.00001190
Iteration 37/1000 | Loss: 0.00001190
Iteration 38/1000 | Loss: 0.00001188
Iteration 39/1000 | Loss: 0.00001188
Iteration 40/1000 | Loss: 0.00001187
Iteration 41/1000 | Loss: 0.00001187
Iteration 42/1000 | Loss: 0.00001187
Iteration 43/1000 | Loss: 0.00001187
Iteration 44/1000 | Loss: 0.00001187
Iteration 45/1000 | Loss: 0.00001187
Iteration 46/1000 | Loss: 0.00001187
Iteration 47/1000 | Loss: 0.00001187
Iteration 48/1000 | Loss: 0.00001187
Iteration 49/1000 | Loss: 0.00001187
Iteration 50/1000 | Loss: 0.00001187
Iteration 51/1000 | Loss: 0.00001185
Iteration 52/1000 | Loss: 0.00001183
Iteration 53/1000 | Loss: 0.00001183
Iteration 54/1000 | Loss: 0.00001183
Iteration 55/1000 | Loss: 0.00001183
Iteration 56/1000 | Loss: 0.00001182
Iteration 57/1000 | Loss: 0.00001182
Iteration 58/1000 | Loss: 0.00001180
Iteration 59/1000 | Loss: 0.00001180
Iteration 60/1000 | Loss: 0.00001180
Iteration 61/1000 | Loss: 0.00001180
Iteration 62/1000 | Loss: 0.00001180
Iteration 63/1000 | Loss: 0.00001180
Iteration 64/1000 | Loss: 0.00001180
Iteration 65/1000 | Loss: 0.00001180
Iteration 66/1000 | Loss: 0.00001179
Iteration 67/1000 | Loss: 0.00001179
Iteration 68/1000 | Loss: 0.00001179
Iteration 69/1000 | Loss: 0.00001178
Iteration 70/1000 | Loss: 0.00001178
Iteration 71/1000 | Loss: 0.00001178
Iteration 72/1000 | Loss: 0.00001177
Iteration 73/1000 | Loss: 0.00001177
Iteration 74/1000 | Loss: 0.00001177
Iteration 75/1000 | Loss: 0.00001177
Iteration 76/1000 | Loss: 0.00001177
Iteration 77/1000 | Loss: 0.00001176
Iteration 78/1000 | Loss: 0.00001176
Iteration 79/1000 | Loss: 0.00001176
Iteration 80/1000 | Loss: 0.00001176
Iteration 81/1000 | Loss: 0.00001176
Iteration 82/1000 | Loss: 0.00001175
Iteration 83/1000 | Loss: 0.00001175
Iteration 84/1000 | Loss: 0.00001175
Iteration 85/1000 | Loss: 0.00001175
Iteration 86/1000 | Loss: 0.00001175
Iteration 87/1000 | Loss: 0.00001175
Iteration 88/1000 | Loss: 0.00001174
Iteration 89/1000 | Loss: 0.00001174
Iteration 90/1000 | Loss: 0.00001174
Iteration 91/1000 | Loss: 0.00001174
Iteration 92/1000 | Loss: 0.00001174
Iteration 93/1000 | Loss: 0.00001174
Iteration 94/1000 | Loss: 0.00001174
Iteration 95/1000 | Loss: 0.00001174
Iteration 96/1000 | Loss: 0.00001174
Iteration 97/1000 | Loss: 0.00001174
Iteration 98/1000 | Loss: 0.00001174
Iteration 99/1000 | Loss: 0.00001174
Iteration 100/1000 | Loss: 0.00001174
Iteration 101/1000 | Loss: 0.00001174
Iteration 102/1000 | Loss: 0.00001174
Iteration 103/1000 | Loss: 0.00001174
Iteration 104/1000 | Loss: 0.00001173
Iteration 105/1000 | Loss: 0.00001173
Iteration 106/1000 | Loss: 0.00001173
Iteration 107/1000 | Loss: 0.00001173
Iteration 108/1000 | Loss: 0.00001173
Iteration 109/1000 | Loss: 0.00001173
Iteration 110/1000 | Loss: 0.00001173
Iteration 111/1000 | Loss: 0.00001173
Iteration 112/1000 | Loss: 0.00001173
Iteration 113/1000 | Loss: 0.00001173
Iteration 114/1000 | Loss: 0.00001173
Iteration 115/1000 | Loss: 0.00001173
Iteration 116/1000 | Loss: 0.00001173
Iteration 117/1000 | Loss: 0.00001173
Iteration 118/1000 | Loss: 0.00001173
Iteration 119/1000 | Loss: 0.00001173
Iteration 120/1000 | Loss: 0.00001173
Iteration 121/1000 | Loss: 0.00001173
Iteration 122/1000 | Loss: 0.00001173
Iteration 123/1000 | Loss: 0.00001172
Iteration 124/1000 | Loss: 0.00001172
Iteration 125/1000 | Loss: 0.00001172
Iteration 126/1000 | Loss: 0.00001172
Iteration 127/1000 | Loss: 0.00001172
Iteration 128/1000 | Loss: 0.00001172
Iteration 129/1000 | Loss: 0.00001172
Iteration 130/1000 | Loss: 0.00001172
Iteration 131/1000 | Loss: 0.00001172
Iteration 132/1000 | Loss: 0.00001172
Iteration 133/1000 | Loss: 0.00001172
Iteration 134/1000 | Loss: 0.00001172
Iteration 135/1000 | Loss: 0.00001172
Iteration 136/1000 | Loss: 0.00001172
Iteration 137/1000 | Loss: 0.00001172
Iteration 138/1000 | Loss: 0.00001172
Iteration 139/1000 | Loss: 0.00001172
Iteration 140/1000 | Loss: 0.00001172
Iteration 141/1000 | Loss: 0.00001172
Iteration 142/1000 | Loss: 0.00001171
Iteration 143/1000 | Loss: 0.00001171
Iteration 144/1000 | Loss: 0.00001171
Iteration 145/1000 | Loss: 0.00001171
Iteration 146/1000 | Loss: 0.00001171
Iteration 147/1000 | Loss: 0.00001171
Iteration 148/1000 | Loss: 0.00001171
Iteration 149/1000 | Loss: 0.00001171
Iteration 150/1000 | Loss: 0.00001171
Iteration 151/1000 | Loss: 0.00001171
Iteration 152/1000 | Loss: 0.00001171
Iteration 153/1000 | Loss: 0.00001171
Iteration 154/1000 | Loss: 0.00001171
Iteration 155/1000 | Loss: 0.00001171
Iteration 156/1000 | Loss: 0.00001171
Iteration 157/1000 | Loss: 0.00001171
Iteration 158/1000 | Loss: 0.00001171
Iteration 159/1000 | Loss: 0.00001171
Iteration 160/1000 | Loss: 0.00001171
Iteration 161/1000 | Loss: 0.00001171
Iteration 162/1000 | Loss: 0.00001171
Iteration 163/1000 | Loss: 0.00001171
Iteration 164/1000 | Loss: 0.00001171
Iteration 165/1000 | Loss: 0.00001171
Iteration 166/1000 | Loss: 0.00001171
Iteration 167/1000 | Loss: 0.00001171
Iteration 168/1000 | Loss: 0.00001171
Iteration 169/1000 | Loss: 0.00001171
Iteration 170/1000 | Loss: 0.00001171
Iteration 171/1000 | Loss: 0.00001171
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 171. Stopping optimization.
Last 5 losses: [1.1714705578924622e-05, 1.1714705578924622e-05, 1.1714705578924622e-05, 1.1714705578924622e-05, 1.1714705578924622e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.1714705578924622e-05

Optimization complete. Final v2v error: 2.91196870803833 mm

Highest mean error: 3.400066614151001 mm for frame 45

Lowest mean error: 2.673767566680908 mm for frame 18

Saving results

Total time: 32.74029040336609
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_celina_posed_002/1030/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1030.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1030
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00822248
Iteration 2/25 | Loss: 0.00145315
Iteration 3/25 | Loss: 0.00123905
Iteration 4/25 | Loss: 0.00120646
Iteration 5/25 | Loss: 0.00120013
Iteration 6/25 | Loss: 0.00119888
Iteration 7/25 | Loss: 0.00119877
Iteration 8/25 | Loss: 0.00119877
Iteration 9/25 | Loss: 0.00119877
Iteration 10/25 | Loss: 0.00119877
Iteration 11/25 | Loss: 0.00119877
Iteration 12/25 | Loss: 0.00119877
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 12. Stopping optimization.
Last 5 losses: [0.00119877012912184, 0.00119877012912184, 0.00119877012912184, 0.00119877012912184, 0.00119877012912184]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.00119877012912184

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 0.93841612
Iteration 2/25 | Loss: 0.00073698
Iteration 3/25 | Loss: 0.00073697
Iteration 4/25 | Loss: 0.00073697
Iteration 5/25 | Loss: 0.00073697
Iteration 6/25 | Loss: 0.00073697
Iteration 7/25 | Loss: 0.00073697
Iteration 8/25 | Loss: 0.00073697
Iteration 9/25 | Loss: 0.00073697
Iteration 10/25 | Loss: 0.00073697
Iteration 11/25 | Loss: 0.00073697
Iteration 12/25 | Loss: 0.00073697
Iteration 13/25 | Loss: 0.00073697
Iteration 14/25 | Loss: 0.00073697
Iteration 15/25 | Loss: 0.00073697
Iteration 16/25 | Loss: 0.00073697
Iteration 17/25 | Loss: 0.00073697
Iteration 18/25 | Loss: 0.00073697
Iteration 19/25 | Loss: 0.00073697
Iteration 20/25 | Loss: 0.00073697
Iteration 21/25 | Loss: 0.00073697
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.0007369703380391002, 0.0007369703380391002, 0.0007369703380391002, 0.0007369703380391002, 0.0007369703380391002]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0007369703380391002

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00073697
Iteration 2/1000 | Loss: 0.00004433
Iteration 3/1000 | Loss: 0.00003154
Iteration 4/1000 | Loss: 0.00002707
Iteration 5/1000 | Loss: 0.00002531
Iteration 6/1000 | Loss: 0.00002376
Iteration 7/1000 | Loss: 0.00002280
Iteration 8/1000 | Loss: 0.00002212
Iteration 9/1000 | Loss: 0.00002168
Iteration 10/1000 | Loss: 0.00002131
Iteration 11/1000 | Loss: 0.00002113
Iteration 12/1000 | Loss: 0.00002088
Iteration 13/1000 | Loss: 0.00002071
Iteration 14/1000 | Loss: 0.00002053
Iteration 15/1000 | Loss: 0.00002032
Iteration 16/1000 | Loss: 0.00002025
Iteration 17/1000 | Loss: 0.00002021
Iteration 18/1000 | Loss: 0.00002021
Iteration 19/1000 | Loss: 0.00002020
Iteration 20/1000 | Loss: 0.00002020
Iteration 21/1000 | Loss: 0.00002019
Iteration 22/1000 | Loss: 0.00002019
Iteration 23/1000 | Loss: 0.00002019
Iteration 24/1000 | Loss: 0.00002018
Iteration 25/1000 | Loss: 0.00002018
Iteration 26/1000 | Loss: 0.00002017
Iteration 27/1000 | Loss: 0.00002017
Iteration 28/1000 | Loss: 0.00002016
Iteration 29/1000 | Loss: 0.00002016
Iteration 30/1000 | Loss: 0.00002015
Iteration 31/1000 | Loss: 0.00002014
Iteration 32/1000 | Loss: 0.00002013
Iteration 33/1000 | Loss: 0.00002013
Iteration 34/1000 | Loss: 0.00002013
Iteration 35/1000 | Loss: 0.00002013
Iteration 36/1000 | Loss: 0.00002013
Iteration 37/1000 | Loss: 0.00002013
Iteration 38/1000 | Loss: 0.00002012
Iteration 39/1000 | Loss: 0.00002012
Iteration 40/1000 | Loss: 0.00002012
Iteration 41/1000 | Loss: 0.00002012
Iteration 42/1000 | Loss: 0.00002012
Iteration 43/1000 | Loss: 0.00002012
Iteration 44/1000 | Loss: 0.00002012
Iteration 45/1000 | Loss: 0.00002011
Iteration 46/1000 | Loss: 0.00002011
Iteration 47/1000 | Loss: 0.00002011
Iteration 48/1000 | Loss: 0.00002011
Iteration 49/1000 | Loss: 0.00002011
Iteration 50/1000 | Loss: 0.00002011
Iteration 51/1000 | Loss: 0.00002011
Iteration 52/1000 | Loss: 0.00002011
Iteration 53/1000 | Loss: 0.00002010
Iteration 54/1000 | Loss: 0.00002010
Iteration 55/1000 | Loss: 0.00002010
Iteration 56/1000 | Loss: 0.00002010
Iteration 57/1000 | Loss: 0.00002010
Iteration 58/1000 | Loss: 0.00002010
Iteration 59/1000 | Loss: 0.00002010
Iteration 60/1000 | Loss: 0.00002010
Iteration 61/1000 | Loss: 0.00002010
Iteration 62/1000 | Loss: 0.00002010
Iteration 63/1000 | Loss: 0.00002010
Iteration 64/1000 | Loss: 0.00002010
Iteration 65/1000 | Loss: 0.00002010
Iteration 66/1000 | Loss: 0.00002010
Iteration 67/1000 | Loss: 0.00002010
Iteration 68/1000 | Loss: 0.00002010
Iteration 69/1000 | Loss: 0.00002010
Iteration 70/1000 | Loss: 0.00002010
Iteration 71/1000 | Loss: 0.00002010
Iteration 72/1000 | Loss: 0.00002010
Iteration 73/1000 | Loss: 0.00002010
Iteration 74/1000 | Loss: 0.00002010
Iteration 75/1000 | Loss: 0.00002010
Iteration 76/1000 | Loss: 0.00002010
Iteration 77/1000 | Loss: 0.00002010
Iteration 78/1000 | Loss: 0.00002010
Iteration 79/1000 | Loss: 0.00002010
Iteration 80/1000 | Loss: 0.00002010
Iteration 81/1000 | Loss: 0.00002010
Iteration 82/1000 | Loss: 0.00002010
Iteration 83/1000 | Loss: 0.00002010
Iteration 84/1000 | Loss: 0.00002010
Iteration 85/1000 | Loss: 0.00002010
Iteration 86/1000 | Loss: 0.00002010
Iteration 87/1000 | Loss: 0.00002010
Iteration 88/1000 | Loss: 0.00002010
Iteration 89/1000 | Loss: 0.00002010
Iteration 90/1000 | Loss: 0.00002010
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 90. Stopping optimization.
Last 5 losses: [2.0100427718716674e-05, 2.0100427718716674e-05, 2.0100427718716674e-05, 2.0100427718716674e-05, 2.0100427718716674e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.0100427718716674e-05

Optimization complete. Final v2v error: 3.9372169971466064 mm

Highest mean error: 4.172494411468506 mm for frame 130

Lowest mean error: 3.7294886112213135 mm for frame 108

Saving results

Total time: 33.69878339767456
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_celina_posed_002/1078/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1078.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1078
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00361889
Iteration 2/25 | Loss: 0.00125540
Iteration 3/25 | Loss: 0.00118810
Iteration 4/25 | Loss: 0.00117838
Iteration 5/25 | Loss: 0.00117546
Iteration 6/25 | Loss: 0.00117546
Iteration 7/25 | Loss: 0.00117546
Iteration 8/25 | Loss: 0.00117546
Iteration 9/25 | Loss: 0.00117546
Iteration 10/25 | Loss: 0.00117546
Iteration 11/25 | Loss: 0.00117546
Iteration 12/25 | Loss: 0.00117546
Iteration 13/25 | Loss: 0.00117546
Iteration 14/25 | Loss: 0.00117546
Iteration 15/25 | Loss: 0.00117546
Iteration 16/25 | Loss: 0.00117546
Iteration 17/25 | Loss: 0.00117546
Iteration 18/25 | Loss: 0.00117546
Iteration 19/25 | Loss: 0.00117546
Iteration 20/25 | Loss: 0.00117546
Iteration 21/25 | Loss: 0.00117546
Iteration 22/25 | Loss: 0.00117546
Iteration 23/25 | Loss: 0.00117546
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 23. Stopping optimization.
Last 5 losses: [0.0011754557490348816, 0.0011754557490348816, 0.0011754557490348816, 0.0011754557490348816, 0.0011754557490348816]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.0011754557490348816

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.55642116
Iteration 2/25 | Loss: 0.00119173
Iteration 3/25 | Loss: 0.00119173
Iteration 4/25 | Loss: 0.00119173
Iteration 5/25 | Loss: 0.00119173
Iteration 6/25 | Loss: 0.00119173
Iteration 7/25 | Loss: 0.00119173
Iteration 8/25 | Loss: 0.00119173
Iteration 9/25 | Loss: 0.00119173
Iteration 10/25 | Loss: 0.00119173
Iteration 11/25 | Loss: 0.00119173
Iteration 12/25 | Loss: 0.00119173
Iteration 13/25 | Loss: 0.00119173
Iteration 14/25 | Loss: 0.00119173
Iteration 15/25 | Loss: 0.00119173
Iteration 16/25 | Loss: 0.00119173
Iteration 17/25 | Loss: 0.00119173
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 17. Stopping optimization.
Last 5 losses: [0.001191727351397276, 0.001191727351397276, 0.001191727351397276, 0.001191727351397276, 0.001191727351397276]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.001191727351397276

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00119173
Iteration 2/1000 | Loss: 0.00001758
Iteration 3/1000 | Loss: 0.00001256
Iteration 4/1000 | Loss: 0.00001159
Iteration 5/1000 | Loss: 0.00001089
Iteration 6/1000 | Loss: 0.00001037
Iteration 7/1000 | Loss: 0.00001008
Iteration 8/1000 | Loss: 0.00000982
Iteration 9/1000 | Loss: 0.00000953
Iteration 10/1000 | Loss: 0.00000946
Iteration 11/1000 | Loss: 0.00000938
Iteration 12/1000 | Loss: 0.00000930
Iteration 13/1000 | Loss: 0.00000926
Iteration 14/1000 | Loss: 0.00000917
Iteration 15/1000 | Loss: 0.00000916
Iteration 16/1000 | Loss: 0.00000916
Iteration 17/1000 | Loss: 0.00000915
Iteration 18/1000 | Loss: 0.00000915
Iteration 19/1000 | Loss: 0.00000915
Iteration 20/1000 | Loss: 0.00000914
Iteration 21/1000 | Loss: 0.00000914
Iteration 22/1000 | Loss: 0.00000913
Iteration 23/1000 | Loss: 0.00000907
Iteration 24/1000 | Loss: 0.00000904
Iteration 25/1000 | Loss: 0.00000902
Iteration 26/1000 | Loss: 0.00000902
Iteration 27/1000 | Loss: 0.00000901
Iteration 28/1000 | Loss: 0.00000901
Iteration 29/1000 | Loss: 0.00000900
Iteration 30/1000 | Loss: 0.00000900
Iteration 31/1000 | Loss: 0.00000899
Iteration 32/1000 | Loss: 0.00000894
Iteration 33/1000 | Loss: 0.00000893
Iteration 34/1000 | Loss: 0.00000891
Iteration 35/1000 | Loss: 0.00000891
Iteration 36/1000 | Loss: 0.00000891
Iteration 37/1000 | Loss: 0.00000891
Iteration 38/1000 | Loss: 0.00000886
Iteration 39/1000 | Loss: 0.00000886
Iteration 40/1000 | Loss: 0.00000885
Iteration 41/1000 | Loss: 0.00000880
Iteration 42/1000 | Loss: 0.00000880
Iteration 43/1000 | Loss: 0.00000877
Iteration 44/1000 | Loss: 0.00000875
Iteration 45/1000 | Loss: 0.00000874
Iteration 46/1000 | Loss: 0.00000873
Iteration 47/1000 | Loss: 0.00000873
Iteration 48/1000 | Loss: 0.00000873
Iteration 49/1000 | Loss: 0.00000873
Iteration 50/1000 | Loss: 0.00000873
Iteration 51/1000 | Loss: 0.00000873
Iteration 52/1000 | Loss: 0.00000873
Iteration 53/1000 | Loss: 0.00000873
Iteration 54/1000 | Loss: 0.00000873
Iteration 55/1000 | Loss: 0.00000873
Iteration 56/1000 | Loss: 0.00000872
Iteration 57/1000 | Loss: 0.00000872
Iteration 58/1000 | Loss: 0.00000872
Iteration 59/1000 | Loss: 0.00000872
Iteration 60/1000 | Loss: 0.00000872
Iteration 61/1000 | Loss: 0.00000872
Iteration 62/1000 | Loss: 0.00000872
Iteration 63/1000 | Loss: 0.00000871
Iteration 64/1000 | Loss: 0.00000871
Iteration 65/1000 | Loss: 0.00000871
Iteration 66/1000 | Loss: 0.00000870
Iteration 67/1000 | Loss: 0.00000870
Iteration 68/1000 | Loss: 0.00000870
Iteration 69/1000 | Loss: 0.00000869
Iteration 70/1000 | Loss: 0.00000869
Iteration 71/1000 | Loss: 0.00000869
Iteration 72/1000 | Loss: 0.00000868
Iteration 73/1000 | Loss: 0.00000868
Iteration 74/1000 | Loss: 0.00000868
Iteration 75/1000 | Loss: 0.00000867
Iteration 76/1000 | Loss: 0.00000867
Iteration 77/1000 | Loss: 0.00000867
Iteration 78/1000 | Loss: 0.00000866
Iteration 79/1000 | Loss: 0.00000866
Iteration 80/1000 | Loss: 0.00000866
Iteration 81/1000 | Loss: 0.00000866
Iteration 82/1000 | Loss: 0.00000865
Iteration 83/1000 | Loss: 0.00000865
Iteration 84/1000 | Loss: 0.00000865
Iteration 85/1000 | Loss: 0.00000865
Iteration 86/1000 | Loss: 0.00000865
Iteration 87/1000 | Loss: 0.00000865
Iteration 88/1000 | Loss: 0.00000865
Iteration 89/1000 | Loss: 0.00000865
Iteration 90/1000 | Loss: 0.00000864
Iteration 91/1000 | Loss: 0.00000863
Iteration 92/1000 | Loss: 0.00000863
Iteration 93/1000 | Loss: 0.00000863
Iteration 94/1000 | Loss: 0.00000863
Iteration 95/1000 | Loss: 0.00000863
Iteration 96/1000 | Loss: 0.00000863
Iteration 97/1000 | Loss: 0.00000863
Iteration 98/1000 | Loss: 0.00000862
Iteration 99/1000 | Loss: 0.00000862
Iteration 100/1000 | Loss: 0.00000862
Iteration 101/1000 | Loss: 0.00000862
Iteration 102/1000 | Loss: 0.00000862
Iteration 103/1000 | Loss: 0.00000861
Iteration 104/1000 | Loss: 0.00000861
Iteration 105/1000 | Loss: 0.00000861
Iteration 106/1000 | Loss: 0.00000861
Iteration 107/1000 | Loss: 0.00000861
Iteration 108/1000 | Loss: 0.00000861
Iteration 109/1000 | Loss: 0.00000861
Iteration 110/1000 | Loss: 0.00000860
Iteration 111/1000 | Loss: 0.00000859
Iteration 112/1000 | Loss: 0.00000859
Iteration 113/1000 | Loss: 0.00000859
Iteration 114/1000 | Loss: 0.00000859
Iteration 115/1000 | Loss: 0.00000859
Iteration 116/1000 | Loss: 0.00000859
Iteration 117/1000 | Loss: 0.00000859
Iteration 118/1000 | Loss: 0.00000858
Iteration 119/1000 | Loss: 0.00000858
Iteration 120/1000 | Loss: 0.00000858
Iteration 121/1000 | Loss: 0.00000857
Iteration 122/1000 | Loss: 0.00000856
Iteration 123/1000 | Loss: 0.00000856
Iteration 124/1000 | Loss: 0.00000856
Iteration 125/1000 | Loss: 0.00000856
Iteration 126/1000 | Loss: 0.00000856
Iteration 127/1000 | Loss: 0.00000855
Iteration 128/1000 | Loss: 0.00000855
Iteration 129/1000 | Loss: 0.00000855
Iteration 130/1000 | Loss: 0.00000855
Iteration 131/1000 | Loss: 0.00000855
Iteration 132/1000 | Loss: 0.00000855
Iteration 133/1000 | Loss: 0.00000855
Iteration 134/1000 | Loss: 0.00000855
Iteration 135/1000 | Loss: 0.00000855
Iteration 136/1000 | Loss: 0.00000855
Iteration 137/1000 | Loss: 0.00000854
Iteration 138/1000 | Loss: 0.00000854
Iteration 139/1000 | Loss: 0.00000854
Iteration 140/1000 | Loss: 0.00000854
Iteration 141/1000 | Loss: 0.00000854
Iteration 142/1000 | Loss: 0.00000854
Iteration 143/1000 | Loss: 0.00000854
Iteration 144/1000 | Loss: 0.00000854
Iteration 145/1000 | Loss: 0.00000854
Iteration 146/1000 | Loss: 0.00000854
Iteration 147/1000 | Loss: 0.00000854
Iteration 148/1000 | Loss: 0.00000854
Iteration 149/1000 | Loss: 0.00000854
Iteration 150/1000 | Loss: 0.00000854
Iteration 151/1000 | Loss: 0.00000854
Iteration 152/1000 | Loss: 0.00000854
Iteration 153/1000 | Loss: 0.00000854
Iteration 154/1000 | Loss: 0.00000854
Iteration 155/1000 | Loss: 0.00000854
Iteration 156/1000 | Loss: 0.00000854
Iteration 157/1000 | Loss: 0.00000854
Iteration 158/1000 | Loss: 0.00000854
Iteration 159/1000 | Loss: 0.00000854
Iteration 160/1000 | Loss: 0.00000854
Iteration 161/1000 | Loss: 0.00000854
Iteration 162/1000 | Loss: 0.00000854
Iteration 163/1000 | Loss: 0.00000854
Iteration 164/1000 | Loss: 0.00000854
Iteration 165/1000 | Loss: 0.00000854
Iteration 166/1000 | Loss: 0.00000854
Iteration 167/1000 | Loss: 0.00000854
Iteration 168/1000 | Loss: 0.00000854
Iteration 169/1000 | Loss: 0.00000854
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 169. Stopping optimization.
Last 5 losses: [8.5355914052343e-06, 8.5355914052343e-06, 8.5355914052343e-06, 8.5355914052343e-06, 8.5355914052343e-06]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 8.5355914052343e-06

Optimization complete. Final v2v error: 2.52986478805542 mm

Highest mean error: 2.932159662246704 mm for frame 138

Lowest mean error: 2.4668924808502197 mm for frame 0

Saving results

Total time: 43.621342420578
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_celina_posed_002/1013/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1013.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1013
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.01031971
Iteration 2/25 | Loss: 0.00179973
Iteration 3/25 | Loss: 0.00160006
Iteration 4/25 | Loss: 0.00145872
Iteration 5/25 | Loss: 0.00131778
Iteration 6/25 | Loss: 0.00128879
Iteration 7/25 | Loss: 0.00125688
Iteration 8/25 | Loss: 0.00130433
Iteration 9/25 | Loss: 0.00122809
Iteration 10/25 | Loss: 0.00122757
Iteration 11/25 | Loss: 0.00122772
Iteration 12/25 | Loss: 0.00122467
Iteration 13/25 | Loss: 0.00122151
Iteration 14/25 | Loss: 0.00122210
Iteration 15/25 | Loss: 0.00121976
Iteration 16/25 | Loss: 0.00122159
Iteration 17/25 | Loss: 0.00122019
Iteration 18/25 | Loss: 0.00122197
Iteration 19/25 | Loss: 0.00121962
Iteration 20/25 | Loss: 0.00122022
Iteration 21/25 | Loss: 0.00122342
Iteration 22/25 | Loss: 0.00122098
Iteration 23/25 | Loss: 0.00122123
Iteration 24/25 | Loss: 0.00121943
Iteration 25/25 | Loss: 0.00121732

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.34049165
Iteration 2/25 | Loss: 0.00144970
Iteration 3/25 | Loss: 0.00144970
Iteration 4/25 | Loss: 0.00144970
Iteration 5/25 | Loss: 0.00144970
Iteration 6/25 | Loss: 0.00144970
Iteration 7/25 | Loss: 0.00144970
Iteration 8/25 | Loss: 0.00144970
Iteration 9/25 | Loss: 0.00144970
Iteration 10/25 | Loss: 0.00144970
Iteration 11/25 | Loss: 0.00144970
Iteration 12/25 | Loss: 0.00144970
Iteration 13/25 | Loss: 0.00144970
Iteration 14/25 | Loss: 0.00144970
Iteration 15/25 | Loss: 0.00144970
Iteration 16/25 | Loss: 0.00144970
Iteration 17/25 | Loss: 0.00144970
Iteration 18/25 | Loss: 0.00144970
Iteration 19/25 | Loss: 0.00144970
Iteration 20/25 | Loss: 0.00144970
Iteration 21/25 | Loss: 0.00144970
Iteration 22/25 | Loss: 0.00144970
Iteration 23/25 | Loss: 0.00144970
Iteration 24/25 | Loss: 0.00144970
Iteration 25/25 | Loss: 0.00144970

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00144970
Iteration 2/1000 | Loss: 0.00010802
Iteration 3/1000 | Loss: 0.00035813
Iteration 4/1000 | Loss: 0.00025180
Iteration 5/1000 | Loss: 0.00174839
Iteration 6/1000 | Loss: 0.00586297
Iteration 7/1000 | Loss: 0.00044992
Iteration 8/1000 | Loss: 0.00046197
Iteration 9/1000 | Loss: 0.00005069
Iteration 10/1000 | Loss: 0.00002213
Iteration 11/1000 | Loss: 0.00001869
Iteration 12/1000 | Loss: 0.00001688
Iteration 13/1000 | Loss: 0.00001556
Iteration 14/1000 | Loss: 0.00001485
Iteration 15/1000 | Loss: 0.00001431
Iteration 16/1000 | Loss: 0.00001392
Iteration 17/1000 | Loss: 0.00001357
Iteration 18/1000 | Loss: 0.00001339
Iteration 19/1000 | Loss: 0.00003137
Iteration 20/1000 | Loss: 0.00004206
Iteration 21/1000 | Loss: 0.00001316
Iteration 22/1000 | Loss: 0.00001316
Iteration 23/1000 | Loss: 0.00001316
Iteration 24/1000 | Loss: 0.00001316
Iteration 25/1000 | Loss: 0.00001316
Iteration 26/1000 | Loss: 0.00001316
Iteration 27/1000 | Loss: 0.00001316
Iteration 28/1000 | Loss: 0.00001316
Iteration 29/1000 | Loss: 0.00001316
Iteration 30/1000 | Loss: 0.00001316
Iteration 31/1000 | Loss: 0.00001316
Iteration 32/1000 | Loss: 0.00001316
Iteration 33/1000 | Loss: 0.00001316
Iteration 34/1000 | Loss: 0.00001315
Iteration 35/1000 | Loss: 0.00002270
Iteration 36/1000 | Loss: 0.00007440
Iteration 37/1000 | Loss: 0.00001311
Iteration 38/1000 | Loss: 0.00001670
Iteration 39/1000 | Loss: 0.00001297
Iteration 40/1000 | Loss: 0.00001297
Iteration 41/1000 | Loss: 0.00001297
Iteration 42/1000 | Loss: 0.00001297
Iteration 43/1000 | Loss: 0.00001296
Iteration 44/1000 | Loss: 0.00001296
Iteration 45/1000 | Loss: 0.00001296
Iteration 46/1000 | Loss: 0.00001293
Iteration 47/1000 | Loss: 0.00001293
Iteration 48/1000 | Loss: 0.00001292
Iteration 49/1000 | Loss: 0.00001288
Iteration 50/1000 | Loss: 0.00001284
Iteration 51/1000 | Loss: 0.00001279
Iteration 52/1000 | Loss: 0.00001274
Iteration 53/1000 | Loss: 0.00001274
Iteration 54/1000 | Loss: 0.00001274
Iteration 55/1000 | Loss: 0.00001274
Iteration 56/1000 | Loss: 0.00001274
Iteration 57/1000 | Loss: 0.00001273
Iteration 58/1000 | Loss: 0.00001273
Iteration 59/1000 | Loss: 0.00001273
Iteration 60/1000 | Loss: 0.00001272
Iteration 61/1000 | Loss: 0.00001272
Iteration 62/1000 | Loss: 0.00001272
Iteration 63/1000 | Loss: 0.00001271
Iteration 64/1000 | Loss: 0.00002528
Iteration 65/1000 | Loss: 0.00001272
Iteration 66/1000 | Loss: 0.00001270
Iteration 67/1000 | Loss: 0.00001269
Iteration 68/1000 | Loss: 0.00001269
Iteration 69/1000 | Loss: 0.00001268
Iteration 70/1000 | Loss: 0.00001268
Iteration 71/1000 | Loss: 0.00001268
Iteration 72/1000 | Loss: 0.00001268
Iteration 73/1000 | Loss: 0.00001268
Iteration 74/1000 | Loss: 0.00001268
Iteration 75/1000 | Loss: 0.00001268
Iteration 76/1000 | Loss: 0.00001268
Iteration 77/1000 | Loss: 0.00001267
Iteration 78/1000 | Loss: 0.00001267
Iteration 79/1000 | Loss: 0.00001267
Iteration 80/1000 | Loss: 0.00001267
Iteration 81/1000 | Loss: 0.00001267
Iteration 82/1000 | Loss: 0.00001267
Iteration 83/1000 | Loss: 0.00001267
Iteration 84/1000 | Loss: 0.00001267
Iteration 85/1000 | Loss: 0.00001266
Iteration 86/1000 | Loss: 0.00001266
Iteration 87/1000 | Loss: 0.00001266
Iteration 88/1000 | Loss: 0.00001265
Iteration 89/1000 | Loss: 0.00001265
Iteration 90/1000 | Loss: 0.00001265
Iteration 91/1000 | Loss: 0.00001265
Iteration 92/1000 | Loss: 0.00001264
Iteration 93/1000 | Loss: 0.00001264
Iteration 94/1000 | Loss: 0.00001264
Iteration 95/1000 | Loss: 0.00001264
Iteration 96/1000 | Loss: 0.00001264
Iteration 97/1000 | Loss: 0.00001264
Iteration 98/1000 | Loss: 0.00001264
Iteration 99/1000 | Loss: 0.00001264
Iteration 100/1000 | Loss: 0.00001264
Iteration 101/1000 | Loss: 0.00001264
Iteration 102/1000 | Loss: 0.00001264
Iteration 103/1000 | Loss: 0.00001264
Iteration 104/1000 | Loss: 0.00001263
Iteration 105/1000 | Loss: 0.00001263
Iteration 106/1000 | Loss: 0.00001263
Iteration 107/1000 | Loss: 0.00001263
Iteration 108/1000 | Loss: 0.00001263
Iteration 109/1000 | Loss: 0.00001263
Iteration 110/1000 | Loss: 0.00001263
Iteration 111/1000 | Loss: 0.00001263
Iteration 112/1000 | Loss: 0.00001263
Iteration 113/1000 | Loss: 0.00001263
Iteration 114/1000 | Loss: 0.00001263
Iteration 115/1000 | Loss: 0.00001263
Iteration 116/1000 | Loss: 0.00001263
Iteration 117/1000 | Loss: 0.00001263
Iteration 118/1000 | Loss: 0.00001262
Iteration 119/1000 | Loss: 0.00001262
Iteration 120/1000 | Loss: 0.00001262
Iteration 121/1000 | Loss: 0.00001262
Iteration 122/1000 | Loss: 0.00001262
Iteration 123/1000 | Loss: 0.00001262
Iteration 124/1000 | Loss: 0.00001262
Iteration 125/1000 | Loss: 0.00001262
Iteration 126/1000 | Loss: 0.00001262
Iteration 127/1000 | Loss: 0.00001262
Iteration 128/1000 | Loss: 0.00001262
Iteration 129/1000 | Loss: 0.00001262
Iteration 130/1000 | Loss: 0.00001262
Iteration 131/1000 | Loss: 0.00001262
Iteration 132/1000 | Loss: 0.00001262
Iteration 133/1000 | Loss: 0.00001262
Iteration 134/1000 | Loss: 0.00001261
Iteration 135/1000 | Loss: 0.00001261
Iteration 136/1000 | Loss: 0.00001261
Iteration 137/1000 | Loss: 0.00001261
Iteration 138/1000 | Loss: 0.00001261
Iteration 139/1000 | Loss: 0.00001261
Iteration 140/1000 | Loss: 0.00001261
Iteration 141/1000 | Loss: 0.00001261
Iteration 142/1000 | Loss: 0.00001261
Iteration 143/1000 | Loss: 0.00001261
Iteration 144/1000 | Loss: 0.00001261
Iteration 145/1000 | Loss: 0.00001260
Iteration 146/1000 | Loss: 0.00001260
Iteration 147/1000 | Loss: 0.00001260
Iteration 148/1000 | Loss: 0.00001260
Iteration 149/1000 | Loss: 0.00001260
Iteration 150/1000 | Loss: 0.00001260
Iteration 151/1000 | Loss: 0.00001260
Iteration 152/1000 | Loss: 0.00001260
Iteration 153/1000 | Loss: 0.00001259
Iteration 154/1000 | Loss: 0.00001259
Iteration 155/1000 | Loss: 0.00001259
Iteration 156/1000 | Loss: 0.00001259
Iteration 157/1000 | Loss: 0.00001259
Iteration 158/1000 | Loss: 0.00001259
Iteration 159/1000 | Loss: 0.00001259
Iteration 160/1000 | Loss: 0.00003592
Iteration 161/1000 | Loss: 0.00001277
Iteration 162/1000 | Loss: 0.00001258
Iteration 163/1000 | Loss: 0.00001258
Iteration 164/1000 | Loss: 0.00001257
Iteration 165/1000 | Loss: 0.00001257
Iteration 166/1000 | Loss: 0.00001257
Iteration 167/1000 | Loss: 0.00001257
Iteration 168/1000 | Loss: 0.00001257
Iteration 169/1000 | Loss: 0.00001257
Iteration 170/1000 | Loss: 0.00001257
Iteration 171/1000 | Loss: 0.00001257
Iteration 172/1000 | Loss: 0.00001256
Iteration 173/1000 | Loss: 0.00001256
Iteration 174/1000 | Loss: 0.00001256
Iteration 175/1000 | Loss: 0.00001256
Iteration 176/1000 | Loss: 0.00001256
Iteration 177/1000 | Loss: 0.00001256
Iteration 178/1000 | Loss: 0.00001256
Iteration 179/1000 | Loss: 0.00001256
Iteration 180/1000 | Loss: 0.00001256
Iteration 181/1000 | Loss: 0.00001256
Iteration 182/1000 | Loss: 0.00001256
Iteration 183/1000 | Loss: 0.00001256
Iteration 184/1000 | Loss: 0.00001256
Iteration 185/1000 | Loss: 0.00001256
Iteration 186/1000 | Loss: 0.00001256
Iteration 187/1000 | Loss: 0.00001256
Iteration 188/1000 | Loss: 0.00001256
Iteration 189/1000 | Loss: 0.00001256
Iteration 190/1000 | Loss: 0.00001256
Iteration 191/1000 | Loss: 0.00001256
Iteration 192/1000 | Loss: 0.00001256
Iteration 193/1000 | Loss: 0.00001256
Iteration 194/1000 | Loss: 0.00001256
Iteration 195/1000 | Loss: 0.00001256
Iteration 196/1000 | Loss: 0.00001256
Iteration 197/1000 | Loss: 0.00001256
Iteration 198/1000 | Loss: 0.00001256
Iteration 199/1000 | Loss: 0.00001256
Iteration 200/1000 | Loss: 0.00001256
Iteration 201/1000 | Loss: 0.00001256
Iteration 202/1000 | Loss: 0.00001256
Iteration 203/1000 | Loss: 0.00001256
Iteration 204/1000 | Loss: 0.00001256
Iteration 205/1000 | Loss: 0.00001256
Iteration 206/1000 | Loss: 0.00001256
Iteration 207/1000 | Loss: 0.00001256
Iteration 208/1000 | Loss: 0.00001256
Iteration 209/1000 | Loss: 0.00001256
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 209. Stopping optimization.
Last 5 losses: [1.255596725968644e-05, 1.255596725968644e-05, 1.255596725968644e-05, 1.255596725968644e-05, 1.255596725968644e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 1.255596725968644e-05

Optimization complete. Final v2v error: 3.0432591438293457 mm

Highest mean error: 3.9427926540374756 mm for frame 83

Lowest mean error: 2.8536529541015625 mm for frame 23

Saving results

Total time: 94.09440088272095
Loading the SMPL Parameters /is/cluster/sbhor/smpl_ground_truth_corr/rp_celina_posed_002/1020/motion_seq.npz
Created directory /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1020.
Output directory: /is/cluster/fast/sbhor/star_bedlam_bomoto/rp_celina_posed_002/1020
Using device: cuda:0
Loaded SMPL model from /is/cluster/sbhor/SMPL_models_SMPLIFYX/smpl/SMPL_NEUTRAL.pkl
Loaded STAR model from <_io.BufferedReader name='/is/cluster/sbhor/STAR/star_1_1/star/STAR_NEUTRAL.npz'>
Processing batch 1/1

Performing pose optimization using an edge loss

Iteration 1/25 | Loss: 0.00930766
Iteration 2/25 | Loss: 0.00189657
Iteration 3/25 | Loss: 0.00163338
Iteration 4/25 | Loss: 0.00161212
Iteration 5/25 | Loss: 0.00162386
Iteration 6/25 | Loss: 0.00160427
Iteration 7/25 | Loss: 0.00156369
Iteration 8/25 | Loss: 0.00153545
Iteration 9/25 | Loss: 0.00151609
Iteration 10/25 | Loss: 0.00151059
Iteration 11/25 | Loss: 0.00150327
Iteration 12/25 | Loss: 0.00150223
Iteration 13/25 | Loss: 0.00149868
Iteration 14/25 | Loss: 0.00150462
Iteration 15/25 | Loss: 0.00149854
Iteration 16/25 | Loss: 0.00149595
Iteration 17/25 | Loss: 0.00149918
Iteration 18/25 | Loss: 0.00149570
Iteration 19/25 | Loss: 0.00149562
Iteration 20/25 | Loss: 0.00149562
Iteration 21/25 | Loss: 0.00149562
Iteration 22/25 | Loss: 0.00149562
Iteration 23/25 | Loss: 0.00149561
Iteration 24/25 | Loss: 0.00149561
Iteration 25/25 | Loss: 0.00149561

Performing global translation and orientation optimization using a vertex loss

Iteration 1/25 | Loss: 1.84889495
Iteration 2/25 | Loss: 0.00273580
Iteration 3/25 | Loss: 0.00243509
Iteration 4/25 | Loss: 0.00243481
Iteration 5/25 | Loss: 0.00243481
Iteration 6/25 | Loss: 0.00243481
Iteration 7/25 | Loss: 0.00243481
Iteration 8/25 | Loss: 0.00243481
Iteration 9/25 | Loss: 0.00243481
Iteration 10/25 | Loss: 0.00243481
Iteration 11/25 | Loss: 0.00243481
Iteration 12/25 | Loss: 0.00243481
Iteration 13/25 | Loss: 0.00243481
Iteration 14/25 | Loss: 0.00243480
Iteration 15/25 | Loss: 0.00243481
Iteration 16/25 | Loss: 0.00243480
Iteration 17/25 | Loss: 0.00243480
Iteration 18/25 | Loss: 0.00243480
Iteration 19/25 | Loss: 0.00243480
Iteration 20/25 | Loss: 0.00243480
Iteration 21/25 | Loss: 0.00243480
Low loss delta threshold (1e-12) for 5 consecutive iterations reached at iteration 21. Stopping optimization.
Last 5 losses: [0.002434804802760482, 0.002434804802760482, 0.002434804802760482, 0.002434804802760482, 0.002434804802760482]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 0.002434804802760482

Optimizing all parameters using a vertex loss

Iteration 1/1000 | Loss: 0.00243480
Iteration 2/1000 | Loss: 0.00027362
Iteration 3/1000 | Loss: 0.00180158
Iteration 4/1000 | Loss: 0.00075436
Iteration 5/1000 | Loss: 0.00081582
Iteration 6/1000 | Loss: 0.00012411
Iteration 7/1000 | Loss: 0.00014685
Iteration 8/1000 | Loss: 0.00032680
Iteration 9/1000 | Loss: 0.00007767
Iteration 10/1000 | Loss: 0.00006856
Iteration 11/1000 | Loss: 0.00047378
Iteration 12/1000 | Loss: 0.00006386
Iteration 13/1000 | Loss: 0.00018972
Iteration 14/1000 | Loss: 0.00005665
Iteration 15/1000 | Loss: 0.00005273
Iteration 16/1000 | Loss: 0.00005030
Iteration 17/1000 | Loss: 0.00054572
Iteration 18/1000 | Loss: 0.00078812
Iteration 19/1000 | Loss: 0.00089277
Iteration 20/1000 | Loss: 0.00059335
Iteration 21/1000 | Loss: 0.00057520
Iteration 22/1000 | Loss: 0.00029490
Iteration 23/1000 | Loss: 0.00005877
Iteration 24/1000 | Loss: 0.00005190
Iteration 25/1000 | Loss: 0.00036904
Iteration 26/1000 | Loss: 0.00005104
Iteration 27/1000 | Loss: 0.00004495
Iteration 28/1000 | Loss: 0.00018723
Iteration 29/1000 | Loss: 0.00004996
Iteration 30/1000 | Loss: 0.00004223
Iteration 31/1000 | Loss: 0.00021704
Iteration 32/1000 | Loss: 0.00031396
Iteration 33/1000 | Loss: 0.00004520
Iteration 34/1000 | Loss: 0.00003916
Iteration 35/1000 | Loss: 0.00003583
Iteration 36/1000 | Loss: 0.00003429
Iteration 37/1000 | Loss: 0.00003374
Iteration 38/1000 | Loss: 0.00025698
Iteration 39/1000 | Loss: 0.00004022
Iteration 40/1000 | Loss: 0.00003403
Iteration 41/1000 | Loss: 0.00003197
Iteration 42/1000 | Loss: 0.00003087
Iteration 43/1000 | Loss: 0.00003049
Iteration 44/1000 | Loss: 0.00003019
Iteration 45/1000 | Loss: 0.00002994
Iteration 46/1000 | Loss: 0.00002991
Iteration 47/1000 | Loss: 0.00002977
Iteration 48/1000 | Loss: 0.00002975
Iteration 49/1000 | Loss: 0.00002970
Iteration 50/1000 | Loss: 0.00002960
Iteration 51/1000 | Loss: 0.00002949
Iteration 52/1000 | Loss: 0.00002940
Iteration 53/1000 | Loss: 0.00002940
Iteration 54/1000 | Loss: 0.00002939
Iteration 55/1000 | Loss: 0.00002938
Iteration 56/1000 | Loss: 0.00002938
Iteration 57/1000 | Loss: 0.00002937
Iteration 58/1000 | Loss: 0.00002935
Iteration 59/1000 | Loss: 0.00002934
Iteration 60/1000 | Loss: 0.00002929
Iteration 61/1000 | Loss: 0.00002928
Iteration 62/1000 | Loss: 0.00002928
Iteration 63/1000 | Loss: 0.00002928
Iteration 64/1000 | Loss: 0.00002927
Iteration 65/1000 | Loss: 0.00002927
Iteration 66/1000 | Loss: 0.00002927
Iteration 67/1000 | Loss: 0.00002927
Iteration 68/1000 | Loss: 0.00002927
Iteration 69/1000 | Loss: 0.00002926
Iteration 70/1000 | Loss: 0.00002926
Iteration 71/1000 | Loss: 0.00002926
Iteration 72/1000 | Loss: 0.00002926
Iteration 73/1000 | Loss: 0.00002926
Iteration 74/1000 | Loss: 0.00002926
Iteration 75/1000 | Loss: 0.00002926
Iteration 76/1000 | Loss: 0.00002926
Iteration 77/1000 | Loss: 0.00002926
Iteration 78/1000 | Loss: 0.00002926
Iteration 79/1000 | Loss: 0.00002926
Iteration 80/1000 | Loss: 0.00002925
Iteration 81/1000 | Loss: 0.00002925
Iteration 82/1000 | Loss: 0.00002925
Iteration 83/1000 | Loss: 0.00002924
Iteration 84/1000 | Loss: 0.00002924
Iteration 85/1000 | Loss: 0.00002923
Iteration 86/1000 | Loss: 0.00002923
Iteration 87/1000 | Loss: 0.00002923
Iteration 88/1000 | Loss: 0.00002923
Iteration 89/1000 | Loss: 0.00002923
Iteration 90/1000 | Loss: 0.00002923
Iteration 91/1000 | Loss: 0.00002923
Iteration 92/1000 | Loss: 0.00002922
Iteration 93/1000 | Loss: 0.00002922
Iteration 94/1000 | Loss: 0.00002922
Iteration 95/1000 | Loss: 0.00002921
Iteration 96/1000 | Loss: 0.00002920
Iteration 97/1000 | Loss: 0.00002920
Iteration 98/1000 | Loss: 0.00002919
Iteration 99/1000 | Loss: 0.00002918
Iteration 100/1000 | Loss: 0.00002916
Iteration 101/1000 | Loss: 0.00002915
Iteration 102/1000 | Loss: 0.00002915
Iteration 103/1000 | Loss: 0.00002913
Iteration 104/1000 | Loss: 0.00002912
Iteration 105/1000 | Loss: 0.00002911
Iteration 106/1000 | Loss: 0.00002911
Iteration 107/1000 | Loss: 0.00002910
Iteration 108/1000 | Loss: 0.00002910
Iteration 109/1000 | Loss: 0.00002909
Iteration 110/1000 | Loss: 0.00002909
Iteration 111/1000 | Loss: 0.00002909
Iteration 112/1000 | Loss: 0.00002909
Iteration 113/1000 | Loss: 0.00002909
Iteration 114/1000 | Loss: 0.00002909
Iteration 115/1000 | Loss: 0.00002908
Iteration 116/1000 | Loss: 0.00002908
Iteration 117/1000 | Loss: 0.00002907
Iteration 118/1000 | Loss: 0.00002907
Iteration 119/1000 | Loss: 0.00002907
Iteration 120/1000 | Loss: 0.00002906
Iteration 121/1000 | Loss: 0.00002906
Iteration 122/1000 | Loss: 0.00002905
Iteration 123/1000 | Loss: 0.00002905
Iteration 124/1000 | Loss: 0.00002905
Iteration 125/1000 | Loss: 0.00002905
Iteration 126/1000 | Loss: 0.00002905
Iteration 127/1000 | Loss: 0.00002905
Iteration 128/1000 | Loss: 0.00002904
Iteration 129/1000 | Loss: 0.00002904
Iteration 130/1000 | Loss: 0.00002904
Iteration 131/1000 | Loss: 0.00002904
Iteration 132/1000 | Loss: 0.00002904
Iteration 133/1000 | Loss: 0.00002904
Iteration 134/1000 | Loss: 0.00002904
Iteration 135/1000 | Loss: 0.00002904
Iteration 136/1000 | Loss: 0.00002904
Iteration 137/1000 | Loss: 0.00002904
Iteration 138/1000 | Loss: 0.00002904
Iteration 139/1000 | Loss: 0.00002904
Iteration 140/1000 | Loss: 0.00002903
Iteration 141/1000 | Loss: 0.00002903
Iteration 142/1000 | Loss: 0.00002902
Iteration 143/1000 | Loss: 0.00002902
Iteration 144/1000 | Loss: 0.00002901
Iteration 145/1000 | Loss: 0.00002901
Iteration 146/1000 | Loss: 0.00002901
Iteration 147/1000 | Loss: 0.00002901
Iteration 148/1000 | Loss: 0.00002900
Iteration 149/1000 | Loss: 0.00002900
Iteration 150/1000 | Loss: 0.00002900
Iteration 151/1000 | Loss: 0.00002899
Iteration 152/1000 | Loss: 0.00002899
Iteration 153/1000 | Loss: 0.00002899
Iteration 154/1000 | Loss: 0.00002899
Iteration 155/1000 | Loss: 0.00002899
Iteration 156/1000 | Loss: 0.00002899
Iteration 157/1000 | Loss: 0.00002899
Iteration 158/1000 | Loss: 0.00002899
Iteration 159/1000 | Loss: 0.00002899
Iteration 160/1000 | Loss: 0.00002899
Iteration 161/1000 | Loss: 0.00002899
Iteration 162/1000 | Loss: 0.00002899
Iteration 163/1000 | Loss: 0.00002898
Iteration 164/1000 | Loss: 0.00002898
Iteration 165/1000 | Loss: 0.00002898
Iteration 166/1000 | Loss: 0.00002896
Iteration 167/1000 | Loss: 0.00002895
Iteration 168/1000 | Loss: 0.00002895
Iteration 169/1000 | Loss: 0.00002895
Iteration 170/1000 | Loss: 0.00002894
Iteration 171/1000 | Loss: 0.00002894
Iteration 172/1000 | Loss: 0.00002894
Iteration 173/1000 | Loss: 0.00002894
Iteration 174/1000 | Loss: 0.00002893
Iteration 175/1000 | Loss: 0.00002893
Iteration 176/1000 | Loss: 0.00002893
Iteration 177/1000 | Loss: 0.00002893
Iteration 178/1000 | Loss: 0.00002893
Iteration 179/1000 | Loss: 0.00002893
Iteration 180/1000 | Loss: 0.00002893
Iteration 181/1000 | Loss: 0.00002893
Iteration 182/1000 | Loss: 0.00002893
Iteration 183/1000 | Loss: 0.00002893
Iteration 184/1000 | Loss: 0.00002893
Iteration 185/1000 | Loss: 0.00002893
Iteration 186/1000 | Loss: 0.00002893
Iteration 187/1000 | Loss: 0.00002893
Iteration 188/1000 | Loss: 0.00002893
Iteration 189/1000 | Loss: 0.00002892
Iteration 190/1000 | Loss: 0.00002892
Iteration 191/1000 | Loss: 0.00002892
Iteration 192/1000 | Loss: 0.00002892
Iteration 193/1000 | Loss: 0.00002891
Iteration 194/1000 | Loss: 0.00002891
Iteration 195/1000 | Loss: 0.00002891
Iteration 196/1000 | Loss: 0.00002891
Iteration 197/1000 | Loss: 0.00002890
Iteration 198/1000 | Loss: 0.00002890
Iteration 199/1000 | Loss: 0.00002890
Iteration 200/1000 | Loss: 0.00002890
Iteration 201/1000 | Loss: 0.00002889
Iteration 202/1000 | Loss: 0.00002889
Iteration 203/1000 | Loss: 0.00002889
Iteration 204/1000 | Loss: 0.00002889
Iteration 205/1000 | Loss: 0.00002889
Iteration 206/1000 | Loss: 0.00002889
Iteration 207/1000 | Loss: 0.00002888
Iteration 208/1000 | Loss: 0.00002888
Iteration 209/1000 | Loss: 0.00002888
Iteration 210/1000 | Loss: 0.00002888
Iteration 211/1000 | Loss: 0.00002888
Iteration 212/1000 | Loss: 0.00002888
Iteration 213/1000 | Loss: 0.00002888
Iteration 214/1000 | Loss: 0.00002888
Iteration 215/1000 | Loss: 0.00002888
Iteration 216/1000 | Loss: 0.00002888
Iteration 217/1000 | Loss: 0.00002888
Iteration 218/1000 | Loss: 0.00002888
Iteration 219/1000 | Loss: 0.00002888
Iteration 220/1000 | Loss: 0.00002888
Iteration 221/1000 | Loss: 0.00002887
Iteration 222/1000 | Loss: 0.00002887
Iteration 223/1000 | Loss: 0.00002887
Iteration 224/1000 | Loss: 0.00002887
Iteration 225/1000 | Loss: 0.00002887
Iteration 226/1000 | Loss: 0.00002887
Iteration 227/1000 | Loss: 0.00002887
Iteration 228/1000 | Loss: 0.00002886
Iteration 229/1000 | Loss: 0.00002886
Iteration 230/1000 | Loss: 0.00002886
Iteration 231/1000 | Loss: 0.00002886
Iteration 232/1000 | Loss: 0.00002886
Iteration 233/1000 | Loss: 0.00002886
Iteration 234/1000 | Loss: 0.00002885
Iteration 235/1000 | Loss: 0.00002885
Iteration 236/1000 | Loss: 0.00002885
Iteration 237/1000 | Loss: 0.00002885
Iteration 238/1000 | Loss: 0.00002885
Iteration 239/1000 | Loss: 0.00002885
Iteration 240/1000 | Loss: 0.00002885
Iteration 241/1000 | Loss: 0.00002885
Iteration 242/1000 | Loss: 0.00002885
Iteration 243/1000 | Loss: 0.00002885
Iteration 244/1000 | Loss: 0.00002885
Iteration 245/1000 | Loss: 0.00002885
Iteration 246/1000 | Loss: 0.00002885
Iteration 247/1000 | Loss: 0.00002885
Iteration 248/1000 | Loss: 0.00002884
Iteration 249/1000 | Loss: 0.00002884
Iteration 250/1000 | Loss: 0.00002884
Iteration 251/1000 | Loss: 0.00002884
Iteration 252/1000 | Loss: 0.00002884
Iteration 253/1000 | Loss: 0.00002884
Iteration 254/1000 | Loss: 0.00002884
Iteration 255/1000 | Loss: 0.00002884
Iteration 256/1000 | Loss: 0.00002884
Iteration 257/1000 | Loss: 0.00002884
Iteration 258/1000 | Loss: 0.00002884
Iteration 259/1000 | Loss: 0.00002884
Iteration 260/1000 | Loss: 0.00002884
Iteration 261/1000 | Loss: 0.00002884
Iteration 262/1000 | Loss: 0.00002884
Iteration 263/1000 | Loss: 0.00002883
Iteration 264/1000 | Loss: 0.00002883
Iteration 265/1000 | Loss: 0.00002883
Iteration 266/1000 | Loss: 0.00002883
Iteration 267/1000 | Loss: 0.00002883
Iteration 268/1000 | Loss: 0.00002883
Iteration 269/1000 | Loss: 0.00002883
Iteration 270/1000 | Loss: 0.00002883
Iteration 271/1000 | Loss: 0.00002883
Iteration 272/1000 | Loss: 0.00002883
Iteration 273/1000 | Loss: 0.00002883
Iteration 274/1000 | Loss: 0.00002883
Iteration 275/1000 | Loss: 0.00002883
Iteration 276/1000 | Loss: 0.00002883
Iteration 277/1000 | Loss: 0.00002883
Iteration 278/1000 | Loss: 0.00002883
Iteration 279/1000 | Loss: 0.00002883
Iteration 280/1000 | Loss: 0.00002883
Iteration 281/1000 | Loss: 0.00002883
Iteration 282/1000 | Loss: 0.00002883
Iteration 283/1000 | Loss: 0.00002883
Iteration 284/1000 | Loss: 0.00002883
Iteration 285/1000 | Loss: 0.00002883
Iteration 286/1000 | Loss: 0.00002883
Iteration 287/1000 | Loss: 0.00002883
Iteration 288/1000 | Loss: 0.00002883
Iteration 289/1000 | Loss: 0.00002883
Iteration 290/1000 | Loss: 0.00002883
Iteration 291/1000 | Loss: 0.00002883
Iteration 292/1000 | Loss: 0.00002883
Iteration 293/1000 | Loss: 0.00002883
Iteration 294/1000 | Loss: 0.00002883
Iteration 295/1000 | Loss: 0.00002883
Iteration 296/1000 | Loss: 0.00002883
Iteration 297/1000 | Loss: 0.00002883
Iteration 298/1000 | Loss: 0.00002883
Iteration 299/1000 | Loss: 0.00002883
Iteration 300/1000 | Loss: 0.00002883
Iteration 301/1000 | Loss: 0.00002883
Iteration 302/1000 | Loss: 0.00002883
Iteration 303/1000 | Loss: 0.00002883
Iteration 304/1000 | Loss: 0.00002883
Iteration 305/1000 | Loss: 0.00002883
Iteration 306/1000 | Loss: 0.00002883
Iteration 307/1000 | Loss: 0.00002883
Iteration 308/1000 | Loss: 0.00002883
Iteration 309/1000 | Loss: 0.00002883
Iteration 310/1000 | Loss: 0.00002883
Iteration 311/1000 | Loss: 0.00002883
Iteration 312/1000 | Loss: 0.00002883
Iteration 313/1000 | Loss: 0.00002883
Iteration 314/1000 | Loss: 0.00002883
Iteration 315/1000 | Loss: 0.00002883
Iteration 316/1000 | Loss: 0.00002883
Iteration 317/1000 | Loss: 0.00002883
Iteration 318/1000 | Loss: 0.00002883
Iteration 319/1000 | Loss: 0.00002883
Iteration 320/1000 | Loss: 0.00002883
Low loss delta threshold (1e-15) for 5 consecutive iterations reached at iteration 320. Stopping optimization.
Last 5 losses: [2.8827955247834325e-05, 2.8827955247834325e-05, 2.8827955247834325e-05, 2.8827955247834325e-05, 2.8827955247834325e-05]
Last 5 loss deltas: [0.0, 0.0, 0.0, 0.0, 0.0]
Final loss: 2.8827955247834325e-05

Optimization complete. Final v2v error: 4.441678524017334 mm

Highest mean error: 5.288960933685303 mm for frame 141

Lowest mean error: 3.3422915935516357 mm for frame 208

Saving results

Total time: 134.80645084381104
